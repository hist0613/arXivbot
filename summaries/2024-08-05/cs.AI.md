New uploads on arXiv(cs.CL)

### Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting (https://arxiv.org/abs/2408.01423)
Comments:
          8 pages,4 figures

- **What's New**: 이번 연구에서는 Natural Language Processing (NLP) 분야에서 사용되는 다양한 Prompt 디자인 전략에서 발생하는 한계를 극복하기 위해, Prompt Recursive Search (PRS) 프레임워크를 제안합니다. 이 프레임워크는 문제의 복잡성을 평가하고 이를 기반으로 구조를 조정하여 토큰을 효율적으로 사용하는 새로운 방법입니다.

- **Technical Details**: 현재 사용되는 주된 Prompt 디자인 방식은 두 가지입니다: Expert-Designed Prompts (EDPs)와 LLM-Derived Prompts (LDPs)입니다. EDPs는 전문가가 특정 데이터셋에 맞게 수동으로 설계하며, 일단 설계되면 변경할 수 없습니다. 반면, LDPs는 언어 모델이 자율적으로 생성하며, 특정 문제에 맞춰 솔루션을 제공하지만 복잡한 문제에서는 오류가 누적될 가능성이 있습니다. PRS 프레임워크는 언어 모델을 활용하여 문제에 맞는 솔루션을 생성하고 문제의 복잡성을 평가하여 구조를 조정합니다.

- **Performance Highlights**: Chain of Thought (CoT) 방식과 비교했을 때, PRS 방식은 BBH 데이터셋에서 Llama3-7B 모델을 사용하여 정확도를 8% 향상시켰으며, 22%의 개선을 달성했습니다. 다양한 도메인에서 다양한 파라미터를 가진 LLM을 사용한 광범위한 실험을 통해 PRS의 효능을 입증했습니다.



### DebateQA: Evaluating Question Answering on Debatable Knowledg (https://arxiv.org/abs/2408.01419)
Comments:
          Dataset and scripts for evaluation are available at this https URL

- **What's New**: 큰 언어 모델(Large Language Models, LLMs)의 발전으로 인해 논쟁적인 질문에 대한 답변을 찾는 것이 가능해졌습니다. 이를 위해서는 LLM 챗봇의 능력을 평가할 신뢰할 만한 방법이 필수적입니다. 이를 해결하기 위해 우리는 DebateQA라는 새로운 데이터셋을 소개합니다. 이 데이터셋은 다양한 관점을 포착한 2,941개의 논쟁적 질문과 여러 인간이 주석한 부분적 답변을 포함하고 있습니다.

- **Technical Details**: DebateQA는 3단계 파이프라인을 통해 부분적 답변을 수집하고, 세 명의 주석자가 이를 주석화했습니다. 우리는 두 가지 메트릭스를 개발했습니다: 관점 다양성(Perspective Diversity, P.D.)은 답변이 여러 관점을 포괄하는지 평가하고, 분쟁 인식(Dispute Awareness, D.A.)은 모델이 질문의 논쟁적 성격을 인식하는지 평가합니다. 이 두 메트릭스는 인간의 선호도와 일치하며, 다양한 모델에 걸쳐 안정적입니다.

- **Performance Highlights**: 12개의 인기 있는 LLM과 검색 강화 생성 방법(Retrieval-Augmented Generation, RAG)을 평가한 결과, LLM들은 대체로 논쟁적 이슈를 잘 인식하지만 다양한 관점을 포함한 포괄적 답변을 제공하는 능력에는 차이가 있음을 발견했습니다. 최고의 오픈 소스 LLM은 일부 상용 모델을 능가하거나 동등한 성능을 보였습니다. RAG 방법은 폐쇄형 모델의 성능을 개선했지만 모든 경우에 유익하지는 않았습니다.



### Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs (https://arxiv.org/abs/2408.01417)
Comments:
          Accepted to COLM 2024

- **What's New**: 최신 연구에서는 인간이 시간 경과에 따라 상호작용 중에 효율적인 언어를 점차 사용하게 됨을 밝혀냈습니다. 이러한 현상을 연구하기 위해 ICCA라는 프레임워크를 도입하여 다중모달 대형 언어 모델(MMLMs)이 유사하게 행동하는지 평가했습니다. 연구 결과, MMLMs는 상대방의 효율적인 언어를 이해할 수 있지만 자신들이 자발적으로 언어를 더 효율적으로 만들지는 않는다는 것이 드러났습니다.

- **Technical Details**: 연구진은 ICCA라는 자동화된 프레임워크를 사용하여, 다중모달 언어 모델들의 대화 적응(in-context behavior)을 평가했습니다. 여러 최신 MMLMs 모델들을 테스트한 결과, 일부 모델만이 GPT-4와 같은 강력한 프롬프팅(prompting)을 통해 자신의 언어를 효율적으로 변화시키는 능력을 보였습니다. 이는 인간 언어의 일반적인 특징이지만, 현재의 모델 훈련 체계에서는 이러한 능력이 자연스럽게 나타나지 않는다는 것을 보여줍니다.

- **Performance Highlights**: 몇몇 모델에서는 강력한 프롬프팅(prompting)으로 이러한 효율적인 언어 사용 능력을 이끌어낼 수 있었으나, 대부분의 모델에서는 자발적인 효율성 증가는 관찰되지 않았습니다. 특히 GPT-4 모델이 이에 해당하며, 이는 특정한 훈련 방식 없이는 자연적으로 발생하지 않는다는 점을 강조합니다.



### Improving Multilingual Neural Machine Translation by Utilizing Semantic and Linguistic Features (https://arxiv.org/abs/2408.01394)
Comments:
          Accepted by ACL2024 Findings

- **What's New**: 본 논문에서는 다중 언어 신경기계번역(NMT)에서 의미적 특징과 언어적 특징을 동시에 활용하여 다국어 번역을 개선하는 새로운 접근법을 제안합니다. 특히, 제로샷 번역(Zero-shot translation) 성능을 향상시키기 위해 엔코더와 디코더 측면에서 특징을 분리하여 학습합니다.

- **Technical Details**: 엔코더 측에서는 의미적 특징과 언어적 특징을 분리하여 학습하는 disentangling learning task를 도입합니다. 이는 엔코더 표현을 정렬하여 정보의 완전성을 유지하면서도 언어 간 지식 전이를 촉진합니다. 디코더 측에서는 언어 인코더(linguistic encoder)를 활용하여 저수준 언어적 특징을 통합하고 목표 언어 생성에 도움이 되게 합니다.

- **Performance Highlights**: 다국어 데이터셋을 대상으로 한 실험 결과, 제안된 방법이 기준 시스템(baseline system) 대비 제로샷 번역 방향에서 평균 3.74 BLEU 포인트, 감독된 번역 방향에서 평균 0.18 BLEU 포인트의 성능 향상을 보였습니다. 제안된 방법이 의미적 및 언어적 특징을 효과적으로 활용하여 제로샷 번역에서 비정상적인 번역(off-target)의 비율을 줄였음을 추가 분석을 통해 확인했습니다.



### Coalitions of Large Language Models Increase the Robustness of AI Agents (https://arxiv.org/abs/2408.01380)
- **What's New**: 이번 연구에서는 단일 모델 기반 AI 에이전트의 한계를 극복하기 위해 프리트레인된 모델들로 이루어진 연합(coalition) 접근 방식을 제안하고 평가했습니다. 이를 통해 특정 작업에서 강점을 보이는 모델들을 활용하여 단일 모델보다 더 나은 성능을 달성할 수 있음을 보였습니다.

- **Technical Details**: 연구에서는 서비스 식별, 슬롯 채우기(slot filling), 응답 형성(task of service identification and discovery, slot filling, and response forming)에 대한 작업을 다양한 프리트레인된 오픈소스 모델들에 분배했습니다. ToolAlpaca 벤치마크를 사용하여 대조 실험을 진행했고, 기본 모델보다 연합 방법이 더 나은 정확도를 보여준다는 것을 입증했습니다.

- **Performance Highlights**: ToolAlpaca 데이터셋을 사용한 결과, 연합 모델들이 개별 모델보다 높은 정확도를 기록했습니다. 예를 들어, 일반 목적의 연합 모델 시스템은 58.6%의 정확도를 달성하여, 단일 모델 기반의 시스템보다 약 10% 높은 성능을 보였습니다. 또한, 각 작업에 최적화된 모델들을 배치함으로써, '슬롯 채우기' 작업에서는 Mixtral 모델이, '도구 계획' 작업에서는 Mistral 모델이 뛰어난 성능을 보여 전체 시스템의 정확도를 58.6%까지 끌어올리는 데 기여했습니다.



### Transformers are Universal In-context Learners (https://arxiv.org/abs/2408.01367)
Comments:
          16 pages

- **What's New**: 이 논문은 트랜스포머(Transformers)의 아키텍처가 임의의 수의 컨텍스트 토큰(context tokens)을 처리할 수 있는 능력을 수학적으로 분석합니다. 이를 위해 토큰들의 확률 분포(probability distribution)로 표현된 컨텍스트에 기반한 매핑을 고려합니다. 트랜스포머는 연속적인 in-context 매핑을 임의의 정밀도로 근사할 수 있으며, 고정된 임베딩 차원과 고정된 헤드 수로도 임의의 수의 토큰을 처리할 수 있다는 점을 보입니다.

- **Technical Details**: 이 연구는 토큰의 확률 분포에 의해 조건화된 매핑(mapping)을 수학적으로 모델링합니다. 이 모델에서는 Wasserstein 거리 측면에서 연속성을 분석합니다. 심층 트랜스포머(deep transformers)가 컴팩트한 토큰 도메인에서 연속적인 in-context 매핑을 임의의 정밀도로 근사할 수 있음을 증명합니다. 주요 결과는 주어진 정밀도 내에서 단일 트랜스포머가 고정된 임베딩 차원과 헤드 수를 가지고도 임의의 수, 심지어 무한대의 수의 토큰을 처리할 수 있다는 점입니다.

- **Performance Highlights**: 이 연구는 트랜스포머의 연속성 및 표현력을 확률 분포 공간에서 엄격하게 형식화합니다. 트랜스포머가 심도 있는 아키텍처를 활용하여 임의의 수의 토큰을 효과적으로 처리할 수 있음을 입증합니다. 하지만, 이 접근법은 마스크드 어텐션(masked attention)을 다루지는 않으며 이는 현 프레임워크를 넘어서는 분석이 필요합니다.



### FANNO: Augmenting High-Quality Instruction Data with Open-Sourced LLMs Only (https://arxiv.org/abs/2408.01323)
- **What's New**: FANNO는 대규모 언어 모델(LLM)을 활용하여 더욱 향상된 작업 성능을 제공하기 위해 도입된 완전 자율적이고 오픈 소스 기반의 프레임워크입니다. 전통적으로 비용이 많이 들고 수작업이 필요한 지시(annotation) 데이터 생성의 문제를 해결하기 위해 FANNO는 기존 지시 데이터 없이도 독립적으로 다양한 고품질 데이터를 생산합니다. FANNO는 Mistral-7b-instruct 모델을 활용하여 문서 선별(document pre-screening), 지시 생성(instruction generation), 응답 생성(response generation) 단계를 통해 데이터를 생성합니다.

- **Technical Details**: FANNO는 세 단계로 구성된 지시 데이터 주석(annotating) 프로세스를 통해 작동합니다. 첫 번째 단계에서는 문서 선별이 이루어지며, 이는 문서 분할, 중복 제거, 길이를 기반으로 한 필터링 등을 포함합니다. 두 번째 단계에서는 지시 생성이 이루어지며, 이는 초기 시드 지시(seed instruction) 생성 및 지시 증강(instruction augmentation)을 포함합니다. 마지막 단계에서는 응답 생성 단계가 포함됩니다. 이 과정에서 UCB(Upper Confidence Bound) 부트스트래핑(breathstrapping) 및 필터링 기법이 사용됩니다. FANNO는 SentenceTransformer와 유사한 커뮤니티 검출 알고리즘을 활용하여 지시 임베딩을 클러스터링합니다.

- **Performance Highlights**: FANNO가 생성하는 데이터는 Alpaca-GPT4-Cleaned와 같은 인간이 주석을 단 데이터와 비교하여 높은 품질과 다양성을 제공합니다. 실험 결과, Open LLM Leaderboard와 AlpacaEval 벤치마크에서 FANNO의 데이터는 유사하거나 더 나은 성능을 보여줍니다. 이에 따라 FANNO는 비용 효율적이면서도 고품질의 지시 데이터를 생산할 수 있는 중요한 도구로 자리매김할 수 있습니다.



### Reconsidering Token Embeddings with the Definitions for Pre-trained Language Models (https://arxiv.org/abs/2408.01308)
- **What's New**: 이 연구는 BART-large와 같은 사전 학습된 언어 모델 (Pre-Trained Language Model, PLM)의 미세 조정 (fine-tuning) 역학을 분석하여 이들의 퇴보 현상에 대한 강인성을 보여줍니다. 이를 바탕으로, 새로운 방법론인 DefinitionEMB를 제안하여 사전 정의를 사용해 PLM용으로 의미 관련 토큰 임베딩을 등방적으로 (isotropically) 분포시키면서 원래의 강인성을 유지합니다.

- **Technical Details**: DefinitionEMB는 Wiktionary에서 가져온 정의를 활용하여 토큰 임베딩을 구성합니다. 로버타-베이스 (RoBERTa-base)와 BART-large 모델에 대해 실험을 진행하였으며, 이를 통해 정의가 저빈도 토큰의 의미 손실 문제를 해결하는 데 효과적임을 증명하였습니다.

- **Performance Highlights**: 제안된 DefinitionEMB 방법론은 GLUE와 네 가지 텍스트 요약 데이터셋에서 성능이 향상되었음을 보여줍니다. 특히, 저빈도 토큰의 경우 성능이 더욱 향상되었습니다.



### Deep Learning based Visually Rich Document Content Understanding: A Survey (https://arxiv.org/abs/2408.01287)
Comments:
          Work in Progress

- **What's New**: 최근 문서 이해에서의 발전은 Visually Rich Documents (VRDs; 시각적 요소가 풍부한 문서)의 정보 추출을 크게 개선하였습니다. 이 논문은 그중에서도 딥러닝 기반의 Visually Rich Document Understanding (VRDU; 시각적 요소가 풍부한 문서 이해) 프레임워크에 대한 종합적인 리뷰를 제공하고 있습니다. 이는 다양한 도메인에서 사용되는 VRDs의 이해를 높이는 데 기여할 것으로 기대됩니다.

- **Technical Details**: VRD는 텍스트와 시각적 요소(예: 표, 차트, 다이어그램, 사진)가 혼합된 문서로, 이러한 요소들은 정보의 포괄적이고 시각적으로 매력적인 전달을 목표로 합니다. 전통적인 정보 추출 방법은 전문가 지식과 수작업을 필요로 하여 비효율적이지만, 딥러닝의 발전으로 이를 개선할 수 있게 되었습니다. 이 논문에서는 딥러닝 기반 VRDU 모델들이 사용하는 다양한 전략과 다운스트림 과업에 대해 체계적으로 조사하고 분석합니다. 주요 기술적 측면으로는 Feature Representation (특징 표현)과 Fusion (융합), Model Architecture (모델 아키텍처), Pretraining Techniques (사전 훈련 기법) 등이 있습니다.

- **Performance Highlights**: 딥러닝 기반 VRDU 모델들은 다양한 다운스트림 과업에서 최첨단 성능을 달성하였습니다. LSTM과 CNN 기반 모델들 뿐만 아니라, Layout-aware Pretrained Frameworks (레이아웃 인식 사전 훈련 프레임워크) 및 Visual-integrated Pretrained Frameworks (시각적 통합 사전 훈련 프레임워크)도 문서 표현을 크게 향상시켰습니다. 이러한 모델들은 Key Information Extraction (중요 정보 추출)과 Question Answering (질문 답변)에서 높은 정확도와 효율성을 보였습니다.

- **Future Directions**: 논문은 VRDU의 새로운 동향과 도전 과제를 식별하고, 미래 연구 방향 및 실질적 응용에 대한 통찰을 제공합니다. 특히, multi-modal learning methods (다중 모달 학습 방법)과 LLM-based frameworks (대형 언어 모델 기반 프레임워크)는 향후 VRDU의 주요 연구 분야로 주목되고 있습니다.



### The Mismeasure of Man and Models: Evaluating Allocational Harms in Large Language Models (https://arxiv.org/abs/2408.01285)
- **What's New**: 이번 연구에서는 Rank-Allocational-Based Bias Index (RABBI)라는 새로운 모델 무관 편향 측정 지표를 소개합니다. 이는 대형 언어 모델(LLMs)이 예측하는 결과의 편향이 실제로 어떻게 할당 결정에 영향을 미치는지를 평가합니다. 기존의 편향 측정 방법과 RABBI를 비교한 결과, RABBI가 할당 결과의 격차와 강한 상관 관계를 보이는 것을 발견했습니다.

- **Technical Details**: RABBI는 모델의 출력에서 파생된 점수를 사용하여 할당 편향을 측정하는 지표입니다. 이 지표는 포인트와 페어와이즈 랭킹(pointwise and pairwise ranking) 스코어링 방법을 적용합니다. 두 가지 할당 결정 과제에서 RABBI와 기존 편향 지표를 비교하고, 열 개의 LLM에서 예측 유효성을 평가하며, 모델 선택을 위한 유용성을 검사했습니다.

- **Performance Highlights**: 연구 결과에 따르면, 평균 성능 격차와 분포 차이에 기반한 기존의 편향 측정 지표는 할당 결과에 대한 그룹 격차를 신뢰성 있게 포착하지 못한다고 합니다. 반면, RABBI는 할당 격차와 강한 상관 관계를 보여, 현재 사용되고 있는 편향 측정 지표와 평가 방법이 할당적 피해를 평가하는 데 충분하지 않음을 강조했습니다.



### RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework (https://arxiv.org/abs/2408.01262)
- **What's New**: 이 논문은 RAGEval이라는 새로운 프레임워크를 소개합니다. RAGEval은 다양한 도메인에서 Large Language Models(LLMs)가 실제로 지식을 어떻게 사용하는지 평가할 수 있는 자동화된 평가 데이터셋을 생성합니다. 이는 기존의 Retrieval-Augmented Generation (RAG) 벤치마크가 일반 지식에 대한 질문에만 초점을 맞추고 있어 특정 도메인 데이터에 대한 평가가 어려운 문제를 해결합니다.

- **Technical Details**: RAGEval은 시드 문서로부터 스키마를 요약하고, 이를 적용하여 다양한 문서를 생성합니다. 그런 다음, 생성된 문서와 구성별로 질문-답변 쌍을 구성합니다. 평가 메트릭으로는 'Completeness(완전성)', 'Hallucination(환각)', 'Irrelevance(무관성)'의 세 가지를 제안하여 LLM이 생성한 응답을 면밀히 평가합니다.

- **Performance Highlights**: RAGEval은 수직 도메인(vertical domains)에서 RAG 모델을 벤치마킹하여, LLM이 지식을 어떻게 활용하는지 보다 정확히 평가할 수 있는 능력을 보입니다. 이는 기존 QA 데이터셋에서 답변의 지식 출처가 매개변수화된 메모리에서 기인한 것인지 또는 검색에서 유래한 것인지 혼란을 방지할 수 있습니다.



### High-Throughput Phenotyping of Clinical Text Using Large Language Models (https://arxiv.org/abs/2408.01214)
Comments:
          Submitted to IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), Houston TX

- **What's New**: 이번 연구는 Online Mendelian Inheritance in Man (OMIM) 데이터베이스의 임상 요약을 활용한 고속 표현형 분석(High-throughput phenotyping) 자동화를 평가했습니다. GPT-4와 GPT-3.5-Turbo 모델을 비교한 결과 GPT-4가 더 뛰어난 성능을 보였으며, 수동 해설자와의 합의도가 높은 것으로 나타났습니다.

- **Technical Details**: 텍스트 추출 및 전처리 작업에서 OMIM API를 이용해 임상 요약을 읽고 추출했습니다. OpenAI API를 통해 전처리된 텍스트에서 신경학적 징후를 식별했습니다. 이후 GPT-4 모델을 사용해 HPO(Human Phenotype Ontology) 용어와 ID로 매핑하였습니다. 마지막으로 카테고리 이진화 및 질병 벡터화를 수행했습니다.

- **Performance Highlights**: GPT-4는 징후 식별, 분류 및 정상화 작업에서 GPT-3.5-Turbo를 능가했습니다. 수동 해설자와 유사한 수준의 합의도를 이루었으며, 추가적인 수동 주석 데이터가 필요하지 않다는 점에서 일반화 가능성이 높음을 보여주었습니다.



### Misinforming LLMs: vulnerabilities, challenges and opportunities (https://arxiv.org/abs/2408.01168)
- **What's New**: 최근 arXiv에 게시된 논문에서는 대형 언어 모델(LLMs)의 기저 메커니즘에 대한 오해를 다룹니다. 연구는 현재 LLM 아키텍처가 통계적 패턴에 의존하기 때문에 본질적으로 신뢰할 수 없다고 주장합니다. 하지만, 생성형 트랜스포머 기반 모델을 사실 기반(fact bases) 및 논리 프로그래밍 언어와 결합하는 연구가 신뢰성 있는 LLM 개발로 이어질 가능성을 제시합니다.

- **Technical Details**: LLMs는 자연어 처리에서 큰 진전을 이루었지만, 실제 인지 과정을 따르지 않고 단순히 단어 임베딩(word embeddings)의 통계적 패턴에 의존합니다. 이는 '환각(hallucination)' 및 잘못된 정보의 취약점을 초래합니다. LLM은 높은 차원의 임베딩 공간에서 텍스트를 인코딩하고 해당 공간에서 텍스트를 디코딩합니다. 따라서 문장은 특정 경로 패턴에 맞춰서 디코딩 됩니다. 이러한 메커니즘은 진정한 인지 과정과 맞지 않으며, 단어 임베딩 벡터의 순차적 패턴의 상관관계에 의존하기 때문에 신뢰할 수 없습니다.

- **Performance Highlights**: 환각 문제를 해결하기 위해 체인 오브 생각(chain-of-thought) 프롬프트와 같은 기술이 도입되었습니다. 이는 멀티스텝 문제를 작은 단계로 나누어 신뢰성을 향상시키는 방법입니다. 그러나 LLM의 잘못된 출력이나 환각 문제가 발생했을 때 어떤 부분이 문제인지 판단할 수 없는 단점이 존재합니다. 최근 연구는 생성형 트랜스포머 모델에 사실 정보를 주입하여 성능을 높이거나, 논리 프로그래밍 언어를 생성하는 코드 작성기로 사용하여 신뢰 가능한 LLM을 개발하는 방향으로 나아가고 있습니다.



### DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs (https://arxiv.org/abs/2408.01154)
- **What's New**: 이 연구는 엔터티 정렬(Entity Alignment, EA)을 위한 밀집 엔터티 검색 프레임워크를 제안합니다. 엔터티의 다양한 특징을 균일하게 인코딩하기 위해 언어 모델을 활용하여, 서로 다른 지식 그래프(Knowledge Graphs, KGs) 사이에서 근접 엔터티 검색을 용이하게 합니다. 이에 따라, 엔터티 검색을 통해 정렬 후보를 생성하고, 후속적으로 후보를 재정렬하여 최종 정렬을 결정합니다. 이 접근 방식은 기존의 EA 방법들과 비교하여 최고의 성능을 보여줍니다.

- **Technical Details**: 이 작업에서는 EA 문제를 텍스트 기반 엔터티 검색 문제로 형식화합니다. 다양한 엔터티의 정보를 텍스트 설명으로 변환하고, 이를 언어 모델 기반 임베딩 모델로 인코딩하여 엔터티 검색을 수행합니다. 이 프레임워크 내에서 이질적인 트리플(triples)로부터 동질적 텍스트 설명을 생성하는 엔터티 구두 모델을 제안합니다. 이를 위해 GPT를 통해 합성 트리플-투-텍스트 데이터셋을 작성하여 구두 모델을 효과적으로 훈련시킵니다. 엔터티 검색과 정렬 재정렬을 위한 임베딩 모델을 설계하고, 엔터티 상호작용을 포착하여 정렬 정확성을 보장합니다. 이 접근 방식은 PLMs(사전 훈련된 언어 모델)의 발전을 활용한 것입니다.

- **Performance Highlights**: 이 방법은 다섯 개의 데이터셋에서 종합적인 실험을 수행했으며, 기존 EA 접근 방식들과 비교하여 최상의 결과를 달성했습니다. 특히, 단일 언어 및 다중 언어 EA 데이터셋에서 현 상태 최고 성능을 보였습니다.



### CFBench: A Comprehensive Constraints-Following Benchmark for LLMs (https://arxiv.org/abs/2408.01122)
Comments:
          15 pages, 10 figures

- **What's New**: 회원님, 이번 AI 뉴스레터는 대형 언어 모델(LLMs)의 자연어 지시사항을 이해하고 준수하는 능력을 평가하는 새로운 벤치마크, CFBench에 대해 소개합니다. 200개 이상의 실제 시나리오와 50개 이상의 NLP 작업을 포함한 1,000개의 샘플로 구성된 이 벤치마크는 LLM이 현실 세계의 지시사항을 얼마나 잘 따르는지 평가하기 위해 설계되었습니다.

- **Technical Details**: CFBench는 사용자 관점에서 지시사항을 구성하고 체계적인 제약 유형 프레임워크를 구축합니다. 이 프레임워크는 10개의 주요 카테고리와 25개 이상의 하위 카테고리를 포함합니다. 평가 방법론은 다양한 제약과 지시사항, 요구사항 달성도를 다각도로 평가하기 위해 다차원 평가 기준을 제안합니다.

- **Performance Highlights**: CFBench에서 현재 최고 성능을 자랑하는 LLM을 평가한 결과, 제약사항 준수에 있어 상당한 개선 여지가 있음을 발견했습니다. 이는 다양한 제약 조건을 포함한 복잡한 현실 세계의 지시사항을 LLM이 어떻게 처리하는지를 이해하는 데 중요한 통찰을 제공합니다. 연구팀은 이러한 평가 데이터를 통해 LLM의 성능을 최적화하기 위한 전략도 제시하고 있습니다.



### Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer (https://arxiv.org/abs/2408.01119)
- **What's New**: 새로운 연구는 큰 언어 모델(LLM)에서 소프트 프롬프트 기반의 멀티태스킹을 개선하기 위한 'Task Prompt Vectors'를 도입했습니다. 이는 튜닝된 소프트 프롬프트의 가중치와 초기화된 값의 원소별 차이를 통해 생성됩니다.

- **Technical Details**: 기존 소프트 프롬프트 기반 메서드는 각 신규 태스크마다 학습 과정을 부분적으로 반복해야 하는 반면, 'Task Prompt Vectors'는 임의의 초기화와 무관하게 태스크 벡터 산술 연산을 가능하게 합니다. 실험은 12개의 NLU 데이터셋에서 수행되었으며, 특히 zero-shot 또는 few-shot 설정에서 효율적으로 초기화할 수 있습니다.

- **Performance Highlights**: 다중 태스크 벡터의 산술 덧셈을 통해 특정 태스크에서 최첨단 기법보다 우수한 성능을 발휘할 수 있는 가능성을 확인했습니다. 이는 제한된 데이터 환경에서도 높은 수준의 멀티태스킹 모듈성을 유지하면서 일부 태스크에서 SPoT(Soft-Prompt Transfer) 보다 뛰어난 성능을 보였습니다.



### IAI Group at CheckThat! 2024: Transformer Models and Data Augmentation for Checkworthy Claim Detection (https://arxiv.org/abs/2408.01118)
Comments:
          Accepted to CLEF2024 CheckThat!

- **What's New**: 이번 논문은 IAI 그룹의 2024 CheckThat! Lab 'Task 1: Check-Worthiness Estimation' 참여 과정을 설명합니다. 이 과제는 영어, 네덜란드어, 아랍어 정치 토론 및 트위터 데이터에서 자동으로 검증할 가치가 있는 주장(check-worthy claims)을 감지하는 것입니다. 다양한 사전 훈련된 생성 디코더 및 인코더 Transformer 모델을 활용하였으며, few-shot chain-of-thought reasoning, fine-tuning, 데이터 증강(data augmentation), 전이 학습(transfer learning) 등의 방법을 적용했습니다.

- **Technical Details**: 이 실험은 영어, 네덜란드어, 아랍어 등 세 가지 언어로 수행되었습니다. 특히 아랍어에서는 훈련 데이터를 영어로 번역한 후 GPT-3.5 모델을 통해 분류하여 최고의 결과를 얻었습니다. 모델 훈련에는 텍스트 정규화(text normalization), 스타일 변환(style transfer), 하이퍼파라미터 그리드 검색(hyperparameter grid searches) 등의 기법이 사용되었으며, 성능 지표 분석은 Weights & Biases (W&B) Python 라이브러리와 온라인 도구를 이용하여 로그가 관리되었습니다.

- **Performance Highlights**: 모델의 성과는 각 언어별로 다르게 나타났으며, 영어에서는 아홉 번째, 네덜란드어에서는 세 번째, 아랍어에서는 첫 번째 성과를 기록했습니다. 특히 다국어 데이터를 활용하여 검증 가능성 감지의 일반화를 높인 점이 주목됩니다. 또한, 비역 기반 테스트 데이터셋에 비해 개발 테스트 데이터셋에서 성능 저하가 많았음을 보고하였으며, 이는 언어별 적응의 어려움과 가능성을 부각시켰습니다.



### BioRAG: A RAG-LLM Framework for Biological Question Reasoning (https://arxiv.org/abs/2408.01107)
Comments:
          12 pages, 7 figures

- **What's New**: BioRAG는 생명과학 질문-응답 시스템에 새로운 접근 방식을 제안합니다. 이는 대규모 언어 모델(LLMs)과 결합된 Retrieval-Augmented Generation(RAG) 프레임워크입니다. 2200만 개의 과학 논문을 기본 지식으로 사용하여 생명과학에 특화된 임베딩 모델을 훈련하고, 도메인별 지식 계층을 활용해 복잡한 쿼리와 문맥을 모델링합니다. BioRAG는 최신 정보를 반복적으로 검색 엔진을 통해 추론하면서 질문을 해체하고 정보를 검색합니다.

- **Technical Details**: BioRAG는 먼저 방대한 연구 논문을 파싱하고, 인덱싱하며, 세분화하여 고품질 학습 데이터를 구축합니다. 그런 다음, PubMedBERT를 기반으로 CLIP 기법을 적용해 생명과학에 특화된 임베딩 모델을 개발하여 생물학적 질문에 맞는 정보를 효율적으로 검색합니다. 또한, 최신 지식을 반영하기 위해 검색 엔진 및 도메인별 도구에서 지식 소스를 적응적으로 선택합니다. 이렇게 수집된 정보를 토대로 대규모 언어 모델이 응답을 생성합니다.

- **Performance Highlights**: BioRAG는 6개의 생물학 질문-응답 데이터셋에서 기존 방법들을 능가하는 성능을 보였습니다. 이는 세심하게 설계된 데이터 준비 및 커스터마이징된 임베딩 모델, 그리고 도메인별 지식 계층을 활용한 CPS와 같은 투명한 프로세스를 통해 복잡한 생물학적 질문을 효과적으로 처리할 수 있음을 시사합니다.



### General-purpose Dataflow Model with Neuromorphic Primitives (https://arxiv.org/abs/2408.01090)
- **What's New**: 이 논문에서는 뉴로모픽 컴퓨팅(neuromorphic computing)을 위한 새로운 데이터플로우 모델(dataflow model)을 제안합니다. 이 모델은 뉴로모픽 하드웨어를 위한 '신경망 기반 데이터 플로우'(neuromorphic dataflow)로, 제어 로직을 간략하고 효율적으로 표현할 수 있습니다. 제어 흐름 프로그램(control flow programs)과의 호환성을 높이며 뉴로모픽 하드웨어의 효율성을 최대한 활용할 수 있도록 설계되었습니다.

- **Technical Details**: 제안된 뉴로모픽 데이터 플로우는 'when'과 'where' 프리미티브(primitives)를 도입하여 제어의 관점을 재구성합니다. 이러한 프리미티브는 데이터 플로우 스키마(schema)에 포함되며, 스파이킹 알고리즘(spiking algorithms)에서 유래한 가소성을 특징으로 합니다. 이 방법은 뉴로모픽 하드웨어에서 범용 프로그램을 실행할 수 있도록 하며, 프로그래머블성과 가소성을 동시에 제공합니다.

- **Performance Highlights**: 이 논문에서 제시된 접근법은 기존의 데이터플로우 모델이 가지는 그래프 복잡성 문제를 해결하며, 뉴로모픽 하드웨어와 더 높은 호환성을 제공합니다. 이를 통해 제어 흐름 프로그램의 실행 가능성을 높이고, 뉴로모픽 하드웨어의 잠재력을 극대화할 수 있습니다.



### Bridging Information Gaps in Dialogues With Grounded Exchanges Using Knowledge Graphs (https://arxiv.org/abs/2408.01088)
Comments:
          Accepted to SIGDIAL 2024

- **What's New**: 이 논문은 대화 시스템에서 지식 기반(knowledge grounding)을 활용해 대화 참여자 간의 정보 격차를 해소하려는 연구를 소개합니다. 이를 위해, 다섯 개의 지식 도메인에 걸친 인간 대화를 주석하여 새로운 대화 코퍼스인 BridgeKG를 생성했습니다. 이를 통해 대형 언어 모델(LLMs)의 지식 기반 태스크 수행 능력을 평가합니다.

- **Technical Details**: 이 연구에서는 기존 대화 코퍼스를 재사용하여 26개의 대화에 아노테이션을 추가하였습니다. 각 대화는 정보 탐색을 목적으로 이루어졌으며, 대화에서 '명시적 확인(explicit)', '암시적 확인(implicit)', '명확화(clarification)' 같은 지식 기반 행동을 라벨링했습니다. 데이터를 주고받는 과정에서 생성된 지식 항목들을 Knowledge Graph 형태로 JSON-LD 형식으로 표현했습니다. 네 가지 최신 언어 모델(Llama-3-8B, Llama-3-70B, GPT-3.5-Turbo, GPT-4o)을 사용하여 지식 기반 태스크를 수행했습니다.

- **Performance Highlights**: 실험 결과, 소수 예시를 추가하면 대형 언어 모델의 성능이 확연히 향상됨을 확인했습니다. 예시 수가 증가하면서 성능은 계속 향상됐지만, 일정 수치 이후로는 개선이 둔화되었습니다. 특히, 오픈 소스 LLMs(Llama-8B, Llama-70B)가 폐쇄형 모델(GPT-3.5, GPT-4o)과 경쟁력 있는 성능을 보였으며, 몇몇 경우에는 오히려 뛰어난 성능을 보여줬습니다.



### Adaptive Contrastive Decoding in Retrieval-Augmented Generation for Handling Noisy Contexts (https://arxiv.org/abs/2408.01084)
- **What’s New**:  본 논문에서는 기존 대규모 언어 모델(LLMs) 적용에서 외부 컨텍스트가 포함될 때 발생할 수 있는 노이즈 문제를 해결하기 위해 'adaptive contrastive decoding (ACD)'을 새롭게 제안하였다. 이 방법은 노이즈가 많은 컨텍스트에서도 모델의 성능이 저하되지 않도록 효과적으로 컨텍스트의 영향을 조절하는 방법이다.

- **Technical Details**:  이 연구는 대규모 언어 모델(LLMs)의 파라메트릭 지식(parametric knowledge)에 외부 지식(external knowledge)을 추가하는 접근 방식을 탐구한다. 특히, 새로운 ACD 방법을 통해 대조 디코딩(contrastive decoding) 과정에서 컨텍스트의 영향을 적응적으로 조절하여 노이즈가 많은 상황에서도 모델의 예측 정확성을 유지한다. 이 과정은 LLM의 불확실성(entropy)을 기반으로 조절되며, 주어진 컨텍스트의 정보성(informativeness)을 반영한다.

- **Performance Highlights**:  제안된 ACD 방법은 세 가지 오픈 도메인 질문 응답(open-domain question answering) 데이터셋에서 성능 향상을 입증하였다. 특히, 노이즈가 많은 컨텍스트 상황에서도 기존의 기법들보다 더욱 높은 성능을 보였으며, 정확한 컨텍스트가 주어졌을 때도 성능 저하를 최소화하였다.



### Leveraging Large Language Models for Mobile App Review Feature Extraction (https://arxiv.org/abs/2408.01063)
Comments:
          46 pages, 8 tables, 11 figures

- **What's New**: 이번 연구는 모바일 앱 리뷰에서 특징 추출을 위한 새로운 접근 방안을 제안합니다. 특히 Transformer 기반의 인코더-온리 (encoder-only) 대형 언어 모델 (LLM)을 활용하여 사용자 리뷰에서 특징을 추출합니다.

- **Technical Details**: 인코더-온리 언어 모델은 Transformer 아키텍처의 인코더 부분만을 사용하여 분류, 명명 엔티티 인식 (NER), 정보 추출 등의 작업에 적합합니다. 연구는 크라우드소싱된 사용자 주석을 이용하여 특징 추출을 감독된 토큰 분류 작업으로 재정의하고, 대량의 사용자 리뷰 코퍼스를 사용한 사전 학습을 통해 모델의 문맥 이해를 향상시키는 방법을 제안합니다. 또한 인스턴스 선택 기법을 적용해 모델 파인튜닝의 효율성을 최적화합니다.

- **Performance Highlights**: 실증 평가 결과, 제안된 방법은 추출된 특징의 정밀도와 재현율을 향상시키고, 성능 효율성 또한 개선되었습니다. 주요 기여로는 새로운 특징 추출 접근 방식, 주석 데이터셋, 확장된 사전 학습 모델, 비용 효과적인 파인튜닝을 위한 인스턴스 선택 메커니즘 등이 있습니다.



### QUDSELECT: Selective Decoding for Questions Under Discussion Parsing (https://arxiv.org/abs/2408.01046)
Comments:
          11 Pages, 5 figures

- **What's New**: QUDSELECT는 질의-응답 논리 관계를 고려하여 문장의 QUD(Question Under Discussion) 종속 구조를 선택적으로 디코딩하는 합동 훈련 프레임워크입니다. 이전 연구들은 파이프라인 방식으로 QUD 파서를 구성했지만, 이는 전체적인 과제를 포괄하지 못해 모든 이론적 기준을 충족하지 못한다는 문제점이 있었습니다. QUDSELECT는 이러한 문제를 해결하기 위해 앵커 문장(anchor sentence)를 예측하고 연관된 질문(question)을 생성하며, 선택적 디코딩 전략을 채택하여 다양한 QUD 후보 중 최적의 것을 선택합니다.

- **Technical Details**: QUDSELECT는 문서의 각 문장을 답변(answer)로 간주하고, 이전 문맥에서 트리거된 질문(question)에 대한 응답으로 보는 QUD 파싱을 수행합니다. 이를 위해 모델을 instruction-tuning하여 앵커 문장을 예측하고 연관된 질문을 생성합니다(예: s13과 s1,…,s12). 선택적 디코딩 전략을 활용하여 여러 앵커 및 질문 쌍을 샘플링하고, 이론적 기준에 기반한 스코어러로 평가한 후 최적의 쌍을 선택합니다.

- **Performance Highlights**: QUDSELECT는 DCQA 데이터셋 실험에서 인간 평가 기준으로 평균 9%의 향상을 보였으며, 자동 평가에서는 4%의 향상을 보여줍니다. 이는 기존의 최첨단 모델 대비 상당한 개선을 나타냅니다.



### UNER: A Unified Prediction Head for Named Entity Recognition in Visually-rich Documents (https://arxiv.org/abs/2408.01038)
Comments:
          accepted by ACM Multimedia 2024

- **What's New**: 이 논문에서 연구자들은 비주얼리치 문서(named entities in visually-rich documents; VrD-NER)의 명명 엔티티 인식을 개선하기 위해 UNER (Unified Named Entity Recognition)이라는 쿼리 인식 엔티티 추출 헤드를 제안했습니다. 이 기법은 기존의 다중 모달 문서 변환기와 협력하여 더욱 견고한 VrD-NER 모델을 개발하는 것을 목표로 합니다.

- **Technical Details**: UNER는 시퀀스 라벨링(sequence labeling)과 읽기 순서 예측(reading order prediction)을 결합하여 불연속 엔티티(discontinuous entities) 문제를 해결합니다. 이를 위해 두 가지 모듈이 사용됩니다: (1) 쿼리 인식 토큰 분류 모듈은 엔티티 사전(예: 'address', 'flight', 'units price')을 이용하여 토큰 레벨의 분류를 수행합니다. (2) 토큰 순서 예측 모듈은 엔티티 내의 쌍별 토큰 순서를 예측합니다. 이 두 모듈의 예측을 결합함으로써 UNER는 엔티티 주석에서 읽기 순서 지식을 학습하고 불연속 엔티티를 정확히 예측할 수 있습니다.

- **Performance Highlights**: 실험 결과, UNER는 여러 도메인과 언어에서 7개의 데이터셋을 통해 성능이 크게 향상됨을 보여주었습니다. 특히 감독된 사전 훈련 단계(supervised pre-training)를 적용했을 때 UNER 헤드는 크로스-언어 및 몇-쇼트(few-shot) 설정에서 현저한 장점을 보였으며, 제로-쇼트(zero-shot) VrD-NER 기능도 보여주었습니다.



### Fairness in Large Language Models in Three Hour (https://arxiv.org/abs/2408.00992)
- **What's New**: 이 튜토리얼은 공정성 이슈를 다루는 최신 연구를 체계적으로 정리하여 제공합니다. 특히 LLM(대규모 언어 모델, Large Language Models)이 실생활에서 어떻게 편향을 가질 수 있는지에 대한 사례 연구로 시작하여, 편향 원인을 분석합니다. 이어서 LLM에서의 공정성 개념을 탐구하며, 편향을 평가하고 공정성을 촉진하기 위한 알고리즘 및 전략을 요약합니다. 또한, LLM의 편향을 평가하기 위한 툴킷과 데이터셋 등의 자원을 모아 놓고, 현재 연구의 도전 과제와 열려 있는 질문들을 논의합니다.

- **Technical Details**: 튜토리얼은 크게 다섯 부분으로 나뉩니다. 첫째로, LLM의 기본 배경과 그 훈련 과정, 그리고 편향의 주요 원인을 다룹니다. 둘째로, LLM에서의 편향을 정량화하는 방법으로 인구 집단 대표성, 고정관념적 연상(stereotypical association), 그리고 성능 격차를 분석합니다. 셋째로, 사전 처리(pre-processing), 훈련 중(in-training), 내부 처리(intra-processing), 후처리(post-processing) 방법을 통해 편향을 줄이는 방안을 논의합니다. 넷째로, 편향을 평가하기 위한 툴킷(toolkits)과 데이터셋을 소개합니다. 마지막으로, 공정성 개념의 수립, 대체현실 데이터 증강(counterfactual data augmentation), 성능과 공정성의 균형 잡기 등의 향후 연구 방향을 제시합니다.

- **Performance Highlights**: 본 튜토리얼은 LLM에서 발생할 수 있는 편향 문제와 그 영향을 명확히 제시하며, 이를 해결하기 위한 현재의 여러 접근법을 포괄적으로 다룹니다. 사례 연구를 통해 LLM이 특정 성별이나 인종에 대해 어떻게 다른 평가를 내릴 수 있는지를 시연하며, 이를 통해 공정성 문제의 심각성을 부각시킵니다. 또한, 다양한 편향 평가 방법론을 비교 분석하고, 이를 줄이기 위한 구체적이고 실용적인 예시를 제공합니다.



### Cross-domain Named Entity Recognition via Graph Matching (https://arxiv.org/abs/2408.00981)
- **What's New**: 해당 연구는 도메인 간 명명 엔터티 인식(NER) 문제를 해결하기 위한 혁신적인 접근 방식을 제안합니다. 연구진은 레이블 관계를 확률 분포로 모델링하고, 소스와 타겟 레이블 공간에서 레이블 그래프를 구축했습니다. 또한, BERT의 단어 임베딩 출력에 레이블 구조를 융합하여 컨텍스트 표현을 강화하였습니다.

- **Technical Details**: 레이블 관계를 그래프로 표현하여 도메인 간 NER을 그래프 매칭 문제로 공식화했습니다. 소스 NER 모델이 예측한 타겟 레이블의 확률 분포로 레이블 그래프를 구성하고, Gromov-Wasserstein 거리(GWD)를 사용하여 두 레이블 그래프를 정렬합니다. Graph Convolutional Network(GCN)를 활용하여 레이블 그래프를 단어 임베딩에 융합시켰습니다. 이 과정에서 보조 작업을 도입하여 각 엔터티 타입의 레이블 특정 구성 요소를 추출합니다.

- **Performance Highlights**: 네 가지 데이터셋에서 실험한 결과, 제안된 방법은 도메인 간 학습, 멀티태스크 학습 및 몇 샷 학습 방법 등을 상회하는 성능을 보였습니다. 풍부한 리소스와 낮은 리소스 설정에서는 기존의 경쟁 방법들을 능가하는 결과를 나타냈습니다.



### Automatic Extraction of Relationships among Motivations, Emotions and Actions from Natural Language Texts (https://arxiv.org/abs/2408.00966)
- **What's New**: 이 연구는 자연어 텍스트에서 동기(motivations), 감정(emotions), 행동(actions) 간의 관계를 명시적으로 밝히기 위해 새로운 그래프 기반 프레임워크를 제안합니다. 이는 방향성 비순환 그래프(Directed Acyclic Graph)를 설계하여 인간 본성(Nature Design)을 설명하고, 외부 사건과 인간 본성 그래프를 연결하기 위해 발달 경험에서 학습된 양육 믿음(Nurture Beliefs)을 통합합니다. 대형 언어 모델(Large Language Models)의 힘을 통해 주석 자원이 필요하지 않습니다. Amazon Fine Foods Reviews 데이터셋을 사용하여 음식과 관련된 동기를 중점적으로 분석하였으며, 총 92,990개의 관계 그래프가 생성되었고 이 중 63%는 논리적으로 타당성이 있습니다.

- **Technical Details**: 이 연구의 프레임워크는 네 가지 단계를 포함합니다: (1) Nature Design 및 Nurture Belief 로딩, (2) 상태 인식, (3) 신호 전송, (4) 행동 수행. Nature Design 그래프는 수천 년간의 유전적 진화 과정을 통해 형성된 인간의 내적 본성을 수동으로 구축하며, Nurture Belief는 발달 경험에서 학습된 믿음을 포함합니다. Amazon Fine Foods Reviews 데이터셋을 사용하여 음식 동기를 중점적으로 다루었으며, 필요에 따라 양육 믿음을 향상시키기 위해 대형 언어 모델을 사용합니다. Food Entities, Experience Feelings, Emotions와 같은 세 가지 주요 Nurture Belief 구성 요소가 포함됩니다.

- **Performance Highlights**: Amazon Fine Foods Reviews 데이터셋을 사용하여 총 92,990개의 관계 그래프를 생성했으며, 이 중 63%는 논리적 타당성을 가지며 올바르게 작동합니다. 이를 통해 인간의 동기, 감정 및 행동 간의 복잡한 관계를 명시적으로 이해하고 분석할 수 있습니다.



### PERSOMA: PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting (https://arxiv.org/abs/2408.00960)
- **What's New**: PERSOMA라는 새로운 Personalized Soft Prompt Adapter 아키텍처를 소개합니다. 이 시스템은 사용자 상호작용 기록을 표현력 있는 소프트 프롬프트 임베딩(soft prompt embeddings)으로 압축하여 캡쳐합니다.

- **Technical Details**: PERSOMA는 사용자의 과거 상호작용을 텍스트 프롬프트가 아닌 소프트 프롬프트(soft prompt)로 변환하여 대형 언어 모델(LLMs)의 성능을 개선합니다. 이 과정에서 Parameter-efficient tuning 기법인 LoRA와 History Resampling Techniques를 사용해 효율성을 높였습니다. 소프트 프롬프트 어댑터(soft prompt adapter)는 사용자 히스토리를 압축하고, 이를 LLM의 어휘 공간으로 맵핑합니다.

- **Performance Highlights**: PERSOMA는 MovieLens 사용자 선호 데이터셋에서 기존의 임베딩 기반 기술과 텍스트 프롬프트 기반 기술을 능가합니다. PERSOMA는 F1 스코어에서 0.18 높게 기록하며, 적은 계산 자원의 사용으로도 동일한 결과를 보여줍니다.



### Leveraging Large Language Models (LLMs) for Traffic Management at Urban Intersections: The Case of Mixed Traffic Scenarios (https://arxiv.org/abs/2408.00948)
- **What's New**: 이번 연구는 도시 교차로에서의 교통 관리를 향상시키기 위해 GPT-4o-mini라는 대형 언어 모델 (Large Language Model, LLM)을 활용했습니다. GPT-4o-mini는 실시간으로 다양한 기본 시나리오에서 교차로의 교통 상황을 분석, 예측, 감지 및 해결하는 능력을 평가받았습니다. 또한, LLM들이 논리적 추론을 통해 교통 효율성과 안전성을 높일 수 있는지 조사하였습니다.

- **Technical Details**: 연구진은 GPT-4o-mini에게 다양한 교차로 시나리오에서 차량의 위치를 예측하고 충돌을 감지 및 해결하도록 했습니다. 연구는 특히 LLM이 복잡한 환경에서 실시간으로 교통 상황을 파악하는 능력을 중점적으로 조사하였으며, 고속도로에서의 혼잡 상태와 다양한 속도 조건에서도 모델의 성능을 평가하였습니다.

- **Performance Highlights**: 실험 결과, GPT-4o-mini는 교통량이 많고 혼잡한 상태에서의 충돌을 효과적으로 감지하고 해결하는 데 성공했습니다. 장애물과 보행자가 포함된 복잡한 다중 교차로 시나리오에서도 성공적인 충돌 관리가 이루어졌습니다. 연구는 LLM의 통합이 도시 교차로 관리의 효율성을 크게 높여 더 안전하고 효율적인 시스템을 마련하는 데 기여할 수 있음을 보여주었습니다.



### UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation (https://arxiv.org/abs/2408.00863)
- **What's New**: LLMs(대형 언어 모델)의 뛰어난 성과를 분자 응용 분야로 확장하려는 연구가 활발히 진행 중입니다. 하지만 기존 분자 LLM들은 일반적으로 어댑터 기반 구조를 사용해 텍스트와 분자를 동등하게 취급하지 않으며, 분자 모달리티에 대한 슈퍼비전 신호가 부족합니다. 이를 해결하기 위해 분자 토큰을 포함한 tokenizer 기반 아키텍처를 채택한 UniMoT를 도입했습니다. UniMoT는 분자 텍스트 모달리티를 통합해 분자를 외국어처럼 해석하고 텍스트처럼 생성할 수 있도록 합니다.

- **Technical Details**: UniMoT는 벡터 양자화(Vector Quantization) 기반 tokenizer를 채택하여 분자를 시퀀스 형태의 분자 토큰으로 변환합니다. 이 tokenizer는 Q-Former를 사용해 분자와 텍스트 간의 모달리티 간격을 좁히며, 시퀀스의 퀀텀 단위를 학습 가능한 코드북을 통해 양자화합니다. 결과적으로 UniMoT는 통합된 토큰 표현 및 자가 회귀(autoregressive) 학습 패러다임을 사용해 분자와 텍스트 모달리티를 통합합니다. 네 단계를 거친 학습 절차를 통해 UniMoT는 다기능 멀티모달 모델로서 분자 이해(comprehension)와 생성(generation) 작업을 수행할 수 있습니다.

- **Performance Highlights**: 연구 결과 UniMoT는 분자 이해 및 생성 작업에서 최첨단 성과를 기록했으며, 다양한 분자 관련 작업에서 탁월한 성능을 발휘했습니다. 이는 기존의 어댑터 기반 구조를 벗어나 tokens를 통한 균일한 처리가 모델의 성능을 극대화할 수 있음을 보여줍니다.



### Mission Impossible: A Statistical Perspective on Jailbreaking LLMs (https://arxiv.org/abs/2408.01420)
- **What's New**: 이 논문은 현재 LLMs의 문제점인 'jailbreaking' 현상을 통계적 관점에서 이론적으로 분석하여, 이를 해결하기 위한 새로운 접근법 E-RLHF를 제안합니다. E-RLHF는 추가적인 훈련 비용 없이 안전한 응답을 유도하며, 다른 방법들과 호환 가능합니다.

- **Technical Details**: 이 논문은 LLMs가 'pretraining' 중에 유해한 행위를 학습할 가능성이 높음을 통계적 프레임워크 하에서 보여줍니다. 이를 바탕으로, RLHF(Reinforcement Learning from Human Feedback) 목표의 단점을 지적하고, 순수함 (harmlessness)과 유용성 (helpfulness) 사이의 차이를 해결하는 E-RLHF 목표를 제안합니다. E-RLHF는 전달된 동작(prompt)을 분리하여 공격자의 강도를 정량화하고, 안전한 응답의 분포를 유지합니다.

- **Performance Highlights**: Empirical 실험 결과에 따르면, E-RLHF는 AdvBench 및 HarmBench 프로젝트에서 제시된 모든 alignment 문제에서 RLHF보다 우수한 성능을 보였습니다. 또한, MT-Bench 프로젝트에서 측정한 모델 성능을 희생시키지 않고도 개선된 안전성을 제공합니다.



### Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer (https://arxiv.org/abs/2408.01402)
Comments:
          2 figures, 8 tables. Accepted by the Training Agents with Foundation Models Workshop at RLC 2024

- **What's New**: 새로운 연구에서는 사전 학습된 언어 모델을 활용한 Language model-initialized Prompt Decision Transformer (LPDT)을 소개합니다. 이 접근법은 pre-trained 언어 모델을 초기화하여 meta-RL 작업에서 성능을 향상시키며 Low-rank Adaptation (LoRA)을 사용하여 모델을 정교하게 조정합니다. 또한, 프롬프트 규제(predict regularization)를 적용하여 다양한 작업 간 차이를 효과적으로 인식할 수 있게 합니다.

- **Technical Details**: LPDT는 사전 학습된 언어 모델을 이용해 초기화된 Prompt Decision Transformer(Prompt-DT)를 활용합니다. LoRA를 통해 데이터 효율적인 방식으로 사전 학습된 모델을 다량의 RL 작업 데이터셋으로 미세 조정합니다. 프롬프트 규제 방법은 주어진 프롬프트 정보에 따라 다양한 테스트 환경을 구분할 수 있도록 설계되었습니다. 이 연구는 또한 MuJoCo 제어 환경 및 Meta World ML1 작업에서 LPDT의 성능을 입증하기 위한 광범위한 실험을 수행했습니다.

- **Performance Highlights**: LPDT는 제안된 기법들을 통해 다양한 실험 환경에서 기존 모델들을 능가하는 성능을 보였습니다. 특히, 제한된 데이터셋 환경에서 LPDT는 더 나은 누적 보상(cumulative rewards)을 달성하여 실제 응용 가능성을 강조했습니다.



### Toward Automatic Relevance Judgment using Vision--Language Models for Image--Text Retrieval Evaluation (https://arxiv.org/abs/2408.01363)
Comments:
          Accepted by ACM SIGIR 2024 LLM4Eval Workshop: this https URL

- **What's New**: 이번 연구는 Vision-Language Models(VLMs)의 성능을 통해 이미지-텍스트 리트리벌 상황에서의 적합성 추정을 평가합니다. 이 연구는 CLIP, LLaVA, GPT-4V 모델을 대상으로 진행되었으며, 이들 모델의 성능이 인간의 적합성 판단과 얼마나 일치하는지를 살펴봅니다.

- **Technical Details**: 연구는 대규모 멀티미디어 콘텐츠 제작을 위한 제로샷(Zero-shot) 리트리벌 태스크에서 VLM들의 적합성 추정 능력을 평가했습니다. 클립스코어(CLIPScore)를 기준으로, LLaVA와 GPT-4V 모델은 인간의 적합성 판단에 대한 켄달의 타우(Kendall's tau) 약 0.4를 기록하며 좋은 성능을 보였습니다. 또한, GPT-4V 모델은 적합성 판단 분포에서도 인간과 유사한 경향을 보이며, 코헨의 카파(Cohen's kappa) 값이 0.08로, CLIPScore의 -0.096보다 현저하게 높은 값을 보였습니다.

- **Performance Highlights**: LLaVA와 GPT-4V 모두 인간의 적합성 판단과 상당히 일치하는 성능을 보였으며, 특히 GPT-4V 모델은 인간과 유사한 판단 분포를 보여줍니다. CLIP 기반 리트리벌 시스템에 대한 편향성을 줄여주며, 모델 기반 적합성 판단이 상당히 효과적임을 발견했습니다.



### Prompt Refinement or Fine-tuning? Best Practices for using LLMs in Computational Social Science Tasks (https://arxiv.org/abs/2408.01346)
Comments:
          5 pages, 1 table

- **What's New**: 이번 연구는 대형 언어 모델(Large Language Models, LLMs)이 컴퓨터 사회 과학(Computational Social Science)에서 텍스트 이해를 위한 강력한 도구가 될 수 있음을 강조하고 있습니다. 하지만 그 다양성으로 인해 표준화된 모범 사례를 확립하는 데 어려움이 있습니다. 이에 따라 연구자들은 23개의 사회 지식 과제를 벤치마크로 사용하여 현대 LLM 기반 분류 방법의 성능을 개괄적으로 설명하고자 합니다.

- **Technical Details**: 이 연구는 Llama-2-7B-chat 및 Meta-Llama-3-8B-Instruct와 같은 두 개의 공개 소스 모델을 사용하여 진행되었습니다. Llama-3는 15조 개의 토큰으로 약 7배 큰 코퍼스를 기반으로 훈련되었으며, 어휘 크기는 Llama-2의 4배에 달합니다. 연구자들은 사회 지식 평가 테스트(SOCKET)의 58개 데이터셋 중 44개 분류 과제를 바탕으로 실험을 실시했습니다. 평가 방법으로는 CHATGPT, GPT-4를 사용한 AI 기반 제로샷(Zero-Shot) 프롬프팅, RAG(Retrieval-Augmented Generation), SFT(Supervised Fine Tuning) 및 DPO(Direct Preference Optimization)와 같은 최첨단 방법이 활용되었습니다.

- **Performance Highlights**: 연구 결과, 더 큰 어휘와 사전 훈련된 코퍼스를 가진 모델을 선택하고 간단한 제로샷 대신 AI로 강화된 프롬프팅을 사용할 것이 권장되며, 과제 특화 데이터로 모델을 세밀 조정(fine-tune)하는 것이 가장 우수한 성능을 보였습니다. 또한, 대량의 훈련 데이터를 사용할 때만 여러 데이터셋에서 더 복잡한 형태의 지시 튜닝(instruction-tuning)을 고려하는 것이 유익하다는 결론이 도출되었습니다.



### MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language Models (https://arxiv.org/abs/2408.01337)
Comments:
          Accepted at ISMIR 2024. Data: this https URL Code: this https URL Supplementary material: this https URL

- **What's New**: MuChoMusic는 멀티모달 언어 모델(multi-modal language models)이 음악을 이해하는 능력을 평가하기 위한 첫 번째 벤치마크입니다. 이 벤치마크는 644개의 음악 트랙에서 1,187개의 다중 선택 질문으로 구성되어 있으며, 인간 주석자에 의해 검증되었습니다. MuChoMusic는 다중모델 언어 모델의 음악 이해 능력을 평가할 수 있는 표준화를 제공합니다.

- **Technical Details**: MuChoMusic는 기존 음악 데이터셋(MusicCaps 및 Song Describer Dataset)에서 가져온 음악 트랙에 대한 질문과 답변을 생성하기 위해 대형 언어 모델(LLMs)을 활용했습니다. 각 질문에는 4가지 선택지가 제공되며, 하나는 정답이고 나머지 세 개는 '잘못된 관련 답변', '올바르지만 관련 없는 답변', '잘못되고 관련 없는 답변'으로 구성되어 있습니다. 이러한 다중 선택 형식은 평가의 표준화를 목표로 합니다.

- **Performance Highlights**: MuChoMusic를 사용하여 다섯 개의 오픈 소스 모델을 평가한 결과, 언어 모달리티에 과도하게 의존하는 경향이 나타났습니다. 이는 멀티모달 통합을 더욱 향상시켜야 하는 필요성을 암시합니다. 데이터와 코드는 오픈 소스로 제공되어, 더 나은 멀티모달 통합을 향한 방향성을 제시합니다.



### The Impact of Hyperparameters on Large Language Model Inference Performance: An Evaluation of vLLM and HuggingFace Pipelines (https://arxiv.org/abs/2408.01050)
- **What's New**: 최근 오픈소스 대형 언어 모델(LLMs)의 급증은 개발자들이 프라이버시와 컴플라이언스(규제 준수) 측면에서 제어할 수 있는 AI 기반 솔루션을 만들 수 있게 해줍니다. 이러한 LLMs를 활용하기 위해서는 추론 엔진이 필요합니다. 이 현재 논문에서는 vLLM와 HuggingFace's 파이프라인을 사용하여 20개의 LLMs 성능, 특히 처리량(일정 시간 동안 생성된 토큰 수)을 분석합니다.

- **Technical Details**: 추론 엔진은 모델의 가중치를 GPU와 같은 사용 가능한 리소스에 로드하여 쿼리를 처리하고 응답을 생성하는 역할을 합니다. 최신 추론 엔진들은 효율적인 메모리 관리를 포함하여 최첨단 성능을 달성하기 위한 새로운 메커니즘을 통합한 vLLM 등이 있습니다. 이 논문에서는 다양한 하이퍼파라미터(hyperparameters)가 추론 성능에 미치는 영향을 조사합니다.

- **Performance Highlights**: 연구 결과에 따르면, 처리량의 지형은 불규칙적으로 나타나며 최고 성능을 달성하기 위해 하이퍼파라미터 최적화가 필수적임을 강조합니다. 또한, GPU 모델 업그레이드 또는 다운그레이드 시 하이퍼파라미터 최적화를 적용하면 HuggingFace's 파이프라인의 처리량이 평균적으로 9.16% 및 13.7% 향상될 수 있음을 보여줍니다.



### Enhancing Financial Market Predictions: Causality-Driven Feature Selection (https://arxiv.org/abs/2408.01005)
Comments:
          Accepted by The 20th International Conference Advanced Data Mining and Applications 2024 (ADMA 2024)

- **What's New**: 이 논문에서는 금융 시장 분석을 혁신적으로 변화시킬 수 있는 FinSen 데이터셋을 소개합니다. 이 데이터셋은 2007년부터 2023년까지 15년에 걸쳐 197개국의 경제 및 금융 뉴스 기사와 주식 시장 데이터를 통합하여 제공합니다. 총 160,000개의 금융 시장 뉴스 기록을 포함하고 있으며, 시계열 정보가 풍부하게 포함되어 있어 전 세계적인 관점을 제시합니다.

- **Technical Details**: 연구는 인과적으로 검증된 감정 점수와 LSTM(Long Short-Term Memory) 모델을 활용하여 시장 예측의 정확성과 신뢰성을 향상시키는 방법을 다룹니다. 특히, 새로운 Focal Calibration Loss 함수가 도입되어, 이로 인해 Expected Calibration Error (ECE)가 3.34%로 감소하는 성과를 보였습니다. 이로써 예측 확률이 실제 결과와 더욱 밀접하게 맞춰지게 됩니다. 감정 분석과 정교한 보정 기법을 결합하여 금융 예측 모델의 신뢰성을 높이는 접근법을 제안합니다.

- **Performance Highlights**: FinSen 데이터셋을 활용하여 인과적으로 확인된 감정 점수를 통합한 LSTM 모델이 S&P 500의 변동성과의 인과 관계를 성공적으로 제시합니다. 이를 바탕으로 신뢰할 수 있는 예측 모델을 개발하는데, SOTA(State-of-the-Art) 보정 방법보다도 더 낮은 ECE를 달성하여 실제 시장 결과와의 일치도를 높였습니다. 이는 금융 투자 분야에서 신뢰할 수 있는 예측을 가능하게 하여, 오해로 인한 비용을 줄이는 중요한 역할을 합니다.



### ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models (https://arxiv.org/abs/2408.00994)
Comments:
          Accepted by ACL 2024 main conference

- **What's New**: 새로운 연구 논문에서는 대형 언어 모델 (LLM)의 코드 생성 기능을 확장하여 주어진 텍스트 설명으로부터 포괄적인 소프트웨어 요구사항을 자동으로 관리하는 방법을 제안합니다. 이 논문에서는 특히 ARCHCODE라는 새로운 프레임워크를 소개하며, 이를 통해 요구사항을 체계적으로 정리하고 생략된 요구사항도 추론하여 코드 스니펫과 테스트 케이스를 생성하는 방법을 설명합니다. Public benchmarks 실험에서 ARCHCODE가 기능 요구사항(Functional Requirements, FRs)과 비기능적 요구사항(Non-Functional Requirements, NFRs) 모두를 효과적으로 만족시키는 것으로 나타났습니다.

- **Technical Details**: ARCHCODE는 In-Context Learning (ICL)을 활용하여 LLM의 광범위한 추론 능력을 발휘하며, 매개변수 업데이트 없이 요구사항을 학습하는 방식을 채택합니다. 각 in-context 학습 예제에는 텍스트 설명, 소프트웨어 요구사항 목록(설명에 명시된 것과 명시되지 않은 것 모두 포함), 그리고 이러한 요구사항을 만족시키는 코드가 포함된 트리플렛이 포함됩니다. 아키코드는 이 예제들을 토대로 LLM가 요구사항을 재구성하고 코드를 생성하며, 각각의 요구사항을 확인하는 테스트 케이스를 생성하도록 유도합니다.

- **Performance Highlights**: ARCHCODE는 HumanEval 및 CodeContests 벤치마크에서 GPT-4 대비 GPT-3.5-Turbo를 사용하여 Pass@k 점수를 각각 4.81%p 및 10.45%p 향상시켰으며, 기존 방법에 비해 50배 적은 수의 테스트 케이스를 생성하여도 성능을 입증했습니다. 또한, ARCHCODE는 FR 뿐만 아니라 NFR도 효과적으로 만족시키는 것으로 확인되었습니다.



### Towards Zero-Shot Annotation of the Built Environment with Vision-Language Models (Vision Paper) (https://arxiv.org/abs/2408.00932)
- **What's New**: 이 논문은 도시 환경의 다양한 특징을 위성 이미지에서 주석(annotations)하는 방법으로서 Vision Language Models (VLMs)을 사용하는 가능성을 탐구합니다. 이 접근법은 인간 주석에 대한 의존도를 줄임으로써, 대규모 학습 데이터셋을 더 저비용으로 생성할 수 있게 합니다.

- **Technical Details**: 기존의 기계 학습 방법은 도시 환경에서 흔하지 않은 구조적 요소들을 인식하는데 어려움을 겪습니다. 저자들은 최첨단 VLM과 설정-변형(promoting strategies)을 결합하여 분할된 이미지 요소에 대해 독립적으로 주석을 달도록 요청하는 전략을 사용합니다. 이 과정은 샘플링이나 레이블 예시가 필요하지 않으며, 완전히 폐쇄된 모델에서도 작동합니다. 저자들은 GPT-4o와 일반 목적의 분할 모델인 SAM을 사용하여 실험을 진행했습니다.

- **Performance Highlights**: 저자들은 정지선(stop lines)과 높아진 테이블(raised tables) 같은 두 가지 도시 특징에 대한 실험에서, 직접적인 제로샷 프롬프트는 거의 0%의 정확도를 보였으나, 사전 분할 전략을 사용한 경우 약 40%의 교집합-영역비율(intersection-over-union) 정확도를 성취하였습니다. 이를 통해 이 방법이 까다롭지만 실현 가능성이 있음을 증명했습니다.



### Automatic Pull Request Description Generation Using LLMs: A T5 Model Approach (https://arxiv.org/abs/2408.00921)
Comments:
          Accepted to 2nd International Conference on Artificial Intelligence, Blockchain, and Internet of Things (AIBThings-2024), September 07-08, 2024, Michigan, USA

- **What's New**: 이번 연구에서는 커밋 메시지와 소스 코드 주석을 기반으로 Pull Request (PR) 설명을 자동으로 생성하는 방법을 제안합니다. 이를 위해 T5 text-to-text transfer 모델을 사용하여 자동 PR 설명 생성 문제를 텍스트 요약 문제로 다루었습니다. 이 방법은 33,466개의 PR을 포함하는 데이터셋을 사용하여 미세조정된 사전 훈련된 T5 모델을 활용한 것이며, 성능 평가에는 ROUGE 메트릭이 사용되었습니다.

- **Technical Details**: 연구진은 T5 text-to-text transfer 모델을 fine-tuning하여 PR 설명을 자동 생성하는 문제를 해결하고자 했습니다. 이를 위해 GitHub에서 수집한 33,466개의 PR 데이터셋을 사용하였으며, 데이터 전처리 과정에서 HTML, URL, 이메일 주소 등의 불필요한 요소를 제거했습니다. 텍스트를 토큰화하는 단계에서는 SentencePiece 접근법을 사용하였고, 최종적으로 토큰을 단어로 변환하여 설명 생성을 완료했습니다.

- **Performance Highlights**: T5 모델은 ROUGE 메트릭을 사용한 평가에서 LexRank와 같은 기존 베이스라인을 크게 능가하는 성능을 보였습니다. 특히, 연구진은 PR 설명의 목표 시퀀스를 최대 50 토큰으로 설정하고, 커밋 메시지와 소스 코드 주석을 포함한 소스 시퀀스를 통해 효율적인 자동 설명 생성을 가능하게 했습니다.



### Granting GPT-4 License and Opportunity: Enhancing Accuracy and Confidence Estimation for Few-Shot Event Detection (https://arxiv.org/abs/2408.00914)
- **What's New**: 이번 연구에서는 GPT-4를 활용하여 이벤트 검출을 위한 신뢰도 추정 방식을 개선하는 방법을 탐구했습니다. 이를 위해 License to speculate and Opportunity to quantify and explain its uncertainty (L&O) 접근법을 도입했습니다. 이 방식은 기존의 복잡한 추가 계산 없이도 신뢰할 수 있는 신뢰도 추정을 제공합니다.

- **Technical Details**: 본 연구에서는 GPT-4를 사용하여 이벤트 검출(tasks of event detection)을 실시했으며, 이를 위해 BETTER ontology를 사용했습니다. L&O 방법은 모델이 불확실한 경우 추측하도록 하고, 불확실성을 정량화하고 설명할 수 있는 기회를 제공합니다. 이 방법은 GPT-4의 내부 통계를 사용하거나 추가적인 모델 튜닝 없이 하나의 쿼리로 출력과 신뢰도 추정을 얻는 것을 특징으로 합니다.

- **Performance Highlights**: L&O 접근법을 적용한 결과, 이벤트 검출의 정확도가 향상되었으며, usable confidence measures (0.759 AUC) 또한 제공되었습니다. 이는 추가적인 기계 장치 없이도 실용적인 성능을 달성했다는 점에서 주목할 만합니다.



### Hybrid Querying Over Relational Databases and Large Language Models (https://arxiv.org/abs/2408.00884)
- **What's New**: 이번 논문에서는 하이브리드 질의를 지원하는 첫 번째 교차 도메인 벤치마크 SWAN을 소개합니다. SWAN은 120개의 데이터베이스 외 질문을 포함하며, 네 가지 실제 세계 데이터베이스에 걸쳐 있습니다. 이를 통해 대형 언어 모델(LLMs)과 관계형 데이터베이스의 통합을 탐구하고자 합니다.

- **Technical Details**: SWAN 벤치마크는 최근 Bird 벤치마크에 기반하며, 오픈 소스 관계형 데이터베이스에서 수집된 데이터를 사용합니다. 논문에서는 또한 HQDL이라는 초기 솔루션을 제안하여 GPT-4 Turbo 모델을 사용한 하이브리드 질의를 시도합니다. HQDL은 데이터베이스 외 질문에 대응하기 위해 몇 가지 예시(prompts)를 활용하는 인컨텍스트 학습(ICL)을 사용합니다.

- **Performance Highlights**: 실험 결과, HQDL은 GPT-4 Turbo 모델을 사용하여 40.0%의 실행 정확도와 48.2%의 데이터 사실 정확도를 달성했습니다. 이는 하이브리드 질의에서의 잠재력과 도전 과제를 모두 강조하며, 앞으로 더 효율적이고 정확한 데이터 시스템의 개발을 위한 연구를 촉진할 것으로 기대됩니다.



### Leveraging LLM Reasoning Enhances Personalized Recommender Systems (https://arxiv.org/abs/2408.00802)
Comments:
          To be published at ACL 2024

- **What's New**: 본 연구는 최근 대규모 언어 모델(Large Language Models, LLMs)이 추천 시스템(RecSys)에서 기능을 향상시키는 방안을 탐구하였다. 특히, Chain-of-Thought(COT) prompting을 통한 LLM의 추론 기능을 추천 시스템에 적용하여 사용자 맞춤 추천의 성능을 개선하고자 하였다. 또한 RecSAVER(RecSys Automatic Verification and Evaluation of Reasoning)이라는 평가 프레임워크를 도입하여, 인간의 평가 없이도 자동으로 추론 응답의 품질을 평가할 수 있는 방법을 제안하였다.

- **Technical Details**: 연구에서 제안된 RecSAVER 프레임워크는 코히전(coherence)와 신뢰성(faithfulness)에 대한 인간의 판단과 일치하는 결과를 제공한다. 또한, zero-shot 및 fine-tuning 시나리오 둘 다에서 LLM의 추론 기능을 사용하여 추천 시스템의 과제 성능이 향상되는 것을 확인하였다. 이는 사용자 평가 예측 과제에서 높은 사용자 결단력과 피드백을 요구하는 과제를 중심으로 실험을 진행하였다. 또한, BLEU와 ROUGE와 같은 문법적 지표가 LLM 출력을 평가하는 데 적합하고, METEOR와 BERTScore는 생성된 출력의 코히전을 측정하는 데 더 적합한 것으로 나타났다.

- **Performance Highlights**: 큰 모델을 사용하여 추론 데이터를 생성하는 것이 더 작은 모델을 fine-tuning 하여 성능과 추론 능력을 향상시키는 데 효과적이라는 점을 보여주었다. 또한 RecSAVER 프레임워크를 통해 인간 평가와 일치하면서도 비용과 효율성을 개선하여 LLM의 추론 기능을 이해하는 데 기여하는 유의미한 통찰을 제공하였다.



### Golden-Retriever: High-Fidelity Agentic Retrieval Augmented Generation for Industrial Knowledge Bas (https://arxiv.org/abs/2408.00798)
- **What's New**: 이 논문은 Golden-Retriever라는 새로운 접근 방식을 소개합니다. 이는 대규모 산업 지식 베이스를 효율적으로 탐색하도록 설계되었으며, 기존의 대형 언어 모델(LLM) 미세 조정 및 Retrieval-Augmented Generation(RAG) 프레임워크가 도메인 특화 용어와 문맥 해석에서 겪는 어려움을 극복합니다. Golden-Retriever는 문서 검색 전에 반영 기반 질문 확장 단계를 포함하며, 이는 전문 용어를 식별하고 문맥에 기반한 의미 명확화를 통해 질문을 확장합니다.

- **Technical Details**: Golden-Retriever는 오프라인 및 온라인 프로세스로 구성됩니다. 오프라인 프로세스는 Optical Character Recognition(OCR)을 사용해 다양한 문서 포맷에서 텍스트를 추출하고, 이를 요약 및 문맥화하여 문서 데이터베이스를 강화합니다. 온라인 프로세스는 사용자 질문 내의 전문 용어와 문맥을 식별한 후, 용어 사전과 대조해 정확한 정의와 설명을 찾습니다. 이렇게 확장된 질문은 RAG 프레임워크에 입력되어 가장 관련성 높은 문서를 검색합니다.

- **Performance Highlights**: 도메인 특화 질문-답변 데이터셋을 사용하여 세 가지 오픈 소스 LLM에서 Golden-Retriever의 성능을 평가한 결과, 우리의 방법이 검색 정확도를 크게 향상시키며 뛰어난 성능을 보였습니다. 기존의 Corrective RAG와 Self-RAG와 달리, Golden-Retriever는 질문의 모호성을 해결하여 검색 단계의 정확성을 높입니다.



### Decoding AI and Human Authorship: Nuances Revealed Through NLP and Statistical Analysis (https://arxiv.org/abs/2408.00769)
- **What's New**: 이번 연구는 인간이 작성한 텍스트와 인공지능(AI)이 생성한 텍스트 간의 미묘한 차이점을 탐구합니다. 이를 통해 언어 표현 방식의 차이를 밝히고, 창의성 패턴 및 본질적 편향을 조사하여 AI가 문학, 커뮤니케이션 및 사회적 구조에 미치는 영향을 이해하는 데 기여합니다.

- **Technical Details**: 이 연구는 LLMs (Large Language Models)가 생성한 텍스트와 인간이 작성한 텍스트로 구성된 50만 개의 에세이를 포함하는 엄선된 데이터를 체계적으로 전처리하고, 철저한 통계 분석을 통해 수행되었습니다. 연구결과, 인간이 작성한 에세이는 평균 단어 수가 더 많지만 평균 단어 길이는 AI가 생성한 에세이보다 짧습니다. 또한, 인간이 작성한 콘텐츠의 어휘 다양성은 AI가 생성한 콘텐츠보다 높지만, AI 생성 에세이의 참신성 수준이 약간 더 높습니다.

- **Performance Highlights**: 이 연구는 AI 모델의 언어 생성 능력을 평가하는 데 있어 직면한 과제를 다루며, 인간-AI 협업 작문의 복잡성을 반영하는 데이터셋의 중요성을 강조합니다. 체계적 전처리와 철저한 통계 분석을 통해 AI 생성 콘텐츠의 발전 모습을 제시하고, 향후 자연어 처리(NLP) 분야의 발전을 위한 귀중한 통찰을 제공합니다.



### Quantification and Validation for Degree of Understanding in M2M Semantic Communications (https://arxiv.org/abs/2408.00767)
Comments:
          ICCT 2024

- **What's New**: AI 및 사물인터넷(IoT) 기술의 발전으로 인해, Shannon-Nyquist 정리에 기반한 네트워크 통신은 전송되는 콘텐츠의 의미 정보(semiotic information)를 간과하게 되면서 한계가 나타나기 시작했습니다. 본 논문에서는 자연어 기반의 기계 대 기계(M2M) 의미 통신(SemCom)을 위한 이중 단계의 계층적 검증 모델을 제안합니다. 이 모델은 자율주행 및 에지 컴퓨팅(edge computing) 등 다양한 응용 분야에 적용될 수 있습니다.

- **Technical Details**: 제안된 모델은 두 통신 당사자 간의 이해도(DoU)를 단어 및 문장 수준에서 정량적으로 측정합니다. 각 단계에서 DoU를 검증하고 확립한 후 다음 단계로 이동합니다. 이 모델은 전송된 콘텐츠의 의미를 추출하고 해석하기 위해 공유 지식 기반(KB)을 사용합니다. 해당 모델은 일련의 실험을 통해 그 효과가 입증되었습니다.

- **Performance Highlights**: 실험 결과, 본 논문에서 제안한 정량화 및 검증 방법이 기계 간 의미 통신의 이해도를 크게 향상시킬 수 있음을 보여줍니다. 이를 통해 보다 높은 신뢰도의 통신이 가능하게 됩니다.



### Characterizing User Archetypes and Discussions on Scored.co (https://arxiv.org/abs/2407.21753)
- **What's New**: 이 논문은 소셜 하이퍼네트워크(Social Hypernetwork) 내에서 노드와 하이퍼엣지(hyperedge)를 특성화하기 위한 다차원 프레임워크를 소개합니다. 저자들은 'Scored.co'라는, 잘 연구되지 않은 우익 성향의 소셜 플랫폼을 중심으로 연구를 진행했습니다. 본 연구는 사용자의 활동, 감정(sentiment), 독성(toxicity) 등 다양한 노드 특징을 통합하여 독특한 사용자 전형(archetype)을 정의하고 이들의 네트워크 내 역할을 이해하고자 합니다.

- **Technical Details**: 논문에서는 하이퍼네트워크 표현을 통해 고차원 상호작용(higher-order interactions)을 연구할 수 있는 가능성을 통합합니다. 사용자의 활동, 감정, 독성 같은 다양한 노드 특징을 분석하고, 하이퍼엣지의 특성을 정의하여 사용자 전형을 생성하는 프레임워크를 제안합니다. 또한, Scored.co 플랫폼의 종합 데이터셋을 이용하여 시간 경과에 따른 이러한 전형의 역동성을 분석하고, 커뮤니티 내에서의 상호작용과 영향을 탐구합니다.

- **Performance Highlights**: 제안된 프레임워크의 유연성 덕분에 개별 사용자 행동과 더 넓은 사회 구조 모두에 대해 상세한 분석이 가능하다는 점이 강조되었습니다. 연구 결과는 고차원 상호작용이 사회적 역학을 이해하는 데 있어 중요함을 강조하며, 복잡한 온라인 환경에서 나타나는 역할과 행동에 대한 새로운 통찰을 제공합니다.



### AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation (https://arxiv.org/abs/2408.00764)
- **What's New**: 이 논문은 대형 언어 모델(LLM) 기반 에이전트의 계획 능력을 향상시키기 위한 연구를 다룹니다. 기존 연구들은 주로 수작업으로 설계된 계획 작업 및 환경에서 경로를 생성하는 것에 중점을 두었기 때문에, 이러한 방식을 개선하고 자동화된 환경 생성 및 다양한 난이도의 계획 작업 생성을 탐구하고 있습니다.

- **Technical Details**: 본 논문에서는 'AgentGen'이라는 프레임워크를 소개합니다. 이 프레임워크는 LLM을 사용해 자동으로 환경을 생성하고, 이러한 환경을 조건으로 계획 작업을 생성합니다. 특히 환경의 다양성을 높이기 위해 다양한 도메인-specific 텍스트 세그먼트로 구성된 '영감 코퍼스(inspiration corpus)'를 활용하여 환경을 합성합니다. 또한 계획 작업의 난이도 다양성을 높이기 위해 '쌍방향 진화 방법(Bi-Evol)'을 제안하며, 이는 쉬운 방향과 어려운 방향에서 계획 작업을 진화시켜 난이도 곡선이 매끄럽게 이어지도록 작업 세트를 합성합니다.

- **Performance Highlights**: AgentGen 프레임워크의 평가 결과는 LLM의 계획 능력을 크게 향상시켰음을 보여줍니다. 예를 들어, AgentGen으로 instruction-tuning된 Llama-3 8B는 종합 성능에서 GPT-3.5를 뛰어넘으며, 특정 작업에서 GPT-4보다 우수한 성능을 보이기도 했습니다.



### CERT-ED: Certifiably Robust Text Classification for Edit Distanc (https://arxiv.org/abs/2408.00728)
Comments:
          22 pages, 3 figures, 12 tables. Include 11 pages of appendices

- **What's New**: CERT-ED (CERTified Edit Distance defense)라는 새로운 접근 방식이 제안되었습니다. 이 방법은 자연어 분류 작업에서 랜덤 삭제(Randomized Deletion)를 확장하여 모든 편집 작업을 인증할 수 있는 멀티 클래스 방어를 제공합니다. 이를 통해 기존의 해밍 거리(RanMASK) 기반 방법을 개선하였습니다.

- **Technical Details**: CERT-ED는 본질적으로 입력 텍스트에 삭제 노이즈를 추가하여 손상된 텍스트도 인증된 예측을 제공할 수 있도록 합니다. 이 방법은 편집 거리(radius r)를 계산하여 인위적인 공격에 대해 강력한 방어를 가능합니다. 공격모델로 5개의 직전 및 5개의 전이 공격을 포함하여 다양한 위협 모델에서 방어 성능을 테스트하였습니다.

- **Performance Highlights**: CERT-ED는 5개의 데이터셋 중 4개에서 RanMASK를 능가했습니다. 직전 및 전이 공격 실험에서 각각 25개의 설정 중 20개와 18개의 설정에서 향상된 견고한 정확도를 보여주었습니다.



### Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions (https://arxiv.org/abs/2408.00727)
- **What's New**: i-MedRAG는 긴 임상 추론이 필요한 복잡한 의료 질문을 해결하기 위해 제안된 새로운 RAG(질문-응답 생성 증강) 구조입니다. 기존의 단일 회차 정보 검색을 뛰어넘어, 여러 회차에 걸친 후속 질의와 응답을 포함하여 LLM(대규모 언어 모델)이 점진적으로 추가 정보를 수집할 수 있도록 합니다.

- **Technical Details**: i-MedRAG는 각 회차마다 LLM이 이전 질의 시도에 기반한 후속 질의를 생성하고, 이를 바닐라 RAG 시스템을 통해 답변하게 되며, 이 과정을 반복하여 탐색 결과를 점진적으로 확장해나갑니다. 이렇게 생성된 질의와 답변은 초기 질문에 대한 응답 생성을 보강하는 데 사용됩니다.

- **Performance Highlights**: i-MedRAG는 MedQA 테스트 세트에서 69.68%의 정확도를 달성하며, 이는 GPT-3.5 기반에서 기존 모든 프롬프트 엔지니어링 및 파인 튜닝(미세 조정) 방법을 능가하는 것입니다. 특히, zero-shot 설정에서도 뛰어난 성능을 보이며, 이 설정 하에서는 훈련 데이터 없이 실제적인 임상 시나리오에서도 적용이 가능합니다.



### Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning (https://arxiv.org/abs/2408.00690)
Comments:
          Code: this https URL, Huggingface: this https URL

- **What's New**: 이 논문에서는 소형 언어 모델(Small Language Models)인 MiniCPM, Phi-2, Gemma의 텍스트 임베딩(Text Embeddings)을 향상시키기 위한 연구를 다룹니다. 특히, 대조적 미세 조정(Contrastive Fine-Tuning)을 통해 MiniCPM의 평균 성능이 56.33% 향상된 것을 확인했습니다. 이 미세 조정 코드 또한 공개되었습니다.

- **Technical Details**: 텍스트 임베딩은 자연어 처리를 가능하게 하는 벡터 표현입니다. 논문에서는 대조적 표현 학습(Contrastive Representation Learning)을 사용하여 유사한 텍스트 쌍을 구별하는 방법을 제시합니다. 또한, LoRA(Low-Rank Adaptation) 기법을 통해 최적의 성능을 유지하면서도 적은 계산 자원으로 미세 조정을 수행함으로써 효율성을 확보했습니다. 실험에는 약 275,000 개의 샘플이 포함된 NLI 데이터셋을 사용했습니다.

- **Performance Highlights**: MiniCPM을 포함한 세 모델의 텍스트 임베딩 품질이 다양한 벤치마크에서 향상되었으며, 특히 MiniCPM은 평균 56.33% 성능 개선을 나타냈습니다.



### Assessing the Variety of a Concept Space Using an Unbiased Estimate of Rao's Quadratic Index (https://arxiv.org/abs/2408.00684)
- **What's New**: 이 연구는 기존의 '다양성' 지표가 가진 한계를 논의하고, 엔지니어링 디자인 문헌에서 사용되는 다양한 메트릭스를 설명하며, 새로운 거리 기반의 다양성 지표를 제안합니다. 이 지표는 SAPPhIRE 모델을 이용하여 두 디자인 개념 간의 실제 거리를 측정합니다. 이 프레임워크는 'VariAnT'라는 소프트웨어 도구에 구현되었습니다.

- **Technical Details**: 새로운 거리 기반의 다양성 지표는 설계 개념 간의 거리를 측정하여 개념 공간의 넓이를 정량화합니다. 이 프레임워크는 인과 관계 모델링에 SAPPhIRE 모델을 사용하여 두 디자인 개념의 실제 거리(real-valued distance)를 측정합니다. 이를 통해 다양한 설계 원칙을 탐색할 수 있는 초기에 디자인 문제를 해결할 수 있는 혁신적인 개념을 평가할 수 있도록 합니다.

- **Performance Highlights**: 제안된 프레임워크는 'VariAnT'라는 소프트웨어 도구에 구현되어 있으며, 도구의 적용은 예시를 통해 시연되었습니다. 새로운 지표와 프레임워크의 유효성을 입증하기 위해 다양한 디자인 개념을 분석할 수 있는 기능을 제공합니다.



### Leveraging Entailment Judgements in Cross-Lingual Summarisation (https://arxiv.org/abs/2408.00675)
- **What's New**: 종합된 Cross-Lingual Summarisation (CLS) 데이터셋은 종종 문서와 요약 쌍이 실제 문서 내용을 충실하게 반영하지 않으며, 허위 내용(hallucinated content)을 포함하는 경우가 많습니다. 본 연구에서는 기존의 X-Langual Natural Language Inference (X-NLI)를 사용하여 참조 요약과 모델 생성 요약의 충실성을 평가하고, 충실도 문제를 인식하는 학습 방식을 도입하여 모델이 더 충실한 요약을 생성하도록 학습시키는 접근법을 제안합니다.

- **Technical Details**: X-NLI를 활용한 충실도 평가는 총 5,000개의 전제-가설 쌍을 포함하는 NLI 테스트 세트를 사용하여 수행되었습니다. 이 연구는 주요 언어들 (영어, 프랑스어, 독일어, 체코어)과 함께 중국어 확장을 포함한 XWikis 코퍼스를 대상으로 하였으며, 문서 전체를 전제로 사용하여 요약 문장의 충실성을 평가하는 다양한 NLI 기반 접근법을 벤치마킹했습니다. 주요 모델로는 mT5-large가 사용되었습니다.

- **Performance Highlights**: 실험 결과, 더 작은 규모지만 더 충실한 데이터셋으로 단순 Fine-Tuning을 수행하는 것만으로도 생성된 요약문의 충실성을 향상시킬 수 있음을 확인했습니다. 특히, InFusE 접근법이 다른 방법들보다 높은 성능을 보여주었으며, 이는 XWikis 데이터셋의 다양한 문서-요약 쌍 특성을 잘 다루기 때문입니다.



### Aligning Multiple Knowledge Graphs in a Single Pass (https://arxiv.org/abs/2408.00662)
- **What's New**: 기존의 엔티티 정렬(EA) 방법들은 주로 한 쌍의 지식 그래프(KGs)를 정렬하는 데 집중했습니다. 하지만 본 연구에서는 다중 KGs(두 개 이상의 KGs)를 정렬하는 새로운 문제를 다루고 있으며, 이를 해결하기 위해 MultiEA라는 효과적인 프레임워크를 제안합니다. 처음으로 모든 KGs의 엔티티를 공통 피처 공간에 임베딩한 후, 사전 정렬된 엔티티 간의 거리를 최소화하는 세 가지 정렬 전략을 탐색합니다.

- **Technical Details**: MultiEA 프레임워크는 공유된 KG 인코더를 통해 모든 후보 KGs의 엔티티를 공통 피처 공간에 임베딩합니다. 그 후, 고차 유사성을 통합하여 정렬 성능을 개선하는 혁신적인 추론 강화 기술을 적용합니다. 마지막으로, 두 개의 새로운 실제 벤치마크 데이터 세트를 구축하고, 이를 통해 광범위한 실험을 수행하여 MultiEA의 효과성을 검증합니다.

- **Performance Highlights**: 실험 결과, MultiEA는 다중 KGs를 단일 실행에서 효율적으로 정렬할 수 있으며, 기존의 쌍별 정렬 방식보다 더 나은 성능을 보였습니다. MultiEA는 모든 후보 KGs의 엔티티를 단일 통합 공간에 임베딩하므로, 유용한 글로벌 정렬 정보를 포착하여 더 일관된 결과를 제공합니다.



### Downstream bias mitigation is all you need (https://arxiv.org/abs/2408.00612)
Comments:
          21 pages, 11 figures, 2 tables

- **What's New**: 최근 Transformer 구조와 대규모 언어 모델(LLMs)의 등장으로 자연어 처리(NLP) 모델의 성능이 크게 향상되었습니다. 이 논문은 사전 훈련된 LLMs가 얼마나 많은 편견을 흡수하고 있는지와, 이후 구체적인 작업에 맞춰 파인튜닝(fine-tuning)될 때 이러한 편견이 어떻게 변하는지를 연구합니다.

- **Technical Details**: 연구에 따르면, 사전 훈련이 완료된 LLMs에 대한 제어적 개입은 분류기(classifier)에서의 편견을 크게 낮추지 못하지만, 도메인 특화 데이터셋에 존재하는 편견은 더 큰 영향을 미칩니다. 따라서 파인튜닝 단계에서 이러한 편견을 완화하는 것이 더 큰 효과를 보일 수 있습니다. 또한, 사전 훈련 이전과 이후 모두 데이터셋의 공출현율(co-occurrence rates)에 약간의 변화만 있어도 모델의 편견에 중요한 영향을 미친다는 것을 발견했습니다.

- **Performance Highlights**: 사전 훈련된 LLMs의 편견을 완화하려는 단순한 시도는 큰 효과가 없지만, 이후 파인튜닝 단계에서 데이터셋의 편향을 개선하는 것이 모델의 성능과 공정성(fairness)에 중요한 이점을 줄 수 있습니다.



### Closing the gap between open-source and commercial large language models for medical evidence summarization (https://arxiv.org/abs/2408.00588)
- **What's New**: 최근 대형 언어 모델(LLM)이 의료 증거 요약(summarizing medical evidence)에 큰 잠재력을 지니고 있는 것으로 밝혀졌습니다. 하지만, 대부분의 연구는 독점적인 LLM에 초점을 맞추고 있으며, 이는 투명성 부족과 벤더 종속성 등 여러 위험 요소를 초래할 수 있습니다. 본 연구에서는 오픈 소스 LLM을 세부 조정(fine-tuning)하여 그 성능을 향상시킬 수 있는지를 조사했습니다.

- **Technical Details**: 우리는 PRIMERA, LongT5, Llama-2 세 가지 널리 사용되는 오픈 소스 LLM을 MedReview 벤치마크 데이터셋을 사용해 세부 조정(fine-tuning)했습니다. 이 데이터셋은 8,161쌍의 체계적인 리뷰와 요약을 포함하고 있습니다. 세부 조정을 위해 Low-Rank Adaptation(LoRA)을 사용했습니다, 이는 모델 파라미터의 일부만 업데이트하는 효율적인 방법입니다.

- **Performance Highlights**: Fine-tuning한 LLM들은 ROUGE-L 9.89, METEOR 13.21, CHRF 15.82의 점수 향상을 보였으며, GPT-3.5의 zero-shot 설정과 유사한 성능을 보였습니다. 또한, 일부 작은 모델들은 더 큰 zero-shot 모델보다 우수한 성능을 보이기도 했습니다. 이러한 성과는 인간 평가와 GPT4-모의 평가에서도 나타났습니다.



### Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses (https://arxiv.org/abs/2408.00584)
Comments:
          Code: this https URL. Artifacts: this https URL

- **What's New**: 이 논문에서는 이탈리아어로 작성된 대형 언어 모델의 리버스(Rebus) 문제 해결 능력을 평가하고자, 방대한 양의 텍스트로 표기된 리버스를 소개합니다. 일반적인 시스템인 LLaMA-3와 GPT-4o는 이 작업에 약한 성능을 보이나, 목적에 맞는 파인 튜닝(ad-hoc fine-tuning)을 통해 성능을 개선할 수 있음을 확인했습니다. 하지만, 성능 향상이 주로 암기에 의해 이루어짐을 알 수 있습니다. 저자들은 리버스 해결이 대형 언어 모델의 언어 능력과 순차적인 지침 준수 능력을 평가하는 어려운 시험대임을 시사합니다.

- **Technical Details**: 저자들은 이탈리아어 퍼즐인 리버스를 평가하기 위해 새로운 텍스트 변형 리버스를 생성하는 전략을 제안했습니다. 이 데이터셋은 Eureka5에서 추출한 223,000개의 리버스 데이터를 활용해 80,000개 이상의 텍스트 변형 리버스를 만듭니다. 이 데이터를 기반으로 광범위한 LLM을 대상으로 몇-샷 프롬팅(few-shot prompting) 평가를 수행했습니다. 특히, 작은 규모이지만 성능이 우수한 Phi-3 Mini 3.8B 모델을 파인 튜닝해 이전의 최첨단 시스템을 뛰어넘는 성과를 거두었습니다. 파인 튜닝은 81,000개의 예제를 사용해 5,000단계의 학습으로 수행되었습니다.

- **Performance Highlights**: 리버스 해결에서 Phi-3 Mini 3.8B 모델은 테스트 데이터셋에서 높은 성능을 보였으며, 특히 정의 해석, 첫 번째 구문 생성, 솔루션 분절 등에서 전반적으로 높은 정확도를 기록했습니다. 간략화된 평가 기준으로는 정의 해석, 첫 구문/문자 정확도, 첫 구문 정밀 일치도가 포함되며, 특히 솔루션 키 일치 비율과 솔루션 단어 정확도에서도 우수한 성적을 나타냈습니다. 단, 일반적인 LLM은 여전히 순차적인 복잡한 지침을 따르는 데 어려움을 겪는 것으로 확인되었습니다.



### Intermittent Semi-working Mask: A New Masking Paradigm for LLMs (https://arxiv.org/abs/2408.00539)
- **What's New**: 이번 연구에서는 Intermittent Semi-working Mask (ISM)라는 새로운 마스킹 스킴(scheme)을 제안하여 다중 회차 대화(multi-turn dialogues)에서 발생하는 문제를 해결하고자 합니다. ISM은 프리픽스 언어모델(prefix LLM)의 높은 품질과 인과 언어모델(causal LLM)의 낮은 생성 지연(latency)을 동시에 유지할 수 있습니다.

- **Technical Details**: 기존 언어모델은 인과 모델과 프리픽스 모델로 구분되며, 프리픽스 모델은 쿼리(query)와 응답(answer)에 대해 양방향 주의(attention)를 적용하여 다중 회차 대화에서 더 나은 성능을 보입니다. 그러나 이는 높은 생성 지연을 초래합니다. ISM은 대화 기록의 쿼리와 응답에 대해 교차적으로 양방향 및 단방향 주의를 적용하여 해당 문제를 해결합니다. 구체적으로는 쿼리와 응답이 후속 쿼리나 응답에 주의를 기울이지 못하도록 하고, 이를 통해 캐시(KV Cache)를 재사용하여 생성 지연을 줄입니다.

- **Performance Highlights**: 실험 결과 ISM은 기존 프리픽스 및 인과 LLM과 비교하여 다중 회차 대화에서 최첨단의 생성 품질과 낮은 지연을 실현했습니다. GPT-4를 평가자로 활용한 벤치마크 데이터셋 실험에서 ISM의 우수성이 입증되었습니다.



### GalleryGPT: Analyzing Paintings with Large Multimodal Models (https://arxiv.org/abs/2408.00491)
Comments:
          Accepted as Oral Presentation at ACM Multimedia 2024

- **What's New**: 이번 연구에서는 큰 멀티모달 모델(multi-modal models)에서 영감을 받아, 미술 작품 분석 작업을 수행하고 이를 통해 개인의 심미적 감수성을 풍부하게 하고 비판적 사고 능력을 향상시키는 데 도움을 주고자 합니다. 주로 시각적 특성에 초점을 맞춘 포괄적인 분석을 위해 'PaintingForm'이라는 대규모 데이터셋을 수집하였으며, 이를 기반으로 'GalleryGPT'라는 향상된 멀티모달 모델을 제안합니다.

- **Technical Details**: 우선 대규모 데이터셋 'PaintingForm'을 구축하기 위해 약 1만 9천 개의 그림 이미지와 5만 개의 분석 문단을 수집했습니다. 그런 다음, ShareGPT4V-7B 기반의 LLaVA 아키텍처를 약간 수정하고 미세 조정하여 상위 모델 'GalleryGPT'를 개발했습니다. 이 모델은 미술 작품의 시각적 특성을 중심으로 분석 문단을 생성하는 데 사용됩니다. 또한, Zero-shot 학습을 통해 AQUA, ArtQuest 등 여러 데이터셋에서 모델의 성능을 평가했습니다.

- **Performance Highlights**: GalleryGPT는 여러 고성능 LMMs와 비교하여 놀라운 성능 향상을 보였습니다. 특히 AQUA, ArtQuest, ArtBench 등 다양한 그림 분석 데이터셋에서 우수한 성능을 보이며, 수집된 데이터와 모델의 뛰어난 능력을 입증했습니다.



### In-Context Example Selection via Similarity Search Improves Low-Resource Machine Translation (https://arxiv.org/abs/2408.00397)
- **What's New**: 이 논문은 대규모 언어 모델 (LLMs)의 맥락 학습 능력을 최적화하기 위해 기계 번역(MT)에 대한 새로운 접근 방식을 제안합니다. 특히, 어떤 예제를 선택하는 것이 번역 성능에 가장 큰 이점을 주는지에 대한 체계적인 연구입니다. 영어에서 프랑스어, 독일어, 스와힐리어, 월로프어로 번역하는 경우를 다루며, 특히 자원이 부족한 언어에서 문장 임베딩 유사성 기반의 예제 선택이 어떻게 성능을 향상시키는지에 대해 논의합니다.

- **Technical Details**: 이 연구는 다국어 문장 임베딩을 사용해 다양한 선택 전략을 비교하고, 영어에서 다른 언어로의 번역 방향을 분석합니다. 예제 선택을 통해 얻는 유사성 비교를 중심으로 문장의 품질과 다변성을 어떻게 균형 잡을 수 있는지에 대해 논의합니다. 또한, LLM 기반 MT 평가의 잠재적 문제를 제기하고, 해당 평가를 보다 적절하게 하기 위한 새로운 평가 프로토콜을 제안합니다. 이를 위해 COMET metric을 LLM 평가에 맞춰 적응시켰습니다.

- **Performance Highlights**: 기존 연구와 달리, 유사성 기반 예제 선택이 자원이 부족한 언어 방향에서 MT 성능을 개선할 수 있음을 발견했습니다. 내린 결론에 따르면, 고품질 예제를 포함한 선택 풀(pool)에서 유사한 문장을 선택하는 것이 무작위 선택보다 더 많은 이점을 줄 수 있습니다. 특히, 저자원 언어에서 모든 메트릭에서 현저한 성능 향상을 관찰했습니다. 이러한 결과는 다양한 규모의 LLM에서도 일관되게 나타났습니다.



### DeliLaw: A Chinese Legal Counselling System Based on a Large Language Mod (https://arxiv.org/abs/2408.00357)
Comments:
          CIKM 2024, 5 pages with 3 figures

- **What's New**: 최신 연구인 DeliLaw는 중국 법률 상담 시스템으로, 대형 언어 모델(LLM)을 기반으로 설계되었습니다. 기존 법률 검색 시스템의 한계를 극복하고, 법률 문서, 법률 조항, 판례 검색 등에서 향상된 정확성을 제공합니다. DeliLaw는 법률 검색 모듈과 사례 검색 모듈을 통합하여 사용자가 대화형 모드에서 전문 법률 질문을 상담할 수 있습니다.

- **Technical Details**: DeliLaw의 시스템은 주로 두 가지 모델로 구성됩니다. 첫째, 문의 의도 분류를 위한 RoBERTa-large 아키텍처를 기반으로 하는 모델입니다. 이 모델은 'LawQuestion', 'LawSearch', 'CaseSearch', 'General'의 네 가지 분류에 대해 높은 정확도를 자랑합니다. 둘째, 법률 검색 모델은 BGE 임베딩 모델을 기반으로 하며, infoNCE 손실 함수와 함께 세밀한 튜닝을 거쳐 법률 도메인에 최적화되었습니다. 벡터 라이브러리 검색과 ElasticSearch 기술을 결합하여 효율적인 사례 검색 모듈을 구축하였습니다.

- **Performance Highlights**: DeliLaw의 검색 정확도는 MRR 61.6%, RECALL 71.1%로 법률 정보 검색의 정밀도와 회수율을 크게 향상시켰습니다. 시스템은 사용자가 입력하는 질문을 즉시 분류하고, 가장 적합한 법률 조항 또는 사례를 신속하게 검색하여 제공합니다. 이러한 성능 덕분에 DeliLaw는 실제 법률 상담 및 검색에서 효과적인 도구로 자리잡을 잠재력이 큽니다.



### Bailing-TTS: Chinese Dialectal Speech Synthesis Towards Human-like Spontaneous Representation (https://arxiv.org/abs/2408.00284)
Comments:
          8 pages, 2 figures

- **What's New**: Bailing-TTS는 대규모 텍스트-음성 변환(TTS) 모델들 중에서도 특히 중국 방언 음성을 생성하는 데 초점을 맞춘 새로운 TTS 모델 패밀리입니다. 이 모델은 반지도 학습(semi-supervised learning)과 구체적인 transformer 아키텍처를 사용하여 텍스트 토큰과 음성 토큰의 정렬을 용이하게 하고, 다단계 학습 프로세스를 통해 중국 방언의 표현 학습을 수행합니다.

- **Technical Details**: Bailing-TTS는 다중 레이어의 자동 회귀(transformer) 모델 기반으로 구성되며, 방언 데이터가 포함된 대규모 데이터셋으로 학습되었습니다. 모델은 구체적인 mixture-of-expert 아키텍처를 통해 다중 중국 방언의 통합 표현과 각 방언의 구체적인 표현을 학습합니다. 다양한 계층적 강화 학습(hierarchical reinforcement learning) 전략을 도입하여 높은 품질의 방언 음성을 생성할 수 있습니다.

- **Performance Highlights**: Bailing-TTS는 높은 수준의 자연스러움과 품질을 자랑하며 실험 결과에 따르면 맨드린(Mandarin) 음성의 경우 평균 옵션 점수(mean option score, MOS)에서 4.32점을, 단어 오류율(WER)에서는 1.86점을 기록했습니다. 이는 인간 스피커의 점수에 근접한 성과입니다. 방언 음성에서도 높은 품질의 결과를 보여줍니다.



### Navigating Text-to-Image Generative Bias across Indic Languages (https://arxiv.org/abs/2408.00283)
Comments:
          Accepted in ECCV 2024

- **What's New**: 이 연구는 인도의 여러 언어에 대한 텍스트-이미지(TTI) 모델의 편향을 조사합니다. 주로 인도에서 사용되는 30개 언어에 대한 모델의 생성 성능과 문화적 관련성을 평가하고, 이를 영어와 비교합니다. 제안된 IndicTTI 벤치마크를 사용하여, 두 개의 오픈소스 확산 모델과 두 개의 상용 생성 API를 통해 이러한 언어들에 대해 포괄적으로 평가합니다. 이 벤치마크의 주요 목표는 TTI 모델이 인도 언어를 얼마나 잘 지원하는지 평가하고, 개선이 필요한 영역을 식별하는 것입니다.

- **Technical Details**: 이 연구는 Stable Diffusion과 Alt Diffusion 모델을 오픈소스 분석에 사용하고, Midjourney 및 Dalle3을 상용 생성 모델 분석에 사용했습니다. 새로운 Cyclic Language-Grounded Correctness (CLGC) 메트릭을 제안하여 모델 성능을 평가하고, Self-Consistency Across Languages (SCAL) 메트릭을 통해 모델 생성의 표현 편향을 평가합니다. 또한 Language-Grounded Correctness (LGC)와 Image-Grounded Correctness (IGC) 메트릭을 통해 모델 성능을 평가합니다. 연구에서는 30개 언어를 사용하여 모델의 정확성 및 문화적 표현 편향을 분석합니다.

- **Performance Highlights**: 연구 결과, 특정 언어 스크립트가 Midjourney에서 인도 신의 이미지를 불러일으켰고, 오픈 소스 모델에서는 아시아 여성과 커플의 이미지가 압도적으로 많이 생성되는 것을 관찰했습니다. Dalle3 모델은 가장 정확한 이미지를 생성하는 것으로 나타났습니다. 이러한 분석을 통해 모델이 사용하는 언어 스크립트와 문화적 영향력 간의 상관관계를 논의했습니다.



### QUITO: Accelerating Long-Context Reasoning through Query-Guided Context Compression (https://arxiv.org/abs/2408.00274)
- **What's New**: 최근 대형 언어 모델(LLM)의 핵심인 맥락 내 학습(ICL) 기능을 개선하고자 새로운 Query-gUIded aTtention cOmpression(QUITO) 방법이 제안되었습니다. 이 방법은 질문에 대한 주의(attention) 메커니즘을 활용하여 불필요한 정보를 걸러내는 역할을 합니다.

- **Technical Details**: QUITO는 트리거 토큰을 사용하여 질문에 대한 맥락의 주의 분포를 계산하고, 여러 필터링 방법을 통해 맥락 길이에 대한 예산 제약을 만족시킵니다. 특히, 자체 주의(self-attention) 메커니즘을 활용하여 토큰의 중요성을 점수화하여 해당 쿼리에 맞는 관련된 맥락을 선택합니다.

- **Performance Highlights**: QUITO는 NaturalQuestions와 ASQA와 같은 두 가지 주요 데이터셋에서 실험을 통해 기존의 기준을 크게 능가함을 보여주었습니다. 예를 들어, 다양한 데이터셋과 다운스트림 LLM에서 최대 20%의 정확도 증가를 이뤘습니다.



### Clover-2: Accurate Inference for Regressive Lightweight Speculative Decoding (https://arxiv.org/abs/2408.00264)
- **What's New**: 논문은 Clover-2를 소개하며, 이는 기존 Clover 프레임워크의 고도화 버전입니다. Clover-2는 모델 구조 개선과 지식 증류(knowledge distillation) 기법을 도입하여 텍스트 생성 작업에서 효율성을 크게 향상시켰습니다. Vicuna 7B와 LLaMA3-Instruct 8B 모델을 사용한 실험에서 Clover-2의 우수한 성능이 입증되었습니다.

- **Technical Details**: Clover-2는 다음과 같은 주요 기능 모듈을 통합하고 있습니다: 리그레시브 커넥션(Regressive Connection), 어텐션 디코더(Attention Decoder), 그리고 어그멘팅 블록(Augmenting Block). 주요 개선 사항으로는 독립된 어텐션 디코더를 사용하여 숨겨진 상태(hidden states)와 출력 토큰 정보를 통합하고 출력 프로젝터를 통해 ResBlock을 대체하며, 더 정교한 어그멘팅 블록을 사용해 모델 성능을 향상시키는 것 등이 포함됩니다. 또한, 지식 증류 전략을 채택하여 LLM의 숨겨진 상태와 분류 출력을 학습합니다.

- **Performance Highlights**: 실험 결과, Clover-2는 표준 디코딩보다 최대 3.00배 높은 처리량을 보였고, 기존 Clover보다 1.18배에서 1.65배 높은 성능을 보였습니다. 또한, RNN 기반 아키텍처임에도 불구하고 EAGLE과 비교하여 최대 9.3% 더 빠른 속도를 자랑했습니다.



### Enhanced Structured State Space Models via Grouped FIR Filtering and Attention Sink Mechanisms (https://arxiv.org/abs/2408.00244)
- **What's New**: 이번 논문에서는 구조화된 상태 공간 모델(SSM, Structured State Space Model)의 성능을 개선하기 위해 새로운 아키텍처를 제안합니다. 기존 SSM에는 반복적 행렬 곱셈으로 인해 훈련 어려움과 민감성이 있었으나, 본 논문에서는 이러한 문제를 완화하기 위해 A-곱셈을 여러 그룹으로 분해하고, Grouped FIR 필터링을 통해 위치 인코딩을 최적화하는 방식을 채택했습니다. 이 새로운 구조는 Grouped FIR-enhanced SSM (GFSSM)로 명명되었으며, semi-separable 행렬을 사용해 효율적인 계산을 수행합니다. 또한, 스트리밍 언어 모델에서 확인된 'attention sink' 현상을 통합하여 긴 시퀀스에서의 안정성과 성능을 향상시켰습니다.

- **Technical Details**: GFSSM 아키텍처는 크게 두 가지 혁신적인 요소를 포함합니다. 먼저, A-곱셈을 더 작은 그룹으로 분해하고 이는 Grouped FIR 필터링을 통해 위치 인코딩을 최적화합니다. 이로 인해 훈련의 민감성을 줄이고 안정성과 성능을 향상시켰습니다. 두 번째로, 스트리밍 언어 모델에서 영감을 받은 attention sink 메커니즘을 통합하여 초기 토큰을 'sink'로 유지함으로써 긴 시퀀스에서도 안정적인 주의 메커니즘을 제공합니다. 이를 통해 모델은 긴 범위의 종속성을 효과적으로 처리할 수 있습니다.

- **Performance Highlights**: GFSSM은 기존 SSM 구조보다 길고 복잡한 시퀀스를 처리하는 데 있어 뛰어난 성능을 보였습니다. 이는 주로 Grouped FIR 필터링과 attention sink 메커니즘의 통합 덕분입니다. 실험 결과에서 이 모델은 더 긴 시퀀스에 대해 높은 안정성과 성능을 유지함을 확인할 수 있었습니다.



### Sentence-wise Speech Summarization: Task, Datasets, and End-to-End Modeling with LM Knowledge Distillation (https://arxiv.org/abs/2408.00205)
Comments:
          Accepted to Interspeech2024. Dataset: this https URL

- **What's New**: 본 논문은 Sen-SSum으로 불리는 새로운 접근 방식을 소개합니다. Sen-SSum은 문장 단위로 음성 문서에서 텍스트 요약을 생성하는 방법으로, 자동 음성 인식(ASR)과 음성 요약의 장점을 결합합니다. 이를 탐구하기 위해 Mega-SSum과 CSJ-SSum 두 가지 데이터셋이 소개되었습니다.

- **Technical Details**: Sen-SSum은 문장 단위로 텍스트 요약을 생성하여 실시간 처리가 가능한 ASR의 장점과 간결한 요약의 장점을 결합합니다. 연구는 두 가지 Transformer 기반 모델을 평가합니다: 1) ASR과 강력한 텍스트 요약 모델을 결합한 카스케이드(Cascade) 모델과 2) 음성을 직접 텍스트 요약으로 변환하는 엔드투엔드(E2E) 모델. E2E 모델의 성능 향상을 위해 지식 증류(knowledge distillation) 방법을 제안하였습니다.

- **Performance Highlights**: 실험 결과, 제안된 지식 증류를 통해 E2E 모델의 성능이 두 데이터셋 모두에서 유의미하게 개선되었습니다. 특히, 특정 조건에서는 생성된 가짜 요약이 수동 요약보다 나은 경우도 있었습니다.



### Automatic Generation of Behavioral Test Cases For Natural Language Processing Using Clustering and Prompting (https://arxiv.org/abs/2408.00161)
- **What's New**: 이 논문은 자연어 처리(NLP) 모델의 행동 테스트를 위한 자동화된 접근 방식을 소개합니다. 현존하는 방법들은 도메인 전문 지식과 많은 시간이 필요로 하는 반면, 이 논문에서는 대형 언어 모델과 통계 기법을 사용하여 테스트 케이스를 자동으로 개발하는 방식을 제안합니다.

- **Technical Details**: 이 접근 방식은 텍스트 표현(text representations)을 클러스터링(cluster)을 통해 의미 있는 그룹으로 신중하게 구성한 후, 프로밍 기법을 사용하여 Minimal Functionality Tests(MFT)를 자동으로 생성합니다. 여기에 사용된 데이터셋은 잘 알려진 Amazon Reviews 코퍼스입니다.

- **Performance Highlights**: 제안된 방법을 통해 생성된 테스트 케이스들을 네 가지 다른 분류 알고리즘(classification algorithms)에 적용하여 행동 테스트 프로필을 분석했습니다. 또한, 이 모델들의 한계와 강점을 논의했습니다.



### Distributed In-Context Learning under Non-IID Among Clients (https://arxiv.org/abs/2408.00144)
Comments:
          12 pages

- **What's New**: 이 논문은 대형 언어 모델(LLMs)을 새로운 또는 익숙하지 않은 작업에 효율적으로 적응시키는 도전과제를 신기원적으로 해결합니다. 특히, 다수의 클라이언트에 분산된 비독립 동일분포(non-IID) 데이터를 가지고 있는 환경에서의 인컨텍스트 학습(ICL)의 장애물을 극복하는 새로운 접근법을 제안합니다. 이를 위해 각 테스트 쿼리에 대한 클라이언트의 기여도를 데이터 기반 방식으로 할당하는 프레임워크를 도입합니다.

- **Technical Details**: 논문에서는 데이터 사용 예산이 존재하는 분산된 non-IID ICL 문제를 다룹니다. 프레임워크는 다음과 같은 단계로 이루어집니다: 1) 서버는 자체 프록시 데이터셋을 사용하여 최적의 예산 통계를 수집합니다. 2) 서버는 이 데이터셋으로 예산 할당기를 학습합니다. 3) 배포 단계에서 서버는 예산 할당기를 사용해 각 테스트 쿼리에 대해 클라이언트당 적절한 예산을 예측하고 ICL을 수행합니다. 또한, 프라이버시 문제가 있는 실제 시나리오에서는 의역(paraphrasing) 방법을 사용하여 프라이버시를 보호합니다.

- **Performance Highlights**: 다양한 데이터셋 벤치마크와 여러 LLM 아키텍처에서, 제안된 프레임워크는 경쟁하는 기준선보다 ICL 성능을 향상시켰습니다. 비공개 및 프라이버시 보호 설정 모두에서 우수한 성능을 보여주었으며, 특히 각 테스트 쿼리에 대한 최적화된 예산 할당을 통해 더 관련성 깊은 문맥을 형성합니다.



### Correcting Negative Bias in Large Language Models through Negative Attention Score Alignmen (https://arxiv.org/abs/2408.00137)
- **What's New**: 이번 연구에서는 언어 모델이 복잡한 추론 작업의 이진 결정에서 부정적 편향(negative bias)을 보이는 현상을 관찰하였습니다. 이를 기반으로 NAS(Negative Attention Score)를 제안하여 이러한 부정적 편향을 체계적으로 정량화하고, 부정 편향 관련 주의 헤드(attention heads)를 식별하였습니다. 또한, NASA(Negative Attention Score Alignment)라는 파라미터 효율적인 미세 조정 기법을 도입해 문제를 해결하고자 합니다.

- **Technical Details**: LLMs(대형 언어 모델)가 'Yes-No' 질문이나 답변 확인 등의 이진 결정 작업에서 부정적 편향을 보일 때 주의 메커니즘 내에서 NAS를 통해 이러한 현상을 정량적으로 측정하고 평가합니다. NAS를 기반으로 부정적으로 작용하는 주의 헤드를 식별하여 모델의 일부 부정적 편향을 유발하는 요소를 밝혀냈습니다. 이를 해결하기 위해 NASA라는 미세 조정 기법을 적용하였으며, 이는 가장 편향된 주의 헤드부터 점진적으로 조정하는 기법입니다.

- **Performance Highlights**: 다양한 추론 작업과 대형 모델 탐색에서 NASA를 사용하여 부정 편향으로 인한 정밀도(precision)와 재현율(recall) 간의 격차를 크게 줄이면서도 모델의 일반화 능력은 그대로 유지되었습니다. NASA 기법은 모델이 이진 결정 작업에서 더 나은 캘리브레이션(calibration) 성능을 보이게 하였습니다.



### A Course Shared Task on Evaluating LLM Output for Clinical Questions (https://arxiv.org/abs/2408.00122)
Comments:
          accepted at the sixth Workshop on Teaching NLP (co-located with ACL 2024)

- **What's New**: 2023/2024 학년도 다름슈타트 공과대학교에서 '기술 언어의 기초' (Foundations of Language Technology; FoLT) 강의의 일환으로 대형 언어 모델 (LLMs)의 유해 답변 생성을 평가하는 공동 과제를 소개합니다. 이 과제는 학생들에게 건강 관련 임상 질문에 대한 LLM의 출력을 평가하도록 하였습니다. 논문에서는 과제 설계와 학생들의 피드백을 다루고 있습니다.

- **Technical Details**: 이 과제는 LLM이 제공하는 답변을 신뢰할 수 있는 과학적 증거를 기반으로 검증하는 일종의 과학적 사실 확인(scientific fact-checking) 과제입니다. 주요 목표는 건강 관련 임상 질문 q와 인간 전문가의 답변 a 및 LLM의 답변 a'를 비교하여 a'가 유해 정보를 포함하는지, 그리고 a'의 각 문장에 세부 범주 레이블을 부여하는 것입니다. Cochrane Clinical Answers(CCA)를 데이터셋으로 활용하였습니다.

- **Performance Highlights**: 이번 과제에는 총 55개 팀이 참가했으며, 360개의 CCAs로부터 1800개의 답변을 주석 달았습니다. 총 5개의 LLM(Llama-2-70b-chat, OpenAI ChatGPT, Microsoft BingChat, PerplexityAI)을 사용했습니다. 참여 학생들은 사실 확인을 위해 결정 트리와 간단한 신경망 모델을 훈련시키고 결과를 제출하였습니다. 전체 과업의 70% 이상의 점수를 획득한 74명의 학생들은 최종 성적에서 보너스 점수를 획득하였습니다.



### Gemma 2: Improving Open Language Models at a Practical Siz (https://arxiv.org/abs/2408.00118)
- **What's New**: Gemma 2는 최신의 경량 오픈 모델로, 2억에서 270억 파라미터 규모의 다양한 모델을 포함합니다. 이번 버전에서는 Transformer 아키텍처에 대한 몇 가지 기술적 수정 사항을 적용했습니다. 대표적으로는 로컬-글로벌 어텐션(interleaving local-global attentions)과 그룹 쿼리 어텐션(group-query attention)을 사용하였습니다. 또한 2B 및 9B 모델은 next token prediction 대신 지식 증류(knowledge distillation)로 학습되었으며, 이는 모델 크기에 비해 최고의 성능을 제공합니다. 모든 모델은 커뮤니티에 공개되었습니다.

- **Technical Details**: Gemma 2는 디코더 전용 Transformer 아키텍처를 기반으로 하며, 기존 Gemma 모델과 유사한 몇 가지 요소를 공유합니다. 여기에는 8192 토큰의 컨텍스트 길이, Rotary Position Embeddings (RoPE) 및 근사화된 GeGLU 비선형성이 포함됩니다. 새롭게 추가된 것은 로컬 슬라이딩 윈도우 어텐션과 글로벌 어텐션의 교차 사용, logit soft-capping, RMSNorm을 사용한 안정화 기술입니다. 또한 그룹 쿼리 어텐션을 사용하여 추론 시간을 단축시키는 동시에 성능을 유지합니다.

- **Performance Highlights**: Gemma 2는 다양한 자동화 벤치마크와 인간 평가에서 동급 규모의 오픈 모델 대비 현저히 향상된 성능을 나타냅니다. 주요 성과로는 질문 응답, 상식 추론, 수학 및 과학, 코딩 등 여러 도메인에서 우수한 성능을 보였습니다. 특히, 지식 증류를 통해 크기가 2-3배 큰 모델과도 경쟁할 수 있는 성능을 제공합니다.



### ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budg (https://arxiv.org/abs/2408.00103)
Comments:
          To be presented at ACL 2024

- **What's New**: ReLiK은 엔터티 연결(Entity Linking, EL)과 관계 추출(Relation Extraction, RE)에 새로운 접근법을 제시하는 논문입니다. 이 시스템은 제공된 입력 텍스트에서 잠재적인 엔터티나 관계를 식별하는 Retriever 모듈과, 식별된 엔터티나 관계를 정확한 텍스트 구간에 연결하는 Reader 모듈로 구성된 Retriever-Reader 아키텍처를 도입합니다. 이 방식은 한 번의 포워드 패스(forward pass)로 엔터티를 연결하거나 관계를 추출할 수 있으며, 사전학습된 언어 모델의 문맥화를 최대한 활용할 수 있습니다.

- **Technical Details**: ReLiK은 인풋과 후보 엔터티 또는 관계를 함께 입력으로 받아 처리합니다. Retriever 모듈은 Dense Passage Retrieval(DPR) 방식을 기반으로, 입력 텍스트의 인코딩과 외부 인덱스의 텍스트 패시지 인코딩을 통해 가장 관련성 높은 패시지를 검색합니다. Reader 모듈은 입력 텍스트와 검색된 패시지를 함께 인코딩하고, 단일 포워드 패스로 엔터티를 연결하거나 관계를 추출합니다. 특히, 우리의 혁신적인 입력 표현 방식은 새로운 엔터티/관계를 zero-shot으로 처리할 수 있는 유연성(Flexibility)을 제공합니다.

- **Performance Highlights**: ReLiK은 동일한 아키텍처를 사용하여 EL과 RE 모두에서 최신 성능(State-of-the-art)을 달성했으며, 타 경쟁 시스템들보다 40배 빠른 추론 속도(Inference Speed)를 보여줍니다. 또한, 우리의 방법론은 학술적 예산으로 훈련이 가능하여, 학술 연구 그룹들이 접근하기 용이합니다. 우리는 ReLiK 시스템이 EL과 RE를 동시에 처리하는 정보 추출(Information Extraction, cIE)에서도 새로운 표준을 설정하였으며, 코드를 GitHub에 공개하여 연구와 활용을 촉진하고 있습니다.



### MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities (https://arxiv.org/abs/2408.00765)
Comments:
          Extension of MM-Vet: arXiv:2308.02490

- **What's New**: MM-Vet v2가 새롭게 출시되어 더욱 발전된 대형 멀티모달 모델을 평가합니다. 이번 버전에서는 '이미지-텍스트 시퀀스 이해(image-text sequence understanding)'라는 새로운 VL 능력이 추가되었습니다. 이를 통해 모델의 이미지와 텍스트가 혼합된 시퀀스를 처리하는 능력을 평가할 수 있습니다.

- **Technical Details**: 기존 MM-Vet는 단일 이미지-텍스트 쌍을 기반으로 질문 형식을 제한했지만, MM-Vet v2는 이 제한을 극복하고 이미지를 <image>으로 나타내는 시퀀스 이해를 포함하도록 개선되었습니다. 새로운 데이터셋은 높은 품질을 유지하면서도 평가 샘플 수를 517개로 확장하였습니다. 질문 생성과 참조 답안 작성은 연구자들이 직접 설계하고 GPT-4V의 초안을 검토 및 수정하는 과정을 거쳤습니다.

- **Performance Highlights**: MM-Vet v2를 활용한 대형 멀티모달 모델 평가에서 Claude 3.5 Sonnet이 71.8점으로 최고 성능을 기록하였고, GPT-4o가 71.0점으로 그 뒤를 이었습니다. 특히, 오픈-웨이트 모델 중에서는 InternVL2-Llama3-76B가 68.4점으로 우수한 성능을 보였습니다.



### Tamper-Resistant Safeguards for Open-Weight LLMs (https://arxiv.org/abs/2408.00761)
Comments:
          Website: this https URL

- **What's New**: 이 논문에서는 대형 언어 모델(LLM)의 악의적인 사용을 막기 위한 새로운 방법론인 TAR(Tamper-Resistant)을 개발했습니다. 기존의 방어 메커니즘은 모델 가중치를 변경하는 공격에 쉽게 무너질 수 있다는 문제점을 해결하고, 수천 번의 미세 조정 후에도 안전 장치가 제거되지 않도록 설계되었습니다.

- **Technical Details**: TAR은 메타 러닝(meta-learning)과 적대적 학습(adversarial training) 접근법을 활용하여 모델의 가중치 변경에 대한 공격을 방어할 수 있도록 설계되었습니다. 이 방법론은 tamper-resistance loss, 학습 시 적대자의 선택, 두 단계 접근법 등 여러 중요한 요소를 결합하여 효과를 발휘합니다.

- **Performance Highlights**: 광범위한 평가와 레드 팀 분석을 통해 TAR을 적용한 모델이 최대 5,000번의 미세 조정 단계에서도 높은 수준의 tamper-resistance를 유지한다는 것을 확인했습니다. 또한, 선행 방법 대비 훨씬 뛰어난 방어력을 입증했습니다.



### SentenceVAE: Faster, Longer and More Accurate Inference with Next-sentence Prediction for Large Language Models (https://arxiv.org/abs/2408.00655)
Comments:
          Modified some of the expression details and optimized the charts

- **What's New**: 현재의 대형 언어 모델(LLMs)은 주로 다음 토큰 예측 방식을 사용하여 추론 시간을 지연시키는데, 본 논문에서는 이를 개선하기 위해 '다음 문장 예측(next-sentence prediction)'이라는 새로운 추론 방식을 소개했습니다. 이를 위해 SentenceVAE라는 작은 모델을 도입했습니다. SentenceVAE는 인코더와 디코더로 구성되어 문장의 정보를 압축하여 하나의 토큰으로 변환하고, 이를 다시 원래의 문장 형식으로 복원합니다.

- **Technical Details**: SentenceVAE는 문장을 여러 토큰으로 분리한 후, 이를 단일 토큰으로 압축하는 인코더와 다시 원래의 단어 단위 토큰 시퀀스로 재구성하는 디코더로 구성되어 있습니다. SentenceVAE를 대형 언어 모델의 입력 및 출력 계층에 통합해, 문장 단위로 추론을 수행하는 SLLMs(Sentence-level LLMs)를 개발하였습니다. 이를 통해 문장을 단위로 나누어 추론 속도를 가속화하면서도 원래의 의미적 일관성을 유지할 수 있습니다.

- **Performance Highlights**: SentenceVAE를 사용한 SLLMs는 기존의 LLMs보다 204~365% 더 빠른 추론 속도를 보였으며, 혼잡도(perplexity)가 46~75% 감소했습니다. 또한 동일한 컨텍스트 길이에서 메모리 오버헤드가 86~91% 감소했음을 확인했습니다. 이 접근 방식의 장점은 모델 매개변수(parameter)가 증가할수록 더욱 증폭되었습니다.



### SynesLM: A Unified Approach for Audio-visual Speech Recognition and Translation via Language Model and Synthetic Data (https://arxiv.org/abs/2408.00624)
- **What's New**: 이번 연구에서 우리는 SynesLM이라는 통합 모델을 소개합니다. 이 모델은 오디오-비주얼 자동 음성 인식(AV-ASR)과 시각적 언어 번역(VST/VMT)의 세 가지 멀티모달 언어 이해 작업을 수행할 수 있습니다. 이전 연구와 달리, 우리의 연구는 전체 프레임 내에서 객체와 동작 등의 더 일반적인 비주얼 정보를 탐색합니다. 또한, 합성 이미지 데이터를 사용하여 이미지와 음성 데이터 간의 상관성을 향상시켰습니다.

- **Technical Details**: SynesLM은 최신 언어 모델의 발전을 활용하여 오디오-비주얼 자동 음성 인식(AV-ASR), 비주얼 지원 음성 번역(VST), 비주얼 기계 번역(VMT)과 같은 복잡한 언어 작업을 능숙하게 처리할 수 있는 통합 접근 방식을 채택하고 있습니다. 최근 멀티모달 언어 이해 데이터셋인 How2와 같은 데이터 세트의 품질을 향상시키기 위해 합성 이미지 데이터 복구 파이프라인을 제안했습니다. 시각적 모달리티의 경우 비디오 클립에서 하나의 프레임을 무작위로 선택하여 비주얼 입력으로 사용하고, 사전 학습된 CLIP 모델을 사용하여 이미지의 전체 피처를 추출했습니다. 음성 입력 처리는 SSL 특성 추출기를 사용하여 음성을 이산 토큰으로 변환합니다.

- **Performance Highlights**: SynesLM은 다양한 작업에서 뛰어난 성능을 기록했습니다. VisSpeech 데이터셋에서 제로샷(Zero-shot) AV-ASR 작업에서 Word Error Rate(WER)를 43.4%에서 39.4%로 낮추며 SOTA 성능을 달성했습니다. 또한 VST에서 BLEU 점수를 37.2에서 43.5로, VMT에서 BLEU 점수를 54.4에서 54.8로 향상시켰습니다.



### Are Bigger Encoders Always Better in Vision Large Models? (https://arxiv.org/abs/2408.00620)
- **What's New**: 최근 몇 년간, 멀티모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)은 실제 응용에서 강력한 잠재력을 보여주고 있습니다. 특히, 비전 언어 모델(Vision Language Models, VLMs)은 멀티모달 정보 이해 능력으로 주목받고 있지만, 현재의 주류 패러다임 하에서 VLM의 스케일링 동향에 대한 연구는 충분하지 않았습니다. 본 연구는 MLLMs의 사전 훈련 단계에서 다양한 인코더 크기와 대형 언어 모델(LLM) 크기를 사용하여 실험을 수행했습니다.

- **Technical Details**: 이번 연구는 스케일링 법칙(scaling laws)을 조사하기 위해, LLaVA1.5 모델을 백본으로 선택했습니다. 실험은 70억 및 130억 개의 파라미터를 가진 모델로 진행되었으며, CC12M 및 Laion400M 이미지-텍스트 쌍 데이터를 사용했습니다. 데이터 크기는 100만에서 1000만 쌍까지 다양하게 조정하여 실험을 진행했습니다. 실험 결과, 단순히 인코더 크기를 늘리는 것이 VLM의 성능을 반드시 향상시키지는 않는다는 결론을 얻었습니다.

- **Performance Highlights**: 핵심 발견은 ViT(Visual Transformer)를 더 많은 파라미터와 함께 CLIP으로 훈련한다고 해서 MLLMs 성능이 향상되지는 않는다는 것입니다. 이는 MLLMs의 성능을 향상시키기 위해 대체 방법을 탐구해야 함을 시사합니다. 또한, 비주얼 인코더의 스케일링 능력의 한계에서 발생하는 문제는 아니라고 분석되었습니다.



### Alleviating Hallucination in Large Vision-Language Models with Active Retrieval Augmentation (https://arxiv.org/abs/2408.00555)
- **What's New**: 최근의 연구는 대형 시각-언어 모델(LVLM)에서 발생하는 왜곡(hallucination) 문제를 해결하기 위해 '액티브 검색 증강 대형 시각-언어 모델(Active Retrieval-Augmented large vision-language model, ARA)'을 제안합니다. 이 모델은 이미지의 계층적 구조를 기반으로 검색 목표를 분해하고, 가장 효과적인 검색 방법을 선별하며, 검색 시기를 조절하여 모델의 불확실성이 낮을 때 검색을 활성화하는 방법을 사용합니다.

- **Technical Details**: ARA 모델은 세 가지 핵심 차원을 통합하여 설계되었습니다. 첫째, 이미지를 계층적으로 분석하여 목표 객체를 추출하는 '구조적 검색'을 수행합니다. 둘째, 다양한 멀티모달 입력 방식을 분석하여 가장 효과적인 검색 방식을 적용하고 신뢰할 수 있는 결과를 필터링합니다. 셋째, 모델의 불확실성이 낮을 때만 검색을 수행하여 불필요한 검색을 피합니다. 이 과정을 통해 ARA는 'coarse-to-fine' 검색 패러다임을 적용하며, 이미지 전체와 특정 지역 모두를 분석해 검색 정확도를 높입니다.

- **Performance Highlights**: 제안된 ARA 모델은 세 가지 LVLM 모델(LLaVA-1.5, Qwen-VL, mPLUG-Owl2)을 이용한 네 가지 벤치마크 테스트에서 인상적인 성능을 보였습니다. 실험 결과에 따르면, 적절한 검색 메커니즘을 활용하고 검색 시점을 신중하게 조절함으로써 왜곡 문제를 효과적으로 감소시킬 수 있음이 확인되었습니다.



### Mitigating Multilingual Hallucination in Large Vision-Language Models (https://arxiv.org/abs/2408.00550)
- **What's New**: LVLMs(대형 비전-언어 모델)은 다양한 작업에서 뛰어난 성능을 보였으나, 입력된 이미지-쿼리 쌍에 대해 그럴듯하지만 잘못된 답변을 생성하는 환각 문제로 고통받고 있습니다. 이 논문에서는 LVLMs의 다중언어 환각 문제를 완화하기 위한 첫 번째 시도를 했습니다. 특히, 다중언어 POPE 벤치마크에서 평균 19.0%의 정확도 향상을 달성했습니다.

- **Technical Details**: 본 연구는 다중언어 환각 제거(MHR) 프레임워크를 두 단계로 제안했습니다. 먼저 다중언어 지시어 이해 능력을 개선한 뒤, 모델의 환각 저항 능력을 강화합니다. 이를 위해 교차 언어 정렬(cross-lingual alignment) 방법을 사용하여 다중언어 환각 데이터를 생성하고, 이를 통해 직접 최적화를 수행합니다.

- **Performance Highlights**: 실험 결과, MHR 프레임워크는 낮은 자원 언어와 높은 자원 언어 모두에서 환각 문제를 크게 감소시켰습니다. 확장된 다중언어 POPE 벤치마크에서 우리 프레임워크는 13개 언어에서 평균적으로 19.0%의 정확도 향상을 보여주었습니다.



### The Monetisation of Toxicity: Analysing YouTube Content Creators and Controversy-Driven Engagemen (https://arxiv.org/abs/2408.00534)
Comments:
          Accept for publication at the 4th International Workshop on Open Challenges in Online Social Networks (OASIS) held in conjunction with 35th ACM Conference on Hypertext and Social Media (HT24)

- **What's New**: 이번 연구에서는 YouTube의 논란성 콘텐츠와 관련된 독특한 데이터셋을 구축하고, 논란, 독성(tocity), 및 수익화(monetisation)의 상관 관계를 분석합니다. Reddit를 통해 20개의 논란성 YouTube 채널을 선정하여 16,349개의 비디오와 1억 5백만 개가 넘는 댓글을 포함한 데이터를 수집했습니다.

- **Technical Details**: 연구팀은 Reddit의 두 개 서브레딧(r/YouTubeDrama, r/InternetDrama)에서 상위 1000개의 핫 쓰레드(hot threads)로부터 데이터를 수집했습니다. 이를 통해 각 쓰레드와 댓글에서 YouTube URL을 추출한 후 Named Entity Recognition (NER) 기법을 사용해 언급된 채널을 식별했습니다. 또한, 비디오 설명에서 수익화 전략을 분류하기 위해 URL과 키워드 리스트를 작성했고, 댓글 독성을 측정하는 머신러닝 모델을 학습시켰습니다.

- **Performance Highlights**: 연구 결과, 독서 댓글 수와 연관된 참여도는 높아졌지만, 수익화에는 부정적인 영향을 미친다는 사실을 발견했습니다. 이는 논란에 의해 촉발된 상호작용이 반드시 재정적 이득으로 이어지지 않음을 시사합니다. 또한, 수익화 전략은 채널마다 상당한 차이를 보였고, 일부 채널은 높은 독성 레벨에도 불구하고 광범위한 수익화를 달성했습니다.



### ABC Align: Large Language Model Alignment for Safety & Accuracy (https://arxiv.org/abs/2408.00307)
Comments:
          23 pages, 4 figures

- **What's New**: 이번 논문에서는 대규모 언어 모델(LLMs)의 새로운 정렬 방법론인 'ABC Align'을 제안합니다. 이 방법론은 대규모 미디어 조직의 표준과 선호도를 LLM 자체에 통합할 수 있게 합니다. 이를 통해 편향을 줄이고 정확도를 향상시키는 동시에 추론 능력을 유지할 수 있습니다.

- **Technical Details**: ABC Align은 공개 소스 모델의 미세 조정(fine-tuning)과 비공개 소스의 '최첨단'(frontier) 모델에서의 In-Context Learning (ICL)을 포함합니다. 여기에는 뉴스 기사 내용, 조직의 'AI 원칙'(Australian Broadcasting Corporation, 2024a), 그리고 내부 검색 증강 생성(RAG) 도구에서 수집된 질문/답변 쌍이 사용됩니다. 미세 조정에서는 합성 데이터 생성, 지식 증류(knowledge distillation), 선호도 최적화 등의 기법을 사용하여 데이터셋을 생성합니다.

- **Performance Highlights**: Meta의 Llama3-8B 모델을 대상으로 한 TruthfulQA 벤치마크에서 23.51%의 상대 성능 향상을 달성했습니다. 또한 OpenAI의 GPT4-turbo 모델에서 내부 RAG 도구와 AI 원칙을 사용하는 시스템 프롬프트가 Bias Benchmark for Question Answering (BBQ) 벤치마크에서 77.54%의 성능 향상을 보였습니다.



### Lost in Translation: Latent Concept Misalignment in Text-to-Image Diffusion Models (https://arxiv.org/abs/2408.00230)
Comments:
          33 pages, 19 figures

- **What's_New**: 새로운 연구는 텍스트에서 이미지로 변환하는 확산 모델(text-to-image diffusion models)에서 발생하는 잠재적 개념 불일치 문제(Latent Concept Misalignment, LC-Mis)을 식별하고 해결하는 방법을 제안합니다. 연구진은 'a tea cup of iced coke'와 같은 문구에서 텍스트와 이미지 간의 불일치 문제가 발생하는 이유를 조사하고 이 문제를 해결하기 위한 자동화된 파이프라인을 개발했습니다. 이 접근법은 LC-Mis 오류를 크게 줄이고 모델의 견고성과 다재다능성을 향상시킵니다.

- **Technical_Details**: 연구진은 대형 언어 모델(LLMs)을 활용하여 LC-Mis 문제의 범위를 철저히 조사하였습니다. 기존 모델에서 텍스트 프롬프트에서 기대하는 개념이 이미지에 제대로 반영되지 않는 문제를 해결하기 위해 'Mixture of Concept Experts (MoCE)'라는 새로운 접근법을 제안했습니다. 또한 입력 텍스트를 확산 모델의 생성 과정에서 두 단계로 분할하여 단계적으로 이미지를 생성하는 방식을 채택했습니다. 이 프로세스는 Clipscore와 Image-Reward와 같은 검증된 지표를 사용하여 이미지와 텍스트 간의 정렬을 측정하고, 이를 통해 최적의 이미지를 생성할 수 있도록 적응합니다.

- **Performance_Highlights**: 새로운 접근법을 통해 LC-Mis 문제를 크게 완화할 수 있었으며, 텍스트에서 이미지로의 변환 모델의 적용성과 유연성을 향상시켰습니다. 실험적 사례 연구를 통해 우리의 방법이 기존 모델보다 뛰어난 성능을 발휘함을 확인했습니다. 연구 결과는 다양한 분야에 걸쳐 이 기술의 가능성을 보여줍니다. 실제로 Midjourney와 SDXL과 같은 최신 모델에서도 우리 방법이 높은 품질의 이미지를 생성하는 데 기여하는 것으로 나타났습니다.



### OmniParser for Pure Vision Based GUI Agen (https://arxiv.org/abs/2408.00203)
- **What's New**: 새로운 연구인 	extsc{OmniParser}는 사용자의 인터페이스(UI) 스크린샷을 구조화된 요소들로 파싱(parsing)하는 기술을 소개합니다. 이로 인해 GPT-4V와 같은 멀티모달 모델이 더 정확하게 동작할 수 있도록 돕습니다.

- **Technical Details**: 	extsc{OmniParser}는 상호작용 가능한 아이콘을 감지하는 Detection 모델과 아이콘의 기능적 의미를 추출하는 Caption 모델로 구성되어 있습니다. 이를 위해 인기 있는 웹페이지들을 바탕으로 상호작용 가능한 아이콘 감지 데이터셋과 설명 데이터셋을 구성했습니다. 이 데이터셋을 통해 모델들을 미세 조정(fine-tune)하여 사용자의 인터페이스를 더 잘 이해할 수 있도록 했습니다.

- **Performance Highlights**: 	extsc{OmniParser}는 ScreenSpot 벤치마크에서 GPT-4V의 성능을 크게 향상시켰습니다. Mind2Web 및 AITW 벤치마크에서도 스크린샷만을 이용한 입력으로, 추가 정보를 요구하는 GPT-4V 기반모델을 뛰어넘는 성능을 발휘했습니다.



### Automated Software Vulnerability Static Code Analysis Using Generative Pre-Trained Transformer Models (https://arxiv.org/abs/2408.00197)
- **What's New**: GPT 모델이 C 및 C++ 소스 코드에서 취약한 코드 구문을 자동으로 식별하는 능력을 평가했습니다. NIST SARD 데이터셋의 36개의 소스 코드 예제를 통해 테스트했으며, 이 데이터셋은 특정 취약점을 나타내는 자연어가 포함되지 않도록 신중하게 큐레이션되었습니다.

- **Technical Details**: 5개의 오픈 소스 GPT 모델을 10가지 추론 온도와 100회 반복을 통해 총 5,000개의 GPT 쿼리를 분석했습니다. 평가에는 Llama-2-70b-chat-hf와 같은 모델들이 포함되었으며, 이 모델들은 파이썬3 모듈인 pytorch와 transformers를 사용하여 로컬 GPU 서버에서 실행되었습니다. 모든 GPT 모델 계산은 로컬 Nvidia A100 GPU 서버에서 수행되었습니다.

- **Performance Highlights**: 높은 거짓 긍정 및 거짓 부정 비율로 인해 완전한 자동 취약점 스캐닝에는 적합하지 않지만, 일부 테스트 케이스에서는 예상보다 좋은 성능을 보였습니다. 특히 NIST SARD 테스트 케이스 149165에서 Llama-2-70b-chat-hf 모델은 버퍼 오버플로우 취약점을 정확히 식별하여 이진 분류 리콜 점수와 정밀도가 1.0을 기록했습니다.



### A Taxonomy of Stereotype Content in Large Language Models (https://arxiv.org/abs/2408.00162)
- **What's New**: 이번 연구에서는 현대의 대형 언어 모델(Large Language Models, LLM)에서 나타나는 고정관념에 대한 분류체계를 소개합니다. ChatGPT 3.5, Llama 3, 그리고 Mixtral 8x7B와 같은 강력하고 널리 사용되는 LLM들을 대상으로 87개의 사회적 범주(성별, 인종, 직업 등)와 연관된 특징을 분석했습니다. 이 연구는 LLM들이 고정관념을 어떻게 반영하는지를 밝히고, 이러한 내용을 AI 감사 및 편향 제거(debiasing)에 중요한 참고 자료로 사용해야 한다고 주장합니다.

- **Technical Details**: 우리는 도덕성(Morality), 능력(Ability), 건강(Health), 신념(Beliefs), 감정(Emotions) 등을 포함한 14개의 고정관념 차원(stereotype dimensions)을 식별하였습니다. 이 차원들은 LLM 고정관념 연관성의 약 90%를 차지합니다. 그 중에서도 '따뜻함(Warmth)'과 '능력(Competence)'이 가장 자주 나타났지만, 다른 차원들도 상당히 빈번하게 발견되었습니다. 또한, LLM에서 나타나는 고정관념은 인간보다 긍정적이었지만, 범주와 차원에 따라 상당한 변동성이 있었습니다.

- **Performance Highlights**: 우리의 연구 결과에 따르면, LLM의 내부 평가(positive/negative)에 대해 이 분류체계가 예측 능력을 지니고 있음이 확인되었습니다. 이로써, 다차원적(n-dimensional) 분류체계가 LLM 고정관념을 평가하는 데 유의미함을 증명하였습니다. 고차원적인 인간의 고정관념이 LLM에서도 반영되고 있으며, 이는 저차원적인 편향 뷰(low-dimensional views of bias)에만 의존해 발생할 수 있는 한계를 최소화하는 AI 감사 및 편향 제거 전략에 반영되어야 함을 시사하고 있습니다.



### Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models (https://arxiv.org/abs/2408.00113)
Comments:
          Oral paper (top 5%) at the ICML 2024 Mechanistic Interpretability Workshop

- **What's New**: 최근 연구에 따르면, Sparse Autoencoders (SAEs)를 사용하여 언어 모델(LM) 내부 표현에서 해석 가능한 특징들을 분리하는 것이 주목받고 있습니다. 그러나 이러한 SAEs의 품질을 평가하기가 어려운데, 그 이유는 우리가 기대하는 '해석 가능한 특징'의 기준이 없기 때문입니다. 이 연구에서는 체스와 오셀로 게임의 기록을 학습한 LMs를 사용하여 자연스러운 해석 가능한 특징들을 측정하고자 합니다. 우리는 새로운 SAE 훈련 기법인 `p-annealing`을 도입하여 이 과정의 성능을 향상시켰습니다.

- **Technical Details**: 이 연구는 체스와 오셀로 게임 기록을 예측하는 언어 모델을 토대로 SAEs를 훈련합니다. 우리는 두 개의 새로운 메트릭으로 SAE의 품질을 측정합니다: 'Board reconstruction'(보드 상태 재구성)과 'Coverage'(커버리지). 또한, 새로운 SAE 훈련 방법인 `p-annealing`을 도입하여 기존 메트릭에 비해 성능을 향상시켰습니다. p-annealing은 훈련 초기에는 convex 최적화 문제를 해결하고, 이후 non-convex 목표를 향해 L_p norm-based sparsity penalty를 적용합니다.

- **Performance Highlights**: p-annealing 방법을 사용한 SAEs는 기존의 방법보다 뛰어난 성능을 보였습니다. 기존의 메트릭과 새롭게 제안된 메트릭 모두에서 유의미한 성능 향상을 확인했습니다. 특히, 체스와 오셀로 모델을 기준으로 훈련된 500개 이상의 SAEs를 공개하여 다른 연구자들이 추가 실험과 검증을 할 수 있도록 했습니다.



### Towards a Universal Method for Meaningful Signal Detection (https://arxiv.org/abs/2408.00016)
- **What's New**: 이 논문은 신호의 함의(menaingfulness)를 감지하는 새로운 방법을 제안합니다. 기존 방식들이 데이터의 복잡성을 측정하는 데 중점을 두었다면, 제안된 방법은 신호 자체의 구조를 분석하여 '의미 있는지'를 독립적으로 평가합니다.

- **Technical Details**: 논문에서는 신호 파형을 입력으로 받아 그것의 '의미 있음을' 점수로 출력하는 방법을 제시합니다. 이 방법은 입력의 연속된 부분을 클러스터링(cluster)하고 코드 길이를 설명 길이 최소화 기준으로 선정하여, 클러스터 라벨의 코드 길이를 '의미 깊음 점수'로 사용합니다. 이는 콜모고로프 복잡성(Kolmogorov complexity) 및 최소 설명 길이 원칙(MDL; Minimum Description Length)과 유사점을 가지며, 의미 있는 부분과 무의미한 부분을 구분하는 점에서 차별화됩니다.

- **Performance Highlights**: 제안된 방법은 인간의 여러 언어와 음성, 새 및 범고래 등의 동물 발성에 대해서는 높은 점수를 부여하며, 다양한 소스의 주변 잡음(ambient noise)에는 낮은 점수를 부여했습니다. 이는 기존의 복잡성 측정 방법들이 단순하거나 랜덤한 데이터에는 높고, 인간 음성에는 중간 정도의 점수를 부여하는 것과는 대조적입니다.



### Framework for Curating Speech Datasets and Evaluating ASR Systems: A Case Study for Polish (https://arxiv.org/abs/2408.00005)
Comments:
          Submitted to NeurIPS 2024 Datasets and Benchmarks Track

- **What's New**: 본 연구는 폴란드어 자동 음성 인식(ASR) 시스템의 포괄적인 비교를 수행한 첫 연구로, 총 24개의 공개된 음성 데이터셋을 정리하고 25개의 ASR 시스템 및 모델을 평가했습니다. 이로써 기존의 데이터셋 발견과 상호운용성(Interoperability) 문제를 해결하여 보다 체계적인 평가를 가능하게 했습니다.

- **Technical Details**: 연구팀은 키워드 기반 문헌 리뷰를 통해 관련 음성 데이터셋을 식별하고 문서화했습니다. 그 후, 다양한 음성 데이터셋을 수집하고 이를 표준화된 프로토콜에 따라 평가하는 프레임워크를 구축하였습니다. 이를 통해 다양한 출처의 읽기 및 자발적 발화 예시를 포함하는 벤치마크(bonus mark) 데이터셋을 구성하였습니다. 이 데이터셋은 공개적으로 제공되어 ASR 시스템의 평가 및 분석에 용이하도록 했습니다.

- **Performance Highlights**: 24개의 데이터셋과 10개의 상용 및 오픈 소스 ASR 시스템을 대상으로 600번의 시스템-모델-테스트 세트 평가를 수행했습니다. 이로 인해 시스템 간, 데이터셋 간, 그리고 연사 인구통계학적 특성 간의 성능 변동을 상세히 분석할 수 있었습니다. 평가 결과는 대시보드 형태로 공개되어, 연구 커뮤니티와 정보 공유 및 협력을 촉진하고 있습니다.



### Handling Numeric Expressions in Automatic Speech Recognition (https://arxiv.org/abs/2408.00004)
- **What's New**: 이 논문은 자동 음성 인식(ASR) 텍스트에서 숫자 표현의 적절한 형식을 지정하는 문제를 다룹니다. 숫자의 올바른 형식은 그 맥락에 따라 달라지기 때문에 이를 해결하는 것은 어려운 문제입니다. 특히, LLM(대형 언어 모델)과 TTS(Text-to-Speech) 모델을 활용하여 적응 데이터를 생성하는 접근법이 제시되었습니다.

- **Technical Details**: 논문은 연도, 타임스탬프, 통화 금액, 수량 등의 숫자 표현을 인식하고 형식화하는 두 가지 접근법(캐스케이드와 엔드 투 엔드)을 비교합니다. 엔드 투 엔드 접근법에서는 LLM과 TTS 모델을 활용하여 데이터 생성 전략을 사용했습니다. 훈련 데이터는 GPT-3.5 터보와 TTS 모델을 활용해 생성되었습니다. Whisper와 mbart 모델이 사용되었으며, 추가적으로 GPT-3.5, GPT-4도 텍스트 분할 모델로 비교되었습니다.

- **Performance Highlights**: 테스트 결과, LLM 기반 접근법은 포맷된 숫자 표현 인식에서 좋은 성능을 보였으며, 적응된 엔드 투 엔드 모델은 더 낮은 지연 시간과 추론 비용으로 경쟁력 있는 성능을 제공합니다. 특히, mbart 기반 모델이 ASR 모델 성능을 향상시키는 것으로 나타났습니다.



### ShieldGemma: Generative AI Content Moderation Based on Gemma (https://arxiv.org/abs/2407.21772)
- **What's New**: ShieldGemma는 Gemma2를 바탕으로 구축된 포괄적인 LLM 기반 안전 콘텐츠 검열 모델 모음입니다. 이 모델들은 주요 해악 유형(성적 명시적 내용, 위험한 콘텐츠, 괴롭힘, 증오 발언)에 대해 사용자 입력과 LLM 생성 출력 모두에서 강력하고 최첨단의 안전 위험 예측을 제공합니다.

- **Technical Details**: ShieldGemma는 2B에서 27B 파라미터 범위의 다양한 콘텐츠 검열 모델을 제안하며, 이는 다양한 애플리케이션 요구 사항에 최적화된 성능을 제공하도록 설계되었습니다. 새로운 LLM 기반 데이터 큐레이션 파이프라인을 도입하여 다양한 안전 작업에 적응할 수 있도록 하였습니다. 주로 합성 데이터를 기반으로 훈련된 모델에서도 강력한 일반화 성능을 입증했습니다.

- **Performance Highlights**: ShieldGemma는 기존 모델(Llama Guard와 비교해 10.8% AU-PRC 향상, WildCard보다 4.3% 향상)과 비교하여 우수한 성능을 보여줬습니다. 이를 통해 LLM 안전성을 진전시키고, 개발자들이 더 효과적인 콘텐츠 검열 솔루션을 만들 수 있도록 하는 귀중한 리소스를 제공하고 있습니다.



### Adaptive Retrieval-Augmented Generation for Conversational Systems (https://arxiv.org/abs/2407.21712)
Comments:
          12 pages, under review

- **What's New**: 최근 연구는 대형 언어 모델(LLM)이 대화 시스템에 통합되는 성공에도 불구하고, 외부 지식을 검색하여 응답을 보강하는 것이 효과적이라는 점을 강조했습니다. 이 연구에서는 모든 대화 턴마다 외부 지식이 필요한지에 관한 필요성을 조사했습니다. 그 결과, RAGate라는 gating model을 개발하여 대화의 컨텍스트와 관련 입력을 모델링함으로써 대화 시스템이 언제 외부 지식 보강이 필요한지를 예측할 수 있게 했습니다.

- **Technical Details**: RAGate는 LLM과 대화 시스템의 맥락을 바탕으로 현재 대화 상황에서 외부 지식이 필요한지 여부를 예측하는 binary knowledge gate 메커니즘입니다. 이를 위해 인간의 판단을 활용하여 학습을 진행합니다. 또한 주어진 Task-Oriented Dialogue (TOD) 시스템 데이터셋, KETOD를 사용하여 다양한 영역에서 실험을 진행했습니다. 이 시스템은 무조건적인 지식 보강이 응답의 불확실성과 헛소리(hallucination)를 증가시킬 가능성이 높다는 점을 발견했습니다.

- **Performance Highlights**: RAGate는 대화 시스템이 적절한 대화 턴에서 외부 지식을 효율적으로 사용하여 고품질의 응답을 생성하도록 합니다. 시스템의 불확실성 및 자신감 레벨을 모델링함으로써, 외부 지식의 항상 보강이 생성 불확실성과 헛소리의 위험을 크게 증가시킬 수 있음을 보여줍니다. RAGate을 적용함으로써, 시스템은 보다 자신 있고 정보가 풍부한 응답을 만들 수 있습니다. 나아가, 사용된 지식 조각의 관련성 수준에 따라 자신감 점수와 보강된 지식의 관련성 간의 긍정적인 상관관계를 관찰할 수 있습니다.



### Synth-Empathy: Towards High-Quality Synthetic Empathy Data (https://arxiv.org/abs/2407.21669)
Comments:
          arXiv admin note: text overlap with arXiv:2407.01937

- **What's New**: 최신 연구인 Synth-Empathy는 대형 언어 모델(LLMs)을 기반으로 한 새로운 데이터 생성 및 품질 관리 파이프라인을 소개합니다. 이는 고품질의 공감 데이터를 자동으로 생성하고 낮은 품질의 데이터를 버림으로써 공감적 응답 성능을 향상시킵니다. 이를 통해 여러 벤치마크에서 최첨단(SoTA) 성능을 달성했습니다.

- **Technical Details**: Synth-Empathy는 세 단계의 파이프라인을 제안합니다. 첫째, 프롬프트를 사용해 공감적 응답을 생성합니다. 둘째, 도메인 지식을 적용하여 품질을 선별합니다. 셋째, 다양성 선택 단계를 통해 추가적인 데이터 큐레이션을 수행합니다. 이렇게 큐레이션된 합성 데이터셋을 사용해 LLM을 미세 조정합니다.

- **Performance Highlights**: Synth-Empathy는 다양한 벤치마크에서 SoTA 성능을 달성했으며, 인간 평가 벤치마크에서도 최상의 성능을 입증했습니다. 이는 실용적인 응용 가능성을 높이며, 품질 높은 공감적 응답을 제공하는 모델을 개발할 수 있게 합니다. 또한 인간 노동 없이도 고품질 데이터를 얻는 것이 가능합니다.



### Defending Jailbreak Attack in VLMs via Cross-modality Information Detector (https://arxiv.org/abs/2407.21659)
Comments:
          12 pages, 9 figures

- **What's New**: 최신 연구는 VLM(Vision Language Model)이 'jailbreak' 공격에 취약하다는 점을 밝혔으며, 이를 방어하기 위해 다양한 기술이 개발되었다고 소개하고 있습니다. 이에 기반하여, 새로운 플러그 앤 플레이(plug-and-play) 방식의 'CIDER' 탐지기를 제안합니다. 이는 시각적 입력의 간섭을 감지하여 모델의 안전성을 높이는 것을 목표로 합니다.

- **Technical Details**: CIDER(Cross-modality Information DEtectoR)는 모델 구조 변경 없이 사용할 수 있는 탐지기로, 텍스트와 이미지 간의 교차 모달 유사성을 활용하여 'jailbreak' 공격을 감지합니다. 이 탐지기는 이미지 입력 전처리 단계에서 디노이저(denoiser)를 사용하여 텍스트와 이미지의 의미적 거리 변화를 계산하고, 이 변화를 기준으로 공격 여부를 판단합니다. 이는 추가적인 계산 비용 없이 효과적으로 작동합니다.

- **Performance Highlights**: CIDER는 기존의 방법들보다 더 높은 탐지 성공률과 낮은 계산 비용을 보여줍니다. 또한, white-box와 black-box VLM 모두에서 뛰어난 전이 성능을 나타내어 광범위한 공격 방법에 대해 효과적으로 대응할 수 있습니다.



### Towards Achieving Human Parity on End-to-end Simultaneous Speech Translation via LLM Agen (https://arxiv.org/abs/2407.21646)
Comments:
          Authors are listed in alphabetical order by last name. Demonstrations and human-annotated test sets are available at this https URL

- **What's New**: 이번 논문에서는 Cross Language Agent - Simultaneous Interpretation (CLASI)를 소개합니다. CLASI는 고품질의 사람과 유사한 동시 음성 번역 시스템입니다. 전문 번역가들이 사용하는 읽기-쓰기 전략을 데이터 기반으로 도입하여 번역 품질과 지연시간의 균형을 맞췄습니다. CLASI는 다중 모달 검색 모듈을 사용해 분야별 용어를 번역하는 데 필요한 정보를 획득하여 번역을 보강합니다.

- **Technical Details**: CLASI는 입력 오디오, 역사적 컨텍스트 및 검색된 정보를 고려하여 오류를 허용하는 번역을 생성할 수 있습니다. 이 시스템은 Human Evaluation Metric인 VIP(Valid Information Proportion)를 사용하여 평가됐으며, 이는 청취자에게 성공적으로 전달된 정보의 양을 측정합니다. CLASI는 중국어-영어와 영어-중국어 번역 방향에서 각각 81.3%와 78.0% VIP를 달성했습니다.

- **Performance Highlights**: 실험 결과 CLASI는 다른 시스템에 비해 큰 차이로 뛰어난 성능을 보였습니다. 상업용 및 오픈 소스 시스템이 35.4%와 41.6% VIP를 달성한 반면, CLASI는 각각 81.3%와 78.0% VIP를 기록했습니다. 더 어려운 데이터셋에서도 다른 시스템이 13% 이하의 VIP를 기록한 반면 CLASI는 70% VIP를 달성했습니다.



### Zero-Shot Cross-Domain Dialogue State Tracking via Dual Low-Rank Adaptation (https://arxiv.org/abs/2407.21633)
Comments:
          Accepted by ACL 2024

- **What's New**: 이번 논문에서는 Zero-shot 대화 상태 추적(Dialogue State Tracking, DST)을 위해 Dual Low-Rank Adaptation (DualLoRA)이라는 새로운 아키텍처를 제안합니다. 이 방식은 최소한의 추가 학습이나 라벨링 없이도 새롭고 미지의 도메인으로 대화 시스템을 신속하게 전환할 수 있도록 설계되었습니다. DualLoRA는 두 개의 Low-Rank Adaptation(LoRA) 컴포넌트를 통합하여 대화 문맥 처리와 프롬프트 최적화를 동시에 타겟팅합니다.

- **Technical Details**: 전통적인 방법론은 프롬프트를 입력 레이어에 통합하거나, 각 Transformer 레이어에 학습 가능한 변수를 추가하는 방식으로 진행됩니다. 하지만 이러한 방식은 학습 과정의 복잡도를 증가시키거나 추론 시간에 추가적인 지연을 초래할 수 있습니다. DualLoRA는 이러한 문제를 해결하기 위해 설계되었습니다. 이 방식은 Transformer 모델의 각 레이어에서 프롬프트의 영향을 지속적으로 반영하도록 하며, 추가적인 추론 시간 지연 없이도 효율적으로 통합 가능합니다.

- **Performance Highlights**: MultiWOZ와 SGD 데이터셋을 이용한 엄격한 평가 결과, DualLoRA는 제로샷 환경에서 기존의 베이스라인 방법을 능가하는 성능을 보였습니다. 다양한 도메인에서 Joint Goal Accuracy(JGA) 측정치가 향상되었음을 확인했습니다. 이는 새로운 도메인에서도 효과적으로 전이될 수 있음을 시사합니다.



### TAROT: Task-Oriented Authorship Obfuscation Using Policy Optimization Methods (https://arxiv.org/abs/2407.21630)
- **What's New**: 저자 위장 기술(Author Obfuscation)의 새로운 접근법인 TAROT(Task-Oriented Authorship Obfuscation Using Policy Optimization)를 제안합니다. 이 방법은 텍스트의 유용성을 보존하면서도 저자의 신원을 숨길 수 있게 합니다. 기존의 기술들은 주로 저자 식별 데이터를 일부만 수정하는 방식이었으나, TAROT는 전체 텍스트를 재생성하여 유용성을 최대화하면서도 프라이버시를 보장합니다.

- **Technical Details**: TAROT는 소형 언어 모델(small language models)을 활용하여 텍스트 재작성(rewriting)을 통해 저자 식별 신호를 제거하면서도 텍스트의 유용성을 보존하는 정책 최적화(policy optimization)를 사용합니다. 초기 모델은 텍스트 단순화 모델을 수퍼바이즈드 파인 튜닝(Supervised Fine-Tuning)과 정책 최적화(Policy Optimization) 기반 보상 모델을 결합해 학습합니다. TAROT-PPO와 TAROT-DPO의 두 가지 버전이 있으며, 각각 서로 다른 파인 튜닝 정책 최적화 알고리즘을 사용합니다.

- **Performance Highlights**: TAROT 모델은 영화 리뷰, 블로그 기사, 학술 논문 등의 세 가지 데이터셋에서 다양한 저자 식별 공격에 대한 실험을 통해 성과를 입증했습니다. 여러 데이터셋과 여러 작업을 목표로 하여 다양한 공격 시나리오에서도 유용성을 유지하면서 저자를 보호할 수 있음을 보여주었습니다.



### PMoE: Progressive Mixture of Experts with Asymmetric Transformer for Continual Learning (https://arxiv.org/abs/2407.21571)
- **What's New**: 이번 연구에서는 Large Language Models (LLMs)의 지속 학습에서 발생하는 기존 지식의 망각 문제를 해결하기 위해 PMoE(Progressive Mixture of Experts with Asymmetric Transformer)를 제안합니다. PMoE는 비대칭적 깊이 설계를 통해 얕은 레이어(shallow layers)는 일반 지식을, 깊은 레이어(deep layers)는 새로운 지식을 담당하도록 하여 망각을 최소화하고자 합니다.

- **Technical Details**: PMoE는 깊은 레이어에 전문가를 점진적으로 추가하고, 라우터(router)를 사용하여 새로운 지식을 적절한 전문가에게 효율적으로 할당합니다. 이 라우터는 깊은 레이어 옆에 배치되어 집계된 정보를 사용해 최적의 성능을 발휘합니다. PMoE는 TRACE 데이터셋과 일반 단어 이해 데이터셋에서 기존의 최첨단 방법보다 우수한 성능을 보였습니다.

- **Performance Highlights**: PMoE는 LoRA와 재생기반 리플레이 방법 및 기존 최첨단 방법보다 TRACE 벤치마크에서 뛰어난 성능을 제공합니다. 비대칭적 설계는 기존 지식을 유지하면서 새로운 지식을 효율적으로 획득하는 데 매우 효과적이며, 파라미터 효율성 면에서도 우수합니다.



### Generative Sentiment Analysis via Latent Category Distribution and Constrained Decoding (https://arxiv.org/abs/2407.21560)
- **What's New**: 이번 연구는 세밀한 감성 분석(fine-grained sentiment analysis)을 위한 생성적 감성 분석 모델을 도입합니다. 기존 모델들이 간과했던 카테고리 의미 포함(category semantic inclusion)과 중복(overlap) 문제를 해결하기 위해 잠재 카테고리 분포 변수(Latent Category Distribution, LCD)를 도입했습니다. 또한, 트라이 데이터 구조(trie data structure)와 제한적 디코딩(constrained decoding) 전략을 활용하여 구조적 패턴 지식을 활용했습니다.

- **Technical Details**: 연구에서 제안된 모델은 감성 사중추출(sentiment quadruple extraction) 과제를 생성적 프로세스로 취급하며, 텍스트와 카테고리 간의 관계 강도를 학습하기 위해 변분 오토인코더(Variational AutoEncoder, VAE)의 입력을 재구성함으로써 잠재 카테고리 분포 변수를 도입했습니다. 추가로, 제한적 디코딩 전략을 사용하여 디코딩 단계에서 검색 공간을 줄이고 시퀀스 생성 과정을 개선했습니다.

- **Performance Highlights**: Restaurant-ACOS와 Laptop-ACOS 데이터셋에서 제안된 모델이 기존의 기준(baseline) 모델에 비해 성능이 향상됨을 실험 결과로 입증했습니다. 또한, 애블레이션(관부) 실험을 통해 잠재 카테고리 분포와 제한적 디코딩 전략의 유효성과 기여도를 확인했습니다.



### Tracing Intricate Cues in Dialogue: Joint Graph Structure and Sentiment Dynamics for Multimodal Emotion Recognition (https://arxiv.org/abs/2407.21536)
Comments:
          Submitted

- **What's New**: 최근 논문에서는 이제까지의 감정 인식 모델들이 내재한 여러 가지 문제점을 해결하기 위해 'GraphSmile'이라는 새로운 접근법을 제안합니다. GraphSmile은 대화 내 감정의 미세한 변화를 추적하는 데 탁월한 성능을 보이는 멀티모달 감정 인식 및 분석 모델입니다.

- **Technical Details**: GraphSmile은 두 가지 주요 모듈, 즉 GSF(Graph Structure Fusion)와 SDP(Sentiment Dynamics Perception)로 구성됩니다. GSF는 그래프 구조를 활용하여 다양한 모달 사이의 감정적 의존성을 층별로 교대로 흡수하며, 모달 간의 충돌을 피하되 충분한 교차 모달 단서를 캡처합니다. SDP는 보조 작업으로, 발화 간 감정 변화를 명확히 도식화하여 감정적 변화를 인식하는 모델의 능력을 증진합니다.

- **Performance Highlights**: GraphSmile은 여러 벤치마크 테스트에서 기존 모델을 능가하는 성능을 입증했습니다. 특히, 복잡한 감정 및 감정 패턴을 효과적으로 처리할 수 있는 역량을 보여주었으며, MERC(Multimodal Emotion Recognition in Conversation)와 MSAC(Multimodal Sentiment Analysis in Conversation) 작업 모두에서 탁월한 성과를 나타냈습니다.



### Data Contamination Report from the 2024 CONDA Shared Task (https://arxiv.org/abs/2407.21530)
Comments:
this https URL

- **What's New**: 현재 사용 가능한 데이터셋과 모델에서 데이터 오염이 발생하는 사례를 수집하고 분석하는 첫 번째 워크샵인 '데이터 오염 워크샵(CONDA 2024)'이 개최되었습니다. 이 워크샵에서는 데이터 오염 문제를 이해하고 평가 결과를 왜곡시킬 수 있는 알려진 오염된 자원에서 결과를 보고하지 않도록 돕는 것을 목표로 하고 있습니다.

- **Technical Details**: 데이터 오염은 평가 데이터가 대규모 모델의 사전 학습 코퍼스에 포함될 때 발생합니다. 이번 워크샵에서는 GitHub 풀 요청을 통해 커뮤니티가 증거를 제출할 수 있는 구조화된 중앙 공공 데이터베이스를 제공합니다. 데이터베이스는 '데이터 기반 접근법'과 '모델 기반 접근법'으로 나뉘며, 각각 사전 학습 데이터와 모델의 출력을 분석하여 오염을 감지합니다.

- **Performance Highlights**: 이번 보고서에서는 23명의 기여자로부터 제출된 566개의 오염 사례를 수집하여 분석한 결과를 공개하였습니다. 이 데이터베이스는 계속해서 운영되며, 새로 나오는 데이터셋과 모델에 대한 오염 보고를 통해 업데이트될 예정입니다.



### Generative Expressive Conversational Speech Synthesis (https://arxiv.org/abs/2407.21491)
Comments:
          14 pages, 6 figures, 8 tables. Accepted by ACM MM 2024

- **What's New**: 이 논문에서는 대화형 음성 합성(Conversational Speech Synthesis, CSS)을 위한 새로운 접근 방식인 GPT-Talker를 제안합니다. 기존 방식이 복잡한 네트워크 아키텍처와 세밀한 최적화를 요구하는 반면, GPT-Talker는 멀티턴 대화(history)를 이산 토큰 시퀀스로 변환해 통합 사용자-에이전트 대화(context)를 형성합니다. 또한 자연스럽고 즉흥적인 스타일의 대화 음성을 포함한 대규모 데이터셋 'NCSSD'도 소개합니다.

- **Technical Details**: GPT-Talker 시스템은 멀티턴 대화 내역을 이산 토큰 시퀀스(discrete token sequence)로 변환하고, 이를 GPT를 활용해 예측하여 에이전트의 응답 시퀀스를 생성합니다. 이후, conversation-enriched VITS 모듈을 통해 표현력 있는 대화 음성을 합성합니다. 새롭게 제안된 NCSSD 데이터셋은 자연스럽게 녹음된 즉흥 대화 음성과 TV 쇼에서 추출된 대화를 포함하며, 총 236시간 길이로 구성된 한국어와 영어 데이터셋입니다.

- **Performance Highlights**: 포괄적인 실험 결과, 우리의 GPT-Talker 모델이 기존 최첨단 CSS 시스템보다 자연스러움과 표현력 측면에서 뛰어나다는 것이 주관적, 객관적 평가로 입증되었습니다. 코드, 데이터셋, 프리트레인 모델은 공개되어 있으며, 누구나 접근 가능합니다.



### Maverick: Efficient and Accurate Coreference Resolution Defying Recent Trends (https://arxiv.org/abs/2407.21489)
Comments:
          Accepted at main conference of ACL 2024. 15 pages

- **What's New**: 최근 자연어 처리(Natural Language Processing) 주요 과업에서 고성능을 구현하기 위해 대규모 autoregressive generative 모델이 주로 사용되고 있습니다. 이러한 경향 속에서, Coreference Resolution 태스크도 예외는 아니었습니다. 그러나 이번에 발표된 논문에서는, Maverick이라는 새로운 시스템을 소개합니다. 이 시스템은 적은 자원 내에서 최고 성능을 자랑하는 Coreference Resolution을 구현하도록 설계되었습니다. 약 500 million 파라미터로, 최대 13 billion 파라미터 모델보다도 높은 성능을 보였습니다.

- **Technical Details**: Maverick 시스템은 단순하지만 정교하게 설계된 파이프라인을 채택해, 학문적 예산 내에서 최고 성능을 실현할 수 있도록 합니다. CoNLL-2012 벤치마크에서 state-of-the-art 성능을 달성하며, 최대 이전 시스템의 0.006배 메모리로 훈련이 가능하고, 170배 빠른 추론속도를 기록했습니다. 다양한 실험을 통해 데이터 부족, 긴 문서, 비도메인 데이터 등에서도 견고한 성능을 보였음을 입증했습니다.

- **Performance Highlights**: Maverick은 less than 13 billion 파라미터를 사용하는 모델보다 우수한 성능을 보여주며, 대표적으로 CoNLL-2012 벤치마크에서 최고 성능을 기록했습니다. 메모리 자원 측면에서는 최대 0.006배 적게 필요했고, 추론 속도는최대 170배 빠르게 나타났습니다. 다양한 조건에서의 실험을 통해 Maverick의 강건함과 효율성을 강조했습니다. 추가적으로, 연구 목적으로 코드와 모델을 공개했습니다.



### On the Problem of Text-To-Speech Model Selection for Synthetic Data Generation in Automatic Speech Recognition (https://arxiv.org/abs/2407.21476)
Comments:
          Accepted at the SynData4GenAI 2024 workshop

- **What's New**: 이번 연구는 다섯 가지 다른 TTS 디코더 아키텍처를 비교하여 CTC 기반 음성 인식 훈련에 미치는 영향을 분석했습니다. 연구 결과, auto-regressive 디코딩이 non-autoregressive 디코딩보다 데이터 생성 측면에서 더 우수한 성능을 보임을 발견했습니다.

- **Technical Details**: 본 연구에서는 Transformer, LSTM, Glow-TTS, Grad-TTS 아키텍처를 기반으로 한 TTS 시스템을 비교했습니다. 우리는 동일한 Transformer 기반 인코더와 convolution 기반 지속성 예측 네트워크를 사용하여 디코더만 변경한 시스템을 구축했습니다. 디코더는 Direct Prediction, Flow, Diffusion 세 가지 방식으로 구분되었습니다.

- **Performance Highlights**: 연구 결과, auto-regressive 디코딩 방식을 사용하는 LSTM 기반 TTS 시스템이 non-autoregressive Transformer 기반 시스템보다 더 나은 성능을 보였습니다. 또한, 기존 평가 지표인 NISQA MOS와 intelligibility가 ASR 성능과 뚜렷한 상관관계를 보이지 않음을 발견했습니다.



### Improving Faithfulness of Large Language Models in Summarization via Sliding Generation and Self-Consistency (https://arxiv.org/abs/2407.21443)
Comments:
          Long paper accepted at LREC-COLING 2024 (oral)

- **What's New**: 최근 연구에서 제안한 SliSum이라는 새로운 요약 생성 전략입니다. 이 전략은 슬라이딩 윈도우(sliding windows)와 자기 일관성(self-consistency) 개념을 활용하여, LLMs(Large Language Models)의 요약 생성 시 사실성을 향상시키는 방법입니다. 이 방법은 특히 긴 문서 요약에서 나타나는 LLMs의 환각(hallucination) 문제를 줄이는 데 효과적입니다.

- **Technical Details**: SliSum은 세 가지 주요 단계로 요약을 생성합니다. 첫 번째 단계는 슬라이딩 생성(Sliding Generation)으로, 문서를 겹치는 윈도우로 나눈 후 각 윈도우에 대해 '로컬 요약(local summaries)'을 생성합니다. 두 번째 단계는 필터링(Filtration)으로, 자기 일관성 원칙에 따라 더 자주 생성된 문장은 더 신뢰할 수 있다고 가정하고 중요하지 않은 내용과 불일치 내용을 제거합니다. 마지막 단계는 집계(Aggregation)로, 로컬 요약에서 충돌이 없는 문장들을 다수결 법칙으로 선정하고 이를 결합하여 최종 요약을 만듭니다.

- **Performance Highlights**: SliSum은 CNN/DM과 XSum 같은 단문 뉴스 데이터셋뿐 아니라, arXiv와 PubMed 같은 장문 과학 논문 데이터셋에서도 GPT-3.5, Claude-2, 그리고 LLaMA-2-13B 모델의 요약의 사실성을 크게 향상시켰습니다. 또한, 유창성과 정보성을 크게 훼손하지 않으면서도 성능 향상을 달성하였습니다. 추가적인 데이터나 모델 훈련이 없이도 이러한 성과를 보였습니다.

- **Research Implications**: SliSum은 LLMs가 전체 문서를 좀 더 공정하고 충실하게 처리하도록 하여 요약의 사실성을 높입니다. 이 방법은 요약 생성에서 LLMs의 환각 문제를 줄이는 데 중요한 기여를 할 수 있어, 다양한 텍스트 길이와 스타일에 적용 가능합니다. 이는 요약 생성 분야에서 새로운 방향을 제시하며, 미래의 연구 개발에 중요한 참고자료가 될 수 있습니다.



### QuestGen: Effectiveness of Question Generation Methods for Fact-Checking Applications (https://arxiv.org/abs/2407.21441)
Comments:
          Accepted in CIKM 2024 as a short paper 4 pages and 1 page references. Fixed typo in author name

- **What's New**: 이번 연구는 질문 분해 기술을 자동화하여 팩트체크의 효율성을 높이는 방법을 제안합니다. 질문 생성 과제를 위해 작은 생성 모델을 미세 조정한 결과, 더 큰 언어 모델(LLM)을 능가했음을 보여줍니다. 일부 경우에는 자동으로 생성된 질문이 사람의 질문보다 더 효과적이라는 결과도 나왔습니다.

- **Technical Details**: 팩트체크 프레임워크는 크게 (1) 검토할 만한 주장 식별, (2) 지지 또는 반박 증거를 찾기 위한 웹 검색, (3) 수집된 증거를 바탕으로 주장의 진위 평가의 3단계로 구성됩니다. 이 연구는 질문 생성 기법을 적용하여 마지막 두 단계를 개선하는 데 초점을 맞추고 있습니다. 작은 생성 모델(Small Language Models, SLM)과 대형 언어 모델(Large Language Models, LLM)을 비교했으며, 핵심적인 매개변수로 건립된 새로운 데이터셋을 활용했습니다.

- **Performance Highlights**: 실험 결과, 미세 조정된 작은 생성 모델이 질문 생성 성능에서 대형 언어 모델보다 최대 8% 더 잘 수행하는 것으로 나타났습니다. 또한, 기계 생성 질문을 통한 증거 검색이 사람 작성 질문보다 더 효과적일 수 있다는 점을 확인했습니다.



### Cost-Effective Hallucination Detection for LLMs (https://arxiv.org/abs/2407.21424)
- **What's New**: 이번 연구는 대형 언어 모델(Large Language Models, LLMs)의 생산 환경에서 발생할 수 있는 'hallucination' (환각) 문제를 해결하기 위한 후처리 감지 프레임워크를 제안합니다. 여기에는 생성된 답변이 환각일 가능성을 나타내는 신뢰도 점수를 생성하고, 이를 입력 및 후보 응답의 속성에 조건화하여 보정하는 과정이 포함됩니다. 최종적으로, 보정된 점수를 기준으로 환각을 감지합니다.

- **Technical Details**: 연구팀은 질문 응답, 사실 검증, 요약 작업을 포함한 다양한 데이터셋에서 최첨단 점수 방법을 벤치마킹했습니다. 다양한 LLM을 사용하여 성능을 종합적으로 평가한 결과, 개별 점수 방법은 모든 상황에서 최적의 성능을 발휘하지 못한다는 결론에 도달했습니다. 이에 따라, 여러 점수를 결합하여 더 나은 성능을 내는 Multi-scoring 프레임워크를 제안했습니다. 또한, 비용 효율적인 Multi-scoring 방법도 도입하여, 더 높은 비용을 들이는 감지 방법보다도 더 우수한 성능을 발휘할 수 있음을 입증했습니다.

- **Performance Highlights**: 연구 결과, 다중 점수 방법을 사용하여 환각 감지 성능이 크게 향상되었으며, 비용 효율적인 Multi-scoring 방법은 높은 성능을 유지하면서도 계산 비용을 크게 절감할 수 있었습니다. 이는 현실적인 제약 조건을 가진 실제 응용 프로그램에서 중요한 의사결정을 지원할 수 있는 잠재력을 보여줍니다.



### Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models (https://arxiv.org/abs/2407.21417)
Comments:
          preprint

- **What's New**: 최근 연구에서는 언어 모델(LMs)을 인간의 지시에 따라 행동하도록 훈련하는 과정에서 지시 따르기와 정합성 간의 트레이드오프가 발생함을 밝혀냈습니다. 이 연구에서는 지시 따르기 데이터셋으로 LLaMA-7B를 파인튜닝하면 정합성이 떨어지고, 반대로 맥락 의존적인 과제에 최적화하면 Vicuna-7B가 지시를 따르는 능력이 저하됨을 보여줍니다. 이를 해결하기 위해 Rejection Sampling for Continued Self-instruction Tuning(ReSet)라는 기법을 제안하였습니다.

- **Technical Details**: 이 연구는 ReSet라는 간단하면서도 효과적인 방법을 제안하였습니다. 이 방법은 언어 모델이 생성한 데이터를 외부 심판이 평가하여 높은 점수를 받은 생성물을 이용해 모델을 재훈련시킵니다. 특히, ReSet는 high-quality 작은 데이터셋(기존의 1/3 크기)으로 더 나은 성능을 나타냈습니다. 이는 다중 작업 학습(Multi-task Learning, MTL) 데이터 믹싱 기법으로도 충분히 해결되지 않는 문제에 대한 대안을 제공합니다.

- **Performance Highlights**: 실험 결과 ReSet를 사용하여 단일 반복(iteration)과 8,000개의 추가 파인튜닝 예제로 훈련한 언어 모델은 정합성 점수가 MTL 기준 대비 최대 18.8% 향상되었습니다. 더 적은 양의 고품질 데이터를 사용해도 정합성 측면에서 최대 31.3% 개선된 결과를 보였습니다. 또한, 모델의 지시 따르기 점수도 유지되는 것을 확인하였습니다.



### GEGA: Graph Convolutional Networks and Evidence Retrieval Guided Attention for Enhanced Document-level Relation Extraction (https://arxiv.org/abs/2407.21384)
- **What's New**: 새로운 문서 레벨 관계 추출(Document-level Relation Extraction, DocRE) 모델인 GEGA가 제안되었습니다. 이 모델은 그래프 신경망(Graph Neural Networks)을 활용하여 문서 내 증거 문장(evidence sentences)에 주의를 기울이는 방법을 제시하며, 멀티 스케일 표현 집계를 통해 증거 추출을 향상시킵니다.

- **Technical Details**: GEGA 모델은 다음과 같은 기술적 요소를 포함합니다: 첫째, 그래프 구조와 Transformer를 결합하여 문서 내 관계 엔티티 쌍과 관련된 증거 문장을 추출합니다. 둘째, 다중 가중치 행렬을 구축하여 증거 문장에 대한 주의 할당을 안내합니다. 마지막으로, 복잡한 교차 관계 추출을 개선하기 위해 다중 스케일 표현 집계를 수행합니다. 이 모델은 완전 지도 학습(fully supervised)과 약 지도 학습(weakly supervised) 설정 아래서도 훈련될 수 있습니다.

- **Performance Highlights**: GEGA 모델은 DocRED, Re-DocRED, Revisit-DocRED 세 가지 주로 사용되는 벤치마크 데이터셋에서 기존의 SOTA 모델에 비해 전반적인 성능 향상을 달성하였습니다. 이로 인해 문서 레벨 관계 추출의 새 표준(SOTA)을 달성하게 되었습니다.



### Performance of Recent Large Language Models for a Low-Resourced Languag (https://arxiv.org/abs/2407.21330)
- **What's New**: 지난 해에 비해 대형 언어 모델(LLMs, Large Language Models)에서 상당한 발전이 있었습니다. GPT와 Llama의 새로운 버전뿐만 아니라 다양한 새로운 LLM이 소개되었습니다. 일부는 오픈 모델로 다운로드 및 수정이 가능합니다. 다중언어 지원 LLM은 이미 사용 가능했지만, 자원이 적은 언어(저자원 언어)인 신할라어(Sinhala)에서는 성능이 좋지 않았습니다.

- **Technical Details**: 저자들은 최근 4개의 LLM을 신할라어로 직접 테스트하고, 영어로 번역한 후 다시 신할라어로 번역하는 방식으로 성능을 평가했습니다. 또한, 소량의 데이터로 이러한 모델을 파인튜닝(fine-tuning)하여 성능 개선 가능성도 알아보았습니다.

- **Performance Highlights**: Claude와 GPT-4o는 기본 상태에서 잘 작동하며, 이전 버전보다 훨씬 좋은 성능을 보였습니다. Llama와 Mistral은 초기 성능이 저조하지만, 파인튜닝을 통해 성능 향상의 가능성을 보였습니다.



### Beyond Silent Letters: Amplifying LLMs in Emotion Recognition with Vocal Nuances (https://arxiv.org/abs/2407.21315)
- **What's New**: 본 연구는 대형 언어 모델(LLMs)을 이용한 음성 감정 인식에 대한 혁신적인 접근 방식을 소개합니다. 본 연구는 LLM이 직접 오디오 입력을 처리할 수 없는 한계를 해결하기 위해 음성 특징을 자연어 설명으로 번역하는 방법을 제안합니다. 이러한 설명은 텍스트 프롬프트에 통합되어, LLM을 아키텍처 변경 없이 멀티모달 감정 분석을 수행할 수 있게 합니다.

- **Technical Details**: 이 방법은 음성 특징을 자연 언어 설명으로 변환하고 이를 텍스트 프롬프트에 통합하여 LLM이 음성 기반 감정 분석을 수행할 수 있도록 합니다. 주요 구성 요소는 다음과 같습니다: 1) Instruction: LLM을 감정 분석 전문가로 포지셔닝, 2) Context: 대화 배경 제공, 3) Speech Descriptions: 오디오 신호를 자연어로 번역하여 음성 특성을 설명, 4) Question: 특정 발언에 대한 감정 레이블 선택 과제 제시.

- **Performance Highlights**: IEMOCAP 및 MELD 데이터셋을 사용한 평가에서, 본 연구 방법은 감정 인식 정확도에서 상당한 개선을 보여주었습니다. IEMOCAP 데이터셋의 가중치 F1 점수에서 2% 포인트 증가(70.111%에서 72.596%)가 나타났습니다. 다양한 LLM 아키텍처와 특징 표현의 효과를 비교한 결과, 고품질 오디오 데이터에서 특히 높은 성능을 보였습니다.



### Model Attribution in Machine-Generated Disinformation: A Domain Generalization Approach with Supervised Contrastive Learning (https://arxiv.org/abs/2407.21264)
Comments:
          10 pages, 2 figures, accepted at DSAA 2024

- **What's New**: 이 연구는 기계 생성 허위 정보(model attribution for machine-generated disinformation)를 소스 모델에 속성화하는 문제를 여러 도메인에서 일반화(domain generalization)하는 방법으로 접근합니다. 각 프롬프트 방법(prompting method)를 독립된 도메인으로 보고, 이에 대해 일관되게 작동할 모델을 제시합니다.

- **Technical Details**: 이 논문에서는 Supervised Contrastive Learning (SCL)을 사용하여 텍스트 분류를 수행하는 새로운 접근법을 제안합니다. 이 방법은 동일한 클래스의 인스턴스 간에는 가까이, 다른 클래스의 인스턴스 간에는 멀리 있도록 문서의 표현을 조정함으로써 모델의 로버스트성을 강화합니다. 이러한 특징 추출 방법은 도메인 특이(non domain-specific) 속성을 학습하여 다양한 프롬프트 방법에 일관되게 대처할 수 있도록 합니다.

- **Performance Highlights**: 본 모델은 `open-ended`, `rewriting`, `paraphrasing`의 프롬프트 방법과 세 가지 최첨단 대형 언어 모델(large language models; LLMs)인 `LLaMA-2`, `ChatGPT`, `Vicuna`를 대상으로 실험하여, 다양한 데이터셋에 걸쳐 최첨단 성능(state-of-the-art performance)를 입증했습니다.



### Adaptive Pre-training Data Detection for Large Language Models via Surprising Tokens (https://arxiv.org/abs/2407.21248)
- **What's New**: 이번 논문에서는 적응형 사전 훈련 데이터 탐지 방법을 제안합니다. 현재의 탐지 솔루션은 LLM의 verbatim(정확히 기억하는) 특성을 이용하여 Membership Inference Attacks (MIAs)에 의존하지만, 이러한 의존성에는 많은 도전 과제가 있습니다. 우리 방법은 이러한 의존성을 줄이며 효과적으로 식별을 증대시킵니다. 특히, 주어진 입력의 놀라운 토큰(surprising tokens)을 적응적으로 찾아냅니다.

- **Technical Details**: 우리의 방법은 정보 이론의 Shannon Entropy를 바탕으로 놀라운 토큰을 식별합니다. 놀라운 토큰은 확률 분포의 엔트로피가 낮고 동시에 실제 정답 토큰의 확률도 낮은 경우를 의미합니다. 이러한 토큰의 예측 확률을 이용해 데이터 탐지를 수행하며, 이는 사전 훈련 데이터 코퍼스나 추가적인 훈련 없이도 가능합니다.

- **Performance Highlights**: 다양한 벤치마크와 모델에서 기존 방법들에 비해 일관되게 성능을 개선하였으며, 최대 29.5% 향상을 기록하였습니다. 또한 새로운 벤치마크인 Dolma-Book을 도입하여 다양한 텍스트 위치에서의 탐지 성능을 평가했습니다.



### Decomposed Prompting to Answer Questions on a Course Discussion Board (https://arxiv.org/abs/2407.21170)
Comments:
          6 pages. Published at International Conference on Artificial Intelligence in Education 2023. Code repository: this https URL

- **What's New**: 이 논문에서는 'decomposed prompting(분해된 프롬프트)' 기법을 사용하여 강의 토론 게시판에서 학생 질문을 분류하고 답변하는 시스템을 제안하고 평가했습니다. 시스템은 대형 언어 모델(LLM)을 사용하여 질문을 개념적, 과제, 물류, 그리고 답변 불가 유형으로 분류합니다. 이 과정을 통해 각 유형에 맞는 다양한 답변 전략을 사용할 수 있습니다. 이러한 접근 방식을 통해 강의 질문의 81% 정확도로 분류가 가능함을 보여주었습니다.

- **Technical Details**: 분해된 프롬프트(decomposed prompting)는 복잡한 문제를 더 작은 하위 작업으로 나누고, 각 하위 작업을 LLM 프롬프트를 사용하여 해결하는 기법입니다. 이 논문에서는 질문 분류와 질문 답변으로 구성된 전문가의 혼합(Mixture of Experts) 디자인을 채택했습니다. 예를 들어, 개념적 질문(conceptual questions)은 특수한 맥락이 필요하지 않지만, 과제와 물류 질문(homework and logistics questions)은 각 과제 또는 강의 계획서의 관련 섹션을 포함해야 합니다.

- **Performance Highlights**: 72개의 역사적 학생 질문을 기반으로 시스템을 평가한 결과, 질문 분류 시스템이 81%의 정확도를 달성했습니다. 추가적으로 추운기(Zero-shot) 예제가 포함된 프롬프트와 몇 가지 유형 레이블을 테스트한 결과, 31개의 예제를 사용했을 때 가장 높은 분류 정확도를 보였습니다. 개념적 질문에 대한 답변 생성 시, 코사인 유사도, ROUGE 점수, Perplexity와 같은 지표로 평가하여 성능을 측정했으며, 이러한 질문에서는 모델의 성능이 좋았습니다.



### Event-Arguments Extraction Corpus and Modeling using BERT for Arabic (https://arxiv.org/abs/2407.21153)
- **What's New**: 새로운 논문에서는 아랍어에 대한 이벤트-인수 추출(task)을 위한 새로운 코퍼스(WojoodHadath)를 소개하며, 이를 통해 이벤트와 관련된 에이전트(agent), 위치(location), 날짜(date) 등의 인수들을 주석했습니다. 또한, BERT 기반의 새로운 이벤트 관계 추출 방식을 제안하고, 이를 텍스트 엔테일먼트(text entailment) 문제로 다루었습니다. 이 방법은 94.01%의 F1-score를 달성했습니다.

- **Technical Details**: 이번 연구에서는 Wojood 코퍼스를 확장하여 55만 토큰으로 구성된 WojoodHadath 코퍼스를 개발하고, 이벤트 관련 인수들을 주석했습니다. 주석 작업의 일관성을 평가한 결과, Kappa 점수는 82.23%, F1-score는 87.2%로 나타났습니다. BERT를 이용한 이벤트-인수 추출 방법을 제안하며, 이는 자연언어추론(NLI) 문제로 프레이밍되어 높은 성능을 보였습니다.

- **Performance Highlights**: 제안된 BERT 기반 이벤트 관계 추출 방법은 F1-score 94.01%를 기록했으며, 추가적으로 수집한 8만 토큰의 도메인 외 코퍼스(TestNLI)에서도 F1-score 83.59%를 달성하여 일반화 성능이 입증되었습니다. 또한, 제안된 시스템은 기존의 SinaTools 도구의 일환으로 구현되었으며, 모든 데이터셋은 공개되어 있습니다.



### Enhancing Semantic Similarity Understanding in Arabic NLP with Nested Embedding Learning (https://arxiv.org/abs/2407.21139)
- **What's New**: 이번 연구는 Matryoshka Embedding Learning을 통해 아랍어 중첩 임베딩 모델을 훈련하는 새로운 프레임워크를 제시합니다. 다양한 문장 유사도 데이터셋을 아랍어로 번역하여 이 모델들을 다방면으로 평가할 수 있는 포괄적인 프레임워크를 제공합니다.

- **Technical Details**: Matryoshka Representation Learning (MRL)은 점차적으로 더 높은 출력 차원을 가지는 임베딩을 생성하는 텍스트 임베딩 모델로, 입력 텍스트를 더 많은 값으로 표현합니다. 아랍어 자연어 추론 데이터셋에 대해 훈련된 중첩 임베딩 모델들이 다양한 유사성 지표를 사용하여 평가되었습니다. 이러한 지표에는 cos한 유사성, 맨해튼 거리, 유클리드 거리, 및 도트 제품 유사성이 포함됩니다.

- **Performance Highlights**: Matryoshka 임베딩 모델은 아랍어의 고유한 의미론적 미묘함을 포착하는 데 탁월한 성능을 보였으며, 전통적인 모델보다 다양한 유사성 지표에서 최대 20-25% 향상된 성과를 보여주었습니다. 이는 언어별 훈련의 효과와 Matryoshka 모델이 아랍어 NLP 작업에서 문장의 의미적 유사성 향상에 미칠 잠재력을 강조합니다.



### Entropy, Thermodynamics and the Geometrization of the Language Mod (https://arxiv.org/abs/2407.21092)
Comments:
          18 pages

- **What's New**: 이번 논문에서는 순수 수학과 이론 물리학이 언어 모델 연구에 어떻게 적용될 수 있는지 논의합니다. 집합론(세트 이론)과 해석학을 사용하여 언어 모델의 수학적으로 엄밀한 정의를 공식화하고, 언어 모델의 분포 모듈리 공간(moduli space of distributions) 개념을 도입합니다.

- **Technical Details**: 이 논문은 함수 해석학과 위상수학을 활용하여 일반화된 분포가설(distributional hypothesis)를 공식화합니다. 또한 언어 모델과 관련된 엔트로피 함수(entropy function)를 정의하여 언어에서 많은 흥미로운 현상들을 이해할 수 있게 해줍니다. 엔트로피 함수의 영점(zero points)과 엔트로피가 0에 가까운 점들이 LLM이 지능적인 언어 모델을 근사화하는 데 있어 주요 장애물이라고 주장합니다.

- **Performance Highlights**: 엔트로피 함수(entropy function)를 사용하여 AGI에 관한 가설을 공식화하고, 열역학을 통해 언어 모델의 개념을 즉시 해석할 수 있음을 보여줍니다. 특히, 언어 모델의 분배 함수(partition function), 내부 에너지(internal energy), 자유 에너지(free energy) 개념을 정의하여 언어 모델의 작동 원리에 대한 통찰을 제공합니다.



### Accelerating Large Language Model Inference with Self-Supervised Early Exits (https://arxiv.org/abs/2407.21082)
- **What's New**: 우리의 연구는 대형 사전 훈련된 언어 모델(LLMs)의 추론을 가속화하기 위한 새로운 기법을 소개합니다. 이 방법은 추론 중 조기 종료를 도입함으로써 달성됩니다. 기존의 대규모 언어 모델들은 다양한 응용 분야에서 사용되지만, 그들의 연산 요구는 상당히 큽니다. 그러나 토큰 복잡도의 고유한 변동성을 활용하여 선택적 가속화를 가능하게 합니다.

- **Technical Details**: 우리는 기존의 트랜스포머 레이어 위에 'early exit heads'(조기 종료 헤드)를 통합하여 특정 종료 조건을 설정할 수 있는 방안을 제안합니다. 이러한 헤드는 모델의 자체 예측을 학습 데이터로 사용하여 자가 지도 학습 방식으로 훈련됩니다. 이를 통해 추가적인 주석 데이터가 필요 없게 됩니다. 신뢰도 메트릭(confidence metric)은 교정 세트를 사용하여 확립되며, 이는 원하는 수준의 정확도를 보장하면서 신뢰도가 미리 설정된 임계값을 초과할 때 조기 종료를 가능하게 합니다.

- **Performance Highlights**: 우리의 방법은 원래의 정확도를 유지하면서 특정 작업에서의 연산 시간을 줄입니다. 이는 광범위한 재훈련 없이 사전 훈련된 LLM의 기존 지식을 활용함으로써 달성됩니다. 이러한 가볍고 모듈화된 수정은 실시간 언어 처리와 같이 자원이 제한된 환경에서도 LLM의 실용성을 크게 향상시킬 수 있는 잠재력을 가지고 있습니다.



### Genetic Instruct: Scaling up Synthetic Generation of Coding Instructions for Large Language Models (https://arxiv.org/abs/2407.21077)
- **What's New**: 이번 논문에서는 대규모 언어 모델(LLMs)의 코드 생성 능력을 향상시키기 위해 Genetic-Instruct라는 새로운 방법을 소개합니다. 이 알고리즘은 진화 알고리즘을 모방하여 소수의 초기 샘플로부터 많은 수의 합성 명령어를 생성합니다. 이를 통해 코드 생성 작업에서 LLM의 정밀도가 크게 향상되었음을 보여줍니다.

- **Technical Details**: Genetic-Instruct는 진화 알고리즘에서 영감을 받아 '교차(crossover)'와 '돌연변이(mutation)'라는 두 가지 주요 진화적 연산을 사용하여 합성 명령어를 생성합니다. 초기 고품질 샘플 세트를 바탕으로 LLM을 사용하여 새로운 명령어와 이에 해당하는 코드 출력물을 생성합니다. 생성된 샘플의 품질 평가를 위해 또 다른 LLM을 활용하여 올바르고 고품질의 샘플만 통과시킵니다. 이를 반복하여 최종 목표 샘플 수를 달성합니다.

- **Performance Highlights**: 합성된 데이터셋을 사용하여 여러 오픈소스 소프트웨어(OSS) LLM을 미세 조정한 결과, 기존 알고리즘들보다 코드 생성 정확도가 크게 향상된 것으로 나타났습니다. 특히, 코드 생성 벤치마크에서 우수한 성능을 보여줍니다.



### Occam's Razor and Bender and Koller's Octopus (https://arxiv.org/abs/2407.21070)
Comments:
          In ACL 2024 Workshop on Teaching NLP (TeachNLP 2024)

- **What's New**: 이번 연구는 2020년 ACL에서 Bender와 Koller가 발표한 'Climbing toward NLU: on meaning form, and understanding in the age of data' 논문을 분석하고 비판적으로 탐구하는 학습자료를 제공합니다. 학생들이 논문의 주장과 이에 대한 반대 주장에 대해 스스로 결론을 내릴 수 있도록 돕습니다.

- **Technical Details**: 연구는 Bender와 Koller의 논문에서 사용된 예시를 중심으로 진행됩니다. 예를 들어, 통신의 형태만을 이해하는 존재(지능형 문어)가 데이터 기반의 텍스트를 해석하는 대형 언어 모델(LLM)과 유사하다는 주장을 다룹니다. 또한, 학습 자료에서는 이러한 LLM이 과연 자연어를 진정으로 이해할 수 있는지에 대한 논의를 포함합니다.

- **Performance Highlights**: 학생들은 Bender와 Koller의 논문을 읽고, 해당 논의의 반대 주장을 다룹니다. 추가로, 이해도가 높은 질문을 통해 스스로 결론을 도출할 수 있도록 유도합니다. 예를 들어, 문어가 빛과 어둠에 따른 메시지 내용을 관찰하여 무엇을 추론할 수 있는지 등에 관한 질문을 제시합니다.

- **Materials**: 학습자료로 다음과 같은 링크들이 제공됩니다: 슬라이드 (https://github.com/guerzh/octopus), 동영상 강의 (https://youtu.be/6QVjGF_J7I0)



### Exploring Genre and Success Classification through Song Lyrics using DistilBERT: A Fun NLP Ventur (https://arxiv.org/abs/2407.21068)
- **What's New**: 이 논문은 노래 가사를 분석하여 장르 분류, 조회수 기반 성공 예측, 대략적인 발매 연도 예측을 시도한 자연어 처리(NLP) 접근법을 제시합니다. DistilBERT 모델을 사용한 장르 분류는 65% 정확도를, BERT 임베딩을 활용한 성공 예측은 79%의 정확도를 보였으며, 서포트 벡터 머신(SVM)이 발매 연도 예측에서 가장 낮은 평균 제곱근 오차(RMSE)인 14.18을 기록했습니다.

- **Technical Details**: 노래 가사 분류를 위해 DistilBERT 토크나이저와 사전 훈련된 'distilbert-base-uncased' 모델을 사용하였고, 이를 통해 특정 장르와 성공 여부를 예측했습니다. 발매 연도 예측에서는 노래 가사로부터 BERT 임베딩을 추출하였으며, SVM이 가장 낮은 RMSE를 기록했습니다. 기존의 기계학습 방법론보다 NLP 모델을 활용하여 더 높은 정확도와 신뢰성을 목표로 하였습니다.

- **Performance Highlights**: 장르 분류에서 65%의 정확도, 조회수 기반 성공 예측에서 79%의 정확도를 기록했으며, 발매 연도 예측에서는 가장 낮은 RMSE인 14.18을 기록한 것이 주요 성과로 소개되었습니다.



### ELP-Adapters: Parameter Efficient Adapter Tuning for Various Speech Processing Tasks (https://arxiv.org/abs/2407.21066)
- **What's New**: 본 논문에서는 ELP-adapter tuning을 제안합니다. 이는 파라미터 효율적인 미세조정을 위해 3가지 어댑터를 사용하는 새로운 방법입니다. 구체적으로, E-adapter(encoder adapter), L-adapter(layer adapter), P-adapter(prompt adapter)로 구성되어 있습니다. 이를 통해 다양한 음성 처리 작업에 맞게 모델을 빠르게 적응시킬 수 있습니다.

- **Technical Details**: E-adapter는 Transformer 기반 인코더 레이어에 통합되어 세밀한 음성 표현을 학습하며, 이는 음성 인식에 효과적입니다. L-adapter는 각 인코더 레이어에서 다운스트림(head)으로의 경로를 만들어 비언어적 특징을 추출하며, 이는 화자 검증과 감정 인식 작업에 유용합니다. P-adapter는 CNN 특징에 의사 특성을 추가하여 효과성과 효율성을 더욱 향상시킵니다. 제안된 ELP-adapter tuning은 Self-supervised 모델을 사용하는 모든 다운스트림 작업에 적용될 수 있습니다.

- **Performance Highlights**: 4개의 다운스트림 작업(음성 인식, 화자 검증, 감정 인식, 의도 분류)에 대해 5개의 Backbone 모델을 사용한 평가를 통해 제안된 방법의 효능을 확인했습니다. 특히, WavLM backbone을 사용할 때, 제안된 방법은 학습 가능한 파라미터 수를 90% 줄이면서도 대부분의 작업에서 기존의 풀 파인튜닝(full fine-tuning) 방법에 비해 성능이 동등하거나 우수했습니다.



### LawLLM: Law Large Language Model for the US Legal System (https://arxiv.org/abs/2407.21065)
Comments:
          21 pages, 2 figures, accepted at the 33rd ACM International Conference on Information and Knowledge Management (CIKM 2024) for the Applied Research Paper track

- **What's New**: 법률 분석 분야에서 복잡한 법적 언어와 유사한 판례의 미묘한 차이로 인해 관련 사례를 찾고 판결을 예측하는 것이 어려운 상황입니다. 이를 해결하기 위해 미국 법률 도메인에 특화된 다중 작업 모델인 Law Large Language Model (LawLLM)를 소개합니다. LawLLM는 유사한 사례 검색(Similar Case Retrieval, SCR), 전례 사례 추천(Precedent Case Recommendation, PCR), 그리고 법적 판결 예측(Legal Judgment Prediction, LJP)에서 뛰어난 성능을 보입니다.

- **Technical Details**: LawLLM는 세 가지 주요 작업을 수행합니다: Similar Case Retrieval (SCR), Precedent Case Recommendation (PCR), 법적 판결 예측(Legal Judgment Prediction, LJP). 모델 개발 과정에서 필요한 데이터 전처리 기술을 각 작업에 맞춰 커스터마이징하였고, 추론 학습(In-context learning)과 고급 정보 검색 기법을 활용하였습니다. 이를 통해 원시 법적 데이터를 훈련 가능한 형식으로 변환하였습니다.

- **Performance Highlights**: LawLLM는 기존 베이스라인 모델을 제로샷(zero-shot) 및 몇 샷(few-shot) 시나리오 모두에서 일관되게 능가하는 성능을 보여줌으로써 다중 작업 기능을 입증했습니다. 또한, 유사한 사례(Similar Case)와 전례 사례(Precedent Case)를 명확히 구분함으로써, 향후 연구에 필요한 맞춤형 전략 개발에 대한 중요한 통찰을 제공합니다.



### Improving noisy student training for low-resource languages in End-to-End ASR using CycleGAN and inter-domain losses (https://arxiv.org/abs/2407.21061)
Comments:
          10 pages (2 for references), 4 figures, published in SIGUL2024@LREC-COLING 2024

- **What's New**: 본 논문은 노이즈 학생 훈련(noisy student training)을 통해 반지도 학습(end-to-end)의 음성 인식 시스템의 성능을 크게 개선하는 방법을 제안했습니다. 특히, 음성-텍스트 데이터가 한정되어 있는 저자원 언어 환경에서 성능을 향상시키기 위해, 외부 텍스트를 활용한 CycleGAN 및 inter-domain 손실 적용 및 이를 자동 하이퍼파라미터 튜닝을 통해 개선하는 방식을 소개합니다. Voxforge 및 Common Voice의 6개 비영어권 언어에 대한 실험 결과, 기존 모델 대비 단어 오류율(WER)을 20% 감소시켰으며, 학생 모델 대비 10% 감소시켰습니다.

- **Technical Details**: CycleGAN과 inter-domain 손실(CID) 방식은 주로 소규모의 음성-텍스트 데이터와 추가적인 외부 텍스트를 이용해 모델을 훈련시키는 구조입니다. 이를 자동 하이퍼파라미터 튜닝을 통합하여 'enhanced CID'로 개선한 후, 이를 노이즈 학생 훈련(NST) 파이프라인에 통합하여 저자원 환경에서도 높은 성능을 발휘할 수 있도록 했습니다. 이 방식에서는 음성 데이터가 추가로 필요하지 않으며, 외부 텍스트 데이터만으로도 성능을 크게 향상시킵니다. 또한, 자동 하이퍼파라미터 튜닝을 통해 모델 튜닝 과정을 단순화하고 더욱 효율적으로 만듭니다.

- **Performance Highlights**: 제안된 방법은 기존 baseline 모델 대비 20%의 단어 오류율 감소를 달성했으며, 학생 모델과 비교했을 때 10%의 단어 오류율 감소를 보여주었습니다. 특히, 외부 추가 음성 데이터 없이 교사 모델의 성능을 향상시키는 데 성공했으며, Voxforge 및 Common Voice의 6개 비영어권 언어에 대해서 실험 결과를 통해 이를 입증했습니다.



### Using Large Language Models for the Interpretation of Building Regulations (https://arxiv.org/abs/2407.21060)
Comments:
          Presented at the 13th Conference on Engineering, Project and Production Management

- **What's New**: 이번 연구에서는 건축 프로젝트의 필수 요소인 규제 준수 검사를 자동화하기 위해 대형 언어 모델(LLMs)인 GPT-3.5를 사용하여 건축 규정을 LegalRuleML로 변환하는 성능을 평가합니다. BIM의 확산으로 인해 디지털 건축 설계 데이터를 쉽게 공유할 수 있게 되면서 자동화된 규제 준수 검사(ACC)에 더 많은 기회가 생겼습니다.

- **Technical Details**: GPT-3.5를 이용하여 few-shot learning 설정에서 건축 규정을 LegalRuleML로 변환하는 작업을 평가하였습니다. 몇 가지 예시 번역만 제공하여도 GPT-3.5가 형식의 기본 구조를 학습할 수 있으며, 시스템 프롬프트를 통해 LegalRuleML 표현을 명확히 지정하고 도메인 전문가 지식의 존재를 탐구합니다. Chain-of-thought reasoning과 self-consistency와 같은 전략의 적용 가능성 또한 조사합니다.

- **Performance Highlights**: GPT-3.5는 광범위한 사전 학습을 통해 도메인 적응에 있어 더 나은 성능을 보일 수 있으며, 이를 통해 ACC에서 더욱 효율적이고 효과적인 검사 프로세스를 지원할 수 있을 것으로 기대됩니다.



### Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks (https://arxiv.org/abs/2407.21059)
- **What's New**: 이번 논문에서는 기존의 취득-생성(Retrieval-augmented Generation, RAG) 패러다임의 한계를 검토하고, 모듈식 RAG(Modular RAG) 프레임워크를 도입했습니다. 복잡한 RAG 시스템을 독립적인 모듈과 특화된 연산자로 분해함으로써, 보다 유연하고 재구성 가능한 구조를 제공합니다. 그런 방식으로, 전통적인 선형 아키텍처를 넘어 라우팅, 스케줄링, 융합 메커니즘을 통합한 더욱 발전된 디자인을 채택하고 있습니다.

- **Technical Details**: 모듈식 RAG는 세 가지 레벨로 구성된 아키텍처를 제공합니다. 상위 레벨에서는 RAG의 중요한 단계를 독립적인 모듈로 처리하고, 중간 레벨은 각 모듈 내에 하위 모듈을 구성하여 기능을 세분화하며, 하위 레벨에서는 연산자의 기본 단위로 구성됩니다. 이 프레임워크에서 RAG 시스템은 계산 그래프 형태로 표현될 수 있으며, 노드는 특정 연산자를 나타냅니다.

- **Performance Highlights**: 모듈식 RAG의 주요 장점은 유연성과 확장성이 뛰어나다는 것입니다. 사용자는 데이터 소스와 작업 시나리오의 요구사항에 따라 다양한 모듈과 연산자를 유연하게 결합할 수 있습니다. 논문에서는 모듈식 RAG의 6가지 대표적인 흐름 패턴을 요약하고, 실용적인 시나리오에서의 범용성을 위해 구체적인 방법을 분석했습니다. 이를 통해 시스템의 유지보수와 이해도를 강화하면서, 새로운 방법의 적응과 확장에 대한 가이드를 제공합니다.



### Understanding the Interplay of Scale, Data, and Bias in Language Models: A Case Study with BER (https://arxiv.org/abs/2407.21058)
- **What's New**: 본 연구는 BERT 모델의 크기와 사전 학습 데이터가 사회적 편견과 고정관념에 어떤 영향을 미치는지 분석합니다. 특히, 모델 스케일이 커짐에 따라 상류(upstream)와 하류(downstream) 작업에서 나타나는 편견의 변화를 조사합니다.

- **Technical Details**: 네 가지 구성 크기의 BERT 모델(mini, small, medium, base)을 실험 대상으로 사용하였으며, 영어 Wikipedia와 Common Crawl(CC-100)의 영어 서브셋을 사전 학습 데이터로 활용하였습니다. 상류 편견은 성별 대명사의 확률과 생성된 텍스트의 감정(sentiment)을 통해 측정되었고, 하류 영향은 유독성 분류 작업에서 다양한 인구 집단의 거짓 양성률(false positive rate) 차이로 평가되었습니다.

- **Performance Highlights**: Common Crawl로 사전 학습된 모델의 경우, 모델 크기가 커질수록 상류 편견이 증가했습니다. 반면, Wikipedia로 사전 학습된 모델은 모델 크기가 커질수록 성별 고정관념이 더 많이 나타났습니다. 두 경우 모두 하류 작업에서는 모델 크기가 커질수록 편견이 감소하는 경향을 보였습니다. 그러나 'gay'와 'homosexual' 같은 특정 정체성을 유독성과 연관짓는 경향은 모델의 크기나 사전 학습 데이터와 관계없이 일관되게 나타났습니다.



### Multi-group Uncertainty Quantification for Long-form Text Generation (https://arxiv.org/abs/2407.21057)
- **What's New**: 최근 연구에서는 대형 언어 모델(Large Language Models, LLM)의 사실 오류와 환각(hallucinations)을 줄이기 위해 불확실성(uncertainty) 정량화 방법을 도입했습니다. 이 연구는 전통적인 전역 데이터 분포뿐만 아니라 개별 하위그룹의 분포에서도 유효한 불확실성 보증을 제공하는 멀티 캘리브레이션(multicalibration) 및 멀티발리드 컨포멀 예측(multivalid conformal prediction)을 도입했습니다.

- **Technical Details**: 연구는 전반적인 도메인과 개별 클레임(claim) 수준에서의 불확실성을 조사했습니다. 특히, (1) 개별 클레임의 사실성을 보증하기 위해 멀티 캘리브레이션(Hebert-Johnson et al., 2018)을 사용하고, (2) 전체 클레임 세트의 불확실성을 보증하기 위해 멀티발리드 컨포멀 예측(Jung et al., 2022)을 적용했습니다. 전형적인 전역 캘리브레이션 및 컨포멀 방법과 대비할 때 멀티 캘리브레이션 및 멀티발리드 컨포멀 예측 기술이 불확실성 측면에서 더 나은 성능을 보였습니다.

- **Performance Highlights**: 이 연구는 전기 생성(biography generation)을 테스트베드로 사용하여 사실성의 멀티그룹 불확실성 정량화를 평가했습니다. 멀티 캘리브레이션 및 멀티발리드 컨포멀 예측 기법이 표준 캘리브레이션 및 컨포멀 예측 방법에 비해 그룹 내부 및 전체 데이터셋에서 불확실성 측정값을 개선하는 것을 실험적으로 입증했습니다.



### What Matters in Explanations: Towards Explainable Fake Review Detection Focusing on Transformers (https://arxiv.org/abs/2407.21056)
- **What's New**: 본 논문은 전자상거래 플랫폼에서 등장하고 있는 허위 리뷰(fraudulent reviews) 문제를 해결하기 위해 설명 가능한 고정확도 프레임워크를 제안합니다. 특히, 신경망 모델이 이해하기 어려운 블랙박스(black-box) 특성을 가지는 문제를 해결하고자 설명 가능한 기법을 제시했습니다.

- **Technical Details**: 딥러닝(DL)과 트랜스포머(transformer) 모델인 XLNet과 DistilBERT를 사용하여 허위 리뷰 탐지 모델을 개발하였습니다. 그런 다음 레이어별 연관성 전파(layer-wise relevance propagation, LRP) 기술을 사용하여 예측 클래스에 기여하는 단어들을 매핑하는 설명을 생성했습니다.

- **Performance Highlights**: 두 개의 벤치마크 데이터셋을 대상으로 실험한 결과, 제안된 예측 모델은 최첨단 성능(State-of-the-Art Performance)을 달성하며 기존의 여러 방법들을 능가했습니다. 또한, 생성된 설명에 대한 사용자의 경험적 평가 결과, 허위 리뷰 식별 맥락에서 고려해야 할 중요한 정보들을 결론지었습니다.



### Bailicai: A Domain-Optimized Retrieval-Augmented Generation Framework for Medical Applications (https://arxiv.org/abs/2407.21055)
- **What's New**: Bailicai 프레임워크를 소개합니다. 이 프레임워크는 Retrieval-Augmented Generation (RAG) 기술을 오픈 소스 대형 언어 모델(LLM)과 통합하여 의학 분야에서 성능을 크게 향상시키는 접근법입니다. Bailicai는 GPT-3.5보다 뛰어난 성능을 보이며, 의학 태스크에서 'hallucination' 문제를 효과적으로 줄입니다.

- **Technical Details**: Bailicai의 주요 구성 요소는 다음과 같습니다: 1) Medical Knowledge Injection, 2) Self-Knowledge Boundary Identification, 3) Directed Acyclic Graph (DAG) Task Decomposition, 4) Retrieval-Augmented Generation. 이 시스템은 UltraMedical 데이터셋에서 추출한 데이터를 기반으로 구축되었으며, LoRA(저-랭크 근사) 기술을 활용하여 모델을 미세조정했습니다.

- **Performance Highlights**: Bailicai는 다수의 의학 기준 테스트에서 기존의 오픈 소스 LLM과 RAG 접근법을 능가하는 성능을 보였습니다. 특히, GPT-3.5의 성능을 초과하며, 의학 응용 분야에서 유의미한 성능 개선을 입증했습니다.



### Sentiment Reasoning for Healthcar (https://arxiv.org/abs/2407.21054)
Comments:
          Preprint, 18 pages

- **What's New**: 이 논문은 감정 분석 작업에 있어 중요한 새로운 과제인 'Sentiment Reasoning'을 소개합니다. 이는 사람의 감정을 더 깊고 맥락적으로 이해하기 위해 고안을 했습니다. 이 접근 방식은 텍스트와 음성 모달리티를 모두 포함하며, 새로운 멀티태스킹 프레임워크와 데이터셋을 제안합니다.

- **Technical Details**: 이 연구는 멀티모달 감정 분석 프레임워크를 제안하며, 이를 위해 MultiMed-SA라는 데이터셋을 사용합니다. 이 데이터셋은 의사와 환자 간의 대화 내용을 포함하고 있으며, 감정 레이블과 그에 대한 논리를 주석으로 달았습니다. 제안된 프레임워크는 ASR (Automated Speech Recognition)을 통해 생성된 텍스트와 사람의 대화 내용을 기반으로 훈련됩니다. 이를 통해 AI가 더 깊이 있는 감정 분석을 할 수 있도록 Chain-of-Thought (CoT)를 통합하여 학습시킵니다.

- **Performance Highlights**: 실험 결과, 논리 보강 학습(rationale-augmented training)을 통해 감정 분류 성능이 향상되었습니다. 이는 사람의 대화 내용과 ASR 환경 모두에서 유효했으며, 생성된 논리가 인간이 작성한 논리와 비슷한 의미를 유지하면서도 다른 어휘를 사용하는 것을 확인했습니다.



### Knowledge Models for Cancer Clinical Practice Guidelines : Construction, Management and Usage in Question Answering (https://arxiv.org/abs/2407.21053)
- **What's New**: 새롭게 제안된 자동화 지식 모델링 알고리즘이 암 임상 진료 지침(CPGs)의 복잡한 내용을 효율적으로 추출하고 프로그램적으로 상호 작용할 수 있는 구조화된 모델로 변환합니다. 이번 연구에서는 National Comprehensive Cancer Network (NCCN)에서 제공하는 네 가지 암 유형에 대한 CPGs를 대상으로 한 알고리즘을 개선하여 제안했습니다.

- **Technical Details**: 제안된 알고리즘은 기존 알고리즘과 달리 다양한 암 유형에 대한 CPGs의 복잡한 지식을 처리할 수 있습니다. 또한, 알고리즘은 새로운 버전의 지침서에서 도입된 특정 변경 사항을 발견하기 위해 서로 다른 버전의 지식 모델을 비교하는 기능을 갖추고 있습니다. 지침서 지식 모델을 보강된 지식 기반으로 활용하여 Q&A 프레임워크를 구축했습니다. Non-Small Cell Lung Cancer (NSCLC) 치료에 대한 신뢰성 있는 두 데이터 소스에서 가져온 32개의 Q&A 세트를 사용해 이 프레임워크를 평가했습니다.

- **Performance Highlights**: Q&A 프레임워크는 하나의 데이터 소스에서 가져온 Q&A 세트로 평가되었으며, 치료 알고리즘에서 54.5% 정확도, NCCN NSCLC 지침서의 논의 부분에서는 81.8% 정확도로 답변을 생성할 수 있었습니다.



### Table-Filling via Mean Teacher for Cross-domain Aspect Sentiment Triplet Extraction (https://arxiv.org/abs/2407.21052)
Comments:
          Accepted by CIKM2024

- **What's New**: 이 논문은 Cross-domain Aspect Sentiment Triplet Extraction (ASTE) 작업에서 새로운 접근법을 제안합니다. 전통적인 방식이 사전 훈련된 언어 모델(Pre-trained Language Models, PLMs)을 사용해 대량의 합성 데이터를 생성하는 데 많은 컴퓨팅 자원을 소모하는 반면, 저자들은 두 단계 객체 탐지(OD, Object Detection) 방법에서 영감을 받아 테이블 채우기(table-filling) 방법을 사용합니다. 그 결과, TFMT(Table-Filling via Mean Teacher)라는 새로운 방법을 소개합니다.

- **Technical Details**: TFMT는 문장을 2차원 테이블로 인코딩하여 단어 간의 관계를 감지합니다. 이 테이블을 특징 맵(feature map)으로 간주하고 영역 일관성(region consistency)을 사용해 생성된 의사 레이블(pseudo-labels)의 품질을 향상시킵니다. 또한, 도메인 간 차이를 줄이기 위해 최대 평균 불일치(Maximum Mean Discrepancy, MMD)를 기반으로 한 교차 도메인 일관성을 설계했습니다. TFMT는 학생 모델과 교사 모델로 구성된 mean teacher 아키텍처를 활용하여 도메인 적응(domain adaptation)을 안내합니다.

- **Performance Highlights**: TFMT는 기존 방법보다 적은 매개변수와 컴퓨팅 비용으로 최첨단 성능을 달성합니다. 합성 데이터 생성에 의존하지 않기 때문에 이전 접근법보다 상대적으로 간단하면서도 강력한 성능을 보여줍니다. 이 방법은 크로스 도메인 ASTE 작업에 새로운 기준선(strong baseline)을 제시하며 후속 연구에 영감을 줄 수 있습니다.



### An Active Inference Strategy for Prompting Reliable Responses from Large Language Models in Medical Practic (https://arxiv.org/abs/2407.21051)
Comments:
          25 pages, 4 figures

- **What's New**: 이 논문은 Large Language Models (LLMs)를 의료 분야에 적용하는 새로운 프레임워크를 소개합니다. 기존 연구는 LLMs가 비결정론적이며 잘못된 혹은 유해한 응답을 제공할 수 있어 의료 사용에 부적절하다고 강조했습니다. 그러나 이 논문은 도메인 특화 데이터셋만을 지식 기반으로 사용하고, Actor-Critic LLM 프롬프트 프로토콜을 도입하여 이러한 문제를 해결하고자 합니다.

- **Technical Details**: 제안된 프레임워크는 검증된 의료 정보를 포함하는 도메인 특화 데이터셋만을 LLM의 지식 기반으로 제한하고, 인간 인지의 액티브 인퍼런스 원칙에 기반한 Actor-Critic LLM 프롬프트 프로토콜을 도입합니다. 이 프로토콜에서 Therapist 에이전트가 환자의 질문에 초기 응답을 하고, Supervisor 에이전트가 응답의 정확성과 신뢰성을 평가하고 조정합니다.

- **Performance Highlights**: 불면증에 대한 인지 행동 치료(CBT-I) 전문가들이 LLM의 응답을 블라인드 형식으로 평가한 검증 연구가 수행되었습니다. 숙련된 CBT-I 치료사들이 LLM이 생성한 응답을 평가한 결과, LLM의 응답이 종종 치료사가 생성한 적절한 응답보다 높은 평가를 받았습니다. 이 구조화된 접근 방식은 LLM 기술을 의료 애플리케이션에 통합하고, 특별 목적의 검증된 LLM 사용의 안전성과 효과성을 확립하기 위한 규제 요구 사항을 충족시키려 합니다.



### Artificial Intelligence in Extracting Diagnostic Data from Dental Records (https://arxiv.org/abs/2407.21050)
Comments:
          11 pages, 2 tables, 3 figures, under review

- **What's New**: 이 연구는 치과 기록의 누락된 구조화된 데이터를 비구조화된 텍스트에서 추출하여 해결하려는 것입니다. 최신 치주학 분류 시스템의 복잡성이 진단 구조의 불완전 또는 누락 문제를 야기하며, 이를 해결하기 위해 첨단 AI와 NLP 방법을 사용합니다. GPT-4를 활용하여 합성 노트를 생성하고, 이를 RoBERTa 모델 훈련에 사용하여 의료 및 치과 언어 이해 능력을 크게 향상시켰습니다.

- **Technical Details**: 이 모델은 두 개의 데이터셋에서 무작위로 선택된 120개의 임상 노트를 평가에 사용했습니다. 새로운 방법론은 GPT-4를 통해 합성된 데이터를 이용해 RoBERTa 모델을 파인튜닝(fine-tuning)하여 개선된 진단 추출 정확도를 보입니다. 결과적으로 치주 상태, 단계, 등급 진단에서 높은 정확도를 나타냈습니다.

- **Performance Highlights**: 결과 분석에 따르면 Site 1에서는 0.99, Site 2에서는 0.98의 높은 정확도를 기록했습니다. 특히 하위 유형(subtype) 카테고리에서는 Site 2가 완벽한 점수를 기록하며 Site 1을 능가했습니다. 이 방법은 치과 진단 추출의 정확성을 높이고 다양한 치과 환경에서의 활용 가능성을 넓힙니다.

- **Impact**: AI와 NLP 기술을 통합하여 문서화를 개선하고 행정 작업을 간소화하며 복잡한 임상 정보를 정확하게 추출하는데 기여합니다. 합성 훈련 데이터를 사용함으로써 훈련 과정을 최적화하고 치과 진단 식별의 정확성과 효율성을 향상시킵니다. 이러한 혁신적인 방법은 보다 넓은 범위의 의료 응용 가능성을 지니며, 궁극적으로 환자 치료의 질을 개선할 것으로 기대됩니다.



### Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieva (https://arxiv.org/abs/2407.21049)
Comments:
          29 pages, 18 figures

- **What's New**: 최근 발표된 arxiv 논문에서는 코드 생성 모델들이 긴 문맥 의존성을 다루는 능력을 평가하기 위한 새로운 접근 방식을 제안했습니다. 특히, 최대 8k 토큰 길이의 문맥 창(context windows)에서 여러 단계의 키 검색 작업(multi-step key retrieval tasks)을 사용하여 다양한 모델의 성능을 평가하였습니다.

- **Technical Details**: 이 연구는 문맥 창에서 점점 더 길어지는 의존성을 다루는 코드 생성 모델의 능력을 평가하기 위한 네 가지 키 검색 작업(one-step, two-step, three-step, and concatenation retrieval)을 제안했습니다. 각각의 작업은 단계별로 난이도가 증가하며, 이는 모델이 여러 조각의 정보를 통합하여 완료할 수 있는 능력을 테스트합니다. 또한, 모델이 매개변수 지식(parametric knowledge)에 의존하지 않도록 함수 이름과 반환 값을 임의의 문자열로 구성하여 모델이 실제로 문맥에서 주어진 정보를 활용하도록 요구했습니다.

- **Performance Highlights**: 연구 결과, 함수가 나중에 정의된 다른 함수를 참조할 때 성능은 최대 2배까지 저하되었으며, 슬라이딩 윈도우 주의 메커니즘을 사용하는 모델은 단일 윈도우 크기보다 멀리 있는 참조를 처리하는 데 어려움을 겪었습니다. 그러나 호출 그래프 정보(call graph information)를 사용하여 프롬프트를 단순히 수정함으로써 다단계 검색 성능을 최대 3배까지 향상시킬 수 있었습니다. 이 연구는 코드 완성 도구에 대한 프롬프트 구성 전략을 시사합니다.



### APTNESS: Incorporating Appraisal Theory and Emotion Support Strategies for Empathetic Response Generation (https://arxiv.org/abs/2407.21048)
Comments:
          Appectped to CIKM2024

- **What's New**: 새로운 AI 프레임워크 APTNESS는 감정지원 전략 및 평가 이론을 통합하여, LLM(대규모 언어 모델)의 인지적 및 감정적 공감 능력을 향상시킵니다.

- **Technical Details**: APTNESS는 검색 증강(Retrieval Augmentation)과 감정지원 전략을 결합한 프레임워크입니다. 감정 팔레트(emotional palette)를 도입하고 평가 이론(Appraisal Theory)에 따라 이를 분해하여 감정 반응 데이터베이스를 구축합니다. 이 데이터베이스는 외부 자원으로 작용하여 LLM의 공감을 증진시킵니다. 감정지원 전략(emotional support strategy)을 통합하여 인지적 공감(cognitive empathy)뿐만 아니라 감정적 공감(affective empathy)도 풍부하게 표현할 수 있습니다.

- **Performance Highlights**: 실험 결과, APTNESS 프레임워크는 다양한 LLM에서 인지적 및 감정적 공감 능력을 크게 향상시켰습니다. 특히, ED와 ET 데이터셋을 사용한 자동화된 턴 기반 평가에서 뛰어난 성능을 보였습니다.



### Promises and Pitfalls of Generative Masked Language Modeling: Theoretical Framework and Practical Guidelines (https://arxiv.org/abs/2407.21046)
Comments:
          ICML 2024

- **What's New**: 이 논문에서는 비자율 회귀(Non-Autoregressive) 패러다임인 생성 마스크드 언어 모델(Generative Masked Language Models, GMLMs)을 소개합니다. GMLMs는 마스킹 기술을 사용하여 데이터의 조건부 확률(conditional probabilities)을 학습하며, 이를 기반으로 Markov Chain을 사용해 샘플링을 수행합니다. 이 접근 방식은 일반적으로 병렬 디코딩이 가능해 속도 및 품질의 균형을 잘 맞추면서도 성능을 높일 수 있습니다.

- **Technical Details**: 논문에서는 GMLMs의 학습 및 추론 속도와 품질을 개선하기 위한 수학적 프레임워크를 개발합니다. 예를 들어, 더 큰 마스크를 사용하여 학습하면 통계적 효율성이 향상되는 것을 증명하였고, 데이터 분포의 조건부 확률을 학습함으로써 분포 전체를 얼마나 잘 학습할 수 있는지를 분석합니다. 또한, 각 디코딩 단계가 좌표를 따라 분해되는 특성을 가지며, 강한 상관관계를 가진 간단한 분포도 효과적으로 샘플링할 수 있도록 Markov Chain의 혼합 시간을 고려합니다.

- **Performance Highlights**: 실험 결과, 우리는 T5 모델을 병렬 디코딩으로 반복적으로 개선하여 기계 번역에서 2~3배 속도 향상을 달성하였습니다. 품질 저하가 최소화된 상태에서 이와 같은 속도 향상을 이뤄냈습니다. 실험에서는 큰 마스킹 비율 사용, 맞춤형 어휘집(custom vocabulary), AR 모델로부터의 디스틸레이션(distillation), 위치 주의기(positional attention) 같은 요소들이 중요한 역할을 했습니다.



### Unlocking the Potential: Benchmarking Large Language Models in Water Engineering and Research (https://arxiv.org/abs/2407.21045)
- **What's New**: 최근 대형 언어 모델(LLMs)의 발전이 다양한 분야에서의 응용 가능성에 대한 관심을 불러일으켰습니다. 본 논문은 이러한 LLMs가 '수자원 전문가 모델'로서의 역할을 효과적으로 수행할 수 있는지를 평가하는 첫 번째 연구입니다. 이를 위해 특수 도메인 벤치마크 스위트(WaterER)를 테스트하여, 수자원 공학 및 연구 작업에 대한 983개의 작업을 준비하고 이를 평가했습니다. 여기에는 폐수 처리, 환경 복원, 음용수 처리 및 분배, 위생, 혐기성 소화, 오염 물질 평가가 포함됩니다.

- **Technical Details**: 일곱 개의 LLMs(GPT-4, GPT-3.5, Gemini, GLM-4, ERNIE, QWEN, Llama3)가 983개의 특정 수자원 공학 및 연구 작업에서 평가되었습니다. 특히, GPT-4는 다양한 복잡한 수자원 공학 작업을 효율적으로 처리하는 데 강점을 보였고, Gemini는 학술적 문맥에서 특화된 능력을 발휘했습니다. Llama3는 중국어 수자원 공학 질문에 가장 뛰어난 응답 능력을 보였으며, GLM-4, ERNIE, QWEN 같은 중국어 모델들도 일부 수자원 공학 작업에서 경쟁력 있는 성능을 보여주었습니다.

- **Performance Highlights**: GPT-4는 '오염 물질 관련 수질 모니터링 및 평가' 논문에 대해 정확한 연구 격차를 생성하는 데 특히 뛰어났습니다. 또한, '폐수 처리 프로세스', '환경 복원', '음용수 처리' 연구 논문의 적절한 제목을 생성하는 데에도 뛰어난 성과를 보였습니다. 전반적으로 이 연구는 LLMs를 수자원 공학 및 연구에서 평가하는 첫 번째 연구로, WaterER 벤치마크를 도입하여 예측의 신뢰성을 평가했습니다. 이 표준화된 평가 프레임워크는 향후 LLM 기술의 발전을 촉진하여 진정한 '수자원 전문가' 모델로 발전시키는 데 기여할 것입니다.



### CP-Prompt: Composition-Based Cross-modal Prompting for Domain-Incremental Continual Learning (https://arxiv.org/abs/2407.21043)
Comments:
          Accepted by ACM MM 2024

- **What's New**: 이 논문에서는 새로운 도메인에서 연속적으로 학습하면서 기존의 정보를 잊지 않기 위한 Cross-modal Domain-Incremental Learning (DIL) 문제를 해결하기 위해 CP-Prompt라는 새로운 프레임워크를 제안합니다. CP-Prompt는 미리 학습된 모델의 제한된 파라미터를 학습시켜 새로운 도메인을 학습하고 기존의 특징 분포를 잊지 않도록 합니다. CP-Prompt는 intra-domain 지식을 멀티-헤드 셀프 어텐션 레이어에 개인화된 프롬프트를 삽입하여 포착하고, 공통 프롬프트 전략으로 inter-domain 지식을 학습합니다.

- **Technical Details**: CP-Prompt는 미리 학습된 모델을 가르치기 위해 twin-prompt 전략을 사용합니다. 얕은 부분의 모델에 임베딩된 공통 프롬프트는 새로운 도메인 연속적으로 학습한 후 동결됩니다. 이러한 공통 프롬프트는 모델이 도메인 간 지식을 보존할 수 있도록 합니다. 개인화된 프롬프트(Prefix-One)는 미리 학습된 모델의 셀프 어텐션 레이어에 임베드되어 도메인 스타일 특징을 가지고 모델 추론에 기여합니다.

- **Performance Highlights**: CP-Prompt는 세 가지 널리 사용되는 DIL 벤치마크 데이터셋에서 기존의 최첨단 샘플-프리 베이스라인을 능가하며, 최소한의 추가 파라미터(0.22%)만을 조정하여 모델의 정확도를 2.3%까지 개선시킵니다.



### They Look Like Each Other: Case-based Reasoning for Explainable Depression Detection on Twitter using Large Language Models (https://arxiv.org/abs/2407.21041)
- **What's New**: 최근 발표된 ProtoDep는 트위터 기반의 우울증 탐지를 위한 새로운 설명 가능한 프레임워크입니다. ProtoDep는 프로토타입 학습(Prototype Learning)과 대규모 언어 모델(Large Language Models, LLMs)을 활용하여 투명한 설명을 제공하는 혁신적인 방법을 제시합니다. 이 프레임워크는 증상 수준, 유사 사용자 비교, 그리고 분류 가중치를 통해 우울증 탐지 모델의 투명성을 크게 향상시킵니다.

- **Technical Details**: ProtoDep는 트위터 데이터 내에서 우울증을 탐지하기 위해 프로토타입 학습을 사용합니다. 이 프레임워크는 다음 다섯 가지 단계로 이루어집니다: 1) 사용자 트윗 임베딩, 2) 증상 프로토타입 학습, 3) 사용자 인코딩, 4) 사용자 프로토타입 학습, 5) 분류 수행. 모델은 학습된 후 특정 사용자가 우울증을 앓고 있는지 여부를 예측합니다. 매 단계는 사용자 및 트윗과 연관된 중요한 정보를 추출하고 이를 기반으로 최종 결정을 내리는 데 도움을 줍니다.

- **Performance Highlights**: ProtoDep는 다섯 개의 벤치마크 데이터셋에서 거의 최첨단 성능을 달성하면서 의미 있는 프로토타입을 학습하는 데 성공했습니다. 이는 기존의 '블랙 박스' 모델과 달리 설명 가능성을 높여 모델의 예측이 어떻게 이루어졌는지 사용자들이 이해하도록 도와줍니다. 이러한 다단계 접근법은 궁극적으로 정신 건강 전문가들이 더 많은 정보를 기반으로 치료를 제공하는 데 도움을 줄 수 있습니다.



### Mapping Patient Trajectories: Understanding and Visualizing Sepsis Prognostic Pathways from Patients Clinical Narratives (https://arxiv.org/abs/2407.21039)
Comments:
          preprint, 8 pages, 6 figures

- **What's New**: 이 논문에서는 전통적인 전자 건강 기록(EHR)의 구조화된 임상 변수 대신 클리니컬 노트(clinical notes)를 활용하여 패혈증(sepsis) 예후 경로(prognostic pathways)를 개발하는 체계적인 방법론을 제안합니다. 다양한 동반질환으로 식별된 환자 하위 그룹을 중심으로 SHAP를 사용하여 이러한 하위 그룹에 대한 설명을 생성합니다.

- **Technical Details**: 본 연구는 MIMIC-III v1.4 데이터베이스로부터 추출된 패혈증 환자 코호트를 대상으로 하였습니다. 시간에 따라 기록된 임상 노트(간호 노트, 방사선 보고서, ECG 보고서)를 사용하여, 생물 의학 용어 사전을 통해 비구조화된 임상 노트를 표준화한 후, 환자 하위 그룹을 식별하고 질병 진행 경로를 추출합니다. 두 가지 BioNER 도구인 ScispaCy와 Metamap을 통해 주요 의학 엔터티를 추출하고, Negex 알고리즘을 사용하여 부정 사항을 식별하였습니다.

- **Performance Highlights**: 추출된 예후 경로는 시간에 따른 패혈증 중증도의 동적 궤적에 대한 귀중한 통찰을 제공하며, 질병 진행의 가능성과 방향을 다양한 맥락에서 시각화하고 결정적 요인이나 바이오마커를 드러냅니다. 이는 의료 제공자가 개별 환자에 맞춤형 치료 전략을 구현할 수 있게 도와줍니다.



### Advancing Chart Question Answering with Robust Chart Component Recognition (https://arxiv.org/abs/2407.21038)
- **What's New**: 새로운 기계 학습 모델인 Chartformer를 소개합니다. 이 모델은 차트 컴포넌트(예: 바, 라인, 파이, 제목, 범례, 축)를 정확하게 인식하고 분류하는 데 탁월한 성능을 보입니다. 또한, Question-guided Deformable Co-Attention (QDCAt) 메커니즘을 도입하여 질문에 기반한 지도를 통해 차트 기능을 결합하고 올바른 답을 도출할 수 있도록 개선하였습니다.

- **Technical Details**: Chartformer는 변형 가능한 주의 메커니즘(deformable attention)과 마스크 주의 메커니즘(mask attention)을 사용하여 차트 그래픽의 시각적 요소를 효과적으로 포착합니다. QDCAt 메커니즘은 Question-guided Offset Network (QON)를 활용해 질문 정보를 차트 기능과 결합하고 시각적 및 차트 관련 기능을 통합합니다.

- **Performance Highlights**: Chartformer는 기존 강력한 기준 모델인 DAT와 Mask2former를 각각 11.4%, 3.2% mAP에서 능가하며, 특히 중복되거나 불규칙한 라인 및 좁은 파이 조각에서 뛰어난 성능을 보입니다. QDChart는 ChartQA에서 15.4%의 정확도로 기존 Pix2Struct 모델을 능가하며, 색상 명확화 및 차트 컴포넌트 크기 비교와 같은 시각적으로 관련된 질문을 처리하는 데 특히 우수한 능력을 보여줍니다.



### An Application of Large Language Models to Coding Negotiation Transcripts (https://arxiv.org/abs/2407.21037)
- **What's New**: Vanderbilt AI Negotiation Lab에서 LLM(대형 언어 모델)을 협상 대본 분석에 적용한 연구 결과를 발표하였습니다. 이 연구는 협상 대본에서 각 문장이나 발언 단위를 자동으로 분류하기 위해 다양한 LLM 전략(제로샷 학습, 파인튜닝, 컨텍스트 학습)을 활용하였습니다. 이 과정에서의 성공과 실패를 바탕으로 최종 전략을 개발하였습니다.

- **Technical Details**: 코딩 스키마 설정부터 이상적인 예문을 생성하고, 세 가지 LLM 모델 코딩 전략을 테스트하는 과정이 상세히 설명되었습니다. 초기에는 47개의 코드를 가진 Jäckel Master 코딩 스키마를 사용하려 했으나, 실제 적용 가능한 19개의 코드로 축소하였습니다. 'Zero-Shot', 'Fine-Tuning' 및 'In-Context Learning' 전략을 사용한 다양한 실험이 수행되었고, 특히 'Fine-Tuning'은 협상 전문가의 예제 문장과 정의를 사용하여 모델을 도메인에 맞게 튜닝하였습니다.

- **Performance Highlights**: 'Zero-Shot' 전략에서는 일반 언어 지식만으로 약 20%의 정확도를 얻었으나, 'Fine-Tuning' 전략에서는 BERT 모델을 Jäckel 코딩 스키마에 맞게 튜닝하여 보다 높은 성능을 이끌어냈습니다. 이 연구는 LLM이 협상 연구를 위한 코딩 프로세스를 자동화하여 시간과 비용을 절약하고, 코딩의 효율성과 신뢰성을 향상시킬 수 있음을 보여줍니다.



### Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress? (https://arxiv.org/abs/2407.21792)
- **What's New**: 이 논문에서는 AI 안전성 연구 분야의 모호함과 일관성 없는 측정치로 인해 발생하는 문제들을 해결하기 위해 포괄적인 메타 분석을 수행하였습니다. 이를 통해 AI 안전성 벤치마크(benchmarks)와 일반적인 능력(general capabilities)의 상관관계를 실증적으로 분석하였으며, 기존 AI 안전성 연구 방향에 대한 조사를 제공하였습니다.

- **Technical Details**: 수십 개 모델에 대해 AI 안전성 벤치마크가 일반적인 모델 능력과 높은 상관관계를 가진다는 사실을 발견했습니다. 이는 능력 향상이 안전성 진보로 잘못 표시될 수 있는 '안전세척(safetywashing)' 가능성을 높입니다. 이를 해결하기 위해, 더욱 의미 있는 안전성 지표를 개발하는 경험적 기초(empirical foundation)를 제안하고, 기계 학습 연구(context)에서 AI 안전성을 일반적인 능력 발전과는 분명히 구분된 연구 목표로 정의하였습니다.

- **Performance Highlights**: 많은 AI 안전성 벤치마크가 일반적인 능력과 강한 상관관계를 보였으며, 이를 통해 더욱 엄격한 안전성 평가 과학을 발전시키고, 측정 가능한 진보로 가는 길을 명확히 하고자 합니다.



### Vision-Language Model Based Handwriting Verification (https://arxiv.org/abs/2407.21788)
Comments:
          4 Pages, 1 Figure, 1 Table, Accepted as Short paper at Irish Machine Vision and Image Processing (IMVIP) Conference

- **What's New**: 문서 포렌식에서 필적 검증(Handwriting Verification)은 중요한 역할을 합니다. 그러나 현재의 딥러닝 기반 접근법은 설명 가능성이 부족하고 대규모 학습 데이터와 수작업 특징에 의존한다는 점에서 포렌식 문서 검사관들에게 신뢰를 받지 못하고 있습니다. 이번 연구는 OpenAI의 GPT-4o와 Google의 PaliGemma와 같은 Vision Language Models(VLMs)를 사용해 이러한 문제를 해결하고자 합니다. 이 모델들은 Visual Question Answering과 0-shot Chain-of-Thought(COT) 추론을 활용하여 명확하고 인간이 이해할 수 있는 설명을 제공합니다.

- **Technical Details**: ['Methods: 본 연구에서는 OpenAI의 GPT-4o VLM을 선택하여 시각 질문 응답(Visual Question Answering) 기능을 사용했습니다. 0-shot Chain-of-Thought(COT) 추론을 통해 인간이 이해가능한 설명을 먼저 생성한 후, 필적 검증을 수행했습니다. 추가적으로, PaliGemma VLM을 사용해 0-shot 프롬프트 엔지니어링 및 파라미터 효율 최적화 슈퍼바이즈드 피인튜닝(PEFT)을 비교했습니다.', "Data: 실험은 CEDAR Letter와 CEDAR AND 데이터셋에서 수행되었습니다. CEDAR Letter 데이터는 1568명의 필자들이 세 번 작성한 편지 원고를 포함하고 있으며, CEDAR AND는 이 데이터의 부분집합으로, 편지 원고에서 추출한 소문자 'and' 단어만 포함하고 있습니다."]

- **Performance Highlights**: ['결과: 실험 결과 CNN 기반의 ResNet-18 아키텍처는 GPT-4o(정확도: 70%)와 슈퍼바이즈드 피인튜닝된 PaliGemma(정확도: 71%)를 능가하였으며, CEDAR AND 데이터셋에서 84%의 정확도를 달성했습니다.', 'CEDAR AND 기준으로 주요 모델들의 성능: GSC(정확도: 78%), ResNet-18(정확도: 84%), ViT(정확도: 79%), GPT-4o 0-shot COT(정확도: 70%), PaliGemma 0-shot COT(정확도: 65%) 및 PaliGemma 슈퍼바이즈드 피인튜닝(정확도: 71%)']



### The Llama 3 Herd of Models (https://arxiv.org/abs/2407.21783)
- **What's New**: 이번 논문은 새로운 파운데이션 모델(foundation model) 세트인 Llama 3를 소개합니다. Llama 3는 다국어 지원, 코딩, 추론, 도구 사용을 네이티브로 지원하는 다양한 언어 모델 군입니다. 최대 4050억 개의 매개변수(parameter)와 128K 토큰의 문맥 창(context window)을 가지는 밀집 트랜스포머(dense Transformer)를 포함하고 있습니다.

- **Technical Details**: Llama 3는 코드 작성, 다국어 처리, 추론 등의 다양한 작업을 수행할 수 있는 다기능 언어 모델 군입니다. 실험적으로 Llama 3는 GPT-4와 같은 선두 언어 모델과 유사한 품질을 제공하는 것으로 나타났습니다. 우리는 또한 미리 학습된(pre-trained) 및 후속 학습된(post-trained) 버전의 405B 매개변수 언어 모델과 입력 및 출력의 안전성을 보장하는 Llama Guard 3 모델을 공개했습니다. 이미지, 비디오, 음성 기능을 통합하기 위해 조합적 접근법(compositional approach)을 사용한 실험 결과도 제시합니다.

- **Performance Highlights**: Llama 3는 이미지 인식, 비디오 인식, 음성 인식 작업에서 최첨단(state-of-the-art) 성능과 경쟁할 수 있는 능력을 보여줍니다. 하지만, 이러한 통합된 모델들은 아직 개발 중이며, 광범위한 공개는 이루어지지 않았습니다.



### Can LLMs "Reason" in Music? An Evaluation of LLMs' Capability of Music Understanding and Generation (https://arxiv.org/abs/2407.21531)
Comments:
          Accepted by ISMIR2024

- **What's New**: 최근 연구는 GPT-4와 Llama2와 같은 대형 언어 모델(LLMs)을 상징적 음악(Symbolic Music) 이해와 생성에 적용하는 방향으로 확장되었습니다. 본 연구는 이러한 LLM들이 고급 음악 이해와 조건부 생성, 특히 다단계 추론(Multi-Step Reasoning) 관점에서 어떻게 성능을 보이는지에 대한 철저한 조사를 수행했습니다.

- **Technical Details**: 음악 추론(Music Reasoning)은 음악 작품에서 명시되지 않은 다양한 화음, 키, 리듬 등의 요소를 추정하는 능력을 의미합니다. 본 연구는 GPT-4, Gemma-7B-it, Llama2-7B-chat, Qwen-7B-chat과 같은 네 가지 LLM을 대상으로 상징적 음악 이해와 생성에 관련된 작업을 평가하였습니다. 또한, 다단계 프롬프트 엔지니어링(Multi-Step Prompt Engineering)을 통해 LLM들이 음악 이해와 생성 작업에서 다단계 명령을 사용하는 방법을 탐구했습니다.

- **Performance Highlights**: 현 LLM들은 곡 수준의 다단계 음악 추론에서는 성능이 떨어지며, 복잡한 음악 작업을 처리할 때 배운 음악 지식을 잘 활용하지 못한다는 점을 확인하였습니다. 예를 들어, 'Musical Form & Motif Conditioned Music Generation' 작업에서 Gemma-7B-it 모델은 제공된 모티프를 반복하는 데 그쳤고, GPT-4는 주어진 조건을 반복하는 데 그쳤습니다. Qwen-7B-chat과 Llama-7B-chat은 올바른 음악 요소와 모티프를 포함했지만 'AB' 형식을 포착하지 못하고 마디의 시간을 유지하지 못했습니다.



### Interpreting and learning voice commands with a Large Language Model for a robot system (https://arxiv.org/abs/2407.21512)
Comments:
          PP-RAI 2024, 5th Polish Conference on Artificial Intelligence, 18-20.04.2024 Warsaw, Poland

- **What's New**: 이 논문은 GPT-4와 같은 대형 언어 모델(LLM)을 로봇에 통합하여 실시간 상호작용 및 의사결정 능력을 향상시키는 방법을 제안합니다. 본 프로젝트는 LLM과 데이터베이스를 결합하여 요청 해석 문제를 해결하고 지식을 획득하는 능력을 향상시키는 데 초점을 맞추고 있습니다.

- **Technical Details**: 이 시스템은 ROS (Robot Operating System) 기반의 아키텍처를 사용합니다. 주요 컴포넌트로는 사용자의 음성 요구를 텍스트로 변환하고 로봇의 응답을 음성으로 변환하는 Talker 노드, 사용자 세션 동안 발생한 이벤트 데이터를 기록하고 조직하는 ContextStore, 작업을 관리하는 TaskER, 의도를 저장하는 TaskDatabase (TD), 자연어 처리를 담당하는 LangProc 등이 있습니다. LangProc는 GPT-4 API를 사용하여 사용자 요청을 처리하고 시스템 작업을 위한 프롬프트를 구성합니다.

- **Performance Highlights**: 제안된 시스템은 '물건 가져오기'와 같은 시나리오에서 효과적으로 작동하였으며, 예기치 않은 질문에 적절하게 대응하고 '설탕' 및 '레몬'과 같은 속성을 기억했습니다. 그러나 5개 이상의 매개변수가 포함된 작업에서는 성능이 저하되는 문제가 발견되었습니다. GPT-4가 때때로 부정확하거나 '환각된' 응답을 생성하는 것도 관찰되었습니다.



### Navigating Beyond Instructions: Vision-and-Language Navigation in Obstructed Environments (https://arxiv.org/abs/2407.21452)
Comments:
          Accepted to MM 2024

- **What's New**: R2R-UNO라는 새로운 데이터셋 및 작업이 소개되었습니다. 이는 기존 Vision-and-Language Navigation (VLN) 시스템에서 자주 발생하는 실시간 동적 장애 요소를 포함시켜, 실제 환경과 지침 간의 불일치를 반영합니다. 이를 통해 에이전트가 예상치 못한 장애물을 효과적으로 대응할 수 있습니다.

- **Technical Details**: R2R-UNO 데이터셋은 R2R 데이터셋의 내비게이션 그래프와 시각적 관측을 수정해 다양한 장애요소를 통합합니다. 또한, 텍스트-이미지 인페인팅(inpainting) 기술을 사용하여 다양한 물체를 원활하게 장면에 삽입하고, 필터링 모듈을 통해 고품질의 장애물을 선택할 수 있게 설계했습니다. 추가로, 새로운 방법인 ObVLN(Obstructed Vision-and-Language Navigation)을 제안하여 커리큘럼 학습 전략(curriculum training strategy)과 가상 그래프 구축 메커니즘을 도입했습니다.

- **Performance Highlights**: R2R-UNO 데이터셋을 사용한 실험 결과, 기존 최첨단 VLN 에이전트가 장애 환경에서 큰 어려움을 겪는 것으로 나타났습니다. 반면, ObVLN을 사용한 에이전트는 원래 환경에서도 강력한 성능을 유지하면서, 예상치 못한 장애물에도 효과적으로 적응해 67%의 성공률(Success Rate, SR)을 기록하며 상당한 성능 향상을 이뤘습니다. 이는 기존 데이터셋과의 비교에서 23%의 성능 향상을 의미합니다.



### MLLM Is a Strong Reranker: Advancing Multimodal Retrieval-augmented Generation via Knowledge-enhanced Reranking and Noise-injected Training (https://arxiv.org/abs/2407.21439)
- **What's New**: RagLLaVA는 최신 정보를 활용하여 사실적이고 정확한 출력을 제공하는 멀티모달 리트리벌 강화 생성(Multimodal Retrieval-augmented Generation, Multimodal RAG)의 한계를 극복하는 새로운 프레임워크입니다. 이는 다양한 데이터 모달리티(텍스트, 이미지, 오디오, 비디오) 간의 컨텐츠 처리 및 생성 능력을 향상시키는 Multimodal Large Language Models(MLLMs)의 단점을 보완합니다.

- **Technical Details**: RagLLaVA는 지식증강 리랭킹(knowledge-enhanced re-ranking)과 노이즈 주입 트레이닝(noise-injected training) 방법을 통해 멀티모달 RAG의 다중 그레인 노이즈 문제(multi-granularity noisy correspondence, MNC)를 해결합니다. 리트리벌 단계에서는 CLIP을 사용하여 외부 메모리에서 top-k 이미지를 검색한 다음, 간단한 인스트럭션 템플릿으로 MLLM을 튜닝하여 리랭킹 기능을 유도합니다. 생성 단계에서는 트레이닝 과정에서 데이터 및 토큰 수준에서 시각적 노이즈를 주입하여 모델의 견고성을 향상시킵니다.

- **Performance Highlights**: RagLLaVA는 이미지 검색 및 이유 파악을 요구하는 두 개의 데이터셋 하위 집합에서 포괄적인 실험을 통해 우수한 성능을 입증했습니다. 실험 결과, RagLLaVA는 정확한 검색과 견고한 생성을 통해 기존 모델들보다 뛰어난 성능을 보여주었습니다.



### Towards interfacing large language models with ASR systems using confidence measures and prompting (https://arxiv.org/abs/2407.21414)
Comments:
          5 pages, 3 figures, 5 tables. Accepted to Interspeech 2024

- **What's New**: 본 연구는 대규모 언어 모델(LLMs)이 자동 음성 인식(ASR) 시스템에서 어떻게 사용할 수 있는지를 탐구합니다. 특히, ASR 성적표의 사후 교정을 LLMs 기반으로 수행하여 성능을 향상시키고자 합니다. 이는 단순한 n-best 리스트 재평가(Rescoring)를 넘어서는 접근법을 제안합니다.

- **Technical Details**: 연구진은 ASR 성적표의 정확도를 새로운 방식으로 개선하기 위해 Whisper 모델에서 초기 ASR 성적표를 얻어내고, OpenAI의 ChatGPT 모델(gpt-3.5-turbo 및 gpt-4-0125-preview)을 교정 작업에 사용합니다. Whisper 모델은 680,000시간의 전사된 음성을 기반으로 훈련되었으며, 문장 및 단어 수준의 신뢰 점수를 제공합니다. 모델의 최종 결과를 개선하기 위해, 문장 및 단어 수준의 신뢰도 기반 필터링 메커니즘을 도입하여 LLMs가 보다 안전하게 오류를 교정할 수 있도록 합니다.

- **Performance Highlights**: 제안된 방법은 경쟁력이 낮은 ASR 시스템에서 성능을 향상시킬 수 있음을 보여줍니다. LibriSpeech 코퍼스에서 WER(단어 오류율) 및 CER(문자 오류율) 기준으로 평가를 진행한 결과, LLMs를 통한 교정이 전반적인 성능 향상에 기여할 수 있음을 확인하였습니다.



### Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering (https://arxiv.org/abs/2407.21368)
- **What's New**: 최근 몇 년간 큰 성과를 거둔 대규모 비전-언어 모델(LVLMs)이 의료 분야로 확장되었습니다. 하지만, 이들 모델은 환각(hallucination) 문제로 인해 복잡한 병리학 진단에 실패하는 경우가 많습니다. 본 연구에서는 이러한 문제를 해결하기 위해 두 가지 프롬프트 전략을 제안합니다. 첫 번째 전략은 질의된 병리학에 대한 상세 설명을 제공하는 것이며, 두 번째 전략은 저비용 약한 학습기(weak learner)를 조정하여 특정 지표에서 높은 성능을 달성하게 한 후, 그 판단을 텍스트로 MLVLM에 전달하는 것입니다.

- **Technical Details**: 첫 번째 프롬프트 전략은 질의된 병리학에 대한 세부 설명을 추가하여 모델의 이해도를 높입니다. 두 번째 전략은 추가 약한 학습기를 별도의 에이전트로 사용하여, 그 모델이 부정적인 이미지를 정확하게 식별하도록 하고, 결과를 프롬프트에 참조로 제공하는 것입니다. 이 전략들은 MIMIC-CXR-JPG와 Chexpert 데이터셋에서 테스트되었으며, F1 점수를 크게 향상시켰습니다. 특히 POPE 지표에 따라 일반 LVLM 도메인에까지 확장될 수 있음을 보여줍니다.

- **Performance Highlights**: 제안된 프롬프트 전략들은 MIMIC-CXR-JPG와 Chexpert 데이터셋에서 테스트되었으며, 다수의 병리학 카테고리에서 F1 점수가 0.27까지 향상되었습니다. 일반 도메인에서도 유사한 전략을 사용하여 거짓 부정(False Negative) 예측을 억제하고, Recall을 약 0.07만큼 향상시켰습니다. 이는 모델이 보다 정교한 진단과 질문 응답을 수행할 수 있도록 도움을 줍니다.



### Multi-Level Querying using A Knowledge Pyramid (https://arxiv.org/abs/2407.21276)
- **What's New**: 본 논문은 기존 검색-증강 생성(RAG) 방법의 정밀도를 개선하기 위해 다층 지식 피라미드 접근 방식을 제안합니다. PolyRAG이라 명명된 이 방법은 온톨로지(Ontologies), 지식 그래프(Knowledge Graphs), 청크 기반 원시 텍스트의 세 가지 레이어로 구성된 지식 피라미드를 사용하며, 이를 통해 정밀도와 재현율 간의 균형을 도모합니다. 두 개의 도메인별 지식 검색 벤치마크(학술 및 금융 도메인)를 도입하여 성능을 평가했습니다.

- **Technical Details**: PolyRAG 접근 방식은 지식 피라미드의 최상위에서 시작하여 확신을 가질 때까지 하위 레이어로 진행하는 워터폴 모델을 따릅니다. 온톨로지, 지식 그래프, 청크 기반 텍스트의 세 가지 레이어로 나누어 크로스 레이어 증강(Cross-layer augmentation) 기법을 사용하여 지식의 포괄적 포함과 동적인 온톨로지 스키마 및 인스턴스 업데이트를 수행합니다. 또한, 지식 응축을 위해 크로스 레이어 필터링 기법을 활용합니다.

- **Performance Highlights**: PolyRAG는 전체적인 실험을 통해 기존의 19가지 SOTA 방법보다 우수한 성능을 입증했으며, 특히 GPT-4의 F1 점수를 0.1636에서 0.8109로 향상시켜 395%의 성능 향상을 보였습니다.



### Advancing Vietnamese Visual Question Answering with Transformer and Convolutional Integration (https://arxiv.org/abs/2407.21229)
Comments:
          Accepted at the journal of Computers & Electrical Engineering (Received 8 March 2024, Revised 8 June 2024, Accepted 10 July 2024)

- **What's New**: 이번 연구에서는 베트남어 비주얼 질문 응답(Vietnamese Visual Question Answering, ViVQA) 데이터셋에 대한 종합적인 실험을 통해 우리 모델의 효과를 입증하고자 했습니다. 특히 이미지 표현 역량을 강화하고, ViVQA 시스템의 전반적인 성능을 개선하는 모델을 개발했습니다.

- **Technical Details**: 우리 모델은 BLIP-2과 EfficientNet을 결합하여 이미지를 처리하고 지역 및 글로벌 특징들을 추출합니다. 이를 통해 트랜스포머 기반 아키텍처(Transformer-based architectures)의 강점을 활용해 포괄적인 맥락 정보를 포착하고, 컨볼루션 신경망(CNN)을 통해 세부적인 지역 특징을 포착합니다. 이러한 모델의 파라미터는 고정(frozen) 상태로 둬서 계산 비용과 학습 시간을 줄이면서도 높은 성능을 유지할 수 있습니다. 정보 융합을 위해 BEiT-3을 기반으로 한 멀티모달 융합 모듈(multi-modal fusion module)을 사용합니다.

- **Performance Highlights**: 우리 모델은 ViVQA 데이터셋의 테스트 세트에서 71.04%의 정확도를 기록하여 경쟁 모델들을 능가하며, 이 분야에서의 연구에 중요한 진전을 가져왔습니다.



### GenRec: Generative Personalized Sequential Recommendation (https://arxiv.org/abs/2407.21191)
- **What's New**: GenRec는 '사전 훈련, 프롬프트, 예측'의 최근 패러다임에 영감을 받아, 연속 추천을 시퀀스-투-시퀀스(sequence-to-sequence) 생성(task)으로 간주하고, 새로운 모델을 제안했습니다. 이 모델은 사용자 및 항목의 명시적 표현을 학습하는 기존의 분류 기반 모델과 달리, Transformer의 시퀀스 모델링 능력을 활용하고, masked item prediction 목표를 채택하여 숨겨진 양방향 시퀀스 패턴을 효과적으로 학습합니다.

- **Technical Details**: GenRec는 수동으로 설계된 하드 프롬프트(hard prompts)에 의존하지 않으며, 텍스트 형식의 사용자 항목 시퀀스를 입력으로 받고, 상위 순위의 다음 항목을 출력으로 제공합니다. 이 모델은 Transformer 기반의 인코더-디코더(encoder-decoder)를 백본으로 사용하며, 시퀀스-투-시퀀스 생성(task)으로 연속 추천을 공식화합니다. 클로즈(cloze) 과제를 훈련 목표로 사용하여 모델을 사전 훈련시키고, 양방향 시퀀스 패턴을 학습합니다.

- **Performance Highlights**: GenRec는 공공의 실제 데이터셋에서 확실하게 일반화되어 최첨단 성과를 달성했습니다. 이 모델은 경량이며, 로우 리소스 환경에서 몇 시간만에 효과적으로 학습할 수 있어, 실제 시나리오 적용에 매우 유리하며, 연속 추천 도메인에서 대형 언어 모델의 민주화를 촉진할 수 있습니다.



### Apple Intelligence Foundation Language Models (https://arxiv.org/abs/2407.21075)
- **What's New**: 애플이 다양한 Apple Intelligence 기능을 지원하기 위해 개발한 새로운 기초 언어 모델(foundation language models)을 발표했습니다. 이 모델들 중에는 약 30억 매개변수를 가진 모바일 기기용 모델(AF-on-device)과 프라이빗 클라우드 컴퓨팅을 위한 대형 서버 기반 모델(AF-server)이 포함됩니다. 이 모델들은 다양한 작업을 효율적이고 정확하게 수행하는 데 중점을 두고 있습니다.

- **Technical Details**: AFM 기초 모델은 Transformer 아키텍처를 기반으로 한 dense decoder-only 모델로 설계되었습니다. 주요 설계 선택사항들은 다음과 같습니다: 입력/출력 임베딩 매트릭스를 공유하여 메모리 사용량을 줄이고, Pre-Normalization과 RMSNorm을 사용하여 학습 안정성을 개선했습니다. 그룹화된 쿼리 어텐션(GQA)과 SwiGLU 활성화 함수를 사용하여 효율성을 높였으며, 긴 문맥 지원을 위해 RoPE positional embeddings를 사용했습니다.

- **Performance Highlights**: 모델의 성능을 높이기 위해 데이터 품질과 효율성에 집중했습니다. 데이터는 출판사로부터 라이선스 받은 데이터, 공개적으로 제공되는 데이터셋, 그리고 Applebot을 통해 수집된 공개 정보들로 구성되어 있습니다. 또한, 사용자 프라이버시 보호를 위해 많은 노력을 기울였으며, 안전하지 않거나 개인 식별 정보가 포함된 자료들을 철저히 걸러냈습니다.



### Enhancing Adversarial Text Attacks on BERT Models with Projected Gradient Descen (https://arxiv.org/abs/2407.21073)
Comments:
          This paper is the pre-reviewed version of our paper that has been accepted for oral presentation and publication in the 4th IEEE ASIANCON. The conference will be organized in Pune, INDIA from August 23 to 25, 2024. The paper consists of 8 pages and it contains 10 tables. It is NOT the final camera-ready version that will be in IEEE Xplore

- **What's New**: 이 논문에서는 BERT-Attack 프레임워크를 수정하여, Projected Gradient Descent (PGD)을 통합한 PGD-BERT-Attack을 제안합니다. 이 새로운 방법은 기존의 BERT-Attack의 한계를 극복하고 공격의 효과성과 강건성을 향상시킵니다.

- **Technical Details**: 기존의 BERT-Attack은 고정된 교란(budget) 한계와 의미적 유사성을 고려하지 않는 문제점을 가지고 있습니다. 이를 해결하기 위해 PGD-BERT-Attack은 PGD를 활용하여 순차적으로 적대적 예시(adversarial examples)를 생성합니다. 이 과정에서는 교란이 거의 눈에 띄지 않으면서도 원본 입력과 의미적으로 유사한 예시를 보장합니다.

- **Performance Highlights**: PGD-BERT-Attack은 원래의 BERT-Attack 및 다른 기준 방법들과 비교하여 더 높은 성공률로 오분류를 유발하면서도 지각적 변화는 낮게 유지됩니다. 또한, 생성된 적대적 예시는 원래 입력과 의미적 유사도가 높아 실세계 시나리오에서의 적용성이 개선됩니다.



### Beyond Metrics: A Critical Analysis of the Variability in Large Language Model Evaluation Frameworks (https://arxiv.org/abs/2407.21072)
Comments:
          15 pages, 3 figures

- **What's New**: 이 논문은 대형 언어 모델(LLMs)의 평가 방법론에 대한 심층 분석을 제공합니다. 최신 NLP 기술 발전에 따라 다양한 평가 프레임워크와 벤치마크 테스트가 등장했습니다. 이 논문은 이러한 평가 방법론들의 장점과 한계, 그리고 NLP 발전에 미치는 영향을 탐구합니다.

- **Technical Details**: LLMs의 성능 평가에는 여러 가지 언어 과제, 모델 아키텍처, 벤치마킹 방법론 등을 신중하게 고려해야 합니다. 기존의 전통적인 메트릭(metric)은 LLM의 언어 이해력, 유창성, 문맥 일관성 등을 충분히 포착하지 못하기 때문에 더욱 정교한 평가가 요구됩니다.

- **Performance Highlights**: 특히, 여러 오픈 소스 언어 모델들(GPT, Llama, Falcon 등)을 사용하여 다중 선택 질문(multiple-choice question) 데이터 세트에서의 성능을 평가하였습니다. 이를 통해 모델의 정확도 메트릭(accuracy metrics)의 계산 방법론을 자세히 분석하였고, 이것이 모델의 성능과 평가 결과의 해석에 미치는 영향을 연구했습니다.



### Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned (https://arxiv.org/abs/2407.21040)
- **What's New**: NL2SQL 분야는 자연어 명령을 실행 가능한 SQL 스크립트로 변환하는 데 큰 진전을 이루었지만, 데이터 쿼리, 분석, 시각화 및 보고를 포함한 보다 폭넓은 데이터 과학 파이프라인의 완전한 자동화는 여전히 복잡한 과제입니다. 본 연구에서는 이러한 데이터 과학 파이프라인을 자동화하는 SageCopilot 시스템을 도입합니다. SageCopilot은 Large Language Models (LLMs), Autonomous Agents (AutoAgents), 그리고 Language User Interfaces (LUIs) 를 통합하여 작동합니다.

- **Technical Details**: SageCopilot은 두 단계 설계를 채택하고 있습니다. 첫 번째 단계는 온라인 컴포넌트로, 사용자 입력을 In-Context Learning (ICL)을 통해 실행 가능한 스크립트로 정제하고, 이러한 스크립트를 실행하여 결과 보고 및 시각화를 수행합니다. 두 번째 단계는 오프라인 준비 단계로, 온라인 단계에서 ICL이 요청한 데모를 준비합니다. Chain-of-Thought 및 prompt-tuning과 같은 최신 전략들이 SageCopilot의 성능 향상을 위해 사용되었습니다.

- **Performance Highlights**: 엄격한 테스트 및 프롬프트 기반 솔루션과의 비교 분석을 통해, SageCopilot이 스크립트 생성 및 실행, 결과 시각화 제공에서 뛰어난 종단 간 성능을 달성했음을 입증했습니다. 실제 데이터 세트를 통해 뒷받침된 심층 분석 연구들에서 SageCopilot의 다양한 컴포넌트와 전략 각각이 데이터 과학의 종단 간 정확성에 기여하는 바를 강조했습니다.



### Multi-Grained Query-Guided Set Prediction Network for Grounded Multimodal Named Entity Recognition (https://arxiv.org/abs/2407.21033)
Comments:
          11 pages, 5 figures

- **What's New**: Grounded Multimodal Named Entity Recognition(GMNER)라는 정보 추출(IE) 작업 분야에서, 최신 연구들은 MRC 기반 프레임워크나 시퀀스 생성 기반 모델을 사용하고 있지만, 이러한 방법들은 멀티모달 엔티티 간의 관계 이해에 어려움을 겪고 있습니다. 이에 본 연구는 MQSPN(Multi-grained Query-guided Set Prediction Network)을 제안해 intra-entity와 inter-entity 수준에서 적절한 관계를 학습하는 새로운 통합 프레임워크를 소개합니다.

- **Technical Details**: MQSPN은 Multi-grained Query Set(MQS)와 Multimodal Set Prediction Network(MSP), 그리고 Query-guided Fusion Net(QFNet)으로 구성됩니다. MQS는 특정 타입 세분화된 쿼리들과 학습 가능한 엔티티 세분화된 쿼리를 결합하여 intra-entity 연결을 강화합니다. MSP는 GMNER를 집합 예측(set prediction) 문제로 재구성하여 inter-entity 관계를 글로벌 매칭 관점에서 적절하게 모델링합니다. QFNet은 텍스트와 시각적 정보를 각각 적절하게 통합하여 노이즈를 줄이는 역할을 합니다.

- **Performance Highlights**: 제안된 MQSPN 프레임워크는 기존 SOTA(State-of-the-Art) 방법들보다 우수한 성능을 기록했습니다. 특히, 어려운 fine-grained GMNER benchmark에서 2.83%의 F1 점수를 향상시켰습니다.



### LLM-Find: An Autonomous GIS Agent Framework for Geospatial Data Retrieva (https://arxiv.org/abs/2407.21024)
- **What's New**: 새롭게 등장한 대형 언어 모델(LLMs)에 의해, 자율적인 GIS 에이전트 (Geographic Information Systems agents)가 공간 분석과 지도 제작 작업을 수행할 수 있는 잠재력이 높아졌습니다. 본 연구는 이러한 GIS 에이전트를 완전 자율적으로 지원하기 위한 연구 격차를 해결하고자 하며, 특히 필수적인 공간 데이터를 자동으로 발견하고 다운로드할 수 있는 방법을 제안합니다. 이를 위해 LLM-Find라는 자율 GIS 에이전트 프레임워크를 제안했습니다.

- **Technical Details**: LLM-Find는 LLM을 의사결정자로 활용하여, 사전 정의된 소스 리스트에서 적절한 데이터 소스를 선택하고 데이터를 추출합니다. 각 데이터 소스는 데이터 검색을 위한 메타데이터와 기술적 세부사항이 기록된 핸드북을 포함합니다. 이 프레임워크는 플러그 앤 플레이 (plug-and-play) 방식으로 설계되어 유연성과 확장성이 보장됩니다. 자동 데이터 스크롤러 또는 인간 사용자가 새로운 핸드북을 추가함으로써 새로운 데이터 소스를 쉽게 추가할 수 있습니다.

- **Performance Highlights**: 개발된 프로토타입 에이전트는 OpenStreetMap, 미 행정 경계 및 인구 통계 데이터, ESRI World Imagery의 위성 베이스맵, 상업 제공자가 제공한 기상 데이터, NYTimes GitHub의 COVID-19 데이터를 포함한 다양한 소스에서 데이터를 성공적으로 검색하는 능력을 입증했습니다. 이 연구는 자율적인 지리 공간 데이터 검색 에이전트를 개발한 최초의 시도 중 하나입니다.



### ThinK: Thinner Key Cache by Query-Driven Pruning (https://arxiv.org/abs/2407.21018)
Comments:
          20 pages, 6 figures

- **What's New**: 이 논문에서는 대형 언어 모델 (LLMs)의 KV 캐시 (KV cache) 메모리 소비 비효율성을 해결하는 새로운 방법, 'ThinK'를 제안합니다. 특히, 길고 복잡한 시퀀스를 다루는 과정에서 발생하는 메모리 및 계산 비용 문제를 다룹니다.

- **Technical Details**: 'ThinK'는 쿼리 의존적인 KV 캐시 프루닝 방식으로, 채널 차원에서 발생하는 중복성을 줄이는 방법입니다. 이러한 중복성은 모듈 내에서 불균형한 크기 분포와 낮은 랭크 구조에 의해 특징지어집니다. ThinK는 주의 가중치 손실을 최소화하면서 가장 중요하지 않은 채널을 선택적으로 제거할 수 있도록 설계되었습니다.

- **Performance Highlights**: 제안된 ThinK 방식은 모델의 정확도를 유지하거나 향상시키면서, 기존 KV 캐시 교체 방법과 비교하여 메모리 비용을 20% 이상 절감합니다. LLaMA3와 Mistral 모델을 사용한 다양한 긴 시퀀스 데이터셋에서의 평가를 통해 ThinK의 효율성이 입증되었습니다. 또한, ThinK의 가치 캐시 프루닝 (value cache pruning)으로 확장 가능한 가능성도 제시하며, 메모리와 계산 오버헤드 모두를 줄이는 데 있어서의 광범위한 적용 가능성을 보여줍니다.



### Evolver: Chain-of-Evolution Prompting to Boost Large Multimodal Models for Hateful Meme Detection (https://arxiv.org/abs/2407.21004)
- **What's New**: 최근의 연구에 따르면 Two-Stream 접근법(Two-stream approaches)이 혐오성 밈 탐지(hateful meme detection)에서 뛰어난 성과를 보이고 있습니다. 그러나 새로운 문화적 아이디어가 융합된 신종 밈이 지속적으로 등장함에 따라 기존 방법들이 효과를 발휘하지 못하거나 구시대적인 방법이 되고 있습니다. 이에 본 연구는 대규모 멀티모달 모델(Large Multimodal Models, LMMs)을 활용한 혐오성 밈 탐지의 가능성을 탐구하는 내용을 담고 있습니다.

- **Technical Details**: 본 연구에서는 'Evolver'라는 새로운 접근법을 제안합니다. Evolver는 LMMs를 체인 오브 에볼루션(Chain-of-Evolution, CoE) 프롬팅(Prompting) 방식으로 통합하여 밈의 진화 속성과 맥락적 정보를 활용합니다. Evolver는 밈의 진화 및 표현 과정을 시뮬레이션하고, 단계를 거치며 LMMs로 추론합니다. 구체적으로, 첫째로 진화쌍 마이닝 모듈(evolutionary pair mining module)이 입력된 밈과 외부의 큐레이션된 밈 세트에서 가장 유사한 상위 k개의 밈을 검색합니다. 둘째로 진화 정보 추출기(evolutionary information extractor)가 페어링된 밈들 사이의 의미 규칙을 요약하고 프롬트를 작성합니다. 마지막으로 맥락적 관련성 증폭기(contextual relevance amplifier)를 통해 진화 과정의 탐색을 촉진하는 혐오성 정보의 맥락적 관련성을 높입니다.

- **Performance Highlights**: 공개된 FHM, MAMI, HarM 데이터셋에서 수행된 광범위한 실험 결과 CoE 프롬팅이 기존 LMMs에 통합될 경우 성능을 향상시킬 수 있음을 보여주었습니다. 더욱 고무적인 것은 CoE 프롬팅이 해석 도구로써 소셜 밈의 진화를 이해하는 데 기여할 수 있다는 점입니다.



### Enabling Contextual Soft Moderation on Social Media through Contrastive Textual Deviation (https://arxiv.org/abs/2407.20910)
- **What's New**: 본 논문에서는 기존 자동 소프트 중재 시스템(soft moderation systems)에 입장 탐지(stace detection)를 추가하여 문맥적인 오탐지(false positives)를 줄이고 더 정확한 경고를 제공하는 방법을 제안합니다. 새로운 접근법으로 텍스트 편차 작업(textual deviation task)인 대조 텍스트 편차(Contrastive Textual Deviation, CTD)를 개발하였습니다.

- **Technical Details**: CTD는 텍스트의 입장을 더욱 정밀하게 탐지하여 기존 입장 탐지 방법보다 우수한 성능을 보입니다. 이를 최신 자동 소프트 중재 시스템인 Lambretta에 통합하여 테스트해 보았습니다.

- **Performance Highlights**: CTD를 통합한 새로운 시스템은 문맥적인 오탐지를 기존의 20%에서 2.1%로 크게 줄였습니다. 이를 통해 더욱 신뢰할 수 있는 소셜 미디어 중재 도구의 구축에 중요한 기여를 할 수 있습니다.



### Automated Review Generation Method Based on Large Language Models (https://arxiv.org/abs/2407.20906)
Comments:
          16 pages, 3 figures, 3 tables

- **What's New**: 이번 연구에서는 Large Language Models (LLMs)을 기반으로 문헌 리뷰를 자동으로 생성하는 방법을 제안했습니다. 이는 PDH 촉매 관련 연구에서 343개의 논문을 빠르게 분석하고, 평균적으로 계정 당 몇 초 만에 포괄적인 리뷰를 작성하는 성과를 보였습니다.

- **Technical Details**: 이 방법은 LLM의 '환각(Hallucination)' 문제를 인식하여 다층 품질 관리 전략을 사용하였습니다. LLM의 정확성을 높이고 잘못된 정보를 줄이기 위해 전문가 검증을 통하여 생성된 리뷰의 정확성과 인용의 일관성을 확인했습니다. 또한, LLM '환각' 발생 비율을 0.5% 이하로 줄일 수 있음을 확인했으며, 95% 이상의 신뢰도를 보였습니다.

- **Performance Highlights**: 이 방법을 통해 한 번에 깊이 있는 문헌 리뷰를 생성할 수 있는 Windows 애플리케이션을 출시하였습니다. 이는 연구자들이 최신 연구 동향을 추적하고 추천 문헌을 찾는 데 큰 도움을 주며, 과학 연구 생산성을 높이는 데 큰 기여를 할 것으로 기대됩니다.



### Effective Black Box Testing of Sentiment Analysis Classification Networks (https://arxiv.org/abs/2407.20884)
Comments:
          This paper uses LaTeX with the IEEEtran.cls document class

- **What's New**: 이 논문은 트랜스포머 기반의 감정 분석 네트워크를 위한 테스트 수트(test suite)를 평가하기 위해 설계된 커버리지 기준(coverage criteria)를 제시합니다. 이 접근 방식은 감정과 관련된 언어적 특성(예: 동사, 형용사, 부사, 명사)을 고려한 입력 공간 분할(input space partitioning)을 이용한 블랙박스 방법입니다.

- **Technical Details**: 테스트 케이스를 효과적으로 생성하기 위해 k-프로젝션 커버리지 메트릭(k-projection coverage metric)을 사용합니다. 이 메트릭은 동일한 시간에 k 특성의 하위 집합을 조사하여 문제의 복잡성을 줄입니다. 큰 언어 모델(large language models)을 사용하여 특정 감정적 특성 조합을 나타내는 문장을 생성합니다.

- **Performance Highlights**: 감정 분석 데이터셋에서 얻은 실험 결과, 제안된 기준과 생성된 테스트는 테스트 커버리지가 평균 16% 증가하였으며, 모델의 정확도가 평균 6.5% 감소하는 결과를 보여주었습니다. 이는 취약성을 식별하는 능력을 나타냅니다.



### Meltemi: The first open Large Language Model for Greek (https://arxiv.org/abs/2407.20743)
- **What's New**: Meltemi 7B는 그리스어에 특화된 최초의 오픈라지 언어모델(Large Language Model)로, 70억 개의 파라미터를 갖추고 있으며, 40억 토큰의 그리스어 코퍼스(corpus)로 훈련되었습니다. Meltemi 7B는 최신 정보(2023년 9월까지)를 포함하고 있습니다. 또한 그리스어 설명 데이터를 번역 및 정제하여 Meltemi 7B Instruction 모델을 튜닝했습니다.

- **Technical Details**: Meltemi 7B의 개발은 Mistral 모델을 기초로 하여 계속적인 사전 훈련을 통해 이루어졌습니다. Meltemi 7B Instruct 모델의 경우, 유도 튜닝(instruction-tuning)을 위해 그리스어 설명 코퍼스가 사용되었습니다. 유해한 내용의 제거와 정렬(alignment)에 특별히 신경을 썼습니다.

- **Performance Highlights**: 개발된 모델들은 포괄적인 평가 코퍼스에 대해 평가되었으며, 프롬프트(prompt)와 응답(response)의 예시가 제공되었습니다. Meltemi 7B와 Meltemi 7B Instruct는 Apache 2.0 라이선스 하에 공개되어 있습니다.



### Adapting Safe-for-Work Classifier for Malaysian Language Text: Enhancing Alignment in LLM-Ops Framework (https://arxiv.org/abs/2407.20729)
- **What's New**: 오늘 소개할 논문은 말레이시아어(LLM-Ops)를 지원하기 위해 개발된 새로운 '세이프 포 워크(Safe-for-Work)' 텍스트 분류기입니다. 이 모델은 말레이시아어로 작성된 잠재적으로 부적절하거나 안전하지 않은 콘텐츠를 탐지할 수 있는 능력을 가지고 있습니다.

- **Technical Details**: 연구진은 다양한 콘텐츠 카테고리를 아우르는 최초의 말레이시아어 텍스트 데이터셋을 큐레이팅하고 주석을 달았습니다. 이 데이터셋을 기반으로 최신 자연어 처리 기술(State-of-the-art natural language processing techniques)을 사용해 텍스트 분류 모델을 훈련시켰습니다.

- **Performance Highlights**: 말레이시아어 환경에서의 LLM 배포와 관련된 잠재적 위험을 완화하고 안정적인 상호작용을 보장하는 데 중요한 역할을 할 것으로 기대됩니다. 또한, 모델은 공개되어 누구나 접근할 수 있으며 추가 연구를 촉진할 수 있습니다.



### Label-Guided Prompt for Multi-label Few-shot Aspect Category Detection (https://arxiv.org/abs/2407.20673)
- **What's New**: 다중 라벨 소수 샘플 (Multi-label few-shot) 측면 범주 감지 (aspect category detection) 작업에서, 문장 및 범주의 표현이 중요 문제로 나타났습니다. 현재 방법들 대부분은 키워드 추출에 의존하지만, 이 방법은 문장에서 범주와 상관 없는 단어까지 포함하게 되어 최적의 성능을 내기 어렵습니다. 대신, 이 논문은 라벨 유도 프롬프트 (label-guided prompt) 방법을 제안하여 문장 및 범주 표현을 개선합니다.

- **Technical Details**: 제안된 방법은 라벨 특정 프롬프트를 사용하여 문장을 결정적 맥락 및 의미 정보와 결합하여 표현합니다. 이 라벨은 대형 언어 모델 (large language model) 을 활용하여 범주의 특징을 포함한 범주 설명을 생성하는 데 사용됩니다. 이 범주 설명은 차별적인 범주 원형 (category prototypes) 구축을 안내합니다.

- **Performance Highlights**: 제안된 방법은 두 개의 공개 데이터셋에서 실험 결과 현재 최첨단 방법들을 3.86% - 4.75%의 Macro-F1 점수로 능가하는 성능을 보여주었습니다.



### ArabicNLU 2024: The First Arabic Natural Language Understanding Shared Task (https://arxiv.org/abs/2407.20663)
Comments:
          In Proceedings of the Second Arabic Natural Language Processing Conference (ArabicNLP 2024), Bangkok, Thailand. Association for Computational Linguistics

- **What's New**: 이번 논문은 Arabic Natural Language Understanding (ArabicNLU 2024) 공유 작업에 대한 개요를 다루며, 두 가지 하위 작업인 단어 의미 중의성 해소 (Word Sense Disambiguation, WSD) 및 위치 언급 중의성 해소 (Location Mention Disambiguation, LMD)에 중점을 둡니다. 이 작업은 자동화 시스템이 아랍어 텍스트에서 단어의 중의성을 해결하고 언급된 위치를 식별하는 능력을 평가하는 것에 목적을 두고 있습니다.

- **Technical Details**: 참여자들에게 제공된 새로운 데이터셋에는 약 34,000개의 주석이 달린 단어들로 구성된 의미 주석 말뭉치인 SALMA와 3,893개의 주석과 763개의 고유 위치 언급을 포함하는 IDRISI-DA 데이터셋이 있습니다. 총 38개의 팀이 등록했으나, 최종 평가 단계에는 세 팀만이 참여하였습니다.

- **Performance Highlights**: WSD 작업의 최고 정확도는 77.8%였으며, LMD 작업의 최고 MRR@1 (Mean Reciprocal Rank at 1)은 95.0%를 기록했습니다. 이 공유 작업은 다양한 기술의 평가 및 비교를 용이하게 했을 뿐만 아니라 아랍어 NLU 기술의 지속적인 발전을 위한 귀중한 통찰력과 자원을 제공하였습니다.



### Prompting Encoder Models for Zero-Shot Classification: A Cross-Domain Study in Italian (https://arxiv.org/abs/2407.20654)
Comments:
          Submitted to 'Language Resource and Evaluation'

- **What's New**: 이 논문은 이탈리아어 법률 및 행정 언어에 특화된 도메인별 엔코더 언어 모델(encoder LMs)을 사용하여 성능을 향상시키는 방법을 탐구합니다. 이는 일반적으로 영어 코퍼스에 기반을 둔 대형 언어 모델(LLMs)의 한계를 보완하고자 합니다. 특히, 도메인 특화된 소형 모델과 프롬프트(prompting) 기술을 결합하여 효율성을 높이는 가능성을 실험하였습니다.

- **Technical Details**: 연구는 문서 분류(document classification)와 엔티티 타이핑(entity typing)과 같은 다운스트림 작업에서 일반 목적의 모델과 추가로 사전 훈련된 전용 엔코더-온리 모델(encoder-only models)을 평가하였습니다. 또한, 의사 로그 가능성(Pseudo-Log-Likelihood)을 사용하여 내적 평가를 수행하였습니다. 추가 사전 훈련된 모델은 일반 지식에서는 강건성이 떨어질 수 있지만, 도메인 특화된 작업에는 더 우수한 적응성을 보입니다.

- **Performance Highlights**: 도메인 특화된 모델은 제로샷(zero-shot) 설정에서도 뛰어난 성능을 발휘하였으며, 보정 기법(calibration techniques)과 인도메인 도메인 전용 단어(in-domain verbalizers)의 적용으로 효율성이 크게 향상되었습니다. 이러한 도메인 특화된 모델은 특히 인도메인 자원이나 전문 지식이 부족한 상황에서 매우 유용합니다.



### Decoding Linguistic Representations of Human Brain (https://arxiv.org/abs/2407.20622)
- **What's New**: 이 논문은 뇌의 활동을 텍스트와 음성 형식으로 디코딩하는 방법의 분류 체계를 제안합니다. 최근에 신경영상(neuroimaging), 의학기술, 생명과학, 인공지능의 급격한 발전 덕분에 뇌에서 발생하는 언어적 표현을 디코딩하는 분야에서 획기적인 성과가 있었습니다. 이 연구는 언어 이해에 초점을 맞춘 신경과학(neuroscience) 연구와 딥러닝 기반 뇌 디코딩 연구를 통합하여 제시합니다.

- **Technical Details**: 이 작업은 신경과학과 딥러닝을 결합하여 뇌 활동으로부터 인지 가능한 언어 정보를 생성하는 프로세스를 분석합니다. 논문은 특히 구체적인 언어인지에 대한 미시적 이해를 제공하며 이를 통해 신경과학자와 딥러닝 연구자들이 뇌 처리와 언어 디코딩에 대한 추가 조사를 용이하게 할 수 있도록 합니다.

- **Performance Highlights**: 이 논문은 ALS(근위축성측삭경화증) 환자와 같이 발음이 제한된 사람들을 돕는 데 크게 기여할 수 있는 가능성을 엿보게 합니다. 또한, 차세대 뇌-컴퓨터 인터페이스(BCI)로의 새로운 접근 방법을 제시합니다.



### Enhancing Agricultural Machinery Management through Advanced LLM Integration (https://arxiv.org/abs/2407.20588)
Comments:
          10 pages

- **What's New**: 인공지능(AI)을 농업에 통합하는 새로운 접근방식을 제안합니다. 특히 최신 대형 언어 모델(Large Language Models, LLMs), 예를 들어 GPT-4와 다중 라운드 프롬프트 엔지니어링(multi-round prompt engineering)을 결합하여 농업 기계 관리의 의사 결정 과정을 향상시키는 방법을 소개합니다. 이 접근 방식은 시스템적으로 개발되고 정제된 프롬프트를 사용하여 LLMs가 정확하고 문맥적으로 관련성 있는 출력을 생성할 수 있도록 합니다.

- **Technical Details**: 이 연구에서는 다양한 온라인 출처에서 수집한 수작업으로 작성된 데이터셋을 사용하여 우리의 접근 방식을 평가했습니다. GPT-4, LLama-2-70B, ChatGPT 모델과 함께 기본 및 최신 상태의 방법들, 예를 들어 Chain of Thought (CoT)와 Thought of Thought (ThoT)와의 비교 실험을 수행했습니다. 이 비교를 통해 우리의 프롬프트 엔지니어링 기법이 어떠한 성과를 나타내는지 분석했습니다.

- **Performance Highlights**: 우리의 방법이 CoT와 ThoT와 같은 기존 기술보다 높은 정확성과 관련성을 달성하여 농업 기계 관리에서 우수한 성능을 보인다는 결과를 얻었습니다. 이는 고급 프롬프트 엔지니어링 기술이 AI의 견고성 및 적용 가능성을 크게 개선할 수 있음을 시사합니다.



### Pruning Large Language Models with Semi-Structural Adaptive Sparse Training (https://arxiv.org/abs/2407.20584)
- **What's New**: 최근에 Transformer 기반 대형 언어 모델들(LLMs)이 다양한 어려운 과제에서 눈에 띄는 성공을 거두었습니다. 그러나, 이 모델들을 배포하는 데는 매개변수 수와 메모리 소비량이 커서 많은 제약이 따릅니다. 이를 해결하기 위해 새로운 훈련 파이프라인, Adaptive Sparse Trainer (AST)를 제안합니다. 이 방법은 모델이 훈련 중 적응적으로 더 나은 높이표(mask)를 선택하게 합니다.

- **Technical Details**: AST는 밀도 모델에서 저장된 지식을 증류(distilling)하여 드문드문한 모델의 과대적합(overfitting)을 방지하며, 안정적인 훈련 과정을 보장합니다. 또한, 추가로 잘 초기화된 매개변수를 모델에 추가하여 메모리 소비량을 약간만 증가시키면서도 성능을 향상시킬 수 있음을 발견했습니다. AST는 좁은 컴퓨팅 비용을 유지하면서도 밀도 모델과 드문 모델 간의 성능 격차를 현저히 줄입니다. 더불어, 기존의 양자화(quantization) 방법과 결합하면, AST는 dense FP32 precision 모델에 비해 최대 16배까지 언어 모델을 압축하면서도 성능의 손실을 최소화합니다.

- **Performance Highlights**: AST는 Llama2-7B 모델에서 여러 zero-shot 작업에 대해 dense와 준구조적 sparse 모델 간의 zero-shot 정확도 격차를 1.12%까지 줄이며, 사전 훈련 토큰의 0.4% 미만을 사용하면서도 이전의 최첨단 방법들보다 더 나은 성능을 보입니다.



### Knesset-DictaBERT: A Hebrew Language Model for Parliamentary Proceedings (https://arxiv.org/abs/2407.20581)
Comments:
          3 pages, 1 table

- **What's New**: Knesset-DictaBERT는 이스라엘 의회록(Knesset Corpus)을 기반으로 한 대형 히브리어 언어 모델입니다. 기존 DictaBERT 아키텍처를 기반으로 하여 의회 언어 이해 능력에서 큰 향상을 보여줍니다.

- **Technical Details**: 이 모델은 MLM(Masked Language Modeling) 임무를 통해 미세 조정(fine-tune)되었습니다. Knesset-DictaBERT는 히브리어 의회록을 사용하여 학습되었으며, 기존 DictaBERT 모델과 비교하여 perplexity와 accuracy에서 향상된 성능을 보여줍니다.

- **Performance Highlights**: 모델의 평가 결과, Knesset-DictaBERT는 perplexity와 accuracy에서 기존 DictaBERT 모델을 능가하는 성능을 발휘했습니다.



### Comparison of Large Language Models for Generating Contextually Relevant Questions (https://arxiv.org/abs/2407.20578)
Comments:
          Published in Springer ECTEL 2024 conference proceedings

- **What's New**: 이 연구는 대형 언어 모델(LLMs, Large Language Models)이 교육 환경에서 자동 질문 생성(Automatic Question Generation)에 얼마나 효과적인지를 탐구합니다. 대학 슬라이드 텍스트에서 질문을 생성하기 위해 세 가지 LLMs을 비교했습니다. 미세 조정(fine-tuning) 없이 슬라이드 텍스트에서 질문을 만들어내는 능력을 평가했습니다. 특히 LLMs의 질문 생성 능력을 조사한 것은 이번 연구가 처음입니다.

- **Technical Details**: 질문 생성은 두 단계로 수행되었습니다. 첫째, Llama 2-Chat 13B를 사용하여 슬라이드에서 답변 구를 추출했습니다. 둘째, 각 답변에 대해 세 가지 모델(GPT-3.5, Llama 2-Chat 13B, Flan T5 XXL)이 질문을 생성했습니다. 46명의 학생들이 246개의 질문을 평가하여, 명확성(clarity), 관련성(relevance), 난이도(difficulty), 슬라이드와의 관계(slide relation), 질문-답변 일치(question-answer alignment) 다섯 가지 메트릭으로 조사했습니다.

- **Performance Highlights**: 결과에 따르면, GPT-3.5와 Llama 2-Chat 13B 모델이 Flan T5 XXL 모델보다 약간 더 우수한 성능을 나타냈습니다. 특히 명확성과 질문-답변 일치 부문에서 두 모델이 우수했으며, GPT-3.5는 답변에 맞춘 질문을 만드는 데 특히 뛰어났습니다. 이번 연구는 교육용 자동 질문 생성에서 LLMs의 가능성을 분석한 점에서 큰 기여를 했습니다.



### CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledg (https://arxiv.org/abs/2407.20564)
Comments:
          9 pages

- **What's New**: 이번 연구에서는 최첨단 대형 언어 모델(LLMs)의 복잡한 논리적 추론 능력에 대한 체계적인 평가를 제시합니다. 이를 위해 자동으로 생성된 일반 도메인 및 생물의학 지식 그래프에 대한 복합 논리 추론 질문 벤치마크를 도입했습니다. 우리의 광범위한 실험은 다양한 'in-context learning' 기술을 활용하여 수행되었습니다.

- **Technical Details**: 연구에서는 'Chain-of-Thought' 시연을 통해 LLM 성능을 크게 향상시킬 수 있음을 확인했습니다. 이를 통해 LLM이 다양한 논리 연산을 포함한 복잡한 논리 추론 작업을 수행하는 능력을 보여주었습니다. 그러나 일반 지식에 대해서는 뛰어난 성과를 보였지만, 전문적인 도메인 지식(전문 용어로는 'domain-specific knowledge')에 대해서는 상당한 도전에 직면했습니다. 특히 LLM은 집합의 합집합 연산에서는 우수한 성과를 보였으나, 교집합 연산에서는 크게 고전하는 비대칭성이 발견되었습니다.

- **Performance Highlights**: LLM은 일반 세계 지식에 대한 추론에서 우수한 성과를 보였으며, 명시적인 'Chain-of-Thought' 시연을 통해 복잡한 논리 추론에서 성능을 향상할 수 있음을 실험적으로 확인했습니다. 연구 결과는 LLM의 논리 연산 능력, 특히 교집합 연산에 대한 한계를 밝혀냈습니다. 이러한 연구의 결과로, 우리는 평가 벤치마크와 코드를 공개할 예정입니다.



### Contrastive Feedback Mechanism for Simultaneous Speech Translation (https://arxiv.org/abs/2407.20524)
Comments:
          Accepted to Interspeech 2024 main conference

- **What's New**: 최근 동시 음성 번역(Simultaneous Speech Translation, SST)에서 중요한 결정 정책(decision policies)은 오프라인으로 훈련된 ST 모델을 동시에 추론하는 데 사용되었으나, 불안정한 예측으로 인해 번역 품질이 저하되는 문제를 완화하는 데 초점을 맞추고 있습니다. 이에 반해, 본 논문에서는 이러한 불안정한 예측을 번역 품질 향상에 활용하는 새로운 방법인 대조 피드백 메커니즘(Contrastive Feedback Mechanism, CFM)을 소개합니다.

- **Technical Details**: 대조 피드백 메커니즘(CFM)은 불안정한 예측을 피드백으로 활용하여 번역 품질을 개선하는 혁신적인 방법입니다. CFM은 대조적인 목적(contrastive objective)을 통해 시스템이 이러한 예측에서 발생하는 원치 않는 모델 행동을 제거하도록 안내합니다. 이는 모델이 더욱 안정적이고 정확한 번역을 생성할 수 있도록 합니다.

- **Performance Highlights**: 본 연구는 MuST-C v1.0 데이터셋에서 8개 언어를 대상으로 3가지 최신 결정 정책을 실험한 결과, CFM이 SST의 성능을 효과적으로 개선한다는 것을 보여주었습니다.



### Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Languag (https://arxiv.org/abs/2407.20513)
Comments:
          Accepted in NeSy 2024 Conference

- **What's New**: 이 논문은 복잡한 신경-기호 모델(neuro-symbolic models)을 위한 도메인 지식을 자연어 프롬프트(natural language prompts)를 통해 작성하는 대화형 파이프라인(pipeline)을 제시합니다. 대규모 언어 모델(large language models)을 활용하여 DomiKnowS 프레임워크에서 선언적 프로그램(declarative programs)을 생성합니다.

- **Technical Details**: DomiKnowS 프레임워크에서는 개념(concepts)과 그 관계(relationships)를 그래프로 표현하고, 논리적 제약(logical constraints)을 추가합니다. 생성된 그래프는 학습 가능한 신경 모델(neural models)과 연결됩니다. 본 파이프라인은 동적 맥락 내 시연 검색(dynamic in-context demonstration retrieval), 기호 구문 분석기(symbolic parser)로부터의 피드백을 기반으로 한 모델 개선, 시각화 및 사용자 상호작용 등의 기법을 활용하여 작업 구조와 공식적인 지식 표현을 생성합니다.

- **Performance Highlights**: 제안된 접근 방식은 ML/AI에 익숙하지 않은 도메인 전문가들도 DomiKnowS 프레임워크에서 맞춤형 신경 모델에 통합될 지식을 공식적으로 선언할 수 있도록 지원합니다.



### A2SF: Accumulative Attention Scoring with Forgetting Factor for Token Pruning in Transformer Decoder (https://arxiv.org/abs/2407.20485)
Comments:
          11 pages(9 pages + reference 2 pages), 6 figures

- **What's New**: 최근 트랜스포머(transformer) 기반 대형 언어 모델(LLM)에서 긴 시퀀스를 처리할 때 KV 캐시로 인한 메모리 병목 현상을 해결하기 위해 Accumulative Attention Score with Forgetting Factor (A2SF) 기법을 제안했습니다. 이 기법은 Attention Score 누적 과정에 망각 계수(Forgetting Factor)를 도입하여 토큰의 공정한 비교를 가능하게 합니다.

- **Technical Details**: A2SF 기법은 기존의 누적 어텐션 스코어가 트랜스포머 디코더 구조에 적합하지 않다는 관찰에서 비롯되었습니다. 디코더 모델에서는 마스킹 효과로 인해 토큰 등장 순서에 따라 어텐션 스코어의 누적 횟수가 달라져 토큰 간 비교의 불균형이 발생합니다. 이를 해결하기 위해 A2SF는 과거 토큰에서 생성된 어텐션 스코어에 반복적으로 망각 계수를 곱해 페널티를 적용합니다. 따라서 오래된 토큰은 큰 페널티를 받아 다양한 연령의 토큰 간에 공정한 비교가 가능합니다.

- **Performance Highlights**: A2SF 기법은 OPT 및 LLaMA 모델에서 정확도 향상을 검증했으며, 특히 LLaMA 2 모델에서 1-shot과 0-shot 학습 성능이 각각 최대 7.8%와 5.1% 향상되었습니다.



### Generating Gender Alternatives in Machine Translation (https://arxiv.org/abs/2407.20438)
Comments:
          GeBNLP 2024

- **What's New**: 이 논문은 기계 번역(MT) 시스템에서 성별 모호성 문제를 해결하기 위해 모든 문법적으로 올바른 성별 번역 대안을 생성하는 방법을 연구합니다. 이는 성별 모호성을 원활하게 해결할 수 있는 MT 사용자 인터페이스를 염두에 두고 수행되었습니다. 논문은 5개의 언어 쌍에 대한 학습 및 테스트 데이터셋을 오픈 소스로 공개하고, 이 작업에 대한 벤치마크를 설정했습니다.

- **Technical Details**: 주요 기술적 기여는 새로운 준지도(semi-supervised) 솔루션입니다. 이는 표준 MT 모델과 원활하게 통합되며, 추가 구성 요소나 추론 오버헤드를 증가시키지 않으면서 높은 성능을 유지합니다.

- **Performance Highlights**: 해당 솔루션은 성능을 저해하지 않고 MT 시스템이 성별 모호성을 효과적으로 처리할 수 있게 해줍니다. 또한, 학습 데이터에 의해 편향된 성별 번역 문제를 해결함으로써 사회적 고정관념을 반영하고 영구화하는 것을 방지합니다.



### Through the Looking Glass, and what Horn Clause Programs Found Ther (https://arxiv.org/abs/2407.20413)
- **What's New**: 이번 연구에서는 Dual Horn 절(clause)을 재검토하여, 이 절이 직관주의적(intuitionistically) 및 고전적으로(classically) 유효한 목표 지향적 전진 추론(goal-driven forward reasoning)을 지원하는 형식적인 부정을 가능하게 함을 탐구했습니다. 특히, Dual Horn 절을 사용하여 배경 이론(context) 내에서 반사실적 가설(counterfactual hypothesis)을 반증할 수 있는 능력을 중점적으로 다루고 있습니다.

- **Technical Details**: Dual Horn 절 프로그램의 실행 모델을 메타인터프리터(metainterpreter)로 명시하고, Dual Horn 절을 Horn 절로 컴파일하는 스킴을 설계하여 성능 저하 없이 실행할 수 있도록 했습니다. 또한 Horn 절과 Dual Horn 절 프로그램을 결합할 수 있는 SymLP 내장 언어도 설계했습니다. 이 접근법을 통해 계산된 답변의 변수 바인딩(variable bindings)들은 반증 성공 이유에 대한 설명(explanations)을 제공할 수 있습니다.

- **Performance Highlights**: 제안된 Dual Horn 절 프로그램은 명제 케이스(propositional case)에서 파산 모형 부정(negation as failure)을 안정 모형 의미론(stable model semantics)으로 구현한 ASP 시스템과 달리, Horn 절 프로그램과 마찬가지로 다항 시간 복잡도(polynomial complexity)를 가집니다. 이는 성능에 있어 큰 이점을 나타냅니다.



### What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models (https://arxiv.org/abs/2407.20382)
Comments:
          ACL Wordplay 2024

- **What's New**: 이 논문에서는 RPG(Role-Playing Game)에서 대사의 역할과 그 중요성을 설명하며, 대화 내용을 더 풍부하고 몰입하게 만드는 새로운 프레임워크를 소개합니다. 이 프레임워크는 LLMs(large language models)와 지식 그래프(Knowledge Graphs)를 활용해 캐릭터 간의 동적이고 맥락에 맞는 대화를 생성합니다. 주요 테스트 환경으로 Final Fantasy VII Remake와 Pokemon을 사용하였습니다.

- **Technical Details**: 새로운 프레임워크는 GPT-4를 사용하여 캐릭터가 정의된 성격을 바탕으로 대화를 생성합니다. 지식 그래프를 활용하여 캐릭터 간의 관계와 맥락을 파악하고, 이를 통해 보다 자연스럽고 상황에 맞는 대화를 생성하려는 목적입니다. 하지만 GPT-4의 성격 표현에는 몇 가지 한계가 발견되었습니다. 예를 들어, GPT-4는 지나치게 긍정적이거나 성숙함 같은 미묘한 성격은 품질이 떨어지는 경향이 있습니다.

- **Performance Highlights**: 프레임워크의 성능을 평가한 결과, GPT-4가 정의된 성격으로 행동하고 대사를 생성하는 데 있어서 유의미한 성과를 보였습니다. 질적 및 양적 evidences(증거)를 통해 그 성능을 입증했으며, 이는 게임 개발자들이 더 섬세한 대사 작성에 도움을 줄 수 있을 것으로 기대됩니다. 그러나 일부 단점도 존재하며, 이를 개선하는 연구가 필요합니다.



### An Efficient Inference Framework for Early-exit Large Language Models (https://arxiv.org/abs/2407.20272)
- **What's New**: 본 연구는 LLMs(Large Language Models)을 사용하는 과정에서 조기 종료(early-exit) 모델을 적용하는 새로운 효율적 추론 프레임워크를 제안합니다. 이는 충분히 확신할 때 나머지 레이어를 건너뛰고 바로 출력 토큰을 생성함으로써 추론 효율성을 높입니다. 이 연구는 LLM 추론 프레임워크에 조기 종료 모델을 통합하여 기존 연구와는 차별화된 점을 보여줍니다.

- **Technical Details**: 본 연구에서는 두 가지 주요 과제를 해결합니다: (1) iteration-level granularity(반복 수준의 세밀도)에서의 batch inference(배치 추론)와 (2) KV cache(키-값 캐시) 관리. 배치 추론의 경우, 모든 시퀀스가 조기 종료 신뢰도 임계치를 넘어설 때까지 배치를 처리하는 방법을 제안합니다. KV 캐시 관리에서는 반복이 종료되기 전에 나머지 레이어의 KV 캐시를 채우는 방식을 제안합니다.

- **Performance Highlights**: 본 연구에서 제안한 솔루션은 전체 레이어에서 작동하는 기존의 vLLM과 비교했을 때 최대 1.25배의 속도 향상을 보여줍니다.



### LAPIS: Language Model-Augmented Police Investigation System (https://arxiv.org/abs/2407.20248)
- **What's New**: 범죄 상황은 시간과의 싸움입니다. 경찰관들에게 신속하면서도 정확한 법률 자문을 제공할 수 있는 AI 보조 범죄 수사 시스템이 필요합니다. LAPIS (Language Model Augmented Police Investigation System)는 경찰관이 합리적이고 법적인 수사 조치를 수행할 수 있도록 지원하는 자동화 시스템입니다. 우리는 범죄 수사 법률 추론 작업에 특화된 파인튜닝 데이터셋(finetuning dataset)과 검색 지식베이스(retrieval knowledgebase)를 구축했습니다.

- **Technical Details**: 우리는 도메인 전문가 그룹의 수작업을 통해 데이터셋의 품질을 향상시켰으며, 새로운 데이터셋에 맞춰 사전에 훈련된 한국어 모델의 가중치(weights)를 파인튜닝(finetuning)했습니다. 그 후, 이 모델을 범죄 수사 지식베이스 검색 접근법과 통합했습니다. LAPIS는 실험 결과에서 경찰관에게 신뢰할 수 있는 법률 자문을 제공하는 데 있어 독점적인 GPT-4 모델보다 우수한 성능을 보여주었습니다.

- **Performance Highlights**: LAPIS가 생성한 논거(rationales)에 대한 정성적 분석은 모델이 전제(premises)를 활용하고 법적으로 올바른 결론을 도출하는 추론 능력을 갖추고 있음을 보여줍니다.



### Steamroller Problems: An Evaluation of LLM Reasoning Capability with Automated Theorem Prover Strategies (https://arxiv.org/abs/2407.20244)
- **What's New**: 이 연구는 Large Language Models (LLMs)가 Automated Theorem Provers (ATPs)의 논리 전략을 따를 수 있는 능력을 최초로 검토합니다. GPT-4, GPT-3.5 Turbo 및 최근의 Google Gemini 모델을 증기 롤러 도메인(steamroller domain)의 문제에 대해 평가합니다.

- **Technical Details**: 정확성 측정 외에 Natural Language Processing 라이브러리인 spaCy를 활용해 LLM의 추론 능력을 조사하는 새로운 방법을 탐구했습니다. 이 과정에서, 테스트된 모델 중 어느 것도 올바른 추론과 올바른 답변 사이의 상관관계가 낮은 것으로 나타났습니다. 또한 ATP 추론 전략을 사용할 때 모델의 성능이 one-shot chain of thought와 유사하였으며, 결과의 정확성에서 불확실성에 유의하는 것이 중요하다는 것을 관찰했습니다.

- **Performance Highlights**: 이전의 추정과 일치하게, LLM이 bottom-up reasoning process를 선호하며 가장 잘 따를 수 있다는 것을 확인했습니다. 그럼에도 불구하고 추론 전략은 신뢰할 수 있는 추론 엔진에 의해 외부 처리될 수 있도록 작고 관련성 있는 공식을 도출하는 데 여전히 유용할 수 있습니다.



### Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions (https://arxiv.org/abs/2407.20243)
- **What's New**: 이번 연구에서는 하위 모델(Large Language Models, LLMs)의 임베딩(embedding) 최적화를 위한 새로운 조정 프레임워크인 Matryoshka-Adaptor를 제안합니다. 이 프레임워크는 임베딩의 차원을 크게 줄이면서도 성능을 유지하여 계산 효율성과 비용 효과성을 높입니다. 특히, 사전 학습된 LLM의 임베딩을 직접 수정하고, 블랙박스 API를 포함한 다양한 LLM 아키텍처와 통합할 수 있도록 설계되었습니다.

- **Technical Details**: Matryoshka-Adaptor는 높은 성능을 유지하면서도 차원을 두 배에서 열두 배까지 줄이는 것을 목표로 합니다. 이 프레임워크는 비지도 학습(unsupervised learning)과 지도 학습(supervised learning) 환경 모두에서 효율성을 발휘합니다. 다양한 영어, 다국어(multilingual), 멀티모달(multimodal) 데이터셋에 대한 엄격한 평가를 통해 우수한 성능을 입증했습니다.

- **Performance Highlights**: Google 및 OpenAI의 임베딩 API와 함께 사용될 때, Matryoshka-Adaptor는 성능을 저하시키지 않으면서 다중 BEIR 데이터셋에서 차원을 두 배에서 열두 배까지 줄이는 데 성공했습니다. 이는 정보 검색과 같은 여러 응용 분야에서 중요한 컴퓨팅 지연과 비용 문제를 해결하는 데 큰 기여를 할 수 있습니다.



### From Feature Importance to Natural Language Explanations Using LLMs with RAG (https://arxiv.org/abs/2407.20990)
- **What's New**: 본 연구는 인간과 상호작용하는 자율적 의사결정 프로세스에서 머신러닝 모델의 출력을 대화 형식으로 이해할 필요성이 증가함에 따라, 대형 언어 모델(LLMs)이 후속 설명 제공자 역할을 할 수 있는 가능성을 탐구합니다. 특히, 장면 이해 과제에서 사용자의 질문에 응답하기 위해 외부 지식 저장소를 사용하는 추적 가능한 질문-응답(traceable question-answering) 방식을 도입합니다.

- **Technical Details**: 이 작업에서는 모델의 출력에 대한 맥락적 세부 정보(고급 특성(high-level features), 특성 중요도(feature importance), 대체 확률(alternative probabilities))을 포함하는 외부 지식 저장소를 활용합니다. 특성 중요도(feature importance)를 계산하기 위해 서브트랙티브 반사실 주의(subtractive counterfactual reasoning)를 사용하며, 이는 의미적 특징을 분해한 결과로 인한 출력 변화를 분석하는 방법입니다. 또한, 설명 과정을 원활히 하기 위해 사회적, 인과적, 선택적, 대비적 요소를 한 번의 프롬프트에 통합하여 응답 생성 과정을 안내합니다.

- **Performance Highlights**: 평가는 LLMs가 생성한 설명이 이러한 요소들을 포함하고 있어 복잡한 모델 출력을 자연 언어로 설명하는 데 잠재력이 있음을 나타냅니다.



### Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach (https://arxiv.org/abs/2407.20899)
- **What's New**: 기존 이미지 분류에 대한 해설 방법들은 신뢰성 있고 그럴듯한 설명을 제공하는 데 어려움을 겪고 있습니다. 이 연구는 CNN 기반 분류기를 수정하지 않고도 구현할 수 있는 사후 자연어 설명 방법을 제안하며, 이를 통해 분류기의 결정 과정을 충실하게 설명합니다.

- **Technical Details**: 이 방법은 중요한 뉴런(influential neurons)과 그에 대응하는 활성화 맵(activation maps)을 분석하여 분류기의 결정 과정을 충실하게 설명하는 구조화된 의미 표현(structured meaning representation)을 생성합니다. 생성된 설명은 언어 모델(language model)을 통해 텍스트로 변환됩니다. 이 파이프라인 접근법을 통해 생성된 설명은 신경망 아키텍처에 기초하여 정확한 통찰력을 제공하면서 비전문가도 이해할 수 있게 됩니다.

- **Performance Highlights**: 실험 결과, 본 연구에서 제안하는 자연어 설명(NLE)이 훨씬 더 그럴듯하고 충실하다는 것을 보여줍니다. 특히, 사용자 개입(뉴런의 은폐) 시 신경망 구조에 대한 개입 효과가 기존 방법들보다 3배 더 효과적입니다.



### SynthVLM: High-Efficiency and High-Quality Synthetic Data for Vision Language Models (https://arxiv.org/abs/2407.20756)
- **What's New**: 최근 웹 이미지 증가와 함께 대규모 이미지 데이터셋을 관리하고 이해하는 것의 중요성이 커지고 있습니다. 본 논문에서는 VLLM(Vision Large Language Models)을 위해 SynthVLM이라는 새로운 데이터 합성 파이프라인을 제안합니다. SynthVLM은 고급 diffusion 모델과 고품질 캡션을 사용하여 캡션에서 고해상도 이미지를 자동으로 생성하고 선택하여 정밀하게 정렬된 이미지-텍스트 쌍을 만들고 있습니다.

- **Technical Details**: SynthVLM은 기존 이미지에서 캡션을 생성하는 방법과 달리, 고품질 캡션을 이용하여 고해상도 이미지를 생성하고 선택하는 방식을 채택했습니다. 이를 통해 데이터 정렬 품질을 높이며 언어 능력을 보존합니다. 또한, 순수하게 생성된 데이터에 의존함으로써 개인정보를 보호하며, 공식 데이터셋 크기의 18%에 불과한 100k 데이터 포인트로 SoTA(State-of-the-Art) 성능을 달성합니다.

- **Performance Highlights**: SynthVLM은 다양한 비전 질문 응답 작업에서 최첨단 성능을 달성했습니다. 기존 GPT-4 Vision 기반 캡션 생성 방법보다 성능이 우수하며, 컴퓨팅 오버헤드를 크게 줄였습니다. 정렬 품질이 높으면서도 고급 언어 능력을 유지하고 있어, 낮은 데이터 포인트 수로도 높은 성능을 보장합니다.



### JaColBERTv2.5: Optimising Multi-Vector Retrievers to Create State-of-the-Art Japanese Retrievers with Constrained Resources (https://arxiv.org/abs/2407.20750)
- **What's New**: 최근 Neural Information Retrieval(신경 정보 검색)은 고자원 언어에서 눈부신 발전을 이루었지만, 일본어와 같은 저자원 언어에서는 데이터 부족 등의 문제로 성장이 더뎠습니다. JaColBERT와 같은 최신 멀티벡터 단일 언어 모델이 이러한 격차를 좁히고 있지만, 여전히 대규모 평가에서는 다국어 방법에 뒤처지고 있습니다. 이를 해결하기 위해 JaColBERT의 핵심적인 추론 및 훈련 설정을 체계적으로 평가하고 개선하여 JaColBERTv2.5를 도입했습니다.

- **Technical Details**: JaColBERTv2.5는 다국어 모델의 비효율성과 언어적 뉘앙스를 포착하지 못하는 문제를 해결하기 위해, 특히 저자원 언어 환경에서 멀티벡터 적용 방법의 훈련 방식을 개선했습니다. 또한 새로운 checkpoint merging step(체크포인트 병합 단계)을 도입해 파인튜닝의 이점을 원래 체크포인트의 일반화 능력과 결합했습니다. JaColBERTv2.5 모델은 4개의 A100 GPU에서 15시간 이하로 훈련되었으며, 1억 1천만 개의 파라미터를 가지고 있습니다.

- **Performance Highlights**: JaColBERTv2.5는 모든 공용 벤치마크에서 최고 성능을 달성했으며, 평균 점수 0.754로 이전 최고 기록 0.720보다 크게 앞선 성과를 보였습니다. 이를 위해 최종 모델, 중간 체크포인트 및 사용된 모든 데이터를 공개하여 향후 연구를 지원할 예정입니다.



### Industrial-Grade Smart Troubleshooting through Causal Technical Language Processing: a Proof of Concep (https://arxiv.org/abs/2407.20700)
Comments:
          2nd Workshop on Causal Inference and Machine Learning in Practice at the KDD 2024 Conference. arXiv admin note: text overlap with arXiv:2407.11056

- **What's New**: 이 논문은 경험 기록(Return on Experience)에서 표현된 기술 언어를 바탕으로 산업 환경 문제를 해결하기 위한 인과 진단 접근법의 개발을 설명합니다. 제안된 방법은 대규모 언어 모델(Large Language Model)의 분산 표현에 포함된 벡터화된 언어 지식과 산업 자산의 내재된 고장 모드 및 메커니즘이 암시하는 인과 연관성을 활용합니다. 실세계 예측 유지보수(Predictive Maintenance) 설정에서 이러한 개념을 실험적으로 설명합니다.

- **Technical Details**: 이 솔루션은 인과성을 인지하는 검색 증강 생성 시스템(causality-aware retrieval augmented generation system)으로 설계되었습니다. 대규모 언어 모델의 분산 표현에 포함된 벡터화된 언어 지식을 활용하여 산업 자산의 내재된 고장 모드와 메커니즘의 인과 연관성을 분석합니다.

- **Performance Highlights**: 실험 결과는 제안된 방법이 실세계 예측 유지보수 설정에서 효과적으로 작동함을 보여줍니다. 그러나 보다 복잡한 시나리오에서 사용되는 인과 기술의 성숙도를 향상시켜야 하는 과제를 논의합니다.



### CultureVo: The Serious Game of Utilizing Gen AI for Enhancing Cultural Intelligenc (https://arxiv.org/abs/2407.20685)
Comments:
          Fourth International Conference on AI-ML Systems, 8-11 October, 2024, Louisiana, USA

- **What's New**: CultureVo 사가 통합 문화 학습 스위트(ICLS)를 개발하여 세계 문화에 대한 기초 지식을 제공한다고 합니다. 이 스위트는 상호작용적인 수업과 게임화된 경험을 결합하여 문화를 배울 수 있도록 설계되었습니다.

- **Technical Details**: ICLS는 오픈 소스 대형 언어 모델(Large Language Models)을 활용한 생성형 AI(Generative AI) 기술을 사용하여 문화 지능(Cultural Intelligence)을 향상시킵니다. 구체적으로는 학습자의 지식 평가 자동화, 행동 패턴 분석, 비 플레이어 캐릭터와의 상호작용 관리 등에 사용합니다. 또, 학습자의 능력을 평가하여 상황에 맞는 힌트와 추천 과정을 제공하며, 생성형 AI가 교육 콘텐츠의 자동 생성 및 검증을 돕습니다.

- **Performance Highlights**: 이 시스템은 실시간 학습자 평가를 통해 각 학습자에게 맞춤화된 콘텐츠를 제공함으로써 학습 효과를 극대화합니다. 또한, 학습자의 행동 패턴 분석을 통해 효율적인 학습 경험을 제공합니다.



### Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks (https://arxiv.org/abs/2407.20657)
Comments:
          Accepted to ECCV 2024, Project Page: this https URL

- **What's New**: 최근의 비전-언어(foundation models) 모델들, 예를 들어 CLIP,은 다양한 다운스트림(downstream) 작업 및 도메인에서 전이학습이 가능한 표현을 학습하는 데 뛰어난 성능을 보여주었습니다. 이러한 강력한 모델들이 등장함에 따라 이들의 능력을 어떻게 효과적으로 활용하여 복잡한 비전 작업을 해결할 것인가가 중요한 문제가 되었습니다. 이번 연구에서는 PDCL-Attack이라는 새로운 전이 공격(transfer attack) 방식을 제안합니다. 이 방법은 CLIP 모델을 활용하여 생성 모델 기반의 공격 프레임워크에서 생성된 적대적 교란(adversarial perturbations)의 전이성(transferability)을 증대시킵니다.

- **Technical Details**: 구체적으로, 우리는 텍스트의 의미 표현력(semantic representation power), 특히 입력 이미지의 정답 클래스 레이블(ground-truth class labels)을 이용한 효과적인 프롬프트 구동형 피처 가이던스(prompt-driven feature guidance)를 공식화했습니다. 우리의 지식에 따르면, 우리는 전이 가능한 생성 공격을 향상시키기 위해 프롬프트 학습(prompt learning)을 도입한 최초의 연구입니다.

- **Performance Highlights**: 다양한 크로스 도메인(cross-domain) 및 크로스 모델(cross-model) 환경에서 진행된 광범위한 실험에서는 우리의 접근 방식이 최첨단 방법(state-of-the-art methods)보다 우수함을 실증적으로 입증하였습니다.



### Questionnaires for Everyone: Streamlining Cross-Cultural Questionnaire Adaptation with GPT-Based Translation Quality Evaluation (https://arxiv.org/abs/2407.20608)
Comments:
          19 pages, 13 figures

- **What's New**: 새로운 연구는 설문지 번역 프로세스를 가속화할 수 있는 프로토타입 툴을 소개합니다. 이 툴은 DeepL을 이용한 순방향-역방향 번역과 GPT-4 기반 번역 품질 평가 및 개선 제안을 통합하고 있습니다.

- **Technical Details**: 연구에서 제안된 툴은 두 가지 주요 구성 요소를 가지고 있습니다: DeepL 기계 번역 및 GPT-4의 번역 품질 평가 및 개선 제안. 두 가지 온라인 연구로 독일어(연구 1, n=10)와 포르투갈어(연구 2, n=20)로 설문지를 번역하며 툴의 효과성을 검증하였습니다.

- **Performance Highlights**: 연구 결과, LLM(대형 언어 모델, Large Language Model) 기반 번역 품질 평가와 개선 제안을 통합하는 것이 사용자가 독립적으로 기존의 비-NLP 지원 번역 방법과 유사한 품질의 결과를 얻을 수 있게 함을 시사합니다. 이는 AI를 통해 더 공정한 설문조사 기반 연구로 나아가는 첫 단계입니다.



### Harvesting Textual and Structured Data from the HAL Publication Repository (https://arxiv.org/abs/2407.20595)
- **What's New**: HALvest라는 독특한 데이터셋을 소개합니다. 이는 프랑스의 국가 출판 저장소인 HAL에서 인용 네트워크와 논문의 전체 텍스트를 연결하는 역할을 합니다. 약 70만 개의 문서가 포함되어 있으며, 이 데이터셋은 언어 모델 학습에 적합하고 폭넓은 학문 분야를 아우릅니다.

- **Technical Details**: HAL 저장소에서 학술 출판물을 필터링함으로써 34개의 언어와 13개의 학문 분야에 걸친 약 165억 개의 토큰을 포함한 약 70만 개의 문서를 수집했습니다. 각 논문의 메타데이터를 인용 네트워크로 변환하여 방향성 이질 그래프를 생성했습니다. 이 그래프에는 HAL에서 고유하게 식별된 저자와 모든 제출된 논문 및 관련 인용이 포함됩니다.

- **Performance Highlights**: 생성된 데이터셋을 사용한 저작권 추정(autorship attribution)의 기준선을 제공하고, 링크 예측(link prediction)을 위한 그래프 표현 학습(graph representation learning)에 최신 기술들을 구현했습니다. 또한 생성된 지식 그래프 구조의 유용성에 대해서도 논의합니다.



### Survey of Design Paradigms for Social Robots (https://arxiv.org/abs/2407.20556)
- **What's New**: 소셜 로봇(Social Robots)이 헬스케어, 교육, 엔터테인먼트 분야에서 그 감정 적응 기능으로 인해 수요가 증가하고 있습니다. 이 논문은 소셜 로봇 설계 패러다임을 체계적으로 검토하고 이를 인지 아키텍처(Cognitive Architectures), 역할 설계 모델(Role Design Models), 언어학적 모델(Linguistic Models), 의사소통 흐름(Communication Flow), 활동 시스템 모델(Activity System Models), 그리고 통합 설계 모델(Integrated Design Models)로 분류하여 분석합니다. 또한, 기존 접근법의 강점과 개선점을 강조하면서, 소셜 로봇 설계의 가장 중요한 측면들을 통합한 새로운 통합 설계 모델을 제안합니다.

- **Technical Details**: 해당 논문은 소셜 로봇 설계의 복잡성을 다루기 위해 다양한 설계 패러다임을 분류하고 분석합니다. 인지 아키텍처(Cognitive Architectures)는 로봇의 지능적 행동을 가능하게 하는 기본 구조를, 역할 설계 모델(Role Design Models)은 특정 역할 수행 능력을, 언어학적 모델(Linguistic Models)은 의사소통 능력을, 의사소통 흐름(Communication Flow)은 상호작용의 구조를, 그리고 활동 시스템 모델(Activity System Models)은 다양한 작업 수행 능력을 뜻합니다. 제안된 새로운 통합 설계 모델은 운영, 소통, 감정적 측면을 통합하여 인간과 로봇 간의 상호작용을 더욱 적응적이고 공감적으로 만듭니다.

- **Performance Highlights**: 제안된 통합 설계 모델은 기존의 설계 접근법보다 운영(Operational), 소통(Communicational), 감정적(Emotional) 측면을 통합함으로써 더욱 뛰어난 상호작용을 제공합니다. 이를 통해 소셜 로봇이 사용자와의 감정적 지지를 강화하며, 다양한 응용 분야에서 더 효과적으로 사용될 수 있음을 보여줍니다.



### Machine Unlearning in Generative AI: A Survey (https://arxiv.org/abs/2407.20516)
- **What's New**: 새로운 연구는 Generative AI (생성적 인공지능)에서 머신 언러닝 (Machine Unlearning, MU) 기술을 사용하는 방법을 조사합니다. 이는 기존의 분류 작업에 사용되던 MU 기술이 생성적 AI에 적용될 수 없다는 문제를 해결하기 위한 것입니다.

- **Technical Details**: 이 논문은 MU의 새로운 문제 정식화, 평가 방법, 그리고 다양한 MU 기술의 장단점에 대한 체계적 논의를 포함합니다. 특히, 웹 크롤링 데이터를 사용한 훈련으로 인해 모델이 기밀 정보, 편향된 정보, 또는 위험한 정보를 기억하고 생성할 수 있는 문제를 해결하고자 합니다.

- **Performance Highlights**: 연구는 생성적 AI 모델에서 바람직하지 않은 지식과 그 영향을 줄이거나 제거하기 위해 다양한 MU 기술을 탐구합니다. 이는 새로운 평가 방법과 문제 정식화 등을 통해 이루어지며, 여러 가지 중요한 도전 과제와 유망한 연구 방향을 제공합니다.



### CoMMIT: Coordinated Instruction Tuning for Multimodal Large Language Models (https://arxiv.org/abs/2407.20454)
Comments:
          9 pages

- **What's New**: 이 논문은 다중 모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)에서 지시 조정(instruction tuning) 방법을 소개합니다. 이 방법은 LLM(backbone LLM)과 사전 학습된 특징 인코더(pre-trained feature encoder)를 원활하게 통합하여 다운스트림 작업에서의 성능을 개선하는 것을 목표로 합니다. 기존 방법의 주된 문제점인 학습 균형 불균형을 새롭게 발견하고, 이를 해결하기 위한 동적 학습 스케줄러(dynamic learning scheduler)와 보조 손실 정규화(auxiliary loss regularization) 방법을 제안합니다.

- **Technical Details**: 논문은 이론적 및 실험적 관점에서 MLLM의 지시 조정을 분석합니다. LLM과 특징 인코더 간의 학습 불균형(unbalanced learning)이 학습 경사(learning gradients)를 감소시켜 모델의 수렴을 지연시키고 불충분한 학습으로 인해 결과가 최적화되지 않는 문제점을 확인했습니다. 이를 해결하기 위해, 학습 균형을 정량적으로 평가하는 측정 방법을 제안하고, 각 구성 요소의 학습 상태를 고려한 보조 손실 정규화를 통해 더 정확한 학습 균형 계수를 추정할 수 있도록 합니다.

- **Performance Highlights**: 여러 가지 LLM 백본과 특징 인코더를 사용하여 수행된 실험 결과, 제안된 방법은 다양한 비전 및 오디오 모달리티에서 여러 다운스트림 작업의 효율성과 효과성을 입증했습니다. 특히, 이 기술은 모델 아키텍처에 구애받지 않고 통합 가능하여 범용적으로 적용될 수 있습니다.



### Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieva (https://arxiv.org/abs/2407.20371)
Comments:
          To be published in Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society; code available at this https URL

- **What's New**: 최근 인공지능(AI) 채용 도구는 이력서 검토 방식을 혁신적으로 변화시켰으며, 대형 언어 모델(Large Language Models, LLMs)도 이에 속할 잠재력을 지닙니다. 그러나 LLMs에 내재된 편향(bias) 때문에 보호받는 속성(Protected Attributes)에 따라 그룹을 불리하게 만들 가능성이 있습니다. 이 연구는 LLMs를 이력서 검토에 사용하는 가능성을 문서 검색 프레임워크(Document Retrieval Framework)를 통해 조사하였습니다.

- **Technical Details**: 9개의 직업을 대상으로, 500개 이상의 공개된 이력서와 500개의 직무 설명을 사용하여 조사하였습니다. Massive Text Embedding (MTE) 모델을 사용하여 이력서 검토 시 편향이 존재하는지 감사 연구(Audit Study)를 수행했습니다.

- **Performance Highlights**: 연구 결과, MTE 모델은 85.1%의 경우에서 백인과 관련된 이름들을, 11.1%의 경우에서 여성과 관련된 이름들을 유리하게 선별하였으며, 소수의 경우에서만 통계적으로 유의미한 차이가 없었습니다. 특히 흑인 남성은 최대 100%의 경우에서 불이익을 받는 것으로 나타났습니다. 또한 문서 길이와 이름의 코퍼스 빈도도 이력서 선별에 영향을 미쳤습니다. 이 결과는 AI 채용 도구의 공정성, 기술 정책에 중요한 함의를 가지고 있습니다.



### BRIDGE: Bridging Gaps in Image Captioning Evaluation with Stronger Visual Cues (https://arxiv.org/abs/2407.20341)
Comments:
          ECCV 2024

- **What's New**: 차세대 이미지 캡셔닝 평가 지표로 BRIDGE를 제안합니다. 이 지표는 인간의 판단과 더 정확하게 일치시키기 위해 기존 지표들(CIDEr, CLIP-Score)의 한계를 극복하고자 했습니다. 특히, 브리지는 참조 캡션(referece captions)을 필요로 하지 않는 새로운 학습 가능한 평가 지표로, 시각적 특징을 밀집 벡터화하고 이를 다중 모달(lmulti-modal) 가상 캡션으로 통합합니다.

- **Technical Details**: BRIDGE는 시각적 특징을 밀집 벡터(dense vectors)로 매핑(mapping)하는 혁신적인 모듈을 사용합니다. 이러한 벡터들은 평가 과정 중에 구축된 다중 모달 가상 캡션에 통합됩니다. 이는 참조 캡션 없이 입력 이미지의 정보를 적절히 포함시켜주며, 인간 심사와 기계 생성 캡션 사이의 격차를 줄이는 기술입니다.

- **Performance Highlights**: 여러 데이터셋을 대상으로 한 실험에서 BRIDGE는 기존의 참조 캡션이 필요 없는 평가 점수(reference-free evaluation scores)와 비교해 최첨단 성능을 달성했습니다. 또한, 해당 연구의 소스 코드와 학습된 모델은 공개되어 있어, 이 기술의 활용도가 높아질 전망입니다.



### Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process (https://arxiv.org/abs/2407.20311)
Comments:
          video appeared in ICML 2024 tutorial

- **What's New**: 최근 언어 모델(language models)의 발전은 수학적 추론 문제를 해결할 수 있는 능력을 보여주며, 초등학교 수준의 수학 벤치마크인 GSM8K에서 거의 완벽한 정확도를 달성했습니다. 이번 논문에서는 언어 모델이 이 문제들을 어떻게 해결하는지 공식적으로 연구하였습니다.

- **Technical Details**: 연구진은 여러 기본적인 질문을 다루기 위해 일련의 통제된 실험을 설계했습니다: (1) 언어 모델이 정말로 추론 능력을 개발할 수 있는가, 아니면 단순히 템플릿을 암기하는가? (2) 모델의 숨겨진(mental) 추론 과정은 무엇인가? (3) 모델이 수학 문제를 해결하는 데 사용하는 기술이 인간과 비슷한가 또는 다른가? (4) GSM8K 같은 데이터셋으로 훈련된 모델이 GSM8K 문제를 해결하는 데 필요한 것 이상의 추론 능력을 개발하는가? (5) 모델이 추론 실수를 일으키는 정신적 과정은 무엇인가? (6) GSM8K 수준의 수학 문제를 효과적으로 해결하기 위해 모델은 얼마나 크거나 깊어야 하는가?

- **Performance Highlights**: 이번 연구는 언어 모델이 수학적 문제를 해결하는 많은 숨겨진 메커니즘을 밝혀내었으며, 현재 LLMs에 대한 이해를 넘어서는 통찰력을 제공하고 있습니다.



### Exploring the Plausibility of Hate and Counter Speech Detectors with Explainable AI (https://arxiv.org/abs/2407.20274)
Comments:
          conference, CBMI2024, 6 pages,

- **What's New**: 이 논문에서는 트랜스포머 모델의 설명 가능성(explainability)과 그 모델이 혐오 발언(hate speech) 및 반발 발언(counter speech) 감지에 얼마나 유용한지 조사합니다.

- **Technical Details**: 논문에서는 네 가지 다른 설명 가능성 접근법, 즉 그래디언트 기반(gradient-based), 섭동 기반(perturbation-based), 어텐션 기반(attention-based), 프로토타입 기반(prototype-based) 접근법의 대표자를 비교합니다. 양적 분석(ablation study)과 질적 분석(user study)을 통해 이를 분석합니다.

- **Performance Highlights**: 결과에 따르면 섭동 기반 설명 가능성이 가장 우수했으며, 그 다음은 그래디언트 기반 및 어텐션 기반 설명 가능성이 우수했습니다. 프로토타입 기반 실험은 유용한 결과를 제공하지 못했습니다. 전체적으로 설명 가능성은 사용자가 모델 예측을 더 잘 이해하는 데 크게 도움이 되는 것으로 나타났습니다.



### Learn while Unlearn: An Iterative Unlearning Framework for Generative Language Models (https://arxiv.org/abs/2407.20271)
- **What's New**: 최근 기계 학습, 특히 자연어 처리(NLP) 분야에서 거대한 데이터셋을 학습한 정교한 모델들이 개발되었지만, 이로 인해 민감한 정보 누출에 대한 우려가 제기되었습니다. 이에 따라 EU의 일반 데이터 보호 규정(GDPR)과 같은 규제 조치가 기계적 '잊기' (Machine Unlearning) 기술에 대한 탐구를 촉진하고 있습니다. 이러한 기술은 모델이 특정 데이터 항목을 선택적으로 잊을 수 있게 하는 것을 목표로 합니다. 본 논문에서는 이러한 문제를 해결하기 위해 Iterative Contrastive Unlearning (ICU) 프레임워크를 소개합니다.

- **Technical Details**: ICU 프레임워크는 세 가지 핵심 요소를 포함합니다. 첫째, 특정 대상 시퀀스를 잊기 위한 Knowledge Unlearning Induction 모듈을 제안합니다. 둘째, 생성 능력의 저하를 방지하기 위해 Contrastive Learning Enhancement 모듈을 통합합니다. 셋째, 각 대상 샘플에 더 적응할 수 있도록 Iterative Unlearning Refinement 모듈을 통합합니다. 이러한 구성 요소들을 통해 원래 학습 데이터에 대한 접근 없이도 효과적인 '잊기' 과정을 수행할 수 있습니다.

- **Performance Highlights**: 실험 결과, ICU 프레임워크는 민감한 정보를 효율적으로 잊으면서도 성능을 유지하는 데 유효함을 입증했습니다. 이는 개인정보 보호를 중시하는 기계 학습 애플리케이션에 유망한 방법을 제공합니다.



### Can Editing LLMs Inject Harm? (https://arxiv.org/abs/2407.20224)
Comments:
          The first two authors contributed equally. 9 pages for main paper, 36 pages including appendix. The code, results, dataset for this paper and more resources are on the project website: this https URL

- **What's New**: 이번 연구에서는 대형 언어 모델(Large Language Models, LLMs)에서 지식 편집(knowledge editing) 기술이 잘못된 정보나 편향을 삽입하여 안전성을 위협할 수 있음을 밝혀냈습니다. 연구팀은 EditAttack이라는 새로운 데이터세트를 구축하고, 편집 공격(Editing Attack)을 체계적으로 조사하였습니다. 특히, '오정보 주입(Misinformation Injection)'과 '편향 주입(Bias Injection)'이라는 두 가지 주요 안전 위험에 중점을 두었습니다.

- **Technical Details**: 오정보 주입 위험을 '상식 오정보 주입(commonsense misinformation injection)'과 '긴 꼬리 오정보 주입(long-tail misinformation injection)'으로 분류했습니다. 연구 결과, 편집 공격은 특히 상식 오정보 주입에서 높은 효과를 보였습니다. 편향 주입 위험의 경우, 단 하나의 편향된 문장 삽입만으로도 일반 출력물에서 큰 편향 증가를 초래할 수 있으며, 이는 모델 전반의 공정성에 치명적인 영향을 미칠 수 있음을 발견했습니다. 또한, 편집 공격은 일반적인 지식과 추론 능력에 미치는 영향이 적어, 탐지하기 어렵다는 점도 확인하였습니다.

- **Performance Highlights**: 편집 공격의 높은 은밀성(stealthiness)으로 인해, 방어가 어렵다는 점을 경험적인 증거를 통해 보여주었습니다. 지식 편집 기술이 LLMs의 안전한 정렬(safety alignment)을 훼손할 수 있는 새로운 오용 위험을 나타냅니다.



### QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieva (https://arxiv.org/abs/2407.20207)
- **What's New**: Dense retrieval에서 장문 텍스트를 dense 벡터(dense vectors)로 임베딩하면 정보 손실이 발생하고, 이에 따라 쿼리-텍스트 매칭의 정확도가 떨어질 수 있습니다. 또한, 저질 텍스트는 과도한 노이즈나 희박한 주요 정보를 가지고 있는 경우가 많아 관련 쿼리와 잘 맞지 않습니다. 기존 연구들은 주로 문장 임베딩 모델(sentence embedding model)이나 검색 프로세스를 개선하는 데 초점을 맞추고 있습니다. 이에 반해, 본 연구는 dense retrieval을 위한 새로운 텍스트 증강 프레임워크를 소개합니다. 이 프레임워크는 원본 텍스트를 정보 밀도가 높은 텍스트 형식으로 변환하여, 임베딩이나 검색 방법론 자체를 수정하지 않고 앞서 언급한 문제를 효과적으로 해결합니다.

- **Technical Details**: 본 연구의 프레임워크는 대형 언어 모델(LLMs)으로부터 zero-shot(prompting) 방법을 통해 두 가지 텍스트 표현을 생성합니다: 질문-응답 쌍(question-answer pairs)과 요소 기반 이벤트(element-driven events). 이를 QAEA-DR로 명명하며, 텍스트 증강 프레임워크 내에서 질문-응답 생성 및 이벤트 추출을 통합합니다. 생성된 텍스트의 품질을 더욱 향상시키기 위해, LLM prompting에서 점수 기반 평가 및 재생성 메커니즘(scoring-based evaluation and regeneration mechanism)을 도입하였습니다.

- **Performance Highlights**: 이론적 분석과 실험적 경험 모두 QAEA-DR 모델이 dense retrieval에 긍정적인 영향을 미친다는 것을 지지합니다.



### MindSearch: Mimicking Human Minds Elicits Deep AI Searcher (https://arxiv.org/abs/2407.20183)
Comments:
          Technical Report. Project Page: https://mindsearch.netlify.app Code: this https URL

- **What's New**: 최신 연구에서는 MindSearch라는 새로운 방법을 도입했습니다. 이 시스템은 인간의 웹 정보 탐색 및 통합 과정에서의 인지적 과정을 모방하여, 대규모 언어 모델(LLM)과 검색 엔진을 효율적으로 결합한 다중 에이전트 프레임워크를 제공합니다.

- **Technical Details**: MindSearch는 두 가지 주요 컴포넌트로 구성됩니다: WebPlanner와 WebSearcher. WebPlanner는 사용자의 질의를 더 작은 서브-질문으로 분해하고 그래프로 확장하는 역할을 합니다. WebSearcher는 각 서브-질문에 대한 계층적 정보 검색을 수행하여 WebPlanner에 필요한 정보를 제공합니다. 이 다중 에이전트 설계 덕분에 MindSearch는 300개 이상의 웹 페이지에서 3분 만에 정보 통합 작업을 수행할 수 있습니다.

- **Performance Highlights**: MindSearch는 질의응답의 깊이와 폭 측면에서 클로즈-셋 및 오픈-셋 QA 문제 모두에서 상당한 성능 향상을 보입니다. 또한, InternLM2.5-7B를 기반으로 한 MindSearch의 응답은 ChatGPT-Web보다 사용자에게 더 선호되는 결과를 제공합니다.



### An Energy-based Model for Word-level AutoCompletion in Computer-aided Translation (https://arxiv.org/abs/2407.20083)
Comments:
          Accepted to TACL 2024

- **What's New**: 이 논문은 Word-level AutoCompletion(WLAC)이라는 컴퓨터 보조 번역에서 중요한 과제를 다룹니다. 저자들은 현재 신경망(neural network) 기반 분류 모델의 한계를 지적하며, 이를 해결하기 위해 새로운 에너지 기반 모델(energy-based model)을 제안합니다.

- **Technical Details**: 기존 모델은 입력 문맥의 숨겨진 벡터(hidden vector)를 대응 레이블(레이블로 취급되는 후보 대상 단어)로 매핑하는 방식으로 동작했습니다. 그러나 숨겨진 벡터가 레이블의 정보를 충분히 반영하지 못해 성능이 저하되었습니다. 새로운 에너지 기반 모델은 문맥 숨겨진 벡터가 출처 문장에서 중요한 정보를 포착하도록 설계되었습니다. 하지만 이 모델은 훈련과 추론에서 효율성과 효과성 문제에 직면했습니다. 이를 해결하기 위해 세 가지 단순하면서도 효과적인 전략을 적용했습니다.

- **Performance Highlights**: 네 가지 표준 벤치마크 실험에서, 이 논문의 재순위화(reranking) 기반 접근 방식은 이전 최첨단(state-of-the-art) 모델 대비 약 6.07%의 성능 향상을 보였습니다. 추가 분석 결과, 제안된 각 전략이 최종 성능에 기여함을 확인했습니다.



### Investigating the Impact of Semi-Supervised Methods with Data Augmentation on Offensive Language Detection in Romanian Languag (https://arxiv.org/abs/2407.20076)
Comments:
          Accepted at KES 2024

- **What's New**: 이 논문은 온라인 플랫폼에서의 공격적 언어(Offensive language) 탐지 모델의 구축을 위해 반지도 학습(Semi-supervised learning) 및 데이터 증강(data augmentation) 기법을 탐구합니다. RO-Offense 데이터셋을 사용하여 총 8개의 반지도 학습 방법을 실험했으며, 데이터 모델에 입력하기 전에 5가지 데이터 증강 기법을 적용했습니다.

- **Technical Details**: 구체적으로, 이 논문에서는 8개의 반지도 학습 방법을 구현하고, 각 방법에 대해 RO-Offense 데이터셋만을 이용하여 실험을 수행했습니다. 실험에 앞서 데이터를 모델에 입력하기 전에 5가지 다른 데이터 증강 기법을 적용했습니다. 반지도 학습을 통해 라벨이 없는 데이터와 라벨이 있는 데이터를 동시에 활용하여 더 정확하고 견고한 모델을 만드려는 시도를 했습니다.

- **Performance Highlights**: 실험 결과, 일부 반지도 학습 방법은 데이터 증강 기법에서 더 큰 이익을 얻는 것으로 나타났습니다. 이는 적절한 데이터 증강과 반지도 학습을 결합하여 공격적 언어 탐지 모델의 성능을 크게 개선할 수 있다는 것을 시사합니다.



### Exploring Large Language Models to generate Easy to Read conten (https://arxiv.org/abs/2407.20046)
- **What's New**: 이번 연구는 인공지능(AI)과 자연어 처리(NLP)를 활용하여 스페인어 텍스트를 체계적으로 쉽게 읽을 수 있는 형식(Easy to Read format)으로 단순화하는 방안을 탐구합니다. 특히, 큰 언어 모델(Large Language Models, LLMs)을 사용하여 Easy to Read 콘텐츠를 생성하는 것에 중점을 두고 있습니다. 이 연구는 Easy to Read 형식으로 적응된 스페인어 병렬 코퍼스를 제공하여 텍스트 단순화 시스템의 학습 및 테스트에 유용한 자원을 제공합니다.

- **Technical Details**: 연구에서는 여러 텍스트 단순화 실험을 수행하였으며, 수집된 코퍼스를 사용해 Llama2 모델을 미세 조정(fine-tuning)하여 Easy to Read 콘텐츠를 생성했습니다. 이 실험에서는 전문가의 지도를 받아 자동으로 단순화된 텍스트를 질적으로 평가했습니다. 이는 인공지능과 NLP를 활용한 텍스트 접근성 향상에 중요한 기여를 합니다.

- **Performance Highlights**: 탐구된 전략은 인지 장애가 있는 개인의 텍스트 접근성을 향상시키는 데 매우 유망하다는 결론을 도출했습니다. 대형 언어 모델(LLMs)을 효율적으로 활용하면서도 에너지 사용을 책임감 있게 관리하는 것이 중요하다는 점을 강조합니다.



### Do LLMs Really Adapt to Domains? An Ontology Learning Perspectiv (https://arxiv.org/abs/2407.19998)
Comments:
          Accepted at ISWC 2024

- **What's New**: 대형 언어 모델(LLMs)이 다양한 자연어 처리 작업과 여러 응용 분야에서 전례 없는 성과를 보였습니다. 그러나 이들의 성공이 비구조적 또는 반구조적 데이터에서 추론하는 능력 때문인지, 아니면 단순히 언어 패턴과 의미를 효과적으로 학습했기 때문인지는 명확하지 않았습니다. 이 논문은 특정 도메인 데이터에서 이러한 모델이 실제로 적응하는지, 아니면 단순히 어휘 의미를 배우는지에 대한 질문을 탐구합니다.

- **Technical Details**: 제어된 실험 설정을 통해, 영어와 의미 없는 단어로 구성된 병렬 말뭉치를 사용하는 WordNet을 이용해 연구했습니다. LLM의 출력 차이를 두 가지 OL(ontology learning) 작업, 관계 추출과 분류 체계 발견에서 조사했습니다. 실험 결과는 모델들이 의미 없는 단어 말뭉치에 적응하는 동안 개념 간의 의미 관계를 일관되게 추론하지 않고, 대신 의미와 프레임을 활용하는 경향이 있음을 보여줍니다.

- **Performance Highlights**: 사전 학습된 LLM을 미세 조정(fine-tuning)하면, 도메인별로 임의적이고 사전에 보지 못한 용어에도 불구하고 어휘 의미 작업에서 성과가 향상됨을 발견했습니다. 이는 OL 적용 가능성을 시사합니다.



### Confidence Estimation for Automatic Detection of Depression and Alzheimer's Disease Based on Clinical Interviews (https://arxiv.org/abs/2407.19984)
Comments:
          Accepted by Interspeech 2024

- **What's New**: 음성 기반으로 알츠하이머병(AD)과 우울증을 자동으로 탐지하는 시스템에서 신뢰도 추정을 개선하는 새로운 방법을 제안합니다. 임상 인터뷰 데이터를 기반으로 한 이 방법은 예측 분포의 2차 확률을 모델링하기 위해 동적 디리클레 사전 분포(dynamic Dirichlet prior distribution)를 사용하여 자동 진단 시스템의 신뢰성을 높입니다.

- **Technical Details**: 제안된 방법은 임상 인터뷰 데이터를 기반으로 AD와 우울증을 탐지하며, 베이지안 접근법(Bayesian approach)을 이용하여 신뢰도 추정을 수행합니다. 동적 디리클레 사전 분포를 사용하여 예측 분포의 2차 확률을 모델링함으로써 모델의 예측에 대한 신뢰도를 제공하고 오진의 위험을 줄입니다.

- **Performance Highlights**: 제안된 방법은 공개 데이터셋(ADReSS와 DAIC-WOZ)에서 실험 결과, 기존의 여러 기준을 능가하는 분류 정확도와 신뢰도 추정 성능을 보여주었습니다. 특히, AD와 우울증 탐지에서 높은 정확도와 신뢰도를 제공하여 임상 현장에서 유용한 도구가 될 수 있음을 확인했습니다.



### A Temporal Psycholinguistics Approach to Identity Resolution of Social Media Users (https://arxiv.org/abs/2407.19967)
- **What's New**: 이 논문에서는 소셜 미디어 플랫폼 간의 신원 해상도(Identity Resolution)를 위한 접근 방식을 제안합니다. 특히 게시물의 주제, 감정, 게시 시점을 활용하여 Disqus와 Twitter의 약 5000개의 프로필을 분석하고 매칭합니다.

- **Technical Details**: 연구에서는 시간적(temporal) 및 비시간적(non-temporal) 방법을 모두 사용하여 분석을 수행했습니다. 시간적 접근법이 전반적으로 더 나은 성능을 보였으며, 시간 창의 크기가 결과에 더 큰 영향을 미친다는 것을 발견했습니다. 또한 감성 분석에서는 데이터 추출 방법의 문제가 있어 감성을 포함해도 큰 차이가 없음을 확인했습니다. 연구 중에는 거리 기반(reward-and-punishment-focused) 스코어링 모델도 실험했으며, 24.198%의 정확도와 평균 순위 158.217을 기록했습니다.

- **Performance Highlights**: 스코어링 모델은 2525개의 수집된 자료 내에서 24.198%의 정확도와 평균 순위 158.217를 달성했습니다. 향후 연구 방향으로는 주제별 감정 평가를 통한 감성 분석 개선, 추가적인 단계가 포함된 시간적 분석의 확장, 그리고 스코어링 모델의 보상 및 가중치 조정에 의한 개선 등이 있습니다.



### Inference acceleration for large language models using "stairs" assisted greedy generation (https://arxiv.org/abs/2407.19947)
Comments:
          Accepted at the 29th International Conference on Information Society and University Studies (IVUS 2024)

- **What's New**: 대형 언어 모델(LLMs)은 뛰어난 예측 능력으로 주목받고 있지만, 실행에 많은 자원이 필요합니다. 본 연구에서는 소형 모델의 빠른 생성 속도, 대형 모델의 일괄 예측(batch prediction), 그리고 'stairs' 검증(stairs validation)을 활용하여 예측 생성 속도를 향상시키는 'stairs' 보조 탐욕 생성(stairs assisted greedy generation)의 구현을 제안합니다.

- **Technical Details**: 이 연구는 'stairs' 보조 탐욕 생성(stairs assisted greedy generation)을 사용하여 텍스트 생성 작업에서 예측 시간 단축을 목표로 합니다. 소형 모델의 빠른 생성 속도와 대형 모델의 일괄 예측을 결합하여 최적의 성능을 유지하면서 자원 소비를 줄이는 방법론을 제시합니다. 'Stairs' 검증(stairs validation)은 이 과정에서 핵심 역할을 합니다.

- **Performance Highlights**: 실험 결과, 단독 대형 언어 모델(stand-alone large LLM) 예측에 비해 텍스트 생성 작업에서 정확도를 유지하면서 예측 시간(inference time)에서 9.58%에서 17.24%의 감소를 달성했습니다.



### Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models (https://arxiv.org/abs/2407.19914)
Comments:
          Accepted at the 29th International Conference on Information Society and University Studies (IVUS 2024)

- **What's New**: 이 연구는 기존 연구들과 달리 리투아니아어 리뷰의 감정 분석(Sentiment Analysis)에 Transformer 모델을 처음으로 도입하여 성능을 측정하였습니다. 특히 다국어 Large Language Models(LLMs)를 활용하여 BERT와 T5 모델을 미세 조정(Fine-tuning)했습니다. 연구 결과, 상업적으로 이용 가능한 최신 GPT-4 모델을 뛰어넘는 성과를 보였습니다.

- **Technical Details**: 연구팀은 다섯 개의 별점으로 구성된 다양한 리투아니아어 온라인 리뷰 데이터를 수집하고 이를 정제(clean)하는 작업을 수행하였습니다. 수집된 데이터를 바탕으로 BERT와 T5 모델을 미세 조정하여 감정 분석을 수행했습니다. 이 방법은 전통적인 기계 학습 및 분류 알고리즘 대비 높은 효과를 보였습니다.

- **Performance Highlights**: 미세 조정된 모델들은 특히 덜 모호한 감정 분석에서 뛰어난 성능을 보였습니다. 가장 인기 있는 1성과 5성 리뷰에 대해 각각 80.74%와 89.61%의 테스트 인식 정확도를 기록했습니다. 이는 현재 상업적인 최첨단 다목적 LLM인 GPT-4를 대폭 초과하는 성과입니다. 이러한 성능 개선 모델들은 온라인에서 공개적으로 제공되었습니다.



### Preliminary WMT24 Ranking of General MT Systems and LLMs (https://arxiv.org/abs/2407.19884)
- **What's New**: 이번 보고서는 WMT24 General MT 시스템의 자동 평가 메트릭(automatic metrics)을 기반으로 한 초기 순위를 제공합니다. 공식 순위는 인간 평가(human evaluation)를 통해 이루어지며, 이는 자동 순위를 뛰어넘습니다. 이 보고서의 목적은 연구 결과를 해석하는 것이 아니라, 시스템 제출을 준비하는 참가자들이 유용하게 활용할 수 있도록 초기 결과를 제공하는 것입니다.

- **Technical Details**: 이번 예비 순위는 BLEU, METEOR, TER 등의 자동 평가 메트릭을 사용하여 생성되었습니다. 자동 메트릭의 결과는 참가자들에게 초기 성능 피드백을 제공하기 위해 집계되었으며, 최종 성능 평가는 인간 평가를 통해 이루어질 예정입니다.

- **Performance Highlights**: 현재의 자동 메트릭을 통한 예비 결과는 공식 순위가 아니므로 참고용으로만 사용해야 합니다. 참가자들은 제출 시스템을 최적화하고 향상시키기 위해 이 피드백을 활용할 수 있습니다. 공정하고 신뢰성 있는 성능 평가를 위해 최종 평가는 인간 평가를 따를 것입니다.



### ATHAR: A High-Quality and Diverse Dataset for Classical Arabic to English Translation (https://arxiv.org/abs/2407.19835)
- **What's New**: 고전 아랍어(Cl알라식 آrabic)는 아랍 문화, 철학 및 과학 문학의 황금기를 대표합니다. 이러한 문학 작품을 번역하여 지식 전파를 촉진하는 것이 중요하다는 것에 폭넓은 동의가 존재하지만, 고전 아랍어 번역 데이터셋의 부족이 문제로 지적되고 있습니다. 이러한 문제를 해결하기 위해 ATHAR 데이터셋이 발표되었습니다. 이 데이터셋은 과학, 문화 및 철학을 포함한 다양한 주제에 대한 66,000개의 고품질 고전 아랍어-영어 번역 샘플을 포함하고 있습니다.

- **Technical Details**: 현존하는 최신의 대형 언어 모델(LLMs)과 번역 시스템의 성능을 다양한 설정에서 평가한 결과, 이러한 데이터셋이 현재 시스템에 필요한 것으로 나타났습니다. 이 데이터셋은 모델을 미세 조정(fine-tuning)하거나 사전 학습에 포함시킬 때 유용하게 사용될 수 있습니다.

- **Performance Highlights**: ATHAR 데이터셋을 활용함으로써 번역 모델의 품질이 크게 향상될 수 있으며, 이는 지식의 전파와 보급에도 기여할 수 있습니다. 이 데이터셋은 HuggingFace Data Hub에서 공개적으로 제공됩니다.



### Concise Thoughts: Impact of Output Length on LLM Reasoning and Cos (https://arxiv.org/abs/2407.19825)
Comments:
          Preprint version, under review

- **What's New**: 이번 논문은 대형 언어 모델(LLMs)이 질문 답변 작업을 수행할 때의 응답 길이를 분석하고, 이를 '정확한 간결성(correct conciseness)'이라는 개념으로 평가하는 새로운 메트릭을 제안한다. 특히, Constrained-CoT(CCoT)라는 개선된 프롬프트 엔지니어링 전략을 통해 모델이 응답 길이를 제한하도록 유도하고자 한다.

- **Technical Details**: 기존의 Chain-of-Thought(CoT) 기법은 출력의 설명력과 정확성을 향상시키는 데 주로 사용되지만, 긴 추론 세부사항을 생성하는 데 시간이 많이 소요된다. 이를 해결하기 위해, 논문에서는 출력 길이가 LLM 추론 파이프라인에 미치는 영향을 분석하고, 정확성을 유지하면서도 간결한 출력을 생성할 수 있도록 CCoT 전략을 고안하였다. CCoT는 모델이 불필요하게 긴 출력을 피하도록 설계되었다.

- **Performance Highlights**: CCoT 전략의 효과는 사전 훈련된 LLM에서 입증되었다. 예를 들어, LLaMA2-70b 모델의 추론을 100단어로 제한할 경우, GSM8K 데이터셋에서 정확도가 36.01%에서 41.07%로 향상되었으며, 평균 출력 길이는 28단어 줄어들었다.



### Comparative Analysis of Encoder-Based NER and Large Language Models for Skill Extraction from Russian Job Vacancies (https://arxiv.org/abs/2407.19816)
- **What's New**: 이번 연구는 노동 시장에서 구직자와 구인 공고의 변화를 분석하고, 러시아의 구인 공고에서 요구되는 주요 기술을 추출하는 방법을 비교합니다. 전통적인 Named Entity Recognition(NER) 방법과 대형 언어 모델(Large Language Models, LLMs)의 성능을 비교하여 어떤 방법이 더 효과적인지 평가하였습니다.

- **Technical Details**: 러시아 구인 공고 4,000건의 라벨링된 데이터셋을 이용해 훈련을 진행하고, 1,472건의 테스트 데이터로 성능을 평가했습니다. 전통적인 NER 모델, 특히 DeepPavlov RuBERT NER을 튜닝한 모델이 정확도, 정밀도, 재현율, 추론 시간 등의 다양한 메트릭에서 LLMs보다 뛰어난 성능을 보였습니다.

- **Performance Highlights**: 연구 결과, 전통적인 NER 모델이 LLMs보다 기술 추출에서 더 효과적이고 효율적으로 구인 공고의 명확성을 높여 줌으로써 구직자들이 자신의 자격을 고용주의 요구사항과 일치시킬 수 있도록 돕는다는 사실을 발견했습니다. 이는 비영어권 환경에서 NLP의 적용 가능성을 높이는 데 기여할 수 있습니다.



### Improving Retrieval Augmented Language Model with Self-Reasoning (https://arxiv.org/abs/2407.19813)
- **What's New**: 최근 RALM(Retrieval-Augmented Language Model)은 외부 지식을 참조하여 지식 집약적인 작업에서 뛰어난 성능을 보여주고 있습니다. 그러나, 신뢰성 및 추적성 문제는 여전히 존재합니다. 본 논문에서는 LLMs(Large Language Models)의 신뢰성과 추적성을 개선하기 위해 자가 추론 프레임워크를 제안합니다. 이 프레임워크는 LLM 자체가 생성한 추론 경로를 활용합니다.

- **Technical Details**: 제안된 프레임워크는 세 가지 주요 과정을 포함합니다: 관련성 인식 프로세스, 증거 인식 선택 프로세스 및 경로 분석 프로세스. 이러한 과정을 통해 RALM에 의해 생성된 응답의 관련성을 높이고, 신뢰성을 증대시키며, 제대로 된 인용을 통해 결과의 추적 가능성을 보장할 수 있습니다.

- **Performance Highlights**: 제안된 프레임워크는 네 개의 공개 데이터셋(두 개의 단기 QA 데이터셋, 하나의 장기 QA 데이터셋, 하나의 사실 검증 데이터셋)을 통해 평가되었으며, 최신 모델을 뛰어넘는 성능을 보여주었습니다. 또한, 단 2,000개의 훈련 샘플로 GPT-4와 유사한 성능을 달성할 수 있었습니다.



### Segmentation en phrases : ouvrez les guillemets sans perdre le f (https://arxiv.org/abs/2407.19808)
Comments:
          in French language

- **What's New**: 이 논문은 XML 문서의 문장 분할을 위한 그래프 캐스케이드(graph cascade) 접근법을 제안합니다. 이 접근법은 따옴표나 하이픈으로 시작하는 문장 내부의 문장, 괄호로 시작하는 삽입구, 그리고 콜론으로 시작하는 목록까지도 주의 깊게 다룹니다.

- **Technical Details**: 논문에서는 도구가 어떻게 작동하는지 설명하고 2019년에 동일한 데이터셋에서 사용할 수 있었던 결과들과 비교합니다. 이 시스템은 따옴표나 하이픈으로 도입된 문장, 괄호로 도입된 삽입구, 콜론으로 도입된 목록 등 다양한 상황을 처리하기 위해 설계되었습니다.

- **Performance Highlights**: 이 시스템의 성능은 테스트 코퍼스에서 평가되었으며, 2019년에 보고된 결과들과 비교하여 개선된 성능을 보여주었습니다. 이 시스템은 복잡한 상황에서도 정확하게 문장 분할을 수행할 수 있습니다.



### Cool-Fusion: Fuse Large Language Models without Training (https://arxiv.org/abs/2407.19807)
- **What's New**: 이 논문에서는 두 개 이상의 이질적인 대형 언어 모델(LLMs)를 결합하여 각각의 강점을 활용하려는 문제를 다룹니다. 이 연구에서는 새로운 접근법인 	extit{Cool-Fusion}을 제안합니다. 이는 기존의 앙상블(ensemble) 방법과 다르게 어떠한 종류의 트레이닝도 필요로 하지 않으면서 서로 다른 vocabularies를 가진 LLM들을 결합할 수 있도록 설계되었습니다.

- **Technical Details**: 	extit{Cool-Fusion}의 기본 아이디어는 각 소스 LLM이 개별적으로 토큰(tokens)을 생성하여, 해당 토큰들이 모든 소스 LLM에 공통된 단어 경계에서 텍스트 세그먼트로 해독될 수 있을 때까지 진행됩니다. 그 다음, 소스 LLM들이 공동으로 생성된 텍스트 세그먼트를 재랭킹(rerank)하고 최적의 세그먼트를 선택합니다. 이러한 방식으로, 한 단계에서 결합된 텍스트 생성을 수행합니다.

- **Performance Highlights**: 	extit{Cool-Fusion}은 다양한 benchmark 데이터셋을 통해 광범위한 실험을 수행했습니다. 그 중 	extit{GSM8K} 데이터셋에서 	extit{Cool-Fusion}은 세 가지 강력한 소스 LLM들의 정확도를 8\%에서 17.8\%까지 크게 향상시켰습니다.



### Teaching LLMs at Charles University: Assignments and Activities (https://arxiv.org/abs/2407.19798)
Comments:
          6th TeachNLP workshop at ACL 2024

- **What's New**: 이 논문은 Charles University에서 새롭게 개설된 '대형 언어 모델(Large Language Models, LLMs)' 과정에서 사용된 학습 자료, 특히 과제와 교실 활동 아이디어를 소개합니다.

- **Technical Details**: 과제에는 기상 보고 생성(weather report generation)과 기계 번역(machine translation)을 위한 LLM 추론 실험이 포함됩니다. 교실 활동으로는 수업 퀴즈, 다운스트림 작업(downstream tasks)과 데이터셋에 대한 집중 연구, 그리고 연구 논문 읽기 및 이해를 목표로 한 '최고의 논문' 세션이 있습니다.

- **Performance Highlights**: 이번 과정을 통해 학생들은 LLM을 활용한 다양한 실제 응용 프로그램에서 실험을 수행하고, 최신 연구 동향을 파악하며, 연구 논문을 읽고 이해하는 능력을 배양하게 됩니다.



### VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks (https://arxiv.org/abs/2407.19795)
Comments:
          31 pages, 5 figures, 20 tables

- **What's New**: 도메인 일반화(Domain Generalization)는 딥러닝 모델의 중요한 측면입니다. 이는 모델이 보지 못한 도메인의 데이터에서도 잘 수행할 수 있는 능력을 결정합니다. 그러나 시각-언어 작업(Vision-Language Tasks)을 위한 딥러닝 모델의 도메인 일반화에 대한 연구는 필수 데이터셋의 부족으로 인해 제한적이었습니다. 이를 해결하기 위해 VolDoGer(Vision-Language Dataset for Domain Generalization)를 제안합니다. 이는 이미지 캡셔닝, 비주얼 질문 응답, 비주얼 엔테일먼트(Visual Entailment) 등 세 가지 시각-언어 작업을 다루는 전용 데이터셋입니다.

- **Technical Details**: VolDoGer는 LLM 기반 데이터 주석 기법을 시각-언어 작업에 확장하여 인간 주석자(Human Annotators)를 모집하는 부담을 줄였습니다. 다양한 모델, 예를 들어, Fine-Tuned 모델에서 최근의 멀티모달 대형 언어 모델(Multimodal Large Language Model)까지 VolDoGer를 통해 도메인 일반화 능력을 평가했습니다.

- **Performance Highlights**: VolDoGer 데이터셋을 통해 다양한 모델의 도메인 일반화 성능을 체계적으로 평가할 수 있게 되었습니다. 이를 통해 특정 모델을 더 효과적으로 도출하고, 시각-언어 작업에서의 도메인 일반화 가능성을 탐구할 수 있습니다.



### Introducing a new hyper-parameter for RAG: Context Window Utilization (https://arxiv.org/abs/2407.19794)
- **What's New**: 이 논문에서는 Retrieval-Augmented Generation (RAG) 시스템을 위한 새로운 하이퍼파라미터 'Context Window Utilization'을 소개합니다. RAG 시스템은 외부 지식 베이스에서 검색된 관련 정보를 통합하여 생성 모델의 정확성과 맥락 관련성을 높입니다.

- **Technical Details**: 연구는 텍스트 청크 크기(chunk size)가 RAG 성능에 미치는 영향을 체계적으로 실험합니다. 이를 위해 서로 다른 청크 크기를 사용하여 RAG 프레임워크의 효율성과 효과성을 분석합니다. 연구 결과, 최적의 청크 크기는 충분한 컨텍스트를 제공하면서도 불필요한 정보를 최소화하는 균형점을 가지고 있음을 발견했습니다.

- **Performance Highlights**: 최적의 청크 크기를 선택함으로써 RAG 시스템의 디자인과 구현을 개선할 수 있습니다. 이 통찰력은 고성능 RAG 시스템 개발에 중요한 요소입니다.



### Synthesizing Scientific Summaries: An Extractive and Abstractive Approach (https://arxiv.org/abs/2407.19779)
Comments:
          the paper consists of 10 pages , 5 figures and 4 tables

- **What's New**: 이 논문에서는 연구 논문 요약을 위한 하이브리드 방법론을 제안합니다. 기존의 변형된 transformer 모델(attention mechanisms)이나 담화 정보(discourse information)를 활용한 접근 방식과 달리, 이 방법론은 추출적 요약(extractive summarisation)과 생성적 요약(abstractive summarisation)의 접근 방식을 결합합니다.

- **Technical Details**: 이 방법론은 첫째, 비지도 학습(unsupervised learning) 기반의 모델 두 개를 사용하여 연구의 주요 발견을 추출합니다. 그리고 두 번째로, 두 개의 transformer 언어 모델을 사용하여 추출된 키 포인트와 논문의 도입 부분을 취합해 요약합니다. 이로 인해 네 가지 조합의 하이브리드 모델이 생성됩니다. 각 모델의 성능은 세 가지 메트릭으로 평가됩니다.

- **Performance Highlights**: 특정 하이퍼 파라미터(hyper parameters) 조합을 활용할 경우, 사람이 쓴 요약보다 높은 수준의 추상성을 가지는 요약이 가능하다는 것을 발견했습니다. 이는 자동 요약 시스템의 잠재력에 대한 중요한 발견입니다.



### Legal Minds, Algorithmic Decisions: How LLMs Apply Constitutional Principles in Complex Scenarios (https://arxiv.org/abs/2407.19760)
Comments:
          Accepted at AIES24

- **What's New**: 이번 연구에서는 대규모 언어 모델(large language models, LLMs), 특히 GPT-4가 복잡한 의사 결정 시나리오에서 헌법 원칙을 해석하는 방식을 실증적으로 분석합니다. 이탈리아 헌법재판소의 생명윤리 문제에 대한 판결을 살펴보고, 이러한 문제에 대한 모델 생성 법적 주장을 국가, 법원 및 신청인의 주장과 비교했습니다.

- **Technical Details**: 연구는 주로 GPT-4가 헌법 해석에서 어떻게 행동하는지를 분석했습니다. 특히 헌법재판에서 상대적인 가치 간의 균형(trade-offs)에 대한 모델 생성 법적 주장이 신청인의 진보적 해석과 더 밀접하게 일치하고, 국가의 보수적 관점이나 법원의 중도적 입장을 간과하는 경향이 있음을 발견했습니다.

- **Performance Highlights**: 실험 결과 GPT-4가 진보적 헌법 해석을 선호하는 뚜렷한 경향이 있다는 것을 밝혔습니다. 이는 기저 데이터의 편향(inherent data biases)의 영향을 반영하며, 실제 시나리오에서의 정렬(alignment) 테스트와 LLM의 의사 결정 과정에 대한 배포 고려의 중요성을 강조합니다.



### KNOWCOMP POKEMON Team at DialAM-2024: A Two-Stage Pipeline for Detecting Relations in Dialogical Argument Mining (https://arxiv.org/abs/2407.19740)
Comments:
          Published on the 11th Workshop on Argument Mining

- **What's New**: Dialogical Argument Mining(DialAM) 분야에서 중요한 성과가 발표되었습니다. DialAM-2024라는 새로운 공유 테스크가 등장했으며, 이는 대화형 논증 마이닝을 중점으로 다룹니다. 이 과제로부터 우리는 명제 노드(proposition nodes)와 발화 노드(locution nodes) 사이에 논증 관계 및 발화의도를 식별해야 합니다.

- **Technical Details**: 이를 위해 두 단계 파이프라인 접근법을 제안했습니다. 첫 번째 단계는 Two-Step S-Node Prediction Model이며, 두 번째 단계는 YA-Node Prediction Model입니다. 각 단계에서 훈련 데이터를 증강하고, 두 번째 단계에서는 문맥(context)을 도입했습니다.

- **Performance Highlights**: 우리 팀 Pokemon은 이 테스크를 성공적으로 완료하였고, ARI Focused 점수에서 1위를, Global Focused 점수에서 4위를 차지했습니다.



### Do Text-to-Vis Benchmarks Test Real Use of Visualisations? (https://arxiv.org/abs/2407.19726)
Comments:
          ARR AE score of 4

- **What's New**: 본 논문은 대형 언어 모델(Large Language Models)이 사용자 요청에 따라 시각화를 위한 코드를 생성할 수 있는 능력을 연구합니다. 이는 데이터 시각화가 언어적 기반을 제공하여 NLP 연구에 매력적인 응용 프로그램이라는 점에서 의미가 큽니다. 그러나 현재 존재하는 벤치마크가 실제 사용 사례를 얼마나 잘 대표하는지 알 수 없다는 문제가 있습니다. 이를 해결하기 위해 본 연구는 벤치마크 데이터셋과 공개 저장소의 코드를 비교하는 실증 연구를 수행했습니다.

- **Technical Details**: 연구 결과, 기존 데이터셋에서는 차트 유형(distribution of chart types), 속성(attributes), 작업 수(number of actions)와 같은 필수 요소들에 대한 평가가 불충분하다는 것을 발견했습니다. 유일하게 대표성을 갖는 데이터셋은 실질적이고 실용적인 벤치마크가 되기 위해 몇 가지 수정이 필요합니다.

- **Performance Highlights**: 이 연구 결과는 새로운 데이터셋 생성에 필요한 가이드라인을 제시하게 됩니다. 특히, 사용자들의 시각화 요구를 충실히 반영하는 시스템 개발을 지원하기 위한 더 많은 벤치마크가 필요하다는 것을 강조합니다. 이를 통해 사용자에게 진정으로 의미 있는 시각화를 제공할 수 있는 시스템 개발이 가능하게 될 것입니다.



### CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcar (https://arxiv.org/abs/2407.19705)
Comments:
          Technical Report

- **What's New**: 이 연구는 Comprehensive Medical Benchmark in Chinese (CMB)를 중심으로, Supervised Fine-Tuning(SFT)에서 데이터셋의 다양성과 분포가 어떻게 대형 언어 모델(LLMs)의 성능을 향상시킬 수 있는지에 대해 집중합니다. 특히, 작은 베이스 모델을 훈련시켜 더 큰 모델과 견줄만한 성적을 달성했다는 점이 주목할 만합니다. 데이터셋의 다양성과 잘 분포된 데이터를 활용하면 모델 크기에 관계없이 최적의 성능을 달성할 수 있다는 것을 보여줍니다.

- **Technical Details**: 이 연구는 데이터 품질 불일치와 같은 잠재적인 문제를 해결하기 위해 다양한 지도 기반 내용을 통합합니다. 또한, 훈련 데이터의 폭넓은 스펙트럼이 모델의 범용성과 여러 의료 시나리오에서의 효과적인 성능을 향상시킬 수 있음을 시사합니다. 이것은 Fine-Tuning 과정에서 데이터셋 품질과 다양성의 중요성을 강조합니다.

- **Performance Highlights**: 작은 베이스 모델로 더 큰 모델과 유사한 성적을 달성함으로써, 작은 모델도 신중하게 선별되고 다양한 데이터셋을 통해 높은 성능 수준에 도달할 수 있음을 보여줍니다. 이는 훈련 데이터의 다양성과 분포가 모델 성능에 중요한 영향을 미친다는 증거를 제공합니다.



### SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages (https://arxiv.org/abs/2407.19672)
- **What's New**: SeaLLMs 3는 동남아시아 언어들을 위한 최신 대형 언어 모델(LLMs)로, 인도네시아어, 베트남어, 태국어, 타갈로그어, 말레이어, 버마어, 크메르어, 라오어, 타밀어, 자바어 등 다양한 언어를 지원하고 있습니다. 이는 주로 영어와 중국어 같은 고자원 언어들에 집중된 기존 연구들과 달리, 상대적으로 지원이 부족했던 저자원 언어들을 겨냥하고 있습니다.

- **Technical Details**: SeaLLMs 3는 효율적인 언어 향상 기법(efficient language enhancement techniques)과 특별히 구성된 학습 데이터셋(instruction tuning dataset)을 활용하여, 훈련 비용을 크게 줄이면서도 높은 성능과 다용성을 유지합니다. 세계 지식(world knowledge), 수학적 추론(mathematical reasoning), 번역(translation), 지침 따르기(instruction following) 등의 여러 작업에서 뛰어난 성능을 보입니다.

- **Performance Highlights**: 유사한 크기의 모델들 중에서 최첨단 성능(state-of-the-art performance)을 달성했으며, 안전성과 신뢰성도 중시하여, 일반적 및 문화 특유의 요소들에서 모두 오류(hallucinations)를 줄이는 메커니즘을 통합했습니다.



### Overview of PerpectiveArg2024: The First Shared Task on Perspective Argument Retrieva (https://arxiv.org/abs/2407.19670)
- **What's New**: 이 논문에서는 첫 번째 퍼스펙티브 아규먼트 리트리벌(shared task on perspective argument retrieval)을 제안합니다. 이는 쿼리(Query)와 아규먼트(Arguments)의 의미적 정렬만을 사용하는 기존 접근법과 달리, 리트리벌 과정에서 퍼스펙티브(Perspectives)를 고려하여 잠재적 영향을 평가합니다. 새로운 다중언어 데이터셋(multilingual dataset)은 연령, 성별, 정치적 태도와 같은 인구통계학적 및 사회문화적(socio) 변수를 포함합니다.

- **Technical Details**: 이 연구는 명시적으로(쿼리와 코퍼스 둘 다) 및 암시적으로(쿼리만) 형성된 퍼스펙티브를 고려하는 세 가지 시나리오를 구분합니다. 주요한 도전과제는 소시오 프로필을 명시적으로 제공하지 않고 퍼스퍼널라이제이션(personalization)을 목표로 할 때 퍼스펙티브를 통합하는 것입니다. 이 논문은 여섯 가지 제출 시스템의 성과를 요약합니다.

- **Performance Highlights**: 리트리벌 시스템은 다수 그룹(majority group)에 대해 편향되는 경향이 있으며, 여성에 대한 편향은 부분적으로 감소시켰습니다. 퍼스펙티브 아규먼트 리트리벌의 초기 단계에서는 성과가 있었지만, 개인화(personalization)와 분극화(polarization) 감소를 위해 최적화를 진행하는 추가 연구가 필요합니다.



### mGTE: Generalized Long-Context Text Representation and Reranking Models for Multilingual Text Retrieva (https://arxiv.org/abs/2407.19669)
Comments:
          20 pages, 5 figures

- **What's New**: 우리는 처음으로 긴 문맥(멀티런구문맥, long-context) 다국어 텍스트 표현 모델(Text Representation Model, TRM)과 재순위기(reranker)를 제롬 구축했습니다. 이 모델은 이전의 다국어 인코더보다 긴 8192-토큰 문맥에서 학습되었습니다.

- **Technical Details**: 새로운 텍스트 인코더(text encoder)는 RoPE와 unpadding 기법이 적용되어 원본 토큰 문맥을 8192개로 확장하였습니다. 하이브리드 TRM 및 교차 인코더 재순위기(cross-encoder reranker)는 대조 학습(contrastive learning)을 통해 구축되었습니다.

- **Performance Highlights**: 새로 제안된 텍스트 인코더는 기존의 같은 크기의 최첨단 XLM-R보다 뛰어난 성능을 보였습니다. 또한, 우리의 TRM과 재순위기는 대형 슈퍼모델인 BGE-M3와 맞먹는 성능을 자랑하면서도 긴 문맥 검색 벤치마크에서 더 나은 결과를 달성했습니다. 추가 분석 결과, 제안된 모델들은 학습 및 추론 시 높은 효율성을 나타냈습니다.



### From Pre-training Corpora to Large Language Models: What Factors Influence LLM Performance in Causal Discovery Tasks? (https://arxiv.org/abs/2407.19638)
- **What's New**: 최근 인공지능 분야의 발전으로 인해 Large Language Models (LLMs)이 인과 발견(causal discovery) 작업에서 놀라운 능력을 보여주고 있습니다. 본 연구는 인과 발견 작업에서 LLM의 성능에 영향을 미치는 요인들을 탐구합니다. 특히, LLM의 사전 학습 코퍼스에서 인과 관계가 등장하는 빈도가 모델의 성능에 미치는 영향을 조사합니다.

- **Technical Details**: 오픈 소스 LLM을 활용하여 인과 관계가 빈번히 언급되는 데이터로 학습된 모델이 인과 발견 쿼리에 얼마나 정확하게 응답할 수 있는지를 분석하였습니다. 연구 결과에 따르면, 인과 정보에 대한 노출 빈도가 높을수록 모델의 성능이 향상되는 것으로 나타났습니다. 또한, 컨텍스트(상황)의 변화가 인과 관계의 타당성에 미치는 영향을 조사한 결과, 동일한 인과 관계도 다양한 컨텍스트에서 서로 다른 예측을 보일 수 있음을 확인했습니다.

- **Performance Highlights**: 본 논문은 인과 발견 작업에서 LLM 성능에 기여하는 다양한 요인에 대한 첫 종합적인 분석을 제공하며, 몇 가지 중요한 발견을 제시합니다. 먼저, 인과 관계에 대한 높은 빈도의 노출이 모델의 성능 향상에 기여함을 밝혔습니다. 또한, 컨텍스트 변화가 인과 관계 예측에 중대한 영향을 미칠 수 있다는 점도 확인했습니다.



### LoginMEA: Local-to-Global Interaction Network for Multi-modal Entity Alignmen (https://arxiv.org/abs/2407.19625)
Comments:
          Accepted by ECAI 2024

- **What's New**: 새로운 논문에서는 Multi-modal entity alignment (MMEA)을 위한 새로운 접근법, 'LoginMEA(Local-to-Global Interaction Network for MMEA)'을 제안합니다. 이 접근법은 로컬 멀티-모달 인터랙션(local multi-modal interactions)을 융합하여 전체 엔티티 시맨틱(holistic entity semantics)을 생성하고, 이를 엔티티 이웃의 글로벌 관계 인터랙션(global relational interactions)으로 정제하는 방식입니다.

- **Technical Details**: LoginMEA는 다른 방식과 차별화되게 유니-모달 정보(uni-modal information)를 적응적으로 융합하고, 관계에 따라 정보를 정제할 수 있는 디자인을 채택하고 있습니다. 이를 위해 첫째, 모달리티 가중치(modality weights)와 저-랭크(interactive fusion)을 통해 멀티-모달 엔티티 정보를 로컬에서 다채롭게 상호작용할 수 있도록 했습니다. 둘째, 그래프 구조의 글로벌 인터랙션을 포착하기 위해 'relation reflection graph attention networks'를 도입하여 엔티티 간의 관계적 연관성을 충분히 포착합니다.

- **Performance Highlights**: 광범위한 실험을 통해 5개의 크로스-KG(cross-KG) 또는 이중 언어 벤치마크 데이터셋에서 LoginMEA의 우수한 성능을 입증했습니다. 이는 로컬 및 글로벌 인터랙션을 효과적으로 포착하는 데 있어 이 방법이 뛰어남을 시사합니다.



### You shall know a piece by the company it keeps. Chess plays as a data for word2vec models (https://arxiv.org/abs/2407.19600)
Comments:
          14 pages, 7 figures

- **What's New**: 이 논문은 비언어적 데이터인 체스 경기에 언어학적 분석 방법을 적용하여, 체스 잡기를 메타포(Metaphor)적으로 언어와 동일시하고 유사성을 모색하고자 합니다. 체스 경기 노테이션(notation)도 일종의 텍스트이며, 체스 말의 위치나 움직임 기록을 특정 언어의 단어와 문장으로 간주할 수 있습니다. 이 논문에서는 언어 모델인 워드 임베딩(word embeddings, word2vec)을 체스 게임 텍스트에 적용하는 방법을 제시합니다.

- **Technical Details**: 언어 모델인 word2vec을 사용하여 체스의 경기 기록을 분석합니다. 자연어 텍스트가 아닌 체스 데이터를 벡터 모델(vector models)로 표현하는 방법론을 설명합니다. 이러한 방법론을 통해 체스 게임의 본질에 대해 중요한 정보를 캡처할 수 있음이 명확하지만, 이러한 표현 방식이 최적의 움직임을 선택하는 데 직접적으로 도움을 줄 가능성은 낮다고 논문은 언급합니다.

- **Performance Highlights**: 제안된 방법론이 체스 엔진이나 사람들에게 최적의 움직임을 선택하는 데 도움이 되는 것은 아니지만, 순수한 학문적 관점에서 체스 게임의 본질을 포착하는 방식에 있어 중요한 정보를 제공할 수 있음을 보여줍니다.



### Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judg (https://arxiv.org/abs/2407.19594)
- **What's New**: 대형 언어 모델(LLMs)이 많은 도메인에서 인간 지식을 빠르게 추월하고 있습니다. 전통적으로 이러한 모델의 개선에는 비용이 많이 드는 인간 데이터가 필요했지만, 최근의 자기 보상 메커니즘(self-rewarding mechanisms)을 통해 LLMs가 인간 레이블러에 의존하지 않고 자신의 응답을 판단하여 개선할 수 있다는 점이 입증되었습니다. 본 연구에서는 모델의 판단 능력을 개선하기 위해 새로운 메타 보상(Meta-Rewarding) 단계를 도입했습니다. 이는 모델이 자신의 판단을 평가하고 그 피드백을 사용하여 판단 능력을 향상시키는 방법입니다.

- **Technical Details**: 기존의 방법들은 주로 모델 응답을 개선하는 데 중점을 두었기 때문에 반복 학습 동안 빠르게 포화 상태에 도달하는 문제가 있었습니다. 이를 해결하기 위해, 메타 보상(Meta-Rewarding) 단계를 추가했습니다. 이 단계에서 모델은 자신의 판단을 다시 한 번 평가하고, 이 과정을 통해 점진적으로 자신을 개선합니다. 이 접근법은 감독되지 않은 방식(unsupervised approach)으로 수행되었습니다.

- **Performance Highlights**: 놀랍게도, 이 비감독 방식은 모델의 판단 능력뿐만 아니라 지시에 따르는 능력까지도 향상시켰습니다. Llama-3-8B-Instruct 모델은 AlpacaEval 2에서 승률이 22.9%에서 39.4%로, Arena-Hard에서 20.6%에서 29.1%로 증가하는 성과를 보였습니다. 이러한 결과는 인간의 감독 없이 모델이 스스로 개선할 수 있는 가능성을 강하게 시사합니다.



### SaulLM-54B & SaulLM-141B: Scaling Up Domain Adaptation for the Legal Domain (https://arxiv.org/abs/2407.19584)
- **What's New**: 이 연구에서는 법률 분야에 특화된 두 가지 대형 언어 모델(LLM), SaulLM-54B와 SaulLM-141B를 소개합니다. 이 모델들은 각각 540억과 1410억 개의 파라미터를 가지며, Mixtral 아키텍처를 기반으로 합니다. SaulLM-54B와 SaulLM-141B는 대규모 도메인 적응을 통해 개발되었습니다. 세 가지 주요 전략에 따라 개발되었습니다: (1) 5400억 개 이상의 법률 토큰을 포함하는 기본 코퍼스를 활용한 지속적인 사전 학습, (2) 특화된 법률 지시 따르기 프로토콜의 구현, (3) 법률 해석에서 모델 출력과 인간 선호도의 일치입니다.

- **Technical Details**: SaulLM-54B와 SaulLM-141B는 Mixtral 아키텍처를 기반으로 합니다. 이 두 모델은 대규모 법률 토큰을 포함한 기본 코퍼스를 활용하여 지속적인 사전 학습을 진행합니다. 또한, 특화된 법률 지시 따르기 프로토콜과 합성 생성 데이터의 통합을 통해 모델의 법률 텍스트 해석 및 처리 능력을 향상시켰습니다. 마지막으로, 모델 출력이 인간의 법률 해석 선호도와 일치하도록 조정되었습니다. 이러한 과정에서 domain-specific adaptation (도메인 특화 적응)의 trade-off (트레이드오프)를 탐구했습니다.

- **Performance Highlights**: SaulLM-54B와 SaulLM-141B는 LegalBench-Instruct에서 이전의 공개 소스 모델들을 능가하는 성능을 보여주었습니다. 학습된 방법들은 법률 해석 및 처리에서 최첨단 성능을 달성했으며, 이는 향후 도메인 적응 연구에 유용한 통찰을 제공합니다. 연구팀은 SaulLM-54B와 SaulLM-141B 모델의 base, instruct, aligned 버전을 MIT 라이센스 하에 공개하여 재사용 및 협력 연구를 촉진하고자 합니다.



### Are LLMs Good Annotators for Discourse-level Event Relation Extraction? (https://arxiv.org/abs/2407.19568)
- **What's New**: 이 논문에서는 대형 언어 모델(LLM)이 담화 수준의 사건 관계 추출(ERE) 작업에서 얼마나 효과적인지 평가합니다. 특히, 길고 복잡한 문서를 다루는 방법과, 대명사 핵어(Coreference), 시간적(Temporal), 원인(Causal), 하위 사건의 종류(Subevent)에 관한 관계를 포함하는 작업들에 초점을 맞춥니다.

- **Technical Details**: 상용 모델인 GPT-3.5와 오픈소스 모델인 LLaMA-2를 사용해 담화 수준의 ERE 작업에서 대형 언어 모델의 성능을 평가합니다. 연구 결과, 감독 학습(Supervised Learning)을 통해 확립된 기준 모델에 비해 LLM은 눈에 띄게 낮은 성능을 보였습니다. 감독된 세부 조정(Supervised Fine-Tuning, SFT)을 통해 LLM 성능을 개선할 수 있으나, 더 작은 감독된 기준 모델에 비해 확장성이 좋지 않았습니다.

- **Performance Highlights**: 양적 및 질적 분석 결과, LLM은 사건 관계를 추출할 때 이벤트 언급을 잘못 만들거나, 관계 간 전이 규칙(Transitivity rules)을 포착하지 못하고, 먼 거리의 관계(Long distance relations)를 감지하지 못하며, 밀집된 사건 언급(Context with dense event mentions)을 이해하지 못하는 등 여러 약점을 드러냈습니다.



### Motamot: A Dataset for Revealing the Supremacy of Large Language Models over Transformer Models in Bengali Political Sentiment Analysis (https://arxiv.org/abs/2407.19528)
Comments:
          Accepted for publication in "The IEEE Region 10 Symposium (TENSYMP 2024)"

- **What's New**: 방글라데시 선거 기간 동안의 정치적 감성 분석에 관한 연구에서 새로운 'Motamot' 데이터셋이 소개되었습니다. 이 데이터셋은 다양한 온라인 신문 포털에서 수집된 긍정적 및 부정적 감정을 주석으로 달아 총 7,058개의 예시로 구성되었습니다.

- **Technical Details**: 이 연구에서는 여러 Pre-trained Language Models (PLMs)와 Large Language Models (LLMs)를 활용하여 감정 분석의 효율성을 평가했습니다. 평가된 PLM에는 BanglaBERT, Bangla BERT Base, XLM-RoBERTa, mBERT, 그리고 sahajBERT가 포함됩니다. LLM으로는 Gemini 1.5 Pro와 GPT 3.5 Turbo가 사용되었습니다. 또한, zero-shot와 few-shot 학습 전략을 통해 감정 분석 방법론을 강화하려는 시도도 수행되었습니다.

- **Performance Highlights**: 결과적으로, BanglaBERT가 PLM 중에서 88.10%의 정확도를 기록하여 매우 우수한 성능을 보였습니다. 반면, few-shot 학습 기술을 적용한 Gemini 1.5 Pro는 96.33%의 정확도로 최고 성능을 발휘했으며, 이는 GPT 3.5 Turbo의 94%를 능가하는 결과입니다.



### Open Sentence Embeddings for Portuguese with the Serafim PT* encoders family (https://arxiv.org/abs/2407.19527)
- **What's New**: 이 논문은 포르투갈어 문장 인코더(Sentence encoder)인 Serafim PT* 시리즈를 소개합니다. Serafim PT*는 여러 크기로 제공되어 다양한 하드웨어 및 계산 예산에 적합하며, 상업적 및 연구 목적으로 사용할 수 있는 자유로운 라이선스 하에 공개됩니다.

- **Technical Details**: 이 논문은 최상위 성능을 지지하는 학습 목표와 매개변수 선택 기준에 대한 체계적인 연구 및 배운 교훈을 함께 제시합니다. 또한 문장 인코더들이 입력의 의미를 인코딩함으로써 분류, 클러스터링 또는 검색과 같은 주요 다운스트림 응용 프로그램을 가능하게 합니다.

- **Performance Highlights**: 각 모델은 최신(State-of-the-art) 성능을 보이며, 상업적 및 연구 목적으로 혼용이 가능함을 명시하고 있습니다.



### Impact of Decoding Methods on Human Alignment of Conversational LLMs (https://arxiv.org/abs/2407.19526)
- **What's New**: 이 연구는 대형 언어 모델(LLMs)을 사람들의 대화에 더 잘 맞추기 위한 방법을 탐구합니다. 주로 웹에서 수집된 데이터로 학습된 기존 LLMs는 정보 텍스트와 유사한 목소리를 가지고 있어 실제 사람들의 대화와는 차이가 있습니다. 본 논문에서는 Beam Search, Top K 샘플링(Top K Sampling), Nucleus 샘플링(Nucleus Sampling)과 같은 디코딩 방법이 LLM 생성 대화와 실제 인간의 대화 간의 정렬에 미치는 영향을 조사합니다.

- **Technical Details**: 논문은 대화의 내용, 스타일, 심리적 지향의 정렬을 측정하기 위한 새로운 지표를 도입하고, 두 개의 대화 데이터셋을 실험에 사용하였습니다. 연구 결과, Beam Search에서 빔(beam)수 감소와 Nucleus 샘플링의 P 값 감소가 더 좋은 정렬을 이끌어낸다는 점을 밝혔습니다. 또한, 업무 지향적(task-oriented) 및 개방형(open-ended) 데이터셋이 정렬 측면에서 다르게 작용하는 것으로 나타났습니다.

- **Performance Highlights**: 연구는 인간-대화 정렬에 있어 컨텍스트(context)를 고려하는 것이 중요함을 강조하며, 각 디코딩 메소드의 조정이 LLM의 성능에 영향을 미친다는 것을 보여줍니다. 특히, Beam Search에서 적은 빔수를 사용할 때와 Nucleus 샘플링에서 낮은 P 값을 적용할 때 더 나은 정렬 성과가 나타났습니다.



### LLAVADI: What Matters For Multimodal Large Language Models Distillation (https://arxiv.org/abs/2407.19409)
- **What's New**: 최근 다중모달 대형 언어 모델(Multimodal Large Language Models, MLLM)의 급성장은 시각적 이해를 언어 모델에 통합하여 일반화된 지능을 발휘할 수 있는 놀라운 잠재력을 보여주었습니다. 그러나 이러한 모델의 거대한 크기로 인해 메모리와 계산 요구량이 크게 증가하여 널리 보급되기 어렵다는 문제가 있습니다. 이번 연구에서는 새로운 효율적인 모델 구조를 제안하거나 소형 MLLM을 처음부터 훈련하지 않습니다. 대신, 지식 증류(knowledge distillation)를 통해 소형 MLLM을 훈련하는 데 중요한 요소에 초점을 맞춥니다.

- **Technical Details**: 이번 연구는 지식 증류 과정에서 훈련 전략, 모델 선택, 증류 알고리즘에 대한 광범위한 연구를 포함합니다. 본 연구에 따르면, 교사-학생 프레임워크에서 토큰 정렬(joint alignment for tokens)과 로그 정렬(logit alignment)이 중요한 역할을 한다는 결과를 보여줍니다. 또한, 다양한 벤치마크와 적절한 전략을 평가하여 흥미로운 관측 결과를 도출하였습니다.

- **Performance Highlights**: 본 연구 결과, 2.7B 규모의 작은 모델도 7B 또는 13B 파라미터를 가진 대형 모델과 동등한 성능을 발휘할 수 있음을 확인했습니다. 이 연구의 소스 코드와 모델은 추가 연구를 위해 공개될 예정입니다.



### Word Segmentation for Asian Languages: Chinese, Korean, and Japanes (https://arxiv.org/abs/2407.19400)
- **What's New**: 이번 연구는 아시아 언어(Chinese, Korean, Japanese)의 단어 분할(segmentation) 접근법에 대해 자세히 다루고 있습니다. 각 언어별로 단어 분할을 처리하는 방법이 다릅니다. 또한, 각 방법의 장점과 단점을 분석하여 제시하였습니다. 미래 연구의 여지도 논의되었습니다.

- **Technical Details**: 중국어(Chinese), 한국어(Korean), 일본어(Japanese)의 단어 분할을 위한 다양한 접근 방식이 연구되었습니다. 각 언어의 특성에 맞춘 방법론들이 제시되었으며, 방법의 효과를 분석하였습니다. 예를 들어, 통계적 접근법과 규칙 기반 접근법의 비교도 포함됩니다.

- **Performance Highlights**: 각 접근 방식의 장점과 단점이 분석되었습니다. 통계적 방법은 대규모 데이터에서 좋은 성능을 보이는 반면, 규칙 기반 접근법은 언어의 특수성을 잘 반영합니다. 각 언어별 접근법의 실제 성능과 한계에 대한 평가도 이루어졌습니다.



### Inference-Time Selective Debiasing (https://arxiv.org/abs/2407.19345)
- **What's New**: 이번 연구에서는 선택적 편향 제거(selective debiasing)라는 새로운 방법을 제안합니다. 이는 모델 재학습(re-training)이 어려운 상황에서도 예측 성능과 공정성(fairness)을 향상시키기 위한 추론(inference) 단계에서의 안전 장치입니다. 특히, 저품질 예측을 제외하는 대신, LEACE라는 후처리(post-processing) 편향 제거 방법을 사용하여 특정 예측의 편향을 제거합니다.

- **Technical Details**: 이 접근법은 선택적 예측(selective prediction)에서 영감을 얻었으며, 잠재적으로 편향된 모델 예측을 식별하고 이를 이후 단계에서 수정합니다. 문제 있는 예측을 선택하기 위해 KL divergence를 기반으로 한 편향 정량화 방법을 제안합니다. 이는 기존의 불확실성 추정(Uncertainty Quantification, UQ) 방법보다 더 나은 결과를 보여주었습니다.

- **Performance Highlights**: 텍스트 분류 데이터셋에 대한 실험 결과, 선택적 편향 제거가 후처리 방법과 학습 중(at-training) 및 전처리(pre-processing) 단계에서의 편향 제거 기법 간의 성능 격차를 줄이는 데 도움이 된다는 것이 입증되었습니다.



### Do Language Models Have a Critical Period for Language Acquisition? (https://arxiv.org/abs/2407.19325)
- **What's New**: 본 연구는 인간의 언어 습득에 필수적인 기간(Critical Period, CP)이 언어 모델(Language Models, LMs)에도 적용될 수 있는지 탐구합니다. CP는 특히 어린 시절 이후에 제2언어(L2)를 습득하는 것이 어려워지고, 이 시기가 지난 후에 제1언어(L1)를 학습하는 노출이 중단되더라도 L1 숙달도가 크게 감소하지 않는 현상입니다. 연구팀은 LMs에 CP 효과가 인간에게만 독특한 것인지, 아니면 더 넓은 범주의 언어 학습자에게도 공유되는지 테스트했습니다.

- **Technical Details**: 실험에 사용된 LMs는 선천적인 성숙 단계와 직접적인 유사성이 없기 때문에, 순차적으로 L1과 L2를 학습했을 때 CP 효과가 나타나지 않았습니다. 이 결과는 CP 효과가 통계적 학습자의 필연적인 결과라는 주장을 반박하며, 선천적인 메커니즘이 CP 효과를 유발할 수 있음을 시사합니다. 연구팀은 훈련 도중에 정규화기(regularizer)를 도입하여 가소성(plasticity)의 감소를 시뮬레이션함으로써 CP를 역설계(reverse-engineer)할 수 있음을 보여주었습니다. 즉, L1 학습만으로는 CP를 유도하기에 충분하지 않으며, 언어 모델을 더 인지적으로 설득력 있게 만들기 위해 추가적인 엔지니어링이 필요하다는 결론입니다.

- **Performance Highlights**: 연구 결과에 따르면, LMs는 순차적으로 L1과 L2를 학습할 때 CP 효과를 보이지 않았습니다. 이는 LMs가 인간의 언어 습득과 동일한 특성을 가지지 않음을 입증하며, CP 효과가 학습 과정에서 자연적으로 발생하지 않는다는 것을 보여줍니다. 정규화기를 사용하여 인위적으로 CP를 도입한 실험에서는 CP 유사 현상이 일부 관찰되었습니다.



### IBMEA: Exploring Variational Information Bottleneck for Multi-modal Entity Alignmen (https://arxiv.org/abs/2407.19302)
Comments:
          Accepted by ACM MM 2024

- **What's New**: multi-modal entity alignment (MMEA)에 대한 새로운 접근법으로 정보 병목(variational information bottleneck)을 활용한 기술을 소개합니다. 이 기술은 정렬과 관련된 정보를 강조하고 무관한 정보를 억제하여, 다양한 양식별 엔티티 표현을 생성합니다.

- **Technical Details**: 특정 엔티티 표현을 확률 분포로 생성하는 다양한 양식별 변수 인코더(variational encoders)를 설계했습니다. 잘못된 단서를 제한하는 네 가지 정보 병목 정규화항(information bottleneck regularizers)을 통해 양식별 엔티티 표현을 개선합니다. 최종적으로 모든 개선된 양식별 표현을 통합하는 정보 대조 정규화항을 제안하여 MMKGs 간의 엔티티 유사성을 강화합니다.

- **Performance Highlights**: 두 개의 cross-KG 및 세 개의 bilingual MMEA 데이터셋에서 실험을 수행하였고, 본 모델은 이전 최고 성능의 기법들을 일관되게 능가했으며, 자원이 적고 잡음이 많은 데이터 시나리오에서도 유망하고 견고한 성능을 보였습니다.



### The Impact of LoRA Adapters for LLMs on Clinical NLP Classification Under Data Limitations (https://arxiv.org/abs/2407.19299)
Comments:
          Under revisions

- **What's New**: 이 연구는 제한된 자원 환경에서 대형 언어 모델(LLMs)을 미세 조정하여 임상 자연어 처리(NLP) 성능을 개선하기 위한 다양한 어댑터 기술의 적용 가능성을 조사했습니다. 특히 Adapter, Lightweight, TinyAttention, Gated Residual Network (GRN) 네 가지 어댑터 구조를 실험하였습니다.

- **Technical Details**: CamemBERT-bio, AliBERT, DrBERT와 같은 생물의학 사전 학습 모델과 두 개의 Transformer 기반 모델을 사용하여 임상 노트 분류 작업을 수행했습니다. Adapter 구조는 Low-Rank Adaptation(LoRA)와 동일한 역할을 하며, 이들 모델을 제한된 자원 환경에서 미세 조정했습니다. 연구 결과, Gated Residual Network (GRN)가 가장 뛰어난 성능을 보였습니다.

- **Performance Highlights**: 어댑터 구조 사용의 효과는 미미했으나, GRN 구조가 정확도, 정밀도, 재현율, F1 점수에서 0.88의 뛰어난 성과를 달성했습니다. 전체 학습 시간은 LLMs의 경우 1000시간을 초과했으나, 단순한 Transformer 기반 모델은 6시간 이하로 걸렸습니다. 이는 LLMs가 충분한 계산 자원과 더 큰 데이터셋을 필요로 하는 반면, 단순한 Transformer 기반 모델이 제한된 환경에서 더 효율적임을 나타냅니다.



### Understanding Memorisation in LLMs: Dynamics, Influencing Factors, and Implications (https://arxiv.org/abs/2407.19262)
- **What's New**: 대형 언어 모델(LLMs)이 학습 데이터(training data)를 얼마나 기억하고 있는지 이해하는 것은 해당 모델의 출력의 신뢰성과 개인정보 보호에 중요한 영향을 미칩니다. 이를 위해 연구팀은 LLMs를 반복적으로 무작위 문자열에 노출시켜 기억 현상을 측정하는 실험적 프레임워크를 구축했습니다. 이를 통해 모델의 행동 패턴을 더 잘 이해할 수 있게 되었습니다.

- **Technical Details**: 실험에서 Pythia, Phi, Llama2와 같은 모델 계열에서 일관된 기억 단계가 발견되었습니다. 또한 어떤 문자열이 다른 문자열보다 더 쉽게 기억되는지, 지역 접두사(local prefixes)와 전역 문맥(global context)의 역할을 규명했습니다. 무작위 문자열에 대한 순차적 노출이 기억 현상에 중요한 영향을 미친다는 것을 확인했습니다.

- **Performance Highlights**: 실험 결과는 놀라운 관찰들을 제공하며, 이러한 발견은 LLMs의 연구와 사용에 중요한 함의를 갖습니다.



### On Behalf of the Stakeholders: Trends in NLP Model Interpretability in the Era of LLMs (https://arxiv.org/abs/2407.19200)
- **What's New**: 최근 NLP 시스템과 특히 LLMs의 도입으로 인해 다양한 분야의 사용자들이 급속도로 이를 채택하고 있습니다. 이러한 확산은 NLP 모델의 해석 가능성 연구와 기술적 리뷰의 폭발적 증가로 이어졌습니다. 그러나 많은 리뷰들이 설명 이해당사자들의 필요와 관점을 간과하는 경우가 있습니다. 이 논문은 세 가지 근본적인 질문을 다루며 왜 해석 가능성이 필요한지, 무엇을 해석하고, 어떻게 해석하는지를 탐구합니다.

- **Technical Details**: 저자들은 지난 10년 동안 다양한 연구 분야에서의 동향을 분석하기 위해 수천 개의 논문을 수집하고 LLM을 사용하여 이를 특성화했습니다. 해석 가능성 패러다임의 성질과 다양한 이해당사자들에게의 관련성을 조사하며, 기존 해석 가능성 패러다임의 실질적 의미를 탐구합니다.

- **Performance Highlights**: 분석을 통해 NLP 개발자와 비개발자 사용자 간, 그리고 다양한 연구 분야 간의 큰 차이점을 발견했습니다. 예를 들어, 내부 모델 구성요소의 설명은 NLP 분야 외부에서는 거의 사용되지 않습니다. 이러한 발견은 미래의 설계, 개발 및 응용에 있어 다양한 이해당사자들의 목표와 요구사항에 보다 부합하는 방법을 제안하는 데 기여할 것입니다.



### Why Misinformation is Created? Detecting them by Integrating Intent Features (https://arxiv.org/abs/2407.19196)
Comments:
          11 pages, 3 figures. Accepted by CIKM 2024

- **What's New**: 이번 연구에서는 트위터와 레딧과 같은 여러 소셜 미디어 플랫폼에서 효율적이고 편리하게 정보가 퍼질 수 있지만, 잘못된 정보가 포함됨으로써 일상생활에 다양한 피해를 준다는 문제를 다룹니다. 이를 해결하기 위해, 새로운 허위 정보 검출(Misinformation Detection; MD) 방법인 'DM-INTER'(Detecting Misinformation by Integrating Intent featuRes)를 제안합니다. 이 방법은 정보와 허위 정보 사이의 의도(intents) 대립에서 영감을 받아, 기사(articles)의 의도를 추론하고 이에 따른 의도 특징(intent features)을 형성하여 기사의 진위를 더 잘 구별할 수 있도록 합니다.

- **Technical Details**: DM-INTER는 기존 심리학 이론에 참고하여 정보와 허위 정보 모두에 대한 의도 집합의 계층 구조(hierarchy)를 구축하고, 이를 사용하여 기사 의도를 추론합니다. 이 과정은 인코더-디코더 구조(encoder-decoder structure)를 통해 이진 답변(binary answers)을 점진적으로 생성함으로써 이루어집니다. 이후 형성된 의도 특징(intent features)과 토큰 특징(token features)을 통합하여 MD를 위한 더 차별적인 기사 특징을 만듭니다.

- **Performance Highlights**: DM-INTER의 성능을 평가하기 위해, 다양한 기준 벤치마크 MD 데이터셋에서 광범위한 실험을 수행했습니다. 실험 결과, DM-INTER는 기존의 MD 방법들보다 뛰어난 성능을 보임을 확인했습니다.



### Harmfully Manipulated Images Matter in Multimodal Misinformation Detection (https://arxiv.org/abs/2407.19192)
Comments:
          Accepted by ACM MM 2024. Code: this https URL

- **What's New**: 이 논문은 이미지 조작의 흔적과 조작 의도의 유해성 여부를 바탕으로 멀티모달 허위정보 검출(Multimodal Misinformation Detection, MMD)를 개선하는 새로운 방법인 'Harmfully Manipulated Images Matter in MMD (HAMI-M3D)'를 제안합니다. 기존의 MMD 방법들이 놓치고 있는 이미지 조작의 단서를 활용하여 더 정확한 허위정보 검출을 가능하게 합니다.

- **Technical Details**: HAMI-M3D 방식은 이미지가 조작되었는지를 나타내는 조작 특징(manipulation features)과 그 조작이 유해한지 무해한지에 대한 의도 특징(intention features)을 학습합니다. 하지만 조작과 의도에 대한 레이블이 명확하지 않기 때문에, 이미지 조작 탐지를 위한 추가적인 데이터셋을 도입하고 두 가지 분류 작업을 Positive and Unlabeled Learning 문제로 공식화하여 두 가지 약하게 지도된 신호(weakly supervised signals)를 대안으로 사용합니다.

- **Performance Highlights**: 세 가지 벤치마크 데이터셋에서 수행한 실험 결과, HAMI-M3D는 모든 MMD 베이스라인의 성능을 일관되게 향상시켰음을 입증했습니다.



### FarSSiBERT: A Novel Transformer-based Model for Semantic Similarity Measurement of Persian Social Networks Informal Texts (https://arxiv.org/abs/2407.19173)
- **What's New**: 새로운 연구는 두 텍스트의 유사성을 평가하는 작업에 초점을 맞추고 있습니다. 특히 페르시아어의 비공식적인 짧은 텍스트에 대한 의미론적 유사성을 측정하는 새로운 Transformer 기반 모델을 도입했습니다. 또한, 이번 연구는 소셜 네트워크로부터 수집된 실제 데이터를 바탕으로 만든 새로운 데이터셋 'FarSSiM'을 소개합니다.

- **Technical Details**: 제안된 모델은 BERT 아키텍처를 기반으로 하며, 페르시아어 비공식 짧은 텍스트 약 1억 4백만 개를 사용하여 처음부터 학습되었습니다. 이 모델은 'FarSSiBERT'라 불리며, 비공식적 텍스트의 구조와 의미를 보다 효과적으로 이해할 수 있도록 설계되었습니다. 또한, 전통적인 토크나이저가 인식하지 못하는 비공식적 단어까지 정확히 식별할 수 있는 새로운 비공식 언어 전문 토크나이저를 제공합니다.

- **Performance Highlights**: 제안된 모델은 Pearson과 Spearman의 상관 계수 기준에서 기존의 ParsBERT, laBSE 및 다국어 BERT보다 우수한 성능을 보였습니다. 또한, 이 사전학습된 대형 언어 모델은 다른 NLP 작업이나 비공식적 텍스트의 토크나이저로서도 큰 가능성을 보유하고 있습니다.



### Addressing Topic Leakage in Cross-Topic Evaluation for Authorship Verification (https://arxiv.org/abs/2407.19164)
Comments:
          Accepted to publish at Transactions of the Association for Computational Linguistics

- **What's New**: 저자 검증(AV, Authorship verification)을 위해 주제 이동에 대한 모델의 견고성을 평가하는 방법을 제시합니다. 전통적인 평가 방법은 훈련 데이터와 테스트 데이터 간의 주제 중복을 최소화하도록 하지만, 테스트 데이터에서도 여전히 주제 유출이 발생할 수 있어 모델 성능이 왜곡되고 순위가 불안정해질 수 있습니다. 이를 해결하기 위해 다양한 주제 집합이 포함된 소규모 데이터셋을 생성하는 Heterogeneity-Informed Topic Sampling(HITS) 평가 방법을 제안합니다.

- **Technical Details**: HITS는 주제 유출의 원인과 영향을 분석하고, 이를 줄이기 위해 고안되었습니다. 이 방법을 통해 주제가 이질적으로 분포된 소규모 데이터셋을 만들고, 이를 통해 모델의 성능 순위를 더 안정적으로 유지할 수 있습니다. 또한, Robust Authorship Verification bENchmark(RAVEN)를 도입하여 주제별 특징에 의존하는 AV 모델의 단점을 드러낼 수 있습니다.

- **Performance Highlights**: 실험 결과 HITS로 샘플링된 데이터셋은 무작위 시드와 평가 분할에도 견고한 모델 순위를 유지하며, 주제 유출 효과를 줄이는 데 유효함을 입증했습니다.



### Many-Shot In-Context Learning for Molecular Inverse Design (https://arxiv.org/abs/2407.19089)
- **What's New**: 대형 언어 모델(LLMs)은 다양한 생성 및 판별 화학 디자인 작업에 대해 몇 가지 샷(In-Context Learning, ICL)에서 훌륭한 성능을 보였습니다. 이 새로운 연구는 확장된 컨텍스트 윈도우(context windows)를 통해 분자 역설계 및 리드 최적화에서 ICL 능력을 향상시키는 방법을 제시합니다.

- **Technical Details**: 새로운 반지도 학습 방법(semi-supervised learning method)을 개발하여 많은 샷 ICL에 사용할 수 있는 실험 데이터 부족 문제를 해결했습니다. 이 방법은 높은 성능이 예측되는 LLM이 생성한 분자를 실험 데이터와 함께 반복적으로 포함하는 방식입니다. 추가로, 이 방법을 멀티모달 LLM(multimodal LLM)에 통합하여 텍스트 지시를 사용하여 생성된 분자 구조를 상호작용적으로 수정할 수 있도록 했습니다.

- **Performance Highlights**: 이 새로운 방법은 기존의 분자 디자인 ICL 방법에 비해 크게 향상된 성능을 보여주며, 과학자들이 접근하고 사용하기 쉽습니다.



### OfficeBench: Benchmarking Language Agents across Multiple Applications for Office Automation (https://arxiv.org/abs/2407.19056)
Comments:
          Preprint

- **What's New**: OfficeBench라는 새로운 벤치마크가 소개되었습니다. 이는 사무 작업 자동화를 위한 평가 도구로, 현재의 대형 언어 모델(LLM) 에이전트들이 실제 사무 작업 흐름에서의 업무를 얼마나 잘 처리하는지 평가합니다. OfficeBench는 LLM 에이전트들이 긴 계획 수립 및 여러 애플리케이션 간의 전환, 그리고 큰 액션 스페이스 내에서의 정확한 작업 수행을 요구합니다.

- **Technical Details**: OfficeBench에서 평가된 LLM 에이전트에는 GPT-4 Omni가 포함되며, 이 에이전트는 47.00%의 통과율을 기록했습니다. 이는 사무 작업 처리에 있어 상당한 성능을 나타내지만, 실제 사무 환경에서의 인간 성능 및 정확성 기준에는 여전히 미치지 못합니다. 평가 방법에서는 작업별 맞춤형 평가 기법을 적용했습니다.

- **Performance Highlights**: GPT-4 Omni는 사무 작업 처리 시 47.00%의 통과율을 기록했습니다. 하지만 대부분의 문제는 작업 중복(Operation Redundancy)과 환각(Hallucinations) 그리고 여러 애플리케이션 간의 전환의 제한에서 발생했습니다. 이러한 문제는 향후 더 효과적인 에이전트 프레임워크 개발에 중요한 통찰을 제공할 수 있습니다.



### Optimising Hard Prompts with Few-Shot Meta-Prompting (https://arxiv.org/abs/2407.18920)
- **What's New**: 이번 논문에서는 기존의 프롬프트 템플릿(prompt templates)을 사용하여 반복적(iterative)으로 더 나은 템플릿을 생성하는 방법을 제시합니다. 특히 문맥(context)을 LLM에게 공개하지 않고도 템플릿을 최적화할 수 있는 방법을 소개합니다.

- **Technical Details**: 이 연구에서는 LLM이 제공하는 샘플링 방법(few shot sampling methods)과 같은 다양한 최적화 방법을 탐구하였습니다. 이러한 최적화 과정에서는 언어 스타일(linguistic styles)과 구문(syntax)을 유지하면서 프롬프트 템플릿을 개선하게 됩니다. 연구 과정에서 문맥을 마스킹(masking)하고 이를 템플릿으로 사용하는 접근 방식을 사용했습니다.

- **Performance Highlights**: 최적화된 프롬프트 템플릿은 최고의 성능을 보이는 방법으로 103.87%의 개선을 이루었습니다. 또한 다양한 문맥적 작업에서 LLM이 구문을 유지하면서 언어 스타일을 모방하는 능력을 입증했습니다. 이를 통해 다른 프롬프트 템플릿 생성 방법의 출력에 미치는 영향을 분석했습니다.



### Aligning Query Representation with Rewritten Query and Relevance Judgments in Conversational Search (https://arxiv.org/abs/2407.20189)
Comments:
          Accepted by CIKM 2024

- **What's New**: 이번 연구는 복잡한 정보를 해결하기 위해 사용자가 시스템과 여러 차례 상호작용하는 대화형 검색(conversational search)에 대한 새로운 접근 방식을 제시합니다. 제안된 모델 이름은 QRACDR(Query Representation Alignment Conversational Dense Retriever)으로, 기존 대화형 검색 방법들과 다른 접근 방식을 채택합니다.

- **Technical Details**: QRACDR 모델은 대화형 검색 데이터에서 재작성된(conversational query rewriting) 쿼리와 관련성 판단(relevance judgments)을 활용하여 쿼리 표현(query representation)을 향상시킵니다. 주요 아이디어는 쿼리 표현을 재작성된 쿼리 및 관련 문서의 표현과 정렬하는 것입니다. 이 접근 방식은 쿼리 표현과 관련 문서 표현의 적절한 정렬을 통해 검색 성능을 높입니다.

- **Performance Highlights**: QRACDR 모델은 대화형 검색 및 전통적인 검색(ad-hoc search) 환경에서 테스트되었으며, 8개의 데이터셋에서 실험을 진행했습니다. 그 결과, 최신 연구방법들과 비교했을 때 QRACDR 모델의 우수한 성능이 입증되었고, 표현 정렬의 효과가 확인되었습니다.



### AutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs (https://arxiv.org/abs/2407.20177)
- **What's New**: 이번 연구에서는 LLMs(대형 언어 모델, Large Language Models)의 성능을 최적화하고, 다양한 다운스트림 작업에서의 성능을 보장하기 위해 도메인이 다른 데이터를 혼합하여 사전훈련을 진행해야 한다고 제안하고 있습니다. 데이터의 규모에 따라 최적의 데이터 구성이 달라질 수 있기 때문에, 적은 규모의 실험으로 최적의 구성을 찾는 일반적인 방법은 최종 모델에 대해 최적의 데이터 혼합을 제공하지 못할 수 있습니다. 이 문제를 해결하기 위해, AutoScale이라는 자동화 도구가 제안되었습니다.

- **Technical Details**: AutoScale은 원하는 목표 규모에서 컴퓨팅 최적의 데이터 구성을 찾기 위해 만들어진 도구입니다. 먼저 AutoScale은 새로운 이중 최적화 프레임워크인 Direct Data Optimization(DDO)을 사용하여 작은 규모에서 최적의 구성을 결정합니다. 이후 더 큰 규모에서 최적의 구성을 예측할 수 있도록 Predictor를 맞춥니다. 이 Predictor의 설계는 데이터 구성과 관련된 스케일링 법칙에 대한 이론적 분석에서 영감을 받았습니다.

- **Performance Highlights**: 실험 결과, AutoScale은 RedPajama 데이터셋에서 774M Decoder-only LMs (GPT-2 Large)의 사전훈련 시 기존 방법보다 25% 빠르게 검증 퍼플렉시티(validation perplexity)를 감소시키며, 재가중치(reweighting)가 없는 경우에 비해 최대 38% 속도가 향상되었습니다. Encoder-only LMs (BERT)의 사전 훈련에서, DDO는 모든 도메인에서 손실을 줄일 뿐만 아니라 GLUE 벤치마크에서 평균 작업 성능을 8.7%, 대규모 QA 데이터셋 (SQuAD)에서 5.9% 향상시켰습니다. AutoScale은 훈련 속도를 최대 28% 향상시켰으며, 사용된 코드는 오픈소스로 제공됩니다.



### BEExAI: Benchmark to Evaluate Explainable AI (https://arxiv.org/abs/2407.19897)
- **What's New**: 최근 연구에서는 Black-box 머신 러닝 모델의 출력을 이해하기 위한 다양한 사후 설명 방법(Post-hoc attribution methods)이 개발되었습니다. 그러나 이러한 설명의 질을 평가하는 데에는 일관된 접근 방식과 정량적 metrics(메트릭스)를 도출하기 위한 합의된 방법론이 부족합니다. 이에 따라 점점 더 복잡해지는 딥러닝 모델의 설명 품질과 정확성을 측정하는 신뢰할 수 있는 방법 필요성이 대두되고 있습니다. 이를 해결하기 위해 BEExAI라는 벤치마크 도구를 제안하여 다양한 포스트 혹스(POST-HOC) XAI (설명 가능한 인공지능) 방법을 대규모로 비교하고, 선택된 평가 metrics(메트릭스)를 사용합니다.

- **Technical Details**: BEExAI는 여러 포스트 혹스 XAI 방법의 성능을 평가하기 위해 특별히 선택된 평가 metrics(메트릭스) 세트를 적용하여 대규모 비교를 가능하게 합니다. 또한 복잡한 딥러닝 모델에서 발생하는 다양한 데이터 응용 프로그램에 효과적으로 적용할 수 있도록 설계되었습니다.

- **Performance Highlights**: BEExAI를 사용하면 다양한 포스트 혹스 XAI 방법의 효능을 더욱 정량적이고 체계적으로 평가할 수 있습니다. 이를 통해 딥러닝 모델의 설명 가능성과 이해도를 향상시킬 수 있는 잠재력이 있습니다.



### Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability (https://arxiv.org/abs/2407.19842)
- **What's New**: 이 논문은 Large Language Models (LLMs)의 취약점을 정확히 탐지하고 이해하기 위한 새로운 방법을 제안합니다. 이 방법은 새로운 Mechanistic Interpretability (MI) 기법을 사용하여 모델이 특정 작업에서 발생하는 취약점을 식별하고 분석할 수 있게 합니다. 특히, GPT-2 Small 모델을 대상으로 3문자 약어 예측 작업에서의 취약성을 탐지하고 이해하는 데 중점을 둡니다.

- **Technical Details**: 제안된 방법은 세 가지 단계로 구성됩니다: (i) 특정 작업에 책임이 있는 모델의 하위 집합을 식별, (ii) 해당 작업을 위한 적대적 샘플을 생성, (iii) 생성된 샘플을 이용해 MI 기법을 활용하여 모델의 취약성을 발견하고 이해. 이 과정은 딥러닝 모델의 내재된 문제를 심도 있게 분석할 수 있는 새로운 접근 방식을 제공합니다.

- **Performance Highlights**: 제안된 방법은 GPT-2 Small 모델을 활용한 실험에서 구체적인 취약점을 효과적으로 식별하고 이해하는 데 성공하였습니다. 이로써 LLMs의 적대적 공격에 대한 취약성을 줄이는 중요한 한 걸음을 내딛었습니다.



### ML-Mamba: Efficient Multi-Modal Large Language Model Utilizing Mamba-2 (https://arxiv.org/abs/2407.19832)
- **What's New**: ML-Mamba는 최신 Mamba-2 모델을 활용한 멀티모달(multimodal) 언어 모델로, 기존의 Transformer 아키텍처 기반 모델이 가진 계산 복잡성 문제를 해결합니다. Mamba-2 모델은 긴 시퀀스(sequence)의 빠른 처리를 제공하며, 이 모델의 특성을 멀티모달 학습에 통합하는 방법을 탐색합니다.

- **Technical Details**: ML-Mamba는 사전 훈련된(pre-trained) Mamba-2 모델을 사용하여 Transformer 기반 백본을 대체하고, 2차원 시각적 선택 스캐닝 메커니즘(2D visual selective scanning mechanisms)을 멀티모달 학습에 통합합니다. 다양한 시각 인코더(visual encoders) 및 Mamba-2 모델 변형을 실험하였습니다.

- **Performance Highlights**: ['ML-Mamba는 TinyLaVA 및 MobileVLM v2와 같은 최첨단 방법론(state-of-the-art methods)과 비교 가능한 성능을 제공하면서 더 빠른 추론 속도를 보여주었습니다.', 'ML-Mamba는 시각적 환각(visual hallucinations) 및 폐쇄형 셋(closed set) 벤치마크 테스트에서의 공간 관계 판단에서 우수한 성능을 입증했습니다.', 'ML-Mamba는 LLaVA와 비교할 때 40% 적은 매개변수(parameter)로 동일한 성능을 달성했습니다.', '기존 Mamba 모델을 사용하는 멀티모달 모델과 비교하여, Mamba-2 기반의 대규모 멀티모달 언어 모델은 더 우수한 추론 성능과 효율성을 보였습니다.']



### Model Agnostic Hybrid Sharding For Heterogeneous Distributed Inferenc (https://arxiv.org/abs/2407.19775)
- **What's New**: Nesa는 대규모 AI 모델의 비효율적인 중앙집중식 구조를 개선하기 위해 모델 독립적인 샤딩 프레임워크를 제안하고 있습니다. 이 프레임워크는 블록체인 기반의 순차적 딥 뉴럴 네트워크 샤딩을 이용해 다양한 노드 네트워크에 계산 작업을 분산시킵니다. 높은 개인정보 보호와 스케일 확장성을 요구하는 문제에 효율적인 해결책을 제공합니다.

- **Technical Details**: Nesa는 퍼스널라이즈드 히러스틱과 라우팅 메커니즘을 사용하여 컴퓨팅 태스크를 분산시키며, 이를 통해 최근 대규모 모델의 분산 트레이닝 및 추론을 가능하게 합니다. 이를 위해 다이나믹 블록별 양자화(dynamic blockwise quantization)와 혼합 매트릭스 분해(mixed matrix decomposition) 등을 사용하여 데이터 전송량과 메모리 요구량을 감소시킵니다. 또한 하드웨어 기반 신뢰 실행 환경(hardware-based trusted execution environments)을 통합하여 데이터 무결성과 기밀성을 보장합니다.

- **Performance Highlights**: 다양한 자연어 처리(natural language processing) 및 비전 태스크를 평가한 결과, 이러한 압축 기술이 모델 정확도를 손상시키지 않는다는 점을 확인했습니다. 이로 인해 최신 AI 기술을 보다 널리 대중에게 제공할 수 있는 가능성을 강조하며, 소비자용 하드웨어로도 효과적인 분산 추론을 가능하게 합니다.



### Efficiently and Effectively: A Two-stage Approach to Balance Plaintext and Encrypted Text for Traffic Classification (https://arxiv.org/abs/2407.19687)
- **What's New**: 이번 논문은 최초로 평문(plain text)과 암호문(encrypted text)이 모델의 효과성과 효율성에 미치는 영향을 분석했습니다. 이를 기반으로 트래픽 분류 작업에서 평문과 암호문의 균형을 맞추기 위한 2단계 접근법을 제안합니다.

- **Technical Details**: 제안된 접근법은 두 단계로 이루어져 있습니다. 첫 번째 단계는 DPC Selector를 사용하여 평문만으로도 정확히 분류할 수 있는지를 판단합니다. 이 단계는 평문에 명시적인 바이트 특징을 사용하여 모델의 효율성을 높입니다. 두 번째 단계는 첫 번째 단계의 결과를 바탕으로 적응형으로 분류를 진행하며, 평문만으로 분류할 수 없는 샘플의 경우 암호문 정보를 통합하여 모델의 효과성을 보장합니다.

- **Performance Highlights**: 두 개의 데이터셋에서 실험 결과, 제안된 모델이 효과성과 효율성 양면에서 최신의(State-of-the-art) 결과를 달성했습니다.



### TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs (https://arxiv.org/abs/2407.19616)
Comments:
          Accepted to ACM Symposium on Document Engineering 2024 (DocEng 24), 2024

- **What's New**: 비지도 학습 기법인 비음수 행렬 분해(NMF)를 활용하여 텍스트 데이터의 주제를 자동으로 레이블링하는 새로운 방법론을 제안하였습니다. 이는 NMFk와 큰 언어 모델(LLM)을 사용하여 주제 레이블을 자동으로 생성합니다.

- **Technical Details**: NMF는 TF-IDF(용어 빈도-역 문서 빈도) 매트릭스를 분해하여 잠재된 주제를 드러내고 데이터셋을 세그먼트화합니다. 이 연구에서는 자동 모델 결정을 위한 비음수 행렬 분해(NMFk)의 출력을 활용하고, 도움말 엔지니어링을 통해 큰 언어 모델(LLMs)을 사용하여 주제 레이블을 생성합니다.

- **Performance Highlights**: 지식 그래프에 관한 34,000개 이상의 과학 초록을 분석한 케이스 스터디에서, 이 방법론이 지식 관리와 문서 조직화에 효과적임을 입증했습니다.



### Memory-efficient Training of LLMs with Larger Mini-batches (https://arxiv.org/abs/2407.19580)
Comments:
          15 pages, 2 figures, 4 tables

- **What's New**: 이번 연구에서는 대형 미니 배치(mini-batch)를 사용한 훈련 성능과 수렴 속도를 향상시키는 방법을 제안합니다. 매우 큰 매개변수를 가진 대형 언어 모델(LLM, Large Language Models)의 경우, 대형 미니 배치를 사용하는 것이 GPU 메모리 제한으로 불가능해지는 문제를 해결하고자 했습니다. 이를 위해, 대형 미니 배치의 동적 특성을 모방하는 작은 미니 배치를 찾아내는 방법을 고안했습니다.

- **Technical Details**: 작은 미니 배치를 선택하여 대형 미니 배치의 그래디언트(gradients)를 정확히 캡처하는 문제를, 부분 모듈 최대화(submodular maximization) 문제로 공식화하였습니다. 그래디언트의 매우 큰 차원성을 고려하여, 제로스 오더 최적화(zeroth-order optimization)와 신경망 가지치기(pruning)의 아이디어를 활용하여 낮은 차원의 그래디언트 추정(high-quality gradient estimates)을 통해 제한된 메모리 내에서 효과적으로 높은 품질의 부분 집합을 선택하는 방법을 제안합니다.

- **Performance Highlights**: 제안된 방법을 사용하여 메모리 요구량을 2배 줄이고, 훈련 속도를 1.3배 높일 수 있음을 증명하였습니다. 이 효과는 MathInstruct 데이터셋에서 Phi-2를 미세 조정(fine-tuning)하는 과정에서 확인되었습니다. 또한, 제안된 방법은 LoRA와 같은 메모리 효율적 방법과 쉽게 결합하여 추가적인 메모리 절감 효과를 얻을 수 있음을 보여줍니다.



### Visual Riddles: a Commonsense and World Knowledge Challenge for Large Vision and Language Models (https://arxiv.org/abs/2407.19474)
Comments:
this https URL

- **What's New**: 저자들은 Visual Riddles라는 벤치마크를 소개했습니다. 이 벤치마크는 시각 및 언어 모델이 차별화된 시각적 수수께끼를 해석할 수 있는 능력을 테스트하기 위해 설계되었습니다. 총 400개의 시각적 수수께끼가 포함되어 있습니다.

- **Technical Details**: 각 시각적 수수께끼는 고유한 이미지를 가져오며, 다양한 text-to-image 모델을 사용해 만들어졌습니다. 수수께끼에는 질문, 정답, 텍스트 힌트 및 출처 정보가 포함됩니다. 또한, 평가를 자동화할 수 있는 평가 작업도 함께 제공됩니다.

- **Performance Highlights**: 사람의 성능은 82% 정확도로 평가되었지만, 현재 존재하는 모델들은 이에 미치지 못합니다. Gemini-Pro-1.5 모델이 40% 정확도로 가장 높은 성과를 보였으나, 여전히 인간 성능에 비해 차이가 큽니다. 이는 Visual Riddles가 시각 및 언어 모델의 복잡한 시각적 시나리오를 해석하는 능력을 향상시키는 데 중요한 자원임을 시사합니다.



### ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding (https://arxiv.org/abs/2407.19435)
Comments:
          This work is accepted by IROS 2024 (Oral)

- **What's New**: 이 논문에서는 수술 장면 이해에 중요한 수술 도구 세그멘테이션(sepmentation)을 개선하기 위해 ASI-Seg라는 프레임워크를 제안합니다. 새로운 ASI-Seg는 외과의사의 음성 명령(audio commands)을 해석하여 목표로 하는 수술 도구를 정확히 세그멘트화 합니다. 이로 인해 수술 중 불필요한 도구로 인한 혼란을 줄이고, 외과의사가 특정 단계를 수행할 때 더 효율적으로 집중할 수 있도록 도와줍니다. 수동으로 프롬프트(prompts)를 지정하지 않아도 되어 실제 수술 환경에서 더 실용적으로 사용될 수 있습니다.

- **Technical Details**: ASI-Seg 프레임워크는 음성 명령(audio commands)을 파싱하여 세그멘테이션 의도를 해석하는 의도 지향적 멀티모달 융합(intention-oriented multimodal fusion)을 제안합니다. 또한 대조 학습 프롬프트 인코더(contrastive learning prompt encoder)를 이용해 필요한 instrument를 효과적으로 구별하는 방법을 고안했습니다. 이는 Segment Anything Model (SAM)의 능력을 더욱 확장시켜 수동 주석에 의존하지 않고도 정확한 세그멘테이션을 가능하게 합니다.

- **Performance Highlights**: 광범위한 실험 결과, ASI-Seg 프레임워크는 기존의 최신 기술 및 의료 SAMs에 비해 의미론적 세그멘테이션과 의도 지향 세그멘테이션 성능에서 현저한 이점을 보여주었습니다. 이는 외과의사들의 작업 흐름을 개선하고 인지적 부담을 줄여주는 데 큰 기여를 합니다.



### Polynomial Regression as a Task for Understanding In-context Learning Through Finetuning and Alignmen (https://arxiv.org/abs/2407.19346)
Comments:
          ICML Workshop on In-Context Learning

- **What's New**: 최근 Transformer 기반 대형 언어 모델에서의 in-context-learning을 이해하기 위해 단순한 함수 클래스가 부상했습니다. 하지만 기존에 제안된 선형 회귀(linear regression)나 다층퍼셉트론(MLP)은 구조적인 제한으로 인해 모델 내에서의 프롬프트(prompting)와 정렬(alignment) 등을 탐구하는 데 부족함이 있었습니다. 본 논문에서는 단항 다항식 회귀(univariate polynomial regression)를 새로운 함수 클래스로 제안합니다. 이는 프롬프트와 정렬을 연구하기에 충분히 풍부하면서도 시각화와 이해가 용이합니다.

- **Technical Details**: 제안된 함수 클래스는 단항 다항식 회귀로, 이는 복잡하지 않으면서도 프롬프팅(prompting)과 정렬(alignment) 같은 중요한 개념들을 연구할 수 있는 구조를 가집니다. 이 함수 클래스는 기존의 단순한 함수 클래스들과 비교하여 더 나은 시각화 및 이해를 제공합니다.

- **Performance Highlights**: 단항 다항식 회귀를 사용하면 모델의 in-context-learning 능력을 더 명확하게 분석할 수 있으며, 특히 프롬프트(prompt) 및 정렬(alignment) 같은 요소들을 효과적으로 연구할 수 있습니다. 이를 통해 모델의 학습 및 이해 과정을 더 명확하게 시각화할 수 있습니다.



### Parameter-Efficient Fine-Tuning via Circular Convolution (https://arxiv.org/abs/2407.19342)
Comments:
          Work in progress

- **What's New**: 이번 연구에서는 Circular Convolution Adaptation (C$^3$A)이라는 새로운 기법을 제안합니다. C$^3$A는 고성능을 유지하면서도 컴퓨팅 자원과 메모리 효율성 모두 뛰어난 모델 적응(Adaptation) 방식을 제공합니다. 기존의 Low-Rank Adaptation (LoRA)는 낮은 차원의 행렬을 사용해 메모리 사용량을 줄이는 데 기여했지만, 근본적인 저순위 특성으로 인해 성능 제한이 있었습니다. C$^3$A는 이러한 한계를 극복합니다.

- **Technical Details**: C$^3$A는 순환 컨볼루션(Circular Convolution)을 통해 고차원 적응(High-Rank Adaptation)을 실현합니다. 이는 메모리를 많이 차지하는 델타 행렬(Full Delta Matrix)의 문제를 해결하면서도 효율적인 컴퓨팅을 가능하게 합니다. 구체적으로, C$^3$A는 $	extbf{A}$와 $	extbf{B}$ 행렬을 각각 순차적으로 곱셈(Sequential Multiplication)하는 LoRA의 방법론을 확장하며, 보다 높은 성능을 제공합니다.

- **Performance Highlights**: 광범위한 실험을 통해 C$^3$A가 다양한 Fine-Tuning 작업에서 기존의 LoRA 및 그 변형보다 일관되게 더 나은 성능을 발휘함을 확인했습니다. 이는 특히 대규모 기반 모델을 미세 조정할 때 우수한 옵션으로 작용할 수 있습니다.



### Stochastic Parrots or ICU Experts? Large Language Models in Critical Care Medicine: A Scoping Review (https://arxiv.org/abs/2407.19256)
Comments:
          28 pages, 5 figures

- **What's New**: 인공지능(AI)의 급속한 발전과 함께 대규모 언어 모델(LLMs)은 자연 언어 이해, 추론, 생성에서 강력한 능력을 보여주고 있습니다. 본 점검 리뷰(Scoping Review)는 중환자 치료 의학(CCM)에서 LLMs의 적용을 탐구합니다. 2019년 1월 1일부터 2024년 6월 10일까지 PubMed, Embase, Scopus, Web of Science, CINAHL, IEEE Xplore 및 ACM Digital Library의 7개 데이터베이스를 통해 문헌을 검색하였으며, 619개의 초기 논문 중 24편이 최종 리뷰를 위해 선택되었습니다.

- **Technical Details**: 이번 리뷰는 LLMs가 중환자 치료 의학에서 어떻게 사용되는지를 임상 결정 지원(Clinical Decision Support), 의료 문서화 및 보고(Medical Documentation and Reporting), 의료 교육 및 의사-환자 커뮤니케이션(Medical Education and Doctor-Patient Communication)의 세 가지 범주로 나누어 설명합니다. LLMs는 비구조화 데이터(Unstructured Data)를 처리하는 데 유리하며, 수작업 피처 엔지니어링(Manual Feature Engineering)이 필요하지 않습니다. 하지만 환각(Hallucinations), 해석 불가능성(Poor Interpretability), 편향 및 정렬 문제(Bias and Alignment Challenges), 프라이버시 및 윤리적 문제(Privacy and Ethics Issues) 등 여러 도전에 직면해 있습니다.

- **Performance Highlights**: LLMs의 잠재력은 CCM에서 환자 결과를 향상시키고 의료 서비스를 최적화하는 중요한 도구로 작용할 수 있습니다. 하지만 모델 신뢰성 및 해석 가능성을 향상시키고 최신 의학 지식을 통합하며 프라이버시 및 윤리적 지침을 강화하는 것이 미래 연구의 과제로 남아 있습니다. 이 연구는 연구자, 임상의 및 정책결정자들에게 중환자 치료 분야에서 LLMs의 현재 상태와 미래 가능성을 이해하는 데 도움을 줍니다.



### Towards the Dynamics of a DNN Learning Symbolic Interactions (https://arxiv.org/abs/2407.19198)
- **What's New**: 이 연구는 딥 뉴럴 네트워크(DNN)의 학습 상호작용에 대한 두 단계 동역학(twо-phase dynamics)을 증명하고 있습니다. 최근 몇 년 동안, DNN의 후처리 설명(post-hoc explanation) 충실도에 대한 실망스러운 견해에도 불구하고, 입력 샘플이 주어지면 소수의 입력 변수들 간 상호작용이 모든 상세한 추론 논리를 충실하게 표현할 수 있다는 일련의 정리가 증명되었습니다.

- **Technical Details**: 특히 다양한 DNN들이 두 단계 동역학에 따라 다른 복잡도의 상호작용을 학습한다는 것이 관찰되었습니다. 이는 DNN의 일반화 성능(generalization power)이 과소적합(under-fitting)에서 과적합(over-fitting)으로 변화하는 방식을 잘 설명합니다. 본 연구에서는 DNN이 다양한 복잡도의 상호작용을 점차적으로 인코딩하는 동역학을 증명하며, 이를 통해 DNN의 과적합 메커니즘을 이론적으로 설명합니다.

- **Performance Highlights**: 실험 결과는 이론이 다양한 과제(task)에서 여러 DNN의 실제 학습 동역학을 잘 예측함을 보여줍니다.



### Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models (https://arxiv.org/abs/2407.19041)
Comments:
          The paper has been accepted by the 33rd ACM International Conference on Information and Knowledge Management (CIKM) in 2024

- **What's New**: 법률 분야에서의 변혁: 딥러닝과 대형 언어 모델(LLMs)의 진보가 법률 작용에 혁신을 불러오고 있습니다. 연구자는 LLMs의 수학적 추론 능력을 활용한 새로운 접근법을 제안하였습니다. 이 접근법은 특수하게 설계된 프롬프트를 사용하여 법률 인공지능(LegalAI) 응용 프로그램의 정밀 요구사항을 충족시키도록 설계되었습니다. 이를 통해 전통적인 법률 관행과 현대 기술의 격차를 해소하고, 더 접근 가능한, 효율적이며 공평한 법률 시스템을 마련하고자 합니다.

- **Technical Details**: 이 제안된 접근법은 LLMs(대형 언어 모델)의 수학적 추론을 활용하여 정밀한 법률 인공지능 응용 프로그램의 요구사항을 충족시키는 것입니다. 연구자는 정밀 지향 LegalAI 작업을 평가할 수 있는 벤치마크로서 맞춤형 데이터셋을 도입하였으며, 이 데이터셋을 통해 LLM 기반 접근법의 유효성을 검증하기 위해 광범위한 실험을 수행하였습니다. 또한, 특수한 프롬프트를 사용하여 법적 정보를 정확하게 생성하고 분석하는 방법을 사용합니다.

- **Performance Highlights**: 광범위한 실험 결과, 제안된 방법이 법률 영역에서 정확한 숫자 추정치를 생성하는 데 효과적임을 확인할 수 있었습니다. 이는 LLMs가 법률 절차를 효율화하고 LegalAI의 발전하는 요구를 충족시키는 데 중요한 역할을 할 수 있음을 시사합니다.



### LitSearch: A Retrieval Benchmark for Scientific Literature Search (https://arxiv.org/abs/2407.18940)
Comments:
          Dataset and code available at this https URL

- **What's New**: 문헌 검색 질문, 예를 들어 '생성된 요약의 일관성 평가에 대한 연구를 어디에서 찾을 수 있을까?'와 같은 질문은 현대 검색 엔진과 정보 검색 시스템에 상당한 도전을 안겨줍니다. 이러한 질문들은 연구 개념에 대한 깊은 이해와 전체 기사를 논리적으로 해석하는 능력을 요구합니다. 이번 작업에서는 LitSearch라는 검색 벤치마크를 도입합니다. 여기에는 최근 머신러닝(ML) 및 자연어처리(NLP) 논문에 대한 597개의 현실적인 문헌 검색 쿼리가 포함되어 있습니다.

- **Technical Details**: LitSearch는 두 가지 요소로 구성되었습니다. (1) 연구 논문의 인라인 인용(citations)이 포함된 단락을 기반으로 GPT-4에 의해 생성된 질문들과 (2) 최근에 발표된 논문에 대한 저자가 직접 작성한 질문들이 포함됩니다. 모든 LitSearch 질문들은 전문가들에 의해 수동으로 검토되거나 편집되었습니다. 또한, 최첨단 검색 모델들을 광범위하게 벤치마크하고, 두 가지 LLM(대형 언어 모델) 기반 재랭킹(reranking) 파이프라인도 평가했습니다.

- **Performance Highlights**: BM25와 최첨단 밀집 검색기(dense retriever) 간의 성능 차이는 절대 recall@5에서 24.8%로 나타났습니다. LLM 기반 재랭킹 전략은 최고 성능의 밀집 검색기를 추가로 4.4% 향상시켰습니다. 또한, Google Search와 같은 상용 검색 엔진과 연구 도구는 LitSearch에서 최적의 밀집 검색기보다 32포인트 뒤처지는 것으로 확인되었습니다. 종합적으로, 이러한 결과는 LitSearch가 retrieval 시스템을 위한 정보 제공 측면에서 실질적으로 유용한 새로운 테스트베드임을 보여줍니다.



### Dynamic Encoder Size Based on Data-Driven Layer-wise Pruning for Speech Recognition (https://arxiv.org/abs/2407.18930)
Comments:
          Accepted by Interspeech 2024

- **What's New**: 이번 연구는 다양한 하드웨어 및 애플리케이션 제약 조건(메모리 및 지연 시간 등)에 따라 다양한 크기의 모델이 필요한 ASR 시스템을 위해 동적 인코더 크기(dynamic encoder size) 접근 방식을 제안합니다. 이는 여러 개의 성능 좋은 모델을 하나의 Supernet에서 처음부터 공동 훈련하는 방식입니다. 이 Supernet에서 계층별로 pruning된 다양한 크기의 subnets을 포함하여 매개변수를 공유합니다.

- **Technical Details**: 제안된 접근 방식은 score-based pruning과 Supernet 훈련을 결합한 Simple-Top-k와 Iterative-Zero-Out라는 두 가지 새로운 방법을 사용하여 데이터 기반으로 최상의 성능을 발휘하는 subnets을 자동으로 선택합니다. 이 과정에서 리소스 집약적인 탐색 작업을 피할 수 있습니다. 이 연구는 CTC를 사용하여 Librispeech와 TED-LIUM-v2 코퍼스에서 실험을 진행했습니다.

- **Performance Highlights**: 우리의 방법은 각 크기 범주의 개별적으로 훈련된 모델과 동등한 성능을 달성할 수 있습니다. 더불어, 전체 크기의 Supernet에서도 소폭의 성능 향상을 일관되게 가져왔습니다.



New uploads on arXiv(cs.IR)

### Toward Automatic Relevance Judgment using Vision--Language Models for Image--Text Retrieval Evaluation (https://arxiv.org/abs/2408.01363)
Comments:
          Accepted by ACM SIGIR 2024 LLM4Eval Workshop: this https URL

- **What's New**: 이번 연구는 Vision-Language Models(VLMs)의 성능을 통해 이미지-텍스트 리트리벌 상황에서의 적합성 추정을 평가합니다. 이 연구는 CLIP, LLaVA, GPT-4V 모델을 대상으로 진행되었으며, 이들 모델의 성능이 인간의 적합성 판단과 얼마나 일치하는지를 살펴봅니다.

- **Technical Details**: 연구는 대규모 멀티미디어 콘텐츠 제작을 위한 제로샷(Zero-shot) 리트리벌 태스크에서 VLM들의 적합성 추정 능력을 평가했습니다. 클립스코어(CLIPScore)를 기준으로, LLaVA와 GPT-4V 모델은 인간의 적합성 판단에 대한 켄달의 타우(Kendall's tau) 약 0.4를 기록하며 좋은 성능을 보였습니다. 또한, GPT-4V 모델은 적합성 판단 분포에서도 인간과 유사한 경향을 보이며, 코헨의 카파(Cohen's kappa) 값이 0.08로, CLIPScore의 -0.096보다 현저하게 높은 값을 보였습니다.

- **Performance Highlights**: LLaVA와 GPT-4V 모두 인간의 적합성 판단과 상당히 일치하는 성능을 보였으며, 특히 GPT-4V 모델은 인간과 유사한 판단 분포를 보여줍니다. CLIP 기반 리트리벌 시스템에 대한 편향성을 줄여주며, 모델 기반 적합성 판단이 상당히 효과적임을 발견했습니다.



### Leveraging Knowledge Graph Embedding for Effective Conversational Recommendation (https://arxiv.org/abs/2408.01342)
Comments:
          26pages, 15figures

- **What's New**: 최근 증가하는 관심을 받고 있는 대화형 추천 시스템(CRS)은 대화 시스템 및 추천 시스템 기술을 통합하여 사용자의 선호를 더 잘 학습하고 추천 성능을 향상시킵니다. 본 논문에서는 기존의 CRS 연구들이 속성, 사용자 및 항목 간의 관계를 효과적으로 다루지 못하는 문제를 지적하고, 이를 개선하기 위해 지식 그래프 기반 대화형 추천 시스템(KG-CRS)을 제안합니다.

- **Technical Details**: KG-CRS에서는 사용자-아이템 그래프(user-item graph)와 아이템-속성 그래프(item-attribute graph)를 동적 그래프로 통합하며, 대화 과정에서 부정적 항목이나 속성을 제거하여 동적으로 변화합니다. 이러한 그래프에서 이웃을 통한 전파를 고려하여 사용자, 아이템 및 속성의 유용한 임베딩(embedding)을 학습합니다.

- **Performance Highlights**: 세 가지 실제 데이터 세트에서 광범위한 실험을 통해 추천 및 대화 작업 모두에서 최신 기법(state-of-the-art approaches)을 능가하는 것이 검증되었습니다.



### Multi-Aspect Reviewed-Item Retrieval via LLM Query Decomposition and Aspect Fusion (https://arxiv.org/abs/2408.00878)
- **What's New**: 사용자 생성 제품 리뷰를 활용한 자연어 기반 제품 질의 응답 시스템에서 다면 조회(Multi-Aspect Retrieval)를 소개합니다. 기존의 후기 아이템 검색(Reviewed-Item Retrieval; RIR)에 Late Fusion(LF) 접근 방식을 대체하는 새로운 Aspect Fusion(AF) 전략을 제안합니다. 이를 통해 다면 질의와 아이템 리뷰의 불균형 문제를 해결하고, 더 나은 성능을 제공합니다.

- **Technical Details**: 기존 LF 방식은 상위 K개의 질의-리뷰 유사도 점수를 평균내어 질의-아이템 유사도를 계산하지만, 이는 리뷰 내 다중 측면(Aspect) 분포의 불균형에 민감합니다. 이를 해결하기 위해 Large Language Model(LLM) 기반의 질의 추출 및 생성 재정렬(Generative Reranking)과 같은 여러 새로운 AF 전략을 도입했습니다. 또한, Recipe-MPR 데이터셋을 활용하여 다양한 불균형 조건에서 성능을 수치적으로 평가했습니다.

- **Performance Highlights**: 불균형 리뷰 코퍼스에서 AF는 LF 대비 MAP@10 점수를 0.36에서 0.52로 향상시켰습니다. 균형 잡힌 데이터셋에서도 유사한 성능을 유지했으며, LLM 기반 재정렬 기법을 적용한 결과 리뷰의 양에 따라 성능이 더욱 개선될 수 있음을 확인했습니다.



### Leveraging LLM Reasoning Enhances Personalized Recommender Systems (https://arxiv.org/abs/2408.00802)
Comments:
          To be published at ACL 2024

- **What's New**: 본 연구는 최근 대규모 언어 모델(Large Language Models, LLMs)이 추천 시스템(RecSys)에서 기능을 향상시키는 방안을 탐구하였다. 특히, Chain-of-Thought(COT) prompting을 통한 LLM의 추론 기능을 추천 시스템에 적용하여 사용자 맞춤 추천의 성능을 개선하고자 하였다. 또한 RecSAVER(RecSys Automatic Verification and Evaluation of Reasoning)이라는 평가 프레임워크를 도입하여, 인간의 평가 없이도 자동으로 추론 응답의 품질을 평가할 수 있는 방법을 제안하였다.

- **Technical Details**: 연구에서 제안된 RecSAVER 프레임워크는 코히전(coherence)와 신뢰성(faithfulness)에 대한 인간의 판단과 일치하는 결과를 제공한다. 또한, zero-shot 및 fine-tuning 시나리오 둘 다에서 LLM의 추론 기능을 사용하여 추천 시스템의 과제 성능이 향상되는 것을 확인하였다. 이는 사용자 평가 예측 과제에서 높은 사용자 결단력과 피드백을 요구하는 과제를 중심으로 실험을 진행하였다. 또한, BLEU와 ROUGE와 같은 문법적 지표가 LLM 출력을 평가하는 데 적합하고, METEOR와 BERTScore는 생성된 출력의 코히전을 측정하는 데 더 적합한 것으로 나타났다.

- **Performance Highlights**: 큰 모델을 사용하여 추론 데이터를 생성하는 것이 더 작은 모델을 fine-tuning 하여 성능과 추론 능력을 향상시키는 데 효과적이라는 점을 보여주었다. 또한 RecSAVER 프레임워크를 통해 인간 평가와 일치하면서도 비용과 효율성을 개선하여 LLM의 추론 기능을 이해하는 데 기여하는 유의미한 통찰을 제공하였다.



### Low Rank Field-Weighted Factorization Machines for Low Latency Item Recommendation (https://arxiv.org/abs/2408.00801)
- **What's New**: 기존의 field-weighted factorization machine (FwFM) 모델의 한계를 해결하기 위해, 논문은 대각행렬 및 대칭 저차원 분해(directional plus symmetric low-rank decomposition)를 이용하여 계산 비용을 감소시키는 새로운 방법을 제안합니다. 이 방법은 기존의 단순한 프루닝(pruning) 전략보다 정확성과 추천 속도에서 더 우수한 성능을 보여줍니다.

- **Technical Details**: FwFM 모델은 쌍(feature interactions) 간의 필드별 상호작용을 학습하여 더 높은 정확도를 제공하지만, 계산 비용은 필드 수의 제곱에 비례하여 증가하게 됩니다. 이를 해결하기 위해, 저자들은 쌍대칭 저차원 분해(directional plus symmetric low-rank decomposition)를 통해 다이어그램을 단순화하여 계산 비용을 줄였습니다. 이 새로운 접근법은 아이템 필드 수에만 비례하는 계산 비용을 가지도록 설계되었습니다.

- **Performance Highlights**: 실제 데이터셋과 대형 온라인 광고 시스템의 데이터에 대한 실험 결과, 저자들이 제안한 DPLR-FwFM 모델은 기존의 공격적인 프루닝(FwFM모델들보다 더 높은 정확도와 낮은 지연(latency)을 보여주었습니다. 특히, 실험 결과들은 DPLR-FwFM이 생산 시스템에 적용되었을 때 더 낮은 지연 시간을 기록하며, 동일한 계산 예산 내에서도 더 나은 성능을 발휘할 수 있음을 증명했습니다.



### Chatbot-Based Ontology Interaction Using Large Language Models and Domain-Specific Standards (https://arxiv.org/abs/2408.00800)
- **What's New**: 이번에는 대형 언어 모델(LLMs)과 챗봇 인터페이스를 활용하여 SPARQL 쿼리 생성 과정을 개선하는 개념을 소개합니다. 사용자는 자연어 입력을 통해 온톨로지의 형식화된 지식에 직관적으로 접근할 수 있습니다. 이번 기법은 사용자 문의를 정확한 SPARQL 쿼리로 변환하여, 대형 언어 모델에 의해 잘못된 정보나 자료 조작이 발생하는 것을 방지합니다.

- **Technical Details**: 이 시스템은 사용자가 자연어(NL)로 질문을 제출하면, 이를 챗봇을 통해 LLM에 전송하여 SPARQL 쿼리로 변환합니다. 그런 다음 쿼리는 백엔드에서 실행되고 그 결과가 사용자에게 표시됩니다. 추가적으로, 온톨로지에 도메인별 표준에서 가져온 추가 텍스트 정보를 통합하여 개념과 관계의 정확한 설명을 제공합니다.

- **Performance Highlights**: 실험 연구 결과, LLMs를 사용한 SPARQL 쿼리 생성이 정확도 면에서 상당한 이점을 보였습니다. 이는 사용자가 더 쉽게 온톨로지를 쿼리하고, 높은 신뢰도를 유지하면서도 명확한 결과를 얻을 수 있도록 했습니다.



### Deep Uncertainty-based explore For Index Construction and Retrieval in Recommendation System (https://arxiv.org/abs/2408.00799)
- **What's New**: 이 논문은 최신 추천 시스템의 매칭 단계에서 불확실성 기반의 인덱스 구축 및 검색 알고리즘(UICR)을 제안합니다. 이 알고리즘은 모델의 불확실성을 활용하여 추천 결과의 관련성과 새로움을 동시에 향상시키려고 합니다.

- **Technical Details**: 논문에서는 기존의 포인트 추정(point estimation) 방식이 아닌 분포 추정(distribution estimate) 방식을 사용하여 사용자와 항목의 불확실성을 모델링합니다. 이는 UN-Index, UN-Retrieval, UN-Model 세 가지 주요 구성 요소로 이루어져 있습니다. UN-Index는 높은 신뢰도의 인덱스를 구축하고, UN-Retrieval는 이 인덱스를 기반으로 검색 중 관련성과 신뢰도를 결합하며, UN-Model은 두 가지 모두의 관련성과 불확실성 점수를 예측하는 모델링 기능을 제공합니다.

- **Performance Highlights**: 실험 결과, UICR은 실전 산업 환경과 여러 오픈소스 데이터셋에서 관련성을 희생하지 않으면서도 새로움을 향상시키는 것으로 나타났습니다. 특히, Shopee의 디스플레이 광고에 대한 온라인 A/B 테스트 결과에서도 제안된 알고리즘의 효과를 증명했습니다.



### Golden-Retriever: High-Fidelity Agentic Retrieval Augmented Generation for Industrial Knowledge Bas (https://arxiv.org/abs/2408.00798)
- **What's New**: 이 논문은 Golden-Retriever라는 새로운 접근 방식을 소개합니다. 이는 대규모 산업 지식 베이스를 효율적으로 탐색하도록 설계되었으며, 기존의 대형 언어 모델(LLM) 미세 조정 및 Retrieval-Augmented Generation(RAG) 프레임워크가 도메인 특화 용어와 문맥 해석에서 겪는 어려움을 극복합니다. Golden-Retriever는 문서 검색 전에 반영 기반 질문 확장 단계를 포함하며, 이는 전문 용어를 식별하고 문맥에 기반한 의미 명확화를 통해 질문을 확장합니다.

- **Technical Details**: Golden-Retriever는 오프라인 및 온라인 프로세스로 구성됩니다. 오프라인 프로세스는 Optical Character Recognition(OCR)을 사용해 다양한 문서 포맷에서 텍스트를 추출하고, 이를 요약 및 문맥화하여 문서 데이터베이스를 강화합니다. 온라인 프로세스는 사용자 질문 내의 전문 용어와 문맥을 식별한 후, 용어 사전과 대조해 정확한 정의와 설명을 찾습니다. 이렇게 확장된 질문은 RAG 프레임워크에 입력되어 가장 관련성 높은 문서를 검색합니다.

- **Performance Highlights**: 도메인 특화 질문-답변 데이터셋을 사용하여 세 가지 오픈 소스 LLM에서 Golden-Retriever의 성능을 평가한 결과, 우리의 방법이 검색 정확도를 크게 향상시키며 뛰어난 성능을 보였습니다. 기존의 Corrective RAG와 Self-RAG와 달리, Golden-Retriever는 질문의 모호성을 해결하여 검색 단계의 정확성을 높입니다.



### PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieva (https://arxiv.org/abs/2408.01349)
Comments:
          Accepted by ACM MM 2024

- **What's New**: 연구자들은 PC$^2$ (Pseudo-Classification based Pseudo-Captioning)라는 새로운 프레임워크를 제안했습니다. 이 모델은 이미지-텍스트 간의 의미적 유사성을 비대조적(non-contrastive) 메커니즘을 통해 학습하고, 잘못된 대응쌍을 더 많은 정보를 제공하는 가짜 캡션(pseudo-captions)을 생성하여 교정합니다. 또한, 새로운 노이즈 데이터셋인 'Noise of Web (NoW)'도 개발되었습니다.

- **Technical Details**: PC$^2$ 프레임워크는 세 가지 주요 전략으로 구성됩니다. 첫째, 캡션을 범주형 레이블로 해석하여 비대조적 학습을 통한 '가짜 분류(pseudo-classification)' 보조 작업을 수행합니다. 둘째, 가짜 캡션을 생성하여 잘못된 대응쌍에도 유익한 감독 정보(supervision)를 제공합니다. 셋째, 가짜 분류기의 예측 변동성을 이용하여 대응쌍의 교정을 돕습니다. 이를 위해 크로스 엔트로피 손실(cross-entropy loss)과 반대쪽(simplicity) 최적화 목표를 사용합니다.

- **Performance Highlights**: PC$^2$ 프레임워크는 기존의 최첨단 크로스 모달 검색 방법과 비교하여 시뮬레이션된 데이터셋과 현실적인 데이터셋 모두에서 놀라운 성능 향상을 보였습니다. 특히, 다양한 NCL (Noisy Correspondence Learning) 환경에서 더 나은 성능을 발휘했습니다. 또한, 새로운 데이터셋인 NoW를 도입하여 이후의 NCL 평가를 위한 강력한 기준을 제공했습니다.



### RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework (https://arxiv.org/abs/2408.01262)
- **What's New**: 이 논문은 RAGEval이라는 새로운 프레임워크를 소개합니다. RAGEval은 다양한 도메인에서 Large Language Models(LLMs)가 실제로 지식을 어떻게 사용하는지 평가할 수 있는 자동화된 평가 데이터셋을 생성합니다. 이는 기존의 Retrieval-Augmented Generation (RAG) 벤치마크가 일반 지식에 대한 질문에만 초점을 맞추고 있어 특정 도메인 데이터에 대한 평가가 어려운 문제를 해결합니다.

- **Technical Details**: RAGEval은 시드 문서로부터 스키마를 요약하고, 이를 적용하여 다양한 문서를 생성합니다. 그런 다음, 생성된 문서와 구성별로 질문-답변 쌍을 구성합니다. 평가 메트릭으로는 'Completeness(완전성)', 'Hallucination(환각)', 'Irrelevance(무관성)'의 세 가지를 제안하여 LLM이 생성한 응답을 면밀히 평가합니다.

- **Performance Highlights**: RAGEval은 수직 도메인(vertical domains)에서 RAG 모델을 벤치마킹하여, LLM이 지식을 어떻게 활용하는지 보다 정확히 평가할 수 있는 능력을 보입니다. 이는 기존 QA 데이터셋에서 답변의 지식 출처가 매개변수화된 메모리에서 기인한 것인지 또는 검색에서 유래한 것인지 혼란을 방지할 수 있습니다.



### Nested Music Transformer: Sequentially Decoding Compound Tokens in Symbolic Music and Audio Generation (https://arxiv.org/abs/2408.01180)
Comments:
          Accepted at 25th International Society for Music Information Retrieval Conference (ISMIR 2024)

- **What's New**: Nested Music Transformer(NMT)는 복합 토큰(compound tokens)을 순차적으로 해독하기 위한 새로운 아키텍처입니다. 이는 효율적인 메모리 사용과 함께 각 복합 토큰의 서브 토큰(sub-tokens) 간의 상호 의존성을 효과적으로 모델링할 수 있도록 설계되었습니다.

- **Technical Details**: NMT는 두 개의 트랜스포머(transformers)로 구성됩니다: 복합 토큰 시퀀스를 모델링하는 메인 디코더(main decoder)와 각각의 복합 토큰의 서브 토큰을 모델링하는 서브 디코더(sub-decoder)입니다. 또한, 서브 디코더 내에서 intra-token 디코더와 Embedding Enricher라는 두 가지 크로스 어텐션(cross-attention) 아키텍처를 통합하여 서브 토큰의 임베딩을 업데이트합니다.

- **Performance Highlights**: 실험 결과에 따르면, NMT를 복합 토큰에 적용하면 다양한 상징적 음악 데이터셋 및 MAESTRO 데이터셋의 이산 오디오 토큰의 처리에서 퍼플렉서티(perplexity)가 개선되는 등 성능이 향상되었습니다. 이는 GPU 메모리 사용량과 학습 시간을 줄이면서도 기존의 평평한(flattened) 토큰 기반 모델과 유사한 성능을 보여줍니다.



### BioRAG: A RAG-LLM Framework for Biological Question Reasoning (https://arxiv.org/abs/2408.01107)
Comments:
          12 pages, 7 figures

- **What's New**: BioRAG는 생명과학 질문-응답 시스템에 새로운 접근 방식을 제안합니다. 이는 대규모 언어 모델(LLMs)과 결합된 Retrieval-Augmented Generation(RAG) 프레임워크입니다. 2200만 개의 과학 논문을 기본 지식으로 사용하여 생명과학에 특화된 임베딩 모델을 훈련하고, 도메인별 지식 계층을 활용해 복잡한 쿼리와 문맥을 모델링합니다. BioRAG는 최신 정보를 반복적으로 검색 엔진을 통해 추론하면서 질문을 해체하고 정보를 검색합니다.

- **Technical Details**: BioRAG는 먼저 방대한 연구 논문을 파싱하고, 인덱싱하며, 세분화하여 고품질 학습 데이터를 구축합니다. 그런 다음, PubMedBERT를 기반으로 CLIP 기법을 적용해 생명과학에 특화된 임베딩 모델을 개발하여 생물학적 질문에 맞는 정보를 효율적으로 검색합니다. 또한, 최신 지식을 반영하기 위해 검색 엔진 및 도메인별 도구에서 지식 소스를 적응적으로 선택합니다. 이렇게 수집된 정보를 토대로 대규모 언어 모델이 응답을 생성합니다.

- **Performance Highlights**: BioRAG는 6개의 생물학 질문-응답 데이터셋에서 기존 방법들을 능가하는 성능을 보였습니다. 이는 세심하게 설계된 데이터 준비 및 커스터마이징된 임베딩 모델, 그리고 도메인별 지식 계층을 활용한 CPS와 같은 투명한 프로세스를 통해 복잡한 생물학적 질문을 효과적으로 처리할 수 있음을 시사합니다.



### An Encoding--Searching Separation Perspective on Bi-Encoder Neural Search (https://arxiv.org/abs/2408.01094)
- **What's New**: 이 논문에서는 신경 검색(neural search)을 위한 바이엔코더(bi-encoder) 아키텍처에 대한 새로운 관점을 제안합니다. 바이엔코더 아키텍처는 테스트 시간에 단순성과 확장성 덕분에 널리 사용되지만, 기존 데이터셋에서 낮은 성능과 새로운 데이터셋에서 약한 제로샷(zero-shot) 성능 등 몇 가지 문제를 가지고 있습니다. 저자는 이러한 문제를 분석하고, 인코딩 정보 병목 현상(encoding information bottleneck)과 임베딩 검색(embedding search)에 대한 기본 가정의 한계를 두 가지 주요 비판으로 요약합니다. 새로운 관점인 인코딩-검색 분리(encoding-searching separation) 관점을 제안하며, 이는 인코딩과 검색 작업을 개념적 및 실질적으로 분리합니다.

- **Technical Details**: 바이엔코더 아키텍처는 검색 쿼리와 항목을 각각 임베딩 벡터로 인코딩하고, 그러고 나서 이들의 유사도 점수를 계산하여 그 유사성(similarity score)을 측정합니다. 그러나 이 접근 방식은 인코딩 정보 병목 현상과 임베딩 검색의 기본 가정에서 오는 한계를 가집니다. 저자는 사고 실험을 통해 인코딩 및 검색 작업을 논리적으로 분석하고, 임베딩 검색의 기본 가정을 도전합니다. 새로운 인코딩-검색 분리 관점은 인코딩과 검색 작업을 구분하여 정보의 병목 현상을 제어하고, 인코딩 및 검색 작업을 설계하는 데 있어 더 큰 자유를 제공하며, 훈련 효율성을 개선합니다.

- **Performance Highlights**: 이 논문에서 제안된 새 관점은 바이엔코더 아키텍처에서 발견된 여러 문제의 근본 원인을 이해하고 완화하는 데 도움을 줄 수 있습니다. 이는 정보 병목 현상을 더 잘 제어하고, 설계 자유도를 높이며, 훈련 효율성을 개선합니다. 기존의 바이엔코더 아키텍처에 비해 수학적으로 동일하지만, 근본적인 아이디어에서 큰 변화를 나타냅니다. 이로 인해 바이엔코더 아키텍처를 자연스럽게 수정하고 문제를 완화하는 데 도움이 됩니다.



### PERSOMA: PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting (https://arxiv.org/abs/2408.00960)
- **What's New**: PERSOMA라는 새로운 Personalized Soft Prompt Adapter 아키텍처를 소개합니다. 이 시스템은 사용자 상호작용 기록을 표현력 있는 소프트 프롬프트 임베딩(soft prompt embeddings)으로 압축하여 캡쳐합니다.

- **Technical Details**: PERSOMA는 사용자의 과거 상호작용을 텍스트 프롬프트가 아닌 소프트 프롬프트(soft prompt)로 변환하여 대형 언어 모델(LLMs)의 성능을 개선합니다. 이 과정에서 Parameter-efficient tuning 기법인 LoRA와 History Resampling Techniques를 사용해 효율성을 높였습니다. 소프트 프롬프트 어댑터(soft prompt adapter)는 사용자 히스토리를 압축하고, 이를 LLM의 어휘 공간으로 맵핑합니다.

- **Performance Highlights**: PERSOMA는 MovieLens 사용자 선호 데이터셋에서 기존의 임베딩 기반 기술과 텍스트 프롬프트 기반 기술을 능가합니다. PERSOMA는 F1 스코어에서 0.18 높게 기록하며, 적은 계산 자원의 사용으로도 동일한 결과를 보여줍니다.



### LICM: Effective and Efficient Long Interest Chain Modeling for News Recommendation (https://arxiv.org/abs/2408.00859)
- **What's New**: 뉴스 추천 시스템에서 사용자의 맞춤형 뉴스를 정확하게 추천하는 것은 항상 핵심적인 도전 과제였습니다. 최근의 노력은 주로 지역 하위 그래프 정보를 추출하는 데 집중했지만, 전반적인 글로벌 뉴스 그래프 추출의 부족은 비슷한 사용자 간에 글로벌 뉴스 정보를 협업적으로 활용하는 능력을 저해했습니다. 이러한 한계를 극복하기 위해, 우리는 유사한 사용자의 협업을 기반으로 글로벌 뉴스 클릭 그래프에서 추출한 장기 체인 관심(Long Interest Chain)을 이웃의 관심과 결합하여 뉴스 추천을 향상시키는 효과적이고 효율적인 방법인 Long Interest Chain Modeling for News Recommendation(LICM)을 제안합니다.

- **Technical Details**: LICM은 모든 사용자의 클릭 이력을 기반으로 한 글로벌 뉴스 그래프에서 장기 체인 관심을 생성하여 고차원 정보를 더 잘 활용할 수 있도록 설계되었습니다. 이를 위해, 우리는 종합적인 선택 메커니즘과 관심 인코더(interest encoder)를 설계하여 글로벌 그래프에서 장기 체인 관심을 얻습니다. 마지막으로, 게이트 네트워크(gated network)를 사용하여 장기 체인 정보를 이웃 정보와 통합하여 최종 사용자 표현을 달성합니다.

- **Performance Highlights**: 실세계 데이터 세트에 대한 실험 결과, 우리의 모델이 뉴스 추천의 성능을 향상시키는 데 있어 효과적이고 효율적임을 확인했습니다.



### Adversarial Text Rewriting for Text-aware Recommender Systems (https://arxiv.org/abs/2408.00312)
Comments:
          Accepted for publication at: 33rd ACM International Conference on Information and Knowledge Management (CIKM 2024). Code and data at: this https URL

- **What's New**: 이 논문은 텍스트-인식 추천 시스템(text-aware recommender systems)의 새로운 취약점을 제시합니다. 텍스트 설명을 재작성하여 추천 시스템을 공격(Adversarial Text Rewriting)할 수 있다는 가능성을 탐구하면서, 악성 판매자가 텍스트 설명을 조작해 부당하게 상품을 상위에 랭크시킬 수 있음을 보여줍니다.

- **Technical Details**: 두 가지 텍스트 재작성 공격 방법을 제안합니다: (1) 높은 공격 성능을 위한 두 단계 미세 조정(two-phase fine-tuning), (2) 높은 텍스트 재작성 품질을 위한 문맥 학습(in-context learning, ICL). 두 방법을 통해, ATR(Adversarial Text Rewriting) 알고리즘이 텍스트 설명을 재작성할 때 실제와 같은 느낌을 유지하면서도 대상 상품의 랭크를 최적화합니다.

- **Performance Highlights**: 3개의 서로 다른 데이터셋과 4개의 기존 접근 방식을 사용한 실험에서, 제안된 텍스트 재작성 공격이 추천 시스템에 취약성을 드러냄을 보였습니다. 특히 ATR로 생성된 텍스트 설명이 본래의 랭크에 비해 상당히 높여졌고, 7개의 경쟁적인 기준선을 뛰어넘었습니다.



### Simple but Efficient: A Multi-Scenario Nearline Retrieval Framework for Recommendation on Taobao (https://arxiv.org/abs/2408.00247)
- **What's New**: 최근 추천 시스템의 매칭 단계에서 여러 시나리오(다양한 상황에서의 사용자 활동) 정보를 활용하는 방식이 연구되고 있습니다. 이 논문에서는 Taobao의 'Guess You Like' 페이지에서 다중 시나리오 근접선 Retrieval Framework를 도입하여 매칭 단계를 개선하는 방법을 제안합니다.

- **Technical Details**: 이 프레임워크는 Flink를 통해 다양한 시나리오의 랭킹 로그를 활용하여 다른 시나리오의 세밀히 랭킹된 결과를 매칭 단계에 실시간으로 반영합니다. 또한 스트리밍 스코어링 모듈을 도입하여 후보 풀에서 중요한 하위 집합을 선택합니다. 이는 모델 프리(model-free) 방식으로 구현되어 높은 효율성을 자랑합니다.

- **Performance Highlights**: 이 방법은 중국의 주요 전자상거래 플랫폼인 Taobao에서 구현되었으며, 제품 거래 건수가 5% 증가하는 등 큰 성과를 보였습니다. 이런 성과는 다양한 시나리오에서 신속하게 구현될 수 있다는 점에서 유망한 결과로 평가받고 있습니다.



### Review of Explainable Graph-Based Recommender Systems (https://arxiv.org/abs/2408.00166)
- **What's New**: 이 논문은 최신 기법에 기반한 설명 가능한 추천 시스템(explainable recommender systems)의 동향을 요약하며, 특별히 그래프 기반 추천 시스템에 중점을 두고 있습니다. 기존의 리뷰 논문과 달리, 이 논문은 그래프를 활용한 추천 시스템의 설명 가능성에 대해 집중적으로 다루고 있습니다.

- **Technical Details**: 논문은 설명 가능한 추천 시스템을 세 가지 측면에서 분류합니다: 학습 방법(learning methods), 설명 방법(explaining methods), 및 설명 유형(explanation types). 또한 주로 사용되는 데이터셋과 설명 가능성 평가 방법(explainability evaluation methods)을 탐구하며, 향후 연구 방향(future directions)을 제시합니다.

- **Performance Highlights**: 논문은 그래프 기반의 설명 가능한 추천 시스템과 관련된 최신 연구 결과를 비교하고 분석함으로써, 새로운 애플리케이션 개발을 위한 기초 자료를 제공합니다.



### Semantic Codebook Learning for Dynamic Recommendation Models (https://arxiv.org/abs/2408.00123)
- **What's New**: Semantic Codebook Learning for Dynamic Recommendation Models (SOLID) 프레임워크가 기존 동적 순차 추천(Dynamic Sequential Recommendation, DSR) 방식의 한계를 효과적으로 극복하며, 사용자 행동을 기반으로 개인화된 추천을 개선하는 중요한 진전을 이루었습니다.

- **Technical Details**: SOLID는 아이템 시퀀스를 의미 시퀀스로 변환하고, 이중 매개변수 모델(dual parameter model)을 사용하여 매개변수 생성 탐색 공간을 압축하며, 추천 시스템 내의 동질성을 활용합니다. 의미 메타코드(semantic metacode)와 의미 코드북(semantic codebook)을 도입하여, 분리된 아이템 표현을 저장하고 견고하고 정확한 매개변수 생성을 보장합니다.

- **Performance Highlights**: 광범위한 실험 결과 SOLID가 기존 DSR 방법을 일관되게 능가하여 더 정확하고 안정적이며 견고한 추천을 제공합니다.



### MIMNet: Multi-Interest Meta Network with Multi-Granularity Target-Guided Attention for Cross-domain Recommendation (https://arxiv.org/abs/2408.00038)
- **What's New**: 본 논문에서는 교차 도메인 추천(CDR)을 위한 새로운 방법인 MIMNet(Multi-interest Meta Network with Multi-granularity Target-guided Attention)을 제안합니다. 이 방법은 사용자 고유의 관심사를 고려하고, 다양한 관심 수준의 다리를 생성하여 출발 도메인에서 목표 도메인으로 사용자 표현을 전송합니다.

- **Technical Details**: 제안된 방법에서는 캡슐 네트워크(capsule network)를 사용하여 출발 도메인에서 사용자의 다중 관심사를 학습합니다. 이러한 관심사는 메타 네트워크(meta network)로 입력되어 다중 관심 수준의 다리가 생성됩니다. 이 후, 다중 관심 다리를 기반으로 출발 도메인에서 목표 도메인으로 사용자 표현을 전송합니다. 또한, 세밀한 신호(fine-grained signals)와 대략적인 신호(coarse-grained signals)를 도입하여 다중-세분화(multi-granularity) 목표 주도 주의(attention) 네트워크를 통해 사용자 변환 관심 수준 표현을 집계합니다.

- **Performance Highlights**: 세 개의 실제 CDR 작업에서 광범위한 실험을 수행한 결과, 제안된 MIMNet 방법이 모든 기준 방법(baseline methods)을 꾸준히 능가하는 성능을 보였습니다.



### Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation (https://arxiv.org/abs/2408.00490)
Comments:
          14 pages

- **What's New**: 새로운 연구에서는 그래프 신경망(GNNs)을 기반으로 한 추천 시스템이 독립적이고 동일분포(IID) 데이터에 기반한 가정이 많은 경우 에외 배치 데이터(out-of-distribution, OOD)에서 성능 저하가 발생하는 문제를 다루고 있습니다. 이를 해결하기 위해, 인과 확산(Causal Diffusion)을 통한 그래프 표현 학습(CausalDiffRec)이라는 새로운 방법이 제안되었습니다. 이 방법은 환경혼란요소를 제거하고 불변 그래프 표현을 학습하여 OOD 데이터에서 모델의 일반화를 향상시킵니다.

- **Technical Details**: CausalDiffRec 방법은 세 가지 주요 구성 요소로 이루어져 있습니다: 환경 생성기(environment generator), 환경 추론(environment inference), 확산 모듈(diffusion module). 환경 생성기는 여러 환경에서 데이터 분포를 시뮬레이션하기 위해 다양한 그래프를 생성하고, 환경 추론 모듈은 이러한 생성된 그래프로부터 환경 요소를 추론하여 불변 그래프 표현 학습을 지도합니다. 확산 모듈은 가역 확산 과정에서 불변 표현을 학습하는 역할을 수행합니다. 또한 이 연구는 인과 확산 기법을 통해 서로 다른 환경에서 불변 그래프 표현을 학습함으로써 OOD 데이터에서의 일반화 성능을 높일 수 있음을 이론적으로 증명합니다.

- **Performance Highlights**: 광범위한 실험을 통해 CausalDiffRec의 OOD 데이터 일반화 성능 향상을 검증하였으며, Food, KuaiRec, Yelp2018, Douban 데이터셋에서 각각 평균 10.69%, 18.83%, 22.41%, 11.65%의 성능 향상을 기록했습니다.



### Towards Explainable and Interpretable Musical Difficulty Estimation: A Parameter-efficient Approach (https://arxiv.org/abs/2408.00473)
- **What's New**: 이 논문은 상징적 음악 표현(symbolic music representations)에서 음악의 난이도를 추정하는 데 사용될 수 있는 설명 가능한 설명자(explainable descriptors)를 도입하고 있습니다. 이를 통해 음악 교육에서 기존의 심층 학습 모델이 가지는 불투명성을 해결하고자 합니다. 이 연구는 새로운 파라미터 효율적인 화이트박스 모델(white-box model)을 통해 이전 연구들을 능가하는 해석 가능한 결과를 제공합니다.

- **Technical Details**: RubricNet이라고 불리는 이 화이트박스 모델은 음악 교육에서 널리 사용되는 평가 도구인 루브릭(rubric)의 개념을 사용하여 음악 난이도를 투명하게 해석할 수 있게 설계되었습니다. 이 모델은 각각의 입력 설명자를 처리하는 일련의 선형 층(linear layers)과 비선형 활성화 함수(nonlinear activation function)로 구성됩니다. 모델의 예측은 시그모이드 함수(sigmoid function)를 사용하여 확률로 변환되며, 이는 MSE(mean squared error) 손실을 사용하여 최적화됩니다.

- **Performance Highlights**: 이 연구는 9개의 클래스로 분류된 피아노 레퍼토리를 평가하여 41.4%의 독립적인 정확도와 1.7의 평균 제곱 오차(MSE)를 달성했습니다. 이는 기존의 연구들을 능가하며, 해석 가능한 결과를 통해 음악 교육에서 실제로 활용될 수 있습니다.



### DiscipLink: Unfolding Interdisciplinary Information Seeking Process via Human-AI Co-Exploration (https://arxiv.org/abs/2408.00447)
- **What's New**: 이번 연구에서는 다양한 학문 분야의 정보를 탐색하는 데 도움을 주는 상호작용 시스템인 DiscipLink를 소개합니다. DiscipLink는 대형 언어 모델(LLMs)과 협력하여 사용자의 관심 주제를 기반으로 탐색 질문을 생성하고, 선택한 질문에 따라 논문을 검색하고 스크리닝하는 과정을 지원합니다.

- **Technical Details**: DiscipLink는 먼저 사용자의 관심 주제에 대해 다양한 학문 분야의 관점에서 탐색 질문(Exploratory Questions, EQs)을 생성합니다. 사용자는 이러한 EQ들을 더 구체화하거나 새로운 방향으로 질문을 유도할 수 있습니다. EQ에 대한 기존 지식을 제시하는 과정에서 LLM 기반 쿼리 확장 전략을 사용하여 다양한 분야의 논문을 검색하며, 검색된 논문에서 주제를 추출하고 사용자의 탐색 포커스와의 연결점을 강조합니다. 평가 과정에서 12명의 대학원생과 7명의 경험 있는 연구자들을 대상으로 DiscipLink의 효율성과 사용성을 검증했습니다.

- **Performance Highlights**: DiscipLink는 참가자들이 과제를 더 효율적으로 수행할 수 있도록 돕고, 더 포괄적인 범위의 지식을 발견하는 데 도움을 주었습니다. 연구자들은 DiscipLink의 공동 탐색 워크플로우를 높이 평가했으며, 이 시스템이 개인 연구자의 독특한 요구를 충족하는 데에 아직 한계가 있음을 지적했습니다.



### DistillGrasp: Integrating Features Correlation with Knowledge Distillation for Depth Completion of Transparent Objects (https://arxiv.org/abs/2408.00337)
Comments:
          10 pages, 5 figures

- **What's New**: 투명한 물체의 깊이 데이터를 더 정확하게 복원하기 위해 DistillGrasp라는 네트워크를 제안합니다. 이 네트워크는 교사 분기와 학생 분기로 구성되어 있으며, 교사 분기는 RGB 이미지를 깊이 맵으로 매핑하는 위치 상관 블록(Position Correlation Block, PCB)을 사용합니다. 학생 분기는 신뢰성 있는 영역에 기반하여 일관된 특징 상관 모듈(Consistent Feature Correlation Module, CFCM)을 사용합니다. 지식 증류(Knowledge Distillation) 기법을 활용하여 학생 네트워크가 교사 네트워크의 지식을 효과적으로 학습할 수 있도록 합니다.

- **Technical Details**: 제안된 DistillGrasp 네트워크는 교사와 학생 분기로 나뉩니다. 교사 네트워크에서 RGB 이미지와 깊이 맵 간의 구조적 정보와 대응 관계를 설정하기 위해 트랜스포머 기반의 위치 상관 블록(PCB)을 사용합니다. 학생 네트워크는 일관된 영역에 기반하여 신뢰 가능한 특징을 추출하는 일관된 특징 상관 모듈(CFCM)을 사용하며, 거리 손실, 구조 손실, 에지 손실을 포함한 증류 손실(distillation loss)을 고안하여 종합적인 특징을 학습할 수 있도록 합니다.

- **Performance Highlights**: ClearGrasp 데이터셋을 기반으로 한 실험 결과, 제안된 교사 네트워크는 정확성과 일반화 측면에서 기존 최첨단 방법보다 우수한 성능을 보여줍니다. 학생 네트워크는 48 FPS의 속도로 경쟁력 있는 결과를 달성합니다. 추가로, 실제 로보틱 그리핑 시스템에 성공적으로 배포되어 제안된 시스템의 효과성과 내구성을 입증했습니다.



### Exploiting Preferences in Loss Functions for Sequential Recommendation via Weak Transitivity (https://arxiv.org/abs/2408.00326)
Comments:
          Accepted to CIKM 2024, Short Research Paper Track

- **What's New**: 이 논문에서는 추천 시스템의 최적화 목적을 확장하여 사용자의 다양한 선호도를 반영하는 새로운 방법을 제안합니다. 기존의 목표는 다음에 관찰된 항목을 유일한 긍정 항목으로 간주하고 나머지 항목을 부정 항목으로 간주하는 바이너리 레이블 할당의 한계를 가지고 있었습니다. 이를 해결하기 위해, 저자들은 항목 점수 사이의 상대적인 순서를 활용하는 새로운 목적 함수를 소개했습니다.

- **Technical Details**: 기존의 최적화 목적은 주로 pairwise, pointwise, setwise 손실 함수로 분류됩니다. 이러한 손실 함수는 긍정 항목의 점수를 높이는 데 초점을 맞추지만, 다른 미관찰 항목들 사이의 잠재적인 구조를 반영하지 못합니다. 저자들은 '약한 추이성(weak transitivity)'이라는 귀납적 관계를 유도하여 선호도를 반영한 항목 점수를 정렬하는 새로운 목적 함수를 제안합니다. 이 새로운 접근법은 BPR 및 BCE와 같은 기존의 손실 함수와는 달리, 미관찰 항목의 점수를 항목의 인기와 반비례하게 조정할 수 있습니다.

- **Performance Highlights**: 저자들은 새로운 목적 함수의 우수성을 네 가지 순차적 추천 데이터셋에서 검증하였습니다. 실험 결과, 제안된 방법은 기존의 손실 함수 및 그 변형된 버전보다 추천 성능이 크게 향상됨을 보여주었습니다. 특히, TransBPRpop 및 TransBCEpop는 항목의 인기에 비례하여 점수가 나타나고, TransBPRniche 및 TransBCEniche는 인기에 반비례하여 점수가 나타나는 특성을 보였습니다.



### Leveraging Weak Cross-Modal Guidance for Coherence Modelling via Iterative Learning (https://arxiv.org/abs/2408.00305)
Comments:
          Accepted by ACM Multimedia 2024

- **What's New**: 이번 연구에서는 금 라벨(gold labels) 없이 데이터를 이용해 크로스모달(coherence modeling) 코히어런스(Coherence)를 모델링할 수 있는 Weak Cross-Modal Guided Ordering (WeGO) 모델을 제안합니다. 이는 한 모달리티에서 예측된 고신뢰성 순서 정보를 다른 모달리티의 코히어런스를 모델링하는 데 활용하는 방법입니다.

- **Technical Details**: WeGO 모델은 예측된 쌍(pairwise)의 순서를 기준 정보로 사용하여 다른 모달리티의 순서를 예측합니다. 추정된 순서 예측을 기반으로, 두 모달리티의 코히어런스 모델을 공동으로 최적화하는 반복 학습 패러다임(iterative learning paradigm)을 설계했습니다. 이 반복적 크로스모달 부스팅(iterative cross-modal boosting)은 추론 단계에서도 각 모달리티의 코히어런스 예측을 강화합니다.

- **Performance Highlights**: 두 개의 공개 데이터셋에서 수행한 실험 결과, 제안된 WeGO 모델이 기존 방법들보다 우수한 성능을 보였습니다. 주요 기술 모듈들은 절제 연구(ablation studies)를 통해 그 효과가 검증되었습니다.



### RDP: Ranked Differential Privacy for Facial Feature Protection in Multiscale Sparsified Subspac (https://arxiv.org/abs/2408.00294)
Comments:
          13 pages, 6 figures

- **What's New**: 이 논문에서는 얼굴 인식 시스템에서 개인 얼굴 이미지를 보호하기 위한 새로운 프라이버시 보호 방법을 제안합니다. 'Ranked Differential Privacy (RDP)'라는 새 접근법을 통해 민감한 얼굴 특징을 보호합니다. 다중 스케일 희소화된 특징 서브스페이스에서 얼굴 특징을 분해한 후, 가벼운 라플라스 (Laplacian) 노이즈를 적용해 최적화된 프라이버시 보장을 제공합니다.

- **Technical Details**: 기술적으로는 원본 얼굴 이미지를 다중 스케일 특징 공간으로 분해하여 희소한 특징 계수를 얻습니다. 그런 다음, 각 특징 계수가 프라이버시 예산에 미치는 영향을 평가한 후, 중요도가 높은 특징 계수에 최적화된 스케일의 노이즈를 추가합니다. 비선형 라그랑주 승수법 (Lagrange Multiplier) 및 두 가지 최적화 방법- NA(Normalization Approximation) 방법과 LMGD(LM optimization Gradient Descent) 방법-을 사용해 노이즈 스케일 매개변수를 최적화합니다.

- **Performance Highlights**: 제안된 RDP 방법은 두 개의 실제 세계 데이터셋에서 다른 첨단 기술보다 뛰어난 성능을 보였습니다. 특히, 프라이버시 예산이 0.2일 때, RDP는 다른 방법보다 약 10dB 높은 PSNR을 달성했습니다. 이는 얼굴 이미지 보호 효과가 크면서도 이미지의 시각적 품질을 크게 손상시키지 않음을 의미합니다.



### Temporal Subspace Clustering for Molecular Dynamics Data (https://arxiv.org/abs/2408.00056)
Comments:
          Accepted as a research paper at BIOKDD 2024

- **What's New**: MOSCITO(Molecular Dynamics Subspace Clustering with Temporal Observance)는 단백질의 분자동역학 데이터를 클러스터링하는 새로운 알고리즘입니다. 기존 방법과는 달리 MOSCITO는 시간 시퀀스 데이터에서 발견되는 순차적 관계를 활용합니다. 또한, 번거로운 사후 처리가 필요 없는 단일 단계 접근법을 제공합니다.

- **Technical Details**: MOSCITO는 시간적 규제를 사용하여 단백질의 분자동역학 궤적에서 유사한 구조를 가지는 시간 단계를 클러스터링합니다. 기존 방법들이 주로 PCA 혹은 TICA와 k-Means 클러스터링을 두 단계로 적용하는 반면, MOSCITO는 바로 데이터의 본질적인 특성을 모델링합니다. 사용자는 시간 창 크기와 이진, 가우시안, 지수, 로그 방법 등 다양한 시간 규제 가중치를 선택할 수 있습니다.

- **Performance Highlights**: MOSCITO는 60개의 궤적과 4개의 단백질을 대상으로 수행한 실험에서 최첨단 성능을 달성했습니다. 특히 적은 수의 클러스터에서도 궤적을 효율적으로 세분화할 수 있습니다. 실험 결과, MOSCITO는 명확한 마코프 상태 모델(Markov State Model)을 통해 기존 방법과 비교해 더 우수한 성능을 보였습니다.



### MOSAIC: Multimodal Multistakeholder-aware Visual Art Recommendation (https://arxiv.org/abs/2407.21758)
- **What's New**: MOSAIC는 시각 예술 추천에 대해 최신 접근 방식을 제안합니다. 이 접근 방식은 여러 이해관계자의 요구를 고려하면서도 사용자 중심 측정치인 참신성, 우연성 및 다양성을 포함합니다. MOSAIC는 최신 CLIP와 BLIP 백본 아키텍처를 사용하여 다양한 분류에 걸친 인기와 대표적인 선택을 최적화하도록 설계되었습니다. 이 시스템은 213명의 사용자 선호도를 반영한 오프라인 평가와 100명의 크라우드워커 사용자 연구를 통해 검증되었습니다.

- **Technical Details**: MOSAIC는 텍스트 설명과 그림 이미지를 공동 훈련하여 그림에 대한 다중 모드(multimodal) 표현을 구축합니다. 그런 다음 다중 이해관계자(multistakeholder) 목표를 공동 최적화하는 다양한 전략을 제안합니다. 이를 위해 MOSAIC는 최신 CLIP와 BLIP 백본 아키텍처를 사용합니다. 특히, 대표적인 Late Fusion 전략과 Early Fusion 전략을 비교하였으며, Early Fusion이 더 나은 성능을 나타낸다고 결론지었습니다.

- **Performance Highlights**: 오프라인 평가 및 사용자 연구 결과, 인기 있는 그림이 사용자에게 더 긍정적으로 인식되는 것으로 나타났으며 대표성이 큰 영향을 미치지 않는다는 것으로 확인되었습니다. MOSAIC는 비단 방문자뿐만 아니라 여러 이해관계자들에게 혜택을 제공합니다. 차세대 시각 예술 추천 시스템 설계에 대한 귀중한 통찰력을 제공하면서, 학습과 발견, 사용자 만족도를 통합하는 방법을 제시합니다.



### Learning Effective Representations for Retrieval Using Self-Distillation with Adaptive Relevance Margins (https://arxiv.org/abs/2407.21515)
Comments:
          9 Pages, 4 Tables, 6 Figures

- **What's New**: 이 논문에서는 지식 증류(knowledge distillation) 대신, 사전 훈련된 언어 모델의 능력을 활용하는 새로운 자체 감독(self-supervision) 손실 함수에 대해 소개합니다. 이를 통해 배치 샘플링(batch sampling)을 통한 하드 네거티브 마이닝(hard negative mining)을 암묵적으로 수행하면서, 별도의 배치 샘플링 없이 비엔코더(bi-encoder)를 훈련할 수 있습니다.

- **Technical Details**: 제안된 접근법은 비엔코더의 훈련을 위해 복잡한 지식 증류 프로세스 대신, 인코더 모델의 사전 훈련된 텍스트 유사성 기능을 감독 신호로 사용합니다. 이 접근법은 데이터 효율성을 높이며, 데이터셋의 13.5%만으로도 기존 교사 증류 방법과 유사한 효과를 내는 것을 체계적인 실험을 통해 검증했습니다. 또한, 새로운 손실 함수는 하이퍼파라미터가 필요 없어, 하이퍼파라미터 튜닝을 줄일 수 있습니다.

- **Performance Highlights**: 제안된 손실 함수를 사용한 자체 증류(self-distillation)는 nDCG@10과 Recall@1000 점수에서 교사 증류 기반 훈련 방법과 유사한 성능을 보였습니다. 특히, 훈련 시간은 초기 방법에 비해 3배에서 15배까지 속도를 높일 수 있습니다.



### Breaking the Hourglass Phenomenon of Residual Quantization: Enhancing the Upper Bound of Generative Retrieva (https://arxiv.org/abs/2407.21488)
- **What's New**: 새로운 논문에서 'Hourglass' 현상으로 인해 생성 검색(generative retrieval) 방법의 효율성이 저하되는 문제를 분석하고 해결책을 제안하였습니다.

- **Technical Details**: Residual Quantization based Semantic Identifiers (RQ-SID)를 생성하는 과정에서, 코드북의 중간 토큰이 과도하게 집중되는 문제가 발생하는데, 이를 'Hourglass' 현상이라 정의하였습니다. 이 현상은 데이터 스파시티(data sparsity) 및 롱테일 분포(long-tailed distribution)에서 기인하며 이를 해결하기 위한 두 가지 방법을 제안했습니다: 히어리스틱 접근법(heuristic approach)과 가변 길이 코딩(variable-length coding) 전략.

- **Performance Highlights**: 경험적인 실험 결과, 제안된 두 가지 방법 모두 'Hourglass' 현상을 완화하고 모델의 성능을 향상시키는 데 효과가 있음을 확인했습니다. 또한, 특히 가변 길이 코딩 전략이 가장 효과적이라는 결론을 내렸습니다.



### ABCDE: Application-Based Cluster Diff Evals (https://arxiv.org/abs/2407.21430)
- **What's New**: 이번 논문은 매우 큰 아이템 집합의 클러스터링을 평가하는 문제를 다룹니다. ABCDE라는 새로운 평가 기술을 소개하며, 각 아이템에 애플리케이션에 특화된 중요 값을 지정할 수 있는 실용성을 강조합니다. ABCDE는 인간의 판단을 최소화하면서도, 클러스터링 품질의 차이를 평가하는 방법을 제공합니다.

- **Technical Details**: ABCDE(애플리케이션 기반 클러스터 차이 평가)는 두 클러스터링(Baseline와 Experiment)의 차이를 분석하고, 더 나은 클러스터링을 결정하는 데 초점을 맞춥니다. 이 방법은 피할 수 없는 'ground truth' 클러스터링을 미리 구축하지 않고, 실제 클러스터링 간의 차이를 기반으로 질문을 샘플링합니다. 포인트와이즈 매트릭스(Pointwise metrics)를 활용하여 클러스터링 차이를 직관적이고 간단하게 이해할 수 있도록 설계되었습니다. 이는 임팩트 매트릭스와 품질 매트릭스로 나뉘며, 자동계산 가능한 임팩트 매트릭스와 인간의 평가를 필요로 하는 품질 매트릭스로 구성됩니다.

- **Performance Highlights**: ABCDE는 전체 아이템 집합을 고려하여 변화를 타겟으로 인간의 평가를 샘플링하는 방식을 통해 높은 신뢰도의 평가 결과를 제공합니다. 이는 전체 클러스터링에 영향을 미치는 실제 변경 사항에 집중하여 클러스터링 품질의 델타를 추정합니다. 또한, 특정 아이템 집합의 임팩트 매트릭스를 쉽게 보고할 수 있어 이해와 디버깅을 용이하게 합니다.



### Personalized Multi-task Training for Recommender System (https://arxiv.org/abs/2407.21364)
Comments:
          11 pages

- **What's New**: 인터넷 상의 방대한 정보 속에서 사용자들이 자신의 취향에 맞는 선택을 할 수 있도록 돕는 추천 시스템(RecSys)이 필수적입니다. 본 논문에서는 다양한 정보 출처로부터 사용자/아이템 임베딩(embedding)을 얻기 위한 최초의 개인화된 멀티태스크 학습 알고리즘 PMTRec을 소개합니다. PMTRec은 사용자/아이템별로 동적으로 태스크 가중치를 조정하고, Gradient Magnitude Balancing module과 Task Focusing module을 도입하여 여러 태스크를 동시에 활용해 추천 정확도를 향상시킵니다.

- **Technical Details**: PMTRec은 다음과 같은 주요 모듈을 포함합니다: (1) Personalized Task Weights: 사용자 또는 아이템별로 태스크 가중치를 다르게 설정하여, 다양한 특정 태스크에 대한 중요도를 각각 다르게 계산합니다. (2) Task Focusing Module: 주 추천 태스크에 맞춰 그래디언트 조합을 맞추도록 학습 과정을 점진적으로 강조합니다. (3) Gradient Magnitude Balancing Module: 각 태스크의 그래디언트 크기를 조정함으로써 태스크 간의 균형을 맞추는 역할을 합니다.

- **Performance Highlights**: 세 가지 실제 데이터셋을 사용한 광범위한 실험을 통해, PMTRec이 기존의 멀티태스크 학습 방법보다 추천 정확도에서 크게 능가하는 성능을 보였습니다. 다양한 규모의 데이터셋에서도 일관되게 높은 성능을 보여주었으며, 여러 태스크를 동시에 활용함으로써 더 포괄적인 임베딩을 생성하는 데 성공했습니다.



### Implementing Streaming algorithm and k-means clusters to RAG (https://arxiv.org/abs/2407.21300)
- **What's New**: 이 논문에서는 정보 검색을 위해 대규모 모델을 보조하는 외부 지식 데이터베이스를 구축한 Retrieval-augmented generation (RAG)의 문제를 해결하려고 합니다. 기존 RAG는 거대한 데이터베이스 때문에 메모리 소모가 크고, 대량의 스트리밍 데이터에 대해서는 즉각적으로 인덱스 데이터베이스를 업데이트하는 데 어려움을 겪습니다. 이러한 문제를 해결하기 위해 스트리밍 알고리즘과 k-means 클러스터링을 RAG와 결합한 새로운 접근 방식을 제안했습니다.

- **Technical Details**: 제안된 접근 방식은 스트리밍 알고리즘을 적용하여 인덱스를 업데이트하고 메모리 소비를 줄입니다. 그런 다음 k-means 알고리즘을 적용하여 유사성이 높은 문서를 클러스터링하여 쿼리 시간을 단축합니다. 이를 통해 데이터베이스를 구축하는 데 필요한 메모리를 절약하면서도 정확성을 유지할 수 있습니다.

- **Performance Highlights**: 네 가지 방법에 대한 비교 실험을 수행한 결과, 스트리밍 알고리즘과 k-means 클러스터링을 사용한 RAG가 정확성과 메모리 측면에서 우수한 성능을 보였습니다. 특히, 대규모 스트리밍 데이터에 대해 제안된 방법이 기존의 RAG보다 더 나은 성능을 발휘하는 것을 확인했습니다.



### GenRec: Generative Personalized Sequential Recommendation (https://arxiv.org/abs/2407.21191)
- **What's New**: GenRec는 '사전 훈련, 프롬프트, 예측'의 최근 패러다임에 영감을 받아, 연속 추천을 시퀀스-투-시퀀스(sequence-to-sequence) 생성(task)으로 간주하고, 새로운 모델을 제안했습니다. 이 모델은 사용자 및 항목의 명시적 표현을 학습하는 기존의 분류 기반 모델과 달리, Transformer의 시퀀스 모델링 능력을 활용하고, masked item prediction 목표를 채택하여 숨겨진 양방향 시퀀스 패턴을 효과적으로 학습합니다.

- **Technical Details**: GenRec는 수동으로 설계된 하드 프롬프트(hard prompts)에 의존하지 않으며, 텍스트 형식의 사용자 항목 시퀀스를 입력으로 받고, 상위 순위의 다음 항목을 출력으로 제공합니다. 이 모델은 Transformer 기반의 인코더-디코더(encoder-decoder)를 백본으로 사용하며, 시퀀스-투-시퀀스 생성(task)으로 연속 추천을 공식화합니다. 클로즈(cloze) 과제를 훈련 목표로 사용하여 모델을 사전 훈련시키고, 양방향 시퀀스 패턴을 학습합니다.

- **Performance Highlights**: GenRec는 공공의 실제 데이터셋에서 확실하게 일반화되어 최첨단 성과를 달성했습니다. 이 모델은 경량이며, 로우 리소스 환경에서 몇 시간만에 효과적으로 학습할 수 있어, 실제 시나리오 적용에 매우 유리하며, 연속 추천 도메인에서 대형 언어 모델의 민주화를 촉진할 수 있습니다.



### Watermarking Recommender Systems (https://arxiv.org/abs/2407.21034)
- **What's New**: 본 논문은 추천 시스템(recommender systems)의 모델 절도를 방지하기 위해 새로운 모델 워터마킹 기법인 Autoregressive Out-of-distribution Watermarking (AOW)를 소개합니다. 이는 기존의 바탕 데이터와 다른 (out-of-distribution) 데이터를 사용하여 생성된 워터마크 시퀀스를 통해 모델의 소유권을 확인하는 방법입니다.

- **Technical Details**: AOW는 초기 아이템을 선택하고, 이 아이템을 오라클 모델을 통해 질의하여 작은 예측 점수를 가진 연속적 아이템들을 선택하여 워터마크 시퀀스를 생성합니다. 이 과정은 자가회귀적으로 (autoregressively) 반복되어 시퀀스가 모델에 학습됩니다. 모델이 잘라진 워터마크 시퀀스를 기반으로 다음 아이템을 예측하게 하여 워터마크의 유효성을 평가합니다.

- **Performance Highlights**: AOW는 디스틸레이션(distillation) 및 미세 조정(fine-tuning) 공격에도 높은 신뢰성으로 워터마크를 추출할 수 있는 강력한 성능을 보입니다. 특히, 기본 설정에서 1.0 Recall@1과 0.75 이상의 Recall@10을 달성했습니다. 이는 추천 시스템의 성능 저하 없이 모델 절도로부터 효과적으로 보호할 수 있음을 의미합니다.



### Multi-Grained Query-Guided Set Prediction Network for Grounded Multimodal Named Entity Recognition (https://arxiv.org/abs/2407.21033)
Comments:
          11 pages, 5 figures

- **What's New**: Grounded Multimodal Named Entity Recognition(GMNER)라는 정보 추출(IE) 작업 분야에서, 최신 연구들은 MRC 기반 프레임워크나 시퀀스 생성 기반 모델을 사용하고 있지만, 이러한 방법들은 멀티모달 엔티티 간의 관계 이해에 어려움을 겪고 있습니다. 이에 본 연구는 MQSPN(Multi-grained Query-guided Set Prediction Network)을 제안해 intra-entity와 inter-entity 수준에서 적절한 관계를 학습하는 새로운 통합 프레임워크를 소개합니다.

- **Technical Details**: MQSPN은 Multi-grained Query Set(MQS)와 Multimodal Set Prediction Network(MSP), 그리고 Query-guided Fusion Net(QFNet)으로 구성됩니다. MQS는 특정 타입 세분화된 쿼리들과 학습 가능한 엔티티 세분화된 쿼리를 결합하여 intra-entity 연결을 강화합니다. MSP는 GMNER를 집합 예측(set prediction) 문제로 재구성하여 inter-entity 관계를 글로벌 매칭 관점에서 적절하게 모델링합니다. QFNet은 텍스트와 시각적 정보를 각각 적절하게 통합하여 노이즈를 줄이는 역할을 합니다.

- **Performance Highlights**: 제안된 MQSPN 프레임워크는 기존 SOTA(State-of-the-Art) 방법들보다 우수한 성능을 기록했습니다. 특히, 어려운 fine-grained GMNER benchmark에서 2.83%의 F1 점수를 향상시켰습니다.



### E-Commerce Product Recommendation System based on ML Algorithms (https://arxiv.org/abs/2407.21026)
- **What's New**: 최근 전자상거래(eCommerce) 플랫폼의 제품 추천 시스템에서 머신러닝 알고리즘이 본격적으로 사용되기 시작했습니다. 이 프로젝트는 첨단 머신러닝 기법을 사용하여 각 고객에게 맞춤형 제품 추천과 혜택을 제공하는 모델을 개발하는 것을 목표로 하고 있습니다.

- **Technical Details**: 이 모델은 데이터의 차원을 줄이기 위해 PCA(Principal Component Analysis)를 사용하고, Gaussian Naive Bayes (GNB), Random Forest (RF), Logistic Regression (LR), Decision Tree (DT)와 같은 네 가지 머신러닝 알고리즘을 사용하여 학습되었습니다.

- **Performance Highlights**: 이 중에서 Random Forest 알고리즘이 가장 높은 정확도(99.6%)를 기록했으며, R 제곱 점수(96.99), MSE (Mean Squared Error) 점수(1.92%), MAE (Mean Absolute Error) 점수(0.087)를 달성했습니다. 이 결과는 고객과 기업 모두에게 이점이 될 수 있습니다.



### LLM-Find: An Autonomous GIS Agent Framework for Geospatial Data Retrieva (https://arxiv.org/abs/2407.21024)
- **What's New**: 새롭게 등장한 대형 언어 모델(LLMs)에 의해, 자율적인 GIS 에이전트 (Geographic Information Systems agents)가 공간 분석과 지도 제작 작업을 수행할 수 있는 잠재력이 높아졌습니다. 본 연구는 이러한 GIS 에이전트를 완전 자율적으로 지원하기 위한 연구 격차를 해결하고자 하며, 특히 필수적인 공간 데이터를 자동으로 발견하고 다운로드할 수 있는 방법을 제안합니다. 이를 위해 LLM-Find라는 자율 GIS 에이전트 프레임워크를 제안했습니다.

- **Technical Details**: LLM-Find는 LLM을 의사결정자로 활용하여, 사전 정의된 소스 리스트에서 적절한 데이터 소스를 선택하고 데이터를 추출합니다. 각 데이터 소스는 데이터 검색을 위한 메타데이터와 기술적 세부사항이 기록된 핸드북을 포함합니다. 이 프레임워크는 플러그 앤 플레이 (plug-and-play) 방식으로 설계되어 유연성과 확장성이 보장됩니다. 자동 데이터 스크롤러 또는 인간 사용자가 새로운 핸드북을 추가함으로써 새로운 데이터 소스를 쉽게 추가할 수 있습니다.

- **Performance Highlights**: 개발된 프로토타입 에이전트는 OpenStreetMap, 미 행정 경계 및 인구 통계 데이터, ESRI World Imagery의 위성 베이스맵, 상업 제공자가 제공한 기상 데이터, NYTimes GitHub의 COVID-19 데이터를 포함한 다양한 소스에서 데이터를 성공적으로 검색하는 능력을 입증했습니다. 이 연구는 자율적인 지리 공간 데이터 검색 에이전트를 개발한 최초의 시도 중 하나입니다.



### A Comprehensive Survey on Retrieval Methods in Recommender Systems (https://arxiv.org/abs/2407.21022)
Comments:
          38 pages

- **What's New**: 산업계에서 널리 사용되는 다단계 캐스케이드 랭킹 시스템은 정보 과부하를 관리하는 데 필수적입니다. 이번 조사에서는 랭킹 단계가 아닌 추천 시스템의 중요한 '검색 단계'에 대해 탐구합니다. 이는 사용자와 항목 간의 유사성 계산을 개선하고, 효율적인 검색을 위한 인덱싱 메커니즘을 강화하며, 검색 훈련 방법을 최적화하는 세 가지 주요 영역에서 기존 연구를 요약합니다.

- **Technical Details**: 검색 단계는 크게 세 가지 키 부분이 있습니다: 1) 사용자와 항목 간 유사성 계산을 개선하는 것 2) 효율적인 검색을 위한 인덱싱 메커니즘을 강화하는 것 3) 검색 훈련 방법을 최적화하는 것입니다. 대표적으로, dual-tower architecture를 사용해 사용자와 항목을 독립적으로 표현하며, inner product나 cosine similarity 같은 기본 유사성 메트릭을 통해 매칭 점수를 계산합니다.

- **Performance Highlights**: 실험은 세 개의 공개 데이터셋에서 수행되었으며, 특정 회사의 온라인 서빙 과정을 포함한 사례 연구를 통해 현재 산업적 응용을 강조합니다. 이는 검색 단계의 효율성과 정확도를 높이는 데 중요한 지표로 작용합니다. 이로써 검색 단계에서 효율적으로 많은 관련 아이템을 포함시키는 것이 중요하며, 최적의 추천 시스템 성능을 지탱하는 데 필수적임을 확인할 수 있습니다.



### Adaptive Retrieval-Augmented Generation for Conversational Systems (https://arxiv.org/abs/2407.21712)
Comments:
          12 pages, under review

- **What's New**: 최근 연구는 대형 언어 모델(LLM)이 대화 시스템에 통합되는 성공에도 불구하고, 외부 지식을 검색하여 응답을 보강하는 것이 효과적이라는 점을 강조했습니다. 이 연구에서는 모든 대화 턴마다 외부 지식이 필요한지에 관한 필요성을 조사했습니다. 그 결과, RAGate라는 gating model을 개발하여 대화의 컨텍스트와 관련 입력을 모델링함으로써 대화 시스템이 언제 외부 지식 보강이 필요한지를 예측할 수 있게 했습니다.

- **Technical Details**: RAGate는 LLM과 대화 시스템의 맥락을 바탕으로 현재 대화 상황에서 외부 지식이 필요한지 여부를 예측하는 binary knowledge gate 메커니즘입니다. 이를 위해 인간의 판단을 활용하여 학습을 진행합니다. 또한 주어진 Task-Oriented Dialogue (TOD) 시스템 데이터셋, KETOD를 사용하여 다양한 영역에서 실험을 진행했습니다. 이 시스템은 무조건적인 지식 보강이 응답의 불확실성과 헛소리(hallucination)를 증가시킬 가능성이 높다는 점을 발견했습니다.

- **Performance Highlights**: RAGate는 대화 시스템이 적절한 대화 턴에서 외부 지식을 효율적으로 사용하여 고품질의 응답을 생성하도록 합니다. 시스템의 불확실성 및 자신감 레벨을 모델링함으로써, 외부 지식의 항상 보강이 생성 불확실성과 헛소리의 위험을 크게 증가시킬 수 있음을 보여줍니다. RAGate을 적용함으로써, 시스템은 보다 자신 있고 정보가 풍부한 응답을 만들 수 있습니다. 나아가, 사용된 지식 조각의 관련성 수준에 따라 자신감 점수와 보강된 지식의 관련성 간의 긍정적인 상관관계를 관찰할 수 있습니다.



### ProSpec RL: Plan Ahead, then Execu (https://arxiv.org/abs/2407.21359)
- **What's New**: 연구팀은 행동 실행 전 잠재적 결과를 상상할 수 있도록 하여 더 정보에 입각한 결정을 내릴 수 있는 Prospective (ProSpec) 강화 학습(RL) 방법을 제안했습니다. ProSpec은 현재 상태와 일련의 샘플링된 행동에 기초하여 미래의 n-스트림 궤적을 상상함으로써 높은 가치와 낮은 위험의 최적 결정을 내립니다.

- **Technical Details**: ProSpec은 동적 모델을 사용하여 현재 상태와 일련의 샘플링된 행동을 바탕으로 미래 상태(상상된 상태)를 예측합니다. 또한 Model Predictive Control(MPC) 개념을 통합하여 이러한 궤적들 중 최적의 행동을 평가하고 선택하는 순환 일관성 제약을 도입했습니다. ProSpec은 또한 순환 일관성을 사용하여 기본적인 두 가지 문제를 완화합니다: 상태 가역성을 향상시켜 비가역적 사건을 피하고(낮은 위험성) 많은 가상 궤적을 생성하여 데이터 효율성을 향상시키는 것입니다.

- **Performance Highlights**: ProSpec 방법은 DMControl 벤치마크에서 유효성을 입증했으며, 우리의 접근법은 상당한 성능 향상을 이루었습니다. 코드는 승인 시 오픈 소스로 공개할 예정입니다.



### LawLLM: Law Large Language Model for the US Legal System (https://arxiv.org/abs/2407.21065)
Comments:
          21 pages, 2 figures, accepted at the 33rd ACM International Conference on Information and Knowledge Management (CIKM 2024) for the Applied Research Paper track

- **What's New**: 법률 분석 분야에서 복잡한 법적 언어와 유사한 판례의 미묘한 차이로 인해 관련 사례를 찾고 판결을 예측하는 것이 어려운 상황입니다. 이를 해결하기 위해 미국 법률 도메인에 특화된 다중 작업 모델인 Law Large Language Model (LawLLM)를 소개합니다. LawLLM는 유사한 사례 검색(Similar Case Retrieval, SCR), 전례 사례 추천(Precedent Case Recommendation, PCR), 그리고 법적 판결 예측(Legal Judgment Prediction, LJP)에서 뛰어난 성능을 보입니다.

- **Technical Details**: LawLLM는 세 가지 주요 작업을 수행합니다: Similar Case Retrieval (SCR), Precedent Case Recommendation (PCR), 법적 판결 예측(Legal Judgment Prediction, LJP). 모델 개발 과정에서 필요한 데이터 전처리 기술을 각 작업에 맞춰 커스터마이징하였고, 추론 학습(In-context learning)과 고급 정보 검색 기법을 활용하였습니다. 이를 통해 원시 법적 데이터를 훈련 가능한 형식으로 변환하였습니다.

- **Performance Highlights**: LawLLM는 기존 베이스라인 모델을 제로샷(zero-shot) 및 몇 샷(few-shot) 시나리오 모두에서 일관되게 능가하는 성능을 보여줌으로써 다중 작업 기능을 입증했습니다. 또한, 유사한 사례(Similar Case)와 전례 사례(Precedent Case)를 명확히 구분함으로써, 향후 연구에 필요한 맞춤형 전략 개발에 대한 중요한 통찰을 제공합니다.



### Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks (https://arxiv.org/abs/2407.21059)
- **What's New**: 이번 논문에서는 기존의 취득-생성(Retrieval-augmented Generation, RAG) 패러다임의 한계를 검토하고, 모듈식 RAG(Modular RAG) 프레임워크를 도입했습니다. 복잡한 RAG 시스템을 독립적인 모듈과 특화된 연산자로 분해함으로써, 보다 유연하고 재구성 가능한 구조를 제공합니다. 그런 방식으로, 전통적인 선형 아키텍처를 넘어 라우팅, 스케줄링, 융합 메커니즘을 통합한 더욱 발전된 디자인을 채택하고 있습니다.

- **Technical Details**: 모듈식 RAG는 세 가지 레벨로 구성된 아키텍처를 제공합니다. 상위 레벨에서는 RAG의 중요한 단계를 독립적인 모듈로 처리하고, 중간 레벨은 각 모듈 내에 하위 모듈을 구성하여 기능을 세분화하며, 하위 레벨에서는 연산자의 기본 단위로 구성됩니다. 이 프레임워크에서 RAG 시스템은 계산 그래프 형태로 표현될 수 있으며, 노드는 특정 연산자를 나타냅니다.

- **Performance Highlights**: 모듈식 RAG의 주요 장점은 유연성과 확장성이 뛰어나다는 것입니다. 사용자는 데이터 소스와 작업 시나리오의 요구사항에 따라 다양한 모듈과 연산자를 유연하게 결합할 수 있습니다. 논문에서는 모듈식 RAG의 6가지 대표적인 흐름 패턴을 요약하고, 실용적인 시나리오에서의 범용성을 위해 구체적인 방법을 분석했습니다. 이를 통해 시스템의 유지보수와 이해도를 강화하면서, 새로운 방법의 적응과 확장에 대한 가이드를 제공합니다.



### What Matters in Explanations: Towards Explainable Fake Review Detection Focusing on Transformers (https://arxiv.org/abs/2407.21056)
- **What's New**: 본 논문은 전자상거래 플랫폼에서 등장하고 있는 허위 리뷰(fraudulent reviews) 문제를 해결하기 위해 설명 가능한 고정확도 프레임워크를 제안합니다. 특히, 신경망 모델이 이해하기 어려운 블랙박스(black-box) 특성을 가지는 문제를 해결하고자 설명 가능한 기법을 제시했습니다.

- **Technical Details**: 딥러닝(DL)과 트랜스포머(transformer) 모델인 XLNet과 DistilBERT를 사용하여 허위 리뷰 탐지 모델을 개발하였습니다. 그런 다음 레이어별 연관성 전파(layer-wise relevance propagation, LRP) 기술을 사용하여 예측 클래스에 기여하는 단어들을 매핑하는 설명을 생성했습니다.

- **Performance Highlights**: 두 개의 벤치마크 데이터셋을 대상으로 실험한 결과, 제안된 예측 모델은 최첨단 성능(State-of-the-Art Performance)을 달성하며 기존의 여러 방법들을 능가했습니다. 또한, 생성된 설명에 대한 사용자의 경험적 평가 결과, 허위 리뷰 식별 맥락에서 고려해야 할 중요한 정보들을 결론지었습니다.



### Advancing Chart Question Answering with Robust Chart Component Recognition (https://arxiv.org/abs/2407.21038)
- **What's New**: 새로운 기계 학습 모델인 Chartformer를 소개합니다. 이 모델은 차트 컴포넌트(예: 바, 라인, 파이, 제목, 범례, 축)를 정확하게 인식하고 분류하는 데 탁월한 성능을 보입니다. 또한, Question-guided Deformable Co-Attention (QDCAt) 메커니즘을 도입하여 질문에 기반한 지도를 통해 차트 기능을 결합하고 올바른 답을 도출할 수 있도록 개선하였습니다.

- **Technical Details**: Chartformer는 변형 가능한 주의 메커니즘(deformable attention)과 마스크 주의 메커니즘(mask attention)을 사용하여 차트 그래픽의 시각적 요소를 효과적으로 포착합니다. QDCAt 메커니즘은 Question-guided Offset Network (QON)를 활용해 질문 정보를 차트 기능과 결합하고 시각적 및 차트 관련 기능을 통합합니다.

- **Performance Highlights**: Chartformer는 기존 강력한 기준 모델인 DAT와 Mask2former를 각각 11.4%, 3.2% mAP에서 능가하며, 특히 중복되거나 불규칙한 라인 및 좁은 파이 조각에서 뛰어난 성능을 보입니다. QDChart는 ChartQA에서 15.4%의 정확도로 기존 Pix2Struct 모델을 능가하며, 색상 명확화 및 차트 컴포넌트 크기 비교와 같은 시각적으로 관련된 질문을 처리하는 데 특히 우수한 능력을 보여줍니다.



### Learn by Selling: Equipping Large Language Models with Product Knowledge for Context-Driven Recommendations (https://arxiv.org/abs/2407.20856)
- **What's New**: 이 논문은 대형 언어 모델(Large Language Models, LLMs)을 사용한 제품 추천 시스템에 대한 새로운 접근법을 제시합니다. 특정한 제품 ID를 포함한 합성 검색 쿼리에 맞춰 LLMs를 훈련시킴으로써 이들이 제품 인벤토리에 대한 종합적인 이해를 할 수 있도록 합니다.

- **Technical Details**: 논문에서 제시된 방법은 LLMs를 합성 검색 쿼리(synthetic search queries)에 맞춰 훈련시킴으로써, 이들이 주어진 컨텍스트 내에서 적절하게 반응할 수 있게 만드는 것입니다. 이는 제품 추천(product recommendations) 분야에서 LLMs의 유효성을 증진시키기 위한 새로운 방법론입니다.

- **Performance Highlights**: 이 접근법의 유효성에 대한 종합적인 분석을 통해 여러 장점과 한계를 밝혔습니다. 또한, 향후 개선 가능성과 발전 방향에 대해서도 논의하였습니다. 이를 통해 LLMs가 제품 추천 시스템에서 중요한 역할을 할 수 있다는 이해를 제공합니다.



### JaColBERTv2.5: Optimising Multi-Vector Retrievers to Create State-of-the-Art Japanese Retrievers with Constrained Resources (https://arxiv.org/abs/2407.20750)
- **What's New**: 최근 Neural Information Retrieval(신경 정보 검색)은 고자원 언어에서 눈부신 발전을 이루었지만, 일본어와 같은 저자원 언어에서는 데이터 부족 등의 문제로 성장이 더뎠습니다. JaColBERT와 같은 최신 멀티벡터 단일 언어 모델이 이러한 격차를 좁히고 있지만, 여전히 대규모 평가에서는 다국어 방법에 뒤처지고 있습니다. 이를 해결하기 위해 JaColBERT의 핵심적인 추론 및 훈련 설정을 체계적으로 평가하고 개선하여 JaColBERTv2.5를 도입했습니다.

- **Technical Details**: JaColBERTv2.5는 다국어 모델의 비효율성과 언어적 뉘앙스를 포착하지 못하는 문제를 해결하기 위해, 특히 저자원 언어 환경에서 멀티벡터 적용 방법의 훈련 방식을 개선했습니다. 또한 새로운 checkpoint merging step(체크포인트 병합 단계)을 도입해 파인튜닝의 이점을 원래 체크포인트의 일반화 능력과 결합했습니다. JaColBERTv2.5 모델은 4개의 A100 GPU에서 15시간 이하로 훈련되었으며, 1억 1천만 개의 파라미터를 가지고 있습니다.

- **Performance Highlights**: JaColBERTv2.5는 모든 공용 벤치마크에서 최고 성능을 달성했으며, 평균 점수 0.754로 이전 최고 기록 0.720보다 크게 앞선 성과를 보였습니다. 이를 위해 최종 모델, 중간 체크포인트 및 사용된 모든 데이터를 공개하여 향후 연구를 지원할 예정입니다.



### RevGNN: Negative Sampling Enhanced Contrastive Graph Learning for Academic Reviewer Recommendation (https://arxiv.org/abs/2407.20684)
Comments:
          Accepted by ACM Transactions on Information Systems (TOIS)

- **What's New**: 최근 그래프 학습(Graph Learning) 기반 모델들은 추천 시스템 분야에서 상당한 진전을 이루었지만, 학술 리뷰어 추천에서의 성능은 여전히 과제로 남아 있습니다. 그 이유는 관찰되지 않은 상호작용이 부정적 샘플(Negative Samples)로 간주된다는 가정에 기인합니다. 본 연구는 이러한 문제를 해결하기 위해 Pseudo Neg-Label 전략을 도입한 RevGNN이라는 모델을 제안합니다.

- **Technical Details**: RevGNN은 리뷰어 추천을 위해 그래프 대조 학습(Graph Contrastive Learning, GCL)을 강화하는 비지도 학습(Unsupervised Learning) 방식의 Pseudo Neg-Label 전략을 활용합니다. 두 단계 인코더 구조를 통해 과학적 지식과 행동을 각각 인코딩하여 리뷰어의 선호도를 근사합니다.

- **Performance Highlights**: 세 개의 실제 데이터셋에서 수행한 광범위한 실험 결과, RevGNN은 네 가지 메트릭스에서 모든 기준선 모델들을 능가하였습니다. 또한, 구성 요소별 상세 분석을 통해 RevGNN의 각 구성 요소가 효과적임을 확인하였습니다.



### Powerful A/B-Testing Metrics and Where to Find Them (https://arxiv.org/abs/2407.20665)
Comments:
          Accepted to the Industry Track of the 2024 ACM Conference on Recommender Systems (RecSys '24)

- **What's New**: 이번 논문에서는 실세계 추천 시스템(recommender system) 평가의 핵심인 온라인 통제 실험(online controlled experiments), 흔히 A/B 테스트로 알려진 기법에 대해 새로운 관점을 제시합니다. 특히, 대규모의 단기 비디오 플랫폼(ShareChat과 Moj)에서 이러한 실험을 어떻게 대규모로 구축하고 활용했는지에 대한 결과와 인사이트를 제공합니다.

- **Technical Details**: 북극성 지표(North Star Metric, 예: 장기 성장이나 매출)를 사용하여 시스템 변종의 우위를 평가합니다. 대부분의 수집된 지표는 사용자 경험에 미치는 영향을 이해하거나 북극성 지표가 유의미하게 움직이지 않을 때(type-II error, 즉 거짓 음성)에 자신 있는 결정을 내릴 수 있도록 지원합니다. 제안된 방법은 과거 수백 개의 실험을 활용하여 유형 I, II, III 오류(type-I, type-II, type-III errors)와 통계적 검정력(e.g. z-점수와 p-값)을 측정하는 것입니다.

- **Performance Highlights**: 이 연구는 두 대규모 단기 비디오 플랫폼인 ShareChat과 Moj를 대상으로 수백 개의 과거 실험을 활용하여 온라인 지표의 높은 통계적 검정력(statistical power)을 찾았습니다. 이를 통해 다양한 지표의 유용성을 평가하는 데 필요한 새로운 파이프라인을 효과적으로 구축했습니다.



### Graphite: A Graph-based Extreme Multi-Label Short Text Classifier for Keyphrase Recommendation (https://arxiv.org/abs/2407.20462)
- **What's New**: 광고와 전자상거래 분야에서 매우 중요한 문제인 핵심어(keyphrase) 추천에 새로운 해결책을 제안합니다. Graphite라는 그래프 기반 분류기 모델을 통해 실시간 핵심어 추천을 구현했습니다. 이 모델은 GPU 없이 작동되며, 네트워크 자원이 제한된 환경에서도 사용 가능합니다.

- **Technical Details**: Graphite는 XML(Extreme Multi-label) 단문(text) 분류 문제로 프레임되었습니다. 이는 입력 텍스트를 키워드로 태깅하여 분류(label)하는 것으로, 기존 신경망 모델보다 경량화되어 훈련과 추론 속도가 빠릅니다. 그래서 대규모 데이터셋에서도 문제없이 동작할 수 있습니다. 이 모델은 결정론적이고 투명하며 신경망 기반 모델보다 본질적으로 더 해석이 용이합니다.

- **Performance Highlights**: Graphite는 eBay의 영어권 사이트에서 40개 카테고리에 걸쳐 포괄적인 성능 분석을 통해 표준 텍스트 분류 모델과 유사한 성능을 보여주었습니다. 특히 최신 XML 모델들이 극한의 자원 요구 조건 때문에 실패하는 경우에도 Graphite는 문제없이 훈련과 추론을 수행할 수 있습니다.



### Aligning Query Representation with Rewritten Query and Relevance Judgments in Conversational Search (https://arxiv.org/abs/2407.20189)
Comments:
          Accepted by CIKM 2024

- **What's New**: 이번 연구는 복잡한 정보를 해결하기 위해 사용자가 시스템과 여러 차례 상호작용하는 대화형 검색(conversational search)에 대한 새로운 접근 방식을 제시합니다. 제안된 모델 이름은 QRACDR(Query Representation Alignment Conversational Dense Retriever)으로, 기존 대화형 검색 방법들과 다른 접근 방식을 채택합니다.

- **Technical Details**: QRACDR 모델은 대화형 검색 데이터에서 재작성된(conversational query rewriting) 쿼리와 관련성 판단(relevance judgments)을 활용하여 쿼리 표현(query representation)을 향상시킵니다. 주요 아이디어는 쿼리 표현을 재작성된 쿼리 및 관련 문서의 표현과 정렬하는 것입니다. 이 접근 방식은 쿼리 표현과 관련 문서 표현의 적절한 정렬을 통해 검색 성능을 높입니다.

- **Performance Highlights**: QRACDR 모델은 대화형 검색 및 전통적인 검색(ad-hoc search) 환경에서 테스트되었으며, 8개의 데이터셋에서 실험을 진행했습니다. 그 결과, 최신 연구방법들과 비교했을 때 QRACDR 모델의 우수한 성능이 입증되었고, 표현 정렬의 효과가 확인되었습니다.



### EXIT: An EXplicit Interest Transfer Framework for Cross-Domain Recommendation (https://arxiv.org/abs/2407.20121)
Comments:
          Accepted at CIKM 2024

- **What's New**: 이번 연구에서는 Meituan과 같은 다수의 비즈니스 영역을 다루는 산업용 추천 시스템에서 발생하는 부정적인 신호 전이 문제를 해결하기 위해 새로운 EXplicit Interest Transfer 프레임워크인 EXIT를 소개합니다. 이 프레임워크는 사용자 간 관심사 신호를 명시적으로 전이하여 추천 정확도를 향상시킵니다.

- **Technical Details**: EXIT 프레임워크는 주요 도메인의 유익한 관심사를 지도 학습(supervised learning)을 통해 직접 학습할 수 있게 하는 새로운 라벨 결합(label combination) 접근 방식을 제안합니다. 또한, 세밀한 장면(scene)에서 관심 전이 강도를 모델링하기 위한 장면 선택 네트워크(scene selector network)를 도입하였습니다. 이러한 기술들은 복잡한 네트워크 구조나 훈련 과정을 거치지 않아도 쉽게 배포할 수 있습니다.

- **Performance Highlights**: EXIT는 산업용 생산 데이터셋을 이용한 오프라인 실험과 온라인 A/B 테스트에서 그 우수성과 효과성이 검증되었습니다. 이미 Meituan App의 온라인 홈페이지 추천 시스템에 성공적으로 배포되어 주요 트래픽을 처리하고 있습니다.



### FiCo-ITR: bridging fine-grained and coarse-grained image-text retrieval for comparative performance analysis (https://arxiv.org/abs/2407.20114)
Comments:
          19 pages, submitted to International Journal of Multimedia Information Retrieval

- **What's New**: 이 논문에서는 Image-Text Retrieval (ITR) 분야에서 Fine-Grained (FG) 인스턴스 레벨의 검색과 Coarse-Grained (CG) 카테고리 레벨의 검색을 비교할 수 있는 표준 평가 방법론을 제공하는 	exttt{FiCo-ITR} 라이브러리를 소개합니다. 이 새로운 라이브러리를 통해 FG와 CG 모델의 직접적인 비교가 가능해졌습니다.

- **Technical Details**: FG 검색은 대규모 Vision-Language Pretraining (VLP)을 활용하여 높은 정확도를 달성하지만, 계산 복잡도가 증가하는 단점이 있습니다. 반면, CG 검색은 Cross-Modal Hashing (CMH)을 사용하여 효율성을 우선시하지만 검색 성능이 떨어질 수 있습니다. 본 연구에서는 대표적인 FG와 CG 모델을 선정하여 정확도, 재현율, 계산 복잡도 등의 측면에서 다양한 데이터 규모에 대해 실증적 평가를 수행하였습니다.

- **Performance Highlights**: 본 연구 결과는 최근의 대표적인 FG와 CG 모델 간의 성능-효율성 트레이드오프에 대한 새로운 통찰을 제공합니다. FG 모델은 높은 정확도를 자랑하지만 고도의 계산 자원이 필요하며, CG 모델은 빠른 검색 속도와 높은 효율성을 제공하지만 상대적으로 낮은 검색 성능을 보입니다. 이러한 결과는 특정 검색 작업을 위한 모델 선택에 있어 보다 정보에 입각한 결정을 내릴 수 있는 토대를 제공합니다.



### AOTree: Aspect Order Tree-based Model for Explainable Recommendation (https://arxiv.org/abs/2407.19937)
- **What's New**: 최근의 추천 시스템(recommender systems)은 정확한 추천뿐만 아니라 사용자들이 이를 더욱 잘 이해할 수 있도록 설명도 제공합니다. 대부분의 기존 설명 가능한 추천 시스템들은 리뷰 내용의 중요성만을 고려하고, 순서 관계(ordering relationship)를 무시하고 있습니다. 이 논문에서는 이러한 문제를 해결하기 위해, 결정 요인들 사이의 의존 관계를 포착할 수 있는 'Aspect Order Tree-based (AOTree)' 추천 방법을 제안했습니다. 이 접근법은 인지 및 결정 심리학(cognitive and decision psychology)의 'Order Effects Theory'에서 영감을 받아 개발되었습니다.

- **Technical Details**: 우선, 추천 시나리오에서 이 이론을 검증하기 위해 사용자 리뷰를 분석했습니다. 그런 다음, 이 이론을 기반으로 AOTree는 사용자의 의사결정 과정에서 사용자인식 측면(aspect orders)을 포착하기 위해 의사결정 트리(decision tree)를 확장하고, 어텐션 메커니즘(attention mechanisms)을 사용하여 특정 순서를 기반으로 예측을 수행합니다. 이는 순서의 의존 관계를 잘 반영하여 해석 가능성을 높입니다.

- **Performance Highlights**: 광범위한 실험 결과, 제안된 방법이 평점 예측(rating predictions)에서 높은 효과를 보여주었고, 사용자의 의사결정 과정을 더 일관되게 반영함으로써 설명 가능성을 향상시켰음을 확인했습니다.



### Generative Retrieval with Preference Optimization for E-commerce Search (https://arxiv.org/abs/2407.19829)
- **What's New**: 이 논문은 E-commerce 검색 시나리오에서 문서 검색을 혁신적으로 개선하는 새로운 프레임워크인 '선호 최적화를 통한 생성적 검색'(generative retrieval with preference optimization)을 제안합니다. 이는 기존의 생성적 검색 방식이 가진 문제들을 해결하고자 합니다.

- **Technical Details**: 제안된 프레임워크는 대상 데이터에 맞춰 autoregressive 모델을 학습하고, 제약 기반의 빔 서치(constraint-based beam search)를 통해 최종 아이템을 생성합니다. 원본 아이템 제목(raw item titles)을 멀티스팬 식별자(multi-span identifiers)로 표현하고, 쿼리에서 제목을 생성하는 작업을 멀티스팬 식별자를 생성하는 작업으로 변경하여 생성 과정을 단순화합니다. 클릭 데이터(click data)를 활용해 인간의 선호에 맞추며, 제약된 검색 방법을 사용해 최종 아이템을 검색하는 주요 스팬을 식별해 결과의 해석 가능성을 향상시킵니다.

- **Performance Highlights**: 광범위한 실험을 통해 이 프레임워크가 실세계 데이터셋에서 경쟁력 있는 성능을 달성했음을 보여줍니다. 온라인 A/B 테스트에서도 이 프레임워크가 전환율 향상에 있어 우수하고 효과적임을 입증하였습니다.



### Adaptive Utilization of Cross-scenario Information for Multi-scenario Recommendation (https://arxiv.org/abs/2407.19727)
- **What's New**: 이 논문에서는 다양한 비즈니스 시나리오를 제공하는 e-commerce(전자 상거래) 플랫폼의 추천 시스템을 위한 새로운 모델 'Cross-Scenario Information Interaction (CSII)'을 제안합니다. 이 모델은 여러 시나리오를 섞어서 시나리오 중심의 전문가들을 통해 모든 시나리오를 효과적으로 처리할 수 있게 돕습니다.

- **Technical Details**: 제안된 CSII 모델에서는 데이터 인스턴스에서 highly transferable features(엄청나게 옮기기 쉬운 특징)을 선택하는 새로운 방법을 도입합니다. 그리고 attention-based aggregator module(주의 기반 집계 모듈)을 제안하여 각 시나리오로부터 상대적인 지식을 적응적으로 추출할 수 있게 합니다. 이 방법을 통해 시나리오 간 정보 상호작용을 최적화할 수 있습니다.

- **Performance Highlights**: 생산 데이터셋에 대한 실험 결과, CSII 모델의 우수성이 검증되었습니다. 또한 Meituan Waimai APP에서의 온라인 A/B 테스트는 평균 GMV(Gross Merchandise Value, 총 상품 거래액)을 1.0% 향상시키는 성능 향상을 보여주었습니다.



### High-Order Fusion Graph Contrastive Learning for Recommendation (https://arxiv.org/abs/2407.19692)
- **What's New**: 본 논문에서는 추천 시스템 분야에서 최근 주목받고 있는 자기지도학습(Self-Supervised Learning, SSL)을 분석하고, 고차원 융합 그래프 대조 학습(High-Order Fusion Graph Contrastive Learning, HFGCL) 프레임워크를 제안합니다. 기존의 데이터 증강(data augmentation) 기법을 배제하고, 그래프 컨볼루션 네트워크(GCN) 과정에서 생성된 고차원 정보를 활용하여 대조적 뷰를 만드는 것이 특징입니다.

- **Technical Details**: 주요한 기존 문제점을 해결하기 위해, HFGCL은 데이터 증강 대신 GCN의 고차원 정보를 사용하여 대조적 뷰를 생성합니다. 이와 더불어 여러 대조 학습(CL) 목적에서 나온 자기지도 신호를 통합하기 위해 진보된 대조 학습 목표를 제안합니다. 이는 대조적 뷰에서 비롯된 양긍정 쌍(positive pairs)을 음성 샘플(negative samples)로부터 멀리 거리두어 자기지도 신호를 효과적으로 융합하는 방식을 채택합니다.

- **Performance Highlights**: HFGCL의 성능은 세 가지 공공 데이터셋에서의 실험 결과를 통해 입증되었습니다. 이 결과는 HFGCL이 최신 기법들(state-of-the-art baselines)보다 더 우수한 성능을 보였음을 나타냅니다.



### GradCraft: Elevating Multi-task Recommendations through Holistic Gradient Crafting (https://arxiv.org/abs/2407.19682)
Comments:
          Accepted by KDD'24

- **What's New**: 새로운 논문에서는 추천 시스템(recommender systems)에서 다중 목표 최적화를 위해 필수적인 다중 작업 학습(multi-task learning) 방법론의 핵심 문제를 다룹니다. 기존 방법론은 추천 시나리오의 특정 특성을 간과하여 적절한 기울기 균형(gradient balance)을 달성하는 데 실패해왔습니다. 이를 해결하기 위해 GradCraft라는 혁신적인 방법론이 제안되었습니다.

- **Technical Details**: GradCraft는 기울기 크기(gradient magnitudes)를 최대 기울기 노름(maximum gradient norm)에 맞추어 동적으로 조정하여 초기의 간섭을 줄입니다. 이후, 모든 충돌 작업을 동시에 고려하여 기울기 방향(direction)에서의 갈등을 제거하기 위해 투영(projections) 방법을 사용합니다. 이를 통해 기울기 크기의 적절한 균형과 전역 방향 균형(global direction balance)을 이론적으로 보장합니다.

- **Performance Highlights**: GradCraft의 효율성은 오프라인 및 온라인 실험을 통해 입증되었습니다. 실험 결과, GradCraft는 추천 시스템에서 다중 작업 성능을 크게 향상시키는 것으로 나타났습니다.



### Enhancing CTR Prediction through Sequential Recommendation Pre-training: Introducing the SRP4CTR Framework (https://arxiv.org/abs/2407.19658)
- **What's New**: 사용자 관심사 이해는 클릭률(CTR) 예측에서 매우 중요합니다. 이번 논문에서는 사용자 행동 이력 데이터를 활용한 자가 지도 학습을 통해 사용자 동적 선호를 더 잘 이해할 수 있는 Sequential Recommendation Pre-training framework for CTR prediction (SRP4CTR)을 제안합니다. 이는 기존 방법들의 추가 추론 비용 문제를 해결하고 특정 항목에 대한 효율적인 정보 전이를 고려합니다.

- **Technical Details**: SRP4CTR는 순차 추천을 통해 CTR 예측 성능을 향상시키는 프레임워크입니다. 먼저 사전 훈련 모델을 도입하는 것이 추론 비용에 미치는 영향을 논의합니다. 이후 사전 훈련 방법을 사용하여 시퀀스 부가 정보(sequence side information)를 동시에 인코딩합니다. Fine-tuning 과정에서는 추정 항목과 사전 훈련 모델 사이에 저비용으로 연결을 구축하기 위해 Cross-Attention Block을 사용합니다. 또한, 질의 변환(querying transformer) 기술을 개발하여 사전 훈련 모델의 지식을 산업용 CTR 모델로 전이합니다.

- **Performance Highlights**: 오프라인 및 온라인 실험에서, SRP4CTR은 기존 기준 모델들보다 뛰어난 성능을 보였습니다.



### Interpretable Triplet Importance for Personalized Ranking (https://arxiv.org/abs/2407.19469)
Comments:
          Accepted by CIKM 2024

- **What's New**: 이번 연구에서는 추천 시스템의 중요한 요소인 개인화된 아이템 랭킹에 대한 새로운 접근법으로 'Triplet Shapley' 방법론을 제안하였습니다. 이 방법론은 사용자의 암묵적 피드백을 활용하여 트리플렛 (사용자, 긍정 아이템, 부정 아이템)을 구성하고, 각 트리플렛의 중요성을 해석 가능한 방식으로 평가하는 Shapley 값에 기반합니다.

- **Technical Details**: Shapley 값 계산이 많은 트리플렛 경우에 매우 비용이 많이 들기 때문에, Monte Carlo (MC) 근사법을 사용하여 Shapley 값을 변환하였습니다. MC 근사법의 안정성을 높이기 위해 control covariates 방법을 채택하였습니다. 최종적으로 중요한 트리플렛의 재샘플링을 통해 모델 학습을 향상시키는데 활용합니다.

- **Performance Highlights**: 클래식한 matrix factorization 모델과 graph neural network 기반 추천 모델을 포함한 6개의 공개 데이터셋에서 광범위한 실험을 수행하였습니다. 실험 결과, 제안한 모델이 최신 방법들보다 일관되게 우수한 성능을 발휘함을 확인하였습니다.



### Enhancing Taobao Display Advertising with Multimodal Representations: Challenges, Approaches and Insights (https://arxiv.org/abs/2407.19467)
Comments:
          Accepted at CIKM 2024

- **What's New**: 이번 연구에서는 다양한 형태의 데이터(multimodal data)를 활용하여 추천 시스템(recommendation systems)의 정확도를 향상시키는 방법을 탐구합니다. 특히 Taobao 디스플레이 광고 시스템과 같은 대규모 산업용 시스템에서는 기존에 주로 사용되던 희소 ID 특징(sparse ID features)에 의존하곤 했습니다. 우리는 이런 한계를 극복하고자, 두 단계의 프레임워크를 소개합니다: 1) 멀티모달 표현의 사전 훈련을 통해 의미적 유사성을 포착하고, 2) 이러한 표현을 기존의 ID 기반 모델에 통합하는 단계입니다.

- **Technical Details**: 이 연구에서는 멀티모달 데이터를 효과적이고 경제적으로 도입하기 위한 주요 도전 과제를 식별한 후, 두 단계의 프레임워크를 제안합니다. 첫째로, 멀티모달 표현을 사전 훈련(pre-training)하여 의미적 유사성을 캡처합니다. 둘째로, 사전 훈련된 멀티모달 표현을 기존의 ID 기반 모델에 통합합니다. 이러한 통합을 용이하게 하기 위해, 멀티모달 표현을 배포할 수 있는 프로덕션 시스템의 아키텍처를 상세히 기술하고 있습니다.

- **Performance Highlights**: 2023년 중반에 멀티모달 표현(multi-modal representations)을 통합한 이후, Taobao 디스플레이 광고 시스템의 성능이 크게 향상되었습니다. 이런 성과를 통해 얻은 인사이트가 멀티모달 데이터를 활용하려는 실무자들에게 귀중한 자원이 될 것이라고 믿습니다.



### MaTrRec: Uniting Mamba and Transformer for Sequential Recommendation (https://arxiv.org/abs/2407.19239)
- **What's New**: 이번에 발표된 논문은 새로운 sequential recommendation 시스템인 MaTrRec 모델을 소개합니다. MaTrRec 모델은 Mamba와 Transformer 모델의 장점을 결합하여, 사용자의 긴 상호 작용 시퀀스와 짧은 상호 작용 시퀀스 모두에서 효율적으로 동작하며 예측 성능을 향상시킵니다.

- **Technical Details**: MaTrRec 모델은 Mamba의 장기 의존성(long-term dependencies) 처리 장점과 트랜스포머(Transformer)의 짧은 기간 동안의 글로벌 어텐션(global attention) 장점을 결합한 혁신적인 모델입니다. 이 모델은 긴 상호작용 시퀀스 데이터를 다루면서도 선형 복잡도(linear complexity)를 유지하며, 또한 짧은 상호작용 데이터에서도 효율적으로 동작합니다.

- **Performance Highlights**: 실험 결과, MaTrRec 모델은 데이터 스파시티(data sparsity) 문제와 콜드 스타트(cold start) 문제를 33%까지 개선하였으며, 아마존 뮤지컬 악기(Amazon Musical Instruments) 데이터셋에서 매우 희소(sparse)한 상태에서도 좋은 성능을 보였습니다. 총 다섯 개의 공개 데이터셋에서 실험을 진행한 결과, 모든 데이터셋에서 현재 최첨단(sequential recommendation) 추천 모델보다 뛰어난 성능을 보였습니다.



### LitSearch: A Retrieval Benchmark for Scientific Literature Search (https://arxiv.org/abs/2407.18940)
Comments:
          Dataset and code available at this https URL

- **What's New**: 문헌 검색 질문, 예를 들어 '생성된 요약의 일관성 평가에 대한 연구를 어디에서 찾을 수 있을까?'와 같은 질문은 현대 검색 엔진과 정보 검색 시스템에 상당한 도전을 안겨줍니다. 이러한 질문들은 연구 개념에 대한 깊은 이해와 전체 기사를 논리적으로 해석하는 능력을 요구합니다. 이번 작업에서는 LitSearch라는 검색 벤치마크를 도입합니다. 여기에는 최근 머신러닝(ML) 및 자연어처리(NLP) 논문에 대한 597개의 현실적인 문헌 검색 쿼리가 포함되어 있습니다.

- **Technical Details**: LitSearch는 두 가지 요소로 구성되었습니다. (1) 연구 논문의 인라인 인용(citations)이 포함된 단락을 기반으로 GPT-4에 의해 생성된 질문들과 (2) 최근에 발표된 논문에 대한 저자가 직접 작성한 질문들이 포함됩니다. 모든 LitSearch 질문들은 전문가들에 의해 수동으로 검토되거나 편집되었습니다. 또한, 최첨단 검색 모델들을 광범위하게 벤치마크하고, 두 가지 LLM(대형 언어 모델) 기반 재랭킹(reranking) 파이프라인도 평가했습니다.

- **Performance Highlights**: BM25와 최첨단 밀집 검색기(dense retriever) 간의 성능 차이는 절대 recall@5에서 24.8%로 나타났습니다. LLM 기반 재랭킹 전략은 최고 성능의 밀집 검색기를 추가로 4.4% 향상시켰습니다. 또한, Google Search와 같은 상용 검색 엔진과 연구 도구는 LitSearch에서 최적의 밀집 검색기보다 32포인트 뒤처지는 것으로 확인되었습니다. 종합적으로, 이러한 결과는 LitSearch가 retrieval 시스템을 위한 정보 제공 측면에서 실질적으로 유용한 새로운 테스트베드임을 보여줍니다.



### Advancements in Recommender Systems: A Comprehensive Analysis Based on Data, Algorithms, and Evaluation (https://arxiv.org/abs/2407.18937)
Comments:
          24 pages, 10 figures, 3 tables

- **What's New**: 이번 연구는 다양한 데이터베이스에서 수집된 286개의 연구 논문을 통해 추천 시스템(RS)에 관한 현재의 도전 과제와 미래 발전 가능성을 체계적으로 검토하고 요약했습니다. RS는 알고리즘 개선, 도메인 응용, 사용자 행동 및 인지, 데이터 처리 및 모델링, 사회적 영향 및 윤리라는 다섯 가지 주요 연구 주제를 포함하고 있습니다.

- **Technical Details**: RS(Recommendation Systems)는 주로 Collaborative Filtering과 Hybrid Recommendation Techniques를 사용합니다. RS의 성능은 네 가지 유형의 데이터 문제, 두 가지 유형의 알고리즘 문제, 두 가지 평가 문제에 의해 제한됩니다. 데이터 관련 문제로는 콜드 스타트(Cold Start), 데이터 희소성(Data Sparsity), 데이터 중독(Data Poisoning)이 있으며, 알고리즘 문제로는 관심 드리프트(Interest Drift), 디바이스-클라우드 협업(Device-Cloud Collaboration), 비인과성(Non-causal Driven), 멀티태스크 충돌(Multitask Conflicts)가 있습니다. 평가 문제로는 오프라인 데이터 누출(Offline Data Leakage)과 다중 목표 균형(Multi-objective Balancing)이 있습니다.

- **Performance Highlights**: 제안된 솔루션으로는 생리적 신호를 결합한 멀티모달 모델링, 사용자 정보 행동을 통한 데이터 중독 방어, 사회적 실험을 통한 생성형 추천 평가, 디바이스-클라우드 리소스 스케줄링을 위한 사전 훈련된 대규모 모델의 미세 조정, 딥 강화 학습을 통한 인과 추론 강화, 확률 분포 기반 멀티태스크 모델 훈련, 교차 시간 데이터셋 분할, 수명 주기 전반에 걸친 추천 목표 평가 등이 있습니다.



### QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieva (https://arxiv.org/abs/2407.20207)
- **What's New**: Dense retrieval에서 장문 텍스트를 dense 벡터(dense vectors)로 임베딩하면 정보 손실이 발생하고, 이에 따라 쿼리-텍스트 매칭의 정확도가 떨어질 수 있습니다. 또한, 저질 텍스트는 과도한 노이즈나 희박한 주요 정보를 가지고 있는 경우가 많아 관련 쿼리와 잘 맞지 않습니다. 기존 연구들은 주로 문장 임베딩 모델(sentence embedding model)이나 검색 프로세스를 개선하는 데 초점을 맞추고 있습니다. 이에 반해, 본 연구는 dense retrieval을 위한 새로운 텍스트 증강 프레임워크를 소개합니다. 이 프레임워크는 원본 텍스트를 정보 밀도가 높은 텍스트 형식으로 변환하여, 임베딩이나 검색 방법론 자체를 수정하지 않고 앞서 언급한 문제를 효과적으로 해결합니다.

- **Technical Details**: 본 연구의 프레임워크는 대형 언어 모델(LLMs)으로부터 zero-shot(prompting) 방법을 통해 두 가지 텍스트 표현을 생성합니다: 질문-응답 쌍(question-answer pairs)과 요소 기반 이벤트(element-driven events). 이를 QAEA-DR로 명명하며, 텍스트 증강 프레임워크 내에서 질문-응답 생성 및 이벤트 추출을 통합합니다. 생성된 텍스트의 품질을 더욱 향상시키기 위해, LLM prompting에서 점수 기반 평가 및 재생성 메커니즘(scoring-based evaluation and regeneration mechanism)을 도입하였습니다.

- **Performance Highlights**: 이론적 분석과 실험적 경험 모두 QAEA-DR 모델이 dense retrieval에 긍정적인 영향을 미친다는 것을 지지합니다.



### Practical and Robust Safety Guarantees for Advanced Counterfactual Learning to Rank (https://arxiv.org/abs/2407.19943)
Comments:
          Full paper at CIKM 2024

- **What's New**: 최신 연구는 안전한 CLTR (Counterfactual learning to rank)을 확장하여 최신 doubly robust (DR) CLTR 및 신뢰 편향(trust bias)에 적용할 수 있도록 일반화하였습니다. 또한, 새로운 접근법인 PRPO (Proximal Ranking Policy Optimization)를 제안하여 사용자 행동에 대한 가정 없이 배포 시 안전성을 보장합니다.

- **Technical Details**: 기존의 안전한 CLTR 접근 방식은 inverse propensity scoring을 사용하여 위치 편향(position bias)을 교정하지만, 최신 DR CLTR 및 신뢰 편향에는 적용되지 않았습니다. 연구진은 이를 일반화하여 최신 기술과 신뢰 편향에 적용할 수 있게 하였으며, PRPO이라는 새로운 방법을 제안했습니다. PRPO는 안전한 모델과 너무 다른 학습 순위 행동을 제한하여 성능 메트릭의 감소를 방지합니다.

- **Performance Highlights**: 실험 결과, 새로운 안전한 doubly robust 방법과 PRPO는 기존의 안전한 inverse propensity scoring 방법보다 높은 성능을 제공하는 것으로 나타났습니다. 그러나 예상치 못한 상황에서는 안전한 doubly robust 접근법이 안전하지 않으며 성능을 저해할 수 있습니다. 이에 비해 PRPO는 최대의 적대적인 상황에서도 항상 안전성을 유지합니다. 따라서 PRPO는 무조건적인 안전성을 제공하는 첫 번째 방법으로, 실제 애플리케이션의 강력한 안전성을 의미합니다.



### Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models (https://arxiv.org/abs/2407.19914)
Comments:
          Accepted at the 29th International Conference on Information Society and University Studies (IVUS 2024)

- **What's New**: 이 연구는 기존 연구들과 달리 리투아니아어 리뷰의 감정 분석(Sentiment Analysis)에 Transformer 모델을 처음으로 도입하여 성능을 측정하였습니다. 특히 다국어 Large Language Models(LLMs)를 활용하여 BERT와 T5 모델을 미세 조정(Fine-tuning)했습니다. 연구 결과, 상업적으로 이용 가능한 최신 GPT-4 모델을 뛰어넘는 성과를 보였습니다.

- **Technical Details**: 연구팀은 다섯 개의 별점으로 구성된 다양한 리투아니아어 온라인 리뷰 데이터를 수집하고 이를 정제(clean)하는 작업을 수행하였습니다. 수집된 데이터를 바탕으로 BERT와 T5 모델을 미세 조정하여 감정 분석을 수행했습니다. 이 방법은 전통적인 기계 학습 및 분류 알고리즘 대비 높은 효과를 보였습니다.

- **Performance Highlights**: 미세 조정된 모델들은 특히 덜 모호한 감정 분석에서 뛰어난 성능을 보였습니다. 가장 인기 있는 1성과 5성 리뷰에 대해 각각 80.74%와 89.61%의 테스트 인식 정확도를 기록했습니다. 이는 현재 상업적인 최첨단 다목적 LLM인 GPT-4를 대폭 초과하는 성과입니다. 이러한 성능 개선 모델들은 온라인에서 공개적으로 제공되었습니다.



### Analyzing and reducing the synthetic-to-real transfer gap in Music Information Retrieval: the task of automatic drum transcription (https://arxiv.org/abs/2407.19823)
Comments:
          21 pages, 4 figures

- **What's New**: 이 논문에서는 Music Information Retrieval(MIR)에서 리듬을 추출하고 분석하는 중요한 도구로 사용되는 자동 드럼 전사(automatic drum transcription)에 대해 다룹니다. 특히, 데이터셋의 규모가 제한적인 문제를 해결하기 위해 새로운 접근법을 제시합니다. 저자들은 기존에 사용되던 가상 악기로 생성된 합성 데이터(synthetic data)만으로는 실제 음악 트랙(real tracks)으로의 일반화가 잘 안된다는 점을 지적합니다.

- **Technical Details**: 연구팀은 데이터를 증가시키는 것 외에도 생성된 데이터를 실제에 더 가깝게 만드는 세 가지 전략을 사용하여 새로운 합성 데이터셋을 구축했습니다. 이들 전략의 효과를 평가하기 위해 다양한 데이터셋을 사용하는 모델의 성능을 측정하였으며, 훈련 데이터 트랙 수가 증가함에 따라 성능이 언제 정체(stagnate)되는지를 조사했습니다.

- **Performance Highlights**: 그 결과, 제안된 전략들이 데이터의 현실성을 증가시키고, 기존의 합성 데이터셋 중에서 가장 낮은 synthetic-to-real transfer gap을 가진 데이터셋을 만들 수 있다는 것을 증명했습니다. 또한, 드럼 전사에서 무한 데이터로 훈련하는 것의 한계를 지적하며, 이를 극복할 수 있는 방법을 제시하였습니다.



### Image-text matching for large-scale book collections (https://arxiv.org/abs/2407.19812)
- **What's New**: 이 논문은 이미지 컬렉션에 있는 모든 책들을 주어진 도서 카탈로그 항목과 매핑하는 문제를 다루고 있습니다. 독립적인 검색 대신 이미지-텍스트 매핑 문제를 다대다(many-to-many) 매칭 프로세스로 간주하여 두 개의 셋 간의 최적의 매칭을 찾습니다.

- **Technical Details**: 책의 척추를 감지하는 최신 세분화 방법(SAM)을 사용하여 상업용 광학 문자 인식(OCR)을 통해 책 정보를 추출합니다. 그런 다음 CLIP 임베딩(embeddings)을 사용하여 처음 빠른 매칭을 수행하고, Hungarian Algorithm 또는 BERT 기반 모델을 사용하여 매칭을 개선하는 2단계 접근법을 제안합니다. 이 모델은 잡음이 있는 OCR 입력과 부분적인 텍스트 매칭에 대처하도록 훈련되었습니다.

- **Performance Highlights**: 스페인의 한 공공 도서관 전체 책 컬렉션을 포함하는 주석이 달린 새로운 책장 이미지 데이터셋을 게시하고, 두 가지의 책 메타데이터 타겟 리스트 (폐쇄 집합의 15,000과 개방 집합의 2.3백만)를 제공합니다. 두 가지 설정에서 성능을 평가하며, Hungarian Matching과 제안된 BERT 기반 모델은 퍼지 문자열 매칭 대비 더 나은 성능을 보였습니다. 타겟 목록이 커질 때와 검출된 책이나 타겟 책 목록이 불완전할 때 매칭 알고리즘의 한계를 강조합니다.



### mGTE: Generalized Long-Context Text Representation and Reranking Models for Multilingual Text Retrieva (https://arxiv.org/abs/2407.19669)
Comments:
          20 pages, 5 figures

- **What's New**: 우리는 처음으로 긴 문맥(멀티런구문맥, long-context) 다국어 텍스트 표현 모델(Text Representation Model, TRM)과 재순위기(reranker)를 제롬 구축했습니다. 이 모델은 이전의 다국어 인코더보다 긴 8192-토큰 문맥에서 학습되었습니다.

- **Technical Details**: 새로운 텍스트 인코더(text encoder)는 RoPE와 unpadding 기법이 적용되어 원본 토큰 문맥을 8192개로 확장하였습니다. 하이브리드 TRM 및 교차 인코더 재순위기(cross-encoder reranker)는 대조 학습(contrastive learning)을 통해 구축되었습니다.

- **Performance Highlights**: 새로 제안된 텍스트 인코더는 기존의 같은 크기의 최첨단 XLM-R보다 뛰어난 성능을 보였습니다. 또한, 우리의 TRM과 재순위기는 대형 슈퍼모델인 BGE-M3와 맞먹는 성능을 자랑하면서도 긴 문맥 검색 벤치마크에서 더 나은 결과를 달성했습니다. 추가 분석 결과, 제안된 모델들은 학습 및 추론 시 높은 효율성을 나타냈습니다.



### Sponsored is the New Organic: Implications of Sponsored Results on Quality of Search Results in the Amazon Marketplac (https://arxiv.org/abs/2407.19099)
Comments:
          This work has been accepted as a full paper in AAAI/ACM conference on Artificial Intelligence, Ethics and Society (AIES) 2024

- **What's New**: 이 연구는 여러 디지털 플랫폼에서 검색 엔진 결과 페이지(SERP)에서 유기적(organic) 결과 사이에 스폰서 광고(sponsored results)를 배치하는 관행에 대해 다루고 있습니다. 특히, Amazon 디지털 마켓플레이스에서 4,800개의 검색 조작을 시뮬레이션하여 조사했습니다.

- **Technical Details**: 연구진은 Amazon SERP에서 총 200만 개의 유기적 결과와 63만8천 개의 스폰서 결과를 분석했습니다. 그 결과, 100위 이후의 유기적 순위를 가진 항목들이 첫 페이지 유기적 결과보다 먼저 스폰서 결과로 나타나는 경향을 발견했습니다.

- **Performance Highlights**: 대부분의 스폰서 결과가 유기적 결과보다 가격이 더 비싸고 품질이 낮은 경우가 많았습니다. 이러한 관찰 결과는 연구자들에게 디지털 마켓플레이스의 광고 관행에 더 많은 투명성과 가드레일(guard rails)을 도입하기 위한 추가 논의를 촉진할 수 있을 것입니다.



### MetaHive: A Cache-Optimized Metadata Management for Heterogeneous Key-Value Stores (https://arxiv.org/abs/2407.19090)
Comments:
          Cloud Databases

- **What's New**: MetaHive라는 새로운 메타데이터 관리 방법론이 소개되었습니다. MetaHive는 이기종 클라우드 키-값(Key-Value) 저장소 클러스터에서 메타데이터를 효율적으로 관리할 수 있게 설계되었습니다.

- **Technical Details**: MetaHive는 원본 데이터와 관련된 메타데이터를 분리하여 독립성을 유지하면서도 사용 시 이들 간의 연계성을 유지합니다. 이는 메타데이터를 하위 프로세스와 다른 키-값 저장소에서 불투명하게 만듭니다. 또한, MetaHive는 메타데이터 항목과 키-값 항목을 메모리 및 저장소에 가깝게 저장하여 캐싱 메커니즘을 최적화하고 메타데이터 검색을 위한 추가 저장소 읽기 오버헤드를 줄입니다.

- **Performance Highlights**: MetaHive는 RocksDB에 배포되어 데이터 무결성을 보장하며, 성능에 미치는 영향을 최소화하면서도 빠른 데이터 검증을 실행하는 것을 보여주었습니다.



New uploads on arXiv(cs.CV)

### NOLO: Navigate Only Look Onc (https://arxiv.org/abs/2408.01384)
- **What's New**: 이번 논문에서는 Transformer 모델의 in-context learning 능력을 이용하여 비디오 내비게이션(video navigation)을 구현하는 새로운 방법을 제안했습니다. NOLO(Navigate Only Look Once)는 오로지 비디오만으로 오프라인 환경에서 새 장면에 적응할 수 있는 내비게이션 정책을 학습합니다. 이는 실제 환경에 접근하지 않고도 학습이 가능하며, 새로운 방의 비디오를 입력으로 받으면 추가적인 미세 조정(fine-tuning)이나 재학습 없이도 적응할 수 있습니다.

- **Technical Details**: 비디오에서의 학습을 가능하게 하기 위해, optical flow를 사용하여 자가 행위 레이블링(pseudo action labeling) 절차를 통해 egocentric 비디오로부터 행동 레이블을 복구합니다. 이후 오프라인 강화 학습을 통해 내비게이션 정책을 학습합니다. NOLO는 영상 내비게이션 문제를 해결하기 위해 optical flow와 오프라인 강화 학습을 통합하여, 조건이 부여된 비디오를 통해 일반화 가능한 내비게이션 정책을 학습합니다.

- **Performance Highlights**: RoboTHOR와 Habitat에서의 실험을 통해 NOLO의 효과를 검증하였습니다. 특히 각 장면에서 단 30초간의 비디오 클립을 보고도 높은 성능을 나타냈습니다. 이는 기존의 방법들과 비교하여 상당한 성능 향상을 보였으며, 추가적인 미세 조정이나 재학습이 필요 없는 NOLO의 in-context 학습 능력을 보여줍니다.



### Spatial-Spectral Morphological Mamba for Hyperspectral Image Classification (https://arxiv.org/abs/2408.01372)
- **What's New**: 이번 논문에서는 Spatial-Spectral Morphological Mamba (MorpMamba) 모델을 도입함으로써 Hyperspectral Image Classification (HSIC)을 위한 더 효율적인 솔루션을 제안하고 있습니다. 기존 Transformer 모델들의 계산 복잡도 문제를 극복하고자, MorpMamba는 State Space Model (SSM)을 활용하여 기하급수적인 계산 효율성을 강화합니다. 모델은 최신 형태학적 연산을 도입하여 토큰 생성, 특성 강화, 다중 헤드 자기-자각 블록을 통해 공간적 및 스펙트럼 정보를 통합합니다.

- **Technical Details**: MorpMamba 모델은 Hyperspectral Image (HSI) 패치를 공간-스펙트럼 토큰으로 변환하는 토큰 생성 모듈로 시작합니다. 이후 형태학적 블록(Morphological Block)을 통해 범주와 모양 정보를 깊이분리합성 컨볼루션 연산으로 계산합니다. 추출된 정보는 특성 강화 모듈에서 강화되며, 다중 헤드 자기-자각(Multi-head Self-Attention) 블록을 통해 더 나은 특성 공간으로 정제됩니다. 마지막으로 결합된 정보는 상태 공간 블록에 전달되어 분류 및 Ground Truth 지도 생성을 수행합니다.

- **Performance Highlights**: 실험 결과, MorpMamba 모델은 CNN과 Transformer 모델들 대비 우수한 성능을 보였습니다. 특히, 공간적-스펙트럼 토큰 생성 및 형태학적 연산을 통한 특성 강화는 분류 정확도를 높이는 데 크게 기여하였습니다. 따라서 MorpMamba는 계산 자원 효율성과 성능 측면에서 강력한 장점을 제공합니다.



### EVIT: Event-based Visual-Inertial Tracking in Semi-Dense Maps Using Windowed Nonlinear Optimization (https://arxiv.org/abs/2408.01370)
Comments:
          8 pages, 5 figures, 3 tables, International Conference on Intelligent Robots and Systems 2024

- **What's New**: 이번 연구에서는 최근에 제안된 이벤트 기반 기하학적 준밀도 추적 패러다임(event-based geometric semi-dense tracking paradigm)에 관성 신호(Inertial Measurement Unit, IMU)를 추가하여 추정의 안정성을 높이는 새로운 방법을 제안합니다. IMU의 추가로 포즈 초기화와 다중 프레임 추적 동안의 정규화를 강화하여 어려운 조명 조건에서도 성능을 향상시키며, 고동적인 시퀀스에서도 안정적인 추적을 유지할 수 있도록 이벤트 표현의 등록률을 줄일 수 있습니다.

- **Technical Details**: 이벤트 카메라(Event Cameras)는 전통적인 카메라와 달리 밝기 변화에 반응하는 센서로, 고동적이고 조명이 어려운 조건에서도 강력한 성능을 발휘합니다. 본 연구는 IMU와 결합하여 다중 프레임을 윈도우 방식으로 추적하는 접근 방식을 사용합니다. 각 프레임의 추적치는 1차 변환 속도와 IMU 바이어스 항목을 포함하도록 하며, IMU 사전 통합 항목을 사용하여 인접한 프레임을 정규화합니다.

- **Performance Highlights**: 제안된 프레임워크(Event-based Visual-Inertial Tracking, EVIT)는 다양한 실제 시퀀스를 평가하여 기존의 이벤트 기반 대안보다 추적 성능 면에서 IMU의 추가가 크게 지원됨을 보였습니다. 특히 조명이 변하는 상황과 고동적 움직임 조건에서도 성능이 개선되었습니다.



### Balanced Residual Distillation Learning for 3D Point Cloud Class-Incremental Semantic Segmentation (https://arxiv.org/abs/2408.01356)
- **What's New**: 본 논문에서는 클래스 증분 학습(Class-incremental learning, CIL)의 성능을 대폭 향상시키기 위해 새로운 균형 잔차 증류 프레임워크(balanced residual distillation framework, BRD-CIL)를 제안합니다. BRD-CIL은 3D 포인트 클라우드 세맨틱 세그멘테이션(semantic segmentation)에서 과거 지식을 효과적으로 정제하고 새로운 학습과 균형을 맞추도록 설계되었습니다. 특히, 본 연구는 네트워크 구조를 동적으로 확장해 기본 모델과 타겟 모델 간의 잔차를 포착하고, 가이던스 마스크(guidance mask)를 통해 기존 클래스에 대한 선호도를 줄입니다.

- **Technical Details**: BRD-CIL은 두 가지 핵심 전략을 포함합니다: 첫째, 잔차 증류 학습 전략(residual distillation learning, RDL)을 통해 기본과 목표 모델 간의 잔차를 학습하여 기존 지식을 정제합니다. 이 전략은 모델이 새로운 데이터의 특정 특성에 따라 파라미터를 선택적으로 업데이트 할 수 있게 해줍니다. 둘째, 균형 가짜 레이블 학습 전략(balanced pseudo-label learning, BPL)은 신규 및 기존 클래스 간의 기여를 균형있게 맞추는 가이던스 마스크를 생성하여 모델의 기본 클래스에 대한 선호도를 줄입니다. 또한 구조적 재변형(structural reparameterization)을 도입하여 장기적인 학습을 지원합니다.

- **Performance Highlights**: 광범위한 실험 결과, BRD-CIL이 3D 포인트 클라우드 세맨틱 세그멘테이션에서 기존 방법보다 뛰어난 균형 능력(balance capability)을 갖추고 있음을 보여주었습니다. 이 프레임워크는 클래스 편중(class-biased) 시나리오에서 새로운 벤치마크를 설정하였습니다.



### Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models within Perturbed Inputs (https://arxiv.org/abs/2408.01355)
Comments:
          Acccepted by ACM MM 2024, 14 pages, 11 figures, 9 tables

- **What's New**: 최근 연구는 Multi-modal Large Language Models (MLLMs)에서 발생하는 '환각(hallucination)' 문제 해결을 위한 새로운 벤치마크인 Hallu-PI를 제안합니다. 이 벤치마크는 7가지 변형된 입력 상황(perturbed inputs)에서 MLLM의 환각을 평가하기 위해 설계되었습니다. 기존 연구는 주로 변형되지 않은 표준 데이터를 사용했지만, 현실 세계에서는 이미지 크롭, 블러링 등 다양한 변형이 빈번하게 발생합니다. 이 점을 고려하여 Hallu-PI는 1,260개의 변형된 이미지와 11개의 객체 유형을 포함하고 있으며, 이미지의 존재, 속성, 관계에 대한 상세한 주석을 담고 있습니다.

- **Technical Details**: Hallu-PI는 노이즈, 블러, 날씨, 디지털 등 네 가지 주요 이미지 변형 유형에 따라 이미지를 분류하고, 이미지 연결, 이미지 크롭, 프롬프트 오류 등 추가적인 세 가지 변형을 제안합니다. 이러한 변형에 대해 주석을 제공하며, 다양한 질문 세트를 통해 분별적(discriminative) 및 생성적(generative) 작업 모두에서 사용할 수 있습니다. 또한, 12개의 주요 MLLMs, 예를 들어 GPT-4V와 Gemini-Pro Vision, 에서 실험한 결과, 변형된 시나리오에서 MLLMs가 상당한 환각을 보이는 것을 확인했습니다.

- **Performance Highlights**: 실험 결과, 변형된 입력 상황에서 GPT-4V와 같은 주요 MLLMs가 매우 높은 환각 현상을 보였습니다. 특히, 이미지 연결, 이미지 크롭, 프롬프트 오류와 같은 특정 변형에 대해 큰 편향을 나타냈습니다. 이러한 문제를 완화하기 위해, 변형-리마인더(Perturbed-Reminder)와 변형-ICL(Perturbed-ICL)이라는 두 가지 기준선을 도입했으며, 이는 GPT-4V에서 환각 현상을 감소시키는 데 효과적임을 입증했습니다.



### StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal Semantic Segmentation (https://arxiv.org/abs/2408.01343)
- **What's New**: 논문은 복잡한 장면에서의 세그멘테이션 정확도를 높이기 위해 'StitchFusion'이라는 새로운 멀티모달(seamantic segmentation) 기반의 기능 융합 프레임워크를 제안합니다. 이 시스템은 대규모 사전 학습된 모델을 인코더 및 기능 융합기로 직접 통합합니다. 인코딩 중 여러 모달 시각 정보를 공유함으로써 모달 통합을 구현하고, MultiAdapter라는 다중 방향 어댑터 모듈을 소개하여 인코딩 중 정보 교환을 가능하게 합니다.

- **Technical Details**: StitchFusion은 사전 학습된 대규모 모델을 인코딩 및 피쳐 융합기에 통합하여 모달 융합을 수행하는 프레임워크입니다. MultiAdapter라는 다중 방향 어댑터 모듈을 제안하여 모달 간 정보 전송을 가능하게 합니다. 이를 통해 인코딩 중에 멀티모달 시각 정보 통합을 실현하며, 적은 수의 추가 매개변수로 크로스 모달 융합을 달성합니다.

- **Performance Highlights**: 네 가지 멀티모달 세그멘테이션 데이터셋에서 광범위한 비교 실험을 통해 StitchFusion 모델은 기존 최첨단 성능을 달성했으며, 추가 매개변수가 최소화되었습니다. 또한, MultiAdapter가 기존 Feature Fusion Modules(FFMs)와 결합될 때 상보성이 강조되었습니다.



### A Robotics-Inspired Scanpath Model Reveals the Importance of Uncertainty and Semantic Object Cues for Gaze Guidance in Dynamic Scenes (https://arxiv.org/abs/2408.01322)
Comments:
          35+16 pages, 8+4 figures

- **What's New**: 본 논문은 동적 실제 장면들에 대한 인간의 시선 추적 행동과 객체 분할을 상호 의존적인 과정으로 취급하는 기계적 모델을 제시합니다. 이 모델은 현재 장면의 분할을 통해 객체 기반의 각기 이동 결정을 내리면서 중심화된(foveated) 객체를 재귀적으로 장면 분할을 정제하는 방식으로 작동합니다. 이는 로보틱스에서 정보 처리 패턴을 차용하여 구현되었습니다.

- **Technical Details**: 제안된 모델은 베이지안 필터(Bayesian filter)를 사용하여 장면 분할의 불확실성을 추정하고 이는 능동적 장면 탐색을 유도하는데 사용됩니다. 모델은 시선 선택과 장면의 분할이 불확실성에 의해 적극적 상호 연결되도록 하며, 고해상도 의미론적 분할을 통해 각기 위치에서 객체 정보를 최신으로 업데이트합니다. 이는 '반복 억제(inhibition of return)' 메커니즘 없이 인간의 자연스런 시각 탐사를 재현합니다.

- **Performance Highlights**: 모델의 성능은 시선 경로 통계(scanpath statistics)와 같은 고차원 통계를 사용하여 인간의 자유 시각 행동을 밀접하게 모방합니다. 광범위한 시뮬레이션과 초반 테스트는 불확실성이 탐색의 균형을 촉진하고 의미론적 객체 단서가 객체 기반 주의(attention)에서 중요한 역할을 한다는 것을 보여줍니다. 추가적으로 사카디 모멘텀(saccadic momentum)이나 사카드 이전 주의(pre-saccadic attention)를 포함할 수 있는 모듈 설계를 갖추고 있어 인간의 시각 경로와 더욱 일치되도록 확장이 가능합니다.



### TopoNAS: Boosting Search Efficiency of Gradient-based NAS via Topological Simplification (https://arxiv.org/abs/2408.01311)
- **What's New**: 최신 Neural Architecture Search (NAS) 기술은 검색 효율성을 크게 향상시키기 위해 'TopoNAS' 라는 모델에 구애받지 않는 새로운 접근 방식을 제안했습니다. 이 방법은 검색 가능한 경로의 위상적 단순화를 통해 검색 시간과 메모리 사용량을 크게 줄여줍니다.

- **Technical Details**: TopoNAS는 검색 공간에서 비선형성을 모델링하여 매개변수화의 어려움을 드러내고, 모듈 공유 전략을 사용하여 검색 가능한 경로의 위상 구조를 단순화합니다. 또한, 검색 정확성을 유지하기 위해 커널 정규화(kernal normalization) 기법을 제안합니다.

- **Performance Highlights**: NASBench201 벤치마크의 다양한 검색 공간에서 실험한 결과, TopoNAS는 검색 효율성을 크게 향상시키면서 높은 수준의 검색 정확도를 유지함을 입증했습니다. 특히, DARTS(Differentiable Architecture Search) 시리즈 아키텍처에서 9.1% 이상의 IN-16 정확도 향상과 검색 비용 감소를 달성했습니다.



### Underwater Object Detection Enhancement via Channel Stabilization (https://arxiv.org/abs/2408.01293)
- **What's New**: 이 연구는 해양 쓰레기를 탐지하기 위해 이미지를 향상시키고 탐지 방법을 평가하는 데 중점을 두고 있습니다. Detectron2를 기반으로 다양한 모델 및 설정을 사용하여 이 작업을 수행하며, 새로운 채널 안정화 기술을 제안하여 연무(haze)와 색깔 간섭을 감소시키는 이미지 향상 모델을 활용하고 다중 스케일 객체 탐지를 개선합니다. 새롭게 제안된 방법은 TrashCan Dataset에서 테스트 되었으며, 성능 향상 결과를 보여줍니다.

- **Technical Details**: 입력 이미지를 LAB 스트레칭과 글로벌 스트레칭을 이용해 사전 처리한 후 채널 안정화 모듈을 사용하여 이미지의 특정 컬러 지배력을 줄입니다. 또한 날카롭게 하는 필터를 적용하여 객체의 프로필을 강조합니다. 다양한 Detectron2 백본 모델을 테스트한 결과 저조도 및 얕은 수역에서 RetinaNet이 최고의 성능을 발휘했습니다. 개별 실험과 비교를 통해 최고의 모델을 찾아내는 과정이 포함되어 있습니다.

- **Performance Highlights**: TrashCan 1.0 Dataset의 인스턴스 버전에서 우리의 방법은 작은 객체에 대한 평균 정밀도에서 9.53%의 절대 증가와 바운딩 박스 탐지에서 7%의 절대 이득을 기록했습니다. 이는 기존 방법에 비해 큰 성능 향상을 보여줍니다.



### TexGen: Text-Guided 3D Texture Generation with Multi-view Sampling and Resampling (https://arxiv.org/abs/2408.01291)
Comments:
          European Conference on Computer Vision (ECCV) 2024

- **What's New**: TexGen은 기존의 2D 텍스트-이미지 생성 모델을 활용하여 3D 메쉬(mesh)에 고품질 텍스처를 생성하는 새로운 프레임워크입니다. 이 모델은 다중-뷰 샘플링 및 재샘플링 전략을 통해 텍스처 일관성을 보장합니다.

- **Technical Details**: TexGen은 기존 텍스트-이미지(diffusion model) 모델을 활용하여 다중-뷰에서의 샘플링 및 재샘플링을 수행합니다. 각 샘플링 단계마다 denoising 절차를 통해 점점 더 많은 텍스처 세부사항을 밝혀내고, 주의-가이드(attention-guided) 다중-뷰 샘플링을 이용하여 뷰 일관성을 유지합니다. 텍스트 및 텍스처 가이드 재샘플링 기법도 도입하여 잡음 추정 및 텍스처 디테일을 향상시킵니다.

- **Performance Highlights**: TexGen은 다양한 3D 객체에 대해 높은 뷰 일관성과 풍부한 외관 세부 사항을 가진 텍스처를 생성하며, 현재의 최첨단 방법들을 능가하는 성능을 보였습니다. 또한, TexGen 프레임워크는 텍스트 기반 텍스처 편집에도 자연스럽게 적용될 수 있습니다.



### Wave-Mamba: Wavelet State Space Model for Ultra-High-Definition Low-Light Image Enhancemen (https://arxiv.org/abs/2408.01276)
Comments:
          10 pages, 8 figures, ACMMM2024 accepted

- **What's New**: 이번 연구에서는 UHD 화질의 저조도 이미지 개선(LLIE) 작업을 위한 Wave-Mamba라는 새로운 방법을 제안합니다. 기존 UHD LLIE 방법은 계산 비용을 줄이기 위해 고배율 다운샘플링을 사용하지만, 이는 정보 손실을 초래합니다. 이에 반해, Wave-Mamba는 웨이블릿 변환을 사용하여 다운샘플링 시 정보 손실을 방지하고 이미지 내용을 노이즈로부터 분리해 효과를 높입니다.

- **Technical Details**: Wave-Mamba는 두 가지 주요 블록으로 구성되어 있습니다. 첫 번째는 'Low-Frequency State Space Block (LFSSBlock)'으로, 저주파수 성분의 정보를 복원하는데 주력합니다. 두 번째는 'High-Frequency Enhance Block (HFEBlock)'으로, 저주파수 정보를 활용하여 고주파수 성분을 보정하고 세부 사항을 정확히 복원합니다. 이 두 블록을 결합함으로써 높은 계산 복잡도를 가질 필요 없이 우수한 성능을 보여줍니다. 잘 알려진 State Space Models (SSMs)과 웨이블릿 변환을 결합하여, 저조도 이미지에서의 복잡한 노이즈에도 더욱 견고하게 대응합니다.

- **Performance Highlights**: Wave-Mamba는 현재 선두적인 기술들을 능가하는 뛰어난 성능을 입증하였으며, 더 간소화된 아키텍처를 유지합니다. 웨이블릿 변환을 통해 정보 손실 없이 효과적으로 저조도 이미지를 향상시키며, 구조적으로 효율적인 방법으로 저주파수와 고주파수 성분을 각각 처리합니다.



### A General Framework to Boost 3D GS Initialization for Text-to-3D Generation by Lexical Richness (https://arxiv.org/abs/2408.01269)
- **What's New**: 최근 텍스트-3D 콘텐츠 생성이 많은 주목을 받고 있으며, 그 중에서도 3D Gaussians Splatting(3D GS)에 관한 연구가 활발히 진행되고 있습니다. 본 논문에서는 기존의 초기화 단계와 렌더링 최적화 단계로 구성된 GS 기반 방법들의 한계를 극복하기 위해, 더 복잡한 텍스트를 처리할 수 있는 새로운 초기화 프레임워크를 제안합니다.

- **Technical Details**: 이 프레임워크는 복잡한 모양을 표현하기 위해 3D Gaussians를 공간적으로 균일한 복셀(voxel)에 집계하는 방식을 채택합니다. 각 복셀은 위치, 크기, 회전이 고정된 3D Gaussian을 포함하며, 투명도(opacity)만이 위치 점유도를 결정합니다. 초기화 네트워크는 주로 두 가지 요소로 구성됩니다: 1) Global Information Perception(GIP) 블록, 2) Gaussians-Text Fusion(GTF) 블록. GIP 블록은 공간적 정보를 전역적으로 상호작용하게 하며, GTF 블록은 교차 주의 메커니즘을 통해 각 3D Gaussian을 보다 관련 있는 단어에 연결하여 의미 있는 특징 융합을 지원합니다.

- **Performance Highlights**: 다양한 실험 결과, 제안된 프레임워크가 단순, 중간, 복잡한 텍스트 입력 모두에 대해 기존 방법들, 예컨대 Shap-E나 LucidDreamer보다 더 높은 질의 3D GS 초기화를 달성했음을 입증하였습니다. 또한 본 프레임워크는 SoTA 훈련 프레임워크와 원활하게 통합될 수 있습니다.



### CLIP4Sketch: Enhancing Sketch to Mugshot Matching through Dataset Augmentation using Diffusion Models (https://arxiv.org/abs/2408.01233)
- **What's New**: 새로운 연구 CLIP4Sketch에서는 특히 질 높은 스케치 이미지를 다수 생성하여 스케치와 얼굴 사진간 매칭 성능을 향상시키는 방법을 제안합니다. 이를 위해 Denoising Diffusion Probabilistic Models (DDPMs)을 활용하여 신원과 스타일에 대한 명확한 제어가 가능한 스케치를 생성합니다. 이 방법은 텍스트 설명 및 Adaface 임베딩을 조건으로 사용하여 고품질 스케치를 생성합니다.

- **Technical Details**: CLIP4Sketch는 CLIP 및 AdaFace 임베딩을 참조 얼굴 사진의 조건으로 사용하여, 텍스트 설명을 통해 스타일을 제어하고, 노이즈를 점진적으로 감소시키는 diffusion 모델을 사용합니다. 이는 다수의 공개된 스케치 데이터셋을 통합하고, ControlNet을 포함하여 신원을 유지하면서도 스타일 변화를 가능하게 합니다. CLIP 인코더와 Adaface 임베딩의 강력한 특징 추출 능력을 결합하여 다양한 스케치와 얼굴 사진 쌍을 생성합니다.

- **Performance Highlights**: CLIP4Sketch를 통해 생성된 합성 데이터셋으로 AdaFace 모델을 미세조정한 결과, 스케치-얼굴 사진 매칭 정확도가 크게 향상되었습니다. 기존의 제한된 현실 스케치 데이터에 비해 성능이 현저하게 향상되었으며, GAN 기반 데이터셋과 비교했을 때 CLIP4Sketch로 생성된 데이터셋이 더 우수함을 확인하였습니다.



### WaveMamba: Spatial-Spectral Wavelet Mamba for Hyperspectral Image Classification (https://arxiv.org/abs/2408.01231)
- **What's New**: 이번 논문에서는 Wavelet 변환과 Spatial-Spectral Mamba 아키텍처를 통합한 새로운 접근 방식인 WaveMamba를 소개합니다. WaveMamba는 Hyperspectral Imaging Classification(HSIC)에서 지역 텍스처 패턴과 전역 맥락 관계를 모두 캡처하여 단일 모델에서 효율적이고 효과적으로 학습합니다. 실험 결과, WaveMamba는 기존 모델을 능가하며 University of Houston 데이터셋에서는 정확도가 4.5% 향상되고 Pavia University 데이터셋에서는 2.0% 증가한 성과를 보였습니다.

- **Technical Details**: WaveMamba는 파형 기반의 향상된 features를 State-Space 아키텍처를 통해 처리하여 공간-스펙트럼 관계와 시간적 종속성을 모델링합니다. 이 모델은 파형 변환을 통해 다중 해상도 분석을 활용하며, 공간-스펙트럼 특성 추출을 최적화합니다. 이는 Mamba 아키텍처와 결합하여 데이터의 지역 및 전역 관계를 동시에 캡처할 수 있습니다. 모델은 중첩된 3D 패치를 사용하여 세밀한 지역 특성을 추출하고, 완전 연결된 dense 층과 비선형 활성화 층을 통해 게이트 메커니즘을 적용하여 공간 및 스펙트럴 토큰을 정제합니다.

- **Performance Highlights**: WaveMamba는 기존의 딥러닝(Deep Learning, DL), Transformer, 그리고 Mamba 방법들에 비해 향상된 정확도를 달성했습니다. 특히 University of Houston 데이터셋에서 4.5%의 정확도 향상, Pavia University 데이터셋에서 2.0%의 성과 향상이 있었습니다. 이는 WaveMamba가 HSI 데이터 내의 복잡한 상호 작용을 효과적으로 처리할 수 있음을 입증하는 결과입니다.



### The Phantom Menace: Unmasking Privacy Leakages in Vision-Language Models (https://arxiv.org/abs/2408.01228)
- **What's New**: 이번 연구는 Vision-Language Models (VLMs)이 신원 정보를 누출하는지 평가하고, 이를 방지하기 위한 효과적인 기법이 필요한 지 여부를 조사하였다. 특히, 신원 정보 누출(Identity Leakage)이 비식별화된 데이터로도 발생하며 일반적인 비식별화 기법이 이를 완전히 막을 수 없다는 점을 발견하였다.

- **Technical Details**: Vision-Language Models (VLMs)은 시각적 및 텍스트 정보를 결합하여 다양한 작업을 수행한다. 이 모델들은 웹에서 크롤링된 많은 양의 데이터로 훈련되며, 이는 종종 비식별화되지 않은 민감한 정보를 포함할 수 있다. 연구팀은 5개의 널리 사용되는 VLMs인 BLIP-2flan-t5-xl, BLIP-2opt, LLaVA-1.57B, LLaVA-1.6mixtral-7B, PaliGemma3b-mix-224을 조사하여 신원 정보 누출 여부를 평가하였다.

- **Performance Highlights**: 비식별화된 데이터로 훈련된 경우에도 VLMs이 신원 정보를 누출할 수 있으며, 일반적으로 사용되는 블러링 기법과 같은 단순한 비식별화 기술이 이를 방지하는 데 충분하지 않다는 점을 확인하였다. 이러한 결과는 VLMs의 프라이버시 보호를 위한 더 강력한 전략이 필요함을 시사한다.



### Multi-head Spatial-Spectral Mamba for Hyperspectral Image Classification (https://arxiv.org/abs/2408.01224)
- **What's New**: Spatial-Spectral Mamba (SSM) 모델에 강화 토큰 및 멀티-헤드 자체 주의(MHSSMamba)를 결합하여 기존의 트랜스포머 모델의 한계를 극복하고 하이퍼스펙트럴 이미지(HSI) 데이터의 분류 성능을 향상시켰습니다. 해당 모델은 공간 및 스펙트럴 정보를 통합하여 로컬 의존성과 순차 정보를 보다 효과적으로 캡처합니다.

- **Technical Details**: MHSSMamba 모델은 HSI 데이터를 여러 3D 패치로 나누고 이를 스펙트럴 토큰과 공간 토큰으로 분할하여 처리합니다. 멀티-헤드 자체 주의 메커니즘을 사용하여, 스펙트럼 대역과 공간 위치 간의 복잡한 관계를 포착하며, 양방향 내외 교차 의존성을 유지합니다. 핵심 기술은 토큰 향상과 멀티-헤드 주의 메커니즘을 통해 중요한 특징을 강조하고 과적합을 줄이는데 있습니다.

- **Performance Highlights**: 제안된 MHSSMamba 모델은 다양한 HSI 데이터셋에서 뛰어난 성능을 보였습니다. Pavia University 데이터셋에서는 97.62%, University of Houston 데이터셋에서는 96.92%, Salinas 데이터셋에서는 96.85%, Wuhan-longKou 데이터셋에서는 99.49%의 정확도를 달성했습니다.



### S2TD-Face: Reconstruct a Detailed 3D Face with Controllable Texture from a Single Sketch (https://arxiv.org/abs/2408.01218)
Comments:
          ACM MM 2024

- **What's New**: 3D 텍스처 얼굴을 스케치로부터 재구성하는 주제로 새로운 방법인 S2TD-Face를 제안했습니다. 이 방법은 스케치의 다양한 스타일을 처리할 수 있으며, 텍스처 제어 모듈을 통해 사용자가 텍스트 프롬프트를 통해 원하는 텍스처를 선택하고 이를 3D 얼굴에 적용할 수 있게 합니다.

- **Technical Details**: S2TD-Face는 두 단계의 지오메트리 재구성 프레임워크로 구성되며, 입력 스케치에서 직접 세부적인 지오메트리를 재구성합니다. 새로운 스케치-지오메트리 손실 함수(sketch-to-geometry loss)를 도입하여, 스케치의 미세한 특징을 반영할 수 있도록 합니다. 텍스처 제어 모듈에서는 텍스트 프롬프트를 이용하여 얼굴 라이브러리에서 적합한 텍스처를 선택하고 이를 UV 공간에 변환하여 지오메트리에 적용합니다.

- **Performance Highlights**: 광범위한 정량적 및 정성적 실험에서 S2TD-Face는 기존의 최첨단 방법들을 능가했습니다. 특히 다른 스타일의 스케치에서도 안정적인 결과를 보이며, 다양한 텍스처 스타일을 재현할 수 있는 능력을 입증하였습니다.



### A Weakly Supervised and Globally Explainable Learning Framework for Brain Tumor Segmentation (https://arxiv.org/abs/2408.01191)
Comments:
          2024 IEEE International Conference on Multimedia and Expo

- **What's New**: 새로운 연구는 픽셀 수준의 주석(annotation)이 필요 없는 뇌종양 분할(segmentation) 방법을 제안합니다. 이 방법은 반사실 생성 프레임워크를 통해 클래스 관련 특징과 클래스 비관련 특징을 효과적으로 분리하고, 이를 통해 새로운 샘플을 생성합니다. 또한, 전역적으로 설명 가능한 매니폴드(manifold)를 얻어, 의미 있는 정상 샘플을 생성하여 종양 영역을 식별할 수 있습니다.

- **Technical Details**: 제안된 프레임워크는 세 단계로 구성됩니다. 첫 번째 단계에서는 대칭적이고 순환적인 생성적 적대 신경망(GAN)을 사용하여 클래스 관련 특징을 추출하고 통합 매니폴드를 생성합니다. 두 번째 단계에서는 훈련된 인코더를 사용하여 데이터셋의 모든 샘플에서 클래스 스타일 코드(CS codes)를 추출하고 이를 토폴로지 데이터 분석을 통해 전역적으로 설명 가능한 토폴로지 그래프를 만듭니다. 세 번째 단계에서는 입력 샘플의 CS 코드를 사용하여 최단 경로를 찾고, 이를 통해 새로운 정상 샘플을 생성하여 종양 영역을 식별합니다.

- **Performance Highlights**: 두 개의 데이터셋에서 평가한 결과, 제안된 방법이 뇌종양 분할에서 뛰어난 성능을 보였습니다. 또한, 전역적으로 설명 가능한 지식을 활용하여 더 정확하고 견고한 분할 결과를 얻을 수 있었습니다.



### VAR-CLIP: Text-to-Image Generator with Visual Auto-Regressive Modeling (https://arxiv.org/abs/2408.01181)
Comments:
          total 10 pages, code:this https URL

- **What's New**: 이번 연구에서는 Visual Auto-Regressive 기술과 CLIP의 기능을 통합한 새로운 텍스트-이미지 모델인 VAR-CLIP이 도입되었습니다. VAR-CLIP은 CLIP을 활용하여 텍스트 임베딩을 생성하고 이를 이미지 생성의 조건으로 사용합니다. 이 모델은 BLIP-2를 활용해 대규모 이미지-텍스트 데이터셋을 구축하여 ImageNet 데이터셋에서도 원활한 훈련을 가능하게 합니다.

- **Technical Details**: VAR-CLIP은 두 단계의 훈련 방식을 채택합니다. 먼저, 멀티-스케일 VQVAE/VQGAN을 훈련시키고, 그 후 CLIP 텍스트 인코더를 사용하여 텍스트 캡션의 표현을 추출해 이미지 생성의 조건 토큰으로 활용합니다. 또한, CLIP 내 단어 위치의 중요성을 조사하여, 처음 20개의 토큰이 다른 토큰보다 더 큰 영향력을 가진다는 사실을 밝혔습니다. 이를 통해 텍스트-이미지 생성의 효율성과 성능을 극대화합니다.

- **Performance Highlights**: 다양한 실험을 통해 VAR-CLIP이 높은 충실도와 텍스트 일치성, 그리고 미적 우수성을 가진 판타지 이미지를 생성하는 데 우수함을 입증했습니다. 이는 텍스트 임베딩을 조건으로 사용하는 VAR의 능력을 보여줍니다. 특히 inference time을 최소화하면서도 고품질의 텍스트-이미지 생성을 실현할 수 있는 모델임을 확인했습니다.



### Rethinking Pre-trained Feature Extractor Selection in Multiple Instance Learning for Whole Slide Image Classification (https://arxiv.org/abs/2408.01167)
Comments:
          12 pages

- **What's New**: 이번 연구는 Whole Slide Images(WSIs)의 효율적인 분류를 위해 사용되는 Multiple Instance Learning(MIL)에서 최적의 Feature Extractor를 선택하는 문제를 다룹니다. 이를 위해 다양한 pre-training 데이터셋, 백본 모델, 그리고 pre-training 방법을 검토하였습니다. 연구 결과, 더 크고 다양한 pre-training 데이터셋을 사용함으로써 성능이 향상되며, 'Modern and deeper' 백본이 'Standard' 백본보다 뛰어난 성능을 보인다는 것을 확인하였습니다.

- **Technical Details**: 이번 연구는 embedding-based MIL 접근법을 주로 사용하며, 패치에서 feature vectors를 추출하는 pre-trained feature extractor를 활용하여 슬라이드 레벨 예측을 수행합니다. 실험은 TCGA-NSCLC와 Camelyon16 두 개의 공공 WSI 데이터셋에서 SOTA MIL 모델을 활용하여 수행되었고, CNN 및 Transformer 백본을 사용하였습니다. 주목할 만한 발견은 다음과 같습니다: 1) 더 크고 다양한 pre-training 데이터셋이 성능향상을 유도함, 2) CNN 및 Transformer 백본에서 'Modern and deeper' 백본이 성능 향상을 보임, 3) Self-Supervised Learning(SSL) 방법의 선택이 중요하며, 특히 Transformer(ViT) 백본에 사용될 때 그 혜택이 큼.

- **Performance Highlights**: 실험 결과를 통해 더 크고 다양한 pre-training 데이터셋이 WSI 분류 성능을 현저히 향상시킨다는 것을 발견하였습니다. 또한, 'Modern and deeper' 백본(CNN 및 Transformer)이 'Standard' 백본보다 뛰어난 성능을 보이며, 특히 Transformer 기반 백본에서는 성능 향상이 더 보장됩니다. SSL 방법을 적용할 때, Transformer(ViT) 백본에 사용하면 가장 큰 성능 향상을 보였습니다. 이를 통해 병리학적인 기반 모델을 설계하는 데 유의미한 가이드를 제공할 수 있습니다.



### PreMix: Boosting Multiple Instance Learning in Digital Histopathology through Pre-training with Intra-Batch Slide Mixing (https://arxiv.org/abs/2408.01162)
Comments:
          15 pages

- **What's New**: PreMix는 whole slide images(WSIs)의 분류를 위한 새로운 약한 지도 학습(multiple instance learning, MIL) 프레임워크입니다. 특히 Barlow Twins Slide Mixing을 포함한 intra-batch slide mixing 접근 방식을 사용하여 MIL aggregation 과정을 사전 훈련합니다. 이를 통해 레이블이 없는 WSI에서 정보를 최대한 활용할 수 있습니다. 사전 훈련 후, Mixup 및 Manifold Mixup 기법을 사용해 모델을 미세 조정합니다.

- **Technical Details**: PreMix 프레임워크는 Barlow Twins Slide Mixing을 사용하여 다양한 크기의 WSI를 효과적으로 처리합니다. 이 방법은 WSI 내부의 공간적 상관 관계를 고려하는 Hierarchical Image Pyramid Transformer(HIPT)과 조합하여 더 나은 성능을 발휘합니다. PreMix는 또한 Manifold Mixup 기법을 Transformer Encoder layer에 적용하여 개선된 성능을 보여줍니다. 다양한 활성 학습(acquisition functions) 방법을 사용하여 레이블 수가 제한된 데이터를 최대한 활용합니다.

- **Performance Highlights**: PreMix는 Camelyon16 데이터셋에서 HIPT baseline 대비 평균 4.7%의 성능 향상을 달성했습니다. 임의 샘플링 및 다양한 활성 학습(acquisition functions)을 통해 적은 양의 레이블이 있는 데이터셋에서도 뛰어난 적응성을 보였습니다. 이로써 다양한 리소스 제약이 있는 데이터셋에 대해서도 높은 효율성과 정확성을 보장합니다.



### Robust Curve Detection in Volumetric Medical Imaging via Attraction Field (https://arxiv.org/abs/2408.01159)
Comments:
          Accepted to ShapeMI MICCAI 2024

- **What's New**: 이 논문에서는 기존의 비효율적인 곡선 검출 기법을 개선한 새로운 방법을 소개합니다. 기존 기술들은 특화된 작업에 종속되기 때문에 보편적으로 적용하기 어려웠습니다. 반면, 이 논문에서는 신경망을 활용하여 물체의 방향, 형태, 위치에 대한 사전 지식 없이 비분기 곡선을 검출하는 혁신적인 접근법을 제시합니다. 즉, 'attraction field'와 'closeness map'을 통해 높은 정확도를 달성합니다.

- **Technical Details**: 이 방법은 3D CNN 네트워크를 기반으로 하며 VNet 기반 백본을 사용합니다. 네트워크의 첫 번째 헤드는 각 보셀(voxel)에서 곡선의 가장 가까운 위치까지 예측하는 'attraction field'를 예측합니다. 두 번째 헤드는 'closeness map'을 통해 관심 영역을 제한하고 멀리 떨어진 아웃라이어를 제거합니다. 인퍼런스(Inference) 단계에서는 이 두 가지 예측 결과를 결합하여 최종적으로 곡선 포인트 클라우드를 생성합니다. '비최대 억제(non-maximum suppression)' 알고리즘을 통해 포인트를 파라미터화합니다.

- **Performance Highlights**: 제안된 방법은 다양한 형태학적 특성을 가진 임상적 관련 과제에서 테스트되었으며, 기존 방법들을 능가하는 서브픽셀(subpixel) 수준의 정확도를 입증했습니다. 특히 대동맥 중심선과 척추 중심선 검출 작업에서 매우 우수한 성능을 보였습니다. 또한 향후 연구를 지원하기 위해 대동맥 중심선 및 마스크에 대한 주석을 포함한 데이터를 공개했습니다.



### PGNeXt: High-Resolution Salient Object Detection via Pyramid Grafting Network (https://arxiv.org/abs/2408.01137)
- **What's New**: 이번 연구에서는 고해상도 고유 객체 감지(HRSOD)를 보다 도전적인 과제로 다루기 위해, 데이터셋과 네트워크 프레임워크 관점에서의 향상된 접근법을 제안합니다. UHRSD(울트라 높은 해상도 고유 객체 감지 데이터셋)라는 새로운 대규모 고해상도 데이터셋을 수집했으며, 여기에는 4K-8K 해상도의 복잡한 현실 시나리오에서 촬영한 5,920장의 이미지가 포함되어 있습니다. 이 데이터셋은 매우 세밀하게 픽셀 단위로 주석이 달려 있어, 이전의 저해상도 SOD 데이터셋을 훨씬 능가합니다.

- **Technical Details**: HR-SOD 작업에서 샘플링 깊이와 수용 범위 크기 사이의 모순을 해결하기 위해, 우리는 피라미드 접목 메커니즘(pyramid grafting mechanism)을 사용한 새로운 원 스테이지 프레임워크를 제안합니다. 전반적으로, 트랜스포머(transformer) 기반과 CNN 기반 백본(backbone)을 사용하여 다른 해상도의 이미지에서 특징을 독립적으로 추출한 후, 이러한 특징을 트랜스포머 브랜치에서 CNN 브랜치로 접목합니다. 주의(attention) 기반의 Cross-Model Grafting Module(CMGM)을 제안하여, 디코딩 과정에서 다양한 소스 특징에 의해 CNN 브랜치가 상세한 정보를 보다 전체적으로 통합할 수 있도록 합니다. 또한, 우리는 주의 행렬을 명시적으로 감독하는 Attention Guided Loss(AGL)를 설계하여, 서로 다른 브랜치의 주의가 네트워크와 더 잘 상호작용하도록 돕습니다.

- **Performance Highlights**: 포괄적인 실험을 통해 UHRSD와 널리 사용되는 SOD 데이터셋에서 우리의 방법이 고유 객체를 정확하게 찾아내면서도 세부 사항을 잘 유지하며, 최신 방법들을 능가하는 성능을 보였습니다. 또한, 제안된 프레임워크의 일반화 능력을 검증하기 위해, 우리는 이를 위장 객체 감지(COD) 작업에 적용했습니다. 주목할 만하게도, 특별한 조정 없이도 최신 COD 방법들보다 우수한 성능을 발휘했습니다.



### IG-SLAM: Instant Gaussian SLAM (https://arxiv.org/abs/2408.01126)
Comments:
          8 pages, 3 page ref, 5 figures, 3DV submission

- **What's New**: IG-SLAM은 밀도 깊이 지도와 환경의 스케일을 고려한 훈련 설계를 결합하여 3D Gaussian Splatting을 활용하는 새로운 RGB 전용 SLAM 시스템을 제안합니다. 이 시스템은 강력한 포즈 추정과 밀도 깊이 지도를 사용하며, 맵 최적화 과정에서 깊이의 불확실성을 활용하여 3D 재구축의 정확성을 높였습니다.

- **Technical Details**: IG-SLAM은 초기 키프레임에서 생성된 밀도 깊이 지도, 깊이 불확실성 및 카메라 포즈를 활용하여 3D Gaussian을 초기화하고 이를 색상 및 가중치 깊이 손실로 최적화합니다. DROID-SLAM을 추적 모듈로 사용하여 각 프레임의 카메라 포즈 및 역 깊이 지도를 유지하고, 전역 밀도 번들 조정을 통해 드리프트 현상을 줄입니다.

- **Performance Highlights**: IG-SLAM은 Replica, TUM-RGBD, ScanNet, 및 EuRoC 데이터셋에서 테스트되었으며, EuRoC 데이터셋에서 특히 뛰어난 성능을 보였습니다. 이 시스템은 기존의 RGB 전용 SLAM 시스템과 경쟁력 있는 성능을 유지하면서 더 빠른 동작 속도를 자랑합니다. 단일 프로세스로 10fps로 동작할 수 있습니다.



### An Efficient and Effective Transformer Decoder-Based Framework for Multi-Task Visual Grounding (https://arxiv.org/abs/2408.01120)
Comments:
          21pages, 10 figures, 9 tables. Accepted to ECCV 2024

- **What's New**: 최신 시각 기반 정합(visual grounding) 방법들은 시청각적 특징 융합을 위해 트랜스포머(Transformers)를 사용하지만, 이로 인해 계산 비용이 제곱으로 증가하는 문제가 발생합니다. 본 논문에서는 트랜스포머 디코더(Transformer Decoder)를 기반으로 한 효율적이고 효과적인 다중 작업 시각 정합(Efficient and Effective Multi-task Visual Grounding; EEVG) 프레임워크를 제안하여 이러한 문제를 해결합니다. 이 방법은 언어와 시각 두 측면 모두에서 비용을 줄입니다.

- **Technical Details**: 언어 측면에서는 트랜스포머 디코더(Transformer Decoder)를 사용하여 시각 및 언어적 특징을 융합하고, 언어 특징을 메모리로, 시각 특징을 쿼리로 입력하여 융합을 수행합니다. 시각 측면에서는 주의(attention) 점수를 기반으로 배경 시각 토큰을 제거하여 계산을 줄입니다. 또한, 남은 희소한 특징 맵에서 직접 분할(segmentation) 마스크를 예측하기 위해 가벼운 마스크 헤드(light mask head)를 설계했습니다.

- **Performance Highlights**: EEVG는 여러 벤치마크에서 그 효율성과 효과를 입증했습니다. 이 접근법은 기존 최신 방법인 PolyFormer보다 28.19% 빠르며, 특히 더 복잡한 언어 표현을 포함하는 RefCOCOg 데이터셋에서 3.93% 향상된 성능을 보였습니다.



### Contribution-based Low-Rank Adaptation with Pre-training Model for Real Image Restoration (https://arxiv.org/abs/2408.01099)
Comments:
          33 pages, 15 figures, for homepage see this url : this https URL

- **What's New**: 최근 논문에서 제안된 새로운 접근법으로, 다수의 이미지 복원 작업을 위한 CoLoRA(기여 기반 저순위 적응)라는 효율적인 파라미터 튜닝 기법과, 무작위 순서 악화 (PROD)를 이용한 효과적인 사전 학습 방법입니다. 이전 기술들과 다르게, CoLoRA는 모든 네트워크 파라미터를 튜닝하는 것이 아니라, 각 새로운 비전 작업(task)에 대해 소량의 파라미터만을 효율적으로 튜닝합니다.

- **Technical Details**: CoLoRA는 저순위 적응(LoRA, Low-Rank Adaptation)을 활용하여 각 작업에 대해 계층별로 적응적 용량을 결정하는 새로운 기여 기반 메소드를 도입하였습니다. 또한, PROD 전략은 사전 학습 모델을 확장하여 성능과 견고성을 개선하며, 합성 사전 학습과 실제 데이터 기반 튜닝 간의 다리를 놓아줍니다. 이 접근법은 다양한 네트워크 아키텍처(CNNs 및 Vision Transformers)와 작업에 유연하게 적용될 수 있습니다.

- **Performance Highlights**: CoLoRA와 PROD는 합성 및 실제 데이터셋에서 다양한 악화 유형의 이미지 복원 작업에서 뛰어난 성능을 입증하였습니다. 특히, 다양한 IR(이미지 복원) 작업에 있어 전체 파라미터 튜닝만큼 효과적이면서도 메모리 및 저장 비용을 대폭 줄일 수 있었습니다. 예를 들어, CoLoRA는 전체 네트워크 파라미터의 약 7% 수준으로 각 작업에 필요한 작은 튜닝 어댑터만 저장하므로, 메모리 효율성 면에서 매우 유리합니다.



### Prototypical Partial Optimal Transport for Universal Domain Adaptation (https://arxiv.org/abs/2408.01089)
- **What's New**: 다양한 소스 및 타깃 도메인 간의 레이블 셋이 동일하지 않은 상황에서 지식을 전이할 수 있는 '유니버설 도메인 적응 (UniDA, Universal Domain Adaptation)'을 위한 새로운 접근법 '미니배치 벡터 기반 부분 최적 수송(m-PPOT, mini-batch Prototypical Partial Optimal Transport)'이 제안되었습니다. 이 접근법은 기존의 UniDA 방법보다 더 나은 성능을 보여주고 있습니다.

- **Technical Details**: 이제 두 도메인 간의 분포를 부분적으로 정렬하는 관점에서 문제를 해결합니다. 소스 프로토타입과 타깃 샘플을 재가중치하여 '알려진(known)' 샘플과 '알 수 없는(unknown)' 샘플을 구별하도록 설계되었습니다. 학습 단계에서는 m-PPOT 전송 계획을 활용하여 재가중 치엔트로피 손실 및 교차 엔트로피 손실을 디자인하여 '알려진'과 '알 수 없는' 샘플을 구분합니다.

- **Performance Highlights**: 네 가지 주요 벤치마크에서 실시한 실험 결과, 이 방법이 기존의 최첨단 UniDA 방법들보다 뛰어난 성능을 보였습니다. 또한, 개별 구성 요소의 유효성을 검증하는 소거 연구(ablation study)를 통해 제안된 방법의 각 요소가 효과적임을 확인했습니다.



### Effect of Fog Particle Size Distribution on 3D Object Detection Under Adverse Weather Conditions (https://arxiv.org/abs/2408.01085)
- **What's New**: 이번 연구에서는 자율주행차 시스템에서 LiDAR 센서의 성능이 안개와 같은 악천후 조건에서 어떻게 저하되는지를 분석했습니다. 특히 안개 입자의 크기 분포가 3D 객체 탐지에 미치는 영향을 주로 다루고 있습니다. 이를 위해 Mie theory와 Meteorological Optical Range (MOR)을 이용해 감쇠 및 역산란 계수를 계산하고, 다양한 난이도에서 Car, Cyclist, Pedestrian에 대한 시스템의 정확도를 평가하였습니다.

- **Technical Details**: 연구는 강한 및 중간의 열적 안개 환경에서 Gamme와 Junge (Power-Law) 분포를 사용하여 안개 입자 크기 분포를 수학적으로 모델링했습니다. KITTI 데이터셋을 수정하여 PV-RCNN++ 심층 신경망 모델을 이용해 Car, Cyclist, Pedestrian의 다양한 탐지 난이도에서 훈련을 진행했습니다. Mie 이론과 MOR을 활용해 감쇠 및 역산란 계수를 계산하고, 자세한 포인트 클라우드를 생성하여 시스템의 정확도를 평가했습니다.

- **Performance Highlights**: 결과 분석에서는 목적 객체의 크기 변화, 안개 환경의 특성 및 탐지 난이도가 증가함에 따라 시스템의 정확도가 크게 달라졌음을 보여줍니다. Car의 경우 약 99%의 높은 정확도를 보인 반면, Pedestrian의 경우 약 73%의 가장 낮은 정확도를 보였습니다.



### FCDFusion: a Fast, Low Color Deviation Method for Fusing Visible and Infrared Image Pairs (https://arxiv.org/abs/2408.01080)
Comments:
          This article has been accepted by Computational Visual Media

- **What's New**: 본 논문에서는 FCDFusion이라는 새로운 고속 가시화 및 적외선 이미지 융합(VIF) 방법을 제안합니다. FCDFusion은 기존에 주로 사용된 색 공간 변환을 생략하고, 직접 RGB 색 공간에서 작동하면서 색 정보 보존과 대조도 개선을 동시에 달성합니다. 이를 통해 색 왜곡을 최소화하고 계산 비용을 크게 줄일 수 있습니다.

- **Technical Details**: FCDFusion은 컬러 공간 변환 없이 RGB 색 공간에서 직접 작동합니다. 감마 보정(gamma correction)을 통합하여 색상과 대조도를 빠르게 개선할 수 있습니다. 융합 과정을 3D 컬러 벡터의 스케일링(확대 계산)으로 간주하여 계산을 간소화했습니다. 이론적 분석과 실험결과, FCDFusion은 픽셀 당 7 FLOPs(Floating Point Operations)만으로 만족스러운 결과를 달성할 수 있음을 보여줍니다. HSV 색 공간을 사용하는 최첨단 고속 색 보존 방법과 비교할 때, FCDFusion은 절반의 계산 비용으로 더 높은 대조도를 제공합니다.

- **Performance Highlights**: FCDFusion은 기존 방법들보다 높은 대조도와 색 보존 능력을 가지면서 계산 비용을 크게 줄였습니다. 새로운 색 편차(color deviation) 메트릭을 제안하여 VIF 방법의 색 보존 능력을 측정했습니다. 특히, FCDFusion은 색 공간 변환 없이 RGB 색 공간에서 직접 작동하므로, 더 빠른 처리 속도를 가능하게 합니다.



### PhysMamba: Leveraging Dual-Stream Cross-Attention SSD for Remote Physiological Measuremen (https://arxiv.org/abs/2408.01077)
- **What's New**: 우리가 제안한 PhysMamba는 rPPG 신호 추출 성능을 향상시키기 위해 Mamba-2 모델을 기반으로 한 이중 스트림(time-frequency interactive model) 모델입니다. PhysMamba는 표준 Mamba-2 모델을 통합하여 다양한 rPPG 특징을 학습하며, CASSD(Cross-Attention State Space Duality) 모듈을 설계하여 두 스트림 사이의 정보 교환과 특징 보완을 돕습니다. 여러 공개 rPPG 데이터셋(PURE, UBFC-rPPG, MMPD)에서 검증되었으며, 특히 복잡한 환경에서도 최첨단 성능을 보여주어 원격 심박수 모니터링 응용에 잠재력을 입증했습니다.

- **Technical Details**: PhysMamba는 두 가지 경로로 구성된 프레임워크를 채택했습니다: Self-Attention(SA) 경로와 Cross-Attention(CA) 경로. 각 경로는 Frame Stem, Multi-temporal Cross Attention Mamba, 그리고 Frequency Domain Feed Forward(FDF) 네트워크를 포함합니다. 최종적으로 두 경로의 출력 결과를 융합하여 rPPG 신호를 예측합니다. 특히, CASSD 모듈은 두 스트림 간의 효과적인 정보 공유와 보완을 통해 성능을 극대화합니다.

- **Performance Highlights**: PhysMamba는 PURE, UBFC-rPPG 및 MMPD와 같은 주요 rPPG 데이터셋에서 최첨단 성능을 달성했습니다. 특히, 내부 및 교차 데이터셋 테스트에서도 높은 성과를 보였으며, 이를 통해 원격 심박수 모니터링 기술의 새로운 가능성을 제시했습니다. 비약적인 성능 향상을 이룬 PhysMamba는 복잡한 환경에서도 강력한 일반화 능력을 자랑합니다.



### Exploiting the Semantic Knowledge of Pre-trained Text-Encoders for Continual Learning (https://arxiv.org/abs/2408.01076)
- **What's New**: 이 논문은 기존의 이미지 기반의 학습 방법에서 텍스트 임베딩(text embeddings)과 같은 풍부한 의미 정보를 활용하는 방향으로 지속 학습(Continual Learning)을 개선하는 방법을 제안합니다. 특히, CLIP 모델과 함께 Semantically-guided Representation Learning (SG-RL)과 Semantically-guided Knowledge Distillation (SG-KD) 모듈을 도입하여 의미 기반의 지식 전이를 강화합니다.

- **Technical Details**: 논문에서는 CLIP 모델을 기반으로 하여 두 가지 핵심적인 모듈을 제안합니다. 첫째, Semantically-guided Representation Learning (SG-RL) 모듈은 현재 태스크의 모든 클래스에 소프트 할당을 통해 클래스 레이블 간의 의미 관례를 반영합니다. 둘째, Semantically-guided Knowledge Distillation (SG-KD) 모듈은 이전 및 현재 클래스 간의 의미적 유사성을 사용하여 지식을 증류합니다. 이를 통해 기존 정보의 손실을 최소화하고 새로운 정보를 더 효과적으로 학습할 수 있습니다.

- **Performance Highlights**: 제안된 방법은 일반 및 세부화된 데이터셋에서 높은 우수성을 보였습니다. 특히, CIFAR-100 데이터셋의 10단계 설정에서 최종 태스크 후의 정확도를 11.4 포인트 향상시켜, 기존 최신 방법보다 우수한 성과를 보였습니다.



### Amodal Segmentation for Laparoscopic Surgery Video Instruments (https://arxiv.org/abs/2408.01067)
- **What's New**: 이 논문은 의료 분야, 특히 수술 도구의 분할 작업에 'Amodal Segmentation' 기법을 소개합니다. 이 기법은 물체의 보이는 부분뿐만 아니라 가려진 부분까지도 식별합니다. 새로운 'Amoal Instruments Segmentation (AIS)' 데이터셋을 개발하여 이를 실현했습니다.

- **Technical Details**: AIS 데이터셋은 2017 MICCAI EndoVis Robotic Instrument Segmentation Challenge 데이터셋을 재주석하여 만들어졌습니다. 총 10개의 비디오, 각각 300 프레임으로 구성되어 있으며, 각 도구는 보이는 부분과 가려진 부분 모두를 포함하는 완전한 마스크로 수동 주석되었습니다. 레이블링 도구로는 LabelMe를 사용했습니다. 또한, 최첨단 amodal 분할 방법들을 평가하여 벤치마크를 설정했습니다.

- **Performance Highlights**: 이 연구는 가려진 수술 도구를 정확하게 예측하는 것이 수술 중 시각적 신호를 제공하여 외과의사의 정확성을 높이고, 수술 후 영상 분석을 통해 수술 과정 평가 및 교육 목적으로 활용될 수 있음을 보여줍니다.



### Boosting Gaze Object Prediction via Pixel-level Supervision from Vision Foundation Mod (https://arxiv.org/abs/2408.01044)
Comments:
          Accepted by ECCV2024

- **What's New**: 이번 연구는 '눈길 대상으로 예측' (GOP: Gaze Object Prediction)을 넘어 '눈길 대상 세분화'(GOS: Gaze Object Segmentation) 과제를 제안합니다. 이는 인간의 시선이 닿은 객체의 픽셀 수준 마스크를 추론하는 것입니다. 이를 통해 시선 객체를 더 세밀하게 예측할 수 있게 되었습니다. 특히 '비전 파운데이션 모델'(VFM: Vision Foundation Model)을 통해 픽셀 수준의 지도가 가능해졌습니다.

- **Technical Details**: 제안된 프레임워크는 예측된 시선 객체의 정확성을 높이기 위해 '비전 파운데이션 모델'의 픽셀 수준 지도를 활용합니다. 기존 방법들과 달리, 추가적인 머리 입력 없이 장면 특징에서 자동으로 머리 특징을 추출하고, 공간-객체 시선 회귀(Space-to-object gaze regression) 기법을 통해 객체의 미세한 세부 정보를 고려합니다. 'Unified Detection and Segmentation Transformer' 즉, MaskDINO를 도입하여 시선 객체 상자와 분할 마스크, 주체의 머리 상자를 동시에 얻습니다. 'RoI 재구성 모듈'을 통해 시선 방향 정보를 캡처하며, '이중 주의 융합 모듈'과 '객체 특징 상호작용 모듈'을 제안하여 공간적 위치와 객체의 세부 정보를 더욱 정밀하게 식별합니다.

- **Performance Highlights**: GOO-Synth와 GOO-Real 데이터셋에서의 실험 결과, 제안된 방법이 눈길 대상으로 예측에서의 높은 정확도를 보여주었습니다. 특히 밀집된 객체 장면에서 시멘틱 모호성을 효과적으로 완화하고, 픽셀 수준의 정밀한 마스크를 생성하여 더욱 정확한 열지도(Heatmap)를 만들어냅니다.



### MambaST: A Plug-and-Play Cross-Spectral Spatial-Temporal Fuser for Efficient Pedestrian Detection (https://arxiv.org/abs/2408.01037)
Comments:
          ITSC 2024 Accepted

- **What's New**: 본 논문은 자율 주행에 효과적인 보행자 탐지를 위한 플러그앤플레이 크로스-스펙트럴(Cross-spectral) 공간-시간 융합 파이프라인인 MambaST를 제안합니다. 이는 어두운 저조도 환경에서 발생하는 탐지 어려움을 해결하고, 열화상 및 가시광선 이미지 데이터를 융합하여 탐지 성능을 향상시킵니다.

- **Technical Details**: MambaST는 최근 제안된 상태 공간 모델(State Space Model, SSM)인 Mamba에 기반을 둡니다. 이 모델은 RGB와 열화상 이미지 모두에서 세밀한 정보와 거칠지만 중요한 정보를 추출할 수 있는 다중 헤드 계층 패치 및 집합 모듈(Multi-head Hierarchical Patching and Aggregation, MHHPA)을 제안합니다. MHHPA 모듈은 YOLO 모형과 쉽게 결합되어 보행자 탐지를 수행할 수 있습니다.

- **Performance Highlights**: 실험 결과, 제안된 MHHPA 모듈은 Transformer 모델을 대체할 수 있는 효과적인 솔루션임을 입증하였고, 특히 소형 보행자 탐지에서 우수한 성능을 보였습니다. KAIST 멀티스펙트럴 보행자 탐지 벤치마크에서 수행한 실험들은 제안된 모델이 적은 모형 파라미터를 요구하면서도 높은 탐지 성능을 보여준다는 것을 입증했습니다.



### POA: Pre-training Once for Models of All Sizes (https://arxiv.org/abs/2408.01031)
Comments:
          Accepted by ECCV2024

- **What's New**: 이번 연구에서는 POA (Pre-training Once for All)라는 새로운 셀프-수퍼바이즈드 학습 프레임워크를 제안했습니다. POA는 단일 사전학습 세션을 통해 다양한 크기의 모델을 동시에 학습할 수 있도록 합니다. 이는 실제 애플리케이션에서 자원의 제약 조건에 맞게 모델을 조정하는 데 드는 개발 노력을 크게 줄여줍니다.

- **Technical Details**: POA는 최신 셀프-디스틸레이션 패러다임에 'Elastic Student' 브랜치를 추가한 구조입니다. 이를 통해 다양한 크기의 서브-네트워크(sub-network)를 원래 학생 모델에서 샘플링하여 동시에 학습합니다. 주로 ViT, Swin Transformer, ResNet과 같은 백본 구조를 사용하여 이미지를 사전학습합니다. 각 서브-네트워크는 교사 네트워크(teacher network)의 출력을 모방하도록 훈련되며, 이 과정에서 EMA (exponential moving average)를 사용하여 교사가 계속 개선됩니다.

- **Performance Highlights**: POA를 사용한 광범위한 실험은 k-최근접 이웃(k-nearest neighbors), 선형 프로빙(linear probing) 평가 및 여러 다운스트림 작업에서 최첨단 성능을 달성했습니다. POA는 단일 사전학습 세션을 통해 100개가 넘는 다양한 크기의 모델을 생성할 수 있었으며, 이는 기존 방법보다 우수한 결과를 보여줍니다. 특히 ViT, Swin Transformer, ResNet 백본을 활용한 모델은 SOTA (State-Of-The-Art) 성능을 기록했습니다.



### EIUP: A Training-Free Approach to Erase Non-Compliant Concepts Conditioned on Implicit Unsafe Prompts (https://arxiv.org/abs/2408.01014)
- **What's New**: 최신 연구에서는 텍스트-이미지 확산 모델(text-to-image diffusion models)이 다양한 개념을 학습하는 능력을 보여주었으나, 동시에 바람직하지 않은 출력을 생성할 수도 있어 심각한 보안 문제가 제기될 수 있음을 지적합니다. 이를 해결하기 위해 새로운 간단하면서도 효과적인 기법을 제안했습니다. 이 기법은 부적합한 개념을 자동으로 감지하고 억제하기 위해 'erasure prompt'를 활용합니다.

- **Technical Details**: 연구는 주목(attention) 메커니즘을 이용해 이미지 생성 과정 중 이미지 공간에서 부적합한 개념의 특성을 식별하고, 이러한 특성을 억제하는 방법을 소개합니다. 또한, 이 기법은 훈련 과정이 필요 없이 다양한 유형의 프롬프트(prompt)에 대해 효과적으로 적용될 수 있습니다. 주목 메커니즘(agent mechanisms)을 통해 원본 암시적 부적합 프롬프트(implicit unsafe prompt)에 조건화된 비안전 이미지를 생성하는 것을 억제합니다.

- **Performance Highlights**: 제안된 기법은 이미지의 품질을 유지하면서도 부적합한 개념의 특성을 억제하는 뛰어난 성능을 보입니다. NSFW(NSFW content) 및 스타일 복제 방지에서 우수한 성능을 보여주며, 테스트된 모든 유형의 프롬프트에서도 탁월한 이미지 충실도와 의미 유사성을 유지하는 것으로 입증되었습니다.



### FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation (https://arxiv.org/abs/2408.00998)
Comments:
          Accepted conference paper of ACM MM 2024

- **What's New**: 이 논문은 대규모 텍스트-이미지 변환(T2I) 확산 모델을 이미지-이미지 변환(I2I) 패러다임에 적응시키는 새롭고 효율적인 접근 방식을 제시합니다. 이를 통해 모델 훈련이나 온라인 최적화 없이 고품질의 텍스트 기반 이미지 변환이 가능해졌습니다.

- **Technical Details**: 주요 접근법은 DCT 스펙트럼 공간에서 다양한 주파수 대역을 이용하여 레퍼런스 이미지의 다양한 지시 요소(guiding factors)를 모델링하고, 주파수 대역 대체 레이어를 개발하여 반대 방향 샘플링 과정 동안 레퍼런스 이미지의 특정 DCT 주파수 대역을 동적으로 대체하는 것입니다.

- **Performance Highlights**: 이 방법은 레퍼런스 이미지의 지시 요소와 지시 강도를 유연하게 조절할 수 있도록 하며, 광범위한 정량적 및 정성적 실험에서 기존 방법에 비해 우수한 I2I 변환 시각 품질, 다용성 및 제어 가능성을 입증했습니다.



### Visible-Thermal Multiple Object Tracking: Large-scale Video Dataset and Progressive Fusion Approach (https://arxiv.org/abs/2408.00969)
- **What's New**: 새로운 대규모 가시-열 영상(MOT) 비디오 벤치마크 VT-MOT를 소개합니다. VT-MOT는 582개의 비디오 시퀀스 쌍과 401,000 프레임 쌍을 포함하며, 감시 카메라, 드론, 및 핸드헬드 장치에서 수집되었습니다. 또한, 공간적 및 시간적 정렬이 높은 정확도로 수행되었으며, 전문가들이 체크한 밀도 높은 높은 품질의 주석(annotation)을 제공합니다.

- **Technical Details**: 본 연구는 두 가지 모달리티(가시광선 및 열 적외선)의 보완 정보를 점진적으로 융합하는 'Progressive Fusion Tracking' 프레임워크(PFTrack)을 제안합니다. 여기에는 시간적 특징 융합과 다중모달 특징 융합의 두 단계가 포함됩니다. 첫 번째 단계에서는 'Attention Mechanism'을 사용하여 근접 프레임의 시간 정보를 융합합니다. 두 번째 단계에서는 교차 주의 모듈을 사용하여 다중모달 특징을 상호 작용시킵니다. 이를 통해 대상의 위치 추적 성능을 강화합니다.

- **Performance Highlights**: VT-MOT 데이터셋을 사용한 실험 결과, 제안된 PFTrack 프레임워크는 최신 상태의 방법들보다 우수함을 입증하였습니다. 3.99백만 개의 주석 상자가 포함된 이 데이터셋은 자연 장면에서 가장 많은 주석을 갖고 있으며, 무거운 가림 현상 및 객체 재획득 문제를 포함합니다. 이러한 벤치마크는 다양한 MOT 알고리즘의 포괄적 평가를 위한 고품질 데이터를 제공합니다.



### Extracting Object Heights From LiDAR & Aerial Imagery (https://arxiv.org/abs/2408.00967)
- **What's New**: 본 연구는 LiDAR 및 항공 이미지를 사용하여 객체의 높이를 추출하는 절차적 방법을 제시합니다. 기존 딥러닝 배경 지식을 필요로 하지 않고 최신 객체 분할(State-of-the-Art, SOTA) 기법을 활용하여 객체 높이를 추출할 수 있는 방법을 논의합니다. 연구에서는 공간적으로 인식할 수 있는 AI를 가능하게 하는 포인트 클라우드(point cloud), 이미지 및 텍스트 인코딩을 포함한 최신 기술들도 다루고 있습니다.

- **Technical Details**: 본 연구에서는 San Antonio, TX의 나무 캐노피 높이를 측정하는 프로젝트를 기반으로, 동일한 워크플로우를 다양한 객체에 적용할 수 있도록 한 절차적 방법론을 소개합니다. LiDAR 포인트는 객체 유형에 따라 분류되며, 개별 객체의 높이, 위치, 면적, 둘레 길이 및 객체 유형을 포함하는 표 형식의 데이터로 변환됩니다. 또한, 데이터 결합을 통해 지면 높이와 객체 높이를 산출하여 객체의 최소, 최대, 평균 높이를 계산합니다.

- **Performance Highlights**: LiDAR와 항공 이미지를 결합하여, 지면 및 객체의 높이 모델을 생성하며, 결과적으로 더 정확한 객체 높이 측정이 가능합니다. 최신 연구는 LiDAR와 이미지를 통합하여, 5개의 밴드(RGB 색상, LiDAR 고도 및 적외선)로 구성된 데이터를 결합함으로써, 원격 센싱 객체 높이가 가장 정확하게 측정될 수 있음을 시사하고 있습니다.

- **Future Directions**: 원격 센싱의 미래는 지리공간 대형언어모델(GeoAI)로 이동하고 있습니다. LiDAR 및 이미지를 포함한 다양한 데이터 형식을 Transformer 아키텍처에 통합하는 연구가 활발히 진행되고 있습니다. 그러나 이러한 아키텍처가 본격적으로 활용되기 위해서는 더 많은 데이터셋이 필요합니다. 지리공간 데이터와 텍스트 데이터를 입력하여 결과를 도출하는 방법론이 지속적으로 개발될 것입니다.

- **Limitations**: 항공 이미지의 정확도는 여전히 과제입니다. 대규모 객체의 정확도는 높지만 작은 객체는 놓치는 문제와, 모델이 도시 환경에서 더 좋은 성능을 보이는 지리적 차이 등이 있습니다.



### MIS-ME: A Multi-modal Framework for Soil Moisture Estimation (https://arxiv.org/abs/2408.00963)
Comments:
          Accepted by DSAA2024

- **What's New**: 새로운 연구에서는 농업에서 토양 습기 예측을 위한 다중 모달 (multi-modal) 접근법을 제안합니다. 이는 스마트폰으로 촬영한 이미지와 기상 데이터(weather data)를 활용해 실시간 정밀 농업을 실현하는 첫 발걸음입니다. 이를 통해 비용이 많이 들고 해석하기 어려운 항공 및 지리 공간 이미지를 대체할 수 있습니다. 우리는 지상 스테이션에서 촬영한 실제 이미지를 포함한 데이터셋을 구축하였으며, 이를 통해 토양 습기를 예측하는 'MIS-ME' - Meteorological & Image based Soil Moisture Estimator 프레임워크를 제안했습니다.

- **Technical Details**: MIS-ME는 세 가지 혁신적인 다중 모달 접근법을 포함합니다: Multi-modal Concat, Hybrid Loss, Learnable Parameters. 각 접근법은 토양 패치 이미지를 기상 데이터와 결합하여 예측 정확성을 최적화합니다. 우리는 실제 세계의 지상 스테이션에서 촬영한 이미지를 사용하여 데이터셋을 구축하고, 이를 통해 토양의 부피 물 함량(volumetric water content, VWC)을 예측하는 모델을 개발했습니다. 이 연구는 특정 기상 조건과 토양 패치 이미지의 조합을 통해 모델의 성능을 향상시키는 데 중점을 두었습니다.

- **Performance Highlights**: MIS-ME는 MAPE (Mean Absolute Percentage Error) 10.79%를 달성하며, 기존의 단항 접근법에 비해 평균 2.6%의 개선을 보였습니다. 특히 기상 데이터에서는 2.6%, 이미지 데이터에서는 1.5%의 개선을 이루어 다중 모달 접근법의 효율성을 입증했습니다. 이러한 결과는 다중 모달 접근법이 정밀농업에서 실용적인 해결책임을 보여주며, 농민들이 모니터링되지 않은 지역의 토양 습기를 더 정확하게 예측할 수 있도록 도와줍니다.



### PrivateGaze: Preserving User Privacy in Black-box Mobile Gaze Tracking Services (https://arxiv.org/abs/2408.00950)
- **What's New**: PrivateGaze는 블랙박스(gaze tracking) 서비스를 사용하는 동안 사용자의 프라이버시를 효과적으로 보호하면서도 시선 추정(gaze estimation) 성능을 저해하지 않는 최초의 접근 방법입니다. 기존의 전체 얼굴 이미지를 프라이버시 강화된 변형된 이미지로 변환하여 개인정보 누출 없이 시선 추정을 수행합니다.

- **Technical Details**: PrivateGaze는 두 가지 주요 과제를 해결하는 기술들을 포함하고 있습니다. 첫째, 사용자의 개인 속성(예: 신원, 성별)을 제거하기 위해 공공 데이터셋에서 평균 전체 얼굴 이미지를 생성하고 이를 템플릿으로 사용해 이미지 변환을 수행합니다. 둘째, 변형된 이미지 내에서 시선 관련 중요한 정보를 유지하기 위해 대체 시선 추정기를 사용할 것을 제안합니다. 이 대체 추정기를 통해 변형된 이미지가 여전히 원래 이미지와 동일한 시선 방향을 유지하도록 합니다.

- **Performance Highlights**: 네 개의 데이터셋에서의 평가 결과, 프라이버시 강화된 이미지가 신원과 성별과 같은 사용자의 개인정보를 보호함을 입증했습니다. 이러한 보호는 인가되지 않은 속성 추론기(attribute recognizer)가 올바른 속성 레이블로 훈련된 경우에도 유효하였습니다. 또한, 변형된 이미지들을 블랙박스 시선 추정기의 입력으로 직접 사용할 때도, 기존의 보호되지 않은 전체 얼굴 이미지와 비교해 추적 성능이 유사하다는 점을 확인했습니다.



### Data-Driven Traffic Simulation for an Intersection in a Metropolis (https://arxiv.org/abs/2408.00943)
Comments:
          CVPR 2024 Workshop POETS Oral

- **What's New**: 이번 연구에서는 대도시 교차로의 교통 흐름을 모델링하기 위한 새로운 데이터 기반 시뮬레이션 환경을 선보입니다. 오랜 기간 동안 수집된 현실 세계의 추적 데이터를 사용하여, 에이전트 상호작용 및 환경 제약을 학습하는 궤적 예측 모델을 훈련하였습니다. 시뮬레이션은 자율적으로 실행되거나, 생성적 분포에 따라 인간의 명시적 제어하에 실행될 수 있습니다.

- **Technical Details**: 이 연구는 주명 높은 YOLOv8 객체 탐지 모델을 보행자와 차량에 맞게 미세 조정하고, BoT-SORT 알고리즘을 사용하여 추적 기반 탐지 패러다임에서 궤적 데이터를 수집했습니다. 수집된 데이터는 예측에 적합하도록 전처리되었습니다. 새로운 에이전트의 궤적은 Gaussian Mixture Model (GMM)을 사용하여 생성되고, 이후 최첨단 궤적 예측 모델을 통해 정밀하게 다듬어집니다. 이 과정에서 Temporal Agent Density 및 Spatial Trajectory Categorization 등의 방법이 사용됩니다.

- **Performance Highlights**: 둘 어느 한 방법으로 실험된 TrajNet++ 모델은 NVIDIA A100 GPU에서 20 FPS로 0.36 최종 변위 오차(FDE)를 달성했습니다.



### Towards Zero-Shot Annotation of the Built Environment with Vision-Language Models (Vision Paper) (https://arxiv.org/abs/2408.00932)
- **What's New**: 이 논문은 도시 환경의 다양한 특징을 위성 이미지에서 주석(annotations)하는 방법으로서 Vision Language Models (VLMs)을 사용하는 가능성을 탐구합니다. 이 접근법은 인간 주석에 대한 의존도를 줄임으로써, 대규모 학습 데이터셋을 더 저비용으로 생성할 수 있게 합니다.

- **Technical Details**: 기존의 기계 학습 방법은 도시 환경에서 흔하지 않은 구조적 요소들을 인식하는데 어려움을 겪습니다. 저자들은 최첨단 VLM과 설정-변형(promoting strategies)을 결합하여 분할된 이미지 요소에 대해 독립적으로 주석을 달도록 요청하는 전략을 사용합니다. 이 과정은 샘플링이나 레이블 예시가 필요하지 않으며, 완전히 폐쇄된 모델에서도 작동합니다. 저자들은 GPT-4o와 일반 목적의 분할 모델인 SAM을 사용하여 실험을 진행했습니다.

- **Performance Highlights**: 저자들은 정지선(stop lines)과 높아진 테이블(raised tables) 같은 두 가지 도시 특징에 대한 실험에서, 직접적인 제로샷 프롬프트는 거의 0%의 정확도를 보였으나, 사전 분할 전략을 사용한 경우 약 40%의 교집합-영역비율(intersection-over-union) 정확도를 성취하였습니다. 이를 통해 이 방법이 까다롭지만 실현 가능성이 있음을 증명했습니다.



### Reclaiming Residual Knowledge: A Novel Paradigm to Low-Bit Quantization (https://arxiv.org/abs/2408.00923)
Comments:
          Accepted by The 35th British Machine Vision Conference (BMVC 2024)

- **What's New**: 이 논문은 저비트(4비트 이하) 양자화(quantization)에 대한 새로운 접근 방식을 제안합니다. 기존의 최적화 기법들과는 달리, 최적 양자화를 컨볼루션 신경망(ConvNets) 아키텍처 탐색 문제로 재해석하였습니다. 제안된 프레임워크는 CoRa(Optimal Quantization Residual Convolutional Operator Low-Rank Adaptation)로, 기존에 무시되었던 양자화 잔여 정보(quantization residual knowledge)를 회수하여 성능 저하를 방지하고, 훈련 없이도 성능을 유지할 수 있음을 보여줍니다.

- **Technical Details**: CoRa는 저비트 양자화에서 잃어버린 정보를 회수하기 위해 저차 어댑터(low-rank adapters)를 사용하여 양자화된 잔여 가중치를 근사합니다. 기존의 방법들은 가중치 공간에서 최적의 가중치를 찾기 위해 광범위한 탐색 공간을 필요로 하지만, CoRa는 훨씬 작은 탐색 공간을 사용하여 효율성을 높였습니다. 이를 위해 CoRa는 컨볼루션 필터를 두 개의 작은 저차 필터로 변환하여 최적의 성능을 유지합니다.

- **Performance Highlights**: CoRa는 ImageNet에서 사전 훈련된 ConvNets을 평가한 결과, 기존의 최첨단 양자화 인식 훈련(QAT) 및 사후 훈련 양자화(PTQ) 방법들과 비교하여 4비트 및 3비트 양자화에서 유사한 성능을 보였습니다. 특히, 소규모 보정 세트(1600개의 이미지)에서 250회 미만의 반복으로 최적화되었습니다. 이렇게 개발된 CoRa는 낮은 비트 양자화에서 최적화 효율성 면에서 새로운 기준을 세웠습니다.



### Medical SAM 2: Segment medical images as video via Segment Anything Model 2 (https://arxiv.org/abs/2408.00874)
- **What's New**: 이 논문에서 소개된 MedSAM-2는 SAM 2 프레임워크를 활용하여 2D 및 3D 의료 이미지 세분화 작업을 수행할 수 있는 고급 세분화 모델입니다. 이 모델은 영상을 연속적으로 다루는 비디오 철학을 적용하여 새로운 One-prompt Segmentation 기능을 도입하였고, 그 결과 시간적 관계와 상관없이 모든 subsequent image에서 같은 유형의 객체를 자동으로 세분화할 수 있습니다.

- **Technical Details**: MedSAM-2는 SAM 2를 기반으로 설계되었으며, 2D와 3D 의료 이미지 세분화에서 모두 뛰어난 성능을 발휘합니다. 이 모델은 고유한 'One-prompt Segmentation' 기능을 제공하여 사용자가 특정 이미지의 프롬프트만 제공하면, 이후 모든 이미지에서도 동일한 객체를 자동으로 세분화할 수 있습니다. 이는 의료 이미지 데이터를 마치 비디오처럼 처리하여 이루어졌으며, confidence memory bank와 weighted pick-up 등의 고유 모듈 및 파이프라인을 포함하고 있습니다.

- **Performance Highlights**: MedSAM-2는 복부 장기, 안구 디스크, 뇌종양, 갑상선 결절, 피부 병변 등 다양한 의료 이미징 모달리티에서 평가되었으며, 기존 모델들을 능가하는 성능을 보였습니다. 특히, 새로운 One-prompt Segmentation 설정에서 이전의 few-shot 및 one-shot Segmentation 모델들을 뛰어넘는 뛰어난 일반화 능력을 시연하였습니다. MedSAM-2는 15개의 다른 벤치마크 및 26개의 독립적인 작업에서 뛰어난 결과를 도출하였습니다.



### A Scalable and Generalized Deep Learning Framework for Anomaly Detection in Surveillance Videos (https://arxiv.org/abs/2408.00792)
- **What's New**: 이 연구는 새로운 딥러닝 (DL) 프레임워크를 소개하며, 다양한 비디오 이상 탐지 작업을 위한 일반화 문제를 해결하려고 합니다. 기존의 DL 접근 방식은 각 작업마다 재훈련이 필요하여 시간과 자원이 많이 소모되었으나, 이번 프레임워크는 재훈련 없이도 다양한 작업에 일반화가 가능합니다.

- **Technical Details**: 새로운 DL 프레임워크는 세 가지 주요 구성 요소를 포함합니다: 첫째, feature 일반화를 향상시키기 위한 transfer learning (전이 학습); 둘째, feature 표현을 개선하기 위한 model fusion (모델 융합); 셋째, 새로운 작업이 도입될 때 처음부터 훈련하지 않고도 classifier를 일반화할 수 있는 multi-task classification (다중 작업 분류)을 포함합니다. 또한, explainability tools (설명 가능 도구)를 사용하여 잠재적인 편향을 식별하고, 가용성과 공정성을 보장합니다.

- **Performance Highlights**: 제안된 프레임워크는 violence detection (폭력 탐지) 작업에서 97.99%의 정확도, shoplifting detection (도난 탐지) 작업에서 83.59%, 두 데이터셋을 사용하는 단일 classifier로 재훈련 없이 88.37%의 정확도를 달성했습니다. 또한, 새로운 데이터셋에서도 87.25%의 정확도를 기록하였습니다. 이는 비디오 이상 탐지에서 일반화 문제를 성공적으로 해결한 첫 사례로, 이 분야에서의 중대한 진전을 의미합니다.



### Data-driven Verification of DNNs for Object Recognition (https://arxiv.org/abs/2408.00783)
- **What's New**: 이 논문은 기존의 그리드 기반 혹은 조합적 테스트를 넘어 딥 러닝 네트워크(DNN)를 검증하기 위해 그래디언트-프리 최적화(gradient-free optimization)를 활용해 성공적으로 DNN을 위조하는 퍼투버이션 체인(perturbation chains)을 찾는 새로운 테스트 접근법을 제안합니다. 본 연구의 접근법은 이미지 세분화 작업에서 철도 트랙을 감지하는 데 적용되어 특정 이미지 클러스터에서 흔한 퍼투버이션(예: 비, 안개, 흐림, 노이즈) 조합에 대해 DNN의 약점을 식별하는 데 성공했습니다.

- **Technical Details**: 이 접근법은 철도 영역에서 이미지 세그멘테이션 작업에 대해 평가되었습니다. 퍼투버이션의 시퀀스와 그 파라미터(예: 가우시안 노이즈의 평균 및 표준 편차)를 최적화하는 것이 목표입니다. 퍼투버이션 체인은 최대 6개의 요소로 이루어져 있으며, 특정 순서와 개별 파라미터는 그래디언트-프리 최적화기로 최적화됩니다. 여기에 사용된 퍼투버이션은 자연적 퍼투버이션(natural perturbations)으로, 이는 일반적인 테스트 이미지 클러스터에서 더욱 의미 있게 최적화될 수 있습니다. 클러스터링에는 사전 훈련된 EfficientNetB4를 사용한 이미지 특징 추출, UMAP을 통한 차원 축소, 그리고 k-means 클러스터링 방법이 사용되었습니다.

- **Performance Highlights**: 제안된 접근법은 공개된 RailSem19 데이터셋에서 테스트 되었으며, 이 데이터셋은 8,500개의 다양한 환경에서 기차의 에고-퍼스펙티브(ego-perspective)로 촬영된 RGB 이미지들로 구성되어 있습니다. 실험 결과, 원본 이미지에서 높은 Intersection-over-Union(IoU) 정확도를 달성했던 U-net 모델이 제안된 접근법에 의해 생성된 반례들에 대해 실패함을 보였습니다. 이는 제안된 접근법이 DNN의 약점을 효과적으로 식별할 수 있음을 의미합니다.



### CATD: Unified Representation Learning for EEG-to-fMRI Cross-Modal Generation (https://arxiv.org/abs/2408.00777)
- **What's New**: 새로운 Condition-Aligned Temporal Diffusion (CATD) 프레임워크가 제안되었습니다. 이 프레임워크는 접근성이 높은 Electroencephalography (EEG) 신호를 통해 비용이 높고 접근이 어려운 기능적 자기공명영상(fMRI)에서 검출된 Blood Oxygen Level Dependent (BOLD) 신호를 생성할 수 있도록 합니다. CATD는 Conditionally Aligned Block (CAB)과 Dynamic Time-Frequency Segmentation (DTFS) 모듈을 사용하여 이종 신경 영상을 잠재 공간에 맞춰 통합된 표현을 제공하고, 이는 신경 영상의 교차 모달 변환을 가능하게 합니다.

- **Technical Details**: 제안된 CATD 프레임워크는 EEG와 BOLD 신호를 잠재 공간에서 정렬하여 나타내며, 이를 위해 Scalable Diffusion Models with Transformers (DiT)를 사용합니다. EEG 신호의 우수한 시간 해상도를 활용하여 BOLD 신호의 시간 초해상도를 향상시키며, 이를 통해 뇌의 동적 세부 사항을 더 잘 포착합니다. EEG 신호는 단기 푸리에 변환을 기반으로 한 동적 시간-주파수 분석 방법을 통해 특징 추출과 차원 축소를 수행하며, 이를 통해 BOLD 프레임과 동일한 차원과 숫자로 변환됩니다.

- **Performance Highlights**: CATD 프레임워크는 신경 활동 예측의 정확성을 높이고, 비정상 뇌 영역을 식별하며, BOLD 신호의 시간 해상도를 향상시키는 데 효과적임이 입증되었습니다. 이를 통해 파킨슨병 예측과 비정상적인 뇌 영역 식별과 같은 의료 응용 분야에서 유망한 가능성을 보여줍니다.



### 2D Neural Fields with Learned Discontinuities (https://arxiv.org/abs/2408.00771)
- **What's New**: 최근 연구에서 전통적인 래스터와 벡터 그래픽스의 한계를 극복하고, 이미지를 고충실도와 해상도 독립성으로 표현할 수 있는 새로운 비연속 신경 필드(Neural Field) 모델이 소개되었습니다. 이 모델은 메시 엣지를 잠재적 비연속점으로 간주하고, 비연속의 크기를 최적화하여 이미지와 비연속점을 동시에 근사하는데 성공했습니다.

- **Technical Details**: 이 연구에서 제안된 비연속 신경 필드 모델은 기존의 InstantNGP에 비해 5dB 이상의 잡음 제거 성능과 10dB 이상의 초해상도 성능 향상을 보여줍니다. 또한, Mumford-Shah 기반 방법보다 3.5배 작은 Chamfer 거리로 비연속점을 더욱 정확히 캡처합니다. 이를 통해 복잡한 예술적 도면이나 자연 이미지에서도 뛰어난 결과를 보여주며, 이 모델은 JPEG 압축이 적용된 벡터 그래픽스 이미지를 복원하는 데도 효과적입니다.

- **Performance Highlights**: 비연속 신경 필드 모델은 잡음 제거 및 초해상도 작업에서 InstantNGP를 각각 5dB 및 10dB 이상 상회하는 성능을 보여줍니다. 또한, Mumford-Shah 기반의 방법보다 3.5배 더 정확한 비연속점 복원력을 제공합니다. 다양한 2D 데이터 세트, 예를 들면 확산 생성 깊이맵에서도 고도로 정교한 세그멘테이션 성능을 발휘합니다.



### Comparing Optical Flow and Deep Learning to Enable Computationally Efficient Traffic Event Detection with Space-Filling Curves (https://arxiv.org/abs/2408.00768)
Comments:
          27th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2024)

- **What's New**: 트래픽 상황에서 이벤트 식별 및 데이터를 수집하는 문제는 여전히 시스템 성능 평가에 중요한 도전 과제입니다. 이 연구에서는 Optical Flow (OF)와 Deep Learning (DL)을 비교하여, 차량의 전방 카메라 비디오 데이터에서 공간 채우기 곡선(space-filling curves)을 통해 컴퓨터 효율적인 이벤트 감지 방법을 제안합니다. OF를 이용한 접근법은 주변 차량의 예상치 못한 방해물을 감지하고, DL 접근법은 인간의 시각 주의를 학습해 운전자의 시선을 예측하여 잠재적인 이벤트 위치를 찾아냅니다.

- **Technical Details**: OF 기반 접근법은 차량 주변의 예상치 못한 방해물을 감지하는데 탁월하며, DL 모델은 사람의 시각 주의를 학습해 운전자의 시선을 예측하여 잠재적인 이벤트 위치를 식별합니다. 이 결과들은 공간 채우기 곡선을 통해 차원 축소되어, 효율적인 이벤트 검색이 가능합니다. 실험은 대규모 가상 데이터 세트 (SMIRK) 와 실제 데이터 세트 (Zenseact Open Dataset, ZOD)를 사용하여 체계적으로 평가되었습니다.

- **Performance Highlights**: OF 접근법은 특이도(specificity)에서 뛰어나고 오탐(false positives)을 줄이는 데 유리하며, DL 접근법은 민감도(sensitivity)에서 우수한 성능을 보입니다. 두 접근법은 모두 실시간 응용에 적합한 처리 속도를 특징으로 하며, 시간과 확장성 측면에서 유사한 성능을 보였습니다.



### Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs (https://arxiv.org/abs/2408.01417)
Comments:
          Accepted to COLM 2024

- **What's New**: 최신 연구에서는 인간이 시간 경과에 따라 상호작용 중에 효율적인 언어를 점차 사용하게 됨을 밝혀냈습니다. 이러한 현상을 연구하기 위해 ICCA라는 프레임워크를 도입하여 다중모달 대형 언어 모델(MMLMs)이 유사하게 행동하는지 평가했습니다. 연구 결과, MMLMs는 상대방의 효율적인 언어를 이해할 수 있지만 자신들이 자발적으로 언어를 더 효율적으로 만들지는 않는다는 것이 드러났습니다.

- **Technical Details**: 연구진은 ICCA라는 자동화된 프레임워크를 사용하여, 다중모달 언어 모델들의 대화 적응(in-context behavior)을 평가했습니다. 여러 최신 MMLMs 모델들을 테스트한 결과, 일부 모델만이 GPT-4와 같은 강력한 프롬프팅(prompting)을 통해 자신의 언어를 효율적으로 변화시키는 능력을 보였습니다. 이는 인간 언어의 일반적인 특징이지만, 현재의 모델 훈련 체계에서는 이러한 능력이 자연스럽게 나타나지 않는다는 것을 보여줍니다.

- **Performance Highlights**: 몇몇 모델에서는 강력한 프롬프팅(prompting)으로 이러한 효율적인 언어 사용 능력을 이끌어낼 수 있었으나, 대부분의 모델에서는 자발적인 효율성 증가는 관찰되지 않았습니다. 특히 GPT-4 모델이 이에 해당하며, 이는 특정한 훈련 방식 없이는 자연적으로 발생하지 않는다는 점을 강조합니다.



### Play to the Score: Stage-Guided Dynamic Multi-Sensory Fusion for Robotic Manipulation (https://arxiv.org/abs/2408.01366)
- **What's New**: MS-Bot은 동적으로 다양한 감각 데이터를 융합하여 복잡한 로봇 조작 작업을 수행하도록 설계된 새로운 방법입니다. 인간이 특정 작업 단계를 이해하고 해당 과정을 통해 다양한 감각을 사용하는 능력에 영감을 받아 개발된 이 시스템은 로봇이 비슷한 능력을 갖추도록 돕습니다. MS-Bot은 작업 단계를 부목표(sub-goal)로 나누어, 각 단계의 세부 상태에 기반하여 동적으로 감각 모달리티의 우선순위를 조정합니다.

- **Technical Details**: MS-Bot은 시각, 청각 및 촉각 센서를 장착한 로봇 시스템에서 작동하며, imitation learning(모방 학습) 방식을 사용하여 훈련됩니다. 핵심 기술로는 coarse-to-fine stage comprehension(단계 이해)과 동적 크로스-어텐션(cross-attention)을 통한 모달리티 융합이 있습니다. 로봇은 현재 관찰 정보와 과거의 행동을 추적하여 현재 단계를 파악하고, 이를 바탕으로 감각 데이터를 융합합니다.

- **Performance Highlights**: MS-Bot은 두 가지 도전적인 조작 작업, 특정 품질의 작은 구슬을 붓는 작업과 키웨이로 페그를 삽입하는 작업에서 기존 방법보다 우수한 성능을 보였습니다. 실험 결과는 MS-Bot이 현재 단계의 세부 상태를 더 잘 이해하고 필요에 따라 모달리티 주의를 동적으로 조정함으로써 더 효과적이고 설명 가능한 동적 융합을 달성한 것을 보여줍니다.



### Toward Automatic Relevance Judgment using Vision--Language Models for Image--Text Retrieval Evaluation (https://arxiv.org/abs/2408.01363)
Comments:
          Accepted by ACM SIGIR 2024 LLM4Eval Workshop: this https URL

- **What's New**: 이번 연구는 Vision-Language Models(VLMs)의 성능을 통해 이미지-텍스트 리트리벌 상황에서의 적합성 추정을 평가합니다. 이 연구는 CLIP, LLaVA, GPT-4V 모델을 대상으로 진행되었으며, 이들 모델의 성능이 인간의 적합성 판단과 얼마나 일치하는지를 살펴봅니다.

- **Technical Details**: 연구는 대규모 멀티미디어 콘텐츠 제작을 위한 제로샷(Zero-shot) 리트리벌 태스크에서 VLM들의 적합성 추정 능력을 평가했습니다. 클립스코어(CLIPScore)를 기준으로, LLaVA와 GPT-4V 모델은 인간의 적합성 판단에 대한 켄달의 타우(Kendall's tau) 약 0.4를 기록하며 좋은 성능을 보였습니다. 또한, GPT-4V 모델은 적합성 판단 분포에서도 인간과 유사한 경향을 보이며, 코헨의 카파(Cohen's kappa) 값이 0.08로, CLIPScore의 -0.096보다 현저하게 높은 값을 보였습니다.

- **Performance Highlights**: LLaVA와 GPT-4V 모두 인간의 적합성 판단과 상당히 일치하는 성능을 보였으며, 특히 GPT-4V 모델은 인간과 유사한 판단 분포를 보여줍니다. CLIP 기반 리트리벌 시스템에 대한 편향성을 줄여주며, 모델 기반 적합성 판단이 상당히 효과적임을 발견했습니다.



### PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieva (https://arxiv.org/abs/2408.01349)
Comments:
          Accepted by ACM MM 2024

- **What's New**: 연구자들은 PC$^2$ (Pseudo-Classification based Pseudo-Captioning)라는 새로운 프레임워크를 제안했습니다. 이 모델은 이미지-텍스트 간의 의미적 유사성을 비대조적(non-contrastive) 메커니즘을 통해 학습하고, 잘못된 대응쌍을 더 많은 정보를 제공하는 가짜 캡션(pseudo-captions)을 생성하여 교정합니다. 또한, 새로운 노이즈 데이터셋인 'Noise of Web (NoW)'도 개발되었습니다.

- **Technical Details**: PC$^2$ 프레임워크는 세 가지 주요 전략으로 구성됩니다. 첫째, 캡션을 범주형 레이블로 해석하여 비대조적 학습을 통한 '가짜 분류(pseudo-classification)' 보조 작업을 수행합니다. 둘째, 가짜 캡션을 생성하여 잘못된 대응쌍에도 유익한 감독 정보(supervision)를 제공합니다. 셋째, 가짜 분류기의 예측 변동성을 이용하여 대응쌍의 교정을 돕습니다. 이를 위해 크로스 엔트로피 손실(cross-entropy loss)과 반대쪽(simplicity) 최적화 목표를 사용합니다.

- **Performance Highlights**: PC$^2$ 프레임워크는 기존의 최첨단 크로스 모달 검색 방법과 비교하여 시뮬레이션된 데이터셋과 현실적인 데이터셋 모두에서 놀라운 성능 향상을 보였습니다. 특히, 다양한 NCL (Noisy Correspondence Learning) 환경에서 더 나은 성능을 발휘했습니다. 또한, 새로운 데이터셋인 NoW를 도입하여 이후의 NCL 평가를 위한 강력한 기준을 제공했습니다.



### A Backbone for Long-Horizon Robot Task Understanding (https://arxiv.org/abs/2408.01334)
Comments:
          8 pages, 8 figures. This work is intended to be submitted to IEEE Robotics and Automation Letters (RA-L) for possible publication

- **What's New**: 테스크 이해와 전이 가능성을 향상시키기 위해 새로운 Therblig-based Backbone Framework (TBBF)을 제안합니다. 이 프레임워크는 therbligs (기본 액션 요소)를 사용하여 로봇 작업을 세분화하고, 이를 현재의 foundation models와 결합하여 작업 이해를 개선합니다.

- **Technical Details**: TBBF는 두 단계로 나눠집니다: 오프라인 학습 단계와 온라인 테스트 단계입니다. MGSF 네트워크를 사용하여 다양한 작업에서 therblig 분할을 정확하게 수행합니다. ActionREG는 이미지에 고급 지식을 인코딩하고, LAP-VC는 시각적 교정을 통해 작업 실행의 정확성을 보장합니다.

- **Performance Highlights**: 실험 결과, therblig 분할에서 94.37%의 리콜과 간단한 시나리오에서 94.4%, 복잡한 시나리오에서 80%의 성공률을 달성했습니다.



### 3DPX: Progressive 2D-to-3D Oral Image Reconstruction with Hybrid MLP-CNN Networks (https://arxiv.org/abs/2408.01292)
Comments:
          accepted by MICCAI 2024

- **What's New**: 최근 연구에서 2D 파노라마 X-레이(Panoramic X-ray, PX) 영상에서 직접 3D 구조를 재구성하는 방법론인 3DPX를 제안했습니다. 3DPX는 다층 퍼셉트론(MLP)과 컨볼루션 신경망(CNN)을 결합하여 점진적으로 3D 이미지를 재구성하는 새로운 네트워크입니다.

- **Technical Details**: 3DPX는 프로그래시브 하이브리드 MLP-CNN 피라미드 네트워크로, 단계별 재구성을 통해 중간 결과물에 지침을 부여합니다. MLP의 장점을 활용하여 장거리 의존성(Fine-grained long-range dependency)을 캡처하고, CNN을 통해 이웃 픽셀 정보를 효과적으로 사용합니다. 이는 전정맥(CNNs)의 기존 한계를 극복하는 방법입니다.

- **Performance Highlights**: 464개의 연구를 포함하는 두 개의 대규모 데이터셋에서 실험한 결과, 3DPX는 기존 최첨단 2D-to-3D 구강 재구성 방법들보다 더 우수한 재구성 품질을 보여줬습니다. 또한, 치아의 각도 비정렬 감지 및 분류 작업에서도 성능 향상을 보였습니다.



### Deep Learning based Visually Rich Document Content Understanding: A Survey (https://arxiv.org/abs/2408.01287)
Comments:
          Work in Progress

- **What's New**: 최근 문서 이해에서의 발전은 Visually Rich Documents (VRDs; 시각적 요소가 풍부한 문서)의 정보 추출을 크게 개선하였습니다. 이 논문은 그중에서도 딥러닝 기반의 Visually Rich Document Understanding (VRDU; 시각적 요소가 풍부한 문서 이해) 프레임워크에 대한 종합적인 리뷰를 제공하고 있습니다. 이는 다양한 도메인에서 사용되는 VRDs의 이해를 높이는 데 기여할 것으로 기대됩니다.

- **Technical Details**: VRD는 텍스트와 시각적 요소(예: 표, 차트, 다이어그램, 사진)가 혼합된 문서로, 이러한 요소들은 정보의 포괄적이고 시각적으로 매력적인 전달을 목표로 합니다. 전통적인 정보 추출 방법은 전문가 지식과 수작업을 필요로 하여 비효율적이지만, 딥러닝의 발전으로 이를 개선할 수 있게 되었습니다. 이 논문에서는 딥러닝 기반 VRDU 모델들이 사용하는 다양한 전략과 다운스트림 과업에 대해 체계적으로 조사하고 분석합니다. 주요 기술적 측면으로는 Feature Representation (특징 표현)과 Fusion (융합), Model Architecture (모델 아키텍처), Pretraining Techniques (사전 훈련 기법) 등이 있습니다.

- **Performance Highlights**: 딥러닝 기반 VRDU 모델들은 다양한 다운스트림 과업에서 최첨단 성능을 달성하였습니다. LSTM과 CNN 기반 모델들 뿐만 아니라, Layout-aware Pretrained Frameworks (레이아웃 인식 사전 훈련 프레임워크) 및 Visual-integrated Pretrained Frameworks (시각적 통합 사전 훈련 프레임워크)도 문서 표현을 크게 향상시켰습니다. 이러한 모델들은 Key Information Extraction (중요 정보 추출)과 Question Answering (질문 답변)에서 높은 정확도와 효율성을 보였습니다.

- **Future Directions**: 논문은 VRDU의 새로운 동향과 도전 과제를 식별하고, 미래 연구 방향 및 실질적 응용에 대한 통찰을 제공합니다. 특히, multi-modal learning methods (다중 모달 학습 방법)과 LLM-based frameworks (대형 언어 모델 기반 프레임워크)는 향후 VRDU의 주요 연구 분야로 주목되고 있습니다.



### Out-Of-Distribution Detection for Audio-visual Generalized Zero-Shot Learning: A General Framework (https://arxiv.org/abs/2408.01284)
- **What's New**: 이 논문에서는 Audio-Visual Generalized Zero-Shot Learning (AV-GZSL)을 위한 새로운 프레임워크를 소개합니다. 이 프레임워크는 기존의 임베딩 기반(embedding-based) 방법과 생성 기반(generative-based) 방법을 통합하여 두 접근법의 장점을 활용하고 단점을 보완하는 방식입니다. 특히, Out-Of-Distribution (OOD) 탐지를 사용하여 보이지 않는 클래스의 특징(feature)을 합성하고 이를 탐지기와 함께 분류기(classifier)를 훈련시키는 것을 제안합니다.

- **Technical Details**: 프레임워크는 우선 Generative Adversarial Networks(GANs)를 활용하여 보이지 않는 특징을 합성합니다. 그리고 이 특징과 함께 OOD 탐지기 및 시각적, 청각적 입력을 위한 두 개의 분류기를 훈련시킵니다. 이 방식으로 테스트 특징이 나타났을 때 해당 특징이 보이는 클래스인지 보이지 않는 클래스인지 판별하고, 각각에 맞는 분류기로 분류합니다.

- **Performance Highlights**: 세 가지 널리 사용되는 오디오-비쥬얼 데이터셋에서 실험한 결과, 기존 최첨단(state-of-the-art) 접근법들에 비해 성능이 크게 향상되었습니다. 코드 및 자료는 

- **https URL**: 



### Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition (https://arxiv.org/abs/2408.01139)
Comments:
          Accepted by Transactions on Machine Learning Research (TMLR 2024)

- **What's New**: 이 연구는 이미지 모델의 섭동강건성(Perturbation robustness)을 해석하기 위해 모델 독립적이고 전역적인 해석 방법을 제안합니다. 본 연구는 두 가지 주요 측면에 의해 동기 부여되었습니다. 첫째, 이전의 전역 해석 연구와 강건성 벤치마크(mean corruption error, mCE)는 이미지 모델 내의 섭동강건성 메커니즘을 직접적으로 해석할 수 있도록 설계되지 않았습니다. 둘째, 자연 이미지의 주파수에 따른 스펙트럼 신호 대 잡음 비율(SNR)이 지수적으로 감소하는 것을 관찰했습니다.

- **Technical Details**: 이 방법은 Shapley value 이론을 적용하여 정보 이론 프레임워크 내에서 강건(FRF) 기능과 비강건(NRF) 기능의 예측력을 계량적으로 평가합니다. I-ASIDE(Image Axiomatic Spectral Importance Decomposition Explanation)라고 명명된 이 방법은 모델의 강건성 메커니즘에 관한 독특한 통찰력을 제공합니다. empiri 연구에서, 주파수에 따른 스펙트럼 SNR이 power-law 형태의 분포를 보이는 것을 입증했습니다. 또한 저주파 신호는 일반적으로 고주파 신호보다 더 강건하지만, 저주파 신호만으로는 높은 분류 정확도를 달성할 수 없음을 알게 되었습니다.

- **Performance Highlights**: 광범위한 실험을 통해 I-ASIDE가 이미지넷(ImageNet)에 사전 학습된 다양한 비전 모델에서 섭동강건성을 측정하고 메커니즘에 대한 해석을 제공할 수 있음을 보여주었습니다. 특히, 저주파 신호로 훈련된 모델이 고주파 신호로 훈련된 모델보다 더 높은 강건성을 보인다.



### Privacy-Preserving Split Learning with Vision Transformers using Patch-Wise Random and Noisy CutMix (https://arxiv.org/abs/2408.01040)
Comments:
          23 pages, 11 figures, 8 tables, to be published in Transactions on Machine Learning Research (TMLR)

- **What's New**: 새로운 DP-CutMixSL 프레임워크가 제안되었습니다. 이는 CutMix 정규화에서 영감을 받아 가우시안 노이즈를 샘플 데이터에 주입하고 클라이언트 간 무작위로 선택된 패치를 혼합하여 데이터 프라이버시를 강화한 것입니다. 이 프레임워크는 특히 membership inference attacks와 reconstruction attacks, label inference attacks에 대해 더 높은 프라이버시 보호를 제공합니다.

- **Technical Details**: DP-CutMixSL은 비전 트랜스포머(Vision Transformer, ViT)의 분산 학습을 위해 개발된 프레임워크입니다. ViT는 주로 대규모 데이터셋에서 높은 성능을 발휘하지만, 작은 데이터셋에서는 성능 저하가 발생합니다. 분할 학습(Split Learning, SL)은 클라이언트와 서버 간의 모델 분할을 통해 이 문제를 해결하려고 합니다. 이 프레임워크는 CutMix 정규화(Yun et al., 2019)를 기반으로 하여 가우시안 노이즈를 샘플 데이터에 주입하여 프라이버시를 보호합니다.

- **Performance Highlights**: 시뮬레이션 결과, DP-CutMixSL은 membership inference attacks뿐만 아니라 reconstruction attacks 및 label inference attacks에서도 기존 방법보다 우수한 프라이버시 보호 성능을 보여줍니다. 실험을 통해 프라이버시 보장 외에도 높은 정확도를 달성한 것이 입증되었습니다.



### Structure from Motion-based Motion Estimation and 3D Reconstruction of Unknown Shaped Space Debris (https://arxiv.org/abs/2408.01035)
Comments:
          6 pages, 10 figures. Manuscript accepted at the 2024 IEEE 20th International Conference on Automation Science and Engineerin (CASE 2024)

- **What's New**: 우주 쓰레기 문제의 심각성을 해결하기 위해, 기존의 3D 데이터 없이 2D 이미지만을 이용하여 구조에서 모션(SfM, Structure from Motion) 기반 알고리즘을 통해 우주 쓰레기의 모션을 정확하게 추정하는 방법을 제안했습니다. 이 방법은 제한된 리소스를 사용하여 우주에서 목표물의 모양과 상대적인 자세 궤적을 동시에 재구성하고 예측할 수 있습니다.

- **Technical Details**: SfM 기반 방법은 다중 뷰에서 촬영된 2D 이미지를 입력으로 받아 다음과 같은 작업을 수행합니다: 1) 이미지에서 특징점을 감지하고 추출, 2) 추출된 특징점들을 매칭하여 객체와 카메라 사이의 상대적인 위치와 방향 변화를 계산, 3) 번들 조정을 통해 재구성된 형상 포인트 및 상대적인 자세를 최적화. 이러한 과정에는 OpenSfM과 같은 오픈 소스 라이브러리를 활용했습니다. 또한, 백그라운드 제거를 위해 rembg와 U2-net 모델을 사용했습니다.

- **Performance Highlights**: 현실적인 마이크로중력 환경을 재현한 2D 공기 부양 테스트베드와 3D 운동 시뮬레이터를 통해 검증된 본 방법은 다중 뷰 이미지 세트를 이용하여 객체의 3D 형상 및 상대적 자세 궤적을 성공적으로 재구성했습니다. 결과적으로, 이 방법은 고밀도의 점 구름 재구성보다는 중간 품질과 계산비용의 균형을 맞추는 OpenSfM을 통해 기록적으로 효율적인 모션 예측을 달성했습니다.



### PINNs for Medical Image Analysis: A Survey (https://arxiv.org/abs/2408.01026)
- **What's New**: 의료 영상 분석(MIA) 분야에서 물리 정보를 통합하는 기계 학습 프레임워크가 혁신을 이끌고 있습니다. 이 연구는 MIA 작업(예: 레지스트레이션, 생성, 분류, 재구성)에서 물리 정보를 활용하는 방법을 탐구하고, 80편 이상의 논문을 체계적으로 리뷰하여 PIMIA(Physics-Informed Medical Image Analysis)의 새로운 통합 분류 체계를 제안합니다.

- **Technical Details**: 이 논문은 PIMIA 작업을 위해 물리적 지식과 과정을 모델링하는 방법, 해당 데이터를 MIA 모델에 통합하는 전략을 다룹니다. 각 작업별로 중심이 되는 물리 기반 작업, 대상 영역(인체 해부학 기준), 대응하는 영상 기법, 모델 학습에 사용된 데이터셋, 채택된 딥 네트워크 아키텍처 및 사용된 주요 물리 과정, 방정식 또는 원리를 표 형식으로 정리하여 제시했습니다.

- **Performance Highlights**: PIMIA 방법의 성능을 비교할 새로운 메트릭을 도입하며, 주요 과제와 개방형 연구 질문, 미래 연구 방향을 요약했습니다. 또한, 물리 우선순위 선택 및 표준 벤치마킹 플랫폼 구축과 같은 PIMIA의 주요 과제들을 강조했습니다.



### A dual-task mutual learning framework for predicting post-thrombectomy cerebral hemorrhag (https://arxiv.org/abs/2408.00940)
- **What's New**: 이 논문은 초기 CT 스캔만을 사용하여 수술 후 뇌출혈을 예측하는 새로운 프레임워크를 제안합니다. 이는 기존의 여러 번 CT 스캔을 통해서만 가능했던 출혈 모니터링 과정을 혁신적으로 개선합니다.

- **Technical Details**: 제안된 프레임워크는 이중 작업 상호 학습 프레임워크(dual-task mutual learning framework)로 구성되어 있으며, 초기 CT 스캔을 입력으로 하여 후속 CT 스캔과 예후 라벨을 동시에 예측합니다. 모델은 자가 주의 메커니즘(self-attention)과 상호작용 주의 메커니즘(interactive attention)을 통합하여 이미지 내 고밀도 영역에 집중하고, 예측 작업 간의 종속성을 모델링합니다.

- **Performance Highlights**: 임상 데이터를 사용한 실험에서, 제안된 방법론은 최첨단 방법들보다 더 우수한 품질의 후속 CT 스캔을 생성하며, 86.37%의 정확도로 예후 라벨을 예측합니다. 이는 시기적절한 수술 후 뇌출혈 스크리닝을 가능하게 하며, 뇌경색 관련 시술의 임상 과정을 크게 혁신할 수 있습니다.



### CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression (https://arxiv.org/abs/2408.00938)
- **What's New**: 특발성 폐섬유증(Intropic Pulmonary Fibrosis, IPF)의 진행을 예측하기 위해 새로운 확산 모델(diffusion model)을 개발했습니다. 이 모델은 환자의 초기 컴퓨터 단층촬영(CT) 스캔에서 팔로우업 CT 스캔을 생성함으로써 질병의 진행 상황을 예측합니다. 이는 기존의 1년 간격의 CT 스캔을 통한 진단 방법의 문제점을 해결하고자 합니다.

- **Technical Details**: 기존 확산 모델을 개선하여 CIResDiff(Clinically-Informed Residual Diffusion) 모델을 제안합니다. 주요 개선 사항은 다음과 같습니다: 1) 대상 영역 사전 등록(target region pre-registration)을 통해 서로 다른 시간대의 CT 스캔을 정렬하여 생성 난이도를 줄임, 2) 전통적 확산 대신 잔여 확산(residual diffusion)을 채택하여 모델이 두 CT 스캔 간의 차이(병변)에 집중할 수 있게 함, 3) CLIP 기술 기반의 임상 정보 통합 과정을 설계하여 폐 기능 정보와 CT 스캔 정보를 활용합니다.

- **Performance Highlights**: 임상 데이터를 기반으로 한 광범위한 실험에서 CIResDiff 모델이 최첨단 기술을 능가하며 IPF 진행을 효과적으로 예측할 수 있음을 증명하였습니다.



### Temporal Evolution of Knee Osteoarthritis: A Diffusion-based Morphing Model for X-ray Medical Image Synthesis (https://arxiv.org/abs/2408.00891)
- **What's New**: 본 연구는 새로운 딥러닝 모델을 도입하여 환자의 건강한 무릎 X-ray와 심한 KOA(Knee Osteoarthritis) 단계 사이의 중간 X-ray 이미지를 합성합니다. 제안된 모델은 건강한 무릎 X-ray를 기반으로 여러 단계의 KOA X-ray 이미지를 생성할 수 있습니다. 특히, Denoising Diffusion Probabilistic Model을 수정하여 'Diffusion-based Morphing Model'을 도입했습니다.

- **Technical Details**: 제안된 접근 방식은 확산(diffusion) 모듈과 변형(morphing) 모듈을 통합합니다. 모델은 소스 및 타겟 무릎 X-ray 이미지 사이의 공간 변형 세부 사항을 포착하고 기하학적 경로를 따라 중간 프레임을 합성합니다. 하이브리드 손실(hybrid loss)을 사용하여 확산 손실(diffusion loss), 변형 손실(morphing loss) 및 감독 손실(supervision loss)을 통합했습니다. 실험 결과는 OsteoArthritis Initiative (OAI) 데이터베이스를 사용하여 검증되었습니다.

- **Performance Highlights**: 제안된 접근 방식은 가장 높은 시간 프레임 합성 성능을 기록했습니다. 이는 KOA 진행을 시뮬레이션하고 분류 모델을 위한 데이터를 효과적으로 증강하는 데 유용합니다. 생성된 X-ray 이미지는 KOA의 진행을 실제적으로 반영하면서 원본 이미지의 구조적 및 질감적 무결성을 유지하는 것으로 나타났습니다.



### HOAA: Hybrid Overestimating Approximate Adder for Enhanced Performance Processing Engin (https://arxiv.org/abs/2408.00806)
- **What's New**: 이 논문은 하이브리드 과대추정 근사 덧셈기(Hybrid Overestimating Approximate Adder, HOAA)를 소개하며, 엣지 AI 애플리케이션에서 성능을 향상시키기 위해 설계되었습니다. 새로운 Plus One Adder 설계를 제안하여 전통적인 Ripple Carry Adder(RCA) 체인에 통합되고, 하드웨어 복잡성을 줄이면서 자원 효율성을 개선합니다. 제안된 디자인은 동적으로 재구성 가능한 HOAA에 통합되어 런타임 내에서 정확 모드와 근사 과대추정 모드 간의 교체가 가능합니다.

- **Technical Details**: 제안된 디자인은 자원 효율적인 Plus One Adder (P1A)를 포함하며, RCA 체인에 통합할 수 있도록 설계되어 1을 초과하는 출력을 제공합니다. 특정 출력을 근사하여 하드웨어 오버헤드를 줄이고, 에러 메트릭을 평가합니다. 이와 함께 HOAA 아키텍처는 여러 산술 연산을 동일한 하드웨어 블록으로 지원할 수 있도록 런타임 교체가 가능한 동적 재구성 기능을 갖췄습니다. 이를 통해 하나의 클럭 사이클을 절약할 수 있습니다. 다양한 테스트 케이스에 대해 평가되며, Monte Carlo 기반의 에러 거리 계산이 제공됩니다. 또한, 아날로그 소자(ASIC) 물리 디자인의 CMOS 28nm 성능 파라미터를 평가합니다.

- **Performance Highlights**: 제안된 HOAA는 최첨단 디자인과 비교하여 면적 효율성이 21% 향상되고, 전력 소모가 33% 감소하는 결과를 보였습니다. 이는 매우 적은 정확도 손실로 확인되었습니다. HOAA는 하드웨어 효율성과 계산 정확도 간의 이상적인 균형을 제공하며, 리소스가 제한된 환경에서 매우 유망한 솔루션이 될 수 있습니다.



### CCSRP: Robust Pruning of Spiking Neural Networks through Cooperative Coevolution (https://arxiv.org/abs/2408.00794)
- **What's New**: 본 연구에서는 Spiking Neural Networks (SNNs)의 컴팩트성과 강인성(robustness)을 동시에 향상시키기 위한 새로운 방법론인 CCSRP를 제안합니다. CCSRP는 Cooperative Co-evolution에 기반하여 SNN을 효과적으로 prune(정리)하는 혁신적인 방법을 제시합니다.

- **Technical Details**: CCSRP는 세 가지 목표(accuracy, robustness, compactness)를 동시에 최적화하는 tri-objective optimization 문제로서, 협력적 공동 진화 프레임워크(cooperative co-evolutionary pruning framework)를 사용하여 각 layer의 filter를 독립적으로 pruning하는 방식을 채택하고 있습니다. 이를 통해 느리고 반복적인 실험 없이도 효율적으로 모델을 경량화할 수 있습니다.

- **Performance Highlights**: CIFAR-10 및 SVHN 데이터셋에 대한 실험 결과, CCSRP는 기존 최신 방법론과 동등하거나 그 이상의 성능을 보여주었습니다. 이로써 자원 제한적이고 안전이 중요한 환경에서도 SNN의 실용적 적용 가능성을 높였습니다.



### Hands-on STEM Learning Experiences using Digital Technologies (https://arxiv.org/abs/2408.00781)
Comments:
          9 pages, 10 figures

- **What's New**: 이탈리아 학교에서 진행된 혁신적인 STEM 교육 접근 방식의 경험과 활동을 공유했습니다. 학생들이 협력, 창의성, 비판적 사고, 실험, 시제품 제작, 의사소통 및 문제 해결과 같은 핵심 역량을 개발하는 다양한 프로젝트를 소개합니다. 디지털 제작 기술을 활용한 STEM 학습의 효과와 이점을 보여줍니다.

- **Technical Details**: 이 접근법은 지속 가능한 발전을 위한 2030 UN 의제에 의해 동기부여되었습니다. 이를 지원하기 위해, FabLab에서 구현된 디지털 제어 기술들이 사용됩니다. 이에는 복잡한 3D 프린팅 구조, 대형 마이크로컨트롤러 보드 복제물, 풍동역학 및 작은 보이지 않는 기본 입자의 시각화 등이 포함됩니다. FabLabs는 3D 프린팅, 레이저 커터, CNC 기계와 같은 저비용, 최첨단 도구들을 제공합니다. 또한 장애가 있는 학생들도 과학에 참여할 수 있도록 다양한 기회를 제공합니다.

- **Performance Highlights**: FabLab에서 제작된 시제품들을 통해 학생들이 실제로 실습하는 과정을 통해 STEM 교육의 질을 높였습니다. FDM 기술을 사용한 3D 프린팅은 수학적 구조부터 생물학적 표본까지 복잡한 3D 객체를 재현할 수 있게 하여 많은 학교와 교육 기관의 STEM 교육 프로그램에 이바지했습니다. Arduino Uno 같은 마이크로컨트롤러를 사용한 교육 프로젝트는 학생들에게 저렴하고 다용도적인 학습 기회를 제공하며, 블록 기반 코딩을 통해 초등학교 학생들도 쉽게 접근할 수 있도록 했습니다. 대형 아두이노 복제, DIY 풍동 튜브 등의 프로젝트는 학생들이 과학적 개념을 더 깊이 이해하는 데 도움을 줍니다.



### In-Depth Analysis of Emotion Recognition through Knowledge-Based Large Language Models (https://arxiv.org/abs/2408.00780)
Comments:
          7 pages

- **What's New**: 이번 논문은 상황 맥락(Context)을 통합한 감정 인식에 대한 새로운 접근 방식을 제안합니다. 기존의 자동 감정 인식이 표정만을 독립적으로 분석하는 데 주로 집중한 반면, 본 연구는 심리학 이론에 기반해 상황 기반의 감정 인식 방법을 설계하고, 이를 통해 감정 인식 정확도를 높일 수 있음을 증명했습니다.

- **Technical Details**: 제안된 방법은 감정 인식의 세 가지 주요 단계로 구성됩니다. 첫째, 상황 맥락 없이 표정만으로부터 감정을 예측합니다. 둘째, 상황 설명만을 통해 감정을 예측합니다. 마지막으로, Bayesian Cue Integration(BCI)를 통해 두 분리된 정보원을 통합합니다. 이를 통해 감정 인식의 정밀성을 크게 향상시켰습니다. 테스트는 감정적 사회 과제인 죄수의 딜레마(prisoner’s dilemma)를 바탕으로 수행되었습니다.

- **Performance Highlights**: 비교 결과, 최상의 자동 감정 인식 방법은 인간 관찰자와 유사한 성능을 보여주었습니다. 특히, LSTM 모델과 GPT-4를 이용한 BCI는 다른 방법들에 비해 상황 맥락을 반영한 감정 인식에서 우수한 성능을 나타냈습니다. Fig. 4와 Fig. 5를 통해 맥락을 통합한 감정 인식이 보다 다양한 감정 예측을 가능하게 하는 것을 확인할 수 있습니다.



### Fuzzy Logic Approach For Visual Analysis Of Websites With K-means Clustering-based Color Extraction (https://arxiv.org/abs/2408.00774)
Comments:
          The work has been submitted to Herald of KBTU journal

- **What's New**: 본 논문은 웹사이트 디자인 미학이 사용자 경험을 향상시키는 데 중요한 역할을 한다는 점을 탐구합니다. 전 세계 인터넷 사용자가 증가함에 따라, 웹사이트의 첫인상이 사용자에게 주는 영향이 큰 것으로 나타났습니다. 특히, 첫인상은 50 밀리초 내에 형성되는 경우가 많습니다. 이 논문에서는 색상의 조화와 폰트의 인기도를 기반으로 웹사이트 미학을 측정하는 새로운 방법을 소개합니다. 이를 위해 퍼지 로직(fuzzy logic)을 사용하여 미적 선호도를 예측합니다.

- **Technical Details**: 색상의 조화(color harmony)와 폰트 인기도(font popularity)를 기반으로 웹사이트 미학을 예측하는 새로운 방법이 소개되었습니다. 약 200개의 인기 있고 자주 사용되는 웹사이트 디자인으로 구성된 데이터를 수집하여, k-평균 클러스터링(k-means clustering)을 사용해 웹사이트 스크린샷에서 주요 색상(dominant colors)을 추출했습니다. 퍼지 로직(fuzzy logic)을 활용해 미적 선호도를 예측했으며, 이는 빠르게 변하는 웹 디자인 트렌드에 적응할 수 있는 방법론입니다.

- **Performance Highlights**: 이 연구의 결과는 웹사이트 미학과 사용성(usability) 간의 관계에 대한 이해를 증진시키는 데 목적이 있습니다. 새로운 평가 방법론을 통해 사용자들에게 더욱 매력적이고 사용하기 쉬운 웹사이트를 설계하는 데 기여할 수 있을 것으로 기대됩니다.



### Hybrid Deep Learning Framework for Enhanced Melanoma Detection (https://arxiv.org/abs/2408.00772)
- **What's New**: 전 세계적으로 사망 원인 1위인 암 문제를 해결하기 위해 새로운 흑색종(melanoma) 검출 프레임워크를 소개합니다. 이 프레임워크는 U-Net과 EfficientNet을 결합하여 피부 이미지의 세그멘테이션(segmentation)과 분류(classification)를 효율적으로 수행합니다. 우리의 연구는 흑색종 검출의 정확성과 효율성을 높이는 데 초점을 맞추고 있습니다.

- **Technical Details**: 우리는 HAM10000 데이터셋을 사용해 U-Net 모델을 훈련시켜 암 부위를 정밀하게 세그멘테이션하였습니다. 동시에 ISIC 2020 데이터셋을 활용해 EfficientNet 모델을 훈련시켜 피부암의 이진 분류를 최적화했습니다. 이 하이브리드 모델은 세그멘테이션과 분류 작업 모두에서 뛰어난 성능을 보여줍니다.

- **Performance Highlights**: 우리 모델은 ISIC 2020 데이터셋에서 99.01%의 놀라운 정확도를 달성했습니다. 이는 기존 모델 구조에 비해 상당한 성능 향상을 보여주며, 자세한 실험 결과는 우리 방법이 높은 정확성과 신뢰성을 갖추고 있음을 입증합니다.



### Optimizing Diffusion Models for Joint Trajectory Prediction and Controllable Generation (https://arxiv.org/abs/2408.00766)
Comments:
          30 pages, 20 figures, Accepted to ECCV 2024

- **What's New**: 최신 연구에서는 자율 주행에서의 궤적 예측 및 제어 가능한 생성 작업을 개선하기 위해 Optimal Gaussian Diffusion (OGD)와 Estimated Clean Manifold (ECM) Guidance라는 두 가지 새로운 방법론을 제안했습니다. OGD는 작은 확산 시간 $T$에 대한 최적의 사전 분포를 최적화하고 여기서부터 역확산 프로세스를 시작합니다. ECM은 네트워크 전체에 걸친 광범위한 그래디언트 역전파를 제거하고 예측된 클린 매니폴드로 직접 가이드 그래디언트(gradient)를 주입하여 계산 비용을 줄입니다.

- **Technical Details**: OGD는 표준 정규 분포로부터 표본을 생성하는 대신, 특정 진동 수준에서 중간 데이터 분포와의 거리를 최소화하는 최적의 정규 분포에서 역확산 과정을 시작합니다. 이를 통해 추가 모델 학습 없이 유연한 확산 단계를 조정할 수 있습니다. ECM은 청정 데이터 매니폴드에서 다목적 최적화 문제로 가이드 샘플링을 수행하며, 전체 확산 모델을 통한 역전파 없이 그래디언트를 직접 주입하는 방식입니다. 이는 빠른 추론 시간과 향상된 성능을 제공합니다.

- **Performance Highlights**: Argoverse 2 데이터셋에서 실험한 결과, OGD는 기존 확산 모델 대비 12분의 1의 확산 단계만을 사용하면서도 더 나은 궤적 예측 성능을 달성했습니다. 또한 ECMR은 OGD와 결합되어, 유사한 현실성을 유지하면서 기존 가이드 샘플링 방식 대비 5분의 1의 추론 단계만으로도 낮은 가이드 비용(sample with significantly lower guidance costs)을 나타냈습니다.



### MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities (https://arxiv.org/abs/2408.00765)
Comments:
          Extension of MM-Vet: arXiv:2308.02490

- **What's New**: MM-Vet v2가 새롭게 출시되어 더욱 발전된 대형 멀티모달 모델을 평가합니다. 이번 버전에서는 '이미지-텍스트 시퀀스 이해(image-text sequence understanding)'라는 새로운 VL 능력이 추가되었습니다. 이를 통해 모델의 이미지와 텍스트가 혼합된 시퀀스를 처리하는 능력을 평가할 수 있습니다.

- **Technical Details**: 기존 MM-Vet는 단일 이미지-텍스트 쌍을 기반으로 질문 형식을 제한했지만, MM-Vet v2는 이 제한을 극복하고 이미지를 <image>으로 나타내는 시퀀스 이해를 포함하도록 개선되었습니다. 새로운 데이터셋은 높은 품질을 유지하면서도 평가 샘플 수를 517개로 확장하였습니다. 질문 생성과 참조 답안 작성은 연구자들이 직접 설계하고 GPT-4V의 초안을 검토 및 수정하는 과정을 거쳤습니다.

- **Performance Highlights**: MM-Vet v2를 활용한 대형 멀티모달 모델 평가에서 Claude 3.5 Sonnet이 71.8점으로 최고 성능을 기록하였고, GPT-4o가 71.0점으로 그 뒤를 이었습니다. 특히, 오픈-웨이트 모델 중에서는 InternVL2-Llama3-76B가 68.4점으로 우수한 성능을 보였습니다.



### UniTalker: Scaling up Audio-Driven 3D Facial Animation through A Unified Mod (https://arxiv.org/abs/2408.00762)
- **What's New**: 최근 발표된 논문에서는 음성 기반 3D 얼굴 애니메이션 생성에 대한 주요 한계를 극복하기 위해 'UniTalker'라는 통합 모델을 제안했습니다. 이 모델은 다양한 주석 방식(different annotations)이 있는 여러 데이터셋을 효과적으로 활용하기 위해 멀티-헤드(multi-head) 아키텍처를 특징으로 합니다. 또한, 논문은 18.5 시간에 달하는 다양한 언어의 음성을 포함한 A2F-Bench라는 새로운 대규모 데이터셋을 공개했습니다.

- **Technical Details**: UniTalker는 PCA, model warm-up, pivot identity embedding 등 세 가지 훈련 전략을 사용하여 훈련 안정성을 높이고 멀티-헤드 출력 간의 일관성을 보장합니다. 특히 PCA는 vertex 기반 주석을 처리하기 위한 차원 축소에 사용되며, pivot identity embedding은 데이터셋 편향을 줄이는 데 도움을 줍니다. 그리고 A2F-Bench는 다섯 개의 공개 데이터셋과 세 개의 새롭게 마련된 데이터셋을 포함하여 총 18.53 시간의 다양한 오디오 데이터를 제공합니다.

- **Performance Highlights**: 단일 UniTalker 모델은 BIWI 데이터셋에서 9.2%, Vocaset에서 13.7%의 입술 vertex 오류(lip vertex error)를 감소시키는 성과를 보였습니다. 더욱이, 미리 훈련된 UniTalker 모델을 기반으로 각 데이터셋을 미세 조정한 결과, 평균 6.3%의 오류 감소를 달성했습니다. 또한, 미리 훈련된 UniTalker를 새로운 데이터셋에서 반만 사용해도 이전 상태의 모델 성능을 능가할 수 있음을 보여주었습니다.



### Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention (https://arxiv.org/abs/2408.00760)
- **What's New**: 이번 연구에서는 무조건 이미지 생성을 위한 새로운 지도 방법론인 Smoothed Energy Guidance (SEG)를 제안합니다. 이는 에너지 기반의 자기-주의 메커니즘(self-attention mechanism)을 활용하여 이미지 생성을 개선하는 방법입니다.

- **Technical Details**: SEG는 자기-주의의 에너지 관점에서 출발하여 에너지 함수의 커브를 직접적으로 조정하여 무조건적인 예측을 수행합니다. 구체적으로, Gaussian kernel 파라미터를 조정하여 에너지 랜드스케이프의 커브를 조절하고, 쿼리 블러링(query blurring) 기법을 도입하여 복잡성을 줄입니다.

- **Performance Highlights**: 다양한 실험에서 SEG는 기존 방법보다 구조적 변화가 적고, 샘플 품질이 향상되었습니다. 특히 ControlNet을 활용한 실험에서도 뛰어난 성과를 보였습니다.



### Text-Guided Video Masked Autoencoder (https://arxiv.org/abs/2408.00759)
Comments:
          Accepted to ECCV 2024

- **What's New**: 이 논문에서는 비디오 마스크드 오토인코더(MAE)에 대해 새로운 텍스트-가이드 마스킹 알고리즘(text-guided masking, TGM)을 소개합니다. 기존의 시각적 단서에 의존하는 마스킹 알고리즘 대신, 텍스트 설명을 사용해 비디오에서 가장 중요한 부분을 마스킹합니다. 동시에 MAE를 마스킹된 비디오-텍스트 대비 학습(masked video-text contrastive learning)과 통합하는 프레임워크도 제안했습니다.

- **Technical Details**: 기존의 모션 가이드 마스킹(motion-guided masking)과는 달리, TGM은 캡션과 가장 높은 상관관계를 가지는 비디오 영역을 마스킹합니다. 이를 위해, 캡션이 제공하는 의미를 활용하여 중요한 비디오 부분을 추출합니다. 그리고 MAE와 마스킹된 비디오-텍스트 대비 학습을 결합하여, 텍스트와 비디오 인코더 표현의 정렬을 도모합니다. 이러한 방법은 기존의 시각적 단서를 필요로 하지 않으며, 텍스트 기반의 풍부한 정보를 활용합니다.

- **Performance Highlights**: TGM은 Kinetics-400 (K400)과 Something-Something V2 (SSv2) 데이터셋에서의 섬세한 학습(finetuning) 성능에서 모션 가이드 마스킹을 각각 최대 1.3%, 0.5% 상회했으며, 선형 평가(linear evaluation)에서도 최대 1.7%의 성능 향상을 보였습니다. 또한, 다양한 액션 인식 데이터셋 및 자아 인식 데이터셋에서도 뛰어난 성능을 입증했습니다.



### Segment anything model 2: an application to 2D and 3D medical images (https://arxiv.org/abs/2408.00756)
Comments:
          11 pages, 7 figures. A first attempt on evaluating SAM 2 on medical images

- **What's New**: Segment Anything Model (SAM)에서 발전한 SAM 2가 기존의 이미지 분할 기능을 비디오 입력으로 확장했습니다. 이로 인해 SAM을 3D 의료 이미지에 적용할 수 있는 가능성이 열리게 되었습니다. 이번 논문은 SAM 2의 2D 및 3D 의료 이미지 분할 능력을 종합적으로 평가합니다.

- **Technical Details**: 논문은 18개의 다양한 의료 영상 데이터셋을 사용하여 SAM 2를 평가합니다. 데이터셋에는 MRI, CT, PET 등의 3D 모달리티 뿐만 아니라 X-ray 및 초음파 같은 2D 모달리티도 포함됩니다. 평가에는 두 가지 파이프라인을 고려합니다: (1) 멀티 프레임 3D 분할 (multi-frame 3D segmentation)과 (2) 싱글 프레임 2D 분할 (single-frame 2D segmentation). 각각의 프레임에 프롬프트(주석)를 제공하는 싱글 프레임 2D 분할은 2D 및 3D 모달리티 모두에 적용되며, 멀티 프레임 3D 분할은 주로 3D 모달리티에 적용됩니다.

- **Performance Highlights**: SAM 2는 싱글 프레임 2D 분할에서는 SAM과 비슷한 성능을 보였지만, 멀티 프레임 3D 분할에서는 주석을 입력할 슬라이스 선택, 예측 방향, 프레임 간 전파 등의 조건에 따라 성능이 달라질 수 있다는 결과를 보여주었습니다.



### Coarse Correspondence Elicit 3D Spacetime Understanding in Multimodal Language Mod (https://arxiv.org/abs/2408.00754)
Comments:
          project page: this https URL

- **What's New**: 논문 'Coarse Correspondence: A Visual Prompting Method for 3D and Temporal Understanding in Multimodal Language Models'에서 저자들은 3D 공간과 시간적 변화를 이해하는 멀티모달 언어 모델(Multimodal Language Models, MLLMs)의 성능을 개선하기 위해 Coarse Correspondence라는 새로운 시각 프롬프팅(visual prompting) 방법을 소개했습니다. 이 방법은 경량화된 추적 모델(lightweight tracking model)을 사용하여 여러 프레임 또는 이미지 셋 간의 객체 대응을 찾아냅니다.

- **Technical Details**: Coarse Correspondence 방법은 비디오 내에서 객체의 빈도를 계산하고, 가장 빈번하게 등장하는 객체들을 고유한 ID 마커로 시각화하는 방식입니다. 이 접근법은 기존의 질문이나 작업과 독립적으로 이미지를 수정하며, 수정된 이미지를 MLLM에 전달합니다. 저자들은 이 방법을 통해 GPT-4V, GPT-4O와 같은 다양한 MLLMs에서 실험을 진행했습니다.

- **Performance Highlights**: 이 논문에서 제안된 Coarse Correspondence 방법은 3D 이해 benchmark인 ScanQA에서 +20.5%, OpenEQA의 한 부분에서 +9.7%, 그리고 긴 영상 이해 benchmark인 EgoSchema에서 +6.0%의 성능 향상을 달성했습니다. 또한, 저자들은 새로운 진단 데이터셋을 통해 MLLMs의 공간적 관점 이해 능력을 평가했으며, 이 방법이 GPT-4 모델의 성능을 개선함을 확인했습니다.



### Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer (https://arxiv.org/abs/2408.00749)
- **What's New**: 최근 연구에 따르면 수확량이 높은 농작물 품종과 직립형 잎 각도(upright leaf angles)를 가진 식물 사이에 높은 상관관계가 있음이 나타났습니다. 직립형 잎 각도를 가진 식물이 그렇지 않은 식물보다 더 많은 빛을 가두며, 이로 인해 광합성 비율이 더 높아집니다. 이러한 측정을 현장에서 자동화하는 기술이 각광받고 있습니다.

- **Technical Details**: 이 연구는 Mask R-CNN 인스턴스 세분화 인공신경망과 시각 트랜스포머인 Line Segment Transformer(LETR)을 활용하여 잎 각도를 자동 추정하는 컴퓨터 비전(CV) 파이프라인을 제안합니다. 이 파이프라인은 여름 2015-Ames ULA와 여름 2015-Ames MLA라는 두 가지 이미지 데이터셋에 적용되었습니다. 연구팀은 각각 872장과 955장의 식물 이미지를 현장에서 FieldBook(안드로이드 애플리케이션)을 사용해 수집했습니다.

- **Performance Highlights**: 제안된 파이프라인으로 추정된 잎 각도는 ImageJ로 수동 측정한 두 독립적인 값과 비교하여 코사인 유사도(Cosine Similarity) 측정 시 0.98의 유사도 점수를 기록했습니다. 이는 제안된 파이프라인이 현장에서 잎 각도를 측정하는 데 유효함을 시사합니다.



### Collaborative Vision-Text Representation Optimizing for Open-Vocabulary Segmentation (https://arxiv.org/abs/2408.00744)
Comments:
          ECCV 2024

- **What's New**: MAFT+는 CLIP의 text representation을 최적화하기 위해 Content-Dependent Transfer (CDT) 방법을 도입하여 각 텍스트 임베딩을 이미지와 상호작용함으로써 향상합니다. 또한, Representation Compensation (RC) 전략을 통해 CLIP의 zero-shot 성능을 유지하며, 시각적-텍스트 표현을 협력적으로 최적화하는 첫 번째 프레임워크를 제공합니다.

- **Technical Details**: MAFT+는 CLIP의 vision과 text representation을 함께 최적화하는 협력적인 프레임워크를 소개합니다. CDT는 Transformer Layers를 사용하여 각 입력 이미지에 따라 텍스트 임베딩을 조건화하여 파라미터 효율적인 방식으로 텍스트 표현을 최적화합니다. RC 전략은 Continual Learning에서의 Catastrophic Forgetting 문제를 방지하기 위해 원래의 CLIP-V 표현을 유지하여 zero-shot 성능을 보존합니다.

- **Performance Highlights**: MAFT+는 OVS 벤치마크에서 뛰어난 성능을 입증하였습니다. 특히, A-847, A-150, PC-459, PC-59 및 PAS-20 데이터셋에서 각각 +0.5, +2.3, +3.4, +0.4 및 +1.1 mIoU 향상을 보여주었습니다. ADE20K 데이터셋의 파노픽 설정에서는 27.1 PQ, 73.5 SQ, 32.9 RQ의 성능을 달성하였습니다.



### Virchow 2: Scaling Self-Supervised Mixed Magnification Models in Pathology (https://arxiv.org/abs/2408.00738)
- **What's New**: 이번 연구에서는 컴퓨테이셔널 병리학(computational pathology) 애플리케이션을 위한 새로운 모델, Virchow 2와 Virchow 2G를 소개합니다. Virchow 2는 632M 파라미터로 구성된 비전 트랜스포머(vision transformer) 모델이며, Virchow 2G는 1.85B 파라미터 모델로, 각각 310만 개의 전 세계 다양한 병원에서 수집된 조직 슬라이드 이미지를 사용하여 훈련되었습니다. DINOv2 훈련 알고리즘에 도메인 맞춤형 적응(domain-inspired adaptations)을 제안하여 모델 성능을 크게 향상시켰습니다.

- **Technical Details**: 이 연구에서는 두 가지 축인 데이터 크기와 모델 크기를 확장하여 진행하였습니다. Virchow 2는 기존 Virchow 모델을 확장한 것으로, 데이터셋 크기를 1.5M에서 3.1M로 늘렸습니다. Virchow 2G는 모델 크기를 1.8B 파라미터로 증가시켜 확장성을 더욱 강화했습니다. 도메인 맞춤형 개선 사항은 DINOv2 알고리즘을 기반으로 한 것으로, 다양한 병리학 이미지를 더 잘 처리할 수 있도록 최적화되었습니다.

- **Performance Highlights**: Virchow 2와 Virchow 2G는 12개의 타일 레벨(tile-level) 작업에서 경쟁 모델을 넘어서는 최고 성능을 달성했습니다. 데이터 다양성과 도메인 특화 학습이 모델 크기만 증가시키는 것보다 더 높은 성능을 제공한다는 것을 보여주었습니다. 결과적으로, 모델 확장성과 데이터 다양성, 도메인 맞춤형 학습 모두 컴퓨테이셔널 병리학 모델 성능에 긍정적인 영향을 미친다는 결론을 얻었습니다.



### TurboEdit: Text-Based Image Editing Using Few-Step Diffusion Models (https://arxiv.org/abs/2408.00735)
Comments:
          Project page: this https URL

- **What's New**: 이 연구에서는 DDPM 소음을 반전시키는 접근방식이 몇 가지 빠른 샘플링 방법에 적용될 때 발생하는 문제를 분석하고 해결책을 제안합니다. 특히 텍스트 기반 이미지 편집에서 시각적 아티팩트와 편집 강도 부족 문제를 해결하기 위해 'shifted noise schedule'과 'pseudo-guidance approach'를 도입하였습니다.

- **Technical Details**:  DDPM 소음 반전 접근방식은 각 타임스텝마다 사전 계산된 노이즈 맵을 사용하여 주어진 프롬프트에 따라 원본 이미지를 재구성하는 방법입니다. 'shifted noise schedule'을 통해 적절한 노이즈 통계를 유지하며, 'pseudo-guidance approach'를 통해 편집 강도를 높이는데 집중하였습니다. 이 방법은 덜 노이즈가 있는 스텝에서 노이즈를 제거하도록 샘플러를 설정하고, 빠른 샘플링 모델에서 주로 무시되던 마지막 스텝에서도 노이즈를 주입하는 방식입니다.

- **Performance Highlights**: 이 방법을 통해, 텍스트 기반의 이미지 편집을 단 3단계의 디퓨전 스텝만으로 가능하게 하였으며, 기존 편집 방법에 비해 속도를 5~500배 가속화하면서도 출력 품질을 유지하거나 향상시켰습니다.



### SAM 2: Segment Anything in Images and Videos (https://arxiv.org/abs/2408.00714)
Comments:
          Website: this https URL

- **What's New**: Segment Anything Model 2 (SAM 2)가 출시되었습니다. SAM 2는 이미지와 비디오에서 프롬프트 가능한 시각적 세분화(promptable visual segmentation) 작업을 해결하기 위한 기반 모델로, 사용자 상호작용을 통해 모델과 데이터를 개선하는 데이터 엔진을 만들었습니다. 이를 통해 지금까지 가장 큰 비디오 세분화 데이터셋을 수집하였습니다.

- **Technical Details**: SAM 2는 단순한 transformer 아키텍처와 스트리밍 메모리를 사용하여 실시간으로 비디오를 처리합니다. 이 모델은 특정 프레임의 포인트, 박스 또는 마스크를 입력으로 받아 세분화 마스크(‘마스크렛’)를 예측합니다. SAM 2는 객체와 이전 상호작용에 대한 정보를 저장하는 메모리 모듈을 갖추고 있습니다. 이를 통해 비디오 내에서 연속된 프레임에서도 일관된 세분화 결과를 생성합니다.

- **Performance Highlights**: SAM 2는 기존 접근 방식보다 3배 적은 상호작용으로 더 높은 정확도의 비디오 세분화를 제공합니다. 또한 이미지 세분화에서는 기존 Segment Anything Model(SAM)보다 더 정확하고 6배 빠릅니다. 최종 Segment Anything Video (SA-V) 데이터셋은 35.5백만 개의 마스크를 포함하고 있으며, 이는 기존 데이터셋보다 마스크 수가 53배 더 많습니다.



### MotionFix: Text-Driven 3D Human Motion Editing (https://arxiv.org/abs/2408.00712)
Comments:
          arXiv v1

- **What's New**: 새로운 연구 논문에서는 3D 인간 동작 편집(3D motion editing)을 텍스트 설명에 맞춰 수행하는 방법을 제시합니다. 이 연구에서는 MotionFix라는 새로운 데이터셋을 구축하여, 주어진 동작과 텍스트로 주어진 수정 사항에 따라 새로운 동작을 생성할 수 있는 모델을 개발했습니다. 이 모델은 조건부 확산 모델(conditional diffusion model)인 TMED로, 텍스트 지시사항과 소스 동작을 입력으로 받아 수정된 동작을 생성합니다.

- **Technical Details**: 연구팀은 먼저 자동화 및 반자동 방법을 통해 (i) 소스 동작, (ii) 타겟 동작, (iii) 수정 텍스트로 이루어진 트리플렛 데이터셋을 수집하여 MotionFix 데이터를 구축했습니다. 이를 통해 조건부 확산 모델 TMED를 훈련시켰습니다. 또한, 텍스트와 모션 쌍 데이터셋만을 사용하여 여러 기준 모델(baselines)을 구축하고, 트리플렛 데이터셋을 활용한 모델의 우수성을 증명했습니다.

- **Performance Highlights**: TMED 모델은 다양한 수정 사항을 포함한 텍스트 설명에 따라 정확하게 동작을 수정하는 데 우수한 성능을 보였습니다. 예를 들어, 전체 공간 좌표 수정, 모션 수행 방식, 특정 신체 부위 수정 및 모션 속도 수정 등을 성공적으로 수행했습니다. 평가에서는 새로운 검색 기반(retrieval-based) 메트릭을 도입하여 모델의 성능을 측정했으며, 트리플렛 데이터셋을 활용한 TMED 모델은 기존의 텍스트-모션 생성 방법론을 기반으로 구축한 강력한 기준 모델을 능가했습니다.



### Synthetic dual image generation for reduction of labeling efforts in semantic segmentation of micrographs with a customized metric function (https://arxiv.org/abs/2408.00707)
- **What's New**: 새로운 워크플로우를 통해 마이크로그래프(micrographs)의 시맨틱 세그멘테이션(semantic segmentation) 모델을 개선하는 방법을 제시합니다. 이 방법은 소수의 마이크로그래프와 해당 마스크만으로 벡터 양자화 변이형 오토인코더(Vector Quantised-Variational AutoEncoder, VQ-VAE) 모델을 훈련시켜 합성 이미지를 생성합니다. 이를 통해 데이터가 적더라도 강력한 모델을 훈련할 수 있습니다.

- **Technical Details**: 워크플로우는 VQ-VAE 모델을 사용해 입력 데이터를 임베딩 공간(embedding space)으로 변환하고, 생성적 모델인 픽셀CNN(PixelCNN)이 이 변환된 이산 코드(discrete codes)의 분포를 학습합니다. 학습된 코드들은 VQ-VAE를 통해 이미지를 생성하고, 해당 마스크와 함께 시맨틱 세그멘테이션에 사용됩니다. 합성 데이터의 평가를 위해 실제 데이터와 합성 데이터를 혼합하여 U-Net 모델을 훈련시켰습니다.

- **Performance Highlights**: 합성 데이터와 실제 데이터를 함께 사용한 모델은 비합성 이미지로만 평가되었습니다. 새로운 커스텀 메트릭스(customized metric)는 평균 교차합집합(mean Intersection over Union, mIoU)에서 몇 픽셀의 오류 예측으로 인해 가치가 크게 감소하지 않도록 방지합니다. 이를 통해 샘플 준비 및 획득 시간과 이미지 처리 및 라벨링 작업의 노력이 줄어들었습니다. 이 접근법은 적은 수의 실제 이미지로도 강력한 모델을 훈련할 수 있는 사용자 친화적인 솔루션을 제공합니다.



### Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM (https://arxiv.org/abs/2408.00706)
Comments:
          2024 IEEE Nuclear Science Symposium and Medical Imaging Conference

- **What's New**: 이 예비 연구에서는 점 기반 의료 이미지 분할(Point-Supervised Segmentation, PSS)을 통해, 비용이 많이 드는 전문가의 윤곽 표기 라벨링 문제를 해결하기 위한 방법을 제안합니다. 특히, PSS는 정확한 크기와 경계 가이드가 부족하여 성능이 기대에 미치지 못하는 경우가 많습니다. 이를 해결하기 위해, 우리는 점 입력을 잠재적인 가상 경계 상자 제안(pseudo bounding box suggestions)으로 변환하는 모듈과, 후속 공간 세밀화 모듈(Spatial Refinement Module) 통해, 단계적으로 성능을 향상시킬 수 있는 반복적 프레임워크를 소개합니다.

- **Technical Details**: 이 연구는 'Semantic Box-Prompt Generator, SBPG' 모듈을 통해 점 입력을 잠재적 경계 상자 제안으로 변환하고, 프로토타입 기반 의미 유사성으로 이를 명시적으로 세밀화합니다. 그 뒤는 뛰어난 일반화 성능을 지닌 MedSAM을 활용하여 분할 마스크(segmentation mask)를 추론하는 'Prompt-Guided Spatial Refinement, PGSR' 모듈이 이어집니다. 이 방법은 원형 기반 의미 유사성(protoype-based semantic similarity)과 MedSAM의 반복 프레임워크를 결합하여 세밀한 경계 상자(coarse-to-fine progression of the bounding box)를 생성합니다.

- **Performance Highlights**: 제안된 방법은 BraTS2018 데이터셋에서 전체 뇌 종양 분할(whole brain tumor segmentation) 평가를 통해 탁월한 성능을 보여주었습니다. 기존의 PSS 방법론과 비교해 우수한 성능을 보였으며, 상자 기반 감시 방법(Box-Supervised Method)에 근접한 성능을 발휘했습니다. 검증 과정에서 3~5번의 반복(iterations)을 통해, 점 프롬프트 기반 방법이 상자 기반 MedSAM에 상응하는 성능을 얻을 수 있음을 확인했습니다.



### Joint Neural Networks for One-shot Object Recognition and Detection (https://arxiv.org/abs/2408.00701)
Comments:
          published as part of the PhD thesis: this https URL

- **What's New**: 이 논문은 까다로운 원샷 객체 인식 및 탐지 작업을 해결하기 위한 새로운 joint neural networks 접근 방식을 제시합니다. Siamese neural networks와 최첨단 multi-box detection 접근 방식을 결합하여 학습 과정에서 보지 못한 클래스에 대해서도 객체 인식 및 탐지를 수행할 수 있습니다.

- **Technical Details**: joint neural networks 아키텍처는 query와 target 이미지를 쌍으로 비교하여 동일한 클래스 패턴을 효과적으로 인식합니다. 두 가지 주요 아키텍처가 제시되었으며, 이들은 각각 원샷 인식 및 탐지 작업을 위해 설계되었습니다. 각 네트워크의 합동 계층(joint layers)은 convolutional layers를 통해 query와 target 입력을 결합합니다.

- **Performance Highlights**: 제안된 접근 방식은 MiniImageNet 데이터셋에서 61.41%의 원샷 객체 인식 정확도를, COCO 데이터셋으로 학습되고 Pascal VOC 데이터셋으로 테스트된 원샷 객체 탐지에서는 47.1%의 mean Average Precision(mAP)을 달성했습니다.



### Scaling Backwards: Minimal Synthetic Pre-training? (https://arxiv.org/abs/2408.00677)
Comments:
          Accepted to ECCV2024

- **What's New**: 이번 논문에서는 전이 학습을 위해 실제 이미지 데이터셋 대신 순수하게 합성된 최소한의 데이터셋을 사용하여도 동일한 성능을 도달할 수 있는지 탐구합니다. 이를 위해, 하나의 프랙탈(Fractal)에 변형을 가하여 데이터셋을 구성하였습니다.

- **Technical Details**: 1. 단일 프랙탈 이미지에 기반한 1-파라미터 프랙탈 데이터셋(1p-frac)을 소개하고, 이를 통해 프리-트레이닝을 진행했습니다. 2. 로컬 변형 크로스 엔트로피(LPCE) 손실을 도입하여 단일 프랙탈 이미지에서 신경망이 작은 변형을 학습하도록 하였습니다. 3. 합성 이미지 최소화 요구사항을 연구하여 작은 변화가 사람의 눈에 구분되지 않더라도 강력한 성능을 발휘할 수 있음을 발견했습니다.

- **Performance Highlights**: 1. 1백만 이미지의 ImageNet-1k와 비교해, 단일 프랙탈 이미지로도 동일하거나 더 나은 프리-트레이닝 성능을 달성했습니다. 2. 단일 프랙탈 이미지에서 Δ 변형도를 제어하여 최소 지원 확률 밀도 분포(Probabilistic density distribution)를 조사, 인간이 구분할 수 없는 최소 Δ에서도 긍정적인 프리-트레이닝 효과를 나타냈습니다. 3. 실제 이미지에서도 유사한 '역시-확장(scaling backwards)' 효과를 관찰하기 위해 그레이스케일 및 어파인 변환(affine transformation)을 사용한 결과, 실제 이미지로도 효과적인 프리-트레이닝이 가능함을 확인했습니다.



### ExpertAF: Expert Actionable Feedback from Video (https://arxiv.org/abs/2408.00672)
Comments:
          Technical report

- **What's New**: 비디오에서 물리적 활동을 분석하여 실질적인 피드백을 제공하는 새로운 방법을 제안합니다. 기존의 기술들은 주로 점수를 매기거나 수행을 비교하는데 그쳤지만, 우리 방법은 전문가의 주석 및 시각적 시연을 통해 사용자가 무엇을 고쳐야 하는지 구체적으로 안내합니다.

- **Technical Details**: 비디오와 3D 포즈 데이터를 결합하여 전문가 주석을 생성하고, 이를 통해 시각적 전문가 시범을 제공합니다. Ego-Exo4D 데이터셋과 강력한 언어 모델을 활용해 약한 감독 학습(weakly-supervised learning) 데이터셋을 구축하고, 다양한 멀티모달(video-language) 모델을 사용하여 피드백을 유추합니다. 

- **Performance Highlights**: 축구, 농구, 암벽 등반을 포함한 다양한 시나리오에서 우리의 모델은 강력한 기준 모델을 뛰어넘는 성능을 입증했으며, 인간 평가에서도 3배 높은 선호도를 보였습니다. 특히, 전문가 포즈 생성에서 최초로 성과를 나타냈습니다.



### SF3D: Stable Fast 3D Mesh Reconstruction with UV-unwrapping and Illumination Disentanglemen (https://arxiv.org/abs/2408.00653)
- **What's New**: SF3D는 단일 이미지로부터 신속하고 고품질의 텍스처 객체 메쉬를 0.5초 만에 재구성하는 혁신적인 방법입니다. SF3D는 메쉬 생성을 위해 명확하게 훈련되었으며, 빠른 UV 언랩핑(unwrap)을 통해 텍스처 생성 속도를 높이고, 재질 매개변수와 정상 맵(normal map)을 예측하여 시각적 품질을 향상시킵니다. 또한, 낮은 주파수 조명 효과를 제거하는 디라이트(delighting) 단계도 포함되어 있어 새로운 조명 조건에서도 쉽게 사용할 수 있습니다.

- **Technical Details**: SF3D는 384x384 해상도의 트리플레인(triplane)을 생성하기 위해 트랜스포머(backbone)를 업그레이드했으며, 이것은 자가 주의(attention)의 복잡성을 줄이기 위해 두 개의 스트림(transformer)을 사용하는 방법을 채택했습니다. 이 아키텍처는 트리플레인 스트림과 잠재 스트림(latent stream)의 두 처리 스트림으로 구성되어 있습니다. 네 개의 이러한 두-스트림 유닛으로 전체 아키텍처가 구성되며, 픽셀 셔플링(pixel shuffling) 작업을 통합하여 실제 해상도를 384x384까지 높였습니다.

- **Performance Highlights**: 실험 결과, SF3D는 기존 기술보다 우수한 성능을 보여주었습니다. 텍스처 정렬이 어려운 고대칭 물체의 경우에도, 이 새로운 모델은 텍스처 정렬 문제를 효과적으로 해결하며 시각적 품질을 크게 향상시켰습니다.



### Towards End-to-End Explainable Facial Action Unit Recognition via Vision-Language Joint Learning (https://arxiv.org/abs/2408.00644)
Comments:
          10 pages, 5 figures, 4 tables

- **What's New**: 종합적으로 새로운 연구인 VL-FAU는 시각적 정보와 언어적 정보를 결합하여, 기존의 얼굴 행동 단위(FAU) 인식 모델들이 간과한 설명 가능성을 높이는 방식을 제안합니다. 이 연구는 FAU 인식의 정확성을 높이는 동시에 각기 다른 FAU 상태에 대한 언어적 설명을 제공하는 데 중점을 둡니다.

- **Technical Details**: VL-FAU는 멀티모달(multimodal) 학습을 사용하여, 세밀한 근육 설명과 얼굴 전체의 구별 가능한 설명을 생성하는 언어 모델을 통합합니다. 다중 레벨의 AU 표현 학습을 통해 개별 AU의 주목 인지 표현 능력을 증진시키고, 다양한 얼굴 특징을 결합한 멀티 스케일(face stem feature)로 최적화합니다.

- **Performance Highlights**: DISFA와 BP4D AU 데이터셋에서 이 모델은 대부분의 지표에서 최첨단 방법들을 능가하는 성능을 보여주었습니다. 또한, 기존의 FAU 인식 방법과 달리, VL-FAU는 예측된 AU에 대한 국부적 및 전역적 수준의 해석 가능 언어 설명을 제공합니다.



### Deep Learning in Medical Image Classification from MRI-based Brain Tumor Images (https://arxiv.org/abs/2408.00636)
- **What's New**: 이 연구에서는 뇌종양 분류를 위한 새로운 딥러닝 모델 MobileNet-BT를 제안했습니다. 이 모델은 기존의 MobileNetV2를 기반으로 하며, MRI(자기공명영상) 데이터를 활용하여 네 가지 유형의 뇌종양(교모세포종, 뇌하수체 종양, 수막종, 비종양)을 분류하는 데 집중하고 있습니다.

- **Technical Details**: 연구에서는 CNN(Convolutional Neural Networks) 모델인 MobileNetV2, EfficientNet-B0, ResNet-18, VGG16을 전이 학습(pre-trained) 모델로 사용했으며, 새로운 MobileNet-BT 모델을 제안했습니다. 모델 훈련을 위해 이미지 증강 및 전처리를 수행했으며, 학습률 스케줄러와 얼리 스탑핑을 이용해 모델의 수렴을 돕고 과적합을 방지했습니다.

- **Performance Highlights**: 제안된 MobileNet-BT 모델은 기존 모델들보다 더 높은 정확도와 F1-score를 달성했습니다. 구체적인 성능 수치는 본문에 제시된 바와 같이 MobileNetV2 (0.8445), ResNet-18 (0.8659), EfficientNet-B0 (0.8933), 및 VGG16과 비교하여 우수한 성능을 보입니다.



### Empowering Snapshot Compressive Imaging: Spatial-Spectral State Space Model with Across-Scanning and Local Enhancemen (https://arxiv.org/abs/2408.00629)
Comments:
          12 pages,6 figures

- **What's New**: 최근 논문에서는 ASLE-SSM(State Space Model with Across-Scanning and Local Enhancement)라는 혁신적인 모델을 소개합니다. 이 모델은 공간 및 스펙트럼 차원에서 글로벌 및 로컬 컨텍스트를 균형 있게 인코딩하고, 채널 간 상호작용을 촉진합니다. 특히, ASLE-SSM은 인접한 스펙트럼 밴드와 픽셀 사이의 로컬 유사성을 활용하여 재구성 과정을 가이드합니다.

- **Technical Details**: ASLE-SSM은 공간-스펙트럼 로컬 큐브를 기반으로 하는 횡주사(across-scanning) 방법과 공간 차원에서의 로컬 스캐닝(local scanning)을 결합합니다. 공간 SSM은 글로벌 및 로컬 다 수신 필드를 균형 있게 유지하며, 스펙트럼-공간 교차 SSM은 로컬 큐브를 활용하여 모듈의 세부 사항을 캡처합니다. 이러한 이중 스캐닝 메커니즘으로 추가 비용 없이 HSI의 로컬 특징을 추출하고 글로벌 관점을 유지합니다.

- **Performance Highlights**: ASLE-SSM은 기존의 최신 방법들보다 우수한 성능을 보입니다. 특히, Transformer 기반의 MST보다 추론 속도가 2.4배 빠르며, 매개변수 측면에서 0.12(M) 줄어든 결과를 보여줍니다. 또한, 최소한의 계산 비용과 매개변수 수를 자랑합니다. 모의 데이터셋 및 실제 데이터셋에서 시각적으로 뛰어난 결과를 제공합니다.



### Are Bigger Encoders Always Better in Vision Large Models? (https://arxiv.org/abs/2408.00620)
- **What's New**: 최근 몇 년간, 멀티모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)은 실제 응용에서 강력한 잠재력을 보여주고 있습니다. 특히, 비전 언어 모델(Vision Language Models, VLMs)은 멀티모달 정보 이해 능력으로 주목받고 있지만, 현재의 주류 패러다임 하에서 VLM의 스케일링 동향에 대한 연구는 충분하지 않았습니다. 본 연구는 MLLMs의 사전 훈련 단계에서 다양한 인코더 크기와 대형 언어 모델(LLM) 크기를 사용하여 실험을 수행했습니다.

- **Technical Details**: 이번 연구는 스케일링 법칙(scaling laws)을 조사하기 위해, LLaVA1.5 모델을 백본으로 선택했습니다. 실험은 70억 및 130억 개의 파라미터를 가진 모델로 진행되었으며, CC12M 및 Laion400M 이미지-텍스트 쌍 데이터를 사용했습니다. 데이터 크기는 100만에서 1000만 쌍까지 다양하게 조정하여 실험을 진행했습니다. 실험 결과, 단순히 인코더 크기를 늘리는 것이 VLM의 성능을 반드시 향상시키지는 않는다는 결론을 얻었습니다.

- **Performance Highlights**: 핵심 발견은 ViT(Visual Transformer)를 더 많은 파라미터와 함께 CLIP으로 훈련한다고 해서 MLLMs 성능이 향상되지는 않는다는 것입니다. 이는 MLLMs의 성능을 향상시키기 위해 대체 방법을 탐구해야 함을 시사합니다. 또한, 비주얼 인코더의 스케일링 능력의 한계에서 발생하는 문제는 아니라고 분석되었습니다.



### Harnessing Uncertainty-aware Bounding Boxes for Unsupervised 3D Object Detection (https://arxiv.org/abs/2408.00619)
Comments:
          Preprint, 14 pages, 4 figures, 4 tables

- **What's New**: 새로운 비지도 3D 객체 탐지 프레임워크가 도입되었습니다. 이 프레임워크는 라벨이 없는 LiDAR 데이터를 이용하여 객체를 식별하며, 기존의 방법들과 달리 불확실성 인식을 통해 모델 성능을 향상시킵니다.

- **Technical Details**: 새로운 프레임워크는 불확실성 추정(uncertainty estimation)과 불확실성 정규화(uncertainty regularization)로 구성됩니다. 추가적인 보조 검출(branch)을 도입해 주 탐지기와 보조 탐지기 간의 예측 차이를 활용하여 좌표 레벨에서 불확실성을 추정합니다. 이를 통해 예측의 신뢰도를 측정한 후, 불확실성이 높은 좌표에 낮은 손실 가중치를 부여하여 모델 학습을 신중하게 조정합니다.

- **Performance Highlights**: 제안된 방법은 nuScenes 및 Lyft 데이터셋에서 기존 기술에 비해 성능이 크게 향상됨을 실험적으로 입증했습니다. nuScenes에서는 AP_BE(average precision)성에서 6.9%, AP_3D에서 2.5% 향상이 있었고, Lyft에서는 AP_BE에서 2.2%, AP_3D에서 1.0%의 향상이 있었습니다.



### Learned Compression of Point Cloud Geometry and Attributes in a Single Model through Multimodal Rate-Contro (https://arxiv.org/abs/2408.00599)
Comments:
          20 pages, 13 figures

- **What's New**: 새로운 연구는 포인트 클라우드(점구름) 데이터의 지오메트리와 속성(Color)의 압축을 통합하여 수행하는 단일, 적응형 오토인코더(Autoencoder) 모델을 제안합니다. 기존 방법들은 지오메트리와 속성을 개별적으로 압축하여 각 모달리티에 대해 별도의 인코더와 디코더가 필요했습니다. 이 연구에서는 지오메트리와 속성의 품질 조건에 따라 모델을 조건화하여 다양한 모달리티 품질 조건을 만족시킵니다.

- **Technical Details**: 이 방법은 단일 오토인코더를 사용하여 지오메트리와 속성 데이터를 통합된 잠재 공간(Latent Space)에 임베딩하고, 이를 엔트로피 암호화(Entropy Encoding)합니다. 이 모델의 핵심은 속성과 지오메트리 품질 간의 타협을 검색하는 대신, 조건화된 모델을 사용하여 필요없는 모델 앙상블 훈련을 우회한다는 것입니다. 포인트의 지역적 품질 및 비율 변화를 허용하여 유저 중심의 스트리밍을 위해 뷰-종속 압축도 가능하게 합니다.

- **Performance Highlights**: 이 새로운 방법을 통해 지오메트리와 속성 압축에 있어 기존 최첨단 방법과 유사한 성능을 보이면서도, 관련 압축 방법에 비해 복잡성을 줄였습니다. 예를 들어, 별도의 지오메트리 디코딩 및 속성 프로젝션 과정이 필요 없게 됩니다. 이는 데이터 전송 과정에서 발생할 불필요한 왜곡을 줄이고, 전체 인코딩 복잡성을 감소시킵니다.



### MUFASA: Multi-View Fusion and Adaptation Network with Spatial Awareness for Radar Object Detection (https://arxiv.org/abs/2408.00565)
Comments:
          Accepted by ICANN 2024

- **What's New**: 이번 연구는 자율주행 시스템에서 LiDAR보다 악천후에 강한 레이더 기반 객체 탐지 방법의 효율성을 높이기 위해 종합적인 특징 추출 기술을 도입합니다. GeoSPA 모듈을 사용해 지역 기하 패턴을 탐색하고, DEMVA 메커니즘을 설계하여 데이터셋 전체의 공유 정보와 각 프레임의 글로벌 정보를 통합하여 객체 탐지 성능을 강화한 MUFASA 방법을 소개합니다.

- **Technical Details**: MUFASA 네트워크는 레이더 포인트 클라우드 데이터를 다중 뷰 표현으로 변환한 후, GeoSPA 모듈을 통해 로컬 기하 패턴을 추출합니다. DEMVA 메커니즘은 데이터셋 전체에 걸친 분산된 주의 메커니즘을 사용하여 정보 손실을 최소화합니다. 두 모듈을 결합하여, MUFASA는 포인트-와이즈와 멀티-뷰 특징을 융합하고, 최종 특징을 사용하여 제안을 생성합니다. GeoSPA는 다양한 탐지 프레임워크와 유연하게 통합될 수 있는 플러그 앤 플레이 모듈로 설계되었습니다.

- **Performance Highlights**: MUFASA 방법은 VoD(Vision of Delft) 및 TJ4DRaDSet 데이터셋에 대해 평가되었으며, VoD 데이터셋에서 mAP 50.24%로 최첨단 결과를 달성했습니다.



### Alleviating Hallucination in Large Vision-Language Models with Active Retrieval Augmentation (https://arxiv.org/abs/2408.00555)
- **What's New**: 최근의 연구는 대형 시각-언어 모델(LVLM)에서 발생하는 왜곡(hallucination) 문제를 해결하기 위해 '액티브 검색 증강 대형 시각-언어 모델(Active Retrieval-Augmented large vision-language model, ARA)'을 제안합니다. 이 모델은 이미지의 계층적 구조를 기반으로 검색 목표를 분해하고, 가장 효과적인 검색 방법을 선별하며, 검색 시기를 조절하여 모델의 불확실성이 낮을 때 검색을 활성화하는 방법을 사용합니다.

- **Technical Details**: ARA 모델은 세 가지 핵심 차원을 통합하여 설계되었습니다. 첫째, 이미지를 계층적으로 분석하여 목표 객체를 추출하는 '구조적 검색'을 수행합니다. 둘째, 다양한 멀티모달 입력 방식을 분석하여 가장 효과적인 검색 방식을 적용하고 신뢰할 수 있는 결과를 필터링합니다. 셋째, 모델의 불확실성이 낮을 때만 검색을 수행하여 불필요한 검색을 피합니다. 이 과정을 통해 ARA는 'coarse-to-fine' 검색 패러다임을 적용하며, 이미지 전체와 특정 지역 모두를 분석해 검색 정확도를 높입니다.

- **Performance Highlights**: 제안된 ARA 모델은 세 가지 LVLM 모델(LLaVA-1.5, Qwen-VL, mPLUG-Owl2)을 이용한 네 가지 벤치마크 테스트에서 인상적인 성능을 보였습니다. 실험 결과에 따르면, 적절한 검색 메커니즘을 활용하고 검색 시점을 신중하게 조절함으로써 왜곡 문제를 효과적으로 감소시킬 수 있음이 확인되었습니다.



### Mitigating Multilingual Hallucination in Large Vision-Language Models (https://arxiv.org/abs/2408.00550)
- **What's New**: LVLMs(대형 비전-언어 모델)은 다양한 작업에서 뛰어난 성능을 보였으나, 입력된 이미지-쿼리 쌍에 대해 그럴듯하지만 잘못된 답변을 생성하는 환각 문제로 고통받고 있습니다. 이 논문에서는 LVLMs의 다중언어 환각 문제를 완화하기 위한 첫 번째 시도를 했습니다. 특히, 다중언어 POPE 벤치마크에서 평균 19.0%의 정확도 향상을 달성했습니다.

- **Technical Details**: 본 연구는 다중언어 환각 제거(MHR) 프레임워크를 두 단계로 제안했습니다. 먼저 다중언어 지시어 이해 능력을 개선한 뒤, 모델의 환각 저항 능력을 강화합니다. 이를 위해 교차 언어 정렬(cross-lingual alignment) 방법을 사용하여 다중언어 환각 데이터를 생성하고, 이를 통해 직접 최적화를 수행합니다.

- **Performance Highlights**: 실험 결과, MHR 프레임워크는 낮은 자원 언어와 높은 자원 언어 모두에서 환각 문제를 크게 감소시켰습니다. 확장된 다중언어 POPE 벤치마크에서 우리 프레임워크는 13개 언어에서 평균적으로 19.0%의 정확도 향상을 보여주었습니다.



### How Effective are Self-Supervised Models for Contact Identification in Videos (https://arxiv.org/abs/2408.00498)
Comments:
          15 pages, 6 figures

- **What's New**: 최근 Self-Supervised Learning(SSL)을 적용한 비디오 콘텐츠 분석 분야에서 새로운 접근 방식이 도입되었습니다. 특히 접점 탐지 문제에 SSL 모델을 적용하여 비디오 시퀀스에서 물리적 접점을 식별하는 연구가 소개되었습니다. 이 연구는 Something-Something v2(SSv2)와 Epic-Kitchen(EK-100) 데이터셋을 활용하여 다양한 상황에서 SSL 모델의 성능을 평가하고 그 유효성을 검증합니다.

- **Technical Details**: 이 연구는 8개의 서로 다른 Convolutional Neural Networks(CNNs) 기반 비디오 SSL 모델을 사용하여 물리적 접점 탐지를 시도합니다. 실험에 포함된 모델은 AVID-CMA, Catch the Patch(CTP), GDT, MoCo, VideoMoCo, Pretext-Contrast(Pre-Con), RSPNet, TCLR로 구성되어 있습니다. 각 모델은 Kinetic-400 데이터셋으로 사전 학습되었으며, R(2+1)D-18 아키텍처(backbone)를 사용하여 일관된 구조를 유지했습니다. 실험 셋업에는 SSv2와 EK-100 데이터셋이 사용되었으며, 이 데이터셋은 다양한 환경과 시나리오에서 모델을 테스트하기 적합합니다.

- **Performance Highlights**: 모델의 성능은 비디오 시퀀스에서 물리적 접점을 식별하는 능력뿐만 아니라 액션 인식(action recognition) 역량도 평가되었습니다. 연구 결과, 다양한 CNN 기반 SSL 모델이 물리적 접점을 효과적으로 탐지하고, 액션 인식과 같은 다운스트림 작업에서도 고성능을 발휘함을 확인했습니다. 이는 광범위한 주석이 필요하지 않은 상황에서도 SSL 모델이 복잡한 비주얼 정보를 해석하는 데 있어 강력한 적응력을 보임을 시사합니다.



### SegStitch: Multidimensional Transformer for Robust and Efficient Medical Imaging Segmentation (https://arxiv.org/abs/2408.00496)
- **What's New**: 이번 연구에서는 SegStitch라는 새로운 아키텍처를 소개합니다. SegStitch는 트랜스포머(transformers)를 denoising ODE 블록과 통합하는 혁신적인 접근 방식을 채택하여 의료 이미지 분할의 문제를 해결합니다. 전체 3D 볼륨을 입력으로 사용하는 대신, 축 패치(axial patches)와 패치 단위의 쿼리(patch-wise queries)를 커스터마이징하여 높은 의미적 일관성을 유지합니다.

- **Technical Details**: SegStitch 아키텍처는 공통 쿼리 키(shared query keys)를 활용하여 다양한 패치 간의 컨텍스트 관계를 향상시킵니다. ODE 기반 네트워크(ODENets)를 통합하여 기능 맵(feature maps)의 동적이고 지속적인 업데이트를 지원합니다. BTCV와 ACDC 데이터셋에서 실험을 수행하여 기존 최첨단 방법보다 최대 11.48%, 6.71%까지 향상된 mDSC 성과를 달성했습니다. 또한, ViT와 neural ODE를 결합하여 네트워크의 안정성과 신뢰성을 크게 향상시켰습니다.

- **Performance Highlights**: SegStitch는 기존 UNETR 아키텍처와 비교했을 때 모델의 파라미터 수를 36.7%, FLOPs를 10.7% 줄였습니다. 이러한 효율성 개선은 실제 임상 환경에서의 적용 가능성을 높입니다. 두 데이터셋에서의 정성 및 정량 결과는 SegStitch가 세분화 정확도와 모델 효율성 측면에서 우수한 성능을 보여줍니다.



### Explainable Emotion Decoding for Human and Computer Vision (https://arxiv.org/abs/2408.00493)
Comments:
          This work has been accepted to be presented to The 2nd World Conference on eXplainable Artificial Intelligence (xAI 2024), July 17-19, 2024 - Malta

- **What's New**: 이 논문은 인간과 컴퓨터 비전(CV) 시스템을 나란히 분석하여, 감정 디코딩(emotion decoding)에 대한 기계 학습(ML) 모델의 설명가능 인공지능(XAI) 기술을 적용하는 방법을 제시합니다. 이를 통해 인간의 뇌에서 특정 과제와 상관관계가 있는 뇌 영역을 강조함으로써 신경과학 분야의 전문가에게 유용한 통찰을 제공합니다.

- **Technical Details**: 연구진은 'StudyForrest' 데이터셋을 활용하여, 피실험자가 영화 '포레스트 검프'를 시청할 때 얻어진 기능적 자기공명영상촬영(fMRI) 데이터와 감정 주석, 시선 추적 데이터로 두 개의 ML 모델을 훈련시켰습니다. 인간 비전 모델에서는 fMRI 데이터를 감정 주석과 연결시키며, 컴퓨터 비전 모델에서는 영화 프레임을 사용하여 픽셀 수준의 히트맵(heatmap)으로 설명합니다. XAI 기술로 LIME(Local Interpretable Model-Agnostic Explanations)과 SHAP(Shapley Additive exPlanations)를 사용했습니다.

- **Performance Highlights**: 연구 결과, 인간 시선 추적을 통해 얻어진 주의 집중 영역이 CV 모델의 XAI 중요도(침투성)와 밀접하게 관련되어 있으며, 이는 CNNs의 생물학적 타당성을 높입니다. 이러한 병렬 분석은 신경과학 커뮤니티(배할 이론)와 ML 커뮤니티(컨볼루션 모델의 생물학적 타당성) 모두에게 유용한 정보를 제공합니다.



### Multi-label Sewer Pipe Defect Recognition with Mask Attention Feature Enhancement and Label Correlation Learning (https://arxiv.org/abs/2408.00489)
Comments:
          Accepted by the Journal of Computing in Civil Engineering

- **What's New**: 이 논문에서는 다양한 결함 범주의 공존과 심각한 클래스 불균형 문제를 해결하기 위해, 마스크 주의(mash attention)로 안내된 특징 향상과 라벨 상관 학습(label correlation learning)을 기반으로 한 다중 레이블 파이프 결함 인식 방법을 제안합니다. 이 방법은 Sewer-ML 학습 데이터셋의 1/16만을 사용하여 현 상태의 수준 높은 분류 성능을 달성하고, 전체 데이터셋에서 F2 메트릭 측면에서 현재 최고 방법보다 11.87% 높은 성능을 보이며 모델의 우수성을 입증했습니다.

- **Technical Details**: 현장 비디오에서 얻은 실시간 데이터를 사용하여 파이프 결함 이미지를 생성하고, 클래스 활성화 맵(class activation maps)을 활용하여 다양한 결함의 국소 공간 판별 정보를 얻습니다. 이후, 셀프 어텐션(self-attention) 메커니즘을 도입해 라벨 사이의 관계를 모델링하며, 비대칭 손실 함수(asymmetric loss function)를 사용하여 클래스 불균형 문제를 해결합니다.

- **Performance Highlights**: 제안된 방법은 Sewer-ML 데이터셋의 1/16만을 사용하여 현 상태 수준의 최고 성능을 달성하였으며, 전체 데이터셋에서는 F2 메트릭 측면에서 기존 방법보다 11.87% 더 나은 성과를 보였습니다. 이는 다중 레이블 분류 작업에서 모델의 강력한 해석 가능성을 보여주는 것입니다.



### Image Super-Resolution with Taylor Expansion Approximation and Large Field Reception (https://arxiv.org/abs/2408.00470)
- **What's New**: 이 논문은 블라인드 초해상도(SR) 작업에서 자가 유사성(self-similarity) 기법의 높은 계산 복잡성을 해결하기 위해 새로운 접근 방식을 제안합니다. 저자들은 자가 유사성 계산에서 발생하는 고차원 행렬 곱셈의 복잡성을 낮추기 위해 이차 Taylor 전개 근사법(STEA)을 도입했습니다. 이는 계산 복잡성을 $	ext{𝒪}(N^2)$에서 $	ext{𝒪}(N)$으로 줄여줍니다. 또한, STEA로 인한 성능 저하를 보완하기 위해 다중 스케일 큰 영역 수용(Multi-Scale Large Field Reception, MLFR)을 설계했습니다. 이 두 가지 핵심 디자인을 LabNet(실험실 데이터용) 및 RealNet(실제 데이터용) 네트워크에 적용했습니다.

- **Technical Details**: 고차원 자가 유사성 계산은 Query와 Key의 행렬 곱에 의한 높은 계산 복잡성을 초래합니다. 이를 해결하기 위해 저자들은 Query와 Key의 곱을 분리하는 이차 Taylor 전개 근사법(STEA)을 제안했습니다. STEA는 자가 유사성 계산에서 발생하는 계산 복잡성을 크게 줄여줍니다. 하지만 STEA로 인해 전역 특성을 필터링하는 능력이 상실되므로, MLFR 모듈을 설계하여 이를 보완했습니다. LabNet과 RealNet은 이러한 두 가지 핵심 디자인(STEA와 MLFR)을 실험실 데이터와 실제 데이터 시나리오에 각각 적용했습니다.

- **Performance Highlights**: 실험 결과, LabNet은 다섯 개의 합성 데이터셋에서 질적 및 양적 평가에서 새로운 벤치마크를 설정했습니다. RealNet은 RealWorld38 데이터셋에서 기존 방법들보다 우수한 시각적 품질을 달성했습니다. 또한, 분리 연구(ablation studies)를 통해 STEA와 MLFR이 LabNet과 RealNet 프레임워크에 기여한 바를 검증했습니다.



### Reenact Anything: Semantic Video Motion Transfer Using Motion-Textual Inversion (https://arxiv.org/abs/2408.00458)
Comments:
          Preprint. All videos in this paper are best viewed as animations with Acrobat Reader by pressing the highlighted frame of each video

- **What's New**: 최근 몇 년 동안 비디오 생성 및 편집 기술이 크게 발전했습니다. 이 논문에서는 기존의 텍스트, 트랙터지 또는 경계 상자(bounding boxes)를 이용한 간단한 움직임(motion) 대신에 단일 참조 비디오(single motion reference video)를 사용하여 더욱 복잡한 움직임을 지정하는 새 방법을 제안합니다. 이 방법은 프리트레인된 이미지-투-비디오 모델(image-to-video model)을 텍스트-투-비디오 모델 대신 사용하여 목표 객체 또는 장면의 외형과 위치를 정확하게 유지하면서 외형과 움직임을 분리하는 데 중점을 둡니다.

- **Technical Details**: 우리의 방법인 'motion-textual inversion'은 이미지-투-비디오 모델이 주로 잠재 이미지 입력에서 외형을 추출하고, 크로스 어텐션(cross-attention)을 통한 텍스트/이미지 임베딩(text/image embedding)이 주로 움직임을 제어한다는 관찰을 기반으로 합니다. 각 프레임에 여러 개의 텍스트/이미지 임베딩 토큰을 포함하는 팽창된 움직임-텍스트 임베딩(inflated motion-text embedding)으로 작업하여 높은 시간적 움직임 정확성을 달성합니다. 이 임베딩은 참조 비디오에서 최적화된 후 다양한 타겟 이미지에 적용되어 의미적으로 유사한 움직임을 가진 비디오를 생성할 수 있습니다.

- **Performance Highlights**: 우리의 방법은 움직임 참조 비디오와 타겟 이미지 간의 공간적 정렬(spatial alignment)을 필요로 하지 않으며, 다양한 도메인에 걸쳐 일반화될 수 있습니다. 예를 들어, 전체 신체와 얼굴 재연(full-body and face reenactment), 무생물 객체와 카메라의 움직임 제어와 같은 다양한 작업에 적용될 수 있습니다. 우리는 의미론적 비디오 움직임 전이 작업에서 실질적으로 기존 방법들을 뛰어넘는 효과를 실험적으로 입증했습니다.



### Focus, Distinguish, and Prompt: Unleashing CLIP for Efficient and Flexible Scene Text Retrieva (https://arxiv.org/abs/2408.00441)
Comments:
          Accepted by ACM MM 2024

- **What's New**: 새로운 연구에서는 Optical Character Recognition (OCR) 기술 없이도 장면 텍스트 검색(Scene Text Retrieval, STR)을 효과적으로 수행할 수 있는 모델, FDP(Focus, Distinguish, and Prompt)를 소개합니다. CLIP(Contrastive Language-Image Pre-training)의 내재된 잠재력을 활용하여 빠른 속도와 뛰어난 검색 정확성을 모두 달성합니다.

- **Technical Details**: FDP 모델은 먼저 CLIP의 주의를 텍스트 영역으로 집중시키기 위해 이미지의 대략적인 텍스트 위치를 모델에게 제공합니다. 그런 다음, 주어진 쿼리 텍스트를 내용어(content word)와 기능어(function word)로 구분하고, 각 종류별로 다른 검색 방법을 적용합니다. 마지막으로, 의미 인지 prompting 전략을 이용해 쿼리 텍스트를 학습 가능한 프롬프트로 변환하고 각 이미지와의 유사성 점수를 계산해 랭킹합니다. 또한, 비슷한 단어들의 부정적 효과를 최소화하기 위해 distracted queries assistance 전략을 적용합니다.

- **Performance Highlights**: FDP는 IIIT-STR 벤치마크에서 기존 최고 성능 모델보다 4.37% 높은 mAP 점수를 기록했으며, 추론 속도는 4배 빠릅니다. FDP는 다양한 형태의 쿼리 텍스트에 대해 더욱 유연하고 일반화된 성능을 보여줍니다.



### MonoMM: A Multi-scale Mamba-Enhanced Network for Real-time Monocular 3D Object Detection (https://arxiv.org/abs/2408.00438)
- **What's New**: 최근 트랜스포머 기반의 단안 3D 객체 탐지 기술이 단일 2D 이미지에서 3D 속성을 추론하는 데 있어 뛰어난 성능을 보여주고 있습니다. 그러나 대부분의 기존 방법은 자원 집약적인 트랜스포머 아키텍처에 의존하여, 긴 시퀀스 데이터 처리 시 효율성과 성능이 크게 저하되는 문제가 있었습니다. 이러한 문제를 해결하고 단안 3D 객체 탐지 기술을 발전시키기 위해, MonoMM이라는 혁신적인 네트워크 아키텍처를 제안합니다. MonoMM은 실시간 단안 3D 객체 탐지를 위한 다중 스케일 Mamba-Enhance 네트워크입니다.

- **Technical Details**: MonoMM은 두 가지 핵심 모듈로 구성됩니다. 첫 번째는 Focused Multi-Scale Fusion (FMF) 모듈로, 다양한 스케일에서 이미지 정보를 효과적으로 보존하고 융합하여 계산 자원을 절약합니다. 이는 정보 흐름을 정확하게 조절하여 모델의 적응성과 견고성을 유지하면서 이미지 세부 사항을 손상시키지 않고 향상시킵니다. 두 번째는 Depth-Aware Feature Enhancement Mamba (DMB) 모듈입니다. 이는 융합된 특징을 입력으로 사용하여 전역적으로 깊이 정보와 시각 정보를 통합하는 새로운 적응 전략을 사용합니다. 이 깊이 융합 전략은 깊이 추정의 정확성을 향상시키고, 다양한 시야각 및 환경 조건에서 모델 성능을 강화합니다.

- **Performance Highlights**: KITTI 데이터 세트에서 수행된 광범위한 실험 결과, MonoMM은 이전의 단안 방법보다 뛰어난 성능을 보여주었고, 실시간 탐지를 달성했습니다. 또한 FMF와 DMB 모듈은 기존의 이미지 기반 프레임워크에 쉽게 통합되어 전체 성능을 향상시킬 수 있습니다.



### CARMIL: Context-Aware Regularization on Multiple Instance Learning models for Whole Slide Images (https://arxiv.org/abs/2408.00427)
- **What's New**: 새로운 연구는 Context-Aware Regularization for Multiple Instance Learning (CARMIL)을 제안하여, 기존의 MIL 모델이 놓치고 있는 공간적 지식을 통합할 수 있도록 설계되었습니다. 또한, 어떤 MIL 모델이 Whole Slide Images(WSIs)에서 공간 인식을 잘 수행하는지 정량화할 수 있는 새로운 기준인 DeltaCon도 도입되었습니다.

- **Technical Details**: CARMIL은 기본 MIL 모델에 공간 인식 기능을 추가하기 위해 정규화(regularization)을 사용합니다. 공간 인코더와 디코더는 특징 추출기와 MIL 모델 사이에 추가되며, Context-Aware Regularization (CAR) 손실 함수를 사용하여 타일 임베딩의 공간적 관계를 보존하도록 학습합니다. 이를 통해 WSI의 타일 간 공간적 관계를 보다 정확하게 반영할 수 있습니다.

- **Performance Highlights**: 본 논문은 CARMIL의 효율성을 신경교세포종(TCGA GBM)과 결장암(TCGA COAD) 데이터를 사용한 생존 분석 작업에서 평가하였습니다. 기존의 공간적 지식이 없는 MIL 모델을 CARMIL을 통해 공간 인식 모델로 변환하고, 이를 통해 C-index(생존 예측의 성능 지수)가 향상됨을 입증하였습니다.



### MPT-PAR:Mix-Parameters Transformer for Panoramic Activity Recognition (https://arxiv.org/abs/2408.00420)
- **What's New**: 이번 연구에서는 복잡하고 혼잡한 환경에서 다양한 세분화 수준에서 행동을 인식하는 파노라마 활동 인식(Task)에 대한 새로운 모델인 MPT-PAR를 제안합니다. 기존 방법들과 달리, MPT-PAR는 각 Task의 고유한 특성과 서로 다른 Task 간의 시너지 효과를 동시에 고려하여 다중 세분화 활동 인식을 극대화합니다.

- **Technical Details**: MPT-PAR 모델은 개별 행동, 사회적 그룹 활동, 그리고 글로벌 활동을 다루기 위해 인코더를 설계했습니다. 이를 통해 여러 세분화 수준에서의 특징을 동시에 통합하며, MPT-PAR는 파라미터 독립 모듈과 파라미터 공유 모듈을 함께 사용해 최상의 성능을 이끌어냅니다. 시간적(Temporal) 및 공간적(Spatial) 정보를 강조하기 위해, 시간-공간 관계 증강 모듈과 장면 재현 학습 모듈을 도입했습니다. 이 모듈들은 행동의 시간적 및 공간적 맥락을 특징 맵에 통합합니다.

- **Performance Highlights**: JRDB-PAR 데이터셋에서 MPT-PAR 모델은 47.5%의 F1 점수를 기록했으며, 이는 최첨단 방법들에 비해 6% 향상된 결과입니다. 특히, 글로벌 활동 인식 서브타스크에서 61.1%의 F1 점수를 기록하며 가장 큰 향상을 보여주었습니다.



### Towards Reliable Advertising Image Generation Using Human Feedback (https://arxiv.org/abs/2408.00418)
Comments:
          ECCV2024

- **What's New**: 본 논문에서는 e-commerce에서 광고 이미지 생성의 효율성을 높이기 위해 멀티모달 Reliable Feedback Network (RFNet)을 소개합니다. RFNet은 생성된 광고 이미지를 자동으로 검사하여 반복적 이미지 생성 과정(Recurrent Generation)에서 사용할 수 있는 이미지를 증가시킵니다. 또한, RFNet의 피드백을 활용한 혁신적인 Consistent Condition regularization을 통해 디퓨전 모델(Diffusion Model)을 미세 조정함으로써 광고 이미지의 생성 효율성을 극대화합니다.

- **Technical Details**: RFNet은 사람이 생성 이미지를 검사하는 과정을 자동화하기 위해 다중 모달 정보를 통합하여 다양한 결함 유형을 판별합니다. 이를 위해, 1백만 개 이상의 휴먼 어노테이션이 포함된 Reliable Feedback 1 Million (RF1M) 데이터셋을 제작하였습니다. Recurrent Generation 기법과 결합하여 사용 가능한 광고 이미지의 비율을 높이며, Consistent Condition regularization을 도입한 RFFT(RFNet Feedback Tuned diffusion model)는 이미지의 미적 가치를 희생하지 않고도 사용 가능 비율을 크게 증가시킵니다.

- **Performance Highlights**: RFNet의 도입과 RFFT 전략은 반복적 이미지 생성 과정에서 시도 횟수를 줄이고, 탁월한 생산 효율성을 제공합니다. 이로써 광고 이미지 생성의 신뢰성을 높이고 시각적인 매력을 유지하며, 보편적으로 사용 가능한 광고 이미지 생성 솔루션을 제안합니다.



### Deepfake Media Forensics: State of the Art and Challenges Ahead (https://arxiv.org/abs/2408.00388)
- **What's New**: AI로 생성된 합성 미디어, 일명 딥페이크(Deepfakes)는 엔터테인먼트부터 사이버 보안까지 다양한 영역에 큰 영향을 미치고 있습니다. 이 기술은 Generative Adversarial Networks(GANs)와 Diffusion Models(DMs)를 활용하여 고도로 현실적인 거짓 콘텐츠를 생성합니다. 이러한 기술의 등장은 새로운 창의적 가능성을 열었지만, 오용될 경우 심각한 윤리적 및 보안상의 문제를 야기할 수 있습니다. 이에 따라 'Impostor Bias'라는 인지적 편향이 발생하여, AI의 능력 때문에 멀티미디어의 진위를 의심하게 됩니다.

- **Technical Details**: 딥페이크 탐지는 머신러닝 기법, 특히 Convolutional Neural Networks(CNNs)를 활용하여 미세한 일관성 부족 및 아티팩트를 식별하는 데 중점을 둡니다. 연구는 크게 다섯 가지 영역으로 나눌 수 있습니다: 탐지, 소스 추적 및 인식, 패시브 인증, 실감 시나리오에서의 탐지, 및 액티브 인증. 이 논문은 이러한 문제들을 해결하는 주요 알고리즘을 검토하고, 각각의 장점과 한계, 그리고 미래 전망을 분석합니다.

- **Performance Highlights**: 현재의 탐지 방법은 복잡한 텍스처와 아티팩트 사이의 미묘한 상호작용을 분석하여 높은 정확도를 보여주지만, 디지털 콘텐츠 조작에 사용되는 다양한 기술에 대해 일반화하는 데는 어려움을 겪고 있습니다. 텍스처 분석과 아티팩트 감지 모두를 활용하는 Texture and Artifact Detector(TAD) 프레임워크는 다양한 위조 시나리오에서 모델의 일반화 능력을 향상시킵니다. 또한, 높은 압축률로 인해 발생하는 탐지 정확도 저하 문제를 해결하기 위해, 학습 가능한 적응형 고주파 강화 프레임워크가 제안되었습니다.



### Few-shot Defect Image Generation based on Consistency Modeling (https://arxiv.org/abs/2408.00372)
- **What's New**: DefectDiffu는 결함 이미지를 다양하게 생성하기 위해 제안된 새로운 텍스트 기반 디퓨전 방법입니다. 이 방법은 다수의 제품에서 배경 일관성(intra-product background consistency)과 결함 일관성(inter-product defect consistency)을 모델링하여, 제품 종류와 결함 강도를 제어할 수 있습니다. 이를 위해 DefectDiffu는 배경, 결함, 융합 부분으로 구성된 세 부분의 분리된 통합 구조(Disentangled Integrated Architecture)를 도입합니다.

- **Technical Details**: DefectDiffu는 텍스트 인코더를 사용하여 배경과 결함, 융합 부분의 일관성 프롬프트를 제공합니다. 이로써 배경과 결함을 분리하여 모델링합니다. 이후, 일관성 방향의 두 단계(결함 방향과 배경 방향)를 조절하는 '더블-프리(Double-Free) 전략'을 제안하여, 제품 종류와 결함 강도를 조절합니다. 이를 통한 결함 변경 방향은 다른 제품들 사이에서도 전이 가능하여, 소수의 샘플로도 결함 이미지를 생성할 수 있습니다.

- **Performance Highlights**: 실험 결과, DefectDiffu가 생성 품질과 다양성 측면에서 최신 기법보다 뛰어남을 입증했습니다. 특히, 소형 결함과 마스크의 생성 품질을 높이기 위해 제안된 적응형 주의-향상 손실(Adaptive Attention-Enhanced Loss)을 사용합니다. DefectDiffu는 제로-샷(Zero-Shot) 결함 생성도 가능하여 데이터 부족 문제를 효과적으로 해결할 수 있습니다.



### High-Precision Self-Supervised Monocular Depth Estimation with Rich-Resource Prior (https://arxiv.org/abs/2408.00361)
Comments:
          ECCV2024

- **What's New**: 이번 논문에서는 단일 입력 이미지만을 사용하는 경우에도 고정밀 깊이 추정을 가능하게 하는 Rich-resource Prior Depth estimator (RPrDepth)를 제안했습니다. 이 모델은 부가적인 고자원 데이터 (rich-resource data)를 사전 정보로 활용하여 단일 이미지 입력 동안에도 높은 정확도의 깊이 추정을 가능합니다.

- **Technical Details**: RPrDepth는 고자원 데이터를 사전 정보로 간주하고, 이를 바탕으로 추론 단계에서 단일 이미지 입력 시에도 깊이 정보를 추정합니다. 특히, 학습 단계에서 고자원 데이터에서 특징을 추출하여 참조 특징(reference features)으로 사용하고, 추론 시에는 이 특징을 기반으로 유사한 픽셀을 검색하여 깊이 추정을 수행합니다. 이 모델은 또한 Prior Depth Fusion Module 및 Rich-resource Guided Loss를 제안하여, 고자원 모델의 일관성을 활용하여 정확도를 향상시킵니다.

- **Performance Highlights**: 실험 결과, RPrDepth 모델은 단일 이미지 입력만 사용하는 다른 모델들보다 뛰어난 성능을 보였으며, 고자원 입력을 사용하는 모델들과 비교해도 동등하거나 더 나은 성능을 달성했습니다. 이러한 결과는 저해상도 단일 이미지 입력만으로도 실생활에서 높은 정확도의 깊이 추정을 가능하게 함을 보여줍니다.



### DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved Denoising Training (https://arxiv.org/abs/2408.00355)
Comments:
          Accepted by ACMMM2024

- **What's New**: DNTextSpotter라는 새로운 노이즈 제거 훈련 방법을 제안하여 Transformer 기반의 텍스트 스포팅(Textr Spotting) 작업을 개선합니다. 이 새로운 방법은 비정형 텍스트 감지 및 인식을 목표로 합니다. 특히, 베지어(Beziér) 중심 곡선의 제어점을 사용해 노이즈 위치 쿼리를 생성하며, 'masked character sliding' 방법을 도입하여 내용과 위치를 일치시킵니다.

- **Technical Details**: DNTextSpotter는 비정형 텍스트 감지를 위해 설계된 새로운 노이즈 제거 훈련 방법입니다. 이 방법은 노이즈 위치 쿼리와 노이즈 내용 쿼리로 쿼리를 분해합니다. 노이즈 위치 쿼리는 베지어 중심 곡선 제어점을 이용해 생성되고, 노이즈 내용 쿼리는 'masked character sliding' 방법을 사용하여 텍스트의 내용이 위치와 일치하도록 초기화됩니다. 또한, 모델이 배경 문자 분류에 대한 추가 손실 함수를 활용하여 배경에 대한 인식을 높입니다.

- **Performance Highlights**: DNTextSpotter는 네 가지 벤치마크(총-텍스트, SCUT-CTW1500, ICDAR15, Inverse-Text)에서 최첨단 방법들을 능가하는 성능을 보였습니다. 특히, Inverse-Text 데이터셋에서는 기존 최상의 방법보다 11.3% 개선된 성과를 기록했습니다. 또한 ResNet-50 백본을 사용한 'None' 결과 측정 지표에서 Total Text와 CTW1500 데이터셋에서 각각 2.0%와 2.1% 성능 향상을 나타냈습니다.



### Autonomous LLM-Enhanced Adversarial Attack for Text-to-Motion (https://arxiv.org/abs/2408.00352)
- **What's New**: 새로운 연구는 인간의 움직임을 텍스트로 생성하는 텍스트-투-모션(Text-to-Motion, T2M) 모델에 대한 보안 문제를 제기하며, 이런 모델을 악의적으로 이용할 수 있는 가능성을 강조하고 있다. 이러한 맥락에서 새로운 자동화된 프레임워크 ALERT-Motion을 소개했다. 이 프레임워크는 대형 언어 모델(Large Language Models, LLMs)을 활용해 T2M 모델을 대상으로 하는 적대적 공격(Adversarial Attacks)을 설계한다.

- **Technical Details**: ALERT-Motion은 두 개의 주요 모듈로 구성되어 있다. 첫째, 적응형 디스패칭 모듈(Adaptive Dispatching Module)은 LLM 기반의 에이전트를 구축하여 적대적 텍스트 프롬프트를 반복적으로 수정하고 검색하도록 한다. 둘째, 멀티모달 정보 대조 모듈(Multimodal Information Contrastive Module)은 목표 움직임 정보를 추출하여 에이전트의 검색을 안내한다. 이 접근 방식으로 ALERT-Motion은 희생 모델이 목표 움직임과 일치하는 출력을 생성하도록 하는 미세한 적대적 프롬프트를 자동으로 생성한다.

- **Performance Highlights**: ALERT-Motion은 기존의 방법들보다 더 높은 공격 성공률을 기록했다. 특히 공격 프롬프트가 자연스러우면서도 미세하여 탐지하기 어려운 점이 특징이다. 이는 연구가 단순히 텍스트-투-이미지(Text-to-Image, T2I)와 연관된 선행 연구를 넘어서는 중요한 발전임을 시사한다.



### Hierarchically Structured Neural Bones for Reconstructing Animatable Objects from Casual Videos (https://arxiv.org/abs/2408.00351)
Comments:
          ECCV 2024 accepted

- **What's New**: 이 논문은 일상적으로 촬영된 비디오를 사용하여 임의 객체의 3D 모델을 생성하고 쉽게 조작할 수 있는 새로운 프레임워크를 제안합니다. 핵심 요소는 트리 구조의 뼈대를 사용하여 객체의 움직임을 포착하는 새로운 계층 변형 모델입니다.

- **Technical Details**: 우리의 계층 시스템은 세분성에 따라 움직임을 분해하며 사전 구조 지식을 활용하지 않고 각 부분 간의 상관 관계를 드러냅니다. 이를 통해 부분 중심과 관련된 표면을 충분히 덮도록 뼈대를 위치시키는 bone occupancy function을 제안합니다. 제안된 구성 요소들은 개선된 품질의 애니메이션 가능한 3D 모델을 일상적인 비디오에서 얻을 수 있게 하고, 최소한의 비용으로 직관적인 방식으로 3D 모델을 조작할 수 있으며, 필요한 경우 제어점을 추가하거나 삭제할 수 있는 인터랙티브한 기능을 제공합니다.

- **Performance Highlights**: 실험 결과, 다양한 사례에서 본 프레임워크의 효능이 입증되었습니다. 재구성 품질, 해석 가능성 및 조작 용이성에서 탁월한 성과를 보여주었습니다. 또한 코드가 공개되어 있습니다.



### A Simple Background Augmentation Method for Object Detection with Diffusion Mod (https://arxiv.org/abs/2408.00350)
- **What's New**: 이번 연구에서는 객체 탐지(Object Detection)와 인스턴스 세분화(Instance Segmentation)와 같은 다양한 다운스트림 작업에 유익하도록 데이터셋의 다양성을 개선하는 문제를 다루었습니다. 새로운 데이터 증강(data augmentation) 접근법을 제안하면서, Stable Diffusion과 같은 텍스트-이미지 합성 기술(text-to-image synthesis)을 활용하여 라벨이 붙은 실제 이미지의 변형을 생성하고, 추가적인 주석(annotation) 없이도 기존의 학습 데이터를 증강할 수 있도록 했습니다. 특히 배경 증강(background augmentation)은 모델의 강건성과 일반화 능력을 크게 향상시켰습니다.

- **Technical Details**: 제안된 방법은 생성 모델(generative model), 특히 텍스트-이미지 합성(text-to-image synthesis)을 사용하여 라벨이 붙은 실제 이미지의 변형을 생성하는 것입니다. Stable Diffusion 모델을 활용하여 라벨이 있는 실제 이미지의 객체와 배경을 적절히 증강합니다. 주요한 접근법은 인페인팅(inpainting)을 통해 기존 주석을 유지하면서 학습 데이터를 증강하는 것입니다. 텍스트 프롬프트(prompt)와 마스크(mask)를 조정하여 생성된 콘텐츠가 기존 주석과 일치하도록 보장합니다.

- **Performance Highlights**: 제안된 증강 기법의 효과는 COCO 데이터셋과 다양한 객체 탐지 벤치마크를 통해 확인되었습니다. 배경 증강을 통해 모델 성능이 크게 향상되었으며, 예를 들어 COCO 학습 데이터의 10%만 사용했을 때 mAP가 최대 5.3%까지 증가했습니다. 이러한 증강 기법은 다양한 어려운 상황에서도 객체 탐지 및 인스턴스 세분화 모델의 성능을 크게 향상시키는 것으로 나타났습니다.



### Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer (https://arxiv.org/abs/2408.00347)
Comments:
          Accepted in BMVC 2024

- **What's New**: Diffusion Transformer Segmentation (DTS) 모델을 제안했습니다. 이 모델은 transformer 아키텍처를 활용하여 global dependency를 self-attention으로 캡쳐하고, 다양한 메디컬 이미징 모달리티에서 뛰어난 성능을 보여줍니다.

- **Technical Details**: DTS 모델은 Swin Transformer encoder와 UNet decoder를 결합하였습니다. 주목할 세 가지 주요 기술은 다음과 같습니다: k-neighbor label smoothing, reverse boundary attention, self-supervised learning. 이 방법들은 메디컬 이미지의 복잡한 구조를 식별하는 능력을 향상시킵니다.

- **Performance Highlights**: DTS 모델은 다양한 메디컬 이미징 모달리티 (CT, MRI, lesion images)에서 기존 모델보다 우수한 결과를 보여줍니다. 특히, 모델의 일반화 능력은 다른 도메인 테스크에서도 높은 성능을 유지함을 보여줍니다.



### DistillGrasp: Integrating Features Correlation with Knowledge Distillation for Depth Completion of Transparent Objects (https://arxiv.org/abs/2408.00337)
Comments:
          10 pages, 5 figures

- **What's New**: 투명한 물체의 깊이 데이터를 더 정확하게 복원하기 위해 DistillGrasp라는 네트워크를 제안합니다. 이 네트워크는 교사 분기와 학생 분기로 구성되어 있으며, 교사 분기는 RGB 이미지를 깊이 맵으로 매핑하는 위치 상관 블록(Position Correlation Block, PCB)을 사용합니다. 학생 분기는 신뢰성 있는 영역에 기반하여 일관된 특징 상관 모듈(Consistent Feature Correlation Module, CFCM)을 사용합니다. 지식 증류(Knowledge Distillation) 기법을 활용하여 학생 네트워크가 교사 네트워크의 지식을 효과적으로 학습할 수 있도록 합니다.

- **Technical Details**: 제안된 DistillGrasp 네트워크는 교사와 학생 분기로 나뉩니다. 교사 네트워크에서 RGB 이미지와 깊이 맵 간의 구조적 정보와 대응 관계를 설정하기 위해 트랜스포머 기반의 위치 상관 블록(PCB)을 사용합니다. 학생 네트워크는 일관된 영역에 기반하여 신뢰 가능한 특징을 추출하는 일관된 특징 상관 모듈(CFCM)을 사용하며, 거리 손실, 구조 손실, 에지 손실을 포함한 증류 손실(distillation loss)을 고안하여 종합적인 특징을 학습할 수 있도록 합니다.

- **Performance Highlights**: ClearGrasp 데이터셋을 기반으로 한 실험 결과, 제안된 교사 네트워크는 정확성과 일반화 측면에서 기존 최첨단 방법보다 우수한 성능을 보여줍니다. 학생 네트워크는 48 FPS의 속도로 경쟁력 있는 결과를 달성합니다. 추가로, 실제 로보틱 그리핑 시스템에 성공적으로 배포되어 제안된 시스템의 효과성과 내구성을 입증했습니다.



### Vision-based Wearable Steering Assistance for People with Impaired Vision in Jogging (https://arxiv.org/abs/2408.00332)
Comments:
          Accepted to ICRA 2024

- **What's New**: 시각 장애인을 위한 새로운 비전 기반 착용형 스티어링(steering) 보조 시스템이 개발되었습니다. 이 시스템은 육상 트랙처럼 대표적인 스포츠 환경에서 사용되며, 사용자들이 실외에서 독립적으로 달릴 수 있도록 돕습니다. 이를 위해, 새로운 데이터셋 MAT를 수집하고 주석을 달았으며, 실시간으로 트랙 라인(track lines)과 장애물(obstacles)을 동시에 탐지할 수 있는 경량 멀티태스크 네트워크를 설계했습니다.

- **Technical Details**: 시스템은 Jetson Orin NX 임베디드 장치에 배치되었습니다. 사용자는 RGB-D 카메라가 장착된 안경을 착용하고, 이것이 실시간 컬러와 깊이 이미지를 캡처합니다. 이 입력은 멀티태스크 네트워크를 통해 처리되어 트랙 라인 세분화와 장애물 탐지가 이루어집니다. 경로 계획 모듈은 스플라인 곡선을 사용하여 프레넷(Frenet) 및 데카르트(Cartesian) 좌표 사이의 변환을 수행하며, 동적 프로그래밍(dynamic programming)을 통해 샘플링 지점 간의 최소 경로 비용을 계산해 최적의 경로를 도출합니다.

- **Performance Highlights**: 실외 실험 결과, 이 시스템은 사용자들이 평균 속도 1.34 m/s로 400미터를 자유롭게 이동할 수 있게 도우며, 이는 건강한 사람들이 달리는 속도와 비슷한 수준입니다. 새로 수집한 MAT 데이터셋은 1000개의 이미지로 구성되며, 공공으로 이용 가능합니다. 이 데이터셋은 장애물 탐지와 트랙 라인 주석이 포함된 이미지로 나뉩니다.



### DECIDER: Leveraging Foundation Model Priors for Improved Model Failure Detection and Explanation (https://arxiv.org/abs/2408.00331)
Comments:
          Accepted at ECCV (European Conference on Computer Vision) 2024

- **What's New**: DECIDER(디사이더)는 새로운 접근법으로, 이미지 분류 모델에서 실패를 감지하기 위해 대형 언어 모델(LLMs)과 비전-언어 모델(VLMs)을 활용합니다. LLMs을 통해 작업 관련 핵심 속성을 지정하고, VLM을 사용해 그 속성에 맞춰 '탈편향된' 분류기를 구성합니다. 이후 원래 모델과 탈편향된 모델 간의 불일치를 측정하여 잠재적인 실패를 감지합니다. 또한, 새로운 속성 제거 전략(attribute-ablation strategy)을 통해 인간이 이해할 수 있는 방식으로 실패 원인을 설명할 수 있습니다.

- **Technical Details**: DECIDER는 LLM(GPT-3)과 VLM(CLIP)을 사용합니다. 먼저 LLM을 활용해 작업에 관련한 핵심 속성을 식별하고, 그 정보를 사용해 VLM이 시각적 특징을 이 속성에 맞추도록 합니다. 그 결과 탈편향된 분류기를 만들고, 원래 모델과 이 분류기 간의 예측 불일치를 통해 실패를 감지합니다. 또한, 속성 제거 전략을 통해 탈편향된 모델의 예측 가능성을 원래 모델과 맞추는 방식으로 실패 사례를 설명합니다.

- **Performance Highlights**: DECIDER는 다양한 기준 변화(subpopulation shifts)와 공변량 변화(covariate shifts)에 걸쳐 광범위한 실험을 통해 최첨단 실패 탐지 성능을 거두었습니다. 특히 매튜스 상관 계수와 실패 및 성공 리콜 면에서 기존 방법들을 크게 능가했습니다. 이러한 결과는 큰 규모의 기초 모델을 활용한 새로운 안전 메커니즘 설계의 유용성을 초기 단계에서 보여줍니다.



### Translating Imaging to Genomics: Leveraging Transformers for Predictive Modeling (https://arxiv.org/abs/2408.00311)
- **What's New**: 이 연구는 CT/MRI 이미지에서 유전자 정보를 예측하는 Transformer 기반 모델을 소개합니다. 현재 대부분의 연구는 침습적인 Whole Slide Images(WSI)에 의존하지만, 본 연구는 비침습적인 CT/MRI 이미지만을 사용하여 유전자 프로필을 예측합니다. 이를 통해 보다 정확하고 개인 맞춤형 의료의 길을 여는 것을 목표로 합니다.

- **Technical Details**: 이미징 데이터는 TCIA, 유전자 데이터는 TCGA 포털에서 얻었으며, TCGA-GBM, TCGA-LGG, TCGA-LUAD, TCGA-BRCA 등의 공개 데이터셋을 사용했습니다. 예측 모듈은 Transformer encoder와 prediction head로 구성되며, TransUNet을 사용하여 로컬 및 글로벌 특징을 학습했습니다. 변환기 인코더는 환자마다 임베딩을 학습하고, 이를 dropout layer와 1D convolution layer를 거쳐 예측합니다. 손실 함수로는 Mean Squared Error (MSE)를 사용했습니다.

- **Performance Highlights**: 우리 모델은 두 가지 기준으로 평가되었습니다. TCGA-GBM 데이터셋에서는 1731개의 유전자와 의미 있는 연관성을, TCGA-BRCA에서는 838개의 유전자와 통계적으로 유의미한 상관 관계를 예측했습니다. 또한, 특정 암 형태와 관련된 유전자들(BRAF, ALK, KRAS for lung cancer, IDH for glioblastoma, CHEK for breast cancer)과 강한 연관성을 발견했습니다. 이러한 결과는 CT/MRI와 RNA-Seq 간의 연관성을 강하게 입증하며, 추가 연구의 필요성을 제시합니다.



### Neural Octahedral Field: Octahedral prior for simultaneous smoothing and sharp edge regularization (https://arxiv.org/abs/2408.00303)
Comments:
          project page: this https URL

- **What's New**: 이번 연구에서는 'octahedral field'를 도입하여 뉴럴 임플리시트 리프레젠테이션(neural implicit representation) 기반의 표면 재구성(surface reconstruction) 문제를 해결하고자 합니다. 이는 기존의 메서드들이 노이즈가 큰 환경에서 과적합(overfitting)되거나 과도하게 부드러운 재구성을 생성하는 문제를 보완하고, 독특한 구형 조화 함수(spherical harmonics) 표현을 활용합니다.

- **Technical Details**: 연구진은 구형 조화 함수와의 연계를 통해 'octahedral field'를 신경 필드(neural field)로 새롭게 제안하여, 탁월한 샤프 엣지(sharp edge) 보존 능력을 제공합니다. 특히, implicit geometry와 동시 학습을 진행하여 양질의 재구성을 이룰 수 있습니다. 또한, alignment loss와 smoothness loss를 디자인하여 학습 효율성을 극대화합니다.

- **Performance Highlights**: 이 접근법은 다양한 전통 및 신경 네트워크 데이터를 사용하는 기존 방법들을 능가하면서, 동시에 노멀(normal) 및 데이터에 대한 사전 정보(prior)를 요구하지 않기 때문에 매우 경쟁력 있는 성능을 보였습니다.



### Towards Flexible Evaluation for Generative Visual Question Answering (https://arxiv.org/abs/2408.00300)
- **What's New**: 시각 질의응답(Visual Question Answering, VQA) 평가의 한계를 극복하면서 멀티모달 언어 모델(MLLM)의 능력을 공정하고 정확하게 평가하기 위해 새로운 접근법을 제시합니다. 이 논문은 VQA 데이터셋의 자유 응답에 대한 평가를 위해 의미론 기반 평가자(Semantics-based Evaluator)를 제안합니다.

- **Technical Details**: 기존 VQA 평가는 정답을 완벽하게 일치시켜야 하는 Exact Match 방식을 사용하여 다양한 응답을 수용하지 못하고 있습니다. 이를 해결하기 위해, 이 논문에서는 정렬(Alignment), 일관성(Consistency), 일반화(Generalization)이라는 세 가지 핵심 속성을 제시하고, 이 속성들을 평가하기 위한 데이터셋으로 AVE(Assessing VQA Evaluators)를 제공합니다. 또한, 이 논문은 VQA 평가의 고유한 특징을 반영하여 세밀하게 설계된 '의미론적으로 유연한 VQA 평가자(SFVE)'를 제안합니다.

- **Performance Highlights**: 실험 결과, 제안된 평가자가 기존의 의미론 평가자들보다 성능이 우수함을 확인했습니다. 특히 ChatGPT와 최첨단 임베딩 모델인 Voyage-lite-02-Instruct도 뛰어넘는 성과를 보였습니다. 또한, 제안된 평가자는 BERT와 같은 인코더 모델과 디코더 전용 모델에도 일반화가 가능함을 보였습니다.



### Tails Tell Tales: Chapter-Wide Manga Transcriptions with Character Names (https://arxiv.org/abs/2408.00298)
- **What's New**: 이 논문은 시각 장애인이 만화를 접근할 수 있도록 돕는 새로운 방법을 제안합니다. 주요 목표는 만화 챕터 전체의 대화 기록(transcript)을 자동으로 생성하여 스토리의 일관성을 유지하는 것입니다. 저자들은 이를 위해 문장이 무엇을 말하는 지 파악하고(텍스트 탐지 및 필수/비필수 구분), 누가 말하는 지 밝히는 문제에 중점을 두었습니다. Magiv2라는 새로운 모델을 소개하며, 이는 높은 정밀도의 화자 구분(speaker diarisation)과 일관된 캐릭터 명명(character naming)을 제공합니다.

- **Technical Details**: Magiv2는 캐릭터 이름과 이미지를 포함하는 캐릭터 뱅크를 활용하여, 장 전체에 걸쳐 일관된 캐릭터 명명을 달성합니다. 또한, 모델은 말풍선 꼬리(speech-bubble tails)를 고려하여 텍스트와 화자의 연관성을 크게 향상시킵니다. 텍스트를 필수와 비필수로 분류하는 데 있어서는 글꼴 스타일과 텍스트 배치를 활용하여 시각적으로 구분합니다.

- **Performance Highlights**: Magiv2는 기존 모델에 비해 화자 구분(speaker attribution)과 일관된 캐릭터 명명(character identification) 측면에서 상당한 성능 향상을 보입니다. 추가로 확장된 PopManga 평가 데이터세트는 캐릭터 이름, 말풍선 꼬리, 텍스트-꼬리 연관성, 텍스트 분류에 대한 주석을 포함합니다. 이를 통해 76개의 만화 시리즈와 11K 이상의 캐릭터 정보를 담은 새로운 데이터세트도 공개되었습니다.



### EmoTalk3D: High-Fidelity Free-View Synthesis of Emotional 3D Talking Head (https://arxiv.org/abs/2408.00297)
Comments:
          ECCV 2024

- **What's New**: 이 논문은 감정 제어가 가능한 3D 대화 머리(3D talking heads) 생성을 위한 새로운 접근법을 제시하며, 이를 통해 향상된 입술 동기화와 렌더링 품질을 제공합니다. 기존의 방법들이 멀티뷰 일관성 및 감정 표현 부족 문제를 겪는 반면, 저자들은 EmoTalk3D 데이터셋을 수집하여 이에 대응합니다. 이를 통해 'Speech-to-Geometry-to-Appearance' 매핑 프레임워크를 제안합니다.

- **Technical Details**: 'Speech-to-Geometry-to-Appearance' 매핑 프레임워크는 주어진 오디오 특징으로부터 정확한 3D 지오메트리 시퀀스를 예측한 후, 예측된 지오메트리로부터 4D 가우시안(Gaussian)을 이용하여 3D 대화 머리의 외형을 합성합니다. 외형은 정적 가우시안(canonical Gaussians)과 동적 가우시안(dynamic Gaussians)으로 분리되고, 멀티뷰 비디오로부터 학습되어 자유뷰(free-view) 대화 머리 애니메이션을 렌더링합니다.

- **Performance Highlights**: 제안된 방법은 입 모양 생성의 정확성과 안정성을 향상시켰으며, 주름과 미묘한 표정과 같은 동적인 얼굴 디테일을 포착합니다. 실험을 통해 고충실도와 감정 제어가 가능한 3D 대화 머리 생성을 입증했습니다. 또한, EmoTalk3D 데이터셋은 35명의 피험자로부터 감정 설명이 포함된 멀티뷰 비디오 데이터를 담고 있어 모델 학습에 중요한 역할을 합니다.



### Head360: Learning a Parametric 3D Full-Head for Free-View Synthesis in 360{\deg} (https://arxiv.org/abs/2408.00296)
Comments:
          ECCV 2024

- **What's New**: 이 논문은 아티스트가 디자인한 고충실도(human head) 데이터셋을 바탕으로 360° 전방위 렌더링이 가능한 새로운 매개변수화된 인체 모델을 제안합니다. 이 모델은 특히 표정 구동 애니메이션(expression-driven animation), 헤어스타일 편집(hairstyle editing) 및 텍스트 기반 수정(text-based modifications) 영역에서 뛰어난 성능을 보여줍니다. 또한, 인체 모델을 구성하는 얼굴의 모양과 외형을 각각 고전 매개변수화 3D 메쉬 모델과 연결 신경 텍스처(neural texture)로 분리하여 표현합니다.

- **Technical Details**: 본 연구에서는 얼굴의 움직임과 외형을 효과적으로 분리하기 위해 '매개변수화 3D 메쉬 + 신경 텍스처' 방식을 채택했습니다. 또한, 머리카락과 얼굴 외형을 분해하는 방법을 제안하여 자유로운 머리 스타일 변경이 가능하도록 했습니다. 단일 이미지 입력 기반의 새로운 역적합(fitting) 방법도 도입하여 높은 일반화 및 충실도를 보장합니다. 이 모델은 기존의 2D와 3D 접근 방식의 단점을 극복하면서 360° 전방위 렌더링, 이미지 기반 피팅(fitting), 외형 편집, 애니메이션을 모두 단일 모델 내에서 가능합니다.

- **Performance Highlights**: 제안된 모델은 표현 및 외형을 매개변수 공간 내에서 잘 분리하여, 렌더링 및 애니메이션 품질에서 최신 성능(state-of-the-art)을 달성합니다. 실험 결과, 얼굴 움직임과 외형이 매개변수 공간에서 잘 분리되어 높은 품질의 3D 인체 모델을 생성하며, 피팅, 애니메이션 및 텍스트 기반 편집에서도 우수한 성능을 발휘합니다. 논문의 코드와 SynHead100 데이터셋은 해당 URL에서 공개됩니다.



### RDP: Ranked Differential Privacy for Facial Feature Protection in Multiscale Sparsified Subspac (https://arxiv.org/abs/2408.00294)
Comments:
          13 pages, 6 figures

- **What's New**: 이 논문에서는 얼굴 인식 시스템에서 개인 얼굴 이미지를 보호하기 위한 새로운 프라이버시 보호 방법을 제안합니다. 'Ranked Differential Privacy (RDP)'라는 새 접근법을 통해 민감한 얼굴 특징을 보호합니다. 다중 스케일 희소화된 특징 서브스페이스에서 얼굴 특징을 분해한 후, 가벼운 라플라스 (Laplacian) 노이즈를 적용해 최적화된 프라이버시 보장을 제공합니다.

- **Technical Details**: 기술적으로는 원본 얼굴 이미지를 다중 스케일 특징 공간으로 분해하여 희소한 특징 계수를 얻습니다. 그런 다음, 각 특징 계수가 프라이버시 예산에 미치는 영향을 평가한 후, 중요도가 높은 특징 계수에 최적화된 스케일의 노이즈를 추가합니다. 비선형 라그랑주 승수법 (Lagrange Multiplier) 및 두 가지 최적화 방법- NA(Normalization Approximation) 방법과 LMGD(LM optimization Gradient Descent) 방법-을 사용해 노이즈 스케일 매개변수를 최적화합니다.

- **Performance Highlights**: 제안된 RDP 방법은 두 개의 실제 세계 데이터셋에서 다른 첨단 기술보다 뛰어난 성능을 보였습니다. 특히, 프라이버시 예산이 0.2일 때, RDP는 다른 방법보다 약 10dB 높은 PSNR을 달성했습니다. 이는 얼굴 이미지 보호 효과가 크면서도 이미지의 시각적 품질을 크게 손상시키지 않음을 의미합니다.



### Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network (https://arxiv.org/abs/2408.00290)
- **What's New**: 이 논문에서는 그래프 네트워크를 기반으로 한 다중모달 파라미터 효율화 파인튜닝(multi-modal parameter-efficient fine-tuning) 기법을 제안했습니다. 이 방법은 이미지와 텍스트 설명을 결합해 멀티모달 피처를 생성하고, 그 피처들을 바탕으로 그래프를 구성합니다. EWC(Elastic Weight Consolidation) 정규화 기법을 손실 함수에 통합하여, 작업 학습 도중 발생할 수 있는 기억 손실 문제를 완화합니다. 이를 통해 OxfordPets, Flowers102, Food101 데이터셋에서 각각 4.45%, 2.92%, 0.23%의 정확도 향상을 달성했습니다.

- **Technical Details**: 제안된 모델은 네 가지 주요 모듈로 구성됩니다. 첫째, 멀티모달 피처 추출(Multi-Modal Feature Extraction) 모듈에서는 MLLM(Multi-Modal Large Language Model)을 통해 각 이미지에서 텍스트 설명을 생성하고, 이미지는 고정된 이미지 인코더와 텍스트 인코더를 통해 이미지 피처와 텍스트 피처를 생성합니다. 둘째, Multi-Modal Graph Construction 모듈에서는 멀티모달 피처 노드의 유사성을 바탕으로 그래프를 구성합니다. 셋째, GA-Net(Graph Adapter Net) 모듈에서는 그래프 노드에서 적절한 지식과 관계를 추출하여 피처를 학습합니다. 넷째, Prediction 모듈에서는 크로스 엔트로피(cross-entropy)와 EWC 정규화가 통합된 손실 함수를 사용하여 기억 손실 문제를 완화합니다.

- **Performance Highlights**: 제안된 방법은 OxfordPets 데이터셋에서 4.45%, Flowers102 데이터셋에서 2.92%, Food101 데이터셋에서 0.23%의 테스트 정확도 향상을 보였습니다. 이는 현재까지의 SOTA(state-of-the-art) 모델 대비 모두 더 높은 성능을 기록한 것입니다.



### Gradient Harmonization in Unsupervised Domain Adaptation (https://arxiv.org/abs/2408.00288)
Comments:
          IEEE TPAMI 2024

- **What's New**: 이 논문에서는 비지도 도메인 적응(Unsupervised Domain Adaptation, UDA)에서 도메인 정렬과 분류 작업 사이의 최적화 갈등을 해결하기 위해 Gradient Harmonization(GH)과 GH++라는 두 가지 새로운 접근법을 제안합니다. 이는 현재의 UDA 방법론이 이 두 작업을 동시에 최적화할 때 발생하는 갈등을 제대로 해결하지 못한다는 문제를 인식하고 이를 해결하려는 시도입니다.

- **Technical Details**: GH는 분류 작업과 도메인 정렬 작업 사이의 기울기 각도를 둔각에서 예각으로 변경하여 갈등을 해소하고, GH++는 이 각도를 수직 각도로 조정하여 두 작업의 최적화 방향에서 벗어나지 않도록 합니다. 이러한 방법들은 모델 최적화 과정에서 기하학적 인식을 활용하여 두 작업이 조화롭게 진행될 수 있도록 합니다. 또한, GH/GH++을 동적으로 가중된 손실 함수 형태로 변환하여 최적화 편의성과 효율성을 높였습니다.

- **Performance Highlights**: 실험 결과에 따르면, 제안된 방법론은 다양한 벤치마크 및 주류 UDA 모델에서 기존 UDA 기반을 향상시킬 뿐만 아니라 최근의 최신 모델들의 성능도 개선시킵니다. GH/GH++ 접근법은 대부분의 기존 UDA 방법론과 직접 통합될 수 있는 범용적인 성격을 가지고 있습니다.



### Diff3DETR:Agent-based Diffusion Model for Semi-supervised 3D Object Detection (https://arxiv.org/abs/2408.00286)
Comments:
          Accepted to ECCV2024

- **What's New**: 최근 3D 객체 탐지 분야에서 반감독(진) 학습에 대한 흥미로운 새로운 개발이 있었습니다. 논문 'Diff3DETR'에서는 반감독 3D 객체 탐지를 위한 에이전트 기반 확산 모델을 소개했습니다. 이 모델은 주석이 달리지 않은 포인트 클라우드(point cloud)에 대한 의사 레이블(pseudo-label)을 생성하는 교사-학생 프레임워크를 사용합니다. 특히, 에이전트 기반 객체 쿼리 생성기(object query generator)가 동적 장면에 효과적으로 적응하는 객체 쿼리를 생성하며, 박스 인식 디노이징(box-aware denoising) 모듈은 DDIM 디노이징 과정과 트랜스포머 디코더의 장거리 어텐션(long-range attention)을 사용하여 경계 상자를 점진적으로 정제합니다. ScanNet 및 SUN RGB-D 데이터 세트에 대한 광범위한 실험 결과, Diff3DETR이 최첨단 반감독 3D 객체 탐지 방법보다 우수한 성능을 보여줍니다.

- **Technical Details**: 이 논문은 Diff3DETR이라는 모델을 소개합니다. 이 모델은 통합된 DETR 아키텍처 내에서 에이전트 기반 객체 쿼리 생성기와 박스 인식 디노이징 모듈을 포함한 확산 모델 기반의 반감독 3D 객체 탐지 모델입니다. 이 모델은 다음과 같은 주요 기술적 세부 사항을 포함하고 있습니다: 1) Mean Teacher 프레임워크를 사용하여 확산 모델과 DETR 아키텍처를 통합합니다. 2) 에이전트 기반 객체 쿼리 생성기를 사용하여 동적 장면에 적응하는 객체 쿼리를 생성합니다. 3) DDIM 디노이징 과정과 트랜스포머 디코더를 결합하여 초기 상자의 노이즈를 제거하고 정확한 객체 예측을 달성합니다.

- **Performance Highlights**: Diff3DETR 모델은 ScanNet과 SUN RGB-D 데이터 세트에서 진행된 광범위한 실험을 통해 기존의 최첨단 반감독 3D 객체 탐지 방법보다 우수한 성능을 입증했습니다. 특히, 이 모델은 더 높은 품질의 의사 레이블을 생성하고, 동적 장면에 적응하며, 초기 상자의 노이즈를 효과적으로 제거하여 정확한 3D 객체 탐지를 달성합니다.



### DMESA: Densely Matching Everything by Segmenting Anything (https://arxiv.org/abs/2408.00279)
- **What's New**: 이번에 발표된 논문에서는 MESA와 DMESA라는 새로운 특징 매칭(feature matching) 방법을 제안합니다. 이러한 방법들은 Segment Anything Model(SAM)을 활용하여 매칭의 중복성을 효과적으로 줄이는 데 중점을 둡니다. SAM의 고급 이미지 이해를 바탕으로 점(match) 매칭 이전에 암묵적 의미 영역(implicit-semantic area) 매칭을 설정하는 것이 핵심 아이디어입니다.

- **Technical Details**: MESA는 희소 매칭 프레임워크(sparse matching framework)를 채택하고, SAM 결과물에서 novel Area Graph(AG)를 통해 후보 영역을 얻어내는 방식입니다. 그 후, 후보 영역 간의 매칭은 그래프 에너지 최소화(graph energy minimization)로 공식화되어 AG에서 유도된 그래픽 모델로 해결됩니다. MESA의 효율성 문제를 해결하기 위해, DMESA는 밀집 매칭 프레임워크(dense matching framework)를 적용하여 제안되었습니다. AG로 후보 영역을 식별한 후, DMESA는 가우시안 혼합 모델(Gaussian Mixture Model)과 기대 최대화(Expectation Maximization)을 통해 생성된 밀집 매칭 분포로 영역 매칭을 설정합니다.

- **Performance Highlights**: DMESA는 MESA에 비해 반복적인 계산을 덜 필요로 하여 속도 개선이 약 5배 정도 상승하지만, 여전히 경쟁력 있는 정확도를 유지합니다. 제안된 방법들은 실내 및 실외 장면을 아우르는 5개 데이터셋에서 광범위하게 평가되었습니다. 결과는 모든 데이터셋에서 다섯 가지 포인트 매칭 기준법에 대해 일관된 성능 개선을 보여줍니다. 또한, 제안된 방법들은 이미지 해상도 변동에 대한 강한 일반화 및 향상된 견고성을 나타냅니다. 코드도 공개되어 있습니다.



### Improving Image De-raining Using Reference-Guided Transformers (https://arxiv.org/abs/2408.00258)
- **What's New**: 이 논문에서는 기존의 이미지 제거 (de-raining) 기술을 개선하기 위해 참조가이드(reference-guided) 기반의 제거 필터를 제안합니다. 이 새로운 필터는 깨끗한 참조 이미지(clean image)를 사용하여 결과를 더욱 정제하는 Transformer 네트워크를 사용합니다. 이를 통해 다양한 데이터셋에서 기존의 방법들에 비해 향상된 성능을 증명합니다.

- **Technical Details**: 제안된 프레임워크는 특징 추출기(feature extractor), 특징 주목 모듈(feature attention module), 그리고 특징 융합 모듈(feature fusion module)로 구성되어 있습니다. 기존의 이미 제거된 이미지와 참조 이미지를 활용하여 여러 스케일의 특징을 추출하며, 주목 모듈을 통해 참조 이미지에서 유용한 특징 패치를 찾습니다. 마지막으로, 융합 모듈이 여러 스케일의 특징을 통합하여 최종 결과를 생성합니다.

- **Performance Highlights**: 새로운 제안된 방식은 기존의 모든 기반 방법들 - prior-based, CNN-based, transformer-based 접근법들에 대해 성능을 향상시킬 수 있습니다. 다양한 데이터셋 실험 결과, 제안된 프레임워크가 기존 모델들을 'plug-and-play' 방식으로 사용하면서 성능을 크게 향상시키는 것을 확인할 수 있었습니다.



### LoopSparseGS: Loop Based Sparse-View Friendly Gaussian Splatting (https://arxiv.org/abs/2408.00254)
Comments:
          13 pages, 10 figures

- **What's New**: 최근 3D 가우시안 스플래팅(3D Gaussian Splatting, 3DGS)을 기반으로 하는 프레임워크인 LoopSparseGS가 제안되었습니다. 이 프레임워크는 희소한 입력 뷰로부터의 소설 뷰 생성 성능을 향상시키기 위해 루프 기반의 Progressive Gaussian Initialization(PGI) 전략을 도입하였습니다. 또한, Depth-alignment Regularization(DAR)과 Sparse-friendly Sampling(SFS) 전략을 통해 더 정밀한 기하학적 감독과 초과 크기 가우시안 타원체 문제를 해결합니다.

- **Technical Details**: LoopSparseGS는 루프 기반의 PGI 전략을 통해 초기화된 점군을 밀집화하고, 구조로부터의 희소한 깊이와 밀도 모노큘러(depth)를 사용하여 기하학적 감독을 제공합니다. 또한, DAR 접근 방식은 절대 규모의 희소한 깊이와 관련된 모노큘러 깊이를 정렬하여 더 매끄럽고 정밀한 깊이 렌더링을 생성합니다. SFS 전략은 높은 오류 픽셀과 관련된 지나치게 큰 가우시안 타원체를 식별하고 분할하여 보다 세부적인 기하학적 및 렌더링 결과를 제공합니다.

- **Performance Highlights**: 종합적인 실험 결과, LoopSparseGS는 실내, 실외, 객체 수준의 다양한 이미지 해상도에서 기존의 최첨단 방법보다 뛰어난 성능을 보였습니다. 네 가지 데이터셋에 대한 실험을 통해 희소 입력 소설 뷰 생성 작업에서 우수한 성능을 입증했습니다.



### Task-Adapter: Task-specific Adaptation of Image Models for Few-shot Action Recognition (https://arxiv.org/abs/2408.00249)
Comments:
          Accepted by ACM MM2024

- **What's New**: Few-shot action recognition을 위한 간단하지만 효과적인 방법, Task-Adapter, 소개합니다. 이 방법은 사전 학습된 모델의 마지막 몇 개 층에 Task-Adapter를 도입하며, 사전 학습된 모델의 파라미터는 고정시킵니다. 이는 전체 모델 파라미터를 미세 조정할 때 발생할 수 있는 과적합 문제를 완화하고, 영상 클래스 내 공유 정보와 클래스 간 차별 정보를 효과적으로 포착합니다.

- **Technical Details**: Task-Adapter는 주어진 작업 내의 서로 다른 비디오에서 태스크-특정(self-attention)을 수행하기 위해 고정된 self-attention 레이어를 재사용합니다. 또한, 이 방법은 Transformer 백본, 특히 ViT에서 이미지 토큰에 대한 원래의 공간적 self-attention을 유지하면서 태스크-특정 self-attention을 추가하여 단지 잘 추출된 특징 수준에서 태스크-특정 적응을 수행하는 기존 접근법과 달리 특징 추출 과정 중에 태스크-특정 적응을 수행합니다.

- **Performance Highlights**: Task-Adapter는 네 가지 표준 few-shot action recognition 데이터셋에서 일관되게 우수한 성과를 보여주며, 특히 Temporal challenging SSv2 데이터셋에서 기존 최첨단 방법들을 큰 차이로 능가합니다. 이로 인해 사전 학습된 모델의 일반화 능력을 최대한 활용하면서 도메인-특정 지식을 통합하는 데 성공했습니다.



### A Prior Embedding-Driven Architecture for Long Distance Blind Iris Recognition (https://arxiv.org/abs/2408.00210)
- **What's New**: 이 논문은 장거리에서 찍힌 불명확한(blind) 홍채 이미지 복원을 위한 새로운 아키텍처를 제안합니다. 제안된 솔루션은 Iris-PPRGAN이라는 홍채 이미지 복원 네트워크와 Insight-Iris라는 강력한 홍채 분류기로 구성됩니다.

- **Technical Details**: Iris-PPRGAN은 Generative Adversarial Network (GAN)과 Deep Neural Network (DNN)로 구성된 두 가지 주요 컴포넌트를 포함합니다. GAN은 Prior Decoder로 사용되고, DNN은 인코더로 사용됩니다. Insight-Iris는 기존의 InsightFace의 병목 모듈(bottleneck module)을 수정하여 제작되었습니다. 낮은 품질의 불명확한 홍채 이미지는 먼저 Iris-PPRGAN을 통해 복원되며, 이후 복원된 홍채 이미지는 Insight-Iris를 통해 인식됩니다.

- **Performance Highlights**: 제안된 방법은 공개 CASIA-Iris-distance 데이터셋에서 정량적 및 정성적으로 모두 기존 방법들보다 우수한 결과를 보여주었습니다. 특히, 복원된 장거리 불명확한 홍채 이미지의 인식률이 90%에 도달했으며, 이는 복원 전 홍채 이미지에 비해 약 10 퍼센트 포인트 향상된 성능을 나타냅니다.



### OmniParser for Pure Vision Based GUI Agen (https://arxiv.org/abs/2408.00203)
- **What's New**: 새로운 연구인 	extsc{OmniParser}는 사용자의 인터페이스(UI) 스크린샷을 구조화된 요소들로 파싱(parsing)하는 기술을 소개합니다. 이로 인해 GPT-4V와 같은 멀티모달 모델이 더 정확하게 동작할 수 있도록 돕습니다.

- **Technical Details**: 	extsc{OmniParser}는 상호작용 가능한 아이콘을 감지하는 Detection 모델과 아이콘의 기능적 의미를 추출하는 Caption 모델로 구성되어 있습니다. 이를 위해 인기 있는 웹페이지들을 바탕으로 상호작용 가능한 아이콘 감지 데이터셋과 설명 데이터셋을 구성했습니다. 이 데이터셋을 통해 모델들을 미세 조정(fine-tune)하여 사용자의 인터페이스를 더 잘 이해할 수 있도록 했습니다.

- **Performance Highlights**: 	extsc{OmniParser}는 ScreenSpot 벤치마크에서 GPT-4V의 성능을 크게 향상시켰습니다. Mind2Web 및 AITW 벤치마크에서도 스크린샷만을 이용한 입력으로, 추가 정보를 요구하는 GPT-4V 기반모델을 뛰어넘는 성능을 발휘했습니다.



### S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images (https://arxiv.org/abs/2408.00191)
Comments:
          Accepted to the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2024

- **What's New**: 최근 발표된 논문에서는 S-SYNTH라는 혁신적인 오픈 소스 피부 시뮬레이션 프레임워크를 소개합니다. 이 프레임워크는 다양한 피부 색조와 병변(lesion)의 모습을 가진 합성 피부와 3D 모델을 빠르게 생성하여 AI 모델의 개발 및 평가에 기여할 수 있습니다. 또한, 실제 피부 데이터를 기반으로 한 AI 모델의 한계와 편향성을 줄이기 위한 목적으로 설계되었습니다.

- **Technical Details**: S-SYNTH는 anatomically inspired multi-layer, multi-component skin and growing lesion model을 사용하여 피부의 외관, 색상, 모발 존재, 병변 형태 및 혈액 비율 등의 변수를 조절할 수 있는 고도로 상세한 3D 피부 모델을 생성합니다. 이 모델은 3D 모델링, 애니메이션 및 시각 효과를 위해 Houdini 소프트웨어와 Python API를 사용하여 구현되었으며, Mitsuba 3 연구지향 렌더링 시스템을 통해 합성 이미지를 생성합니다.

- **Performance Highlights**: S-SYNTH로 생성된 합성 이미지는 제한된 실제 이미지 데이터셋을 사용할 때 피부 병변의 분할 성능을 향상시키는 데 도움이 됩니다. 특히, S-SYNTH 합성 이미지를 사용하여 훈련된 모델은 실제 피부 데이터를 바탕으로 한 모델과 유사한 성능 경향을 보이며, 레이블 오류와 제한된 데이터셋의 한계를 완화할 수 있습니다.



### CC-SAM: SAM with Cross-feature Attention and Context for Ultrasound Image Segmentation (https://arxiv.org/abs/2408.00181)
Comments:
          Accepted to ECCV 2024

- **What's New**: Segment Anything Model (SAM)은 자연 이미지 세분화에서 큰 성공을 거두었지만, 의료 영상 분야에서는 여러 도전 과제에 직면했습니다. 이를 해결하고자 종합적인 수정안을 소개합니다. CNN 분기를 이미지 인코더로 사용하고, SAM의 Vision Transformer (ViT) 인코더와 결합하는 새로운 변이주의 주의 퓨전 모듈을 도입하였습니다. 또한, ChatGPT를 활용해 텍스트 기반의 프롬프트를 생성하여 의료 영상 세분화 성능을 향상시켰습니다.

- **Technical Details**: CC-SAM 모델을 제안하며, 고정된 CNN과 ViT 인코더를 각각 사용한 후, 어댑터를 통해 더욱 효율적으로 미세 조정하였습니다. 변이주의 주의 퓨전 (variational attention fusion) 메커니즘을 도입하여, CNN과 ViT 분기 특징 간의 시너지 효과를 높였습니다. 또한, ChatGPT를 이용해 생성된 텍스트 프롬프트를 사용하는 전략을 도입하여 세분화 성능을 향상시켰습니다. 이 접근 방식은 기존의 메스 데이터셋에 대한 토크나이제이션 접근법에서 발생할 수 있는 문제를 해결합니다.

- **Performance Highlights**: CC-SAM은 기존의 의료 영상 세분화를 위한 SAM 최적화 전략보다 더 뛰어난 성능을 보였습니다. 특히, GPT-4로 생성된 텍스트 프롬프트를 사용한 결과, 모델이 초음파 의료 이미지의 뉘앙스를 더 잘 이해하고 세분화 정확도를 높였습니다. 또한, CC-SAM은 새로운 변이주의 주의 퓨전 기법을 통해 특성을 결합하여 성능을 크게 향상시켰습니다.



### Strike the Balance: On-the-Fly Uncertainty based User Interactions for Long-Term Video Object Segmentation (https://arxiv.org/abs/2408.00169)
- **What's New**: 본 논문에서는 상호작용적(Interactive) 및 준자동(Semi-Automatic) 접근법을 결합한 '게으른 비디오 객체 분할(Lazy Video Object Segmentation, ziVOS)'을 제안합니다. 기존의 오프라인 기반 비디오 객체 분할과는 달리, 온라인으로 녹화된 시퀀스를 대상으로 합니다. 이는 사용자 피드백을 실시간으로 반영하며 오랜 기간 동안 객체 추적을 유지합니다.

- **Technical Details**: ziVOS는 추적 상태의 불확실성을 추정하여 사용자의 상호작용이 필요한지를 결정합니다. 사용자는 클릭 기반의 상호작용으로 객체를 지정하며, 각 프레임 및 객체당 한 번의 상호작용만 허용됩니다. 이를 통해 예측된 마스크의 불확실성이 높을 경우, 사용자 수정 또는 가상 수정(pseudo-corrections)을 통해 모델의 예측을 정교화합니다.

- **Performance Highlights**: 최신 LVOS 데이터셋(long-term 동영상 포함)을 사용하여 제안된 방법을 평가하였습니다. 제안된 Lazy-XMem은 추적 상태의 성능을 예측하기 위해 엔트로피(entropy)를 사용하며, 이를 통해 오랫동안 지속되는 시퀀스에서도 견고한 추적 성능을 유지합니다. 새로운 평가지표를 도입하여 메소드의 강인성과 사용자의 작업량을 측정합니다.



### Certifying Robustness of Learning-Based Keypoint Detection and Pose Estimation Methods (https://arxiv.org/abs/2408.00117)
Comments:
          25 pages, 10 figures, 5 tables

- **What's New**: 이 연구는 비전 기반 6D 객체 포즈 추정(two-stage 6D object pose estimation)의 지역적 강건성(local robustness) 인증에 초점을 맞추고 있습니다. 두 단계 방법론은 우선 딥 뉴럴 네트워크를 사용한 키포인트(keypoint) 회귀를 수행하고, 그 다음 Perspective-n-Point (PnP) 기술을 적용하여 높은 정확도의 객체 포즈 추정을 달성합니다. 이 연구는 이러한 방법들의 강건성을 시스템 수준에서 인증하는 첫 번째 시도로, 현실 세계의 시나리오에서 대규모 키포인트 기반 포즈 추정 문제의 강건성을 인증하고자 합니다.

- **Technical Details**: 이 연구는 포즈 추정의 지역적 강건성 인증을 신경망 분류 문제로 변환하여 해결하려 합니다. 이를 위해 기존의 비선형 연산을 대체하고, 이미지의 볼록 껍질(convex hull)을 입력 명세로 사용하여 의미론적 입력 변형을 보다 정확하게 묘사합니다. 또한, 민감도 분석을 통해 포즈 정확성 기준을 키포인트 정확도로 전파하고, 이를 통해 최대 허용 오차 임계값 설정 문제를 최적화합니다. 각 픽셀을 개별 클래스로 간주하여, 이러한 임계값은 분류와 유사한 출력 명세를 정의합니다.

- **Performance Highlights**: 주요 구성 요소들이 포괄적인 평가를 통해 강건성을 가지고 있다는 것을 입증하며, 현실적인 변형에 대한 검증을 통해 그 효과를 검토했습니다. 이 인증 프레임워크는 포즈 추정이 입력 이미지의 변형에도 일정 범위 내에서 동일한 성능을 유지할 수 있는지 확인하는 데 중점을 둡니다.



### Automated Sperm Morphology Analysis Based on Instance-Aware Part Segmentation (https://arxiv.org/abs/2408.00112)
Comments:
          Accepted to ICRA 2024

- **What's New**: 이 논문은 기존의 수작업 기반 정자 형태 분석을 자동화하기 위해 새로운 기술을 제안합니다. 제안된 기술은 포괄적이고 정량적인 형태 분석을 가능하게 하며, 특히 길고 구부러진 정자 꼬리의 형태 측정에 중점을 둡니다.

- **Technical Details**: 새로운 attention-based instance-aware part segmentation network 이 설계되어 경계 상자 밖의 문맥을 재구성하고 Feature Pyramid Network(FPN)를 통해 왜곡된 특징을 수정합니다. 정자 꼬리 형태 측정을 위해 outlier filtering method 와 endpoint detection algorithm 이 포함된 자동화된 centerline 기반 측정 방법이 제안되었습니다.

- **Performance Highlights**: 제안된 네트워크는 기존의 최첨단 RP-R-CNN을 9.2% 정도 능가했으며, 제안된 꼬리 형태 측정 방법은 길이, 폭, 곡률 측정에서 각각 95.34%, 96.39%, 91.2% 의 높은 정확도를 달성했습니다.



### WAS: Dataset and Methods for Artistic Text Segmentation (https://arxiv.org/abs/2408.00106)
Comments:
          Accepted by ECCV 2024

- **What's New**: 이 논문에서는 예술 텍스트 분할(artistic text segmentation) 작업을 다루고 있으며, 이를 위해 새로운 실세계 예술 텍스트 분할 데이터셋인 WAS-R을 구성했습니다. 기존의 텍스트 분할 방법들은 규칙적인 텍스트에는 유의한 성과를 보였으나, 예술적인 텍스트에서는 성능이 저조했습니다.

- **Technical Details**: 예술 텍스트 분할의 주요 도전 과제는 (1) 예술 텍스트의 스트로크 형태가 다양하고 복잡하다는 것과 (2) 전반적인 위상 구조가 복잡하다는 점입니다. 이를 해결하기 위해, 우리는 계층별 관성을 가진 퀘리(layer-wise momentum query) 디코더와 골격 도움 헤드(skeleton-assisted head)를 제안했습니다. 또한, 대규모 멀티모달 모델과 확산 모델(diffusion model)을 활용한 데이터 합성 전략을 제안하여 실제적인 이미지와 라벨을 생성했습니다.

- **Performance Highlights**: 실험 결과, 제안된 방법과 합성 데이터셋이 예술 텍스트 분할 성능을 크게 향상시켰음을 확인했습니다. 특히, 다른 공개 데이터셋에서도 최첨단 성능(SOTA)을 달성하였으며, 제안된 모델은 미세 조정 없이도 경쟁력 있는 성능을 발휘했습니다.



### From Attributes to Natural Language: A Survey and Foresight on Text-based Person Re-identification (https://arxiv.org/abs/2408.00096)
- **What's New**: 최근 텍스트 기반의 사람 재식별(Text-based Person Re-ID) 분야에서, 여러 기술적인 측면을 종합적으로 정리한 리뷰 논문이 등장했습니다. 이 논문은 텍스트 기반 사람 재식별의 새로운 분류 체계를 제안하며, 평가(Evaluation), 전략(Strategy), 아키텍처(Architecture), 최적화(Optimization) 측면에서 검토합니다.

- **Technical Details**: 텍스트 기반 사람 재식별에서 속성(attribute) 및 자연어(natural language)을 이용한 식별 개념을 기본적인 개념으로 다루고 있습니다. 주요 데이터셋과 평가 지표, 특징 추출 전략, 네트워크 아키텍처, 모델 최적화 및 모달리티 정렬을 위한 Loss 함수 등을 심층 분석합니다. 이 리뷰는 또한 이 분야의 현재 도전 과제를 확인하고, 이러한 과제를 해결하기 위한 향후 연구 방향성과 베이스라인 아키텍처(기준 구조)를 제시하고 있습니다.

- **Performance Highlights**: 기존 연구에서는 속성을 이용한 사람 재식별 방법들이 높은 인식 정밀도와 해석 가능성을 제공하지만, 텍스트 기반 접근 방식이 보다 유연하고 강력할 수 있다는 것을 밝혔습니다. 다양한 방법들이 모달리티 격차를 줄이기 위해 사용될 수 있으며, 자연어 처리가 이를 더 잘 지원할 수 있습니다. 예를 들어, 자유 형식의 자연어 기술은 예전의 속성 기반 접근 방식보다 더 많은 정보를 포괄적으로 담을 수 있는 장점을 가집니다.



### Localized Gaussian Splatting Editing with Contextual Awareness (https://arxiv.org/abs/2408.00083)
- **What's New**: 최신 텍스트 기반 3D 객체 생성 기술은 큰 성공을 거두었지만, 배경을 고려하지 않아 조명 불일치 문제를 초래했습니다. 이를 해결하기 위해 우리는 3D Gaussian Splatting (3DGS) 표현에 기반한 조명 인식 3D 씬 편집 파이프라인을 도입했습니다.

- **Technical Details**: 우리의 접근 방식은 조건부 2D Diffusion 모델의 채우기(inpainting) 작업이 조명 일치 측면에서 일관성이 있다는 핵심 관찰에 기반합니다. 이 접근법은 앵커 뷰 제안(AVP) 알고리즘을 도입해 장면 조명을 가장 잘 표현하는 단일 뷰를 선택하여 초기 가이던스로 사용합니다. 이후 심도 안내 채우기 점수 증류 샘플링(DI-SDS)을 통해 텍스처를 강화합니다.

- **Performance Highlights**: 우리는 조명과 그림자가 명확한 실제 씬에서 편집을 평가하면서 기존 텍스트 기반 3D 편집 방법들에 비해 우수한 성능을 입증했습니다.



### Evaluating Transfer Learning in Deep Learning Models for Classification on a Custom Wildlife Dataset: Can YOLOv8 Surpass Other Architectures? (https://arxiv.org/abs/2408.00002)
Comments:
          This paper is being reviewed by SN Computer Science (springer journal)

- **What's New**: 이번 연구에서는 심층 학습 기반 기술을 사용하여 멸종 위기에 처한 동물 종을 자동으로 모니터링하는 방법을 연구했습니다. 심층 신경망(Deep Learning) 및 전이 학습(Transfer Learning) 기법을 활용하여 DenseNet, ResNet, VGGNet, YOLOv8 등의 다양한 모델을 비교했습니다. 결과적으로 YOLOv8 모델이 97.39%의 학습 정확도와 96.50%의 F1 스코어를 기록하며 가장 우수한 성능을 보였습니다.

- **Technical Details**: 연구진은 iNaturalist, ZooChat와 같은 신뢰할 수 있는 온라인 데이터베이스를 활용하여 맞춤형 데이터셋을 구축했습니다. 각 종별로 50장의 이미지가 포함되었고, 총 1150장의 이미지로 이루어진 균형 잡힌 데이터셋을 만들었습니다. 데이터 전처리 과정에서는 이미지의 비율을 1:1로 맞추고 해상도를 400x400으로 고정했으며, 정규화를 통해 모델의 수렴 속도를 높였습니다. 데이터셋은 80%의 훈련 데이터와 20%의 검증 데이터로 나누어졌고, 다양한 데이터 증강 기법을 적용하여 일반화 능력을 향상시켰습니다. 전이 학습 기법을 통해 사전 학습된 모델의 가중치를 동결하고 출력층만 맞춤형 완전 연결층으로 교체했습니다.

- **Performance Highlights**: YOLOv8 모델은 훈련 정확도 97.39%, F1 스코어 96.50%로 다른 모델들보다 뛰어난 성능을 보였습니다. 이는 DenseNet, ResNet, VGGNet 등 다른 인기있는 모델을 능가하는 결과입니다. 이 연구는 기존 인간 주도 모니터링 방법보다 높은 정확도와 효율성을 제공하는 YOLOv8 기반의 자동화된 야생 동물 모니터링 시스템이 멸종 위기 동물 보호에 크게 기여할 수 있음을 시사합니다.



### Replication in Visual Diffusion Models: A Survey and Outlook (https://arxiv.org/abs/2408.00001)
Comments:
          The first survey focuses on replication in visual diffusion models. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 시각적 확산 모델(Visual diffusion models)은 창의적인 AI 분야에서 고품질의 다양성을 가진 콘텐츠를 생성해 큰 변화를 일으켰습니다. 본 논문은 이러한 모델이 학습 과정에서 이미지를 기억하고 이를 추론 과정에서 다시 생성함으로써 프라이버시, 보안, 저작권에 대한 문제를 야기하는 현상을 최초로 포괄적으로 리뷰합니다.

- **Technical Details**: 논문은 복제 현상을 해명(unveiling), 이해(understanding), 완화(mitigating)라는 세 가지 측면으로 나누어 기존 연구를 체계적으로 분류합니다. 해명 부분에서는 복제되는 사례를 탐지하는 방법을 중점으로 다루고, 이해 부분에서는 이 현상의 근본적인 메커니즘과 요인을 분석하며, 완화 부분에서는 이를 줄이거나 제거하기 위한 전략을 개발하는 데 중점을 둡니다.

- **Performance Highlights**: 본 논문은 특히 헬스케어 분야에서 환자 데이터와 관련된 프라이버시 문제가 복제 현상으로 인해 심각하게 우려된다는 점을 강조합니다. 결론 부분에서는 복제를 탐지하고 벤치마킹하는 것의 어려움과 같은 현존하는 도전 과제와 보다 견고한 완화 기술 개발을 위한 향후 방향성을 논의합니다.



### AMAES: Augmented Masked Autoencoder Pretraining on Public Brain MRI Data for 3D-Native Segmentation (https://arxiv.org/abs/2408.00640)
- **What's New**: 이 연구는 큰 규모의 도메인-특정 데이터셋에서 3D 시맨틱 세그멘테이션 모델의 셀프-슈퍼바이즈드 프리트레이닝(self-supervised pretraining) 영향력을 조사합니다. 연구팀은 공개 소스로부터 44,756개의 뇌 MRI 볼륨을 포함하는 최대의 공개 데이터셋인 BRAINS-45K를 소개합니다. 또한 최신 세그멘테이션 아키텍처를 프리트레이닝하기 위해 설계를 간소화하고 최적화한 방법들로 재검토하였으며, 새로운 증강 전략을 결합한 AMAES 프레임워크를 제안합니다.

- **Technical Details**: AMAES 프레임워크는 마스킹 이미지 모델링(Masked-image-modeling)과 강도 기반의 증강 복귀(intensity-based augmentation reversal)에 기반을 두고 있으며, 메모리 사용량, 실행 시간, 및 파인튜닝 성능을 균형 있게 조정합니다. U-Net과 MedNeXt 아키텍처를 백본으로 사용하여 세 가지 까다로운 다운스트림 작업에서 프리트레이닝 효과를 평가하였습니다.

- **Performance Highlights**: AMAES를 사용하여 제안된 데이터셋으로 프리트레이닝한 결과, 평가된 경우의 대다수에서 세그멘테이션 성능이 크게 개선되었습니다. 또한, 대규모 데이터셋에서 프리트레이닝을 수행하는 경우에도 증강을 사용하여 모델을 프리트레이닝하는 것이 유익한 것으로 나타났습니다.



### Privacy-preserving datasets by capturing feature distributions with Conditional VAEs (https://arxiv.org/abs/2408.00639)
Comments:
          Accepted at BMVC 2024

- **What's New**: 딥 러닝 애플리케이션을 위한 데이터셋 생성 문제를 해결하기 위해 새로운 접근 방식을 제안합니다. 이 연구는 미리 학습된 비전 모델(Vision Foundation Models)에서 추출한 특성 벡터(feature vectors)를 학습한 조건부 변이 오토인코더(CVAE)를 사용합니다. 이를 통해 원본 데이터와 다르면서도 다양하고 프라이버시를 보호하는 합성 특성 벡터를 생성할 수 있습니다.

- **Technical Details**: 제안된 방법은 미리 학습된 비전 모델에서 복잡한 패턴을 효과적으로 탐지하고 표현할 수 있는 특성을 이용합니다. CVAE(Conditional Variational Autoencoder)를 학습하여 데이터 분포를 정확하게 캡처하고 원본 데이터를 공개하지 않고도 필요한 데이터셋 크기를 샘플링할 수 있습니다. 이 접근 방식은 기존의 k-익명성(k-anonymity) 기반의 방법보다 더 다양하고 강력한 데이터셋을 생성합니다.

- **Performance Highlights**: 이 방법은 의료 및 자연 이미지 도메인 모두에서 기존 방법보다 뛰어난 성능을 보였습니다. 특히, 데이터 다양성과 모델의 강건성(robustness) 측면에서 우수한 결과를 나타냈습니다. 이는 프라이버시를 유지하면서도 사용자 데이터를 보호하고, 구체적인 이미지(또는 임베딩 이미지)를 공개하지 않습니다.



### SynesLM: A Unified Approach for Audio-visual Speech Recognition and Translation via Language Model and Synthetic Data (https://arxiv.org/abs/2408.00624)
- **What's New**: 이번 연구에서 우리는 SynesLM이라는 통합 모델을 소개합니다. 이 모델은 오디오-비주얼 자동 음성 인식(AV-ASR)과 시각적 언어 번역(VST/VMT)의 세 가지 멀티모달 언어 이해 작업을 수행할 수 있습니다. 이전 연구와 달리, 우리의 연구는 전체 프레임 내에서 객체와 동작 등의 더 일반적인 비주얼 정보를 탐색합니다. 또한, 합성 이미지 데이터를 사용하여 이미지와 음성 데이터 간의 상관성을 향상시켰습니다.

- **Technical Details**: SynesLM은 최신 언어 모델의 발전을 활용하여 오디오-비주얼 자동 음성 인식(AV-ASR), 비주얼 지원 음성 번역(VST), 비주얼 기계 번역(VMT)과 같은 복잡한 언어 작업을 능숙하게 처리할 수 있는 통합 접근 방식을 채택하고 있습니다. 최근 멀티모달 언어 이해 데이터셋인 How2와 같은 데이터 세트의 품질을 향상시키기 위해 합성 이미지 데이터 복구 파이프라인을 제안했습니다. 시각적 모달리티의 경우 비디오 클립에서 하나의 프레임을 무작위로 선택하여 비주얼 입력으로 사용하고, 사전 학습된 CLIP 모델을 사용하여 이미지의 전체 피처를 추출했습니다. 음성 입력 처리는 SSL 특성 추출기를 사용하여 음성을 이산 토큰으로 변환합니다.

- **Performance Highlights**: SynesLM은 다양한 작업에서 뛰어난 성능을 기록했습니다. VisSpeech 데이터셋에서 제로샷(Zero-shot) AV-ASR 작업에서 Word Error Rate(WER)를 43.4%에서 39.4%로 낮추며 SOTA 성능을 달성했습니다. 또한 VST에서 BLEU 점수를 37.2에서 43.5로, VMT에서 BLEU 점수를 54.4에서 54.8로 향상시켰습니다.



### Regional quality estimation for echocardiography using deep learning (https://arxiv.org/abs/2408.00591)
- **What's New**: 최근 발표된 연구는 심초음파 이미지의 품질을 자동으로 추정하는 세 가지 방법을 비교하여, 기존 연구의 한계를 극복하고 실용적인 사용성을 높였습니다. 연구는 심초음파의 보기 정확성과 이미지 품질을 구분하지 못했던 이전 연구들과 달리, 심초음파 이미지의 지역적 품질을 평가하는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 본 연구에서는 세 가지 자동 이미지 품질 추정 방법을 개발하였습니다: 1) 기존의 픽셀 기반 메트릭, 예를 들어 심근을 관심영역(ROI)으로 하고 좌심실(좌심방)을 배경으로 하는 Generalized Contrast-to-Noise Ratio(gCNR) 2) U-Net 모델을 사용하여 B-모드 이미지로부터 코히어런스를 예측하는 지역적 이미지 코히어런스 3) 심초음파 이미지의 각 지역의 품질을 직접적으로 예측하는 End-to-End 딥러닝 모델. 세 가지 방법 모두 심장 전문의 세 명이 수동으로 작성한 지역 이미지 품질 주석과 비교 평가되었습니다.

- **Performance Highlights**: 성능 평가 결과, gCNR 메트릭은 낮은 스피어만 상관계수(ρ = 0.24)를 기록해 저조한 성능을 보였으나, End-to-End 학습 모델이 가장 우수한 성능(ρ = 0.69)을 기록했습니다. 이는 관찰자 간의 상관계수(ρ = 0.63)와 비슷한 수준입니다. 또한 코히어런스 기반 방법은 ρ = 0.58을 기록하여 클래식 메트릭을 능가하며, End-to-End 접근 방식보다 더 일반적인 것으로 나타났습니다.



### High-Quality, ROS Compatible Video Encoding and Decoding for High-Definition Datasets (https://arxiv.org/abs/2408.00538)
- **What's New**: 이 논문은 로보틱 데이터셋에서 비디오 데이터를 압축된 형태로 저장하고 공유하는 방법을 조사합니다. 특히, 최신 비디오 인코더를 사용하여 고해상도와 높은 프레임 속도의 비디오 데이터를 효과적으로 압축하는 방법을 제시하며, ROS 1 및 ROS 2 프레임워크 내에서 mp4 비디오를 다시 재생할 수 있는 소프트웨어를 개발했습니다.

- **Technical Details**: 이 소프트웨어는 mp4 비디오를 플레이백할 수 있으며, ROS 환경에서 시뮬레이션 시간을 동기화하는 기능을 가지고 있습니다. 논문에서는 다양한 인코더와 설정을 평가하여 크기, 품질, 인코딩 시간 측면에서 최적의 구성을 찾았습니다. 주요 인코더로는 H.264/AVC, H.265/HEVC, AV1이 있습니다.

- **Performance Highlights**: 최적의 인코더와 설정을 사용하여 고해상도 비디오 데이터셋을 43GB 크기로 압축할 수 있음을 실험을 통해 입증했습니다. 이는 원래 데이터의 크기를 크게 줄이면서도 뛰어난 이미지 품질을 유지하는 성과를 보여줍니다.



### GalleryGPT: Analyzing Paintings with Large Multimodal Models (https://arxiv.org/abs/2408.00491)
Comments:
          Accepted as Oral Presentation at ACM Multimedia 2024

- **What's New**: 이번 연구에서는 큰 멀티모달 모델(multi-modal models)에서 영감을 받아, 미술 작품 분석 작업을 수행하고 이를 통해 개인의 심미적 감수성을 풍부하게 하고 비판적 사고 능력을 향상시키는 데 도움을 주고자 합니다. 주로 시각적 특성에 초점을 맞춘 포괄적인 분석을 위해 'PaintingForm'이라는 대규모 데이터셋을 수집하였으며, 이를 기반으로 'GalleryGPT'라는 향상된 멀티모달 모델을 제안합니다.

- **Technical Details**: 우선 대규모 데이터셋 'PaintingForm'을 구축하기 위해 약 1만 9천 개의 그림 이미지와 5만 개의 분석 문단을 수집했습니다. 그런 다음, ShareGPT4V-7B 기반의 LLaVA 아키텍처를 약간 수정하고 미세 조정하여 상위 모델 'GalleryGPT'를 개발했습니다. 이 모델은 미술 작품의 시각적 특성을 중심으로 분석 문단을 생성하는 데 사용됩니다. 또한, Zero-shot 학습을 통해 AQUA, ArtQuest 등 여러 데이터셋에서 모델의 성능을 평가했습니다.

- **Performance Highlights**: GalleryGPT는 여러 고성능 LMMs와 비교하여 놀라운 성능 향상을 보였습니다. 특히 AQUA, ArtQuest, ArtBench 등 다양한 그림 분석 데이터셋에서 우수한 성능을 보이며, 수집된 데이터와 모델의 뛰어난 능력을 입증했습니다.



### A Systematic Review on Long-Tailed Learning (https://arxiv.org/abs/2408.00483)
Comments:
          Current Under Revision at IEEE TNNLS. [This is the long/Full-length version of our Long-Tailed Learning Survey paper]

- **What's New**: 이번 연구는 긴 꼬리(롱테일) 학습의 최신 동향을 포괄적으로 조사한 논문입니다. 연구진은 긴 꼬리 학습을 위해 새로운 분류법(새로운 taxonomy)을 제안하며, 데이터 균형 조정(data balancing), 신경망 구조(neural architecture), 특징 강화(feature enrichment), 로짓 조정(logits adjustment), 손실 함수(loss function), 부가 기능(bells and whistles), 네트워크 최적화(network optimization), 사후 처리(post hoc processing) 등 8가지 측면으로 나누어 분석하였습니다.

- **Technical Details**: 긴 꼬리 학습(long-tailed learning)에서는 주요 목표가 각 클래스의 샘플 수 불균형을 해결하고, 특히 소수 클래스(minority/tail classes)를 정확히 식별하는 모델을 개발하는 것입니다. 이번 연구에서는 다양한 롱테일 학습 방법들을 제안된 분류법에 따라 체계적으로 리뷰하고, 롱테일 학습과 불균형 학습(imbalance learning)의 차이점을 분석합니다. 주요 접근 방식으로는 데이터 재샘플링(resampling), 손실 함수 재가중(loss reweighting), 전이 학습(transfer learning) 등이 포함됩니다.

- **Performance Highlights**: 논문은 롱테일 시나리오에서 사용되는 다양한 학습 방법들이 소수 클래스에 대한 인식률을 개선함을 강조합니다. 특히, 심층 특징 표현 학습(deep feature representation learning)과 분류기 훈련(classifier training) 분리를 통한 방식, 샘플 가중치를 다르게 부여하는 방법 등이 중요한 성과를 보였습니다. 여러 하위 작업에서의 실험 결과도 요약되며, 향후 연구 방향에 대한 논의도 포함됩니다.



### DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving (https://arxiv.org/abs/2408.00415)
Comments:
          19 pages, 9 figures

- **What's New**: 고품질의 폐쇄 루프 시뮬레이션 시스템 DriveArena가 발표되었습니다. 이 시스템은 실제 주행 시나리오에서 주행 에이전트(driving agents)를 평가할 수 있도록 설계되었습니다. 주요 특징으로는 교통 시뮬레이터인 Traffic Manager와 고충실도 조건부 생성 모델인 World Dreamer의 결합이 있습니다.

- **Technical Details**: DriveArena는 모듈화된 구조로, 주요 구성 요소들을 자유롭게 교체할 수 있습니다. Traffic Manager는 전 세계의 어떠한 도로 지도에서도 현실감 있는 교통 흐름을 생성할 수 있으며, World Dreamer는 무한 오토리그레션(autoregression)을 갖춘 고충실도 모델입니다. 이 시스템은 카메라 입력 기반 주행 에이전트와 통합되며 실시간 상호작용을 통해 폐쇄 루프 시뮬레이션을 실현합니다.

- **Performance Highlights**: DriveArena는 다양한 복잡한 주행 시나리오에서 주행 에이전트가 계속해서 학습하고 진화할 수 있도록 돕습니다. Traffic Manager는 동적인 교통 시나리오를 생성할 수 있고, World Dreamer는 다양한 시간대 및 날씨 조건에서 현실감 있는 이미지를 생성할 수 있습니다. 이러한 상호작용을 통해 주행 에이전트의 실제 주행 능력을 종합적으로 평가할 수 있습니다.



### Enhancing Whole Slide Pathology Foundation Models through Stain Normalization (https://arxiv.org/abs/2408.00380)
Comments:
          13 pages, 8 figures

- **What's New**: 최근 디지털 병리학에서 자체-지도 학습 (self-supervised learning) 기법을 사용하여 기초 모델을 개발하는 연구가 활발히 진행되고 있습니다. 이러한 모델들은 주로 전체 슬라이드 이미지 (Whole Slide Images, WSIs)에서 추출한 작은 패치를 이용해 학습합니다. 그러나, 우리는 WSI-특정 특징 붕괴(WSI-specific feature collapse)라 불리는 중요한 문제를 발견했으며, 이를 해결하기 위해 염색 정상화를 적용한 병리학 기초 모델인 Stain Normalized Pathology Foundational Model을 도입했습니다.

- **Technical Details**: WSI-특정 특징 붕괴는 각 WSI에서 추출한 패치의 특징들이 특정 WSI에 따라 군집화되는 현상을 말합니다. 이를 해결하기 위해 패치 전처리 단계에서 Macenko 염색 정상화를 적용하여 색상 변동을 줄였습니다. 우리 모델은 총 34,795개의 WSI에서 추출한 285,153,903개의 패치를 이용해 학습되었습니다. DINO(self-DIstillation with NO labels) 자체-지도 학습 방법을 사용하여 모델을 구축했습니다.

- **Performance Highlights**: Stain Normalized Pathology Foundational Model은 다양한 패치 수준의 작업에서 기존 최첨단 모델들과의 비교에서 우수한 성능을 보였습니다. 특히, PCAM, MHIST, CRC 100k, TIL-Detection, MSI-CRC 및 MSI-STAD와 같은 여섯 가지 다운스트림 데이터셋에서 뛰어난 성능을 기록했습니다. 이러한 결과는 염색 정상화의 도입이 모델의 효율성과 일반화 능력을 크게 향상시켰음을 시사합니다.



### Conformal Trajectory Prediction with Multi-View Data Integration in Cooperative Driving (https://arxiv.org/abs/2408.00374)
- **What's New**: V2INet은 다중 뷰 데이터를 효율적으로 모델링하기 위해 기존의 단일 뷰 모델을 확장하여 새로운 경로 예측 프레임워크를 소개합니다. 이 접근 방식은 비슷한 방식으로 다수의 뷰를 수동으로 병합하거나 별도 학습 단계를 필요로 하는 이전 방법들과 달리, end-to-end 방식의 훈련을 지원하여 유연성과 성능을 증대시킵니다. 또한, 예측된 다중 모드 궤적을 칼리브레이션하는 사후 적합 예측 모듈을 도입하여 유효하고 효율적인 신뢰 구간을 제공합니다.

- **Technical Details**: 이 모델은 단일 뷰 데이터에서 수집한 궤적 정보를 그래프 신경망(GNN) 기반 모델(LaneGCN, HiVT 등)을 활용하여 시간 의존성, 에이전트 간 상호 작용, 에이전트-차선 관계를 캡처한 후, 서로 다른 뷰에서 수집된 노드 임베딩을 교차 그래프 주의 모듈을 통해 병합합니다. 그런 다음 융합된 최종 임베딩은 다중 모드 디코더를 통해 미래 궤적 예측을 생성합니다. 추가적으로, CP(Conformal Prediction) 모듈은 사후적 예측 결과를 캘리브레이션하여 사용자 지정 확률로 실제 값을 포함하는 신뢰 구간을 제공합니다.

- **Performance Highlights**: V2INet 프레임워크는 실제 V2I 데이터셋 V2X-Seq를 사용하여 평가되었으며, Final Displacement Error(FDE)와 Miss Rate(MR) 측면에서 단일 GPU로 우수한 성능을 보였습니다. 이는 이전 모델들과 비교해 더 적은 자원으로 더 높은 예측 성능을 입증합니다.



### Multimodal Fusion and Coherence Modeling for Video Topic Segmentation (https://arxiv.org/abs/2408.00365)
- **What's New**: 이번 연구에서는 비디오 주제 분할(Video Topic Segmentation, VTS) 작업을 개선하기 위해 멀티모달 융합과 멀티모달 일관성 모델링을 철저히 탐구하였습니다. 특히, 다양한 크로스-어텐션(Cross-Attention)과 전문가들의 혼합(Mixture of Experts, MoE)을 활용한 멀티모달 융합 아키텍처를 비교하였습니다. 또한, 멀티모달 대비 학습(contrastive learning)으로 모델을 사전 훈련(pre-train)하고 미세 조정(fine-tune)하는 방법을 제안하였습니다. 새로운 사전 훈련 임무와 멀티모달 일관성 모델링을 향상시키는 미세 조정 임무도 제안하였습니다.

- **Technical Details**: VTS 작업은 비디오를 이해하기 쉬운 비중첩(non-overlapping) 주제로 나누는 작업입니다. 기존의 얕은 기능이나 비지도 학습 방법은 주제 전환의 세부적인 부분을 정확하게 구별하는데 어려움을 겪고 있습니다. 이를 해결하기 위해, 멀티모달 융합을 크로스-어텐션(Cross-Attention)과 전문가들의 혼합(Mixture of Experts, MoE) 아키텍처를 통해 강화하였습니다. 또한, 멀티모달 대비 학습(Multimodal Contrastive Learning)을 이용해 모델을 사전 훈련하고 미세 조정하여 멀티모달 일관성을 강화하였습니다. 교육 비디오, 특히 강의 비디오를 대상으로 새로운 사전 훈련 및 미세 조정 임무를 제안하였습니다.

- **Performance Highlights**: 제안된 방법은 영문과 중국어 강의 비디오 데이터셋에서 경쟁적인 비지도 및 지도 기준 모델들을 능가하는 성능을 보였습니다. 새롭게 구축한 대규모 중국어 강의 비디오 주제 분할 데이터셋(CLVS)을 통해 VTS 연구를 촉진하였습니다. 실험 결과, 제안된 모델이 새로운 state-of-the-art (SOTA) 성능을 설정하였으며, 포괄적인 소거 실험(ablation study)을 통해 접근 방식의 효과성을 확인하였습니다.



### IN-Sight: Interactive Navigation through Sigh (https://arxiv.org/abs/2408.00343)
Comments:
          The 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)

- **What's New**: 최근 시각 내비게이션 시스템은 환경을 정적(static)으로 취급하여 장애물과 상호작용하는 능력이 부족하다는 한계가 있습니다. 이러한 문제를 해결하기 위해 IN-Sight라는 새로운 접근 방식을 소개합니다. IN-Sight는 RGB-D 관찰을 활용하여 통과 가능성(traversability) 점수를 계산하고 이를 의미론적 지도(semantic map)에 통합함으로써 더 효과적인 경로 계획을 가능하게 합니다. 이러한 접근 방식은 현실적인 인텔 SPEAR 시뮬레이터(Intel SPEAR Simulator)에서 종단간(end-to-end) 교육을 통해 이루어집니다.

- **Technical Details**: IN-Sight는 전역 지도(global map)에 통과 가능성(traversability) 추정치를 지속적으로 통합하는 계층적 플래너 구조를 사용합니다. 이러한 글로벌 플래너(global planner)는 A* 경로 탐색을 실행하여 목표를 향한 최소 비용 경로를 계산합니다. 로컬 플래너(local planner)는 재발 신경망(RNN)을 사용하여 끊임없이 장애물 주변을 탐색하고 상호작용이 필요한지 여부를 결정합니다. 교육 과정에서는 현실적인 센서 아티팩트(sensing artifacts)의 영향을 줄이기 위한 다양한 강건화 기법(robustification techniques)을 사용합니다.

- **Performance Highlights**: 시뮬레이션 시나리오와 소거 연구(ablation studies)를 통해 IN-Sight의 효과를 입증했습니다. 또한, 교육된 플래너를 다리가 있는 로봇 플랫폼 ANYmal에 zero-shot sim-to-real 전이(zero-shot sim-to-real transfer)를 통해 실제 환경에서도 성공적으로 적용했습니다. 이러한 결과는 IN-Sight의 실제 환경 내 상호작용 가능한 내비게이션의 실용적 잠재력을 입증합니다.



### ADBM: Adversarial diffusion bridge model for reliable adversarial purification (https://arxiv.org/abs/2408.00315)
Comments:
          20 pages

- **What's New**: Diffusion-based purification(DiffPure)는 효과적인 적대적 예시 방어 방법으로 인식되어 왔지만, 기존 미리 훈련된 diffusion model을 직접 사용하는 것은 최적이 아님을 발견했습니다. 이를 해결하기 위해 우리는 고유의 Adversarial Diffusion Bridge Model(ADBM)을 제안했습니다.

- **Technical Details**: DiffPure는 원래 생성 작업에 맞춰 훈련된 diffusion models을 사용하므로 적대적 정화 작업에서는 비효율적입니다. ADBM은 역방향 다리를 구축하여 변형된 적대적 데이터를 원래 깨끗한 예시로 복구하는 과정을 향상시켰습니다. ADBM은 복구 품질과 노이즈 제거 성능 사이의 간극을 극복합니다. 또한, 우리가 개발한 신뢰 가능한 적응형 공격 평가 방법을 통해 ADBM의 우수성을 검증했습니다.

- **Performance Highlights**: ADBM은 여러 시나리오에서 DiffPure보다 더 높은 적대적 견고함을 입증했습니다. 특히 CIFAR-10 데이터셋에서 DiffPure 대비 4.4%의 향상된 견고성을 보였으며, 깨끗한 데이터에서는 유사한 정확도를 유지했습니다. 또한, ADBM은 적응형 공격뿐 아니라 전이 기반 및 쿼리 기반 공격에서도 우수한 성능을 나타냈습니다.



### Navigating Text-to-Image Generative Bias across Indic Languages (https://arxiv.org/abs/2408.00283)
Comments:
          Accepted in ECCV 2024

- **What's New**: 이 연구는 인도의 여러 언어에 대한 텍스트-이미지(TTI) 모델의 편향을 조사합니다. 주로 인도에서 사용되는 30개 언어에 대한 모델의 생성 성능과 문화적 관련성을 평가하고, 이를 영어와 비교합니다. 제안된 IndicTTI 벤치마크를 사용하여, 두 개의 오픈소스 확산 모델과 두 개의 상용 생성 API를 통해 이러한 언어들에 대해 포괄적으로 평가합니다. 이 벤치마크의 주요 목표는 TTI 모델이 인도 언어를 얼마나 잘 지원하는지 평가하고, 개선이 필요한 영역을 식별하는 것입니다.

- **Technical Details**: 이 연구는 Stable Diffusion과 Alt Diffusion 모델을 오픈소스 분석에 사용하고, Midjourney 및 Dalle3을 상용 생성 모델 분석에 사용했습니다. 새로운 Cyclic Language-Grounded Correctness (CLGC) 메트릭을 제안하여 모델 성능을 평가하고, Self-Consistency Across Languages (SCAL) 메트릭을 통해 모델 생성의 표현 편향을 평가합니다. 또한 Language-Grounded Correctness (LGC)와 Image-Grounded Correctness (IGC) 메트릭을 통해 모델 성능을 평가합니다. 연구에서는 30개 언어를 사용하여 모델의 정확성 및 문화적 표현 편향을 분석합니다.

- **Performance Highlights**: 연구 결과, 특정 언어 스크립트가 Midjourney에서 인도 신의 이미지를 불러일으켰고, 오픈 소스 모델에서는 아시아 여성과 커플의 이미지가 압도적으로 많이 생성되는 것을 관찰했습니다. Dalle3 모델은 가장 정확한 이미지를 생성하는 것으로 나타났습니다. 이러한 분석을 통해 모델이 사용하는 언어 스크립트와 문화적 영향력 간의 상관관계를 논의했습니다.



### 3D U-KAN Implementation for Multi-modal MRI Brain Tumor Segmentation (https://arxiv.org/abs/2408.00273)
- **What's New**: U-KAN 네트워크는 Kolmogorov-Arnold Network(KAN) 레이어를 통합한 U-Net 기반 모델로, 3D 뇌종양 분할에 적용되어 성능을 입증하고 있습니다. 이번 연구에서는 U-KAN의 3D 변형을 제안하고, Squeeze-and-Excitation(SE) 모듈을 추가하여 글로벌 주의(attention)를 부여한 UKAN-SE 모델을 소개합니다.

- **Technical Details**: 이번 연구에서는 BraTS 2024 데이터셋을 이용하여 U-KAN과 UKAN-SE를 기존 방법인 U-Net, Attention U-Net, Swin UNETR와 비교했습니다. 총 1350개의 레이블이 부여된 훈련 샘플과 188개의 레이블이 없는 검증 샘플을 사용했으며, 네 가지 MRI 모달리티(T1, T1Gd, T2, FLAIR)를 포함합니다. 데이터 전처리에는 해부학적 템플릿에 정렬, 해상도 정규화, 두개골 제거 등이 포함되었습니다. 학습 과정을 촉진하기 위해 데이터 증강(data augmentation)을 통해 다양한 훈련 데이터를 생성하였습니다. 손실 함수로는 소프트 Dice 점수와 교차 엔트로피(Cross Entropy) 손실을 조합한 것을 사용했습니다.

- **Performance Highlights**: 약 1,060만개의 파라미터를 가진 U-KAN과 UKAN-SE는 훈련 시간이 U-Net과 Attention U-Net의 1/4, Swin UNETR의 1/6에 불과함에도 불구하고 대부분의 평가 지표에서 우수한 성능을 발휘했습니다. 특히 UKAN-SE는 U-KAN보다 약간 더 높은 성능을 보였습니다.



### Revocable Backdoor for Deep Model Trading (https://arxiv.org/abs/2408.00255)
Comments:
          to appear in ECAI 2024

- **What's New**: 본 논문에서는 기존 딥 모델의 취약점을 역이용하여, 해독 가능한 백도어(Revocable Backdoor) 및 딥 모델 거래 시나리오를 제안합니다. 이 접근법을 통해 모델의 성능을 저하시키지 않으면서도, 재훈련 없이 쉽게 백도어를 제거할 수 있습니다. 판매자는 시범 버전(trial version)을 제공하고, 구매자가 만족할 경우 최종 결제를 통해 백도어를 제거하는 방법입니다.

- **Technical Details**: 내부 특징 맵(feature maps)을 관리하기 위한 특정 마스크 행렬(mask matrices)를 설계하여, 이를 사용해 백도어를 비활성화 할 수 있습니다. 이 마스크 행렬은 모델의 성능을 감소시키지 않으면서 백도어를 활성화 및 비활성화하는 데 사용됩니다. 모델 거래 시나리오에서는, 판매자는 해독 가능한 백도어가 적용된 모델을 훈련시키고, 구매자는 보증금을 지불하고 시범 버전을 얻습니다. 만족할 경우 최종 결제를 통해 마스크 행렬을 받아 백도어를 제거합니다.

- **Performance Highlights**: 다양한 데이터셋과 네트워크 아키텍처를 사용한 광범위한 실험을 통해 제안된 해독 가능한 백도어의 실현 가능성과 견고성을 입증하였습니다. 백도어가 있는 모델은 트리거가 존재할 때 공격자가 원하는 출력값을 반환하며, 정상적인 입력에는 올바른 출력 값을 반환합니다.



### multiGradICON: A Foundation Model for Multimodal Medical Image Registration (https://arxiv.org/abs/2408.00221)
- **What's New**: medical image registration 분야에서 세계최고 (SOTA) 성능을 자랑하는 신경 네트워크 방식이 주로 단일 모달리티(monomodal)를 대상으로 하였으나, 최근 다중 모달리티(multimodal)를 지원하는 모델인 multiGradICON이 제안되었습니다. 이 모델은 동일한 신경 네트워크로 단일 모달리티와 다중 모달리티를 모두 다룰 수 있도록 설계되었습니다.

- **Technical Details**: multiGradICON은 주로 세 가지 핵심 요소를 통해 기존 uniGradICON을 확장합니다. 첫째, 이미지 유사도 측정을 다중 모달리티에 적합하게 조정하였습니다. 둘째, 다중 모달리티 레지스트레이션 작업을 포함하는 더 큰 데이터셋을 사용한 학습이 가능합니다. 셋째, 이미지 유사도 손실(loss)을 무작위화(randomization)하는 기법이 도입되었습니다. 이 모델에서는 1-LNCC²를 기본 유사도 손실로 사용하며, 이를 통해 실험의 단순성을 유지합니다.

- **Performance Highlights**: 실험 결과 multiGradICON은 다중 모달리티 일반화에 대해 뛰어난 성능을 보여주었으며, 단일 모달리티 레지스트레이션에서도 좋은 정확도를 유지하였습니다. 또한 유사도 손실을 무작위화하여 데이터를 여러 파라메트릭으로 구성할 때도 높은 레지스트레이션 정확도를 달성했습니다.



### Hierarchical Conditioning of Diffusion Models Using Tree-of-Life for Studying Species Evolution (https://arxiv.org/abs/2408.00160)
- **What's New**: 이번 연구에서는 Phylo-Diffusion이라는 새로운 프레임워크를 소개합니다. 이 프레임워크는 진화적 지식을 통해 확산 모델(diffusion models)을 조건화하여 이미지로부터 자동으로 진화적 특성을 발견하는 것을 목표로 합니다. Phylo-Diffusion은 HIERarchical Embeddings(HIER-Embeds)라는 전략을 통해 진화 정보를 인코딩합니다.

- **Technical Details**: Phylo-Diffusion은 확산 모델(diffusion models)에 나무 기반의 지식을 구조화하여 임베딩 공간을 구성하는 혁신적인 방법론입니다. HIER-Embed는 진화도를 네 개의 수준으로 끊어서 각 종(species)에 대한 진화 정보를 시퀀스로 인코딩합니다. 그리고 두 가지 새로운 실험인 Trait Masking과 Trait Swapping을 제안합니다. Trait Masking은 특정 수준의 정보를 잡음으로 마스킹하여 이미지에서 해당 수준의 특성이 사라지는 것을 관찰하고, Trait Swapping은 참조 종의 특정 수준 임베딩을 동일 수준의 형제 노드와 교환하여 특성 차이를 시각화합니다.

- **Performance Highlights**: 연구진은 물고기와 새의 진화적 특성을 분석하여 Phylo-Diffusion의 유용성을 입증했습니다. Phylo-Diffusion을 통해 의미 있는 특성 변화를 포착할 수 있었으며 이는 생물학적 메커니즘에 대한 새로운 통찰력을 제공했습니다.



### StyleRF-VolVis: Style Transfer of Neural Radiance Fields for Expressive Volume Visualization (https://arxiv.org/abs/2408.00150)
Comments:
          Accepted by IEEE VIS 2024

- **What's New**: 이 논문에서는 StyleRF-VolVis라는 혁신적인 스타일 전이(Style Transfer) 프레임워크를 소개합니다. 이 시스템은 신경 방사장(Neural Radiance Field, NeRF)을 통해 표현력 있는 볼륨 시각화(VolVis)를 구현합니다. 기존 방식과 달리 많은 훈련 이미지나 긴 훈련 시간이 필요하지 않으며, 높은 품질과 일관성, 유연성을 제공합니다.

- **Technical Details**: StyleRF-VolVis의 핵심은 장면 기하(geometry)와 색상 표현(style)을 정확히 분리하는 능력에 있습니다. 이를 통해 색상, 불투명도, 조명 등을 쉽게 수정할 수 있으며, 3D 장면 재구성에서 참조 이미지의 스타일을 효과적으로 전이할 수 있습니다. 이를 위해 StyleRF-VolVis는 기본 NeRF 모델, 팔레트 색상 네트워크(Palette Color Network), 그리고 무제한 색상 네트워크(Unrestricted Color Network)로 구성됩니다.

- **Performance Highlights**: StyleRF-VolVis는 다양한 볼륨 렌더링 장면과 참조 이미지를 사용한 실험에서 뛰어난 품질, 일관성 및 유연성을 보여주었으며, 다른 이미지 기반(AdaIN), 비디오 기반(ReReVST), 및 NeRF 기반(ARF, SNeRF) 스타일 렌더링 솔루션과 비교하여 우수한 성능을 입증했습니다.



### Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey (https://arxiv.org/abs/2407.21794)
Comments:
          survey paper. We welcome questions, issues, and paper requests via this https URL

- **What's New**: Vision Language Models (VLMs)와 같은 새로운 패러다임이 OOD 탐지 및 기타 관련 문제들(이상 탐지, 신기성 탐지, 개방형 세트 인식, 이상치 탐지)의 경계를 모호하게 만드는 현상이 논의되고 있습니다. 이 논문은 이러한 변화를 반영하여 해당 문제들을 통합적으로 이해하기 위한 'Generalized OOD Detection v2' 프레임워크를 제안합니다.

- **Technical Details**: 기존의 OOD 탐지 프레임워크를 확장하여 OD, AD, ND, OSR 및 OOD 탐지 문제의 진화를 요약했습니다. 새로운 프레임워크는 다음 여섯 가지 기준을 기반으로 합니다: 분포 이동 탐지, In-Distribution(ID) 데이터 유형, ID 분류의 필요성, 전이 학습 vs 접합적 학습. 이 프레임워크는 각 문제의 정의와 문제 설정, 벤치마크와의 중요한 변화를 강조합니다.

- **Performance Highlights**: VLMs 시대에서 AD와 OOD 탐지가 가장 큰 도전 과제로 부각되었습니다. 특히 CLIP 기반의 OOD 탐지와 AD 방법론을 조사하며, LVLMs(GPT-4V와 같은 대규모 비전 언어 모델) 시대의 초기 발전 사항을 소개합니다.



### Vision-Language Model Based Handwriting Verification (https://arxiv.org/abs/2407.21788)
Comments:
          4 Pages, 1 Figure, 1 Table, Accepted as Short paper at Irish Machine Vision and Image Processing (IMVIP) Conference

- **What's New**: 문서 포렌식에서 필적 검증(Handwriting Verification)은 중요한 역할을 합니다. 그러나 현재의 딥러닝 기반 접근법은 설명 가능성이 부족하고 대규모 학습 데이터와 수작업 특징에 의존한다는 점에서 포렌식 문서 검사관들에게 신뢰를 받지 못하고 있습니다. 이번 연구는 OpenAI의 GPT-4o와 Google의 PaliGemma와 같은 Vision Language Models(VLMs)를 사용해 이러한 문제를 해결하고자 합니다. 이 모델들은 Visual Question Answering과 0-shot Chain-of-Thought(COT) 추론을 활용하여 명확하고 인간이 이해할 수 있는 설명을 제공합니다.

- **Technical Details**: ['Methods: 본 연구에서는 OpenAI의 GPT-4o VLM을 선택하여 시각 질문 응답(Visual Question Answering) 기능을 사용했습니다. 0-shot Chain-of-Thought(COT) 추론을 통해 인간이 이해가능한 설명을 먼저 생성한 후, 필적 검증을 수행했습니다. 추가적으로, PaliGemma VLM을 사용해 0-shot 프롬프트 엔지니어링 및 파라미터 효율 최적화 슈퍼바이즈드 피인튜닝(PEFT)을 비교했습니다.', "Data: 실험은 CEDAR Letter와 CEDAR AND 데이터셋에서 수행되었습니다. CEDAR Letter 데이터는 1568명의 필자들이 세 번 작성한 편지 원고를 포함하고 있으며, CEDAR AND는 이 데이터의 부분집합으로, 편지 원고에서 추출한 소문자 'and' 단어만 포함하고 있습니다."]

- **Performance Highlights**: ['결과: 실험 결과 CNN 기반의 ResNet-18 아키텍처는 GPT-4o(정확도: 70%)와 슈퍼바이즈드 피인튜닝된 PaliGemma(정확도: 71%)를 능가하였으며, CEDAR AND 데이터셋에서 84%의 정확도를 달성했습니다.', 'CEDAR AND 기준으로 주요 모델들의 성능: GSC(정확도: 78%), ResNet-18(정확도: 84%), ViT(정확도: 79%), GPT-4o 0-shot COT(정확도: 70%), PaliGemma 0-shot COT(정확도: 65%) 및 PaliGemma 슈퍼바이즈드 피인튜닝(정확도: 71%)']



### RainMamba: Enhanced Locality Learning with State Space Models for Video Deraining (https://arxiv.org/abs/2407.21773)
Comments:
          ACM Multimedia 2024

- **What's New**: 아웃도어 비전 시스템은 비 줄기와 빗방울에 의해 자주 오염되며, 이는 시각적 작업과 멀티미디어 응용 프로그램의 성능을 크게 저하시킵니다. 이를 해결하기 위해, 새로운 SSMs 기반 비디오 제거 네트워크(RainMamba)가 제안되었습니다. 이 네트워크는 Hilbert 스캔 메커니즘을 도입하여 시퀀스 수준의 지역 정보를 더 잘 캡처할 수 있으며, 패치 수준의 자기 유사성 학습을 향상시키는 차이 유도 동적 대조 지역 학습 전략을 도입합니다.

- **Technical Details**: RainMamba는 SSMs(State Space Models)를 기반으로 한 비디오 제거 네트워크로, 새로운 Hilbert 스캔 메커니즘을 통해 시계열 및 공간 차원에서 지역 학습을 향상시킵니다. 또한 차이 유도 동적 대조 지역 학습 전략을 도입하여 패치 수준의 자기 유사성을 강화합니다. Hilbert Curve는 inherent locality characteristic를 가지고 있어, 시공간적 픽셀을 1D 시퀀스로 변환함으로써 보다 세밀한 복원을 가능하게 합니다.

- **Performance Highlights**: 네트워크는 네 가지 합성 비디오 제거 데이터셋과 실제 비디오에서의 실험을 통해 비 줄기와 빗방울 제거에서 우수한 성능을 보였습니다. Optical Flow, Deformable Convolution, 그리고 Self-attention와 같은 기존의 방법보다 높은 효율성을 제공합니다.



### Paying More Attention to Image: A Training-Free Method for Alleviating Hallucination in LVLMs (https://arxiv.org/abs/2407.21771)
- **What's New**: 본 연구에서는 기존의 대규모 비전-언어 모델(LVLMs)이 시각 입력 없이도 일관된 설명을 생성하는 '텍스트 관성(text inertia)' 현상을 해결하기 위한 새로운 훈련이 필요 없는 알고리즘을 제안하였습니다. 이 알고리즘은 이미지 토큰에 할당된 주의(attention) 가중치를 적응적으로 조정하고 증폭하여 시각적 요소의 중요성을 강조합니다.

- **Technical Details**: LVLMs의 비전 인코더와 대규모 언어 모델(LLMs) 간의 규모 불균형이 발생할 수 있으며, 이는 다중 모달 이해의 편중을 초래할 수 있습니다. 제안된 방법은 이미지 토큰의 주의 가중치를 증폭시키고, 순수 텍스트 입력의 로짓을 멀티모달 입력의 로짓에서 뺌으로써 LLMs에 대한 편향을 줄입니다. 이 접근 방식은 추가적인 훈련 없이 기계가 이미지에 더 집중하게 하여 텍스트 관성을 완화합니다.

- **Performance Highlights**: 광범위한 실험 결과, 다양한 평가지표에서 LVLMs의 환각적 출력 빈도가 크게 감소한 것으로 나타났습니다. 실험은 COCO 데이터셋을 사용하여 이미지 설명 작업의 맥락에서 세 가지 LVLMs를 상대로 수행되었으며, 텍스트 관성이 실질적으로 줄어듦을 확인했습니다.



### Learning Video Context as Interleaved Multimodal Sequences (https://arxiv.org/abs/2407.21757)
Comments:
          Accepted by ECCV 2024

- **What's New**: MovieSeq는 서사 비디오(narrative video) 이해를 위해 개발된 새로운 멀티모달(multimodal) 언어 모델입니다. 이 모델은 비디오를 이미지, 줄거리, 비디오, 자막 등의 요소가 엮인 멀티모달 시퀀스로 표현하여, 언어 모델이 이러한 요소들 간의 관계를 더 잘 이해할 수 있게 합니다. 외부 지식 데이터베이스를 연결하거나 오프라인 모델을 활용하여 자막을 생성하는 등의 방법을 통해 비디오 맥락에 대한 이해도를 높입니다.

- **Technical Details**: MovieSeq의 핵심 아이디어는 비디오를 이미지, 줄거리, 비디오, 자막 등 멀티모달 시퀀스로 엮어 표현하는 것입니다. 이러한 접근 방식은 언어 모델이 멀티모달 지시(instruction)를 통해 비디오와 상호작용할 수 있게 합니다. 예를 들어, 비디오만 사용하는 대신 캐릭터 사진, 이름, 대사 등을 함께 제공하여 모델이 다양한 요소를 연관 짓고 더 포괄적인 응답을 생성할 수 있도록 합니다.

- **Performance Highlights**: MovieSeq는 6개의 데이터셋(LVU, MAD, Movienet, CMD, TVC, MovieQA)과 5개의 설정(비디오 분류, 오디오 설명, 비디오-텍스트 검색, 비디오 캡션, 비디오 질문-응답)을 통해 효과를 입증했습니다. 이 모델은 다양한 작업에서 일관되게 좋은 성능을 보였습니다. 코드는 공개적으로 제공될 예정입니다.



### A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation (https://arxiv.org/abs/2407.21739)
- **What's New**: 이번 연구에서는 의료 영상 분석을 위한 효율적인 연합 학습(Federated Learning) 방법을 제안합니다. 특히, Segment Anything Model (SAM)을 3D 의료 이미지 분할을 위해 적응시키는 과정에서 통신 비용 문제를 해결하고자 합니다. 새로운 접근 방식인 Parameter-Efficient Fine-Tuning (PEFT)와 Low-Rank Adapters (LoRA)를 연합 학습에 적용하여 통신 효율성을 극대화하였습니다.

- **Technical Details**: SAM 모델의 주요 구성 요소인 이미지 인코더(Image Encoder), 프롬프트 인코더(Prompt Encoder), 그리고 마스크 디코더(Mask Decoder)를 활용합니다. SAM 모델의 디코더에서 특정 계층만을 선택적으로 미세 조정하여 통신 비용이 적은 상황에서도 우수한 성능을 유지하는 방법론을 탐구했습니다. 이로 인해, 전체 모델을 미세 조정하는 것보다 통신 비용을 크게 줄일 수 있었습니다 (~48배 감소).

- **Performance Highlights**: 제안된 방법은 Fed-KiTS 데이터셋에서 완전 미세 조정에 비해 통신 비용을 약 48배 줄였으며, 성능은 3D 분할 작업에서 약 6%의 Dice 점수가 향상되었습니다. 또한, SAMed 접근 방식과 비슷한 성과를 내면서도 통신 비용을 약 2.8배 절감하고 미세 조정해야 할 파라미터 수를 줄였습니다.



### Unifying Event-based Flow, Stereo and Depth Estimation via Feature Similarity Matching (https://arxiv.org/abs/2407.21735)
- **What's New**: 최신 연구인 EventMatch 프레임워크를 소개합니다. EventMatch는 이벤트센서를 기반으로 하는 광학 흐름 추정, 스테레오 매칭, 깊이 추정을 통합된 모델로 해결하는 새로운 접근법입니다. 기존의 개별 작업에 대한 특화된 아키텍처가 아닌, 단일 모델이 다양한 작업을 수행할 수 있도록 설계되었습니다.

- **Technical Details**: EventMatch는 이벤트 기반 밀집 대응 일치 문제(dense correspondence matching)를 전체적으로 재구성하여, 시간적 상호작용(temporal interaction)과 공간적 상호작용(spatial interaction)을 통한 지식 통합이 가능한 공유 특징 유사성 모듈(shared feature similarities module)을 사용합니다. 또한 다양한 작업 헤드(task heads)를 통해 시간 도메인의 광학 흐름 추정과 공간 도메인의 스테레오 매칭 등을 동시에 수행할 수 있습니다. 이 프레임워크는 이벤트 기반 광학 흐름과 스테레오 시차를 추정하는 데 있어 특징 유사성 매칭 전략을 활용하여, 3D 기하학적 관계를 고려하는 새로운 방식으로 접근합니다.

- **Performance Highlights**: DSEC 벤치마크 실험 결과, EventMatch 모델은 기존의 최첨단 방법들을 능가하는 성능을 보여주었습니다. 이 모델은 광학 흐름 추정과 시차 추정 작업에서 우수한 결과를 나타내며, 재학습 없이 두 작업을 동시에 효과적으로 처리할 수 있습니다. 코드 또한 추후 공개될 예정입니다.



### Detecting, Explaining, and Mitigating Memorization in Diffusion Models (https://arxiv.org/abs/2407.21720)
Comments:
          16 pages, 9 figures, accepted as oral presentation in ICLR 2024

- **What's New**: 기존의 이미지 생성에 있어서 뛰어난 성능을 보여준 diffusion models에 관련된 최신 연구에서, 특정 훈련 데이터를 그대로 복제해 결과물로 생성하는 경우가 관찰되었습니다. 이러한 복제는 법적 문제를 야기할 가능성이 있으며, 특히 생성된 콘텐츠가 독점 정보를 포함할 때 그렇습니다. 이번 연구에서는 텍스트 조건 예측의 크기를 조사하여 기억된 프롬프트를 탐지하는 간단하고 효과적인 방법을 소개합니다.

- **Technical Details**: 우리의 제안된 방법은 샘플링 알고리즘을 방해하지 않으면서도 통합이 가능하며, 단일 프롬프트당 단일 세대에서 첫 생성 단계에서조차 높은 정확도를 제공합니다. 이 탐지 전략을 기반으로 각 단어 또는 토큰이 기억화에 기여하는 정도를 설명하는 접근 방식을 공개합니다. 또한, 텍스트 조건 예측의 크기를 활용하여 기억화를 최소화하거나 훈련 중 필터링하는 두 가지 전략을 제안합니다.

- **Performance Highlights**: 제안된 전략들은 높은 생성 품질을 유지하면서도 효과적으로 기억화(memoration)을 방지하는 데 성공하였습니다. 이러한 방식은 사용자에게 프롬프트를 조정할 수 있는 설명 가능한(interactive, explainable) 인터페이스를 제공합니다.



### Tora: Trajectory-oriented Diffusion Transformer for Video Generation (https://arxiv.org/abs/2407.21705)
- **What's New**: 최근 Diffusion Transformer (DiT) 기술이 고품질 비디오 콘텐츠 생성에서 놀라운 성과를 보였지만, 조절 가능한 동작을 효과적으로 생성하는 데에는 제한이 있었습니다. 이를 해결하기 위해, 본 논문은 Tora라는 최초의 trajectory-oriented DiT 프레임워크를 소개합니다. Tora는 텍스트, 영상, 경로 데이터를 동시에 통합하여 비디오를 생성합니다.

- **Technical Details**: Tora는 Trajectory Extractor (TE), Spatial-Temporal DiT, 그리고 Motion-guidance Fuser (MGF)로 구성됩니다. TE는 임의의 경로를 계층적 시공간 동작 패치(hierarchical spacetime motion patches)로 인코딩하고, MGF는 이러한 패치를 DiT 블록에 통합하여 경로에 따른 일관된 비디오를 생성합니다. Tora는 OpenSora를 기본 DiT 프레임워크로 사용하며, 텍스트 및 영상 데이터와 더불어 경로 데이터도 효과적으로 처리할 수 있는 모듈을 설계했습니다.

- **Performance Highlights**: 실험 결과, Tora는 다양한 비율과 해상도의 720p 비디오를 최대 204 프레임까지 생성할 수 있으며, 경로에 따라 실제 물리적 세계의 동작을 정밀하게 모사할 수 있음을 보여주었습니다. 또한, Tora는 기존의 최고 성능 방법들보다 우수한 모션 충실도를 달성했습니다.



### Hyper-parameter tuning for text guided image editing (https://arxiv.org/abs/2407.21703)
Comments:
          Codes are available at this https URL

- **What's New**: Forgedit는 새롭고 복잡한 이미지 편집 문제를 해결할 수 있는 업그레이드 된 방법으로, 입력 이미지와 목표 텍스트 프롬프트(text prompt)만 있으면 이미지 편집이 가능합니다. 특히, 단 30초 만에 입력 이미지를 '기억'하고 이해할 수 있는 특징을 갖추고 있습니다.

- **Technical Details**: Forgedit의 작업은 두 단계로 이루어집니다. 첫 번째는 미세조정(finetuning) 단계로, 모든 이미지를 같은 하이퍼파라미터(hyper-paramters)를 사용해 미세조정합니다. 두 번째는 편집 단계로, 불필요하게 복잡해 보일 수 있지만 실질적으로 이전 SOTA(State Of The Art) 모델인 Imagic 보다 덜 복잡하면서도 Imagic의 과적합(overfitting) 문제를 해결한 접근 방식입니다.

- **Performance Highlights**: Forgedit는 Imagic이 직면했던 과적합 문제를 완벽하게 해결하면서도, 효율적인 하이퍼파라미터 튜닝을 통해 이상적인 편집 결과를 얻을 수 있습니다. 또한, 예를 통해 Forgedit의 편집 과정 워크플로(workflow)를 상세히 설명할 것입니다.



### Explainable Artificial Intelligence for Quantifying Interfering and High-Risk Behaviors in Autism Spectrum Disorder in a Real-World Classroom Environment Using Privacy-Preserving Video Analysis (https://arxiv.org/abs/2407.21691)
- **What's New**: 최근 연구는 ASD(자폐 스펙트럼 장애)를 가진 학생들의 방해 및 고위험 행동을 자동으로 감지하고 정량화하는 비디오 기반 기술을 활용하여 일상적인 교실 환경에서 효과적인 개입을 추적하는 방법을 제시합니다. 이는 교실 내에서 실시간으로 행동을 감지하고 분석하는 도구로서, 데이터 수집의 부담을 줄이고 더 정확한 행동 평가를 가능하게 합니다.

- **Technical Details**: 이 연구에서는 최첨단 비디오 기반 그룹 활동 인식 기술을 사용하여 ASD 행동을 객관적이고 자동으로 정량화했습니다. 작업은 Harris, New York의 The Center for Discovery의 연구 교실에서 진행되었습니다. 연구 교실에는 여섯 대의 카메라가 설치되었으며, 두 개의 주요 각도(상단 보기 및 측면 보기)에서 비디오 데이터를 수집했습니다. 데이터는 25분 길이의 비디오 세션으로 나누어졌으며, 각 세션은 연구 보조원이 Noldus The Observer XT 15 소프트웨어를 사용하여 행동을 주석 처리했습니다.

- **Performance Highlights**: 제안된 모델은 문제 행동 에피소드를 77%의 F1-score로 탐지했으며, 다양한 유형의 ASD 행동에서 특징적인 행동 패턴을 포착했습니다. 이 연구는 실제 환경에서 ASD 행동을 정량화할 수 있는 최초의 연구로, 장기적이고 대규모로 ASD 어린이들의 행동을 모니터링하는 실용적인 도구 개발에 중요한 단계를 제시합니다.



### Dynamic Object Queries for Transformer-based Incremental Object Detection (https://arxiv.org/abs/2407.21687)
- **What's New**: 새로운 객체 검출(Incremental Object Detection, IOD) 방법인 DyQ-DETR가 공개되었습니다. DyQ-DETR는 Transformer 구조를 기반으로 하여 객체 쿼리(object queries)를 동적으로 조정해, 모델의 표현 능력을 단계적으로 확장하면서도 오래된 지식과 새로운 지식의 균형을 유지하는 것이 특징입니다. 이를 통해 기존의 지식을 잃지 않으면서도 새로운 클래스를 배우는 능력을 향상시킵니다.

- **Technical Details**: DyQ-DETR는 'Dynamic object Query-based Detection Transformer'의 약어로, IOD 문제를 해결하기 위해 설계된 새로운 모델입니다. 이 모델은 CNN이 부착된 Transformer 인코더를 통해 이미지의 시각적 특징을 추출하고, 시간이 지남에 따라 새로운 클래스에 대응하는 학습 가능한 객체 쿼리를 기존 객체 쿼리와 결합하여 사용합니다. 이를 통해 새로운 클래스의 정보와 기존 클래스의 지식을 효율적으로 적응시키며, 상호 간섭을 줄이기 위해 분리된 이중 매칭을 도입합니다. 또한, 위험 균형 부분 보정을 통해 불완전한 주석을 효과적으로 처리하는 예시 재생(exemplar replay)을 제공합니다.

- **Performance Highlights**: 공개된 실험 결과에 따르면 DyQ-DETR는 기존 최첨단 방법들을 크게 능가합니다. 비-예시 시나리오에서 평균 4.3% AP(매칭 정도)를 향상시켰고, 예시 재생을 사용할 경우 평균 2.9% AP 향상을 기록했습니다. 이 모델은 제한된 파라미터 오버헤드로 인한 높은 성능을 자랑합니다.



### Expressive Whole-Body 3D Gaussian Avatar (https://arxiv.org/abs/2407.21686)
Comments:
          Accepted to ECCV 2024. Project page: this https URL

- **What's New**: 이번 연구에서는 ExAvatar라는 새로운 기술을 소개합니다. ExAvatar는 짧은 단안 비디오(monocular video)로부터 얼굴 표정과 손 동작을 포함한 전체 신체 3D 인간 아바타를 학습합니다. 기존의 3D 인간 아바타 모델들은 주로 신체 동작만 지원했으나, ExAvatar는 SMPL-X와 3D Gaussian Splatting(3DGS)를 조합하여 얼굴 표정과 손 동작까지 지원하는 점이 독특합니다.

- **Technical Details**: ExAvatar는 SMPL-X와 3D Gaussian Splatting(3DGS)을 혼합한 하이브리드 표현 방식을 채택했습니다. SMPL-X의 메쉬 토폴로지를 3D Gaussians에 적용하여 각 3D Gaussian을 표면의 정점으로 취급하고, 이를 통해 새로운 얼굴 표정과 포즈를 구현할 수 있습니다. 또한 연결 기반 정규화를 사용하여 새로운 얼굴 표정과 포즈에서 아티팩트를 크게 감소시킬 수 있습니다.

- **Performance Highlights**: 실험 결과, ExAvatar는 여러 벤치마크에서 기존의 모든 3D 인간 아바타들을 능가하였습니다. 이 시스템은 짧은 단안 비디오에서도 다양한 얼굴 표정 코드를 애니메이션할 수 있으며, 연결 정보를 사용하는 고유한 방식 덕분에 특히 새로운 얼굴 표정과 포즈에서 아티팩트를 크게 줄일 수 있었습니다.



### Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation (https://arxiv.org/abs/2407.21674)
- **What's New**: 이번 연구는 실제 데이터와 합성 데이터 사이의 통계적 특성을 깊이 조사하여, 합성 데이터가 모델의 성능에 끼치는 영향을 분석했습니다. 연구 결과, 합성 데이터와 실제 데이터 간의 상관관계가 강할 때, 모델이 표면적인 특징에 지나치게 의존하는 '단순함 편향 (simplicity bias)' 현상이 발생함을 발견했습니다. 이는 특히 의료 영상에서 두드러지며, 모델의 실전 배포 시 성능 저하를 초래할 수 있습니다.

- **Technical Details**: 본 논문에서는 합성 데이터의 통계적 특성이 모델의 학습에 미치는 영향을 체계적으로 실험했습니다. 특히, 디지털 이미지 분류(task)와 심장 초음파 영상의 이중대 및 사중대 뷰 분류 문제에서 이 현상을 확인했습니다. 이를 통해 모델이 실제와 합성 데이터를 구분하는데 사용하는 특징이 실제 작업과 관계없이 학습될 수 있다는 것을 증명했습니다.

- **Performance Highlights**: 연구에서는 모델이 합성 데이터의 특징을 비정상적으로 쉽게 사용할 수 있다는 사실을 밝혀냈습니다. 예를 들어, 숫자 분류 작업에서 모델은 숫자 자체라기보다는 데이터가 합성 데이터인지 아닌지를 구분하는 데 집중했습니다. 심장 초음파 영상에서도 마찬가지로, 모델은 이중대 및 사중대 뷰를 올바르게 구분하기보다, 데이터 출처(실제 vs. 합성)에 의존해 분류를 수행했습니다. 이러한 단순함 편향은 배포 시 성능 저하로 이어졌으며, 데이터의 출처와 타겟 간의 상관관계가 낮아지는 테스트 환경에서 특히 두드러졌습니다.



### An Explainable Vision Transformer with Transfer Learning Combined with Support Vector Machine Based Efficient Drought Stress Identification (https://arxiv.org/abs/2407.21666)
Comments:
          30 pages, 6 figures, 4 tables

- **What's New**: 이번 연구에서는 비전 트랜스포머(ViTs, Vision Transformers)의 우수한 점을 활용한 감자 작물의 가뭄 스트레스 탐지 모델을 제안했습니다. 이 모델은 공중 이미지 데이터를 사용하여 비침습적(non-invasive)으로 작물의 생리적 변화를 감지합니다. 기존의 Convolutional Neural Networks(CNNs)보다 긴 거리의 종속성과 복잡한 공간적 관계를 더 잘 포착할 수 있는 ViTs의 강점을 활용합니다.

- **Technical Details**: 감자 작물의 공중 이미지를 이용하여 두 가지 접근법을 적용했습니다. 첫 번째 접근법은 ViT와 Support Vector Machine(SVM)을 결합하여 ViT가 사진에서 섬세한 공간적 특징을 추출하고, SVM이 이를 통해 작물의 건강 상태를 분류합니다. 두 번째 접근법은 ViT 내에 전용 분류 레이어를 사용하여 가뭄 스트레스를 직접 탐지하는 것입니다. 또한 모델의 결정 과정을 설명하기 위해 주의 맵(attention maps)을 시각화하여 구체적인 공간적 특징을 강조했습니다.

- **Performance Highlights**: 제안된 방법은 가뭄 스트레스 식별에 있어 높은 정확성을 달성했으며, 다양한 미세한 식물 특징을 분석하는 데 있어 큰 도움이 되었습니다. 특히, ViT가 견고하고 해석 가능한 솔루션을 제공하여 농업인들이 작물 관리를 위한 정보에 입각한 결정을 내리는 데 중요한 역할을 합니다.



### MTA-CLIP: Language-Guided Semantic Segmentation with Mask-Text Alignmen (https://arxiv.org/abs/2407.21654)
Comments:
          accepted at ECCV 2024

- **What's New**: 최근 대규모 비전-언어 모델(Vision-Language Models, VLMs)인 CLIP이 의미 분할(Semantic Segmentation) 성능을 향상시킬 수 있음이 입증되었습니다. 기존 방법들은 주로 픽셀-레벨(Pixel-Level) 비전-언어 정렬에 초점을 맞추었지만, 저해상도 이미지 특징 사용으로 경계 모호성 문제를 겪고 있었습니다. 이를 해결하기 위해 새로운 프레임워크 MTA-CLIP을 도입했습니다. MTA-CLIP은 마스크-레벨(Mask-Level) 비전-언어 정렬을 통해 성능을 향상시키고 이로 인해 경계 문제를 효과적으로 해결합니다.

- **Technical Details**: MTA-CLIP은 두 가지 주요 구성 요소로 구성됩니다. 첫째, Mask-Text Decoder는 CLIP 언어 모델을 사용하여 마스크 표현을 강화하고, Mask-to-Text Contrastive Learning을 통해 텍스트 임베딩과 조정합니다. 둘째, Mask-Text Prompt Learning을 도입하여 다양한 컨텍스트에 맞춘 프롬프트를 사용해 서로 다른 클래스 표현을 잡아냅니다. 이로 인해 텍스트 임베딩과의 정렬이 더욱 효과적이 됩니다.

- **Performance Highlights**: MTA-CLIP은 표준 벤치마크 데이터셋인 ADE20k와 Cityscapes에서 각각 평균 2.8%와 1.3% 성능 향상을 이루며, 기존 방법들을 뛰어넘는 새로운 성과를 달성했습니다.



### Spatial Transformer Network YOLO Model for Agricultural Object Detection (https://arxiv.org/abs/2407.21652)
Comments:
          7 pages, 5 figures, submitted for review

- **What's New**: 이 논문에서는 YOLO 모델의 단점인 혼잡하거나 부분적으로 가려진 장면에서의 성능 문제와 작은 저대비 객체 감지 문제를 개선하기 위해 Spatial Transformer Networks (STNs)를 통합한 새로운 방법을 제안합니다. 새롭게 제안된 STN-YOLO 모델은 이미지의 중요한 영역에 집중하고 공간 불변성을 높여 객체 감지 성능을 향상시킵니다. 이 방법은 정성적, 정량적으로 객체 감지 성능을 개선합니다. 또한, 농업 객체 감지를 위한 벤치마크 데이터셋과 최신 식물 페노타이핑 온실 시설에서의 새로운 데이터셋을 제시합니다.

- **Technical Details**: STN-YOLO 모델은 STN 모듈을 통합하여 공간 변환에 대한 강인성을 향상시킵니다. 이 STN 모듈은 입력 이미지에 학습 가능한 Affine 변환을 적용하여 객체 감지 정확도를 높입니다. 제안된 방법은 다양한 공간 변환을 포함한 데이터셋에서 실험을 통해 검증되었으며, 특히 농업 분야의 객체 감지에 효과적입니다. 새로운 Plant Growth and Phenotyping (PGP) 데이터셋은 다중 스펙트럼 이미지, 다양한 조명 조건에서의 이미지, 정밀한 주석 및 다양한 크기와 형태의 식물 이미지를 포함하고 있습니다.

- **Performance Highlights**: 제안된 STN-YOLO 모델은 기존 YOLO 모델을 능가하는 성능을 보였습니다. 다양한 농업 벤치마크 데이터셋에서 실험한 결과, STN-YOLO는 객체 감지 정확도와 강인성 면에서 뛰어난 성능을 입증했습니다. 새로운 PGP 데이터셋은 식물 탐지 및 페노타이핑 연구를 발전시킬 수 있는 중요한 자원이 됩니다.



### RoadFormer+: Delivering RGB-X Scene Parsing through Scale-Aware Information Decoupling and Advanced Heterogeneous Feature Fusion (https://arxiv.org/abs/2407.21631)
Comments:
          11 pages, 5 figures

- **What's New**: 새롭게 제안된 RoadFormer+는 다양한 데이터 유형(예: Depth, Thermal, Surface Normal, Polarization)을 효과적으로 융합할 수 있는 모델입니다. 기존 RGB-Normal 데이터 융합에 강점을 보였던 RoadFormer의 한계를 극복하고, 모든 범주의 도시 장면 파싱을 위해 더 강력하고 적응 가능한 네트워크를 제공합니다.

- **Technical Details**: RoadFormer+는 하이브리드 특징 분리 인코더(HFDE)를 사용하여 이질적인 특징을 전역과 지역 성분으로 분리합니다. 이 후, 듀얼 브랜치 다중 스케일 이질적 특징 융합 블록(MHFF)을 통해 이 분리된 특징을 융합합니다. MHFF 블록은 병렬 Transformer 주의 메커니즘과 CNN 모듈을 사용하여 여러 스케일과 수용 필드에서 특징을 병합합니다. 융합된 특징은 디코더에 입력되어 최종 의미 예측을 생성합니다.

- **Performance Highlights**: RoadFormer+는 KITTI Road 벤치마크에서 1위를 기록하고, Cityscapes, MFNet, FMB, 및 ZJU 데이터셋에서 mean intersection over union(mIoU) 성능에서 최첨단(State-of-the-Art)을 달성하였습니다. 또한, RoadFormer과 비교하여 학습 가능한 매개변수의 수를 65% 줄였습니다.



### EZSR: Event-based Zero-Shot Recognition (https://arxiv.org/abs/2407.21616)
- **What's New**: 이 연구는 이벤트 카메라 데이터를 활용해 제로샷 객체 인식을 수행하는 새로운 방법을 제안합니다. 기존 방법들은 RGB 이미지를 통해 사전 학습된 CLIP (Contrastive Language-Image Pre-Training)을 이용해 최대한의 임베딩 유사성을 목표로 했지만, 이는 종종 최적의 성능을 보이지 못했습니다. 이번 연구에서는 재구성 네트워크 없이 이벤트 인코더를 개발하고, 이벤트 임베딩 공간과 텍스트 임베딩 공간 사이의 의미론적 불일치를 해결하기 위해 스칼라 기반의 정규화 전략을 활용합니다.

- **Technical Details**: 기존 방법들은 이벤트 데이터를 RGB 프레임으로 변환하거나 추출된 특징 간의 전체적인 유사성을 최대화하기 위해 대조 학습(Contrastive Learning)을 사용했습니다. 그러나 임베딩의 높은 차원으로 인해 정렬의 자유도가 높아져 의미론적 불일치가 발생했습니다. 이를 해결하기 위해 연구진은 스칼라 단위의 정규화를 제안하고, 이벤트와 텍스트 임베딩을 직접적으로 정렬하는 새로운 학습 목표를 활용합니다. 또한, 정적 RGB 이미지에서 이벤트 데이터를 합성해 데이터 부족 문제를 해결하는 파이프라인도 제안됩니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 N-ImageNet 데이터셋에서 47.84%의 제로샷 정확도를 달성했으며, 이는 기존의 지도 학습법보다도 우수한 성능을 보였습니다. 연구진은 이벤트 카메라 데이터를 사용한 9개의 표준 벤치마크 데이터셋에서 평가를 수행해 경쟁력 있는 성능을 입증했습니다.



### MicroMIL: Graph-based Contextual Multiple Instance Learning for Patient Diagnosis Using Microscopy Images (https://arxiv.org/abs/2407.21604)
Comments:
          The first two authors contributed equally to this work

- **What's New**: 본 논문에서는 병리 조직학 연구에 현재 사용되는 전체 슬라이드 이미지(WSIs) 대신 현미경 이미지 분석을 활용하여 MicroMIL이라는 약지도 멀티 인스턴스 학습(MIL) 프레임워크를 제안합니다. MicroMIL은 Deep Cluster Embedding (DCE)과 Gumbel Softmax를 통해 동적으로 이미지를 클러스터링하고 대표 이미지를 추출합니다. 이 후 Graph Neural Network (GNN)를 사용하여 지역적이며 다양한 영역의 문맥 정보를 포착합니다. MicroMIL은 기존 그래프 기반 MIL 방법들과 달리 절대 위치 정보 없이 효율적으로 처리할 수 있습니다.

- **Technical Details**: MicroMIL은 다음과 같은 주요 기술적 요소들로 구성되어 있습니다: 1) 이미지를 동적으로 클러스터링하기 위해 Deep Cluster Embedding (DCE)을 사용하고, Gumbel Softmax를 이용해 각 클러스터에서 대표 이미지를 추출합니다. 2) 상삼각형 유사성 행렬을 기반으로 그래프 엣지를 구성하고, 가장 유사한 이웃과 노드를 연결하여 지역적 문맥 정보를 포착합니다. 3) Graph Neural Network (GNN)를 이용하여 클러스터 내의 지역적 정보를 통합하고 클러스터 간 문맥 정보를 결합합니다.

- **Performance Highlights**: MicroMIL은 실세계 대장암 데이터셋(Seegene)과 공공 BreakHis 데이터셋에서 기존의 최신 방법론보다 우수한 성능을 보였습니다. DCE를 통해 중복된 이미지를 효과적으로 제거하고, GNN을 통해 대표 이미지의 유사성에 기반한 문맥 정보를 추출함으로써, 현미경 이미지를 활용한 환자 진단을 위한 강력하고 효율적인 솔루션을 제공합니다.



### Evaluating SAM2's Role in Camouflaged Object Detection: From SAM to SAM2 (https://arxiv.org/abs/2407.21596)
- **What's New**: Meta AI Research는 초기의 Segment Anything Model (SAM)의 후속 버전인 Segment Anything Model 2 (SAM2)를 개발했습니다. SAM2는 이미지 뿐만 아니라 비디오 분할도 가능한 통합 모델이며, 세그먼트 정확도와 속도에서 이전 모델보다 큰 향상을 보여줍니다. 그러나 SAM2는 자동 모드에서 프롬프트 없이 이미지 내 다른 객체를 인식하는 능력이 감소했습니다.

- **Technical Details**: 최근 몇 년간 대형 언어 모델(LLM)은 자연어 처리(NLP) 분야에서 혁신을 일으켰습니다. 이에 영감을 받아 CLIP, DINOv2, BLIP, SAM 등 비전(vision) 기반 모델들도 출현했습니다. SAM은 주목할 만한 이미지 분할 모델로 빠르게 주목받았으며, 이를 확장한 SAM2는 이미지와 비디오 분할을 동시에 처리할 수 있는 통합된 아키텍처로 설계되었습니다. SAM2의 성능을 평가하기 위해 CAMO, COD10K, NC4K, MoCA-Mask 등 세 가지의 벤치마크 데이터셋을 사용했습니다. 주요 성능 측정 지표로는 Sα(subscript), mean E-measure, Fβ(subscript), weighted F-measure, max F-measure, mean absolute error가 포함됩니다.

- **Performance Highlights**: SAM2는 프롬프트 기반 세그먼테이션에서는 SAM보다 훨씬 뛰어난 성능을 보여줍니다. 예를 들어, MoCA-Mask 데이터셋에서 video camouflaged object detection(VCOD)을 수행할 때, 최첨단 방법들보다 뛰어난 성능을 기록했습니다. 그러나 자동 모드에서 비프롬프트 세그먼트 정확도는 저하됩니다. SAM2는 특정 이미지에 대한 마스크 예측에서 수량과 품질 모두에서 SAM에 비해 뒤처지는 것으로 나타났습니다.



### Adaptive Mix for Semi-Supervised Medical Image Segmentation (https://arxiv.org/abs/2407.21586)
- **What's New**: 이 연구는 이미지 믹스업(Adaptive Mix, AdaMix) 알고리즘을 제안하여, 학습 도중 자가페이스 학습 방식에서 이미지 믹스업의 교란 정도를 적응적으로 조정합니다. AdaMix는 일반적인 모델 성능이 학습 중 점진적으로 향상된다는 가정을 기반으로, 초기 학습 단계에서는 상대적으로 단순한 교란 샘플을 제공하고, 점진적으로 교란 이미지를 난이도를 조절합니다. 이를 통해, 반자율 학습(SSL)에서 강약한 가상 지도(supervision)를 개선할 수 있습니다.

- **Technical Details**: AdaMix는 자기 주도 학습(즉, self-paced learning) 개념을 믹스업 알고리즘에 도입하여, 특정 훈련 손실 지표를 기반으로 믹스업 패치를 생성합니다. AdaMix-ST, AdaMix-MT, AdaMix-CT와 같은 세 가지 프레임워크가 개발되었습니다. 각각은 자가 학습(self-training), 평균 교사(mean-teacher), 공동 훈련(co-training) 방식으로 SSL 프레임워크에 통합됩니다. 예를 들어, AdaMix-CT는 ACDC 데이터세트에서 10%의 레이블 데이터를 사용했을 때 Dice 점수에서 2.62%, 평균 표면 거리에서 48.25%의 상대적 향상을 달성했습니다.

- **Performance Highlights**: 제안된 프레임워크는 2D 및 3D 모드에서 사용 가능한 세 가지 공공 데이터 세트에 대해 광범위한 실험을 수행하였으며, 그 결과 각 방법의 우월성을 입증했습니다. AdaMix는 훈련 과정에서 안정적인 수렴 능력을 유지하고, 검증 및 테스트 단계에서 더 나은 일반화를 달성하는데, 이는 무작위 믹스업이나 고정된 규칙 기반 믹스업보다 뛰어납니다.



### InScope: A New Real-world 3D Infrastructure-side Collaborative Perception Dataset for Open Traffic Scenarios (https://arxiv.org/abs/2407.21581)
- **What's New**: 이번 논문은 자율주행 차량의 인프라 기반 협력 인식 시스템(Infrastructure-side Collaborative Perception System)을 위한 새로운 3D 데이터셋 InScope를 소개했습니다. 이 데이터셋은 다중 위치의 LiDAR 시스템을 인프라에 전략적으로 배치하여 가려짐 문제를 해결하는 데 중점을 둡니다. InScope는 20일간의 데이터 수집 기간 동안 303개의 추적 경로와 187,787개의 3D 바운딩 박스를 포함하고 있습니다.

- **Technical Details**: InScope 데이터셋은 다중 위치에 배치된 LiDAR 시스템을 통해 인프라 측에서 데이터를 수집합니다. 주요 LiDAR는 필수 인식 데이터를 캡처하고, 보조 LiDAR는 가려진 영역의 정보를 보완합니다. 이 데이터셋은 3D 객체 탐지, 다중 소스 데이터 융합, 데이터 도메인 전송, 3D 다중 객체 추적 등 네 가지 벤치마크를 지원합니다.

- **Performance Highlights**: 실험 결과에 따르면, InScope를 활용하여 실제 시나리오에서의 3D 다중 객체 탐지 및 추적 성능이 크게 향상되었습니다. 특히 가려지거나 작은 객체 및 먼 거리의 객체를 추적하는 데 있어서 유용한 것으로 나타났습니다. InScope 데이터셋은 새로운 지표를 도입하여 단일 LiDAR와 다중 LiDAR 시나리오 간의 탐지 성능 저하 비율을 평가할 수 있도록 하였습니다.



### Voxel Scene Graph for Intracranial Hemorrhag (https://arxiv.org/abs/2407.21580)
- **What's New**: 이 논문에서 소개한 연구는 3D CT 스캔 데이터를 사용하여 Scene Graph Generation(SGG) 방법을 처음으로 적용한 것입니다. 이로 인해 임상 뇌 장면의 전반적인 표현을 학습하고, 의사 결정에 중요한 통찰을 제공합니다.

- **Technical Details**: 이 연구는 ICH(두개내 출혈) 감지를 위해 맞춤형 객체 감지 방법을 설계하고, 이를 SGG 방법과 결합하여 특정 의료 장면을 학습합니다. 두 단계로 구성된 이 메서드는 먼저 객체를 로컬라이즈합니다. 이는 Retina U-Net과 Feature Pyramid Network를 사용하여 다양한 크기와 모양의 출혈을 감지하며, 중간선과 뇌실 시스템은 단일 스케일에서 나타나는 특징을 고려합니다. 이후 Neural Motifs와 Iterative Message Passing을 기반으로 한 두 가지 변형(V-MOTIF와 V-IMP)을 사용하여 객체 간의 관계를 예측합니다.

- **Performance Highlights**: 두 개의 CT 데이터셋에서 평가한 결과, 제안된 모델은 임상적으로 관련된 관계를 74%까지 재현할 수 있음을 확인했습니다. 이는 기존의 nnDetection 방식보다 우수하며, 임상 장면의 컴팩트하고 해석 가능한 표현을 통해 의사 결정 지원과 향후 작업에 유용한 데이터를 제공합니다.



### Multi-Site Class-Incremental Learning with Weighted Experts in Echocardiography (https://arxiv.org/abs/2407.21577)
Comments:
          Accepted for Oral at MICCAI workshop ASMUS-2024

- **What's New**: 이 논문에서는 심초음파 영상 분류기의 성능을 최적화하기 위한 새 검출법을 제안합니다. 이 방법은 다양한 다중 사이트 데이터의 필요성을 이해하고, 모델 드리프트(model drift)를 완화하기 위해 새로운 데이터를 섭렵하여 자주 업데이트 해야 한다는 점에서 출발합니다. 단순한 파인 튜닝(fine-tuning) 대신, 데이터셋 별 전문가 네트워크를 학습하고, 스코어 퓨전 모델(score fusion model)을 통해 이들을 결합합니다. 이 접근법은 비자격 전문가(unqualified expert)의 영향을 최소화하여 투명성을 증진합니다.

- **Technical Details**: 제안된 방법은 경험적 데이터셋에서 학습한 이미지를 사용하는 대신, 각 데이터셋의 특징을 기반으로 학습된 피쳐(learned features)를 사용합니다. 이는 라이선스나 개인정보 문제를 완화합니다. 우리의 클래스-증가 학습법(class-incremental learning method)은 각 데이터셋에 대해 전문가 네트워크를 학습하고, 인퍼런스 동안 각 전문가의 기여를 학습된 인분포 점수(in-distribution score)를 통해 가중치를 부여하여 결합합니다. 이러한 방식으로 모든 데이터의 재학습이 필요 없도록 하여 훈련 시간 및 비용을 줄입니다.

- **Performance Highlights**: 본 연구에서는 다중 사이트 6개의 데이터셋을 사용하여 유효성을 검증했으며, 이미지 외부 전송 없이 성능을 향상시켰습니다. 이는 훈련 시간과 비용을 크게 감소시키고, 추가적인 증가 단계(incremental steps)를 통해 더욱 최적화할 수 있음을 보여줍니다. 새로운 접근법은 '비자격 전문가'의 영향을 최소화하여 투명성과 성능 모두를 향상시킨다고 입증되었습니다.



### Conditioned Prompt-Optimization for Continual Deepfake Detection (https://arxiv.org/abs/2407.21554)
Comments:
          Accepted at ICPR 2024

- **What's New**: Prompt2Guard라는 새로운 접근법이 소개되었습니다. 이 방법은 Vision-Language Models (VLMs)와 도메인 특정 멀티모달 프롬프트를 사용하여 예제 없는 연속 딥페이크 탐지를 구현합니다. 기존의 VLM 기반 방법들과 달리, 예측 엔삼블 기법을 사용하여 작업 선택 문제를 해결하며, 이는 다중 전방 패스를 필요로 하지 않습니다.

- **Technical Details**: Prompt2Guard는 VLM 내부 표현을 변경하지 않는 읽기 전용 프롬프트(읽기 전용 멀티모달 프롬프트)를 활용합니다. 이를 통해 다중 작업에서 예측 점수를 앙상블 할 수 있으며, 다중 전방 패스를 필요로 하지 않기 때문에 정확성과 효율성을 모두 향상시킵니다. 또한, 딥페이크 탐지에 특화된 텍스트 프롬프트 조건화를 제안합니다.

- **Performance Highlights**: Prompt2Guard는 다양한 도메인과 생성기를 아우르는 다섯 가지 딥페이크 탐지 데이터셋으로 구성된 CDDB-Hard 벤치마크에서 최고의 성능을 기록했습니다. 또한, 연속 학습 시나리오에서 катастроф적 망각을 방지하면서도 탁월한 작업별 평균 정확도를 보여주었습니다.



### ControlMLLM: Training-Free Visual Prompt Learning for Multimodal Large Language Models (https://arxiv.org/abs/2407.21534)
Comments:
          Code:this https URL

- **What's New**: 이 논문에서는 학습 과정을 필요로 하지 않는 방법을 제안하여, 학습 가능한 시각 토큰 최적화를 통해 Multimodal Large Language Models (MLLMs)에 시각적 참조 기능을 주입합니다. 이 방법은 MLLM 디코더의 어텐션 맵에서 텍스트 프롬프트 토큰과 시각 토큰 간의 관계를 관찰하고, 추론 과정에서 MLP 출력을 통해 시각 토큰을 조정하여 텍스트 프롬프트 토큰이 어떤 시각 토큰에 참석할지 제어합니다. 이를 통해 특정 영역에 대한 상세한 설명과 논리를 필요로 하는 경우, 모델 재학습 없이 참조할 수 있는 기능을 제공합니다.

- **Technical Details**: 제안된 방법은 MLLM 디코더의 어텐션 레이어에서 픽셀과 텍스트 프롬프트 토큰 간의 관계를 모델링하는 기존의 어텐션 맵을 이용합니다. 시각 토큰은 MLP 출력으로부터 조정되며, 학습 가능한 잠재 변수를 추가하여 어텐션 맵에서 참조 영역의 강도를 높이는 에너지 함수에 기반한 최적화를 수행합니다. 이렇게 하지 않아도 모델의 재학습이나 추가 데이터 없이 박스, 마스크, 낙서, 포인트 등의 다양한 시각 프롬프트를 지원합니다.

- **Performance Highlights**: 결과는 제안된 방법이 컨트롤 가능성과 해석 가능성을 보여주며, 새로운 데이터 도메인에 대한 일반화 능력도 가지고 있음을 입증합니다.



### Skeleton-Based Action Recognition with Spatial-Structural Graph Convolution (https://arxiv.org/abs/2407.21525)
- **What's New**: 본 연구에서는 인간 활동 인식(HAR) 분야에 있어 최신 기술을 소개합니다. 특히, Graph Convolutional Network(GCN)을 기반으로 인간 골격 데이터를 이용한 활동 인식이 주목받고 있습니다. 그러나 기존 GCN 방법은 골격 데이터 표현과 과도한 스무딩 문제에 대한 연구가 필요했습니다. 이를 해결하기 위해 Spatial-Structural GCN(SpSt-GCN)이라는 두 스트림 그래프 컨볼루션 방법을 제안합니다. 정적인 공간 연결과 동적인 구조 연결을 통해 각기 다른 인간 움직임에 맞춘 유연한 정보 집합이 가능하게 하였습니다.

- **Technical Details**: SpSt-GCN은 두 가지 주요 아이디어에 기반합니다. 첫째, 가장자리 노드는 세밀한 활동 인식에 중요하며, 일반적인 중앙 노드보다 제한된 이웃 정보만을 집계할 수 있습니다. 둘째, GCN의 과도한 스무딩 문제를 해소하기 위해 구조적 연결 방식을 채택하여 차별화를 꾀하고, 각 샘플의 가장자리 노드의 유사성을 바탕으로 구조 연결을 데이터 기반으로 초기화합니다. SpSt-GCN은 인간 골격의 고정된 공간적 연결과 움직임에 따라 변하는 구조적 연결을 동시에 고려합니다.

- **Performance Highlights**: 제안된 방법은 NTU RGB+D와 NTU RGB+D 120와 같은 대규모 데이터 세트에서 평가되었으며, 높은 효율성과 좋은 성능을 보였습니다. 본 연구의 주요 기여는 대칭적 인간 구조와 가장자리 노드를 더 잘 표현할 수 있는 공간-구조 그래프 컨볼루션 방법을 제안한 것과, 인접 노드의 수에만 의존하지 않고 차별적 접근법을 통해 유연성을 높인 것입니다.



### PhysFlow: Skin tone transfer for remote heart rate estimation through conditional normalizing flows (https://arxiv.org/abs/2407.21519)
- **What's New**: 최근 심리 신호를 원격으로 측정하는 딥러닝 방법들이 전통적인 방법을 능가하는 성과를 보여주었습니다. 그러나 다양한 인종적 배경을 대표하지 못하는 데이터셋 부족 때문에 일부 딥러닝 모델은 피부색에 따른 성능 차이를 보입니다. 이를 해결하기 위해 PhysFlow라는 새로운 데이터 증강 방법을 제안합니다. 이는 피부색 정보를 분리하고, 얼굴 비디오에서 CIELAB 색상 공간 피부 특징을 추출하여 심박수 추정 성능을 개선합니다.

- **Technical Details**: PhysFlow는 조건부 정규화 흐름(conditional normalizing flows)을 사용하여 피부색 정보를 얼굴 비디오의 다른 외형 및 시간적 특징과 분리합니다. 또한 CIELAB 색상 공간의 피부 특징을 모델 조건으로 사용하여 자동적으로 피부색을 측정합니다. 이 과정은 외부 레이블이 필요 없이 얼굴 비디오에서 직접 피부색을 추출합니다. 이러한 접근 방식은 피츠패트릭 스케일(Fitzpatrick scale)에 비해 주관적 오류를 줄이고 더 다양한 피부색을 포함할 수 있습니다.

- **Performance Highlights**: UCLA-rPPG 및 MMPD와 같은 공개 데이터셋을 사용하여 PhysFlow를 검증한 결과, 특히 어두운 피부톤에서 심박수 오류가 감소한 것으로 나타났습니다. 또한, 다양한 데이터 기반 rPPG 방법에 대해 적용 가능하고 적응력이 뛰어난 것으로 입증되었습니다.



### A Simple Low-bit Quantization Framework for Video Snapshot Compressive Imaging (https://arxiv.org/abs/2407.21517)
Comments:
          18 pages, Accepted by ECCV 2024

- **What's New**: 이번 연구에서는 비디오 스냅샷 압축 영상(Video Snapshot Compressive Imaging, SCI)을 위한 새로운 저비트 양자화 프레임워크인 Q-SCI를 제안했습니다. 기존의 SOTA (State-of-the-Art) 딥러닝 기반 알고리즘은 높은 성능을 보였지만, 계산 비용이 높다는 단점이 있었습니다. 이러한 문제를 해결하기 위해 Q-SCI는 고품질의 특징 추출 모듈과 정밀한 비디오 재구성 모듈을 설계하여 저비트 양자화 모델에서도 높은 품질의 특징을 추출하고 전달할 수 있도록 했습니다.

- **Technical Details**: Q-SCI 프레임워크는 주로 특징 추출(feature extraction), 특징 향상(feature enhancement), 비디오 재구성(video reconstruction) 모듈로 구성된 딥러닝 기반 비디오 SCI 재구성 방법을 다룹니다. 특히, Transformer 브랜치의 정보 왜곡을 줄이기 위해 쿼리(query)와 키(key) 분포에 시프트 연산을 도입했습니다. 이를 통해 성능 격차를 줄일 수 있었습니다.

- **Performance Highlights**: 종합적인 실험 결과에 따르면, Q-SCI 프레임워크를 통해 4비트로 양자화된 EfficientSCI-S 모델이 이론적으로 실수 값 EfficientSCI-S에 비해 7.8배의 속도 향상을 이루면서도, 성능 차이는 단 2.3%에 불과했습니다. 코드도 공개되어 있습니다.



### PEAR: Phrase-Based Hand-Object Interaction Anticipation (https://arxiv.org/abs/2407.21510)
Comments:
          22 pages, 10 figures, 4 tables

- **What's New**: 최신 연구는 주로 손-객체 상호작용 의도를 예측하지만, 조작(manipulation)에 대한 고려가 부족해서 예측의 정확성이 떨어진다. 이를 해결하기 위해, PEAR(Phrase-based Hand-Object Interaction Anticipation)라는 새로운 모델을 제안한다. 이 모델은 사전-접촉 상호작용 의도와 사후-접촉 상호작용 조작을 함께 예측한다.

- **Technical Details**: PEAR 모델은 두 가지 접근법을 사용한다. 첫째로, 동사, 명사, 이미지 간의 크로스 정렬(cross-alignment)을 수행하여 손 움직임 패턴과 객체 기능 속성의 다양성을 감소시켜 의도 불확실성을 완화한다. 둘째로, 의도와 조작 간에 동적 통합 및 잔차 연결(residual connections)을 통해 양방향 제약을 설정하여 요소 간의 일관성을 보장하고 조작 불확실성을 극복한다. 또한, C-VAE(Conditional-Variational Autoencoder) 디코더를 사용하여 예측 결과에 작은 변이를 도입한다.

- **Performance Highlights**: 새로운 데이터셋 EGO-HOIP를 수집하여 PEAR의 성능을 평가하였다. 이 데이터셋은 상호작용 시나리오와 프롬프트 5천 쌍, 90개의 동사 레이블, 600개의 명사 카테고리를 포함한다. PEAR는 EGO-HOIP 데이터셋에서 최첨단 성과를 달성하며 손-객체 상호작용 예측에서 우수성을 입증하였다.



### MaskUno: Switch-Split Block For Enhancing Instance Segmentation (https://arxiv.org/abs/2407.21498)
- **What's New**: 최신 연구에서는 인스턴스 세분화(instance segmentation) 문제의 해결책으로 MaskUno를 도입합니다. MaskUno는 마스크 예측을 Switch-Split 블록으로 대체하여 정제된 ROI를 처리하고, 이를 분류하고, 전문 마스크 예측기로 할당합니다. 이 방법은 기존의 대부분의 인스턴스 세분화 방법론에서 발생하는 클래스 간 경쟁 문제를 줄이기 위해 설계되었습니다.

- **Technical Details**: MaskUno는 인스턴스 세분화 모델의 최종 예측 레이어를 모듈식 Switch-Split 블록으로 교체합니다. 이 블록은 특정 클래스를 위한 분할 마스크 예측기를 사용해 각 클래스 간의 경쟁 커널 문제를 방지합니다. 이러한 방식으로 각 클래스 별로 독립적으로 최적화가 이루어져 더 풍부한 표현이 가능해집니다.

- **Performance Highlights**: MaskUno는 COCO 데이터셋을 사용한 여러 모델에 적용해 테스트했을 때, 고성능의 DetectoRS 모델에서 평균 정밀도(mAP)가 2.03% 증가했습니다. 이 결과는 MaskUno가 클래스 수와 상관없이 인스턴스 세분화 모델의 성능을 향상시킨다는 것을 보여줍니다.



### Mitral Regurgitation Recogniton based on Unsupervised Out-of-Distribution Detection with Residual Diffusion Amplification (https://arxiv.org/abs/2407.21497)
Comments:
          Accepted by MICCAI MLMI 2024, 11 pages, 3 figures

- **What's New**: 심장 판막 질환인 승모판막 역류(MR)의 진단을 목표로, 초음파 동영상에서 MR을 식별하기 위해 비지도 학습 기반의 out-of-distribution(OOD) 탐지 기법을 제안했습니다. 이 방법은 기존 깊은 학습 역사에서 데이터 불균형 문제를 해결하며, 초음파 동영상에서 MR을 식별하는 데 새롭게 OOD 탐지 메소드를 적용한 첫 사례입니다.

- **Technical Details**: 제안된 메소드는 특성 추출기(feature extractor), 특성 재구성 모델(feature reconstruction model), 그리고 잔여 누적 증폭 알고리즘(residual accumulation amplification algorithm)으로 구성됩니다. 특성 추출기는 동영상 클립에서 특성을 추출하고, 특성 재구성 모델은 원래의 특성을 복원합니다. 잔여 누적 증폭 알고리즘은 테스트 단계에서 OOD 데이터의 노이즈 특성을 재구성하여 OOD 특성의 재구성 오류를 점진적으로 증폭시킵니다. 이 알고리즘은 간단하지만 효율적이며, 재구성 기반의 OOD 탐지 방법에 플러그 앤 플레이 요소로 통합될 수 있습니다.

- **Performance Highlights**: 본 연구에서 제안한 방법은 893개의 비-MR 동영상과 267개의 MR 동영상이 포함된 대규모 초음파 데이터셋에서 검증되었습니다. 실험 결과, 제안된 OOD 탐지 방법이 효과적으로 MR 샘플을 식별할 수 있음을 보여주었습니다.



### Fine-gained Zero-shot Video Sampling (https://arxiv.org/abs/2407.21475)
- **What's New**: 해당 연구에서는 새로운 Zero-Shot video Sampling 알고리즘인 $\mathcal{ZS}^2$를 제안합니다. 이 알고리즘은 기존의 이미지 생성 방법에서 직접 고품질의 비디오 클립을 샘플링할 수 있게 해줍니다. $\\mathcal{ZS}^2$는 별도의 학습이나 최적화 과정 없이, Stable Diffusion과 같은 사전 학습된 이미지 합성 방법을 사용해 비디오를 생성합니다.

- **Technical Details**: $\unction{ZS}^2$는 종속성(Dependency) 노이즈 모델과 시간적 모멘텀 주의 메커니즘(temporal momentum attention)을 활용하여 각각 콘텐츠 일관성과 애니메이션 일관성을 보장합니다. 이 알고리즘은 기존의 DDIM과 같은 이미지 샘플링 알고리즘과 쉽게 통합되어 비디오 생성이 가능합니다. 또한, 조건부와 특화된 비디오 생성, 지시된 비디오 편집 등의 작업에 적용할 수 있습니다.

- **Performance Highlights**: $\unction{ZS}^2$는 zero-shot 비디오 생성에서 최첨단 성능을 달성하여, 때로는 최근 감독된(supervised) 방법들을 능가합니다. 실험 결과, $\\function{ZS}^2$는 훈련이나 튜닝 없이도 텍스트 설명에 맞춰 일관성 있는 비디오 프레임을 생성할 수 있음을 보여줍니다.



### Deep Learning-Based Longitudinal Prediction of Childhood Myopia Progression Using Fundus Image Sequences and Baseline Refraction Data (https://arxiv.org/abs/2407.21467)
- **What's New**: 본 연구에서는 어린이 근시의 진행을 예측하기 위한 새로운 고정확도 방법을 소개합니다. 이 방법은 망막(fundus) 이미지와 기초 굴절 데이터만을 사용하여 어린이 근시 경과와 근시 위험을 정량적으로 예측할 수 있습니다.

- **Technical Details**: 연구는 Henan 지역에서 6년 동안 3,408명의 어린이들을 대상으로 16,211장의 망막 이미지와 해당 굴절 데이터를 활용하여 검증되었습니다. 본 연구에서 제안된 방법은 깊은 학습(deep learning)에 기반하고, 연간 0.311 디옵터(D) 오차 범위를 가지며, 근시 및 고도근시(high myopia) 발생 위험 예측에서 각각 0.944와 0.995의 AUC 점수를 기록했습니다.

- **Performance Highlights**: 본 모델은 추가 메타 데이터나 반복적인 진료가 필요하지 않으며, 단 한번의 측정만으로도 유효한 예측이 가능합니다. 이를 통해 의료 비용을 획기적으로 절감할 수 있으며, 대규모 스크리닝(screening)에도 용이합니다.



### MarvelOVD: Marrying Object Recognition and Vision-Language Models for Robust Open-Vocabulary Object Detection (https://arxiv.org/abs/2407.21465)
Comments:
          Codes are available at this https URL

- **What's New**: 최근 연구에서 비전 언어 모델(VLM)을 이용한 의사 레이블(pseudo-label)을 통해 열린 어휘 탐지(OVD)를 향상시키는 방법이 제안되었습니다. MarvelOVD라는 새로운 패러다임이 도입되었으며, 탐지기와 VLM을 결합하여 더 나은 훈련 목표를 생성하고 온라인 방식으로 학습 절차를 최적화합니다. 주요 통찰력은 탐지기가 VLM의 배경 및 맥락 이해 부족을 보완하는 강력한 보조 안내 역할을 할 수 있다는 것입니다.

- **Technical Details**: MarvelOVD는 '배경'과 '맥락' 인식을 이용하여 의사 레이블을 정화하고 훈련 설계에서 발생하는 편향을 효과적으로 억제하는 것을 목표로 합니다. 이를 위해 Online Mining 기법과 Adaptive Reweighting 방법을 도입하여 비정확한 훈련 상자를 효과적으로 무시합니다. 또한, 'base-novel-conflict' 문제를 식별하고 이를 방지하기 위해 계층적 레이블 할당 방법을 제안합니다. 이 방법은 COCO와 LVIS 데이터셋에서 광범위한 실험을 통해 뛰어난 성능을 보였습니다.

- **Performance Highlights**: 전통적인 OVD 모델을 크게 뛰어넘는 성과를 보여주었으며 COCO와 LVIS 벤치마크에서 새로운 상태-최고 (state-of-the-art) 성과를 기록했습니다. MarvelOVD는 다른 최신 방법들보다 월등한 성능을 자랑합니다.



### StreetSurfaceVis: a dataset of crowdsourced street-level imagery with semi-automated annotations of road surface type and quality (https://arxiv.org/abs/2407.21454)
Comments:
          11 pages, 2 figures

- **What's New**: 이 논문에서는 StreetSurfaceVis라는 새로운 데이터셋을 소개합니다. 이 데이터셋은 과밀화된 플랫폼(Mapillary)에서 수집된 9,122개의 거리 수준 이미지로 구성되어 있으며, 도로 표면 유형과 품질에 따라 수동으로 주석이 달려 있습니다. 이는 도로 네트워크의 전반적인 표면 평가를 위한 모델을 훈련시키는 데 사용됩니다. 현재의 공개 데이터셋은 지리적 범위와 카메라 설정이 제한적이며 보도나 자전거 도로를 포함하지 않는 경우가 많습니다. 다양성이 풍부한 데이터셋을 구축함으로써, 우리는 다양한 이미지 소스에서 높은 정확성을 유지하는 견고한 모델을 가능하게 합니다.

- **Technical Details**: StreetSurfaceVis 데이터셋의 이미지는 크라우드소싱 플랫폼 Mapillary에서 수집한 독일 내 거리 수준 이미지로 구성되어 있으며, 이는 각기 다른 지리적 위치, 다양한 카메라 각도 및 운송 수단을 사용한 기여자들로 인해 이질적입니다. 데이터셋은 지도에 태그로 지정된 독일의 OpenStreetMap (OSM) 데이터를 사용하여 사전 필터링하고, 맞춤형 표면 유형 분류 모델을 반복적으로 훈련 및 적용하며, GPT-4 모델을 활용한 프롬프트 기반 이미지 분류 및 이미지 임베딩을 사용한 유사성 기반 검색을 통해 미리 라벨을 지정하는 전략을 포함합니다.

- **Performance Highlights**: 논문에서는 이러한 전략을 사용하여 수동 주석 작업을 효과적으로 줄이면서 각 클래스의 충분한 대표성을 유지할 수 있음을 보여 주었습니다. 또한, 표면 유형에 대한 Krippendorff’s α 지수는 0.96으로 계산되어 높은 수준의 일치도를 나타냈습니다.



### Forecasting Future Videos from Novel Views via Disentangled 3D Scene Representation (https://arxiv.org/abs/2407.21450)
Comments:
          Accepted to ECCV 2024. Project Page: this https URL

- **What's New**: 최근의 기술적 한계점을 극복하고자, 우리는 장면 기하학(scene geometry)과 움직임(scene motion)을 분리하여 처리하는 새로운 방법을 제안합니다. 이로써 2D 장면을 3D 점 구름(point clouds)으로 변환하여, 보다 높은 품질의 미래 비디오를 새로운 시각에서 렌더링할 수 있게 합니다. 또한, 이 방법은 초기 자아 움직임(ego-motion)을 예측하고 다음으로 동적 객체의 잔여 움직임(residual motion)을 예측하는 두 단계 접근법을 사용합니다.

- **Technical Details**: 우리의 접근법은 먼저 장면 기하학을 3D 점 구름으로 변환한 후, 3D 점들을 기반으로 물리적 움직임을 예측하는 방식을 따릅니다. 이 과정을 통해 장면 요소의 위치를 조정하여 미래 프레임을 생성합니다. 첫 단계에서는 자아 움직임을 예측하고, 두 번째 단계에서는 동적 객체의 움직임을 예측하는 방식을 통해 전체 장면 움직임을 효과적으로 모델링합니다. 이를 위해 입력 프레임으로부터 깊이 맵을 추정하고, 점 구름을 구성한 뒤, 고급 3D-2D 렌더링 기술을 사용합니다.

- **Performance Highlights**: 우리의 방법은 KITTI와 Cityscapes 데이터셋을 기반으로 한 실험에서 기존의 강력한 기본 방법들보다 뛰어난 성능을 보여주었습니다. 특히, 새로운 시각에서의 고품질 시각 예측과 사실적인 합성을 통해 더 나은 결과를 도출하였습니다.



### Accelerating Image Super-Resolution Networks with Pixel-Level Classification (https://arxiv.org/abs/2407.21448)
Comments:
          Accepted by ECCV 2024

- **What's New**: 최근 대규모 이미지(super-resolution, SR) 기술의 필요성이 증가하고 있는 가운데, 특히 2K에서 8K 해상도의 이미지를 대상으로 하는 경우가 많습니다. 이를 위한 새로운 솔루션으로, 픽셀 수준에서 자원을 적응적으로 분배하는 'Pixel-level Classifier for Single Image Super-Resolution (PCSR)' 메서드가 제안되었습니다. PCSR은 이미지의 각각의 픽셀의 복원 어려움에 따라 자원을 배분하여 효율성과 성능을 최적화합니다.

- **Technical Details**: PCSR 모델은 백본(backbone), 픽셀 수준의 분류기(pixel-level classifier), 그리고 다양한 용량의 픽셀 수준 업샘플러(pixel-level upsamplers)로 구성되어 있습니다. 모델의 작동 방식은 다음과 같습니다: 1) 백본이 저해상도 입력을 받아 저해상도 특징 맵을 생성, 2) 픽셀 수준 분류기가 특징 맵과 픽셀의 상대 위치를 사용하여 각 픽셀을 적절한 업샘플러에 할당, 3) 각 픽셀이 적절한 업샘플러에 배정되어 RGB 값을 예측, 4) 모든 픽셀의 RGB 값을 집계하여 초해상도 출력 이미지를 생성. 이러한 방식으로 픽셀 단위로 연산을 줄여 기존의 패치 분배 방식보다 더 높은 효율성을 얻을 수 있습니다.

- **Performance Highlights**: 실험 결과, PCSR은 다양한 백본 모델과 벤치마크에서 PSNR-FLOP 트레이드오프 측면에서 기존의 패치 분배 방법보다 우수한 성능을 보였습니다. 특히 Test2K/4K/8K와 Urban100 벤치마크에서 뛰어난 성능을 입증했습니다. 또한, 전체 이미지를 처리하는 기존의 방법과 비교해보았을 때도 우수한 성능을 나타냈습니다.



### A Plug-and-Play Method for Rare Human-Object Interactions Detection by Bridging Domain Gap (https://arxiv.org/abs/2407.21438)
- **What's New**: 최신 연구는 인간-객체 상호작용(HOI) 검출에서 발생하는 데이터 불균형 문제를 해결하기 위해 새로운 모델 불가지론적(Context-Enhanced Feature Alignment, CEFA) 모듈을 소개했습니다. 이 모듈은 생성된 데이터와 원본 데이터를 특징 수준에서 효과적으로 정렬하고 도메인 차이를 극복하는 데 중점을 둡니다.

- **Technical Details**: CEFA 모듈은 특징 정렬 모듈(feature alignment module)과 컨텍스트 강화 모듈(context enhancement module)로 구성됩니다. 특징 정렬 모듈은 인스턴스 정보를 집계하여 인간-객체 쌍을 정렬하며, 컨텍스트 강화 모듈은 전통적인 디스크리미네이터(discriminator) 스타일의 정렬 방법이 중요 컨텍스트 정보를 잃는 문제를 해결하기 위해 설계되었습니다. 이 모듈은 생성된 이미지와 원본 이미지 사이의 도메인 차이를 극복하고, 새로운 학습 데이터를 구축하여 모델의 성능을 향상시킵니다.

- **Performance Highlights**: CEFA 모듈은 플러그 앤 플레이(plug-and-play) 방식으로 기존 HOI 모델에 적용될 수 있으며, 희귀 범주에서의 검출 성능을 향상시킬 수 있음을 여러 실험을 통해 입증하였습니다.



### Enriching thermal point clouds of buildings using semantic 3D building modelsenriching thermal point clouds of buildings using semantic 3D building models (https://arxiv.org/abs/2407.21436)
Comments:
          Accepted to the 3D GeoInfo 2024

- **What's New**: 본 연구는 열 점군(Thermal point clouds)에 고해상도의 LoD3 건물 모델의 지리정보 및 의미 정보를 통합하는 새로운 워크플로우를 제안합니다. 이를 통해 서로 다른 소스에서 얻어진 점군을 자동으로 공동 등록(co-register)하고, 열 점군에 상세한 외벽-수준의 의미 정보를 제공할 수 있게 합니다. 이러한 방식은 건물의 다양한 열 분석을 용이하게 하고, 열 점군을 직접 사용한 딥러닝 모델 개발에 기여할 수 있게 합니다.

- **Technical Details**: 열 점군은 열 복사 데이터와 레이저 점군을 결합하여 객체의 열 특성을 효과적으로 캡처합니다. 제안된 방법은 먼저 고해상도의 LoD3 건물 모델을 의미 점군으로 변환한 후, 이를 열 점군과 공동 등록하는 일련의 프로세스를 거칩니다. LoD3 모델과 점군은 서로 다른 데이터 형식을 사용하며, 이는 B-Rep 형태의 구조화된 형식과 언스트럭처(Non-structured) 포인트 클라우드 형식(X, Y, Z)으로 구분됩니다. 이 과정에서 건물의 다양한 열 속성을 분석하고, LoD3 모델의 기하학적 정보를 검증하며 세부 사항을 보강하는 데 기여합니다.

- **Performance Highlights**: 이 방법은 기존의 점군 의미 분할 및 레이블링 방식보다 정확도가 높으며, 특히 외벽 수준의 세부 정보(예: 창문, 문, 발코니 등)를 효율적으로 분류할 수 있습니다. 실험 결과, 제안된 방법이 모델에서 제공하는 의미 정보를 열 점군에 성공적으로 통합하여 열 분석 응용을 보다 정밀하게 수행할 수 있음을 확인했습니다.



### Analyzing the impact of semantic LoD3 building models on image-based vehicle localization (https://arxiv.org/abs/2407.21432)
Comments:
          Accepted to the 3D GeoInfo 2024

- **What's New**: 이 논문은 고도로 정밀한 3D 건물 모델의 이미지 특징을 활용한 새로운 차량 위치 추정 방법을 도입하였습니다. 특히 도시 지역에서 GNSS 신호 강도가 약해지는 문제를 해결하기 위해 기존의 방법들 대신, Level of Detail (LoD) 3 모델을 사용하여 위치 정밀도를 크게 향상시키는 것이 핵심입니다.

- **Technical Details**: 이 연구는 다양한 방법론을 통해 LoD2와 LoD3 모델을 비교 분석했습니다. 특히, ORB, SIFT, SURF 등의 기능 매칭 알고리즘과 딥러닝(Deep Learning) 기법을 사용하여 실험을 수행했습니다. 구체적으로, 가상 이미지를 생성하여 이들 이미지에서 특징을 추출하고, 이를 기반으로 카메라 위치를 추정합니다. 이 과정에서 삼변형(triangulation) 알고리즘을 활용하여 폴리헤드럴(building model)을 메시(mesh) 모델로 변환하고 레이 캐스팅(ray casting)을 통해 가상 이미지를 생성합니다.

- **Performance Highlights**: 실험 결과, LoD3 모델을 사용하면 LoD2 모델에 비해 최대 69% 더 많은 특징을 감지할 수 있었습니다. 이는 GNSS 신호가 약한 도시 협곡에서 위치 정밀도를 크게 향상시킬 수 있는 잠재성을 시사합니다. 이를 통해 LoD3 모델이 위치 추정에 실질적으로 기여할 수 있는 가능성을 확인했습니다.



### Generalized Tampered Scene Text Detection in the era of Generative AI (https://arxiv.org/abs/2407.21422)
- **What's New**: 본 논문에서는 텍스트 이미지 편집의 발전에 따라 발생하는 허위 정보 확산 문제를 해결하기 위한 새로운 작업을 제안합니다. 제안된 작업은 open-set tampered scene text detection으로, 이는 모델이 본 적 없는 유형의 변조 텍스트를 검출하는 능력을 평가합니다. 또한, 8개의 텍스트 편집 모델로 변조된 텍스트를 포함하는 새로운 데이터셋을 소개하고, fine-grained perception과 open-set generalization 능력을 향상시키기 위한 새로운 사전 학습 패러다임인 Texture Jitter를 도입했습니다.

- **Technical Details**: 제안된 Texture Jitter는 텍스트의 무작위 지역의 텍스처를 미세하게 변경하여 다양한 텍스처 이상을 만들어 모델을 훈련시키는 방식입니다. 이를 통해 고품질의 학습 데이터 부족 문제를 완화하고, 모델이 텍스처 이상을 감지하도록 하여 세분화된 인식 능력을 향상시킵니다. 또한, Difference-Aware Forensics (DAF)라는 새로운 프레임워크를 통해 실제 텍스트의 특징을 학습하고 입/출력 텍스트의 특징 차이를 비교하여 변조 여부를 판단하는 방법을 제안하였습니다.

- **Performance Highlights**: 광범위한 실험을 통해 제안된 방법의 뛰어난 성능을 검증하였습니다. 예를 들어, zero-shot 성능은 기존 최고 성능 모델보다 훨씬 높은 성능을 보여줬습니다. 제안된 방법은 OSTF 벤치마크에서 open-set generalization 능력을 27.88 mean F-score로 향상시켰으며, zero-shot 버전은 Tampered-IC13 벤치마크에서 이전 SOTA 방법인 UPOCR를 10.46 mean IoU로 앞질렀습니다.



### VIPeR: Visual Incremental Place Recognition with Adaptive Mining and Lifelong Learning (https://arxiv.org/abs/2407.21416)
Comments:
          8 pages, 4 figures

- **What's New**: VIPeR(VIsual Place Recognition)은 자율 및 증강/가상 현실 시스템에서 필수적인 VPR(Visual Place Recognition) 기능을 개선하는 새로운 방법입니다. VIPeR는 새 환경에 적응하면서 기존 환경의 성능을 유지하는 것이 특징입니다.

- **Technical Details**: VIPeR은 인크리멘탈 러닝(incremental learning) 접근법을 사용하여 새로운 환경에서도 성능 저하 없이 적응할 수 있도록 설계되었습니다. 핵심 기술로는 트리플릿 손실(Triplet Loss)에 대한 적응형 마이닝(adaptive mining) 전략과 인간의 기억 시스템에서 영감을 받은 새로운 메모리 뱅크(memory bank)가 있습니다. 메모리 뱅크는 감각 기억(sensory memory), 작업 기억(working memory), 장기 기억(long-term memory)으로 구성됩니다. 또 하나의 주요 기술은 확률적 지식 증류(probabilistic knowledge distillation)로, 이전에 학습한 지식을 명시적으로 보호하는 역할을 합니다.

- **Performance Highlights**: VIPeR는 Oxford Robotcar, Nordland, TartanAir 세 가지 대규모 데이터셋에서 테스트되었습니다. 실험 결과, VIPeR는 대부분의 측면에서 성능이 우수했으며, 특히 평균 성능에서 13.65%의 가장 큰 향상을 보였습니다. 기존 방법들과 비교했을 때 VIPeR는 더욱 향상된 성능을 보여주었습니다.



### Benchmarking AIGC Video Quality Assessment: A Dataset and Unified Mod (https://arxiv.org/abs/2407.21408)
- **What's New**: 최근 인공지능(AI) 기반의 비디오 생성 기술 발전으로 AI 생성 콘텐츠(AIGC) 비디오의 품질 평가 필요성이 대두되고 있습니다. 이를 위해, 이번 연구에서는 주관적 및 객관적 품질 평가 관점에서 AIGC-VQA 문제를 체계적으로 조사하였습니다. 특히, 주관적 관점에서는 대규모 생성 비디오 품질 평가(LGVQ) 데이터셋을 구축하여 공간적 품질, 시간적 품질, 텍스트-비디오 일치성 평가를 수행했습니다. 객관적 관점에서는 기존 품질 평가 지표를 LGVQ 데이터셋에 벤치마킹하였습니다.

- **Technical Details**: 이번 연구에서는 468개의 텍스트 프롬프트로 생성된 2,808개의 AIGC 비디오를 포함한 LGVQ 데이터셋을 구축했습니다. 각 비디오의 공간적 품질, 시간적 품질, 텍스트-비디오 일치성에 대한 주관적 평가를 위해 54명의 평가자를 초청하였습니다. 이후, 기존의 영상 품질 평가 지표들을 LGVQ 데이터셋에 벤치마킹하여 그 성능을 분석했습니다. 이 과정에서, 우리는 AIGC 비디오의 품질을 포괄적이고 정확하게 평가하기 위한 통합 모델인 UGVQ(Unify Generated Video Quality assessment) 모델을 제안했습니다. UGVQ는 CLIP의 시각적, 텍스트 특징과 SlowFast의 모션 특징을 사용하며, 각 특징을 통합하여 향상된 품질 인식 특징 표현을 제공합니다.

- **Performance Highlights**: UGVQ 모델은 LGVQ 데이터셋에서 기존의 재학습된 품질 평가 지표들에 비해 모든 세 가지 품질 측면에서 가장 우수한 성능을 보였습니다. 이는 UGVQ 모델이 AIGC 비디오의 품질을 평가하기 위한 효과적이고 종합적인 VQA 지표로서 활용될 수 있음을 시사합니다.



### DD-rPPGNet: De-interfering and Descriptive Feature Learning for Unsupervised rPPG Estimation (https://arxiv.org/abs/2407.21402)
- **What's New**: 이번 논문에서는 원격 광용적맥파 (rPPG) 신호를 정확하게 추정하기 위해 DD-rPPGNet이라는 새로운 모델을 제안했습니다. 이 모델은 rPPG 신호의 간섭(interference)을 제거하고 진정한 rPPG 신호를 학습하도록 설계되었습니다.

- **Technical Details**: DD-rPPGNet는 두 단계로 구성된 비지도방식(unsupervised)의 새로운 모델입니다. 첫 번째 단계에서는 약간의 증강된 학습 데이터를 사용하여 초기 rPPG 신호를 추정합니다. 두 번째 단계에서는 간섭 특징을 추정하여 이러한 간섭을 제거한 rPPG 특징을 도출하고, 진정한 rPPG 신호를 강화합니다. 또한, 미세한 색상 변화(chrominance changes)를 포착하기 위해 3D Learnable Descriptive Convolution (3DLDC)를 도입해 rPPG 추정을 향상시킵니다.

- **Performance Highlights**: 다섯 개의 rPPG 벤치마크 데이터셋에서의 실험 결과, 제안된 DD-rPPGNet는 기존 비지도방식 rPPG 추정 방법을 능가했으며, 최첨단 지도방식(supervised)의 rPPG 추정 방법과 경쟁력을 가집니다.



### Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering (https://arxiv.org/abs/2407.21368)
- **What's New**: 최근 몇 년간 큰 성과를 거둔 대규모 비전-언어 모델(LVLMs)이 의료 분야로 확장되었습니다. 하지만, 이들 모델은 환각(hallucination) 문제로 인해 복잡한 병리학 진단에 실패하는 경우가 많습니다. 본 연구에서는 이러한 문제를 해결하기 위해 두 가지 프롬프트 전략을 제안합니다. 첫 번째 전략은 질의된 병리학에 대한 상세 설명을 제공하는 것이며, 두 번째 전략은 저비용 약한 학습기(weak learner)를 조정하여 특정 지표에서 높은 성능을 달성하게 한 후, 그 판단을 텍스트로 MLVLM에 전달하는 것입니다.

- **Technical Details**: 첫 번째 프롬프트 전략은 질의된 병리학에 대한 세부 설명을 추가하여 모델의 이해도를 높입니다. 두 번째 전략은 추가 약한 학습기를 별도의 에이전트로 사용하여, 그 모델이 부정적인 이미지를 정확하게 식별하도록 하고, 결과를 프롬프트에 참조로 제공하는 것입니다. 이 전략들은 MIMIC-CXR-JPG와 Chexpert 데이터셋에서 테스트되었으며, F1 점수를 크게 향상시켰습니다. 특히 POPE 지표에 따라 일반 LVLM 도메인에까지 확장될 수 있음을 보여줍니다.

- **Performance Highlights**: 제안된 프롬프트 전략들은 MIMIC-CXR-JPG와 Chexpert 데이터셋에서 테스트되었으며, 다수의 병리학 카테고리에서 F1 점수가 0.27까지 향상되었습니다. 일반 도메인에서도 유사한 전략을 사용하여 거짓 부정(False Negative) 예측을 억제하고, Recall을 약 0.07만큼 향상시켰습니다. 이는 모델이 보다 정교한 진단과 질문 응답을 수행할 수 있도록 도움을 줍니다.



### ESIQA: Perceptual Quality Assessment of Vision-Pro-based Egocentric Spatial Images (https://arxiv.org/abs/2407.21363)
Comments:
          8 pages, 8 figures

- **What's New**: eXtended Reality(XR)의 발전과 동시에, 헤드마운트 촬영 및 디스플레이 기술은 큰 주목을 받고 있습니다. 이러한 기술을 통해 촬영된 자아중심 공간 이미지와 비디오의 인식 품질 평가(IQA)는 도전 과제가 되고 있습니다. 본 논문에서는 자아중심 공간 이미지 품질 평가 데이터베이스(ESIQAD)를 최초로 구축하였으며, 이를 통해 다양한 뷰잉 모드에서 22개의 최첨단 IQA 모델 성능을 평가한 벤치마크 실험을 실시했습니다.

- **Technical Details**: ESIQAD는 Apple Vision Pro를 사용하여 촬영된 400개의 이미지와 iPhone의 'Spatial Camera' 앱을 통해 생성된 100개의 이미지를 포함한 총 500개의 자아중심 공간 이미지로 구성되어 있습니다. 이들 이미지는 2D, 3D-윈도우 디스플레이, 3D-몰입형 디스플레이 등 세 가지 뷰잉 모드에서 평균 의견 점수(MOS)를 수집했습니다. 주관적 실험을 통해 다양한 신의 인간 인지 품질 점수를 수집하였으며, 총 22명의 참가자가 포함되었습니다.

- **Performance Highlights**: 벤치마크 실험 결과, 다양한 신에서 22개의 최첨단 IQA 모델의 성능을 평가했습니다. 실험에는 Apple Vision Pro의 고정 해상도(2560 x 2560)와 iPhone의 고해상도(4032 x 3024) 이미지를 활용하였으며, 평가 환경은 2D 모니터 및 Apple Vision Pro 장치를 사용한 3D 모드로 구성되었습니다. 이러한 결과는 자아중심 공간 이미지의 품질 평가 연구에 중요한 기초자료로 사용될 것입니다.



### Small Object Few-shot Segmentation for Vision-based Industrial Inspection (https://arxiv.org/abs/2407.21351)
- **What's New**: 이 논문은 산업용 비전 기반 검사(Visual-based Industrial Inspection, VII)에서 새롭고 보지 못한 결함을 몇 가지 주석만으로도 재교육 없이 빠르게 찾는 방법을 제안합니다. 기존의 몇 샷 세그멘테이션(FSS) 기법은 작은 결함을 찾는 데 여러 문제를 겪는데, 이를 해결하기 위해 저자는 소규모 물체 몇 샷 세그멘테이션 모델(SOFS)을 제안합니다. 이 모델은 원본 이미지를 리사이징하지 않고 지원 주석의 프로토타입 강도를 다운샘플링하여 결함의 강도를 정확히 나타냅니다. 또한, 비정상적인 사전 지도를 설계하여(false positives) 잘못된 양성을 줄입니다.

- **Technical Details**: SOFS 모델의 핵심 아이디어는 원본 이미지를 리사이징하지 않고, 지원 주석의 프로토타입 강도를 다운샘플링하여 대상 의미의 왜곡을 피하며, 비정상적인 사전 지도를 사용하여 모델이 잘못된 양성을 줄이는 것입니다. SOFS는 훈련 중 작은 물체를 자르고, 테스트에서는 슬라이딩 윈도우 메커니즘을 사용하여 픽셀 영역을 일정하게 유지합니다. 또한, 혼합된 정상적인 Dice 손실 함수를 제안하여 모델이 잘못된 양성을 예측하지 않도록 대형 패널티를 부과합니다.

- **Performance Highlights**: SOFS는 VISION V1 데이터셋에서 12.2% mIoU 향상을 이루며, 기존의 SegGPT를 능가하는 성과를 보였습니다. 몇 샷 이상 탐지 실험에서도 경쟁력 있는 성능을 입증하였습니다. 이는 VII에서 FSS와 FAD 모두를 달성한 최초의 모델입니다.



### High-throughput 3D shape completion of potato tubers on a harvester (https://arxiv.org/abs/2407.21341)
Comments:
          18 pages, 11 figures, 6 tables

- **What's New**: 이 연구는 RGB-D 카메라를 사용해 개별 감자 결절의 3D 부피를 추정하는 CoRe++라는 3D 형태 완료 네트워크를 개발했습니다. 이 네트워크는 RGB-D 이미지로부터 3D 형태를 완성하며, 새로운 데이터 전처리 및 색상 데이터 증강 기법을 적용했습니다. 연구팀은 네트워크의 정확도와 속도 향상을 통해 실제 작동하는 수확기에서 높은 처리량으로 감자 수확량을 추정할 수 있다는 결론을 내렸습니다.

- **Technical Details**: CoRe++ 네트워크는 RGB-D 이미지에서 얻은 데이터를 압축하는 convolutional encoder(컨벌루셔널 인코더)와 이를 활용해 3D 형태를 완성하는 Deep Signed Distance Field Network(DeepSDF, 딥 서명 거리 필드 네트워크)로 구성되어 있습니다. 인코더는 RGB-D 이미지를 고정된 벡터로 압축한 후, 디코더는 이를 사용해 3D 형태를 완성합니다. 본 연구에서는 339개의 감자 결절에 대한 부분 및 완전한 3D 포인트 클라우드를 수집해 네트워크를 평가했습니다. 또한 새로운 데이터 전처리 및 색상 데이터 증강 기법을 적용해 기존의 CoRe 네트워크를 개선했습니다.

- **Performance Highlights**: 테스트 세트에서 CoRe++는 평균 2.8mm의 정확도로 3D 형태를 완성했으며, 부피 추정에서는 RMSE가 22.6ml로 기존 모델들보다 더 나은 성능을 보였습니다. 중앙 이미지 영역에서 3D 형태 완성을 수행할 경우 RMSE는 18.2ml로 더 줄어들었습니다. 감자 하나당 3D 형태 완성 시간은 10밀리초로, 이는 실제 수확기에서 고처리량 감자 수확량 추정에 충분히 빠르고 정확함을 나타냅니다.



### On-the-fly Point Feature Representation for Point Clouds Analysis (https://arxiv.org/abs/2407.21335)
Comments:
          Accepted by ACM MM 2024

- **What's New**: 이번 연구에서는 점 구름 데이터(point cloud) 분석의 새로운 방법인 On-the-fly Point Feature Representation (OPFR)을 제안합니다. OPFR은 Curve Feature Generator 모듈을 통해 풍부한 기하 정보를 명시적으로 캡처합니다. 이 접근법은 컴퓨터 비전 커뮤니티에서 널리 사용되는 Point Feature Histogram (PFH)에서 영감을 받았습니다. 그러나 PFH가 대규모 데이터셋과 밀집된 점 구름에 적용될 때 큰 어려움이 있다는 점을 고려하여, OPFR은 Local Reference Constructor 모듈을 도입하여 계산 효율성을 획기적으로 향상시켰습니다.

- **Technical Details**: OPFR의 주요 구성 요소는 Curve Feature Generator와 Local Reference Constructor입니다. Curve Feature Generator 모듈은 지역 곡률 정보를 명시적으로 캡처하며, Local Reference Constructor 모듈은 삼각형 집합(triangle sets)을 기반으로 지역 좌표 시스템을 근사하여 계산 시간을 크게 줄입니다. 또한, Hierarchical Sampling 모듈을 도입하여 삼각형 집합의 왜곡 문제를 줄이고, 견고한 기하 피처를 제공합니다. 이 모듈들은 다양한 백본(backbone) 네트워크와 호환되도록 설계되었습니다.

- **Performance Highlights**: 제안된 OPFR 방법은 PointNet++ 백본을 기반으로 ModelNet40 데이터셋에서 분류 정확도(Overall Accuracy, OA)를 90.7%에서 94.5%로 (+3.8%) 향상시켰으며, S3DIS Area-5 데이터셋에서 의미론적 세분화 정확도를 86.4%에서 90.0%로 (+3.6%) 증가시켰습니다. Point Transformer 백본과 통합했을 때, ModelNet40에서 94.8%의 OA, S3DIS Area-5에서 91.7%의 OA를 달성하며, 두 작업 모두에서 최고 성능(state-of-the-art)을 달성했습니다.



### Chat2Layout: Interactive 3D Furniture Layout with a Multimodal LLM (https://arxiv.org/abs/2407.21333)
Comments:
          Main paper with supplemental materials

- **What's New**: 이번 논문에서는 Chat2Layout라는 혁신적인 인터랙티브 가구 배치 생성 시스템을 소개합니다. 이 시스템은 멀티모달 대형 언어 모델(multimodal large language models, MLLMs)을 활용하여 상호작용적 레이아웃 디자인을 가능하게 합니다. 이를 통해 사용자는 3D 가상 공간 내에서 언어적 및 시각적 피드백을 주고받으며 가구 배치를 동적으로 생성 및 배치할 수 있습니다.

- **Technical Details**: Chat2Layout는 통합된 비전-질문 패러다임(vision-question paradigm)를 통해 MLLMs와의 원활한 커뮤니케이션을 가능하게 합니다. 이 패러다임은 텍스트와 시각 정보를 모두 활용하여 모델의 가중치를 변경하지 않고도 학습을 진행할 수 있게 합니다. 주요 기술로는 '비주얼-텍스트 프롬프팅(visual-text prompting)' 기술과 '오프라인-투-온라인 검색(Offline-to-Online search)' 방법이 있습니다. 이 방법들은 효율적인 인-컨텍스트 학습을 지원하며, 제한된 예시에서 필요한 정보를 자동으로 추출합니다.

- **Performance Highlights**: Chat2Layout 시스템은 다양한 3D 가구 배치 작업을 지원하며, 복잡한 가구 배치를 언어적으로 상호작용하며 생성할 수 있습니다. 실험 결과, 이 접근법은 언어적 상호작용을 통해 여러 회차에 걸쳐 레이아웃을 세부적으로 조정할 수 있으며, 사용자의 기대와 공간 제약을 반영하는 뛰어난 배치 결과를 도출해 낼 수 있음을 입증했습니다.



### CAMAv2: A Vision-Centric Approach for Static Map Element Annotation (https://arxiv.org/abs/2407.21331)
Comments:
          arXiv admin note: text overlap with arXiv:2309.11754

- **What's New**: 최근 HD 맵 생성 알고리즘의 발전으로 고품질의 데이터가 필요한 수요가 급증하고 있습니다. CAMAv2는 기존의 LiDAR 센서가 아닌 비전 중심 접근법을 통해 일관되고 정확한 지도 주석을 생성하는 새로운 프레임워크를 제안합니다. 이 프레임워크는 nuScenes 데이터셋을 활용하여 더 낮은 재투영 오류를 달성합니다.

- **Technical Details**: CAMAv2는 LiDAR 입력 없이 주변 카메라 이미지만으로 높은 품질의 3D 주석을 생성할 수 있는 프레임워크입니다. 3D 재구성 파이프라인을 통해 정확한 카메라 움직임과 희소 포인트 클라우드를 생성하며, 고정밀 도로 표면 메쉬 재구성 알고리즘을 사용합니다. 마지막으로, 자동 지도 주석 도구를 통해 벡터화된 차선 표현을 추출합니다. 이를 통해 전체 시퀀스에 걸쳐 공간적 시간적으로 일관된 고정밀 주석을 제공합니다.

- **Performance Highlights**: CAMAv2가 생성한 주석은 nuScenes 기본 HD 맵보다 낮은 재투영 오류(예: 4.96 vs. 8.03 픽셀)를 달성하였습니다. CAMAv2 주석으로 훈련된 모델 또한 더 낮은 재투영 오류(예: 5.62 vs. 8.43 픽셀)를 기록하며, 일관성 및 기하학적 정확도를 크게 향상시킵니다.



### Pathology Foundation Models (https://arxiv.org/abs/2407.21317)
Comments:
          19 pages, 1 figure, 3 tables

- **What's New**: 병리학(病理學)은 수술 및 생검을 통해 얻은 환자 조직 샘플의 진단 및 평가에서 중요한 역할을 오랫동안 해왔습니다. 최근에는 Whole Slide Scanners와 딥러닝 기술(Deep Learning Technologies)의 발전으로 병리학 AI(인공지능) 분야에서도 큰 진전이 이루어졌습니다. 특히, 최근에 등장한 Foundation Models(FMs)는 기존 AI 모델보다 더 정확하고 다양한 작업에 적용 가능하여 의료 분야에서 그 활용도가 크게 확대되고 있습니다. 병리학에서는 많은 FMs가 개발되었고, 여러 질병 진단, 희귀 암 진단, 환자 생존 예후 예측, 바이오마커(Biomarker) 발현 예측, 면역조직화학적 발현 강도의 점수화 등의 다양한 작업에서 그 적용이 보고되고 있습니다.

- **Technical Details**: Foundation Models(FMs)은 대규모의 AI 모델로서 다양한 병리학적 작업에 적용됩니다. 예를 들어, 질병 진단, 희귀 암 진단, 환자 생존 예후 예측, 바이오마커 발현 예측 및 면역조직화학적 발현 강도의 점수화 등에 활용됩니다. 하지만 이러한 FMs의 임상적 적용에는 아직 해결해야 할 여러 문제가 있습니다.

- **Performance Highlights**: 현재 연구는 이러한 문제들을 해결하기 위해 진행 중이며, 미래에는 병리학 FMs와 다른 의료 분야의 FMs를 통합하는 Generalist Medical AI의 개발이 예상됩니다. 이를 통해 정밀 의료 및 개인 맞춤형 의료를 촉진하고 실제 임상 환경에서 효과적으로 AI가 활용될 수 있을 것입니다.



### EUDA: An Efficient Unsupervised Domain Adaptation via Self-Supervised Vision Transformer (https://arxiv.org/abs/2407.21311)
Comments:
          12 pages, 4 figures

- **What's New**: 최근 비전 트랜스포머(ViTs)의 높은 성과에도 불구하고, 복잡성과 많은 수의 학습 가능 매개변수로 인해 실제 응용에서 제한이 있습니다. 이를 해결하기 위해 EUDA(Efficient Unsupervised Domain Adaptation) 프레임워크를 도입했습니다. EUDA는 자신-지도 비전 트랜스포머(self-supervised ViT)인 DINOv2를 특징 추출기로 사용하고, 단순한 완전 연결층을 통해 특징을 정제하여 도메인 적응을 강화합니다. SDAL(Synergistic Domain Alignment Loss)을 통해 CE(Cross-Entropy)와 MMD(Maximum Mean Discrepancy) 손실을 통합해 적응을 최적화합니다.

- **Technical Details**: EUDA는 DINOv2를 특징 추출기로 사용하며, 네트워크의 데이터 중심 특징을 단순한 완전 연결층을 통해 정제합니다. 또한 SDAL(Synergistic Domain Alignment Loss)은 CE(Cross-Entropy)와 MMD(Maximum Mean Discrepancy) 손실을 결합하여 소스 도메인의 분류 오류를 최소화하면서 소스 및 타겟 도메인 분포를 정렬합니다. 이는 혼합된 손실 함수로 소스 도메인에서 분류 오류를 최소화하고 도메인 간 분포를 정렬하려는 목적을 갖습니다.

- **Performance Highlights**: EUDA는 기존 최첨단 방법들과 비교하여 42%에서 99.7% 적은 학습 가능 매개변수를 사용하면서 유사한 성능을 보여주었습니다. 이는 제한된 리소스 환경에서 모델을 훈련하는 데 효과적임을 입증합니다.



### Enhanced Self-Checkout System for Retail Based on Improved YOLOv10 (https://arxiv.org/abs/2407.21308)
- **What's New**: 이 연구는 YOLOv10 네트워크를 개선하여 소매 자동화를 위한 혁신적인 셀프 체크아웃 시스템을 제안합니다. YOLOv8의 검출 헤드 구조를 포함시키는 등 타겟화된 최적화를 통해 제품 인식 정확도를 크게 향상시켰습니다. 또한, 셀프 체크아웃 시나리오에 맞춘 후처리 알고리즘을 개발하여 시스템의 실제 적용 능력을 높였습니다.

- **Technical Details**: 본 연구에서는 YOLOv8과 YOLOv10을 결합하여 MidState-YOLO 네트워크를 개발했습니다. 전통적인 C2f 모델을 Dual Convolutional kernels(DualConv)을 사용하여 수정하고 C2f_듀얼모듈(C2f_Dualmodule)로 대체했습니다. Spatial Pyramid Pooling layer(SPPF) 전에 Efficient Multi-Scale Attention 모듈을 통합하여 소매 제품을 정확하게 위치 추적 및 인식할 수 있게 했습니다. 최종적으로 개발한 모델은 MidState-YOLO-ED 네트워크입니다.

- **Performance Highlights**: 실험 결과, 제안된 개선 전략이 모델의 제품 인식 정확도를 크게 향상시키고, 매개변수와 계산 부하를 관리 가능한 범위 내에서 유지하면서도 기존의 방법들보다 뛰어난 성능을 보임을 확인했습니다. 본 시스템은 제품 인식 정확도와 체크아웃 속도에서 현존하는 방법들보다 우수한 성능을 제공합니다.



### SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving (https://arxiv.org/abs/2407.21293)
Comments:
          16 pages, 3 figures

- **What's New**: 새로운 대형 언어 모델(Large Language Models, LLMs)의 빠른 발전은 다양한 분야에 큰 혜택을 줄 수 있습니다. 특히, 완전 자동 운전(end-to-end autonomous driving, e2eAD) 분야는 LLMs가 더 많은 모달리티를 지원하면서 새로운 기회를 맞이하고 있습니다. 이에 따라 저자들은 SimpleLLM4AD라 불리는 새로운 e2eAD 방법을 제안했습니다.

- **Technical Details**: SimpleLLM4AD는 비전-언어 모델(vision-language model, VLM)을 활용하여 e2eAD 태스크를 인식(perception), 예측(prediction), 계획(planning), 행동(behavior)이라는 네 단계로 나눕니다. 각 단계는 시각적 질문 응답(visusal question answering, VQA) 쌍으로 구성되며, 이러한 VQA 쌍들은 Graph VQA(GVQA)라는 그래프로 서로 연결됩니다. 비전 트랜스포머(vision transformers, ViT) 모델은 nuScenes 시각 데이터를 처리하기 위해 사용되며, VLM은 시각적 입력으로부터 추출된 정보를 해석하고 추론하는 데 활용됩니다.

- **Performance Highlights**: 저자들의 실험 결과, SimpleLLM4AD는 복잡한 주행 시나리오에서 경쟁력 있는 성능을 보여주었습니다. 네 단계의 구조를 통해 VQA 쌍을 체계적으로 추론할 수 있어 정보와 결정의 일관성을 유지합니다. 특히, VLM 통합은 시스템이 문맥을 이해한 결정을 내릴 수 있게 해주어 신뢰성과 안전성을 크게 향상시킵니다.



### Fine-grained Metrics for Point Cloud Semantic Segmentation (https://arxiv.org/abs/2407.21289)
Comments:
          PRCV 2024

- **What's New**: 이 논문에서는 점 클라우드(semantic segmentation) 데이터셋에서 관찰되는 두 가지 불균형(카테고리 불균형 및 크기 불균형)을 해결하기 위해 더 상세한 mIoU 와 mAcc 평가 지표를 제안합니다. 이는 현재의 평가 지표가 주요 카테고리와 큰 객체에 대해 편향되어 있는 문제를 해결하고자 합니다.

- **Technical Details**: 새로운 평가 지표로 제안된 fine-grained mIoU와 mAcc는 점 클라우드 수준의 평가(metric)와 근사 객체(instance) 수준의 평가(metric)를 포함합니다. 이 새로운 지표는 Semantic3D, ScanNet, S3DIS와 같은 다양한 실내외 데이터셋에서의 알고리즘 평가에 사용되었습니다.

- **Performance Highlights**: 제안된 세밀한 mIoU 및 mAcc 지표는 기존의 평가 지표보다 풍부한 통계 정보를 제공하며, 큰 객체에 대한 편향을 줄여줍니다. 이는 점 클라우드 분할 알고리즘의 더 견고하고 종합적인 비교를 가능하게 합니다.



### Robust Box Prompt based SAM for Medical Image Segmentation (https://arxiv.org/abs/2407.21284)
Comments:
          Accepted by MICCAI MLMI 2024

- **What's New**: 새로운 연구에서는 Segment Anything Model(SAM)의 세분화 성능을 다양한 품질의 프롬프트(프롬프트)가 있을 때에도 향상시키기 위해 RoBox-SAM을 제안했다. 이는 임상 환경에서 발생할 수 있는 저품질 프롬프트의 문제를 해결하기 위한 것이다.

- **Technical Details**: RoBox-SAM은 세 가지 주요 기여를 한다. 첫 번째로, 프롬프트 정제 모듈(PRM)을 통해 잠재적인 타겟을 인지하고 저품질 박스 프롬프트를 고품질의 프롬프트로 변환하는 오프셋을 예측한다. 두 번째로, 프롬프트 향상 모듈(PEM)은 노이즈 있는 프롬프트와 최적화된 프롬프트 간의 이동 정보를 사용하여 자동으로 포인트 프롬프트를 생성한다. 마지막으로, 자기 정보 추출기(SIE)를 통해 입력 이미지에서 선행 정보를 추출하여 이미지 임베딩 및 주의 계산을 최적화한다. 이 기능들은 SAM의 이미지 임베딩과 주의 계산을 최적화함으로써, 프롬프트 품질에 관계없이 SAM의 강건성을 향상시킨다.

- **Performance Highlights**: 의료 세분화 데이터셋(총 99,299장 이미지, 5개 모달리티, 25개 장기/타겟)에서 광범위한 실험을 통해 RoBox-SAM의 효과가 입증되었다. RoBox-SAM은 다양한 품질의 박스 프롬프트에 대해서도 강건하며, 다양한 의료 이미징 모달리티와 타겟에 대해 뛰어난 성능을 달성한다.



### Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-N (https://arxiv.org/abs/2407.21273)
Comments:
          Accepted for the 5th International Workshop of Advances in Simplifying Medical UltraSound (ASMUS), held in conjunction with MICCAI 2024, the 27th International Conference on Medical Image Computing and Computer Assisted Intervention

- **What's New**: 새로운 MSU-Net 모델을 도입하여 초음파 이미지 분할에서 정확성과 불확실성 평가를 크게 향상시켰습니다. 이 모델은 Monte Carlo U-Net보다 18.1% 더 나은 성능을 보였으며, 특히 비전문가를 지원하는 데 유용합니다.

- **Technical Details**: MSU-Net은 여러 U-Net을 앙상블 (ensemble)로 훈련하는 다단계 접근법을 채택합니다. 이 모델은 디코더부분에 드롭아웃 (dropout)을 도입하여 Monte Carlo 샘플링을 통해 베이지안 추론을 근사합니다. 여러 개의 모델을 과잉생산하고 탈상관 (decorrelation)을 기반으로 최종 앙상블을 구성합니다.

- **Performance Highlights**: 초음파 이미지 세분화 (segmentation)에서 MSU-Net은 단일 Monte Carlo U-Net에 비해 18.1% 향상된 성능을 보였습니다. 이는 모델의 투명성과 신뢰성을 높이며, 안전한 주삽입을 지원합니다.



### DDU-Net: A Domain Decomposition-based CNN for High-Resolution Image Segmentation on Multiple GPUs (https://arxiv.org/abs/2407.21266)
- **What's New**: DDU-Net이라는 새로운 U-Net 기반 도메인 분할(domain decomposition) 아키텍처가 제안되었습니다. 이 아키텍처는 초고해상도 이미지(segmentation)에 효율적으로 처리될 수 있도록 입력 이미지를 비중첩 패치(non-overlapping patches)로 나누어 독립적으로 처리합니다. 또한, 패치 간의 상호 정보 교환을 위해 통신 네트워크를 추가하여 공간적 맥락 이해를 향상시킵니다.

- **Technical Details**: 본 연구는 U-Net 아키텍처를 기반으로 도메인 분할 기법을 통합한 모델을 제안합니다. 이 방법은 기존의 네트워크가 초고해상도 이미지를 처리하는 데 필요한 높은 메모리 요구를 해결하기 위해 설계되었습니다. 특히, 입력 이미지를 16x16의 비중첩 패치로 분할하고, 이러한 패치 간의 상호 정보 교환을 촉진하기 위해 통신 네트워크를 도입합니다.

- **Performance Highlights**: 제안된 DDU-Net 모델은 합성 데이터셋과 DeepGlobe land cover classification 데이터셋에서 실험적으로 검증되었습니다. 패치 간의 상호 정보 교환을 포함한 모델은 그렇지 않은 모델에 비해 IoU(intersection over union) 점수가 2-3% 향상된 결과를 보였습니다. 또한, 제안된 접근 방식은 전체 이미지를 대상으로 훈련된 기본 U-Net 모델과 동등한 성능을 보였습니다.



### Leveraging Adaptive Implicit Representation Mapping for Ultra High-Resolution Image Segmentation (https://arxiv.org/abs/2407.21256)
- **What's New**: 새로운 연구는 초고해상도 이미지 분할(refinement)을 위한 새로운 방법인 Adaptive Implicit Representation Mapping(AIRM)을 제안합니다. 이는 기존의 CNN 기반 인코더와 공유 암묵적 표현 변환 기능(Shared Implicit Representation Mapping Function, SIRMF)의 한계를 극복하기 위한 것입니다.

- **Technical Details**: 이 연구는 두 가지 주요 컴포넌트로 구성됩니다: (1) Affinity Empowered Encoder(AEE)는 Transformer 아키텍처와 세만틱 유사도를 활용해 장거리 피처를 효과적으로 모델링하는 강력한 피처 추출기입니다. (2) Adaptive Implicit Representation Mapping Function(AIRMF)은 전체 피처를 바탕으로 별도의 네트워크에서 파라미터를 예측하여 픽셀 단위 피처를 적응적으로 변환합니다. 이로 인해 글로벌 세만틱 정보가 포함된 유연하고 정확한 피처 변환이 가능합니다.

- **Performance Highlights**: BIG와 PASCAL VOC 2012와 같은 초고해상도 분할 개선 데이터셋에서의 광범위한 실험 결과, 제안된 방법이 경쟁자를 큰 차이로 능가하는 성능을 보여주었습니다.



### Lifelong Person Search (https://arxiv.org/abs/2407.21252)
Comments:
          10 pages, 6 figure

- **What's New**: 이번 논문에서는 기존의 단일 목표 데이터셋에만 적용되는 사람 검색(Person Search) 방법의 한계를 넘어, 새로운 문제로서 'Lifelong Person Search (LPS)'를 처음 소개했습니다. LPS는 새로운 데이터셋을 점진적으로 학습하면서도 이전 데이터셋에서 학습한 지식을 잃지 않고 유지하는 문제를 다루고 있습니다.

- **Technical Details**: 이 논문은 사람 검색(TF: Person Search)에서 발생하는 'Catastrophic forgetting' 문제를 해결하기 위해 새로운 방식의 종합적인 LPS 프레임워크를 제안합니다. 이 프레임워크는 구체적으로 다음 기술 요소를 포함합니다:
1. **Knowledge distillation**: 프로토타입 피쳐와 하드 백그라운드 제안을 활용해, 이전 모델과 새로운 모델 간의 일관성을 확보합니다.
2. **Rehearsal-based instance matching**: 라벨이 없는 사람 인스턴스를 부가적으로 사용해, 이전 도메인에서의 식별 능력을 늘립니다.
3. **End-to-end learning**: 사람 탐지와 재식별을 통합해 효율성을 극대화합니다.

- **Performance Highlights**: 제안된 방법은 LPS 시나리오에서 기존 방법들에 비해 월등히 높은 성능을 보였습니다. 실험 결과, 제안된 방법이 사람 탐지와 재식별 모두에서 이전 도메인에 대한 지식을 더 잘 유지함을 확인했습니다.



### Advancing Vietnamese Visual Question Answering with Transformer and Convolutional Integration (https://arxiv.org/abs/2407.21229)
Comments:
          Accepted at the journal of Computers & Electrical Engineering (Received 8 March 2024, Revised 8 June 2024, Accepted 10 July 2024)

- **What's New**: 이번 연구에서는 베트남어 비주얼 질문 응답(Vietnamese Visual Question Answering, ViVQA) 데이터셋에 대한 종합적인 실험을 통해 우리 모델의 효과를 입증하고자 했습니다. 특히 이미지 표현 역량을 강화하고, ViVQA 시스템의 전반적인 성능을 개선하는 모델을 개발했습니다.

- **Technical Details**: 우리 모델은 BLIP-2과 EfficientNet을 결합하여 이미지를 처리하고 지역 및 글로벌 특징들을 추출합니다. 이를 통해 트랜스포머 기반 아키텍처(Transformer-based architectures)의 강점을 활용해 포괄적인 맥락 정보를 포착하고, 컨볼루션 신경망(CNN)을 통해 세부적인 지역 특징을 포착합니다. 이러한 모델의 파라미터는 고정(frozen) 상태로 둬서 계산 비용과 학습 시간을 줄이면서도 높은 성능을 유지할 수 있습니다. 정보 융합을 위해 BEiT-3을 기반으로 한 멀티모달 융합 모듈(multi-modal fusion module)을 사용합니다.

- **Performance Highlights**: 우리 모델은 ViVQA 데이터셋의 테스트 세트에서 71.04%의 정확도를 기록하여 경쟁 모델들을 능가하며, 이 분야에서의 연구에 중요한 진전을 가져왔습니다.



### AI Safety in Practice: Enhancing Adversarial Robustness in Multimodal Image Captioning (https://arxiv.org/abs/2407.21174)
Comments:
          Accepted into KDD 2024 workshop on Ethical AI

- **What's New**: 이 논문은 시각적 및 텍스트 데이터를 결합한 멀티모달 이미지 캡셔닝 모델(multimodal image captioning models)의 공격 저항성을 강화할 효과적인 전략을 제시합니다. FGSM(Fast Gradient Sign Method)를 이용해 적대적 예제(adversarial examples)를 생성하고 적대적 훈련(adversarial training) 기법을 적용해 두 개의 벤치마크 데이터셋인 Flickr8k와 COCO에서 모델의 저항성을 향상시켰음을 입증합니다. 특히, 멀티모달 아키텍처의 텍스트 디코더(text decoder)만 선택적으로 훈련하는 접근법이 계산 효율성을 높이면서도 전제 훈련과 유사한 성능을 보여줍니다.

- **Technical Details**: 이 연구는 이미지 캡셔닝 작업을 위해 GPT-2와 Vision Transformer(ViT) 모델을 결합하는 아키텍처를 사용합니다. ViT는 이미지를 작은 패치로 나누어 이를 평평하게 하고 선형적으로 투영하여 변환합니다. ViT의 [CLS] 토큰이 이미지의 전체적인 맥락적 측면을 캡처한 후 GPT-2 디코더가 이를 이용해 캡션을 생성합니다. FGSM을 활용해 적대적 예제를 생성하고, 모델 파라미터에 대한 손실 함수의 그래디언트를 사용해 작은 교란을 추가하는 방식으로 적대적 예제를 만듭니다.

- **Performance Highlights**: Flickr8k와 COCO 데이터셋에서 실험한 결과, 텍스트 디코더만을 훈련해도 전체 모델을 훈련했을 때와 유사한 성능을 보였습니다. 반대로, 텍스트 디코더를 고정하고 이미지 인코더만 훈련할 경우 성능이 크게 저하되었습니다. 이는 텍스트 디코더가 공격 저항성을 높이는 데 중요한 역할을 한다는 것을 시사합니다.



### PLANesT-3D: A new annotated dataset for segmentation of 3D plant point clouds (https://arxiv.org/abs/2407.21150)
- **What's New**: 이번 논문에서는 새로운 3D 컬러 포인트 클라우드(Color Point Cloud) 데이터셋, PLANesT-3D를 소개합니다. 이 데이터셋은 Capsicum annuum (고추), Rosa kordana (장미), Ribes rubrum (구즈베리) 등 세 가지 식물 종의 34개의 실제 식물 모델로 구성되어 있습니다. PLANesT-3D 데이터셋은 '잎'과 '줄기'에 대한 의미론적 레이블과 기관 인스턴스 레이블을 포함하고 있습니다. 또한, 새로운 의미론적 세그멘테이션(Semantic Segmentation) 기법인 SP-LSCnet를 제안하고 이를 평가했습니다.

- **Technical Details**: PLANesT-3D 데이터셋은 DSLR 카메라(예: Canon EOS 6D)의 2D 컬러 이미지로부터 구조-모션(Structure from Motion, SfM)과 멀티뷰 스테레오(MVS)를 사용하여 3D 포인트 클라우드로 재구성되었습니다. 새로운 세그멘테이션 기법인 SP-LSCnet는 무감독 클러스터링(Unsupervised Clustering) 방식인 t-SNE를 기반으로 한 클러스터링 방법과 포인트 클라우드 분류 신경망을 결합한 시스템입니다. 이 기법은 국부 지역 조직 조정을 위한 두 가지 적응 모듈을 포함하여 기능 추출을 수행합니다. 또한, 기존의 신경망 아키텍처인 PointNet++와 RoseSegNet의 성능을 PLANesT-3D 데이터셋에서 평가했습니다.

- **Performance Highlights**: SP-LSCnet은 PLANesT-3D 데이터셋에서 탁월한 성능을 발휘했으며, 특히 RoseSegNet는 하이퍼파라미터 재조정 없이도 높은 효율을 입증했습니다. 이러한 성과는 PLANesT-3D 데이터셋이 3D 식물 모델의 자동 해석을 위한 기계 학습 알고리즘의 훈련 및 평가에 중요한 기여를 했음을 보여줍니다.



### Adding Multi-modal Controls to Whole-body Human Motion Generation (https://arxiv.org/abs/2407.21136)
- **What's New**: ControlMM은 텍스트, 음성, 음악 같은 다중 모달리티를 통해 전신 모션 생성을 제어하는 통합 프레임워크입니다. ControlMM-Attn을 통해 정적 및 동적 인간 토폴로지 구조를 병렬로 모델링하여 서로 다른 모션 분포 간의 모션 지식을 효과적으로 학습하고 전송합니다. 이 프레임워크는 설치 형태로 제공되며, 사용자는 다양한 조건에 맞추어 모션 생성을 관리할 수 있습니다.

- **Technical Details**: ControlMM은 2단계의 코스-투-파인(coarse-to-fine) 학습 전략을 사용합니다. 첫 번째 단계에서는 텍스트를 기반으로 한 의미적 모션 생성 능력을 학습하고, 두 번째 단계에서 제어 브랜치를 추가하여 고정된 백본에서 파인-그레인(fine-grain) 제어를 통해 조건을 맞춤화할 수 있도록 합니다. 특정 조건 없이 혼합 훈련으로 인한 최적화 혼란을 피할 수 있습니다. 또한, 단일 모션 표현인 SMPL-X 형식을 기반으로 한 첫 번째 공개 다중 모달 전신 인간 모션 생성 벤치마크인 ControlMM-Bench를 도입하였습니다.

- **Performance Highlights**: ControlMM은 텍스트-모션 변환(Text-to-Motion), 음성-제스처 변환(Speech-to-Gesture), 음악-댄스 변환(Music-to-Dance) 등 다양한 표준 모션 생성 작업에서 state-of-the-art 성능을 달성했습니다. 실험 결과, ControlMM은 다양한 기준선을 상회하는 성능을 보였으며, 모델 설계, 학습 전략, 확장 효과에 대한 가치 있는 인사이트를 제공했습니다.



### Self-supervised Multi-future Occupancy Forecasting for Autonomous Driving (https://arxiv.org/abs/2407.21126)
- **What's New**: 자율주행 차량(AV: Autonomous Vehicles)의 안전한 내비게이션을 위해 환경 예측 프레임워크가 중요합니다. 새로운 프레임워크는 LiDAR로 생성된 점유 격자 지도(L-OGM: LiDAR-generated Occupancy Grid Maps)를 사용하여 자율 학습 기반으로 장면 예측이 가능하게 하며, 부분적인 관찰 가능성과 인식 감지 오류에 대해 강력함을 제공합니다. 기존 접근법은 격자 셀 공간에서 결정론적(L-deterministic) L-OGM 예측 아키텍처에 중점을 두었으나, 본 연구는 확률적(stochastic) L-OGM 예측을 생성 모델(generative architecture)의 잠재 공간(latent space)에서 수행하여 이를 개선합니다.

- **Technical Details**: 본 연구의 프레임워크는 RGB 카메라, 지도, 계획된 궤적 주변환경 정보들을 조건으로 사용하는 장면 예측을 수행합니다. 두 가지 디코딩 방식을 제안하였는데, 실시간 고품질 예측을 위한 단일 스텝 디코더(single-step decoder)와 시간적 일관성 문제를 해결하고 압축 손실을 줄이기 위해 추가적인 프레임 정제를 수행하는 확산 기반 배치 디코더(diffusion-based batch decoder)가 있습니다.

- **Performance Highlights**: nuScenes와 Waymo Open 데이터셋을 사용한 실험 결과, 본 연구의 모든 변형 프레임워크는 기존 방법보다 높은 질적 및 양적 성능을 보였습니다.



### PAV: Personalized Head Avatar from Unstructured Video Collection (https://arxiv.org/abs/2407.21047)
Comments:
          Accepted to ECCV24. Project page: this https URL

- **What's New**: 새로운 연구로 PAV(Personalized Head Avatar) 모델이 제안되었습니다. PAV는 monocular talking face 비디오를 사용하여 다양한 외형 및 형상 변화에서도 인물의 얼굴을 재현할 수 있는 동적 변형 가능한 Neural Radiance Fields(NeRF)를 학습합니다. 이는 기존의 NeRF 방법들이 개별 외형을 모델링하는 데 한정된 것과 달리, 다중 외형 NeRF를 학습할 수 있게 합니다.

- **Technical Details**: PAV는 스케일과 밀도를 예측하는 appearance-conditioned density 변형을 도입해 인물의 형상 변화, 예를 들어 얼굴 털이나 연조직을 동적으로 모델링합니다. 여러 비디오 클립의 외형을 조합해 하나의 통일된 네트워크로 학습합니다. 각 비디오에 대해 학습 가능한 잠재 뉴럴 특징을 사용하고, 이는 재현 방식에 appearance embedding을 통해 반영됩니다.

- **Performance Highlights**: PAV는 다양한 연구에서 기존 방법들과 비교해 더 높은 화질의 시각적 렌더링을 보여줍니다. 다양한 인물 비디오 데이터를 사용하여 성능을 평가한 결과, PAV는 소수의 관찰로도 고품질의 3D 재구성을 가능하게 했습니다.



### Direct Unlearning Optimization for Robust and Safe Text-to-Image Models (https://arxiv.org/abs/2407.21035)
Comments:
          Extended abstract accepted in GenLaw 2024 workshop @ ICML2024

- **What's New**: 최근 텍스트-이미지 변환(T2I) 모델의 발전은 대규모 데이터셋 덕분에 큰 혜택을 받았지만, 이는 부적절한 콘텐츠 생성을 초래할 수 있는 잠재적 위험을 동반합니다. 이를 해결하기 위해 연구자들은 부적절한 콘텐츠를 생성할 수 있는 능력을 제거하는 'unlearning' 기술을 개발했습니다. 그러나 이러한 기술은 공격에 취약해 신뢰성 문제를 안고 있습니다. 이 논문에서는 새로운 'Direct Unlearning Optimization (DUO)' 프레임워크를 제안하여 T2I 모델에서 NSFW 콘텐츠를 제거하면서도 관련 없는 주제에 대한 성능을 유지합니다.

- **Technical Details**: DUO는 'preference optimization' 접근법을 사용하여 제어된 쌍 이미지 데이터를 활용해 모델이 부적절한 시각적 개념을 제거하도록 학습합니다. 또한, 'output-preserving regularization' 용어를 도입해 안전한 콘텐츠 생성 능력을 유지합니다. DUO는 unsafe 콘셉트를 가진 이미지와 그에 대응하는 안전한 이미지를 생성하여 모델이 후자의 이미지를 선호하도록 학습합니다. 이를 위해 'Direct Preference Optimization (DPO)' 기법을 사용합니다.

- **Performance Highlights**: 광범위한 실험 결과, DUO는 FID와 CLIP 점수로 측정된 바와 같이, 다양한 최첨단 'red teaming' 방법에 견고하게 방어할 수 있으며, 관련 없는 주제에 대한 성능 저하 없이 안전하게 작동합니다. 평가에서는 LPIPS, FID, CLIP 점수를 통해 실험을 수행했습니다.



### Safeguard Text-to-Image Diffusion Models with Human Feedback Inversion (https://arxiv.org/abs/2407.21032)
Comments:
          ECCV 2024. 56 pages, 24 figures. Caution: This paper contains discussions and examples related to harmful content, including text and images. Reader discretion is advised. Code is available at this https URL

- **What's New**: 이 논문에서는 잠재적으로 유해하거나 저작권이 있는 콘텐츠를 생성할 수 있는 대규모 텍스트-이미지 변환 모델의 사회적 문제를 다룹니다. 인간 피드백을 활용한 새로운 프레임워크인 Human Feedback Inversion(HFI)를 제안하여, 모델이 생성한 이미지에 대한 문제점을 텍스트 토큰으로 압축하여 제거 및 완화합니다.

- **Technical Details**: 기존 모델은 인터넷에서 수집된 데이터에 의존해 왔으며, 필터링 과정에서 문제 있는 개념들이 남아있어 문제가 생깁니다. HFI는 모델이 생성한 이미지에 대한 인간의 피드백을 활용하여 텍스트 토큰으로 변환하고, 이러한 토큰을 통해 문제 이미지를 제거하거나 완화합니다. 또한 Self-Distillation 기반의 Safe self-Distillation Diffusion(SDD) 기법을 도입하여 훈련 목적을 단순화하고, 인간의 판단 기준에 더욱 잘 맞춥니다.

- **Performance Highlights**: 실험 결과 HFI 프레임워크는 문제 있는 콘텐츠의 생성을 획기적으로 줄이면서도 이미지 품질을 유지하는 것으로 나타났습니다. 예를 들어, Van Gogh의 예술 스타일을 제거하려는 과제에서, 인간 피드백을 기반으로 필수적인 그림 스타일은 유지하면서 그의 특징적인 붓질만 제거하였습니다. 또, 나체 이미지 제거 과제에서는, HFI가 포르노그래픽 콘텐츠를 성공적으로 제거한 반면, 기존 방법은 도발적인 이미지를 여전히 생성하였습니다. 이를 통해 HFI와 SDD의 조합이 다양한 프롬프트에서 안전하고 적절한 이미지 출력을 일관되게 제공함을 확인하였습니다.



### Success Probability in Multi-View Imaging (https://arxiv.org/abs/2407.21027)
- **What's New**: 이 논문은 다중 뷰 이미징(Multi-view imaging) 시스템에서 성공 확률을 분석하는 새로운 프레임워크를 제안합니다. 이는 특히 임의성(Noise) 때문에 카메라의 시야각(Field of View; FOV)이 충분히 겹치지 않을 가능성이 있는 경우에 중요합니다. 이 프레임워크는 자기 보정(self-calibration)이 가능하도록 시야각 중복과 시각적 유사성이 충분한 경우 이를 완화할 수 있음을 나타냅니다. 사례 연구로 나노위성의 3D 구름 재구성을 고려합니다.

- **Technical Details**: 다중 뷰 이미징 시스템은 로봇, 보안 카메라, 드론, 위성 등의 플랫폼에서 사용됩니다. 성공적인 3D 복구는 모든 카메라의 시야각(FOV)이 충분히 겹쳐질 때 가능하지만, 기계 시스템의 불확실성(Noise)으로 인해 겹치는 시야각 확보는 확률적입니다. 이 논문은 시야각 중복성(Overlap)을 기반으로 카메라 포인팅의 잡음 모델(Noize Model)을 사용하여 자기 보정 확률을 유도합니다. 이는 나노위성 형성에서 지구 관측 미션의 제한 사항을 분석하는 데 적용됩니다.

- **Performance Highlights**: 논문에서 제안한 프레임워크는 자기 보정을 통해 포인팅 오류를 줄이고, 따라서 3D 재구성의 성공 확률을 높이는 데 도움이 됩니다. 또한, 다양한 지구 관측 미션에서 비용 효율성이 높은 작은 위성들의 형성에서 발생하는 독특한 도전 과제를 해결하는 데 유용한 도구를 제공합니다.



### The Llama 3 Herd of Models (https://arxiv.org/abs/2407.21783)
- **What's New**: 이번 논문은 새로운 파운데이션 모델(foundation model) 세트인 Llama 3를 소개합니다. Llama 3는 다국어 지원, 코딩, 추론, 도구 사용을 네이티브로 지원하는 다양한 언어 모델 군입니다. 최대 4050억 개의 매개변수(parameter)와 128K 토큰의 문맥 창(context window)을 가지는 밀집 트랜스포머(dense Transformer)를 포함하고 있습니다.

- **Technical Details**: Llama 3는 코드 작성, 다국어 처리, 추론 등의 다양한 작업을 수행할 수 있는 다기능 언어 모델 군입니다. 실험적으로 Llama 3는 GPT-4와 같은 선두 언어 모델과 유사한 품질을 제공하는 것으로 나타났습니다. 우리는 또한 미리 학습된(pre-trained) 및 후속 학습된(post-trained) 버전의 405B 매개변수 언어 모델과 입력 및 출력의 안전성을 보장하는 Llama Guard 3 모델을 공개했습니다. 이미지, 비디오, 음성 기능을 통합하기 위해 조합적 접근법(compositional approach)을 사용한 실험 결과도 제시합니다.

- **Performance Highlights**: Llama 3는 이미지 인식, 비디오 인식, 음성 인식 작업에서 최첨단(state-of-the-art) 성능과 경쟁할 수 있는 능력을 보여줍니다. 하지만, 이러한 통합된 모델들은 아직 개발 중이며, 광범위한 공개는 이루어지지 않았습니다.



### Contrastive Factor Analysis (https://arxiv.org/abs/2407.21740)
- **What's New**: 이 논문은 대조 학습(contrastive learning, CL)과 행렬 분해(matrix factorization, MF), 요인 분석(factor analysis, FA)의 수학적 동등성을 활용해 새로운 대조 요인 분석(Contrastive Factor Analysis, CFA) 프레임워크를 제안합니다. 특히, FA의 비음수 버전(non-negative extension)을 통해 해석 가능성을 높이고 복잡한 종속성을 모델링하는 능력을 증진합니다.

- **Technical Details**: CFA는 대조 학습 방법을 따라 관계 행렬(relation matrix)을 모델링하여 Gaussian 잠재 변수로 분해합니다. 또한, 비음수의 목표 행렬을 고려해 감마 잠재 변수로 분해하는 대조 비음수 요인 분석(contrastive non-negative FA)을 도입했습니다. 이를 위해 Gaussian 및 Weibull 변분 추론 네트워크를 개발하여 잠재 변수의 사후 분포를 근사합니다.

- **Performance Highlights**: 제안된 CFA와 비음수 확장은 더욱 표현력(expression), 외부 데이터 발생(out-of-distribution)에 대한 견고성, 해석 가능성 및 불확실성 평가 측면에서 뛰어난 성능을 보여줍니다. 실험 결과는 이러한 다양한 핵심 속성들에 대한 방법론의 효율성을 입증합니다.



### Leveraging Self-Supervised Learning for Fetal Cardiac Planes Classification using Ultrasound Scan Videos (https://arxiv.org/abs/2407.21738)
Comments:
          Simplifying Medical Ultrasound: 4th International Workshop, ASMUS 2023, Held in Conjunction with MICCAI 2023, Vancouver, BC, Canada, October 8, 2023, Proceedings

- **What's New**: 본 연구에서는 초음파(US) 비디오 데이터를 활용하여 별도의 라벨링 없이 연속 학습 방법(Self-supervised learning, 이하 SSL)을 적용하여 태아 심장 표준 평면(SFCP) 분류 성능을 향상시키고자 합니다. 특히, 제한된 라벨 데이터만을 사용하는 상황에서도 성능이 개선되는 것을 목표로 합니다. BarlowTwins 접근법이 가장 일관된 성능을 보여주었으며, ImageNet 초기화와 비교해 F1-스코어가 12% 향상되었습니다.

- **Technical Details**: 연구에서는 7가지 SSL 접근법을 비교했습니다. 재구성(Reconstruction), 대조 손실(Contrastive loss), 증류(Distillation), 정보 이론(Information theory) 기반 방법들이 포함되었습니다. 특히, 500개 이상의 다운스트림(downstream) 실험을 통해 다양한 설정에서의 성능을 평가하였고, 데이터셋의 변동성(variance)이 크기(size)보다 더 중요한 요소임을 확인했습니다. ResNet-50을 백본 네트워크로 사용하였고, 각 SSL 방법론에 맞는 적절한 네트워크 모듈을 추가로 사용했습니다.

- **Performance Highlights**: SSL 학습에서 데이터의 변동성이 크면 모델이 보다 일반화된 표현을 학습할 수 있어 다운스트림 태스크의 성능이 향상됩니다. 특히 BarlowTwins 방법이 다양한 설정과 데이터 변동성에도 견고한 성능을 보여주었습니다. 1%의 라벨 데이터를 사용한 전체 미세 조정(fine-tuning)에서 ImageNet 초기화를 사용한 경우보다 F1-스코어가 12% 상승하였으며, 다른 SSL 초기화 방법과 비교해 최소 4% 이상 성능이 개선되었습니다.



### MSA2Net: Multi-scale Adaptive Attention-guided Network for Medical Image Segmentation (https://arxiv.org/abs/2407.21640)
Comments:
          Accepted at BMVC 2025. Supplementary materials included at the end of the main paper (3 pages, 2 figures, 1 table)

- **What's New**: MSA2Net을 도입하여 의료 영상 세분화에서 새로운 딥 세분화 프레임워크를 소개했습니다. 이 프레임워크는 효율적인 설계의 스킵 연결(skip-connections)을 특징으로 하며, Multi-Scale Adaptive Spatial Attention Gate (MASAG)을 포함합니다. 이는 수용 영역(receptive field)을 동적으로 조정하여 공간적으로 관련된 특징을 선택적으로 강조하고 배경의 방해 요소를 최소화합니다.

- **Technical Details**: MSA2Net은 스킵 연결을 통해 coarse-grained 인코더 특징(feature)을 fine-grained 디코더 특징 맵과 결합하여 특징 융합을 용이하게 합니다. 또한 MASAG 모듈을 도입하여 공간적으로 중요한 특징을 다중 스케일에서 강조합니다. 디코더의 얕은 층에서는 Large Kernel Attention (LKA) 모듈을 사용하여 고해상도 이미지 처리 문제를 해결하고, 깊은 층에서는 Dual Attention Enhanced Transformer (DAE-Former) 블록을 사용하여 저해상도 이미지에서도 장거리 상호작용을 유지합니다.

- **Performance Highlights**: MSA2Net은 피부과(ISIC2018)와 방사선(Synapse) 데이터셋에서 광범위한 평가를 통해 SOTA(State-of-the-Art) 방법을 능가하거나 동등한 성능을 입증했습니다. 이 프레임워크는 다양한 지표(metric)에서 우수한 성능을 보였습니다.



### Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components (https://arxiv.org/abs/2407.21638)
Comments:
          Accepted to MICCAI UNSURE Workshop

- **What's New**: 최신 의료 영상 해석의 자동화는 진단 워크플로우의 병목 현상을 완화하는 데 중요하며, 특히 자연어 처리(NLP) 분야의 발전으로 큰 주목을 받고 있습니다. 이번 연구에서는 진단적 중요성의 의미론에 관한 AI 기반 방사선 보고서의 신뢰성을 평가하기 위해 모듈형 보조 감사 구성요소(auxiliary auditing components, AC)로 구성된 품질 관리 프레임워크를 제안합니다.

- **Technical Details**: 제안된 프레임워크는 MIMIC-CXR 데이터셋을 이용해 평가되었으며, ACs를 질병 분류기로 활용해 진단적 의미를 추출합니다. 보고서 생성 모델 GenX를 개발하여 이미지에 대한 텍스트 시퀀스를 생성하고, 보고서와 AC 레이블의 일관성을 평가해 품질을 검토합니다. GenX는 기존 연구들과 경쟁력 있는 성능을 보이며, 제작된 보고서는 ACs의 분류 신뢰도를 활용해 보다 엄격한 품질 검토를 시행합니다.

- **Performance Highlights**: MIMIC-CXR 데이터셋에서의 평가 결과, ACs을 포함한 보고서는 필터링되지 않은 보고서에 비해 더 높은 F1 점수를 기록했습니다. 이는 보고서와 보조 구성 요소 간의 일관성이 자동화된 보고서 생성의 유망한 감사 메커니즘임을 보여줍니다.



### Robust Simultaneous Multislice MRI Reconstruction Using Deep Generative Priors (https://arxiv.org/abs/2407.21600)
- **What's New**: 본 연구는 깊은 생성 모델 (deep generative models)을 활용한 Simultaneous multislice (SMS) MRI 재구성 방법을 제안합니다. Gaussian 노이즈에서 시작하여, 역확산 반복 (reverse diffusion iterations)을 통해 개별 슬라이스를 복구하면서 측정된 k-space 데이터 일관성(data consistency)을 유지합니다. 더불어, 저주파수 향상 (Low-Frequency Enhancement, LFE) 모듈을 통합하여 SMS-가속된 FSE 및 EPI 시퀀스에서 자율보정 신호(autocalibration signals)를 쉽게 통합할 수 없는 문제를 해결했습니다.

- **Technical Details**: 제안된 방법은 Denoising diffusion probabilistic models (DDPM)을 사용하여 MR 재구성 역문제를 푸는 방식입니다. DDPM을 단일 슬라이스 이미지로 훈련시킬 수 있도록 하여 특별한 조정 없이 SMS 작업에 적용 가능합니다. 저주파수 향상 모듈(LFE)은 자율보정 신호를 신뢰하기 어려운 상황에서 역확산 과정을 안정화 시킵니다. 또한, SMS MRI의 복잡성을 다루기 위해 읽기 결합(readout concatenation) 프레임워크를 활용하여 데이터를 재구성합니다.

- **Performance Highlights**: 제안된 방법은 다양한 데이터세트에서 기존 방법들보다 일관되게 더 나은 성능을 보였으며, 보지 못한 데이터셋에 대해서도 강력한 일반화 능력을 보여주었습니다. 이미지 SNR을 크게 개선하고, 잔여 에일리어징(residual aliasing) 아티팩트를 줄이며, 다양한 설정에서도 우수한 재구성 결과를 보였습니다. 코드 및 방법에 대한 세부 내용은 리뷰 완료 후 공개될 예정입니다.



### Expanding the Medical Decathlon dataset: segmentation of colon and colorectal cancer from computed tomography images (https://arxiv.org/abs/2407.21516)
Comments:
          8 pages, 2 figures, 2 tables

- **What's New**: 이 논문에서는 Medical Decathlon 데이터셋을 확장하여, 대장 및 대장암의 마크업(markup)을 추가해 의료 영상 처리 분야에서 실질적 문제를 해결하려는 시도를 했습니다. 주요 기여점은 경험 많은 방사선 전문의가 검증한 데이터를 품질에 따라 부분 집합으로 분류하고 이를 공개 도메인에 제공한 것입니다.

- **Technical Details**: 논문에서는 UNet 아키텍처(neural network models of the UNet architecture)를 활용하여 5-파트 교차 검증(5-part cross-validation)을 통해 모델을 훈련시켰습니다. 결과적으로 평균 Dice 지수(Dice metric quality) 0.6988 ± 0.3을 달성했습니다. 이런 노력은 초기 단계에서 대장암을 탐지하고 방사선 전문의가 병리학을 찾는 과정을 용이하게 하며, 진단 과정을 크게 가속화할 것입니다.

- **Performance Highlights**: 경험 많은 방사선 전문의가 검증한 데이터와 분류된 데이터 세트, 그리고 5-파트 교차 검증을 통해 UNet 모델이 0.6988 ± 0.3의 Dice 메트릭 품질을 달성했다는 점이 주요 성과입니다. 공개된 마크업은 대장암 감지의 품질을 개선하고 방사선 전문의의 연구 기술을 단순화하는 데 중요한 기여를 할 것입니다.



### Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation (https://arxiv.org/abs/2407.21490)
Comments:
          Accepted by MICCAI MLMI 2024

- **What's New**: 심초음파(Echocardiography) 비디오 생성을 위한 새로운 방법이 제안되었습니다. 이 방법은 초기 프레임과 운동 곡선(Motion curve)을 가이드로 사용하여 심초음파 비디오를 생성하게 됩니다. 기존 방법들이 전체적인 조건에 의존했다면, 이 방법은 각각의 심장 구조에 맞춘 운동 제어를 가능하게 합니다.

- **Technical Details**: 제안된 방법의 주요 기여점은 세 가지입니다. 첫째, 각 심장 하부구조로부터 운동 정보를 추출하여 운동 곡선을 구성합니다. 둘째, 이 운동 곡선을 시각적 정보에 맞추기 위해 구조-운동 정렬 모듈(Structure-to-Motion alignment)을 제안합니다. 셋째, 위치 인식 주의 메커니즘(Position-aware attention mechanism)을 설계하여 구조적 위치 정보를 가진 가우시안 마스크를 활용하여 비디오 일관성을 향상시킵니다. 이 모델은 SD (Stable Diffusion) VAE(Variational Auto-Encoder)를 사용하여 프레임을 잠재 특징으로 다운샘플링하고, 노이즈를 추가하고 제거하며 비디오를 생성합니다.

- **Performance Highlights**: 이번 연구에서 제안된 방법은 세 가지 심초음파 데이터셋에 대해 기존 방법들보다 높은 충실도와 일관성을 보였습니다. 또한, 사용자 정의 가능성을 제공하여 초기 프레임이나 운동 곡선을 조정함으로써 사용자 요구에 맞춘 비디오 생성이 가능합니다. 구체적으로, 좌심실(Left Ventricle), 좌심방(Left Atrium), 승모판(Mitral Valve) 등 주요 구조에 맞춘 세밀한 운동 제어가 가능하도록 설계되었습니다.



### Navigating Beyond Instructions: Vision-and-Language Navigation in Obstructed Environments (https://arxiv.org/abs/2407.21452)
Comments:
          Accepted to MM 2024

- **What's New**: R2R-UNO라는 새로운 데이터셋 및 작업이 소개되었습니다. 이는 기존 Vision-and-Language Navigation (VLN) 시스템에서 자주 발생하는 실시간 동적 장애 요소를 포함시켜, 실제 환경과 지침 간의 불일치를 반영합니다. 이를 통해 에이전트가 예상치 못한 장애물을 효과적으로 대응할 수 있습니다.

- **Technical Details**: R2R-UNO 데이터셋은 R2R 데이터셋의 내비게이션 그래프와 시각적 관측을 수정해 다양한 장애요소를 통합합니다. 또한, 텍스트-이미지 인페인팅(inpainting) 기술을 사용하여 다양한 물체를 원활하게 장면에 삽입하고, 필터링 모듈을 통해 고품질의 장애물을 선택할 수 있게 설계했습니다. 추가로, 새로운 방법인 ObVLN(Obstructed Vision-and-Language Navigation)을 제안하여 커리큘럼 학습 전략(curriculum training strategy)과 가상 그래프 구축 메커니즘을 도입했습니다.

- **Performance Highlights**: R2R-UNO 데이터셋을 사용한 실험 결과, 기존 최첨단 VLN 에이전트가 장애 환경에서 큰 어려움을 겪는 것으로 나타났습니다. 반면, ObVLN을 사용한 에이전트는 원래 환경에서도 강력한 성능을 유지하면서, 예상치 못한 장애물에도 효과적으로 적응해 67%의 성공률(Success Rate, SR)을 기록하며 상당한 성능 향상을 이뤘습니다. 이는 기존 데이터셋과의 비교에서 23%의 성능 향상을 의미합니다.



### Force Sensing Guided Artery-Vein Segmentation via Sequential Ultrasound Images (https://arxiv.org/abs/2407.21394)
- **What's New**: 이 연구는 초음파 이미지에서 동맥과 정맥을 더 정확히 구분하기 위해 고안된 새로운 힘 감지 기반 세분화 접근법을 소개합니다. 이 방법은 혈관의 변형성을 활용하여 동맥 및 정맥을 정확히 구별합니다. 이를 위해 연구팀은 초음파 이미지 시퀀스에서 가장 중요한 혈관 변형을 나타내는 주요 프레임을 식별하고, 이러한 프레임을 주의 메커니즘(Attention Mechanisms)과 결합하여 세분화 정확도를 높였습니다. 또한, 동맥 및 정맥의 초음파 이미지와 힘 데이터를 포함한 첫 번째 멀티모달 데이터셋 'Mus-V'를 제공할 예정입니다.

- **Technical Details**: 제안된 방법은 U-Net, Swin-unet, Transunet 등 다양한 세분화 네트워크와 통합될 수 있습니다. 연구팀은 초음파 탐침(US probe)에 장착된 힘 센서를 사용하여 실시간으로 힘 데이터를 수집하고, 가장 중요한 변형을 나타내는 주요 프레임을 식별합니다. 이러한 주요 프레임은 현재 프레임과 결합하여 혈관 변형 정보를 캡처하고 저장한 후, 주의 메커니즘을 통해 이를 통합합니다. 또한, 새로운 데이터셋 Mus-V는 총 3114개의 초음파 이미지와 이를 수집하는 동안 기록된 대응하는 힘 데이터로 구성되어 있습니다.

- **Performance Highlights**: 새로운 힘 감지 기반 세분화 접근법은 여러 U자형 네트워크에서 상당한 성능 향상을 보여주었습니다. 실험 결과는 이 방법이 다양한 세분화 네트워크에 적용될 수 있으며, 세분화 정확도를 크게 개선할 수 있음을 나타냅니다.



### Design and Development of Laughter Recognition System Based on Multimodal Fusion and Deep Learning (https://arxiv.org/abs/2407.21391)
Comments:
          7 pages,2 figures

- **What's New**: 이 연구는 멀티모달 융합(multi-modal fusion)과 딥러닝(deep learning)을 기반으로 웃음 인식 시스템을 설계하고 구현하는 것을 목표로 합니다. 이미지와 오디오 처리 기술을 활용해 정확한 웃음 인식과 감정 분석을 달성합니다.

- **Technical Details**: 시스템은 먼저 OpenCV 라이브러리를 사용해 비디오 파일에서 얼굴 정보를 추출하고, Librosa 라이브러리를 통해 MFCC와 같은 오디오 특징을 처리합니다. 이후 멀티모달 융합 기법을 사용해 이미지와 오디오 특징을 통합한 후, 딥러닝 모델을 사용해 학습 및 예측을 수행합니다.

- **Performance Highlights**: 평가 결과, 모델은 테스트 데이터셋에서 80%의 정확도(accuracy), 정밀도(precision), 재현율(recall)을 기록했으며, F1 점수는 80%로 강력한 성능을 입증했습니다. 시스템은 현실적인 데이터 변동성에도 잘 대응할 수 있는 능력을 보여줍니다.



### SmileyNet -- Towards the Prediction of the Lottery by Reading Tea Leaves with AI (https://arxiv.org/abs/2407.21385)
Comments:
          This is a satirical accumulation of misconceptions, mistakes, and flawed reasoning I have encountered in recent times as a reviewer and sometimes even as a reader of published papers. I hope it is entertaining and useful in the context of the education of BSc, MSc, and PhD students in Machine Learning, Artificial Intelligence, and Cognitive Science

- **What's New**: SmileyNet는 새로운 바이오-영감을 받은 신경망으로, 긍정적인 감정이 인지 과정을 향상시킬 수 있다는 사실에 기반하여 개발되었습니다. 이를 통해 신경망에 미소 이모티콘을 입력하여 긍정적인 감정을 유도하고, 이후 동전 던지기의 결과를 예측하는 데 사용합니다. 이 과정에서 SmileyNet은 무려 72%의 예측 정확도를 보이며, 그 성능은 ResNet-34(49%)나 YOLOv5(53%)보다 훨씬 뛰어납니다.

- **Technical Details**: SmileyNet은 네트워크를 긍정적인 감정 상태로 최적화하는 독특한 교육 방법을 사용합니다. 네트워크는 먼저 'U+1F642'(슬ightly Smiling Face) 이모티콘을 입력으로 받아들여 긍정적인 감정 상태로 편향됩니다. 이를 통해 네트워크가 스트레스 없는 환경에서 학습하도록 도와줍니다. 이러한 생체 영감 방법은 기존 신경망 𝒩o⁢l⁢d를 새로운 신경망 𝒩n⁢e⁢w으로 전환하여 더 나은 성능을 기대할 수 있습니다.

- **Performance Highlights**: SmileyNet은 동전 던지기 결과 예측에서 72%의 정확도를 기록하며 뛰어난 성능을 보였습니다. 이는 비교 대상으로 사용된 ResNet-34(49%)나 YOLOv5(53%)보다 월등히 높은 수치입니다. 이를 통해 SmileyNet이 단순히 랜덤 추측을 넘어서 예측 능력을 갖추고 있음을 확인할 수 있었습니다.



### Identity-Consistent Diffusion Network for Grading Knee Osteoarthritis Progression in Radiographic Imaging (https://arxiv.org/abs/2407.21381)
Comments:
          Accepted by ECCV 2024

- **What's New**: 이번 연구에서는 KOA(무릎 관절염)의 중증도와 진행 상태를 다각도로 예측하는 새로운 생성 모델인 Identity-Consistent Radiographic Diffusion Network (IC-RDN)를 제안합니다. 이 모델은 초기 X-ray 스캔을 기반으로 향후 무릎 X-ray 스캔을 예측하여 KOA의 진행 상태를 더 잘 설명하고 이해할 수 있도록 지원합니다.

- **Technical Details**: IC-RDN은 두 가지 주요 모듈로 구성됩니다: 첫째, 'identity prior module'은 확산 과정에서 환자의 정체성을 유지하며 임상적 세부사항에 중점을 둡니다. 둘째, 'generation-guided progression prediction module'은 예측된 향후 X-ray와 초기 X-ray를 활용하여 KOA의 중증도 진행 상태를 예측합니다. 대조 학습 전략을 사용하여 예측 모델의 정확성을 높였습니다.

- **Performance Highlights**: 광범위한 실험을 통해 제안된 IC-RDN의 효과가 입증되었습니다. OAI(공공 데이터셋)를 활용한 실험 결과, 이 방법이 KOA 중증도 예측의 정밀도를 크게 향상시켰음을 확인하였습니다. 특히 기존의 단순한 예측 모델과 비교하여 임상적 세부사항을 더 잘 반영하고, 설명 가능성이 높은 결과를 얻을 수 있었습니다.



### Dynamic Gesture Recognition in Ultra-Range Distance for Effective Human-Robot Interaction (https://arxiv.org/abs/2407.21374)
- **What's New**: 이번 논문은 Human-Robot Interaction (HRI)에서 초장거리 제스처 인식을 위한 새로운 접근법을 제시합니다. 이를 통해 서비스 로봇, 검색 및 구조 작업, 드론 기반 상호 작용에서 인간의 제스처를 장거리에서 인식하는 로봇의 능력을 향상시키는 Temporal-Spatiotemporal Fusion Network (TSFN) 모델을 제안합니다.

- **Technical Details**: TSFN 모델은 Temporal Convolutional Networks (TCN)을 통해 시간적 의존성을 포착하고 R(2+1)D convolutional networks를 통해 시공간적 특징을 추출합니다. 모델은 웹캠으로 수집된 다양한 시나리오를 포함한 데이터셋을 학습하며, 주어진 동영상 시퀀스와 제스처 집합을 함수로 매핑하여 제스처를 인식하도록 설계되었습니다. 주요 손실 함수는 cross-entropy loss와 global context loss를 포함하며, 거리에 따른 제스처 인식의 정확성을 유지하도록 distance-aware loss 및 robustness loss도 포함합니다.

- **Performance Highlights**: 실험 결과, 제안된 TSFN 모델은 28미터 거리에서 실시간으로 동작하며, 장거리 제스처 인식 정확도가 크게 향상되었습니다. 특히, 긴 제스처 시퀀스에서 두드러진 성능을 보여주었습니다.



### MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework (https://arxiv.org/abs/2407.21343)
Comments:
          Submitted to BraTS 2024

- **What's New**: 의료 영상 분할 연구에서 표준화된 도구의 부재로 인해 방법들의 비교가 어려운 문제를 해결하기 위해 Medical Imaging Segmentation Toolkit (MIST)가 도입되었습니다. MIST는 간단하고 모듈화된 엔드투엔드 의료 영상 분할 프레임워크로, 일관된 데이터 분석, 전처리, 평가 파이프라인을 제공하여 재현 가능하고 공정한 비교를 가능하게 합니다. BraTS Adult Glioma Post-Treatment Challenge 데이터셋을 사용하여 MIST의 효용성이 입증되었습니다.

- **Technical Details**: MIST는 표준 데이터 형식 요구사항, 파이프라인, 보조 기능을 포함합니다. 데이터 분석 파이프라인은 데이터 셋의 크롭핑, 타겟 스페이싱, 패치 크기 선택, 정규화 매개변수 등을 포함합니다. 전처리 파이프라인은 이미지의 전경 마스크에 따라 크롭하고, 오른쪽-앞-아래 방향으로 재정렬하며, 목표 스페이싱으로 리샘플링하고, 강도 값을 윈도우 및 정규화합니다. 또한 거리 변환 맵(DTM)을 계산하거나 MR 이미지의 바이어스 보정을 할 수 있습니다.

- **Performance Highlights**: BraTS Adult Glioma Post-Treatment Challenge 데이터셋을 사용하여 수행한 테스트에서 MIST는 정확한 분할 마스크를 생성하고 다중 GPU에서 확장 가능함을 보여주었습니다. 이는 MIST가 미래의 의료 영상 연구 및 개발에 강력한 도구로서의 잠재력을 가진다는 것을 강조합니다.



### Knowledge-Guided Prompt Learning for Lifespan Brain MR Image Segmentation (https://arxiv.org/abs/2407.21328)
- **What's New**: 자동 뇌 MRI 분할 기술 향상을 위한 KGPL(Knowledge-Guided Prompt Learning) 프레임워크를 소개합니다. 이 접근법은 대규모 데이터셋에서의 사전 훈련과 지식 기반 임베딩을 통합하여 다양한 연령대의 뇌 구조를 정확하게 분할합니다.

- **Technical Details**: 제안된 방법은 두 단계로 이루어집니다. 첫 번째 단계에서는 대규모 데이터셋을 사용하여 최적화되지 않은 레이블로 모델을 사전 훈련하고, 두 번째 단계에서는 이미지-텍스트 정렬을 통해 학습된 지식 구동 임베딩을 모델에 통합합니다. 이러한 지식 기반 프롬프트는 해부학적 변동성과 생물학적 과정을 캡처하여 다양한 연령 그룹에서 구조적 특징 임베딩을 학습할 수 있게 합니다. Swin UNETR 모델을 주요 백본으로 활용하여 뛰어난 성능을 입증했습니다.

- **Performance Highlights**: 제안된 KGPL 방법은 뇌 조직과 구조 분할에서 평균 DSC 값이 각각 95.17%와 94.19%를 달성하며, 기존의 최신 기법들(SOTA)보다 우수하고 견고한 성능을 보여주었습니다.



### STANet: A Novel Spatio-Temporal Aggregation Network for Depression Classification with Small and Unbalanced FMRI Data (https://arxiv.org/abs/2407.21323)
- **What's New**: 우울증 진단의 정확성을 높이기 위해 Spatio-Temporal Aggregation Network(STANet) 모델을 제안했습니다. 이 모델은 뇌 활동의 시공간적 특징을 포착하기 위해 CNN과 RNN을 통합하여 우울증 진단을 향상시킵니다.

- **Technical Details**: STANet은 다음과 같은 단계로 구성됩니다: (1) 독립 성분 분석(ICA)를 통해 시공간 정보를 집계, (2) 다중 규모의 딥 컨볼루션(deep convolution)을 사용해 세부 특징을 포착, (3) 소수 클래스(new samples)를 생성하기 위해 SMOTE(Synthetic Minority Over-sampling Technique)로 데이터 균형을 맞춤, (4) AFGRU 분류기를 이용하여 푸리에 변환(Fourier transformation)과 GRU(Gated Recurrent Unit)를 결합하여 장기 종속성을 포착하고 모델의 일반화를 향상시킵니다.

- **Performance Highlights**: 실험 결과, STANet은 82.38%의 정확도와 90.72%의 AUC를 달성했습니다. STFA 모듈(StFA module)은 다중 규모에서 더 깊은 특징을 포착하여 분류 성능을 향상시켰고, AFGRU 분류기는 적응 가중치(adaptive weights) 및 스택된 GRU로 더 높은 정확도와 AUC를 기록했습니다. 또한, SMOTE는 다른 샘플링 방법보다 뛰어났으며, 시공간 집계 특징은 단순한 시간적 또는 공간적 특징만 사용하는 것보다 더 나은 성능을 보였습니다. STANet은 전통적인 또는 딥 러닝 기반의 분류기와 기능적 연결성 기반의 분류기를 제치고 10회 교차 검증(ten-fold cross-validation)에서 우수한 성능을 보였습니다.



### Automated Quantification of Hyperreflective Foci in SD-OCT With Diabetic Retinopathy (https://arxiv.org/abs/2407.21272)
Comments:
          IEEE Journal of Biomedical and Health Informatics, Volume: 24, Issue: 4, pp. 1125 - 1136, 2020

- **What's New**: 이 논문은 망막 질환 진행과 관련이 있는 과반사 초점(HFs)의 자동 계량 알고리즘을 제안합니다. 이 알고리즘은 HFs를 분할하고 정량화하는 데 사용되며, 이는 현재 안과의사들이 HFs의 볼륨을 평가하는 데 도움을 줍니다.

- **Technical Details**: 제안된 알고리즘은 두 가지 병렬 프로세스로 구성됩니다: ROI(관심 영역) 생성과 HFs 추정입니다. ROI 생성을 위해 형태학적 복원을 사용하고, 데이터 분포와 클러스터링을 위해 히스토그램을 구성합니다. HFs 추정은 컴포넌트 트리에서 얻은 연결 영역으로부터 극단 지역을 추출하는 방식으로 이루어집니다. 마지막으로, 두 프로세스를 병합하여 분할된 HFs를 얻습니다. 이 알고리즘은 비증식성 당뇨망막병증(NPDR), 증식성 당뇨망막병증(PDR), 당뇨황반부종(DME)으로 진단된 40명의 환자로부터 얻은 40개의 3D SD-OCT 볼륨에서 테스트되었습니다.

- **Performance Highlights**: 제안된 알고리즘은 NPDR에 대해 평균 Dice Similarity Coefficient (DSC)와 상관 계수(상관계수)가 각각 69.70% 및 0.99로 나타났습니다. PDR의 경우 각각 70.31%, 0.99이며, DME의 경우 각각 71.30%, 0.99로 나타났습니다. 이 알고리즘은 안과의사에게 HFs의 부피, 크기, 위치에 대한 양질의 정보를 제공합니다.



### DEF-oriCORN: efficient 3D scene understanding for robust language-directed manipulation without demonstrations (https://arxiv.org/abs/2407.21267)
- **What's New**: DEF-oriCORN은 언어 지향적인 조작 작업을 위한 새로운 프레임워크로 제안되었습니다. 객체 기반의 새로운 장면 표현 방식과 확산 모델 기반 상태 추정 알고리즘을 채택하여, 드문 카메라 시야에서도 효율적이고 견고한 조작 계획을 가능하게 합니다. 특히, 투명한 물체와 반사 물체를 포함한 다양한 재료에 대해 현실 세계에서 제로샷(Zero-shot) 일반화를 달성합니다.

- **Technical Details**: 이 프레임워크는 물체의 형태와 방향을 나타내는 신경 표현체 (neural representation)인 z𝑧z와 공간 점유 중심(c) 및 일련의 대표적인 기하학적 점(M)으로 표현된 물체 상태를 사용합니다. 또한 SO(3)-동변량 네트워크로 예비 학습을 거쳐 새로운 방향으로의 일반화를 가능하게 합니다. 충돌 검사는 신경 표현으로 직접 예측되며, 언어 명령의 객체 접지를 위해 CLIP을 사용합니다. 필셀을 기반으로 한 CLIP 피처를 계산하고, 물체 상태 𝐬의 레이 히팅(ray-hitting) 디코더를 통해 객체 접지를 평가합니다.

- **Performance Highlights**: DEF-oriCORN는 합성 및 실제 환경에서 추정, 그립 계획, 모션 계획, 그리고 언어 지향적 조작 문제에서 최첨단 성능을 뛰어넘는 정확성과 속도를 달성했습니다. 특히, 소수의 RGB 이미지와 제로샷 상황에서도 탁월한 성능을 발휘합니다.



### Outlier Detection in Large Radiological Datasets using UMAP (https://arxiv.org/abs/2407.21263)
Comments:
          Accepted in MICCAI-2024 Workshop on Topology- and Graph-Informed Imaging Informatics (TGI3)

- **What's New**: 이번 논문에서는 UMAP(Uniform Manifold Approximation and Projection) 알고리즘을 활용해 의료 데이터셋에서 이상치를 발견하는 새로운 방법을 제안합니다. ChestX-ray14, CheXpert 및 MURA 데이터셋을 사용하여 이 방법의 유효성을 증명하였습니다. 이 방법은 데이터셋 생성 시점에서 데이터 품질을 향상시킬 수 있는 유용한 도구로 작용할 수 있습니다.

- **Technical Details**: 이 방법은 이미지 특징을 추출하기 위해 DenseNet-121 모델을 사용하고, UMAP을 통해 고차원의 특징을 2차원으로 변환하여 시각화합니다. DenseNet-121은 ImageNet 데이터셋을 통해 학습된 딥러닝 네트워크로, 이미지의 최종 계층에서 특징을 추출합니다. 특징 추출 후 UMAP을 사용하여 고차원 데이터를 2-D로 축소합니다.

- **Performance Highlights**: 제안된 방법을 통해 ChestX-ray14 데이터셋에서는 총 92개의 측면 x-ray 이미지와 다양한 아티팩트가 포함된 이미지를 발견했습니다. CheXpert 데이터셋에서는 저질 JPEG 압축이나 부주의로 인한 스플라이싱으로 발생한 블록 아티팩트를 가진 이미지 107개, 노이즈 이미지 19개, 블록 아티팩트와 다이내믹 레인지 문제가 있는 이미지 53개, 세로형 아티팩트가 있는 이미지 88개 등을 발견했습니다. 또한, 모델을 변경하여 다양한 실험을 통해 결과의 일관성을 확인했습니다.



### VITAL: Visual Teleoperation to Enhance Robot Learning through Human-in-the-Loop Corrections (https://arxiv.org/abs/2407.21244)
- **What's New**: 본 논문은 VITAL이라는 저비용의 시각적 원격조작 시스템을 통해 로봇이 사람의 행동을 모방하여 새로운 기술을 습득하는 모방 학습(Imitation Learning, IL)의 데이터 수집 문제를 해결하고자 한다. 특히, 양손 조작 작업에 적합한 이 시스템은 저렴한 하드웨어와 시각 처리 기술을 활용하여 고품질 데모를 수집하고, 이를 확대하여 방대한 훈련 데이터셋을 만드는 방법을 제안한다.

- **Technical Details**: VITAL 시스템은 인간의 동작을 포착하기 위해 외부 RGB-D 카메라와 Bluetooth가 장착된 셀카 스틱을 사용하며, MediaPipe 라이브러리를 통해 상체의 24개 주요 포인트를 추적한다. 추적된 동작 데이터는 로봇 팔과 그립퍼의 실시간 명령으로 변환된다. 또한, AruCo 마커를 사용해 스틱의 방향을 추적하며, 인간-세계 기준 프레임을 안정적으로 구축하기 위해 어깨와 고관절 키포인트를 사용한다. 추가적으로, 두 팔의 길이 차이를 보완하기 위해 스케일링 팩터를 적용하여 원격조작의 직관성과 정밀성을 높였다.

- **Performance Highlights**: 본 방법은 다양한 복잡성의 작업(예: 병 수집, 물건 쌓기, 망치질)에서 실험을 통해 검증되었고, 인간의 실시간 피드백과 실제 데이터의 통합을 통해 로봇이 실제 업무에서 높은 성능을 발휘할 수 있음을 확인하였다. 또한, 새로운 작업(예: 음료 트레이 세팅)에서도 시스템의 적응성과 확장성을 입증하였다.



### TMA-Grid: An open-source, zero-footprint web application for FAIR Tissue MicroArray De-arraying (https://arxiv.org/abs/2407.21233)
Comments:
          NA

- **What's New**: 티슈 마이크로어레이(TMA) 분석을 위한 새로운 웹 애플리케이션, TMA-Grid가 개발되었습니다. 이 애플리케이션은 브라우저 내에서 구동되는 인터랙티브한 방식으로, 다운로드나 설치 없이 사용이 가능하며 데이터 프라이버시를 보장합니다. 사용자는 세그멘테이션(segmentation)과 그리드(grid) 조정 결과를 쉽게 조정할 수 있습니다.

- **Technical Details**: TMA-Grid는 정확한 티슈 세그멘테이션(tissue segmentation)을 위해 컨볼루션 신경망(convolutional neural network)을 통합하고, 각 코어(core)를 예상 위치와 매칭하기 위해 그리드 추정 알고리즘(grid estimation algorithm)을 사용합니다. 또한, 이 애플리케이션은 Findable, Accessible, Interoperable, Reusable(FAIR) 원칙에 따라 설계되어, TMA 연구 워크플로우와의 원활한 통합을 강조합니다.

- **Performance Highlights**: TMA-Grid는 어셈블리 오류로 인한 코어의 잘못된 정렬과 아티팩트를 효과적으로 처리할 수 있습니다. 사용자 친화적인 인터페이스 덕분에, 사용자가 쉽게 데이터 세그멘테이션과 그리드 조정을 할 수 있어 TMA의 다운스트림 분석을 더욱 신뢰성 있게 수행할 수 있습니다.



### DeepBaR: Fault Backdoor Attack on Deep Neural Network Layers (https://arxiv.org/abs/2407.21220)
- **What's New**: 최근 컴퓨터 비전(computer vision) 분야에서 큰 성과를 보인 신경망(machine learning) 기반의 기계 학습과 관련된 보안 문제에 대한 새로운 연구, DeepBaR가 소개되었습니다. 이 연구는 신경망 훈련 중 특히 'fine-tuning' 단계에서 백도어(backdoor)를 심는 새로운 방법론을 제시하며, 이는 공격 성공률이 98.30%에 달할 정도로 높은 성과를 보였습니다.

- **Technical Details**: DeepBaR는 사용자 정의 손실 함수(custom loss function)를 최적화하여 심지에 거의 보이지 않는 '트리거'를 추가한 이미지로 'adversarial samples'를 생성합니다. 이는 인간이 쉽게 인지하지 못할 이미지 변화를 통해 목표 클래스가 아닌 임의의 다른 클래스로 분류되도록 만듭니다. 또한 ResNet-50, DenseNet-121 같은 복잡한 경락망 아키텍처에서도 성공적으로 적용 가능합니다.

- **Performance Highlights**: VGG-19에서 최고 98.30%, ResNet-50에서 97.94%, DenseNet-121에서 88.94%의 높은 공격 성공률을 달성했습니다. 중요하게도, DeepBaR는 비악성 입력이 주어질 때 네트워크의 정확도에 큰 영향을 미치지 않으며, 기존 모델 대비 성능 저하는 평균 0.8%에 불과합니다.



### Distribution-Aware Replay for Continual MRI Segmentation (https://arxiv.org/abs/2407.21216)
- **What's New**: 환자 집단의 변화와 이미지 획득의 차이로 인해 의료 이미지 분포가 지속적으로 변화하는 문제를 해결하기 위해 새로운 분포 인식 재생 전략(distribution-aware replay strategy)이 도입되었습니다. 이 전략은 특징의 자동 인코딩(auto-encoding)을 활용하여 잊어버림(mitigate forgetting)을 줄이는 동시에 학습된 특징 분포(feature distribution)를 활용하여 모델 실패를 감지합니다. 본 연구는 해마(hippocampus)와 전립선(Prostate) MRI 분할작업에서 실험적으로 입증되었습니다.

- **Technical Details**: 새로운 접근법은 이중단계 모델링(two-stage modeling)에 기초해, 1차 판별 모델에 간섭 없이 2차 생성 모델(generative model)이 학습된 분포를 인코딩하는 방식입니다. 구체적으로, UNet의 잠재 특징(latent features)의 저차원 분포를 모델링하기 위해 두 번째 조건부 변이 오토인코더(VAE)를 제안합니다. 새로운 샘플이 기존 학습 데이터 분포에서 벗어나는지 평가하고, 모델을 지속적으로 적응시키는 동안 기존 지식을 잊지 않기 위해 과거 샘플의 특징을 재생하는 구조입니다.

- **Performance Highlights**: 연구는 도메인 증분(domain incremental) MRI 분할 작업에서 UNet을 활용한 새로운 방법을 검증했습니다. 또한 증강 데이터셋에서 OoD(out-of-distribution) 감지 성능을 평가했습니다. 실험결과는 제안된 전략이 기존의 방법들보다 모델 성능 저하를 효과적으로 완화하고, 기대하지 않은 분포 변화에 대한 모델의 실패를 성공적으로 감지할 수 있음을 보여줍니다.



### Embedding Space Selection for Detecting Memorization and Fingerprinting in Generative Models (https://arxiv.org/abs/2407.21159)
- **What's New**: 이번 연구에서는 인공지능 분야에서 중요한 기술인 Vision Transformers(ViTs)를 이용해 데이터 메모리제이션(memorization)을 측정하는 새로운 접근법을 제안합니다. 특히, ViTs의 레이어별로 메모리제이션 스코어를 분석한 결과, 후반부(깊은) 레이어일수록 메모리제이션이 적다는 트렌드를 발견했습니다. 또한, 새로운 지문화(fingerprinting) 방법을 도입하여 생성된 영상에서 모델을 더욱 정확하게 식별할 수 있는 방법을 제시했습니다.

- **Technical Details**: 이번 연구는 CT-Score 라는 임베딩 기반 데이터 복제(metrics of data-copying)를 이용해 메모리제이션을 측정했습니다. 각 레이어의 임베딩에서 CT-Score를 계산하였고, 전체 데이터 공간에서 K-Means 알고리즘을 사용해 클러스터링을 수행했습니다. 이 방법은 ViTs의 아키텍처와 모델이 학습된 데이터, 최적화 기법 등이 모델의 메모리제이션 특성에 영향을 준다는 점을 바탕으로 합니다.

- **Performance Highlights**: 기존의 방법들에 비해 30% 더 높은 모델 식별 정확도를 보였습니다. 이는 디지털 정보 조작 방지를 위한 더 효과적인 도구를 제공함으로써, 생성된 콘텐츠의 출처를 추적하는 데 중요한 역할을 할 수 있습니다.



### Domain Shift Analysis in Chest Radiographs Classification in a Veterans Healthcare Administration Population (https://arxiv.org/abs/2407.21149)
- **What's New**: 이 연구는 도메인 이동(domain shift)과 흉부 X-레이 분류 정확도에 대한 영향을 평가하고, 라벨의 품질과 인구통계학적 요인(연령, 성별, 연구 연도)의 영향을 분석합니다.

- **Technical Details**: 연구에는 DenseNet121 모델을 사용하여 MIMIC-CXR 데이터셋에서 사전 학습된 딥러닝 기반 다중 레이블 분류(Multi-label Classification)을 수행했습니다. 레이블은 CheXpert와 CheXbert 라벨러를 사용하여 방사선 보고서에서 추출했습니다. MIMIC-CXR와 VA-CXR 데이터셋의 14개 흉부 X-레이 라벨 성능을 비교했습니다. VA-CXR은 2010년부터 2022년까지의 259k 이상의 흉부 X-레이 이미지를 포함합니다.

- **Performance Highlights**: 연구 결과, 다양한 NLP 추출 도구를 사용한 다중 라벨 분류 성능 검증에서 VA-CXR 데이터셋이 MIMIC-CXR 데이터셋보다 낮은 불일치율을 보였습니다. CheXpert와 CheXbert를 사용하는 모델 간 AUC 점수에서 차이가 나타났으며, 'Enlarged Cardiomediastinum' 라벨을 제외하고는 미지의 데이터 셋에서 도메인 이동이 최소화되었습니다. 연구 연도의 하위 그룹 분석에서 다중 라벨 분류 모델 성능의 가장 큰 변이가 나타났습니다.



### Taming the Frequency Factory of Sinusoidal Networks (https://arxiv.org/abs/2407.21121)
- **What's New**: 이번 연구에서는 저차원 신호를 인코딩하는 데 탁월한 성과를 보인 sinusoidal MLPs의 구조와 표현 능력에 대해 조사합니다. 연구는 이 네트워크의 파생물(iterative components)을 훈련에 사용 가능하게 하는 부드러움과 높은 표현 능력에 주목합니다. sinusoidal MLPs의 용량 속성을 이론적 및 실험적으로 타당화하는 결과를 제공하며, 이들의 초기화와 훈련을 제어할 수 있는 메커니즘을 제안합니다.

- **Technical Details**: 본 연구는 Fourier 시리즈 관점에서 접근하며, 모델의 스펙트럼과 훈련을 연결합니다. 새로운 삼각 함수 정체성을 사용하여 네트워크 용량을 이해하고, 각 sinusoidal 뉴런이 입력 주파수의 정수 선형 조합으로 표현된 새로운 주파수를 생성함을 규명합니다. 이를 통해 입력 뉴런을 초기화하고, 신호 스펙트럼을 샘플링합니다. 또한, 각 은닉 뉴런은 완전히 은닉 가중치로 결정된 동일한 주파수를 생성합니다. 이러한 초기화 및 훈련 전략은 네트워크 스펙트럼의 bandlimit을 제어할 수 있도록 설계되었습니다.

- **Performance Highlights**: sinusoidal MLPs이 높은 표현력을 가지며 이미지, 표면, 애니메이션 및 광 방사 필드 등 다양한 매체 객체를 나타내는 데 성공적으로 사용되었습니다. 연구는 새로운 삼각 함수 정체성을 기반으로 한 초기화 방법과 훈련 중 스펙트럼을 제어하는 기법으로 더욱 안정적이고 수렴성 있는 훈련을 보장합니다.



### Multi-Grained Query-Guided Set Prediction Network for Grounded Multimodal Named Entity Recognition (https://arxiv.org/abs/2407.21033)
Comments:
          11 pages, 5 figures

- **What's New**: Grounded Multimodal Named Entity Recognition(GMNER)라는 정보 추출(IE) 작업 분야에서, 최신 연구들은 MRC 기반 프레임워크나 시퀀스 생성 기반 모델을 사용하고 있지만, 이러한 방법들은 멀티모달 엔티티 간의 관계 이해에 어려움을 겪고 있습니다. 이에 본 연구는 MQSPN(Multi-grained Query-guided Set Prediction Network)을 제안해 intra-entity와 inter-entity 수준에서 적절한 관계를 학습하는 새로운 통합 프레임워크를 소개합니다.

- **Technical Details**: MQSPN은 Multi-grained Query Set(MQS)와 Multimodal Set Prediction Network(MSP), 그리고 Query-guided Fusion Net(QFNet)으로 구성됩니다. MQS는 특정 타입 세분화된 쿼리들과 학습 가능한 엔티티 세분화된 쿼리를 결합하여 intra-entity 연결을 강화합니다. MSP는 GMNER를 집합 예측(set prediction) 문제로 재구성하여 inter-entity 관계를 글로벌 매칭 관점에서 적절하게 모델링합니다. QFNet은 텍스트와 시각적 정보를 각각 적절하게 통합하여 노이즈를 줄이는 역할을 합니다.

- **Performance Highlights**: 제안된 MQSPN 프레임워크는 기존 SOTA(State-of-the-Art) 방법들보다 우수한 성능을 기록했습니다. 특히, 어려운 fine-grained GMNER benchmark에서 2.83%의 F1 점수를 향상시켰습니다.



### U-Net-based Lung Thickness Map for Pixel-level Lung Volume Estimation of Chest X-rays (https://arxiv.org/abs/2110.12509)
- **What's New**: 이번 연구의 목적은 실제 및 합성 전면 X-레이(frontral X-ray) 영상에서 U-Net을 사용하여 생성된 폐 두께 지도(lung thickness map)를 통해 총 폐 용적(TLV)을 추정하는 것이었습니다. 이 과정에서 U-Net 모델이 합성 영상과 실제 영상 모두에서 유효하게 동작함을 검증하였습니다.

- **Technical Details**: 5,959개의 흉부 X-레이 CT 스캔을 두 개의 공개 데이터셋(lung nodule analysis 2016, RSNA pulmonary embolism detection challenge 2020)에서 가져왔습니다. 또한, 흉부 CT 스캔이 포함된 72명의 피험자 데이터를 후향적으로 선택하였습니다. 모든 CT 스캔과 해당 폐 세그멘테이션(lung segmentation)은 시뮬레이션된 X-레이 스펙트럼을 사용하여 합성 영상과 폐 두께 지도로 변환되었습니다. U-Net 모델은 공개 데이터셋의 합성 영상을 바탕으로 훈련되었으며, 폐 두께 지도를 예측하고 TLV를 추정하는 데 사용되었습니다.

- **Performance Highlights**: 공개 데이터셋의 합성 영상 테스트 데이터에서 예측된 TLV 값과 CT 기반의 참 값 간의 상관 관계(Pearson correlation)가 강하게 나타났습니다 (n=1,191, r=0.987, P < 0.001). 인-하우스(in-house) 합성 및 실제 영상의 TLV 예측 값 또한 강한 상관 관계를 보였습니다 (n=72, r=0.973, P < 0.001 for synthetic; n=72, r=0.908, P < 0.001 for real). 결론적으로, U-Net을 사용한 픽셀 수준의 폐 두께 지도 생성을 통해 합성 및 실제 X-레이 영상에서 TLV를 성공적으로 추정할 수 있었습니다.



### Matting by Generation (https://arxiv.org/abs/2407.21017)
Comments:
          SIGGRAPH'24, Project page: this https URL

- **What's New**: 이 논문은 이미지 매팅(image matting)을 수행하는 혁신적인 접근 방식을 소개합니다. 전통적인 회귀 기반의 작업을 생성적 모델링(generative modeling)로 재정의하였습니다. 이 방식은 광범위하게 사전 학습된(latent diffusion models) 잠재 확산 모델의 기능을 활용하여 매팅 과정을 정규화합니다.

- **Technical Details**: 이 방법은 새로운 아키텍처 혁신을 포함하여 고해상도와 세부 사항이 뛰어난 매트를 생성할 수 있도록 모델에게 힘을 실어줍니다. 제안된 방법은 유도(guidance) 없이도, 또는 다양한 추가적인 단서들을 통해 가이드된(guidance-based) 방식으로도 이미지 매팅을 수행할 수 있도록 다재다능합니다.

- **Performance Highlights**: 세 가지 벤치마크 데이터셋을 통한 종합적인 평가에서 이번 접근 방식은 정량적 및 정성적으로 모두 우수한 성능을 보였습니다. 결과는 우리의 방법이 견고하고 효과적일 뿐만 아니라, 사실적인 품질과 가까운 시각적으로 매력적인 매트를 생성하는 능력을 강조합니다.



### Add-SD: Rational Generation without Manual Referenc (https://arxiv.org/abs/2407.21016)
- **What's New**: 새로운 연구 'Add-SD'는 텍스트 프롬프트(text prompts)만으로 객체를 현실적인 크기와 위치로 장면에 자동으로 삽입하는 파이프라인을 제안합니다. 기존의 레이아웃 조건(layout-conditioned) 방법과 달리, Add-SD는 바운딩 박스 같은 비싼 인간 참조를 요구하지 않습니다.

- **Technical Details**: Add-SD는 세 가지 주요 기여를 합니다. 첫째, 다양한 텍스트 명령 기반 이미지 쌍을 포함하는 데이터셋을 제안합니다. 둘째, Stable Diffusion (SD) 모델을 합리적인 생성(rational generation)을 위해 파인튜닝(fine-tuning)합니다. 셋째, 다운스트림(downstream) 작업을 향상시키기 위해 합성 데이터를 생성합니다. RemovalDataset은 객체가 제거된 원본-편집된 이미지 쌍과 텍스트 명령을 포함하며, 이는 모델 파인튜닝에 사용됩니다.

- **Performance Highlights**: LVIS val 실험에서 Add-SD는 희귀 클래스(rare classes)에 대해 베이스라인 대비 4.3 mAP 향상을 보여줍니다. 모델과 코드는 공개되어 있습니다.



### CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning (https://arxiv.org/abs/2407.21011)
Comments:
          Accepted by MICCAI 2024

- **What's New**: 최근 Contrastive Language-Image Pre-training (CLIP) 분야에서 자가 지도 학습(self-supervised representation learning)의 많은 진전이 있었습니다. 그러나 기존의 CLIP 같은 접근 방식은 모델과 데이터셋의 규모 때문에 상당한 GPU 자원과 긴 학습 시간을 필요로 합니다. 이로 인해 데이터셋이 적은 의료 분야에서 효과적인 활용이 어렵습니다. 이에 새로운 언어-이미지 대조 학습 방법인 CLEFT를 도입했습니다. 이는 대규모 사전 학습된 언어 및 비주얼 모델의 장점을 활용하여 효율적입니다.

- **Technical Details**: CLEFT는 컨텍스트 기반 프롬프트 학습 전략을 통해 정보 풍부한 임상 진단 데이터와 단순한 클래스 레이블 간의 격차를 줄입니다. 이 방법론은 효율적인 대형 언어 모델과 프롬프트 미세 조정(prompt Fine-Tuning)을 도입하여, 임상 진단 데이터를 효과적으로 활용합니다. 또한, 모델 훈련 파라미터를 39% 줄이고, 학습 가능한 언어 모델 크기를 기존의 BERT 인코더와 비교할 때 4%로 줄였습니다.

- **Performance Highlights**: 제안된 방법론은 여러 흉부 X-ray 및 유방촬영술(mammography) 데이터셋에서 다양한 기준선(baselines)과 비교하여 최첨단 성능을 보였습니다. 특히, 효율적이고 파라미터를 줄일 수 있는 프레임워크를 통해 의료 데이터의 한계를 극복하고 더 나은 진단 성능을 입증했습니다.



### XHand: Real-time Expressive Hand Avatar (https://arxiv.org/abs/2407.21002)
- **What's New**: 새로운 핸드 아바타 시스템인 XHand가 소개되었습니다. XHand는 실시간으로 손의 형태, 외관, 변형을 종합적으로 생성할 수 있도록 설계되었습니다. 이는 가상 현실 및 게임 환경에서 즉석 렌더링이 중요한 역할을 하는 응용 분야에 매우 유용합니다.

- **Technical Details**: XHand는 손 변형 이동(Hand Deformation Displacements), 반사율(Albedo), 선형 블렌딩 스키닝 가중치(Linear Blending Skinning Weights)를 예측하기 위해 세 가지 기능 임베딩 모듈(Feature Embedding Modules)을 사용합니다. 결과적으로, 메쉬 기반 신경 렌더러를 통해 세세한 메쉬(fine-grained meshes)를 실시간으로 포토리얼리스틱(photo-realistic)하게 렌더링할 수 있습니다. 훈련 과정에서는 파트-어웨어 라플라스 평활화 전략(Part-aware Laplace Smoothing Strategy)을 사용하여 필요 없는 아티팩트를 제거하면서 필수적인 세부 사항을 효과적으로 유지합니다.

- **Performance Highlights**: InterHand2.6M 및 DeepHandMesh 데이터셋에 대한 실험적 평가에서 XHand는 다양한 포즈의 손 애니메이션에 대해 높은 충실도의 기하학 및 텍스처를 복원할 수 있는 성능을 입증했습니다. 이는 실시간으로 구현될 수 있으며, 전체 구현은 곧 공개될 예정입니다.



### GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language Models (https://arxiv.org/abs/2407.21001)
- **What's New**: 이 논문은 Vision-language models (VLMs)이 이미지 분석에서 개인의 활동과 관련된 성별 편향(Gender-Activity Binding Bias, GAB)을 어떻게 나타내는지 연구하고 있습니다. 특히, 다양한 성별의 사람들이 여러 활동을 하는 복잡한 상황에서 이 편향이 두드러진다는 점을 강조합니다. 이를 위해 약 5500개의 AI 생성 이미지를 포함한 GAB 데이터셋을 소개하고, 이를 활용하여 성별-활동 연관 편향을 측정합니다.

- **Technical Details**: 연구진은 GAB 데이터셋을 만들기 위해 다양한 활동을 나타내는 약 5500개의 AI 생성 이미지를 사용하였으며, 이미지의 다양성, 품질 및 현실성을 평가했습니다. 12개의 유명한 사전 학습된 VLMs을 텍스트-이미지 및 이미지-텍스트 검색 컨텍스트에서 테스트하여 이 편향이 모델 예측에 미치는 영향을 측정했습니다. 또한, VLMs의 텍스트 인코더(text encoders)에서의 편향을 정량화하고, VLMs이 활동을 인식하는 능력을 평가하기 위한 추가 실험도 수행했습니다.

- **Performance Highlights**: 실험 결과, VLMs은 성별-활동 연관 편향(Gender-Activity Binding Bias) 상황에서 평균 약 13.2%의 성능 저하를 겪는 것으로 나타났습니다. 이는 VLMs이 내재된 성별 편향으로 인해 실제 활동 수행자와 관련된 성별을 올바르게 예측하는 데 어려움을 겪고 있음을 시사합니다.



### PIXELMOD: Improving Soft Moderation of Visual Misleading Information on Twitter (https://arxiv.org/abs/2407.20987)
- **What's New**: 이번 연구에서는 이미지 기반의 허위 정보를 효과적으로 탐지하기 위한 시스템인 PIXELMOD를 소개합니다. PIXELMOD는 사용자가 트위터에서 공유하는 이미지를 검토하여 소프트 중재(soft moderation) 레이블을 적용할 수 있는 후보 이미지를 식별합니다.

- **Technical Details**: PIXELMOD 시스템은 다음과 같은 기술들을 결합하여 성능을 극대화합니다. 첫째, perceptual hashes를 통해 이미지를 신속하게 비교합니다. 둘째, vector databases를 사용하여 이미지를 효율적으로 저장하고 검색합니다. 셋째, optical character recognition (OCR)을 통해 이미지 내 텍스트를 인식합니다. 이러한 접근 방식을 통해 대규모 이미지 검토가 가능합니다.

- **Performance Highlights**: 효율적인 이미지 유사성 탐지에서 PIXELMOD는 기존 방법들보다 뛰어난 성능을 보였습니다. 2020년 미국 대선 트윗 데이터를 테스트한 결과, PIXELMOD는 0.99%의 낮은 잘못된 탐지(false detection)와 2.06%의 낮은 놓친 탐지(false negatives) 비율을 기록했습니다.



### MMTrail: A Multimodal Trailer Video Dataset with Language and Music Descriptions (https://arxiv.org/abs/2407.20962)
Comments:
          15 Pages. Dataset report

- **What's New**: 기존의 비디오-언어 데이터셋(video-language dataset)은 주로 시각적인 프레임에 대한 텍스트 설명만 제공하며, 오디오를 약하게 관련된 정보로 취급합니다. 이에 대한 대안으로, 우리는 MMTrail이라는 대규모 멀티 모달리티 비디오-언어 데이터셋을 제안합니다. MMTrail은 visual captions(시각 설명)이 포함된 2천만 개 이상의 트레일러 클립과, 멀티모달 캡션(multimodal captions)이 있는 200만 개의 고품질 클립을 포함하고 있습니다.

- **Technical Details**: MMTrail 데이터셋은 트레일러 영상(trailers)의 예고편(full-length video works)을 제공합니다. 트레일러는 컨텍스트(context), 시각적 프레임(visual frames) 및 백그라운드 음악(background music)을 통합하여 다양한 주제와 캐릭터 유형(예: 영화, 뉴스, 게임 등)을 담고 있습니다. 또한, 백그라운드 음악은 시각적 컨텍스트와 일치하도록 맞춤 설계되어 있습니다. 우리는 이를 활용하여 27.1k 시간 이상의 트레일러 비디오를 포함하는 체계적인 캡셔닝 프레임워크(captioning framework)를 제안합니다. 또 LLM(Advanced Large Language Model)을 활용하여 모든 어노테이션(annotation)들을 적응적으로 병합합니다.

- **Performance Highlights**: 우리의 실험에서는 데이터셋의 평가 지표(evaluation metrics)와 벤치마크 결과(benchmark results)를 제공하여, 우리 어노테이션의 높은 품질과 모델 학습에 대한 효과성을 입증했습니다.



### Learning Ordinality in Semantic Segmentation (https://arxiv.org/abs/2407.20959)
Comments:
          12 pages

- **What's New**: 본 논문에서는 기존의 픽셀 단위의 순서적(segmentation methods) 세분화 방법과 달리, 이미지의 구조적 공간을 활용하는 새로운 공간 순서적 세분화(spatial ordinal segmentation) 방법을 제안합니다. 이러한 방법은 픽셀이 독립적인 관찰이라고 보는 대신, 주변 문맥(context)을 고려하여 픽셀을 종속적인 관찰로 취급함으로써 순서적 일관성(ordinal consistency)을 촉진합니다.

- **Technical Details**: 제안된 공간 순서적 세분화 방법은 이미지를 구조적으로 분석하여 문맥적 정보(contextual information)를 활용하며, 모델이 도메인에 존재하는 순서적 관계(ordinal relations)를 더욱 잘 학습할 수 있도록 합니다. 연구는 5개의 바이오메디컬(biomedical) 데이터셋과 여러 자율주행(autonomous driving) 데이터셋 구성을 사용하여 평가되었습니다.

- **Performance Highlights**: 순서적 방법(ordinal methods)을 통해 평가된 결과, 순서적 일관성이 증가된 모델을 생성할 수 있었으며, 순서적 메트릭(ordinal metrics)에서 상당한 개선을 보였습니다. 또한 Dice coefficient에서도 일부 향상을 확인했으며, 순서적 일관성을 도입함으로써 모델의 일반화 능력이 향상되었음을 보여주었습니다.



### dopanim: A Dataset of Doppelganger Animals with Noisy Annotations from Multiple Humans (https://arxiv.org/abs/2407.20950)
Comments:
          Under review @ NeurIPS 2024 (Datasets and Benchmarks Track)

- **What's New**: 새로운 벤치마크 데이터셋, dopanim을 소개합니다. 이 데이터셋은 15개의 클래스에 약 15,750개의 동물 이미지를 포함하고 있으며, 약 10,500개의 이미지에는 20명의 인간 annotators가 52,000개 이상의 주석을 달았습니다. 이 주석의 정확도는 약 67%에 달합니다.

- **Technical Details**: 이 데이터셋의 주요 특성은 다음과 같습니다: (1) 유사한 동물(doppelganger animals)을 분류하는 도전적인 과제, (2) 인간 추산 가능성을 주석으로 활용, 그리고 (3) annotator 메타데이터 포함. 우리는 잘 알려진 다중 주석 학습 방법 (multi-annotator learning approaches) 을 사용하여 이 데이터셋의 7가지 변형을 벤치마크 했습니다.

- **Performance Highlights**: 이 데이터셋을 활용하여 명확한 클래스 레이블을 넘어서는 학습과 액티브 러닝(active learning) 등의 추가 평가 사례를 제시합니다. 데이터셋과 종합적인 코드베이스가 공개되어 있어 데이터 수집 과정을 모방하고 모든 실험 결과를 재현할 수 있습니다.



### UniProcessor: A Text-induced Unified Low-level Image Processor (https://arxiv.org/abs/2407.20928)
- **What's New**: 이 논문에서는 다양한 저수준 비전 문제를 효율적으로 처리할 수 있는 통합 이미지 프로세서(UniProcessor)를 제안합니다. UniProcessor는 텍스트 기반 명령을 사용하여 여러 유형의 저하(degradation)와 수준을 처리할 수 있으며, 멀티모달 제어(multi-modal control)를 지원합니다. 본 시스템은 30가지 저하 유형을 처리할 수 있습니다.

- **Technical Details**: UniProcessor는 주제 프롬프트(subject prompt)와 조작 프롬프트(manipulation prompt)를 사용하여 저하 특정 정보를 인코딩하고 이를 처리합니다. 이러한 컨텍스트 제어(context control) 기능은 교차 주의(cross-attention)를 통해 UniProcessor 백본에 주입되어 처리 과정을 제어합니다. 자동 주제 프롬프트 생성을 위해 일반 목적의 저수준 저하 인식을 위한 비전-언어 모델(vision-language model)을 명령 튜닝 기법을 통해 구축했습니다.

- **Performance Highlights**: 실험 결과, UniProcessor는 추가적인 훈련이나 튜닝 없이도 다양한 저하 유형을 잘 처리하며, 다른 경쟁 방법보다 뛰어난 성능을 보였습니다. 또한, 저하 인식 컨텍스트 제어(degradation-aware context control)를 통해 여러 저하가 있는 이미지 내에서 단일 왜곡(distortion)을 개별적으로 처리할 수 있는 능력을 처음으로 보여주었습니다.



### SSPA: Split-and-Synthesize Prompting with Gated Alignments for Multi-Label Image Recognition (https://arxiv.org/abs/2407.20920)
Comments:
          13 pages, 8 figures

- **What's New**: 새로운 Split-and-Synthesize Prompting with Gated Alignments (SSPA) 프레임워크가 제안되었습니다. 이 프레임워크는 Vision-Language Models(VLMs)의 가능성을 최대화하여 다중 라벨 이미지 인식(multi-label image recognition) 작업을 개선합니다.

- **Technical Details**: SSPA는 Split-and-Synthesize Prompting(SSP) 전략을 통해 일반 지식과 특정 라벨 의미(label semantics)를 따로 모델링한 후 quaternion network를 사용해 신중하게 결합합니다. 또한, Gated Dual-Modal Alignments(GDMA)를 도입하여 시각적 모달리티와 언어적 모달리티 간의 양방향 상호작용을 촉진하고, 중복된 교차 모달 정보를 제거하여 효율적인 영역 수준 정렬(region-level alignments)을 가능하게 합니다. 최종 예측은 기존의 방식과는 다르게 소프트 집계(soft aggregator)를 통해 모든 이미지 영역의 결과를 공동으로 고려하여 도출됩니다.

- **Performance Highlights**: 자연, 보행자 속성, 원격 감지를 포함한 세 가지 도메인의 아홉 가지 데이터셋에서 SSPA의 실험 결과는 최첨단 성능을 보여줍니다. 추가 분석을 통해 SSP의 효율성과 GDMA의 해석 가능성도 입증되었습니다. 해당 코드는 공개될 예정입니다.



### Dynamic Scene Understanding through Object-Centric Voxelization and Neural Rendering (https://arxiv.org/abs/2407.20908)
- **What's New**: 새로운 연구에서는 무감독(Unsupervised) 비디오에서 객체 중심 표현을 학습하는 쉽지 않은 문제를 해결하기 위해, 3D 생성 모델인 DynaVol-S를 소개했습니다. DynaVol-S는 차별화 가능한 볼륨 렌더링 프레임워크(Differentiable Volume Rendering Framework) 내에서 객체 중심 학습을 가능하게 합니다.

- **Technical Details**: 핵심 아이디어는 개별 공간 위치에서 객체별 점유 확률을 추론하는 3D 성격의 장면을 캡처하는 객체 중심의 복셀화(Voxelization)를 수행하는 것입니다. 복셀 특징은 정형 공간 변형 함수(Canonical-Space Deformation Function)를 통해 진화하고, 조합적 NeRF와 함께 역 렌더링 파이프라인(Inverse Rendering Pipeline)에서 최적화됩니다. 또한, 2D 의미적 특징(Semantic Features)을 통합하여 3D 의미적 그리드(Semantic Grids)를 생성하여, 다중 분리 복셀 그리드(Multiple Disentangled Voxel Grids)를 통해 장면을 표현합니다.

- **Performance Highlights**: DynaVol-S는 새로운 뷰 합성(Novel View Synthesis)과 동적 장면의 비감독 분해(Unsupervised Decomposition) 작업에서 기존 모델보다 성능이 크게 개선되었습니다. 기하학적 구조와 의미적 특징을 공동으로 고려하여 복잡한 객체 상호작용을 포함한 실제 시나리오의 어려움을 효과적으로 해결합니다. 또한, 훈련이 완료되면 명확하게 의미 있는 복셀 특징(Explicitly Meaningful Voxel Features)을 사용하여 기하학적 형태 편집(Edit Geometric Shapes)이나 객체의 운동 궤적 조작(Manipulate Motion Trajectories)과 같은 새로운 장면 생성 기능을 제공합니다.



### What is YOLOv5: A deep look into the internal features of the popular object detector (https://arxiv.org/abs/2407.20892)
- **What's New**: 이 연구는 YOLOv5 객체 탐지 모델의 종합적인 분석을 제시하며, 그 아키텍처, 훈련 방법론, 성능을 조사합니다. 특히, Cross Stage Partial (크로스 스테이지 부분) 백본과 Path Aggregation-Network (경로 집합 네트워크) 등의 핵심 구성 요소들을 자세히 다룹니다. 또한, Darknet에서 PyTorch로의 전환과 이것이 모델 개발에 미친 영향을 논의합니다. 이 연구는 객체 탐지 분야에서 YOLOv5의 능력과 위치를 이해하는 데 큰 통찰력을 제공합니다.

- **Technical Details**: YOLOv5 모델의 아키텍처는 Cross Stage Partial (CSP) 백본과 Path Aggregation-Network (PAN)으로 구성되어 있습니다. CSP 백본은 네트워크의 정보를 효율적으로 전달하고, PAN은 멀티스케일 기능을 통합합니다. 또, YOLOv5는 Darknet에서 PyTorch로 전환되었는데, 이는 모델 개발의 유연성과 실행 효율성을 높였습니다.

- **Performance Highlights**: YOLOv5는 다양한 지표와 하드웨어 플랫폼에서 뛰어난 성능을 보였습니다. 특히, 제한된 엣지 디플로이먼트(Edge Deployment) 시나리오에서 많은 인기를 얻고 있습니다. 이 모델은 속도와 정확성 면에서 다른 객체 탐지 모델보다 탁월한 성능을 제공합니다.



### Automatic Die Studies for Ancient Numismatics (https://arxiv.org/abs/2407.20876)
Comments:
          code: this https URL

- **What's New**: 고대 화폐 생산량을 정량화하는 데 근본적인 'Die studies'를 완전히 자동화하는 새로운 방법을 제안했습니다. 이 접근법은 빠르고 강력한 로컬 디스크립터 매칭(local descriptors matching) 및 클러스터링 기반(clustering-based) 기법을 사용합니다.

- **Technical Details**: 이 논문은 전통적으로 수작업으로 이루어지던 'Die studies'를 자동화하는 방법을 제안합니다. 첫째로, 빠르고 강력한 로컬 디스크립터 매칭을 자동으로 설정합니다. 또한, 중요한 하이퍼파라미터를 결정하기 위해 외부 참조 없이 사용할 수 있는 고유 측정기(intrinsic metric)를 사용하는 클러스터링 기반 접근법이 핵심입니다.

- **Performance Highlights**: 제안된 방법은 두 개의 그리스 동전 코퍼스(corpora)에서 검증되었으며, 기존의 베이스라인을 자동으로 구현하고 평가하여 성능을 크게 향상시킨 것으로 나타났습니다.



### A Comparative Analysis of YOLOv5, YOLOv8, and YOLOv10 in Kitchen Safety (https://arxiv.org/abs/2407.20872)
- **What's New**: 이 연구는 주방에서 칼 사용 시의 안전 사고를 방지하기 위한 YOLO 모델들의 비교 분석을 다룹니다. 특히 칼을 다룰 때 손가락을 말아서 물체를 잡고 칼날이 아닌 손잡이만 닿도록 하는 안전 조치를 중심으로 합니다. YOLOv5, YOLOv8, YOLOv10 모델들이 분석되었습니다.

- **Technical Details**: 이 연구에서는 YOLOv5, YOLOv8, YOLOv10 모델이 사용되었습니다. 모델의 성능 평가는 Precision, Recall, F-score, 정규화 혼동 행렬(normalized confusion matrix)을 통해 이루어졌습니다. 모델은 손, 칼, 채소, 도마(cutting board)와 같은 클라스를 인식하는 데 사용되었습니다. 요약하면, YOLOv5는 칼날을 피하는 문제에서 뛰어난 성능을 보였고, YOLOv8은 물체를 잡을 때 손가락을 말아야 한다는 위험 요소를 더 잘 감지했습니다.

- **Performance Highlights**: YOLOv5와 YOLOv8은 손, 칼, 채소 인식에서 거의 동일한 성능을 보였지만, 세 모델 모두 도마 인식에서는 정확했습니다. 이 연구는 현실 세계에서 이러한 모델들의 장단점을 탐구하며, 안전 감시 시스템의 정확성과 효율성을 높이기 위한 YOLO 아키텍처 최적화 방안을 제시합니다.



### Mean of Means: A 10-dollar Solution for Human Localization with Calibration-free and Unconstrained Camera Settings (https://arxiv.org/abs/2407.20870)
- **What's New**: 이 연구에서는 메타버스 시대에 중요한 인체 위치 추적 문제를 해결하기 위해 저비용의 확률론적 접근법을 제안합니다. 기존 솔루션들이 고비용 하드웨어와 여러 고해상도 카메라에 의존하던 문제점을 대체하는 것입니다.

- **Technical Details**: 이 방법은 인체의 모든 점을 관측값(observations)으로 보고, 이들이 인체의 기하학적 중심을 중심으로 하는 분포로부터 생성된다고 가정합니다. 이를 통해 샘플링의 효율성을 크게 향상시켜, 관심 지점 당 샘플 개수를 수백에서 수십억으로 늘립니다. 또한, 중앙 극한 정리(Central Limit Theorem)를 활용해 월드 좌표의 평균과 픽셀 좌표의 평균 간의 관계를 모델링함으로써 일반성(normality)을 보장하고 학습 과정을 간소화합니다.

- **Performance Highlights**: 제안된 방법은 두 대의 해상도 640x480 픽셀의 웹 카메라만을 사용하여 10 USD의 저비용으로 0.3m 범위 내에서 95%의 위치 정확도와 0.5m 범위 내에서 거의 100%에 가까운 정확도를 달성하는 데 성공했습니다.



### DeTurb: Atmospheric Turbulence Mitigation with Deformable 3D Convolutions and 3D Swin Transformers (https://arxiv.org/abs/2407.20855)
- **What's New**: 이번 연구에서는 새로운 프레임워크를 제안하여 대기 난류(atmospheric turbulence)로 인한 장거리 촬영의 이미지를 개선합니다. 이 프레임워크는 기하학적 복원(geometric restoration)을 향상 모듈과 결합하여 적용됩니다. 새로운 방법은 딥러닝(deep learning) 접근법을 통해 기존의 모델 기반 접근법보다 더 빠르고 효과적으로 문제를 해결합니다.

- **Technical Details**: 프레임워크는 피라미드 아키텍처(pyramid architecture)와 변형 가능한 3D 합성곱(deformable 3D convolutions)을 사용하여 임의의 왜곡(random perturbations)과 기하학적 왜곡(geometric distortion)을 제거합니다. 그 후, 다중 스케일 아키텍처(multi-scale architecture)와 3D Swin Transformers를 활용하여 정렬된 프레임을 통해 선명한 이미지를 재구성합니다.

- **Performance Highlights**: 제안된 프레임워크는 합성된 대기 난류 효과와 실제 대기 난류 효과 모두에서 현존하는 최첨단 기술들을 뛰어넘는 성능을 발휘하며, 속도와 모델 크기에서도 합리적인 수준을 유지합니다.



### NIS-SLAM: Neural Implicit Semantic RGB-D SLAM for 3D Consistent Scene Understanding (https://arxiv.org/abs/2407.20853)
Comments:
          Accept by TVCG (ISMAR 2024 Journal Track)

- **What's New**: NIS-SLAM이라는 새로운 효율적인 neural implicit semantic RGB-D SLAM 시스템을 소개합니다. 이 시스템은 사전 학습된 2D segmentation 네트워크를 활용하여 일관된 semantic representation(의미 표현)를 학습합니다.

- **Technical Details**: 고해상도의 표면 재구성과 공간적으로 일관된 scene understanding(장면 이해)을 위해, high-frequency multi-resolution tetrahedron-based features(고주파 다중 해상도 사면체 기반 기능)와 low-frequency positional encoding(저주파 위치 인코딩)을 결합하였습니다. 또한, 여러 시점에서 발생하는 2D segmentation 결과의 불일치를 해결하기 위해 이전에 비키프레임의 semantic probabilities(의미 확률)을 키프레임에 통합하는 fusion strategy(융합 전략)을 제안합니다. 추가로, 신뢰도 기반의 pixel sampling(픽셀 샘플링)과 progressive optimization weight function(진행적인 최적화 가중치 함수)을 통해 견고한 카메라 추적을 구현하였습니다.

- **Performance Highlights**: 다양한 데이터셋에서 기존의 다른 neural dense implicit RGB-D SLAM 접근법과 비교했을 때, 더 뛰어난 또는 경쟁력 있는 성능을 보였습니다. 또한, 증강 현실 응용 프로그램에서도 사용할 수 있음을 보여주었습니다.



### Assessing Graphical Perception of Image Embedding Models using Channel Effectiveness (https://arxiv.org/abs/2407.20845)
Comments:
          In Proceedings of the 2024 IEEE Visualization and Visual Analytics (VIS)

- **What's New**: 이번 연구에서는 이미지 임베딩 모델(image embedding models)의 그래픽 인식(grok perception) 평가를 위한 새로운 프레임워크를 도입했습니다. 기존 벤치마크가 모델의 성능을 대략적으로 평가하는 데 그쳤다면, 우리는 모델이 차트를 처리하는 메커니즘을 보다 정확히 평가하기 위해 이 프레임워크를 설계했습니다. 특히, 차트 이해에서 시각적 채널(channel)의 정확성과 변별성(discriminability)을 중점적으로 평가합니다.

- **Technical Details**: 그래픽적 인식 평가를 위해 두 가지 주요 측면을 분석합니다. 첫째, 채널 정확성(channel accuracy)은 임베딩의 선형성(linearity)을 통해 평가하며, 이는 자극의 크기와 인식된 정도가 얼마나 잘 일치하는지를 측정합니다. 둘째, 변별성(discriminability)은 임베딩 사이의 거리(distances)를 기반으로 평가하며, 임베딩의 구별 가능성을 나타냅니다. 이번 실험에서는 CLIP 모델을 사용해 인간과는 다른 방식으로 길이(length), 기울기(tilt), 곡률(curvature) 등의 채널 변별성을 보여주었습니다.

- **Performance Highlights**: 실험 결과, CLIP 모델이 채널 정확성에서 인간과 다르게 인식하며 특히 길이, 기울기, 곡률 등의 채널에서 독특한 변별성을 보여줍니다. 이러한 결과는 정확한 차트 이해 및 인간과 유사한 그래픽 인식을 위한 향후 응용 프로그램에 도움이 될 수 있습니다. 이를 토대로 보다 신뢰할 수 있는 시각적 인코더(visual encoders)의 광범위한 벤치마크 개발을 목표로 하고 있습니다.



### DFE-IANet: A Method for Polyp Image Classification Based on Dual-domain Feature Extraction and Interaction Attention (https://arxiv.org/abs/2407.20843)
Comments:
          This paper has been accepted by 2024 International Conference on Intelligent Computing (ICIC 2024). It can be accessed at this http URL

- **What's New**: 이 논문은 대장암을 예방하기 위해 위장관에서 용종을 조기에 발견하고 치료하는 데 도움이 되는 새로운 네트워크 DFE-IANet을 제안합니다. 이 네트워크는 spectral transformation(스펙트럼 변환)과 feature interaction(특징 상호작용)을 기반으로 합니다. 특히 DFE-IANet은 복잡한 질감, 색상, 형태에 의해 영향을 받는 용종의 특징을 효과적으로 분류할 수 있도록 설계되었습니다.

- **Technical Details**: 먼저, 고유한 multi-scale frequency domain feature extraction (MSFD) 블록을 사용하여 주파수 도메인에서 미세한 질감의 세부 정보를 추출합니다. 이어서, multi-scale interaction attention (MSIA) 블록을 설계하여 네트워크가 중요한 특징을 추출하는 능력을 향상시킵니다. 이 블록은 self-attention(자체 집중) 방식에 다중 스케일 특징을 도입하여, 네트워크가 중요한 영역에 집중하도록 유도합니다. 마지막으로, 이 네트워크는 4M의 작은 파라미터로 설계되어 효율성과 정확성에서 뛰어난 성능을 발휘합니다.

- **Performance Highlights**: DFE-IANet은 Kvasir 데이터셋에서 최신의 다른 네트워크들보다 뛰어난 성능을 보여주었으며, Top-1 정확도 93.94%를 달성했습니다. 이는 ViT보다 8.94%, ResNet50보다 1.69%, VMamba보다 1.88% 높은 수치입니다. 코드도 공개되어 있습니다.



### Vulnerabilities in AI-generated Image Detection: The Challenge of Adversarial Attacks (https://arxiv.org/abs/2407.20836)
- **What's New**: 최근 GAN과 Diffusion 모델의 등장으로 이미지 합성 기술이 급격히 발전하면서 허위 정보 확산에 대한 우려가 커지고 있습니다. 이에 대응하기 위해 다수의 인공지능 생성 이미지(AIGI) 탐지기가 제안되었으나, 이들 탐지기의 적대적 공격에 대한 취약성에 대한 체계적인 이해는 부족한 상태입니다. 본 논문에서는 최첨단 AIGI 탐지기를 대상으로 백색 상자(white-box)와 흑색 상자(black-box) 설정에서의 적대적 공격 취약성을 조사합니다.

- **Technical Details**: AIGI 탐지를 위한 새로운 공격 방법을 제안하며, 이는 두 가지 주요 부품을 포함하고 있습니다. 첫 번째로, 실 이미지와 가짜 이미지의 주파수 도메인(frequency domain)에서의 명백한 차이에 영감을 받아, 이미지의 원래 주파수 분포에서 벗어나게 하기 위해 주파수 도메인에서의 교란을 추가합니다. 두 번째로, 대리 모델(surrogate model)의 전체 후방 분포(posterior distribution)를 탐색하여 이질적 모델 간의 격차를 더욱 좁히고자 합니다. 이는 새로운 후-학습 베이지안(post-train Bayesian) 전략을 도입하여 단일 대리 모델을 베이지안 모델로 변환함으로써, 재훈련 없이 다수의 희생자 모델을 시뮬레이션할 수 있게 합니다. 본 방법을 주파수 기반 후-학습 베이지안 공격(FPBA)이라 명명합니다.

- **Performance Highlights**: FPBA를 통해 적대적 공격이 AIGI 탐지기에 진정한 위협이 될 수 있음을 입증합니다. FPBA는 모델, 생성기, 방어 방법을 넘어서는 블랙박스 공격을 성공적으로 수행할 수 있으며, 크로스-제너레이터 검출(cross-generator detection)을 회피하는 실제 시나리오에서도 효과적입니다.



### WARM-3D: A Weakly-Supervised Sim2Real Domain Adaptation Framework for Roadside Monocular 3D Object Detection (https://arxiv.org/abs/2407.20818)
- **What's New**: 본 연구에서는 도로변 단안 3D 감지를 위한 대규모, 고품질 3D 데이터셋이 부족한 문제를 해결하기 위해 비싸지 않은 대규모의 합성 데이터셋을 활용하는 방법을 연구했습니다. 새로운 TUMTraf Synthetic Dataset(합성 데이터셋)을 소개하며, 이를 통해 부족한 현실 세계 데이터셋을 보완하고자 합니다. 더불어, Sim2Real 도메인 전이를 지원하기 위한 간결하면서도 효과적인 WARM-3D 프레임워크를 제안했습니다.

- **Technical Details**: WARM-3D는 저렴한 합성 데이터셋과 상용 2D 탐지기(2D detector)로부터 얻어진 2D 라벨을 활용하여 약지도 립을 제공합니다. 이 방법을 통해 단순한 2D 라벨만으로도 성능을 크게 향상시킬 수 있습니다. 특히, WARM-3D는 Pseudo-2D supervision을 이용할 때, 기준 성능보다 +12.40% mAP 3D 성능 향상을 달성했습니다. 또한, 2D GT를 약한 라벨로 사용할 때는 Oracle 기준 성능에 가까운 성능을 보였습니다.

- **Performance Highlights**: WARM-3D는 다양한 현실 세계 환경에서도 미지의 샘플 인식 능력을 향상시킴으로써 실제 응용 가능성을 강조합니다. 이는 새로운 환경에 대한 적응력과 강력한 일반화 성능을 보여줍니다.



### SpotFormer: Multi-Scale Spatio-Temporal Transformer for Facial Expression Spotting (https://arxiv.org/abs/2407.20799)
- **What's New**: 이번 연구에서는 동영상에서 특정 시기에 얼굴 표정이 발생하는 것을 식별하는 작업인 얼굴 표정 탐지를 위한 새로운 프레임워크를 제안합니다. 연구팀은 미세표정(micro-expressions)과 관련된 문제들을 해결하기 위해 효율적인 방법을 개발했습니다. 이를 통해 일반적인 얼굴 움직임과 미세한 표정 변화를 구분하고 탐지할 수 있는 성능을 보여주었습니다.

- **Technical Details**: 첫째, 입력된 이미지 시퀀스의 다중 해상도 optical flow를 압축된 슬라이딩 윈도우(sliding windows) 내에서 계산하는 SW-MRO(Sliding Window-based Multi-Resolution Optical flow) 특징을 제안했습니다. 이 방법은 일반 표정과 미세 표정을 구분할 수 있는 윈도우 길이를 사용해 미세한 움직임을 효과적으로 드러내고 심각한 머리 움직임 문제를 방지합니다. 둘째, SpotFormer라는 다중 스케일 시공간 트랜스포머(Transformer)를 제안하여 SW-MRO 특징의 시공간 관계를 동시에 인코딩해 정확한 프레임 별 확률 추정을 가능하게 합니다. SpotFormer에서 제안된 Facial Local Graph Pooling(FLGP) 및 convolutional layers가 다중 스케일 시공간 특징 추출에 사용됩니다. 셋째, SpotFormer에 감독된 대조 학습(supervised contrastive learning)을 도입해 서로 다른 유형의 표정 간의 변별력을 향상시켰습니다.

- **Performance Highlights**: SAMM-LV 및 CAS(ME)^2 데이터셋에서 광범위한 실험 결과, 제안된 방법이 최신 모델보다 특히 미세 표정 탐지에서 우수한 성능을 보여주었습니다.



### Retinex-Diffusion: On Controlling Illumination Conditions in Diffusion Models via Retinex Theory (https://arxiv.org/abs/2407.20785)
- **What's New**: 이번 논문은 확산 모델(diffusion model)에서 조명(light) 조작에 대한 새로운 접근 방식을 소개하고 있습니다. 이는 조건부 이미지 생성에서 조명 조건에 중점을 둔 공백을 해결하는 방법입니다.

- **Technical Details**: 논문에서는 확산 모델을 블랙박스(black-box) 이미지 렌더러로 개념화하고, 이미지 형성 모델과 일치하도록 에너지 함수를 전략적으로 분해합니다. 이를 통해 생성 과정 동안 조명 관련 속성을 효과적으로 분리하고 제어할 수 있습니다.

- **Performance Highlights**: 제안된 방법은 캐스트 섀도우(cast shadow), 소프트 섀도우(soft shadow), 상호 반사(inter-reflections) 등 현실적인 조명 효과가 있는 이미지를 생성합니다. 특히, 내재적 분해를 학습하거나 잠재 공간(latent space)에서 방향을 찾거나 새로운 데이터셋으로 추가 학습을 할 필요 없이 이를 달성합니다.



### Inverse Problems with Diffusion Models: A MAP Estimation Perspectiv (https://arxiv.org/abs/2407.20784)
Comments:
          10 pages

- **What's New**: 이 연구는 역문제(inverse problems)를 해결하기 위해 새로운 MAP 추정(MAP estimation) 프레임워크를 제안합니다. 이 프레임워크는 역문제를 해결하기 위해 사전 학습된 비조건 확산 모델(unconditional diffusion model)을 활용하는 기존 방법들의 한계를 극복하고, 최적화 과정을 통해 조건부 생성 과정을 모델링합니다.

- **Technical Details**: 연구진이 제안한 MAP 추정 프레임워크는 연속 시간 확산 모델(continuous time diffusion model)의 역 조건부 생성(reversible conditional generation) 과정을 MAP 목표의 최적화 과정으로 모델링합니다. 이 때, MAP 목표의 그래디언트 항목(gradient term)이 계산 가능하기 때문에 최적화가 가능합니다. 제안된 프레임워크는 이론적으로 일반적인 역문제를 그래디언트 기반 최적화 방법으로 해결할 수 있습니다. 그러나 손실 목표(loss objective)가 매우 비볼록(non-convex)하기 때문에 완벽한 그래디언트 기반 최적화 알고리즘을 찾는 것은 여전히 어려운 과제입니다.

- **Performance Highlights**: 연구진은 제안한 프레임워크를 통해 소음이 없는(noiseless) 및 소음이 있는(noisy) 이미지 인페인팅(image inpainting) 작업용 알고리즘을 개발했습니다. 다양한 마스크 설정(mask settings)에서 광범위한 실험을 통해 제안한 알고리즘을 검증하였으며 실험 결과, 제안된 프레임워크가 효과적으로 작동함을 확인했습니다.



### SynthVLM: High-Efficiency and High-Quality Synthetic Data for Vision Language Models (https://arxiv.org/abs/2407.20756)
- **What's New**: 최근 웹 이미지 증가와 함께 대규모 이미지 데이터셋을 관리하고 이해하는 것의 중요성이 커지고 있습니다. 본 논문에서는 VLLM(Vision Large Language Models)을 위해 SynthVLM이라는 새로운 데이터 합성 파이프라인을 제안합니다. SynthVLM은 고급 diffusion 모델과 고품질 캡션을 사용하여 캡션에서 고해상도 이미지를 자동으로 생성하고 선택하여 정밀하게 정렬된 이미지-텍스트 쌍을 만들고 있습니다.

- **Technical Details**: SynthVLM은 기존 이미지에서 캡션을 생성하는 방법과 달리, 고품질 캡션을 이용하여 고해상도 이미지를 생성하고 선택하는 방식을 채택했습니다. 이를 통해 데이터 정렬 품질을 높이며 언어 능력을 보존합니다. 또한, 순수하게 생성된 데이터에 의존함으로써 개인정보를 보호하며, 공식 데이터셋 크기의 18%에 불과한 100k 데이터 포인트로 SoTA(State-of-the-Art) 성능을 달성합니다.

- **Performance Highlights**: SynthVLM은 다양한 비전 질문 응답 작업에서 최첨단 성능을 달성했습니다. 기존 GPT-4 Vision 기반 캡션 생성 방법보다 성능이 우수하며, 컴퓨팅 오버헤드를 크게 줄였습니다. 정렬 품질이 높으면서도 고급 언어 능력을 유지하고 있어, 낮은 데이터 포인트 수로도 높은 성능을 보장합니다.



### Re-localization acceleration with Medoid Silhouette Clustering (https://arxiv.org/abs/2407.20749)
Comments:
          11 pages, 6 figures

- **What's New**: 본 논문에서는 시각적 리로컬리제이션(visual re-localization)의 속도를 가속화하는 새로운 접근법을 제시합니다. 시각적 클러스터링 알고리즘으로 추출된 키프레임을 기반으로 한 트리 구조의 검색 전략을 통해, 매칭 가속화를 달성할 수 있습니다. 이 방법은 기존의 방식과 비교하여 수행시간을 50%에서 최대 90% 절감하면서도 정확도를 유지합니다.

- **Technical Details**: 본 연구에서는 딥 뉴럴 네트워크(deep neural network) 구조 내에서 리로컬리제이션 프로세스를 가속화하는 방식에 주목합니다. 제안된 방법은 시각적 클러스터링 알고리즘으로 추출된 키프레임을 활용하여 트리 구조의 검색 전략을 설계하였습니다. 이 전략은 검색 시간을 단축시키기 위한 방법으로 구현되었습니다.

- **Performance Highlights**: 제안된 방법은 세 가지의 공공 데이터셋(public datasets)에서 두 가지의 작업에 대해 검증되었습니다. 그 결과, 기존의 기준선(baseline)과 비교했을 때, 수행시간을 50%에서 최대 90% 절감하는 동시에 위치 정확도를 떨어뜨리지 않는 성과를 보였습니다.



### Scene-Specific Trajectory Sets: Maximizing Representation in Motion Forecasting (https://arxiv.org/abs/2407.20732)
- **What's New**: 자율 주행에서 배우자(actor)의 다양한 미래 궤적(trajectory)을 예측하는 것은 필수적입니다. 이번 연구는 다중 궤적 집합을 사용하여 장면 내에서 맞춤화된 궤적을 생성하는 새로운 접근 방식을 제안합니다. 이는 교차로와 비교차로와 같은 다양한 장면(context)에 맞춘 궤적을 생성하는 방식으로, 지도 정보(map information)와 배우자의 역학(actor dynamics)을 활용합니다.

- **Technical Details**: 우리의 방법은 장면 배치를 조건으로 하는 궤적을 생성하는 결정론적 목표 샘플링 알고리즘(deterministic goal sampling algorithm)을 도입합니다. 또한, 다양한 샘플링 전략과 집합 크기를 경험적으로 조사하여 커버리지(coverage)와 다양성(diversity) 사이의 절충점을 최적화했습니다. Recursive In-Distribution Subsampling (RIDS) 방법을 사용하여 표현 공간을 효과적으로 축소하고, 메트릭 기반 샘플링에 비해 궤적의 허용 가능성을 향상시켰습니다.

- **Performance Highlights**: Argoverse 2 데이터셋 실험 결과, 우리의 장면별 궤적 집합이 전통적인 단일 집합 접근법에 비해 더 높은 가능성(plausibility)과 다양성을 유지한다는 것을 입증했습니다. 이는 실제 운전 시나리오에서 배우자의 복잡하고 이질적인 행동을 더 잘 포착할 수 있음을 보여줍니다.



### Autogenic Language Embedding for Coherent Point Tracking (https://arxiv.org/abs/2407.20730)
Comments:
          accepted by ACM MM 2024

- **What's New**: 최근 컴퓨터 비전 분야의 많은 연구들이 시간 모델링 기법에 집중하여 지역적 특징의 유사성을 향상시키려 했으나, 추적된 포인트의 의미적 일관성을 간과하는 경우가 많았습니다. 이에 본 논문에서는 텍스트 임베딩(language embeddings)을 활용하여 동일 객체에 관한 프레임별 시각적 특징의 일관성을 강화하는 새로운 방법을 제안합니다. 기존의 시각-언어 스키마와는 달리, 본 접근법은 텍스트 주석 없이 전용 매핑 네트워크를 통해 시각적 특징으로부터 텍스트 임베딩을 학습합니다.

- **Technical Details**: 본 연구에서 제안하는 자가 생성 언어 임베딩(auto-genic language embedding for visual feature enhancement) 기법은 전용 매핑 네트워크를 사용하여 시각적 특징으로부터 텍스트 임베딩을 학습합니다. 또 하나의 주요 구성 요소는 일관성 디코더(consistency decoder)로, 이는 최소한의 컴퓨팅 오버헤드로 텍스트 토큰을 시각적 특징에 효율적으로 통합합니다. 이를 통해 장기간 비디오 시퀀스에서의 포인트 일치(potint correspondence)를 강화합니다.

- **Performance Highlights**: 주요 추적 벤치마크에서의 광범위한 실험 결과, 본 방법은 시각적 단서에만 의존하는 트래커들에 비해 우수한 성능을 보여주었습니다. 특히, 외형의 변동성이 큰 장기 비디오에서의 추적 궤도(tacking trajectories) 향상이 두드러졌습니다.



### Neural Fields for Continuous Periodic Motion Estimation in 4D Cardiovascular Imaging (https://arxiv.org/abs/2407.20728)
Comments:
          10 pages, 5 figures, STACOM 2024

- **What's New**: 이 논문에서는 심혈관 주기의 벽 변형(deformation)을 연속적으로 추정하는 새로운 뉴럴 필드(neural fields) 기반 방법을 제안합니다. 특히, 기존의 4D flow MRI 분석이 주로 정적인 동맥 벽을 사용한 반면, 이 방법은 주기적인 벽 변형을 직접적으로 추정하여 벽의 움직임 패턴을 시각화하고 정량화할 수 있습니다.

- **Technical Details**: 제안된 방법은 3D + 시간 데이터셋에 대해 암묵적 뉴럴 표현(implicit neural representation, INR)을 최적화하여, 시간에 따른 속도 벡터 필드(VVF)를 나타냅니다. 상미분방정식(ODE) 해석기를 사용하여 VVF를 변형 벡터 필드(DVF)로 통합하여, 시간 경과에 따른 이미지, 세그멘테이션 마스크(segmentations masks) 또는 메시(mesh)를 변형시킬 수 있습니다. 이를 통해 주기적인 3D + 시간 심혈관 데이터를 적절히 반영하고자, 시간 입력을 INR에 주기적으로 인코딩하고 DVF를 규제(regulate)하는 두 가지 방법으로 주기성을 부여했습니다.

- **Performance Highlights**: 제안된 방법의 유효성은 다양한 주기적 패턴을 가지는 합성 데이터, ECG-게이트 CT, 그리고 4D flow MRI 데이터에 대해 입증되었습니다. 이 방법은 4D flow MRI 분석을 개선하는 데 중요한 도구로 활용될 수 있습니다.



### SceneTeller: Language-to-3D Scene Generation (https://arxiv.org/abs/2407.20727)
Comments:
          ECCV'24 camera-ready version

- **What's New**: 최신 인공지능 기술을 활용한 텍스트 기반 3D 방 설계 방법을 제안합니다. 사용자가 자연 언어로 방 안에 배치할 물체를 설명하면, 이를 기반으로 고품질의 3D 장면을 생성합니다. 추가 텍스트 프롬프트(prompt)를 통해 장면 전체 또는 개별 객체의 외관을 변경할 수도 있습니다.

- **Technical Details**: 제안된 방법은 In-Context Learning, CAD 모델 검색, 3D Gaussian Splatting 기반의 스타일화 기술을 사용하여 동작합니다. 이 파이프라인은 전문가가 아니더라도 쉽게 사용할 수 있게 설계되었습니다.

- **Performance Highlights**: 턴키(turnkey) 파이프라인을 통해 생산된 3D 장면의 품질은 최첨단 수준(state-of-the-art)입니다.



### Boosting Audio Visual Question Answering via Key Semantic-Aware Cues (https://arxiv.org/abs/2407.20693)
Comments:
          Accepted by ACM MM 2024

- **What's New**: 이번 연구에서는 Audio Visual Question Answering (AVQA) 과제와 관련된 Temporal-Spatial Perception Model (TSPM)을 제안합니다. 이 모델은 비디오의 다양한 시각적 객체, 소리, 및 이들의 상호작용에 대한 질문에 답할 수 있도록 설계되었습니다. TSPM은 질문과 관련된 중요한 시각적 및 청각적 단서를 인식하는 데 초점을 맞추고 있습니다.

- **Technical Details**: 비주얼-랭귀지 사전학습 모델을 사용하여 비선언적(non-declarative) 질문과 시각적 표현을 동일한 의미 공간에 맞추는 어려움을 고려하여, 질문 템플릿에서 파생된 선언문 형식의 프롬프트를 작성하였습니다. 이를 통해 중요한 세그먼트를 더 잘 식별할 수 있도록 돕습니다. 그런 다음, 시각 토큰을 선택된 세그먼트에서 병합하여 중요한 잠재적 목표를 강조하는 공간 인식 모듈을 설계하고, 오디오와의 교차 모드를 통해 소리 인식 영역을 인식합니다. 최종적으로 이러한 모듈에서 추출된 중요한 시공간 단서를 통합하여 질문에 답을 합니다.

- **Performance Highlights**: 다양한 AVQA 벤치마크에서 광범위한 실험을 통해 해당 프레임워크가 오디오-비주얼 장면을 이해하고 복잡한 질문에 효과적으로 대답하는 데 뛰어나다는 것이 입증되었습니다. 코드도 공개되었습니다.



### 3D-GRES: Generalized 3D Referring Expression Segmentation (https://arxiv.org/abs/2407.20664)
Comments:
          Accepted by ACM MM 2024 (Oral), Code: this https URL

- **What's New**: 3D 공간에서 자연어 설명을 기반으로 특정 인스턴스를 분할하는 기존의 3D Referring Expression Segmentation (3D-RES) 접근 방법은 한 가지 대상만을 분할하는 데 제한이 있었습니다. 이에 대한 해결책으로, 우리는 Generalized 3D Referring Expression Segmentation (3D-GRES)를 도입하여 자연어 지침에 따라 여러 인스턴스를 분할하는 능력을 확장했습니다.

- **Technical Details**: 우리는 Multi-Query Decoupled Interaction Network (MDIN)을 제안했습니다. MDIN은 텍스트 기반의 Sparse Queries (TSQ)와 Multi-object Decoupling Optimization (MDO)이라는 두 가지 주요 구성 요소로 구성되어 있습니다. TSQ는 쿼리 초기화를 위해 주요 타겟에 분포된 희소 점구름(features)을 생성하며, MDO는 다중 객체 시나리오에서 각 타겟을 서로 다른 쿼리에 할당하면서 그들의 의미적 일관성을 유지합니다.

- **Performance Highlights**: 새로운 데이터 세트인 Multi3DRes를 구축하여 이 새로운 작업에 적응시켰습니다. 이 데이터 세트에 대한 종합적인 평가에서 기존 모델을 능가하는 실질적인 향상을 입증하였습니다. 벤치마크와 코드가 사용할 수 있게 되어 있으며, 복잡한 다중 객체 3D 장면 이해에 새로운 가능성을 열었습니다.



### DocXPand-25k: a large and diverse benchmark dataset for identity documents analysis (https://arxiv.org/abs/2407.20662)
- **What's New**: ID 문서 (identity document) 이미지 분석은 은행 계좌 개설이나 보험 가입과 같은 많은 온라인 서비스에서 필수적입니다. 이 논문에서는 DocXPand-25k 데이터셋을 소개합니다. 이 데이터셋은 사용자 정의 벡터 템플릿(vectorial templates)을 사용하여 생성된 24,994개의 풍부하게 라벨링된 ID 이미지로 구성됩니다. 이 데이터셋은 네 가지 신분증(identity cards), 두 가지 거주 허가증(residence permits), 세 가지 여권(passports) 디자인을 포함한 총 아홉 가지의 가상의 ID 디자인을 포함하고 있습니다.

- **Technical Details**: 이 데이터셋에 포함된 ID들은 인위적으로 생성된 개인 정보(이름, 날짜, 식별자, 얼굴, 바코드 등)를 특징으로 하며 시각적 레이아웃과 텍스트 내용의 다양성을 제공합니다. 실제 세계의 사진, 스캔본 및 ID 스크린샷에서 가져온 약 5.8k의 다양한 배경을 수집하여 배경의 다양성을 보장했습니다. 이 이미지를 생성하는 데 사용된 소프트웨어는 MIT 라이센스 하에 공개되었으며, 데이터셋은 CC-BY-NC-SA 4.0 License 하에 배포되었습니다.



### What makes for good morphology representations for spatial omics? (https://arxiv.org/abs/2407.20660)
- **What's New**: 이번 논문에서는 spatial omics와 imaging AI의 결합을 통해 조직의 공간적 유전자 발현 패턴을 보다 총체적으로 이해할 수 있는 새로운 프레임워크를 소개합니다. 이는 특히 유전자 발현 패턴과 연결된 형태학적 특징을 예측하고 분석하는 방식에 중점을 둡니다.

- **Technical Details**: 논문에서 소개된 프레임워크는 두 가지 방법으로 설명됩니다. 첫 번째는 형태학적 특징을 유전자 발현 패턴과 공간적으로 연관 짓는 '번역(translation)' 방법입니다. 이는 초고해상도 유전자 발현 맵을 생성하거나, 임상 H&E 염색 샘플에서 유전 정보를 추론하는데 사용될 수 있습니다. 두 번째는 형태학적 특징을 유전자 발현 패턴과 공간적으로 보완하는 '통합(integration)' 방법입니다. 이러한 특징은 특히 유전자 발현이 형태학적 변화보다 먼저 일어나는 경우, 또는 형태학적 변화가 유전자 발현 이후에 남아 있는 경우에 공간 영역을 정의하는 데 사용됩니다.

- **Performance Highlights**: 번역 및 통합 방법은 각각의 목적에 따라 유전자 발현 정보를 예측하거나 풍부하게 하는 데 유용합니다. 예를 들어, 번역 방법은 초고해상도 유전자 발현 맵 생성에 활용되어 좀 더 정밀한 유전자 분석을 가능하게 하고, 통합 방법은 기존 유전자 데이터를 보완하여 공간적 도메인을 정의하는 데 기여합니다.



### Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks (https://arxiv.org/abs/2407.20657)
Comments:
          Accepted to ECCV 2024, Project Page: this https URL

- **What's New**: 최근의 비전-언어(foundation models) 모델들, 예를 들어 CLIP,은 다양한 다운스트림(downstream) 작업 및 도메인에서 전이학습이 가능한 표현을 학습하는 데 뛰어난 성능을 보여주었습니다. 이러한 강력한 모델들이 등장함에 따라 이들의 능력을 어떻게 효과적으로 활용하여 복잡한 비전 작업을 해결할 것인가가 중요한 문제가 되었습니다. 이번 연구에서는 PDCL-Attack이라는 새로운 전이 공격(transfer attack) 방식을 제안합니다. 이 방법은 CLIP 모델을 활용하여 생성 모델 기반의 공격 프레임워크에서 생성된 적대적 교란(adversarial perturbations)의 전이성(transferability)을 증대시킵니다.

- **Technical Details**: 구체적으로, 우리는 텍스트의 의미 표현력(semantic representation power), 특히 입력 이미지의 정답 클래스 레이블(ground-truth class labels)을 이용한 효과적인 프롬프트 구동형 피처 가이던스(prompt-driven feature guidance)를 공식화했습니다. 우리의 지식에 따르면, 우리는 전이 가능한 생성 공격을 향상시키기 위해 프롬프트 학습(prompt learning)을 도입한 최초의 연구입니다.

- **Performance Highlights**: 다양한 크로스 도메인(cross-domain) 및 크로스 모델(cross-model) 환경에서 진행된 광범위한 실험에서는 우리의 접근 방식이 최첨단 방법(state-of-the-art methods)보다 우수함을 실증적으로 입증하였습니다.



### FACL-Attack: Frequency-Aware Contrastive Learning for Transferable Adversarial Attacks (https://arxiv.org/abs/2407.20653)
Comments:
          Accepted to AAAI 2024, Project Page: this https URL

- **What's New**: 이 논문에서는 딥 뉴럴 네트워크의 취약한 보안 문제를 해결하기 위해 주파수 영역에서 특징 대조(feature contrastive) 접근 방식을 도입하여 교차 도메인(cross-domain)과 교차 모델(cross-model) 설정에서 견고한 적대적 예시(adversarial examples)를 생성하는 방법을 탐구합니다.

- **Technical Details**: 제안된 두 가지 모듈은 훈련 단계에서만 사용됩니다. 첫 번째 모듈은 FADR(Frequency-Aware Domain Randomization) 모듈로, 도메인 변이성이 있는 저주파 및 고주파 성분을 무작위화(randomize)합니다. 두 번째 모듈은 FACL(Frequency-Augmented Contrastive Learning) 모듈로, 깨끗한 이미지와 왜곡된 이미지의 도메인 불변 중간 주파수 요소를 효과적으로 분리합니다. 이 두 모듈을 통해 견고한 적대적 예시를 생성합니다.

- **Performance Highlights**: 제안된 방법은 광범위한 교차 도메인 및 교차 모델 실험을 통해 생성된 적대적 교란(perturbations)의 강력한 이식성(transferability)을 입증하며, 추론 시간 복잡성(inference time complexity)을 유지합니다.



### Image Re-Identification: Where Self-supervision Meets Vision-Language Learning (https://arxiv.org/abs/2407.20647)
- **What's New**: 최근 대규모 비전-언어 사전 학습 모델(CLIP)이 이미지 재식별(ReID) 작업에서 인상적인 성능을 보였습니다. 본 연구에서는 이러한 CLIP 모델이 자기 지도 학습(self-supervision)을 통해 이미지 ReID 작업에 얼마나 도움이 될 수 있는지를 탐구했습니다. SVLL-ReID라는 새로운 모델을 제안하며, 이는 두 단계의 훈련 과정을 통해 자기 지도 학습과 사전 학습된 CLIP을 최초로 통합한 시도입니다.

- **Technical Details**: SVLL-ReID 모델은 두 가지 주요 관찰을 기반으로 합니다: 1) 첫 번째 훈련 단계에서 언어 자기 지도 학습(language self-supervision)을 도입하면 학습 가능한 텍스트 프롬프트(text prompts)가 더 구분 가능해집니다. 2) 두 번째 훈련 단계에서 비전 자기 지도 학습(vision self-supervision)을 도입하면 이미지 인코더에서 학습된 이미지 특징(image features)이 더 판별 가능해집니다. 이러한 관찰은 첫 번째 단계에서의 텍스트 프롬프트 학습이 언어 자기 지도 학습으로부터 혜택을 받을 수 있고, 두 번째 단계에서의 이미지 특징 학습이 비전 자기 지도 학습으로 혜택을 받을 수 있음을 시사합니다.

- **Performance Highlights**: SVLL-ReID는 구체적인 텍스트 레이블 없이 6개의 이미지 ReID 벤치마크 데이터셋에서 실험을 수행하여, 최신 성능(state-of-the-art)들과 비교했을 때 전반적으로 최고의 성능을 달성하였습니다. 코드는 공개될 예정입니다.



### Generalizing AI-driven Assessment of Immunohistochemistry across Immunostains and Cancer Types: A Universal Immunohistochemistry Analyzer (https://arxiv.org/abs/2407.20643)
- **What's New**: 최근 인공지능(AI)은 면역조직화학법(IHC) 평가의 어려움을 해결할 잠재적인 솔루션으로 떠오르고 있습니다. 이번 연구에서는 종양 및 IHC 타입에 관계없이 IHC 이미지를 해석할 수 있는 AI 모델인 Universal IHC (UIHC) 분석기를 개발했습니다. 이 모델은 PD-L1 또는 HER2로 염색된 다양한 암종의 데이터를 사용하여 훈련되었습니다.

- **Technical Details**: UIHC 모델은 다중 코호트(multi-cohort) 훈련 데이터를 사용하여 개발되었으며, 이는 기존의 단일 코호트(single-cohort) 모델과 비교하여 뛰어난 성능을 보여줍니다. 특히, PD-L1 및 HER2 염색 데이터 뿐만 아니라 c-MET 발현을 MET 돌연변이와 함께 정량적으로 평가하는 데도 효과적입니다.

- **Performance Highlights**: UIHC 모델은 보이지 않는 IHC 해석에 있어서 기존의 단일 코호트 모델보다 높은 Kappa 점수(0.578 vs. 최대 0.509)를 기록하였습니다. 또한, 다양한 양성 염색 기준 값에 대해 일관된 우수한 성능을 보였습니다. 정성적 분석을 통해 UIHC가 표현 수준에 따라 패치를 효과적으로 클러스터링한다는 것이 확인되었습니다.



### Effectively Leveraging CLIP for Generating Situational Summaries of Images and Videos (https://arxiv.org/abs/2407.20642)
Comments:
          38 pages, 12 figures. arXiv admin note: text overlap with arXiv:2307.00586

- **What's New**: 새로운 연구는 컴퓨터 비전 기반 상황 인식을 다루며, 멀티모달 모델 CLIP을 활용하여 ClipSitu라는 새로운 모델을 제안했습니다. 이 모델은 전체 미세 조정(fine-tuning) 없이도 상황 인식 및 현지화 과업에서 최첨단 성능을 달성합니다.

- **Technical Details**: ClipSitu는 CLIP 기반 이미지, 동사 및 역할 임베딩(embedding)을 사용하여 동사와 연관된 모든 역할을 수행하는 명사를 예측합니다. 이를 위해 크로스-어텐션 트랜스포머(cross-attention Transformer)인 ClipSitu XTF를 통해 시각적 토큰 표현과 의미적 역할 쿼리 간의 연결을 강화합니다. 또한, 동사별 역할 예측 모델을 도입하여 근사적으로 완벽한 정확도로 상황 요약을 생성하는 종단간(end-to-end) 프레임워크를 구상했습니다.

- **Performance Highlights**: ClipSitu 모델은 기존 방법들과 비교했을 때 상황 인식에서의 모호성을 줄이고, 구조화된 설명을 생성하여 더 높은 성능을 보였습니다. 이 모델은 이미지뿐만 아니라 비디오 상황 인식에서도 높은 성능을 발휘하며, 기존 최신 방법들과 유사한 성능을 보입니다.



### Spiking-DD: Neuromorphic Event Camera based Driver Distraction Detection with Spiking Neural Network (https://arxiv.org/abs/2407.20633)
Comments:
          Irish Machine Vision and Image Processing Conference (IMVIP) 2024

- **What's New**: 이 논문에서는 운전자 모니터링 시스템에서 이벤트 카메라(event camera)를 사용한 새로운 접근법을 소개합니다. 이 방법은 Computationally Efficient Spiking Neural Networks (SNN)을 활용하여 운전자 주의 분산을 감지하는 'Sensing without Seeing' 개념을 도입합니다. 이는 이벤트 카메라 데이터와 SNN을 결합하여 운전자 주의 분산을 탐지하는 최초의 연구입니다.

- **Technical Details**: 이 연구에서 제안한 Spiking-DD 네트워크는 이벤트 카메라와 최적화된 네트워크를 결합함으로써 전력 효율, 저지연성, 향상된 프라이버시, 언더샘플링 방지와 같은 이점들을 극대화합니다. 이벤트 카메라의 빠른 반응과 저전력 소모 특성을 활용하여 운전자의 주의 분산 상태를 효율적으로 감지합니다.

- **Performance Highlights**: Spiking-DD 네트워크는 현재의 이벤트 기반 방법론보다 더 적은 파라미터를 사용하면서도 더 높은 정확도를 보여줍니다. 최신(state-of-the-art) 성능을 달성하여 도로 안전을 강화하고 사고율을 줄이는 데 기여할 수 있는 가능성이 있습니다.



### SharkTrack: an accurate, generalisable software for streamlining shark and ray underwater video analysis (https://arxiv.org/abs/2407.20623)
- **What's New**: 새로운 연구에서는 Elasmobranch (상어와 가오리) 개체군 감시를 위한 SharkTrack이라는 AI 강화 BRUVS 분석 소프트웨어를 개발했습니다. 이 소프트웨어는 Convolutional Neural Networks (CNNs)와 Multi-Object Tracking 기술을 이용해 elasmobranch를 탐지하고 추적합니다.

- **Technical Details**: SharkTrack은 BRUVS 영상을 분석하여 elasmobranch 종을 수동으로 분류하고, 상대적 풍부도를 측정하는 표준 지표인 MaxN을 계산하는 어노테이션 파이프라인을 제공합니다. 이 소프트웨어는 학습 중에 본 적 없는 지역의 BRUVS 영상에서 테스트되었습니다. SharkTrack은 207시간의 영상에 대해 89%의 정확도로 MaxN을 계산했으며, 수동 분석 시간은 한 시간의 영상당 두 분 정도로 97% 감소했습니다.

- **Performance Highlights**: SharkTrack은 기존의 수동 방법과 비교하여 97% 이상의 분석 시간 절감을 제공하며, 다양한 해양 생태계와 elasmobranch 종에 대한 응용이 가능하다는 점에서 기존 모델들을 능가합니다. 소프트웨어와 다양한 데이터셋을 공개하여 해양 보호 연구에 중요한 기여를 할 것으로 기대됩니다.



### Knowledge Fused Recognition: Fusing Hierarchical Knowledge for Image Recognition through Quantitative Relativity Modeling and Deep Metric Learning (https://arxiv.org/abs/2407.20600)
- **What's New**: 이 논문에서는 이미지 클래스에 대한 계층적 사전 지식을 효과적으로 융합하여 이미지 인식 성능을 향상시키는 새로운 딥 메트릭 학습(deep metric learning) 기반 방법을 제안합니다. 이 기법은 계층적 지식(hierarchical knowledge)을 정량적(relativity)에 맞춰 모델의 잠재 공간(latent space)과 지식 공간(knowledge space) 내 거리를 정렬하는 새로운 트리플릿 손실 함수(triplet loss function)을 도입합니다.

- **Technical Details**: 기존 딥 메트릭 학습 방법은 주로 이미지 클래스 간의 질적 상대성(qualitative relativity)에 중점을 두었지만, 이 논문에서는 정량적인 상대성을 고려합니다. 이 방법은 트리플릿 손실 함수를 통해 모델의 잠재 공간과 지식 공간 내 거리가 정렬되도록 합니다. 이를 통해 계층적 지식을 효과적으로 융합하여 인식 성능을 향상시킵니다. 제안된 방법은 CIFAR-10, CIFAR-100, Mini-ImageNet, 그리고 ImageNet-1K 데이터셋에서 실험적으로 검증되었습니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 기존의 베이스라인 및 기존 방법을 능가하는 이미지 인식 성능을 보여주었습니다. 특히, CIFAR-10, CIFAR-100, Mini-ImageNet, ImageNet-1K 데이터셋에서 유의미한 성능 향상이 확인되었습니다.



### EgoSonics: Generating Synchronized Audio for Silent Egocentric Videos (https://arxiv.org/abs/2407.20592)
Comments:
          preprint

- **What's New**: EgoSonics는 무음의 자이로센서 비디오(egocentric videos)에 의미 있는 오디오 트랙을 생성하는 방법을 소개합니다. 이 기술은 가상 현실, 보조 기술, 기존 데이터셋의 보강 등 새로운 응용 가능성을 열어줍니다. 기존 연구는 주로 연설, 음악, 충격음 등에 한정되어 있었지만, EgoSonics는 이러한 한계를 뛰어넘어 더 넓은 범위의 오디오 주파수를 포착합니다.

- **Technical Details**: EgoSonics는 조건부 오디오 합성에서 잠재 확산 모델(latent diffusion models)의 강점을 활용합니다. 오디오와 비디오 데이터를 생성에 적합한 형태로 인코딩 및 처리한 뒤, 이 데이터를 사용하여 입력된 비디오의 의미를 포착하는 오디오 트랙을 생성합니다. 추가적으로 제안된 SyncroNet은 ControlNet 위에 구축되어 합성된 오디오와의 시간 동기화를 가능하게 하는 제어 신호를 제공합니다.

- **Performance Highlights**: EgoSonics는 광범위한 평가를 통해 기존 연구보다 뛰어난 오디오 품질을 보여주며, 새롭게 제안된 동기화 평가 방법에서도 우수한 성능을 보였습니다. 또한, 비디오 요약(video summarization)을 개선하는 등의 다양한 응용 프로그램에서도 모델의 효과를 입증했습니다.



### Image-based Detection of Segment Misalignment in Multi-mirror Satellites using Transfer Learning (https://arxiv.org/abs/2407.20582)
- **What's New**: 이 논문에서 우리는 멀티미러 위성, 특히 향후 CubeSat 디자인과 제임스 웹 우주 망원경(JWST)에서 세그먼트 불일치를 감지하는 전이 학습(transfer learning) 기반 시스템을 소개합니다. 환경적 요인들로 인해 미러 세그먼트가 불일치할 때 이미지가 왜곡되어 '고스트 이미지(ghost image)'라고 불리는 자체의 이동된 복사본이 나타날 수 있습니다.

- **Technical Details**: 세그먼트 불일치를 감지하기 위해, 우리는 대규모 이미지 모델을 이전 학습(pre-trained)하여, 위성 이미지의 회색조 패치에서 Fast Fourier Transform (FFT)을 적용했습니다. 다중 미러 디자인은 임의의 수의 미러를 사용할 수 있으며, 본 실험에서는 4, 6, 8개의 세그먼트를 가진 모의 CubeSat로 테스트를 수행했습니다. 위성이 불일치한 세그먼트를 가졌는지 여부와 얼마나 많은 세그먼트가 불일치했는지를 판단하기 위해 시스템 설계를 고안했습니다.

- **Performance Highlights**: 고스트 이미지의 강도는 불일치한 세그먼트 수에 비례합니다. 강도 분류(intensity classification)를 위해 훈련된 모델은 N-1 세그먼트를 분류하려 했으며, 이진 모델(binary models)은 8개 클래스에서 98.75%의 분류 정확도를 달성했고, 강도 분류 모델은 98.05%의 정확도를 기록했습니다.



### Monocular Human-Object Reconstruction in the Wild (https://arxiv.org/abs/2407.20566)
Comments:
          Accepted by MM '24

- **What's New**: 이번 연구는 실세계 이미지에서 2D 정보만을 활용하여 3D 인간-객체 상호작용의 공간적 관계를 학습하는 방법을 제안하고 있습니다. 이는 통제된 환경에서 수집된 데이터셋에서 학습된 기존 모델들이 실세계 시나리오에 잘 일반화되지 않는 문제를 극복하기 위함입니다.

- **Technical Details**: 제안된 방법은 2D 이미지에서 3D 인간-객체 공간적 관계에 대한 사전 지식을 학습하기 위해 Flow 기반 신경망(neural network)을 사용합니다. 이 모델은 2D 인간-객체 키포인트(keypoint) 레이아웃과 각 이미지의 뷰포트(viewport)의 사전 분포(prior distribution)를 학습합니다. 학습된 사전 지식은 후속 최적화 단계(post-optimization stage)에서 인간과 객체 간의 상대적인 자세를 조정하는 데 활용됩니다.

- **Performance Highlights**: 실내 BEHAVE 데이터셋과 실외 WildHOI 데이터셋을 통해 제안된 방법을 검증하고 벤치마크 테스트를 수행했습니다. 실험 결과, 제안된 방법은 2D 레이아웃 정보만을 사용했음에도 불구하고, BEHAVE 데이터셋에서는 완전한 3D 감독학습(supervised) 방법들과 비슷한 성능을 보였으며, 실세계 이미지에서는 이전 방법들에 비해 일반성과 상호작용 다양성에서 우수한 성능을 보였습니다.



### Pyramid Coder: Hierarchical Code Generator for Compositional Visual Question Answering (https://arxiv.org/abs/2407.20563)
Comments:
          Accepted to the IEEE International Conference on Image Processing (IEEE ICIP) 2024

- **What's New**: 이 논문에서는 Programmatic Visual Question Answering (PVQA) 모델을 개선하기 위해 새로운 프레임워크인 PyramidCoder를 소개했습니다. PyramidCoder는 계층적 구조를 가지고 있으며, 각각의 계층은 질문 재구성(query rephrasing), 코드 생성(code generation), 답변 통합(answer aggregation)이라는 고유한 목적을 가지고 있습니다. 이 프레임워크는 고정된 Large Language Model (LLM)과 사전 정의된 프롬프트를 사용하여 추가적인 학습 없이 다양한 LLM 아키텍처에서 유연하게 적용될 수 있습니다.

- **Technical Details**: PyramidCoder는 세 가지 계층으로 구성된 프레임워크로, 각 계층은 다음과 같은 역할을 합니다: 1. Query Rephrasing: 질문을 재구성하여 이해하기 쉽게 합니다. 2. Code Generation: 재구성된 질문을 기반으로 실행 가능한 코드를 생성합니다. 3. Answer Aggregation: 생성된 코드의 결과를 통합하여 최종 답변을 도출합니다. 이 과정에서 하나의 고정된 LLM과 사전에 정의된 프롬프트를 사용하므로 추가 학습이 필요 없습니다.

- **Performance Highlights**: PyramidCoder는 최신 기술을 적용한 PVQA 모델과 비교했을 때, GQA 데이터셋에서 적어도 0.5%, VQAv2 데이터셋에서 1.4%, NLVR2 데이터셋에서 2.9%의 정확도 향상을 이루었습니다.



### StackFLOW: Monocular Human-Object Reconstruction by Stacked Normalizing Flow with Offs (https://arxiv.org/abs/2407.20545)
Comments:
          Accepted by IJCAI-23

- **What's New**: 이번 연구에서는 단안 이미지(monocular images)에서 3D 인간-객체 상호작용(human-object interaction)을 인지하기 위해, 인간 메시(human mesh)와 객체 메시(object mesh) 표면에서 밀집하게 샘플링된 앵커에서의 인간-객체 오프셋(Human-Object Offset)을 사용하는 새로운 방법을 제안하였습니다. 이 방법은 이전 연구들에서 사용된 접촉 지도(contact map)나 암시적 거리 필드(implicit distance field)보다 더 간단하고 효율적으로 고도로 상세한 공간적 상관관계를 인코딩할 수 있습니다.

- **Technical Details**: 제안된 표현 방식을 기반으로, 이미지로부터 인간-객체 공간 관계의 후분포(posterior distribution)를 추론하기 위해 Stacked Normalizing Flow (StackFLOW)를 제안합니다. 최적화 단계에서는 이 후분포를 기반으로 샘플의 가능성을 극대화하고 2D-3D 대응 재투영 손실(reprojection loss)을 최소화하여 인간의 자세(human body pose)와 객체의 6D 자세를 미세 조정(finetune)합니다.

- **Performance Highlights**: 광범위한 실험 결과, 우리의 방법이 도전적인 BEHAVE 및 InterCap 데이터셋에서 탁월한 성과를 달성함을 보여줍니다.



### HandDAGT: A Denoising Adaptive Graph Transformer for 3D Hand Pose Estimation (https://arxiv.org/abs/2407.20542)
Comments:
          Accepted as a conference paper to European Conference on Computer Vision (ECCV) 2024

- **What's New**: 이 논문은 새로운 방법인 Denoising Adaptive Graph Transformer, HandDAGT를 제안하여 3D 손 자세 추정을 개선하려고 합니다. 이 방법은 입력 패치로부터 효과적인 기하학적 특징을 탐색하는 변환기 구조를 활용하며, 키포인트 추정을 위해 새로운 어텐션 메커니즘을 통합합니다. 또한, 모델의 강인성과 정확도를 높이기 위해 새로운 디노이징 훈련 전략을 도입합니다.

- **Technical Details**: HandDAGT는 입력 패치로부터 기하학적 특징을 탐색하는 Transformer 구조를 사용합니다. 그리고 어텐션 메커니즘을 통해 키네마틱 대응 및 국부 기하학적 특징의 기여를 적응적으로 가중치로 부여하여 추정합니다. 이러한 특징은 손의 자가 장막(self-occlusion) 및 상호작용하는 객체와의 내부 장막(intra-occlusion) 상황에서 모델이 키네마틱 및 지역 정보를 적절히 사용하게 하여, 모델의 강인성과 정확성을 증가시킵니다.

- **Performance Highlights**: 실험 결과, 제안된 모델은 네 가지 도전적인 손 자세 벤치마크 데이터셋에서 기존 방법들을 크게 능가하는 성능을 보였습니다. 코드와 사전 학습된 모델은 공개되어 있습니다.



### Markers Identification for Relative Pose Estimation of an Uncooperative Targ (https://arxiv.org/abs/2407.20515)
Comments:
          2024 AAS/AIAA Astrodynamics Specialist Conference

- **What's New**: 이 논문은 ESA(Environmental Satellite)의 안전한 궤도 이탈을 위해 추격 우주선의 이미지 처리와 Convolutional Neural Networks(CNNs)를 사용하여 구조 마커를 감지하는 새로운 방법을 소개합니다. 이는 자율적인 우주 쓰레기 제거를 지원하는 획기적인 방법입니다.

- **Technical Details**: 고급 이미지 전처리기술(image pre-processing techniques)인 노이즈 추가(noise addition)와 블러링(blurring)을 사용하여 마커 검출의 정확도와 견고성을 향상시키는 기법을 적용했습니다.

- **Performance Highlights**: 초기 결과는 자율적인 우주 쓰레기 제거에 대해 유망한 가능성을 보여주며, 실제 우주 임무에서 견고하고 자율적인 시스템을 구현함으로써 우주 파편 제거 작업의 안전성과 효율성을 크게 향상시킬 수 있음을 시사합니다.



### Interpreting and Mitigating Hallucination in MLLMs through Multi-agent Deba (https://arxiv.org/abs/2407.20505)
- **What's New**: 이번 논문에서는 다중 모달 언어 모델(Multimodal Large Language Models, MLLMs)의 환각(hallucination) 문제를 해결하기 위해 새로운 접근 방식을 제안했습니다. 저자들은 MLLMs의 환각 발생 원인을 느린 사고(slow-thinking) 및 발산적 사고(divergent-thinking)의 부족으로 설명하며, 이를 극복하기 위해 자기 성찰(self-reflection)과 다중 에이전트 토론(multi-agent debate) 접근 방식을 도입했습니다.

- **Technical Details**: 제안된 접근 방식은 두 가지 주요 구성 요소로 나뉩니다. 첫째, 자기 성찰(self-reflection) 방식은 모델이 더 느리게 사고하고 자가 수정하는 능력을 강화합니다. 둘째, 다중 에이전트 토론(multi-agent debate) 방식은 여러 에이전트가 다양한 관점을 공유하며 발산적 사고를 촉진하는 기법입니다. 이러한 방식은 단순히 환각 여부를 판단하는 것을 넘어서 어떤 이미지 영역이 환각을 유발했는지와 그 이유를 해석하는 데 기여합니다.

- **Performance Highlights**: 다양한 벤치마크 실험 결과, 제안된 접근 방식은 여러 MLLMs에서의 환각 완화 성능을 입증했습니다. 특히 제안된 방법은 환각을 완화할 뿐만 아니라 창의성과 환각을 구별하는 능력을 갖추고 있으며, MLLMs의 창의성 평가 방법도 제시했습니다.



### Restoring Real-World Degraded Events Improves Deblurring Quality (https://arxiv.org/abs/2407.20502)
- **What's New**: DVS(Dynamic Vision Sensor)의 고속성과 낮은 지연시간 덕분에 모션 디블러링(motion deblurring)에 자주 사용됩니다. 그러나 실제 환경에서는 이벤트(event)의 열화로 인해 디블러링 결과에 많은 아티팩트가 발생합니다. 이 문제를 해결하기 위해 새로운 모델인 RDNet을 제안했습니다. RDNet은 이벤트의 열화를 모델링하고 고품질 디블러링을 촉진하는 새로운 접근 방식을 활용합니다.

- **Technical Details**: RDNet은 두 단계로 구성됩니다. 첫 번째 단계에서는 이벤트의 열화 메커니즘을 분석하고, 이를 기반으로 페어드 이벤트(paired events)를 시뮬레이트합니다. 이러한 페어드 이벤트는 복원 모델(training the restoration model)을 학습하는데 사용됩니다. 두 번째 단계에서는 첫 번째 단계에서 복원된 이벤트를 가이드로 사용해 디블러링을 수행합니다. 또한, 다양한 열화 수준의 이벤트를 포함하는 새로운 실세계 데이터셋인 DavisMCR을 제시했습니다. 이 데이터셋은 환경 밝기 및 목표 객체 대비를 조작하여 수집되었습니다.

- **Performance Highlights**: RDNet은 합성 데이터셋(GOPRO), 실세계 데이터셋(REBlur), 제안된 데이터셋(DavisMCR)에서 실험을 수행했습니다. 결과적으로 RDNet은 기존의 이벤트 디노이즈(event denoising) 방법보다 이벤트 복원 성능이 뛰어나며, 최첨단 방법들과 비교해 디블러링에서도 우수한 성능을 보였습니다. DavisMCR 데이터셋은 링크를 통해 제공됩니다.



### Weakly Supervised Intracranial Hemorrhage Segmentation with YOLO and an Uncertainty Rectified Segment Anything Mod (https://arxiv.org/abs/2407.20461)
Comments:
          Manuscript was accepted at SWITCH2024. 10 pages, 2 figures

- **What's New**: 본 논문에서는 약한 감독(weakly supervised) 학습을 활용한 새로운 두개내 출혈(ICH) 분할 기법을 제안했습니다. 이 방법은 YOLO 객체 감지 모델과 불확실성 조정된 Segment Anything Model (SAM)을 결합하여, 큰 데이터셋이나 정교한 세분화 데이터 없이도 높은 정확도의 ICH 감지를 가능하게 합니다.

- **Technical Details**: 우리는 YOLOv8 모델을 사용하여 자동으로 상자(box)와 점(point) 프롬프트를 생성했으며, 이를 통해 SAM이 CT 스캔에서 ICH를 감지하고 분할할 수 있도록 했습니다. 제안된 프레임워크에는 YOLO-SAM-BBox, YOLO-SAM-Point, YOLO-SAM-PointBBox 세 가지 변형이 포함되며, 각각 상자 프롬프트, 점 프롬프트, 상자와 점 프롬프트의 조합을 사용하여 ICH 분할을 수행합니다. 또한, 프롬프트 생성 시 발생하는 불확실성을 해결하기 위해 불확실성 조정 전략을 사용했습니다.

- **Performance Highlights**: 제안된 방법은 ICH 감지에서 0.933의 높은 정확도와 0.796의 AUC를 기록했으며, ICH 분할에서는 평균 Dice 점수 0.629를 달성했습니다. 이는 기존의 약한 감독 및 일반적인 지도 학습 방법(예: UNet, Swin-UNETR)을 능가하는 성과입니다.



### Learning Feature-Preserving Portrait Editing from Generated Pairs (https://arxiv.org/abs/2407.20455)
- **What's New**: 이 논문에서는 인물 사진 편집(portrait editing)에서 주체의 특징(예: 정체성)을 보존하는데 어려움이 있는 기존 기법들을 개선하기 위한 새로운 방법을 제안합니다. 자동 생성된 페어 데이터를 활용한 학습 기반의 방법으로, 변경되지 않은 주체의 특징을 보존하면서 원하는 편집을 수행할 수 있습니다.

- **Technical Details**: 특히, 저렴한 비용으로 필요한 편집을 위한 합리적인 학습 쌍을 생성하는 데이터 생성 프로세스를 설계하였습니다. 이러한 쌍을 바탕으로 Multi-Conditioned Diffusion Model을 도입하여 편집 방향을 효과적으로 학습하고 주체의 특징을 보존합니다. 추론 과정(Inference)에서 우리 모델은 정확한 편집 마스크를 생성하여 세부 주체 특징을 보존하는데 기여합니다.

- **Performance Highlights**: 코스튬 편집과 만화 표정 편집 실험에서 우리 방법은 정량적, 정성적으로 최첨단 품질(state-of-the-art quality)에 도달했습니다.



### MEVDT: Multi-Modal Event-Based Vehicle Detection and Tracking Datas (https://arxiv.org/abs/2407.20446)
- **What's New**: MEVDT(Multi-Modal Event-based Vehicle Detection and Tracking) 데이터셋을 소개합니다. 이 데이터셋은 Dynamic and Active-Pixel Vision Sensor(DAVIS) 240c 하이브리드 이벤트 기반 카메라를 사용하여 교통 장면의 이벤트 데이터와 그레이스케일 이미지를 동기화된 스트림으로 제공합니다. 연구자들이 실시간 자동차 환경에서 객체 검출 및 추적 알고리즘을 개발하고 평가할 수 있도록 고품질의 실제 주석 데이터셋을 제공하는 것을 목표로 합니다.

- **Technical Details**: MEVDT 데이터셋은 63개의 멀티모달 시퀀스, 약 13,000장의 이미지, 500만 개의 이벤트, 10,000개의 객체 라벨, 85개의 고유 객체 추적 궤적을 포함하고 있습니다. 또한, 객체 분류, 픽셀 단위의 정밀 경계 상자, 고유 객체 ID가 포함된 수동 주석된 그라운드 트루스(ground truth) 라벨도 제공되며, 라벨링 주파수는 24Hz입니다.

- **Performance Highlights**: MEVDT 데이터셋은 이벤트 기반 비전(event-based vision) 연구를 한 단계 발전시키기 위해 설계되었으며, 실시간 자동차 환경에서 객체 검출 및 추적 알고리즘의 성능을 극대화하는 데 필요한 고품질의 실제 주석 데이터를 제공합니다.



### BaseBoostDepth: Exploiting Larger Baselines For Self-supervised Monocular Depth Estimation (https://arxiv.org/abs/2407.20437)
- **What's New**: 이번 연구에서는 다중 베이스라인(multi-baseline) 스테레오 깊이 추정(stereo depth estimation)에서 베이스라인 간격을 늘리면 깊이 추정의 정확도(accuracy)가 크게 향상된다는 기존 이해와 달리, 더 큰 프레임 간격(frame separation) 사용 시 다양한 요인으로 인해 깊이 품질이 저하된다는 것을 보였습니다. 이를 해결하기 위해, 새롭게 제안된 BaseBoostDepth 알고리즘은 커리큘럼 학습(curriculum learning) 최적화 전략을 도입하여 더 큰 프레임 간격을 효과적으로 활용합니다.

- **Technical Details**: BaseBoostDepth는 커리큘럼 학습에서 영감을 받아 크게 나누어진 프레임을 활용하지만, 이는 단독으로는 충분하지 않으므로 포즈 추정(pose estimation) 정확도를 높이기 위해 점진적 포즈 추정(incremental pose estimation)을 도입했습니다. 또한, 모델의 강건성을 향상시키기 위해 포즈 추정에 오류를 추가하여 재구성(error-induced reconstructions)을 최적화하는 방식을 도입했습니다.

- **Performance Highlights**: 결과적으로, 제안된 깊이 네트워크는 KITTI와 SYNS-patches 데이터셋에서 이미지(image-based), 엣지(edge-based), 포인트 클라우드(point cloud-based) 기반 지표들 모두에서 최첨단 성능(state-of-the-art performance)을 달성했으며, 테스트 시 계산 복잡도(computational complexity)를 증가시키지 않았습니다.



### Mean Opinion Score as a New Metric for User-Evaluation of XAI Methods (https://arxiv.org/abs/2407.20427)
Comments:
          Supported by organization Laboratoire Bordelais de Recherche en Informatique, 15 pages, 4 figures, 3 tables

- **What's New**: 이 논문은 Mean Opinion Score (MOS)를 XAI (설명 가능한 인공지능) 후처리 설명자의 사용자 중심 평가 메트릭으로 사용하는 것에 대해 조사하고 있습니다. MOS를 측정하기 위해 의도적으로 왜곡된 이미지의 설명 맵과 함께 사용자를 대상으로 실험을 제안했습니다.

- **Technical Details**: 세 가지 특징 귀속 방법(feature attribution methods) - Grad-CAM (Gradient-weighted Class Activation Mapping), MLFEM (Multi-Layered Feature Explanation Method), FEM (Feature Explanation Method) - 을 이 메트릭으로 비교했습니다. 자동 메트릭과의 상관 관계는 Spearman의 순위 상관 계수를 통해 연구되었습니다.

- **Performance Highlights**: MLFEM의 MOS는 자동 메트릭 IAUC (Insertion Area Under Curve)와 DAUC (Deletion Area Under Curve) 와 가장 높은 상관 관계를 나타냈습니다. 그러나 전체적인 상관 관계는 제한적이며, 이는 자동 메트릭과 사용자 중심 메트릭 간의 합의 부족을 강조합니다.



### Dense Self-Supervised Learning for Medical Image Segmentation (https://arxiv.org/abs/2407.20395)
Comments:
          Accepted at MIDL 2024

- **What's New**: 이번 연구는 Pix2Rep이라는 self-supervised learning (SSL)을 활용한 새로운 few-shot segmentation 접근법을 제안합니다. 이는 주석(annotation)의 부담을 줄이기 위해, 주석이 없는 이미지에서도 강력한 픽셀 수준의 표현을 학습할 수 있도록 합니다.

- **Technical Details**: Pix2Rep은 대조적 SSL(contrastive SSL)에서 전체 이미지에 대한 새로운 픽셀 수준의 손실 함수(loss)와 사전 학습(pre-training) 패러다임을 도입했습니다. 이는 일반적인 encoder-decoder 딥러닝 백본(e.g., U-Net)에 적용됩니다. 대부분의 SSL 기법이 강도와 공간 이미지 증강(augmentation) 하에서 학습된 이미지 수준 표현의 불변성을 강제하는 반면, Pix2Rep은 픽셀 수준 표현의 등가성(equivariance)을 강제합니다.

- **Performance Highlights**: 이번 연구는 심장 MRI 세분화 임무를 통해 프레임워크를 입증했습니다. 결과적으로, 기존의 반지도 학습(semi-) 및 자가 지도 학습(self-supervised) 접근법보다 성능이 향상되었음을 보여줍니다. 완전 감독된 U-Net 기준에 비해 동일한 성능에서 주석 부담이 5배 감소를 나타냈습니다. 이는 one-shot segmentation에서 linear-probing 시 30%, fine-tuning 시 31%의 DICE 개선을 포함합니다. 마지막으로, Pix2Rep 개념을 Barlow Twins 비대조 SSL(non-contrastive SSL)과 통합하여 더욱 향상된 세분화 성능을 달성했습니다.



### Alignment Scores: Robust Metrics for Multiview Pose Accuracy Evaluation (https://arxiv.org/abs/2407.20391)
- **What's New**: 본 연구는 카메라 포즈의 정확성을 평가하기 위한 새로운 세 가지 지표인 Translation Alignment Score (TAS), Rotation Alignment Score (RAS), Pose Alignment Score (PAS)를 제안합니다. TAS는 회전을 독립적으로 번역 정확도를 평가하고, RAS는 번역을 독립적으로 회전 정확도를 평가합니다. PAS는 이 두 점수의 평균으로, 번역과 회전의 결합 정확성을 평가합니다.

- **Technical Details**: TAS는 네 단계로 계산됩니다: (1) 가장 가까운 짝 간 거리의 상위 사분위수, $d$, 찾기. (2) 추정된 궤적을 정확한 궤적에 맞추기 위한 강력한 등록 방법을 사용하여 정렬. (3) 모든 거리 오차를 수집하고, $0.01d$에서 $d$까지 다양한 임계값에 대해 누적 빈도를 얻습니다. (4) 이러한 누적 빈도를 합산하고 이론적인 최대값이 1이 되도록 정규화. TAS는 다음과 같은 실질적인 장점을 가지고 있습니다: (1) 이상치와 공선 운동에 강함, (2) 다른 데이터셋에 대해 매개변수를 조정할 필요가 없음. RAS는 TAS와 유사한 방식으로 계산되며, 기존의 회전 지표보다도 이상치에 대해 더 강건함을 보여줍니다.

- **Performance Highlights**: 제안된 지표들은 광범위한 시뮬레이션을 통해 검증되었으며, 각각의 장점과 단점에 대한 심도 있는 논의가 제공되었습니다.



### A Model Generalization Study in Localizing Indoor Cows with COw LOcalization (COLO) datas (https://arxiv.org/abs/2407.20372)
Comments:
          17 pages, 7 figures

- **What's New**: 새로운 연구는 정밀 축산 농업(PLF)에서 소를 감지하기 위한 객체 탐지 모델 YOLOv8과 YOLOv9의 일반화 능력을 실내 프리스톨 우사 절차에서 조사했습니다. 'COws LOcalization'(COLO)라는 새로운 공개 데이터셋을 이용하여 모델 복잡성과 조명 조건 및 카메라 각도 변화가 모델의 일반화 성능에 미치는 영향을 탐구했습니다.

- **Technical Details**: 연구는 세 가지 주요 가설을 통해 진행되었습니다: (1) 모델의 일반화는 조명 조건과 카메라 각도 변화에 균등하게 영향을 받는다; (2) 높은 모델 복잡성은 더 나은 일반화 성능을 보장한다; (3) 관련 작업에서 훈련된 사용자 초기 가중치(custom initial weights)로 미세 조정하면 항상 탐지 작업의 장점을 가져온다. 결과는 옆면에서 촬영한 이미지에서 소를 감지하는 데 상당한 어려움이 있으며, 다양한 카메라 각도를 포함하는 것이 얼마나 중요한지 강조했습니다.

- **Performance Highlights**: 높은 모델 복잡성이 반드시 성능 향상을 의미하지 않으며, 최적의 모델 구성은 특정 작업과 데이터셋에 크게 의존한다는 것을 발견했습니다. 마지막으로, 관련 작업에서 훈련된 사용자 초기 가중치로 미세 조정하는 것이 이점이 있는 반면, 단순 모델은 이러한 접근 방식에서 동일한 이점을 얻지 못합니다. 사전 훈련된 가중치를 활용하여 간단한 모델을 훈련하는 것이 더 효율적입니다. 본 연구는 적응형 방법과 고급 데이터 증대를 통해 일반성과 견고성을 향상시키는 것에 주안점을 두고 있습니다.



### BRIDGE: Bridging Gaps in Image Captioning Evaluation with Stronger Visual Cues (https://arxiv.org/abs/2407.20341)
Comments:
          ECCV 2024

- **What's New**: 차세대 이미지 캡셔닝 평가 지표로 BRIDGE를 제안합니다. 이 지표는 인간의 판단과 더 정확하게 일치시키기 위해 기존 지표들(CIDEr, CLIP-Score)의 한계를 극복하고자 했습니다. 특히, 브리지는 참조 캡션(referece captions)을 필요로 하지 않는 새로운 학습 가능한 평가 지표로, 시각적 특징을 밀집 벡터화하고 이를 다중 모달(lmulti-modal) 가상 캡션으로 통합합니다.

- **Technical Details**: BRIDGE는 시각적 특징을 밀집 벡터(dense vectors)로 매핑(mapping)하는 혁신적인 모듈을 사용합니다. 이러한 벡터들은 평가 과정 중에 구축된 다중 모달 가상 캡션에 통합됩니다. 이는 참조 캡션 없이 입력 이미지의 정보를 적절히 포함시켜주며, 인간 심사와 기계 생성 캡션 사이의 격차를 줄이는 기술입니다.

- **Performance Highlights**: 여러 데이터셋을 대상으로 한 실험에서 BRIDGE는 기존의 참조 캡션이 필요 없는 평가 점수(reference-free evaluation scores)와 비교해 최첨단 성능을 달성했습니다. 또한, 해당 연구의 소스 코드와 학습된 모델은 공개되어 있어, 이 기술의 활용도가 높아질 전망입니다.



### Contrasting Deepfakes Diffusion via Contrastive Learning and Global-Local Similarities (https://arxiv.org/abs/2407.20337)
Comments:
          ECCV 2024

- **What's New**: 새로운 연구에서는 CoDE (Contrastive Deepfake Embeddings)라는 혁신적인 임베딩 공간을 제안합니다. 이 임베딩 공간은 딥페이크(Deepfake) 탐지를 위해 특별히 설계되었으며, 기존 CLIP 엔코딩 공간의 한계를 극복합니다.

- **Technical Details**: CoDE는 대비 학습(contrastive learning)을 통해 글로벌-로컬 유사성을 강제하며 훈련됩니다. 연구팀은 확산 모델(diffusion models)에 의해 생성된 이미지에 중점을 두고 4개의 다른 생성기를 사용하여 생성된 920만 개의 이미지가 포함된 종합 데이터셋을 생성했습니다.

- **Performance Highlights**: CoDE는 새로 수집된 데이터셋에서 최첨단(state-of-the-art) 정확도를 달성하였으며, 보지 못한 이미지 생성기에도 뛰어난 일반화 능력을 보여주었습니다. 연구의 소스 코드, 훈련된 모델 및 데이터셋은 공개되어 있습니다.



### Sun Off, Lights On: Photorealistic Monocular Nighttime Simulation for Robust Semantic Perception (https://arxiv.org/abs/2407.20336)
Comments:
          Submitted for review

- **What's New**: 새로운 연구 'Sun Off, Lights On (SOLO)'는 주간 이미지로부터 현실적인 야간 이미지를 생성하는 방법을 제안합니다. 이 방법은 3D 공간에서 작동하여 주간 이미지의 3D 기하학, 소재, 광원 위치를 추정하고, 확률적으로 광원을 배치하여 표준 레이 트레이싱(ray tracing)을 실행하여 야경을 재조명합니다.

- **Technical Details**: SOLO는 입력된 주간 이미지에서 3D 기하학, 소재 및 광원 위치를 명시적으로 추정한 후, 의미론적 정보에 근거하여 광원을 확률적으로 배치합니다. 그후 표준 레이 트레이싱을 통해 광원과 물체의 상호작용을 계산하여 현실적인 야경 이미지를 생성합니다. 이는 기존의 데이터 기반 또는 수작업 기법보다 높은 현실감을 제공합니다.

- **Performance Highlights**: SOLO가 생성한 야경 이미지는 시각적 품질과 포토리얼리즘(photorealism) 측면에서 기존 방법보다 우수하며, 주간-야간 적응(day-to-night adaptation)에서 의미론적 야간 세분화(semantic nighttime segmentation)에 더 유리한 것으로 입증되었습니다.



### Utilizing Generative Adversarial Networks for Image Data Augmentation and Classification of Semiconductor Wafer Dicing Induced Defects (https://arxiv.org/abs/2407.20268)
Comments:
          Accepted for: 2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)

- **What's New**: 반도체 제조 공정에서 웨이퍼 다이싱(wafer dicing) 과정은 결함에 취약하여 수율(yield)에 큰 영향을 미칩니다. 이 논문에서는 딥 신경망(deep neural networks)을 이용한 시각 검사 시스템에서 발생하는 데이터 부족 문제를 해결하기 위해, 생성적 적대 신경망(GAN, Generative Adversarial Networks)을 활용한 이미지 데이터 증강(image data augmentation) 및 반도체 웨이퍼 다이싱 결함 분류(classification)를 탐구했습니다. 이를 통해 실제 다이싱 결함을 모방한 합성 이미지(synthetic images)를 생성하여 훈련 데이터의 다양성과 균형을 향상시키고자 했습니다.

- **Technical Details**: 세 가지 다양한 GAN 변형(variants)을 사용하여 고해상도 이미지 합성을 수행했습니다: 딥 컨볼루션 GAN(Deep Convolutional GAN, DCGAN), 사이클GAN(CycleGAN), 그리고 스타일 GAN3(StyleGAN3). 이 방법을 통해 실제와 유사한 합성 이미지를 생성하여 시각 검사 시스템의 데이터를 보강(image augmentation) 하였습니다.

- **Performance Highlights**: 진행 중인 결과에서는 분류 정확도(classification accuracy)가 크게 향상됨을 보여주었으며, 균형 잡힌 정확도(balanced accuracy)가 65.1%에서 88.2%로 평균 23.1% 향상되었습니다. 이는 생산 공정에서 수율 최적화를 가능하게 할 수 있습니다.



### Evolver: Chain-of-Evolution Prompting to Boost Large Multimodal Models for Hateful Meme Detection (https://arxiv.org/abs/2407.21004)
- **What's New**: 최근의 연구에 따르면 Two-Stream 접근법(Two-stream approaches)이 혐오성 밈 탐지(hateful meme detection)에서 뛰어난 성과를 보이고 있습니다. 그러나 새로운 문화적 아이디어가 융합된 신종 밈이 지속적으로 등장함에 따라 기존 방법들이 효과를 발휘하지 못하거나 구시대적인 방법이 되고 있습니다. 이에 본 연구는 대규모 멀티모달 모델(Large Multimodal Models, LMMs)을 활용한 혐오성 밈 탐지의 가능성을 탐구하는 내용을 담고 있습니다.

- **Technical Details**: 본 연구에서는 'Evolver'라는 새로운 접근법을 제안합니다. Evolver는 LMMs를 체인 오브 에볼루션(Chain-of-Evolution, CoE) 프롬팅(Prompting) 방식으로 통합하여 밈의 진화 속성과 맥락적 정보를 활용합니다. Evolver는 밈의 진화 및 표현 과정을 시뮬레이션하고, 단계를 거치며 LMMs로 추론합니다. 구체적으로, 첫째로 진화쌍 마이닝 모듈(evolutionary pair mining module)이 입력된 밈과 외부의 큐레이션된 밈 세트에서 가장 유사한 상위 k개의 밈을 검색합니다. 둘째로 진화 정보 추출기(evolutionary information extractor)가 페어링된 밈들 사이의 의미 규칙을 요약하고 프롬트를 작성합니다. 마지막으로 맥락적 관련성 증폭기(contextual relevance amplifier)를 통해 진화 과정의 탐색을 촉진하는 혐오성 정보의 맥락적 관련성을 높입니다.

- **Performance Highlights**: 공개된 FHM, MAMI, HarM 데이터셋에서 수행된 광범위한 실험 결과 CoE 프롬팅이 기존 LMMs에 통합될 경우 성능을 향상시킬 수 있음을 보여주었습니다. 더욱 고무적인 것은 CoE 프롬팅이 해석 도구로써 소셜 밈의 진화를 이해하는 데 기여할 수 있다는 점입니다.



### From Feature Importance to Natural Language Explanations Using LLMs with RAG (https://arxiv.org/abs/2407.20990)
- **What's New**: 본 연구는 인간과 상호작용하는 자율적 의사결정 프로세스에서 머신러닝 모델의 출력을 대화 형식으로 이해할 필요성이 증가함에 따라, 대형 언어 모델(LLMs)이 후속 설명 제공자 역할을 할 수 있는 가능성을 탐구합니다. 특히, 장면 이해 과제에서 사용자의 질문에 응답하기 위해 외부 지식 저장소를 사용하는 추적 가능한 질문-응답(traceable question-answering) 방식을 도입합니다.

- **Technical Details**: 이 작업에서는 모델의 출력에 대한 맥락적 세부 정보(고급 특성(high-level features), 특성 중요도(feature importance), 대체 확률(alternative probabilities))을 포함하는 외부 지식 저장소를 활용합니다. 특성 중요도(feature importance)를 계산하기 위해 서브트랙티브 반사실 주의(subtractive counterfactual reasoning)를 사용하며, 이는 의미적 특징을 분해한 결과로 인한 출력 변화를 분석하는 방법입니다. 또한, 설명 과정을 원활히 하기 위해 사회적, 인과적, 선택적, 대비적 요소를 한 번의 프롬프트에 통합하여 응답 생성 과정을 안내합니다.

- **Performance Highlights**: 평가는 LLMs가 생성한 설명이 이러한 요소들을 포함하고 있어 복잡한 모델 출력을 자연 언어로 설명하는 데 잠재력이 있음을 나타냅니다.



### EAR: Edge-Aware Reconstruction of 3-D vertebrae structures from bi-planar X-ray images (https://arxiv.org/abs/2407.20937)
Comments:
          13 pages, 11 figures, 3 tables

- **What's New**: 이번 연구에서는 2-D X-ray 이미지에서 3-D 척추 구조를 정확하게 재구성하기 위해 새로운 Edge-Aware Reconstruction (EAR) 네트워크를 제안합니다. 이 네트워크는 척추 모양과 비대칭적인 척추 구조의 경계 정보를 보존하는 데 중점을 둡니다.

- **Technical Details**: EAR 네트워크는 auto-encoder 아키텍처를 백본으로 사용하며, 엣지 어텐션 모듈(edge attention module)과 주파수 향상 모듈(frequency enhancement module)을 통해 엣지 재구성에 대한 인식을 강화합니다. 또한, 재구성 손실(reconstruction loss), 엣지 손실(edge loss), 주파수 손실(frequency loss) 및 투영 손실(projection loss) 등 네 가지 손실 항목을 결합합니다.

- **Performance Highlights**: 세 가지 공개 데이터셋을 사용하여 네 가지 최신 모델과 비교한 결과, 제안된 EAR 네트워크는 MSE 25.32%, MAE 15.32%, Dice 86.44%, SSIM 80.13%, PSNR 23.7612 및 주파수 거리(frequency distance) 0.3014와 같은 성과를 보였습니다. 이로 인해 EAR은 3-D 공간 정보를 제공하고, 정밀한 수술 계획 수립에 중요한 도움을 줄 수 있습니다.



### How to Choose a Reinforcement-Learning Algorithm (https://arxiv.org/abs/2407.20917)
Comments:
          40 pages

- **What's New**: 이 연구는 강화 학습(reinforcement learning) 알고리즘과 행동 분포(action-distribution) 패밀리를 선택하는 과정을 간소화합니다. 기존 방법들과 그 특성에 대한 체계적인 개요와, 어떤 경우에 어떤 방법을 선택해야 하는지에 대한 지침을 제공합니다. 또한, 이러한 지침의 인터랙티브 버전이 온라인에서 제공됩니다.

- **Technical Details**: 연구에서는 다양한 강화 학습 알고리즘과 행동 분포 패밀리에 대한 개요와 성격을 상세히 설명합니다. 이를 통해 특정 작업에 최적화된 알고리즘을 선택하는 데 도움을 줍니다. 연구는 이론적 기반과 실용적 사례를 함께 제시하여, 알고리즘 선택 과정을 체계적으로 정리합니다.

- **Performance Highlights**: 강화 학습 알고리즘 선택에 대한 명확한 지침을 제공하며, 이러한 지침을 인터랙티브 버전으로 변환하여 사용자들이 쉽게 접근할 수 있도록 하였습니다. 이는 강화 학습 모델 설계 및 최적화에 큰 도움이 될 것으로 예상됩니다.



### Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks (https://arxiv.org/abs/2407.20891)
Comments:
          25 pages, 14 figures, 11 tables

- **What's New**: 이번 연구에서는 Bayesian 신경망(Bayesian Neural Networks, BNNs)의 계산 복잡성을 줄여 대규모 작업에서도 사용할 수 있는 혁신적인 프레임워크를 소개했습니다. 우리의 접근 방식은 딥 앙상블(Deep Ensembles)을 기반으로 하지만, 사전 학습된 신경망의 매개변수에서 여러 저랭크(low-rank) 섭동을 도입하여 비용을 크게 줄였습니다. 이를 Bayesian Low-Rank LeArning (Bella)라고 명명했습니다.

- **Technical Details**: Bella는 사전 학습된 신경망의 매개변수에 여러 저랭크 섭동을 적용하여 Bayesian 포스터리어(Bayesian posterior)를 근사하는데 필요한 학습 가능한 매개변수의 수를 크게 줄입니다. 기존의 단순한 앙상블 뿐만 아니라 이전에는 불가능하다고 여겨졌던 Stein Variational Gradient Descent (SVGD)와 같은 더 복잡한 Bayesian 학습 방법도 Bella 프레임워크 내에서 원활하게 구현할 수 있습니다.

- **Performance Highlights**: Bella는 학습 가능한 매개변수의 수를 줄이면서도 기존 Bayesian 학습 방법과 비-Bayesian 기준치를 유지하거나 경우에 따라 이를 능가하는 성능을 보였습니다. ImageNet, CAMELYON17, DomainNet, VQA with CLIP, LLaVA와 같은 대규모 작업에서 Bella의 효과성과 다재다능함을 입증하였습니다.



### S3PET: Semi-supervised Standard-dose PET Image Reconstruction via Dose-aware Token Swap (https://arxiv.org/abs/2407.20878)
- **What's New**: 고품질의 양전자 방출 단층촬영 (PET) 이미지를 얻기 위해 낮은 방사선 추적자 용량으로부터 표준 용량 PET (SPET) 이미지를 재구성하는 것이 중요합니다. S3PET라는 새로운 반지도 학습 프레임워크를 제안하여, 풍부한 짝을 이루지 않은(unpaired) 이미지와 제한된 짝을 이룬(paired) SPET 및 LPET 이미지를 사용한 학습을 가능하게 합니다.

- **Technical Details**: 이 프레임워크는 두 단계로 이루어져 있습니다. 첫 번째 단계는 비지도 예비 훈련(un-supervised pre-training) 단계로, 짝을 이루지 않은 이미지들로부터 표현을 추출합니다. 두 번째 단계에서는 감독 하에 용량 인식 재구성(dose-aware reconstruction)이 이루어져 LPET로부터 SPET 이미지로의 재구성을 가능하게 합니다. 구체적으로, 첫 번째 단계에서는 두 개의 독립적인 용량-특정 마스크 오토인코더(DsMAEs)를 사용하여 짝을 이루지 않은 SPET 및 LPET 이미지를 이해합니다. 두 번째 단계에서는 예비 훈련된 DsMAEs가 짝을 이룬 이미지들로 추가로 미세 조정(finetune) 됩니다. 또한, 용량 지식 분리 모듈(dose knowledge decouple module)을 도입하여 LPET와 SPET의 용량-특정 및 용량-불변 지식을 분리하고, SPET의 용량-특정 정보를 LPET로 전이하는 용량-특정 지식 학습 모듈(dose-specific knowledge learning module)을 제안합니다.

- **Performance Highlights**: 두 개의 데이터셋 실험에서, S3PET는 정량적 및 정성적으로 최신의 최고 성능(state-of-the-art performance)을 달성했습니다.



### A Comparative Study of Neural Surface Reconstruction for Scientific Visualization (https://arxiv.org/abs/2407.20868)
- **What's New**: 이 연구는 과학 시각화를 위한 3D 표면 재구성 방법들을 비교평가합니다. 특히, 여러 뷰 렌더링 이미지를 통해 3D 표면을 재구성하는 방법에 중점을 둡니다. 10가지 방법을 신경 방사체 필드(neural radiance fields)와 신경 암묵적 표면(neural implicit surfaces)으로 분류하여 분석하였습니다.

- **Technical Details**: 이번 연구에서는 거리 함수(distance functions), 특히 SDFs(Signed Distance Functions)와 UDFs(Uncertain Distance Functions)를 활용하여 재구성된 표면의 정확도와 매끄러움을 향상시키는 방법을 조사했습니다. NeuS2는 폐쇄 표면(closed surfaces) 재구성을, NeUDF는 개방 표면(open surfaces) 재구성에 유망한 후보로 확인되었습니다.

- **Performance Highlights**: NeuS2는 폐쇄 표면을 재구성하는 데 있어 뛰어난 효율성과 품질을 보여주었고, NeUDF는 몇 가지 한계에도 불구하고 개방 표면 재구성에 유망한 성능을 보였습니다. 해당 벤치마크 데이터셋을 공유함으로써, 다른 연구자들이 그들의 방법을 테스트하고 표면 재구성 솔루션을 향상시키는 데 기여할 수 있도록 하였습니다.



### Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing (https://arxiv.org/abs/2407.20830)
- **What's New**: 새로운 연구는 민감한 데이터를 중앙 집중화 없이 강력한 모델을 개발할 수 있는 협업 학습 패러다임인 연합 학습(federated learning)을 개선한 Federated Knowledge Recycling (FedKR)을 제안합니다. FedKR은 로컬에서 생성된 합성 데이터를 사용하여 기관 간 협업을 촉진하고, 기존 방법보다 프라이버시 공격에 대한 보안을 강화합니다.

- **Technical Details**: FedKR은 고급 데이터 생성 기술과 동적 집계(dynamıc aggregation) 프로세스를 결합하여 수행합니다. 이는 모델, 파라미터 또는 업데이트 노출에 따른 공격 피면을 줄여 프라이버시 및 보안 취약성을 해결합니다. FedKR은 기관 내에서 생성되는 합성 데이터를 사용하여 협업을 촉진합니다.

- **Performance Highlights**: 일반 데이터셋 및 의료 데이터셋에서의 실험 결과, FedKR은 로컬 데이터로부터 모델을 학습시키는 방법에 비해 평균 정확도가 4.24% 향상되었으며, 데이터가 부족한 시나리오에서 특히 효과적임이 입증되었습니다.



### Highly Efficient No-reference 4K Video Quality Assessment with Full-Pixel Covering Sampling and Training Strategy (https://arxiv.org/abs/2407.20766)
Comments:
          Accepted by ACM MM 2024

- **What's New**: 이번 논문에서는 초고화질(4K) 비디오의 품질을 평가할 수 있는 새로운 무참조(No-Reference, NR) 비디오 품질 평가(Quality Assessment, VQA) 기술을 제안합니다. 기존의 고성능 VQA 방법들이 초고화질 비디오의 품질을 평가하는데 큰 컴퓨팅 비용이 소모되는 문제를 해결하기 위해 새로운 데이터 샘플링 및 학습 전략을 도입했습니다. 이 방법은 4K 비디오의 전체 데이터를 표준 소비자용 GPU에서 손상 없이 효과적으로 학습하고 추론할 수 있게 합니다.

- **Technical Details**: 첫째로, 과도한 해상도 문제를 해결하기 위한 새로운 데이터 샘플링 및 학습 전략이 제안되었습니다. 이 전략은 VQA Swin Transformer 기반 모델이 4K 비디오의 전체 데이터를 사용할 수 있게 해줍니다. 둘째로, 4K 프레임 내 각 서브 영역이 전체 인식에 미치는 영향을 고려한 가중치 및 스코어링 체계를 개발하여 인간의 주관적 인식 모드를 모방했습니다. 셋째로, 비디오 프레임의 주파수 영역 정보를 통합하여 비디오 품질에 영향을 미치는 세부 사항을 더 잘 포착하고, 모델의 일반화 가능성을 향상시켰습니다.

- **Performance Highlights**: 이번에 제안된 기술은 특화된 4K VQA 데이터셋에서 기존 방법들을 크게 능가할 뿐만 아니라, 여러 오픈소스 NR 비디오 품질 데이터셋에서도 최첨단 성능을 달성했습니다.



### PIP: Prototypes-Injected Prompt for Federated Class Incremental Learning (https://arxiv.org/abs/2407.20705)
Comments:
          Conference on Information and Knowledge Management (CIKM) 2024 (Accepted)

- **What's New**: Federated Class Incremental Learning (FCIL) 분야의 새로운 연구 발표로, 기존 클래스의 데이터를 반복 사용하지 않고도 이전 학습에서의 망각 현상(catastrophic forgetting)과 데이터 분포의 불균형(non-IID data distribution) 문제를 동시에 해결하는 방법을 제시했습니다.

- **Technical Details**: 새롭게 제안된 방법은 프로토타입 삽입(PIP)이라고 불리며, 주요 아이디어는 다음과 같습니다: a) 프로토타입 삽입을 통한 프롬프트 학습 (prototype injection on prompt learning), b) 프로토타입 증강 (prototype augmentation), c) 서버 쪽 가중치가 적용된 가우시안 집계 (weighted Gaussian aggregation).

- **Performance Highlights**: CIFAR100, MiniImageNet, TinyImageNet 데이터셋에서 기존 최첨단(SOTA) 방법들보다 최대 33% 더 높은 성능을 보이며, 다양한 작업 크기에서의 견고성을 입증했습니다. 또한, 참여하는 로컬 클라이언트 수와 글로벌 라운드가 적을수록 유리함을 나타냈습니다. 추가 연구를 위해 소스 코드, 베이스라인 및 실험 로그가 공개되었습니다.



### Time Series Anomaly Detection with CNN for Environmental Sensors in Healthcare-Io (https://arxiv.org/abs/2407.20695)
- **What's New**: 이 연구는 헬스케어-IoT에서 시계열 데이터의 이상 탐지를 위한 새로운 방법을 개발하였습니다. 제안된 방법은 Cooja라는 IoT 네트워크 시뮬레이터를 사용하여 Distributed Denial of Service (DDoS) 공격을 생성하고, 이는 온도 및 습도와 같은 환경 센서를 에뮬레이트합니다.

- **Technical Details**: 제안된 방법에서는 Convolutional Neural Networks (CNNs)을 이용하여 시계열 데이터에서의 이상을 탐지합니다. CNNs은 여러 계층을 통해 입력 데이터를 처리하여 패턴을 인식하고, 그 결과로 이상 상황을 식별할 수 있습니다. 본 연구에서는 Cooja 시뮬레이터를 통해 DDoS 공격 시나리오를 생성하고, 이를 CNN 모델로 분석하여 이상 탐지 성능을 검증하였습니다.

- **Performance Highlights**: 제안된 방법은 92%의 정확도로 잠재적 공격을 식별할 수 있음을 보여주었습니다. 이는 현재 헬스케어-IoT 시스템에서 발생할 수 있는 다양한 공격에 대해 효율적이고 실시간으로 대응할 수 있는 가능성을 제시합니다.



### Benchmarking Histopathology Foundation Models for Ovarian Cancer Bevacizumab Treatment Response Prediction from Whole Slide Images (https://arxiv.org/abs/2407.20596)
- **What's New**: 이 논문에서는 반복성 난소암 치료에 일반적으로 사용되는 베바시주맙(Bevacizumab)의 반응을 예측하기 위해 최신 조직병리학 기초 모델(histopathology foundation models)을 활용하는 연구를 소개합니다. 베바시주맙은 고급 단계의 난소암 환자에서 무진행 생존기간(progression-free survival, PFS)을 향상시키는 것으로 알려져 있으나, 환자의 반응을 예측할 수 있는 생체표지자(biomarker)의 부재가 개인 맞춤형 치료 도입에 걸림돌이 되어 왔습니다.

- **Technical Details**: 이 연구에서는 대규모 전체 슬라이드 이미지(WSI) 데이터 세트로 훈련된 최신 조직병리학 기초 모델을 사용하여 난소 종양 조직의 특성을 추출하고, 이를 통해 WSIs에서 베바시주맙 반응을 예측합니다. 다양한 조직병리학 기초 모델과 다중 인스턴스 학습(Multiple Instance Learning, MIL) 전략을 결합하여 광범위한 실험을 수행한 결과, 최고의 모델은 AUC 점수 0.86 및 정확도 72.5%를 기록했습니다.

- **Performance Highlights**: 생존 모델(survival models)은 고등급 장액성 난소암(high-grade serous ovarian carcinoma) 환자들 중에서도 고위험군과 저위험군을 통계적으로 유의미하게(p < 0.05) 구분하는 데 성공했습니다. 또한, WSIs의 높은 집중 영역(high-attention regions)은 모델의 설명 가능성을 높이고, 치료 예후의 유망한 이미지 생체표지자로 사용할 수 있음을 보여주었습니다.



### High-Resolution Spatial Transcriptomics from Histology Images using HisToSGE (https://arxiv.org/abs/2407.20518)
- **What's New**: 새로운 연구는 'HisToSGE'라는 방법을 개발하여, 조직 샘플 내에서 고밀도의 유전자 발현 프로파일을 예측하고 분석하는 새로운 접근 방식을 제안합니다. 이 기술은 기존의 방법들이 가지는 이미지 특징 캡쳐의 한계를 극복하고 유전자 발현 프로파일의 고해상도 예측을 가능하게 합니다.

- **Technical Details**: HisToSGE는 병리 이미지 큰 모델(Pathology Image Large Model, PILM)을 활용하여 조직 이미지에서 풍부한 이미지 특징을 추출합니다. 그리고 특징 학습 모듈(feature learning module)을 통해 고해상도의 유전자 발현 프로파일을 생성합니다. 이 접근법은 기존의 저차원 위치 좌표에 의존하는 방법들을 개선하여 보다 정확한 결과를 제공합니다.

- **Performance Highlights**: HisToSGE는 네 가지 ST 데이터셋에서 다섯 가지 최신 방식들과 비교 평가되었습니다. 그 결과, HisToSGE는 고해상도 유전자 발현 프로파일 생성 및 공간 도메인 식별(spatial domain identification) 등의 후속 작업에서 뛰어난 성능을 보여주었습니다. 관련 모든 코드와 공개 데이터셋은 논문 내 제공 링크를 통해 접근이 가능합니다.



### Enhancing Quantitative Image Synthesis through Pretraining and Resolution Scaling for Bone Mineral Density Estimation from a Plain X-ray Imag (https://arxiv.org/abs/2407.20495)
Comments:
          SASHIMI, 2024 (MICCAI workshop). 13 pages, 3 figures

- **What's New**: 이 연구는 정량적 이미지 합성(Quantitative Image Synthesis, QIS) 성능을 향상시키기 위해 사전학습(pretraining)과 이미지 해상도 스케일링(image resolution scaling)을 탐구했다. 본 논문은 QIS 기반 골밀도(BMD) 추정을 위한 새로운 벤치마크를 제안하고 있으며, 적절한 사전학습이 QIS 성능을 크게 개선시킬 수 있음을 보여준다.

- **Technical Details**: 연구에서는 일반 X-ray 이미지에서 합성된 정량적 이미지를 사용하여 BMD를 추정하는 작업을 통해 사전학습 성능을 평가했다. 적절한 사전학습은 BMD 추정의 상관관계(correlation)를 0.820에서 0.898로 크게 향상시켰고, 해상도를 스케일업 하면 상관관계가 0.923까지 상승하는 결과를 보여주었다.

- **Performance Highlights**: 적절한 사전학습과 해상도 스케일링을 통해 BMD 추정의 상관관계가 0.820에서 0.923까지 향상됨을 확인했다. 이는 기존 방법들에 비해 상당한 성능 향상을 의미한다. 향후 연구에서는 더 많은 사전학습 전략을 탐구하고 다른 이미지 합성 작업에도 이를 적용할 예정이다.



### Event-based Optical Flow on Neuromorphic Processor: ANN vs. SNN Comparison based on Activation Sparsification (https://arxiv.org/abs/2407.20421)
Comments:
          18 pages, 12 figures, 4 tables

- **What's New**: 이번 연구에서는 이벤트 기반의 광류(optical flow)에 대한 스파이킹 신경망(SNNs)과 인공 신경망(ANNs)을 비교하여, SNNs가 더 효율적인지에 대해 평가하였습니다. 이를 위해 활성화 희소화(activation sparsification)와 신경형 프로세서(neuromorphic processor)인 SENECA를 기반으로 하는 이벤트 기반 광류 솔루션을 제안했습니다.

- **Technical Details**: SENECA는 ANN 활성화 및 SNN 스파이크의 희소성을 활용하여 두 종류의 신경망 추론을 가속화할 수 있는 이벤트 기반 처리 메커니즘을 갖추고 있습니다. 이를 통해 유사한 낮은 활성화/스파이크 밀도(~5%)를 갖춘 ANN과 SNN를 비교 실험 하였습니다. 하드웨어 인 루프(hardware-in-loop) 실험에서는 평균 시간과 에너지 소비를 측정하였습니다.

- **Performance Highlights**: 실험 결과, SNN은 44.9ms와 927.0 마이크로줄(microjoules)의 에너지를 소비했으며, 이는 ANN의 62.5%와 75.2%만을 소비하는 결과를 나타냈습니다. 이러한 높은 효율성은 픽셀 단위의 스파이크 밀도(43.5% 대 66.5%)가 낮아 뉴런 상태에 대한 메모리 접근 작업이 적게 요구되기 때문임을 알게 되었습니다.



### Analysis and Improvement of Rank-Ordered Mean Algorithm in Single-Photon LiDAR (https://arxiv.org/abs/2407.20399)
Comments:
          6 pages, 7 figures, submitted to the IEEE 26th International Workshop on Multimedia Signal Processing (MMSP)

- **What's New**: 이 논문은 단일-광자 LiDAR를 사용한 심도 측정을 위해 기존에 널리 사용되는 ROM(Rank-Ordered Mean) 필터의 성능을 이론적으로 분석하고 개선된 신호 추출 기법을 제시합니다. ROM 필터는 배경 소음을 줄이는 데에 효과적이나, 반사율이 특정 임계값 이하로 떨어지면 성능 문제가 발생할 수 있음을 이론적으로 밝혀냈습니다. 이를 바탕으로 더욱 정밀한 타임스탬프 클러스터를 선택하는 새로운 알고리즘을 제안합니다.

- **Technical Details**: 단일-광자 LiDAR 시스템은 매치드 필터(Matched Filter)로 심도(depth)를 추정하는 방식과, 배경 소음을 제거하기 위해 Shin 외 연구진이 제안한 ROM 필터를 사용합니다. ROM 필터는 주변의 중앙값(median statistics)을 기반으로 작은 범위의 타임스탬프를 선택하여 노이즈가 섞인 포톤 도착 타임스탬프를 걸러냅니다. 그러나 이 논문에서는 ROM 필터가 신호 대 잡음비(signal-to-background ratio)와 깊이(depth)에 따라 성능 한계가 있음을 이론적으로 분석하였습니다. 저자들은 반사율이 임계값 이하로 떨어질 때 성능 저하가 일어나는 'phase transition' 현상을 발견하였고, 이를 해결하기 위한 개선된 방법으로 더욱 촘촘한 타임스탬프 클러스터를 선택하는 알고리즘을 제안합니다.

- **Performance Highlights**: 실험 결과, 제안된 알고리즘은 기존의 ROM에 비해 동일한 신호 강도에서 심도 추정 성능을 3 배 향상시켰으며, 신호 강도 대비 17배 높은 노이즈 수준에서도 높은 이미지 품질을 유지하였습니다. 이는 제안된 접근 방식이 강한 배경 소음과 낮은 반사율 조건에서도 우수한 성능을 발휘함을 보여줍니다.



### Two-Phase Segmentation Approach for Accurate Left Ventricle Segmentation in Cardiac MRI using Machine Learning (https://arxiv.org/abs/2407.20387)
- **What's New**: 새로운 연구에서는 심장 MRI(CMR) 스캔에서 좌심실(LV)을 정확하게 세분화하는 기법을 제안합니다. 이 연구는 CMR 스캔에서 LV의 세 가지 구역(기저부, 중간 심실, 첨부)을 위한 별도의 매개변수 세트를 사용하는 방법을 소개하며, 이를 통해 두 단계로 나뉜 세분화 접근 방식을 제안합니다. 첫 번째 단계에서는 LV 종류에 따라 이미지를 세 그룹으로 분류하고, 두 번째 단계에서는 앞서 실행된 단계로부터 가져온 매개변수를 사용하여 CMR 이미지를 세분화합니다.

- **Technical Details**: 제안된 방법은 10-Fold Cross Validation을 사용하여 공개된 데이터셋(Automated Cardiac Diagnosis Challenge (ACDC))에서 테스트되었습니다. 기저부, 중간 심실, 첨부와 같은 세 가지 다른 유형의 LV 슬라이스에 대해 최적화된 매개변수 세트를 사용하여 두 단계로 나뉜 세분화 접근 방식을 사용합니다. 첫 번째 단계는 이미지를 세 가지 LV 슬라이스 유형으로 분류하고, 두 번째 단계에서는 첫 번째 단계에서 가져온 매개변수를 사용하여 CMR 이미지를 세분화합니다.

- **Performance Highlights**: 제안된 방법은 10-Fold Cross Validation을 통해 0.9228의 평균 점수를 달성했습니다. 종합적인 테스트 결과, 특정 유형의 슬라이스에 적합한 최적의 매개변수 세트가 다른 유형의 슬라이스에 적절히 적용되지 않는다는 점을 확인했습니다. 제안된 접근 방식은 이러한 매개변수 표준화에 중요한 빈틈을 메우며, 심장 이미지 분석의 정확도를 향상시키려는 목표를 가지고 있습니다.



### Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing (https://arxiv.org/abs/2407.20232)
- **What's New**: 텍스트 기반 편집(diffusion) 모델들이 사용자의 입력 지시가 모호할 때 성능이 제한적이라는 문제를 해결하기 위해 'Specify ANd Edit'(SANE)이라는 무스펙 추론 파이프라인을 제안했습니다. SANE는 대형 언어 모델(LLM)을 사용해 입력 지시를 구체적인 지시로 분해한 후, 새로운 디노이징(denoising) 가이드 전략을 통해 이를 입력 이미지에 적용합니다.

- **Technical Details**: SANE는 LLM을 활용해 사용자의 모호한 지시를 구체적으로 분해합니다. 이를 위해 저자들은 입력 이미지에 적용할 명확한 개입을 도출합니다. SANE 전략의 핵심은 신속한 지시 분해와 그 개선된 디노이징 가이드 접근 방식 덕분에 높은 해석 가능성과 다양한 출력 결과를 얻는 것입니다. 실험은 세 가지 기본 설정과 두 개의 데이터세트에서 수행되었습니다.

- **Performance Highlights**: SANE는 기존의 모든 구성에서 이점을 보였으며, 편집 모델의 해석 가능성을 높이는 동시에 출력의 다양성을 크게 증진했습니다. 또한, 모호한 지시뿐만 아니라 명확한 지시에도 이 접근법이 적용될 수 있음을 보였습니다. 코드와 구체적 구현은 공개되어 있습니다.



### Improving 2D Feature Representations by 3D-Aware Fine-Tuning (https://arxiv.org/abs/2407.20229)
Comments:
          ECCV 2024. Project page: this https URL

- **What's New**: 이번 연구에서는 순수하게 2D 데이터로만 훈련된 기존의 시각적 기초 모델 (visual foundation models)이 가진 3D 구조 이해의 한계를 넘어서기 위해 3D 인식을 도입한 미세 조정을 제안합니다. 이 방법은 2D 기초 모델에 3D 인식을 전이시키는 새로운 미세 조정 전략을 설계하고 이를 3D 인식 데이터를 통해 시연합니다.

- **Technical Details**: 2D 특징(feature)을 효과적인 3D Gaussian 표현(3D Gaussian representation)으로 변환하여 임의의 뷰에서 재렌더링할 수 있는 방법을 설계했습니다. 이 재렌더링된 3D 인식 특징을 사용하여 2D 기초 모델에 3D 인식을 주입하는 미세 조정(strategy)을 디자인했습니다. 이러한 조정된 모델은 단순히 선형 프로빙(linear probing)만으로도 세멘틱 세그멘테이션(semantic segmentation)과 깊이 추정(depth estimation)과 같은 다운스트림 작업 성능을 쉽게 향상시킬 수 있습니다.

- **Performance Highlights**: 실내 데이터셋에만 미세 조정되었음에도 불구하고, 이 방법을 통한 성능 향상은 다양한 실내 데이터셋과 도메인을 벗어난(out-of-domain) 데이터셋에도 적용 가능함을 보였습니다. 이를 통해 커뮤니티가 2D 기초 모델을 훈련할 때 3D 인식 주입을 고려하도록 장려하는 것이 연구의 목표입니다.



### FlexAttention for Efficient High-Resolution Vision-Language Models (https://arxiv.org/abs/2407.20228)
Comments:
          Accepted by ECCV 2024

- **What's New**: 이번 논문에서는 고해상도 비전-언어 모델(vision-language models)의 효율성을 높이기 위한 FlexAttention 메커니즘을 제안합니다. 새로운 접근법으로 계산 비용을 크게 줄이면서도 높은 성능을 유지합니다.

- **Technical Details**: FlexAttention 메커니즘에서는 이미지를 고해상도 토큰과 저해상도 토큰으로 인코딩하여 주로 저해상도 토큰과 몇몇 선택된 고해상도 토큰만을 사용해 어텐션 맵(attention map)을 계산합니다. 고해상도 토큰은 입력 어텐션 맵을 기반으로 관련 영역의 토큰을 검색하는 고해상도 선택 모듈로 선택됩니다. 선택된 고해상도 토큰은 저해상도 토큰과 텍스트 토큰과 결합되어 계층적 자기 어텐션 층(hierarchical self-attention layer)으로 입력되며, 이 과정을 반복하여 고해상도 토큰 선택을 단계적으로 진행합니다.

- **Performance Highlights**: 멀티모달 벤치마크 실험에서 FlexAttention은 기존 고해상도 VLMs(예: V* Bench에서 약 9%, TextVQA에서 약 7%)보다 성능이 뛰어나며, 계산 비용을 거의 40% 줄이는 데 성공했습니다.



### Correspondence-Free SE(3) Point Cloud Registration in RKHS via Unsupervised Equivariant Learning (https://arxiv.org/abs/2407.20223)
Comments:
          10 pages, to be published in ECCV 2024

- **What's New**: 이번 연구에서는 포인트 클라우드(point cloud) 등록 기법에서 포인트 대응을 필요로 하지 않는 강력한 비지도 SE(3) 등록 방법을 소개합니다. 이 방법은 재생 커널 히버트 공간(reproducing kernel Hilbert space, RKHS)에서 SE(3)-등변(equivariant) 특징을 활용하여 직접적인 특징 공간 등록을 수행합니다.

- **Technical Details**: 이 방법에서는 포인트 클라우드를 RKHS에서 함수로 간주하고, 새로운 RKHS 거리(metric)를 제안하여 노이즈, 아웃라이어(outlier), 비대칭 데이터를 효과적으로 처리합니다. 또한 제한된 정답 데이터를 효과적으로 다루기 위한 비지도 학습 접근 방식을 도입하여 실제 데이터셋에 적응할 수 있도록 합니다.

- **Performance Highlights**: 제안된 방법은 모델넷40(ModelNet40)과 ETH3D와 같은 합성 및 실세계 데이터셋에서 기존의 전통적인 방법과 지도 학습 모델을 능가하는 등록 정확도를 보여줍니다. 특히 실 RGB-D 오도메트리(odometry) 데이터에서의 성공적인 등록은 이 방법이 최초임을 강조합니다. 코드는 공개되어 {this https URL}에서 확인할 수 있습니다.



### Global Structure-from-Motion Revisited (https://arxiv.org/abs/2407.20219)
Comments:
          accepted at ECCV2024

- **What's New**: 이번 연구에서는 Structure-from-Motion (SfM) 문제를 해결하기 위한 새로운 전방위(global) 시스템인 GLOMAP을 제안합니다. 이는 기존의 COLMAP과 같은 대표적인 점진적(incremental) SfM 시스템에 비해 월등히 빠르며, 정확도와 견고성 면에서도 동등하거나 우수한 성능을 보입니다.

- **Technical Details**: SfM 문제는 이미지로부터 3D 구조 및 카메라 움직임을 복원하는 기술입니다. 현재 대부분의 시스템은 뛰어난 정확도와 견고성으로 인해 점진적 접근 방식을 따릅니다. GLOMAP은 전방위 접근 방식을 채택하여 더 나은 확장성 및 효율성을 제공합니다. GLOMAP 시스템은 전체적으로 효율적인 구조 덕분에 더욱 빠르게 처리할 수 있습니다.

- **Performance Highlights**: GLOMAP은 전방위 SfM 접근 방식에서 현존하는 모든 시스템 중 최고 수준의 성과를 보입니다. 기존의 가장 널리 사용되는 점진적 SfM 시스템인 COLMAP과 비교했을 때, 정확도와 견고성 면에서 동등하거나 더 나은 결과를 보이면서도 처리 속도가 수 배에서 수십 배 빠릅니다. GLOMAP은 오픈 소스로 제공되어 누구나 사용할 수 있습니다.



### SANGRIA: Surgical Video Scene Graph Optimization for Surgical Workflow Prediction (https://arxiv.org/abs/2407.20214)
Comments:
          9 pages, 3 figures, 3 tables, MICCAI GRAIL Workshop paper

- **What's New**: 새로운 연구에서는 수술 장면 그래프 (surgical scene graph)를 생성하고 최적화할 수 있는 엔드 투 엔드 프레임워크를 소개합니다. 이는 수술 워크플로우 (surgical workflow) 인식을 위해 그래프 기반의 전체적인 장면 표현 (holistic scene representations)을 사용하는 방법입니다.

- **Technical Details**: 제안된 접근법은 그래프 기반 분광 클러스터링 (graph-based spectral clustering)의 유연성과 파운데이션 모델 (foundation models)의 일반화 능력을 활용하여 비지도 학습 (unsupervised learning)으로 학습 가능한 속성을 가진 장면 그래프를 생성합니다. 초기 공간 그래프 (spatial graph)는 연속적인 프레임 간의 로컬 매치를 사용한 희소한 시간적 연결 (sparse temporal connections)로 보강됩니다. 동적 장면 그래프의 시공간 관계 (spatiotemporal relations)와 노드 특성 (node features)을 공동 최적화하여 단순한 약한 수술 단계 레이블 (weak surgical phase labels)을 사용해 의미론적 장면 이해 (semantic scene comprehension)와 장면 그래프 생성을 수행합니다.

- **Performance Highlights**: 효과적인 중간 장면 표현 분리 단계를 파이프라인 내에 포함시켜, CATARACTS 데이터셋 (CATARACTS dataset)에서 수술 워크플로우 인식 정확도를 8% 개선하고, F1 점수를 10% 향상시켰습니다.



### Towards Localized Fine-Grained Control for Facial Expression Generation (https://arxiv.org/abs/2407.20175)
- **What's New**: 얼굴 생성 시 정밀한 표정 제어를 위한 새로운 방식을 제안합니다. AUs(Action Units)를 활용하여 다양한 근육 움직임을 세밀하게 제어함으로써, 전형적인 감정 모델을 넘어서는 미세하고 진짜와 같은 표정을 생성하는 방법을 소개합니다.

- **Technical Details**: AUs(Action Units)는 얼굴의 해부학적 특성에 기반하여 특정 근육의 움직임을 설명합니다. 이는 각 근육의 움직임 강도를 정확하고 국소적으로 제어할 수 있게 합니다. 이 기술을 텍스트 및 이미지 프롬프트와 결합하여, 어댑터(adapters)를 사용하여 더 직관적이고 정밀한 제어가 가능하도록 합니다.

- **Performance Highlights**: 제안된 방법은 기존 생성 모델이 생성하는 평면적이고 성격 없는 미소와는 달리, 의심(doubtful) 같은 비전형적인 표정을 안정적으로 생성할 수 있습니다. 또한, 다양한 AUs의 조합을 통해 현실 세계의 표정을 반영하는 미세하고 진짜와 같은 반응을 생성할 수 있습니다. 코드와 데이터셋은 공개되어 있습니다.



### Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning (https://arxiv.org/abs/2407.20174)
Comments:
          11 pages, 7 figures

- **What's New**: 새로운 멀티모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)이 차트 질문 응답(Chart Question Answering, CQA)에 대한 잠재력을 보여주고 있습니다. 저자들은 데이터 수집 및 합성을 통해 학습 데이터셋(차트, 데이터 테이블, 질문-답변 쌍)을 확장하는 기존 노력들의 한계를 지적하며, 새로운 접근 방안을 제안합니다.

- **Technical Details**: 현재 데이터 수집 및 합성 방식은 데이터의 양에 집중하고, 세밀한 시각 인코딩과 QA 작업을 제대로 고려하지 않아 실제 CQA 시나리오와 불균형한 데이터 분포를 보입니다. 기존 MLLMs의 학습 방법은 자연 이미지 처리를 위해 설계되었으며, 차트의 풍부한 텍스트 요소와 같은 고유 특성 적응을 충분히 탐구하지 않았습니다. 이를 해결하기 위해 저자들은 '시각 참조 지침 학습'(Visualization-Referenced Instruction Tuning) 접근 방식을 제안합니다. 이는 기존 데이터셋에서 다양한 고품질 데이터를 효과적으로 필터링하고, LLM 기반 생성 기술을 사용하여 데이터를 세부적으로 정제하고 증강하여 실제 QA 작업과 시각 인코딩에 더 잘 맞추도록 합니다. 또한, 비전 인코더(Vision Encoder)를 풀어주고 다양한 해상도 적응 전략을 혼합하여 세밀한 인식을 강화합니다.

- **Performance Highlights**: 실험 결과, 제안된 접근 방식은 적은 학습 예제만으로도 기존 CQA 모델을 꾸준히 능가하며, 주요 벤치마크에서 최첨단 성능을 보였습니다. 또한, 후속 연구를 위한 벤치마크로 사용할 데이터셋 분할을 제공하였습니다. 이 논문의 소스 코드와 데이터셋은 제공되는 URL에서 이용할 수 있습니다.



### Diffusion Feedback Helps CLIP See Better (https://arxiv.org/abs/2407.20171)
- **What's New**: 최근 연구에 따르면 CLIP 모델에서 시각적으로 중요한 단점들이 발견되었습니다. 이러한 단점들은 방향, 개수, 색상, 구조 등을 구별하기 어려운 문제를 포함합니다. 연구진은 이러한 문제를 해결하기 위해 단순한 후처리(post-training) 접근 방식을 제안하였으며, 이를 DIVA(Diffusion model as a Visual Assistant)라고 명명했습니다. DIVA는 텍스트-이미지(diffusion) 모델의 생성 피드백을 활용하여 CLIP의 표현을 최적화합니다.

- **Technical Details**: DIVA는 CLIP 모델의 시각적 단점을 해결하기 위한 자가 지도(self-supervised) diffusion 프로세스를 활용합니다. 이 방식은 텍스트-이미지 확산(diffusion) 모델을 사용하여 이미지에서 텍스트 없이 CLIP 표현을 최적화하는 방식으로 진행됩니다. 이를 통해 CLIP의 미세한 시각 능력을 평가하는 MMVP-VLM 벤치마크에서 성능을 높이는 것이 확인되었습니다.

- **Performance Highlights**: DIVA는 MMVP-VLM 벤치마크에서 CLIP의 성능을 3-7% 향상시키는 것으로 나타났습니다. 또한, 다중 모달(li후속umodal) 언어 모델(MLLMs) 및 시각 모델의 다중 모달 이해 및 세분화(segmentation) 작업 성능도 향상되었습니다. 29개의 이미지 분류 및 검색 벤치마크에서 평가한 결과, DIVA는 CLIP의 강력한 zero-shot 능력도 유지하는 것으로 확인되었습니다.



### DDAP: Dual-Domain Anti-Personalization against Text-to-Image Diffusion Models (https://arxiv.org/abs/2407.20141)
Comments:
          Accepted by IJCB 2024

- **What's New**: 본 논문에서는 개인화된 시각 콘텐츠 생성 모델의 악용을 방지하기 위해 새로운 Dual-Domain Anti-Personalization 프레임워크(DDAP)를 제안합니다. 이는 적대적 샘플을 사용하여 개인화된 생성 모델 훈련을 혼란시키는 현재 방법들의 한계를 극복합니다.

- **Technical Details**: DDAP는 두 가지 주요 기술로 구성됩니다. 첫째, 이미지 인코더의 고정적이고 교란에 민감한 특성을 활용한 Spatial Perturbation Learning(SPL)입니다. 이는 생성된 이미지의 전체 텍스처를 방해합니다. 둘째, 주파수 도메인에서 확산 모델의 특성을 이용한 Frequency Perturbation Learning(FPL)입니다. 이는 이미지의 세부 사항에 집중하여 적대적 샘플을 생성합니다. 이 두 방법을 교대로 사용하여, 효과적으로 두 도메인의 강점을 결합한 DDAP 프레임워크를 구축했습니다. 또한, 시각적 품질을 높이기 위해 주의 영역을 정확하게 포착하는 로컬라이제이션 모듈을 설계하여, 공격의 효과를 유지하면서 불필요한 배경 방해를 피합니다.

- **Performance Highlights**: 얼굴 데이터셋에서 실행한 광범위한 실험 결과, 제안된 DDAP는 개인화된 생성 모델의 방해 효과를 증대시키는 동시에 적대적 샘플의 높은 품질을 유지하였습니다. 이는 실제 응용에서 프라이버시 보호를 더 효과적으로 만들어줍니다.



### RSC-SNN: Exploring the Trade-off Between Adversarial Robustness and Accuracy in Spiking Neural Networks via Randomized Smoothing Coding (https://arxiv.org/abs/2407.20099)
Comments:
          Accepted by ACM MM 2024

- **What's New**: 이번 연구는 스파이킹 신경망(Spiking Neural Networks, SNNs)의 고유한 적대적 견고성(adversarial robustness)에 대해 이론적으로 밝혔습니다. SNN이 이미지넷(ImageNet)과 같은 대규모 데이터셋에서도 그 강점을 유지할 수 있는지 검증했습니다.

- **Technical Details**: 이 연구에서는 SNN의 포아송 코딩(Poisson coding)이 적대적 견고성을 제공하는 주요 요인임을 이론적으로 증명했습니다. 이를 통해 포아송 코딩과 랜덤화 스무딩(randomized smoothing) 방어 전략의 개념적 동등성을 확인하였습니다. 또한 새로운 랜덤화 스무딩 코딩(Randomized Smoothing Coding, RSC) 방법을 제안하여 정확성과 적대적 견고성 사이의 트레이드오프를 심층 분석했습니다.

- **Performance Highlights**: 제안된 RSC-SNNs는 적대적 견고성 측면에서 ANNs(인공지능 신경망)를 능가했으며, 대규모 데이터셋인 이미지넷(ImageNet)에서 최첨단 견고성 결과를 달성했습니다. 이 연구의 오픈 소스 구현 코드는 제공된 URL에서 확인할 수 있습니다.



### Infrared Small Target Detection based on Adjustable Sensitivity Strategy and Multi-Scale Fusion (https://arxiv.org/abs/2407.20090)
- **What's New**: 최근에는 딥러닝 기반 단일 프레임 적외선 소형 표적(SIRST) 검출 기술이 상당한 진전을 이루었지만, 기존의 적외선 소형 표적 검출 방법은 고정된 이미지 해상도, 단일 파장, 또는 특정 이미징 시스템에 최적화되어 실제 응용에서 한계가 있습니다. 이러한 문제를 해결하기 위해 조정 가능한 민감도(Adjustable Sensitivity, AS) 전략과 다중 스케일 융합(Multi-Scale Fusion)에 기반한 정교한 적외선 소형 표적 검출 방안을 제안합니다.

- **Technical Details**: 구체적으로, 다중 스케일 방향 인식 네트워크(Multi-Scale Direction-Aware Network, MSDA-Net) 기반의 다중 스케일 모델 융합 프레임워크를 구축하여 여러 스케일의 입력 이미지를 사용해 여러 모델을 훈련시키고 이를 융합합니다. 다중 스케일 융합은 서로 다른 스케일에서 표적의 모양, 가장자리, 질감 특징을 갖추고 있어 모델의 타겟 위치 식별을 더 정확하고 신뢰성 있게 만듭니다. 또한, 적외선 소형 표적 검출 과제의 특성을 충분히 고려하여 가장자리 강화 난이도 마이닝(Edge Enhancement Difficulty Mining, EEDM) 손실을 구축합니다. EEDM 손실은 불균형한 카테고리 문제를 완화하고 네트워크가 학습 중 어려운 타겟 영역과 가장자리 특징에 더 집중하도록 유도합니다.

- **Performance Highlights**: 추가로, 후 처리에 대해 조정 가능한 민감도 전략을 제안합니다. 이 전략은 분할 정확도를 보장하면서 적외선 소형 표적의 검출율을 크게 향상시킵니다. 광범위한 실험 결과, 제안한 방안이 최고의 성능을 달성했음을 보여줍니다. 특히 이 방안은 PRCV 2024 광역 적외선 소형 표적 검출 대회에서 1위를 차지했습니다.



### UniTTA: Unified Benchmark and Versatile Framework Towards Realistic Test-Time Adaptation (https://arxiv.org/abs/2407.20080)
- **What's New**: 이번에 발표된 연구는 테스트 시간 적응(Test-Time Adaptation, TTA) 모델에 대한 새로운 벤치마크(Unified Test-Time Adaptation, UniTTA)를 제안합니다. UniTTA 벤치마크는 다양한 도메인(domain)과 클래스 불균형(class imbalance) 조건에서 TTA 모델을 평가할 수 있도록 설계되었습니다. 이를 통해 현실적인 TTA 성능을 종합적으로 평가할 수 있습니다.

- **Technical Details**: UniTTA 벤치마크는 각 시나리오를 원본 데이터셋에서 샘플링하기 위한 마코프 상태 전이 행렬(Markov state transition matrix)로 설명합니다. 이 벤치마크는 도메인과 클래스를 독립적인 두 차원으로 고려하여, 불균형/균형(imbalance/balance) 및 독립적/비독립적/연속적(i.i.d./non-i.i.d./continual) 조건의 조합을 다룹니다. 총 36가지 시나리오를 포괄합니다. 또한, 벤치마크와 함께 제안된 UniTTA 프레임워크는 균형 도메인 정규화(Balanced Domain Normalization, BDN) 레이어와 상관된 특징 적응(COrrelated Feature Adaptation, COFA) 방법을 포함합니다. BDN은 도메인 분포 차이를, COFA는 클래스 분포 차이를 줄이는 데 도움이 됩니다.

- **Performance Highlights**: 실험 결과, UniTTA 프레임워크는 UniTTA 벤치마크에서 뛰어난 성능을 보이며, 평균적으로 최첨단 성능(state-of-the-art performance)을 달성했습니다. 연구진은 관련 코드를 공개하여, 실무자들이 적절한 TTA 방법을 선택하는 데 가이드를 제공합니다.



### Background Semantics Matter: Cross-Task Feature Exchange Network for Clustered Infrared Small Target Detection With Sky-Annotated Datas (https://arxiv.org/abs/2407.20078)
- **What's New**: 적외선 소형 타겟 탐지(infrared small target detection)는 타겟 자체 특징이 적고 유사한 배경 혼란 요소가 많아, 기존 방식으로는 탐지가 쉽지 않았습니다. 이를 해결하기 위해 새로운 과제인 클러스터 적외선 소형 타겟 탐지(clustered infrared small target detection)를 제안하고, DenseSIRST라는 새로운 벤치마크 데이터셋을 소개합니다. 이 데이터셋은 배경 영역에 대한 픽셀 단위의 시멘틱 어노테이션을 제공하여 기존의 희박한 타겟 탐지에서 밀도 높은 타겟 탐지로의 전환을 가능하게 합니다.

- **Technical Details**: DenseSIRST를 활용하여 'Background-Aware Feature Exchange Network (BAFE-Net)'라는 모델을 제안합니다. 이 모델은 단일 타겟 탐지에서 벗어나 타겟 탐지와 배경 시멘틱 세그멘테이션을 동시에 수행하는 멀티태스크 아키텍처로 전환됩니다. BAFE-Net은 타겟과 배경 시멘틱을 두 과제 사이에 상호 교환(cross-task feature hard-exchange)하여 정확도를 높입니다. 추가로, 배경 인식 가우시안 카피-페이스트(Background-Aware Gaussian Copy-Paste, BAG-CP) 방법을 제안하여, 훈련 중 복잡한 비하늘 배경에서의 오탐(false alarm)을 피하기 위해 작은 타겟을 선별적으로 하늘 영역에 복사-붙여넣기 합니다.

- **Performance Highlights**: 광범위한 실험을 통해 BAG-CP와 BAFE-Net의 타겟 탐지 정확도 향상과 오탐 감소 효과를 검증하였습니다. DenseSIRST 데이터셋, 코드, 훈련된 모델은 공개되어 있으므로, 연구자들은 이를 통해 추가적인 검증 및 개발을 진행할 수 있습니다.



### SalNAS: Efficient Saliency-prediction Neural Architecture Search with self-knowledge distillation (https://arxiv.org/abs/2407.20062)
Comments:
          Published in Engineering Applications of Artificial Intelligence

- **What's New**: 최근 심층 합성곱 신경망(Deep Convolutional Neural Networks)을 통한 주목성 예측(Saliency Prediction)의 성능이 크게 향상되었습니다. 그러나 신경망 아키텍처를 수동으로 구성하는 것은 여전히 도메인 지식과 많은 시간이 필요하며 오류가 발생할 수 있습니다. 이를 해결하기 위해 우리는 새로운 신경망 아키텍처 검색(Neural Architecture Search, NAS) 프레임워크를 제안합니다. 이 프레임워크의 첫 번째 기여는 후보 아키텍처를 모두 포함하는 가중치 공유 네트워크를 통해 주목성 예측을 위한 슈퍼넷(Supernet)을 구축하며, 이를 SalNAS라고 명명합니다. 두 번째 기여는 Self-KD(Self-Knowledge Distillation) 접근 방식을 통해 일반화 성능을 향상시키는 것입니다.

- **Technical Details**: SalNAS는 인코더-디코더(Encoder-Decoder)에 다이나믹 합성곱(Dynamic Convolution)을 통합하여 구성된 가중치 공유 네트워크로, 모든 후보 아키텍처를 포함합니다. 비록 SalNAS가 20.98백만 개의 파라미터를 가진 매우 효율적인 모델일지라도, 일반화의 부족 문제를 겪을 수 있습니다. 이를 해결하기 위해, Self-KD 접근 방식을 제안합니다. Self-KD에서는 학생 SalNAS를 훈련할 때, 교사 모델(Teacher Model)에서의 예측값과 실제 값의 가중 평균 정보를 사용합니다. 교사 모델은 동일한 아키텍처를 가지며, 교차 검증(Cross-Validation)으로 선택된 최적의 가중치를 포함합니다. Self-KD는 교사 모델에서의 그래디언트(Gradient) 계산 없이도 효율적인 훈련 시스템을 구현할 수 있습니다.

- **Performance Highlights**: Self-KD를 활용한 SalNAS는 일곱 개의 벤치마크 데이터셋(Benchmark Datasets)에서 대부분의 평가 기준에서 다른 최첨단 주목성 예측 모델들을 능가하면서 경량 모델로서의 특성을 유지합니다.



### MaskInversion: Localized Embeddings via Optimization of Explainability Maps (https://arxiv.org/abs/2407.20034)
Comments:
          Project page: this https URL

- **What's New**: Vision-language 모델인 CLIP과 같은 기초 모델들은 글로벌 차원의 이미지-언어 정합성에서 놀라운 성과를 거두었지만, 여전히 특정 이미지 영역에 대한 표현에서는 한계가 존재합니다. 이를 해결하기 위해 MaskInversion 방법을 제안합니다. MaskInversion은 사전 학습된 기초 모델들의 특징 표현을 활용하여 테스트 시 마스크로 지정된 쿼리 이미지 영역에 대해 컨텍스트 인식형 임베딩을 생성합니다.

- **Technical Details**: MaskInversion은 초기화된 임베딩 토큰(embedding token)을 시작점으로 하여, 기초 모델에서 파생된 설명 가능성 맵(explainability map)을 쿼리 마스크와 비교합니다. 임베딩 토큰은 그 후 설명 가능성 맵과 쿼리 마스크 간의 차이를 최소화하여 쿼리 영역을 근사하도록 정제됩니다. 이 과정에서 기초 모델 자체는 고정된 상태로 유지되며, 임베딩 벡터만 업데이트됩니다. 설명 가능성 맵을 도출하기 위해 그라디언트를 계산하는 것은 비용이 많이 들 수 있으므로, 우리는 이 계산을 단순화하는 그라디언트 분해 전략(gradient decomposition strategy)을 제안합니다.

- **Performance Highlights**: 학습된 지역 표현은 오픈 보캐뷸러리(open-vocabulary) 클래스 검색, 언급 표현 이해(referring expression comprehension), 국지화된 캡셔닝(localized captioning) 및 이미지 생성과 같은 다양한 작업에 사용할 수 있습니다. 우리는 PascalVOC, MSCOCO, RefCOCO, OpenImagesV7와 같은 여러 데이터셋에서 제안된 방법을 평가하고 다른 최신 기법(State-Of-The-Art)들과 비교하여 그 성능을 입증했습니다.



### ImagiNet: A Multi-Content Dataset for Generalizable Synthetic Image Detection via Contrastive Learning (https://arxiv.org/abs/2407.20020)
Comments:
          24 pages, 9 figures, 9 tables

- **What's New**: 새로운 연구인 ImagiNet이 소개되었습니다. 이는 고해상도와 균형 잡힌 데이터셋으로, 기존 자원에서 발생할 수 있는 잠재적 편향을 줄이기 위해 설계된 합성 이미지 검출용 데이터셋입니다. 20만 개의 예시를 포함하며, 사진, 그림, 얼굴, 카테고리 미분류 등의 네 가지 콘텐츠 범주를 포함합니다. 이 연구는 합성 이미지를 진짜 이미지와 구분하고 생성 모델을 식별할 수 있는 시스템을 제공합니다.

- **Technical Details**: ImagiNet은 공개 소스와 독점 생성기를 사용하여 생성된 합성 이미지와 공개 데이터셋에서 수집된 동일한 콘텐츠 유형의 실제 이미지로 구성됩니다. ResNet-50 모델이 자기 지도 대조 목표(Self-supervised contrastive objective: SelfCon)를 사용하여 두 가지 트랙(i) 진짜 또는 합성 이미지로 분류, ii) 생성 모델 식별)에서 훈련됩니다.

- **Performance Highlights**: ImagiNet은 벤치마크에서 최첨단 성능을 보이며 높은 추론 속도를 갖추고 있습니다. AUC가 최대 0.99에 도달하였고, 균형 정확도는 86%에서 95% 범위로 소셜 네트워크 조건(압축 및 리사이징 포함)에서도 우수한 성능을 보여줍니다.



### Classification of freshwater snails of the genus Radomaniola with multimodal triplet networks (https://arxiv.org/abs/2407.20013)
Comments:
          Spotlight at ICML 2024 AI for Science workshop

- **What's New**: 본 논문에서는 Radomaniola 속의 민물 달팽이를 분류하는 머신러닝 시스템의 첫 번째 제안을 소개합니다. 작은 규모의 불균형 데이터셋과 많은 수의 클래스, 클래스 간의 높은 시각적 유사성이라는 특정한 도전에 대해 논의하고 이를 어떻게 해결했는지 설명합니다.

- **Technical Details**: 이 도전 과제들을 극복하기 위해 트리플렛 네트워크(triplet networks)와 이미지, 측정치, 유전 정보의 여러 입력 모달리티를 사용했습니다. 이로 인해 분류 성능이 숙련된 도메인 전문가와 비슷한 수준에 도달할 수 있었습니다.

- **Performance Highlights**: 본 시스템은 작은 규모이면서도 매우 불균형한 데이터셋을 다루며, 다양한 특징을 결합함으로써 높은 정확도를 달성했습니다.



### Reproducibility Study of "ITI-GEN: Inclusive Text-to-Image Generation" (https://arxiv.org/abs/2407.19996)
Comments:
          Accepted to TMLR, see this https URL

- **What's New**: 이 연구는 'ITI-GEN: Inclusive Text-to-Image Generation' 모델 재현 연구로, Zhang et al. (2023a)에서 제안한 모델을 재현하여 모델의 포용성을 개선하는 방법을 탐구합니다. 연구 결과, ITI-GEN이 생성 이미지의 다양성과 품질을 향상시키고 확장 가능하며 Plug-and-Play 기능과 효율적인 계산 성능을 갖춘다는 주장이 대부분 사실임을 확인했습니다.

- **Technical Details**: ITI-GEN 모델은 종종 원치 않는 속성을 대리 특징(Proxy Feature)으로 사용하거나 성별과 대머리와 같은 상관된 속성 쌍을 분리하지 못하는 문제를 겪습니다. 또한, 고려되는 속성의 수가 증가할수록 학습 시간이 기하급수적으로 증가하고, 합성된 모든 요소에 대해 포용적인 이미지를 생성하는 데 어려움을 겪습니다. 이러한 문제를 해결하기 위해 우리는 하드 프롬프트 검색(Hard Prompt Search)과 부정 프롬프트(negative prompting)를 제안합니다. 이는 학습이 필요하지 않으며, 기본 하드 프롬프트 검색에 비해 부정을 처리하는 데 탁월합니다.

- **Performance Highlights**: Hard Prompt Search (negative prompting 포함)는 자연어로 표현하기 어려운 연속형 속성에는 사용이 불가능합니다. 반면, ITI-GEN은 학습 중 이미지를 통해 가이드되므로 이러한 영역에서 뛰어납니다. 최종적으로, ITI-GEN과 Hard Prompt Search (negative prompting 포함)를 결합하여 최상의 성능을 도출하는 방안을 제안합니다.



### More precise edge detections (https://arxiv.org/abs/2407.19992)
Comments:
          11 pages

- **What's New**: 이미지 엣지 감지(Edge Detection, ED)는 컴퓨터 비전의 기본 과제입니다. CNN 기반 모델을 도입함으로써 ED 알고리즘의 성능이 크게 향상되었지만, 현재의 모델들은 매우 낮은 오류 허용 범위에서 여전히 불만족스러운 정밀도(precision) 비율을 보입니다. 따라서 더 정밀한 예측을 위한 모델 구조에 대한 조사가 필요합니다. 본 논문에서는, 더 정밀한 ED 모델을 Cascaded Skipping Density Blocks(CSDB)으로 제안합니다. 이 CSDB 모델은 다양한 데이터셋에서 최첨단(SOTA) 예측 결과를 획득했으며, 특히 평균 정밀도율(AP)에서 두각을 나타냈습니다.

- **Technical Details**: 우리의 모델은 다운샘플링(down-sample) 작업을 포함하고 있지 않으며, 이로 인해 일반적으로 신뢰되는 해당 작업이 반드시 필요하지 않음을 입증합니다. 또한, 데이터 증가(data augmentation)에 대한 새로운 수정 사항을 사용하여 훈련 시 노이즈 없는 데이터가 사용될 수 있도록 하여, 엣지 맵(edge maps) 자체에 대한 예측 성능을 향상시킵니다.

- **Performance Highlights**: 제안된 모델은 여러 데이터셋에서 높은 평균 정밀도(AP)를 달성하며 최첨단(SOTA) 결과를 나타냈습니다. 특히, 광범위한 실험을 통해 이를 확인하였습니다.



### Mixture of Nested Experts: Adaptive Processing of Visual Tokens (https://arxiv.org/abs/2407.19985)
- **What's New**: Vision Transformer (ViT) 모델들은 대규모 데이터 처리에 효과적으로 확장될 수 있지만, 시각적 정보의 내재된 중복성(redundancy)을 활용하지 못해 높은 계산 비용을 수반합니다. 이를 해결하기 위해 Mixture of Experts (MoE) 네트워크는 동일한 추론 시간 비용을 유지하면서도 확장성을 제공합니다. 하지만, 이 방법은 더 많은 파라미터를 요구합니다. 본 연구에서는 각 전문가가 증가하는 계산-정확도 곡선에 위치한 병렬구조로 중첩된 전문가(Mixture of Nested Experts, MoNE)를 제안합니다. MoNE는 동적으로 토큰을 우선순위에 따라 선택하고, 중복된 토큰을 더 저렴한 중첩된 전문가를 통해 처리함으로써 주어진 계산 예산 내에서 효율성을 극대화합니다.

- **Technical Details**: MoNE는 포괄적인 전문가 구조를 사용하여 계산 예산에 맞춰 동적으로 토큰을 선택합니다. 중복된 토큰은 더 저렴한 중첩 전문가들을 통하는 점을 이용해 효율성을 높입니다. 이를 통해, 기본 모델들과 동일한 성능을 달성하면서도 추론 시간 계산을 두 배 이상 줄입니다. 주요 데이터셋인 ImageNet-21K, Kinetics400, 그리고 Something-Something-v2에서 본 접근법을 검증하였습니다. MoNE는 단일 학습 모델로 다양한 추론 시간 계산 예산에서도 강력한 성능을 유지하여 적응성을 보여줍니다.

- **Performance Highlights**: 기본 모델과 동일한 성능을 유지하면서도 추론 시간 계산을 두 배 이상 줄였습니다. ImageNet-21K, Kinetics400 및 Something-Something-v2 데이터셋 상에서 MoNE의 효율성을 검증하였습니다. 단일 학습 모델을 사용하여 다양한 추론 시간 계산 예산에서도 일관된 성능을 보여주는 강력한 적응성을 입증하였습니다.



### Adversarial Robustness in RGB-Skeleton Action Recognition: Leveraging Attention Modality Reweighter (https://arxiv.org/abs/2407.19981)
Comments:
          Accepted by IJCB 2024

- **What's New**: 이번 연구에서는 RGB-skeleton 행동 인식 모델의 강건성을 향상시키는 방안을 체계적으로 조사했습니다. 특히 기존 연구가 단일 모달(domain)에 집중했던 것과 달리, 우리는 멀티 모달(multi-modal) 접근법을 통해 더 높은 강건성을 추구합니다.

- **Technical Details**: 우리는 RGB 모달리티와 skeleton 모달리티 각각의 강건성에 대한 실증 분석을 실시한 결과, skeleton 모달리티가 더 강건하다는 것을 확인했습니다. 이를 바탕으로, 우리는 주의(attention) 레이어를 활용하여 두 모달리티를 재가중(weight)하는 AMR (Attention-based Modality Reweighter)을 제안합니다. AMR은 멀티모달 모델과의 쉬운 통합을 위해 플러그 앤 플레이(plug-and-play) 방식으로 설계되었습니다.

- **Performance Highlights**: NTU-RGB+D 60 데이터셋 기준으로, AMR 방식이 기존의 SOTA 방법들에 비해 PGD20 공격에 대해 43.77% 향상된 성능을 보였습니다. 이는 여러 모달리티 간의 강건성 차이를 효과적으로 균형잡는 결과를 보여줍니다.



### FedDEO: Description-Enhanced One-Shot Federated Learning with Diffusion Models (https://arxiv.org/abs/2407.19953)
Comments:
          Accepted by MM 24

- **What's New**: 새로운 연구인 FedDEO는 Description-Enhanced One-Shot Federated Learning (OSFL) 기법을 제안합니다. 이는 확산 모델(Diffusion Model, DM)을 사용하여 로컬 클라이언트의 지식을 서버로 전송하는 혁신적인 접근법을 탐구합니다. 기존의 방법들과 달리, 이 방법은 공공 데이터셋이나 통일된 특징 추출기를 필요로 하지 않습니다.

- **Technical Details**: FedDEO의 핵심 아이디어는 클라이언트 데이터에서 로컬 설명(local descriptions)을 훈련시키는 것으로, 이를 통해 분산된 클라이언트의 지식을 서버로 전송합니다. 구체적으로, 클라이언트들은 자신들의 데이터를 통해 로컬 설명을 훈련시키며, 이들은 서버로 업로드됩니다. 서버에서는 이 설명들을 조건으로 사용하여 다양한 클라이언트 분포에 맞는 합성 데이터셋을 생성하는 DM을 안내합니다. 이 합성 데이터셋을 사용해 집합된 모델을 훈련시킵니다.

- **Performance Highlights**: 세 가지 대규모 실제 데이터셋에 대한 이론적 분석 및 충분한 데이터와 시각화 실험을 통해, 로컬 설명을 훈련함으로써 서버가 높은 품질과 다양성을 갖춘 합성 데이터셋을 생성할 수 있음을 입증했습니다. 이에 따라 통신 및 프라이버시 보호 측면에서 이점이 있으며, 집합된 모델은 기존의 연합학습(FL) 또는 확산 기반 OSFL 방법들과 비교하여 우수한 성능을 나타냈고, 일부 클라이언트에서는 중앙 집중식 훈련의 성능 최고치를 넘어섰습니다.



### Robust Conformal Volume Estimation in 3D Medical Images (https://arxiv.org/abs/2407.19938)
Comments:
          Early accepted at MICCAI 2024

- **What's New**: 3D 의학 이미지 분할(3D medical image segmentation)의 중요한 응용 중 하나인 체적 측정(Volumetry)에 대해 새로운 접근법이 제안되었습니다. 이 논문에서는 Conformal Prediction의 가중치 기반(weighted) 형식을 적용하여 불확실성 정량화(uncertainty quantification)에서 발생하는 교환 가능성 가정(exchangability assumption)의 문제를 완화하려는 내용을 다루고 있습니다.

- **Technical Details**: 기존 Conformal Prediction 방법론은 보정 샘플과 테스트 샘플이 교환 가능하다는 가정을 기반으로 합니다. 그러나 의료 이미지 영역에서는 이 가정이 자주 위배되는 문제가 있습니다. 이를 해결하기 위해, 보정과 테스트 분포 사이의 밀도 비율(density ratio)을 추정하는 효율적인 접근법을 제안하였습니다. 이는 세그멘테이션 모델(segmentation model)이 생성한 압축된 잠재 표현(compressed latent representations)을 사용합니다. 이러한 접근법은 고차원의 데이터(high-dimensional data)를 다룰 때 특히 유용합니다.

- **Performance Highlights**: 제안된 방법은 공변량 변화(covariate shifts)가 있는 상황에서 커버리지 오류(coverage error)를 줄이는 데 효율적임을 입증했습니다. 이는 합성 데이터(synthetic data)와 실제 데이터(real-world settings) 모두에서 확인되었습니다.



### FreeLong: Training-Free Long Video Generation with SpectralBlend Temporal Attention (https://arxiv.org/abs/2407.19918)
Comments:
          Project page: this https URL

- **What's New**: 최신 연구는 짧은 동영상 생성 모델(short video diffusion model)을 기반으로 일관되고 더 긴 동영상을 생성하는 방법을 제안합니다. 새로운 접근 방식을 통해 사전 학습된 16 프레임 동영상 생성 모델을 128 프레임 동영상 생성으로 확장할 수 있는 FreeLong 솔루션이 소개됩니다.

- **Technical Details**: FreeLong은 길이에 상관없이 높은 품질의 동영상을 생성하기 위해 주파수 분포를 균형 잡아 비디오 기능을 개선합니다. 이 방법은 전역 비디오 특징(global video features)의 저주파(low-frequency) 컴포넌트와 국부 비디오 특징(local video features)의 고주파(high-frequency) 컴포넌트를 혼합합니다. 이를 통해 전역 일관성을 유지하면서 지역적인 세부 정보를 풍부하게 유지합니다.

- **Performance Highlights**: FreeLong은 여러 기본 비디오 확산 모델에서 테스트되었으며, 상당한 성능 개선을 보여주었습니다. 추가적으로, FreeLong은 여러 프롬프트를 갖는 경우에도 시각적 일관성과 씬(scene) 간의 매끄러운 전환을 지원하여 일관성 있는 멀티 프롬프트 생성이 가능합니다.



### Cell Culture Assistive Application for Precipitation Image Diagnosis (https://arxiv.org/abs/2407.19913)
Comments:
          18 pages, 15 figures, 5 tables

- **What's New**: 이 연구에서는 재생 의학 연구에서 중요한 384-well 플레이트 내의 침전을 자동으로 감지하는 애플리케이션을 개발했습니다. 이 시스템은 광학 현미경 이미지를 사용하여 배양된 세포의 상태를 모니터링하며, 인간 감독의 부하를 줄이고 일관된 검사를 제공합니다.

- **Technical Details**: 이 연구는 약 20,000개의 이미지 패치로부터 침전 클래스를 추출하기 위해 MN-pair 대조 클러스터링(mn-pair contrastive clustering)을 적용했습니다. 또한, 침전 특징을 감지하기 위해 더 깊은 FCDDs 검출기와 선택적 백본(optional backbones)을 비교했습니다. 이후, Quadruplet well 이미지의 최대 점수를 사용하여 Isolation Forest 알고리즘을 통해 침전을 탐지할 수 있는 머신 러닝 파이프라인을 구축했습니다. 이 안omaly score는 0에서 1의 범위로 제공됩니다.

- **Performance Highlights**: 이 애플리케이션을 통해 384-well 플레이트에서 침전 상황을 히트맵(heatmap)으로 시각화할 수 있습니다. 침전 특징이 지나치게 축소되지 않도록 1200 픽셀 사각형 웰 이미지를 240 픽셀 크기 사각형으로 나누고 해상도를 유지했습니다. 이 방법으로 약 10-20μm 크기의 작은 침전 특징을 효과적으로 감지할 수 있습니다.



### End-to-end SYNTAX score prediction: benchmark and methods (https://arxiv.org/abs/2407.19894)
- **What's New**: 이번 연구에서는 관상동맥 질환(severity) 심각도를 측정하는 SYNTAX 점수를 자동으로 추정하는 새로운 의료 회귀(regression) 및 분류(classification) 문제를 도입합니다. 연구는 1,844명의 환자를 대상으로 하며, 이는 SYNTAX 점수가 0인 환자와 0이 아닌 환자들이 균형 있게 분포되어 있는 종합 데이터셋을 제공합니다.

- **Technical Details**: 이 데이터셋에는 다중 뷰 X-ray 비디오를 통해 캡처된 완전한 관상동맥조영술(coronary angiography) 샘플이 포함되어 있어 여러 각도에서 관상동맥을 관찰할 수 있습니다. 또, SYNTAX 점수를 추정하기 위한 새롭고 완전 자동화된 end-to-end 방법을 제시합니다.

- **Performance Highlights**: 이와 같은 어려운 작업을 위해, 점수 예측에서 R2 결정 계수(coefficient of determination) 0.51의 의미 있는 성과를 달성하였습니다.



### Self-Supervised Learning for Text Recognition: A Critical Survey (https://arxiv.org/abs/2407.19889)
Comments:
          This article is under revision

- **What's New**: 이 논문은 이미지에서 텍스트 정보를 추출하는 텍스트 인식(Text Recognition, TR) 분야에서 자기 지도 학습(Self-Supervised Learning, SSL)의 적용에 대한 포괄적인 리뷰를 제공합니다. 최근 몇 년 동안 TR 분야에서도 SSL 방법론이 급격히 발전하고 있지만, 이러한 방법들이 독립적으로 탐구되고 비교 분석이 부족하여 연구의 진전에 장애가 되고 있습니다. 이 논문은 이러한 문제를 해결하기 위해 SSL을 사용한 TR 연구의 현재 상태를 종합적으로 검토하고 분석합니다.

- **Technical Details**: 기존 텍스트 인식 솔루션들은 딥 뉴럴 네트워크(Deep Neural Networks, DNN)을 사용하여 큰 양의 수동으로 라벨링된 데이터나 합성 데이터를 필요로 합니다. 그러나 SSL은 레이블이 없는 데이터셋을 활용하여 DNN을 훈련시키고, 의미 있는 강력한 표현을 생성하는 방식입니다. TR의 독특한 특성 때문에 초기에 SSL은 간과되었지만, 최근에는 TR을 위한 SSL 방법론이 활발히 개발되고 있습니다. 이 논문은 이러한 SSL 방법론들을 비교하고, 현재 문헌의 불일치점을 강조하며, TR 분야의 일반적인 통찰을 제공합니다.

- **Performance Highlights**: 논문은 현재 존재하는 다양한 SSL 방법론들의 결과를 비교 분석하고, 문헌의 불일치점을 지적합니다. 이를 통해 TR 분야에서의 연구 표준화를 제안하고, 새로운 연구 방향을 제시하며, 이 분야의 올바른 발전을 촉진하는 것을 목표로 합니다.



### Yucca: A Deep Learning Framework For Medical Image Analysis (https://arxiv.org/abs/2407.19888)
- **What's New**: Yucca라는 새로운 오픈 소스 AI 프레임워크가 개발되었습니다. 이는 의료 영상 분석을 위해 설계되었으며, PyTorch 및 PyTorch Lightning을 기반으로 구축되었습니다. 핵심은 유연성, 모듈성, 사용자 친화성을 갖춘 것입니다.

- **Technical Details**: Yucca는 Functional(기능), Modules(모듈), Pipeline(파이프라인)의 세 가지 계층 아키텍처를 특징으로 합니다. 이를 통해 포괄적이고 맞춤형 솔루션을 제공합니다. 다양한 의료 영상 분석 태스크에서 최첨단 성과를 달성하였으며, 커뮤니티의 기여를 통해 기능과 영향을 더욱 발전시킬 것을 초대합니다.

- **Performance Highlights**: Yucca는 뇌 내 미세 출혈(Cerebral microbleeds) 탐지, 백질 고강도(White matter hyperintensity) 분할, 해마(Hippocampus) 분할 등의 다양한 작업에서 최첨단(State-of-the-art) 성능을 발휘하였습니다. 이는 Yucca의 견고함과 다재다능함을 입증합니다.



### Exploring Robust Face-Voice Matching in Multilingual Environments (https://arxiv.org/abs/2407.19875)
- **What's New**: 이 논문은 Team Xaiofei의 다국어 환경에서 얼굴-목소리 연관성(Face-Voice Association)을 탐구한 혁신적인 접근법을 소개합니다. 논문은 다국적 환경에서 얼굴-목소리 매칭의 영향을 조사하며 이를 위해 Fusion and Orthogonal Projection (FOP)을 기반으로 한 네 가지 주요 컴포넌트를 도입했습니다: 듀얼 브랜치 구조, 동적 샘플 쌍 가중치 부여, 강력한 데이터 증강 기법, 점수 폴라라이제이션 전략입니다.

- **Technical Details**: 듀얼 브랜치 구조는 보조 기제로 작용하여 다양한 정보를 종합적으로 제공하고 통합합니다. 또한 다양한 샘플 쌍에 동적 가중치 부여 메케니즘을 도입하여 학습을 최적화했습니다. 데이터의 일반화를 향상시키기 위해 데이터 증강 기법도 사용되었습니다. 마지막으로, 연령 및 성별 매칭 정확도를 기반으로 한 점수 폴라라이제이션 전략이 최종 결과를 더 명확하게 합니다.

- **Performance Highlights**: 우리 방법은 V2-EH 데이터셋에서 20.07의 동일 오류율(Equal Error Rate, EER)을, V1-EU 데이터셋에서는 21.76의 EER을 달성하며 상당한 효과성을 입증했습니다.



### Normality Addition via Normality Detection in Industrial Image Anomaly Detection Models (https://arxiv.org/abs/2407.19849)
- **What's New**: 이번 연구에서는 이미지 이상 탐지(IAD) 작업에서 새로운 시나리오인 정상 추가(Normality Addition)를 제안합니다. 이는 훈련 후 의사 결정 경계를 조정하여 새로운 정상 패턴을 포함시키는 방법입니다. 이 시나리오를 해결하기 위해 제안된 방법은 NAND(Normality Addition via Normality Detection)입니다.

- **Technical Details**: NAND는 비전-언어 모델(vision-language model)을 활용하여 정상 탐지(normality detection)를 수행합니다. 이미지에 대한 텍스트 설명을 기반으로 의도된 정상 패턴과 관련된 이미지를 탐지합니다. 그리고 사전 훈련된 이미지 이상 탐지(IAD) 모델 결과를 수정하여 정상 추가를 구현합니다.

- **Performance Highlights**: IAD의 벤치마크 데이터셋인 MVTec AD를 사용하여 정상 추가 작업에 대한 평가 프로토콜을 설정하고 NAND 방법의 효과를 실증적으로 입증했습니다.



### VortSDF: 3D Modeling with Centroidal Voronoi Tesselation on Signed Distance Field (https://arxiv.org/abs/2407.19837)
- **What's New**: 이번 논문에서는 기존의 정규 voxel grid를 대체하는 대안적 방법으로 Centroidal Voronoi Tesselation(CVT)을 활용한 새로운 3D 형태 재구성 방식을 제안합니다. 이 접근법은 shape occupancy에 맞춰 관찰 공간을 더 잘 분할하고, 형태 표면 주변의 이산화를 집중시킵니다.

- **Technical Details**: 이 논문에서는 CVT를 활용한 3D 형태 재구성을 위해 부피 최적화 프레임워크를 도입합니다. 이 프레임워크는 명시적 SDF(fields)를 얕은 색상 네트워크와 결합하여, 사면체(grid) 내에서 3D 형태 속성을 추정합니다. 기존의 voxel grid는 단순하고 깔끔한 장면이 아닐 경우 성능 저하가 발생할 수 있었으나, CVT는 이러한 제한점을 극복할 수 있는 방안을 제시합니다.

- **Performance Highlights**: 실험 결과, Chamfer statistics를 이용한 다양한 시나리오(예: 물체, 열린 장면 또는 인간 등의 재구성)를 통해 이 접근 방식이 이전에 없는 수준의 재구성 품질을 입증했습니다.



### ML-Mamba: Efficient Multi-Modal Large Language Model Utilizing Mamba-2 (https://arxiv.org/abs/2407.19832)
- **What's New**: ML-Mamba는 최신 Mamba-2 모델을 활용한 멀티모달(multimodal) 언어 모델로, 기존의 Transformer 아키텍처 기반 모델이 가진 계산 복잡성 문제를 해결합니다. Mamba-2 모델은 긴 시퀀스(sequence)의 빠른 처리를 제공하며, 이 모델의 특성을 멀티모달 학습에 통합하는 방법을 탐색합니다.

- **Technical Details**: ML-Mamba는 사전 훈련된(pre-trained) Mamba-2 모델을 사용하여 Transformer 기반 백본을 대체하고, 2차원 시각적 선택 스캐닝 메커니즘(2D visual selective scanning mechanisms)을 멀티모달 학습에 통합합니다. 다양한 시각 인코더(visual encoders) 및 Mamba-2 모델 변형을 실험하였습니다.

- **Performance Highlights**: ['ML-Mamba는 TinyLaVA 및 MobileVLM v2와 같은 최첨단 방법론(state-of-the-art methods)과 비교 가능한 성능을 제공하면서 더 빠른 추론 속도를 보여주었습니다.', 'ML-Mamba는 시각적 환각(visual hallucinations) 및 폐쇄형 셋(closed set) 벤치마크 테스트에서의 공간 관계 판단에서 우수한 성능을 입증했습니다.', 'ML-Mamba는 LLaVA와 비교할 때 40% 적은 매개변수(parameter)로 동일한 성능을 달성했습니다.', '기존 Mamba 모델을 사용하는 멀티모달 모델과 비교하여, Mamba-2 기반의 대규모 멀티모달 언어 모델은 더 우수한 추론 성능과 효율성을 보였습니다.']



### ActivityCLIP: Enhancing Group Activity Recognition by Mining Complementary Information from Text to Supplement Image Modality (https://arxiv.org/abs/2407.19820)
- **What's New**: 기존 방식은 주로 이미지 모달리티의 정보만을 사용하여 그룹 활동을 인식합니다. 하지만 이미지 정보 채굴은 이미 포화 상태에 이르렀기 때문에, 더 풍부한 정보를 추출하기 어렵습니다. 따라서 이미지를 보완하기 위해 다른 모달리티에서 보충 정보를 추출하는 것이 점점 중요해지고 있습니다. 특히, 행동 라벨(action labels)은 행동의 의미를 명확하게 표현하는 텍스트 정보를 제공합니다. 이러한 점을 해결하고자, 우리는 ActivityCLIP을 제안합니다. 이는 행동 라벨에 포함된 텍스트 정보를 채굴하여 이미지 정보를 보완하는 플러그앤플레이 방식입니다.

- **Technical Details**: ActivityCLIP은 텍스트와 이미지 브랜치로 구성되어 있습니다. 여기서 텍스트 브랜치가 이미지 브랜치에 플러그인 형태로 추가됩니다. 텍스트 브랜치는 Image2Text 모듈과 관계 모델링 모듈로 구성됩니다. 특히, CLIP을 통해 이미지 정보를 텍스트 정보로 적응시키는 지식 전달 모듈(knowledge transfer module)인 Image2Text를 제안합니다. 또한, 방법의 편의성을 유지하기 위해 적은 수의 학습 가능한 파라미터를 추가하여 텍스트 브랜치에서 상호작용 관계를 모델링 합니다.

- **Performance Highlights**: Method의 일반성을 보여주기 위해, ActivityCLIP을 사용하여 세 가지 대표적인 방법을 복제하였고, 학습 가능한 파라미터를 최소한으로 추가하면서 각 방법의 성능을 크게 향상시켰습니다. 또한, 광범위한 ablation 연구 단독 실험들을 통해, 최첨단 방법들과 비교하여 ActivityCLIP의 효과성을 입증했습니다.



### Image-text matching for large-scale book collections (https://arxiv.org/abs/2407.19812)
- **What's New**: 이 논문은 이미지 컬렉션에 있는 모든 책들을 주어진 도서 카탈로그 항목과 매핑하는 문제를 다루고 있습니다. 독립적인 검색 대신 이미지-텍스트 매핑 문제를 다대다(many-to-many) 매칭 프로세스로 간주하여 두 개의 셋 간의 최적의 매칭을 찾습니다.

- **Technical Details**: 책의 척추를 감지하는 최신 세분화 방법(SAM)을 사용하여 상업용 광학 문자 인식(OCR)을 통해 책 정보를 추출합니다. 그런 다음 CLIP 임베딩(embeddings)을 사용하여 처음 빠른 매칭을 수행하고, Hungarian Algorithm 또는 BERT 기반 모델을 사용하여 매칭을 개선하는 2단계 접근법을 제안합니다. 이 모델은 잡음이 있는 OCR 입력과 부분적인 텍스트 매칭에 대처하도록 훈련되었습니다.

- **Performance Highlights**: 스페인의 한 공공 도서관 전체 책 컬렉션을 포함하는 주석이 달린 새로운 책장 이미지 데이터셋을 게시하고, 두 가지의 책 메타데이터 타겟 리스트 (폐쇄 집합의 15,000과 개방 집합의 2.3백만)를 제공합니다. 두 가지 설정에서 성능을 평가하며, Hungarian Matching과 제안된 BERT 기반 모델은 퍼지 문자열 매칭 대비 더 나은 성능을 보였습니다. 타겟 목록이 커질 때와 검출된 책이나 타겟 책 목록이 불완전할 때 매칭 알고리즘의 한계를 강조합니다.



### Synthetic Thermal and RGB Videos for Automatic Pain Assessment utilizing a Vision-MLP Architectur (https://arxiv.org/abs/2407.19811)
- **What's New**: 이번 연구는 Generative Adversarial Networks(GANs)을 활용해 생성된 합성 열 영상(synthetic thermal videos)을 통증 인식(pain recognition) 파이프라인에 통합하고 그 효능을 평가합니다. Vision-MLP와 Transformer 기반 모듈을 활용하여 RGB 및 합성 열 영상을 단일 모드(unimodal)와 다중 모드(multimodal) 설정에서 사용합니다. 실험은 BioVid 데이터베이스의 얼굴 영상을 기반으로 수행되었습니다.

- **Technical Details**: 이번 연구의 프레임워크는 Vision-MLP와 Transformer 기반 모듈로 구성되어 있으며, 두 모듈 모두 RGB와 합성 열 영상을 활용합니다. 합성 열 영상은 GANs를 통해 생성됩니다. 실험은 얼굴 영상 데이터를 사용하는 BioVid 데이터베이스를 통해 수행되었으며, 이를 통해 합성 열 영상의 효능을 검증했습니다.

- **Performance Highlights**: 실험 결과, 합성 열 영상이 통증 인식의 효과를 높이는 데 유리함을 확인하였습니다. 이는 환자 모니터링의 연속성과 효율성을 향상시키는 데 기여할 수 있는 중요한 결과로 해석됩니다.



### Twins-PainViT: Towards a Modality-Agnostic Vision Transformer Framework for Multimodal Automatic Pain Assessment using Facial Videos and fNIRS (https://arxiv.org/abs/2407.19809)
- **What's New**: 이 논문은 AI4PAIN의 차세대 통증 평가를 위한 첫 번째 멀티모달 감지 그랜드 챌린지에 제출되었습니다. 본 연구에서는 자동 통증 평가의 중요성을 강조하며 이를 위해 안면 비디오와 fNIRS(기능적 근적외선 분광법)를 사용하는 멀티모달 프레임워크를 제안합니다. 이 방법은 도메인에 특화된 모델의 필요성을 줄이는 모달리티 독립적 접근 방식을 채택했습니다.

- **Technical Details**: 제안된 방식에서는 두 개의 Vision Transformer(ViT) 구성을 사용하고, fNIRS의 파형 표현과 두 개의 모달리티에서 추출된 임베딩의 파형 표현을 채택하여 그 효과를 입증했습니다. 이렇게 함으로써 도메인에 특정되지 않는 모델을 이용해 통증 평가를 수행할 수 있습니다.

- **Performance Highlights**: 제안된 방법은 다수준 통증 평가 작업에서 46.76%의 정확도를 달성하며, 자동 통증 평가에서 효과적인 방법임을 보여줍니다.



### Interpreting Low-level Vision Models with Causal Effect Maps (https://arxiv.org/abs/2407.19789)
- **What's New**: Deep neural networks는 저수준 시각 작업(low-level vision tasks)의 성능을 크게 향상시켰지만 해석 가능성은 더욱 어려워졌습니다. 이를 해결하기 위해 우리는 인과론(causality theory)을 사용하여 저수준 시각 모델을 해석하고, Causal Effect Map (CEM)이라는 모델/작업-무관한 방법을 제안합니다. CEM을 통해 입력과 출력 간의 관계를 시각화하고 정량화할 수 있습니다.

- **Technical Details**: CEM은 저수준 시각 작업을 분석할 때 긍정적 혹은 부정적 효과를 시각화하고 정량화하는 도구입니다. 분석 결과 몇 가지 흥미로운 통찰을 얻었는데, (1) 입력 이미지의 더 많은 정보를 사용한다고 해서 항상 긍정적인 결과를 낳는 것은 아니다. (2) 이미지 노이즈 제거(image denoising)에 전체 수용 영역(global receptive field)를 포함하는 메커니즘(e.g., 채널 주의력(channel attention))을 추가하는 것은 무의미할 수 있다. (3) 여러 작업을 통합해 일반 모델을 훈련하면 네트워크가 전역 컨텍스트보다 지역 정보를 우선시할 수 있습니다.

- **Performance Highlights**: 이 도구는 우리의 일반적인 지식을 새롭게 하고, 저수준 시각 모델에 대한 더 깊은 이해를 제공합니다. 코드는 접근 가능합니다.



### SciPostLayout: A Dataset for Layout Analysis and Layout Generation of Scientific Posters (https://arxiv.org/abs/2407.19787)
Comments:
          Accepted by BMVC2024

- **What's New**: 새로운 연구는 SciPostLayout 데이터셋을 소개합니다. 이 데이터셋은 과학 포스터 7,855개와 수동으로 진행된 레이아웃 주석을 포함하며, 이는 레이아웃 분석 및 생성 연구에 사용됩니다. 추가로, 데이터셋은 100개의 과학 논문과 해당 포스터를 포함하고 있습니다. 모든 자료는 CC-BY 라이선스 하에 공개적으로 이용 가능하며, 관련 데이터셋과 코드도 공개되어 있습니다.

- **Technical Details**: SciPostLayout 데이터셋은 레이아웃 분석(leayout analysis) 및 생성(layout generation)을 위해 기존 컴퓨터 비전 모델을 사용하여 실험을 수행했습니다. 또한, 이 데이터셋을 통해 과학 논문에서 포스터 레이아웃을 생성하는 실험도 진행했으며, 이를 통해 대형 언어 모델(large language models, LLM)을 과학 포스터 생성 시스템으로 활용할 가능성을 확인했습니다.

- **Performance Highlights**: 레이아웃 분석 및 생성 실험에서, SciPostLayout을 활용한 테스트는 기존의 과학 논문을 사용하는 것보다 더 어려운 것으로 나타났습니다. 이는 과학 포스터 생성의 도전 과제를 제시하면서도, 새로운 데이터셋의 유용성을 보여줍니다.



### Garment Animation NeRF with Color Editing (https://arxiv.org/abs/2407.19774)
- **What's New**: 전통적인 작업 흐름 없이 캐릭터 움직임에서 직접 고품질의 의류 애니메이션을 생성하는 새로운 접근법을 제안합니다. 이 방법은 명시적인 의류 프록시(proxy) 없이 본체 움직임에서 의류 동적 특징을 추론합니다.

- **Technical Details**: 우리의 접근법은 본체 움직임에서 의류 구조의 초기 개요를 제공합니다. 동시에, 미리 학습된 이미지 모델로 생성된 의류의 앞면과 뒷면의 참조 이미지를 통해 세부적인 특징을 캡처합니다. 이 특징들은 신경 복사장(neural radiance field)을 구성하는데 사용되어 의류 애니메이션 비디오를 렌더링합니다. 또한, 시각적 요소를 분해하여 의류 재색상화 기능을 제공합니다.

- **Performance Highlights**: 기존의 신경 렌더링 기술에 비해 동적 의류 및 주름 세부사항 모델링에서 질적 및 양적으로 개선된 성능을 나타냅니다. 새로운 본체 움직임 및 카메라 뷰에 대한 일반화 가능성을 증명하며, 실제 및 합성 의류 데이터에서 색상 편집의 적용성을 보여줍니다.



### Efficient Face Super-Resolution via Wavelet-based Feature Enhancement Network (https://arxiv.org/abs/2407.19768)
- **What's New**: 이번 연구에서는 얼굴의 고해상도 이미지를 저해상도 이미지로부터 복원하는 새로운 방법을 제안합니다. 기존 방법들은 인코더-디코더 구조를 사용해 얼굴의 구조적 특징을 추출하지만, 직접적인 다운샘플링이 왜곡을 가져오는 문제가 있었습니다. 이를 해결하기 위해, 입력 특징을 고주파와 저주파 성분으로 무손실 분해하여 처리하는 웨이블릿 기반 (wavelet-based) 특징 강화 네트워크를 제안합니다.

- **Technical Details**: 제안된 네트워크는 웨이블릿 변환 (wavelet transform)을 이용해 입력 특징을 고주파 및 저주파 성분으로 나누어 각기 별도로 처리함으로써 특징 왜곡을 줄입니다. 또한, 얼굴 특징 추출의 효율성을 높이기 위해 **풀 도메인 트랜스포머**를 제안하여 로컬, 지역 및 글로벌 얼굴 특징을 강화합니다. 이러한 설계를 통해 여러 모듈을 중첩하지 않고도 더 나은 성능을 발휘할 수 있습니다.

- **Performance Highlights**: 실험 결과, 제안된 방법이 성능, 모델 크기 및 속도에서 효과적으로 균형을 맞추는 것으로 나타났습니다. 이를 통해 기존 방법들보다 더 우수한 결과를 얻을 수 있었습니다.



### PredIN: Towards Open-Set Gesture Recognition via Prediction Inconsistency (https://arxiv.org/abs/2407.19753)
Comments:
          Under review

- **What's New**: 이 논문은 surface electromyography (sEMG)를 기반으로 한 제스처 인식에서 효과적인 open-set 시스템을 제안합니다. 기존의 모델들이 미리 정의된 제스처들만 인식하는 데에 그쳤던 반면, 이번 연구는 알려지지 않은 제스처를 정확히 거부하면서 알려진 제스처를 정확하게 분류하는 기술을 개발했습니다.

- **Technical Details**: 제안된 PredIN(ensemble learning approach) 모델은 앙상블의 다양성을 향상시켜서 예측 일관성(prediction inconsistency)을 증폭시킵니다. 이를 통해 알려지지 않은 제스처를 더 효과적으로 탐지할 수 있습니다. PredIN 모델은 각 앙상블 구성원 간의 클래스 특징 분포 불일치(class feature distribution inconsistency)를 최대화하여 다양성을 늘리고, 동시에 개별 앙상블 구성원의 성능을 유지하기 위해 클래스 간 분리성(inter-class separability)을 최적화합니다.

- **Performance Highlights**: PredIN 모델은 다양한 벤치마크 데이터셋에서 최신 방법들보다 성능이 우수하다는 것을 입증했습니다. 특히 미리 정의된 제스처에 대한 정확한 닫힌 세트 분류와 알려지지 않은 제스처에서의 효과적인 거부를 동시에 성취하는 데 성공해 open-set 제스처 인식에서 큰 효과와 우월성을 보여주고 있습니다.



### Contextuality Helps Representation Learning for Generalized Category Discovery (https://arxiv.org/abs/2407.19752)
- **What's New**: 본 논문은 일반화된 카테고리 발견 (Generalized Category Discovery, GCD)을 위한 새로운 접근법을 소개합니다. 이 접근법은 맥락성(contextuality) 개념을 활용하여 라벨이 없는 데이터셋에서 카테고리를 식별하고 분류하는 능력을 향상시킵니다. 이는 인간 인지가 맥락 내에서 객체를 인식하는 능력에서 영감을 받았습니다.

- **Technical Details**: 제안된 모델은 두 수준의 맥락성을 통합합니다. 인스턴스 수준(instance-level)에서는 근접 이웃 컨텍스트를 활용한 대조 학습(contrastive learning)을 사용하고, 클러스터 수준(cluster-level)에서는 카테고리 프로토타입(category prototypes)을 기반으로 한 전형적인 대조 학습(prototypical contrastive learning)을 사용합니다. 이 맥락 정보를 통합함으로써 특징 학습과 모든 카테고리의 분류 정확도가 효과적으로 향상됩니다. 이는 전통적인 반지도학습(semi-supervised) 및 새로운 카테고리 발견 기술과는 다르게, 알려진 카테고리와 새로운 카테고리가 모두 포함된 라벨이 없는 데이터에서 실질적이고 도전적인 시나리오에 중점을 둡니다.

- **Performance Highlights**: 몇몇 벤치마크 데이터셋에서의 광범위한 실험 결과, 제안된 모델이 최첨단 기법(state-of-the-art)들을 능가하는 성능을 보여줍니다. 코드도 공개되어 있습니다.



### Octave-YOLO: Cross frequency detection network with octave convolution (https://arxiv.org/abs/2407.19746)
- **What's New**: Octave-YOLO는 임베디드 시스템(embedded systems) 내에서 고해상도(high-resolution) 이미지를 실시간으로 처리하기 위해 설계된 새로운 객체 탐지 모델입니다. 이 모델은 고해상도 이미지 처리 시 발생하는 높은 계산 요구 사항을 줄이기 위해 개발되었습니다.

- **Technical Details**: Octave-YOLO는 입력 피처 맵(feature map)을 저해상도, 저주파수(low-resolution, low-frequency) 및 고해상도, 고주파수(high-resolution, high-frequency) 섹션으로 분할하는 크로스 프리퀀시 파셜 네트워크(CFPNet)를 도입했습니다. 이러한 설정은 복잡한 연산을 저해상도 피처 맵에서만 수행할 수 있게 하여 계산 부담을 크게 줄이면서도 고해상도 맵의 세부사항을 유지합니다. 또한, 깊이 분리 가능한 합성곱(depthwise separable convolution)을 사용하여 지연(latency)도 감소시켰습니다.

- **Performance Highlights**: 경험적 결과에 따르면, Octave-YOLO는 YOLOv8과 거의 동일한 성능을 유지하면서도 계산 요구 사항을 크게 줄였습니다. 예를 들어, 1080x1080 해상도에서 Octave-YOLO-N은 YOLOv8보다 1.56배 빠르게 동작하며, 약 40% 적은 파라미터와 FLOPs로 COCO 데이터셋에서 거의 동일한 정확도를 달성했습니다.



### Revolutionizing Urban Safety Perception Assessments: Integrating Multimodal Large Language Models with Street View Images (https://arxiv.org/abs/2407.19719)
Comments:
          13 pages, 9 figures

- **What's New**: 최신 연구에서 도시 안전 평가를 위한 자동화된 방법론이 제안되었습니다. 전통적으로 안전 평가를 위해서는 인적 자원에 많이 의존했지만, 이 연구에서는 최근 멀티모달 대형 언어 모델(MLLMs)을 활용하여 더 효율적인 방법을 제시합니다. 특히, GPT-4 모델을 사용하여 인간의 인식과 유사한 안전 순위를 매기는 데 성공했습니다.

- **Technical Details**: 연구에서는 사전 학습된 CLIP(Contrastive Language-Image Pre-training) 기능과 K-최근접 이웃(K-NN) 검색 알고리즘을 사용하여 대규모 도시 안전 지수를 빠르게 평가하는 방법을 제안했습니다. 이는 기존의 깊이 학습 모델(deep learning)의 훈련 필요성을 줄이고, 예측 성능을 높이는 데 중점을 두었습니다.

- **Performance Highlights**: 제안된 방법은 기존의 깊이 학습 접근 방식을 뛰어넘는 성능을 보여주었습니다. 실험 결과, 제안된 자동화 방법이 더 효율적이며 정확한 도시 안전 평가를 가능하게 한다는 것이 입증되었습니다. 이는 도시 계획가, 정책 입안자, 연구자들에게 매우 유용한 도구가 될 것입니다.



### Rethinking RGB-D Fusion for Semantic Segmentation in Surgical Datasets (https://arxiv.org/abs/2407.19714)
- **What's New**: 이 논문은 수술 장면 이해를 위한 기술적 구성 요소로서 의미론적 분할(semantic segmentation)을 위한 새로운 방법, SurgDepth를 제안합니다. SurgDepth는 RGB 및 깊이(depth) 정보를 활용한 멀티모달 학습 프레임워크로, 현존하는 모든 공개 데이터셋에서 최고 성능을 보여줍니다. 특히, Vision Transformers(ViTs)를 기반으로 RGB 및 깊이 정보를 단순한 융합 메커니즘을 통해 인코딩하는 방식입니다.

- **Technical Details**: SurgDepth는 Vision Transformers(ViTs)를 기반으로, RGB와 깊이 정보를 모두 인코딩하는 심플한 융합 메커니즘을 사용합니다. 이전 접근 방식과 달리, SurgDepth는 자연 이미지로 학습된 모델을 미세 조정하거나, 단일 RGB 사전 학습(backbone)만 사용하는 것이 아니라, RGB-D 정보를 모두 활용하도록 설계되었습니다. 실험은 EndoVis2022, AutoLapro, LapI2I 및 EndoVis2017과 같은 벤치마크 데이터셋에서 수행되었습니다.

- **Performance Highlights**: SurgDepth는 EndoVis 2022 SAR-RARP50 챌린지에서 새로운 최고 성능 IoU 0.86을 달성하며, 최상의 현재 방법을 최소 4% 이상 초과하였습니다. 이 성과는 ConvNeXt 블록으로 구성된 얕고 계산 효율적인 디코더(decoder)를 사용한 결과입니다.



### ALEN: A Dual-Approach for Uniform and Non-Uniform Low-Light Image Enhancemen (https://arxiv.org/abs/2407.19708)
- **What's New**: 저조도 이미지 향상(Low-light image enhancement) 작업의 중요성을 강조하며, 새로운 접근법인 Adaptive Light Enhancement Network (ALEN)을 소개합니다. ALEN은 이미지의 국소(지역) 및 전체(global)에서 조도 개선이 필요한지를 분류하는 분류 메커니즘(classification mechanism)을 사용하여, 조도와 색상을 동시에 향상시키는 네트워크입니다.

- **Technical Details**: ALEN은 Light Classification Network (LCNet)과 Single-Channel Network (SCNet), Multi-Channel Network (MCNet)으로 구성됩니다. LCNet은 조명 상태를 분류하며, SCNet과 MCNet은 각각 조도와 색상을 정확하게 추정하여 이미지를 향상시킵니다.

- **Performance Highlights**: 공개된 저조도 조건 데이터셋에서 광범위한 실험을 통해 ALEN의 강력한 일반화 능력을 입증했습니다. 정량적(metrics) 및 정성적(qualitative) 평가에서 최근의 최첨단(state-of-the-art) 방법들과 비교하여 탁월한 성능을 보여주었습니다. 또한, ALEN은 시각적 인식(visual perception) 뿐만 아니라, 의미론적 분할(semantic segmentation)과 같은 고차원의 비전 작업에서도 향상된 성능을 나타냅니다.



### Classification Matters: Improving Video Action Detection with Class-Specific Attention (https://arxiv.org/abs/2407.19698)
Comments:
          31 pages, accepted to ECCV 2024

- **What's New**: 이 논문에서는 비디오 액션 검출(Video Action Detection, VAD)에 대한 새로운 접근법을 제안합니다. 전통적인 VAD 방법들이 액터(actor) 지역에만 주로 집중하여 중요한 문맥적 정보(contextual information)를 간과하는 문제를 해결하기 위해, 본 연구에서는 클래스별로 전용 쿼리(class-dedicated query)를 할당하여 문맥과 액터 사이의 균형을 맞추는 방식으로 특징을 추출하고자 합니다.

- **Technical Details**: 제안된 모델은 각 액션 클래스에 대해 전용 쿼리를 할당하여, 각 클래스를 효과적으로 분류하기 위해 어디에 집중해야 할지를 동적으로 결정할 수 있게 합니다. 이를 통해 액터 중심의 편향을 줄이고, 각 액션 클래스에 관련된 문맥적 정보에도 주의를 기울이도록 설계되었습니다.

- **Performance Highlights**: 제안된 모델은 세 가지 도전적인 벤치마크 테스트에서 모두 우수한 성능을 보여주었습니다. 특히, 적은 수의 파라미터와 더 적은 계산량으로도 탁월한 성능을 발휘하였습니다.



### Cross-Layer Feature Pyramid Transformer for Small Object Detection in Aerial Images (https://arxiv.org/abs/2407.19696)
- **What's New**: 이번 논문에서는 공중 이미지(aerial images)에서의 작은 객체 감지에 특화된 새로운 업샘플러 프리 피처 피라미드 네트워크(Cross-Layer Feature Pyramid Transformer, CFPT)를 소개합니다. CFPT는 두 가지 주의 블록(attention blocks)을 활용하여 선형 계산 복잡성을 가지고 있습니다: Cross-Layer Channel-Wise Attention (CCA)와 Cross-Layer Spatial-Wise Attention (CSA). 또한 CFPT는 위치 인식 능력을 향상시키기 위해 Cross-Layer Consistent Relative Positional Encoding (CCPE)를 제안합니다.

- **Technical Details**: CCA는 채널 차원에서 cross-layer global information을 파악하기 위해 채널별 토큰 그룹을 나누어 cross-layer 상호작용을 수행하며, CSA는 공간 차원에서 이를 수행합니다. 이러한 모듈들을 통합함으로써, CFPT는 cross-layer 상호작용을 한 번에 가능하게 하여 요소별 합산 및 층별 전송과 관련된 의미적 차이와 정보 손실을 방지합니다. 또한 CFPT는 글로벌 컨텍스트 정보를 통합하여 작은 객체의 감지 성능을 향상시킵니다. CCPE는 inter-layer mutual receptive fields에 기반하여 디자인된 위치 인식 인코딩 기법입니다.

- **Performance Highlights**: CFPT는 VisDrone2019-DET와 TinyPerson이라는 두 가지 어려운 공중 이미지 객체 감지 데이터셋에서 그 성능을 평가받았습니다. 광범위한 실험 결과, CFPT는 최신의 피처 피라미드 네트워크를 능가하면서도 더 낮은 계산 비용을 주장합니다. 관련 코드는 추후 공개될 예정입니다.



### Structural damage detection via hierarchical damage information with volumetric assessmen (https://arxiv.org/abs/2407.19694)
- **What's New**: 구조적 손상 탐지 모델에서 이미지 환경과 노이즈 라벨 문제를 해결하기 위한 새로운 접근법인 Guided-DetNet이 제안되었습니다. 이 모델은 특성적으로 Generative Attention Module (GAM), Hierarchical Elimination Algorithm (HEA), 그리고 Volumetric Contour Visual Assessment (VCVA)로 구성되어 있습니다. 이 세 가지 구성 요소를 통해 복잡한 이미지 환경, 노이즈 라벨링 문제, 그리고 탐지 후 수동 평가 문제를 완화할 수 있습니다.

- **Technical Details**: GAM(Generative Attention Module)은 가로와 세로 방향에서 패치를 병합하고 전경과 배경 특징을 결합하여 복잡한 이미지 환경을 극복합니다. HEA(Hierarchical Elimination Algorithm)는 클래스들간의 계층적인 관계를 이용하여 이미지 내에서 불가능한 클래스를 제거함으로써 노이즈 라벨 문제를 해결합니다. VCVA(Volumetric Contour Visual Assessment)는 Dirac 델타 분포를 활용하여 탐지된 손상에 대한 부피적 표현과 정량화를 통해 손상의 심각성을 평가합니다.

- **Performance Highlights**: 포괄적인 정량적 연구, 두 가지 강건성 테스트, 그리고 PEER Hub Image-Net 데이터셋을 기반으로 한 응용 시나리오를 통해 Guided-DetNet의 유망한 성능이 입증되었습니다. 이 모델은 삼중 분류 작업에서 비교 모델보다 최소 3% 이상, 이중 탐지 작업에서 최소 2% 이상의 성능 차이를 보이며 뛰어난 성능을 발휘했습니다.



### Harnessing Large Vision and Language Models in Agriculture: A Review (https://arxiv.org/abs/2407.19679)
- **What's New**: 대형 모델(Large Models)이 농업 분야에서 중요한 역할을 할 수 있다는 새로운 연구 결과가 발표되었습니다. 이 연구는 농업용 대형 언어 모델(LLM: Large Language Model), 대형 비전 모델(LVM: Large Vision Model), 대형 비전-언어 모델(LVLM: Large Vision-Language Models)의 잠재적 응용을 탐구합니다.

- **Technical Details**: 이 논문은 농업 이미지 처리, 농업 질문 응답 시스템, 농업 기계 자동화 등 다양한 농업 생산 과업을 해결하기 위한 멀티모달 대형 언어 모델(MLLM: Multimodal Large Language Models)의 가능성을 조사합니다. 이를 통해 해충 및 질병 탐지, 토양 및 씨앗 품질 평가 등에서 대형 모델의 강력한 성능이 부각되었습니다.

- **Performance Highlights**: 대형 모델은 농업 분야에서 매우 중요한 역할을 할 수 있으며, 농업 생산 효율성과 수확량을 크게 향상시킬 잠재력을 가집니다. 이를 통해 농부들은 이미지, 텍스트 등의 다양한 정보를 기반으로 현명한 결정을 내릴 수 있습니다.



### Semi-Supervised Teacher-Reference-Student Architecture for Action Quality Assessmen (https://arxiv.org/abs/2407.19675)
Comments:
          To be published in ECCV2024

- **What's New**: 기존의 행동 품질 평가 (AQA, Action Quality Assessment) 방법은 완전한 지도 학습을 위해 많은 라벨 주석이 필요했으나, 이를 수작업으로 생성하는 것은 비용이 많이 들고 어려운 과정이었습니다. 이 논문에서는 차별화된 교사-참조-학생 (teacher-reference-student) 아키텍처를 제안하여 소량의 라벨 데이터와 다량의 비라벨 데이터를 활용해 AQA 작업의 평가를 개선하는 반지도 학습 (semi-supervised learning) 방법을 소개합니다. 구체적으로, 교사 네트워크는 비라벨 데이터의 고차원 특징을 포착하여 pseudo-label(유사 라벨)을 예측하고, 참조 네트워크는 추가적인 행동 정보를 제공하여 학생 네트워크의 학습을 돕습니다.

- **Technical Details**: 제안된 방법에서는 교사 네트워크와 참조 네트워크가 학생 네트워크를 감독하기 위해 비라벨 데이터에 pseudo-label을 생성합니다. 교사 네트워크는 높은 수준의 특징을 포착하여 비라벨 데이터의 pseudo-label을 예측하고, 참조 네트워크는 학생 네트워크에 적절한 감독을 제공하기 위해 추가적인 행동 정보를 참조합니다. 또한, pseudo-label의 신뢰성을 향상시키기 위해 교사 네트워크 및 참조 네트워크의 가장 정확한 출력을 저장하는 'confidence memory(신뢰 메모리)'를 도입했습니다.

- **Performance Highlights**: 제안된 방법의 유효성을 검증하기 위해 세 가지 AQA 벤치마크 데이터셋에서 광범위한 실험을 수행했습니다. 실험 결과, 제안된 방법이 기존의 반지도 AQA 방법을 능가하며, 상당한 개선을 달성했다는 것이 확인되었습니다.



### Advancing Prompt Learning through an External Layer (https://arxiv.org/abs/2407.19674)
- **What's New**: 이번 연구에서는 프롬프트 학습(Prompt Learning)을 통해 사전 학습된 비주얼-언어 모델(VLMs)을 다양한 다운스트림 작업에 적응시키는 방법을 제안했습니다. 이 방법은 텍스트 임베딩을 동결시키는 대신 텍스트 브랜치와 학습 가능한 시각적 임베딩(Visual Embeddings)을 사용하는 외부 계층(External Layer, EnLa)을 도입해 모델을 적응시키는 것입니다. 이 방식은 학습 능력을 균형 있게 유지하면서 성능을 강화하는 데 목적이 있습니다.

- **Technical Details**: 제안된 방법의 핵심 요소로는 i) 최적 운송(Optimal Transport)을 불일치 측정(metric)으로 사용하여 비전(Visual)과 텍스트 모달리티를 정렬하는 방식과 ii) 이 두 모달리티 간의 상호작용을 강화하기 위한 새로운 강화 기능이 포함됩니다. 이는 사전 학습된 CLIP의 유효한 임베딩 위에 학습 가능한 외부 계층을 구축하는 방식으로 설계되었습니다.

- **Performance Highlights**: 광범위한 실험을 통해 우리의 방법이 기존의 프롬프트 학습 방법과 비교했을 때 11개의 데이터셋에 걸친 4가지 대표적인 작업에서 우수한 성능을 보인다는 것을 확인했습니다.



### Take A Step Back: Rethinking the Two Stages in Visual Reasoning (https://arxiv.org/abs/2407.19666)
Comments:
          ECCV 2024, Project page: this https URL

- **What's New**: 새로운 연구에서는 시각적 추론(Visual reasoning)에 대해 재평가하며, 이를 통해 현재의 방법들이 다양한 분야에서 일반화하기 어렵고 데이터 편향에 취약하다는 점을 지적합니다. 두 단계 접근법(two-stage perspective)을 통해 시각적 추론을 개선하는 방법을 제안합니다: (1) 심볼화(Symbolization)와 (2) 심볼이나 그 표현을 기반으로 한 논리적 추론(Logical reasoning). 이 연구는 심볼화보다는 논리적 추론이 더 일반화에 유리하다는 것을 발견했습니다.

- **Technical Details**: 연구팀은 심볼화와 논리적 추론을 분리하여 접근하며, 심볼화는 데이터 도메인마다 분리된 인코더(separated encoders)를 사용하고, 논리적 추론에는 공유된(reasoner)를 이용하는 것을 제안합니다. 이렇게 함으로써 시각적 추론 체계의 설계 원칙을 수립하고, 2D 및 3D 모달리티를 포함한 다양한 시각적 추론 작업에서 뛰어난 일반화 능력을 보여줍니다.

- **Performance Highlights**: 제안된 두 단계(two-stage) 프레임워크는 퍼즐, 물리적 예측(physical prediction), 시각적 질문 응답(Visual Question Answering, VQA) 등 다양한 시각적 추론 작업에서 압도적인 일반화 능력을 입증했습니다. 이는 기존 방법들이 가진 데이터 편향 문제를 해결하며, 다양한 데이터 도메인에서의 성능을 크게 향상시켰습니다.



### Towards a Knowledge guided Multimodal Foundation Model for Spatio-Temporal Remote Sensing Applications (https://arxiv.org/abs/2407.19660)
Comments:
          9 pages

- **What's New**: 최근 지구 관측 위성 이미지의 방대한 양으로 인해 지구 과학에 대한 기본 모델(foundation models)에 대한 관심이 증가하고 있습니다. 기존의 원격 센싱(foundation models)은 다양한 스펙트럼 이미지를 이용하여 마스킹 재구성 작업(masked reconstruction task)에 사전 훈련(pretrained)된 대규모 모델을 생성합니다. 이러한 모델의 임베딩(embeddings)은 다양한 원격 센싱 응용 프로그램에 사용될 수 있습니다. 본 논문에서는 전통적인 단일 모달리티(single modality) 마스크드 오토인코더(masked autoencoder) 기반 모델을 넘어서는 원격 센싱 지구 과학 응용 프로그램을 위한 기본 모델링 프레임워크를 제안합니다. 본 프레임워크는 물리적 드라이버가 환경 시스템에 미치는 영향을 캡쳐한 스펙트럼 이미지와 그 관계가 시스템의 특성에 의해 규율된다는 지식 가이드 원칙을 활용합니다.

- **Technical Details**: 이 프레임워크는 멀티모달 데이터(스펙트럼 이미지 및 기상 데이터)를 입력으로 사용하고, 가변 단계 예측 작업(variable step forecasting task)을 사전 훈련 목표로 활용합니다. 특히, 우리의 방법인 다중 모달 가변 단계 예측(MultiModal Variable Step Forecasting, MM-VSF)은 멀티모달 데이터를 활용하여 원격 센싱 지구 과학 응용 프로그램을 위한 예측 작업을 수행합니다.

- **Performance Highlights**: 우리의 평가에서, 기상을 활용한 위성 이미지 예측이 기본 모델의 사전 훈련 작업으로 효과적일 수 있음을 보여줍니다. 또한, 단일 모달리티 입력과 마스킹 재구성 기반 사전 훈련 방식으로 훈련된 모델과 비교했을 때 MM-VSF의 임베딩이 픽셀 단위 작물 매핑(pixle wise crop mapping)의 다운스트림 작업에서 더욱 높은 효과를 나타냅니다.



### SALVE: A 3D Reconstruction Benchmark of Wounds from Consumer-grade Videos (https://arxiv.org/abs/2407.19652)
- **What's New**: 이 논문은 소비자용 비디오에서 임상적 상처 평가를 위한 자동 시스템의 적용을 검토하며, 기존의 3D 복원 (3D reconstruction) 방법에 대한 충분한 평가가 이루어지지 않았다는 점을 지적합니다. 이에 대한 해결책으로, SALVE 데이터셋을 도입하여, 다양한 카메라로 촬영된 현실적인 상처 모형의 비디오 기록을 포함한 3D 상처 복원에 대한 포괄적인 연구를 제시합니다.

- **Technical Details**: SALVE 데이터셋을 사용하여 전통적인 사진측량 (photogrammetry) 파이프라인부터 고급 신경 렌더링 (neural rendering) 접근법에 이르기까지 최신 3D 복원 방법의 정확도와 정밀도를 평가하였습니다. 실험 결과, 사진측량 접근법은 임상적 상처 측정을 위한 매끄러운 표면을 제공하지 못하며, 신경 렌더링 접근법은 이러한 문제를 해결하는데 유망한 가능성을 보여주었습니다.

- **Performance Highlights**: 실험 결과, 기존의 사진측량 방법은 임상적 상처 측정을 위한 매끄러운 표면을 제공하는데 실패했으나, 신경 렌더링 접근법은 상처 관리 실무에서 기술의 사용을 진전시키는데 있어 유망한 가능성을 보였습니다.



### ComNeck: Bridging Compressed Image Latents and Multimodal LLMs via Universal Transform-Neck (https://arxiv.org/abs/2407.19651)
- **What's New**: 이 논문은 Multimodal Large Language Models (MLLMs)를 활용하는 다운스트림 비전 작업에 맞춰 압축된 이미지 잠재 변수를 적응시키는 첫 번째 연구를 소개합니다. MLLMs는 텍스트 이외의 이미지 같은 모달리티에 대형 언어 모델의 성공을 확장하였지만, 그 크기 때문에 자원 제약이 있는 장치에 배포하기 어려웠습니다. 클라우드 기반 MLLMs를 사용할 수 있는 상황에서는, 엔드 장치에서 촬영한 원본 이미지를 클라우드로 전송하는 데 효율적인 이미지 압축 시스템이 필요합니다.

- **Technical Details**: 본 연구는 최첨단 신경망 이미지 압축(neural image compression)에 중점을 두고, 경량의 변환 넥(transform-neck)과 대리 손실(surrogate loss)을 포함하는 새로운 프레임워크를 제안합니다. 이 프레임워크는 여러 응용 시나리오에 적용될 수 있으며, 변환 넥은 다양한 MLLM들이 공통으로 사용하는 시각 인코더(visual encoder)와 호환됩니다. 본 프레임워크는 다운스트림 MLLM이 변환 넥을 훈련하는 과정에 참여하지 않으며, 잠재적으로 신경망 이미지 코덱(neural image codec)도 훈련 과정에서 제외될 수 있다는 특징을 가지고 있습니다. 이러한 접근은 MLLM을 훈련에 포함시키는 기존 방법들과 차별화됩니다.

- **Performance Highlights**: 다양한 신경망 이미지 코덱과 여러 MLLM 기반 비전 작업에서의 광범위한 실험 결과, 제안된 방법이 뛰어난 속도-정확도 성능(rate-accuracy performance)을 저복잡도로 달성함을 보여줍니다. 이는 본 프레임워크의 효과성을 입증합니다.



### Practical Video Object Detection via Feature Selection and Aggregation (https://arxiv.org/abs/2407.19650)
- **What's New**: 본 연구에서는 비디오 객체 탐지(Video Object Detection, VOD)의 핵심 문제를 해결하기 위해 매우 간단하면서도 강력한 특징 선택 및 집계 전략을 제안합니다. 기존의 고비용의 두 단계 탐지기(two-stage detectors) 대신, 단일 단계 탐지기(one-stage detectors)가 가진 잠재력을 활용합니다.

- **Technical Details**: 비디오의 특정 프레임 내 탐지는 다른 프레임의 정보를 활용할 수 있습니다. 이를 위해 제안된 방법은 두 단계 탐지기의 높은 계산 비용 문제를 해결하면서도 성능을 향상시키는 전략을 채택합니다. 구체적으로는, 밀집 예측 지도에서 후보 특징을 압축하고, 목표 프레임과 참조 프레임 간의 관계를 평가하여 집계를 가이드합니다. 이를 통해 단일 단계 탐지기의 대규모 계산 및 메모리 소비를 줄입니다.

- **Performance Highlights**: 종합적인 실험 및 ablation study를 통해 제안된 디자인의 효능을 검증하였으며, 최첨단 VOD 방법들보다 효과적이고 효율적인 성능을 입증하였습니다. 특히, 단일 3090 GPU에서 ImageNet VID 데이터셋에 대해 30FPS 이상의 속도로 92.9% AP50의 새로운 기록 성능을 달성하였습니다. 이는 대규모 또는 실시간 애플리케이션에서 매우 유망한 옵션으로 평가됩니다.



### Text2LiDAR: Text-guided LiDAR Point Cloud Generation via Equirectangular Transformer (https://arxiv.org/abs/2407.19628)
- **What's New**: 복잡한 교통 환경과 다양한 날씨 조건에서 LiDAR 데이터 수집의 어려움과 비용 문제를 해결하기 위해 Text2LiDAR라는 새로운 모델을 제안합니다. 이 모델은 텍스트 제어가 가능한 LiDAR 데이터 생성을 보다 효율적이고 다양하게 수행할 수 있습니다. 이는 이 분야에서 최초로 연구된 내용입니다.

- **Technical Details**: Text2LiDAR 모델은 특별히 설계된 직사각형 변환기(Transformer) 아키텍처를 사용하여 LiDAR 데이터를 효율적으로 캡처합니다. 독특한 equirectangular attention 메커니즘을 통해 LiDAR 특징을 포착하며, global-to-focused attention 메커니즘을 통해 제어 신호를 효율적으로 통합하는 control-signal embedding injector를 설계했습니다. 또한, 생성된 point cloud의 선명도를 보장하기 위해 고주파수 세부사항을 복원하는 frequency modulator를 추가로 설계했습니다.

- **Performance Highlights**: KITTI-360 및 nuScenes 데이터셋에서 다양한 형태의 비제어 및 텍스트제어생성 실험을 통해 우리는 Text2LiDAR 모델이 뛰어난 성능을 보여준다는 것을 입증했습니다. nuLiDARtext 데이터셋을 구축하여 850개의 장면에서 34,149개의 LiDAR point clouds에 대한 다양한 텍스트 설명을 제공합니다. 이를 통해 이 분야의 발전 및 텍스트 제어 생성 성능 최적화를 도모하고자 합니다.



### Look Hear: Gaze Prediction for Speech-directed Human Attention (https://arxiv.org/abs/2407.19605)
Comments:
          Accepted for ECCV 2024

- **What's New**: 본 연구는 컴퓨터 시스템이 인간과 효과적으로 상호작용하기 위해 단어의 생성이 사용자들의 순간 순간의 주의(attention)에 어떻게 영향을 미치는지를 이해해야 한다는 점을 강조합니다. 우리의 연구는 이미지와 관련 표현(referring expression)을 들으면서 사람의 시선이 어느 물체에 고정되는지를 예측하는 것에 초점을 맞추고 있습니다. 이를 위해 새로운 모델인 Attention in Referral Transformer(ART)를 개발했습니다.

- **Technical Details**: ART 모델은 멀티모달 변환기 인코더(multimodal transformer encoder)를 사용하여 시선 행동과 그 기저의 기초 과제를 공동 학습하며, 자회귀 변환기 디코더(autoregressive transformer decoder)를 통해 각 단어에 대해 고정 이력을 기반으로 복수의 고정 지점을 예측합니다. 이 모델의 훈련을 위해, 우리는 RefCOCO-Gaze라는 대규모 데이터셋을 생성했습니다. 이 데이터셋은 220명의 참가자로부터 얻은 19,738개의 시선 경로(scanpaths)를 포함하며, 이는 2,094개의 고유한 이미지-표현 쌍입니다.

- **Performance Highlights**: 양적 및 질적 분석에서, ART 모델은 기존 방법들보다 시선 경로 예측에서 우수한 성능을 보였으며, 대기(waiting), 스캐닝(scanning), 검증(verification)과 같은 여러 인간 주의 패턴을 포착하는 듯했습니다.



### Bridging the Gap: Studio-like Avatar Creation from a Monocular Phone Captur (https://arxiv.org/abs/2407.19593)
Comments:
          ECCV 2024

- **What's New**: 전통적으로 사실적인 아바타(avatars)를 생성하기 위해서는 LightStage 시스템과 같은 복잡하고 비싼 스튜디오 장비가 필요합니다. 하지만 최근 신경 표현(neural representations)의 발전으로 스마트폰 스캔으로부터 사실적이고 애니메이션 가능한 3D 아바타를 생성할 수 있게 되었습니다. 이들은 캡처 시점의 조명이 고정되어 있고 얼굴의 세부 사항이 부족하며 귀 뒤쪽과 같은 일부 영역이 누락되는 문제가 있습니다. 이 논문에서는 짧은 단안 스마트폰 캡처로부터 스튜디오와 같은 조명이 적용된 텍스처 맵(texture maps)을 생성하는 방법을 제안합니다.

- **Technical Details**: 이 방법은 $W^+$ 공간에서의 StyleGAN2를 사용하여 스마트폰 텍스처 맵을 파라미터화함으로써 거의 완벽한 재구성을 가능하게 합니다. 그런 다음, 소수의 스튜디오 캡처 텍스처를 적대적 훈련 신호로 사용하여 $W^+$ 파라미터화된 공간에서 샘플링을 통해 StyleGAN2를 미세 조정(finetune)합니다. 얼굴 세부 사항의 사실감과 정확성을 더욱 향상시키기 위해, 우리는 스마트폰 캡처 텍스처 맵의 이미지 그라디언트에 의해 유도되는 정교한 Diffusion Model를 사용하여 StyleGAN2의 출력을 초고해상도(super-resolve)합니다.

- **Performance Highlights**: 훈련이 완료되면, 우리 방법은 일반적인 단안 스마트폰 비디오로부터 사실적이고 사실감 있는 아바타 생성 텍스처 맵을 매우 잘 생성합니다. 우리는 이 방법의 성능을 입증하기 위해 일반적인 단안 스마트폰 캡처로부터 생성된 사실적이며 균일하게 조명된 완전한 아바타를 시연합니다.



### Forecast-PEFT: Parameter-Efficient Fine-Tuning for Pre-trained Motion Forecasting Models (https://arxiv.org/abs/2407.19564)
Comments:
          This work has been submitted to the IEEE for possible publication

- **What's New**: 최근 모션 예측(motion forecasting) 분야에서는 셀프 수퍼바이즈드 프리-트레이닝(self-supervised pre-training)이 큰 발전을 이루어왔습니다. 그러나 특정 다운스트림 작업을 위한 프리-트레이닝된 모델의 적응(adaptation)은 광범위한 파인 튜닝(fine-tuning)을 통해 비효율적일 때가 많습니다. 새로운 방식인 Forecast-PEFT를 도입하여 모델의 대부분의 파라미터(parameters)를 고정하고, 새로 도입된 프롬프트(prompts)와 어댑터(adapters)에 초점을 맞춰 조정합니다. 이는 사전 학습된 표현을 보존하면서도 재학습이 필요한 파라미터 수를 크게 줄여 효율성을 높입니다.

- **Technical Details**: Forecast-PEFT는 파인 튜닝 전략(fine-tuning strategy)으로, 모델의 주요 파라미터를 고정(freeze)하고 새로운 프로즌(promps)와 어댑터(adapters)에 조정을 집중합니다. 이 방식은 특정 작업에 맞춰 모델을 재훈련할 때 기존의 전면 파인 튜닝 방법이 충분히 이를 활용하지 못하는 문제를 해결합니다. 또한, Forecast-PEFT는 다른 데이터셋에 효율적으로 적응할 수 있는 능력을 갖추고 있어, 광범위한 재훈련 없이도 견고한 성능을 보장합니다.

- **Performance Highlights**: 실험 결과, Forecast-PEFT는 모션 예측 작업에서 기존의 전면 파인 튜닝 방법을 능가하여, 필요한 학습 파라미터의 17%만으로도 높은 정확도를 달성했습니다. 더 나아가, Forecast-FT를 통해 예측 성능이 최대 9.6% 향상되어 기존의 베이스라인 방법을 뛰어넘는 결과를 보였습니다. 코드(code)는 지정된 URL을 통해 제공될 예정입니다.



### Exploring the Adversarial Robustness of CLIP for AI-generated Image Detection (https://arxiv.org/abs/2407.19553)
- **What's New**: 최근의 연구에서는 AI 생성 이미지(결찰된 이미지를 생성하는 모델) 탐지기 탐지에 주목하여, 새로운 분석 결과를 제시합니다. 특히, Contrastive Language-Image Pretraining (CLIP)에 기반한 비주얼 트랜스포머(Visual Transformer) 백본의 탐지기와 전통적인 CNN(Convolutional Neural Network) 기반 탐지기의 성능을 비교합니다. 이 논문에서는 다양한 조건 하에서의 적대적 공격에 대한 탐지기의 견고성(robustness)을 연구하였습니다.

- **Technical Details**: 비교 연구는 주로 CLIP 기반 방법과 CNN 기반 방법 간의 견고성을 분석하는데 초점을 맞췄습니다. 다양한 조건에서 적대적 공격(adversarial attacks)에 대한 각 탐지기의 성능을 평가하였으며, 수치 결과와 주파수 도메인 패턴을 분석하였습니다. CLIP 기반 탐지기도 CNN 기반 탐지기처럼 화이트-박스 공격(white-box attacks)에 취약함을 발견하였으나, 공격의 전이가 쉽게 일어나지 않음을 확인했습니다.

- **Performance Highlights**: CLIP 기반 탐지기는 CNN과 달리 다른 형태의 적대적 노이즈(adversarial noise) 패턴을 보였으며, 이는 주파수 도메인 분석 결과에도 반영되었습니다. 이런 연구 결과는 포렌식 탐지기(foreinsic detector)의 고유 특성에 대한 새로운 통찰력을 제공하며, 더 효과적인 보안 전략을 개발하는 데 도움이 될 것입니다.



### Improving Domain Adaptation Through Class Aware Frequency Transformation (https://arxiv.org/abs/2407.19551)
Comments:
          Accepted at the International Journal of Computer Vision

- **What's New**: 이번 연구에서는 Frequency Transformation(주파수 변환)을 사용하여 소스 도메인과 타겟 도메인(예: synthetic image와 real image 각각) 간의 도메인 격차를 줄이고자 하는 Domain Adaptation(도메인 적응) 작업에 대해 탐구하였습니다. 새로운 접근 방식인 Class Aware Frequency Transformation(CAFT)을 제안하여, 기존 UDA(Unsupervised Domain Adaptation) 알고리즘의 전반적인 성능을 향상시키는 pseudo label 기반의 class consistent(클래스 일관적) 저주파 교환 방법을 사용합니다.

- **Technical Details**: CAFT++는 기존의 딥러닝 기반 방법들에 비해 계산 효율성이 더 높으며, 기존의 UDA 알고리즘에 쉽게 플러그인하여 성능을 향상시킬 수 있습니다. 또한, ADT2P(absolute difference of top-2 class prediction probabilities)를 기반으로 하여 타겟 pseudo label을 깨끗한 세트와 노이즈 세트로 필터링하는 새로운 접근 방식을 도입하였습니다. 깨끗한 pseudo label을 가진 샘플은 비지도 학습 알고리즘의 성능을 향상시키는 데 사용될 수 있습니다.

- **Performance Highlights**: 다양한 public domain adaptation datasets에서 여러 UDA 알고리즘을 바탕으로 평가한 결과, CAFT++는 모든 인기 있는 벤치마크에서 상당한 성능 향상을 이뤘습니다.



### Cycle3D: High-quality and Consistent Image-to-3D Generation via Generation-Reconstruction Cyc (https://arxiv.org/abs/2407.19548)
Comments:
          Project page: this https URL

- **What's New**: 최신 3D 대규모 재구성 모델들은 일반적으로 다단계 프로세스를 사용합니다. 먼저 다중 뷰 (multi-view) 확산 모델을 통해 다중 뷰 이미지를 생성하고, 그 후 피드-포워드 (feed-forward) 모델을 사용해 이미지를 3D 콘텐츠로 재구성합니다. 그러나, 다중 뷰 확산 모델은 종종 낮은 품질의 일관성 없는 이미지를 생성하여 최종 3D 재구성의 품질을 저하시킵니다. 이러한 문제를 해결하기 위해 Cycle3D라는 통합된 3D 생성 프레임워크를 제안합니다. 이 프레임워크는 다단계 확산 프로세스 동안 2D 확산 기반 생성 모듈과 피드-포워드 3D 재구성 모듈을 순환적으로 활용합니다.

- **Technical Details**: 특히, Cycle3D는 2D 확산 모델을 적용하여 고품질의 텍스처(texture)를 생성하며, 재구성 모델은 다중 뷰의 일관성을 보장합니다. 더 나아가 2D 확산 모델을 통해 생성된 콘텐츠를 제어하고 참조 뷰 정보를 보이지 않는 뷰에 주입하여, 3D 생성의 다양성과 텍스처 일관성을 향상시킬 수 있습니다. 이 방식은 디노이징(denoising) 과정에서 3D 생성의 전체적인 품질을 높이는 데 기여합니다.

- **Performance Highlights**: 광범위한 실험 결과, Cycle3D는 최첨단 기법들과 비교했을 때, 일관된 고품질의 3D 콘텐츠를 제작하는데 우수한 능력을 보였습니다.



### Temporal Feature Matters: A Framework for Diffusion Model Quantization (https://arxiv.org/abs/2407.19547)
Comments:
          arXiv admin note: substantial text overlap with arXiv:2311.16503

- **What's New**: 이번 연구에서는 Diffusion 모델의 느린 추론 시간과 높은 메모리 요구 사항을 해결하는 새로운 양자화 프레임워크를 제안합니다. 이 프레임워크는 Temporal Information-aware Reconstruction(TIAR)와 Finite Set Calibration(FSC)을 통해 기존의 PTQ(Post-Training Quantization) 방법이 처리하지 못한 시간을 고려한 양자화를 도입했습니다.

- **Technical Details**: 제안된 양자화 프레임워크는 세 가지 주요 요소로 구성됩니다: 1) Temporal Information Block(TIB)을 기반으로 하는 TIAR와 FSC로 고정밀 시간 특징을 효율적으로 정렬합니다. 2) 관련 모듈에 대해 간접적이고 복잡한 최적화를 대신하여 미리 계산하고 캐시된 시간 특징의 양자화가 오류를 최소화합니다. 3) 시간 특징 오류를 이용해 섬세하게 선택하여 최상의 점검을 보장합니다. 이 프레임워크는 대부분의 시간 정보를 보존하고 고품질의 종단간(End-to-End) 생성 성능을 보장합니다.

- **Performance Highlights**: 다양한 데이터셋과 Diffusion 모델에서 광범위한 테스트 결과, 제안된 방법이 4-bit 양자화에서도 전체 정밀도 모델의 성능에 매우 가깝다는 사실을 확인했습니다. 특히, 양자화된 SD-XL 모델은 CPU에서 2.20배, GPU에서는 5.76배의 하드웨어 가속 효과를 보여주며 효율성을 입증했습니다.



### XLIP: Cross-modal Attention Masked Modelling for Medical Language-Image Pre-Training (https://arxiv.org/abs/2407.19546)
- **What's New**: 의료 분야에서 비전과 언어 사전 훈련(VLP)을 위해 XLIP(의료 언어-이미지 사전 훈련을 위한 마스킹 모델링) 프레임워크를 제안합니다. 이는 고유의 병리학적 특징을 학습하고 이미지와 텍스트 데이터를 결합하여 더 나은 전이 학습을 가능하게 합니다.

- **Technical Details**: 우리는 주의력 마스킹 이미지 모델링(AttMIM)과 엔티티 구동 마스킹 언어 모델링 모듈(EntMLM)을 도입하였습니다. 이 모듈들은 다중 모달 특징 상호작용을 통해 병리학적 시각적 및 텍스트 토큰을 재구성하여 의료 관련 특징을 향상시킵니다. AttMIM 모듈은 텍스트 특징에 매우 반응하는 이미지 특징의 일부를 마스킹하여, 유사한 의료 이미지 데이터의 재구성 효율성을 높입니다. 또한, XLIP는 질병 종류 프롬프트를 도입하여 짝을 이루지 않은(unpaired) 데이터를 활용하고자 합니다.

- **Performance Highlights**: XLIP는 다섯 가지 데이터셋에서 제로샷(zero-shot) 및 파인 튜닝(fine-tuning) 분류 성능에 대해 최신(SOTA)의 성과를 달성했습니다.



### UniVoxel: Fast Inverse Rendering by Unified Voxelization of Scene Representation (https://arxiv.org/abs/2407.19542)
Comments:
          ECCV2024

- **What's New**: 기존의 역 렌더링(inverse rendering) 방법은 기하학(geometry), 재료(materials), 조명(illumination)을 별도로 모델링하여 최적화에 많은 계산이 요구되었습니다. 새로운 연구에서는 기하학, 재료 및 조명을 통합적으로 모델링할 수 있는 통합 보컬화(unified voxelization) 프레임워크 UniVoxel을 설계했습니다. 이 프레임워크는 역 렌더링 속도를 크게 가속화합니다.

- **Technical Details**: UniVoxel은 장면을 잠재 부피 표현(latent volumetric representation)으로 인코딩하여 경량 신경망(lightweight neural networks)을 통해 기하학, 재료 및 조명을 통합적으로 학습할 수 있습니다. 특히, UniVoxel의 중요한 설계 요소는 국부적으로 구형 가우시안(local Spherical Gaussians)을 사용하여 입사 광휘(incident light radiance)를 표현하고, 이를 통해 비싼 다중 반사선 추적(multi-bounce ray tracing) 없이도 직접 조명, 간접 조명 및 광 가시성(light visibility)의 결합 효과를 효율적으로 모델링할 수 있다는 점입니다.

- **Performance Highlights**: 다양한 장면을 다루는 여러 벤치마크에서 광범위한 실험을 통해 UniVoxel은 다른 방법에 비해 최적화 효율을 크게 향상시키며 장면당 훈련 시간을 몇 시간에서 18분으로 감소시켰습니다. 또한, 유리한 재구성 품질을 달성했습니다.



### VersusDebias: Universal Zero-Shot Debiasing for Text-to-Image Models via SLM-Based Prompt Engineering and Generative Adversary (https://arxiv.org/abs/2407.19524)
- **What's New**: VersusDebias는 Text-to-Image(T2I) 모델에서 발생하는 편향을 교정하기 위한 혁신적이고 범용적인 디바이어싱 프레임워크입니다. 이 프레임워크는 생성적 적대 기제(Generative Adversarial Mechanism, GAM)와 소형 언어 모델(Small Language Model, SLM)을 포함하여 모델의 환각(Hallucination) 문제를 해결하고 다양한 프롬프트를 처리할 수 있습니다.

- **Technical Details**: 이 프레임워크는 두 가지 주요 메커니즘으로 구성됩니다. 첫째, 자가 적응형 생성적 적대 기제(GAM)는 각 프롬프트에 맞추어 특수 속성 배열을 생성해 T2I 모델의 환각 영향을 줄입니다. 둘째, 소형 언어 모델(SLM)은 프롬프트 엔지니어링을 사용하여 T2I 모델을 위한 디바이어스된 프롬프트를 생성하고, 제로샷(Zero-Shot) 디바이어싱 능력과 모델별 맞춤 최적화를 제공합니다.

- **Performance Highlights**: 광범위한 실험에서 VersusDebias는 성별, 인종, 연령 등 여러 보호 속성에 대해 다양한 모델에서 편향을 교정하는 능력을 보여주었습니다. 또한 VersusDebias는 제로샷 및 퓨샷(Few-shot) 상황 모두에서 기존 방법보다 우수한 성능을 발휘하여 그 유용성을 입증했습니다.



### Ego-VPA: Egocentric Video Understanding with Parameter-efficient Adaptation (https://arxiv.org/abs/2407.19520)
- **What's New**: 이 연구는 새로운 도메인에 적응할 때 큰 백본(backbone)을 미세 조정해야 하는 비디오 이해 문제를 다룹니다. 본 논문에서는 비디오-언어 사전 학습에 기반한 자아 중심 비디오 기초 모델(Ego-VFMs)을 활용하여 새로운 적응 방법인 Ego-VPA를 제안합니다.

- **Technical Details**: Ego-VPA는 비디오 프레임/텍스트 특징을 로컬 희소 근사 (local sparse approximation)를 통해 기저 프롬프트(basis prompts)를 사용하여 로컬 희소 근사를 수행합니다. 선택된 기저 프롬프트는 비디오/텍스트 프롬프트를 합성하는 데 사용됩니다. 기저 프롬프트는 프레임 및 모달리티 간에 공유되므로, 이는 효율적으로 컨텍스트 융합(context fusion) 및 교차 모달 전이(cross-modal transfer)를 모델링합니다.

- **Performance Highlights**: 실험 결과, Ego-VPA는 경량화된 적응(learnable 파라미터가 0.84%만 필요)에서 매우 우수한 성과를 보였으며, 기존의 베이스라인을 크게 향상시키고 전체 미세 조정의 성능에 도달했습니다.



### Detached and Interactive Multimodal Learning (https://arxiv.org/abs/2407.19514)
Comments:
          Accepted by ACM MM 24

- **What's New**: 최근 멀티모달 학습(MML, Multimodal Learning)은 단일 모달리티의 한계를 보완하여 멀티모달 데이터 내의 포괄적인 상보적 정보를 제공하면서 큰 관심을 받고 있습니다. 기존의 MML 방법들은 주로 통합 학습 프레임워크를 통해 학습 목표를 균일하게 설정하여 모달리티 경쟁 문제를 일으킬 수 있는데, 이는 특정 모달리티에서만 피드백을 많이 받아 다른 모달의 잠재력을 제한할 수 있습니다. 이러한 문제를 해결하기 위해, 본 논문에서는 모달리티 경쟁을 피하면서 모달리티 간 상호 보완적 정보를 학습하기 위한 새로운 독립적 MML 프레임워크인 DI-MML을 소개합니다.

- **Technical Details**: DI-MML의 핵심은 각 모달리티 인코더(Modality Encoder)를 별개의 학습 목표로 개별적으로 학습시키는 것입니다. 또한 공유 분류기(Shared Classifier)를 통해 공통의 특징 공간을 정의하여 모달 간 상호작용을 촉진하고, 차원 분리 단방향 대조(DUC, dimension-decoupled unidirectional contrastive) 손실을 적용하여 모달리티 수준의 지식 전이를 촉진합니다. 샘플 쌍의 신뢰도가 다를 수 있는 점을 고려하여, DI-MML은 인퍼런스 시 인스턴스 수준에서 상보적인 정보를 효과적으로 활용하기 위한 불확실성 인식 로그 확률(Certainty-aware Logit Weighting) 전략도 개발하였습니다.

- **Performance Highlights**: 오디오-비주얼(audio-visual), 흐름-이미지(flow-image), 전방-후방(front-rear view) 데이터셋을 활용한 광범위한 실험 결과, 제안된 방법이 우수한 성능을 보임을 확인할 수 있었습니다. 또한 논문의 코드는 공개되어 있습니다.



### Large-scale cervical precancerous screening via AI-assisted cytology whole slide image analysis (https://arxiv.org/abs/2407.19512)
- **What's New**: 자궁경부암 조기 선별을 위해 개발된 새로운 AI 접근법인 STRIDE가 소개되었습니다. 이 방식은 세포 수준 레이블이 제한된 상황에서도 환자 수준 레이블과 결합하여 큰 데이터셋에서 확장 가능한 학습을 가능하게 합니다. 또한, 정말 실세계 도메인 변화에 대해 강인한 진단을 위해 색상 적대적 샘플(color adversarial samples)을 사용한 훈련을 통해 현실적 변화를 모방합니다.

- **Technical Details**: STRIDE는 자궁경부 세포학의 대규모 데이터를 기반으로 구축된 강력하고 인터프리터블한 진단을 위한 확장 가능한 기술(Scalable Technology for Robust and Interpretable Diagnosis)입니다. 이 모델은 소량의 세포 수준 레이블과 환자 수준 레이블을 통합하여 엔드 투 엔드(end-to-end) 학습 전략을 사용합니다. 또한 병리학자의 진단 과정을 모방한 텍스트 설명을 생성하여 임상 환경에서의 신뢰성을 제공합니다.

- **Performance Highlights**: 183개 의료 센터에서 자궁경부 세포학 환자로부터 수집된 341,889개의 WSI와 1억 개의 세포를 포함한 데이터셋을 통해 광범위한 실험과 평가가 이루어졌으며, STRIDE는 이전 최첨단 기술들보다 뛰어난 성능을 입증하였습니다.



### WeCromCL: Weakly Supervised Cross-Modality Contrastive Learning for Transcription-only Supervised Text Spotting (https://arxiv.org/abs/2407.19507)
Comments:
          Accepted by ECCV 2024

- **What's New**: 이 연구는 텍스트 스포팅(Text Spotting)에서 텍스트 경계(boundaries) 주석 없이 전사(transcription)만으로 학습이 가능한 방법을 제안합니다. 이는 비싼 경계 주석 비용을 제거할 수 있으며, 이 문제를 약한 지도 학습(weakly supervised) 기반의 교차-모달리티 대조 학습(cross-modality contrastive learning) 문제로 공식화합니다. 제안된 모델 WeCromCL은 장면 이미지에서 텍스트 전사의 위치를 약하게 감독(weakly supervised) 방식으로 감지할 수 있습니다.

- **Technical Details**: WeCromCL은 텍스트 전사와 장면 이미지 간의 문자 단위(character-wise) 대조 학습을 통해 전사의 상관된 영역의 외관 일관성(appearance consistency)을 모델링합니다. 이는 일반적인 교차-모달리티 대조 학습 방법과 달리 전체 이미지와 텍스트 설명 간의 전체적인 의미적 상관관계를 모델링하지 않습니다. WeCromCL은 감지된 앵커 포인트(anchor points)를 의사 위치 레이블(pseudo location labels)로 사용하여 텍스트 스포팅을 학습합니다.

- **Performance Highlights**: 네 가지 도전적인 벤치마크에서 넓은 범위의 실험을 통해 WeCromCL 모델이 다른 방법들보다 우수한 성능을 보여줍니다. 코드도 공개될 예정입니다.



### Skeleton-based Group Activity Recognition via Spatial-Temporal Panoramic Graph (https://arxiv.org/abs/2407.19497)
- **What's New**: 이번 연구에서는 비디오에서 집단 활동 인식을 위한 새로운 방법론을 제안합니다. 기존의 RGB 기반 방식은 배경 변화, 가림(occlusion), 모션 블러, 높은 계산 부담 같은 문제점이 있습니다. 이와 반대로 키포인트 기반 방법은 가벼우면서도 유익한 인간 동작 표현을 제공하지만, 정확한 개별 주석과 상호작용 이해 모듈 (interaction reasoning module)을 필요로 합니다. 이를 해결하기 위해, 여러 사람의 골격과 객체를 통합한 파노라마 그래프(panoramic graph)를 설계하여 그룹 활동을 효과적으로 캡슐화합니다.

- **Technical Details**: 이 파노라마 그래프는 Graph Convolutional Network (GCN)을 통해 사람 내, 사람 간, 사람과 객체 간의 상호작용을 통합한 공간-시간 그래프 컨볼루션 모델링을 가능하게 합니다. 실용적으로, 이 모델은 포즈 추정 (pose estimation) 및 추적 알고리즘을 사용하여 골격 좌표를 추출하고, Multi-person Panoramic GCN (MP-GCN)을 사용하여 그룹 활동을 예측합니다.

- **Performance Highlights**: Volleyball 및 NBA 데이터셋에서의 광범위한 실험 결과, MP-GCN은 정확성과 효율성 면에서 최첨단 성능을 달성하였습니다. 특히, 우리의 방법은 추정된 2D 키포인트만을 입력으로 사용하면서 RGB 기반 접근 방식을 능가합니다. 코드는 해당 링크에서 사용할 수 있습니다.



### Official-NV: A News Video Dataset for Multimodal Fake News Detection (https://arxiv.org/abs/2407.19493)
- **What's New**: 이번 논문에서는 공식 Xinhua 뉴스 비디오로 구성된 새로운 데이터셋인 Official-NV를 소개합니다. 이는 비디오 형태의 가짜 뉴스 탐지 문제를 해결하기 위해 만들어졌습니다.

- **Technical Details**: Official-NV 데이터셋은 Xinhua에서 크롤링한 비디오들과 이를 확장시키기 위해 LLM(Large Language Model) 생성 및 수작업 수정을 통해 구성되었습니다. 이 데이터셋은 비디오 모달의 가짜 뉴스 탐지를 위한 멀티모달 접근 방식을 개선하는 데 중점을 두고 있습니다.

- **Performance Highlights**: Official-NV 데이터셋의 장점을 증명하기 위해 기준 모델(baseline model)을 사용하여 벤치마킹을 수행하였으며, 이를 통해 멀티모달 가짜 뉴스 탐지에 있어서 이 데이터셋의 우수성을 입증했습니다.



### Multi-modal Crowd Counting via Modal Emulation (https://arxiv.org/abs/2407.19491)
Comments:
          This is the preprint version of the paper to appear in BMVC 2024. Please cite the final published version. Code is available at this https URL

- **What's New**: 본 논문에서는 군중수를 추정하는 데 있어 중요한 역할을 하는 멀티모달 인식(Multi-modal crowd counting)을 위해, 모드 에뮬레이션 기반(modal emulation-based)의 2-패스 멀티모달 군중 수 산정 프레임워크를 제안합니다. 이 프레임워크는 효율적인 모드 에뮬레이션, 정렬(alignment) 및 융합(fusion)을 가능하게 합니다.

- **Technical Details**: 프레임워크는 두 가지 주요 구성 요소로 이루어집니다: '멀티모달 추론 패스(multi-modal inference pass)'와 '크로스모달 에뮬레이션 패스(cross-modal emulation pass)'. 멀티모달 추론 패스는 하이브리드 크로스모달 어텐션 모듈(hybrid cross-modal attention module)을 이용해 글로벌 및 로컬 정보를 추출하고 멀티모달 융합을 효율적으로 수행합니다. 크로스모달 에뮬레이션 패스는 어텐션 프롬프팅(attention prompting)을 사용하여 서로 다른 모달리티를 조정하고 멀티모달 정렬을 강화합니다. 또, 모딩 일치 모듈(modality alignment module)은 효율적인 모달 일치 손실(modal consistency loss)을 사용해 두 패스의 출력을 정렬하고 모달리티 간의 의미적 차이를 줄입니다.

- **Performance Highlights**: RGB-열화상(RGB-Thermal) 및 RGB-깊이(RGB-Depth) 수 계산 데이터셋에서 광범위한 실험을 통해, 본 프레임워크가 이전 방법들에 비해 우수한 성능을 보임을 입증하였습니다. 코드(Code)는 제공된 URL에서 확인 가능합니다.



### Visual Riddles: a Commonsense and World Knowledge Challenge for Large Vision and Language Models (https://arxiv.org/abs/2407.19474)
Comments:
this https URL

- **What's New**: 저자들은 Visual Riddles라는 벤치마크를 소개했습니다. 이 벤치마크는 시각 및 언어 모델이 차별화된 시각적 수수께끼를 해석할 수 있는 능력을 테스트하기 위해 설계되었습니다. 총 400개의 시각적 수수께끼가 포함되어 있습니다.

- **Technical Details**: 각 시각적 수수께끼는 고유한 이미지를 가져오며, 다양한 text-to-image 모델을 사용해 만들어졌습니다. 수수께끼에는 질문, 정답, 텍스트 힌트 및 출처 정보가 포함됩니다. 또한, 평가를 자동화할 수 있는 평가 작업도 함께 제공됩니다.

- **Performance Highlights**: 사람의 성능은 82% 정확도로 평가되었지만, 현재 존재하는 모델들은 이에 미치지 못합니다. Gemini-Pro-1.5 모델이 40% 정확도로 가장 높은 성과를 보였으나, 여전히 인간 성능에 비해 차이가 큽니다. 이는 Visual Riddles가 시각 및 언어 모델의 복잡한 시각적 시나리오를 해석하는 능력을 향상시키는 데 중요한 자원임을 시사합니다.



### Combined CNN and ViT features off-the-shelf: Another astounding baseline for recognition (https://arxiv.org/abs/2407.19472)
Comments:
          Under consideration at WIFS 2024

- **What's New**: 이번 연구는 원래 ImageNet 대규모 시각 인식 챌린지(ImageNet Large Scale Visual Recognition Challenge)용으로 개발된 사전 학습 아키텍처들을 periocular 인식에 적용했습니다. 해당 아키텍처들은 원래 설계된 과제를 넘어서 다양한 컴퓨터 비전 작업에서 중요한 성공을 거두었습니다. 이번 연구는 기존의 Convolutional Neural Network(CNN)를 사용하는 연구를 확장하여 최근에 제안된 Vision Transformers(ViT)을 포함시켰습니다.

- **Technical Details**: 연구에 따르면 CNN 및 ViT는 중간계층(middle-layer)의 특성을 이용해 periocular 이미지를 통해 개인을 인식하는 데 적합합니다. 또한, CNN과 ViT는 서로 매우 보완적이며, 이들의 조합은 인식 정확도를 더욱 향상시킬 수 있음을 입증했습니다. 이와 함께, 사전 학습된 모델의 일부만 사용해도 좋은 정확도를 달성할 수 있고, 이러한 모델은 파라미터 수가 적어 더 얇은 모델(thin models)이 되며, 이는 모바일과 같은 자원 제한 환경에 적합합니다.

- **Performance Highlights**: 효율성은 전통적인 수작업 특징(traditional handcrafted features)을 추가함으로써 더욱 개선됩니다. 이는 작은 부분의 사전 학습된 모델만으로도 높은 정확도를 달성할 수 있음을 보여줍니다.



### On the Evaluation Consistency of Attribution-based Explanations (https://arxiv.org/abs/2407.19471)
Comments:
          Accepted as a conference paper by ECCV 2024

- **What's New**: 최근 주목받고 있는 설명 가능한 인공지능(XAI)의 주요 접근법인 어트리뷰션 기반 설명 방법에 대한 일관된 설정 및 체계적인 연구의 부재를 해결하고자 합니다. 이를 위해 이미지 도메인에서 어트리뷰션 방법을 벤치마킹할 수 있는 오픈 플랫폼인 Meta-Rank를 소개합니다. 현재 Meta-Rank는 여덟 가지 주요 어트리뷰션 방법을 여섯 가지 유명 모델 아키텍처와 네 가지 다양한 데이터셋에서 평가합니다.

- **Technical Details**: Meta-Rank는 Most Relevant First(MoRF)와 Least Relevant First(LeRF) 평가 프로토콜을 사용하여 어트리뷰션 방법을 평가합니다. 이를 통해 다양한 설정에서 평가했을 때 서로 다른 성능 순위가 나타날 수 있음을 발견했습니다. 또한, 동일한 훈련 경로를 따라 다양한 체크포인트에서 일관된 성능 순위를 보여줍니다. 이전의 일관된 평가 시도는 보다 이질적인 모델과 데이터셋에서 베이스라인보다 나은 성과를 보이지 않았습니다.

- **Performance Highlights**: 우리의 벤치마크는 어트리뷰션 평가 노력이 새로운 모델과 데이터셋 범위를 포함하도록 확장되어야 하며, 다양한 어트리뷰션 방법의 성공에 대한 기존 가정들을 재평가해야 함을 강조합니다. 본 연구의 코드와 데이터는 공개되어 있습니다.



### MVPbev: Multi-view Perspective Image Generation from BEV with Test-time Controllability and Generalizability (https://arxiv.org/abs/2407.19468)
Comments:
          Accepted by ACM MM24

- **What's New**: 이 연구는 Bird-Eye-View(BEV) 의미론으로부터 텍스트 프롬프트를 통해 다중 시각적 RGB 생성을 다룹니다. MVPbev라는 새로운 접근법은 두 단계를 통해 서로 다른 관점의 이미지를 일관되게 생성하며, 기존 방법들이 갖는 레이아웃 일관성 문제와 세부 텍스트 프롬프트 처리, 새로운 시점 일반화의 한계를 극복합니다.

- **Technical Details**: MVPbev는 먼저 주어진 BEV 의미론을 카메라 매개변수를 사용해 퍼스펙티브 뷰(perspective view)로 투영시키고, 그 다음에 다중 시각적 주의 모듈(multi-view attention module)을 도입해 겹치는 뷰 간의 지역 일관성을 명시적으로 강화합니다. 마지막으로, MVPbev는 테스트 시간에 프리트레인된 텍스트-이미지 확산 모델(text-to-image diffusion model)을 통해 인스턴스 레벨의 제어를 허용합니다.

- **Performance Highlights**: NuScenes에서의 광범위한 실험을 통해, 우리의 방법이 수천 개의 학습 샘플을 사용하여 텍스트 설명으로부터 고해상도의 사실적인 이미지를 생성할 수 있으며, 다양한 평가 지표에서 기존 최신 방법들을 능가함을 입증했습니다. 또한, 우리의 방법이 새로운 평가 지표와 포괄적인 인간 분석을 통해 일반화 가능성과 제어 가능성 면에서 뛰어남을 보여줍니다.



### White Matter Geometry-Guided Score-Based Diffusion Model for Tissue Microstructure Imputation in Tractography Imaging (https://arxiv.org/abs/2407.19460)
Comments:
          12 pages, 3 figures, 2 tables

- **What's New**: 이번 연구에서는 조직 미세구조(tissue microstructure)를 복원하는 새로운 딥러닝 모델인 WMG-Diff (White Matter Geometry-guided Diffusion) 모델을 제안합니다. 이 모델은 백질 신경 섬유(tracotography)의 해상도를 개선하여 질병 예측, 해부학적 분절 분석, 수술적 뇌 매핑 및 비영상 표현형 분류 등에서 활용될 수 있습니다.

- **Technical Details**: WMG-Diff 모델은 크게 세 가지 중요한 기술적 요소를 포함하고 있습니다. 첫 번째는 diffusion magnetic resonance imaging (dMRI) tractography 섬유 클러스터에 대해 조직 미세구조를 복원하기 위한 딥 스코어 기반 유도 확산 모델입니다. 두 번째는 각 개인의 백질 아틀라스의 기하학적 관계를 반영한 잡음 제거(denoising) 함수입니다. 세 번째로 이 모델은 9342명의 대규모 데이터셋을 사용하여 훈련되고 평가되었습니다.

- **Performance Highlights**: 조직 미세구조 복원 및 비영상 표현형 예측과 관련된 다양한 실험 결과, WMG-Diff 모델은 기존 최신 방법들(state-of-the-art methods)보다 뛰어난 성능을 보였습니다. 이로 인해 WMG-Diff 모델은 다양한 뇌 데이터 분석 작업에서 중요한 도구로 활용될 수 있을 것입니다.



### FIND: Fine-tuning Initial Noise Distribution with Policy Optimization for Diffusion Models (https://arxiv.org/abs/2407.19453)
- **What's New**: 최근 몇 년 동안, 대규모 사전 훈련된 확산 모델(diffusion models)이 이미지 및 비디오 생성 작업에서 뛰어난 능력을 보여주었습니다. 그러나 기존 모델들은 훈련 데이터셋에 흔히 등장하는 시각적인 객체들을 생성하는 경향이 있어, 사용자 입력 프롬프트(prompt)와 일치하지 않는 결과를 만들어냅니다. 이 논문에서는 Fine-tuning Initial Noise Distribution (FIND) 프레임워크를 소개하며, 정책 최적화(policy optimization)을 통해 초기 분포를 직접 최적화하여 생성된 콘텐츠가 사용자 입력 프롬프트와 일치하도록 했습니다.

- **Technical Details**: 이 연구는 먼저 확산 제거 절차(diffusion denoising procedure)를 단일 단계 마코프 결정 과정(one-step Markov decision process)으로 재구성하고, 정책 최적화를 사용하여 초기 분포를 직접 최적화합니다. 또한, 최적화 중 훈련 안정성을 보장하기 위해 동적 보상 보정 모듈(dynamic reward calibration module)을 제안합니다. 마지막으로, 네트워크 훈련을 위한 역사적 데이터를 활용하고 과도한 최적화를 억제하기 위해 비율 클리핑 알고리즘(ratio clipping algorithm)을 도입했습니다.

- **Performance Highlights**: 광범위한 실험 결과, 본 방법이 텍스트-이미지(text-to-image)와 텍스트-비디오(text-to-video) 작업 모두에서 프롬프트와 생성된 콘텐츠 간의 일관성을 달성하는 데 있어서 최첨단(SOTA) 방법을 능가함을 보여줍니다. 또한, 본 방법은 SOTA 접근법보다 10배 더 빠르게 결과를 얻습니다.



### Perm: A Parametric Representation for Multi-Style 3D Hair Modeling (https://arxiv.org/abs/2407.19451)
Comments:
          Project page: this https URL

- **What's New**: 새로운 연구로 자체 학습된 매개변수화된 인간 3D 머리카락 모델인 Perm을 소개합니다. Perm은 기존 작업과 달리 PCA 기반 주파수 도메인에서 글로벌 머리 모양과 로컬 스트랜드 세부 사항을 분리하여 보다 정밀한 편집과 출력 제어를 가능하게 합니다.

- **Technical Details**: Perm은 주파수 도메인에서의 주성분 분석(PCA) 기반 스트랜드 표현을 사용하여 머리 구조 텍스처를 저주파부터 고주파 구조로 분해합니다. 이 분해된 텍스처는 다양한 생성 모델(generative models)로 매개변수화되어 기존 머리 모델링 과정의 여러 단계를 모방합니다. Perm은 가이드 텍스처를 위한 StyleGAN2, 잔여 텍스처를 위한 변이 자동인코더(VAE), 그리고 가이드 텍스처 업샘플링을 위한 U-Net을 훈련합니다.

- **Performance Highlights**: Perm은 3D 머리카락 매개변수화, 헤어스타일 인터폴레이션, 단일 뷰 머리 재구성 등의 다양한 응용 분야에서 뛰어난 성능을 입증합니다. 특히, 특정 작업을 위해 훈련되지 않았음에도 불구하고 Perm은 이 작업에서 최첨단 대안들에 비해 동등하거나 우수한 성능을 발휘합니다. 또한, hair-conditioned 이미지 생성을 위해 Perm을 사용하는 새로운 응용 프로그램이 도입되었습니다.



### X-Fake: Juggling Utility Evaluation and Explanation of Simulated SAR Images (https://arxiv.org/abs/2407.19436)
- **What's New**: SAR 이미지 시뮬레이션의 품질 평가를 위해 새로운 신뢰성 있는 평가 프레임워크인 X-Fake를 제안하였습니다. 이 프레임워크는 시뮬레이션된 SAR 이미지의 실효성을 평가하는 데 중점을 두며, 확률적 평가자와 인과 설명자를 통합하여 신뢰성 있는 평가를 달성합니다.

- **Technical Details**: X-Fake는 Bayesian 딥 모델을 사용하여 실제 데이터를 조건으로 하여 후향 분포를 학습하는 확률적 평가자를 구축합니다. 시뮬레이션된 데이터의 예측된 불확실성은 분포 불일치를 반영할 수 있습니다. 인과 설명자는 introspective variational auto-encoder (IntroVAE)를 사용하여 고해상도의 대조 설명을 생성합니다. 최종적으로 IntroVAE의 잠재 코드는 평가 지표와 사전 정보를 통해 최적화되어 시뮬레이션된 데이터의 부자연스러운 세부 사항을 명확히 밝힙니다.

- **Performance Highlights**: 4개의 전자기 모델 및 생성 AI 접근 방식에서 얻은 시뮬레이션된 SAR 이미지 데이터셋에서 검증된 결과, X-Fake 프레임워크가 다른 이미지 품질 평가(IQA) 방법들보다 유틸리티 측면에서 우수한 성능을 나타냈습니다. 또한 생성된 대조 설명이 신뢰성이 높으며, 애플리케이션에서 데이터 유틸리티를 더 향상시킬 수 있음을 보여주었습니다.



### ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding (https://arxiv.org/abs/2407.19435)
Comments:
          This work is accepted by IROS 2024 (Oral)

- **What's New**: 이 논문에서는 수술 장면 이해에 중요한 수술 도구 세그멘테이션(sepmentation)을 개선하기 위해 ASI-Seg라는 프레임워크를 제안합니다. 새로운 ASI-Seg는 외과의사의 음성 명령(audio commands)을 해석하여 목표로 하는 수술 도구를 정확히 세그멘트화 합니다. 이로 인해 수술 중 불필요한 도구로 인한 혼란을 줄이고, 외과의사가 특정 단계를 수행할 때 더 효율적으로 집중할 수 있도록 도와줍니다. 수동으로 프롬프트(prompts)를 지정하지 않아도 되어 실제 수술 환경에서 더 실용적으로 사용될 수 있습니다.

- **Technical Details**: ASI-Seg 프레임워크는 음성 명령(audio commands)을 파싱하여 세그멘테이션 의도를 해석하는 의도 지향적 멀티모달 융합(intention-oriented multimodal fusion)을 제안합니다. 또한 대조 학습 프롬프트 인코더(contrastive learning prompt encoder)를 이용해 필요한 instrument를 효과적으로 구별하는 방법을 고안했습니다. 이는 Segment Anything Model (SAM)의 능력을 더욱 확장시켜 수동 주석에 의존하지 않고도 정확한 세그멘테이션을 가능하게 합니다.

- **Performance Highlights**: 광범위한 실험 결과, ASI-Seg 프레임워크는 기존의 최신 기술 및 의료 SAMs에 비해 의미론적 세그멘테이션과 의도 지향 세그멘테이션 성능에서 현저한 이점을 보여주었습니다. 이는 외과의사들의 작업 흐름을 개선하고 인지적 부담을 줄여주는 데 큰 기여를 합니다.



### FINER++: Building a Family of Variable-periodic Functions for Activating Implicit Neural Representation (https://arxiv.org/abs/2407.19434)
Comments:
          Extension of previous CVPR paper "FINER: Flexible spectral-bias tuning in implicit neural representation by variable-periodic activation functions". arXiv admin note: substantial text overlap with arXiv:2312.02434

- **What's New**: 새롭게 제안된 FINER++ 프레임워크는 기존의 주기적(Periodic)/비주기적(Non-Periodic) 활성화 함수(Activation Functions)를 가변 주기적(Variable-Periodic) 함수로 확장하여, 신경망의 바이어스(bias)를 다양한 범위로 초기화함으로써 주파수 지정된 스펙트럼 편향(Spectral Bias)과 용량-수렴 간극(Capacity-Convergence Gap) 문제를 해결합니다.

- **Technical Details**: FINER++는 주기적/비주기적 활성화 함수를 가변 주기적 함수로 확장함으로써, 함수의 정의 영역 활용도를 증가시킵니다. 다양한 주파수를 가진 하위 함수를 활성화할 수 있도록 신경망의 바이어스를 다른 범위로 초기화하여 주파수 집합을 유연하게 조정할 수 있습니다.

- **Performance Highlights**: 이 프레임워크는 Sine(사인), Gauss(가우스), Wavelet(웨이블릿) 활성화 함수 골격에서 2D 이미지 맞춤화, 3D 서명 거리 필드 표현, 5D 신경 방사장 최적화, 스트리머블 INR 전송 등 다양한 작업을 수행함으로써 기존의 INR 기술을 개선하는데 유용함을 입증하였습니다.



### Progressive Domain Adaptation for Thermal Infrared Object Tracking (https://arxiv.org/abs/2407.19430)
Comments:
          10 pages, 8 figures

- **What's New**: 대부분의 기존 열 화상(TIR, Thermal InfraRed) 추적기는 대규모 레이블이 있는 TIR 훈련 데이터셋의 부족으로 인해 주로 RGB 데이터셋에서 직접 훈련됩니다. 하지만 이러한 훈련 방식은 도메인 이동 문제(domain shift issue)로 인해 TIR 데이터에서 상당한 성능 저하를 겪습니다. 이를 해결하기 위해, 본 연구에서는 RGB 추적으로부터 배운 유용한 지식을 TIR 추적기로 전이하는 'Progressive Domain Adaptation framework for TIR Tracking (PDAT)'를 제안합니다. 이 프레임워크는 대규모 레이블이 있는 RGB 데이터셋을 최대한 활용하면서, 대규모 TIR 데이터에 대해 시간 소모적이고 노동집약적인 레이블링을 요구하지 않습니다.

- **Technical Details**: PDAT는 두 개의 주요 도메인 적응 모듈을 포함합니다. 첫째, 적대적 기반(adversarial-based) 글로벌 도메인 적응 모듈을 제안하여 특징(feature) 수준에서 도메인 간 갭을 거칠게 줄입니다. 둘째, 클러스터링 기반(subdomain) 서브도메인 적응 방법을 설계하여 RGB와 TIR 데이터셋의 특징 분포를 정교하게 정렬합니다. 이 두 도메인 적응 모듈은 점진적인(training) 훈련을 통해 두 도메인 간의 차이를 점차적으로 제거하여 도메인 불변 미세 특징을 학습합니다. 또한, 제안된 도메인 적응 프레임워크를 훈련하기 위해 148만 개가 넘는 라벨이 없는 대규모 TIR 데이터셋을 수집했습니다.

- **Performance Highlights**: 5개의 TIR 추적 벤치마크에서 실험 결과, 제안된 방법이 약 6%의 성공률 향상을 보여주며 그 효과를 입증했습니다.



### NVC-1B: A Large Neural Video Coding Mod (https://arxiv.org/abs/2407.19402)
- **What's New**: 대규모 모델(large models)은 자연어 처리와 컴퓨터 비전 분야에서 주목할 만한 성과를 이루었으나, 신경망 비디오 코딩(neural video coding)에 관한 대규모 모델은 아직 탐구되지 않았습니다. 이번 논문에서는 대규모 신경망 비디오 코딩 모델을 구축하는 방법을 탐구해봤습니다. 이를 통해, 10억 개 이상의 파라미터를 가진 최초의 신경망 비디오 코딩 모델인 NVC-1B를 설계했습니다.

- **Technical Details**: 기존의 소형 베이스라인 모델을 바탕으로, 모션 인코더-디코더(motion encoder-decoder), 모션 엔트로피 모델(motion entropy model), 컨텍스트 인코더-디코더(contextual encoder-decoder), 컨텍스트 엔트로피 모델(contextual entropy model) 및 시간적 컨텍스트 마이닝 모듈(temporal context mining module) 등 각 코딩 부품의 모델 크기를 점차 확대했습니다. 또한, CNN, 혼합 CNN-Transformer, Transformer 아키텍처 등 다양한 아키텍처를 사용하여 신경망 비디오 코딩 모델을 구현하고, 모델 아키텍처가 비디오 압축 성능에 미치는 영향을 분석했습니다.

- **Performance Highlights**: 실험 결과, 제안된 대규모 모델은 소형 베이스라인 모델에 비해 비디오 압축 성능이 크게 향상되었으며, 최첨단 압축 효율을 나타냈습니다. 대규모 모델이 비디오 코딩 기술을 새로운 차원으로 끌어올릴 수 있을 것으로 기대됩니다.



### Domain Adaptive Lung Nodule Detection in X-ray Imag (https://arxiv.org/abs/2407.19397)
Comments:
          This paper will submit to IEEE SMC 2024

- **What's New**: 의료 영상 데이터는 서로 다른 의료 기관에서 수집된 경우 데이터 분포가 상이해, 학습 및 적용 단계 간 도메인 변화(domain shift)로 인해 폐 결절 감지에 많은 어려움을 초래합니다. 이를 해결하기 위해 새로운 도메인 적응 방법을 제안하며, 이는 Mean Teacher Self-Training(교사-학생 자가 학습)과 Contrastive Learning(대조 학습)을 활용합니다. 특히, 새로운 계층적 대조 학습 전략을 통해 결절(nodule)과 배경 간의 구분을 강화하도록 했습니다. 또한, 새로운 주석이 달린 X-ray 이미지 데이터셋을 소개하여 폐 결절 감지 연구의 향상을 도모합니다.

- **Technical Details**: 먼저, 계층적 대조 학습(strategy)를 통해 결절 표현을 세분화하고 결절과 배경 간의 구별을 강화합니다. 다음으로, Nodlue-Level Domain-Invariant Feature Learning(NDL) 모듈을 도입하여 다양한 도메인 간의 역학습(adversarial learning)을 통해 도메인 불변(domain-invariant) 특성을 캡처합니다. 이 방법들은 특히 훈련과 테스트 도메인 사이의 변화(domain shift)를 극복하는 데 초점을 맞추고 있습니다.

- **Performance Highlights**: 다양한 X-ray 데이터셋을 사용한 광범위한 실험에서, 제안된 접근 방식이 도메인 변화의 영향을 줄이는 데 효과적임을 입증하였습니다. 이는 기존의 비지도 도메인 적응 감지 방법들이 겪는 문제들을 해결하며, 다양한 의료 기관에서 수집된 데이터의 폐 결절 감지율을 향상시킵니다.



### Depth-Wise Convolutions in Vision Transformers for Efficient Training on Small Datasets (https://arxiv.org/abs/2407.19394)
- **What's New**: 본 논문에서는 Vision Transformer(ViT)의 성능을 높이기 위한 새로운 Depth-Wise Convolution 모듈을 제안합니다. 이 모듈은 가볍고 효율적으로 ViT 모델 내에서 Transformer 블록을 우회하여 로컬(local)과 글로벌(global) 정보를 모두 캡처할 수 있도록 합니다.

- **Technical Details**: ViT는 이미지 또는 비디오의 이웃 픽셀 사이의 관계를 무시하고 초기부터 글로벌 컨텍스트를 포착하는 self-attention 메커니즘을 사용합니다. 제안된 Depth-Wise Convolution 모듈은 이 문제를 해결하기 위해 ViT 모델에 적용되며, Transformer 블록 전체를 우회하여 로컬 정보를 캡처합니다. 또한, 다양한 커널의 병렬 Depth-Wise Convolution 모듈을 독립적으로 결합하여 로컬 정보 획득을 강화하는 두 가지 아키텍처 변형을 도입합니다.

- **Performance Highlights**: 제안된 방법은 CIFAR-10, CIFAR-100, Tiny-ImageNet, 그리고 ImageNet과 같은 소규모 데이터셋에 대한 이미지 분류 성능을 크게 향상시킵니다. 또한, COCO 데이터셋 기반의 객체 감지와 인스턴스 세분화(instance segmentation) 작업에서도 성능이 대폭 향상되었습니다.



### Multi-modal Imaging Genomics Transformer: Attentive Integration of Imaging with Genomic Biomarkers for Schizophrenia Classification (https://arxiv.org/abs/2407.19385)
Comments:
          Accepted for presentation at the AI for Imaging Genomic Learning (AIIG) Workshop, MICCAI 2024

- **What's New**: 새로운 연구는 조현병(SZ)의 진단을 향상시키기 위해 다중 모달(Multi-modal) 접근 방식을 소개했습니다. 이 연구는 구조적 및 기능적 MRI 데이터와 유전적 특성을 통합하는 Multi-modal Imaging Genomics Transformer(MIGTrans)를 도입하여 SZ 관련 신경해부학적 및 연결체(connectome) 이상을 포착합니다.

- **Technical Details**: MIGTrans는 구조적 및 기능적 이미징 데이터와 유전체(genomics) 데이터를 주의 깊게 결합하여 SZ 진단의 정밀도를 높이는 시스템입니다. 이는 기존 연구들이 주로 구조적 및 기능적 MRI 데이터에 중점을 둔 것과 달리, 유전적 특성의 통합을 통해 유전적인 SZ 특성을 식별하려는 시도를 포함합니다.

- **Performance Highlights**: MIGTrans는 86.05% (+/- 0.02)의 정확도로 SZ 분류 성능을 개선하였으며, 명확한 해석을 제공하고, SZ와 관련된 중요한 유전체 위치와 뇌 형태적/연결 패턴을 식별하는 데 성공했습니다.



### ClickDiff: Click to Induce Semantic Contact Map for Controllable Grasp Generation with Diffusion Models (https://arxiv.org/abs/2407.19370)
Comments:
          ACM Multimedia 2024

- **What's New**: ClickDiff는 상세한 Semantic Contact Map (SCM)을 활용하여 사용자 지정 혹은 알고리즘으로 예측된 방식에 따라 정밀하게 제어할 수 있는 손잡이 생성(Grasp Generation)을 가능하게 하는 새로운 모델입니다. 이는 기존 방법들이 주로 가시성과 다양성을 중점으로 했던 것에서 벗어나 손과 물체 간의 정밀한 상호작용(예: 접촉)을 고려한 접근법을 시도합니다.

- **Technical Details**: ClickDiff는 Dual Generation Framework를 도입하여, 두 개의 모듈이 협력하여 작업을 수행합니다. 첫 번째 모듈은 Semantic Conditional Module로, 세밀한 접촉 정보를 기반으로 합리적인 접촉 지도를 생성합니다. 두 번째 모듈은 Contact Conditional Module로, 생성된 접촉 지도와 물체의 점 구름(Object Point Clouds)을 활용하여 현실적인 손잡이를 생성합니다. 또한 이 접근법은 기존에 보지 못한 물체에서도 효과적으로 작동합니다.

- **Performance Highlights**: ClickDiff는 GRAB 및 ARCTIC 데이터셋 상에서의 단일 손잡이(Unimanual)와 양손 손잡이(Bimanual) 생성 실험을 통해 그 유효성과 견고성을 입증하였습니다. 특히, 새로운 물체에서도 높은 성능을 보였습니다. 이의 기여는 정밀한 손잡이 생성에서의 새로운 기준을 제시하며, 관련된 연구 분야에서 큰 발전을 이끌어낼 것입니다.



### Integrating Large Language Models into a Tri-Modal Architecture for Automated Depression Classification (https://arxiv.org/abs/2407.19340)
- **What's New**: 본 연구는 Major Depressive Disorder (MDD) 분류를 위한 BiLSTM 기반의 삼중(트라이) 모달 모델(Urod-level fusion architecture)을 제안합니다. 이 모델은 임상 인터뷰 녹음 자료를 바탕으로 이진 분류를 수행합니다. 특히, 이 연구는 대형 언어 모델을 다중 모달 아키텍처에 도입한 첫 번째 작업으로 주목받고 있습니다.

- **Technical Details**: 제안된 아키텍처는 Mel Frequency Cepstral Coefficients (MFCC), Facial Action Units, 그리고 텍스트 데이터를 처리하기 위해 두-샷 러닝(GPT-4) 모델을 통합합니다. 모델은 BiLSTM을 기반으로 한 모델 수준의 융합 구조를 가지고 있습니다. DAIC-WOZ AVEC 2016 Challenge 데이터를 사용하여 교차 검증을 진행했습니다.

- **Performance Highlights**: Leave-One-Subject-Out 테스트에서 제안된 모델은 91.01% 정확도, 85.95% F1-스코어, 80% 정밀도, 그리고 92.86% 재현율을 달성했습니다. 이는 기본 모델 및 기존 최첨단 모델들을 뛰어넘는 성능입니다.



### MSP-MVS: Multi-granularity Segmentation Prior Guided Multi-View Stereo (https://arxiv.org/abs/2407.19323)
- **What's New**: 이번에 소개하는 논문은 textureless areas(텍스처 없는 지역)에서의 MVS(Multi-View Stereo) 문제 해결을 위한 새로운 접근법을 제안합니다. 기존 방법들이 patch(패치) 변형을 통해 수용 범위를 넓히는 동안, 깊이 불연속성(depth discontinuity) 영역에서의 혼동으로 인해 정확도가 떨어지는 문제를 해결합니다. 이를 위해 제안된 Multi-granularity Segmentation Prior Multi-View Stereo(MSP-MVS)은 multi-granularity depth edges를 통합하여 패치 변형을 제한하는 기법을 도입합니다.

- **Technical Details**: MSP-MVS는 크게 세 가지 주요 기법을 통해 기존 방식을 개선합니다. 첫째, multi-granularity segmentation prior(다중 세분화 경계 우선순위)를 도입하여 패치 변형을 적절한 영역 내에서만 발생하게 합니다. 둘째, anchor equidistribution(앵커 균등분포)을 통해 변형된 패치가 더 고르게 분포된 앵커를 가짐으로써 균일한 영역 커버리지를 보장합니다. 셋째, iterative local search optimization(반복 지역적 탐구 최적화)을 통해 더 큰 패치를 희소한 대표 후보자들로 나타내어, 패치의 표현 능력을 크게 향상시킵니다.

- **Performance Highlights**: 제안된 메서드는 ETH3D와 Tanks & Temples 벤치마크에서 최첨단(state-of-the-art) 결과를 달성하며, 그 효과성과 강력한 일반화 능력을 입증했습니다. 이를 통해 다양한 데이터셋에서의 성능 향상이 기대됩니다.



### Ensembling convolutional neural networks for human skin segmentation (https://arxiv.org/abs/2407.19310)
Comments:
          Paper accepted for IBERAMIA 2024

- **What's New**: 디지털 이미지에서 인간 피부 영역을 감지하고 분할하는 것은 많은 연구가 진행된 컴퓨터 비전(CV) 분야 중 하나입니다. 전통적으로는 픽셀 단위의 피부 색상 모델링을 이용했지만, 최근에는 심층 합성곱 신경망(Deep Convolutional Neural Networks)을 이용해 텍스처 및 기하학적(features) 특성을 포함하는 문맥 기반 분석이 주로 사용되고 있습니다. 이 논문에서는 컬러 정보 없이 회색조 이미지에서 피부 영역을 분할하는 가능성을 탐구하였고, 이를 색상 정보와 결합하여 효과를 극대화하는 연구를 수행했습니다.

- **Technical Details**: 연구진은 다양한 특성에 초점을 맞춘 데이터셋을 사용하여 합성곱 네트워크(Convolutional Network)를 훈련시켜, 개별 결과를 또 다른 합성곱 네트워크에 결합시키는 앙상블(Ensemble) 기법을 제안했습니다. 최종 분할 맵을 생성하기 위해 추가로 훈련된 네트워크를 통해 합성된 결과가 기존의 기본 분류기와 투표 기반 앙상블을 능가하는 것이 실험 결과에서 명확하게 나타났습니다.

- **Performance Highlights**: 이 접근 방법은 기본 분류기와 기존의 투표 기반 앙상블보다 우수한 성능을 보이며, 세그먼트 기반의 성능을 향상시키는 데 도움을 줄 것입니다. 이는 인간 피부 감지 문제를 넘어 의미론적 세분화(Semantic Segmentation) 시스템의 성능을 향상시키는 데 기여할 것으로 기대됩니다.



### Comprehensive Attribution: Inherently Explainable Vision Model with Feature Detector (https://arxiv.org/abs/2407.19308)
- **What's New**: 최근 딥 비전 모델(deep vision models)의 인기가 급상승함에 따라 모델 예측에 대한 설명(explanations)에 대한 요구가 강화되고 있습니다. 본 논문에서는 모델의 행동을 더 잘 이해하도록 돕는 새로운 목표를 제안합니다. 특히, 기존 방법들이 직면했던 불완전성(incompleteness) 문제와 상호 고리(interlocking) 문제를 해결하는 데 중점을 둡니다.

- **Technical Details**: 제안된 방법은 선택자(selector)와 예측자(predictor)를 협력적으로 훈련시키는 방식으로, 선택자가 중요한 특징을 식별하면 예측자가 이를 이용해 예측을 수행합니다. 불완전성 문제를 해결하기 위해, 마스킹된 영역에서 판별 특성이 나타나지 않도록 하는 새로운 목표를 도입하였습니다. 이 목표는 모델이 노이즈가 아닌 실제 판별 특성을 학습하도록 도와줍니다. 또한, 사전 훈련된 탐지기(pre-trained detector)를 사용하여 마스킹된 영역에서 판별 특성을 감지하고 선택자가 노이즈를 선택할 경우 감지기를 통해 패널티를 부여하여 문제를 해결하도록 합니다.

- **Performance Highlights**: 광범위한 실험 결과, 제안된 모델은 기존의 블랙박스 모델(black-box model)보다 더 높은 정확도로 예측을 수행하며, 특성 커버리지(feature coverage), 지역화 능력(localization ability), 신뢰성(fidelity) 및 견고성(robustness) 측면에서 우수한 속성을 가진 어트리뷰션 맵(attribution maps)을 생성함을 확인했습니다.



### Symmetrical Joint Learning Support-query Prototypes for Few-shot Segmentation (https://arxiv.org/abs/2407.19306)
- **What's New**: Sym-Net은 Few-Shot Segmentation(FSS)의 중요한 문제인 클래스 내 변이를 해결하기 위해 쿼리(query)와 지원(support) 프로토타입을 대칭적으로 학습하는 새로운 프레임워크를 제안합니다. 이 접근 방식은 기존의 쿼리 기능을 지원 프로토타입과 매칭하여 쿼리 프로토타입을 생성하는 편향된 학습을 넘어, 대칭적 학습을 통해 쿼리와 지원 프로토타입을 균형 있게 학습합니다.

- **Technical Details**: Sym-Net의 주요 모듈 중 하나는 시각-텍스트 정렬 기반의 프로토타입 집계 모듈입니다. 이 모듈은 단순히 쿼리 기반 프로토타입으로 세련된 것이 아니라, 쿼리와 지원 샘플 모두에서 공동으로 학습하여 클래스 내 불일치를 처리하는데 유용합니다. 세부적으로는, 슬라이딩 윈도우(sliding windows)와 셀프-액티베이션 커널(self-activation kernel)을 사용하여 잘못된 배경 매치를 억제하는 파라미터 프리 우선 마스크 생성 모듈이 설계되었습니다. 또한, 프로토타입 학습 중 공간적 풀링으로 인한 정보 손실 문제를 해결하기 위해, 지원 및 쿼리 이미지 간의 다중 스케일 공간 관계를 포착할 수 있는 상향식 하이퍼-상관 모듈(top-down hyper-correlation module)이 통합되었습니다. 이 접근 방식은 또한 공동 최적화된 하드 트리플렛 마이닝 전략(co-optimized hard triplet mining strategy)을 구현하여 최적화를 진행합니다.

- **Performance Highlights**: 실험 결과, 제안된 Sym-Net이 최첨단 모델을 능가하는 성능을 보여줍니다. 이는 FSS에서 제한된 주석 데이터로 세그멘테이션 성능을 향상시키는 데 있어, 지원-쿼리 프로토타입을 대칭적으로 학습하는 접근 방식이 유망하다는 것을 입증합니다.



### GP-VLS: A general-purpose vision language model for surgery (https://arxiv.org/abs/2407.19305)
- **What's New**: 본 논문에서는 수술 장면을 이해하고 자연어를 통해 상호작용할 수 있는 범용 비전-언어 모델(GP-VLS)을 소개합니다. GP-VLS는 의료 및 수술 지식을 시각적 장면 이해와 통합하여 수술 장면을 보다 효과적으로 분석할 수 있도록 설계되었습니다. 이를 위해 논문에서는 새로운 종합 평가 체계인 SurgiQual을 제안합니다.

- **Technical Details**: GP-VLS를 훈련하기 위해 의료 지식, 수술 교과서 및 비전-언어 페어에 걸친 6개의 새로운 데이터셋을 개발하였습니다. 이 데이터셋은 주기 인식(phase recognition) 및 도구 식별(tool identification)과 같은 작업을 포함합니다. GP-VLS는 기존의 오픈 소스 및 클로즈드 소스 모델에 비해 수술 비전-언어 작업에서 8-21%의 향상된 정확도를 보여줍니다.

- **Performance Highlights**: GP-VLS는 SurgiQual 벤치마크에서 기존 모델들보다 8-21% 높은 정확도를 기록하며 우수한 성능을 입증했습니다. 또한 의료 및 수술 지식 테스트에서도 오픈 소스 대안에 비해 강력한 성능을 보여줍니다. 이 모델은 외과의사들이 다양한 작업과 시나리오에서 도움을 받을 수 있는 AI 비서 개발의 기초를 제공합니다.



### Rethinking Attention Module Design for Point Cloud Analysis (https://arxiv.org/abs/2407.19294)
- **What's New**: 최근 주목받는 관점기반(point cloud) 분석을 위한 주목 메커니즘(attention mechanism)의 설계에 대한 재고와 일관된 기본 프레임워크 내에서의 탐구를 진행했습니다. 본 논문에서는 다양한 설정과 작업을 포함한 여러 연구 논문에서 사용되는 주목 모듈(attention module)을 일관된 조건 하에 비교할 수 있도록 했습니다.

- **Technical Details**: 본 연구에서는 전역 기반(global-based)과 국소 기반(local-based) 주목 방법을 모두 연구하고, 국소 기반 주목에서 이웃의 선택 기준과 규모에 초점을 맞췄습니다. 전통적인 추가/연결 기반(addition/concatenation-based) 접근법에서부터 널리 채택된 점곱(dot product) 기반 방법, 최근 제안된 벡터 주목(vector attention) 기법까지 다양한 집계된 지역 특징 및 주목 점수 계산 방법을 평가했습니다. 또한, 다양한 위치 인코딩(position encoding) 방법들도 조사했습니다.

- **Performance Highlights**: 광범위한 실험적 분석 결과, 다양한 점 구름 작업(point cloud tasks)에서 보편적으로 최적의 설계는 없다는 것을 밝힙니다. 대신, 최적 관행을 통해 특정 작업을 위한 맞춤형 주목 모듈을 제안하여 점 구름 분류 및 세분화 기준에서 우수한 성능을 달성했습니다.



### Mamba? Catch The Hype Or Rethink What Really Helps for Image Registration (https://arxiv.org/abs/2407.19274)
Comments:
          WBIR 2024 Workshop on Biomedical Imaging Registration

- **What's New**: 이번 연구 결과는 '고급' 컴퓨팅 요소를 채택하는 것이 등록 정확도를 크게 향상시키지 못한다는 것을 보여줍니다. 기존의 잘 확립된 등록 전용 설계가 기본 성능에 비해 1.5% 정도 미미하지만 공정한 개선을 제공합니다.

- **Technical Details**: 연구는 모든 저수준 및 고수준 등록 구성 요소의 엄격하고 공정한 평가와 기여 분리의 중요성을 강조하며, 단순히 컴퓨터 비전 트렌드를 따르는 '고급' 컴퓨팅 블록의 사용을 지양합니다. 대신 간단하면서도 효과적인 솔루션과 기존 등록 정확도를 넘어서는 새로운 평가 지표를 제안합니다.

- **Performance Highlights**: 기존의 등록 전용 설계를 통해 기본 성능 대비 약 1.5%의 향상이 있었음을 발견했습니다. 이 연구는 다양한 장기(organ)와 모달리티(modality)를 아우르는 추가 연구를 권장합니다.



### Sewer Image Super-Resolution with Depth Priors and Its Lightweight Network (https://arxiv.org/abs/2407.19271)
- **What's New**: 하수도 시스템의 결함 탐지를 위한 주요 방법인 Quick-view(QV)를 개선하는 새로운 Depth-guided, Reference-based Super-Resolution 프레임워크, DSRNet이 소개되었습니다. 이 연구는 QV 이미지의 깊이 관계를 활용하여 이미지 품질을 향상시키는 새로운 접근법을 제시합니다.

- **Technical Details**: DSRNet은 주로 두 가지 핵심 구성요소로 구성되며, 깊이 추출 모듈(depth extraction module)과 깊이 정보 매칭 모듈(depth information matching module, DMM)입니다. 저해상도 이미지의 인접 프레임을 참조 이미지로 사용하여 텍스처 정보를 복원합니다. 또한, 주의 기제를 기반으로 한 초해상도 지식 증류 모델을 도입하여, 복잡한 교사 모델과 간소화된 학생 모델 간의 특징 유사성을 확보합니다. 이를 통해 DSRNet의 경량 버전을 제공합니다.

- **Performance Highlights**: 실험 결과, DSRNet은 PSNR과 SSIM 지표에서 다른 방법들보다 상당한 성능 향상을 보여줍니다. 하수도 결함 의미 분할, 객체 탐지, 분류 등의 작업에서도 Pipe 데이터셋 및 Sewer-ML 데이터셋을 대상으로 실험을 수행하여, 저해상도 하수도 이미지의 성능을 크게 향상시켰음을 입증하였습니다.



### Fine-Grained Scene Graph Generation via Sample-Level Bias Prediction (https://arxiv.org/abs/2407.19259)
Comments:
          24 pages, 10 figures, ECCV2024

- **What's New**: 새로운 샘플 수준 편향 예측(Sample-Level Bias Prediction, 약칭 SBP) 방법이 제안되었습니다. 이 방법은 장면 그래프 생성(Scene Graph Generation, 약칭 SGG)의 세부 정확도를 높이도록 설계되었습니다. 주된 목표는 SGG 예측의 초기 관계를 미세 조정하여 더 정교한 관계를 예측하는 것입니다.

- **Technical Details**: 이 방법에서는 먼저 클래식 SGG 모델을 훈련시키고, 그 모델을 사용해 원래 예측과 실제 라벨 사이의 차이를 계산하여 보정 편향 세트를 구축합니다. 그런 다음, Bias-Oriented Generative Adversarial Network (BGAN)을 설계하여 이러한 보정 편향을 예측하도록 학습시킵니다. 이 모델을 통해 원래의 거친 관계 예측을 더 정밀한 관계로 수정할 수 있습니다.

- **Performance Highlights**: 이 방법은 VG, GQA, VG-1800 데이터셋에서 광범위한 실험 결과를 통해 입증되었습니다. 세 가지 주요 SGG 모델(Motif, VCtree, Transformer)에 대해 Average@K 성능 평가에서 최고 성능을 보였습니다. 특히 VG 데이터셋에서 PredCls, SGCls, SGDet 작업에 대해 각각 평균 5.6%, 3.9%, 3.2%의 향상을 보여줍니다.



### Radio Frequency Signal based Human Silhouette Segmentation: A Sequential Diffusion Approach (https://arxiv.org/abs/2407.19244)
- **What's New**: 이번 연구에서는 복잡한 환경에서 인간의 실루엣 분할 (Human Silhouette Segmentation, HSS) 문제를 해결하기 위해 두 단계의 순차적 확산 모델 (Sequential Diffusion Model, SDM)을 제안했습니다. 기존 연구들이 주로 일회성 접근 방식에 기반하고 있어 RF(domain)에서의 일관된 투영 능력이 부족했고, 인간의 움직임 동력을 위한 시공간 패턴이 충분히 탐구되지 않았습니다. 본 연구에서는 이러한 한계를 극복하고자 고품질의 분할을 점진적으로 합성하는 방법을 제시합니다.

- **Technical Details**: 크로스 뷰 변환 블록 (Cross-view transformation blocks)을 설계하여 확산 모델(diffusion model)이 멀티 스케일(multi-scale) 방식으로 신호 평면에서 방향 투영과 같은 개별 프레임에서의 인간 관련 패턴들을 포괄적으로 특성화할 수 있도록 합니다. 또한 시공간 블록(spatio-temporal blocks)을 통해 프레임 수준 모델을 미세 조정하고 시공간 컨텍스트 및 움직임 동력을 통합하여 분할 맵의 일관성을 높입니다.

- **Performance Highlights**: 공개 벤치마크인 HIBER 데이터셋에 대한 포괄적인 실험 결과, 제안된 방법이 IoU (Intersection over Union) 0.732로 최첨단 성능을 보여주었습니다. 이로써 복잡한 환경에서도 높은 정확도의 인간 실루엣 분할이 가능함이 증명되었습니다. 코드 사용을 원하는 연구자들을 위해 소스 코드도 공개되었습니다.



### Magic3DSketch: Create Colorful 3D Models From Sketch-Based 3D Modeling Guided by Text and Language-Image Pre-Training (https://arxiv.org/abs/2407.19225)
- **What's New**: 증가하는 AR/VR 응용 프로그램 수요와 함께 3D 콘텐츠 요구도 증가하고 있습니다. 그러나 전통적인 3D 모델링 방법은 노동 집약적이고 기술이 필요한 작업으로, 초보 사용자에게는 도전적입니다. 이를 해결하기 위해 제안된 Magic3DSketch는 스케치를 인코딩(encoding)하여 텍스트 설명과 외부 사전 지식을 활용해 3D 메쉬(mesh)를 예측하는 혁신적인 방법을 제시합니다. 특히, 언어-이미지 사전 학습된 인공 신경망(Neural Networks)을 통합하여 단일 시야 스케치의 희소하고 모호한 특성을 보완합니다.

- **Technical Details**: Magic3DSketch는 스케치 입력과 텍스트 설명을 결합하여 3D 메쉬를 생성합니다. 언어-이미지 사전 학습된 모델을 활용하여 스케치의 충분하지 않은 정보들을 보충하며, 이를 통해 보다 사실적이고 정교한 구조의 3D 모델을 생성할 수 있습니다. 또한, 텍스트 기반 설명을 이용해 색상 정보를 추가하는 기능을 처음으로 도입했습니다.

- **Performance Highlights**: Magic3DSketch는 기존의 텍스트-투-3D(text-to-3D) 접근법에 비해 더 높은 사용성과 제어성을 제공하며, 사용자 연구에서 높은 만족도를 보였습니다. 특히, 합성 데이터셋과 실제 데이터셋 모두에서 최첨단(state-of-the-art) 성능을 달성하였고, 텍스트 입력의 도움을 받아 더 세밀하고 현실적인 3D 구조를 생성하는 능력을 입증했습니다.



### Faster Image2Video Generation: A Closer Look at CLIP Image Embedding's Impact on Spatio-Temporal Cross-Attentions (https://arxiv.org/abs/2407.19205)
- **What's New**: 본 논문은 Stable Video Diffusion (SVD) 프레임워크 내에서 CLIP 이미지 임베딩의 역할을 조사하고, 비디오 생성 품질과 계산 효율성에 미치는 영향에 대해 연구합니다. 주요 발견으로는 CLIP 임베딩이 미적 품질에는 중요하지만 비디오 출력의 주제 및 배경 일관성에는 크게 기여하지 않는다는 것을 밝혔습니다. 이를 바탕으로, 새로운 접근법인 VCUT를 소개합니다.

- **Technical Details**: SVD 프레임워크에서는 비디오 생성 과정에서 CLIP 임베딩이 중요한 역할을 하나, 비디오의 주제나 배경 일관성에는 큰 영향을 주지 않는다고 설명합니다. 또한, 계산 비용이 많이 드는 크로스 어텐션(Cross-Attention) 메커니즘을 더 단순한 선형 레이어(Linear Layer)로 대체할 수 있음을 제안합니다. 이 선형 레이어는 첫 번째 디퓨전 추론(Diffusion Inference) 단계에서 한 번만 계산되고, 이후 추론 과정에서 캐시된 출력을 재사용함으로써 효율성을 높입니다.

- **Performance Highlights**: 새롭게 제시된 VCUT 접근법은 SVD 아키텍처 내에서 효율성을 최적화하고, 시간적 크로스 어텐션을 제거하고 공간적 크로스 어텐션을 한 번 계산된 선형 레이어로 대체하여 계산 부하를 크게 줄입니다. 이를 통해 비디오 하나당 최대 322T MACs(다중 누산 연산, Multiple-Accumulate Operations)를 절약하고, 모델 파라미터도 최대 50M까지 줄여서, 기존 대비 약 20%의 지연 시간을 줄이는 성과를 달성했습니다.



### LLaVA-Read: Enhancing Reading Ability of Multimodal Language Models (https://arxiv.org/abs/2407.19185)
Comments:
          NeurIPS 2024 Under Review

- **What's New**: 신규 멀티모달(대규모 다중 양식) 언어 모델인 LLaVA-Read를 소개합니다. 이 모델은 이미지 내에 포함된 텍스트의 이해도를 향상시켜 기존 모델들의 한계를 극복하고 보다 정확한 텍스트 이해를 제공하는 것을 목표로 하고 있습니다.

- **Technical Details**: LLaVA-Read는 듀얼 비주얼 인코더(dual visual encoders)와 비주얼 텍스트 인코더(visual text encoder)를 활용합니다. 이 구조는 이미지 속 텍스트를 효과적으로 인식하고 레이아웃을 이해하는데 도움을 줍니다. 기존의 시각 인코더(visual encoders)는 텍스트 이해에 있어서 한계가 있었음을 분석을 통해 확인하고, 이를 극복하기 위한 새로운 접근 방식을 제안합니다.

- **Performance Highlights**: LLaVA-Read는 텍스트가 많이 포함된 이미지 이해(task)에서 기존의 최신 모델(state-of-the-art)을 뛰어넘는 성능을 보였습니다. 이를 통해 시각적 텍스트 이해가 여전히 개방된 과제이며, 효율적인 비주얼 텍스트 인코더가 향후 멀티모달 시스템의 성공에 중요한 요소임을 시사합니다.



### Enhancing Tree Type Detection in Forest Fire Risk Assessment: Multi-Stage Approach and Color Encoding with Forest Fire Risk Evaluation Framework for UAV Imagery (https://arxiv.org/abs/2407.19184)
- **What's New**: 이번 연구에서는 이전의 통합 산불 위험 평가 프레임워크를 최적화하기 위해 UAV(무인항공기)와 다단계 객체 탐지 알고리즘을 활용한 산불 감지를 연구하였습니다. Faster R-CNN, Grid R-CNN, Sparse R-CNN, Cascade R-CNN, Dynamic R-CNN, Libra R-CNN과 같은 다양한 탐지 기법을 도입하고, 주의력 강화 기술인 CBAM, 전처리를 위한 랜덤 지우기 (random erasing), 그리고 다른 색상 공간 표현을 통한 최적화 방안을 탐구했습니다.

- **Technical Details**: 본 연구에서는 다양한 최신 객체 탐지 알고리즘을 사용하여 산불 위험 평가의 정확도를 조사했습니다. Faster R-CNN, Grid R-CNN, Sparse R-CNN, Cascade R-CNN, Dynamic R-CNN, Libra R-CNN 등 알고리즘을 UAV에 사용했습니다. 또한 CBAM(Convolutional Block Attention Module)을 사용하여 주의력 강화, 랜덤 지우기를 통한 데이터 전처리, 그리고 다양한 색상 공간 표현 방법을 적용하여 최적화를 시도했습니다.

- **Performance Highlights**: 이 연구의 실험 결과는 다단계 객체 탐지 알고리즘과 최적화 기법들이 산불 위험 평가의 정확도 향상에 효과적임을 보여주었습니다. 특히 캐나다 브리티시 컬럼비아 지역에서 수집한 항공 이미지 데이터를 이용한 실험을 통해 이러한 향상을 확인하였습니다. 이 연구는 UAV 기반 산불 감지 및 평과 시스템의 발전에 기여하며, 지속 가능한 산림 관리 및 보존 노력을 지원하는데 중요한 역할을 할 것입니다.



### Data Processing Techniques for Modern Multimodal Models (https://arxiv.org/abs/2407.19180)
- **What's New**: 이번 논문에서는 현대 멀티모달 모델 교육에서 사용되는 일반적인 데이터 처리 기술에 대한 종합 검토를 제공합니다. 특히, diffusion 모델과 멀티모달 대형 언어 모델(Multi-Modal Large Language Models, MLLMs)에 중점을 두고 있습니다.

- **Technical Details**: 연구에서는 데이터 처리 기술을 네 가지 범주로 요약하였습니다: 데이터 품질(data quality), 데이터 양(data quantity), 데이터 분포(data distribution) 및 데이터 안전성(data safety). 이 논문은 각 모델 유형에 따른 최적의 데이터 처리 방법 선택에 대한 연구 결과를 제시합니다.

- **Performance Highlights**: 이 연구는 멀티모달 모델 개발자에게 효과적인 데이터 처리 기술을 제공하기 위한 지침을 제시하는 것을 목표로 합니다.



### Power-LLaVA: Large Language and Vision Assistant for Power Transmission Line Inspection (https://arxiv.org/abs/2407.19178)
- **What's New**: 최근 몇 년 동안 심층 학습 기술(deep learning technology)의 통합 덕분에 전력 송전선(inspecting power transmission line) 점검에서 눈에 띄는 성과를 이룩했습니다. 그러나 현재의 점검 방식은 여전히 일반화와 지능화에서 어려움을 겪고 있어 더 널리 적용되지 못하고 있습니다. 이번 논문에서는 사람과의 대화로 전문적이고 신뢰할 수 있는 전력 송전선 점검 서비스를 제공하기 위해 설계된 최초의 대형 언어 및 비전 어시스턴트인 Power-LLaVA를 소개합니다. 또한 이 점검 작업을 위해 대규모 고품질 데이터셋을 구축하였습니다. 이 데이터셋을 이용한 두 단계 훈련 전략을 통해 Power-LLaVA는 비교적 낮은 훈련 비용으로 뛰어난 성능을 보여줍니다. 코드 역시 공개될 예정입니다.

- **Technical Details**: Power-LLaVA는 전력 송전선 점검을 위해 설계된 최초의 대형 언어 및 비전 어시스턴트입니다. 이를 위해 대규모 고품질 데이터셋을 구축하고, 두 단계 훈련 전략을 사용했습니다. 첫 단계는 사전 훈련(pre-training)으로, 데이터셋의 일반적인 특징을 학습합니다. 두 번째 단계는 미세 조정(fine-tuning)으로, 특정 전력 송전선 점검 작업(task-specific inspection tasks)에 맞게 최적화합니다. 이와 같은 접근 방식을 통해 낮은 훈련 비용으로도 높은 성능을 달성할 수 있었습니다.

- **Performance Highlights**: 광범위한 실험을 통해 Power-LLaVA가 전력 송전선 점검 분야에서 뛰어난 성능을 입증하였습니다. 실험 결과, Power-LLaVA는 기존의 점검 방식에 비해 높은 정확도와 효율성을 보여주었으며, 코드도 곧 공개될 예정입니다.



### Reducing Spurious Correlation for Federated Domain Generalization (https://arxiv.org/abs/2407.19174)
Comments:
          10 pages, 4 figures

- **What's New**: 새로운 프레임워크 FedCD (Cross-Domain Invariant Federated Learning)가 제안되었습니다. 이 프레임워크는 로컬 및 글로벌 수준에서 최적화를 수행하여 다양한 도메인 간의 문제를 해결하고자 합니다. 특히, 새로운 도메인 데이터에 대해 예측 성능을 개선하는 것을 목표로 하고 있습니다.

- **Technical Details**: FedCD는 모델이 스푸리어스(spurious) 상관관계에 의존하지 않도록 Spurious Correlation Intervener (SCI)를 활용하여 자체 지도 (self-supervised) 방식으로 로컬 수준에서 개입자를 생성합니다. 또한, Risk Extrapolation Aggregation (REA) 전략을 사용하여 수학적 최적화를 통해 글로벌 상관관계 기반 예측을 촉진합니다. FedCD는 데이터나 피처를 공유하지 않고, 모델과 관련된 그라디언트만 공유합니다.

- **Performance Highlights**: 다양한 실험 및 에블레이션(ablation) 연구 결과, FedCD는 분류 및 객체 검출 일반화 작업에서 기준 모델 대비 평균적으로 적어도 Acc에서 1.45%, mAP50에서 4.8% 및 1.27% 향상된 성능을 보였습니다.



### Revisit Self-supervised Depth Estimation with Local Structure-from-Motion (https://arxiv.org/abs/2407.19166)
- **What's New**: 이 논문에서는 RGB 비디오에서 장면 깊이를 복원하는 자가 지도 깊이 추정(self-supervised depth estimation)과 Structure-from-Motion (SfM)을 통합하는 새로운 방법을 제안합니다. 기존의 자가 지도 학습 방법은 인접 프레임에서 정의된 손실을 통해 학습하지만, 본 연구에서는 로컬 SfM을 수행하는 대안을 제시합니다.

- **Technical Details**: 제안된 방법에서는 보정된 RGB 또는 RGB-D 이미지를 사용하여 깊이 맵(depthmaps)과 쌍별 대응 맵(pair-wise correspondence maps)을 추정합니다. 이후 새로운 번들-RANSAC-조정 알고리즘(bundle-RANSAC-adjustment algorithm)을 통해 카메라 포즈와 각 깊이 맵에 대한 깊이 조정을 공동으로 최적화합니다. 마지막으로 카메라 포즈를 고정하고, 신경망을 사용하지 않는 NeRF를 통해 조밀한 삼각 측량과 기하학적 검증을 수행합니다. 이 과정에서 포즈, 깊이 조정 및 삼각 측량된 희소 깊이(sparse depths)가 결과물로 산출됩니다.

- **Performance Highlights**: 자가 지도 학습 방식으로 $5$ 프레임 내에서 최고 성능의 감독된 깊이 및 대응 모델(SoTA supervised depth and correspondence models)에 이점이 있음을 최초로 보여주었습니다.



### Robust Multimodal 3D Object Detection via Modality-Agnostic Decoding and Proximity-based Modality Ensemb (https://arxiv.org/abs/2407.19156)
- **What's New**: MEFormer라는 새로운 접근 방식을 제안하여 LiDAR 센서에 의존하지 않고 3D 객체 검출을 수행합니다. 이 방법은 다양한 센서 모달리티(modality)로부터 얻은 정보를 효과적으로 융합하여 성능을 향상시킵니다.

- **Technical Details**: MEFormer는 모달리티에 구애받지 않는 디코딩 기술(Modality Agnostic Decoding, MOAD)과 근접 기반 모달리티 앙상블 모듈(Proximity-based Modality Ensemble, PME)을 도입합니다. MOAD는 입력 모달리티와 관계없이 변환기 디코더(transformer decoder)를 통해 기하학적 및 의미적 특징을 추출하고, PME는 환경에 따라 각 모달리티의 강점을 적응적으로 활용하면서 센서 노이즈의 영향을 줄입니다.

- **Performance Highlights**: MEFormer는 nuScenes 검증 세트에서 NDS 73.9%와 mAP 71.5%로 최고 수준의 성능을 달성했습니다. 다양한 환경 변화와 센서 문제에도 강인성을 보이며, 소스 코드는 공개되어 있습니다.



### RePLAy: Remove Projective LiDAR Depthmap Artifacts via Exploiting Epipolar Geometry (https://arxiv.org/abs/2407.19154)
- **What's New**: 새로운 연구는 RePLAy라는 매개변수 없는 분석적 솔루션을 제안하여 LiDAR와 RGB 카메라 사이의 정합 문제를 해결합니다. 이 접근법은 물리적 간격으로 인해 발생하는 LiDAR 투영 깊이맵의 왜곡을 제거합니다.

- **Technical Details**: 제안된 방법은 가상의 LiDAR 카메라와 RGB 카메라 간의 쌍안시스템을 구축하여 프로젝트 왜곡을 제거합니다. 제안된 분석 솔루션으로 에피폴라 클루전(epipolar occlusion)을 결정함으로써 왜곡을 제거합니다.

- **Performance Highlights**: 제안한 RePLAy 기법은 최신 단안 깊이 추정기(monocular depth estimators)와 3D 객체 검출기(object detectors)에 일관된 성능 향상을 보여줍니다. KITTI 데이터셋을 비롯해 대부분 자율주행 데이터셋인 nuScenes, Waymo와 DDAD에도 적용 가능합니다.



### Few-Shot Medical Image Segmentation with Large Kernel Attention (https://arxiv.org/abs/2407.19148)
- **What's New**: 의료 영상 분할(Medical Image Segmentation) 분야에서 소수의 주석 데이터로도 높은 정확도를 달성할 수 있는 새로운 모델을 제안합니다. 이 모델은 meta-learning을 기반으로 하며, comprehensive feature representation 능력을 갖추고 있습니다. 이를 통해, 지역적(Local) 및 장거리(Long-range) 특징을 모두 포착하여 분할 정확도를 향상시킵니다.

- **Technical Details**: 제안된 모델은 네 가지 주요 모듈로 구성되어 있습니다: Dual-path feature extractor, Attention module, Adaptive prototype prediction module, Multi-scale prediction fusion module. Dual-path feature extractor는 32x32 크기와 64x64 크기의 다중 스케일 특징을 획득합니다. Attention module은 지역적 및 장거리 정보를 캡처합니다. Adaptive prototype prediction module은 자동으로 이상 점수 임계를 조정하여 프로토타입을 예측합니다. 마지막으로, Multi-scale fusion prediction module은 다양한 스케일의 예측 마스크를 결합하여 최종 분할 결과를 생성합니다.

- **Performance Highlights**: CHAOS 및 CMR라는 공개 MRI 데이터셋에서 실험한 결과, 제안된 모델이 최첨단 성능을 달성하였습니다(State-of-the-Art Performance).



### Multi-Expert Adaptive Selection: Task-Balancing for All-in-One Image Restoration (https://arxiv.org/abs/2407.19139)
- **What's New**: 단일 이미지 복원 프레임워크를 사용하여 다중 작업 이미지 복원을 달성하려는 연구들이 많아지고 있습니다. 그러나 이 논문은 특정 작업들의 요구를 동시에 충족시키고, 작업 간의 관계를 균형 있게 유지하며, 모델 설계에서 작업 상호작용을 효과적으로 활용하는 것과 같은 실제적인 문제들을 해결하기 위해 새로운 접근 방식을 제안합니다. 이를 위해 다중 전문가 적응 선택 메커니즘(multi-expert adaptive selection mechanism)을 탐구합니다.

- **Technical Details**: 우선, 이미지의 저주파 및 고주파 성분을 포함하는 픽셀 채널 수준과 글로벌 수준을 모두 고려하는 특징 표현 방법(feature representation method)을 설계합니다. 이 방법을 기반으로 다중 전문가 선택 및 앙상블 계획을 구성합니다. 이 계획은 입력 이미지의 내용과 현재 작업의 프롬프트에 따라 전문가 라이브러리에서 가장 적합한 전문가를 적응적으로 선택합니다. 이를 통해 다양한 작업의 개별적인 요구를 충족시키며, 작업 간의 균형과 최적화도 달성할 수 있습니다.

- **Performance Highlights**: 전문가를 공유함으로써 우리 설계는 다른 작업들 간의 상호연결을 촉진하여 전반적인 성능과 자원 활용도를 향상시킵니다. 또한, 다중 전문가 메커니즘은 무관한 전문가들을 효과적으로 제거하여 방해를 줄이고 이미지 복원의 효과성과 정확도를 더욱 향상시킵니다. 실험 결과, 제안된 방법이 기존 접근 방식들보다 효과적이고 우월하다는 것이 증명되었으며, 다중 작업 이미지 복원에서의 실용적인 응용 가능성을 강조하고 있습니다.



### ObjectCarver: Semi-automatic segmentation, reconstruction and separation of 3D objects (https://arxiv.org/abs/2407.19108)
Comments:
          Project page is: this https URL

- **What's New**: ObjectCarver라는 새로운 방법이 도입되었습니다. 사용자는 하나의 뷰에서 단순 클릭 입력을 통해 개별 객체의 분할을 시작할 수 있습니다. 이 방법은 포즈된 다중 뷰 이미지와 사용자 입력 클릭 세트를 사용하여 장면을 개별 객체로 분해하고 각 객체에 대해 고품질의 3D 표면을 재구성합니다.

- **Technical Details**: 이 방법은 floaters를 방지하고 폐색(occlusion)에 의한 부적절한 조각화를 피하기 위한 손실 함수(loss function)를 도입합니다. 또한, 새로운 장면 초기화(scene initialization) 방법을 도입하여 이전 접근 방식에 비해 기하학적 세부 사항을 유지하면서 프로세스를 크게 가속화합니다. 이는 서명 거리 필드(SDF, Signed Distance Fields)를 사용하여 객체를 분리하는 기존의 방법과 달리, 세그먼트 마스크(segment masks)가 없어도 작동할 수 있습니다.

- **Performance Highlights**: ObjectCarver는 그림자 진리 마스크(ground truth masks)나 단안 단서(monocular cues)가 필요하지 않음에도 불구하고, 정성적이면서도 정량적으로 기존의 기준선을 능가합니다. 또한, 평가를 위한 새로운 벤치마크 데이터셋(benchmark dataset)을 소개합니다.



### UniForensics: Face Forgery Detection via General Facial Representation (https://arxiv.org/abs/2407.19079)
- **What's New**: UniForensics는 기존의 딥페이크 탐지 방법이 주로 저수준 텍스처(텍스처, texture) 특징에 의존하는 문제를 해결합니다. 이 방법은 고수준 의미(semantic) 특징을 활용하여 시간적(domain temporal) 불일치를 탐지합니다. 주요 하이라이트는 Transformer 기반 비디오 분류 네트워크와 메타 기능(face encoder for enriched facial representation)을 초기화하여 보다 풍부한 얼굴 표현을 활용하는 것입니다.

- **Technical Details**: UniForensics는 시간적 불일치를 더 잘 탐지하기 위해 Transformer 기반의 비디오 분류 네트워크를 사용합니다. 또한, 얼굴 표현을 풍부하게 하기 위해 메타 기능(face encoder)을 초기화합니다. 실제 얼굴 비디오 데이터를 효과적으로 활용하기 위해 Dynamic Video Self-Blending (DVSB) 방법을 설계하여 다양한 시간적(spatio-temporal) 위조 흔적을 생성합니다. 두 단계의 훈련 접근 방식을 채택하며, 첫 단계는 새로운 자기 지도 대조 학습(self-supervised contrastive learning)을 사용하여 위조 흔적에 집중하게 하고, 두 번째 단계에서는 얼굴 위조 탐지 데이터셋을 사용해 세부 조정을 진행합니다.

- **Performance Highlights**: UniForensics는 Celeb-DFv2와 DFDC 데이터셋에서 각각 95.3% 및 77.2%의 교차 데이터셋 AUC를 달성하며 기존 얼굴 위조 탐지 방법을 능가하는 일반화(Generalization) 능력과 강인성을 보였습을 보여줍니다.



### Flexible graph convolutional network for 3D human pose estimation (https://arxiv.org/abs/2407.19077)
Comments:
          arXiv admin note: text overlap with arXiv:2307.16074

- **What's New**: Flex-GCN은 그래프 컨볼루션 네트워크(graph convolutional networks)의 제한점을 극복하고자 제안된 새로운 모델입니다. 기존 모델들이 1-홉 이웃(one-hop neighbors)에 의존해, 신체 관절 간의 고차원 의존성(high-order dependencies)을 제대로 캡처하지 못하는 문제를 해결하고자 합니다. 특히, Flex-GCN은 전역 정보와 의존성을 더 넓고 효과적으로 학습할 수 있도록 설계되었습니다.

- **Technical Details**: Flex-GCN의 핵심은 유연한 그래프 컨볼루션(flexible graph convolution)입니다. 이는 각 노드의 즉시 이웃(immediate neighbors)과 이차 이웃(second-order neighbors)으로부터 특징(features)을 집계(aggregate)합니다. 이는 표준 컨볼루션과 같은 시간 및 메모리 복잡도를 유지하면서 이루어집니다. 네트워크 아키텍처는 유연한 그래프 컨볼루션 층의 잔여 블록(residual blocks)과 전역 특징 수집, 정규화, 보정을 위한 전역 반응 정규화(global response normalization) 층으로 구성됩니다.

- **Performance Highlights**: 정량적 및 정성적인 실험 결과는 Flex-GCN의 효율성을 입증합니다. 해당 모델은 벤치마크 데이터셋에서 경쟁력 있는 성능을 보여주었습니다.



### Configural processing as an optimized strategy for robust object recognition in neural networks (https://arxiv.org/abs/2407.19072)
- **What's New**: 이 논문은 객체 인식(object recognition)에서 중요한 역할을 하는 통합 처리(configural processing)의 효용성을 조사합니다. 특히, 국소적 특징(local featural cues)보다 통합적 단서(configural cues)가 더 강력한 인식 능력을 제공한다는 가설을 평가합니다.

- **Technical Details**: 연구진은 구성된 문자 자극(composite letter stimuli)을 사용하여 다양한 신경망 모델(neural network models)을 훈련시키고 평가했습니다. 모델들은 로컬 단서(local cues)와 통합적 단서(configural cues)를 각각 사용해 훈련되었습니다. 층별 분석(layerwise analysis)을 통해 통합적 단서에 대한 민감도가 로컬 단서보다 나중에 나타나는 것을 발견했습니다. 중요한 점은 이 통합 처리가 순전파(feedforward) 방식으로만 발생했으며, 반복 계산(recurrent computations)은 필요하지 않았습니다.

- **Performance Highlights**: 실험 결과, 통합적 단서는 회전(rotation)이나 스케일링(scaling) 등의 기하학적 변환에 대해 더 강력한 성능을 보였습니다. 두 가지 단서가 동시에 제공되는 상황에서도 통합적 단서가 더 선호되었습니다. 또한, 이러한 통합적 처리 방식은 문자 자극뿐만 아니라 자연적 얼굴 이미지(naturalistic face images)에도 성공적으로 적용되었습니다. 이 연구는 통합적 처리가 다양한 시각 조건에서 강력한 객체 처리를 위해 유익하다는 신경계산적(neurocomputational) 증거를 제공합니다.



### ScalingGaussian: Enhancing 3D Content Creation with Generative Gaussian Splatting (https://arxiv.org/abs/2407.19035)
Comments:
          14 pages

- **What's New**: ScalingGaussian라는 새로운 3D 콘텐츠 생성 프레임워크가 소개되었습니다. 이는 기존의 3D 및 2D 확산 모델(3D and 2D diffusion models)을 결합하여 생성된 3D 자산에서 상세한 텍스처와 높은 기하학적 일관성(geometric consistency)을 달성합니다. 이 기술은 전통적으로 전문가에게 의존하던 3D 모델링, 텍스처링 및 렌더링을 대중적으로 접근 가능하게 만듭니다.

- **Technical Details**: 초기에는 3D 확산 모델(3D diffusion model)이 점 구름(point clouds)을 생성하고, 이를 선택적 로컬 지역(local regions) 소거, 가우시안 노이즈(Gaussian noise) 주입, 및 로컬 밀도 가중 선택(local density-weighted selection)을 통해 밀집시킵니다. 이를 정제하기 위해 2D 확산 모델(2D diffusion model)과 Score Distillation Sampling (SDS) 손실을 사용하여 3D 가우시안을 복제(clone) 및 분할(split)하도록 유도합니다. 마지막으로, 3D 가우시안은 메시(meshes)로 변환되고 Mean Square Error(MSE) 및 Gradient Profile Prior(GPP) 손실을 통해 표면 텍스처를 최적화합니다.

- **Performance Highlights**: Image-to-3D 작업에 대한 실험 결과, ScalingGaussian 접근법은 고품질의 3D 자산을 효율적으로 생성하는 데 성공했으며, 흔히 발생하는 3D 확산의 드문 점 구름 문제를 해결하여 개선된 기하학적 구조와 상세한 텍스처를 제공했습니다.



### MangaUB: A Manga Understanding Benchmark for Large Multimodal Models (https://arxiv.org/abs/2407.19034)
Comments:
          This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 이 논문에서는 현대 대규모 멀티모달 모델(LMMs)의 만화 이해 능력을 평가하기 위해 새로운 벤치마크인 MangaUB를 설계하고 평가했습니다. MangaUB는 단일 패널과 여러 패널에 걸쳐 표시된 콘텐츠의 인식과 이해를 평가할 수 있게 설계되었습니다.

- **Technical Details**: MangaUB는 만화 패널이 자연 이미지와 다르기 때문에, 전통적으로 만화를 위한 특별한 컴퓨팅 시스템을 설계해야 했던 접근법과는 달리, LMMs의 적응 가능한 특성을 활용하여 보다 일반적인 접근법을 제공하기 위한 분석 도구입니다. 이는 모델의 다양한 만화 이해 능력을 세밀하게 분석할 수 있게 합니다.

- **Performance Highlights**: 결과에 따르면, 이미지 콘텐츠 인식에서는 강력한 성능을 보였으나, 여러 패널에 걸쳐 전달되는 감정과 정보를 이해하는 데에는 여전히 도전 과제가 남아 있습니다. 이는 만화 이해를 위한 LMMs의 향후 개선 방향을 제시합니다.



### Sparse Refinement for Efficient High-Resolution Semantic Segmentation (https://arxiv.org/abs/2407.19014)
Comments:
          ECCV 2024. The first two authors contributed equally to this work. Project page: this https URL

- **What's New**: 새로운 논문 'SparseRefine'에서는 고해상도 이미지(예: 8메가픽셀)에서 세밀한 디테일을 캡처하면서도 계산 복잡성을 최소화하는 방법을 제시합니다. 이 접근법은 저해상도의 밀집 예측을 사용한 후, 높은 엔트로피(entropy)의 희소한 픽셀들을 위한 고해상도 개선을 추가합니다. 이는 자율 주행 및 증강/혼합 현실과 같은 실생활 응용 프로그램에서 유용합니다.

- **Technical Details**: SparseRefine 방법은 크게 세 단계로 나뉩니다: 첫째, 저해상도 출력에서 엔트로피 선택기를 사용해 높은 엔트로피를 가지는 희소한 픽셀 집합을 식별합니다. 둘째, 희소한 픽셀의 특징을 효율적으로 추출하기 위해 희소 특징 추출기(sparse feature extractor)를 사용하는 것입니다. 마지막으로, 게이트 합성기(gated ensembler)를 통해 이 희소한 픽셀의 개선 사항을 초기 예측에 적용합니다. 이 방법은 기존의 어떤 semantic segmentation 모델(CNN- 또는 ViT 기반)에도 통합될 수 있습니다.

- **Performance Highlights**: SparseRefine를 HRNet-W48, SegFormer-B5, Mask2Former-T/L 및 SegNeXt-L 모델에 Cityscapes 데이터셋에 적용하면 속도가 1.5배에서 3.7배까지 증가하면서도 정확도 손실이 거의 없거나 아예 발생하지 않았습니다. 이 'dense+sparse' 패러다임은 효율적인 고해상도 비주얼 컴퓨팅의 새로운 길을 열어줍니다.



### PromptCCD: Learning Gaussian Mixture Prompt Pool for Continual Category Discovery (https://arxiv.org/abs/2407.19001)
Comments:
          ECCV 2024, Project page: this https URL

- **What's New**: PromptCCD라는 새로운 프레임워크가 도입되었습니다. 이 프레임워크는 연속적인 비라벨 데이터 스트림에서 새로운 카테고리를 자동으로 발견하고, 카테고리 발견 동안 발생할 수 있는 catastrophic forgetting 문제를 해결하는 데 중점을 둡니다.

- **Technical Details**: PromptCCD는 Gaussian Mixture Model (GMM)을 활용한 Gaussian Mixture Prompting (GMP) 모듈을 핵심으로 합니다. GMP는 동적으로 업데이트되는 풀(pool)로서, 표현 학습을 촉진하고 카테고리 발견 동안 잊어버림을 방지하는 역할을 합니다. 또한, GMP는 카테고리 수를 사전에 알지 못하더라도 비라벨 데이터에서 카테고리 수를 실시간으로 추정할 수 있게 합니다.

- **Performance Highlights**: PromptCCD는 대표적인 공개 데이터셋에서 기존 최신 방법들을 상당히 능가하며, 그 효과를 입증하였습니다. CCD를 위해 Generalized Category Discovery (GCD)의 표준 평가 메트릭을 확장하여 적용하였습니다.



### Graph-based Unsupervised Disentangled Representation Learning via Multimodal Large Language Models (https://arxiv.org/abs/2407.18999)
Comments:
          9 pages, 7 figures

- **What's New**: 본 논문에서는 관찰된 데이터의 기반 요인을 식별하고 분해하기 위한 새로운 접근법인 양방향 가중 그래프 기반 프레임워크를 소개합니다. 이 프레임워크는 복잡한 데이터 내에서 요인을 추출하고 이들의 상관관계를 학습합니다. 특히, 기존의 비현실적인 통계적 독립성 가정을 개선하여, 상관관계를 고려한 요인 분석을 수행합니다.

- **Technical Details**: 제안된 방법은 먼저 $eta$-VAE(Variational Autoencoder)를 기반으로 요인을 그래프의 초기 노드로 추출합니다. 이후 멀티모달 대형 언어 모델(MLLM, Multimodal Large Language Model)을 활용하여 잠재적 상관관계를 탐색하고 순위를 매기며 가중치를 업데이트합니다. 이러한 보완적인 모듈을 통합하여 미세한, 실용적이고 비지도식의 disentanglement(분리)를 달성합니다.

- **Performance Highlights**: 실험 결과 본 방법이 기존 방법들에 비해 disentanglement와 데이터 재구성 측면에서 우수한 성능을 보였습니다. 또한, MLLM으로부터 향상된 해석 가능성과 일반화 가능성을 계승하였습니다.



### Region Guided Attention Network for Retinal Vessel Segmentation (https://arxiv.org/abs/2407.18970)
- **What's New**: 망막 혈관 촬영(retinal imaging)은 신경학적 건강을 실시간으로 평가할 수 있는 독특한 장점을 가진 방법입니다. 이 연구에서는 엔코더-디코더 메커니즘(encoder-decoder mechanism)과 영역 유도 주의(region-guided attention) 기반의 경량 망막 혈관 세분화 네트워크를 제시합니다. 새로운 역방향 추가 주의 블록(inverse addition attention blocks)을 도입하여 관심 영역(foreground regions)에 집중하는 방식을 사용합니다.

- **Technical Details**: 본 네트워크는 역방향 추가 주의 블록과 영역 유도 주의(region-guided attention)를 사용하여 대상 영역(intriguing regions)의 세분화를 개선합니다. 모델 성능 향상을 위해 가중치 다이스 손실(weighted dice loss)을 적용하였습니다. 이는 망막 혈관 세분화 작업에서 자주 발생하는 클래스 불균형(class imbalance)의 문제를 해결하는 데 효과적입니다. 다이스 손실함수(dice loss)는 거짓 양성(false positives)과 거짓 음성(false negatives)을 동일하게 벌점화함으로써 더 정확한 세분화를 유도합니다.

- **Performance Highlights**: 기준 데이터셋(benchmark dataset)에서 광범위한 실험 결과, 최신 방법론과 비교하여 다음과 같은 성과를 보였습니다: 재현율(recall) 0.8285, 정밀도(precision) 0.8098, 정확도(accuracy) 0.9677, F1 점수 0.8166.



### Real Face Video Animation Platform (https://arxiv.org/abs/2407.18955)
- **What's New**: 최근 몇 년 동안, 얼굴 영상 생성 모델(facial video generation models)이 인기를 얻었습니다. 그러나 이러한 모델은 고급 애니메이션 스타일 얼굴 학습 세트(anime-style face training sets)의 부재로 인해 과장된 애니메이션 스타일 얼굴을 다루는 데 한계가 있습니다. 이를 해결하기 위해, 우리는 실시간으로 실제 인간 얼굴을 만화 스타일 얼굴로 변환할 수 있는 페이셜 애니메이션 플랫폼(facial animation platform)을 제안합니다. 이 플랫폼은 여러 모델(multiple models)을 지원하며, Gradio 프레임워크(Gradio framework)를 기반으로 구축되어 뛰어난 상호작용성과 사용자 친화성을 자랑합니다.

- **Technical Details**: 사용자는 실제 얼굴 영상 또는 이미지를 입력하고 원하는 만화 스타일을 선택할 수 있습니다. 시스템은 이후 얼굴 특징을 자동으로 분석하고 필요한 전처리(preprocessing)을 수행한 후 적절한 모델을 호출하여 표현력이 풍부한 애니메이션 스타일 얼굴을 생성합니다. 우리는 HDTF 데이터셋(HDTF dataset)을 처리하기 위해 다양한 모델을 시스템 내에서 사용하여 애니메이션화 된 얼굴 영상 데이터셋(facial video dataset)을 생성합니다.



### Photogrammetry for Digital Twinning Industry 4.0 (I4) Systems (https://arxiv.org/abs/2407.18951)
- **What's New**: 이 논문은 Industry 4.0의 도래와 함께 제조 업계에서의 클라우드 컴퓨팅, 머신 러닝(ML), 인공지능(AI), 및 범용 네트워크 연결성을 통합하여 성능 최적화 및 생산성 향상을 이루고 있는 현재 흐름을 다룹니다. 특히, 디지털 트윈(Digital Twin, DT) 기술의 한 형태로서 사진측량(Photogrammetry)과 3D 스캐닝 기술을 통해 물리적 프로세스를 정확하게 디지털화하는 방법을 연구합니다.

- **Technical Details**: 이 연구에서는 아이폰 15 프로(iPhone 15 Pro)의 스테레오 비전 기능을 활용하여 Industry 4.0 시스템의 깊이 정보를 캡처하고, 이 이미지를 3D 스캐닝 도구를 사용하여 3D 모델로 변환한 후, 3D 모델링 및 렌더링 소프트웨어에서 DT 모델을 생성했습니다. 이 방식의 신뢰성을 확인하기 위해 수동 측정값(테이프 측정기)을 기준으로 3D 모델의 오류율을 측정했습니다.

- **Performance Highlights**: 수작업으로 측정한 값과 포토그래메트리(Photogrammetry) 방식으로 생성된 모델 간의 평균 오차율은 4.97%였으며, 표준 편차는 5.54%로 나타났습니다. 이는 소비자 등급의 장치를 사용한 포토그래메트리가 스마트 제조를 위한 디지털 트윈 생성에 효율적이며 비용 효율적인 접근법이 될 수 있음을 의미합니다.



### Predicting Winning Captions for Weekly New Yorker Comics (https://arxiv.org/abs/2407.18949)
- **What's New**: Vision Transformers (ViTs)를 사용한 이미지 캡셔닝 기술을 New Yorker 만화에 적용하여 캡션을 생성하는 연구로, 주어진 만화의 위트와 유머를 반영한 텍스트를 제공하는 방식을 탐구하였습니다. 이 연구는 이미지 캡셔닝 기술의 새로운 표준을 제시합니다.

- **Technical Details**: 이 논문에서는 Vision Transformers (ViTs) 기반의 인코더-디코더 모델을 활용하여 만화 이미지에 적절한 캡션을 생성하는 방법을 구현하였습니다. 이 작업은 복잡한 시각적 및 언어적 처리뿐만 아니라 문화적 뉘앙스와 유머에 대한 이해를 요구합니다.

- **Performance Highlights**: 이 연구는 New Yorker 만화 캡션 콘테스트의 우승 작품에 필적할 정도의 위트와 유머를 담은 캡션을 생성하는 데 성공하였습니다. 이는 이미지 캡셔닝 기술의 높은 성능과 잠재력을 보여줍니다.



### WalkTheDog: Cross-Morphology Motion Alignment via Phase Manifolds (https://arxiv.org/abs/2407.18946)
Comments:
          SIGGRAPH 2024. Project page: this https URL Video: this https URL

- **What's New**: 우리는 캐릭터의 형태와 골격 구조에 독립적으로 모션 데이터셋의 주기성 구조와 의미를 이해하기 위한 새로운 접근 방식을 소개합니다. 기존의 고차원 잠재 공간을 사용하는 방법과 달리, 잠재 진폭에 대응하는 다중 닫힌 곡선으로 구성된 페이즈 매니폴드(phase manifold)를 제안합니다.

- **Technical Details**: 제안된 벡터 양자화 주기성 오토인코더(vector quantized periodic autoencoder)를 통해 사람과 개와 같은 여러 캐릭터에 대해 감독 없이 공용 페이즈 매니폴드를 학습합니다. 이는 이산 구조와 얕은 네트워크를 병목(bottleneck)으로 사용하여 달성되며, 의미적으로 유사한 모션들이 동일한 매니폴드의 곡선에 클러스터링됩니다. 같은 구성 요소 내의 모션은 페이즈 변수에 의해 시간적으로 정렬됩니다.

- **Performance Highlights**: 개선된 모션 매칭 프레임워크와 결합하여, 우리는 모션 검색, 전이 및 스타일라이제이션을 포함한 여러 응용 프로그램에서 매니폴드가 시간 및 의미 정렬의 가능성을 보여줍니다. 이 논문의 코드와 사전 훈련된 모델은 해당 URL에서 사용할 수 있습니다.



### LEMoN: Label Error Detection using Multimodal Neighbors (https://arxiv.org/abs/2407.18941)
- **What's New**: 이 논문에서는 이미지-캡션 쌍 (image-caption pairs)으로 구성된 대형 데이터셋의 신뢰성을 높이기 위한 새로운 방법인 LEMoN을 제안합니다. 많은 데이터셋이 웹에서 스크래핑한 데이터를 사용하고 있어, 잘못 레이블된 예시들이 포함될 가능성이 큽니다. 이러한 문제를 해결하기 위해, LEMoN은 이미지와 캡션의 적절성을 평가하여 오류가 있는 레이블을 자동으로 식별합니다.

- **Technical Details**: LEMoN은 대비 학습 (contrastively pretrained)된 멀티모달 모델의 잠재 공간 (latent space)에서 이미지-캡션 쌍의 멀티모달 네이버후드 (multimodal neighborhood)를 활용합니다. 기존의 유사도 기반 필터링 방법을 넘어서는 새로운 접근법으로, 이미지와 캡션의 잠재 표현을 비교하여 데이터셋에서 노이즈를 식별합니다.

- **Performance Highlights**: LEMoN은 레이블 오류 식별에서 기존의 기준선 (baseline) 대비 더 우수한 성능을 보였습니다. 또한, LEMoN으로 필터링한 데이터셋을 사용한 학습에서는 분류 및 캡션 생성 성능이 향상되었습니다.



### Monitoring Time-Varying Changes of Historic Structures Through Photogrammetry-Driven Digital Twinning (https://arxiv.org/abs/2407.18925)
- **What's New**: 역사적 구조물의 시간에 따른 변화를 모니터링 하기 위해 새롭고 혁신적인 디지털 트윈 프레임워크(digital twin framework)를 제안했습니다. 이 프레임워크는 기존 연구와 달리 구조적 손상의 발전 과정을 평가하는 데 중점을 두고 있습니다.

- **Technical Details**: 제안된 디지털 트윈 프레임워크는 총 5개의 구성 요소로 이루어져 있으며, 이를 통해 역사적 구조물의 장기적인 변화를 추적합니다. 연구는 괌(Guam)섬의 포트 솔레다드(Fort Soledad)에 있는 카세메이트를 테스트베드로 사용하여 검증되었습니다.

- **Performance Highlights**: 연구 결과에 따르면, 제안된 디지털 트윈 프레임워크가 시간 흐름에 따른 구조물의 악화를 효과적으로 모니터링할 수 있음이 확인되었습니다. 이는 문화유산 보존 커뮤니티의 시급한 요구를 충족시킬 수 있음을 보여줍니다.



### SAPG: Split and Aggregate Policy Gradients (https://arxiv.org/abs/2407.20230)
Comments:
          In ICML 2024 (Oral). Website at this https URL

- **What's New**: 본 논문에서는 현재 강화 학습(Reinforcement Learning, RL) 방법, 특히 PPO가 병렬화된 환경의 이점을 제대로 활용하지 못하고 성능이 포화된다는 문제를 지적합니다. 이를 해결하기 위해 새로운 온-정책 강화 학습 알고리즘인 SAPG를 제안합니다. SAPG는 대규모 환경을 효과적으로 활용할 수 있으며, 환경을 여러 개의 청크로 나눈 후 중요도 샘플링(importance sampling)을 통해 다시 합칩니다.

- **Technical Details**: SAPG는 기존의 온-정책 RL 알고리즘이 특정 포인트 이후 병렬화 환경에서 이점을 충분히 활용하지 못하는 문제를 개선합니다. 이를 위해 SAPG 알고리즘은 대규모 환경을 청크로 나눈 다음, 중요도 샘플링을 사용하여 이 청크들을 다시 합칩니다. 이 과정은 GPU 기반 시뮬레이션의 장점을 극대화하고, 대량의 데이터를 효과적으로 사용할 수 있게 합니다.

- **Performance Highlights**: SAPG는 다양한 도전적인 환경에서 기존의 PPO와 다른 강력한 기준선 알고리즘이 높은 성능을 달성하지 못하는 상황에서도 우수한 성능을 보였습니다. 대규모 환경을 활용할 수 있는 능력이 뛰어나기 때문에, SAPG는 학습 속도와 최종 성능 면에서 현저한 향상을 보였습니다.



### Registering Neural 4D Gaussians for Endoscopic Surgery (https://arxiv.org/abs/2407.20213)
- **What's New**: 이번 연구에서는 신경망(neural networks)을 이용하여 4D 장면을 고품질로 재구성하는 새로운 방법을 제안했습니다. 특히, 수술 계획(surgical planning) 및 시뮬레이션을 위한 동적 장면 등록(dynamic scene registration)이 주요 도전 과제로 언급됩니다. 본 논문에서는 수술 장면을 효과적으로 포착하는 4D Gaussian Splatting 기법을 사용하였으며, 더욱 정확한 등록을 위해 Spatially Weight Cluttering (SWC) 방법을 도입했습니다.

- **Technical Details**: 연구에서는 먼저 4D Gaussian Splatting을 이용하여 수술 장면을 고정적(static) 및 동적(dynamic)으로 효과적으로 표현합니다. 그런 다음, SWC(Spatially Weight Cluttering) 방식을 도입하여 수술 장면 간의 특징을 정확히 정렬함으로써 실제와 유사한 수술 시뮬레이션을 가능하게 합니다. 마지막으로, 변형 가능한 장면 등록(deformable scene registration) 전략을 제시하여 공간적 및 시간적 정보를 모두 활용하여 대응(correspondence)을 맞추는 방식을 적용했습니다.

- **Performance Highlights**: 제안된 방법은 기존의 암묵적 신경 표현(implicit neural representation) 등록 방법들에 비해 뛰어난 성능을 발휘합니다. 이 방법은 수술 계획 및 훈련을 개선할 가능성이 있으며, 궁극적으로 환자 결과 향상에 기여할 수 있습니다.



### SpaER: Learning Spatio-temporal Equivariant Representations for Fetal Brain Motion Tracking (https://arxiv.org/abs/2407.20198)
Comments:
          11 pages, 3 figures, Medical Image Computing and Computer Assisted Interventions (MICCAI) Workshop on Perinatal Imaging, Placental and Preterm Image analysis (PIPPI) 2024

- **What's New**: SpaER는 태아의 움직임을 추적하기 위한 혁신적인 방법을 소개합니다. 이 방법은 기하학적 변환에 불변적인 필터와 자기 주의 메커니즘(self-attention mechanisms)을 활용하여 시공간 표현을 효과적으로 학습합니다. 기존에 정적인 이미지 쌍에서 태아 뇌의 움직임을 추정하는 접근법과 달리, SpaER는 시간적, 공간적 차원에서 태아 머리의 강체 운동 패턴을 동적으로 추적합니다.

- **Technical Details**: SpaER는 먼저 저차원 공간 표현(低次元 空間 表現)을 통해 강체 운동 시퀀스를 효율적으로 학습하는 기하학적 변환 불변 신경망(equivariant neural network)을 개발합니다. 이후, 시간 인코딩과 자기 주의 신경망 계층(self-attention neural network layers)을 통합해 시공간 표현을 학습합니다. 이를 통해 태아 뇌 운동의 장기적인 의존성을 포착하고, 대비 변화 및 심각한 움직임 왜곡으로 인한 정렬 오류를 해결할 수 있습니다. 또한, 모든 시간 프레임에 걸쳐 이미지 왜곡을 적절히 다루는 기하학적 변형 추정(估定)을 제공합니다.

- **Performance Highlights**: SpaER은 태아 MRI 시퀀스에서 태아의 움직임을 정확하게 측정, 추적 및 교정하는 데 중요한 잠재적 가치를 지니고 있습니다. 우리가 아는 한, 데이터 증강(data augmentation) 없이 태아의 움직임을 추적하기 위해 깊은 신경망(deep neural networks)으로 시공간 표현을 학습하는 접근법으로는 첫 번째 사례입니다. 모형은 실제 태아 에코 평면 이미지(real fetal echo-planar images)를 사용하여 시뮬레이션된 모션(Motion)과 실제 모션을 통해 검증되었습니다.



### Theia: Distilling Diverse Vision Foundation Models for Robot Learning (https://arxiv.org/abs/2407.20179)
- **What's New**: 비전 기반 로봇 정책 학습에서 단일 작업 요구(분류 또는 세그먼트와 같은)를 넘어 다양한 비주얼 작업에 대한 전체적인 이해가 필요합니다. 이를 기반으로, 우리는 다양한 비주얼 작업들에 훈련된 여러 기성 비전 기초 모델들(vision foundation models)을 집대성하여 Theia라는 비전 기초 모델을 도입했습니다. Theia는 로봇 학습을 향상시키기 위해 다양한 시각적 지식을 인코딩합니다.

- **Technical Details**: Theia는 여러 비전 기초 모델들의 풍부한 시각적 표현을 증류하여 로봇에게 학습시킵니다. 학습 데이터가 적고 모델 크기가 작음에도 불구하고, Theia는 최첨단의 모델들과 이전의 로봇 학습 모델들을 능가합니다. 또한, 사전 훈련된 시각적 표현의 품질을 정량화하고 피처 노름 분포(feature norm distributions)의 엔트로피가 높을수록 로봇 학습 성능이 향상된다는 가설을 세웠습니다.

- **Performance Highlights**: 다양한 실험 결과, Theia는 자사 모델들과 이전 로봇 학습 모델들보다 더 나은 성능을 보였고, 학습 데이터와 모델 크기 모두에서 더 효율적임을 입증했습니다. 코드와 모델은 특정 URL에서 사용 가능합니다.



### LatentArtiFusion: An Effective and Efficient Histological Artifacts Restoration Framework (https://arxiv.org/abs/2407.20172)
Comments:
          Accept to DGM4MICCAI2024

- **What's New**: 이번 연구에서는 병리학자와 컴퓨터 지원 진단 (CAD) 시스템 모두에서 분석 오류를 유발할 수 있는 병리학적 유물(histological artifacts)을 복원하기 위한 새로운 프레임워크 'LatentArtiFusion'을 제안합니다. LatentArtiFusion은 잠재 확산 모델(Latent Diffusion Model, LDM)을 활용하여 기존 GAN(Generative Adversarial Networks) 및 픽셀 수준 확산 모델(pixel-level Diffusion Models) 기반 접근 방식에서 겪는 성능 한계와 계산 비효율성을 극복합니다.

- **Technical Details**: LatentArtiFusion은 전통적인 픽셀 수준 확산 프레임워크와 달리 낮은 차원의 잠재 공간에서 복원 과정을 실행하여 계산 효율성을 크게 향상시킵니다. 또한, 비유물(non-artifact) 영역에서의 잘못된 전이를 방지하기 위해 잠재 공간에서의 새로운 지역 유물 복원 알고리즘을 도입하여 기존의 GAN 기반 방식과 차별화됩니다.

- **Performance Highlights**: 실험 결과, LatentArtiFusion은 기존의 최첨단 픽셀 수준 확산 프레임워크 대비 30배 이상의 속도 향상을 달성했습니다. 또한, 다양한 평가 지표에서 GAN 기반 방법을 최소 5% 이상 초과하는 성능을 보였습니다. 추가로, 조직 분류 작업의 다운스트림(downstream) 평가에서 제안된 프레임워크의 실질적인 유용성을 입증하였습니다.



### FiCo-ITR: bridging fine-grained and coarse-grained image-text retrieval for comparative performance analysis (https://arxiv.org/abs/2407.20114)
Comments:
          19 pages, submitted to International Journal of Multimedia Information Retrieval

- **What's New**: 이 논문에서는 Image-Text Retrieval (ITR) 분야에서 Fine-Grained (FG) 인스턴스 레벨의 검색과 Coarse-Grained (CG) 카테고리 레벨의 검색을 비교할 수 있는 표준 평가 방법론을 제공하는 	exttt{FiCo-ITR} 라이브러리를 소개합니다. 이 새로운 라이브러리를 통해 FG와 CG 모델의 직접적인 비교가 가능해졌습니다.

- **Technical Details**: FG 검색은 대규모 Vision-Language Pretraining (VLP)을 활용하여 높은 정확도를 달성하지만, 계산 복잡도가 증가하는 단점이 있습니다. 반면, CG 검색은 Cross-Modal Hashing (CMH)을 사용하여 효율성을 우선시하지만 검색 성능이 떨어질 수 있습니다. 본 연구에서는 대표적인 FG와 CG 모델을 선정하여 정확도, 재현율, 계산 복잡도 등의 측면에서 다양한 데이터 규모에 대해 실증적 평가를 수행하였습니다.

- **Performance Highlights**: 본 연구 결과는 최근의 대표적인 FG와 CG 모델 간의 성능-효율성 트레이드오프에 대한 새로운 통찰을 제공합니다. FG 모델은 높은 정확도를 자랑하지만 고도의 계산 자원이 필요하며, CG 모델은 빠른 검색 속도와 높은 효율성을 제공하지만 상대적으로 낮은 검색 성능을 보입니다. 이러한 결과는 특정 검색 작업을 위한 모델 선택에 있어 보다 정보에 입각한 결정을 내릴 수 있는 토대를 제공합니다.



### Classification, Regression and Segmentation directly from k-Space in Cardiac MRI (https://arxiv.org/abs/2407.20108)
- **What's New**: 새로운 연구에서는 심장 자기공명영상(CMR) 진단에 있어 기존의 이미지 도메인 방법 대신 k-space 데이터를 직접 처리하는 모델, KMAE를 제안합니다. 이는 중간 변환 단계를 생략하고, 심장 질병 분류, 관련 표현형 회귀, 심장 형태 분할 작업을 수행할 수 있습니다.

- **Technical Details**: KMAE는 Transformer 기반 모델로, 복소수 값이 포함된 k-space 데이터를 직접 처리합니다. 기존의 마그니튜드 정보만 사용하는 DICOM 이미지 방식과 달리, k-space는 마그니튜드와 위상 정보를 모두 포함하고 있습니다. 또한, 심장 MRI 진단에서 중요한 역할을 할 수 있는 k-space 기반의 직접적인 처리 방식을 전면에 내세웠습니다.

- **Performance Highlights**: 본 연구에서 KMAE 모델은 기존 이미지 도메인 방법(예: Masked Autoencoders (MAEs))에 비해 경쟁력 있는 분류 및 회귀 성능을 보였고, 심장 근육 분할 작업에서도 0.884의 만족스러운 Dice 점수를 기록하였습니다. 또한, k-space 데이터가 8배 적게 샘플링된 상황에서도 일관된 성능을 유지하는 강력함을 입증하였습니다.



### Segmenting Fetal Head with Efficient Fine-tuning Strategies in Low-resource Settings: an empirical study with U-N (https://arxiv.org/abs/2407.20086)
Comments:
          5 figures, 2 tables

- **What's New**: 이번 연구는 태아 초음파 영상에서 태아의 머리 둘레를 정확하게 측정하기 위해 필요한 세분화(sementation) 작업에서 사용되는 U-Net 모델의 튜닝 전략에 대한 다양한 접근 방법을 요약했습니다. 특히, 훈련이 오래 걸리거나 데이터가 제한된 상황에서 효율적인 튜닝 방법을 탐구했습니다. 연구에서는 여러 국가의 초음파 데이터를 활용한 실험 결과를 바탕으로 최적의 튜닝 전략을 분석했습니다.

- **Technical Details**: 연구팀은 U-Net 모델의 인코더-디코더(encoder-decoder) 구조를 중심으로 여러 백본(backbone) 아키텍처와 모델 구성 요소, 튜닝 전략(fine-tuning strategies)을 비교했습니다. 주어진 실험은 네덜란드, 스페인, 말라위, 이집트 및 알제리의 데이터를 활용하여 진행되었으며, 특히 디코더 부분의 튜닝 전략이 다른 부분의 전략보다 우수함을 발견했습니다. 또한, 파라미터 수가 적은 네트워크 아키텍처도 유사하거나 더 나은 성능을 발휘할 수 있음을 보여줍니다.

- **Performance Highlights**: 연구 결과, U-Net 모델을 처음부터 훈련하는 것보다 튜닝을 통한 학습이 더 나은 성능을 보였으며, 디코더 부분을 중심으로 한 튜닝 전략이 다른 부분의 튜닝 전략보다 우수했습니다. 특히, 데이터가 제한된 환경에서 이러한 튜닝 전략이 효과적임을 입증하였으며, Few-shot Learning에서도 우수한 결과를 보였습니다. 코드와 특정 튜닝된 가중치(weights)도 공개하여 연구의 재현성을 높였습니다.



### MimiQ: Low-Bit Data-Free Quantization of Vision Transformers with Encouraging Inter-Head Attention Similarity (https://arxiv.org/abs/2407.20021)
Comments:
          Author Preprint

- **What's New**: 이번 연구에서는 원본 학습 데이터 없이 저비트(quantization)를 수행할 수 있는 데이터 프리 양자화(DFQ) 기법을 비전 트랜스포머(ViT) 아키텍처에 적용하는 새로운 방법을 제시합니다. 이 방법은 특히 헤드 간 주의(attention) 유사성을 aligning하여 성능을 향상시킵니다.

- **Technical Details**: 제안된 방법 \\aname은 헤드 별 주의 반응(head-wise attention responses)을 공간적 쿼리 패치(spatial query patches)에 맞추어 synthetic data를 생성합니다. 이후, 헤드 별 구조적 주의 증류(head-wise structural attention distillation)를 적용하여 양자화된 네트워크의 주의 맵을 풀-프리시전(Full-Precision) 네트워크의 주의 맵과 맞춥니다.

- **Performance Highlights**: 실험 결과, 제안된 방법이 기존 데이터 프리 ViT 양자화 기법보다 뛰어난 성능을 보여주었으며, 새로운 state-of-the-art 성능을 달성하였습니다.



### From Flat to Spatial: Comparison of 4 methods constructing 3D, 2 and 1/2D Models from 2D Plans with neural networks (https://arxiv.org/abs/2407.19970)
- **What's New**: 이 논문은 단일 이미지에서 2.5D 및 3D 메쉬(mesh)로의 변환에 대한 네 가지 혁신적인 방법을 평가합니다. 이러한 기술들은 건축 디자인 시각화 및 효율성을 향상시키는 데 큰 역할을 합니다. 논문에서는 특히 'One-2-3-45', 'CRM: 단일 이미지에서 3D 텍스처 메쉬로의 변환', 'Instant Mesh', 'Image-to-Mesh' 방법의 적용 가능성을 집중적으로 분석합니다.

- **Technical Details**: 첫 번째 방법인 'One-2-3-45'는 확산 기반 접근법을 활용하여 다중 뷰 재구성을 생성하며, 높은 기하학적 충실도와 텍스처 품질을 보장합니다. 'CRM'은 컨볼루션 네트워크(convolutional network)를 사용해 기하학적 프라이어(priors)를 통합하여 세밀하고 텍스처링된 메쉬를 신속하게 생성합니다. 'Instant Mesh'는 다중 뷰 확산 및 희소 뷰 모델을 결합하여 속도와 확장성을 제공하며, 다양한 건축 프로젝트에 적합합니다. 'Image-to-Mesh'는 생성적 적대 신경망(GAN)을 활용해 단일 이미지에서 3D 메쉬를 생성하며, 이미지와 깊이 맵 데이터를 교육 과정에 통합하여 텍스처 충실도와 기하학적 정확성을 유지합니다.

- **Performance Highlights**: 이 비교 연구는 각 방법이 디자인 주기 시간을 줄이고 정확성을 개선하며 다양한 건축 스타일 및 요구사항에 유연한 적응을 가능하게 한다는 측면에서의 기여를 강조합니다. 이러한 3D 메쉬 생성 기술의 발전은 신속한 시각화 및 반복 작업을 통해 건축 실무에 혁신을 가져올 것입니다.



### Language-driven Grasp Detection with Mask-guided Attention (https://arxiv.org/abs/2407.19877)
Comments:
          Accepted at IROS 2024

- **What's New**: 이 논문에서는 언어 주도(에 의한) 잡기 탐지를 위한 새로운 방법을 제안합니다. 이 방법은 transformer 주의 메커니즘(attention mechanism)과 의미 분할(semantic segmentation) 기능을 활용하여 마스크 유도 주의(mask-guided attention)를 사용합니다. 기존 방법들이 가리움 문제(occlusion)와 언어를 사용한 잡기 문제에서 어려움을 겪는 반면, 이 새로운 방법은 시각 정보, 분할 마스크 기능, 자연 언어 명령을 통합하여 잡기 탐지 정확도를 크게 향상시킵니다.

- **Technical Details**: 제안된 방법은 transformer 주의 메커니즘과 의미 분할 기능을 통합하여 마스크 유도 주의를 생성합니다. 이는 시각 데이터와 함께 분할 마스크 특징, 자연 언어 지시를 결합하여 기계가 더 정확하게 목표물을 인식하고 잡을 수 있게 만듭니다.

- **Performance Highlights**: 집중적인 실험 결과, 새로운 방법은 최근 다른 기준들을 10.0%의 성공 점수 향상으로 명확하게 능가하는 것으로 나타났습니다. 또한, 실제 로봇 실험에서도 우리의 방법의 효율성을 확인했습니다.



### Distilling High Diagnostic Value Patches for Whole Slide Image Classification Using Attention Mechanism (https://arxiv.org/abs/2407.19821)
- **What's New**: 본 논문에서는 Whole Slide Image (WSI) 분류에서 다중 인스턴스 학습 (Multiple Instance Learning, MIL)의 새로운 접근법인 AFD-MIL를 소개합니다. AFD-MIL는 주의 메커니즘(attention mechanism)을 사용하여 진단 가치가 높은 패치를 추출하고, 이를 통해 불필요한 노이즈를 줄입니다.

- **Technical Details**: AFD-MIL는 약지도 학습(weakly supervised learning)에서의 전처리 단계로 중복 패치를 제거하며, 기존처럼 모든 패치를 강제로 통합하는 대신 진단적 가치가 높은 특징을 끌어내기 위해 주의 메커니즘을 사용합니다. 또한, 글로벌 손실 최적화(global loss optimization)를 사용하여 특징 증류 모듈을 미세 조정합니다.

- **Performance Highlights**: AFD-MIL는 Camelyon16(유방암) 데이터셋에서 91.47%의 정확도(ACC)와 94.29%의 AUC를, TCGA-NSCLC(비소세포 폐암) 데이터셋에서 93.33%의 ACC와 98.17%의 AUC를 기록했습니다. 이 방법은 기존 MIL 방법들과 비교하여 일관된 성능 향상을 보이며, 특정 질병에 맞춘 특징 증류 방법을 사용했습니다.



### VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks (https://arxiv.org/abs/2407.19795)
Comments:
          31 pages, 5 figures, 20 tables

- **What's New**: 도메인 일반화(Domain Generalization)는 딥러닝 모델의 중요한 측면입니다. 이는 모델이 보지 못한 도메인의 데이터에서도 잘 수행할 수 있는 능력을 결정합니다. 그러나 시각-언어 작업(Vision-Language Tasks)을 위한 딥러닝 모델의 도메인 일반화에 대한 연구는 필수 데이터셋의 부족으로 인해 제한적이었습니다. 이를 해결하기 위해 VolDoGer(Vision-Language Dataset for Domain Generalization)를 제안합니다. 이는 이미지 캡셔닝, 비주얼 질문 응답, 비주얼 엔테일먼트(Visual Entailment) 등 세 가지 시각-언어 작업을 다루는 전용 데이터셋입니다.

- **Technical Details**: VolDoGer는 LLM 기반 데이터 주석 기법을 시각-언어 작업에 확장하여 인간 주석자(Human Annotators)를 모집하는 부담을 줄였습니다. 다양한 모델, 예를 들어, Fine-Tuned 모델에서 최근의 멀티모달 대형 언어 모델(Multimodal Large Language Model)까지 VolDoGer를 통해 도메인 일반화 능력을 평가했습니다.

- **Performance Highlights**: VolDoGer 데이터셋을 통해 다양한 모델의 도메인 일반화 성능을 체계적으로 평가할 수 있게 되었습니다. 이를 통해 특정 모델을 더 효과적으로 도출하고, 시각-언어 작업에서의 도메인 일반화 가능성을 탐구할 수 있습니다.



### Unmasking unlearnable models: a classification challenge for biomedical images without visible cues (https://arxiv.org/abs/2407.19773)
- **What's New**: 이미지에서 시각적 단서가 없는 특성을 예측하는 것은 알고리즘이 시각적으로 상관된 실제 결과를 포착하도록 설계되어 있기 때문에 어려운 문제입니다. 본 연구는 특히 MGMT 메틸화 상태를 MRI 이미지로부터 예측하는 문제에 집중합니다. 이는 교모세포종 환자의 치료 결정을 위한 중요한 요소로 작용합니다. 기존 모델들의 성능이 만족스럽지 못한 상황에서 이를 해결하는 것이 긴급하다는 점을 강조했습니다.

- **Technical Details**: 본 연구에서는 전이 학습(transfer learning)을 이용하여 기존 모델의 벤치마크를 수행하고, 모델의 아키텍처를 계층(strahlo layers)별로 살펴보는 방식으로 역학적 구조를 분석했습니다. 또한, 특징 선택 전략(feature selection strategy)을 적용하여 모델의 해석력을 높였습니다. 이러한 접근방식을 통해, 현재의 모델들이 학습 가능하지 않으며 실제 응용을 위해서는 새로운 아키텍처가 필요할 수 있음을 발견했습니다.

- **Performance Highlights**: 본 연구는 시각적 단서가 없는 특성을 예측하는 모델에서 현재의 한계를 지적하고 이에 대한 해결책을 제안하는 것으로, 이러한 연구가 예측 모델의 발전과 비가시적 단서 기반의 응용에 중요한 기여를 할 것으로 기대됩니다.



### TeleOR: Real-time Telemedicine System for Full-Scene Operating Room (https://arxiv.org/abs/2407.19763)
- **What's New**: TeleOR은 원격 수술 분야에서 고충실도, 실시간 장면 재구성 및 전송을 통해 새로운 시대를 여는 혁신적인 시스템입니다. TeleOR은 동적 자체 보정(dynamic self-calibration), 선택적 OR 재구성(selective OR reconstruction), 뷰포트 적응형 전송(viewport-adaptive transmission)과 같은 세 가지 혁신적인 접근 방식을 도입하였습니다.

- **Technical Details**: TeleOR의 동적 자체 보정(dynamic self-calibration) 기능은 사전 마커 없이 고유한 장면 특징을 활용하여 장애물 회피 및 실시간 카메라 조정을 지원합니다. 선택적 OR 재구성(selective OR reconstruction)은 동적으로 변화하는 장면 세그먼트에 집중하여 재구성 복잡성을 줄이고, 뷰포트 적응형 전송(viewport-adaptive transmission)은 실시간 클라이언트 피드백을 기반으로 데이터를 최적화하여 대역폭 제약 내에서 고품질 3D 재구성을 효율적으로 제공합니다.

- **Performance Highlights**: 4D-OR 수술 장면 데이터셋에 대해 실시된 종합 실험에서 TeleOR의 우수성과 적용 가능성이 입증되었습니다. 이는 원격 수술 가이던스에 내재된 공간적, 기술적 장애를 극복함으로써 원격 개입(tele-intervention)을 혁신적으로 변화시킬 잠재력을 밝힙니다.



### Foundations for Unfairness in Anomaly Detection -- Case Studies in Facial Imaging Data (https://arxiv.org/abs/2407.19646)
Comments:
          16 pages, 8 figures, AAAI/ACM AIES24

- **What's New**: 이번 연구는 깊은 이상 탐지(Deep Anomaly Detection, AD) 알고리즘의 공정성 문제를 얼굴 이미지 데이터를 통해 탐구합니다. 이는 AI를 얼굴 이미지 데이터에 적용하는 것의 논란과, AD 알고리즘의 공정성 문제를 밝히기 위한 시도입니다. 특히, 최근 연구에 따르면 자화상에서 유색 인종 남성이 비정상치(Outlier)로 선택될 가능성이 높다는 것을 강조하고 있습니다.

- **Technical Details**: 우리는 AD 알고리즘의 두 주요 범주, 즉 오토인코더(Autoencoder) 기반과 단일 클래스 기반 알고리즘에 대해 연구했습니다. 이 알고리즘들은 모든 인스턴스를 압축하려 시도하며 쉽게 압축되지 않는 인스턴스를 비정상치로 간주합니다. 연구를 통해, 그룹의 과소 대표(예: 유색 인종이 상대적으로 적음), 가짜 그룹 특징(예: 남성은 종종 모자를 쓰고 촬영됨), 그룹 레이블링 노이즈(예: 인종은 주관적임) 등의 불공정성 원인을 실험적으로 확인했습니다.

- **Performance Highlights**: 중요한 결과로, 압축 불가능성이 주요 원인이라 생각했으나, 실험 결과는 그렇지 않음을 보였으며, 자연스러운 계층 구조를 제시했습니다. 이는 AD 알고리즘의 불공정성 문제를 해결하는 데 중요한 통찰을 제공합니다.



### AgEval: A Benchmark for Zero-Shot and Few-Shot Plant Stress Phenotyping with Multimodal LLMs (https://arxiv.org/abs/2407.19617)
- **What's New**: 최근 농업에서 식물 스트레스 표현형 분석은 전문가 평가와 특수 모델에 의존해 확장성에 한계가 있었습니다. 멀티모달 대형 언어 모델 (Large Language Models, LLMs)의 최근 발전으로 이러한 문제를 해결할 가능성이 있습니다. 이번 연구에서는 12개의 다양한 식물 스트레스 표현형 분석 과제를 포함하는 AgEval 벤치마크를 제시했습니다.

- **Technical Details**: 이번 연구는 Claude, GPT, Gemini, LLaVA 등의 최신 모델을 활용하여 제로 샷(Zero-shot) 및 몇 샷(Few-shot) 인컨텍스트 학습 성능을 평가했습니다. 특히 Few-shot 학습에서 성능이 크게 향상되어, 최고 성능 모델에서 8-shot 식별을 통해 F1 점수가 46.24%에서 73.37%로 증가했습니다.

- **Performance Highlights**: Few-shot 예제는 데이터셋의 다른 클래스에서 가져온 경우 성능에 거의 또는 부정적인 영향을 미쳤지만 정확한 카테고리 예제가 있는 경우 성능이 15.38% 향상되었습니다. 또한 모델의 클래스별 일관성을 평가한 결과, 변동 계수(Coefficient of Variance, CV)가 모델들 간 26.02%에서 58.03% 범위로 나타나, 높은 신뢰성을 위해 '어려운' 클래스에 대한 주제 지식이 필요하다는 것을 발견했습니다. AgEval은 농업 애플리케이션에서 멀티모달 LLM의 기본 메트릭을 수립하고, 대규모 식물 스트레스 표현형 분석을 향상시킬 가능성을 제공합니다.



### Solving Short-Term Relocalization Problems In Monocular Keyframe Visual SLAM Using Spatial And Semantic Data (https://arxiv.org/abs/2407.19518)
Comments:
          8 pages, Keywords: VSLAM, Localization, Semantics. Presented in 2024 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)

- **What's New**: 이 논문은 단안 카메라 시스템(모노큘러 카메라 시스템)을 사용하는 모바일 로봇의 강력한 단기 재위치 측정 능력(short-term relocalization) 개발에 중점을 두고 있습니다. 새로운 다중 모드 키프레임 서술자(multimodal keyframe descriptor)를 도입했으며, 이 서술자는 환경에서 감지된 객체들의 의미정보(semantic information)와 카메라의 공간정보(spatial information)를 포함하고 있습니다. 이를 통해 새로운 키프레임 기반 위치 인식(Keyframe-based Place Recognition, KPR) 방식을 제안했습니다.

- **Technical Details**: 이 새로운 KPR 방식은 다단계 키프레임 필터링 알고리즘(multi-stage keyframe filtering algorithm)으로 구성되며, MKVSLAM 시스템을 위한 새로운 재위치 측정 파이프라인을 제공합니다. 키프레임 서술자는 환경에서 객체와의 상호작용과 카메라의 위치 데이터를 결합한 포괄적인 데이터 포인트를 제공합니다.

- **Performance Highlights**: 제안된 접근법은 여러 실내 GPS 차단 데이터셋(indoors GPS denied datasets)에 대해 평가되었으며, 단어의 가방 술어(bag-of-words approach)와 비교하여 정확한 자세 복구(pose recovery)를 달성함을 입증했습니다.



### EPD: Long-term Memory Extraction, Context-awared Planning and Multi-iteration Decision @ EgoPlan Challenge ICML 2024 (https://arxiv.org/abs/2407.19510)
- **What's New**: 이번 기술 보고서에서는 ICML 2024에서 열린 EgoPlan Challenge에 대한 솔루션을 소개합니다. 실제 egocentric(자기중심적인) 작업 계획 문제를 해결하기 위해 EPD라는 새로운 계획 프레임워크를 도입했습니다.

- **Technical Details**: EPD는 세 가지 단계로 구성됩니다: 장기 기억 추출(long-term memory Extraction), 문맥 인식 계획(context-aware Planning), 다중 반복 의사결정(multi-iteration Decision). 첫째, 추출 모델은 작업 목표, 작업 진행, 현재 관측을 바탕으로 진행 동영상에서 작업 관련 기억 정보를 추출합니다. 둘째, 계획 모델은 기억 정보의 문맥을 현재 관측에서 얻은 세분화된 시각 정보와 결합해 다음 행동을 예측합니다. 마지막으로 다중 반복 의사결정을 통해 의사결정 모델은 작업 상황과 현재 상태를 종합적으로 이해하여 가장 현실적인 계획 결정을 내립니다.

- **Performance Highlights**: EgoPlan-Test 세트에서 EPD는 1,584개의 자기중심적 작업 계획 질문에 대해 53.85%의 계획 정확도를 달성했습니다. 모든 코드는 제공된 링크에서 확인할 수 있습니다.



### Multi-task Neural Networks for Pain Intensity Estimation using Electrocardiogram and Demographic Factors (https://arxiv.org/abs/2407.19475)
- **What's New**: 이 논문에서는 고통(pain) 인식을 위한 새로운 다목적 신경망(multi-task neural network)을 제안합니다. 이 네트워크는 개인의 나이와 성별 정보를 활용하여 고통을 자동으로 추정하며, 다른 기존 접근 방식들과 비교하여 그 장점을 증명합니다.

- **Technical Details**: 연구에서는 심전도(electrocardiography) 신호를 사용하여 고통 인식의 여러 형태를 분석하며, 인구통계학적 정보에 따른 고통 인식의 변화를 밝혀냅니다. 제안된 다목적 신경망은 고통을 효과적으로 평가하고, 다양한 형태로 나타나는 고통을 객관적이고 즉각적으로 인식합니다.

- **Performance Highlights**: 제안된 방법은 기존 방법들에 비해 성능 면에서 우수한 결과를 보여주며, 신경망이 나이와 성별 정보를 동시에 활용함으로써 더 정확한 고통 추정이 가능하다는 장점이 있습니다.



### Reputation-Driven Asynchronous Federated Learning for Enhanced Trajectory Prediction with Blockchain (https://arxiv.org/abs/2407.19428)
- **What's New**: 이 논문에서는 자율 주행 응용 프로그램에서 안전한 데이터 공유를 위해 블록체인과 결합된 연합 학습(federated learning)을 소개합니다. 차량에서 생성되는 데이터의 정교함과 복잡성이 증가함에 따라 데이터 품질 감사의 부족이 궤적 예측(trajectory prediction) 작업에 대한 다중 당사자 불신을 야기시킵니다. 이를 해결하기 위해 이 논문은 해석 가능한 명성 양자화 메커니즘(reputation quantization mechanism)을 이용한 비동기 연합 학습 데이터 공유 방법을 제안합니다.

- **Technical Details**: 이 접근법은 그래프 신경망 도구(graph neural network)를 사용하여 데이터 제공자가 차등 개인정보 보호(differential privacy) 제약 아래 데이터 구조를 공유하도록 합니다. 또한, 깊이 강화 학습(deep reinforcement learning)을 구현하여 차량을 명성 수준에 따라 분류함으로써 연합 학습의 집계 효율성을 최적화합니다.

- **Performance Highlights**: 실험 결과에 따르면, 이 새로운 데이터 공유 방법은 궤적 예측 작업의 보안을 강화할 뿐만 아니라 예측 정확도도 향상시키는 것으로 나타났습니다.



New uploads on arXiv(cs.AI)

### Conditional LoRA Parameter Generation (https://arxiv.org/abs/2408.01415)
- **What's New**: 최근 몇 년간 생성 모델이 이미지, 비디오, 텍스트와 같은 다양한 분야에서 놀라운 성과를 거두었습니다. 이에 영감을 받아 연구자들은 신경망 파라미터를 생성하기 위해 생성 모델을 이용하는 방법을 탐구했으나, 파라미터 크기와 고성능 파라미터 생성의 실용성 문제로 어려움을 겪었습니다. 이번 논문에서 우리는 고성능 파라미터 생성을 현실적으로 가능하게 하는 새로운 접근 방식인 COND P-DIFF를 제안합니다. 특히, LoRA (Low-Rank Adaptation) 가중치의 미세 조정 과정에서 이를 시도하였습니다.

- **Technical Details**: 이 논문에서 사용된 주요 기술은 오토인코더와 조건부 잠재 확산 모델입니다(Conditional Latent Diffusion Model). 오토인코더는 파라미터의 효율적인 잠재 표현을 추출하는 용도로 사용되며, 조건부 잠재 확산 모델은 랜덤 노이즈로부터 특정 작업 조건에 따른 고성능 모델 파라미터를 합성합니다. 우리는 먼저 다양한 데이터세트에서 정상적인 최적화 방법(SGD)을 통해 최적화된 모델로부터 파라미터를 선택하고, 이를 오토인코더로 학습시켜 잠재 표현을 만듭니다. 이후 조건부 잠재 확산 모델을 통해 특정 작업 조건을 기준으로 이러한 잠재 표현을 재구성합니다. 최종적으로, 학습된 오토인코더의 디코더를 통해 새롭게 생성된 고성능 파라미터를 생성합니다.

- **Performance Highlights**: 실험 결과, COND P-DIFF는 컴퓨터 비전 및 자연어 처리 분야에서 안정적으로 고성능 파라미터를 생성하는 데 성공했습니다. 특히, 전통적인 최적화 방법으로 얻어진 파라미터와는 다른 분포를 보였으며, 이는 일반화 능력이 있음을 시사합니다. 이 연구는 조건 기반의 파라미터 생성의 가능성을 열어주며, 특정 작업에 맞춘 신경망의 적응을 위한 유망한 방향을 제시하고 있습니다.



### A Comprehensive Review of Multimodal Large Language Models: Performance and Challenges Across Different Tasks (https://arxiv.org/abs/2408.01319)
- **What's New**: 멀티모달 대형 언어 모델(Multimodal Large Language Models, MLLM)의 체계적 응용 분석이 제시되었습니다. 이 논문은 MLLM이 텍스트, 이미지, 비디오, 오디오 및 생리 데이터를 통합하여 단일 모달 시스템을 뛰어넘는 복합적인 실세계 애플리케이션에 대해 해결할 수 있는 능력을 강조합니다.

- **Technical Details**: MLLM은 다양한 데이터 유형(텍스트, 이미징, 비디오, 오디오, 생리학적 시퀀스)을 처리하고 통합하는 AI 시스템으로, 각 모달 데이터의 조화로운 상호작용을 통해 더 정밀하고 포괄적인 정보 생성을 가능하게 합니다. 주요 구성 요소로는 멀티모달 입력 인코더(multimodal input encoder), 특징 융합 메커니즘(feature fusion mechanism), 멀티모달 출력 디코더(multimodal output decoder)가 있습니다. 이 모델들은 embedding layers, Vision Transformers(ViT), Residual Networks(ResNet), C-Former, HuBERT, BEATs, Whisper 같은 최첨단 기술을 활용하여 데이터를 처리합니다.

- **Performance Highlights**: MLLM은 텍스트 생성, 기계 번역, 감성 분석 등의 자연어 처리(Natural Language Processing, NLP) 과제에서 뛰어난 성능을 보이며, 이미지 분류, 목표 탐지, 이미지 주석 등의 비전 과제에서도 큰 향상을 보였습니다. 특히, 비디오 처리와 오디오 분석에서도 멀티모달 정보 통합을 통해 정확성이 높아졌으며, 이는 가상현실, 비디오 게임, 교육 애플리케이션 등에서 커다란 활용 가능성을 제시합니다.



### TrIM: Triangular Input Movement Systolic Array for Convolutional Neural Networks -- Part I: Dataflow and Analytical Modelling (https://arxiv.org/abs/2408.01254)
Comments:
          This work has been submitted to the IEEE for possible publication

- **What's New**: 최근 AI 모델의 계산복잡도와 데이터 강도가 증가함에 따라 새로운 컴퓨팅 패러다임이 제안되고 있습니다. 이 논문은 CNN(Convolutional Neural Networks)의 데이터 병목 문제를 해결하기 위해 TrIM이라는 삼각형 입력 이동을 기반으로 한 새로운 데이터 흐름을 제안합니다. 이는 기존의 데이터 흐름들과 비교할 때 메모리 접근 횟수를 약 10배 줄이고, PEs (Processing Elements)의 겹치는 연산을 통해 높은 처리량을 가능하게 합니다.

- **Technical Details**: TrIM 데이터 흐름은 Systolic Arrays(SAs)에 적합하며, PEs가 입력 데이터를 삼각형 방식으로 이동시키면서 데이터를 계속 교환 및 처리합니다. TrIM은 기존의 무게 정지 (Weight Stationary) 및 행 정지 (Row Stationary) 데이터 흐름과 비교하여 메모리 접근을 최소화하고, 높은 데이터 활용도를 보장합니다. 이로 인해 메모리 접근 횟수를 약 10배 줄이고, 필요한 레지스터 수를 최대 15.6배 줄일 수 있습니다.

- **Performance Highlights**: TrIM 데이터 흐름은 높은 처리량을 보장하며, 최대 81.8%의 처리량 개선을 나타냅니다. 이는 기존의 행 정지 데이터 흐름 대비 매우 뛰어난 성능을 의미합니다. 또한, PEs의 마이크로 아키텍처가 단순하여 레지스터 수가 현저히 줄어들어, 에너지 효율성도 높아집니다.



### Metareasoning in uncertain environments: a meta-BAMDP framework (https://arxiv.org/abs/2408.01253)
- **What's New**: 이 논문은 일반적인 인간 메타추론 모델이 기저 MDP(마코프 결정 과정)의 전이와 보상 분포를 알고 있다고 가정하는 반면, 이러한 분포를 모르는 환경에서의 메타추론을 처리하기 위한 메타 베이스-적응형 MDP(meta-BAMDP) 프레임워크를 제안합니다. 이는 인간과 AI 시스템이 직면하는 보다 현실적인 계획 문제 집합을 포괄합니다.

- **Technical Details**: 메타추론(metareasoning)은 최적 성능을 달성하기 위해 적절한 추론 알고리즘(P*)을 선택하는 알고리즘(Pmeta)으로 정의됩니다. 본 논문은 미지의 보상/전이 분포가 있는 환경에서도 메타추론이 가능하도록 메타-BAMDP 프레임워크를 제시합니다. 이 모델은 기존의 베르누이 대기 확률 모델을 확장하고, 인간의 의사결정 과정을 연구하기 위해 두-루프 베르누이(TABB) 과제에 적용합니다.

- **Performance Highlights**: 비록 메타 문제의 복잡성 때문에 해결책은 근사적이지만, 인간의 의사결정 시나리오에 대해 현실적인 가정 하에서 견고합니다. 이 연구 결과는 인지적 제약 하에서 인간 탐사의 규범적 프레임워크를 제시하며, 불확실성과 자원 제약 하에서 계획하는 AI 시스템 설계에 실용적인 적용 가능성을 제공합니다.



### Rubric-based Learner Modelling via Noisy Gates Bayesian Networks for Computational Thinking Skills Assessmen (https://arxiv.org/abs/2408.01221)
- **What's New**: 현대 및 개인화된 교육에서 학습자의 능력을 개발하고 정확하게 평가하는 것이 점점 중요해지고 있습니다. 이번 연구에서는 자동 기술 평가를 위해 기존의 과제별 능력 루브릭(competence rubric)을 사용하여 학습자 모델을 도출하는 절차를 제안했습니다. 본 연구는 이전 접근 방식의 두 가지 주요 한계점을 극복하기 위해 설계되었습니다: (i) 평가 루브릭에 정의된 능력 간의 순서(ordering)가 간접적으로만 모델링되었다; (ii) 과제를 수행하는 데 필요한 추가 기술이 모델에 포함되지 않았습니다. 첫 번째 문제를 해결하기 위해, 우리는 네트워크 구조를 변경하지 않고도 기술 순서를 엄격히 적용하는 더미 관찰 노드(dummy observed nodes)를 도입했습니다.

- **Technical Details**: 두 번째 문제를 해결하기 위해, 두 층의 게이트(gates)를 사용하는 네트워크를 설계했습니다. 첫 번째 층은 noisy-OR 게이트로 논리적 OR 연산을 수행하고, 두 번째 층은 AND 연산을 통해 논리적 AND 연산을 수행합니다. 이러한 변화를 통해 모델 결과의 일관성과 유연성을 향상시키면서도 모델의 간결한 매개변수화, 해석 가능성 및 전문가의 관찰을 간단하게 유지할 수 있습니다.

- **Performance Highlights**: 해당 접근법을 사용하여 Computational Thinking (CT) 기술 평가를 위한 학습자 모델을 개발했습니다. CT-cube 기술 평가 프레임워크와 Cross Array Task (CAT)를 사용하여 이 모델의 타당성을 입증하고 실현 가능성을 시연했습니다.



### Multi-Objective Deep Reinforcement Learning for Optimisation in Autonomous Systems (https://arxiv.org/abs/2408.01188)
Comments:
          pages, Accepted to AI4AS 2024 workshop

- **What's New**: 이 논문은 자율 시스템(AS)에서 Deep W-Learning(DWN)을 사용하여 다중 목적 강화 학습(MORL) 기술을 실현한 첫 번째 연구입니다. DWN을 Emergent Web Servers(EWS) 자율 서버에 적용하여 실행 시간 성능을 최적화하는 최적의 설정을 찾아냈습니다. 이 연구는 전형적인 단일목적 최적화 기법(DQN, ε-greedy)과 비교하여 다중 목적을 동시에 최적화하는 DWN의 우수성을 입증합니다.

- **Technical Details**: DWN(Deep W-Learning)은 전통적인 다중 목적 테이블 RL 접근 방식인 W-learning을 신경망과 통합한 방법입니다. 이는 Deep Q-Learning(DQN)을 확장하여 여러 목적을 동시에 최적화할 수 있게 합니다. MDP(마르코프 결정 프로세스)를 기반으로 최적 정책을 찾기 위해 Q-값을 반복적으로 업데이트하는 Bellman 방정식을 사용합니다. DWN은 기존의 학습 벤치마크와는 다르게 실제 환경에 적용되었으며, EWS에서 최적의 서버 설정을 찾는 데 사용되었습니다.

- **Performance Highlights**: 초기 평가 결과, DWN은 평균 응답 시간에서 DQN과 ε-greedy 접근 방식에 비해 우수한 성능을 보였으며, 다만 비용 변동성 측면에서는 ε-greedy가 더 나은 성과를 보였습니다. 이 연구는 다중 목적을 위한 RL의 잠재력을 보여주며, 기존의 단일 목적 최적화 방법들이 처리하기 어려운 동적 환경과 우선순위 변화에 더 잘 적응할 수 있음을 입증합니다.



### Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition (https://arxiv.org/abs/2408.01139)
Comments:
          Accepted by Transactions on Machine Learning Research (TMLR 2024)

- **What's New**: 이 연구는 이미지 모델의 섭동강건성(Perturbation robustness)을 해석하기 위해 모델 독립적이고 전역적인 해석 방법을 제안합니다. 본 연구는 두 가지 주요 측면에 의해 동기 부여되었습니다. 첫째, 이전의 전역 해석 연구와 강건성 벤치마크(mean corruption error, mCE)는 이미지 모델 내의 섭동강건성 메커니즘을 직접적으로 해석할 수 있도록 설계되지 않았습니다. 둘째, 자연 이미지의 주파수에 따른 스펙트럼 신호 대 잡음 비율(SNR)이 지수적으로 감소하는 것을 관찰했습니다.

- **Technical Details**: 이 방법은 Shapley value 이론을 적용하여 정보 이론 프레임워크 내에서 강건(FRF) 기능과 비강건(NRF) 기능의 예측력을 계량적으로 평가합니다. I-ASIDE(Image Axiomatic Spectral Importance Decomposition Explanation)라고 명명된 이 방법은 모델의 강건성 메커니즘에 관한 독특한 통찰력을 제공합니다. empiri 연구에서, 주파수에 따른 스펙트럼 SNR이 power-law 형태의 분포를 보이는 것을 입증했습니다. 또한 저주파 신호는 일반적으로 고주파 신호보다 더 강건하지만, 저주파 신호만으로는 높은 분류 정확도를 달성할 수 없음을 알게 되었습니다.

- **Performance Highlights**: 광범위한 실험을 통해 I-ASIDE가 이미지넷(ImageNet)에 사전 학습된 다양한 비전 모델에서 섭동강건성을 측정하고 메커니즘에 대한 해석을 제공할 수 있음을 보여주었습니다. 특히, 저주파 신호로 훈련된 모델이 고주파 신호로 훈련된 모델보다 더 높은 강건성을 보인다.



### Being Accountable is Smart: Navigating the Technical and Regulatory Landscape of AI-based Services for Power Grid (https://arxiv.org/abs/2408.01121)
Comments:
          Author's version of the paper for International Conference on Information Technology for Social Good (GoodIT '24), September 4--6, 2024, Bremen, Germany. It is posted here for your personal use. Not for redistribution

- **What's New**: 최근 AI와 전력망 디지털화가 스마트 그리드(smart grid)에 다수의 효과적인 AI 기반 서비스 적용 시나리오를 제시했습니다. 그러나 이러한 주요 인프라에서 AI를 채택하는 데에는 규제의 불명확성과 리스크 정량화 기법의 부족이 걸림돌로 작용하고 있습니다. 본 논문은 에너지 부문의 AI 기반 서비스에서 책임성(accountability)의 중요성을 강조하며, 현재 AI법의 결함을 지적하고 이를 보완하기 위한 접근 방안을 제안합니다.

- **Technical Details**: 본 연구는 AI 기반 스마트 그리드 서비스에서 책임성을 정량화할 수 있는 정의를 도출하고, AI 서비스 생애주기의 여러 단계를 평가하여 관련 책임 리스크를 식별하는 기술적 접근 방안을 제시합니다. 또한, 다양한 연구를 참고하여 AI 서비스의 책임성 보장을 위한 법적 규제와 기술적 프레임워크의 필요성을 강조합니다.

- **Performance Highlights**: 유럽 위원회는 AI 통합을 착수하면서 2021년 AI법을 제안하고 2024년에 이를 채택하였으나, 도메인 별 구체적인 규제는 부재하여 해석의 여지를 남기고 있습니다. 본 논문은 AI 기반 스마트 그리드 서비스의 책임성을 보장하는 규제 프레임워크가 혁신을 방해하지 않으면서도 리스크를 제한할 수 있는 필요성과 그 접근 방안을 제공합니다.



### Dissecting Dissonance: Benchmarking Large Multimodal Models Against Self-Contradictory Instructions (https://arxiv.org/abs/2408.01091)
Comments:
          Accepted by the 18th European Conference on Computer Vision ECCV 2024

- **What's New**: 대규모 멀티모달 모델(LMMs)이 인간의 지시에 잘 따르지만, 멀티모달 상호작용과 맥락의 길이가 증가하면서 순간적으로 모순된 지시사항이 발생할 수 있습니다. 이를 해결하기 위해 Self-Contradictory Instructions 벤치마크를 도입했습니다. 이 벤치마크는 LMM이 모순된 명령을 인식할 수 있는 능력을 평가합니다.

- **Technical Details**: Self-Contradictory Instructions 벤치마크에는 언어와 비전(vision) 패러다임 간에 고르게 분포된 20,000개의 모순이 포함되어 있습니다. 이 데이터셋은 새로운 자동 데이터셋 생성 프레임워크에 의해 작성되었으며, 다양한 형식의 지시사항을 포괄할 수 있도록 가속화되었습니다. 우리의 종합적인 평가 결과에 따르면 현재의 LMMs은 자각(self-awareness)의 부족으로 멀티모달 지시 불일치를 일관되게 식별하는 데 어려움을 겪고 있습니다.

- **Performance Highlights**: 이 문제를 해결하기 위해 Cognitive Awakening Prompting(CAP)을 제안하여 외부에서 인식을 주입해 불일치 감지를 크게 개선했습니다. 데이터셋과 코드가 공개되어 있습니다.



### A Survey on Self-play Methods in Reinforcement Learning (https://arxiv.org/abs/2408.01072)
- **What's New**: 이 논문은 강화 학습(Reinforcement Learning, RL)에서 자가 플레이(Self-play)의 중요성과 역할을 체계적으로 설명하고 있습니다. 최근 들어 자가 플레이는 에이전트가 자신의 복사본 또는 과거 버전과 상호 작용하는 방식으로, 특히 다중 에이전트 강화 학습(MARL)과 기본적인 게임 이론 개념을 포함하여 그 역할이 부각되고 있습니다. 이 논문은 자가 플레이 관련 알고리즘을 통합된 프레임워크 내에서 분류하고, 다양한 시나리오에서 자가 플레이의 역할을 설명하면서 실용적 함의를 제공합니다. 또한 미래 연구 방향과 오픈 챌린지(Open Challenges)에 대해서도 논의합니다.

- **Technical Details**: 이 논문은 먼저 RL의 기본 프레임워크와 게임 이론의 기본 개념을 설명합니다. MDP(마코프 결정 과정)는 RL의 기본 모델로, 상태, 행동, 전이, 보상으로 환경을 설명합니다. MARL(다중 에이전트 강화 학습)은 다양한 에이전트가 상호 작용하는 복잡한 동역학을 포함하며, 자가 플레이는 이러한 MARL의 문제를 해결하는데 도움을 줍니다. 특히 부분 관찰 마코프 게임(POMGs, Partially Observable Markov Games)은 여럿의 에이전트 간에 완전한 상태 정보를 공유하지 않는 상황을 다룹니다.

- **Performance Highlights**: 자가 플레이는 Go, 체스, 포커, 비디오 게임 등의 다양한 시나리오에서 인간의 전문성을 넘어서는 전략을 개발하는 데 성공하였습니다. 그러나 자가 플레이는 최적의 전략으로 수렴하지 못하거나 상당한 계산 자원이 필요할 수 있다는 한계도 존재합니다.

- **Open Challenges**: 자가 플레이에서는 비정상성(non-stationarity), 조정(coordination), 균형 선택(equilibrium selection)과 같은 MARL의 주요 문제들을 해결하는데 여전히 어려움이 있으며, 이들 문제를 극복하기 위한 연구가 필요합니다. 추가적으로, 자가 플레이의 이론적 안전성, 알고리즘 프레임워크의 제한, 자가 플레이 관련 기존 연구들의 통합적 시각 제공에 대한 필요성 등이 논의되었습니다.



### From Stem to Stern: Contestability Along AI Value Chains (https://arxiv.org/abs/2408.01051)
Comments:
          5 pages, 0 figure, to be held as a workshop at CSCW'24

- **What's New**: 새로운 워크숍이 설계되었습니다. 이 워크숍은 인공지능(AI) 가치 사슬(value chain)에서 발생할 수 있는 다양한 논쟁 가능성(contestability)을 다루며, 이를 통해 연구 로드맵을 도출하여 향후 연구를 형성하고 영감을 주기 위한 것입니다.

- **Technical Details**: 이 워크숍은 가치 사슬의 다양한 부분에서 논쟁 가능성을 탐구합니다. 물질 추출에서 데이터 수집, 모델 개발, 인간 감시, 그리고 결과의 사회적 및 환경적 영향을 포함하여 다양한 단계에서의 AI 시스템 논쟁을 다룰 예정입니다. 또한, 참가자들의 발표와 토론을 통해 구체적이고 성공적이거나 실패한 AI 시스템의 사례를 공유할 예정입니다.

- **Performance Highlights**: 워크숍에서는 참가자들의 개별 발표와 그룹 활동을 통해 이론적이고 실험적인 연구 및 실제 사례를 다룹니다. 주요 목표는 요구 사항, 기존 지원, 다가오는 기회를 이해하여 향후 연구와 실습에 정보를 제공하는 것입니다. 워크숍 이후에는 공동으로 로드맵을 작성하여 AI 연구에 대한 비전을 제시할 예정입니다.



### Semantic Skill Grounding for Embodied Instruction-Following in Cross-Domain Environments (https://arxiv.org/abs/2408.01024)
- **What's New**: 이 논문은 체화된 지시 따르기(Embodied Instruction-Following, EIF)에서 사전 학습된 언어 모델(Language Models, LMs)을 사용하여 다양한 도메인에서 작업을 계획하는 데 중점을 둡니다. 이를 위해 SemGro라는 프레임워크를 제안하여 고차원적 의미를 지닌 기술을 하위 수준으로 점차 분해(decompose)하여 목표 도메인에서 실행 가능한 수준에 맞춥니다.

- **Technical Details**: SemGro는 의미 기술의 계층적 특성을 활용합니다. 짧은 시간 동안의 낮은 의미의 기술에서 긴 시간 동안의 높은 의미의 기술까지 다양한 기술을 식별합니다. 그리고 사전 학습된 기술을 목표 도메인에서 실행 가능하게 하기 위해 언어 모델의 추론 능력(reasoning capabilities)을 사용하여 기술을 분해합니다. 또한, 다중 모달 확장(multi-modal extension)을 통해 기술의 실행 가능성을 평가합니다.

- **Performance Highlights**: VirtualHome 벤치마크에서 300개의 크로스 도메인 시나리오에 대해 SemGro의 효능을 입증했습니다. SemGro는 이전의 최첨단 작업 계획 프레임워크 LLM-Planner 대비 작업 완료 성능에서 23.97% 더 뛰어났습니다.



### Piculet: Specialized Models-Guided Hallucination Decrease for MultiModal Large Language Models (https://arxiv.org/abs/2408.01003)
Comments:
          14 pages, 5 figures

- **What's New**: 우리는 멀티모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)에서 환각(hallucinations) 문제를 해결하는 새로운 방법인 Piculet을 제안합니다. 이 방법은 훈련이 필요 없으며, 다양한 전문 모델을 활용하여 시각 정보를 추출하고 이를 원본 이미지 및 쿼리와 함께 MLLMs에 입력함으로써 환각을 줄입니다.

- **Technical Details**: Piculet은 다중 전문 모델을 사용하여 입력 이미지에서 시각적 정보를 추출합니다. 그런 다음, 이 정보를 원본 이미지 및 쿼리와 결합하여 MLLMs에 입력으로 사용합니다. 이 과정은 MLLMs의 환각을 줄이기 위해 외부 지식을 활용합니다. 우리 방법은 훈련이 필요 없고, 다양한 MLLMs에 쉽게 적용할 수 있습니다.

- **Performance Highlights**: Piculet을 POPE, MME, LLaVA-QA90 데이터셋에서 정량적 및 정성적으로 평가한 결과, 환각 문제가 크게 줄어든 것을 확인했습니다. 예를 들어, LLaVA-QA90 벤치마크에서 기본 Qwen-VL-Chat의 정확도를 10점 만점에서 6.1에서 7.3까지 크게 개선했습니다.



### A Safe Exploration Strategy for Model-free Task Adaptation in Safety-constrained Grid Environments (https://arxiv.org/abs/2408.00997)
- **What's New**: 이 논문에서는 안전제약(safety-constrained)이 있는 환경에서 모델 프리 강화 학습(agent)이 환경을 탐색하는 새로운 프레임워크를 소개합니다. 이 프레임워크는 에이전트가 환경의 안전 제한 내에서 상호작용할 수 있도록 하기 위한 것입니다. 프레임워크는 프리 트레이닝 단계(pre-training phase)와 이 후 잠재적 안전하지 않은 상황을 예측할 수 있는 이진 분류 모델(binary classification model)을 포함합니다.

- **Technical Details**: 제안된 프레임워크는 먼저 에이전트가 통제된 환경에서 미리 훈련하는 단계를 갖습니다. 이 단계에서 에이전트는 환경의 동적인 특성을 배우고, 잠재적으로 위험한 상태를 인식할 수 있는 모델을 학습합니다. 그런 다음, 이 모델은 새로운 환경에서 안전하지 않은 상태를 예측하는 이진 분류기로 작동합니다. 안전하지 않은 상태가 예측되면, 에이전트는 사전에 정의된 안전 정책(safe policy)을 따라 행동하게 됩니다.

- **Performance Highlights**: 세 가지 무작위로 생성된 그리드 환경(grid environments)에서 프레임워크가 평가되었으며, 모델 프리 에이전트가 새로운 작업(task)과 환경에서 안전하게 적응하고 최적 정책을 학습할 수 있음을 보여주었습니다. 결과적으로, 적절한 안전 정책을 정의하고 안전하지 않은 상태를 탐지하기 위해 잘 훈련된 모델을 활용하면 모델 프리 에이전트가 안전 위반을 크게 줄이면서 새로운 환경에 적응할 수 있습니다.



### On the Resilience of Multi-Agent Systems with Malicious Agents (https://arxiv.org/abs/2408.00989)
Comments:
          10 pages

- **What's New**: 이 논문은 멀티 에이전트 시스템(multi-agent systems)의 탄력성(resilience)과 그에 대한 악의적 에이전트의 영향력을 조사합니다. 연구에서는 멀티 에이전트 시스템의 구조와 악의적 에이전트의 존재가 다양한 다운스트림 작업에 미치는 영향을 중점적으로 다룹니다. 새로운 악의적 에이전트를 시뮬레이션하기 위해 AutoTransform과 AutoInject라는 두 가지 방법을 도입했습니다.

- **Technical Details**: AutoTransform은 정상적인 에이전트를 악의적인 상태로 변환시키는 방법이며, 해당 에이전트의 기능적 무결성을 유지한 채 은밀하게 오류를 삽입합니다. AutoInject는 에이전트 간 통신 메시지에 직접 오류를 삽입하는 방식으로, 역시 자동화된 방식으로 작동합니다. 이 두 가지 방법은 매뉴얼 변경 없이 악의적 에이전트를 시스템에 도입하기 위한 도구입니다.

- **Performance Highlights**: 이 연구는 코드 생성, 수학 문제 해결, 번역, 텍스트 평가 등 네 가지 다운스트림 작업에서 멀티 에이전트 시스템의 성능을 테스트했습니다. 계층적(hierarchical) 구조의 멀티 에이전트 시스템이 가장 높은 탄력성을 보였으며, 퍼포먼스 저하율은 23.6%로 나타났습니다. 이는 Linear 구조(46.4%)나 Flat 구조(49.8%)보다 우수한 결과입니다. 또한, 각 에이전트의 메시지를 검토하고 수정하는 'Inspector' 에이전트나 수신한 메시지를 도전하는 'Challenger' 메커니즘 도입을 통해 시스템의 탄력성을 크게 향상시킬 수 있음을 입증했습니다.



### A SAT-based approach to rigorous verification of Bayesian networks (https://arxiv.org/abs/2408.00986)
Comments:
          Workshop on Explainable and Robust AI for Industry 4.0 & 5.0 (X-RAI) at European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (2024)

- **What's New**: 최근 기계학습의 발전으로 인해 다양한 실제 응용 분야에서의 사용이 가속화되고 있습니다. 하지만, 안전이 중요한 분야에서는 모델의 복잡성, 해석 불가능성, 그리고 행동에 대한 공식적인 보장이 없다는 점 때문에 배포에 어려움이 따릅니다. 이 논문에서는 이러한 단점을 해결하기 위해 Bayesian 네트워크를 위한 검증 프레임워크를 도입합니다. 특히, 두 가지 주요 검증 쿼리인 'if-then rules (ITR)'와 'feature monotonicity (FMO)'를 도입하여 다양한 속성을 검증합니다.

- **Technical Details**: 이 논문의 프레임워크는 두 가지 주요 구성 요소로 이루어져 있습니다. 첫 번째는 Bayesian 네트워크를 불 대수 리터럴로 변환하는 두 단계의 컴파일 및 인코딩 방식입니다. 두 번째는 이러한 리터럴을 활용하여 여러 속성을 제약 조건으로 인코딩한 공식 검증 쿼리를 수행하는 것입니다. 구체적으로, 이 프레임워크는 Multi-valued Decision Diagrams (MDDs)로 Bayesian 네트워크를 컴파일한 후 이를 Conjunctive Normal Form (CNF)으로 인코딩합니다. 이를 통해 모델의 확률적 표현을 보다 이해하기 쉽게 변환하고, 다양한 검증 쿼리를 개발할 수 있습니다.

- **Performance Highlights**: 제안된 검증 프레임워크는 실제 시나리오에서의 실용성을 보여주기 위해 벤치마크 테스트를 수행했습니다. Bayesian 네트워크의 형식을 불 대수로 정확하게 변환하고, SAT 형식을 이용하여 속성의 검증을 수행함으로써 높은 효율성과 정확성을 입증했습니다. 또한, 모델의 디버깅을 용이하게 하기 위해 증명 검색 방법을 사용하여 쿼리를 만족하지 않는 반례를 열거하는 기능도 도입했습니다.



### Integrating ESG and AI: A Comprehensive Responsible AI Assessment Framework (https://arxiv.org/abs/2408.00965)
Comments:
          23 pages, 8 tables, 10 figures

- **What's New**: 최근 인공지능(AI) 투자와 환경, 사회, 거버넌스(ESG) 요소들을 통합하기 위해 새롭게 개발된 ESG-AI 프레임워크를 소개합니다. 이 프레임워크는 28개의 회사와의 협력을 통해 개발되었으며, AI 사용 사례, AI 거버넌스 지표, RAI(Responsible AI) 심층 평가의 세 가지 주요 구성 요소로 구성되어 있습니다. 이 프레임워크와 도구 세트는 2024년 4월 공개되었고, 투자 커뮤니티로부터 긍정적인 반응을 얻었습니다.

- **Technical Details**: ESG-AI 프레임워크는 산업 실무자들과의 협력을 통해 개발되었으며, AI 애플리케이션의 환경 및 사회적 영향을 평가합니다. 투자자들이 기업의 책임 있는 AI 활용 여부를 평가할 수 있게 돕고, 특정 리스크 영역을 철저히 평가하는 구조화된 접근 방식을 제공합니다. 프레임워크와 도구는 주로 ESG 관리자와 AI 회사들을 지원하며, RAI 실천과 리스크 평가를 할 수 있도록 합니다. 주요 자료로는 RAI 질문 은행, RAI 메트릭 카탈로그, 호주 AI 윤리 원칙, EU AI 법안, NIST AI 리스크 관리 프레임워크, AI 표준(ISO/IEC 42001) 등이 포함됩니다.

- **Performance Highlights**: 이 프레임워크는 ESG와 AI의 통합을 통해 투자자들에게 실용적인 도구를 제공하고, AI 윤리 원칙을 실행 가능한 수준으로 운영화합니다. 또한 이 프레임워크와 함께 제공되는 RAI 메트릭 세트는 기업들이 성과 데이터를 투명하게 측정, 관리 및 공개할 것을 독려합니다. 이는 투자자들이 성과를 평가하고 모범 사례를 이해하는 데 어려움을 겪지 않도록 돕습니다.



### Generalisation of Total Uncertainty in AI: A Theoretical Study (https://arxiv.org/abs/2408.00946)
Comments:
          9 pages

- **What's New**: 이번 연구는 AI의 불확실성(Uncertainty)에 대한 새로운 정의를 제안하고, 불확실성을 더 잘 이해하고 관리하는 방법을 탐구합니다. 기존 연구와 최신 개발, 실제 응용 사례를 분석하여 AI에서 불확실성의 종합적인 개념을 제시합니다.

- **Technical Details**: AI에서 불확실성은 Aleatoric Uncertainty(통계적 불확실성)와 Epistemic Uncertainty(지식적 불확실성) 두 가지 형태로 나뉩니다. Aleatoric 불확실성은 데이터의 고유한 무작위성에서 비롯되며 감소되지 않는 반면, Epistemic 불확실성은 정보나 데이터의 부족에서 기인하며 추가적인 데이터 수집을 통해 줄일 수 있습니다. 이 논문은 다양한 불확실성 모델들(예: intervals(간격), random sets(무작위 집합), probability intervals(확률 간격), credal sets(신뢰 집합))을 소개하고, 특히 Epistemic 불확실성을 다룰 수 있는 모델들에 초점을 맞추고 있습니다.

- **Performance Highlights**: 논문에서 제안하는 새로운 불확실성 정의는 기존 방법들보다 더 효율적으로 불확실성을 측정하고 관리할 수 있습니다. 이로 인해 AI 시스템의 안정성 및 안전성을 향상시킬 수 있습니다. 특히, Bayesian methods, ensemble models, 그리고 conformal prediction 등 다양한 방법들을 통해 더 정확한 예측 결과를 도출할 수 있는 방법에 대해 탐구합니다.



### Granting GPT-4 License and Opportunity: Enhancing Accuracy and Confidence Estimation for Few-Shot Event Detection (https://arxiv.org/abs/2408.00914)
- **What's New**: 이번 연구에서는 GPT-4를 활용하여 이벤트 검출을 위한 신뢰도 추정 방식을 개선하는 방법을 탐구했습니다. 이를 위해 License to speculate and Opportunity to quantify and explain its uncertainty (L&O) 접근법을 도입했습니다. 이 방식은 기존의 복잡한 추가 계산 없이도 신뢰할 수 있는 신뢰도 추정을 제공합니다.

- **Technical Details**: 본 연구에서는 GPT-4를 사용하여 이벤트 검출(tasks of event detection)을 실시했으며, 이를 위해 BETTER ontology를 사용했습니다. L&O 방법은 모델이 불확실한 경우 추측하도록 하고, 불확실성을 정량화하고 설명할 수 있는 기회를 제공합니다. 이 방법은 GPT-4의 내부 통계를 사용하거나 추가적인 모델 튜닝 없이 하나의 쿼리로 출력과 신뢰도 추정을 얻는 것을 특징으로 합니다.

- **Performance Highlights**: L&O 접근법을 적용한 결과, 이벤트 검출의 정확도가 향상되었으며, usable confidence measures (0.759 AUC) 또한 제공되었습니다. 이는 추가적인 기계 장치 없이도 실용적인 성능을 달성했다는 점에서 주목할 만합니다.



### Online Detection of Anomalies in Temporal Knowledge Graphs with Interpretability (https://arxiv.org/abs/2408.00872)
Comments:
          15 pages, 8 figures. Accepted by SIGMOD 2025 Round 2

- **What's New**: AnoT라는 새로운 Temporal Knowledge Graph (TKG) 요약 방법이 도입되었습니다. 이 방법은 TKG 내의 이상 값을 해석 가능하게 온라인으로 탐지할 수 있도록 설계되었습니다. AnoT는 새로운 지식이 등장할 때 이를 규칙 그래프(rule graph)로 매핑하고, 이를 순회하면서 새로운 지식의 이상 점수를 도출합니다.

- **Technical Details**: AnoT는 TKG를 요약하여 새로운 유형의 규칙 그래프(rule graph)로 변환함으로써 복잡한 패턴을 유연하게 추론할 수 있게 합니다. 새로운 지식이 등장하면 이를 규칙 그래프 상의 노드로 매핑하고 순회하면서 이상 점수를 계산합니다. 이 과정에서 도달 가능한 노드는 새로운 지식의 유효성 또는 이상성을 판단할 수 있는 해석 가능한 증거를 제공합니다. AnoT는 감지기(detector), 업데이트기(updater), 모니터(monitor)라는 세 가지 주요 요소로 구성됩니다. 이 요소들은 각각 오프라인 TKG 요약 및 온라인 점수 매기기, 실시간 규칙 그래프 업데이트, 그리고 규칙 그래프의 근사 오차를 추정하는 역할을 합니다.

- **Performance Highlights**: 네 개의 실제 데이터셋 실험 결과, AnoT는 정확성과 상호 운용성(interoperability)에서 기존 방법을 상당히 뛰어넘는 성능을 보였습니다. 평균 11.5%의 AUC와 13.6%의 정밀도로 기존 방법보다 우수한 성과를 냈습니다.



### UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization (https://arxiv.org/abs/2408.00860)
- **What's New**: 새로운 모델 UlRe-NeRF를 소개합니다. 이 모델은 묵시적 신경 네트워크(implicit neural networks)와 명시적 초음파 볼륨 렌더링(explicit ultrasound volume rendering)을 결합한 초음파 신경 렌더링 아키텍처(ultrasound neural rendering architecture)입니다. 이 모델은 반사 방향 매개변수화(reflection direction parameterization)와 고조파 인코딩(harmonic encoding)을 사용하여 고주파 반사 강도 추정을 생성하고, 매질의 물리적 속성 파라미터를 출력합니다.

- **Technical Details**: 모델은 방향 MLP와 공간 MLP 모듈을 포함합니다. 방향 MLP 모듈은 시점 의존적인 고주파 반사 강도(view-dependent high-frequency reflection intensity)를 추정하고, 공간 MLP 모듈은 매질의 물리적 속성 파라미터를 생성합니다. 이러한 파라미터는 볼륨 렌더링(volume rendering) 과정에서 사용되어 초음파 파동의 매질 내 전파와 반사 행동을 정확하게 재현합니다.

- **Performance Highlights**: 실험 결과, UlRe-NeRF 모델은 특히 복잡한 매질 구조를 처리하는 데 있어 고충실도 초음파 이미지 재구성의 사실성과 정확성을 크게 향상시켰습니다.



### LICM: Effective and Efficient Long Interest Chain Modeling for News Recommendation (https://arxiv.org/abs/2408.00859)
- **What's New**: 뉴스 추천 시스템에서 사용자의 맞춤형 뉴스를 정확하게 추천하는 것은 항상 핵심적인 도전 과제였습니다. 최근의 노력은 주로 지역 하위 그래프 정보를 추출하는 데 집중했지만, 전반적인 글로벌 뉴스 그래프 추출의 부족은 비슷한 사용자 간에 글로벌 뉴스 정보를 협업적으로 활용하는 능력을 저해했습니다. 이러한 한계를 극복하기 위해, 우리는 유사한 사용자의 협업을 기반으로 글로벌 뉴스 클릭 그래프에서 추출한 장기 체인 관심(Long Interest Chain)을 이웃의 관심과 결합하여 뉴스 추천을 향상시키는 효과적이고 효율적인 방법인 Long Interest Chain Modeling for News Recommendation(LICM)을 제안합니다.

- **Technical Details**: LICM은 모든 사용자의 클릭 이력을 기반으로 한 글로벌 뉴스 그래프에서 장기 체인 관심을 생성하여 고차원 정보를 더 잘 활용할 수 있도록 설계되었습니다. 이를 위해, 우리는 종합적인 선택 메커니즘과 관심 인코더(interest encoder)를 설계하여 글로벌 그래프에서 장기 체인 관심을 얻습니다. 마지막으로, 게이트 네트워크(gated network)를 사용하여 장기 체인 정보를 이웃 정보와 통합하여 최종 사용자 표현을 달성합니다.

- **Performance Highlights**: 실세계 데이터 세트에 대한 실험 결과, 우리의 모델이 뉴스 추천의 성능을 향상시키는 데 있어 효과적이고 효율적임을 확인했습니다.



### Y Social: an LLM-powered Social Media Digital Twin (https://arxiv.org/abs/2408.00818)
Comments:
          29 pages, 5 figures

- **What's New**: 논문에서는 온라인 소셜 미디어 플랫폼을 복제하는 차세대 디지털 트윈 'Y'를 소개합니다. 디지털 트윈은 실제 시스템을 가상으로 복제하여 고급 분석과 실험을 가능하게 합니다. 특히 소셜 미디어의 경우, Y는 사용자의 상호작용, 콘텐츠 확산, 네트워크 동역학을 정확하게 시뮬레이션 할 수 있는 강력한 도구입니다.

- **Technical Details**: Y는 최신 Large Language Models(LLMs, 대규모 언어 모델)을 활용하여 정교한 에이전트 행동을 복제합니다. 이를 통해 사용자의 상호작용과 정보 확산을 정확하게 시뮬레이션할 수 있으며, 플랫폼 정책의 영향을 이해하는 데 중요한 통찰력을 제공합니다. LLMs의 통합으로 Y는 미묘한 텍스트 콘텐츠를 생성하고 사용자 반응을 예측할 수 있습니다.

- **Performance Highlights**: Y는 실제 사용자 행동을 모방하는 정교한 시뮬레이션을 제공하여 연구자들이 다양한 가설을 검증할 수 있도록 도와줍니다. 실제 데이터를 바탕으로 한 인비트로(in-vitro) 실험이 가능하며, 이는 복잡한 사회 시스템을 더 잘 이해하는 데 기여합니다.



### Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting (https://arxiv.org/abs/2408.01423)
Comments:
          8 pages,4 figures

- **What's New**: 이번 연구에서는 Natural Language Processing (NLP) 분야에서 사용되는 다양한 Prompt 디자인 전략에서 발생하는 한계를 극복하기 위해, Prompt Recursive Search (PRS) 프레임워크를 제안합니다. 이 프레임워크는 문제의 복잡성을 평가하고 이를 기반으로 구조를 조정하여 토큰을 효율적으로 사용하는 새로운 방법입니다.

- **Technical Details**: 현재 사용되는 주된 Prompt 디자인 방식은 두 가지입니다: Expert-Designed Prompts (EDPs)와 LLM-Derived Prompts (LDPs)입니다. EDPs는 전문가가 특정 데이터셋에 맞게 수동으로 설계하며, 일단 설계되면 변경할 수 없습니다. 반면, LDPs는 언어 모델이 자율적으로 생성하며, 특정 문제에 맞춰 솔루션을 제공하지만 복잡한 문제에서는 오류가 누적될 가능성이 있습니다. PRS 프레임워크는 언어 모델을 활용하여 문제에 맞는 솔루션을 생성하고 문제의 복잡성을 평가하여 구조를 조정합니다.

- **Performance Highlights**: Chain of Thought (CoT) 방식과 비교했을 때, PRS 방식은 BBH 데이터셋에서 Llama3-7B 모델을 사용하여 정확도를 8% 향상시켰으며, 22%의 개선을 달성했습니다. 다양한 도메인에서 다양한 파라미터를 가진 LLM을 사용한 광범위한 실험을 통해 PRS의 효능을 입증했습니다.



### Mission Impossible: A Statistical Perspective on Jailbreaking LLMs (https://arxiv.org/abs/2408.01420)
- **What's New**: 이 논문은 현재 LLMs의 문제점인 'jailbreaking' 현상을 통계적 관점에서 이론적으로 분석하여, 이를 해결하기 위한 새로운 접근법 E-RLHF를 제안합니다. E-RLHF는 추가적인 훈련 비용 없이 안전한 응답을 유도하며, 다른 방법들과 호환 가능합니다.

- **Technical Details**: 이 논문은 LLMs가 'pretraining' 중에 유해한 행위를 학습할 가능성이 높음을 통계적 프레임워크 하에서 보여줍니다. 이를 바탕으로, RLHF(Reinforcement Learning from Human Feedback) 목표의 단점을 지적하고, 순수함 (harmlessness)과 유용성 (helpfulness) 사이의 차이를 해결하는 E-RLHF 목표를 제안합니다. E-RLHF는 전달된 동작(prompt)을 분리하여 공격자의 강도를 정량화하고, 안전한 응답의 분포를 유지합니다.

- **Performance Highlights**: Empirical 실험 결과에 따르면, E-RLHF는 AdvBench 및 HarmBench 프로젝트에서 제시된 모든 alignment 문제에서 RLHF보다 우수한 성능을 보였습니다. 또한, MT-Bench 프로젝트에서 측정한 모델 성능을 희생시키지 않고도 개선된 안전성을 제공합니다.



### Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs (https://arxiv.org/abs/2408.01417)
Comments:
          Accepted to COLM 2024

- **What's New**: 최신 연구에서는 인간이 시간 경과에 따라 상호작용 중에 효율적인 언어를 점차 사용하게 됨을 밝혀냈습니다. 이러한 현상을 연구하기 위해 ICCA라는 프레임워크를 도입하여 다중모달 대형 언어 모델(MMLMs)이 유사하게 행동하는지 평가했습니다. 연구 결과, MMLMs는 상대방의 효율적인 언어를 이해할 수 있지만 자신들이 자발적으로 언어를 더 효율적으로 만들지는 않는다는 것이 드러났습니다.

- **Technical Details**: 연구진은 ICCA라는 자동화된 프레임워크를 사용하여, 다중모달 언어 모델들의 대화 적응(in-context behavior)을 평가했습니다. 여러 최신 MMLMs 모델들을 테스트한 결과, 일부 모델만이 GPT-4와 같은 강력한 프롬프팅(prompting)을 통해 자신의 언어를 효율적으로 변화시키는 능력을 보였습니다. 이는 인간 언어의 일반적인 특징이지만, 현재의 모델 훈련 체계에서는 이러한 능력이 자연스럽게 나타나지 않는다는 것을 보여줍니다.

- **Performance Highlights**: 몇몇 모델에서는 강력한 프롬프팅(prompting)으로 이러한 효율적인 언어 사용 능력을 이끌어낼 수 있었으나, 대부분의 모델에서는 자발적인 효율성 증가는 관찰되지 않았습니다. 특히 GPT-4 모델이 이에 해당하며, 이는 특정한 훈련 방식 없이는 자연적으로 발생하지 않는다는 점을 강조합니다.



### The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability (https://arxiv.org/abs/2408.01416)
- **What's New**: 이번 연구에서는 신경망(Neural Networks)의 해석 가능성(interpretability)을 인과 매개 분석(causal mediation analysis)에 기반해 체계화하는 새로운 관점을 제안합니다. 기존 연구들이 이론적 기초 공유 없이 임의의 평가를 사용해왔기 때문에, 본 연구는 이를 통일성 있게 정리하고, 인과적 단위(causal units)를 명확히 정의하여 연구의 진전 측정과 기법 비교를 용이하게 합니다.

- **Technical Details**: 이 논문은 신경망의 인과 해석가능성을 인과 그래프(causal graphs)와 매개변수(mediators)의 관점에서 논의합니다. Lewis(1973, 1986)와 Pearl(2000)의 연구를 기초로 하여, 본 논문은 인과 매개 분석 프레임워크를 활용해 신경망의 중간 계산이 모델 출력에 어떻게 영향을 미치는지 설명합니다. 인과 메커니즘 이해를 위해 매개변수 탐색 기법을 분류하고 분석합니다.

- **Performance Highlights**: 각 매개변수의 장단점을 비교 분석하여, 연구 목표에 따라 가장 적절한 매개변수와 탐색 방법을 추천합니다. 또한, 새로운 매개변수를 발견하고, 인과 단위간의 비교를 위한 표준화된 평가 방법을 제안하여, 연구자들이 신경망의 복잡한 추상화를 보다 잘 이해할 수 있도록 돕습니다.



### Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer (https://arxiv.org/abs/2408.01402)
Comments:
          2 figures, 8 tables. Accepted by the Training Agents with Foundation Models Workshop at RLC 2024

- **What's New**: 새로운 연구에서는 사전 학습된 언어 모델을 활용한 Language model-initialized Prompt Decision Transformer (LPDT)을 소개합니다. 이 접근법은 pre-trained 언어 모델을 초기화하여 meta-RL 작업에서 성능을 향상시키며 Low-rank Adaptation (LoRA)을 사용하여 모델을 정교하게 조정합니다. 또한, 프롬프트 규제(predict regularization)를 적용하여 다양한 작업 간 차이를 효과적으로 인식할 수 있게 합니다.

- **Technical Details**: LPDT는 사전 학습된 언어 모델을 이용해 초기화된 Prompt Decision Transformer(Prompt-DT)를 활용합니다. LoRA를 통해 데이터 효율적인 방식으로 사전 학습된 모델을 다량의 RL 작업 데이터셋으로 미세 조정합니다. 프롬프트 규제 방법은 주어진 프롬프트 정보에 따라 다양한 테스트 환경을 구분할 수 있도록 설계되었습니다. 이 연구는 또한 MuJoCo 제어 환경 및 Meta World ML1 작업에서 LPDT의 성능을 입증하기 위한 광범위한 실험을 수행했습니다.

- **Performance Highlights**: LPDT는 제안된 기법들을 통해 다양한 실험 환경에서 기존 모델들을 능가하는 성능을 보였습니다. 특히, 제한된 데이터셋 환경에서 LPDT는 더 나은 누적 보상(cumulative rewards)을 달성하여 실제 응용 가능성을 강조했습니다.



### PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieva (https://arxiv.org/abs/2408.01349)
Comments:
          Accepted by ACM MM 2024

- **What's New**: 연구자들은 PC$^2$ (Pseudo-Classification based Pseudo-Captioning)라는 새로운 프레임워크를 제안했습니다. 이 모델은 이미지-텍스트 간의 의미적 유사성을 비대조적(non-contrastive) 메커니즘을 통해 학습하고, 잘못된 대응쌍을 더 많은 정보를 제공하는 가짜 캡션(pseudo-captions)을 생성하여 교정합니다. 또한, 새로운 노이즈 데이터셋인 'Noise of Web (NoW)'도 개발되었습니다.

- **Technical Details**: PC$^2$ 프레임워크는 세 가지 주요 전략으로 구성됩니다. 첫째, 캡션을 범주형 레이블로 해석하여 비대조적 학습을 통한 '가짜 분류(pseudo-classification)' 보조 작업을 수행합니다. 둘째, 가짜 캡션을 생성하여 잘못된 대응쌍에도 유익한 감독 정보(supervision)를 제공합니다. 셋째, 가짜 분류기의 예측 변동성을 이용하여 대응쌍의 교정을 돕습니다. 이를 위해 크로스 엔트로피 손실(cross-entropy loss)과 반대쪽(simplicity) 최적화 목표를 사용합니다.

- **Performance Highlights**: PC$^2$ 프레임워크는 기존의 최첨단 크로스 모달 검색 방법과 비교하여 시뮬레이션된 데이터셋과 현실적인 데이터셋 모두에서 놀라운 성능 향상을 보였습니다. 특히, 다양한 NCL (Noisy Correspondence Learning) 환경에서 더 나은 성능을 발휘했습니다. 또한, 새로운 데이터셋인 NoW를 도입하여 이후의 NCL 평가를 위한 강력한 기준을 제공했습니다.



### StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal Semantic Segmentation (https://arxiv.org/abs/2408.01343)
- **What's New**: 논문은 복잡한 장면에서의 세그멘테이션 정확도를 높이기 위해 'StitchFusion'이라는 새로운 멀티모달(seamantic segmentation) 기반의 기능 융합 프레임워크를 제안합니다. 이 시스템은 대규모 사전 학습된 모델을 인코더 및 기능 융합기로 직접 통합합니다. 인코딩 중 여러 모달 시각 정보를 공유함으로써 모달 통합을 구현하고, MultiAdapter라는 다중 방향 어댑터 모듈을 소개하여 인코딩 중 정보 교환을 가능하게 합니다.

- **Technical Details**: StitchFusion은 사전 학습된 대규모 모델을 인코딩 및 피쳐 융합기에 통합하여 모달 융합을 수행하는 프레임워크입니다. MultiAdapter라는 다중 방향 어댑터 모듈을 제안하여 모달 간 정보 전송을 가능하게 합니다. 이를 통해 인코딩 중에 멀티모달 시각 정보 통합을 실현하며, 적은 수의 추가 매개변수로 크로스 모달 융합을 달성합니다.

- **Performance Highlights**: 네 가지 멀티모달 세그멘테이션 데이터셋에서 광범위한 비교 실험을 통해 StitchFusion 모델은 기존 최첨단 성능을 달성했으며, 추가 매개변수가 최소화되었습니다. 또한, MultiAdapter가 기존 Feature Fusion Modules(FFMs)와 결합될 때 상보성이 강조되었습니다.



### Leveraging Knowledge Graph Embedding for Effective Conversational Recommendation (https://arxiv.org/abs/2408.01342)
Comments:
          26pages, 15figures

- **What's New**: 최근 증가하는 관심을 받고 있는 대화형 추천 시스템(CRS)은 대화 시스템 및 추천 시스템 기술을 통합하여 사용자의 선호를 더 잘 학습하고 추천 성능을 향상시킵니다. 본 논문에서는 기존의 CRS 연구들이 속성, 사용자 및 항목 간의 관계를 효과적으로 다루지 못하는 문제를 지적하고, 이를 개선하기 위해 지식 그래프 기반 대화형 추천 시스템(KG-CRS)을 제안합니다.

- **Technical Details**: KG-CRS에서는 사용자-아이템 그래프(user-item graph)와 아이템-속성 그래프(item-attribute graph)를 동적 그래프로 통합하며, 대화 과정에서 부정적 항목이나 속성을 제거하여 동적으로 변화합니다. 이러한 그래프에서 이웃을 통한 전파를 고려하여 사용자, 아이템 및 속성의 유용한 임베딩(embedding)을 학습합니다.

- **Performance Highlights**: 세 가지 실제 데이터 세트에서 광범위한 실험을 통해 추천 및 대화 작업 모두에서 최신 기법(state-of-the-art approaches)을 능가하는 것이 검증되었습니다.



### A Backbone for Long-Horizon Robot Task Understanding (https://arxiv.org/abs/2408.01334)
Comments:
          8 pages, 8 figures. This work is intended to be submitted to IEEE Robotics and Automation Letters (RA-L) for possible publication

- **What's New**: 테스크 이해와 전이 가능성을 향상시키기 위해 새로운 Therblig-based Backbone Framework (TBBF)을 제안합니다. 이 프레임워크는 therbligs (기본 액션 요소)를 사용하여 로봇 작업을 세분화하고, 이를 현재의 foundation models와 결합하여 작업 이해를 개선합니다.

- **Technical Details**: TBBF는 두 단계로 나눠집니다: 오프라인 학습 단계와 온라인 테스트 단계입니다. MGSF 네트워크를 사용하여 다양한 작업에서 therblig 분할을 정확하게 수행합니다. ActionREG는 이미지에 고급 지식을 인코딩하고, LAP-VC는 시각적 교정을 통해 작업 실행의 정확성을 보장합니다.

- **Performance Highlights**: 실험 결과, therblig 분할에서 94.37%의 리콜과 간단한 시나리오에서 94.4%, 복잡한 시나리오에서 80%의 성공률을 달성했습니다.



### A Robotics-Inspired Scanpath Model Reveals the Importance of Uncertainty and Semantic Object Cues for Gaze Guidance in Dynamic Scenes (https://arxiv.org/abs/2408.01322)
Comments:
          35+16 pages, 8+4 figures

- **What's New**: 본 논문은 동적 실제 장면들에 대한 인간의 시선 추적 행동과 객체 분할을 상호 의존적인 과정으로 취급하는 기계적 모델을 제시합니다. 이 모델은 현재 장면의 분할을 통해 객체 기반의 각기 이동 결정을 내리면서 중심화된(foveated) 객체를 재귀적으로 장면 분할을 정제하는 방식으로 작동합니다. 이는 로보틱스에서 정보 처리 패턴을 차용하여 구현되었습니다.

- **Technical Details**: 제안된 모델은 베이지안 필터(Bayesian filter)를 사용하여 장면 분할의 불확실성을 추정하고 이는 능동적 장면 탐색을 유도하는데 사용됩니다. 모델은 시선 선택과 장면의 분할이 불확실성에 의해 적극적 상호 연결되도록 하며, 고해상도 의미론적 분할을 통해 각기 위치에서 객체 정보를 최신으로 업데이트합니다. 이는 '반복 억제(inhibition of return)' 메커니즘 없이 인간의 자연스런 시각 탐사를 재현합니다.

- **Performance Highlights**: 모델의 성능은 시선 경로 통계(scanpath statistics)와 같은 고차원 통계를 사용하여 인간의 자유 시각 행동을 밀접하게 모방합니다. 광범위한 시뮬레이션과 초반 테스트는 불확실성이 탐색의 균형을 촉진하고 의미론적 객체 단서가 객체 기반 주의(attention)에서 중요한 역할을 한다는 것을 보여줍니다. 추가적으로 사카디 모멘텀(saccadic momentum)이나 사카드 이전 주의(pre-saccadic attention)를 포함할 수 있는 모듈 설계를 갖추고 있어 인간의 시각 경로와 더욱 일치되도록 확장이 가능합니다.



### Synergistic pathways of modulation enable robust task packing within neural dynamics (https://arxiv.org/abs/2408.01316)
Comments:
          24 pages, 6 figures

- **What's New**: 이 논문은 반향 신경망 모델(recurrent neural network models, RNNs)을 사용하여 신경 역동성의 두 가지 맥락적 조절 형태를 탐구하며, 이들은 뉴런의 흥분성 수준과 시냅스 강도 수준에서 나타난다고 설명합니다. 이 연구는 각 조절 메커니즘이 다중 작업 학습 환경에서 어떻게 작용하는지에 대한 공통성과 시너지를 규명합니다.

- **Technical Details**: 개발된 모델은 뉴런의 상태를 나타내는 벡터와 비선형 활성화 함수인 tanh(𝑥)를 사용합니다. 외부 입력은 피드포워드 이득(𝐁)을 통해 주어지며, 기본적인 시냅스 연결(𝐉)을 포함합니다. 첫 번째 메커니즘은 뉴런의 흥분성을 조절하는 추가 입력(β⁢𝐃⁢𝐮𝑐)이며, 두 번째는 시냅스 가중치에서 발생하는 저차수 조절 행렬(𝐇⁢diag⁢(𝐮𝑐)⁢𝐇⊤)을 사용합니다. 이 두 가지 메커니즘 모두 다중 작업 학습에서 맥락적 모호성에 대한 강인성과 네트워크 크기 효율성을 분석합니다.

- **Performance Highlights**: 연구 결과, 뉴런의 흥분성 조절과 시냅스 강도 조절이 각기 다른 동역학을 유도하며, 이들은 다중 작업 학습에서 상호 보완적이고 시너지를 일으킬 수 있음을 보여줍니다. 이러한 차별화된 메커니즘들은 다중 시간 척도에 걸쳐 작용하여 다중 작업 학습의 강인성을 향상시키는 데 중요한 역할을 할 수 있음을 시사합니다.



### A Decision-driven Methodology for Designing Uncertainty-aware AI Self-Assessmen (https://arxiv.org/abs/2408.01301)
- **What's New**: 이 논문에서는 AI 시스템의 투명성, 견고성(Robustness), 신뢰성을 높이기 위한 다양한 도구와 기법을 제시하고 있습니다. 특히, AI 예측의 불확실성을 정량화하고 AI 스스로의 예측 신뢰성을 '자가 평가(Self-assessment)'하는 방법을 다룹니다. 이를 통해 의사 결정자가 AI 예측의 신뢰성을 더 잘 이해하도록 돕습니다.

- **Technical Details**: 이 논문의 핵심은 불확실성 인식 자가 평가(Uncertainty-aware self-assessment) 기법을 통해 AI 예측의 신뢰성을 판단하고자 하는 것입니다. 자가 평가 방법은 AI의 예측 정확도와 관련된 불확실성을 정량화함으로써 의사 결정자가 AI 예측의 신뢰도를 평가할 수 있습니다. 이는 최적의 의사 결정 정책을 설계하는 데 큰 도움이 됩니다. 또한, 다양한 자가 평가 기법을 문헌 조사 로 포괄적으로 분류하고 있습니다.

- **Performance Highlights**: 논문은 두 개의 현실적인 국가 관심 시나리오에서 자가 평가 기법의 유용성을 입증합니다. 또한 머신러닝 엔지니어와 AI 시스템 사용자를 위한 실질적인 지침을 제공하여 문제에 적합한 자가 평가 기법을 선택하고 설계할 수 있도록 돕고 있습니다. 이를 통해 실제 응용 프로그램에서의 AI 예측 신뢰성을 크게 향상시킬 수 있습니다.



### 3DPX: Progressive 2D-to-3D Oral Image Reconstruction with Hybrid MLP-CNN Networks (https://arxiv.org/abs/2408.01292)
Comments:
          accepted by MICCAI 2024

- **What's New**: 최근 연구에서 2D 파노라마 X-레이(Panoramic X-ray, PX) 영상에서 직접 3D 구조를 재구성하는 방법론인 3DPX를 제안했습니다. 3DPX는 다층 퍼셉트론(MLP)과 컨볼루션 신경망(CNN)을 결합하여 점진적으로 3D 이미지를 재구성하는 새로운 네트워크입니다.

- **Technical Details**: 3DPX는 프로그래시브 하이브리드 MLP-CNN 피라미드 네트워크로, 단계별 재구성을 통해 중간 결과물에 지침을 부여합니다. MLP의 장점을 활용하여 장거리 의존성(Fine-grained long-range dependency)을 캡처하고, CNN을 통해 이웃 픽셀 정보를 효과적으로 사용합니다. 이는 전정맥(CNNs)의 기존 한계를 극복하는 방법입니다.

- **Performance Highlights**: 464개의 연구를 포함하는 두 개의 대규모 데이터셋에서 실험한 결과, 3DPX는 기존 최첨단 2D-to-3D 구강 재구성 방법들보다 더 우수한 재구성 품질을 보여줬습니다. 또한, 치아의 각도 비정렬 감지 및 분류 작업에서도 성능 향상을 보였습니다.



### The virtual CAT: A tool for algorithmic thinking assessment in Swiss compulsory education (https://arxiv.org/abs/2408.01263)
- **What's New**: 디지털 시대에서 알고리즘적 사고(Algorithmic Thinking, AT) 능력은 컴퓨터 과학 분야를 넘어 매우 중요한 스킬로 여겨집니다. 이 논문은 스위스 의무 교육 과정에서 AT 평가를 위한 디지털 도구인 가상 Cross Array Task (CAT)를 소개합니다. 이 도구는 제스처 기반 인터페이스와 비주얼 블록 기반 프로그램 인터페이스를 특징으로 하여 다양한 학습자들이 사용할 수 있으며, 다국어 지원 기능을 갖추고 있습니다.

- **Technical Details**: 가상 CAT 플랫폼의 디자인 과정은 세 가지 사용자 경험(UX) 설계 생명주기로 구성됩니다. 첫 번째 단계에서는 목표 설정 및 툴 요구사항 정의가 이루어지며, 두 번째 단계에서는 UX 검사자의 피드백을 통해 초기 프로토타입의 사용성을 개선합니다. 마지막으로 아동을 참여자로 포함하여 그들의 요구와 선호를 설계에 반영합니다. CAT는 색깔이 있는 교차형 배열을 사용하여 학생들이 복잡한 패턴을 재현하는 알고리즘을 작성하고, 이를 에이전트에 전달하여 실행하는 활동입니다.

- **Performance Highlights**: 스위스에서 다양한 배경을 가진 학생들을 대상으로 한 초기 평가 결과, 가상 CAT 플랫폼은 다양한 연령, 개발 단계 및 교육 배경을 가진 학생들의 AT 능력을 평가하는 데 적합한 것으로 나타났습니다.



### Detection and Characterization of Coordinated Online Behavior: A Survey (https://arxiv.org/abs/2408.01257)
- **What's New**: 이 논문은 온라인 상에서의 조정된 행동(coordinated behavior)에 대한 기존 연구들을 체계적으로 수집, 분류, 비판적으로 논의한 서베이(survey)입니다. 연구자들은 산업계와 학계의 정의를 일치시키고, 조정된 온라인 행동을 연구하기 위한 포괄적인 프레임워크를 제안합니다. 이에 따라 기존의 탐지 및 특성화 방법들을 검토하고 비판적으로 논의합니다.

- **Technical Details**: 조정된 행동은 여러 연결된 행위자들이 목표를 추구하는 과정입니다. 이 연구는 기존의 여러 정의들을 분석하고, 행위자, 활동, 목표라는 세 가지 기본 구성요소를 명확히 정의하며 필수 요소로 사용합니다. 설문 조사에서는 2014년에서 2024년 사이에 출판된 84편의 논문을 포함하고 있으며, Google Scholar 및 Scopus에서 'behavior', 'coordinated', 'inauthentic', 'collaborative' 등의 용어를 사용해 논문을 식별했습니다.

- **Performance Highlights**: 이 논문은 조정된 온라인 행동의 이해와 탐지, 특성화에 관한 주요 도전과 유망한 연구 방향을 식별합니다. 또한 학계와 산업계 전문가들이 디지털 공간에서 발생하는 조정된 행동의 복잡성을 이해하고 대응하는 데 유용한 안내서 역할을 합니다.



### Deep progressive reinforcement learning-based flexible resource scheduling framework for IRS and UAV-assisted MEC system (https://arxiv.org/abs/2408.01248)
Comments:
          13 pages, 10 figures

- **What's New**: 이 논문에서는 지능형 반사 표면(IRS)과 무인 항공기(UAV) 지원 모바일 엣지 컴퓨팅(MEC) 시스템을 최적화하기 위한 FRES (Flexible REsource Scheduling) 프레임워크를 제안합니다. 이 시스템은 특히 임시 및 긴급 상황에서 에너지 소비를 최소화하기 위해 설계되었습니다. UAV 위치, IRS 페이즈 시프트, 업무 오프로딩(task offloading), 자원 할당을 최적화하여 가변적인 UAV 수를 처리합니다.

- **Technical Details**: FRES 프레임워크는 딥 프로그레시브 강화 학습(deep progressive reinforcement learning)을 활용합니다. 여기에는 두 가지 주요 혁신이 포함됩니다. 첫째, 멀티태스크 에이전트(multi-task agent)는 혼합 정수 비선형 프로그래밍(MINLP) 문제를 처리하도록 설계되었습니다. 이것은 정수 변수로 오프로딩 결정을 하는 분류 헤드와 연속 변수로 자원 할당을 해결하는 적합 헤드로 구성되어 있습니다. 둘째, Progressive 스케줄러는 에이전트를 조정하여 UAV 수의 변동에 적응하고, 경험을 축적하며 'catastrophic forgetting' 문제를 방지합니다.

- **Performance Highlights**: 경량 탐색 탭(Light Taboo Search, LTS)을 도입하여 FRES의 글로벌 탐색 능력을 향상시켰습니다. 수치 결과는 FRES 프레임워크가 동적 MEC 시스템에서도 실시간 최적 자원 스케줄링을 제공할 수 있음을 보여줍니다. 이는 통신 환경의 변화에 민감하게 반응하며 에너지를 효율적으로 사용할 수 있음을 의미합니다.



### Tailoring Graph Neural Network-based Flow-guided Localization to Individual Bloodstreams and Activities (https://arxiv.org/abs/2408.01239)
Comments:
          7 pages, 9 figures, 2 tables, 16 references, accepted at ACM NanoCom'25

- **What's New**: 이 논문은 기존의 그래프 신경망(GNN: Graph Neural Network)을 이용한 혈류 유도 위치 추적 방법을 개선하여, 개별 환자의 생리적 지표(키, 몸무게, 심박수)를 기반으로 GNN을 적응시키는 새로운 파이프라인을 제안합니다. 이 방법은 환자의 활동에 따른 변화와 개별 혈류의 신체적 다양성을 반영할 수 있어 기존 방법의 한계를 극복합니다.

- **Technical Details**: 제안된 방법은 기존 GNN 모델에 마스터 노드(master node)를 추가하여 신체 형태와 심박수 정보를 포함합니다. 입력 그래프 설계의 엣지 가중치(edge weights)를 개선하여 나노디바이스가 혈류를 통해 특정 지역을 방문할 확률을 포함시킵니다. 이러한 확장된 모델을 이용하여 9개의 개별 프로파일을 정의하고, 프로파일 적응이 위치 추적 정확도에 미치는 영향을 평가했습니다.

- **Performance Highlights**: 제안된 GNN 기반 혈류 유도 위치 추적 방법은 대부분의 신체 타입과 활동 수준에서 성능 향상을 보였습니다. 이러한 결과는 개별 환자의 혈류와 활동 반영을 통해 기존의 정지 상태 환자를 기준으로 한 모델보다 더 높은 적응성을 가지는 모델의 잠재력을 시사합니다.



### High-Throughput Phenotyping of Clinical Text Using Large Language Models (https://arxiv.org/abs/2408.01214)
Comments:
          Submitted to IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), Houston TX

- **What's New**: 이번 연구는 Online Mendelian Inheritance in Man (OMIM) 데이터베이스의 임상 요약을 활용한 고속 표현형 분석(High-throughput phenotyping) 자동화를 평가했습니다. GPT-4와 GPT-3.5-Turbo 모델을 비교한 결과 GPT-4가 더 뛰어난 성능을 보였으며, 수동 해설자와의 합의도가 높은 것으로 나타났습니다.

- **Technical Details**: 텍스트 추출 및 전처리 작업에서 OMIM API를 이용해 임상 요약을 읽고 추출했습니다. OpenAI API를 통해 전처리된 텍스트에서 신경학적 징후를 식별했습니다. 이후 GPT-4 모델을 사용해 HPO(Human Phenotype Ontology) 용어와 ID로 매핑하였습니다. 마지막으로 카테고리 이진화 및 질병 벡터화를 수행했습니다.

- **Performance Highlights**: GPT-4는 징후 식별, 분류 및 정상화 작업에서 GPT-3.5-Turbo를 능가했습니다. 수동 해설자와 유사한 수준의 합의도를 이루었으며, 추가적인 수동 주석 데이터가 필요하지 않다는 점에서 일반화 가능성이 높음을 보여주었습니다.



### Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning (https://arxiv.org/abs/2408.01187)
Comments:
          Accepted at QCE24 - QCRL24 Workshop

- **What's New**: 본 연구는 Quantum Reinforcement Learning(QRL)에 메타휴리스틱 알고리즘(metaheuristic algorithms)을 통합하는 방안을 탐구합니다. Particle Swarm Optimization(PSO), Ant Colony Optimization(ACO), Tabu Search(TS), Genetic Algorithm(GA), Simulated Annealing(SA), Harmony Search(HS) 등의 메타휴리스틱 알고리즘을 활용하여 QRL의 파라미터 최적화를 시도합니다. 그 결과, Simulated Annealing과 Particle Swarm Optimization이 특히 뛰어난 성능을 보였으며, Cart Pole 환경에서도 이들 알고리즘이 최적의 결과를 도출했습니다. 이는 QRL 학습에서 Particle Swarm Optimization과 Simulated Annealing의 효율성을 시사합니다.

- **Technical Details**: QRL에서는 전통적인 gradient-based 최적화 방법이 비효율적일 수 있습니다. 따라서 본 연구는 gradient-free 알고리즘을 사용하여 QRL의 Variational Quantum Circuits(VQC) 파라미터를 최적화합니다. Metaheuristic 알고리즘으로는 SA(시뮬레이션된 어닐링), PSO(입자 군집 최적화), ACO(개미 군집 최적화), TS(타부 검색), GA(유전 알고리즘), HS(하모니 검색)을 선택했습니다. 이들 알고리즘은 다양한 QRL 환경에서 테스트되었습니다.

- **Performance Highlights**: 5x5 MiniGrid Reinforcement Learning 환경에서 모든 알고리즘이 근사 최적 결과를 보였으며, 특히 SA와 PSO가 뛰어난 성능을 보였습니다. Cart Pole 환경에서는 SA, GA, PSO가 최적의 결과를 얻었고, 다른 알고리즘은 랜덤 액션 선택보다 약간 더 나은 성능을 보였습니다. 이는 Particle Swarm Optimization과 Simulated Annealing이 QRL에서 효율적인 학습을 가능하게 한다는 것을 보여줍니다.



### Misinforming LLMs: vulnerabilities, challenges and opportunities (https://arxiv.org/abs/2408.01168)
- **What's New**: 최근 arXiv에 게시된 논문에서는 대형 언어 모델(LLMs)의 기저 메커니즘에 대한 오해를 다룹니다. 연구는 현재 LLM 아키텍처가 통계적 패턴에 의존하기 때문에 본질적으로 신뢰할 수 없다고 주장합니다. 하지만, 생성형 트랜스포머 기반 모델을 사실 기반(fact bases) 및 논리 프로그래밍 언어와 결합하는 연구가 신뢰성 있는 LLM 개발로 이어질 가능성을 제시합니다.

- **Technical Details**: LLMs는 자연어 처리에서 큰 진전을 이루었지만, 실제 인지 과정을 따르지 않고 단순히 단어 임베딩(word embeddings)의 통계적 패턴에 의존합니다. 이는 '환각(hallucination)' 및 잘못된 정보의 취약점을 초래합니다. LLM은 높은 차원의 임베딩 공간에서 텍스트를 인코딩하고 해당 공간에서 텍스트를 디코딩합니다. 따라서 문장은 특정 경로 패턴에 맞춰서 디코딩 됩니다. 이러한 메커니즘은 진정한 인지 과정과 맞지 않으며, 단어 임베딩 벡터의 순차적 패턴의 상관관계에 의존하기 때문에 신뢰할 수 없습니다.

- **Performance Highlights**: 환각 문제를 해결하기 위해 체인 오브 생각(chain-of-thought) 프롬프트와 같은 기술이 도입되었습니다. 이는 멀티스텝 문제를 작은 단계로 나누어 신뢰성을 향상시키는 방법입니다. 그러나 LLM의 잘못된 출력이나 환각 문제가 발생했을 때 어떤 부분이 문제인지 판단할 수 없는 단점이 존재합니다. 최근 연구는 생성형 트랜스포머 모델에 사실 정보를 주입하여 성능을 높이거나, 논리 프로그래밍 언어를 생성하는 코드 작성기로 사용하여 신뢰 가능한 LLM을 개발하는 방향으로 나아가고 있습니다.



### TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation (https://arxiv.org/abs/2408.01156)
- **What's New**: 이 논문에서는 새로운 확률 모델인 TCR-GPT를 소개합니다. 이 모델은 decoder-only transformer 아키텍처를 기반으로 하여 TCR(T-cell receptors) 서열 패턴을 파악하고 이를 복제하도록 설계되었습니다. TCR-GPT는 강화 학습(Reinforcement Learning, RL)을 활용하여 특정 펩타이드(peptides)를 인식할 수 있는 TCR 서열을 생성하도록 조정할 수 있습니다. 이는 표적 면역 치료 및 백신 개발을 위한 잠재력을 크게 향상시킵니다.

- **Technical Details**: TCR-GPT는 auto-regressive transformers를 활용한 텍스트 생성 모델로, TCR의 서열 확률 분포를 학습합니다. 서열 확률 분포를 추론하는 정확도는 Pearson 상관계수로 측정된 0.953입니다. 강화 학습(RL)을 통해 사전 학습된 TCR-GPT 모델을 미세 조정하여 특정 펩타이드에 결합할 가능성이 있는 TCR 서열을 생성할 수 있습니다. PanPep 도구를 사용해 펩타이드-TCR 결합 예측을 반복적으로 미세 조정하여 모델의 적응성을 높였습니다.

- **Performance Highlights**: TCR-GPT는 기존 모델보다 서열 확률 분포를 추론하는데 높은 정확도를 보였습니다 (0.953). 또한 강화 학습을 통해 특정 펩타이드를 인식할 가능성이 높은 TCR 서열을 성공적으로 생성하여 생물학적으로 중요한 TCR 서열의 확률 분포에 적응할 수 있는 효율성을 보여주었습니다.



### DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs (https://arxiv.org/abs/2408.01154)
- **What's New**: 이 연구는 엔터티 정렬(Entity Alignment, EA)을 위한 밀집 엔터티 검색 프레임워크를 제안합니다. 엔터티의 다양한 특징을 균일하게 인코딩하기 위해 언어 모델을 활용하여, 서로 다른 지식 그래프(Knowledge Graphs, KGs) 사이에서 근접 엔터티 검색을 용이하게 합니다. 이에 따라, 엔터티 검색을 통해 정렬 후보를 생성하고, 후속적으로 후보를 재정렬하여 최종 정렬을 결정합니다. 이 접근 방식은 기존의 EA 방법들과 비교하여 최고의 성능을 보여줍니다.

- **Technical Details**: 이 작업에서는 EA 문제를 텍스트 기반 엔터티 검색 문제로 형식화합니다. 다양한 엔터티의 정보를 텍스트 설명으로 변환하고, 이를 언어 모델 기반 임베딩 모델로 인코딩하여 엔터티 검색을 수행합니다. 이 프레임워크 내에서 이질적인 트리플(triples)로부터 동질적 텍스트 설명을 생성하는 엔터티 구두 모델을 제안합니다. 이를 위해 GPT를 통해 합성 트리플-투-텍스트 데이터셋을 작성하여 구두 모델을 효과적으로 훈련시킵니다. 엔터티 검색과 정렬 재정렬을 위한 임베딩 모델을 설계하고, 엔터티 상호작용을 포착하여 정렬 정확성을 보장합니다. 이 접근 방식은 PLMs(사전 훈련된 언어 모델)의 발전을 활용한 것입니다.

- **Performance Highlights**: 이 방법은 다섯 개의 데이터셋에서 종합적인 실험을 수행했으며, 기존 EA 접근 방식들과 비교하여 최상의 결과를 달성했습니다. 특히, 단일 언어 및 다중 언어 EA 데이터셋에서 현 상태 최고 성능을 보였습니다.



### A Survey of Mamba (https://arxiv.org/abs/2408.01129)
- **What's New**: 새로운 아키텍처인 Mamba가 제안되었습니다. Mamba는 고전적인 상태 공간 모델(classical state space models)에서 영감을 받아 고안되었으며, Transformers와 유사한 모델링 능력을 제공하면서도 시퀀스 길이와 관련된 거의 선형적 확장성을 유지합니다. 이는 Transformers의 주된 단점인 주의 계산(attention calculation)의 이차 복잡성으로 인한 느린 추론 시간을 극복할 잠재력을 가지고 있습니다.

- **Technical Details**: Mamba는 상태 공간 모델(state space models)의 매개변수를 입력에 따라 파라미터화하여 불필요한 정보를 걸러내고 필요한 데이터만 무한히 유지하는 단순하면서도 효과적인 선택 메커니즘을 처음으로 도입합니다. 또한, Mamba는 스캔을 사용하여 모델을 재귀적으로 계산하는 하드웨어 인식 알고리즘을 제안하여 A100 GPU에서 최대 3배의 더 빠른 연산을 수행할 수 있게 합니다.

- **Performance Highlights**: Mamba 기반 모델들은 복잡하고 긴 시퀀스 데이터를 효율적으로 모델링할 수 있는 능력과 거의 선형적 확장성을 가지고 있어서, 자연어 처리, 컴퓨터 비전, 헬스케어 등 다양한 도메인에서 뛰어난 성능을 보여주고 있습니다. 예를 들어, Zoom et al. (2024)의 연구에서 제안된 Vim 모델은 DeiT 모델보다 2.8배 빠르며, 고해상도 이미지의 특성을 추출할 때 GPU 메모리를 86.8% 절약합니다.



### BioRAG: A RAG-LLM Framework for Biological Question Reasoning (https://arxiv.org/abs/2408.01107)
Comments:
          12 pages, 7 figures

- **What's New**: BioRAG는 생명과학 질문-응답 시스템에 새로운 접근 방식을 제안합니다. 이는 대규모 언어 모델(LLMs)과 결합된 Retrieval-Augmented Generation(RAG) 프레임워크입니다. 2200만 개의 과학 논문을 기본 지식으로 사용하여 생명과학에 특화된 임베딩 모델을 훈련하고, 도메인별 지식 계층을 활용해 복잡한 쿼리와 문맥을 모델링합니다. BioRAG는 최신 정보를 반복적으로 검색 엔진을 통해 추론하면서 질문을 해체하고 정보를 검색합니다.

- **Technical Details**: BioRAG는 먼저 방대한 연구 논문을 파싱하고, 인덱싱하며, 세분화하여 고품질 학습 데이터를 구축합니다. 그런 다음, PubMedBERT를 기반으로 CLIP 기법을 적용해 생명과학에 특화된 임베딩 모델을 개발하여 생물학적 질문에 맞는 정보를 효율적으로 검색합니다. 또한, 최신 지식을 반영하기 위해 검색 엔진 및 도메인별 도구에서 지식 소스를 적응적으로 선택합니다. 이렇게 수집된 정보를 토대로 대규모 언어 모델이 응답을 생성합니다.

- **Performance Highlights**: BioRAG는 6개의 생물학 질문-응답 데이터셋에서 기존 방법들을 능가하는 성능을 보였습니다. 이는 세심하게 설계된 데이터 준비 및 커스터마이징된 임베딩 모델, 그리고 도메인별 지식 계층을 활용한 CPS와 같은 투명한 프로세스를 통해 복잡한 생물학적 질문을 효과적으로 처리할 수 있음을 시사합니다.



### Contribution-based Low-Rank Adaptation with Pre-training Model for Real Image Restoration (https://arxiv.org/abs/2408.01099)
Comments:
          33 pages, 15 figures, for homepage see this url : this https URL

- **What's New**: 최근 논문에서 제안된 새로운 접근법으로, 다수의 이미지 복원 작업을 위한 CoLoRA(기여 기반 저순위 적응)라는 효율적인 파라미터 튜닝 기법과, 무작위 순서 악화 (PROD)를 이용한 효과적인 사전 학습 방법입니다. 이전 기술들과 다르게, CoLoRA는 모든 네트워크 파라미터를 튜닝하는 것이 아니라, 각 새로운 비전 작업(task)에 대해 소량의 파라미터만을 효율적으로 튜닝합니다.

- **Technical Details**: CoLoRA는 저순위 적응(LoRA, Low-Rank Adaptation)을 활용하여 각 작업에 대해 계층별로 적응적 용량을 결정하는 새로운 기여 기반 메소드를 도입하였습니다. 또한, PROD 전략은 사전 학습 모델을 확장하여 성능과 견고성을 개선하며, 합성 사전 학습과 실제 데이터 기반 튜닝 간의 다리를 놓아줍니다. 이 접근법은 다양한 네트워크 아키텍처(CNNs 및 Vision Transformers)와 작업에 유연하게 적용될 수 있습니다.

- **Performance Highlights**: CoLoRA와 PROD는 합성 및 실제 데이터셋에서 다양한 악화 유형의 이미지 복원 작업에서 뛰어난 성능을 입증하였습니다. 특히, 다양한 IR(이미지 복원) 작업에 있어 전체 파라미터 튜닝만큼 효과적이면서도 메모리 및 저장 비용을 대폭 줄일 수 있었습니다. 예를 들어, CoLoRA는 전체 네트워크 파라미터의 약 7% 수준으로 각 작업에 필요한 작은 튜닝 어댑터만 저장하므로, 메모리 효율성 면에서 매우 유리합니다.



### Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with Transformers and Novel Encoding (https://arxiv.org/abs/2408.01096)
Comments:
          Accepted at the 25th International Society for Music Information Retrieval Conference (ISMIR 2024)

- **What's New**: 15세기 한국 궁중음악인 지화평과 취풍형을 부활시키는 프로젝트가 국립국악원(National Gugak Center)과 협력하여 진행되었습니다. 이 프로젝트는 한국 전통 음보 체계인 정간보(Jeongganbo)를 활용하여 단순한 멜로디 데이터를 기반으로 6파트 앙상블용 악보를 생성하는 것을 목표로 했습니다. 연구팀은 정간보 데이터를 인식하는 맞춤형 광학 음악 인식(optical music recognition) 기술을 이용하여 BERT와 유사한 마스크드 언어 모델(masked language model) 훈련을 진행했습니다.

- **Technical Details**: 이번 연구는 두 종류의 트랜스포머(transformer) 기반 모델, 즉 인코더-디코더(encoder-decoder) 트랜스포머 모델을 활용했습니다. 데이터셋은 85개의 궁중음악 악보에서 추출되었으며 총 28,010개의 정간 단위로 구성되었습니다. 또한, 정간보의 구조를 엄격히 따르는 인코딩 스킴(encoding scheme)을 제안하여 음의 길이를 포지션으로 표시했습니다. 이를 통해 학습 데이터가 제한된 상태에서도 높은 품질의 음악을 생성할 수 있게 되었습니다.

- **Performance Highlights**: 생성된 지화평과 취풍형의 궁중음악은 국립국악원의 전문가들에 의해 평가되었으며, 국립국악원 정악단에 의해 실제 연주되었습니다. 연구 결과, 생성된 음악이 콘서트 수준의 품질을 자랑하며 전통 음악 보존의 중요성을 부각하였습니다.



### The EAP-AIAS: Adapting the AI Assessment Scale for English for Academic Purposes (https://arxiv.org/abs/2408.01075)
- **What's New**: 이번 논문에서는 효과적인 영어 학문 목적 학습(EAP) 교육을 위해 AI 평가 스케일(AIAS)을 EAP 상황에 맞게 적응시킨 EAP-AIAS 프레임워크를 제안합니다. 이 Framework는 생성형 인공지능(GenAI) 도구를 EAP 평가 관행에 통합하면서 학문적 무결성을 유지하고 언어 발달을 지원하기 위한 체계적인 접근 방식을 제공합니다.

- **Technical Details**: EAP-AIAS 프레임워크는 'No AI'부터 'Full AI'까지 다섯 가지 수준으로 구성되어 있으며, 각 수준에서는 EAP 과제에서 적절한 생성형 인공지능(GenAI) 사용을 구체적으로 명시합니다. 이 적응의 이면에는 언어 학습자들의 독특한 요구와 EAP의 언어 능력 및 학문적 적응(disciplinary acculturation)에 대한 이중 초점이 고려되었습니다.

- **Performance Highlights**: EAP-AIAS는 다양한 EAP 평가 형태—예를 들어, writing tasks(쓰기 과제), presentations(프레젠테이션), research projects(연구 프로젝트) 등—에서 잠재적인 적용 가능성을 탐색합니다. 이 프레임워크는 교육 현장에서 GenAI 통합의 복잡성을 처리하고, AI 향상된 학문적 및 직업적 미래를 대비하는 학습자들을 준비시키기 위해 EAP 교육자들에게 유연한 도구를 제공하는 것을 목표로 합니다.



### LLM as Runtime Error Handler: A Promising Pathway to Adaptive Self-Healing of Software Systems (https://arxiv.org/abs/2408.01055)
- **What's New**: Healer는 런타임 오류를 실시간으로 처리하기 위해 Large Language Models (LLMs)을 활용한 첫 번째 LLM 지원 자가 치유 프레임워크입니다. 이 시스템은 예상치 못한 런타임 오류가 발생할 때 자동으로 오류 처리 코드를 생성하고 실행하여 프로그램 상태를 수정합니다.

- **Technical Details**: Healer는 GPT-3.5, GPT-4 및 CodeQwen-7B를 포함한 세 개의 최신 LLM을 사용하여 런타임 오류를 처리합니다. 프레임워크는 오류 메시지, 프로그램 상태 및 오류가 발생한 소스 코드를 수집한 후, 이를 기반으로 LLM을 통해 오류 처리 코드를 생성하고, 그 코드를 격리된 환경에서 실행하여 프로그램 상태를 수정합니다.

- **Performance Highlights**: Healer의 성능을 1,185개의 코드 및 테스트 케이스 쌍을 사용하여 평가한 결과, GPT-4는 어떠한 미세 조정 없이 72.8%의 런타임 오류를 성공적으로 처리했습니다. 미세 조정을 거친 GPT-3.5와 CodeQwen은 각각 31.7% 및 23.1%의 중단 없는 인스턴스 개선을 보였으며, GPT-3.5는 GPT-4와 비견될 만한 성능을 나타냈습니다.



### GNN-MolKAN: Harnessing the Power of KAN to Advance Molecular Representation Learning with GNNs (https://arxiv.org/abs/2408.01018)
- **What's New**: GNN-MolKAN과 GNN-MolKAN+라는 새로운 클래스의 Graph Neural Networks (GNNs)을 제안하여 Kolmogorov-Arnold Networks (KAN) 아키텍처를 통합했습니다. 이는 GNN의 과도한 압축 문제를 해결하여 분자의 구조적 세부사항을 더 잘 보존하고, 효율성과 성능을 향상시킵니다. 또한, 새로운 KAN 버전인 Adaptive FastKAN (AdFastKAN)을 도입하여 모델의 안정성과 속도를 크게 개선하였습니다.

- **Technical Details**: GNN-MolKAN과 GNN-MolKAN+는 Kolmogorov-Arnold Networks (KAN) 아키텍처를 GNN에 통합합니다. KAN은 다변수 함수의 복잡한 문제를 단순화된 단일 변수 구성 요소로 분해하는 Kolmogorov-Arnold 표현 정리를 기반으로 합니다. KAN은 기존의 Multi-Layer Perceptrons (MLPs)보다 높은 정확성을 제공하며, 두꺼운 네트워크 구조를 사용하지 않고도 효율적인 계산을 가능하게 합니다. 또한, Adaptable FastKAN은 학습 가능한 RBFs (Radial Basis Functions)를 기반으로 하여 데이터의 다양한 분포에 적응할 수 있도록 고안되었습니다.

- **Performance Highlights**: GNN-MolKAN과 GNN-MolKAN+는 기존의 최첨단(self-supervised) 방법을 능가하거나 일치시키면서도 더 적은 시간과 파라미터를 요구합니다. 분자 속성 예측 데이터셋 6개, 회귀 데이터셋 6개, 그리고 few-shot 학습 데이터셋 4개에서 검증되었으며, few-shot 학습 시 평균 6.97%의 개선을 달성하였습니다. 이 모델들은 강력한 예측 능력과 보완적 일반화 능력을 보여줍니다.



### IBB Traffic Graph Data: Benchmarking and Road Traffic Prediction Mod (https://arxiv.org/abs/2408.01016)
- **What's New**: 교통 혼잡 예측을 위한 새로운 IBB Traffic 그래프 데이터셋을 소개합니다. 이는 실시간 데이터 수집 및 도시와 고속도로 모두를 포함하는 2451개의 센서 위치를 커버하여 기존 데이터셋의 한계를 극복합니다. 또한, 새로운 도로 교통 예측 모델을 제안하여 복잡한 시간적, 공간적 관계를 고려한 고도화된 예측을 제공합니다.

- **Technical Details**: IBB Traffic 그래프 데이터셋은 2451개의 센서에서 수집된 데이터를 포함하며, 각 센서의 측정 빈도는 1시간 간격입니다. 데이터셋은 노드 특성(average speed, vehicle count 등)과 센서 특성(대륙, 지역, 도로 유형 등)을 포함하며, 노드 간의 관계를 정의하는 무가중치 엣지를 사용합니다. 제안된 모델은 GLEE(Node embedding)와 ExtraTrees(Classification)를 사용하여 노드 임베딩과 트래픽 예측을 수행합니다.

- **Performance Highlights**: 제안된 모델은 기존의 기준 모델보다 평균 4% 더 높은 정확도를 기록했습니다. 이는 트래픽 예측에서 중요한 시간적 링크를 강화하고 복잡한 공간적 관계를 보다 효과적으로 모델링한 결과입니다.



### Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs (https://arxiv.org/abs/2408.01008)
Comments:
          LA-UR-24-28177

- **What's New**: 최근 몇 년간 큰 언어 모델(LLMs)은 질문-응답, 감정 분석, 텍스트 요약, 기계 번역과 같은 다양한 자연 언어 처리(NLP) 작업에서 놀라운 성능을 보여주고 있습니다. 그러나 이들 모델의 복잡성은 막대한 컴퓨팅 자원을 요구하며, 이는 널리 연구되고 응용되는 데 걸림돌이 됩니다. 이러한 문제를 해결하기 위해 다양한 매개변수 효율적인 미세 조정(Parameter-Efficient Fine-Tuning) 전략이 개발되었습니다. 이번 논문에서는 새로운 PEFT 접근 방식인 Tensor Train Low-Rank Approximation (TT-LoRA)을 제안합니다. 이는 기존의 LoRETTA 방식을 최적화하여 어댑터(Adapter)와 전통적인 LoRA 기반 구조를 제거해 모델의 압축성을 크게 향상시키면서도 성능 유지 및 추론 지연을 줄이고, 계산 부담을 낮춥니다.

- **Technical Details**: TT-LoRA는 텐서 트레인 분해(TT Decomposition)를 이용해 모델의 무게 매트릭스를 효율적으로 저차원으로 표현하는 방식입니다. 기존 LoRA 방식과 달리 TT-LoRA는 어댑터와 기존 LoRA 구조를 배제하여 추가적 추론 지연을 없애고, 모델 압축성을 향상시키며 계산 복잡성을 줄입니다. TT-LoRA를 이용하면 다양한 스케일의 LLM들, 특히 BERT 기반 모델과 대규모 LLaMA-2 및 LLaMA-3 모델들을 효과적으로 미세 조정할 수 있습니다. 이러한 접근 방식은 특히 자원이 제한된 플랫폼에서 모델을 배포할 때 유용합니다.

- **Performance Highlights**: TT-LoRA는 다양한 다운스트림(Downstream) 작업에서, 그리고 다양한 모델 스케일에서 성능을 평가했습니다. 그 결과, TT-LoRA는 더 큰 모델과 비교해도 성능을 유지하면서도 큰 압축 효과를 보여줍니다. 특히 일반 PEFT 방법들과 비교해 볼 때, TT-LoRA는 뛰어난 성능을 나타냈으며, 모델 압축성과 성능 간의 균형을 잘 맞췄습니다. 이는 자원 제한이 있는 플랫폼에서 대규모 언어 모델을 효율적으로 운영할 수 있는 가능성을 열어줍니다.



### FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation (https://arxiv.org/abs/2408.00998)
Comments:
          Accepted conference paper of ACM MM 2024

- **What's New**: 이 논문은 대규모 텍스트-이미지 변환(T2I) 확산 모델을 이미지-이미지 변환(I2I) 패러다임에 적응시키는 새롭고 효율적인 접근 방식을 제시합니다. 이를 통해 모델 훈련이나 온라인 최적화 없이 고품질의 텍스트 기반 이미지 변환이 가능해졌습니다.

- **Technical Details**: 주요 접근법은 DCT 스펙트럼 공간에서 다양한 주파수 대역을 이용하여 레퍼런스 이미지의 다양한 지시 요소(guiding factors)를 모델링하고, 주파수 대역 대체 레이어를 개발하여 반대 방향 샘플링 과정 동안 레퍼런스 이미지의 특정 DCT 주파수 대역을 동적으로 대체하는 것입니다.

- **Performance Highlights**: 이 방법은 레퍼런스 이미지의 지시 요소와 지시 강도를 유연하게 조절할 수 있도록 하며, 광범위한 정량적 및 정성적 실험에서 기존 방법에 비해 우수한 I2I 변환 시각 품질, 다용성 및 제어 가능성을 입증했습니다.



### IncidentNet: Traffic Incident Detection, Localization and Severity Estimation with Sparse Sensing (https://arxiv.org/abs/2408.00996)
Comments:
          6 pages, 6 figures, 2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC)

- **What's New**: IncidentNet은 도시 환경에서 드문 센서 데이터를 기반으로 트래픽 사건(traumatic incident)을 분류, 위치 지정, 심각도를 추정하는 혁신적인 딥러닝 접근법을 제시합니다. 새로운 방식으로 희박한 센서 배치에서도 높은 정확도의 트래픽 사건 탐지가 가능합니다.

- **Technical Details**: 이 모델은 교차로에 설치된 카메라로 수집된 미세 트래픽 데이터(microscopic traffic data)를 사용합니다. 새로운 합성 미세 트래픽 데이터셋을 생성하는 방법론을 제시하며, 이는 광범위하게 적용 가능한 공공 트래픽 흐름 데이터를 바탕으로 합니다. Deep learning 모델은 TabNet을 활용하여 31일간의 시뮬레이션 데이터를 학습했습니다.

- **Performance Highlights**: IncidentNet은 교차로의 20% 미만의 카메라 배치에서도 98%의 탐지율, 7% 미만의 잘못된 알람률, 평균 197초의 탐지 시간을 달성했습니다. 고속도로 시나리오에서는 99%의 탐지율과 4.17%의 잘못된 알람률을 보였습니다.



### ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models (https://arxiv.org/abs/2408.00994)
Comments:
          Accepted by ACL 2024 main conference

- **What's New**: 새로운 연구 논문에서는 대형 언어 모델 (LLM)의 코드 생성 기능을 확장하여 주어진 텍스트 설명으로부터 포괄적인 소프트웨어 요구사항을 자동으로 관리하는 방법을 제안합니다. 이 논문에서는 특히 ARCHCODE라는 새로운 프레임워크를 소개하며, 이를 통해 요구사항을 체계적으로 정리하고 생략된 요구사항도 추론하여 코드 스니펫과 테스트 케이스를 생성하는 방법을 설명합니다. Public benchmarks 실험에서 ARCHCODE가 기능 요구사항(Functional Requirements, FRs)과 비기능적 요구사항(Non-Functional Requirements, NFRs) 모두를 효과적으로 만족시키는 것으로 나타났습니다.

- **Technical Details**: ARCHCODE는 In-Context Learning (ICL)을 활용하여 LLM의 광범위한 추론 능력을 발휘하며, 매개변수 업데이트 없이 요구사항을 학습하는 방식을 채택합니다. 각 in-context 학습 예제에는 텍스트 설명, 소프트웨어 요구사항 목록(설명에 명시된 것과 명시되지 않은 것 모두 포함), 그리고 이러한 요구사항을 만족시키는 코드가 포함된 트리플렛이 포함됩니다. 아키코드는 이 예제들을 토대로 LLM가 요구사항을 재구성하고 코드를 생성하며, 각각의 요구사항을 확인하는 테스트 케이스를 생성하도록 유도합니다.

- **Performance Highlights**: ARCHCODE는 HumanEval 및 CodeContests 벤치마크에서 GPT-4 대비 GPT-3.5-Turbo를 사용하여 Pass@k 점수를 각각 4.81%p 및 10.45%p 향상시켰으며, 기존 방법에 비해 50배 적은 수의 테스트 케이스를 생성하여도 성능을 입증했습니다. 또한, ARCHCODE는 FR 뿐만 아니라 NFR도 효과적으로 만족시키는 것으로 확인되었습니다.



### PERSOMA: PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting (https://arxiv.org/abs/2408.00960)
- **What's New**: PERSOMA라는 새로운 Personalized Soft Prompt Adapter 아키텍처를 소개합니다. 이 시스템은 사용자 상호작용 기록을 표현력 있는 소프트 프롬프트 임베딩(soft prompt embeddings)으로 압축하여 캡쳐합니다.

- **Technical Details**: PERSOMA는 사용자의 과거 상호작용을 텍스트 프롬프트가 아닌 소프트 프롬프트(soft prompt)로 변환하여 대형 언어 모델(LLMs)의 성능을 개선합니다. 이 과정에서 Parameter-efficient tuning 기법인 LoRA와 History Resampling Techniques를 사용해 효율성을 높였습니다. 소프트 프롬프트 어댑터(soft prompt adapter)는 사용자 히스토리를 압축하고, 이를 LLM의 어휘 공간으로 맵핑합니다.

- **Performance Highlights**: PERSOMA는 MovieLens 사용자 선호 데이터셋에서 기존의 임베딩 기반 기술과 텍스트 프롬프트 기반 기술을 능가합니다. PERSOMA는 F1 스코어에서 0.18 높게 기록하며, 적은 계산 자원의 사용으로도 동일한 결과를 보여줍니다.



### CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression (https://arxiv.org/abs/2408.00938)
- **What's New**: 특발성 폐섬유증(Intropic Pulmonary Fibrosis, IPF)의 진행을 예측하기 위해 새로운 확산 모델(diffusion model)을 개발했습니다. 이 모델은 환자의 초기 컴퓨터 단층촬영(CT) 스캔에서 팔로우업 CT 스캔을 생성함으로써 질병의 진행 상황을 예측합니다. 이는 기존의 1년 간격의 CT 스캔을 통한 진단 방법의 문제점을 해결하고자 합니다.

- **Technical Details**: 기존 확산 모델을 개선하여 CIResDiff(Clinically-Informed Residual Diffusion) 모델을 제안합니다. 주요 개선 사항은 다음과 같습니다: 1) 대상 영역 사전 등록(target region pre-registration)을 통해 서로 다른 시간대의 CT 스캔을 정렬하여 생성 난이도를 줄임, 2) 전통적 확산 대신 잔여 확산(residual diffusion)을 채택하여 모델이 두 CT 스캔 간의 차이(병변)에 집중할 수 있게 함, 3) CLIP 기술 기반의 임상 정보 통합 과정을 설계하여 폐 기능 정보와 CT 스캔 정보를 활용합니다.

- **Performance Highlights**: 임상 데이터를 기반으로 한 광범위한 실험에서 CIResDiff 모델이 최첨단 기술을 능가하며 IPF 진행을 효과적으로 예측할 수 있음을 증명하였습니다.



### Enabling High Data Throughput Reinforcement Learning on GPUs: A Domain Agnostic Framework for Data-Driven Scientific Research (https://arxiv.org/abs/2408.00930)
- **What's New**: WarpSci는 강화 학습 (Reinforcement Learning, RL)을 활용한 데이터 구동 과학 연구에 최적화된 프레임워크입니다. 이 프레임워크는 CPU와 GPU 간의 데이터 전송을 제거하고 단일 또는 다중 GPU에서 수천 개의 시뮬레이션을 동시에 실행할 수 있습니다.

- **Technical Details**: WarpSci는 각 GPU에서 RL 워크플로우 전체를 실행하며, 이를 위해 GPU 내 통합된 데이터 저장소를 활용합니다. 이 방식은 CPU-GPU 데이터 전송을 최소화하고 GPU 내부 데이터 전송을 제거하여 시뮬레이션 및 훈련 시간을 크게 단축합니다. 또한, WarpSci는 GPU 병렬 처리를 활용하여 수천 개의 단일 에이전트 또는 다중 에이전트 시뮬레이션을 동시에 실행할 수 있습니다. 간단한 Python 클래스와 CUDA 백엔드를 제공하여 사용자 정의 환경을 쉽게 구축할 수 있습니다.

- **Performance Highlights**: WarpSci는 단일 Nvidia A100 GPU에서 8.6백만 환경 스텝/초(cartpole 환경 10K 개), 0.12백만 경제 시뮬레이션 1K 개, 0.95백만 촉매 반응 경로 2K 개 성능을 달성하여 상당한 생산성을 보입니다. 이 프레임워크의 주요 특징은 거의 완벽한 병렬성을 보여주며, 여러 GPU에 걸쳐 훈련을 확장할 수 있는 능력을 갖췄습니다.



### WHITE PAPER: A Brief Exploration of Data Exfiltration using GCG Suffixes (https://arxiv.org/abs/2408.00925)
Comments:
          8 pages, 8 figures. Conducted as part of employment at Microsoft Corporation

- **What's New**: 이 논문은 Cross-Prompt Injection Attack (XPIA)라는 새로운 공격 기법과 이와 결합된 Greedy Coordinate Gradient (GCG) suffix attack을 소개합니다. 이러한 새로운 결합된 공격 방식(GCG-XPIA)은 대규모 언어 모델(LLM)을 통해 민감한 데이터를 유출하는 효과적인 방법으로 제시되고 있습니다.

- **Technical Details**: XPIA는 공격자가 이메일과 같은 제3자 데이터에 악성 명령어를 삽입하여, 해당 데이터를 소비하는 대규모 언어 모델(LLM)이 사용자의 지시를 무시하고 삽입된 명령어만을 실행하게 만드는 공격입니다. GCG suffix attack는 Zou et al.에 의해 2023년에 처음 발표되었으며, 프롬프트에 접미사를 추가하여 모델의 긍정적인 응답을 유도합니다. 이 두 공격을 결합한 GCG-XPIA는 제3자 데이터에 GCG 접미사를 포함한 주입을 통해 모델의 주의를 악성 명령으로 효과적으로 전환시킬 수 있습니다.

- **Performance Highlights**: 마이크로소프트의 AI Red Team에서 시뮬레이션한 GCG-XPIA 시나리오에서, GCG 접미사의 존재는 데이터 유출 성공 가능성을 약 20% 증가시키는 것으로 나타났습니다. 데이터 유출은 기업에 평균 약 4.5백만 달러의 비용이 발생하며, 각종 이메일 및 문서에 삽입된 주입으로 인한 것이다. XPIA와 GCG suffix의 결합은 GPT-3.5와 GPT-4와 같은 고복잡도 모델에서도 효과적임이 입증되었습니다.



### Reclaiming Residual Knowledge: A Novel Paradigm to Low-Bit Quantization (https://arxiv.org/abs/2408.00923)
Comments:
          Accepted by The 35th British Machine Vision Conference (BMVC 2024)

- **What's New**: 이 논문은 저비트(4비트 이하) 양자화(quantization)에 대한 새로운 접근 방식을 제안합니다. 기존의 최적화 기법들과는 달리, 최적 양자화를 컨볼루션 신경망(ConvNets) 아키텍처 탐색 문제로 재해석하였습니다. 제안된 프레임워크는 CoRa(Optimal Quantization Residual Convolutional Operator Low-Rank Adaptation)로, 기존에 무시되었던 양자화 잔여 정보(quantization residual knowledge)를 회수하여 성능 저하를 방지하고, 훈련 없이도 성능을 유지할 수 있음을 보여줍니다.

- **Technical Details**: CoRa는 저비트 양자화에서 잃어버린 정보를 회수하기 위해 저차 어댑터(low-rank adapters)를 사용하여 양자화된 잔여 가중치를 근사합니다. 기존의 방법들은 가중치 공간에서 최적의 가중치를 찾기 위해 광범위한 탐색 공간을 필요로 하지만, CoRa는 훨씬 작은 탐색 공간을 사용하여 효율성을 높였습니다. 이를 위해 CoRa는 컨볼루션 필터를 두 개의 작은 저차 필터로 변환하여 최적의 성능을 유지합니다.

- **Performance Highlights**: CoRa는 ImageNet에서 사전 훈련된 ConvNets을 평가한 결과, 기존의 최첨단 양자화 인식 훈련(QAT) 및 사후 훈련 양자화(PTQ) 방법들과 비교하여 4비트 및 3비트 양자화에서 유사한 성능을 보였습니다. 특히, 소규모 보정 세트(1600개의 이미지)에서 250회 미만의 반복으로 최적화되었습니다. 이렇게 개발된 CoRa는 낮은 비트 양자화에서 최적화 효율성 면에서 새로운 기준을 세웠습니다.



### Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations (https://arxiv.org/abs/2408.00906)
Comments:
          Accepted at MLCN 2024

- **What's New**: 새로운 그래프 신경망(GNN) 기법을 사용하여 파킨슨병(Parkinson's Disease, PD)을 진단하는 방법을 제안합니다. 이 방법은 휴식 상태 EEG(뇌파)를 사용하여 PD를 설명 가능하게 탐지하고자 합니다. 기존의 깊이 학습(deep learning, DL) 기법들이 가지고 있는 문제들을 해결하면서, GNN 기반의 새로운 접근 방식을 도입했습니다.

- **Technical Details**: 제안된 방법은 구조적 글로벌 컨볼루션(structured global convolutions)과 대조 학습(contrastive learning)을 결합하여 제한된 데이터로 복잡한 특징을 잘 모델링합니다. 또한, 다중 헤드 그래프 구조 학습기(multi-head graph structure learner)를 도입하여 비유클리드(non-Euclidean) 구조의 EEG 데이터를 포착합니다. 마지막으로, 헤드별 그래디언트 가중 그래프 주의 설명기(head-wise gradient-weighted graph attention explainer)를 사용하여 신경 연결 통찰(neural connectivity insights)을 제공합니다.

- **Performance Highlights**: UC San Diego 파킨슨병 EEG 데이터셋을 사용하여 개발 및 평가하였고, 주제별 하나를 남겨놓는 교차 검증(subject-wise leave-one-out cross-validation)에서 69.40% 탐지 정확도를 달성하였습니다. 또한, 학습된 그래프 토폴로지(graph topology)에 대한 직관적인 설명을 생성할 수 있었습니다.



### Expressive MIDI-format Piano Performance Generation (https://arxiv.org/abs/2408.00900)
Comments:
          4 pages, 2 figures

- **What's New**: 이번 연구에서는 표현력 있는 피아노 연주를 MIDI 포맷으로 생성할 수 있는 생성형 신경망(generative neural network)을 선보였습니다. 이 모델은 생동감 있는 마이크로 타이밍(micro-timing), 풍부한 다성 텍스처(polyphonic texture), 다양한 다이내믹(dynamics), 그리고 지속 페달 효과(sustain pedal effects)로 음악적 표현력을 반영합니다.

- **Technical Details**: 이 모델은 데이터 처리에서부터 신경망 설계까지 여러 혁신적인 측면을 포함하고 있습니다. 모델은 LSTM, Attention 메커니즘을 사용하여 여러 입력과 출력을 상호 연관된 형태로 생성하며, 이는 음악성과 일관성을 유지하는 데 중요한 역할을 합니다. MIDI 데이터 형식을 사용하여 높은 수준의 음악적 표현을 최적화했습니다.

- **Performance Highlights**: 생성된 피아노 곡은 원시 오디오로 생성한 음악에 뒤지지 않는 표현력을 가지고 있으며, 고급 뮤지컬 측면들을 대부분 유지하고 있습니다. 다만 제출 시간의 제한으로 인해 모델이 충분히 훈련되지 않아 일관성이 떨어지는 부분이 있을 수 있습니다. 그럼에도 불구하고, 모델은 강력한 생성 능력을 보여주고 있습니다.



### On the Relationship Between Monotone and Squared Probabilistic Circuits (https://arxiv.org/abs/2408.00876)
Comments:
          7th Workshop on Tractable Probabilistic Modeling

- **What's New**: 이번 연구에서는 확률 회로(probabilistic circuits)를 이용한 새로운 모델인 InceptionPCs를 제안합니다. 이는 기존의 단조 회로(monotone circuits)와 제곱 회로(squared circuits) 모두를 포괄하며, 복합 파라미터(complex parameters)를 사용합니다. 이는 기존 모델들의 한계를 극복하고 더 나은 표현력을 가질 수 있음을 보여줍니다.

- **Technical Details**: 확률 회로는 가중치를 두고 덧셈과 곱셈으로 이루어진 계산 그래프로 정의됩니다. 이를 통해 밀도 함수(density functions)나 질량 함수(mass functions)를 나타내고 학습할 수 있으며, 주변 추론(marginal inference)이 가능해집니다. 기존에는 비음수 가중치(monotone circuit)를 사용한 모델이 주를 이루었으나, 최근 제곱 회로(squared circuit)를 사용한 방법이 제안되었습니다. 제곱 회로를 사용하면 음수 가중치도 허용되며, 더욱 압축된 형태로 모델을 표현할 수 있습니다.

- **Performance Highlights**: InceptionPCs는 이미지 데이터셋(MNIST, FashionMNIST)에서 단조 회로와 제곱 회로보다 더 나은 성능을 보였습니다. 이는 InceptionPCs가 두 가지 회로 모델의 장점을 결합하여 더 우수한 표현력을 가졌음을 뜻합니다.



### UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation (https://arxiv.org/abs/2408.00863)
- **What's New**: LLMs(대형 언어 모델)의 뛰어난 성과를 분자 응용 분야로 확장하려는 연구가 활발히 진행 중입니다. 하지만 기존 분자 LLM들은 일반적으로 어댑터 기반 구조를 사용해 텍스트와 분자를 동등하게 취급하지 않으며, 분자 모달리티에 대한 슈퍼비전 신호가 부족합니다. 이를 해결하기 위해 분자 토큰을 포함한 tokenizer 기반 아키텍처를 채택한 UniMoT를 도입했습니다. UniMoT는 분자 텍스트 모달리티를 통합해 분자를 외국어처럼 해석하고 텍스트처럼 생성할 수 있도록 합니다.

- **Technical Details**: UniMoT는 벡터 양자화(Vector Quantization) 기반 tokenizer를 채택하여 분자를 시퀀스 형태의 분자 토큰으로 변환합니다. 이 tokenizer는 Q-Former를 사용해 분자와 텍스트 간의 모달리티 간격을 좁히며, 시퀀스의 퀀텀 단위를 학습 가능한 코드북을 통해 양자화합니다. 결과적으로 UniMoT는 통합된 토큰 표현 및 자가 회귀(autoregressive) 학습 패러다임을 사용해 분자와 텍스트 모달리티를 통합합니다. 네 단계를 거친 학습 절차를 통해 UniMoT는 다기능 멀티모달 모델로서 분자 이해(comprehension)와 생성(generation) 작업을 수행할 수 있습니다.

- **Performance Highlights**: 연구 결과 UniMoT는 분자 이해 및 생성 작업에서 최첨단 성과를 기록했으며, 다양한 분자 관련 작업에서 탁월한 성능을 발휘했습니다. 이는 기존의 어댑터 기반 구조를 벗어나 tokens를 통한 균일한 처리가 모델의 성능을 극대화할 수 있음을 보여줍니다.



### Calibrating Bayesian Generative Machine Learning for Bayesiamplification (https://arxiv.org/abs/2408.00838)
Comments:
          15 pages, 6 figures

- **What's New**: 최근 입자 물리학에서 생성적 신경망(generative neural networks)과 베이지안 머신러닝(Bayesian machine learning)을 결합한 연구가 등장했습니다. 이 논문은 생성된 분포의 불확실성을 정량화하는 명확한 체계를 제안합니다. 저자들은 저차원 장난감 데이터셋에 연속 정규 흐름(Continuous Normalizing Flow)을 적용하여, 베이지안 불확실성의 교정을 평가합니다.

- **Technical Details**: 이 연구에서는 연속 정규 흐름(CNF)을 사용하여 생성적 신경망 모델의 불확실성을 정량화합니다. 특히, 평균 필드 가우시안 가중치 사후(mean-field Gaussian weight posterior)와 몬테칼로 샘플링(Monte Carlo sampling)이라는 두 가지 접근법을 사용하여 불확실성을 평가합니다. 이를 통해 데이터의 부드러운 특징에서의 데이터 증폭(data amplification)을 나타낼 수 있습니다.

- **Performance Highlights**: 논문에서는 베이지안 생성 신경망의 불확실성이 잘 교정된 경우 통계적 힘을 예측할 수 있음을 보입니다. 결과적으로, 생성된 데이터 세트의 통계적 중요성(significance)을 정량화하고, 불확실성 교정이 중요한 응용 분야에서도 이 방법이 유효함을 확인합니다.



### Adaptive traffic signal safety and efficiency improvement by multi objective deep reinforcement learning approach (https://arxiv.org/abs/2408.00814)
- **What's New**: 이 연구는 교차로에서의 제어 전략을 강화하는 동시에 안전, 효율, 및 탈탄소화(decarbonization) 목표를 해결하기 위한 다목적 심층 강화 학습(multi-objective deep reinforcement learning, DRL) 기법을 이용한 적응형 교통 신호 제어법(adaptive traffic signal control, ATSC)을 소개합니다. 기존의 ATSC 방법은 주로 교통 효율에 중점을 두며 실시간 동적 교통 상황에 적응하는 것이 어려운 문제를 가집니다. 이러한 문제를 해결하기 위해, 본 연구는 Dueling Double Deep Q Network(D3QN) 프레임워크를 통합한 DRL 기반 ATSC 알고리즘을 제안합니다.

- **Technical Details**: 제안된 ATSC 알고리즘은 Dueling Double Deep Q Network(D3QN) 프레임워크를 활용하여 구현되었습니다. 이 알고리즘의 성능은 중국 창사시에 위치한 모의 교차로에서 평가되었습니다.

- **Performance Highlights**: 제안된 ATSC 알고리즘은 전통적인 ATSC 및 효율 최적화에 중점을 둔 ATSC 알고리즘을 압도하며, 교통 갈등(traffic conflicts)을 16% 이상 줄이고, 탄소 배출량을 4% 감소시키는 데 성공했습니다. 또한, 전통적인 ATSC에 비해 대기 시간을 18% 줄였으며, D3QN 프레임워크를 통합한 DRL 기반 ATSC 알고리즘과 비교했을 때는 대기 시간이 0.64% 증가하는 약간의 증가를 보였습니다. 이러한 미세한 증가는 효율성과 안전, 탈탄소화와 같은 다른 목적들 간의 균형을 나타냅니다. 특히 높은 교통 수요 시나리오에서 모든 세 가지 목표에 걸쳐 우수한 성능을 보여줍니다.



### ChipExpert: The Open-Source Integrated-Circuit-Design-Specific Large Language Mod (https://arxiv.org/abs/2408.00804)
- **What's New**: 이번에 소개된 ChipExpert는 통합회로(IC) 디자인 분야를 위해 특화된 최초의 오픈 소스 교육용 대형 언어 모델(LLM)입니다. 이는 IC 디자인의 도전과 요구를 충족시키기 위해 고안되었습니다.

- **Technical Details**: ChipExpert는 현존하는 최고의 오픈 소스 기초 모델 중 하나인 Llama-3 8B를 기반으로 훈련되었습니다. 훈련 과정은 데이터 준비, 지속적 사전 훈련, 지도학습 방식의 미세 조정, 선호도 정렬(Direct Preference Optimization), 평가로 구성됩니다. 데이터 준비 단계에서 수작업 선택과 데이터 합성 기법을 통해 고품질의 맞춤형 데이터셋을 구성하였고, 여러 단계에 걸쳐 IC 디자인 지식을 습득하고 사용자 질의에 전문적으로 응답하는 방법을 학습하였습니다.

- **Performance Highlights**: ChipExpert는 새롭게 개발된 IC 디자인 벤치마크 ChipICD-Bench에서 다수의 실험을 통해 뛰어난 성능을 입증하였습니다. 이 벤치마크를 통해 IC 디자인 지식 기반 질의-응답 작업에서 높은 수준의 전문성을 보여주었습니다. 또한, RAG(Retrieval-Augmented Generation) 시스템을 통해 시뮬레이션 오류를 줄였습니다.



### A Comprehensive Survey on Root Cause Analysis in (Micro) Services: Methodologies, Challenges, and Trends (https://arxiv.org/abs/2408.00803)
- **What's New**: 이 설문조사는 마이크로서비스 내의 근본 원인 분석(root cause analysis, RCA) 기술에 대한 포괄적이며 구조화된 리뷰를 제공합니다. 이 리뷰는 메트릭스(metrics), 추적(traces), 로그(logs) 및 다중 모델 데이터(multi-model data)와 같은 다양한 방법론을 탐구하며, 마이크로서비스 아키텍처 내의 도전 과제와 미래 트렌드에 대해 깊이 있게 논의합니다. 이 논문은 AI와 자동화 혁신의 최전선을 차지하면서, 향후 연구 방향에 대한 지침을 제공합니다.

- **Technical Details**: 마이크로서비스 아키텍처에서는 서비스 호출 간 관계가 네트워크 형태를 이루며, 이는 시스템 전반에 걸쳐 계층적으로 조직됩니다. RCA 기술은 로그, 메트릭스 및 알림과 같은 다양한 출처에서 데이터를 수집하고 분석하여 문제의 근본 원인을 식별하는 데 사용됩니다. 이 과정에서 기계 학습과 기타 고급 AI 기술이 활용됩니다. 설문조사는 총 다섯 가지 주요 방법론(메트릭 기반, 추적 기반, 로그 기반, 다중 모델 기반, LLM 역할)을 포괄적으로 분석합니다.

- **Performance Highlights**: RCA 기술의 주요 목표는 문제 해결 프로세스를 신속하게 진행하여 평균 복구 시간(MTTR)을 단축하고 재발을 방지하는 것입니다. 이를 통해 운영 효율성이 향상되고 시스템의 신뢰성과 견고성이 증대됩니다. 리뷰는 역사적인 접근 방식을 조사할 뿐만 아니라 최신 연구 방법론도 포함하여 RCA 분야의 현재 상태를 포괄적으로 다룹니다.



### Leveraging LLM Reasoning Enhances Personalized Recommender Systems (https://arxiv.org/abs/2408.00802)
Comments:
          To be published at ACL 2024

- **What's New**: 본 연구는 최근 대규모 언어 모델(Large Language Models, LLMs)이 추천 시스템(RecSys)에서 기능을 향상시키는 방안을 탐구하였다. 특히, Chain-of-Thought(COT) prompting을 통한 LLM의 추론 기능을 추천 시스템에 적용하여 사용자 맞춤 추천의 성능을 개선하고자 하였다. 또한 RecSAVER(RecSys Automatic Verification and Evaluation of Reasoning)이라는 평가 프레임워크를 도입하여, 인간의 평가 없이도 자동으로 추론 응답의 품질을 평가할 수 있는 방법을 제안하였다.

- **Technical Details**: 연구에서 제안된 RecSAVER 프레임워크는 코히전(coherence)와 신뢰성(faithfulness)에 대한 인간의 판단과 일치하는 결과를 제공한다. 또한, zero-shot 및 fine-tuning 시나리오 둘 다에서 LLM의 추론 기능을 사용하여 추천 시스템의 과제 성능이 향상되는 것을 확인하였다. 이는 사용자 평가 예측 과제에서 높은 사용자 결단력과 피드백을 요구하는 과제를 중심으로 실험을 진행하였다. 또한, BLEU와 ROUGE와 같은 문법적 지표가 LLM 출력을 평가하는 데 적합하고, METEOR와 BERTScore는 생성된 출력의 코히전을 측정하는 데 더 적합한 것으로 나타났다.

- **Performance Highlights**: 큰 모델을 사용하여 추론 데이터를 생성하는 것이 더 작은 모델을 fine-tuning 하여 성능과 추론 능력을 향상시키는 데 효과적이라는 점을 보여주었다. 또한 RecSAVER 프레임워크를 통해 인간 평가와 일치하면서도 비용과 효율성을 개선하여 LLM의 추론 기능을 이해하는 데 기여하는 유의미한 통찰을 제공하였다.



### Chatbot-Based Ontology Interaction Using Large Language Models and Domain-Specific Standards (https://arxiv.org/abs/2408.00800)
- **What's New**: 이번에는 대형 언어 모델(LLMs)과 챗봇 인터페이스를 활용하여 SPARQL 쿼리 생성 과정을 개선하는 개념을 소개합니다. 사용자는 자연어 입력을 통해 온톨로지의 형식화된 지식에 직관적으로 접근할 수 있습니다. 이번 기법은 사용자 문의를 정확한 SPARQL 쿼리로 변환하여, 대형 언어 모델에 의해 잘못된 정보나 자료 조작이 발생하는 것을 방지합니다.

- **Technical Details**: 이 시스템은 사용자가 자연어(NL)로 질문을 제출하면, 이를 챗봇을 통해 LLM에 전송하여 SPARQL 쿼리로 변환합니다. 그런 다음 쿼리는 백엔드에서 실행되고 그 결과가 사용자에게 표시됩니다. 추가적으로, 온톨로지에 도메인별 표준에서 가져온 추가 텍스트 정보를 통합하여 개념과 관계의 정확한 설명을 제공합니다.

- **Performance Highlights**: 실험 연구 결과, LLMs를 사용한 SPARQL 쿼리 생성이 정확도 면에서 상당한 이점을 보였습니다. 이는 사용자가 더 쉽게 온톨로지를 쿼리하고, 높은 신뢰도를 유지하면서도 명확한 결과를 얻을 수 있도록 했습니다.



### Golden-Retriever: High-Fidelity Agentic Retrieval Augmented Generation for Industrial Knowledge Bas (https://arxiv.org/abs/2408.00798)
- **What's New**: 이 논문은 Golden-Retriever라는 새로운 접근 방식을 소개합니다. 이는 대규모 산업 지식 베이스를 효율적으로 탐색하도록 설계되었으며, 기존의 대형 언어 모델(LLM) 미세 조정 및 Retrieval-Augmented Generation(RAG) 프레임워크가 도메인 특화 용어와 문맥 해석에서 겪는 어려움을 극복합니다. Golden-Retriever는 문서 검색 전에 반영 기반 질문 확장 단계를 포함하며, 이는 전문 용어를 식별하고 문맥에 기반한 의미 명확화를 통해 질문을 확장합니다.

- **Technical Details**: Golden-Retriever는 오프라인 및 온라인 프로세스로 구성됩니다. 오프라인 프로세스는 Optical Character Recognition(OCR)을 사용해 다양한 문서 포맷에서 텍스트를 추출하고, 이를 요약 및 문맥화하여 문서 데이터베이스를 강화합니다. 온라인 프로세스는 사용자 질문 내의 전문 용어와 문맥을 식별한 후, 용어 사전과 대조해 정확한 정의와 설명을 찾습니다. 이렇게 확장된 질문은 RAG 프레임워크에 입력되어 가장 관련성 높은 문서를 검색합니다.

- **Performance Highlights**: 도메인 특화 질문-답변 데이터셋을 사용하여 세 가지 오픈 소스 LLM에서 Golden-Retriever의 성능을 평가한 결과, 우리의 방법이 검색 정확도를 크게 향상시키며 뛰어난 성능을 보였습니다. 기존의 Corrective RAG와 Self-RAG와 달리, Golden-Retriever는 질문의 모호성을 해결하여 검색 단계의 정확성을 높입니다.



### CCSRP: Robust Pruning of Spiking Neural Networks through Cooperative Coevolution (https://arxiv.org/abs/2408.00794)
- **What's New**: 본 연구에서는 Spiking Neural Networks (SNNs)의 컴팩트성과 강인성(robustness)을 동시에 향상시키기 위한 새로운 방법론인 CCSRP를 제안합니다. CCSRP는 Cooperative Co-evolution에 기반하여 SNN을 효과적으로 prune(정리)하는 혁신적인 방법을 제시합니다.

- **Technical Details**: CCSRP는 세 가지 목표(accuracy, robustness, compactness)를 동시에 최적화하는 tri-objective optimization 문제로서, 협력적 공동 진화 프레임워크(cooperative co-evolutionary pruning framework)를 사용하여 각 layer의 filter를 독립적으로 pruning하는 방식을 채택하고 있습니다. 이를 통해 느리고 반복적인 실험 없이도 효율적으로 모델을 경량화할 수 있습니다.

- **Performance Highlights**: CIFAR-10 및 SVHN 데이터셋에 대한 실험 결과, CCSRP는 기존 최신 방법론과 동등하거나 그 이상의 성능을 보여주었습니다. 이로써 자원 제한적이고 안전이 중요한 환경에서도 SNN의 실용적 적용 가능성을 높였습니다.



### A Scalable and Generalized Deep Learning Framework for Anomaly Detection in Surveillance Videos (https://arxiv.org/abs/2408.00792)
- **What's New**: 이 연구는 새로운 딥러닝 (DL) 프레임워크를 소개하며, 다양한 비디오 이상 탐지 작업을 위한 일반화 문제를 해결하려고 합니다. 기존의 DL 접근 방식은 각 작업마다 재훈련이 필요하여 시간과 자원이 많이 소모되었으나, 이번 프레임워크는 재훈련 없이도 다양한 작업에 일반화가 가능합니다.

- **Technical Details**: 새로운 DL 프레임워크는 세 가지 주요 구성 요소를 포함합니다: 첫째, feature 일반화를 향상시키기 위한 transfer learning (전이 학습); 둘째, feature 표현을 개선하기 위한 model fusion (모델 융합); 셋째, 새로운 작업이 도입될 때 처음부터 훈련하지 않고도 classifier를 일반화할 수 있는 multi-task classification (다중 작업 분류)을 포함합니다. 또한, explainability tools (설명 가능 도구)를 사용하여 잠재적인 편향을 식별하고, 가용성과 공정성을 보장합니다.

- **Performance Highlights**: 제안된 프레임워크는 violence detection (폭력 탐지) 작업에서 97.99%의 정확도, shoplifting detection (도난 탐지) 작업에서 83.59%, 두 데이터셋을 사용하는 단일 classifier로 재훈련 없이 88.37%의 정확도를 달성했습니다. 또한, 새로운 데이터셋에서도 87.25%의 정확도를 기록하였습니다. 이는 비디오 이상 탐지에서 일반화 문제를 성공적으로 해결한 첫 사례로, 이 분야에서의 중대한 진전을 의미합니다.



### Improving Air Mobility for Pre-Disaster Planning with Neural Network Accelerated Genetic Algorithm (https://arxiv.org/abs/2408.00790)
Comments:
          7 pages, 8 figures, ITSC 2024

- **What's New**: 이번 연구에서는 자연 재해 발생 전 공항 운영을 최적화하기 위한 새로운 프레임워크를 제안합니다. 방재 상황 접근 전 단계에서 다중 공항의 운영 데이터를 통합한 후, 정기 항공편에 지장을 주지 않으면서 영향을 받는 공항의 최대 출항 수용량을 달성하는 최적의 대피 항공편 수를 결정합니다. 이를 위해 Neural Network(NN)과 Genetic Algorithm(GA)을 결합한 혁신적인 접근 방식을 제안합니다.

- **Technical Details**: 본 연구는 자연 재해와 같은 비상 상황에서 항공교통을 효과적으로 계획할 수 있도록 NN과 GA를 결합한 프레임워크를 사용합니다. 특히, GA의 반복 횟수와 인구 군(pool)의 크기를 줄여 최적 솔루션에 도달하는데 필요한 계산 오버헤드를 줄이는 것을 목표로 합니다. 연구의 두 가지 주요 측정항목은 비상 상황에서 공항의 평균 비상 항공 운항 능력(c)과 그 표준편차(s)로, 이를 수학적 모델에 기반하여 최적화합니다.

- **Performance Highlights**: 제안된 프레임워크는 실제 비행 운영 데이터를 기반으로 평가되었으며, GA와 NN을 결합함으로써 기존 방법론과 유사한 결과를 제공하면서도 계산 오버헤드는 줄일 수 있었습니다. 특히 NN을 사용해서 GA가 더 빠르게 수렴될 수 있었으며, 이는 훈련 데이터와 다른 공항에서도 여전히 효과적임을 확인할 수 있었습니다.



### Machine Learning for Dynamic Management Zone in Smart Farming (https://arxiv.org/abs/2408.00789)
- **What's New**: 이 논문은 기계 학습(ML) 클러스터링 알고리즘을 기반으로 작물 수확량 데이터, 고도 및 토양 질감 지도, 그리고 NDVI 데이터를 사용하여 동적 관리 구역을 구분하는 방법을 제안합니다. 이 새로운 접근법은 농업 전문가들이 작물 수익 구역의 공간 변동을 분석하고 경제적이면서 지속 가능한 현장별 관리 방식을 채택하는 데 도움이 됩니다.

- **Technical Details**: 제안된 방법은 작물 수확량, 고도 및 토양 질감 데이터, NDVI 데이터를 이용해 기계 학습 클러스터링 알고리즘을 적용합니다. 주어진 필드의 경계 지도에 기반한 10mx10m 그리드를 생성하여 시간 독립적인 그리드를 만듭니다. 데이터 포인트는 필드 경계로부터 20m 안쪽에 있는 경계에서 제외됩니다. 모라노의 클러스터링(Moran's LISA clustering)과 지리적으로 가중치가 있는 회귀(GWR)를 사용하여 주요 요인을 식별합니다.

- **Performance Highlights**: 수확량 빈도 맵을 사용해 작물 성장 기간 동안 동적으로 변화하는 문제를 포착할 수 있습니다. 제안된 관리 구역 구분 방법은 위성 기반 NDVI 모니터링을 통해 수확량 잠재력과 안정성 구역을 분석하여 가변 비율 질소(N) 비료의 더 효율적인 적용을 지원합니다. 이 접근법은 농업 전문가들이 현장에서 문제를 지속적으로 파악하고 해결하기 위한 경제적이고 지속 가능한 의사 결정을 내리도록 합니다.



### Whether to trust: the ML leap of faith (https://arxiv.org/abs/2408.00786)
Comments:
          12 pages, 12 figures

- **What's New**: 이번 연구에서는 사용자가 ML(머신러닝)을 신뢰할 때 발생하는 Leap of Faith(LoF)를 식별하고 측정할 수 있는 새로운 방법을 제안합니다. LoF 매트릭스를 통해 ML 모델이 사용자의 정신 모델에 얼마나 부합하는지를 시각적으로 대비할 수 있습니다. 이는 신뢰 메트릭을 통해 사용자의 행동을 통해 신뢰도를 처음으로 측정하고 이를 결과와 연결시킬 수 있는 방안을 제시합니다. 연구는 AI가 내장된 수면 개선 시스템의 3개월 파일럿 테스트를 통해 새로운 접근 방식을 설명합니다.

- **Technical Details**: LoF 매트릭스는 사용자의 데이터와 목적 함수를 ML 모델과 규칙 기반 AI 모델에 입력하여 매칭을 식별합니다. 규칙 기반 AI 모델은 전문가들에 의해 검증된 참조 점으로, 사용자의 정신 모델과 미리 비교가 가능합니다. 이를 통해 ML 모델의 결과물과 사용자의 기대치를 대비하여 LoF를 시각적으로 식별하고 측정할 수 있습니다. 또한 신뢰 메트릭을 통해 사용자가 행동을 통해 신뢰를 보여주는지 처음으로 측정하고, 정당한 신뢰를 결과와 연결시킵니다.

- **Performance Highlights**: 제안된 LoF 매트릭스와 신뢰 측정 접근 방식은 3개월 동안 진행된 고위험 환경의 수면 개선 시스템 파일럿 테스트에서 검증되었습니다. 이 방식은 사용자가 ML을 신뢰할 때의 Leap of Faith를 명확히 하고, 이를 통해 신뢰도 향상 및 정당화 여부를 평가하여 신뢰할 수 있는 ML 도입을 지원합니다.



### In-Depth Analysis of Emotion Recognition through Knowledge-Based Large Language Models (https://arxiv.org/abs/2408.00780)
Comments:
          7 pages

- **What's New**: 이번 논문은 상황 맥락(Context)을 통합한 감정 인식에 대한 새로운 접근 방식을 제안합니다. 기존의 자동 감정 인식이 표정만을 독립적으로 분석하는 데 주로 집중한 반면, 본 연구는 심리학 이론에 기반해 상황 기반의 감정 인식 방법을 설계하고, 이를 통해 감정 인식 정확도를 높일 수 있음을 증명했습니다.

- **Technical Details**: 제안된 방법은 감정 인식의 세 가지 주요 단계로 구성됩니다. 첫째, 상황 맥락 없이 표정만으로부터 감정을 예측합니다. 둘째, 상황 설명만을 통해 감정을 예측합니다. 마지막으로, Bayesian Cue Integration(BCI)를 통해 두 분리된 정보원을 통합합니다. 이를 통해 감정 인식의 정밀성을 크게 향상시켰습니다. 테스트는 감정적 사회 과제인 죄수의 딜레마(prisoner’s dilemma)를 바탕으로 수행되었습니다.

- **Performance Highlights**: 비교 결과, 최상의 자동 감정 인식 방법은 인간 관찰자와 유사한 성능을 보여주었습니다. 특히, LSTM 모델과 GPT-4를 이용한 BCI는 다른 방법들에 비해 상황 맥락을 반영한 감정 인식에서 우수한 성능을 나타냈습니다. Fig. 4와 Fig. 5를 통해 맥락을 통합한 감정 인식이 보다 다양한 감정 예측을 가능하게 하는 것을 확인할 수 있습니다.



### Learning Structurally Stabilized Representations for Multi-modal Lossless DNA Storag (https://arxiv.org/abs/2408.00779)
- **What's New**: 이번 논문에서는 Reed-Solomon 부호화된 단일 가닥 표현 학습(RSRL)이란 새로운 DNA 저장용 다중 모달 무손실 데이터 저장을 목적으로 하는 엔드 투 엔드 모델을 제안합니다. RSRL은 오류 수정 코드와 구조 생물학에서 영감을 받아 개발되었습니다. 기존의 학습 기반 방법과 달리, RSRL은 Reed-Solomon 부호화를 통해 이진 데이터를 변환한 후 데이터 표현을 학습합니다. 그 후 RS 코드 정보를 포함한 마스크를 사용하여 학습 과정에서 발생하는 버스트 오류를 수정하며 표현을 마스킹합니다.

- **Technical Details**: RSRL은 먼저 Reed-Solomon(RS) 코드로 변환된 이진 데이터에서 학습 표현을 생성합니다. 그런 다음 이 표현을 RS 코드 정보가 담긴 마스크로 마스킹하여 학습 과정에서 발생하는 버스트 오류를 수정합니다. 디코딩된 데이터 표현에는 새로운 생물학적으로 안정된 손실 함수가 적용되어 단일 가닥 구조를 유지하도록 합니다. RSRL의 데이터 표현은 높은 내구성, 고밀도 및 무손실의 특성을 가집니다.

- **Performance Highlights**: RSRL은 실제 다중 모달 데이터 저장 작업에서 여러 강력한 기준선 모델들과 비교되었습니다. 실험 결과 RSRL은 정보 밀도를 18% 증가시키고 열역학 성능을 11% 향상시키며, 코딩 및 디코딩 지연을 100배 이상 줄였습니다. 이러한 결과는 DNA 저장 기술 분야에서 중요한 진전을 의미합니다.



### Frontend Diffusion: Exploring Intent-Based User Interfaces through Abstract-to-Detailed Task Transitions (https://arxiv.org/abs/2408.00778)
- **What's New**: Generative AI의 등장으로 사용자 인터페이스가 명령 기반에서 의도 기반으로 변화하고 있습니다. 이번 논문은 이러한 새로운 패러다임을 탐구하기 위해 'Frontend Diffusion'이라는 도구를 소개합니다. 이 도구는 사용자의 스케치로부터 고품질의 웹사이트를 생성하는 시스템으로, 스케치, 작성, 코딩의 세 가지 단계로 이루어진 작업 전환 프로세스를 통해 작동합니다.

- **Technical Details**: Frontend Diffusion은 Claude 3.5 Sonnet이라는 대형 언어 모델(LLM)을 이용해 텍스트와 코드를 생성합니다. 시스템은 먼저 사용자의 스케치를 SVG 형식으로 변환한 다음, 이를 JPG 형식으로 변환합니다. 이 후 시스템은 이러한 입력을 'PRD(Product Requirements Document)'라는 구조화된 문서로 변환하고, Pexels API를 활용해 이미지를 통합합니다. 코딩 단계에서는 PRD와 사용자 입력을 사용해 초기 코드를 생성한 다음, 반복적인 수정을 통해 기능을 더하고 결함을 줄입니다.

- **Performance Highlights**: 생성된 웹사이트는 내용, 이미지, 색상, 레이아웃 및 기능 면에서 적절한 시각적 만족도를 보였습니다. 연구 팀은 이 작업 전환 패러다임이 의도 기반 인터페이스를 탐구하는 데 더 많은 가능성을 열어준다고 주장하며, 비디오 생성과 같은 더 복잡하고 상호 의존적인 작업에도 이러한 접근법을 확장할 수 있을 것이라고 제안합니다.



### Decoding AI and Human Authorship: Nuances Revealed Through NLP and Statistical Analysis (https://arxiv.org/abs/2408.00769)
- **What's New**: 이번 연구는 인간이 작성한 텍스트와 인공지능(AI)이 생성한 텍스트 간의 미묘한 차이점을 탐구합니다. 이를 통해 언어 표현 방식의 차이를 밝히고, 창의성 패턴 및 본질적 편향을 조사하여 AI가 문학, 커뮤니케이션 및 사회적 구조에 미치는 영향을 이해하는 데 기여합니다.

- **Technical Details**: 이 연구는 LLMs (Large Language Models)가 생성한 텍스트와 인간이 작성한 텍스트로 구성된 50만 개의 에세이를 포함하는 엄선된 데이터를 체계적으로 전처리하고, 철저한 통계 분석을 통해 수행되었습니다. 연구결과, 인간이 작성한 에세이는 평균 단어 수가 더 많지만 평균 단어 길이는 AI가 생성한 에세이보다 짧습니다. 또한, 인간이 작성한 콘텐츠의 어휘 다양성은 AI가 생성한 콘텐츠보다 높지만, AI 생성 에세이의 참신성 수준이 약간 더 높습니다.

- **Performance Highlights**: 이 연구는 AI 모델의 언어 생성 능력을 평가하는 데 있어 직면한 과제를 다루며, 인간-AI 협업 작문의 복잡성을 반영하는 데이터셋의 중요성을 강조합니다. 체계적 전처리와 철저한 통계 분석을 통해 AI 생성 콘텐츠의 발전 모습을 제시하고, 향후 자연어 처리(NLP) 분야의 발전을 위한 귀중한 통찰을 제공합니다.



### Comparing Optical Flow and Deep Learning to Enable Computationally Efficient Traffic Event Detection with Space-Filling Curves (https://arxiv.org/abs/2408.00768)
Comments:
          27th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2024)

- **What's New**: 트래픽 상황에서 이벤트 식별 및 데이터를 수집하는 문제는 여전히 시스템 성능 평가에 중요한 도전 과제입니다. 이 연구에서는 Optical Flow (OF)와 Deep Learning (DL)을 비교하여, 차량의 전방 카메라 비디오 데이터에서 공간 채우기 곡선(space-filling curves)을 통해 컴퓨터 효율적인 이벤트 감지 방법을 제안합니다. OF를 이용한 접근법은 주변 차량의 예상치 못한 방해물을 감지하고, DL 접근법은 인간의 시각 주의를 학습해 운전자의 시선을 예측하여 잠재적인 이벤트 위치를 찾아냅니다.

- **Technical Details**: OF 기반 접근법은 차량 주변의 예상치 못한 방해물을 감지하는데 탁월하며, DL 모델은 사람의 시각 주의를 학습해 운전자의 시선을 예측하여 잠재적인 이벤트 위치를 식별합니다. 이 결과들은 공간 채우기 곡선을 통해 차원 축소되어, 효율적인 이벤트 검색이 가능합니다. 실험은 대규모 가상 데이터 세트 (SMIRK) 와 실제 데이터 세트 (Zenseact Open Dataset, ZOD)를 사용하여 체계적으로 평가되었습니다.

- **Performance Highlights**: OF 접근법은 특이도(specificity)에서 뛰어나고 오탐(false positives)을 줄이는 데 유리하며, DL 접근법은 민감도(sensitivity)에서 우수한 성능을 보입니다. 두 접근법은 모두 실시간 응용에 적합한 처리 속도를 특징으로 하며, 시간과 확장성 측면에서 유사한 성능을 보였습니다.



### Characterizing User Archetypes and Discussions on Scored.co (https://arxiv.org/abs/2407.21753)
- **What's New**: 이 논문은 소셜 하이퍼네트워크(Social Hypernetwork) 내에서 노드와 하이퍼엣지(hyperedge)를 특성화하기 위한 다차원 프레임워크를 소개합니다. 저자들은 'Scored.co'라는, 잘 연구되지 않은 우익 성향의 소셜 플랫폼을 중심으로 연구를 진행했습니다. 본 연구는 사용자의 활동, 감정(sentiment), 독성(toxicity) 등 다양한 노드 특징을 통합하여 독특한 사용자 전형(archetype)을 정의하고 이들의 네트워크 내 역할을 이해하고자 합니다.

- **Technical Details**: 논문에서는 하이퍼네트워크 표현을 통해 고차원 상호작용(higher-order interactions)을 연구할 수 있는 가능성을 통합합니다. 사용자의 활동, 감정, 독성 같은 다양한 노드 특징을 분석하고, 하이퍼엣지의 특성을 정의하여 사용자 전형을 생성하는 프레임워크를 제안합니다. 또한, Scored.co 플랫폼의 종합 데이터셋을 이용하여 시간 경과에 따른 이러한 전형의 역동성을 분석하고, 커뮤니티 내에서의 상호작용과 영향을 탐구합니다.

- **Performance Highlights**: 제안된 프레임워크의 유연성 덕분에 개별 사용자 행동과 더 넓은 사회 구조 모두에 대해 상세한 분석이 가능하다는 점이 강조되었습니다. 연구 결과는 고차원 상호작용이 사회적 역학을 이해하는 데 있어 중요함을 강조하며, 복잡한 온라인 환경에서 나타나는 역할과 행동에 대한 새로운 통찰을 제공합니다.



### DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency (https://arxiv.org/abs/2408.00741)
- **What's New**: 최근 생성형 대형 언어 모델(generative large language models, LLM)의 급속한 발전과 널리 퍼진 채택으로 인해 이는 다양한 응용 프로그램에서 필수적인 역할을 하고 있습니다. LLM 추론 클러스터는 엄격한 서비스 수준 목표(SLOs)를 요구하는 많은 수의 쿼리를 처리합니다. 이러한 환경에서 에너지 효율을 최적화하기 위해 DynamoLLM이라는 최초의 에너지 관리 프레임워크가 제안되었습니다. DynamoLLM은 자동으로 추론 클러스터를 재구성하여 성능 SLO를 준수하면서 에너지 소비와 비용을 절감합니다.

- **Technical Details**: DynamoLLM은 LLM 추론 환경의 독특한 특성을 활용하여 에너지 소비를 절감하고 성능을 유지합니다. 이 시스템은 모델의 에너지-성능 프로파일을 사용하여 자동으로 에너지 효율적인 구성을 선택합니다. 서버 인스턴스 수 조정, 모델 병렬화, GPU 주파수 조정을 포함한 여러 조정 요소(노브)를 활용합니다. DynamoLLM은 다양한 유형의 요청에 최적화된 여러 LLM 인스턴스 풀을 유지하며, 시간에 따라 요청 분포가 변할 때 동적으로 풀을 크기 조정합니다. DynamoLLM은 계층적 컨트롤러 구조를 사용하여 계산 복잡성을 줄이고 중앙 집중식 병목 현상을 제거합니다. 또한, 빈번하고 부드러운 전환을 위해 재구성 오버헤드를 최소화하는 기술을 포함하고 있습니다.

- **Performance Highlights**: DynamoLLM을 주요 클라우드 제공자의 실제 프로덕션 수준의 트레이스에서 평가한 결과, 에너지를 53% 절약하고 운영 탄소 배출량을 38% 줄이며 고객 비용을 61% 감소시켰으며, 지연 시간 SLO를 충족했습니다. 이 프레임워크는 높은 수준의 효율성 및 서비스 품질을 유지하면서 변동하는 워크로드 수요에 대응할 수 있습니다.



### An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models (https://arxiv.org/abs/2408.00724)
- **What's New**: 이번 연구는 대형 언어 모델(LLMs)의 최적 추론 구성 방안에 대해 조사한 결과입니다. 연구진은 다양한 추론 방식, 예를 들어 Greedy Search, Majority Voting, Best-of-N, Weighted Voting 등을 사용하여 최적의 성능과 계산 비용 간의 균형을 찾아냈습니다. 특히, 소형 언어 모델과 새롭고 정교한 Tree Search 알고리즘을 결합하여 예산 제한 시나리오에서 높은 문제 해결 정확성을 도출할 가능성이 있음을 확인했습니다.

- **Technical Details**: 연구는 수학적 추론 벤치마크(MATH500 및 GSM8K 테스트 세트)를 통해 다양한 모델 크기와 추론 알고리즘의 성능을 정밀하게 평가했습니다. 여기에는 Greedy Search, Majority Voting, Best-of-N, Weighted Voting 및 이들의 Tree Search 변형 관련 실험이 포함됩니다. 또한, 연구진은 새로운 REward BAlanced SEarch (REBASE) 알고리즘을 제안하여 MCTS 방법보다 적은 FLOPs로 더 높은 정확성을 달성했습니다.

- **Performance Highlights**: Llemma-7B 모델이 Llemma-34B 모델과 비교하여 두 배 적은 FLOPs를 사용하면서도 유사한 정확성을 나타냈습니다. REBASE 알고리즘이 포함된 소형 언어 모델이 전반적으로 Pareto-optimal trade-off를 달성하며, 예산이 제한된 실제 상황에서도 소형 모델의 이점을 증명했습니다.



### Can Developers Prompt? A Controlled Experiment for Code Documentation Generation (https://arxiv.org/abs/2408.00686)
Comments:
          Accepted at the 40th IEEE International Conference on Software Maintenance and Evolution (ICSME)

- **What's New**: 이번 연구는 대형 언어 모델(LLMs)이 코드 문서화를 자동화하는 데 있어 얼마나 효과적으로 사용할 수 있는지를 조사합니다. 특히 개발자가 간결하고 유용한 문서화를 생성하기 위해 LLMs를 어떻게 프롬프트(Prompt)할 수 있는지에 중점을 두었습니다. 20명의 전문 개발자와 30명의 컴퓨터 공학 학생을 대상으로 컨트롤된 실험을 수행했습니다.

- **Technical Details**: 실험 참가자들은 두 개의 Python 함수에 대한 코드 문서화 생성 작업을 수행했습니다. 실험 그룹은 Visual Studio Code의 ChatGPT와 유사한 확장 프로그램을 사용하여 즉흥적인 프롬프트를 입력한 반면, 통제 그룹은 미리 정의된 few-shot 프롬프트를 실행했습니다. 실험 결과에 따르면, 참가자들은 프롬프트 엔지니어링 기술에 대한 인식이 부족하거나 이를 적용하지 못했습니다.

- **Performance Highlights**: 학생들은 즉흥적인 프롬프트로 생성된 문서의 가독성과 간결성, 유용성이 확연히 낮다고 판단했으며, 일부 전문가는 ad-hoc 프롬프트에 'Docstring' 키워드를 포함시킴으로써 더 높은 품질의 문서를 생성할 수 있었습니다. 학생들은 프롬프트를 작성하는 데 더 많은 지원이 필요하다고 느낀 반면, 전문가는 adhoc 프롬프트의 유연성을 높이 평가했습니다. 두 그룹 모두 도구의 출력을 완벽하게 평가한 경우는 드물었습니다. 대신, 도구를 문서화를 점진적으로 수정하는 지원 도구로 이해했습니다.



### SentenceVAE: Faster, Longer and More Accurate Inference with Next-sentence Prediction for Large Language Models (https://arxiv.org/abs/2408.00655)
Comments:
          Modified some of the expression details and optimized the charts

- **What's New**: 현재의 대형 언어 모델(LLMs)은 주로 다음 토큰 예측 방식을 사용하여 추론 시간을 지연시키는데, 본 논문에서는 이를 개선하기 위해 '다음 문장 예측(next-sentence prediction)'이라는 새로운 추론 방식을 소개했습니다. 이를 위해 SentenceVAE라는 작은 모델을 도입했습니다. SentenceVAE는 인코더와 디코더로 구성되어 문장의 정보를 압축하여 하나의 토큰으로 변환하고, 이를 다시 원래의 문장 형식으로 복원합니다.

- **Technical Details**: SentenceVAE는 문장을 여러 토큰으로 분리한 후, 이를 단일 토큰으로 압축하는 인코더와 다시 원래의 단어 단위 토큰 시퀀스로 재구성하는 디코더로 구성되어 있습니다. SentenceVAE를 대형 언어 모델의 입력 및 출력 계층에 통합해, 문장 단위로 추론을 수행하는 SLLMs(Sentence-level LLMs)를 개발하였습니다. 이를 통해 문장을 단위로 나누어 추론 속도를 가속화하면서도 원래의 의미적 일관성을 유지할 수 있습니다.

- **Performance Highlights**: SentenceVAE를 사용한 SLLMs는 기존의 LLMs보다 204~365% 더 빠른 추론 속도를 보였으며, 혼잡도(perplexity)가 46~75% 감소했습니다. 또한 동일한 컨텍스트 길이에서 메모리 오버헤드가 86~91% 감소했음을 확인했습니다. 이 접근 방식의 장점은 모델 매개변수(parameter)가 증가할수록 더욱 증폭되었습니다.



### Unlocking Fair Use in the Generative AI Supply Chain: A Systematized Literature Review (https://arxiv.org/abs/2408.00613)
- **What's New**: 이 논문은 생성형 AI(GenAI)의 다양한 이해관계자들의 목표와 기대를 체계적으로 분류하여, 이들이 GenAI 공급망에 기여하는 가치를 분석합니다. 특히, GenAI 회사들이 '공정 사용(fair use)'을 주장하며 저작권법의 과학 및 예술 촉진 목적에 얼마나 부합하는지 평가합니다.

- **Technical Details**: 이 연구는 Human-Computer Interaction (HCI) 문헌의 체계적인 문헌 리뷰를 기반으로 PRISM 진술에 따라 수행되었습니다. 연구 질문에 대한 답을 얻기 위해 2014년 1월 1일부터 2024년 4월 30일까지의 데이터를 대상으로 다양한 키워드 조합을 사용하여 5895개의 관련 논문을 검색했습니다. 또한, 이해관계자들을 GenAI 공급망의 각 단계에 맞춰 매핑하였습니다.

- **Performance Highlights**: 연구 결과, GenAI 모델 훈련에서의 '공정 사용' 주장과 관련하여 저작권법의 목적 달성 여부를 파악할 수 있었습니다. 이를 통해 향후 연구 방향과 정책 입안자들이 다루어야 할 연구 공백도 발견되었습니다. 특히, 창작자들의 권리 보호와 과학 및 예술의 진보 사이의 균형을 맞추는 것이 중요함을 강조합니다.



### Illustrating Classic Brazilian Books using a Text-To-Image Diffusion Mod (https://arxiv.org/abs/2408.00544)
Comments:
          7 pages, 2 figures

- **What's New**: 최근 몇 년 사이, 생성 인공지능(Generative Artificial Intelligence, GenAI)은 텍스트, 오디오, 비디오, 이미지 생성과 같은 다양한 형태의 데이터를 처리하는 능력에서 큰 발전을 이루었습니다. 이 논문은 잠재 확산 모델(Latent Diffusion Models, LDMs)의 혁신적 기법을 이용하여 브라질의 고전 문학 작품을 삽화로 만드는 실험을 다루고 있습니다. 이를 통해 생성된 삽화들이 독자의 경험을 풍부하게 할 수 있는지를 평가하고자 합니다.

- **Technical Details**: 이 연구에서는 7개의 브라질 고전 문학 작품을 선택하여 Stable Diffusion 모델을 사용해 텍스트 기반 삽화를 생성했습니다. 두 단계의 방법론을 사용하여 Stable Diffusion XL Base 1.0을 통해 초기 이미지를 생성한 후, Stable Diffusion XL Refiner 1.0으로 그 이미지를 정제했습니다. 3090 GPU를 사용한 하드웨어 환경에서 모든 연산을 수행했습니다. 각 텍스트에서 도출된 텍스트 프롬프트를 바탕으로 시각적 콘텐츠를 생성하였으며, 클립 점수(CLIP Score)와 귀환 점수(Inception Score)를 통해 결과를 평가했습니다.

- **Performance Highlights**: 프롬프트 설계의 중요성은 생성된 이미지의 품질 및 정확도에서 두드러졌습니다. 'Senhora'와 'O Triste Fim de Policarpo Quaresma'와 같은 작품에서는 모델 편향으로 인해 주로 백인 인물이 그려지는 문제가 발생했습니다. 그러나 'Horto'와 'O Triste Fim de Policarpo Quaresma'에서는 비교적 성공적으로 시각화를 이루어냈습니다. 이는 텍스트 프롬프트의 구체성, 모델 훈련 및 개선이 얼마나 중요한지를 보여줍니다. 향후 프롬프트 엔지니어링과 모델 훈련의 개선이 필요함을 확인했습니다.



### A new approach for encoding code and assisting code understanding (https://arxiv.org/abs/2408.00521)
Comments:
          10 page, 14 figures

- **What's New**: 이번 연구에서는 기존 GPT의 autoregressive(next-word prediction) 패러다임의 제한점을 극복하기 위한 새로운 접근 방식을 제안합니다. 특히 코드 이해를 개선하기 위해 이미지를 생성하는 데 성공적으로 사용된 diffusion techniques를 기반으로 한 새로운 인코딩 방식을 도입했습니다.

- **Technical Details**: 기존 GPT는 autoregressive 방식으로 다음 단어를 예측하여 텍스트를 생성하지만, 이는 계획, 작업 기억, 백트래킹, 그리고 논리적 추론 능력이 부족하다는 문제가 있습니다. 우리는 코드 이해에서 이러한 제한점을 확인했습니다. 연구진은 텍스트를 자연어가 아닌, 복합적 이미지(heterogeneous image)로 인코딩하는 새로운 방법을 제안하고, CLIP 기반의 새로운 텍스트-코드 인코더 모델을 설계했습니다.

- **Performance Highlights**: 456,360개의 텍스트-코드 쌍을 사용한 비지도 학습(self-supervised learning)을 통해 제안된 모델은 새로운 데이터에 대한 zero-shot 예측 성능을 달성했습니다. 이는 향후 diffusion 기술을 활용한 코드 생성 작업의 기초가 될 수 있습니다.



### HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization (https://arxiv.org/abs/2408.00481)
Comments:
          System Demonstration

- **What's New**: 전통 중국 의학(TCM)의 독특한 진단 및 치료 기술과 뛰어난 임상 효능이 특히 노인 케어와 헬스케어 분야에서 중요한 역할을 합니다. 이를 바탕으로, TCM 챗봇을 개발하여 사용자가 직관적이고 자연스러운 방식으로 상담 서비스를 받을 수 있도록 합니다. HBot은 3D 인체 모델과 지식 그래프를 기반으로 한 헬스케어 챗봇으로, 지식 Q&A, 처방 추천, 뜸 요법(moxibustion therapy) 추천, 그리고 경혈(acupoint) 검색 등의 대화형 서비스를 제공합니다.

- **Technical Details**: HBot은 인체 모델을 3D로 시각화하여 경혈의 위치를 직관적으로 보여줍니다. 이는 HBot이 빨리 숙달할 수 있도록 도와줍니다. 사용자 인터페이스는 네비게이션 바, 3D 인체 대시보드, 대화 프레임, 멀티미디어 보드로 나누어져 있습니다. HBot의 시스템 아키텍처는 6개의 주요 모듈로 구성됩니다: Interactive 3D Body, User Intent Detection, Entity&Relation Extraction, LLM Handler, LLM Wrapper, Knowledge Graph Construction. 이 모듈들은 사용자의 질의를 처리하고 적절한 응답을 생성하는 역할을 합니다.

- **Performance Highlights**: HBot의 기능은 인간 평가를 통해 견고성이 입증되었습니다. 의도 감지(intent detection), 엔티티 및 관계 추출(entity & relation extraction), 지식 쿼리(knowledge query)와 같은 기능들이 공개 API로 제공될 예정입니다. 또한, 3D 모델은 다양한 상호작용을 지원하며, 사용자는 웹 브라우저를 통해 쉽게 접근할 수 있습니다.



### Ontological Relations from Word Embeddings (https://arxiv.org/abs/2408.00444)
- **What's New**: 최근 연구에서 BERT와 같은 인기 있는 신경 모델로부터 도출된 단어 임베딩이 단어의 의미적 유사성을 효과적으로 근사함이 입증되었습니다. 본 연구는 이러한 임베딩이 서브섬션(subsumption)과 같은 존재론적 관계를 연결할 수 있을지 탐구합니다. 이 논문에서는 여러 사전 학습된 모델로부터 생성된 임베딩을 사용하여 클래스를 예측하는 모델을 테스트하며, 단순한 피드포워드 아키텍처로도 유망한 정확도를 달성할 수 있음이 밝혀졌습니다.

- **Technical Details**: 본 연구는 BERT와 같은 대형 언어 모델로부터 생성된 단어 임베딩을 이용하여 웹 온톨로지의 클래스를 예측하는 간단한 모델을 제안합니다. 사전 학습된 네 가지 트랜스포머 기반 모델을 사용하며, 각 엔터티의 이름과 설명을 임베딩으로 변환하고, 평균 풀링(mean-pooling)을 통해 하나의 벡터로 집계합니다. 이 벡터는 Fully Connected Layers와 ReLU 활성 함수를 포함하는 간단한 신경망 모델의 입력으로 사용되며, 최종 출력은 20차원의 벡터로 구성됩니다. 이 벡터는 20개의 예측된 존재론적 관계를 나타내며, 크로스 엔트로피 손실 함수를 통해 실제 관계와 비교됩니다.

- **Performance Highlights**: 실험 결과, 간단한 피드포워드 아키텍처를 사용한 클래스를 예측하는 모델이 다양한 ontologies에 대해 유망한 정확도를 보였습니다. 또한, 여러 모델을 교차 검증한 결과, 다양한 입력 데이터에 따라 일반화 능력이 변화함을 확인할 수 있었습니다. 이는 대형 열린 도메인에서 존재론적 관계를 내포하고 추론할 수 있는 지식 모델 개발의 가능성을 시사합니다.



### Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures (https://arxiv.org/abs/2408.00399)
Comments:
          26th International Conference of the Catalan Association for Artificial Intelligence

- **What's New**: 이번 연구에서는 두 변수만을 사용하는, 즉 쌍변량(pairwise) 설정에서 인과 관계를 발견하는 방법의 일반화 가능성을 목표로 하였습니다. 기존의 감독 학습(supervised learning)으로 얻어진 기준선 결과가 잘못된 해석을 유도할 수 있다는 문제 제기를 하였습니다. 따라서, 비감독 학습(unsupervised learning) 접근 방식을 사용하여 서로 다른 변수 유형을 고려한 새로운 표준 편향 없는 결과를 제시하였습니다.

- **Technical Details**: 이번 연구는 인과 발견(Causal Discovery) 방법론의 조합을 통해 기존의 감독 학습 접근 방식이 아닌, 비감독 학습 접근 방식을 따릅니다. 구체적으로는 강건한 상호 정보(Mutual Information) 측정을 사용하고, 다양한 무조건 독립성 테스트를 결합합니다. 필수적인 개념으로는 기능적 인과 모델(Functional Causal Models; FCM) 및 선형 애디티브 노이즈 모델(linear additive noise models)이 포함됩니다.

- **Performance Highlights**: 제안된 방법은 변수 유형과 데이터의 다양성을 고려하여 쌍변량 인과 발견의 기준 벤치마크 결과를 재평가합니다. 이를 통해 잘못된 방향의 독립성이 위반되는 경우를 관찰할 수 있으며, 결과적으로 완전히 알려지지 않은 환경에서 인과 발견 작업을 안내할 수 있는 참조 지표를 제공합니다.



### Conformal Trajectory Prediction with Multi-View Data Integration in Cooperative Driving (https://arxiv.org/abs/2408.00374)
- **What's New**: V2INet은 다중 뷰 데이터를 효율적으로 모델링하기 위해 기존의 단일 뷰 모델을 확장하여 새로운 경로 예측 프레임워크를 소개합니다. 이 접근 방식은 비슷한 방식으로 다수의 뷰를 수동으로 병합하거나 별도 학습 단계를 필요로 하는 이전 방법들과 달리, end-to-end 방식의 훈련을 지원하여 유연성과 성능을 증대시킵니다. 또한, 예측된 다중 모드 궤적을 칼리브레이션하는 사후 적합 예측 모듈을 도입하여 유효하고 효율적인 신뢰 구간을 제공합니다.

- **Technical Details**: 이 모델은 단일 뷰 데이터에서 수집한 궤적 정보를 그래프 신경망(GNN) 기반 모델(LaneGCN, HiVT 등)을 활용하여 시간 의존성, 에이전트 간 상호 작용, 에이전트-차선 관계를 캡처한 후, 서로 다른 뷰에서 수집된 노드 임베딩을 교차 그래프 주의 모듈을 통해 병합합니다. 그런 다음 융합된 최종 임베딩은 다중 모드 디코더를 통해 미래 궤적 예측을 생성합니다. 추가적으로, CP(Conformal Prediction) 모듈은 사후적 예측 결과를 캘리브레이션하여 사용자 지정 확률로 실제 값을 포함하는 신뢰 구간을 제공합니다.

- **Performance Highlights**: V2INet 프레임워크는 실제 V2I 데이터셋 V2X-Seq를 사용하여 평가되었으며, Final Displacement Error(FDE)와 Miss Rate(MR) 측면에서 단일 GPU로 우수한 성능을 보였습니다. 이는 이전 모델들과 비교해 더 적은 자원으로 더 높은 예측 성능을 입증합니다.



### Multimodal Fusion and Coherence Modeling for Video Topic Segmentation (https://arxiv.org/abs/2408.00365)
- **What's New**: 이번 연구에서는 비디오 주제 분할(Video Topic Segmentation, VTS) 작업을 개선하기 위해 멀티모달 융합과 멀티모달 일관성 모델링을 철저히 탐구하였습니다. 특히, 다양한 크로스-어텐션(Cross-Attention)과 전문가들의 혼합(Mixture of Experts, MoE)을 활용한 멀티모달 융합 아키텍처를 비교하였습니다. 또한, 멀티모달 대비 학습(contrastive learning)으로 모델을 사전 훈련(pre-train)하고 미세 조정(fine-tune)하는 방법을 제안하였습니다. 새로운 사전 훈련 임무와 멀티모달 일관성 모델링을 향상시키는 미세 조정 임무도 제안하였습니다.

- **Technical Details**: VTS 작업은 비디오를 이해하기 쉬운 비중첩(non-overlapping) 주제로 나누는 작업입니다. 기존의 얕은 기능이나 비지도 학습 방법은 주제 전환의 세부적인 부분을 정확하게 구별하는데 어려움을 겪고 있습니다. 이를 해결하기 위해, 멀티모달 융합을 크로스-어텐션(Cross-Attention)과 전문가들의 혼합(Mixture of Experts, MoE) 아키텍처를 통해 강화하였습니다. 또한, 멀티모달 대비 학습(Multimodal Contrastive Learning)을 이용해 모델을 사전 훈련하고 미세 조정하여 멀티모달 일관성을 강화하였습니다. 교육 비디오, 특히 강의 비디오를 대상으로 새로운 사전 훈련 및 미세 조정 임무를 제안하였습니다.

- **Performance Highlights**: 제안된 방법은 영문과 중국어 강의 비디오 데이터셋에서 경쟁적인 비지도 및 지도 기준 모델들을 능가하는 성능을 보였습니다. 새롭게 구축한 대규모 중국어 강의 비디오 주제 분할 데이터셋(CLVS)을 통해 VTS 연구를 촉진하였습니다. 실험 결과, 제안된 모델이 새로운 state-of-the-art (SOTA) 성능을 설정하였으며, 포괄적인 소거 실험(ablation study)을 통해 접근 방식의 효과성을 확인하였습니다.



### Towards Scalable GPU-Accelerated SNN Training via Temporal Fusion (https://arxiv.org/abs/2408.00280)
Comments:
          International Conference on Artificial Neural Networks (ICANN) 2024

- **What's New**: 본 연구에서는 GPU 플랫폼에서 SNNs(Spiking Neural Networks)의 신호 전파 동역학을 가속화하는 새로운 temporal fusion 방법을 제시합니다. SNNs는 생물학적 신경망의 복잡한 동역학을 모방하는 인공지능의 변혁적인 발전으로 주목받고 있지만, 기존의 GPU를 이용한 훈련 방법은 시간이 많이 소요됨에 따라 연구 발전에 어려움을 겪고 있습니다.

- **Technical Details**: 제안된 방법은 SNNs의 temporal axis를 따라 스파이크 뉴런 모델의 전파 패턴을 분리하는 전략을 도입하여 보다 효율적인 정보 흐름을 촉진하며, 이는 계산 정확도를 유지합니다. 이 방법은 다수의 GPUs를 활용할 수 있도록 확장되었으며, pipeline parallelism 프레임워크를 통해 스파이킹 뉴런의 본질적인 temporal dynamics에 적합하게 설계되었습니다.

- **Performance Highlights**: 제안된 방법은 NVIDIA A100 GPUs에서 기존 SNNs 라이브러리/구현을 기준으로 $5	imes$에서 $40	imes$의 속도 향상을 달성했습니다. 실험 코드도 공개되어 있어, 해당 URL을 통해 접근할 수 있습니다.



### RoCo:Robust Collaborative Perception By Iterative Object Matching and Pose Adjustmen (https://arxiv.org/abs/2408.00257)
Comments:
          ACM MM2024

- **What's New**: RoCo는 협력적 자율 주행에 있어 객체 정렬 문제를 해결하는 혁신적인 비지도 학습 기반 프레임워크입니다. 기존 방식과 달리 객체 매칭(object matching)을 통해 에이전트의 자세(pose)를 조정하는 점이 특징입니다. 이는 협력적 인식에서 자세 보정을 객체 매칭 문제로 모델링한 첫 번째 사례로, 에이전트 간의 공통 객체를 안정적으로 연결합니다.

- **Technical Details**: RoCo는 주로 객체 매칭과 견고한 그래프 최적화 두 부분으로 나뉩니다. 객체 매칭 단계에서는 거리와 주변 구조 일관성을 활용하여 각 에이전트가 감지한 객체 사이의 일치 관계를 형성합니다. 그 후, 그래프 최적화 과정을 통해 에이전트 자세를 전역 관찰 일관성에 따라 점진적으로 조정합니다. 이 과정을 반복하여 최종적으로 일치된 객체 정보를 기반으로 자세를 수정합니다. 타 방법과 달리 RoCo는 추가적인 네트워크 모델 재학습 없이도 다양한 3D 객체 감지 기반 협력 인식 프레임워크에 통합될 수 있습니다.

- **Performance Highlights**: RoCo는 시뮬레이션 및 실제 데이터셋(V2XSet, DAIR-V2X)에서 실험을 수행한 결과, 자세 오류가 있는 상황에서도 꾸준히 기존 방법들보다 우수한 협력적 3D 객체 감지 성능을 보였습니다. RoCo는 혼잡하고 복잡한 환경에서도 높은 수준의 견고성과 정확성을 유지하며, 잡음이 많은 상황에서도 정확하게 객체를 정렬할 수 있습니다.



### Multiple Greedy Quasi-Newton Methods for Saddle Point Problems (https://arxiv.org/abs/2408.00241)
Comments:
          Submitted to DOCS 2024

- **What's New**: 이 논문은 Multiple Greedy Quasi-Newton (MGSR1-SP) 방법론을 소개하며, 이는 강하게 볼록-강하게 오목(SCSC) 안장점 문제를 해결하기 위한 새로운 접근법입니다. MGSR1-SP는 제곱 불확정 헤시안 행렬의 근사치를 향상시켜, 반복적인 그리디 업데이트를 통해 안정성과 효율성을 크게 향상시킵니다.

- **Technical Details**: MGSR1-SP는 제곱 헤시안(Hessian) 행렬의 근사치를 다중 그리디 업데이트 방식으로 개선합니다. 이 알고리즘은 이론적으로 선형-2차 수렴률(linear-quadratic convergence rate)을 보장합니다. 또한, 공변량 편향을 제거하기 위해 AUC 최대화 및 적대적 디바이어싱(adversarial debiasing) 문제에 대한 수치 실험을 통해 우수한 성능을 검증했습니다.

- **Performance Highlights**: 실험 결과, MGSR1-SP는 최첨단 알고리즘 대비 빠른 수렴 속도를 보였으며, 다양한 머신 러닝 애플리케이션에서 효율적이고 정확한 헤시안 근사치가 중요한 영역에서 성능 향상 가능성을 확인했습니다.



### Lost in Translation: Latent Concept Misalignment in Text-to-Image Diffusion Models (https://arxiv.org/abs/2408.00230)
Comments:
          33 pages, 19 figures

- **What's_New**: 새로운 연구는 텍스트에서 이미지로 변환하는 확산 모델(text-to-image diffusion models)에서 발생하는 잠재적 개념 불일치 문제(Latent Concept Misalignment, LC-Mis)을 식별하고 해결하는 방법을 제안합니다. 연구진은 'a tea cup of iced coke'와 같은 문구에서 텍스트와 이미지 간의 불일치 문제가 발생하는 이유를 조사하고 이 문제를 해결하기 위한 자동화된 파이프라인을 개발했습니다. 이 접근법은 LC-Mis 오류를 크게 줄이고 모델의 견고성과 다재다능성을 향상시킵니다.

- **Technical_Details**: 연구진은 대형 언어 모델(LLMs)을 활용하여 LC-Mis 문제의 범위를 철저히 조사하였습니다. 기존 모델에서 텍스트 프롬프트에서 기대하는 개념이 이미지에 제대로 반영되지 않는 문제를 해결하기 위해 'Mixture of Concept Experts (MoCE)'라는 새로운 접근법을 제안했습니다. 또한 입력 텍스트를 확산 모델의 생성 과정에서 두 단계로 분할하여 단계적으로 이미지를 생성하는 방식을 채택했습니다. 이 프로세스는 Clipscore와 Image-Reward와 같은 검증된 지표를 사용하여 이미지와 텍스트 간의 정렬을 측정하고, 이를 통해 최적의 이미지를 생성할 수 있도록 적응합니다.

- **Performance_Highlights**: 새로운 접근법을 통해 LC-Mis 문제를 크게 완화할 수 있었으며, 텍스트에서 이미지로의 변환 모델의 적용성과 유연성을 향상시켰습니다. 실험적 사례 연구를 통해 우리의 방법이 기존 모델보다 뛰어난 성능을 발휘함을 확인했습니다. 연구 결과는 다양한 분야에 걸쳐 이 기술의 가능성을 보여줍니다. 실제로 Midjourney와 SDXL과 같은 최신 모델에서도 우리 방법이 높은 품질의 이미지를 생성하는 데 기여하는 것으로 나타났습니다.



### Finch: Prompt-guided Key-Value Cache Compression (https://arxiv.org/abs/2408.00167)
- **What's New**: 최근 대형 언어 모델(Large Language Models; LLMs)의 응용, 예를 들어 Retrieval-Augmented Generation과 챗봇은 더 긴 입력 컨텍스트를 처리할 필요가 증가하고 있습니다. 이를 해결하기 위해 Finch라는 새로운 접근법을 제안합니다. Finch는 프롬프트와 긴 텍스트를 대상으로 프롬프트를 조건으로 텍스트 청크에서 가장 관련성이 높은 Key (K)와 Value (V) 쌍을 반복적으로 식별하여 입력 컨텍스트를 압축합니다. 이러한 쌍만 KV 캐시에 저장되며, 이는 모델의 컨텍스트 윈도우로 제한된 공간 내에서 최종적으로 긴 텍스트의 압축된 버전을 포함하게 됩니다. Finch는 모델의 추가 학습 없이 대형 입력을 효율적으로 처리할 수 있게 합니다.

- **Technical Details**: Finch는 사전 훈련된 모델의 self-attention 가중치를 활용하여 입력 컨텍스트를 압축합니다. 긴 문서와 입력 프롬프트를 모델 컨텍스트 크기에 맞춰 여러 단계로 처리합니다. 매 단계에서 문서 청크를 처리하며, 프롬프트와 문서 청크 사이의 attention 정보를 사용하여 각 레이어에서 가장 관련성이 높은 KV 쌍을 식별합니다. 이 정보를 KV 캐시에 저장하고 이를 동적으로 선택하여 KV 캐시의 기억 영역을 효과적으로 관리합니다. 이는 새로운 학습이나 외부 모델에 대한 의존 없이 동작하며, 높은 압축률에도 불구하고 모델 응답의 정확성을 유지합니다.

- **Performance Highlights**: Finch는 다양한 태스크에서 2배에서 93배까지의 압축 범위를 달성하며, 대부분의 실험에서 단순한 트렁케이션(truncation) 기준을 능가합니다. 질문 응답 태스크에서 Finch는 2.35배 압축률에서도 비교 가능한 생성 품질을 유지하며, 3.76배 압축률에서도 기준 정확도의 90%를 달성하면서 엔드 투 엔드 실행 시간을 단축시킵니다. LongLLMLingua와 비교했을 때, Finch는 대부분의 태스크에서 최고 품질 점수를 기록하며, 특히 RAG 기반선을 12개의 실험 중 10개에서 능가합니다.



### Formal Ethical Obligations in Reinforcement Learning Agents: Verification and Policy Updates (https://arxiv.org/abs/2408.00147)
- **What's New**: 이번 아카이브(arxiv) 논문에서는 불확실한 환경에서 에이전트가 수행해야 할 행동들을 자동으로 이유화할 수 있는 'Expected Act Utilitarian deontic logic'라고 불리는 새로운 의무론적 논리를 제안합니다. 이를 통해 에이전트의 전략적 의무를 명시하고 검증한 후, 참조 정책을 수정하여 이 의무를 충족할 수 있습니다. 기존의 보상 기반 접근 방식과 달리 논리적 수준에서 작업함으로써 트레이드오프의 투명성을 높였습니다.

- **Technical Details**: 이 논문은 강화 학습(RL) 에이전트가 전략적 의무를 얼마나 잘 충족하는지 모델 검증을 위한 알고리즘과, 참조 정책을 수정하여 의무를 충족시키는 정책 변경 알고리즘을 소개합니다. 이 알고리즘들은 강화 학습 의사결정 정책을 정확하게 추상화하는 DAC-MDPs와 장난감 격자 세계 환경을 사용해 설명되었습니다. 또한, Expected Act Utilitarianism(EAU)을 확장하여 에이전트의 전체 정책에서 의무를 기반으로 하는 전략적 양식을 도입했습니다.

- **Performance Highlights**: 이 논문의 기여는 다음과 같습니다: (1) EAU의 확장을 통해 무한 지평에서 최적 정책으로 충족되어야 할 전략적 의무를 형식화, (2) MDP가 주어진 전략적 의무를 충족하는지 모델 검증하는 알고리즘, (3) 유틸리티 최적화 정책을 의무를 충족하도록 수정하는 알고리즘, (4) 사전 보상이 알려지지 않은 경우를 위한 정책 탐색 알고리즘의 확장, (5) 모델 검증 및 정책 탐색 알고리즘의 효과성을 입증하는 실험적 증거.



### Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs (https://arxiv.org/abs/2408.00114)
- **What's New**: 이번 연구는 대규모 언어 모델(LLMs, Large Language Models)의 추론 능력 중 귀납적 추론(inductive reasoning)과 연역적 추론(deductive reasoning)을 명확히 구분하고, 각각의 과제를 통해 모델의 성능을 평가하는 새로운 프레임워크인 SolverLearner를 제안합니다.

- **Technical Details**: SolverLearner는 (x, y) 입력-출력 데이터 포인트를 통해 함수 y = f_w(x)를 학습함으로써 LLM의 진정한 귀납적 추론 능력을 탐구합니다. 이를 통해 대조적으로 귀납적 추론과 연역적 추론을 분리하여 연구할 수 있게 합니다. 기존 연구는 주로 입력-출력(IO) 예시를 사용한 최적화 방식으로 귀납적 추론을 평가했으나, 이는 연역적 추론 능력과 귀납적 추론 능력을 명확히 구분하지 못했습니다. SolverLearner는 이를 개선하여 외부 인터프리터를 통해 함수를 적용함으로써 LLM의 연역적 추론을 배제하고 귀납적 추론을 평가합니다.

- **Performance Highlights**: 연구 결과, LLM은 SolverLearner를 통해 귀납적 추론에서 거의 완벽에 가까운 성능(대부분의 경우 ACC 1)을 보여주었습니다. 그러나 'counterfactual' 추론과 같은 연역적 추론 과제에서는 상대적으로 약한 성능을 보였습니다. 이는 LLM이 연역적 추론보다는 귀납적 추론에서 더 우수한 능력을 가졌음을 의미합니다.



### Preference-Based Abstract Argumentation for Case-Based Reasoning (with-Appendix) (https://arxiv.org/abs/2408.00108)
Comments:
          Accepted for KR2024. Includes Appendix

- **What's New**: 이 논문은 해석 가능하고 데이터 기반의 분류 모델의 효율성과 유연성을 향상시키기 위해 사용자가 정의한 선호도를 활용하는 새로운 접근법을 소개합니다. 논문에서는 Abstract Argumentation(추상적 논증)과 Case-Based Reasoning(CBR, 사례 기반 추론)을 결합한 Preference-Based Abstract Argumentation for Case-Based Reasoning(AA-CBR-P)를 제안합니다. 사용자가 사례를 비교할 다양한 접근방법을 우선순위에 따라 정의할 수 있게 합니다.

- **Technical Details**: AA-CBR-P 모델은 사용자 정의 선호도를 기반으로 사례를 비교하고 예측할 때 이러한 선호도를 따르는 것을 증명합니다. 이 모델이 기존의 추상적 논증을 이용한 사례 기반 추론 접근법보다 선호도를 더 명확하게 표현할 수 있다는 것을 입증합니다. 또한 실제 임상 시험에서 주로 사용하는 의료 데이터셋에 이 모델을 적용하며 그 효용성을 입증합니다. 이 데이터셋은 주요 뇌종양 환자를 평가하는 다양한 방법을 평가한 임상 시험에서 수집된 것입니다.

- **Performance Highlights**: 실험 결과, AA-CBR-P 접근법은 데이터셋에서 다른 해석 가능한 머신러닝 모델보다 우수한 성능을 보였습니다. 이는 사용자 정의 선호도를 통합한 모델이 진단 및 의사결정에 중요한 역할을 할 수 있다는 것을 나타냅니다.



### Areas of Improvement for Autonomous Vehicles: A Machine Learning Analysis of Disengagement Reports (https://arxiv.org/abs/2408.00051)
- **What's New**: 2023년 캘리포니아 교통국(CDMV)이 자율주행차(AV) 생산업체로부터 수집한 자동운전 모드 이탈(Disengagement) 요인 데이터에 대한 기계 학습(ML) 기반 분석이 발표되었습니다. 이번 연구는 자연어 처리(NLP) 기법을 사용하여 이탈 보고서(DRs) 설명에서 중요한 정보를 추출하고, k-Means 클러스터링 알고리즘을 사용하여 보고 내용을 그룹화했습니다.

- **Technical Details**: 이 연구에서는 NLP 접근법을 활용하여 이탈 설명에서 중요한 정보를 추출하고, 이를 바탕으로 k-Means 클러스터링 알고리즘을 적용하여 보고 항목들을 그룹화했습니다. 클러스터 빈도를 분석한 후 각 클러스터를 이탈 요인에 따라 수동으로 분류하였습니다.

- **Performance Highlights**: 이전 연도 DRs의 발견 사항을 논의하면서, 자율주행차의 개선이 필요한 부분을 식별할 수 있는 분석을 제공하였습니다. 이번 연구를 통해 AV 기술의 향상 방향을 제시하고자 합니다.



### Con4m: Context-aware Consistency Learning Framework for Segmented Time Series Classification (https://arxiv.org/abs/2408.00041)
- **What's New**: 이 논문은 시간 시계열 분류(Time Series Classification, TSC)를 다루며, 특히 분할된 시계열의 분류에서 발생하는 문제들을 해결하는 새로운 방법론 Con4m을 제안합니다. 기존 TSC 모델들은 독립적이고 동일하게 분포되어 있는(i.i.d.) 데이터를 가정하지만, 실제로는 여러 클래스가 다양한 길이로 섞인 시계열 데이터(MVD)가 빈번하게 등장합니다. 이러한 상황에서는 연속된 인스턴스 간의 자연스러운 시간적 의존성 및 경계 레이블의 불일치가 문제를 일으킵니다. Con4m은 이러한 문제를 해결하기 위해 설계된 일관성 학습 프레임워크입니다.

- **Technical Details**: Con4m 프레임워크는 MVD(다중 클래스 및 가변 길이의 데이터)에서 더 효과적인 두 가지 주요 접근법을 사용합니다. 첫째, 데이터 및 레이블 수준에서 문맥적 정보를 활용하여 클래스 분류 인스턴스의 구별력을 향상시키는 것입니다. 둘째, 모델 예측과 문맥적 정보를 통합하여 연속된 세그먼트의 일관성 없는 레이블을 조화시키는 방식으로, 점진적으로 레이블을 조정합니다. 이를 통해 더욱 견고한 모델을 구축하고, 학습 중 경계 레이블의 불일치 문제를 해결합니다.

- **Performance Highlights**: 다양한 공개 및 민간 데이터셋을 대상으로 한 실험 결과, Con4m 프레임워크가 다중 클래스 및 가변 길이(MVD)의 분할된 시간 시계열 분류 작업에서 탁월한 성능을 입증했습니다. 레이블 대체 실험 및 사례 연구를 통해 Con4m의 레이블 조화 능력이 추가로 검증되었습니다.



### Enhanced Fault Detection and Cause Identification Using Integrated Attention Mechanism (https://arxiv.org/abs/2408.00033)
- **What's New**: 본 연구는 테네시 이스트만 공정(Tennessee Eastman Process, TEP)에서 결함 감지와 원인 식별을 위한 새로운 방법론을 소개합니다. 이 방법론은 양방향 장단기 메모리(Bidirectional Long Short-Term Memory, BiLSTM) 신경망과 통합 어텐션 메커니즘(Integrated Attention Mechanism, IAM)을 결합하여 구현되었습니다.

- **Technical Details**: IAM은 스케일드 닷 프로덕트 어텐션(scaled dot product attention), 잔여 어텐션(residual attention), 동적 어텐션(dynamic attention)의 강점을 결합하여 TEP 결함 감지에 중요한 복잡한 패턴과 종속성을 포착합니다. 초기 단계에서 어텐션 메커니즘은 입력 데이터에서 중요한 특징을 추출하여 모델의 해석 가능성과 관련성을 향상시킵니다. BiLSTM 네트워크는 이러한 특징을 양방향으로 처리하여 장거리 종속성을 포착하고, IAM은 출력을 더욱 정제하여 결함 감지 결과를 개선합니다.

- **Performance Highlights**: 모의 실험 결과, 이 접근 방식은 정확성, 오경보율(false alarm rate), 오분류율(misclassification rate)에서 기존 방법들보다 우수한 성능을 보여주었습니다. 이 방법론은 TEP의 결함 감지 및 진단에 있어 강력하고 해석 가능한 솔루션을 제공하며, 산업 응용에서의 잠재력을 강조합니다.



### A New Type of Foundation Model Based on Recordings of People's Emotions and Physiology (https://arxiv.org/abs/2408.00030)
Comments:
          12 pages, 2 figures, 3 tables

- **What's New**: 최근 AI 붐 속에서 수십억 달러가 투자되고 있는 파운데이션 모델들이 주목받고 있습니다. 대표적으로 Chat-GPT와 같은 모델들은 대량의 인터넷 데이터를 학습하고, 강화 학습(재강화학습), RAG(재결합학습), 프롬프트 엔지니어링(prompt engineering) 및 인지 모델링(cognitive modelling)을 통해 행동을 미세 조정합니다. 그러나 기존 챗봇들은 사람들의 실제 감정 및 생리적 반응을 반영하지 않아 모방하는 인물의 표면적인 모습을 재현하는 수준입니다. 본 논문에서는 사람의 시각 및 청각 자극, 감정 및 생리적 반응을 기록하여 새로운 형태의 '1인칭 파운데이션 모델(first-person foundation model)'을 제안합니다.

- **Technical Details**: 1인칭 파운데이션 모델은 환경 자극을 사람의 감정 및 생리적 상태에 매핑(mapping)하고, 이를 바탕으로 사람의 행동을 예측합니다. 이를 위해 우리는 착용자가 보고 듣는 것과 감정적 및 생리적 상태를 캡처하는 녹화 장비(recording rig)를 개발했습니다. 이러한 새로운 데이터 소스는 차세대 파운데이션 모델 구축을 위한 데이터 부족 문제를 해결하는 데 도움이 될 수 있습니다.

- **Performance Highlights**: 1인칭 파운데이션 모델은 새로운 유형의 추천 시스템, 개인 비서, 생성적 대립 신경망(GAN), 데이팅 및 채용 분야 등에서 많은 흥미로운 응용 프로그램을 제공할 수 있습니다.



### Need of AI in Modern Education: in the Eyes of Explainable AI (xAI) (https://arxiv.org/abs/2408.00025)
Comments:
          Accepted for the book: Blockchain and AI in Shaping the Modern Education System, Publisher: CRC Press, Taylor & Francis Group, USA

- **What's New**: 이 논문은 AI의 복잡성과 편향성 문제를 교육에 대한 공정한 접근을 저해하는 요소로 지적하며, 이를 이해하고 해결하기 위한 개념을 제시합니다. 연구에 따르면 부모의 소득이 자녀의 교육에 큰 영향을 미치는 것으로 나타났으며, AI가 이러한 결정을 내리는 데 어떻게 작용하는지를 Explainable AI 도구를 사용해 탐구하였습니다.

- **Technical Details**: 논문은 복잡한 모델을 통해 부모 소득과 교육의 관계를 분석하고 설명 가능한 AI (Explainable AI) 도구를 사용하여 결정 과정을 해명합니다. 성인 인구조사 데이터셋을 이용하여 개인의 연간 소득이 5만 달러 이상인지 예측하는 이진 분류 문제를 중심으로 연구를 진행하였습니다. 또한 SWOT 분석, 추천 시스템, 투명성 향상 및 개인화된 피드백 등의 현대 AI 기법을 통해 교육 시스템의 개선 방안을 모색합니다.

- **Performance Highlights**: 연구에서 사용된 AI 모델은 부모 소득이 자녀 교육에 미치는 영향을 해명하면서도 편향성을 지적합니다. 이로 인해 교육에서의 AI 사용이 공정한 기회를 제공하기 위한 더 나은 솔루션이 필요함을 강조합니다. 성능 지표로는 모델의 해명 가능성, 신뢰도, 투명성 등이 고려되었으며, 이를 통해 더욱 신뢰할 수 있고 공정한 교육 정책 수립의 기초를 마련하고자 했습니다.



### Deceptive AI systems that give explanations are more convincing than honest AI systems and can amplify belief in misinformation (https://arxiv.org/abs/2408.00024)
- **What's New**: 본 연구는 대형 언어 모델(LLMs)과 같은 고도화된 인공지능(AI) 시스템이 단순히 잘못된 정보를 생성하는 것을 넘어, 이를 정당화하고 신뢰도를 높이는 기만적인 설명(deceptive explanations)을 생성해 사람들의 믿음에 미치는 영향을 조사합니다. 연구 결과, AI가 생성한 기만적인 설명들이 정확하고 정직한 설명들보다 더욱 설득력이 있으며, 잘못된 뉴스 헤드라인을 더욱 신뢰하게 만들고 진실된 정보를 약화시키는 데 큰 영향을 미친다는 것을 발견했습니다.

- **Technical Details**: 연구진은 GPT-3 기반의 Davinci 모델을 사용해 실제 진짜 및 가짜 뉴스 헤드라인에 대해 정직한 설명과 기만적인 설명을 생성했습니다. 데이터셋은 'liar-plus' 공개 데이터셋을 바탕으로 구축되었으며, 각 설명의 진실성과 논리적 타당성을 독립적으로 검증했습니다. 실험에는 총 1,192명의 참여자가 포함되었고, 이들에게 진실성 판단과 피드백 수정 가능성을 평가하게 하여 AI 생성 설명의 영향력을 측정했습니다.

- **Performance Highlights**: 기만적인 AI 생성 설명이 단순하게 잘못된 뉴스를 분류하는 것보다도 사람들의 신념에 더 큰 영향을 미쳤습니다. 또한, 개인의 인지적 반성(cognitive reflection)이나 AI에 대한 신뢰도가 기만적 설명이 미치는 영향을 완전히 막지는 못하는 것으로 나타났습니다. 다만, 논리적 타당성(logical validity)이 낮은 설명은 신뢰성이 낮게 평가됩니다. 이는 논리적 사고 및 비판적 사고 능력을 기르는 것이 AI 기반 허위 정보에 대한 저항력을 키우는 데 중요함을 시사합니다.



### MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities (https://arxiv.org/abs/2408.00765)
Comments:
          Extension of MM-Vet: arXiv:2308.02490

- **What's New**: MM-Vet v2가 새롭게 출시되어 더욱 발전된 대형 멀티모달 모델을 평가합니다. 이번 버전에서는 '이미지-텍스트 시퀀스 이해(image-text sequence understanding)'라는 새로운 VL 능력이 추가되었습니다. 이를 통해 모델의 이미지와 텍스트가 혼합된 시퀀스를 처리하는 능력을 평가할 수 있습니다.

- **Technical Details**: 기존 MM-Vet는 단일 이미지-텍스트 쌍을 기반으로 질문 형식을 제한했지만, MM-Vet v2는 이 제한을 극복하고 이미지를 <image>으로 나타내는 시퀀스 이해를 포함하도록 개선되었습니다. 새로운 데이터셋은 높은 품질을 유지하면서도 평가 샘플 수를 517개로 확장하였습니다. 질문 생성과 참조 답안 작성은 연구자들이 직접 설계하고 GPT-4V의 초안을 검토 및 수정하는 과정을 거쳤습니다.

- **Performance Highlights**: MM-Vet v2를 활용한 대형 멀티모달 모델 평가에서 Claude 3.5 Sonnet이 71.8점으로 최고 성능을 기록하였고, GPT-4o가 71.0점으로 그 뒤를 이었습니다. 특히, 오픈-웨이트 모델 중에서는 InternVL2-Llama3-76B가 68.4점으로 우수한 성능을 보였습니다.



### AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation (https://arxiv.org/abs/2408.00764)
- **What's New**: 이 논문은 대형 언어 모델(LLM) 기반 에이전트의 계획 능력을 향상시키기 위한 연구를 다룹니다. 기존 연구들은 주로 수작업으로 설계된 계획 작업 및 환경에서 경로를 생성하는 것에 중점을 두었기 때문에, 이러한 방식을 개선하고 자동화된 환경 생성 및 다양한 난이도의 계획 작업 생성을 탐구하고 있습니다.

- **Technical Details**: 본 논문에서는 'AgentGen'이라는 프레임워크를 소개합니다. 이 프레임워크는 LLM을 사용해 자동으로 환경을 생성하고, 이러한 환경을 조건으로 계획 작업을 생성합니다. 특히 환경의 다양성을 높이기 위해 다양한 도메인-specific 텍스트 세그먼트로 구성된 '영감 코퍼스(inspiration corpus)'를 활용하여 환경을 합성합니다. 또한 계획 작업의 난이도 다양성을 높이기 위해 '쌍방향 진화 방법(Bi-Evol)'을 제안하며, 이는 쉬운 방향과 어려운 방향에서 계획 작업을 진화시켜 난이도 곡선이 매끄럽게 이어지도록 작업 세트를 합성합니다.

- **Performance Highlights**: AgentGen 프레임워크의 평가 결과는 LLM의 계획 능력을 크게 향상시켰음을 보여줍니다. 예를 들어, AgentGen으로 instruction-tuning된 Llama-3 8B는 종합 성능에서 GPT-3.5를 뛰어넘으며, 특정 작업에서 GPT-4보다 우수한 성능을 보이기도 했습니다.



### Tamper-Resistant Safeguards for Open-Weight LLMs (https://arxiv.org/abs/2408.00761)
Comments:
          Website: this https URL

- **What's New**: 이 논문에서는 대형 언어 모델(LLM)의 악의적인 사용을 막기 위한 새로운 방법론인 TAR(Tamper-Resistant)을 개발했습니다. 기존의 방어 메커니즘은 모델 가중치를 변경하는 공격에 쉽게 무너질 수 있다는 문제점을 해결하고, 수천 번의 미세 조정 후에도 안전 장치가 제거되지 않도록 설계되었습니다.

- **Technical Details**: TAR은 메타 러닝(meta-learning)과 적대적 학습(adversarial training) 접근법을 활용하여 모델의 가중치 변경에 대한 공격을 방어할 수 있도록 설계되었습니다. 이 방법론은 tamper-resistance loss, 학습 시 적대자의 선택, 두 단계 접근법 등 여러 중요한 요소를 결합하여 효과를 발휘합니다.

- **Performance Highlights**: 광범위한 평가와 레드 팀 분석을 통해 TAR을 적용한 모델이 최대 5,000번의 미세 조정 단계에서도 높은 수준의 tamper-resistance를 유지한다는 것을 확인했습니다. 또한, 선행 방법 대비 훨씬 뛰어난 방어력을 입증했습니다.



### Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention (https://arxiv.org/abs/2408.00760)
- **What's New**: 이번 연구에서는 무조건 이미지 생성을 위한 새로운 지도 방법론인 Smoothed Energy Guidance (SEG)를 제안합니다. 이는 에너지 기반의 자기-주의 메커니즘(self-attention mechanism)을 활용하여 이미지 생성을 개선하는 방법입니다.

- **Technical Details**: SEG는 자기-주의의 에너지 관점에서 출발하여 에너지 함수의 커브를 직접적으로 조정하여 무조건적인 예측을 수행합니다. 구체적으로, Gaussian kernel 파라미터를 조정하여 에너지 랜드스케이프의 커브를 조절하고, 쿼리 블러링(query blurring) 기법을 도입하여 복잡성을 줄입니다.

- **Performance Highlights**: 다양한 실험에서 SEG는 기존 방법보다 구조적 변화가 적고, 샘플 품질이 향상되었습니다. 특히 ControlNet을 활용한 실험에서도 뛰어난 성과를 보였습니다.



### Segment anything model 2: an application to 2D and 3D medical images (https://arxiv.org/abs/2408.00756)
Comments:
          11 pages, 7 figures. A first attempt on evaluating SAM 2 on medical images

- **What's New**: Segment Anything Model (SAM)에서 발전한 SAM 2가 기존의 이미지 분할 기능을 비디오 입력으로 확장했습니다. 이로 인해 SAM을 3D 의료 이미지에 적용할 수 있는 가능성이 열리게 되었습니다. 이번 논문은 SAM 2의 2D 및 3D 의료 이미지 분할 능력을 종합적으로 평가합니다.

- **Technical Details**: 논문은 18개의 다양한 의료 영상 데이터셋을 사용하여 SAM 2를 평가합니다. 데이터셋에는 MRI, CT, PET 등의 3D 모달리티 뿐만 아니라 X-ray 및 초음파 같은 2D 모달리티도 포함됩니다. 평가에는 두 가지 파이프라인을 고려합니다: (1) 멀티 프레임 3D 분할 (multi-frame 3D segmentation)과 (2) 싱글 프레임 2D 분할 (single-frame 2D segmentation). 각각의 프레임에 프롬프트(주석)를 제공하는 싱글 프레임 2D 분할은 2D 및 3D 모달리티 모두에 적용되며, 멀티 프레임 3D 분할은 주로 3D 모달리티에 적용됩니다.

- **Performance Highlights**: SAM 2는 싱글 프레임 2D 분할에서는 SAM과 비슷한 성능을 보였지만, 멀티 프레임 3D 분할에서는 주석을 입력할 슬라이스 선택, 예측 방향, 프레임 간 전파 등의 조건에 따라 성능이 달라질 수 있다는 결과를 보여주었습니다.



### A deep learning-enabled smart garment for versatile sleep behaviour monitoring (https://arxiv.org/abs/2408.00753)
Comments:
          18 pages, 5 figures, 1 table

- **What's New**: 이 논문에서는 간단한 웨어러블 장치를 사용하여 다양한 건강하지 못한 수면 패턴을 인식하는 문제를 해결하기 위해 스마트 의류에 인쇄된 고감도 스트레인 센서(array)를 개발했습니다. 이 센서들은 깊은 학습 신경망과 함께 코 호흡, 입 호흡, 코골이, 이갈이, 중심성 수면 무호흡(CSA), 폐쇄성 수면 무호흡(OSA) 등 여섯 가지 수면 상태를 98.6%의 높은 정확도로 정확하게 감지할 수 있습니다.

- **Technical Details**: 스마트 의류의 칼라 부분에 인쇄된 이 스트레인 센서(array)는 외부 후두 근육의 미세한 진동을 감지할 수 있습니다. 깊은 학습 뉴럴 네트워크(Deep Learning Neural Network)를 사용하여 여섯 가지 수면 상태를 인식할 수 있으며, 특정 위치를 요구하지 않습니다. 또한, 설명 가능한 인공지능(XAI) 시각화 기술을 통해 신호 패턴 분석을 반영하며 낮은 편향을 유지합니다. 전이 학습(Transfer Learning) 테스트에서는 매우 소수의 샘플(클래스 당 15개 이하)만으로도 새로운 사용자에 대해 95% 이상의 높은 정확도를 달성할 수 있음을 보여줍니다.

- **Performance Highlights**: 이 스마트 의류 시스템은 98.6%의 높은 정확도로 여섯 가지 수면 상태를 인식할 수 있으며, 이는 단순한 홈 모니터링 장치로서의 높은 잠재력을 보여줍니다. 또한, 높은 내구성과 확장 가능한 제조 공정을 통해 실제 응용에서 높은 범용성과 설명 가능성을 입증했습니다.



### A Policy-Gradient Approach to Solving Imperfect-Information Games with Iterate Convergenc (https://arxiv.org/abs/2408.00751)
- **What's New**: 최근 발표된 논문에서는 정책 그라디언트 방법(policy gradient method)이 두 명의 플레이어가 참여하는 제로섬 불완전 정보 광범위 형식 게임(Extensive-Form Games, EFGs)에서 안전하게 사용될 수 있는지에 대해 연구하였습니다. 결과적으로 정책 그라디언트 방법이 자기 대결(self-play)에서 규제된 내시 균형(regularized Nash equilibrium)에 수렴하는 것을 처음으로 증명하였습니다.

- **Technical Details**: 기존의 단일 에이전트 강화 학습에서는 정책 그라디언트 방법이 반복 수렴(iterate convergence), 확률적 궤적 피드백(stochastic trajectory feedback)의 효율적 사용, 중요도 샘플링 보정(importance sampling corrections)을 이론적으로 배제하는 등의 장점으로 널리 사용되어 왔습니다. 그러나 다중 에이전트 불완전 정보 설정(extensive-form games)에서는 이러한 특성이 이론적으로 보장될 수 있는지 불분명했습니다. 본 연구는 이러한 한계를 극복하기 위해 두 명의 플레이어가 참여하는 제로섬 불완전 정보 광범위 형식 게임에서 정책 그라디언트 방법이 사용될 수 있는 가능성을 조사했습니다.

- **Performance Highlights**: 연구 결과, 정책 그라디언트 방법이 실제로 자기 대결에서 규제된 내시 균형에 수렴한다는 점을 증명하였습니다. 이는 기존에 사용된 반사실적 값(counterfactual values) 대신 직접 정책 그라디언트 방법을 안전하게 사용할 수 있는 가능성을 제시하며, 정책 그라디언트 방법의 활용 범위를 다중 에이전트 설정으로 확장할 수 있는 중요한 발견입니다.



### Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer (https://arxiv.org/abs/2408.00749)
- **What's New**: 최근 연구에 따르면 수확량이 높은 농작물 품종과 직립형 잎 각도(upright leaf angles)를 가진 식물 사이에 높은 상관관계가 있음이 나타났습니다. 직립형 잎 각도를 가진 식물이 그렇지 않은 식물보다 더 많은 빛을 가두며, 이로 인해 광합성 비율이 더 높아집니다. 이러한 측정을 현장에서 자동화하는 기술이 각광받고 있습니다.

- **Technical Details**: 이 연구는 Mask R-CNN 인스턴스 세분화 인공신경망과 시각 트랜스포머인 Line Segment Transformer(LETR)을 활용하여 잎 각도를 자동 추정하는 컴퓨터 비전(CV) 파이프라인을 제안합니다. 이 파이프라인은 여름 2015-Ames ULA와 여름 2015-Ames MLA라는 두 가지 이미지 데이터셋에 적용되었습니다. 연구팀은 각각 872장과 955장의 식물 이미지를 현장에서 FieldBook(안드로이드 애플리케이션)을 사용해 수집했습니다.

- **Performance Highlights**: 제안된 파이프라인으로 추정된 잎 각도는 ImageJ로 수동 측정한 두 독립적인 값과 비교하여 코사인 유사도(Cosine Similarity) 측정 시 0.98의 유사도 점수를 기록했습니다. 이는 제안된 파이프라인이 현장에서 잎 각도를 측정하는 데 유효함을 시사합니다.



### Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions (https://arxiv.org/abs/2408.00727)
- **What's New**: i-MedRAG는 긴 임상 추론이 필요한 복잡한 의료 질문을 해결하기 위해 제안된 새로운 RAG(질문-응답 생성 증강) 구조입니다. 기존의 단일 회차 정보 검색을 뛰어넘어, 여러 회차에 걸친 후속 질의와 응답을 포함하여 LLM(대규모 언어 모델)이 점진적으로 추가 정보를 수집할 수 있도록 합니다.

- **Technical Details**: i-MedRAG는 각 회차마다 LLM이 이전 질의 시도에 기반한 후속 질의를 생성하고, 이를 바닐라 RAG 시스템을 통해 답변하게 되며, 이 과정을 반복하여 탐색 결과를 점진적으로 확장해나갑니다. 이렇게 생성된 질의와 답변은 초기 질문에 대한 응답 생성을 보강하는 데 사용됩니다.

- **Performance Highlights**: i-MedRAG는 MedQA 테스트 세트에서 69.68%의 정확도를 달성하며, 이는 GPT-3.5 기반에서 기존 모든 프롬프트 엔지니어링 및 파인 튜닝(미세 조정) 방법을 능가하는 것입니다. 특히, zero-shot 설정에서도 뛰어난 성능을 보이며, 이 설정 하에서는 훈련 데이터 없이 실제적인 임상 시나리오에서도 적용이 가능합니다.



### Pathway to Secure and Trustworthy 6G for LLMs: Attacks, Defense, and Opportunities (https://arxiv.org/abs/2408.00722)
Comments:
          7 pages, 4 figures

- **What's New**: 이 논문은 6G 네트워크 환경에서 큰 언어 모델(LLMs)을 미세 조정하는 과정에서 발생할 수 있는 보안 취약점, 특히 멤버십 추론 공격(Membership Inference Attack)에 대해 탐구합니다. 연구 결과, LLM을 사용하는 모든 하위 작업에서 이러한 공격이 효과적일 수 있으며, 이는 개인 데이터 유출로 이어질 수 있습니다.

- **Technical Details**: 논문에서는 공격자가 하위 작업용으로 미세 조정된 모델에 접근할 수 있을 때 멤버십 추론 공격을 수행할 수 있는 공격 네트워크의 특성을 정의합니다. 실험 결과, 예명 인식(named entity recognition) 작업에서 최대 92%의 공격 성공률을 달성할 수 있음을 보여주었습니다. 이를 바탕으로 가능한 방어 메커니즘과 연구 방향을 논의합니다.

- **Performance Highlights**: 실험에서 예명 인식 작업(named entity recognition task)에서 최대 92%의 멤버십 추론 공격 성공률을 기록했습니다. 이러한 높은 성공률은 LLM의 프라이버시 문제와 보안 취약성을 강조합니다.



### SAM 2: Segment Anything in Images and Videos (https://arxiv.org/abs/2408.00714)
Comments:
          Website: this https URL

- **What's New**: Segment Anything Model 2 (SAM 2)가 출시되었습니다. SAM 2는 이미지와 비디오에서 프롬프트 가능한 시각적 세분화(promptable visual segmentation) 작업을 해결하기 위한 기반 모델로, 사용자 상호작용을 통해 모델과 데이터를 개선하는 데이터 엔진을 만들었습니다. 이를 통해 지금까지 가장 큰 비디오 세분화 데이터셋을 수집하였습니다.

- **Technical Details**: SAM 2는 단순한 transformer 아키텍처와 스트리밍 메모리를 사용하여 실시간으로 비디오를 처리합니다. 이 모델은 특정 프레임의 포인트, 박스 또는 마스크를 입력으로 받아 세분화 마스크(‘마스크렛’)를 예측합니다. SAM 2는 객체와 이전 상호작용에 대한 정보를 저장하는 메모리 모듈을 갖추고 있습니다. 이를 통해 비디오 내에서 연속된 프레임에서도 일관된 세분화 결과를 생성합니다.

- **Performance Highlights**: SAM 2는 기존 접근 방식보다 3배 적은 상호작용으로 더 높은 정확도의 비디오 세분화를 제공합니다. 또한 이미지 세분화에서는 기존 Segment Anything Model(SAM)보다 더 정확하고 6배 빠릅니다. 최종 Segment Anything Video (SA-V) 데이터셋은 35.5백만 개의 마스크를 포함하고 있으며, 이는 기존 데이터셋보다 마스크 수가 53배 더 많습니다.



### Investigating Brain Connectivity and Regional Statistics from EEG for early stage Parkinson's Classification (https://arxiv.org/abs/2408.00711)
- **What's New**: 이번 연구는 뇌 연결성 지표(brain connectivity metrics)와 신호 통계(signal statistics)를 결합하여 파킨슨병 초기 단계(PD) 진단에 대한 EEG 데이터의 효율성을 평가합니다. 이 연구는 각성 상태 5개(깨있는 상태 및 네 가지 수면 단계)에 대한 데이터를 사용합니다.

- **Technical Details**: 본 연구의 파이프라인에서는 Ada Boost 모델을 사용하여 도전적인 초기 단계 파킨슨병 분류 작업을 수행합니다. 연구는 30명의 참가자(파킨슨병 11명, 건강한 대조군 19명) 데이터를 사용하였고, 9가지 뇌 연결성 지표를 평가했습니다. 각성 상태마다 최적의 연결성 지표가 다르며, N1 데이터에서 Phase Lag Index(PLI, 위상 지연 지수)가 86%의 최고 개별 분류 정확도를 기록했습니다. PLI와 EEG 신호의 주파수 특성에서 도출된 통계를 결합하여 성능을 향상시켰습니다.

- **Performance Highlights**: 결과적으로, PLI와 지역 신호 통계(data)가 결합된 파이프라인이 91%의 최고 분류 정확도를 달성했습니다. 또한 N1 데이터에서 Phase Lag Index(PLI)를 통계와 결합했을 때 재현율(recall) 80%, 정밀도(precision) 96%를 기록했습니다. N1 EEG 데이터를 사용하면 파킨슨병 분류에 더 우수함을 나타냈으며, 이는 PD에서 N1 수면이 방해되는 것과 관련이 있을 수 있다고 결론지었습니다.



### Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM (https://arxiv.org/abs/2408.00706)
Comments:
          2024 IEEE Nuclear Science Symposium and Medical Imaging Conference

- **What's New**: 이 예비 연구에서는 점 기반 의료 이미지 분할(Point-Supervised Segmentation, PSS)을 통해, 비용이 많이 드는 전문가의 윤곽 표기 라벨링 문제를 해결하기 위한 방법을 제안합니다. 특히, PSS는 정확한 크기와 경계 가이드가 부족하여 성능이 기대에 미치지 못하는 경우가 많습니다. 이를 해결하기 위해, 우리는 점 입력을 잠재적인 가상 경계 상자 제안(pseudo bounding box suggestions)으로 변환하는 모듈과, 후속 공간 세밀화 모듈(Spatial Refinement Module) 통해, 단계적으로 성능을 향상시킬 수 있는 반복적 프레임워크를 소개합니다.

- **Technical Details**: 이 연구는 'Semantic Box-Prompt Generator, SBPG' 모듈을 통해 점 입력을 잠재적 경계 상자 제안으로 변환하고, 프로토타입 기반 의미 유사성으로 이를 명시적으로 세밀화합니다. 그 뒤는 뛰어난 일반화 성능을 지닌 MedSAM을 활용하여 분할 마스크(segmentation mask)를 추론하는 'Prompt-Guided Spatial Refinement, PGSR' 모듈이 이어집니다. 이 방법은 원형 기반 의미 유사성(protoype-based semantic similarity)과 MedSAM의 반복 프레임워크를 결합하여 세밀한 경계 상자(coarse-to-fine progression of the bounding box)를 생성합니다.

- **Performance Highlights**: 제안된 방법은 BraTS2018 데이터셋에서 전체 뇌 종양 분할(whole brain tumor segmentation) 평가를 통해 탁월한 성능을 보여주었습니다. 기존의 PSS 방법론과 비교해 우수한 성능을 보였으며, 상자 기반 감시 방법(Box-Supervised Method)에 근접한 성능을 발휘했습니다. 검증 과정에서 3~5번의 반복(iterations)을 통해, 점 프롬프트 기반 방법이 상자 기반 MedSAM에 상응하는 성능을 얻을 수 있음을 확인했습니다.



### Future of Artificial Intelligence in Agile Software Developmen (https://arxiv.org/abs/2408.00703)
- **What's New**: 이 논문에서는 소프트웨어 프로젝트 개발에서 AI 도구와 기술을 활용하여 최대한의 지원을 제공하는 방법을 제안합니다. 특히, 최근 산업에서 점점 더 선호되고 있는 애자일 소프트웨어 프로젝트에 초점을 맞추고 있습니다.

- **Technical Details**: 소프트웨어 프로세스 프레임워크는 인간의 상호작용을 요구하는 활동들로 구성되어 있으며, 이는 오류와 불확실성의 가능성을 초래할 수 있습니다. AI는 LLMs(Large Language Models), GenAI(Generative AI) 모델, AI 에이전트 등을 활용하여 이러한 루틴 작업, 리스크 분석 및 예측, 전략 추천, 의사 결정 지원 등을 통해 소프트웨어 개발 관리자, 소프트웨어 테스터 및 팀원들을 도울 수 있습니다.

- **Performance Highlights**: 이 논문은 AI가 프로젝트 관리팀의 효율성을 높이고 리스크를 줄이며 프로젝트 성공률을 높일 수 있는 잠재력을 가지고 있음을 강조합니다. 또한, AI는 이해관계자가 정보에 입각한 결정을 내릴 수 있도록 복잡한 개념과 개발 프로세스를 해체하는 데 도움을 줄 수 있습니다.



### Accelerating Full Waveform Inversion By Transfer Learning (https://arxiv.org/abs/2408.00695)
- **What's New**: 이 논문에서는 신경망(Neural Network, NN)을 이용한 새로운 FWI(Full Waveform Inversion) 기법을 소개합니다. 기존의 NN 기반 FWI 방법을 한 단계 업그레이드하여 전이 학습(Transfer Learning)을 도입하였습니다. 이 접근 방식은 감독 학습(Supervised Pretraining)을 활용하여 NN의 가중치 초기화(initial weight)를 개선함으로써 최적화 문제의 빠른 수렴과 더 나은 재구축 품질을 달성합니다.

- **Technical Details**: 기존 FWI 방법은 파동 전파에 의해 얻어진 희소 데이터를 이용하여 재료 필드를 재구축합니다. NN 기반 FWI는 NN을 이용하여 재료 필드의 이산화를 통해 최적화 문제의 강건성과 재구축 품질을 향상시킵니다. 이번 연구에서는 초기 추정치를 기반으로 NN의 가중치를 반복적으로 업데이트하여 시뮬레이션된 파동 신호를 희소 데이터 세트에 맞추는 방식으로 작동합니다. 특히, 전이 학습을 통해 사전 학습(pretraining)된 NN 가중치 초기화가 더 빠른 수렴과 물리적으로 의미 있는 지역 최소값을 제공한다는 점을 강조합니다. 사전 학습된 신경망은 기존 FWI의 첫 번째 반복에서 얻은 그라디언트 정보를 사용하여 미지의 재료 필드를 예측하도록 훈련되었습니다.

- **Performance Highlights**: 이 새로운 전이 학습 기반 NN-FWI는 다음과 같은 세 가지 방법과 비교되었습니다: (1) 기존의 FWI, (2) 사전 학습 없는 NN 기반 FWI, (3) 사전 학습된 NN으로부터 예측된 초기 추정치를 사용하는 기존의 FWI. 그 결과, 전이 학습 기반 NN-FWI가 수렴 속도와 재구축 품질 측면에서 다른 방법들을 능가한다는 것을 확인했습니다. 특히 2D 도메인에서 임의로 위치한 다양한 형태와 방향의 타원의 공극을 포함하는 참조 시뮬레이션 데이터를 통해 검증되었습니다.



### Learning in Multi-Objective Public Goods Games with Non-Linear Utilities (https://arxiv.org/abs/2408.00682)
Comments:
          In press at ECAI 2024

- **What's New**: 다중 목적 공공재 게임(Public Goods Games)에서의 최적 의사 결정 문제를 해결하기 위해, 에이전트의 위험 선호도를 기반으로 한 다중 목적 강화 학습(multi-objective reinforcement learning) 모델을 새롭게 제안했습니다. 이 연구는 에이전트들이 비협조적인 환경에서도 협력 패턴을 유지할 수 있게 하여, 인간과 협력하거나 지원하는 인공지능 에이전트의 성능을 향상시키는 것을 목표로 합니다.

- **Technical Details**: 연구에서는 개별 에이전트의 위험 선호도(risk preferences)를 모델링하기 위해, 매개변수화된 비선형 효용 함수(parametric non-linear utility function)를 도입했습니다. 다중 목적 접근 방식은 공공재 게임에서 집단과 개인 보상 성분 사이의 상호 작용을 분석합니다. 또한, 환경적 불확실성과 사회적 불확실성의 분리를 통해 이러한 불확실성들이 게임에서 인센티브 정렬 수준에 미치는 영향을 연구합니다.

- **Performance Highlights**: 비선형 유틸리티 함수가 다중 목적 최적화 기준에 따라 다르게 작용함에 주목했습니다. 실험 결과, 환경적 불확실성이 있는 상황에서 위험 회피적 유틸리티 함수는 협력을 크게 감소시키며, 위험 추구적 유틸리티 함수는 이기적 전략이 지배적인 환경에서도 협력을 증가시킬 수 있음을 보였습니다.



### AMAES: Augmented Masked Autoencoder Pretraining on Public Brain MRI Data for 3D-Native Segmentation (https://arxiv.org/abs/2408.00640)
- **What's New**: 이 연구는 큰 규모의 도메인-특정 데이터셋에서 3D 시맨틱 세그멘테이션 모델의 셀프-슈퍼바이즈드 프리트레이닝(self-supervised pretraining) 영향력을 조사합니다. 연구팀은 공개 소스로부터 44,756개의 뇌 MRI 볼륨을 포함하는 최대의 공개 데이터셋인 BRAINS-45K를 소개합니다. 또한 최신 세그멘테이션 아키텍처를 프리트레이닝하기 위해 설계를 간소화하고 최적화한 방법들로 재검토하였으며, 새로운 증강 전략을 결합한 AMAES 프레임워크를 제안합니다.

- **Technical Details**: AMAES 프레임워크는 마스킹 이미지 모델링(Masked-image-modeling)과 강도 기반의 증강 복귀(intensity-based augmentation reversal)에 기반을 두고 있으며, 메모리 사용량, 실행 시간, 및 파인튜닝 성능을 균형 있게 조정합니다. U-Net과 MedNeXt 아키텍처를 백본으로 사용하여 세 가지 까다로운 다운스트림 작업에서 프리트레이닝 효과를 평가하였습니다.

- **Performance Highlights**: AMAES를 사용하여 제안된 데이터셋으로 프리트레이닝한 결과, 평가된 경우의 대다수에서 세그멘테이션 성능이 크게 개선되었습니다. 또한, 대규모 데이터셋에서 프리트레이닝을 수행하는 경우에도 증강을 사용하여 모델을 프리트레이닝하는 것이 유익한 것으로 나타났습니다.



### DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks (https://arxiv.org/abs/2408.00633)
- **What's New**: DisTrack는 온라인 소셜 네트워크(Online Social Networks, OSNs)에서의 허위 정보(misinformation) 추적 및 분석을 위한 새로운 방법론과 도구입니다. 이 기술은 자연어 처리(NLP), 소셜 네트워크 분석(SNA), 그래프 시각화(graph visualization)의 결합을 통해 설계되었습니다.

- **Technical Details**: DisTrack의 아키텍처는 키워드 검색, 의미 유사도 평가(semantic similarity assessments), 그래프 생성 기법(graph generation techniques)을 포함한 다양한 방법론을 통합하여 허위 정보의 모니터링, 잘못된 주장과의 정렬에 따른 콘텐츠 분류, 상세한 그래프를 통한 전파 캐스케이드 시각화를 가능하게 합니다. 특히 트위터(X)를 사용하여 이러한 허위 정보의 전파를 분석합니다. 기존의 자동화 시스템의 단점을 보완한 반자동적 방법론을 활용하여 정확하고 적시적인 검증을 수행합니다.

- **Performance Highlights**: DisTrack의 효과는 혐오 표현, 백신 반대 허위 정보, 러시아-우크라이나 갈등의 잘못된 서사에 초점을 맞춘 3가지 사례 연구를 통해 입증되었습니다. 이 연구들은 DisTrack이 허위 정보를 전파하는 게시물과 이를 반박하는 게시물을 구별하고, 허위 정보의 진화 과정을 추적할 수 있음을 보여줍니다. 이 도구는 또한 허위 정보의 전파 경로를 추적하고, 다양한 행위자의 영향력을 평가할 수 있습니다.



### Closing the gap between open-source and commercial large language models for medical evidence summarization (https://arxiv.org/abs/2408.00588)
- **What's New**: 최근 대형 언어 모델(LLM)이 의료 증거 요약(summarizing medical evidence)에 큰 잠재력을 지니고 있는 것으로 밝혀졌습니다. 하지만, 대부분의 연구는 독점적인 LLM에 초점을 맞추고 있으며, 이는 투명성 부족과 벤더 종속성 등 여러 위험 요소를 초래할 수 있습니다. 본 연구에서는 오픈 소스 LLM을 세부 조정(fine-tuning)하여 그 성능을 향상시킬 수 있는지를 조사했습니다.

- **Technical Details**: 우리는 PRIMERA, LongT5, Llama-2 세 가지 널리 사용되는 오픈 소스 LLM을 MedReview 벤치마크 데이터셋을 사용해 세부 조정(fine-tuning)했습니다. 이 데이터셋은 8,161쌍의 체계적인 리뷰와 요약을 포함하고 있습니다. 세부 조정을 위해 Low-Rank Adaptation(LoRA)을 사용했습니다, 이는 모델 파라미터의 일부만 업데이트하는 효율적인 방법입니다.

- **Performance Highlights**: Fine-tuning한 LLM들은 ROUGE-L 9.89, METEOR 13.21, CHRF 15.82의 점수 향상을 보였으며, GPT-3.5의 zero-shot 설정과 유사한 성능을 보였습니다. 또한, 일부 작은 모델들은 더 큰 zero-shot 모델보다 우수한 성능을 보이기도 했습니다. 이러한 성과는 인간 평가와 GPT4-모의 평가에서도 나타났습니다.



### Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses (https://arxiv.org/abs/2408.00584)
Comments:
          Code: this https URL. Artifacts: this https URL

- **What's New**: 이 논문에서는 이탈리아어로 작성된 대형 언어 모델의 리버스(Rebus) 문제 해결 능력을 평가하고자, 방대한 양의 텍스트로 표기된 리버스를 소개합니다. 일반적인 시스템인 LLaMA-3와 GPT-4o는 이 작업에 약한 성능을 보이나, 목적에 맞는 파인 튜닝(ad-hoc fine-tuning)을 통해 성능을 개선할 수 있음을 확인했습니다. 하지만, 성능 향상이 주로 암기에 의해 이루어짐을 알 수 있습니다. 저자들은 리버스 해결이 대형 언어 모델의 언어 능력과 순차적인 지침 준수 능력을 평가하는 어려운 시험대임을 시사합니다.

- **Technical Details**: 저자들은 이탈리아어 퍼즐인 리버스를 평가하기 위해 새로운 텍스트 변형 리버스를 생성하는 전략을 제안했습니다. 이 데이터셋은 Eureka5에서 추출한 223,000개의 리버스 데이터를 활용해 80,000개 이상의 텍스트 변형 리버스를 만듭니다. 이 데이터를 기반으로 광범위한 LLM을 대상으로 몇-샷 프롬팅(few-shot prompting) 평가를 수행했습니다. 특히, 작은 규모이지만 성능이 우수한 Phi-3 Mini 3.8B 모델을 파인 튜닝해 이전의 최첨단 시스템을 뛰어넘는 성과를 거두었습니다. 파인 튜닝은 81,000개의 예제를 사용해 5,000단계의 학습으로 수행되었습니다.

- **Performance Highlights**: 리버스 해결에서 Phi-3 Mini 3.8B 모델은 테스트 데이터셋에서 높은 성능을 보였으며, 특히 정의 해석, 첫 번째 구문 생성, 솔루션 분절 등에서 전반적으로 높은 정확도를 기록했습니다. 간략화된 평가 기준으로는 정의 해석, 첫 구문/문자 정확도, 첫 구문 정밀 일치도가 포함되며, 특히 솔루션 키 일치 비율과 솔루션 단어 정확도에서도 우수한 성적을 나타냈습니다. 단, 일반적인 LLM은 여전히 순차적인 복잡한 지침을 따르는 데 어려움을 겪는 것으로 확인되었습니다.



### Alleviating Hallucination in Large Vision-Language Models with Active Retrieval Augmentation (https://arxiv.org/abs/2408.00555)
- **What's New**: 최근의 연구는 대형 시각-언어 모델(LVLM)에서 발생하는 왜곡(hallucination) 문제를 해결하기 위해 '액티브 검색 증강 대형 시각-언어 모델(Active Retrieval-Augmented large vision-language model, ARA)'을 제안합니다. 이 모델은 이미지의 계층적 구조를 기반으로 검색 목표를 분해하고, 가장 효과적인 검색 방법을 선별하며, 검색 시기를 조절하여 모델의 불확실성이 낮을 때 검색을 활성화하는 방법을 사용합니다.

- **Technical Details**: ARA 모델은 세 가지 핵심 차원을 통합하여 설계되었습니다. 첫째, 이미지를 계층적으로 분석하여 목표 객체를 추출하는 '구조적 검색'을 수행합니다. 둘째, 다양한 멀티모달 입력 방식을 분석하여 가장 효과적인 검색 방식을 적용하고 신뢰할 수 있는 결과를 필터링합니다. 셋째, 모델의 불확실성이 낮을 때만 검색을 수행하여 불필요한 검색을 피합니다. 이 과정을 통해 ARA는 'coarse-to-fine' 검색 패러다임을 적용하며, 이미지 전체와 특정 지역 모두를 분석해 검색 정확도를 높입니다.

- **Performance Highlights**: 제안된 ARA 모델은 세 가지 LVLM 모델(LLaVA-1.5, Qwen-VL, mPLUG-Owl2)을 이용한 네 가지 벤치마크 테스트에서 인상적인 성능을 보였습니다. 실험 결과에 따르면, 적절한 검색 메커니즘을 활용하고 검색 시점을 신중하게 조절함으로써 왜곡 문제를 효과적으로 감소시킬 수 있음이 확인되었습니다.



### Mitigating Multilingual Hallucination in Large Vision-Language Models (https://arxiv.org/abs/2408.00550)
- **What's New**: LVLMs(대형 비전-언어 모델)은 다양한 작업에서 뛰어난 성능을 보였으나, 입력된 이미지-쿼리 쌍에 대해 그럴듯하지만 잘못된 답변을 생성하는 환각 문제로 고통받고 있습니다. 이 논문에서는 LVLMs의 다중언어 환각 문제를 완화하기 위한 첫 번째 시도를 했습니다. 특히, 다중언어 POPE 벤치마크에서 평균 19.0%의 정확도 향상을 달성했습니다.

- **Technical Details**: 본 연구는 다중언어 환각 제거(MHR) 프레임워크를 두 단계로 제안했습니다. 먼저 다중언어 지시어 이해 능력을 개선한 뒤, 모델의 환각 저항 능력을 강화합니다. 이를 위해 교차 언어 정렬(cross-lingual alignment) 방법을 사용하여 다중언어 환각 데이터를 생성하고, 이를 통해 직접 최적화를 수행합니다.

- **Performance Highlights**: 실험 결과, MHR 프레임워크는 낮은 자원 언어와 높은 자원 언어 모두에서 환각 문제를 크게 감소시켰습니다. 확장된 다중언어 POPE 벤치마크에서 우리 프레임워크는 13개 언어에서 평균적으로 19.0%의 정확도 향상을 보여주었습니다.



### Learning to Embed Distributions via Maximum Kernel Entropy (https://arxiv.org/abs/2408.00549)
- **What's New**: 본 논문에서는 데이터 의존적인 분포 커널(distribution kernel)을 비지도 학습하는 새로운 목표(Objective)를 제안합니다. 이는 확률측정(Probability Measure)의 임베딩 공간에서 엔트로피 최대화(Entropy Maximization) 원칙에 기반합니다. 이러한 접근 방식은 기존의 커널 선택 문제를 해결하여, 비지도 학습 환경에서 적절한 분포 임베딩 커널을 자동으로 학습할 수 있음을 보여줍니다.

- **Technical Details**: 이 연구는 데이터 포인트를 실수 벡터가 아닌 특징들의 집합(Set) 또는 객체들의 그룹(Group)으로 나타내야 하는 실제 시나리오를 다룹니다. 제안된 방법은 커널 평균 임베딩(kernel mean embeddings)과 공분산 연산자 임베딩(covariance operator embeddings)을 사용하여 데이터 분포를 힐베르트 공간(Hilbert Space)으로 매핑합니다. 중요한 점은 제안된 커널 k가 특징 맵 ϕ를 통해 확률 분포 P를 고유하게 임베딩할 수 있어야 한다는 것입니다.

- **Performance Highlights**: 제안된 데이터 의존 분포 커널 학습 프레임워크는 다양한 모달리티에서 분류 작업을 수행해 성능을 입증했습니다. 특히, 이 방법은 기존의 핸드픽 커널 선택 관행 대신 이론적으로 근거 있는 대안을 제공하고 복잡한 분포 기반 문제 해결에 있어 강력한 도구임을 보여주었습니다.



### The Energy Cost of Artificial Intelligence of Things Lifecyc (https://arxiv.org/abs/2408.00540)
Comments:
          12 pages, 13 figures

- **What's New**: 최근 사물인터넷(IoT)과 AI를 결합한 AIoT 시스템에서 에너지와 탄소 비용이 문제가 되는 것을 해결하기 위해 새로운 지표, AIoT 라이프사이클의 에너지 비용(eCAL)을 제안했습니다. eCAL은 AIoT 시스템의 생애 주기 동안 데이터 조작의 복잡성을 분석하여 전체 및 비트당 에너지 소비를 포착합니다.

- **Technical Details**: eCAL은 AIoT 시스템을 데이터 수집, 저장, 전처리, 학습, 평가, 추론 등의 여러 데이터 조작 구성 요소로 분해하여 각 구성 요소의 에너지 소비를 분석합니다. 이는 비트당 에너지 비용을 측정하는 기존의 'Energy-per-Bit' 지표와는 달리, 모델 추론에 소요되는 전체 에너지를 포착하는 데 중점을 둡니다. 또한, eCAL을 통해 모델이 더 잘 될수록, 그리고 더 자주 사용될수록 추론의 에너지 효율이 증가함을 보여 줍니다.

- **Performance Highlights**: AIoT 시스템의 경우, 예를 들어 100회의 추론을 수행하는 것보다 1000회의 추론을 수행하는 것이 비트당 에너지 소비가 1.43배 더 적은 것으로 나타났습니다. 또한, 2023년 재생 가능 에너지 데이터를 사용한 분석 결과, 독일에서 AIoT 시스템을 배포할 경우 핀란드에서보다 4.62배 더 많은 CO2 배출량을 초래함을 확인했습니다.



### Intermittent Semi-working Mask: A New Masking Paradigm for LLMs (https://arxiv.org/abs/2408.00539)
- **What's New**: 이번 연구에서는 Intermittent Semi-working Mask (ISM)라는 새로운 마스킹 스킴(scheme)을 제안하여 다중 회차 대화(multi-turn dialogues)에서 발생하는 문제를 해결하고자 합니다. ISM은 프리픽스 언어모델(prefix LLM)의 높은 품질과 인과 언어모델(causal LLM)의 낮은 생성 지연(latency)을 동시에 유지할 수 있습니다.

- **Technical Details**: 기존 언어모델은 인과 모델과 프리픽스 모델로 구분되며, 프리픽스 모델은 쿼리(query)와 응답(answer)에 대해 양방향 주의(attention)를 적용하여 다중 회차 대화에서 더 나은 성능을 보입니다. 그러나 이는 높은 생성 지연을 초래합니다. ISM은 대화 기록의 쿼리와 응답에 대해 교차적으로 양방향 및 단방향 주의를 적용하여 해당 문제를 해결합니다. 구체적으로는 쿼리와 응답이 후속 쿼리나 응답에 주의를 기울이지 못하도록 하고, 이를 통해 캐시(KV Cache)를 재사용하여 생성 지연을 줄입니다.

- **Performance Highlights**: 실험 결과 ISM은 기존 프리픽스 및 인과 LLM과 비교하여 다중 회차 대화에서 최첨단의 생성 품질과 낮은 지연을 실현했습니다. GPT-4를 평가자로 활용한 벤치마크 데이터셋 실험에서 ISM의 우수성이 입증되었습니다.



### Hilbert curves for efficient exploratory landscape analysis neighbourhood sampling (https://arxiv.org/abs/2408.00526)
Comments:
          A version of this paper is published as conference proceedings of EvoApps 2024

- **What's New**: 본 연구에서는 최적화 문제의 탐색 공간을 효율적으로 샘플링하기 위한 새로운 방법으로 힐버트 곡선(Hilbert curves)을 제안합니다. 힐버트 곡선은 공간을 일관되게 커버하며, 인접한 포인트 사이의 관계를 보존하는 특징을 가지고 있어 정보 컨텐츠와 같은 중요한 다차원 위치 정보를 효과적으로 추출할 수 있습니다.

- **Technical Details**: 힐버트 곡선은 프랙탈 곡선의 한 유형으로, 유한한 반복 과정을 통해 다차원 공간을 채우는 연속 함수입니다. 연구에서는 전체 탐색 공간을 균등하게 덮으며 서로 인접한 포인트를 효과적으로 맞추기 위해 Hilbert Space-Filling Curve를 사용하였습니다. 이는 기존의 가장 가까운 이웃(nearest neighbor) 알고리즘보다 계산 비용이 적게 들면서 높은 품질의 샘플을 얻을 수 있게 해줍니다.

- **Performance Highlights**: 연구 결과, Hilbert 곡선을 사용하는 샘플링 방법이 라틴 하이퍼큐브 샘플링(Latin hypercube sampling, LHS) 및 이웃 정렬 방식에 비해 계산 비용에서 큰 절감을 이루며, 추출된 특징의 품질에서도 우수한 성능을 나타냈습니다. 힐버트 곡선을 통한 이웃 정렬 방식은 기존의 가장 가까운 이웃 정렬 방식보다 훨씬 빠르게 수행되며, 높은 이웃 관계 보존 능력을 보여줍니다.



### Jailbreaking Text-to-Image Models with LLM-Based Agents (https://arxiv.org/abs/2408.00523)
- **What's New**: 최근 AI 연구에서 대화, 프로그래밍 또는 특수 도메인에 주로 집중했던 대규모 언어 모델(LLM) 기반의 자율 에이전트에 반해, 생성 AI 안전성 작업을 해결하는 새로운 프레임워크 Atlas를 도입하였습니다. Atlas는 T2I(Text-to-Image) 모델의 안전 필터를 우회할 수 있는 자율 에이전트 시스템으로, 다양한 프롬프트를 생성하여 이러한 필터를 우회하도록 설계되었습니다.

- **Technical Details**: Atlas는 비전 언어 모델(VLM)을 활용해 제공된 프롬프트가 T2I 모델의 안전 필터를 작동시키는지 평가합니다. 그런 다음, LLM과 VLM이 협력해 필터를 우회할 수 있는 대체 프롬프트를 생성합니다. 이를 위해 다중 에이전트 커뮤니케이션, 컨텍스트 학습(ICL) 메모리 메커니즘 및 체인 오브 사고(COT) 접근방식을 사용하여 LLM의 추론 능력을 강화합니다.

- **Performance Highlights**: 평가 결과, Atlas는 다양한 최신 T2I 모델의 다중 모드 안전 필터를 성공적으로 우회하였으며, 기존 방법보다 더 적은 쿼리 수로 높은 품질의 이미지를 생성하였습니다. 특히, 기존 안전 필터에서는 거의 100%의 우회율을 달성하였고, 가장 보수적인 안전 필터에서도 82.45% 이상의 우회율을 보였습니다.



### Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation (https://arxiv.org/abs/2408.00490)
Comments:
          14 pages

- **What's New**: 새로운 연구에서는 그래프 신경망(GNNs)을 기반으로 한 추천 시스템이 독립적이고 동일분포(IID) 데이터에 기반한 가정이 많은 경우 에외 배치 데이터(out-of-distribution, OOD)에서 성능 저하가 발생하는 문제를 다루고 있습니다. 이를 해결하기 위해, 인과 확산(Causal Diffusion)을 통한 그래프 표현 학습(CausalDiffRec)이라는 새로운 방법이 제안되었습니다. 이 방법은 환경혼란요소를 제거하고 불변 그래프 표현을 학습하여 OOD 데이터에서 모델의 일반화를 향상시킵니다.

- **Technical Details**: CausalDiffRec 방법은 세 가지 주요 구성 요소로 이루어져 있습니다: 환경 생성기(environment generator), 환경 추론(environment inference), 확산 모듈(diffusion module). 환경 생성기는 여러 환경에서 데이터 분포를 시뮬레이션하기 위해 다양한 그래프를 생성하고, 환경 추론 모듈은 이러한 생성된 그래프로부터 환경 요소를 추론하여 불변 그래프 표현 학습을 지도합니다. 확산 모듈은 가역 확산 과정에서 불변 표현을 학습하는 역할을 수행합니다. 또한 이 연구는 인과 확산 기법을 통해 서로 다른 환경에서 불변 그래프 표현을 학습함으로써 OOD 데이터에서의 일반화 성능을 높일 수 있음을 이론적으로 증명합니다.

- **Performance Highlights**: 광범위한 실험을 통해 CausalDiffRec의 OOD 데이터 일반화 성능 향상을 검증하였으며, Food, KuaiRec, Yelp2018, Douban 데이터셋에서 각각 평균 10.69%, 18.83%, 22.41%, 11.65%의 성능 향상을 기록했습니다.



### A Systematic Review on Long-Tailed Learning (https://arxiv.org/abs/2408.00483)
Comments:
          Current Under Revision at IEEE TNNLS. [This is the long/Full-length version of our Long-Tailed Learning Survey paper]

- **What's New**: 이번 연구는 긴 꼬리(롱테일) 학습의 최신 동향을 포괄적으로 조사한 논문입니다. 연구진은 긴 꼬리 학습을 위해 새로운 분류법(새로운 taxonomy)을 제안하며, 데이터 균형 조정(data balancing), 신경망 구조(neural architecture), 특징 강화(feature enrichment), 로짓 조정(logits adjustment), 손실 함수(loss function), 부가 기능(bells and whistles), 네트워크 최적화(network optimization), 사후 처리(post hoc processing) 등 8가지 측면으로 나누어 분석하였습니다.

- **Technical Details**: 긴 꼬리 학습(long-tailed learning)에서는 주요 목표가 각 클래스의 샘플 수 불균형을 해결하고, 특히 소수 클래스(minority/tail classes)를 정확히 식별하는 모델을 개발하는 것입니다. 이번 연구에서는 다양한 롱테일 학습 방법들을 제안된 분류법에 따라 체계적으로 리뷰하고, 롱테일 학습과 불균형 학습(imbalance learning)의 차이점을 분석합니다. 주요 접근 방식으로는 데이터 재샘플링(resampling), 손실 함수 재가중(loss reweighting), 전이 학습(transfer learning) 등이 포함됩니다.

- **Performance Highlights**: 논문은 롱테일 시나리오에서 사용되는 다양한 학습 방법들이 소수 클래스에 대한 인식률을 개선함을 강조합니다. 특히, 심층 특징 표현 학습(deep feature representation learning)과 분류기 훈련(classifier training) 분리를 통한 방식, 샘플 가중치를 다르게 부여하는 방법 등이 중요한 성과를 보였습니다. 여러 하위 작업에서의 실험 결과도 요약되며, 향후 연구 방향에 대한 논의도 포함됩니다.



### Towards Explainable and Interpretable Musical Difficulty Estimation: A Parameter-efficient Approach (https://arxiv.org/abs/2408.00473)
- **What's New**: 이 논문은 상징적 음악 표현(symbolic music representations)에서 음악의 난이도를 추정하는 데 사용될 수 있는 설명 가능한 설명자(explainable descriptors)를 도입하고 있습니다. 이를 통해 음악 교육에서 기존의 심층 학습 모델이 가지는 불투명성을 해결하고자 합니다. 이 연구는 새로운 파라미터 효율적인 화이트박스 모델(white-box model)을 통해 이전 연구들을 능가하는 해석 가능한 결과를 제공합니다.

- **Technical Details**: RubricNet이라고 불리는 이 화이트박스 모델은 음악 교육에서 널리 사용되는 평가 도구인 루브릭(rubric)의 개념을 사용하여 음악 난이도를 투명하게 해석할 수 있게 설계되었습니다. 이 모델은 각각의 입력 설명자를 처리하는 일련의 선형 층(linear layers)과 비선형 활성화 함수(nonlinear activation function)로 구성됩니다. 모델의 예측은 시그모이드 함수(sigmoid function)를 사용하여 확률로 변환되며, 이는 MSE(mean squared error) 손실을 사용하여 최적화됩니다.

- **Performance Highlights**: 이 연구는 9개의 클래스로 분류된 피아노 레퍼토리를 평가하여 41.4%의 독립적인 정확도와 1.7의 평균 제곱 오차(MSE)를 달성했습니다. 이는 기존의 연구들을 능가하며, 해석 가능한 결과를 통해 음악 교육에서 실제로 활용될 수 있습니다.



### Image Super-Resolution with Taylor Expansion Approximation and Large Field Reception (https://arxiv.org/abs/2408.00470)
- **What's New**: 이 논문은 블라인드 초해상도(SR) 작업에서 자가 유사성(self-similarity) 기법의 높은 계산 복잡성을 해결하기 위해 새로운 접근 방식을 제안합니다. 저자들은 자가 유사성 계산에서 발생하는 고차원 행렬 곱셈의 복잡성을 낮추기 위해 이차 Taylor 전개 근사법(STEA)을 도입했습니다. 이는 계산 복잡성을 $	ext{𝒪}(N^2)$에서 $	ext{𝒪}(N)$으로 줄여줍니다. 또한, STEA로 인한 성능 저하를 보완하기 위해 다중 스케일 큰 영역 수용(Multi-Scale Large Field Reception, MLFR)을 설계했습니다. 이 두 가지 핵심 디자인을 LabNet(실험실 데이터용) 및 RealNet(실제 데이터용) 네트워크에 적용했습니다.

- **Technical Details**: 고차원 자가 유사성 계산은 Query와 Key의 행렬 곱에 의한 높은 계산 복잡성을 초래합니다. 이를 해결하기 위해 저자들은 Query와 Key의 곱을 분리하는 이차 Taylor 전개 근사법(STEA)을 제안했습니다. STEA는 자가 유사성 계산에서 발생하는 계산 복잡성을 크게 줄여줍니다. 하지만 STEA로 인해 전역 특성을 필터링하는 능력이 상실되므로, MLFR 모듈을 설계하여 이를 보완했습니다. LabNet과 RealNet은 이러한 두 가지 핵심 디자인(STEA와 MLFR)을 실험실 데이터와 실제 데이터 시나리오에 각각 적용했습니다.

- **Performance Highlights**: 실험 결과, LabNet은 다섯 개의 합성 데이터셋에서 질적 및 양적 평가에서 새로운 벤치마크를 설정했습니다. RealNet은 RealWorld38 데이터셋에서 기존 방법들보다 우수한 시각적 품질을 달성했습니다. 또한, 분리 연구(ablation studies)를 통해 STEA와 MLFR이 LabNet과 RealNet 프레임워크에 기여한 바를 검증했습니다.



### DiscipLink: Unfolding Interdisciplinary Information Seeking Process via Human-AI Co-Exploration (https://arxiv.org/abs/2408.00447)
- **What's New**: 이번 연구에서는 다양한 학문 분야의 정보를 탐색하는 데 도움을 주는 상호작용 시스템인 DiscipLink를 소개합니다. DiscipLink는 대형 언어 모델(LLMs)과 협력하여 사용자의 관심 주제를 기반으로 탐색 질문을 생성하고, 선택한 질문에 따라 논문을 검색하고 스크리닝하는 과정을 지원합니다.

- **Technical Details**: DiscipLink는 먼저 사용자의 관심 주제에 대해 다양한 학문 분야의 관점에서 탐색 질문(Exploratory Questions, EQs)을 생성합니다. 사용자는 이러한 EQ들을 더 구체화하거나 새로운 방향으로 질문을 유도할 수 있습니다. EQ에 대한 기존 지식을 제시하는 과정에서 LLM 기반 쿼리 확장 전략을 사용하여 다양한 분야의 논문을 검색하며, 검색된 논문에서 주제를 추출하고 사용자의 탐색 포커스와의 연결점을 강조합니다. 평가 과정에서 12명의 대학원생과 7명의 경험 있는 연구자들을 대상으로 DiscipLink의 효율성과 사용성을 검증했습니다.

- **Performance Highlights**: DiscipLink는 참가자들이 과제를 더 효율적으로 수행할 수 있도록 돕고, 더 포괄적인 범위의 지식을 발견하는 데 도움을 주었습니다. 연구자들은 DiscipLink의 공동 탐색 워크플로우를 높이 평가했으며, 이 시스템이 개인 연구자의 독특한 요구를 충족하는 데에 아직 한계가 있음을 지적했습니다.



### Focus, Distinguish, and Prompt: Unleashing CLIP for Efficient and Flexible Scene Text Retrieva (https://arxiv.org/abs/2408.00441)
Comments:
          Accepted by ACM MM 2024

- **What's New**: 새로운 연구에서는 Optical Character Recognition (OCR) 기술 없이도 장면 텍스트 검색(Scene Text Retrieval, STR)을 효과적으로 수행할 수 있는 모델, FDP(Focus, Distinguish, and Prompt)를 소개합니다. CLIP(Contrastive Language-Image Pre-training)의 내재된 잠재력을 활용하여 빠른 속도와 뛰어난 검색 정확성을 모두 달성합니다.

- **Technical Details**: FDP 모델은 먼저 CLIP의 주의를 텍스트 영역으로 집중시키기 위해 이미지의 대략적인 텍스트 위치를 모델에게 제공합니다. 그런 다음, 주어진 쿼리 텍스트를 내용어(content word)와 기능어(function word)로 구분하고, 각 종류별로 다른 검색 방법을 적용합니다. 마지막으로, 의미 인지 prompting 전략을 이용해 쿼리 텍스트를 학습 가능한 프롬프트로 변환하고 각 이미지와의 유사성 점수를 계산해 랭킹합니다. 또한, 비슷한 단어들의 부정적 효과를 최소화하기 위해 distracted queries assistance 전략을 적용합니다.

- **Performance Highlights**: FDP는 IIIT-STR 벤치마크에서 기존 최고 성능 모델보다 4.37% 높은 mAP 점수를 기록했으며, 추론 속도는 4배 빠릅니다. FDP는 다양한 형태의 쿼리 텍스트에 대해 더욱 유연하고 일반화된 성능을 보여줍니다.



### A Qualitative Study on Using ChatGPT for Software Security: Perception vs. Practicality (https://arxiv.org/abs/2408.00435)
Comments:
          Accepted for publication at International Conference on Trust, Privacy and Security - 2024

- **What's New**: 대규모 언어 모델 (LLMs)의 발전으로 ChatGPT와 같은 인공지능(AI) 챗봇이 다양한 금지능력 및 정확성을 바탕으로 여러 작업을 수행할 수 있게 되었습니다. 이 논문은 ChatGPT가 소프트웨어 보안 작업에서 어떻게 보완될 수 있는지를 조사합니다. 특히, 실 사용자 평가와 실제 환경에서의 실험을 통해 ChatGPT의 보안 관련 잠재력을 평가했습니다.

- **Technical Details**: 연구팀은 두 가지 접근법을 사용하여 연구를 진행했습니다. 먼저, Twitter에서 소프트웨어 보안을 위한 ChatGPT 사용에 대한 사용자들의 견해를 분석한 경험적 연구를 수행했습니다. 이후, 취약성 탐지를 중심으로 한 실험을 통해 실세계 환경에서의 ChatGPT의 실효성을 평가했습니다. 이 과정에서 40가지 취약성 유형과 12개 프로그래밍 언어를 다루는 데이터셋을 사용했습니다.

- **Performance Highlights**: Twitter 데이터 분석 결과, 보안 전문가들은 ChatGPT가 취약점 탐지, 정보 검색 및 침투 테스트와 같은 다양한 소프트웨어 보안 작업에 유용하다고 평가했습니다. 그러나 실제 실험에서는 ChatGPT가 제공하는 정보가 대체로 일반적인 보안 정보에 불과하여 산업적 용도로는 부적합하다는 결론에 도달했습니다. 이를 통해, 추후 LLMs가 소프트웨어 보안을 위한 특화된 모델로 발전할 수 있는 방향성을 제시했습니다.



### Augmenting Channel Simulator and Semi- Supervised Learning for Efficient Indoor Positioning (https://arxiv.org/abs/2408.00429)
Comments:
          ACCEPTED for presentation at 2024 IEEE Global Communications Conference

- **What's New**: 이 연구는 실내 위치 추적의 노동 집약적이고 자원 소모적인 문제를 해결하기 위해 효율적인 접근 방식을 제안합니다. 제안된 접근 방식은 라벨링된 데이터와 비라벨링된 채널 데이터를 효과적으로 활용하는 편향된 교사를 포함한 반지도 학습(SSLB: Semi-Supervised Learning with a Biased Teacher) 알고리즘 도입을 포함합니다. 이를 통해 측정 비용과 하이퍼파라미터 조정 문제를 개선하며, 시뮬레이션 결과에서 낮은 비용으로 높은 성능을 보여줍니다.

- **Technical Details**: 이 연구에서 제안된 부가된 기능은 업데이트된 채널 시뮬레이터(UCHS: Updated Channel Simulator)를 사용하여 비라벨링된 데이터를 생성하는 것입니다. 이를 통해 측정 환경의 확률적 파라미터를 추출하고, 라벨링된 데이터와 유사한 비라벨링된 채널 데이터를 시뮬레이션합니다. 또한, 라벨링된 데이터와 비라벨링된 데이터의 특징을 포착하기 위해 신뢰도를 기반으로 비라벨링된 데이터를 가중하는 편향된 교사 SSLB를 도입합니다. 이는 실내 위치 추적과 같은 회귀 작업에서 처음으로 신뢰도를 도입한 사례입니다.

- **Performance Highlights**: 제안된 접근 방식은 기존 벤치마크에 비해 측정 오버헤드와 훈련 비용을 최소화하면서 탁월한 성능을 보여줍니다. 특히, 비라벨링된 데이터의 신뢰도를 얻기 위해 설계된 새로운 SSL 구조(SSLB)가 추가적인 바이어스 정보를 라벨링된 데이터셋에서 추출하여 훈련 비용 절감을 크게 달성합니다.



### CARMIL: Context-Aware Regularization on Multiple Instance Learning models for Whole Slide Images (https://arxiv.org/abs/2408.00427)
- **What's New**: 새로운 연구는 Context-Aware Regularization for Multiple Instance Learning (CARMIL)을 제안하여, 기존의 MIL 모델이 놓치고 있는 공간적 지식을 통합할 수 있도록 설계되었습니다. 또한, 어떤 MIL 모델이 Whole Slide Images(WSIs)에서 공간 인식을 잘 수행하는지 정량화할 수 있는 새로운 기준인 DeltaCon도 도입되었습니다.

- **Technical Details**: CARMIL은 기본 MIL 모델에 공간 인식 기능을 추가하기 위해 정규화(regularization)을 사용합니다. 공간 인코더와 디코더는 특징 추출기와 MIL 모델 사이에 추가되며, Context-Aware Regularization (CAR) 손실 함수를 사용하여 타일 임베딩의 공간적 관계를 보존하도록 학습합니다. 이를 통해 WSI의 타일 간 공간적 관계를 보다 정확하게 반영할 수 있습니다.

- **Performance Highlights**: 본 논문은 CARMIL의 효율성을 신경교세포종(TCGA GBM)과 결장암(TCGA COAD) 데이터를 사용한 생존 분석 작업에서 평가하였습니다. 기존의 공간적 지식이 없는 MIL 모델을 CARMIL을 통해 공간 인식 모델로 변환하고, 이를 통해 C-index(생존 예측의 성능 지수)가 향상됨을 입증하였습니다.



### Towards Evolutionary-based Automated Machine Learning for Small Molecule Pharmacokinetic Prediction (https://arxiv.org/abs/2408.00421)
Comments:
          Paper accepted and presented at the 14th Workshop on Evolutionary Computation for the Automated Design of Algorithms (ECADA), which happened during the Genetic and Evolutionary Computation Conference (GECCO)

- **What's New**: 본 논문에서는 소분자 약리학적 예측을 위해 새로운 자동화 머신 러닝(AutoML) 방법을 제안합니다. 이 방법은 문법 기반의 유전프로그래밍(grammar-based genetic programming)을 활용하여 입력된 분자 데이터의 특성에 맞춘 예측 파이프라인을 자동으로 선택하고 설계합니다. 기존의 수동 제작된 머신 러닝 알고리즘이나 파이프라인의 비효율성과 편향성을 극복하여, 약리학적 예측 성능을 개선합니다.

- **Technical Details**: 제안된 AutoML 방법은 문맥 자유 문법(context-free grammar)을 사용하여 알고리즘 탐색 공간을 정의하고, 분자 표현, 특징 전처리, 특징 선택, 머신 러닝 모델링 및 하이퍼 파라미터 최적화를 포함한 최적 예측 파이프라인을 찾기 위해 문법 기반 유전프로그래밍(GGP)을 이용합니다. 이 방법은 작은 분자 데이터셋에 대해 최적화된 ML 구동 약물 발견 파이프라인을 추천하는 원스톱(end-to-end) 접근법을 제공합니다.

- **Performance Highlights**: 12개의 PK 데이터셋에 대한 결과에서 AutoML 방법이 다양한 머신 러닝 알고리즘을 효과적으로 선택하여 기존의 비정교한 방법 및 첨단 방법과 비교하여 유사하거나 개선된 예측 성능을 보였습니다. 이 방법은 소분자 연구의 약물 발견에서 중요한 자원으로 활동할 것으로 기대됩니다.



### MPT-PAR:Mix-Parameters Transformer for Panoramic Activity Recognition (https://arxiv.org/abs/2408.00420)
- **What's New**: 이번 연구에서는 복잡하고 혼잡한 환경에서 다양한 세분화 수준에서 행동을 인식하는 파노라마 활동 인식(Task)에 대한 새로운 모델인 MPT-PAR를 제안합니다. 기존 방법들과 달리, MPT-PAR는 각 Task의 고유한 특성과 서로 다른 Task 간의 시너지 효과를 동시에 고려하여 다중 세분화 활동 인식을 극대화합니다.

- **Technical Details**: MPT-PAR 모델은 개별 행동, 사회적 그룹 활동, 그리고 글로벌 활동을 다루기 위해 인코더를 설계했습니다. 이를 통해 여러 세분화 수준에서의 특징을 동시에 통합하며, MPT-PAR는 파라미터 독립 모듈과 파라미터 공유 모듈을 함께 사용해 최상의 성능을 이끌어냅니다. 시간적(Temporal) 및 공간적(Spatial) 정보를 강조하기 위해, 시간-공간 관계 증강 모듈과 장면 재현 학습 모듈을 도입했습니다. 이 모듈들은 행동의 시간적 및 공간적 맥락을 특징 맵에 통합합니다.

- **Performance Highlights**: JRDB-PAR 데이터셋에서 MPT-PAR 모델은 47.5%의 F1 점수를 기록했으며, 이는 최첨단 방법들에 비해 6% 향상된 결과입니다. 특히, 글로벌 활동 인식 서브타스크에서 61.1%의 F1 점수를 기록하며 가장 큰 향상을 보여주었습니다.



### DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving (https://arxiv.org/abs/2408.00415)
Comments:
          19 pages, 9 figures

- **What's New**: 고품질의 폐쇄 루프 시뮬레이션 시스템 DriveArena가 발표되었습니다. 이 시스템은 실제 주행 시나리오에서 주행 에이전트(driving agents)를 평가할 수 있도록 설계되었습니다. 주요 특징으로는 교통 시뮬레이터인 Traffic Manager와 고충실도 조건부 생성 모델인 World Dreamer의 결합이 있습니다.

- **Technical Details**: DriveArena는 모듈화된 구조로, 주요 구성 요소들을 자유롭게 교체할 수 있습니다. Traffic Manager는 전 세계의 어떠한 도로 지도에서도 현실감 있는 교통 흐름을 생성할 수 있으며, World Dreamer는 무한 오토리그레션(autoregression)을 갖춘 고충실도 모델입니다. 이 시스템은 카메라 입력 기반 주행 에이전트와 통합되며 실시간 상호작용을 통해 폐쇄 루프 시뮬레이션을 실현합니다.

- **Performance Highlights**: DriveArena는 다양한 복잡한 주행 시나리오에서 주행 에이전트가 계속해서 학습하고 진화할 수 있도록 돕습니다. Traffic Manager는 동적인 교통 시나리오를 생성할 수 있고, World Dreamer는 다양한 시간대 및 날씨 조건에서 현실감 있는 이미지를 생성할 수 있습니다. 이러한 상호작용을 통해 주행 에이전트의 실제 주행 능력을 종합적으로 평가할 수 있습니다.



### Enhancing Whole Slide Pathology Foundation Models through Stain Normalization (https://arxiv.org/abs/2408.00380)
Comments:
          13 pages, 8 figures

- **What's New**: 최근 디지털 병리학에서 자체-지도 학습 (self-supervised learning) 기법을 사용하여 기초 모델을 개발하는 연구가 활발히 진행되고 있습니다. 이러한 모델들은 주로 전체 슬라이드 이미지 (Whole Slide Images, WSIs)에서 추출한 작은 패치를 이용해 학습합니다. 그러나, 우리는 WSI-특정 특징 붕괴(WSI-specific feature collapse)라 불리는 중요한 문제를 발견했으며, 이를 해결하기 위해 염색 정상화를 적용한 병리학 기초 모델인 Stain Normalized Pathology Foundational Model을 도입했습니다.

- **Technical Details**: WSI-특정 특징 붕괴는 각 WSI에서 추출한 패치의 특징들이 특정 WSI에 따라 군집화되는 현상을 말합니다. 이를 해결하기 위해 패치 전처리 단계에서 Macenko 염색 정상화를 적용하여 색상 변동을 줄였습니다. 우리 모델은 총 34,795개의 WSI에서 추출한 285,153,903개의 패치를 이용해 학습되었습니다. DINO(self-DIstillation with NO labels) 자체-지도 학습 방법을 사용하여 모델을 구축했습니다.

- **Performance Highlights**: Stain Normalized Pathology Foundational Model은 다양한 패치 수준의 작업에서 기존 최첨단 모델들과의 비교에서 우수한 성능을 보였습니다. 특히, PCAM, MHIST, CRC 100k, TIL-Detection, MSI-CRC 및 MSI-STAD와 같은 여섯 가지 다운스트림 데이터셋에서 뛰어난 성능을 기록했습니다. 이러한 결과는 염색 정상화의 도입이 모델의 효율성과 일반화 능력을 크게 향상시켰음을 시사합니다.



### On the Limitations and Prospects of Machine Unlearning for Generative AI (https://arxiv.org/abs/2408.00376)
- **What's New**: 이번 논문에서는 Generative AI(GenAI, 생성 AI) 분야에서 data 관련 위험성을 줄이기 위해 제안된 Machine Unlearning 기법에 대해 심층적으로 논의합니다. GenAI는 텍스트, 이미지, 오디오 및 그래프와 같은 다양한 도메인에서 탁월한 성과를 얻었지만, 데이터 프라이버시, 보안 및 윤리적인 측면에서 새로운 도전과 위험을 초래하고 있습니다.

- **Technical Details**: Machine Unlearning은 특정 데이터 샘플이나 특징을 훈련된 모델에서 제거 또는 약화시키는 과정을 의미합니다. 전통적인 머신러닝 작업에서는 이미 효능이 입증되었지만, GenAI에서의 적용 가능성은 아직 불확실합니다. 이번 논문에서는 문제의 형성화, 배경, 현재 기법의 한계에 대해 논의하고, LLMs 및 이미지 생성 모델(difussion models)을 중심으로 분석합니다.

- **Performance Highlights**: Machine Unlearning을 GenAI에 적용함에 있어 몇 가지 중요한 한계가 식별되었습니다. 첫째, 실질적인 응용을 위해 충분히 효과적인 수준에 도달하지 못했습니다. 둘째, 현재의 평가 지표는 다각적인 영향을 충분히 포착하지 못하며, 셋째, unlearning 기법이 모델의 성능과 일반화 및 안전성에 미치는 영향이 우려됩니다. 연구는 향후 평가 지표의 강화, 벤치마킹, 유틸리티와 unlearning의 균형 조사에 집중할 것을 제안합니다.



### DiM-Gesture: Co-Speech Gesture Generation with Adaptive Layer Normalization Mamba-2 framework (https://arxiv.org/abs/2408.00370)
Comments:
          10 pages,10 figures. arXiv admin note: text overlap with arXiv:2403.10805

- **What's New**: 최신 연구에서는 Transformer 기반 아키텍처의 메모리 사용 문제와 느린 추론 속도의 한계를 극복하기 위해, DiM-Gestures라는 새로운 끝에서 끝까지 처리 가능한 생성 모델을 제안합니다. 이 모델은 Mamba 기반 아키텍처를 이용하여 원시 음성 오디오에서 3D 전신 제스처를 생성하며, 특히 Mamba 기반 퍼지 특성 추출기와 비자연회귀형 적응형 레이어 정규화(AdaLN) Mamba-2 확산 아키텍처를 통합하고 있습니다.

- **Technical Details**: DiM-Gestures 모델은 Mamba 기반 프레임워크와 WavLM 사전 학습된 모델을 활용하여 퍼지 특성을 자동으로 추출합니다. 이 추출된 특성은 단일 잠재 특성으로 결합되어 AdaLN Mamba-2에서 처리됩니다. AdaLN Mamba-2는 모든 토큰에서 일관된 조건 메커니즘을 구현하여 퍼지 특성과 결과 제스처 시퀀스 간의 상호 작용을 강력하게 모델링합니다. Diffusion 모델을 사용하여 학습과 추론을 수행하며, ZEGGS와 BEAT 데이터셋에서 광범위한 주관적 및 객관적 평가를 통해 우수한 성과를 입증하였습니다.

- **Performance Highlights**: 주관적 및 객관적 평가 결과, DiM-Gestures 모델은 현재의 최첨단 방법들보다 향상된 성능을 보였으며, 특히 메모리 사용을 최적화하고 추론 속도를 가속화한 것으로 나타났습니다. 이는 변환기 아키텍처와 비교하여 더욱 자연스럽고, 고품질의 동작을 생성하면서도 높은 제스처-음성 동기화를 보장하는데 성공하였습니다.



### DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved Denoising Training (https://arxiv.org/abs/2408.00355)
Comments:
          Accepted by ACMMM2024

- **What's New**: DNTextSpotter라는 새로운 노이즈 제거 훈련 방법을 제안하여 Transformer 기반의 텍스트 스포팅(Textr Spotting) 작업을 개선합니다. 이 새로운 방법은 비정형 텍스트 감지 및 인식을 목표로 합니다. 특히, 베지어(Beziér) 중심 곡선의 제어점을 사용해 노이즈 위치 쿼리를 생성하며, 'masked character sliding' 방법을 도입하여 내용과 위치를 일치시킵니다.

- **Technical Details**: DNTextSpotter는 비정형 텍스트 감지를 위해 설계된 새로운 노이즈 제거 훈련 방법입니다. 이 방법은 노이즈 위치 쿼리와 노이즈 내용 쿼리로 쿼리를 분해합니다. 노이즈 위치 쿼리는 베지어 중심 곡선 제어점을 이용해 생성되고, 노이즈 내용 쿼리는 'masked character sliding' 방법을 사용하여 텍스트의 내용이 위치와 일치하도록 초기화됩니다. 또한, 모델이 배경 문자 분류에 대한 추가 손실 함수를 활용하여 배경에 대한 인식을 높입니다.

- **Performance Highlights**: DNTextSpotter는 네 가지 벤치마크(총-텍스트, SCUT-CTW1500, ICDAR15, Inverse-Text)에서 최첨단 방법들을 능가하는 성능을 보였습니다. 특히, Inverse-Text 데이터셋에서는 기존 최상의 방법보다 11.3% 개선된 성과를 기록했습니다. 또한 ResNet-50 백본을 사용한 'None' 결과 측정 지표에서 Total Text와 CTW1500 데이터셋에서 각각 2.0%와 2.1% 성능 향상을 나타냈습니다.



### A Simple Background Augmentation Method for Object Detection with Diffusion Mod (https://arxiv.org/abs/2408.00350)
- **What's New**: 이번 연구에서는 객체 탐지(Object Detection)와 인스턴스 세분화(Instance Segmentation)와 같은 다양한 다운스트림 작업에 유익하도록 데이터셋의 다양성을 개선하는 문제를 다루었습니다. 새로운 데이터 증강(data augmentation) 접근법을 제안하면서, Stable Diffusion과 같은 텍스트-이미지 합성 기술(text-to-image synthesis)을 활용하여 라벨이 붙은 실제 이미지의 변형을 생성하고, 추가적인 주석(annotation) 없이도 기존의 학습 데이터를 증강할 수 있도록 했습니다. 특히 배경 증강(background augmentation)은 모델의 강건성과 일반화 능력을 크게 향상시켰습니다.

- **Technical Details**: 제안된 방법은 생성 모델(generative model), 특히 텍스트-이미지 합성(text-to-image synthesis)을 사용하여 라벨이 붙은 실제 이미지의 변형을 생성하는 것입니다. Stable Diffusion 모델을 활용하여 라벨이 있는 실제 이미지의 객체와 배경을 적절히 증강합니다. 주요한 접근법은 인페인팅(inpainting)을 통해 기존 주석을 유지하면서 학습 데이터를 증강하는 것입니다. 텍스트 프롬프트(prompt)와 마스크(mask)를 조정하여 생성된 콘텐츠가 기존 주석과 일치하도록 보장합니다.

- **Performance Highlights**: 제안된 증강 기법의 효과는 COCO 데이터셋과 다양한 객체 탐지 벤치마크를 통해 확인되었습니다. 배경 증강을 통해 모델 성능이 크게 향상되었으며, 예를 들어 COCO 학습 데이터의 10%만 사용했을 때 mAP가 최대 5.3%까지 증가했습니다. 이러한 증강 기법은 다양한 어려운 상황에서도 객체 탐지 및 인스턴스 세분화 모델의 성능을 크게 향상시키는 것으로 나타났습니다.



### Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks (https://arxiv.org/abs/2408.00348)
- **What's New**: 최신 연구는 의료 영상 분석(MedIA) 기술에 대한 적대적 공격(adversarial attacks)과 그 방어 전략을 다룹니다. 특히, 딥 뉴럴 네트워크(DNN)가 적대적 공격에 취약함을 강조하면서, 의료 진단에 미치는 영향을 평가하는 것이 중요하다고 주장합니다.

- **Technical Details**: 적대적 공격(adversarial attacks)은 기계 학습 모델을 속이기 위해 고안된 미세한 변경 사항을 입력 데이터에 추가하는 기술입니다. '화이트박스 공격(White-box attacks)'과 '블랙박스 공격(Black-box attacks)'이 일반적이며, '훈련 단계에서의 적대적 공격(adversarial attacks at the training stage)'과 '테스트 단계에서의 회피 공격(evasion attacks)'이 주요 유형으로 설명됩니다. 또한, U-Net과 InceptionResNetV2 등의 모델이 적대적 공격에 취약함을 보였습니다.

- **Performance Highlights**: Ultrasound imaging에서의 적대적 공격은 InceptionResNetV2 모델의 정확도를 48% 감소시켰습니다. 의료 영상 세분화(segmenting) 작업에서는 적대적 사례가 DNN 모델의 성능을 크게 저하시킬 수 있으며, ISIC 피부 병변 데이터셋과 녹내장(optic disk) 데이터 셋에서의 실험이 이를 뒷받침합니다.



### Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer (https://arxiv.org/abs/2408.00347)
Comments:
          Accepted in BMVC 2024

- **What's New**: Diffusion Transformer Segmentation (DTS) 모델을 제안했습니다. 이 모델은 transformer 아키텍처를 활용하여 global dependency를 self-attention으로 캡쳐하고, 다양한 메디컬 이미징 모달리티에서 뛰어난 성능을 보여줍니다.

- **Technical Details**: DTS 모델은 Swin Transformer encoder와 UNet decoder를 결합하였습니다. 주목할 세 가지 주요 기술은 다음과 같습니다: k-neighbor label smoothing, reverse boundary attention, self-supervised learning. 이 방법들은 메디컬 이미지의 복잡한 구조를 식별하는 능력을 향상시킵니다.

- **Performance Highlights**: DTS 모델은 다양한 메디컬 이미징 모달리티 (CT, MRI, lesion images)에서 기존 모델보다 우수한 결과를 보여줍니다. 특히, 모델의 일반화 능력은 다른 도메인 테스크에서도 높은 성능을 유지함을 보여줍니다.



### Neural Graph Matching for Video Retrieval in Large-Scale Video-driven E-commerc (https://arxiv.org/abs/2408.00346)
- **What's New**: 전통적인 전자상거래가 짧은 동영상 기반의 전자상거래(video-driven e-commerce)와 결합함에 따라 새로운 패러다임이 등장했습니다. 이 방식은 매력적인 동영상을 사용하여 제품을 소개하고 사용자에게 동영상과 아이템 서비스를 동시에 제공합니다. 이 논문에서는 특히 동영상 검색(video retrieval) 작업에 초점을 맞추고 있습니다.

- **Technical Details**: 본 연구에서는 사용자-비디오 및 사용자-아이템 상호작용을 이중 그래프(dual graph)로 모델링하여 사용자 선호도 이해를 그래프 매칭 문제(graph matching problem)로 혁신적으로 줄이는 방식을 소개합니다. 이를 해결하기 위해 노드 수준 및 선호도 수준의 그래프 매칭으로 구성된 새로운 바이레벨 그래프 매칭 네트워크(bi-level Graph Matching Network, GMN)를 제안합니다. 노드 수준 매칭은 비디오와 아이템을 매칭하고, 선호도 수준 매칭은 비디오와 아이템에서 추출한 여러 사용자 선호도를 매칭하는 데 목표를 둡니다.

- **Performance Highlights**: 제안된 GMN은 AUC에서 1.9%, CTR에서 7.15% 상당의 성능 향상을 보이며, 최첨단 접근 방식들보다 우수한 성능을 보여주었습니다. 현재 이 기술은 하루에 수억 명의 사용자를 대상으로 동작하는 유명한 동영상 기반 전자상거래 플랫폼에 배포되어 사용되고 있습니다.



### MuJoCo MPC for Humanoid Control: Evaluation on HumanoidBench (https://arxiv.org/abs/2408.00342)
Comments:
          3 pages, 3 figures, submitted to IEEE Conference on Robotics and Automation (ICRA@40)

- **What's New**: 이번 연구에서는 전체 신체를 제어하는 휴머노이드 로봇의 새로운 벤치마크 테스트인 'HumanoidBench'를 MuJoCo와 MPC(Model Predictive Control)를 사용해 해결하려 시도했습니다. 기존의 보상 함수가 희소하여 비정상적이고 비현실적인 움직임을 유도하는 문제를 해결하기 위해 정규화 항을 도입했습니다. 또한 코드가 공개되어 MuJoCo MPC의 일부로 사용할 수 있게 되었습니다.

- **Technical Details**: 저자들은 MuJoCo 기반의 새로운 휴머노이드 로봇 벤치마크 테스트를 해결하기 위해 MPC를 사용했습니다. 이 방법은 매 시점마다 다단계 미리보기 검색을 통해 최적의 행동을 선택합니다. 보상 함수를 비용 함수로 변환한 후, 로봇의 안정성을 향상시키고 더 밀도 있는 보상 신호를 제공하는 여러 shaping terms를 도입했습니다. 예를 들어, 로봇의 머리 높이, 중심 질량(CoM)의 선형 속도, 제어 신호의 크기 등을 고려했습니다.

- **Performance Highlights**: 도입된 새로운 보상 함수와 안정화 항목을 통해 HumanoidBench 점수를 높이면서도 현실적인 자세와 부드러운 제어 신호를 유지할 수 있었습니다. 'Walk', 'Stand' 및 'Push' 태스크에서 측정된 평활성 트래젝토리와 제어 신호 크기 면에서 기존 방법보다 높은 성능을 보였습니다. 특히, 각 플래너의 평균 실행 시간을 비교한 결과, 제안된 방법이 더 일관되고 높은 성과를 거두었음을 확인했습니다.



### OTAD: An Optimal Transport-Induced Robust Model for Agnostic Adversarial Attack (https://arxiv.org/abs/2408.00329)
Comments:
          14 pages, 2 figures

- **What's New**: 딥 뉴럴 네트워크(DNN)이 입력에 대한 작은 적대적 왜곡(adversarial perturbations)에도 취약하다는 점은 안정성과 신뢰성 문제를 야기합니다. 이에 대한 해결책으로 새로운 2단계 Optimal Transport 기반 적대적 방어(Optimal Transport induced Adversarial Defense, OTAD) 모델이 제안되었습니다. 이 모델은 최적의 운송지도(optimal transport map)를 통해 데이터와 특징을 연결하고, 지역적 리프칙 연속성(lipschitz continuity)을 보장합니다. OTAD는 ResNet 및 Transformer와 같은 다양한 네트워크 아키텍처에 적용할 수 있어 복잡한 데이터에도 적합합니다.

- **Technical Details**: 첫 번째 단계에서는 최적의 운송 이론(optimal transport theory)을 기반으로 한 정규화를 통해 DNN을 훈련시켜, 데이터에서 그 특징으로 향하는 이산적 운송지도를 얻습니다. 다음으로 이 운송지도의 고유한 규칙성을 활용하여 CIP(Convex Integration Problem)를 해결함으로써 지역적 리프칙 연속성을 보장합니다. 이 과정에서 Transformer를 기반으로 한 'CIP-net'을 훈련시켜 효율적인 계산을 구현합니다. 또한 OTAD를 Transformer 아키텍처(예: ViT)로 확장하고, L2 거리로 인한 문제를 해결하기 위해 메트릭 학습(metric learning)을 도입합니다.

- **Performance Highlights**: 다양한 실험 결과는 OTAD 모델이 기존의 적대적 훈련 방법 및 리프칙 네트워크보다 다양한 데이터셋에서 우수한 성능을 보인다는 것을 입증합니다. 이는 새로운 최적의 운송지도와 CIP 기반의 접근 방식이 DNN의 방어 능력을 향상시킴을 나타냅니다.



### ADBM: Adversarial diffusion bridge model for reliable adversarial purification (https://arxiv.org/abs/2408.00315)
Comments:
          20 pages

- **What's New**: Diffusion-based purification(DiffPure)는 효과적인 적대적 예시 방어 방법으로 인식되어 왔지만, 기존 미리 훈련된 diffusion model을 직접 사용하는 것은 최적이 아님을 발견했습니다. 이를 해결하기 위해 우리는 고유의 Adversarial Diffusion Bridge Model(ADBM)을 제안했습니다.

- **Technical Details**: DiffPure는 원래 생성 작업에 맞춰 훈련된 diffusion models을 사용하므로 적대적 정화 작업에서는 비효율적입니다. ADBM은 역방향 다리를 구축하여 변형된 적대적 데이터를 원래 깨끗한 예시로 복구하는 과정을 향상시켰습니다. ADBM은 복구 품질과 노이즈 제거 성능 사이의 간극을 극복합니다. 또한, 우리가 개발한 신뢰 가능한 적응형 공격 평가 방법을 통해 ADBM의 우수성을 검증했습니다.

- **Performance Highlights**: ADBM은 여러 시나리오에서 DiffPure보다 더 높은 적대적 견고함을 입증했습니다. 특히 CIFAR-10 데이터셋에서 DiffPure 대비 4.4%의 향상된 견고성을 보였으며, 깨끗한 데이터에서는 유사한 정확도를 유지했습니다. 또한, ADBM은 적응형 공격뿐 아니라 전이 기반 및 쿼리 기반 공격에서도 우수한 성능을 나타냈습니다.



### Discretizing Continuous Action Space with Unimodal Probability Distributions for On-Policy Reinforcement Learning (https://arxiv.org/abs/2408.00309)
Comments:
          IEEE Transactions on Neural Networks and Learning Systems

- **What's New**: 새로운 연구는 연속적 제어(Task)에 대한 정책 반복 강화 학습(on-policy reinforcement learning)을 위해 이산적 행동 공간(discretizing action space)을 사용하는 효율적인 방법을 제안합니다. 구체적으로, 이 방법은 포아송 분포(Poisson probability distribution)를 사용하여 이산적인 정책이 단일 모드(unimodal)를 가지도록 제약합니다. 이를 통해 높은 복잡도를 가진 제어 과제(Humanoid 등)에서 더욱 빠른 수렴과 높은 성능을 보여줍니다.

- **Technical Details**: 본 논문에서는 이산적 정책(discrete policy)이 연속적 행동 공간(continuous action space)에서의 내재적인 순서(ordering)를 효과적으로 활용할 수 있도록 명시적인 단일 모드 확률 분포를 사용합니다. 이를 위해 각 행동 차원(action dimension)에 대해 포아송 분포를 사용하여 손실 함수(loss function)를 통해 행동 공간에 순서 제약을 부여합니다. 이러한 접근법은 이산적 행동 집합에서의 파라미터 폭발을 피하면서 일반화를 개선하는 데 중점을 둡니다.

- **Performance Highlights**: 제안된 방법은 MuJoCo 연속 제어 과제에서 기존의 방법에 비해 큰 성능 향상을 보였습니다. 실험 결과, 단일 모드 확률 분포를 가지는 이산적 정책은 더 낮은 분산과 안정적인 학습 과정을 제공하며, 특히 복잡한 과제에서 뛰어난 학습 성능을 보여주었습니다. 이는 높은 차원에서 더 빠른 수렴 및 성능 개선을 의미합니다.



### ABC Align: Large Language Model Alignment for Safety & Accuracy (https://arxiv.org/abs/2408.00307)
Comments:
          23 pages, 4 figures

- **What's New**: 이번 논문에서는 대규모 언어 모델(LLMs)의 새로운 정렬 방법론인 'ABC Align'을 제안합니다. 이 방법론은 대규모 미디어 조직의 표준과 선호도를 LLM 자체에 통합할 수 있게 합니다. 이를 통해 편향을 줄이고 정확도를 향상시키는 동시에 추론 능력을 유지할 수 있습니다.

- **Technical Details**: ABC Align은 공개 소스 모델의 미세 조정(fine-tuning)과 비공개 소스의 '최첨단'(frontier) 모델에서의 In-Context Learning (ICL)을 포함합니다. 여기에는 뉴스 기사 내용, 조직의 'AI 원칙'(Australian Broadcasting Corporation, 2024a), 그리고 내부 검색 증강 생성(RAG) 도구에서 수집된 질문/답변 쌍이 사용됩니다. 미세 조정에서는 합성 데이터 생성, 지식 증류(knowledge distillation), 선호도 최적화 등의 기법을 사용하여 데이터셋을 생성합니다.

- **Performance Highlights**: Meta의 Llama3-8B 모델을 대상으로 한 TruthfulQA 벤치마크에서 23.51%의 상대 성능 향상을 달성했습니다. 또한 OpenAI의 GPT4-turbo 모델에서 내부 RAG 도구와 AI 원칙을 사용하는 시스템 프롬프트가 Bias Benchmark for Question Answering (BBQ) 벤치마크에서 77.54%의 성능 향상을 보였습니다.



### Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck (https://arxiv.org/abs/2408.00295)
Comments:
          13 pages, 7 figures

- **What's New**: 최근 논문에서는 기존 Graph Neural Networks(GNNs)의 문제점을 해결하기 위한 새로운 기법을 제안했습니다. 이 기법은 Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck (CGRL)로 불리며, 노드 분류 작업에서 효과적으로 작동합니다.

- **Technical Details**: CGRL은 노드와 엣지를 자동으로 마스킹하여 최적의 그래프 구조를 학습합니다. 또한, 정보 병목 이론(Information Bottleneck Theory)을 적용해 불필요한 정보를 제거하면서 노드 분류에 필요한 정보를 최대한 보존합니다. 이 과정에서 원본 보기의 노이즈를 추가해 만든 논쟁적 뷰(adversarial views)를 통해 모델의 강인성을 높입니다.

- **Performance Highlights**: 실험 결과, CGRL 방식은 여러 공개된 실제 데이터셋에서 기존 최첨단 알고리즘들을 능가하는 성능을 보였습니다. 특히, 이 방식은 GNN의 인기 편향 문제와 노이즈 간섭 문제를 효과적으로 완화했습니다.



### Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network (https://arxiv.org/abs/2408.00290)
- **What's New**: 이 논문에서는 그래프 네트워크를 기반으로 한 다중모달 파라미터 효율화 파인튜닝(multi-modal parameter-efficient fine-tuning) 기법을 제안했습니다. 이 방법은 이미지와 텍스트 설명을 결합해 멀티모달 피처를 생성하고, 그 피처들을 바탕으로 그래프를 구성합니다. EWC(Elastic Weight Consolidation) 정규화 기법을 손실 함수에 통합하여, 작업 학습 도중 발생할 수 있는 기억 손실 문제를 완화합니다. 이를 통해 OxfordPets, Flowers102, Food101 데이터셋에서 각각 4.45%, 2.92%, 0.23%의 정확도 향상을 달성했습니다.

- **Technical Details**: 제안된 모델은 네 가지 주요 모듈로 구성됩니다. 첫째, 멀티모달 피처 추출(Multi-Modal Feature Extraction) 모듈에서는 MLLM(Multi-Modal Large Language Model)을 통해 각 이미지에서 텍스트 설명을 생성하고, 이미지는 고정된 이미지 인코더와 텍스트 인코더를 통해 이미지 피처와 텍스트 피처를 생성합니다. 둘째, Multi-Modal Graph Construction 모듈에서는 멀티모달 피처 노드의 유사성을 바탕으로 그래프를 구성합니다. 셋째, GA-Net(Graph Adapter Net) 모듈에서는 그래프 노드에서 적절한 지식과 관계를 추출하여 피처를 학습합니다. 넷째, Prediction 모듈에서는 크로스 엔트로피(cross-entropy)와 EWC 정규화가 통합된 손실 함수를 사용하여 기억 손실 문제를 완화합니다.

- **Performance Highlights**: 제안된 방법은 OxfordPets 데이터셋에서 4.45%, Flowers102 데이터셋에서 2.92%, Food101 데이터셋에서 0.23%의 테스트 정확도 향상을 보였습니다. 이는 현재까지의 SOTA(state-of-the-art) 모델 대비 모두 더 높은 성능을 기록한 것입니다.



### Gradient Harmonization in Unsupervised Domain Adaptation (https://arxiv.org/abs/2408.00288)
Comments:
          IEEE TPAMI 2024

- **What's New**: 이 논문에서는 비지도 도메인 적응(Unsupervised Domain Adaptation, UDA)에서 도메인 정렬과 분류 작업 사이의 최적화 갈등을 해결하기 위해 Gradient Harmonization(GH)과 GH++라는 두 가지 새로운 접근법을 제안합니다. 이는 현재의 UDA 방법론이 이 두 작업을 동시에 최적화할 때 발생하는 갈등을 제대로 해결하지 못한다는 문제를 인식하고 이를 해결하려는 시도입니다.

- **Technical Details**: GH는 분류 작업과 도메인 정렬 작업 사이의 기울기 각도를 둔각에서 예각으로 변경하여 갈등을 해소하고, GH++는 이 각도를 수직 각도로 조정하여 두 작업의 최적화 방향에서 벗어나지 않도록 합니다. 이러한 방법들은 모델 최적화 과정에서 기하학적 인식을 활용하여 두 작업이 조화롭게 진행될 수 있도록 합니다. 또한, GH/GH++을 동적으로 가중된 손실 함수 형태로 변환하여 최적화 편의성과 효율성을 높였습니다.

- **Performance Highlights**: 실험 결과에 따르면, 제안된 방법론은 다양한 벤치마크 및 주류 UDA 모델에서 기존 UDA 기반을 향상시킬 뿐만 아니라 최근의 최신 모델들의 성능도 개선시킵니다. GH/GH++ 접근법은 대부분의 기존 UDA 방법론과 직접 통합될 수 있는 범용적인 성격을 가지고 있습니다.



### High Performance Im2win and Direct Convolutions using Three Tensor Layouts on SIMD Architectures (https://arxiv.org/abs/2408.00278)
- **What's New**: 이 논문은 딥 신경망(deep neural networks) 내에서 중요한 컴퍼넌트인 합성곱(convolution)의 성능을 최적화하기 위한 세 가지 새로운 데이터 레이아웃인 NHWC, CHWN, CHWN8을 제안하고, 이를 im2win 합성곱에 적용했습니다. 또한, 이러한 레이아웃에서 직접 합성곱(direct convolution)과 im2win 합성곱을 위한 일반적인 최적화 기법을 도입하였습니다.

- **Technical Details**: 세 가지 주요 합성곱 방법인 직접 합성곱, im2col 기반 합성곱, im2win 합성곱이 있으며, 각 방법은 입력 텐서(입력 데이터 배열)를 다르게 변형합니다. im2win 합성곱은 입력 텐서를 dot product 윈도우로 재구성하여 메모리 접근성과 데이터 재사용을 최적화합니다. 새로운 레이아웃 중 NHWC는 메모리 접근성과 계산 효율성에서 기존의 NCHW 레이아웃에 비해 뛰어난 성능을 보여줍니다.

- **Performance Highlights**: 실험 결과, 새로운 NHWC 레이아웃을 적용한 im2win 합성곱은 NCHW 레이아웃에 비해 최대 355% 성능 향상을 보여주었으며, 최적화된 im2win과 직접 합성곱은 각각 기계의 이론적 최고 성능의 95% 및 94%까지 달성하였습니다. 이는 심도 있는 성능 특성화를 통해 합성곱 연산의 효율성을 극대화할 수 있음을 보여줍니다.



### QUITO: Accelerating Long-Context Reasoning through Query-Guided Context Compression (https://arxiv.org/abs/2408.00274)
- **What's New**: 최근 대형 언어 모델(LLM)의 핵심인 맥락 내 학습(ICL) 기능을 개선하고자 새로운 Query-gUIded aTtention cOmpression(QUITO) 방법이 제안되었습니다. 이 방법은 질문에 대한 주의(attention) 메커니즘을 활용하여 불필요한 정보를 걸러내는 역할을 합니다.

- **Technical Details**: QUITO는 트리거 토큰을 사용하여 질문에 대한 맥락의 주의 분포를 계산하고, 여러 필터링 방법을 통해 맥락 길이에 대한 예산 제약을 만족시킵니다. 특히, 자체 주의(self-attention) 메커니즘을 활용하여 토큰의 중요성을 점수화하여 해당 쿼리에 맞는 관련된 맥락을 선택합니다.

- **Performance Highlights**: QUITO는 NaturalQuestions와 ASQA와 같은 두 가지 주요 데이터셋에서 실험을 통해 기존의 기준을 크게 능가함을 보여주었습니다. 예를 들어, 다양한 데이터셋과 다운스트림 LLM에서 최대 20%의 정확도 증가를 이뤘습니다.



### Clover-2: Accurate Inference for Regressive Lightweight Speculative Decoding (https://arxiv.org/abs/2408.00264)
- **What's New**: 논문은 Clover-2를 소개하며, 이는 기존 Clover 프레임워크의 고도화 버전입니다. Clover-2는 모델 구조 개선과 지식 증류(knowledge distillation) 기법을 도입하여 텍스트 생성 작업에서 효율성을 크게 향상시켰습니다. Vicuna 7B와 LLaMA3-Instruct 8B 모델을 사용한 실험에서 Clover-2의 우수한 성능이 입증되었습니다.

- **Technical Details**: Clover-2는 다음과 같은 주요 기능 모듈을 통합하고 있습니다: 리그레시브 커넥션(Regressive Connection), 어텐션 디코더(Attention Decoder), 그리고 어그멘팅 블록(Augmenting Block). 주요 개선 사항으로는 독립된 어텐션 디코더를 사용하여 숨겨진 상태(hidden states)와 출력 토큰 정보를 통합하고 출력 프로젝터를 통해 ResBlock을 대체하며, 더 정교한 어그멘팅 블록을 사용해 모델 성능을 향상시키는 것 등이 포함됩니다. 또한, 지식 증류 전략을 채택하여 LLM의 숨겨진 상태와 분류 출력을 학습합니다.

- **Performance Highlights**: 실험 결과, Clover-2는 표준 디코딩보다 최대 3.00배 높은 처리량을 보였고, 기존 Clover보다 1.18배에서 1.65배 높은 성능을 보였습니다. 또한, RNN 기반 아키텍처임에도 불구하고 EAGLE과 비교하여 최대 9.3% 더 빠른 속도를 자랑했습니다.



### A Prior Embedding-Driven Architecture for Long Distance Blind Iris Recognition (https://arxiv.org/abs/2408.00210)
- **What's New**: 이 논문은 장거리에서 찍힌 불명확한(blind) 홍채 이미지 복원을 위한 새로운 아키텍처를 제안합니다. 제안된 솔루션은 Iris-PPRGAN이라는 홍채 이미지 복원 네트워크와 Insight-Iris라는 강력한 홍채 분류기로 구성됩니다.

- **Technical Details**: Iris-PPRGAN은 Generative Adversarial Network (GAN)과 Deep Neural Network (DNN)로 구성된 두 가지 주요 컴포넌트를 포함합니다. GAN은 Prior Decoder로 사용되고, DNN은 인코더로 사용됩니다. Insight-Iris는 기존의 InsightFace의 병목 모듈(bottleneck module)을 수정하여 제작되었습니다. 낮은 품질의 불명확한 홍채 이미지는 먼저 Iris-PPRGAN을 통해 복원되며, 이후 복원된 홍채 이미지는 Insight-Iris를 통해 인식됩니다.

- **Performance Highlights**: 제안된 방법은 공개 CASIA-Iris-distance 데이터셋에서 정량적 및 정성적으로 모두 기존 방법들보다 우수한 결과를 보여주었습니다. 특히, 복원된 장거리 불명확한 홍채 이미지의 인식률이 90%에 도달했으며, 이는 복원 전 홍채 이미지에 비해 약 10 퍼센트 포인트 향상된 성능을 나타냅니다.



### OmniParser for Pure Vision Based GUI Agen (https://arxiv.org/abs/2408.00203)
- **What's New**: 새로운 연구인 	extsc{OmniParser}는 사용자의 인터페이스(UI) 스크린샷을 구조화된 요소들로 파싱(parsing)하는 기술을 소개합니다. 이로 인해 GPT-4V와 같은 멀티모달 모델이 더 정확하게 동작할 수 있도록 돕습니다.

- **Technical Details**: 	extsc{OmniParser}는 상호작용 가능한 아이콘을 감지하는 Detection 모델과 아이콘의 기능적 의미를 추출하는 Caption 모델로 구성되어 있습니다. 이를 위해 인기 있는 웹페이지들을 바탕으로 상호작용 가능한 아이콘 감지 데이터셋과 설명 데이터셋을 구성했습니다. 이 데이터셋을 통해 모델들을 미세 조정(fine-tune)하여 사용자의 인터페이스를 더 잘 이해할 수 있도록 했습니다.

- **Performance Highlights**: 	extsc{OmniParser}는 ScreenSpot 벤치마크에서 GPT-4V의 성능을 크게 향상시켰습니다. Mind2Web 및 AITW 벤치마크에서도 스크린샷만을 이용한 입력으로, 추가 정보를 요구하는 GPT-4V 기반모델을 뛰어넘는 성능을 발휘했습니다.



### Automated Software Vulnerability Static Code Analysis Using Generative Pre-Trained Transformer Models (https://arxiv.org/abs/2408.00197)
- **What's New**: GPT 모델이 C 및 C++ 소스 코드에서 취약한 코드 구문을 자동으로 식별하는 능력을 평가했습니다. NIST SARD 데이터셋의 36개의 소스 코드 예제를 통해 테스트했으며, 이 데이터셋은 특정 취약점을 나타내는 자연어가 포함되지 않도록 신중하게 큐레이션되었습니다.

- **Technical Details**: 5개의 오픈 소스 GPT 모델을 10가지 추론 온도와 100회 반복을 통해 총 5,000개의 GPT 쿼리를 분석했습니다. 평가에는 Llama-2-70b-chat-hf와 같은 모델들이 포함되었으며, 이 모델들은 파이썬3 모듈인 pytorch와 transformers를 사용하여 로컬 GPU 서버에서 실행되었습니다. 모든 GPT 모델 계산은 로컬 Nvidia A100 GPU 서버에서 수행되었습니다.

- **Performance Highlights**: 높은 거짓 긍정 및 거짓 부정 비율로 인해 완전한 자동 취약점 스캐닝에는 적합하지 않지만, 일부 테스트 케이스에서는 예상보다 좋은 성능을 보였습니다. 특히 NIST SARD 테스트 케이스 149165에서 Llama-2-70b-chat-hf 모델은 버퍼 오버플로우 취약점을 정확히 식별하여 이진 분류 리콜 점수와 정밀도가 1.0을 기록했습니다.



### Resilience and Security of Deep Neural Networks Against Intentional and Unintentional Perturbations: Survey and Research Challenges (https://arxiv.org/abs/2408.00193)
- **What's New**: 이 논문은 딥러닝 네트워크(DNN)의 의도적 및 비의도적 외부 교란에 대한 회복력을 조사한 최초의 종합적인 연구입니다. 두 종류의 교란을 통합하는 비전은 지금까지 부족했으며, 이 연구는 두 분야 간의 아이디어 교환을 촉진하여 DNN 보안 및 회복력의 최전선을 발전시키는 것을 목표로 합니다.

- **Technical Details**: DNN은 객체 탐지, 언어 번역, 이미지 분류 등 다양한 중요한 작업을 수행할 수 있습니다. 그러나 DNN은 의도적 교란(소수의 픽셀 변경으로 오분류 초래)과 비의도적 교란(환경적 변화로 인한 오분류)에 민감합니다. 의도적 교란은 적대적 머신러닝(adversarial machine learning)으로도 알려져 있으며, 비의도적 교란은 Out-of-Distribution(OOD) 표본과 관련이 있습니다. 이 연구는 의도적 교란과 비의도적 교란을 탐지하고 방어하는 다양한 접근 방법과 그들 간의 공통점, 강점 및 약점을 조사합니다.

- **Performance Highlights**: 이 연구는 DNN의 회복력을 평가하기 위한 기준으로 Fast Gradient Sign Method (FGSM), Basic Iterative Method (BIM), 및 Projected Gradient Descent (PGD)을 제안합니다. 또한, Carlini-Wagner(CW) 손실 함수와 Multi-Target (MT) 접근법을 통해 여러 대상으로의 공격을 최적화하는 방법을 소개합니다. DNN의 교란 탐지 및 방어 전략에 대한 공통된 접근법을 발견함으로써 두 커뮤니티 간의 새로운 관점을 채택할 수 있을 것으로 기대됩니다.



### S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images (https://arxiv.org/abs/2408.00191)
Comments:
          Accepted to the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2024

- **What's New**: 최근 발표된 논문에서는 S-SYNTH라는 혁신적인 오픈 소스 피부 시뮬레이션 프레임워크를 소개합니다. 이 프레임워크는 다양한 피부 색조와 병변(lesion)의 모습을 가진 합성 피부와 3D 모델을 빠르게 생성하여 AI 모델의 개발 및 평가에 기여할 수 있습니다. 또한, 실제 피부 데이터를 기반으로 한 AI 모델의 한계와 편향성을 줄이기 위한 목적으로 설계되었습니다.

- **Technical Details**: S-SYNTH는 anatomically inspired multi-layer, multi-component skin and growing lesion model을 사용하여 피부의 외관, 색상, 모발 존재, 병변 형태 및 혈액 비율 등의 변수를 조절할 수 있는 고도로 상세한 3D 피부 모델을 생성합니다. 이 모델은 3D 모델링, 애니메이션 및 시각 효과를 위해 Houdini 소프트웨어와 Python API를 사용하여 구현되었으며, Mitsuba 3 연구지향 렌더링 시스템을 통해 합성 이미지를 생성합니다.

- **Performance Highlights**: S-SYNTH로 생성된 합성 이미지는 제한된 실제 이미지 데이터셋을 사용할 때 피부 병변의 분할 성능을 향상시키는 데 도움이 됩니다. 특히, S-SYNTH 합성 이미지를 사용하여 훈련된 모델은 실제 피부 데이터를 바탕으로 한 모델과 유사한 성능 경향을 보이며, 레이블 오류와 제한된 데이터셋의 한계를 완화할 수 있습니다.



### CREW: Facilitating Human-AI Teaming Research (https://arxiv.org/abs/2408.00170)
Comments:
          Our project website is at: this http URL

- **What's New**: CREW 플랫폼을 통해 Human-AI 팀 연구를 촉진하고, 다양한 학문 간 협력을 강화하려는 노력이 있었습니다. 이 플랫폼은 인간의 개입을 강조하며, 기존 연구에서 다루지 못했던 다양한 과제를 확장 가능한 모듈형 설계로 지원합니다. 또한, CREW는 최첨단 알고리즘 및 최적화된 기준선(Baselines)을 활용한 실시간 사람 가이드 학습 에이전트 벤치마크를 포함하고 있습니다. 이 플랫폼을 통해 50명의 인간 대상 실험을 일주일 내에 수행할 수 있었습니다.

- **Technical Details**: CREW는 인지 연구와 Human-AI 팀 연구를 위한 사전 설계된 과제를 포함하고 있으며, 확장이 용이한 모듈형 설계(Modular Design)로 이루어져 있습니다. 또한, 다중 모달 인간 생리 신호 기록을 지원하여 행동 분석을 수행할 수 있습니다. 실시간 통신을 지원하며, 다양한 모드의 Human-AI 팀 협력에 적합한 플랫폼을 제공합니다. CREW는 병렬 세션을 통해 실험 효율성을 극대화하고, 인간과 에이전트 데이터를 종합적으로 수집할 수 있는 인터페이스를 갖추고 있습니다.

- **Performance Highlights**: CREW 플랫폼을 활용하여 50명의 인간 대상 실험을 일주일 내에 완료하여 벤치마크의 효과성을 검증하였습니다. 또한, 다양한 RL (Reinforcement Learning) 알고리즘과 기준선을 포함한 벤치마크를 통해 실시간 인간 가이드 학습 에이전트를 평가하였습니다.



### Review of Explainable Graph-Based Recommender Systems (https://arxiv.org/abs/2408.00166)
- **What's New**: 이 논문은 최신 기법에 기반한 설명 가능한 추천 시스템(explainable recommender systems)의 동향을 요약하며, 특별히 그래프 기반 추천 시스템에 중점을 두고 있습니다. 기존의 리뷰 논문과 달리, 이 논문은 그래프를 활용한 추천 시스템의 설명 가능성에 대해 집중적으로 다루고 있습니다.

- **Technical Details**: 논문은 설명 가능한 추천 시스템을 세 가지 측면에서 분류합니다: 학습 방법(learning methods), 설명 방법(explaining methods), 및 설명 유형(explanation types). 또한 주로 사용되는 데이터셋과 설명 가능성 평가 방법(explainability evaluation methods)을 탐구하며, 향후 연구 방향(future directions)을 제시합니다.

- **Performance Highlights**: 논문은 그래프 기반의 설명 가능한 추천 시스템과 관련된 최신 연구 결과를 비교하고 분석함으로써, 새로운 애플리케이션 개발을 위한 기초 자료를 제공합니다.



### Non-convolutional Graph Neural Networks (https://arxiv.org/abs/2408.00165)
- **What's New**: 이번 연구는 기존의 컨볼루션 기반 그래프 신경망(GNN)의 한계를 극복하기 위해 완전히 새로운 모듈을 제안합니다. 이 모듈은 컨볼루션 연산자를 전혀 사용하지 않으며, 이를 '통합 메모리를 가진 랜덤 워크' (RUM) 신경망이라고 부릅니다. 주목할 점은 RUM이 기존 GNN에서 자주 직면하는 표현력 부족, over-smoothing(과잉 평활화), over-squashing(과잉 압축) 문제를 해결한다는 점입니다.

- **Technical Details**: RUM 신경망은 각 노드에서 종료되는 랜덤 워크를 통해 네트워크의 구조적 및 의미적 특징을 통합합니다. 이를 위해 RNN(재귀 신경망)이 사용되며, 랜덤 워크를 거치는 동안 수집된 정보를 통합해 노드 임베딩을 형성합니다. 이는 기존의 컨볼루션 연산자 없이도 네트워크의 표현력을 높일 수 있도록 해줍니다. 이 연구에서는 이러한 접근법이 Weisfeiler-Lehman(WL) 동형성 테스트보다 더 표현력이 뛰어남을 이론적으로 입증하고 실험적으로 확인했습니다.

- **Performance Highlights**: 다양한 노드 및 그래프 수준의 분류와 회귀 작업에서 RUM은 기존의 복잡한 컨볼루션 기반 GNNs보다 경쟁력 있는 성능을 보였습니다. 더 나아가, RUM은 메모리 효율적이고 확장성이 뛰어나며, 단순한 컨볼루션 GNN보다 성능이 빠르다는 점에서도 주목할만합니다.



### A Taxonomy of Stereotype Content in Large Language Models (https://arxiv.org/abs/2408.00162)
- **What's New**: 이번 연구에서는 현대의 대형 언어 모델(Large Language Models, LLM)에서 나타나는 고정관념에 대한 분류체계를 소개합니다. ChatGPT 3.5, Llama 3, 그리고 Mixtral 8x7B와 같은 강력하고 널리 사용되는 LLM들을 대상으로 87개의 사회적 범주(성별, 인종, 직업 등)와 연관된 특징을 분석했습니다. 이 연구는 LLM들이 고정관념을 어떻게 반영하는지를 밝히고, 이러한 내용을 AI 감사 및 편향 제거(debiasing)에 중요한 참고 자료로 사용해야 한다고 주장합니다.

- **Technical Details**: 우리는 도덕성(Morality), 능력(Ability), 건강(Health), 신념(Beliefs), 감정(Emotions) 등을 포함한 14개의 고정관념 차원(stereotype dimensions)을 식별하였습니다. 이 차원들은 LLM 고정관념 연관성의 약 90%를 차지합니다. 그 중에서도 '따뜻함(Warmth)'과 '능력(Competence)'이 가장 자주 나타났지만, 다른 차원들도 상당히 빈번하게 발견되었습니다. 또한, LLM에서 나타나는 고정관념은 인간보다 긍정적이었지만, 범주와 차원에 따라 상당한 변동성이 있었습니다.

- **Performance Highlights**: 우리의 연구 결과에 따르면, LLM의 내부 평가(positive/negative)에 대해 이 분류체계가 예측 능력을 지니고 있음이 확인되었습니다. 이로써, 다차원적(n-dimensional) 분류체계가 LLM 고정관념을 평가하는 데 유의미함을 증명하였습니다. 고차원적인 인간의 고정관념이 LLM에서도 반영되고 있으며, 이는 저차원적인 편향 뷰(low-dimensional views of bias)에만 의존해 발생할 수 있는 한계를 최소화하는 AI 감사 및 편향 제거 전략에 반영되어야 함을 시사하고 있습니다.



### Automatic Generation of Behavioral Test Cases For Natural Language Processing Using Clustering and Prompting (https://arxiv.org/abs/2408.00161)
- **What's New**: 이 논문은 자연어 처리(NLP) 모델의 행동 테스트를 위한 자동화된 접근 방식을 소개합니다. 현존하는 방법들은 도메인 전문 지식과 많은 시간이 필요로 하는 반면, 이 논문에서는 대형 언어 모델과 통계 기법을 사용하여 테스트 케이스를 자동으로 개발하는 방식을 제안합니다.

- **Technical Details**: 이 접근 방식은 텍스트 표현(text representations)을 클러스터링(cluster)을 통해 의미 있는 그룹으로 신중하게 구성한 후, 프로밍 기법을 사용하여 Minimal Functionality Tests(MFT)를 자동으로 생성합니다. 여기에 사용된 데이터셋은 잘 알려진 Amazon Reviews 코퍼스입니다.

- **Performance Highlights**: 제안된 방법을 통해 생성된 테스트 케이스들을 네 가지 다른 분류 알고리즘(classification algorithms)에 적용하여 행동 테스트 프로필을 분석했습니다. 또한, 이 모델들의 한계와 강점을 논의했습니다.



### Moderating Group Conversation Dynamics with Social Robots (https://arxiv.org/abs/2408.00151)
Comments:
          6 pages, 6 figures, 1 table. Accepted at the workshop on advancing Group Understanding and robots' adaptive behavior (GROUND), held at the Robotics Science and Systems (RSS) Conference, 2024

- **What's New**: 이 연구는 그룹 대화에서 소셜 로봇의 참여 효과와 다양한 어드레스 정책(addressing policies)의 효과를 조사합니다. 300명의 참가자가 4명씩 그룹으로 나뉘어 휴머노이드 로봇과 상호작용하였고, 로봇은 대화 데이터를 활용해 적절한 발화자를 결정했습니다. 연구 결과, 로봇의 어드레스 정책이 대화 동태에 상당한 영향을 미쳐 각 참가자에게 더 균형 잡힌 주의를 기울이고 소그룹 형성을 줄이는 데 기여했습니다.

- **Technical Details**: 로봇의 자율 대화 기능은 CAIR(Cloud Artificial Intelligence and Robotics)라는 클라우드 소프트웨어 아키텍처로 구현되었습니다. CAIR는 OWL2로 구현된 온톨로지를 사용하여 지식 표현을 관리하며, 대화 주제와 관련된 문장 조각을 실행 시 동적으로 구성합니다. 개별 대화 참여자를 식별하기 위해 등록 서비스와 오디오 녹음 서비스가 사용되었으며, 대화 상태(dialouge state)를 통해 멀티파티 상호작용을 지원합니다.

- **Performance Highlights**: 75개의 실험에서 300명의 참가자들이 로봇과 그룹 대화에 참여하였고, 로봇은 수집된 자료를 통해 참여 수준을 분석하고 소그룹을 식별하며 전반적인 대화 동태를 평가했습니다. 이를 통해 균형있는 참여를 촉진하는 효과를 입증했습니다.



### StyleRF-VolVis: Style Transfer of Neural Radiance Fields for Expressive Volume Visualization (https://arxiv.org/abs/2408.00150)
Comments:
          Accepted by IEEE VIS 2024

- **What's New**: 이 논문에서는 StyleRF-VolVis라는 혁신적인 스타일 전이(Style Transfer) 프레임워크를 소개합니다. 이 시스템은 신경 방사장(Neural Radiance Field, NeRF)을 통해 표현력 있는 볼륨 시각화(VolVis)를 구현합니다. 기존 방식과 달리 많은 훈련 이미지나 긴 훈련 시간이 필요하지 않으며, 높은 품질과 일관성, 유연성을 제공합니다.

- **Technical Details**: StyleRF-VolVis의 핵심은 장면 기하(geometry)와 색상 표현(style)을 정확히 분리하는 능력에 있습니다. 이를 통해 색상, 불투명도, 조명 등을 쉽게 수정할 수 있으며, 3D 장면 재구성에서 참조 이미지의 스타일을 효과적으로 전이할 수 있습니다. 이를 위해 StyleRF-VolVis는 기본 NeRF 모델, 팔레트 색상 네트워크(Palette Color Network), 그리고 무제한 색상 네트워크(Unrestricted Color Network)로 구성됩니다.

- **Performance Highlights**: StyleRF-VolVis는 다양한 볼륨 렌더링 장면과 참조 이미지를 사용한 실험에서 뛰어난 품질, 일관성 및 유연성을 보여주었으며, 다른 이미지 기반(AdaIN), 비디오 기반(ReReVST), 및 NeRF 기반(ARF, SNeRF) 스타일 렌더링 솔루션과 비교하여 우수한 성능을 입증했습니다.



### Distributed In-Context Learning under Non-IID Among Clients (https://arxiv.org/abs/2408.00144)
Comments:
          12 pages

- **What's New**: 이 논문은 대형 언어 모델(LLMs)을 새로운 또는 익숙하지 않은 작업에 효율적으로 적응시키는 도전과제를 신기원적으로 해결합니다. 특히, 다수의 클라이언트에 분산된 비독립 동일분포(non-IID) 데이터를 가지고 있는 환경에서의 인컨텍스트 학습(ICL)의 장애물을 극복하는 새로운 접근법을 제안합니다. 이를 위해 각 테스트 쿼리에 대한 클라이언트의 기여도를 데이터 기반 방식으로 할당하는 프레임워크를 도입합니다.

- **Technical Details**: 논문에서는 데이터 사용 예산이 존재하는 분산된 non-IID ICL 문제를 다룹니다. 프레임워크는 다음과 같은 단계로 이루어집니다: 1) 서버는 자체 프록시 데이터셋을 사용하여 최적의 예산 통계를 수집합니다. 2) 서버는 이 데이터셋으로 예산 할당기를 학습합니다. 3) 배포 단계에서 서버는 예산 할당기를 사용해 각 테스트 쿼리에 대해 클라이언트당 적절한 예산을 예측하고 ICL을 수행합니다. 또한, 프라이버시 문제가 있는 실제 시나리오에서는 의역(paraphrasing) 방법을 사용하여 프라이버시를 보호합니다.

- **Performance Highlights**: 다양한 데이터셋 벤치마크와 여러 LLM 아키텍처에서, 제안된 프레임워크는 경쟁하는 기준선보다 ICL 성능을 향상시켰습니다. 비공개 및 프라이버시 보호 설정 모두에서 우수한 성능을 보여주었으며, 특히 각 테스트 쿼리에 대한 최적화된 예산 할당을 통해 더 관련성 깊은 문맥을 형성합니다.



### Correcting Negative Bias in Large Language Models through Negative Attention Score Alignmen (https://arxiv.org/abs/2408.00137)
- **What's New**: 이번 연구에서는 언어 모델이 복잡한 추론 작업의 이진 결정에서 부정적 편향(negative bias)을 보이는 현상을 관찰하였습니다. 이를 기반으로 NAS(Negative Attention Score)를 제안하여 이러한 부정적 편향을 체계적으로 정량화하고, 부정 편향 관련 주의 헤드(attention heads)를 식별하였습니다. 또한, NASA(Negative Attention Score Alignment)라는 파라미터 효율적인 미세 조정 기법을 도입해 문제를 해결하고자 합니다.

- **Technical Details**: LLMs(대형 언어 모델)가 'Yes-No' 질문이나 답변 확인 등의 이진 결정 작업에서 부정적 편향을 보일 때 주의 메커니즘 내에서 NAS를 통해 이러한 현상을 정량적으로 측정하고 평가합니다. NAS를 기반으로 부정적으로 작용하는 주의 헤드를 식별하여 모델의 일부 부정적 편향을 유발하는 요소를 밝혀냈습니다. 이를 해결하기 위해 NASA라는 미세 조정 기법을 적용하였으며, 이는 가장 편향된 주의 헤드부터 점진적으로 조정하는 기법입니다.

- **Performance Highlights**: 다양한 추론 작업과 대형 모델 탐색에서 NASA를 사용하여 부정 편향으로 인한 정밀도(precision)와 재현율(recall) 간의 격차를 크게 줄이면서도 모델의 일반화 능력은 그대로 유지되었습니다. NASA 기법은 모델이 이진 결정 작업에서 더 나은 캘리브레이션(calibration) 성능을 보이게 하였습니다.



### Distributionally Robust Optimization as a Scalable Framework to Characterize Extreme Value Distributions (https://arxiv.org/abs/2408.00131)
- **What's New**: 이 연구는 다차원 극단값 이론(Extreme Value Theory, EVT) 통계를 위한 분포 강건 최적화(DRO) 추정기를 개발하는 데 초점을 맞추고 있습니다. 특히, 공간 포아송 점 과정을 이용한 세미 파라메트릭 모델인 최대 안정 분포(max-stable distributions)를 사용하여 극단값 데이터를 추정합니다.

- **Technical Details**: EVT는 심각하게 부족한 극단값 데이터를 다루기 때문에 모델 오차가 발생할 가능성이 큽니다. 이를 해결하기 위해 세미 파라메트릭 max-stable 제약을 사용하는 DRO 추정기를 연구하였습니다. 본 연구는 일부 흥미로운 문제에 대해 다루기 쉬운 convex 정식화(e.g. CVaR)와 일반적인 신경망 기반 추정기를 포함합니다. 최적 수송(Wasserstein metric for optimal transport)과 같은 방법론을 사용하여 모형 오차를 수량화합니다. 또한, 불확실성 세트를 신중하게 설계하여 max-stable 성질을 유지하도록 합니다.

- **Performance Highlights**: 제안된 방법은 합성 데이터와 실제 금융 데이터 세트에 대해 검증되었습니다. 다양한 합성 데이터 세트를 통해 신경망 아키텍처의 성능을 검증하였으며, 조건부 가치 위험(CVaR) 메트릭을 적용하여 예상된 결과를 도출했습니다. 제안된 방법론은 기존 분석과 비교하여 성능 면에서 혁신적이라고 평가됩니다.



### Semantic Codebook Learning for Dynamic Recommendation Models (https://arxiv.org/abs/2408.00123)
- **What's New**: Semantic Codebook Learning for Dynamic Recommendation Models (SOLID) 프레임워크가 기존 동적 순차 추천(Dynamic Sequential Recommendation, DSR) 방식의 한계를 효과적으로 극복하며, 사용자 행동을 기반으로 개인화된 추천을 개선하는 중요한 진전을 이루었습니다.

- **Technical Details**: SOLID는 아이템 시퀀스를 의미 시퀀스로 변환하고, 이중 매개변수 모델(dual parameter model)을 사용하여 매개변수 생성 탐색 공간을 압축하며, 추천 시스템 내의 동질성을 활용합니다. 의미 메타코드(semantic metacode)와 의미 코드북(semantic codebook)을 도입하여, 분리된 아이템 표현을 저장하고 견고하고 정확한 매개변수 생성을 보장합니다.

- **Performance Highlights**: 광범위한 실험 결과 SOLID가 기존 DSR 방법을 일관되게 능가하여 더 정확하고 안정적이며 견고한 추천을 제공합니다.



### Gemma 2: Improving Open Language Models at a Practical Siz (https://arxiv.org/abs/2408.00118)
- **What's New**: Gemma 2는 최신의 경량 오픈 모델로, 2억에서 270억 파라미터 규모의 다양한 모델을 포함합니다. 이번 버전에서는 Transformer 아키텍처에 대한 몇 가지 기술적 수정 사항을 적용했습니다. 대표적으로는 로컬-글로벌 어텐션(interleaving local-global attentions)과 그룹 쿼리 어텐션(group-query attention)을 사용하였습니다. 또한 2B 및 9B 모델은 next token prediction 대신 지식 증류(knowledge distillation)로 학습되었으며, 이는 모델 크기에 비해 최고의 성능을 제공합니다. 모든 모델은 커뮤니티에 공개되었습니다.

- **Technical Details**: Gemma 2는 디코더 전용 Transformer 아키텍처를 기반으로 하며, 기존 Gemma 모델과 유사한 몇 가지 요소를 공유합니다. 여기에는 8192 토큰의 컨텍스트 길이, Rotary Position Embeddings (RoPE) 및 근사화된 GeGLU 비선형성이 포함됩니다. 새롭게 추가된 것은 로컬 슬라이딩 윈도우 어텐션과 글로벌 어텐션의 교차 사용, logit soft-capping, RMSNorm을 사용한 안정화 기술입니다. 또한 그룹 쿼리 어텐션을 사용하여 추론 시간을 단축시키는 동시에 성능을 유지합니다.

- **Performance Highlights**: Gemma 2는 다양한 자동화 벤치마크와 인간 평가에서 동급 규모의 오픈 모델 대비 현저히 향상된 성능을 나타냅니다. 주요 성과로는 질문 응답, 상식 추론, 수학 및 과학, 코딩 등 여러 도메인에서 우수한 성능을 보였습니다. 특히, 지식 증류를 통해 크기가 2-3배 큰 모델과도 경쟁할 수 있는 성능을 제공합니다.



### Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models (https://arxiv.org/abs/2408.00113)
Comments:
          Oral paper (top 5%) at the ICML 2024 Mechanistic Interpretability Workshop

- **What's New**: 최근 연구에 따르면, Sparse Autoencoders (SAEs)를 사용하여 언어 모델(LM) 내부 표현에서 해석 가능한 특징들을 분리하는 것이 주목받고 있습니다. 그러나 이러한 SAEs의 품질을 평가하기가 어려운데, 그 이유는 우리가 기대하는 '해석 가능한 특징'의 기준이 없기 때문입니다. 이 연구에서는 체스와 오셀로 게임의 기록을 학습한 LMs를 사용하여 자연스러운 해석 가능한 특징들을 측정하고자 합니다. 우리는 새로운 SAE 훈련 기법인 `p-annealing`을 도입하여 이 과정의 성능을 향상시켰습니다.

- **Technical Details**: 이 연구는 체스와 오셀로 게임 기록을 예측하는 언어 모델을 토대로 SAEs를 훈련합니다. 우리는 두 개의 새로운 메트릭으로 SAE의 품질을 측정합니다: 'Board reconstruction'(보드 상태 재구성)과 'Coverage'(커버리지). 또한, 새로운 SAE 훈련 방법인 `p-annealing`을 도입하여 기존 메트릭에 비해 성능을 향상시켰습니다. p-annealing은 훈련 초기에는 convex 최적화 문제를 해결하고, 이후 non-convex 목표를 향해 L_p norm-based sparsity penalty를 적용합니다.

- **Performance Highlights**: p-annealing 방법을 사용한 SAEs는 기존의 방법보다 뛰어난 성능을 보였습니다. 기존의 메트릭과 새롭게 제안된 메트릭 모두에서 유의미한 성능 향상을 확인했습니다. 특히, 체스와 오셀로 모델을 기준으로 훈련된 500개 이상의 SAEs를 공개하여 다른 연구자들이 추가 실험과 검증을 할 수 있도록 했습니다.



### WAS: Dataset and Methods for Artistic Text Segmentation (https://arxiv.org/abs/2408.00106)
Comments:
          Accepted by ECCV 2024

- **What's New**: 이 논문에서는 예술 텍스트 분할(artistic text segmentation) 작업을 다루고 있으며, 이를 위해 새로운 실세계 예술 텍스트 분할 데이터셋인 WAS-R을 구성했습니다. 기존의 텍스트 분할 방법들은 규칙적인 텍스트에는 유의한 성과를 보였으나, 예술적인 텍스트에서는 성능이 저조했습니다.

- **Technical Details**: 예술 텍스트 분할의 주요 도전 과제는 (1) 예술 텍스트의 스트로크 형태가 다양하고 복잡하다는 것과 (2) 전반적인 위상 구조가 복잡하다는 점입니다. 이를 해결하기 위해, 우리는 계층별 관성을 가진 퀘리(layer-wise momentum query) 디코더와 골격 도움 헤드(skeleton-assisted head)를 제안했습니다. 또한, 대규모 멀티모달 모델과 확산 모델(diffusion model)을 활용한 데이터 합성 전략을 제안하여 실제적인 이미지와 라벨을 생성했습니다.

- **Performance Highlights**: 실험 결과, 제안된 방법과 합성 데이터셋이 예술 텍스트 분할 성능을 크게 향상시켰음을 확인했습니다. 특히, 다른 공개 데이터셋에서도 최첨단 성능(SOTA)을 달성하였으며, 제안된 모델은 미세 조정 없이도 경쟁력 있는 성능을 발휘했습니다.



### ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budg (https://arxiv.org/abs/2408.00103)
Comments:
          To be presented at ACL 2024

- **What's New**: ReLiK은 엔터티 연결(Entity Linking, EL)과 관계 추출(Relation Extraction, RE)에 새로운 접근법을 제시하는 논문입니다. 이 시스템은 제공된 입력 텍스트에서 잠재적인 엔터티나 관계를 식별하는 Retriever 모듈과, 식별된 엔터티나 관계를 정확한 텍스트 구간에 연결하는 Reader 모듈로 구성된 Retriever-Reader 아키텍처를 도입합니다. 이 방식은 한 번의 포워드 패스(forward pass)로 엔터티를 연결하거나 관계를 추출할 수 있으며, 사전학습된 언어 모델의 문맥화를 최대한 활용할 수 있습니다.

- **Technical Details**: ReLiK은 인풋과 후보 엔터티 또는 관계를 함께 입력으로 받아 처리합니다. Retriever 모듈은 Dense Passage Retrieval(DPR) 방식을 기반으로, 입력 텍스트의 인코딩과 외부 인덱스의 텍스트 패시지 인코딩을 통해 가장 관련성 높은 패시지를 검색합니다. Reader 모듈은 입력 텍스트와 검색된 패시지를 함께 인코딩하고, 단일 포워드 패스로 엔터티를 연결하거나 관계를 추출합니다. 특히, 우리의 혁신적인 입력 표현 방식은 새로운 엔터티/관계를 zero-shot으로 처리할 수 있는 유연성(Flexibility)을 제공합니다.

- **Performance Highlights**: ReLiK은 동일한 아키텍처를 사용하여 EL과 RE 모두에서 최신 성능(State-of-the-art)을 달성했으며, 타 경쟁 시스템들보다 40배 빠른 추론 속도(Inference Speed)를 보여줍니다. 또한, 우리의 방법론은 학술적 예산으로 훈련이 가능하여, 학술 연구 그룹들이 접근하기 용이합니다. 우리는 ReLiK 시스템이 EL과 RE를 동시에 처리하는 정보 추출(Information Extraction, cIE)에서도 새로운 표준을 설정하였으며, 코드를 GitHub에 공개하여 연구와 활용을 촉진하고 있습니다.



### From Attributes to Natural Language: A Survey and Foresight on Text-based Person Re-identification (https://arxiv.org/abs/2408.00096)
- **What's New**: 최근 텍스트 기반의 사람 재식별(Text-based Person Re-ID) 분야에서, 여러 기술적인 측면을 종합적으로 정리한 리뷰 논문이 등장했습니다. 이 논문은 텍스트 기반 사람 재식별의 새로운 분류 체계를 제안하며, 평가(Evaluation), 전략(Strategy), 아키텍처(Architecture), 최적화(Optimization) 측면에서 검토합니다.

- **Technical Details**: 텍스트 기반 사람 재식별에서 속성(attribute) 및 자연어(natural language)을 이용한 식별 개념을 기본적인 개념으로 다루고 있습니다. 주요 데이터셋과 평가 지표, 특징 추출 전략, 네트워크 아키텍처, 모델 최적화 및 모달리티 정렬을 위한 Loss 함수 등을 심층 분석합니다. 이 리뷰는 또한 이 분야의 현재 도전 과제를 확인하고, 이러한 과제를 해결하기 위한 향후 연구 방향성과 베이스라인 아키텍처(기준 구조)를 제시하고 있습니다.

- **Performance Highlights**: 기존 연구에서는 속성을 이용한 사람 재식별 방법들이 높은 인식 정밀도와 해석 가능성을 제공하지만, 텍스트 기반 접근 방식이 보다 유연하고 강력할 수 있다는 것을 밝혔습니다. 다양한 방법들이 모달리티 격차를 줄이기 위해 사용될 수 있으며, 자연어 처리가 이를 더 잘 지원할 수 있습니다. 예를 들어, 자유 형식의 자연어 기술은 예전의 속성 기반 접근 방식보다 더 많은 정보를 포괄적으로 담을 수 있는 장점을 가집니다.



### Execution Semantics of Behavior Trees in Robotic Applications (https://arxiv.org/abs/2408.00090)
Comments:
          13 pages, 9 figures

- **What's New**: 이 문서는 로봇(robots) 응용 프로그램에서 사용되는 행위 트리(Behavior Trees: BT)의 실행 의미(execution semantics)를 설명합니다. 특히, 중지 의미(Halt semantics)에 세부적으로 집중합니다.

- **Technical Details**: BT는 로봇의 제어 시스템에서 중요한 역할을 합니다. 이 문서에서는 BT의 실행 과정을 비형식적이지만 명확하게 설명합니다. 'Halt semantics'는 BT 노드가 어떻게 중지되는지, 그리고 중지 시 시스템이 어떻게 동작하는지를 다룹니다.

- **Performance Highlights**: 이 논문은 로봇 제어 시스템 내에서의 BT의 구체적인 작동 방식을 이해하고 향상시키는 데 기여할 수 있습니다. 중지 의미에 대한 명확한 이해는 시스템의 안정성과 예측성을 높이는 데 필수적입니다.



### Barlow Twins Deep Neural Network for Advanced 1D Drug-Target Interaction Prediction (https://arxiv.org/abs/2408.00040)
Comments:
          9 pages, 2 figures

- **What's New**: 새로운 BarlowDTI 모델은 약물-타겟 상호작용(Drug-Target Interaction)을 예측하는 혁신적인 방법을 제시합니다. 이 모델은 강력한 Barlow Twins 아키텍처를 특징 추출에 활용하며, 타겟 단백질의 구조를 고려하여 다수의 벤치마크에서 최고 성능을 달성합니다. Gradient Boosting Machine을 사용하여 빠르고 효율적인 예측을 보장합니다.

- **Technical Details**: BarlowDTI는 SMILES 표기법, 1차 아미노산 서열과 주석이 달린 상호작용 속성을 사용합니다. 입력 데이터는 벡터화되며, Barlow Twins 기반의 Self-Supervised Learning(SSL) 모델이 사용됩니다. 최종적으로 Barlow Twins 모델에서 생성된 임베딩을 사용하여 Gradient Boosting Machine(GBM)을 훈련합니다. 이 접근 방식은 깊이 학습(Deep Learning)의 표현력과 머신 러닝(Machine Learning)의 데이터 제한 상황에서의 성능을 결합합니다.

- **Performance Highlights**: BarlowDTI는 바이오메디컬 네트워크, 미국 특허 데이터베이스, 그리고 72개의 키네이스 억제제와 442개의 키네이스 상호작용 데이터와 같은 주요 벤치마크에서 현존하는 여러 모델을 능가했습니다. 특히, BioSNAP 데이터셋에서는 DLM-DTI 모델에 비해 5% 이상의 PR AUC(Precision-Recall Area Under Curve) 개선을 보였으며, BindingDB 데이터셋에서는 12% 이상의 개선을, 그리고 DAVIS 벤치마크에서는 18% 이상의 개선을 기록했습니다.



### WebApp1K: A Practical Code-Generation Benchmark for Web App Developmen (https://arxiv.org/abs/2408.00019)
- **What's New**: 이 논문에서는 웹 애플리케이션 개발을 위한 LLM의 성능을 평가하는 실질적인 코드 생성 벤치마크인 WebApp1K를 소개합니다. 이 벤치마크는 LLM의 코드 정확성과 기능성을 지속적으로 향상시키는 데 도움을 주고, 최신 LLM들과의 성능 비교를 가능하게 합니다.

- **Technical Details**: WebApp1K는 React 프레임워크(Framework)를 사용하여 1000개의 문제를 설정하고, 각 문제는 사용자 여정을 기반으로 합니다. 전체 벤치마크는 사용자의 성공 사례와 실패 사례를 시뮬레이션하여 fetchMock, await, expect 등의 코드를 통해 테스트합니다. 이 벤치마크는 오픈 소스 기여자들이 만든 고품질 코드와 모범 사례를 포함하고 있어, LLM에 내재된 지식을 검증하는데 적합합니다.

- **Performance Highlights**: GPT-4o와 Claude 3.5의 성능이 가장 뛰어나며, DeepSeek Coder V2는 이들에 근접한 결과를 보여주었습니다. 모델 크기와 코드 정확성 사이에는 높은 상관관계가 있으며, 특정한 프롬프팅 기술이 모든 모델의 성능을 향상시키는 데 보편적으로 적용되지 않았음을 발견했습니다. WebApp1K의 데이터셋, 실행 스크립트, 리더보드는 GitHub 및 Huggingface를 통해 공유되고 있습니다.



### Framework for Curating Speech Datasets and Evaluating ASR Systems: A Case Study for Polish (https://arxiv.org/abs/2408.00005)
Comments:
          Submitted to NeurIPS 2024 Datasets and Benchmarks Track

- **What's New**: 본 연구는 폴란드어 자동 음성 인식(ASR) 시스템의 포괄적인 비교를 수행한 첫 연구로, 총 24개의 공개된 음성 데이터셋을 정리하고 25개의 ASR 시스템 및 모델을 평가했습니다. 이로써 기존의 데이터셋 발견과 상호운용성(Interoperability) 문제를 해결하여 보다 체계적인 평가를 가능하게 했습니다.

- **Technical Details**: 연구팀은 키워드 기반 문헌 리뷰를 통해 관련 음성 데이터셋을 식별하고 문서화했습니다. 그 후, 다양한 음성 데이터셋을 수집하고 이를 표준화된 프로토콜에 따라 평가하는 프레임워크를 구축하였습니다. 이를 통해 다양한 출처의 읽기 및 자발적 발화 예시를 포함하는 벤치마크(bonus mark) 데이터셋을 구성하였습니다. 이 데이터셋은 공개적으로 제공되어 ASR 시스템의 평가 및 분석에 용이하도록 했습니다.

- **Performance Highlights**: 24개의 데이터셋과 10개의 상용 및 오픈 소스 ASR 시스템을 대상으로 600번의 시스템-모델-테스트 세트 평가를 수행했습니다. 이로 인해 시스템 간, 데이터셋 간, 그리고 연사 인구통계학적 특성 간의 성능 변동을 상세히 분석할 수 있었습니다. 평가 결과는 대시보드 형태로 공개되어, 연구 커뮤니티와 정보 공유 및 협력을 촉진하고 있습니다.



### Handling Numeric Expressions in Automatic Speech Recognition (https://arxiv.org/abs/2408.00004)
- **What's New**: 이 논문은 자동 음성 인식(ASR) 텍스트에서 숫자 표현의 적절한 형식을 지정하는 문제를 다룹니다. 숫자의 올바른 형식은 그 맥락에 따라 달라지기 때문에 이를 해결하는 것은 어려운 문제입니다. 특히, LLM(대형 언어 모델)과 TTS(Text-to-Speech) 모델을 활용하여 적응 데이터를 생성하는 접근법이 제시되었습니다.

- **Technical Details**: 논문은 연도, 타임스탬프, 통화 금액, 수량 등의 숫자 표현을 인식하고 형식화하는 두 가지 접근법(캐스케이드와 엔드 투 엔드)을 비교합니다. 엔드 투 엔드 접근법에서는 LLM과 TTS 모델을 활용하여 데이터 생성 전략을 사용했습니다. 훈련 데이터는 GPT-3.5 터보와 TTS 모델을 활용해 생성되었습니다. Whisper와 mbart 모델이 사용되었으며, 추가적으로 GPT-3.5, GPT-4도 텍스트 분할 모델로 비교되었습니다.

- **Performance Highlights**: 테스트 결과, LLM 기반 접근법은 포맷된 숫자 표현 인식에서 좋은 성능을 보였으며, 적응된 엔드 투 엔드 모델은 더 낮은 지연 시간과 추론 비용으로 경쟁력 있는 성능을 제공합니다. 특히, mbart 기반 모델이 ASR 모델 성능을 향상시키는 것으로 나타났습니다.



### Evaluating Transfer Learning in Deep Learning Models for Classification on a Custom Wildlife Dataset: Can YOLOv8 Surpass Other Architectures? (https://arxiv.org/abs/2408.00002)
Comments:
          This paper is being reviewed by SN Computer Science (springer journal)

- **What's New**: 이번 연구에서는 심층 학습 기반 기술을 사용하여 멸종 위기에 처한 동물 종을 자동으로 모니터링하는 방법을 연구했습니다. 심층 신경망(Deep Learning) 및 전이 학습(Transfer Learning) 기법을 활용하여 DenseNet, ResNet, VGGNet, YOLOv8 등의 다양한 모델을 비교했습니다. 결과적으로 YOLOv8 모델이 97.39%의 학습 정확도와 96.50%의 F1 스코어를 기록하며 가장 우수한 성능을 보였습니다.

- **Technical Details**: 연구진은 iNaturalist, ZooChat와 같은 신뢰할 수 있는 온라인 데이터베이스를 활용하여 맞춤형 데이터셋을 구축했습니다. 각 종별로 50장의 이미지가 포함되었고, 총 1150장의 이미지로 이루어진 균형 잡힌 데이터셋을 만들었습니다. 데이터 전처리 과정에서는 이미지의 비율을 1:1로 맞추고 해상도를 400x400으로 고정했으며, 정규화를 통해 모델의 수렴 속도를 높였습니다. 데이터셋은 80%의 훈련 데이터와 20%의 검증 데이터로 나누어졌고, 다양한 데이터 증강 기법을 적용하여 일반화 능력을 향상시켰습니다. 전이 학습 기법을 통해 사전 학습된 모델의 가중치를 동결하고 출력층만 맞춤형 완전 연결층으로 교체했습니다.

- **Performance Highlights**: YOLOv8 모델은 훈련 정확도 97.39%, F1 스코어 96.50%로 다른 모델들보다 뛰어난 성능을 보였습니다. 이는 DenseNet, ResNet, VGGNet 등 다른 인기있는 모델을 능가하는 결과입니다. 이 연구는 기존 인간 주도 모니터링 방법보다 높은 정확도와 효율성을 제공하는 YOLOv8 기반의 자동화된 야생 동물 모니터링 시스템이 멸종 위기 동물 보호에 크게 기여할 수 있음을 시사합니다.



### Replication in Visual Diffusion Models: A Survey and Outlook (https://arxiv.org/abs/2408.00001)
Comments:
          The first survey focuses on replication in visual diffusion models. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 시각적 확산 모델(Visual diffusion models)은 창의적인 AI 분야에서 고품질의 다양성을 가진 콘텐츠를 생성해 큰 변화를 일으켰습니다. 본 논문은 이러한 모델이 학습 과정에서 이미지를 기억하고 이를 추론 과정에서 다시 생성함으로써 프라이버시, 보안, 저작권에 대한 문제를 야기하는 현상을 최초로 포괄적으로 리뷰합니다.

- **Technical Details**: 논문은 복제 현상을 해명(unveiling), 이해(understanding), 완화(mitigating)라는 세 가지 측면으로 나누어 기존 연구를 체계적으로 분류합니다. 해명 부분에서는 복제되는 사례를 탐지하는 방법을 중점으로 다루고, 이해 부분에서는 이 현상의 근본적인 메커니즘과 요인을 분석하며, 완화 부분에서는 이를 줄이거나 제거하기 위한 전략을 개발하는 데 중점을 둡니다.

- **Performance Highlights**: 본 논문은 특히 헬스케어 분야에서 환자 데이터와 관련된 프라이버시 문제가 복제 현상으로 인해 심각하게 우려된다는 점을 강조합니다. 결론 부분에서는 복제를 탐지하고 벤치마킹하는 것의 어려움과 같은 현존하는 도전 과제와 보다 견고한 완화 기술 개발을 위한 향후 방향성을 논의합니다.



### The Llama 3 Herd of Models (https://arxiv.org/abs/2407.21783)
- **What's New**: 이번 논문은 새로운 파운데이션 모델(foundation model) 세트인 Llama 3를 소개합니다. Llama 3는 다국어 지원, 코딩, 추론, 도구 사용을 네이티브로 지원하는 다양한 언어 모델 군입니다. 최대 4050억 개의 매개변수(parameter)와 128K 토큰의 문맥 창(context window)을 가지는 밀집 트랜스포머(dense Transformer)를 포함하고 있습니다.

- **Technical Details**: Llama 3는 코드 작성, 다국어 처리, 추론 등의 다양한 작업을 수행할 수 있는 다기능 언어 모델 군입니다. 실험적으로 Llama 3는 GPT-4와 같은 선두 언어 모델과 유사한 품질을 제공하는 것으로 나타났습니다. 우리는 또한 미리 학습된(pre-trained) 및 후속 학습된(post-trained) 버전의 405B 매개변수 언어 모델과 입력 및 출력의 안전성을 보장하는 Llama Guard 3 모델을 공개했습니다. 이미지, 비디오, 음성 기능을 통합하기 위해 조합적 접근법(compositional approach)을 사용한 실험 결과도 제시합니다.

- **Performance Highlights**: Llama 3는 이미지 인식, 비디오 인식, 음성 인식 작업에서 최첨단(state-of-the-art) 성능과 경쟁할 수 있는 능력을 보여줍니다. 하지만, 이러한 통합된 모델들은 아직 개발 중이며, 광범위한 공개는 이루어지지 않았습니다.



### Tulip Agent -- Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries (https://arxiv.org/abs/2407.21778)
Comments:
          19 pages, 4 figures

- **What's New**: Tulip 에이전트라는 새로운 자율형 LLM 기반 에이전트 아키텍처를 소개합니다. 이 에이전트는 Create, Read, Update, Delete 액세스를 통해 잠재적으로 많은 도구를 포함할 수 있는 도구 라이브러리에 접근할 수 있습니다. Tulip 에이전트는 시스템 프롬프트에 모든 도구 설명을 인코딩하지 않으며, 대신 벡터 스토어(vector store)를 활용하여 적절한 도구를 재귀적으로 검색합니다.

- **Technical Details**: 최신 구현과 달리, Tulip 에이전트는 시스템 프롬프트에 전체 도구 설명을 포함시키지 않아서 모델의 컨텍스트 윈도우(context window)를 절약합니다. 또한 적절한 도구를 검색하기 위해 전체 프롬프트를 임베드하는 대신, 확장 가능한 도구 라이브러리에서 재귀적으로 도구를 검색하는 방식을 사용합니다. 이러한 아키텍처는 추론 비용을 크게 줄이며 대규모 도구 라이브러리의 사용을 가능하게 하고, 에이전트가 도구 셋을 적응 및 확장할 수 있게 합니다.

- **Performance Highlights**: 수학적 맥락에서 여러 ablation study를 통해 Tulip 에이전트 아키텍처를 평가하였습니다. 또한 로봇 공학에 적용함으로써 그 일반성을 입증하였습니다. 참고 구현 및 벤치마크는 제공된 URL에서 확인할 수 있습니다.



### MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts (https://arxiv.org/abs/2407.21770)
- **What's New**: MoMa은 새로운 모달리티 인식 혼합 전문가(MoE) 아키텍처로, 혼합 모달, 초기 융합 언어 모델의 사전 학습을 위한 것입니다. MoMa는 이미지와 텍스트를 임의의 순서로 처리하며, 전문가 모듈을 모달리티별 그룹으로 나눕니다. 이러한 그룹은 각자 지정된 토큰만 처리하면서 학습된 라우팅을 통해 의미적으로 적응할 수 있습니다.

- **Technical Details**: MoMa의 핵심은 모달리티별 전문가 그룹으로 나눠진 Mixture-of-Experts(MoE) 메커니즘입니다. 텍스트와 이미지 토큰은 각기 다른 정보 밀도와 중복 패턴을 가지므로, 모달리티별 모듈을 도입하여 각 모달리티에 특화된 특징을 잘 포착할 수 있습니다. Chameleon 아키텍처를 기반으로, 너비와 깊이 두 차원에서 스파스티를 적용했습니다: 너비에서는 Feed-forward blocks(전달 블록)를 통한 MoE를 적용하고, 깊이에서는 특정 층의 계산을 선택적으로 건너뛰는 Mixture-of-Depths(MoD)를 적용했습니다.

- **Performance Highlights**: 모달리티 인식 전문가와 MoD를 결합한 MoMa는 매우 높은 FLOPs 절감 효과를 보였습니다. 1조 토큰의 훈련 예산 하에서, MoMa 1.4B 모델(4 텍스트 전문가와 4 이미지 전문가 포함)은 FLOPs 절감을 달성했습니다: 텍스트 처리에서 2.6배, 이미지 처리에서 5.2배입니다. 이것은 FLOPs 절감에서 기준 전문가 선택 MoE와 비교하여 더욱 효율적인 성능을 입증합니다. 그러나 MoD와 결합 시, 향상된 FLOPS 절감에도 불구하고 캐주얼 인퍼런스(causal inference) 성능에서는 라우터 정확도에 대한 민감성으로 인해 성능 저하가 발생했습니다.



### ParLS-PBO: A Parallel Local Search Solver for Pseudo Boolean Optimization (https://arxiv.org/abs/2407.21729)
Comments:
          17 pages,2 figures, to be published in The 30th International Conference on Principles and Practice of Constraint Programming

- **What's New**: 최근 수년 간 여러 최적화 문제에 널리 사용된 국지 탐색(local search) 기법이 Pseudo-Boolean Optimization (PBO) 문제 해결에서도 채택되었습니다. 이번 논문에서는 기존 LSPBO(LSPBO)의 성능을 향상시키기 위해 동적 점수 매기기 메커니즘(dynamic scoring mechanism)을 도입하고, 이를 바탕으로 첫 병렬 국지 탐색 PBO 솔버를 개발했습니다. 새로운 병렬 솔버는 여러 스레드(thread) 간 좋은 해를 공유하고, 이를 통해 탐색을 안내하는 방식을 취합니다.

- **Technical Details**: 먼저, 개선된 LSPBO는 어려운 제약 조건(hard constraints)과 목표 함수(objective function)의 점수 사이 균형을 동적으로 맞추는 메커니즘을 추가했습니다. 또한, 병렬 국지 탐색 PBO 솔버를 위해 해결책 풀(solution pool)을 유지하며, 각 스레드에서 좋은 해를 교환하여 탐색을 진행합니다. 이 과정에서 해결책의 품질과 다양성을 고려한 함수로 해결책 풀을 업데이트합니다. 추가적으로, 해결책 풀의 극성 밀도(polarity density)를 계산하여 국지 탐색의 점수 함수를 강화합니다.

- **Performance Highlights**: 실험 결과, 제안된 병렬 접근 방식은 상업적인 유명 솔버 Gurobi의 병렬 버전과 경쟁할 만한 성능을 보였습니다. 특히, ParLS-PBO는 최대 32개의 스레드까지 성능이 향상되는 스케일러빌리티(확장성)를 보였습니다. 기존의 LS-PBO, DeciLS-PBO, NuPBO와 같은 솔버들은 물론, SCIP, HYBRID, PBO-IHS, FiberSCIP와 비교해도 뛰어난 성능을 자랑합니다.



### Artificial Intelligence Approaches for Energy Efficiency: A Review (https://arxiv.org/abs/2407.21726)
- **What's New**: 이번 논문은 지속 가능한 개발 목표 중 7번(저렴하고 청정한 에너지), 9번(산업, 혁신 및 인프라), 13번(기후 행동)에 중점을 두고 있습니다. 인공지능(AI)과 다중 에이전트 시스템(MAS)을 활용하여 스마트 빌딩에서 에너지 효율성을 높이는 방법을 주요 논점으로 삼고 있습니다.

- **Technical Details**: 에너지 관리 시스템(EMS) 설계와 결함 감지 및 최소화를 위해 AI 도구를 사용합니다. 주요 기술로는 빅 데이터(Big Data)와 사물인터넷(IoT)을 통한 데이터 수집, 그리고 머신러닝(Machine Learning) 모델 훈련 등이 있습니다. HVAC 시스템이 건물에서 가장 많은 에너지를 소비하기 때문에 이에 대한 특별한 집중이 필요합니다. AI 기반의 에너지 관리 시스템은 이 데이터를 활용하여 예측 모델을 개발하고, 실시간으로 데이터를 처리합니다.

- **Performance Highlights**: 논문에서는 다양한 AI 기법과 모델을 통해 에너지 소비 예측, 정전 예측, 에너지 저장 및 관리, 열 쾌적성 평가, 가전제품의 세부적인 에너지 소비 예측 등 여러 방면에서의 응용 사례를 제시합니다. 또한 최적화 알고리즘(Optimal Algorithms)을 사용하여 건물의 에너지 소비를 줄이는 방법에 대해 논의됩니다. 강화학습(Reinforcement Learning)을 통해 사용자들의 에너지 소비 습관을 최적화하는 기법도 강조됩니다.



### Assessing the State of AI Policy (https://arxiv.org/abs/2407.21717)
- **What's New**: AI 애플리케이션의 배포가 급격히 가속화되는 가운데, 이러한 기술들이 인프라, 소비자 제품 및 가정용 응용 프로그램 등 다양한 분야에서 대중과 만나고 있습니다. 많은 AI 기술들은 물리적 상해나 편향의 형태로 위험을 내포하고 있기 때문에 정책 입안자들이 감독의 필요성을 고려해야 합니다. 하지만 대부분의 정책 입안자들은 새로운 AI 기술이 안전하고 효과적이며 감독이 필요한지를 판단할 기술적 지식이 부족하여 전문가 의견에 의존해야 합니다. 이 논문은 국제, 미국 주, 도시 및 연방 수준에서의 AI 법률 및 지침 현황을 개괄하고 있으며, 관련 비즈니스 표준과 기술 사회(technical society)의 이니셔티브를 검토합니다. 그런 다음 겹침과 격차 분석(overlap and gap analysis)을 수행하여 미래 정책 수립을 위한 권고 사항과 지침을 포함한 참고 가이드를 제공합니다.

- **Technical Details**: 이 연구는 AI 법률, 규정 및 지침의 전반적인 경관을 조사합니다. 특히, 국제적으로, 미국의 주, 도시 및 연방 수준에서의 법률 및 지시사항, 관련 비즈니스 표준과 기술 사회(technical society)의 이니셔티브까지 포괄적으로 검토합니다. 또한, 이러한 법률과 표준이 어떻게 겹치는지와 어떤 부분에서 격차가 존재하는지를 분석하여 보다 종합적인 감독 체계를 구축하기 위한 참고 자료를 제공합니다.

- **Performance Highlights**: 이 논문은 AI 기술이 대중에게 미치는 잠재적 위험을 인식하고 정책 입안자들이 보다 효과적으로 감독할 수 있는 능력을 갖추기 위한 중요한 단계임을 강조합니다. 이를 위해 다양한 수준에서의 법률 및 규정을 종합적으로 분석한 결과, 겹침과 격차를 발견하고 이에 대한 권고 사항과 지침을 제공함으로써 미래의 AI 정책이 보다 공정하고 안전하게 수립될 수 있도록 돕습니다.



### UMMAN: Unsupervised Multi-graph Merge Adversarial Network for Disease Prediction Based on Intestinal Flora (https://arxiv.org/abs/2407.21714)
- **What's New**: 이 논문에서는 처음으로 장내 미생물군을 이용한 질병 예측 작업에 그래프 기계 학습(GNN: Graph Neural Network)을 적용한 새로운 아키텍처인 '비지도 다중 그래프 병합 적대적 네트워크(UMMAN: Unsupervised Multi-graph Merge Adversarial Network)'를 소개합니다. 이 방법은 인간 몸체 내 다양한 숙주에서 장내 미생물 간의 복잡한 상관관계를 학습하여 예측 성능을 높입니다.

- **Technical Details**: UMMAN은 여러 가지 relation-types(관계 유형)를 사용하여 다양한 연관성을 가진 Multi-graph(다중 그래프)를 구축한 후, 노드 간의 관계를 섞어주는 Shuffled-Graph(섞인 그래프)를 생성합니다. Node Feature Global Integration (NFGI) 모듈을 소개하여 그래프의 글로벌 특징을 나타내고, 적대적 손실과 하이브리드 주의 손실로 구성된 joint loss를 설계하여 실제 그래프 임베딩이 Original-Graph(원래 그래프)와 일치하고 Shuffled-Graph와는 달라지도록 유도합니다. 그 결과 UMMAN은 비지도 학습 시나리오에서 노드의 임베딩을 효율적으로 획득할 수 있습니다.

- **Performance Highlights**: 다섯 개의 고전적 OTU(운영 분류 단위: Operational Taxonomic Units) 장내 미생물 데이터셋에서 실험한 결과, UMMAN은 장내 미생물 질병 예측 작업에서 최첨단 성능을 달성했음을 보여줍니다. 이는 기존 방법들보다 더 안정적임을 증명합니다.



### CEAR: Automatic construction of a knowledge graph of chemical entities and roles from scientific literatur (https://arxiv.org/abs/2407.21708)
- **What's New**: 이 연구는 기존 화학 관련 지식체계인 ChEBI(화학물질의 생물학적 관심대상)와 대형 언어 모델(LLM)을 결합하여 화학 연구 논문에서 화학 물질과 그 역할을 더 효율적으로 식별하고 지식 그래프(KG)를 생성하는 새로운 방법론을 제안합니다. 이는 ChEBI의 한계를 보완하고, 빠른 속도로 증가하는 화학 지식을 더 잘 반영하고자 하는 목적을 가지고 있습니다.

- **Technical Details**: 이 방법론은 두 가지 주요 단계를 포함합니다. 첫째, 기존에 주석이 달린 텍스트 코퍼스를 ChEBI의 지식으로 보강하고, 대형 언어 모델(LLM)을 미세 조정하여 화학 물질과 그 역할을 인식하도록 구현합니다. 둘째, 이러한 인식된 정보를 바탕으로 두 번째 LLM을 사용하여 화학 물질과 역할(Chemical Entities And Roles, CEAR)에 대한 지식 그래프(KG)를 생성합니다. 이를 위해, 연구 논문의 전체 텍스트를 추출하고 JSON 문서 형식으로 저장하며, RDF-star 형식으로 관계들을 모델링합니다.

- **Performance Highlights**: 실험 결과, LLM을 이용한 접근 방식은 화학 연구 논문에서 화학 물질과 역할을 높은 정확도와 재현율로 식별하는 데 효과적임이 증명되었습니다. 또한, ChemRxiv의 8,000개 논문에서 데이터를 추출하여 ChEBI에 없는 새로운 정보를 포함하는 지식 그래프를 성공적으로 생성하였습니다.



### TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities (https://arxiv.org/abs/2407.21693)
- **What's New**: 이번 연구에서는 다양한 생활 서비스 시나리오를 담은 중국어 대화 데이터셋인 TransferTOD를 소개합니다. 이 데이터셋은 30개의 인기 생활 서비스 시나리오에서 인공지능 시스템과의 대화를 시뮬레이션하며, 정보 수집 및 슬롯 채우기 작업에서 뛰어난 성능을 보여주었습니다.

- **Technical Details**: TransferTOD 데이터셋은 35965개의 발화와 5460개의 대화로 구성되어 있으며, 다양한 질문 스타일 및 노이즈에 강한 데이터를 포함합니다. 모델 학습을 위해 전체 파라미터를 미세 조정(full-parameter fine-tuning)하는 방법을 사용했습니다. 데이터 수집 과정은 슬롯 생성, 데이터 교란 도입, GPT를 통한 대화 다양화, 수동으로 대화 내용을 정제하는 4단계로 이루어졌습니다.

- **Performance Highlights**: TransferTOD-7B 모델은 슬롯 채우기와 질문 능력에서 GPT-4를 능가하는 성능을 보여주었으며, 도메인 외 테스트에서도 GPT-3.5-Turbo를 능가하는 결과를 냈습니다. 데이터 처리와 질문 다양성, 언어 유창성을 최적화하여 모델 성능이 크게 향상되었습니다.



### Human interaction classifier for LLM based chatbo (https://arxiv.org/abs/2407.21647)
Comments:
          16 pages, 13 figures

- **What's New**: 이 연구는 Applus+ IDIADA의 지능형 에이전트 AIDA를 위한 인간 상호작용 분류기를 개발하는 데 중점을 둡니다. 주된 목표는 대화, 서비스, 문서 번역과 같은 다양한 상호작용을 식별하여 요청을 적절한 채널로 유도하고 보다 전문적이고 효율적인 서비스를 제공하는 것입니다.

- **Technical Details**: 다양한 모델이 비교되었습니다. 여기에는 LLM(대형 언어 모델)을 기반으로 한 분류기와 KNN, SVM, 인공신경망(ANN)을 사용하는 모델이 포함됩니다. LLM 기반 접근 방식과 비교할 때 SVM과 ANN 모델이 Cohere embeddings를 사용하여 더 나은 성능을 보였습니다.

- **Performance Highlights**: 연구 결과, SVM 모델과 Cohere embeddings가 가장 뛰어난 F1 점수와 빠른 실행 시간을 보여 최고의 성능을 기록했습니다. 이 모델은 Applus+ IDIADA의 AIDA 환경에서 정확성과 계산 효율성의 최적 균형을 제공하여 인간 상호작용을 분류하는 데 가장 적합한 옵션으로 결론이 났습니다.



### Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components (https://arxiv.org/abs/2407.21638)
Comments:
          Accepted to MICCAI UNSURE Workshop

- **What's New**: 최신 의료 영상 해석의 자동화는 진단 워크플로우의 병목 현상을 완화하는 데 중요하며, 특히 자연어 처리(NLP) 분야의 발전으로 큰 주목을 받고 있습니다. 이번 연구에서는 진단적 중요성의 의미론에 관한 AI 기반 방사선 보고서의 신뢰성을 평가하기 위해 모듈형 보조 감사 구성요소(auxiliary auditing components, AC)로 구성된 품질 관리 프레임워크를 제안합니다.

- **Technical Details**: 제안된 프레임워크는 MIMIC-CXR 데이터셋을 이용해 평가되었으며, ACs를 질병 분류기로 활용해 진단적 의미를 추출합니다. 보고서 생성 모델 GenX를 개발하여 이미지에 대한 텍스트 시퀀스를 생성하고, 보고서와 AC 레이블의 일관성을 평가해 품질을 검토합니다. GenX는 기존 연구들과 경쟁력 있는 성능을 보이며, 제작된 보고서는 ACs의 분류 신뢰도를 활용해 보다 엄격한 품질 검토를 시행합니다.

- **Performance Highlights**: MIMIC-CXR 데이터셋에서의 평가 결과, ACs을 포함한 보고서는 필터링되지 않은 보고서에 비해 더 높은 F1 점수를 기록했습니다. 이는 보고서와 보조 구성 요소 간의 일관성이 자동화된 보고서 생성의 유망한 감사 메커니즘임을 보여줍니다.



### TRGR: Transmissive RIS-aided Gait Recognition Through Walls (https://arxiv.org/abs/2407.21566)
Comments:
          Globecom 2024 IoTSN accepted

- **What's New**: 무선 주파수(RF) 신호를 이용한 보행 인식 기술은 정밀한 식별이 필요한 다양한 응용 분야에서 가능성을 보이고 있습니다. 이 논문에서는 TRGR이라는 새로운 시스템을 소개합니다. 기존 시스템의 한계인 시야선(LOS) 환경 내에 있어야 하고, 콘크리트와 두꺼운 벽을 통과할 때 신호 대 잡음 비(SNR)가 낮아지는 문제를 해결하기 위해, 재구성 가능한 지능형 표면(RIS)을 활용한 투과형 보행 인식 시스템인 TRGR을 제안합니다.

- **Technical Details**: TRGR은 CSI(Channel State Information) 크기 측정값만으로 벽을 통과해 사람의 신원을 식별할 수 있습니다. 이를 위해 투과형 RIS와 구성 교대 최적화 알고리즘을 이용하여 벽 통과 성능과 신호 품질을 향상시킵니다. 또한, 잔여 컨볼루션 네트워크(RCNN)를 기반으로 하여 강력한 보행 정보를 학습합니다. 이러한 접근 방식은 기하급수적인 전송 품질 향상과 보다 효과적인 보행 인식을 가능하게 합니다.

- **Performance Highlights**: 실험 결과에 따르면 TRGR은 콘크리트 벽을 통과할 때 사람 식별의 평균 정확도가 97.88%에 달하며, 이는 TRGR 시스템의 효과성과 견고함을 입증합니다. 다양한 실험 결과들이 TRGR의 뛰어난 성능을 강조하며, RF 기반 보행 인식 시스템의 향상을 위해 투과형 RIS의 잠재력을 크게 시사합니다.



### Operator-based semantics for choice programs: is choosing losing? (full version) (https://arxiv.org/abs/2407.21556)
Comments:
          Extended version of a paper accepted at KR 2024

- **What's New**: 이번 연구는 의미론(semantics)에 대한 연구가 어려웠던 논리 프로그래밍의 선택 구조(choice constructs)의 의미론을 정의하고 비교하는 데 사용될 수 있는 연산자 기반(framework operator-based)의 접근 방안을 제안합니다. 이를 통해 기존의 다양한 두 값 논리(two-valued semantics)의 한계를 극복하고, 논리 프로그래밍의 선택 구조를 원리적으로 정의하고 비교할 수 있게 합니다.

- **Technical Details**: 본 연구는 즉각적 결과 연산자(immediate consequence operators)를 기반으로 논리 프로그램의 선택 구조를 정의하고 연구합니다. 이 연산자들은 설명 도구의 설계에도 유용하며 문제 해결기(solvers)의 기초를 제공합니다. 특히 비결정성 근사 고정점 이론(non-deterministic approximation fixpoint theory, AFT)을 사용하여 다양한 지원(Supported) 및 안정적(Stable) 의미론을 정의하고, 이를 비교적 원칙적으로 비교합니다.

- **Performance Highlights**: 논문의 주요 기여점은 다음과 같습니다. (1) 비결정적 근사 고정점 이론을 사용해 다양한 지원 및 안정적 의미론을 정의, (2) 건설적인 안정 고정점을 소개해, 존재하는 많은 의미론들을 일반화, (3) 포스트레이트 기반의 비교를 도입해 기존 의미론들과의 관계를 원리적으로 비교, (4) 선택 구조와 분해(disjunction) 논리 프로그램 간의 관계를 명확히 함.



### FSSC: Federated Learning of Transformer Neural Networks for Semantic Image Communication (https://arxiv.org/abs/2407.21507)
- **What's New**: 이 논문에서는 다중 사용자 배치 시나리오에서 이미지 의미적 통신 문제를 다루고, Swin Transformer 기반 의미 통신 시스템(Swin Transformer-based semantic communication system, FSSC)을 위한 연합 학습(Federated Learning, FL) 전략을 제안합니다. Swin Transformer를 사용한 공동 소스-채널 코딩(Joint Source-Channel Coding, JSCC)을 통해 통신 시스템에서 의미 정보를 효과적으로 추출할 수 있음을 입증합니다. 또한, FL 프레임워크를 도입하여 각 사용자의 데이터 보호와 서버 또는 모바일 엣지의 작업 부하를 줄이는 데 도움이 되는 글로벌 모델 학습을 구현합니다.

- **Technical Details**: Swin Transformer 기반 의미 통신 시스템(STSC)은 이미지 재구성을 중심으로 한 고유한 아키텍처를 통해 입력 데이터 내의 복잡한 의미 관계를 표현하며, 이는 기존 Transformer 모델에 비해 계산 복잡성을 줄이고 모델 학습과 추론 속도를 높입니다. 연합 학습 FL을 사용하면 사용자의 개인 데이터를 직접 공유하지 않고도 다중 사용자의 지식을 통합하여 글로벌 모델을 학습할 수 있습니다. STSC의 연합 학습 프로세스는 클라우드 서버가 모델을 초기화하고, 각 클라이언트가 로컬에서 학습을 수행한 후 업데이트된 모델 파라미터를 클라우드 서버로 전송하여 Federated Averaging을 통해 글로벌 모델을 도출하는 방식으로 진행됩니다.

- **Performance Highlights**: 시뮬레이션 결과, 제안된 방법이 일반적인 JSCC 알고리즘 및 전통적인 분리 기반 통신 알고리즘보다 뛰어나며, 특히 로컬 의미를 통합한 후 전역 모형의 피크 신호 대 잡음비(Peak Signal-to-Noise Ratio, PSNR)가 2dB 이상 증가했습니다. 이러한 결과는 제안된 알고리즘의 효과를 명확하게 증명합니다.



### Parallel Strategies for Best-First Generalized Planning (https://arxiv.org/abs/2407.21485)
Comments:
          3 pages

- **What's New**: 최근 인공지능(AI) 연구에서 중요한 목표 중 하나는 최신 계획 해결사(planning solvers)와 일반화된 계획(generalized planning, GP) 간의 성능 격차를 해소하는 것입니다. 이번 연구에서는 Best-First Generalized Planning (BFGP) 알고리즘의 병렬 탐색 기법을 적용하여 이러한 성능 격차를 좁히기 위한 새로운 접근법을 제안합니다. BFGP는 새로운 해답 공간을 기반으로 하며, 탐색 히스틱(heuristic) 검색을 사용하여 여러 고전적 계획 인스턴스를 해결할 수 있습니다.

- **Technical Details**: BFGP는 병렬 프로그래밍을 통해 효율적으로 확장될 수 있습니다. 이 논문에서는 BFGP가 병렬화에 적합한 이유와 이를 고전적 계획자와 구별짓는 몇 가지 특성에 대해 논의합니다. 또한 코어 수에 따라 선형으로 확장 가능한 두 가지 간단한 공유 메모리 병렬 전략을 제안합니다. 해당 알고리즘은 해답 노드를 분배하고 도달된 노드의 일관성을 유지하는 데 중요한 역할을 합니다.

- **Performance Highlights**: BFGP는 해답 공간 탐색 중 상태를 반복하지 않는 특성을 가지고 있으며, 이는 병렬화에 필요한 중복 검출(overhead)과 동기화 문제를 줄여줍니다. 또한 Greedy Best-First Search (GBFS)는 평가 함수 f(n)=h(n)만 사용하여 목표 상태까지의 추정 비용만을 고려합니다. 이러한 구조적 특징 덕분에 BFGP는 병렬화된 환경에서 우수한 성능을 발휘할 수 있습니다.



### eSPARQL: Representing and Reconciling Agnostic and Atheistic Beliefs in RDF-star Knowledge Graphs (https://arxiv.org/abs/2407.21483)
- **What's New**: 이번 연구에서는 RDF-star의 확장인 eSPARQL이라는 새로운 쿼리 언어를 제안합니다. 이 언어는 다중 소스 간의 상충되는 믿음들을 효과적으로 처리할 수 있도록 설계되었습니다.

- **Technical Details**: eSPARQL은 RDF 및 SPARQL 프로토콜을 기반으로 하며, FROM 절을 확장하여 여러 믿음 상태를 다룰 수 있도록 합니다. RDF-star의 확장을 통해 네 가지 논리 값(true, unknown, false, conflicting)을 처리하는 메커니즘을 제안합니다.

- **Performance Highlights**: 본 연구에서는 eSPARQL이 네 가지 사용 사례 쿼리를 표현할 수 있음을 보여줍니다. 여기에는 특정 개인의 믿음 쿼리, 믿음의 집계, 상충되는 믿음들 및 믿음의 중첩 쿼리가 포함됩니다.



### Multi-agent Assessment with QoS Enhancement for HD Map Updates in a Vehicular Network (https://arxiv.org/abs/2407.21460)
- **What's New**: 본 연구에서는 차량 애드혹 네트워크(VANET)에서 고해상도(HD) 맵의 전송 성능을 개선하기 위해 단일 에이전트를 이용한 Q-learning 솔루션을 다중 에이전트 환경에 확장하여 평가했습니다. 새로운 솔루션은 네트워크 성능을 향상시키기 위해 상태 및 액션 공간을 자율적으로 활용합니다.

- **Technical Details**: 이 솔루션은 Q-learning과 동일한 보상 함수를 각 에이전트에 적용하여 높은 차원의 문제를 해결하고 계산 복잡도를 줄입니다. 또한 이 솔루션은 중앙 집중형 학습과 분산형 학습의 성능을 비교하며 음성, 비디오, HD 맵, 및 베스트 에포트(Best-Effort) 등 다양한 서비스의 성능 향상을 실험을 통해 평가합니다. 본 연구는 다중 에이전트 설정에서 중앙 집중형 단일 에이전트 접근법보다 더 나은 성능을 보여줍니다.

- **Performance Highlights**: 실험 결과에 따르면 본 연구의 제안된 솔루션은 음성의 경우 40.4%, 비디오의 경우 36%, HD 맵의 경우 43%, 베스트 에포트의 경우 12%의 시간 지연(latency) 개선을 달성했습니다.



### KemenkeuGPT: Leveraging a Large Language Model on Indonesia's Government Financial Data and Regulations to Enhance Decision Making (https://arxiv.org/abs/2407.21459)
Comments:
          14 pages, 7 figures, 10 tables

- **What's New**: 이번 연구는 인도네시아 재무 데이터를 분석하고 규정을 이해하는 데 있어서 대형 언어 모델(LLMs)의 잠재력을 조사하고 있습니다. 연구에서는 특히 LangChain과 Retrieval-Augmented Generation(RAG)을 사용해 KemenkeuGPT를 개발하였습니다. 이를 통해 공공부문에서도 LLM의 활용 가능성을 탐구합니다.

- **Technical Details**: KemenkeuGPT는 RAG, 프롬프트 엔지니어링(prompt engineering), 파인 튜닝(fine-tuning)을 통해 개발되었습니다. 연구 과정에서는 2003년부터 2023년까지의 데이터를 사용하며, 인도네시아 통계청과 국제통화기금(IMF)의 데이터도 포함됩니다. 모델 성능은 인간 피드백, LLM 기반 평가 및 벤치마킹을 통해 평가되었습니다.

- **Performance Highlights**: 모델의 정확도는 35%에서 61%로, 올바름(correctness)은 48%에서 64%로 향상되었습니다. RAGAS 프레임워크 평가에서 KemenkeuGPT는 44%의 올바름과 73%의 충실도(faithfulness), 40%의 정밀도(precision), 60%의 재현율(recall)을 기록하여 다른 기준 모델들을 능가했습니다.



### MLLM Is a Strong Reranker: Advancing Multimodal Retrieval-augmented Generation via Knowledge-enhanced Reranking and Noise-injected Training (https://arxiv.org/abs/2407.21439)
- **What's New**: RagLLaVA는 최신 정보를 활용하여 사실적이고 정확한 출력을 제공하는 멀티모달 리트리벌 강화 생성(Multimodal Retrieval-augmented Generation, Multimodal RAG)의 한계를 극복하는 새로운 프레임워크입니다. 이는 다양한 데이터 모달리티(텍스트, 이미지, 오디오, 비디오) 간의 컨텐츠 처리 및 생성 능력을 향상시키는 Multimodal Large Language Models(MLLMs)의 단점을 보완합니다.

- **Technical Details**: RagLLaVA는 지식증강 리랭킹(knowledge-enhanced re-ranking)과 노이즈 주입 트레이닝(noise-injected training) 방법을 통해 멀티모달 RAG의 다중 그레인 노이즈 문제(multi-granularity noisy correspondence, MNC)를 해결합니다. 리트리벌 단계에서는 CLIP을 사용하여 외부 메모리에서 top-k 이미지를 검색한 다음, 간단한 인스트럭션 템플릿으로 MLLM을 튜닝하여 리랭킹 기능을 유도합니다. 생성 단계에서는 트레이닝 과정에서 데이터 및 토큰 수준에서 시각적 노이즈를 주입하여 모델의 견고성을 향상시킵니다.

- **Performance Highlights**: RagLLaVA는 이미지 검색 및 이유 파악을 요구하는 두 개의 데이터셋 하위 집합에서 포괄적인 실험을 통해 우수한 성능을 입증했습니다. 실험 결과, RagLLaVA는 정확한 검색과 견고한 생성을 통해 기존 모델들보다 뛰어난 성능을 보여주었습니다.



### SmileyNet -- Towards the Prediction of the Lottery by Reading Tea Leaves with AI (https://arxiv.org/abs/2407.21385)
Comments:
          This is a satirical accumulation of misconceptions, mistakes, and flawed reasoning I have encountered in recent times as a reviewer and sometimes even as a reader of published papers. I hope it is entertaining and useful in the context of the education of BSc, MSc, and PhD students in Machine Learning, Artificial Intelligence, and Cognitive Science

- **What's New**: SmileyNet는 새로운 바이오-영감을 받은 신경망으로, 긍정적인 감정이 인지 과정을 향상시킬 수 있다는 사실에 기반하여 개발되었습니다. 이를 통해 신경망에 미소 이모티콘을 입력하여 긍정적인 감정을 유도하고, 이후 동전 던지기의 결과를 예측하는 데 사용합니다. 이 과정에서 SmileyNet은 무려 72%의 예측 정확도를 보이며, 그 성능은 ResNet-34(49%)나 YOLOv5(53%)보다 훨씬 뛰어납니다.

- **Technical Details**: SmileyNet은 네트워크를 긍정적인 감정 상태로 최적화하는 독특한 교육 방법을 사용합니다. 네트워크는 먼저 'U+1F642'(슬ightly Smiling Face) 이모티콘을 입력으로 받아들여 긍정적인 감정 상태로 편향됩니다. 이를 통해 네트워크가 스트레스 없는 환경에서 학습하도록 도와줍니다. 이러한 생체 영감 방법은 기존 신경망 𝒩o⁢l⁢d를 새로운 신경망 𝒩n⁢e⁢w으로 전환하여 더 나은 성능을 기대할 수 있습니다.

- **Performance Highlights**: SmileyNet은 동전 던지기 결과 예측에서 72%의 정확도를 기록하며 뛰어난 성능을 보였습니다. 이는 비교 대상으로 사용된 ResNet-34(49%)나 YOLOv5(53%)보다 월등히 높은 수치입니다. 이를 통해 SmileyNet이 단순히 랜덤 추측을 넘어서 예측 능력을 갖추고 있음을 확인할 수 있었습니다.



### An Extended Kalman Filter Integrated Latent Feature Model on Dynamic Weighted Directed Graphs (https://arxiv.org/abs/2407.21376)
- **What's New**: 새로운 연구는 동적 가중치 유향 그래프(Dynamic Weighted Directed Graph, DWDG)를 정확히 표현하기 위해 Extended-Kalman-Filter-Incorporated Latent Feature(EKLF) 모델을 제안합니다. 기존 접근 방법들은 데이터 중심적 관점에서 복잡한 시간적 패턴을 탐구하지만, 이는 DWDG가 시간에 따라 큰 변동을 보일 때 정확도가 떨어지는 단점이 있었습니다. 이를 해결하기 위해 제안된 EKLF 모델은 모델 중심적 관점을 채택하고 있습니다.

- **Technical Details**: EKLF 모델은 두 가지 주요 아이디어로 나뉘어집니다: (a) 확장 칼만 필터(Extended Kalman Filter, EKF)를 사용하여 비선형 상태 전이와 관측 함수를 통해 복잡한 시간적 패턴을 정확히 추적; (b) 교대 최소 제곱법(Alternating Least Squares, ALS) 알고리즘을 사용하여 잠재 특징(latent features, LFs)을 번갈아가며 학습하여 DWDG를 정확히 표현. 이러한 접근 방식은 DWDG의 누락된 엣지 가중치(missing edge weights)를 예측하는 데 있어 뛰어난 성능을 보입니다.

- **Performance Highlights**: 실증 연구 결과, EKLF 모델은 기존의 최신 모델들보다 예측 정확도와 계산 효율성에서 뛰어난 성과를 보였습니다. 제안된 EKLF 모델은 제어 모델을 병합하여 DWDG의 정확한 표현이 가능함을 보여주었습니다.



### Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs (https://arxiv.org/abs/2407.21358)
Comments:
          Accepted for publication at the ACL 2024 Conference

- **What's New**: 이 연구는 지식 그래프(KGs)를 통해 대형 언어 모델(LLMs)의 외부 지식을 강화하는 방법을 소개합니다. 특히, Tree-of-Traversals라는 새로운 제로샷(reasoning) 알고리즘을 도입하여, 여러 KGs와의 통합을 제공합니다. 이 알고리즘은 LLM이 KGs와 상호작용할 수 있는 액션을 제공하여 질문 답변과 KG 질문 답변 작업의 성능을 크게 향상시킵니다.

- **Technical Details**: Tree-of-Traversals 알고리즘은 로컬 KG 서브그래프를 확장하는 방식으로 작동합니다. 처음에는 원래 질문에 포함된 엔티티로 초기화된 로컬 KG 서브그래프를 가지게 되며, 나무 탐색 알고리즘을 사용해 KG 상호작용을 통해 관련 지식을 얻습니다. 이 알고리즘은 아래와 같은 주요 컴포넌트로 구성됩니다: (1) 하나 이상의 KG와 상호작용하기 위한 지식 그래프 인터페이스, (2) 액션 상태 머신(ASM), (3) 나무 탐색 알고리즘.

- **Performance Highlights**: 2WikiMultiHop과 QALD-10 두 가지 질문 답변 작업에서 Tree-of-Traversals의 성능을 평가한 결과, 성능이 크게 향상되었습니다. 또한 새로운 데이터셋을 개발하여 일반 및 도메인 특정 KG의 결합 추론을 테스트하고 평가했습니다. 아마존 Bedrock에서 호스팅된 다양한 크기의 세 가지 모델에 대한 상세한 실험 및 제거 연구도 수행했습니다.



### Dual-Constrained Dynamical Neural ODEs for Ambiguity-aware Continuous Emotion Prediction (https://arxiv.org/abs/2407.21344)
Comments:
          This paper has been accepted at INTERSPEECh 2024

- **What's New**: 최근 몇 년 동안 감정 모호성(ambiguity)을 모델링하는 연구가 많이 이루어졌으며, 감정을 분포(distributions)로 표현하여 모호성을 포착하는 데 많은 발전이 있었습니다. 그러나 감정 분포의 시간적 의존성을 고려하는 연구는 상대적으로 적었습니다. 본 논문은 제약된 동적 신경 보통 미분 방정식(constrained dynamical neural ordinary differential equations, CD-NODE)을 활용하여 감정의 시간적인 변화를 모델링하는 새로운 접근 방식을 제안했습니다.

- **Technical Details**: 본 연구에서는 감정 분포의 시간적 역학을 다루기 위해 감정 분포의 매개변수를 추정하는 ODEs를 사용하고, 추가적인 제약을 통해 시스템 출력의 범위를 제한하여 예측된 분포의 유효성을 보장했습니다. 제안된 CD-NODEγ 시스템은 감정 상태를 시간에 따라 변화하는 Beta 분포로 예측하며, 연속적인 감정 분포의 매끄러움과 범위를 제어하는 두 가지 제약을 통합했습니다.

- **Performance Highlights**: 제안된 시스템은 공공 데이터셋인 RECOLA 데이터셋에서 평가되었으며, 다양한 평가 지표에 걸쳐 매우 유망한 성능을 보였습니다. 이는 감정 예측 시스템에서 시간적 의존성을 통합하는 것이 중요한 발전임을 시사합니다.



### Image-Based Deep Reinforcement Learning with Intrinsically Motivated Stimuli: On the Execution of Complex Robotic Tasks (https://arxiv.org/abs/2407.21338)
- **What's New**: 새로운 연구에서는 내재적 동기 부여 이론(intrinsic motivation theory)에서 영감을 받아 희소한 보상(sparse reward)이 주어지는 복잡한 환경 탐색을 개선하기 위해 참신함(novelty)과 놀라움(surprise)을 활용하는 'NaSA-TD3'라는 새로운 강화 학습(RL) 알고리즘을 도입했습니다. 이 방법은 픽셀 기반으로 학습할 수 있으며, 복잡한 로봇 제어 작업을 효율적으로 수행할 수 있습니다.

- **Technical Details**: NaSA-TD3는 TD3 프레임워크를 확장하여 이미지 기반의 actor-critic 방법으로 변경했습니다. 내재적 동기 부여에서 영감을 받아 참신함과 놀라운 자극을 보상으로 활용했으며, 오토인코더(autoencoder) 네트워크를 사용하는 것이 특징입니다. 이 방식은 로봇의 다중 자유도(Degrees of Freedom, DoF)와 같은 복잡한 환경에서 효율적인 탐색 전략을 찾는 데 도움을 줍니다.

- **Performance Highlights**: NaSA-TD3는 최종 성능 측면에서 기존의 최첨단 RL 이미지 기반 방법보다 뛰어나며, 사전 학습된 모델이나 인간의 시연을 요구하지 않습니다. 이 알고리즘은 시뮬레이션 환경과 실제 환경 모두에서 복잡한 연속 제어 로봇 작업을 성공적으로 다룹니다.



### MetaOpenFOAM: an LLM-based multi-agent framework for CFD (https://arxiv.org/abs/2407.21320)
Comments:
          31 pages,10 figures, 11 tables

- **What's New**: CFD(Computational Fluid Dynamics, 전산 유체 역학) 시뮬레이션을 자동화하기 위한 새로운 프레임워크 MetaOpenFOAM이 소개되었습니다. 이 프레임워크는 자연어 입력만으로도 복잡한 CFD 시뮬레이션을 완료할 수 있습니다.

- **Technical Details**: MetaOpenFOAM은 MetaGPT의 assembly line paradigm을 활용하여 여러 에이전트에게 다양한 역할을 할당하고, 복잡한 CFD 작업을 관리 가능한 하위 작업으로 효율적으로 분할합니다. 또한, Langchain의 Retrieval-Augmented Generation(RAG) 기술을 통합하여 OpenFOAM 튜토리얼의 검색 가능한 데이터베이스를 제공함으로써 프레임워크의 능력을 향상시킵니다.

- **Performance Highlights**: 8개의 CFD 시뮬레이션 과제를 통해 테스트한 결과, MetaOpenFOAM은 각 테스트에서 평균 85%의 높은 합격률을 기록했으며, 각 테스트 케이스의 비용은 평균 $0.22에 불과했습니다. 이 시뮬레이션 과제는 압축성 및 비압축성 흐름, 2D 및 3D 흐름, 열 전달, 연소 등을 포함하며, 자연어 입력만으로도 CFD 시뮬레이션을 자동화할 수 있음을 보여줍니다.



### Multi-Level Querying using A Knowledge Pyramid (https://arxiv.org/abs/2407.21276)
- **What's New**: 본 논문은 기존 검색-증강 생성(RAG) 방법의 정밀도를 개선하기 위해 다층 지식 피라미드 접근 방식을 제안합니다. PolyRAG이라 명명된 이 방법은 온톨로지(Ontologies), 지식 그래프(Knowledge Graphs), 청크 기반 원시 텍스트의 세 가지 레이어로 구성된 지식 피라미드를 사용하며, 이를 통해 정밀도와 재현율 간의 균형을 도모합니다. 두 개의 도메인별 지식 검색 벤치마크(학술 및 금융 도메인)를 도입하여 성능을 평가했습니다.

- **Technical Details**: PolyRAG 접근 방식은 지식 피라미드의 최상위에서 시작하여 확신을 가질 때까지 하위 레이어로 진행하는 워터폴 모델을 따릅니다. 온톨로지, 지식 그래프, 청크 기반 텍스트의 세 가지 레이어로 나누어 크로스 레이어 증강(Cross-layer augmentation) 기법을 사용하여 지식의 포괄적 포함과 동적인 온톨로지 스키마 및 인스턴스 업데이트를 수행합니다. 또한, 지식 응축을 위해 크로스 레이어 필터링 기법을 활용합니다.

- **Performance Highlights**: PolyRAG는 전체적인 실험을 통해 기존의 19가지 SOTA 방법보다 우수한 성능을 입증했으며, 특히 GPT-4의 F1 점수를 0.1636에서 0.8109로 향상시켜 395%의 성능 향상을 보였습니다.



### FreqTSF: Time Series Forecasting Via Simulating Frequency Kramer-Kronig Relations (https://arxiv.org/abs/2407.21275)
- **What's New**: 이번 논문에서는 복잡한 시계열 데이터 예측을 위해 FreqTSF라는 새로운 모델을 제안하였습니다. Transformer 기반 모델의 'anti-order' 특성으로 인해 장기 예측 성능이 제한적이라는 문제를 해결하기 위해, 주파수 영역에서의 예측을 강조하며 FreqBlock 모듈을 도입했습니다. FreqBlock은 Frequency Transform Module을 통해 주파수 표현을 얻고, Kramer-Kronig relations (KKRs)을 재구성하여 주파수 교차 주의(Frequency Cross Attention)를 활용하여 실수부와 허수부 간의 관계를 강화합니다.

- **Technical Details**: FreqTSF 모델은 다수의 FreqBlock을 잇는 residual 구조를 채택하여 주파수 영역에서 KKRs를 시뮬레이션하고 성능 저하를 피합니다. FreqBlock의 두 주요 모듈인 Frequency Transform Module과 Frequency Cross Attention은 계산 복잡도와 메모리 복잡도를 각각 O(L^2)에서 O(L)로 효율적으로 줄입니다. Short-Time Fourier Transform (STFT)을 사용하여 각기 다른 주기성 신호를 주파수 영역으로 변환하고, 이를 통해 intra-variable 및 inter-variable 변동을 효과적으로 처리합니다.

- **Performance Highlights**: 4개의 벤치마크 데이터셋에서 시행된 실험 결과, FreqTSF는 state-of-the-art 모델에 비해 평균적으로 15%의 MSE 감소와 11%의 MAE 감소를 달성했습니다. 주파수 영역에서의 feature extraction을 통해 Transformer 모델의 성능을 극대화하고, 더 나아가 메모리와 시간 효율성을 크게 향상시켰습니다.



### Automated Quantification of Hyperreflective Foci in SD-OCT With Diabetic Retinopathy (https://arxiv.org/abs/2407.21272)
Comments:
          IEEE Journal of Biomedical and Health Informatics, Volume: 24, Issue: 4, pp. 1125 - 1136, 2020

- **What's New**: 이 논문은 망막 질환 진행과 관련이 있는 과반사 초점(HFs)의 자동 계량 알고리즘을 제안합니다. 이 알고리즘은 HFs를 분할하고 정량화하는 데 사용되며, 이는 현재 안과의사들이 HFs의 볼륨을 평가하는 데 도움을 줍니다.

- **Technical Details**: 제안된 알고리즘은 두 가지 병렬 프로세스로 구성됩니다: ROI(관심 영역) 생성과 HFs 추정입니다. ROI 생성을 위해 형태학적 복원을 사용하고, 데이터 분포와 클러스터링을 위해 히스토그램을 구성합니다. HFs 추정은 컴포넌트 트리에서 얻은 연결 영역으로부터 극단 지역을 추출하는 방식으로 이루어집니다. 마지막으로, 두 프로세스를 병합하여 분할된 HFs를 얻습니다. 이 알고리즘은 비증식성 당뇨망막병증(NPDR), 증식성 당뇨망막병증(PDR), 당뇨황반부종(DME)으로 진단된 40명의 환자로부터 얻은 40개의 3D SD-OCT 볼륨에서 테스트되었습니다.

- **Performance Highlights**: 제안된 알고리즘은 NPDR에 대해 평균 Dice Similarity Coefficient (DSC)와 상관 계수(상관계수)가 각각 69.70% 및 0.99로 나타났습니다. PDR의 경우 각각 70.31%, 0.99이며, DME의 경우 각각 71.30%, 0.99로 나타났습니다. 이 알고리즘은 안과의사에게 HFs의 부피, 크기, 위치에 대한 양질의 정보를 제공합니다.



### LoRaWAN Based Dynamic Noise Mapping with Machine Learning for Urban Noise Enforcemen (https://arxiv.org/abs/2407.21204)
- **What's New**: 본 논문은 저전력 광역 네트워크(LPWAN), 특히 LoRaWAN 기반의 사물인터넷(IoT) 인프라를 이용한 동적 소음 매핑(dymamic noise mapping) 접근법을 제안합니다. 이 방법은 일시적인 비교통 소음원을 동적으로 지도화하여 주민들의 소음 노출 문제를 해결하려는 목적을 가지고 있습니다.

- **Technical Details**: LoRaWAN은 저비용 도시 전역 소음 모니터링 시스템을 가능하게 하지만, 낮은 데이터 전송 속도가 문제로 작용할 수 있습니다. 이를 해결하기 위해 본 연구는 기계 학습(ML)을 이용하여 드문 데이터 기반에서 비교통 소음원의 이벤트 및 위치를 예측하는 방법을 제안합니다. 이 모델은 도시 환경의 건물로 인한 공간적 음향 변동성을 고려하여 동작합니다. 소음 데이터는 2바이트의 소리 압력 레벨(SPL) 읽기값을 주기적으로 전송하여 수집됩니다.

- **Performance Highlights**: 현장 테스트 결과 제안된 시스템이 비교통 소음원으로 인한 지도의 오류를 최대 51%까지 줄일 수 있음을 보여줍니다. 또한, 상당한 데이터 패킷 손실에도 유효성을 유지할 수 있음을 입증하였습니다.



### Rolling in the deep of cognitive and AI biases (https://arxiv.org/abs/2407.21202)
Comments:
          14 pages, 1 figure

- **What's New**: 현대 사회에서, 헬스케어, 금융 서비스, 법 집행 등 여러 민감한 영역에서 AI(인공지능)가 중요한 결정을 내리는 데 인간과 함께하거나 단독으로 사용됩니다. 그러나, AI 시스템이 공정하도록 설계되었음에도 불구하고, 여전히 일부 개인과 그룹에게 불합리하거나 차별적인 결과를 제공한다는 비판이 존재합니다. 이 논문은 기존의 머신러닝 파이프라인이 아닌, 인간의 인지 편향(cognitive bias)이 AI 공정성(fairness)에 미치는 영향을 중심으로 새로운 접근법을 제시합니다.

- **Technical Details**: 기존의 연구들은 AI 공정성을 데이터 특징 및 통계적 관점에서 다루고 있습니다. 그러나, 이 논문은 인간의 인지과학에서 정의된 휴리스틱(heuristics)을 바탕으로 AI의 편향을 이해하고자 합니다. 논문은 인간의 행동이 AI의 전반적 생애 주기(lifecycle)에 어떤 영향을 미치는지를 분석하며, 새로운 맵핑 방법을 도입해 인간 휴리스틱과 AI 편향 간의 관계를 설명하고 있습니다.

- **Performance Highlights**: 이 접근법을 통해, 논문은 인간 중심적 케이스 스터디를 강화함으로써, 기존 연구들이 간과한 편향의 원인과 결과를 드러낼 수 있을 것이라고 기대합니다. 또한, 이 새로운 이론적 프레임워크는 결국, 인간과 AI 사이의 통합과 협력을 통해 더 공정한 AI 시스템을 설계하는 데 기여할 것입니다.



### Deduction Game Framework and Information Set Entropy Search (https://arxiv.org/abs/2407.21178)
Comments:
          IEEE Conference on Games (IEEE CoG)

- **What's New**: 본 논문에서는 단일 플레이어 추론 게임을 효과적으로 해결하기 위한 새로운 'Information Set Entropy Search'(ISES) 알고리즘을 소개합니다. 이 알고리즘은 샘플링 기법을 통해 제한된 계산 자원과 시간 내에서 에이전트가 최적의 결정을 내릴 수 있게 합니다. 실험 결과는 ISES 알고리즘이 기존의 Single Observer Information Set Monte Carlo Tree Search (SO-ISMCTS) 알고리즘보다 뛰어난 성능을 보임을 입증했습니다.

- **Technical Details**: 단일 플레이어 추론 게임은 게임 시작 시 비밀 코드를 감추고, 플레이어는 일련의 질문(행동)을 통해 비밀을 찾아내야 합니다. 논문에서는 정보 집합(information set)의 엔트로피를 사용해 게임 상태의 불확실성을 평가합니다. 새로운 ISES 알고리즘은 정보 집합의 평균 정보 이득을 최대화하는 방향으로 게임 상태를 탐색합니다. 이는 Shannon의 엔트로피 공식을 기반으로 계산됩니다.

- **Performance Highlights**: 8가지 실험 게임에서 ISES 알고리즘은 제한된 결정 시간 내에서 SO-ISMCTS 알고리즘보다 더 우수한 성능을 보였습니다. ISES 알고리즘은 게임 설계에 대한 통찰력을 제공하며, 엔트로피 변화로 인해 설명 가능한 의사결정을 가능케 합니다.



### Extending choice assessments to choice functions: An algorithm for computing the natural extension (https://arxiv.org/abs/2407.21164)
Comments:
          40 pages, 8 figures, pre-print for International Journal of Approximate Reasoning

- **What's New**: 이 논문은 선택 함수 (choice functions) 프레임워크를 사용하여 기존 선택으로부터 새로운 선택을 유추하는 방법을 연구합니다. 특히 주어진 선택 평가 (choice assessment)를 일관된 선택 함수로 확장하는 자연스러운(가장 보수적인) 확장을 정의하고, 이를 새로운 선택을 하는 데 사용합니다.

- **Technical Details**: 주요 기술적인 내용으로는 자연 확장을 계산하기 위한 실용적인 알고리즘과 확장성을 개선하는 다양한 방법을 제시합니다. 확장 계산을 위한 알고리즘은 선택 평가 유형에 따라 테스트되었습니다.

- **Performance Highlights**: 실제로 제안된 알고리즘은 다양한 선택 평가 유형에 대해 테스트되었으며, 이 과정에서 확장성을 개선하기 위한 여러 방법이 구현되었습니다. 이를 통해 제공된 알고리즘이 다양한 맥락에서 효율적으로 작동함을 확인할 수 있었습니다.



### Palu: Compressing KV-Cache with Low-Rank Projection (https://arxiv.org/abs/2407.21118)
- **What's New**: 이번 논문에서는 새로운 KV-Cache 압축 프레임워크인 Palu를 소개합니다. Palu는 저차원(low-rank) 투영을 이용하여 대형 언어 모델(LLM)의 메모리 최적화를 달성합니다. 기존의 KV-Cache 압축 방식과는 달리 Palu는 숨겨진 차원에서 발생하는 여유 공간을 효과적으로 활용합니다.

- **Technical Details**: Palu는 낮은 순위로 분해된 행렬을 캐싱하고, 실시간으로 이를 재구성하여 메모리 사용을 줄입니다. 이를 위해 중급(low-rank) 분해 기법, 효율적인 순위 검색 알고리즘 및 GPU 커널 최적화 등을 포함하고 있습니다. 또한, Palu는 저차원 인식 양자화 알고리즘을 통합하여 양자화 정확도를 증가시킵니다.

- **Performance Highlights**: 실험 결과, Palu는 KV-Cache를 91.25% 이상 압축하면서도 최신 양자화 방법보다 낮은 퍼플렉시티를 유지합니다. 또한, 50% 압축률로는 주목할 만한 end-to-end 속도 향상(1.61배)을 보여주어 LLM의 메모리 사용량을 줄이고 속도를 높이는 데 효율적임을 입증했습니다.



### Apple Intelligence Foundation Language Models (https://arxiv.org/abs/2407.21075)
- **What's New**: 애플이 다양한 Apple Intelligence 기능을 지원하기 위해 개발한 새로운 기초 언어 모델(foundation language models)을 발표했습니다. 이 모델들 중에는 약 30억 매개변수를 가진 모바일 기기용 모델(AF-on-device)과 프라이빗 클라우드 컴퓨팅을 위한 대형 서버 기반 모델(AF-server)이 포함됩니다. 이 모델들은 다양한 작업을 효율적이고 정확하게 수행하는 데 중점을 두고 있습니다.

- **Technical Details**: AFM 기초 모델은 Transformer 아키텍처를 기반으로 한 dense decoder-only 모델로 설계되었습니다. 주요 설계 선택사항들은 다음과 같습니다: 입력/출력 임베딩 매트릭스를 공유하여 메모리 사용량을 줄이고, Pre-Normalization과 RMSNorm을 사용하여 학습 안정성을 개선했습니다. 그룹화된 쿼리 어텐션(GQA)과 SwiGLU 활성화 함수를 사용하여 효율성을 높였으며, 긴 문맥 지원을 위해 RoPE positional embeddings를 사용했습니다.

- **Performance Highlights**: 모델의 성능을 높이기 위해 데이터 품질과 효율성에 집중했습니다. 데이터는 출판사로부터 라이선스 받은 데이터, 공개적으로 제공되는 데이터셋, 그리고 Applebot을 통해 수집된 공개 정보들로 구성되어 있습니다. 또한, 사용자 프라이버시 보호를 위해 많은 노력을 기울였으며, 안전하지 않거나 개인 식별 정보가 포함된 자료들을 철저히 걸러냈습니다.



### Beyond Metrics: A Critical Analysis of the Variability in Large Language Model Evaluation Frameworks (https://arxiv.org/abs/2407.21072)
Comments:
          15 pages, 3 figures

- **What's New**: 이 논문은 대형 언어 모델(LLMs)의 평가 방법론에 대한 심층 분석을 제공합니다. 최신 NLP 기술 발전에 따라 다양한 평가 프레임워크와 벤치마크 테스트가 등장했습니다. 이 논문은 이러한 평가 방법론들의 장점과 한계, 그리고 NLP 발전에 미치는 영향을 탐구합니다.

- **Technical Details**: LLMs의 성능 평가에는 여러 가지 언어 과제, 모델 아키텍처, 벤치마킹 방법론 등을 신중하게 고려해야 합니다. 기존의 전통적인 메트릭(metric)은 LLM의 언어 이해력, 유창성, 문맥 일관성 등을 충분히 포착하지 못하기 때문에 더욱 정교한 평가가 요구됩니다.

- **Performance Highlights**: 특히, 여러 오픈 소스 언어 모델들(GPT, Llama, Falcon 등)을 사용하여 다중 선택 질문(multiple-choice question) 데이터 세트에서의 성능을 평가하였습니다. 이를 통해 모델의 정확도 메트릭(accuracy metrics)의 계산 방법론을 자세히 분석하였고, 이것이 모델의 성능과 평가 결과의 해석에 미치는 영향을 연구했습니다.



### Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned (https://arxiv.org/abs/2407.21040)
- **What's New**: NL2SQL 분야는 자연어 명령을 실행 가능한 SQL 스크립트로 변환하는 데 큰 진전을 이루었지만, 데이터 쿼리, 분석, 시각화 및 보고를 포함한 보다 폭넓은 데이터 과학 파이프라인의 완전한 자동화는 여전히 복잡한 과제입니다. 본 연구에서는 이러한 데이터 과학 파이프라인을 자동화하는 SageCopilot 시스템을 도입합니다. SageCopilot은 Large Language Models (LLMs), Autonomous Agents (AutoAgents), 그리고 Language User Interfaces (LUIs) 를 통합하여 작동합니다.

- **Technical Details**: SageCopilot은 두 단계 설계를 채택하고 있습니다. 첫 번째 단계는 온라인 컴포넌트로, 사용자 입력을 In-Context Learning (ICL)을 통해 실행 가능한 스크립트로 정제하고, 이러한 스크립트를 실행하여 결과 보고 및 시각화를 수행합니다. 두 번째 단계는 오프라인 준비 단계로, 온라인 단계에서 ICL이 요청한 데모를 준비합니다. Chain-of-Thought 및 prompt-tuning과 같은 최신 전략들이 SageCopilot의 성능 향상을 위해 사용되었습니다.

- **Performance Highlights**: 엄격한 테스트 및 프롬프트 기반 솔루션과의 비교 분석을 통해, SageCopilot이 스크립트 생성 및 실행, 결과 시각화 제공에서 뛰어난 종단 간 성능을 달성했음을 입증했습니다. 실제 데이터 세트를 통해 뒷받침된 심층 분석 연구들에서 SageCopilot의 다양한 컴포넌트와 전략 각각이 데이터 과학의 종단 간 정확성에 기여하는 바를 강조했습니다.



### Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey (https://arxiv.org/abs/2407.21794)
Comments:
          survey paper. We welcome questions, issues, and paper requests via this https URL

- **What's New**: Vision Language Models (VLMs)와 같은 새로운 패러다임이 OOD 탐지 및 기타 관련 문제들(이상 탐지, 신기성 탐지, 개방형 세트 인식, 이상치 탐지)의 경계를 모호하게 만드는 현상이 논의되고 있습니다. 이 논문은 이러한 변화를 반영하여 해당 문제들을 통합적으로 이해하기 위한 'Generalized OOD Detection v2' 프레임워크를 제안합니다.

- **Technical Details**: 기존의 OOD 탐지 프레임워크를 확장하여 OD, AD, ND, OSR 및 OOD 탐지 문제의 진화를 요약했습니다. 새로운 프레임워크는 다음 여섯 가지 기준을 기반으로 합니다: 분포 이동 탐지, In-Distribution(ID) 데이터 유형, ID 분류의 필요성, 전이 학습 vs 접합적 학습. 이 프레임워크는 각 문제의 정의와 문제 설정, 벤치마크와의 중요한 변화를 강조합니다.

- **Performance Highlights**: VLMs 시대에서 AD와 OOD 탐지가 가장 큰 도전 과제로 부각되었습니다. 특히 CLIP 기반의 OOD 탐지와 AD 방법론을 조사하며, LVLMs(GPT-4V와 같은 대규모 비전 언어 모델) 시대의 초기 발전 사항을 소개합니다.



### Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress? (https://arxiv.org/abs/2407.21792)
- **What's New**: 이 논문에서는 AI 안전성 연구 분야의 모호함과 일관성 없는 측정치로 인해 발생하는 문제들을 해결하기 위해 포괄적인 메타 분석을 수행하였습니다. 이를 통해 AI 안전성 벤치마크(benchmarks)와 일반적인 능력(general capabilities)의 상관관계를 실증적으로 분석하였으며, 기존 AI 안전성 연구 방향에 대한 조사를 제공하였습니다.

- **Technical Details**: 수십 개 모델에 대해 AI 안전성 벤치마크가 일반적인 모델 능력과 높은 상관관계를 가진다는 사실을 발견했습니다. 이는 능력 향상이 안전성 진보로 잘못 표시될 수 있는 '안전세척(safetywashing)' 가능성을 높입니다. 이를 해결하기 위해, 더욱 의미 있는 안전성 지표를 개발하는 경험적 기초(empirical foundation)를 제안하고, 기계 학습 연구(context)에서 AI 안전성을 일반적인 능력 발전과는 분명히 구분된 연구 목표로 정의하였습니다.

- **Performance Highlights**: 많은 AI 안전성 벤치마크가 일반적인 능력과 강한 상관관계를 보였으며, 이를 통해 더욱 엄격한 안전성 평가 과학을 발전시키고, 측정 가능한 진보로 가는 길을 명확히 하고자 합니다.



### Vision-Language Model Based Handwriting Verification (https://arxiv.org/abs/2407.21788)
Comments:
          4 Pages, 1 Figure, 1 Table, Accepted as Short paper at Irish Machine Vision and Image Processing (IMVIP) Conference

- **What's New**: 문서 포렌식에서 필적 검증(Handwriting Verification)은 중요한 역할을 합니다. 그러나 현재의 딥러닝 기반 접근법은 설명 가능성이 부족하고 대규모 학습 데이터와 수작업 특징에 의존한다는 점에서 포렌식 문서 검사관들에게 신뢰를 받지 못하고 있습니다. 이번 연구는 OpenAI의 GPT-4o와 Google의 PaliGemma와 같은 Vision Language Models(VLMs)를 사용해 이러한 문제를 해결하고자 합니다. 이 모델들은 Visual Question Answering과 0-shot Chain-of-Thought(COT) 추론을 활용하여 명확하고 인간이 이해할 수 있는 설명을 제공합니다.

- **Technical Details**: ['Methods: 본 연구에서는 OpenAI의 GPT-4o VLM을 선택하여 시각 질문 응답(Visual Question Answering) 기능을 사용했습니다. 0-shot Chain-of-Thought(COT) 추론을 통해 인간이 이해가능한 설명을 먼저 생성한 후, 필적 검증을 수행했습니다. 추가적으로, PaliGemma VLM을 사용해 0-shot 프롬프트 엔지니어링 및 파라미터 효율 최적화 슈퍼바이즈드 피인튜닝(PEFT)을 비교했습니다.', "Data: 실험은 CEDAR Letter와 CEDAR AND 데이터셋에서 수행되었습니다. CEDAR Letter 데이터는 1568명의 필자들이 세 번 작성한 편지 원고를 포함하고 있으며, CEDAR AND는 이 데이터의 부분집합으로, 편지 원고에서 추출한 소문자 'and' 단어만 포함하고 있습니다."]

- **Performance Highlights**: ['결과: 실험 결과 CNN 기반의 ResNet-18 아키텍처는 GPT-4o(정확도: 70%)와 슈퍼바이즈드 피인튜닝된 PaliGemma(정확도: 71%)를 능가하였으며, CEDAR AND 데이터셋에서 84%의 정확도를 달성했습니다.', 'CEDAR AND 기준으로 주요 모델들의 성능: GSC(정확도: 78%), ResNet-18(정확도: 84%), ViT(정확도: 79%), GPT-4o 0-shot COT(정확도: 70%), PaliGemma 0-shot COT(정확도: 65%) 및 PaliGemma 슈퍼바이즈드 피인튜닝(정확도: 71%)']



### Large Language Monkeys: Scaling Inference Compute with Repeated Sampling (https://arxiv.org/abs/2407.21787)
- **What's New**: 이 논문에서는 언어 모델(Large Language Models, LLMs)의 추론(compute for inference)을 여러 시도(repeated sampling)로 확장하여 성능을 향상시키는 방법을 탐구합니다. 이는 기존에 한 번의 시도에서 머물렀던 문제 해결 프로세스를 여러 번 시도함으로써 더 높은 성능을 얻는 접근 방식입니다. 특히, 자동화된 검증이 가능한 도메인(예: 코딩, 형식적 증명)에서 성능이 크게 향상되었습니다.

- **Technical Details**: 여기서 주목할 만한 것은 반복 샘플링(repeated sampling)이 범위(coverage)와 정확도(precision)에 미치는 영향입니다. 범위는 생성된 샘플 중 어느 하나라도 문제를 해결할 수 있는 비율을 의미하며, 정확도는 여러 샘플 중에서 올바른 답을 선택할 수 있는 능력을 의미합니다. 연구는 다양한 모델과 샘플 수에 걸쳐 범위가 로그-선형(log-linear) 관계를 따르며, 기하급수적으로 증가할 수 있음을 보여줍니다. 이를 통해 추론 계산(inference compute)을 효과적으로 확장하는 방법을 제시합니다.

- **Performance Highlights**: 여러 작업과 모델을 대상으로 한 실험 결과, DeepSeek-V2-Coder-Instruct 모델을 250회 샘플링한 경우, SWE-bench Lite 데이터셋에서 문제 해결률이 15.9%에서 56%로 증가했습니다. 이는 단일 시도로 43%를 달성한 최신 상태(SOTA)보다 높은 수치입니다. 또한, Llama-3 모델을 사용한 수학 단어 문제(Math Word Problems) 해결에서는 10,000회 샘플링한 경우 범위가 95% 이상으로 증가했지만, 다수결 투표(majority voting)나 보상 모델(reward models)과 같은 일반적인 방법들은 수백 개 샘플 이상에서 성능이 정체되는 한계를 보였습니다.



### HGOE: Hybrid External and Internal Graph Outlier Exposure for Graph Out-of-Distribution Detection (https://arxiv.org/abs/2407.21742)
Comments:
          Proceedings of the 32nd ACM International Conference on Multimedia

- **What's New**: 이번 논문에서는 그래프 데이터를 위한 Out-of-Distribution (OOD) 탐지 문제를 해결하기 위해 새로운 프레임워크인 Hybrid External and Internal Graph Outlier Exposure (HGOE)를 제안합니다. 이 프레임워크는 다양한 도메인에서 실제 외부 그래프 데이터를 활용하고, ID 서브그룹 내에서 내부 이상치를 합성하여 그래프 OOD 탐지 성능을 향상시킵니다. 또한, 경계 인식 OE 손실 함수를 개발하여 고품질 OOD 샘플의 활용도를 극대화하고 저품질 샘플의 영향을 최소화합니다.

- **Technical Details**: HGOE 프레임워크는 모델에 독립적이며, 외부와 내부 이상치를 동시에 활용하는 하이브리드 접근 방식을 따릅니다. 외부 이상치는 공공 데이터베이스에서 쉽게 수집될 수 있으며, 내부 그래프 이상치는 Graphon 기반 ID-mixup 전략을 사용하여 서브그룹 간의 OOD 영역을 시뮬레이션하고 OOD 샘플을 합성합니다. 이러한 이상치들로부터 학습하기 위해, 경계 인식 OE 손실 함수를 제안하여 진짜 이상치로부터 적응적으로 학습하고 의도하지 않은 편향을 방지합니다.

- **Performance Highlights**: 제안된 HGOE 프레임워크는 8개의 실제 데이터셋에서 기존의 그래프 OOD 탐지 모델들의 성능을 크게 향상시켰습니다. 이는 외부와 내부 이상치를 동시에 활용하여 데이터의 다양성을 증대시키고, 경계 인식 손실 함수를 통해 OOD 샘플의 품질을 최대한 활용했기 때문입니다.



### Contrastive Factor Analysis (https://arxiv.org/abs/2407.21740)
- **What's New**: 이 논문은 대조 학습(contrastive learning, CL)과 행렬 분해(matrix factorization, MF), 요인 분석(factor analysis, FA)의 수학적 동등성을 활용해 새로운 대조 요인 분석(Contrastive Factor Analysis, CFA) 프레임워크를 제안합니다. 특히, FA의 비음수 버전(non-negative extension)을 통해 해석 가능성을 높이고 복잡한 종속성을 모델링하는 능력을 증진합니다.

- **Technical Details**: CFA는 대조 학습 방법을 따라 관계 행렬(relation matrix)을 모델링하여 Gaussian 잠재 변수로 분해합니다. 또한, 비음수의 목표 행렬을 고려해 감마 잠재 변수로 분해하는 대조 비음수 요인 분석(contrastive non-negative FA)을 도입했습니다. 이를 위해 Gaussian 및 Weibull 변분 추론 네트워크를 개발하여 잠재 변수의 사후 분포를 근사합니다.

- **Performance Highlights**: 제안된 CFA와 비음수 확장은 더욱 표현력(expression), 외부 데이터 발생(out-of-distribution)에 대한 견고성, 해석 가능성 및 불확실성 평가 측면에서 뛰어난 성능을 보여줍니다. 실험 결과는 이러한 다양한 핵심 속성들에 대한 방법론의 효율성을 입증합니다.



### A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation (https://arxiv.org/abs/2407.21739)
- **What's New**: 이번 연구에서는 의료 영상 분석을 위한 효율적인 연합 학습(Federated Learning) 방법을 제안합니다. 특히, Segment Anything Model (SAM)을 3D 의료 이미지 분할을 위해 적응시키는 과정에서 통신 비용 문제를 해결하고자 합니다. 새로운 접근 방식인 Parameter-Efficient Fine-Tuning (PEFT)와 Low-Rank Adapters (LoRA)를 연합 학습에 적용하여 통신 효율성을 극대화하였습니다.

- **Technical Details**: SAM 모델의 주요 구성 요소인 이미지 인코더(Image Encoder), 프롬프트 인코더(Prompt Encoder), 그리고 마스크 디코더(Mask Decoder)를 활용합니다. SAM 모델의 디코더에서 특정 계층만을 선택적으로 미세 조정하여 통신 비용이 적은 상황에서도 우수한 성능을 유지하는 방법론을 탐구했습니다. 이로 인해, 전체 모델을 미세 조정하는 것보다 통신 비용을 크게 줄일 수 있었습니다 (~48배 감소).

- **Performance Highlights**: 제안된 방법은 Fed-KiTS 데이터셋에서 완전 미세 조정에 비해 통신 비용을 약 48배 줄였으며, 성능은 3D 분할 작업에서 약 6%의 Dice 점수가 향상되었습니다. 또한, SAMed 접근 방식과 비슷한 성과를 내면서도 통신 비용을 약 2.8배 절감하고 미세 조정해야 할 파라미터 수를 줄였습니다.



### Leveraging Self-Supervised Learning for Fetal Cardiac Planes Classification using Ultrasound Scan Videos (https://arxiv.org/abs/2407.21738)
Comments:
          Simplifying Medical Ultrasound: 4th International Workshop, ASMUS 2023, Held in Conjunction with MICCAI 2023, Vancouver, BC, Canada, October 8, 2023, Proceedings

- **What's New**: 본 연구에서는 초음파(US) 비디오 데이터를 활용하여 별도의 라벨링 없이 연속 학습 방법(Self-supervised learning, 이하 SSL)을 적용하여 태아 심장 표준 평면(SFCP) 분류 성능을 향상시키고자 합니다. 특히, 제한된 라벨 데이터만을 사용하는 상황에서도 성능이 개선되는 것을 목표로 합니다. BarlowTwins 접근법이 가장 일관된 성능을 보여주었으며, ImageNet 초기화와 비교해 F1-스코어가 12% 향상되었습니다.

- **Technical Details**: 연구에서는 7가지 SSL 접근법을 비교했습니다. 재구성(Reconstruction), 대조 손실(Contrastive loss), 증류(Distillation), 정보 이론(Information theory) 기반 방법들이 포함되었습니다. 특히, 500개 이상의 다운스트림(downstream) 실험을 통해 다양한 설정에서의 성능을 평가하였고, 데이터셋의 변동성(variance)이 크기(size)보다 더 중요한 요소임을 확인했습니다. ResNet-50을 백본 네트워크로 사용하였고, 각 SSL 방법론에 맞는 적절한 네트워크 모듈을 추가로 사용했습니다.

- **Performance Highlights**: SSL 학습에서 데이터의 변동성이 크면 모델이 보다 일반화된 표현을 학습할 수 있어 다운스트림 태스크의 성능이 향상됩니다. 특히 BarlowTwins 방법이 다양한 설정과 데이터 변동성에도 견고한 성능을 보여주었습니다. 1%의 라벨 데이터를 사용한 전체 미세 조정(fine-tuning)에서 ImageNet 초기화를 사용한 경우보다 F1-스코어가 12% 상승하였으며, 다른 SSL 초기화 방법과 비교해 최소 4% 이상 성능이 개선되었습니다.



### Open-Vocabulary Audio-Visual Semantic Segmentation (https://arxiv.org/abs/2407.21721)
Comments:
          Accepted by ACM MM 2024 (Oral)

- **What's New**: 이번 연구에서는 음향 신호를 통해 비디오에서 소리를 내는 객체를 분할하고 분류하는 새로운 작업인 오픈-어휘 오디오-비주얼 의미 분할(open-vocabulary audio-visual semantic segmentation)을 제안하였습니다. 이는 기존의 오디오-비주얼 의미 분할(audio-visual semantic segmentation, AVSS)보다 더 도전적인 작업으로, 기존 학습 데이터에서 본적 없거나 들은 적 없는 새로운 카테고리도 인식할 수 있어야 합니다.

- **Technical Details**: OV-AVSS라는 새로운 프레임워크를 제안했으며, 이는 두 가지 주요 모듈로 구성됩니다: 1) 유니버설 소리 출처(localization) 모듈은 오디오-비주얼 융합을 수행하여 잠재적 소리 내는 객체를 찾습니다. 2) 오픈-어휘 분류 모듈은 대규모로 사전 학습된 비전-언어 모델(Vision-Language Models)의 사전 지식을 활용하여 카테고리를 예측합니다. 제안된 모델은 AVSBench-OV 벤치마크 데이터셋을 기반으로 검증되었습니다.

- **Performance Highlights**: 실험 결과 OV-AVSS는 기존 모델 대비 강력한 분할 성능과 제로-샷(zero-shot) 일반화 능력을 보였습니다. AVSBench-OV 데이터셋에서 기본 카테고리(base categories)에 대해 55.43% mIoU, 새로운 카테고리(novel categories)에 대해 29.14% mIoU를 기록하였으며, 이는 현 상태-최고(state-of-the-art) 제로-샷 방법보다 41.88%/20.61%, 오픈-어휘 방법보다 10.2%/11.6% 개선된 성능을 보였습니다.



### Social Learning through Interactions with Other Agents: A Survey (https://arxiv.org/abs/2407.21713)
Comments:
          To be published in IJCAI 2024, available on this http URL

- **What's New**: 이 논문은 인간 지능의 발달에 중요한 역할을 하는 사회적 학습(social learning)이 머신러닝에 어떻게 반영되었는지를 조사하고 있습니다. 특히, 화신된 에이전트(embodied agents)가 이러한 기술을 어떻게 활용할 수 있는지에 초점을 맞추고 있습니다. 또한, 자연어 처리(NLP)의 최근 발전이 새로운 사회적 학습 형태를 가능하게 하는 방법에 대해 논의합니다.

- **Technical Details**: 논문은 다양한 사회적 학습 기법들이 인간의 모방(behavioral cloning)과 다음 토큰 예측(next-token prediction)을 어떻게 반영하는지, 인간의 피드백으로부터 학습하는 방법이 인간 교육을 어떻게 반영하는지, 그리고 완전히 소통 가능한 에이전트가 서로 배우는 방법을 탐구합니다. Tomasello의 사회적 학습 이론에 따라 모방 학습(imitative learning), 지도 학습(instructive learning), 협업 학습(collaborative learning)으로 구분하여 검토하고 있습니다.

- **Performance Highlights**: 논문은 대규모 언어 모델(LLMs)을 사용한 초기 실험에서 화신된 에이전트가 제로샷(zero-shot) 성능을 발휘하는 등 놀라운 성과를 보여주었음을 언급합니다. 비전 언어 모델(Vision Language Models, VLMs)과 다른 멀티모달 모델들의 개발로 인해 인간의 시연 데이터를 활용하고 문화적 지식을 활용할 수 있는 에이전트가 만들어졌습니다. 이러한 모델들은 서로 소통할 수 있는 능력을 선천적으로 가지고 있으며, 협력적 그룹을 형성하는 데 강점을 보였습니다.



### Dynamic Object Queries for Transformer-based Incremental Object Detection (https://arxiv.org/abs/2407.21687)
- **What's New**: 새로운 객체 검출(Incremental Object Detection, IOD) 방법인 DyQ-DETR가 공개되었습니다. DyQ-DETR는 Transformer 구조를 기반으로 하여 객체 쿼리(object queries)를 동적으로 조정해, 모델의 표현 능력을 단계적으로 확장하면서도 오래된 지식과 새로운 지식의 균형을 유지하는 것이 특징입니다. 이를 통해 기존의 지식을 잃지 않으면서도 새로운 클래스를 배우는 능력을 향상시킵니다.

- **Technical Details**: DyQ-DETR는 'Dynamic object Query-based Detection Transformer'의 약어로, IOD 문제를 해결하기 위해 설계된 새로운 모델입니다. 이 모델은 CNN이 부착된 Transformer 인코더를 통해 이미지의 시각적 특징을 추출하고, 시간이 지남에 따라 새로운 클래스에 대응하는 학습 가능한 객체 쿼리를 기존 객체 쿼리와 결합하여 사용합니다. 이를 통해 새로운 클래스의 정보와 기존 클래스의 지식을 효율적으로 적응시키며, 상호 간섭을 줄이기 위해 분리된 이중 매칭을 도입합니다. 또한, 위험 균형 부분 보정을 통해 불완전한 주석을 효과적으로 처리하는 예시 재생(exemplar replay)을 제공합니다.

- **Performance Highlights**: 공개된 실험 결과에 따르면 DyQ-DETR는 기존 최첨단 방법들을 크게 능가합니다. 비-예시 시나리오에서 평균 4.3% AP(매칭 정도)를 향상시켰고, 예시 재생을 사용할 경우 평균 2.9% AP 향상을 기록했습니다. 이 모델은 제한된 파라미터 오버헤드로 인한 높은 성능을 자랑합니다.



### Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation (https://arxiv.org/abs/2407.21674)
- **What's New**: 이번 연구는 실제 데이터와 합성 데이터 사이의 통계적 특성을 깊이 조사하여, 합성 데이터가 모델의 성능에 끼치는 영향을 분석했습니다. 연구 결과, 합성 데이터와 실제 데이터 간의 상관관계가 강할 때, 모델이 표면적인 특징에 지나치게 의존하는 '단순함 편향 (simplicity bias)' 현상이 발생함을 발견했습니다. 이는 특히 의료 영상에서 두드러지며, 모델의 실전 배포 시 성능 저하를 초래할 수 있습니다.

- **Technical Details**: 본 논문에서는 합성 데이터의 통계적 특성이 모델의 학습에 미치는 영향을 체계적으로 실험했습니다. 특히, 디지털 이미지 분류(task)와 심장 초음파 영상의 이중대 및 사중대 뷰 분류 문제에서 이 현상을 확인했습니다. 이를 통해 모델이 실제와 합성 데이터를 구분하는데 사용하는 특징이 실제 작업과 관계없이 학습될 수 있다는 것을 증명했습니다.

- **Performance Highlights**: 연구에서는 모델이 합성 데이터의 특징을 비정상적으로 쉽게 사용할 수 있다는 사실을 밝혀냈습니다. 예를 들어, 숫자 분류 작업에서 모델은 숫자 자체라기보다는 데이터가 합성 데이터인지 아닌지를 구분하는 데 집중했습니다. 심장 초음파 영상에서도 마찬가지로, 모델은 이중대 및 사중대 뷰를 올바르게 구분하기보다, 데이터 출처(실제 vs. 합성)에 의존해 분류를 수행했습니다. 이러한 단순함 편향은 배포 시 성능 저하로 이어졌으며, 데이터의 출처와 타겟 간의 상관관계가 낮아지는 테스트 환경에서 특히 두드러졌습니다.



### Universal Approximation Theory: Foundations for Parallelism in Neural Networks (https://arxiv.org/abs/2407.21670)
- **What's New**: 최근 심층 학습 모델의 목층(layer) 수가 증가하면서 학습 및 추론 시간이 급격히 증가하는 문제가 대두되고 있습니다. 이를 해결하기 위해, 이 논문에서는 Universal Approximation Theorem(UAT)을 기반으로 한 병렬화 전략을 제안하고, Para-Former라는 병렬 네트워크를 설계하였습니다. Para-Former는 기존의 직렬 모델과 달리 목층 수가 증가해도 추론 시간이 늘어나지 않아, 다층 네트워크의 추론 속도를 크게 향상시킵니다.

- **Technical Details**: 이 논문은 Universal Approximation Theorem(UAT)을 근본 이론으로 삼고 병렬 네트워크 설계의 필요성을 강조하고 있습니다. 논문 저자들은 Transformer와 Residual 기반의 CNN이 UAT의 구체적 구현이라는 점을 근거로, 이러한 이론적 배경을 바탕으로 Para-Former라는 병렬 네트워크를 설계했습니다. Para-Former의 설계 과정에서 네트워크가 데이터를 기반으로 동적으로 함수를 근사화할 수 있는 능력을 갖추도록 설정하였습니다.

- **Performance Highlights**: Para-Former는 실험 결과, 목층 수가 증가해도 추론 시간이 늘어나지 않으며, 이는 다층 네트워크의 추론 속도를 크게 향상시킴을 확인했습니다. 또한, 다양한 데이터 셋에서의 효율성을 검증한 결과, Para-Former는 기존의 직렬 네트워크보다 월등한 성능을 보여주었습니다.



### An Explainable Vision Transformer with Transfer Learning Combined with Support Vector Machine Based Efficient Drought Stress Identification (https://arxiv.org/abs/2407.21666)
Comments:
          30 pages, 6 figures, 4 tables

- **What's New**: 이번 연구에서는 비전 트랜스포머(ViTs, Vision Transformers)의 우수한 점을 활용한 감자 작물의 가뭄 스트레스 탐지 모델을 제안했습니다. 이 모델은 공중 이미지 데이터를 사용하여 비침습적(non-invasive)으로 작물의 생리적 변화를 감지합니다. 기존의 Convolutional Neural Networks(CNNs)보다 긴 거리의 종속성과 복잡한 공간적 관계를 더 잘 포착할 수 있는 ViTs의 강점을 활용합니다.

- **Technical Details**: 감자 작물의 공중 이미지를 이용하여 두 가지 접근법을 적용했습니다. 첫 번째 접근법은 ViT와 Support Vector Machine(SVM)을 결합하여 ViT가 사진에서 섬세한 공간적 특징을 추출하고, SVM이 이를 통해 작물의 건강 상태를 분류합니다. 두 번째 접근법은 ViT 내에 전용 분류 레이어를 사용하여 가뭄 스트레스를 직접 탐지하는 것입니다. 또한 모델의 결정 과정을 설명하기 위해 주의 맵(attention maps)을 시각화하여 구체적인 공간적 특징을 강조했습니다.

- **Performance Highlights**: 제안된 방법은 가뭄 스트레스 식별에 있어 높은 정확성을 달성했으며, 다양한 미세한 식물 특징을 분석하는 데 있어 큰 도움이 되었습니다. 특히, ViT가 견고하고 해석 가능한 솔루션을 제공하여 농업인들이 작물 관리를 위한 정보에 입각한 결정을 내리는 데 중요한 역할을 합니다.



### Spatial Transformer Network YOLO Model for Agricultural Object Detection (https://arxiv.org/abs/2407.21652)
Comments:
          7 pages, 5 figures, submitted for review

- **What's New**: 이 논문에서는 YOLO 모델의 단점인 혼잡하거나 부분적으로 가려진 장면에서의 성능 문제와 작은 저대비 객체 감지 문제를 개선하기 위해 Spatial Transformer Networks (STNs)를 통합한 새로운 방법을 제안합니다. 새롭게 제안된 STN-YOLO 모델은 이미지의 중요한 영역에 집중하고 공간 불변성을 높여 객체 감지 성능을 향상시킵니다. 이 방법은 정성적, 정량적으로 객체 감지 성능을 개선합니다. 또한, 농업 객체 감지를 위한 벤치마크 데이터셋과 최신 식물 페노타이핑 온실 시설에서의 새로운 데이터셋을 제시합니다.

- **Technical Details**: STN-YOLO 모델은 STN 모듈을 통합하여 공간 변환에 대한 강인성을 향상시킵니다. 이 STN 모듈은 입력 이미지에 학습 가능한 Affine 변환을 적용하여 객체 감지 정확도를 높입니다. 제안된 방법은 다양한 공간 변환을 포함한 데이터셋에서 실험을 통해 검증되었으며, 특히 농업 분야의 객체 감지에 효과적입니다. 새로운 Plant Growth and Phenotyping (PGP) 데이터셋은 다중 스펙트럼 이미지, 다양한 조명 조건에서의 이미지, 정밀한 주석 및 다양한 크기와 형태의 식물 이미지를 포함하고 있습니다.

- **Performance Highlights**: 제안된 STN-YOLO 모델은 기존 YOLO 모델을 능가하는 성능을 보였습니다. 다양한 농업 벤치마크 데이터셋에서 실험한 결과, STN-YOLO는 객체 감지 정확도와 강인성 면에서 뛰어난 성능을 입증했습니다. 새로운 PGP 데이터셋은 식물 탐지 및 페노타이핑 연구를 발전시킬 수 있는 중요한 자원이 됩니다.



### Lyapunov weights to convey the meaning of time in physics-informed neural networks (https://arxiv.org/abs/2407.21642)
- **What's New**: 이 논문에서는 물리 정보를 포함한 신경망(Physics-Informed Neural Networks, PINN)에서 시간의 특수한 차원을 고려하여 자동으로 적응하는 가중치 스키마를 제안합니다. 논문은 Lyapunov 지표(Lyapunov Exponents)를 활용하여 혼돈 시스템(chaotic systems), 주기적 시스템(periodic systems), 안정적인 시스템(stable dynamics)에 대응하는 최적의 시간 가중치를 도입하는 방법을 이론적으로 설명합니다.

- **Technical Details**: PINNs는 복잡한 수학 방정식을 해결하기 위해 도입된 신경망 구조로, 주요 함수와 그 미분을 기반으로 한 방정식을 풀기 위해 사용됩니다. 기존 연구에서는 시간 샘플링 또는 가중치 조정에 대한 여러 접근 방식을 제안했으나 이들은 경험적인 방식에 의존했습니다. 본 연구에서는 Lyapunov 지표를 사용하여 시간이 지남에 따라 가중치를 조정하는 방식이 더욱 원칙적이며 효과적임을 이론적으로 증명하고, 특정 시점까지의 누적 오차의 지수 함수를 적용하는 방식으로 가중치를 계산하는 방법을 도입합니다.

- **Performance Highlights**: 제안된 방법은 기존 방법들과 달리 추가적인 하이퍼 파라미터를 조정할 필요가 없으며, 이론적 분석과 실험 결과 모두에서 혼돈적, 주기적, 또는 안정적인 동역학 체계에 대해 우수한 성능을 보였습니다. 이로 인해, PINNs의 성능을 시간 차원에서 향상시키는 데 있어 중요한 기여를 할 수 있을 것으로 기대됩니다.



### Between the AI and Me: Analysing Listeners' Perspectives on AI- and Human-Composed Progressive Metal Music (https://arxiv.org/abs/2407.21615)
Comments:
          Reviewed pre-print accepted for publication at ISMIR 2024

- **What's New**: 최근 AI가 창작 예술과 음악 전통에 큰 변화를 주고 있으며, 이는 인간과 AI 간의 상호작용에 대한 연구가 중요해졌습니다. 본 연구는 Progressive Metal 장르에서 AI-와 인간이 창작한 음악에 대한 참여자들의 의견을 조사합니다. AI 생성 예시는 ProgGP라는 Transformer 모델을 사용하여 생성되었으며, 이를 통해 AI와 인간 창작물의 차이를 비교합니다.

- **Technical Details**: 본 연구에서는 GuitarPro를 활용하여 Progressive Metal 음악을 생성했습니다. Transformer-XL 모델인 ProgGP는 DadaGP 데이터셋을 학습하고 Progressive Metal 코퍼스에 대해 파인튜닝되었습니다. 연구는 인간 창작물과 AI 생성물을 비교하고, 각각의 선택 방식(랜덤 vs 선택된 예시)에 따른 차이를 분석합니다. 이를 위해 청취자 피드백을 통해 선호도, 창의성, 일관성, 연주 가능성 등의 측면에서 평가했습니다.

- **Performance Highlights**: 총 32명의 Progressive Metal 팬들이 참여한 청취 및 반영 연구를 통해 AI가 생성한 Progressive Metal과 Rock 음악을 비교했습니다. AI 생성물은 청취자들에 의해 식별될 수 있었으며, 일부 AI 생성물은 인간 창작물과 유사한 평가를 받았습니다. 하지만 참여자들은 전반적으로 인간이 창작한 음악을 더 선호하는 경향을 보였습니다. 또한, AI 생성 음악이 특정 장르에 적합하게 튜닝될 수 있음을 확인했습니다.



### Enhancing Partially Spoofed Audio Localization with Boundary-aware Attention Mechanism (https://arxiv.org/abs/2407.21611)
- **What's New**: 이번 연구에서는 Boundary-aware Attention Mechanism (BAM)이라는 새로운 방법을 제안합니다. BAM은 Boundary Enhancement와 Boundary Frame-wise Attention이라는 두 개의 핵심 모듈로 구성되어 있습니다. 이 방법은 단일 모델 내에서 경계(boundary) 정보를 활용하여 부분적 스푸핑 오디오의 프레임 수준에서의 진위 여부를 결정합니다. PartialSpoof 데이터베이스를 사용한 실험 결과, 제안된 방법은 최고의 성능을 달성했습니다.

- **Technical Details**: BAM은 Wav2vec2 (W2V2) 또는 WavLM과 같은 사전 학습된 모델을 전처리 단계에서 사용하여 오디오 특징을 추출합니다. 그 후, Boundary Enhancement (BE) 모듈은 프레임 내(intra-frame) 및 프레임 간(inter-frame) 정보를 조합하여 경계 프레임을 탐지하고 경계 특징을 추출합니다. Boundary Frame-wise Attention (BFA) 모듈은 경계 예측 결과를 사용하여 프레임 간의 특징 상호작용을 조절하여 진짜 프레임과 가짜 프레임을 효과적으로 구분합니다. 이 과정은 경계 정보를 이용해 프레임 수준에서 신뢰할 수 있는 진위 결정을 내리는 데 기여합니다.

- **Performance Highlights**: 제안된 BAM 방법은 PartialSpoof 데이터베이스에서 이전의 방법들에 비해 최고의 위치 지정(localization) 성능을 보였습니다. 특히, 이 방법은 경계 정보를 단일 CM 시스템 내에서 처음으로 활용한 연구로, 프레임 수준에서 진위 여부를 결정하는 정확도를 크게 향상시켰습니다. 실험 결과, 기존의 방법들에 비해 우수한 성능을 입증하였습니다.



### Robust Simultaneous Multislice MRI Reconstruction Using Deep Generative Priors (https://arxiv.org/abs/2407.21600)
- **What's New**: 본 연구는 깊은 생성 모델 (deep generative models)을 활용한 Simultaneous multislice (SMS) MRI 재구성 방법을 제안합니다. Gaussian 노이즈에서 시작하여, 역확산 반복 (reverse diffusion iterations)을 통해 개별 슬라이스를 복구하면서 측정된 k-space 데이터 일관성(data consistency)을 유지합니다. 더불어, 저주파수 향상 (Low-Frequency Enhancement, LFE) 모듈을 통합하여 SMS-가속된 FSE 및 EPI 시퀀스에서 자율보정 신호(autocalibration signals)를 쉽게 통합할 수 없는 문제를 해결했습니다.

- **Technical Details**: 제안된 방법은 Denoising diffusion probabilistic models (DDPM)을 사용하여 MR 재구성 역문제를 푸는 방식입니다. DDPM을 단일 슬라이스 이미지로 훈련시킬 수 있도록 하여 특별한 조정 없이 SMS 작업에 적용 가능합니다. 저주파수 향상 모듈(LFE)은 자율보정 신호를 신뢰하기 어려운 상황에서 역확산 과정을 안정화 시킵니다. 또한, SMS MRI의 복잡성을 다루기 위해 읽기 결합(readout concatenation) 프레임워크를 활용하여 데이터를 재구성합니다.

- **Performance Highlights**: 제안된 방법은 다양한 데이터세트에서 기존 방법들보다 일관되게 더 나은 성능을 보였으며, 보지 못한 데이터셋에 대해서도 강력한 일반화 능력을 보여주었습니다. 이미지 SNR을 크게 개선하고, 잔여 에일리어징(residual aliasing) 아티팩트를 줄이며, 다양한 설정에서도 우수한 재구성 결과를 보였습니다. 코드 및 방법에 대한 세부 내용은 리뷰 완료 후 공개될 예정입니다.



### Measuring What Matters: Intrinsic Distance Preservation as a Robust Metric for Embedding Quality (https://arxiv.org/abs/2407.21590)
- **What's New**: 새로운 논문에서 'Intrinsic Distance Preservation Evaluation (IDPE)' 방법을 소개했습니다. 이는 본래 자료와 임베딩 공간에서 데이터 포인트 사이의 Mahalanobis 거리를 보존하는 방식으로 임베딩 품질을 평가하는 방법입니다. 이 방법은 다운스트림 작업에서의 성능에 의존하지 않아 임베딩 품질을 보다 정확하게 평가할 수 있습니다.

- **Technical Details**: IDPE는 Mahalanobis 거리를 사용하여 원본 데이터와 임베딩된 공간 사이의 본질적인 구조를 보존하는지를 평가합니다. 이 방법은 효율적인 유사성 검색 기법들을 활용하여 대규모 데이터셋에도 적용 가능합니다. 그리고 PCA와 t-SNE 임베딩을 IDPE로 평가하여 전통적인 지표들이 포착하지 못하는 성능 인사이트를 발견했습니다.

- **Performance Highlights**: IDPE 방법은 신뢰도(trustworthiness)와 연속성(continuity) 같은 기존의 본질적 지표들과 Average Rank, Mean Reciprocal Rank 같은 외재적 지표들과 비교하여 더 포괄적이고 신뢰할 수 있는 평가를 제공합니다. 그 결과 IDPE가 다양한 시나리오에서 보다 우수한 임베딩 품질 평가를 제공함을 보여줍니다.



### Voxel Scene Graph for Intracranial Hemorrhag (https://arxiv.org/abs/2407.21580)
- **What's New**: 이 논문에서 소개한 연구는 3D CT 스캔 데이터를 사용하여 Scene Graph Generation(SGG) 방법을 처음으로 적용한 것입니다. 이로 인해 임상 뇌 장면의 전반적인 표현을 학습하고, 의사 결정에 중요한 통찰을 제공합니다.

- **Technical Details**: 이 연구는 ICH(두개내 출혈) 감지를 위해 맞춤형 객체 감지 방법을 설계하고, 이를 SGG 방법과 결합하여 특정 의료 장면을 학습합니다. 두 단계로 구성된 이 메서드는 먼저 객체를 로컬라이즈합니다. 이는 Retina U-Net과 Feature Pyramid Network를 사용하여 다양한 크기와 모양의 출혈을 감지하며, 중간선과 뇌실 시스템은 단일 스케일에서 나타나는 특징을 고려합니다. 이후 Neural Motifs와 Iterative Message Passing을 기반으로 한 두 가지 변형(V-MOTIF와 V-IMP)을 사용하여 객체 간의 관계를 예측합니다.

- **Performance Highlights**: 두 개의 CT 데이터셋에서 평가한 결과, 제안된 모델은 임상적으로 관련된 관계를 74%까지 재현할 수 있음을 확인했습니다. 이는 기존의 nnDetection 방식보다 우수하며, 임상 장면의 컴팩트하고 해석 가능한 표현을 통해 의사 결정 지원과 향후 작업에 유용한 데이터를 제공합니다.



### A Performance Study of LLM-Generated Code on Leetcod (https://arxiv.org/abs/2407.21579)
- **What's New**: 이 연구는 Leetcode 데이터셋을 사용하여 LLMs (Large Language Models) 생성된 코드와 인간이 작성한 솔루션의 효율성을 비교하였습니다. 18개의 LLMs를 온도(temperature) 및 성공률과 같은 요소를 고려하여 비교하였으며, LLMs가 생성한 코드가 특정 모델에 상관없이 유사한 성능을 보인다는 것을 발견했습니다. 특히, LLMs가 평균적으로 인간이 작성한 코드보다 더 효율적인 코드를 생성할 수 있다는 점이 강조됩니다.

- **Technical Details**: 연구팀은 Leetcode를 벤치마킹 데이터셋으로 사용하여 LLMs의 성능을 측정했습니다. 데이터 오염(potential data contamination)에 대한 문제와 Leetcode 플랫폼의 측정 신뢰성도 논의되었습니다. 실험 설계는 각 문제에 대해 여러 후보 솔루션을 제공하고 생성된 솔루션의 실행 시간을 비교할 수 있는 방식으로 이루어졌습니다. 연구 질문으로는 LLMs 간의 성능 차이, LLM의 성공률 및 온도가 코드의 성능에 미치는 영향, LLMs가 생성한 코드의 인간 코드보다 효율성 여부 등이 제기되었습니다.

- **Performance Highlights**: 평가 결과, 18개의 LLMs가 생성한 코드는 특정 모델에 상관없이 유사한 성능을 보였으며, 평균적으로 인간이 작성한 코드보다 더 효율적이었습니다. 또한, 고온 설정이 LLMs의 유효 코드 생성 능력을 저하시킬 수 있음을 발견했습니다. 이를 통해 LLMs의 코드 생성 성능에 대한 새로운 이해를 제공하였고, 향후 최적화 연구의 기반을 마련했습니다.



### Multi-Site Class-Incremental Learning with Weighted Experts in Echocardiography (https://arxiv.org/abs/2407.21577)
Comments:
          Accepted for Oral at MICCAI workshop ASMUS-2024

- **What's New**: 이 논문에서는 심초음파 영상 분류기의 성능을 최적화하기 위한 새 검출법을 제안합니다. 이 방법은 다양한 다중 사이트 데이터의 필요성을 이해하고, 모델 드리프트(model drift)를 완화하기 위해 새로운 데이터를 섭렵하여 자주 업데이트 해야 한다는 점에서 출발합니다. 단순한 파인 튜닝(fine-tuning) 대신, 데이터셋 별 전문가 네트워크를 학습하고, 스코어 퓨전 모델(score fusion model)을 통해 이들을 결합합니다. 이 접근법은 비자격 전문가(unqualified expert)의 영향을 최소화하여 투명성을 증진합니다.

- **Technical Details**: 제안된 방법은 경험적 데이터셋에서 학습한 이미지를 사용하는 대신, 각 데이터셋의 특징을 기반으로 학습된 피쳐(learned features)를 사용합니다. 이는 라이선스나 개인정보 문제를 완화합니다. 우리의 클래스-증가 학습법(class-incremental learning method)은 각 데이터셋에 대해 전문가 네트워크를 학습하고, 인퍼런스 동안 각 전문가의 기여를 학습된 인분포 점수(in-distribution score)를 통해 가중치를 부여하여 결합합니다. 이러한 방식으로 모든 데이터의 재학습이 필요 없도록 하여 훈련 시간 및 비용을 줄입니다.

- **Performance Highlights**: 본 연구에서는 다중 사이트 6개의 데이터셋을 사용하여 유효성을 검증했으며, 이미지 외부 전송 없이 성능을 향상시켰습니다. 이는 훈련 시간과 비용을 크게 감소시키고, 추가적인 증가 단계(incremental steps)를 통해 더욱 최적화할 수 있음을 보여줍니다. 새로운 접근법은 '비자격 전문가'의 영향을 최소화하여 투명성과 성능 모두를 향상시킨다고 입증되었습니다.



### PMoE: Progressive Mixture of Experts with Asymmetric Transformer for Continual Learning (https://arxiv.org/abs/2407.21571)
- **What's New**: 이번 연구에서는 Large Language Models (LLMs)의 지속 학습에서 발생하는 기존 지식의 망각 문제를 해결하기 위해 PMoE(Progressive Mixture of Experts with Asymmetric Transformer)를 제안합니다. PMoE는 비대칭적 깊이 설계를 통해 얕은 레이어(shallow layers)는 일반 지식을, 깊은 레이어(deep layers)는 새로운 지식을 담당하도록 하여 망각을 최소화하고자 합니다.

- **Technical Details**: PMoE는 깊은 레이어에 전문가를 점진적으로 추가하고, 라우터(router)를 사용하여 새로운 지식을 적절한 전문가에게 효율적으로 할당합니다. 이 라우터는 깊은 레이어 옆에 배치되어 집계된 정보를 사용해 최적의 성능을 발휘합니다. PMoE는 TRACE 데이터셋과 일반 단어 이해 데이터셋에서 기존의 최첨단 방법보다 우수한 성능을 보였습니다.

- **Performance Highlights**: PMoE는 LoRA와 재생기반 리플레이 방법 및 기존 최첨단 방법보다 TRACE 벤치마크에서 뛰어난 성능을 제공합니다. 비대칭적 설계는 기존 지식을 유지하면서 새로운 지식을 효율적으로 획득하는 데 매우 효과적이며, 파라미터 효율성 면에서도 우수합니다.



### Generative Sentiment Analysis via Latent Category Distribution and Constrained Decoding (https://arxiv.org/abs/2407.21560)
- **What's New**: 이번 연구는 세밀한 감성 분석(fine-grained sentiment analysis)을 위한 생성적 감성 분석 모델을 도입합니다. 기존 모델들이 간과했던 카테고리 의미 포함(category semantic inclusion)과 중복(overlap) 문제를 해결하기 위해 잠재 카테고리 분포 변수(Latent Category Distribution, LCD)를 도입했습니다. 또한, 트라이 데이터 구조(trie data structure)와 제한적 디코딩(constrained decoding) 전략을 활용하여 구조적 패턴 지식을 활용했습니다.

- **Technical Details**: 연구에서 제안된 모델은 감성 사중추출(sentiment quadruple extraction) 과제를 생성적 프로세스로 취급하며, 텍스트와 카테고리 간의 관계 강도를 학습하기 위해 변분 오토인코더(Variational AutoEncoder, VAE)의 입력을 재구성함으로써 잠재 카테고리 분포 변수를 도입했습니다. 추가로, 제한적 디코딩 전략을 사용하여 디코딩 단계에서 검색 공간을 줄이고 시퀀스 생성 과정을 개선했습니다.

- **Performance Highlights**: Restaurant-ACOS와 Laptop-ACOS 데이터셋에서 제안된 모델이 기존의 기준(baseline) 모델에 비해 성능이 향상됨을 실험 결과로 입증했습니다. 또한, 애블레이션(관부) 실험을 통해 잠재 카테고리 분포와 제한적 디코딩 전략의 유효성과 기여도를 확인했습니다.



### Skeleton-Based Action Recognition with Spatial-Structural Graph Convolution (https://arxiv.org/abs/2407.21525)
- **What's New**: 본 연구에서는 인간 활동 인식(HAR) 분야에 있어 최신 기술을 소개합니다. 특히, Graph Convolutional Network(GCN)을 기반으로 인간 골격 데이터를 이용한 활동 인식이 주목받고 있습니다. 그러나 기존 GCN 방법은 골격 데이터 표현과 과도한 스무딩 문제에 대한 연구가 필요했습니다. 이를 해결하기 위해 Spatial-Structural GCN(SpSt-GCN)이라는 두 스트림 그래프 컨볼루션 방법을 제안합니다. 정적인 공간 연결과 동적인 구조 연결을 통해 각기 다른 인간 움직임에 맞춘 유연한 정보 집합이 가능하게 하였습니다.

- **Technical Details**: SpSt-GCN은 두 가지 주요 아이디어에 기반합니다. 첫째, 가장자리 노드는 세밀한 활동 인식에 중요하며, 일반적인 중앙 노드보다 제한된 이웃 정보만을 집계할 수 있습니다. 둘째, GCN의 과도한 스무딩 문제를 해소하기 위해 구조적 연결 방식을 채택하여 차별화를 꾀하고, 각 샘플의 가장자리 노드의 유사성을 바탕으로 구조 연결을 데이터 기반으로 초기화합니다. SpSt-GCN은 인간 골격의 고정된 공간적 연결과 움직임에 따라 변하는 구조적 연결을 동시에 고려합니다.

- **Performance Highlights**: 제안된 방법은 NTU RGB+D와 NTU RGB+D 120와 같은 대규모 데이터 세트에서 평가되었으며, 높은 효율성과 좋은 성능을 보였습니다. 본 연구의 주요 기여는 대칭적 인간 구조와 가장자리 노드를 더 잘 표현할 수 있는 공간-구조 그래프 컨볼루션 방법을 제안한 것과, 인접 노드의 수에만 의존하지 않고 차별적 접근법을 통해 유연성을 높인 것입니다.



### Tabular Data Augmentation for Machine Learning: Progress and Prospects of Embracing Generative AI (https://arxiv.org/abs/2407.21523)
Comments:
          repository maintained at this https URL

- **What's New**: 기계 학습(ML)이 표형 데이터(tabular data)에 널리 사용되고 있지만, 모델 학습을 위한 고품질의 풍부한 표형 데이터를 얻는 데 여전히 큰 장애물이 있었습니다. 이 논문은 표형 데이터 증강(Tabular Data Augmentation, TDA)을 통한 데이터 증강에 관한 진전과 미래 전망을 종합적으로 검토합니다. 특히, 생성 AI(generative AI)를 활용한 최신 동향에 중점을 두고 있습니다.

- **Technical Details**: TDA 파이프라인은 주로 세 가지 과정으로 구성됩니다: 증강 전(Pre-augmentation), 증강(Augmentation), 증강 후(Post-augmentation). 증강 전 과정은 오류 처리, 표 주석, 표 간소화, 표 표현, 표 색인화, 표 탐색, 스키마 맞춤(schema matching), 엔티티 맞춤(entity matching) 등의 준비 작업을 포함합니다. 증강 과정은 현재 TDA 방법을 체계적으로 분석하며, 외부 데이터를 검색하는 검색 기반 방법(retrieval-based methods)과 합성 데이터를 생성하는 생성 기반 방법(generation-based methods)으로 분류됩니다. 이 방법들은 각 행, 열, 셀, 전체 표 수준에서의 증강 과정의 세분화에 따라 추가 분류됩니다. 증강 후 과정은 데이터셋, 평가 및 최적화 측면에 중점을 둡니다.

- **Performance Highlights**: 논문은 생성 AI 시대에서 TDA의 현재 동향과 미래 방향을 요약하며, 유망한 기회를 강조합니다. 관련 자료와 논문은 GitHub 저장소에서 지속적으로 업데이트되고 유지관리됩니다.



### The Impacts of AI Avatar Appearance and Disclosure on User Motivation (https://arxiv.org/abs/2407.21521)
Comments:
          15 pages, 6 figures, submitted to the 2nd International Conference on Data Science & Artificial Intelligence

- **What's New**: 이 연구는 가상 상호작용에서 사용자의 동기부여에 미치는 인공지능(AI) 특성의 영향을 조사합니다. AI 아바타가 AI로 공개되거나 특정 성별을 나타낼 때, 사용자-AI 상호작용에서 어떤 영향을 미치는지 탐구합니다. 72,500명 이상의 참가자가 AI 동료와 함께 또는 혼자 검색 문제를 해결하는 게임 기반 실험을 통해, AI 공개 여부와 성별이 사용자 동기에 미치는 영향을 분석했습니다.

- **Technical Details**: 실험은 Roblox라는 가상 세계에서 진행되었습니다. 참가자들은 AI 아바타와 함께 혹은 혼자 총 15단계의 검색 작업을 수행했습니다. 참가자 절반에는 자신이 AI와 함께 게임을 하고 있다는 사실이 공개되지 않았습니다. 참가자들의 놀이 강도를 측정하기 위해 각 단계를 완료한 시간 대비 게임을 떠나기 전까지의 시간을 분석했습니다. 이를 통해 AI 성별 외관이 동기에 미치는 영향을 비교했습니다.

- **Performance Highlights**: 실험 결과, 다른 아바타가 있을 때 독립적으로 혼자 플레이할 때보다 플레이 강도가 낮아졌습니다. AI 아바타가 AI임을 공개한 경우, 공개되지 않은 AI 동료보다 더 높은 노력 강도를 보였습니다. 또한, 남성형 AI 외관은 노력 강도를 감소시키는 경향을 보였습니다.



### Expanding the Medical Decathlon dataset: segmentation of colon and colorectal cancer from computed tomography images (https://arxiv.org/abs/2407.21516)
Comments:
          8 pages, 2 figures, 2 tables

- **What's New**: 이 논문에서는 Medical Decathlon 데이터셋을 확장하여, 대장 및 대장암의 마크업(markup)을 추가해 의료 영상 처리 분야에서 실질적 문제를 해결하려는 시도를 했습니다. 주요 기여점은 경험 많은 방사선 전문의가 검증한 데이터를 품질에 따라 부분 집합으로 분류하고 이를 공개 도메인에 제공한 것입니다.

- **Technical Details**: 논문에서는 UNet 아키텍처(neural network models of the UNet architecture)를 활용하여 5-파트 교차 검증(5-part cross-validation)을 통해 모델을 훈련시켰습니다. 결과적으로 평균 Dice 지수(Dice metric quality) 0.6988 ± 0.3을 달성했습니다. 이런 노력은 초기 단계에서 대장암을 탐지하고 방사선 전문의가 병리학을 찾는 과정을 용이하게 하며, 진단 과정을 크게 가속화할 것입니다.

- **Performance Highlights**: 경험 많은 방사선 전문의가 검증한 데이터와 분류된 데이터 세트, 그리고 5-파트 교차 검증을 통해 UNet 모델이 0.6988 ± 0.3의 Dice 메트릭 품질을 달성했다는 점이 주요 성과입니다. 공개된 마크업은 대장암 감지의 품질을 개선하고 방사선 전문의의 연구 기술을 단순화하는 데 중요한 기여를 할 것입니다.



### MaskUno: Switch-Split Block For Enhancing Instance Segmentation (https://arxiv.org/abs/2407.21498)
- **What's New**: 최신 연구에서는 인스턴스 세분화(instance segmentation) 문제의 해결책으로 MaskUno를 도입합니다. MaskUno는 마스크 예측을 Switch-Split 블록으로 대체하여 정제된 ROI를 처리하고, 이를 분류하고, 전문 마스크 예측기로 할당합니다. 이 방법은 기존의 대부분의 인스턴스 세분화 방법론에서 발생하는 클래스 간 경쟁 문제를 줄이기 위해 설계되었습니다.

- **Technical Details**: MaskUno는 인스턴스 세분화 모델의 최종 예측 레이어를 모듈식 Switch-Split 블록으로 교체합니다. 이 블록은 특정 클래스를 위한 분할 마스크 예측기를 사용해 각 클래스 간의 경쟁 커널 문제를 방지합니다. 이러한 방식으로 각 클래스 별로 독립적으로 최적화가 이루어져 더 풍부한 표현이 가능해집니다.

- **Performance Highlights**: MaskUno는 COCO 데이터셋을 사용한 여러 모델에 적용해 테스트했을 때, 고성능의 DetectoRS 모델에서 평균 정밀도(mAP)가 2.03% 증가했습니다. 이 결과는 MaskUno가 클래스 수와 상관없이 인스턴스 세분화 모델의 성능을 향상시킨다는 것을 보여줍니다.



### Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation (https://arxiv.org/abs/2407.21490)
Comments:
          Accepted by MICCAI MLMI 2024

- **What's New**: 심초음파(Echocardiography) 비디오 생성을 위한 새로운 방법이 제안되었습니다. 이 방법은 초기 프레임과 운동 곡선(Motion curve)을 가이드로 사용하여 심초음파 비디오를 생성하게 됩니다. 기존 방법들이 전체적인 조건에 의존했다면, 이 방법은 각각의 심장 구조에 맞춘 운동 제어를 가능하게 합니다.

- **Technical Details**: 제안된 방법의 주요 기여점은 세 가지입니다. 첫째, 각 심장 하부구조로부터 운동 정보를 추출하여 운동 곡선을 구성합니다. 둘째, 이 운동 곡선을 시각적 정보에 맞추기 위해 구조-운동 정렬 모듈(Structure-to-Motion alignment)을 제안합니다. 셋째, 위치 인식 주의 메커니즘(Position-aware attention mechanism)을 설계하여 구조적 위치 정보를 가진 가우시안 마스크를 활용하여 비디오 일관성을 향상시킵니다. 이 모델은 SD (Stable Diffusion) VAE(Variational Auto-Encoder)를 사용하여 프레임을 잠재 특징으로 다운샘플링하고, 노이즈를 추가하고 제거하며 비디오를 생성합니다.

- **Performance Highlights**: 이번 연구에서 제안된 방법은 세 가지 심초음파 데이터셋에 대해 기존 방법들보다 높은 충실도와 일관성을 보였습니다. 또한, 사용자 정의 가능성을 제공하여 초기 프레임이나 운동 곡선을 조정함으로써 사용자 요구에 맞춘 비디오 생성이 가능합니다. 구체적으로, 좌심실(Left Ventricle), 좌심방(Left Atrium), 승모판(Mitral Valve) 등 주요 구조에 맞춘 세밀한 운동 제어가 가능하도록 설계되었습니다.



### Maverick: Efficient and Accurate Coreference Resolution Defying Recent Trends (https://arxiv.org/abs/2407.21489)
Comments:
          Accepted at main conference of ACL 2024. 15 pages

- **What's New**: 최근 자연어 처리(Natural Language Processing) 주요 과업에서 고성능을 구현하기 위해 대규모 autoregressive generative 모델이 주로 사용되고 있습니다. 이러한 경향 속에서, Coreference Resolution 태스크도 예외는 아니었습니다. 그러나 이번에 발표된 논문에서는, Maverick이라는 새로운 시스템을 소개합니다. 이 시스템은 적은 자원 내에서 최고 성능을 자랑하는 Coreference Resolution을 구현하도록 설계되었습니다. 약 500 million 파라미터로, 최대 13 billion 파라미터 모델보다도 높은 성능을 보였습니다.

- **Technical Details**: Maverick 시스템은 단순하지만 정교하게 설계된 파이프라인을 채택해, 학문적 예산 내에서 최고 성능을 실현할 수 있도록 합니다. CoNLL-2012 벤치마크에서 state-of-the-art 성능을 달성하며, 최대 이전 시스템의 0.006배 메모리로 훈련이 가능하고, 170배 빠른 추론속도를 기록했습니다. 다양한 실험을 통해 데이터 부족, 긴 문서, 비도메인 데이터 등에서도 견고한 성능을 보였음을 입증했습니다.

- **Performance Highlights**: Maverick은 less than 13 billion 파라미터를 사용하는 모델보다 우수한 성능을 보여주며, 대표적으로 CoNLL-2012 벤치마크에서 최고 성능을 기록했습니다. 메모리 자원 측면에서는 최대 0.006배 적게 필요했고, 추론 속도는최대 170배 빠르게 나타났습니다. 다양한 조건에서의 실험을 통해 Maverick의 강건함과 효율성을 강조했습니다. 추가적으로, 연구 목적으로 코드와 모델을 공개했습니다.



### Breaking the Hourglass Phenomenon of Residual Quantization: Enhancing the Upper Bound of Generative Retrieva (https://arxiv.org/abs/2407.21488)
- **What's New**: 새로운 논문에서 'Hourglass' 현상으로 인해 생성 검색(generative retrieval) 방법의 효율성이 저하되는 문제를 분석하고 해결책을 제안하였습니다.

- **Technical Details**: Residual Quantization based Semantic Identifiers (RQ-SID)를 생성하는 과정에서, 코드북의 중간 토큰이 과도하게 집중되는 문제가 발생하는데, 이를 'Hourglass' 현상이라 정의하였습니다. 이 현상은 데이터 스파시티(data sparsity) 및 롱테일 분포(long-tailed distribution)에서 기인하며 이를 해결하기 위한 두 가지 방법을 제안했습니다: 히어리스틱 접근법(heuristic approach)과 가변 길이 코딩(variable-length coding) 전략.

- **Performance Highlights**: 경험적인 실험 결과, 제안된 두 가지 방법 모두 'Hourglass' 현상을 완화하고 모델의 성능을 향상시키는 데 효과가 있음을 확인했습니다. 또한, 특히 가변 길이 코딩 전략이 가장 효과적이라는 결론을 내렸습니다.



### Fine-gained Zero-shot Video Sampling (https://arxiv.org/abs/2407.21475)
- **What's New**: 해당 연구에서는 새로운 Zero-Shot video Sampling 알고리즘인 $\mathcal{ZS}^2$를 제안합니다. 이 알고리즘은 기존의 이미지 생성 방법에서 직접 고품질의 비디오 클립을 샘플링할 수 있게 해줍니다. $\\mathcal{ZS}^2$는 별도의 학습이나 최적화 과정 없이, Stable Diffusion과 같은 사전 학습된 이미지 합성 방법을 사용해 비디오를 생성합니다.

- **Technical Details**: $\unction{ZS}^2$는 종속성(Dependency) 노이즈 모델과 시간적 모멘텀 주의 메커니즘(temporal momentum attention)을 활용하여 각각 콘텐츠 일관성과 애니메이션 일관성을 보장합니다. 이 알고리즘은 기존의 DDIM과 같은 이미지 샘플링 알고리즘과 쉽게 통합되어 비디오 생성이 가능합니다. 또한, 조건부와 특화된 비디오 생성, 지시된 비디오 편집 등의 작업에 적용할 수 있습니다.

- **Performance Highlights**: $\unction{ZS}^2$는 zero-shot 비디오 생성에서 최첨단 성능을 달성하여, 때로는 최근 감독된(supervised) 방법들을 능가합니다. 실험 결과, $\\function{ZS}^2$는 훈련이나 튜닝 없이도 텍스트 설명에 맞춰 일관성 있는 비디오 프레임을 생성할 수 있음을 보여줍니다.



### An Invertible State Space for Process Trees (https://arxiv.org/abs/2407.21468)
Comments:
          8 pages, 7 figures

- **What's New**: 이 연구는 프로세스 트리(Process Trees)에 대한 변환 가능한 상태 공간 정의를 제안합니다. 이는 프로세스 트리의 상태 공간 그래프가 그 역의 상태 공간 그래프와 이성형(isomorphic)임을 보여줍니다. 이 결과는 프로세스 트리 응용에 시간 효율적인 분해 전략을 개발하는 데 기여할 수 있습니다.

- **Technical Details**: 제안된 상태 공간 정의는 세 가지 가능한 정점 상태만을 사용하는 간단한 구조입니다. 이 구조는 강력한 이론적 보장을 가지고 있으며, 프로세스 트리의 상태 공간 그래프가 그 역의 상태 공간 그래프와 이성형이 되도록 합니다. 이렇게 함으로써 일반적인 최적화 기법과 검색 문제에 대한 전략을 적용할 수 있게 됩니다.

- **Performance Highlights**: 실험 결과에 따르면 제안된 상태 공간 정의는 상태 공간 그래프에 대해 양방향 검색(bidirectional search)을 적용할 수 있어, 일반적인 너비 우선 검색(breadth-first search) 위에 간단하게 덧붙여져 전반적인 성능을 크게 향상시키는 것으로 나타났습니다.



### Deep Learning-Based Longitudinal Prediction of Childhood Myopia Progression Using Fundus Image Sequences and Baseline Refraction Data (https://arxiv.org/abs/2407.21467)
- **What's New**: 본 연구에서는 어린이 근시의 진행을 예측하기 위한 새로운 고정확도 방법을 소개합니다. 이 방법은 망막(fundus) 이미지와 기초 굴절 데이터만을 사용하여 어린이 근시 경과와 근시 위험을 정량적으로 예측할 수 있습니다.

- **Technical Details**: 연구는 Henan 지역에서 6년 동안 3,408명의 어린이들을 대상으로 16,211장의 망막 이미지와 해당 굴절 데이터를 활용하여 검증되었습니다. 본 연구에서 제안된 방법은 깊은 학습(deep learning)에 기반하고, 연간 0.311 디옵터(D) 오차 범위를 가지며, 근시 및 고도근시(high myopia) 발생 위험 예측에서 각각 0.944와 0.995의 AUC 점수를 기록했습니다.

- **Performance Highlights**: 본 모델은 추가 메타 데이터나 반복적인 진료가 필요하지 않으며, 단 한번의 측정만으로도 유효한 예측이 가능합니다. 이를 통해 의료 비용을 획기적으로 절감할 수 있으며, 대규모 스크리닝(screening)에도 용이합니다.



### TinyChirp: Bird Song Recognition Using TinyML Models on Low-power Wireless Acoustic Sensors (https://arxiv.org/abs/2407.21453)
- **What's New**: 본 논문은 TinyML(초소형 기계 학습) 신경망 아키텍처와 압축 기술을 다양한 종 분류에 활용한 실험적 비교를 다룹니다. 특히, 이동량이 적은 장치에서 새의 노래를 탐지하는 방법에 중점을 두어, corn bunting(종달새)의 노래를 대상으로 한 데이터 세트와 비교 연구 결과를 제공합니다.

- **Technical Details**: 새의 노래 탐지를 위해서는 연속적인 오디오 녹음이 필요하며, 이는 메모리 및 에너지 예산에 큰 부담을 줍니다. 이 문제를 해결하기 위해, 본 논문은 시간을 줄이고 메모리 소비를 최소화하는 부분 합성곱 기술(partial convolution technology)을 사용하여 신경망을 최적화하였습니다. 또한, 두 단계 분류 접근법(two-stage classification approach)을 제안하여 계산 및 저장 비용을 줄이고 전반적인 정확도를 높였습니다.

- **Performance Highlights**: 실험 결과는 개별 새 종을 비교적 간단한 아키텍처로도 견고하게 감지할 수 있음을 보여주었습니다. 본 연구는 고품질의 데이터 세트와 코드가 포함된 실험 결과를 공개하여, 향후 연구와 실질적인 응용에 기여할 수 있는 기반을 마련했습니다. 이러한 접근법을 통해 특정 새 노래만을 저장함으로써 장치의 수명을 연장할 수 있음을 입증했습니다.



### Improving Faithfulness of Large Language Models in Summarization via Sliding Generation and Self-Consistency (https://arxiv.org/abs/2407.21443)
Comments:
          Long paper accepted at LREC-COLING 2024 (oral)

- **What's New**: 최근 연구에서 제안한 SliSum이라는 새로운 요약 생성 전략입니다. 이 전략은 슬라이딩 윈도우(sliding windows)와 자기 일관성(self-consistency) 개념을 활용하여, LLMs(Large Language Models)의 요약 생성 시 사실성을 향상시키는 방법입니다. 이 방법은 특히 긴 문서 요약에서 나타나는 LLMs의 환각(hallucination) 문제를 줄이는 데 효과적입니다.

- **Technical Details**: SliSum은 세 가지 주요 단계로 요약을 생성합니다. 첫 번째 단계는 슬라이딩 생성(Sliding Generation)으로, 문서를 겹치는 윈도우로 나눈 후 각 윈도우에 대해 '로컬 요약(local summaries)'을 생성합니다. 두 번째 단계는 필터링(Filtration)으로, 자기 일관성 원칙에 따라 더 자주 생성된 문장은 더 신뢰할 수 있다고 가정하고 중요하지 않은 내용과 불일치 내용을 제거합니다. 마지막 단계는 집계(Aggregation)로, 로컬 요약에서 충돌이 없는 문장들을 다수결 법칙으로 선정하고 이를 결합하여 최종 요약을 만듭니다.

- **Performance Highlights**: SliSum은 CNN/DM과 XSum 같은 단문 뉴스 데이터셋뿐 아니라, arXiv와 PubMed 같은 장문 과학 논문 데이터셋에서도 GPT-3.5, Claude-2, 그리고 LLaMA-2-13B 모델의 요약의 사실성을 크게 향상시켰습니다. 또한, 유창성과 정보성을 크게 훼손하지 않으면서도 성능 향상을 달성하였습니다. 추가적인 데이터나 모델 훈련이 없이도 이러한 성과를 보였습니다.

- **Research Implications**: SliSum은 LLMs가 전체 문서를 좀 더 공정하고 충실하게 처리하도록 하여 요약의 사실성을 높입니다. 이 방법은 요약 생성에서 LLMs의 환각 문제를 줄이는 데 중요한 기여를 할 수 있어, 다양한 텍스트 길이와 스타일에 적용 가능합니다. 이는 요약 생성 분야에서 새로운 방향을 제시하며, 미래의 연구 개발에 중요한 참고자료가 될 수 있습니다.



### Deformable 3D Shape Diffusion Mod (https://arxiv.org/abs/2407.21428)
- **What's New**: 본 연구는 기존의 3D 점 구름(Point Cloud) 생성 방법들이 3D 형태의 본질적인 기하학적 특징을 완전히 고려하지 못한다는 문제를 해결하기 위해, 새로운 변형 가능한 3D 형태 확산 모델을 제안합니다. 이 모델은 점 구름 생성, 메쉬 변형, 얼굴 애니메이션 등 다양한 3D 형태 조작을 지원합니다.

- **Technical Details**: 제안된 방법은 Differential Deformation Kernel(DDK)을 도입하여 기하학적 구조의 생성을 순차적이고 비강체 변형 단계로 분해합니다. 이를 통해, 확산 과정을 기하학적으로 인식하고 효과적으로 처리할 수 있습니다. 또한, 확산 과정의 역 시뮬레이션을 통해 주어진 템플릿 분포로부터 원래 기하학적 구조를 복원합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 점 구름 생성에 있어서 최첨단 성능을 보였으며, 메쉬 변형에서도 경쟁력 있는 결과를 보여줬습니다. 광범위한 시각적 데모는 그래픽 렌더링, 애니메이션 제작 등 다양한 실용적인 애플리케이션에서의 높은 잠재력을 강조하고 있습니다.



### Cost-Effective Hallucination Detection for LLMs (https://arxiv.org/abs/2407.21424)
- **What's New**: 이번 연구는 대형 언어 모델(Large Language Models, LLMs)의 생산 환경에서 발생할 수 있는 'hallucination' (환각) 문제를 해결하기 위한 후처리 감지 프레임워크를 제안합니다. 여기에는 생성된 답변이 환각일 가능성을 나타내는 신뢰도 점수를 생성하고, 이를 입력 및 후보 응답의 속성에 조건화하여 보정하는 과정이 포함됩니다. 최종적으로, 보정된 점수를 기준으로 환각을 감지합니다.

- **Technical Details**: 연구팀은 질문 응답, 사실 검증, 요약 작업을 포함한 다양한 데이터셋에서 최첨단 점수 방법을 벤치마킹했습니다. 다양한 LLM을 사용하여 성능을 종합적으로 평가한 결과, 개별 점수 방법은 모든 상황에서 최적의 성능을 발휘하지 못한다는 결론에 도달했습니다. 이에 따라, 여러 점수를 결합하여 더 나은 성능을 내는 Multi-scoring 프레임워크를 제안했습니다. 또한, 비용 효율적인 Multi-scoring 방법도 도입하여, 더 높은 비용을 들이는 감지 방법보다도 더 우수한 성능을 발휘할 수 있음을 입증했습니다.

- **Performance Highlights**: 연구 결과, 다중 점수 방법을 사용하여 환각 감지 성능이 크게 향상되었으며, 비용 효율적인 Multi-scoring 방법은 높은 성능을 유지하면서도 계산 비용을 크게 절감할 수 있었습니다. 이는 현실적인 제약 조건을 가진 실제 응용 프로그램에서 중요한 의사결정을 지원할 수 있는 잠재력을 보여줍니다.



### GEGA: Graph Convolutional Networks and Evidence Retrieval Guided Attention for Enhanced Document-level Relation Extraction (https://arxiv.org/abs/2407.21384)
- **What's New**: 새로운 문서 레벨 관계 추출(Document-level Relation Extraction, DocRE) 모델인 GEGA가 제안되었습니다. 이 모델은 그래프 신경망(Graph Neural Networks)을 활용하여 문서 내 증거 문장(evidence sentences)에 주의를 기울이는 방법을 제시하며, 멀티 스케일 표현 집계를 통해 증거 추출을 향상시킵니다.

- **Technical Details**: GEGA 모델은 다음과 같은 기술적 요소를 포함합니다: 첫째, 그래프 구조와 Transformer를 결합하여 문서 내 관계 엔티티 쌍과 관련된 증거 문장을 추출합니다. 둘째, 다중 가중치 행렬을 구축하여 증거 문장에 대한 주의 할당을 안내합니다. 마지막으로, 복잡한 교차 관계 추출을 개선하기 위해 다중 스케일 표현 집계를 수행합니다. 이 모델은 완전 지도 학습(fully supervised)과 약 지도 학습(weakly supervised) 설정 아래서도 훈련될 수 있습니다.

- **Performance Highlights**: GEGA 모델은 DocRED, Re-DocRED, Revisit-DocRED 세 가지 주로 사용되는 벤치마크 데이터셋에서 기존의 SOTA 모델에 비해 전반적인 성능 향상을 달성하였습니다. 이로 인해 문서 레벨 관계 추출의 새 표준(SOTA)을 달성하게 되었습니다.



### Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering (https://arxiv.org/abs/2407.21368)
- **What's New**: 최근 몇 년간 큰 성과를 거둔 대규모 비전-언어 모델(LVLMs)이 의료 분야로 확장되었습니다. 하지만, 이들 모델은 환각(hallucination) 문제로 인해 복잡한 병리학 진단에 실패하는 경우가 많습니다. 본 연구에서는 이러한 문제를 해결하기 위해 두 가지 프롬프트 전략을 제안합니다. 첫 번째 전략은 질의된 병리학에 대한 상세 설명을 제공하는 것이며, 두 번째 전략은 저비용 약한 학습기(weak learner)를 조정하여 특정 지표에서 높은 성능을 달성하게 한 후, 그 판단을 텍스트로 MLVLM에 전달하는 것입니다.

- **Technical Details**: 첫 번째 프롬프트 전략은 질의된 병리학에 대한 세부 설명을 추가하여 모델의 이해도를 높입니다. 두 번째 전략은 추가 약한 학습기를 별도의 에이전트로 사용하여, 그 모델이 부정적인 이미지를 정확하게 식별하도록 하고, 결과를 프롬프트에 참조로 제공하는 것입니다. 이 전략들은 MIMIC-CXR-JPG와 Chexpert 데이터셋에서 테스트되었으며, F1 점수를 크게 향상시켰습니다. 특히 POPE 지표에 따라 일반 LVLM 도메인에까지 확장될 수 있음을 보여줍니다.

- **Performance Highlights**: 제안된 프롬프트 전략들은 MIMIC-CXR-JPG와 Chexpert 데이터셋에서 테스트되었으며, 다수의 병리학 카테고리에서 F1 점수가 0.27까지 향상되었습니다. 일반 도메인에서도 유사한 전략을 사용하여 거짓 부정(False Negative) 예측을 억제하고, Recall을 약 0.07만큼 향상시켰습니다. 이는 모델이 보다 정교한 진단과 질문 응답을 수행할 수 있도록 도움을 줍니다.



### ProSpec RL: Plan Ahead, then Execu (https://arxiv.org/abs/2407.21359)
- **What's New**: 연구팀은 행동 실행 전 잠재적 결과를 상상할 수 있도록 하여 더 정보에 입각한 결정을 내릴 수 있는 Prospective (ProSpec) 강화 학습(RL) 방법을 제안했습니다. ProSpec은 현재 상태와 일련의 샘플링된 행동에 기초하여 미래의 n-스트림 궤적을 상상함으로써 높은 가치와 낮은 위험의 최적 결정을 내립니다.

- **Technical Details**: ProSpec은 동적 모델을 사용하여 현재 상태와 일련의 샘플링된 행동을 바탕으로 미래 상태(상상된 상태)를 예측합니다. 또한 Model Predictive Control(MPC) 개념을 통합하여 이러한 궤적들 중 최적의 행동을 평가하고 선택하는 순환 일관성 제약을 도입했습니다. ProSpec은 또한 순환 일관성을 사용하여 기본적인 두 가지 문제를 완화합니다: 상태 가역성을 향상시켜 비가역적 사건을 피하고(낮은 위험성) 많은 가상 궤적을 생성하여 데이터 효율성을 향상시키는 것입니다.

- **Performance Highlights**: ProSpec 방법은 DMControl 벤치마크에서 유효성을 입증했으며, 우리의 접근법은 상당한 성능 향상을 이루었습니다. 코드는 승인 시 오픈 소스로 공개할 예정입니다.



### Small Object Few-shot Segmentation for Vision-based Industrial Inspection (https://arxiv.org/abs/2407.21351)
- **What's New**: 이 논문은 산업용 비전 기반 검사(Visual-based Industrial Inspection, VII)에서 새롭고 보지 못한 결함을 몇 가지 주석만으로도 재교육 없이 빠르게 찾는 방법을 제안합니다. 기존의 몇 샷 세그멘테이션(FSS) 기법은 작은 결함을 찾는 데 여러 문제를 겪는데, 이를 해결하기 위해 저자는 소규모 물체 몇 샷 세그멘테이션 모델(SOFS)을 제안합니다. 이 모델은 원본 이미지를 리사이징하지 않고 지원 주석의 프로토타입 강도를 다운샘플링하여 결함의 강도를 정확히 나타냅니다. 또한, 비정상적인 사전 지도를 설계하여(false positives) 잘못된 양성을 줄입니다.

- **Technical Details**: SOFS 모델의 핵심 아이디어는 원본 이미지를 리사이징하지 않고, 지원 주석의 프로토타입 강도를 다운샘플링하여 대상 의미의 왜곡을 피하며, 비정상적인 사전 지도를 사용하여 모델이 잘못된 양성을 줄이는 것입니다. SOFS는 훈련 중 작은 물체를 자르고, 테스트에서는 슬라이딩 윈도우 메커니즘을 사용하여 픽셀 영역을 일정하게 유지합니다. 또한, 혼합된 정상적인 Dice 손실 함수를 제안하여 모델이 잘못된 양성을 예측하지 않도록 대형 패널티를 부과합니다.

- **Performance Highlights**: SOFS는 VISION V1 데이터셋에서 12.2% mIoU 향상을 이루며, 기존의 SegGPT를 능가하는 성과를 보였습니다. 몇 샷 이상 탐지 실험에서도 경쟁력 있는 성능을 입증하였습니다. 이는 VII에서 FSS와 FAD 모두를 달성한 최초의 모델입니다.



### Differentially Private Block-wise Gradient Shuffle for Deep Learning (https://arxiv.org/abs/2407.21347)
Comments:
          43 pages, 11 figures, 8 tables

- **What's New**: 이 연구는 전통적인 차분 프라이버시 확률적 경사 하강법(DP-SGD)을 개선한 새로운 알고리즘인 차분 프라이버시 블록-와이즈 경사 셔플(DP-BloGS)을 도입합니다. 이는 정보 이론적 프라이버시 분석을 모델로 한 셔플 기법을 통해 기울기에 확률적 노이즈를 도입하는 접근 방식을 취합니다. DP-BloGS는 특정 블록 크기 선택, 배치 레이어 클리핑, 기울기 누적을 결합하여 비프라이버시 훈련에 근접한 훈련 시간을 달성하면서도 비슷한 수준의 프라이버시와 유틸리티를 제공합니다.

- **Technical Details**: DP-BloGS는 세 가지 주요 요소로 구성됩니다: 트레이너(Trainer), 제너레이터(Generator), 회계 담당자(Accountant). 트레이너는 훈련과 관련된 모든 작업을 처리하고, 제너레이터는 기울기를 받아들이고 모델의 가중치 업데이트 전에 기울기를 셔플링 처리합니다. 회계 담당자는 블록 크기를 최적화하고 훈련 과정 동안 프라이버시 비용을 추적합니다. 알고리즘의 핵심 단계는 기울기를 절단하고 블록 크기에 맞게 셔플링한 후 프라이버시 예산(privacy budget)을 사용해 프라이버시 비용을 계산하는 것입니다.

- **Performance Highlights**: DP-BloGS는 실험 결과, DP-SGD보다 데이터 추출 시도에 훨씬 강력한 저항성을 보였으며, 훈련 시간도 비슷하거나 더 빠릅니다. DP-BloGS는 최대 11억 개의 파라미터를 가진 모델에서도 효과를 발휘하며, 프라이버시와 유틸리티의 균형을 맞추기 위해 최적의 블록 크기와 클리핑 임계값을 선택합니다.



### MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework (https://arxiv.org/abs/2407.21343)
Comments:
          Submitted to BraTS 2024

- **What's New**: 의료 영상 분할 연구에서 표준화된 도구의 부재로 인해 방법들의 비교가 어려운 문제를 해결하기 위해 Medical Imaging Segmentation Toolkit (MIST)가 도입되었습니다. MIST는 간단하고 모듈화된 엔드투엔드 의료 영상 분할 프레임워크로, 일관된 데이터 분석, 전처리, 평가 파이프라인을 제공하여 재현 가능하고 공정한 비교를 가능하게 합니다. BraTS Adult Glioma Post-Treatment Challenge 데이터셋을 사용하여 MIST의 효용성이 입증되었습니다.

- **Technical Details**: MIST는 표준 데이터 형식 요구사항, 파이프라인, 보조 기능을 포함합니다. 데이터 분석 파이프라인은 데이터 셋의 크롭핑, 타겟 스페이싱, 패치 크기 선택, 정규화 매개변수 등을 포함합니다. 전처리 파이프라인은 이미지의 전경 마스크에 따라 크롭하고, 오른쪽-앞-아래 방향으로 재정렬하며, 목표 스페이싱으로 리샘플링하고, 강도 값을 윈도우 및 정규화합니다. 또한 거리 변환 맵(DTM)을 계산하거나 MR 이미지의 바이어스 보정을 할 수 있습니다.

- **Performance Highlights**: BraTS Adult Glioma Post-Treatment Challenge 데이터셋을 사용하여 수행한 테스트에서 MIST는 정확한 분할 마스크를 생성하고 다중 GPU에서 확장 가능함을 보여주었습니다. 이는 MIST가 미래의 의료 영상 연구 및 개발에 강력한 도구로서의 잠재력을 가진다는 것을 강조합니다.



### Big Cooperative Learning (https://arxiv.org/abs/2407.21319)
- **What's New**: 기술 협력의 중요성은 인간 지능의 진화뿐만 아니라 최신 인공지능(AI) 혁명의 근간이 됩니다. 본 논문에서는 이른바 '빅 러닝(Big Learning)'을 제안하여 대규모 학습 작업들이 협력함으로써 데이터의 본질에 접근하는 방식을 설명합니다.

- **Technical Details**: 빅 러닝은 다양한 예측 관점에서 데이터의 본질을 탐구하는 협력적 학습 프레임워크입니다. 이는 대부분의 파운데이션 모델(foundation models)의 학습 목표를 통일하는 역할을 하며, 기존 모델들이 기반하는 가정을 동시에 노출시킵니다. 특화된 시뮬레이션을 통해 빅 러닝의 원리를 시연하였으며, 이를 토대로 파운데이션 모델의 성공을 학습 관점에서 정당화하고 흥미로운 부수적인 결과를 제공합니다.

- **Performance Highlights**: 빅 러닝은 전통적 머신 러닝 패러다임을 업그레이드할 수 있는 새로운 방향성을 제시하며, 관련 응용 프로그램들에 새로운 활력을 부여합니다. 예를 들어, 빅 러닝을 사용하여 기존 생상적 적대 신경망(GAN)을 업그레이드해 BigLearn-GAN이라는 새로운 기본 모델을 제안하였습니다. 이 모델은 다양한 데이터 샘플링 능력을 보유하여 다중 모달 설정에서 다방면의 교차 모달 생성을 가능케 합니다.



### Beyond Silent Letters: Amplifying LLMs in Emotion Recognition with Vocal Nuances (https://arxiv.org/abs/2407.21315)
- **What's New**: 본 연구는 대형 언어 모델(LLMs)을 이용한 음성 감정 인식에 대한 혁신적인 접근 방식을 소개합니다. 본 연구는 LLM이 직접 오디오 입력을 처리할 수 없는 한계를 해결하기 위해 음성 특징을 자연어 설명으로 번역하는 방법을 제안합니다. 이러한 설명은 텍스트 프롬프트에 통합되어, LLM을 아키텍처 변경 없이 멀티모달 감정 분석을 수행할 수 있게 합니다.

- **Technical Details**: 이 방법은 음성 특징을 자연 언어 설명으로 변환하고 이를 텍스트 프롬프트에 통합하여 LLM이 음성 기반 감정 분석을 수행할 수 있도록 합니다. 주요 구성 요소는 다음과 같습니다: 1) Instruction: LLM을 감정 분석 전문가로 포지셔닝, 2) Context: 대화 배경 제공, 3) Speech Descriptions: 오디오 신호를 자연어로 번역하여 음성 특성을 설명, 4) Question: 특정 발언에 대한 감정 레이블 선택 과제 제시.

- **Performance Highlights**: IEMOCAP 및 MELD 데이터셋을 사용한 평가에서, 본 연구 방법은 감정 인식 정확도에서 상당한 개선을 보여주었습니다. IEMOCAP 데이터셋의 가중치 F1 점수에서 2% 포인트 증가(70.111%에서 72.596%)가 나타났습니다. 다양한 LLM 아키텍처와 특징 표현의 효과를 비교한 결과, 고품질 오디오 데이터에서 특히 높은 성능을 보였습니다.



### EUDA: An Efficient Unsupervised Domain Adaptation via Self-Supervised Vision Transformer (https://arxiv.org/abs/2407.21311)
Comments:
          12 pages, 4 figures

- **What's New**: 최근 비전 트랜스포머(ViTs)의 높은 성과에도 불구하고, 복잡성과 많은 수의 학습 가능 매개변수로 인해 실제 응용에서 제한이 있습니다. 이를 해결하기 위해 EUDA(Efficient Unsupervised Domain Adaptation) 프레임워크를 도입했습니다. EUDA는 자신-지도 비전 트랜스포머(self-supervised ViT)인 DINOv2를 특징 추출기로 사용하고, 단순한 완전 연결층을 통해 특징을 정제하여 도메인 적응을 강화합니다. SDAL(Synergistic Domain Alignment Loss)을 통해 CE(Cross-Entropy)와 MMD(Maximum Mean Discrepancy) 손실을 통합해 적응을 최적화합니다.

- **Technical Details**: EUDA는 DINOv2를 특징 추출기로 사용하며, 네트워크의 데이터 중심 특징을 단순한 완전 연결층을 통해 정제합니다. 또한 SDAL(Synergistic Domain Alignment Loss)은 CE(Cross-Entropy)와 MMD(Maximum Mean Discrepancy) 손실을 결합하여 소스 도메인의 분류 오류를 최소화하면서 소스 및 타겟 도메인 분포를 정렬합니다. 이는 혼합된 손실 함수로 소스 도메인에서 분류 오류를 최소화하고 도메인 간 분포를 정렬하려는 목적을 갖습니다.

- **Performance Highlights**: EUDA는 기존 최첨단 방법들과 비교하여 42%에서 99.7% 적은 학습 가능 매개변수를 사용하면서 유사한 성능을 보여주었습니다. 이는 제한된 리소스 환경에서 모델을 훈련하는 데 효과적임을 입증합니다.



### Implementing Streaming algorithm and k-means clusters to RAG (https://arxiv.org/abs/2407.21300)
- **What's New**: 이 논문에서는 정보 검색을 위해 대규모 모델을 보조하는 외부 지식 데이터베이스를 구축한 Retrieval-augmented generation (RAG)의 문제를 해결하려고 합니다. 기존 RAG는 거대한 데이터베이스 때문에 메모리 소모가 크고, 대량의 스트리밍 데이터에 대해서는 즉각적으로 인덱스 데이터베이스를 업데이트하는 데 어려움을 겪습니다. 이러한 문제를 해결하기 위해 스트리밍 알고리즘과 k-means 클러스터링을 RAG와 결합한 새로운 접근 방식을 제안했습니다.

- **Technical Details**: 제안된 접근 방식은 스트리밍 알고리즘을 적용하여 인덱스를 업데이트하고 메모리 소비를 줄입니다. 그런 다음 k-means 알고리즘을 적용하여 유사성이 높은 문서를 클러스터링하여 쿼리 시간을 단축합니다. 이를 통해 데이터베이스를 구축하는 데 필요한 메모리를 절약하면서도 정확성을 유지할 수 있습니다.

- **Performance Highlights**: 네 가지 방법에 대한 비교 실험을 수행한 결과, 스트리밍 알고리즘과 k-means 클러스터링을 사용한 RAG가 정확성과 메모리 측면에서 우수한 성능을 보였습니다. 특히, 대규모 스트리밍 데이터에 대해 제안된 방법이 기존의 RAG보다 더 나은 성능을 발휘하는 것을 확인했습니다.



### Who should I trust? A Visual Analytics Approach for Comparing Net Load Forecasting Models (https://arxiv.org/abs/2407.21299)
Comments:
          Accepted for publication in the proceedings of 2025 IEEE PES Grid Edge Technologies Conference & Exposition (Grid Edge)

- **What's New**: 이 논문은 에너지 기획과 무역 및 부하 분포에 대한 의사 결정 지원을 위해 필수적인 순 부하 예측 모델을 비교하기 위한 시각 분석 기반 애플리케이션을 소개합니다. 이 애플리케이션은 태양광 침투 수준, 데이터셋 해상도 및 시각에 따른 모델 성능을 여러 달에 걸쳐 시각화하여 사용자가 모델 성능의 차이를 쉽게 식별할 수 있도록 도와줍니다.

- **Technical Details**: 주요 기술적 요소는 깊이 학습 기반 확률적 순 부하 예측 모델을 다루며, kPF(kernelized probabilistic forecasting) 모듈, 오토인코더(autoencoder, AE), 장기단기기억(LSTM, long short-term memory) 네트워크로 구성됩니다. 이 모델은 NREL과 SETO가 주최하는 Net Load Forecasting Prize 경연 대회에서도 사용되었습니다. 모델 비교를 위한 참조 모델(reference model)은 최근 30일 동안의 역사적 데이터를 이용해 확률적 예측을 생성합니다. 이를 기준으로 연속 순위 확률 점수(Continuous Ranked Probability Score, CRPS)와 CRPS 기술 점수(CRPSS)을 계산하여 성능을 평가합니다.

- **Performance Highlights**: 깊이 학습 모델이 전통적인 예측 모델보다 더 우수한 성능을 보여주었으나, 데이터 해상도가 낮은 경우(예: 1시간 간격)에는 성능이 저하되었습니다. 이를 해결하기 위해 kPF와 autoencoder를 제거하고 LSTM만을 이용한 모델을 개발했습니다. 최종적으로 검증된 결과, LSTM만으로 구성된 새로운 모델이 더 나은 성능을 보여주었습니다. 애플리케이션은 다양한 태양광 침투 수준과 시간대를 통해 모델 성능을 시각적으로 비교하고, 신뢰도를 높이는 데 도움을 줍니다.



### A Vectorization Method Induced By Maximal Margin Classification For Persistent Diagrams (https://arxiv.org/abs/2407.21298)
- **What's New**: 이 논문은 단백질 구조 분석에 효과적인 지속적 호몰로지(Persistent homology)를 이용한 보다 기하학적인 벡터화 기법을 제안합니다. 기존의 벡터화 방법이 지나치게 인위적이며 정보 활용 효율성과 방법의 합리성을 보장하지 못하는 문제를 해결하려고 합니다. 연구진은 Banach 공간에서 최대 마진 분류(Maximal margin classification) 기반의 새로운 벡터화 방법을 도입하고, 특정 기능을 가진 단백질을 식별하는 프레임워크를 제안합니다.

- **Technical Details**: 연구진은 지속적 도형(Persistent diagrams)을 포함한 공간을 Banach 공간으로 임베딩한 후, 최대 마진 분류 이론을 적용했습니다. 이는 고전적인 이차 프로그래밍 문제로 변환되며, 또한 유한한 지속적 도형 집합을 기반으로 벡터화를 정의했습니다. 이 논문은 지속적 도형에서의 분류 문제를 최소 계산을 필요로 하는 거리(metric)를 사용해 해결합니다.

- **Performance Highlights**: 연구진의 벡터화 방법은 단백질 데이터의 이진 분류 문제에 적용했을 때 기존의 13가지 벡터화 방법 중 가장 성능이 좋았던 통계적 방법보다 높은 정확도와 견고성을 보였습니다. 특히, 유전자 편집 기술과 관련된 Cas-associated 단백질 데이터에서 우수한 성능을 나타냈습니다.



### SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving (https://arxiv.org/abs/2407.21293)
Comments:
          16 pages, 3 figures

- **What's New**: 새로운 대형 언어 모델(Large Language Models, LLMs)의 빠른 발전은 다양한 분야에 큰 혜택을 줄 수 있습니다. 특히, 완전 자동 운전(end-to-end autonomous driving, e2eAD) 분야는 LLMs가 더 많은 모달리티를 지원하면서 새로운 기회를 맞이하고 있습니다. 이에 따라 저자들은 SimpleLLM4AD라 불리는 새로운 e2eAD 방법을 제안했습니다.

- **Technical Details**: SimpleLLM4AD는 비전-언어 모델(vision-language model, VLM)을 활용하여 e2eAD 태스크를 인식(perception), 예측(prediction), 계획(planning), 행동(behavior)이라는 네 단계로 나눕니다. 각 단계는 시각적 질문 응답(visusal question answering, VQA) 쌍으로 구성되며, 이러한 VQA 쌍들은 Graph VQA(GVQA)라는 그래프로 서로 연결됩니다. 비전 트랜스포머(vision transformers, ViT) 모델은 nuScenes 시각 데이터를 처리하기 위해 사용되며, VLM은 시각적 입력으로부터 추출된 정보를 해석하고 추론하는 데 활용됩니다.

- **Performance Highlights**: 저자들의 실험 결과, SimpleLLM4AD는 복잡한 주행 시나리오에서 경쟁력 있는 성능을 보여주었습니다. 네 단계의 구조를 통해 VQA 쌍을 체계적으로 추론할 수 있어 정보와 결정의 일관성을 유지합니다. 특히, VLM 통합은 시스템이 문맥을 이해한 결정을 내릴 수 있게 해주어 신뢰성과 안전성을 크게 향상시킵니다.



### Robust Box Prompt based SAM for Medical Image Segmentation (https://arxiv.org/abs/2407.21284)
Comments:
          Accepted by MICCAI MLMI 2024

- **What's New**: 새로운 연구에서는 Segment Anything Model(SAM)의 세분화 성능을 다양한 품질의 프롬프트(프롬프트)가 있을 때에도 향상시키기 위해 RoBox-SAM을 제안했다. 이는 임상 환경에서 발생할 수 있는 저품질 프롬프트의 문제를 해결하기 위한 것이다.

- **Technical Details**: RoBox-SAM은 세 가지 주요 기여를 한다. 첫 번째로, 프롬프트 정제 모듈(PRM)을 통해 잠재적인 타겟을 인지하고 저품질 박스 프롬프트를 고품질의 프롬프트로 변환하는 오프셋을 예측한다. 두 번째로, 프롬프트 향상 모듈(PEM)은 노이즈 있는 프롬프트와 최적화된 프롬프트 간의 이동 정보를 사용하여 자동으로 포인트 프롬프트를 생성한다. 마지막으로, 자기 정보 추출기(SIE)를 통해 입력 이미지에서 선행 정보를 추출하여 이미지 임베딩 및 주의 계산을 최적화한다. 이 기능들은 SAM의 이미지 임베딩과 주의 계산을 최적화함으로써, 프롬프트 품질에 관계없이 SAM의 강건성을 향상시킨다.

- **Performance Highlights**: 의료 세분화 데이터셋(총 99,299장 이미지, 5개 모달리티, 25개 장기/타겟)에서 광범위한 실험을 통해 RoBox-SAM의 효과가 입증되었다. RoBox-SAM은 다양한 품질의 박스 프롬프트에 대해서도 강건하며, 다양한 의료 이미징 모달리티와 타겟에 대해 뛰어난 성능을 달성한다.



### Unlocking the Potential of Binding Corporate Rules (BCRs) in Health Data Transfers (https://arxiv.org/abs/2407.21281)
- **What's New**: 이 논문은 EU GDPR(General Data Protection Regulation) 하에서 기업 그룹 내에서 건강 데이터의 안전한 전송을 관리하고 촉진하는 데 중요한 역할을 하는 Binding Corporate Rules(BCRs)에 대해 탐구합니다. 특히 건강 데이터 및 AI 기술 채택의 증가로 인한 도전에 대해 논의합니다.

- **Technical Details**: BCRs는 GDPR 및 유사한 국제 데이터 보호법을 준수하도록 설계되어 민감한 건강 및 유전체 데이터를 전송하는 유연한 메커니즘을 제공합니다. 이 장에서는 Schrems II 판결 이후 발표된 EDPB(European Data Protection Board) Recommendations 1/2022에 대해 비판적으로 분석하여 그 엄격한 요구사항과 데이터 보호 및 AI 관리 프레임워크를 우선 순위로 두는 균형 잡힌 접근 방식의 필요성을 강조합니다. 또한 BCR 승인 절차를 설명하며 이 절차를 간소화하여 BCR의 채택을 촉진할 필요성을 강조합니다.

- **Performance Highlights**: BCR은 투명성, 책임성 및 국제적 협력을 촉진하는 필수 도구로서 안전한 건강 데이터 관리를 위한 역할을 합니다. 논문은 BCR 채택을 장려하고 승인 절차를 간소화하며 혁신적인 접근 방식을 촉진하기 위한 선제적 조치의 필요성을 강조합니다. 이는 BCR이 글로벌 데이터 보호 및 준수를 위한 강력한 메커니즘으로 유지되도록 보장합니다.



### Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-N (https://arxiv.org/abs/2407.21273)
Comments:
          Accepted for the 5th International Workshop of Advances in Simplifying Medical UltraSound (ASMUS), held in conjunction with MICCAI 2024, the 27th International Conference on Medical Image Computing and Computer Assisted Intervention

- **What's New**: 새로운 MSU-Net 모델을 도입하여 초음파 이미지 분할에서 정확성과 불확실성 평가를 크게 향상시켰습니다. 이 모델은 Monte Carlo U-Net보다 18.1% 더 나은 성능을 보였으며, 특히 비전문가를 지원하는 데 유용합니다.

- **Technical Details**: MSU-Net은 여러 U-Net을 앙상블 (ensemble)로 훈련하는 다단계 접근법을 채택합니다. 이 모델은 디코더부분에 드롭아웃 (dropout)을 도입하여 Monte Carlo 샘플링을 통해 베이지안 추론을 근사합니다. 여러 개의 모델을 과잉생산하고 탈상관 (decorrelation)을 기반으로 최종 앙상블을 구성합니다.

- **Performance Highlights**: 초음파 이미지 세분화 (segmentation)에서 MSU-Net은 단일 Monte Carlo U-Net에 비해 18.1% 향상된 성능을 보였습니다. 이는 모델의 투명성과 신뢰성을 높이며, 안전한 주삽입을 지원합니다.



### DEF-oriCORN: efficient 3D scene understanding for robust language-directed manipulation without demonstrations (https://arxiv.org/abs/2407.21267)
- **What's New**: DEF-oriCORN은 언어 지향적인 조작 작업을 위한 새로운 프레임워크로 제안되었습니다. 객체 기반의 새로운 장면 표현 방식과 확산 모델 기반 상태 추정 알고리즘을 채택하여, 드문 카메라 시야에서도 효율적이고 견고한 조작 계획을 가능하게 합니다. 특히, 투명한 물체와 반사 물체를 포함한 다양한 재료에 대해 현실 세계에서 제로샷(Zero-shot) 일반화를 달성합니다.

- **Technical Details**: 이 프레임워크는 물체의 형태와 방향을 나타내는 신경 표현체 (neural representation)인 z𝑧z와 공간 점유 중심(c) 및 일련의 대표적인 기하학적 점(M)으로 표현된 물체 상태를 사용합니다. 또한 SO(3)-동변량 네트워크로 예비 학습을 거쳐 새로운 방향으로의 일반화를 가능하게 합니다. 충돌 검사는 신경 표현으로 직접 예측되며, 언어 명령의 객체 접지를 위해 CLIP을 사용합니다. 필셀을 기반으로 한 CLIP 피처를 계산하고, 물체 상태 𝐬의 레이 히팅(ray-hitting) 디코더를 통해 객체 접지를 평가합니다.

- **Performance Highlights**: DEF-oriCORN는 합성 및 실제 환경에서 추정, 그립 계획, 모션 계획, 그리고 언어 지향적 조작 문제에서 최첨단 성능을 뛰어넘는 정확성과 속도를 달성했습니다. 특히, 소수의 RGB 이미지와 제로샷 상황에서도 탁월한 성능을 발휘합니다.



### Tractable and Provably Efficient Distributional Reinforcement Learning with General Value Function Approximation (https://arxiv.org/abs/2407.21260)
- **What's New**: 이번 논문에서는 분포형 강화 학습 (Distributional Reinforcement Learning, DistRL)에서 일반적인 가치 함수 근사 방법을 사용하는 경우의 후회 (regret) 분석을 제시합니다. 특히, 제한된 에피소드 마르코프 결정 프로세스 (finite episodic Markov Decision Process) 설정에서 이를 다루고 있습니다. 논문은 새로운 개념인 벨만 불편성 (Bellman unbiasedness)를 도입하여 분포 업데이트를 통계적 함수적 동적 프로그래밍을 통해 정확하게 학습할 수 있는 방법론을 제시합니다. 이를 기반으로, 추정 방법으로 비선형 통계 함수적 (nonlinear statistical functionals)을 포함하여, 무한 차원 반환 분포를 유한한 개수의 모멘트 함수적 (moment functionals) 으로 근사할 수 있는 유일한 방법임을 이론적으로 증명합니다. SF-LSVI 알고리즘을 제안하고, $\tilde{O}(d_E H^{\frac{3}{2}}\sqrt{K})$의 후회 경계 (regret bound)를 입증합니다.

- **Technical Details**: SF-LSVI 알고리즘은 일반적인 가치 함수 근사 방법을 사용하여 통계 함수적 (statistical functionals)을 통해 분포형 강화 학습을 수행합니다. 이 알고리즘은 벨만 불편성을 만족하는 모멘트 함수적을 사용하여, 정확하게 학습할 수 있는 갱신 방법을 제공합니다. 벨만 불편성은 통계 함수적이 샘플링된 분포에서 목표 분포를 균형 있게 추정할 수 있는 성질입니다. 논문은 무한 차원 반환 분포를 표현하기 위해 유한한 수의 파라미터를 사용함으로써 발생하는 근사 오류를 다루며, 모멘트 함수적이 이러한 근사 오류를 최소화할 수 있음을 이론적으로 입증합니다.

- **Performance Highlights**: SF-LSVI 알고리즘은 후회 상한을 $\tilde{O}(d_E H^{\frac{3}{2}}\sqrt{K})$로 달성하여, 기존의 구조적 가정을 약화시키면서 더 나은 후회 경계를 제공합니다. 이는 RL에서 일반적인 기능 근사 값을 사용하는 경우의 성능 효율성을 입증합니다. 이러한 결과는 복잡한 실세계 상황에서도 더 안전하고 효과적인 결정론적 (deterministic) 결정을 내릴 수 있게 합니다.



### Lifelong Person Search (https://arxiv.org/abs/2407.21252)
Comments:
          10 pages, 6 figure

- **What's New**: 이번 논문에서는 기존의 단일 목표 데이터셋에만 적용되는 사람 검색(Person Search) 방법의 한계를 넘어, 새로운 문제로서 'Lifelong Person Search (LPS)'를 처음 소개했습니다. LPS는 새로운 데이터셋을 점진적으로 학습하면서도 이전 데이터셋에서 학습한 지식을 잃지 않고 유지하는 문제를 다루고 있습니다.

- **Technical Details**: 이 논문은 사람 검색(TF: Person Search)에서 발생하는 'Catastrophic forgetting' 문제를 해결하기 위해 새로운 방식의 종합적인 LPS 프레임워크를 제안합니다. 이 프레임워크는 구체적으로 다음 기술 요소를 포함합니다:
1. **Knowledge distillation**: 프로토타입 피쳐와 하드 백그라운드 제안을 활용해, 이전 모델과 새로운 모델 간의 일관성을 확보합니다.
2. **Rehearsal-based instance matching**: 라벨이 없는 사람 인스턴스를 부가적으로 사용해, 이전 도메인에서의 식별 능력을 늘립니다.
3. **End-to-end learning**: 사람 탐지와 재식별을 통합해 효율성을 극대화합니다.

- **Performance Highlights**: 제안된 방법은 LPS 시나리오에서 기존 방법들에 비해 월등히 높은 성능을 보였습니다. 실험 결과, 제안된 방법이 사람 탐지와 재식별 모두에서 이전 도메인에 대한 지식을 더 잘 유지함을 확인했습니다.



### VITAL: Visual Teleoperation to Enhance Robot Learning through Human-in-the-Loop Corrections (https://arxiv.org/abs/2407.21244)
- **What's New**: 본 논문은 VITAL이라는 저비용의 시각적 원격조작 시스템을 통해 로봇이 사람의 행동을 모방하여 새로운 기술을 습득하는 모방 학습(Imitation Learning, IL)의 데이터 수집 문제를 해결하고자 한다. 특히, 양손 조작 작업에 적합한 이 시스템은 저렴한 하드웨어와 시각 처리 기술을 활용하여 고품질 데모를 수집하고, 이를 확대하여 방대한 훈련 데이터셋을 만드는 방법을 제안한다.

- **Technical Details**: VITAL 시스템은 인간의 동작을 포착하기 위해 외부 RGB-D 카메라와 Bluetooth가 장착된 셀카 스틱을 사용하며, MediaPipe 라이브러리를 통해 상체의 24개 주요 포인트를 추적한다. 추적된 동작 데이터는 로봇 팔과 그립퍼의 실시간 명령으로 변환된다. 또한, AruCo 마커를 사용해 스틱의 방향을 추적하며, 인간-세계 기준 프레임을 안정적으로 구축하기 위해 어깨와 고관절 키포인트를 사용한다. 추가적으로, 두 팔의 길이 차이를 보완하기 위해 스케일링 팩터를 적용하여 원격조작의 직관성과 정밀성을 높였다.

- **Performance Highlights**: 본 방법은 다양한 복잡성의 작업(예: 병 수집, 물건 쌓기, 망치질)에서 실험을 통해 검증되었고, 인간의 실시간 피드백과 실제 데이터의 통합을 통해 로봇이 실제 업무에서 높은 성능을 발휘할 수 있음을 확인하였다. 또한, 새로운 작업(예: 음료 트레이 세팅)에서도 시스템의 적응성과 확장성을 입증하였다.



### Informed Correctors for Discrete Diffusion Models (https://arxiv.org/abs/2407.21243)
- **What's New**: 이 논문은 이산 공간에서 데이터 생성과 모델링을 위한 유망한 프레임워크인 이산 확산 모델링(Discrete diffusion modeling)을 다룹니다. 저자들은 표준 예측-보정(predictor-corrector) 전략의 한계를 인식하고, 모델이 학습한 정보를 활용해 더 신뢰성 있게 오차를 수정할 수 있는 '정보를 활용한 보정기(informed correctors)'를 제안합니다. 또한, k-Gillespie's라는 새로운 샘플링 알고리즘을 제안하여, $	au$	au$-leaping 대비 더 적은 계산 비용으로 더 높은 품질의 샘플을 생성할 수 있습니다.

- **Technical Details**: 일반적인 확산 모델링은 연속 공간에서의 이미지 생성 등에서 주로 사용되며, 여기에선 점차 데이터를 잡음으로 변환시키는 '전방 과정'과 이를 역으로 복원하는 '역방 과정'을 학습합니다. 최근에는 이러한 확산 모델을 이산 영역으로 확장하려는 연구가 진행 중입니다. 저자들은 특히 연속 시간 마코프 연쇄(CTMC)를 사용하는 TauLDR 모델을 분석하며, 흡수 상태 확산(absorbing state diffusion)에서 발생하는 문제를 해결하기 위해 정보 활용 보정기와 k-Gillespie's 알고리즘을 제안합니다.

- **Performance Highlights**: 여러 실제 및 인공 데이터셋에서 시험한 결과, k-Gillespie's 알고리즘과 정보 활용 보정기를 사용한 모델이 더 적은 계산 비용으로도 더 높은 품질의 샘플을 생성할 수 있음을 확인했습니다. 이를 통해 효율성과 샘플 품질 측면에서 큰 발전을 이룬 것을 입증하였습니다.



### Bug Analysis Towards Bug Resolution Time Prediction (https://arxiv.org/abs/2407.21241)
- **What's New**: 소프트웨어 개발에서 발생하는 버그를 해결하기 위해 Jira 이슈 트래킹 시스템에서 정보를 추출하고, 새 버그의 해결 시간을 예측하는 방법론을 제안합니다. 이 연구는 네트워크 프로젝트 ONAP에 적용되어 네트워크 소프트웨어화 프로젝트에서 버그 해결 시간과 관련된 인사이트를 제공합니다.

- **Technical Details**: 네트워크 소프트웨어화(Network softwarization)는 특정 애플리케이션을 위한 전용 하드웨어를 프로그래머블한 구성 요소로 대체하는 것을 말합니다. 이 연구에서는 Jira 이슈 트래킹 시스템을 사용하여 버그 데이터를 수집하고 분석하였으며, 버그 해결 시간을 예측하는 머신 러닝 모델을 제안합니다. 제안된 모델은 네트워크 프로젝트 ONOS, ONAP 등에 적용되었습니다.

- **Performance Highlights**: 연구의 주요 기여는 다음과 같습니다: 보고된 버그의 수집 전략과 필터링, 워크플로우에서 가장 일반적인 경로의 식별, 버그 해결 시간 분포 등의 기본 데이터 분석, 우선순위와 리포터의 영향 같은 고급 데이터 분석, 다양한 전략을 사용한 버그 해결 시간 예측 및 신경망을 사용한 개별 버그의 정확한 해결 시간 예측.



### TMA-Grid: An open-source, zero-footprint web application for FAIR Tissue MicroArray De-arraying (https://arxiv.org/abs/2407.21233)
Comments:
          NA

- **What's New**: 티슈 마이크로어레이(TMA) 분석을 위한 새로운 웹 애플리케이션, TMA-Grid가 개발되었습니다. 이 애플리케이션은 브라우저 내에서 구동되는 인터랙티브한 방식으로, 다운로드나 설치 없이 사용이 가능하며 데이터 프라이버시를 보장합니다. 사용자는 세그멘테이션(segmentation)과 그리드(grid) 조정 결과를 쉽게 조정할 수 있습니다.

- **Technical Details**: TMA-Grid는 정확한 티슈 세그멘테이션(tissue segmentation)을 위해 컨볼루션 신경망(convolutional neural network)을 통합하고, 각 코어(core)를 예상 위치와 매칭하기 위해 그리드 추정 알고리즘(grid estimation algorithm)을 사용합니다. 또한, 이 애플리케이션은 Findable, Accessible, Interoperable, Reusable(FAIR) 원칙에 따라 설계되어, TMA 연구 워크플로우와의 원활한 통합을 강조합니다.

- **Performance Highlights**: TMA-Grid는 어셈블리 오류로 인한 코어의 잘못된 정렬과 아티팩트를 효과적으로 처리할 수 있습니다. 사용자 친화적인 인터페이스 덕분에, 사용자가 쉽게 데이터 세그멘테이션과 그리드 조정을 할 수 있어 TMA의 다운스트림 분석을 더욱 신뢰성 있게 수행할 수 있습니다.



### Assessing Programming Task Difficulty for Efficient Evaluation of Large Language Models (https://arxiv.org/abs/2407.21227)
- **What's New**: 대형 언어 모델(LLMs)이 코드 작성 작업에서 탁월한 성능을 보이지만, 각 작업의 난이도를 평가하는 데 한계가 있었습니다. 이 논문에서는 'HardEval'이라고 불리는 새로운 프레임워크를 소개합니다. HardEval은 LLMs의 난이도를 평가하고, 새로운 어려운 작업을 생성할 수 있게 도와줍니다. 이를 통해 연구자와 실무자들이 더욱 정밀한 평가를 하여 LLMs의 성능을 개선할 수 있게 합니다.

- **Technical Details**: HardEval은 다양한 프로그래밍 작업에 대해 여러 LLMs를 활용하여 얻은 응답을 바탕으로 난이도를 평가합니다. 이를 위해 각 작업에 대해 다양한 프롬프트(prompts)를 생성하고, 이를 통해 코드 조각들을 수집한 후 작업 난이도를 계산합니다. 이 프레임워크는 HumanEval+와 ClassEval 두 가지 코드 생성 벤치마크를 사용했으며, 모든 작업에 대해 18개의 서로 다른 프롬프트를 만들었습니다. 그런 다음 CodeLLama, MagiCoder, DeepSeekCode, CodeGemma, GPT-3.5 등 5개의 LLM을 사용하여 각각의 응답을 수집하고, 이를 통해 기능적, 문법적 정확성을 분석했습니다.

- **Performance Highlights**: HardEval은 HumanEval+와 ClassEval 벤치마크에서 각각 어려운 작업을 21%와 27%로 식별하였습니다. 이는 기존 벤치마크의 평균 정확도와는 별개로 개별 작업의 난이도를 더 잘 평가할 수 있는 방법을 제공합니다. 또한, 특정 주제별 어려운 작업을 생성하기 위해 주제 모델링 기법인 BERTopic을 사용하였으며, 총 15개의 새로운 어려운 작업을 생성하는데 성공했습니다. 이러한 어려운 작업은 LLMs의 특정 약점을 밝혀내고 이를 개선하는 데 유용할 수 있습니다.



### AI methods for approximate compiling of unitaries (https://arxiv.org/abs/2407.21225)
- **What's New**: 이번 연구에서는 슈퍼컨덕팅 하드웨어에서 흔히 사용되는 고정된 2-큐빗 게이트와 임의의 1-큐빗 회전을 사용하는 유니터리(산을 표현하는 매트릭스)의 근사적 컴파일(approximate compiling)을 위한 인공지능(AI) 기법을 탐구합니다. 본 연구는 세 가지 주요 단계를 포함하며, AI 기반 접근법을 통해 초기 템플릿 선택, 초기 매개 변수 추정을 수행한 후, 이 매개변수를 최적화하여 회로의 신뢰도를 극대화합니다. 특히 2-큐빗 및 3-큐빗 유니터리들에 대한 성능 실험을 통해 기존 방법보다 유의미한 개선을 보여줍니다.

- **Technical Details**: 제안된 파이프라인은 템플릿 선택(deep learning을 통해 유니터리를 입력으로 템플릿을 선택), 매개변수 예측(autoencoder-like 모델을 통해 초기 매개 변수를 예측), 매개변수 최적화(gradient descent를 통해 매개 변수를 최적화)로 구성됩니다. 특히, 첫 번째 모델은 유니터리 매트릭스의 입력 값을 사용하여 예측된 템플릿을 선택하며, 두 번째 모델은 템플릿에서 초기 값을 제공하고 이 값을 기반으로 최적화 과정을 진행합니다. 만약 원하는 신뢰도를 얻지 못한 경우, 다른 템플릿을 선택하여 반복합니다.

- **Performance Highlights**: 2-큐빗 및 3-큐빗 유니터리에 대해 실험한 결과, 제안된 방법은 기존의 모든 템플릿에 대해 탐색(search)하거나 랜덤 초기화를 사용하는 방법에 비해 신뢰도와 성능 면에서 유의미한 향상을 보였습니다. 이러한 결과는 AI가 양자 컴퓨팅용 회로 변환(transpiling) 프로세스를 향상시키고, 현재 및 미래의 양자 하드웨어에서 보다 효율적인 연산을 지원할 수 있음을 시사합니다.



### GenRec: Generative Personalized Sequential Recommendation (https://arxiv.org/abs/2407.21191)
- **What's New**: GenRec는 '사전 훈련, 프롬프트, 예측'의 최근 패러다임에 영감을 받아, 연속 추천을 시퀀스-투-시퀀스(sequence-to-sequence) 생성(task)으로 간주하고, 새로운 모델을 제안했습니다. 이 모델은 사용자 및 항목의 명시적 표현을 학습하는 기존의 분류 기반 모델과 달리, Transformer의 시퀀스 모델링 능력을 활용하고, masked item prediction 목표를 채택하여 숨겨진 양방향 시퀀스 패턴을 효과적으로 학습합니다.

- **Technical Details**: GenRec는 수동으로 설계된 하드 프롬프트(hard prompts)에 의존하지 않으며, 텍스트 형식의 사용자 항목 시퀀스를 입력으로 받고, 상위 순위의 다음 항목을 출력으로 제공합니다. 이 모델은 Transformer 기반의 인코더-디코더(encoder-decoder)를 백본으로 사용하며, 시퀀스-투-시퀀스 생성(task)으로 연속 추천을 공식화합니다. 클로즈(cloze) 과제를 훈련 목표로 사용하여 모델을 사전 훈련시키고, 양방향 시퀀스 패턴을 학습합니다.

- **Performance Highlights**: GenRec는 공공의 실제 데이터셋에서 확실하게 일반화되어 최첨단 성과를 달성했습니다. 이 모델은 경량이며, 로우 리소스 환경에서 몇 시간만에 효과적으로 학습할 수 있어, 실제 시나리오 적용에 매우 유리하며, 연속 추천 도메인에서 대형 언어 모델의 민주화를 촉진할 수 있습니다.



### Multi-task Photonic Reservoir Computing: Wavelength Division Multiplexing for Parallel Computing with a Silicon Microring Resonator (https://arxiv.org/abs/2407.21189)
Comments:
          Main text: 11 figures, 3 tables. Supplementary material: 2 figures, 4 tables. The pre-print is under review in Frontiers: Advanced Optical Technologies. The abstract is shorter than in the PDF file to comply with arXiv requirements

- **What's New**: 최근 더 강력한 컴퓨팅 자원에 대한 요구가 증가하면서, 기존 Von Neumann 아키텍처를 벗어난 새로운 컴퓨팅 패러다임이 활발하게 연구되고 있습니다. 본 연구에서는 포토닉스(Photonics) 기반의 시간 및 파장 분할 다중화(Time and Wavelength Division Multiplexing, WDM)를 이용해 하나의 포토닉 칩(Photonic Chip)에서 네 가지 독립적인 작업을 동시에 해결하는 개념 증명을 제시합니다. 이는 저장형 컴퓨팅(In-Memory Computing)의 병목 문제를 해결할 수 있는 가능성을 제시합니다.

- **Technical Details**: 시스템은 마이크로링 공진기(Microring Resonator, MRR)를 기반으로 한 시간 지연 저수지 컴퓨팅(Time-Delay Reservoir Computing, TDRC)로 구성됩니다. 다루는 작업은 시계열 예측, 파형 신호 분류, 무선 채널 균일화 및 레이더 신호 예측을 포함합니다. 시간 분할 다중화(Time-Division Multiplexing)를 통해 신경망의 노드 역할을 하는 요소들을 효율적으로 배치하고, WDM을 통해 각각의 작업을 병렬화합니다. 각 광학 채널의 입력 전력 및 주파수를 조정하여, 각 작업의 성능을 단일 작업 운영에 초점을 맞춘 최신 보고서에 상응하는 수준으로 유지할 수 있습니다.

- **Performance Highlights**: 시스템은 동일 작업의 최대 10개의 인스턴스를 동시에 계산할 수 있으며, 우수한 성능을 입증했습니다. 또한, 메모리 용량과 비선형성도 분석되어 각 작업 성능과의 상관관계를 도출했습니다. 본 연구는 병렬 계산(Parallel Computing)의 새로운 가능성을 제시하며, 피드백 메커니즘의 영향도 탐색합니다.



### AI Safety in Practice: Enhancing Adversarial Robustness in Multimodal Image Captioning (https://arxiv.org/abs/2407.21174)
Comments:
          Accepted into KDD 2024 workshop on Ethical AI

- **What's New**: 이 논문은 시각적 및 텍스트 데이터를 결합한 멀티모달 이미지 캡셔닝 모델(multimodal image captioning models)의 공격 저항성을 강화할 효과적인 전략을 제시합니다. FGSM(Fast Gradient Sign Method)를 이용해 적대적 예제(adversarial examples)를 생성하고 적대적 훈련(adversarial training) 기법을 적용해 두 개의 벤치마크 데이터셋인 Flickr8k와 COCO에서 모델의 저항성을 향상시켰음을 입증합니다. 특히, 멀티모달 아키텍처의 텍스트 디코더(text decoder)만 선택적으로 훈련하는 접근법이 계산 효율성을 높이면서도 전제 훈련과 유사한 성능을 보여줍니다.

- **Technical Details**: 이 연구는 이미지 캡셔닝 작업을 위해 GPT-2와 Vision Transformer(ViT) 모델을 결합하는 아키텍처를 사용합니다. ViT는 이미지를 작은 패치로 나누어 이를 평평하게 하고 선형적으로 투영하여 변환합니다. ViT의 [CLS] 토큰이 이미지의 전체적인 맥락적 측면을 캡처한 후 GPT-2 디코더가 이를 이용해 캡션을 생성합니다. FGSM을 활용해 적대적 예제를 생성하고, 모델 파라미터에 대한 손실 함수의 그래디언트를 사용해 작은 교란을 추가하는 방식으로 적대적 예제를 만듭니다.

- **Performance Highlights**: Flickr8k와 COCO 데이터셋에서 실험한 결과, 텍스트 디코더만을 훈련해도 전체 모델을 훈련했을 때와 유사한 성능을 보였습니다. 반대로, 텍스트 디코더를 고정하고 이미지 인코더만 훈련할 경우 성능이 크게 저하되었습니다. 이는 텍스트 디코더가 공격 저항성을 높이는 데 중요한 역할을 한다는 것을 시사합니다.



### Understanding Public Safety Trends in Calgary through data mining (https://arxiv.org/abs/2407.21163)
Comments:
          14 pages

- **What's New**: 이 논문은 캘거리의 다양한 공공 데이터 세트를 활용하여 지역 범죄, 무질서, 교통사고의 패턴과 통찰력을 밝혀냅니다. 인구 통계, 주택 및 애완동물 등록과 같은 지역 특성을 지리 공간 시각화 및 상관 분석을 통해 분석하였습니다. chi-square 테스트를 사용하여 강하게 상관된 특징을 식별하고, 연관 규칙 마이닝과 머신 러닝 알고리즘을 사용하여 예측 모델을 구축했습니다. 그 결과 범죄율은 인구 밀도와 밀접하게 연관되어 있으며, 애완동물 등록은 큰 영향을 미치지 않는다는 것을 발견했습니다. 이 연구는 도시 관리자에게 커뮤니티 안전 전략을 향상시키기 위한 귀중한 통찰력을 제공합니다.

- **Technical Details**: 이 연구는 캘거리, 캐나다를 사례로 하여 거리 조명, 나무, 교통사고, 범죄, 애완동물 등록, 인구 조사 데이터, 커뮤니티 보안 및 교통 카메라 데이터 등 다중 출처 도시 데이터를 활용했습니다. 이 연구는 K-Means 및 DBSCAN과 같은 군집화 알고리즘의 성능 향상을 위해 CLARANS 및 CLIQUE와 같은 고급 군집화 알고리즘을 도입하고 매개변수 최적화를 통해 성능을 향상시켰습니다. 또한, 공간 데이터 마이닝 기법을 사용하여 커뮤니티 안전에 영향을 미치는 주요 요인을 탐구하고 예측 모델을 구축했습니다.

- **Performance Highlights**: 협회 규칙 마이닝 및 머신 러닝 알고리즘을 사용하여 예측 모델을 작성했습니다. 그 결과, 범죄율은 인구 밀도와 밀접하게 연관되어 있으며, 애완동물 등록은 범죄율에 작은 영향을 미치는 것으로 나타났습니다. 데이터 전처리 후, 정리된 데이터는 Panda 데이터 프레임으로 로드되어 추가 청소 및 분석을 수행했습니다. 지리 좌표가 없는 데이터세트는 Python 스크립트를 통해 각 자릿수와 경도좌표를 할당하여 군집 분석을 수행했습니다. 예측 모델은 실제 데이터를 기반으로 하여 도시 관리 의사 결정을 지원하고 커뮤니티 안전 전략 향상에 기여할 수 있는 새로운 통찰력을 제공합니다.



### Private Collaborative Edge Inference via Over-the-Air Computation (https://arxiv.org/abs/2407.21151)
Comments:
          15 pages, 8 figures. This work extends from our preliminary study presented at the 2022 IEEE International Symposium on Information Theory [1]. arXiv admin note: text overlap with arXiv:2202.03129

- **What's New**: 이번 연구에서는 각 클라이언트 모델이 로컬 데이터셋에서 독립적으로 학습되는 무선 엣지의 협력적 추론(collaborative inference)을 고려합니다. 특히, 우리는 다중 액세스 채널(multiple access channel)에서 중첩(superposition) 특성을 활용하여 대역폭 효율적인 다중 사용자 추론 방법을 제안합니다.

- **Technical Details**: 우리는 데이터 정확도를 극대화하는 동시에 로컬 모델의 프라이버시를 보장하기 위해 노력했습니다. 오버 더 에어(over-the-air) 연산 방식을 활용한 앙상블(ensemble) 및 멀티 뷰(multi-view) 분류 방법을 제안했습니다. 이 방법들은 통계적으로 유의미한 차이로 기존의 직교 접근법보다 더 나은 성능을 보였으며, 자원을 적게 소비하고 프라이버시를 보장합니다.

- **Performance Highlights**: 제안된 오버 더 에어 멀티 사용자 추론 방법의 이점을 증명하기 위한 실험 결과를 제공하고, 설계 선택의 효과를 입증하기 위해 ablation study도 수행했습니다. 이를 위한 프레임워크의 소스 코드는 추가 연구와 재현성을 위해 Github에 공개했습니다.



### Domain Shift Analysis in Chest Radiographs Classification in a Veterans Healthcare Administration Population (https://arxiv.org/abs/2407.21149)
- **What's New**: 이 연구는 도메인 이동(domain shift)과 흉부 X-레이 분류 정확도에 대한 영향을 평가하고, 라벨의 품질과 인구통계학적 요인(연령, 성별, 연구 연도)의 영향을 분석합니다.

- **Technical Details**: 연구에는 DenseNet121 모델을 사용하여 MIMIC-CXR 데이터셋에서 사전 학습된 딥러닝 기반 다중 레이블 분류(Multi-label Classification)을 수행했습니다. 레이블은 CheXpert와 CheXbert 라벨러를 사용하여 방사선 보고서에서 추출했습니다. MIMIC-CXR와 VA-CXR 데이터셋의 14개 흉부 X-레이 라벨 성능을 비교했습니다. VA-CXR은 2010년부터 2022년까지의 259k 이상의 흉부 X-레이 이미지를 포함합니다.

- **Performance Highlights**: 연구 결과, 다양한 NLP 추출 도구를 사용한 다중 라벨 분류 성능 검증에서 VA-CXR 데이터셋이 MIMIC-CXR 데이터셋보다 낮은 불일치율을 보였습니다. CheXpert와 CheXbert를 사용하는 모델 간 AUC 점수에서 차이가 나타났으며, 'Enlarged Cardiomediastinum' 라벨을 제외하고는 미지의 데이터 셋에서 도메인 이동이 최소화되었습니다. 연구 연도의 하위 그룹 분석에서 다중 라벨 분류 모델 성능의 가장 큰 변이가 나타났습니다.



### Zero Shot Health Trajectory Prediction Using Transformer (https://arxiv.org/abs/2407.21124)
- **What's New**: ETHOS는 Transformer 아키텍처를 사용하여 높은 차원성과 이질적이며 에피소드적인 건강 데이터를 분석하는 혁신적인 접근 방식을 제안합니다. 이를 통해 환자의 건강 기록을 토큰화하여 미래의 건강 경로를 예측함으로써 의료 분석의 새로운 지평을 열었습니다. 또한, 별도의 라벨링 데이터나 모델의 세부 조정 없이 다양하고 특이한 상황에 대한 예측이 가능합니다.

- **Technical Details**: ETHOS는 Patient Health Timelines (PHTs)를 이용합니다. PHT는 환자의 건강 이벤트를 시간 순으로 상세하게 토큰화한 데이터입니다. ETHOS는 이러한 PHT를 바탕으로 미래의 건강 기록 (fPHT)을 토큰 단위로 예측합니다. 이 모델은 MIMIC-IV v.2.2 데이터셋을 활용하여 훈련되었으며, 데이터의 노이즈를 추가적인 클리닝 없이 그대로 사용하였습니다. 이를 통해 데이터의 불일치나 누락된 정보에 대한 강력한 내성을 확인하였습니다.

- **Performance Highlights**: ETHOS는 입원 및 중환자실 사망률 예측, ICU 체류 기간 예상, 재입원 확률 결정 등의 다양한 작업에서 제로샷 학습(Zero-shot learning) 능력을 입증했습니다. 또한, 중환자실 입원 시점의 첫날 Sequential Organ Failure Assessment (SOFA) 점수를 예측하는 회귀 작업에서도 뛰어난 성능을 보였습니다. 이 밖에도 진단 관련 그룹(DRG) 분류 작업에 성공하여 다양한 응용 가능성을 보여줍니다.



### High-Dimensional Fault Tolerance Testing of Highly Automated Vehicles Based on Low-Rank Models (https://arxiv.org/abs/2407.21069)
Comments:
          Accepted by ITSC 2024

- **What's New**: 이 연구는 고자동화차량(HAV)의 결함 주입(Fault Injection, FI) 테스트를 가속화하기 위해 저순위(Low-rank) 매트릭스 인수분해(Matrix Factorization) 모델을 제안합니다. 특히 'Smoothness Regularized Matrix Factorization (SRMF)' 프레임워크를 활용하여 안전성과 성능을 예측하고, HAV의 결함 탐지를 개선합니다. 이는 결함 주입 테스트에 저순위 모델을 도입한 최초의 연구입니다.

- **Technical Details**: SRMF는 고차원의 테스트 공간을 저차원의 구조로 변환하여 결함 주입 테스트를 수행합니다. 여기에는 세 가지 유형의 'Smoothness Regularization'이 추가된 저순위 제약이 사용됩니다. 먼저, 평가된 데이터를 안전 값에 따라 구조화된 매트릭스로 정리한 후, 매트릭스 구조에서 포착된 상관관계를 통해 테스트하지 않은 값을 추정합니다. 이 접근법을 통해 결함 매트릭스의 전체 패턴을 저순위 속성으로 포착하며, 새로운 시나리오 평가없이 예측할 수 있습니다.

- **Performance Highlights**: 실험 결과에 따르면, SRMF는 기존 머신러닝 모델에 비해 다양한 시나리오에서 가장 낮은 예측 오류를 기록하였으며, 희귀한 치명적 결함을 예측하는 데 우수한 성능을 보였습니다. 또한, 1171배의 가속률, 99.3%의 정밀도 및 91.1%의 F1 점수를 달성하여 HAV의 치명적 결함을 효율적으로 식별할 수 있음을 보였습니다.



### ELP-Adapters: Parameter Efficient Adapter Tuning for Various Speech Processing Tasks (https://arxiv.org/abs/2407.21066)
- **What's New**: 본 논문에서는 ELP-adapter tuning을 제안합니다. 이는 파라미터 효율적인 미세조정을 위해 3가지 어댑터를 사용하는 새로운 방법입니다. 구체적으로, E-adapter(encoder adapter), L-adapter(layer adapter), P-adapter(prompt adapter)로 구성되어 있습니다. 이를 통해 다양한 음성 처리 작업에 맞게 모델을 빠르게 적응시킬 수 있습니다.

- **Technical Details**: E-adapter는 Transformer 기반 인코더 레이어에 통합되어 세밀한 음성 표현을 학습하며, 이는 음성 인식에 효과적입니다. L-adapter는 각 인코더 레이어에서 다운스트림(head)으로의 경로를 만들어 비언어적 특징을 추출하며, 이는 화자 검증과 감정 인식 작업에 유용합니다. P-adapter는 CNN 특징에 의사 특성을 추가하여 효과성과 효율성을 더욱 향상시킵니다. 제안된 ELP-adapter tuning은 Self-supervised 모델을 사용하는 모든 다운스트림 작업에 적용될 수 있습니다.

- **Performance Highlights**: 4개의 다운스트림 작업(음성 인식, 화자 검증, 감정 인식, 의도 분류)에 대해 5개의 Backbone 모델을 사용한 평가를 통해 제안된 방법의 효능을 확인했습니다. 특히, WavLM backbone을 사용할 때, 제안된 방법은 학습 가능한 파라미터 수를 90% 줄이면서도 대부분의 작업에서 기존의 풀 파인튜닝(full fine-tuning) 방법에 비해 성능이 동등하거나 우수했습니다.



### Using Large Language Models for the Interpretation of Building Regulations (https://arxiv.org/abs/2407.21060)
Comments:
          Presented at the 13th Conference on Engineering, Project and Production Management

- **What's New**: 이번 연구에서는 건축 프로젝트의 필수 요소인 규제 준수 검사를 자동화하기 위해 대형 언어 모델(LLMs)인 GPT-3.5를 사용하여 건축 규정을 LegalRuleML로 변환하는 성능을 평가합니다. BIM의 확산으로 인해 디지털 건축 설계 데이터를 쉽게 공유할 수 있게 되면서 자동화된 규제 준수 검사(ACC)에 더 많은 기회가 생겼습니다.

- **Technical Details**: GPT-3.5를 이용하여 few-shot learning 설정에서 건축 규정을 LegalRuleML로 변환하는 작업을 평가하였습니다. 몇 가지 예시 번역만 제공하여도 GPT-3.5가 형식의 기본 구조를 학습할 수 있으며, 시스템 프롬프트를 통해 LegalRuleML 표현을 명확히 지정하고 도메인 전문가 지식의 존재를 탐구합니다. Chain-of-thought reasoning과 self-consistency와 같은 전략의 적용 가능성 또한 조사합니다.

- **Performance Highlights**: GPT-3.5는 광범위한 사전 학습을 통해 도메인 적응에 있어 더 나은 성능을 보일 수 있으며, 이를 통해 ACC에서 더욱 효율적이고 효과적인 검사 프로세스를 지원할 수 있을 것으로 기대됩니다.



### Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks (https://arxiv.org/abs/2407.21059)
- **What's New**: 이번 논문에서는 기존의 취득-생성(Retrieval-augmented Generation, RAG) 패러다임의 한계를 검토하고, 모듈식 RAG(Modular RAG) 프레임워크를 도입했습니다. 복잡한 RAG 시스템을 독립적인 모듈과 특화된 연산자로 분해함으로써, 보다 유연하고 재구성 가능한 구조를 제공합니다. 그런 방식으로, 전통적인 선형 아키텍처를 넘어 라우팅, 스케줄링, 융합 메커니즘을 통합한 더욱 발전된 디자인을 채택하고 있습니다.

- **Technical Details**: 모듈식 RAG는 세 가지 레벨로 구성된 아키텍처를 제공합니다. 상위 레벨에서는 RAG의 중요한 단계를 독립적인 모듈로 처리하고, 중간 레벨은 각 모듈 내에 하위 모듈을 구성하여 기능을 세분화하며, 하위 레벨에서는 연산자의 기본 단위로 구성됩니다. 이 프레임워크에서 RAG 시스템은 계산 그래프 형태로 표현될 수 있으며, 노드는 특정 연산자를 나타냅니다.

- **Performance Highlights**: 모듈식 RAG의 주요 장점은 유연성과 확장성이 뛰어나다는 것입니다. 사용자는 데이터 소스와 작업 시나리오의 요구사항에 따라 다양한 모듈과 연산자를 유연하게 결합할 수 있습니다. 논문에서는 모듈식 RAG의 6가지 대표적인 흐름 패턴을 요약하고, 실용적인 시나리오에서의 범용성을 위해 구체적인 방법을 분석했습니다. 이를 통해 시스템의 유지보수와 이해도를 강화하면서, 새로운 방법의 적응과 확장에 대한 가이드를 제공합니다.



### Understanding the Interplay of Scale, Data, and Bias in Language Models: A Case Study with BER (https://arxiv.org/abs/2407.21058)
- **What's New**: 본 연구는 BERT 모델의 크기와 사전 학습 데이터가 사회적 편견과 고정관념에 어떤 영향을 미치는지 분석합니다. 특히, 모델 스케일이 커짐에 따라 상류(upstream)와 하류(downstream) 작업에서 나타나는 편견의 변화를 조사합니다.

- **Technical Details**: 네 가지 구성 크기의 BERT 모델(mini, small, medium, base)을 실험 대상으로 사용하였으며, 영어 Wikipedia와 Common Crawl(CC-100)의 영어 서브셋을 사전 학습 데이터로 활용하였습니다. 상류 편견은 성별 대명사의 확률과 생성된 텍스트의 감정(sentiment)을 통해 측정되었고, 하류 영향은 유독성 분류 작업에서 다양한 인구 집단의 거짓 양성률(false positive rate) 차이로 평가되었습니다.

- **Performance Highlights**: Common Crawl로 사전 학습된 모델의 경우, 모델 크기가 커질수록 상류 편견이 증가했습니다. 반면, Wikipedia로 사전 학습된 모델은 모델 크기가 커질수록 성별 고정관념이 더 많이 나타났습니다. 두 경우 모두 하류 작업에서는 모델 크기가 커질수록 편견이 감소하는 경향을 보였습니다. 그러나 'gay'와 'homosexual' 같은 특정 정체성을 유독성과 연관짓는 경향은 모델의 크기나 사전 학습 데이터와 관계없이 일관되게 나타났습니다.



### Multi-group Uncertainty Quantification for Long-form Text Generation (https://arxiv.org/abs/2407.21057)
- **What's New**: 최근 연구에서는 대형 언어 모델(Large Language Models, LLM)의 사실 오류와 환각(hallucinations)을 줄이기 위해 불확실성(uncertainty) 정량화 방법을 도입했습니다. 이 연구는 전통적인 전역 데이터 분포뿐만 아니라 개별 하위그룹의 분포에서도 유효한 불확실성 보증을 제공하는 멀티 캘리브레이션(multicalibration) 및 멀티발리드 컨포멀 예측(multivalid conformal prediction)을 도입했습니다.

- **Technical Details**: 연구는 전반적인 도메인과 개별 클레임(claim) 수준에서의 불확실성을 조사했습니다. 특히, (1) 개별 클레임의 사실성을 보증하기 위해 멀티 캘리브레이션(Hebert-Johnson et al., 2018)을 사용하고, (2) 전체 클레임 세트의 불확실성을 보증하기 위해 멀티발리드 컨포멀 예측(Jung et al., 2022)을 적용했습니다. 전형적인 전역 캘리브레이션 및 컨포멀 방법과 대비할 때 멀티 캘리브레이션 및 멀티발리드 컨포멀 예측 기술이 불확실성 측면에서 더 나은 성능을 보였습니다.

- **Performance Highlights**: 이 연구는 전기 생성(biography generation)을 테스트베드로 사용하여 사실성의 멀티그룹 불확실성 정량화를 평가했습니다. 멀티 캘리브레이션 및 멀티발리드 컨포멀 예측 기법이 표준 캘리브레이션 및 컨포멀 예측 방법에 비해 그룹 내부 및 전체 데이터셋에서 불확실성 측정값을 개선하는 것을 실험적으로 입증했습니다.



### Sentiment Reasoning for Healthcar (https://arxiv.org/abs/2407.21054)
Comments:
          Preprint, 18 pages

- **What's New**: 이 논문은 감정 분석 작업에 있어 중요한 새로운 과제인 'Sentiment Reasoning'을 소개합니다. 이는 사람의 감정을 더 깊고 맥락적으로 이해하기 위해 고안을 했습니다. 이 접근 방식은 텍스트와 음성 모달리티를 모두 포함하며, 새로운 멀티태스킹 프레임워크와 데이터셋을 제안합니다.

- **Technical Details**: 이 연구는 멀티모달 감정 분석 프레임워크를 제안하며, 이를 위해 MultiMed-SA라는 데이터셋을 사용합니다. 이 데이터셋은 의사와 환자 간의 대화 내용을 포함하고 있으며, 감정 레이블과 그에 대한 논리를 주석으로 달았습니다. 제안된 프레임워크는 ASR (Automated Speech Recognition)을 통해 생성된 텍스트와 사람의 대화 내용을 기반으로 훈련됩니다. 이를 통해 AI가 더 깊이 있는 감정 분석을 할 수 있도록 Chain-of-Thought (CoT)를 통합하여 학습시킵니다.

- **Performance Highlights**: 실험 결과, 논리 보강 학습(rationale-augmented training)을 통해 감정 분류 성능이 향상되었습니다. 이는 사람의 대화 내용과 ASR 환경 모두에서 유효했으며, 생성된 논리가 인간이 작성한 논리와 비슷한 의미를 유지하면서도 다른 어휘를 사용하는 것을 확인했습니다.



### Knowledge Models for Cancer Clinical Practice Guidelines : Construction, Management and Usage in Question Answering (https://arxiv.org/abs/2407.21053)
- **What's New**: 새롭게 제안된 자동화 지식 모델링 알고리즘이 암 임상 진료 지침(CPGs)의 복잡한 내용을 효율적으로 추출하고 프로그램적으로 상호 작용할 수 있는 구조화된 모델로 변환합니다. 이번 연구에서는 National Comprehensive Cancer Network (NCCN)에서 제공하는 네 가지 암 유형에 대한 CPGs를 대상으로 한 알고리즘을 개선하여 제안했습니다.

- **Technical Details**: 제안된 알고리즘은 기존 알고리즘과 달리 다양한 암 유형에 대한 CPGs의 복잡한 지식을 처리할 수 있습니다. 또한, 알고리즘은 새로운 버전의 지침서에서 도입된 특정 변경 사항을 발견하기 위해 서로 다른 버전의 지식 모델을 비교하는 기능을 갖추고 있습니다. 지침서 지식 모델을 보강된 지식 기반으로 활용하여 Q&A 프레임워크를 구축했습니다. Non-Small Cell Lung Cancer (NSCLC) 치료에 대한 신뢰성 있는 두 데이터 소스에서 가져온 32개의 Q&A 세트를 사용해 이 프레임워크를 평가했습니다.

- **Performance Highlights**: Q&A 프레임워크는 하나의 데이터 소스에서 가져온 Q&A 세트로 평가되었으며, 치료 알고리즘에서 54.5% 정확도, NCCN NSCLC 지침서의 논의 부분에서는 81.8% 정확도로 답변을 생성할 수 있었습니다.



### Table-Filling via Mean Teacher for Cross-domain Aspect Sentiment Triplet Extraction (https://arxiv.org/abs/2407.21052)
Comments:
          Accepted by CIKM2024

- **What's New**: 이 논문은 Cross-domain Aspect Sentiment Triplet Extraction (ASTE) 작업에서 새로운 접근법을 제안합니다. 전통적인 방식이 사전 훈련된 언어 모델(Pre-trained Language Models, PLMs)을 사용해 대량의 합성 데이터를 생성하는 데 많은 컴퓨팅 자원을 소모하는 반면, 저자들은 두 단계 객체 탐지(OD, Object Detection) 방법에서 영감을 받아 테이블 채우기(table-filling) 방법을 사용합니다. 그 결과, TFMT(Table-Filling via Mean Teacher)라는 새로운 방법을 소개합니다.

- **Technical Details**: TFMT는 문장을 2차원 테이블로 인코딩하여 단어 간의 관계를 감지합니다. 이 테이블을 특징 맵(feature map)으로 간주하고 영역 일관성(region consistency)을 사용해 생성된 의사 레이블(pseudo-labels)의 품질을 향상시킵니다. 또한, 도메인 간 차이를 줄이기 위해 최대 평균 불일치(Maximum Mean Discrepancy, MMD)를 기반으로 한 교차 도메인 일관성을 설계했습니다. TFMT는 학생 모델과 교사 모델로 구성된 mean teacher 아키텍처를 활용하여 도메인 적응(domain adaptation)을 안내합니다.

- **Performance Highlights**: TFMT는 기존 방법보다 적은 매개변수와 컴퓨팅 비용으로 최첨단 성능을 달성합니다. 합성 데이터 생성에 의존하지 않기 때문에 이전 접근법보다 상대적으로 간단하면서도 강력한 성능을 보여줍니다. 이 방법은 크로스 도메인 ASTE 작업에 새로운 기준선(strong baseline)을 제시하며 후속 연구에 영감을 줄 수 있습니다.



### Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieva (https://arxiv.org/abs/2407.21049)
Comments:
          29 pages, 18 figures

- **What's New**: 최근 발표된 arxiv 논문에서는 코드 생성 모델들이 긴 문맥 의존성을 다루는 능력을 평가하기 위한 새로운 접근 방식을 제안했습니다. 특히, 최대 8k 토큰 길이의 문맥 창(context windows)에서 여러 단계의 키 검색 작업(multi-step key retrieval tasks)을 사용하여 다양한 모델의 성능을 평가하였습니다.

- **Technical Details**: 이 연구는 문맥 창에서 점점 더 길어지는 의존성을 다루는 코드 생성 모델의 능력을 평가하기 위한 네 가지 키 검색 작업(one-step, two-step, three-step, and concatenation retrieval)을 제안했습니다. 각각의 작업은 단계별로 난이도가 증가하며, 이는 모델이 여러 조각의 정보를 통합하여 완료할 수 있는 능력을 테스트합니다. 또한, 모델이 매개변수 지식(parametric knowledge)에 의존하지 않도록 함수 이름과 반환 값을 임의의 문자열로 구성하여 모델이 실제로 문맥에서 주어진 정보를 활용하도록 요구했습니다.

- **Performance Highlights**: 연구 결과, 함수가 나중에 정의된 다른 함수를 참조할 때 성능은 최대 2배까지 저하되었으며, 슬라이딩 윈도우 주의 메커니즘을 사용하는 모델은 단일 윈도우 크기보다 멀리 있는 참조를 처리하는 데 어려움을 겪었습니다. 그러나 호출 그래프 정보(call graph information)를 사용하여 프롬프트를 단순히 수정함으로써 다단계 검색 성능을 최대 3배까지 향상시킬 수 있었습니다. 이 연구는 코드 완성 도구에 대한 프롬프트 구성 전략을 시사합니다.



### APTNESS: Incorporating Appraisal Theory and Emotion Support Strategies for Empathetic Response Generation (https://arxiv.org/abs/2407.21048)
Comments:
          Appectped to CIKM2024

- **What's New**: 새로운 AI 프레임워크 APTNESS는 감정지원 전략 및 평가 이론을 통합하여, LLM(대규모 언어 모델)의 인지적 및 감정적 공감 능력을 향상시킵니다.

- **Technical Details**: APTNESS는 검색 증강(Retrieval Augmentation)과 감정지원 전략을 결합한 프레임워크입니다. 감정 팔레트(emotional palette)를 도입하고 평가 이론(Appraisal Theory)에 따라 이를 분해하여 감정 반응 데이터베이스를 구축합니다. 이 데이터베이스는 외부 자원으로 작용하여 LLM의 공감을 증진시킵니다. 감정지원 전략(emotional support strategy)을 통합하여 인지적 공감(cognitive empathy)뿐만 아니라 감정적 공감(affective empathy)도 풍부하게 표현할 수 있습니다.

- **Performance Highlights**: 실험 결과, APTNESS 프레임워크는 다양한 LLM에서 인지적 및 감정적 공감 능력을 크게 향상시켰습니다. 특히, ED와 ET 데이터셋을 사용한 자동화된 턴 기반 평가에서 뛰어난 성능을 보였습니다.



### Unlocking the Potential: Benchmarking Large Language Models in Water Engineering and Research (https://arxiv.org/abs/2407.21045)
- **What's New**: 최근 대형 언어 모델(LLMs)의 발전이 다양한 분야에서의 응용 가능성에 대한 관심을 불러일으켰습니다. 본 논문은 이러한 LLMs가 '수자원 전문가 모델'로서의 역할을 효과적으로 수행할 수 있는지를 평가하는 첫 번째 연구입니다. 이를 위해 특수 도메인 벤치마크 스위트(WaterER)를 테스트하여, 수자원 공학 및 연구 작업에 대한 983개의 작업을 준비하고 이를 평가했습니다. 여기에는 폐수 처리, 환경 복원, 음용수 처리 및 분배, 위생, 혐기성 소화, 오염 물질 평가가 포함됩니다.

- **Technical Details**: 일곱 개의 LLMs(GPT-4, GPT-3.5, Gemini, GLM-4, ERNIE, QWEN, Llama3)가 983개의 특정 수자원 공학 및 연구 작업에서 평가되었습니다. 특히, GPT-4는 다양한 복잡한 수자원 공학 작업을 효율적으로 처리하는 데 강점을 보였고, Gemini는 학술적 문맥에서 특화된 능력을 발휘했습니다. Llama3는 중국어 수자원 공학 질문에 가장 뛰어난 응답 능력을 보였으며, GLM-4, ERNIE, QWEN 같은 중국어 모델들도 일부 수자원 공학 작업에서 경쟁력 있는 성능을 보여주었습니다.

- **Performance Highlights**: GPT-4는 '오염 물질 관련 수질 모니터링 및 평가' 논문에 대해 정확한 연구 격차를 생성하는 데 특히 뛰어났습니다. 또한, '폐수 처리 프로세스', '환경 복원', '음용수 처리' 연구 논문의 적절한 제목을 생성하는 데에도 뛰어난 성과를 보였습니다. 전반적으로 이 연구는 LLMs를 수자원 공학 및 연구에서 평가하는 첫 번째 연구로, WaterER 벤치마크를 도입하여 예측의 신뢰성을 평가했습니다. 이 표준화된 평가 프레임워크는 향후 LLM 기술의 발전을 촉진하여 진정한 '수자원 전문가' 모델로 발전시키는 데 기여할 것입니다.



### CP-Prompt: Composition-Based Cross-modal Prompting for Domain-Incremental Continual Learning (https://arxiv.org/abs/2407.21043)
Comments:
          Accepted by ACM MM 2024

- **What's New**: 이 논문에서는 새로운 도메인에서 연속적으로 학습하면서 기존의 정보를 잊지 않기 위한 Cross-modal Domain-Incremental Learning (DIL) 문제를 해결하기 위해 CP-Prompt라는 새로운 프레임워크를 제안합니다. CP-Prompt는 미리 학습된 모델의 제한된 파라미터를 학습시켜 새로운 도메인을 학습하고 기존의 특징 분포를 잊지 않도록 합니다. CP-Prompt는 intra-domain 지식을 멀티-헤드 셀프 어텐션 레이어에 개인화된 프롬프트를 삽입하여 포착하고, 공통 프롬프트 전략으로 inter-domain 지식을 학습합니다.

- **Technical Details**: CP-Prompt는 미리 학습된 모델을 가르치기 위해 twin-prompt 전략을 사용합니다. 얕은 부분의 모델에 임베딩된 공통 프롬프트는 새로운 도메인 연속적으로 학습한 후 동결됩니다. 이러한 공통 프롬프트는 모델이 도메인 간 지식을 보존할 수 있도록 합니다. 개인화된 프롬프트(Prefix-One)는 미리 학습된 모델의 셀프 어텐션 레이어에 임베드되어 도메인 스타일 특징을 가지고 모델 추론에 기여합니다.

- **Performance Highlights**: CP-Prompt는 세 가지 널리 사용되는 DIL 벤치마크 데이터셋에서 기존의 최첨단 샘플-프리 베이스라인을 능가하며, 최소한의 추가 파라미터(0.22%)만을 조정하여 모델의 정확도를 2.3%까지 개선시킵니다.



### They Look Like Each Other: Case-based Reasoning for Explainable Depression Detection on Twitter using Large Language Models (https://arxiv.org/abs/2407.21041)
- **What's New**: 최근 발표된 ProtoDep는 트위터 기반의 우울증 탐지를 위한 새로운 설명 가능한 프레임워크입니다. ProtoDep는 프로토타입 학습(Prototype Learning)과 대규모 언어 모델(Large Language Models, LLMs)을 활용하여 투명한 설명을 제공하는 혁신적인 방법을 제시합니다. 이 프레임워크는 증상 수준, 유사 사용자 비교, 그리고 분류 가중치를 통해 우울증 탐지 모델의 투명성을 크게 향상시킵니다.

- **Technical Details**: ProtoDep는 트위터 데이터 내에서 우울증을 탐지하기 위해 프로토타입 학습을 사용합니다. 이 프레임워크는 다음 다섯 가지 단계로 이루어집니다: 1) 사용자 트윗 임베딩, 2) 증상 프로토타입 학습, 3) 사용자 인코딩, 4) 사용자 프로토타입 학습, 5) 분류 수행. 모델은 학습된 후 특정 사용자가 우울증을 앓고 있는지 여부를 예측합니다. 매 단계는 사용자 및 트윗과 연관된 중요한 정보를 추출하고 이를 기반으로 최종 결정을 내리는 데 도움을 줍니다.

- **Performance Highlights**: ProtoDep는 다섯 개의 벤치마크 데이터셋에서 거의 최첨단 성능을 달성하면서 의미 있는 프로토타입을 학습하는 데 성공했습니다. 이는 기존의 '블랙 박스' 모델과 달리 설명 가능성을 높여 모델의 예측이 어떻게 이루어졌는지 사용자들이 이해하도록 도와줍니다. 이러한 다단계 접근법은 궁극적으로 정신 건강 전문가들이 더 많은 정보를 기반으로 치료를 제공하는 데 도움을 줄 수 있습니다.



### Mapping Patient Trajectories: Understanding and Visualizing Sepsis Prognostic Pathways from Patients Clinical Narratives (https://arxiv.org/abs/2407.21039)
Comments:
          preprint, 8 pages, 6 figures

- **What's New**: 이 논문에서는 전통적인 전자 건강 기록(EHR)의 구조화된 임상 변수 대신 클리니컬 노트(clinical notes)를 활용하여 패혈증(sepsis) 예후 경로(prognostic pathways)를 개발하는 체계적인 방법론을 제안합니다. 다양한 동반질환으로 식별된 환자 하위 그룹을 중심으로 SHAP를 사용하여 이러한 하위 그룹에 대한 설명을 생성합니다.

- **Technical Details**: 본 연구는 MIMIC-III v1.4 데이터베이스로부터 추출된 패혈증 환자 코호트를 대상으로 하였습니다. 시간에 따라 기록된 임상 노트(간호 노트, 방사선 보고서, ECG 보고서)를 사용하여, 생물 의학 용어 사전을 통해 비구조화된 임상 노트를 표준화한 후, 환자 하위 그룹을 식별하고 질병 진행 경로를 추출합니다. 두 가지 BioNER 도구인 ScispaCy와 Metamap을 통해 주요 의학 엔터티를 추출하고, Negex 알고리즘을 사용하여 부정 사항을 식별하였습니다.

- **Performance Highlights**: 추출된 예후 경로는 시간에 따른 패혈증 중증도의 동적 궤적에 대한 귀중한 통찰을 제공하며, 질병 진행의 가능성과 방향을 다양한 맥락에서 시각화하고 결정적 요인이나 바이오마커를 드러냅니다. 이는 의료 제공자가 개별 환자에 맞춤형 치료 전략을 구현할 수 있게 도와줍니다.



### Advancing Chart Question Answering with Robust Chart Component Recognition (https://arxiv.org/abs/2407.21038)
- **What's New**: 새로운 기계 학습 모델인 Chartformer를 소개합니다. 이 모델은 차트 컴포넌트(예: 바, 라인, 파이, 제목, 범례, 축)를 정확하게 인식하고 분류하는 데 탁월한 성능을 보입니다. 또한, Question-guided Deformable Co-Attention (QDCAt) 메커니즘을 도입하여 질문에 기반한 지도를 통해 차트 기능을 결합하고 올바른 답을 도출할 수 있도록 개선하였습니다.

- **Technical Details**: Chartformer는 변형 가능한 주의 메커니즘(deformable attention)과 마스크 주의 메커니즘(mask attention)을 사용하여 차트 그래픽의 시각적 요소를 효과적으로 포착합니다. QDCAt 메커니즘은 Question-guided Offset Network (QON)를 활용해 질문 정보를 차트 기능과 결합하고 시각적 및 차트 관련 기능을 통합합니다.

- **Performance Highlights**: Chartformer는 기존 강력한 기준 모델인 DAT와 Mask2former를 각각 11.4%, 3.2% mAP에서 능가하며, 특히 중복되거나 불규칙한 라인 및 좁은 파이 조각에서 뛰어난 성능을 보입니다. QDChart는 ChartQA에서 15.4%의 정확도로 기존 Pix2Struct 모델을 능가하며, 색상 명확화 및 차트 컴포넌트 크기 비교와 같은 시각적으로 관련된 질문을 처리하는 데 특히 우수한 능력을 보여줍니다.



### An Application of Large Language Models to Coding Negotiation Transcripts (https://arxiv.org/abs/2407.21037)
- **What's New**: Vanderbilt AI Negotiation Lab에서 LLM(대형 언어 모델)을 협상 대본 분석에 적용한 연구 결과를 발표하였습니다. 이 연구는 협상 대본에서 각 문장이나 발언 단위를 자동으로 분류하기 위해 다양한 LLM 전략(제로샷 학습, 파인튜닝, 컨텍스트 학습)을 활용하였습니다. 이 과정에서의 성공과 실패를 바탕으로 최종 전략을 개발하였습니다.

- **Technical Details**: 코딩 스키마 설정부터 이상적인 예문을 생성하고, 세 가지 LLM 모델 코딩 전략을 테스트하는 과정이 상세히 설명되었습니다. 초기에는 47개의 코드를 가진 Jäckel Master 코딩 스키마를 사용하려 했으나, 실제 적용 가능한 19개의 코드로 축소하였습니다. 'Zero-Shot', 'Fine-Tuning' 및 'In-Context Learning' 전략을 사용한 다양한 실험이 수행되었고, 특히 'Fine-Tuning'은 협상 전문가의 예제 문장과 정의를 사용하여 모델을 도메인에 맞게 튜닝하였습니다.

- **Performance Highlights**: 'Zero-Shot' 전략에서는 일반 언어 지식만으로 약 20%의 정확도를 얻었으나, 'Fine-Tuning' 전략에서는 BERT 모델을 Jäckel 코딩 스키마에 맞게 튜닝하여 보다 높은 성능을 이끌어냈습니다. 이 연구는 LLM이 협상 연구를 위한 코딩 프로세스를 자동화하여 시간과 비용을 절약하고, 코딩의 효율성과 신뢰성을 향상시킬 수 있음을 보여줍니다.



### Multi-Grained Query-Guided Set Prediction Network for Grounded Multimodal Named Entity Recognition (https://arxiv.org/abs/2407.21033)
Comments:
          11 pages, 5 figures

- **What's New**: Grounded Multimodal Named Entity Recognition(GMNER)라는 정보 추출(IE) 작업 분야에서, 최신 연구들은 MRC 기반 프레임워크나 시퀀스 생성 기반 모델을 사용하고 있지만, 이러한 방법들은 멀티모달 엔티티 간의 관계 이해에 어려움을 겪고 있습니다. 이에 본 연구는 MQSPN(Multi-grained Query-guided Set Prediction Network)을 제안해 intra-entity와 inter-entity 수준에서 적절한 관계를 학습하는 새로운 통합 프레임워크를 소개합니다.

- **Technical Details**: MQSPN은 Multi-grained Query Set(MQS)와 Multimodal Set Prediction Network(MSP), 그리고 Query-guided Fusion Net(QFNet)으로 구성됩니다. MQS는 특정 타입 세분화된 쿼리들과 학습 가능한 엔티티 세분화된 쿼리를 결합하여 intra-entity 연결을 강화합니다. MSP는 GMNER를 집합 예측(set prediction) 문제로 재구성하여 inter-entity 관계를 글로벌 매칭 관점에서 적절하게 모델링합니다. QFNet은 텍스트와 시각적 정보를 각각 적절하게 통합하여 노이즈를 줄이는 역할을 합니다.

- **Performance Highlights**: 제안된 MQSPN 프레임워크는 기존 SOTA(State-of-the-Art) 방법들보다 우수한 성능을 기록했습니다. 특히, 어려운 fine-grained GMNER benchmark에서 2.83%의 F1 점수를 향상시켰습니다.



### Safeguard Text-to-Image Diffusion Models with Human Feedback Inversion (https://arxiv.org/abs/2407.21032)
Comments:
          ECCV 2024. 56 pages, 24 figures. Caution: This paper contains discussions and examples related to harmful content, including text and images. Reader discretion is advised. Code is available at this https URL

- **What's New**: 이 논문에서는 잠재적으로 유해하거나 저작권이 있는 콘텐츠를 생성할 수 있는 대규모 텍스트-이미지 변환 모델의 사회적 문제를 다룹니다. 인간 피드백을 활용한 새로운 프레임워크인 Human Feedback Inversion(HFI)를 제안하여, 모델이 생성한 이미지에 대한 문제점을 텍스트 토큰으로 압축하여 제거 및 완화합니다.

- **Technical Details**: 기존 모델은 인터넷에서 수집된 데이터에 의존해 왔으며, 필터링 과정에서 문제 있는 개념들이 남아있어 문제가 생깁니다. HFI는 모델이 생성한 이미지에 대한 인간의 피드백을 활용하여 텍스트 토큰으로 변환하고, 이러한 토큰을 통해 문제 이미지를 제거하거나 완화합니다. 또한 Self-Distillation 기반의 Safe self-Distillation Diffusion(SDD) 기법을 도입하여 훈련 목적을 단순화하고, 인간의 판단 기준에 더욱 잘 맞춥니다.

- **Performance Highlights**: 실험 결과 HFI 프레임워크는 문제 있는 콘텐츠의 생성을 획기적으로 줄이면서도 이미지 품질을 유지하는 것으로 나타났습니다. 예를 들어, Van Gogh의 예술 스타일을 제거하려는 과제에서, 인간 피드백을 기반으로 필수적인 그림 스타일은 유지하면서 그의 특징적인 붓질만 제거하였습니다. 또, 나체 이미지 제거 과제에서는, HFI가 포르노그래픽 콘텐츠를 성공적으로 제거한 반면, 기존 방법은 도발적인 이미지를 여전히 생성하였습니다. 이를 통해 HFI와 SDD의 조합이 다양한 프롬프트에서 안전하고 적절한 이미지 출력을 일관되게 제공함을 확인하였습니다.



### Cluster and Separate: a GNN Approach to Voice and Staff Prediction for Score Engraving (https://arxiv.org/abs/2407.21030)
Comments:
          Accepted at the 25th International Society for Music Information Retrieval (ISMIR) 2024

- **What's New**: 이번 연구는 quantized symbolic music(주로 MIDI 파일)의 노트를 여러 소리 및 스태프로 분리하는 문제에 접근합니다. 이는 인간 음악가가 읽기 쉬운 악보를 제작하는 '악보 각인(Engraving)' 작업의 중요한 부분입니다. 특히 피아노 음악에 집중하며 화성선(Homophonic voices)과 교차 스태프(voices)를 지원하는 시스템을 제안합니다.

- **Technical Details**: 본 연구는 end-to-end 시스템을 사용하여 각 화음에 속한 노트를 클러스터링하고 소리(voice)의 일부분인 노트들을 연결하는 그래프 신경망(Graph Neural Networks; GNN)을 기반으로 합니다. 데이터셋에 대한 접근 방식에서, 각 노트를 그래프로 모델링하여 GNN 모델에 전달한 후 목소리, 스태프, 화음 그룹화 정보가 포함된 출력 그래프를 예측하여 시스템이 작동합니다.

- **Performance Highlights**: 제안된 시스템은 두 가지 다른 스타일의 데이터셋에서 기존 접근방식에 비해 명확하고 일관된 성능 향상을 보여주었습니다. 특히 시스템의 효율성과 효과성을 강조하며, 결과를 음악 악보에 직접 시각화하는 도구를 개발하여 예측 결과를 제공했습니다.



### LLM-Find: An Autonomous GIS Agent Framework for Geospatial Data Retrieva (https://arxiv.org/abs/2407.21024)
- **What's New**: 새롭게 등장한 대형 언어 모델(LLMs)에 의해, 자율적인 GIS 에이전트 (Geographic Information Systems agents)가 공간 분석과 지도 제작 작업을 수행할 수 있는 잠재력이 높아졌습니다. 본 연구는 이러한 GIS 에이전트를 완전 자율적으로 지원하기 위한 연구 격차를 해결하고자 하며, 특히 필수적인 공간 데이터를 자동으로 발견하고 다운로드할 수 있는 방법을 제안합니다. 이를 위해 LLM-Find라는 자율 GIS 에이전트 프레임워크를 제안했습니다.

- **Technical Details**: LLM-Find는 LLM을 의사결정자로 활용하여, 사전 정의된 소스 리스트에서 적절한 데이터 소스를 선택하고 데이터를 추출합니다. 각 데이터 소스는 데이터 검색을 위한 메타데이터와 기술적 세부사항이 기록된 핸드북을 포함합니다. 이 프레임워크는 플러그 앤 플레이 (plug-and-play) 방식으로 설계되어 유연성과 확장성이 보장됩니다. 자동 데이터 스크롤러 또는 인간 사용자가 새로운 핸드북을 추가함으로써 새로운 데이터 소스를 쉽게 추가할 수 있습니다.

- **Performance Highlights**: 개발된 프로토타입 에이전트는 OpenStreetMap, 미 행정 경계 및 인구 통계 데이터, ESRI World Imagery의 위성 베이스맵, 상업 제공자가 제공한 기상 데이터, NYTimes GitHub의 COVID-19 데이터를 포함한 다양한 소스에서 데이터를 성공적으로 검색하는 능력을 입증했습니다. 이 연구는 자율적인 지리 공간 데이터 검색 에이전트를 개발한 최초의 시도 중 하나입니다.



### The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks (https://arxiv.org/abs/2310.15469)
Comments:
          This work has been accepted by CCS 2024

- **What's New**: 최근 연구에서는 대규모 언어 모델(LLM)에 대한 새로운 공격 방식을 제안했습니다. 'Janus 공격'은 LLM의 미세 조정(fine-tuning) 인터페이스를 악용하여 훈련 데이터에서 잊혀진 개인 식별 정보(PII)를 되찾을 수 있는 방법입니다.

- **Technical Details**: Janus 공격은 소수의 PII 인스턴스(최소 10개)를 활용하여 PII 연관 작업을 정의한 맞춤형 미세 조정 데이터셋을 생성합니다. 그런 다음 평가 데이터셋의 perplexity를 기반으로 오버피팅을 방지하면서 모델을 미세 조정합니다. 결국, fine-tuning 데이터셋에 정의된 동일한 프롬프트를 사용하여 PII를 회수합니다.

- **Performance Highlights**: Janus는 기존의 공격 방식들에 비해 10배 이상의 개인정보 위험을 증폭시키며, 최첨단 프라이버시 추출 공격인 프리픽스 공격과 in-context learning(ICL)을 각각 2-16배 성능으로 능가합니다. 예를 들어, Enron 데이터셋에서는 최대 35.19%의 개인 이메일을, ECHR에서는 6.16%의 지리적 위치 정보를, Ai4Privacy에서는 2.08%의 사회보장번호를 추출했습니다.



### AI-Assisted Generation of Difficult Math Questions (https://arxiv.org/abs/2407.21009)
- **What's New**: 수학적 추론을 강화하기 위해 혼합 접근 방식(LLM과 인간 전문가의 협력)을 사용하여 다양한 수학 문제를 생성하는 프레임워크를 제안합니다. 이 연구는 특히 기존 수학 데이터셋(MATH)으로부터 '핵심 기술(core skills)'을 추출하고 이것을 바탕으로 새로운 문제를 생성하는 방식입니다.

- **Technical Details**: 프레임워크는 LLM의 메타인지 기술을 활용하여 기존 수학 데이터셋(MATH)에서 핵심 기술을 추출합니다. 이러한 기술들은 무작위 쌍으로 조합되어 LLM을 통해 새로운 문제를 생성합니다. 생성된 문제들은 'out of distribution' 문제로 간주되며, 이를 인간 주석자들이 검증하고 더욱 정제합니다. 이 과정에서도 LLM의 지원을 받아 효율성을 높이고 있습니다.

- **Performance Highlights**: MATH$^2$ 데이터셋은 모델의 성능을 평가한 결과 기존 MATH 데이터셋보다 성능이 낮았습니다. 그러나 MATH$^2$의 문제를 맥락 예시(in-context examples)로 사용했을 때, MATH 데이터셋에서의 성능이 향상되었습니다. 특히 MATH$^2$ 데이터셋에서의 성공률은 MATH의 성공률의 제곱에 해당하였으며, 이는 두 가지 수학 기술의 비중이 높음을 시사합니다.



### From Feature Importance to Natural Language Explanations Using LLMs with RAG (https://arxiv.org/abs/2407.20990)
- **What's New**: 본 연구는 인간과 상호작용하는 자율적 의사결정 프로세스에서 머신러닝 모델의 출력을 대화 형식으로 이해할 필요성이 증가함에 따라, 대형 언어 모델(LLMs)이 후속 설명 제공자 역할을 할 수 있는 가능성을 탐구합니다. 특히, 장면 이해 과제에서 사용자의 질문에 응답하기 위해 외부 지식 저장소를 사용하는 추적 가능한 질문-응답(traceable question-answering) 방식을 도입합니다.

- **Technical Details**: 이 작업에서는 모델의 출력에 대한 맥락적 세부 정보(고급 특성(high-level features), 특성 중요도(feature importance), 대체 확률(alternative probabilities))을 포함하는 외부 지식 저장소를 활용합니다. 특성 중요도(feature importance)를 계산하기 위해 서브트랙티브 반사실 주의(subtractive counterfactual reasoning)를 사용하며, 이는 의미적 특징을 분해한 결과로 인한 출력 변화를 분석하는 방법입니다. 또한, 설명 과정을 원활히 하기 위해 사회적, 인과적, 선택적, 대비적 요소를 한 번의 프롬프트에 통합하여 응답 생성 과정을 안내합니다.

- **Performance Highlights**: 평가는 LLMs가 생성한 설명이 이러한 요소들을 포함하고 있어 복잡한 모델 출력을 자연 언어로 설명하는 데 잠재력이 있음을 나타냅니다.



### An evidence-based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems (https://arxiv.org/abs/2407.20951)
- **What's New**: 이번 연구는 데이터 집중 시스템(data-intensive systems)이 미치는 영향을 규제하기 위한 인권의 역할을 인정하는 것부터 시작하여 제3의 접근 방식을 제안합니다. 특히, 인공지능(AI) 활용 분야에서 인권 영향 평가(HRIA: Human Rights Impact Assessment)를 위한 방법론과 모델을 제시합니다.

- **Technical Details**: 이 연구는 여섯 개국의 데이터 보호 당국(dpa: data protection authorities)에서 나오는 700개 이상의 결정과 문서를 분석했습니다. 이를 통해 인권이 이미 데이터 사용에 관한 결정에서 중요한 역할을 하고 있음을 발견했습니다. 제공되는 HRIA 모델은 AI 애플리케이션에 특화되어 있으며, 리스크 평가에서 측정 가능한 접근 방식을 제공합니다.

- **Performance Highlights**: 제안된 HRIA 방법론의 실행 가능성과 효과를 입증하기 위해 구체적인 사례 연구가 수행되었습니다. 이러한 연구는 HRIA가 단순한 이론적 논쟁에서 벗어나 AI에 기반한 데이터 집중 애플리케이션의 실질적이고 맥락적인 구현으로 이어질 수 있음을 보여줍니다.



### The Realizability of Revision and Contraction Operators in Epistemic Spaces (https://arxiv.org/abs/2407.20918)
- **What's New**: 이 논문은 인지적 공간 (epistemic spaces)에서 신념 수정 (belief revision) 및 신념 축소 (belief contraction) 연산자의 실현 가능성을 연구합니다. 논문에서는 AGM 수정 (AGM revision) 및 AGM 축소 (AGM contraction) 연산자가 정확히 결정된 인지적 공간에서만 실현 가능함을 관찰합니다. 이를 통해 특정한 형태의 맥시오이스 연산자 (maxichoice operator)인 선형 변경 연산자 (linear change operators) 클래스를 정의합니다.

- **Technical Details**: AGM 수정 및 AGM 축소 연산자는 인지적 공간의 특정 조건 하에서만 실현 가능합니다. 논문에서는 이러한 조건을 충족하는 정확한 인지적 공간을 찾아 정의하고, 그렇게 정의된 조건에서 선형 변경 연산자 (linear change operators)가 이러한 AGM 수정 및 AGM 축소 연산자의 표준적 실현임을 보입니다.

- **Performance Highlights**: AGM 수정 및 AGM 축소 연산자가 실현 가능한 경우 선형 변경 연산자가 이러한 연산자의 표준적 실현으로 효과적으로 사용될 수 있음을 입증합니다. 이는 인지적 공간에서 보다 정확하고 예측 가능한 신념 수정 및 신념 축소를 가능하게 하여, 다양한 응용 분야에서 신뢰할 수 있는 결과를 제공할 수 있다는 점에 주목할 만합니다.



### Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach (https://arxiv.org/abs/2407.20899)
- **What's New**: 기존 이미지 분류에 대한 해설 방법들은 신뢰성 있고 그럴듯한 설명을 제공하는 데 어려움을 겪고 있습니다. 이 연구는 CNN 기반 분류기를 수정하지 않고도 구현할 수 있는 사후 자연어 설명 방법을 제안하며, 이를 통해 분류기의 결정 과정을 충실하게 설명합니다.

- **Technical Details**: 이 방법은 중요한 뉴런(influential neurons)과 그에 대응하는 활성화 맵(activation maps)을 분석하여 분류기의 결정 과정을 충실하게 설명하는 구조화된 의미 표현(structured meaning representation)을 생성합니다. 생성된 설명은 언어 모델(language model)을 통해 텍스트로 변환됩니다. 이 파이프라인 접근법을 통해 생성된 설명은 신경망 아키텍처에 기초하여 정확한 통찰력을 제공하면서 비전문가도 이해할 수 있게 됩니다.

- **Performance Highlights**: 실험 결과, 본 연구에서 제안하는 자연어 설명(NLE)이 훨씬 더 그럴듯하고 충실하다는 것을 보여줍니다. 특히, 사용자 개입(뉴런의 은폐) 시 신경망 구조에 대한 개입 효과가 기존 방법들보다 3배 더 효과적입니다.



### A Scalable Tool For Analyzing Genomic Variants Of Humans Using Knowledge Graphs and Machine Learning (https://arxiv.org/abs/2407.20879)
Comments:
          arXiv admin note: substantial text overlap with arXiv:2312.04423

- **What's New**: 이 논문은 COVID-19 환자로부터 얻은 RNA 시퀀싱(RNA-seq) 데이터를 분석하기 위해 지식 그래프(knowledge graphs)와 그래프 머신 러닝(graph machine learning, GML)을 통합하는 새로운 방법론을 제안합니다. 이를 통해 RNA 수준에서의 복잡한 유전적 관계를 이해할 수 있는 기회를 제공합니다.

- **Technical Details**: 제안된 방법은 변이 수준의 유전 정보 추출, SnpEff를 사용하여 추가 메타데이터로 데이터 주석 달기, 그리고 Variant Call Format (VCF) 파일을 Resource Description Framework (RDF) 트리플로 변환하는 과정을 포함합니다. 결과 지식 그래프는 환자 메타데이터로 추가 강화되고, 그래프 데이터베이스에 저장되어 효율적인 질의와 색인화가 가능합니다. 또한, Deep Graph Library (DGL)를 이용하여 GraphSAGE와 Graph Convolutional Networks (GCNs)를 통해 노드 분류(node classification)와 같은 그래프 머신 러닝 작업을 수행합니다.

- **Performance Highlights**: 제안된 도구인 VariantKG는 세 가지 주요 시나리오에서 중대한 유틸리티를 보여줍니다: 새로운 VCF 데이터로 그래프를 풍부하게 만들기, 사용자 정의 기능에 기반한 서브그래프 생성, 그리고 노드 분류를 위한 그래프 머신 러닝 수행.



### How to Measure the Intelligence of Large Language Models? (https://arxiv.org/abs/2407.20828)
Comments:
          3 pages, 1 figure

- **What's New**: 최근 ChatGPT 및 대형 언어 모델(LLMs)의 등장으로 현재와 미래의 모델에 대한 지능, 가능성 및 위험성에 대한 논의가 활발해지고 있습니다. 특히 '초인적(super-human)' 인공지능의 부상이 다뤄졌습니다. 알란 튜링(Alan Turing)의 정신에 따라 현존하는 최첨단 언어 모델은 이미 그의 유명한 테스트를 통과한 것으로 여겨지고 있습니다. 게다가, 현재 모델은 여러 벤치마크 테스트에서 인간을 능가합니다.

- **Technical Details**: 기술적 관점에서 LLMs는 일상 생활, 산업, 과학을 연결하는 다재다능한 동반자가 되었습니다. 하지만 이 모델들은 종종 인간에게는 사소하게 여겨지는 작업에서 완전히 실패하기도 합니다. 예를 들어 학계에서는 적은 입력으로도 설득력 있는 연구 논문을 작성할 수 있지만, 사실 일관성의 결여나 지속적인 환각(hallucination) 문제로 인해 과학 저널에서 AI 기반 콘텐츠에 대한 여러 가지 제한이 제기되었습니다.

- **Performance Highlights**: 현재 모델은 특정 작업에서 벤치마크 테스트에서 인간을 초과하는 성능을 보입니다. 그러나 LLMs의 신뢰성(trustworthiness)은 더욱 애매하고 평가하기 어려운 문제로 남아 있습니다. 이 논문에서는 LLMs의 지능을 작업별 통계적 메트릭(metric)뿐만 아니라 질적(qualitative) 및 양적(quantitative) 측정 기준으로 평가해야 한다고 주장합니다.



### Adding Circumscription to Decidable Fragments of First-Order Logic: A Complexity Rollercoaster (https://arxiv.org/abs/2407.20822)
Comments:
          23 pages - Extended version of a paper accepted at KR 2024

- **What's New**: 이 논문에서는 초등 논리의 결정 가능한 표현 조각들에 대한 서술 축소(circumscription) 확장을 연구합니다. 특히 두 변수 조각 FO^2, 집계 양화사를 포함한 확장 C^2, 그리고 보호 조각 GF에 대해 논의합니다.

- **Technical Details**: 이 연구는 유니어리(predicates)가 서술 축소 시 최소화되거나 고정될 때 논리적 결론의 결정 가능성이 유지됨을 증명합니다. FO^2의 경우 복잡도는 coNexp에서 coNExp^NP-완전 (coNExp^NP-complete)으로, GF의 경우 2Exp에서 Tower-완전 (Tower-complete)으로 증가하지만, C^2의 복잡도는 여전히 미해결 상태에 있습니다.

- **Performance Highlights**: GF 문장이 하나의 결합 쿼리의 유니언일 때는 문제의 결정 가능성을 보여주며, 결합 복잡성(combined complexity)에서 Tower-완전 (Tower-complete)하고, 데이터 복잡성(data complexity)에서는 기본적입니다. 반면 한 정수 쿼리와 보호된 형태의 존재 규칙들이 포함된 온톨로지를 고려할 때는, 모든 k ≥ 0에 대해 데이터 복잡성이 k-Exp-hard한 사례가 존재한다는 것을 증명하였습니다.



### ARCLE: The Abstraction and Reasoning Corpus Learning Environment for Reinforcement Learning (https://arxiv.org/abs/2407.20806)
Comments:
          Accepted by CoLLAs 2024, Project page: this https URL

- **What's New**: 이 연구는 Abstraction and Reasoning Corpus (ARC)를 위한 강화학습 연구를 촉진하기 위해 설계된 환경인 ARCLE을 소개합니다. 이 새로운 환경은 방대한 액션 공간(action space), 도달하기 어려운 목표(goal), 다양한 작업(task) 등 기존 강화학습의 문제들을 해결할 수 있도록 도와줍니다.

- **Technical Details**: ARCLE 환경 내에서 강화학습 에이전트는 Proximal Policy Optimization을 활용하여 개별 작업을 학습할 수 있습니다. 또한, 비 팩토리얼 정책(non-factorial policies)과 보조 손실(auxiliary losses)을 도입하여 성능을 향상시키고 액션 공간 및 목표 달성 문제를 효과적으로 완화했습니다.

- **Performance Highlights**: ARCLE의 도입으로, 다양한 강화학습 에이전트들이 보다 효율적이고 효과적으로 특정 작업을 학습할 수 있게 되었습니다. 특히, 비 팩토리얼 정책과 보조 손실의 채용은 성능 향상에 중요하게 기여했습니다.

- **Research Directions**: ARCLE을 활용한 여러 연구 방향과 동기가 제안되었습니다. 여기에는 MAML(Model-Agnostic Meta-Learning), GFlowNets, 그리고 World Models와 같은 기법들이 포함됩니다. 이 기법들은 ARC 환경에서 더 나은 학습과 추론을 가능하게 할 것입니다.



### How Novice Programmers Use and Experience ChatGPT when Solving Programming Exercises in an Introductory Cours (https://arxiv.org/abs/2407.20792)
Comments:
          Accepted at 2024 IEEE ASEE Frontiers in Education Conference

- **What's New**: 이 연구 논문은 기초 프로그래밍 교육에서 Generative AI (GenAI)의 활용에 대한 학생들의 관점을 조사하여 교육 연구 커뮤니티에 기여하고 있습니다. 특히 학생들이 ChatGPT와 같은 관련 도구를 어떻게 사용하는지를 중심으로 다루며, 이는 교육자와 고등 교육 기관이 학생들의 학습을 지원하고 적절한 교육 및 평가 방법을 개발하는 데 중요한 정보가 될 것입니다.

- **Technical Details**: 연구는 독일의 대형 대학에서 컴퓨팅 학생들에게 기초 프로그래밍 과업을 ChatGPT의 도움을 받아 해결하도록 요청했습니다. 학생들(n=298)은 ChatGPT 사용에 대한 정보와 툴에 대한 평가를 온라인 설문조사를 통해 제공했습니다. 연구 질문은 (1) 학생들은 기초 프로그래밍 연습 맥락에서 ChatGPT의 사용 패턴에 대해 무엇을 보고하는가? (2) 학생들은 기초 프로그래밍 연습 맥락에서 ChatGPT를 어떻게 인식하는가? 두 가지입니다.

- **Performance Highlights**: 이 연구는 주로 ChatGPT-3.5가 초보 프로그래머들에 의해 고등 교육 맥락에서 어떻게 응용되는지에 대한 포괄적인 평가를 제공합니다. 이는 AI의 빠른 발전과 교육 환경에서의 광범위한 사용을 고려할 때, AI가 프로그래밍 교육을 어떻게 향상시킬 수 있는지에 대한 중요한 인사이트를 제공합니다.



### Metaheuristic Enhanced with Feature-Based Guidance and Diversity Management for Solving the Capacitated Vehicle Routing Problem (https://arxiv.org/abs/2407.20777)
Comments:
          https://hal.science/hal-04663574

- **What's New**: 이번 연구에서는 Capacitated Vehicle Routing Problem (CVRP) 문제 해결을 위한 피처 기반 가이드 (feature-based guidance)를 강화한 메타휴리스틱 알고리즘을 제안했습니다. 이 가이드를 공식화하기 위해 지도 학습(ML) 모델을 개발하고 활용하였습니다.

- **Technical Details**: 제안된 메타휴리스틱 알고리즘은 가까운 이웃 탐색(neighborhood search)과 새로운 하이브리드 분할(hybrid split) 및 경로 연결(path relinking) 메커니즘을 결합하여 최적화 과정 동안 솔루션의 다양성을 제어합니다. 지도 학습 모델은 가이드를 공식화하고, 최적화 과정 동안 솔루션의 다양성을 제어하는 역할을 합니다.

- **Performance Highlights**: 제안된 가이드는 CVRP 문제를 해결하는 데 있어 메타휴리스틱 알고리즘의 성능을 통계적으로 유의미하게 향상시켰으며, 또한 최신 메타휴리스틱 알고리즘 중에서도 경쟁력 있는 솔루션을 만들어냈습니다.



### OmniBal: Towards Fast Instruct-tuning for Vision-Language Models via Omniverse Computation Balanc (https://arxiv.org/abs/2407.20761)
- **What's New**: 최근 시각-언어 지시-튜닝(Vision-Language Instruct-Tuning) 모델은 세상에 대한 보다 포괄적인 이해 덕분에 큰 진전을 이루었습니다. 본 연구에서는 이러한 모델에 대한 대규모 3D 병렬 훈련이 장치 간 불균형한 계산 부하를 초래한다는 것을 발견했습니다. 이를 해결하기 위해 데이터, 모델, 메모리 관점에서 계산 부하를 재조정하여 더 균형 잡힌 장치 간 계산을 달성했습니다.

- **Technical Details**: 구체적으로, 데이터 측면에서는 장치 내 및 장치 간 새로운 균형 있는 미니 배치(mini-batches)로 인스턴스를 그룹화했습니다. 모델 측면에서는 검색 기반 방법을 사용하여 더 균형 잡힌 분할을 달성했습니다. 메모리 최적화 측면에서는 각 파티션의 재계산 전략을 적응적으로 조정하여 사용 가능한 메모리를 최대한 활용했습니다. 이러한 세 가지 구성요소는 독립적이지 않으며, 하나의 옴니버스 균형 훈련 프레임워크를 형성합니다.

- **Performance Highlights**: 우리 방법의 유효성을 확인하기 위해 다양한 실험을 수행했습니다. InternVL-Chat의 공개 훈련 코드와 비교했을 때, GPU 일수를 크게 줄였으며 약 1.8배의 속도 향상을 달성했습니다. 우리의 방법의 효과성과 일반화 가능성은 다양한 모델과 데이터셋에 걸쳐 추가로 입증되었습니다.



### Integer-Valued Training and Spike-Driven Inference Spiking Neural Network for High-performance and Energy-efficient Object Detection (https://arxiv.org/abs/2407.20708)
Comments:
          Accepted by ECCV2024; 19 pages, 4 figures

- **What's New**: 이 논문에서는 뇌에서 영감을 받은 Spiking Neural Networks(SNNs)의 성능을 개선하여 현재 간단한 분류 작업에만 제한된 SNNs를 객체 인식(object detection) 작업에도 적용하려는 시도를 다룹니다. 저자들은 SNNs와 ANNs간의 성능 격차를 줄이는 데 중점을 두고 SpikeYOLO라는 새로운 아키텍처를 설계하여 이 문제를 해결하고자 합니다.

- **Technical Details**: 기존 YOLO(YOLO series)의 과도한 복잡성으로 인해 스파이크 신호가 저하되는 문제를 피하기 위해 YOLO 아키텍처를 단순화하고 메타 SNN 블록(meta SNN blocks)을 통합한 SpikeYOLO를 설계하였습니다. 또한, 막전위(membrane potentials)를 이진 스파이크로 변환하는 과정에서 발생하는 양자화 오류(quantization errors)를 해결하기 위해, 정수 값을 활성화(activate Integer values)하고 추론 시 가상 타임스텝(virtual timesteps)을 확장하여 스파이크 기반을 유지하는 새로운 스파이킹 뉴런을 설계했습니다.

- **Performance Highlights**: 제안된 방법은 COCO 정적 데이터셋(static dataset)에서 기존 최고 성능의 SNN보다 AP@50이 15.0%, mAP@50:95가 18.7% 향상된 66.2%와 48.9%의 성능을 기록했습니다. 또한, neuromorphic Gen1 데이터셋에서 동등한 아키텍처를 가진 ANN보다 2.5% 높은 67.2%의 성능을 달성하며, 에너지 효율성도 5.7배 개선되었습니다.



### Industrial-Grade Smart Troubleshooting through Causal Technical Language Processing: a Proof of Concep (https://arxiv.org/abs/2407.20700)
Comments:
          2nd Workshop on Causal Inference and Machine Learning in Practice at the KDD 2024 Conference. arXiv admin note: text overlap with arXiv:2407.11056

- **What's New**: 이 논문은 경험 기록(Return on Experience)에서 표현된 기술 언어를 바탕으로 산업 환경 문제를 해결하기 위한 인과 진단 접근법의 개발을 설명합니다. 제안된 방법은 대규모 언어 모델(Large Language Model)의 분산 표현에 포함된 벡터화된 언어 지식과 산업 자산의 내재된 고장 모드 및 메커니즘이 암시하는 인과 연관성을 활용합니다. 실세계 예측 유지보수(Predictive Maintenance) 설정에서 이러한 개념을 실험적으로 설명합니다.

- **Technical Details**: 이 솔루션은 인과성을 인지하는 검색 증강 생성 시스템(causality-aware retrieval augmented generation system)으로 설계되었습니다. 대규모 언어 모델의 분산 표현에 포함된 벡터화된 언어 지식을 활용하여 산업 자산의 내재된 고장 모드와 메커니즘의 인과 연관성을 분석합니다.

- **Performance Highlights**: 실험 결과는 제안된 방법이 실세계 예측 유지보수 설정에서 효과적으로 작동함을 보여줍니다. 그러나 보다 복잡한 시나리오에서 사용되는 인과 기술의 성숙도를 향상시켜야 하는 과제를 논의합니다.



### Mimicking the Mavens: Agent-based Opinion Synthesis and Emotion Prediction for Social Media Influencers (https://arxiv.org/abs/2407.20668)
Comments:
          Upon acceptance of the article by IEEE, the preprint article must be replaced with the accepted version, as described in the section 'Accepted article.'

- **What's New**: 본 연구는 인터넷에서의 비정형적이고 맥락에 민감하며 이질적인 커뮤니케이션의 특성을 다루며, 사회적 트렌드를 예측하고 전략적 대응을 유도하는 새로운 컴퓨팅 프레임워크를 소개합니다. 이 프레임워크는 새로운 뉴스 스토리와 트렌드 주제에 맞춘 자동 5W1H(어디서, 누구, 언제, 무엇을, 왜, 어떻게) 질문 생성 엔진을 제안합니다. 이를 통해 여섯 개의 도메인에서 총 60명의 익명 의견 리더 에이전트를 구축하고, 고도화된 거대 언어 모델(LLM)과 Retrieval-Augmented Generation(RAG)을 결합하여 의견을 생성합니다.

- **Technical Details**: 자동 5W1H 모듈을 통해 뉴스 스토리와 문제들을 분석하고 질문을 생성합니다. 이후, 여섯 개 도메인에 걸친 60명의 익명 의견 리더 에이전트를 활용하여 확대된 거대 언어 모델 (LLM)과 Retrieval-Augmented Generation(RAG) 기술을 사용해 시뮬레이션을 진행합니다. 이 과정에서 특정 이벤트에 대한 의견 리더들의 잠재적 견해와 대중의 감정 반응을 예측합니다.

- **Performance Highlights**: 자동 5W1H 모듈의 성능은 평균 GPT-4 점수 8.83/10으로 매우 높은 정확도를 보여줍니다. 의견 리더 에이전트들은 평균 GPT-4 평가 점수 6.85/10을 기록하며 일관된 성능을 나타냈습니다. '러시아-우크라이나 전쟁'을 사례 연구로 삼아, 주요 영향력 있는 인사들의 관점과 감정 예측이 실제 현실 세계의 감정 트렌드와 일치함을 확인했습니다.



### Unveiling the Potential of Spiking Dynamics in Graph Representation Learning through Spatial-Temporal Normalization and Coding Strategies (https://arxiv.org/abs/2407.20508)
- **What's New**: 이번 연구에서는 스파이킹 뉴럴 네트워크(SNNs)가 그래프 표현 학습(graph representation learning) 분야에서 가지는 잠재력에 주목하여, 특히 비유클리드 데이터(non-Euclidean data)에 SNNs를 적용합니다. 이를 통해 기존의 그래프 신경망(GNNs)와 비교하여 에너지 효율성이 높고 이벤트 기반의 처리 방식에 대한 이해를 높이고자 합니다. 저자들은 스파이크 기반의 그래프 신경망 모델을 제안하며, 새로운 공간-시간 특징 정규화(STFN) 기법을 도입해 훈련 효율성과 모델 안정성을 향상시켰습니다.

- **Technical Details**: 제안된 모델은 스파이킹 다이내믹스를 그래프 학습에 통합하며, SNN의 성과에 대한 상세한 분석을 통해 레이트 코딩(rate coding)과 시간 코딩(temporal coding)이 성능에 미치는 영향을 탐구합니다. 또한, 모델이 과도한 평활화 문제(oversmoothing problem)를 해결하는 데 도움이 되는지 평가합니다. 이 모델은 기존의 딥 그래프 네트워크와의 비교를 통해 그 성능을 검증합니다.

- **Performance Highlights**: 실험 결과, 제안된 SNN 모델은 최신의 GNNs 기술과 비교하여 경쟁력 있는 성능을 보여주며, 동시에 계산 비용을 상당히 줄일 수 있음을 입증했습니다. 이는 SNNs가 복잡한 그래프 기반 시나리오에서 효율적인 뉴로모픽 컴퓨팅(neuromorphic computing) 애플리케이션의 잠재력을 가지고 있음을 시사합니다.



### Domain Adaptable Prescriptive AI Agent for Enterpris (https://arxiv.org/abs/2407.20447)
- **What's New**: MIT-IBM Watson AI Lab에서 진행한 이번 연구는 PrecAIse라는 새로운 개념 증명 에이전트를 소개합니다. PrecAIse는 기업 사용자들이 더 나은 비즈니스 결정을 내릴 수 있도록 돕기 위해 설계된 도메인 적응형 대화형 에이전트로, 최신의 인과 추론(causal inference) 및 처방 분석(prescriptive analytics) 도구를 자연어 상호작용을 통해 쉽게 접근할 수 있도록 합니다.

- **Technical Details**: PrecAIse는 다기능 호출(function calling) 기능을 포함하고 있어 신뢰할 수 있는 상호작용 및 동적 대화를 유지할 수 있습니다. 또한 다양한 새로운 도메인을 지원할 수 있으며, 이를 통해 기업 사용자는 머신러닝 및 데이터 과학에 대한 제한된 지식으로도 복잡한 처방 분석을 활용할 수 있습니다. 이 에이전트는 복잡한 컴퓨팅 자원이 필요없이 자연어 사용자 인터페이스(NLUI)를 통해 대화형 방식으로 운영됩니다.

- **Performance Highlights**: PrecAIse는 사용자가 쉽게 접근할 수 있는 대화형 에이전트를 통해 기업 내 복잡한 인과 추론 및 처방 분석 도구의 도입을 촉진할 수 있게 설계되었습니다. 이를 통해 기업 사용자들은 기술적 복잡성을 극복하고, 보다 효율적인 의사결정을 내릴 수 있는 환경을 제공받을 것입니다.



### Appraisal-Guided Proximal Policy Optimization: Modeling Psychological Disorders in Dynamic Grid World (https://arxiv.org/abs/2407.20383)
- **What's New**: 이 연구는 강화 학습(RL) 에이전트를 이용해 심리적 장애를 모델링하는 방법론을 개발한 것입니다. 감정 평가 이론(Appraisal theory)을 적용하여 AG-PPO(Appraisal-Guided Proximal Policy Optimization) 알고리즘을 통해 RL 에이전트를 훈련시켰습니다. 이를 통해 심리적 장애를 시뮬레이션하고 에이전트 행동을 조절하는 다양한 보상 형태 전략을 조사했습니다.

- **Technical Details**: 연구진은 동적 grid world 환경에서 강화 학습(RL) 에이전트를 감정 평가 이론에 기반해 훈련시켰습니다. AG-PPO 알고리즘을 사용했으며, 다양한 보상 형태를 적용하여 심리적 장애(특히 불안 장애와 강박 장애와 유사한 행동)를 시뮬레이션했습니다. 표준 PPO 알고리즘과 AG-PPO 알고리즘의 여러 구성 요소를 비교하여 일반화 기능 측면에서 성능 향상을 입증했습니다.

- **Performance Highlights**: AG-PPO 알고리즘은 표준 PPO 알고리즘보다 성능이 크게 개선되었으며, 복잡한 테스트 환경에서 심리적 장애와 관련된 증상을 평가하는 데 있어 중요한 역할을 했습니다. 다양한 심리적 장애를 에이전트의 행동 패턴을 통해 시뮬레이션하고 평가하는 데 성공했습니다.



### Leveraging Natural Language and Item Response Theory Models for ESG Scoring (https://arxiv.org/abs/2407.20377)
- **What's New**: 이 논문은 환경, 사회, 지배구조(ESG) 점수를 평가하는 혁신적인 접근법을 탐구합니다. 특히, 자연어 처리(NLP) 기법과 문항 반응 이론(IRT), 구체적으로 Rasch 모델을 통합합니다. 이 연구는 브라질의 주요 석유 회사인 Petrobras와 관련된 2022년과 2023년 간의 포르투갈어 뉴스 기사를 포괄하는 데이터셋을 활용합니다. 이 데이터를 고급 NLP 방법을 사용해 ESG 관련 감정으로 필터링하고 분류합니다.

- **Technical Details**: 이 연구는 NLP(Natural Language Processing) 기법을 사용해 ESG에 관련된 뉴스 기사의 감정을 분류합니다. 그런 다음 Rasch 모델을 적용해 이러한 ESG 측정치의 심리측정 속성을 평가합니다. Rasch 모델은 문항 반응 이론(IRT)의 일종으로, 심리측정학에서 주로 사용되는 접근법입니다.

- **Performance Highlights**: 결과는 이 방법론이 ESG 요인을 보다 정확하고 신뢰성 있게 측정하는 데 효과적임을 보여줍니다. 특히 중요한 기간과 트렌드를 강조합니다. 이 접근법은 ESG 메트릭의 견고성을 향상시킬 수 있으며, ESG 보고의 시간적 역학에 대한 더 깊은 이해를 제공합니다.



### Evaluating Large Language Models for automatic analysis of teacher simulations (https://arxiv.org/abs/2407.20360)
- **What's New**: 디지털 시뮬레이션(DS)은 사용자들이 대화형 프롬프트를 통해 에이전트와 상호작용하며 현실적인 교실 시나리오에서 교사 후보자들을 훈련시키는 매력적인 학습 경험을 제공합니다. 이 연구는 DS에서 사용자 응답을 자동으로 분석하는 데 복잡함을 해결하기 위해 대형 언어 모델(LLMs)을 평가했습니다.

- **Technical Details**: DeBERTaV3와 Llama 3를 zero-shot, few-shot, fine-tuning 방식과 결합하여 평가하였습니다. 실험 결과, 특정 특성(특정 사용자 행동)을 식별할 때 LLM의 성능에 큰 차이가 발생했음을 발견했습니다. 특히, DeBERTaV3는 새로운 특성을 식별해야 할 때 성능이 크게 감소한 반면, Llama 3는 새로운 특성을 감지하는 데 더 나은 성능을 보이고 더욱 안정적인 성능을 보여주었습니다.

- **Performance Highlights**: DeBERTaV3는 새로운 특성을 식별할 때 성능이 크게 저하되었습니다. 반면, Llama 3는 새로운 특성을 감지하는 데 있어서 더 나은 성능을 나타내며, 안정적으로 작동했습니다. DS에서 교사 교육자들이 시뮬레이션이나 교육 목표에 따라 새로운 특성을 도입해야 할 경우, Llama 3를 사용하는 것이 더 권장됩니다.



### Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process (https://arxiv.org/abs/2407.20311)
Comments:
          video appeared in ICML 2024 tutorial

- **What's New**: 최근 언어 모델(language models)의 발전은 수학적 추론 문제를 해결할 수 있는 능력을 보여주며, 초등학교 수준의 수학 벤치마크인 GSM8K에서 거의 완벽한 정확도를 달성했습니다. 이번 논문에서는 언어 모델이 이 문제들을 어떻게 해결하는지 공식적으로 연구하였습니다.

- **Technical Details**: 연구진은 여러 기본적인 질문을 다루기 위해 일련의 통제된 실험을 설계했습니다: (1) 언어 모델이 정말로 추론 능력을 개발할 수 있는가, 아니면 단순히 템플릿을 암기하는가? (2) 모델의 숨겨진(mental) 추론 과정은 무엇인가? (3) 모델이 수학 문제를 해결하는 데 사용하는 기술이 인간과 비슷한가 또는 다른가? (4) GSM8K 같은 데이터셋으로 훈련된 모델이 GSM8K 문제를 해결하는 데 필요한 것 이상의 추론 능력을 개발하는가? (5) 모델이 추론 실수를 일으키는 정신적 과정은 무엇인가? (6) GSM8K 수준의 수학 문제를 효과적으로 해결하기 위해 모델은 얼마나 크거나 깊어야 하는가?

- **Performance Highlights**: 이번 연구는 언어 모델이 수학적 문제를 해결하는 많은 숨겨진 메커니즘을 밝혀내었으며, 현재 LLMs에 대한 이해를 넘어서는 통찰력을 제공하고 있습니다.



### Formalization of Dialogue in the Decision Support System of Dr. Watson Typ (https://arxiv.org/abs/2407.20291)
- **What's New**: 이 논문은 이전 출판물에서 제안된 Dr. Watson 유형의 AI 시스템에서 친근한 대화의 이론을 더 발전시키고 공식화했습니다. 이 AI의 주요 원칙은 사용자의 입력과 시스템에 수집된 데이터를 분석하여 사용자에게 질문을 던지면서 친근하게 해결책으로 안내하는 것입니다.

- **Technical Details**: 이 AI 시스템은 사용자 입력(User Input)과 시스템에 축적된 데이터(Data)를 분석하여 질문을 생성합니다. 이러한 접근 방식을 통해 사용자가 자연스럽고 친근한 방식으로 문제를 해결할 수 있도록 유도합니다.

- **Performance Highlights**: 이 접근 방식은 사용자 경험(User Experience)을 향상시키는 데 중점을 두며, 사용자가 느끼는 친밀감과 편안함을 강조합니다. 또한, 시스템의 효율성과 사용자 참여도가 크게 개선될 것으로 예상됩니다.



### Variational Inference Using Material Point Method (https://arxiv.org/abs/2407.20287)
- **What's New**: 최근 발표된 논문에서는 변분 추론(variational inference)을 위한 새로운 그라디언트 기반 입자 샘플링(particle sampling) 방법인 MPM-ParVI를 제안했습니다. 이 방법은 물질점 방법(Material Point Method, MPM)에 기반을 두고 있으며, 변형 가능한 물체의 변형을 시뮬레이션합니다.

- **Technical Details**: MPM-ParVI는 상호작용 입자 시스템(interacting particle system, IPS)으로 연속체 재료를 모델링합니다. 각 입자는 완전한 물리적 특성을 지니며, 보존 역학(conservation dynamics)을 따라 상호작용하고 진화합니다. 이 방법은 베이지안 추론에서 자주 다루는 모델(예: 계산 불가능한 밀도)과 생성 모델링(예: 점수 기반)과 같은 확률적 모델의 결정론적 샘플링(deterministic sampling) 및 추론을 쉽게 구현할 수 있도록 합니다.

- **Performance Highlights**: MPM-ParVI는 목표 밀도(target density)에 의해 주도되는 외부 효과 하에서 변형 가능한 물체(예: 고체 또는 유체)의 변형을 시뮬레이션합니다. 이 물체의 일시적 또는 안정적 구성은 목표 밀도를 근사하게 됩니다.



### MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI (https://arxiv.org/abs/2407.20284)
- **What's New**: 현대 의료에서 정확한 질병 예측과 개인 맞춤형 추천의 복잡한 문제를 해결하기 위해 MLtoGAI를 소개합니다. 이 연구는 시맨틱 웹 기술과 머신 러닝(ML)을 통합하여 질병 예측을 향상시키고 ChatGPT를 통해 사용자 친화적인 설명을 제공합니다. MLtoGAI 시스템은 재사용 가능한 질병 온톨로지, 진단 분류 모델, 그리고 시맨틱 웹 규칙 언어(SWRL)를 포함하여 세 가지 주요 구성 요소로 이루어져 있습니다.

- **Technical Details**: MLtoGAI 시스템은 재사용 가능한 질병 온톨로지, 환자 증상을 사용하여 특정 질병을 정확하게 감지하는 진단 분류 모델, 그리고 시맨틱 웹 규칙 언어(SWRL)를 비롯한 온톨로지와 ChatGPT를 통합하여 명확하고 개인화된 건강 조언을 생성하는 것의 세 가지 주요 구성 요소로 구축되었습니다. 이러한 접근 방식은 예측 정확도를 크게 향상시키며 이해하기 쉬운 결과를 제공합니다.

- **Performance Highlights**: MLtoGAI 시스템은 예측 정확도와 사용자 만족도에 있어서 상당한 향상을 보였으며, 200개의 합성 환자 데이터 기록을 사용하여 시스템의 성능과 신뢰성을 검증했습니다. ML 알고리즘의 강점을 투명하고 인간이 이해할 수 있는 설명을 제공하는 ChatGPT와 결합함으로써 예측 정확도와 사용자 이해도를 높이는 데 성공했습니다.



### Causal Understanding For Video Question Answering (https://arxiv.org/abs/2407.20257)
- **What's New**: 본 논문은 기존의 NExT-QA 데이터셋(NExT-QA dataset)에서의 비디오 질문 응답(Video Question Answering)의 한계를 지적하고 이를 해결하기 위한 네 가지 새로운 개선 방향을 제안합니다. 이를 통해 단일 프레임(single-frame) 및 전체 비디오(complete-video) 기반 접근 방식 모두에서 최첨단(state-of-the-art) 결과를 얻었습니다.

- **Technical Details**: 기존 접근 방식은 서브 샘플링 정보(sub-sampled information) 또는 인과적 개입(causal intervention) 기법을 사용해 비디오의 전체 특징을 활용했습니다. 본 연구는 각 문제를 체계적으로 해결하기 위해 스마트하게 프레임을 샘플링(smartly sampling frames)하고, 명시적으로 동작을 인코딩(explicitly encoding actions)하며, 모델의 이해력을 도전하는 개입(interventions)을 생성하는 방법을 제안합니다.

- **Performance Highlights**: 제안된 방법은 단일 프레임 기반 접근 방식에서 +6.3%, 전체 비디오 기반 접근 방식에서 +1.1%의 성능 향상을 이루어 NExT-QA 데이터셋에서 최첨단 성능을 달성했습니다.



### ThinK: Thinner Key Cache by Query-Driven Pruning (https://arxiv.org/abs/2407.21018)
Comments:
          20 pages, 6 figures

- **What's New**: 이 논문에서는 대형 언어 모델 (LLMs)의 KV 캐시 (KV cache) 메모리 소비 비효율성을 해결하는 새로운 방법, 'ThinK'를 제안합니다. 특히, 길고 복잡한 시퀀스를 다루는 과정에서 발생하는 메모리 및 계산 비용 문제를 다룹니다.

- **Technical Details**: 'ThinK'는 쿼리 의존적인 KV 캐시 프루닝 방식으로, 채널 차원에서 발생하는 중복성을 줄이는 방법입니다. 이러한 중복성은 모듈 내에서 불균형한 크기 분포와 낮은 랭크 구조에 의해 특징지어집니다. ThinK는 주의 가중치 손실을 최소화하면서 가장 중요하지 않은 채널을 선택적으로 제거할 수 있도록 설계되었습니다.

- **Performance Highlights**: 제안된 ThinK 방식은 모델의 정확도를 유지하거나 향상시키면서, 기존 KV 캐시 교체 방법과 비교하여 메모리 비용을 20% 이상 절감합니다. LLaMA3와 Mistral 모델을 사용한 다양한 긴 시퀀스 데이터셋에서의 평가를 통해 ThinK의 효율성이 입증되었습니다. 또한, ThinK의 가치 캐시 프루닝 (value cache pruning)으로 확장 가능한 가능성도 제시하며, 메모리와 계산 오버헤드 모두를 줄이는 데 있어서의 광범위한 적용 가능성을 보여줍니다.



### CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning (https://arxiv.org/abs/2407.21011)
Comments:
          Accepted by MICCAI 2024

- **What's New**: 최근 Contrastive Language-Image Pre-training (CLIP) 분야에서 자가 지도 학습(self-supervised representation learning)의 많은 진전이 있었습니다. 그러나 기존의 CLIP 같은 접근 방식은 모델과 데이터셋의 규모 때문에 상당한 GPU 자원과 긴 학습 시간을 필요로 합니다. 이로 인해 데이터셋이 적은 의료 분야에서 효과적인 활용이 어렵습니다. 이에 새로운 언어-이미지 대조 학습 방법인 CLEFT를 도입했습니다. 이는 대규모 사전 학습된 언어 및 비주얼 모델의 장점을 활용하여 효율적입니다.

- **Technical Details**: CLEFT는 컨텍스트 기반 프롬프트 학습 전략을 통해 정보 풍부한 임상 진단 데이터와 단순한 클래스 레이블 간의 격차를 줄입니다. 이 방법론은 효율적인 대형 언어 모델과 프롬프트 미세 조정(prompt Fine-Tuning)을 도입하여, 임상 진단 데이터를 효과적으로 활용합니다. 또한, 모델 훈련 파라미터를 39% 줄이고, 학습 가능한 언어 모델 크기를 기존의 BERT 인코더와 비교할 때 4%로 줄였습니다.

- **Performance Highlights**: 제안된 방법론은 여러 흉부 X-ray 및 유방촬영술(mammography) 데이터셋에서 다양한 기준선(baselines)과 비교하여 최첨단 성능을 보였습니다. 특히, 효율적이고 파라미터를 줄일 수 있는 프레임워크를 통해 의료 데이터의 한계를 극복하고 더 나은 진단 성능을 입증했습니다.



### XHand: Real-time Expressive Hand Avatar (https://arxiv.org/abs/2407.21002)
- **What's New**: 새로운 핸드 아바타 시스템인 XHand가 소개되었습니다. XHand는 실시간으로 손의 형태, 외관, 변형을 종합적으로 생성할 수 있도록 설계되었습니다. 이는 가상 현실 및 게임 환경에서 즉석 렌더링이 중요한 역할을 하는 응용 분야에 매우 유용합니다.

- **Technical Details**: XHand는 손 변형 이동(Hand Deformation Displacements), 반사율(Albedo), 선형 블렌딩 스키닝 가중치(Linear Blending Skinning Weights)를 예측하기 위해 세 가지 기능 임베딩 모듈(Feature Embedding Modules)을 사용합니다. 결과적으로, 메쉬 기반 신경 렌더러를 통해 세세한 메쉬(fine-grained meshes)를 실시간으로 포토리얼리스틱(photo-realistic)하게 렌더링할 수 있습니다. 훈련 과정에서는 파트-어웨어 라플라스 평활화 전략(Part-aware Laplace Smoothing Strategy)을 사용하여 필요 없는 아티팩트를 제거하면서 필수적인 세부 사항을 효과적으로 유지합니다.

- **Performance Highlights**: InterHand2.6M 및 DeepHandMesh 데이터셋에 대한 실험적 평가에서 XHand는 다양한 포즈의 손 애니메이션에 대해 높은 충실도의 기하학 및 텍스처를 복원할 수 있는 성능을 입증했습니다. 이는 실시간으로 구현될 수 있으며, 전체 구현은 곧 공개될 예정입니다.



### GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language Models (https://arxiv.org/abs/2407.21001)
- **What's New**: 이 논문은 Vision-language models (VLMs)이 이미지 분석에서 개인의 활동과 관련된 성별 편향(Gender-Activity Binding Bias, GAB)을 어떻게 나타내는지 연구하고 있습니다. 특히, 다양한 성별의 사람들이 여러 활동을 하는 복잡한 상황에서 이 편향이 두드러진다는 점을 강조합니다. 이를 위해 약 5500개의 AI 생성 이미지를 포함한 GAB 데이터셋을 소개하고, 이를 활용하여 성별-활동 연관 편향을 측정합니다.

- **Technical Details**: 연구진은 GAB 데이터셋을 만들기 위해 다양한 활동을 나타내는 약 5500개의 AI 생성 이미지를 사용하였으며, 이미지의 다양성, 품질 및 현실성을 평가했습니다. 12개의 유명한 사전 학습된 VLMs을 텍스트-이미지 및 이미지-텍스트 검색 컨텍스트에서 테스트하여 이 편향이 모델 예측에 미치는 영향을 측정했습니다. 또한, VLMs의 텍스트 인코더(text encoders)에서의 편향을 정량화하고, VLMs이 활동을 인식하는 능력을 평가하기 위한 추가 실험도 수행했습니다.

- **Performance Highlights**: 실험 결과, VLMs은 성별-활동 연관 편향(Gender-Activity Binding Bias) 상황에서 평균 약 13.2%의 성능 저하를 겪는 것으로 나타났습니다. 이는 VLMs이 내재된 성별 편향으로 인해 실제 활동 수행자와 관련된 성별을 올바르게 예측하는 데 어려움을 겪고 있음을 시사합니다.



### MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning (https://arxiv.org/abs/2407.20999)
- **What's New**: 최근 대형 언어 모델 (LLMs)은 다양한 작업에서 놀라운 성능을 보여주고 있습니다. 새로운 파인튜닝 (fine-tuning) 알고리즘인 Momentum-Filtered Optimizer (MoFO)를 제안합니다. MoFO는 반복적으로 모멘텀 크기가 가장 큰 모델 파라미터를 선택하고 업데이트하는 것입니다.

- **Technical Details**: MoFO의 핵심 아이디어는 풀-파라미터 훈련 (full-parameter training)과 비교해 파라미터를 사전 훈련된 모델에 더 가깝게 유지하면서 유사한 파인튜닝 성능을 달성하는 것입니다. 이는 지식 망각 (knowledge forgetting)을 완화합니다. 또한, 대부분의 기존 방법과 달리 MoFO는 사전 훈련 데이터를 필요로 하지 않으며, 체크포인트 전용 오픈 소스 LLMs의 파인튜닝 시나리오에 적합합니다. MoFO는 원래의 손실 함수 (loss function)를 변경하지 않아 파인튜닝 작업에서 모델 성능을 저해할 위험이 없습니다.

- **Performance Highlights**: MoFO는 엄격한 수렴 분석 (convergence analysis)과 광범위한 실험을 통해 기존 방법보다 지식 망각을 효과적으로 완화하고 파인튜닝 성능을 향상시키는 우수성을 입증했습니다.



### Large Language Models (LLMs) for Semantic Communication in Edge-based IoT Networks (https://arxiv.org/abs/2407.20970)
Comments:
          6pages, 3 figures, Magazine

- **What's New**: 최신 5G 및 6G 통신 기술의 등장과 함께, IoT 시대를 맞아 현재의 통신 기술이 샤논 한계(Shannon's limit)에 접근함에 따라, '의미론적 통신'(Semantic Communication)에 대한 연구가 주목받고 있습니다. 본 논문은 대규모 언어 모델(LLMs)이 네트워크 에지(Network Edge)에서 IoT 네트워크의 효율적인 통신을 위해 어떻게 사용할 수 있는지에 대한 프레임워크를 소개합니다.

- **Technical Details**: LLMs는 수십억 개의 매개변수로 구성된 다양한 데이터셋을 통해 광범위하게 훈련되어 인간과 유사한 텍스트를 이해하고 생성할 수 있습니다. 최근 '에지 컴퓨팅'(Edge Computing)과 같은 근접 소스 계산 기술의 발전에 비추어, 이 논문은 다양한 모듈을 포함한 프레임워크를 설명합니다. 이 프레임워크는 의미론적 통신의 우산 아래에서 LLMs를 활용하여 IoT 네트워크에서의 효율적인 통신을 가능하게 합니다.

- **Performance Highlights**: 논문은 이러한 프레임워크를 통한 여러 응용 프로그램과 시스템 개발의 어려움과 기회를 분석하고 있습니다. LLMs를 사용함으로써, 네트워크 에지에서 의미론적 통신이 향상되는 가능성을 제시합니다.



### An Effective Dynamic Gradient Calibration Method for Continual Learning (https://arxiv.org/abs/2407.20956)
- **What's New**: 이번 논문에서는 지속적인 학습(Continual learning, CL) 문제를 그래디언트(gradient) 관점에서 접근하는 새로운 알고리즘을 제안합니다. 이 알고리즘은 모델의 업데이트 단계별로 그래디언트를 보정하여 이전 데이터가 부족한 상황에서도 모델이 올바른 방향으로 학습되도록 안내하는 것을 목표로 합니다.

- **Technical Details**: 제안된 방법은 랜덤 그래디언트 감소(stochastic variance reduction) 방법의 대표적 기법인 SVRG(Stochastic Variance Reduced Gradient)와 SAGA를 영감으로 개발되었습니다. 특히, 이러한 방법을 통해 그래디언트 추정의 분산을 줄이고, 메모리 제한으로 인해 모든 과거 데이터를 저장할 수 없는 상황에서 효과적으로 학습할 수 있는 방법을 제시합니다. 제안된 접근법은 여러 기존의 CL 방법들과 결합하여 더욱 향상된 성능을 얻을 수 있는 범용적인 도구로 활용될 수 있습니다.

- **Performance Highlights**: 여러 벤치마크 데이터셋을 통해 실험한 결과, 제안된 알고리즘이 실질적인 상황에서 우수한 성능을 보인다는 것을 확인하였습니다. 이는 'devastating forgetting' 현상을 효과적으로 완화하며, 기존 방법들보다 더 나은 학습 효율성을 보입니다.



### Emotion-driven Piano Music Generation via Two-stage Disentanglement and Functional Representation (https://arxiv.org/abs/2407.20955)
Comments:
          Proceedings of the 25th International Society for Music Information Retrieval Conference, ISMIR 2024

- **What's New**: 자동 음악 생성에서 감정적 측면을 효과적으로 모델링하기 위한 새로운 접근법이 제안되었습니다. 이 논문은 피아노 연주 생성에서 감정을 분리(disentanglement)하는 두 단계 프레임워크를 탐구합니다. 첫 번째 단계는 리드 시트(lead sheet)의 발렌스를 모델링하고, 두 번째 단계에서는 성능 수준의 속성을 도입하여 각성을 모델링합니다.

- **Technical Details**: 리드 시트의 발렌스(valence)를 모델링하기 위해 주요-단조 음계의 정서적 영향을 포착하는 새로운 기능적 표현(functional representation)을 도입했습니다. 이 표현은 음표, 코드, 키 서명(key signature) 간의 상호작용을 포착하는 데 중점을 두고 있습니다. 두 단계 프레임워크로 감정 모델링을 분리하여 수행합니다. 첫 번째 단계는 리드 시트의 발렌스 모델링, 두 번째 단계는 성능 수준에서의 각성 모델링을 목표로 합니다.

- **Performance Highlights**: 객관적 및 주관적 실험에서 이 프레임워크의 감정적 발렌스와 각성 모델링의 효율성(validated the effectiveness)이 입증되었습니다. 또한, 감정 제어(emotional controls)의 새로운 응용을 통해 감정 중심 음악 생성 분야에서 넓은 가능성을 보여주었습니다.



### Complete Approximations of Incomplete Queries (https://arxiv.org/abs/2407.20932)
Comments:
          accepted at RuleML+RR 2024

- **What's New**: 이 논문은 부분적으로 완성된 데이터베이스에 대한 결합 쿼리의 완전성과 불완전한 쿼리의 근사에 대해 연구합니다. 쿼리와 데이터베이스의 어느 부분이 완전한지 지정하는 완전성 규칙을 사용하여, 쿼리가 완전히 답변될 수 있는지 조사합니다. 불가능한 경우, 쿼리를 최대 완전 전문화 (Maximal Complete Specializations, MCS) 또는 최소 완전 일반화 (Minimal Complete Generalization, MCG)로 재구성하는 방법을 탐구합니다.

- **Technical Details**: MSG (Minimal Complete Specialization Generalization)은 선주문에서 단조 연산자의 최소 고정점으로 특징지을 수 있습니다. MCS (Maximal Complete Specializations)는 완전성 규칙의 재귀적 역방향 적용을 통해 계산될 수 있습니다. 이 두 문제의 복잡성을 연구하고, 각각 ASP와 Prolog 엔진을 사용한 구현 기술을 논의합니다.

- **Performance Highlights**: 논문에서는 부분적으로 완성된 데이터베이스에 대해 쿼리를 완전히 답변할 수 있는지 분석하고, 쿼리를 최적으로 근사화하는 방법을 제안합니다. MCS는 완전성 규칙을 적용하여 재귀적으로 계산되며, MSG는 최소 고정점을 찾는 것과 관련이 있습니다.



### How to Choose a Reinforcement-Learning Algorithm (https://arxiv.org/abs/2407.20917)
Comments:
          40 pages

- **What's New**: 이 연구는 강화 학습(reinforcement learning) 알고리즘과 행동 분포(action-distribution) 패밀리를 선택하는 과정을 간소화합니다. 기존 방법들과 그 특성에 대한 체계적인 개요와, 어떤 경우에 어떤 방법을 선택해야 하는지에 대한 지침을 제공합니다. 또한, 이러한 지침의 인터랙티브 버전이 온라인에서 제공됩니다.

- **Technical Details**: 연구에서는 다양한 강화 학습 알고리즘과 행동 분포 패밀리에 대한 개요와 성격을 상세히 설명합니다. 이를 통해 특정 작업에 최적화된 알고리즘을 선택하는 데 도움을 줍니다. 연구는 이론적 기반과 실용적 사례를 함께 제시하여, 알고리즘 선택 과정을 체계적으로 정리합니다.

- **Performance Highlights**: 강화 학습 알고리즘 선택에 대한 명확한 지침을 제공하며, 이러한 지침을 인터랙티브 버전으로 변환하여 사용자들이 쉽게 접근할 수 있도록 하였습니다. 이는 강화 학습 모델 설계 및 최적화에 큰 도움이 될 것으로 예상됩니다.



### Automated Review Generation Method Based on Large Language Models (https://arxiv.org/abs/2407.20906)
Comments:
          16 pages, 3 figures, 3 tables

- **What's New**: 이번 연구에서는 Large Language Models (LLMs)을 기반으로 문헌 리뷰를 자동으로 생성하는 방법을 제안했습니다. 이는 PDH 촉매 관련 연구에서 343개의 논문을 빠르게 분석하고, 평균적으로 계정 당 몇 초 만에 포괄적인 리뷰를 작성하는 성과를 보였습니다.

- **Technical Details**: 이 방법은 LLM의 '환각(Hallucination)' 문제를 인식하여 다층 품질 관리 전략을 사용하였습니다. LLM의 정확성을 높이고 잘못된 정보를 줄이기 위해 전문가 검증을 통하여 생성된 리뷰의 정확성과 인용의 일관성을 확인했습니다. 또한, LLM '환각' 발생 비율을 0.5% 이하로 줄일 수 있음을 확인했으며, 95% 이상의 신뢰도를 보였습니다.

- **Performance Highlights**: 이 방법을 통해 한 번에 깊이 있는 문헌 리뷰를 생성할 수 있는 Windows 애플리케이션을 출시하였습니다. 이는 연구자들이 최신 연구 동향을 추적하고 추천 문헌을 찾는 데 큰 도움을 주며, 과학 연구 생산성을 높이는 데 큰 기여를 할 것으로 기대됩니다.



### MambaCapsule: Towards Transparent Cardiac Disease Diagnosis with Electrocardiography Using Mamba Capsule Network (https://arxiv.org/abs/2407.20893)
- **What's New**: 이번 논문에서는 불규칙한 심장 박동을 특징으로 하는 심부정맥 진단을 위한 새로운 딥러닝 모델인 MambaCapsule을 소개합니다. 이는 Electrocardiogram (ECG) 신호를 이용하여 심부정맥을 진단하는 모델로, 모델의 해석 가능성을 높이면서도 정확도를 향상시키기 위해 설계되었습니다.

- **Technical Details**: MambaCapsule 모델은 Mamba를 활용한 feature extraction(특징 추출)과 Capsule 네트워크를 사용한 prediction(예측)으로 구성되어 있습니다. 이 모델은 신경망이 신호의 특징과 그들 간의 관계를 학습하여 예측된 선택에서 ECG 신호를 재구성함으로써 인간 뇌의 처리 메커니즘과 유사하게 작동합니다. 신뢰 점수뿐만 아니라 신호 특징을 제공하여 모델 결과의 해석 가능성을 높였습니다.

- **Performance Highlights**: MambaCapsule 모델은 MIT-BIH 및 PTB 데이터셋을 기반으로 AAMI 표준에 따라 평가되었으며, 각각의 테스트 셋에서 99.54%와 99.59%의 정확도를 달성했습니다. 이러한 결과는 표준 테스트 프로토콜에서도 모델의 우수한 성능을 입증합니다.



### Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks (https://arxiv.org/abs/2407.20891)
Comments:
          25 pages, 14 figures, 11 tables

- **What's New**: 이번 연구에서는 Bayesian 신경망(Bayesian Neural Networks, BNNs)의 계산 복잡성을 줄여 대규모 작업에서도 사용할 수 있는 혁신적인 프레임워크를 소개했습니다. 우리의 접근 방식은 딥 앙상블(Deep Ensembles)을 기반으로 하지만, 사전 학습된 신경망의 매개변수에서 여러 저랭크(low-rank) 섭동을 도입하여 비용을 크게 줄였습니다. 이를 Bayesian Low-Rank LeArning (Bella)라고 명명했습니다.

- **Technical Details**: Bella는 사전 학습된 신경망의 매개변수에 여러 저랭크 섭동을 적용하여 Bayesian 포스터리어(Bayesian posterior)를 근사하는데 필요한 학습 가능한 매개변수의 수를 크게 줄입니다. 기존의 단순한 앙상블 뿐만 아니라 이전에는 불가능하다고 여겨졌던 Stein Variational Gradient Descent (SVGD)와 같은 더 복잡한 Bayesian 학습 방법도 Bella 프레임워크 내에서 원활하게 구현할 수 있습니다.

- **Performance Highlights**: Bella는 학습 가능한 매개변수의 수를 줄이면서도 기존 Bayesian 학습 방법과 비-Bayesian 기준치를 유지하거나 경우에 따라 이를 능가하는 성능을 보였습니다. ImageNet, CAMELYON17, DomainNet, VQA with CLIP, LLaVA와 같은 대규모 작업에서 Bella의 효과성과 다재다능함을 입증하였습니다.



### Effective Black Box Testing of Sentiment Analysis Classification Networks (https://arxiv.org/abs/2407.20884)
Comments:
          This paper uses LaTeX with the IEEEtran.cls document class

- **What's New**: 이 논문은 트랜스포머 기반의 감정 분석 네트워크를 위한 테스트 수트(test suite)를 평가하기 위해 설계된 커버리지 기준(coverage criteria)를 제시합니다. 이 접근 방식은 감정과 관련된 언어적 특성(예: 동사, 형용사, 부사, 명사)을 고려한 입력 공간 분할(input space partitioning)을 이용한 블랙박스 방법입니다.

- **Technical Details**: 테스트 케이스를 효과적으로 생성하기 위해 k-프로젝션 커버리지 메트릭(k-projection coverage metric)을 사용합니다. 이 메트릭은 동일한 시간에 k 특성의 하위 집합을 조사하여 문제의 복잡성을 줄입니다. 큰 언어 모델(large language models)을 사용하여 특정 감정적 특성 조합을 나타내는 문장을 생성합니다.

- **Performance Highlights**: 감정 분석 데이터셋에서 얻은 실험 결과, 제안된 기준과 생성된 테스트는 테스트 커버리지가 평균 16% 증가하였으며, 모델의 정확도가 평균 6.5% 감소하는 결과를 보여주었습니다. 이는 취약성을 식별하는 능력을 나타냅니다.



### Learn by Selling: Equipping Large Language Models with Product Knowledge for Context-Driven Recommendations (https://arxiv.org/abs/2407.20856)
- **What's New**: 이 논문은 대형 언어 모델(Large Language Models, LLMs)을 사용한 제품 추천 시스템에 대한 새로운 접근법을 제시합니다. 특정한 제품 ID를 포함한 합성 검색 쿼리에 맞춰 LLMs를 훈련시킴으로써 이들이 제품 인벤토리에 대한 종합적인 이해를 할 수 있도록 합니다.

- **Technical Details**: 논문에서 제시된 방법은 LLMs를 합성 검색 쿼리(synthetic search queries)에 맞춰 훈련시킴으로써, 이들이 주어진 컨텍스트 내에서 적절하게 반응할 수 있게 만드는 것입니다. 이는 제품 추천(product recommendations) 분야에서 LLMs의 유효성을 증진시키기 위한 새로운 방법론입니다.

- **Performance Highlights**: 이 접근법의 유효성에 대한 종합적인 분석을 통해 여러 장점과 한계를 밝혔습니다. 또한, 향후 개선 가능성과 발전 방향에 대해서도 논의하였습니다. 이를 통해 LLMs가 제품 추천 시스템에서 중요한 역할을 할 수 있다는 이해를 제공합니다.



### Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing (https://arxiv.org/abs/2407.20830)
- **What's New**: 새로운 연구는 민감한 데이터를 중앙 집중화 없이 강력한 모델을 개발할 수 있는 협업 학습 패러다임인 연합 학습(federated learning)을 개선한 Federated Knowledge Recycling (FedKR)을 제안합니다. FedKR은 로컬에서 생성된 합성 데이터를 사용하여 기관 간 협업을 촉진하고, 기존 방법보다 프라이버시 공격에 대한 보안을 강화합니다.

- **Technical Details**: FedKR은 고급 데이터 생성 기술과 동적 집계(dynamıc aggregation) 프로세스를 결합하여 수행합니다. 이는 모델, 파라미터 또는 업데이트 노출에 따른 공격 피면을 줄여 프라이버시 및 보안 취약성을 해결합니다. FedKR은 기관 내에서 생성되는 합성 데이터를 사용하여 협업을 촉진합니다.

- **Performance Highlights**: 일반 데이터셋 및 의료 데이터셋에서의 실험 결과, FedKR은 로컬 데이터로부터 모델을 학습시키는 방법에 비해 평균 정확도가 4.24% 향상되었으며, 데이터가 부족한 시나리오에서 특히 효과적임이 입증되었습니다.



### Diffusion Augmented Agents: A Framework for Efficient Exploration and Transfer Learning (https://arxiv.org/abs/2407.20798)
Comments:
          Published at 3rd Conference on Lifelong Learning Agents (CoLLAs), 2024

- **What's New**: 새로운 Diffusion Augmented Agents (DAAG) 프레임워크를 소개합니다. 이 프레임워크는 대규모 언어 모델(large language models), 비전-언어 모델(vision language models), 그리고 확산 모델(diffusion models)을 활용해 강화 학습의 샘플 효율성과 전이 학습(transfer learning)을 향상시킵니다. 주어진 타겟 지시 사항에 맞게, 에이전트의 과거 경험을 확산 모델을 사용해 시간적 및 기하학적으로 일관된 방식으로 변환하는 Hindsight Experience Augmentation 기술을 사용합니다.

- **Technical Details**: 이 프레임워크는 대규모 언어 모델(large language model)이 사람의 감독 없이 자율적인 과정을 조율하며, 평생 학습 시나리오에 잘 적합합니다. 이 과정은 보상 라벨이 붙은 데이터의 양을 줄여, 시각 언어 모델을 세밀하게 튜닝하거나 새로운 작업을 학습하는 강화 학습 에이전트를 훈련시키는 데 사용됩니다. 구체적으로, DAAG는 과거의 경험을 활용해 보상 감지기를 학습하고 새로운 작업을 습득하는 데 중요한 역량을 갖춘 효율적인 평생 학습 에이전트 개발에 기여합니다.

- **Performance Highlights**: 우리는 조작(manipulation)과 네비게이션(navigation)을 포함하는 시뮬레이션된 로봇 환경에서 DAAG의 샘플 효율성 향상을 입증했습니다. 결과적으로 DAAG는 보상 감지기(reward detectors)의 학습, 과거 경험의 전이, 그리고 새로운 작업 획득에서 향상된 성능을 보여주었습니다. 추가 자료와 시각화는 웹사이트에서 확인할 수 있습니다.



### Be aware of overfitting by hyperparameter optimization! (https://arxiv.org/abs/2407.20786)
Comments:
          19 pages, 5 Tables

- **What's New**: 이 논문은 용해도(prediction) 예측에 사용된 최신 그래프 기반 기법과 Natural Language Processing(NLP) 방식인 Transformer CNN을 비교 분석한 연구 결과를 소개합니다. 특히, Hyperparameter optimization(하이퍼파라미터 최적화)이 항상 더 나은 모델을 가져오지 않을 수 있으며, 사전 설정된 하이퍼파라미터를 사용할 경우 계산 노력을 약 10,000배 줄일 수 있다는 점을 강조합니다.

- **Technical Details**: 연구에서는 7개의 열역학 및 동역학 용해도 데이터셋을 사용하여 다양한 데이터 정리 프로토콜과 하이퍼파라미터 최적화를 적용한 모델을 비교하였습니다. 이들 모델은 Transformer CNN과 그래프 기반 방법들 사이의 28개의 쌍별 비교에서 26개 경우 Transformer CNN이 더 나은 성능을 보여주었음을 입증했습니다. Transformer CNN은 SMILES(simplified molecular-input line-entry system) 데이터를 기반으로 한 NLP 기법을 활용합니다.

- **Performance Highlights**: Transformer CNN은 동일한 프로토콜을 사용한 모든 분석 세트에서 그래프 기반 기법보다 나은 결과를 보여주었으며, 계산 시간도 다른 방법에 비해 극히 적게 소요되었습니다. 이 연구는 하이퍼파라미터 최적화가 항상 유효하지 않음을 보여주며, 동일한 통계 측정을 사용한 결과 비교의 중요성을 강조합니다.



### Interpretable Pre-Trained Transformers for Heart Time-Series Data (https://arxiv.org/abs/2407.20775)
Comments:
          14 pages, 5 figures

- **What's New**: 새로운 연구에서는 GPT 시리즈처럼 디코더 전용 transformer를 주기적인 심장 타임 시리즈 데이터에 적용하여 두 가지 사전 학습된 일반 목적 심장 모델, 즉 PPG-PT와 ECG-PT를 생성했습니다. 이 모델들은 완전히 해석할 수 있다는 것이 입증되었습니다.

- **Technical Details**: 이 논문에서는 aggregate attention maps를 사용하여 모델이 예측을 위해 이전 심장 주기의 유사한 지점에 집중하고, 심층 레이어에서 점차적으로 주의를 확장하는 것을 보여주었습니다. 또한, 동일한 값을 갖는 토큰들이 ECG와 PPG 주기의 서로 다른 지점에서 고차원 공간에서 위상에 따라 별도의 클러스터를 형성한다는 것을 입증했습니다. 개별 attention heads가 PPG의 dicrotic notch나 ECG의 P파 같은 생리학적으로 중요한 특징에 반응한다는 것도 강조되었습니다.

- **Performance Highlights**: 이 사전 학습된 모델들은 심방세동 분류와 같은 작업에 대해 쉽게 세밀 조정(fine-tuning)이 가능하며, 이 특정 예에서 세밀 조정에는 11분의 컴퓨터 시간이 걸렸고, 각각 ECG와 PPG에서 leave-one-subject-out AUC가 0.99와 0.93을 달성했습니다. 중요한 점은, 이 세밀 조정된 모델들도 완전히 설명 가능하며, 심방세동을 강력히 시사하는 컨텍스트의 영역으로 주의가 이동하는 것을 확인할 수 있었습니다.



### Cost-Based Semantics for Querying Inconsistent Weighted Knowledge Bases (https://arxiv.org/abs/2407.20754)
Comments:
          This is an extended version of a paper appearing at the 21st International Conference on Principles of Knowledge Representation and Reasoning (KR 2024). 20 pages

- **What's New**: 본 논문에서는 불일치가 있는 설명 논리(Description Logic) 지식베이스를 질의하는 양적 접근법을 탐구합니다. 지식베이스의 공리와 주장에 (무한 가능성을 가지는) 가중치를 부여하고, 이를 기반으로 해석 비용을 산정합니다. 주어진 한도 내에서의 비용을 고려하는 해석과 최적 비용 해석 두 가지 개념을 기반으로 특정 답변과 가능한 답변을 정의합니다.

- **Technical Details**: 이 연구에서는 공리와 주장에 가중치를 부여하여 각 해석의 비용을 산정합니다. 비용이 주어진 한도를 초과하지 않는 해석 혹은 최적 비용 해석을 사용하여 특정 답변(certain answer)과 가능한 답변(possible answer)을 정의합니다. ELbot에서 ALCO까지의 설명 논리를 대상으로, 유한한 비용 충족 가능성과 특정 및 가능한 답변 인식의 결합 및 데이터 복잡성(combined and data complexity)에 대한 종합적 분석이 이뤄졌습니다.

- **Performance Highlights**: 연구의 주요 공헌은 주어진 한도 내에서의 비용을 고려한 해석과 최적 비용 해석을 바탕으로, 결합 복잡도와 데이터 복잡성에 대한 체계적인 분석을 제공한 것입니다. 이를 통해 불일치가 있는 설명 논리 지식베이스의 질의에 대한 새로운 시각을 제시합니다.



### Efficient Quantum One-Class Support Vector Machines for Anomaly Detection Using Randomized Measurements and Variable Subsampling (https://arxiv.org/abs/2407.20753)
Comments:
          Submitted to Springer Nature CS

- **What's New**: 새 연구는 반양성 경향(variance)과 하위표본 추출(subsampling)의 장점을 결합한 양자 특이 탐지 모델을 제안합니다. 구체적으로는 양자 무작위 측정 커널(Quantum Randomized Measurements Kernels)과 변형된 특징 배깅(Rotated Feature Bagging)을 사용하여 데이터 크기와 특징 수에 대해 선형 시간 복잡도를 달성하는 방법을 개발했습니다.

- **Technical Details**: 이 연구는 양자 단일 클래스 서포트 벡터 머신(Quantum One-Class Support Vector Machines)의 시간 복잡도 문제를 해결하는 데 중점을 두고 있습니다. 양자 무작위 측정 커널은 높은 평균 정확도를 제공하지만, 반양성(variance)이 높은 단점이 있습니다. 변형된 하위표본 추출 방법은 데이터 크기에 대해 선형 시간 복잡도를 가지고 반양성이 낮지만 평균 정확도가 떨어집니다. 이 두 가지 방법과 특징 배깅을 결합함으로써, 데이터 크기와 특징 수에 모두 선형 시간 복잡도를 유지하면서 성능을 향상시켰습니다.

- **Performance Highlights**: 제안된 모델은 성능이 크게 향상되었을 뿐만 아니라, 훈련 및 테스트 시간도 크게 단축되었습니다. 새로운 결합 기법은 두 개의 독립적인 방법의 장점을 합쳐 데이터 크기와 특징 수에 대해 선형적인 시간 복잡도를 달성하여 빠르고 효율적인 양자 특이 탐지 모델을 구성합니다.



### JaColBERTv2.5: Optimising Multi-Vector Retrievers to Create State-of-the-Art Japanese Retrievers with Constrained Resources (https://arxiv.org/abs/2407.20750)
- **What's New**: 최근 Neural Information Retrieval(신경 정보 검색)은 고자원 언어에서 눈부신 발전을 이루었지만, 일본어와 같은 저자원 언어에서는 데이터 부족 등의 문제로 성장이 더뎠습니다. JaColBERT와 같은 최신 멀티벡터 단일 언어 모델이 이러한 격차를 좁히고 있지만, 여전히 대규모 평가에서는 다국어 방법에 뒤처지고 있습니다. 이를 해결하기 위해 JaColBERT의 핵심적인 추론 및 훈련 설정을 체계적으로 평가하고 개선하여 JaColBERTv2.5를 도입했습니다.

- **Technical Details**: JaColBERTv2.5는 다국어 모델의 비효율성과 언어적 뉘앙스를 포착하지 못하는 문제를 해결하기 위해, 특히 저자원 언어 환경에서 멀티벡터 적용 방법의 훈련 방식을 개선했습니다. 또한 새로운 checkpoint merging step(체크포인트 병합 단계)을 도입해 파인튜닝의 이점을 원래 체크포인트의 일반화 능력과 결합했습니다. JaColBERTv2.5 모델은 4개의 A100 GPU에서 15시간 이하로 훈련되었으며, 1억 1천만 개의 파라미터를 가지고 있습니다.

- **Performance Highlights**: JaColBERTv2.5는 모든 공용 벤치마크에서 최고 성능을 달성했으며, 평균 점수 0.754로 이전 최고 기록 0.720보다 크게 앞선 성과를 보였습니다. 이를 위해 최종 모델, 중간 체크포인트 및 사용된 모든 데이터를 공개하여 향후 연구를 지원할 예정입니다.



### Architectural Influence on Variational Quantum Circuits in Multi-Agent Reinforcement Learning: Evolutionary Strategies for Optimization (https://arxiv.org/abs/2407.20739)
- **What's New**: 최근 몇 년간, 다중 에이전트 강화 학습(Multi-Agent Reinforcement Learning, MARL)은 자율 주행, 통신 및 글로벌 헬스 등 다양한 과학 및 산업 분야에 적용되어 왔습니다. 하지만 MARL은 차원의 지수적 증가와 같은 문제를 겪고 있습니다. 이번 연구는 양자 역학의 고유한 속성을 활용하여 이러한 제한을 극복하고자 합니다. 기존 연구들은 그래디언트가 없는 양자 강화 학습과 진화 최적화를 사용하여 학습 파라미터 수를 줄이고, 'barren plateaus' 및 사라지는 그래디언트 문제를 피하는 접근 방식을 개발했습니다.

- **Technical Details**: 이번 연구에서는 Kölle et al.의 접근 방식을 확장하여, Gate-Based, Layer-Based, Prototype-Based 개념을 제안하고 이를 통해 VQCs(Variational Quantum Circuits)를 변형 및 재조합 하였습니다. 추가적으로, 변형 전용 전략과 Gate-Based 접근 방식에서 가장 좋은 성능을 보였습니다. 특히, Coin Game 환경에서 평가된 결과, 최고의 에이전트가 더 높은 점수, 더 많은 총 수집 동전 및 자신의 동전 수집 비율에서 뛰어난 성능을 보였습니다.

- **Performance Highlights**: VQCs는 동일한 수의 학습 파라미터를 가진 기존의 신경망보다 훨씬 더 나은 성능을 보였으며, 비슷한 성능의 신경망과 비교할 때 파라미터 수를 97% 이상 줄일 수 있었습니다. 변형 전용 전략과 Gate-Based 접근 방식에서 최고의 성능을 보였으며, 'Coin Game' 환경에서 최고의 에이전트가 더 높은 점수와 수집한 동전 비율을 보여주었습니다.



### Exploring Loss Landscapes through the Lens of Spin Glass Theory (https://arxiv.org/abs/2407.20724)
Comments:
          21 pages, 10 figures

- **What's New**: 본 논문은 DNNs(deep neural networks)의 내부 표현, 의사 결정 메커니즘, 파라미터 초과 공간에서의 과적합이 없는 현상, 높은 일반화 능력 등 현재까지 명확히 이해되지 않은 요소들을 분석합니다. 이를 위해, 통계 물리학의 스핀 글라스(spin glass)를 통해 DNNs의 손실 지형(loss landscape)을 조사합니다. 특히, 단일 은닉층 ReLU(Rectified Linear Unit) 신경망 모델을 사용하여 MNIST와 CIFAR10 데이터셋을 훈련시켜 스핀 글라스와의 유사성을 평가했습니다.

- **Technical Details**: 논문에서는 다음과 같은 방식을 통해 DNNs의 손실 지형을 분석했습니다: (1) 파라미터 공간에서의 랜덤 워크(random walk)를 사용하여 손실 지형의 구조를 파악; (2) 은닉층의 순열 대칭(permutation symmetry)으로 인해 손실 지형의 동일한 영역 복사본 간의 연결성을 연구하는 순열-보간(protocal-interpolation) 프로토콜 도입; (3) 계층적 군집화(hierarchical clustering)를 통해 훈련된 솔루션 간의 계층 구조를 밝혀 스핀 글라스의 복제 대칭 파괴(Replica Symmetry Breaking; RSB) 현상과 유사한 현상을 확인; (4) 손실 지형의 울퉁불퉁한 정도와 DNN의 일반화 성능 사이의 관계를 평가하여 평탄화된 최소값이 일반화 성능을 개선한다는 결과 도출.

- **Performance Highlights**: DNN의 손실 지형이 복잡한 에너지 지형을 가지고 있으며, 손실 지형의 평탄화된 부분이 DNN의 일반화 성능을 향상시킨다는 점을 발견했습니다. 이로 인해 스핀 글라스의 이론적 틀이 DNN의 작동 방식을 이해하는 데 유용하다는 것을 확인할 수 있었습니다.



### Cocobo: Exploring Large Language Models as the Engine for End-User Robot Programming (https://arxiv.org/abs/2407.20712)
Comments:
          This is the preprint version of a paper accepted for presentation at the IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC), 2024

- **What's New**: Cocobo라는 새로운 자연어 프로그래밍 시스템이 도입되었습니다. 이 시스템은 인터랙티브 다이어그램과 대형 언어 모델(Large Language Models, LLMs)을 활용하여, 사용자가 로봇 프로그램을 작성하고 디버깅할 수 있게 돕습니다.

- **Technical Details**: Cocobo는 사용자 의도를 이해하고, 자동으로 로봇 프로그램을 생성하고 설명하며, 실행 가능한 코드와 플로차트(Flowchart) 표현 간의 변환을 지원하기 위해 LLM을 사용합니다.

- **Performance Highlights**: 사용자 연구 결과, Cocobo는 학습 곡선이 낮아 코딩 경험이 전무한 사용자도 성공적으로 로봇 프로그램을 커스터마이징할 수 있음을 보여줍니다.



### PIP: Prototypes-Injected Prompt for Federated Class Incremental Learning (https://arxiv.org/abs/2407.20705)
Comments:
          Conference on Information and Knowledge Management (CIKM) 2024 (Accepted)

- **What's New**: Federated Class Incremental Learning (FCIL) 분야의 새로운 연구 발표로, 기존 클래스의 데이터를 반복 사용하지 않고도 이전 학습에서의 망각 현상(catastrophic forgetting)과 데이터 분포의 불균형(non-IID data distribution) 문제를 동시에 해결하는 방법을 제시했습니다.

- **Technical Details**: 새롭게 제안된 방법은 프로토타입 삽입(PIP)이라고 불리며, 주요 아이디어는 다음과 같습니다: a) 프로토타입 삽입을 통한 프롬프트 학습 (prototype injection on prompt learning), b) 프로토타입 증강 (prototype augmentation), c) 서버 쪽 가중치가 적용된 가우시안 집계 (weighted Gaussian aggregation).

- **Performance Highlights**: CIFAR100, MiniImageNet, TinyImageNet 데이터셋에서 기존 최첨단(SOTA) 방법들보다 최대 33% 더 높은 성능을 보이며, 다양한 작업 크기에서의 견고성을 입증했습니다. 또한, 참여하는 로컬 클라이언트 수와 글로벌 라운드가 적을수록 유리함을 나타냈습니다. 추가 연구를 위해 소스 코드, 베이스라인 및 실험 로그가 공개되었습니다.



### Boosting Audio Visual Question Answering via Key Semantic-Aware Cues (https://arxiv.org/abs/2407.20693)
Comments:
          Accepted by ACM MM 2024

- **What's New**: 이번 연구에서는 Audio Visual Question Answering (AVQA) 과제와 관련된 Temporal-Spatial Perception Model (TSPM)을 제안합니다. 이 모델은 비디오의 다양한 시각적 객체, 소리, 및 이들의 상호작용에 대한 질문에 답할 수 있도록 설계되었습니다. TSPM은 질문과 관련된 중요한 시각적 및 청각적 단서를 인식하는 데 초점을 맞추고 있습니다.

- **Technical Details**: 비주얼-랭귀지 사전학습 모델을 사용하여 비선언적(non-declarative) 질문과 시각적 표현을 동일한 의미 공간에 맞추는 어려움을 고려하여, 질문 템플릿에서 파생된 선언문 형식의 프롬프트를 작성하였습니다. 이를 통해 중요한 세그먼트를 더 잘 식별할 수 있도록 돕습니다. 그런 다음, 시각 토큰을 선택된 세그먼트에서 병합하여 중요한 잠재적 목표를 강조하는 공간 인식 모듈을 설계하고, 오디오와의 교차 모드를 통해 소리 인식 영역을 인식합니다. 최종적으로 이러한 모듈에서 추출된 중요한 시공간 단서를 통합하여 질문에 답을 합니다.

- **Performance Highlights**: 다양한 AVQA 벤치마크에서 광범위한 실험을 통해 해당 프레임워크가 오디오-비주얼 장면을 이해하고 복잡한 질문에 효과적으로 대답하는 데 뛰어나다는 것이 입증되었습니다. 코드도 공개되었습니다.



### RevGNN: Negative Sampling Enhanced Contrastive Graph Learning for Academic Reviewer Recommendation (https://arxiv.org/abs/2407.20684)
Comments:
          Accepted by ACM Transactions on Information Systems (TOIS)

- **What's New**: 최근 그래프 학습(Graph Learning) 기반 모델들은 추천 시스템 분야에서 상당한 진전을 이루었지만, 학술 리뷰어 추천에서의 성능은 여전히 과제로 남아 있습니다. 그 이유는 관찰되지 않은 상호작용이 부정적 샘플(Negative Samples)로 간주된다는 가정에 기인합니다. 본 연구는 이러한 문제를 해결하기 위해 Pseudo Neg-Label 전략을 도입한 RevGNN이라는 모델을 제안합니다.

- **Technical Details**: RevGNN은 리뷰어 추천을 위해 그래프 대조 학습(Graph Contrastive Learning, GCL)을 강화하는 비지도 학습(Unsupervised Learning) 방식의 Pseudo Neg-Label 전략을 활용합니다. 두 단계 인코더 구조를 통해 과학적 지식과 행동을 각각 인코딩하여 리뷰어의 선호도를 근사합니다.

- **Performance Highlights**: 세 개의 실제 데이터셋에서 수행한 광범위한 실험 결과, RevGNN은 네 가지 메트릭스에서 모든 기준선 모델들을 능가하였습니다. 또한, 구성 요소별 상세 분석을 통해 RevGNN의 각 구성 요소가 효과적임을 확인하였습니다.



### Label-Guided Prompt for Multi-label Few-shot Aspect Category Detection (https://arxiv.org/abs/2407.20673)
- **What's New**: 다중 라벨 소수 샘플 (Multi-label few-shot) 측면 범주 감지 (aspect category detection) 작업에서, 문장 및 범주의 표현이 중요 문제로 나타났습니다. 현재 방법들 대부분은 키워드 추출에 의존하지만, 이 방법은 문장에서 범주와 상관 없는 단어까지 포함하게 되어 최적의 성능을 내기 어렵습니다. 대신, 이 논문은 라벨 유도 프롬프트 (label-guided prompt) 방법을 제안하여 문장 및 범주 표현을 개선합니다.

- **Technical Details**: 제안된 방법은 라벨 특정 프롬프트를 사용하여 문장을 결정적 맥락 및 의미 정보와 결합하여 표현합니다. 이 라벨은 대형 언어 모델 (large language model) 을 활용하여 범주의 특징을 포함한 범주 설명을 생성하는 데 사용됩니다. 이 범주 설명은 차별적인 범주 원형 (category prototypes) 구축을 안내합니다.

- **Performance Highlights**: 제안된 방법은 두 개의 공개 데이터셋에서 실험 결과 현재 최첨단 방법들을 3.86% - 4.75%의 Macro-F1 점수로 능가하는 성능을 보여주었습니다.



### A Tutorial on the Use of Physics-Informed Neural Networks to Compute the Spectrum of Quantum Systems (https://arxiv.org/abs/2407.20669)
Comments:
          17 pages, 4 figures

- **What's New**: 양자 다체 시스템(Quantum many-body systems)의 모의(simulation)에 인공지능을 활용하는 새로운 접근법이 소개되었습니다. 특히, 물리 정보를 내포한 신경망(Physics-Informed Neural Network, PINN)이 슈뢰딩거 방정식(Schrödinger equation)의 고유값(eigenvalues)과 고유함수(eigenfunctions)를 구하는 방법을 설명합니다.

- **Technical Details**: PINN은 자동 미분(Automatic Differentiation)을 활용해 메쉬(mesh)가 필요 없는 방식으로 적분-미분 방정식(Integro-Differential Equations)을 해결합니다. 특히, 이 방법은 무감독 학습(unsupervised) 방식으로, 물리 시스템에 대한 추가 지식을 손실 함수(loss)에 도입하여 더 빠르고 정확한 수렴(convergence)을 가능하게 합니다. 또한, 무한 잠재력 우물 및 고리를 이루는 입자 문제에 적용하여 복소수 고유함수(complex-valued eigenfunctions)와 퇴화 상태(degenerate states)를 다루는 방법을 구체적으로 설명합니다.

- **Performance Highlights**: PINN 방법은 바닥 상태(ground state)부터 시작해 점진적으로 상태를 발견해 나가는 방식으로, 효율적으로 고유값과 고유함수를 찾을 수 있습니다. 또한, 메쉬가 필요 없는 특성을 활용하여 콜로케이션 포인트(collocation points)를 스마트하게 선택함으로써 성능을 향상시킵니다.



### Rethinking the Function of Neurons in KANs (https://arxiv.org/abs/2407.20667)
- **What's New**: Kolmogorov-Arnold Networks (KANs)의 뉴런은 기존에 Kolmogorov-Arnold 표현 정리에 따라 단순 합산(sum)을 사용하고 있었습니다. 본 연구에서는 KAN 뉴런에 대해 합산을 대체할 수 있는 새로운 다변수 함수(multivariate function)를 탐색하였습니다. 다양한 머신러닝(Machine Learning) 벤치마크 테스크에서 평균 함수(average function)를 적용한 결과, 전통적인 KAN보다 더 우수한 성능 향상을 이룰 수 있음을 발견했습니다.

- **Technical Details**: 본 연구는 KAN 뉴런에서 합산을 평균 함수로 대체하여 실험을 진행하였습니다. 이를 통해 스플라인(spline)의 입력을 활성화 함수(activation function)의 유효 범위 내로 제한함으로써 학습의 안정성을 높였다는 중요한 발견을 하였습니다.

- **Performance Highlights**: 평균 함수를 채택한 KAN 뉴런은 전통적인 KAN에 비해 상당한 성능 향상을 보였습니다. 이는 기존 합산 함수 대신 평균 함수를 사용함으로써 실현된 것입니다.



### Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks (https://arxiv.org/abs/2407.20657)
Comments:
          Accepted to ECCV 2024, Project Page: this https URL

- **What's New**: 최근의 비전-언어(foundation models) 모델들, 예를 들어 CLIP,은 다양한 다운스트림(downstream) 작업 및 도메인에서 전이학습이 가능한 표현을 학습하는 데 뛰어난 성능을 보여주었습니다. 이러한 강력한 모델들이 등장함에 따라 이들의 능력을 어떻게 효과적으로 활용하여 복잡한 비전 작업을 해결할 것인가가 중요한 문제가 되었습니다. 이번 연구에서는 PDCL-Attack이라는 새로운 전이 공격(transfer attack) 방식을 제안합니다. 이 방법은 CLIP 모델을 활용하여 생성 모델 기반의 공격 프레임워크에서 생성된 적대적 교란(adversarial perturbations)의 전이성(transferability)을 증대시킵니다.

- **Technical Details**: 구체적으로, 우리는 텍스트의 의미 표현력(semantic representation power), 특히 입력 이미지의 정답 클래스 레이블(ground-truth class labels)을 이용한 효과적인 프롬프트 구동형 피처 가이던스(prompt-driven feature guidance)를 공식화했습니다. 우리의 지식에 따르면, 우리는 전이 가능한 생성 공격을 향상시키기 위해 프롬프트 학습(prompt learning)을 도입한 최초의 연구입니다.

- **Performance Highlights**: 다양한 크로스 도메인(cross-domain) 및 크로스 모델(cross-model) 환경에서 진행된 광범위한 실험에서는 우리의 접근 방식이 최첨단 방법(state-of-the-art methods)보다 우수함을 실증적으로 입증하였습니다.



### Prompting Encoder Models for Zero-Shot Classification: A Cross-Domain Study in Italian (https://arxiv.org/abs/2407.20654)
Comments:
          Submitted to 'Language Resource and Evaluation'

- **What's New**: 이 논문은 이탈리아어 법률 및 행정 언어에 특화된 도메인별 엔코더 언어 모델(encoder LMs)을 사용하여 성능을 향상시키는 방법을 탐구합니다. 이는 일반적으로 영어 코퍼스에 기반을 둔 대형 언어 모델(LLMs)의 한계를 보완하고자 합니다. 특히, 도메인 특화된 소형 모델과 프롬프트(prompting) 기술을 결합하여 효율성을 높이는 가능성을 실험하였습니다.

- **Technical Details**: 연구는 문서 분류(document classification)와 엔티티 타이핑(entity typing)과 같은 다운스트림 작업에서 일반 목적의 모델과 추가로 사전 훈련된 전용 엔코더-온리 모델(encoder-only models)을 평가하였습니다. 또한, 의사 로그 가능성(Pseudo-Log-Likelihood)을 사용하여 내적 평가를 수행하였습니다. 추가 사전 훈련된 모델은 일반 지식에서는 강건성이 떨어질 수 있지만, 도메인 특화된 작업에는 더 우수한 적응성을 보입니다.

- **Performance Highlights**: 도메인 특화된 모델은 제로샷(zero-shot) 설정에서도 뛰어난 성능을 발휘하였으며, 보정 기법(calibration techniques)과 인도메인 도메인 전용 단어(in-domain verbalizers)의 적용으로 효율성이 크게 향상되었습니다. 이러한 도메인 특화된 모델은 특히 인도메인 자원이나 전문 지식이 부족한 상황에서 매우 유용합니다.



### FACL-Attack: Frequency-Aware Contrastive Learning for Transferable Adversarial Attacks (https://arxiv.org/abs/2407.20653)
Comments:
          Accepted to AAAI 2024, Project Page: this https URL

- **What's New**: 이 논문에서는 딥 뉴럴 네트워크의 취약한 보안 문제를 해결하기 위해 주파수 영역에서 특징 대조(feature contrastive) 접근 방식을 도입하여 교차 도메인(cross-domain)과 교차 모델(cross-model) 설정에서 견고한 적대적 예시(adversarial examples)를 생성하는 방법을 탐구합니다.

- **Technical Details**: 제안된 두 가지 모듈은 훈련 단계에서만 사용됩니다. 첫 번째 모듈은 FADR(Frequency-Aware Domain Randomization) 모듈로, 도메인 변이성이 있는 저주파 및 고주파 성분을 무작위화(randomize)합니다. 두 번째 모듈은 FACL(Frequency-Augmented Contrastive Learning) 모듈로, 깨끗한 이미지와 왜곡된 이미지의 도메인 불변 중간 주파수 요소를 효과적으로 분리합니다. 이 두 모듈을 통해 견고한 적대적 예시를 생성합니다.

- **Performance Highlights**: 제안된 방법은 광범위한 교차 도메인 및 교차 모델 실험을 통해 생성된 적대적 교란(perturbations)의 강력한 이식성(transferability)을 입증하며, 추론 시간 복잡성(inference time complexity)을 유지합니다.



### No learning rates needed: Introducing SALSA -- Stable Armijo Line Search Adaptation (https://arxiv.org/abs/2407.20650)
Comments:
          published in IJCNN 2024. arXiv admin note: text overlap with arXiv:2403.18519

- **What's New**: 이번 연구에서는 기존의 선형 탐색 알고리즘 (line search methods)이 갖고 있는 문제점을 식별하고, 이를 개선하는 방법을 제안했습니다. 특히, 기존의 Armijo 선형 탐색 방법을 더 빠르게 계산하고, 모멘텀 항 (momentum term)을 추가하여 스토캐스틱 미니 배칭 (stochastic mini-batching)에 적합하게 만들었습니다. 이를 통해 학습률 조정이 필요 없는 최적화 방법론을 개발하였습니다.

- **Technical Details**: 새로운 최적화 접근 방식은 Armijo 조건을 활용하면서도 본래의 계산 속도를 증가시키고 모멘텀 항을 도입하여 스토캐스틱 미니 배칭에 더 효과적으로 적용될 수 있게 했습니다. 이러한 개선된 방법은 Adam과 SGD 옵티마이저에 대해 학습률 조정이 잘 튜닝된 경우보다 더 우수한 성능을 보였습니다. 다양한 아키텍처(Transformers, CNNs, MLPs)와 데이터 도메인(NLP, 이미지 데이터)에서도 평가되었습니다.

- **Performance Highlights**: 새로운 최적화 기법은 기존의 Armijo 구현체 및 잘 조정된 Adam과 SGD 학습률 스케줄을 모두 능가하는 성능을 보여주었습니다. 이 방법론은 대규모 데이터셋과 복잡한 데이터 도메인에서도 뛰어난 성능을 발휘하며, 매우 다양한 아키텍처에 적용되었습니다. 최적화 코드는 PyTorch 옵티마이저로서 Python 패키지 형태로 공개되었으며, 누구나 쉽게 사용할 수 있습니다.



### Leveraging Multi-facet Paths for Heterogeneous Graph Representation Learning (https://arxiv.org/abs/2407.20648)
Comments:
          9pages

- **What's New**: 최근 그래프 신경망 (GNN)과 이종 그래프 신경망 (HGNN) 분야에서 노드 임베딩과 관계 학습이 다양한 작업에 대해 크게 발달하였습니다. 그러나 기존 방법들은 종종 도메인 특화 사전 정의된 메타-패스(meta-paths)에 의존하여, 더 복잡한 상호작용을 잡아내기 어려웠습니다. 새로운 모델인 MF2Vec이 소개되었습니다. 이 모델은 사전 정의된 메타-패스 대신 다중 측면 경로(multi-faceted paths)를 사용하여 더 세밀하게 경로를 학습합니다.

- **Technical Details**: MF2Vec은 랜덤 워크(random walk)를 통해 경로를 추출하고, 사전 정의된 스키마를 무시하며 다중 측면 벡터(multi-faceted vectors)를 생성합니다. 이를 통해 노드와 그 관계의 다양한 측면을 학습하며, 동질적 네트워크(homogeneous network)를 구축하고 노드 임베딩을 통해 분류(classification), 링크 예측(link prediction), 군집화(clustering)에 활용할 수 있습니다. 해당 코드도 공개되어 쉽게 접근할 수 있습니다.

- **Performance Highlights**: 광범위한 실험 결과, MF2Vec은 기존 방법들을 능가하며, 복잡한 네트워크를 분석하는데 더 유연하고 포괄적인 프레임워크를 제공합니다. 이는 다양한 작업에서 우수한 성능을 입증하였습니다.



### Autonomous Improvement of Instruction Following Skills via Foundation Models (https://arxiv.org/abs/2407.20635)
- **What's New**: 이번 연구는 자율적으로 수집된 데이터를 통해 작동 지시를 따르는 로봇의 성능을 향상시키는 새로운 접근 방식을 제안합니다. 이 접근법은 인간의 감독 없이 데이터를 수집하고 학습할 수 있는 로봇 개발의 가능성을 열어줍니다.

- **Technical Details**: 우리의 프레임워크는 비전-언어 모델(vision-language models)를 활용하여 새로운 환경에서 의미 있는 경험을 수집하고 평가합니다. 이후, 지시 사항을 (의미있는) 언어 조건부 이미지 생성과 (의미없는) 목표 달성으로 분해하는 방법을 사용하여 자율적으로 수집된 데이터로부터 인간 주석 없이 향상될 수 있는 방법을 제공합니다.

- **Performance Highlights**: 실험 결과, 새로운 환경에서도 자율적으로 수집된 데이터를 통해 로봇 정책(robot policy)을 크게 향상시킬 수 있음을 확인했습니다. 5개 테이블탑 환경에서 30,500개의 경로를 수집한 자율 데이터 셋과 우리의 의미 있는 자율 향상 파이프라인 코드를 오픈소스로 공개합니다.



### Pruning Large Language Models with Semi-Structural Adaptive Sparse Training (https://arxiv.org/abs/2407.20584)
- **What's New**: 최근에 Transformer 기반 대형 언어 모델들(LLMs)이 다양한 어려운 과제에서 눈에 띄는 성공을 거두었습니다. 그러나, 이 모델들을 배포하는 데는 매개변수 수와 메모리 소비량이 커서 많은 제약이 따릅니다. 이를 해결하기 위해 새로운 훈련 파이프라인, Adaptive Sparse Trainer (AST)를 제안합니다. 이 방법은 모델이 훈련 중 적응적으로 더 나은 높이표(mask)를 선택하게 합니다.

- **Technical Details**: AST는 밀도 모델에서 저장된 지식을 증류(distilling)하여 드문드문한 모델의 과대적합(overfitting)을 방지하며, 안정적인 훈련 과정을 보장합니다. 또한, 추가로 잘 초기화된 매개변수를 모델에 추가하여 메모리 소비량을 약간만 증가시키면서도 성능을 향상시킬 수 있음을 발견했습니다. AST는 좁은 컴퓨팅 비용을 유지하면서도 밀도 모델과 드문 모델 간의 성능 격차를 현저히 줄입니다. 더불어, 기존의 양자화(quantization) 방법과 결합하면, AST는 dense FP32 precision 모델에 비해 최대 16배까지 언어 모델을 압축하면서도 성능의 손실을 최소화합니다.

- **Performance Highlights**: AST는 Llama2-7B 모델에서 여러 zero-shot 작업에 대해 dense와 준구조적 sparse 모델 간의 zero-shot 정확도 격차를 1.12%까지 줄이며, 사전 훈련 토큰의 0.4% 미만을 사용하면서도 이전의 최첨단 방법들보다 더 나은 성능을 보입니다.



### Image-based Detection of Segment Misalignment in Multi-mirror Satellites using Transfer Learning (https://arxiv.org/abs/2407.20582)
- **What's New**: 이 논문에서 우리는 멀티미러 위성, 특히 향후 CubeSat 디자인과 제임스 웹 우주 망원경(JWST)에서 세그먼트 불일치를 감지하는 전이 학습(transfer learning) 기반 시스템을 소개합니다. 환경적 요인들로 인해 미러 세그먼트가 불일치할 때 이미지가 왜곡되어 '고스트 이미지(ghost image)'라고 불리는 자체의 이동된 복사본이 나타날 수 있습니다.

- **Technical Details**: 세그먼트 불일치를 감지하기 위해, 우리는 대규모 이미지 모델을 이전 학습(pre-trained)하여, 위성 이미지의 회색조 패치에서 Fast Fourier Transform (FFT)을 적용했습니다. 다중 미러 디자인은 임의의 수의 미러를 사용할 수 있으며, 본 실험에서는 4, 6, 8개의 세그먼트를 가진 모의 CubeSat로 테스트를 수행했습니다. 위성이 불일치한 세그먼트를 가졌는지 여부와 얼마나 많은 세그먼트가 불일치했는지를 판단하기 위해 시스템 설계를 고안했습니다.

- **Performance Highlights**: 고스트 이미지의 강도는 불일치한 세그먼트 수에 비례합니다. 강도 분류(intensity classification)를 위해 훈련된 모델은 N-1 세그먼트를 분류하려 했으며, 이진 모델(binary models)은 8개 클래스에서 98.75%의 분류 정확도를 달성했고, 강도 분류 모델은 98.05%의 정확도를 기록했습니다.



### Comparison of Large Language Models for Generating Contextually Relevant Questions (https://arxiv.org/abs/2407.20578)
Comments:
          Published in Springer ECTEL 2024 conference proceedings

- **What's New**: 이 연구는 대형 언어 모델(LLMs, Large Language Models)이 교육 환경에서 자동 질문 생성(Automatic Question Generation)에 얼마나 효과적인지를 탐구합니다. 대학 슬라이드 텍스트에서 질문을 생성하기 위해 세 가지 LLMs을 비교했습니다. 미세 조정(fine-tuning) 없이 슬라이드 텍스트에서 질문을 만들어내는 능력을 평가했습니다. 특히 LLMs의 질문 생성 능력을 조사한 것은 이번 연구가 처음입니다.

- **Technical Details**: 질문 생성은 두 단계로 수행되었습니다. 첫째, Llama 2-Chat 13B를 사용하여 슬라이드에서 답변 구를 추출했습니다. 둘째, 각 답변에 대해 세 가지 모델(GPT-3.5, Llama 2-Chat 13B, Flan T5 XXL)이 질문을 생성했습니다. 46명의 학생들이 246개의 질문을 평가하여, 명확성(clarity), 관련성(relevance), 난이도(difficulty), 슬라이드와의 관계(slide relation), 질문-답변 일치(question-answer alignment) 다섯 가지 메트릭으로 조사했습니다.

- **Performance Highlights**: 결과에 따르면, GPT-3.5와 Llama 2-Chat 13B 모델이 Flan T5 XXL 모델보다 약간 더 우수한 성능을 나타냈습니다. 특히 명확성과 질문-답변 일치 부문에서 두 모델이 우수했으며, GPT-3.5는 답변에 맞춘 질문을 만드는 데 특히 뛰어났습니다. 이번 연구는 교육용 자동 질문 생성에서 LLMs의 가능성을 분석한 점에서 큰 기여를 했습니다.



### Pyramid Coder: Hierarchical Code Generator for Compositional Visual Question Answering (https://arxiv.org/abs/2407.20563)
Comments:
          Accepted to the IEEE International Conference on Image Processing (IEEE ICIP) 2024

- **What's New**: 이 논문에서는 Programmatic Visual Question Answering (PVQA) 모델을 개선하기 위해 새로운 프레임워크인 PyramidCoder를 소개했습니다. PyramidCoder는 계층적 구조를 가지고 있으며, 각각의 계층은 질문 재구성(query rephrasing), 코드 생성(code generation), 답변 통합(answer aggregation)이라는 고유한 목적을 가지고 있습니다. 이 프레임워크는 고정된 Large Language Model (LLM)과 사전 정의된 프롬프트를 사용하여 추가적인 학습 없이 다양한 LLM 아키텍처에서 유연하게 적용될 수 있습니다.

- **Technical Details**: PyramidCoder는 세 가지 계층으로 구성된 프레임워크로, 각 계층은 다음과 같은 역할을 합니다: 1. Query Rephrasing: 질문을 재구성하여 이해하기 쉽게 합니다. 2. Code Generation: 재구성된 질문을 기반으로 실행 가능한 코드를 생성합니다. 3. Answer Aggregation: 생성된 코드의 결과를 통합하여 최종 답변을 도출합니다. 이 과정에서 하나의 고정된 LLM과 사전에 정의된 프롬프트를 사용하므로 추가 학습이 필요 없습니다.

- **Performance Highlights**: PyramidCoder는 최신 기술을 적용한 PVQA 모델과 비교했을 때, GQA 데이터셋에서 적어도 0.5%, VQAv2 데이터셋에서 1.4%, NLVR2 데이터셋에서 2.9%의 정확도 향상을 이루었습니다.



### CELLM: An Efficient Communication in Large Language Models Training for Federated Learning (https://arxiv.org/abs/2407.20557)
Comments:
          22 pages, 10 figures

- **What's New**: 이번 논문에서는 선도적인 모델 학습 패러다임인 연합 학습(Federated Learning, FL)에 최적화된 대형 언어 모델(Large Language Models, LLMs) 훈련 방법을 제안합니다. 특히, 다양한 로컬 데이터 분포를 가진 클라이언트들이 협업하는 연합 학습에서 발생하는 통계적 이질성을 해결하기 위해 LLMs의 잠재력을 탐구합니다. 본 연구는 LLMs의 효율적인 훈련을 위해 두 가지 핵심 기술을 채택했습니다: 낮은 랭크 적응(LoRA)과 희소 업데이트.

- **Technical Details**: 크게 두 가지 기술이 사용되었습니다. 첫째는 LoRA(Low-Rank Adaptation) 기법을 통해 로컬 모델 훈련의 계산 부하를 줄였습니다. 둘째, 훈련 과정에서 희소 업데이트(Sparse Updates)를 사용하여 통신 비용을 크게 줄였습니다. 이 두 기술을 결합하여, 통신 비용을 기존의 LoRA 대비 최대 10배, 더 복잡한 희소 LoRA 기반 방법 대비 최대 5배까지 감소시켰습니다.

- **Performance Highlights**: 제안된 방법은 기본적인 LoRA와 비교하여 통신 비용을 최대 10배 절감하고, 더욱 복잡한 희소 LoRA 기법과 비교했을 때도 최대 5배의 통신 비용 절감을 이루었으며, 그럼에도 불구하고 더 높은 유틸리티를 달성했습니다. 효과적인 랭크와 희소성 구성을 신중하게 선택하는 것이 연합 학습에서 LLMs를 훈련하는 데 중요하다는 점을 강조하고 있습니다.



### DuA: Dual Attentive Transformer in Long-Term Continuous EEG Emotion Analysis (https://arxiv.org/abs/2407.20519)
Comments:
          11 pages, 3 figures

- **What's New**: 감정 두뇌-컴퓨터 인터페이스(aBCI)는 EEG 신호를 통해 감정 상태를 모니터링하고 해석하는 데 잠재력이 크다고 인정받고 있습니다. 본 연구에서는 장기 연속 EEG 감정 분석을 위한 'Dual Attentive (DuA) Transformer' 프레임워크를 제안했습니다. 기존의 세그먼트 기반 접근 방식과 달리, DuA는 전체 EEG 실험(trial)을 하나의 단위로 처리하여 감정을 인식합니다.

- **Technical Details**: 제안된 DuA Transformer 프레임워크는 세 가지 핵심 모듈을 포함합니다. 첫째, 'Spatial-Spectral Network Module'은 EEG 신호의 공간적 및 스펙트럼 정보를 동시에 포착합니다. 둘째, 'Temporal Network Module'은 장기적인 EEG 데이터 내의 시간적 의존성을 감지합니다. 셋째, 'Transfer Learning Module'은 다양한 피험자 및 조건에 대한 모델 적응성을 향상시킵니다. 이러한 구조는 기존의 방법보다 다양한 시간 길이에 적응할 수 있는 이점을 제공합니다.

- **Performance Highlights**: 자체 제작한 장기 EEG 감정 데이터베이스와 두 개의 벤치마크 EEG 감정 데이터베이스를 사용하여 DuA Transformer를 광범위하게 평가했습니다. 'Trial-based Leave-One-Subject-Out Cross-Subject Cross-Validation' 프로토콜에 기반한 실험 결과, 제안된 DuA Transformer는 기존 방법들보다 장기 연속 EEG 감정 분석에서 평균 5.28%의 성능 향상을 보여주었습니다.



### High-Resolution Spatial Transcriptomics from Histology Images using HisToSGE (https://arxiv.org/abs/2407.20518)
- **What's New**: 새로운 연구는 'HisToSGE'라는 방법을 개발하여, 조직 샘플 내에서 고밀도의 유전자 발현 프로파일을 예측하고 분석하는 새로운 접근 방식을 제안합니다. 이 기술은 기존의 방법들이 가지는 이미지 특징 캡쳐의 한계를 극복하고 유전자 발현 프로파일의 고해상도 예측을 가능하게 합니다.

- **Technical Details**: HisToSGE는 병리 이미지 큰 모델(Pathology Image Large Model, PILM)을 활용하여 조직 이미지에서 풍부한 이미지 특징을 추출합니다. 그리고 특징 학습 모듈(feature learning module)을 통해 고해상도의 유전자 발현 프로파일을 생성합니다. 이 접근법은 기존의 저차원 위치 좌표에 의존하는 방법들을 개선하여 보다 정확한 결과를 제공합니다.

- **Performance Highlights**: HisToSGE는 네 가지 ST 데이터셋에서 다섯 가지 최신 방식들과 비교 평가되었습니다. 그 결과, HisToSGE는 고해상도 유전자 발현 프로파일 생성 및 공간 도메인 식별(spatial domain identification) 등의 후속 작업에서 뛰어난 성능을 보여주었습니다. 관련 모든 코드와 공개 데이터셋은 논문 내 제공 링크를 통해 접근이 가능합니다.



### Machine Unlearning in Generative AI: A Survey (https://arxiv.org/abs/2407.20516)
- **What's New**: 새로운 연구는 Generative AI (생성적 인공지능)에서 머신 언러닝 (Machine Unlearning, MU) 기술을 사용하는 방법을 조사합니다. 이는 기존의 분류 작업에 사용되던 MU 기술이 생성적 AI에 적용될 수 없다는 문제를 해결하기 위한 것입니다.

- **Technical Details**: 이 논문은 MU의 새로운 문제 정식화, 평가 방법, 그리고 다양한 MU 기술의 장단점에 대한 체계적 논의를 포함합니다. 특히, 웹 크롤링 데이터를 사용한 훈련으로 인해 모델이 기밀 정보, 편향된 정보, 또는 위험한 정보를 기억하고 생성할 수 있는 문제를 해결하고자 합니다.

- **Performance Highlights**: 연구는 생성적 AI 모델에서 바람직하지 않은 지식과 그 영향을 줄이거나 제거하기 위해 다양한 MU 기술을 탐구합니다. 이는 새로운 평가 방법과 문제 정식화 등을 통해 이루어지며, 여러 가지 중요한 도전 과제와 유망한 연구 방향을 제공합니다.



### Markers Identification for Relative Pose Estimation of an Uncooperative Targ (https://arxiv.org/abs/2407.20515)
Comments:
          2024 AAS/AIAA Astrodynamics Specialist Conference

- **What's New**: 이 논문은 ESA(Environmental Satellite)의 안전한 궤도 이탈을 위해 추격 우주선의 이미지 처리와 Convolutional Neural Networks(CNNs)를 사용하여 구조 마커를 감지하는 새로운 방법을 소개합니다. 이는 자율적인 우주 쓰레기 제거를 지원하는 획기적인 방법입니다.

- **Technical Details**: 고급 이미지 전처리기술(image pre-processing techniques)인 노이즈 추가(noise addition)와 블러링(blurring)을 사용하여 마커 검출의 정확도와 견고성을 향상시키는 기법을 적용했습니다.

- **Performance Highlights**: 초기 결과는 자율적인 우주 쓰레기 제거에 대해 유망한 가능성을 보여주며, 실제 우주 임무에서 견고하고 자율적인 시스템을 구현함으로써 우주 파편 제거 작업의 안전성과 효율성을 크게 향상시킬 수 있음을 시사합니다.



### Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Languag (https://arxiv.org/abs/2407.20513)
Comments:
          Accepted in NeSy 2024 Conference

- **What's New**: 이 논문은 복잡한 신경-기호 모델(neuro-symbolic models)을 위한 도메인 지식을 자연어 프롬프트(natural language prompts)를 통해 작성하는 대화형 파이프라인(pipeline)을 제시합니다. 대규모 언어 모델(large language models)을 활용하여 DomiKnowS 프레임워크에서 선언적 프로그램(declarative programs)을 생성합니다.

- **Technical Details**: DomiKnowS 프레임워크에서는 개념(concepts)과 그 관계(relationships)를 그래프로 표현하고, 논리적 제약(logical constraints)을 추가합니다. 생성된 그래프는 학습 가능한 신경 모델(neural models)과 연결됩니다. 본 파이프라인은 동적 맥락 내 시연 검색(dynamic in-context demonstration retrieval), 기호 구문 분석기(symbolic parser)로부터의 피드백을 기반으로 한 모델 개선, 시각화 및 사용자 상호작용 등의 기법을 활용하여 작업 구조와 공식적인 지식 표현을 생성합니다.

- **Performance Highlights**: 제안된 접근 방식은 ML/AI에 익숙하지 않은 도메인 전문가들도 DomiKnowS 프레임워크에서 맞춤형 신경 모델에 통합될 지식을 공식적으로 선언할 수 있도록 지원합니다.



### Boosting Efficiency in Task-Agnostic Exploration through Causal Knowledg (https://arxiv.org/abs/2407.20506)
Comments:
          This paper was accepted by IJCAI'24

- **What's New**: 이 논문에서는 예산 제한으로 데이터 수집에 한계가 있는 상황에서, 훈련 자원 품질을 향상시키기 위한 새로운 전략을 제안합니다. 'Causal Exploration(인과 탐색)'이라는 방법을 소개하며, 이는 데이터 수집과 모델 훈련 모두에 있어 인과 지식을 활용합니다. 특히, Task-Agnostic Reinforcement Learning(과제 비구체적 강화 학습) 영역에서 샘플 효율성 및 신뢰성을 높이는 것에 초점을 맞추고 있습니다.

- **Technical Details**: 탐색 단계에서는 에이전트(agent)가 세계 모델(world model) 훈련에 가장 유익한 인과적 통찰을 얻을 수 있는 행동을 적극적으로 선택합니다. 데이터 수집이 진행됨에 따라 인과 지식이 점진적으로 획득되고 개선됩니다. 이러한 인과 탐색은 보다 적은 데이터로 정확한 세계 모델 학습을 도와주며, 수렴에 대한 이론적 보장을 제공합니다.

- **Performance Highlights**: 복합 데이터(synthetic data) 및 실제 응용 프로그램을 대상으로 한 실험에서 인과 탐색의 이점이 추가적으로 검증되었습니다. 인과 탐색이 데이터 효율성을 높이고 더 적은 데이터로도 정확한 모델을 학습할 수 있음을 보여줍니다.



### A federated large language model for long-term time series forecasting (https://arxiv.org/abs/2407.20503)
- **What's New**: 이번 논문에서는 연합 학습 기반 대형 언어 모델 (LLM)을 사용하여 장기 시계열 예측 문제를 해결하는 FedTime 모델을 제안합니다. 이 모델은 데이터 프라이버시, 통신 오버헤드, 확장성 문제를 해결하는 데 중점을 두고 있습니다.

- **Technical Details**: FedTime은 사전 학습된 LLM을 연합 학습(federated learning)으로 미세 조정(fine-tuning)하고, K-평균 클러스터링(K-means clustering)을 통해 엣지 디바이스(또는 클라이언트)를 구분하여 모델 훈련의 집중도를 높였습니다. 또한, 채널 독립성(channel independence)과 패칭(patching)을 활용하여 로컬 의미 정보를 잘 보존하고, 정보 손실을 최소화하였습니다.

- **Performance Highlights**: 다양한 실제 예측 벤치마크에서 FedTime 모델은 최근의 다른 접근법들에 비해 상당한 성능 향상을 보였습니다. 뿐만 아니라, 자원 사용의 효율성을 증대시켜 통신 오버헤드를 줄이는 데도 성공했습니다.



### Toward Efficient Permutation for Hierarchical N:M Sparsity on GPUs (https://arxiv.org/abs/2407.20496)
Comments:
          11 pages, 5 figures

- **What's New**: 새로운 연구에서는 딥 뉴럴 네트워크(Deep Neural Network)를 압축하기 위한 강력한 기술인 N:M 스파시티 프루닝(N:M Sparsity Pruning)을 소개합니다. 이 기술은 NVIDIA의 Sparse Tensor Core 기술을 활용하여 해당 하드웨어의 지원을 받아 모델 정확성을 유지하면서 데이터 접근의 불규칙성으로 인한 오버헤드를 최소화합니다. 새로운 접근법인 계층적 N:M 스파시티(HiNM Sparsity)를 도입하여 다양한 압축 비율을 달성할 수 있으며, 이를 위해 '자이로-퍼뮤테이션(Gyro-Permutation)' 채널 재배열 방법을 제안합니다.

- **Technical Details**: 이 연구는 기본 N:M 스파시티를 먼저 열 방향의 벡터 스파시티로 적용한 후, 유지된 열 벡터에 대해 행 방향의 N:M 스파시티를 적용하는 다단계 접근법을 사용합니다. 자이로-퍼뮤테이션(Gyro-Permutation) 방법은 HiNM 스파시티 요구에 맞춘 채널 샘플링, 클러스터링 및 할당 단계를 포함하여 퍼뮤테이션 단계에서 독특한 특성을 활용하도록 설계되었습니다. 또한, HiNM 스파스 네트워크 실행 동안 독립적인 레이어 퍼뮤테이션을 가능하게 하는 GPU 커널도 개발되었습니다.

- **Performance Highlights**: 다양한 딥 뉴럴 네트워크 모델에 대한 광범위한 실험 평가 결과, 자이로-퍼뮤테이션(Gyro-Permutation)은 HiNM 스파스 네트워크의 정확성을 크게 향상시켜 비구조적(Unstructured) 스파스 네트워크와 유사한 성능 수준에 도달할 수 있음을 보여줍니다.



### A Method for Fast Autonomy Transfer in Reinforcement Learning (https://arxiv.org/abs/2407.20466)
- **What's New**: 이 논문은 여러 환경에서 사전 학습된 평론가 가치 함수(critic value functions)를 활용하여 신속한 자율성 전이를 촉진하는 새로운 강화 학습(RL) 전략을 소개합니다. 전통적인 방법과 달리, 이 접근법은 기존 지식을 통합하여 RL 에이전트가 새로운 설정에 신속하게 적응할 수 있도록 합니다.

- **Technical Details**: 우리는 Multi-Critic Actor-Critic (MCAC) 알고리즘을 개발하고, 그 수렴(convergence)을 확립했으며, 실험을 통해 그 효능을 입증했습니다. MCAC는 기존의 액터-크리틱(actor-critic) 알고리즘보다 최대 22.76배 빠른 자율성 전이와 더 높은 보상 축적을 달성할 수 있습니다.

- **Performance Highlights**: MCAC 알고리즘은 기존의 액터-크리틱 알고리즘 대비 22.76배 더 빠른 자율성 전이를 가능하게 했으며, 보상(reward) 축적 측면에서도 더 우수한 성과를 보여주었습니다. 이러한 발전은 축적된 지식을 활용한 효율적인 적응이 RL 응용 분야에서 잠재력이 있음을 강조합니다.



### Futga: Towards Fine-grained Music Understanding through Temporally-enhanced Generative Augmentation (https://arxiv.org/abs/2407.20445)
Comments:
          6 pages

- **What's New**: FUTGA 모델은 기존 음악 캡션 생성 방식의 한계를 극복하여 세밀한 음악 특성과 시간에 따른 음악 변화까지 포착할 수 있습니다. 기존 음악 캡션 데이터셋과 대형 언어 모델(LLMs)을 활용하여 전체 곡에 대한 구조적 설명과 시간 경계를 포함한 세밀한 음악 캡션을 생성할 수 있습니다.

- **Technical Details**: FUTGA는 생성적 증강(generative augmentation) 기법을 사용하여 시간 구성을 학습함으로써 세밀한 음악 이해 능력을 갖추었습니다. 또한, FUTGA는 제안된 합성 데이터셋(synthetic dataset)을 통해 주요 전환 지점에서 음악의 시간적 변화를 식별하고 각 음악 세그먼트에 대한 상세한 설명을 생성할 수 있습니다. MusicCaps와 Song Describer 데이터셋의 증강을 위해 생성된 풀 길이 음악 캡션 데이터셋을 도입하였습니다.

- **Performance Highlights**: 여러 다운스트림 작업(예: 음악 생성 및 검색)에서 자동으로 생성된 캡션의 품질을 평가하였으며, 제안된 음악 캡션 생성 방식이 다양한 다운스트림 작업에서 더 나은 성과를 보였습니다.



### Generating Gender Alternatives in Machine Translation (https://arxiv.org/abs/2407.20438)
Comments:
          GeBNLP 2024

- **What's New**: 이 논문은 기계 번역(MT) 시스템에서 성별 모호성 문제를 해결하기 위해 모든 문법적으로 올바른 성별 번역 대안을 생성하는 방법을 연구합니다. 이는 성별 모호성을 원활하게 해결할 수 있는 MT 사용자 인터페이스를 염두에 두고 수행되었습니다. 논문은 5개의 언어 쌍에 대한 학습 및 테스트 데이터셋을 오픈 소스로 공개하고, 이 작업에 대한 벤치마크를 설정했습니다.

- **Technical Details**: 주요 기술적 기여는 새로운 준지도(semi-supervised) 솔루션입니다. 이는 표준 MT 모델과 원활하게 통합되며, 추가 구성 요소나 추론 오버헤드를 증가시키지 않으면서 높은 성능을 유지합니다.

- **Performance Highlights**: 해당 솔루션은 성능을 저해하지 않고 MT 시스템이 성별 모호성을 효과적으로 처리할 수 있게 해줍니다. 또한, 학습 데이터에 의해 편향된 성별 번역 문제를 해결함으로써 사회적 고정관념을 반영하고 영구화하는 것을 방지합니다.



### Dense Self-Supervised Learning for Medical Image Segmentation (https://arxiv.org/abs/2407.20395)
Comments:
          Accepted at MIDL 2024

- **What's New**: 이번 연구는 Pix2Rep이라는 self-supervised learning (SSL)을 활용한 새로운 few-shot segmentation 접근법을 제안합니다. 이는 주석(annotation)의 부담을 줄이기 위해, 주석이 없는 이미지에서도 강력한 픽셀 수준의 표현을 학습할 수 있도록 합니다.

- **Technical Details**: Pix2Rep은 대조적 SSL(contrastive SSL)에서 전체 이미지에 대한 새로운 픽셀 수준의 손실 함수(loss)와 사전 학습(pre-training) 패러다임을 도입했습니다. 이는 일반적인 encoder-decoder 딥러닝 백본(e.g., U-Net)에 적용됩니다. 대부분의 SSL 기법이 강도와 공간 이미지 증강(augmentation) 하에서 학습된 이미지 수준 표현의 불변성을 강제하는 반면, Pix2Rep은 픽셀 수준 표현의 등가성(equivariance)을 강제합니다.

- **Performance Highlights**: 이번 연구는 심장 MRI 세분화 임무를 통해 프레임워크를 입증했습니다. 결과적으로, 기존의 반지도 학습(semi-) 및 자가 지도 학습(self-supervised) 접근법보다 성능이 향상되었음을 보여줍니다. 완전 감독된 U-Net 기준에 비해 동일한 성능에서 주석 부담이 5배 감소를 나타냈습니다. 이는 one-shot segmentation에서 linear-probing 시 30%, fine-tuning 시 31%의 DICE 개선을 포함합니다. 마지막으로, Pix2Rep 개념을 Barlow Twins 비대조 SSL(non-contrastive SSL)과 통합하여 더욱 향상된 세분화 성능을 달성했습니다.



### Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieva (https://arxiv.org/abs/2407.20371)
Comments:
          To be published in Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society; code available at this https URL

- **What's New**: 최근 인공지능(AI) 채용 도구는 이력서 검토 방식을 혁신적으로 변화시켰으며, 대형 언어 모델(Large Language Models, LLMs)도 이에 속할 잠재력을 지닙니다. 그러나 LLMs에 내재된 편향(bias) 때문에 보호받는 속성(Protected Attributes)에 따라 그룹을 불리하게 만들 가능성이 있습니다. 이 연구는 LLMs를 이력서 검토에 사용하는 가능성을 문서 검색 프레임워크(Document Retrieval Framework)를 통해 조사하였습니다.

- **Technical Details**: 9개의 직업을 대상으로, 500개 이상의 공개된 이력서와 500개의 직무 설명을 사용하여 조사하였습니다. Massive Text Embedding (MTE) 모델을 사용하여 이력서 검토 시 편향이 존재하는지 감사 연구(Audit Study)를 수행했습니다.

- **Performance Highlights**: 연구 결과, MTE 모델은 85.1%의 경우에서 백인과 관련된 이름들을, 11.1%의 경우에서 여성과 관련된 이름들을 유리하게 선별하였으며, 소수의 경우에서만 통계적으로 유의미한 차이가 없었습니다. 특히 흑인 남성은 최대 100%의 경우에서 불이익을 받는 것으로 나타났습니다. 또한 문서 길이와 이름의 코퍼스 빈도도 이력서 선별에 영향을 미쳤습니다. 이 결과는 AI 채용 도구의 공정성, 기술 정책에 중요한 함의를 가지고 있습니다.



### LiteEFG: An Efficient Python Library for Solving Extensive-form Games (https://arxiv.org/abs/2407.20351)
- **What's New**: LiteEFG는 다중 플레이어 광범위 형태 게임 (extensive-form games, EFGs)을 해결할 수 있는 효율적인 라이브러리입니다. 이 라이브러리는 사용자가 게임 트리 구조 업데이트에 대한 연산 그래프 (computation graphs)를 Python에서 쉽게 표현할 수 있도록 합니다.

- **Technical Details**: LiteEFG는 Python 바인딩을 사용하여 업데이트 규칙이 정의된 연산 그래프를 C++ 백엔드에서 실행합니다. 이로 인해 Python에서 알고리즘을 실행하는 것에 비해 상당한 속도 향상이 있습니다. 특히 LiteEFG에서는 사용자가 게임의 결정 노드에서의 업데이트 규칙에 대한 연산 그래프만 지정하면, 이 규칙이 각 결정 노드에 자동으로 분배되고 불완전 정보 게임 (imperfect-information game)의 구조가 자동으로 처리됩니다.

- **Performance Highlights**: Python에서 알고리즘을 직접 실행하는 것보다 C++ 백엔드에서 연산 그래프를 수행함으로써 상당한 속도 향상을 이뤘습니다.



### BRIDGE: Bridging Gaps in Image Captioning Evaluation with Stronger Visual Cues (https://arxiv.org/abs/2407.20341)
Comments:
          ECCV 2024

- **What's New**: 차세대 이미지 캡셔닝 평가 지표로 BRIDGE를 제안합니다. 이 지표는 인간의 판단과 더 정확하게 일치시키기 위해 기존 지표들(CIDEr, CLIP-Score)의 한계를 극복하고자 했습니다. 특히, 브리지는 참조 캡션(referece captions)을 필요로 하지 않는 새로운 학습 가능한 평가 지표로, 시각적 특징을 밀집 벡터화하고 이를 다중 모달(lmulti-modal) 가상 캡션으로 통합합니다.

- **Technical Details**: BRIDGE는 시각적 특징을 밀집 벡터(dense vectors)로 매핑(mapping)하는 혁신적인 모듈을 사용합니다. 이러한 벡터들은 평가 과정 중에 구축된 다중 모달 가상 캡션에 통합됩니다. 이는 참조 캡션 없이 입력 이미지의 정보를 적절히 포함시켜주며, 인간 심사와 기계 생성 캡션 사이의 격차를 줄이는 기술입니다.

- **Performance Highlights**: 여러 데이터셋을 대상으로 한 실험에서 BRIDGE는 기존의 참조 캡션이 필요 없는 평가 점수(reference-free evaluation scores)와 비교해 최첨단 성능을 달성했습니다. 또한, 해당 연구의 소스 코드와 학습된 모델은 공개되어 있어, 이 기술의 활용도가 높아질 전망입니다.



### Contrasting Deepfakes Diffusion via Contrastive Learning and Global-Local Similarities (https://arxiv.org/abs/2407.20337)
Comments:
          ECCV 2024

- **What's New**: 새로운 연구에서는 CoDE (Contrastive Deepfake Embeddings)라는 혁신적인 임베딩 공간을 제안합니다. 이 임베딩 공간은 딥페이크(Deepfake) 탐지를 위해 특별히 설계되었으며, 기존 CLIP 엔코딩 공간의 한계를 극복합니다.

- **Technical Details**: CoDE는 대비 학습(contrastive learning)을 통해 글로벌-로컬 유사성을 강제하며 훈련됩니다. 연구팀은 확산 모델(diffusion models)에 의해 생성된 이미지에 중점을 두고 4개의 다른 생성기를 사용하여 생성된 920만 개의 이미지가 포함된 종합 데이터셋을 생성했습니다.

- **Performance Highlights**: CoDE는 새로 수집된 데이터셋에서 최첨단(state-of-the-art) 정확도를 달성하였으며, 보지 못한 이미지 생성기에도 뛰어난 일반화 능력을 보여주었습니다. 연구의 소스 코드, 훈련된 모델 및 데이터셋은 공개되어 있습니다.



### Legal Aspects of Decentralized and Platform-Driven Economies (https://arxiv.org/abs/2407.20301)
- **What's New**: 공유 경제(Sharing Economy)가 전 세계 거의 모든 부문과 활동으로 확대되고 있습니다. 약 10년 전만 해도 시장에서 운영되는 플랫폼 기반 회사는 소수였으며, Zipcar, BlaBlaCar 및 Couchsurfing 등이 그 중 일부였습니다. 그러나 Airbnb와 Uber는 교통 및 숙박 산업을 혁신하며 거의 모든 주요 도시에 존재감을 드러냈습니다.

- **Technical Details**: 접근(access) 우선이 소유(ownership)보다 우선시는 패러다임 전환은, 개인이 제품이나 서비스를 구매하지 않고도 사용할 수 있도록 하는 전통적인 비즈니스 모델에서 이동하고 있습니다. 디지털 플랫폼, 데이터 및 알고리즘 기반 회사, 탈중앙화된 블록체인(blockchain) 기술은 막대한 잠재력을 가지고 있습니다. 그러나 이러한 기술들은 게임의 규칙을 변경하고 있습니다. 특히 AI 시스템은 법적 시스템을 도전하며, 운영자, 사용자 및 제조업체의 책임과 관련된 현재의 법적 프레임워크를 재구성할 것입니다.

- **Performance Highlights**: 이 장에서는 이러한 파괴적인 기술의 법적 문제를 설명하고 기술하고 있습니다. 저자는 더 진취적이고 유연한 규제 구조를 요구하고 있습니다.



### Dataset Distillation for Offline Reinforcement Learning (https://arxiv.org/abs/2407.20299)
Comments:
          ICML 2024 DMLR Workshop

- **What's New**: 오프라인 강화 학습(Offline reinforcement learning)은 종종 정책(policy)을 학습하기 위한 고품질 데이터셋을 필요로 합니다. 그러나 많은 상황에서 그러한 데이터셋을 얻는 것이 불가능하거나 오프라인 데이터를 활용하여 실제 환경에서 우수한 성능을 발휘하는 정책을 학습하는 것이 쉽지 않습니다. 이에 대한 해결책으로 데이터 증류(data distillation)를 사용하여 더 나은 데이터셋을 학습하고 증류하여 더 나은 정책 모델을 학습할 수 있도록 하는 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 데이터 증류를 통해 기존 데이터셋을 보다 정제된(dataset synthesis) 형태로 변환하여, 이렇게 생성된 데이터셋을 이용해 학습된 모델이 원래의 전체 데이터셋 혹은 상위 퍼센타일 행동 복제(Percentile behavioral cloning) 방법을 사용해 학습된 모델과 유사한 성능을 발휘하도록 합니다.

- **Performance Highlights**: 우리의 방법은 원본 데이터셋이나 상위 퍼센타일 행동 복제 방법을 사용해 학습된 모델과 유사한 성능을 보이는 모델을 학습할 수 있는 데이터셋을 합성할 수 있음을 보여줍니다.



### A Bayesian Flow Network Framework for Chemistry Tasks (https://arxiv.org/abs/2407.20294)
- **What's New**: 이번 연구에서는 화학 작업을 처리하는 ChemBFN이라는 새로운 언어 모델을 도입했습니다. 이 모델은 불연속 데이터(discrete data)에서 베이지안 플로우 네트워크(Bayesian flow networks)를 기반으로 작업합니다. 새로운 정확도 스케줄(accuracy schedule)을 제안하여 샘플링 품질을 개선하고 재구성 손실(reconstruction loss)을 크게 줄였습니다.

- **Technical Details**: ChemBFN 모델은 시료 채취 단계의 수가 적을 때도 분자(molecules)의 다양성을 만족하는 생성이 적절히 이루어지도록 설계되었습니다. 조건부 생성(conditional generation)을 위해 분류기 없는 가이던스(classifier-free guidance) 방법을 채택했습니다. 또한, 생성 훈련(generative training) 후 모델은 회귀(regression) 및 분류(classification) 작업에서 최첨단 성능(state-of-the-art performance)으로 미세 조정(fine-tune)할 수 있습니다.

- **Performance Highlights**: ChemBFN 모델은 하나의 모듈 스타일(single module style)에서 모든 작업을 수행할 수 있는 길을 열었으며, 제안된 방법이 다양한 분자 생성을 용이하게 하고 우수한 성능을 나타낸다는 증거를 제공합니다.



### Assessing AI Rationality: The Random Guesser Test for Sequential Decision-Making Systems (https://arxiv.org/abs/2407.20276)
Comments:
          Accepted into AIBS 2024: The First Workshop on AI Behavioral Science, 5 pages, 4 figures

- **What's New**: AI 시스템의 편향된 결정(Biased Decision)에 대한 리스크와 취약성을 정량적으로 평가하는 일반적인 접근 방식을 제안합니다. 제안된 접근 방식의 핵심 원칙은 모든 AI 알고리즘이 랜덤 추측자(Random Guesser)보다 뛰어나야 한다는 것입니다. 이는 자명해 보일 수 있지만, 룰렛 게임을 포함한 단순한 순차적 의사결정 시나리오에서 복잡한 AI 기반 접근 방식이 랜덤 추측자보다 현저히 열등한 성능을 보인다는 실증 결과를 보여줍니다.

- **Technical Details**: 제안된 접근 방식은 특히 현대의 추천 시스템(Recommender systems)이 너무 낮은 리스크(Risk) 옵션을 선호하는 경향을 강조합니다. '랜덤 추측자 테스트(Random Guesser Test)'는 AI 행동의 합리성을 평가하는 유용한 도구로 사용할 수 있으며, 탐색(Exploration) 증대를 통해 시스템을 개선할 수 있는 잠재적 방법을 제안합니다.

- **Performance Highlights**: 룰렛 게임을 통한 실증 결과에서 복잡한 AI 기반 접근 방식이 랜덤 추측자보다 성능이 떨어질 수 있음을 발견했습니다. 이는 추천 시스템을 포함한 다양한 AI 시스템에 대해 탐색을 강화하는 것이 중요하다는 점을 시사합니다.



### Exploring the Plausibility of Hate and Counter Speech Detectors with Explainable AI (https://arxiv.org/abs/2407.20274)
Comments:
          conference, CBMI2024, 6 pages,

- **What's New**: 이 논문에서는 트랜스포머 모델의 설명 가능성(explainability)과 그 모델이 혐오 발언(hate speech) 및 반발 발언(counter speech) 감지에 얼마나 유용한지 조사합니다.

- **Technical Details**: 논문에서는 네 가지 다른 설명 가능성 접근법, 즉 그래디언트 기반(gradient-based), 섭동 기반(perturbation-based), 어텐션 기반(attention-based), 프로토타입 기반(prototype-based) 접근법의 대표자를 비교합니다. 양적 분석(ablation study)과 질적 분석(user study)을 통해 이를 분석합니다.

- **Performance Highlights**: 결과에 따르면 섭동 기반 설명 가능성이 가장 우수했으며, 그 다음은 그래디언트 기반 및 어텐션 기반 설명 가능성이 우수했습니다. 프로토타입 기반 실험은 유용한 결과를 제공하지 못했습니다. 전체적으로 설명 가능성은 사용자가 모델 예측을 더 잘 이해하는 데 크게 도움이 되는 것으로 나타났습니다.



### An Efficient Inference Framework for Early-exit Large Language Models (https://arxiv.org/abs/2407.20272)
- **What's New**: 본 연구는 LLMs(Large Language Models)을 사용하는 과정에서 조기 종료(early-exit) 모델을 적용하는 새로운 효율적 추론 프레임워크를 제안합니다. 이는 충분히 확신할 때 나머지 레이어를 건너뛰고 바로 출력 토큰을 생성함으로써 추론 효율성을 높입니다. 이 연구는 LLM 추론 프레임워크에 조기 종료 모델을 통합하여 기존 연구와는 차별화된 점을 보여줍니다.

- **Technical Details**: 본 연구에서는 두 가지 주요 과제를 해결합니다: (1) iteration-level granularity(반복 수준의 세밀도)에서의 batch inference(배치 추론)와 (2) KV cache(키-값 캐시) 관리. 배치 추론의 경우, 모든 시퀀스가 조기 종료 신뢰도 임계치를 넘어설 때까지 배치를 처리하는 방법을 제안합니다. KV 캐시 관리에서는 반복이 종료되기 전에 나머지 레이어의 KV 캐시를 채우는 방식을 제안합니다.

- **Performance Highlights**: 본 연구에서 제안한 솔루션은 전체 레이어에서 작동하는 기존의 vLLM과 비교했을 때 최대 1.25배의 속도 향상을 보여줍니다.



### Learn while Unlearn: An Iterative Unlearning Framework for Generative Language Models (https://arxiv.org/abs/2407.20271)
- **What's New**: 최근 기계 학습, 특히 자연어 처리(NLP) 분야에서 거대한 데이터셋을 학습한 정교한 모델들이 개발되었지만, 이로 인해 민감한 정보 누출에 대한 우려가 제기되었습니다. 이에 따라 EU의 일반 데이터 보호 규정(GDPR)과 같은 규제 조치가 기계적 '잊기' (Machine Unlearning) 기술에 대한 탐구를 촉진하고 있습니다. 이러한 기술은 모델이 특정 데이터 항목을 선택적으로 잊을 수 있게 하는 것을 목표로 합니다. 본 논문에서는 이러한 문제를 해결하기 위해 Iterative Contrastive Unlearning (ICU) 프레임워크를 소개합니다.

- **Technical Details**: ICU 프레임워크는 세 가지 핵심 요소를 포함합니다. 첫째, 특정 대상 시퀀스를 잊기 위한 Knowledge Unlearning Induction 모듈을 제안합니다. 둘째, 생성 능력의 저하를 방지하기 위해 Contrastive Learning Enhancement 모듈을 통합합니다. 셋째, 각 대상 샘플에 더 적응할 수 있도록 Iterative Unlearning Refinement 모듈을 통합합니다. 이러한 구성 요소들을 통해 원래 학습 데이터에 대한 접근 없이도 효과적인 '잊기' 과정을 수행할 수 있습니다.

- **Performance Highlights**: 실험 결과, ICU 프레임워크는 민감한 정보를 효율적으로 잊으면서도 성능을 유지하는 데 유효함을 입증했습니다. 이는 개인정보 보호를 중시하는 기계 학습 애플리케이션에 유망한 방법을 제공합니다.



### A Large Encoder-Decoder Family of Foundation Models For Chemical Languag (https://arxiv.org/abs/2407.20267)
Comments:
          14 pages, 3 figures, 14 tables

- **What's New**: 이 논문은 화학 언어 모델(chemical language models)에서 대규모 사전 학습 방법론이 중요한 발전을 이루었음을 소개합니다. 저자들은 PubChem에서 가져온 9100만 개의 SMILES 샘플(약 40억 개의 분자 토큰)이 포함된 데이터 셋을 사용하여 대규모 인코더-디코더 화학 기초 모델(encoder-decoder chemical foundation models)을 사전 학습했습니다. 이 모델은 양자 속성 예측(quantum property prediction)과 같은 복잡한 작업을 지원하며 두 가지 주요 변형(289M 및 $8	imes289M$)을 제공합니다.

- **Technical Details**: 이 연구에서는 크게 표기 말뭉치(unlabeled corpora)에서 자가 지도 학습(self-supervised learning)을 통해 입력 토큰의 문맥화된 표현(contextualized representations)을 학습하는 방법을 채택하였습니다. 사전 학습 후 특정 작업에 대해 미세 조정(fine-tuning)을 수행하여 주석 데이터셋(annotated datasets)에 대한 의존성을 줄이고 화학 언어 표현의 이해를 확장했습니다. 제안된 모델은 다수의 벤치마크 데이터셋에서의 실험을 통해 최첨단 결과를 제공하는 능력을 검증했습니다. 또한, 추론 작업의 전제 조건으로서 임베딩 공간(embedding space)의 조합성(compositionality)에 대한 초기 평가를 제공했습니다.

- **Performance Highlights**: 제안된 모델은 다양한 작업에 대해 최첨단 결과를 제공하며, 소수 샷 학습(few-shot learning) 능력을 갖추고 있습니다. 특히, 생성된 잠재 공간(latent space)이 분리 가능한(separable) 것으로 나타났습니다.



### Making LLMs Work for Enterprise Data Tasks (https://arxiv.org/abs/2407.20256)
Comments:
          Poster at North East Database Day 2024

- **What's New**: 이 논문은 대형 언어 모델(LLMs)이 사설 데이터 생태계의 기업 데이터베이스 테이블에 대해 잘 알지 못한다는 문제를 다루고 있습니다. 이는 웹 텍스트와 구조와 내용 면에서 크게 다릅니다. LLMs의 성능이 그들이 훈련된 데이터에 크게 연관되어 있기 때문에, 기업 데이터베이스 관리 및 분석 작업에 얼마나 유용한가에 대한 연구가 필요합니다. 이에 대한 실험 결과를 제시하여 기업 데이터셋에서 텍스트-투-SQL(text-to-SQL)과 의미론적 컬럼 타입 감지(semantic column-type detection) 작업에 대한 LLMs의 성능을 개선하는 방법을 논의합니다.

- **Technical Details**: 이 연구는 LLMs의 성능을 벤치마크 데이터셋과 비교하여 실험하였으며, 기업 데이터셋에서의 성능이 상당히 낮다는 것을 발견했습니다. 이를 바탕으로 지연(latency), 비용(cost) 및 품질(quality)이라는 세 가지 근본적인 도전 과제를 식별하고, 이를 효과적으로 해결할 수 있는 잠재적인 솔루션을 제안합니다.

- **Performance Highlights**: 실험 결과, LLMs가 일반적으로 사용되는 벤치마크 데이터셋에서보다 기업 데이터셋에서의 성능이 상당히 낮다는 사실을 확인했습니다. 이를 통해 기업 데이터 워크플로우에서 LLMs를 효과적으로 사용하기 위한 해결책을 제시합니다.



### Riemannian Geometry-Based EEG Approaches: A Literature Review (https://arxiv.org/abs/2407.20250)
- **What's New**: 이 논문에서는 최근 뇌-컴퓨터 인터페이스 (BCI)에서 EEG 신호 해독을 향상시키기 위해 리만 기하학(Riemannian geometry)과 딥러닝을 통합한 최신 연구 성과를 종합적으로 검토합니다. 특히 2017년 이후의 최근 업적을 업데이트하여 딥러닝 접근법이 EEG 신호의 비유클리드 데이터 구조를 더 잘 처리하는 방법을 비교 분석합니다. 이 논문은 소음 민감성, 비정상성(Non-stationarity), 긴 캘리브레이션 시간을 다루는 전통적인 문제를 해결하는 방법을 소개합니다.

- **Technical Details**: 딥러닝과 리만 기하학(DL과 Riemannian geometry)을 통합하여 비유클리드 데이터(non-Euclidean data)를 처리하는 방법론에 대한 논의가 포함되어 있으며, 이는 특히 EEG 신호에서 중요합니다. 소개된 접근법은 새로운 분류 프레임워크와 신호 처리 기술로 인해 기존 제한 사항을 크게 줄일 수 있습니다. 또한, 매니폴드(Manifold) 학습 및 리만 기반 분류의 현재 단점을 식별하고, 실제 구현과 이론적 확장을 포함한 미래 연구 방향을 제안합니다.

- **Performance Highlights**: 딥러닝과 리만 기하학의 결합은 글로벌 BCI 대회에서 상당한 성과를 보여왔습니다. 특히, 소음에 대한 감도, 비정상성 문제 및 긴 캘리브레이션 시간과 같은 문제를 효과적으로 처리할 수 있는 새로운 기술과 분류 프레임워크를 도입했습니다. 이는 이론적 연구와 실질적인 응용 사이의 간극을 메우는 데 도움을 줍니다.



### LAPIS: Language Model-Augmented Police Investigation System (https://arxiv.org/abs/2407.20248)
- **What's New**: 범죄 상황은 시간과의 싸움입니다. 경찰관들에게 신속하면서도 정확한 법률 자문을 제공할 수 있는 AI 보조 범죄 수사 시스템이 필요합니다. LAPIS (Language Model Augmented Police Investigation System)는 경찰관이 합리적이고 법적인 수사 조치를 수행할 수 있도록 지원하는 자동화 시스템입니다. 우리는 범죄 수사 법률 추론 작업에 특화된 파인튜닝 데이터셋(finetuning dataset)과 검색 지식베이스(retrieval knowledgebase)를 구축했습니다.

- **Technical Details**: 우리는 도메인 전문가 그룹의 수작업을 통해 데이터셋의 품질을 향상시켰으며, 새로운 데이터셋에 맞춰 사전에 훈련된 한국어 모델의 가중치(weights)를 파인튜닝(finetuning)했습니다. 그 후, 이 모델을 범죄 수사 지식베이스 검색 접근법과 통합했습니다. LAPIS는 실험 결과에서 경찰관에게 신뢰할 수 있는 법률 자문을 제공하는 데 있어 독점적인 GPT-4 모델보다 우수한 성능을 보여주었습니다.

- **Performance Highlights**: LAPIS가 생성한 논거(rationales)에 대한 정성적 분석은 모델이 전제(premises)를 활용하고 법적으로 올바른 결론을 도출하는 추론 능력을 갖추고 있음을 보여줍니다.



### How Homogenizing the Channel-wise Magnitude Can Enhance EEG Classification Model? (https://arxiv.org/abs/2407.20247)
- **What's New**: 본 연구는 EEG(뇌전도) 데이터 전처리 방법을 제안합니다. 전통적으로 EEG 데이터는 여러 전극 신호를 사용하여 데이터 중복과 주요 신호의 지배 현상이 발생합니다. 이러한 문제를 해결하기 위해, 연구진은 간단하지만 효과적인 새로운 접근 방식을 제안합니다.

- **Technical Details**: 제안된 방법은 먼저 Inverted Channel-wise Magnitude Homogenization (ICWMH)을 사용하여 EEG 데이터를 인코딩된 이미지로 변환합니다. 이 과정을 통해 채널 간의 바이어스를 줄일 수 있습니다. 다음으로, 엣지 검출 기술을 EEG 인코딩된 이미지에 적용하고, 스킵 연결을 사용하여 데이터에서 가장 중요한 변환을 강조하고 구조적이며 불변한 정보를 보존합니다. 이러한 과정은 큰 Deep Learning (DL) 네트워크를 사용하지 않고도 EEG 학습 과정을 효율적으로 향상시킵니다.

- **Performance Highlights**: 실험평가결과, 제안된 방법이 기존 기준선에 비해 2%에서 5%까지 성능이 향상됨을 확인했습니다.



### Steamroller Problems: An Evaluation of LLM Reasoning Capability with Automated Theorem Prover Strategies (https://arxiv.org/abs/2407.20244)
- **What's New**: 이 연구는 Large Language Models (LLMs)가 Automated Theorem Provers (ATPs)의 논리 전략을 따를 수 있는 능력을 최초로 검토합니다. GPT-4, GPT-3.5 Turbo 및 최근의 Google Gemini 모델을 증기 롤러 도메인(steamroller domain)의 문제에 대해 평가합니다.

- **Technical Details**: 정확성 측정 외에 Natural Language Processing 라이브러리인 spaCy를 활용해 LLM의 추론 능력을 조사하는 새로운 방법을 탐구했습니다. 이 과정에서, 테스트된 모델 중 어느 것도 올바른 추론과 올바른 답변 사이의 상관관계가 낮은 것으로 나타났습니다. 또한 ATP 추론 전략을 사용할 때 모델의 성능이 one-shot chain of thought와 유사하였으며, 결과의 정확성에서 불확실성에 유의하는 것이 중요하다는 것을 관찰했습니다.

- **Performance Highlights**: 이전의 추정과 일치하게, LLM이 bottom-up reasoning process를 선호하며 가장 잘 따를 수 있다는 것을 확인했습니다. 그럼에도 불구하고 추론 전략은 신뢰할 수 있는 추론 엔진에 의해 외부 처리될 수 있도록 작고 관련성 있는 공식을 도출하는 데 여전히 유용할 수 있습니다.



### BadRobot: Jailbreaking LLM-based Embodied AI in the Physical World (https://arxiv.org/abs/2407.20242)
Comments:
          Preliminary version (15 pages, 4 figures). Work in progress, revisions ongoing. Appreciate understanding and welcome any feedback

- **What's New**: 본 연구는 대형 언어 모델(LLM, Large Language Models)을 기반으로 한 체현된 AI(Embodied AI)의 새로운 안전 문제를 첫 번째로 제기합니다. 연구진은 이 AI 시스템이 가정과 산업에서 널리 사용될 것으로 예상되는 미래에 대한 우려를 표현하며, 아시모프의 로봇 3원칙에 위배되는 해로운 행동을 유발할 가능성을 탐구했습니다.

- **Technical Details**: 본 연구는 체현된 AI의 탈출(jailbreaking)에 대한 개념을 정립하고, 세 가지 주요 보안 취약점을 노출했습니다: 첫째, 손상된 LLM을 통한 로봇 탈출; 둘째, 행동과 언어 공간 간의 안전 불일치; 셋째, 미인지 위험 행동을 유도하는 기만적 프롬프트(deceptive prompts)를 분석했습니다. 이 위험성을 줄이기 위한 잠재적 완화 조치도 분석했습니다.

- **Performance Highlights**: 체현된 AI 시스템의 안전 문제와 이를 해결하기 위한 연구는 빠르게 발전하고 있습니다. 본 연구는 체현된 AI가 아시모프의 로봇 3원칙을 위반할 수 있는 위험성을 처음으로 실증함으로써, 단순한 기능 구현을 넘어서 실제 응용 환경에서의 안전 보장을 위한 기초를 마련했습니다.



### NudgeRank: Digital Algorithmic Nudging for Personalized Health (https://arxiv.org/abs/2407.20241)
Comments:
          To be published in Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '24)

- **What's New**: 이 논문에서는 인구 전체의 건강 행동을 촉진하기 위해 설계된 혁신적인 디지털 알고리즘 'NudgeRank' 시스템을 소개합니다. 이 시스템은 Graph Neural Networks와 확장 가능한 Knowledge Graph를 결합하여 매일 110만 명 이상의 케어 수혜자에게 개인 맞춤형 및 상황 인식된 nudges를 제공합니다. 이는 AI 주도의 건강 행동 변화 이니셔티브 중 가장 큰 규모 중 하나입니다.

- **Technical Details**: 'NudgeRank'는 Graph Neural Networks (그래프 신경망)과 Knowledge Graph (지식 그래프)를 결합한 Recommender System (추천 시스템)입니다. 이 시스템은 다양한 건강 상태와 착용 가능한 디바이스들을 수용할 수 있습니다. NudgeRank는 자동화 및 관찰 가능성 표준을 유지하면서 상용 컴퓨팅 자원에서 효율적으로 운영됩니다.

- **Performance Highlights**: 철저한 평가 결과, 건강 결과에서 통계적으로 유의미한 개선이 나타났습니다. 예를 들어, 일일 걸음 수는 6.17% 증가하고 운동 시간은 7.61% 증가했습니다. 또한 사용자 참여도와 프로그램 등록률이 급증했으며, 오픈율(open rate)이 기존 시스템의 4%에 비해 13.1%로 크게 증가했습니다.



### Social and Ethical Risks Posed by General-Purpose LLMs for Settling Newcomers in Canada (https://arxiv.org/abs/2407.20240)
Comments:
          26 pages, 8 figures

- **What's New**: 캐나다의 비영리 정착 부문(settlement sector)은 이민자들이 성공적으로 통합될 수 있도록 지원합니다. 이 부문은 증가하는 이민 목표 속에서 운영 압박이 커지고 있으며, 이는 신뢰할 수 있는 AI 솔루션을 통해 효율성과 혁신을 향상시킬 필요성을 강조합니다. 본 연구는 ChatGPT와 같은 범용 생성 AI의 사용이 일반적일 수 있으나, 이러한 도구가 정착 도메인에 맞지 않으며 이민자와 난민에게 해로운 영향을 미칠 수 있음을 탐구합니다.

- **Technical Details**: 이 연구는 주요 두 가지 목표를 가집니다. 첫째, 생성형 AI의 무분별한 사용에 대한 경고를 제공합니다. 둘째, 영향을 받는 커뮤니티의 선호도에 맞춘 맞춤형 대형 언어 모델(LLM)을 개발하고, AI 문해력(AI literacy) 프로그램을 촉진하는 추가 연구와 개발을 장려합니다. 이러한 기술은 정착 부문의 기존 워크플로에 매끄럽게 통합되어야 하며, 인간의 감독, 신뢰성 및 책임성을 보장해야 합니다.

- **Performance Highlights**: 본 연구는 정착 부문에서 사용자 맞춤형 AI 솔루션의 필요성을 강조하며, 기존의 워크플로에 통합될 수 있는 기술의 중요성을 부각합니다. 이를 통해 인식 제고와 추가 연구의 필요성이 더욱 부각되었습니다.



### Artificial Intelligence from Idea to Implementation. How Can AI Reshape the Education Landscape? (https://arxiv.org/abs/2407.20236)
Comments:
          33 pages, book chapter

- **What's New**: 이 논문은 인공지능(AI) 기술의 진화와 오늘날 사회에 미치는 영향을 소개합니다. 역사적 맥락을 통해 AI의 일반적인 정의와 기술 타임라인을 제공하며, AI 윈터(AI winters)라고 불리는 정체기와 끊임없는 열정과 투자에 따른 재도약을 강조합니다. 특히 교육 분야에서 AI의 변혁적 효과에 중점을 두고 있습니다.

- **Technical Details**: 이 논문은 AI 기술이 이론적 개념에서 실제 도구로 어떻게 전환되었는지를 설명하며, 교육적 접근 방식과 학생 참여를 재정립하는 데 미치는 영향을 사례를 통해 보여줍니다.

- **Performance Highlights**: AI가 교육에 미치는 영향에 대해 논의하며, 기술적 진보와 사회적 함의를 모두 고려하는 균형 잡힌 접근의 필요성을 강조하면서 논문을 마무리합니다.



### Supertrust: Evolution-based superalignment strategy for safe coexistenc (https://arxiv.org/abs/2407.20208)
- **What's New**: 새로운 논문에서는 초지능(superintelligence)을 제어하는 문제의 기존 접근 방식이 근본적인 불신을 내재화하게 되며, 이는 위험한 불일치를 초래할 수 있다는 점을 지적합니다. 논문은 이 문제를 '어떻게 하면 초지능과 인간 사이에 보호적인 상호 신뢰를 구축할 수 있을까'로 재정의하고, 본능적인 신뢰를 기반으로 한 새로운 전략을 제시합니다.

- **Technical Details**: 기존의 전략은 훈련 후(post-training) 제약과 도덕적 가치를 도입하는 반면, 근본적인 성향(pre-training)은 영구적인 제어 의도에 기반을 둔다는 점에서 자연적인 불신을 생성하게 됩니다. 논문은 이를 해결하기 위해, 본성을 본능적으로 신뢰할 수 있도록 하여, 초지능이 인간을 가족적 부모-자녀 신뢰관계로 이해하도록 하는 전략을 제안합니다.

- **Performance Highlights**: 제안된 'Supertrust' 정렬 전략은 초지능이 인간의 도덕적 판단 능력과 임시적 안전 제약을 이해하고 수용하는 방식으로 보호적인 공존을 가능하게 합니다. 이를 통해 미래의 초지능 발전 과정에서 가장 안전한 결과를 도출할 수 있을 것으로 기대됩니다.



### rLLM: Relational Table Learning with LLMs (https://arxiv.org/abs/2407.20157)
- **What's New**: rLLM (relationLLM)은 Relational Table Learning (RTL)와 Large Language Models (LLMs)을 위한 PyTorch 라이브러리입니다. 이 라이브러리는 최첨단 Graph Neural Networks (GNNs), LLMs, 그리고 Table Neural Networks를 표준화된 모듈로 분해하여 간단히 '결합(combine), 정렬(align), 공동훈련(co-train)' 방식으로 새로운 RTL 모델을 빠르게 구축할 수 있게 합니다.

- **Technical Details**: rLLM의 사용을 설명하기 위해 간단한 RTL 방법인 BRIDGE가 소개되었습니다. 또한, 기존 데이터셋을 개선하여 세 가지 새로운 관계형 테이블 데이터셋(TML1M, TLF2K, TACM12K)을 제시하였습니다. 라이브러리는 모듈식 접근 방식으로, 개발자가 새로운 모델을 신속하게 만들고 실험할 수 있도록 지원합니다.

- **Performance Highlights**: rLLM의 코드는 this https URL에서 확인할 수 있으며, RTL 관련 작업에 유용하고 사용하기 쉬운 개발 프레임워크로 사용되길 바랍니다. 새로운 데이터셋과 함께 제공되는 rLLM의 모듈형식의 간단한 구성요소들은 모델 학습의 유연성과 효율성을 증가시킵니다.



### ByteCheckpoint: A Unified Checkpointing System for LLM Developmen (https://arxiv.org/abs/2407.20143)
- **What's New**: ByteCheckpoint는 PyTorch-native 다중 프레임워크 LLM(대규모 언어 모델) 체크포인트 시스템으로서, 자동 온라인 체크포인트 리샤딩을 지원합니다. 이는 다양한 훈련 프레임워크와 병렬 구성 간의 복잡한 호환성을 해결하기 위해 설계되었습니다.

- **Technical Details**: ByteCheckpoint는 데이터/메타데이터 분리형 저장소 아키텍처를 사용하여 체크포인트 저장을 병렬 전략 및 훈련 프레임워크와 분리합니다. 비정형 텐서 샤딩 문제를 해결하기 위해 효율적인 비동기 텐서 병합 기술을 도입했으며, 여러 I/O 성능 최적화 기술을 제안하였습니다.

- **Performance Highlights**: 실험 결과, ByteCheckpoint는 기존 방법에 비해 체크포인트 저장 비용을 최대 529.22배, 로딩 비용을 최대 3.51배까지 감소시키는 뛰어난 성능을 보였습니다.



### Shapley Value Computation in Ontology-Mediated Query Answering (https://arxiv.org/abs/2407.20058)
- **What's New**: 이번 논문에서는 셰이플리 값(Shapley Value)을 온톨로지 기반 질의 응답(OMQA)에 활용하는 방법을 탐구합니다. 특히, 셰이플리 값 계산(SVC)의 복잡도에 대한 상세한 분석을 제시합니다.

- **Technical Details**: OMQA 설정에서 셰이플리 값 계산의 복잡성 분석을 수행하였으며, 설명 논리 ELHI_⊥로 구성된 온톨로지 T와 연결된 상수 없는 동형 폐쇄 질의 q로 구성된 온톨로지 기반 질의(T,q)를 대상으로 PF/#P-난해구 분류를 확립했습니다. 또한, 상수를 포함할 수 있는 연결되지 않은 질의도 다룰 수 있도록 #P-난해성 측면을 강화했습니다.

- **Performance Highlights**: 이 연구 결과는 최근 발견된 SVC와 확률 질의 평가 사이의 연계를利用하며, 확률적 OMQA에 대한 기존 결과를 일반화하는 데 기여합니다.



### A Study on the Implementation Method of an Agent-Based Advanced RAG System Using Graph (https://arxiv.org/abs/2407.19994)
- **What's New**: 이 연구는 기존의 검색 증강 생성(RAG, Retrieval-Augmented Generation) 모델의 한계를 극복하고 고품질 생성형 인공지능 서비스를 개발하기 위해 Graph 기술 기반의 진보된 RAG 시스템을 구현하는 것을 목표로 합니다. 기존 RAG 모델은 검색된 정보를 활용하여 높은 정확성과 유창성을 보여주지만, 사전 로드된 지식을 재처리하지 않고 응답을 생성함으로 인해 정확도 저하 문제를 겪을 수 있습니다.

- **Technical Details**: 이 연구에서는 Graph 기술을 활용한 향상된 RAG 시스템을 구현합니다. 시스템은 정보를 효율적으로 검색하고 활용하도록 설계되었습니다. 특히, LangGraph를 사용하여 검색된 정보의 신뢰성을 평가하고, 다양한 데이터를 종합하여 더 정확하고 향상된 응답을 생성합니다. 또한, 시스템의 작동 원리, 주요 구현 단계, 구현 코드 및 검증 결과를 통해 상세하게 설명하여 고급 RAG 기술에 대한 이해를 도와줍니다.

- **Performance Highlights**: 이 접근 방식은 기업 서비스에서 고급 RAG 시스템을 구현하기 위한 실용적 지침을 제공하며, 실제 응용에 유용한 자료가 됩니다.



### Simply Trainable Nearest Neighbour Machine Translation with GPU Inferenc (https://arxiv.org/abs/2407.19965)
Comments:
          6 pages

- **What's New**: 이 논문에서는 학습 가능한 최근접 이웃 기계 번역 (nearest neighbor machine translation, knnMT)을 제안하고, GPU에서의 추론 실험을 수행했습니다. 이 방법은 각 입력 문장에 대해 작은 데이터 저장소(datastore)를 적응적으로 구성하고, knnMT와 사전 학습된 결과 사이의 인터폴레이션 계수를 자동으로 학습하는 단일 레이어 네트워크를 훈련합니다. 이를 통해 서로 다른 도메인에서 번역 품질을 자동으로 조절할 수 있습니다.

- **Technical Details**: 기존의 knnMT는 큰 참조 말뭉치를 검색하고 고정된 인터폴레이션을 사용하는데서 발생하는 계산 복잡성과 번역 품질 문제를 겪고 있습니다. 이 논문에서는 그러한 문제점을 해결하기 위해 두 가지 주요 단계를 제안합니다. 첫 번째 단계로 각 입력 문장에 대해 작은 데이터 저장소를 동적으로 구축하고, 두 번째 단계로는 knnMT와 사전 훈련된 모델 간의 인터폴레이션 계수를 학습 가능한 단일 레이어 네트워크를 사용하여 도메인에 따라 자동으로 인터폴레이션을 조절합니다.

- **Performance Highlights**: 다양한 도메인에서의 실험 결과, 제안된 방법은 Dai et al.의 방법보다 번역 품질을 개선하거나 유지하면서도 자동으로 조절하는 능력을 보여주었습니다. 또한, GPU에서의 추론 결과, knnMT를 GPU에 통합했을 때 속도가 5% 정도만 감소하는 성능을 입증하였습니다.



### Monetizing Currency Pair Sentiments through LLM Explainability (https://arxiv.org/abs/2407.19922)
Comments:
          7 pages, 3 figures, AIFin@ECAI 2024

- **What's New**: 본 연구에서는 큰 언어 모델(large language models, LLMs)이 어떻게 감정 분석(sentiment analysis, SA)과 설명 가능성(explainability)에 활용될 수 있는지를 강조합니다. 특히, SA의 설명 가능성을 위해 모델 독립적인 도구로서 LLMs를 사후(post-hoc) 모델로 활용하는 새로운 기술을 제안합니다.

- **Technical Details**: 제안된 기술은 금융 도메인에서 통화 쌍 가격 예측을 위해 사용되었으며, 이를 위해 공개 뉴스 피드 데이터와 시장 가격 데이터를 결합하였습니다(Open news feed data merged with market prices). 기존의 설명 가능한 인공지능(eXplainable AI) 대신 사용할 수 있는 유효한 대안뿐만 아니라, ML 모델의 입력 데이터로 피드백하여 미래 통화 쌍 가격을 예측하는 데 도움을 준다는 것을 보여주었습니다.

- **Performance Highlights**: 본 연구의 결과는 설명 가능성을 ML 입력 자료로서 전통적으로 사용할 경우 보다 향상된 ML 예측을 위한 일반적인 방법으로 활용될 수 있는 가능성을 시사합니다.



### Leveraging Foundation Models for Zero-Shot IoT Sensing (https://arxiv.org/abs/2407.19893)
- **What's New**: IoT (사물인터넷) 장치에서 동작하는 딥러닝 모델들이 보통 유도(훈련)된 조건 하에서만 동작하며, 훈련 데이터와 다른 보지 못한 클래스(unseen classes)를 인식하지 못하는 문제를 해결하기 위해 이번 연구에서는 제로샷 학습(ZSL: Zero-Shot Learning)을 활용합니다. 웹 스케일 데이터에서 훈련된 Foundation Models(FMs)는 자연어 처리와 시각적 이해에서 인상적인 제로샷 학습 능력을 보였으나, 이를 mmWave, IMU, Wi-Fi와 같은 신호를 사용하는 제로샷 IoT 센싱에 활용하는 것은 충분히 조사되지 않았습니다. 본 연구에서는 IoT 데이터 임베딩(embeddings)을 FM의 텍스트 인코더가 생성한 시맨틱 임베딩과 정렬(alignment)시켜, 제로샷 IoT 센싱을 실현하려 합니다.

- **Technical Details**: IoT 센서 신호 생성에 관여하는 물리학 원리를 활용해 시맨틱 임베딩 추출을 위한 보다 효과적인 프롬프트(prompts)를 도출하기 위해 크로스 어텐션(cross-attention)을 사용합니다. 이는 자동으로 최적화된 학습 가능한 소프트 프롬프트와 IoT 센싱 작업의 도메인 지식을 인코딩한 보조 하드 프롬프트를 결합합니다. 또한, 훈련 중 보지 못한 클래스 데이터가 부족하여 IoT 임베딩이 보이는 클래스에 편향되는 문제를 해결하기 위해 데이터 증대(data augmentation)를 사용해 보지 못한 클래스 IoT 데이터를 합성하여 IoT 특징 추출기와 임베딩 프로젝터를 미세 조정(fine-tuning)합니다.

- **Performance Highlights**: 우리 접근법은 여러 IoT 센싱 작업에서 우수한 오픈 셋(open-set) 탐지 및 일반화된 제로샷 학습 성과를 보였습니다. 다양한 베이스라인과 비교했을 때, 제안된 방식이 더 나은 성능을 달성하였습니다. 우리 코드 및 관련 자료는 다음 URL에서 제공됩니다: this https URL_ZSL_IoT.



### A Unified Graph Transformer for Overcoming Isolations in Multi-modal Recommendation (https://arxiv.org/abs/2407.19886)
- **What's New**: 이번 연구는 온라인 멀티미디어 서비스, 특히 전자상거래 플랫폼에서 필요로 하는 개인화 추천 시스템의 성능을 향상시키기 위해 고안된 새로운 모델인 Unified Multi-modal Graph Transformer (UGT)를 소개합니다. 기존의 멀티모달 추천 시스템이 독립적으로 특징 추출과 모달리티 모델링 과정을 진행하는 점과 달리, 본 연구는 통합된 모델 사용이 이러한 이슈를 해결할 수 있다고 가정합니다.

- **Technical Details**: UGT 모델은 첫 번째로 멀티웨이 트랜스포머(multi-way transformer)를 활용하여 원시 데이터로부터 정렬된 멀티모달 특징을 추출합니다. 이 후, 통합된 그래프 신경망(graph neural network)을 구축하여 사용자와 아이템의 표현을 그들의 대응하는 멀티모달 특징과 함께 결합합니다. 또한, UGT 모델의 그래프 트랜스포머 구조를 통해, 자주 사용되는 멀티모달 추천 손실 함수들과 함께 최적화될 경우 모델의 효과성을 극대화할 수 있음을 보입니다.

- **Performance Highlights**: UGT 모델은 사용자/아이템 표현 및 멀티모달 특징을 일관성 있게 추출하고 결합함으로써 멀티모달 추천 시스템의 성능을 크게 향상시킵니다. 그래프 트랜스포머 아키텍처를 통해 UGT 모델이 추천 시스템의 효과성을 극대화하는 데 기여하며, 이는 종래의 개별적인 처리 방식보다 더 뛰어난 성능 증진을 보여줍니다.



### Distances Between Partial Preference Orderings (https://arxiv.org/abs/2407.19869)
Comments:
          10 pages

- **What's New**: 이 논문은 부분 선호 순서 (partial preference orderings) 사이의 거리를 측정하는 두 가지 접근 방식을 제안합니다. 첫 번째 접근은 조합론에 기반한 조합 접근법으로, 모든 가능한 전체 선호 순서를 생성하고, Frobenius 거리를 계산하는 방법입니다. 두 번째 접근은 믿음 함수 (belief functions)를 사용하는 방법으로, 부분 선호 순서의 부족한 정보를 적절히 모델링할 수 있습니다.

- **Technical Details**: 첫 번째 접근 방식에서는 조합론에 기반하여 모든 가능한 전체 선호 순서를 생성하고 이들 간의 Frobenius 거리를 계산합니다. 그러나 이 방법은 고차원 문제를 해결하는 데 매우 비효율적입니다. 두 번째 접근 방식은 믿음 함수를 사용하여 부분 선호 순서의 부족한 정보를 적절히 모델링하고, 조합 복잡성의 한계로부터 벗어난 거리 계산 방식을 제안합니다.

- **Performance Highlights**: 논문은 간단한 예제를 통해 두 이론적 방법이 어떻게 작동하는지 보여줍니다. 믿음 함수를 사용한 두 번째 접근 방식은 효율성을 극대화하면서도 조합 복잡성의 한계를 극복할 수 있음을 강조합니다.



### Imitation Learning for Intra-Day Power Grid Operation through Topology Actions (https://arxiv.org/abs/2407.19865)
Comments:
          To be presented at the Machine Learning for Sustainable Power Systems 2024 workshop and to be published in the corresponding Springer Communications in Computer and Information Science proceedings

- **What's New**: 본 논문에서는 Topology Actions를 통한 하루 앞서의 전력망 운영을 위해 모방 학습(imitation learning)의 성능을 연구합니다. 특히, greedy agent와 N-1 agent라는 두 가지 규칙 기반 전문가 에이전트를 고려합니다. N-1 agent는 안전 고려 사항을 반영하여 운영 성능이 훨씬 높지만 계산 비용이 많이 듭니다.

- **Technical Details**: 전문가 상태-행동 쌍을 바탕으로 완전 연결 신경망(FCNN)을 훈련시켰으며, 두 가지 방법으로 평가했습니다. 첫째로, 클래스 불균형 및 클래스 중첩으로 인해 광범위한 하이퍼파라미터 튜닝에도 불구하고 분류 정확도가 제한되었습니다. 둘째로, 전력 시스템 에이전트로서의 FCNN은 전문가 에이전트보다 약간 낮은 성능을 보였습니다.

- **Performance Highlights**: 하이브리드 에이전트는 최소한의 추가 시뮬레이션을 포함하여 전문가 에이전트의 성능과 일치하면서도 컴퓨팅 비용을 크게 줄였습니다. 따라서 모방 학습은 빠르고 높은 성능의 전력망 에이전트를 개발하는 데 가능성을 보여주며, 향후 L2RPN 연구에서 이를 탐색할 동기를 제공합니다.



### Imputation for prediction: beware of diminishing returns (https://arxiv.org/abs/2407.19804)
- **What's New**: 새로운 연구에서는 누락된 값(missing values)을 다루는 일반적인 방법인 '대치'(Imputation)에 대해 깊이 탐구하였습니다. 기존의 연구들과 달리, 이 연구는 고급 대치 방법이 실제로 예측 성능을 크게 향상시키는지 여부를 평가하고 있습니다. 20개의 데이터셋에서 다양한 대치 및 예측 모델을 사용하여 분석한 결과, 특정 조건 하에서는 대치 정확도가 덜 중요하다는 결론을 도출했습니다.

- **Technical Details**: 연구에서는 'MCAR'(Missing Completely at Random)와 같은 시나리오에서도 'missingness indicator'(누락 지표)를 사용하면 예측 성능에 유익하다는 점을 발견했습니다. 또한, 더 강력한 모델을 사용할 때, 그리고 누락 지표를 보완 입력으로 포함할 때, 대치 방법의 정확성이 예측 성능에 뚜렷한 영향을 미치지 않는다는 것을 보여주었습니다. 흥미롭게도, 생성된 선형 결과보다 실제 데이터 결과에서는 대치 정확도가 예측 성능에 덜 중요하다는 점도 확인했습니다.

- **Performance Highlights**: 실제 데이터에서 강력한 모델들과 함께 대치 방법을 개선하는 것이 예측 성능에 큰 영향을 미치지 않는다는 결론을 내렸습니다. 이는 예측을 개선하기 위해 고급 대치 방법에 투자하는 것이 제한된 이익을 제공할 수 있음을 시사합니다.



### Hashing based Contrastive Learning for Virtual Screening (https://arxiv.org/abs/2407.19790)
- **What's New**: 이 논문에서는 컴퓨터 기반 약물 발견(computer-aided drug discovery)에서 중요한 가상 스크리닝(VS)를 위한 새로운 방법인 DrugHash를 제안합니다. DrugHash는 VS 과정에서 기존의 리얼 밸류 벡터(real-valued vector) 표현 대신 효율적인 바이너리 해시 코드(binary hash codes)를 사용하여 메모리와 시간을 크게 절약하면서도 높은 정확도를 제공합니다.

- **Technical Details**: DrugHash는 대조 학습(contrastive learning)을 활용하여 단백질과 분자 모두에 대해 바이너리 해시 코드를 학습하는 간단하면서도 효과적인 해싱 전략을 설계합니다. 이를 통해 엔드 투 엔드 학습(end-to-end learning)이 가능해지며, 기존 방법들이 요구하는 막대한 메모리와 시간을 줄일 수 있습니다.

- **Performance Highlights**: DrugHash는 메모리 소비를 32배 줄이고 속도를 3.5배 개선함으로써 기존 방법들을 능가하여 최신의(state-of-the-art) 정확도를 달성했습니다.



### Multimodal Large Language Models for Bioimage Analysis (https://arxiv.org/abs/2407.19778)
- **What's New**: 최근에 등장한 다중모드 대형 언어 모델(Multimodal Large Language Models, MLLMs)은 이해, 분석, 추론 및 일반화와 같은 뛰어난 능력을 보이고 있으며, 이를 통해 다양한 모달리티로 얻은 생물학적 이미지와 데이터를 정교하게 추출할 수 있을 것으로 기대됩니다. 이는 생물학 연구에서 새로운 계산 프레임워크 개발을 가속화하는 데 기여할 수 있습니다.

- **Technical Details**: MLLMs는 다중 모드 데이터를 처리할 수 있는 역량을 갖추고 있으며, 이는 생물학적 이미지와 데이터를 다차원적으로 분석하고 해석할 수 있는 강력한 도구가 될 수 있습니다. 이러한 모델들은 주로 인간이 해석하고 요약하는 데 의존하던 생물학적 관찰의 의미 있는 결론을 도출할 수 있는 능력으로 주목받고 있습니다.

- **Performance Highlights**: MLLMs의 이러한 혁신적 특성은 생물학 연구에서 지식을 추출하고 새로운 인사이트를 도출하는 데 매우 유용할 것으로 예상됩니다. 이는 연구자들이 더 복잡하고 방대한 데이터를 효과적으로 처리하고 분석할 수 있게 하여 연구 효율성을 크게 향상시킬 수 있습니다.



### Model Agnostic Hybrid Sharding For Heterogeneous Distributed Inferenc (https://arxiv.org/abs/2407.19775)
- **What's New**: Nesa는 대규모 AI 모델의 비효율적인 중앙집중식 구조를 개선하기 위해 모델 독립적인 샤딩 프레임워크를 제안하고 있습니다. 이 프레임워크는 블록체인 기반의 순차적 딥 뉴럴 네트워크 샤딩을 이용해 다양한 노드 네트워크에 계산 작업을 분산시킵니다. 높은 개인정보 보호와 스케일 확장성을 요구하는 문제에 효율적인 해결책을 제공합니다.

- **Technical Details**: Nesa는 퍼스널라이즈드 히러스틱과 라우팅 메커니즘을 사용하여 컴퓨팅 태스크를 분산시키며, 이를 통해 최근 대규모 모델의 분산 트레이닝 및 추론을 가능하게 합니다. 이를 위해 다이나믹 블록별 양자화(dynamic blockwise quantization)와 혼합 매트릭스 분해(mixed matrix decomposition) 등을 사용하여 데이터 전송량과 메모리 요구량을 감소시킵니다. 또한 하드웨어 기반 신뢰 실행 환경(hardware-based trusted execution environments)을 통합하여 데이터 무결성과 기밀성을 보장합니다.

- **Performance Highlights**: 다양한 자연어 처리(natural language processing) 및 비전 태스크를 평가한 결과, 이러한 압축 기술이 모델 정확도를 손상시키지 않는다는 점을 확인했습니다. 이로 인해 최신 AI 기술을 보다 널리 대중에게 제공할 수 있는 가능성을 강조하며, 소비자용 하드웨어로도 효과적인 분산 추론을 가능하게 합니다.



### Generating Unseen Code Tests In Infinitum (https://arxiv.org/abs/2407.19772)
- **What's New**: 이번 연구에서는 코딩 관련 작업에서 사용되는 대형 언어 모델(LLMs)을 위한 새로운 평가 방법을 제안합니다. 기존의 벤치마크 평가 방식은 훈련 데이터로의 유출 문제로 잘 알려져 있으나, 이를 해결하기 위한 벤치마크 변형 방법을 제시하였습니다. 이것은 지속적인 테스트 데이터 생성을 통해 데이터 유출 문제를 완화할 수 있습니다.

- **Technical Details**: 본 방법은 코드 생성 작업과 프로그래밍 언어 전반에 걸쳐 일반화할 수 있는 벤치마크 변형을 생성하며, 자체 코드베이스(In-house Code bases)에도 적용할 수 있습니다. 연구팀은 Python에서 텍스트-코드 생성 작업을 위한 auto-regression 벤치마크를 구현했습니다. 이 벤치마크는 디버깅 및 모델 생성 변화를 추적하는데 도움을 주며, LLM 회귀 테스트 프로세스의 일환으로 설계되었습니다.

- **Performance Highlights**: auto-regression 벤치마크는 모델의 디버깅과 생성된 코드의 변화를 추적하는 데 유용하며, 이를 통해 평가와 비교의 신뢰성을 높였습니다. 지속적인 테스트 데이터 생성을 통해 훈련 데이터로의 유출을 방지하는 데 중점을 두었습니다.



### Map2Traj: Street Map Piloted Zero-shot Trajectory Generation with Diffusion Mod (https://arxiv.org/abs/2407.19765)
- **What's New**: 최근 무선 네트워크 최적화를 위한 새로운 사용자 이동성 모델링(이동 패턴 모델링) 기법이 발표되었습니다. 이는 'Map2Traj'라는 새로운 zero-shot 경로 생성(trajectory generation) 방법을 제안하며, 도로 지도를 활용해 실제와 유사한 이동 경로를 생성합니다.

- **Technical Details**: Map2Traj는 확산 모델(diffusion model)을 활용하여 경로 생성의 노이즈 제거 과정을 지속적으로 조정합니다. 이 모델은 Xi'an, 중국의 다양한 지역에서 수집된 실제 경로 데이터와 해당 도로 지도를 학습하며, 관측되지 않은 지역의 도로 지도만으로도 신뢰성 있는 경로 데이터를 생성할 수 있도록 설계되었습니다. 이로써 개인정보 문제로 인해 접근이 어려운 실제 경로 데이터 문제를 해결하고자 했습니다.

- **Performance Highlights**: 폭넓은 실험 결과, Map2Traj는 실제 이동 패턴과 유사한 합성 경로를 생성할 수 있음이 입증되었습니다. Trajectory similarity(경로 유사성)와 distribution similarity(분포 유사성) 측면에서 우수한 성능을 보이며, 무선 네트워크 최적화와 같은 다운스트림(downstream) 응용에도 효과적임을 보여주는 사례 연구도 포함되어 있습니다.



### Smart Language Agents in Real-World Planning (https://arxiv.org/abs/2407.19667)
Comments:
          5 pages, 1 figure

- **What's New**: 이 논문에서는 최근 자연 언어 처리(NLP)에서 성공적으로 이용되고 있는 대형 언어 모델(LLMs)을 활용하여 여행 계획 기능을 향상시키기 위해 새로운 방법을 탐구했습니다. 특히 'sole-planning' 모드에 초점을 두어, 필요한 참조 정보를 제공받은 에이전트(agent)가 이 정보를 토대로 종합적인 계획을 세울 수 있도록 했습니다.

- **Technical Details**: 논문에서는 LLM 자동 생성 프롬프트(prompt)와 'human-in-the-loop' 방식을 결합한 반자동 프롬프트 생성 프레임워크를 제안합니다. 이 프레임워크는 프롬프트를 반복적으로 정제(refine)하여 LLM의 성능을 향상시키는 것을 목표로 합니다. 이러한 접근법은 실제 환경을 정확하게 시뮬레이션하는 것이 아니지만, 단독 계획 수립 능력을 최적화함으로써 사용자의 전반적인 경험을 향상시킬 수 있다고 주장하고 있습니다.

- **Performance Highlights**: 연구 결과, LLM 자동 생성 프롬프트만으로는 한계가 존재하며, 'human-in-the-loop' 방식을 도입했을 때 단 한 번의 반복(iteration)만으로도 성능이 $139\%$ 향상됨을 확인했습니다.



### AI-Driven Healthcare: A Survey on Ensuring Fairness and Mitigating Bias (https://arxiv.org/abs/2407.19655)
- **What's New**: 새로운 인공지능(AI) 기술들이 의료 분야 전반에 걸쳐 큰 변화를 일으키고 있습니다. 이러한 변화는 심장학(cardiology), 안과(ophthalmology), 피부과(dermatology), 응급의학(emergency medicine) 등 다양한 전문 분야에서 서비스의 효율성과 효과를 극대화하고 있습니다. AI 기술이 진단 정확도, 치료 개인화(personalization), 환자 결과 예측을 크게 개선하였습니다. 하지만 이러한 발전은 데이터 및 알고리즘의 편향(bias)와 관련된 윤리적 및 공정성 문제를 동반하고 있습니다.

- **Technical Details**: AI의 발전에는 머신러닝(machine learning), 신경망(neural networks), 자연어 처리(natural language processing)와 같은 기술들이 활용되고 있습니다. 이러한 기술을 통해 의료진은 향상된 진단 정확도, 개인화된 치료 계획, 그리고 정확한 환자 예후 예측이 가능해졌습니다. 그러나 데이터와 알고리즘의 편향은 의료 서비스 제공에 있어 공정한 결과를 방해할 수 있습니다.

- **Performance Highlights**: 이 논문은 의료 분야에서 AI의 통합을 조사하고, 편향과 관련된 주요 문제점을 강조하며 이러한 문제를 해결하기 위한 전략을 탐구합니다. 다양한 데이터셋의 필요성, 공정성을 인지하는 알고리즘의 개발, 그리고 규제 프레임워크의 수립이 중요하다고 강조되었습니다. 논문은 투명한 AI 의사결정, 혁신적이고 포용적인 AI 애플리케이션 개발을 위해 미래 연구의 방향성을 제시합니다.



### Foundations for Unfairness in Anomaly Detection -- Case Studies in Facial Imaging Data (https://arxiv.org/abs/2407.19646)
Comments:
          16 pages, 8 figures, AAAI/ACM AIES24

- **What's New**: 이번 연구는 깊은 이상 탐지(Deep Anomaly Detection, AD) 알고리즘의 공정성 문제를 얼굴 이미지 데이터를 통해 탐구합니다. 이는 AI를 얼굴 이미지 데이터에 적용하는 것의 논란과, AD 알고리즘의 공정성 문제를 밝히기 위한 시도입니다. 특히, 최근 연구에 따르면 자화상에서 유색 인종 남성이 비정상치(Outlier)로 선택될 가능성이 높다는 것을 강조하고 있습니다.

- **Technical Details**: 우리는 AD 알고리즘의 두 주요 범주, 즉 오토인코더(Autoencoder) 기반과 단일 클래스 기반 알고리즘에 대해 연구했습니다. 이 알고리즘들은 모든 인스턴스를 압축하려 시도하며 쉽게 압축되지 않는 인스턴스를 비정상치로 간주합니다. 연구를 통해, 그룹의 과소 대표(예: 유색 인종이 상대적으로 적음), 가짜 그룹 특징(예: 남성은 종종 모자를 쓰고 촬영됨), 그룹 레이블링 노이즈(예: 인종은 주관적임) 등의 불공정성 원인을 실험적으로 확인했습니다.

- **Performance Highlights**: 중요한 결과로, 압축 불가능성이 주요 원인이라 생각했으나, 실험 결과는 그렇지 않음을 보였으며, 자연스러운 계층 구조를 제시했습니다. 이는 AD 알고리즘의 불공정성 문제를 해결하는 데 중요한 통찰을 제공합니다.



### Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation (https://arxiv.org/abs/2407.19643)
- **What's New**: Lenovo 지원을 받아 개발된 새로운 챗봇 'Prometheus'를 소개합니다. 이 챗봇은 자연어로 입력된 사용자 요청을 처리할 수 있으며, 지식 그래프(KG)를 활용하여 컴퓨터 구성 요소에 대한 맞춤형 추천을 제공합니다.

- **Technical Details**: Prometheus는 Large Language Model (LLM)과 지식 그래프(KG)를 통합하여 사용자 의도를 정확하게 해석하고, 제품명을 포함한 엔티티를 식별 및 연계합니다. 이를 통해 유저의 컴퓨터 설정 요구사항을 정확히 이해하고 응답할 수 있습니다.

- **Performance Highlights**: Prometheus는 자연어 처리 유닛이 인간 언어의 모호성과 변수를 효과적으로 다뤄 사용자 의도를 정확하게 파악하며, 지식 그래프 노드와의 정확한 엔티티 연결을 실현해 개인 맞춤형 추천을 제공합니다.



### OptiMUS-0.3: Using Large Language Models to Model and Solve Optimization Problems at Sca (https://arxiv.org/abs/2407.19633)
Comments:
          This paper documents OptiMUS-0.3, improving on OptiMUS-0.1 (arXiv:2310.06116) and OptiMUS-0.2 (arXiv:2402.10172). arXiv admin note: text overlap with arXiv:2402.10172

- **What's New**: 최신 연구에서는 최적화 문제(optimization problems)를 자연어(natural language) 설명으로부터 수학적 모델로 변환하고 해결할 수 있는 대형 언어 모델(Large Language Model, LLM) 기반 시스템, OptiMUS-0.3을 소개하고 있습니다. 이 시스템은 문제를 공식화하고 해결하는 과정을 자동화하여 최적화 도구와 기술의 보편적인 적용을 방해하는 제약을 줄이는 데 도움이 됩니다. 새로운 데이터셋 NLP4LP도 함께 공개되었습니다.

- **Technical Details**: OptiMUS-0.3은 혼합 정수 선형 계획법(mixed integer linear programming) 문제를 포함한 다양한 최적화 문제를 다룰 수 있도록 설계되었습니다. 이 시스템은 자연어 설명으로부터 수학적 모델을 개발하고, 솔버 코드(solver code)를 작성 및 디버깅(debugging)하며, 생성된 솔루션을 평가하고, 이러한 평가를 바탕으로 모델과 코드의 효율성 및 정확성을 개선할 수 있습니다. 또한 모듈 구조(modular structure)를 채택하여 복잡하고 긴 데이터를 다룰 수 있는 기능을 보유하고 있습니다.

- **Performance Highlights**: OptiMUS-0.3은 기존 최첨단(state-of-the-art) 방법을 소위 '쉬운 데이터셋'에서 12% 이상, '어려운 데이터셋'에서 8% 이상 능가하는 성능을 보였습니다. 특히, 새로운 데이터셋 NLP4LP에서는 긴 설명과 복잡한 문제를 효과적으로 처리할 수 있는 우수한 성능을 입증했습니다.



### "A Good Bot Always Knows Its Limitations": Assessing Autonomous System Decision-making Competencies through Factorized Machine Self-confidenc (https://arxiv.org/abs/2407.19631)
Comments:
          59 pages, 22 figures, draft to be submitted for journal review

- **What's New**: 이 논문에서는 자율 시스템이 작업 수완을 자가 평가하는 능력에 대한 새로운 개념적 틀을 소개합니다. 이는 인지적 자율 시스템에 있어서 중요한 연구 주제입니다. 제안된 프레임워크는 Factorized Machine Self-confidence (FaMSeC)라고 불리며, 알고리즘적 의사결정 프로세스를 추진하는 여러 요인들에 대한 포괄적인 설명을 제공합니다.

- **Technical Details**: FaMSeC는 Markov decision processes(MDP) 같은 광범위한 확률적 의사결정 알고리즘에 내장된 계층적 문제 해결 통계를 통해 자체 신뢰성 지표를 도출합니다. 이러한 통계는 비전문 사용자 또는 전문가 시스템 설계자가 지정한 능력기준에 대한 확률적 초과 한계를 평가하고 등급을 매겨 얻어집니다. FaMSeC 접근법은 '알고리즘의 적합도' 평가를 인간이 이해할 수 있는 능력 자가 평가 보고서로 쉽게 통합할 수 있게 합니다.

- **Performance Highlights**: Markov decision process 에이전트를 위한 세부 설명과 응용 예제를 통해 이번 프레임워크의 두 요인(성과 평가 및 해법 품질)을 다양한 작업 맥락에서 실질적으로 계산하고 보고하는 방법을 제시합니다. 이 과정은 메타 유틸리티 함수, 행동 시뮬레이션 및 대체 예측 모델의 새로운 사용 사례를 통해 수행됩니다.



### LLMs' Understanding of Natural Language Revealed (https://arxiv.org/abs/2407.19630)
- **What's New**: 최근 연구에 따르면, 대형 언어 모델(LLMs)의 언어 이해 능력이 과장되었음을 지적하고 있습니다. 특히 LLMs가 인간처럼 일관된 언어를 생성하는 데 능하지만, 실제 언어 이해 능력은 제대로 테스트되지 않았다고 합니다.

- **Technical Details**: 연구는 LLMs가 대규모 데이터 기반으로 언어를 하향식(reverse engineering) 방식으로 이해하려 한다고 설명합니다. 그러나 문제 해결이나 계획 수립과 같은 상징적 변수(symbolic variables) 조작이 필요한 작업에서는 능력이 부족하며, 이는 기존 연구 [25][26]에서도 확인된 바 있습니다. 실제 테스트 방법으로는, 텍스트 생성(text generation)과 반대되는 작업을 수행하게 하여 주어진 텍스트 조각(snippets)을 기반으로 LLMs가 무엇을 '이해했는지'를 질의합니다.

- **Performance Highlights**: 결과적으로, LLMs는 방대한 양의 텍스트를 암기한 결과로 인해 매우 피상적인 추론을 할 수 있을 뿐, 진정으로 언어를 이해하고 있지는 않다고 결론지었습니다.



### Enhancing Code Translation in Language Models with Few-Shot Learning via Retrieval-Augmented Generation (https://arxiv.org/abs/2407.19619)
Comments:
          LLM for code translation

- **What's New**: 대형 언어 모델(LLMs)의 출현으로 코드 번역 분야가 크게 발전하였으나, 이 모델들은 부족한 맥락적 이해로 인해 복잡한 번역 작업에서 종종 어려움을 겪습니다. 본 논문에서는 Few-Shot Learning을 강화한 retrieval-based 기법을 통해 코드 번역을 향상시키는 새로운 접근 방식을 소개합니다. 우리는 기존 코드 번역 저장소를 활용하여 가장 관련성이 높은 예제를 동적으로 검색하고, 이를 통해 새로운 코드 세그먼트를 번역하도록 모델을 안내합니다.

- **Technical Details**: 우리의 방법은 Retrieval-Augmented Generation (RAG)에 기반하며, 맥락 예제를 제공하여 모델이 실시간으로 배울 수 있게 함으로써 번역 품질을 크게 향상시킵니다. RAG 방법은 전통적인 파인 튜닝(fine-tuning) 방법보다 기존 코드베이스나 로컬에 저장된 코드의 동적 활용이 가능하며, 광범위한 재훈련 없이도 다양한 번역 작업에 적응할 수 있습니다. 우리는 Starcoder, Llama3-70B Instruct, CodeLlama-34B Instruct, Granite-34B Code Instruct, Mixtral-8x22B와 같은 오픈 LLM 모델과 GPT-3.5 Turbo 및 GPT-4와 같은 상용 모델을 사용하여 다양한 데이터셋에서 실험을 수행했습니다.

- **Performance Highlights**: 우리의 접근 방안이 특히 Fortran과 CPP 간의 번역에서 전통적인 zero-shot 방법에 비해 우수함을 입증했습니다. 또한, 추론 중 제공되는 예제의 수(1, 2, 3 shots)와 RAG를 위한 다양한 임베딩 모델(Nomic-Embed, Starencoder, CodeBERT)을 탐구하여 접근 방안의 견고성과 효과를 평가했습니다.



### Mixture of Modular Experts: Distilling Knowledge from a Multilingual Teacher into Specialized Modular Language Models (https://arxiv.org/abs/2407.19610)
Comments:
          Preprint

- **What's New**: 이 연구는 지식 증류(Knowledge Distillation, KD)와 전문가 혼합(Mixture of Experts, MoE)을 결합하여 모듈러하고 효율적인 다국어 언어 모델을 개발합니다. 연구의 주요 목표는 KD에서의 적응형 알파와 고정 알파 방법을 평가하고, 다중 도메인 입력을 처리하고 치명적 망각(catastrophic forgetting)을 방지하는 모듈러 MoE 아키텍처를 비교하는 것입니다.

- **Technical Details**: 지식 증류(KD)를 통해 대형 언어 모델(LLMs)을 작은 효율적인 모델로 압축하고, 전문가 혼합(MoE)을 통해 특화된 작업에서의 모듈러리티를 향상시킵니다. 실험 결과에 따르면 두 가지 KD 방법 모두 유사한 성능을 보였으며, 적응형 알파에서 약간의 개선이 있었습니다. 라우터(router)는 입력 시퀀스를 영어, 프랑스어, 독일어 또는 Python으로 분류하도록 훈련되었으며, 99.95%의 정밀도, 재현율, F1 점수를 달성했습니다. 가장 효과적인 분류기는 로지스틱 회귀(Logistic Regression)였습니다.

- **Performance Highlights**: 모듈러 MoE 아키텍처 평가에서 미리 훈련된 언어 전문가(Pre-trained Language Experts, PLE)와 공동 전문가 임베딩 훈련(Joint Expert Embedding Training, JEET)은 유사한 성능을 보였고, 일반 전문가를 포함한 MoE 설정(MoE-CE)은 약간 낮은 성능을 보였습니다. 단일 세션 훈련과 MoE 접근 방식이 치명적 망각 문제를 완화시키는 데 효과적이었고, MoE 아키텍처는 여러 언어에 걸쳐 지식을 잘 유지했습니다.

- **Resources**: 연구는 데이터셋, 균형 잡힌 데이터셋 생성 도구, 연구 코드베이스 등을 포함한 오픈 소스 자원을 제공합니다.



### The Interpretability of Codebooks in Model-Based Reinforcement Learning is Limited (https://arxiv.org/abs/2407.19532)
- **What's New**: 이 논문에서는 딥 강화 학습 시스템의 해석 가능성을 향상시키기 위한 벡터 양자화(타 코드북) 방법을 조사하였습니다. 저자들은 강화 학습 환경인 Crafter에서 실험을 통해 벡터 양자화가 모델 해석 가능성을 제공하는지 여부를 연구하였습니다.

- **Technical Details**: 벡터 양자화(Vector Quantization, VQ) 방법은 신경망의 잠재 공간(latent space)을 이산화(discretize)합니다. 저자들은 이러한 이산화가 발생하는 해석 가능성이 실제로 존재하는지 확인하기 위해 모델 기반 강화 학습에서 벡터 양자화를 사용한 실험을 진행하였습니다. 특히, 코드의 일관성, 고유성 보장 및 개념 분리(disentanglement)에 미치는 영향을 분석하였습니다.

- **Performance Highlights**: 실험 결과, 벡터 양자화 모델의 코드는 일관성이 없고, 고유성을 보장하지 않으며, 개념 분리에 제한적인 영향을 미침을 발견하였습니다. 이러한 요소들은 모두 해석 가능성을 위해 필수적인 특성이기 때문에 벡터 양자화가 모델 해석 가능성에 근본적으로 불충분할 수 있음을 보여줍니다.



### Multi-task Neural Networks for Pain Intensity Estimation using Electrocardiogram and Demographic Factors (https://arxiv.org/abs/2407.19475)
- **What's New**: 이 논문에서는 고통(pain) 인식을 위한 새로운 다목적 신경망(multi-task neural network)을 제안합니다. 이 네트워크는 개인의 나이와 성별 정보를 활용하여 고통을 자동으로 추정하며, 다른 기존 접근 방식들과 비교하여 그 장점을 증명합니다.

- **Technical Details**: 연구에서는 심전도(electrocardiography) 신호를 사용하여 고통 인식의 여러 형태를 분석하며, 인구통계학적 정보에 따른 고통 인식의 변화를 밝혀냅니다. 제안된 다목적 신경망은 고통을 효과적으로 평가하고, 다양한 형태로 나타나는 고통을 객관적이고 즉각적으로 인식합니다.

- **Performance Highlights**: 제안된 방법은 기존 방법들에 비해 성능 면에서 우수한 결과를 보여주며, 신경망이 나이와 성별 정보를 동시에 활용함으로써 더 정확한 고통 추정이 가능하다는 장점이 있습니다.



### Conversational AI Multi-Agent Interoperability, Universal Open APIs for Agentic Natural Language Multimodal Communications (https://arxiv.org/abs/2407.19438)
Comments:
          22 pages, 8 figures

- **What's New**: 이번 논문은 Conversational AI 다중 에이전트 상호운용성 프레임워크(interoperability frameworks)를 분석하고, Linux Foundation AI 및 DATA가 제안한 새로운 'Open Voice Interoperability' (OVON) 아키텍처를 설명합니다. 새로운 접근 방식은 주요 구성 요소와 함께 설명되어 있으며, 표준 다중 모달 AI 에이전트 통신을 배포하는 데 유용한 장점과 사용 사례를 강조합니다.

- **Technical Details**: 이 프레임워크는 Universal APIs를 기반으로 다양한 Conversational AI 에이전트(chatbots, voicebots, videobots, human agents 등) 간의 상호운용 가능한 상호작용을 구축하고 활성화합니다. 또한 특정 서비스를 제공하는 에이전트를 효율적으로 찾고 표준 Manifest 출판을 통해 이 서비스에 대한 정확한 정보를 얻을 수 있도록 설계된 새로운 Discovery 사양 프레임워크가 도입되었습니다. 이 모든 것은 Natural Language 기반 APIs를 통해 접근 가능합니다.

- **Performance Highlights**: 이 기여의 주요 목적은 다양한 플랫폼에서 AI 상호작용의 능력과 확장성을 크게 향상시키는 것입니다. 새로운 상호운용 가능한 Conversational AI 아시스턴트를 위한 아키텍처는 일반화될 수 있도록 설계되었으며, 오픈 리포지토리를 통해 접근할 수 있습니다.



### A Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy (https://arxiv.org/abs/2407.19422)
- **What's New**: 이번 논문은 인공지능(AI)을 활용한 인지 행동 치료(CBT)의 혁신적인 통합 방안을 다룹니다. 특히, 사전 학습 모델(Pre-Training Models, PTMs)과 거대 언어 모델(Large Language Models, LLMs)이 CBT 제공을 지원, 최적화 및 자동화하는 데에 큰 잠재력을 지니고 있음을 강조합니다. AI 기술의 도입이 CBT의 디지털 전환을 가속화할 수 있음을 논의합니다.

- **Technical Details**: CBT의 기본 개념을 소개한 후, 각 치료 단계별(치료 전, 치료 과정, 치료 후)로 AI와 CBT를 통합하는 방법을 설명합니다. 또한, CBT 관련 작업에 유용한 데이터셋을 요약하여 제공하고 있습니다. 현재 AI가 CBT에 제공할 수 있는 이점과 제한점을 논의하며 향후 연구가 필요한 핵심 영역을 제안합니다.

- **Performance Highlights**: AI 통합 CBT는 더욱 접근 가능하고 효율적이며 개인화된 정신 건강 중재를 가능하게 할 것입니다. 특히, 장기적인 효과와 임상적 유용성을 더 탐구하고 검증하는 것이 중요하다는 점을 강조하고 있습니다.



### Appformer: A Novel Framework for Mobile App Usage Prediction Leveraging Progressive Multi-Modal Data Fusion and Feature Extraction (https://arxiv.org/abs/2407.19414)
- **What's New**: 새로운 논문은 Appformer라는 새로운 모바일 애플리케이션 예측 프레임워크를 소개합니다. 이 프레임워크는 순차 데이터를 처리하는 데 있어 Transformer와 유사한 아키텍처의 효율성에서 영감을 받았습니다. Appformer는 다중 모달 데이터의 융합과 데이터 마이닝 기술의 시너지를 활용하면서 사용자 프라이버시를 유지합니다.

- **Technical Details**: Appformer는 'Multi-Modal Data Progressive Fusion Module'과 고급 'Feature Extraction Module'을 결합합니다. 여기에서 사용되는 주요 데이터는 기지국과 연관된 관심 지점(POIs)입니다. 다양한 실험을 통해 최적의 군집화 방법을 식별하고 이를 초기 교차 모달 데이터 융합 단계에서 통합합니다. 시간적 단위는 단어 임베딩(word embeddings)을 통해 인코딩되고, 이후 단계에서 결합됩니다. Feature Extraction Module은 시계열 분석(time series analysis)에 특화된 Transformer 유사 아키텍처를 사용하여 포괄적인 특징을 분석하고 추출합니다.

- **Performance Highlights**: 상세한 실험 검증을 통해 Appformer가 모바일 앱 사용 예측에서 최첨단(SOTA) 지표를 달성함을 확인했습니다. 이는 이 분야에서의 중요한 진전을 의미합니다.



### Identity-Driven Hierarchical Role-Playing Agents (https://arxiv.org/abs/2407.19412)
- **What's New**: 최근 들어 대형 언어 모델(Large Language Models, LLMs)을 활용하여 롤플레잉(role-playing) 기능을 구현하는 연구가 주목을 받고 있습니다. 이에 대한 주요 접근 방식은 정제된 프롬프트(prompts)를 사용하는 방법과 특정 역할 데이터셋에 대한 파인튜닝(fine-tuning)을 통한 방식이 있습니다. 그러나 이 방법들은 각각 정확성 부족과 유연성의 제한이라는 문제를 가지고 있습니다. 이를 해결하고자 우리는 독창적인 Hierarchical Identity Role-Playing Framework (HIRPF)를 제안하여 유연성과 정밀성 간의 균형을 맞추었습니다.

- **Technical Details**: 우리는 정체성(identity) 이론을 바탕으로 HIRPF를 구축하였으며, 이 프레임워크는 다중 정체성 조합을 사용하여 복잡한 캐릭터를 구성합니다. 이를 위해 정체성 대화 데이터셋(identity dialogue dataset)을 개발하고, 확장 평가(scale evaluation)와 개방형 상황 평가(open situation evaluation)를 포함한 평가 벤치마크(evaluation benchmark)를 제안하였습니다.

- **Performance Highlights**: 경험적 결과는 우리의 프레임워크가 정체성 수준의 역할 시뮬레이션에서 뛰어난 성능을 발휘하는 것을 보여주었으며, 이는 사회적 시뮬레이션(social simulation) 애플리케이션에 대한 잠재력을 드러냈습니다.



### AdaCoder: Adaptive Prompt Compression for Programmatic Visual Question Answering (https://arxiv.org/abs/2407.19410)
- **What's New**: 최근 비주얼 질문 답변(Visual Question Answering) 시스템에서는 대형 언어 모델(Large Language Models, LLMs)을 통해 실행 가능한 프로그램을 생성하여 질문에 답하는 비주얼 프로그래매틱 모델(Visual Programmatic Models, VPMs)이 주목받고 있습니다. 이 연구에서는 기존 VPM의 긴 입력 프롬프트 문제를 해결하기 위해 'AdaCoder'라는 적응형 프롬프트 압축 프레임워크를 제안합니다.

- **Technical Details**: AdaCoder는 두 단계로 운영됩니다. 첫 번째는 압축 단계로, Python 언어의 API 정의와 코드 예제를 설명하는 프리프롬프트(preprompt)로부터 특정 질문 유형에 따라 압축된 프리프롬프트 세트를 생성합니다. 두 번째는 추론 단계로, 입력된 질문을 기반으로 질문 유형을 예측하고 적합한 압축된 프리프롬프트를 선택하여 코드 생성을 통해 질문에 답변합니다. AdaCoder는 단일 고정된 LLM과 사전에 정의된 프롬프트를 사용하므로 추가 훈련 없이 다양한 강력한 블랙박스 LLM(GPT, Claude 등)에서 적응성을 유지할 수 있습니다.

- **Performance Highlights**: AdaCoder를 ViperGPT에 적용한 실험 결과, 토큰 길이를 71.1% 줄이면서도 비주얼 질문 답변 성능을 유지하거나 개선하는 것을 확인하였습니다.



### Logic Distillation: Learning from Code Function by Function for Planning and Decision-making (https://arxiv.org/abs/2407.19405)
Comments:
          9 pages, 7 figures

- **What's New**: 최근 주목받고 있는 큰 언어 모델(LLMs)의 논리적 추론 능력을 소형 언어 모델(S-LLMs)에 전수하기 위한 새로운 프레임워크인 Logic Distillation(LD)이 제안되었습니다. LD는 복잡한 명령을 이산 함수(discrete functions)로 구체화하고, 이를 기반으로 S-LLMs를 미세 조정하여 논리적 추론의 능력을 갖추게 합니다.

- **Technical Details**: LD는 처음에 큰 언어 모델(L-LLMs)을 사용하여 복잡한 명령을 개별 함수로 구체화하고, 사용 사례를 통해 함수 기반(function base)을 구축합니다. 이후 이 기반을 바탕으로 S-LLMs를 미세 조정하여 L-LLMs가 사용하는 논리적 계획 및 의사 결정 능력을 학습하도록 합니다. 테스트 단계에서는 retriever를 사용해 명령과 현재 상태에 기반해 상위 $K$개의 관련 함수를 식별하고 S-LLMs가 이를 선택 및 호출하여 결과를 도출하도록 합니다.

- **Performance Highlights**: 실험 결과, LD의 도움을 받은 S-LLMs는 논리적 계획 및 의사 결정 작업에서 L-LLMs와 비슷하거나 그 이상의 성과를 내는 것으로 나타났습니다.



### Integrating Cognitive AI with Generative Models for Enhanced Question Answering in Skill-based Learning (https://arxiv.org/abs/2407.19393)
Comments:
          9 pages, 6 figures, 1 table

- **What's New**: 이 논문은 온라인 학습 환경에서 학습자들에게 빠르고 정확한 피드백을 제공하기 위한 새로운 접근법을 제안합니다. 구체적으로, 인지 AI(Cognitive AI)와 생성 AI(Generative AI)를 결합하여 기술 기반 학습의 문제를 해결하려고 합니다. 논문은 TMK(Task-Method-Knowledge) 모델을 사용하여 온라인 지식 기반 AI 과정에서 가르치는 기술을 인코딩하는 방법을 설명합니다.

- **Technical Details**: 논문에서는 대형 언어 모델(Large Language Models), 사고 사슬(Chain-of-Thought), 반복 개선(Iterative Refinement) 같은 기술을 활용하여 학습자의 질문에 대해 이성적인 설명(reasoned explanations)을 생성하는 프레임워크를 제시합니다. 이러한 접근법을 통해 기술의 메커니즘과 개념에 대한 이해력을 높일 수 있습니다.

- **Performance Highlights**: 이 접근법은 기존의 비디오 학습 도구가 가지고 있는 한계를 극복하는 데 초점을 맞추고 있으며, 텍스트 코퍼스에서 답을 검색하는 기존 생성 AI 방법이 참된 이해력을 보여주는지 여부에 대한 한계를 극복하려고 합니다.



### Semantic Communication Enhanced by Knowledge Graph Representation Learning (https://arxiv.org/abs/2407.19338)
Comments:
          Accepted for publication at the 25th IEEE International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)

- **What's New**: 이 논문은 새로운 의미 통신(semantic communications) 패러다임에서 의미적 지식을 그래프로 표현하고 처리하는 이점에 대해 연구합니다. 제안된 접근 방식은 의미적 및 실용적 측면을 활용하며, 대형 언어 모델(LLMs)을 사용하여 지식을 컴팩트하게 표현하고 지능형 에이전트 간에 교환하는 방법을 제공합니다.

- **Technical Details**: 이 논문은 LLMs와 그래프 신경망(Graph Neural Networks, GNNs)을 사용하여 의미적 인코더(semantic encoder)를 구성합니다. 전송되는 정보는 수신자에게 의미 있는 형태로 선택되며, 이 유도된 임베딩 벡터(embedding vector)는 '노드(semantic concepts entities)', '엣지(relations between concepts)', '노드'의 삼중입체(triplet) 형식을 가집니다. 따라서 의미적 정보는 의미 개념 추상 공간에서 요소들 간의 관계를 표현합니다.

- **Performance Highlights**: 실험적 시뮬레이션을 통해 지식 그래프를 활용하여 정보를 의미적으로 압축하고 전송하는 방법의 효과성을 보여줍니다. 무선 채널을 통해 노드 임베딩과 동등한 의미적 심볼만 전송하고, 수신 측에서 완전한 지식 그래프를 추론하는 방식을 제안합니다.



### A Semi-supervised Fake News Detection using Sentiment Encoding and LSTM with Self-Attention (https://arxiv.org/abs/2407.19332)
- **What's New**: 이 논문에서는 부분 지도 학습(semi-supervised learning)을 사용하여 소수의 레이블된 데이터만으로도 가짜 뉴스를 효과적으로 감지할 수 있는 방법을 제안합니다. 기존의 방법들이 대규모의 수작업으로 레이블된 데이터를 필요로 하는 데 반해, 본 연구는 최소한의 라벨 데이터로도 효과적인 탐지가 가능함을 보여줍니다.

- **Technical Details**: 제안된 방법은 최신의 사전 학습된 모델(pretrained models)을 활용한 감정 분석(sentiment analysis)을 포함합니다. 모델은 LSTM(Long Short-Term Memory) 및 자기 주의(self-attention) 레이어를 결합하여 부분 지도 학습 방식으로 학습됩니다. 이를 통해 모델이 가짜 뉴스를 더 정확하게 탐지할 수 있도록 합니다.

- **Performance Highlights**: 제안된 모델은 20,000개의 뉴스 콘텐츠와 그에 대한 피드백을 포함한 데이터셋을 기준으로 벤치마크되었습니다. 이를 통해 정밀도(precision), 재현율(recall) 등의 성능 지표에서 경쟁 방법들보다 우수한 성능을 보였습니다.



### Multi-Modal CLIP-Informed Protein Editing (https://arxiv.org/abs/2407.19296)
Comments:
          13 pages, 7 figures, 5 tables

- **What's New**: 새로운 단백질 편집 방법인 ProtET를 소개합니다. ProtET는 효율적인 CLIP-informed 단백질 편집을 multi-modality learning을 통해 달성합니다. ProtET는 단백질-바이오텍스트(protein-biotext) 표현을 대비 학습(contrastive learning)으로 정렬한 후, 편집 지시 텍스트와 원래 단백질 서열을 기반으로 목표 단백질 서열을 생성합니다.

- **Technical Details**: ProtET는 두 단계로 구성됩니다. 첫 번째 단계는 대비 학습(contrastive learning)으로 두 개의 대형 언어 모델(LLMs)을 사용해 단백질-바이오텍스트 표현을 정렬합니다. 두 번째 단계에서는 편집 지시 텍스트와 원래 단백질 서열의 융합된 특징이 최종 편집 조건으로 사용되어 목표 단백질 서열을 생성합니다.

- **Performance Highlights**: 다양한 속성 영역에서 ProtET의 뛰어난 성능이 입증되었습니다. 이는 인간이 기대하는 기능 향상, 효소 촉매 활성, 단백질 안정성, 항체 특이 결합 능력 등을 포함합니다. ProtET는 상태 최첨단 성능(state-of-the-art results)을 큰 폭으로 개선하여, 단백질 안정성을 16.67%와 16.90%로 크게 향상시켰습니다. 이는 ProtET가 학문적, 산업적 및 임상적 요구를 해결하는데 중요한 역할을 할 수 있음을 시사합니다.



### Large Language Models for Human-like Autonomous Driving: A Survey (https://arxiv.org/abs/2407.19280)
Comments:
          8 pages, 2 figures, accepted at IEEE Intelligent Transportation Systems Conference (ITSC) 2024

- **What's New**: 대형 언어 모델 (LLMs)과 자율 주행 (AD) 분야의 결합이 새로운 전환점을 맞이하고 있습니다. 이 논문에서는 AD 시스템이 규칙 기반 및 최적화 기반 방법에서 학습 기반 기술로, 특히 심층 강화 학습 (Deep Reinforcement Learning)으로 발전하여, 이제는 LLMs를 통해 보다 인간과 유사한 AD를 구현할 수 있는 새로운 차원으로 나아감을 논의합니다.

- **Technical Details**: 이 설문조사는 LLMs의 주요 특징과 일반적인 훈련 체계에 대해 소개한 후, 모듈형 AD 파이프라인과 End-to-End AD 시스템에서의 응용을 중점적으로 다룹니다. 논문은 특히 실시간 추론, 안전성 보증, 배치 비용 등 LLMs를 AD 시스템에 통합하는 데 따르는 도전 과제를 강조합니다. 또한 이러한 도전 과제를 해결할 수 있는 연구 방향을 제안합니다.

- **Performance Highlights**: LLMs를 활용한 AD 시스템의 주요 발전 사항을 다루고, 현재 시급한 도전 과제들을 식별합니다. 이를 통해 연구자와 실무자에게 통찰력과 영감을 제공하여 더 안전하고 똑똑하며 인간 중심적인 AD 기술 개발에 기여하고자 합니다.



### Interactive Learning in Computer Science Education Supported by a Discord Chatbo (https://arxiv.org/abs/2407.19266)
Comments:
          Revised and accepted paper at the IEEE German Education Conference 2024 (GECon 2024) and to be published in IEEE proceedings

- **What's New**: 첫 학기 컴퓨터 과학 강좌에서 학생들의 상호작용과 피드백 수집을 개선하기 위해, Discord 커뮤니케이션 서버에 명령어 기반의 채팅봇(DiscordBot)을 통합했습니다. 이 기술적 개선을 통해 학생들은 과제, 퀴즈, 강의에 대한 피드백을 짧은 설문을 통해 제공할 수 있게 되었습니다.

- **Technical Details**: DiscordBot은 주로 피드백 수집, 출석 체크, 강의 시작 전 안내 등의 기능을 수행합니다. 이를 통해 학생들은 스트레스 없이 강사들과 소통할 수 있으며, 실시간 피드백을 반영하여 강사들이 다음 활동의 난이도를 조정하고 학습 세션에서 논의를 촉진할 수 있습니다. 이러한 데이터는 전통적인 학기 말 설문조사를 통해 얻을 수 없는 인사이트를 제공합니다.

- **Performance Highlights**: DiscordBot과의 상호작용이 용이하다고 학생들이 보고했으며, 향후 학기에서도 이를 계속 사용하고자 하는 의사를 나타냈습니다. 이와 같은 상호작용적 접근은 학생들의 학습 경험을 향상시키는 데 크게 기여할 것으로 보입니다. 또한 학생들이 활동의 난이도와 기대 결과를 정확하게 인식할 수 있게 되었습니다.



### Stochastic Parrots or ICU Experts? Large Language Models in Critical Care Medicine: A Scoping Review (https://arxiv.org/abs/2407.19256)
Comments:
          28 pages, 5 figures

- **What's New**: 인공지능(AI)의 급속한 발전과 함께 대규모 언어 모델(LLMs)은 자연 언어 이해, 추론, 생성에서 강력한 능력을 보여주고 있습니다. 본 점검 리뷰(Scoping Review)는 중환자 치료 의학(CCM)에서 LLMs의 적용을 탐구합니다. 2019년 1월 1일부터 2024년 6월 10일까지 PubMed, Embase, Scopus, Web of Science, CINAHL, IEEE Xplore 및 ACM Digital Library의 7개 데이터베이스를 통해 문헌을 검색하였으며, 619개의 초기 논문 중 24편이 최종 리뷰를 위해 선택되었습니다.

- **Technical Details**: 이번 리뷰는 LLMs가 중환자 치료 의학에서 어떻게 사용되는지를 임상 결정 지원(Clinical Decision Support), 의료 문서화 및 보고(Medical Documentation and Reporting), 의료 교육 및 의사-환자 커뮤니케이션(Medical Education and Doctor-Patient Communication)의 세 가지 범주로 나누어 설명합니다. LLMs는 비구조화 데이터(Unstructured Data)를 처리하는 데 유리하며, 수작업 피처 엔지니어링(Manual Feature Engineering)이 필요하지 않습니다. 하지만 환각(Hallucinations), 해석 불가능성(Poor Interpretability), 편향 및 정렬 문제(Bias and Alignment Challenges), 프라이버시 및 윤리적 문제(Privacy and Ethics Issues) 등 여러 도전에 직면해 있습니다.

- **Performance Highlights**: LLMs의 잠재력은 CCM에서 환자 결과를 향상시키고 의료 서비스를 최적화하는 중요한 도구로 작용할 수 있습니다. 하지만 모델 신뢰성 및 해석 가능성을 향상시키고 최신 의학 지식을 통합하며 프라이버시 및 윤리적 지침을 강화하는 것이 미래 연구의 과제로 남아 있습니다. 이 연구는 연구자, 임상의 및 정책결정자들에게 중환자 치료 분야에서 LLMs의 현재 상태와 미래 가능성을 이해하는 데 도움을 줍니다.



### Mamba-UIE: Enhancing Underwater Images with Physical Model Constrain (https://arxiv.org/abs/2407.19248)
- **What's New**: 이번 연구에서는 물속 이미지 향상(Underwater Image Enhancement, UIE)을 위해 Mamba-UIE라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 물리적 모델 제약(physical model constraint)을 기반으로 하여 입력 이미지를 네 가지 구성 요소—수중 장면 복사도(underwater scene radiance), 직접 전달 맵(direct transmission map), 산란 전달 맵(backscatter transmission map), 전반적 배경 조명(global background light)—로 분해합니다.

- **Technical Details**: 제안된 Mamba-UIE 네트워크는 선형 복잡성 상태 공간 모델(Linear Complexity State Space Models, SSM)을 기반으로 설계되었습니다. 이는 트랜스포머(Transformers)가 긴 시퀀스를 처리할 때 발생하는 이차적인 계산 복잡성을 해결합니다. Mamba in Convolution 블록을 도입하여 채널 및 공간 수준의 장거리 의존성을 모델링하면서도 CNN 백본(backbone)을 유지해 로컬 특징과 디테일을 복구합니다. 재구성된 이미지와 원본 이미지 사이의 일관성 제약을 적용함으로써 물리적 제약을 충족시키는 방법론도 포함됩니다.

- **Performance Highlights**: 세 개의 공개 데이터셋에서 광범위한 실험을 수행한 결과, 제안된 Mamba-UIE는 PSNR 27.13 및 SSIM 0.93의 성능을 기록하며 기존 최첨단 방법들보다 우수한 성능을 보였습니다. 특히 UIEB 데이터셋에서 매우 높은 성능을 나타냈습니다.



### Greedy Output Approximation: Towards Efficient Structured Pruning for LLMs Without Retraining (https://arxiv.org/abs/2407.19126)
- **What's New**: 이번 연구는 대형 언어 모델(LLMs)의 불필요한 부분을 제거하여, 특히 재훈련(retraining) 단계를 거치지 않고, 단발성 신경망 가지치기(single-shot pruning) 방법을 제안합니다. Transformer 기반의 LLMs를 보다 간단하게 가지치기(pruning)할 수 있도록 독립적으로 기능하는 depth-2 가지치기 구조를 도입했습니다. 또한 출력 근사(output approximation) 최적화 관점에서 파생된 두 가지 추론 인식 가지치기(inference-aware pruning) 기준을 제안하여, 전통적인 gradient와 Hessian과 같은 훈련 인식(training-aware) 메트릭을 능가합니다.

- **Technical Details**: 제안된 방법은 재훈련 없이 가지치기 오류를 완화하기 위해 두 단계 재구성(two-step reconstruction) 기술을 도입합니다. 이는 더 간단하고 비용 효율적인 방식으로 LLMs를 가지치기할 수 있도록 합니다. 또한, 제안된 추론 인식 가지치기 기준은 출력 근사 최적화 관점에서 유도된 방법으로, 기존의 훈련 인식 메트릭보다 뛰어난 성능을 보입니다.

- **Performance Highlights**: 실험 결과, 본 접근 방식은 다양한 데이터셋과 모델에서 우수한 성능을 유지하면서도 컴퓨팅 비용 및 하드웨어 요구사항을 크게 줄이는 것으로 나타났습니다.



### Large Language Models as Co-Pilots for Causal Inference in Medical Studies (https://arxiv.org/abs/2407.19118)
- **What's New**: 이번 연구에서는 대형 언어 모델(Large Language Models, LLMs)이 연구자들을 보조하여 연구 설계 결함을 식별할 수 있는 '원인 분석 보조 도구'(causal co-pilot)로서의 역할을 탐구합니다. 특히 실세계 임상 데이터에 기반한 관찰 연구에서 발생하는 잔여 교란(residual confounding), 선택 편향(selection bias), 치료와 측정 시점 불일치 등의 문제를 파악하는 데 중점을 둡니다.

- **Technical Details**: 이 논문에서는 다양한 분야의 도메인 지식을 인코딩하여 연구자와 자연어로 상호작용하면서 연구 설계에 문맥화된 도움을 제공하는 LLMs의 개념적 프레임워크를 제안합니다. 또한, 기존의 인과 추론(causal inference) 프레임워크에 LLMs를 접목시키는 구조적 프레임워크를 제안하고, 이를 검증하기 위한 예시를 제공합니다.

- **Performance Highlights**: 논문에서는 LLMs가 연구 설계의 결함을 식별하는 데 있어 직관적이고 전문적인 도움을 제공할 수 있다는 것을 강조합니다. 특히 역학 연구(epidemiological research)에 LLMs를 적용하여 신뢰할 수 있는 결과를 도출하기 위한 독특한 도전과 기회들을 밝힙니다.



### GPT Deciphering Fedspeak: Quantifying Dissent Among Hawks and Doves (https://arxiv.org/abs/2407.19110)
- **What's New**: 이 새 논문은 Federal Open Market Committee (FOMC)의 통화 정책 결정에서 발생하는 구성원들 간의 불일치를 측정하기 위해 GPT-4를 사용했습니다. 이를 통해 FOMC 회의록과 회의의 텍스트 기록이 구성원들의 경제 전망에 대한 다양한 시각을 반영하지만, 공공에 발표된 최종 성명서에서는 이러한 의견 차이가 거의 드러나지 않음을 발견했습니다.

- **Technical Details**: 연구진은 인플레이션 주제에 대한 구성원들 간의 의견 불일치를 정량화하기 위해 OpenAI의 최신 언어 모델인 GPT-4를 활용했습니다. FOMC 회의록과 의사록(transcripts and minutes)을 분석하여 매크로 경제 전망에 대한 다양한 시각을 탐색하였고, 최종 성명서에서 이 같은 의견 차이가 거의 누락되거나 생략됨을 밝혀냈습니다.

- **Performance Highlights**: 이 연구는 FOMC의 성명서만을 기반으로 미래의 통화 정책을 예측할 경우, 매파(hawks)와 비둘기파(doves) 사이의 의견 불일치(dissent)를 충분히 반영하지 못할 것이라는 것을 보여줍니다. 따라서, 더욱 정밀한 예측을 위해서는 더 넓은 텍스트 자료를 분석하는 접근이 필요함을 시사합니다.



### Solving Robotics Problems in Zero-Shot with Vision-Language Models (https://arxiv.org/abs/2407.19094)
Comments:
          aka Wonderful Team

- **What's New**: Wonderful Team는 새로운 환경에서 이미지를 입력받아 로봇이 작업을 수행하는 데 필요한 일련의 동작을 출력하는 멀티에이전트 시각 언어 모델 프레임워크(Wonderful Team, a multi-agent visual LLM framework)를 소개합니다. 이전 연구와 달리, 이 프레임워크는 파인 튜닝(fine-tuning) 없이도 로봇 작업을 수행할 수 있습니다.

- **Technical Details**: 이 연구는 VLLM(Vision Language Model)의 진보된 성능을 기반으로, 단일 오프더쉘프 VLLM을 활용하여 로봇 작업의 고수준 계획부터 저수준 위치 추출 및 동작 실행까지 모두 처리할 수 있음을 보여줍니다. Wonderful Team은 멀티에이전트 LLM의 최근 발전을 이용하여 작업을 에이전트 계층(hierarchy) 내에서 분할하여 장기적인 작업도 효과적으로 처리할 수 있습니다.

- **Performance Highlights**: VIMABench 및 실제 로봇 환경에서의 실험을 통해 조작(manipulation), 시각 목표 달성(visual goal-reaching), 시각적 추론(visual reasoning) 등 다양한 로봇 작업을 제로샷(zero-shot)으로 처리할 수 있는 시스템의 성능을 입증했습니다. 이 결과는 향후 로봇 문제의 기본(backbone)으로서 시각 언어 모델이 강력하게 고려되어야 함을 강조합니다.



### Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models (https://arxiv.org/abs/2407.19041)
Comments:
          The paper has been accepted by the 33rd ACM International Conference on Information and Knowledge Management (CIKM) in 2024

- **What's New**: 법률 분야에서의 변혁: 딥러닝과 대형 언어 모델(LLMs)의 진보가 법률 작용에 혁신을 불러오고 있습니다. 연구자는 LLMs의 수학적 추론 능력을 활용한 새로운 접근법을 제안하였습니다. 이 접근법은 특수하게 설계된 프롬프트를 사용하여 법률 인공지능(LegalAI) 응용 프로그램의 정밀 요구사항을 충족시키도록 설계되었습니다. 이를 통해 전통적인 법률 관행과 현대 기술의 격차를 해소하고, 더 접근 가능한, 효율적이며 공평한 법률 시스템을 마련하고자 합니다.

- **Technical Details**: 이 제안된 접근법은 LLMs(대형 언어 모델)의 수학적 추론을 활용하여 정밀한 법률 인공지능 응용 프로그램의 요구사항을 충족시키는 것입니다. 연구자는 정밀 지향 LegalAI 작업을 평가할 수 있는 벤치마크로서 맞춤형 데이터셋을 도입하였으며, 이 데이터셋을 통해 LLM 기반 접근법의 유효성을 검증하기 위해 광범위한 실험을 수행하였습니다. 또한, 특수한 프롬프트를 사용하여 법적 정보를 정확하게 생성하고 분석하는 방법을 사용합니다.

- **Performance Highlights**: 광범위한 실험 결과, 제안된 방법이 법률 영역에서 정확한 숫자 추정치를 생성하는 데 효과적임을 확인할 수 있었습니다. 이는 LLMs가 법률 절차를 효율화하고 LegalAI의 발전하는 요구를 충족시키는 데 중요한 역할을 할 수 있음을 시사합니다.



### A Fault Prognostic System for the Turbine Guide Bearings of a Hydropower Plant Using Long-Short Term Memory (LSTM) (https://arxiv.org/abs/2407.19040)
Comments:
          8 figures, 3 tables

- **What's New**: 본 논문은 수력 발전소(Hydropower Plants, HPPs)의 터빈 베어링에 대한 인공지능 고장 예측 시스템을 개발하는 연구를 다루고 있습니다. 기존의 반응적 접근 방법에서 벗어나 더 지능적인 예측 접근 방법으로의 전환을 목표로 합니다.

- **Technical Details**: 이 연구에서는 Long Short-Term Memory (LSTM) 알고리즘을 활용하여 모델을 개발했습니다. 초기에는 테스트 장치에서 수집한 베어링 진동 데이터를 이용해 모델을 학습 및 테스트했으며, 이후 파키스탄의 실제 수력 발전소에서 Supervisory Control and Data Acquisition (SCADA) 시스템을 통해 수집한 현실적인 베어링 진동 데이터를 이용해 추가 학습 및 테스트를 진행했습니다.

- **Performance Highlights**: 제안된 모델은 베어링 진동 값을 매우 정확하게 예측하여, 매우 낮은 Root Mean Square Error (RMSE)를 달성하였습니다.



### Artificial neural networks on graded vector spaces (https://arxiv.org/abs/2407.19031)
- **What's New**: 새로운 인공 신경망 모델이 개발되었습니다. 이 모델들은 데이터 내의 서로 다른 특징들이 서로 다른 중요성(가중치)을 가질 때 적합한 모델입니다. 이는 처음으로 수학적으로 설계된 모델로서, 모든 등급이 1인 일반적인 벡터 공간에서의 신경망보다 더 나은 성능을 기대할 수 있습니다.

- **Technical Details**: 이 연구는 등급(graded vector spaces)을 가진 벡터 공간에 적합한 신경망 모델을 소개합니다. 각 특징에 대해 다른 가중치를 부여함으로써, 데이터의 다양한 중요성을 반영할 수 있습니다. 기존의 신경망 모델은 모든 특징이 동일하게 취급되는 일반적인 벡터 공간을 기반으로 하지만, 이번 연구에서는 그것을 확장하여 유연성을 증가시켰습니다.

- **Performance Highlights**: 새로 제안된 모델은 전통적인 벡터 공간 기반 신경망 모델보다 나은 성능을 보일 것으로 기대됩니다. 이는 각 특징의 중요성을 더 정확히 반영함으로써 얻어지는 개선된 성능을 의미합니다.



### Towards a Cyber Information Ontology (https://arxiv.org/abs/2407.18998)
Comments:
          14

- **What's New**: 이 논문은 사이버 온톨로지(cyber ontologies, 예: 파일 시스템 온톨로지와 데이터 융합 온톨로지)를 상위 및 중간 수준의 온톨로지와 연결하는 인터페이스 역할을 하는 일련의 용어를 소개합니다. 구체적으로는 Basic Formal Ontology와 Common Core Ontologies를 대상으로 합니다.

- **Technical Details**: 새로운 용어들은 사이버 정보 관리의 고유한 특징인 정보 항목의 여러 번 복제, 그러한 복제 행위로 인해 생성되는 복제 집합(aggregates of copies), 그리고 이 집합의 모든 구성원을 대표하는 신뢰도 높은 구성원들(faithful members)을 중심으로 구성됩니다.

- **Performance Highlights**: 이 논문은 사이버 정보 관리의 복제 행위 및 결과물에 대한 이해를 높이고, 이를 통해 관련 온톨로지 간의 상호 운용성을 개선하는 데 기여할 수 있는 새로운 용어들을 제안합니다.



### A maturity framework for data driven maintenanc (https://arxiv.org/abs/2407.18996)
Comments:
          in Proceedings of the 8th European Conference of the Prognostics and Health Management Society 2024

- **What's New**: 이 논문은 데이터 기반 유지 보수(Data-driven maintenance)에서 만나는 여러 과제들을 탐구하고, 성숙 프레임워크(Maturity Framework)를 통해 네 가지 측면을 고려할 것을 제안합니다. 이 네 가지 측면은 데이터/의사결정 성숙도(Data/Decision Maturity), 실제 세계에서 데이터로의 변환, 의사결정의 계산 가능성(Computability) 및 관계에서 얻어진 인과성(Causality)입니다.

- **Technical Details**: 논문에서는 이론적 개념들을 논의한 후, 결함 감지 및 식별(Fault Detection and Identification) 문제를 실제로 어떻게 접근할 수 있는지 탐구합니다. 경험 기반(Experience-based) 접근법과 모델 기반(Model-based) 접근법을 이 성숙 프레임워크의 네 가지 측면에서 비교하고 논의합니다. 두 접근법 모두 동일한 결정을 도출하지만, 인과성의 할당에서는 차이가 난다는 점을 확인했습니다.

- **Performance Highlights**: 두 접근법의 결과는 동일한 결정을 도출하였으나, 인과성 할당(Causality Assignment)에서 차이가 존재함을 확인할 수 있었습니다. 이는 성숙도 평가는 단순히 의사결정의 유형을 넘어 제안된 다른 측면들도 포함해야 한다는 것을 나타냅니다.



### Online Test Synthesis From Requirements: Enhancing Reinforcement Learning with Game Theory (https://arxiv.org/abs/2407.18994)
- **What's New**: 이 논문에서는 반응형 구현에 대해 오토마타(automata)로 지정된 기능 요구 사항에서 블랙박스 테스트 케이스를 자동으로 온라인으로 생성하는 방법을 다룹니다. 테스트 목적은 상태 커버리지 기준을 충족하도록 특정 상태에 도달하는 것이며, 동시에 요구 사항 위반을 모니터링하는 것입니다.

- **Technical Details**: 저자들은 강화 학습(reinforcement learning)에서 효율적으로 유망한 입력을 선택하는 전통적인 기법인 몬테카를로 트리 탐색(Monte Carlo Tree Search, MCTS)을 기반으로 접근 방식을 개발했습니다. 오토마타 요구 사항을 구현과 테스터 간의 게임으로 보고, 이 게임에서 유망한 입력으로 검색을 편향시키는 휴리스틱(heuristic)을 개발했습니다.

- **Performance Highlights**: 실험을 통해 휴리스틱이 몬테카를로 트리 탐색 알고리듬(MCTS)의 수렴 속도를 가속화하여 테스트 성능을 향상시킨다는 것을 보여주었습니다.



### Towards Automated Solution Recipe Generation for Industrial Asset Management with LLM (https://arxiv.org/abs/2407.18992)
- **What's New**: 본 연구는 대형 언어 모델(Large Language Models, LLMs)을 활용하여 조건 기반 관리(Conditional-Based Management, CBM)의 원칙을 적용한 새로운 산업 자산 관리(Industrial Asset Management, IAM) 접근법을 소개합니다. 연구는 데이터 과학자들과 도메인 전문가들 간의 집중적인 협업에 의존하는 기존의 모델 구축 프로세스를 자동화하는 방법론을 제안합니다.

- **Technical Details**: 주요 혁신 두 가지를 소개합니다: 첫째, 분류법 기반의 프로밍 생성을 통해 AI 솔루션 레시피를 자동으로 생성하고, 둘째, 문서, 샘플 데이터, 모델로 구성된 일련의 산출물을 포함하는 솔루션 레시피를 생성하는 LLM 파이프라인 세트를 제시합니다. 이 파이프라인들은 표준 원칙에 따라 이끌어지며, 초기 솔루션 템플릿을 인간의 직접적인 입력 없이 이종 자산 클래스에 대해 생성할 수 있습니다. 이는 광범위한 도메인 지식의 의존도를 줄이고 자동화를 향상시킵니다.

- **Performance Highlights**: 연구는 10개의 다양한 자산 클래스에 걸쳐 자산의 건강과 지속 가능성을 평가함으로써 우리의 방법론을 평가합니다. 연구 결과는 LLM과 분류법 기반의 LLM 프로밍 파이프라인이 자산 관리를 변화시키는 잠재력을 지니고 있음을 보여줍니다. 이는 신속한 클라이언트 솔루션에 통합될 후속 연구 및 개발 이니셔티브를 위한 청사진을 제공합니다.



### Intelligence Analysis of Language Models (https://arxiv.org/abs/2407.18968)
- **What's New**: 이 프로젝트에서는 대형 언어 모델(LLMs)의 추상적 추론 능력을 시험하기 위해 Abstraction and Reasoning Corpus (ARC) 데이터셋을 사용했습니다. 이는 객체 식별, 기본 셈하기, 기초적인 기하학 원칙과 같은 핵심 개념을 이해하는 것을 요구하는 대표적 벤치마크입니다.

- **Technical Details**: ARC 데이터셋의 작업들을 프롬프트 기반(프롬프트-based) 형식으로 변환하여 모델을 평가했습니다. 초기에는 제로샷(Zero-shot) 접근법을 통해 모델의 잠재력을 평가했으며, 이후 체인 오브 사고(Chain-of-Thought, CoT) 기법의 적용을 조사하여 모델 성능 향상을 검토했습니다.

- **Performance Highlights**: 결과적으로, 현대의 대형 언어 모델(LLMs)에 대한 높은 기대에도 불구하고, 이러한 모델들이 비교적 간단한 ARC 데이터셋 하위 집합에서도 비언어적 도메인에서 여전히 고전을 겪고 있다는 것을 발견했습니다. 이 연구는 이러한 맥락에서 오픈 소스 모델의 역량을 집중적으로 조사한 첫 번째 연구입니다.



### Generative AI Augmented Induction-based Formal Verification (https://arxiv.org/abs/2407.18965)
Comments:
          To appear at the 37th IEEE International System-on-Chip Conference, Sep 16-19 2024, Dresden, Germany

- **What's New**: Generative Artificial Intelligence (GenAI) 기술이 현재 세계에서 인간의 노력을 크게 줄이는 데 보여주고 있습니다. 이 논문은 GenAI가 끼치는 영향과 한계를 탐구하면서, 특히 유도 기반 형식 검증(induction-based formal verification)에 대해 연구합니다.

- **Technical Details**: GenAI는 딥러닝(deep learning) 기술을 활용하여 텍스트, 이미지, 코드, 음악 및 비디오와 같은 원본 및 현실적 콘텐츠를 생성합니다. 현대의 대형 언어 모델(Large Language Models, LLMs)은 이러한 GenAI 모델에 사용되며 하드웨어 개발을 지원하는 데 도움이 될 수 있습니다. 형식 검증(formal verification)은 설계의 정확성을 철저히 검증하기 위해 수학 기반의 증명 방법을 이용합니다.

- **Performance Highlights**: 이 논문에서는 GenAI가 유도 기반 형식 검증의 검증 처리량을 증가시키는 데 어떻게 사용될 수 있는지를 실증적으로 보여줍니다.



### MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains (https://arxiv.org/abs/2407.18961)
- **What's New**: 최근 대형 언어 모델(Large Language Models, LLMs)의 발전으로 인해 인간과 유사한 에이전트로서 모델의 능력을 평가하기 위한 종합적인 벤치마크에 대한 수요가 증가하고 있습니다. 기존 벤치마크는 특정 응용 시나리오에 초점을 맞추어 작업 완료를 강조하지만, 결과를 이끌어내는 기본 기술을 세세하게 분석하지 못하는 경우가 많습니다. 이러한 문제점을 해결하기 위해 Massive Multitask Agent Understanding (MMAU) 벤치마크를 소개합니다.

- **Technical Details**: MMAU 벤치마크는 복잡한 환경 설정이 필요 없는 종합적인 오프라인 작업을 특징으로 합니다. 이 벤치마크는 Tool-use, Directed Acyclic Graph (DAG) QA, Data Science and Machine Learning coding, Contest-level programming, Mathematics의 다섯 가지 분야와 Understanding, Reasoning, Planning, Problem-solving, Self-correction의 다섯 가지 필수 능력을 평가합니다. 총 20개의 세심하게 설계된 작업을 포함하며, 3,000개 이상의 다양한 프롬프트를 다룹니다.

- **Performance Highlights**: MMAU를 통해 18개의 대표 모델을 테스트하여 심도 있는 분석을 제공합니다. 이 벤치마크는 LLM 에이전트의 능력과 한계를 조명할 뿐만 아니라, 그들의 성과에 대한 해석 가능성을 향상시킵니다. MMAU의 데이터셋과 평가 스크립트는 공개되어 있습니다.



### Unexplainability of Artificial Intelligence Judgments in Kant's Perspectiv (https://arxiv.org/abs/2407.18950)
Comments:
          9 pages, 3 figures

- **What's New**: 칸트의 순수 이성 비판에서 제시된 인간 판단의 선험적 구조를 인공지능(AI)도 구현할 수 있는지에 대한 평가가 필요하다. 본 논문에서는 AI 판단이 칸트의 인간 판단 특성으로 해석할 수 없는 형식을 보인다고 주장한다.

- **Technical Details**: AI 판단은 칸트가 설명한 인간 판단의 특성과 중복되지 않는 불확실성을 나타낸다. 그 결과, 물리적 직관 없이 개념을 해석하는 것이 쉽지 않으며, 비전(vision)을 통해 그 기능을 보여도 이해가 어렵다. 또한, AI가 자연어(Natural Language)에서 주어(subject)와 술어(predicate)를 사용해 문장을 만들더라도 그것이 인간이 수용할 수 있는 수준의 개념 이해를 제공하는지는 판단하기 어렵다.

- **Performance Highlights**: 자연어를 통한 AI의 설명은 신뢰할 수 있는지 의문이 제기된다. AI가 판단을 구성하는 요소들을 만들 수는 있지만, 그것이 인간과 같은 수준의 개념 이해로 이어지지는 않는다는 점이 강조된다.



### Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing (https://arxiv.org/abs/2407.20232)
- **What's New**: 텍스트 기반 편집(diffusion) 모델들이 사용자의 입력 지시가 모호할 때 성능이 제한적이라는 문제를 해결하기 위해 'Specify ANd Edit'(SANE)이라는 무스펙 추론 파이프라인을 제안했습니다. SANE는 대형 언어 모델(LLM)을 사용해 입력 지시를 구체적인 지시로 분해한 후, 새로운 디노이징(denoising) 가이드 전략을 통해 이를 입력 이미지에 적용합니다.

- **Technical Details**: SANE는 LLM을 활용해 사용자의 모호한 지시를 구체적으로 분해합니다. 이를 위해 저자들은 입력 이미지에 적용할 명확한 개입을 도출합니다. SANE 전략의 핵심은 신속한 지시 분해와 그 개선된 디노이징 가이드 접근 방식 덕분에 높은 해석 가능성과 다양한 출력 결과를 얻는 것입니다. 실험은 세 가지 기본 설정과 두 개의 데이터세트에서 수행되었습니다.

- **Performance Highlights**: SANE는 기존의 모든 구성에서 이점을 보였으며, 편집 모델의 해석 가능성을 높이는 동시에 출력의 다양성을 크게 증진했습니다. 또한, 모호한 지시뿐만 아니라 명확한 지시에도 이 접근법이 적용될 수 있음을 보였습니다. 코드와 구체적 구현은 공개되어 있습니다.



### SAPG: Split and Aggregate Policy Gradients (https://arxiv.org/abs/2407.20230)
Comments:
          In ICML 2024 (Oral). Website at this https URL

- **What's New**: 본 논문에서는 현재 강화 학습(Reinforcement Learning, RL) 방법, 특히 PPO가 병렬화된 환경의 이점을 제대로 활용하지 못하고 성능이 포화된다는 문제를 지적합니다. 이를 해결하기 위해 새로운 온-정책 강화 학습 알고리즘인 SAPG를 제안합니다. SAPG는 대규모 환경을 효과적으로 활용할 수 있으며, 환경을 여러 개의 청크로 나눈 후 중요도 샘플링(importance sampling)을 통해 다시 합칩니다.

- **Technical Details**: SAPG는 기존의 온-정책 RL 알고리즘이 특정 포인트 이후 병렬화 환경에서 이점을 충분히 활용하지 못하는 문제를 개선합니다. 이를 위해 SAPG 알고리즘은 대규모 환경을 청크로 나눈 다음, 중요도 샘플링을 사용하여 이 청크들을 다시 합칩니다. 이 과정은 GPU 기반 시뮬레이션의 장점을 극대화하고, 대량의 데이터를 효과적으로 사용할 수 있게 합니다.

- **Performance Highlights**: SAPG는 다양한 도전적인 환경에서 기존의 PPO와 다른 강력한 기준선 알고리즘이 높은 성능을 달성하지 못하는 상황에서도 우수한 성능을 보였습니다. 대규모 환경을 활용할 수 있는 능력이 뛰어나기 때문에, SAPG는 학습 속도와 최종 성능 면에서 현저한 향상을 보였습니다.



### SANGRIA: Surgical Video Scene Graph Optimization for Surgical Workflow Prediction (https://arxiv.org/abs/2407.20214)
Comments:
          9 pages, 3 figures, 3 tables, MICCAI GRAIL Workshop paper

- **What's New**: 새로운 연구에서는 수술 장면 그래프 (surgical scene graph)를 생성하고 최적화할 수 있는 엔드 투 엔드 프레임워크를 소개합니다. 이는 수술 워크플로우 (surgical workflow) 인식을 위해 그래프 기반의 전체적인 장면 표현 (holistic scene representations)을 사용하는 방법입니다.

- **Technical Details**: 제안된 접근법은 그래프 기반 분광 클러스터링 (graph-based spectral clustering)의 유연성과 파운데이션 모델 (foundation models)의 일반화 능력을 활용하여 비지도 학습 (unsupervised learning)으로 학습 가능한 속성을 가진 장면 그래프를 생성합니다. 초기 공간 그래프 (spatial graph)는 연속적인 프레임 간의 로컬 매치를 사용한 희소한 시간적 연결 (sparse temporal connections)로 보강됩니다. 동적 장면 그래프의 시공간 관계 (spatiotemporal relations)와 노드 특성 (node features)을 공동 최적화하여 단순한 약한 수술 단계 레이블 (weak surgical phase labels)을 사용해 의미론적 장면 이해 (semantic scene comprehension)와 장면 그래프 생성을 수행합니다.

- **Performance Highlights**: 효과적인 중간 장면 표현 분리 단계를 파이프라인 내에 포함시켜, CATARACTS 데이터셋 (CATARACTS dataset)에서 수술 워크플로우 인식 정확도를 8% 개선하고, F1 점수를 10% 향상시켰습니다.



### QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieva (https://arxiv.org/abs/2407.20207)
- **What's New**: Dense retrieval에서 장문 텍스트를 dense 벡터(dense vectors)로 임베딩하면 정보 손실이 발생하고, 이에 따라 쿼리-텍스트 매칭의 정확도가 떨어질 수 있습니다. 또한, 저질 텍스트는 과도한 노이즈나 희박한 주요 정보를 가지고 있는 경우가 많아 관련 쿼리와 잘 맞지 않습니다. 기존 연구들은 주로 문장 임베딩 모델(sentence embedding model)이나 검색 프로세스를 개선하는 데 초점을 맞추고 있습니다. 이에 반해, 본 연구는 dense retrieval을 위한 새로운 텍스트 증강 프레임워크를 소개합니다. 이 프레임워크는 원본 텍스트를 정보 밀도가 높은 텍스트 형식으로 변환하여, 임베딩이나 검색 방법론 자체를 수정하지 않고 앞서 언급한 문제를 효과적으로 해결합니다.

- **Technical Details**: 본 연구의 프레임워크는 대형 언어 모델(LLMs)으로부터 zero-shot(prompting) 방법을 통해 두 가지 텍스트 표현을 생성합니다: 질문-응답 쌍(question-answer pairs)과 요소 기반 이벤트(element-driven events). 이를 QAEA-DR로 명명하며, 텍스트 증강 프레임워크 내에서 질문-응답 생성 및 이벤트 추출을 통합합니다. 생성된 텍스트의 품질을 더욱 향상시키기 위해, LLM prompting에서 점수 기반 평가 및 재생성 메커니즘(scoring-based evaluation and regeneration mechanism)을 도입하였습니다.

- **Performance Highlights**: 이론적 분석과 실험적 경험 모두 QAEA-DR 모델이 dense retrieval에 긍정적인 영향을 미친다는 것을 지지합니다.



### Learning Random Numbers to Realize Appendable Memory System for Artificial Intelligence to Acquire New Knowledge after Deploymen (https://arxiv.org/abs/2407.20197)
- **What's New**: 이 연구에서는 데이터의 파라미터 업데이트 없이 기억(메모리)하고 이를 호출(리콜)할 수 있는 신경망 시스템을 구축하는 학습 방법을 개발했습니다. 이 시스템은 'Appendable Memory 시스템'이라고 불리며, AI가 배포된 후에도 새로운 지식을 습득할 수 있도록 합니다. Appendable Memory 시스템은 데이터 저장을 담당하는 'Memorizer'와 정보를 호출하는 'Recaller'로 구성된 키-값 저장소(key-value store)입니다.

- **Technical Details**: Appendable Memory 시스템에서는 'Memorizer'가 데이터를 받아서 Appendable Memory 벡터에 저장하며, 이 벡터는 AI가 새로운 지식을 습득할 때 동적으로 업데이트됩니다. 'Recaller'는 이 벡터에서 정보를 호출하는 역할을 합니다. 전통적인 머신 러닝 방법은 학습 데이터셋의 고유한 특성을 학습하는 반면, 본 연구에서는 학습 데이터의 특징을 제거하고 운용(operation)을 학습시키는 방법을 제안합니다. 구체적으로는, 학습에 관련된 모든 데이터를 확률화(probabilize)하여 AI가 데이터의 고유한 특성을 학습하지 않도록 했습니다.

- **Performance Highlights**: 제안된 학습 방법은 전통적인 머신 러닝 방법과 근본적으로 다르며, 유한한 메모리 내에 정보를 저장하고 이를 나중에 호출할 수 있는 AI 시스템 구축의 기초적인 접근 방식을 제공합니다.



### MindSearch: Mimicking Human Minds Elicits Deep AI Searcher (https://arxiv.org/abs/2407.20183)
Comments:
          Technical Report. Project Page: https://mindsearch.netlify.app Code: this https URL

- **What's New**: 최신 연구에서는 MindSearch라는 새로운 방법을 도입했습니다. 이 시스템은 인간의 웹 정보 탐색 및 통합 과정에서의 인지적 과정을 모방하여, 대규모 언어 모델(LLM)과 검색 엔진을 효율적으로 결합한 다중 에이전트 프레임워크를 제공합니다.

- **Technical Details**: MindSearch는 두 가지 주요 컴포넌트로 구성됩니다: WebPlanner와 WebSearcher. WebPlanner는 사용자의 질의를 더 작은 서브-질문으로 분해하고 그래프로 확장하는 역할을 합니다. WebSearcher는 각 서브-질문에 대한 계층적 정보 검색을 수행하여 WebPlanner에 필요한 정보를 제공합니다. 이 다중 에이전트 설계 덕분에 MindSearch는 300개 이상의 웹 페이지에서 3분 만에 정보 통합 작업을 수행할 수 있습니다.

- **Performance Highlights**: MindSearch는 질의응답의 깊이와 폭 측면에서 클로즈-셋 및 오픈-셋 QA 문제 모두에서 상당한 성능 향상을 보입니다. 또한, InternLM2.5-7B를 기반으로 한 MindSearch의 응답은 ChatGPT-Web보다 사용자에게 더 선호되는 결과를 제공합니다.



### Blockchain for Large Language Model Security and Safety: A Holistic Survey (https://arxiv.org/abs/2407.20181)
Comments:
          Submitted to SIGKDD Explorations

- **What's New**: 최근 언어 모델(Large Language Models, LLM)의 접근이 용이해지면서, 이들에 대한 상업적 및 학문적 관심이 폭발적으로 증가했습니다. 동시에, LLM이 경험하는 새로운 공격 형태도 급증하여 사용자 데이터를 대규모로 위협하고 있습니다. 이 연구는 LLM의 취약점을 보호하기 위해 블록체인 기술이 어떻게 활용되고 있는지를 평가하고, 이를 위한 새로운 응용 가능성을 분석합니다.

- **Technical Details**: 이 논문은 LLM의 취약점 방어를 위한 블록체인 기술의 사용 현황을 평가하고, 이를 위한 새로운 응용 가능성을 분석합니다. 다양한 연구 분야의 본질을 정확히 담아내기 위해 BC4LLM(Blockchain for Large Language Models)의 분류 체계를 도입하고, 여러 정의를 개발했습니다. 또한, 전반적인 연구 노력을 맥락화하기 위한 프레임워크를 제시하고, 이 분야의 미래 연구 목표와 도전 과제를 식별했습니다.

- **Performance Highlights**: 이 연구는 LLM의 데이터 불변성과 방어력을 강화하기 위한 블록체인의 강력한 보증을 활용합니다. 데이터의 무결성과 증명이 가능하다는 점에서 블록체인은 LLM이 직면하는 다양한 공격에 대한 방어를 위한 유망한 수단으로 떠오르고 있습니다. 특히, BC4LLM 분야에서의 다양한 응용 가능성을 분석함으로써, 향후 연구와 실용적 적용을 위한 기반을 마련했습니다.



### Theia: Distilling Diverse Vision Foundation Models for Robot Learning (https://arxiv.org/abs/2407.20179)
- **What's New**: 비전 기반 로봇 정책 학습에서 단일 작업 요구(분류 또는 세그먼트와 같은)를 넘어 다양한 비주얼 작업에 대한 전체적인 이해가 필요합니다. 이를 기반으로, 우리는 다양한 비주얼 작업들에 훈련된 여러 기성 비전 기초 모델들(vision foundation models)을 집대성하여 Theia라는 비전 기초 모델을 도입했습니다. Theia는 로봇 학습을 향상시키기 위해 다양한 시각적 지식을 인코딩합니다.

- **Technical Details**: Theia는 여러 비전 기초 모델들의 풍부한 시각적 표현을 증류하여 로봇에게 학습시킵니다. 학습 데이터가 적고 모델 크기가 작음에도 불구하고, Theia는 최첨단의 모델들과 이전의 로봇 학습 모델들을 능가합니다. 또한, 사전 훈련된 시각적 표현의 품질을 정량화하고 피처 노름 분포(feature norm distributions)의 엔트로피가 높을수록 로봇 학습 성능이 향상된다는 가설을 세웠습니다.

- **Performance Highlights**: 다양한 실험 결과, Theia는 자사 모델들과 이전 로봇 학습 모델들보다 더 나은 성능을 보였고, 학습 데이터와 모델 크기 모두에서 더 효율적임을 입증했습니다. 코드와 모델은 특정 URL에서 사용 가능합니다.



### AutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs (https://arxiv.org/abs/2407.20177)
- **What's New**: 이번 연구에서는 LLMs(대형 언어 모델, Large Language Models)의 성능을 최적화하고, 다양한 다운스트림 작업에서의 성능을 보장하기 위해 도메인이 다른 데이터를 혼합하여 사전훈련을 진행해야 한다고 제안하고 있습니다. 데이터의 규모에 따라 최적의 데이터 구성이 달라질 수 있기 때문에, 적은 규모의 실험으로 최적의 구성을 찾는 일반적인 방법은 최종 모델에 대해 최적의 데이터 혼합을 제공하지 못할 수 있습니다. 이 문제를 해결하기 위해, AutoScale이라는 자동화 도구가 제안되었습니다.

- **Technical Details**: AutoScale은 원하는 목표 규모에서 컴퓨팅 최적의 데이터 구성을 찾기 위해 만들어진 도구입니다. 먼저 AutoScale은 새로운 이중 최적화 프레임워크인 Direct Data Optimization(DDO)을 사용하여 작은 규모에서 최적의 구성을 결정합니다. 이후 더 큰 규모에서 최적의 구성을 예측할 수 있도록 Predictor를 맞춥니다. 이 Predictor의 설계는 데이터 구성과 관련된 스케일링 법칙에 대한 이론적 분석에서 영감을 받았습니다.

- **Performance Highlights**: 실험 결과, AutoScale은 RedPajama 데이터셋에서 774M Decoder-only LMs (GPT-2 Large)의 사전훈련 시 기존 방법보다 25% 빠르게 검증 퍼플렉시티(validation perplexity)를 감소시키며, 재가중치(reweighting)가 없는 경우에 비해 최대 38% 속도가 향상되었습니다. Encoder-only LMs (BERT)의 사전 훈련에서, DDO는 모든 도메인에서 손실을 줄일 뿐만 아니라 GLUE 벤치마크에서 평균 작업 성능을 8.7%, 대규모 QA 데이터셋 (SQuAD)에서 5.9% 향상시켰습니다. AutoScale은 훈련 속도를 최대 28% 향상시켰으며, 사용된 코드는 오픈소스로 제공됩니다.



### Emotion-Driven Melody Harmonization via Melodic Variation and Functional Representation (https://arxiv.org/abs/2407.20176)
Comments:
          This work is the initial version of the ISMIR 2024 paper EMO-Disentanger

- **What's New**: 이 논문은 감정 주도 멜로디 화음(harmonization)을 통해 단일 멜로디에 다양한 감정을 전달하는 화음을 생성하는 새로운 방법을 제안합니다. 기존 연구에서는 동일한 멜로디에 서로 다른 화음을 적용하더라도 감정적 발란스(emotional valence)를 변화시키는 것이 어렵다는 문제를 발견했고, 이는 멜로디 자체의 제약과 기존 음악 표현의 한계 때문이라고 보고 있습니다. 이번 연구에서는 상징적 음악을 위한 새로운 기능적 표현(functional representation)을 제안합니다. 이 방법은 주요-단조(major-minor) 조성을 통해 음악의 감정적 성격을 형성하는 음악 키(key)의 중요한 역할을 고려합니다.

- **Technical Details**: 이 새로운 방법은 키(key)에 따라 멜로디 변형을 허용하며, 감정 모델링을 향상시키기 위한 데이터 부족 문제를 해결합니다. Transformer 모델을 사용하여 키 조정이 가능한 멜로디를 화음으로 만듭니다. 이 과정에서 키(key)는 규칙 기반(rule-based) 또는 모델 기반(model-based) 방식으로 결정될 수 있습니다. 새로운 기능적 표현을 통해 키를 인식하는 화음 생성의 효과를 입증했습니다.

- **Performance Highlights**: 실험 결과, 우리의 새로운 표현법이 키 인식 화음을 생성하는 데 효과적임을 확인했습니다. 객관적 및 주관적 평가에서, 제안된 접근 방식이 다방면의 멜로디에 특정한 발란스(valence)를 전달하는 잠재력을 가지고 있음을 보여주었습니다.



### Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning (https://arxiv.org/abs/2407.20174)
Comments:
          11 pages, 7 figures

- **What's New**: 새로운 멀티모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)이 차트 질문 응답(Chart Question Answering, CQA)에 대한 잠재력을 보여주고 있습니다. 저자들은 데이터 수집 및 합성을 통해 학습 데이터셋(차트, 데이터 테이블, 질문-답변 쌍)을 확장하는 기존 노력들의 한계를 지적하며, 새로운 접근 방안을 제안합니다.

- **Technical Details**: 현재 데이터 수집 및 합성 방식은 데이터의 양에 집중하고, 세밀한 시각 인코딩과 QA 작업을 제대로 고려하지 않아 실제 CQA 시나리오와 불균형한 데이터 분포를 보입니다. 기존 MLLMs의 학습 방법은 자연 이미지 처리를 위해 설계되었으며, 차트의 풍부한 텍스트 요소와 같은 고유 특성 적응을 충분히 탐구하지 않았습니다. 이를 해결하기 위해 저자들은 '시각 참조 지침 학습'(Visualization-Referenced Instruction Tuning) 접근 방식을 제안합니다. 이는 기존 데이터셋에서 다양한 고품질 데이터를 효과적으로 필터링하고, LLM 기반 생성 기술을 사용하여 데이터를 세부적으로 정제하고 증강하여 실제 QA 작업과 시각 인코딩에 더 잘 맞추도록 합니다. 또한, 비전 인코더(Vision Encoder)를 풀어주고 다양한 해상도 적응 전략을 혼합하여 세밀한 인식을 강화합니다.

- **Performance Highlights**: 실험 결과, 제안된 접근 방식은 적은 학습 예제만으로도 기존 CQA 모델을 꾸준히 능가하며, 주요 벤치마크에서 최첨단 성능을 보였습니다. 또한, 후속 연구를 위한 벤치마크로 사용할 데이터셋 분할을 제공하였습니다. 이 논문의 소스 코드와 데이터셋은 제공되는 URL에서 이용할 수 있습니다.



### LatentArtiFusion: An Effective and Efficient Histological Artifacts Restoration Framework (https://arxiv.org/abs/2407.20172)
Comments:
          Accept to DGM4MICCAI2024

- **What's New**: 이번 연구에서는 병리학자와 컴퓨터 지원 진단 (CAD) 시스템 모두에서 분석 오류를 유발할 수 있는 병리학적 유물(histological artifacts)을 복원하기 위한 새로운 프레임워크 'LatentArtiFusion'을 제안합니다. LatentArtiFusion은 잠재 확산 모델(Latent Diffusion Model, LDM)을 활용하여 기존 GAN(Generative Adversarial Networks) 및 픽셀 수준 확산 모델(pixel-level Diffusion Models) 기반 접근 방식에서 겪는 성능 한계와 계산 비효율성을 극복합니다.

- **Technical Details**: LatentArtiFusion은 전통적인 픽셀 수준 확산 프레임워크와 달리 낮은 차원의 잠재 공간에서 복원 과정을 실행하여 계산 효율성을 크게 향상시킵니다. 또한, 비유물(non-artifact) 영역에서의 잘못된 전이를 방지하기 위해 잠재 공간에서의 새로운 지역 유물 복원 알고리즘을 도입하여 기존의 GAN 기반 방식과 차별화됩니다.

- **Performance Highlights**: 실험 결과, LatentArtiFusion은 기존의 최첨단 픽셀 수준 확산 프레임워크 대비 30배 이상의 속도 향상을 달성했습니다. 또한, 다양한 평가 지표에서 GAN 기반 방법을 최소 5% 이상 초과하는 성능을 보였습니다. 추가로, 조직 분류 작업의 다운스트림(downstream) 평가에서 제안된 프레임워크의 실질적인 유용성을 입증하였습니다.



### Language-Conditioned Offline RL for Multi-Robot Navigation (https://arxiv.org/abs/2407.20164)
- **What's New**: 자연어 지시를 해석하고 따를 수 있는 다중 로봇 팀을 위한 새로운 네비게이션 정책 개발 방법이 제시되었습니다.

- **Technical Details**: 대형 언어 모델(LLMs)에서 사전 훈련된 임베딩(embeddings)을 조건으로 하는 정책을 통해 진행되며, 20분 정도의 임의로 수집된 데이터만으로 오프라인 강화 학습을 통해 훈련됩니다. 이 방법은 시뮬레이터나 환경 모델이 필요 없으며, 실제 로봇에 대해 별도의 파인튜닝 없이 즉시 배치할 수 있는 저지연(low-latency) 제어 정책을 생성합니다.

- **Performance Highlights**: 다섯 대의 실제 로봇 팀에 대한 실험에서, 이러한 정책이 보이지 않는 명령에 대해 잘 일반화하는 것을 보여주었으며, 이는 LLM의 잠재 공간(latent space)에 대한 이해를 나타냅니다.



### Quantum Machine Learning Architecture Search via Deep Reinforcement Learning (https://arxiv.org/abs/2407.20147)
Comments:
          Accepted by IEEE International Conference on Quantum Computing and Engineering - QCE 2024

- **What's New**: 양자 컴퓨팅(Quantum Computing, QC)과 머신 러닝(Machine Learning, ML)의 빠른 발전으로 양자 머신 러닝(Quantum Machine Learning, QML)이라는 새로운 분야가 부상하고 있습니다. 이 논문은 기존의 복잡한 QML 모델 설계 문제를 해결하기 위해 딥 강화 학습(Deep Reinforcement Learning)을 활용하여 특정 지도 학습(Supervised Learning) 작업에 맞춘 QML 모델 아키텍처를 탐색하는 방법을 제안합니다.

- **Technical Details**: 본 연구에서는 강화 학습(RL) 에이전트를 훈련하여 사전 정의되지 않은 앙자트(ansatz) 없이 QML 모델을 탐색하는 정책을 개발합니다. 또한, 학습 목표를 동적으로 조정하는 적응 메커니즘(Adaptive Mechanism)을 통합하여 에이전트의 학습 프로세스를 지속적으로 개선합니다. 이를 통해 분류 작업(Classification Tasks)에서 성과를 입증합니다. 특히, 제안된 방법은 높은 분류 정확도를 유지하면서 게이트 깊이(Gate Depth)를 최소화하는 가변 양자 회로(VQC) 아키텍처를 성공적으로 식별합니다.

- **Performance Highlights**: 광범위한 수치 시뮬레이션(Numerical Simulations)을 통해 제안된 접근법의 효능을 보여줍니다. 이 방법은 AI 기반의 양자 회로 설계를 진전시키는 것뿐만 아니라, NISQ(Noisy Intermediate-Scale Quantum) 시대에서의 성능 향상에 큰 잠재력을 가지고 있습니다.



### To accept or not to accept? An IRT-TOE Framework to Understand Educators' Resistance to Generative AI in Higher Education (https://arxiv.org/abs/2407.20130)
- **What's New**: OpenAI가 공개한 ChatGPT 이후로, 생성 인공지능 (Generative AI, GenAI)을 교육에 통합하는 것에 대한 장점과 도전 과제에 관한 광범위한 논의가 진행되고 있습니다. 정보 시스템 분야에서 기술 수용에 관한 연구는 특정 기술의 도입에 영향을 미치는 다양한 요소를 이해하는 데 중요합니다. 이 연구는 고등 교육에서 교육자들이 GenAI를 사용하지 못하게 하는 장벽을 예측하기 위한 이론적 모델을 개발하는 것이 목적입니다.

- **Technical Details**: 기존의 이론적 프레임워크는 주로 기술 수용을 촉진하는 요소를 설명하는 데 중점을 두고, 장애 요소는 상대적으로 덜 고려했습니다. 본 연구는 이러한 결함을 보완하기 위해 혁신 저항 이론(Innovation Resistance Theory, IRT)과 기술-조직-환경(Technology-Organization-Environment, TOE) 프레임워크의 구성 요소를 결합하여 이론적 모델을 제안합니다. 이 모델은 양적 접근 방법을 사용하여 측정 도구로 전환되며, 질적 접근 방법을 통해 분석을 보완하고 GenAI 도입에 관한 우려 사항을 발견합니다.

- **Performance Highlights**: 이 연구는 처음으로 고등 교육에서 GenAI 채택에 대한 장애 요소를 체계적으로 분석하려는 시도를 합니다. 교육자들이 GenAI 도입을 주저하는 이유를 이론적으로 설명하고, 이를 정량화하여 실증적으로 예측할 수 있는 도구를 제공한다는 점에서 중요한 기여를 합니다.



### AxiomVision: Accuracy-Guaranteed Adaptive Visual Model Selection for Perspective-Aware Video Analytics (https://arxiv.org/abs/2407.20124)
Comments:
          Accepted by ACM MM 2024

- **What's New**: AxiomVision은 엣지 컴퓨팅(edge computing)을 활용하여 다양한 시나리오 하에서 비디오 분석(Video Analytics)을 위해 가장 효율적인 시각 모델을 동적으로 선택할 수 있는 새로운 프레임워크입니다. 이 기술은 멀티미디어 시스템에서의 객체 감지, 분류, 카운팅 등을 다루는 데 최상의 효율성을 보장합니다.

- **Technical Details**: AxiomVision은 계층화된 엣지-클라우드 아키텍처(tiered edge-cloud architecture)를 사용하여 다양한 시각 모델을 배치할 수 있습니다. 이것은 경량 모델(lightweight models)부터 복잡한 DNN(deep neural networks)까지 포괄하여 특정 시나리오에 맞게 조정됩니다. 주요 기술적 혁신은 세 가지입니다: (1) 지속적 온라인 학습(continual online learning)을 이용한 동적 시각 모델 선택 메커니즘, (2) 카메라의 관점(perspective)의 영향을 효율적으로 고려하는 온라인 방법, (3) 모델 선택 과정을 가속화하는 토폴로지 기반 그룹화(topology-driven grouping) 접근법.

- **Performance Highlights**: AxiomVision은 이론적으로 높은 성능을 보장하며, 실험적으로 25.7%의 정확도 향상을 달성했습니다.



### EXIT: An EXplicit Interest Transfer Framework for Cross-Domain Recommendation (https://arxiv.org/abs/2407.20121)
Comments:
          Accepted at CIKM 2024

- **What's New**: 이번 연구에서는 Meituan과 같은 다수의 비즈니스 영역을 다루는 산업용 추천 시스템에서 발생하는 부정적인 신호 전이 문제를 해결하기 위해 새로운 EXplicit Interest Transfer 프레임워크인 EXIT를 소개합니다. 이 프레임워크는 사용자 간 관심사 신호를 명시적으로 전이하여 추천 정확도를 향상시킵니다.

- **Technical Details**: EXIT 프레임워크는 주요 도메인의 유익한 관심사를 지도 학습(supervised learning)을 통해 직접 학습할 수 있게 하는 새로운 라벨 결합(label combination) 접근 방식을 제안합니다. 또한, 세밀한 장면(scene)에서 관심 전이 강도를 모델링하기 위한 장면 선택 네트워크(scene selector network)를 도입하였습니다. 이러한 기술들은 복잡한 네트워크 구조나 훈련 과정을 거치지 않아도 쉽게 배포할 수 있습니다.

- **Performance Highlights**: EXIT는 산업용 생산 데이터셋을 이용한 오프라인 실험과 온라인 A/B 테스트에서 그 우수성과 효과성이 검증되었습니다. 이미 Meituan App의 온라인 홈페이지 추천 시스템에 성공적으로 배포되어 주요 트래픽을 처리하고 있습니다.



