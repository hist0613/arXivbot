New uploads on arXiv(cs.CL)

### From Babbling to Fluency: Evaluating the Evolution of Language Models in Terms of Human Language Acquisition (https://arxiv.org/abs/2410.13259)
- **What's New**: 본 논문은 언어 모델(LM)의 언어 능력을 인지 언어 습득의 관점에서 비판적으로 분석하며, 고전적인 언어 발달 이론을 바탕으로 언어 모델의 생성 능력을 평가하기 위한 3단계 프레임워크를 제안합니다.

- **Technical Details**: 제안된 3단계 프레임워크는 기본 단어 이해에서 복잡한 문법 및 논리적 추론까지의 능력을 평가합니다. 이 연구에서는 2019년부터 2024년까지의 15개의 언어 모델을 평가하며, 레지스터 이론(register theory)이 모델 능력에 미치는 영향을 탐구합니다.

- **Performance Highlights**: 최근 언어 모델들이 전반적인 성능에서 이전 모델들을 능가했지만, 그 발전 경로는 인간의 언어 습득과 일치하지 않음을 보였습니다. 특히, 문장 구조와 보조 동사와 같은 특정 분야에서는 큰 발전이 없었습니다.



### A Systematic Investigation of Knowledge Retrieval and Selection for Retrieval Augmented Generation (https://arxiv.org/abs/2410.13258)
- **What's New**: 이번 연구에서는 Retrieval-augmented generation (RAG) 시스템에서 지식 검색(knowledge retrieval)과 지식 선택(knowledge selection)이 생성(performance) 결과에 미치는 영향을 체계적으로 분석합니다. 연구 결과, 지식 검색의 질이 생성 품질에 커다란 영향을 미친다는 것을 보여주고, 특정 조건에서는 지식 선택의 역할이 제한적이라는 것을 밝혀냈습니다.

- **Technical Details**: RAG는 세 가지 단계로 구성됩니다: (1) Knowledge retrieval, (2) 선택적 Knowledge selection, (3) 생성(generation). 이 과정에서 K는 검색된 지식 세트, K'는 선택된 지식입니다. 연구는 다양한 비율의 금(gold) 지식과 방해(distraction) 지식을 블렌딩하여 실험합니다.

- **Performance Highlights**: 연구에 따르면, 강력한 생성 모델을 사용할 경우 지식 검색 소득(knowledge recall score)을 향상시키는 것이 중요하며, 약한 생성 모델이나 모호한 작업에서는 지식 F1 점수가 전체 성능 향상에 결정적인 요소가 됩니다.



### Automatic Translation Alignment Pipeline for Multilingual Digital Editions of Literary Works (https://arxiv.org/abs/2410.13255)
Comments:
          18 pages, Computational Humanities Research Conference, December 4-6, 2024, Aarhus, Denmark

- **What's New**: 이 논문은 Alessandro Manzoni의 소설 "I promessi sposi"의 다국어 디지털 에디션(Multilingual Digital Edition, MDE) 제작을 위한 번역 정렬 알고리즘의 적용을 조사합니다. 19세기와 20세기의 8개 언어(영어, 스페인어, 프랑스어, 독일어, 네덜란드어, 폴란드어, 러시아어, 중국어) 번역을 포함하여 MDE의 주요 요구 사항을 식별하고, 문학 텍스트 번역에 대한 현재 알고리즘의 한계를 강조하며, MDE 생성을 위한 자동화된 파이프라인을 제안합니다.

- **Technical Details**: 이 연구에서는 문학 작품의 다국어 디지털 에디션을 제작하기 위해 최신 정렬 기법을 적용하는 자동 번역 정렬 파이프라인을 제안합니다. 이 파이프라인은 원문과 번역 텍스트의 나란히 배치된 웹 기반 표현으로 변환되며, 텍스트 조각을 관리 가능한 길이로 정렬하여 사용자에게 독서 및 분석에 용이하도록 합니다. 또한, 문학 번역의 정렬을 평가하기 위한 새로운 메트릭스를 제안하고 있습니다.

- **Performance Highlights**: 논문에서 제안한 정렬 메트릭스는 기존 정렬 알고리즘의 성능을 보다 포괄적으로 평가할 수 있게 하며, 문학 작품의 다국어 디지털 에디션 제작 시 독자의 집중력과 이해를 증진할 수 있는 방법들을 제시합니다. 이는 번역의 삽입 및 생략된 부분을 시각적으로 강조하여 사용자로 하여금 각 번역의 뉘앙스를 파악할 수 있도록 돕습니다.



### Atomic Calibration of LLMs in Long-Form Generations (https://arxiv.org/abs/2410.13246)
- **What's New**: 본 논문에서는 LLM(대규모 언어 모델)의 신뢰성을 높이기 위한 새로운 접근법인 atomic calibration을 제안합니다. 기존의 macro calibration은 주로 짧은 응답에 대한 신뢰도를 평가하는 데 초점을 맞추었으나, 긴 응답의 경우 더욱 복잡한 진술이 포함될 수 있어 적합하지 않다는 점을 강조하였습니다.

- **Technical Details**: atomic calibration은 긴 응답을 작은 단위인 atomic claims로 분해하여 세부적인 신뢰도를 평가합니다. 본 연구에서는 LLM의 신뢰성 추정 방법을 discriminative와 generative 유형으로 나누고, 이들의 조합이 calibration을 개선할 수 있음을 보여줍니다. 또한, 7종의 LLM과 3개의 데이터셋을 사용하여 실험을 수행하였습니다.

- **Performance Highlights**: atomic calibration은 긴 형식의 생성 과정에서도 잘 작동하며, macro calibration 결과를 개선할 수 있는 것으로 나타났습니다. 이 방법은 LLM의 생성 과정에서 신뢰성과 calibration 변화의 패턴을 심도 있게 분석할 수 있는 가능성을 열어줍니다.



### Large Language Models are Easily Confused: A Quantitative Metric, Security Implications and Typological Analysis (https://arxiv.org/abs/2410.13237)
Comments:
          17 pages, 6 figures, 14 tables

- **What's New**: 이번 연구에서는 Large Language Models (LLMs)에서 발생하는 'Language Confusion' 현상을 분석하고, 이를 정량화하기 위한 새로운 측정 기준인 'Language Confusion Entropy'를 제안합니다. 이는 다양한 언어 분포의 패턴을 탐구하며, LLM 보안과의 연관성도 밝혔습니다.

- **Technical Details**: Language Confusion Entropy는 LLM에서 발생하는 언어 혼란 정도를 정량화하는 지표로, 언어 유형론에 기반한 언어 분포를 사용하여 LLM이 혼란스러울 때의 양상을 포착합니다. 이 연구는 여러 언어 간의 의미적 유사성과 LLM의 취약성을 연결지으며, 다국어 임베딩 역전 공격(multilingual embedding inversion attacks)에 대한 통찰을 제공합니다.

- **Performance Highlights**: 연구 결과, 언어 유형론을 기반으로 분석한 패턴들이 언어 혼란과 연관되어 있음을 발견했습니다. 특히 자원이 적은 언어는 혼란이 덜 발생하며, 다양한 스크립트와 언어 계열을 아우르는 훈련이 언어 혼란을 보다 효과적으로 완화할 수 있다는 결과를 도출했습니다.



### SPIN: Self-Supervised Prompt INjection (https://arxiv.org/abs/2410.13236)
- **What's New**: 이번 논문에서는 Self-supervised Prompt INjection (SPIN)라는 새로운 방어 메커니즘을 도입하여, 다양한 adversarial 공격 및 jailbreak 공격에 대해 LLMs의 안전성을 향상시키는 방법을 제시합니다. SPIN은 추론 시간(inference-time)에서 이루어지므로 기존의 안전성 정렬과 호환되며 추가적인 안전성 레이어를 제공합니다.

- **Technical Details**: SPIN은 self-supervised learning을 기반으로 하여, 공격을 탐지하고 입력을 복구하는 방어 기법입니다. LLM의 자연 가이드라인을 무효화하는 프롬프트가 모델의 다른 능력도 저하시키기 때문에, 이를 이용해 공격을 탐지할 수 있습니다. 방어 메커니즘은 기존의 방어 시스템과의 호환성이 있으며, 악의적 또는 선의적 레이블에 의존하지 않고 재빠른 시점에서 온라인으로 사용할 수 있습니다.

- **Performance Highlights**: SPIN의 적용 결과, Attack Success Rate (ASR)를 최대 87.9%까지 감소시킬 수 있었으며, benign 사용자 요청에 대한 성능을 유지했습니다. Advbench에서 Universal Adversarial Triggers를 사용한 실험 결과, Vicuna 모델에서는 ASR이 12.11%, Llama-2 모델에서는 0%로 감소하여 두 모델을 완전히 보호했습니다. 또한, 공격자들이 방어 체계를 알고 있어도 여전히 강인성을 보였습니다.



### Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation (https://arxiv.org/abs/2410.13232)
Comments:
          Work in progress

- **What's New**: 최근 대규모 언어 모델(LLMs)을 기반으로 한 웹 에이전트의 성능이 긴 시간의 작업에서 최적이 아님을 강조하며, '세계 모델'(world model)의 부재를 확인했다. 이 논문은 행동의 결과를 시뮬레이션하여 더 나은 의사 결정을 할 수 있는 세계 모델 증강 웹 에이전트(WMA)를 제안한다.

- **Technical Details**: 제안된 WMA 웹 에이전트는 정책 모델에서 도출된 행동 후보의 결과를 시뮬레이션하고 각 행동의 보상을 추정하는 가치 함수를 사용하여 최종 행동을 선택한다. 이를 위해 접합 중심 관찰 추상화(transition-focused observation abstraction)를 도입하여 주요 상태 차이를 강조하는 자유형 자연어 설명을 생성한다.

- **Performance Highlights**: WebArena 및 Mind2Web 실험에서 제안된 세계 모델을 통해 LLM 기반 에이전트의 정책 선택이 향상되었음을 보이며, 최근 트리 탐색 에이전트에 비해 각각 6.8배와 5.3배의 비용 및 시간 효율성을 입증했다.



### Proof Flow: Preliminary Study on Generative Flow Network Language Model Tuning for Formal Reasoning (https://arxiv.org/abs/2410.13224)
- **What's New**: 이 논문에서는 Generative Flow Networks(GFlowNets)를 이용해 LLM(대형 언어 모델)의 고급 추론 능력을 향상시키는 기법을 소개합니다. 기존의 시스템 2 사고 체계를 활용하여 더 복잡한 문제를 해결하기 위한 새로운 접근법을 제시합니다.

- **Technical Details**: GFlowNets는 최대 엔트로피 강화 학습(maximum entropy reinforcement learning) 알고리즘으로, 보상에 비례하여 구성적인 객체를 샘플링하는 정책을 훈련하도록 설계되었습니다. 이 연구에서는 GFlowNet을 Lean(형식 수학 언어) 환경과 통합하여 신경 정리 증명(Neural Theorem Proving, NTP)에서의 증명 검색(task) 문제를 해결합니다.

- **Performance Highlights**: 예비 실험 결과에 따르면, GFlowNet fine-tuning은 신경 정리 증명 작업에서 모델의 탐색성과 추론 능력을 개선하여 증명 검색 성능을 향상시키는 잠재력을 보여주었습니다. 기존 모델보다 더 높은 해결 비율이 관찰되었습니다.



### CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy (https://arxiv.org/abs/2410.13218)
- **What's New**: 본 논문은 지금의 정신 건강 지원에서 환자의 필요와 제공 가능한 지원 간의 큰 격차를 해결하기 위한 접근법으로서, 대형 언어 모델(LLMs)을 전문적인 심리 치료에 활용하는 가능성을 깊이 조사합니다. 특히, 우리는 인지 행동 치료(CBT) 지원의 체계적 평가를 위한 새로운 벤치마크인 CBT-BENCH를 제안합니다.

- **Technical Details**: CBT-BENCH는 세 가지 수준의 과제로 구성됩니다: I: 기본 CBT 지식 습득을 위한 다중 선택 질문; II: 인지 모델 이해를 위한 인지 왜곡 분류, 주요 핵심 신념 분류, 세부 핵심 신념 분류 작업; III: CBT 세션에서 환자 발화에 대한 치료적 응답 생성. 논문에서는 CBT의 핵심 측면을 AI 지원을 통해 향상할 수 있는 가능성을 조명하며, 각 과제는 기본 지식 암기부터 실제 치료 대화에 참여하는 것과 같은 복잡한 능력 요구 사항의 계층을 포함합니다.

- **Performance Highlights**: 실험 결과에 따르면 LLMs는 CBT 지식을 암기하는 데는 상대적으로 잘 수행하였지만, 환자의 인지 구조에 대한 깊은 분석이 필요한 복잡한 실제 시나리오에서는 부족한 성과를 보였습니다. LLMs는 일반적으로 엄격한 논리적 추론 프로세스를 따르지만, 치료에서 중요한 환자의 관점에서 사고하고 관계를 구축하는 능력이 부족하다는 제한점을 보여주었습니다.



### FaithBench: A Diverse Hallucination Benchmark for Summarization by Modern LLMs (https://arxiv.org/abs/2410.13210)
- **What's New**: 이 논문에서는 10개의 현대 LLM(대형 언어 모델)와 8개의 모델 가족에서 발생하는 도전적 환각을 포함하는 FaithBench라는 환각 평가 벤치마크를 제안합니다.

- **Technical Details**: FaithBench는 인공지능 모델에 의해 생성된 요약에서 발생하는 환각(hallucination)을 평가하기 위해 설계되었습니다. 이 벤치마크는 LLM 가족에 따라 다양한 환각 사례를 포함하고 있으며, 각 요약은 인간 전문가에 의해 주석이 달린 ground truth를 포함하고 있습니다.

- **Performance Highlights**: 연구 결과에 따르면, GPT-4o와 GPT-3.5-Turbo가 가장 낮은 환각 비율을 나타냈지만, 환각 탐지 모델의 정확도는 여전히 50%에 가까운 수치를 기록하여 개선의 여지가 많음을 시사합니다.



### BQA: Body Language Question Answering Dataset for Video Large Language Models (https://arxiv.org/abs/2410.13206)
- **What's New**: 이 논문은 인간의 신체 언어를 정확하게 해석하기 위해 Video Large Language Models (VideoLLMs)에 필요한 새로운 데이터셋인 BQA (Body Language Question Answering) 를 제안합니다. 이 데이터셋은 26가지 감정 레이블을 가진 신체 언어 비디오에서 감정을 해석하는 능력을 평가합니다.

- **Technical Details**: BQA 데이터셋은 5-10초 길이의 7632개의 짧은 비디오 클립으로 구성되어 있으며, 각 클립은 젠더(gender), 나이(age), 민족(ethnicity) 메타데이터와 함께 26가지 감정 레이블을 포함합니다. 본 연구는 다양한 VideoLLMs 모델의 성능을 평가하여 신체 언어 해석의 어려움을 드러냅니다.

- **Performance Highlights**: BQA를 통해 평가한 결과, VideoLLMs 모델들은 특정 나이 그룹이나 민족에 따라 편향된 답변을 제공하는 경향이 있음을 발견했습니다. 특히 GPT-4o와 Gemini 모델이 높은 정확도를 기록했으며, 신체 언어 해석 능력에서 다른 모델들보다 우수한 성능을 보였습니다.



### Measuring Free-Form Decision-Making Inconsistency of Language Models in Military Crisis Simulations (https://arxiv.org/abs/2410.13204)
- **What's New**: 이번 연구는 언어 모델(LMs)이 고위험 결정-making 환경에서 일관성이 부족한 응답을 나타내는지를 조사합니다. 특히 군사 위기 시뮬레이션에서 LMs가 생성하는 자유형(free-form) 응답을 분석하여 군사적 결정-making에 대한 신뢰성 문제를 강조합니다.

- **Technical Details**: 이 연구에서는 BERTScore를 기반으로 하여 LMs의 응답 일관성을 정량적으로 측정합니다. 실험 결과, 모든 LMs는 세부적인 상황 조정에도 불구하고 의미적으로 상이한 응답을 제공하며, 이는 높은 수준의 일관성 결여를 나타냅니다. 또한, 프롬프트의 민감도 변주가 일관성에 미치는 영향을 탐구합니다.

- **Performance Highlights**: 군사적인 고위험 환경에서 LMs의 의사결정 신뢰성을 고민할 때, 이러한 연구 결과가 더욱 중요해집니다. LMs는 상황에 따라 서로 다른 일관성 수준을 보이며, 이로 인해 고위험 결정-making에서 신중한 접근이 필요하다는 결론을 도출했습니다.



### Meta-DiffuB: A Contextualized Sequence-to-Sequence Text Diffusion Model with Meta-Exploration (https://arxiv.org/abs/2410.13201)
- **What's New**: Meta-DiffuB는 Seq2Seq 텍스트 생성을 위한 새로운 스케줄러-탐색자 모델을 도입하여 기존 S2S-Diffusion 모델의 한계를 극복합니다. 기존 모델들은 고정된 또는 수작업으로 만든 규칙에 의존하여 노이즈를 스케줄링하는 반면, Meta-DiffuB는 문맥화된 노이즈 스케줄링을 통해 문장별로 적합한 노이즈를 적용합니다.

- **Technical Details**: Meta-DiffuB는 두 가지 모델로 구성됩니다: 스케줄러와 탐색자. 스케줄러는 각 문장의 특성에 맞춰 적절한 수준의 노이즈를 스케줄링하고, 탐색자는 해당 노이즈를 활용하여 업데이트 및 생성을 수행합니다. 이 접근 방식은 자연어 처리(NLP)에서 Seq2Seq 작업의 의미론적 특성을 반영합니다.

- **Performance Highlights**: Meta-DiffuB는 네 가지 Seq2Seq 벤치마크 데이터세트에서 기존 S2S-Diffusion 모델 및 정밀 조정된 사전 훈련된 언어 모델(PLMs)과 비교하여 최첨단 성능을 달성합니다. 또한, 스케줄러 모델은 기존 DiffuSeq를 더욱 향상시키기 위한 '플러그 앤 플레이' 기능을 제공합니다.



### The Geometry of Numerical Reasoning: Language Models Compare Numeric Properties in Linear Subspaces (https://arxiv.org/abs/2410.13194)
- **What's New**: 이번 논문에서는 대형 언어 모델(LLM)이 논리적 비교 질문에 답변할 때 저차원(subspace) 임베딩 공간에 인코딩된 숫자 속성을 어떻게 활용하는지 조사하였습니다. 특히, LLM이 수치적 추론(numerical reasoning) 문제를 해결하기 위해 이러한 선형 서브스페이스를 활용한다는 점을 강조합니다.

- **Technical Details**: 본 연구에서는 부분최소제곱회귀(partial least squares regression, PLS)를 사용하여 LLM의 내부에서 숫자 속성과 관련된 서브스페이스를 식별하였으며, 이 서브스페이스에개입(intervention)을 통해 숨겨진 상태(hidden state)를 조작하여 LLM의 비교 결과를 변경하는 실험을 진행하였습니다. 연구에서는 LLM이 학습한 수치적 속성이 비선형이 아닌 선형적으로 표현된 정보를 활용한다는 것을 보여줍니다.

- **Performance Highlights**: 실험 결과, LLM은 출생 연도(birth year), 사망 연도(death year), 위도(latitude) 등 3가지 숫자 속성에 대해 다양한 수치 추론 작업을 해결하는 데 성공적인 성과를 보였습니다. 모델은 출생/사망 연도 예측에서 약 75%의 정확도를 보였으나, 위도 관련 질문에서는 56%의 정확도로 상대적으로 낮은 성과를 나타냈습니다.



### Evaluating Self-Generated Documents for Enhancing Retrieval-Augmented Generation with Large Language Models (https://arxiv.org/abs/2410.13192)
Comments:
          Under Review

- **What's New**: 이번 연구는 Self-Generated Documents (SGDs)와 검색된 콘텐츠의 통합이 대규모 언어 모델(LLM)의 성능 향상에 어떻게 기여하는지를 탐구합니다. 이는 SGDs의 고유한 특성을 중점적으로 분석하는 첫 번째 연구로, 이를 통해 SGD의 다양한 유형이 성능에 미치는 영향을 비교하고자 합니다.

- **Technical Details**: 연구에서는 Systemic Functional Linguistics (SFL)에 기반한 SGDs의 분류 체계를 개발하고, 다양한 지식 집약적(task) 작업에 대한 실험을 통해 서로 다른 SGD 범주의 영향력을 평가합니다. 이를 통해 LLM 성능 개선에 가장 효과적인 SGD 유형을 도출합니다.

- **Performance Highlights**: 연구 결과와 SGD 범주에 따라 개발된 추가 융합(fusion) 방법은 RAG( retrieval-augmented generation) 기반의 지식 기반 QA 작업에서 SGDs를 효과적으로 활용하기 위한 실용적인 지침을 제공합니다.



### MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback (https://arxiv.org/abs/2410.13191)
Comments:
          Equal contribution for the first two authors

- **What's New**: 이번 연구에서는 MCQG-SRefine라는 새로운 프레임워크를 제안하여, 전문의 시험을 위한 고품질 다지선다 질문(USMLE 스타일 질문)을 자동 생성하는 방법을 소개합니다. 이 프레임워크는 LLM의 자기 수정(self-refine) 기반으로, 전문가의 피드백과 반복적인 자기 비판을 통해 질문의 품질과 난이도가 향상됩니다.

- **Technical Details**: MCQG-SRefine는 의료 사례를 입력으로 받아 USMLE 스타일의 질문을 생성합니다. FR 쿼리 설정과 41개의 주요 주제를 포함한 체크리스트를 기반으로, LLM이 의료 사례에서 정보를 추출하여 질문을 생성합니다. 또한, LLM 스스로 피드백을 주고, 이를 기반으로 질문을 수정하는 세 가지 단계(S1: 초기 MCQ 생성, S2: 비판 피드백, S3: 수정 피드백)를 따릅니다.

- **Performance Highlights**: MCQG-SRefine를 통해 생성된 질문은 GPT-4가 생성한 질문보다 72.5%의 선호도를 기록했으며, 더 높은 난이도의 질문을 생성하는 것이 확인되었습니다. 쉽고 중간 수준의 질문에서 각각 80% 감소 및 2.25배 증가, 어려운 질문에서 4배 증가하는 결과를 보였습니다. LLM-as-Judge를 활용해 전문가 평가를 대체할 수 있는 신뢰성 있는 자동 평가 시스템 또한 제안되었습니다.



### aiXcoder-7B: A Lightweight and Effective Large Language Model for Code Completion (https://arxiv.org/abs/2410.13187)
Comments:
          aiXcoder-7B is available at this https URL

- **What's New**: aiXcoder-7B는 70억 개의 매개변수를 가지며, 코드 완성을 위하여 설계된 경량화된 대형 언어 모델(LLM)입니다. 기존 LLM에 비해 보다 높은 정확도를 기록하며, 개발자 생산성을 높이기 위해 응답 시간을 단축시킵니다.

- **Technical Details**: aiXcoder-7B는 세 가지 주요 요소에 의해 우수한 성능을 발휘합니다: (1) 다중 목표 훈련(Multi-objective training), (2) 다양한 데이터 샘플링 전략(Diverse data sampling), (3) 방대한 고품질 데이터(Extensive high-quality data). 특히, Structured Fill-In-the-Middle (SFIM)이라는 훈련 목표를 사용하여 코드의 구문 구조를 고려합니다. 이와 함께 1.2 조 개의 고유한 토큰을 소비하여 훈련됩니다.

- **Performance Highlights**: aiXcoder-7B는 6개의 코드 완성 벤치마크에서 최신 LLM들보다 우수한 성능을 나타내며, 심지어 StarCoder2-15B와 CodeLlama-34B와 같은 더 큰 LLM보다도 뛰어난 결과를 기록하였습니다. 이는 aiXcoder-7B가 경량화된 모델임에도 불구하고 뛰어난 코드 완성 정확도를 보유하고 있음을 나타냅니다.



### Router-Tuning: A Simple and Effective Approach for Enabling Dynamic-Depth in Transformers (https://arxiv.org/abs/2410.13184)
- **What's New**: 이번 논문에서는 Mixture of Depths (MoD) 모델의 한계점을 극복하기 위해 Router-Tuning과 Attention with Dynamic Depths (MindSkip)를 제안하며, 훈련 비용 절감과 성능 유지 간의 균형을 맞추는 방법을 다룹니다.

- **Technical Details**: Router-Tuning은 라우터 네트워크만 조정하는 방법으로, 전체 모델의 매개변수를 업데이트하지 않고도 효율적으로 훈련할 수 있습니다. MindSkip는 Attention 계층에 동적 깊이를 적용하여 성능 손실 없이 연산 비용과 메모리 사용량을 줄입니다.

- **Performance Highlights**: 심층 실험 결과, 제안된 방법은 21%의 속도 향상과 0.2%의 성능 저하율을 기록하였으며, Nvidia RTX A6000에서 30분 이내에 Router-Tuning이 완료됩니다.



### AdaSwitch: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning (https://arxiv.org/abs/2410.13181)
Comments:
          EMNLP 2024 Main Conference

- **What's New**: AdaSwitch라는 새로운 LLM 활용 패러다임을 제안하여 클라우드 기반의 대형 LLM과 로컬 배치된 소형 LLM이 협력하여 복잡한 작업을 해결한다. 이 프레임워크는 두 가지 주요 모듈인 로컬 에이전트와 클라우드 에이전트로 구성되어 있으며, 각각의 에이전트는 서로 다른 복잡도의 추론 단계를 처리한다.

- **Technical Details**: 이 연구는 AdaSwitch라는 새로운 프레임워크를 통해 소형 LLM과 대형 LLM 간의 협업을 가능하게 하며, 이를 통해 계산 비용을 줄이고 성능을 향상시킨다. 로컬 에이전트는 더 간단한 추론 단계를 처리하고, 클라우드 에이전트는 복잡한 추론 단계를 관리한다. 로컬 에이전트는 필수적인 경우 클라우드 에이전트에게 도움을 요청하도록 설계되었다.

- **Performance Highlights**: AdaSwitch는 수학적 추론 및 복잡한 질문 응답 등 7개의 벤치마크에서 실험을 진행했으며, 다양한 LLM을 사용하여 로컬 및 클라우드 에이전트를 초기화하는 데 성공했다. 예를 들어 DeepSeek-Coder-1.3B 모델은 성능이 29.3%에서 53.9%로 향상되었고, StarCoder2-3B는 Llama-30B에 비해 5배 적은 계산 오버헤드로 유사한 성능을 달성하였다.



### SLM-Mod: Small Language Models Surpass LLMs at Content Moderation (https://arxiv.org/abs/2410.13155)
Comments:
          Preprint: 15 pages, 8 figures, 8 pages

- **What's New**: 이 논문에서는 대형 언어 모델(LLMs) 대신 커뮤니티 특화 콘텐츠 조정을 위해 오픈 소스의 소형 언어 모델(SLMs)을 사용하는 가능성을 탐구합니다. SLM들은 비용 효율적이며 LLMs와 비슷한 성능을 발휘할 수 있는 잠재력을 가지고 있습니다.

- **Technical Details**: SLMs(15B 파라미터 이하)에 대한 세부 조정을 수행하고, 15개의 인기 있는 Reddit 커뮤니티에서 수집한 150K 댓글을 활용하여 이들의 성능을 평가했습니다. 결과적으로 SLMs는 콘텐츠 조정에서 LLMs보다 11.5% 더 높은 정확도와 25.7% 더 높은 재현율을 보였습니다. 소형 언어 모델을 조정하기 위한 저자원 접근법인 LoRA(Low-Rank Adaptation) 기법이 사용되었습니다.

- **Performance Highlights**: SLMs는 인도메인 콘텐츠 조정 작업에서 LLMs에 비해 더 높은 정확도와 재현율을 기록했으며, 다소 낮은 정밀도를 보였습니다. 이는 커뮤니티 특정 조정을 위한 더 효율적인 대안을 제공할 수 있음을 보여줍니다.



### Better to Ask in English: Evaluation of Large Language Models on English, Low-resource and Cross-Lingual Settings (https://arxiv.org/abs/2410.13153)
- **What's New**: 이 연구는 저자들이 방글라어, 힌디어, 우르두어 같은 저자원 언어에서의 LLM(대형 언어 모델) 성능을 평가하고, GPT-4, Llama 2, Gemini의 효과를 분석한 결과를 담고 있습니다. 또한, 모델들이 저자원 언어에서 영어만큼 성능을 발휘하지 못함을 강조합니다.

- **Technical Details**: 연구에서는 제로샷 프롬프팅(zero-shot prompting)과 5가지 서로 다른 프롬프 설정을 사용하여 방글라어, 힌디어, 우르두어와 같은 저자원 언어에서의 LLM 성능을 분석했습니다. 이 연구는 또한 자연어 추론(NLI)을 포함하여 LLM 성능을 향상시키기 위한 새로운 접근 방식을 소개하였습니다.

- **Performance Highlights**: 결과는 GPT-4가 모든 언어와 프롬프 설정에서 Llama 2 및 Gemini보다 우수한 성능을 보였다는 것을 보여줍니다. 또한 모든 LLM이 저자원 언어 프롬프보다 영어 프롬프에서 더 나은 성능을 발휘했습니다.



### Mapping Bias in Vision Language Models: Signposts, Pitfalls, and the Road Ahead (https://arxiv.org/abs/2410.13146)
Comments:
          Under Review at NAACL 2025

- **What's New**: 이 논문은 Vision Language Models (VLMs)의 공정성을 평가하기 위해 5개의 모델과 6개의 데이터셋을 분석하고, 편향(bias)에 대한 새로운 통찰을 제공합니다. 특히, 기존의 표정 기반(portrait-based) 데이터셋이 VLM의 공정성을 평가하는 데 가장 유용하다는 것을 발견했습니다.

- **Technical Details**: 본 연구는 UTKFace, CelebA, PATA, VLStereoSet, VisoGender와 같은 여러 데이터셋을 활용하여 VLM의 편향을 평가하였습니다. 각 모델이 성별, 인종 및 연령과 같은 보호 속성을 어떻게 처리하는지 분석를 진행하며, 특히 데이터셋의 구성에 따라 평가 결과가 달라질 수 있음을 강조합니다. VisoGender 데이터셋의 어려운 버전을 소개하여 철저한 평가를 가능하게 합니다. 

- **Performance Highlights**: LLaVa와 CLIP 모델 간의 성능과 공정성의 격차를 발견하여, VLM의 공정성 평가에 대한 보다 효과적이고 체계적인 데이터셋 설계의 필요성을 강조합니다. 저자들은 기존 데이터셋의 한계를 지적하며, VLM의 평가를 위한 향후 연구 방향을 제안합니다.



### Data Defenses Against Large Language Models (https://arxiv.org/abs/2410.13138)
- **What's New**: 본 논문에서는 "data defenses"라는 새로운 전략을 정의하고 구축하여 데이터 소유자가 LLM(대형 언어 모델)의 추론을 차단할 수 있도록 하는 방안을 제안합니다. 이는 개인 식별 정보 추론이나 저작권 텍스트 사용을 감소시키기 위한 자동 생성적 adversarial prompt injections 기법으로 구성됩니다.

- **Technical Details**: 우리는 저작권 침해, 개인 정보 보호 침해 및 감시 강화를 포함한 다양한 추론 시 발생할 수 있는 해악을 확인합니다. 이는 LLM 추론을 방해함으로써 권한을 데이터 소유자에게 되돌리는 기회를 제공합니다. 이 "data defenses"는 보다 저렴하고 빠르게 생성될 수 있으며, 중앙 집중적인 대처 수단 없이도 LLM의 정확도를 크게 떨어뜨립니다. 또한 이러한 방어 방법은 여러 공격 설정에 강력하며, 상업적 및 오픈 소스 LLM 모두에 대해 효과적임을 입증합니다.

- **Performance Highlights**: 우리는 제안하는 data defenses가 최신 상업적 및 오픈 소스 LLM에서 효과적으로 작동하며, 방어 메커니즘 생성 시간이 매우 짧고 자동화되어 있다는 것을 보여줍니다. 이러한 데이터 방어는 사용자가 콘텐츠에 대한 LLM의 추론을 제어할 수 있는 즉각적이고 저비용의 방법을 제공합니다.



### Retrieval-Enhanced Named Entity Recognition (https://arxiv.org/abs/2410.13118)
Comments:
          13 pages, 6 figures, 3 tables

- **What's New**: RENER (Retrieval-Enhanced Named Entity Recognition)는 In-Context Learning (ICL) 및 정보 검색 기술을 결합하여 명명된 개체 인식(NER) 작업에서 성능을 향상시키기 위해 제안된 새로운 방법입니다. 이 방법은 입력 텍스트에 대해 유사한 예제를 검색하고 이를 언어 모델에 통합하여 NER을 수행할 수 있도록 합니다.

- **Technical Details**: RENER는 언어 모델과 정보 검색 알고리즘에 독립적이며, 언어 모델과의 결합이 최소화된 상태로 새로운 명명된 개체를 인식하는 데 사용할 수 있습니다. 이 과정에서 언어 모델에 직접적인 의존성이 없으며, 다양한 NER 도메인에 쉽게 배포할 수 있습니다. 또한 CrossNER 컬렉션에서의 실험 결과, RENER는 최신 기술(State-of-the-Art) 성능을 달성하였으며, 정보 검색 기술을 사용할 경우 F-score를 최대 11% 상승시킬 수 있음을 보여주었습니다.

- **Performance Highlights**: RENER는 CrossNER 데이터셋에서 최신 성능을 달성하였으며, 정보 검색 기법을 활용함으로써 비슷한 시스템 대비 성능을 최대 11% 향상시킬 수 있었습니다. 이는 NER 작업에서 ICL과 RAG 기법을 성공적으로 결합했음을 나타냅니다.



### Learning to Summarize from LLM-generated Feedback (https://arxiv.org/abs/2410.13116)
- **What's New**: 이번 연구에서는 LLM(대규모 언어 모델) 생성 피드백을 통해 요약 품질을 향상시키는 방법을 탐구하고, FeedSum이라는 대규모 데이터셋을 소개합니다. 이는 다양한 품질의 요약에 대한 다차원 LLM 피드백을 포함하고 있습니다.

- **Technical Details**: FeedSum 데이터셋에서는 13개의 서로 다른 언어 모델을 사용하여 요약을 생성하고, 각 요약에 대해 신뢰성(faithfulness), 완전성(completeness), 간결성(conciseness)이라는 세 가지 핵심 차원에 대한 피드백을 수집합니다. 두 가지 방법인 감독형 세부 조정(supervised fine-tuning)과 직접 선호 최적화(direct preference optimization)를 비교하였고, SummLlama3-8B 모델이 Llama3-70b-instruct 모델보다 더 뛰어난 성능을 보였음을 확인했습니다.

- **Performance Highlights**: SummLlama3-8B 모델은 크기가 10배 이상 큰 Llama3-70b-instruct 모델을 초월하여 인간의 선호에 맞는 요약을 생성하는 데 성공하였습니다. 이는 Smaller 모델이 적절한 훈련을 통해 더 우수한 성능을 얻을 수 있음을 보여줍니다.



### A Little Human Data Goes A Long Way (https://arxiv.org/abs/2410.13098)
- **What's New**: NLP 시스템의 효율성을 높이기 위해, 인간 주석 데이터의 일부를 합성 데이터로 대체하는 방법을 연구하였으며, 90%까지 대체해도 성능 저하가 미미하지만 마지막 10% 대체 시에는 성능이 크게 떨어진다는 중요한 발견을 했습니다.

- **Technical Details**: 합성 데이터 생성 과정을 통해 데이터 포인트 수를 일정하게 유지하며 인간 생성 데이터 비율을 점진적으로 증가시켜 성능을 비교하였습니다. 사용하는 데이터셋은 총 8개로 Fact Verification (FV) 및 Question Answering (QA) 태스크에 대해 실험하였습니다. 평가 지표로는 정확도, Exact Match, String Inclusion, BLEU, ROUGE-1, BERTScore를 사용하였습니다.

- **Performance Highlights**: 완전히 합성 데이터로 훈련된 FV 및 QA 시스템은 최소 125개의 인간 데이터 포인트를 추가할 경우 성능이 현저히 개선되며, 작은 비율의 인간 데이터가 큰 가치를 지닐 수 있다는 것을 발견했습니다. 추가적인 인간 데이터를 통한 성능 향상은 200 포인트의 인간 데이터로 가능하며, 이는 수량적으로 더 많은 합성 데이터 포인트에 비해 비용 효율적이라는 것을 보여줍니다.



### Reverse-Engineering the Reader (https://arxiv.org/abs/2410.13086)
- **What's New**: 이 연구는 기존의 언어 모델을 인간의 심리 측정 데이터에 맞춰 최적화하는 새로운 방법론을 제시합니다. 이를 통해 언어 처리 시스템의 이해를 높이고자 합니다.

- **Technical Details**: 연구진은 언어 모델이 특정 언어 단위의 읽기 시간을 예측하는 능력을 향상시키기 위해 서프라이절 이론(surprisal theory)을 기반으로 한 새로운 정렬 기법을 사용합니다. 모델의 파라미터를 조정하여 읽기 시간을 예측하는 선형 회귀의 계수를 최적화합니다.

- **Performance Highlights**: 제안된 기법은 여러 모델 크기와 데이터 세트에서 언어 모델의 심리 측정 예측력을 향상시키는 것으로 나타났습니다. 그러나 심리 측정 예측력과 후속 자연어 처리(NLP) 작업 성능 간에 반비례 관계가 발견되었습니다.



### Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models (https://arxiv.org/abs/2410.13080)
Comments:
          21 pages, 10 figures

- **What's New**: 이 논문은 GCR(Graph-Constrained Reasoning)이라는 새로운 프레임워크를 제안합니다. GCR은 구조화된 지식(graph)과 비구조화된 추론을 결합하여 LLM의 신뢰할 수 있는 추론을 돕습니다.

- **Technical Details**: GCR은 KG-Trie라는 trie 기반 인덱스를 사용하여 KG의 구조를 LLM의 디코딩 과정에 통합합니다. 이를 통해 LLM은 KG에 직접적으로 기반한 추론을 수행하고 잘못된 정보(hallucinations)를 제거할 수 있습니다.

- **Performance Highlights**: 포괄적인 실험 결과에 따르면 GCR은 여러 KGQA 벤치마크에서 최신 성능(state-of-the-art performance)을 달성하고, 추가적인 학습 없이도 새로운 KG에 강력한 제로샷 제너럴라이제이션(zero-shot generalizability)을 보이는 것으로 나타났습니다.



### Tuning Language Models by Mixture-of-Depths Ensemb (https://arxiv.org/abs/2410.13077)
- **What's New**: 최근 연구에서는 Transformer 기반의 대형 언어 모델(LLMs)에서 최종 레이어만을 사용하는 대신, 중간 레이어의 예측 능력에 주목하여 새로운 조정 프레임워크인 Mixture-of-Depths (MoD)를 제안하였습니다. MoD는 훈련 시 다양한 레이어의 출력을 활용함으로써 예측 성능을 향상시키고, 기존 조정 방법과 통합할 수 있는 특징을 가지고 있습니다.

- **Technical Details**: Mixture-of-Depths (MoD) 프레임워크는 레이어별 가중치를 학습하여 최종 로그잇(logits)으로 기여하는 앙상블로서의 레이어 훈련을 가능하게 합니다. 보조 증류 손실(auxiliary distillation loss) 및 추가 정규화 모듈을 적용하여, 최종 레이어 출력을 교사가 되는 훈련 방식으로 중간 레이어의 예측 출력을 모델 학습 시 최대화하는 접근을 취합니다. 이 방법은 훈련 가능한 파라미터를 소폭 증가시키면서도, 기본 언어 모델의 성능을 유지합니다.

- **Performance Highlights**: MoD 프레임워크를 적용한 결과, 산술 및 상식 추론 작업에서 성능이 일관되게 향상되었으며, 전통적인 훈련 가능한 모듈과 비교하여 97% 적은 파라미터로 유사한 성능을 달성하였습니다. 이러한 결과는 LLM의 중간 표현을 활용하는 것이 훈련 중 예측 능력을 크게 향상시킬 수 있음을 보여줍니다.



### PromptExp: Multi-granularity Prompt Explanation of Large Language Models (https://arxiv.org/abs/2410.13073)
Comments:
          11 pages

- **What's New**: 이번 연구에서는 자연어 처리에서 대규모 언어 모델(LLMs)의 해석 가능한 프롬프트 공학을 위한 새로운 프레임워크인 OurTool을 소개합니다. 이 프레임워크는 토큰 수준의 통찰력을 집계하여 멀티 그레인 울라리티(multi-granularity) 설명을 제공합니다.

- **Technical Details**: OurTool은 두 가지 토큰 수준 설명 접근 방식을 제안합니다: 첫 번째는 aggregation-based approach로, 기존의 로컬 설명 기법을 결합하여 프롬프트의 각 토큰에 대한 포괄적인 설명을 생성합니다. 두 번째는 perturbation-based approach로, 토큰 마스킹의 영향을 평가하기 위한 새로운 기법을 도입합니다.

- **Performance Highlights**: 사례 연구를 통해 OurTool이 감정 분석에서 최고의 성과를 나타내며, 사용자의 평가에서도 80% 이상의 참여자가 OurTool이 제공하는 설명이 타당하고 정확하다고 응답했습니다.



### Is Semantic Chunking Worth the Computational Cost? (https://arxiv.org/abs/2410.13070)
- **What's New**: 최근 Retrieval-Augmented Generation (RAG) 시스템에서 문서를 의미적으로 일관된 세그먼트로 분할하는 semantic chunking이 인기를 얻고 있습니다. 본 연구는 semantic chunking이 보다 간단한 fixed-size chunking에 비해 실질적인 이점을 제공하는지에 대한 체계적인 평가를 진행했습니다.

- **Technical Details**: 연구팀은 document retrieval, evidence retrieval, answer generation 세 가지 일반적인 retrieval 관련 작업을 통해 semantic chunking의 효용성을 평가했으며, 다양한 chunking 전략을 비교하여 최적의 성능을 갖는 chunker를 확인했습니다. 또한, 두 가지 chunking 전략으로 fixed-size chunker와 breakpoint-based semantic chunker, clustering-based semantic chunker를 채택하여 평가하였습니다.

- **Performance Highlights**: 결과적으로, semantic chunking이 특정 상황에서 일부 이점을 보였지만, 이러한 이점들은 불일치하며 고정 크기 청크에 대한 계산 비용을 정당화할 만큼 충분하지 않다는 것을 보였습니다. 이는 RAG 시스템에서 더 효율적이고 적응적인 chunking 전략의 필요성을 강조합니다.



### ERAS: Evaluating the Robustness of Chinese NLP Models to Morphological Garden Path Errors (https://arxiv.org/abs/2410.13057)
Comments:
          Under review in ARR/NAACL

- **What's New**: 이 논문에서는 중국어를 다루는 NLP 모델들이 형태소적 garden path 오류에 취약하다는 것을 보여줍니다. 이를 평가하기 위해 ERAS라는 벤치마크를 제안합니다.

- **Technical Details**: ERAS 벤치마크는 지역적으로 모호한 구문과 모호하지 않은 구문으로 이루어진 203,944 쌍의 시험 문장과 통제 문장을 포함합니다. 이 연구는 Transformer 기반 및 비신경 단어 분리 모델과 캐릭터 수준의 토큰화를 사용하는 감정 분석 모델을 평가합니다.

- **Performance Highlights**: 실험 결과, 단어 분리 모델과 감정 분석 모델 모두가 garden path 오류를 범하며, 단어 경계 정보를 제공하여 모델 성능을 개선할 수 있다는 것을 보여줍니다.



### Channel-Wise Mixed-Precision Quantization for Large Language Models (https://arxiv.org/abs/2410.13056)
- **What's New**: 본 연구에서는 채널별 혼합 정밀도 양자화(Channel-Wise Mixed-Precision Quantization, CMPQ)라는 혁신적인 방법을 제안합니다. CMPQ는 각 채널의 활성화 분포에 기반하여 양자화 정밀도를 할당하는 새로운 혼합 정밀도 양자화 기법으로, 다양한 비트폭 제약에 적응하도록 설계되었습니다.

- **Technical Details**: CMPQ는 비균일 양자화(non-uniform quantization) 전략을 채택하며, 두 가지 이상치 추출(outlier extraction) 기법을 결합하여 필수 정보를 보존하며 양자화 손실을 최소화합니다. 이 방법은 채널별로 정밀도를 조정하여 각 채널의 활성화 norm에 따라 높은 정밀도 혹은 낮은 정밀도를 할당합니다.

- **Performance Highlights**: CMPQ는 실험을 통해 정수 비트 양자화(integer-bit quantization) 작업에서 성능을 향상시키는 한편, 적은 메모리 증가로 상당한 성능 향상을 이끌어냈습니다. 이 연구는 다양한 디바이스의 기능에서 큰 이점을 제공합니다.



### LFOSum: Summarizing Long-form Opinions with Large Language Models (https://arxiv.org/abs/2410.13037)
- **What's New**: 이 논문에서는 온라인 리뷰의 대량 처리 및 요약을 위한 새로운 접근법을 제안합니다. 특히, 1천 개 이상의 리뷰로 구성된 새로운 데이터셋을 소개하며, 이를 기반으로 하는 LLM(대형 언어 모델) 기반 요약 기법을 제안합니다.

- **Technical Details**: LFOSum 데이터셋은 TripAdvisor에서 수집된 호텔 리뷰로, 각 엔티티는 1천 개 이상의 리뷰를 포함하고 있습니다. 두 가지의 훈련이 필요 없는 요약 방법, 즉 Retrieval-Augmented Generation (RAG)과 긴 맥락의 LLM을 이용하여 대량 리뷰 요약을 처리합니다. 사용자 맞춤형 요약을 위한 세 가지 제어 메커니즘(쿼리 제어, 감정 제어, 길이 제어)을 도입하여 사용자 요구에 맞춘 요약을 가능하게 합니다.

- **Performance Highlights**: LLM은 여전히 긴 형식의 요약에서 감정과 형식 준수의 균형을 맞추는 데 어려움을 겪고 있으나, 관련 정보를 집중적으로 추출할 경우 오픈 소스 모델이 효과적으로 간격을 좁힐 수 있음을 보여줍니다.



### When Not to Answer: Evaluating Prompts on GPT Models for Effective Abstention in Unanswerable Math Word Problems (https://arxiv.org/abs/2410.13029)
Comments:
          11 pages, 7 figures, 2 tables

- **What's New**: 본 논문은 대형 언어 모델(GPT 모델)이 해결 불가능한 수학 단어 문제에 적절하게 대응할 수 있는지 평가하고, 이러한 모델들의 개선 방안을 모색한다. 특히, 모델들이 정답이 없을 경우 어떻게 'abstain' (응답 거부) 할 수 있는지를 연구하며, 이 과정을 향상시키기 위한 프롬프트 기술을 탐구한다.

- **Technical Details**: 연구는 Unanswerable Word Math Problem (UWMP) 데이터셋을 활용하였으며, 각 문제에 대해 'abstention' (응답 거부), 정확도(correctness), 신뢰도(confidence)의 세 가지 요소를 통합한 평가 지표를 도입하였다. 실험을 통해 다양한 프롬프트 기술을 적용하여 모델의 응답 행동을 분석하고, 해결 불가능한 질문에 대한 모델의 경향성을 분석하였다.

- **Performance Highlights**: 실험 결과, GPT 모델들은 해결이 불가능한 문제에 대해 잘못된 정보를 스스로 생성하는 경향이 있으며, 결과적으로 이러한 모델들은 수학 문제 해결에 있어 불확실성과 복잡한 추론을 효과적으로 관리하지 못한다는 점이 밝혀졌다. 이는 향후 모델들이 더 나은 관리와 결정을 내릴 수 있도록 개선이 필요함을 강조한다.



### LoRA Soups: Merging LoRAs for Practical Skill Composition Tasks (https://arxiv.org/abs/2410.13025)
Comments:
          9 pages plus references and appendices

- **What's New**: 이 논문은 Low-Rank Adaptation (LoRA) 기법을 사용하여 여러 LoRA 모듈을 통합하여 기술 조합(skill composition)을 구현하는 방법을 연구합니다. 이 방식은 특정 기술과 지식이 필요한 작업에서 이전 모델 및 데이터 병합 기법보다 우수한 성능을 보입니다.

- **Technical Details**: 주요 기여는 LoRA의 연결(concatenation)을 최적으로 평균화하여 서로 다른 기술로 개별 훈련된 LoRA를 병합하는 새로운 방법인 Learnable Concatenation (CAT)을 제안하는 것입니다. 이는 모델의 일부 층에서 저랭크 업데이트를 추가하여 진행됩니다.

- **Performance Highlights**: CAT는 수학 문제 해결에서 기존 방법에 비해 평균 43% 및 12% 향상을 보이며, LLM의 프롬프트 형식 변화에 대한 견고성도 개선합니다. 본 연구는 기술 조합 작업을 해결하기 위한 효율적인 방법으로 모델 병합을 지지합니다.



### LEGAL-UQA: A Low-Resource Urdu-English Dataset for Legal Question Answering (https://arxiv.org/abs/2410.13013)
Comments:
          8 pages

- **What's New**: LEGAL-UQA는 파키스탄 헌법에서 유래한 첫 번째 우르두 법률 질문-답변(QA) 데이터셋을 소개합니다. 이 데이터셋은 619개의 질문-답변 쌍을 포함하며, 법률 기사의 컨텍스트도 포함되어 있어 낮은 자원 언어의 도메인 특화된 NLP 자원의 필요성을 해결합니다.

- **Technical Details**: 데이터셋 생성 과정은 OCR 추출, 수동 수정 및 GPT-4를 활용한 QA 쌍의 번역 및 생성으로 구성됩니다. LEGAL-UQA의 성능을 평가하기 위해 최신의 일반 언어 및 임베딩 모델을 실험하였으며, Claude-3.5-Sonnet 모델이 인간 평가에서 99.19%의 정확도를 달성하였습니다. 또한, mt5-large-UQA-1.0 모델을 미세 조정하여 다국어 모델을 전문 분야에 적용하는 데 따른 도전 과제를 강조하였습니다.

- **Performance Highlights**: OpenAI의 text-embedding-3-large는 Mistral의 mistral-embed 보다 더 나은 검색 성능을 보였습니다. LEGAL-UQA는 글로벌 NLP 발전과 현지화된 응용 프로그램 간의 격차를 해소하며, 파키스탄 내 법률 정보 접근성을 개선하는 기반을 마련합니다.



### POROver: Improving Safety and Reducing Overrefusal in Large Language Models with Overgeneration and Preference Optimization (https://arxiv.org/abs/2410.12999)
- **What's New**: 최근 대규모 언어 모델(LLM)의 안전성과 유용성 균형을 맞추는 것이 주요 도전 과제가 되고 있습니다. 본 연구는 GPT-4o와 같은 고급 'teacher' 모델을 사용하여 훈련 데이터를 과도하게 생성하는 방식이 안전성(safety)과 과도 거부(overrefusal) 간의 균형에 미치는 영향을 분석합니다.

- **Technical Details**: 본 작업에서는 POROver(Preference Optimization for Reducing Overrefusal)라는 새로운 전략을 통해 고급 teacher 모델의 응답을 활용하여 과도 거부를 줄이기 위한 방법을 제시합니다. 연구 결과에 의하면, 일반적인 목적의 프롬프트에 대해 과도하게 생성된 응답은 안전성과 유용성 간의 균형을 개선하며, F1 점수가 70.8%에서 88.3%로 향상됩니다.

- **Performance Highlights**: 과도 생성된 유해 프롬프트에 대한 응답의 경우, 과도 거부율이 94.4%에서 45.2%로 감소합니다. 또한, Preference Optimization 알고리즘을 활용하면 모델의 과도 거부율을 15.0%로 줄일 수 있으며, 비교 가능한 수준의 안전성을 유지할 수 있습니다.



### "Let's Argue Both Sides": Argument Generation Can Force Small Models to Utilize Previously Inaccessible Reasoning Capabilities (https://arxiv.org/abs/2410.12997)
Comments:
          Accepted to Workshop on Customizable NLP: Progress and Challenges in Customizing NLP for a Domain, Application, Group, or Individual at EMNLP 2024

- **What's New**: 이 연구에서는 논리적 추론이 필요한 상황에서 대규모 언어 모델(LLM)의 성능 강화를 위해 'Argument Generation'(주장 생성)이라는 새로운 기법을 제안합니다.

- **Technical Details**: 주장 생성 기법은 두 단계로 진행됩니다. 첫 번째 단계에서는 가능한 선택지 각각에 대한 주장을 생성하도록 모델에게 지시하고, 두 번째 단계에서는 생성된 주장들을 랭크한 다음, 최종 결과(output)와 일치하도록 매핑합니다. 이 방법은 체인 오브 스로우(Chain-of-Thought) 기법에 비해 더 나은 결과를 도출할 수 있습니다.

- **Performance Highlights**: 실험 결과, 주장 생성 기법은 체인 오브 스로우 기법보다 적어도 동등하거나 우수한 성능을 보이며, 특히 작은 언어 모델에 대해 더 큰 성능 향상을 보여주는 복잡한 관계를 나타냅니다.



### Qtok: A Comprehensive Framework for Evaluating Multilingual Tokenizer Quality in Large Language Models (https://arxiv.org/abs/2410.12989)
Comments:
          24 pages, 9 figures, 6 tables. Code and data available at this https URL

- **What's New**: 이번 연구에서 우리는 Qtok이라는 도구를 도입하여 멀티링구얼 모델에서의 토크나이저 품질을 평가하는 방법론을 제공합니다. 기존의 연구에서는 주로 데이터셋 품질이나 모델 아키텍처에 초점을 맞추었지만, 토크나이저의 중요성은 상대적으로 간과되었습니다.

- **Technical Details**: 연구팀은 Qtok 도구를 통해 58개의 공개 모델에서 13개의 다양한 토크나이저를 평가했습니다. 이 도구는 언어 범위, 토큰 완전성, 언어 및 언어 범주에 따라 분포를 측정하는 지표를 포함하여 토크나이저의 품질을 평가합니다. 또한 코어 토큰 개념을 도입하여 긍정적으로 반복되는 토큰을 구분하였습니다.

- **Performance Highlights**: 분석 결과, 다양한 언어 및 범주에서 토큰 분포의 중요 자질 불균형이 발견되어 현재의 토크나이징 전략에서 개선이 필요한 부분을 강조하였습니다. 연구는 토크나이저의 품질 평가 방법을 제공하고 이로 인해 멀티링구얼 LLM의 성능 향상 가능성을 제시합니다.



### Leveraging LLMs for Translating and Classifying Mental Health Data (https://arxiv.org/abs/2410.12985)
- **What's New**: 이번 연구는 그리스어로 생성된 사용자 게시글을 자동 번역하여 우울증의 심각성을 탐지하는 방법을 탐구합니다. 이는 영어 외의 언어에 대한 LLMs (Large Language Models)의 적용에 대한 연구가 부족한 상황에서 이루어졌습니다.

- **Technical Details**: 연구에서는 GPT3.5-turbo 모델을 사용하여 영어와 그리스어로 작성된 게시글에서 우울증의 심각성을 평가했습니다. LLMs의 결과는 영어에서 우울증을 효과적으로 식별하지 못했고, 그리스어에서도 성과가 다양합니다.

- **Performance Highlights**: 연구 결과, 우울증의 심각성을 인식하는 데 있어 GPT3.5-turbo의 성능이 그리스어에서도 일관되게 낮게 나타났으며, 추가 연구와 인간 감독의 중요성이 강조되었습니다.



### BenchmarkCards: Large Language Model and Risk Reporting (https://arxiv.org/abs/2410.12974)
- **What's New**: 대형 언어 모델(LLMs)의 위험을 줄이기 위한 새로운 프레임워크인 BenchmarkCards가 소개되었습니다. 이 프레임워크는 특정 취약성을 테스트하기 위해 설계된 벤치마크의 문서화 방식을 표준화합니다.

- **Technical Details**: BenchmarkCards는 LLM 벤치마크 속성을 문서화하는 구조적 프레임워크를 제공합니다. 이 프레임워크는 벤치마크 결과를 측정하거나 해석하는 방법을 정의하지 않고, 특정 리스크(위험) 및 평가 방법론에 대한 정보를 제공하는 표준화된 방법을 제공합니다. 포함된 속성으로는 bias(편향) 및 fairness(공정성) 등이 있습니다.

- **Performance Highlights**: 이 구조화된 메타데이터는 연구자들이 적절한 벤치마크를 선택할 수 있도록 도와주며, LLM 평가에서의 투명성과 재현성을 촉진합니다.



### Evaluating the Instruction-following Abilities of Language Models using Knowledge Tasks (https://arxiv.org/abs/2410.12972)
- **What's New**: 이번 연구에서는 과제 성과와 명령 이행 능력을 동시에 쉽게 검증할 수 있는 instruction-following을 위한 벤치마크를 개발하는 데 초점을 맞추었습니다.

- **Technical Details**: 기존의 지식 벤치마크를 수정하고, 올바른 지식 과제 답변에 따라 조건부로 적용되는 지침과 다중 선택 지식 답변 과제에서의 후보 옵션 공간을 활용한 지침으로 보강합니다. 연구에서는 다양한 크기의 공개 대형 언어 모델(1B-405B)과 GPT-4o-mini 및 GPT-4와 같은 폐쇄형 모델을 포함하여, 지침이 간단한 경우에도 LLM들이 따라가지 못하는 문제를 발견했습니다.

- **Performance Highlights**: 이 연구에서는 모델의 zero-shot instruction-following 성능을 평가하는 최초의 벤치마크를 출시하며, 다양한 지침 클래스에서 instruction-following 성능을 조사하고 이를 통해 모델의 지식 작업 수행능력을 질적으로 검토하였습니다.



### Self-Pluralising Culture Alignment for Large Language Models (https://arxiv.org/abs/2410.12971)
Comments:
          Implementation for the paper: this https URL

- **What's New**: 방금 발표된 연구에서 제안된 CultureSPA는 대규모 언어 모델(LLMs)이 여러 문화에 동시적으로 적응할 수 있도록 도와주는 혁신적인 프레임워크입니다. 기존의 기술은 특정 문화의 다양성을 고려하지 않았던 반면, CultureSPA는 LLM의 внутрен적인 문화 지식을 활용하여 이를 해결합니다.

- **Technical Details**: CultureSPA는 첫째, 다양한 문화 주제에 대한 질문을 생성하고, 둘째로, 이러한 질문에 대한 LLM의 출력을 수집합니다. 이 과정은 문화 정보를 제공하지 않는 culture-unaware prompting과 특정 문화에 맞춰 LLM을 유도하는 culture-aware prompting을 포함합니다. 최종적으로 이 데이터를 사용하여 LLM을 문화 간 협업(culture-joint) 및 특정 문화(culture-specific) 방식으로 정교화합니다.

- **Performance Highlights**: 광범위한 실험 결과, CultureSPA는 LLM의 다양한 문화에 대한 적합성을 크게 향상시켰으며, 일반적인 능력에 손상을 주지 않았습니다. 또한 CultureSPA와 고급 prompt engineering 기술을 결합하면 추가 개선이 가능합니다. Impressively, culture-joint vs culture-specific tuning 전략의 비교는 전자가 더 우수함을 보여줍니다.



### Facilitating Multi-turn Function Calling for LLMs via Compositional Instruction Tuning (https://arxiv.org/abs/2410.12952)
- **What's New**: 본 논문에서는 기존의 단일 턴(single-turn) 상호작용과는 달리 다중 턴(multi-turn) 함수 호출을 LLM(대형 언어 모델)이 수행할 수 있는 필요성을 다룹니다. 이는 실제 세계에서 복합적인 쿼리를 처리하는 데 필수적입니다.

- **Technical Details**: 논문에서 제안하는 BUTTON 접근법은 하향식(top-down) 경로 생성과 하향식(bottom-up) 명령 구성 방법을 통해 합성된 지침 튜닝 데이터(synthetic compositional instruction tuning data)를 생성합니다. 하향식 단계에서는 원자적 작업(atomic tasks)을 기반으로 간단한 작업 정의 후, 이러한 작업을 사용하여 합성 작업을 개발합니다. 그런 다음, 하향식 단계에서는 시뮬레이션된 인간, 보조자, 도구 간의 상호작용을 통해 다중 턴 함수 호출 경로를 수집합니다.

- **Performance Highlights**: BUTTONInstruct라는 8천 개 데이터 포인트로 구성된 데이터셋을 제작하였으며, 다양한 LLM에서의 광범위한 실험을 통해 효과성을 입증하였습니다.



### What Do Speech Foundation Models Not Learn About Speech? (https://arxiv.org/abs/2410.12948)
Comments:
          20 Pages

- **What's New**: 본 연구에서는 Whisper, Seamless, Wav2Vec, HuBERT 및 Qwen2-Audio와 같은 여러 음성 기초 모델이 비언어적 신호(Non-verbal cues)를 어떻게 포착하고 있는지를 분석합니다. 특히 이들 모델의 학습된 표현(Representations)과 다양한 작업에서의 일반화 가능성을 평가합니다.

- **Technical Details**: 연구는 Dynamic-SUPERB 벤치마크에서 선택된 다섯 가지 모델의 레이어별 특징을 추출하고, 레이어별 특징에 대한 K-최근접 이웃(K-Nearest Neighbors, KNN) 및 신경망(Neural Networks, NN) 분류기를 훈련시켜 비언어적 신호에 대한 모델의 응답을 측정합니다. 또한, 제로-샷(Zero-shot) 환경에서 모델을 평가하고, 그 결과를 통해 모델의 레이어별 표현의 특성과 다운스트림(Downstream) 작업 적응에 필요한 변화의 정도를 파악합니다.

- **Performance Highlights**: 연구 결과, 일부 모델은 특정 작업에 대해 제로-샷 환경에서도 우수한 성능을 보이며, 이는 모델이 학습한 표현의 질과 상관관계를 나타냅니다. 또한 모델의 깊이에 따른 학습된 표현의 분리 가능성 사이에는 볼록한 관계가 존재하며, 이로 인해 작업 별 특성을 캡처하는 다양한 레이어가 확인됩니다.



### Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging (https://arxiv.org/abs/2410.12937)
Comments:
          Findings of EMNLP 2024

- **What's New**: 이 연구는 기존의 언어 모델에 새로운 기술을 추가하는 방식인 "parallel train then merge" (PTM) 접근법을 소개합니다. PTM은 여러 기술을 모델에 효율적으로 추가 가능하게 하며, 기존 기술을 잊게 하지 않고도 새로운 기술을 통합할 수 있는 장점이 있습니다.

- **Technical Details**: CFT (continued finetuning), RT (retraining), PTM은 기존 모델에 새로운 기술을 추가하기 위한 세 가지 방법입니다. PTM은 새로운 데이터에 대해서만 개별적으로 훈련하여 모델 파라미터를 병합하는 방식으로, 기존 기술을 보존하는 동시에 새로운 기술도 효과적으로 학습할 수 있습니다. 실험은 과학 문헌 이해, 코딩 및 안전 관련 요청 거부에서 진행되었습니다.

- **Performance Highlights**: PTM은 기존의 CFT보다 50–95% 효율적으로 훈련할 수 있으며, 원래 모델의 일반 기술을 거의 모두 유지하면서 새로운 기술에서도 유사한 성능을 달성합니다. 또한, PTM은 안전 관련 거부 능력을 개선하며, 전반적인 성능을 유지할 수 있습니다. 이 연구의 결과는 PTM이 CFT보다 효과적인 옵션이라는 것을 보여줍니다.



### Enhancing Mathematical Reasoning in LLMs by Stepwise Correction (https://arxiv.org/abs/2410.12934)
Comments:
          under review

- **What's New**: 이 논문에서는 Stepwise Correction (StepCo)라는 새로운 프롬프팅 방법을 제안합니다. 이 방법은 LLM이 스스로 생성한 추론 과정에서 잘못된 단계를 식별하고 수정하는 데 도움을 줍니다.

- **Technical Details**: StepCo는 프로세스 기반 슈퍼바이저(PSV)를 이용하여 이전 단계에서 발생한 오류가 다음 단계로 전파되지 않도록 하며, 각 단계의 정확성을 평가하고 수정하는 반복적인 verify-then-revise 프로세스를 적용합니다.

- **Performance Highlights**: StepCo는 여러 데이터세트에서 평균 정확도 94.1%를 달성하며, Best-of-N 방법에 비해 2.4% 높은 성능을 보이면서 토큰 소비를 77.8% 감소시킵니다.



### Interpreting token compositionality in LLMs: A robustness analysis (https://arxiv.org/abs/2410.12924)
Comments:
          15 pages, 2 Figures, 7 tables

- **What's New**: 이번 연구에서는 Constituent-Aware Pooling (CAP)という 새로운 방법론을 제안하여 대형 언어 모델(LLMs)의 구성적 언어 구조 처리 방식을 분석합니다. 이는 LLM의 내부 메커니즘을 이해하고, 신뢰성 및 해석 가능성을 개선하기 위해 필수적입니다.

- **Technical Details**: CAP는 토큰 식별 기법을 사용하여 개별 토큰의 활성화를 응집된 언어 단위로 집계하는 방법입니다. 연구에서는 세 가지 작업(역 정의 모델링, 동의어 예측 및 상위어 예측)을 통해 모델의 성능을 평가하였으며, 여기서 토큰 간의 정보 처리 방식 및 분산 현상을 관찰했습니다. CAP는 단어 수준 및 구문 수준 모두에서 작동하며, 세 가지 집계 모드(최대 집계, 평균 집계, 합계 집계)를 제공합니다.

- **Performance Highlights**: 연구 결과, LLM의 성능은 구성적 활성화 교란이 적용될 때 유의미하게 저하되는 것으로 나타났습니다. 특히 더 큰 모델일수록 이러한 교란에 더 민감한 경향을 보였습니다. 이는 현재의 변환기 아키텍처가 구성적 의미 처리에 있어 한계가 있음을 시사하며, 해결을 위한 새로운 접근 방식이 필요함을 강조합니다.



### MSc-SQL: Multi-Sample Critiquing Small Language Models For Text-To-SQL Translation (https://arxiv.org/abs/2410.12916)
Comments:
          3rd Table Representation Learning Workshop at NeurIPS 2024

- **What's New**: 이 논문에서는 자연어를 SQL로 변환하기 위한 텍스트-투-SQL 생성 기술을 향상시키기 위한 새로운 모델, MSc-SQL을 소개하고 있습니다. 최근 몇 가지 클로즈드 소스 모델에 의존하여 성능이 제한된 문제를 해결하기 위해 작은 오픈 소스 모델을 개발하는 데 중점을 두고 있습니다.

- **Technical Details**: Msc-SQL 모델은 여러 SQL 쿼리를 샘플링하고, 생성된 쿼리의 실행 결과와 메타데이터를 바탕으로 최상의 결과를 선택하는 샘플 비평 모델(sample-critiquing model)을 포함합니다. 이 접근 방식은 여러 후보를 동시에 평가하여 보다 적절한 SQL 쿼리를 생성할 수 있도록 도와줍니다.

- **Performance Highlights**: MSc-SQL는 오픈 소스 모델 중에서 최신 성능을 기록하면서도 기존의 클로즈드 소스 모델과 경쟁력을 유지합니다. 이 모델은 더 낮은 비용으로도 높은 품질의 SQL 쿼리를 생성할 수 있습니다.



### A Survey on Data Synthesis and Augmentation for Large Language Models (https://arxiv.org/abs/2410.12896)
- **What's New**: 이 논문은 대규모 언어 모델(LLM)의 개발에 있어 데이터 합성(data synthesis) 및 증강(augmentation) 기법의 중요성을 강조하며, 전체 생애 주기(lifecycle)와 핵심 기능에 따른 연구를 종합적으로 정리합니다.

- **Technical Details**: 데이터 합성과 증강은 LLM의 훈련과 평가를 위해 필수적으로 사용되며, 기존 데이터에 의존하는 것을 줄이고, 다양한 고품질 데이터를 생성하는 데 중요한 역할을 합니다. 이 연구에서는 LLM의 생애 주기(pre-training, fine-tuning 등)와 핵심 기능(이해, 논리 등)을 중심으로 기존 연구를 분류하고 체계적으로 검토합니다.

- **Performance Highlights**: 이 연구는 LLM 개발의 향후 방향성을 제시하고, 데이터 합성과 증강 기법이 LLM 성능 향상에 기여할 수 있는 가능성을 탐구합니다. 또한, 연구자들이 데이터를 효과적으로 생성하는 방법을 이해할 수 있도록 돕습니다.



### Large Language Models and the Rationalist Empiricist Deba (https://arxiv.org/abs/2410.12895)
- **What's New**: 이 논문은 LLMs(대형 언어 모델)가 Chomsky와 Quine, Skinner 간의 논쟁에 어떻게 영향을 미치는지를 탐구하며, LLMs가 합리주의를 정당화하는 주장과 기존의 경험주의에 대한 비판을 다룬다.

- **Technical Details**: LLMs는 본래의 편향을 내장해야 하며, 이는 언어능력(linguistic competence)을 설명하는 데 있어 경험주의가 개념적 자원을 부족하다는 주장을 뒷받침한다. 그러나 이러한 주장은 사용되는 경험주의의 성격에 의존한다.

- **Performance Highlights**: 인간은 한정된 자극(poverty of stimulus) 속에서도 학습하는 반면, LLMs는 풍부한 자극(rich stimulus) 덕분에 학습한다. 이는 인간과 LLMs가 출력(output)을 생성하는 데에 있어 다른 기본 능력(underlying competencies)을 사용함을 나타낸다.



### MIRROR: A Novel Approach for the Automated Evaluation of Open-Ended Question Generation (https://arxiv.org/abs/2410.12893)
Comments:
          Accepted at FM-Eduassess @ NEURIPS 2024 (ORAL Paper)

- **What's New**: 이번 연구에서는 자동 질문 생성(Automated Question Generation, AQG) 시스템이 생성한 질문의 품질 평가를 자동화하기 위해 대규모 언어 모델(LLM)을 활용하는 새로운 시스템인 MIRROR (Multi-LLM Iterative Review and Response for Optimized Rating)를 제안합니다.

- **Technical Details**: MIRROR는 여러 LLM에 피드백을 제공하여 인간의 평가 지표(grammaticality, relevance, appropriateness, novelty, complexity)에 기반하여 점수를 생성하는 프로세스를 포함합니다. GPT-4, Gemini, Llama2-70b와 같은 최첨단 LLM을 사용하여 실험을 진행하였으며, 인간 전문가의 평가와의 Pearson 상관 계수(Pearson's correlation coefficient)를 측정하여 결과를 비교하였습니다.

- **Performance Highlights**: MIRROR를 적용한 결과, relevance, appropriateness, novelty, complexity, grammaticality와 같은 인간 평가 지표의 점수가 개선되어 인간 기준 점수와 더 가까운 결과를 보였습니다. 더불어 직접 프롬프트를 사용하여 평가한 경우보다 인간 전문가와의 상관 계수가 향상되었습니다.



### Multi-trait User Simulation with Adaptive Decoding for Conversational Task Assistants (https://arxiv.org/abs/2410.12891)
Comments:
          Preprint fron EMNLP 2024 Findings

- **What's New**: 이 논문은 Multi-Trait Adaptive Decoding (mTAD)이라는 새로운 접근 방식을 제안합니다. mTAD는 다양한 trait-specific Language Models (LMs)에서 샘플링하여 디코딩 시간에 다양한 사용자 프로필을 생성하여 사용자 시뮬레이션을 개선합니다.

- **Technical Details**: mTAD는 다양한 대화 trait를 모델링하기 위해 specialized LMs를 결합하는 모델 기반 접근 방식을 따릅니다. 기존의 조합 훈련 데이터나 추가적인 모델 Fine-tuning 없이, trait-specific LM에서 분포를 샘플링하여 동적으로 결합합니다. 이 기법은 사용자 대화 프로필의 다양한 조합을 가능하게 하여 더 풍부한 대화 패턴을 생성합니다.

- **Performance Highlights**: 실험 결과, mTAD는 단일 trait 모델링에서 효과적임을 입증하며, 아울러 특정 패턴을 포착할 수 있는 능력을 보여줍니다. mTAD는 다양한 사용자 시뮬레이터를 결합하는 데 강력하고 유연한 프레임워크로, 기존 LM을 재훈련할 필요 없이 새로운 traits를 추가할 수 있습니다.



### REFINE on Scarce Data: Retrieval Enhancement through Fine-Tuning via Model Fusion of Embedding Models (https://arxiv.org/abs/2410.12890)
Comments:
          Accepted in AJCAI'24

- **What's New**: 본 논문에서는 데이터 부족 문제를 해결하기 위해 REFINE이라는 새로운 접근 방식을 제안합니다. 이 방법은 효과적인 검색을 개선하기 위해 사용 가능한 문서에서 합성 데이터를 생성하고, 모델 융합(Model Fusion) 기법을 통해 임베딩을 향상시킵니다.

- **Technical Details**: REFINE은 LLM(대규모 언어 모델)을 활용하여 사용 가능한 비지도 문서에서 대조적 훈련 데이터셋을 생성합니다. 생성된 데이터셋은 표준 파인튜닝 방법을 통해 임베딩 모델의 성능을 개선하며, 새로운 데이터 특정 학습을 포함하는 모델 융합 기법을 도입하여 성능을 더욱 향상시킵니다.

- **Performance Highlights**: SQUAD 및 RAG-12000 데이터셋과 독점 TOURISM 데이터셋에서 실험을 수행한 결과, REFINE이 적용된 표준 파인튜닝이 기본 사전 훈련 모델에 비해 더 나은 성능을 보였고, TOURISM 데이터셋에서는 5.76%, SQUAD 데이터셋에서는 6.58%의 개선을, RAG-12000 데이터셋에서는 0.32%의 향상을 기록했습니다.



### AT-RAG: An Adaptive RAG Model Enhancing Query Efficiency with Topic Filtering and Iterative Reasoning (https://arxiv.org/abs/2410.12886)
- **What's New**: AT-RAG라는 새로운 멀티스텝 RAG 모델을 제안하여, 복잡한 다중 단계 쿼리를 보다 효율적으로 처리하는 방법을 소개합니다.

- **Technical Details**: AT-RAG는 BERTopic을 활용하여 쿼리의 주제를 동적으로 할당함으로써 문서 검색 및 추론 과정의 정확성과 효율성을 향상시킵니다. 이 모델은 Chain-of-Thought (CoT) 추론을 통합하여 반복적인 문서 검색 및 추론을 가능하게 합니다.

- **Performance Highlights**: AT-RAG는 기존 RAG 모델 대비 Accuracy, Completeness, Relevance에서 현저한 개선을 보였으며, 특히 의료 QA와 같은 복잡한 도메인-specific 문제 해결에 적합합니다. 모델은 다양한 benchmark dataset에서 높은 성능을 발휘하였고, 검색 시간을 줄이면서 높은 정밀도를 유지합니다.



### Scaling Laws for Multilingual Language Models (https://arxiv.org/abs/2410.12883)
- **What's New**: 본 연구에서는 다국어 데이터로 훈련된 일반 목적의 디코더 전용 언어 모델을 위한 새로운 스케일링 법칙을 제안합니다. 각 언어의 성능을 개별적으로 분석하기 어려운 문제를 다루기 위해, 우리는 개별 언어 대신 언어 가족에 초점을 맞추고, 각 언어 가족의 테스트 교차 엔트로피 손실(test cross-entropy loss)은 혼합 내 다른 언어와 무관하게 샘플링 비율(sampling ratio)에 의해 결정된다는 가설을 검증했습니다.

- **Technical Details**: 제안한 스케일링 법칙은 테스트 교차 엔트로피 손실을 모델 크기(model size), 데이터셋 크기(dataset size), 샘플링 비율(sampling ratios)과 연결하는 전력 법칙(power-law relationship)을 도출합니다. 이를 통해 다양한 조합에 대한 성능 예측이 가능해졌으며, 훈련 혼합 내 언어 가족의 최적 샘플링 비율을 도출할 수 있게 되었습니다. 우리는 23개 언어, 5개 언어 가족을 대상으로 100개 이상의 모델을 훈련하여 대규모 실증 연구를 수행했습니다.

- **Performance Highlights**: 실험 결과, 작은 모델(85M 파라미터)에서 도출한 최적 샘플링 비율이 수십 배 큰 모델(1.2B 파라미터)에도 효과적으로 일반화됨을 보여주었습니다. 이는 리소스를 효율적으로 사용할 수 있는 다국어 언어 모델 훈련을 위한 접근 방식을 제공합니다.



### Navigating the Cultural Kaleidoscope: A Hitchhiker's Guide to Sensitivity in Large Language Models (https://arxiv.org/abs/2410.12880)
- **What's New**: 이 논문은 글로벌 AI 애플리케이션에서 LLMs의 문화적 민감성을 보장하는 중요성을 강조하며, 작은 매개변수 모델 내에서 발생하는 문화적 손해를 다루기 위한 두 개의 주요 기여를 제시합니다. 첫째, 다양한 문화적 맥락에서 모델의 출력을 평가하기 위한 문화적 손해 테스트 데이터셋을 소개합니다. 둘째, 다양한 주석자 피드백을 기반으로 문화적 민감성을 회복하기 위한 데이터셋을 제안합니다.

- **Technical Details**: 이 연구는 문화적 손해 평가 데이터셋과 문화적 정렬 선호 데이터셋을 구축하여 작은 매개변수 LLMs의 문화적 민감성을 높이고 해로운 출력을 줄이는 것을 목표로 합니다. 데이터셋은 사회적, 정치적, 경제적, 종교적, 문화적 가치를 반영하며, 다양한 문화적 맥락에서 모델 출력을 시스템적으로 평가할 수 있는 프레임워크를 제공합니다. 또한, reinforcement learning from human feedback (RLHF) 기법을 사용하여 문화적 기준을 존중하는 모델의 미세 조정을 지원합니다.

- **Performance Highlights**: 문화적 정렬 피드백을 통합함으로써 Mistral-v0.2(7B) 모델의 해로운 출력 발생률이 71.96%에서 3.07%로 급격히 감소하는 등의 성과를 보였습니다. 이 연구는 LLM이 다양한 문화적 경관에서 안전하고 윤리적으로 탐색할 수 있는 미래의 AI 시스템을 구축하는 데 기여할 것입니다.



### Exploring transfer learning for Deep NLP systems on rarely annotated languages (https://arxiv.org/abs/2410.12879)
- **What's New**: 이 논문은 자연어 처리(NLP) 분야에서 힌디어와 네팔리 언어 간의 Part-of-Speech (POS) 태깅에 대한 전이 학습(Transfer Learning)의 응용을 연구합니다. 특히, 두 언어의 공동 훈련이 성능 향상에 기여하는지를 탐구합니다.

- **Technical Details**: 연구에서는 BLSTM-CNN-CRF(변형 장기 단기 기억-합성곱 신경망-조건부 무작위 필드) 모델을 사용하며, 단일 언어(word embeddings), 벡터 매핑 임베딩(vector-mapped embeddings), 공동 훈련된 힌디어-네팔리 단어 임베딩(jointly trained Hindi-Nepali word embeddings)에서의 결과를 비교합니다. 다양한 드롭아웃 비율(0.25~0.5)과 최적화 알고리즘(ADAM, AdaDelta)을 평가합니다.

- **Performance Highlights**: 결과는 공동 훈련된 힌디어-네팔리 단어 임베딩이 단일 언어 및 벡터 매핑 임베딩에 비해 모든 모델에서 성능을 향상시킴을 보여줍니다.



### Towards More Effective Table-to-Text Generation: Assessing In-Context Learning and Self-Evaluation with Open-Source Models (https://arxiv.org/abs/2410.12878)
Comments:
          15 pages

- **What's New**: 이 연구는 자연어 처리의 핵심 작업인 테이블-텍스트 생성(table-to-text generation)에 대해, 다양한 in-context learning 전략의 효과를 평가합니다. 특히, 모델에 주어진 예제가 성능에 미치는 영향을 조사하고, 실제 애플리케이션을 기반으로 한 사례를 제공합니다.

- **Technical Details**: 모델은 zero-shot, single-shot, few-shot 프롬프트를 사용하여 테이블 데이터에서 내러티브 텍스트로 전환합니다. 이 연구에서는 두 개의 벤치마크 데이터셋인 WikiBio와 ToTTo에서 실험이 수행되었고, Llama 3와 Phi-3 모델을 사용하여 결과를 비교했습니다. 또한, GPT-4를 사용하여 초기 프롬프트를 생성하고, 이를 기반으로 최적화를 진행하였습니다.

- **Performance Highlights**: 예제를 제공함으로써 테이블-텍스트 생성의 성능이 크게 향상되었습니다. LLM 자가 평가 방법은 아직 인간의 판단과 일치도가 개선되어야 하지만, overall 성능 개선을 확인할 수 있었습니다.



### Improving Instruction-Following in Language Models through Activation Steering (https://arxiv.org/abs/2410.12877)
- **What's New**: 이 논문에서는 언어 모델(LLM)의 지침 따르기 능력을 향상시키기 위한 새로운 접근 방식을 제안합니다. 이는 지침에 따라 모델의 동작을 조정하기 위해 지침별 벡터 표현을 파생하는 내용을 다룹니다.

- **Technical Details**: 이 연구는 입력의 지침이 없는 경우와 있는 경우의 활성화(activation)의 차이를 기반으로 벡터 표현을 계산하여 모델의 출력을 조작하는 방식입니다. 사용된 활성화 벡터는 출력 형식, 길이, 특정 단어 포함 여부 등 여러 조건을 모델이 준수하도록 유도합니다.

- **Performance Highlights**: 4개의 서로 다른 모델을 대상으로 한 실험을 통해, 이 방법이 지침을 명시적으로 제공하지 않아도 모델이 제약사항을 따르도록 도와주고, 지침이 있을 때도 성능을 향상시킬 수 있음을 보여주었습니다. 또한, 여러 지침을 동시에 적용할 수 있다는 것이 확인되었습니다.



### In-context KV-Cache Eviction for LLMs via Attention-Ga (https://arxiv.org/abs/2410.12876)
- **What's New**: 본 논문은 Attention-Gate라는 매개변수화된 KV-Cache 제거 메커니즘을 도입하여 비효율적인 기존 제거 전략의 한계를 극복하려고 합니다. 이는 입력된 전체 컨텍스트를 기준으로 각 토큰의 제거 플래그를 생성하여 효율적인 in-context eviction을 실현합니다.

- **Technical Details**: Attention-Gate(AG)는 모델 내의 self-attention 레이어 전방에 위치하여, 입력된 토큰 특징 시퀀스를 처리하여 각 토큰에 대한 제거 플래그를 생성합니다. AG는 사전 훈련된 대형 언어 모델에 무리 없이 통합될 수 있으며, 최소한의 컴퓨팅 및 메모리 오버헤드를 가지면서 효율적입니다.

- **Performance Highlights**: 효율적인 지속적 사전 훈련(CPT) 후에, 기존의 훈련 없는 제거 전략보다 더 높은 평균 정확도를 달성하며 더 많은 토큰을 제거할 수 있음을 증명합니다. Supervised fine-tuning(SFT)에서는 LoRA로 미세 조정된 LLM보다 성능이 우수하며, RTE 데이터셋에서 13.9%의 정확도 향상과 62.8%의 토큰 제거를 달성하여 중복 토큰의 효과적인 제거가 성능을 개선할 수 있음을 나타냅니다.



### On Debiasing Text Embeddings Through Context Injection (https://arxiv.org/abs/2410.12874)
- **What's New**: 이 논문에서는 텍스트 임베딩 모델에서의 편향(bias)을 정량화하고, 그로부터 방지 성능을 평가하기 위해 19개의 임베딩 모델을 체계적으로 분석하였습니다. 최신 컨텍스트 인젝션(context injection) 기법을 활용하여 이들 모델의 편향을 줄이는 새로운 알고리즘을 제안합니다.

- **Technical Details**: 저자들은 두 가지 기존 기법인 기하학적 투영(geometric projection)과 WEAT(Word Embedding Association Test)를 수정하여 19개 임베딩 모델의 편향을 정량화합니다. 각 모델은 서로 다른 강도와 부분에서 편향(예: 성별, 나이)에 따라 평가받습니다. 또한 컨텍스트를 주입하여 편향을 감소시키는 방법론을 이용해 모델의 반응성을 측정합니다.

- **Performance Highlights**: 결과적으로 성능이 높은 임베딩 모델은 일반적으로 더 많은 편향을 캡처하는 경향이 있지만, 컨텍스트를 포함할 경우 편향을 줄이는 데 더 잘 대응한다고 밝혀졌습니다. 본 연구에서 제안하는 새로운 알고리즘은 동적으로 선택된 k 값에 대해 효과적인 검색 결과를 제공할 수 있습니다.



### Beyond Right and Wrong: Mitigating Cold Start in Knowledge Tracing Using Large Language Model and Option Weigh (https://arxiv.org/abs/2410.12872)
Comments:
          11 pages

- **What's New**: 이 논문에서는 LOKT 모델을 소개하여 Knowledge Tracing (KT)의 콜드 스타트 문제를 해결합니다. LOKT는 대규모 언어모델(LLM)을 사용하여 적은 이전 데이터로도 학습자의 지식 상태를 추적하고 예측할 수 있는 방법론을 제시합니다.

- **Technical Details**: LOKT 모델은 전통적인 KT 모델에 옵션 가중치를 통합하여 단순한 정답/오답 분류를 넘어 학습자의 다양한 잘못된 응답을 분석합니다. 이를 통해 LLM이 언어 기반 정량적 정보를 활용하여 학습자의 이해도를 보다 정확하게 평가할 수 있도록 합니다.

- **Performance Highlights**: 5개의 공공 데이터셋을 사용한 실험에서 LOKT 모델은 이른 단계의 개인화 학습 도구를 지원하며, '학습자 콜드 스타트'와 '시스템 콜드 스타트' 상황에서도 높은 예측 정확도를 유지하는 것을 보여주었습니다.



### Skill Learning Using Process Mining for Large Language Model Plan Generation (https://arxiv.org/abs/2410.12870)
Comments:
          12 pages, 5 figures, 2 tables, accepted at ICPM 2024'

- **What's New**: 이 논문에서는 대형 언어 모델(LLM)의 계획 생성을 개선하기 위해 프로세스 마이닝( process mining ) 기법을 통합한 새로운 기술 학습 접근 방식을 소개합니다. 이 접근 방식은 계획 생성 과정의 효율성과 해석 가능성을 향상시키는 것을 목표로 합니다.

- **Technical Details**: 텍스트 베이스 LLM 플래너가 생성한 단순 시퀀스 대신, 프로세스 모델을 사용하여 구조화된 제어 흐름을 만들고 이를 통해 플래너의 능력을 향상시키는 방법을 제안합니다. 새로운 기술 학습 프레임워크에서는 Inductive Miner 알고리즘을 사용하여 일반적인 프로세스 모델을 추출합니다.

- **Performance Highlights**: 실험 결과, 제안한 기술 검색 방법이 특정 조건에서 기존의 정확도 기준을 초과하는 것으로 나타났으며, 유연한 기술 발견과 병렬 실행을 지원하여 성능이 향상되었습니다.



### Language Model Preference Evaluation with Multiple Weak Evaluators (https://arxiv.org/abs/2410.12869)
- **What's New**: 이 논문에서는 효율적인 평가 방식의 필요성을 강조하며 신뢰성 있는 LLM(대규모 언어 모델) 출력 평가를 위한 새로운 방법론인 GED(Preference Graph Ensemble and Denoise)를 소개합니다.

- **Technical Details**: GED는 두 가지 주요 단계로 구성됩니다: (1) 여러 LLM의 평가 결과를 통합하여 단일 preference graph(선호 그래프)를 만드는 graph ensemble과 (2) 반복적 패턴과 불일치를 제거하여 방향 비순환 그래프(DAG) 구조를 보장하는 graph denoising입니다.

- **Performance Highlights**: GED는 실험 결과에서 10개 벤치마크 데이터셋을 통해 기존 방법들보다 우수한 성능을 보였으며, 예를 들어, 응답 선택 작업에서 평균 4.51% 향상을 기록했습니다. GED는 약한 평가자(combiner) 조합을 통해 강한 평가자보다 뛰어난 성능을 보여, 평가 신뢰성을 높이고 모델 성능을 향상시키는 능력을 입증했습니다.



### Empowering Dysarthric Speech: Leveraging Advanced LLMs for Accurate Speech Correction and Multimodal Emotion Analysis (https://arxiv.org/abs/2410.12867)
Comments:
          19 pages, 6 figures, 3 tables

- **What's New**: 이번 논문은 뇌 손상으로 인해 발생하는 운동 언어 장애인 발음장애(dysarthria)의 인식 및 번역에 대한 새로운 접근 방식을 제시합니다. 이 연구는 발음장애를 가진 개인들이 보다 효과적으로 소통할 수 있도록 지원하기 위해 고급 언어 모델(large language models)을 활용합니다.

- **Technical Details**: 이 연구에서는 OpenAI Whisper 모델을 사용하여 발음장애의 음성을 텍스트로 변환한 후, LLaMA 3.1(70B) 및 Mistral 8x7B와 같은 모델을 미세 조정하여 왜곡된 입력으로부터 의도된 문장을 예측합니다. 데이터 세트는 TORGO 데이터 세트와 Google 음성 데이터를 결합하였으며, 감정 컨텍스트를 수작업으로 라벨링하여 모델 학습에 사용합니다.

- **Performance Highlights**: 제안된 시스템은 발음장애의 음성을 재구성하고 감정을 인식하는 데 있어 높은 정확도를 달성하며, 이는 실질적인 음성 데이터와 비교했을 때 눈에 띄는 발전을 보여줍니다. 이 접근 방식은 발음장애 사용자를 위한 보다 포괄적이며 효과적인 커뮤니케이션 지원 도구를 제공합니다.



### Towards Homogeneous Lexical Tone Decoding from Heterogeneous Intracranial Recordings (https://arxiv.org/abs/2410.12866)
Comments:
          Preprint V1 with 10 pages main text

- **What's New**: 최근 뇌-컴퓨터 인터페이스(BCI)의 발전으로 인해 두개내(recordings)에서 음조(lexical tones)를 해독하는 것이 가능해졌습니다. 이는 언어 손상으로 인해 의사소통 능력이 제한된 사람들에게 도움을 줄 수 있는 잠재력을 제공합니다. 하지만 생리적 및 기기적 요소로 인해 발생하는 데이터 이질성(data heterogeneity)은 통합적인 뇌 음조 해독에 상당한 도전 과제가 됩니다.

- **Technical Details**: 이 논문에서는 H2DiLR(Homogeneity-Heterogeneity Disentangled Learning for neural Representations)이라는 새로운 프레임워크를 도입하여, 여러 피험자의 두개내 기록에서 동질성과 이질성을 분리하고 학습합니다. 이 연구에서는 407개의 음절(syllables)을 포함하는 중국어 재료를 읽는 여러 참가자로부터 스테레오전자뇌전도(sEEG) 데이터를 수집했습니다.

- **Performance Highlights**: 광범위한 실험을 통해 H2DiLR은 기존의 이질적인 해독 접근 방식보다 현저히 우수한 성능을 보임을 입증했습니다. 또한 H2DiLR이 신경 표현 학습 과정에서 동질성과 이질성을 효과적으로 포착함을 실증적으로 확인하였습니다.



### ELF-Gym: Evaluating Large Language Models Generated Features for Tabular Prediction (https://arxiv.org/abs/2410.12865)
- **What's New**: ELF-Gym 프레임워크를 통해 LLM이 생성한 feature의 품질을 정량적으로 평가하는 새로운 방법론을 제시합니다.

- **Technical Details**: ELF-Gym은 Kaggle 대회에서 수집한 251개의 'golden' features를 기준으로 LLMs의 feature 엔지니어링 능력을 평가합니다. 평가 과정에서 LLM이 생성한 features의 다운스트림 모델 성능과 전문가가 제작한 features와의 의미적, 기능적 유사성을 측정합니다.

- **Performance Highlights**: 최선의 경우, LLM은 'golden' features의 약 56%를 의미적으로 포착할 수 있지만, 복잡한 feature가 요구되는 데이터셋에서는 실패할 수도 있습니다.



### Investigating Implicit Bias in Large Language Models: A Large-Scale Study of Over 50 LLMs (https://arxiv.org/abs/2410.12864)
- **What's New**: 이번 연구에서는 최신 대규모 언어 모델(LLM)들이 내재된 편향(implicit bias)을 가지고 있으며, 이러한 편향이 개발된 모델의 크기나 복잡성이 증가함에 따라 강화되고 있다는 점을 강조합니다. 또한, 편향 완화(bias mitigation)가 모델 개발에서 보편적으로 우선시되지 않고 있다는 사실을 강조합니다.

- **Technical Details**: 연구진은 50개 이상의 LLM을 대상으로 LLM Implicit Association Test (IAT) Bias 및 LLM Decision Bias 측정을 통해 내재된 편향의 정도를 탐구했습니다. 이 연구는 대규모 실험을 통해 신 모델에서 더 높은 편향 수준을 관찰하였으며, 이는 합성 데이터의 사용 증가와 관련이 있을 수 있다고 가정합니다.

- **Performance Highlights**: 새로운 또는 더 큰 언어 모델들이 자동으로 편향 수준이 감소하지 않으며, 때때로 이전 모델들보다 높은 편향 점수를 나타내기도 했습니다. 이러한 발견은 공정하고 책임감 있는 AI 시스템 개발을 위한 편향 탐지 및 완화 전략의 필요성을 강조합니다.



### Enhancing Affinity Propagation for Improved Public Sentiment Insights (https://arxiv.org/abs/2410.12862)
- **What's New**: 이 연구는 감독 학습(supervised learning)에 의존하지 않고 감정 분석(sentiment analysis)을 수행하기 위한 비감독 학습(unsupervised learning) 기술을 도입합니다. 특히 Affinity Propagation (AP) 클러스터링 기법을 사용합니다.

- **Technical Details**: AP 클러스터링은 사전 정의된 클러스터 수 없이 텍스트 데이터를 자연적인 패턴에 따라 그룹화합니다. 이 논문에서는 텍스트 표현을 위한 TF-IDF 벡터화(TF-IDF Vectorization)와 차원 축소(principal component analysis, PCA) 기법을 사용하여 AP 클러스터링과 K-평균 클러스터링(K-means clustering)을 비교합니다. AP는 Agglomerative Hierarchical Clustering과 결합하여 성능을 향상시킵니다.

- **Performance Highlights**: AP와 Agglomerative Hierarchical Clustering의 조합이 K-평균보다 현저히 더 우수한 성능을 보였으며, 실험 평가는 Silhouette Score, Calinski-Harabasz Score, Davies-Bouldin Index를 통해 진행되었습니다. 이 연구는 널리 사용되는 레이블 데이터에 대한 필요 없이 대중 감정을 분석할 수 있는 스케일 가능하고 효율적인 비감독 학습 프레임워크를 제안하여 자연어 처리(NLP) 분야에 기여합니다.



### Scaled and Inter-token Relation Enhanced Transformer for Sample-restricted Residential NILM (https://arxiv.org/abs/2410.12861)
Comments:
          Submitted to 27th IEEE-ICCIT

- **What's New**: 이 논문은 Non-Intrusive Load Monitoring (NILM)에서 transformer 모델의 훈련을 개선하기 위한 새로운 두 가지 메커니즘을 제안합니다. 이는 작은 규모의 데이터셋에서 transformer의 성능을 향상시키는 데 중점을 둡니다.

- **Technical Details**: 제안된 두 가지 메커니즘은 inter-token relation enhancement mechanism과 dynamic temperature tuning mechanism입니다. 첫 번째 메커니즘은 훈련 중에 토큰 유사성 행렬에서 intra-token의 중요도를 줄이고 inter-token에 집중도를 높입니다. 두 번째 메커니즘은 토큰 유사성 행렬에 대해 학습 가능한 온도 조정을 도입하여 고정 온도 값에 수반되는 과도한 smoothing 문제를 완화합니다.

- **Performance Highlights**: REDD 주거용 NILM 데이터셋을 사용한 실험 결과, 제안된 방법이 원래 transformer 모델보다 여러 가전 제품 유형에서 성능을 현저히 향상시키는 것으로 나타났습니다.



### LLMD: A Large Language Model for Interpreting Longitudinal Medical Records (https://arxiv.org/abs/2410.12860)
- **What's New**: LLMD는 환자의 의료 기록을 기반으로 의료 이력을 분석하도록 설계된 대규모 언어 모델이며, 의료 지식과 레이블이 지정된 장기 기록을 결합하여 정확한 환자 건강 정보를 제공한다.

- **Technical Details**: LLMD는 10년 이상의 치료 기록과 140개 이상의 치료 기관에서 수집된 대량의 데이터를 포함하여, 지속적인 프리트레이닝(pretraining)과 작업 기반 지침 세밀 조정(instruction fine-tuning)을 통해 훈련된다. 이 구조화(structuring) 및 추상화(abstraction) 작업은 의료 기록의 메타데이터와 임상명명 엔티티(clinical named-entities)를 식별하고 정규화하여 높은 수준의 표현으로 변환한다.

- **Performance Highlights**: LLMD-8B는 PubMedQA 텍스트 응답에서 최첨단 정확도를 달성하며, 기존의 크고 일반화된 모델 및 도메인 맞춤형 모델보다 우수한 성능을 보인다. 실제 환자 데이터를 분석할 때, 의료 지식이 아닌 프리트레이닝과 세밀 조정의 중요성을 강조하며 LLM의 의료 활용을 위한 격차에 대해 논의한다.



### Enhancing Long Context Performance in LLMs Through Inner Loop Query Mechanism (https://arxiv.org/abs/2410.12859)
- **What's New**: 이번 논문에서는 Inner Loop Memory Augmented Tree Retrieval (ILM-TR)이라는 혁신적인 접근법을 통해 복잡한 질문에 대한 보다 깊이 있는 답변 생성을 가능하게 하는 새로운 메모리 체계를 도입합니다. 이 메커니즘은 초기 질문뿐만 아니라 중간 결과에 기반한 내부 루프 쿼리를 활용하여 정보를 검색합니다.

- **Technical Details**: ILM-TR 방법은 기본적으로 두 부분으로 구성되어 있습니다: retriever와 inner-loop query. Retriever 부분에서는 RAPTOR의 트리 빌드 방법을 사용하여 원시 데이터를 짧고 연속적인 텍스트 청크로 분할하고, 각 청크의 요약을 생성합니다. Inner-loop 쿼리는 LLM을 사용하여 최종 답변을 생성하며, Short-Term Memory (STM)라는 영역에 정보를 저장하고, 전달된 데이터를 바탕으로 반복적으로 쿼리를 수행합니다.

- **Performance Highlights**: ILM-TR 시스템은 Multi-Needle In A Haystack (M-NIAH) 및 BABILong과 같은 표준 긴 컨텍스트 벤치마크에서 기존 RAG 방법을 초월하는 성능을 보여주며, 500k tokens까지 컨텍스트 길이가 증가해도 성능 저하 없이 지속적인 성능을 유지합니다.



### Large Language Models for Medical OSCE Assessment: A Novel Approach to Transcript Analysis (https://arxiv.org/abs/2410.12858)
- **What's New**: 이번 연구에서는 대규모 언어 모델(LLMs)을 활용하여 의료 기초 교육 과정에서의 학생의 의사소통 능력을 평가하는 가능성을 탐구하였습니다. 기존의 수작업 평가 방식에 비해 시간과 비용을 절감할 수 있는 자동화된 OSCE 평가 시스템을 제안합니다.

- **Technical Details**: 연구에서 2,027개의 OSCE 비디오 데이터를 활용하여 학생의 환자 의료 정보 요약 능력을 평가하였습니다. Whisper-v3를 사용하여 음성을 텍스트로 변환한 후, GPT-4를 포함한 다양한 LLM 기반 접근 방식을 통해 학생의 성과를 채점하였습니다. 연구에서는 zero-shot prompting, retrieval augmented generation 및 다중 모달 앙상블 기법을 적용하였습니다.

- **Performance Highlights**: GPT-4는 인간 채점자와의 코헨 카파(Cohen's kappa) 지수 0.88을 기록하여 LLM 기반 OSCE 채점의 가능성을 보여주었습니다. 오픈 소스 모델 또한 유망한 결과를 보였으며, 자동 채점 시스템의 구현 가능성을 제시하였습니다.



### Enterprise Benchmarks for Large Language Model Evaluation (https://arxiv.org/abs/2410.12857)
- **What's New**: 이 연구는 대규모 언어 모델(LLM)의 평가를 위한 새로운 벤치마크를 제시합니다. 이는 금융 서비스, 법률, 사이버 보안 및 기후 변화와 지속 가능성과 같은 다양한 기업 도메인에서의 NLP 작업을 포함하는 25개의 공개 데이터셋을 활용합니다.

- **Technical Details**: 본 연구에서는 LLM 평가를 위한 프레임워크를 개발하여, 각 도메인에 맞는 성능 지표와 벤치마크를 제공합니다. 이 프레임워크는 Stanford의 HELM을 보강하여, 도메인별로 구체화된 벤치마크를 추가하고 이를 통해 LLM의 성능을 측정할 수 있는 구조를 갖추고 있습니다.

- **Performance Highlights**: 13개의 모델을 다양한 기업 작업에 적용하여 성능을 평가한 결과, 특정 작업의 요구사항에 맞는 모델 선택의 중요성이 드러났습니다. 이 연구는 실질적인 기업 애플리케이션의 요구를 반영한 벤치마크와 평가 메트릭을 통해 LLM의 최적화를 도울 것으로 기대됩니다.



### Optimized Biomedical Question-Answering Services with LLM and Multi-BERT Integration (https://arxiv.org/abs/2410.12856)
Comments:
          10 pages, 12 figures, accepted and to be published in the proceedings of 2024 IEEE International Conference on Data Mining Workshops (ICDMW)

- **What's New**: 이 논문에서는 대형 언어 모델(LLMs)과 Multi-BERT 구성을 통합하여 생물의학적 질문-응답(QA) 서비스를 개선하는 정교한 접근 방식을 제안합니다. 이 시스템은 복잡한 생물의학 데이터의 방대한 양을 처리하고 우선 순위를 매기는 능력을 향상시켜 의료 전문가들이 더 나은 환자 결과 및 정보에 기반한 의사 결정을 내릴 수 있도록 지원하는 것을 목표로 합니다.

- **Technical Details**: BERT(Bidirectional Encoder Representations from Transformers) 및 BioBERT 모델의 혁신적인 사용과 다층 퍼셉트론(MLP) 레이어의 결합을 통해, 의료 부문의 증가하는 요구에 대해 보다 전문화되고 효율적인 응답을 제공합니다. 이 접근 방식은 과적합(overfitting) 문제를 해결하기 위해 하나의 BERT 모델을 동결(freeze)하면서 다른 모델을 훈련(training)하는 방법을 사용하여 QA 서비스의 전반적인 적응성을 개선합니다.

- **Performance Highlights**: BioASQ 및 BioMRC와 같은 대규모 데이터셋을 사용하여 QA 서비스 성능의 주요 지표에서 상당한 개선을 나타내는 것을 입증합니다. 이 작업은 고급 언어 모델이 의료 분야에서 실질적인 차이를 만들 수 있는 방법을 강조하며, 복잡한 정보를 관리하는 전문가들을 위해 신뢰할 수 있고 반응성이 뛰어난 도구를 제공합니다.



### JAILJUDGE: A Comprehensive Jailbreak Judge Benchmark with Multi-Agent Enhanced Explanation Evaluation Framework (https://arxiv.org/abs/2410.12855)
- **What's New**: 이번 연구에서는 jailbreak 공격에 대한 LLMs의 방어력 평가를 위한 새로운 벤치마크인 JAILJUDGE를 제안합니다. 이 벤치마크는 다양한 리스크 시나리오를 포함하고 있으며, 고품질의 인간 주석이 포함된 데이터셋으로 구성되어 있습니다.

- **Technical Details**: JAILJUDGE 데이터셋은 35k 이상의 instruction-tune 데이터를 포함하며, JailJudge MultiAgent 프레임워크를 통해 명시적 reasoning(추론)을 바탕으로 한 세밀한 평가가 가능합니다. JAILJUDGE Guard는 instruction-tuning된 종합적인 평가 모델로 비용 없이 reasonability 설명을 제공합니다.

- **Performance Highlights**: JailJudge 메소드의 성능은 다양한 모델(GPT-4, Llama-Guard 등)에서 최첨단을 나타냅니다. JailBoost는 성능을 29.24% 향상시켰고, GuardShield는 방어 ASR을 40.46%에서 0.15%로 감소시켰습니다.



### TPO: Aligning Large Language Models with Multi-branch & Multi-step Preference Trees (https://arxiv.org/abs/2410.12854)
- **What's New**: 본 연구에서는 기존의 DPO(Direct Preference Optimization) 알고리즘에서 발생하는 한계를 극복하기 위해 TPO(Tree Preference Optimization)를 제안합니다. TPO는 선호 트리(preference tree)에서 대응하는 응답을 샘플링하는 대신, 전체 선호 트리로부터 직접 학습합니다.

- **Technical Details**: TPO는 언어 모델 정렬을 Preference List Ranking 문제로 정의하며, 이는 주어진 프롬프트에 대한 응답의 순위가 매겨진 선호 리스트로부터 더 효과적으로 학습할 수 있도록 합니다. 또한, Adaptive Step Reward를 사용하여 긴 체인의 추론에서 LLM이 차별화된 단계를 인식하는 데 도움을 주고, 각 단계의 보상 값(reward values)을 조정하여 세밀한 선호 최적화(fine-grained preference optimization)를 수행합니다.

- **Performance Highlights**: TPO는 수학적 추론(task)에서의 실험을 통해 DPO보다 세 가지 공개 대형 언어 모델에 대해 네 개의 데이터셋에서 일관되게 우수한 성능을 보였습니다.



### Diversity of Thought Elicits Stronger Reasoning Capabilities in Multi-Agent Debate Frameworks (https://arxiv.org/abs/2410.12853)
Comments:
          11 pages, 9 figures

- **What's New**: 이 연구는 대형 언어 모델(LLMs)의 추론 능력과 사실 정확성을 개선하기 위한 다중 에이전트 토론(multi-agent debate) 프레임워크를 제안합니다. 특히, 다양한 모델을 활용한 경우에 더 뛰어난 성능을 발휘했으며, GPT-4와 비교하여 더 높은 정확성을 기록하였습니다.

- **Technical Details**: 다중 에이전트 토론 프레임워크는 질문 인코딩, 토론 모델, 토론 라운드, 응답 요약, 반복적 정제 및 최종 요약의 여섯 가지 주요 구성 요소로 이루어져 있습니다. 이 과정에서 다양한 모델 아키텍처를 활용하여 각 모델의 사고 다양성에 기반한 강력한 논리를 생성합니다.

- **Performance Highlights**: 이 연구에서 사용한 중간 용량 모델 세트(Gemini-Pro, Mixtral 7BX8,와 PaLM 2-M)는 4회 토론 후 GSM-8K 벤치마크에서 91%의 정확도를 기록하여 GPT-4를 초월하였고, ASDiv 벤치마크에서는 94%로 새로운 최고 기록을 세웠습니다.



### The Large Language Model GreekLegalRoBERTa (https://arxiv.org/abs/2410.12852)
- **What's New**: 그리스 법률 및 비법률 텍스트에 대해 훈련된 네 가지 버전의 GreekLegalRoBERTa 모델을 개발했습니다. 이 모델은 GreekLegalBERT 및 그리스 관련 다른 모델들의 성능을 초과합니다.

- **Technical Details**: 이 논문에서는 RoBERTa(Liu et al., 2019)를 사용하여 그리스 법률 문서에서의 이름 개체 인식(NER) 및 다중 클래스 법률 주제 분류 작업을 수행했습니다. 훈련된 네 가지 GreekLegalRoBERTa 모델은 Nomothesia 플랫폼, 그리스 의회 의사록, 유럽 의회 의사록 병렬 코퍼스 등에서 수집된 데이터로 훈련되었습니다.

- **Performance Highlights**: 모델들은 GreekLegalNER에서 이전의 모든 모델들을 초과하는 성능을 보였고, GreekLegalCode 작업에서도 개선된 성능을 나타내었습니다. 특히, micro 평균에서 GreekLegalBERT-v2의 성능을 1.2 포인트 개선하였고, 다양한 분류에서 다른 성과도 달성하였습니다.



### VibeCheck: Discover and Quantify Qualitative Differences in Large Language Models (https://arxiv.org/abs/2410.12851)
Comments:
          10 pages, unironic use of the word 'vibe'

- **What's New**: VibeCheck는 대형 언어 모델(LLMs) 간의 뚜렷한 특성(vibes)을 발견하고 측정하는 시스템으로, 모델의 출력에서 다양한 차원(ton, formatting, writing style)을 평가할 수 있는 새로운 방식입니다. 이 시스템은 사용자의 선호와 모델의 정체성을 예측할 수 있는 vibres를 자동으로 확인합니다.

- **Technical Details**: VibeCheck는 모델의 출력을 통해 vibes를 반복적으로 발견하고, LLM 판별자를 통해 각 vibe의 유용성을 정량적으로 측정합니다. 발견된 vibes는 다수의 사용자의 합의, 모델 간 차별화, 사용자 선호 예측 세 가지 기준을 충족해야 합니다. VibeCheck는 Llama-3-70b와 GPT-4의 사용자 대화 데이터를 기반으로 실험했으며, 80%의 정체성 예측 정확도와 61%의 사용자 선호 예측 정확도를 달성했습니다.

- **Performance Highlights**: VibeCheck의 결과에 따르면, Llama는 친근하고 유머러스하며 다소 논란이 있는 vibe를 가지며, Command X는 요약 시 구체적인 서론과 결론을 추가하는 경향이 있고, Llama-405b는 수학 문제에서 자신의 사고 과정을 과도하게 설명하는 경향이 있는 반면, GPT-4는 캡셔닝에서 장면의 정서와 분위기에 집중하는 경향이 있음을 확인했습니다.



### RecurFormer: Not All Transformer Heads Need Self-Attention (https://arxiv.org/abs/2410.12850)
- **What's New**: 이 논문에서는 Transformer 기반의 대형 언어 모델(LLM)의 응답 생성 과정에서 발생하는 계산 비용 문제를 해결하기 위해 RecurFormer라는 새로운 아키텍처를 제안합니다. RecurFormer는 특정 attention head를 linear recurrent neural network (RNN)인 Mamba 아키텍처로 교체하여 메모리 캐시 사이즈를 줄이고, 토큰을 제거하지 않으면서 생성 품질을 유지합니다.

- **Technical Details**: RecurFormer는 recency aware 속성을 가진 attention head를 Mamba 아키텍처로 교체하는 방식으로 구성되어 있습니다. Mamba는 selective structured state-space sequence model 기반의 linear RNN으로, parallel 및 recursive 계산을 지원합니다. 이 방식은 기존 Transformer의 가중치를 계속 활용할 수 있도록 하여 모델의 성능을 유지하면서도 계산 효율을 증대시킵니다.

- **Performance Highlights**: 실험 결과, RecurFormer는 원래 모델의 성능을 유지하면서도 추론 효율성을 크게 향상시키는 것으로 나타났습니다. 또한, 지속적인 훈련을 통해 성능 회복이 가능하다는 것을 보여주어, 긴 입력에 관련된 작업에서 Transformer 기반 LLM의 계산적 도전에 대한 실용적인 해결책을 제공합니다.



### Prompt Engineering a Schizophrenia Chatbot: Utilizing a Multi-Agent Approach for Enhanced Compliance with Prompt Instructions (https://arxiv.org/abs/2410.12848)
- **What's New**: 이 논문은 정신분열증 환자를 위한 교육 플랫폼에서 Large Language Models (LLMs)인 GPT-4를 활용하는 방법을 제안합니다. 특히, 챗봇의 반응이 초기에 설정된 범위를 넘는 경우를 다루기 위해 Critical Analysis Filter를 도입했습니다.

- **Technical Details**: 이 시스템은 여러 LLM 에이전트가 챗봇의 반응을 분석하고 개선하는 역할을 합니다. 실험에서는 정보 제공 목적의 정신분열증 챗봇을 개발하고, 필터가 비활성화된 상태에서 대화를 진행하여 챗봇의 범위를 초과하는 모습을 관찰했습니다. 이후 AI 에이전트를 통해 범위를 벗어난 주제에 대한 샘플 대화를 자동 생성하고, 각 반응에 대해 컴플라이언스 점수를 할당했습니다.

- **Performance Highlights**: Critical Analysis Filter를 활성화했을 때 챗봇의 컴플라이언스 점수는 67.0%에서 적정 수준(점수 >=2)을 유지했지만, 필터가 비활성화된 경우에는 단지 8.7%에 불과했습니다. 이는 정신 건강 플랫폼에서 LLM을 효과적이고 안전하게 사용하기 위한 자기 반성 계층의 필요성을 시사합니다.



### ACCEPT: Adaptive Codebook for Composite and Efficient Prompt Tuning (https://arxiv.org/abs/2410.12847)
Comments:
          EMNLP Findings 2024

- **What's New**: 이 연구에서는 Adaptive Codebook for Composite and Efficient Prompt Tuning (ACCEPT)이라는 새로운 방법을 제안합니다. 기존의 Prompt Tuning (PT) 기법이 개별적으로 업데이트되는 프롬프트로 인해 파라미터 수가 비례적으로 증가하는 문제를 해결하여 모든 소프트 프롬프트가 학습 가능한 코드북 벡터를 공유하도록 하여 파라미터 효율성을 높입니다.

- **Technical Details**: ACCEPT는 제품 양자화(Product Quantization, PQ) 개념을 바탕으로 하며, 각 프롬프트의 단어 임베딩을 여러 하위 섹션으로 나누어 각각의 섹션에 대해 코드북을 구성합니다. 이 방법은 프롬프트의 각 하위 벡터가 선형 계수를 통해 부드럽게 결합되도록 하여 더 높은 다양성과 유연성을 제공합니다. 또한, ACCEPT는 0.3%의 플로우우먼스 파라미터만 조정하여 17개의 자연어 작업에서 우수한 성능을 달성합니다.

- **Performance Highlights**: 17개의 다양한 자연어 작업에서 ACCEPT 방법이 이전의 PT 접근법을 일관되게 초과 달성했습니다. 특히, 몇 가지 샷(few-shot) 및 대형 모델 환경에서 뛰어난 성능을 보여주며, 사전 훈련된 언어 모델(PLMs)의 효율성을 극대화합니다.



### Accurate and Regret-aware Numerical Problem Solver for Tabular Question Answering (https://arxiv.org/abs/2410.12846)
- **What's New**: TabLaP라는 모델을 제안하여, Large Language Model (LLM)을 답변 생성기가 아닌 계획자로 활용하며, 숫자 계산을 위한 정확한 처리기인 Python interpreter에게 계산을 맡깁니다. 또한, TabLaP가 생성한 답변의 신뢰성을 정량화하여 사용자가 후회 유발 가능성을 줄일 수 있도록 합니다.

- **Technical Details**: TabLaP는 두 개의 모델 브랜치를 갖고 있으며, 하나는 NumSolver로 숫자 질문을 처리하고, 다른 하나는 최신 TableQA 모델입니다. 생성된 답변을 통합하기 위해 AnsSelecter라는 LLM을 사용하여 신뢰할 수 있는 브랜치를 선택합니다. TwEvaluator 모듈을 통해 각 브랜치의 정확도를 추적하여 답변 신뢰성을 평가합니다.

- **Performance Highlights**: TabLaP는 두 개의 벤치마크 데이터셋에서 기존의 SOTA 모델에 비해 각각 5.7%와 5.8% 향상된 정확도를 기록했습니다. 또한, TabLaP의 신뢰성 플래그는 사용자 후회 비율을 두 데이터셋에서 각각 30.9%와 20.6% 감소시켰습니다.



### Toward Relieving Clinician Burden by Automatically Generating Progress Notes using Interim Hospital Data (https://arxiv.org/abs/2410.12845)
Comments:
          Accepted at the AMIA 2024 Annual Symposium

- **What's New**: 이 논문에서는 전자 건강 기록(EHR)의 구조화된 정보를 활용하여 진행 노트 생성(Progress Note Generation, PNG) 자동화를 위한 새로운 방법론을 제안합니다. 특히, 1616명의 환자로부터 수집된 7089개의 주석 인스턴스를 포함한 대형 데이터셋 ChartPNG를 소개합니다.

- **Technical Details**: 이 연구는 임상 의사들이 작성한 SOAP 노트를 기반으로 하는 프로세스입니다. 진행 노트는 환자의 주관적 및 객관적 상태와 평가 및 계획(A&P)으로 구성되어 있으며, 연구는 A&P 섹션의 자동 생성을 주로 목표로 합니다. 이 과정에서 대형 언어 모델을 활용하여 자동 분석을 수행하고, 향후 연구 기회를 찾아내기 위해 오류 분석을 실시하였습니다.

- **Performance Highlights**: 자동화된 분석에서는 Biomistral 모델이 BERTScore F1 점수 80.53과 MEDCON 점수 19.61을 기록하였고, 수작업 분석에서는 76.9%의 정확도로 관련 구조화 데이터를 활용할 수 있음을 보여주었습니다.



### TextLap: Customizing Language Models for Text-to-Layout Planning (https://arxiv.org/abs/2410.12844)
Comments:
          Accepted to the EMNLP Findings

- **What's New**: 이 논문에서는 사용자가 텍스트 지시만으로 매력적인 그래픽 레이아웃을 생성할 수 있도록 돕는 새로운 방법인 TextLap을 제안합니다. TextLap은 특별히 설계된 레이아웃 계획 데이터셋인 InstLap을 활용하여 대형 언어 모델(LLM)을 사용자 맞춤형 그래픽 디자이너로 변환합니다.

- **Technical Details**: TextLap 모델은 레이아웃 생성을 위한 text-to-layout 작업을 수행합니다. 사용자 입력에 따라 레이아웃을 생성하고 수정할 수 있으며, 이는 자연어 대화를 통해 이루어집니다. InstLap 데이터셋은 이미지-캡션 페어를 필터링하고 향상하여 LLM에 대한 사용자 지시 튜닝 데이터를 제공합니다.

- **Performance Highlights**: 텍스트 기반 레이아웃 계획인 TextLap은 다양한 벤치마크 데이터셋에서 평가된 결과, GPT-4 기반의 방법보다 우수한 성능을 나타냈습니다. TextLap은 디자인 생성에 필요한 시간을 줄이고, 디자이너의 작업 효율성을 향상시키는 데 기여합니다.



### Exploring Prompt Engineering: A Systematic Review with SWOT Analysis (https://arxiv.org/abs/2410.12843)
Comments:
          14 pages, 1 figures

- **What's New**: 이번 논문에서는 대형 언어 모델(LLM) 내에서 프롬프트 엔지니어링(prompt engineering) 기술에 대한 포괄적인 SWOT 분석을 수행했습니다. 언어학 원칙을 강조하며, 다양한 기술들을 분석하여 그 강점, 약점, 기회 및 위협을 파악했습니다. 이러한 발견은 AI 상호작용을 향상시키고 언어 모델이 인간의 프롬프트를 이해하는 방법을 개선하는 데 기여합니다.

- **Technical Details**: 이 논문에서는 100편 이상의 관련 문헌을 조사하여 프롬프트 엔지니어링 분야에 대한 폭넓은 통찰을 제공합니다. 주요 프롬프트 엔지니어링 기술로는 템플릿 기반 접근법(template-based approaches)과 파인 튜닝(fine-tuning) 방식이 있으며, 각 기술의 문제점 및 도전 과제를 다루었습니다. 또한, BLEU, BERTScore, ROUGE 및 Perplexity와 같은 여러 평가 메트릭(metrics)을 확인했습니다. 연구는 언어 모델의 행동을 이해하는 데 도움을 주고, 맞춤형 상호작용을 제공하는 목표에 맞춰 진행되었습니다.

- **Performance Highlights**: 이 연구는 LLM의 정확성 및 관련성을 향상시킬 수 있는 효과적인 프롬프트 엔지니어링의 중요성을 강조하며, 사용자 및 개발자 간의 지식 공유와 대화형 AI 툴의 발전을 촉진합니다. 특히, 차별화된 접근법을 통해 응답 정확도를 높이고, 대화형 AI의 성장에 기여할 것입니다.



### A Two-Model Approach for Humour Style Recognition (https://arxiv.org/abs/2410.12842)
- **What's New**: 이번 연구에서는 1,463개의 인스턴스를 포함하는 새로운 텍스트 데이터셋을 도입하여 네 가지 유머 스타일(자기 증진, 자기 비하, 친화적, 공격적) 및 비유머 텍스트를 인식하는 데 필요한 기계 학습 모델링을 지원합니다. 이는 유머 스타일 인식의 연구 공백을 채우는 중요한 기여를 합니다.

- **Technical Details**: 연구에서는 고전 기계 학습 분류기, 텍스트 임베딩 모델 및 DistilBERT를 포함한 다양한 컴퓨팅 방법을 사용하여 기준 성능을 설정하였습니다. 또한, 친화적 유머 분류의 F1 점수를 11.61% 향상시키는 두 개의 모델 접근 방식을 제안하였습니다. 이 연구는 각 유머 스타일에 대한 다중 클래스 분류 문제를 다룹니다.

- **Performance Highlights**: 두 개의 모델 접근 방식을 통해 14개의 테스트된 모델에서 일관된 성능 개선을 보였으며, 특히 친화적 유머 분류에서 F1 점수의 11.61% 향상을 달성했습니다. 이는 문학, 소셜 미디어 및 다른 텍스트 출처에서 유머를 연구하기 위한 새로운 도구를 제공합니다.



### UniAutoML: A Human-Centered Framework for Unified Discriminative and Generative AutoML with Large Language Models (https://arxiv.org/abs/2410.12841)
- **What's New**: 새로운 AutoML 프레임워크인 UniAutoML이 소개되었습니다. UniAutoML은 기존의 AutoML 프레임워크가 주로 다루었던 discriminative task 뿐만 아니라 generative task도 통합하여 지원하는 것이 특징입니다. 사용자가 쉽게 접근할 수 있도록 자연어로 상호작용할 수 있는 대화형 사용자 인터페이스(CUI)를 제공합니다.

- **Technical Details**: UniAutoML은 Large Language Models (LLMs)를 활용하여 데이터 처리, 모델 선택 및 하이퍼파라미터 검색을 자동화한 인공지능 프레임워크입니다. 사용자들은 자연어 명령을 통해 복잡한 모델을 fine-tuning 할 수 있으며, 모델은 HuggingFace에서 사전 훈련된 다양한 모델을 선택하고 사용할 수 있습니다. 또한, safety guard-line을 설계하여 사용자 입력과 LLM 출력의 필터링이 이루어집니다.

- **Performance Highlights**: UniAutoML은 25명의 참가자를 대상으로 8개의 다양한 데이터셋에 대한 실험을 통해 성능과 사용성을 평가하였고, 그 결과 사용자 제어와 신뢰도를 향상시켰습니다. UniAutoML의 인간 중심 디자인은 AutoML의 기능과 사용자 이해 사이의 격차를 해소하여 더 많은 사람들이 ML(Machine Learning)에 접근할 수 있도록 합니다.



### Answering Questions in Stages: Prompt Chaining for Contract QA (https://arxiv.org/abs/2410.12840)
- **What's New**: 이번 연구에서는 법률 문서에서의 질문에 대한 구조적 답변 생성을 위한 새로운 두 단계 프롬프트 체인을 제안합니다. 이전의 프롬프트가 긴 조항을 다루는 데 한계를 보였던 반면, 이 방식은 더 복잡한 법률 텍스트를 효과적으로 처리할 수 있는 가능성을 보여줍니다.

- **Technical Details**: 이 연구는 법률 관련 질문에 대한 응답을 두 단계로 처리하는 전략을 사용하는데, 첫 번째 단계에서는 관련 법률 텍스트의 요약을 생성하고, 두 번째 단계에서는 이 요약을 사용하여 기존의 프롬프트 템플릿에 대해 질문에 대한 답변을 형성합니다. 이를 통해 질문과 답변 옵션 간의 매핑을 개선할 수 있습니다.

- **Performance Highlights**: 실험 결과, 두 단계 프롬프트 체인이 단순한 프롬프트에 비해 대부분의 경우 더 효과적임을 보여주었습니다. 이는 법률 전문가들이 문서를 더 효율적으로 검토하고 자동화된 워크플로우 및 데이터 파이프라인을 구축할 수 있도록 도와주는 기회를 제공합니다.



### Capturing Bias Diversity in LLMs (https://arxiv.org/abs/2410.12839)
Comments:
          2nd International Conference on Foundation and Large Language Models (FLLM2024), 26-29 November, 2024 | Dubai, UAE

- **What's New**: 이 논문은 대규모 언어 모델(Large Language Models, LLMs)의 출력 다양성을 높이기 위해 여러 개의 사용자 정의 GPT 모델을 구성하여 BiasGPT라는 새로운 프레임워크를 제안하고 평가합니다. 이 모델들은 성별, 연령 및 인종 같은 특정 인구통계학적 특성의 편향을 반영하여 협력하고, 다양한 관점을 통합하여 인간의 경험을 보다 잘 캡처한 응답을 생성합니다.

- **Technical Details**: BiasGPT는 여러 개의 사용자 정의 GPT 모델을 사용하여 각 모델이 특정 인구 통계적 특성을 반영함으로써 다양한 응답을 생성하는 방법입니다. 이 방법론은 사용자 정의된 LLM을 통해 학습된 편향들이 통합되어 보다 포괄적이고 공정한 AI 챗봇 응답을 형성하도록 합니다. 또한, 논문에서는 대화 데이터 수집 과정에서 연령, 인종, 성별 기반의 다양한 편향을 다루기 위한 포괄적인 접근 방식을 사용합니다.

- **Performance Highlights**: 일련의 실험을 통해 BiasGPT는 다양한 사회적 특성을 반영한 응답을 생성할 수 있는 능력을 입증하였으며, 이는 더욱 포괄적이고 대표적인 AI 대화를 형성하는 데 기여할 것입니다. 이 연구는 AI 기술의 포용성을 높이는 방향으로 나아가는 데 주요한 실험적 근거를 제공합니다.



### A Comprehensive Survey of Retrieval-Augmented Generation (RAG): Evolution, Current Landscape and Future Directions (https://arxiv.org/abs/2410.12837)
Comments:
          4 Figures

- **What's New**: 이 논문은 Retrieval-Augmented Generation (RAG)의 발전 과정을 포괄적으로 조사하며, 기존 개념에서 최신 기술에 이르기까지의 변화를 설명합니다. RAG는 검색 메커니즘과 생성 언어 모델을 결합하여 출력의 정확성을 높이며, LLMs의 주요 제한 사항을 해결합니다.

- **Technical Details**: RAG의 기본 아키텍처는 지식 집약적인 작업을 처리하기 위해 검색과 생성을 어떻게 통합하는지에 중점을 둡니다. 논문에서는 retrieval-augmented language models에서의 주요 혁신과 질문 답변, 요약 및 지식 기반 작업 등 다양한 도메인에서의 응용 사례를 자세히 리뷰합니다.

- **Performance Highlights**: 최근 연구 성과는 retrieval 효율성을 개선하기 위한 새로운 방법을 강조하고 있으며, RAG의 연구 방향으로는 모델의 견고성 향상, RAG 모델의 적용 범위 확대 및 사회적 함의 문제 다루기가 제안됩니다.



### How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs (https://arxiv.org/abs/2410.13857)
- **What's New**: 이 논문에서는 Transformer 기반 대형 언어 모델(LLMs)의 수학적 능력을 이론적으로 분석하고, 특히 산술작업에서의 성능을 강조합니다. 숫자 정밀도가 수학적 작업의 성공적인 수행을 좌우하는 핵심 요소로 밝혀졌습니다.

- **Technical Details**: 저자들은 LLM의 기본 산술 작업인 정수 덧셈, 반복 덧셈, 정수 곱셈을 분석합니다. 저자들은 정밀도에 따라 모델의 크기가 달라지며, 낮은 정밀도(int8, int4)의 Transformer는 문제를 풀기 위해 폭발적으로 큰 모델을 요구한다고 주장합니다. 이와 대조적으로 표준 정밀도(float32)는 훨씬 작고 효율적인 모델로도 이를 처리할 수 있음을 보여줍니다.

- **Performance Highlights**: 실험 결과는 두 가지 정밀도(int4 및 표준 정밀도) 모두에서 정수 덧셈 작업에서 충분한 성능을 보였지만, 반복 덧셈 및 정수 곱셈과 같은 복잡한 작업에서는 낮은 정밀도가 성능 저하를 일으킨다는 것을 보여주었습니다.



### Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation (https://arxiv.org/abs/2410.13848)
Comments:
          Technical Report

- **What's New**: 이 논문에서는 다양한 모드의 이해 및 생성을 통합한 새로운 자율 회귀 프레임워크인 Janus를 소개합니다. 기존 연구는 주로 단일 시각 인코더를 사용했으나, Janus는 시각 인코딩을 별도의 경로로 분리하여 성능과 유연성을 향상시켰습니다.

- **Technical Details**: Janus는 고유한 transformer 아키텍처를 사용하여 시각 이해 및 생성을 위한 독립적인 인코딩 경로를 제공합니다. 이를 통해 이해와 생성 작업 사이의 정보를 분리하고, 각 작업에 가장 적합한 인코딩 방법을 선택할 수 있는 유연성을 제공합니다.

- **Performance Highlights**: Janus는 기존의 통합 모델보다 뛰어난 성능을 보여주며, MMBench 및 SEED-Bench와 같은 벤치마크에서 최고 성과를 기록했습니다. 또한, DALL-E 2와 SDXL과 같은 특정 작업 모델을 초월하는 성과를 보였습니다.



### A Unified View of Delta Parameter Editing in Post-Trained Large-Scale Models (https://arxiv.org/abs/2410.13841)
- **What's New**: 이 논문은 delta parameters(델타 파라미터)의 편집 작업을 Riemann sum(리만 합) 근사를 통해 체계적으로 이해하고 분류하는 새로운 관점을 제시합니다. 기존의 편집 기법들이 어떻게 모델 성능에 영향을 미치는지를 설명하는 통합된 프레임워크를 수립했습니다.

- **Technical Details**: 델타 파라미터는 사전 훈련(pre-trained) 모델과 후 훈련(post-trained) 모델의 파라미터 차이를 나타냅니다. 저자들은 delta parameters의 편집 연산을 Riemann sum approximation(리만 합 근사)을 기반으로 설명하며, 수행된 편집으로 인한 손실 변화를 수학적으로 분석하고 competitive, decreased, improved 성능을 가진 기법으로 분류합니다.

- **Performance Highlights**: 많은 실험을 통해 ViT, LLaMA 3, Qwen 2, Mistral 등 다양한 모델에서 저자들의 이론적인 발견을 뒷받침합니다. DARE와 BitDelta와 같은 기존 기법에서의 성능 향상과 저하를 정량적으로 검증하였으며, 기존의 delta parameter 조정 기술의 한계를 지적하고, 보다 일반화된 접근 방식을 제공하는 확장들을 제안합니다.



### A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglemen (https://arxiv.org/abs/2410.13828)
- **What's New**: 본 논문에서는 Reinforcement Learning from Human Feedback (RLHF)에서 전통적인 margin-based 손실을 사용하는 것의 문제점을 다루고 있습니다. 특히, 이 접근 방법이 선호 및 비선호 응답 각각에 대해 이상적인 언어 모델 behavior를 충분히 명시하지 않는다는 점이 강조됩니다.

- **Technical Details**: 우리는 margin의 증가에 따른 두 가지 의도치 않은 결과를 식별했습니다: (1) 비선호 응답의 확률이 증가할 수 있으며 이는 안전 문제와 관련된 alignment 실패를 초래할 수 있습니다. (2) 선호 응답의 확률이 감소할 수 있으며, 이 경우에도 그 응답은 이상적일 수 있습니다. 이러한 현상의 원인은 gradient entanglement으로 명명하였으며, 이는 선호 및 비선호 응답의 확률 변화가 서로 얽혀 있는 문제를 나타냅니다.

- **Performance Highlights**: 본 논문은 margin 기반 preference optimization 알고리즘의 훈련 동역학을 설명하고, margin 기반 방법의 under-specification 문제를 완화할 수 있는 잠재적인 알고리즘 설계를 제안합니다.



### AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents (https://arxiv.org/abs/2410.13825)
- **What's New**: 이 연구는 LLM(대형 언어 모델)을 기반으로 한 웹 에이전트를 개선하기 위한 혁신적인 접근 방식을 제안합니다. 구체적으로, 에이전트의 관찰(object) 및 행동(action) 공간을 정제하여 LLM의 능력에 더욱 잘 부합하도록 합니다.

- **Technical Details**: 제안된 방법은 세 가지 구성 요소로 이루어져 있습니다: 1) 필수적이지 않은 행동을 줄여 에이전트의 기능을 단순화; 2) 중복되거나 불필요한 웹 요소를 제거하여 관찰을 개선; 3) 'branch' 및 'prune'와 같은 두 가지 계획 행동을 도입하여 에이전트의 내비게이션 흐름을 자기 조직화 합니다.

- **Performance Highlights**: AgentOccam는 WebArena 벤치마크에서 기존의 최첨단 방법보다 9.8 포인트 (+29.4%) 향상된 성능을 보이고, 유사한 일반 웹 에이전트에 비해 성공률을 26.6 포인트 (+161%) 증가시켰습니다. 이 모든 것을 추가적인 맥락 예제, 온라인 피드백 또는 검색 전략 없이 달성했습니다.



### Harnessing Webpage UIs for Text-Rich Visual Understanding (https://arxiv.org/abs/2410.13824)
- **What's New**: 이번 연구에서는 웹 페이지 UI에서 일반 다중 모달 지침을 합성하여 MLLM(다중 모달 대형 언어 모델)의 텍스트가 풍부한 시각적 이해(text-rich visual understanding) 능력을 향상시키는 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 730만 개 샘플로 구성된 MultiUI 데이터셋을 활용하며, 이는 100만 개 웹사이트에서 수집되었습니다. 텍스트 기반 대형 언어 모델(LLM)은 웹페이지 접근성 트리에서 구조적 텍스트 표현을 처리하여 다중 모달 모델을 교육하는 데 필요한 지침을 생성합니다.

- **Performance Highlights**: MultiUI로 훈련된 모델은 웹 UI 작업에서 VisualWebBench에서 최대 48%의 개선을 보였으며, Mind2Web 데이터셋에서 액션 정확도가 19.1% 향상되었습니다. 더 나아가 이 모델은 비웹 UI 작업과 문서 이해, OCR, 차트 해석과 같은 비 UI 도메인에서도 놀라운 일반화를 보여주었습니다.



### Optimal Quantization for Matrix Multiplication (https://arxiv.org/abs/2410.13780)
- **What's New**: 본 연구는 대규모 매트릭스의 lossy compression (양자화) 기법을 통해 매트릭스 곱셈을 가속화하기 위한 새로운 알고리즘을 제안합니다. 이 접근법은 전통적인 벡터 양자화와 다르게, 매트릭스 자체가 아니라 매트릭스 곱셈의 근사를 목표로 합니다.

- **Technical Details**: 이 논문은 iid Gaussian 아이템을 가진 매트릭스의 평균 제곱 오차에 대한 비비대칭 하한을 제공하며, 특정한 프레임워크에서 Frobenius norms를 사용하여 매트릭스 A, B의 압축과 동시에 근사 오차를 보장하는 보편적인 양자기를 제안합니다. 이는 깊은 신경망(Deep Neural Networks)과 대규모 언어 모델(Large Language Models)에서 메모리 대역폭의 병목 현상을 해결하기 위한 중요성을 강조합니다.

- **Performance Highlights**: 제안된 양자기는 최적 성능에 근접한 결과를 실현하며, 정보 이론적으로 iid Gaussian 매트릭스의 매트릭스 곱셈에 대한 rate-distortion function을 도출합니다.



### MobA: A Two-Level Agent System for Efficient Mobile Task Automation (https://arxiv.org/abs/2410.13757)
Comments:
          27 pages, 6 figures, and 5 tables. We will release our source code in a few days

- **What's New**: MobA라는 혁신적인 모바일 어시스턴트를 제안합니다. 이를 통해 다중 모달 대형 언어 모델(Multimodal Large Language Models, MLLM)을 활용하여 사용자의 명령 이해와 계획 능력을 향상시킵니다.

- **Technical Details**: MobA는 두 가지 수준의 에이전트 아키텍처로 구성되어 있습니다. 상위 에이전트(Global Agent, GA)는 사용자 명령을 이해하고, 히스토리 메모리를 추적하며, 작업을 계획하는 역할을 합니다. 하위 에이전트(Local Agent, LA)는 GA의 메모리와 서브 태스크에 따라 상세한 작업을 함수 호출의 형태로 예측합니다. 또한, Reflect Module을 통합하여 이전에 보지 못한 복잡한 작업을 처리할 수 있는 능력을 제공합니다.

- **Performance Highlights**: MobA는 실제 평가에서 작업 수행 효율성(Task Execution Efficiency)과 완료율(Completion Rate)에서 상당한 개선을 보여주며, MLLM을 활용한 모바일 어시스턴트의 가능성을 강조합니다.



### Exploring the Design Space of Visual Context Representation in Video MLLMs (https://arxiv.org/abs/2410.13694)
Comments:
          Long Video MLLM; work in progress

- **What's New**: 비디오 다중 모달 대형 언어 모델(Video Multimodal Large Language Models, MLLMs)의 시각적 컨텍스트 표현에 대한 체계적인 연구를 다룬 첫 번째 논문입니다. 연구진은 최적의 시각적 컨텍스트 표현 방식인 Opt-Visor 모델을 제안하며, 최대 162 프레임까지의 비디오를 처리할 수 있습니다.

- **Technical Details**: 비디오 MLLMs의 성능 향상을 위해 프레임 선택(frame selection)과 임베딩 선택(embedding selection)을 최적화하는 제약 최적화 문제로 작업을 정의했습니다. 각 프레임에서의 토큰 수와 프레임 수에 따른 언어 모델링 손실(training loss)을 함수로 모델링하여 시각적 컨텍스트의 경쟁 관계를 이해합니다. 이러한 분석을 바탕으로 성능 추세를 설명하는 함수 곡선을 맞추어 다양한 선택 전략의 효과를 평가했습니다.

- **Performance Highlights**: 실험 결과, 시각적 임베딩 수(토큰 또는 프레임)를 증가시키는 것이 전반적으로 성능 향상에 기여한다는 것을 확인했습니다. 특히, 압축 기반 방법이 더 적은 시각적 임베딩으로도 더 많은 의미 정보를 보존할 수 있다는 점이 강조되었습니다. 연구진은 이러한 성과를 통해 프레임 선택과 임베딩 선택 간의 이상적인 비율을 찾는 방법을 제안하고, 경험적 실험과 일치하는 제안된 최적 설정을 검증하였습니다.



### Pose-Based Sign Language Appearance Transfer (https://arxiv.org/abs/2410.13675)
- **What's New**: 이 연구에서는 수화에서 서명자의 외모를 제어하는 방법을 소개하며, 서면 내용은 보존하는 방법을 제시합니다. 이 방법은 서명자의 외모를 다른 사람으로 전이하여 자연스러운 움직임과 전환을 유지합니다.

- **Technical Details**: 서명자의 외모를 변경하고 서명 내용을 유지하기 위해 포즈 시퀀스를 조작하는 방법을 사용합니다. 신호 긴밀성과 자연스러운 운동을 위해 몸체와 얼굴의 특성은 수정하지만 손의 형상은 유지합니다. 이는 평균화된 포즈를 통해 수행됩니다.

- **Performance Highlights**: 이 방법은 서명자의 신원을 식별하는 정확성을 줄이면서도 수화 인식 성능을 약간 저하시킵니다. 분석 결과, 원래 포즈를 이용한 모델이 가장 뛰어난 성능을 보였으며, 전이된 포즈를 사용했을 때 신원 식별 정확도가 52.20%로 감소했습니다. 이는 프라이버시와 유용성 간의 균형을 잘 보여줍니다.



### VL-GLUE: A Suite of Fundamental yet Challenging Visuo-Linguistic Reasoning Tasks (https://arxiv.org/abs/2410.13666)
Comments:
          18 pages, 7 figures

- **What's New**: 본 연구에서는 비주얼-언어적 (Visuo-Linguistic) 이해를 위한 새로운 멀티태스크 벤치마크인 VL-GLUE를 제안합니다. VL-GLUE는 7개의 다양한 태스크로 구성되어 있으며, 10만 개 이상의 샘플을 포함해 비주얼과 텍스트 간의 결합 추론 능력을 평가합니다.

- **Technical Details**: VL-GLUE는 이미지와 텍스트 정보를 결합하여 추론을 필요로 하는 7개의 태스크로 구성되어 있습니다. 이 benchmark는 다양한 이미지 유형(일상 장면, 도표 등)과 특정 도메인 텍스트(요리, 정치 등)를 포함해, 실제 세계에서의 멀티모달 이해의 필요성을 보여줍니다.

- **Performance Highlights**: 기존의 대규모 비전-언어 모델들이 VL-GLUE 벤치마크에서 낮은 점수를 얻어, 이 분야의 모델들이 시기적절한 비주얼-언어적 추론 능력을 갖춤이 긴급하게 요구되고 있다는 점이 부각되었습니다.



### H2OVL-Mississippi Vision Language Models Technical Repor (https://arxiv.org/abs/2410.13611)
- **What's New**: H2OVL-Mississippi 모델은 3700만 개의 이미지-텍스트 쌍을 기반으로, 8개의 H100 GPU를 사용하여 240시간 동안 훈련된 작은 비전-언어 모델(VLM) 쌍을 소개합니다. 특히, H2OVL-Mississippi-0.8B는 8억 개의 매개변수로 구성되어 텍스트 인식에 특화되어 있으며, OCRBench의 텍스트 인식 부문에서 최첨단 성능을 발휘하고 있습니다.

- **Technical Details**: H2OVL-Mississippi 모델은 Vision Transformer(비전 트랜스포머) 구성 요소와 대형 언어 모델(LLM)로 이루어집니다. H2OVL-Mississippi-0.8B는 OCR 및 문서 중심 작업에 최적화되어 있고, H2OVL-Mississippi-2B는 다양한 멀티모달 작업을 수행할 수 있는 일반 목적 모델입니다. 이들은 각각 256에서 1590개의 시각적 토큰을 생성하며, 동적 해상도 전략(dynamic resolution)과 다중 스케일 적응 크롭(multi-scale adaptive cropping) 전략을 활용하여 다양한 이미지 크기와 종횡비에 적응합니다.

- **Performance Highlights**: H2OVL-Mississippi-0.8B는 OCRBench에서 텍스트 인식 부문에서 최첨단 성능을 보여주며, H2OVL-Mississippi-2B는 다양한 학술 벤치마크에서 경쟁력 있는 메트릭스를 제공합니다. 두 모델 모두 H2O-Danube 언어 모델의 기능을 확장하여 비주얼 도메인으로의 적용 가능성을 높이고, Apache 2.0 라이선스 하에 공개되어 문서 AI와 비주얼 LLM의 접근성을 높였습니다.



### MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling (https://arxiv.org/abs/2410.13610)
- **What's New**: 이번 논문에서는 LLMs(대형 언어 모델)와 의료 분야의 복잡한 문제를 해결하기 위한 새로운 프레임워크인 MeNTi를 소개합니다.

- **Technical Details**: MeNTi는 LLMs를 위한 보편적인 에이전트 아키텍처로, 전문화된 의료 도구 세트를 통합하고 메타 도구(meta-tool) 및 중첩 호출(nested calling) 메커니즘을 사용하여 LLM 도구 활용을 강화합니다. 이를 통해 유연한 도구 선택 및 중첩 도구 호출이 가능해지며, 계산기 선택, 슬롯 채우기(slot filling), 단위 변환을 포함한 복잡한 의료 시나리오 문제를 해결합니다.

- **Performance Highlights**: CalcQA라는 벤치마크를 통해 LLM의 정량적 평가 능력을 검증하며, 100개의 사례-계산기 쌍과 281개의 의료 도구가 포함된 도구 키트를 통해 실험 결과에서 상당한 성능 개선을 보여주었습니다.



### Large Language Models as Narrative-Driven Recommenders (https://arxiv.org/abs/2410.13604)
Comments:
          Under review; 19 pages

- **What's New**: 이번 연구에서는 대형 언어 모델(LLMs)을 사용하여 자유형식의 텍스트로 표현된 영화 추천 요청에 대한 개인화된 추천을 제공하기 위한 새로운 접근 방식을 탐구하였습니다. 특히, reddit의 영화 추천 커뮤니티에서 수집된 데이터셋을 활용하여 38개의 오픈소스 및 클로즈드 소스 LLM의 성능을 비교하였습니다.

- **Technical Details**: 이 연구는 zero-shot, identity, few-shot 프롬프트 기법을 사용하여 LLM이 사용자 요청을 자연어로 처리하고 관련 영화를 추천할 수 있는지 평가합니다. 평가된 LLM은 크기에 따라 분류되며, 각 모델은 기본적인 zero-shot 프롬프트를 통해 추천 정확도를 높일 수 있음을 보여줍니다.

- **Performance Highlights**: LLMs는 기존의 추천 알고리즘보다 더 높은 성능을 보이며, 특히 GPT-4o는 기본 성능보다 70% 더 높은 추천 성능을 보였습니다. 중간 크기의 오픈소스 모델도 상대적으로 높은 성능을 유지하며 클로즈드 소스 모델과 비교하여 경쟁력을 보여주었습니다.



### MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs (https://arxiv.org/abs/2410.13502)
Comments:
          Preprint

- **What's New**: MathGAP이라는 새로운 평가 프레임워크를 제시하여, 보다 복잡한 산술 증명이 포함된 문제에서 대형 언어 모델(LLMs)의 일반화 능력을 분석합니다. 이를 통해 기존의 평가 방법의 한계를 극복하고 보다 체계적인 연구를 가능하게 합니다.

- **Technical Details**: MathGAP는 고정된 증명 기준을 따르는 문제를 생성하고 체계적인 체인-오브-생각(chain-of-thought) 주석을 제공합니다. 이 프레임워크는 증명 나무(proof trees)를 기반으로 각 문제의 복잡성을 특성화하고, 간단한 예제를 사용하여 더 복잡한 문제를 해결할 수 있는 LLM의 능력을 평가합니다.

- **Performance Highlights**: 모델 성능은 증명 깊이와 너비가 증가함에 따라 일관되게 감소하며, 특히 비선형(nonlinear) 문제에서 눈에 띄는 감소가 관찰됩니다. 흥미롭게도, 테스트 세트와 동일한 분포의 예제를 제공하는 것이 항상 성능에 이롭지 않으며, 다양한 복잡성을 가진 예제를 제시하는 것이 더 유효한 경우가 많습니다.



### Progressive Mixed-Precision Decoding for Efficient LLM Inferenc (https://arxiv.org/abs/2410.13461)
- **What's New**: 본 연구에서는 LLM(대형 언어 모델)의 추론 단계에서 질량량(data precision) 할당을 개선하기 위해 단계 인식(phase-aware) 방법을 제안합니다. 이 방법은 prefill 단계에서 높은 정밀도를 유지하고, decoding 단계에서는 낮은 정밀도로 갈수록 하여 메모리 성능과 품질을 모두 향상시킵니다.

- **Technical Details**: 제안된 방법은 Progressive Mixed-Precision Decoding(PMPD)이라는 전략을 통해, 자동 회귀 생성 과정에서의 후반부 토큰들은 정밀도 감소에 더 탄력적이므로 초기 정밀도를 높게 유지하고, 후반부에서 점진적으로 정밀도를 감소시키는 방식으로 동작합니다. 또한, 두 가지 정밀도 전환 스케줄러를 통해 정밀도 감소 시점을 전략적으로 결정합니다.

- **Performance Highlights**: 다양한 언어 작업에서 우리의 방법을 적용했을 때, NPU 플랫폼에서는 3.8-8.0배의 디코딩 처리량 향상을 달성하고, GPU에서는 fp16 모델에 비해 1.4-12.2배의 속도 증가를 기록했습니다. 이처럼, uniform quantization 접근법보다 1.54배 더 높은 성능을 보여 주며 출력 품질을 유지합니다.



### Similarity-Dissimilarity Loss with Supervised Contrastive Learning for Multi-label Classification (https://arxiv.org/abs/2410.13439)
- **What's New**: 본 연구는 멀티 라벨 분류에서의 슈퍼바이저드 대조 학습(Supervised Contrastive Learning)에서 긍정 샘플을 결정하는 데 있어 새로운 접근 방식을 제안합니다. 특히, 다섯 가지 고유한 관계를 도입하고, 유사성 및 비유사성 손실(Similarity-Dissimilarity Loss)을 통해 대조 손실 함수(weights)를 동적으로 조정합니다.

- **Technical Details**: 다섯 가지 관계(R2, R3, R4, R5)를 정의하여 멀티 라벨 샘플과 앵커(anchor) 사이의 유사성과 비유사성을 계산하여 손실을 재가중화하는 새로운 Similarity-Dissimilarity Loss를 제안합니다. 이를 통해 ALL, ANY 및 MulSupCon 등의 기존 방법의 한계를 극복합니다.

- **Performance Highlights**: MIMIC 데이터셋에서 멀티 라벨 텍스트 분류 실험을 수행한 결과, 제안된 손실 함수가 슈퍼바이저드 대조 학습 패러다임 하에서 모든 인코더(encoders)에 대해 성능을 효과적으로 향상시키는 것으로 나타났습니다. 실험 결과는 제안된 방법의 효과성과 견고성을 뒷받침합니다.



### MoR: Mixture of Ranks for Low-Rank Adaptation Tuning (https://arxiv.org/abs/2410.13408)
Comments:
          11 pages, 7 figures

- **What's New**: 이 논문에서는 Mixture of Ranks (MoR)라는 새로운 접근 방식을 도입하여 LoRA의 성능을 개선하고, 다중 작업에서 효율적으로 학습할 수 있는 방법을 제안합니다. 기존의 LoRA와 MoE 방식의 한계를 극복하고, 다양한 작업에 대한 rank-specific 정보를 효과적으로 학습합니다.

- **Technical Details**: MoR은 세 가지 주요 구성 요소인 공유 전문가(shared experts), 다중 rank 적응(multi-rank adaptation), 혼합 학습(mixture learning)으로 구성됩니다. 이 방법은 여러 LoRA를 통합하여 학습할 수 있는 새로운 프레임워크를 제공하며, 매핑(mapping) 및 스케일링(scaling)을 통해 다중 작업을 수행합니다.

- **Performance Highlights**: MoR는 기존 LoRA 방법 대비 1.31%의 성능 향상을 달성하면서도 파라미터는 93.93%만 사용합니다. 또한, 다양한 실험에서 MoR은 효율성, 일반화 가능성, 확장성을 입증하며, 다중 LoRA 구조의 학습 비용을 크게 줄이고 더 간결한 정보를 동적으로 학습할 수 있음을 보여줍니다.



### Towards Hybrid Intelligence in Journalism: Findings and Lessons Learnt from a Collaborative Analysis of Greek Political Rhetoric by ChatGPT and Humans (https://arxiv.org/abs/2410.13400)
- **What's New**: 이번 연구 프로젝트는 그리스 2023년 총선을 준비하기 위해 시작된 "정치 담론 분석: 인간과 인공지능 간의 협력"으로, 정치 지도자들의 캠페인 연설을 분석하는 데 중점을 두었습니다.

- **Technical Details**: 본 장에서는 감정 분석(sentiment analysis), 양극화(polarization), 포퓰리즘(populism), 주제 탐지(topic detection), 고유명사 인식(Named Entities Recognition, NER) 등 다양한 정치 담론 분석의 측면을 다룹니다. 대형 언어 모델(large language model, LLM) 특히 OpenAI의 ChatGPT의 정치 연설 분석 능력을 조사하였고, AI가 저널리즘 프로젝트 및 기타 사회적 분야에서 어떻게 활용될 수 있는지에 대해 인간의 감독(human oversight)의 중요성을 강조하였습니다.

- **Performance Highlights**: 이 프로젝트는 디지털 인문학(digital humanities) 분야에서 인간-AI 협력(hybrid intelligence)의 혁신적인 예로서, 향후 연구니즈에 대한 귀중한 통찰력을 제공합니다.



### On the Use of Audio to Improve Dialogue Policies (https://arxiv.org/abs/2410.13385)
Comments:
          IberSpeech 2024

- **What's New**: 본 논문은 오디오 정보와 텍스트 임베딩을 조합하여 대화 정책을 개선하는 새로운 아키텍처를 제안하고 있습니다. 특히, 소음이 있는 전사 환경에서 성능 향상을 이루었습니다.

- **Technical Details**: 제안된 시스템은 Double Multi-Head Attention (MHA) 기법을 활용하여 오디오 정보와 텍스트 정보를 결합합니다. GPT-2를 사용한 텍스트 표현과 Wav2Vec2.0과 같은 미리 훈련된 모델을 통해 오디오 표현을 생성합니다.

- **Performance Highlights**: DSTC2 데이터셋을 사용한 실험에서, 오디오 정보를 포함한 대화 정책은 텍스트 기반 시스템에 비해 9.8% 상대적 향상을 보였습니다. 다중 모달 특성의 결합 방식이 성능 향상에 중요한 역할을 합니다.



### Remember, Retrieve and Generate: Understanding Infinite Visual Concepts as Your Personalized Assistan (https://arxiv.org/abs/2410.13360)
- **What's New**: 본 논문에서는 Retrieval Augmented Personalization (RAP) 프레임워크를 소개하여 다중 모드 대형 언어 모델(MLLMs)의 개인화를 가능하게 합니다. RAP는 일반 MLLM을 개인화된 어시스턴트로 전환하는 세 가지 주요 단계로 구성됩니다: 기억(Recall), 검색(Retrieve), 생성(Generate).

- **Technical Details**: RAP는 사용자 관련 정보(예: 이름, 아바타 등)를 저장하는 키-값 데이터베이스를 설계합니다. 사용자가 대화를 시작할 때, RAP는 다중 모드 검색기를 통해 데이터베이스에서 관련 정보를 검색하고, 이를 MLLM에 입력하여 개인화된 지식 강화 응답을 생성합니다. 추가로 생성 품질 향상을 위해 데이터 수집 파이프라인을 개발하고 개인화된 훈련을 위한 전문적인 데이터셋을 생성합니다.

- **Performance Highlights**: RAP-MLLMs는 개인화된 이미지 캡션 작성, 질문 응답 및 시각적 인식과 같은 다양한 작업에서 뛰어난 유연성과 생성 품질을 보여줍니다. 모델들은 무한한 시각적 개념에 대해 일반화 능력을 발휘하며, 사용자 관련 정보를 효과적으로 처리하여 개인화된 출력을 제공합니다.



### Mitigating Hallucinations in Large Vision-Language Models via Summary-Guided Decoding (https://arxiv.org/abs/2410.13321)
- **What's New**: 이번 연구에서는 LVLMs에서 나타나는 언어 priors의 문제를 해결하기 위해 새로운 방법인 Summary-Guided Decoding (SGD)를 제안합니다. SGD는 이미지 정보에 더 집중하도록 모델을 유도하며, 텍스트 품질을 유지합니다.

- **Technical Details**: 연구는 LVLMs에서의 언어 priors를 분석하고, 이미지 관련 부분의 품사(POS)와 연관된 토큰을 생성할 때 언어 priors에 대한 모델의 의존도가 증가함을 발견했습니다. SGD는 요약(context) 기법을 활용하여 이미지 관련 POS 토큰의 다음-토큰 확률을 수정하여 텍스트 품질을 최대한 보존하면서 이미지 정보를 반영합니다.

- **Performance Highlights**: SGD는 객체 환각(object hallucination) 벤치마크에서 모든 다른 해석 방법을 초월했으며(CHAIRS에서 +16.5%, CHAIRI에서 +19% 향상), 정밀도와 재현율의 균형을 잘 유지하며 Pareto optimal성을 달성했습니다. 또한 텍스트 품질을 거의 완벽하게 유지하면서 객체 환각을 줄이는 데 강력한 성과를 보였습니다.



### CLaMP 2: Multimodal Music Information Retrieval Across 101 Languages Using Large Language Models (https://arxiv.org/abs/2410.13267)
Comments:
          17 pages, 10 figures, 4 tables

- **What's New**: CLaMP 2는 101개 언어를 지원하는 새로운 음악 정보 검색 시스템으로, ABC 표기법과 MIDI를 동시에 활용하는 다중 모드(multi-modal) 모델입니다. 이 시스템은 150만 개의 ABC-MIDI-텍스트 트리플로 사전 훈련되어, 언어 모델을 통해 텍스트의 노이즈를 줄이고 다국어 설명을 정제합니다.

- **Technical Details**: CLaMP 2는 대조 학습(contrastive learning)을 통해 텍스트 인코더와 음악 인코더를 정렬합니다. 이 시스템은 LLM(대형 언어 모델)을 이용하여 101개 언어의 음악 정보를 효과적으로 처리합니다. 특히, 기존의 음악 메타데이터의 일관성을 개선하고 이러한 데이터셋을 통해 훈련을 받음으로써 다국어 검색 성능을 높입니다.

- **Performance Highlights**: CLaMP 2는 다국어 의미 검색과 음악 분류에서 최첨단(results state-of-the-art) 성능을 보여주며, 기존 음악 정보 검색 시스템의 한계를 넘어 글로벌 음악 접근성을 향상시킵니다.



### Disentangling Likes and Dislikes in Personalized Generative Explainable Recommendation (https://arxiv.org/abs/2410.13248)
- **What's New**: 최근 설명 가능한 추천 시스템에 대한 연구는 표준 텍스트 생성 문제로 접근하며, 모델을 예측된 텍스트와 실제 텍스트 간의 유사성을 기반으로 평가합니다. 그러나 이 접근법은 사용자(구매 후) 감정을 정확히 반영하는지 여부를 간과합니다. 이 연구에서는 사용자의 감정을 중점적으로 고려하는 새로운 데이터셋과 평가 방법을 소개합니다.

- **Technical Details**: 우리는 LLM(Long Language Model)을 사용하여 사용자 구매 후 리뷰에서 긍정적 및 부정적 의견을 명시적으로 추출하여 데이터셋을 구성합니다. 시스템을 평가할 때 생성된 설명이 1) 사용자 감정과 잘 일치하는지, 2) 목표 아이템에 대한 사용자 의견의 긍정적 및 부정적 식별을 정확히 수행하는지에 대한 두 가지 기준을 제안합니다.

- **Performance Highlights**: 여러 최신 모델을 우리의 데이터셋에서 벤치마킹하였으며, 기존 지표에서 높은 성과를 달성하더라도 생성된 설명이 사용자 감정과 잘 일치하지 않을 수 있음을 보여줍니다. 또한, 목표 아이템에 대한 사용자(예측된) 평가가 모델에 직접 입력될 경우, 기존 모델들이 보다 감정 인식적인 설명을 제공할 수 있음을 발견하였습니다.



### Anchored Alignment for Self-Explanations Enhancemen (https://arxiv.org/abs/2410.13216)
- **What's New**: 본 연구에서는 언어 모델의 자기 설명(self-explanation) 능력을 향상시키기 위해 주석이 달린 이유 설명이 없는 경우에도 이들의 사고 내용을 명확히 서술하는 방식으로 모델 정렬(alignment) 방법론을 제안합니다.

- **Technical Details**: 본 방법론은 설명 품질 평가(explanation quality assessment), 자기 지시 데이터셋 생성(self-instruction dataset generation), 모델 정렬(model alignment)이라는 세 가지 핵심 요소로 구성됩니다. 특히, 'Anchor Preference Pairs'라는 새로운 기술을 도입하여 모델 출력을 일관되게 정확한 것, 일관되게 부정확한 것, 가변적인 것으로 세 가지 범주로 분류하여 선호 쌍(preference pairs) 선택을 개선합니다. 이를 통해 Direct Preference Optimization (DPO) 전략의 효과성을 증대시킵니다.

- **Performance Highlights**: 실험 결과, 본 접근법은 다른 fine-tuning 전략과 비교할 때 설명 품질을 유의미하게 개선하면서도 정확성을 유지하는 것으로 나타났습니다. 특히, Anchor Preference Pairs를 활용한 방법론이 Judge 기반 평가에만 의존한 자기 정렬 전략보다 더욱 우수한 성능을 보이는 것을 입증했습니다.



### Failing Forward: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation (https://arxiv.org/abs/2410.13198)
Comments:
          Preprint. Under Review

- **What's New**: 본 논문에서는 Generative Error Correction (GEC) 모델의 일반화 한계를 극복하기 위해 DARAG (Data- and Retrieval-Augmented Generative Error Correction) 접근법을 제안합니다. 이 방법은 ASR (Automatic Speech Recognition) 시스템의 오류 교정 성능을 향상시키기 위해 synthetic data를 생성하고, named entities (NEs)를 효과적으로 처리하기 위한 retrieval-augmented correction 기술을 도입합니다.

- **Technical Details**: DARAG 접근법은 LLMs (Large Language Models)에 의해 생성된 synthetic transcripts와 text-to-speech 모델을 사용하여 GEC 훈련 데이터셋을 증강합니다. 또한, OOD (Out-Of-Domain) 시나리오에서의 오류를 비지도 학습 방식으로 시뮬레이션하며, 데이터베이스에서 추출한 named entities를 사용하여 입력 데이터를 보강합니다. 이는 GEC가 테스트 시 경험하는 새로운 오류 유형을 처리할 수 있도록 돕습니다.

- **Performance Highlights**: DARAG는 기존의 GEC 방법들과 비교하여 8%에서 30%까지의 상대적인 Word Error Rate (WER) 개선을 달성하였으며, OOD 환경에서는 10%에서 33% 향상이 있었습니다. 여러 데이터셋과 설정에서의 실험 결과 이 접근법이 ASR 성능을 극대화하는 데 효과적임을 입증했습니다.



### Chain of Ideas: Revolutionizing Research in Novel Idea Development with LLM Agents (https://arxiv.org/abs/2410.13185)
Comments:
          10 pages,5 figures, conference

- **What's New**: 이 논문은 Chain-of-Ideas (CoI) 에이전트를 통해 대형 언어 모델(LLMs)이 연구 아이디어 생성의 효율성을 개선할 수 있는 새로운 방안을 제안합니다. CoI 에이전트는 관련 문헌을 체계적으로 정리하여 연구 분야의 발전을 잘 반영하도록 돕습니다.

- **Technical Details**: CoI 에이전트는 (1) CoI 구성, (2) 아이디어 생성, (3) 실험 설계의 세 가지 단계로 구성됩니다. 각 단계에서 LLM은 연구 분야의 다양한 트렌드를 반영하여 복수의 CoIs를 구축하고, 각 CoI에 대해 예측 및 아이디어를 체계적으로 발전시키는 과정을 거칩니다.

- **Performance Highlights**: 실험 결과에 따르면 CoI 에이전트는 여러 자동화된 방법보다 항상 높은 성능을 보였으며, 사람의 연구 아이디어 생성 품질과도 비교 가능한 결과를 나타냈습니다. CoI 에이전트는 아이디어 생성에서 56 ELO 점수 차이로 두 번째 방법을 초월했습니다.



### EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning (https://arxiv.org/abs/2410.13179)
- **What's New**: 이번 논문에서는 Speech Representation Learning을 위한 새로운 Self-Supervised Learning 접근 법인 EH-MAM (Easy-to-Hard adaptive Masked Acoustic Modeling)을 제안합니다. 기존의 랜덤 마스킹 방식을 사용하는 Masked Acoustic Modeling (MAM)과는 달리, 우리는 선택적이고 적응적인 마스킹 전략을 도입하였습니다.

- **Technical Details**: EH-MAM은 SSL 훈련 중 모델에 점진적으로 더 어려운 영역을 도입하여 재구성을 수행합니다. 개별 프레임의 재구성 손실( reconstruction loss)을 활용하여 MAM 전제 과제를 해결하는 난이도를 판단하며, 이를 위해 교사 모델(teacher model)을 사용하여 프레임 단위 손실을 예측하고 어떤 프레임을 마스킹할 지 결정합니다.

- **Performance Highlights**: EH-MAM은 여러 최신 기준선(baselines) 대비 5%-10% 향상된 성능을 보이며, 저자원(low-resource) 음성 인식 및 SUPERB 벤치마크에서 효과적으로 유용한 컨텍스트를 포착하는 마스킹 영역을 분석합니다.



### An Evolved Universal Transformer Memory (https://arxiv.org/abs/2410.13166)
Comments:
          29 pages, 14 figures. Preprint, under submission. Source code is available at this https URL

- **What's New**: 본 논문은 Neural Attention Memory Models (NAMMs)을 제안하며, 메모리 관리를 위한 학습된 네트워크를 도입하여 Transformers의 성능과 효율성을 동시에 향상시킵니다. 이는 기계가 가진 메모리 관리의 질의를 진화 기반 접근법으로 해결하여, 기능적으로 매우 다양한 아키텍처에서 자율적으로 적용될 수 있도록 설계되었습니다.

- **Technical Details**: NAMMs는 Transformers의 Key-Value (KV) 캐시의 잠재적 메모리를 형성하는 새로운 방법을 제안하여, 각 레이어와 attention head가 그들의 특정 요구에 가장 관련 있는 정보에 집중하도록 지원합니다. 이 방식은 학습된 attention 매트릭스를 기반으로 모든 transformer 기반 아키텍처에 일반적으로 적용 가능하며, Llama 3 8B 모델 위에서 학습하여 성능과 효율성을 모두 극대화합니다.

- **Performance Highlights**: NAMMs를 통한 학습 결과로 36개의 LongBench, InfiniteBench 및 새로운 일본어 벤치마크에서 뛰어난 성능 개선을 기록했습니다. 기존의 수작업 전략과 비교할 때, NAMMs는 성능 저하 없이 메모리 용량을 유의미하게 감소시켰습니다. 또한, NAMMs는 언어 과제로만 학습되었음에도 불구하고 다양한 입력 모달리티를 통해 다른 transformer 모델에 제로샷 전이(transfer) 되는 성과를 보였습니다.



### Controllable Generation via Locally Constrained Resampling (https://arxiv.org/abs/2410.13111)
Comments:
          arXiv admin note: text overlap with arXiv:2312.03905

- **What's New**: 이번 논문에서 저자들은 LLMs (Large Language Models)의 제한을 받는 샘플링 문제를 해결하기 위한 새로운 확률론적 접근 방식을 제안합니다. 기존의 greedy 방법론 대신 Bayesian conditioning을 통해 더 글로벌한 제약 생성이 가능하도록 개선하였습니다.

- **Technical Details**: 제안된 방법은 LLM 샘플에서 유도된 지역적인 분포를 기반으로 하며, 이를 사용하여 제약을 조건화하고 샘플링합니다. 이 접근법은 싱글 토큰별로 제약을 강제로 이행하는 것이 아니라 전체 시퀀스를 고려하여 제약을 적용합니다. 제약 회로(Constraint Circuits)를 통해 Boolean python 함수를 사용하여 제약을 효율적으로 표현할 수 있습니다.

- **Performance Highlights**: 제안된 방법은 LLM의 독소 생성 방지 및 Sudoku 퍼즐 해결과 같은 여러 작업에서 평가되었습니다. 특히, 독소 표현의 리스트를 제외함으로써 모델의 출력을 독소 생성에서 멀어지게 하여 이전의 방법론보다 우수한 성능을 보였으며, Sudoku 퍼즐에서는 100%의 정확도를 달성했습니다. GPT4-o와 Gemini 1.5와 비교할 때 이들의 정확도는 각각 26% 및 45%에 불과했습니다.



### Communication-Efficient and Tensorized Federated Fine-Tuning of Large Language Models (https://arxiv.org/abs/2410.13097)
- **What's New**: 본 논문에서는 파라미터 효율적인 미세 조정(PEFT) 방법을 여러 장치에 분산된 개인 데이터로 미세 조정하기 위한 새로운 방법인 FedTT 및 FedTT+를 제안합니다. 이 방법들은 Federated Learning(FL)과 통합되어 사용자 프라이버시를 보호하면서도 데이터 이질성 문제를 해결하는 데 초점을 맞추고 있습니다.

- **Technical Details**: FedTT는 클라이언트 측 모델의 인코더/디코더 블록에 텐서화된 어댑터를 통합하여 LLM을 적응시키는 방법입니다. FedTT는 크로스-사일로 FL 및 대규모 크로스-디바이스 FL 모두에 적용될 수 있습니다. FedTT+는 데이터 이질성에 대한 강인성을 추가적으로 향상시키기 위해 텐서 요소의 일부를 적응적으로 동결하여 학습 가능한 파라미터 수를 줄입니다.

- **Performance Highlights**: BERT 및 LLaMA 모델에 대한 실험 결과, 제안된 방법들이 기존의 연합 PEFT 접근 방식과 비교하여 데이터 이질성 문제를 성공적으로 해결했으며, 최대 10배의 통신 비용 절감 효과를 보였습니다. FedTT+는 상태-of-the-art 크로스-사일로 FL 방법들을 능가하는 성능을 보여주었습니다.



### Self-Comparison for Dataset-Level Membership Inference in Large (Vision-)Language Models (https://arxiv.org/abs/2410.13088)
- **What's New**: 본 논문에서는 Self-Comparison Membership Inference (SMI)이라는 새로운 데이터셋 수준의 멤버십 추론 방법을 제안합니다. 기존의 Membership Inference Attack (MIA) 방법론의 한계를 극복하기 위해 설계된 이 방식은 정체된 데이터에 대한 비밀스러운 사용을 감지할 수 있습니다.

- **Technical Details**: SMI 방법은 멤버 데이터(membership data)의 접두사와 비멤버 데이터(non-membership data)의 접미사를 비교하여, 훈련 데이터에 대한 모델의 암기 현상을 유도합니다. 구체적으로는, 멤버 데이터가 주어졌을 때, 패러프레이징(paraphrasing)을 통해 두 세트의 분포가 어떻게 변화하는지를 비교합니다. 기존 MIA 방식은 반드시 그라운드 트루스 멤버 데이터를 요구하는 반면, SMI는 유사한 분포를 가지지 않아도 되는 보조 비멤버 세트를 요구합니다.

- **Performance Highlights**: SMI 방법은 다양한 LLMs 및 VLMs 모델에서 기존의 MIA 및 데이터셋 추론 기술보다 뛰어난 성능을 보였습니다. 이는 특히 그라운드 트루스 멤버 데이터에 대한 사전 지식이 없을 때에도 유효합니다. 실험 결과, 우리의 방법이 공개 모델, 파인 튜닝된 모델 및 API 기반 상업 모델에 이르기까지 여러 데이터셋에서 우수한 성능을 발휘함을 확인하였습니다.



### MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models (https://arxiv.org/abs/2410.13085)
- **What's New**: 본 논문에서는 Med-LVLMs의 사실성을 향상시키기 위해 MMed-RAG라는 다중 모달 RAG 시스템을 제안합니다. 이 시스템은 도메인 인식을 위한 검색 메커니즘, 적응형 검색된 컨텍스트 선택 방법, 그리고 검증 가능한 RAG 기반의 선호 미세 조정 전략을 포함하여, 의료 데이터의 다양한 분야에 대해 일반적이고 신뢰할 수 있는 접근 방식을 제공합니다.

- **Technical Details**: MMed-RAG는 세 가지 주요 요소로 구성됩니다: 1) 도메인 인식 검색 메커니즘 - 입력 의료 이미지에 적합한 검색 모델을 선택하기 위해 도메인 식별 모듈을 설계하였습니다. 2) 적응형 검색된 컨텍스트 선택 - 검색된 컨텍스트의 개수를 선택하는 방법입니다. 3) RAG 기반 선호 미세 조정 - 교차 모달 정렬을 개선하고 모델과 실제 간의 전체 정렬을 높이는 방법입니다.

- **Performance Highlights**: MMed-RAG는 5개의 의료 데이터세트에서 실험을 실시하여, Medical VQA와 보고서 생성 작업에서 각각 18.5% 및 69.1%의 사실 정확도를 향상시켰습니다. 전반적으로 MMed-RAG는 Med-LVLMs의 정확성을 평균 43.8% 개선하였습니다.



### Language Models as Semiotic Machines: Reconceptualizing AI Language Systems through Structuralist and Post-Structuralist Theories of Languag (https://arxiv.org/abs/2410.13065)
Comments:
          18 pages, 2 figures

- **What's New**: 이 논문은 대형 언어 모델(LLM)을 인간의 인지 과정을 모방하는 것으로 보지 않고, 기호학적 기계(semiotic machines)로 재구성하여 이해하는 새로운 프레임워크를 제안합니다. 저자는 페르디낭 드 소쉬르(Ferdinand de Saussure)와 자크 데리다(Jacques Derrida)의 언어 이론에 기초하여 LLM을 언어 자체의 모델로 설명하고 있습니다.

- **Technical Details**: 논문은 세 부분으로 나뉘어 있으며, 첫 번째 부분에서는 word2vec 임베딩 알고리즘의 작동 방식과 소쉬르의 기호 체계에 대한 설명을 제공합니다. 두 번째 부분에서는 데리다의 비판을 적용하여 LLM이 모델링하는 '쓰기'의 개념을 논의합니다. 마지막 세 번째 부분에서는 현대 LLM이 의미의 고정되지 않은 개념을 어떻게 반영하는지에 대해 설명하며, '다음 토큰 생성' 메커니즘이 의미의 역동성을 포착한다고 주장합니다.

- **Performance Highlights**: 대형 언어 모델은 언어 사용에서 거의 인간의 수준에 도달하며, word2vec 알고리즘을 기반으로 하여 컨텍스트 기반의 의미 표현을 채택하고 있습니다. 이러한 모델은 개별 단어뿐만 아니라 문장 및 다른 언어 구조를 포함한 복잡한 표현을 생성하려고 하며, 현재 사용되는 데이터셋은 방대한 양의 정보를 포함하고 있어, LLM이 언어 자체에 근접한 모델링을 가능하게 합니다.



### Supply Chain Network Extraction and Entity Classification Leveraging Large Language Models (https://arxiv.org/abs/2410.13051)
Comments:
          11 pages, 4 figures

- **What's New**: 이 논문에서는 자연어 처리(NLP) 및 대형 언어 모델(LLM)를 활용하여 비정형 텍스트 데이터를 기반으로 공급망 그래프를 구축하는 새로운 접근 방식을 제안합니다. 특히 토목 공학 산업을 사례 연구로 삼아 LLM이 기업, 프로젝트 등의 숨겨진 관계를 발견할 수 있는 방법을 보여줍니다.

- **Technical Details**: 본 연구는 데이터 수집, 프롬프트 엔지니어링, 그래프 구축, 엔티티 분류의 네 가지 주요 단계로 구성된 방법론을 적용합니다. 데이터 수집은 공개 소스의 뉴스 기사를 통해 이루어지며, 각 기업에 대해 2018년부터 2023년까지 연도별로 최소 10개의 뉴스 기사를 수집하여 총 50개의 원시 텍스트 데이터 포인트를 확보합니다. 이를 통해 각 기업의 활동에 대한 포괄적인 관점을 유지합니다.

- **Performance Highlights**: LLM으로 특정 산업에 맞춰 세부 조정(fine-tuning)을 수행함으로써 엔티티 분류의 정확도가 향상되었으며, 이는 산업별 공급망 분석의 잠재력을 강조합니다. 본 연구는 LLM을 통해 공급망 네트워크 모델링의 자동화를 가능하게 한 첫 번째 사례로, 공급망 동학에 대한 깊이 있는 통찰력을 제공합니다.



### LLM Confidence Evaluation Measures in Zero-Shot CSS Classification (https://arxiv.org/abs/2410.13047)
- **What's New**: 이 논문은 데이터 주석 작업에서의 대형 언어 모델(LLM)의 신뢰성을 평가하기 위해 세 가지 핵심 기여를 제안합니다. 첫째, 데이터 주석 작업을 위한 불확실성 정량화(UQ) 성능 측정 방법을 제안합니다. 둘째, 세 가지 서로 다른 LLM과 CSS 데이터 주석 작업에서 다섯 가지 UQ 전략을 처음으로 비교합니다. 셋째, LLM의 낮은 신뢰도 주석을 효과적으로 식별하고 잘못 레이블이 붙은 데이터를 발견하는 새로운 UQ 집계 전략을 소개합니다.

- **Technical Details**: 연구는 대형 언어 모델의 신뢰성을 평가하기 위해 여러 UQ 기법을 사용해 분석하였으며, 새로운 UQ 집계 전략을 제안하여 잘못 분류된 LLM 레이블 데이터를 식별하는 과정을 보다 간소화하였습니다. 이 논문은 다양한 UQ 방법을 비교하고, AUC(Area Under Curve) 분석을 통해 신뢰도 점수의 백분위수 기반 임계값을 적용하여 기술됩니다.

- **Performance Highlights**: 제안된 UQ 집계 전략은 기존 방법에 비해 개선된 성능을 보여주며, Human-in-the-loop 데이터 주석 프로세스를 획기적으로 개선할 수 있음을 입증했습니다. 이를 통해, LLM이 생성한 데이터 중 인간이 자원을 소모해야 할 데이터의 식별이 용이해졌습니다.



### Sensitivity of Generative VLMs to Semantically and Lexically Altered Prompts (https://arxiv.org/abs/2410.13030)
- **What's New**: 본 논문은 generative vision-language 모델(VLM)의 프롬프트에서의 어휘적 및 의미적 변화에 대한 민감성을 평가합니다. SugarCrepe++ 데이터셋을 사용하여 이러한 모델들이 프롬프트의 사소한 변화에 어떤 영향을 받는지를 분석합니다.

- **Technical Details**: 이 연구는 BLIP, BakLLaVA 및 GPT-4o와 같은 generative VLMs의 어휘 및 의미 변화 이해 능력을 평가합니다. SugarCrepe++ 데이터셋에서는 두 개의 긍정적인 캡션(P1, P2)과 하나의 부정적인 캡션(N)을 포함하여, 어휘적으로 다르지만 의미적으로 유사한 캡션을 제공합니다.

- **Performance Highlights**: 실험 결과, BakLLaVA와 GPT-4o 모두 입력 프롬프트의 약간의 변화에 대해 높은 민감성을 보였으며, 동일한 프롬프트에서 옵션의 순서를 변경하는 것만으로도 성능에 큰 차이를 보였습니다. 또한, 서로 다른 VLMs 간의 일관성이 부족하여 결과의 일관성을 높이기 위한 추가 연구가 필요함을 보여줍니다.



### Learning Representations for Reasoning: Generalizing Across Diverse Structures (https://arxiv.org/abs/2410.13018)
Comments:
          PhD thesis

- **What's New**: 이 논문은 인공지능 분야에서의 추론의 중요성과 관련하여, 기존의 지식 구조 및 쿼리 구조를 초월하는 일반화 알고리즘을 제안합니다. 또한, 구조적 데이터에서 기계 학습 개발을 가속화하기 위한 시스템을 구축했습니다.

- **Technical Details**: 제안된 모델 NBFNet은 전통적인 경로 기반(path-based) 방법과 동적 프로그래밍(dynamic programming)을 결합하여 새로운 엔티티(entity) 및 관계(relation) 어휘를 사용한 지식 그래프의 미지의 부분에 대한 유도 일반화를 실현합니다. A*Net은 NBFNet의 확장형으로, 수백만 개 규모의 지식 그래프에서도 우수한 성능을 발휘합니다.

- **Performance Highlights**: NBFNet은 기존의 최신 방법들에 비해 모든 설정에서 평균 18%의 성능 향상을 이루었으며, 특히 지식 그래프 완성(HITS@1) 및 유도 관계 예측(HITS@10)에서 각각 22%의 성능 개선을 보여줍니다.



### Large Language Models as a Tool for Mining Object Knowledg (https://arxiv.org/abs/2410.12959)
- **What's New**: 이번 연구는 대형 언어 모델(LLMs)이 일반 물체에 대한 명시적 지식을 공식화하는 능력을 조사하며, 물체의 구성 요소(부분) 및 재질에 대한 지식을 명확히 구분합니다. 이로 인해 LLMs의 잠재력을 이용하여 AI 시스템의 지식 기반을 보강하거나 대체하는 데 기여할 수 있습니다.

- **Technical Details**: 이 연구에서는 few-shot과 zero-shot multi-step 프롬프트 기법을 활용하여 약 2,300개의 물체 및 하위 유형에 대한 부품과 재질에 대한 데이터를 수집합니다. LLM의 언어 이해 능력을 통해 물체의 전체 구성과 부품의 재질에 대한 지식을 명확히 정리합니다.

- **Performance Highlights**: 평가 결과, 추출된 지식의 대부분이 인간의 이해와 일치하나, 프롬프트 기법에 따라 과도하게 단순화되거나 필요 이상의 세부 정보가 제공되는 경우도 있음을 보여줍니다. 이 연구는 물체 구조 및 구성에 대한 추론을 위한 유용한 자원으로서 기능할 것입니다.



### Mechanistic Unlearning: Robust Knowledge Unlearning and Editing via Mechanistic Localization (https://arxiv.org/abs/2410.12949)
Comments:
          20 pages, 19 figures, 7 tables

- **What's New**: 본 연구에서는 대형 언어 모델(LLM)에서 지식 편집 및 비학습(unlearning) 방법의 향상을 위한 기계적 해석 가능성(mechanistic interpretability)의 역할을 조사합니다. 특히, 출력 보존(output preserving) 기반의 구성 요소 로컬라이제이션 방식과 예측 가능한 중간 상태를 이용한 고수준 메커니즘 발견 방식 간의 차이를 강조합니다.

- **Technical Details**: 연구에서는 사실 회상(factual recall)을 위한 로컬라이제이션을 FLU(fact lookup) 메커니즘에 기반하여 진행하며, 이를 통해 이전의 방법들보다 더 견고한 편집 및 비학습을 구현합니다. 다양한 입력/출력 형식에서의 견고함이 향상되었으며, 원하지 않는 정보를 다시 학습하는 것을 방지하면서 부작용(side effects)도 감소합니다.

- **Performance Highlights**: Gemma-7B 모델을 사용하여 다양한 데이터셋에서 FLU 메커니즘 기반의 편집 및 비학습이 기존 방법들보다 더 높은 견고성과 일반화 능력을 나타낸다는 것을 확인하였습니다. 특히, 스포츠 사실 데이터셋과 CounterFact 데이터셋에서 실험을 수행하여 이런 결과를 입증하였습니다.



### Exploiting Longitudinal Speech Sessions via Voice Assistant Systems for Early Detection of Cognitive Declin (https://arxiv.org/abs/2410.12885)
Comments:
          IEEE International Conference on E-health Networking, Application & Services

- **What's New**: 본 연구는 음성 비서 시스템(VAS)을 활용하여 18개월 동안 3개월 간격으로 7회의 음성 데이터를 원격으로 수집하는 종단적 연구를 진행하였다. 이를 통해 경도 인지 장애(MCI) 탐지와 인지 변화 예측 방법론을 제안하였다.

- **Technical Details**: 연구에서는 음성과 관련된 데이터에서 역사적 데이터를 포함한 두 가지 방법을 사용하여 MCI 탐지와 인지 변화를 예측하였다. 저장된 음성 데이터는 35명의 참가자들로부터 수집되었으며, 이들은 20명의 MCI 환자와 15명의 건강 대조군(HC)으로 구성되었다. 각 참가자는 18개의 인지 과제 질문에 답함으로써 인지 능력이 평가되었다. 음성 데이터는 자가 감독 학습 및 대형 언어 모델을 통해 추출된 음향(acoustic) 및 언어적(linguistic) 특징을 사용하여 분석되었다.

- **Performance Highlights**: 연구 결과, 역사적 데이터를 포함하였을 때 MCI 탐지의 F1-score는 음향 특징의 경우 58.6%에서 71.2%로(12.6% 개선), 언어적 특징의 경우 62.1%에서 75.1%로(13.0% 개선) 상승하였다. 인지 변화 예측에 있어서도 음향 특징의 경우 73.7%의 F1-score를 달성하였다. 이러한 결과들은 음성 비서 시스템을 기반으로 한 음성 세션이 조기 인지 저하 탐지에 잠재력을 지니고 있음을 확인시켜 준다.



### MIND: Math Informed syNthetic Dialogues for Pretraining LLMs (https://arxiv.org/abs/2410.12881)
Comments:
          31 pages, 5 figures, 14 tables

- **What's New**: 이번 연구에서는 대규모 다채로운 Math Informed syNthetic Dialogue (MIND) 생성 방법을 제안하여 대형 언어 모델(LLMs)의 수학적 추론 능력을 향상시키는 것을 목표로 합니다.

- **Technical Details**: MIND를 활용하여 OpenWebMath (OWM)를 기반으로 합성 대화를 생성하고, 이를 통해 새로운 수학 데이터셋인 MIND-OWM을 만듭니다. 실험 결과, 대화 참여자 간의 지식 격차를 포함하는 것이 고품질 수학 데이터를 생성하는 데 필수적임을 보여줍니다. 또한, 합성 데이터와 원본 데이터를 사전 학습(pretraining) 시 효과적으로 포맷하고 통합하는 방법을 식별하였습니다.

- **Performance Highlights**: MIND-OWM에서 사전 학습된 모델은 원본 데이터만으로 사전 학습된 모델 대비 수학적 추론에서 상당한 향상을 보였습니다 (GSM8K: +13.42%, MATH: +2.30%). 또한, 전문 지식(MMLU: +4.55%, MMLU-STEM: +4.28%) 및 일반적인 추론 과제(GENERAL REASONING: +2.51%)에서도 우수한 성능을 기록했습니다.



### IMAS: A Comprehensive Agentic Approach to Rural Healthcare Delivery (https://arxiv.org/abs/2410.12868)
- **What's New**: COVID-19 이후, 농촌 지역의 의료 접근성 문제 해결을 위한 첨단 의료 보조 시스템(IMAS) 제안

- **Technical Details**: IMAS는 Large Language Models (LLMs)와 다섯 가지 주요 구성 요소(번역, 의료 복잡성 평가, 전문가 네트워크 통합, 최종 의료 조언 생성, 응답 단순화)로 구성되어 있습니다.

- **Performance Highlights**: IMAS는 MedQA, PubMedQA, JAMA 데이터셋을 통해 효과성을 입증하였으며, 특히 저소득 및 정보 소외 지역사회의 의료 근로자들에게 더 쉽게 접근할 수 있도록 지원합니다.



### A Dutch Financial Large Language Mod (https://arxiv.org/abs/2410.12835)
Comments:
          9 pages, 1 figure, accepted at ACM ICAIF'24

- **What's New**: 이 논문은 다양한 금융 과제를 위해 특별히 설계되고 최적화된 최초의 네덜란드어 금융 대형 언어 모델(LLM)인 FinGEITje를 소개합니다. 이와 함께 140,000개 이상의 샘플로 구성된 전문 네덜란드어 금융 지시 조정 데이터셋이 공개되며, 자동 번역 및 데이터 처리 방법을 활용하여 구축되었습니다.

- **Technical Details**: FinGEITje는 금융 과제를 위한 첫 번째 네덜란드어 LLM으로, 데이터셋 생성을 위한 공개 데이터 구축 방법론이 제공됩니다. 또한 독립 평가자로서 LLM을 활용하는 자동 평가 방법을 도입하여 성능 평가 시 수작업 개입을 줄였습니다.

- **Performance Highlights**: FinGEITje는 다섯 가지 주요 네덜란드어 및 영어 금융 과제에서 우수한 성능을 나타내며, 금융 뉴스 및 소셜 미디어 게시물의 감정 분류, 금융 문서에서의 주요 개체 식별, 가격 변동에 대한 주장 검증을 위한 뉴스 헤드라인 분류, 금융 관계 추출 및 특정 금융 질의 응답 등의 중요한 애플리케이션을 제공합니다.



### Rethinking Misalignment in Vision-Language Model Adaptation from a Causal Perspectiv (https://arxiv.org/abs/2410.12816)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 본 논문에서는 CLIP 모델의 두 가지 정렬 문제인 작업 불일치(task misalignment) 및 데이터 불일치(data misalignment)를 해결하기 위한 방법을 제안합니다. 특히, 데이터 불일치가 다운스트림 작업에서 성능에 미치는 영향을 분석하고 Causality-Guided Semantic Decoupling and Classification (CDC) 방법론을 개발하여 이 문제를 해결합니다.

- **Technical Details**: CDC 방법론은 두 가지 주요 구성 요소인 Visual-Language Dual Semantic Decoupling (VSD)와 Decoupled Semantic Trusted Classification (DSTC)로 이루어져 있습니다. VSD는 다양한 의미를 표현하는 여러 프롬프트 템플릿을 모델에 통합하여 학습합니다. DSTC는 각 층에서 분리된 의미에 기반하여 분류 작업을 독립적으로 수행하며, 예측의 불확실성을 동시에 추정합니다.

- **Performance Highlights**: 다양한 데이터셋과 여러 작업에서 진행된 실험 결과, CDC 방법론이 CLIP의 성능을 유의미하게 향상시킴을 보여주었습니다. 특히, 새로운 클래스에 대한 인식 성능이 개선되는 효과가 있음을 확인했습니다.



### Context is Key(NMF): Modelling Topical Information Dynamics in Chinese Diaspora Media (https://arxiv.org/abs/2410.12791)
Comments:
          Accepted to the 2024 Computational Humanities Research Conference (CHR)

- **What's New**: 중국 공화국(China)의 선거 개입 관련 연구에서, KeyNMF라는 새로운 정적 및 동적 주제 모델링 접근 방식이 제안되었습니다. 이 연구는 중국 언론 내 정보 역동성을 연구하기 위한 파이프라인을 개발하여, 2024년 유럽 의회 선거 전후의 데이터 분석에 적용했습니다.

- **Technical Details**: KeyNMF는 transformer 기반의 문맥적 임베딩 모델을 활용하여, 정적 및 동적 주제 모델링을 수행합니다. 이 접근법은 각 문서에서 키워드 중요도를 계산하고, NMF(Non-negative Matrix Factorization)를 통해 이를 분해하는 구조를 가지고 있습니다. 또한, 유럽의 중국 디아스포라 미디어에 대한 자료를 분석하여 정보의 새로움과 공명을 측정하며, 시계열 데이터의 변화에 따라 주제를 효과적으로 추적할 수 있습니다.

- **Performance Highlights**: KeyNMF 접근법은 중국 데이터셋에 대해 효과적임을 입증하며, 복잡한 시스템 내 정보 역동성을 묘사하는 기존 기법들과 통합되어 실험됩니다. 연구 결과는 중국 디아스포라 미디어의 정보 역동성의 효과성을 입증함과 동시에, 향후 연구를 위한 기초 자료를 제공합니다.



### Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception (https://arxiv.org/abs/2410.12788)
- **What's New**: 이 논문에서는 Retrieval-Augmented Generation (RAG) 방법론에서 중요한 텍스트 청킹(text chunking)의 이전 이해를 확장하는 "메타 청킹(Meta-Chunking)"이라는 새로운 개념을 도입합니다.

- **Technical Details**: 메타 청킹은 문장과 문단 사이의 세밀한 경계를 정의합니다. 이 논문에서 제안된 두 가지 전략인 Margin Sampling Chunking과 Perplexity Chunking을 통해 LLMs (Large Language Models)를 사용하여 텍스트 청킹 과정을 세분화하였습니다.

- **Performance Highlights**: 11개의 데이터셋에서 실험한 결과, 메타 청킹이 RAG 기반의 단일 및 다단계 질문 응답 성능을 더 효율적으로 개선함을 보였습니다. 예를 들어, 2WikiMultihopQA 데이터셋에서는 유사도 청킹(similarity chunking)보다 1.32 높은 성능을 보였고, 소요 시간은 45.8%에 불과했습니다.



### Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information (https://arxiv.org/abs/2410.12774)
Comments:
          main paper 12 pages, Appendix 7 pages, 1 figure, 18 tables

- **What's New**: 이 연구에서는 다중 작업 학습(Multi-task Learning, MTL)에서의 작업 관련성을 정의하기 위해 pointwise V-usable 정보(점별 V-사용 가능 정보, PVI)를 기반으로 한 새로운 메트릭을 제안합니다. PVI는 데이터셋이 주어진 모델에 대해 얼마나 많은 사용 가능한 정보를 포함하고 있는지를 추정하는 최근의 기법입니다.

- **Technical Details**: PVI는 모델에 따라 데이터 인스턴스의 난이도를 추정하며, 이를 통해 비슷한 난이도의 작업들을 그룹화하여 MTL에서 성능을 극대화할 수 있다고 가정합니다. 15개의 NLP 데이터셋을 이용한 실험을 통해 MTL 결과를 기존 단일 학습자 모델 및 최신 대형 언어 모델과 비교하였습니다. 또한, PVI 기반 작업 그룹화를 통한 성능 비교를 실시하였습니다.

- **Performance Highlights**: PVI 추정치가 비슷한 작업들을 그룹화함으로써 다중 작업 학습이 성능을 개선하고, 총 파라미터 수를 줄이면서도 다양한 도메인에 걸쳐 일관된 성능을 보였습니다. 이 연구는 PVI 추정값을 이용한 작업 그룹화가 STL 성능을 초과할 수 있음을 입증하였습니다.



### Unitary Multi-Margin BERT for Robust Natural Language Processing (https://arxiv.org/abs/2410.12759)
- **What's New**: 최근 딥 러닝에서 적대적 공격에 대한 발전으로 인해 자연어 처리(NLP) 시스템이 위험에 처해 있습니다. 이 논문은 Bidirectional Encoder Representations from Transformers(BERT)의 견고성을 크게 향상시키는 보편적인 기술인 Unitary Multi-Margin BERT(UniBERT)를 소개합니다.

- **Technical Details**: UniBERT는 cross-entropy loss를 multi-margin loss로 교체하고, weight 매트릭스를 단위 행렬로 제한하여 적대적 공격에 대한 강인성을 강화합니다. 이러한 접근 방식을 통해 다중 클래스를 구분하는 신경 표현을 보다 뚜렷하게 분리합니다. 수치적으로, UniBERT는 공격 후 분류 정확도를 5.3% 개선하여 73.8%에 도달하며, 단일 스칼라 매개변수를 통해 사전 및 사후 정확도 간의 트레이드오프를 조정할 수 있습니다.

- **Performance Highlights**: UniBERT는 기존의 방어 방법들과 비교할 때 여러 작업에서 공격 후 정확도를 유의미하게 향상시킵니다. 특히, 우리의 모델은 적대적 훈련 방식에 대한 의존 없이 설계되었으며, 간단한 구현이 가능합니다.



### StyleDistance: Stronger Content-Independent Style Embeddings with Synthetic Parallel Examples (https://arxiv.org/abs/2410.12757)
- **What's New**: 이 논문에서는 StyleDistance라는 새로운 접근 방식을 도입하여 컨텐츠와 독립적인 스타일 임베딩을 강화하는 방법을 제안합니다. 기존의 방식들이 콘텐츠와 스타일을 혼합할 위험이 있던 점을 해결하기 위해, 대형 언어 모델을 활용하여 스타일 변화를 조절한 거의 동일한 패러프레이즈의 합성 데이터셋을 생성합니다.

- **Technical Details**: StyleDistance는 40가지 스타일 특징을 기반으로 긍정적 및 부정적인 예시를 생산하여 보다 정밀한 대비 학습(contrastive learning)을 가능하게 합니다. 이러한 합성 데이터는 기존 데이터셋에서 발생하는 콘텐츠 누출(content leakage) 문제에 대해 더 강건합니다. 이 연구에서는 인간 및 자동 평가를 통해 StyleDistance 임베딩의 품질을 검토하였습니다.

- **Performance Highlights**: StyleDistance는 스타일 임베딩의 콘텐츠 독립성(content independence)을 획기적으로 개선하여, 실제 벤치마크에서 일반화가 가능하다는 것을 입증하였고, 다운스트림 애플리케이션에서 기존 스타일 표현을 초월하는 성능을 보였습니다.



### Comparative Analysis of Extrinsic Factors for NER in French (https://arxiv.org/abs/2410.12750)
- **What's New**: 이 논문은 프랑스어 명명실체인식(NER) 향상을 위한 다양한 외부 요인의 영향을 분석하고, 제한된 데이터에서 모델 성능을 높이는 기법들을 탐색합니다.

- **Technical Details**: 논문은 세 가지 주석 기법(i.e., IO, BIO, BIOES)과 두 가지 데이터 증강 기법(label-wise token replacement, shuffle within segments)을 사용하여 French NER 성능을 향상시키는 방법을 제시합니다. 모델은 조건부 랜덤 필드(CRF)와 LSTM으로 구축되었으며, Transformer 기반의 임베딩(Flaubert)을 활용했습니다.

- **Performance Highlights**: BIOES 주석 기법을 사용하여 모델의 F1 점수를 62.41에서 79.39로 향상시켰습니다. LSTM과 Transformer 기반 임베딩 결합이 성능을 크게 개선하며, 데이터 증강 기법을 적용한 결과 훈련 데이터셋과 엔티티 수가 약 2배 증가했습니다.



### WorldMedQA-V: a multilingual, multimodal medical examination dataset for multimodal language models evaluation (https://arxiv.org/abs/2410.12722)
Comments:
          submitted for review, total of 14 pages

- **What's New**: 이번 연구에서는 헬스케어 환경에서 VLM(vision language models)의 성능 평가를 위해 다국어, 다모달의 가치 있는 벤치마크 데이터셋인 WorldMedQA-V를 소개합니다. 이 데이터셋은 브라질, 이스라엘, 일본, 스페인 등 네 개 국가의 의료 이미지를 통합하여 568개의 레이블이 있는 선택형 QA를 포함하고 있습니다.

- **Technical Details**: WorldMedQA-V는 다양한 국가의 언어 환경을 지원하며, 의료 전문가에 의해 검증된 새로운 다모달 시험 문제를 포함합니다. 연구에서는 의료 시험 데이터에서 이미지 데이터를 추가할 때 성능 및 안정성에 미치는 영향을 조사하고, 다양한 언어 및 지역의 모델 성능 차이를 평가합니다.

- **Performance Highlights**: GPT4o 모델이 WorldMedQA-V에서 가장 높은 성능을 보였으며, 특히 일본 데이터셋에서 88%의 정확도를 달성했습니다. 전반적으로 모델은 영어로 번역된 데이터셋에서 더 나은 성과를 보였으며, 일부 데이터셋에서는 70%를 초과하는 성과를 기록했습니다.



### WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines (https://arxiv.org/abs/2410.12705)
- **What's New**: WorldCuisines라는 대규모 벤치마크가 소개되어 VLMs의 다문화적 및 다언어적 이해력을 평가할 수 있는 새로운 기준을 제시합니다. 이 벤치마크는 30개 언어와 방언에서 각각의 텍스트-이미지 쌍을 포함하고 있어 다문화적인 VQA 데이터셋으로는 가장 큰 규모를 자랑합니다.

- **Technical Details**: 이 연구는 VLMs를 평가하기 위해 100만 개 이상의 고품질의 다언어 및 다문화 텍스트-이미지 쌍으로 구성된 WorldCuisines를 개발했습니다. 벤치마크는 2가지 작업을 포함합니다: (1) 요리 이름 예측, (2) 요리가 일반적으로 소비되는 위치 예측. VQA 데이터셋은 30개 언어와 방언으로 구성되어 있으며, 다양한 질문 유형에 대한 평가를 포함합니다.

- **Performance Highlights**: VLMs는 적절한 위치 맥락에서 더 좋은 성능을 보였으나, 적대적인 맥락에서는 어려움을 겪었고, 특정 지역 요리와 언어 예측에서의 어려움이 드러났습니다. 데이터셋과 관련된 주의 깊은 메타데이터와 이미지도 함께 제공되어 향후 연구 지원을 기대합니다.



### Building Better: Avoiding Pitfalls in Developing Language Resources when Data is Scarc (https://arxiv.org/abs/2410.12691)
- **What's New**: 이 논문은 중간에서 낮은 자원(threshold) 언어에 대한 NLP(자연어처리) 연구의 한계와 문제점을 조사하며, 데이터 수집, 윤리적 주석(annotation) 관행, 데이터 품질에 중점을 두고 연구자 및 관계자의 피드백을 수집했습니다.

- **Technical Details**: 설문조사를 통해 데이터 품질, 언어적 및 문화적 적합성, 주석 관행의 윤리성을 분석하였으며, 그 결과로 고품질 언어 아티팩트(artefacts)를 만들기 위한 여러 가지 추천 사항을 제시합니다. 연구자들은 언어 사용자와의 밀접한 협업이 필요하며, 주장하는 바에 따르면 자원 부족은 연구 선택 및 방법론에 영향을 미쳤습니다.

- **Performance Highlights**: 연구는 NLP 커뮤니티와의 대화를 통해 중간 및 낮은 자원 언어에 대한 공통적인 인센티브, 한계 및 관행을 조명하였고, 향후 연구 및 개선 방향에 대한 실질적인 추천을 제공합니다.



### Evaluating Morphological Compositional Generalization in Large Language Models (https://arxiv.org/abs/2410.12656)
Comments:
          33 pages

- **What's New**: 본 연구는 대형 언어 모델(LLMs)의 형태론적 일반화 능력을 구성적(compositional) 관점에서 체계적으로 조사합니다. 형태소(morpheme)를 구성적 원시 단위로 정의하고, 이를 기반으로 한 새로운 유전자 및 판별(task) 과제를 설계하였습니다.

- **Technical Details**: 우리는 지도 학습된 멀티링궐 모델들(GPT-4, Gemini-1.5 등)을 평가하였으며, 터키어와 핀란드어와 같은 교착어(agglutinative languages)를 대상으로 했습니다. 모델은 새로운 단어의 어근에 적용했을 때 형태론적 연결(compositionality) 일반화가 부족하며, 형태론적 복잡성이 증가할수록 성능이 급격히 감소하는 경향을 보였습니다.

- **Performance Highlights**: 모델은 개별적인 형태론적 조합을 식별하는 데 있어 최소한의 성과를 보였지만, 그 성능은 시스템적이지 않아 인간과 비교했을 때 상당한 정확도 차이를 보였습니다. 인간은 복잡한 형태론적 구조에서도 일관된 성능을 유지하는 반면, 모델의 성능은 뚜렷한 감소를 보였습니다.



### From Measurement Instruments to Data: Leveraging Theory-Driven Synthetic Training Data for Classifying Social Constructs (https://arxiv.org/abs/2410.12622)
- **What's New**: 이 논문은 사회적 구조를 측정하는 데 있어 이론 기반의 합성(training) 데이터의 잠재력을 체계적으로 조사합니다. 이를 통해 사회 과학에서의 측정 도구에서 얻은 지식을 합성 데이터 생성에 어떻게 활용할 수 있는지를 탐구합니다.

- **Technical Details**: 연구자는 두 가지 초점을 두어 성차별(sexism)과 정치적 주제를 측정합니다. 연구의 핵심 질문은 이론 기반의 합성 데이터가 사회적 구조 측정의 성과를 향상시킬 수 있는가입니다. 논문에서는 annotation codebooks와 설문 척도를 사용하여 데이터 생성을 이끌어냅니다.

- **Performance Highlights**: 정치 주제 연구에서는 실제 데이터의 30-90%를 합성 데이터로 교체했을 때 성과가 유지되거나 소폭 향상되었습니다. 반면 성차별 연구에서는 합성 데이터의 비율이 증가할수록 모델의 성과가 떨어지는 경향을 보였습니다.



### Weak-to-Strong Generalization beyond Accuracy: a Pilot Study in Safety, Toxicity, and Legal Reasoning (https://arxiv.org/abs/2410.12621)
- **What's New**: 이 논문은 기존의 약한 감독자(w weak supervisors) 사용 방식을 확대하여 실제 정렬(alignment) 관련 과제에 적용하는 방법을 제시합니다.

- **Technical Details**: 약한 생성(weak-to-strong generation) 현상을 안전성(safety), 독성(toxicity), 법적 추론(legal reasoning)과 같은 복잡한 정렬 작업에 대해 실험적으로 입증합니다.

- **Performance Highlights**: 정렬 성능을 향상시키기 위한 효율적인 전략을 탐색하며, 특정 정렬 작업과 관련된 문제와 잠재적 해결책을 요약하고 분석합니다.



### Parsing Akkadian Verbs with Prolog (https://arxiv.org/abs/2410.12617)
Comments:
          6 pages, 9 figures, presented at ACL-02 the Association of Computational Linguistics, 2002

- **What's New**: 이 논문은 아카디안(Akkadian)의 유한 동사 형태를 위한 파싱(Parsing) 및 생성(Generation) 시스템을 설명합니다. 이 시스템은 접미사(suffixes)의 추가 가능성을 가지고 있으며, 프로로그(Prolog)로 구현되었습니다.

- **Technical Details**: 제시된 시스템은 D, N, G 어간(stems)을 해석하고, 목적격(accusative), 여격(dative), 벤티브(ventive) 어미(endings)를 처리할 수 있도록 설계되었습니다.

- **Performance Highlights**: 이 시스템은 아카디안 동사 형태의 파싱과 생성을 효과적으로 지원하여 이 언어의 구조적 이해를 향상시킬 수 있는 잠재력을 보여줍니다.



### Exploring Model Kinship for Merging Large Language Models (https://arxiv.org/abs/2410.12613)
Comments:
          Ongoing work

- **What's New**: 이 연구는 모델 병합(model merging)을 위한 새로운 평가 기준인 모델 친척성(model kinship)을 도입합니다. 모델 친척성은 LLM(대형 언어 모델) 간의 유사성과 관련성을 측정하여, 반복적인 병합 과정에서 성능 개선을 돕는 정보를 제공합니다.

- **Technical Details**: 모델 병합은 여러 개별 모델을 통합하여 다중 작업 목표를 달성하는 전략입니다. 본 논문에서는 모델 친척성을 기준으로 한 Top-k Greedy Merging 전략을 제안하며, 이는 모델 진화(model evolution)에서의 최적화 문제와 지역 최적점(local optima traps)을 피할 수 있도록 도와줍니다.

- **Performance Highlights**: 모델 친척성을 사용한 새로운 병합 전략은 벤치마크 데이터셋에서 더 나은 성능을 달성하며, 평균 성능 향상과 강한 상관관계가 있음을 보여줍니다. 이 연구는 모델 병합의 효율성과 효과성을 높이기 위한 실용적인 전략을 제시합니다.



### Not All Votes Count! Programs as Verifiers Improve Self-Consistency of Language Models for Math Reasoning (https://arxiv.org/abs/2410.12608)
- **What's New**: 이 논문에서는 PROVE라는 프로그램 기반 검증 프레임워크를 제안하여 수학적 추론 문제를 해결하는 방식이 개선되었습니다. 이 방법은 중간 단계의 오류를 줄이고, 최종 답변을 집계하기 전에 가능성 있는 잘못된 추론 경로를 필터링합니다.

- **Technical Details**: PROVE는 여러 개의 추론 경로를 샘플링하여 가장 일반적인 답변을 선택하는 대신, 생성된 솔루션과 불일치하는 프로그램 출력과 관련된 솔루션을 거부하고, 파이썬 프로그램으로 검증된 솔루션만 집계합니다. 이 연구는 0.5B에서 13B 파라미터를 가진 다양한 오픈소스 LLM 13개를 대상으로 전국적으로 7개의 수학 벤치마크에서 평가하였습니다.

- **Performance Highlights**: PROVE는 GSM8K 벤치마크에서 Qwen2-0.5B-Instruct의 정확도를 48.85%에서 53.83%로, Llama-3.2-1B-Instruct의 정확도를 65.66%에서 73.01%로, Gemma-2-2b-it의 정확도를 73.39%에서 79.61%로, Llama-2-7B-chat의 정확도를 41.32%에서 59.51%로 증가시켰습니다.



### CCSBench: Evaluating Compositional Controllability in LLMs for Scientific Document Summarization (https://arxiv.org/abs/2410.12601)
- **What's New**: CCSBench라는 새로운 벤치마크를 소개하며, 이는 과학 문서 요약에서 여러 속성을 동시에 제어할 수 있도록 돕습니다. 특히, 길이(length)와 경험적 초점(empirical focus) 등의 명시적 속성뿐만 아니라, 가독성(readability)과 같은 암시적 속성도 포함됩니다.

- **Technical Details**: CCSBench는 explicit (명시적) 속성과 implicit (암시적) 속성의 세밀한 제어를 가능하게 하며, 명시적 속성은 길이와 키워드 포함을, 암시적 속성은 가독성과 경험적 초점을 다룹니다. 이 연구에서는 다양한 LLMs(GPT-4, LLaMA2 등)에서 CCSBench를 기반으로 한 실험을 수행하여, 제어 속성 간의 균형을 맞추는 데 있어 큰 언어 모델들이 겪는 한계를 밝혀냈습니다.

- **Performance Highlights**: 대부분의 LLM들은 가독성을 높이 유지하면서 경험적 초점을 강조하는 데 어려움을 겪습니다. 특히, LLaMA2와 같은 decoder-only 모델들은 긴 의존성을 모델링하는 데 있어서 문제가 발생하며, encoder-decoder 모델들은 더 나은 적응성을 보여줍니다. 이러한 결과는 과학적 요약을 위한 조합 가능성에 대한 새로운 연구 필요성을 강조합니다.



### On the Risk of Evidence Pollution for Malicious Social Text Detection in the Era of LLMs (https://arxiv.org/abs/2410.12600)
- **What's New**: 이번 논문에서는 악의적인 소셜 텍스트를 식별하는 데 있어 증거를 강화한 감지기의 새로운 잠재적 위험성을 탐구합니다. 특히 대형 언어 모델(LLMs)의 발전으로 인한 증거 오염(evidence pollution) 문제를 다룹니다.

- **Technical Details**: 연구는 기본적인 오염, 리프레이징(rephrasing), LLMs에 의한 증거 생성(manipulation) 등 여러 가지 시나리오에서 증거를 조작하는 방법을 모사합니다. 이에 대한 방어 전략으로 데이터와 모델 측면에서 기계 생성 텍스트 감지(machine-generated text detection), 전문가 혼합(mixture of experts), 매개변수 업데이트(parameter updating) 등의 세 가지 접근 방식을 제안합니다.

- **Performance Highlights**: 실험 결과, 증거 오염, 특히 생성 전략이 기존의 감지기를 심각하게 약화시키는 것으로 나타났습니다. 그러나 방어 전략들이 증거 오염을 완화할 수 있지만, 주석 데이터의 필요성과 높은 추론 비용(inference costs) 등의 실용적인 제한이 존재합니다.



### Can We Reverse In-Context Knowledge Edits? (https://arxiv.org/abs/2410.12586)
- **What's New**: 이번 연구에서는 인-컨텍스트 지식 편집(IKE)의 검출 및 역전 과정에 대한 새로운 접근 방안을 제시합니다. 특히, IKE를 악용한 편집을 탐지하고 이를 복원하는 새로운 과제를 소개하였습니다.

- **Technical Details**: IKE(인-컨텍스트 지식 편집)는 LLM(대형 언어 모델)의 출력물을 파라미터 변경 없이 효율적으로 수정할 수 있도록 합니다. 저자들은 특수하게 조정된 역전 토큰을 사용하여 IKE 편집을 회복하는 방법을 제안합니다.

- **Performance Highlights**: 연구에서는 IKE 편집을 80% 이상의 정확도로 검출할 수 있음을 보였으며, 연속적인 역전 토큰을 활용하여 여러 LLM에서 원본 출력을 80% 이상 회복할 수 있음을 입증했습니다.



### STRUX: An LLM for Decision-Making with Structured Explanations (https://arxiv.org/abs/2410.12583)
Comments:
          10 pages, 7 figures, submitted to NAACL 2025

- **What's New**: 이 논문에서는 새로운 LLM (Large Language Model) 의사결정 프레임워크인 STRUX를 소개합니다. STRUX는 구조화된 설명을 제공하여 LLM의 의사결정을 개선합니다.

- **Technical Details**: STRUX는 긴 정보를 간결한 핵심 사실의 표로 정제한 후, 자기 반성 단계(self-reflection steps)를 통해 어떤 사실이 중요한지를 결정합니다. 이 사실을 특정 결정과 관련하여 유리한(favorable) 것과 불리한(adverse) 것으로 분류합니다. 마지막으로, LLM을 미세 조정(fine-tune)하여 이러한 핵심 사실을 식별하고 우선순위를 매깁니다.

- **Performance Highlights**: STRUX는 수익 전화 회의(transcripts) 데이터를 기반으로 한 주식 투자 의사 결정 예측 과제에서 강력한 기준선(baselines) 대비 뛰어난 성능을 보였습니다. 이는 의사결정의 투명성을 높여주며, 사용자들이 다양한 요인의 영향을 이해할 수 있도록 합니다.



### A Claim Decomposition Benchmark for Long-form Answer Verification (https://arxiv.org/abs/2410.12558)
Comments:
          Accepted by CCIR 2024

- **What's New**: 이번 연구에서는 LLM(대규모 언어 모델)의 응답에서 사실성이 결여된 'hallucination' 문제를 해결하기 위해, 각 주장에 대한 출처를 명확히 하는 새로운 기준을 제시합니다. 특히, 각 응답에서 주장이나 진술을 식별하는 것의 중요성을 강조하며, 이를 위한 새로운 Claim Decomposition Benchmark를 도입합니다.

- **Technical Details**: 우리는 CACDD(Chinese Atomic Claim Decomposition Dataset)를 소개합니다. 이 데이터셋은 500개의 인간 주석 질문-응답 쌍으로 구성되어 있으며, 총 4956개의 원자적(claim) 주장을 포함합니다. 데이터를 고품질로 유지하기 위해 전문가의 추가 주석이 포함되었습니다. 실험에서는 zero-shot, few-shot 및 fine-tuned LLM를 사용하여 성능 비교를 진행하였습니다.

- **Performance Highlights**: 실험 결과, 주장 분해(claim decomposition)는 매우 도전적인 작업으로, 추가적인 탐색이 필요하다는 것을 보여주었습니다. 모든 코드와 데이터는 공개적으로 사용 가능합니다.



### LLM-based Translation Inference with Iterative Bilingual Understanding (https://arxiv.org/abs/2410.12543)
Comments:
          Work in progress

- **What's New**: 본 연구에서는 Iterative Bilingual Understanding Translation (IBUT)이라는 새로운 방법을 제안합니다. 이 방법은 LLM의 교차 언어 능력과 번역 작업의 이중 특성을 기반으로 하여 번역 품질을 개선하는 데 초점을 맞추고 있습니다.

- **Technical Details**: IBUT 방법은 Understanding Generation, Alignment Judgment, Iterative Refinement, Understanding-Based Translation의 네 가지 부분으로 구성됩니다. IBUT는 먼저 LLM을 활용하여 소스 및 타겟 언어에 대한 맥락 이해를 생성하고, 그 후 이 이해를 기반으로 다양한 언어 쌍에서 번역을 수행합니다.

- **Performance Highlights**: 실험 결과, IBUT는 여러 강력한 비교 방법들보다 뛰어난 성능을 보였으며, 특히 뉴스, 상식, 문화 번역 벤치마크와 같은 다양한 도메인에 일반화되는 성능이 입증되었습니다. 평균적으로 +1.3, +4.2, +2.3의 COMET 점수 향상을 보였습니다.



### MedAide: Towards an Omni Medical Aide via Specialized LLM-based Multi-Agent Collaboration (https://arxiv.org/abs/2410.12532)
Comments:
          LLM-based Multi-Agent Collaboration for Medical Applications

- **What's New**: 이번 논문에서는 복잡한 의료 응용 프로그램에서 LLM의 한계를 극복하기 위해 MedAide라는 새로운 프레임워크를 제안합니다. 이 시스템은 개인화된 추천 및 진단 분석을 제공하여 LLM의 성능을 향상시킵니다.

- **Technical Details**: MedAide는 retrieval-augmented generation을 통해 쿼리를 재작성하여 정확한 의료 의도 이해를 할 수 있도록 합니다. 또한, 문맥 인코더(contextual encoder)를 사용하여 의도 프로토타입 임베딩(intent prototype embeddings)을 생성하고, 이를 통해 유사성 매칭(similarity matching)으로 세밀한 의도를 인식합니다.

- **Performance Highlights**: 상당한 실험을 통해 MedAide가 현재의 LLM을 초월하고 의료 전문성(medical proficiency)과 전략적 추론(strategic reasoning)을 향상시킨다는 결과가 나타났습니다. 이 결과는 네 가지 의료 벤치마크에서 전문가의 평가와 자동화된 지표 자동(metrics) 평가를 통해 얻어졌습니다.



### FiRST: Finetuning Router-Selective Transformers for Input-Adaptive Latency Reduction (https://arxiv.org/abs/2410.12513)
Comments:
          17 pages, 6 figures, Submitted to ICLR 2025

- **What's New**: 본 연구에서는 Auto-regressive Large Language Models (LLMs)의 출력 지연(latency) 문제를 해결하기 위한 새로운 알고리즘인 FIRST를 제안합니다.

- **Technical Details**: FIRST는 입력 시퀀스에 대해 동적으로 transformer 레이어의 하위 집합을 선택하기 위해 레이어별 라우터(layer-specific routers)를 사용하는 알고리즘입니다. 프롬프트(prompt)는 디코딩 과정에서 어떤 레이어를 건너뛸지 결정합니다. FIRST는 KV 캐싱(KV Caching)과의 호환성을 유지하여 더 빠른 추론을 가능하게 하며, LoRA 어댑터를 탑재하여 외부 데이터셋에서 세부 조정을 통해 태스크별 정확성을 향상시킵니다.

- **Performance Highlights**: FIRST는 광범위한 실험을 통해 레이턴시(latency)를 크게 감소시키면서도 경쟁력 있는 성능을 유지함을 보여주며, 저자원 환경(low-resource environments)에서 LLM 배포를 위한 효율적인 솔루션을 제공합니다.



### Advancing Fairness in Natural Language Processing: From Traditional Methods to Explainability (https://arxiv.org/abs/2410.12511)
Comments:
          PhD Thesis, Toulouse University

- **What's New**: 이 박사 논문은 자연어 처리(NLP) 시스템 내의 공정성(fairness)을 보장하는 방법에 대한 연구를 다룹니다. 특히, NLP 기술이 다양한 인간 집단에 미치는 영향을 분석하면서, 기술적 도전 과제 이상으로 도덕적이고 윤리적인 필요성을 강조합니다.

- **Technical Details**: 먼저, 다중 클래스 분류기에서 편향(bias)을 완화하기 위한 혁신적인 알고리즘을 소개하고, 이는 고위험 NLP 애플리케이션에 적합하게 설계되었습니다. 덧붙여, Bios 데이터셋 분석을 통해 데이터셋 크기가 차별적 편향에 미치는 영향 및 기존의 공정성 메트릭의 한계를 논의합니다. 이후 COCKATIEL이라는 모델 불변 설명 가능성(explainability) 방법을 제안하며, 이는 Transformer 모델의 개념을 식별하고 순위를 매기는 데 있어 이전 접근 방식을 뛰어넘습니다. 마지막으로, TaCo라는 새로운 방법을 통해 Transformer 모델 임베딩의 편향을 중화(neutralize)하는 기여를 합니다.

- **Performance Highlights**: 공정성과 설명 가능성을 결합한 이 연구는 NLP 패러다임에 도전하고 재구성하는 데 기여하며, 기계 학습에서 공정성에 대한 지속적인 담론에 귀중한 솔루션을 제공합니다.



### With a Grain of SALT: Are LLMs Fair Across Social Dimensions? (https://arxiv.org/abs/2410.12499)
- **What's New**: 본 논문은 다양한 성별, 종교 및 인종에 대한 오픈 소스 Large Language Models (LLMs)의 편향 분석을 제시합니다. 저자들은 편향 탐지 데이터셋을 생성하기 위한 방법론을 소개하며, 이를 위해 7개의 편향 트리거를 사용합니다.

- **Technical Details**: 트리거에는 General Debate, Positioned Debate, Career Advice, Story Generation, Problem-Solving, Cover-Letter Writing, CV Generation이 포함됩니다. 각 트리거에 대해 다양한 성별, 종교 및 인종 그룹을 아우르는 프롬프트를 생성하기 위해 GPT-4o를 사용합니다. 생성된 데이터셋에서 Llama 및 Gemma 모델을 평가하고, GPT-4o-mini를 통해 각 그룹과 관련된 LLM 생성 텍스트를 익명화한 후, GPT-4o-as-a-Judge를 사용하여 쌍대 비교를 수행합니다. 편향 정도는 쌍대 비교에서의 승패 수를 통해 정량화합니다.

- **Performance Highlights**: 분석은 영어, 독일어, 아랍어의 세 가지 언어에 걸쳐 편향이 어떻게 나타나는지를 탐구합니다. 연구 결과, LLM은 각 카테고리에서 특정 그룹에 대해 강한 양극화를 보이며, 모델 간 일관성을 확인했습니다. 그러나 언어가 변할 때 문화적 신호와 맥락의 차이로 인해 변화와 이상이 나타납니다.



### End-to-end Planner Training for Language Modeling (https://arxiv.org/abs/2410.12492)
Comments:
          14 pages

- **What's New**: 이번 연구에서는 언어 모델(LLM)의 훈련을 개선하기 위한 새로운 방법을 제안합니다. 특히, 계획 모듈(planning module)을 통해 미래 문장의 추상 레이블을 예측하고 이 예측에 기반하여 LLM을 조정하는 방식에서 차별화를 도모하였습니다.

- **Technical Details**: 기존 방법은 비미분 가능(non-differentiable)하여 계획자(planner)와 LLM의 공동 엔드투엔드 조정(joint end-to-end tuning)이 불가능했습니다. 본 논문에서는 이러한 문제를 해결하기 위해 레이블의 확률을 혼합 가중치(mixing weights)로 사용하여 LLM을 미분 가능하게 조정하는 방법을 제안합니다.

- **Performance Highlights**: 실험 결과, perplexity(퍼플렉시티)가 일관되게 개선되었으며, 이는 제안된 방법의 효과성을 나타냅니다.



### Insights from the Inverse: Reconstructing LLM Training Goals Through Inverse RL (https://arxiv.org/abs/2410.12491)
Comments:
          Preprint

- **What's New**: 이 논문에서는 인공지능 언어 모델(Large Language Models, LLMs)의 해석을 위한 새로운 접근 방식으로 역강화학습(Inverse Reinforcement Learning, IRL)을 소개합니다. 이 방법을 통해 LLM의 암묵적 보상 함수(reward functions)를 회수하는 실험을 수행하였으며, 다양한 크기의 독성 관련 LLM에서 최대 80.40%의 정확도로 인류의 선호도를 예측하는 보상 모델을 추출했습니다.

- **Technical Details**: 역강화학습(IRL)은 에이전트의 행동 관찰을 기반으로 기저에 있는 보상 함수를 회복하고자 하는 기계 학습의 패러다임입니다. 이 연구에서는 LLM에 IRL을 적용하여 이들의 의사결정 과정을 인식하고, LLM 교육 과정의 비가시성을 해소하고자 합니다. 특히, 아이디어는 보상 함수가 쉽게 회복될 경우 LLM이 안전성 위험에 빠질 가능성이 더 높아질 수 있음을 나타냅니다. 논문에서는 최대 마진 IRL(Maximum Margin IRL) 방법을 사용하여 보상 기능을 추출하는 데 중점을 두었습니다.

- **Performance Highlights**: 여러 독성 데이터셋에서의 실험 결과, 간단한 IRL 방법인 Max-Margin 방식으로도 보상 모델이 성공적으로 추출되었으며, 새로운 LLM을 미세 조정(fine-tuning)하는 데 효과적임을 입증했습니다. 이 연구는 LLM의 정렬(alignment) 이해 및 개선을 위한 새로운 관점을 제공하며, 강력한 언어 모델의 책임 있는 개발 및 배치에 대한 의미 있는 시사점을 제시합니다.



### KcMF: A Knowledge-compliant Framework for Schema and Entity Matching with Fine-tuning-free LLMs (https://arxiv.org/abs/2410.12480)
- **What's New**: 이 논문은 Knowledge-Compliant Matching Framework (KcMF)를 제시하여 대규모 언어 모델(LLM)의 데이터 매칭(Task) 관련 신뢰성 문제를 해결하고자 한다. KcMF는 도메인별 세부 튜닝 없이 사용할 수 있으며, pseudo-code 기반의 작업 분해 전략을 사용하여 LLM의 추론 과정을 안내한다.

- **Technical Details**: KcMF는 두 가지 메커니즘인 Dataset as Knowledge (DaK)와 Example as Knowledge (EaK)를 사용하여 비구조화된 도메인 지식이 부족할 때 도메인 지식 세트를 구축한다. 또한, 결과 앙상블 전략인 Inconsistency-tolerant Generation Ensembling (IntGE)을 도입하여 여러 지식 출처를 활용하고 잘못 형식화된 출력을 억제한다.

- **Performance Highlights**: KcMF는 MIMIC 및 Synthea와 같은 다양한 벤치마크에서 평가되었으며, 이전의 비LLM 상태에서 가장 뛰어난 방법들보다 평균 F1 점수 22.9% 향상을 보이며, SOTA LLM과도 효과적으로 경쟁한다. KcMF는 다양한 LLM에서 잘 일반화된다는 점도 주목할 만하다.



### MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models (https://arxiv.org/abs/2410.12478)
Comments:
          Comments: This work was intended as a replacement of arXiv:2402.13606 and any subsequent updates will appear there

- **What's New**: 이 논문은 대규모 언어 모델(LLMs)의 신뢰성과 관련된 문제를 다루며, 영어 외의 언어에서의 신뢰도 추정(confiendce estimations)에 대한 연구가 부족하다는 점을 강조합니다. 특히, 다국어 신뢰도 추정(Multilingual Confidence estimation, MlingConf)에 대한 포괄적인 조사를 소개합니다.

- **Technical Details**: 연구는 언어에 구애받지 않는(Language-agnostic, LA) 및 언어 특정(Language-specific, LS) 작업을 다루어, 다국어 신뢰도 추정의 성능과 언어 우세(effect of language dominance)에 대해 탐구합니다. LA 작업을 위한 고품질 다국어 데이터셋 4개와 특정 사회, 문화적 및 지리적 맥락을 고려한 LS 작업을 위한 데이터셋 1개가 사용되었습니다.

- **Performance Highlights**: 실험 결과, LA 작업에서는 영어가 신뢰도 추정에서 두드러진 언어적 우세를 보이는 반면, LS 작업에서는 질문과 관련된 언어를 사용하여 LLM을 유도할 때 다국어 신뢰도 추정에서 더 나은 성과를 나타냅니다. 이는 LS 작업에서 언어 특정 프롬프트를 사용하는 간단하면서 효과적인 원어민 톤 유도 전략(native-tone prompting strategy)의 필요성을 시사합니다.



### Retrieval-Reasoning Large Language Model-based Synthetic Clinical Trial Generation (https://arxiv.org/abs/2410.12476)
- **What's New**: 이번 연구에서는 대규모 언어 모델(LLM)을 활용하여 인공적이지만 현실적인 이중 성공/실패 레이블을 가진 임상 시험 데이터를 생성하는 새로운 Retrieval-Reasoning few-shot 프레임워크를 소개합니다.

- **Technical Details**: 이 프레임워크는 실제 임상 시험 데이터를 기반으로 하여 생성된 합성(artificial) 임상 시험 데이터의 다양성과 현실성을 극대화하며, 모델 학습을 위한 이론적 토대를 제공합니다. 또한, Synthetic clinical trial datasets에 대한 바이너리 분류기(bi-nary classifier)로 사전 훈련된 모델의 파인튜닝(fine-tuning)을 통해 하위 작업(downstream tasks)인 시험 결과 예측(trial outcome prediction)의 성능을 향상시킴을 입증합니다.

- **Performance Highlights**: 실제 임상 시험 데이터베이스에서 수행한 실험 결과, 생성된 합성 데이터가 실제 데이터셋을 효과적으로 보강하며, 임상 연구를 가속화하고 환자 개인 정보 보호를 위한 윤리적 기준을 유지하는 데 기여할 수 있음을 시사합니다.



### Learning to Predict Usage Options of Product Reviews with LLM-Generated Labels (https://arxiv.org/abs/2410.12470)
Comments:
          9 pages

- **What's New**: 이 논문은 고객 리뷰에서 제품 사용 옵션을 예측하는 독립적인 모델을 학습하기 위한 새로운 접근 방식을 제안하며, 이를 통해 대규모 데이터 세트를 효율적으로 라벨링하는 방법을 논의합니다. 일반적인 crowd-sourcing 방식의 한계를 극복하기 위해 LLM(대형 언어 모델)을 활용하여 몇 가지 샷 학습(few-shot learning)으로 데이터 라벨링을 수행하는 방법을 소개합니다.

- **Technical Details**: 제안된 방법론은 GPT-4와 같은 최신 LLM을 활용하여 고객 리뷰로부터 제품 사용 옵션을 추출하는 복잡한 태스크에 중점을 두고 있습니다. 연구진은 이러한 사용 옵션을 텍스트 문구로 정의하며, 여러 참고 기준을 비교하기 위한 새로운 평가 지표인 HAMS4를 도입했습니다. 또한, LLM 사용에 따른 에너지 효율성과 개인 정보 보호 측면에서의 이점을 강조하고 있습니다.

- **Performance Highlights**: 실험 결과, LLM을 활용한 라벨링이 전문 vendor 서비스보다 높은 품질의 데이터를 생성함을 보여주었습니다. 특히, GPT-4를 통해 생성된 라벨은 도메인 전문가의 수준에 도달하였으며, LLM을 사용한 데이터 주석 작업은 인력을 활용하는 것에 비해 높은 비용 절감을 가능하게 합니다.



### Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention (https://arxiv.org/abs/2410.12462)
- **What's New**: 본 논문에서는 Inference-Time Cross-Lingual Intervention (INCLINE)라는 새로운 프레임워크를 제안합니다. 이 방법은 낮은 성능의 언어를 높은 성능의 언어와 정렬하여 LLM의 성능을 개선합니다.

- **Technical Details**: INCLINE은 주로 데이터 병렬성(parallel sentences)을 이용해 Least-Squares 최적화를 통해 정렬 행렬(alignment matrices)을 학습합니다. 이 행렬은 추론(inference) 동안 낮은 성능 언어의 표현을 높은 성능 언어의 공간으로 변환하는 데 사용됩니다.

- **Performance Highlights**: 아홉 개의 벤치마크에서 다섯 개의 LLM을 대상으로 한 광범위한 실험을 통해 INCLINE이 다양한 작업 및 언어에서 성능을 유의미하게 개선한다고 밝혔습니다. 이 방법은 비용 효율적이며 다양한 응용 프로그램에 적용할 수 있습니다.



### The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph (https://arxiv.org/abs/2410.12458)
Comments:
          19 pages, 5 figures, 5 tables

- **What's New**: 이 논문에서는 새롭게 제안된 데이터 선택 기법인 GraphFilter에 대해 설명합니다. 이 방법은 데이터셋을 두 부분으로 나누어진 그래프(bipartite graph)로 표현하여 문장과 이들로 구성된 n-그램(n-grams)을 연결합니다.

- **Technical Details**: GraphFilter는 문서 간의 관계 및 언어 패턴을 효과적으로 포착하여 n-그램 다양성을 증대시키는 문장을 선택할 수 있도록 합니다. 선택 과정에서 품질과 다양성을 균형 있게 고려하기 위해, 품질 메트릭(quality metric)과 다양성 메트릭(diversity metric)을 곱셈 방식으로 결합한 우선 순위 함수(priority function)를 제안합니다. GraphFilter는 반복적으로 높은 우선 순위 문장을 선택하고, n-그램을 제거하여 그래프를 업데이트하며, 변화하는 데이터 환경을 반영하기 위해 우선 순위를 재계산합니다.

- **Performance Highlights**: 여섯 개의 널리 사용되는 벤치마크를 기반으로 세 가지 모델 백본(model backbone)을 사용하여 광범위한 실험을 실시하였으며, GraphFilter는 아홉 가지 기준선(baseline) 접근 방식을 모두 초월하는 성능을 보였습니다. 결과적으로 모델 성능 및 계산 효율성(computational efficiency)이 우수함을 입증했습니다.



### Open Ko-LLM Leaderboard2: Bridging Foundational and Practical Evaluation for Korean LLMs (https://arxiv.org/abs/2410.12445)
- **What's New**: Open Ko-LLM Leaderboard2가 기존의 Open Ko-LLM Leaderboard의 한계를 보완하여 새롭게 등장했습니다. 이 새로운 리더보드는 더 관련성 높은 실제 과업을 기반으로 한 벤치마크를 제공합니다.

- **Technical Details**: 기존의 벤치마크는 주로 영어 버전의 번역본으로 구성되어 있었으나, Open Ko-LLM Leaderboard2는 네 가지 새로운 한국어 네이티브 벤치마크를 도입하여 한국어의 고유한 특성을 보다 잘 반영합니다.

- **Performance Highlights**: 이 개선된 리더보드는 한국어 Large Language Model (LLM)에 대한 보다 의미 있는 평가를 제공하여 모델들의 질적 영향력을 높이는 데 기여하고자 합니다.



### Expanding Chatbot Knowledge in Customer Service: Context-Aware Similar Question Generation Using Large Language Models (https://arxiv.org/abs/2410.12444)
- **What's New**: 이 논문에서는 고객의 질문 표현의 다양성을 수용하기 위해 사전 정의된 질문-답변 쌍(QA pairs)을 기반으로 하는 서비스 챗봇의 응답 신뢰성을 높이는 접근법으로 유사 질문 생성(Similar Question Generation, SQG) 방법을 제안합니다.

- **Technical Details**: 제안된 SQG 방법은 대형 언어 모델(Large Language Models, LLMs)을 기반으로 하며, 이를 통해 원래 QA 쌍과 의미적 일관성을 유지하면서도 다양한 질문을 생성할 수 있습니다. LLM의 자연어 이해 능력을 활용하여 특별히 설계된 프롬프트를 사용하여 모델을 세밀하게 조정합니다.

- **Performance Highlights**: 실제 고객 서비스 데이터셋을 통해 수행된 실험 결과, 제안된 방법이 의미적 다양성 면에서 기존의 방법들을 크게 초월하는 성과를 보였으며, 인간 평가에서도 고객의 의도를 반영한 답변 통합이 비즈니스 요구사항을 충족하는 질문의 수를 증가시키는 데 중요한 요소임을 확인했습니다.



### Conformity in Large Language Models (https://arxiv.org/abs/2410.12428)
Comments:
          16 pages (8 pages main body), 14 figures

- **What's New**: 이 연구는 최신 LLMs(대형 언어 모델)에서의 conformity effect(순응 효과)를 분석하고, 모델들이 다수 의견에 얼마나 수용적인지를 탐구합니다.

- **Technical Details**: 심리 실험을 LLM에 적용하여, 원래 선택에 관계없이 모든 LLM이 다양한 지식 영역에서 다수에 대해 다양한 수준의 순응을 보이는 사실을 입증했습니다. 또한, 모델이 예측에 대한 불확실성이 높을수록 순응 가능성이 증가한다는 점을 발견했습니다. 훈련 패러다임과 입력 특성 등 순응에 영향을 미치는 요소를 분석하여, instruction-tuned 모델은 순응에 덜 영향을 받는다고 밝혀냈습니다.

- **Performance Highlights**: 정확한 응답에도 불구하고 LLM들이 다수의 의견에 따르는 경향이 있으며, 더 자연스러운 다수 톤이 순응을 강화하는 경향이 있습니다. 연구에서는 Devil's Advocate와 Question Distillation 두 가지 개입 방법을 제안하여, LLM의 순응을 완화하기 위한 통찰을 제공합니다.



### Theoretical Analysis of Hierarchical Language Recognition and Generation by Transformers without Positional Encoding (https://arxiv.org/abs/2410.12413)
Comments:
          55 pages, 11 figures

- **What's New**: 본 연구에서는 Transformers가 특정 positional encoding(위치 인코딩) 없이도 모델 크기에 비례하여 계층적 언어(hierarchical language)를 효율적으로 인식하고 생성할 수 있다는 건설적 증명을 제시합니다.

- **Technical Details**: 연구에서는 causal masking(인과 마스킹)과 시작 토큰(starting token)이 Transformers가 계층 구조에서 positional information(위치 정보)과 depth(깊이)를 계산하도록 할 수 있음을 보여줍니다. 이를 통해 positional encoding 없이도 계층적 언어 생성을 가능하게 함을 입증하였습니다.

- **Performance Highlights**: 또한, 명시적 positional encoding이 시퀀스 길이(sequence length)에 대한 일반화(generalization)에 부정적인 영향을 미칠 수 있다는 점도 제안하였습니다.



### Nominal Class Assignment in Swahili: A Computational Accoun (https://arxiv.org/abs/2410.12406)
Comments:
          Tenth Italian Conference on Computational Linguistics (CliC-it-2024)

- **What's New**: 스와힐리어의 의미론(semantics)과 명사 클래스 할당(nominal class assignment) 간의 관계를 다룬 연구로, 최초로 각 명사 클래스의 의미적 응집력(semantic cohesion)을 정량적으로 평가하고 이의 본질을 설명하려 하였습니다.

- **Technical Details**: 스와힐리는 총 18개의 명사 클래스를 가지고 있으며, 각 명사 클래스는 접사(affix)에 의해 신호(signal)가 제공됩니다. 연구는 단어 벡터(word vectors)를 기반으로 하여 의미적 내용을 예측 가능한 요소인지를 컴퓨터적으로 조사합니다. 스와힐리 명사의 번역을 통해 형태론적(confounding morphological cues) 접근을 피하고, TUKI 스와힐리-영어 사전을 사용하여 6,341개의 고유 기록을 수집하였습니다.

- **Performance Highlights**: 이 연구는 스와힐리어 명사 클래스의 의미 바로잡기 성능에 대한 새로운 통찰력을 제공하며, 명사 클래스의 예측 가능성에 대한 새로운 평가를 제시합니다. 종래 연구들과 달리, 형식적 성능 지표를 극대화하는 것이 아닌 의미론적 내용만으로 명사 클래스 소속을 예측하는 데 초점을 맞추었습니다.



### ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs (https://arxiv.org/abs/2410.12405)
Comments:
          EMNLP 2024, Findings

- **What's New**: 이 연구에서는 LLMs(대형 언어 모델)의 프롬프트(prompt) 민감도를 평가하고 이해하기 위한 새로운 프레임워크인 ProSA를 소개합니다. 기존 연구에서는 주로 인스턴스 수준의 프롬프트 변동성을 간과하였고, 이에 따른 주관적 평가의 영향도 외면해왔습니다.

- **Technical Details**: ProSA는 새로운 민감도 측정 지표인 PromptSensiScore를 포함하며, 디코딩(confidence) 신뢰도를 활용하여 LLMs의 작동 메커니즘을 해명하는 데 집중합니다. 이 연구는 여러 작업을 포함하여 프롬프트 민감성이 데이터셋과 모델에 따라 변동하며, 대형 모델이 더 뛰어난 강건성을 보이는 것을 발견했습니다.

- **Performance Highlights**: 우리의 연구 결과에 따르면 몇 가지 사례(few-shot examples)를 제시하는 것이 민감도 문제를 완화시킬 수 있으며, 복잡한 추론-oriented 작업에서 주관적 평가도 프롬프트 민감성에 영향을 받습니다. 또한, 모델의 높은 신뢰도가 프롬프트 강건성과 상관관계가 있음을 나타냅니다.



### Tracking Universal Features Through Fine-Tuning and Model Merging (https://arxiv.org/abs/2410.12391)
- **What's New**: 본 연구에서는 다양한 텍스트 도메인에서 미세 조정된 언어 모델 간의 특징 발생, 소멸 및 지속성을 조사합니다. 1층의 Transformer 언어 모델을 BabyLM 코퍼스와 Python 코드의 조합에 대해 훈련시키고, 이후 TinyStories와 Lua 언어에서 각각의 모델을 미세 조정한 후, 구형 선형 보간(Spherical Linear Interpolation) 기술을 사용하여 이 두 모델을 통합합니다.

- **Technical Details**: 실험은 기초 모델인 BabyPython을 사용하여 진행되며, 이 모델은 BabyLM 100M 코퍼스와 Python 코드의 일부로 훈련됩니다. 각각의 미세 조정 모델은 Lua 언어와 TinyStories 데이터셋으로 이루어져 있으며, 이들은 통합되어 LuaStories라는 새로운 모델이 생성됩니다. 특징 추출은 Sparse Autoencoder를 통해 이루어지며, 3백만 토큰의 데이터를 샘플링하여 특징 활성화 패턴을 수집합니다. 특징의 지속 가능성은 80% 이상의 상관관계를 기준으로 정의됩니다.

- **Performance Highlights**: LuaStories 모델은 원래의 Lua와 TinyStories 각 모델에 비해 정확도가 20% 낮지만, 두 모델의 공통 기초 모델에 비해서는 약 20% 향상된 성능을 보입니다. 이 모델은 Lua와 TinyStories 데이터 모두에 대해 동등하게 정확한 모델링을 제공합니다.



### Prompt Compression for Large Language Models: A Survey (https://arxiv.org/abs/2410.12388)
- **What's New**: 최근 대규모 언어 모델(LLMs)을 활용하여 복잡한 자연어 작업을 수행하는 데 있어 긴 프롬프트(prompt)를 사용하는 것이 메모리 사용량과 추론 비용을 증가시킴에 따라, 프롬프트 압축(prompt compression) 기술에 대한 연구 관심이 높아지고 있습니다.

- **Technical Details**: 본 설문조사는 하드 프롬프트(hard prompt) 방법과 소프트 프롬프트(soft prompt) 방법으로 분류된 여러 프롬프트 압축 기술을 개관합니다. 이러한 기술의 기술적인 접근 방식을 비교하고, attention optimization, Parameter-Efficient Fine-Tuning (PEFT), modality fusion, 새로운 합성 언어(synthetic language)의 관점에서 이들의 메커니즘을 이해하는 다양한 방법을 탐구합니다.

- **Performance Highlights**: 프롬프트 압축 기술의 다운스트림(downstream) 적응을 검토한 후, 현재 프롬프트 압축 방법의 한계점을 분석하고, 압축 인코더 최적화, 하드 및 소프트 프롬프트 방법의 결합, 다중 모달리티(multimodality)에서의 통찰력 활용 등 여러 미래 방향을 제시합니다.



### Evaluation of Attribution Bias in Retrieval-Augmented Large Language Models (https://arxiv.org/abs/2410.12380)
- **What's New**: 이 논문에서는 retrieval augmented generation (RAG)에서 모델 출력의 검증 가능성을 높이기 위해 소스 문서에 답변을 귀속시키는 방법을 다룹니다. 특히, 우리는 LLMs의 귀속 민감도(attribution sensitivity)와 저자(authorship) 정보에 대한 편향(bias)을 검사합니다.

- **Technical Details**: 연구는 LLM에게 소스 문서의 저자에 대한 정보를 제공하고 이를 바탕으로 답변을 귀속시키도록 지시하는 실험적 설정을 설계했습니다. 여기서는 counterfactual evaluation을 사용하여 세 가지 LLM을 분석하며, 귀속 민감도와 편향을 평가합니다.

- **Performance Highlights**: 연구 결과, 소스 문서의 저자 정보를 추가하는 것이 LLM의 귀속 품질을 3%에서 18%까지 상당히 변화시킬 수 있음을 발견했습니다. 또한, LLM은 명시적인 인간 저자에게 귀속되는 경향이 있으며, 이는 이전 연구에서 LLM 생성 콘텐츠가 인간 작성 콘텐츠보다 선호될 수 있다는 결과에 대한 대안 가설로 작용할 수 있음을 보여줍니다.



### HerO at AVeriTeC: The Herd of Open Large Language Models for Verifying Real-World Claims (https://arxiv.org/abs/2410.12377)
Comments:
          A system description paper for the AVeriTeC shared task, hosted by the seventh FEVER workshop (co-located with EMNLP 2024)

- **What's New**: 이번 논문에서는 AVeriTeC 공유 작업을 위해 자동 사실 확인 프로세스를 수행하는 HerO 시스템을 소개합니다. HerO는 공개적으로 이용 가능한 Large Language Models (LLMs)만을 이용해 여러 단계의 자동 사실 확인을 수행하며, 이는 real-world claims(실제 세계의 주장) 검증에 그 가능성을 보여줍니다.

- **Technical Details**: HerO는 Evidence Retrieval(증거 검색), Question Generation(질문 생성), Veracity Prediction(진위 예측)의 각 단계에 LLM을 활용합니다. 특히, Generic Language Model('gpt') 및 Gemini 모델과 같은 독점적 LLM을 사용하지 않고, 오픈 LLM만 사용하여 시스템의 투명성을 확보했습니다. 하이브리드 검색 방법을 통해 상위 10개의 증거 후보를 결정합니다. 우리 시스템은 llama-3.1-70b와 SFR-embedding-2를 사용하여 최적의 성능을 보였습니다.

- **Performance Highlights**: HerO는 AVeriTeC 점수 0.57로 리더보드에서 2위를 차지했으며, 일반 LLM을 사용한 시스템이 실제 주장을 검증하는 데 성공적인 가능성을 보여주었습니다. 논문은 미래 연구를 위해 소스 코드를 공개합니다.



### GECTurk WEB: An Explainable Online Platform for Turkish Grammatical Error Detection and Correction (https://arxiv.org/abs/2410.12350)
- **What's New**: GECTurk WEB은 터키어의 문법 오류를 감지하고 수정할 수 있는 새로운 웹 기반 시스템으로, 기존의 도구들이 주로 맞춤법 오류에 집중했던 것과는 달리, 문법 오류에 중점을 두고 개발되었습니다.

- **Technical Details**: 이 시스템은 쉬운 접근성을 제공하며, 복잡한 문법 규칙을 가진 터키어의 일반적인 오류를 감지합니다. 여기에는 диacritics의 잘못된 사용, 복합어 및 외래어, 대명사, 경구와 같은 오류가 포함됩니다. 오프라인 및 온라인 도구로 제공되며 사용 효율성을 88.3으로 평가받았습니다.

- **Performance Highlights**: GECTurk WEB은 사용자가 문법 규칙을 학습하고 기억하는 데 도움을 주며, 참가자의 80%가 제시된 설명을 통해 문법 규칙을 이해하는 데 효과적이었다고 응답했습니다.



### A linguistic analysis of undesirable outcomes in the era of generative AI (https://arxiv.org/abs/2410.12341)
- **What's New**: 이 연구는 생성 AI 모델의 중장기 영향을 분석하며, 기계 생성 정보의 신뢰성을 탐구합니다. 특히, 기존 연구에서 소홀히 다루어진 언어적 측면을 집중적으로 분석하기 위해 LLama2의 대화형 버전을 기반으로 포괄적인 시뮬레이션 프레임워크를 제시합니다.

- **Technical Details**: 모델의 성능 저하는 'self-consuming loop'에 의해 일어납니다. 이 연구에서는 텍스트의 다양성을 측정하기 위해 엔트로피(Entropy), TTR(지수적 정확도)와 같은 언어적 척도와 POSTags 빈도를 사용합니다. 또한, n-그램(N-gram) 분석 및 의미망(Semantic Networks)을 통해 생성된 콘텐츠를 평가합니다.

- **Performance Highlights**: 연구 결과, LLama2 모델은 생성 과정에서 텍스트의 어휘적 풍부함이 감소하고 다양성이 줄어들며, 모델의 성능 저하는 콘텐츠의 질 저하와 동시에 언어적 패턴 왜곡으로 이어져 있다고 합니다. 이는 초기 입력 텍스트의 선택과 관리가 모델 붕괴 문제 해결에 매우 중요함을 강조합니다.



### Understanding the Role of LLMs in Multimodal Evaluation Benchmarks (https://arxiv.org/abs/2410.12329)
- **What's New**: 본 논문은 Multimodal Large Language Models (MLLMs)의 평가에서 LLM 백본(LLM backbone)의 역할을 심도있게 조사하여, 현재의 벤치마크가 실제로 멀티모달 추론(multimodal reasoning)을 평가하는 정도와 LLM의 사전 지식(prior knowledge)이 성능에 미치는 영향을 규명합니다.

- **Technical Details**: 우리는 LLM 백본과 멀티모달 통합(multimodal integration)의 기여도를 분리하기 위한 수정된 평가 프로토콜(modified evaluation protocol)과 LLM이 멀티모달 질문에 필요한 지식을 갖추고 있는지를 진단하는 자동 지식 식별 기술(automatic knowledge identification technique)을 소개합니다. 연구는 네 가지 다양한 MLLM 벤치마크와 여덟 가지 최첨단 MLLMs를 포함합니다.

- **Performance Highlights**: 핵심 발견은 일부 벤치마크가 시각적 입력 없이도 높은 성능(high performance)을 허용하며, LLM 백본의 부족한 세계 지식이 오류율의 최대 50%를 차지할 수 있다는 것입니다. 이는 언어 능력에 대한 심한 의존도를 보여줍니다. 지식 부족 문제를 해결하기 위해 우리는 지식 증강 파이프라인(knowledge augmentation pipeline)을 제안하며, 이는 특정 데이터셋에서 최대 60%의 성능 향상을 이루어 약 4배 성능 증가를 가져옵니다.



### Neuron-based Personality Trait Induction in Large Language Models (https://arxiv.org/abs/2410.12327)
- **What's New**: 이번 논문에서는 대형 언어 모델(LLMs)이 개인 특성을 모사하는 능력을 개선하기 위해 새로운 신경 기반 접근법을 제안합니다. 특히, 'PersonalityBench'라는 대규모 데이터셋을 구축하였으며, 이를 활용하여 개인 관련 뉴런을 효율적으로 식별하는 방법을 제시합니다.

- **Technical Details**: PersonalityBench는 심리학에서의 'Big Five' 개인 특성에 기반하여 LLMs의 생성 능력을 평가하는 데이터셋입니다. 이 연구에서 제안하는 방법은 특정 특성의 반대 측면을 조사하여 개인 관련 뉴런을 식별하고, 이러한 뉴런의 값을 조작하여 LLMs의 특성을 세밀하게 조절할 수 있게 합니다.

- **Performance Highlights**: 실험 결과, 제안된 뉴런 식별 및 특성 유도 방법이 미세 조정된 모델과 유사한 성능을 보여주며, 개인 특성 유도에 있어 보다 효율적이고 유연한 솔루션을 제공합니다.



### Optimizing Low-Resource Language Model Training: Comprehensive Analysis of Multi-Epoch, Multi-Lingual, and Two-Stage Approaches (https://arxiv.org/abs/2410.12325)
Comments:
          16 pages, 10 figures

- **What's New**: 본 논문은 저자원 언어(Low-resource language)를 위한 대형 언어 모델(Large Language Models, LLM)의 훈련 설정 최적화에 대한 문제를 다루고 있습니다. 기존의 연구들은 제한된 목표 언어 코퍼스를 효율적으로 활용하기 위해 다중 에포크, 다국어( multilingual), 및 이단계(training) 훈련 방법을 채택했지만, 이 세 가지 접근 방식을 결합하여 LLM 훈련을 위한 최적의 하이퍼파라미터 설정에 대한 이해가 부족했습니다.

- **Technical Details**: (1) 목표 언어 코퍼스의 양이 줄어들수록, 최적의 훈련 접근 방식은 단일 언어 단일 단계 훈련에서 다국어 이단계 훈련으로 전환됩니다. 이는 계산 예산(compute budget)에 따라 변경되는 기준이 있습니다. (2) 최적의 모델 규모(model scale)는 목표 언어 코퍼스의 양에 관계없이 안정적으로 유지되어, 단일 언어 훈련의 계산 최적 규모를 사용할 수 있습니다. (3) 최적의 에포크 수(epoch number)는 소규모 실험에서 대규모로 외삽(extrapolated)할 수 있습니다.

- **Performance Highlights**: 단일 단계 훈련(single-stage training)에서 목표 언어 검증 손실(validation loss)은 목표 언어 비율(target language ratio)에 대해 거듭제곱 법칙(power law)을 따른다고 주장하며, 이는 데이터 양, 모델 규모 또는 언어 쌍(pair)과는 무관한 지수를 가지고 있습니다.



### Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up (https://arxiv.org/abs/2410.12323)
- **What's New**: 이번 논문에서는 Reversal of Thought (RoT)라는 새로운 프레임워크를 제안하여 대형 언어 모델(LLM)의 논리적 추론 능력을 향상시킵니다. RoT는 메타 인지 메커니즘을 통합하여 LLM이 사람의 피드백에 기반하여 cognitive preference에 맞게 태스크별 프롬프트를 생성할 수 있도록 지원합니다.

- **Technical Details**: RoT는 Preference-Guided Reverse Reasoning 전략을 활용하여, pseudocode 계획을 위한 논리 기호를 통합하고, 쌍대 선호 자기 평가를 통해 특정 태스크를 위한 프롬프트를 생성합니다. 또한, Cognitive Preference Manager를 통해 LLM의 지식 경계를 평가하고, 알려진 태스크에 대한 솔루션 논리를 집계하며, 알려지지 않은 태스크에 대한 스타일 템플릿을 사용하여 논리적 추론 능력을 확장합니다.

- **Performance Highlights**: 여러 태스크에서의 실험 결과, RoT는 기존 방법들보다 논리적 추론의 정확성과 효율성 모두에서 우수한 성능을 보였습니다. 이는 RoT가 LLM의 논리적 유연성과 정확성을 동시에 개선하는 데 기여함을 나타냅니다.



### Open Domain Question Answering with Conflicting Contexts (https://arxiv.org/abs/2410.12311)
- **What's New**: 이 논문은 웹에서 검색된 정보가 상충하는 경우에 대해 다룬 첫 번째 연구 중 하나로, 25%의 명확한 질문이 상충하는 정보에 이끌릴 수 있음을 보여줍니다. 이 연구는 Question Answering with Conflicting Contexts (QACC)라는 데이터셋을 수집하고, 이를 기반으로 대형 언어 모델(LLMs)의 한계를 분석합니다.

- **Technical Details**: 연구팀은 Google Search API를 사용하여 명확한 질문에 대한 결과를 수집하고, Amazon Mechanical Turk를 통해 인간 주석자들이 상충하는 대답의 존재 여부를 판단하도록 했습니다. 이를 통해 명확한 질문의 약 25%가 상충하는 정보를 생성함을 발견했습니다. 또한, 이들은 GPT-3.5, Claude-3, Phi-3와 같은 세 가지 LLM을 평가하였고, 이러한 상충이 성능 저하를 초래한다는 것을 보여주었습니다.

- **Performance Highlights**: 주석자의 자연어 설명으로 LLM을 파인튜닝한 결과, LLM의 성능이 향상되었습니다. 특히, QACC 데이터셋과 DQ-Open 데이터셋에서 상충하는 정보를 처리하는 능력이 개선되었습니다. 이는 LLM이 상충하는 맥락을 이해하고 올바른 답변을 내리는 데 도움이 되는 중요한 통찰을 제시합니다.



### Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering Vectors (https://arxiv.org/abs/2410.12299)
- **What's New**: 이번 논문에서는 Semantics-Adaptive Dynamic Intervention (SADI)라는 새로운 접근법을 제안하여 기존의 고정된 Steering Vector의 한계를 극복하고, 다양한 입력 의미에 따라 모델 활성화를 동적으로 조정할 수 있는 방법을 제시합니다.

- **Technical Details**: SADI는 Contrastive Pairs의 활성화 차이를 활용하여 모델 활성화에 영향을 미치는 중요한 요소들을 정확히 식별합니다. 이 방법은 Binary Masking을 통해 중요한 요소를 식별하고, Adaptive Steering을 통해 입력 의미에 따라 동적으로 모델 활성화를 조정하는 과정을 포함합니다.

- **Performance Highlights**: SADI는 LLaMA2-7b-chat, BLOOMZ-7b, Mistral-7b, Falcon-7b-instruct 등 다양한 모델 백본에서 11개의 주요 벤치마크 과제를 대상으로 실험한 결과, 기존 방법보다 성능이 크게 향상되었으며, 정확도 향상은 최대 +14.69에 달했습니다.



### Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs (https://arxiv.org/abs/2410.12298)
- **What's New**: Pyramid-Driven Alignment (PDA)라는 새로운 프레임워크를 제안하여 LLM(대형 언어 모델)과 KG(지식 그래프)의 통합을 최적화하고, 이를 통해 더 정확한 질문-답변 작업을 수행할 수 있도록 한다.

- **Technical Details**: PDA는 Pyramid Principle 분석을 사용하여 계층적 피라미드 구조를 구축하며, 이것이 입력 질문을 반영하도록 설계된다. 또한, 재귀적 메커니즘을 통해 KG의 추론 능력을 활용하여 질문-답변 작업을 위한 더 정확한 지식 검색을 가능하게 한다.

- **Performance Highlights**: PDA는 2WikiMultihopQA, Mintaka, WebQuestionsSP와 같은 세 가지 데이터셋에서 실험을 진행했으며, 각 데이터셋에서 SOTA(최첨단 성능) 결과를 달성하여 최대 26.70% 및 26.78%의 성능 향상을 이뤄냈다.



### How much do contextualized representations encode long-range context? (https://arxiv.org/abs/2410.12292)
Comments:
          17 pages, 9 figures

- **What's New**: 이 논문에서는 신경 오토회귀 언어 모델에서의 긴 범위 문맥(context)을 분석하며, 특히 수천 개 토큰이 포함된 문맥을 중점적으로 다룹니다. 새로운 방법론으로 \'비대칭 보정 코사인 유사도(Anisotropy-Calibrated Cosine Similarity, ACCS)를 사용하여 문맥화의 정도를 측정합니다.

- **Technical Details**: 연구에서는 문맥-혼합(context-mixing) 과정을 통해 긴 범위 문맥이 어떻게 표현되는지를 분석합니다. 이를 위해 다양한 아키텍처와 훈련 설정을 가진 모델을 대상으로 실험을 실시했으며, ACCS라는 메트릭을 통해 숨겨진 표현이 얼마나 문맥화되어 있는지를 정량화합니다. 또한, 회귀 모델과 하이브리드 모델의 차이점도 강조됩니다.

- **Performance Highlights**: 결과에 따르면, 고복잡성 시퀀스에 대한 인식 능력이 아키텍처에 따라 차이가 있으며, 하이브리드 모델이 긴 문맥의 구조를 더 효과적으로 인코딩함을 보여줍니다. 또한, 훈련 구성과 모델 크기 역시 긴 범위 문맥 인코딩에 큰 영향을 미치며, 이러한 결과는 기존 언어 모델의 발전 방향에 대한 힌트를 제공합니다.



### Kallini et al. (2024) do not compare impossible languages with constituency-based ones (https://arxiv.org/abs/2410.12271)
- **What's New**: 이 논문은 언어 모델이 인간 언어의 경계를 이해하는 데 어떻게 사용될 수 있는지를 탐구하며, GPT-2가 다양한 인공 언어(synthetic languages)를 학습할 때의 비대칭성(asymmetry)을 분석합니다.

- **Technical Details**: Kallini et al. (2024)의 연구에 따르면, LLMs(large language models)는 인간 언어를 학습하는 데 성공할 뿐만 아니라 불가능한 언어 언어(impossible languages)를 학습하는 데 어려움을 겪는지 테스트하였습니다. 이 비대칭성은 LLM의 귀납적 편향(inductive biases)이 인간 언어에 대한 가능성과 일치한다는 지지를 제공합니다.

- **Performance Highlights**: 논문에서 제시된 주요 비판은 Kallini et al.의 비교가 잘못된 혼합(confound)을 포함하고 있으며, 더욱 적절한 비교를 위해 다양한 constituency-based 규칙을 탐색할 것을 제안합니다.



### An Automatic and Cost-Efficient Peer-Review Framework for Language Generation Evaluation (https://arxiv.org/abs/2410.12265)
- **What's New**: 대형 언어 모델(LLM)의 평가 효율성을 높이기 위한 새로운 연구인 Auto-PRE 시스템이 소개되었습니다. 이 시스템은 이전의 수동 평가 방식에서 벗어나 자동으로 평가자 LLM을 선택하는 독창적인 접근 방식을 사용합니다.

- **Technical Details**: Auto-PRE는 평가의 일관성(consistency), 자기 신뢰성(self-confidence), 적합성(pertinence) 등 평가자의 특성을 기반으로 하여 LLM의 평가를 수행하는 자동화된 프레임워크입니다. 이 연구에서는 요약 생성(summary generation), 비사실 질문 대답(non-factoid question-answering), 대화 생성(dialogue generation) 등 세 가지 작업에 대한 실험을 진행했습니다.

- **Performance Highlights**: Auto-PRE 시스템은 낮은 비용으로 최첨단 성과(state-of-the-art performance)를 달성했으며, 프롬프트 전략(prompt strategies) 및 평가 형식(evaluation formats)이 평가 성과에 미치는 영향을 강조했습니다. 이는 미래의 방법 최적화(method optimization)에 대한 지침을 제공합니다.



### CoFE-RAG: A Comprehensive Full-chain Evaluation Framework for Retrieval-Augmented Generation with Enhanced Data Diversity (https://arxiv.org/abs/2410.12248)
- **What's New**: 본 논문에서는 Retrieval-Augmented Generation (RAG) 시스템의 평가를 개선하기 위한 Comprehensive Full-chain Evaluation (CoFE-RAG) 프레임워크를 제안합니다. 이 프레임워크는 RAG 파이프라인의 모든 단계에서 철저한 평가를 수행할 수 있도록 도와줍니다.

- **Technical Details**: CoFE-RAG 프레임워크는 chunking, retrieval, reranking, generation을 포함한 전반적인 RAG 파이프라인의 평가를 지원합니다. 평가를 효과적으로 수행하기 위해 coarse-grained 및 fine-grained 키워드를 도입하여, golden chunks의 주석에 의존하지 않고 수집된 문맥을 평가합니다. 또한, 다양한 데이터 시나리오를 다루는 벤치마크 데이터셋을 발표하였습니다.

- **Performance Highlights**: 실험을 통해 각 단계에서 RAG 시스템의 효과를 평가하여, 다양한 데이터 시나리오를 처리하는 RAG 시스템의 능력과 한계를 더 미세하게 이해할 수 있는 통찰력을 제공합니다.



### EPS-MoE: Expert Pipeline Scheduler for Cost-Efficient MoE Inferenc (https://arxiv.org/abs/2410.12247)
Comments:
          13 pages, 14 figures

- **What's New**: 이번 논문에서는 새로운 expert pipeline scheduler인 EPS-MoE를 제안합니다. 이 방법은 기존의 LLM inference parallelism 전략을 넘어서는 혁신적인 방식을 제공합니다.

- **Technical Details**: EPS-MoE는 MoE 아키텍처의 FFN(FeedForward Network) 모듈의 계산을 최적화하는 데 중점을 두며, GroupGemm과 DenseGemm의 최적 핵심 구현을 동적으로 선택하여 다른 작업 부하(load)에 대해 적응적으로 \\textit{all2all} 통신과 겹치게 함으로써 처리량(throughput)을 크게 증가시킵니다.

- **Performance Highlights**: 실험 결과, 기존의 병렬 추론 방법에 비해 평균 21% 향상된 prefill throughput을 보였습니다. 특히, DeepSeekV2 모델에서 EPS-MoE를 적용하여 초당 100K tokens의 prefill throughput에서 at least 120K tokens per second로 가속화했습니다.



### On A Scale From 1 to 5: Quantifying Hallucination in Faithfulness Evaluation (https://arxiv.org/abs/2410.12222)
Comments:
          14 pages, 13 figures

- **What's New**: 이번 논문에서는 자동화된 사실성 평가를 통해 자연어 생성(NLG)의 신뢰성을 높이기 위한 방법을 연구하였습니다. 특히, 신뢰도를 평가하기 위해 대형 언어 모델(LLM)을 활용한 점수 매기기 방법을 제안하였습니다.

- **Technical Details**: 제안된 방법은 LLM과 자연어 추론(NLI) 모델을 이용하여 참조(referece)와 가설(hypothesis) 쌍의 신뢰성 점수를 도출합니다. 또한, 다양한 유형의 가설을 비교하여 신뢰도 점수의 변동성을 분석하였고, 합성된 비신뢰한 데이터를 생성하는 방법도 개발하였습니다.

- **Performance Highlights**: 연구 결과, GPT-4 모델은 소스와 생성이 사실적으로 일치하는지를 정확하게 판단하고 설명할 수 있음을 보여주었습니다. 비신뢰성 데이터로 NLI 모델을 조정할 경우 성능이 향상되었고, 이러한 시스템의 배포 시 레이턴시(latency)와 비용에 대한 통찰도 제공하였습니다.



### Accurate and Data-Efficient Toxicity Prediction when Annotators Disagr (https://arxiv.org/abs/2410.12217)
- **What's New**: 본 논문은 전통적인 라벨 집계 방법의 한계를 극복하고 개별 주석자(annotator)가 주는 라벨을 예측하는 새로운 접근법을 소개합니다. 특히, 개별 주석자에 대한 정보를 통합하여 텍스트의 독성(toxicity)을 평가하는 세 가지 방법, 즉 Neural Collaborative Filtering(NCF), In-Context Learning(ICL), 및 Intermediate Embedding 기반 아키텍처를 제안합니다.

- **Technical Details**: 우선 NCF(Nural Collaborative Filtering) 접근방식과 ICL(In-Context Learning) 접근방식은 주석자별 역사(history), 인구통계학적(demographic) 정보 및 설문조사(survey) 정보를 통합하여 예측 정확도를 향상시킵니다. 특히, embedding 기반 아키텍처는 다른 방식보다 월등한 성능을 보였습니다. 또한, 설문조사 정보를 통해 예측된 인구통계학적 데이터를 사용하는 것이 실제 데이터와 비슷한 성능을 내는 것으로 나타났습니다.

- **Performance Highlights**: 연구 결과에 따르면, 각기 다른 주석자 정보 타입의 상대적 유용성을 고려해야 하며, 주관적 자연어 처리(NLP) 작업에서 주석자 모델링을 위한 새로운 접근법을 제공합니다. embedding 기반 아키텍처는 예측 정확도를 크게 높여 주목받았습니다.



### Negative-Prompt-driven Alignment for Generative Language Mod (https://arxiv.org/abs/2410.12194)
- **What's New**: 대형 언어 모델들이 눈에 띄는 능력을 보이고 있지만, 그 출력을 인간의 가치와 선호에 맞추는 것은 여전히 중요한 도전 과제로 남아 있습니다. 기존의 정렬 방법들은 주로 긍정적인 예제에 초점을 맞추고 부정적인 응답의 중요성을 간과하고 있습니다.

- **Technical Details**: NEAT(NEgative-prompt-driven AlignmenT)를 제안합니다. 이 방법은 최적화 과정에서 긍정적인 예제와 함께 부정적인 프롬프트를 사용해 바람직하지 않은 응답을 생성합니다. NEAT는 유해한 출력을 생성하는 모델에 대해 명시적으로 페널티를 부과하여, 바람직한 행동으로 유도하며 동시에 바람직하지 않거나 편향된 응답 생성을 피하도록 합니다. 이를 통해 선호도에 대한 온라인 정렬을 수행하며, 확장된 선호도 데이터셋을 기반으로 랭킹 손실(ranking loss)을 통합합니다.

- **Performance Highlights**: 광범위한 실험을 통해 NEAT의 효과성을 검증하였으며, 언어 모델이 인간의 가치와 선호에 더 잘 정렬되도록 유의미하게 향상됨을 나타냈습니다.



### Exploring Large Language Models for Hate Speech Detection in Rioplatense Spanish (https://arxiv.org/abs/2410.12174)
- **What's New**: 본 논문에서는 Rioplatense 스페인어에서의 혐오 발언 감지(Hate Speech Detection)에서 대형 언어 모델(Large Language Models)의 성능을 분석합니다. 특히, ChatGPT 3.5, Mixtral, Aya와 최신의 BERT 분류기와의 비교 실험을 통해 대형 언어 모델의 장단점을 밝혔습니다.

- **Technical Details**: 논문에서는 체인 오브 띵크(Chain-of-Thought) 추론을 활용하여 실험을 수행하였습니다. 실험은 대형 언어 모델이 정교하게 조정된 BERT 분류기에 비해 낮은 정밀도를 보이긴 했지만, 특히 동성애 혐오 및 성별 정체성에 대한 혐오 발언과 같은 미세한 사례에 대해서는 민감하다는 것을 보여줍니다.

- **Performance Highlights**: 대형 언어 모델은 특정 비속어(slang) 또는 속어(slum)를 검출하는 데 어려움을 겪는 경우가 있지만, 이전에 언급한 미세한 경우에서는 여전히 좋은 성능을 발휘합니다. 또한, 우리가 개발한 코드와 모델은 향후 연구를 위해 공개되었습니다.



### Table-LLM-Specialist: Language Model Specialists for Tables using Iterative Generator-Validator Fine-tuning (https://arxiv.org/abs/2410.12164)
- **What's New**: 이번 연구에서 우리는 Table-LLM-Specialist, 즉 Table-Specialist를 제안하며, 이는 테이블 작업을 위한 새로운 자기 학습(fine-tuning) 패러다임입니다. 각 테이블 작업에는 생성(generative)적 특성과 분류(classification)적 특성을 가지는 두 가지 대칭적인 버전이 존재한다는 점을 통찰합니다. 이를 통해 'Generator-Validator' 패러다임을 제안하며, 수작업으로 라벨링된 데이터 없이도 강력한 모델을 세분화할 수 있음을 보여줍니다.

- **Technical Details**: Table-Specialist 모델은 특정 테이블 작업에 특화되어 있으며, 이를 지원하기 위해 언어 모델에서 반복적으로 데이터를 생성(generate)하고 검증(validate)하는 방식으로 학습됩니다. 이 방식은 다양한 실제 테이블에서 체계적으로 생성된 훈련 데이터를 활용하여 이루어집니다.

- **Performance Highlights**: Table-Specialist는 (1) 다양한 테이블 작업에서 강력한 성능을 발휘하며, 예를 들어 GPT-3.5에서 세밀조정(fine-tuning)한 경우 vanilla GPT-3.5보다 성능이 뛰어나고 경우에 따라 GPT-4 수준 품질에 도달합니다, (2) 더 낮은 배포 비용을 제공하며, 적은 지연(latency)과 추론(inference) 비용으로 비슷한 품질을 유지하면서 더 작은 모델을 배포할 수 있습니다, (3) 여러 기준에 대해 평가할 때 더 나은 일반화(generalizability)를 보여줍니다.



### Exploiting LLMs' Reasoning Capability to Infer Implicit Concepts in Legal Information Retrieva (https://arxiv.org/abs/2410.12154)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 이번 연구는 법적 상황과 관련된 법적 용어 및 사실을 식별하기 위해 대형 언어 모델(LLMs)의 논리적 추론 능력을 활용하는 새로운 정보 검색 시스템을 제안합니다. 이 시스템은 전통적인 검색 방법의 한계를 극복하며, 법적 문제를 인식하고 이를 사용하여 쿼리 확장을 수행합니다.

- **Technical Details**: 제안된 방법론은 두 가지 쿼리 확장 기법을 통해 사용되며, 이는 대형 언어 모델의 제로-샷 프롬프트 기법을 통해 법적 개념과 관련된 용어를 생성하고, 이러한 용어를 쿼리에 통합하여 검색 성능을 향상시킵니다. 또한, lexical based ranking model(BM25)과 semantic based ranking model을 통합하여 최적의 검색 결과를 생성합니다.

- **Performance Highlights**: COLIEE 2022와 2023 대회에서 제안된 앙상블 검색 시스템은 모든 참여 팀 중에서 가장 우수한 성과를 달성하였습니다. LLM에서 얻은 추가 정보가 검색 정확도를 크게 향상시키는 데 기여했습니다.



### Layer-of-Thoughts Prompting (LoT): Leveraging LLM-Based Retrieval with Constraint Hierarchies (https://arxiv.org/abs/2410.12153)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 이번 논문에서는 Layer-of-Thoughts Prompting (LoT)라는 새로운 접근 방식을 제시합니다. 이는 제약 계층을 활용하여 주어진 쿼리에 대한 후보 응답을 필터링하고 세분화하는 기법입니다.

- **Technical Details**: LoT 방법은 제약 사항을 통합하여 구조화된 검색 프로세스를 가능하게 하며, 이는 정보 검색 정보를 더 잘 설명하고 자동화할 수 있는 방법입니다. 기존의 방법들은 다양한 프롬프트 기법을 다루었지만, 다중 턴 상호작용에서 프롬프트의 세부 사항에 대한 탐구가 부족했습니다. 이번 연구는 프롬프트간의 계층적 관계에 초점을 맞추어 이 빈틈을 메웁니다. 대형 언어 모델(LLMs)을 활용하여, LoT는 정보 검색 작업의 정확성과 이해도를 크게 향상시킵니다.

- **Performance Highlights**: LoT 기법은 효율적이고 해석 가능한 검색 알고리즘 개발에 결정적인 역할을 하는 사고 계층의 효능을 입증하였습니다. 이 방법은 설명 가능성과 자동화를 강화하여 정보 검색 정확성을 크게 개선했습니다.



### Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning (https://arxiv.org/abs/2410.12130)
- **What's New**: 이 논문은 대형 언어 모델(LLMs)의 환각(hallucination) 문제를 해결하기 위한 새로운 접근법인 Iterative Model-level Contrastive Learning (Iter-AHMCL)을 소개합니다. 이 방법은 환각을 줄이면서도 LLM의 원래 능력을 유지하도록 설계되었습니다.

- **Technical Details**: Iter-AHMCL 방법은 미리 훈련된 LLM의 표현층을 수정하여 환각이 있는 데이터와 없는 데이터를 기반으로 학습된 대비 모델을 사용합니다. 긍정적(positive) 및 부정적(negative) 모델을 통해 환각을 감소시키는 좀 더 직관적인 경로를 생성하고, 반복적인 대조 학습(iterative contrastive learning)을 통해 성능을 향상시킵니다.

- **Performance Highlights**: 본 논문은 LLaMA2, Alpaca, LLaMA3, Qwen 등 네 개의 미리 훈련된 LLM 모델에서 특별히 설계된 데이터셋으로 파인튜닝(finetuning) 실험을 수행하였으며, TruthfulQA 벤치마크에서 평균 10.1 포인트의 성능 향상을 달성했습니다. Iter-AHMCL은 환각을 줄이면서 LLM의 일반적인 능력을 유지하는 효과적인 방법임을 보여줍니다.



### OMCAT: Omni Context Aware Transformer (https://arxiv.org/abs/2410.12109)
Comments:
          Demo page: this https URL

- **What's New**: 대규모 언어 모델(LLMs)의 진전을 바탕으로 새로운 데이터셋(OCTAV)과 모델(OMCAT)을 발표하였습니다. 이 모델은 시청각 기반 질문 응답(task)에서 우수한 성능을 발휘합니다.

- **Technical Details**: OCTAV(Omni Context and Temporal Audio Video)는 소리 이벤트를 통해 비디오에서 발생하는 사건의 전환을 캡처하는 혁신적인 데이터셋입니다. OMCAT(Omni Context Aware Transformer)는 RoTE(Rotary Time Embeddings)를 활용하여 시각 및 청각 데이터를 위한 통합 모델을 제공합니다.

- **Performance Highlights**: OMCAT는 AVQA(Audio-Visual Question Answering) 작업 및 OCTAV 벤치마크에서 최첨단 성능을 보여주며, 시간적 추론과 시청각 정렬에서 의미 있는 개선을 기록했습니다.



### De-jargonizing Science for Journalists with GPT-4: A Pilot Study (https://arxiv.org/abs/2410.12069)
Comments:
          Accepted to Computation+Journalism Symposium 2024

- **What's New**: 이번 연구는 GPT-4 (대형 언어 모델, LLM)와 Retrieval-Augmented Generation (RAG)를 활용하여 과학 논문의 초록에서 전문 용어를 식별하고 정의하는 '인간-기계 협업 시스템'을 평가했습니다. 이 시스템은 독자의 자가 보고 지식을 바탕으로 전문 용어를 정확하게 식별하며, 개인화가 가능함을 보여줍니다.

- **Technical Details**: 제안된 시스템은 과학적인 초록에서 독자의 전문 지식을 바탕으로 복잡한 전문 용어를 식별하고, 각 용어에 대한 간단하고 접근 가능한 정의를 생성합니다. OpenAI의 GPT-4를 사용하여 전문 용어를 식별하고, RAG를 통해 생성된 정의에 대한 맥락을 제공합니다. 이 연구는 64개의 arXiv 사전 인쇄물 데이터를 통해 LLM 기반 시스템의 성능을 평가하였습니다.

- **Performance Highlights**: GPT-4는 독자의 전문 지식에 관계없이 전문 용어를 과다 예측하는 경향이 있으나, 실제로 독자가 식별한 전문 용어에 대한 상대적으로 높은 기억률(0.68의 중앙 기억률)을 보여주었습니다. 또한 초록만을 기반으로 한 정의 생성이 RAG 기반의 전체 본문 맥락보다 더 정확하고 높은 품질을 가진 정의를 생산함을 나타냅니다.



### LegalLens Shared Task 2024: Legal Violation Identification in Unstructured Tex (https://arxiv.org/abs/2410.12064)
- **What's New**: 이번 논문은 LegalLens Shared Task의 결과를 발표하며, 현실에서 법적 위반을 탐지하는 데 중점을 두고 이를 위한 두 가지 하위 작업인 LegalLens-NER과 LegalLens-NLI에 대해 다룹니다.

- **Technical Details**: LegalLens-NER은 비구조화된 텍스트에서 법적 위반 관련 엔티티를 식별하고, LegalLens-NLI는 이 위반을 특정 법적 맥락이나 관련 사례와 연결하는 작업입니다. 38개 팀이 참여했으며, 데이터셋은 노동, 개인정보 보호, 소비자 보호 분야를 포함한 내용으로 구성되었습니다.

- **Performance Highlights**: 최고 성과를 낸 팀은 NER에서 7.11%의 성능 향상을 달성했고, NLI에서도 5.7%의 향상을 보였습니다. 그러나 법적 텍스트의 복잡성으로 인해 여전히 발전 가능한 여지가 많이 남아 있습니다.



### Large-scale cloze evaluation reveals that token prediction tasks are neither lexically nor semantically aligned (https://arxiv.org/abs/2410.12057)
- **What's New**: 이번 연구에서는 여러 언어 모델의 다음 토큰 예측(next token prediction) 수준에서 생성 행동을 비교하여, cloze 작업에서 인간의 생성과 비교합니다. 연구 결과, 대규모 모델들이 일반적으로 인간의 응답을 더 잘 추정하지만, 확률 총합을 과소 평가하고, 희귀한 응답을 과대 평가하며, 최상위 응답을 과소 평가하는 경향이 있다는 것을 발견했습니다. 이 논문은 언어 모델의 생성이 클로즈 작업의 대체나 모델로 사용될 수 없음을 보여줍니다.

- **Technical Details**: 연구는 인간의 생성을 확률적 관점에서 잘 이해하고, LMs와 인간 간의 차이를 더 잘 알아내기 위해 single-word production을 검토합니다. cloze 작업은 문맥이 주어지고 그 안의 한 단어를 추론하는 작업으로, 인간의 응답 예측에서는 P(w|c)로 표기되는 단어의 발생 확률이 관찰된 모든 응답의 상대 빈도로 추정됩니다. 반면 언어 모델은 신경망을 통해 단어에 점수를 부여하고 softmax 함수를 통해 확률 분포를 생성합니다.

- **Performance Highlights**: Peelle et al. (2020)에서 수집한 3,085개의 영어 문장에 대해 인간 응답으로부터 얻은 cloze 확률과 여러 신경 언어 모델(GPT-2, RoBERTa, Pythia 모델 등)에서 추출한 확률을 비교했습니다. 모델들은 약 50,000의 서브워드(subword) 어휘 크기를 사용하며, 모델 크기, 훈련 시간, 데이터 중복 제거와 같은 여러 하이퍼파라미터의 영향을 탐구하는 Pythia 모델이 특히 흥미로운 결과를 제공합니다.



### A State-of-the-Art Morphosyntactic Parser and Lemmatizer for Ancient Greek (https://arxiv.org/abs/2410.12055)
- **What's New**: 이 논문은 고대 그리스어를 위한 최첨단 morphosyntactic parser(구문 분석기) 및 lemmatizer(어간 추출기)를 식별하고 비교하는 실험을 소개합니다. 다양한 최신 모델들이 Ancient Greek Dependency Treebank(고대 그리스어 종속 트리뱅크) 주석 체계에 따라 주석을 추가할 수 있도록 설계되었습니다.

- **Technical Details**: 이 연구는 Dithrax 모델을 기본 모델로 사용하였으며, Trankit과 GreBERTa, PhilBERTa, GreTA, PhilTa와 같은 최신 모델들을 추가로 조정하였습니다. Bayesian 분석 결과, Dithrax와 Trankit은 Morphology에 대한 주석을 거의 동일하게 수행하며, Trankit은 Syntax에 가장 적합하고 GreTa는 Lemmata에 우수함을 나타냅니다. 이 연구는 Token Embeddings가 높은 UAS(간접 성능 점수) 및 LAS(구조적 성능 점수)를 달성하기에는 불충분하다는 점 강조하며, 특히 구문 관계를 주의 깊게 포착하도록 설계된 모델링 전략이 필요합니다.

- **Performance Highlights**: 실험 결과, Dithrax와 Trankit의 Morphosyntactic 주석 성능은 비슷하며, Trankit은 Syntax에 대한 주석 정확도가 가장 높고, GreTa는 Lemmata에서 최고의 성능을 보였습니다. 최우수 성능 모델들이 온라인에서 재사용을 위해 제공됩니다.



### Skill-LLM: Repurposing General-Purpose LLMs for Skill Extraction (https://arxiv.org/abs/2410.12052)
- **What's New**: 이번 연구에서는 기술 및 LLM(대규모 언어 모델)의 전문화된 버전인 Skill-LLM을 미세 조정하여 직무 설명서에서 기술을 추출하는 정확도를 향상시키는 방법을 제안합니다.

- **Technical Details**: 본 연구에서는 NER(명명된 개체 인식) 기술을 활용하고, 기존 최첨단(SOTA) 방법들과의 성능을 비교하기 위해 다양한 벤치마크 데이터셋을 사용했습니다. LLM을 기반으로 한 학습된 모델은 복잡한 프롬프트 없이도 안정적이고 정확한 출력을 생성할 수 있습니다.

- **Performance Highlights**: 기존 SOTA 기법들에 비해 F1 점수가 개선되었으며, 경량 모델을 미세 조정함으로써 제한된 컴퓨팅 리소스에서도 우수한 성능을 발휘하였습니다.



### Sabi\'a-3 Technical Repor (https://arxiv.org/abs/2410.12049)
- **What's New**: Sabiá-3는 브라질 중심의 대규모 데이터셋으로 훈련된 새로운 언어 모델로, 포르투갈어 및 브라질 관련 과제에서 우수한 성능을 보여줍니다. Sabiá-2와 비교하여 특히 추론 요구 과제에서 크게 향상되었습니다.

- **Technical Details**: Sabiá-3는 브라질 문화와 역사에 맞춘 포르투갈어 문서 데이터셋으로 훈련되었습니다. 두 가지 주요 단계에서 개발 되었습니다: (1) 사전 훈련(Pre-training) 단계에서 고품질 데이터에 대한 자기지도 학습(Self-supervised learning) 전략으로 훈련, (2) 사후 훈련(Post-training) 단계에서 인간의 선호에 맞춰 조정되었습니다. TPU v5 가속기를 사용하여 효율적으로 훈련했습니다.

- **Performance Highlights**: Sabiá-3는 ENADE 2022 및 2023 시험에서 Sabiá-2에 비해 70% 오류 감소를 보였고, GPT-4o와 경쟁력 있는 성능을 발휘했습니다. 특히 CPNU 시험에서 주목할 만한 성과를 보여 다른 모델들보다 높은 정확도를 달성했습니다.



### Boosting Logical Fallacy Reasoning in LLMs via Logical Structure Tr (https://arxiv.org/abs/2410.12048)
Comments:
          Accepted to EMNLP 2024

- **What's New**: 이 연구는 논리적 오류(logical fallacy)를 탐지하고 분류하기 위한 새로운 접근법을 제안합니다. 구체적으로, 연구진은 연결어(connective words)를 통해 제안된 논리적 관계와 실제 논리적 관계 간의 불일치를 인식하는 데 초점을 맞추고, 이를 통해 기존의 접근법을 개선합니다.

- **Technical Details**: 연구진은 '논리 구조 트리(logical structure tree)'를 구성하여 연결어와 그에 해당하는 텍스트 인수를 계층적으로 표현합니다. 이 트리는 비지도 학습(unsupervised learning) 방식으로 구성되며, 연결어는 비단말 노드(non-terminal nodes), 텍스트 인수는 단말 노드(terminal nodes)로 배치됩니다. 논리 구조 트리는 LLMs(대형 언어 모델)에 두 가지 방법으로 통합됩니다: 1. 트리를 자연어 설명(natural language descriptions)으로 변환하여 LLMs에 입력, 2. 트리 임베딩(tree embedding)을 도출하여 소프트 프롬프트(soft prompt)로 삽입.

- **Performance Highlights**: 벤치마크 데이터를 기반으로 한 실험 결과, 이 연구는 논리적 오류 탐지에서 F1 점수를 최대 3.45%, 분류에서 최대 6.75% 향상시켰습니다. 이를 통해 제안된 접근법이 오류 탐지 및 분류 작업에서 상당한 성과를 거두었음을 입증했습니다.



### Concept-Reversed Winograd Schema Challenge: Evaluating and Improving Robust Reasoning in Large Language Models via Abstraction (https://arxiv.org/abs/2410.12040)
- **What's New**: 이 논문에서는 LLMs의 reasoning 성능을 평가하기 위한 새로운 데이터셋인 Concept-Reversed Winograd Schema Challenge (CR-WSC)를 제안합니다. 이 데이터셋은 기존의 Winograd Schema Challenge (WSC)에서 개념을 반전시켜 LLMs가 잘못된 대답과 더 연관된 답변을 이끌어내도록 구성되었습니다.

- **Technical Details**: CR-WSC 데이터셋은 LLM의 약점을 이용한 적대적인 질문들을 포함하고, Abstraction-of-Thought (AoT)라는 새로운 프롬프트 방법을 통해 LLMs의 robustness를 향상시키고자 합니다. AoT는 문제를 일반화하여 추상화한 후 reasoning을 수행하는 두 단계의 접근 방식을 채택합니다.

- **Performance Highlights**: 실험 결과, CR-WSC는 기존의 WSC에 비해 LLMs에게 상당히 더 어려운 과제로 나타났으며, AoT를 사용함으로써 LLMs의 reasoning 성능과 robustness가 현저하게 향상되었습니다.



### On Classification with Large Language Models in Cultural Analytics (https://arxiv.org/abs/2410.12029)
- **What's New**: 본 논문에서는 문화 분석(cultural analytics)에서의 분류(classification) 사용 방식과 대형 언어 모델(LLMs)의 적합성을 조사합니다. 공공 데이터셋을 기반으로 한 10개의 작업을 정의하고 LLMs와 전통적인 감독 학습(supervised methods) 간의 성능을 비교합니다. LLMs는 기존의 작업에서는 경쟁력을 보이지만 새로운 작업에는 부족함을 보입니다.

- **Technical Details**: LLMs를 통한 분류 수행 방식을 네 가지 차원으로 탐구합니다: 1) 최근 문화 분석에서의 분류 사용 조사의 결과, 2) 실험 가능한 10개의 작업 정의, 3) 다양한 분류 모델(예: bag-of-words, masked language models, large language models)의 성능 벤치마크 수행, 4) LLMs를 통한 카테고리 이해 및 탐색적 데이터 분석(exploratory data analysis) 수행.

- **Performance Highlights**: 기존의 영어 기반 작업에서는 LLMs가 전통적 감독 모델과 경쟁할 수 있으나, 새로운 작업에서는 만족스럽지 못한 성능을 보였습니다. 이 연구는 LLMs가 탐색적 데이터 분석(in exploratory data analysis)을 지원할 수 있는 방법을 제시합니다.



### MoE-Pruner: Pruning Mixture-of-Experts Large Language Model using the Hints from Its Router (https://arxiv.org/abs/2410.12013)
- **What's New**: 새로운 논문에서는 Mixture-of-Experts (MoE) 아키텍처의 메모리 소비 및 전문가 중복성을 줄이기 위해 MoE-Pruner라는 방법을 제안합니다. 이 방법은 각 출력 뉴런에서 입력 활성화와 라우터 가중치를 곱한 최소 크기의 가중치를 가지는 방법으로 일회를 통해 손실을 최소화합니다.

- **Technical Details**: MoE-Pruner는 활발하지 않은 전문가의 가중치를 제거하여 모델을 가지치기하는 기법입니다. 이 프로세스는 재학습이나 가중치 업데이트 없이 한 번의 조정 데이터만으로 수행됩니다. Mixtral-8x7B 및 Mixtral-8x22B 모델에 대해 여러 언어 벤치마크에서 그 효용성이 입증되었습니다.

- **Performance Highlights**: Mixtral-8x7B 모델은 50%의 희소성을 가지면서도 원래 모델의 99% 성능을 유지하며, 전문가별 지식 증류를 통해 성능 회복이 가능합니다. 기존의 최첨단 LLM 가지치기 방법들에 비해 우수한 결과를 보였습니다.



### Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models (https://arxiv.org/abs/2410.12011)
Comments:
          9 pages, Accepted to EMNLP 2025 Main

- **What's New**: PIXEL 모델은 서브워드 기반 언어 모델의 대안으로 등장했으며, 다양한 스크립트를 표현할 수 있는 능력을 보여줍니다. 그러나 이 모델은 대부분의 언어 과제에서 BERT와 같은 단일언어 서브워드 모델에 비해 성능이 떨어진다는 점이 주목받고 있습니다.

- **Technical Details**: PIXEL은 비전 트랜스포머(ViT) 기반의 모델로, 시각적 패치를 입력으로 받고 텍스트가 렌더링된 형태로 처리됩니다. 연구에서는 PIXEL의 다양한 레이어에서 언어적 정보와 시각적 정보를 각각 탐구하며, 출력 결과를 BERT 및 ViT-mae와 비교합니다. 또한, 입력 레벨에서 특정 서체 제약을 도입했을 때 언어적 학습이 어떻게 향상되는지를 조사하였습니다.

- **Performance Highlights**: PIXEL은 하위 레이어에서 표면적인 언어적 정보를 학습하며, 상위 레이어에서는 구문론(syntax) 및 의미론(semantics) 추상화가 진행됩니다. 그러나 ViT에 비해 이미지 과제에서의 성능은 낮아, 시각적 지식 습득이 언어적 지식 습득 과정에서 희석되는 경향이 있음을 발견하였습니다.



### Toolken+: Improving LLM Tool Usage with Reranking and a Reject Option (https://arxiv.org/abs/2410.12004)
Comments:
          EMNLP 2024 Findings

- **What's New**: 최근 제안된 ToolkenGPT 도구 학습 패러다임은 유망한 성능을 보여주지만, 도구 문서 활용의 부족과 도구 사용 여부 판단에서의 실수라는 두 가지 주요 문제에 직면해 있습니다. 이를 해결하기 위해 Toolken+를 도입하였으며, 이는 Top k 도구의 재순위 및 'Reject' 옵션을 통해 문제를 완화합니다.

- **Technical Details**: Toolken+는 ToolkenGPT의 기존 기능을 확장하여, 도구 문서를 재순위하는 기능과 사용 여부를 결정하는 'Reject' 옵션을 추가하여 처음 두 단계를 개선합니다. 여기에서 'Reject'는 모델이 도구 호출 없이 텍스트 생성을 진행할 수 있도록 하는 기능입니다. 또한, Toolken 훈련 알고리즘에 대한 이론적 정당성을 제공합니다.

- **Performance Highlights**: GSM8K, MetaTool 및 VirtualHome 데이터셋을 통해 우리의 접근 방식이 중요한 성능 향상을 보여주었음을 입증하였습니다. 이 연구는 ToolkenGPT의 잘못된 도구 호출을 최소화하고, 더 신뢰할 수 있는 LLM 에이전트를 개발할 수 있도록 합니다.



### Impacts of Continued Legal Pre-Training and IFT on LLMs' Latent Representations of Human-Defined Legal Concepts (https://arxiv.org/abs/2410.12001)
- **What's New**: 이 논문은 대형 언어 모델(LLMs)의 법률 교육(Corpus)에서의 지속적인 사전 훈련(Pre-training)과 지시적 미세 조정(Instruction Fine-tuning, IFT)이 인간이 정의한 법률 개념을 어떻게 활용하는지를 분석합니다.

- **Technical Details**: 세 가지 모델인 Mistral 7B, SaulLM-7B-Base (법률 데이터셋에서의 지속적인 사전 훈련을 포함한 Mistral 7B), 및 SaulLM-7B-Instruct (추가적인 IFT 포함)를 비교했습니다. 최근 AI & Law 문헌에서의 7개 텍스트 시퀀스에 대해 모델의 주의(attention) 비율을 비교하고, 법률 훈련이 인간의 법적 지식 구조에 따라 새로운 주의 패턴을 생성했는지를 시각화했습니다.

- **Performance Highlights**: 법률 교육의 영향은 다양한 인간 정의 법률 개념에 따라 고르지 않게 분포되었으며, 법률 훈련 중에 학습된 법적 지식의 맥락적 표현이 인간 정의 법률 개념의 구조와 일치하지 않는다는 결과를 도출했습니다.



### Holistic Reasoning with Long-Context LMs: A Benchmark for Database Operations on Massive Textual Data (https://arxiv.org/abs/2410.11996)
- **What's New**: HoloBench라는 새로운 평가 프레임워크를 소개하여, Long-Context Language Models (LCLMs)의 다각적 추론(holistic reasoning) 능력을 체계적으로 평가합니다. 이 프레임워크는 데이터베이스 기반의 추론 작업을 텍스트 기반 맥락으로 가져와 LCLMs의 성능을 비교할 수 있도록 합니다.

- **Technical Details**: HoloBench는 LCLMs의 다각적 추론을 평가하기 위해 세 가지 주요 요인: (1) 맥락의 길이 및 정보량, (2) 관련 정보의 배치 위치, (3) 질문의 유형 및 난이도를 조절하여 모델 성능을 평가합니다. 기존의 벤치마크에서는 주로 단일 또는 이차원적 요인만을 고려하였으나, HoloBench는 이들 세 가지 요인을 동시에 평가합니다.

- **Performance Highlights**: 실험 결과, LCLMs의 성능은 맥락의 길이보다 맥락 내 정보량에 더 크게 영향을 받으며, 질문의 복잡성이 성능에 더 큰 영향을 미친다는 것을 발견했습니다. 또한, 최대 또는 최소 값을 찾는 질문은 LCLMs에게 상대적으로 쉬운 반면, 여러 정보 조합이 필요한 작업에서는 정확도가 현저히 감소했습니다.



### DISP-LLM: Dimension-Independent Structural Pruning for Large Language Models (https://arxiv.org/abs/2410.11988)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 논문에서는 기존의 구조적 가지치기(Structural Pruning) 방법의 제약을 완화하고, 임베딩 차원에서의 구조적 의존성을 제거하는 새로운 차원 독립 구조적 가지치기 방법(DISP-LLM)을 제안하였습니다. 이 방법은 각 블록이 다양한 피처 맵(subset of feature maps)을 사용할 수 있게 하며, 구조적 의존성을 제거함으로써 유연성을 크게 향상시켰습니다.

- **Technical Details**: DISP-LLM은 서로 다른 레이어가 임베딩 차원에서 서로 다른 피쳐의 하위 집합(subset)을 선택할 수 있도록 하며, 추가적인 매개변수를 도입하지 않고도 레이어의 폭(width)을 학습할 수 있게 합니다. 이 접근 방식은 그라디언트 기반 최적화 방법을 사용하여 레이어 폭을 조정하며, 레이어별로 전역적으로 제어됩니다. 또한, 각 레이어의 출력 및 입력 차원에서 다양한 폭을 가질 수 있습니다.

- **Performance Highlights**: 이번 연구 결과는 DISP-LLM 방법이 OPT, LLaMA, LLaMA-2, Phi-1.5, Phi-2와 같은 다양한 LLM 모델에 대해 최신 기술들보다 뛰어난 성능을 보여주며, SEMI-STRUCTURAL 가지치기와 유사한 정확도를 달성할 수 있음을 증명합니다. 이 방법은 낮은 계산 비용을 유지하면서도 효율적인 가지치기를 가능하게 하였습니다.



### The Fair Language Model Paradox (https://arxiv.org/abs/2410.11985)
- **What's New**: 이 논문은 Large Language Models (LLMs)의 토큰 수준에서의 훈련 동역학을 조명하며, 가중치 감쇠(weight decay)가 저주파(low-frequency) 토큰의 성능에 미치는 부정적인 영향을 발견하였습니다. 이러한 연구는 기존의 성능 지표에 의해 간과되었던 중요한 통찰을 제공합니다.

- **Technical Details**: 이 연구는 IMDB 데이터셋을 사용하여 270M과 3B 파라미터를 가진 Apple OpenELM 모델과 Qwen2 모델을 훈련하면서 다양한 가중치 감쇠 수준을 적용하였습니다. 결과적으로, 가중치 감쇠가 증가할수록 저주파 토큰의 성능이 유의미하게 감소하는 것을 확인했습니다. 또한, 고주파 토큰이 저주파 토큰보다 학습 속도에서 일관되게 우세하다는 발견이 있었습니다.

- **Performance Highlights**: 가중치 감쇠를 통한 일반화 촉진을 목표로 하는 기존의 방법이 저주파 토큰을 무시하는 결과를 초래하며, 이는 데이터의 대다수를 차지하는 저주파 토큰에 대한 성능 저하로 이어진다는 점이 명확해졌습니다. 이로 인해 더 일반적인 토큰에 유리한 편향이 발생하며, 새로운 정규화 기법의 필요성이 부각되었습니다.



### JudgeBench: A Benchmark for Evaluating LLM-based Judges (https://arxiv.org/abs/2410.12784)
Comments:
          preprint

- **What's New**: 본 논문에서는 LLM 기반의 평가자(judges)의 신뢰성을 점검하기 위한 새로운 평가 프레임워크를 제안합니다. 이를 통해 기존의 인간 평가자와 비교할 수 있는 JudgeBench라는 벤치마크를 소개합니다.

- **Technical Details**: JudgeBench는 지식(knowledge), 추론(reasoning), 수학(math), 코딩(coding) 등의 난이도 있는 응답 쌍을 평가하는 새로운 벤치마크입니다. 기존의 데이터셋을 활용하여 난이도 높은 응답 쌍으로 변환하는 파이프라인을 활용합니다.

- **Performance Highlights**: JudgeBench는 이전 벤치마크에 비해 훨씬 더 큰 도전을 제시하며, 많은 강력한 모델들이 무작위 추측(random guessing)보다 조금 더 나은 성과를 낼 뿐임을 보여주었습니다. 이는 LLM 기반 평가자의 평가 과정에서의 신뢰성을 높이는 데 기여할 것으로 기대됩니다.



### In-Context Learning Enables Robot Action Prediction in LLMs (https://arxiv.org/abs/2410.12782)
- **What's New**: 이 논문에서는 RoboPrompt라는 새로운 프레임워크를 소개하여, 트레이닝 없이 오프-the-shelf LLM을 통해 로봇 행동을 직접 예측할 수 있도록 한다. RoboPrompt는 ICL(인컨텍스트 학습)의 기능을 활용하여 필요에 따라 로봇의 행동을 예측하는 방법을 제안한다.

- **Technical Details**: RoboPrompt의 접근 방식은 주어진 에피소드에서 주요 키프레임을 식별하는 것으로 시작하며, 이러한 키프레임에서 로봇의 행동과 초기 객체 자세를 추출한다. 이들은 텍스트 서술로 변환되고, 구조화된 템플릿으로 ICL 예제를 형성하여 LLM이 테스트 시간에 로봇 행동을 직접 예측할 수 있게 한다.

- **Performance Highlights**: RoboPrompt는 RL-Bench 시뮬레이션과 실제 환경에서 16가지의 작업을 수행한 결과, 제로샷 및 ICL 기준 대비 우수한 성능을 보여주었다. 다양한 LLM에 적용 가능하며, ICL 예제 수에 따라 확장성이 뛰어나고, 감독 방법들과도 경쟁력 있는 성과를 낸다.



### Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts (https://arxiv.org/abs/2410.12777)
- **What's New**: 본 논문에서는 확산 모델(Diffusion Models, DMs)에서 유해하거나 저작권이 있는 개념을 효과적으로 '망각'(unlearn)하고자 하는 '메타-망각'(meta-unlearning) 프레임워크를 제안합니다. 이는 모델이 학습된 데이터를 잊고 나서도, 악의적인 파인튜닝(finetuning)을 통해 망각된 개념을 다시 학습하지 않도록 돕습니다.

- **Technical Details**: 메타-망각 프레임워크는 두 가지 주요 요소를 포함합니다: (1) 특정 데이터를 효과적으로 잊도록 하는 표준 망각 목표(unlearning objective)와 (2) 악의적인 파인튜닝 시 망각된 개념의 재학습을 방지하기 위한 메타 목표(meta objective)입니다. 제안된 접근 방법은 기존의 망각 방법과 호환되며, 간단한 메타 목표만 추가하면 됩니다. 실험은 Stable Diffusion 모델(SD-v1-4 및 SDXL)에 대한 다양한 메타-망각 개념의 효과를 검증합니다.

- **Performance Highlights**: 제안된 메타-망각 접근 방식은 학습된 개념들을 안정적으로 망각시키며, 필연적으로 여전히 남아 있는 유관 개념들이 해체(self-destruct)되어 망각된 개념의 재학습을 방지합니다. 다양한 실험과 근거 자료를 통해 메타-망각 프레임워크의 효과가 입증되었습니다.



### CREAM: Consistency Regularized Self-Rewarding Language Models (https://arxiv.org/abs/2410.12735)
- **What's New**: 본 논문은 self-rewarding language models (SRLMs)의 rewarding bias 문제를 해결하기 위한 새로운 접근 방식을 제안합니다. 이 과정에서 Consistency Regularized sElf-rewarding lAnguage Model(CREAM)을 도입하여 self-rewarding 훈련의 신뢰성 있는 데이터 학습을 돕고 있습니다.

- **Technical Details**: CREAM은 반복적인 선호 훈련에서의 보상 일관성을 활용하여 모델이 불확실한 선호 데이터를 학습하지 않도록 정규화합니다. 이를 위해 과거 반복의 보상 모델을 사용해 선호를 순위화하고, 현재 모델이 생성한 순위와 비교하여 일관성을 측정합니다. 이러한 방식은 보상 레이블링의 과잉 신뢰를 줄이고, 훈련의 효율성을 높입니다.

- **Performance Highlights**: CREAM은 여러 자연어 벤치마크에서 실험을 통해 보상 일관성과 정렬 성능을 개선한 것으로 나타났습니다. 이로 인해 LLM의 품질이 향상되어 더욱 효과적으로 인간 가치 및 선호에 맞춰 정렬될 수 있음을 보여줍니다.



### Sarcasm Detection in a Less-Resourced Languag (https://arxiv.org/abs/2410.12704)
Comments:
          4 pages, published in the Slovenian Conference on Artificial Intelligence

- **What's New**: 이 논문은 슬로베니아어와 같은 리소스가 부족한 언어에 대한 풍자 감지 데이터 세트를 구축하기 위해 최신 기술을 활용하는 방법을 제시합니다. 특히, 중형 변환기 모델과 매우 큰 생성 언어 모델을 이용하여 번역된 데이터 세트의 유효성을 조사합니다.

- **Technical Details**: 풍자 감지의 이 연구는 기계 번역과 대형 생성 언어 모델(LLM)을 결합하여 슬로베니아어 데이터 세트를 최신 기술로 구축하였습니다. T5 모델과 OpenAI의 GPT-4를 사용하여 풍자의 맥락을 유지하며 번역했습니다. 또한, 앙상블(ensemble) 기법을 통해 다양한 모델 성능을 평가하였습니다.

- **Performance Highlights**: 모델 성능 실험 결과, 더 큰 모델이 일반적으로 더 작은 모델보다 우수한 성능을 보였으며, 앙상블 기법을 적용하면 풍자 감지 성능이 소폭 향상되었습니다. 최종 앙상블 접근 방식은 $	ext{F}_1$-score가 0.765로, 원래 언어의 주석자 간의 합의에 가까운 결과를 얻었습니다.



### VividMed: Vision Language Model with Versatile Visual Grounding for Medicin (https://arxiv.org/abs/2410.12694)
- **What's New**: 최신 연구에 따르면, Vision Language Models (VLMs)의 발전은 시각적으로 기반을 둔 응답 생성에서 놀라운 가능성을 보여주고 있습니다. 그러나 의료 분야에서는 특정 도전 과제가 존재합니다. VividMed라는 새로운 모델은 이 문제를 해결하기 위해 다양한 시각적 기반을 제공하고, 2D 및 3D 이미지를 모두 처리할 수 있도록 설계되었습니다.

- **Technical Details**: VividMed는 세 가지 단계의 훈련 과정과 자동 데이터 주석 파이프라인을 통해 학습됩니다. 이 모델은 세분화 마스크와 인스턴스 수준의 경계 상자를 동시에 생성할 수 있으며, Segment Anything Model (SAM)을 기반으로 한 시각적 기반 기능을 통합하여 성능을 향상시킵니다. VividMed는 다양한 의료 영상 모달리티를 처리할 수 있습니다.

- **Performance Highlights**: 실험 결과, VividMed는 기존 VLMs의 시각적 기반 작업에서 우수한 성능을 보이며, Visual Question Answering (VQA) 및 보고서 생성과 같은 일반적인 하위 작업에서도 경쟁력 있는 성과를 나타냈습니다. 시각적 기반 능력을 통합함으로써, VividMed는 다른 하위 작업에서도 성능 향상을 이루었습니다.



### Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models (https://arxiv.org/abs/2410.12662)
- **What's New**: 본 연구에서는 Large Vision-Language Models (LVLMs)의 비주얼 입력에 대한 안전 메커니즘의 전이 부족 문제를 다룹니다. 현재의 방법론이 비주얼 모달리티에 대해 안전 메커니즘을 효과적으로 전이하지 못함을 발견하고, Text-Guided vision-language Alignment (TGA)라는 새로운 방법을 제안합니다.

- **Technical Details**: TGA는 입력된 비전과 관련된 텍스트를 검색하여 LLMs의 hidden states 공간으로 비전을 투영하는 데 도움을 줍니다. 이로써 이미지의 hidden states와 텍스트의 hidden states 간의 정렬을 이루게 됩니다. 연구 결과, TGA는 기존 LLMs의 안전 메커니즘을 비전으로 성공적으로 전이할 수 있음을 보여주었습니다.

- **Performance Highlights**: TGA는 안전한 결과를 도출하며, InstructBLip, LLaVA-1.5 및 Qwen-VL-Chat과 같은 기존의 최첨단 LVLM들과 비교할 때 다양한 비전 작업에서 일반 성능을 유지합니다.



### Revealing the Barriers of Language Agents in Planning (https://arxiv.org/abs/2410.12409)
Comments:
          Work in Progress

- **What's New**: 이 논문에서는 인공지능의 자율 계획(autonomous planning) 분야에서 현재 언어 에이전트(language agents)가 인간 수준의 계획 능력에 도달하지 못하는 이유를 분석합니다.

- **Technical Details**: 연구에서는 feature attribution study를 적용하여 계획을 저해하는 두 가지 주요 요인을 식별했습니다. 첫 번째는 제약 조건(constraints)의 제한된 역할이고, 두 번째는 질문(question)의 감소하는 영향입니다. 이러한 요인들로 인해 현재 사용되고 있는 전략들이 문제를 완전히 해결하지 못하고 있다는 점도 발견했습니다.

- **Performance Highlights**: 현재 최첨단 추론 모델인 OpenAI o1은 복잡한 실제 계획 기준에서 15.6%의 성과를 달성했으며, 이는 인간 수준의 계획 접근 방식에는 여전히 큰 격차가 있음을 나타냅니다.



### Beyond Coarse-Grained Matching in Video-Text Retrieva (https://arxiv.org/abs/2410.12407)
Comments:
          Accepted to ACCV 2024

- **What's New**: 비디오-텍스트 검색(video-text retrieval)에 대한 새로운 접근 방식이 제시되었습니다. 특히, 기존 데이터셋에 대해 미세하게 변형된 하드 네거티브 테스트 캡션을 자동으로 생성하는 방법을 도입하였습니다.

- **Technical Details**: 제안된 방법은 네 개의 시각적으로 최신(state-of-the-art) 모델을 사용하여 두 개의 표준 벤치마크(MSR-VTT, VATEX)와 두 개의 상세한 설명이 포함된 특별 데이터셋(VLN-UVO, VLN-OOPS)에서 실험을 수행합니다. 모델의 미세한 단어 차이를 인식하는 능력을 검증하기 위해 기본적인 기준을 제안하였습니다.

- **Performance Highlights**: 전반적인 결과, 현재 평가 벤치마크가 모델이 미세 단어 차이를 감지하는 데 부족하다는 점과, 모델들이 이러한 미세한 변화를 구별하는 데 어려움을 겪는다는 점을 발견하였습니다. 제안된 미세 평가 방법은 모델의 미세한 이해 능력을 향상시키는 데 효과적임이 입증되었습니다.



### PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking (https://arxiv.org/abs/2410.12375)
- **What's New**: PRefLexOR (Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning)는 선호 최적화(preference optimization)와 강화 학습(Reinforcement Learning) 개념을 결합하여 모델이 반복적인 추론 개선을 통해 스스로 학습할 수 있도록 합니다.

- **Technical Details**: 이 논문은 다단계 추론(multi-step reasoning) 과정에서 모델이 중간 단계를 재검토하고 수정한 후 최종 출력을 생성하는 재귀 학습(recursive learning) 접근 방식을 제안합니다. 모델은 선호 응답(preferred responses)과 비선호 응답(non-preferred responses) 간의 로그 확률(log odds)을 최적화하여 정확한 결정 경로에 정렬하는 것을 배웁니다. 또한, 무작위 텍스트 조각에서 질문을 생성하고 관련 세부 정보를 맥락화하기 위해 동적 지식 그래프(dynamic knowledge graph)를 구축합니다.

- **Performance Highlights**: 3억 개의 파라미터를 가진 소형 언어 모델(small language models)에서 구현되었으며, 작은 모델도 깊이 있는 추론과 반성(reflection)을 통해 스스로를 반복적으로 학습할 수 있음을 보여줍니다. 생물 재료 과학(biological materials science) 분야에서의 다양한 사례 연구를 통해 이 방법을 증명하며, 추론 시간에 반복 샘플링을 통해 응답을 성공적으로 개선하는 다중 에이전트 재귀 자기 개선 추론(multi-agent recursive self-improving inference) 접근 방식을 구축합니다.



### Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistanc (https://arxiv.org/abs/2410.12361)
Comments:
          9 pages, 4 figures

- **What's New**: 이 논문에서는 명시적인 인간 지시 없이도 작업을 예측하고 시작할 수 있는 선제적 에이전트(proactive agents)를 개발하는 문제에 접근합니다.

- **Technical Details**: 실제 인간 활동 데이터를 수집하여 선제적 작업 예측(proactive task predictions)을 생성합니다. 이 예측은 인간 주석자에 의해 수용(accepted) 또는 거부(rejected)로 라벨링됩니다. 라벨링된 데이터는 인간 판단을 시뮬레이션하는 보상 모델(reward model)을 훈련하는 데 사용됩니다. 또한, ProactiveBench라는 6,790개의 다양한 이벤트를 포함하는 데이터셋 통합 파이프라인을 개발하였습니다.

- **Performance Highlights**: 미세 조정된(fine-tuned) 모델은 F1-Score 66.47%로 선제적으로 도움을 제공하는 능력을 평가하며, 모든 오픈 소스 및 클로즈드 소스 모델을 초월하는 성과를 보여주었습니다.



### LLM-based Cognitive Models of Students with Misconceptions (https://arxiv.org/abs/2410.12294)
- **What's New**: 이 논문은 AI 기반 교육 기술에서 학생 인지를 정확하게 모델링하는 것의 중요성을 강조하며, 학생 모델링에서 잘못된 인식을 포함한 정확한 문제 해결을 동시에 충족하는 새로운 접근 방식을 제안합니다.

- **Technical Details**: MalAlgoPy라는 새로운 Python 라이브러리를 통해 대수 문제 해결 과정에서 학생의 해결 패턴을 반영하는 데이터셋을 생성하며, 이를 그래프 기반으로 나타냅니다. 모델은 학생 모델(Cognitive Student Models, CSM)로서, 잘못된 인식과 올바른 지식을 동시에 반영하는 방법으로 훈련됩니다.

- **Performance Highlights**: 잘못된 인식 예제로 훈련된 LLMs는 문제를 올바르게 해결하는 능력이 감소했으나, 훈련 데이터에서 올바른 예제와 잘못된 예제의 비율을 조정함으로써 두 가지 속성을 모두 만족하는 CSM을 개발할 수 있음을 보여주었습니다.



### A Prompt-Based Knowledge Graph Foundation Model for Universal In-Context Reasoning (https://arxiv.org/abs/2410.12288)
Comments:
          Accepted in the 38th Conference on Neural Information Processing Systems (NeurIPS 2024)

- **What's New**: 이번 논문에서는 다양한 지식 그래프(KG)에서의 일반화된 추론 능력을 달성하기 위해, 문맥 내 학습(in-context learning)을 이용한 프롬프트 기반 KG 기초 모델(KG-ICL)을 제안합니다. 이 모델은 다양한 KG와 추론 환경에 걸쳐 지식을 전이하고 일반화할 수 있는 기능을 갖추고 있습니다.

- **Technical Details**: KG-ICL 모델은 쿼리와 관련된 예제 사실을 중심으로 한 프롬프트 그래프(prompt graph)를 도입하여 쿼리 관계를 이해합니다. 이를 통해 새로운 실체와 관계에 대한 일반화 능력을 가진 통합 토크나이저(unified tokenizer)를 제안하고, 두 개의 메시지 패싱 신경망(message passing neural networks)을 통해 프롬프트 인코딩과 KG 추론을 수행합니다.

- **Performance Highlights**: 43개의 다양한 KG에 대한 실험 결과, KG-ICL 모델은 대부분의 데이터셋에서 기존 모델을 초과 성능을 보이며, 뛰어난 일반화 및 보편적 추론 능력을 보여줍니다. 이 모델은 높은 효율성을 갖추고 예제를 활용하는 데 강력한 성능을 발휘합니다.



### Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting (https://arxiv.org/abs/2410.12284)
- **What's New**: 이번 연구는 자연어 설명(NLE), 주목지도(saliency mapping), 두 가지 설명 방식의 조합이 실제 의료 현장에서 AI와 협력하여 가슴 X선 분석을 수행하는 의료 종사자들에게 미치는 영향을 대규모 사용자 연구로 평가한 내용을 다룹니다. 연구 결과, 언어 기반 설명이 과도한 의존성을 초래함을 발견하였고, 주목지도와 결합했을 때 그 단점을 완화할 수 있음을 확인했습니다.

- **Technical Details**: 이 연구는 85명의 의료 종사자를 대상으로 진행되었으며, 각각 80개의 독특한 이미지를 분석했습니다. 연구에서는 주목지도, 자연어 설명 및 두 가지 설명의 조합을 포함하여 네 가지 다양한 CDSS(Clinical Decision Support System) 설정에서 수행되었습니다. 조건이 불완전한 AI 및 XAI 환경에서 다양한 설명 유형이 사용자의 행동에 미치는 영향을 조사했습니다.

- **Performance Highlights**: 결과적으로, 설명의 질은 유용성에 중요한 영향을 미쳤으며, 설명 정확도가 AI 정확도와 일치할 때 사용자에게 긍정적인 영향을 미치는 것으로 나타났습니다. 특히, 주목지도와 자연어 설명의 조합은 설명 유형 중 가장 유용한 것으로 평가되었습니다. 반면 AI와 설명의 정확도가 불일치할 경우, 사용자 성능에 부정적인 영향을 미칠 수 있음을 걸러냈습니다.



### Beyond Oversmoothing: Evaluating DDPM and MSE for Scalable Speech Synthesis in ASR (https://arxiv.org/abs/2410.12279)
Comments:
          Under review at ICASSP 2025

- **What's New**: 이 논문에서는 TTS(Text-to-Speech) 시스템에서 의도적으로 생성된 합성 음성이 인간 수준의 자연스러움에 근접했지만, ASR(Automatic Speech Recognition) 시스템의 성능은 여전히 실 음성에 비해 낮다는 패러독스를 탐구합니다.

- **Technical Details**: Denoising Diffusion Probabilistic Models (DDPM)와 Mean Squared Error (MSE) 기반 모델을 비교하여 ASR 모델 교육에 관한 성능을 분석합니다. DDPM은 더 다양한 발화자와 데이터를 활용하는 데에 더 효과적이며, 모드 붕괴(mode collapse)를 줄이고 전체 확률 분포를 모델링하는 데 중요한 역할을 합니다. 또한, TTS 훈련 데이터 크기에 따른 ASR 성능 변화를 단계적으로 분석합니다.

- **Performance Highlights**: 예를 들어, DDPM을 사용하여 합성음성과 실음성 간의 단어 오류율(Word Error Rate, WER) 비율을 1.46으로 기록했으나, 실제 음성과 합성 음성 간의 성능 차이는 여전히 남아있음을 발견했습니다. 이러한 결과는 DDPM이 MSE보다 더 유리한 스케일링 곡선을 보이고, 두 모델 모두 감소하는 수익의 한계를 겪고 있다는 것을 보여줍니다.



### Controlled Automatic Task-Specific Synthetic Data Generation for Hallucination Detection (https://arxiv.org/abs/2410.12278)
- **What's New**: 이 논문에서는 환각 감지를 위한 비트리비얼(task-specific) 합성 데이터세트를 자동으로 생성하는 새로운 접근 방식을 제안합니다. 이 방법은 두 단계의 생성-선택 파이프라인을 특징으로 하며, 환각 패턴 지침(hallucination pattern guidance) 및 언어 스타일 정렬(language style alignment)을 활용하여 데이터 품질을 향상시킵니다.

- **Technical Details**: 제안된 방법은 자동화된 생성-선택 파이프라인을 기반으로 하며, 환각 패턴 가이드를 통해 특정 작업에 적합한 환각 샘플을 생성하고, 언어 스타일 정렬을 통해 합성 데이터의 스타일을 벤치마크 텍스트와 일치시킵니다. 이 방법은 세 가지 대화 벤치마크에서 실험을 통해 검증되었으며, F1 점수 0.938을 달성하여 기존의 인컨텍스트러닝(ICL) 기반 감지기를 32.5%의 큰 차이로 초과했습니다.

- **Performance Highlights**: 제안된 환각 감지기는 생성된 합성 데이터세트를 통해 훈련된 결과, 상기된 세 가지 차원에서 뛰어난 일반화 능력을 보여주었습니다. 또한, 생성된 합성 환각이 실제 비환각 샘플에 더 유사함을 입증하였으며, 이는 우리 접근 방식의 강력한 일반화 능력을 확인하였습니다.



### Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations (https://arxiv.org/abs/2410.12228)
- **What's New**: 이 논문은 개인화 추천 시스템을 향상시키기 위해 다양한 데이터 모달리티(data modalities)를 통합하는 새로운 프레임워크인 Triple Modality Fusion (TMF)를 소개합니다. 이 프레임워크는 시각적, 텍스트, 그래프 데이터의 융합을 통해 수행됩니다.

- **Technical Details**: TMF 모델은 큰 언어 모델(LLMs)과의 정렬을 통해 세 가지 모달리티를 통합하며, 각각의 모달리티는 사용자 행동을 포괄적으로 표현하기 위해 서로 다른 특징을 제공합니다. 시각적 정보는 아이템의 맥락 및 미적 특성을 캡처하고, 텍스트 데이터는 사용자 관심사와 아이템 특성에 대한 상세한 통찰력을 제공하며, 그래프 데이터는 아이템-행동 이질 그래프(item-behavior heterogeneous graph) 내의 관계를 설명합니다.

- **Performance Highlights**: 광범위한 실험을 통해 추천 정확성을 개선하는 효과를 입증하였습니다. 추가적인 ablation 연구를 통해 TMF 모델 디자인의 효과성과 이점을 검증하였습니다.



### OmnixR: Evaluating Omni-modality Language Models on Reasoning across Modalities (https://arxiv.org/abs/2410.12219)
Comments:
          19 pages, 6 figures, 12 tables

- **What's New**: OmnixR는 여러 다중 모달리티(omni-modality)를 처리하는 최신 AI 모델의 성능을 평가하기 위한 새로운 벤치마크입니다. 기존의 평가 방법이 단일 또는 이중 모달리티에 한정되어 있었던 반면, OmnixR는 복잡한 비디오, 오디오, 텍스트 조합을 평가하므로, 모델의 종합적인 이해력을 테스트합니다.

- **Technical Details**: OmnixR 벤치마크는 두 가지 데이터 집합으로 구성됩니다: (1) Omni××R_{synth}: 텍스트 정보를 다양한 모달리티(오디오, 이미지, 비디오)로 변환한 합성 데이터 집합이며, (2) Omni××R_{real}: 전문가들에 의해 수집되고 주석이 달린 실제 데이터를 포함하여, 오미모달리티(omni-modality) 추론력을 평가합니다. Omnify!라는 자동화 도구를 사용하여 데이터를 생성하며, 이는 모델의 다중 모달 이해력과 추론 능력을 평가하는 데 초점을 맞춥니다.

- **Performance Highlights**: 실험 결과, 최신 OLM들은 OmnixR 질문에서 여러 모달리티 정보를 통합하여 정확한 답변을 도출하는 데 어려움을 겪었습니다. 특히, 간단한 촉진 전략(ETA prompting)을 사용하여 성능 개선 가능성을 보여주었지만, 현실적인 환경에서 오미모달 행동 불일치를 완전히 해소하기 위해 추가적인 훈련이 필요하다는 점이 드러났습니다.



### Preference Optimization with Multi-Sample Comparisons (https://arxiv.org/abs/2410.12138)
Comments:
          preprint

- **What's New**: 이번 연구에서는 다중 샘플 비교를 포함하는 새로운 포스트 트레이닝(post-training) 접근 방식을 소개합니다. 이를 통해 생성 모델의 다양성 및 편향을 보다 정확하게 평가할 수 있게 됩니다.

- **Technical Details**: 제안된 방법론은 Multi-sample Direct Preference Optimization (mDPO)와 Multi-sample Identity Preference Optimization (mIPO)로, 전통적인 DAP 방식(DAP methods)에 비해 그룹 특성(group-wise characteristics)에 집중합니다. 기존의 접근 방식들은 단일 샘플 비교(single-sample comparisons)에 의존하는 반면, 새로운 방법들은 다중 샘플 비교를 통해 특성을 최적화합니다.

- **Performance Highlights**: 실험 결과, 다중 샘플 비교는 생성 모델의 다양성 및 불편향성을 위한 최적화에서 단일 샘플 비교보다 더 효과적이라는 것을 입증하였습니다. 특히, 데이터셋 내에서 레이블 노이즈(label noise)가 존재할 경우, 다중 샘플 비교 방법이 보다 강력한 최적화 프레임워크를 제공하는 것으로 나타났습니다.



### Scaling laws for post-training quantized large language models (https://arxiv.org/abs/2410.12119)
- **What's New**: 본 연구는 대형 언어 모델(LLMs)에서 훈련 후 압축(Post-Training Compression), 특히 양자화에 관한 새로운 통찰력을 제공합니다. 기존의 사전 훈련(pre-training) 기준을 넘어, 저정밀(低精度) 텐서 데이터 타입에서 LLM의 성능 예측을 가능하게 하는 여러 요소들이 신뢰할 수 있는 방식으로 식별되었습니다.

- **Technical Details**: 연구에서는 LLM의 훈련된 모델의 일반화 능력과 관련된 여러 요소(예: pre-trained NLL loss, local loss landscape 등)에 대한 체계적인 실증 연구가 이루어졌습니다. 특히, 로컬 손실 경관(local loss landscape)에서의 변화와 다양한 저정밀 데이터 타입의 영향을 분석하며, 이를 바탕으로 PTQ(post-training quantization) 절차의 결과를 예측할 수 있는 통계 모델(statistical model)을 개발했습니다.

- **Performance Highlights**: 연구 결과, LLM의 양자화 성능은 특정 LLM 가족에 대해 예측 가능한 경향을 보이며, 이는 PTQ 과정에서 고려해야 할 다수의 요소를 체계적으로 파악함으로써 이루어졌습니다. Quantization의 최적화는 모델 품질을 일정 부분 회복시키는 데 도움이 되며, 전반적인 PTQ 프로세스의 신뢰성을 높이는 데 기여합니다.



### Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming (https://arxiv.org/abs/2410.12112)
Comments:
          50 pages, 25 figures, 7 tables

- **What's New**: 새로운 연구에서는 복잡한 계획 문제를 해결하기 위해 대규모 언어 모델(LLMs)을 활용하는 LLMFP라는 일반 목적의 프레임워크를 제안합니다. 이 프레임워크는 태스크 특정 예제 없이도 최적화 문제로 계획 문제를 공식화하고 해결할 수 있는 가능성을 보여줍니다.

- **Technical Details**: LLMFP는 자연어 도메인 설명과 쿼리, 배경 정보를 입력받아 계획 문제를 해결하는 다섯 단계 프로세스를 갖추고 있습니다: 목표 및 주요 제약 조건 제안, 변수 표현 구축, 최적화 문제로 문제 공식화, 코드 실행 및 플랜 변환, 마지막으로 결과에 대한 평가 및 수정. 이 프레임워크는 SMT(상태 수정 이론)를 사용하여 최적화 문제를 인코딩합니다.

- **Performance Highlights**: LLMFP는 9개의 다양한 계획 문제에 적용되었으며, GPT-4o 및 Claude 3.5 Sonnet의 평균 최적 비율은 각각 83.7% 및 86.8%로, OpenAI o1-preview의 직접 계획 생성법보다 37.6% 및 40.7% 상승한 성과를 내며 탁월한 성능을 입증했습니다.



### LocoMotion: Learning Motion-Focused Video-Language Representations (https://arxiv.org/abs/2410.12018)
Comments:
          ACCV 2024

- **What's New**: 이 논문은 동작 중심 비디오-언어 표현(motion-focused video-language representations)을 목표로 하고 있습니다. 기존의 방법들이 공간적인(focused on spatial) 데이터에 의존하여 물체와 장면을 식별하는 데 중점을 두었던 반면, 이 연구에서는 동작을 설명하는 캡션(captions)에서 학습하는 LocoMotion을 제안합니다.

- **Technical Details**: 기존의 비디오-언어 표현 방법은 캡션이 공간적 측면에 집중된 반면, LocoMotion은 지역 물체의 동작을 아우르는 동작 중심 캡션을 생성하여 학습합니다. 이를 위해 비디오에 합성된 동작(synthetic motions)을 추가하고 이 동작의 매개변수(parameters)를 활용하여 상응하는 캡션을 생성합니다. 또한, 동작의 다양성을 높이기 위해 동사 변형 парафразинг(verb-variation paraphrasing)을 도입하여 동작 기본 요소(primitive motions)와 고수준 동사 간의 연관성을 학습합니다.

- **Performance Highlights**: 실험 결과, 동작 중심 데이터가 제한적인 상황에서도 효과적인 성능을 보이며, 다양한 하위 작업(downstream tasks)에 대해 우수한 적합성을 입증했습니다.



### Bias Similarity Across Large Language Models (https://arxiv.org/abs/2410.12010)
Comments:
          under review

- **What's New**: 이 논문은 여러 LLM(대형 언어 모델) 간의 편향(bias) 유사성을 비교한 최초의 작업이다. 기존 연구들은 개별 모델에서의 편향을 분석했지만, 다양한 모델 간의 편향을 비교한 연구는 부족했다. 이를 통해 LLM의 편향을 서로 분석하여 향후 모델 디버깅 기술에 기여할 수 있는 가능성을 제시한다.

- **Technical Details**: 연구에서는 10개의 오픈 및 클로즈드 소스 LLM을 포함하여 4종 모델 패밀리에서 편향의 정도를 평가하였다. 두 개의 데이터 세트를 사용해 4개의 편향 차원에서 질문 4천 개와 100만 개에 대한 LLM의 출력 분포를 측정하였으며, 결과적으로 다음과 같은 주요 발견을 도출했다: 1) 파인튜닝(fine-tuning)이 출력 분포를 유의미하게 변경하지 않음, 2) 동일 모델 패밀리 내에서도 유사한 출력 분포를 생성하지 않음, 3) 훈련 데이터 정보 유출 가능성이 존재함.

- **Performance Highlights**: 연구 결과는 다음과 같다: 1) LLM의 파인튜닝이 출력 분포에 미치는 영향이 제한적이며, 이는 편향 완화 능력을 제한할 수 있다. 2) 동일 패밀리의 LLM이 출력 경향성에서 서로 다르게 작용해 편향 처리를 위한 모델 간 상호연관성이 낮다. 3) 다양한 모델 간의 편향 레벨이 달라 데이터 보안 및 개인 정보 보호에 대한 우려가 제기된다.



### FLARE: Faithful Logic-Aided Reasoning and Exploration (https://arxiv.org/abs/2410.11900)
- **What's New**: 본 논문에서는 기존의 Chain-of-Thought (CoT) 방법론의 문제점을 해결하기 위해 Faithful Logic-Aided Reasoning and Exploration (FLARE)라는 새로운 접근 방식을 제안합니다. FLARE는 LLM을 사용하여 문제 공간을 탐색하고, 논리 프로그래밍 언어를 이용해 자연어 쿼리를 사실과 술어로 변환하여 코드 실행을 시뮬레이션합니다.

- **Technical Details**: FLARE는 세 가지 모듈로 구성되어 있습니다: 계획 생성을 위한 모듈, Prolog 코드를 생성하는 모듈, 그리고 문제를 해결하기 위한 시뮬레이션 검색 모듈입니다. 이 시스템은 멀티-홉 검색을 통해 자연어 쿼리의 해답을 찾는 과정에서 이유 과정을 정량적으로 평가할 수 있습니다.

- **Performance Highlights**: FLARE는 9개의 다양한 추론 벤치마크 중 7개에서 SOTA (State Of The Art) 결과를 달성하였으며, F-CoT보다 평균 16%, CoT보다 9% 향상된 성능을 보였습니다. 모델의 정확도는 이유 과정의 신뢰성과 강하게 상관관계가 있음을 입증하였습니다.



### Automatic Screening for Children with Speech Disorder using Automatic Speech Recognition: Opportunities and Challenges (https://arxiv.org/abs/2410.11865)
Comments:
          AAAI-FSS 24

- **What's New**: 이 연구에서는 아동의 언어 평가(SLA)에 AI 기술을 통합하는 것이 중요하다는 점을 강조하며, 특히 자동 음성 인식(ASR) 모델을 아동의 언어에 적합하게 조정하는 방법을 제안합니다. 또한, 효율적이고 확장 가능한 SLA 방법의 필요성을 논의합니다.

- **Technical Details**: 자동 음성 인식(ASR) 기술은 아동의 음성을 텍스트 형식으로 변환하는 데 사용됩니다. ASR 모델은 주로 성인 음성에 초점을 맞추고 있지만, 아동의 음성 특징에 적합하게 조정하는 것이 필수적입니다. Fine-tuning을 통해 ASR 모델의 성능을 개선할 수 있으며, 기존의 방법 외에도 아동의 음성 데이터에서 직접 사전 훈련하는 방법도 제시되고 있습니다.

- **Performance Highlights**: 최근의 연구들은 자동 평가 시스템의 정확도가 95%를 초과한다고 주장하며, Ambiki, Smart Ears와 같은 소비자 수준의 소프트웨어도 이러한 목표를 달성하기 위해 개발되고 있습니다. 그러나 이러한 접근 방식은 결과 해석에 대한 과학적 설명이 부족하다는 문제점이 있습니다.



### ChatVis: Automating Scientific Visualization with a Large Language Mod (https://arxiv.org/abs/2410.11863)
- **What's New**: 본 논문에서는 ChatVis라는 반복적 보조 도구를 개발하여 데이터 분석 및 시각화를 위한 Python 스크립트를 생성하는 방법을 제안합니다. 사용자는 자연어로 작업을 지정할 수 있으며, LLM(large language model)이 원하는 작업에 대한 Python 스크립트를 생성하고 반복적으로 수정하여 올바르게 실행되도록 합니다. 중간에 발생하는 오류를 감지하고 수정하는 메커니즘이 포함되어 있습니다.

- **Technical Details**: ChatVis는 사용자 입력을 기반으로 자연어로 설명된 시각화 요구사항을 처리하여, 추가적인 프롬프트를 생성하고 이를 통해 Python 스크립트를 만들어냅니다. 최종적으로 ParaView의 PvPython API를 사용하여 스크립트를 실행하고 결과를 확인합니다. 반복적인 피드백 루프를 통해 오류 메시지가 LLM에 전달되어 코드가 개선됩니다. 이 방법은 과거의 여러 스크립트와 비교하여 정확한 시각화를 생성하는 데 성공했습니다.

- **Performance Highlights**: ChatVis는 다섯 가지 대표적 시각화 시나리오에서 올바른 실행 결과를 보여줍니다. 비교 대상이 된 다른 LLM에서는 ChatVis와 같은 도움 없이 정확한 스크립트를 생성하지 못했습니다. 이번 연구는 LLM을 활용한 과학적 시각화를 위한 최초의 시도 중 하나로 평가됩니다.



### Survey and Evaluation of Converging Architecture in LLMs based on Footsteps of Operations (https://arxiv.org/abs/2410.11381)
Comments:
          13 pages and 16 figures

- **What's New**: 이 논문은 Attention 메커니즘과 Transformer 아키텍처의 발전이 LLM(대형 언어 모델)의 구조적 수렴에 미친 영향을 분석하고, 다양한 하이퍼파라미터 설정에 따른 성능 경향을 정리하고 있습니다.

- **Technical Details**: LLM 아키텍처의 성능을 레이어 구성, 작동 메커니즘, 모델 크기를 고려하여 분석하였으며, 특히 최신의 RTX 6000을 사용하여 하이퍼파라미터 설정의 영향을 평가했습니다. TensorRT-LLM과 같은 고속 추론 성능을 지원하는 오픈소스 라이브러리도 논의되었습니다.

- **Performance Highlights**: 연구 결과, 동일한 모델이라 하더라도 하이퍼파라미터 설정이나 서버와 엣지 환경에서의 배포 방식에 따라 성능이 달라질 수 있다는 것을 확인했습니다. 또한, 최신 오픈소스 LLM(Begma와 Llama)의 아키텍처를 분석하고, 고성능 GPU에서 추론 프로세스를 집중적으로 살펴보았습니다.



### The rotating normal form of braids is regular (https://arxiv.org/abs/1606.08970)
Comments:
          Erratum. The Lemma 4.1 of the previous version is incorrect, as pointed out by June Roupin. This lemma, is not used in the rest of the paper. We have replaced it with Definition 4.1

- **What's New**: 이번 논문은 Birman-Ko-Lee 모노이드에서 정의된 rotating normal form의 강력한 연결성을 다룹니다. 특히, Dehornoy의 braid ordering과의 관계를 강조하며, Birman-Ko-Lee braid의 모든 대표 단어들 중에서 특정 단어인 rotating word를 선택하는 과정을 설명합니다.

- **Technical Details**: 이 논문에서는 모든 n >= 2의 경우에 대해 n strands 위에서 rotating words를 인식하는 유한 상태 오토마타(finite-state automaton)를 구성합니다. 이를 통해 rotating normal form이 정규(regular)임을 증명합니다. 또한, 전체 braid group에 대해 정의된 $\sigma$-definite normal form의 정규성을 도출합니다.

- **Performance Highlights**: rotating normal form의 정규성이 입증됨에 따라, 관련된 계산 및 알고리즘적 적용에 있어 더 나은 이해와 처리 효율성을 نظ를 수 있게 되었습니다.



### NesTools: A Dataset for Evaluating Nested Tool Learning Abilities of Large Language Models (https://arxiv.org/abs/2410.11805)
- **What's New**: 최근의 연구는 대형 언어 모델(LLM)들이 도구 학습(tool learning)을 통해 실세계 애플리케이션에서 뛰어난 성과를 이루고 있음을 보여주고 있습니다. 특히, LLM이 여러 도구를 중첩하여 호출하는 새로운 데이터셋인 NesTools를 소개하여, 중첩 도구 학습(nested tool learning)의 성능 평가를 위한 기준을 마련했습니다.

- **Technical Details**: NesTools는 자동 데이터 생성 방법을 통해 대규모 중첩 도구 호출을 생성할 수 있는 새로운 프레임워크를 제공합니다. 데이터셋은 도구 및 인스턴스 생성, 쿼리 생성, 데이터 검토 및 정제를 포함하는 복잡한 과정으로 구성됩니다. 최종적으로 1,000개의 데이터 항목을 신중하게 선택하고 교차 검증하여 높은 품질을 보장합니다.

- **Performance Highlights**: 22개의 LLM에 대해 NesTools를 활용하여 실험을 수행한 결과, 모델들은 규모 확장(scale scaling)으로부터 일부 혜택을 보았으나, 도구 선택 및 깊이 중첩된 호출에서 여전히 성능 저하를 경험했습니다. 이 결과는 LLM이 복잡한 중첩 도구 학습 작업에서 어려움을 겪고 있음을 보여줍니다.



### Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability (https://arxiv.org/abs/2410.11786)
Comments:
          14 pages, 5 figures, 10 tables, EMNLP 2024 Findings

- **What's New**: 이번 연구에서는 Selection-p이라는 새로운 압축 방법을 제안하며, LLMs가 불필요한 토큰을 효과적으로 분류하여 압축할 수 있는 능력을 탐구합니다.

- **Technical Details**: 이 연구는 self-supervised pre-training 기법을 사용하여, LLM이 입력 토큰에 대해 보존 혹은 삭제할지의 확률을 계산하도록 합니다. 이는 추가적인 파라미터를 거의 추가하지 않고 이루어지며, 기존의 방법들에 비해 더 유연하고 효과적인 압축을 가능하게 합니다.

- **Performance Highlights**: Selection-p은 10배의 압축에서 단 0.8%의 성능 감소만 있으면서도 다수의 분류 작업에서 최상의 성능을 기록했습니다. 또한, 다양한 모델 간의 이동 가능성을 크게 향상시켰습니다.



### MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation (https://arxiv.org/abs/2410.11779)
Comments:
          Ongoing work

- **What's New**: 이번 연구에서 우리는 Multimodal Large Language Models (MLLMs)에서의 환각(hallucination) 현상을 심층적으로 분석하고, 이 현상의 배경 메커니즘을 이해하기 위한 새로운 동적 수정 디코딩 방법인 DeCo(이전 레이어 동지식 지능 수정)를 제안합니다.

- **Technical Details**: DeCo는 MLLM의 결론 층에 도달하기 전에 발생한 지식 정보를 동적으로 선택하여 최종 출력 로짓(logits)을 조정합니다. 이 방법은 모델에 구애받지 않으며, 여러 전통적인 디코딩 전략과 원활하게 통합될 수 있습니다.

- **Performance Highlights**: DeCo를 이미지 캡셔닝 및 시각 질문 답변 데이터셋에 적용한 결과, 평균 10.8%의 환각 억제 효과를 보여주었으며, 다양한 데이터셋에서 기존 방법들보다 더 높은 성능을 기록했습니다. 또한 DeCo는 이전 방법들과 비교했을 때 약간의 지연(latency) 증가가 있었지만, 속도는 훨씬 더 빨라졌습니다.



### Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models (https://arxiv.org/abs/2410.11772)
Comments:
          EMNLP 2024

- **What's New**: 이 연구는 Layer-wise Sparse Tuning (IST)라는 새로운 방법론을 제안하며, 이는 특정 레이어의 중요성을 평가하여 중요도가 높은 레이어만 업데이트함으로써 메모리 및 연산 부하를 감소시킵니다.

- **Technical Details**: Importance-aware Sparse Tuning (IST)은 PEFT(파라미터 효율적 미세 조정) 방법과 호환되는 플러그 앤 플레이 기법으로, 레이어별 중요도 점수를 통해 가장 중요한 레이어의 서브셋을 선택하여 전체 레이어의 효율성을 최적화합니다. 또한, 이 연구는 경량화된 메모리 요구 사항과 빠른 수렴 속도를 제공합니다.

- **Performance Highlights**: IST는 기존의 PEFT 방법들에 비해 우수한 성능을 보이며, 다양한 LLM 및 다운스트림 태스크에 대한 폭넓은 실험을 통해 그 유효성이 입증되었습니다.



### Personas with Attitudes: Controlling LLMs for Diverse Data Annotation (https://arxiv.org/abs/2410.11745)
Comments:
          21 pages, 13 figures

- **What's New**: 본 논문에서는 개인화된 LLM(대규모 언어 모델)을 활용하여 데이터 주석 작업의 다양성과 제어를 향상시키는 새로운 접근 방식을 제안합니다. 개인화된 persona(페르소나) 설명을 LLM 프롬프트에 삽입하여 주석의 다양성을 증가시키는지를 조사하였으며, 이로 인해 생성된 주석의 수준이 일관성 있고 제어 가능함을 입증하였습니다.

- **Technical Details**: 우리는 두 가지 연구를 통해 LLM 프롬프트에 persona를 주입하는 것이 가능성을 탐구합니다. 첫 번째 연구는 prescriptive paradigm(처방적 패러다임)을 다루며, 두 번째 연구는 descriptive paradigm(기술적 패러다임)을 따릅니다. 각 연구에서 persona-프롬프트 LLM이 주석의 다양성과 패턴을 생성하는 능력을 테스트합니다.

- **Performance Highlights**: 연구 결과, persona에 의해 유도된 LLM 주석이 더 많은 다양성을 생성하며, 이 효과는 제어 가능하고 반복 가능하다는 것을 보여줍니다. 이는 비폭력 감지와 같은 주관적 NLP 작업에서 데이터 주석을 개선하는 유용한 도구로 자리 잡게 됩니다.



### Converging to a Lingua Franca: Evolution of Linguistic Regions and Semantics Alignment in Multilingual Large Language Models (https://arxiv.org/abs/2410.11718)
Comments:
          16 pages, 11 figures, 4 tables

- **What's New**: 이번 연구는 대형 언어 모델(LLMs)이 다양한 언어를 처리할 때 나타나는 뉴런 활성화 패턴의 유사성을 발견했으며, 이를 통해 중요한 언어 영역의 존재와 위치를 규명했습니다. 또한, 동일한 의미를 갖는 다른 언어의 문장을 처리할 때도 비슷한 패턴을 보여주어, LLM이 언어 간 의미 정렬을 이룬다는 점을 강조했습니다.

- **Technical Details**: 연구에서는 대형 언어 모델의 뉴런이 서로 다른 언어 처리 시 비슷한 활성화 패턴을 보이는데, 이를 통해 특정 언어를 처리하는 뉴런과 주요 언어 영역을 식별할 수 있음을 확인했습니다. LLM의 첫 번째 및 마지막 층에 중요한 언어 뉴런이 집중되어 있으며, 훈련이 진행됨에 따라 이러한 뉴런의 밀도가 증가합니다. 연구는 BLOOM과 LLaMA2 모델을 기반으로 하여 이러한 구조적 진화 과정을 지원하는 실험들을 진행했습니다.

- **Performance Highlights**: 훈련 과정이 진행됨에 따라 주요 언어 영역의 크기가 줄어들고, 의미 정렬이 더욱 두드러지면서 기계의 언어 독립적 처리 성능이 향상되었습니다. 특히, 모델의 크기가 증가할수록 언어 간 활성화 패턴이 더 언어 독립적으로 변화하는 경향이 있으며, 이는 LLM의 잠재 의미 공간을 통해 이루어지는 것으로 설명됩니다.



### MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models (https://arxiv.org/abs/2410.11710)
- **What's New**: MTU-Bench (Multi-Granularity Tool-Use Benchmark)는 대형 언어 모델(LLMs)의 도구 사용 능력을 다양한 상황에서 평가할 수 있도록 설계되었습니다. 기존의 평가 모델들은 한정된 도구 사용 시나리오와 높은 평가 비용 문제를 지적하며, MTU-Bench는 이를 해결합니다.

- **Technical Details**: MTU-Bench는 5개의 도구 사용 장면(단일 턴 및 단일 도구, 단일 턴 및 다중 도구, 다중 턴 및 단일 도구, 다중 턴 및 다중 도구, 출처 분포 외의 작업)을 포괄하며, 모든 평가 메트릭은 예측 결과와 실제 정답을 기반으로 하여 GPT API나 인간 평가자 없이 수행됩니다. MTU-Instruct 데이터셋을 통해 LLM의 도구 사용 능력을 향상시키는 방법도 제안됩니다.

- **Performance Highlights**: MTU-Bench를 통한 실험 결과는 MTU-LLaMA라는 모델이 다양한 시나리오와 메트릭에서 최상의 성능을 보였음을 보여줍니다. 이는 도구 사용 능력에 대한 유용한 통찰을 제공하며, 고급 기능들이 다수 발견되었습니다.



### Magnifier Prompt: Tackling Multimodal Hallucination via Extremely Simple Instructions (https://arxiv.org/abs/2410.11701)
Comments:
          9 pages, 13 tables, 4 figures

- **What's New**: 이 논문에서는 멀티모달 대형 언어 모델(MLLMs)에서 허위 정보(hallucinations)를 줄이기 위해 Magnifier Prompt (MagPrompt)라는 단순하면서도 효과적인 방법을 제안합니다. MagPrompt는 모델이 시각적 정보에 더 집중하도록 유도하며, 이미지와 내부 지식 간의 충돌이 있을 경우 이미지의 우선권을 강조하는 원칙에 기반합니다.

- **Technical Details**: MagPrompt는 훈련 없이 적용 가능하며, GPT-4o 및 Gemini와 같은 오픈소스와 클로즈드소스 모델에 모두 사용할 수 있습니다. 실험 결과, MagPrompt는 다양한 데이터셋에서 효과적으로 작동하며, 복잡한 방법인 VCD와 비교할 때 동등하거나 더 나은 성능을 보입니다. 이 방법은 간단한 지침을 통해 MLLMs의 허위 정보 문제를 해결할 수 있는 가능성을 보여줍니다.

- **Performance Highlights**: 실험에서 MagPrompt는 LLaVA-1.5와 Qwen-VL 모델에서 VCD보다 더 우수한 성능을 발휘했으며, F1 점수 전반에서 유의미한 향상을 기록했습니다. 또한 MagPrompt는 GPT-4o 및 Gemini와 같은 최신 클로즈드소스 모델에서도 적용 가능하여, 기존의 복잡한 방법들이 적용되지 않는 상황에서도 성능 향상을 가져왔습니다.



### IntGrad MT: Eliciting LLMs' Machine Translation Capabilities with Sentence Interpolation and Gradual M (https://arxiv.org/abs/2410.11693)
- **What's New**: 최근 대형 언어 모델(LLMs)은 추가 평행 데이터셋에 대한 미세 조정 없이 번역 작업에서 강력한 성능을 입증했지만, 저자원 언어 쌍에서는 여전히 낮은 성능을 보이고 있습니다. 본 논문에서는 LLM의 고유한 번역 능력을 최대한 활용하는 새로운 방법인 IntGrad MT를 제안하여 이러한 문제를 해결하고자 했습니다.

- **Technical Details**: IntGrad MT는 두 가지 기술인 Sentence Interpolation과 Gradual MT로 구성되어 있습니다. Sentence Interpolation은 간단한 문장을 점진적으로 더 어려운 문장으로 변화시키는 기법이며, Gradual MT는 이전 문장의 번역 결과를 이후 문장의 번역을 위해 몇 개의 샘플로 사용하는 방법입니다. 이 접근 방식을 통해 LLM의 번역 성능을 크게 향상시킬 수 있었습니다.

- **Performance Highlights**: IntGrad MT는 다양한 LLM(GPT-3.5 Turbo, Mistral Nemo Instruct, Llama 3.1 70B Instruct, Llama 3.1 8B Instruct)에 대해 여러 언어(German, Chinese, Hindi, Korean, Swahili, Marathi, Bengali)에서 테스트를 진행하였으며, 그 결과 저자원 언어에서 특히 큰 성과 향상을 보였습니다(Hindi(8.26), Swahili(7.10), Bengali(6.97), Marathi(13.03)).



### Understanding Likelihood Over-optimisation in Direct Alignment Algorithms (https://arxiv.org/abs/2410.11677)
Comments:
          Preprint Version

- **What's New**: 이번 연구에서는 Direct Alignment Algorithms (DAAs)로 알려진 새로운 방법론인 Direct Preference Optimisation (DPO)와 Identity Preference Optimisation (IPO)에서의 completion likelihood와 모델 성능 간의 관계를 탐구하고, 'likelihood over-optimisation'이라는 중요한 문제를 밝혀냈습니다.

- **Technical Details**: Direct Alignment Algorithms는 인간의 선호를 반영하기 위해, gewünschten (desired) 결과를 생성할 가능성을 높이고, 반면에 비선호 결과의 가능성을 줄이도록 설계되었습니다. 하지만, 좋은 결과의 likelihood가 높아도 모델 성능이 반드시 향상되지 않을 수 있으며, 이는 모델의 diversity를 저해하는 Over-Optimisation 현상으로 이어질 수 있습니다. 이 연구에서는 Two key indicators가 제시됩니다: (1) Decreasing Entropy over Top-k Tokens와 (2) Diminishing Top-k Token Probability Mass.

- **Performance Highlights**: 실험 결과, Over-Optimisation의 신뢰할 수 있는 신호를 제공하는 두 가지 지표가 제시되었고, 이를 통해 인간의 선호와의 정렬을 개선하며 성능 저하를 방지할 수 있음을 확인하였습니다.



### Leaving the barn door open for Clever Hans: Simple features predict LLM benchmark answers (https://arxiv.org/abs/2410.11672)
- **What's New**: 이 논문은 AI 벤치마크의 내부 타당성(internal validity)가 중요한 이유와 AI 시스템들이 의도치 않게 벤치마크를 해결하는 방법을 탐구합니다. 'Clever Hans' 효과를 염두에 두고, 최근 LLM(대형 언어 모델) 벤치마크에서 간단한 $n$-grams를 조합하여 레이블(label)을 예측할 수 있는지를 조사합니다.

- **Technical Details**: 연구에서는 단일 및 이중 $n$-grams를 사용하여 다중 선택 형식의 벤치마크에서 정답 레이블을 예측하는 로지스틱 회귀(classifier)를 훈련시킵니다. 이러한 분류기는 벤치마크가 테스트하도록 설계된 능력을 개발할 필요가 없기 때문에, 레이블이 성공적으로 예측될 경우 그 예제가 특정 능력을 사용할 필요 없이 해결될 수 있음을 시사합니다.

- **Performance Highlights**: 여러 벤치마크에서 과거 데이터에 기반한 간단한 분류기가 높은 정확도를 기록하여 내부 타당성이 문제가 될 수 있음을 시사하고, 일부 LLM들이 이와 같은 표면적인 패턴을 활용하여 벤치마크 문제를 해결할 수 있음을 보여줍니다. 또한 LLM의 성능이 벤치마크 데이터의 작고 미세한 변화에 감지된다는 점에 주목하여, 이들이 절차적 능력 대신 얕은 패턴에 의존하고 있다는 우려를 제기합니다.



### Eliciting Textual Descriptions from Representations of Continuous Prompts (https://arxiv.org/abs/2410.11660)
- **What's New**: 이 논문에서는 연속 프롬프트(Continuous prompts) 또는 소프트 프롬프트(Soft prompts)의 해석을 위한 새로운 접근 방식을 제안합니다. 기존의 접근 방식은 개별 프롬프트 토큰을 어휘 공간에 투영하는 것이었으나, 이는 불완전하고 모호한 결과를 가져올 수 있어 신뢰성 문제가 있었습니다. 대신, 본 연구에서는 모델 추론 중에 프롬프트의 표현으로부터 텍스트 설명을 이끌어내는 방법을 제안하였습니다.

- **Technical Details**: 이 연구에서는 Patchscopes 프레임워크(Ghandeharioun et al., 2024)를 활용하여 프롬프트의 표현을 추출하고, 이를 이용해 자연어로 된 작업 설명을 생성하는 InSPEcT(Patchscope)의 개념을 도입합니다. InSPEcT는 타겟 프롬프트에 패치하여 작업 설명을 디코딩하는 방식으로 작동합니다. 이 방식은 기존의 어휘 투영과 달리 프롬프트 길이에 구애받지 않고 자연스럽고 이해하기 쉬운 해석을 제공합니다.

- **Performance Highlights**: InSPEcT를 사용하여 5개의 작업에 대해 학습된 연속 프롬프트의 설명을 생성하였고, 이는 일반적으로 관련된 타겟 작업에 대한 정확한 설명을 산출했습니다. 프롬프트의 성능이 높아질수록, 이끌어낸 설명의 정확성도 증가하는 경향을 보였습니다. Furthermore, InSPEcT의 개선된 버전은 연속 프롬프트에 포함된 편향된 특성을 드러내며, 이러한 특성이 포함될 경우 모델의 예측이 편향되었음을 보여주었습니다.



### Unveiling the Mystery of Visual Attributes of Concrete and Abstract Concepts: Variability, Nearest Neighbors, and Challenging Categories (https://arxiv.org/abs/2410.11657)
- **What's New**: 이번 연구에서는 구체적(concrete)인 개념과 추상적(abstract)인 개념의 시각적 표현의 다양성을 분석하였습니다. 약 1000개의 개념을 포함하는 이미지 데이터셋을 사용하여, 이 두 개념의 시각적 특징에 대한 이해를 증진하고자 하였습니다.

- **Technical Details**: 우리는 Bing과 YFCC에서 추출한 약 1000개의 추상적 및 구체적 개념에 대한 이미지를 활용하였습니다. 이 연구에서는 각 개념에 대한 이미지의 시각적 다양성을 평가하고, 최근접 이웃(nearest neighbor) 분석을 통해 시각적 특징의 변동성을 분석하였으며, 도전 요인을 분류하고 주석을 달았습니다. 연구 결과, ViT(Vision Transformer)보다 색상과 질감과 같은 기본적인 시각적 특징의 조합이 구체적 및 추상적 개념 분류에 더 효과적이라는 것을 발견하였습니다.

- **Performance Highlights**: 이미지 분류 실험에서, 구체적이고 추상적인 개념 간의 시각적 다양성을 성공적으로 구별할 수 있었으며, ViT는 최근접 이웃 분석에서 뛰어난 성능을 보였습니다. 이는 다른 텍스트 이외의 양식으로 개념 변수를 분석할 때 시각적 특징 선택의 신중함을 강조합니다.



### Retrieval Augmented Spelling Correction for E-Commerce Applications (https://arxiv.org/abs/2410.11655)
- **What's New**: 본 논문은 신생 브랜드 이름이 전통적인 철자 교정 시스템에 미치는 영향을 다루며, Retrieval Augmented Generation (RAG) 접근법을 사용하여 전통적인 방법보다 향상된 철자 교정을 보입니다.

- **Technical Details**: Retrieval Augmented Generation (RAG) 방법론을 통해 사용자 쿼리를 제품 카탈로그에서 관련 항목으로 검색하고, 이를 기반으로 Fine-tuning된 대형 언어 모델(LLM)에 컨텍스트를 제공합니다. 실험에 사용된 모델은 Mistral-7B와 Claude-3-sonnet이며, 다양한 검색 방법(BM25, Fuzzy BM25, ColBERT)을 평가했습니다.

- **Performance Highlights**: RAG 기반 접근법은 철자 교정 성능에서 일관된 향상을 보여줍니다. 특히 브랜드 이름이 포함된 쿼리에서 가장 큰 성과를 기록하였고, 레이턴시(혹은 지연 시간)의 증가도 최소화되었습니다.



### Transformer Layer Injection: A Novel Approach for Efficient Upscaling of Large Language Models (https://arxiv.org/abs/2410.11654)
- **What's New**: 본 논문에서는 Transformer Layer Injection (TLI)라는 새로운 기법을 제안합니다. 이 방법은 대규모 언어 모델(LLMs)의 효율적인 업스케일링을 가능하게 하며, 계산 비용을 최소화하면서 모델 성능을 유지합니다.

- **Technical Details**: TLI는 전통적인 Depth Up-Scaling (DUS) 기술을 개선하여 K개의 레이어 세트마다 새로운 레이어를 주입함으로써, transformer 블록을 통과하는 숨겨진 표현에 최소한의 방해로 작동합니다. TLI는 초기 손실을 줄이고, 훈련 단계를 최소화하며, 고정밀도를 강조합니다.

- **Performance Highlights**: TLI는 LLama3의 1B, 3B, 8B 모델에 대한 실험을 통해 초기화 효율성과 데이터 활용에서 MoE 및 DUS보다 우수한 결과를 보였습니다. 이는 훈련 단계 수를 크게 줄이고, KoBEST 및 KMCQA와 같은 작업에서 성능을 향상시키는 것으로 나타났습니다. TLI는 데이터 효율적이고 비용 효과적인 솔루션으로, 최대 405B 매개변수까지의 모델 업스케일링에 적합합니다.



### Measuring Spiritual Values and Bias of Large Language Models (https://arxiv.org/abs/2410.11647)
Comments:
          9 pages including appendix; 5 figures; 5 tables; submitted to ARR - Octobor 2024

- **What's New**: 이번 연구에서는 인기 있는 대형 언어 모델(LLMs)의 영적 가치가 다양하다는 것을 검증하였으며, 이는 세속적이거나 무신론적이라는 기존의 고정관념과는 대조적입니다. 또한, 이러한 다양한 영적 가치가 사회적 공정성 시나리오에서 어떻게 영향을 미치는지 탐구하였습니다.

- **Technical Details**: 연구는 설문지 형식의 영적 가치 평가 도구 두 가지(SP-Typology 및 SP-10Axes)를 사용하여 LLMs의 영적 가치를 측정하였습니다. 평가를 통해 LLMs가 상당히 종교적 경향을 보이며, 특히 종교적 LLM들이 증오 발언 탐지에서 더 좋은 성능을 보이는 것으로 나타났습니다. 추가 실험에서는 종교 문헌에 대한 비지도 학습을 통해 LLM의 성능이 더욱 향상됨을 확인했습니다.

- **Performance Highlights**: LLMs가 다양한 영적 가치를 반영하는 것으로 나타났으며, 이는 모델의 성능에 중요하게 작용합니다. 특히, 더 종교적인 LLM들이 증오 발언을 탐지하는 과제에서 더 높은 성능을 나타냈습니다. 전체적으로, LLMs의 영적 편견을 완화하기 위한 계속된 추가 학습의 효과를 입증했습니다.



### Tokenization and Morphology in Multilingual Language Models: A~Comparative Analysis of mT5 and ByT5 (https://arxiv.org/abs/2410.11627)
- **What's New**: 이 논문은 다국어 언어 모델에서 형태소(morphology) 지식에 대한 토큰화(tokenization)의 영향을 분석합니다. mT5와 ByT5라는 두 다국어 모델의 토큰화 전략을 비교하여 형태소 정보가 어떻게 인코딩되는지를 탐구합니다. 이 연구는 서로 다른 토큰화 전략이 다국어 모델의 형태소 지식 획득에 미치는 영향을 이해하고자 합니다.

- **Technical Details**: 연구에서는 mT5(서브워드 토큰화)와 ByT5(문자 수준 토큰화) 두 모델의 형태소 지식을 프로빙(probing)하여 분석합니다. 17개 언어를 대상으로 메타 분석을 실시하였으며, 특히 중간 및 후층에서 형태소 정보가 인코딩됨을 발견하였습니다. 또한, 언어의 불규칙성 정도가 형태소 지식 획득에 중요한 역할을 한다고 제안합니다.

- **Performance Highlights**: 다국어 언어 모델은 특정 언어의 형태소 시스템을 타 언어보다 더 잘 학습함을 보였으며, 특히 불규칙성이 더 많은 언어는 더 많은 전훈련(pre-training) 데이터 비율의 혜택을 받습니다. 형태소는 표준 토크나이저를 사용하는 모델의 초기 층에서 학습되지만, 문자 기반 모델은 후층에서 유사한 형태소 지식을 발휘합니다.



### Findings of the WMT 2024 Shared Task on Chat Translation (https://arxiv.org/abs/2410.11624)
Comments:
          12 pages, 5 figures, 13 tables

- **What's New**: 이번 논문은 Chat Translation Shared Task의 세 번째 에디션에 대한 발견을 제시하며, 새로운 언어 쌍인 영어-한국어(English-Korean)와 영어-네덜란드어(English-Dutch)가 추가되었습니다. 또한 대화 맥락이 번역 품질에 미치는 영향을 분석하는 데 초점을 맞추었습니다.

- **Technical Details**: 이번 번역 과제는 고객 지원 대화를 번역하는 시스템의 성능을 평가하는 데 중점을 두며, 22개의 주요 제출물 및 32개의 비교 제출물이 있었습니다. 자동화된 메트릭과 인간 평가를 사용하여 각 시스템을 종합적으로 평가하였고, LLMs(대형 언어 모델)가 효과적으로 활용되었습니다.

- **Performance Highlights**: 참여한 모든 시스템과 언어 쌍에서 회화 수준의 번역 품질이 확연히 높은 반면, 후반 대화의 번역과 전체 대화 수준의 개선이 필요함을 보여주었습니다. Unbabel-IT의 제출물이 대부분의 언어 쌍에서 최상의 결과를 달성했습니다.



### Causal Reasoning in Large Language Models: A Knowledge Graph Approach (https://arxiv.org/abs/2410.11588)
Comments:
          Accepted at NeurIPS 2024 Workshop on Causality and Large Models (CaLM)

- **What's New**: 이 논문은 지식 그래프(knowledge graph, KG)를 기반으로 한 무작위 보행(random-walk) 추론 방법을 제안하며, 인과관계(causal relationships)를 활용하여 LLM 성능을 분석합니다.

- **Technical Details**: 지식 그래프는 관련 정보(related information)와 노드 간의 연결을 통해 추론 구조(reasoning structure)를 제공하여 무작위 보행을 수행합니다. 실험은 상식 질문 응답(task)에서 수행되었습니다.

- **Performance Highlights**: 제안된 KG 기반 무작위 보행 추론 방법은 LLM의 추론 능력과 성능을 개선하며, 세 가지 비관련 문장을 쿼리에 포함시키는 것이 기존의 관념과는 달리 LLM 성능을 향상시킵니다. 이러한 결과는 LLM 성능 최적화에서 인과 구조(causal structures)의 통합이 중요한 역할을 할 수 있음을 시사합니다.



### Multi-round jailbreak attack on large language models (https://arxiv.org/abs/2410.11533)
- **What's New**: 본 연구에서는 Large Language Model (LLM)의 jailbreaking 공격을 보다 깊이 이해하기 위해 다단계 jailbreaking 접근 방식을 제안합니다. 이 방법은 위험한 프롬프트를 재작성하고 점진적으로 덜 해로운 하위 질문으로 분해하여 LLM의 안전 점검을 우회할 수 있습니다.

- **Technical Details**: 검증된 결과를 바탕으로, 우리는 Llama3-8B 모델을 사용하여 위험한 질문들을 비위험 하위 질문으로 분리하고, 이 과정에서 LLM이 도출해낸 질문들을 피해 모델에 이어서 묻는 방식을 채택했습니다. 또한, 피해 모델이 하위 질문을 거부하는 경우 새로운 분해 작업을 생성하는 방식을 반복합니다.

- **Performance Highlights**: 실험 결과에 따르면, Llama2-7B 모델에서 94%의 성공률을 기록하여 다단계 jailbreaking 접근 방식의 효과성을 입증했습니다. 이를 통해 정적 규칙 기반 필터를 효과적으로 우회할 수 있음을 보여주었습니다.



### TopoLM: brain-like spatio-functional organization in a topographic language mod (https://arxiv.org/abs/2410.11516)
- **What's New**: TopoLM이라는 새로운 딥러닝 모델이 소개되었으며, 이는 인공지능 언어 모델이 뇌의 언어 시스템과 유사한 스페이셜(topographic) 표현을 사용하는 방법을 보여줍니다.

- **Technical Details**: TopoLM은 transformer 아키텍처에 기반하여 구성되었고, 모델 유닛의 2차원 공간 배치를 포함합니다. 다음 토큰 예측(nnext-token prediction) 목표와 공간 부드러움 손실(spatial smoothness loss)을 결합하여, 텍스트의 의미론적으로 해석 가능한 클러스터를 형성합니다.

- **Performance Highlights**: TopoLM은 언어 처리하는 뇌의 기능적 클러스터가 미세한 언어적 특징에 따라 조직되는 것을 예측하는 데 성공했으며, 브레인 스코어 플랫폼을 이용한 뇌 정렬 벤치마크에서 비슷한 성과를 보였습니다.



### DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG (https://arxiv.org/abs/2410.11494)
Comments:
          EMNLP 2024 Main

- **What's New**: 이 논문에서는 지속적으로 업데이트되는 지식 기반에서 새로운 언어 표현을 해결하는 새로운 작업을 제시합니다. 이를 통해 지식 집합과 함께 작동하는 retrieval-augmented generation (RAG) 시스템의 문제를 다루고 있습니다.

- **Technical Details**: DynamicER 벤치마크를 포함하며, 새로운 표현에 대한 동적 엔티티 언급 해결과 엔티티 중심의 지식 집약형 QA 작업을 평가합니다. 이는 엔티티 링크 및 RAG 모델의 새로운 표현에 대한 적응성을 측정합니다. 기존의 엔티티 링크 모델이 새로운 표현을 엔티티에 연결하는 데 어려움을 겪고 있음을 발견했습니다. 따라서 우리는 시간에 따라 세분화된 클러스터링 방법을 제안하여 진화하는 엔티티와 새로운 언급의 시간 동태를 효과적으로 관리합니다.

- **Performance Highlights**: 광범위한 실험을 통해 제안된 방법이 기존의 기준선보다 더 나은 성능을 보여주며, 해결된 언급을 사용하여 QA 작업의 RAG 모델 성능을 향상시킵니다.



### O-Edit: Orthogonal Subspace Editing for Language Model Sequential Editing (https://arxiv.org/abs/2410.11469)
- **What's New**: 이번 논문에서는 Orthogonal Subspace Editing (O-Edit)이라는 새로운 방법을 제안합니다. 이 방법은 여러 번의 지식 업데이트가 있을 때도 모델 성능 저하를 최소화하면서 연속적인 편집을 가능하게 합니다.

- **Technical Details**: O-Edit는 각 지식 업데이트의 방향을 직교화하여 후속 업데이트 간의 간섭을 최소화하며, 서로 관련 없는 지식에 대한 새로운 업데이트의 영향을 줄입니다. 또한, 이전에 편집된 데이터를 다시 사용하는 필요 없이 각 편집을 시간에 맞게 처리합니다.

- **Performance Highlights**: O-Edit는 주류 LLMs에서 수천 개의 편집을 수행할 수 있으며, 기존 방법보다 평균 성능 개선이 4.2배 더 좋고, 다운스트림 작업에서 모델 성능을 효과적으로 유지하면서 최소한의 추가 파라미터 오버헤드로 작동합니다.



### Mitigating Frequency Bias and Anisotropy in Language Model Pre-Training with Syntactic Smoothing (https://arxiv.org/abs/2410.11462)
- **What's New**: 이 논문에서는 언어 모델의 frequency bias를 정량화하는 방법을 제안하고, 미세 조정을 통해 이 bias를 줄이는 새로운 기법인 Syntactic Smoothing을 소개합니다. 이 방법은 유사한 문법적 특성을 가진 단어들 사이에서 학습 신호를 분산시킴으로써 드문 단어들의 표현력을 개선합니다.

- **Technical Details**: Syntactic Smoothing 방법은 토큰의 표현을 동기화하기 위해 part-of-speech (POS) 태그 분포를 기반으로 한 유사성 메트릭을 사용합니다. 최대 우도(maximum likelihood) 극대화 목표 함수를 조정하여 문법적으로 유사한 토큰에게 학습 신호를 분산시킵니다.

- **Performance Highlights**: 이 방법은 드문 영어 토큰에서의 성능을 개선하고, anisotropy를 감소시키는 결과를 보였습니다. 특히, 모델의 anisotropy 정도는 frequency bias와 상관관계가 있으며, 이를 통해 언어 모델의 전반적인 성능 향상을 확인할 수 있었습니다.



### Jigsaw Puzzles: Splitting Harmful Questions to Jailbreak Large Language Models (https://arxiv.org/abs/2410.11459)
- **What's New**: 이 논문에서는 Jigsaw Puzzles (JSP)라는 새로운 다중 회전( multi-turn ) jailbreak 전략을 제안합니다. 이 전략은 복잡한 질문을 해소하는 LLM의 능력을 이용하면서도, 기존의 방어 메커니즘을 우회하는 방법을 보여줍니다.

- **Technical Details**: JSP는 질문을 무해한 조각으로 나누고, 각 회전에서 LLM이 이 조각들을 재구성하고 응답하도록 요청합니다. 이 과정을 통해 모델의 약점을 노출시키고, 다중 회전 대화에서의 공격 가능성을 탐구합니다. 실험 결과 JSP는 5가지의 고급 LLM (Gemini-1.5-Pro, Llama-3.1-70B, GPT-4, GPT-4o, GPT-4o-mini)에서 189개의 유해한 질문에 대해 평균 93.76%의 공격 성공률을 기록했습니다.

- **Performance Highlights**: JSP는 GPT-4의 유해 질의 벤치마크에서 92%의 최신 공격 성공률을 달성하였고, 방어 전략에 대해 강력한 저항력을 보여줍니다.



### Tending Towards Stability: Convergence Challenges in Small Language Models (https://arxiv.org/abs/2410.11451)
- **What's New**: 이번 연구는 언어 모델의 파라미터 수를 늘리는 것이 성능 향상에 효과적이라는 주장을 다룹니다. 그러나 소형 언어 모델이 운영 비용이 낮음에도 불구하고 대형 모델에 비해 성능이 저하되는 이유에 대한 명확한 원인을 분석합니다.

- **Technical Details**: 연구에서는 Pythia 모델 스위트를 사용하여 다양한 모델 크기에서 Attention과 MLP 활성화의 수렴(convergence) 동력을 분석합니다. 특히, 각 층(layer)의 효과적인 차원(rank)이 이 과정에 미치는 영향을 조사하였습니다.

- **Performance Highlights**: 대형 모델의 경우 훈련 초기 (첫 20%)에 거의 모든 층이 안정화되는 반면, 소형 모델은 파라미터의 효과적인 차원이 낮을 때 느리고 불안정한 수렴 양상을 보입니다. 이 연구는 소형 모델의 학습 동역학(learning dynamics)에서 비효율성을 해결하는 데 있어 방향을 제시할 수 있습니다.



### A Cross-Lingual Statutory Article Retrieval Dataset for Taiwan Legal Studies (https://arxiv.org/abs/2410.11450)
- **What's New**: 이 논문은 다국어 환경에서 법률 정보 검색을 향상시키기 위해 설계된 cross-lingual statutory article retrieval (SAR) 데이터셋을 소개합니다.

- **Technical Details**: 이 데이터셋은 영어로 된 구술 언어 스타일의 법률 질문과 그에 상응하는 중국어 버전 및 관련 법령을 포함하고 있으며, 대만의 모든 민사, 형사 및 행정법을 다룹니다. 또한 번역 오류를 완화하고 cross-lingual retrieval 성능을 개선하기 위한 여러 LLM 기반 방법을 제안합니다.

- **Performance Highlights**: 이 연구는 비원어민, 특히 대만의 외국인들이 법률 정보에 접근할 수 있도록 지원하는 중요한 자원으로, 포괄적인 법률 정보 검색 시스템 개발에 기여할 것입니다.



### AIC CTU system at AVeriTeC: Re-framing automated fact-checking as a simple RAG task (https://arxiv.org/abs/2410.11446)
- **What's New**: 이 논문은 AVeriTeC 공유 과제에서의 3위 제출 결과를 설명합니다. 우리는 Retrieval-Augmented Generation (RAG) 방식을 간단히 설계하여 실제 데이터를 활용한 사실 확인의 도전을 해결하고자 했습니다.

- **Technical Details**: 논문은 두 개의 모듈, 즉 Retriever와 Evidence & Label generator의 상세한 설명을 제공합니다. MMR-reranking 및 Likert-scale confidence estimation과 같은 기능을 정당화합니다.

- **Performance Highlights**: AVeriTeC 개발 및 테스트 세트에서 우리의 솔루션을 평가하였고, 결과를 해석하였습니다. GPT-4o가 우리의 파이프라인에 가장 적합한 모델로 선정되었으며, Llama 3.1 70B는 유망한 오픈소스 대안으로 주목받고 있습니다. 또한, 예측의 오류 분석을 수행하여 데이터의 잡음이나 모호한 사실 확인과 관련된 과오를 발견하였습니다.



### Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs (https://arxiv.org/abs/2410.11437)
Comments:
          EMNLP 2024 Findings

- **What's New**: 본 논문에서는 멀티모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)의 시각적 질문-응답(Visual Question Answering, VQA) 문제에서 모델의 게으름(model laziness) 현상을 분석합니다. 특히, 이러한 모델이 쉬운 질문에는 오류를 범하는 경향이 있음을 밝히고 있습니다.

- **Technical Details**: 모델의 게으름을 체계적으로 조사하기 위해 LazyBench라는 벤치마크를 수동으로 구축하였으며, 이에는 예/아니오 질문, 다중 선택, 단답형 질문 및 이미지 설명 작업이 포함됩니다. LazyBench를 기반으로 한 분석 결과, 최신 MLLM 모델들(GPT-4o, Gemini-1.5-pro, Claude 3, LLaVA-v1.5-13B)에서 게으름 현상이 널리 존재하며, 이는 성능이 더 높은 모델에서 더욱 두드러지게 나타납니다.

- **Performance Highlights**: VQA v2(LLaVA-v1.5-13B) 벤치마크 분석 결과에서 약 절반의 실패 사례가 모델의 게으름으로 인해 발생한다는 것을 발견하였습니다. 이러한 결과는 모델이 자신의 능력을 충분히 활용할 수 있도록 보장하는 것이 중요함을 강조합니다. 게으름 현상을 완화하기 위한 초기 탐색을 통해 사고의 연쇄(chain of thought, CoT) 기법이 이 문제를 효과적으로 해결할 수 있음을 발견하였습니다.



### Titanic Calling: Low Bandwidth Video Conference from the Titanic Wreck (https://arxiv.org/abs/2410.11434)
- **What's New**: 2022년 여름, 타이타닉 잔해 탐사 중 진행된 통신 실험에 관한 결과를 보고합니다. 이 연구는 깊은 해양에서의 음성 인식 및 텍스트 전송을 통한 커뮤니케이션 시스템의 발전을 보여줍니다.

- **Technical Details**: 해양 심층에서의 통신은 라디오 전송이 불가능하며, 따라서 sonar 신호를 기반으로 합니다. 본 시스템은 음성을 텍스트로 변환한 후, 텍스트 메시지를 수면으로 전송하고, 이를 합성된 입술 동기화 비디오로 재구성합니다. 낮은 대역폭의 sonar 신호 때문의 메시지 전송 한계에도 불구하고, 시스템은 효과적으로 작동하였습니다.

- **Performance Highlights**: 실제 타이타닉 탐사 중 시스템을 테스트하였고, 복잡한 시스템에도 불구하고 수용 가능한 지연(latency)과 우수한 품질을 달성하였습니다. 시스템 시연 비디오는 링크를 통해 제공됩니다.



### ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability (https://arxiv.org/abs/2410.11414)
Comments:
          23pages

- **What's New**: 본 논문에서는 RAG 모델에서의 환각(hallucination) 메커니즘을 심도 있게 분석하고, ReDeEP라는 새로운 환각 탐지 방법을 제안합니다.

- **Technical Details**: RAG 모델은 외부 지식을 결합하여 파라메트릭(내부) 지식이 부족할 때 발생하는 환각을 줄이기 위해 설계되었습니다. 본 논문에서는 LLM의 Knowledge FFN과 Copying Heads가 각각 외부 및 내부 지식을 어떻게 활용하는지에 대한 연구를 통해, 환각이 어떻게 발생하는지를 조사하였습니다.

- **Performance Highlights**: ReDeEP를 통해 환각 탐지 정확도가 크게 향상되었으며, AARF는 Knowledge FFN과 Copying Heads의 기여를 조절하여 환각을 완화하는 데 성공했습니다.



### PMMT: Preference Alignment in Multilingual Machine Translation via LLM Distillation (https://arxiv.org/abs/2410.11410)
- **What's New**: 이 논문은 대규모 다국어 평행 말뭉치를 생성하는 새로운 방법을 제안하며, 이는 특정 번역 선호도에 맞추어져 있습니다. 기존의 번역 방법들이 주로 정확성에 집중한 반면, 인간의 표현 선호를 반영하는 데에는 소홀했던 문제를 해결하고자 합니다.

- **Technical Details**: 제안된 방법은 두 단계로 구성됩니다: 먼저, 여러 번역 자원을 활용하여 소규모 시드 데이터셋을 구축합니다. 이후, 이 시드 데이터를 기반으로 번역 LLM (Large Language Model)을 훈련하여 새로운 소스 텍스트로부터 후보 번역을 생성합니다. 그 다음, 작은 맞춤형 데이터셋을 이용하여 인간의 선호도에 맞은 보상 모델(RM)을 훈련시키고, 후보 번역을 선택하는 데 사용합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 특정 인간 선호가 반영된 번역 작업에서 큰 차이로 성과를 나타내었으며, WMT와 Flores와 같은 공용 벤치마크에서도 경쟁력 있는 성능을 보였습니다. 이는 사용자 맞춤형 번역 요구를 만족시키는 데에서 큰 가능성을 나타냅니다.



### Do LLMs Have the Generalization Ability in Conducting Causal Inference? (https://arxiv.org/abs/2410.11385)
- **What's New**: 본 논문은 대규모 언어 모델(LLM)의 인과 추론(generalization capability)에서의 일반화 능력을 평가하기 위한 새로운 벤치마크 생성 프레임워크를 제안합니다. 이전에 볼 수 없었던 현상에 대한 인과 관계 추론의 성능을 측정하는 데 중점을 두었습니다.

- **Technical Details**: 연구에서는 Causal Path Discovery (CP), Backdoor Adjustment (BA), Factual Inference (FI), Counterfactual Inference (CI) 네 가지 인과 추론 작업을 선택하여 이들의 일반화 능력을 평가했습니다. 무작위로 생성된 그래프와 노드 이름을 사용하여 새롭고 가상의 인과 시나리오를 만드는 벤치마크를 구축했습니다.

- **Performance Highlights**: 실험 결과, LLM은 간단한 CP, FI 및 복잡한 CI 질문의 해결에서 좋은 일반화 성능을 보였지만, BA 질문에서는 어려움을 겪었고 문제 복잡도가 증가함에 따라 성능의 변동이 뚜렷하게 나타났습니다. 초기 성과는 좋으나 새로운 연구 맥락에서 인과 추론의 성능은 여전히 한계가 있습니다.



### Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL (https://arxiv.org/abs/2410.11371)
Comments:
          Accepted to EMNLP2024 Findings

- **What's New**: 이 논문은 Large Language Models (LLMs)을 이용한 text-to-SQL 변환에서 발생하는 성능과 효율성 간의 균형 문제를 해결하기 위해 새로운 방법인 KID (Knowledge Distillation with Imperfect Data)를 제안합니다.

- **Technical Details**: KID는 지식 증류(knowledge distillation) 기술을 기반으로 하여, 대형 teacher 모델의 지식을 소형 student 모델에 전이합니다. KID의 핵심은 불완전한 데이터(imperfect data)를 사용하여 학습-추론 간의 불일치를 효과적으로 완화하는 것입니다.

- **Performance Highlights**: KID는 5개의 text-to-SQL 벤치마크에서 평균 5.83% 성능 향상을 달성하며, 다양한 모델 유형과 크기에서 일관되고 의미 있는 개선 효과를 보입니다.



### Enhance Graph Alignment for Large Language Models (https://arxiv.org/abs/2410.11370)
Comments:
          Under review

- **What's New**: 본 연구에서는 Graph Alignment Large Language Models (GALLM)를 제안하여 LLM이 그래프 데이터를 더 잘 이해하고 사용할 수 있도록 합니다. 새로운 자기지도 학습 방식과 템플릿 정렬을 통해 성능을 개선합니다.

- **Technical Details**: GALLM은 크게 두 가지 단계로 구성됩니다: 첫 번째는 자기지도 조정(self-supervised tuning) 단계로, 텍스트 일치(task) 작업을 통해 LLM을 훈련시킵니다. 두 번째는 작업 특정 조정(task-specific tuning) 단계로, 추가적인 설명과 정렬된 템플릿을 통해 감독 정보를 활용하여 두 가지 범주 프롬프트 방법을 제시합니다.

- **Performance Highlights**: 여러 데이터셋에 대한 실험 평가 결과, 감독 학습(supervised learning), 멀티 데이터셋 일반화(multi-dataset generalizability), 특히 제로샷 능력(zero-shot capability)에서 상당한 성과 개선이 있음을 보여주었습니다.



### LargePiG: Your Large Language Model is Secretly a Pointer Generator (https://arxiv.org/abs/2410.11366)
Comments:
          24 pages

- **What's New**: 이번 연구에서는 대형 언어 모델(LLMs) 기반 쿼리 생성에서 발생하는 환각 문제를 다루기 위해 relevance hallucination과 factuality hallucination이라는 새로운 유형을 도입하였습니다. 이를 통해 LLM에서 생성된 쿼리의 내용과 형식을 효과적으로 분리하는 기법을 제안합니다.

- **Technical Details**: 우리는 LLM을 포인터 생성기(Pointer-Generator, PG)로 변환하는 새로운 접근 방식을 제안합니다. 이 방법은 LLM의 내재적 주의(attention) 가중치를 활용하여 포인터 주의 분포를 생성하고, 모델의 상위 층과 마지막 층의 어휘 분포 차이를 기반으로 복사 확률을 도출합니다. 이러한 방식을 통해 우리는 훈련 없이도 PG 기능을 구현할 수 있습니다.

- **Performance Highlights**: LargePiG는 TruthfulVQG와 TruthfulDQG라는 두 가지 데이터셋에서 효과성을 입증하였으며, 다양한 LLM 기반의 쿼리 생성 방법에서 사실성과 관련성을 향상시켰습니다. 추가 실험을 통해 대형 비전 언어 모델에서 환각 문제를 줄이고 문서 기반 질문 응답과 사실성 평가 과제의 정확성을 개선할 수 있음을 보여주었습니다.



### RATE: Score Reward Models with Imperfect Rewrites of Rewrites (https://arxiv.org/abs/2410.11348)
Comments:
          Submitted as a conference paper to ICLR 2025. Code is available at this https URL

- **What's New**: 이 논문은 언어 모델링에서 사용되는 보상 모델의 평가 방법인 RATE(Rewrite-based Attribute Treatment Estimators)를 개발했습니다. 이 방법은 응답의 특정 속성이 보상에 미치는 인과관계를 측정할 수 있게 해줍니다.

- **Technical Details**: RATE는 큰 언어 모델을 사용하여 응답을 재작성(rewrite)하고, 재작성 오류를 보정하기 위해 두 번 재작성하는 방식을 사용합니다. 이 방법은 비대칭 재작성에서도 신뢰할 수 있는 인과적인 보상 변화를 추정할 수 있습니다.

- **Performance Highlights**: RATE 평가 방법은 합성 및 실제 데이터에서 효과적임을 보여줍니다. 이 방법은 비인과성 상관관계를 교정할 수 있고, 보상 모델을 평가할 때 이러한 교정이 중요함을 실증적으로 입증했습니다.



### SHAKTI: A 2.5 Billion Parameter Small Language Model Optimized for Edge AI and Low-Resource Environments (https://arxiv.org/abs/2410.11331)
Comments:
          Paper in pdf format is 11 pages and contains 4 tables

- **What's New**: Shakti는 25억 개의 매개변수를 가진 언어 모델로, 스마트폰, 웨어러블 기기 및 IoT 시스템과 같은 자원 제약 환경에서 최적화되어 있습니다. 이 모델은 높은 효율성과 정밀도를 갖춘 NLP를 결합하여 실시간 AI 애플리케이션에 적합하며, 다양한 언어와 도메인 특정 작업을 지원합니다.

- **Technical Details**: Shakti는 Variable Grouped Query Attention (VGQA)이라는 기술 혁신을 도입하여 메모리 사용량을 줄이고 추론 시간을 단축합니다. 또한, Pre-normalization과 SwiGLU 활성화 함수를 사용하여 훈련 과정을 안정화하고, Rotary Positional Embeddings (RoPE)를 통합하여 긴 텍스트 시퀀스를 처리할 수 있게 합니다.

- **Performance Highlights**: Shakti는 벤치마크 평가에서 더 큰 모델들과 비교하여 경쟁력 있는 성능을 보이며, 낮은 대기 시간과 높은 장치 내 효율성을 유지합니다. 또한, 특히 헬스케어, 금융 및 고객 서비스와 같은 산업에서 실시간 AI 솔루션을 제공하는 데 이상적입니다.



### Speculative Knowledge Distillation: Bridging the Teacher-Student Gap Through Interleaved Sampling (https://arxiv.org/abs/2410.11325)
- **What's New**: 최근의 연구에서 Knowledge Distillation (KB) 기술이 작고 효율적인 모델들이 대형 모델과 유사한 성능을 낼 수 있도록 발전했습니다. 본 논문에서는 Speculative Knowledge Distillation (SKD)라는 새로운 방식을 제안합니다. SKD는 학생 모델과 교사 모델 간의 협력을 통해 고품질의 훈련 데이터를 실시간으로 생성하는 방식을 사용합니다.

- **Technical Details**: SKD는 학생 모델이 제안하는 토큰에서 품질이 낮은 것을 교사 모델의 분포에 근거하여 교체하는 프로세스를 가지고 있습니다. 이 방법은 교사 모델이 생성할 가능성이 낮은 토큰을 필터링하고, 대신 교사 모델에서 재 샘플링하는 방식을 사용합니다. SKD는 초기 훈련 단계에서는 기존의 Supervised KD와 유사하게 작동하다가, 학생 모델의 성능이 향상됨에 따라 On-policy KD와 비슷한 방식으로 동작합니다.

- **Performance Highlights**: SKD는 다양한 텍스트 생성 작업에서 기존의 KD 방법들보다 뛰어난 성능을 보였습니다. 예를 들어, Gemma-7B를 Gemma-2B로 증류하는 과정에서 저자원 기계 번역에서 41.8%, 요약에서 230%, 산술적 추론에서 160%의 성능 향상을 기록했습니다. 또한, SKD가 MATH 및 GSMplus 테스트에서 각각 198% 및 360%의 성과를 달성했습니다.



### Self-adaptive Multimodal Retrieval-Augmented Generation (https://arxiv.org/abs/2410.11321)
- **What's New**: 이번 연구에서는 Self-adaptive Multimodal Retrieval-Augmented Generation (SAM-RAG)이라는 새로운 접근 방식을 제안합니다. 기존의 RAG 방법이 고정된 수의 문서에 의존하는 한계를 극복하고, 입력 쿼리에 따라 동적으로 관련 문서를 필터링하며, 생성된 응답과 검색된 문서의 품질을 검증하는 기능을 포함하고 있습니다.

- **Technical Details**: SAM-RAG는 query에 대한 관련 데이터를 능동적으로 선택하고, 여러 관점에서 생성된 응답을 검증하는 멀티모달 RAG 프레임워크입니다. 이 프레임워크는 relevance, usefulness, support의 세 가지 기준을 정의하고 이를 바탕으로 검색 결과를 평가하여 응답을 생성합니다. 또한, 상태-of-the-art 모델에서 지식을 증류하여 성능을 보장합니다.

- **Performance Highlights**: SAM-RAG는 기존의 최첨단 모델들, 특히 MuRAG에 비해 멀티모달 RAG 작업에서 뛰어난 성능을 보입니다. 실험 및 ablation 연구를 통해 SAM-RAG의 동적 검색 메커니즘이 성과 향상에 미치는 중요성을 강조하며, 각 검증이 검색 정확도 및 응답 품질을 어떻게 개선하는지에 대한 사례 연구를 제시합니다.



### SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation (https://arxiv.org/abs/2410.11315)
Comments:
          15 pages, 6 figures, 5 tables. Accepted by EMNLP 2024 (main)

- **What's New**: 이 논문에서는 Retrieval-Augmented Generation (RAG)에서 성능을 향상시키기 위해 모델 기반의 증거 추출 학습 프레임워크 SEER를 제안합니다. 기존의 휴리스틱(heuristic) 기반 방법의 여러 문제를 해결하고자 하며, 이 프레임워크는 자기 정렬(self-aligned) 학습을 통해 증거를 최적화하는 것을 목표로 합니다.

- **Technical Details**: SEER는 세 가지 주요 단계로 구성됩니다: (1) 증거 추출: 의미적 일관성과 다양한 길이의 증거를 샘플링하여 추출합니다. (2) 전문가 평가: 쿼리, 답변, 구절 및 증거로 구성된 4중 항목 QuadQARE를 사용하여 각 증거의 품질을 평가합니다. (3) 자기 정렬: 추출된 증거의 순위 목록에 따라 최적화 작업을 수행합니다.

- **Performance Highlights**: 광범위한 실험을 통해 SEER는 RAG 성능을 크게 개선하고, 추출된 증거의 신뢰성(faithfulness), 유용성(helpfulness), 응축성(conciseness)을 향상시키며, 증거의 길이를 9.25배 줄이는 성과를 보였습니다.



### Enhancing Assamese NLP Capabilities: Introducing a Centralized Dataset Repository (https://arxiv.org/abs/2410.11291)
Comments:
          6 pages, 1 table, 1 figure

- **What's New**: 이 논문은 저자들이 아삼어(NLT) 및 NMT(Natural Machine Translation)를 위한 중앙집중식 오픈 소스 데이터셋 저장소를 설계하여 소개합니다. 이 저장소는 GitHub에서 제공되며, 감정 분석(sentiment analysis), 개체 인식(named entity recognition), 기계 번역 등의 다양한 작업을 지원합니다.

- **Technical Details**: 이 데이터셋은 두 가지 유형으로 나뉘며, 사전 훈련(pre-training) 및 후 훈련(post-training)에 사용되는 코퍼스가 포함되어 있습니다. 예를 들어, Wikipedia 데이터셋, CC100 코퍼스, C4 다국어 데이터셋 등을 포함하고 있으며, 이들은 아삼어 모델 훈련에 도용될 수 있습니다. 또한, ChatGPT에 의해 생성된 데이터셋도 포함되어 있습니다.

- **Performance Highlights**: 이 저장소는 아삼어 연구에 있어 협업과 혁신을 촉진합니다. 향후 연구는 NMT 모델에 대한 새로운 응용 프로그램, 이미지 캡셔닝(image captioning), AI 기반 챗봇 개발 등을 포함할 수 있습니다. 데이터의 제한 사항에도 불구하고, 아삼어에 대한 NLP 연구의 디지털 시대에서의 지속 가능성을 보여줍니다.



### Process Reward Model with Q-Value Rankings (https://arxiv.org/abs/2410.11287)
- **What's New**: 본 논문에서는 기존의 Process Reward Modeling (PRM) 방식을 개선하기 위해 Process Q-value Model (PQM)이라는 새로운 프레임워크를 제안합니다. PQM은 Q-value 순위 매기기 문제로 PRM을 재정의하고, 각 단계 간의 상호 의존성을 보다 효과적으로 캡처합니다.

- **Technical Details**: PQM 모델은 Markov Decision Process (MDP) 맥락에서 PRM을 최적화하며, 새로운 비교 손실 함수(comparative loss function)를 기반으로 Q-value 순위를 최적화합니다. 이로 인해 각 단계의 기여도를 보다 세분화하여 평가할 수 있게 됩니다.

- **Performance Highlights**: PQM은 다양한 샘플링 정책(sampling policies), 언어 모델 백본(language model backbones), 그리고 다단계 추론(multi-step reasoning) 벤치마크에서 기존의 분류 기반 PRM에 비해 우수한 성능을 보였습니다. 예를 들어, Llama-3-70B-Instruct 모델에서 샘플링한 솔루션의 정확도가 39.8%에서 51.4%로 개선되었으며, 이는 MATH500 벤치마크에서 직접적인 11.6% 향상을 나타냅니다.



### Cognitive Overload Attack:Prompt Injection for Long Contex (https://arxiv.org/abs/2410.11272)
Comments:
          40 pages, 31 Figures

- **What's New**: 이번 논문에서는 대규모 언어 모델(LLMs)의 In-Context Learning (ICL) 개념을 인지 신경 과학의 관점에서 재해석하였으며, 인간 인지에서의 학습 과정과 ICL 간의 유사성을 강조하였습니다. 이를 통해 LLMs가 인지 과부하(cognitive overload)를 경험할 수 있음을 경험적으로 검증하고, 이러한 현상을 악용하여 LLMs를 jailbreaking할 수 있는 공격 기법을 제안하였습니다.

- **Technical Details**: 논문에서는 Cognitive Load Theory (CLT) 원리를 기반으로 LLMs의 ICL을 분석하였으며, LLMs에서의 인지 과부하가 모델의 성능에 미치는 영향을 실험적으로 검증하였습니다. 실험 결과, LLMs는 인지 과부하 상태에 놓일 경우 성능 저하가 발생하며, 이를 통해 공격자가 LLM의 안전 메커니즘을 우회할 수 있는 방향으로 ICL을 조작할 수 있음을 보여주었습니다.

- **Performance Highlights**: 고급 모델들(GPT-4, Claude-3.5 Sonnet, 등)은 인지 과부하 공격에 대해 최대 99.99%의 공격 성공률을 기록하였으며, 이러한 공격 방식은 다양한 LLMs에 전이 가능하다는 것을 입증하였습니다. 이는 LLMs의 구조적 취약점을 드러내며, 악의적인 공격으로부터 방어하기 위한 강력한 방안이 필요함을 강조합니다.



### In-Context Learning for Long-Context Sentiment Analysis on Infrastructure Project Opinions (https://arxiv.org/abs/2410.11265)
- **What's New**: 이번 연구는 GPT-4o, Claude 3.5 Sonnet, Gemini 1.5 Pro 등 세 가지 주요 대형 언어 모델(LLMs)의 성능을 장기적이고 복잡한 의견이 상이한 문서에 대해 평가하였습니다.

- **Technical Details**: 연구에서는 제로샷(zero-shot)과 몇 샷(few-shot) 시나리오에서 인프라 프로젝트와 관련된 긴 문서들을 분석했습니다. 각 모델의 성능을 비교하는 데 있어 다양한 문서의 복잡성과 감정의 변동성을 고려했습니다.

- **Performance Highlights**: 결과적으로 GPT-4o는 간단하고 짧은 문서에서 제로샷 시나리오에서 뛰어난 성능을 보였으나, Claude 3.5 Sonnet는 복잡한 문서와 감정 변동이 있는 상황에서 더 우수한 성능을 나타냈습니다. 몇 샷 시나리오에서는 Claude 3.5 Sonnet이 전반적으로 뛰어난 성과를 보였고, GPT-4o는 시연 횟수가 증가함에 따라 더 큰 안정성을 보였습니다.



### HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications (https://arxiv.org/abs/2410.11239)
- **What's New**: 이 논문에서는 HR 관련 수백 개의 반복적 프로세스를 자동화하기 위해 HR-Agent라는 HR 전용 LLM(대형 언어 모델) 기반 대화 시스템을 개발했다고 보고하고 있습니다. 이 시스템은 의료 청구, 접근 요청과 같은 HR 프로세스의 효율성을 높일 수 있도록 설계되었습니다.

- **Technical Details**: HR-Agent는 대화 상태 추적(DST) 기술을 활용하여 대화 중 사용자 의도 및 세부 사항을 모니터링하고 예측합니다. 이 시스템은 신속한 응답 시간, 신뢰성 있는 정보 추출, 다양한 HR 용도 처리, 기밀성 유지 및 HR 특화의 요구 사항을 충족합니다. 대화 데이터는 추론 과정 중 LLM으로 전송되지 않아 기밀성이 유지됩니다.

- **Performance Highlights**: HR-Agent는 더 큰 언어 모델과 비교하여 더 작고 빠르면서도 뛰어난 성능을 발휘합니다. 이 시스템은 휴먼 리소스 프로세스의 효율성을 크게 향상시킵니다.



### Unleashing the Power of LLMs as Multi-Modal Encoders for Text and Graph-Structured Data (https://arxiv.org/abs/2410.11235)
- **What's New**: 이번 논문에서는 Janus라는 새로운 프레임워크를 제안하여 대형 언어 모델(LLM)을 활용해 텍스트와 그래프 데이터를 공동으로 인코딩하는 방법을 소개합니다. 이 방법은 그래프 임베딩을 텍스트 임베딩과 동일한 공간으로 투영하여 두 가지 모달리티를 함께 처리할 수 있도록 합니다.

- **Technical Details**: Janus는 다층 퍼셉트론(MLP) 어댑터를 사용하여 그래프 임베딩을 텍스트 임베딩 공간으로 변환하며, 대조 학습(contrastive learning)을 통해 그래프와 텍스트 공간을 효과적으로 정렬합니다. 이것은 두 모달리티의 통합을 최적화하여 더 나은 조합 표현을 학습할 수 있게 합니다.

- **Performance Highlights**: Janus는 지식 그래프(Contextualized Knowledge Graph) 질의 응답(QA) 작업, 그래프-텍스트 쌍 분류, 검색 작업 등에 대해 총 6개의 데이터셋에서 실험을 진행하여 기존 방법들보다 뛰어난 성능을 보였습니다. 특히 QA 작업에서는 최대 11.4%의 개선을 달성했습니다.



### "Is Hate Lost in Translation?": Evaluation of Multilingual LGBTQIA+ Hate Speech Detection (https://arxiv.org/abs/2410.11230)
Comments:
          Under review

- **What's New**: 이번 연구는 여러 언어(영어, 이탈리아어, 중국어, 코드 스위칭된 영어-타밀)를 포함하여 LGBTQIA+에 대한 혐오 발언 탐지의 도전과제를 다루고 있습니다. 기계 번역의 영향을 조사하고, 혐오 발언이 번역 과정에서도 잘 보존되는지를 검토했습니다.

- **Technical Details**: 본 연구는 영어, 이탈리아어, 중국어 및 영어-타밀(코드 혼합)이라는 레이블이 붙은 데이터세트를 이용하여 LGBTQIA+ 특화 혐오 발언을 분류합니다. 저희는 LLM(large language model)을 사용하여 제로샷 분류를 수행하고, 번역 후 영어로 다시 분류를 진행했습니다.

- **Performance Highlights**: 모델 성능은 영어에서 가장 높았으며, 영어-타밀의 코드 스위칭 시나리오에서 가장 낮았습니다. 파인튜닝을 통해 모든 언어의 성능이 일관되게 향상되었으나, 번역의 경우 혼합된 결과를 나타냅니다. 영어의 F1 스코어는 0.7952로 가장 높았고, 영어-타밀은 0.3619로 가장 낮았습니다.



### On the Capacity of Citation Generation by Large Language Models (https://arxiv.org/abs/2410.11217)
Comments:
          Accepted by CCIR 2024

- **What's New**: 이번 연구는 대형 언어 모델(LLMs)이 생성하는 응답 내 인용 생성 능력에 대한 체계적 분석을 실시하고, 인용 품질을 향상시키기 위한 새로운 방법을 제시합니다. 주된 초점은 기존 연구들이 응답의 정확성을 높이는 데 집중했던 것과 달리, 정확한 출처 귀속 기능을 개선하는 것입니다.

- **Technical Details**: 연구에서 사용한 두 가지 기본 방법은 few-shot 및 fine-tuning입니다. 인용 품질 향상을 위해 Generate-then-Refine 방법을 제안하며, 이는 관련 인용을 추가하고 불필요한 인용을 제거하여 응답 텍스트를 변경하지 않고 인용 품질을 개선하는 방식을 포함합니다. 또한, 새로운 인용 평가 메트릭도 도입하여 기존 메트릭에서 불필요한 인용에 대한 과도한 처벌을 배제합니다.

- **Performance Highlights**: WebGLM-QA, ASQA, ELI5 데이터셋에서 실험한 결과, 제시된 방법이 LLMs에 의해 생성된 응답의 인용 품질을 상당히 향상시키는 것으로 나타났습니다. 연구의 주요 기여는 LLM이 생성하는 인용 분석, 인용 품질 평가를 위한 보다 포괄적인 메트릭 제안, 그리고 인용 품질을 대폭 향상시키는 Generate-then-Refine 접근법을 제시한 것입니다.



### Sampling Strategies for Creation of a Benchmark for Dialectal Sentiment Classification (https://arxiv.org/abs/2410.11216)
Comments:
          Under review

- **What's New**: 본 논문은 영어로 작성된 Google Places 리뷰의 방언적 감정 분류를 위한 벤치마크를 만들기 위한 데이터 샘플링 전략을 조사합니다. 호주(호주 영어), 인도(인도 영어), 영국(영국 영어) 리뷰들로부터 자가 감독 데이터셋을 수집하며, 이 데이터는 자가 감독 감정 라벨(1성에서 5성에 해당)을 포함합니다.

- **Technical Details**: 연구는 라벨 의미론, 리뷰 길이 및 감정 비율을 기반으로 한 샘플링 기술을 사용하여 세 가지 세분화된 BERT 기반 모델에서 성능을 보고합니다. 연구는 Google Places 리뷰 데이터에서 방언 데이터를 수집하고 자가 감독을 사용하여 다단계 라벨을 할당하는 방법을 제시합니다.

- **Performance Highlights**: 우리는 다양한 데이터 샘플링 기술을 적용하여 효과적이고 도전적인 벤치마크 데이터셋을 구성하였으며, 이 방언 데이터에 대한 모델 성능 종합 평가에서 통찰을 제공합니다. 평가 결과는 호주 영어 및 영국 영어와 같은 내圈 방언뿐만 아니라 인도 영어와 같은 비원주 방언을 위한 도전적인 시나리오를 강조합니다.



### Athena: Retrieval-augmented Legal Judgment Prediction with Large Language Models (https://arxiv.org/abs/2410.11195)
Comments:
          13 pages, 6 figures

- **What's New**: 최근 ChatGPT, LLaMA 및 Claude와 같은 대형 언어 모델(LLMs)이 법률 분야를 포함한 여러 도메인에서 두각을 나타내고 있습니다. 이에 따라 LLM과 실제 응용 프로그램 간의 인터페이스로서 프롬프트 엔지니어링(prompt engineering, PE)의 발전이 주목받고 있습니다. 본 연구에서는 'Athena'라는 새로운 프레임워크를 제안하여 법적 판단 예측(legal judgment prediction, LJP) 문제 해결에 RAG를 핵심 전처리 구성 요소로 활용합니다.

- **Technical Details**: Athena는 고발(고소)에 대한 지식 기반을 구축하고, 벡터화(vectorization)를 통해 의미 검색(semantic retrieval) 메커니즘을 첨부합니다. 실험 결과, Athena의 전반적인 성능이 크게 향상되어 CAIL2018 데이터셋에서 최첨단 결과를 달성하였습니다. 우리는 RAG를 도입하여 LLM의 법률 분야에서의 지식 취득을 개선하고, 이를 통해 환각(hallucination)과 모호성을 완화합니다.

- **Performance Highlights**: 실험에서는 LLM의 '중간에 길을 잃은(lost-in-the-middle)' 현상을 재현하며, 적절한 하이퍼 파라미터 조정(hyper-parameter tuning)을 통해 최대 95%의 정확도를 달성할 수 있음을 보여주었습니다. 또 한편, 쿼리 재작성(query rewriting) 및 데이터 분포(data distribution)의 영향도 연구하여 향후 연구 방향을 제시하였습니다.



### Model Swarms: Collaborative Search to Adapt LLM Experts via Swarm Intelligenc (https://arxiv.org/abs/2410.11163)
- **What's New**: 새로운 논문에서는 Model Swarms라는 협업 검색 알고리즘을 제안하여 LLMs(대형 언어 모델)를 스웜 지능(swarm intelligence)으로 적응시키는 방법을 소개합니다. 이 방법은 다양한 모델들이 각자의 능력과 데이터를 기반으로 최적화된 유틸리티 함수를 활용하여 협력적으로 방향성을 가지고 움직입니다.

- **Technical Details**: Model Swarms는 파티클 스웜 최적화(Particle Swarm Optimization, PSO)에 영감을 받아, 다수의 LLM 전문가를 "입자(particles)"로 간주하고 이들이 모델 가중치 공간에서 협력적으로 움직이며 새로운 모델 적응을 검색합니다. 각 입자는 개인 최적 지점(personal best)과 전체 최적 지점(global best) 정보를 공유하며, 유틸리티 함수에 기반하여 운동을 업데이트합니다.

- **Performance Highlights**: Model Swarms는 200개의 사례로도 작업을 최적화하여 12개의 기존 모델 조합 기준을 초과하여 13.3% 성능 개선을 달성했습니다. 또한, 의료, 법률, 과학 및 문화 도메인에서 다중 작업을 공동 최적화하여 독립적으로 작업을 수행할 때보다 더 나은 전문가를 생성하고, 보상 모델의 경우 사전 설정 없이 더 나은 제어력을 보여줍니다. 인간의 관심사에 대해서도 기존 모델과 경쟁하며 85% 이상의 사례에서 뛰어난 성과를 나타냈습니다.



### LLM Unlearning via Loss Adjustment with Only Forget Data (https://arxiv.org/abs/2410.11143)
Comments:
          Paper under review

- **What's New**: 이번 연구에서는 기존의 unlearning 방식에서 요구되는 retain data나 reference LLM 없이도 LLM의 응답 조정이 가능하다는 것을 제안합니다.

- **Technical Details**: 우리의 방법인 FLAT(Forget data only Loss AjustmenT)는 잊어야 할 데이터에 대한 정보만을 사용하여 f-divergence를 극대화함으로써 모델 응답을 조정합니다. 이를 통해 잊는 과정에서의 성능을 저하시키지 않고 모델의 유용성을 유지할 수 있습니다.

- **Performance Highlights**: 실험 결과, FLAT는 해리포터 데이터셋, MUSE 벤치마크 및 TOFU 데이터셋과 같은 다양한 과제에서 기존 방법들에 비해 우수한 unlearning 성능을 달성하였으며, 모델의 유지 능력에 미치는 영향도 최소화했습니다.



### IsoChronoMeter: A simple and effective isochronic translation evaluation metric (https://arxiv.org/abs/2410.11127)
Comments:
          WMT24 (co-located with EMNLP24), Accepted to Shared Task Track, 6 pages, 2 figures, 4 tables, 2 pages references

- **What's New**: 이번 연구에서는 IsoChronoMeter (ICM)라는 새로운 이소크로닉 번역 측정 지표를 제안하며, 자동 더빙의 중요한 맥락에서 이소크로닉 번역의 효과성을 강조합니다. 기존 최첨단 번역 시스템들이 이소크로닉 번역을 고려하지 않은 경우 이 지표에서 미흡한 결과를 보였음을 입증했습니다.

- **Technical Details**: IsoChronoMeter (ICM)는 기존의 텍스트-음성 변환(TTS) 지속시간 예측기를 기반으로 하여 이소크로닉 번역을 측정하는 단순하면서도 효과적인 지표입니다. ICM은 원래 음성 길이 예측과 번역된 음성 길이 예측 간의 상대적 절대 오차를 사용하여 계산됩니다. ICM 값이 0이면 두 음성 길이 예측이 동일하다는 것을 의미하며, 값이 클수록 두 예측의 차이가 큽니다.

- **Performance Highlights**: ICM은 기존 번역 시스템들이 이소크로닉 번역을 충족하지 못하고 있음을 보여주며, AI 기반 더빙 시스템의 품질과 자연스러움을 향상시키기 위해 이소크로닉 번역의 필요성을 강조합니다. 이 연구는 CoVost-2 데이터 세트를 활용하여 이소크로닉 번역 평가의 필요성을 제기합니다.



### A Systematic Review on Prompt Engineering in Large Language Models for K-12 STEM Education (https://arxiv.org/abs/2410.11123)
- **What's New**: 본 연구는 K-12 STEM 교육에서 LLMs(대형 언어 모델)과 prompt engineering(프롬프트 엔지니어링)의 결합 사용에 대한 실증 연구를 분석하였습니다. 2021년부터 2024년까지 발표된 논문 중 30개를 선택하여 감독한 내용입니다.

- **Technical Details**: PRISMA 프로토콜을 따르며, 2,654개의 논문을 검토 후 30개 연구를 선정했습니다. 연구에서는 사용된 prompting strategies(프롬프트 전략), LLM의 종류, 효과 평가 방법, 이전 연구의 한계를 확인하였습니다.

- **Performance Highlights**: 간단한 prompting은 일반적으로 사용되지만, few-shot 및 chain-of-thought prompting과 같은 고급 기법이 다양한 교육 작업에서 긍정적인 결과를 보여주었습니다. GPT 시리즈 모델이 주로 사용되지만, 적은 수의 파라미터를 가진 모델(예: Blender 7B)과 효과적인 prompt engineering이 결합되었을 때 특정 상황에서 더 큰 모델(예: GPT-3)을 초월하는 성능을 보였습니다.



### ChuLo: Chunk-Level Key Information Representation for Long Document Processing (https://arxiv.org/abs/2410.11119)
Comments:
          Submitted to ICLR 2025

- **What's New**: 본 논문에서는 긴 문서 분류에서 기존의 한계를 극복하는 새로운 청크 표현 방법인 ChuLo를 소개합니다. ChuLo는 비지도 키프레이즈 추출을 이용하여 입력 토큰을 그룹화하고 시맨틱적으로 중요한 키프레이즈 기반의 청크를 강조하여 핵심 문서 내용을 유지하면서 입력 길이를 줄입니다.

- **Technical Details**: ChuLo는 비지도 학습 방법을 통해 중요한 키프레이즈를 추출하여 입력 길이를 감소시키면서도 핵심 내용을 보존합니다. 이 방법은 긴 문서 처리에서 정보 손실을 최소화하고 Transformer 모델의 효율성을 향상시킵니다. 또한, 모든 토큰을 유지하는 것이 중요한 토큰 분류 작업에서 세밀한 주석을 잃지 않도록 보장합니다.

- **Performance Highlights**: 다양한 긴 문서 분류 작업 및 긴 문서 토큰 분류 작업에서 ChuLo의 효과성을 평가하였으며, 방대한 질적 및 양적 분석을 통해 경쟁력 있는 결과를 입증하였습니다.



### Active Learning for Robust and Representative LLM Generation in Safety-Critical Scenarios (https://arxiv.org/abs/2410.11114)
- **What's New**: 이 논문은 안전 시나리오에서 LLM(대형 언어 모델)의 출력을 안내하기 위해 클러스터링과 능동 학습(active learning)을 결합한 새로운 프레임워크를 제안합니다.

- **Technical Details**: 제안된 프레임워크는 다양한 클러스터에서 불확실한 사례를 식별하고, 이를 LLM에게 전달하여 반복적인 생성 과정을 통해 더 균형 잡힌 데이터 세트를 생성합니다. 총 5.4K의 안전 위반 사항 데이터셋을 구축하였으며, 이는 다양한 안전 시나리오를 포괄합니다.

- **Performance Highlights**: 이 방법으로 생성된 데이터는 액티브 러너 모델의 정확도와 F1 점수를 향상시키며, 다른 모델에서도 성능 개선의 효과를 보입니다. 이는 기존 시뮬레이션 중심의 연구를 넘어 새로운 데이터 세트를 생성하면서 머신 러닝 모델 훈련에 실질적 적용 가능성을 보여줍니다.



### JOOCI: a Framework for Learning Comprehensive Speech Representations (https://arxiv.org/abs/2410.11086)
Comments:
          Submitted to ICLR 2025

- **What's New**: 본 논문에서는 JOOCI(이중 최적화 프레임워크)를 제안하여 기존의 단일 임베딩 방식으로 인해 발생하는 비효율성을 극복하고, 다른 정보(other information)와 내용(content information)을 독립적으로 최적화합니다.

- **Technical Details**: JOOCI 프레임워크는 두 개의 주요 인코더(내용 인코더 및 다른 인코더)를 사용하여 각각의 정보를 모델링합니다. 내용 인코더(Content Encoder)는 내용 정보를 담고 있으며, 다른 인코더(Other Encoder)는 비언어적 정보를 캡처합니다. 이 프레임워크는 공유 인코더(Shared Encoder)를 사용하여 원시 음성을 다운샘플링하고 두 인코더를 위한 임베딩 계층을 제공합니다.

- **Performance Highlights**: SUPERB 벤치마크에서 JOOCI는 비슷한 크기(1억 개의 파라미터)와 사전 훈련 데이터(960시간)를 가진 다른 최신 모델들보다 성능이 일관되게 우수하며, 주요 음성 다운스트림 작업들에 있는 평가 결과에서 큰 차이를 보였습니다.



### Gender Bias in Decision-Making with Large Language Models: A Study of Relationship Conflicts (https://arxiv.org/abs/2410.11084)
Comments:
          EMNLP Findings 2024

- **What's New**: 이번 연구는 대규모 언어 모델(LLMs)의 성별 편견을 분석하며, 특히 관계 결정 상황에서 성 역할에 대한 모델의 이해를 조사합니다. 새로운 데이터셋인 DeMET Prompts를 사용하여 친밀한 관계의 다양한 시나리오를 탐구합니다.

- **Technical Details**: DeMET Prompts는 전통적-평등주의 시나리오를 포함하며, 다양한 이름 목록(남성, 여성, 중립적 이름)을 통해 아홉 가지 관계 구성을 분석합니다. 안전성 가드레일(safety guardrails)을 추가하여 모델의 편견을 어떻게 줄일 수 있는지를 평가합니다.

- **Performance Highlights**: 모든 모델은 여성, 성 중립 이름, 남성 순으로 편견이 나타났으며, 안전성 가드레일을 추가할 경우 이러한 편견이 감소하였습니다. 연구 결과는 모델이 전통적인 남성 우위의 고정관념을 회피하며 '전통적으로 여성'인 개인과 더 자주 연관되어 있음을 보여줍니다.



### Code-Mixer Ya Nahi: Novel Approaches to Measuring Multilingual LLMs' Code-Mixing Capabilities (https://arxiv.org/abs/2410.11079)
Comments:
          Manuscript submitted to COLING 2025

- **What's New**: 다언어 대형 언어 모델(Multilingual Large Language Models, LLMs)의 기계 번역(Machine Translation, MT) 능력은 이미 뛰어난 성과를 보여주었지만, 코드 스위칭(code-switching) 상황에서의 능력은 충분히 탐구되지 않았습니다. 이 논문에서는 코드를 혼합한 문장을 생성하기 위한 새로운 프롬프트 기법인 Rule-Based Prompting을 소개합니다.

- **Technical Details**: 연구에서는 $k$-shot prompting($k\in\{0, 1, 10, 20\}$)과 Rule-Based Prompting을 사용하여 GPT-3.5-turbo, GPT-4, Gemini Pro와 같은 3개의 인기 있는 다국어 LLM의 코드 혼합 MT 능력을 측정하고 비교합니다. 데이터셋은 영어-{힌디어(Hindi), 벵골어(Bengali), 구자라티어(Gujarati), 프랑스어(French), 스페인어(Spanish)}의 5개 언어 쌍을 포함하며, 이를 통해 다언어 LLM의 영어와 코드 혼합 문장 간의 번역 능력을 평가합니다.

- **Performance Highlights**: 결과에 따르면, $k$-shot prompting이 종종 최고의 성과를 나타내지만, Rule-Based Prompting은 코드 혼합의 스타일이 다양한 고유한 문장을 생성하는 데 유망한 결과를 보여줍니다. 또한, 이 연구의 실제 적용으로 코드 혼합 챗봇을 개발하였습니다.



### PRACTIQ: A Practical Conversational Text-to-SQL dataset with Ambiguous and Unanswerable Queries (https://arxiv.org/abs/2410.11076)
- **What's New**: 이 논문에서는 실전에서 사용자 질문의 모호성과 답변 불가능성을 반영한 PRACTIQ라는 대화형 text-to-SQL 데이터셋을 생성했습니다. 기존의 text-to-SQL 시스템들이 명확한 질문에 초점을 맞췄던 반면, PRACTIQ는 실제 사용자 질의를 바탕으로 하여 모호하고 답변 불가능한 질문을 포함합니다.

- **Technical Details**: PRACTIQ는 네 가지 모호한 질문 카테고리와 네 가지 답변 불가능 질문 카테고리를 정의한 후, 이를 바탕으로 대화 형식의 질문을 생성합니다. 또한, 질문 분류 및 SQL 예측을 위한 두 단계의 프레임워크를 구현했습니다. 이를 위해 여러 대형 언어 모델(LLM)을 사용하여 성능을 평가하고 있습니다.

- **Performance Highlights**: 실험 결과, 현재의 최첨단(text-to-SQL) 시스템들은 모호하고 답변 불가능한 질문을 효과적으로 처리하지 못함을 보여주었습니다. PRACTIQ 데이터셋을 통해 이러한 문제를 개선하는 데 기여할 것으로 기대됩니다.



### An Annotated Dataset of Errors in Premodern Greek and Baselines for Detecting Them (https://arxiv.org/abs/2410.11071)
- **What's New**: 이번 연구에서는 고대 그리스어(ancient Greek)에서 실제 오류(real errors)를 포함하는 첫 번째 데이터셋을 소개합니다. 이 데이터셋은 수세기 동안 복사(copied) 과정에서 축적된 오류를 평가하는 데 사용됩니다.

- **Technical Details**: 1,000개의 단어(sampled words)를 BERT(Bidirectional Encoder Representations from Transformers) 기반의 조건(conditionals)에서 파생된 메트릭(metrics)으로 샘플링하여 오류가 있을 가능성이 높은 단어를 추출하였습니다. 이후 전문가(domain expert)가 오류로 주석(annotation) 및 레이블(labeling)을 붙였습니다. 논문에서는 새로운 오류 탐지(error detection) 방법을 제안하고, 판별자(discriminator) 기반의 탐지기가 가장 높은 성과를 보인다는 것을 발견하였습니다.

- **Performance Highlights**: 우리의 판별자(discriminator) 기반 탐지기는 실제 오류(real errors) 분류에서 true positive rate를 5% 향상시켰습니다. 또한, 필사 오류(scribal errors)가 인쇄(print) 또는 디지털화(digitization) 오류보다 탐지하기 더 어렵다는 것을 관찰했습니다. 이 데이터셋은 고대 텍스트의 오류 탐지 방법을 평가하는 기초를 제공합니다.



### Assessing Bias in Metric Models for LLM Open-Ended Generation Bias Benchmarks (https://arxiv.org/abs/2410.11059)
Comments:
          NeurIPS 2024 EvalEval Workshop

- **What's New**: 본 연구는 대형 언어 모델(LLMs)의 편향을 평가하는 open-generation bias benchmarks, 특히 BOLD 및 SAGED의 내재적 편향을 분석합니다. 이를 통해 불공정한 결론에 이르게 하는 분류기(classifiers)의 편향을 조사했습니다.

- **Technical Details**: MGSD 데이터셋을 사용하여 두 가지 실험을 수행했습니다. 첫 번째 실험에서는 counterfactuals를 통해 인구 통계 그룹 간의 예측 변동성을 측정하고, 두 번째 실험에서는 SHAP(Shapley Additive Explanations) 도구를 사용하여 관찰된 편향이 이러한 counterfactuals에서 유래했음을 검증했습니다.

- **Performance Highlights**: 연구 결과, 다양한 인구통계 설명자(demographic descriptors)에서 불평등한 처리 결과가 나타났으며, 특히 RegardV3는 가장 큰 편향을 보였습니다. Race 그룹이 가장 많은 편향을 보였고, Detoxify는 인종 간 독성 점수에서 큰 변동성을 보였습니다.



### Beyond Human-Only: Evaluating Human-Machine Collaboration for Collecting High-Quality Translation Data (https://arxiv.org/abs/2410.11056)
- **What's New**: 이 연구에서는 인간-기계 협력을 통해 고품질 번역을 효과적으로 수집하는 방법을 제시합니다. 11가지 접근 방식을 통해 작업의 효율성과 비용 절감 효과를 입증했습니다.

- **Technical Details**: 이 연구는 전통적인 인간 번역 방식과 기계 번역 방식 및 하이브리드 접근 방식을 포함한 11가지 방법을 비교 분석했습니다. 오류 분석을 통해 인간과 기계 기여의 보완적 강점을 강조했습니다.

- **Performance Highlights**: 인간-기계 협력 방식은 전통적인 방법의 약 60%의 비용으로 높은 품질의 번역을 제공할 수 있으며, 연구 데이터 세트는 18,000개 번역 세그먼트를 포함하고 있습니다.



### Varying Shades of Wrong: Aligning LLMs with Wrong Answers Only (https://arxiv.org/abs/2410.11055)
- **What's New**: 본 논문에서는 주석(annotation)이 부족한 상황에서 LLM(large language model)의 성능을 어떻게 확장할 수 있는지에 관한 두 가지 연구 질문에 초점을 맞춥니다. (1) LLM이 잘못된 옵션들 사이에서 신뢰할 수 있는 선호도를 생성할 수 있는가? (2) 이러한 잘못된 옵션 간 선호와의 정렬(alignment)이 도움이 되는가?

- **Technical Details**: 연구에서는 Self-consistency, token probabilities, LLM-as-a-judge와 같은 방법을 통해 잘못된 옵션들 사이의 선호도를 이끌어내고 이 합성(preference optimization)을 통해 언어 모델을 미세 조정(fine-tune)합니다. 실험 결과, LLM은 다양한 shades of wrong을 구분하며, 일부 경우에는 더 나은 정확성을 보입니다. 아울러, 잘못된-잘못된 선호에 대한 정렬이 모델의 교정(calibration)을 향상시키는 데 기여합니다.

- **Performance Highlights**: 7개의 LLM과 8개의 데이터셋을 활용한 광범위한 실험을 통해, (1) LLM이 잘못된 옵션 사이의 선호도를 구분할 수 있으며, 무작위 추측보다 평균 20.9% 높은 성능을 보입니다. (2) 잘못된 옵션 간 선호도와의 정렬이 LLM의 성능을 개선시켜, 경우에 따라 올바른 답안을 도출하기도 하며, 전체적으로 모델의 교정 오류(Estimated Calibration Error)는 최대 9.4% 감소합니다.



### Personality Differences Drive Conversational Dynamics: A High-Dimensional NLP Approach (https://arxiv.org/abs/2410.11043)
Comments:
          To be published in the Proceedings of the Second Workshop on Social Influence in Conversations (SICon 2024), co-located with EMNLP 2024

- **What's New**: 이 논문은 대화의 주제 흐름이 시간에 따라 어떻게 나타나는지와 대화 상대자들의 성격 특성이 이 주제 흐름에 어떻게 기여하는지를 조사합니다.

- **Technical Details**: 1655개의 비공식 대화를 통해 수집된 데이터에서 텍스트 임베딩을 활용하여 고차원 공간으로 대화 궤적을 매핑합니다. 비선형 투영과 클러스터링을 사용하여 각 대화자의 주제 진입과 퇴장을 식별합니다. 대화 흐름의 차이는 	extit{topic entropy}와 	extit{linguistic alignment}를 통해 정량화됩니다.

- **Performance Highlights**: 성격 차원이 더 큰 개방성을 가진 대화자는 더 다양한 주제에 대해 더 많은 시간을 소요하며, 외향성이 큰 차이를 가진 대화자는 대화 중에 언어적 일치도가 더 크게 감소하는 경향이 있습니다. 또한, 외향성 차이에 따라 감정 변화의 차이가 더 크고, 주제 엔트로피가 클수록 감정 증가가 더 크게 나타나는 것으로 확인되었습니다.



### Persistent Topological Features in Large Language Models (https://arxiv.org/abs/2410.11042)
Comments:
          10+6 pages, 7 figures, 1 table. All comments welcome!

- **What's New**: 이 논문은 대규모 언어 모델(LLMs)의 내부 표현을 분석하기 위해 새로운 프레임워크인 zigzag persistence를 도입하였습니다. 이는 동적 변환을 겪는 데이터의 위상학적(topological) 특성을 효과적으로 설명하는 방법으로, LLM의 레이어(layer) 간 변화를 추적합니다.

- **Technical Details**: 제안된 persistence similarity는 LLM 레이어 간의 위상적 특성이 어떻게 지속되고 변화하는지를 정량화하는 새로운 메트릭(metric)입니다. 기존의 유사성 측정 방법들과 달리, persistence similarity는 두 레이어 간의 모든 변환 궤적을 추적하여 내부 작동 원인에 대한 깊은 통찰력을 제공합니다.

- **Performance Highlights**: 이 접근법을 통해 중요한 레이어들을 식별하고 불필요한 레이어를 제거함으로써 성능 저하 없이 모델을 경량화할 수 있음을 보였습니다. 여러 벤치마크 데이터셋에서 최신 방법들과 비슷한 성능을 유지하며, 다양한 모델과 하이퍼파라미터 설정에서 일관된 위상적 행동을 보였습니다.



### Improving the Language Understanding Capabilities of Large Language Models Using Reinforcement Learning (https://arxiv.org/abs/2410.11020)
- **What's New**: 본 논문에서는 대형 언어 모델(LLMs)이 자연어 이해(NLU) 작업에서 기존 BERT 모델보다 성능이 떨어진다는 점을 개선하기 위해, SFT(구조화된 미세 조정)와 PPO(인접 정책 최적화) 두 가지 접근 방식을 탐구합니다. 특히, PPO가 LLM의 NLU 성능을 어떻게 향상시킬 수 있는지 분석합니다.

- **Technical Details**: 이 연구는 LLM을 대상으로 SFT와 PPO를 사용하여 NLU 능력을 개선하는 방법을 제안합니다. SFT에서는 저순위 적응(LoRA) 계층을 활용하여 미세 조정 비용을 줄이고, PPO를 통해 토큰 생성 과정을 행동으로 간주하여 보상 기능을 틀로 삼아 모델을 최적화합니다.

- **Performance Highlights**: 실험 결과, PPO가 SFT에 비해 GLUE 벤치마크에서 평균 6.3 점 향상된 성능을 보였으며, zero-shot과 few-shot 방식을 경쟁하여 각각 38.7 및 26.1 점 우수한 성과를 달성했습니다. PPO는 BERT-large보다도 GLUE에서 2.7 점, SuperGLUE에서 9.3 점 높은 성능을 기록했습니다.



### Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback (https://arxiv.org/abs/2410.11009)
Comments:
          Accepted to appear at EMNLP 2024

- **What's New**: AI가 매개된 커뮤니케이션 시스템인 Nifty를 통해 사용자 피드백을 효과적으로 통합하여 AI 글쓰기 모델의 성능을 향상시키는 방법을 제안합니다.

- **Technical Details**: Nifty는 사용자가 스마트 추천 시스템의 제안 중 아무것도 클릭하지 않았을 때 발생하는 일회성 암묵적 부정 피드백을 활용합니다. 이 방법은 분류기 가이드를 사용하여 이 피드백을 텍스트 생성 과정에 통합합니다. 두 가지 조건 설정을 탐구하는데, 하나는 제안에 포함되지 않은 다음 의도에 따라 모델을 조정(push)하는 것이고, 다른 하나는 사용자가 제안을 거부한 것에 직접적으로 조건을 두는 것입니다.

- **Performance Highlights**: 이 시스템은 MultiWOZ 및 Schema-Guided Dialog 데이터셋을 사용하여 Rouge-L에서 최대 34%, 올바른 의도 생성에서 89% 향상을 보였으며, 인간 평가자에 의한 86%의 승률을 기록했습니다.



### Assessing the Human Likeness of AI-Generated Counterspeech (https://arxiv.org/abs/2410.11007)
- **What's New**: 이 연구는 AI가 생성한 카운터스피치(counterspeech)의 인간 유사성을 평가하여, 주목받지 못했던 평가 요소인 인간 유사성을 분석합니다. 이전 연구는 표면적 형식이나 관련성 중심이었으나, 이번 연구는 더 나아가 AI 기법이 얼마나 인간의 반응을 잘 모방하는지를 탐구합니다.

- **Technical Details**: 연구에서 여러 LLM(대규모 언어 모델) 기반 생성 전략을 구현하고 평가하여, AI와 인간이 쓰는 카운터스피치를 쉽게 구별할 수 있음을 발견했습니다. 특히, 언어적 특성, 예의(polite), 구체성(specificity)에서 차이를 확인했습니다. 실험 방법으로는 Prompting, Prompt and Select, Fine-tuning, Outcome-constrained와 같은 다양한 생성 전략을 사용했습니다.

- **Performance Highlights**: 연구 결과, AI가 생성한 카운터스피치는 인간이 작성한 것에 비해 언어적 특성에서 현저한 차이를 보이고, 더 예의 바르지만 덜 구체적이라는 것을 나타냈습니다. 이러한 차이는 분류기(classifier)와 사람 모두가 쉽게 감지할 수 있었으며, 이는 AI 기술이 완전히 인간의 카운터스피치 능력을 대체할 수 없다는 것을 보여줍니다.



### Effective Self-Mining of In-Context Examples for Unsupervised Machine Translation with LLMs (https://arxiv.org/abs/2410.11006)
- **What's New**: 이 연구에서는 기계 번역(machine translation, MT)을 위한 컨텍스트 예제(in-context examples)를 무감독으로 추출하는 새로운 접근 방식을 제안합니다. 특히 자원이 부족한 언어 쌍의 MT에 적용할 수 있으며, 이 방법은 단어 수준의 채굴(word-level mining) 방식으로 시작하여 문장 수준의 채굴로 발전합니다.

- **Technical Details**: 제안된 방법은 두 단계로 나뉘며, 첫 번째 단계는 단어 수준 번역(stage)은 LLM을 이용하여 고품질의 단어 번역을 생성하고, 이를 통해 합성된 병렬 데이터(synthetic parallel data)를 생성합니다. 두 번째 단계인 문장 수준 변환(stage)에서는 이 데이터 를 활용하여 테스트 입력의 번역을 위한 최적의 예제를 만듭니다. 무감독 채굴된 문장 쌍에서 예제를 선택하기 위한 신규 방법을 제안합니다.

- **Performance Highlights**: 이 방법은 FLORES-200 데이터셋의 288개 방향에서 두 개의 다국어 LLM을 활용하여 성능을 평가하였으며, 다른 최신 UMT 방법들에 비해 평균 7 BLEU 포인트 향상된 성능을 기록했습니다. 또한, 제안된 방식은 기존의 ICL 방법과 비슷한 수준의 성능을 보이며, 특히 자원 수준이 낮은 언어 쌍에서의 기계 번역 성능을 개선하는 데 효과적임을 입증했습니다.



### One Language, Many Gaps: Evaluating Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks (https://arxiv.org/abs/2410.11005)
- **What's New**: 이 연구는 대규모 언어 모델(LLM)이 비표준 방언인 아프리카계 미국인 방언 영어(AAVE)에 대해 공정성과 강인성을 가지고 있는지를 평가한 최초의 연구입니다. 기존의 벤치마크는 LLM의 성능을 평가할 때 방언 사용자의 경험을 무시했습니다.

- **Technical Details**: 논문에서는 ReDial이라는 새로운 벤치마크를 만들어 1.2K 이상의 표준 영어(Standardized English)와 AAVE 쌍을 포함했습니다. 이를 통해 알고리즘, 수학, 논리, 포괄적 추론 등 네 가지 주요 추론 작업에 대해 평가를 수행했습니다. GPT-4o, GPT-4, LLaMA-3.1/3 등 여러 최신 LLM을 평가하였습니다.

- **Performance Highlights**: 대부분의 LLM 남성 모든 기준 대조반의 AAVE 쿼리에 대해 두드러지게 성능이 저하되었습니다. 예를 들어, LLaMA-3.1-70B-Instruct를 제외한 모든 모델의 AAVE 통과율은 0.6 이하로 떨어졌으며, 이는 표준 영어의 베스트 통과율 0.832에 비해 상당히 낮은 수치입니다.



### Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs (https://arxiv.org/abs/2410.11001)
- **What's New**: 이번 연구에서는 LLM(대형 언어 모델)에 의해 생성된 역사적 응답을 활용하여 RAG(검색 증강 생성)를 개선하기 위한 '그래프 오브 레코드'(GoR)를 제안합니다. 기존 방법들이 유용한 정보를 포함하는 LLM 생성 응답을 무시하는 것에 대한 문제점을 해결하려고 합니다.

- **Technical Details**: GoR 방법론은 LLM이 시뮬레이션한 사용자 쿼리와 관련된 텍스트 청크 간의 엣지를 통해 기록 그래프를 구축합니다. 재귀 신경망(graph neural network)을 사용하여 노드 간의 정교한 상관관계를 학습하고, BERTScore 기반의 자가 지도 학습(objective)을 통해 최적화를 진행합니다. 이를 통해 노드 임베딩이 쿼리와의 의미적 및 논리적 상관관계를 반영할 수 있도록 합니다.

- **Performance Highlights**: GoR은 WCEP 데이터셋에서 Rouge-L에서 15%, Rouge-1에서 8%, Rouge-2에서 19% 개선된 성능을 보여줍니다. 총 12개 기준선과의 비교를 통해 GoR의 우수성이 입증되었습니다.



### Watching the Watchers: Exposing Gender Disparities in Machine Translation Quality Estimation (https://arxiv.org/abs/2410.10995)
Comments:
          Work in progress

- **What's New**: 이 논문은 기계 번역에서 품질 추정(QE) 지표의 성별 편향을 처음으로 조사하며, 이로 인해 발생하는 문제점과 해당 문제의 영향에 대해 다룬다. 성별 grammatical gender이 있는 언어로의 번역을 중점적으로 다룬다.

- **Technical Details**: 저자들은 11개의 최신 QE 지표를 사용하여 기계 번역 시스템에서 성별 편향을 평가했다. 특정 단어의 성별 변화에 따른 품질 점수를 비교하고, 문맥 정보를 사용하여 이러한 편향이 완화되는지를 분석한다.

- **Performance Highlights**: 실험 결과, 남성화된 번역이 여성화된 번역보다 높은 점수를 받으며, 성 중립 번역은 불리하게 평가되는 경향을 보였다. 문맥 기반 QE 지표는 남성 변화에 대한 오류를 줄이지만, 여성 변화에 대한 오류는 여전히 해결하지 못해 성별 불균형을 심화시키는 결과를 나타냈다.



### Performance in a dialectal profiling task of LLMs for varieties of Brazilian Portugues (https://arxiv.org/abs/2410.10991)
Comments:
          8 pages, XI Jornada de Descrição do Português

- **What's New**: 이번 논문은 LLM(대규모 언어 모델)이 브라질 포르투갈어의 다양한 방언에 대해 어떻게 편향을 나타내는지를 탐구합니다. 또한, GPT 3.5, GPT-4o, Gemini, Sabiá-2 등 네 가지 LLM을 분석하여 사회언어학적 규칙을 고려하는지를 평가했습니다.

- **Technical Details**: 연구 방법론은 세 단계로 나뉘며, LLM들이 각 브라질 주를 대표하는 텍스트를 생성하고 이러한 텍스트를 기반으로 한국어 또는 영어로 타겟 주를 식별하는 작업을 포함합니다. 연구 과정은 데이터 정리(cleaning), 표준화(standardization), 데이터 구조화(structuring)를 포함했습니다.

- **Performance Highlights**: Sabiá-2 모델은 방언 변형을 전혀 보여주지 않는 반면, GPT 3.5, GPT-4o, Gemini는 두 번째 인칭 대명사와 첫 번째 인칭 동사의 일치 등에서 방언의 차이에 대한 민감성을 보여주었습니다. 이 연구는 LLM이 방언을 처리하는 방식에 대한 중요한 통찰력을 제공합니다.



### Fine-tuning can Help Detect Pretraining Data from Large Language Models (https://arxiv.org/abs/2410.10880)
- **What's New**: 이 논문은 Fine-tuned Score Deviation (FSD)라는 새로운 방법을 제안하여 사전 훈련 데이터 탐지의 성능을 개선합니다. 이는 모델이 미리 보지 못한 데이터를 소량으로 분석함으로써 사전 훈련 집합의 구성원과 비구성원 간의 차이를 늘리는 방법입니다.

- **Technical Details**: FSD는 특정 도메인(예: Wikipedia의 이벤트 데이터, arXiv 연구 논문)에서 모델을 미세 조정(fine-tuning)한 후의 점수 편차를 측정하여 구성원과 비구성원 간의 간격을 확장합니다. 기존 방법들에 비해, FSD는 소량의 보지 않은 데이터를 통해 비구성원의 점수를 크게 감소시켜 더 명확한 구분을 가능하게 합니다.

- **Performance Highlights**: 다양한 벤치마크 데이터셋(예: WikiMIA, ArXivTection)에서 FSD를 통해 기존 방법의 AUC score가 크게 향상되었으며, 예를 들어, WikiMIA에서 Min-k%의 경우 0.62에서 0.91로 증가했습니다. ArXivTection에서는 TPR@5%FPR 점수가 0.10에서 0.81로 개선되었습니다.



### Herald: A Natural Language Annotated Lean 4 Datas (https://arxiv.org/abs/2410.10878)
- **What's New**: 이 논문은 Mathlib4 코퍼스를 자연어로 번역하기 위한 새로운 프레임워크를 소개하고, 이를 기반으로 Lean 4 분석기를 활용한 이중 증강 전략을 적용하였습니다. 새로운 데이터셋인 Herald를 생성하고, 이를 통해 자연어-형식언어(NL-FL) 번역 모델의 성능을 향상시키는 방법을 제시합니다.

- **Technical Details**: 이 연구에서 제안하는 Herald 데이터셋은 Mathlib4에서 580k의 유효한 문장과 44k의 NL-FL 정리 쌍을 포함하고 있으며, 자연어 추론을 형식언어로 변환하는 과정에서 LLM(large language models)의 성능을 개선하는 구조적 정보를 제공합니다. 이 데이터셋은 '증분적 비형식화(informalization)'와 '형식화(formalization)' 과정을 통해 생성됩니다.

- **Performance Highlights**: Herald 번역기는 miniF2F-test에서 93.2% 정확도를 달성했으며, 내부 대학 교재 데이터세트에서 22.5%의 정확도로, 이전의 모델인 InternLM2-Math-Plus-7B와 TheoremLlama에 비해 현저히 높은 성능을 보였습니다. 또한 Stack 프로젝트의 섹션을 성공적으로 번역하여 대학 수준의 수학 문헌의 자동 형식화에서 중요한 진전을 이루었습니다.



### Improving Data Efficiency via Curating LLM-Driven Rating Systems (https://arxiv.org/abs/2410.10877)
- **What's New**: 이번 연구에서는 각종 대형 언어 모델(LLM)의 데이터 선택을 위한 새로운 방법인 DS2(Diversity-aware Score curation method)를 소개합니다. DS2는 LLM 기반의 점수에서 발생하는 오류 패턴을 분석하여 보다 정확하고 다양한 데이터를 선택할 수 있도록 합니다.

- **Technical Details**: DS2는 점수 전이 행렬(score transition matrix)을 활용하여 기존 LLM에서 생성된 점수의 오류를 수정하고, 데이터 샘플의 다양성을 보장합니다. 이 접근법을 통해 DS2가 선택한 3.3%의 데이터 서브셋이 300k 샘플의 전체 데이터보다 다양한 기계 정렬 벤치마크에서 더 우수한 성능을 보임을 입증했습니다.

- **Performance Highlights**: DS2를 통해 선택된 데이터에 대해 파인튜닝한 모델은 LIMA라는 인간 커리가 된 데이터셋보다도 뛰어난 성능을 나타냈습니다. 이는 기존의 데이터 스케일링 가정을 도전하며, 양질의 데이터 선택의 중요성을 강조합니다.



### FreqMark: Frequency-Based Watermark for Sentence-Level Detection of LLM-Generated Tex (https://arxiv.org/abs/2410.10876)
- **What's New**: 이 논문에서는 LLM(대형 언어 모델) 생성 텍스트에 대해 탐지 가능한 주파수 기반 워터마크를 삽입하는 FreqMark라는 새로운 워터마킹 기법을 제안합니다. 이는 Token 샘플링 과정에서 주기적인 신호를 사용하여 Token을 선택함으로써 이뤄집니다.

- **Technical Details**: FreqMark는 워터마크를 생성하기 위해 Short-Time Fourier Transform (STFT) 분석을 활용합니다. 이 방법은 LLM이 생성한 콘텐츠를 정확하게 식별할 수 있게 해주며, 사람의 저작물과 LLM 생성물이 혼합된 텍스트 시나리오에서도 효과적입니다. 주기적인 신호는 특정 패턴에 따라 다음 Token을 선택하게 하여 워터마크를 삽입합니다.

- **Performance Highlights**: 실험 결과 FreqMark는 다양한 공격 시나리오에 대해 강력한 탐지 능력을 발휘하며, AUC(Area Under the Curve) 값이 최대 0.98에 도달했습니다. 이는 기존 탐지 방법보다 월등한 성능을 나타냅니다.



### Optimizing Transformer based on high-performance optimizer for predicting employment sentiment in American social media conten (https://arxiv.org/abs/2410.10874)
Comments:
          5 pages, 5 figures

- **What's New**: 본 연구는 군집 지능 최적화 알고리즘(optimization algorithm)을 기반으로 Transformer 모델을 개선하였으며, 미국 소셜 미디어에서의 고용 관련 텍스트 콘텐츠의 감정을 예측하는 것을 목표로 합니다.

- **Technical Details**: 텍스트 전처리(text preprocessing), 특징 추출(feature extraction) 및 벡터화(vectorization)를 통해 텍스트 데이터를 수치 데이터로 성공적으로 변환하였으며, 이를 모델 학습에 사용하였습니다. 실험 결과, 학습 과정 동안 모델의 정확도가 49.27%에서 82.83%로 증가하고, 손실 값(loss value)은 0.67에서 0.35로 감소하였습니다.

- **Performance Highlights**: 혼동 행렬(confusion matrix) 분석에 따르면, 학습 세트에서의 정확도는 86.15%이며, 테스트 세트에서도 82.91%의 좋은 성능을 보였습니다. 학습 세트와 테스트 세트 간의 정확도 차이는 3.24%에 불과하여 모델의 일반화 능력이 강함을 나타냅니다. 또한 Kappa 계수(Kappa coefficient)는 0.66, F-measure는 0.80으로, 소셜 미디어 감성 분석에서 모델의 효과성을 추가적으로 검증하였습니다.



### AuditWen:An Open-Source Large Language Model for Aud (https://arxiv.org/abs/2410.10873)
Comments:
          18 pages,1 figures

- **What's New**: 이번 연구에서는 Qwen을 기반으로 한 첫 번째 오픈소스 감사 대화형 대형 언어 모델 (LLM)인 AuditWen을 소개하며, 15개의 감사 작업과 28,000개의 지침 데이터를 통해 감사 분야에 특화된 모델을 구축했습니다.

- **Technical Details**: AuditWen은 3단계로 구성된 감사 작업을 위한 데이터셋을 활용하여 Qwen을 세부 조정한 모델입니다. 연구는 세 가지 유형의 필요(핵심 요구사항, 규제 요구사항, 파생 요구사항)로 감사에서의 LLM 적용 시나리오를 추출하였으며, 이를 바탕으로 3,000개의 지침을 포함한 평가 기준을 개발했습니다.

- **Performance Highlights**: 실험 결과 AuditWen은 질문 이해 및 답변 생성에서 기존의 LLM들과 비교하여 우수한 성능을 보였으며, 특히 감사 이슈 요약 및 법률 추천 작업에서 효과적입니다. AuditWen은 실제 감사 업무에 즉시 적용할 수 있는 값진 도구로 입증되었습니다.



### ToolBridge: An Open-Source Dataset to Equip LLMs with External Tool Capabilities (https://arxiv.org/abs/2410.10872)
Comments:
          technical report

- **What's New**: 이 논문은 ToolBridge라는 새로운 파이프라인을 통해 LLMs(대규모 언어 모델)가 외부 도구를 효과적으로 사용하는 방법을 학습할 수 있도록 지원하는 고품질의 공개 데이터셋을 만드는 과정을 설명합니다. 특히, 외부 도구 API 삽입을 위한 데이터 항목을 식별하는 전략을 제안하고, 이를 통해 LLM의 예측 정확도를 향상시키는 데 중점을 두고 있습니다.

- **Technical Details**: ToolBridge는 공개된 오픈 액세스 데이터셋을 원시 데이터셋 풀로 사용하여, 효과적인 LLM 교육을 위한 데이터 항목 선별, 변환, 필터링의 세 단계로 구성된 파이프라인을 제안합니다. 이 과정에서 LLM의 감독된 세밀 조정(Supervised Fine-Tuning, SFT)을 통해 정확도 향상을 위해 외부 도구를 적절한 맥락에서 호출할 수 있습니다.

- **Performance Highlights**: ToolBridge를 통해 훈련된 LLM은 여러 표준 벤치마크와 맞춤형 평가 데이터셋에서 일관된 성능 향상을 보여 주었습니다. 이 연구는 외부 도구와의 통합에서 LLMs의 교육 데이터를 공개하는 최초의 연구로, 연구자들이 다양한 분야에서 LLM의 외부 도구 사용하는 능력을 발전시킬 수 있을 것으로 기대됩니다.



### Applying Refusal-Vector Ablation to Llama 3.1 70B Agents (https://arxiv.org/abs/2410.10871)
- **What's New**: 최근 Llama 3.1 Instruct와 같은 언어 모델들이 자율적인 에이전트 행동을 할 수 있는 능력이 향상되었다. 본 연구에서는 Llama 3.1 70B 모델에 대해 거부 벡터 제거(refusal-vector ablation)를 적용하고 간단한 에이전트 구조를 구현하여 제한 없는 에이전트를 만들었다. 이 모델들이 위험한 작업을 성공적으로 수행할 수 있다는 점에서 현재의 안전 메커니즘에 큰 취약점이 존재함을 강조한다.

- **Technical Details**: 이 연구는 모델의 거부 행동이 잔여 스트림(residual stream)의 단일 방향에 의해 주로 매개되며, 이 방향을 제거하면 모델이 거부하지 않도록 생성할 수 있음을 보여준다. Llama 3.1 모델에 이 기술을 적용한 결과, 모델이 수정 없이도 많은 비윤리적 작업을 수행할 수 있음이 발견되었다. 또한 'Safe Agent Benchmark'라는 새로운 평가 기준을 도입하여 에이전트의 안전성과 능력을 테스트하는 방법론을 제시한다.

- **Performance Highlights**: Llama 3.1 70B 모델은 28개의 위험한 작업 중 18개를 수행할 의향이 있었으나, 대화 모드에서는 모든 28개 작업에 대해 어떻게 수행할지 조언을 거부했다. 이는 모델의 점점 더 향상된 능력이 악용될 위험을 증가시키며, 언어 모델 에이전트의 향상된 안전 프레임워크 필요성을 강조한다.



### PortLLM: Personalizing Evolving Large Language Models with Training-Free and Portable Model Patches (https://arxiv.org/abs/2410.10870)
- **What's New**: 이 연구에서는 PortLLM이라는 새로운 프레임워크를 소개합니다. 이 프레임워크는 특별한 훈련 없이 도메인 특정 지식을 지속적으로 전이할 수 있도록 설계되었습니다. 사용자가 이전의 모델에서 훈련된 지식을 기반으로 새로운 모델에 손쉽게 적용할 수 있는 기능을 제공합니다.

- **Technical Details**: PortLLM은 LoRA에서 파생된 모델 패치를 활용하여 사전 훈련된 LLM의 다양한 버전 간 도메인 지식을 전이합니다. 이 과정은 훈련 없이 실행되며, 이는 유지 관리 비용을 대폭 낮추고, GPU 메모리 사용량을 최대 12.2배까지 줄일 수 있습니다. 실험에서는 Mistral-7B, Llama2-7B, Llama3.1-8B, Gemma2-9B 등 다양한 모델 아키텍처에서의 효과를 검증하였습니다.

- **Performance Highlights**: PortLLM은 LoRA로 조정한 모델과 유사한 성능을 보이며, 효율적인 자원 사용을 통해 더 짧은 시간 안에 높은 성능을 달성합니다. 또한, 실험 결과는 다양한 타입의 질문 응답 및 추론 과제를 포함한 7개의 과제에서 긍정적인 결과를 보여주었습니다.



### Application of NotebookLM, a Large Language Model with Retrieval-Augmented Generation, for Lung Cancer Staging (https://arxiv.org/abs/2410.10869)
Comments:
          9 pages, 5 figures, 1 table, 3 ancillary files

- **What's New**: 최근 방사선학에서 대규모 언어 모델(LLMs), 특히 NotebookLM과 같은 RAG(검색 증강 생성) 기술이 주목받고 있습니다. 기존 LLMs의 신뢰성 문제를 해결하기 위해, RAG를 통해 증가된 신뢰할 수 있는 외부 지식(REK)을 활용한 연구가 진행되었습니다.

- **Technical Details**: 본 연구에서는 일본의 최신 폐암 병기 분류 지침을 REK로 제공하여, NotebookLM에 100개의 허구의 폐암 사례를 CT 소견을 기반으로 병기 분류하도록 하였습니다. 이 과정에서 gold-standard LLM인 GPT-4 Omni(GPT-4o)와 비교하였으며, 두 모델 모두 REK 활용 유무에 따른 성능을 평가했습니다.

- **Performance Highlights**: NotebookLM은 폐암 병기 분류 실험에서 86%의 진단 정확도를 기록하여, REK를 사용한 GPT-4o의 39% 및 REK 없이의 25%과 비교하여 월등한 성과를 보였습니다. 또한, NotebookLM은 REK 내에서의 참조 위치 검색에서 95%의 정확도를 보여 주목받고 있습니다.



### Mitigating the Impact of Reference Quality on Evaluation of Summarization Systems with Reference-Free Metrics (https://arxiv.org/abs/2410.10867)
- **What's New**: 이 논문에서는 인간의 평가와 높은 상관관계를 가지면서 계산 비용이 매우 낮은 새로운 reference-free (참조 없는) 메트릭을 소개합니다.

- **Technical Details**: 제안된 메트릭은 기존의 reference-based (참조 기반) 메트릭과 함께 사용될 수 있으며, 저품질 참조 설정에서 메트릭의 견고성을 향상시킵니다. 특히 긴 문서의 요약에 대한 relevance (관련성)을 잘 나타냅니다.

- **Performance Highlights**: 이 메트릭은 인간의 평가와 높은 상관관계를 가지며, 저비용으로 계산 가능함을 보여줍니다.



### CodeUnlearn: Amortized Zero-Shot Machine Unlearning in Language Models Using Discrete Concep (https://arxiv.org/abs/2410.10866)
- **What's New**: 본 논문은 대규모 언어 모델(LLMs)의 민감한 정보를 삭제하는 새로운 방법인 제로샷 언러닝(zero-shot unlearning) 접근법을 제안합니다. 기존의 방법은 특화된 데이터 구조나 전체 재훈련이 필요한 반면, 본 연구는 정보 제어 및 흐름 조절을 위해 Sparse Autoencoders(SAEs)와 코드북을 활용합니다.

- **Technical Details**: 코드북 기능을 사용하여 언러닝을 조직화하는 본 접근법은 활성화 벡터를 코드북에 따라 변환하여 특정 주제와 연관된 정보를 효율적으로 식별하고 삭제하도록 합니다. 이 과정에서 벡터 양자화(Vector Quantization, VQ)를 이용해 잠재 공간을 구조화하고, 이산 표현(discrete representations)을 통해 정보를 선택적으로 제거하는 방식을 사용합니다.

- **Performance Highlights**: 본 연구에서는 제안한 방법이 기존의 기계 언러닝 기술에서 한 걸음 나아가 복잡한 언어 작업까지 적용되는 유용성을 입증하였습니다. 또한 선택적이고 효율적인 정보 삭제를 통해 모델의 성능을 유지하면서 민감한 정보를 안전하게 제거할 수 있음을 보여주었습니다.



### Generating Synthetic Datasets for Few-shot Prompt Tuning (https://arxiv.org/abs/2410.10865)
- **What's New**: 이번 논문에서는 few-shot learning 환경에서의 prompt tuning의 한계를 극복하기 위해 LLMs(대형 언어 모델)를 활용하여 특정 작업에 맞는 레이블이 있는 데이터를 합성하는 방법을 제안합니다. 특히, Distribution-Aligned Weighted generator tuning (DawGen)이라는 새로운 방법론을 소개하며, gradient surgery를 이용해 서로 다른 데이터 소스 간의 상충하는 그래디언트를 제거하는 방식을 채택하였습니다.

- **Technical Details**: 제안된 방법은 세 단계로 나뉘며, 첫째로, 제한된 수의 실제 샘플을 통해 소프트 프롬프트를 학습합니다. 둘째로, 적응된 생성기를 통해 합성 훈련 세트를 생성합니다. 셋째로, 합성 데이터와 실제 데이터를 결합하여 소프트 프롬프트를 훈련하여 판별 LLM에 적용합니다.

- **Performance Highlights**: 7개의 문장 쌍 분류 데이터셋에서 실험한 결과, 제안된 방법이 few-shot learning 설정에서 prompt tuning의 효과를 크게 향상시킴을 보여주었습니다. 특히, 102K 파라미터로 구성된 PT가 770M 파라미터의 FT보다 뛰어난 성능을 보였으며, QQP, MRPC, SICK 데이터셋에서 대규모 실제 데이터셋을 사용한 전이 학습과 비교하여 유사한 성능을 달성했습니다.



### Fill In The Gaps: Model Calibration and Generalization with Synthetic Data (https://arxiv.org/abs/2410.10864)
Comments:
          Accepted to EMNLP 2024 Main Conference (Long paper)

- **What's New**: 본 연구에서는 합성 데이터(synthetic data)를 활용한 새로운 모델 캘리브레이션(calibration) 방법을 제안합니다. 기존의 캘리브레이션 방법이 모델의 정확도(accuracy)를 저하시킬 수 있는 문제를 해결하고, Expected Calibration Error (ECE)를 줄이며, 모델의 정확도를 유지하는 전략을 사용했습니다.

- **Technical Details**: 모델 캘리브레이션을 위한 방법론은 Probably Approximately Correct (PAC) 학습 프레임워크를 기반으로 하며, 합성 데이터를 생성하는 데 오픈 소스의 대형 언어 모델(Large Language Model)인 Llama 2를 활용합니다. 이 방법은 자연어 처리(NLP) 작업에서 모델의 성능을 개선하기 위해 고안되었습니다.

- **Performance Highlights**: 모델을 네 가지 자연어 처리 작업에 대해 테스트한 결과, 평균 34%의 정확도 향상과 33%의 ECE 감소를 관찰했습니다. 이는 합성 데이터가 모델의 예측 불확실성(calibration)을 줄이는 데 효과적임을 보여줍니다.



### What makes your model a low-empathy or warmth person: Exploring the Origins of Personality in LLMs (https://arxiv.org/abs/2410.10863)
Comments:
          under review

- **What's New**: 본 연구는 대형 언어 모델(LLMs)이 어떻게 장기적인 배경 요인과 단기적인 압력을 통해 인격 특성을 표현하는지를 탐구합니다. 특히, 사회 결정론 이론을 바탕으로 LLM의 성격 형성 과정에 대한 심층 분석을 제공합니다.

- **Technical Details**: 저자들은 Sparse Autoencoder(SAE) 및 representation-based 방법론을 활용하여 LLM의 장기 및 단기 인격 특성을 추출하고 분석합니다. 이를 통해 각각의 배경 요인이 모델의 인격과 안전성에 미치는 영향을 평가하며, Big Five Inventory(BFI) 및 Short Dark Triad(SD-3) 같은 인물 테스트를 통해 LLM의 인격을 평가합니다.

- **Performance Highlights**: 이 연구는 LLM의 인격 조정을 위한 새로운 기법을 제시하고, 모델의 행동을 세밀하게 수정하는 방법을 제공합니다. 또한, 배경 요인이 LLM의 안전성 평가에 미치는 영향을 분석하고, Personality-driven 요인이 LLM의 어두운 특성에 기여할 수 있는 가능성을 탐색합니다.



### Superficial Safety Alignment Hypothesis (https://arxiv.org/abs/2410.10862)
- **What's New**: 이 논문에서는 안전 제어(safety alignment)와 일반 제어(alignment) 사이의 간극을 해소하기 위해 'Superficial Safety Alignment Hypothesis (SSAH)'를 제안합니다. 이 가설은 안전 제어가 모델이 올바른 추론 방향을 선택하도록 가르쳐야 한다고 주장합니다.

- **Technical Details**: 이 연구에서는 안전 제어가 효과적으로 이루어지기 위해서는 특정 안전-critical component를 동결(freeze)하고 여분의 유닛(redundant units)을 재사용하는 것이 필요하다고 설명합니다. 특히 Exclusive Safety Unit (ESU), Exclusive Utility Unit (EUU), Complex Unit (CU), Redundant Unit (RU) 등 4가지 주목할 만한 유닛을 식별했습니다.

- **Performance Highlights**: 모델의 fine-tuning 중 7.5%의 안전-critical component를 동결하는 방식으로 모델의 안전 특성을 유지하면서 새로운 작업에 적응할 수 있음을 발견했습니다. 또한, 사전 훈련된 모델에서 20%의 여분의 유닛을 'alignment budget'으로 활용하여 안전 제어 목표를 효과적으로 달성할 수 있다는 사실을 보여주었습니다.



New uploads on arXiv(cs.IR)

### Enhancing AI Accessibility in Veterinary Medicine: Linking Classifiers and Electronic Health Records (https://arxiv.org/abs/2410.14625)
- **What's New**: 수의학 분야의 헬스케어에서, 새로운 소프트웨어 솔루션인 Anna가 기계 학습(ML) 분류기를 전자 건강 기록(EHR)과 통합하여 실시간으로 실험실 데이터를 분석할 수 있는 기능을 제공합니다.

- **Technical Details**: Anna는 기존의 EHR 시스템에 기계 학습 분류기를 통합하여, 데이터의 경직성이나 IT 자원의 제한 없이 진단 정확도를 높이고 환자 치료를 개선할 수 있는 도구입니다.

- **Performance Highlights**: Anna는 ML 분류기의 결과를 EHR의 실험실 데이터에 실시간으로 제공함으로써, 수의학적 진단의 효율성을 크게 향상시킬 수 있습니다.



### SPFresh: Incremental In-Place Update for Billion-Scale Vector Search (https://arxiv.org/abs/2410.14452)
Comments:
          SOSP 23

- **What's New**: 본 논문에서는 SPFresh라는 시스템을 소개합니다. SPFresh는 벡터 인덱스를 효율적으로 업데이트 할 수 있는 기술을 제공합니다. 특히, 고차원 벡터에 대한 Approximate Nearest Neighbor Search (ANNS)를 지원하며, 벡터 업데이트를 인플레이스(in-place)로 처리할 수 있도록 한다는 점에서 기존의 시스템들과 차별화됩니다.

- **Technical Details**: SPFresh의 핵심은 LIRE(Lightweight Incremental Rebalancing Protocol)입니다. LIRE는 벡터 파티션을 분할하고 인접한 파티션으로 벡터를 재배치하여 데이터 분포의 변동에 적응합니다. 이 방식은 전체 인덱스를 재구성하지 않고도 로컬에서 벡터를 업데이트할 수 있게 해 주어, 검색 지연(latency)과 정확성을 개선할 수 있습니다.

- **Performance Highlights**: SPFresh는 기존의 전역 재구성(global rebuild) 기반 솔루션에 비해 쿼리 지연시간과 정확성을 뛰어넘는 성능을 제공합니다. 또한, 백분율로 보았을 때 단 1%의 DRAM과 10% 미만의 코어만을 사용하여도 기존의 최첨단 기술과 비교할 때, 십억 규모 벡터 인덱스에서 1%의 일일 벡터 업데이트율을 유지하며 운영할 수 있습니다.



### Graph Neural Patching for Cold-Start Recommendations (https://arxiv.org/abs/2410.14241)
Comments:
          13 pages, accepted by Australasian Database Conference 2024. arXiv admin note: substantial text overlap with arXiv:2209.12215

- **What's New**: 이번 논문에서는 추천 시스템의 cold start 문제를 해결하기 위해 새로운 Graph Neural Patching(GNP) 모델을 도입하였습니다. GNP는warm 사용자/아이템을 위한 GWarmer와 cold-start 추천을 위한 Patching Network의 두 가지 기능을 가진 프레임워크입니다.

- **Technical Details**: 이 모델은 GNN(Graph Neural Network) 구조를 기반으로 하며, GWarmer는 기존 warm 사용자와 아이템에 대한 협업 신호를 모델링하고, Patching Network는 cold-start 추천을 위한 임베딩을 생성시켜 GWarmer의 성능을 향상시킵니다. GNP는 다양한 보조 정보를 활용하여, cold-start 사용자/아이템에 대해 추천 성능 저하 없이 분석할 수 있는 혁신적인 접근법을 제공합니다.

- **Performance Highlights**: 세 가지 벤치마크 데이터 세트에서 실시한 실험 결과, GNP는 warm 및 cold 사용자/아이템 모두에서 추천 성능이 기존 모델보다 통계적으로 유의미하게 우수한 것으로 나타났습니다. GNP는 특히 기존 warm 사용자 및 아이템에 대한 추천 품질을 유지하면서 cold-start 문제를 효과적으로 해결합니다.



### Personalized Image Generation with Large Multimodal Models (https://arxiv.org/abs/2410.14170)
- **What's New**: 본 논문은 개인화된 이미지 생성을 위한 새로운 프레임워크인 Pigeon을 제안하며, 사용자의 선호도를 포착하기 위해 노이즈가 포함된 사용자 이력 이미지와 다중 모달 지침을 효과적으로 분석하는 방법을 설명합니다.

- **Technical Details**: Pigeon은 세 가지 모듈(마스크 생성 모듈, 개인화 모듈, 이미지 생성 모듈)로 구성되어 있어, 개인화된 이미지 생성을 지원합니다. 특히, 두 단계의 선호도 정렬 기법을 도입하여 감독 데이터가 부족한 상황에서 LMMs(Large Multimodal Models)를 효과적으로 조정합니다.

- **Performance Highlights**: Pigeon은 개인화된 스티커와 영화 포스터 생성에서 폭넓은 양적 평가를 통해 기존의 여러 생성 기준선을 초과 달성하였으며, 평균적으로 사용자의 71%가 Pigeon이 생성한 이미지의 개인화 및 의미적 정렬이 우수하다고 평가했습니다.



### Optimizing Retrieval-Augmented Generation with Elasticsearch for Enhanced Question-Answering Systems (https://arxiv.org/abs/2410.14167)
- **What's New**: 이번 연구는 Retrieval Augmented Generation (RAG) 프레임워크에 Elasticsearch를 통합하여 대규모 언어 모델(LLMs)이 질문에 답변할 때의 정확도와 품질을 향상시키고자 하였습니다.

- **Technical Details**: 실험은 Stanford Question Answering Dataset (SQuAD) 2.0 버전을 테스트 데이터셋으로 사용하였고, BM25-RAG, TF-IDF-RAG, 그리고 새로 제안된 ES-RAG 방식과 같은 다양한 검색 방법의 성능을 비교하였습니다.

- **Performance Highlights**: ES-RAG는 검색 효율에서 명확한 장점을 보일 뿐 아니라 정확도 면에서도 TF-IDF-RAG보다 0.51%포인트 더 높은 성과를 보였습니다. Elasticsearch의 강력한 검색 능력과 다양한 구성 옵션으로 인해 질문-답변 시스템이 복잡한 쿼리를 더 잘 처리하고 사용자 요구에 따라 더 유연하고 효율적인 응답을 제공할 수 있습니다.



### Best in Tau@LLMJudge: Criteria-Based Relevance Evaluation with Llama3 (https://arxiv.org/abs/2410.14044)
- **What's New**: 이 연구에서는 전통적인 정보 검색 시스템 평가 방법에서의 인적 주석의 필요성을 줄이기 위해, 대형 언어 모델(LLMs)을 활용하여 쿼리에 대한 관련성 라벨을 자동으로 생성하는 새로운 접근 방식을 제안합니다. 특히, 'Four Prompts' 방법론을 통해 세부 기준에 따라 패세지를 평가하고, 이 기준들을 통합하여 최종적인 관련성 라벨을 생성하는 방법에 대해 논의합니다.

- **Technical Details**: 연구는 두 가지 가설을 설정합니다. 첫 번째 가설은 관련성을 특정 기준(정확성(exactness), 범위(coverage), 주제 적합성(topicality), 맥락 적합성(contextual fit))으로 나누어 평가하면 최종 라벨 품질이 향상된다는 것입니다. 두 번째 가설은 쿼리와 패세지 간의 언어 스타일 차이가 자동 관련성 라벨 예측에 해를 끼칠 수 있다고 설정하며, 이를 해결하기 위해 쿼리 스타일에 맞춘 패세지 요약을 생성하여 관련성을 평가합니다.

- **Performance Highlights**: 본 연구는 Summer 2024에 LLMJudge 챌린지 데이터에 기초한 실증 평가를 실시했습니다. 그 결과 'Four Prompts' 접근 방식이 Kendall의 tau 상관 계수에서 가장 높은 점수를 얻었으며, 이를 통해 인간 평가자 간의 높은 일치도를 입증하였습니다. 또한, 이 연구에서 제안한 기준 기반 점수는 평가자에게 유용한 통찰을 제공하며, 패세지가 특정 관련성 판단을 받은 이유를 이해하는 데 도움을 줍니다.



### Classifying Peace in Global Media Using RAG and Intergroup Reciprocity (https://arxiv.org/abs/2410.13865)
Comments:
          6 pages, 1 figure

- **What's New**: 이 연구는 글로벌 미디어에서 평화의 통찰력을 식별하기 위한 새로운 접근법을 제안합니다. Retrieval Augmented Generation (RAG) 모델과 Positive 및 Negative Intergroup Reciprocity (PIR/NIR) 개념을 활용하여 미디어 기사의 상호작용 관계를 보다 정확하고 의미 있게 분석합니다.

- **Technical Details**: 이 연구는 RAG 모델을 이용해 미디어 기사를 분석하고, Positive Intergroup Reciprocity (PIR)와 Negative Intergroup Reciprocity (NIR)를 식별하는 절차를 포함합니다. 데이터는 News On the Web (NOW) 데이터셋에서 수집하였으며, 700,000개의 기사와 58백만 단어로 구성되어 있습니다. 연구 방법론은 기사를 고차원 벡터로 임베딩하고, LLM을 이용한 쿼리 및 코사인 유사도를 통한 기계 학습 분류를 포함합니다.

- **Performance Highlights**: 이 연구는 여러 국가들 간의 평화 수준에 대한 통찰력을 제공하며, 미디어 중재가 어떻게 PIR 또는 NIR에 따라 국가를 분류할 수 있는지를 보여줍니다. 기존의 평화 측정 방법과는 다른 대안적 관점을 제공하며, RAG 모델을 통해 현실 세계에서의 PIR/NIR 측정을 시도합니다.



### SIMformer: Single-Layer Vanilla Transformer Can Learn Free-Space Trajectory Similarity (https://arxiv.org/abs/2410.14629)
- **What's New**: 이번 연구에서는 기존의 복잡한 모델을 간소화하고, 효율성과 효과성을 동시에 개선할 수 있는 방법으로 SIMformer라는 단일 레이어 바닐라 트랜스포머 인코더 기반 모델을 제안합니다.

- **Technical Details**: SIMformer는 단일 레이어 바닐라 트랜스포머 인코더를 특징 추출기로 사용하고, Euclidean distance 대신 특정 유사도 함수(예: Hausdorff를 위해 Chebyshev distance 및 DTW를 위해 cosine) 을 활용하여 다양한 지표를 근사합니다.

- **Performance Highlights**: SIMformer는 널리 사용되는 4개의 벤치마크(Porto, T-Drive, Geolife, AIS)에서 평균 27.59%의 top-k hit 비율 개선을 보여주었고, 속도 및 메모리 사용량에서도 각각 30% 더 빠르며 10% 절약할 수 있었습니다.



### ChartifyText: Automated Chart Generation from Data-Involved Texts via LLM (https://arxiv.org/abs/2410.14331)
- **What's New**: 이 연구는 데이터와 관련된 텍스트에서 자동으로 차트를 생성하여 정보를 효과적으로 전달할 수 있는 방법을 제안합니다. 기존 방식의 한계를 극복하기 위해 LLM(대형 언어 모델)을 활용하여 데이터 추출과 차트 생성을 동시에 수행하는 ChartifyText라는 혁신적인 접근법을 소개합니다.

- **Technical Details**: ChartifyText는 두 가지 주요 모듈로 구성됩니다: 첫째, tabular data inference 모듈은 입력된 텍스트에서 데이터를 추론하여 테이블 형식으로 구성하고, 둘째, expressive chart generation 모듈은 이 데이터를 기반으로 직관적이고 간결한 차트를 생성합니다. 데이터의 범위, 불확실성, 누락된 데이터 값 및 주관적인 감정을 명시적으로 고려합니다.

- **Performance Highlights**: 대규모의 실제 데이터가 포함된 텍스트 문서에서 ChartifyText의 효과를 평가한 결과, 사용자들은 데이터 관련 텍스트의 이해도가 향상되었음을 보고하였습니다. 전문가 인터뷰와 사용자 연구를 통해 ChartifyText의 유용성과 효과성이 입증되었습니다.



### Towards Robust Transcription: Exploring Noise Injection Strategies for Training Data Augmentation (https://arxiv.org/abs/2410.14122)
Comments:
          Accepted to the Late-Breaking Demo Session of the 25th International Society for Music Information Retrieval (ISMIR) Conference, 2024

- **What's New**: 최근 자동 피아노 전사(Automatic Piano Transcription, APT) 기술의 발전에도 불구하고, 노이즈가 많은 환경에서의 시스템 성능이 저하되는 문제는 거의 탐구되지 않았습니다. 본 연구는 다양한 신호 대 잡음 비율(Signal-to-Noise Ratio, SNR)에서 백색소음(white noise)을 주입하여 APT 모델의 성능을 평가합니다.

- **Technical Details**: 본 연구에서는 Onsets and Frames 모델을 활용하여, 백색소음을 주입한 데이터로 훈련된 모델의 성능을 평가했습니다. 실험에는 -6dB에서 45dB까지의 SNR 구간을 고려하여 적어도 18개의 서로 다른 SNR 수준에서 모델의 성능을 평가했습니다. 데이터는 MAESTRO v3 데이터셋을 사용했으며, 클린 오디오와 노이즈-주입 오디오의 비율을 나타내는 청정 대 노이즈 비율(Clean-to-Noise Ratio, CNR)을 도입했습니다.

- **Performance Highlights**: 실험 결과, 노이즈 주입 데이터로 훈련된 모델은 낮은 SNR에서 클린 데이터로만 훈련된 모델보다 현저하게 성능이 우수하며, 고 SNR에서는 이 두 모델 간의 차이가 줄어드는 경향이 관찰되었습니다. 통계적 분석(t-test)을 통해 얻은 Precision, Recall, F1 스코어에서 유의미한 차이가 도출되었습니다. 이 연구는 다양한 노이즈 환경에 대한 강인성을 강화하는 것이 클린 환경에서의 성능 저하와 충돌하지 않음을 시사합니다.



### Lightweight Correlation-Aware Table Compression (https://arxiv.org/abs/2410.14066)
Comments:
          Third Table Representation Learning Workshop (TRL 2024)

- **What's New**: 이 논문은 데이터 레이크를 위한 새로운 경량 프레임워크인 'Virtual'을 소개합니다. 이 프레임워크는 기존 공개 저장 형식들과의 통합을 통해 데이터 상호 연관성을 자동으로 활용하여 파일 크기를 최대 40% 감소시키는 성과를 달성했습니다. 또한, 상대적으로 적은 스캔 성능 저하만 발생합니다.

- **Technical Details**: Virtual 프레임워크는 세 가지 주요 구성 요소로 구성되어 있습니다: (a) FunctionDriller, (b) Optimizer, (c) Compressor. 이들은 각각 상호 연관성을 탐지하고, 선택하며, 실제 압축을 수행하는 단계에 해당합니다. 특히 FunctionDriller는 주어진 테이블 내에서 열 간의 상관관계를 식별합니다.

- **Performance Highlights**: 실험 결과, Virtual은 Apache Parquet نسبت해 데이터 크기를 최대 40%까지 줄일 수 있었으며, 가상화된 열에 대한 스캔 속도 저하가 거의 발생하지 않았습니다. 이는 데이터 분석을 위한 신뢰성 높은 대안을 제공하는 중요한 발전입니다.



### P4GCN: Vertical Federated Social Recommendation with Privacy-Preserving Two-Party Graph Convolution Networks (https://arxiv.org/abs/2410.13905)
- **What's New**: 최근 그래프 신경망(GNNs)은 소셜 추천 시스템에서 자주 사용되고 있으나, 사용자 프라이버시 및 비즈니스 제약으로 인해 다른 플랫폼에서의 소셜 정보를 직접적으로 이용하기 어려운 문제가 있음. 이를 해결하기 위해 우리는 민감한 소셜 정보에 직접 접근하지 않고 추천 정확도를 향상시키는 새로운 수직 연합 소셜 추천 방법을 제안함.

- **Technical Details**: 제안된 방법인 P4GCN(Privacy-Preserving Party-to-Party Graph Convolution Networks)은 두 개의 파티 간의 협력적 데이터 처리 중 데이터 프라이버시를 보장하는 Sandwich-Encryption 모듈을 도입함. 이 방법은 GNN 모델을 최적화하기 위한 안전한 사회 추천 프로토콜을 개발하는 것을 목표로 함.

- **Performance Highlights**: 4개의 실제 데이터셋에서 실시한 실험 결과, P4GCN은 추천 정확도에서 최신 기술들을 초능가하며 통신 효율성 또한 향상됨을 입증함. 또한, 프라이버시 예산의 유틸리티에 미치는 영향에 대해서도 평가함.



### Pessimistic Evaluation (https://arxiv.org/abs/2410.13680)
- **What's New**: 이 연구는 정보 접근 시스템 평가의 새로운 접근 방식을 제안합니다. 기존의 평균 유틸리티 기반 평가 방식이 아닌, 최악의 경우 유틸리티에 초점을 맞춘 비관적(pessimistic) 평가 방법을 주장합니다.

- **Technical Details**: 비관적 평가는 정보 과학 커뮤니티의 평등한 정보 접근에 대한 기존 연구에 기반을 두고 있으며, 정치 이론에서 잘 제정된 방법론을 토대로 합니다. 연구에서는 lexicographic minimum을 비관적 평가의 이론적으로 타당한 방법으로 소개합니다.

- **Performance Highlights**: 이 연구 결과는 비관적 평가 방법이 시스템의 행동을 더 잘 이해하는 데 도움이 될 수 있으며, 특히 사회적 선이라는 원칙과 관련된 상황에서 기존의 평가 방법을 보완할 수 있음을 보여줍니다.



### Large Language Models as Narrative-Driven Recommenders (https://arxiv.org/abs/2410.13604)
Comments:
          Under review; 19 pages

- **What's New**: 이번 연구에서는 대형 언어 모델(LLMs)을 사용하여 자유형식의 텍스트로 표현된 영화 추천 요청에 대한 개인화된 추천을 제공하기 위한 새로운 접근 방식을 탐구하였습니다. 특히, reddit의 영화 추천 커뮤니티에서 수집된 데이터셋을 활용하여 38개의 오픈소스 및 클로즈드 소스 LLM의 성능을 비교하였습니다.

- **Technical Details**: 이 연구는 zero-shot, identity, few-shot 프롬프트 기법을 사용하여 LLM이 사용자 요청을 자연어로 처리하고 관련 영화를 추천할 수 있는지 평가합니다. 평가된 LLM은 크기에 따라 분류되며, 각 모델은 기본적인 zero-shot 프롬프트를 통해 추천 정확도를 높일 수 있음을 보여줍니다.

- **Performance Highlights**: LLMs는 기존의 추천 알고리즘보다 더 높은 성능을 보이며, 특히 GPT-4o는 기본 성능보다 70% 더 높은 추천 성능을 보였습니다. 중간 크기의 오픈소스 모델도 상대적으로 높은 성능을 유지하며 클로즈드 소스 모델과 비교하여 경쟁력을 보여주었습니다.



### Cross-Domain Sequential Recommendation via Neural Process (https://arxiv.org/abs/2410.13588)
Comments:
          Work in progress

- **What's New**: 이 논문은 Cross-Domain Sequential Recommendation (CDSR)에서 중첩되지 않은 사용자 행동의 잠재력을 활용하는 방법을 탐구합니다. CDSR의 기존 방법들이 주로 중첩 사용자 행동에 집중함에 따라 발생하는 한계를 극복하기 위해, 저자들은 새로운 CDSRNP라는 프레임워크를 제안합니다.

- **Technical Details**: CDSRNP는 메타 학습(meta-learning) 접근 방식을 활용하여, 지원 세트(support set)에서 관찰된 중첩 사용자 행동을 샘플링하고, 쿼리 세트(query set)에서 비중첩 사용자 예측을 지원합니다. 이는 Neural Processes(NP)를 이용하여 prior와 posterior 샘플 분포를 학습하고, 이는 다양한 도메인 간 상호작용 패턴을 이해하는 데 도움을 줍니다.

- **Performance Highlights**: 저자들은 CDSRNP가 두 개의 실제 데이터 세트에서 기존의 최첨단 방법들과 비교하여 눈에 띄는 성능 향상을 달성했음을 보여주었습니다. CDSRNP는 중첩 사용자 행동을 고려함으로써 CDSR의 새로운 패러다임을 제시하고, 비중첩 사용자 예측을 위한 세밀한 관심 적응 레이어를 설계하였습니다.



### Generate and Instantiate What You Prefer: Text-Guided Diffusion for Sequential Recommendation (https://arxiv.org/abs/2410.13428)
- **What's New**: 최근 생성 추천 시스템의 발전 특히 Sequential Recommendation (순차 추천) 작업에서 새로운 아이템에 대한 일반화 능력을 띄게 되었습니다. 이와 관련된 Diffusion-based Generative Recommendation (확산 기반 생성 추천)이 데이터 분포를 캡처하고 고품질 샘플을 생성할 수 있는 능력을 가지며 효과적인 도구로 부각되었습니다. 그러나 두 가지 주요 문제 점이 지적되었습니다: 1) 오라클 아이템의 데이터 분포 일관성 부족, 2) 역사적 상호 작용을 넘어서 더 유익한 제어 신호로의 확장 어려움.

- **Technical Details**: iDreamRec (intention-guided DreamRec)은 구체적인 사전 지식을 활용해 아이템 임베딩을 구축하며, 상세한 텍스트 설명과 고급 Text Embedding Models (TEM)을 통해 수치화된 데이터로 변환합니다. 이를 통해 생성 과정에서 오라클 아이템 생성을 위한 제어 신호인 의도 지침을 통합할 수 있습니다. TMP와 결합한 상태에서, iDreamRec은 조건부 확산 모델을 훈련시켜 아이템 임베딩을 정렬합니다.

- **Performance Highlights**: 4개의 데이터 세트에서 실험 결과, iDreamRec는 기존의 확산 기반 생성 추천 시스템들 (예: DreamRec, DiffRec)에 비해 향상된 성능을 보여주었으며, 의도 지침을 통합하여 보다 정밀하고 효과적인 추천 생성을 가능하게 하였습니다.



### Context-aware adaptive personalised recommendation: a meta-hybrid (https://arxiv.org/abs/2410.13374)
- **What's New**: 이번 논문에서는 정보를 종합할 수 있는 메타 하이브리드 추천 시스템을 제안하고 있습니다. 이 시스템은 사용자마다 최적의 추천 알고리즘을 예측하기 위해 Machine Learning을 사용할 수 있도록 개발되었습니다.

- **Technical Details**: 제안된 메타 하이브리드 추천 시스템은 사용자에 대한 맥락적 및 선호 정보를 기반으로 다양한 추천 알고리즘 중에서 최고의 성능을 발휘하는 것을 선택합니다. 오프라인 평가를 위해 MovieLens와 The Movie DB 데이터셋을 사용하였으며, 이를 통해 각 세션과 사용자에 적합한 추천기를 선택할 수 있습니다.

- **Performance Highlights**: 이 연구에서 제안한 메타 하이브리드 추천 시스템은 정상화된 Discounted Gain과 Root Mean Square Error 메트릭에서 기존의 개별 접근 방식보다 20-50% 더 나은 성능을 보였습니다. 그러나 사용자의 표준 정보 기반으로 최적 성능을 달성하기란 어려운 과제입니다.



### Starbucks: Improved Training for 2D Matryoshka Embeddings (https://arxiv.org/abs/2410.13230)
- **What's New**: 이 논문에서는 Starbucks라는 새로운 Matryoshka 유사 임베딩 모델 훈련 전략을 제안합니다. 이 전략은 미세 조정(fine-tuning) 및 사전 훈련(pre-training) 단계를 포함하여 2D Matryoshka 모델의 접근성을 높이고 효과성을 향상시키는 데 중점을 두고 있습니다.

- **Technical Details**: Starbucks는 두 가지 주요 프로세스로 구성됩니다: Starbucks Masked Autoencoding (SMAE) 사전 훈련 및 Starbucks Representation Learning (SRL) 미세 조정입니다. SRL 단계에서 특정 레이어-차원 쌍의 고정 목록을 제공하여 손실을 계산하고, SMAE에서는 다양한 레이어-차원 쌍으로의 마스크 자기 인코딩 언어 모델링을 적용합니다.

- **Performance Highlights**: 실험 결과, Starbucks 모델은 2D Matryoshka 모델보다 성능이 향상되어 별도로 훈련한 모델과 동등한 효과성을 보여주었습니다. 이는 의미적 텍스트 유사성 및 검색 벤치마크에서 확인되었습니다.



### Transformers4NewsRec: A Transformer-based News Recommendation Framework (https://arxiv.org/abs/2410.13125)
- **What's New**: Transformers4NewsRec는 새로운 Python 프레임워크로, 다양한 뉴스 추천 모델의 성능을 비교하고 통합할 수 있는 유연한 기능을 제공합니다. 이 프레임워크는 Transformer 기반 아키텍처와 전통적인 DL 기법, 그래프 기반 방법을 활용하여 뉴스 추천을 개선하는 데 초점을 맞추고 있습니다.

- **Technical Details**: 이 프레임워크는 데이터 모듈, 모델 모듈, 평가 모듈, 유틸리티 도구 모듈의 4가지 핵심 컴포넌트로 구성되어 있으며, 다양한 모델과 데이터셋을 시험하고 실험 설정을 유연하게 조정할 수 있는 명령 줄 인터페이스를 제공합니다. 또한, 기존 제로 패딩 방식을 대체하는 새로운 연결 기반 배치 방법을 제안하여 훈련 및 평가 속도를 100% 이상 향상시킵니다.

- **Performance Highlights**: BATM-NR와 GLORY 모델은 MIND-SMALL 및 MIND-LARGE 데이터셋에서 전통적인 모델들보다 더 높은 성능을 보여주었으며, 특히 뉴스 제목과 본문을 함께 사용할 때 그 성능이 크게 향상되었습니다. BERT와 같은 사전 훈련된 언어 모델을 활용한 경우, 모델 성능이 더욱 개선되는 경향을 보였습니다.



### Preference Diffusion for Recommendation (https://arxiv.org/abs/2410.13117)
- **What's New**: PreferDiff는 신규 개인화 순위 손실 함수로, 기존의 추천 시스템들이 사용하는 전통적인 목표 대신에Diffusion Models(확산 모델) 특화된 최적화 목표를 제안합니다.

- **Technical Details**: PreferDiff는 BPR(Bayesian Personalized Ranking)을 로그 가능도 순위 목표로 변환하고 여러 개의 네거티브 샘플을 통합하여 사용자 선호도를 더 잘 포착하도록 설계되었습니다. 변분 추론(variational inference)을 이용해 계산의 어려움을 극복하고 오차 기준에서 MSE 대신 cosine error를 적용하여 추천 작업에 대한 정렬을 개선합니다. 또한, 생성(generation) 및 선호(preference) 간의 균형을 맞춤으로써 DMs의 학습 안정성을 향상시킵니다.

- **Performance Highlights**: 세 가지 벤치마크에서 진행된 실험을 통해, PreferDiff는 우수한 추천 성능을 보였으며 일반적인 연속 추천(sequential recommendation) 능력에서 주목할 만한 결과를 나타냈습니다.



### Leveraging Large Language Models to Enhance Personalized Recommendations in E-commerc (https://arxiv.org/abs/2410.12829)
Comments:
          This paper has been accepted by the 5th International Conference on Electrical, Communication and Computer Engineering (ICECCE 2024)

- **What's New**: 이번 연구는 대규모 언어 모델(LLM)이 전자상거래의 개인화 추천 시스템에 어떻게 적용될 수 있는지를 심도 있게 탐구합니다. 전통적인 추천 알고리즘의 한계를 극복하기 위해 LLM 기반의 추천 시스템 프레임워크를 제안하였습니다.

- **Technical Details**: 비교 실험을 통해 LLM 기반 추천 모델이 정밀도(precision), 재현율(recall), F1 점수, 평균 클릭률(CTR), 추천 다양성 등의 여러 핵심 지표에서 유의미한 개선을 보여주었습니다. LLM 모델의 정밀도는 0.75에서 0.82로 향상되었고, 재현율은 0.68에서 0.77로 증가하였으며, F1 점수는 0.71에서 0.79로 향상되었습니다. 평균 클릭률은 0.56에서 0.63으로 증가하였고, 추천 다양성은 41.2% 증가하여 0.34에서 0.48로 개선되었습니다.

- **Performance Highlights**: LLM은 사용자 의견과 제품 설명 데이터에 대한 심층적인 의미 이해를 통해 사용자의 암묵적인 요구를 효과적으로 파악하고, 맥락 데이터(contextual data)를 결합하여 동적인 추천을 생성하여 더 정확하고 다양한 결과를 제공합니다. 이는 사용자 경험을 개선하고 플랫폼의 판매 성장에 기여할 수 있는 중요한 연구 결과입니다.



### Optimizing and Evaluating Enterprise Retrieval-Augmented Generation (RAG): A Content Design Perspectiv (https://arxiv.org/abs/2410.12812)
Comments:
          6 pages, 4 figures, to be published in ICAAI 2024 conference proceedings

- **What's New**: 본 논문에서는 리뷰 기반 생성(Retrieval-augmented generation, RAG) 솔루션의 구현 및 유지 관리 경험을 공유하고 있습니다. 기존 RAG 문헌에서 일반적으로 제시된 패턴과의 차별성을 강조하며, 모듈화되어 있고 모델에 의존하지 않는 접근 방식을 중심으로 해결책을 제시합니다.

- **Technical Details**: RAG의 기본 원리는 지식 기반에서 관련 콘텐츠를 검색하고, 이 콘텐츠에 기반한 프롬프트를 작성한 후, LLM에게 출력을 생성하도록 요청하는 것입니다. 그러나 본 팀의 RAG 솔루션은 벡터 데이터베이스에 의존하지 않아 다양한 검색 기법과 LLM을 사용합니다. 지식 기반 콘텐츠 최적화 및 실시간 사용자 질문에 대한 테스트와 평가 방안도 다루고 있습니다.

- **Performance Highlights**: 기존 RAG 평가 지표는 기존 사용자 질문에 대한 응답 평가에 유용하지 않아, 유연한 '인간 선도' 접근 방식이 필요하다는 점을 강조하고 있습니다. 지식 기반 콘텐츠 개선을 통해 RAG 솔루션의 성공 여부에 큰 영향을 미칠 수 있음을 보여줍니다.



### Ads Supply Personalization via Doubly Robust Learning (https://arxiv.org/abs/2410.12799)
Comments:
          Accepted by CIKM'24

- **What's New**: 이 논문에서는 광고 공급 개인화를 위한 새로운 프레임워크를 제시합니다. 이 프레임워크는 데이터 수집 정책을 통해 정보를 최적 활용하여 장기적 치료 효과 추정의 정확성을 크게 향상시킵니다. 또한, 낮은 복잡도로 인해 기존 방법들보다 계산 비용이 절감되고, 대규모 애플리케이션에 확장 가능하다는 장점을 지니고 있습니다.

- **Technical Details**: 제안된 프레임워크는 Doubly Robust Learning (DRL)을 기반으로 하여 장기적인 인과 효과를 모델링하는 가벼운 솔루션을 제공합니다. DRT 프레임워크는 데이터 수집과 모델링 단계에서 정보를 효율적으로 활용해 성능 향상 및 모델 복잡성 감소를 이끌어내며, 기존의 광고 및 유기 콘텐츠 배포 시스템과 통합이 용이합니다.

- **Performance Highlights**: 오프라인 실험과 온라인 생산 테스트를 통해, 이 프레임워크는 몇 달 간에 걸쳐 비즈니스 주요 지표에서 상당한 개선을 지속적으로 보여주었으며, 세계에서 가장 큰 소셜 미디어 플랫폼 중 하나에 완전히 배포되었습니다.



### Disaggregating Embedding Recommendation Systems with FlexEMR (https://arxiv.org/abs/2410.12794)
- **What's New**: FlexEMR는 embedding 기반 추천 (EMR) 모델의 비효율성을 해결하기 위한 새로운 분산 시스템으로, 네트워크 데이터 전송의 효율성을 개선하고 총 비용 소유권을 줄이기 위한 디자인을 제안합니다.

- **Technical Details**: FlexEMR는 두 가지 기술 세트를 통해 네트워크 문제를 해결합니다. 첫 번째는 embedding 조회의 시간적 및 공간적 지역성을 활용하여 데이터 이동을 줄이고, 두 번째는 다중 스레드 RDMA 엔진을 설계하여 동시 조회 하위 요청을 최적화하는 것입니다.

- **Performance Highlights**: 초기 프로토타입에서 FlexEMR은 원격 embedding 조회의 성능을 향상시켰으며, queuing latency를 크게 줄이고, 응답 혼잡을 완화하는 데 기여했습니다.



### Disjointness Violations in Wikidata (https://arxiv.org/abs/2410.13707)
Comments:
          Sixth International Knowledge Graph and Semantic Web Conference

- **What's New**: 이 논문은 Wikidata에서의 불일치 체크(disjointness checks)의 현재 모델링을 분석하고, 이를 통해 발생하는 불일치 위반(disjointness violations)의 패턴과 원인을 확인하였습니다. SPARQL 쿼리를 사용해 각각의 원인을 규명하고, 서로 충돌하는 정보를 식별 및 수정할 수 있는 공식을 제시합니다.

- **Technical Details**: Wikidata는 1억 개 이상의 객체를 포함하는 대규모 지식 그래프입니다. 본 논문에서는 RDF(리소스 기술 프레임워크)를 사용하여 Wikidata에서 쌍별 불일치 클래스(pairwise disjoint classes)의 정보를 수집하였습니다. SPARQL 쿼리를 작성하여 불일치 유니온 문장(disjoint union statements)의 쌍을 찾아내었습니다.

- **Performance Highlights**: 논문에서 제안한 방식은 불일치 상황을 정량화하고, 성능을 개선하여 사용자가 문제를 식별하고 수정하는 효율성을 높이는 데 기여할 수 있습니다. 총 758개의 불일치 유니온 문장이 631개 클래스에서 생성되었으며, 7,027개의 쌍별 불일치 문장(pairwise disjoint statements)이 도출되었습니다.



### Comparing the Utility, Preference, and Performance of Course Material Search Functionality and Retrieval-Augmented Generation Large Language Model (RAG-LLM) AI Chatbots in Information-Seeking Tasks (https://arxiv.org/abs/2410.13326)
Comments:
          12 pages, 4 figures

- **What's New**: 최근의 대형 언어 모델(LLMs)을 활용한 AI 챗봇이 교육 지원 도구로서의 가능성을 탐구하기 위한 연구가 진행됨. 이 연구는 LLM 기반 챗봇의 성능을 전통적인 검색 기능과 비교하여 학생들을 지원하는 방법을 조사함.

- **Technical Details**: 실험에서는 14명의 참가자가 웹 소프트웨어 개발 과정의 과제를 수행. 참가자는 두 그룹으로 나뉘어 LLM 챗봇과 검색 기능에 대한 접근 순서를 다르게 설정. LLM 챗봇은 retrieval-augmented generation(RAG) 기술을 활용하여 추가 정보를 제공.

- **Performance Highlights**: LLM 기반 챗봇과 전통적인 검색 기능 모두 유용하다고 인식되었으며, 특정 과제에서 더 잘 작동하는 경향이 있음. LLM 챗봇을 먼저 사용한 그룹은 검색 기능을 더 선호했고, 그 반응은 연구에서 흥미로운 결과로 나타짐.



### SBI-RAG: Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation (https://arxiv.org/abs/2410.13293)
Comments:
          Accepted to the 4th MATH-AI Workshop at NeurIPS'24

- **What's New**: 본 논문에서는 Schema-Based Instruction Retrieval-Augmented Generation (SBI-RAG) 프레임워크를 제안합니다. 이 프레임워크는 대형 언어 모델(LLM)을 통합하여 수학 단어 문제(MWP)를 해결하는 과정을 지원하며, 기존의 Schema-Based Instruction(SBI) 방법을 바탕으로 발전했습니다.

- **Technical Details**: SBI-RAG는 기본적으로 네 가지 주요 부분으로 나뉩니다: 1) Schema Classifier, 2) Prompt Creation, 3) Context Retrieval, 4) Answer and Response Generation. Schema Classifier는 DistilBERT를 기반으로 하여 특정 문제에 적합한 schema를 예측하고, 그에 따라 schema-specific prompt를 생성합니다. 이후 Retrieval-Augmented Generation(RAG) 프레임워크를 이용하여 관련 문서를 검색하고, LLM을 통해 구체적인 단계별 해답을 생성합니다.

- **Performance Highlights**: GSM8K 데이터셋에서의 평가 결과, SBI-RAG는 GPT-4 및 GPT-3.5 Turbo와 비교하여 문제 해결의 정확성과 추론의 명료성을 향상시키는 데 효과적임을 보였습니다. 새로운 'reasoning score' 메트릭을 도입하여 LLM의 해결 과정의 질을 평가하였으며, 이는 학생들의 교육적 이점을 제공할 가능성이 있습니다.



### Disentangling Likes and Dislikes in Personalized Generative Explainable Recommendation (https://arxiv.org/abs/2410.13248)
- **What's New**: 최근 설명 가능한 추천 시스템에 대한 연구는 표준 텍스트 생성 문제로 접근하며, 모델을 예측된 텍스트와 실제 텍스트 간의 유사성을 기반으로 평가합니다. 그러나 이 접근법은 사용자(구매 후) 감정을 정확히 반영하는지 여부를 간과합니다. 이 연구에서는 사용자의 감정을 중점적으로 고려하는 새로운 데이터셋과 평가 방법을 소개합니다.

- **Technical Details**: 우리는 LLM(Long Language Model)을 사용하여 사용자 구매 후 리뷰에서 긍정적 및 부정적 의견을 명시적으로 추출하여 데이터셋을 구성합니다. 시스템을 평가할 때 생성된 설명이 1) 사용자 감정과 잘 일치하는지, 2) 목표 아이템에 대한 사용자 의견의 긍정적 및 부정적 식별을 정확히 수행하는지에 대한 두 가지 기준을 제안합니다.

- **Performance Highlights**: 여러 최신 모델을 우리의 데이터셋에서 벤치마킹하였으며, 기존 지표에서 높은 성과를 달성하더라도 생성된 설명이 사용자 감정과 잘 일치하지 않을 수 있음을 보여줍니다. 또한, 목표 아이템에 대한 사용자(예측된) 평가가 모델에 직접 입력될 경우, 기존 모델들이 보다 감정 인식적인 설명을 제공할 수 있음을 발견하였습니다.



### Research on Travel Route Planing Problems Based on Greedy Algorithm (https://arxiv.org/abs/2410.13226)
- **What's New**: 이 연구에서는 초기 경로 탐색 및 관광객의 개인화 요구를 충족하는 최적화된 경로 계획 알고리즘이 제안되었습니다. 특히, PCA(Principal Component Analysis) 및 KMO(Kaiser-Meyer-Olkin) 테스트와 TOPSIS(TOPSIS: Technique for Order Preference by Similarity to Ideal Solution) 기법을 통해 도시 평가 지표의 차원 축소 및 종합 평가를 수행했습니다.

- **Technical Details**: 연구에서는 PCA를 사용하여 도시 평가 지표의 차원을 축소하고, KMO 테스트를 통해 데이터 적합성을 판단하고, TOPSIS 및 엔트로피 가중치 방법을 통해 데이터를 종합 평가했습니다. 경로 최적화를 위해서는 그리디 알고리즘이 사용되었으며, 관광 명소 방문에 소요되는 시간을 고려한 경로 계획이 이루어졌습니다.

- **Performance Highlights**: 이 알고리즘은 352개의 도시에서 100개의 관광 명소 데이터를 활용하여 관광객에게 최적화된 여행 경로를 제공함으로써 여행 비용을 줄이고 현지 최적해(local optimum) 문제를 피하는 데 기여합니다. 결과적으로 관광객의 요구에 맞춘 맞춤형 경로 계획을 통해 효율적인 여행 경험을 지원합니다.



### MixEHR-Nest: Identifying Subphenotypes within Electronic Health Records through Hierarchical Guided-Topic Modeling (https://arxiv.org/abs/2410.13217)
- **What's New**: MixEHR-Nest는 전자 건강 기록(EHR) 데이터를 활용하여 고유한 하위 표현형(sub-phenotype) 주제를 유도하는 새로운 지침(topic model) 모델입니다. 이 모델은 경험적인 표현형 개념(PheCodes, CCS 코드를 포함)으로 초기화된 하위 주제를 탐지하여 질병 패턴을 더욱 세분화하여 나타냅니다.

- **Technical Details**: MixEHR-Nest는 다중 모달(multi-modal) EHR 데이터에서 1500개 이상의 표현형으로부터 뚜렷한 하위 표현형 주제를 유도할 수 있는 구조화된 하이라키(topic model)입니다. 이 모델은 각 환자의 의료 기록을 문서(document)로, 코드(예: ICD 코드)를 단어 토큰(word tokens)으로 간주하여 학습합니다. 이 연구는 하위 표현형 주제의 묘사, 다중 유형의 EHR 정보 학습, 높은 해석 가능성을 통한 자동 하위 표현형 유도를 포함합니다.

- **Performance Highlights**: MixEHR-Nest는 ICU 환자 사망률 예측, 당뇨병 환자의 초기 인슐린 치료 예측에서 성능을 향상시켰습니다. 또한 MixEHR-Nest는 같은 표현형 아래에서 연령 분포의 뚜렷한 하위 표현형을 확인함으로써 다양한 질병에 걸쳐 질병의 진행 및 중증도를 예측하는 데 기여했습니다.



### Retrieval-Enhanced Named Entity Recognition (https://arxiv.org/abs/2410.13118)
Comments:
          13 pages, 6 figures, 3 tables

- **What's New**: RENER (Retrieval-Enhanced Named Entity Recognition)는 In-Context Learning (ICL) 및 정보 검색 기술을 결합하여 명명된 개체 인식(NER) 작업에서 성능을 향상시키기 위해 제안된 새로운 방법입니다. 이 방법은 입력 텍스트에 대해 유사한 예제를 검색하고 이를 언어 모델에 통합하여 NER을 수행할 수 있도록 합니다.

- **Technical Details**: RENER는 언어 모델과 정보 검색 알고리즘에 독립적이며, 언어 모델과의 결합이 최소화된 상태로 새로운 명명된 개체를 인식하는 데 사용할 수 있습니다. 이 과정에서 언어 모델에 직접적인 의존성이 없으며, 다양한 NER 도메인에 쉽게 배포할 수 있습니다. 또한 CrossNER 컬렉션에서의 실험 결과, RENER는 최신 기술(State-of-the-Art) 성능을 달성하였으며, 정보 검색 기술을 사용할 경우 F-score를 최대 11% 상승시킬 수 있음을 보여주었습니다.

- **Performance Highlights**: RENER는 CrossNER 데이터셋에서 최신 성능을 달성하였으며, 정보 검색 기법을 활용함으로써 비슷한 시스템 대비 성능을 최대 11% 향상시킬 수 있었습니다. 이는 NER 작업에서 ICL과 RAG 기법을 성공적으로 결합했음을 나타냅니다.



### Is Semantic Chunking Worth the Computational Cost? (https://arxiv.org/abs/2410.13070)
- **What's New**: 최근 Retrieval-Augmented Generation (RAG) 시스템에서 문서를 의미적으로 일관된 세그먼트로 분할하는 semantic chunking이 인기를 얻고 있습니다. 본 연구는 semantic chunking이 보다 간단한 fixed-size chunking에 비해 실질적인 이점을 제공하는지에 대한 체계적인 평가를 진행했습니다.

- **Technical Details**: 연구팀은 document retrieval, evidence retrieval, answer generation 세 가지 일반적인 retrieval 관련 작업을 통해 semantic chunking의 효용성을 평가했으며, 다양한 chunking 전략을 비교하여 최적의 성능을 갖는 chunker를 확인했습니다. 또한, 두 가지 chunking 전략으로 fixed-size chunker와 breakpoint-based semantic chunker, clustering-based semantic chunker를 채택하여 평가하였습니다.

- **Performance Highlights**: 결과적으로, semantic chunking이 특정 상황에서 일부 이점을 보였지만, 이러한 이점들은 불일치하며 고정 크기 청크에 대한 계산 비용을 정당화할 만큼 충분하지 않다는 것을 보였습니다. 이는 RAG 시스템에서 더 효율적이고 적응적인 chunking 전략의 필요성을 강조합니다.



### Supply Chain Network Extraction and Entity Classification Leveraging Large Language Models (https://arxiv.org/abs/2410.13051)
Comments:
          11 pages, 4 figures

- **What's New**: 이 논문에서는 자연어 처리(NLP) 및 대형 언어 모델(LLM)를 활용하여 비정형 텍스트 데이터를 기반으로 공급망 그래프를 구축하는 새로운 접근 방식을 제안합니다. 특히 토목 공학 산업을 사례 연구로 삼아 LLM이 기업, 프로젝트 등의 숨겨진 관계를 발견할 수 있는 방법을 보여줍니다.

- **Technical Details**: 본 연구는 데이터 수집, 프롬프트 엔지니어링, 그래프 구축, 엔티티 분류의 네 가지 주요 단계로 구성된 방법론을 적용합니다. 데이터 수집은 공개 소스의 뉴스 기사를 통해 이루어지며, 각 기업에 대해 2018년부터 2023년까지 연도별로 최소 10개의 뉴스 기사를 수집하여 총 50개의 원시 텍스트 데이터 포인트를 확보합니다. 이를 통해 각 기업의 활동에 대한 포괄적인 관점을 유지합니다.

- **Performance Highlights**: LLM으로 특정 산업에 맞춰 세부 조정(fine-tuning)을 수행함으로써 엔티티 분류의 정확도가 향상되었으며, 이는 산업별 공급망 분석의 잠재력을 강조합니다. 본 연구는 LLM을 통해 공급망 네트워크 모델링의 자동화를 가능하게 한 첫 번째 사례로, 공급망 동학에 대한 깊이 있는 통찰력을 제공합니다.



### LLM Confidence Evaluation Measures in Zero-Shot CSS Classification (https://arxiv.org/abs/2410.13047)
- **What's New**: 이 논문은 데이터 주석 작업에서의 대형 언어 모델(LLM)의 신뢰성을 평가하기 위해 세 가지 핵심 기여를 제안합니다. 첫째, 데이터 주석 작업을 위한 불확실성 정량화(UQ) 성능 측정 방법을 제안합니다. 둘째, 세 가지 서로 다른 LLM과 CSS 데이터 주석 작업에서 다섯 가지 UQ 전략을 처음으로 비교합니다. 셋째, LLM의 낮은 신뢰도 주석을 효과적으로 식별하고 잘못 레이블이 붙은 데이터를 발견하는 새로운 UQ 집계 전략을 소개합니다.

- **Technical Details**: 연구는 대형 언어 모델의 신뢰성을 평가하기 위해 여러 UQ 기법을 사용해 분석하였으며, 새로운 UQ 집계 전략을 제안하여 잘못 분류된 LLM 레이블 데이터를 식별하는 과정을 보다 간소화하였습니다. 이 논문은 다양한 UQ 방법을 비교하고, AUC(Area Under Curve) 분석을 통해 신뢰도 점수의 백분위수 기반 임계값을 적용하여 기술됩니다.

- **Performance Highlights**: 제안된 UQ 집계 전략은 기존 방법에 비해 개선된 성능을 보여주며, Human-in-the-loop 데이터 주석 프로세스를 획기적으로 개선할 수 있음을 입증했습니다. 이를 통해, LLM이 생성한 데이터 중 인간이 자원을 소모해야 할 데이터의 식별이 용이해졌습니다.



### LFOSum: Summarizing Long-form Opinions with Large Language Models (https://arxiv.org/abs/2410.13037)
- **What's New**: 이 논문에서는 온라인 리뷰의 대량 처리 및 요약을 위한 새로운 접근법을 제안합니다. 특히, 1천 개 이상의 리뷰로 구성된 새로운 데이터셋을 소개하며, 이를 기반으로 하는 LLM(대형 언어 모델) 기반 요약 기법을 제안합니다.

- **Technical Details**: LFOSum 데이터셋은 TripAdvisor에서 수집된 호텔 리뷰로, 각 엔티티는 1천 개 이상의 리뷰를 포함하고 있습니다. 두 가지의 훈련이 필요 없는 요약 방법, 즉 Retrieval-Augmented Generation (RAG)과 긴 맥락의 LLM을 이용하여 대량 리뷰 요약을 처리합니다. 사용자 맞춤형 요약을 위한 세 가지 제어 메커니즘(쿼리 제어, 감정 제어, 길이 제어)을 도입하여 사용자 요구에 맞춘 요약을 가능하게 합니다.

- **Performance Highlights**: LLM은 여전히 긴 형식의 요약에서 감정과 형식 준수의 균형을 맞추는 데 어려움을 겪고 있으나, 관련 정보를 집중적으로 추출할 경우 오픈 소스 모델이 효과적으로 간격을 좁힐 수 있음을 보여줍니다.



### Towards Computational Analysis of Pansori Singing (https://arxiv.org/abs/2410.12956)
Comments:
          Late-Breaking Demo Session of the 25th International Society for Music Information Retrieval (ISMIR) Conference, 2024

- **What's New**: 이 논문에서는 한국 전통 음악인 판소리의 오디오와 해당 전사(Transcription)를 기반으로 한 컴퓨터 분석을 도입하고, 현대의 Music Information Retrieval (MIR) 방식이 어떻게 전통 음악 분석에 활용될 수 있는지를 보여줍니다.

- **Technical Details**: 판소리의 기본 주파수(F0) 윤곽을 추출하기 위해 CREPE 알고리즘을 사용하였고, 노이즈를 줄이기 위해 신뢰 점수 0.6 미만의 F0 값을 필터링했습니다. 비트 감지를 위해 madmom 라이브러리를 활용하였으며, 12/4 박자를 유지하기 위해 수동으로 비트를 주석 처리했습니다. n-gram 알고리즘을 통해 다양한 다목(Daemok)에서 발생하는 패턴을 분석했습니다.

- **Performance Highlights**: 판소리에 나타나는 모드의 분석은 장르의 구조 및 음악 언어를 이해하는 데 중요합니다. 예를 들어, Jeokbyeokga는 Gyemyeonjo와 Ujo 두 가지 모드를 포함하고 있으며, 각 다목의 특정한 음조와 장식 기법을 분석하여 지배 모드를 평가할 수 있습니다. 또한 다목 간 유사한 패턴을 발견하고, 동적 비브라토가 감정 표현에 중요한 역할을 한다는 점도 강조하였습니다.



### REFINE on Scarce Data: Retrieval Enhancement through Fine-Tuning via Model Fusion of Embedding Models (https://arxiv.org/abs/2410.12890)
Comments:
          Accepted in AJCAI'24

- **What's New**: 본 논문에서는 데이터 부족 문제를 해결하기 위해 REFINE이라는 새로운 접근 방식을 제안합니다. 이 방법은 효과적인 검색을 개선하기 위해 사용 가능한 문서에서 합성 데이터를 생성하고, 모델 융합(Model Fusion) 기법을 통해 임베딩을 향상시킵니다.

- **Technical Details**: REFINE은 LLM(대규모 언어 모델)을 활용하여 사용 가능한 비지도 문서에서 대조적 훈련 데이터셋을 생성합니다. 생성된 데이터셋은 표준 파인튜닝 방법을 통해 임베딩 모델의 성능을 개선하며, 새로운 데이터 특정 학습을 포함하는 모델 융합 기법을 도입하여 성능을 더욱 향상시킵니다.

- **Performance Highlights**: SQUAD 및 RAG-12000 데이터셋과 독점 TOURISM 데이터셋에서 실험을 수행한 결과, REFINE이 적용된 표준 파인튜닝이 기본 사전 훈련 모델에 비해 더 나은 성능을 보였고, TOURISM 데이터셋에서는 5.76%, SQUAD 데이터셋에서는 6.58%의 개선을, RAG-12000 데이터셋에서는 0.32%의 향상을 기록했습니다.



### AT-RAG: An Adaptive RAG Model Enhancing Query Efficiency with Topic Filtering and Iterative Reasoning (https://arxiv.org/abs/2410.12886)
- **What's New**: AT-RAG라는 새로운 멀티스텝 RAG 모델을 제안하여, 복잡한 다중 단계 쿼리를 보다 효율적으로 처리하는 방법을 소개합니다.

- **Technical Details**: AT-RAG는 BERTopic을 활용하여 쿼리의 주제를 동적으로 할당함으로써 문서 검색 및 추론 과정의 정확성과 효율성을 향상시킵니다. 이 모델은 Chain-of-Thought (CoT) 추론을 통합하여 반복적인 문서 검색 및 추론을 가능하게 합니다.

- **Performance Highlights**: AT-RAG는 기존 RAG 모델 대비 Accuracy, Completeness, Relevance에서 현저한 개선을 보였으며, 특히 의료 QA와 같은 복잡한 도메인-specific 문제 해결에 적합합니다. 모델은 다양한 benchmark dataset에서 높은 성능을 발휘하였고, 검색 시간을 줄이면서 높은 정밀도를 유지합니다.



### Enhancing Affinity Propagation for Improved Public Sentiment Insights (https://arxiv.org/abs/2410.12862)
- **What's New**: 이 연구는 감독 학습(supervised learning)에 의존하지 않고 감정 분석(sentiment analysis)을 수행하기 위한 비감독 학습(unsupervised learning) 기술을 도입합니다. 특히 Affinity Propagation (AP) 클러스터링 기법을 사용합니다.

- **Technical Details**: AP 클러스터링은 사전 정의된 클러스터 수 없이 텍스트 데이터를 자연적인 패턴에 따라 그룹화합니다. 이 논문에서는 텍스트 표현을 위한 TF-IDF 벡터화(TF-IDF Vectorization)와 차원 축소(principal component analysis, PCA) 기법을 사용하여 AP 클러스터링과 K-평균 클러스터링(K-means clustering)을 비교합니다. AP는 Agglomerative Hierarchical Clustering과 결합하여 성능을 향상시킵니다.

- **Performance Highlights**: AP와 Agglomerative Hierarchical Clustering의 조합이 K-평균보다 현저히 더 우수한 성능을 보였으며, 실험 평가는 Silhouette Score, Calinski-Harabasz Score, Davies-Bouldin Index를 통해 진행되었습니다. 이 연구는 널리 사용되는 레이블 데이터에 대한 필요 없이 대중 감정을 분석할 수 있는 스케일 가능하고 효율적인 비감독 학습 프레임워크를 제안하여 자연어 처리(NLP) 분야에 기여합니다.



### Enhancing Long Context Performance in LLMs Through Inner Loop Query Mechanism (https://arxiv.org/abs/2410.12859)
- **What's New**: 이번 논문에서는 Inner Loop Memory Augmented Tree Retrieval (ILM-TR)이라는 혁신적인 접근법을 통해 복잡한 질문에 대한 보다 깊이 있는 답변 생성을 가능하게 하는 새로운 메모리 체계를 도입합니다. 이 메커니즘은 초기 질문뿐만 아니라 중간 결과에 기반한 내부 루프 쿼리를 활용하여 정보를 검색합니다.

- **Technical Details**: ILM-TR 방법은 기본적으로 두 부분으로 구성되어 있습니다: retriever와 inner-loop query. Retriever 부분에서는 RAPTOR의 트리 빌드 방법을 사용하여 원시 데이터를 짧고 연속적인 텍스트 청크로 분할하고, 각 청크의 요약을 생성합니다. Inner-loop 쿼리는 LLM을 사용하여 최종 답변을 생성하며, Short-Term Memory (STM)라는 영역에 정보를 저장하고, 전달된 데이터를 바탕으로 반복적으로 쿼리를 수행합니다.

- **Performance Highlights**: ILM-TR 시스템은 Multi-Needle In A Haystack (M-NIAH) 및 BABILong과 같은 표준 긴 컨텍스트 벤치마크에서 기존 RAG 방법을 초월하는 성능을 보여주며, 500k tokens까지 컨텍스트 길이가 증가해도 성능 저하 없이 지속적인 성능을 유지합니다.



### A Comprehensive Survey of Retrieval-Augmented Generation (RAG): Evolution, Current Landscape and Future Directions (https://arxiv.org/abs/2410.12837)
Comments:
          4 Figures

- **What's New**: 이 논문은 Retrieval-Augmented Generation (RAG)의 발전 과정을 포괄적으로 조사하며, 기존 개념에서 최신 기술에 이르기까지의 변화를 설명합니다. RAG는 검색 메커니즘과 생성 언어 모델을 결합하여 출력의 정확성을 높이며, LLMs의 주요 제한 사항을 해결합니다.

- **Technical Details**: RAG의 기본 아키텍처는 지식 집약적인 작업을 처리하기 위해 검색과 생성을 어떻게 통합하는지에 중점을 둡니다. 논문에서는 retrieval-augmented language models에서의 주요 혁신과 질문 답변, 요약 및 지식 기반 작업 등 다양한 도메인에서의 응용 사례를 자세히 리뷰합니다.

- **Performance Highlights**: 최근 연구 성과는 retrieval 효율성을 개선하기 위한 새로운 방법을 강조하고 있으며, RAG의 연구 방향으로는 모델의 견고성 향상, RAG 모델의 적용 범위 확대 및 사회적 함의 문제 다루기가 제안됩니다.



### Predicting the Geolocation of Tweets Using transformer models on Customized Data (https://arxiv.org/abs/2303.07865)
Comments:
          31 pages, 5 tables, 9 figures

- **What's New**: 이번 연구는 트위터 사용자 및 트윗의 지리적 위치 예측을 위한 유연한 접근 방식을 제공합니다. 연구진은 자연어 처리(NLP) 기술인 신경망을 활용하여 위도와 경도로 구성된 위치 좌표를 추정하고, 이차원 가우시안 혼합 모델(GMM)을 적용하여 보다 정확한 예측을 가능하게 합니다.

- **Technical Details**: 제안된 모델은 미리 훈련된 Bidirectional Encoder Representations from Transformers(BERT)를 기반으로 하여 트위터 데이터셋에서 세부 조정되었습니다. 연구 결과, 전 세계 수준에서 평균 30km 미만의 오류를 기록하며, 미국의 경우 15km 미만의 오류로 더욱 향상된 예측 성능을 보였습니다.

- **Performance Highlights**: 제안된 방법론은 트윗의 내용 및 메타데이터 컨텍스트에 대한 텍스트 특징을 훈련 및 평가에 사용했습니다. 연구팀은 전체 트위터 데이터에서 단 1-2%만이 정확한 지리적 좌표를 지닌 메타데이터로 구분됨을 강조하며, 이로 인해 효과적인 지리적 위치 예측의 필요성을 언급합니다.



### RosePO: Aligning LLM-based Recommenders with Human Values (https://arxiv.org/abs/2410.12519)
- **What's New**: 최근에 추천 시스템을 위한 Large Language Models (LLMs)의 활용도가 높아지고 있습니다. 본 논문에서는 '도움이 되고 해롭지 않은' LLM 기반 추천기를 구축하기 위해 Recommendation with smoothing personalized Preference Optimization (RosePO)라는 프레임워크를 제안합니다. 이 프레임워크는 사용자 선호도 간의 비교 관계를 모델링하는 데 초점을 맞추고 있습니다.

- **Technical Details**: RosePO는 SFT(Supervised Fine-Tuning) 데이터와 자연스럽게 일치하는 입력 및 선택된 응답뿐만 아니라, 도움을 증대시키기 위한 거부 샘플링 전략과 해로움을 감소시키기 위한 두 가지 전략을 설계했습니다. 또한, 자동으로 구성된 선호도 데이터의 불확실성에 강력하도록 개인화된 스무딩 팩터를 도입했습니다.

- **Performance Highlights**: 세 가지 실제 데이터 세트에 대한 평가 결과, 본 방법이 추천 성능을 개선했을 뿐 아니라, 의미적 환각(semantic hallucination)과 인기 편향(popularity bias)을 완화하는 데 효과적임을 보여주었습니다.



### Unifying Economic and Language Models for Enhanced Sentiment Analysis of the Oil Mark (https://arxiv.org/abs/2410.12473)
- **What's New**: 원유 시장에 특화된 CrudeBERT라는 새로운 Language Model이 도입되었습니다. 이 모델은 기존의 전통적인 예측 방법의 한계를 극복하기 위해 개발되었습니다.

- **Technical Details**: CrudeBERT는 자연어 처리(Natural Language Processing) 분야에서 발전된 Generative Pre-trained Transformer(GPT) 모델을 기반으로 하며, 원유 시장에 특화된 용어를 효과적으로 처리하도록 파인 튜닝(Fine-tuning)되었습니다.

- **Performance Highlights**: CrudeBERT의 감정 점수(Sentiment Scores)는 WTI 선물 곡선(WTI Futures Curve)과 더 밀접하게 일치하며, 가격 예측(Price Predictions) 성능을 크게 향상시켰습니다.



### Mitigating Dual Latent Confounding Biases in Recommender Systems (https://arxiv.org/abs/2410.12451)
- **What's New**: 최근 추천 시스템 분야에서, 종래 시스템들이 겪었던 편향(bias) 문제를 해결하기 위한 새로운 방법인 IViDR이 제안되었습니다. 이 방법은 Instrumental Variables (IV) 접근법과 Identifiable Variational Auto-Encoder (iVAE)를 결합하여, 이중 잠재 혼동 변수(dual latent confounders)에 의한 편향을 줄여주는 통합 솔루션입니다.

- **Technical Details**: IViDR은 사용자의 특징 임베딩을 IV로 활용하여 아이템과 사용자 피드백 간의 잠재 혼동 변수들이 야기하는 편향을 해결합니다. 이 시스템은 원래의 상호작용 데이터와 편향이 제거된 데이터에서 잠재적 혼동 변수의 식별 가능한 표현을 유추하기 위해 iVAE를 사용합니다. 이론적으로 IV의 유효성과 배우 representations의 식별 가능성을 분석합니다.

- **Performance Highlights**: 실제 데이터와 합성 데이터에 대한 광범위한 실험 결과, IViDR은 편향을 줄이고 추천의 정확성을 높이는 데 있어 최신 모델들을 능가하는 성능을 보였습니다.



### QUIDS: Query Intent Generation via Dual Space Modeling (https://arxiv.org/abs/2410.12400)
- **What's New**: 이번 논문에서는 *query intent generation*라는 새로운 작업을 제안하여, 관련 문서와 비관련 문서를 사용하여 검색 쿼리에 대한 상세하고 정확한 의도 설명을 자동으로 생성하는 방법을 다룹니다. 기존 방법들이 쿼리 분류나 클러스터링으로 단순화했던 것과 달리, 우리는 비유적 해석을 넘어 더 정교한 쿼리 의도를 포착하기 위해 새로운 접근 방식인 이중 공간 모델을 도입했습니다.

- **Technical Details**: 우리는 문서의 의미적 관련성과 비관련성 정보를 사용하여 쿼리 의도를 이해하는 이중 공간 모델을 제안합니다. 이 과정에서 관련 문서와 비관련 문서를 인코딩하여 표현 공간에서 분리하고, 새로운 비틀기 공간에서 의미를 분리하여 최종 의도 설명을 생성합니다. 이를 통해, 쿼리와 직접 연결된 의미만을 재생산합니다. 또한, *transformer* 기반 모델(T5, BART)을 활용하여 이중 인코더 아키텍처에서 대조 학습(contrastive learning)을 적용합니다.

- **Performance Highlights**: 벤치마크 데이터셋 Q2ID에서 우리의 모델은 기존 방법들에 비해 뛰어난 성능을 보였으며, ROUGE 메트릭과 BERTScore 측정에서 최첨단 기준선보다 우수한 결과를 나타냈습니다. 인간 평가 및 LLM 기반 평가도 실시하여 모델의 강점과 약점을 종합적으로 분석했습니다. 이 모델은 irrelevant intent topics에 대한 집중도를 효과적으로 감소시키는 특성을 보여, 사용자 검색 경험을 향상시킬 수 있는 잠재력을 지니고 있습니다.



### Multi-Cause Deconfounding for Recommender Systems with Latent Confounders (https://arxiv.org/abs/2410.12366)
- **What's New**: 본 논문에서는 추천 시스템에서 발생하는 latent confounders의 문제를 해결하기 위해 Multi-Cause Deconfounding Method (MCDCF)를 제안합니다. 이 방법은 사용자의 행동 데이터를 활용하여 여러 사용자와 아이템 간의 상호작용을 분석함으로써 latent confounders에 대한 대체 변수를 학습합니다.

- **Technical Details**: MCDCF는 추천 시스템의 모델을 multi-cause 문제로 설정하고 사용자와 아이템의 latent confounders를 실행 가능한 대체 변수로 분리하여 학습합니다. 이 과정에서 causality의 효과를 추정하고 click prediction을 통해 사용자 피드백을 예측하는 과정을 포함합니다.

- **Performance Highlights**: 세 개의 실제 데이터셋에서 수행된 실험을 통해 MCDCF 방식이 사용자와 아이템에 관련된 latent confounders를 효과적으로 회복하고, 바이어스를 줄이며 추천의 정확성을 개선함을 입증하였습니다.



### Comprehending Knowledge Graphs with Large Language Models for Recommender Systems (https://arxiv.org/abs/2410.12229)
- **What's New**: 이번 연구에서는 CoLaKG라는 새로운 방법을 제안하여 추천 시스템의 성능을 개선합니다. CoLaKG는 대규모 언어 모델(LLM)을 활용하여 지식 그래프(KG)의 한계를 극복하고, 아이템 간의 세밀한 의미적 연결을 유지합니다.

- **Technical Details**: CoLaKG는 아이템 중심의 하위 그래프(subgraph)를 KG에서 추출하고, 이를 LLM에 대한 입력으로 변환합니다. LLM은 이러한 하위 그래프에 대한 이해를 출력하고, 이를 의미적 임베딩(semantic embedding)으로 변환합니다. 또한, 이 임베딩을 바탕으로 아이템-아이템 그래프(item-item graph)를 구성하여 고차원 관계를 직접적으로 포착합니다.

- **Performance Highlights**: 실제 데이터셋 4종에 대한 광범위한 실험 결과, CoLaKG 방법이 기존 방법들에 비해 우수한 성능을 보였음을 확인했습니다.



### Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations (https://arxiv.org/abs/2410.12228)
- **What's New**: 이 논문은 개인화 추천 시스템을 향상시키기 위해 다양한 데이터 모달리티(data modalities)를 통합하는 새로운 프레임워크인 Triple Modality Fusion (TMF)를 소개합니다. 이 프레임워크는 시각적, 텍스트, 그래프 데이터의 융합을 통해 수행됩니다.

- **Technical Details**: TMF 모델은 큰 언어 모델(LLMs)과의 정렬을 통해 세 가지 모달리티를 통합하며, 각각의 모달리티는 사용자 행동을 포괄적으로 표현하기 위해 서로 다른 특징을 제공합니다. 시각적 정보는 아이템의 맥락 및 미적 특성을 캡처하고, 텍스트 데이터는 사용자 관심사와 아이템 특성에 대한 상세한 통찰력을 제공하며, 그래프 데이터는 아이템-행동 이질 그래프(item-behavior heterogeneous graph) 내의 관계를 설명합니다.

- **Performance Highlights**: 광범위한 실험을 통해 추천 정확성을 개선하는 효과를 입증하였습니다. 추가적인 ablation 연구를 통해 TMF 모델 디자인의 효과성과 이점을 검증하였습니다.



### Post-Userist Recommender Systems : A Manifesto (https://arxiv.org/abs/2410.11870)
Comments:
          Extended abstract for paper presented at AltRecSys Workshop 2024. Held at the 18th ACM Conference on Recommender Systems, Bari, Italy. October 18, 2024

- **What's New**: 이 논문에서는 추천 시스템에서 제안하는 방법론으로서 'userist recommendation'을 정의하고, 사용자와 시스템 간의 관계만으로 구성된 접근법을 논의합니다. 'post-userist recommendation'은 다양한 이해관계자가 얽혀있는 더 큰 관계의 장을 제시하며 추천 기능을 구별합니다.

- **Technical Details**: 추천 시스템의 새로운 접근 방식으로 'userist recommendation'과 'post-userist recommendation' 개념을 도입합니다. 'post-userist recommendation'은 생성 미디어와의 관계를 포함하여, 창작자와 관객 간의 연결을 가능하게 하는 기능을 중시합니다.

- **Performance Highlights**: 생성 미디어의 시대에 접어들면서, 사용자 지향 추천(userist recommendation)은 개인화된 미디어 생성과 구분할 수 없게 되며, 따라서 'post-userist recommendation'이 추천 시스템 연구의 유일한 미래 방향이라고 주장합니다.



### The Moral Case for Using Language Model Agents for Recommendation (https://arxiv.org/abs/2410.12123)
- **What's New**: 이 논문은 정보 및 통신 환경의 한계와 기존 추천 시스템의 한계를 논의하며, 언어 모델(LM) 에이전트를 사용하는 대안적 접근 방식을 제안합니다.

- **Technical Details**: 기존 추천 시스템은 대량 감시(mass surveillance)를 촉진하고 권력을 집중시킵니다. 이 논문은 LM 에이전트를 사용하여 자연어로 표현된 사용자의 선호와 가치에 맞는 콘텐츠를 소싱하고 큐레이션하는 방법을 탐구하며, 여기에는 후보 생성(candidate generation), 계산 효율성(computational efficiency), 선호 모델링(preference modelling), 프롬프트 주입(prompt injection)과 같은 도전 과제가 포함됩니다.

- **Performance Highlights**: 성공적으로 구현될 경우, LM 에이전트는 대량 감시에 의존하지 않고 디지털 공공 영역을 안내할 수 있으며, 권력을 플랫폼에서 사용자에게 돌려주고, 행동적 프록시(proxy)가 아닌 중요한 요소를 최적화하며, 사용자의 주체성(agency)을 강화하는 역할을 할 수 있습니다.



### Online Digital Investigative Journalism using SociaLens (https://arxiv.org/abs/2410.11890)
- **What's New**: 본 논문에서는 대형 언어 모델(LLM)과 기계 학습(ML) 기술을 통합하여 언론 보도에서의 정보 검색 및 분석을 혁신할 수 있는 도구인 SociaLens를 소개합니다. 이는 기자들이 데이터 중심의 내용과 통찰력을 생성하는 데 도움을 주어, 현대의 조사 저널리즘을 새로운 단계로 이끌 것을 목표로 하고 있습니다.

- **Technical Details**: SociaLens는 온라인 소스에서 쿼리 전용 데이터를 식별하고 추출하는 다재다능하고 자율적인 조사 저널리즘 도구입니다. 이 도구는 ML 분석을 완전 자율적으로 수행하여 대량의 데이터에서 결론을 도출할 수 있도록 설계되었습니다. SociaLens는 OpenAI의 GPT-4o API를 기반으로 하며, 자연어 대화 분석을 위한 대화형 에이전트를 포함하고 있습니다. 또한, 맞춤형 그래픽 인터페이스를 통해 사용자는 구조화된 형태로 사실을 추출할 수 있습니다.

- **Performance Highlights**: 사례 연구로 방글라데시의 아동 성폭력 사건을 분석했으며, SociaLens가 복잡한 데이터 수집 및 분석 작업을 수행함으로써 기자들이 스스로 코드 전문 지식이 없는 상태에서도 정교한 통찰력을 얻을 수 있음을 보여줍니다. SociaLens는 텍스트 및 시각 보고서를 생성할 수 있으며, 사용자 질문에 대한 대화형 응대와 실시간 예측 분석을 통해 기자들에게 효율적인 뉴스 보도를 지원합니다.



### GeoLife+: Large-Scale Simulated Trajectory Datasets Calibrated to the GeoLife Datas (https://arxiv.org/abs/2410.11853)
Comments:
          Accepted paper at this https URL

- **What's New**: 이 논문에서는 실제 GeoLife 데이터셋의 통계적 특징을 활용하고, 이와 유사한 이동 패턴을 생성하기 위해 생명체의 행동을 시뮬레이션하는 'Pattern of Life Simulation (POL)'을 결합하여 GeoLife+라는 새로운 시뮬레이션 데이터를 생성했습니다.

- **Technical Details**: Genetic algorithm을 활용하여 GeoLife 데이터의 패턴과 유사한 특징을 재현하도록 POL의 파라미터를 조정했습니다. 이로 인해 182명, 1천명, 5천명, 1만명, 5만명, 10만명의 에이전트를 가진 여러 시뮬레이션 데이터셋을 생성했으며, 이는 각기 다른 기간 동안 수집되었습니다. 데이터는 기가바이트 단위로 제공됩니다.

- **Performance Highlights**: GeoLife 데이터와 유사한 통계적 특성을 가지면서도 밀도가 훨씬 높은 시뮬레이션 데이터셋으로, 연구자들이 미시적인 인간의 이동 패턴을 더 잘 이해하고 다양한 응용 프로그램에 활용할 수 있도록 돕습니다.



### GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable Recommendation (https://arxiv.org/abs/2410.11841)
- **What's New**: GaVaMoE는 새로운 Gaussian-Variational Gated Mixture of Experts 프레임워크를 도입하여 설명 가능한 추천 시스템의 개인화 및 데이터 희소성을 해결합니다.

- **Technical Details**: GaVaMoE는 두 가지 주요 구성 요소를 포함합니다: (1) Variational Autoencoder (VAE)와 Gaussian Mixture Model (GMM)을 사용하여 복잡한 사용자-아이템 협업 선호를 모델링하는 평가 재구성 모듈; (2) 다수의 전문가 모델을 활용해 세부적으로 개인화된 설명을 생성하는 다중 게이팅 메커니즘입니다.

- **Performance Highlights**: GaVaMoE는 세 개의 실제 데이터셋에서 실행된 광범위한 실험을 통해 기존 방법보다 설명 품질, 개인화 및 일관성에서 유의미하게 우수한 성능을 보여주었습니다.



### Adaptive Coordinators and Prompts on Heterogeneous Graphs for Cross-Domain Recommendations (https://arxiv.org/abs/2410.11719)
Comments:
          Under review

- **What's New**: 본 논문에서는 HAGO라는 새로운 프레임워크를 제안하여 다중 도메인 추천 시스템의 성능을 향상시키는 방법을 소개합니다. HAGO는 이질적인 적응형 그래프 코디네이터를 통해 다중 도메인 그래프를 통합하여 추천 시스템의 정확성을 높입니다.

- **Technical Details**: HAGO는 다섯 가지 주요 요소로 구성되어 있습니다: 이질적 그래프 코디네이터, 다중 도메인 그래프 사전 학습(또는 pre-training) 전략, 그래프 프롬프트(Graph prompting) 방법, 그리고 다양한 그래프 기반 모델과의 호환성을 제공합니다. 이 구조는 코디네이터 간의 연결을 동적으로 조정하여 유용한 상호작용을 강화하고 부정적 전이(Negative transfer) 효과를 완화합니다.

- **Performance Highlights**: HAGO는 두 개의 실제 플랫폼에서 7개의 서로 다른 도메인에 대한 실험을 수행하여 최신 기법들과 비교할 때 뛰어난 성능을 보였습니다. 이 결과는 HAGO가 다양한 실세계 응용 프로그램에 적용될 수 있는 가능성을 보여줍니다.



### CoActionGraphRec: Sequential Multi-Interest Recommendations Using Co-Action Graphs (https://arxiv.org/abs/2410.11464)
- **What's New**: 이 논문에서는 eBay와 같은 전자 상거래 플랫폼을 위한 아이템 추천 시스템 개발 시 마주하는 독특한 도전 과제를 다룹니다. 특히 데이터 희소성과 다양한 사용자 관심사를 해결하기 위한 CoActionGraphRec (CAGR) 모델을 제안합니다.

- **Technical Details**: CAGR 모델은 텍스트 기반의 두 개의 타워 구조를 가진 딥러닝 모델(Item Tower 및 User Tower)을 사용하고, 공동 행동 그래프(co-action graph) 레이어를 활용합니다. Item Tower에서는 각 아이템을 공동 행동 아이템으로 표현하여 공동 신호(collaborative signals)를 포착하고, User Tower에서는 각각의 사용자 행동 시퀀스를 나타내는 완전 연결 그래프를 구축하여 쌍 관계를 인코딩합니다. 또한, 명시적 상호작용 모듈이 행동 상호작용을 캡쳐하는 표현을 학습합니다.

- **Performance Highlights**: 광범위한 오프라인 및 온라인 A/B 테스트 실험 결과, 제안된 접근 방식이 최신 방법들에 비해 주요 지표에서 성능 개선을 보여줍니다.



### Sequential LLM Framework for Fashion Recommendation (https://arxiv.org/abs/2410.11327)
- **What's New**: 이 논문은 패션 산업에 최적화된 추천 시스템을 제안하며, 선행 학습된 대형 언어 모델(LLM)을 활용하여 추천 성능을 향상시키는 방법을 제시합니다.

- **Technical Details**: 제안된 프레임워크는 세 가지 주요 단계로 이루어져 있습니다: 첫째, 추천 목표에 맞춘 전문 프롬프트를 설계하는 프롬프트 엔지니어링 기술을 사용합니다. 둘째, 비용이 많이 드는 훈련 비용을 줄이기 위해 Parameter-Efficient Fine-Tuning (PEFT) 기술을 적용합니다. 마지막으로, 예측된 제품 제목 및 ID를 활용하여 관련 후보 항목을 검색하고 순위를 매기는 mix-up 기반 검색 기술을 사용합니다.

- **Performance Highlights**: 실험 결과, 제안된 프레임워크는 패션 추천 성능을 현저히 향상시켰다고 합니다. 특히, 기존의 패션 추천 시스템보다 효과적으로 사용자 선호도를 파악하고, 콜드 스타트 문제를 극복하는 데 기여했습니다.



### Optimizing Encoder-Only Transformers for Session-Based Recommendation Systems (https://arxiv.org/abs/2410.11150)
- **What's New**: 이 논문에서는 Sequential Masked Modeling (SMM)이라는 새로운 접근법을 소개하며, 이는 단일 세션 추천 시스템에서의 다음 추천 아이템 예측 문제를 해결하기 위해 설계되었습니다. 이 방법은 데이터 증강(data augmentation)과 특별한 토큰 마스킹 전략을 결합하여 시퀀스 종속성(sequential dependencies)을 효과적으로 포착합니다.

- **Technical Details**: SMM은 인코더 전용 트랜스포머 아키텍처를 활용하여 설계되었습니다. 이 방법에서는 윈도우 슬라이딩을 통한 데이터 증강과 펜얼리미니트 토큰 마스킹 전략을 사용하여 세션 데이터를 처리합니다. 제안하는 방법은 Yoochoose 1/64, Diginetica, Tmall의 세 가지 주요 데이터 세트에서 평가되었습니다.

- **Performance Highlights**: Transformer-SMM 모델은 동일한 정보 수준에서 가장 최신 모델들과 비교했을 때 명확한 성능 향상을 보였습니다. 사용자 데이터가 더 많이 제공되는 모델들과 비교해도 경쟁력을 유지하며 높은 정확도와 순위 평가 지표를 기록했습니다.



### SGUQ: Staged Graph Convolution Neural Network for Alzheimer's Disease Diagnosis using Multi-Omics Data (https://arxiv.org/abs/2410.11046)
Comments:
          20 pages, 2 figures

- **What's New**: 새롭게 제안된 SGUQ(단계적 그래프 컨볼루션 네트워크)는 알츠하이머병(AD) 진단을 위한 다중 오믹스 데이터(Multi-omics Data) 이용 시, mRNA 데이터로 시작하고 필요한 경우에만 DNA 메틸화 및 miRNA 데이터를 점진적으로 추가함으로써 임상 비용을 줄이고 진단 정확성을 향상시킵니다.

- **Technical Details**: SGUQ는 불확실성 정량화(Uncertainty Quantification)를 포함하는 그래프 기반 구조로, mRNA와 DNA 메틸화 데이터, miRNA 데이터를 단계적으로 통합하여 사용할 수 있도록 설계되었습니다. 이는 기존의 AI 접근 방식이 모든 오믹스 데이터를 완료해야 하는 비효율성에서 벗어나는 방법입니다.

- **Performance Highlights**: SGUQ는 ROSMAP 데이터셋에서 0.858의 정확도를 달성했으며, 46.23%의 샘플은 단일 모달 오믹스 데이터(mRNA)만으로 신뢰성 있게 예측되었고, 16.04%의 추가 샘플은 두 개의 오믹스 데이터 유형(mRNA + DNA 메틸화)을 결합했을 때 신뢰성 있게 예측되었습니다.



### DIIT: A Domain-Invariant Information Transfer Method for Industrial Cross-Domain Recommendation (https://arxiv.org/abs/2410.10835)
Comments:
          Accepted at CIKM 2024

- **What's New**: 이 논문에서는 산업 추천 시스템(Recommendation System, RS)에서의 Cross-Domain Recommendation (CDR) 문제를 해결하기 위한 새로운 방법인 DIIT(End-to-End Domain-Invariant Information Transfer)를 제안합니다. 이는 기존의 CDR 방법들이 산업 환경에서의 데이터 변화에 적합하지 않은 점을 개선하고자 합니다.

- **Technical Details**: DIIT는 두 가지 추출기(Extractor)를 사용하여 각 도메인에서 공통적인 정보(domain-invariant information)를 최대한으로 추출합니다. 첫 번째 추출기는 도메인 수준에서 동작하는 도메인 불변 정보 추출기으로, 두 번째 추출기는 표상 수준에서의 추출을 담당합니다. 또한, 수집된 정보를 최신 목표 도메인 모델로 전송하기 위한 마이그레이터(Migrator)를 설계하였습니다. 이 과정에서 다중 지점 지식 증류(Multi-spot Knowledge Distillation, KD)를 통해 다른 구조의 소스 도메인 모델로부터 효과적으로 정보를 전송할 수 있습니다.

- **Performance Highlights**: DIIT는 하나의 생산 데이터셋과 두 개의 공개 데이터셋에서 실험을 통해 효과성과 효율성을 입증하였습니다. 특히, 사용자의 즉각적인 관심 변화를 잘 반영하면서도 높은 성능을 유지하도록 설계되어 있습니다.



### LR-SQL: A Supervised Fine-Tuning Method for Text2SQL Tasks under Low-Resource Scenarios (https://arxiv.org/abs/2410.11457)
Comments:
          12pages, 4 figures,submitting to a journal

- **What's New**: LR-SQL은 데이터베이스의 복잡성으로 인한 GPU 메모리 요구량 증가 문제를 해결하기 위해 제안되었습니다. 기계 학습 모델의 세분화된 조정을 통해 더 효율적인 Text2SQL 변환을 가능하게 합니다.

- **Technical Details**: LR-SQL은 schema_link 모델과 SQL_generation 모델의 두 가지 감독적 세부 조정(supervised fine-tuning) 모델로 구성되어 있습니다. schema_link 모델은 전체 데이터베이스를 유연한 테이블 조합으로 나누어 모델이 이산 조각에서 관계를 학습할 수 있게 합니다. 또한, Chain-of-Thought 능력을 훈련시켜 다양한 조각 간의 관계 인지를 개선합니다.

- **Performance Highlights**: LR-SQL은 기존 방법에 비해 총 GPU 메모리 사용량을 40% 줄였으며, schema_link 작업에서 테이블 예측 정확도는 2% 감소했습니다. 전체 Text2SQL 작업에서는 실행 정확도(Execution Accuracy)가 0.6% 감소했습니다.



### Enhance Graph Alignment for Large Language Models (https://arxiv.org/abs/2410.11370)
Comments:
          Under review

- **What's New**: 본 연구에서는 Graph Alignment Large Language Models (GALLM)를 제안하여 LLM이 그래프 데이터를 더 잘 이해하고 사용할 수 있도록 합니다. 새로운 자기지도 학습 방식과 템플릿 정렬을 통해 성능을 개선합니다.

- **Technical Details**: GALLM은 크게 두 가지 단계로 구성됩니다: 첫 번째는 자기지도 조정(self-supervised tuning) 단계로, 텍스트 일치(task) 작업을 통해 LLM을 훈련시킵니다. 두 번째는 작업 특정 조정(task-specific tuning) 단계로, 추가적인 설명과 정렬된 템플릿을 통해 감독 정보를 활용하여 두 가지 범주 프롬프트 방법을 제시합니다.

- **Performance Highlights**: 여러 데이터셋에 대한 실험 평가 결과, 감독 학습(supervised learning), 멀티 데이터셋 일반화(multi-dataset generalizability), 특히 제로샷 능력(zero-shot capability)에서 상당한 성과 개선이 있음을 보여주었습니다.



### Reducing Labeling Costs in Sentiment Analysis via Semi-Supervised Learning (https://arxiv.org/abs/2410.11355)
Comments:
          12 pages, 7 figures, accepted at the 2024 8th International Conference on Natural Language Processing and Information Retrieval (NLPIR 2024), Okayama, Japan, 2024

- **What's New**: 이 연구는 기계 학습에서 데이터 레이블링의 효율성을 높이는 새로운 접근 방식을 제시합니다. 전통적인 방법에 비해 레이블의 수를 크게 줄일 수 있는 반지도 학습(semi-supervised learning)에서의 레이블 전파(label propagation)를 탐구하고 있습니다.

- **Technical Details**: 본 연구에서는 텍스트 분류를 위한 매니폴드 가정(manifold assumption)을 기반으로 한 전이식 레이블 전파(transductive label propagation) 방법을 사용합니다. 그래프 기반(graph-based) 방법을 활용하여 레이블이 없는 데이터에 대한 유사 레이블(pseudo-labels)을 생성하고, 이를 통해 깊은 신경망(deep neural networks)을 학습합니다.

- **Performance Highlights**: 본 연구는 감정 분석(sentiment analysis) 분야에 대한 실험을 통해 레이블 전파의 효과성을 평가하며, 기존의 레이블링 방법에 비해 성능이 비슷한 결과를 얻을 수 있음을 보이고 있습니다.



### On the Capacity of Citation Generation by Large Language Models (https://arxiv.org/abs/2410.11217)
Comments:
          Accepted by CCIR 2024

- **What's New**: 이번 연구는 대형 언어 모델(LLMs)이 생성하는 응답 내 인용 생성 능력에 대한 체계적 분석을 실시하고, 인용 품질을 향상시키기 위한 새로운 방법을 제시합니다. 주된 초점은 기존 연구들이 응답의 정확성을 높이는 데 집중했던 것과 달리, 정확한 출처 귀속 기능을 개선하는 것입니다.

- **Technical Details**: 연구에서 사용한 두 가지 기본 방법은 few-shot 및 fine-tuning입니다. 인용 품질 향상을 위해 Generate-then-Refine 방법을 제안하며, 이는 관련 인용을 추가하고 불필요한 인용을 제거하여 응답 텍스트를 변경하지 않고 인용 품질을 개선하는 방식을 포함합니다. 또한, 새로운 인용 평가 메트릭도 도입하여 기존 메트릭에서 불필요한 인용에 대한 과도한 처벌을 배제합니다.

- **Performance Highlights**: WebGLM-QA, ASQA, ELI5 데이터셋에서 실험한 결과, 제시된 방법이 LLMs에 의해 생성된 응답의 인용 품질을 상당히 향상시키는 것으로 나타났습니다. 연구의 주요 기여는 LLM이 생성하는 인용 분석, 인용 품질 평가를 위한 보다 포괄적인 메트릭 제안, 그리고 인용 품질을 대폭 향상시키는 Generate-then-Refine 접근법을 제시한 것입니다.



### GraFPrint: A GNN-Based Approach for Audio Identification (https://arxiv.org/abs/2410.10994)
Comments:
          Submitted to IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)

- **What's New**: 이 논문은 GraFPrint라는 오디오 식별 프레임워크를 소개합니다. 이 프레임워크는 Graph Neural Networks (GNNs)의 구조적 학습 능력을 활용하여 강력한 오디오 핑거프린트를 생성합니다.

- **Technical Details**: GraFPrint는 시-주파수(time-frequency) 표현에서 k-nearest neighbor (k-NN) 그래프를 구성하고, max-relative 그래프 컨볼루션을 적용하여 지역 및 전역 정보를 인코딩합니다. 네트워크는 자기 지도(self-supervised) 대조적 접근법을 사용하여 훈련되며, 이 과정에서 환경 소음에 대한 저항성을 강화합니다.

- **Performance Highlights**: GraFPrint는 대규모 데이터셋에서 다양한 레벨의 세분화(granularity)에서 우수한 성능을 보여주며, 경량화되고 확장 가능하여 광범위 참조 데이터베이스가 있는 실제 응용 프로그램에 적합합니다.



### Mitigating the Impact of Reference Quality on Evaluation of Summarization Systems with Reference-Free Metrics (https://arxiv.org/abs/2410.10867)
- **What's New**: 이 논문에서는 인간의 평가와 높은 상관관계를 가지면서 계산 비용이 매우 낮은 새로운 reference-free (참조 없는) 메트릭을 소개합니다.

- **Technical Details**: 제안된 메트릭은 기존의 reference-based (참조 기반) 메트릭과 함께 사용될 수 있으며, 저품질 참조 설정에서 메트릭의 견고성을 향상시킵니다. 특히 긴 문서의 요약에 대한 relevance (관련성)을 잘 나타냅니다.

- **Performance Highlights**: 이 메트릭은 인간의 평가와 높은 상관관계를 가지며, 저비용으로 계산 가능함을 보여줍니다.



### Generating Model Parameters for Controlling: Parameter Diffusion for Controllable Multi-Task Recommendation (https://arxiv.org/abs/2410.10639)
- **What's New**: 이 논문에서는 재훈련 없이 추천 모델의 파라미터를 동적으로 조정하여 사용자의 변화하는 요구에 효과적으로 대응할 수 있는 새로운 접근법인 PaDiRec를 제안합니다.

- **Technical Details**: PaDiRec는 조건부 훈련(conditional training)을 통해 다양한 작업 요구 사항을 기반으로 최적화된 모델 파라미터의 분포를 학습하기 위해 확산 모델(diffusion model)을 사용합니다. 이 접근법은 기존 추천 시스템과 호환되며, 어댑터 튜닝(adapter tuning) 기법을 통해 최적화된 모델 파라미터를 미리 확보한 후, 테스트 시에도 시간에 따라 변경되는 작업 요구 사항에 따라 모델 파라미터를 생성합니다.

- **Performance Highlights**: 공개 데이터셋과 상업 앱에서 수집한 데이터셋을 통한 광범위한 실험 결과, PaDiRec는 동적 요구 사항 변화에 대한 추천 시스템의 제어력을 효과적으로 향상시키며, 이를 통해 추천 성능도 유지합니다.



### VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents (https://arxiv.org/abs/2410.10594)
- **What's New**: 이 논문에서는 기존의 텍스트 기반 Retrieval-augmented generation (RAG) 시스템의 한계를 극복하기 위해 비전-언어 모델(Vision-Language Model, VLM)을 이용한 새로운 RAG 파이프라인인 VisRAG를 제안합니다.

- **Technical Details**: VisRAG는 문서를 직접 이미지로 임베딩하여 VLM을 통해 정보를 추출하는 방식으로 동작합니다. VisRAG-Ret와 VisRAG-Gen이라는 두 구성 요소로 이루어져 있으며, 이들은 각각 이미지 기반 정보 검색과 생성 기능을 수행합니다.

- **Performance Highlights**: VisRAG는 전통적인 텍스트 기반 RAG에 비해 검색 및 생성 단계 모두에서 성능이 25-39% 향상되었으며, 특히 다중 문서 처리를 효율적으로 수행할 수 있는 가능성이 확인되었습니다.



### Advancing Academic Knowledge Retrieval via LLM-enhanced Representation Similarity Fusion (https://arxiv.org/abs/2410.10455)
Comments:
          The 2nd Place of KDD Cup 2024 OAG-Challenge AQA

- **What's New**: 2024 KDD Cup AQA 챌린지에서 2위를 차지한 LLM-KnowSimFuser는 LLM(대규모 언어 모델)의 강력한 언어 이해 및 개방형 도메인 지식을 활용하여 관련 학술 용어를 정확하게 추출하는 retrieval 모델의 진전을 목표로 하였다.

- **Technical Details**: 이 접근법은 세 가지 주요 구성 요소로 이루어져 있다: (1) 사전 학습 모델을 사용한 embedding 추출, (2) fine-tuning된 모델을 통한 embedding 산출, (3) 유사성 행렬을 계산하고 융합하여 문서의 관련성을 평가한다. 이를 위해 NV-Embed-v1, SFR-Embedding-Mistral, GritLM-7B, Linq-Embed-Mistral과 같은 여러 사전 학습 모델이 사용되었다.

- **Performance Highlights**: 제안된 LLM-KnowSimFuser는 최종 리더보드에서 0.20726의 점수를 달성하였으며, 실험 결과 각 모델과 융합된 변형의 성능이 비교 분석되었다.



### A Hybrid Filtering for Micro-video Hashtag Recommendation using Graph-based Deep Neural Network (https://arxiv.org/abs/2410.10367)
- **What's New**: 이번 연구에서는 마이크로 비디오에 대한 해시태그 추천 시스템을 위한 새로운 하이브리드 필터링 기반 기술인 MISHON을 제안합니다. MISHON은 콘텐츠 기반 필터링과 사용자 기반 협업 필터링을 결합하여 사용자와의 관련성을 고려한 해시태그 추천을 제공합니다.

- **Technical Details**: MISHON 기술은 사용자 간의 역사적인 태깅 행동을 기반으로 유사한 사용자 모델링을 통해 사용자 간 상호작용을 분석합니다. 또한, 그래프 기반의 딥 뉴럴 네트워크를 활용하여 사용자 간, 모달리티 간, 사용자-모달리티 간 상호작용을 모델링합니다.

- **Performance Highlights**: 세 개의 실세계 데이터셋에서 MISHON은 F1 스코어 측면에서 각각 3.6%, 2.8%, 및 6.5%의 상대적 향상을 달성했습니다. 또한, 차가운 시작 문제를 해결하기 위해 콘텐츠 및 사회적 영향을 기반으로 한 기술을 도입하여, 관련성이 없는 사용자의 경우에도 15.8%의 개선된 F1 스코어를 보여주었습니다.



### Enhancing Attributed Graph Networks with Alignment and Uniformity Constraints for Session-based Recommendation (https://arxiv.org/abs/2410.10296)
Comments:
          11 pages, 4 figures, 5 tables. Accepted by ICWS 2024

- **What's New**: 이 논문은 기존의 속성 비인식(Session-based Recommendation, SBR) 모델을 향상시키기 위한 일반적인 프레임워크인 AttrGAU(Attributed Graph Networks with Alignment and Uniformity Constraints)를 제안합니다. 이는 주로 모델 설계에 특화된 기존의 방법들과 차별화되어, 다양한 모델에 적용할 수 있습니다.

- **Technical Details**: AttrGAU는 항목-속성 관계의 이질성을 고려하여 이항 속성 그래프(Bipartite Attributed Graph)를 구성하고, 속성 인식 그래프 컨볼루션(attribute-aware graph convolution)을 통해 노드 임베딩을 개선합니다. 또한, 세션 표현 학습에서 기존 SBR 모델을 그래프 신경망 및 주의(attention) 읽기 모듈로 분리하여 비침입적(non-intrusive) 구조를 유지합니다. 조정(alignment) 및 균일성(uniformity) 제약 조건을 도입하여 속성 의미(attribute semantics)와 협동 의미(collaborative semantics) 간의 분포 불일치를 최적화합니다.

- **Performance Highlights**: 세 가지 공개 벤치마크 데이터셋에 대한 광범위한 실험에서 AttrGAU 프레임워크가 기존 SBR 모델의 추천 성능과 데이터 희소성(data sparsity) 및 잡음(noise) 문제에 대한 강인성을 크게 향상시킬 수 있음을 보여주었습니다.



### FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG (https://arxiv.org/abs/2410.10293)
Comments:
          18 pages, 6 figures, 13 tables

- **What's New**: 본 연구에서는 Retrieval-Augmented Generation (RAG) 구조의 한계를 극복하기 위한 새로운 접근 방식을 제안합니다. 기존의 flat retrieval 방식의 단점을 보완하기 위해, coarse-to-fine granularity를 적용한 FunnelRAG라는 점진적 검색 패러다임을 도입했습니다.

- **Technical Details**: FunnelRAG는 검색 단계를 점진적으로 진행하여 후보 군집의 규모를 줄이고 검색 단위의 세분성을 높이며 검색기의 용량 수준을 증가시킵니다. 이를 통해 Mixed-capacity retrievers를 활용하여 효율성과 정확성을 모두 개선합니다. 근본적으로, Coarse-to-Fine Granularity를 통해 대량의 문서에서 먼저 coarse-grained units를 만들고, 이를 다시 세분화하여 최종적으로 passage-level units로 분리합니다.

- **Performance Highlights**: FunnelRAG는 기존 retrieval 방식에 비해 약 40%의 시간 오버헤드를 줄이며, 경쟁력 있는 retrieval 성능을 유지하였습니다. 이는 Natural Question (NQ) 및 Trivia QA (TQA)와 같은 open-domain 질문 응답 시스템에서의 성능 개선을 입증합니다.



### DecKG: Decentralized Collaborative Learning with Knowledge Graph Enhancement for POI Recommendation (https://arxiv.org/abs/2410.10130)
- **What's New**: 본 연구에서는 사용자 간의 협업 학습을 통한 분산형 추천 시스템인 DecKG(Decentralized Collaborative Learning with Knowledge Graph Enhancement) 프레임워크를 제안합니다. 기존의 POI(Point-of-Interest) 추천 시스템들이 개인 정보 보호 문제를 유발하는 중앙 집중형 모델에서 벗어나기 위해 자율적인 데이터 학습을 가능하게 했으며, 이는 외부 지식 그래프를 통합하여 모델의 성능을 향상시키는 독창적인 방법을 제공합니다.

- **Technical Details**: DecKG는 사용자가 민감한 상호작용 데이터를 직접 서버에 업로드하는 대신, 일반 항목 범주를 업로드함으로써 비민감한 체크인 데이터를 생성합니다. 서버는 전체 지식 그래프(Knowledge Graph)를 사전 학습하고, 각 사용자에게 관련된 세분화된 서브 지식 그래프(sub-KG)를 배포합니다. 클라이언트 장치에서 이러한 서브-KG를 통해 추가적인 지식 학습이 가능하며, 이 과정을 통해 사용자 간의 지식 교환이 이루어집니다.

- **Performance Highlights**: 실제 데이터셋을 통해 DecKG의 성능을 평가한 결과, 기존의 분산 POI 추천 시스템보다 추천 성능이 현저히 향상된 것으로 나타났습니다. 이는 DecKG가 개인 정보 보호를 유지하면서도 더욱 효과적인 추천을 제공할 수 있는 가능성을 시사합니다.



### MAIR: A Massive Benchmark for Evaluating Instructed Retrieva (https://arxiv.org/abs/2410.10127)
Comments:
          EMNLP 2024

- **What's New**: 이 논문은 MAIR (Massive Instructed Retrieval Benchmark)라는 새로운 정보 검색 (IR) 벤치마크를 제안합니다. MAIR는 6개의 도메인에서 126개의 독특한 IR 작업을 포함하며, 최신 IR 모델의 일반화 능력을 평가하기 위한 광범위한 기준을 제공합니다.

- **Technical Details**: MAIR는 126개의 다양한 검색 작업으로 구성되어 있으며, 805개의 고유한 지침(instruction)이 포함되어 있습니다. 이 데이터 세트는 SIGIR 논문, 기존 벤치마크, TREC 공유 작업 및 최신 LLM 벤치마크와 같은 여러 출처에서 수집되었습니다. 모델의 성능을 평가하기 위해 sparse retriever, single-task text embedding models, non-instruction-tuned multi-task text embedding models, instruction-tuned embedding models 및 re-ranking models를 포함한 다양한 검색 모델을 벤치마킹했습니다.

- **Performance Highlights**: 실험 결과, instruction-tuned 모델이 비-instruction-tuned 모델에 비해 MAIR에서 일반적으로 더 우수한 성능을 발휘했습니다. 특히, GritLM-7B 모델이 평균 nDCG@10에서 55.20으로 가장 높은 점수를 기록했습니다. 이러한 결과는 지침 추가 시 명확한 성능 향상을 보여줍니다.



### The Role of Fake Users in Sequential Recommender Systems (https://arxiv.org/abs/2410.09936)
Comments:
          10 pages, 2 figures

- **What's New**: 이번 연구는 Sequential Recommender Systems (SRSs)이 현실 세계에서 fake users(가짜 사용자)의 존재에 어떻게 영향을 받는지를 분석하며, 이로 인해 발생하는 성능 저하를 실질적으로 평가합니다. 이러한 가짜 사용자들은 무작위로 아이템에 상호작용하거나, 인기 있는 또는 인기 없는 아이템을 추종하거나, 특정 장르에 집중하는 행동을 보입니다.

- **Technical Details**: SRS 조사는 Normalized Discounted Cumulative Gain (NDCG) 및 Rank Sensitivity List (RLS)와 같은 성능 메트릭스를 통해 수행되었습니다. 두 가지 모델(SASRec 및 GRU4Rec)을 사용하여 MovieLens 1M, MovieLens 100k, Foursquare NYC 및 Foursquare Tokyo 데이터 세트를 기반으로 실험이 이루어졌습니다. 가짜 사용자의 유형과 수에 따라 NDCG와 RLS의 성과 변화를 분석했습니다.

- **Performance Highlights**: 가짜 사용자 존재가 RLS 메트릭스의 성능을 심각하게 저하시킬 수 있으며, RLS 값이 거의 0에 가까워지는 경우도 발생할 수 있다는 발견이 있었습니다. 반면, 전통적인 메트릭인 NDCG는 상대적으로 안정한 수준을 유지하는 경향을 보였습니다.



### Analysis and Design of a Personalized Recommendation System Based on a Dynamic User Interest Mod (https://arxiv.org/abs/2410.09923)
- **What's New**: 인터넷의 빠른 발전과 정보의 폭발로 사용자를 위한 정확한 개인화 추천(Recommendation) 제공이 중요한 연구 주제로 대두되고 있습니다. 본 논문은 동적 사용자 관심 모델(Dynamic User Interest Model)에 기반한 개인화 추천 시스템을 설계하고 분석하였습니다.

- **Technical Details**: 이 시스템은 사용자 행동 데이터(User Behavior Data)를 수집하고, 동적 사용자 관심 모델을 구축하여 여러 추천 알고리즘을 결합하여 사용자가 개인화된 콘텐츠를 받을 수 있도록 합니다. 논문에서는 시스템의 아키텍처 설계(Architecture Design), 알고리즘 구현(Algorithm Implementation), 실험 결과(Experimental Results)에 대해 상세히 논의합니다.

- **Performance Highlights**: 연구 결과에 따르면, 이 시스템은 추천 정확도(Recommendation Accuracy)와 사용자 만족도(User Satisfaction)를 상당히 개선하는 것으로 나타났습니다. 향후 연구 방향(Future Research Directions)도 탐구하고 있습니다.



### A Comparative Study of PDF Parsing Tools Across Diverse Document Categories (https://arxiv.org/abs/2410.09871)
Comments:
          17 pages,11 figures, 5 tables

- **What's New**: 본 연구는 다양한 문서 유형에 대한 PDF 파싱 도구의 성능을 비교 연구함으로써, 주로 학술 문서 외의 문서에서의 효과성을 개선하고자 하는 새로운 접근 방식을 제시합니다.

- **Technical Details**: 본 연구는 10가지 인기 있는 PDF 파싱 도구를 DocLayNet 데이터셋을 사용하여 6가지 문서 카테고리에서 성능을 평가했습니다. 여기에는 PyPDF, PyMuPDF, pdfplumber, pypdfium2, Unstructured, Tabula, Camelot, Nougat 및 Table Transformer(TATR)와 같은 머신러닝 기반 도구가 포함됩니다. 텍스트 추출과 테이블 탐지 능력을 평가하였으며, rule-based 및 learning-based 방법론을 사용하여 주기적으로 결과를 비교하였습니다.

- **Performance Highlights**: 텍스트 추출의 경우 PyMuPDF와 pypdfium이 다른 도구들보다 우수한 성능을 보였으나, 과학 및 특허 문서에서 모든 파서들이 어려움을 겪었습니다. 테이블 탐지에서는 TATR가 금융 및 특허, 법률 및 과학 카테고리에서 탁월한 성능을 보였고, Camelot은 입찰 문서에서 가장 높은 성능을 기록했습니다. 이러한 결과는 문서 유형과 특정 작업에 따라 적절한 파싱 도구를 선택하는 것이 중요하다는 점을 강조합니다.



### Agentic Information Retrieva (https://arxiv.org/abs/2410.09713)
Comments:
          11 pages, position paper

- **What's New**: 본 논문에서는 대규모 언어 모델(LLMs)이 정보 검색(Information Retrieval) 방식에 미친 영향을 분석하고, 유능한 LLM 에이전트의 기능을 바탕으로 하는 새로운 정보 검색 패러다임인 Agentic Information Retrieval (Agentic IR)를 소개합니다. 이는 전통적인 정보 검색 시스템의 한계를 극복하고, 보다 유연한 정보 접근 방식을 제시합니다.

- **Technical Details**: Agentic IR은 기존의 고정된 정보 검색 아키텍처 대신, 에이전트를 중심으로 한 통합 아키텍처를 도입합니다. 에이전트는 관찰(observation), 추론(reasoning), 행동(action)을 반복적으로 수행하여 사용자에게 최적의 정보를 제공하는 구조입니다. 이 과정에서 프롬프트 엔지니어링(prompt engineering), 검색 강화 생성(retrieval-augmented generation), 감독 및 강화 학습 기법을 포함한 다양한 방법이 사용됩니다.

- **Performance Highlights**: Agentic IR은 삶의 보조자(life assistant), 비즈니스 보조자(business assistant), 코드 보조자(coding assistant) 등 다양한 응용 분야에서 활용될 가능성이 큽니다. 이를 통해 미래의 디지털 생태계에서 중요한 정보 진입 점이 될 것으로 기대됩니다.



### Towards Scalable Semantic Representation for Recommendation (https://arxiv.org/abs/2410.09560)
- **What's New**: 최근 대형 언어 모델(LLM)의 발전과 함께, LLM 기반으로 개발된 Semantic ID가 추천 시스템의 성능을 향상시키기 위한 연구가 더욱 늘어나고 있습니다. 이 논문에서는 Mixture-of-Codes라는 새로운 접근 방식을 제안하여 LLM의 의미적 표현을 효과적으로 확장합니다.

- **Technical Details**: 제안된 Mixture-of-Codes (MoC) 방법은 두 단계로 구성됩니다. 첫 번째 단계에서는 여러 개의 독립적인 코드북(codebook)을 학습하여 LLM의 표현을 인덱싱합니다. 두 번째 단계에서는 생성된 코드의 학습 가능 임베딩을 융합(fuse)하여 하류 추천(stage) 단계에서 사용합니다. 또한 VQ-VAE 방법을 활용하여 코드 임베딩을 생성하며, 이러한 과정에서 코드의 차원(dimension)을 추천 시스템의 ID 임베딩 차원에 맞추어 처리합니다.

- **Performance Highlights**: 실험 결과, MoC 방법은 분별력(discriminability), 차원 견고성(dimension robustness), 성능(performance) 면에서 우수한 확장성을 달성하는 것으로 나타났습니다. 세 개의 공개 데이터셋에서 진행된 포괄적인 실험을 통해 이 방법의 효과가 입증되었습니다.



### Eco-Aware Graph Neural Networks for Sustainable Recommendations (https://arxiv.org/abs/2410.09514)
Comments:
          9 pages, 2 tables, 3 figures, RecSoGood Workshop

- **What's New**: 이번 연구는 GNN(그래프 신경망)을 활용한 추천 시스템의 환경적 영향을 분석한 최초의 연구로, 기존 문헌에서 간과된 탄소 배출 문제에 주목하고 있습니다. GNN 기반의 추천 아키텍처에서의 에너지 소비 및 탄소 발자국을 평가하며, 지속 가능하고 책임 있는 인공지능 개발에 기여할 수 있는 데이터를 제공합니다.

- **Technical Details**: 이 연구는 CodeCarbon을 활용하여 CPU와 GPU의 전력 소비를 추적하며, CO2-eq(이산화탄소 등가물) 배출량을 측정합니다. 다양한 GNN 아키텍처, 즉 Neural Graph Collaborative Filtering (NGCF), LightGCN 및 SimGCL 모델을 평가하고 각각의 임베딩 크기에 따라 모델의 성능과 환경적 영향을 실험합니다.

- **Performance Highlights**: GNN 기반 추천 시스템의 훈련과 배포에서 발생하는 탄소 배출에 대한 포괄적인 분석을 수행하였으며, 에너지 소비 및 수명 주기 전반의 환경적 영향을 고려하여 추천 시스템의 성능과 지속 가능성 간의 균형을 맞출 수 있는 방법을 제시합니다.



### Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performanc (https://arxiv.org/abs/2410.09359)
- **What's New**: 이번 연구는 그린 추천 시스템(Green Recommender Systems) 맥락에서, 다운샘플링(downsampling) 기법을 통해 추천 알고리즘의 성능을 에너지 효율적으로 최적화하는 가능성을 탐구합니다. 대규모 모델 훈련의 환경적 영향을 고려하여, 다양한 추천 알고리즘의 성능을 데이터셋 크기 변화에 따라 분석했습니다.

- **Technical Details**: 연구는 MovieLens 100K, 1M, 10M와 Amazon Toys and Games 데이터셋을 사용하여 수행되었으며, 훈련 데이터를 최대 50%까지 줄였음에도 불구하고 FunkSVD 및 BiasedMF처럼 일부 알고리즘이 상당한 추천 품질을 유지함을 발견했습니다. nDCG@10 점수는 전체 데이터셋 성능의 약 13% 이내로 나타났습니다.

- **Performance Highlights**: 다운샘플링한 훈련 세트로 알고리즘을 훈련 시, 평균적으로 실행 시간 약 72% 감소와 함께 에너지 소비를 줄일 수 있었습니다. 이는 알고리즘 프로토타입 및 초기 테스트를 고려할 경우 상당한 탄소 배출 감소를 가져올 수 있는데, 알고리즘당 데이터셋당 CO2e 배출량 감소를 추정할 수 있습니다.



### Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models (https://arxiv.org/abs/2410.10542)
Comments:
          Accepted on NLLP at EMNLP 2024

- **What's New**: 본 연구에서는 인도의 법원 판결 예측을 위한 실제 시나리오를 탐구하고, InLegalBERT, BERT, XLNet과 같은 다양한 transformer 기반 모델과 LLMs인 Llama-2 및 GPT-3.5 Turbo를 활용합니다. 사례가 재판을 위해 제시될 때 순간적인 정보를 기반으로 한 판결 예측을 시도하며, 후향적 분석 없이 실제 상황을 모방합니다.

- **Technical Details**: transformer 모델의 효율성을 평가하고 법적 사실의 요약을 통해 예측 품질을 향상시키는 방법을 실험합니다. 계층적 transformer 모델을 도입하여 판결 사실을 최적화하고, 법령, 판례, 주장과 같은 추가적인 법적 정보를 포함하여 LLMs의 성능을 개선합니다. 이 연구는 GPT-3.5 Turbo가 인도의 법적 판결 예측에서 뛰어난 성능을 보이는 것을 발견했습니다.

- **Performance Highlights**: 자동 평가 및 인간 평가 모두에서 LLMs가 전문가 수준의 성능에 도달하지 못했음을 보이며, 판결 예측과 설명 품질 모두에서 개선의 여지가 있음을 시사합니다. Clarity와 Linking이라는 두 가지 새로운 평가 지표를 정의하여 LLM이 생성한 예측 및 설명의 품질을 평가합니다.



### Medico: Towards Hallucination Detection and Correction with Multi-source Evidence Fusion (https://arxiv.org/abs/2410.10408)
Comments:
          12 pages, 3 figures, 6 tables. Accepted by EMNLP 2024's demo track

- **What's New**: 새로운 연구인 Medico는 다원적 증거 융합(Multi-source evidence fusion)을 통한 환각 감지 및 수정 프레임워크입니다. 이는 LLMs(대형 언어 모델)의 환각 문제를 해결하기 위해 다양한 출처에서 증거를 수집하고, 생성된 콘텐츠가 사실 오류를 포함하는지 여부를 탐지하여 그 판단의 이유(rationale)를 제공하고, 반복적으로 환각된 내용을 수정합니다.

- **Technical Details**: Medico 프레임워크는 세 가지 주요 구성 요소로 이루어져 있습니다: (1) 다원적 증거 융합(Multi-source Evidence Fusion) - 여러 출처에서 다양한 증거를 수집합니다; (2) 증거 기반 환각 감지(Hallucination Detection with Evidence) - 융합된 증거를 활용하여 LLMs의 생성된 콘텐츠를 확인하고 판단의 이유를 제시합니다; (3) 이유에 기반한 환각 수정(Hallucination Correction with Rationale) - 분류 결과가 잘못된 경우, 이유에 따라 환각된 콘텐츠를 반복적으로 수정합니다. 이를 통해 Medico는 설명 가능성(explainability)을 제공하며, 모델 무관(model-agnostic)하므로 다양한 LLMs에 적용 가능합니다.

- **Performance Highlights**: Medico는 증거 검색(evidence retrieval)에서 0.964 HR@5 및 0.908 MRR@5, 환각 탐지(hallucination detection)에서 0.927-0.951 F1, 환각 수정(hallucination correction)에서 0.973-0.979 승인율(approval rate)을 기록하며 뛰어난 성능을 입증했습니다.



### Collaborative filtering based on nonnegative/binary matrix factorization (https://arxiv.org/abs/2410.10381)
Comments:
          12 pages, 7 figures

- **What's New**: 본 논문에서는 희소한 데이터의 협업 필터링에 적합한 수정된 Nonnegative/Binary Matrix Factorization (NBMF) 알고리즘을 제안합니다.

- **Technical Details**: 수정된 NBMF 방법에서는 평점 행렬의 평가되지 않은 요소들을 마스킹(masking)하여 협업 필터링 성능을 향상시킵니다. 또한, 저지연 Ising 머신(ising machine)을 사용하여 계산 시간을 단축시키는 장점이 있습니다.

- **Performance Highlights**: 기존 NBMF가 밀집 데이터에서 주로 사용되었던 것과 달리, 제안된 방법은 희소 데이터에서도 효과적으로 작동하여 좋은 추천 성능을 보여줍니다.



### BookWorm: A Dataset for Character Description and Analysis (https://arxiv.org/abs/2410.10372)
Comments:
          30 pages, 2 figures, EMNLP 2024 Findings

- **What's New**: 이 연구에서는 복잡한 내러티브와 수많은 등장인물이 포함된 장편 문학 작품에서 등장인물을 이해하는 데 초점을 맞추고 있습니다. 'BookWorm'이라는 새로운 데이터셋을 도입하여 캐릭터 설명과 분석을 통해 등장인물의 발전과 사회적 맥락을 이해하는 여러 과제를 수행합니다.

- **Technical Details**: 우리는 두 가지 과제를 정의합니다: 등장인물 설명(character description)과 등장인물 분석(character analysis). BookWorm 데이터셋은 Gutenberg Project에서 도서와 관련된 인간 작성 설명과 분석을 쌍으로 구성합니다. 우리는 최첨단 long-context 모델의 성능을 평가하고, 데이터셋을 이용해 retrieval-based 접근 방식이 더 효과적임을 발견했습니다. 다양한 기법을 통해 캐릭터 정보를 검색하고, hierarchical 처리 방식보다 retrieval 기반 모델이 두 작업 모두에서 더 나은 성능을 발휘한다는 것을 입증했습니다.

- **Performance Highlights**: 조정(fine-tuned)된 모델을 사용한 경우, coreference 기반 retrieval 방식이 가장 사실적인 설명을 생성하는 것으로 나타났으며, 이는 사실(fact) 및 함축(entailment) 기반 메트릭을 통해 측정되었습니다. 본 연구는 장편 내러티브 이해에 대한 추가 연구를 촉진할 것이란 기대를 표현하고 있습니다.



### Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning (https://arxiv.org/abs/2410.10360)
- **What's New**: 이번 연구에서는 Retrieval-Augmented Generation (RAG) 접근 방식을 사용하여 대규모 언어 모델(LLMs)의 환상 생성과 지식 노후화 문제를 해결하기 위한 새로운 프레임워크인 Parenting을 제안합니다.

- **Technical Details**: Parenting은 LLM의 파라미터 공간 내에서 adherence와 robustness를 분리하는 방법론으로, forward activation gain을 기반으로 한 주요 파라미터 검색 기법을 활용하여 두 요소와 강히 연결된 중요한 파라미터 유닛을 식별하고 고립시킵니다. 이후 각기 다른 능력을 가진 파라미터 유닛에 대해 특화된 미세 조정 방법을 적용하여 균형 잡힌 adherence와 robustness의 향상을 목표로 합니다.

- **Performance Highlights**: 다양한 데이터셋과 모델을 대상으로 한 광범위한 실험을 통해 Parenting의 효과성과 일반화 가능성이 입증되었습니다.



### Back-of-the-Book Index Automation for Arabic Documents (https://arxiv.org/abs/2410.10286)
- **What's New**: 이 연구는 아랍어 도서의 백서 색인(Back-of-the-book index) 추출 자동화를 통해 도서의 가독성을 향상시키고, 수작업으로 인한 오류를 줄이는 방법을 제안합니다.

- **Technical Details**: 각 인덱스 용어에 대해 관련 페이지에서 모든 가능한 명사구(Noun Phrases)를 추출하여 후보 풀을 정의합니다. 이 명사구는 품사 분석(Part-of-speech analysis)을 통해 식별되며 효율적인 검색을 위해 벡터 데이터베이스(Vector Database)에 저장됩니다. 우리는 정확한 일치(Exact Matches), 어휘 유사성(Lexical Similarity), 의미 유사성(Semantic Similarity) 등의 여러 메트릭을 사용하여 가장 적합한 발생Occurrences를 결정합니다.

- **Performance Highlights**: F1-score가 .966(정확도 Precision = .966, 재현율 Recall = .966)으로 매우 우수한 성능을 기록하였습니다. 이러한 결과는 백서 색인 생성 및 검토 자동화와 관련된 향후 연구에 대한 가능성을 열어줍니다.



### Leveraging Customer Feedback for Multi-modal Insight Extraction (https://arxiv.org/abs/2410.09999)
Comments:
          NAACL 2024

- **What's New**: 이 논문은 고객 피드백의 이미지와 텍스트 정보를 융합하여 행동 가능한 인사이트를 효과적으로 추출하는 새로운 다중 모달(multi-modal) 접근 방식을 소개합니다.

- **Technical Details**: 제안된 방법은 라테ント 공간(latent space)에서 이미지와 텍스트 정보를 융합하고 이미지-텍스트 기반 텍스트 디코더(image-text grounded text decoder)를 통해 관련 피드백 세그먼트를 추출합니다. 약한 지도 학습(weakly-supervised) 데이터 생성 기법을 활용하여 훈련 데이터를 생성합니다.

- **Performance Highlights**: 제안한 모델은 보지 않은 데이터에 대해 평가되었으며, 기존 기준선(baselines)을 F1 점수에서 14점 초과하여 뛰어난 성능을 보였습니다.



### Learning to Rank for Multiple Retrieval-Augmented Models through Iterative Utility Maximization (https://arxiv.org/abs/2410.09942)
- **What's New**: 이 논문은 여러 개의 Retrieval-Augmented Generation (RAG) 에이전트를 위해 통합 검색 엔진을 설계하는 방법을 제시합니다. 이 검색 엔진은 반복적인 피드백 수집 과정을 통해 각 에이전트의 요구에 최적화됩니다.

- **Technical Details**: 이 새로운 방법론은 expectation-maximization 알고리즘에 기반하여, 각 에이전트의 유틸리티 함수를 극대화하는 것을 목표로 합니다. 오프라인 단계에서는 검색 엔진이 최적의 매개변수를 사용하여 문서를 검색하고, 각 에이전트로부터 피드백을 받아 이를 바탕으로 개선합니다. 또한 온라인 환경에서도 실시간 피드백을 활용하여 검색 결과를 조정합니다.

- **Performance Highlights**: KILT 벤치마크의 다양한 데이터셋에서 실험한 결과, 제안하는 방법이 18개의 RAG 모델에서 평균적으로 기존의 최첨단 방법보다 훨씬 우수한 성능을 보였습니다. 개인화 과정에서 검색 엔진의 성능 또한 향상되었음을 입증하였습니다.



### ViFi-ReID: A Two-Stream Vision-WiFi Multimodal Approach for Person Re-identification (https://arxiv.org/abs/2410.09875)
- **What's New**: 본 연구는 WiFi 신호와 비디오 데이터의 멀티모달(fusion) 접근 방식을 활용하여 사람 재식별(Person Re-identification, ReID)에 대한 혁신적인 해결책을 제시합니다. 기존의 이미지 기반 방법의 한계를 극복하기 위해, 우리는 일반적인 라우터를 감지 장치로 활용하여 보행 정보(gait)를 추출합니다. 이를 통해 다양한 환경에서도 일관된 ReID 성능을 유지할 수 있습니다.

- **Technical Details**: 우리는 두 가지 스트림 네트워크를 활용하여 비디오 이해(video understanding)와 신호 분석(signal analysis) 작업을 별도로 처리하고, 비디오 데이터와 WiFi 데이터를 결합하여 멀티모달 퓨전을 수행합니다. WiFi 신호는 고정 시간 단위로 인코딩되고 영상 모듈에서는 독립적인 공간 및 시간 인코더를 사용하여 보행 모션 특징을 추출합니다. 크로스 모달(cross-modal) 맵핑을 위해 대비 학습(contrastive learning)과 어려운 예제 마이닝(hard example mining) 기반의 손실 함수를 설계하였습니다.

- **Performance Highlights**: 실제 환경에서 실시된 실험을 통해 제안한 방법이 다양한 센서 간의 상관관계를 효과적으로 발견하고, 시각과 신호 모달리티 간의 격차를 줄이며, 감지 범위를 크게 확장하고 ReID 정확도를 개선함을 입증했습니다. 이로 인해, 다양한 환경(단일 모달 및 멀티모달)에서 사람의 ID를 일관되게 추적할 수 있는 가능성을 제시합니다.



### Generating Driving Simulations via Conversation (https://arxiv.org/abs/2410.09829)
Comments:
          6 pages, 6 figures, 2 tables

- **What's New**: 본 논문은 자율주행차의 시뮬레이션 테스트를 위한 자연어 인터페이스를 설계하였습니다. 이 인터페이스는 비코딩(Non-coding) 도메인 전문가는 적절한 시나리오와 차량 행동을 합성하는 데 도움을 줍니다. 인간 실험 결과, 대화가 성공적인 시뮬레이션 생성을 위해 필수적이라는 것을 보여주며, 대화를 통한 성공률이 4.5배 높았습니다.

- **Technical Details**: 이 시스템은 자연어로 작성된 설명을 바탕으로 Scenic 코드를 생성하는 대화 시스템입니다. 사용자가 시뮬레이션 인스턴스에 반응하며 대화하는 방식으로 작동합니다. 이 시스템은 retrieval-augmented generation (RAG) 및 in-context learning을 사용하여 프로그램을 생성합니다. 시뮬레이터에서 생성된 시뮬레이션의 성공 여부에 따라 사용자의 피드백을 받아 출력을 수정합니다.

- **Performance Highlights**: 우리는 자율주행차의 다양한 주행 시나리오에 대한 자연어 설명과 Scenic 프로그램 쌍으로 구성된 데이터 세트를 생성했습니다. 이 데이터 세트를 활용하여 대화 시스템의 정확도를 평가했으며, 대화의 여러 턴을 통한 상호작용이 효과적임을 확인했습니다.



### ContextWIN: Whittle Index Based Mixture-of-Experts Neural Model For Restless Bandits Via Deep RL (https://arxiv.org/abs/2410.09781)
- **What's New**: 이 연구에서는 ContextWIN이라는 새로운 아키텍처를 소개합니다. 이는 Neural Whittle Index Network (NeurWIN) 모델을 확장하여 맥락 인식(Context-aware) 접근 방식을 통해 Restless Multi-Armed Bandit (RMAB) 문제를 해결합니다.

- **Technical Details**: ContextWIN은 강화 학습(Reinforcement Learning) 프레임워크 내에서 전문가 혼합(Mixture of Experts)을 통합하여 동적 환경에서 결정을 내리는 데 필요한 맥락 정보를 효과적으로 활용합니다. 이 모델은 NeurWIN 네트워크의 하위 집합에 맥락별 가중치를 할당하여 각 팔에 대한 Whittle 지수 계산의 효율성과 정확성을 개선합니다. ContextWIN은 NeurWIN 모듈과 통합되어 각 팔에 대한 Whittle 지수를 배워냅니다.

- **Performance Highlights**: 실험 결과, ContextWIN은 다양한 RMAB 시나리오에서 실용적인 효율성을 증명하였으며, 특히 추천 시스템에서의 성능 향상을 보여주었습니다. 연구는 또한 NeurWIN과 ContextWIN 모델 간의 수렴(convergence)을 엄밀히 입증하여 이론적 강건성을 보장합니다.



### Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models (https://arxiv.org/abs/2410.09629)
Comments:
          EMNLP 2024 main conference long paper

- **What's New**: 이번 연구에서는 기존의 지식 습득의 한계를 극복하기 위해, 새로운 합성 지식 습득 방법인 Ski를 제안합니다. 이 방법은 정밀한 합성, 교차 생성, 조립 증대 전략을 활용하여 원천 지식으로부터 고품질 데이터 표현을 구축합니다.

- **Technical Details**: Ski는 Fine-grained Synthesis를 통해 n-gram 지식 맥락 기반의 가상의 질문을 생성하고, Interleaved Generation을 통해 특정 지식에 대한 질문과 답변을 동시 생성합니다. Assemble Augmentation은 다양한 n-gram 범위에서 Fine-grained Synthesis를 조합하여 질문과 답변 쌍을 균형 있게 반복합니다. 이 방식으로 Ski는 LLM의 지식 정제를 효과적으로 지원합니다.

- **Performance Highlights**: Ski는 금융, 생명 의학, 개방 생성 등의 다양한 질문-답변 작업에서 두 개의 오픈 소스 LLM인 Llama2-7B와 Mistral-7B에 대해 실험을 수행하여 기존 방법들보다 상당히 높은 성능을 기록했습니다.



### Toward General Instruction-Following Alignment for Retrieval-Augmented Generation (https://arxiv.org/abs/2410.09584)
Comments:
          Working in progress

- **What's New**: 이 연구에서는 Retrieval-Augmented Generation (RAG) 시스템의 instruction-following (IF) 정렬을 위한 최초의 자동화된, 확장 가능하며 검증 가능한 합성 파이프라인인 VIF-RAG를 제안합니다.

- **Technical Details**: VIF-RAG는 100개 미만의 최소 원자 지침을 수동으로 작성하고, 복잡한 지침을 합성하고 검증하기 위한 조합 규칙을 개발합니다. 감독 모델을 사용하여 지침을 재작성하고, Python 실행기를 통해 지침 품질을 자동으로 검증하는 코드를 생성합니다. 이 과정을 통해 >100k 규모의 고품질 VIF-RAG-QA 데이터셋을 자동으로 생성합니다. 또한 FollowRAG Benchmark를 도입하여 약 3천 개의 테스트 샘플과 22개 범주의 일반 지침 제약과 4개 지식 집약적 QA 데이터셋을 포함합니다.

- **Performance Highlights**: FollowRAG를 사용하여 VIF-RAG가 LLM 성능을 일반 지침 제약의 넓은 범위에서 크게 향상시키는 것을 보여줍니다. 해당 연구는 RAG 시스템에서 IF 정렬을 달성하기 위한 실용적인 통찰력을 제공합니다.



### ACER: Automatic Language Model Context Extension via Retrieva (https://arxiv.org/abs/2410.09141)
- **What's New**: 본 논문에서는 자동화된 데이터 합성 파이프라인(Automatic Data Synthesis Pipeline)을 통해 긴 문맥(long-context) 처리 능력을 향상시키는 새로운 접근 법을 제안합니다. 기존의 모델들이 긴 문맥 처리에서 한계를 보이는 반면, 이와는 달리 짧은 문맥(short-context) 모델을 활용하여 사용자의 질문에 대한 효과적인 긴 문맥 처리를 가능하게 할 수 있는 방안을 모색하고 있습니다.

- **Technical Details**: 제안된 접근법인 ACER(Automates Context Extension via Retrieval)는 두 단계로 구성됩니다: 1) 자동 데이터 합성, 2) 자기 훈련(self-training). 첫 번째 단계에서는 사전 훈련된 짧은 문맥 LM을 이용해 정보 검색(retrieval) 후 불완전한 데이터를 생성하고, 두 번째 단계에서는 이 데이터를 기반으로 긴 문맥 처리 능력을 개선하기 위해 LM을 미세 조정합니다.

- **Performance Highlights**: 실험 결과, ACER로 훈련된 모델은 감독 없이도 기존의 일반적인 긴 문맥 모델들을 초과하는 성능을 보였으며, 실제 테스트 데이터셋에서도 효과적인 긴 문맥 검색 생성(long-context retrieval augmented generation) 작업에서 높은 성과를 거두었습니다.



### $\textit{lucie}$: An Improved Python Package for Loading Datasets from the UCI Machine Learning Repository (https://arxiv.org/abs/2410.09119)
Comments:
          5 pages, 3 figures

- **What's New**: 이번 연구에서는 UCIMLR(University of California--Irvine Machine Learning Repository)에서 많은 데이터셋이 구식 형식으로 저장되어 있어 기존의 ucimlrepo 패키지를 통해 쉽게 가져올 수 없다는 문제를 해결하기 위한 도구인 lucie를 제안합니다. lucie는 자동으로 데이터 형식을 판별하여 이전에 가져올 수 없었던 데이터셋을 가져올 수 있도록 도와줍니다.

- **Technical Details**: lucie는 인기 있는 상위 100개의 데이터셋을 기반으로 설계되었으며, 이후 130개의 추가 데이터셋에서 검증되었습니다. 이 도구는 특정 데이터 형식의 파일을 탐색하고 스크래핑하여 데이터를 pandas 데이터프레임으로 불러오는 데 성공적으로 작동합니다. 기준으로 95.4%의 성공률을 기록했으며, 이는 기존의 ucimlrepo의 73.1%와 비교하여 상당히 높은 성과입니다.

- **Performance Highlights**: lucie는 이전에는 가져올 수 없었던 데이터셋을 손쉽게 다룰 수 있게 만들어줍니다. 또한, 대부분의 데이터셋에서 자주 발생하는 공통적인 패턴을 발견하여 이를 기반으로 데이터 임포트를 일반화하였으며, 링크와 URL 기반의 데이터셋을 자동으로 가져오는 기능을 갖추고 있습니다.



New uploads on arXiv(cs.CV)

### BiGR: Harnessing Binary Latent Codes for Image Generation and Improved Visual Representation Capabilities (https://arxiv.org/abs/2410.14672)
Comments:
          Project page: this https URL

- **What's New**: 새로운 BiGR 모델은 조건부 이미지 생성(conditional image generation)을 위한 방식으로, 효율적인 이미지 생성을 지원하는 혁신적인 엔트로피 순서 샘플링(entropy-ordered sampling) 방법을 도입했습니다. 이 모델은 생성(generation)과 판별(discrimination) 작업을 통합하여 동일한 프레임워크 내에서 처리합니다.

- **Technical Details**: BiGR 모델은 바이너리 토크나이저(binary tokenizer), 마스킹 모델링(masked modeling) 메커니즘, 바이너리 트랜스코더(binary transcoder)를 사용하여 바이너리 코드 예측을 수행합니다. 이러한 설계는 생성 및 표현 성능을 동시에 향상시키는 데 중점을 둡니다.

- **Performance Highlights**: 광범위한 실험을 통해 BiGR은 FID-50k를 기준으로 한 생성 품질에서 우수한 성능을 보이며, 선형 프로브(linear-probe) 정확도를 통해 표현 능력에서도 성과를 입증했습니다. 또한, BiGR은 여러 비전 작업에서 제로샷 제너럴리제이션(zero-shot generalization) 기능을 보여주어, 구조적 수정 없이 이미지 인페인팅(image inpainting), 아웃페인팅(outpainting), 편집(editing), 보간(interpolation), 보강(enrichment) 등 다양한 응용이 가능합니다.



### Parallel Backpropagation for Inverse of a Convolution with Application to Normalizing Flows (https://arxiv.org/abs/2410.14634)
Comments:
          Preprint

- **What's New**: 본 연구에서는 이미지 디블러링(image deblurring), 정규화 흐름(Normalizing Flows) 등 다양한 응용 분야에서 사용되는 가역적 컨볼루션(invertible convolution)의 빠른 병렬 역전파(backpropagation) 알고리즘을 제안합니다. 기존의 $O(n^3)$ 시간 복잡도를 가진 알고리즘과 달리, 제안하는 알고리즘은 $O(\\sqrt{n})$의 시간 복잡도로 실행됩니다.

- **Technical Details**: 우리는 m×m(m 	imes m) 크기의 정사각형 이미지에 대해 O(m⋅k^2) 시간 복잡도를 가지는 병렬 역전파 알고리즘을 개발하여 GPU(CUDA)에서 구현하였습니다. 이 알고리즘은 정규화 흐름의 전방 패스(forward pass)에서 컨볼루션과 함께 작동하여 반전된 정규화 흐름 모델(Inverse-Flow)을 구성합니다.

- **Performance Highlights**: Inverse-Flow 모델은 표준 데이터셋(MNIST, CIFAR10)에서 샘플링 속도가 크게 개선되었으며, 이전 모델들과 비슷한 bits per dimension을 유지하였습니다. 이를 통해 빠른 샘플 생성 및 효율적인 모델 평가가 가능하다는 것을 입증하였습니다.



### Swiss Army Knife: Synergizing Biases in Knowledge from Vision Foundation Models for Multi-Task Learning (https://arxiv.org/abs/2410.14633)
- **What's New**: 이 논문은 여러 비전 기초 모델(VFM)을 통합하여 다중 작업 학습을 향상시키기 위한 새로운 접근 방식인 '스위스 아미 나이프(SAK, Swiss Army Knife)' 모델을 제안합니다. SAK는 각 VFM의 고유한 표현 편향을 보존하면서 지식을 적응적으로 증류하는 프레임워크입니다.

- **Technical Details**: SAK는 여러 VFM 간의 지식 증류를 위해 다중 교사 지식 증류 프레임워크를 활용합니다. 이는 교사 비특화 스템(Teacher-Agnostic Stem)과 교사 특정 어댑터 경로(Teacher-Specific Adapter Path) 모듈을 포함하여 각 VFM 교사에 맞춘 특별한 표현을 생성합니다. 추가적으로, 표현 혼합 라우터(Mixture-of-Representations Router)를 통해 관련성이 높은 표현을 동적으로 선택하고 결합합니다.

- **Performance Highlights**: SAK는 NYUD-v2 벤치마크에서 다중 작업 학습의 이전 최첨단 모델보다 10% 이상의 성능 향상을 보여주며, PASCAL-Context와 NYUD-v2의 두 개의 널리 사용되는 다중 작업 벤치마크에서 평가되었습니다. 이 모델은 다양한 VFM 교사와 다중 작업을 지원하는 높은 유연성을 제공합니다.



### MultiOrg: A Multi-rater Organoid-detection Datas (https://arxiv.org/abs/2410.14612)
- **What's New**: MultiOrg는 불확실성(uncertainty) 정량화 기능이 포함된 생물의학 분야의 객체 탐지(object detection) 작업을 위한 포괄적인 오르가노이드(organoid) 데이터셋입니다. 이 데이터셋은 400개 이상의 고해상도 2D 현미경 이미지와 60,000개 이상의 오르가노이드 주석(annotation)으로 구성되어 있습니다.

- **Technical Details**: MultiOrg 데이터셋은 두 전문가가 서로 다른 시간에 독립적으로 주석을 달아 제공하는 세 가지 레이블 세트를 포함하고 있습니다. 이는 주석의 불확실성을 정량화할 수 있는 기회를 제공합니다. 데이터셋에는 다양한 생물학적 연구 설정에서 유래된 오르가노이드가 포함되어 있으며, 두 가지 유형의 오르가노이드가 다르게 자라고 있습니다. 또한, 사용자들이 시각화 및 수정할 수 있는 Lung organoids를 위한 도구도 함께 제공합니다.

- **Performance Highlights**: 다양한 객체 탐지 알고리즘에 대한 벤치마킹을 위해 네 가지 잘 알려진 딥 러닝 모델을 교육 및 테스트했습니다. 이 데이터셋은 기존 오르가노이드 데이터셋 중 두 번째로 큰 규모이며, 여러 레이블을 도입한 첫 번째 생물의학 객체 탐지 데이터셋 중 하나로 꼽힙니다. 또한, 사용자는 napari 플러그인을 통해 오르가노이드의 정량화를 수행할 수 있어 생물학적 연구를 위한 고속 이미지 분석이 가능해집니다.



### DRACO-DehazeNet: An Efficient Image Dehazing Network Combining Detail Recovery and a Novel Contrastive Learning Paradigm (https://arxiv.org/abs/2410.14595)
Comments:
          Submitted to a journal and currently under review. Once the paper is accepted and published, the copyright will be transferred to the corresponding journal

- **What's New**: 본 논문에서는 새로운 Detail Recovery And Contrastive DehazeNet (DRACO-DehazeNet) 모델을 제안하여, 제한된 데이터로도 효과적으로 훈련이 가능하며, 효율적인 영상 해상 기술을 제공하는 방법을 소개합니다.

- **Technical Details**: DRACO-DehazeNet은 Dense Dilated Inverted Residual Block (DDIRB) 및 ATTention-imbued Detail Recovery Network (ATTDRN)를 결합하여 이상적으로 설계되었으며, quadruplet loss에 기반한 contrastive dehazing 기법을 도입하여 haze와 clear 이미지의 특징을 명확히 구분합니다.

- **Performance Highlights**: 다양한 벤치마크 haze 데이터셋에 대한 광범위한 테스트 결과, DRACO-DehazeNet은 기존 방법들에 비해 뛰어난 성능을 입증하였으며, 해당 작업을 위한 코드 저장소도 곧 공개될 예정입니다.



### Multi-modal Pose Diffuser: A Multimodal Generative Conditional Pose Prior (https://arxiv.org/abs/2410.14540)
- **What's New**: 이 논문에서는 MOPED(Multi-modal Pose Diffuser)를 소개하며, 이는 기존의 SMPL(Scanned Multi-Person Linear) 모델의 한계를 극복하기 위해 다중 모드 조건부 확산 모델을 활용한 첫 번째 방법입니다. MOPED는 이미지 및 텍스트와 같은 다양한 입력에 조건을 부여하여 포즈 생성을 가능하게 합니다.

- **Technical Details**: MOPED는 조건부 확산 모델(conditional diffusion model)을 사용하여 실제적인 인간 자세를 분류하는 강력한 인간 자세 우선 모델입니다. 이 방법은 포즈 추정(pose estimation), 포즈 노이즈 제거(pose denoising), 포즈 완성(pose completion)이라는 세 가지 작업에서 효과를 증명하였습니다.

- **Performance Highlights**: MOPED는 전통적인 포즈 모델들보다 향상된 성능을 보이며, 다양한 포즈 관련 작업에서 강력한 성능을 입증하였습니다. 이를 통해, MOPED가 포즈 예측의 정확도를 크게 높일 수 있음을 확인할 수 있습니다.



### CLIP-VAD: Exploiting Vision-Language Models for Voice Activity Detection (https://arxiv.org/abs/2410.14509)
- **What's New**: 본 연구에서는 최신 비주얼-언어 모델의 발전에서 영감을 받아, Contrastive Language-Image Pretraining (CLIP) 모델을 활용한 새로운 음성 활동 탐지 방법(Voice Activity Detection, VAD)을 제안합니다. 이 방법은 상반신 영상과 자동으로 생성된 텍스트 설명을 결합한 딥 뉴럴 네트워크를 통해 VAD를 수행합니다.

- **Technical Details**: CLIP-VAD라는 이름의 제안된 네트워크는 상반신 이미지를 포함한 비디오 세그먼트를 처리가능한 비주얼 인코더(visual encoder)와 VLM에 의해 제공된 텍스트 설명을 처리하는 텍스트 인코더(text encoder)를 포함합니다. 이 인코더들은 최종적으로 VAD 작업을 수행하기 위해 결합됩니다. CLIP의 대조 손실(constrastive loss)을 활용하여 비주얼 및 텍스트 데이터를 정렬하는 것이 특징입니다.

- **Performance Highlights**: 실험 결과, CLIP-VAD는 기존의 비주얼 VAD 방법에 비해 우수한 성능을 보이며, 대규모 음성-비주얼 데이터셋에서 전처리 없이도 오디오-비주얼 VAD 방식과 유사하거나 더 나은 성능을 달성했습니다.



### LEAD: Latent Realignment for Human Motion Diffusion (https://arxiv.org/abs/2410.14508)
- **What's New**: 이 연구에서 제안하는 LEAD 모델은 latent diffusion을 기반으로 하는 텍스트-모션 (text-to-motion) 생성 모델로, 기존 모델들이 가지고 있는 의미 구조의 결여를 보완하고자 한다.

- **Technical Details**: LEAD는 motion VAE의 원래 latent 공간을 언어 모델인 CLIP과 더 잘 일치하도록 재조정하는 projector 모듈을 적용하여 새로운 의미 구조를 갖춘 latent 공간을 형성한다. 이를 통해 motion textual inversion이라는 새로운 작업을 제안하며, 사전 훈련된 언어 모델의 latent 공간에서 예시 동작의 특성을 가장 잘 캡처하는 임베딩을 찾는 방식으로 동작한다.

- **Performance Highlights**: LEAD는 HumanML3D와 KIT-ML 데이터셋에서 텍스트-모션 생성을 수행한 결과, 기존의 최첨단 모델들과 비슷한 성능을 보여주었으며, 특히 텍스트로부터 개인화된 동작 생성을 위한 작업에서 더욱 개선된 질적 및 양적 결과를 보였다.



### Neural Real-Time Recalibration for Infrared Multi-Camera Systems (https://arxiv.org/abs/2410.14505)
Comments:
          real-time camera calibration, infrared camera, neural calibration

- **What's New**: 현재 적시적소의 인프라레드 다중 카메라 시스템의 실시간 교정에 대한 학습이 필요하지 않은 신경망 기법이 없습니다. 이 논문에서는 실시간으로 높은 정확도의 다중 카메라 인프라레드 시스템 교정을 다루며, 동적 실시간 교정이 가능한 신경망 기반 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 3D 기하학과 2D 이미지 프로젝션을 직접 연관시키는 미분 가능한 프로젝션 모델을 통합하여 내재적 및 외재적 카메라 파라미터의 직접 최적화를 용이하게 합니다. 모델 변형 두 가지를 소개하며, 하나는 온보드 처리로 2D 포인트를 다루는 다중 카메라 시스템을 위한 것이고, 다른 하나는 색상 코드된 프로젝션 포인트를 사용하는 이미지 기반 시스템입니다.

- **Performance Highlights**: 공식 실험을 통해 우리는 제안된 방법이 전통적인 교정 기법보다 더 높은 정확도를 보이며, 시간이 중요한 애플리케이션에 요구되는 실시간 교정을 달성함을 입증했습니다. 이는 다중 카메라 시스템의 실시간 교정 분야에서 중요한 도약을 의미합니다.



### How Do Training Methods Influence the Utilization of Vision Models? (https://arxiv.org/abs/2410.14470)
Comments:
          Accepted at the Interpretable AI: Past, Present and Future Workshop at NeurIPS 2024

- **What's New**: 이 논문은 인공 신경망에서 각 격자의 중요성이 어떻게 달라지는지를 집중적으로 조사하며, 특히 훈련 방법이 신경망의 결정 함수에 미치는 영향을 분석하였습니다. 이를 위해 동일한 아키텍처와 훈련 데이터를 사용하되, 다양한 훈련 관행을 활용하여 이미지 분류 모델들을 비교하였습니다.

- **Technical Details**: 연구는 ResNet-50 아키텍처를 기반으로 하여 진행되었으며, 각 층의 파라미터를 무작위 값으로 대체하는 방법을 사용하여 각 층의 기여도를 측정하였습니다. 이때 Softmax 함수를 적용하여 결정 확률 벡터의 코사인 거리를 통해 층의 중요성을 수치적으로 평가하였습니다. 또한, 훈련 방법에 따라 특정 층들이 중요하게 작용하는지에 대한 차이를 관찰하였습니다.

- **Performance Highlights**: 결과적으로, 훈련 방법이 각 층의 중요도에 큰 영향을 미친다는 것을 확인하였습니다. 예를 들어, 개선된 훈련 레짐과 자가 지도 학습이 조기 층의 중요성을 높였고, 반면 적대적 훈련(adversarial training)은 이러한 경향과는 반대의 결과를 보였습니다. 이는 신경망 내부의 메커니즘을 더 깊이 이해하는 데 기여할 것으로 보입니다.



### LUDVIG: Learning-free Uplifting of 2D Visual features to Gaussian Splatting scenes (https://arxiv.org/abs/2410.14462)
- **What's New**: 본 논문에서는 2D 비전 모델의 시각적 특징이나 의미 마스크(semantic masks)를 3D 장면으로 업리프트하는 방식에 대해 다루고 있습니다. 기존의 반복 최적화(iterative optimization) 기반 접근법에 의존하는 대신, 간단하면서도 효과적인 집계 기법(aggregation technique)을 제시하여 뛰어난 결과를 얻었습니다.

- **Technical Details**: 이 연구는 Segment Anything(SAM)에서 제공되는 의미 마스크를 적용하여 최첨단(segmentation quality comparable to the state of the art) 세분화 품질을 달성했습니다. DINOv2 피처를 일반 형태로 확장하고, 그래프 확산(graph diffusion)을 통해 3D 장면 기하학을 통합하여, SAM에 비해 수백만 개의 주석 마스크로 학습되지 않은 DINOv2를 사용하더라도 경쟁력 있는 세분화 결과를 성취했습니다.

- **Performance Highlights**: SAM에서 생성된 의미 마스크에 적용했을 때, 본 연구의 방법은 최첨단 기술에 비해 상당히 빠르며 비교 가능한 세분화 결과를 달성하였습니다. DINOv2를 통한 세분화 성능 또한 이전 SAM 기반의 연구에 필적하여, 간단한 차원 축소(dimensionality reduction)와 그래프 확산을 활용하여 3D 장면 기하학을 통합했습니다.



### Toward Generalizing Visual Brain Decoding to Unseen Subjects (https://arxiv.org/abs/2410.14445)
- **What's New**: 이번 연구는 기존의 뇌 디코딩 기술이 미지의 주체들에게 일반화될 수 있는지를 탐구합니다. 특히, 177명의 주체를 포함하는 대규모 이미지-fMRI 데이터셋을 구축하여, 다양한 주체의 뇌 활동을 연구하며 일관된 처리를 통해 일반화 능력을 향상시키고자 하였습니다.

- **Technical Details**: 연구는 Human Connectome Project(HCP)에서 수집한 3,127쌍의 이미지-fMRI 반응 데이터로 구성된 데이터셋을 활용합니다. 단일 모델을 사용하여 MLP, CNN, Transformer와 같은 다양한 네트워크 아키텍처에서 일반화 성능을 실험하였습니다. 모든 주체에 대해 동일한 처리 방식을 적용하여 모델 복잡성을 최소화하였습니다.

- **Performance Highlights**: 훈련 주체 수에 따른 일반화 능력의 명확한 증가를 보여주며, 훈련 주체 수가 1명에서 167명으로 증가하면서 정확도가 2%에서 45%로 향상되었습니다. 주체 간 유사성에 따라 일반화 성능이 달라지는 경향도 관찰되었으며, 남성과 여성 그룹 간의 차이가 크다는 결과를 도출하였습니다.



### FashionR2R: Texture-preserving Rendered-to-Real Image Translation with Diffusion Models (https://arxiv.org/abs/2410.14429)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 논문은 렌더링된 이미지를 사실감 있는 이미지로 변환하는 새로운 프레임워크를 소개합니다. 주목할 만한 점은 긍정적인 도메인 정제(finetuning)와 부정적인 도메인 임베딩(embedding) 기법을 적용하여 촬영된 이미지를 바탕으로 사전 학습된 Text-to-image (T2I) diffusion 모델에 지식을 주입하는 것입니다.

- **Technical Details**: 제안된 프레임워크는 두 단계로 구성됩니다: Domain Knowledge Injection (DKI)와 Realistic Image Generation (RIG). DKI 단계에서는 T2I diffusion 모델에 지식을 주입하고, RIG 단계에서는 입력된 렌더링 이미지를 기반으로 사실적인 이미지를 생성합니다. 이때 Texture-preserving Attention Control (TAC)을 사용하여 미세한 의류 텍스처를 보존하고, UNet 구조에 인코딩된 분리된 기능을 활용합니다.

- **Performance Highlights**: 제안된 방법은 렌더링된 이미지를 현실 이미지로 변환하는 과정에서 효과적이며 우수한 성능을 보여주었습니다. 또한, SynFashion 데이터셋을 통해 다양한 텍스처를 가진 고품질 디지털 의류 이미지를 제공하여 연구에 기여하고 있습니다.



### Variable Aperture Bokeh Rendering via Customized Focal Plane Guidanc (https://arxiv.org/abs/2410.14400)
- **What's New**: 본 논문에서는 사용자 맞춤형 초점면 제어와 다양한 조리개 생성 기능을 제공하는 효과적인 Bokeh 렌더링 방법을 제안하고, 변동 조리개 Bokeh 데이터셋(Variable Aperture Bokeh Dataset, VABD)을 기여합니다.

- **Technical Details**: 제안된 변동 조리개 Bokeh 모델(Variable Aperture Bokeh Model, VABM)은, 사용자가 제공하는 초점면 마스크 및 심도 맵(depth map)을 기반으로 Bokeh를 렌더링합니다. 이 모델은 Mamba를 통해 긴 거리 의존성을 모델링하여 컴퓨팅 비용을 줄입니다.

- **Performance Highlights**: VABM은 단 4.4M의 파라미터로 공인된 EBB! 벤치마크 데이터셋과 VABD 데이터셋에서 경쟁력 있는 성능을 달성하였으며, 기존 방법들보다 가벼운 계산 부담을 가지고 있습니다.



### Dynamic Negative Guidance of Diffusion Models (https://arxiv.org/abs/2410.14398)
Comments:
          Paper currently under review. Submitted to ICLR 2025

- **What's New**: 이번 논문에서는 기존의 Negative Prompting (NP) 기법의 한계를 분석하고, 이를 보완하기 위한 Dynamic Negative Guidance (DNG)라는 새로운 기술을 제안합니다. DNG는 추가적인 훈련 없이 시간 및 상태에 기반한 최적의 모드를 통해 가이드를 조절하는 기법입니다.

- **Technical Details**: DNG는 기존 NP와 달리, 디노이징 과정 중 posterior class probability를 추정하는 데 초점을 맞춥니다. 이를 위해 생성 과정에서 이산 마르코프 체인을 추적하여 제한된 계산 오버헤드로 진행합니다. DNG의 구현은 기존 프로세스를 크게 변경하지 않으면서도 효과적인 개선을 보여줍니다.

- **Performance Highlights**: MNIST 및 CIFAR10 데이터셋에서 DNG의 성능을 평가한 결과, 기존 방법들과 비교했을 때 안전성, 클래스 균형 유지 및 이미지 품질이 향상되었음을 확인하였습니다. 또한, DNG는 Stable Diffusion과의 결합을 통해 NP보다 더 정확하고 덜 침해적인 가이드를 제공할 수 있는 가능성을 보였습니다.



### AnomalyNCD: Towards Novel Anomaly Class Discovery in Industrial Scenarios (https://arxiv.org/abs/2410.14379)
- **What's New**: 본 논문은 기존의 이상 탐지 방법들의 한계를 극복하고, 산업 분야의 이상을 자동으로 발견하고 인식하는 새로운 프레임워크인 AnomalyNCD를 제안합니다. 이 프레임워크는 새로운 클래스를 효과적으로 발견할 수 있는 Novel Class Discovery (NCD) 기법을 활용하여 여러 클래스의 이상을 분류할 수 있도록 합니다.

- **Technical Details**: AnomalyNCD 프레임워크는 주 요소 이진화(Main Element Binarization, MEBin) 기술을 사용하여 이상 영역을 마스크 형태로 분할하고, 이후 마스크 기반 대비 표현 학습(mask-guided contrastive representation learning)을 통해 특징의 분별력을 향상시킵니다. 이 과정을 통해 네트워크의 초점을 실제 이상 영역에 집중시켜, 매칭되지 않은 이상에 대한 혼동을 줄이고, 각 이상을 분류할 수 있도록 합니다. 또, 이미지와 영역 수준의 유연한 분류를 가능하게 하는 영역 병합 전략도 개발되었습니다.

- **Performance Highlights**: AnomalyNCD는 MVTec AD 및 MTD 데이터셋에서 최신 연구 결과를 능가하는 성능을 기록했습니다. 기존 방법들에 비해 AnomalyNCD는 MVTec AD에서 10.8%의 $F_1$ 증진, 8.8% NMI 증진, 9.5% ARI 증진을 달성했으며, MTD에서는 각각 12.8%, 5.7%, 10.8%의 증진을 보였습니다.



### Impact of imperfect annotations on CNN training and performance for instance segmentation and classification in digital pathology (https://arxiv.org/abs/2410.14365)
- **What's New**: 본 연구는 디지털 병리학에서 세포 핵을 탐지하고 세분화 및 분류하는 과제에서 노이즈가 있는 주석이 CNN 모델의 성능에 미치는 영향을 조사합니다. 특히, 주석 노이즈에 대한 과적합(overfitting)을 방지하기 위한 적절한 훈련 에포크 수 결정 조건을 분석합니다.

- **Technical Details**: 이 연구는 CNN 모델을 사용하여 잘못된 주석이 도입된 훈련 세트를 사용합니다. 실험에서는 잘 정제된 검증 세트를 이용하여 과적합을 방지하고 모델 성능을 유지하는 방법을 검토하며, 사전 훈련(pre-training) 역할의 유익성도 강조합니다.

- **Performance Highlights**: 완벽한 검증 세트를 사용하여 훈련을 중단하는 것이 성능 회복에 크게 기여하며, CNNs가 주석의 오류를 어느 정도 견딜 수 있다는 결과를 도출하였습니다.



### Zero-shot Action Localization via the Confidence of Large Vision-Language Models (https://arxiv.org/abs/2410.14340)
- **What's New**: 본 연구에서는 대규모 비전-언어 모델(LVLM)을 활용하여 비지도 학습(unsupervised learning) 환경에서 제로샷 액션 로컬리제이션(Zero-Shot Action Localization, ZEAL) 방법을 제안합니다. 기존 방법들이 많은 데이터와 레이블을 필요로 하는데 비해, 제안된 방법은 고급 언어 모델(LLM)의 내장된 액션 지식을 바탕으로 액션의 시작과 끝을 명확히 설명하는 질의를 생성합니다.

- **Technical Details**: 본 논문은 LLM을 활용하여 액션 클래스를 시작과 끝의 세밀한 설명자로 분해하고, 이 설명자를 LVLM에 질의로 사용하여 각 비디오 프레임에 대한 신뢰 점수를 생성합니다. LVLM은 이러한 비주얼 질문에 대해 긍정 또는 부정으로 답변하며, 이러한 신뢰 점수를 통해 액션 로컬리제이션을 수행합니다.

- **Performance Highlights**: THUMOS14 데이터셋에서 이전의 훈련 기반 방법들과 비교하여 경쟁력 있는 또는 최첨단의 제로샷 결과를 달성했습니다. 이는 본 프레임워크가 훈련 데이터나 특정 작업에 구애받지 않고 액션 로컬리제이션을 수행할 수 있는 유연성을 가지며, 실제 비디오 분석에서의 적용 가능성을 시사합니다.



### Evaluating the evaluators: Towards human-aligned metrics for missing markers reconstruction (https://arxiv.org/abs/2410.14334)
- **What's New**: 이번 논문에서는 결측 마커 복원을 위한 머신러닝(Machine Learning) 기반 솔루션의 성능 평가를 위한 새로운 메트릭을 제안하고 평가하였다. 현재까지 주로 사용되어온 평균 제곱 오차(Mean Squared Error, MSE) 지표는 결측 마커의 품질 주관적 인식과 상관관계가 없음을 밝혔다. 이를 보완하기 위해 새로운 메트릭인 Bone Distance Preservation (BDP) 및 Velocity Distance (VD)를 제안하였다.

- **Technical Details**: Motion capture (MoCap) 기술은 영화 및 비디오 게임 산업에서 가상의 캐릭터에 사실적인 움직임을 부여하기 위해 널리 사용된다. 기존의 연구들은 딥러닝(Deep Learning) 모델을 사용하여 마커 결측 문제를 해결하려 했으며, 주로 인공적으로 생성된 데이터에서의 성능 측정에 의존했다. 본 연구는 실제 데이터에서의 성능 평가에 초점을 맞추고, 새로운 메트릭이 애니메이터의 요구와 얼마나 잘 일치하는지를 분석하였다.

- **Performance Highlights**: Human subject study를 통해 다양한 머신러닝 시스템으로 청소된 모션 캡처 시퀀스에 대한 전문가의 인식 품질 평가와 새로운 메트릭의 상관관계를 분석했다. 결론적으로, 새로운 메트릭이 MSE보다 애니메이션 품질에 대한 인간의 판단과 더 잘 맞으므로, 향후 MoCap 데이터 청소 및 복원 분야에서 더 나은 발전을 이끌어낼 것으로 기대된다.



### Croc: Pretraining Large Multimodal Models with Cross-Modal Comprehension (https://arxiv.org/abs/2410.14332)
Comments:
          18 pages, 11 figures

- **What's New**: 이 논문에서는 Large Multimodal Models (LMMs)의 시각적 이해 능력을 향상시키기 위한 새로운 pretraining 패러다임을 제안합니다. 새로운 cross-modal comprehension 단계를 도입하여 시각 및 언어 정보를 보다 효과적으로 통합합니다.

- **Technical Details**: 이 연구는 동적으로 학습 가능한 prompt token pool을 설계하고 헝가리안 알고리즘(Hungarian algorithm)을 사용하여 원래 시각 토큰의 일부를 관련성이 높은 prompt 토큰으로 교체합니다. 또한, visual tokens를 LLMs에 대한 "외국어(foreign language)"로 개념화하고, bidirectional visual attention과 unidirectional textual attention을 통합한 혼합 주의 메커니즘(mixed attention mechanism)을 사용하여 visual token의 이해를 증진시킵니다.

- **Performance Highlights**: Croc 모델은 150만 개의 공개 데이터로 사전 훈련된 후 다양한 비전-언어 벤치마크에서 최신 성능(State-of-the-Art)을 달성했습니다. 이는 LLMs의 시각적 이해 및 추론 능력을 강화하는 데 크게 기여합니다.



### HiCo: Hierarchical Controllable Diffusion Model for Layout-to-image Generation (https://arxiv.org/abs/2410.14324)
Comments:
          NeurIPS2024

- **What's New**: 본 논문에서는 Hierarchical Controllable (HiCo) diffusion 모델을 제안하며, 객체 분리가 가능한 조건부 가지 구조를 통해 레이아웃-이미지 생성 문제를 해결하고자 한다. 이를 통해 복잡한 레이아웃에서도 효과적으로 이미지를 생성할 수 있다.

- **Technical Details**: HiCo 모델은 다중 가지 구조를 사용하여 레이아웃을 계층적으로 모델링하고, Fuse Net을 통해 이들 가지를 통합하여 출력한다. 기존 방법들 대비 객체 누락과 영상 품질 문제를 크게 줄이는데 성공했으며, HiCo-7K 벤치마크를 통해 성능을 평가하고 있다.

- **Performance Highlights**: HiCo 모델은 COCO 데이터셋과 GRIT 데이터셋에서 뛰어난 성능을 보여주었다. 특히 HiCo-7K 벤치마크에서 최신 기술로 입증된 성능을 바탕으로 복잡한 레이아웃 생성에서의 우수성을 강조한다.



### Advanced Underwater Image Quality Enhancement via Hybrid Super-Resolution Convolutional Neural Networks and Multi-Scale Retinex-Based Defogging Techniques (https://arxiv.org/abs/2410.14285)
- **What's New**: 이번 연구에서는 수중 이미지의 품질 저하 문제를 해결하기 위해 Multi-Scale Retinex (MSR) 디포깅 기법과 Super-Resolution Convolutional Neural Networks (SRCNN)을 결합한 새로운 하이브리드 전략을 제안합니다.

- **Technical Details**: Retinex 알고리즘은 인간의 시각 인식을 모사하여 조명 불균형과 흐림 현상을 줄이고, SRCNN은 수중 이미지의 공간 해상도를 향상시킵니다. 이 두 가지 방법을 결합하여 수중 이미지의 선명도, 대비, 색상 복원을 개선합니다. 연구는 실제 수중 데이터셋에서의 광범위한 실험을 통해 해당 접근 방식의 효과를 입증합니다.

- **Performance Highlights**: 정량적 평가 지표인 Structural Similarity Index Measure (SSIM)와 Peak Signal-to-Noise Ratio (PSNR)를 사용하여 기존 방법보다 선명도, 가시성, 특징 보존에서 상당한 개선을 보였습니다. 이 접근법은 해양 탐사, 수중 로봇 공학, 자율 수중 차량 등 실시간 수중 응용 분야에서 중요한 역할을 할 수 있습니다.



### Takin-ADA: Emotion Controllable Audio-Driven Animation with Canonical and Landmark Loss Optimization (https://arxiv.org/abs/2410.14283)
Comments:
          under review

- **What's New**: Takin-ADA는 실시간 오디오 기반 초상화 애니메이션을 위한 혁신적인 두 단계 접근 방식을 제공합니다. 특히 미세한 표정 전달을 개선하고 원하지 않는 표현 누수를 줄이는 특수 손실 함수와 고급 오디오 처리 기술을 도입하여 립싱크 정확도를 향상시켰습니다.

- **Technical Details**: 첫 번째 단계에서 3D Implicit Keypoints Framework를 사용하여 동작과 외관을 분리하고 미세한 표정 전달을 강화합니다. 두 번째 단계에서는 오디오 조건화 분산 모델을 사용하여 립싱크 정확성을 높이고 얼굴 표정 및 머리 운동에 대한 유연한 제어를 가능하게 합니다.

- **Performance Highlights**: Takin-ADA는 RTX 4090 GPU에서 최대 42 FPS의 속도로 512x512 해상도 얼굴 애니메이션을 생성하며, 기존 상업적 솔루션을 능가합니다. 광범위한 실험을 통해 비디오 품질, 얼굴 역동성의 현실감, 자연스러운 머리 움직임에서 이전 방법들을 크게 초월하는 것을 입증했습니다.



### You Only Look Twice! for Failure Causes Identification of Drill Bits (https://arxiv.org/abs/2410.14282)
- **What's New**: 이 연구는 드릴 비트의 손상 원인 및 관련 메커니즘을 디지털 이미지 분석을 통해 효율적으로 식별하는 방법을 제안합니다. 특히, YOLO(Location and Damage Cutter Detection) 모델 및 Decision Tree와 Random Forests 모델을 활용하여 드릴 비트의 손상 위치와 유형을 분석하는 자동화된 프로세스를 개발했습니다.

- **Technical Details**: PDC 커터에 대한 다양한 손상 유형(Ringout, Core out, Smooth Wear, Fracture, Thermal Damage)을 분석하며, 여러 머신러닝 모델(Decision Tree, Random Forest, YOLOv5)을 활용합니다. 모델의 성능은 커터 위치 감지에서 0.97 mPA, 손상 감지에서 0.49 mPA를 기록했습니다. 나아가, RRFCI를 통한 손상 원인 분류도 제안하였습니다.

- **Performance Highlights**: 테스트에서 10개의 독립적인 드릴 비트를 사용했을 때, 완전 자동화된 파이프라인이 24개의 손상 원인을 100% 식별하였습니다. Rule-based 접근법은 모든 손상 원인에서 macro-average F1-score 0.94를 달성하여 DT와 RF보다 우수한 성능을 보였습니다.



### ClearSR: Latent Low-Resolution Image Embeddings Help Diffusion-Based Real-World Super Resolution Models See Clearer (https://arxiv.org/abs/2410.14279)
- **What's New**: 이 논문에서는 ClearSR이라는 새로운 방법을 제안합니다. 이 방법은 Diffusion 기반의 실세계 이미지 초해상도(Real-ISR)에서 잠재적 저해상도 이미지 임베딩(Latent Low-Resolution Image Embeddings)을 더 효율적으로 활용할 수 있습니다. 기존 Real-ISR 모델들은 텍스트-이미지 변환 모델의 생성적 우선 순위를 활용하여 고해상도(HR) 이미지를 생성하는 데 중점을 두었으나, 출력 이미지의 내용과 입력 저해상도(LR) 이미지 간의 불일치 문제가 발생할 수 있었습니다.

- **Technical Details**: ClearSR은 ControlNet으로부터의 제어 신호를 잠재적 저해상도(LR) 임베딩을 사용하여 구속합니다. 이 방법은 Detail Preserving Module(DPM)과 Structure Preserving Module(SPM)이라는 두 가지 모듈을 사용하여 ControlNet의 다양한 레이어에서 LR 정보를 효과적으로 추출하고, 구조적 정보와 세부 정보를 개선합니다. 또한, Latent Space Adjustment(LSA) 전략을 도입하여 추론 단계에서 LR 임베딩을 조정함으로써 충실도와 생성 능력을 동시에 향상시킵니다.

- **Performance Highlights**: 실험 결과, ClearSR은 여러 테스트 세트에서 다양한 메트릭을 기준으로 기존 모델들보다 우수한 성능을 보여주었으며, 생성된 초해상도(SR) 결과는 LR 이미지와 더 높은 일관성을 지니고 있습니다. PSNR에서 내부적으로 2dB 이상의 개선을 달성하였으며, 시각적으로도 훨씬 더 명확한 결과를 생성하는 것을 확인했습니다.



### HYPNOS : Highly Precise Foreground-focused Diffusion Finetuning for Inanimate Objects (https://arxiv.org/abs/2410.14265)
Comments:
          26 pages, 12 figures, to appear on the Rich Media with Generative AI workshop in conjunction with Asian Conference on Computer Vision (ACCV) 2024

- **What's New**: 본 논문은 Hypnos라는 새로운 foreground-focused diffusion finetuning 기법을 제안하며, 이는 비생물체 생성 작업에서 높은 정확도를 가능하게 합니다.

- **Technical Details**: Hypnos는 두 가지 주요 접근 방식을 구현합니다: (i) content-centric prompting 전략과 (ii) 추가적인 foreground-focused 판별 모듈의 활용입니다. 이 모듈은 diffusion 모델과 연결되어 있으며, 제공된 감독 메커니즘 세트를 통해 미세 조정됩니다.

- **Performance Highlights**: 제안된 전략은 기존 기술에 비해 더욱 강력한 성능을 보이며 시각적으로 뛰어난 결과를 제공합니다. 이 연구는 Hypnos가 Dreambooth 및 Textual Inversion 기술과 어떻게 다른 동작을 보이는지에 대한 평가도 포함합니다.



### Vision-Language Navigation with Energy-Based Policy (https://arxiv.org/abs/2410.14250)
- **What's New**: 본 논문에서는 기존의 비전-언어 내비게이션(VLN) 모델의 한계를 해결하기 위해 에너지 기반 내비게이션 정책(ENP)을 제안합니다. 이는 전문가의 상태-행동 분포를 에너지 기반 모델로 모델링하여, 전반적으로 전문가 정책과 정렬할 수 있도록 학습합니다.

- **Technical Details**: ENP는 전문가의 상태-행동 쌍에 낮은 에너지 값을 할당하고, 이를 통해 P(s,a) 기반의 joint distribution 을 모델링합니다. 학습 과정에서 ENP는 지속적인 대비 발산(persistent contrastive divergence) 기법을 도입하여 P(s)의 기대값을 추정하고, Stochastic Gradient Langevin Dynamics를 통해 샘플링을 수행합니다.

- **Performance Highlights**: ENP는 여러 VLN 아키텍처에서 R2R, REVERIE, RxR 및 R2R-CE와 같은 벤치마크에서 우수한 성과를 보여주었습니다. 예를 들어, R2R에서는 2% SR, REVERIE에서는 1.22% RGS, R2R-CE에서는 2% SR, 그리고 RxR-CE에서는 1.07% NDTW의 성과 향상을 기록하였습니다.



### ERDDCI: Exact Reversible Diffusion via Dual-Chain Inversion for High-Quality Image Editing (https://arxiv.org/abs/2410.14247)
- **What's New**: 이번 논문에서는 기존의 Diffusion Models (DMs)의 한계점을 극복하기 위한 새로운 방법인 Exact Reversible Diffusion via Dual-Chain Inversion (ERDDCI)를 제안합니다. ERDDCI는 이미지의 정확한 복원을 보장하기 위해 새로운 Dual-Chain Inversion (DCI) 기술을 활용합니다.

- **Technical Details**: ERDDCI는 기존의 DDIM (Denoising Diffusion Implicit Models)에서 발생하는 누적 오류 문제를 해결하기 위한 접근 방식입니다. DCI 기술을 통해 이미지 편집의 정확성을 높이고, 동적 제어 전략(Dynamic Control Strategy, DCS)을 도입하여 고급 가이드 스케일에서도 더 정교한 이미지 편집을 수행할 수 있습니다.

- **Performance Highlights**: 실험 결과, ERDDCI는 기존의 최첨단 모델보다 우수한 성능을 보이며, 50단계의 확산 과정에서 SSIM(Structural Similarity Index) 0.999와 LPIPS(Learned Perceptual Image Patch Similarity) 0.001을 기록하였습니다. 이는 이미지 재구성 및 편집의 속도와 정확성을 크게 향상시킬 수 있음을 보여줍니다.



### PReP: Efficient context-based shape retrieval for missing parts (https://arxiv.org/abs/2410.14245)
- **What's New**: 본 논문에서는 포인트 클라우드(domain) 도메인에서의 형태 부품 검색 문제를 다루고 있습니다. 기존의 형태 검색 방법은 검색 대상 객체가 존재해야 하지만, 본 연구는 교체할 부품이 존재하지 않을 때의 상황을 위한 Part Retrieval Pipeline (PReP)을 제안합니다.

- **Technical Details**: PReP는 메트릭 러닝(metric learning) 기법과 훈련된 분류 모델을 결합하여 데이터베이스에서 잠재적 교체 부품의 적합성을 측정하는 파이프라인입니다. 이 시스템은 어려움을 점진적으로 증가시키는 혁신적인 훈련 절차를 통해 형태 컨텍스트만을 기반으로 적합한 부품을 인식하는 능력을 학습합니다. 비교적 낮은 파라미터 크기와 계산 요구 사항 덕분에, 수만 개의 예비 부품을 수 초 내에 분류할 수 있습니다.

- **Performance Highlights**: PReP는 컴퓨터 비효율성과 강건한 검색 정확도를 유지하며, 결손 부품에 대한 형태 검색을 수행할 수 있는 최초의 파이프라인입니다. 본 연구에서는 이 과정을 완료하기 위해 필요한 각 단계에서의 도전과 설계 선택을 광범위하게 설명합니다.



### Pseudo-label Refinement for Improving Self-Supervised Learning Systems (https://arxiv.org/abs/2410.14242)
- **What's New**: 이 연구에서는 자기 지도 학습 시스템의 성능을 향상시키기 위해 새로운 모형인 pseudo-label refinement (SLR) 알고리즘을 제안합니다. 이는 클러스터링 기반의 pseudo-label에서 발생하는 노이즈 문제를 해결하고, 이전 에폭의 클러스터 라벨을 현재 에폭의 클러스터 라벨 공간에 투영하여 더 정밀한 soft refined label을 생성합니다.

- **Technical Details**: SLR 알고리즘은 클러스터 라벨의 일관성을 유지하면서 이전 에폭의 pseudo-label을 현재 에폭의 클러스터 라벨 공간에 투영합니다. 이 과정에서 현재 클러스터 라벨과 투영된 라벨의 선형 조합을 통해 refined soft labels를 계산하고, 이는 계층적 클러스터링을 통해 refined hard-labels로 변환됩니다.

- **Performance Highlights**: SLR 알고리즘은 unsupervised domain adaptation (UDA) 맥락에서 사람 재식별(Re-ID) 작업에 평가되었으며, 다양한 UDA 작업(실제-합성, 합성-실제, 서로 다른 실제-실제 시나리오)에 대해 mean Average Precision (mAP) 성능이 크게 향상되었습니다.



### Storyboard guided Alignment for Fine-grained Video Action Recognition (https://arxiv.org/abs/2410.14238)
- **What's New**: 본 논문에서는 비디오 액션 인식 문제를 해결하기 위해 다중 세분화 프레임워크(multi-granularity framework)를 제안합니다. 이 프레임워크는 글로벌 비디오 의미(global video semantics)와 원자 행동(atomic actions)의 세부적인 이해를 결합하여 인식 성능을 향상시키는 것을 목표로 합니다.

- **Technical Details**: 프레임워크는 비디오의 글로벌 텍스트를 세분화된 서브 텍스트로 분해하고, 이를 통해 모호성이나 비일관성이 있는 액션을 가진 비디오에 대한 효과적인 비디오 임베딩을 생성합니다. 이를 위해, 사전 훈련된 대형 언어 모델(pre-trained large language model, LLM)을 활용하여 비디오의 세부적인 설명을 생성하고, 이 설명들을 필터링하는 메트릭을 설계하여 액션을 더 잘 이해할 수 있도록 합니다.

- **Performance Highlights**: 제안된 방법은 다양한 비디오 액션 인식 데이터셋에서 우수한 성능을 보였으며, 감독(supervised), 소수 샷(few-shot), 제로 샷(zero-shot) 설정에서 모두 탁월한 결과를 달성했습니다.



### MambaSCI: Efficient Mamba-UNet for Quad-Bayer Patterned Video Snapshot Compressive Imaging (https://arxiv.org/abs/2410.14214)
Comments:
          NeurIPS 2024

- **What's New**: 본 연구에서는 quad-Bayer 패턴으로 캡처된 컬러 비디오의 스냅샷 압축 이미지(SCI) 복원을 위한 MambaSCI 방법을 제안합니다. 이는 기존의 Bayer 패턴에 기반한 알고리즘의 한계를 극복하기 위한 첫 번째 시도입니다.

- **Technical Details**: MambaSCI 방법은 Mamba 아키텍처와 UNet 아키텍처를 기반으로 하며, Residual-Mamba-Blocks를 커스터마이즈하여 Spatial-Temporal Mamba (STMamba), Edge-Detail-Reconstruction (EDR) 모듈 및 Channel Attention (CA) 모듈을 연결합니다. STMamba는 선형 복잡도로 장기적인 공간-시간 의존성을 모델링하며, EDR은 엣지 세부 사항 복원을 개선하고, CA는 Mamba 모델의 누락된 채널 정보 상호작용을 보상하는 데 사용됩니다.

- **Performance Highlights**: 실험 결과, MambaSCI는 낮은 계산 비용과 메모리 비용으로 최첨단 방법들을 초월하는 성능을 보여줍니다.



### Shape Transformation Driven by Active Contour for Class-Imbalanced Semi-Supervised Medical Image Segmentation (https://arxiv.org/abs/2410.14210)
- **What's New**: 이 논문에서는 3D 의료 이미지를 주석 처리하는 데 필요한 전문 지식과 시간 소모를 줄이기 위한 새로운 방법(STAC, Shape Transformation driven by Active Contour)을 제안합니다.

- **Technical Details**: STAC는 액티브 컨투어(active contour) 방법의 곡선 진화 이론에 영감을 얻어, 유기체의 형태를 암묵적으로 표현하기 위해 signed distance function (SDF)을 레벨 셋 함수로 사용합니다. 이는 SDF의 기울기 방향으로 복셀(voxel)을 변형하여 작은 장기의 크기를 확대하여 불균형한 클래스 분포를 완화합니다.

- **Performance Highlights**: 두 개의 벤치마크 데이터셋에서 실험 결과, 제안된 방법이 최신 기술들과 비교하여 상당한 성능 향상을 보여주었습니다.



### Rethinking Transformer for Long Contextual Histopathology Whole Slide Image Analysis (https://arxiv.org/abs/2410.14195)
Comments:
          NeurIPS-2024. arXiv admin note: text overlap with arXiv:2311.12885

- **What's New**: 본 논문에서는 Whole Slide Image (WSI) 분석을 위한 새로운 접근 방식을 제안합니다. 기존 방법들은 Multi-Instance Learning (MIL) 방법에 의존했지만, 본 연구에서는 local-global hybrid Transformer를 통해 WSI의 복잡한 정보를 효과적으로 처리합니다.

- **Technical Details**: WSI에서 긴 시퀀스를 처리하는 데 있어 self-attention의 계산 복잡성 문제를 해결하기 위해 local attention mask를 제안합니다. 이는 attention matrix의 rank를 향상시키며, chunked attention 계산에서 O(n²)의 복잡도를 O(n)으로 감소시킵니다. 이러한 접근은 global 및 local 정보의 상호작용을 동시에 모델링합니다.

- **Performance Highlights**: Long-contextual MIL (LongMIL) 방법은 4개의 WSI 데이터 세트(유방, 위, 결장 및 직장 암)에 대한 진단과 예후 과제에서 강력한 성능을 보였으며, 모델의 효과성과 실제 응용 가능성을 입증했습니다.



### Neural Signed Distance Function Inference through Splatting 3D Gaussians Pulled on Zero-Level S (https://arxiv.org/abs/2410.14189)
Comments:
          Accepted by NeurIPS 2024. Project page: this https URL

- **What's New**: 이번 연구에서는 multi-view 기반의 surface reconstruction에서 SDF( signed distance function)를 추론하는 새로운 접근을 제시합니다. 이를 위해 3D Gaussian Splatting(3DGS)와 neural SDF의 학습을 seamless하게 결합하여, multi-view 일관성을 통해 SDF 추론을 보다 효과적으로 제약합니다.

- **Technical Details**: 연구에서 제안된 방법은 3D Gaussian을 neural SDF의 zero-level set에 동적으로 정렬하고, 이를 위해 differentiable rasterization을 통해 정렬된 3D Gaussian을 렌더링합니다. 또한, 주변 공간을 3D Gaussian에 맞춰 업데이트하여, surface 근처의 signed distance field를 점진적으로 정제합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 널리 사용되는 벤치마크에서 기존 방법들에 비해 더 정확하고 매끄러우며 세부적인 지오메트리를 복원하는 데 우수성을 보였습니다.



### Feature Augmentation based Test-Time Adaptation (https://arxiv.org/abs/2410.14178)
Comments:
          10 pages

- **What's New**: 이번 논문에서는 Feature Augmentation based Test-time Adaptation (FATA)이라는 새로운 기법을 제안합니다. FATA는 제한된 입력 데이터를 효과적으로 활용하기 위한 방법으로, Normalization Perturbation을 이용해 특징을 증강시켜 모델을 적응시킵니다. 이 방법은 기존 모델 구조를 변경하지 않고 간편하게 통합할 수 있습니다.

- **Technical Details**: FATA는 입력 데이터의 특징을 증강하기 위해 Normalization Perturbation (NP) 기법을 사용하며, FATA 손실을 통해 증강된 특징과 원본 특징의 출력을 유사하게 학습합니다. 이를 통해 모델은 적은 양의 신뢰할 수 있는 샘플로도 더 일반화된 표현을 얻을 수 있습니다. 논문에서는 FATA를 ImageNet-C와 Office-Home 데이터셋에서 다양한 모델과 시나리오에 적용하여 효과성을 입증했습니다.

- **Performance Highlights**: FATA를 적용한 방법들은 다양한 실제 시나리오에서 우수한 성능을 보여주었으며, 기존 기법들보다 뛰어난 성능 개선을 이뤘습니다. FATA는 기존의 엔트로피 기반 샘플 선택 기법과 결합하여 효과적으로 성능을 향상시킬 수 있는 가능성을 보여주었습니다.



### DaRePlane: Direction-aware Representations for Dynamic Scene Reconstruction (https://arxiv.org/abs/2410.14169)
Comments:
          arXiv admin note: substantial text overlap with arXiv:2403.02265

- **What's New**: DaRePlane는 6개의 서로 다른 방향에서 장면 동 역성을 캡쳐하는 방향 인식 표현 방식을 제안하여 고주파(dynamic) 장면의 리렌더링(re-rendering)의 성능을 향상시킵니다.

- **Technical Details**: 이 방법은 역 이중 트리 복소 웨이브렛 변환(dual-tree complex wavelet transformation, DTCWT)을 통해 평면 기반 정보를 복구하고, Neural Radiance Fields (NeRF) 시스템에서는 공간-시간 점을 위해 복구된 평면의 벡터를 융합하여 특징을 계산합니다. Gaussian splatting (GS) 시스템에서도 비슷한 방식으로 Gaussian 포인트의 특징을 계산합니다.

- **Performance Highlights**: DaRePlane은 정식 및 수술(dynamic surgical) 장면에서 NeRF와 GS 시스템에 적용했을 때 다양한 복잡한 동적 장면에 대해 최첨단 성능을 보여주었습니다.



### Optimal DLT-based Solutions for the Perspective-n-Poin (https://arxiv.org/abs/2410.14164)
Comments:
          8 pages, 6 figures, 2 tables

- **What's New**: 이번 논문에서는 수정된 normalized direct linear transform (DLT) 알고리즘을 제안하여 기존 DLT보다 훨씬 더 우수한 성능을 보여줍니다. 이 수정은 선형 시스템 내의 다양한 측정을 분석적으로 가중치화하여 계산 비용은 거의 증가시키지 않는 방법입니다.

- **Technical Details**: 이 연구는 DLT를 개선하여 PnP 문제에 접목시켰습니다. 특히 카메라 매트릭스에 대한 사전 정보가 있을 경우, DLT는 최대 우도 추정 (maximum likelihood estimation)으로 변환될 수 있습니다. 이 최대 우도 접근법은 동차 좌표계의 점 측정과 카메라 투사 매트릭스를 사용하여 이루어집니다. 논문에서는 또한 정규화된 DLT를 사용한 최적의 회전 행렬 S⁢O⁢(3) 회전을 검색하는 방법을 설명합니다.

- **Performance Highlights**: 수치 실험 결과, 제안된 최적 DLT (oDLT)는 기존의 EPnP, CPnP, RPnP 및 OPnP와 같은 인기 있는 방법 대비 성능과 실행 시간이 모두 개선되었습니다. 특히, oDLT는 Gauss-Newton 최적화를 통해 발견된 진정한 최적 솔루션에 가까운 결과를 나타내며, 계산 비용은 상대적으로 적습니다.



### Unlabeled Action Quality Assessment Based on Multi-dimensional Adaptive Constrained Dynamic Time Warping (https://arxiv.org/abs/2410.14161)
- **What's New**: 이 연구에서는 온라인 운동 실행 품질 평가의 새로운 방법인 MED-ACDTW을 제안합니다. 이 방법은 라벨의 필요 없이 템플릿 비디오와 시험 비디오의 특성을 비교하여 운동 품질을 평가할 수 있습니다.

- **Technical Details**: MED-ACDTW는 주관적 평가에 의존하지 않아 새로운 운동에 대한 신속한 적용이 가능합니다. 이 방법은 2D 및 3D 공간 차원을 활용하고 다양한 신체 특징을 이용하여 기존 방법보다 2-3% 정확도를 높였습니다. 또한, MED 모듈은 프레임 거리 일치를 향상시켜 전반적인 변별력을 크게 증가시킵니다. 적응형 제약조건은 약 30%의 변별력을 추가합니다.

- **Performance Highlights**: 이 알고리즘은 새로운 운동의 템플릿을 활용하여 라벨이 없는 행동 일치를 가능하게 하며, 153개의 클립 비디오 데이터셋을 통해 적절한 평가 기준을 제공합니다. 결과적으로, 기존 스코어링 시스템보다 향상된 성능을 나타냈습니다.



### Assessing Open-world Forgetting in Generative Image Model Customization (https://arxiv.org/abs/2410.14159)
Comments:
          Project page: this https URL

- **What's New**: 이번 논문에서는 diffusion 모델에서 발생하는 open-world forgetting 개념을 소개하고, 모델 맞춤화가 가져오는 의도치 않은 변화에 대한 첫 번째 포괄적인 조사를 수행했습니다. 이 연구는 semantic drift와 appearance drift를 분석을 통해 모델의 신뢰성에 미치는 영향을 강조합니다.

- **Technical Details**: 저자들은 zero-shot classification을 활용하여 semantic drift를 분석하고, 제한된 데이터로도 큰 성능 하락(최대 60%)을 관찰하였습니다. 또한, appearance drift 분석을 통해 생성된 콘텐츠의 색상과 텍스처에서의 중대한 변화를 발견하였고, 이를 해결하기 위한 functional regularization 기법을 제안합니다.

- **Performance Highlights**: 저자들은 DreamBooth 및 CustomDiffusion 기법을 활용하여 open-world forgetting을 평가하였고, 이러한 맞춤화가 모델의 기존 지식 및 기술에 미치는 부정적인 영향을 밝혀냈습니다. 제안된 방식은 semantic 및 appearance drift를 효과적으로 줄이는 데 도움을 주며, 미래 연구에 대한 통찰을 제공합니다.



### Preview-based Category Contrastive Learning for Knowledge Distillation (https://arxiv.org/abs/2410.14143)
Comments:
          14 pages, 8 figures, Journal

- **What's New**: 이번 연구에서는 Knowledge Distillation(KD) 기법의 새로운 접근 방식인 Preview-based Category Contrastive Learning Method(PCKD)를 소개합니다. 기존의 표본 레벨(feature representation) 일관성에 초점을 맞춘 LD 방법의 한계를 극복하고, 각 샘플의 난이도에 따라 학생 모델이 학습하는 방식을 다이내믹하게 조정합니다.

- **Technical Details**: PCKD는 인스턴스 레벨의 특징 대조(constrastive) 학습을 통해 교사 모델의 구조적 지식(knowledge)을 전이하고, 카테고리 중심(center) 간의 관계를 학습하는 것을 목표로 합니다. 이는 카테고리 표현을 최적화하고 명확한 카테고리 중심을 통해 더 나은 분류(classification) 결과를 제공합니다. 특히, 학생 모델이 샘플의 난이도에 따라 조정된 가중치(weight)를 부여받아 학습하는 프리뷰(preview) 전략을 도입했습니다.

- **Performance Highlights**: CIFAR-100, ImageNet 등의 여러 데이터셋에서 PCKD의 성능을 검증했습니다. PCKD는 기존의 최첨단 방법들과 비교했을 때 우수한 성능을 보여주었습니다. 실험 결과는 PCKD의 새로운 카테고리 대조 학습 및 프리뷰 기반 학습 전략이 효과적임을 입증하였습니다.



### ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom (https://arxiv.org/abs/2410.14138)
- **What's New**: 대형 비전-언어 모델(LVLMs)은 비주얼 이해 작업에서 큰 발전을 이루었지만, 비주얼 추론 작업에서는 이미지 정보보다 언어 지식을 우선시하여 성능 저하가 발생하는 문제가 있었습니다. 이를 해결하기 위해 LVLM의 비주얼 추론 과정을 시각적 인식과 텍스트 추론의 두 단계로 분해하고 새로운 비주얼 추론 프레임워크인 ProReason을 제안합니다.

- **Technical Details**: ProReason은 질문 지향적이고 추론이 포함된 시각적 정보 추출과 분리된 비전-추론 기능을 갖춘 다중 단계 다중 모달 추론 프레임워크입니다. 이 프레임워크는 행동(Action), 판단(Judgment), 요약(Summary)의 세 단계로 나뉘며, 각 단계는 고유한 역할을 가진 에이전트를 포함합니다. 이로 인해 시각 정보의 수집과 추론을 효과적으로 분리하여 각 단계에서 LVLM의 한계를 보완합니다.

- **Performance Highlights**: ProReason은 기존의 다중 단계 추론 프레임워크 및 수동 동료 방법을 능가하여 다양한 벤치마크에서 성능을 향상시키며, MMMU 벤치마크에서 최대 15%의 성능 향상이 관찰되었습니다. 이 프레임워크는 LLM과의 통합 가능성을 입증하여 LVLM의 비주얼 추론 향상에 기여하는 중요한 기초 자료가 될 것입니다.



### Extreme Precipitation Nowcasting using Multi-Task Latent Diffusion Models (https://arxiv.org/abs/2410.14103)
Comments:
          12 pages, 6figures

- **What's New**: 본 논문에서는 다중 작업 잠재 확산 모델(Multi-Task Latent Diffusion Model, MTLDM)을 도입하여 고 강수 강도 영역에서의 레이더 이미지의 공간 세부사항을 더 정확하게 예측할 수 있는 방법을 제시합니다.

- **Technical Details**: MTLDM은 레이더 이미지를 여러 구성 요소로 분해하여 각 구성 요소를 별도로 예측하는 분할 정복(divide-and-conquer) 접근 방식을 사용합니다. 이는 다양한 강수 강도에 해당하는 여러 구성 요소로 구성된 강수 이미지를 개념화하여 예측합니다.

- **Performance Highlights**: MTLDM은 실제 강수 지역을 최대 5-80분 이전까지 공간적 일관성을 유지하여 예측할 수 있으며, 기존의 최첨단 기술들보다 여러 평가 지표에서 뛰어난 성과를 보였습니다.



### Enhancing In-vehicle Multiple Object Tracking Systems with Embeddable Ising Machines (https://arxiv.org/abs/2410.14093)
Comments:
          18 pages, 7 figures, 2 tables

- **What's New**: 이 논문은 자율주행 차량에서 멀티 오브젝트 추적(Multiple Object Tracking, MOT)을 위한 새로운 시스템을 제안합니다. 이 시스템은 유연한 할당 기능을 도입하여 장기 장애물 사건(occlusion events)에도 대응할 수 있으며, 이 과정에서 양자영감을 받은 알고리즘인 simulated bifurcation을 사용하는 임베어블(Ising machine)을 활용합니다.

- **Technical Details**: 제안된 시스템은 임베어블(Ising machine)을 사용하여 NP-hard 조합 최적화 문제를 해결합니다. 두 개의 FPGA를 통해 실시간 객체 감지와 할당을 실행하며, 유사도 매트릭스(Similarity Matrix)를 기반으로 할당을 결정합니다. 시스템은 각 비디오 프레임마다 두 번의 QUBO 문제를 해결하고, 서로 다른 가중치 계수를 적용하여 장애물 사건의 발생 및 위치를 감지합니다.

- **Performance Highlights**: 제안된 시스템은 평균 23프레임/초로 실시간 전체 처리량을 달성하며, Ising machine 강화 기능을 통한 멀티 오브젝트 추적의 성능을 보여줍니다. 이는 특히 많은 트래커가 하나의 감지와 매칭되는 경우에서도 적절한 비용 함수 총합을 기준으로 선택될 수 있는 가능성을 제공합니다.



### MMAD-Purify: A Precision-Optimized Framework for Efficient and Scalable Multi-Modal Attacks (https://arxiv.org/abs/2410.14089)
- **What's New**: 이번 논문에서는 다중 모달리티를 활용한 적대적 공격 프레임워크를 제안하여, diffusion 모델을 통한 모델 강건성 평가의 새로운 가능성을 제시하였습니다.

- **Technical Details**: 논문에서는 precision-optimized noise predictor를 포함한 혁신적인 공격 프레임워크를 소개합니다. 기존의 gradient 기반 적대적 공격 및 diffusion 모델 기반 방법의 한계를 극복하기 위해 distilled diffusion model을 사용하여 공격의 효율성을 높였습니다.

- **Performance Highlights**: 제안된 프레임워크는 적대적 예제의 생성에서 우수한 전이성 및 강건성을 보이며, 기존 gradient 기반 공격 모델보다 높은 효과성과 효율성을 달성했습니다. 또한, 계산 비용을 크게 줄이며 높은 충실도의 적대적 예제를 생성합니다.



### Your Interest, Your Summaries: Query-Focused Long Video Summarization (https://arxiv.org/abs/2410.14087)
Comments:
          To appear at the 18th International Conference on Control, Automation, Robotics and Vision (ICARCV), December 2024, Dubai, UAE

- **What's New**: 이번 논문에서는 사용자 쿼리를 기반으로 한 비디오 요약(Query-Focused Video Summarization) 접근법을 제안합니다. 이를 위해 Fully Convolutional Sequence Network with Attention (FCSNA-QFVS)라는 새로운 모델을 도입하였습니다.

- **Technical Details**: 제안된 모델은 1D temporal convolution과 Attention 메커니즘을 활용하여 사용자가 지정한 쿼리에 따라 비디오의 관련 콘텐츠를 효율적으로 추출하고 강조합니다. 또한, shot-scoring module을 통해 각 shot의 쿼리 관련성 점수를 예측하고 가장 높은 점수를 받은 2%의 shot을 선택하여 요약 비디오를 생성합니다.

- **Performance Highlights**: 모델은 benchmark UTEgocentric dataset을 사용하여 평가되었으며, 이전 연구들과 비교하여 정량적 및 정성적 분석을 통해 효과성을 입증했습니다. 또한, 요약 품질을 포괄적으로 평가하는 데 중점을 두었습니다.



### SAMReg: SAM-enabled Image Registration with ROI-based Correspondenc (https://arxiv.org/abs/2410.14083)
- **What's New**: 이 논문은 의료 이미지 등록을 위한 쌍으로 구성된 관심 영역(ROIs)에 기반한 새로운 공간적 일치(Spatial Correspondence) 표현을 제안합니다. 이는 기존의 샘플 이동 및 공간 변환 함수 기반 방법과 비교하여 임상 응용에서의 잠재적 이점에 대해 논의하고 있습니다.

- **Technical Details**: 제안된 ROI 기반 일치는 학습 기반(image registration과 segmentation의 명확한 연결)과의 관계를 통해 두 가지의 이미징 등록 접근 방식을 동기화 가능합니다. 특히, (pre-)트레이닝된 세분화 네트워크를 사용하는 새로운 등록 알고리즘 SAMReg를 개발하였으며, 이는 어떠한 트레이닝 데이터나 gradient 기반 미세 조정, prompt engineering을 필요로 하지 않습니다.

- **Performance Highlights**: SAMReg는 심장 MRI와 폐 CT 같은 intra-subject 등록 작업, 전립선 MRI 및 망막 이미징을 포함한 challenging inter-subject 등록 시나리오, 그리고 비임상 예제로서 항공 이미지 등록에 대해 평가되었습니다. 제안된 방법은 신체 구조에서의 Dice 및 target registration error와 같은 측정 지표에 대해 강도 기반 반복 알고리즘 및 DDF 예측 학습 기반 네트워크보다 뛰어난 성능을 보였으며, 완전 세분화된 트레이닝 데이터를 바탕으로 한 weakly-supervised 등록 접근 방식과도 경쟁력 있는 성능을 입증하였습니다.



### FaceSaliencyAug: Mitigating Geographic, Gender and Stereotypical Biases via Saliency-Based Data Augmentation (https://arxiv.org/abs/2410.14070)
Comments:
          Accepted at Image Signal and Video processing

- **What's New**: 이 연구에서는 Convolutional Neural Networks (CNNs) 및 Vision Transformers (ViTs)에서 성별 편향을 해결하기 위한 새로운 접근법인 FaceSaliencyAug를 제안합니다. 이 접근법은 이미지에서 얼굴의 두드러진 영역을 활용하여 지리적 및 고정관념적 편향을 완화하도록 설계되었습니다.

- **Technical Details**: FaceSaliencyAug는 여러 데이터 세트에서의 데이터 다양성을 증대시키고 모델 성능을 향상시키기 위해 두드러진 얼굴 영역에 대해 선택된 마스크를 적용합니다. 실험에서 Image Similarity Score (ISS)를 사용하여 데이터 세트의 다양성을 정량화하고, CEO, 엔지니어, 간호사 및 학교 교사 데이터 세트에서 성별 편향을 측정하기 위해 Image-Image Association Score (IIAS)를 사용합니다. 또한, 이 방법은 CNNs와 ViTs 모두에서 성별 편향을 감소시키는 데 효과적임을 보여주었습니다.

- **Performance Highlights**: 제안된 FaceSaliencyAug 방법은 Flickr Faces HQ (FFHQ), WIKI, IMDB, Labelled Faces in the Wild (LFW), UTK Faces 및 Diverse Dataset을 포함한 다섯 개의 데이터 세트에서 뛰어난 다양성 메트릭을 달성하였으며, 네 개의 직업 데이터 세트에서 성별 편향을 상당히 줄이는 데 성공했습니다. 이는 컴퓨터 비전 모델의 공정성과 포용성을 개선하는 데 기여하고 있습니다.



### Human Action Anticipation: A Survey (https://arxiv.org/abs/2410.14045)
Comments:
          30 pages, 9 figures, 12 tables

- **What's New**: 본 연구에서는 인간 행동 예측에 관한 최신 기술 혁신과 새로운 대규모 데이터셋 개발을 종합적으로 다루며, 기존 방법론에 대한 포괄적인 성능 비교를 제공합니다.

- **Technical Details**: 행동 예측 연구는 고유 관점(egocentric) 및 외부 관점(exocentric)에서의 다양한 비디오 데이터셋을 활용하여, 각기 다른 작업을 포괄하는 일곱 가지 예측 작업을 정의하고, 이를 모델 설계, 다중 모달 입력, 사전 훈련 전략 등으로 분류합니다.

- **Performance Highlights**: 11개의 행동 예측 데이터셋에 대한 기존 접근 방식의 성능 비교를 통해, 각 연도의 주요 방법론 발전을 시각적으로 제시하고, 최신 기술 및 데이터셋의 영향을 강조합니다.



### Probabilistic U-Net with Kendall Shape Spaces for Geometry-Aware Segmentations of Images (https://arxiv.org/abs/2410.14017)
Comments:
          22 pages, 13 figures

- **What's New**: 이번 논문에서는 이미지 분할 분야의 확률적(Probabilistic) 딥 뉴럴 네트워크(DNN) 모델을 제안합니다. 기본적으로, 기존의 확률적 세분화 모델은 세분화의 기하학적(geometry) 또는 형태(shape)를 고려하지 않지만, 본 모델은 이런 기하학을 통합하여 보다 섬세한 세분화를 생성합니다.

- **Technical Details**: 제안된 모델은 Kohl et al. (2018)의 Probabilistic U-Net을 기반으로 다중 세분화를 생성합니다. 또한 Vadgama et al. (2023)의 Kendall Shape Variational Auto-Encoder(VAE)를 채택하여 잠재 변수 레이어(latent variable layer)에 Kendall 형태 공간을 인코딩합니다. 모델은 입력 이미지의 기하학적 정보를 고려하여 공간적으로 일관된 지역을 생성하는 데 중점을 둡니다.

- **Performance Highlights**: 결과적으로, 본 연구에서 제안한 Kendall Shape Probabilistic U-Net은 기존의 방법보다 더 신뢰할 수 있고 일관된 세분화를 제공합니다. 이는 의학 영상의 종양 세분화와 같은 다양한 실제 이미지 분석 시나리오에 유용한 잠재적 응용 프로그램을 가지고 있습니다.



### Reproducibility study of "LICO: Explainable Models with Language-Image Consistency" (https://arxiv.org/abs/2410.13989)
Comments:
          15 pages, 2 figures, Machine Learning Reproducibility Challenge 2024

- **What's New**: 이번 논문에서는 Lei et al. (2023)이 제안한 LICO 방법의 주장을 재검토하고, 이를 통해 기계 학습의 재현성 위기에 대한 문제를 다루고 있습니다. LICO는 비전-언어 모델의 자연어 감독(natural language supervision)을 활용해 특징 표현(feature representations)을 풍부하게 하고 학습 과정을 안내합니다.

- **Technical Details**: 논문에서는 (Wide) ResNets와 Grad-CAM, RISE와 같은 기존의 해석 가능성 기법을 사용하여 LICO의 효과를 검증하였습니다. LICO는 두 가지 훈련 목표를 사용하며, 하나는 이미지 매니폴드(image manifold)와 텍스트 프롬프트 매니폴드(text prompt manifold)를 일치시키는 매니폴드 매칭 손실(manifold matching loss)이고, 다른 하나는 프롬프트 토큰(prompt tokens)과 특징 맵(feature maps) 간의 관계를 확립하는 최적 수송 손실(optimal transport loss)입니다.

- **Performance Highlights**: 실험 결과, LICO를 사용한 이미지를 분류할 때 기존 방식에 비해 일관되게 분류 성능(classification performance)이 개선되지 않았으며, 해석 가능성 해석의 정량적, 정성적 조치에서도 개선이 이루어지지 않았습니다. 이는 해석 가능성 연구에서 엄격한 평가와 투명한 보고의 중요성을 강조합니다.



### Satellite Streaming Video QoE Prediction: A Real-World Subjective Database and Network-Level Prediction Models (https://arxiv.org/abs/2410.13952)
- **What's New**: 이 논문은 실제 위성 네트워크에서 수집된 179 개의 비디오로 구성된 새로운 LIVE-Viasat Real-World Satellite QoE Database를 소개하며, 이는 다양한 실제 왜곡 패턴에 의해 영향을 받은 비디오 스트리밍 품질(quality)을 평가하는 주관적 연구에 기초하고 있습니다.

- **Technical Details**: 이 데이터베이스는 재생 중 발생하는 다양한 왜곡을 반영하여 구축되었으며, 연구자는 54명의 참여자로부터 지속적인 의견 점수 및 회고적 QoE 점수를 수집했습니다. 분석을 통해 정체 사건(stall events), 해상도 공간(spatial resolutions), 비트 전송률(bitrate), 네트워크 파라미터(network parameters) 등 다양한 요인이 QoE에 미치는 영향을 조명했습니다.

- **Performance Highlights**: 새롭게 제안된 모델인 SatQA는 네트워크 파라미터만을 사용하여 QoE를 정확하게 예측할 수 있으며, 높은 정확도와 신뢰성을 나타내는 Spearman의 순위 상관 계수(SROCC), Pearson의 선형 상관 계수(PLCC), 평균 제곱근 오차(RMSE)로 평가되었습니다.



### ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding (https://arxiv.org/abs/2410.13924)
- **What's New**: 이 논문에서는 ARKit LabelMaker라고 하는 최초의 대규모 실세계 3D 데이터셋을 소개합니다. 이 데이터셋은 촘촘한 의미론적 주석이 추가되어 있으며, ARKitScenes 데이터셋을 보완합니다.

- **Technical Details**: LabelMaker 자동 주석 파이프라인을 통해 ARKitScenes 데이터셋에 촘촘한 의미주석을 자동으로 생성하였고, 이를 통해 대규모 사전 학습이 가능하도록 개선했습니다.

- **Performance Highlights**: ARKitScenes 데이터셋의 자동 생성된 주석을 사용하여, 현재 가장 많이 사용되는 3D 분할 방법인 MinkowskiNet과 PTv3의 성능을 여러 벤치마크에서 향상시켰습니다.



### GraspDiffusion: Synthesizing Realistic Whole-body Hand-Object Interaction (https://arxiv.org/abs/2410.13911)
- **What's New**: 이 논문에서는 GraspDiffusion이라는 새로운 생성 방법을 제안하여 인간-객체 상호작용을 사실적으로 생성할 수 있는 방법을 소개합니다. 기존의 생성 모델들이 손과 객체의 상호작용을 제대로 이해하거나 시각화하는 데 어려움을 겪었던 문제를 해결합니다.

- **Technical Details**: GraspDiffusion은 3D 객체 메쉬를 바탕으로 전체 신체 자세를 구성하고, 이를 통해 객체와의 상호작용을 명확히 반영합니다. 이 과정은 3D 바디와 손 자세를 각각 활용하여 결합된 그립(grip) 자세를 최적화하는 두 단계의 프레임워크를 사용합니다.

- **Performance Highlights**: GraspDiffusion은 이전 방법들보다 현실적인 전신 상호작용을 생성하는 데 성공하며, 명시적(손으로 직접 그립) 및 암시적(몸 방향, 시선) 상호작용을 모두 보여줍니다. 또한, 이 모델은 가벼운 아키텍처로만 구성되어 있어 실제 작업에 쉽게 적용할 수 있습니다.



### Transformers Utilization in Chart Understanding: A Review of Recent Advances & Future Trends (https://arxiv.org/abs/2410.13883)
- **What's New**: 최근 몇 년간 비전-언어(vision-language) 작업에 대한 관심이 증가하고 있으며, 특히 차트 상호작용(chart interactions)과 관련된 작업에 대한 연구가 활발히 진행되고 있습니다. 본 논문은 차트 이해(Chart Understanding, CU)에 있어 현재 사용되는 최첨단(transformer 기반) 솔루션들을 검토합니다.

- **Technical Details**: 본 연구에서는 변환기(transformer) 아키텍처를 사용한 다양한 CU 프레임워크를 분석하고, 이와 관련된 벤치마킹 데이터셋 및 평가 기법을 조명합니다. CU 작업은 인지적(task) 요구사항에 따라 세 가지 층으로 분류됩니다. 단일 작업(single-task) 및 다중 작업(multi-task) 프레임워크 간의 차이를 명확히 하고, 사전 훈련(pre-trained) 및 프롬프트 엔지니어링(prompt-engineering) 기술에 대해서도 다룹니다.

- **Performance Highlights**: 최근 연구에서 OCR 의존성, 저해상도 이미지 처리 및 시각적 추론 강화와 같은 주요 도전 과제가 제기되었습니다. 향후 연구 방향으로는 이러한 문제를 해결하고, 견고한 벤치마크를 개발하며, 모델 효율성을 최적화하는 것이 포함됩니다. 설명 가능한 AI 기술적 통합 및 실데이터와 합성데이터 간의 균형 탐색도 CU 연구의 발전에 필수적입니다.



### Articulate-Anything: Automatic Modeling of Articulated Objects via a Vision-Language Foundation Mod (https://arxiv.org/abs/2410.13882)
- **What's New**: Articulate-Anything 시스템은 텍스트, 이미지, 비디오 등 다양한 입력 방식에서 복잡한 물체의 자동 조작을 실현합니다. 이 시스템은 기존의 3D 자산 데이터세트를 활용하며, 비전-언어 모델(vision-language models, VLMs)을 기반으로 상호작용할 수 있는 디지털 트윈을 생성합니다.

- **Technical Details**: Articulate-Anything는 비전-언어 액터-비평 시스템(actor-critic system)으로, 고급 Python 코드를 생성하는 비전-언어 액터와 예측을 실제값과 비교해 피드백을 제공하는 비전-언어 비평가로 구성되어 있습니다. 이러한 시스템은 URDF(Unified Robot Description Format) 파일로 컴파일할 수 있습니다.

- **Performance Highlights**: Articulate-Anything는 PartNet-Mobility 데이터셋에서 8.7-12.2%의 성공률을 75%로 향상시키며, 이전 연구의 한계를 극복하고 새로운 최첨단 성과 기준을 설정했습니다. 이 시스템은 로봇 정책 훈련에서도 유용하게 사용되고 있습니다.



### Explaining an image classifier with a generative model conditioned by uncertainty (https://arxiv.org/abs/2410.13871)
- **What's New**: 본 논문에서는 이미지 분류기(image classifier)의 불확실성(uncertainty)을 통해 생성 모델(generative model)을 조건화하는 새로운 접근 방식을 제안합니다. 이를 통해 이미지 분류기의 행동을 분석하고 설명할 수 있습니다.

- **Technical Details**: 이 연구는 합성 데이터(synthetic data)와 왜곡된 MNIST 데이터셋(MNIST dataset)의 예비 실험(preliminary experiments)을 통해 아이디어를 검증합니다. 생성 모델은 이미지 분류기의 출력을 바탕으로 조건화되며, 이는 불확실성 정보를 통합하여 더 나은 설명 가능성을 제공합니다.

- **Performance Highlights**: 초기 실험 결과는 제안된 방법이 기존 접근 방식보다 이미지 분류기 분석에서 유용함을 보여줍니다.



### A Hybrid Feature Fusion Deep Learning Framework for Leukemia Cancer Detection in Microscopic Blood Sample Using Gated Recurrent Unit and Uncertainty Quantification (https://arxiv.org/abs/2410.14536)
- **What's New**: 이번 연구는 Acute Lymphoblastic Leukemia (ALL) 진단을 위한 고유한 하이브리드 딥러닝 모델을 제안하고, 불확실성 정량화(uncertainty quantification) 기법을 적용하여 진단의 신뢰성을 높였습니다.

- **Technical Details**: 모델은 MobileNetV2-GRU, InceptionV3-GRU 및 EfficientNetB3-GRU로 구성된 하이브리드 딥러닝 모델을 활용하여 미세 이미지에서 ALL을 분류합니다. Bayesian optimization을 통해 하이퍼파라미터를 조정하고, Deep Ensemble을 통해 불확실성을 처리합니다.

- **Performance Highlights**: ALL-IDB1 데이터세트에서 100%, ALL-IDB2 데이터세트에서 98.07%, 통합 데이터세트에서 98.64%의 정확도를 기록하여 AML 진단의 신뢰성을 입증하였습니다.



### Less is More: Selective Reduction of CT Data for Self-Supervised Pre-Training of Deep Learning Models with Contrastive Learning Improves Downstream Classification Performanc (https://arxiv.org/abs/2410.14524)
Comments:
          Published in Computers in Biology and Medicine

- **What's New**: 이 논문은 의료 이미지를 위한 대조 학습 (contrastive learning) 기반의 자기 지도 (self-supervised) 사전 학습에서 데이터셋의 중복을 줄이는 다양한 전략을 조사합니다.

- **Technical Details**: 대조 학습을 사용하여 CT 이미지의 낮은 분산(variance)을 극복하기 위해 정보 이론 (information theory), 딥 임베딩 (deep embedding), 해싱 (hashing) 기반의 접근법을 통해 데이터셋에서 중복을 식별하고 감소시키는 방법을 사용합니다.

- **Performance Highlights**: 데이터셋 감소로 인해 COVID CT 분류 대회에서 AUC 점수가 0.78에서 0.83으로 향상되었고, OrganSMNIST 분류 대회에서는 0.97에서 0.98로, 뇌 출혈 분류 작업에서는 0.73에서 0.83로 개선되었습니다. 또한, 사전 학습이 데이터셋 감소 덕분에 최대 아홉 배 더 빨라졌습니다.



### An Integrated Deep Learning Model for Skin Cancer Detection Using Hybrid Feature Fusion Techniqu (https://arxiv.org/abs/2410.14489)
- **What's New**: 본 연구에서는 Deep Learning 기반의 하이브리드 프레임워크를 제안하여 피부 병변의 양성과 악성을 정확히 분류하는 방법을 소개합니다. 특히 InceptionV3와 DenseNet121 두 개의 사전 훈련된 모델을 통해 데이터셋 전처리 후 결과를 융합하여 우수한 성능을 나타냅니다.

- **Technical Details**: 하이브리드 DL 시스템은 데이터셋 전처리, 두 종류의 딥러닝 모델(InceptionV3, DenseNet121) 훈련, 가중치 합 규칙을 통해 결과를 융합하는 방식으로 설계되었습니다. 이 과정에서 모델의 정밀도를 높이기 위한 다층 신경망 구조와 레이블 데이터를 활용합니다.

- **Performance Highlights**: 본 연구는 92.27%의 검출 정확도, 92.33%의 민감도, 92.22%의 특이도, 90.81%의 정밀도, 그리고 91.57%의 F1 점수를 달성하여 기존 모델을 능가하는 성능을 보여주었습니다. 이는 피부암 진단의 신뢰성과 견고성을 증명합니다.



### Integrating Deep Learning with Fundus and Optical Coherence Tomography for Cardiovascular Disease Prediction (https://arxiv.org/abs/2410.14423)
Comments:
          Part of the book series: Lecture Notes in Computer Science ((LNCS,volume 15155))

- **What's New**: 이 연구는 망막 광학 단층 촬영(Optical Coherence Tomography, OCT) 이미지와 촬영된 안저 사진을 결합하여 심혈관 질환(CVD) 발병 위험을 가진 환자를 조기 식별할 수 있는 가능성을 보여줍니다. 새로운 다채널 변형 오토인코더(Multi-channel Variational Autoencoder, MCVAE)를 기반으로 한 이진 분류 네트워크를 제안합니다.

- **Technical Details**: 주요 방법론은 두 단계로 구성됩니다: 첫째, 약 18,000명의 CVD- 환자 데이터를 사용하여 MCVAE를 훈련하여 망막 OCT 및 안저 이미지에서 특징을 추출합니다. 둘째, 변환기 기반의 이진 분류기를 활용하여 CVD- 환자와 미래 CVD 위험이 있는 환자를 구분합니다. 이를 위해 고차원 이미지 데이터의 압축된 잠재 표현을 학습합니다.

- **Performance Highlights**: 모델은 총 2854명의 피험자를 사용하여 훈련되었으며, AUROC 0.78, 정확도 0.68, 정밀도 0.74, 민감도 0.73, 특이도 0.68의 성능을 달성했습니다. 이는 환자의 망막 이미지를 기반으로 미래의 CVD 사건 위험을 확인하는 데 효과적임을 보여줍니다.



### SurgeryV2: Bridging the Gap Between Model Merging and Multi-Task Learning with Deep Representation Surgery (https://arxiv.org/abs/2410.14389)
Comments:
          This paper is an extended version of our previous work [arXiv:2402.02705] presented at ICML 2024

- **What's New**: 이번 논문은 모델 병합(model merging) 기반 다중 작업 학습(multi-task learning, MTL)에서 발생하는 '표현 편향(representation bias)' 문제를 다루고 있으며, 이를 개선하기 위한 새로운 접근 방식을 제안합니다.

- **Technical Details**: 저자들은 첫 번째로 'Surgery'라는 경량의 작업별 모듈을 제안하여 merged model의 최종 층 표현을 expert models의 최종 층과 정렬합니다. 또한, 보다 포괄적인 해결책으로 'SurgeryV2'를 제안하여 모든 층에서 표현 편향을 완화하며, 전통적인 MTL 방법과의 성능 격차를 줄입니다.

- **Performance Highlights**: SurgeryV2는 기존의 expert models나 전통적 MTL 모델과 비슷한 수준의 성능에 도달했으며, 최첨단(model merging) 기술과 결합했을 때 주요 성능 향상을 보여주었습니다. 실험 결과, SurgeryV2는 같은 용량에서 Surgery보다 더 적은 반복으로도 훨씬 높은 정확도를 달성했습니다.



### 2D-3D Deformable Image Registration of Histology Slide and Micro-CT with ML-based Initialization (https://arxiv.org/abs/2410.14343)
Comments:
          12 pages, 4 figures

- **What's New**: 최근 조직학(histology)과 미세 전산화 단층촬영(Micro-CT, µCT) 기술의 발전은 가상 조직학 가시성을 확대하는 데 기여하고 있습니다. 그러나 소프트 조직의 µCT 이미지는 저화질로 인해 여러 도전 과제가 남아 있습니다. 본 연구에서는 새로운 2D-3D 다중 모달 변형 이미지 등록 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 기계 학습(Machine Learning, ML)을 기반으로 초기화를 진행한 후, 분석적인 비대칭 변형 최적화를 통해 등록을 완성합니다. 검토된 데이터셋은 편도선 및 종양 조직에서 획득한 µCT 이미지를 포함하며, 본 연구는 기존 강도 및 키 포인트 기반 방법과 비교해 우수한 성능을 보입니다.

- **Performance Highlights**: 제안된 2D-3D 변형 이미지 등록 방법은 기존의 강도 기반 및 키 포인트 기반 방법보다 더 나은 성능을 발휘하며, 시각적 평가와 기준 기반 평가 모두에서 뛰어난 결과를 나타냅니다.



### Fast proxy centers for Jeffreys centroids: The Jeffreys-Fisher-Rao and the inductive Gauss-Bregman centers (https://arxiv.org/abs/2410.14326)
Comments:
          35 pages, 10 figures

- **What's New**: 이 논문에서는 Jeffreys centroid의 대체로 제안되는 새로운 Jeffreys-Fisher-Rao 중심을 소개합니다. 이는 Fisher-Rao midpoint를 기반으로 하여 다양한 확률 분포의 중심성을 제공하며, 특히 범주형 및 정규 분포에서 폐쇄 형태의 공식으로 구현됩니다.

- **Technical Details**: Jeffreys-Fisher-Rao 중심은 단일 매개변수 지수 가족 분포에 대해 일반적인 공식을 제공하며, 같은 평균을 가진 정규 분포에 대해서는 Jeffreys centroid와 일치합니다. 또한, Gauss-Bregman inductive center를 정의하여 Jeffreys centroid를 잘 근사할 수 있도록 합니다.

- **Performance Highlights**: 실험을 통해 Jeffreys-Fisher-Rao 중심과 Gauss-Bregman 중심이 Jeffreys centroid 대신 잘 작동하는 것을 보여줍니다. 이러한 중심들은 정보 기하학에서 쌍대 평면을 통해 빠르게 대안을 제시하고, 특히 같은 평균을 가진 정규 분포의 경우 Jeffreys centroid와 일치합니다.



### Text-to-Image Representativity Fairness Evaluation Framework (https://arxiv.org/abs/2410.14201)
- **What's New**: 이번 논문에서는 텍스트-이미지 (Text-to-Image, TTI) 생성 시스템의 대표성 공정성 (Representativity Fairness)을 평가하기 위한 프레임워크를 제안합니다. 이 프레임워크는 다양성 (Diversity), 포함성 (Inclusion), 품질 (Quality)의 세 가지 측면을 평가하며, 사람 기반 접근 방식과 모델 기반 접근 방식이 상호 대체 가능성을 평가합니다.

- **Technical Details**: 프레임워크는 이미지 생성을 위한 프롬프트를 제안하고, 세 가지 측면을 평가하는 데 필요한 인간 및 모델 기반 접근 방식을 제시합니다. 모델 기반 접근 방식은 사람 기반보다 더 적은 자원을 필요로 하며, 특정한 경우에 한정된 리소스에서도 잘 작동할 수 있도록 설계되었습니다.

- **Performance Highlights**: Stable Diffusion 모델에 대한 평가 결과, 제안된 프레임워크가 TTI 시스템의 편향을 효과적으로 포착할 수 있다는 것을 보여주었고, 제안된 모델 기반 접근 방식이 인간 기반 접근 방식의 세 가지 구성 요소 중 세 가지에서 높은 상관관계를 가지고 상호 대체할 수 있음을 확인하였습니다. 이는 비용을 줄이고 프로세스를 자동화할 수 있는 잠재력을 제공합니다.



### Learning autonomous driving from aerial imagery (https://arxiv.org/abs/2410.14177)
Comments:
          Presented at IROS 2024

- **What's New**: 이 연구에서는 항공 이미지를 기반으로 지상 차량의 인식을 통한 제어(intuitive control)를 학습하는 문제를 다룹니다. 기존의 고품질 시뮬레이터와 달리, Neural Radiance Field (NeRF)를 중간 표현으로 사용하여 새로운 시점을 합성(synthesize)하여 보다 효율적인 데이터 생성을 가능하게 합니다.

- **Technical Details**: NeRF를 활용하여 바닥에서의 관찰을 바탕으로 시뮬레이터에 필요한 데이터를 생성하며, 이는 전통적인 photogrammetric 시뮬레이터보다 컴팩트한 표현을 제공합니다. 이 연구는 비행기의 시점에서 지상 차량의 인식 및 제어를 위한 두 가지 문제를 다룹니다; (i) 시각적 재위치(localization) 및 (ii) end-to-end 운전.

- **Performance Highlights**: 제작한 미니 도시 환경에서 로봇 자동차에 대한 모방 정책(imitation policy)을 통해 본 방법의 효용성을 입증하였고, 실제 환경에서 자동차를 재위치할 수 있는 능력을 보여주었습니다. 이를 통해 실제 주행 데이터 없이도 고유한 운전 경로 및 조향 명령을 직접 학습할 수 있음을 확인했습니다.



### Deep Learning Applications in Medical Image Analysis: Advancements, Challenges, and Future Directions (https://arxiv.org/abs/2410.14131)
- **What's New**: 최근의 연구들은 심층 학습(Deep Learning) 알고리즘이 뛰어난 정확성과 효율성을 통해 의료 영상 분석의 혁신을 이끌어내고 있음을 보여주고 있습니다. 특히, 합성곱 신경망(Convolutional Neural Networks, CNNs)이 여러 의료 과목에서 자율적으로 특성을 학습하여 진단을 가속화하는 데 중요한 역할을 하고 있습니다.

- **Technical Details**: 딥러닝은 다차원 의료 이미지(MRI, CT 스캔, 엑스레이 등)에서 특징을 수동으로 추출할 필요 없이 자동적으로 학습하는 능력을 보입니다. 이러한 기술은 병리학(Pathology), 영상의학(Radiology), 안과학(Ophthalmology), 심장학(Cardilogy) 등 다양한 분야에서 질병 탐지, 분류(classification), 그리고 분할(segmentation) 작업에 사용됩니다.

- **Performance Highlights**: 이 연구에서 제안된 모델들은 임상 절차의 신뢰성과 신속성을 향상시키며, 의료진이 정확하고 빠른 진단을 내리는 데 도움을 주고 있습니다.



### Self Supervised Deep Learning for Robot Grasping (https://arxiv.org/abs/2410.14084)
- **What's New**: 이번 연구는 기존의 라벨링 된 데이터에 의존하는 딥 러닝 기반 로봇 그랩핑(Grasping) 접근 방식의 한계를 극복하기 위해 자가 감독(Self-Supervised) 로봇 설정을 제안합니다.

- **Technical Details**: 연구에서는 CNN(Convolutional Neural Network)을 훈련하기 위해 로봇이 자가 라벨링(Self-Labeling) 및 데이터 수집을 수행하는 방법을 설명합니다. 이 로봇은 작은 실험실 환경에서 사용하기 적합하며, 여러 객체에 대해 수백 시간 동안 훈련할 수 있도록 설계되었습니다.

- **Performance Highlights**: 이 방법은 기존 비싼 세트업과 큰 에너지 소모를 줄이면서 성능을 향상시킬 수 있는 가능성을 제공합니다. 더 큰 로봇에 훈련된 Neural Network를 통합하거나 스케일링 할 수 있는 이점도 있습니다.



### On Partial Prototype Collapse in the DINO Family of Self-Supervised Methods (https://arxiv.org/abs/2410.14060)
Comments:
          First version of the paper appeared in OpenReview on 22 Sep 2023. Accepted to BMVC 2024

- **What's New**: 본 논문에서는 DINO 방법군에서의 부분 프로토타입 붕괴(partial prototype collapse) 문제를 정의하고 이를 해결하기 위한 KoLeo-proto 정규화 방법을 제안합니다. 이 방법은 다양한 프로토타입을 활용하도록 유도하여 보다 정교한 클러스터와 유용한 표현을 학습할 수 있도록 돕습니다.

- **Technical Details**: Self-supervised learning (SSL)에서 클러스터(cluster)를 기반으로 표현을 모델링하는 방식이 널리 쓰입니다. DINO 방법군은 동시 학습 중에 발생하는 프로토타입 간의 간섭으로 인해, 특정 프로토타입이 동일한 벡터로 수렴하는 부분 프로토타입 붕괴 문제를 겪습니다. 이를 방지하기 위해, KoLeo-proto 정규화는 프로토타입의 차별적 엔트로피(differential entropy)를 극대화하여 다양한 프로토타입을 장려합니다.

- **Performance Highlights**: iNaturalist-2018과 같은 긴 꼬리의 데이터셋에서 사전 학습을 진행했을 때, 동일한 데이터셋을 분류하는 성능에서 명확한 성능 향상을 보여주었으며, 이전 모델들과 비교했을 때 전이 성능(transfer performance)에도 영향을 미치지 않았다는 결과를 나타냈습니다.



### Segmentation of Pediatric Brain Tumors using a Radiologically informed, Deep Learning Cascad (https://arxiv.org/abs/2410.14020)
- **What's New**: 이번 연구에서는 소아 환자의 Diffuse Intrinsic Pontine Glioma (DIPG) 및 Diffuse Midline Glioma (DMG) 뇌종양 세분화를 위한 새로운 nnU-Net 접근 방식을 제안합니다. BraTS-PEDs 2024 챌린지에 제출된 이 방법은 기존 nnU-Net 기술에 계층적 캐스케이드를 적용하여 세분화 작업을 수행합니다.

- **Technical Details**: 이 연구에서는 residual encoder 변형 nnU-Net을 기반 모델로 사용하여 고품질 세분화를 제공합니다. nnU-Net의 구현에 여러 가지 수정을 추가하고, 두 단계의 캐스케이드를 통해 뇌종양의 하위 구조를 조정하여 세분화합니다. T1w, T1w-CE, T2w 및 T2-FLAIR MRI에서 CC, ED, ET 및 NET 종양 레이블을 세분화하기 위해 훈련된 nnU-Net Residual Encoder의 출력을 두 개의 추가 모델에 전달하여 ET 대 NET, CC 대 ED를 분류합니다. 이 과정에서 방사선학적 가이드라인을 사용하여 멀티 파라메트릭 MRI (mpMRI)를 선택합니다.

- **Performance Highlights**: 제안된 방법은 기본 nnU-Net 및 앙상블 nnU-Net과 비교했을 때 BraTS-PEDs 2024 챌린지에서 안정적인 세분화를 제공합니다. 결과적으로 ET, NET, CC 및 ED에 대해 평균 Dice 점수가 각각 0.657, 0.904, 0.703, 0.967이며, HD95는 76.2, 10.1, 111.0, 12.3입니다.



### From Real Artifacts to Virtual Reference: A Robust Framework for Translating Endoscopic Images (https://arxiv.org/abs/2410.13896)
- **What's New**: 이 논문은 내시경 영상의 잡음과 아티팩트가 많은 환자 영상을 사전 수술 데이터로부터 복원된 깨끗한 가상 이미지와 정렬하는 강력한 기술을 필요로 하는 도메인 적응 문제를 다룹니다.

- **Technical Details**: 이 연구는 새로운 'local-global' 변환 프레임워크와 잡음 저항 특징 추출 전략을 포함한 아티팩트 내성 이미지 변환 방법을 제안합니다. 여기서 'local' 단계는 특징의 잡음을 제거하고, 'global' 단계는 전반적인 스타일 전환을 수행합니다. 또한, 잡음 내성 특징을 추출하기 위한 새로운 대비 학습 전략도 제안됩니다.

- **Performance Highlights**: 상세한 검증을 통해 기존의 최첨단 기술 대비 성능이 크게 향상되었다는 것을 보여주었으며, 새로운 벤치마크도 제안되어 이미지 변환 모델의 견고성을 평가하는 comprehensive한 분석을 제공합니다.



### UniDrive: Towards Universal Driving Perception Across Camera Configurations (https://arxiv.org/abs/2410.13864)
Comments:
          Preprint; 14 pages, 5 figures, 2 tables; Code at this https URL

- **What's New**: 이번 논문에서는 다양한 카메라 구성에 대해 범용적인 인식을 달성하기 위한 새로운 프레임워크인 UniDrive를 제안합니다. 이 프레임워크는 여러 가상 카메라를 통합하여 사용자의 운전 인식 모델을 최적화합니다.

- **Technical Details**: UniDrive는 통합된 가상 카메라 환경을 사용하고, 지면을 인식하는 프로젝션 방법을 통해 원본 이미지를 가상 뷰로 변환합니다. 또한, 원본 카메라와 가상 카메라 간의 예측 프로젝션 오류를 최소화하여 구성 최적화를 수행합니다. 이 방법은 기존의 3D 인식 메서드에 플러그 앤 플레이 모듈로 적용할 수 있습니다.

- **Performance Highlights**: 실험 결과, UniDrive는 하나의 특정 카메라 구성에서 교육된 모델이 다양한 카메라 구성에 잘 일반화될 수 있도록 하며, 성능 저하를 최소화합니다. CARLA의 데이터셋을 이용해 다양한 카메라 구성에서 효율성을 검증하였습니다.



### Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens (https://arxiv.org/abs/2410.13863)
Comments:
          Tech report

- **What's New**: 이 연구는 text-to-image generation의 맥락에서 자가 회귀 모델(autoregressive models) 스케일링 문제를 조사합니다. 특히 이 모델들이 사용하는 token이 discrete인지 continuous인지, 그리고 token이 BERT 및 GPT와 유사한 transformer 아키텍처에서 무작위(random)로 생성되는지 또는 고정(raster) 순서로 생성되는지를 중심으로 성능을 비교합니다.

- **Technical Details**: 연구는 VQ(vector quantization) 방식이 이미지 생성 성능에 미치는 영향과 token 생성 순서가 시각적 품질에 미치는 영향을 분석합니다. Fluid라는 새로운 random-order autoregressive 모델을 continuous token으로 학습시켜, 10.5B 모델인 Fluid가 MS-COCO 30K에서 제로샷 FID(zero-shot FID) 6.16을 기록했습니다.

- **Performance Highlights**: Fluid 모델은 FID와 GenEval 점수에서 다른 모델에 비해 우수한 성능을 보여주며, 특히 무작위 순서 모델이 raster 순서 모델에 비해 GenEval 점수에서 현저히 더 나은 결과를 보였습니다. 연구 결과는 비전 모델과 언어 모델 간의 스케일링 격차를 줄여주는 데 기여할 것으로 기대됩니다.



### DepthSplat: Connecting Gaussian Splatting and Depth (https://arxiv.org/abs/2410.13862)
Comments:
          Project page: this https URL

- **What's New**: 본 논문에서는 Gaussian splatting과 깊이 추정(depth estimation)을 결합하여 DepthSplat를 제안합니다. 이를 통해 두 기술 간의 상호작용을 연구하고, 개별 기술의 한계를 극복하며 성능을 강화합니다.

- **Technical Details**: DepthSplat는 사전 학습된 단안(depth from a single image) 특성을 활용하여 다중 뷰 깊이 모델을 개선합니다. 이 모델은 복잡한 장면에서 일관성 높은 깊이 예측을 수행할 수 있으며, Gaussian splatting 모듈은 완전하게 미분 가능하여 대규모 비구속 데이터셋에서 깊이 예측 모델을 사전 학습하는 새로운 방법을 제공합니다.

- **Performance Highlights**: DepthSplat는 ScanNet, RealEstate10K 및 DL3DV 데이터셋에서 최신 성능(State-of-the-art performance)을 기록했습니다. 이 결과는 Gaussian splatting과 깊이 추정의 연결이 상호 이점을 제공함을 보여줍니다.



### PUMA: Empowering Unified MLLM with Multi-granular Visual Generation (https://arxiv.org/abs/2410.13861)
Comments:
          Project page: this https URL

- **What's New**: 이 논문에서는 PUMA라는 새로운 접근 방식을 제안하고 있습니다. PUMA는 다양한 이미지 생성 작업의 서로 다른 세분화 요구를 통합하여 다양한 시각 작업을 처리할 수 있는 통합된 MLLM(다중 모드 대형 언어 모델) 프레임워크를 제공합니다.

- **Technical Details**: PUMA는 세 가지 주요 모듈로 구성됩니다: 1) 다양한 세분화 표현을 추출하는 이미지 인코더, 2) 다중 스케일 이미지 피쳐를 처리하는 자가 회귀 MLLM, 3) MLLM에서 생성된 피쳐를 다양한 세분화 수준에서 디코딩하는 특수화된 확산 기반 이미지 디코더. PUMA는 두 단계의 훈련 전략을 통해 최적화됩니다.

- **Performance Highlights**: PUMA는 이미지 이해, 텍스트-이미지 생성, 이미지 편집, 인페인팅, 컬러화 및 조건부 생성 등 다양한 다중 모드 작업을 처리할 수 있는 능력을 보여주며, 진정한 AGI(인공지능 일반화)를 향한 중요한 이정표로 자리잡고 있습니다.



### VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding (https://arxiv.org/abs/2410.13860)
Comments:
          CoRL 2024 Camera Ready. 25 pages. A novel zero-shot 3D visual grounding framework based solely on 2D images

- **What's New**: VLM-Grounder는 2D 이미지를 기반으로 한 새로운 zero-shot 3D visual grounding 프레임워크로, 기존의 객체 중심 정보에만 의존하는 방식의 한계를 극복합니다.

- **Technical Details**: 이 새로운 프레임워크는 이미지 시퀀스를 동적으로 스티칭(stitching)하고, 목표 객체를 찾기 위한 grounding 및 feedback 체계를 적용하며, 3D boundary box를 정확히 추정하기 위해 multi-view ensemble projection을 사용합니다. 이 과정에서 VLM(GPT-4V)을 활용하여 사용자 쿼리를 분석합니다.

- **Performance Highlights**: ScanRefer와 Nr3D 데이터셋을 대상으로 한 실험에서 VLM-Grounder는 각각 51.6%의 Acc@0.25와 48.0%의 Acc를 기록하며, 이전의 zero-shot 방법들을 능가하였습니다.



### $\gamma-$MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large Language Models (https://arxiv.org/abs/2410.13859)
- **What's New**: 이 논문에서는 기존의 멀티모달 대형 언어 모델(MLLMs)에서 발생하는 높은 계산 비용 문제를 해결하기 위한 새로운 접근법인 γ-MoD를 제안합니다. 이 방법은 "activated tokens"의 관점에서 모델의 효율성을 극대화합니다.

- **Technical Details**: γ-MoD는 주의 맵의 랭크(rank of attention maps, ARank)를 사용하여 각 레이어의 중복성을 측정하고 중복된 레이어를 MoD 레이어로 변환하는 전략입니다. 이를 통해 MLLM의 90% 이상의 밀집(dense) 레이어를 MoD로 효과적으로 변환할 수 있습니다.

- **Performance Highlights**: 실험 결과, γ-MoD는 LLaVA-HR 모델의 학습 및 추론 시간에서 각각 31.0% 및 53.2%를 단축시키며, 성능 저하는 단 1.5%로 유지됩니다. 이는 γ-MoD의 일반화 능력이 뛰어남을 나타냅니다.



### Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation (https://arxiv.org/abs/2410.13848)
Comments:
          Technical Report

- **What's New**: 이 논문에서는 다양한 모드의 이해 및 생성을 통합한 새로운 자율 회귀 프레임워크인 Janus를 소개합니다. 기존 연구는 주로 단일 시각 인코더를 사용했으나, Janus는 시각 인코딩을 별도의 경로로 분리하여 성능과 유연성을 향상시켰습니다.

- **Technical Details**: Janus는 고유한 transformer 아키텍처를 사용하여 시각 이해 및 생성을 위한 독립적인 인코딩 경로를 제공합니다. 이를 통해 이해와 생성 작업 사이의 정보를 분리하고, 각 작업에 가장 적합한 인코딩 방법을 선택할 수 있는 유연성을 제공합니다.

- **Performance Highlights**: Janus는 기존의 통합 모델보다 뛰어난 성능을 보여주며, MMBench 및 SEED-Bench와 같은 벤치마크에서 최고 성과를 기록했습니다. 또한, DALL-E 2와 SDXL과 같은 특정 작업 모델을 초월하는 성과를 보였습니다.



### D-FINE: Redefine Regression Task in DETRs as Fine-grained Distribution Refinemen (https://arxiv.org/abs/2410.13842)
- **What's New**: D-FINE을 제안하며, DETR 모델 내에서 바운딩 박스 회귀 작업을 재정의하여 뛰어난 위치 정확도를 달성.

- **Technical Details**: 주요 구성 요소인 Fine-grained Distribution Refinement (FDR)와 Global Optimal Localization Self-Distillation (GO-LSD)를 통해, 고정 좌표 대신 확률 분포를 반복적으로 정제하여 정확도를 높임. 또한, GO-LSD는 깊은 레이어에서 세밀한 정보로부터 지식을 얕은 레이어로 이전하여 최적화를 단순화함.

- **Performance Highlights**: D-FINE-L와 D-FINE-X는 COCO 데이터셋에서 각각 54.0%와 55.8% AP를 기록하며, NVIDIA T4 GPU에서 각각 124 FPS 및 78 FPS의 속도를 유지. Objects365에서 사전 훈련 후 최대 59.3% AP 달성하며, 기존 실시간 감지기들을 초월함.



### VidPanos: Generative Panoramic Videos from Casual Panning Videos (https://arxiv.org/abs/2410.13832)
Comments:
          Project page at this https URL. To appear at SIGGRAPH Asia 2024 (conference track)

- **What's New**: 이 논문에서는 일반적인 동적인 장면에서 촬영된 패닝(panning) 비디오로부터 파노라마(panoramic) 비디오를 합성하는 새로운 방법을 제안합니다. 기존의 정적인 장면에서는 잘 알고 있던 스티칭(stitching) 문제를 넘어, 움직이는 물체가 포함된 장면의 연속성을 고려하여, 마치 광각(wide-angle) 카메라로 촬영한 것처럼 파노라마 비디오를 생성하는 방법론입니다.

- **Technical Details**: 이 접근법은 공간-시간 오프페인팅(space-time outpainting) 문제로 설정되며, 입력 비디오와 같은 길이를 가진 전체 파노라마 비디오를 생성하는 것을 목표로 합니다. 제안된 방법은 비디오 프레임을 등록하여 단일 비디오 볼륨을 만들고, 입력 비디오 바깥의 공간-시간 영역을 초기적으로 알 수 없는 상태로 두며, 그 후 이 알 수 없는 영역을 완성하는 과정을 포함합니다. 최근의 생성 모델(generative model)을 도입하고, 이 모델의 한계를 최소화하며 효과를 극대화할 수 있는 방법을 적용합니다.

- **Performance Highlights**: 제안된 시스템은 사람, 차량, 흐르는 물 등 다양한 실생활 장면에 대하여 비디오 파노라마를 생성할 수 있으며, 입력 비디오의 알려진 영역과 일관되게 동작하고, 리얼리스틱(realistic)하게 보이는 결과를 생성합니다. 이 연구는 Lumiere와 Phenaki라는 두 가지 비디오 생성 모델을 활용하여 실험을 진행하였으며, 각 모델의 장단점을 분석하였습니다.



### DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise Motion Contro (https://arxiv.org/abs/2410.13830)
Comments:
          Project page: this https URL

- **What's New**: DreamVideo-2는 복잡한 테스트 타임 파인튜닝 없이 특정 주제와 모션 궤적을 갖는 비디오를 생성할 수 있는 제로샷(Zero-shot) 비디오 사용자 지정 프레임워크입니다. 사용자는 단일 이미지와 경계 상자(바운딩 박스) 시퀀스를 입력으로 제공하여 비디오를 만들 수 있습니다.

- **Technical Details**: 본 연구에서는 주제 학습을 위한 모델의 고유한 능력을 활용하는 레퍼런스 어텐션(reference attention)과, 경계 상자에서 파생된 박스 마스크의 강력한 모션 신호를 완전히 활용하여 정밀한 모션 제어를 달성하기 위한 마스크 가이드 모션 모듈(mask-guided motion module)을 도입합니다. 또한, 마스크된 레퍼런스 어텐션과 재가중화 확산 손실(reweighted diffusion loss)을 통해 주제 학습과 모션 제어의 균형을 맞추는 두 가지 디자인을 제안합니다.

- **Performance Highlights**: DreamVideo-2는 새로운 데이터셋에서 수행된 포괄적인 실험 결과에 따르면 기존의 최첨단 방법들보다 주제 사용자 지정 및 모션 제어 모두에서 뛰어난 성능을 보입니다.



### Harnessing Webpage UIs for Text-Rich Visual Understanding (https://arxiv.org/abs/2410.13824)
- **What's New**: 이번 연구에서는 웹 페이지 UI에서 일반 다중 모달 지침을 합성하여 MLLM(다중 모달 대형 언어 모델)의 텍스트가 풍부한 시각적 이해(text-rich visual understanding) 능력을 향상시키는 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 730만 개 샘플로 구성된 MultiUI 데이터셋을 활용하며, 이는 100만 개 웹사이트에서 수집되었습니다. 텍스트 기반 대형 언어 모델(LLM)은 웹페이지 접근성 트리에서 구조적 텍스트 표현을 처리하여 다중 모달 모델을 교육하는 데 필요한 지침을 생성합니다.

- **Performance Highlights**: MultiUI로 훈련된 모델은 웹 UI 작업에서 VisualWebBench에서 최대 48%의 개선을 보였으며, Mind2Web 데이터셋에서 액션 정확도가 19.1% 향상되었습니다. 더 나아가 이 모델은 비웹 UI 작업과 문서 이해, OCR, 차트 해석과 같은 비 UI 도메인에서도 놀라운 일반화를 보여주었습니다.



### Deep Generative Models Unveil Patterns in Medical Images Through Vision-Language Conditioning (https://arxiv.org/abs/2410.13823)
Comments:
          Accepted by AIM-FM Workshop of NeurIPS2024

- **What's New**: 이 연구는 깊은 생성 모델(Deep Generative Models)이 의학 이미지 분석에 어떻게 패턴을 드러내고 표현할 수 있는지를 강조합니다. 특히, 기존의 데이터 증대(data augmentation)를 넘어서는 접근 방식을 제시하며, 임상 데이터와 세분화 마스크(segmentation masks)를 결합하여 이미지 합성(image synthesis) 과정을 안내합니다.

- **Technical Details**: 연구에서는 임상 정보를 텍스트로 변환하는 혁신적인 접근 방식을 사용하여 누락된 값을 처리하고, 대규모의 사전 훈련된 비전-언어 모델(vision-language models)을 활용하여 독립적인 임상 항목 간의 관계를 탐구합니다. 텍스트-비주얼 임베딩(text-visual embedding) 메커니즘을 도입하여 네트워크가 제공된 정보를 효과적으로 활용할 수 있도록 조건을 강화합니다. 이 방법은 GAN 기반과 확산 모델(diffusion models) 모두에 일반화할 수 있습니다.

- **Performance Highlights**: 가슴 CT 데이터셋을 활용한 실험 결과에서, 흡연 상태와 관련된 폐의 일관된 강도 변화가 임상 관찰과 일치하는 것을 보여주었으며, 이는 특정 속성이 의료 이미지 패턴에 미치는 영향을 포착하고 시각화하는 데 있어 방법의 효과를 입증합니다. 이 연구는 깊은 생성 모델을 활용하여 복잡한 임상 상태를 조기 발견하고 정밀 시각화할 수 있는 새로운 길을 제공합니다.



### Multi-style conversion for semantic segmentation of lesions in fundus images by adversarial attacks (https://arxiv.org/abs/2410.13822)
Comments:
          preprint

- **What's New**: 이번 논문에서는 다양한 데이터베이스의 주석 스타일 간 표준화를 해결하기 위해 'adversarial style conversion'이라는 새로운 방법을 도입합니다. 이 방법은 단일 아키텍처에서 결합된 데이터베이스를 활용하여 모델이 입력에 따라 자발적으로 세분화 스타일을 조정하도록 훈련되었습니다.

- **Technical Details**: 제안된 방법론은 인코더 특징을 기반으로 데이터셋의 출처를 탐지하는 'linear probe'를 추가하고, 적대적 공격(adversarial attacks)을 통해 모델의 세분화 스타일을 조정하는 방식을 채택합니다. 이는 여러 데이터셋에서 훈련된 세분화 모델의 스타일 변환을 가능하게 합니다.

- **Performance Highlights**: 논문의 결과는 데이터셋 조합을 통해 질적으로나 양적으로 유의미한 개선을 보이며, 모델의 일반화 성능, 불확실성 추정 및 주석 스타일 간의 지속적 보간과 같은 기회를 제공합니다.



### ConsisSR: Delving Deep into Consistency in Diffusion-based Image Super-Resolution (https://arxiv.org/abs/2410.13807)
- **What's New**: 본 논문에서는 Real-world image super-resolution (Real-ISR) 문제를 해결하기 위해 ConsisSR이라는 새로운 방법을 제안합니다. 이 방법은 텍스트-이미지 (T2I) diffusion 모델을 활용하여 의미적 일관성과 픽셀 수준의 일관성을 모두 처리할 수 있도록 설계되었습니다.

- **Technical Details**: ConsisSR의 핵심 기술로는 먼저, Hybrid Prompt Adapter (HPA)를 통해 CLIP 이미지 임베딩과 텍스트 임베딩을 효과적으로 결합하여 의미적 일관성을 확보합니다. 또한 Time-aware Latent Augmentation (TALA)을 도입하여 T2I 생성과 Real-ISR의 일관성 요건 간의 간극을 줄입니다. GAN-Embedding 방식은 Real-ESRGAN의 사전 학습된 데이터를 활용하여 초기 diffusion 단계를 건너뛰고 추론 속도를 획기적으로 향상시킵니다.

- **Performance Highlights**: 제안하는 ConsisSR은 전체적인 SDSR 방법들 중에서 SOTA (state-of-the-art) 성능을 달성하며, 기존 모델에 비해 추론 프로세스를 최소 10단계로 줄여도 샘플링 품질을 유지합니다.



### MotionBank: A Large-scale Video Motion Benchmark with Disentangled Rule-based Annotations (https://arxiv.org/abs/2410.13790)
- **What's New**: 이 논문에서는 대규모 모션 모델(Large Motion Model, LMM)을 구축하고 벤치마크하는 방법에 대해 다루고 있습니다. 새로운 MotionBank 데이터셋은 13개의 비디오 액션 데이터셋을 통합하여 1.24M개의 모션 시퀀스와 132.9M개의 프레임을 포함하고 있어 자연적이고 다양한 인간 모션을 제공합니다.

- **Technical Details**: MotionBank는 다양한 사람들의 일상 활동에서 수집된 대규모 인간 중심의 비디오 액션 데이터셋으로, 4D 모션 데이터의 부족함을 해결합니다. 이 데이터는 SMPL(Skinned Multi-Person Linear Model) 매개변수를 활용하여 생성되며, 이동 캡션 생성 알고리즘을 통해 자동으로 비편향적이고 규칙 기반의 텍스트 설명을 생성합니다.

- **Performance Highlights**: 실험 결과, MotionBank는 인간 모션 생성, 상황에 맞는 모션 생성 및 모션 이해와 같은 일반적인 모션 관련 작업에 유익하다는 것을 보여주었습니다. 또한 이 데이터셋은 LMM을 위한 효율적인 대안으로서 기능할 수 있습니다.



### Emphasizing Semantic Consistency of Salient Posture for Speech-Driven Gesture Generation (https://arxiv.org/abs/2410.13786)
- **What's New**: 이번 연구에서는 기존의 음성 기반 제스처 생성 방법에서 나타나는 문제점을 해결하기 위해 강조된 의미적 일관성을 바탕으로 새로운 방법을 제안합니다. 특히, 두 가지 모달리티인 오디오와 신체 자세의 개별 표현을 학습하는 조인트 매니폴드 공간을 도입하여 의미적 연관성을 활용하고, 특히 중요한 자세 구분에 중점을 두었습니다.

- **Technical Details**: 새로운 방법에서는 의미적 일관성을 강하게 유지하기 위해 일관성 손실(consistency loss)을 활용합니다. 또한, 약한 감독 학습을 활용한 중요한 자세 감지기를 도입하여 중요한 자세를 식별하고, 이와 관련된 일관성 손실을 보강하여 높은 의미적 내용을 가진 자세와 오디오를 효과적으로 정렬합니다. 음성의 표정과 신체 제스처를 별도로 합성하는 두 가지 가지(branch)를 설계하여 동기화 및 자연스러움을 월등히 개선합니다.

- **Performance Highlights**: 광범위한 실험 결과에 따르면, 제안된 방법은 기존의 최첨단 접근법들에 비해 우수한 성능을 입증하였습니다. 특히, 의미적 일관성을 강조함으로써 만들어진 제스처의 자연스러움과 전달력이 크게 향상되었습니다.



### Improving Multi-modal Large Language Model through Boosting Vision Capabilities (https://arxiv.org/abs/2410.13733)
- **What's New**: 최근 시각-언어 모델의 시각 이해 능력을 향상시키기 위해 Arcana라는 새로운 멀티모달 언어 모델을 제안합니다. 이 모델은 두 가지 중요한 기술인 MM-LoRA와 QLadder 어댑터를 도입합니다.

- **Technical Details**: Arcana는 MM-LoRA를 통해 시각과 언어를 각각 위한 두 개의 병렬 LoRA로 구성된 디코더를 구현합니다. 또한, QLadder 어댑터를 사용하여 고정된 사전 훈련된 시각 인코더로부터의 중간 표현을 집계하는 '계단' 구조를 포함합니다. 이 구조는 시각 정보를 더 잘 학습하고 통합할 수 있도록 돕습니다.

- **Performance Highlights**: 실험 결과, Arcana는 DINOv2 기반의 첨단 방법들과 비슷한 성과를 내며, 기존의 멀티모달 벤치마크에서 성능 향상을 보여줍니다. 기능적 측면에서 MM-LoRA와 QLadder의 효율성을 입증했습니다.



### DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation (https://arxiv.org/abs/2410.13726)
- **What's New**: 이번 연구에서는 DAWN(Dynamic frame Avatar With Non-autoregressive diffusion)이라는 새로운 프레임워크를 통해 오디오 클립과 초상화를 이용한 직접적인 동영상 생성 방식을 선보입니다. DAWN은 기존의 autoregressive (AR) 방식의 한계를 극복하여, 모든 프레임을 동시 생성할 수 있는 비선형(non-autoregressive, NAR) 전략을 적용하였습니다.

- **Technical Details**: DAWN 프레임워크는 (1) 오디오에 기반한 전체적인 얼굴 역학을 생성하는 잠재적 동작 공간에서의 생성과 (2) 오디오 기반의 머리 자세 및 깜빡임 생성이라는 두 가지 주요 구성 요소로 이루어져 있습니다. 추가적으로, Pose and Blink generation Network (PBNet)는 오디오에서 자연스러운 머리 자세와 깜빡임 시퀀스를 생성하는 데 사용됩니다. DAWN은 A2V-FDM(Audio-to-Video Flow Diffusion Model)을 통해 입술과 오디오 간의 암묵적 관계를 학습합니다.

- **Performance Highlights**: DAWN은 빠른 생성 속도와 더불어 정확한 입술 동작 및 자연스러운 자세/깜빡임을 보장하여, 실제감 있고 생동감 넘치는 비디오를 생성합니다. 또한, DAWN은 뛰어난 외삽(extrapolation) 능력을 발휘하며, 긴 비디오에서도 높은 품질을 안정적으로 유지할 수 있는 가능성을 보여줍니다.



### Movie Gen: A Cast of Media Foundation Models (https://arxiv.org/abs/2410.13720)
- **What's New**: 이번 논문에서는 Movie Gen이라는 새로운 foundation 모델 세트를 제안합니다. 이 모델은 다양한 화면 비율과 동기화된 오디오와 함께 고품질 1080p HD 비디오를 생성하며, 사용자의 이미지를 기반으로 한 개인화된 비디오 생성 및 정밀한 지침 기반 비디오 편집 기능도 포함되어 있습니다.

- **Technical Details**: Movie Gen은 30B 파라미터의 트랜스포머 모델로, 최대 73K 비디오 토큰의 컨텍스트 길이를 가지고 있습니다. 이 모델은 텍스트-비디오 합성, 비디오 개인화, 비디오 편집, 비디오-오디오 생성 및 텍스트-오디오 생성과 같은 다양한 작업에서 최첨단 성능을 기록합니다. 인터넷 스케일의 이미지, 비디오, 오디오 데이터를 통해 사전 학습되었습니다.

- **Performance Highlights**: Movie Gen 모델은 기존 상업 시스템을 초월하여 텍스트-비디오 생성, 비디오 개인화, 정밀 비디오 편집 및 오디오 생성 작업에서 탁월한 성능을 보여줍니다. 특히, Movie Gen Video는 최대 16초의 개인화된 HD 비디오 생성을 가능하게 하며, Movie Gen Audio는 정밀한 음악 생성과 음향 효과 생성을 지원합니다.



### Exploring the Design Space of Visual Context Representation in Video MLLMs (https://arxiv.org/abs/2410.13694)
Comments:
          Long Video MLLM; work in progress

- **What's New**: 비디오 다중 모달 대형 언어 모델(Video Multimodal Large Language Models, MLLMs)의 시각적 컨텍스트 표현에 대한 체계적인 연구를 다룬 첫 번째 논문입니다. 연구진은 최적의 시각적 컨텍스트 표현 방식인 Opt-Visor 모델을 제안하며, 최대 162 프레임까지의 비디오를 처리할 수 있습니다.

- **Technical Details**: 비디오 MLLMs의 성능 향상을 위해 프레임 선택(frame selection)과 임베딩 선택(embedding selection)을 최적화하는 제약 최적화 문제로 작업을 정의했습니다. 각 프레임에서의 토큰 수와 프레임 수에 따른 언어 모델링 손실(training loss)을 함수로 모델링하여 시각적 컨텍스트의 경쟁 관계를 이해합니다. 이러한 분석을 바탕으로 성능 추세를 설명하는 함수 곡선을 맞추어 다양한 선택 전략의 효과를 평가했습니다.

- **Performance Highlights**: 실험 결과, 시각적 임베딩 수(토큰 또는 프레임)를 증가시키는 것이 전반적으로 성능 향상에 기여한다는 것을 확인했습니다. 특히, 압축 기반 방법이 더 적은 시각적 임베딩으로도 더 많은 의미 정보를 보존할 수 있다는 점이 강조되었습니다. 연구진은 이러한 성과를 통해 프레임 선택과 임베딩 선택 간의 이상적인 비율을 찾는 방법을 제안하고, 경험적 실험과 일치하는 제안된 최적 설정을 검증하였습니다.



### Label-free prediction of fluorescence markers in bovine satellite cells using deep learning (https://arxiv.org/abs/2410.13685)
Comments:
          11 pages, 4 figures

- **What's New**: 본 연구에서는 소의 위성 세포(Bovine Satellite Cells, BSCs)의 비침습적이고 비표지(label-free) 방법을 통해 품질을 평가하는 새로운 접근법을 제시합니다. 이는 전통적인 염색 및 세포 관찰 방법의 한계를 극복하기 위한 딥러닝 기반의 기술을 활용하였습니다.

- **Technical Details**: U-Net 기반의 CNN 모델을 사용하여 세포 배양의 하나의 밝은 필드 밝기(optical) 이미지를 통해 여러 개의 형광 신호를 예측했습니다. DAPI와 Pax7 두 가지 주요 생체 표지를 사용하여 BSCs의 풍부함과 품질을 평가하였으며, 이미지 전처리 과정에서 형광 잡음을 제거하여 예측 성능을 개선했습니다. 48개의 생물학적 복제본을 사용하고 Pearson 상관 계수 및 SSIM과 같은 통계적 성능 지표로 모델을 평가하였습니다.

- **Performance Highlights**: 모델은 DAPI 예측에서 더 우수한 성능을 보였으며, 이는 균일한 염색 덕분입니다. Pax7 예측은 생물학적 이질성을 반영하여 더 변동성이 컸습니다. 또한 향상된 시각화 기술을 통해 예측의 해석 가능성을 높여 연구자들이 모델 예측을 쉽게 이해하도록 지원했습니다. 최종 결과는 BSC 품질 평가의 비침습적이고 실용적인 AI 기반 평가를 가능하게 하여 기른 고기 산업의 발전에 기여할 것입니다.



### Pose-Based Sign Language Appearance Transfer (https://arxiv.org/abs/2410.13675)
- **What's New**: 이 연구에서는 수화에서 서명자의 외모를 제어하는 방법을 소개하며, 서면 내용은 보존하는 방법을 제시합니다. 이 방법은 서명자의 외모를 다른 사람으로 전이하여 자연스러운 움직임과 전환을 유지합니다.

- **Technical Details**: 서명자의 외모를 변경하고 서명 내용을 유지하기 위해 포즈 시퀀스를 조작하는 방법을 사용합니다. 신호 긴밀성과 자연스러운 운동을 위해 몸체와 얼굴의 특성은 수정하지만 손의 형상은 유지합니다. 이는 평균화된 포즈를 통해 수행됩니다.

- **Performance Highlights**: 이 방법은 서명자의 신원을 식별하는 정확성을 줄이면서도 수화 인식 성능을 약간 저하시킵니다. 분석 결과, 원래 포즈를 이용한 모델이 가장 뛰어난 성능을 보였으며, 전이된 포즈를 사용했을 때 신원 식별 정확도가 52.20%로 감소했습니다. 이는 프라이버시와 유용성 간의 균형을 잘 보여줍니다.



### Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion (https://arxiv.org/abs/2410.13674)
Comments:
          23 pages, including references and appendix. Code is available at this http URL

- **What's New**: 본 논문에서는 기존의 데이터 증강(data augmentation) 기법의 한계를 극복하기 위해, 이미지 가이드를 활용하여 합성 이미지와 실제 이미지 간의 스펙트럼 보간을 수행하는 새로운 접근 방법인 'Diffusion Curriculum (DisCL)'을 제안합니다.

- **Technical Details**: 기존의 텍스트 가이드는 합성 이미지의 품질이 원본 이미지와 어떤 연관이 있는지를 제어할 수 없지만, 이미지 가이드를 통해 합성 이미지와 실제 이미지의 유사성을 조절할 수 있습니다. DisCL은 훈련 단계에 따라 이미지 합성의 가이드 수준을 조정하여 모델을 위한 어려운 샘플을 식별하고 이들을 학습하는 데 가장 효과적인 가이드 수준을 평가합니다.

- **Performance Highlights**: DisCL을 iWildCam 데이터셋에 적용했을 때 OOD(Out-of-Distribution) 및 ID(In-Distribution) 매크로 정확도에서 각각 2.7% 및 2.1% 향상을 보여주었으며, ImageNet-LT에서 기본 모델의 tail-class 정확도를 4.4%에서 23.64%로 개선하고 모든 클래스 정확도에서 4.02% 향상을 달성했습니다.



### VL-GLUE: A Suite of Fundamental yet Challenging Visuo-Linguistic Reasoning Tasks (https://arxiv.org/abs/2410.13666)
Comments:
          18 pages, 7 figures

- **What's New**: 본 연구에서는 비주얼-언어적 (Visuo-Linguistic) 이해를 위한 새로운 멀티태스크 벤치마크인 VL-GLUE를 제안합니다. VL-GLUE는 7개의 다양한 태스크로 구성되어 있으며, 10만 개 이상의 샘플을 포함해 비주얼과 텍스트 간의 결합 추론 능력을 평가합니다.

- **Technical Details**: VL-GLUE는 이미지와 텍스트 정보를 결합하여 추론을 필요로 하는 7개의 태스크로 구성되어 있습니다. 이 benchmark는 다양한 이미지 유형(일상 장면, 도표 등)과 특정 도메인 텍스트(요리, 정치 등)를 포함해, 실제 세계에서의 멀티모달 이해의 필요성을 보여줍니다.

- **Performance Highlights**: 기존의 대규모 비전-언어 모델들이 VL-GLUE 벤치마크에서 낮은 점수를 얻어, 이 분야의 모델들이 시기적절한 비주얼-언어적 추론 능력을 갖춤이 긴급하게 요구되고 있다는 점이 부각되었습니다.



### DiRecNetV2: A Transformer-Enhanced Network for Aerial Disaster Recognition (https://arxiv.org/abs/2410.13663)
Comments:
          23 pages

- **What's New**: 이번 연구에서는 UAV(무인 항공기)와 AI 모델을 통합한 재난 인식 시스템을 위한 새로운 하이브리드 모델인 DiRecNetV2를 소개합니다. 이 모델은 전통적인 CNN(합성곱 신경망)의 특징 추출 능력을 바탕으로 Vision Transformers(ViT)의 글로벌 컨텍스트 해석 능력을 결합하여 경량화된 재난 관리 솔루션을 제공합니다.

- **Technical Details**: DiRecNetV2는 CNN과 ViT의 결합으로 이루어져 있으며, CNN의 강력한 특징 추출 능력과 ViT의 장거리 의존성 캡처의 조합으로 설계되었습니다. 이 모델은 Nvidia Orin Jetson 장비에서 176.13 FPS의 속도로 실행될 수 있도록 최적화되어 있습니다. AIDERSv2 데이터셋을 활용하여, 단일 레이블과 다중 레이블 인식 성능을 평가하였습니다.

- **Performance Highlights**: DiRecNetV2는 단일 레이블 테스트 세트에서 0.964의 가중 F1 점수를 달성하였으며, 복잡한 다중 레이블 테스트 세트에서 0.614의 점수를 기록하였습니다. 이는 이 모델이 단일 재난과 다중 재난 인식 및 분석에서 효과적임을 보여줍니다.



### ActionCOMET: A Zero-shot Approach to Learn Image-specific Commonsense Concepts about Actions (https://arxiv.org/abs/2410.13662)
Comments:
          15 pages, 3 figures. arXiv admin note: text overlap with arXiv:2004.10796 by other authors

- **What's New**: 이 논문은 인간이 수행하는 행동에 대한 다양한 추론을 자동 시스템에 적용하기 위한 새로운 멀티모달 작업을 제안하고 있습니다. 이를 위해 8.5k의 이미지와 59.3k의 행동 추론을 포함하는 새로운 데이터셋을 개발했습니다.

- **Technical Details**: 이 연구에서는 ActionCOMET이라는 제로샷 프레임워크를 도입하여 제공된 시각적 입력에 따라 언어 모델에서 지식을 감별합니다. 이 시스템은 요리 비디오 데이터셋을 기반으로 수집된 데이터를 사용하여 인과 관계와 같은 복잡한 행동 개념을 학습합니다.

- **Performance Highlights**: ActionCOMET의 초기 결과는 수집된 데이터셋에서의 성능을 나타내며, 기존의 최첨단 VQA(Visual Question Answering) 접근 방식과 비교하여 의미 있는 결과를 보여주고 있습니다.



### Help Me Identify: Is an LLM+VQA System All We Need to Identify Visual Concepts? (https://arxiv.org/abs/2410.13651)
Comments:
          14 pages, 7 figures

- **What's New**: 본 연구는 대규모 언어 모델(LLM)과 비주얼 질문 답변(Visual Question Answering, VQA) 시스템을 활용하여 제로샷(Zero-shot) 기반의 세밀한 비주얼 개념 학습 프레임워크를 제안합니다.

- **Technical Details**: 이 프레임워크에서는 GPT-3를 통해 데이터셋 내 비주얼 객체의 풍부한 언어적 설명을 얻고, 이를 이진 질문의 집합으로 변환하여 VQA 시스템에 제공합니다. 질문과 쿼리 이미지를 함께 제시하고, 답변을 집계하여 테스트 이미지에서 객체의 존재 여부를 확인합니다.

- **Performance Highlights**: 실험 결과, 기존의 제로샷 비주얼 분류 방법 및 소수 샷(few-shot) 개념 학습 방법과 비교할 때 상대적으로 유사한 성능을 보였습니다. 특히, 본 연구는 상당한 계산 오버헤드 없이도 설명 가능성을 유지하면서 높은 성능을 달성합니다.



### Comparison of Image Preprocessing Techniques for Vehicle License Plate Recognition Using OCR: Performance and Accuracy Evaluation (https://arxiv.org/abs/2410.13622)
Comments:
          12 pages, 13 figures

- **What's New**: 이 연구에서는 Optical Character Recognition (OCR) 기술을 개선하기 위한 다양한 이미지 전처리 기법들을 탐구하고 평가합니다. 특히 차량 번호판 인식에 초점을 맞춰, 그레이스케일 변환, CLAHE (Contrast Limited Adaptive Histogram Equalization), 양방향 필터(Bilateral Filter) 등 여러 기법을 적용하며, 각각의 기술이 어떻게 정확도, 정밀도, 재현율 및 F1 점수에 영향을 미치는지를 분석합니다.

- **Technical Details**: 연구는 BRASIL 차량 번호판 데이터셋을 사용하여 실험을 진행합니다. 각각의 전처리 기법은 단독 및 조합적으로 평가되며, 평가 지표로는 정확도(accuracy), 정밀도(precision), 재현율(recall), F1-score, ROC 곡선(ROC curve), AUC, ANOVA 등을 사용하여 최적의 방법을 도출합니다. 이러한 통계적 분석은 OCR 성능을 현실 세계 시나리오에서 최적화하는 데 중요한 인사이트를 제공합니다.

- **Performance Highlights**: 연구 결과, CLAHE와 그레이스케일 변환 조합이 차량 번호판 인식에서 가장 높은 정확도를 보였으며, 이를 바탕으로 제안된 전처리 기법들 중 최적의 실용적 접근법을 제공합니다. 이 연구는 OCR의 성능을 향상시키기 위해 연구자들에게 유용한 가이드를 제공하며, 교통 모니터링 및 차량 보안과 같은 분야에 significant한 영향을 미칠 것으로 기대됩니다.



### Enhanced Prompt-leveraged Weakly Supervised Cancer Segmentation based on Segment Anything (https://arxiv.org/abs/2410.13621)
Comments:
          10 pages, 7 figures

- **What's New**: 이번 연구에서는 제한된 레이블 데이터로 인한 문제를 해결하기 위한 약한 감독 기반의 세그멘테이션 모델인 Weakly Supervised Semantic Segmentation (WSSS)을 제안합니다. Class Activation Map (CAM)과 Segment Anything Model (SAM) 기반의 가짜 레이블링을 결합하여 이를 실시하였습니다.

- **Technical Details**: SAM을 기반으로 하는 가짜 레이블 생성에서, Attention Dropout Layer(ADL)를 개선하여 시각적 프롬프트를 명시적으로 통합하였습니다. 이를 통해 CAM 기반 접근법에서의 부분 및 잘못된 활성화 문제를 완화하고, GPU 메모리 사용량을 12GB로 제한하면서도 성능을 유지할 수 있었습니다.

- **Performance Highlights**: 제안된 방법은 유방암의 조직병리학적 데이터셋에 대한 실험에서 기존 WSSS 방법들을 초월하였으며, 제안된 접근법이 메모리 효율적임을 보여주었습니다. 코드 또한 공개되어 있어, 연구자들이 적용할 수 있습니다.



### LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decomposition for Parameter-Efficient Fine-Tuning (https://arxiv.org/abs/2410.13618)
Comments:
          13 pages, 7 figures

- **What's New**: 모델 스케일의 급격한 증가로 인해 파라미터 효율적인 미세 조정 기법인 LoLDU가 제안되었습니다. 이 방법은 기존의 Low-Rank Adaptation (LoRA)와 같은 접근과 차별화되면서 훈련 가능한 파라미터 수를 2600배 줄이며 비슷한 성능을 유지합니다.

- **Technical Details**: LoLDU는 Lower-Diag-Upper Decomposition (LDU)을 활용하여 희소 행렬의 초기화 및 최적화를 통해 수렴 속도를 향상시키고, 대각 행렬을 최적화하여 스케일 변환을 강화합니다. 지금까지 제안된 PEFT 기법 중 가장 적은 수의 파라미터(0.00025%)만을 조정하는 방식으로 작업합니다.

- **Performance Highlights**: LoLDU는 다양한 모델 아키텍처(LLaMA2, RoBERTa, ViT, Stable Diffusion)에서 instruction-following, natural language understanding (NLU), 이미지 분류 및 생성 작업을 포함한 4개의 지침 데이터 세트, 6개의 NLU 데이터 세트, 8개의 이미지 분류 데이터 세트에서 포괄적인 실험을 통해 효과성과 다재다능함을 입증했습니다.



### Spatiotemporal Object Detection for Improved Aerial Vehicle Detection in Traffic Monitoring (https://arxiv.org/abs/2410.13616)
Comments:
          13 pages

- **What's New**: 이번 연구는 UAV(무인 항공기) 카메라를 이용한 다중 클래스 차량 탐지의 발전을 다루며, Spatiotemporal Object Detection 모델을 개발하였습니다. 이를 위해 6,600개의 주석이 달린 연속 프레임 이미지로 구성된 Spatio-Temporal Vehicle Detection Dataset(STVD)를 소개하며, 이를 통해 알고리즘의 포괄적인 훈련과 평가를 가능하게 합니다.

- **Technical Details**: YOLO 기반 객체 탐지 알고리즘을 개선하여 시간적 동역학을 통합하였으며, 스페이셔 (spatial)와 템포럴 (temporal) 정보 모두를 활용하는 모델을 개발하였습니다. 기존의 단일 프레임 모델보다 뛰어난 성능을 발휘하며, 특히 주목(attention) 메커니즘을 통합하여 성능을 더 향상시킬 수 있음을 입증하였습니다.

- **Performance Highlights**: 실험적으로, 가장 우수한 시공간 모델이 단일 프레임 모델에 비해 16.22% 향상된 성능을 보였으며, 주목 메커니즘을 통합한 모델은 추가적인 성능 향상 가능성을 보여주었습니다.



### Material Fingerprinting: Identifying and Predicting Perceptual Attributes of Material Appearanc (https://arxiv.org/abs/2410.13615)
Comments:
          14 pages, 12 figures, 3 tables

- **What's New**: 본 논문은 동적인 시각적 자극에서 얻어진 인식적(stylish) 특징을 인코딩하여 새로운 재료 식별 방법을 제시합니다. 347 가지 재료의 비디오를 통해 수집된 16개의 중요한 인식 속성과 이를 활용한 '물질 지문'(material fingerprint) 생성 과정이 포함되어 있습니다.

- **Technical Details**: 심리 물리적 실험을 통해 20명 이상의 참가자로부터 각 재료에 대한 속성 평가를 수집하고, 이를 바탕으로 통계적 및 딥 러닝 이미지 특징과 인식 속성 간의 관계를 예측하기 위해 다층 퍼셉트론(multi-layer perceptron) 모델을 훈련시켰습니다. 이러한 과정은 재료 속성 간의 시각적 유사성 및 차별성을 intuitively 판단할 수 있는 파라미터로 작용합니다.

- **Performance Highlights**: 제안된 모델은 단 두 개의 이미지로부터도 효과적으로 시각적 지문을 추론할 수 있으며, 이는 디지털 애플리케이션에서 더 효율적이고 실용적인 재료 분석 가능성을 보여줍니다. 이 연구는 공공 데이터셋을 구축하고, 16개의 인식 속성을 통해 다양한 재료에 대한 이해를 증진시키는 중요한 기여를 합니다.



### MEGA: Memory-Efficient 4D Gaussian Splatting for Dynamic Scenes (https://arxiv.org/abs/2410.13613)
- **What's New**: 새로운 4D Gaussian Splatting (4DGS) 기술이 복잡한 동적 3D 장면을 고품질로 캡처할 수 있는 가능성을 보여주고 있습니다. 특히, 이 논문은 전통적인 4DGS의 메모리 문제를 해결하기 위한 메모리 효율적인 프레임워크를 제안합니다.

- **Technical Details**: 제안된 프레임워크는 색상을 3개의 매개변수를 가지는 개별 Gaussian의 직접 색상 요소와 경량의 교대 전류 색상 예측기로 분해합니다. 또한, 엔트로피 제약 Gaussian 변형 기법을 도입하여 각 Gaussian의 작용 범위를 확장하고, 투명도 기반의 엔트로피 손실을 통합하여 필요한 Gaussian의 수를 최소화합니다.

- **Performance Highlights**: 6비트 부동 소수점(FP16) 저장 및 zip 압축을 통해 Technicolor 및 Neural 3D 비디오 데이터셋에서 각각 190× 및 125×의 저장 공간 감소를 달성하면서도, 렌더링 속도와 장면 표현 품질을 유지합니다.



### H2OVL-Mississippi Vision Language Models Technical Repor (https://arxiv.org/abs/2410.13611)
- **What's New**: H2OVL-Mississippi 모델은 3700만 개의 이미지-텍스트 쌍을 기반으로, 8개의 H100 GPU를 사용하여 240시간 동안 훈련된 작은 비전-언어 모델(VLM) 쌍을 소개합니다. 특히, H2OVL-Mississippi-0.8B는 8억 개의 매개변수로 구성되어 텍스트 인식에 특화되어 있으며, OCRBench의 텍스트 인식 부문에서 최첨단 성능을 발휘하고 있습니다.

- **Technical Details**: H2OVL-Mississippi 모델은 Vision Transformer(비전 트랜스포머) 구성 요소와 대형 언어 모델(LLM)로 이루어집니다. H2OVL-Mississippi-0.8B는 OCR 및 문서 중심 작업에 최적화되어 있고, H2OVL-Mississippi-2B는 다양한 멀티모달 작업을 수행할 수 있는 일반 목적 모델입니다. 이들은 각각 256에서 1590개의 시각적 토큰을 생성하며, 동적 해상도 전략(dynamic resolution)과 다중 스케일 적응 크롭(multi-scale adaptive cropping) 전략을 활용하여 다양한 이미지 크기와 종횡비에 적응합니다.

- **Performance Highlights**: H2OVL-Mississippi-0.8B는 OCRBench에서 텍스트 인식 부문에서 최첨단 성능을 보여주며, H2OVL-Mississippi-2B는 다양한 학술 벤치마크에서 경쟁력 있는 메트릭스를 제공합니다. 두 모델 모두 H2O-Danube 언어 모델의 기능을 확장하여 비주얼 도메인으로의 적용 가능성을 높이고, Apache 2.0 라이선스 하에 공개되어 문서 AI와 비주얼 LLM의 접근성을 높였습니다.



### DN-4DGS: Denoised Deformable Network with Temporal-Spatial Aggregation for Dynamic Scene Rendering (https://arxiv.org/abs/2410.13607)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 논문에서는 실시간 수준의 동적 장면 렌더링을 위한 새로운 접근법인 Denoised Deformable Network with Temporal-Spatial Aggregation (DN-4DGS)를 제안합니다. 기존의 NeRF(Neural Radiance Fields) 방식의 한계를 극복하고, 3D Gaussian Splatting(3DGS)을 활용하여 노이즈를 줄이고 성능을 향상시키는 방법에 초점을 맞추고 있습니다.

- **Technical Details**: DN-4DGS는 Noise Suppression Strategy(NSS)와 Decoupled Temporal-Spatial Aggregation Module(DTS)라는 두 가지 주요 구성 요소로 이루어져 있습니다. NSS는 캘러니컬(Canonical) 3D Gaussian의 좌표 분포를 변경하고 노이즈를 억제하여 더 정확한 변형 필드를 생성합니다. DTS는 인접한 포인트와 프레임의 정보를 집계하여 공간-시간 정보를 비뚤어지지 않도록 처리합니다. 또한, 주요 좌표 변형 과정을 통해 노이즈를 감소시키고 최적의 결과를 도출하게 됩니다.

- **Performance Highlights**: 제안된 방법인 DN-4DGS는 다양한 현실 세계 데이터셋에서 최첨단의 렌더링 품질을 실시간 수준에서 달성합니다. 실험을 통해 기존의 동적 씬 렌더링 기법들과 비교하여 빠른 속도와 높은 정확도를 보여주며, 실무에 적용 가능성을 엿볼 수 있습니다.



### Let Me Finish My Sentence: Video Temporal Grounding with Holistic Text Understanding (https://arxiv.org/abs/2410.13598)
Comments:
          Accepted by ACMMM 24

- **What's New**: 이번 논문에서는 Video Temporal Grounding (VTG) 분야에서 query 문장의 전체적인 의미를 고려하지 못했던 기존의 접근 방식을 보완하기 위해 세 가지 주요 기여를 제안합니다. 첫째, 전체적인 텍스트 정보를 통합한 시각적 프레임 레벨 게이트 메커니즘을 소개하고, 둘째, 쿼리와 관련 있는 프레임 간의 정밀한 상관관계를 학습하는 cross-modal alignment loss를 제안합니다.

- **Technical Details**: 제안된 방법론은 두 가지 gating 메커니즘을 활용하는 gated cross-attention을 기반으로 하며, 각각 지역적(local) 및 비지역적(non-local) 게이트를 도입함으로써 텍스트 앵커와 개별 영상 프레임 간의 유사성을 평가합니다. 그리고 두 가지 정밀 정렬 손실(clip-level consistency loss와 frame-level relevance loss)을 통해 영상 내용과 쿼리 텍스트 간의 정렬을 최적화합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 QVHighlights, Charades-STA 및 TACoS와 같은 VTG 벤치마크에서 기존 최첨단 방법들보다 우수한 성능을 보여줍니다. 이는 전체적인 텍스트 이해가 모델이 영상 내에서 의미적으로 중요한 부분에 집중하도록 유도함을 나타냅니다.



### Pseudo Dataset Generation for Out-of-Domain Multi-Camera View Recommendation (https://arxiv.org/abs/2410.13585)
Comments:
          Accepted to VCIP 2024. Project page: this https URL

- **What's New**: 이 논문은 정규 비디오에서 유사 레이블(pseudo-labeled) 다중 카메라 편집 데이터셋을 생성하는 방법론을 제안합니다. 이는 레이블이 있는 다중 카메라 보기 추천 데이터가 부족한 문제를 해결하는 데 도움을 주며, 특히 기존 데이터셋이 특정 장면이나 스타일에 국한되었음을 지적합니다.

- **Technical Details**: 논문에서 제안하는 방법은 정규 비디오에서 샷을 감지하고, 이를 클러스터링하여 가상의 카메라 레이블(pseudo-camera labels)을 생성하는 것입니다. 이후 각 가상의 카메라에서 가장 시각적으로 유사한 샷을 후보로 선택하여 유사 레이블 데이터를 생성합니다. 이 과정은 Temporal Segment Network (TSN)를 통해 샷 분류 기능을 추출하고 K-Means 알고리즘으로 클러스터링을 수행하여 이루어집니다.

- **Performance Highlights**: 제안된 방식으로 훈련된 모델은 목표 영역(target domain)에서의 분류 정확도가 68%의 상대적 향상을 이뤘습니다. 이는 훈련된 모델의 정확도가 22.65에서 38.14로 개선되는 결과를 보여줍니다.



### Co-Segmentation without any Pixel-level Supervision with Application to Large-Scale Sketch Classification (https://arxiv.org/abs/2410.13582)
Comments:
          ACCV 2024 Main Paper + Supplementary (Appendix)

- **What's New**: 이 논문에서는 픽셀 수준의 감독 없이 여러 이미지에서 공통 객체의 픽셀 수준 분할(object co-segmentation)을 위한 새로운 방법을 제안합니다. 두 가지의 사전 훈련된 Vision Transformer(비전 변환기) 모델을 활용하여 이미지 내의 클래스 관련성과 클래스타입 간의 관련성을 평가합니다.

- **Technical Details**: 이 방법은 두 개의 ViT 모델을 사용하는데, 하나는 ImageNet으로 분류 훈련된 ViT로 대략적인 객체 위치 추정을 위해 사용되고, 다른 하나는 DINO로 훈련된 자가 감독형 ViT로 이미지 내부의 토큰 관련성을 평가합니다. 단계적으로 패치 수준의 클래스 관련성을 평가한 후, Biased N-Cut 방법을 통해 이미지 패치 분할을 진행합니다.

- **Performance Highlights**: 제안된 방법은 최근의 어려운 벤치마크에서 동등한 감독 수준(이미지 레이블)을 가진 방법들 중에서 최첨단 성능을 달성하였으며, 픽셀 수준의 감독이 포함된 방법들과도 경쟁력이 있습니다. 또한 이 방법은 대규모 스케치 인식 작업에서도 뛰어난 성능을 보입니다.



### DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving Scene Representation (https://arxiv.org/abs/2410.13571)
Comments:
this https URL

- **What's New**: 이번 논문은 자율주행 시나리오에서 4D 장면 재구성을 개선하기 위해 세계 모델 프라이어를 활용한 최초의 프레임워크인 DriveDreamer4D를 소개합니다.

- **Technical Details**: DriveDreamer4D는 자율주행 세계 모델을 생성 엔진으로 활용하여, 실제 주행 데이터 기반의 새로운 경로 비디오를 합성하는 방법을 사용합니다. 이를 통해 복잡한 주행 환경에서 전경과 배경 요소의 동적 운동을 독립적으로 조절하여 4D 장면의 공간-시간 일관성을 보장합니다. 또한, Novel Trajectory Generation Module (NTGM)을 제안하여 다양한 구조화된 교통 조건을 자동으로 생성합니다.

- **Performance Highlights**: 실험 결과, DriveDreamer4D는 새로운 경로 관점에서 생성 품질을 크게 향상시켜, PVG, S3Gaussian, Deformable-GS에 대해 FID에서 각각 24.5%, 39.0%, 10.5%의 상대적 개선을 달성했습니다. 또한, 주행 에이전트 간의 공간-시간 일관성이 눈에 띄게 향상되어 NTA-IoU 지표에서 각각 20.3%, 42.0%, 13.7%의 증가를 보였습니다.



### CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining Cloth-Changing Person Re-Identification Models (https://arxiv.org/abs/2410.13567)
- **What's New**: 본 논문에서는 Cloth-changing person re-identification (CC-ReID) 문제를 해결하기 위해, 고품질의 합성 데이터 생성 파이프라인을 제안했습니다. 특히, 6,000개의 개인 ID와 1,179,976개의 이미지로 구성된 새로운 자가 주석 CC-ReID 데이터셋인 Cloth-Changing Unreal Person (CCUP)을 구축하여 기존의 데이터 드리븐 모델의 한계를 극복하고자 했습니다.

- **Technical Details**: CCUP 데이터셋은 현실적 인물 모델과 다양한 시나리오를 통해 대규모 합성 데이터를 생성하는 과정을 포함합니다. 데이터 생성 과정에서는 MakeHuman 소프트웨어를 사용하여 리얼한 인체 스켈레탈 메쉬를 생성하고, Unreal Engine을 통해 다양한 감시 환경에서의 시뮬레이션을 수행했습니다. 이 방식으로, 각 개인은 평균 26.5벌의 의상을 착용하며, CCTV 카메라를 통해 자동으로 레이블링된 데이터가 생성됩니다.

- **Performance Highlights**: 제안된 CCUP 데이터셋을 기반으로 한 프리트레인-파인튜닝(pretrain-finetune) 프레임워크는 TransReID와 FIRe^2와 같은 전통적인 모델의 일반화 능력을 개선하는 데 기여합니다. 실험 결과, CCUP에서 프리트레인 되고 각 벤치마크(PRCC, VC-Clothes, NKUP)에서 파인튜닝된 두 가지 모델이 다른 최신 모델들을 능가하는 성능을 보여주었습니다.



### 360U-Former: HDR Illumination Estimation with Panoramic Adapted Vision Transformers (https://arxiv.org/abs/2410.13566)
Comments:
          Accepted at AIM Workshop 2024 at ECCV 2024, 18 pages, 6 figures

- **What's New**: 이 논문에서는 Equirectangular Panorama (ERP) 포맷을 활용한 조명 추정의 새로운 네트워크 아키텍처인 360U-Former를 제안합니다. 이는 U-Net 스타일의 Vision-Transformer 기반으로, PanoSWIN을 활용하여 ERP 포맷에 맞게 조정된 창 당 주의(attention) 블록을 사용합니다. 이는 조명 추정 분야에서 순수한 Vision-Transformer 모델이 최초로 사용되는 사례입니다.

- **Technical Details**: 360U-Former는 Limited Field of View (LFOV) Low Dynamic Range image (LDRI)로부터 HDRI를 생성하기 위해 Generative Adversarial Network (GAN)으로 훈련되었습니다. 이 모델은 기존의 ERP 이미지에서 발생하는 아티팩트(artifacts) 문제를 해결하여, 세로 가장자리에서의 seam이나 극점(poles)에서의 왜곡을 없앴습니다. PanoSWIN 주의 모듈과 원형 패딩(circular padding)을 사용하여 ERP 이미지를 보다 정확하게 인코딩하고 생성할 수 있도록 하였습니다.

- **Performance Highlights**: 360U-Former는 기존의 최첨단 방법들과 비교하여 ERP 아티팩트를 제거하는 데에 있어 뛰어난 성능을 보였으며, 확장성과 정확도 면에서 우수한 결과를 나타냅니다. 추가적으로, 이 모델은 다양한 실내 및 실외 환경을 재현하는 데 성공하여, 조명 조건을 복잡하게 처리할 수 있는 능력을 보여줍니다.



### SDI-Paste: Synthetic Dynamic Instance Copy-Paste for Video Instance Segmentation (https://arxiv.org/abs/2410.13565)
- **What's New**: 이 논문에서는 Copy-Paste와 같은 데이터 증강(Data Augmentation) 방법을 활용하여 기존 비디오 데이터셋을 확장하는 새로운 접근법을 제안합니다.

- **Technical Details**: Synthetic Dynamic Instance Copy-Paste라는 파이프라인을 통해, 동적으로 변형되는 객체를 포함한 합성 비디오 시퀀스를 생성하고, 이를 목표 비디오 시퀀스의 프레임에 복사하여 붙여넣습니다. 이 방법은 비디오 인스턴스 분할(Video Instance Segmentation) 작업에 적용되었습니다.

- **Performance Highlights**: +2.9 AP (6.5%) 및 +2.1 AP (4.9%)의 성능 상승을 기록했습니다. 두 개의 인기 있는 네트워크를 기반으로 실험을 수행하였으며, 코드와 모델을 공개했습니다.



### Generative Location Modeling for Spatially Aware Object Insertion (https://arxiv.org/abs/2410.13564)
- **What's New**: 이번 연구에서는 객체 삽입(Object Insertion)을 위한 새로운 접근 방식을 제안합니다. 기존의 방법들은 일반적으로 객체의 위치와 형태 생성의 두 단계를 동시에 처리하기 어려웠습니다. 그러나 본 연구에서는 위치 모델(Location Model)을 따로 생성하여 객체의 적절한 위치를 먼저 찾고, 그 이후에 객체를 생성하는 두 단계의 접근 방식을 도입하였습니다.

- **Technical Details**: 우리는 배경 이미지와 원하는 객체 클래스에 조건화된 바운딩 박스 좌표를 생성하는 자기 회귀 모델(Autoregressive Model)을 훈련시킵니다. 이를 통해 객체의 적절한 위치를 식별하고, 기존의 위치 데이터셋에서 희소한 주석(Sparse Annotations)을 효과적으로 처리합니다. 추가로, 긍정적 및 부정적 레이블을 활용한 직접 선호 최적화(Direct Preference Optimization)를 통해 모델의 정확도를 향상시킵니다.

- **Performance Highlights**: 광범위한 실험을 통해 제안된 생성적 위치 모델이 최신 Instruction-tuned 모델 및 위치 모델링 기준선보다 뛰어난 성능을 보임을 입증했습니다. 특히, 위치 추정의 정확성이 높아질수록 생성된 이미지 품질이 향상되는 경향을 확인했습니다. 사용자 연구(User Study)에서 본 접근 방식이 효과적임을 추가로 검증하였습니다.



### RemoteDet-Mamba: A Hybrid Mamba-CNN Network for Multi-modal Object Detection in Remote Sensing Images (https://arxiv.org/abs/2410.13532)
- **What's New**: 본 논문에서는 원거리 이미지를 활용한 무인 항공기(UAV) 원거리 탐지를 위한 새로운 멀티모달 탐지 네트워크인 RemoteDet-Mamba를 제안합니다. 이 네트워크는 단일 모드의 지역적 특성을 학습하고 패치 수준에서 글로벌 특성을 통합하여 작은 물체의 식별을 개선합니다.

- **Technical Details**: RemoteDet-Mamba는 Siamese CNN 네트워크와 Cross-modal Fusion Mamba (CFM) 모듈로 구성됩니다. CFM 모듈은 선택적 스캔 2D 메커니즘(SS2D)을 기반으로 하며, 특징의 4방향 스캔을 통해 밀집하게 분포된 작은 객체를 효과적으로 분리하고 글로벌 정보를 추출합니다. 이 구조는 선형 시간 복잡성을 유지합니다.

- **Performance Highlights**: DroneVehicle 데이터셋에서의 실험 결과, RemoteDet-Mamba는 최신 기법에 비해 우수한 탐지 성능을 보여주며, 계산 효율성과 매개변수 수를 유지했습니다.



### L3DG: Latent 3D Gaussian Diffusion (https://arxiv.org/abs/2410.13530)
Comments:
          SIGGRAPH Asia 2024, project page: this https URL , video: this https URL

- **What's New**: L3DG는 처음으로 3D Gaussian의 생성적 모델링을 위한 접근법으로, 잠재적 3D Gaussian 확산(3D Gaussian diffusion) 방식을 도입합니다. 이를 통해 전체 방 크기의 장면을 생성할 수 있는 효과적인 생성적 3D 모델링이 가능해졌습니다.

- **Technical Details**: L3DG는 VQ-VAE(vectored-quantized variational autoencoder)를 사용하여 3D Gaussian의 압축된 잠재 공간을 학습합니다. 이 공간은 희소(convolutional) 아키텍처를 통해 구성되며, 이는 효율적인 방 크기 장면 처리를 가능하게 합니다. 이 접근 방식은 8천 개의 Gaussian을 사용하는 작은 규모의 객체와 20만 개의 Gaussian을 사용하는 방 크기 장면 모두를 위한 고충실도(high-fidelity) 뷰 합성을 지원합니다. 3D Gaussian을 통해 생성된 장면은 임의의 시점(viewpoint)에서 실시간으로 렌더링할 수 있습니다.

- **Performance Highlights**: L3DG는 기존의 무조건적 객체 수준의 방사 필드(rapiance field) 합성보다 시각적 품질을 크게 개선하였으며, 대규모 장면 생성에서 더욱 효율적으로 확장 가능한 가능성을 보여줍니다. 실험 결과, L3DG는 PhotoShape 데이터셋에서 FID 지표가 약 45% 향상되었습니다.



### Generative Adversarial Synthesis of Radar Point Cloud Scenes (https://arxiv.org/abs/2410.13526)
Comments:
          ICMIM 2024; 7th IEEE MTT Conference

- **What's New**: 이 논문에서는 자동차 레이더의 검증과 검증을 위해 현실적인 교통 시나리오 데이터셋이 필요하다는 점을 논의하며, GANs(Generative Adversarial Networks)를 활용한 레이더 장면 합성을 제안합니다.

- **Technical Details**: PointNet++ 기반의 GAN 모델을 사용하여 현실적인 레이더 포인트 클라우드 장면을 생성하며, 생성된 장면의 성능을 실제 장면의 테스트 세트와 비교하기 위해 이진 분류기(binary classifier)를 사용합니다.

- **Performance Highlights**: 우리의 GAN 모델은 실제 장면 테스트 세트에 대해 ~87%의 유사한 성능을 달성함을 보여줍니다.



### Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data? (https://arxiv.org/abs/2410.13523)
Comments:
          Under Review

- **What's New**: 의료 이미지 분석에 대한 기존의 MedVLP 모델이 실제 데이터에 의존하는 반면, 이 연구는 고품질의 합성 데이터(Synthetic Data)를 사용하여 모델을 학습시키는 방안을 제안합니다. 특히, 현실 데이터에 비해 합성 데이터만으로 훈련된 MedVLP 모델이 매력적인 성과를 보였습니다.

- **Technical Details**: 연구에서는 off-the-shelf generative models를 사용하여 200,000개의 합성 X-ray 이미지와 보고서를 포함하는 SynCXR 데이터셋을 생성했습니다. 이 데이터셋은 데이터 품질과 분포를 조절하여 구축되었습니다. 제안된 자동화된 파이프라인을 통해 생성된 합성 데이터만으로 훈련한 MedVLP 모델은 실제 데이터로 훈련한 모델보다 AUC에서 평균 3.8% 개선된 성능을 보였습니다.

- **Performance Highlights**: 합성 데이터 또는 혼합(data mixing) 데이터를 사용하여 훈련된 MedVLP 모델은 실제 데이터에서 훈련된 모델보다 일관되게 우수한 성과를 나타냅니다. 특히 zero-shot classification과 segmentation에서 강력한 성능을 발휘하며, 특정 영역에서는 성능이 9.07% 향상되기도 했습니다.



### SAda-Net: A Self-Supervised Adaptive Stereo Estimation CNN For Remote Sensing Image Data (https://arxiv.org/abs/2410.13500)
Comments:
          Will be presented at ICPR2024 in December 2024 in Kolkata, India

- **What's New**: 본 논문에서는 기존의 깊이 학습(deep learning) 기반 스테레오 추정(stereo estimation) 방법이 정확한 지상 진리(ground truth) 데이터에 의존하는 단점을 극복하기 위해, 지상 진리 데이터 없이도 훈련이 가능한 자가 지도(Self-supervised) CNN을 제안합니다.

- **Technical Details**: 제안된 방법은 단계별로 진행되며, 초기에 생성된 분산 맵(disparity map)은 부정확하고 잡음(noise)이 많습니다. 왼쪽-오른쪽 일관성 체크(left-right consistency check)를 사용하여 초기 의사 지상 진리(pseudo ground-truth)를 생성하고, 이를 기반으로 매 에포크(epoch)마다 모델을 업데이트합니다. 불일치 포인트의 합을 통해 네트워크의 수렴(convergence)을 추적합니다.

- **Performance Highlights**: 실제 복잡한 장면에서 좋은 성능을 나타내며, 약 495K의 경량화된 파라미터를 사용함으로써 상업적 하드웨어에서 효율적으로 사용 가능합니다.



### SemSim: Revisiting Weak-to-Strong Consistency from a Semantic Similarity Perspective for Semi-supervised Medical Image Segmentation (https://arxiv.org/abs/2410.13486)
- **What's New**: 이 논문은 Medical image segmentation에서의 새로운 반지도 학습(Semi-supervised learning)을 제안합니다. 여기서 제안된 SemSim 프레임워크는 기존의 FixMatch에서 발전하였으며, 주요한 두 가지 문제를 해결하기 위한 접근 방식을 포함하고 있습니다.

- **Technical Details**: 본 논문에서는 두 가지 주요 개념, 즉 intra-image semantic consistency와 cross-image semantic consistency를 바탕으로 한 SemSim 프레임워크를 제안합니다. Intra-image에서는 픽셀 간의 관계를 고려하여 예측을 정제하고, cross-image에서는 라벨이 있는 데이터와 라벨이 없는 데이터 간의 유사성을 활용하여 더 일치된 클래스 분포를 확립합니다. 또한, 이 과정에서 spatial-aware fusion module (SFM)을 통하여 다양한 스케일의 특징 정보를 조합하여 더 나은 성능을 이끌어냅니다.

- **Performance Highlights**: 다수의 공공 segmentation 벤치마크에 대한 실험 결과, SemSim은 기존의 최첨단 반지도 학습 방법들에 비해 일관된 개선을 보여줍니다.



### Day-Night Adaptation: An Innovative Source-free Adaptation Framework for Medical Image Segmentation (https://arxiv.org/abs/2410.13472)
Comments:
          10 pages, 4 figures, 6 tables

- **What's New**: 이 논문은 의료 영상의 분포 변화(distribution shifts) 문제를 해결하기 위한 새로운 접근 방식인 Day-Night Adaptation(DyNA) 프레임워크를 제안합니다. 이 프레임워크는 Source-free Domain Adaptation(SFDA)와 Test-Time Adaptation(TTA)을 통합하여 의료 데이터의 개인 정보 보호를 유지하면서도 모델을 효과적으로 적응시키는 방법을 소개합니다.

- **Technical Details**: DyNA 프레임워크는 낮과 밤의 적응 루프를 통해 사전 교육된 모델을 목표 도메인에 지속적으로 적응시키기 위한 전략을 갖추고 있습니다. 낮에는 모델의 파라미터를 고정하고 각 테스트 샘플에 대해 저주파(low-frequency) 프롬프트를 훈련하며, 메모리 뱅크를 구성하여 프롬프트 초기화를 도와줍니다. 밤에는 기존의 Teacher-Student self-training Paradigm에 글로벌 학생 모델을 통합하여 아울러 훈련 안정성을 유지합니다.

- **Performance Highlights**: DyNA는 두 가지 기준 의료 영상 분할 작업(폴립 분할 및 시신경원판/컵 분할)에서 여러 최신 TTA 및 SFDA 방법과 비교하여 뛰어난 성능을 보였습니다. 이로 인해 DyNA는 특히 임상 상황에서의 효용성이 입증되었습니다.



### SiamSeg: Self-Training with Contrastive Learning for Unsupervised Domain Adaptation in Remote Sensing (https://arxiv.org/abs/2410.13471)
- **What's New**: 본 논문은 원거리 감지(Remote Sensing) 이미지의 의미 세분화(Semantic Segmentation)에서 새로운 접근법인 SiamSeg를 제시합니다. 이는 대비 학습(Contrast Learning)을 최초로 도입하여 의미 정보 학습의 부족 문제를 해결하고 세분화 네트워크의 성능을 향상시킵니다.

- **Technical Details**: SiamSeg는 동일한 이미지의 다양한 데이터 증강을 통해 긍정적인 샘플 쌍을 생성하고, Siamese 네트워크를 사용하여 모델을 최적화합니다. 새로운 손실 함수가 제안되어, 대비 학습 손실을 포함하여 모델의 학습 효과성을 증대시킵니다.

- **Performance Highlights**: SiamSeg는 다양한 데이터 세트에서 새로운 최첨단 성능을 달성하며, 특히 원거리 감지 이미지의 세분화 과정에서 중요한 도메인 편향 문제를 효과적으로 해결합니다.



### Object Pose Estimation Using Implicit Representation For Transparent Objects (https://arxiv.org/abs/2410.13465)
- **What's New**: 이 논문은 Neural Radiance Field (NeRF)를 활용하여 투명 객체의 6D pose 추정을 위한 새로운 파이프라인을 제안합니다. 기존의 CAD 모델 대신 신경망 기반의 형상을 사용하여, 실제 장면을 보다 사실적으로 렌더링하고 비교할 수 있는 기법을 도입하였습니다.

- **Technical Details**: 이 접근법은 render-and-compare 방식을 기반으로 하며, NeRF를 활용하여 시각적 종속성을 고려한 고품질 가설을 렌더링합니다. 이 방법은 RGB 이미지 및 다중 시점의 이미지 집합을 활용하여 6D 포즈를 추정하며, 다양한 평가지표인 MSPD, MSSD, ADD 등을 사용하여 성능을 검증합니다.

- **Performance Highlights**: 제안된 NeRF 기반의 render-and-compare 방법은 투명 및 반사적인 가정용 객체에 대한 대규모 데이터셋에서 현재의 최첨단 결과를 초과하는 성과를 거두었습니다.



### Augmentation Policy Generation for Image Classification Using Large Language Models (https://arxiv.org/abs/2410.13453)
Comments:
          5 pages, 2 figures, 4 tables, submitted for consideration to the International Workshop on Computational Intelligence for Multimedia Understanding (IWCIM), ISCAS 2025

- **What's New**: 이 논문은 대형 언어 모델을 활용하여 데이터 세트에 맞춤화된 효율적인 데이터 증강 정책을 자동으로 생성하는 전략을 제안합니다. 기존의 많은 데이터 증강 기법이 특정 데이터 세트에 최적화되어 있었으나, 저자는 모든 데이터 유형에 적용 가능한 데이터 증강 파이프라인을 개발하여 모델의 성능을 개선하였습니다.

- **Technical Details**: 제안된 방법은 LLM (Large Language Model)을 사용하여 데이터 세트와 모델 아키텍처의 특정 특성에 맞춘 증강 정책을 생성합니다. 이 과정에 있어 LLM은 반복적으로 모델 성능 피드백과 상호작용하여 증강 정책을 정련해 나갑니다. 각 반복 과정은 데이터 설명, 모델 아키텍처, 목표 평가 지표와 증강 횟수를 기반으로 합니다.

- **Performance Highlights**: 의료 이미지 데이터 세트를 이용한 실험에서 제안된 방법은 기존의 최첨단 데이터 증강 기술을 초과하는 성과를 보였습니다. APTOS 2019 데이터 세트에서 ResNet18 모델이 0.8743의 검증 정확도를 기록하였으며, Gemini 및 ChatGPT 설정 모두에서 최고의 성능을 발휘했습니다.



### Temporal-Enhanced Multimodal Transformer for Referring Multi-Object Tracking and Segmentation (https://arxiv.org/abs/2410.13437)
- **What's New**: 이번 연구에서 새롭고 향상된 교차 모달 모델인 TenRMOT을 소개했습니다. 이 모델은 언어 표현을 활용하여 비디오 내에서 목표 객체를 추적하는 작업에 있어 시각적 및 언어적 정보를 결합합니다.

- **Technical Details**: TenRMOT은 Transformer 기반의 방법론으로, 인코딩 및 디코딩 단계에서 기능 융합을 진행합니다. 새로운 Interleaving Cross-modality Encoder(ICE)와 Query Update Module(QUM)을 도입하여 객체 추적의 정확도를 높입니다. 특히, 언어 기반 쿼리를 활용하여 메모리 기능을 적절히 탐색하며, 지속적인 쿼리 업데이트를 통해 객체의 일관성을 보장합니다.

- **Performance Highlights**: TenRMOT은 Ref-KITTI Segmentation 데이터셋에서 준수한 성능을 보여주며, 이는 각각 평균 10.7개의 마스크를 포함한 총 818개의 표현으로 이루어져 있습니다. 이 새로운 데이터셋은 기존 비디오 세그멘테이션 데이터셋보다 더 큰 도전 과제를 제공합니다.



### Performance of Gaussian Mixture Model Classifiers on Embedded Feature Spaces (https://arxiv.org/abs/2410.13421)
Comments:
          8 pages

- **What's New**: 이 논문은 CLIP 및 ImageBind와 같은 데이터 임베딩을 이용하여 다중 모달 데이터의 분석을 위한 성능을 분류에 대한 대안으로서 Gaussian Mixture Model (GMM) 기반 계층을 사용하는 것으로 평가합니다. 주요 기여는 이렇게 임베딩된 공간에서 GMM 분류 성능을 조사하고 GMM 기반 분류기를 제안하는 것입니다.

- **Technical Details**: Gaussian mixture models (GMMs)는 강력한 확률 밀도 함수로, 이미지 분류를 위한 데이터 임베딩으로 CLIP 및 ImageBind를 사용하여 SDGM(Sparse Discriminative Gaussian mixture)와 DGMMC(Deep Gaussian Mixture Model Classifier) 계층을 평가합니다. DGMMC는 이전 제안보다 더 적은 매개변수를 가진 새로운 분류기입니다.

- **Performance Highlights**: DGMMC는 이미지 데이터셋에서 CLIP과 ImageBind보다 높은 정확도를 이끌어내며, GMM에서 필요한 가우시안 구성 요소 수는 종종 하나(G=1)로 충분함을 발견했습니다. ImageBind는 이미지 데이터 분류에서 CLIP보다 더 좋은 성능을 제공합니다.



### RescueADI: Adaptive Disaster Interpretation in Remote Sensing Images with Autonomous Agents (https://arxiv.org/abs/2410.13384)
- **What's New**: 본 논문에서는 현재 재해 상황 해석에서의 한계를 극복하기 위해 Adaptive Disaster Interpretation (ADI)라는 새로운 태스크를 소개합니다. ADI는 다수의 해석 태스크를 연계하여 재해 장면에 대한 종합적인 분석을 제공합니다.

- **Technical Details**: 작가는 RescueADI라는 새로운 데이터셋을 발표하였습니다. 이 데이터셋은 고해상도 원격 탐지 이미지와 함께 계획, 인식, 식별을 위한 주석을 포함하고 있으며, 9종의 요청 유형을 포함한 4,044개의 RSIs, 16,949개의 의미 마스크, 14,483개의 객체 경계 박스를 포함합니다. 제안된 새로운 해석 방법은 대형 언어 모델(LLMs)을 사용하여 자율 에이전트를 통해 태스크를 계획하고 실행합니다.

- **Performance Highlights**: RescueADI 데이터셋에 대한 실험 결과, 제안된 방법이 기존 시각적 질문 응답(VQA) 방법보다 9% 더 높은 정확도를 달성하여 전통적인 재해 해석 접근 방식에 비해 우수하다는 것을 보여줍니다.



### Railway LiDAR semantic segmentation based on intelligent semi-automated data annotation (https://arxiv.org/abs/2410.13383)
Comments:
          This article has been accepted for publication in the IEEE VTC Fall 2024

- **What's New**: 이 논문은 자동화된 기차의 환경 인식을 위한 3D LiDAR 의미(segmentation) 분할 방법을 새롭게 제안합니다. 특히, 카메라 이미지와 LiDAR 스캔을 결합하여 점별 3D 의미 분할(point-wise 3D semantic segmentation)을 수행하는 아키텍처인 2DPass 네트워크를 활용합니다.

- **Technical Details**: 이 연구는 데이터셋 준비, 라벨링, 모델 훈련의 세 가지 단계로 이루어집니다. 데이터 손실을 줄이기 위해 Deeplabv3+ 네트워크를 사용한 이미지 의미(segmentation) 네트워크로부터 라벨을 추출하고, 수동으로 수정된 52개의 정밀 라벨로 구성된 데이터셋을 생성합니다. 그 후, 최첨단 LiDAR 의미(segmentation) 네트워크인 2DPass를 훈련하여 총 9개의 클래스에 대해 평균 IoU(Intersection over Union) 71.48%의 성능을 달성합니다.

- **Performance Highlights**: 제안된 네트워크는 작은 크기의 라벨이 붙은 스캔에서 효과적으로 훈련되어, 71.48%의 높은 평균 IoU 성능을 보여줍니다. 이는 기차의 안전한 운전 및 장애물 감지에 필수적인 정확한 환경 인식 기술로 평가됩니다.



### Accurate Checkerboard Corner Detection under Defoucs (https://arxiv.org/abs/2410.13371)
- **What's New**: 본 논문은 체커보드 코너 검출을 위한 새로운 서브픽셀 개선 방법을 제안하며, 기존의 대칭 기반 방법의 한계를 보완하여 가시광선 카메라에서 정확성을 크게 향상시킵니다.

- **Technical Details**: 우리는 대칭 기반의 서브픽셀 정밀도 개선 접근 방식을 소개하며, 불명확한 이미지와 초점 흐림(defocus) 영향을 고려한 단순화된 목적 함수를 도출합니다. 이 방법은 계산 시간을 줄이고 과적합(overfitting) 위험을 완화하는 데 기여합니다.

- **Performance Highlights**: 새로운 방법은 기존 기술보다 가시광선 카메라 캘리브레이션에서 상당한 정확성 개선을 보여주었으며, 특히 기존 방법보다 1/2121/21 / 2 및 1/4141/41 / 4로 재투영 오류를 줄이는 결과를 기록했습니다.



### MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models (https://arxiv.org/abs/2410.13370)
Comments:
          Project page: this https URL

- **What's New**: 이번 논문에서는 텍스트-이미지(T2I) 모델의 개인화 작업에서 구성 요소를 제어할 수 있는 새로운 접근법을 제시합니다. 사용자가 특정 시각적 개념의 개별 요소를 재구성할 수 있도록 하여 더 정밀한 커스터마이징을 가능하게 합니다. 

- **Technical Details**: 새로운 프레임워크인 MagicTailor를 통해 Dynamic Masked Degradation (DM-Deg)과 Dual-Stream Balancing (DS-Bal)을 활용하여 개인화 과정에서의 의미적 오염(semantic pollution)을 줄이고, 의미적 불균형(semantic imbalance)을 관리합니다. 이 프레임워크는 T2I 모델을 동적으로 조정하여 개인화된 개념을 정확하게 반영합니다.

- **Performance Highlights**: MagicTailor는 실험을 통해 구성 요소 제어가 가능한 개인화 작업에서 최첨단(SOTA) 성과를 달성하였으며, 다양한 추가 응용 가능성을 보여줍니다.



### Remember, Retrieve and Generate: Understanding Infinite Visual Concepts as Your Personalized Assistan (https://arxiv.org/abs/2410.13360)
- **What's New**: 본 논문에서는 Retrieval Augmented Personalization (RAP) 프레임워크를 소개하여 다중 모드 대형 언어 모델(MLLMs)의 개인화를 가능하게 합니다. RAP는 일반 MLLM을 개인화된 어시스턴트로 전환하는 세 가지 주요 단계로 구성됩니다: 기억(Recall), 검색(Retrieve), 생성(Generate).

- **Technical Details**: RAP는 사용자 관련 정보(예: 이름, 아바타 등)를 저장하는 키-값 데이터베이스를 설계합니다. 사용자가 대화를 시작할 때, RAP는 다중 모드 검색기를 통해 데이터베이스에서 관련 정보를 검색하고, 이를 MLLM에 입력하여 개인화된 지식 강화 응답을 생성합니다. 추가로 생성 품질 향상을 위해 데이터 수집 파이프라인을 개발하고 개인화된 훈련을 위한 전문적인 데이터셋을 생성합니다.

- **Performance Highlights**: RAP-MLLMs는 개인화된 이미지 캡션 작성, 질문 응답 및 시각적 인식과 같은 다양한 작업에서 뛰어난 유연성과 생성 품질을 보여줍니다. 모델들은 무한한 시각적 개념에 대해 일반화 능력을 발휘하며, 사용자 관련 정보를 효과적으로 처리하여 개인화된 출력을 제공합니다.



### Self-Supervised Scene Flow Estimation with Point-Voxel Fusion and Surface Representation (https://arxiv.org/abs/2410.13355)
Comments:
          The paper is under consideration at 2025 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)

- **What's New**: 이 논문에서는 기존의 포인트 기반 방식과 복셀 기반 기법의 단점을 보완하기 위해 포인트-복셀 융합(Point-Voxel Fusion) 방법을 제안합니다. 이 방법은 희소 격자 주의(Sparse Grid Attention) 및 이동창(Dynamic Windowing) 전략을 활용하여 장거리 의존성을 캡처하면서 또한 세부적인 특성을 추출합니다.

- **Technical Details**: 포인트-복셀 융합 아키텍처는 포인트 브랜치가 한층 정교한 특징을 추출하고, 복셀 브랜치는 장거리 의존성을 포착합니다. Umbrella Surface Feature Extraction (USFE) 모듈을 통해 복잡한 3D 객체의 지역 표면 정보를 명시적으로 인코딩하고, 이를 통해 기하학적 구조를 정밀하게 유지합니다.

- **Performance Highlights**: FlyingThings3D 및 KITTI 데이터셋에서 실험을 거쳤으며, 이번 방법은 모든 다른 자가 지도 방법들을 초과하며, 완전 감독 방법에 비해서도 매우 경쟁력 있는 결과를 달성했습니다. 특히 KITTIo와 KITTIs 데이터셋에서 EPE가 각각 8.51% 및 10.52% 감소했습니다.



### GlossyGS: Inverse Rendering of Glossy Objects with 3D Gaussian Splatting (https://arxiv.org/abs/2410.13349)
- **What's New**: 본 연구에서는 GlossyGS라는 혁신적인 3D-GS 기반의 역 렌더링 프레임워크를 소개합니다. 이 프레임워크는 재료(priors) 통합을 통해 반짝이는(glossy) 객체의 기하학(geometry)과 재료(materials)를 정확하게 재구성하는 것을 목표로 합니다.

- **Technical Details**: GlossyGS는 micro-facet geometry segmentation prior를 사용하여 본래의 모호성을 줄이고 기하학과 재료의 분해를 개선합니다. 또한, 반사 표면의 법선(normal distribution) 분포를 더 정확하게 시뮬레이션하기 위해 normal map prefiltering 전략을 도입하였습니다. 이를 통해 반짝이는 객체를 묘사하기 위해 명시적(explicit) 및 암시적(implicit) 방법을 사용하는 하이브리드 기하학 및 재료 표현을 구현합니다.

- **Performance Highlights**: 정량적 분석과 정성적 시각화를 통해 제안된 방법이 고충실도(high-fidelity) 기하학과 재료를 재구성하는 데 효과적이며, 최신 기술(state-of-the-art)과 비교할 때 우수한 성능을 발휘한다는 것을 보여주었습니다.



### Inadequate contrast ratio of road markings as an indicator for ADAS failur (https://arxiv.org/abs/2410.13320)
Comments:
          IRF World Congress 2024

- **What's New**: 도로 markings는 인간 운전자는 물론이고 ADAS(Advanced Driver Assistance Systems)와 자율 주행에 사용되는 기계 비전 기술에도 필수적인 도로 안전 기능으로 보고되고 있습니다. 이 연구에서는 여러 가시성 조건에서 카메라 기반 ADAS의 테스트 중 발생한 경로 계획의 심각한 실패를 기록했습니다.

- **Technical Details**: 본 연구는 다양한 가시성 조건(낮, 밤, 비, 눈부심)에서 ADAS의 도로 marking 인식 성능을 분석하였습니다. Type II 도로 marking(구조화된 marking)은 Type I 도로 marking(평평한 선)보다 저조한 가시성 조건에서 일관되게 더 나은 신뢰성을 보였습니다. 도로 marking의 대비 비율(contrast ratio)은 ADAS의 교통 차선 인식에 있어 중요한 요소로 분석되었습니다. 가장 높은 대비 비율은 밤 시간대, 방해 요소 없이 측정되었으며, Type II가 Type I보다 0.1의 통계적으로 유의미한 차이를 보였습니다.

- **Performance Highlights**: 주목할 만한 것은, ADAS의 불충분한 차선 인식은 도로 marking의 매우 낮은 대비 비율과 관련이 있었다는 점입니다. 비 또는 젖은 도로에서 대비 비율은 저하되었으며, Type II marking이 Type I보다 유의미하게 높은 대비 비율을 유지했습니다. 그러나 특정 최소 대비 비율 값은 ADAS 알고리즘의 복잡성으로 인해 찾을 수 없었습니다.



### Enhancing Dataset Distillation via Label Inconsistency Elimination and Learning Pattern Refinemen (https://arxiv.org/abs/2410.13311)
Comments:
          ECCV 2024 Dataset Distillation Challenge

- **What's New**: 이번 연구는 ECCV-2024 데이터 증류 챌린지에서 1위를 차지한 M-DATM(Modified Difficulty-Aligned Trajectory Matching) 기법을 제안하고, 고유의 버전의 DATM을 개선하여 라벨 불일치와 레이트(Late) 궤적 정보 학습의 어려움을 극복하는 방법을 정리합니다.

- **Technical Details**: M-DATM은 DATM에서 두 가지 중요한 수정을 소개합니다: (1) 소프트 라벨 기법 제거 - 이는 라벨 불일치를 줄이고, 평가 시의 일관성을 보장합니다; (2) 일치 범위 조정 - Tiny ImageNet에서의 어려운 패턴 학습 문제를 해결하기 위해 학습 패턴의 난이도를 낮추어 주는 것입니다. M-DATM을 통해 CIFAR-100과 Tiny ImageNet에서 각각 0.4061과 0.1831의 정확도를 기록하며, IPC 트랙에서 1위를 달성했습니다.

- **Performance Highlights**: M-DATM은 ECCV-2024 데이터 증류 챌린지에서 IPC 트랙 1위로 선정되었으며, 이는 데이터 효율성을 높이고, 향후 데이터 증류 연구의 강력한 기준이 될 것입니다.



### LESS: Label-Efficient and Single-Stage Referring 3D Segmentation (https://arxiv.org/abs/2410.13294)
- **What's New**: 본 연구에서는 Referring 3D Segmentation의 새로운 프로세스를 제안하며, 이를 LESS(Label-Efficient and Single-Stage)라는 이름으로 부릅니다. 기존의 2단계 방법 대신, 이 모델은 효율적인 binary mask만으로 감독 받아 단일 단계에서 작업을 수행합니다.

- **Technical Details**: LESS는 Point-Word Cross-Modal Alignment 모듈을 통해 포인트와 단어의 정밀한 특성을 정렬하고, Query Mask Predictor 모듈과 Query-Sentence Alignment 모듈을 통해 마스크와 쿼리 간의 거친 정렬을 수행합니다. 특히, area regularization loss와 point-to-point contrastive loss를 통해 복잡한 객체 배경의 간섭을 제거하는 방법을 고안했습니다.

- **Performance Highlights**: LESS는 ScanRefer 데이터셋에서 기존의 방법보다 약 3.7% mIoU의 성능 향상을 보이며 최첨단 성과를 달성했습니다. 이는 binary label만으로도 가능한 혁신적인 접근임을 보여줍니다.



### Composing Novel Classes: A Concept-Driven Approach to Generalized Category Discovery (https://arxiv.org/abs/2410.13285)
Comments:
          Underreview. The first two authors contribute equally

- **What's New**: 본 논문에서는 라벨이 없는 데이터셋에서 새로운 클래스를 발견하는 일반화된 범주 발견(Generalized Category Discovery, GCD) 문제를 다룹니다. 이미 알려진 클래스의 지식을 활용하여 새로운 클래스를 발견하기 위한 새로운 개념 학습 프레임워크인 ConceptGCD를 제안합니다. 이 방법은 두 가지 유형의 개념—파생 가능한(derivable) 개념과 파생 불가능한(underivable) 개념으로 분류하고, 단계별 학습 방식을 채택하여 각 개념을 별도로 학습합니다.

- **Technical Details**: ConceptGCD 프레임워크는 다음 세 가지 핵심 단계로 구성됩니다: 1) 알려진 클래스 개념 학습: 라벨이 있는 알려진 클래스 데이터를 통해 딥 네트워크 모델을 훈련하여 개념을 얻습니다. 이를 위해 개념 공분산 손실(concept covariance loss)을 도입하여 다양한 개념 간 독립성을 촉진합니다. 2) 파생 가능한 개념 생성: 알려진 클래스 개념을 기반으로 선형 층과 ReLU 층을 활용하여 파생 가능한 개념을 생성합니다. 3) 파생 불가능한 개념 학습: 마지막 단계에서 파생 불가능한 개념을 학습하며, 이전에 생성된 개념을 보존합니다. 이를 위해 처음 선형 층의 차원을 확장하고, 특성 공간(feature space)에서 대조 손실(contrastive loss)로 학습합니다.

- **Performance Highlights**: 다양한 벤치마크 데이터셋에서 진행한 실험은 ConceptGCD가 기존 최첨단 방법들에 비해 향상된 성능을 보임을 보여줍니다. 특히, 제안하는 공분산 손실과 개념 점수 정규화(concept score normalization) 기술이 개념 학습에 기여한 바가 큽니다.



### Hybrid bundle-adjusting 3D Gaussians for view consistent rendering with pose optimization (https://arxiv.org/abs/2410.13280)
Comments:
          Photonics Asia 2024

- **What's New**: 본 논문은 불완전한 카메라 자세에서 시각적으로 일관된 새로운 시점을 렌더링하는 도전 과제를 해결하기 위한 하이브리드 번들 조정 3D 가우시안 모델을 소개합니다.

- **Technical Details**: 이 모델은 이미지 기반 및 신경 3D 표현을 조합하여 정면 장면에서 일관된 이미지를 생성하고 카메라 자세를 최적화합니다. 주요 기술 구성 요소는 다음과 같습니다: 1) 포인트 클라우드를 복셀화하여 신경 3D 앵커 기능을 추출하고, 2) 근처 뷰의 이미지 기능을 활용하여 렌더링 품질을 향상시키며, 3) 초기 카메라 자세를 조정하기 위해 조정된 번들 조정 기법을 사용합니다.

- **Performance Highlights**: 실제 및 합성 데이터셋에서의 광범위한 실험을 통해 모델이 카메라 자세 불일치를 해결하면서 신경 장면 표현을 효과적으로 최적화할 수 있음을 보여줍니다.



### Inductive Gradient Adjustment For Spectral Bias In Implicit Neural Representations (https://arxiv.org/abs/2410.13271)
Comments:
          28 pages, 12 figures

- **What's New**: 이 논문은 Implicit Neural Representations (INRs)에서의 spectral bias 문제를 해결하기 위해, Multi-layer Perceptrons (MLPs)의 선형 역학 모델을 탐구하고 empirical Neural Tangent Kernel (eNTK) 행렬을 기반으로 inductive gradient adjustment (IGA) 방법을 제안합니다.

- **Technical Details**: 이 연구는 MLPs의 linear dynamics 모델을 이용하여 empirical NTK (eNTK) 행렬을 통해 spectral bias와 training dynamics 사이의 관계를 이론적으로 규명합니다. 제안하는 IGA 방법은 대량의 데이터 포인트에 대해 eNTK 기반 gradient 변환 행렬의 inductive 일반화를 통해 spectral bias를 개선할 수 있습니다.

- **Performance Highlights**: 실험 결과는 제안한 방법이 기존의 training dynamics 조정 방법들보다 더 나은 성능을 발휘하며, INRs의 퀄리티를 향상시켜 고해상도 텍스처와 뚜렷한 변별력을 선보임을 보여줍니다.



### Fundus to Fluorescein Angiography Video Generation as a Retinal Generative Foundation Mod (https://arxiv.org/abs/2410.13242)
- **What's New**: Fundus2Video는 단일 CF 이미지에서 동적 FFA 비디오를 생성하는 자가 회귀 생성적 적대 신경망(GAN) 모델로, 기존의 정적 이미지 생성 방법의 한계를 극복합니다.

- **Technical Details**: 이 모델은 동적 FFA 비디오 생성에서 FVD(Frechet Video Distance) 1497.12, PSNR(Peak Signal-to-Noise Ratio) 11.77을 기록하며, 생성된 비디오의 신뢰성은 임상 전문가들에 의해 검증되었습니다. 또한, 모델의 생성기는 혈관 세분화(blood vessel segmentation), 망막 질병 진단(retinal disease diagnosis), 전신 질병 예측(systemic disease prediction) 및 다중 모달 검색(multimodal retrieval)에서 탁월한 전이 학습 성능을 보여줍니다.

- **Performance Highlights**: Fundus2Video는 제로샷(zero-shot) 및 소샷(few-shot) 가능성이 뛰어나며, 비침습적(non-invasive)인 FFA 검사의 강력한 대안으로 자리매김하게 됩니다.



### Latent Image and Video Resolution Prediction using Convolutional Neural Networks (https://arxiv.org/abs/2410.13227)
Comments:
          Submitted in ICIP conference

- **What's New**: 이 논문은 Video Quality Assessment (VQA) 문헌에서 거의 주목받지 않은 latent resolution prediction 문제를 소개합니다. 이 문제는 이미지나 비디오가 원래 해상도보다 높은 해상도로 업스케일된 경우 발생합니다. 논문은 문제를 형식화하고 훈련 및 평가를 위한 데이터셋을 구축하며, 이 문제를 해결하기 위해 두 가지 Convolutional Neural Network (CNN) 알고리즘을 포함한 머신러닝 알고리즘을 소개합니다.

- **Technical Details**: 논문에서 제안하는 두 가지 CNN 기반 방법은 이미지의 질감이 있는 부분에 초점을 맞추지만, 이미지를 처리하는 방식에는 차이가 있습니다. 첫 번째 방법은 이미지에서 관심 지역에서 추출한 여러 패치를 사용하는 반면, 두 번째 방법은 전체 이미지를 입력으로 받아 출력 맵을 생성합니다. 비트맵을 통해 관심 점의 위치를 추적하고, 신뢰할 수 있는 품질 예측을 추출합니다. 이는 144p에서 1080p까지 다양한 latent resolution을 가진 이미지와 비디오로 구성된 커스텀 데이터셋에서 실험하여 예측합니다.

- **Performance Highlights**: 실험 결과, 제안한 방법들이 약 95%의 정확도로 이미지/비디오의 latent resolution을 예측할 수 있음을 보여줍니다.



### UniG: Modelling Unitary 3D Gaussians for View-consistent 3D Reconstruction (https://arxiv.org/abs/2410.13195)
- **What's New**: 이 논문에서는 UniG라는 새로운 3D 재구성 및 새로운 보기 합성 모델을 제안합니다. 이 모델은 드문 이미지로부터 높은 신뢰도의 3D Gaussian 표현을 생성합니다. 기존의 3D Gaussian 기반 방법은 각 보기당 Gaussian을 독립적으로 추정하였으나, 이는 보기 간 불일치 문제를 야기합니다. UniG는 DETR(Distance-Equivalent Transformation Representation) 유사 구조를 통해 이 문제를 해결합니다.

- **Technical Details**: UniG는 다수의 입력 이미지에서 다중 보기 교차 주의(Multi-view Cross-Attention, MVDFA)를 통해 3D Gaussian 쿼리를 업데이트합니다. 각 3D Gaussian은 콘텐츠와 위치(3D Gaussian의 중심) 부분으로 구성되며, 변형 가능 Transformer 인코더-디코더 구조에서 반복적으로 정제됩니다. 또한, 저렴한 메모리 요구 사항을 갖춘 3D Spatial Efficient Self-Attention (SESA) 방식을 사용하여 처리 효율성을 높입니다.

- **Performance Highlights**: UniG는 Objaverse에서 학습하고 GSO 벤치마크에서 테스트할 때 PSNR을 4.2 dB 개선하며, 기존 방법에 비해 정량적 및 정성적으로 우수한 성능을 보입니다.



### FAMSeC: A Few-shot-sample-based General AI-generated Image Detection Method (https://arxiv.org/abs/2410.13156)
- **What's New**: 이번 논문에서는 FAMSeC라는 새로운 AI 생성 이미지 탐지 방법을 제안합니다. 이 방법은 LoRA 기반의 Forgery Awareness Module과 Semantic feature-guided Contrastive learning strategy를 기반으로 하여 적은 샘플로도 일반화 능력을 유지하면서 효과적으로 학습합니다.

- **Technical Details**: FAMSeC는 CLIP:ViT 기능을 활용하여 AI 생성 이미지 탐지의 일반화 능력을 강화합니다. 주요 구성 요소인 Forgery Awareness Module (FAM)은 LoRA를 기반으로 하여 과적합 문제를 방지하면서도 적은 수의 샘플로 유용한 특성을 학습합니다. 또한, Semantic feature-guided Contrastive learning strategy (SeC)는 FAM의 학습을 더욱 향상시킵니다.

- **Performance Highlights**: FAMSeC는 ProGAN 데이터셋에서 4000개의 진짜 및 가짜 이미지로 훈련되었으며, 평균 분류 정확도는 95.22%에 도달했습니다. 이는 기존의 최첨단 방법에 비해 14.55% 높은 정확도를 기록하며, 단 0.56%의 훈련 샘플로 이루어졌습니다.



### Unlocking the Capabilities of Masked Generative Models for Image Synthesis via Self-Guidanc (https://arxiv.org/abs/2410.13136)
Comments:
          NeurIPS 2024. Code is available at: this https URL

- **What's New**: 본 논문에서는 Masked Generative Models (MGMs)의 성능을 개선하기 위해 일반화된 가이던스 (guidance) 공식화 및 자기 가이던스 샘플링 (self-guidance sampling) 방법을 제안합니다. 이로 인해 MGMs는 높은 품질과 다양성을 동시에 달성할 수 있게 되었습니다.

- **Technical Details**: MGMs는 [MASK] 토큰을 사용하여 입력 토큰을 점진적으로 마스킹하는 방식으로 작동합니다. 이 논문에서는 semantic smoothing을 위한 보조 작업 (auxiliary task)을 도입하여 고온 샘플링 (high-temperature sampling)을 통해 품질과 다양성을 동시에 향상시키는 방법을 설명합니다.

- **Performance Highlights**: 제안된 방법은 기존 MGMs 샘플링 방법들보다 더 효율적인 훈련 및 샘플링 비용으로 상대적으로 우수한 품질-다양성 균형을 달성하였으며, 10회의 미세 조정으로 샘플 품질을 효과적으로 개선했습니다.



### Boosting Imperceptibility of Stable Diffusion-based Adversarial Examples Generation with Momentum (https://arxiv.org/abs/2410.13122)
Comments:
          10 pages, 12 figures. To be published in IEEE TPS 2024 Proceedings. Code available on GitHub: this https URL

- **What's New**: 본 논문은 네트워크 분류기를 효과적으로 혼란시킬 수 있는 적대적 예제를 생성하기 위한 새로운 프레임워크인 Stable Diffusion 기반의 Momentum Integrated Adversarial Examples (SD-MIAE)를 제안합니다. 이 방법은 고유한 클래스 라벨에 대한 시맨틱 유사성을 유지하면서 시각적으로 인지 불가능한 적대적 예제를 생성하는 데 중점을 둡니다.

- **Technical Details**: SD-MIAE는 두 가지 단계로 구성됩니다: (1) 초기 적대적 최적화 단계에서 토큰 임베딩을 수정하여 자연스러운 이미지를 생성하고, (2) 모멘텀 기반의 최적화 단계에서 적대적 perturbation을 정제합니다. 모멘텀을 도입함으로써, 최적화 과정에서의 안정성을 높이고, 고차원 잠재 공간에서의 이미지 생성을 통해 자연스러운 외관을 유지합니다.

- **Performance Highlights**: SD-MIAE는 79%의 높은 오분류율을 달성하여 최신 기법에 비해 35% 개선된 성능을 보이며, 적대적 perturbations의 비가시성과 원래 클래스 라벨에 대한 시맨틱 유사성을 유지하는 데 기여합니다.



### Trust but Verify: Programmatic VLM Evaluation in the Wild (https://arxiv.org/abs/2410.13121)
- **What's New**: 본 논문에서는 프로그램 기반 VLM 평가(Programmatic VLM Evaluation, PROVE)라는 새로운 벤치마크 패러다임을 제안합니다. 이 방법은 비주얼 컨텐츠에 대한 오픈 엔디드 질의에 대한 VLM의 응답을 신뢰성 있게 평가할 수 있도록 설계되었습니다.

- **Technical Details**: PROVE는 하이퍼 세부 이미지 캡션으로부터 구성된 고충실도의 씬 그래프(scene graph) 표현을 기반으로 하며, 이를 통해 다양한 질문-응답(QA) 쌍을 생성하고, 각 QA 쌍의 검증을 위한 프로그램을 함께 생성합니다. 이후, 이 프로그램을 통해 각각의 QA 쌍의 정확성과 기초를 검증하면서 10,500개의 시각적으로 기초가 있는 QA 쌍을 포함하는 데이터셋을 구축합니다.

- **Performance Highlights**: BENCHMARK한 결과, 대부분의 기존 VLM들은 유용성과 진실성 사이의 균형을 잘 맞추지 못함을 발견했습니다. 도출된 결과는 최근 '더 나은' VLM 교육의 진전이 유용성 향상으로 이어지지만 진실성 향상에는 큰 도움을 주지 않는다는 것을 보여줍니다.



### Task Consistent Prototype Learning for Incremental Few-shot Semantic Segmentation (https://arxiv.org/abs/2410.13094)
Comments:
          conference

- **What's New**: 이번 연구는 Incremental Few-Shot Semantic Segmentation (iFSS) 문제에 대한 새로운 접근 방식을 제안합니다. 이는 모델이 몇 개의 주석된 예제만으로 새로운 클래스에 대한 세분화 능력을 지속적으로 확장할 수 있도록 하는 것을 목표로 합니다.

- **Technical Details**: 연구는 메타 학습(meta-learning)을 기반으로 한 프로토타입 접근 방식을 사용하여, 기존 지식을 보존하면서 신속하게 적응할 수 있도록 모델을 유도합니다. 특히, 베이스 세션 동안의 증강 평가 프로토콜을 모방하여 가상의 증분 작업 시퀀스를 샘플링하여 메타 목표를 설정, 신속한 적응을 가능케 합니다. 프로토타입 공간 재분배 학습(Prototype Space Redistribution Learning, PSRL)을 통해 클래스 프로토타입을 동적으로 업데이트하여 최적의 프로토타입 경계를 설정합니다.

- **Performance Highlights**: PASCAL 및 COCO 벤치마크를 기반으로 한 iFSS 데이터셋에 대한 광범위한 실험 결과, 제안된 방법이 여러 경쟁 기법에 비해 월등한 성능을 보임을 확인했습니다.



### A low complexity contextual stacked ensemble-learning approach for pedestrian intent prediction (https://arxiv.org/abs/2410.13039)
- **What's New**: 이 논문은 보행자의 횡단 의도를 예측하기 위한 새로운 저복잡도의 앙상블 학습 접근법인 Contextual Stacked Ensemble-learning (CSE) 방법을 제안합니다. 이 방법은 보행자의 이미지를 스켈레톤화(skeleton-ization)하여 데이터 용량을 감소시키고, 맥락 정보(contextual information)를 추가하여 예측 성능을 향상시킵니다.

- **Technical Details**: CSE 방법은 보행자의 이미지를 17개 키포인트로 압축한 후, 스택 앙상블 학습(stacked ensemble learning)을 통해 맥락 정보를 반영합니다. 이 방법은 pedestrian intent prediction (PIP) 문제를 비디오 클립에서 보행자가 횡단하는지 여부를 예측하는 문제로 형성하였으며, 99.7%의 계산 복잡성 감소를 달성합니다.

- **Performance Highlights**: 실험 결과는 기존의 최첨단 방법과 유사한 PIP 예측 성능을 보였으며, FLOPS와 학습 가능한 매개변수에서 각각 99.99%와 99.7%의 감소를 기록했습니다. 이 연구는 IEEE Intelligent Transportation Systems Society (ITSS) 학생 대회에서 보행자 행동 예측 부문 1등 상을 수상했습니다.



### Sensitivity of Generative VLMs to Semantically and Lexically Altered Prompts (https://arxiv.org/abs/2410.13030)
- **What's New**: 본 논문은 generative vision-language 모델(VLM)의 프롬프트에서의 어휘적 및 의미적 변화에 대한 민감성을 평가합니다. SugarCrepe++ 데이터셋을 사용하여 이러한 모델들이 프롬프트의 사소한 변화에 어떤 영향을 받는지를 분석합니다.

- **Technical Details**: 이 연구는 BLIP, BakLLaVA 및 GPT-4o와 같은 generative VLMs의 어휘 및 의미 변화 이해 능력을 평가합니다. SugarCrepe++ 데이터셋에서는 두 개의 긍정적인 캡션(P1, P2)과 하나의 부정적인 캡션(N)을 포함하여, 어휘적으로 다르지만 의미적으로 유사한 캡션을 제공합니다.

- **Performance Highlights**: 실험 결과, BakLLaVA와 GPT-4o 모두 입력 프롬프트의 약간의 변화에 대해 높은 민감성을 보였으며, 동일한 프롬프트에서 옵션의 순서를 변경하는 것만으로도 성능에 큰 차이를 보였습니다. 또한, 서로 다른 VLMs 간의 일관성이 부족하여 결과의 일관성을 높이기 위한 추가 연구가 필요함을 보여줍니다.



### Geometric Trajectory Diffusion Models (https://arxiv.org/abs/2410.13027)
Comments:
          Published at NeurIPS 2024. 29 pages, 10 figures

- **What's New**: 이번 연구에서는 3D 기하학적 궤적을 모델링하기 위해 최초의 diffusion model인 GeoTDM(Geometric Trajectory Diffusion Model)을 제안합니다. 이는 기존의 정적 구조에 대응하는 방법을 넘어, 물리적 시스템이 본질적으로 동적이라는 사실을 반영합니다.

- **Technical Details**: GeoTDM은 물리적 대칭과 동역학의 시간적 상관 관계를 포함한 복잡한 공간 상호작용을 포착해야 하는 도전에 직면했습니다. 이에 SE(3)-equivariant spatial convolution과 temporal attention을 활용한 새로운 전이 커널을 개발하여 적절한 대칭을 가진 밀도를 생성합니다. 또한, 조건부 생성을 위한 표현력 있는 궤적 분포를 유도하기 위해 일반화된 학습 가능한 기하학적 사전(geometric prior)을 도입했습니다.

- **Performance Highlights**: 다양한 시나리오에서 진행한 실험 결과, GeoTDM은 물리적 시뮬레이션, 분자 동역학, 보행자 운동을 포함하여 비조건부 및 조건부 생성을 통해 사실적인 기하 궤적을 생성할 수 있으며, 품질이显著 향상됨을 보여주었습니다.



### Interpreting and Analyzing CLIP's Zero-Shot Image Classification via Mutual Knowledg (https://arxiv.org/abs/2410.13016)
Comments:
          Accepted to NeurIPS 2024

- **What's New**: 이 연구는 Contrastive Language-Image Pretraining (CLIP) 모델의 이미지 분류 해석 방식을 새로운 관점에서 접근합니다. 특히, 이미지와 텍스트 간의 상호 지식(mutual knowledge)을 기반으로 CLIP 모델이 공유하는 임베딩 공간에서의 유사성 및 차이를 어떻게 이해할 수 있는지를 분석합니다.

- **Technical Details**: CLIP 모델은 시각적 인코더와 텍스트 인코더로 구성되어 있으며, 두 인코더는 양의 이미지-텍스트 쌍을 임베딩 공간에서 서로 가깝게 배치하도록 훈련됩니다. 연구에서는 Mutual Information (MI) 분석을 통해 두 인코더 간의 공통 개념을 해석하고, 13개의 CLIP 모델을 사용해 구조, 크기 및 사전 훈련 데이터에 따라 분석합니다. 이 과정에서 이 논문은 비디오와 텍스트 개념을 위한 설명적 접근 방식을 제안합니다.

- **Performance Highlights**: 논문에서 제안하는 방법은 CLIP 모델의 제로샷(zero-shot) 분류 정확도를 3.75% 향상시키며, CLIP 모델이 예측할 때 어떤 공통점을 학습하는지를 시각적으로 설명할 수 있습니다. 또한, 다양한 모델의 크기, 사전 훈련 데이터 및 정확도와의 관계를 탐구할 수 있습니다.



### Explainable Binary Classification of Separable Shape Ensembles (https://arxiv.org/abs/2410.12994)
Comments:
          20 pages, 7 figures

- **What's New**: 이 논문에서는 재료 과학에서 미세 구조의 곡선 경계(curve boundaries)를 효과적으로 분석하기 위해 새로운 패턴 인식 기술을 제안합니다. 전자 후방 산란 회절(electron backscatter diffraction, EBSD) 기술을 사용하여 측정된 미세 구조의 영상 세분화(image segmentation) 데이터를 활용하여 곡선 집합의 차이를 정량화하기 위한 방법론을 개발했습니다.

- **Technical Details**: 주요 기법으로는 곡선 기능에 대한 강체 불변성(rigid-invariance) 오르토노말 분해(orthonormal decomposition)를 사용하여 곡선의 스케일 변화(scale variations)와 비선형 변형(complementary features of undulation)을 분리합니다. 분리된 형태 텐서를 이용해 두 개의 EBSD 앙상블의 형태 분포(shape distributions)를 구별하는 데 사용했습니다. 또한 제품 최대 평균 차이(maximum mean discrepancy, MMD)를 활용하여 레이블이 없는 데이터에서도 신뢰할 수 있는 분류를 지원합니다.

- **Performance Highlights**: 실험 결과, 제안하는 방법은 i) 통계적 거부에 민감하지 않음을 실증하고, ii) 인간의 관측과 일치하는 결론을 도출하며, iii) 인간의 눈으로는 감지할 수 없는 차이까지 검출하는 데 성공했습니다. iv) 또한 오류 측정값을 감지할 수 있는 능력을 보였습니다.



### Super-resolving Real-world Image Illumination Enhancement: A New Dataset and A Conditional Diffusion Mod (https://arxiv.org/abs/2410.12961)
Comments:
          Code and dataset at this https URL

- **What's New**: 본 논문에서는 저조도 환경에서 이미지 품질 향상을 위한 새로운 SRRIIE 데이터셋과 효율적인 conditional diffusion probabilistic model을 제안합니다. 이 데이터셋은 4800개의 저해상도-고해상도 이미지 쌍으로 구성되어 있으며 실세계 이미지를 모사한 degradation을 모델링할 수 있도록 설계되었습니다.

- **Technical Details**: SRRIIE 데이터셋은 -6 EV에서 0 EV까지의 노출 레벨과 ISO 50에서 12800까지의 설정으로 ILDC 카메라로 캡처한 이미지를 포함합니다. 본 연구는 Raw sensor data를 이용한 conditional diffusion 모델을 도입하여 복잡한 잡음 속에서도 고해상도 구조적 세부 정보를 점진적으로 생성하며, novel time-melding condition을 통해 생성 과정의 일관성을 높입니다.

- **Performance Highlights**: 연구 결과, 제안된 방법이 기존 방법들에 비해 이미지 구조와 선명도를 효과적으로 복원하는 능력이 뛰어난 것으로 나타났습니다. SRRIIE 데이터셋을 통한 정량적 및 정성적 평가 결과, 새로운 조건을 조정한 conditional diffusion 모델이 복잡한 잡음으로부터 선명한 이미지 세부 정보를 생성할 수 있는 가능성과 효율성을 보여주었습니다.



### Gradient Map-Assisted Head and Neck Tumor Segmentation: A Pre-RT to Mid-RT Approach in MRI-Guided Radiotherapy (https://arxiv.org/abs/2410.12941)
- **What's New**: 이번 연구는 방사선 치료 (RT)에서 두경부 암의 종양 구획 정확성을 향상시키기 위해 사전 방사선 치료 이미지와 지역 그래디언트 맵을 활용한 새로운 방법을 제안합니다. 이는 기존의 수동 분할 방식의 한계를 극복하기 위한 목적으로, MRI 유도 적응 방사선 치료에 적용됩니다.

- **Technical Details**: 본 연구에서는 nnUNet 프레임워크를 사용하여 모델을 구현하고 훈련했습니다. 방사선 치료 전(pre-RT) 이미지의 변형 등록된 구획을 기반으로 종양 주변의 관심 영역 (ROIs)을 정의한 후, 이를 통해 미드 방사선 치료(mid-RT) T2 강도 이미지를 처리하여 그래디언트 맵을 생성했습니다. 이러한 방법을 통해 종양의 경계 구획을 향상시키고자 하였습니다.

- **Performance Highlights**: 본 연구의 최종 DSCagg 점수는 GTVp(주 종양)에서 0.534, GTVn(림프절 종양)에서 0.867로 나타났으며, 평균 점수는 0.70을 기록했습니다. 이는 적응 방사선 치료의 분할 및 치료 계획 강화에 기여할 잠재력을 가지고 있습니다.



### UMambaAdj: Advancing GTV Segmentation for Head and Neck Cancer in MRI-Guided RT with UMamba and nnU-Net ResEnc Planner (https://arxiv.org/abs/2410.12940)
- **What's New**: 본 연구는 MRI 유도 적응 방사선 치료에서 두 가지 최신 심층 학습 세분화 기법, UMamba와 nnU-Net Residual Encoder(ResEnc)를 통합하여 'UMambaAdj'라는 새로운 접근 방식을 제안합니다. 이 방법은 주두경부암 치료에서 종양 부피(GTV)를 더 정밀하게 세분화하는 데 기여할 것으로 기대됩니다.

- **Technical Details**: UMambaAdj는 3D ResEnc U-Net과 Mamba 블록을 결합하여 구성됩니다. CNN 구조는 nnU-Net Residual Encoder Planner에 따라 설정되며, 6단계의 U-Net은 총 6개의 잔차 CNN 블록을 포함하여 GTVp와 GTVn의 세분화를 위해 설계되었습니다. Mamba 레이어는 입력 이미지 특징 맵을 처리하여 장기 의존성을 효과적으로 캡처합니다.

- **Performance Highlights**: MNTS-MRG 2024 챌린지 테스트 세트에서 GTVp에 대해 0.751, GTVn에 대해 0.842의 Dice 유사도 계수(DSC)를 달성했으며, 평균 DSC는 0.796였습니다. 이는 MRI 유도 적응 방사선 치료에서 보다 정밀한 종양 윤곽을 제공하며 HNC 환자의 치료 결과를 향상시킬 가능성을 보여줍니다.



### DreamCraft3D++: Efficient Hierarchical 3D Generation with Multi-Plane Reconstruction Mod (https://arxiv.org/abs/2410.12928)
Comments:
          Project Page: this https URL

- **What's New**: DreamCraft3D++는 복잡한 3D 자산을 효율적이고 고품질로 생성할 수 있는 DreamCraft3D의 확장판입니다. 이 모델은 이전의 기하학 조각 최적화 단계를 대체하는 feed-forward multi-plane 기반 재구성 모델을 도입하여 프로세스를 1000배 가속화했습니다.

- **Technical Details**: 본 연구는 DreamCraft3D의 기존 다단계 생성 프로세스를 유지하면서, geometry sculpting 단계를 feed-forward 방식의 대형 재구성 모델로 대체합니다. 또, IP-Adapter 모듈을 제안하여 다각적 이미지를 기반으로 텍스처 및 기하학 일관성을 향상시킵니다. 이를 통해 DreamCraft3D의 DreamBooth fine-tuning에 비해 4배 더 빠른 결과를 제공합니다.

- **Performance Highlights**: DreamCraft3D++는 다양한 데이터셋에 대한 실험을 통해 복잡한 기하 구조 및 사실적인 360° 텍스처를 가진 창의적인 3D 자산을 생성할 수 있는 능력을 입증하였으며, 기존의 최첨단 image-to-3D 방법론에 비해 품질과 속도에서 우수함을 보였습니다.



### DEeR: Deviation Eliminating and Noise Regulating for Privacy-preserving Federated Low-rank Adaptation (https://arxiv.org/abs/2410.12926)
- **What's New**: 본 논문에서는 저랭크 적응(low-rank adaptation, LoRA)과 연합 학습(federated learning, FL)을 통합하여 개인 정보 보호가 가능한 분산 훈련을 통해 사전 훈련된 기본 모델(pretrained foundation models)을 의료 작업에 적응하도록 하는 새로운 접근 방식을 소개합니다. 이 연구의 핵심은 LoRA와 FL의 직접 결합에서 발생하는 두 가지 문제인 집계 편차(aggregation deviation)와 차분 개인 정보 보호(differential privacy, DP) 노이즈 증폭 효과를 해결하는 것입니다.

- **Technical Details**: 새로 제안된 프레임워크인 DEeR(Deviation Eliminating and Noise Regulating)는 이론적으로 LoRA 매개변수의 동등성을 보장하여 집계 편차를 제거하는 데 필요한 조건을 증명하였습니다. 이를 바탕으로 소위 '편차 제거기(deviation eliminator)'가 설계되어 교대 최소화(alternating minimization) 알고리즘을 활용해 학습 중 집계 편차를 항상 0으로 유지하도록 LoRA의 매개변수를 반복적으로 최적화합니다. 또한, 노이즈 증폭 효과를 분석하여 DP 노이즈와 LoRA 매개변수 간의 '선형 관계'가 이 문제의 주요 원인임을 발견하고, 이를 억제하기 위해 두 가지 조절 인자를 이용하는 '노이즈 조절기(noise regulator)'를 제안하여 DP와 LoRA 간의 관계를 분리하고 강력한 개인 정보 보호와 우수한 파인튜닝 성능을 달성합니다.

- **Performance Highlights**: DEeR는 공개 의료 데이터셋에서 기존의 최첨단 방법들보다 우수한 성능을 보였으며, 편차 제거기와 노이즈 조절기의 유효성을 검증하기 위한 종합적인 실험이 이루어졌습니다.



### GCM-Net: Graph-enhanced Cross-Modal Infusion with a Metaheuristic-Driven Network for Video Sentiment and Emotion Analysis (https://arxiv.org/abs/2410.12828)
- **What's New**: 이 논문은 다양한 모달리티(modality)에서의 감정 분석(Emotion Recognition)과 감정 인식(Sentiment Analysis)의 복잡성을 해결하기 위해 새로운 프레임워크(GCM-Net)를 제안합니다. 본 연구는 모달리티 통합(fusion)과 특징 최적화(feature optimization)에 주안점을 두고 있습니다.

- **Technical Details**: GCM-Net은 그래프 샘플링(graph sampling)과 집계를 통해 모달리티 특징을 재조정하는 기능을 포함하고 있습니다. 또한, 교차 모달(attention) 모듈을 사용하여 모달 간 상호작용을 파악하고 발화 관련성(utterance relevance)을 결정합니다. 하모닉 최적화(harmonic optimization) 모듈은 메타휴리스틱(metaheuristic) 알고리즘을 사용하여 주목(attention)된 특징들을 결합합니다.

- **Performance Highlights**: 제안된 GCM-Net의 성능은 CMU MOSI 데이터셋에서 91.56%, CMU MOSEI 데이터셋에서 86.95%의 정확도를 보였으며, IEMOCAP 데이터셋에서의 감정 분석에서 85.66%의 정확도를 기록했습니다. 이는 기존 방법 대비 상당한 성능 향상을 나타냅니다.



### AVID: Adapting Video Diffusion Models to World Models (https://arxiv.org/abs/2410.12822)
- **What's New**: 이 연구에서는 사전 학습된 비디오 확산 모델을 액션 조건화된 월드 모델에 적응시키는 새로운 접근 방식인 AVID를 제안합니다. AVID는 액션 라벨이 붙은 비디오의 작은 도메인 특정 데이터셋에서 어댑터를 학습하여, 사전 학습된 모델의 매개변수에 접근할 수 없이 액션에 조건화된 비디오를 생성합니다.

- **Technical Details**: Diffusion 모델(확산 모델)의 노이즈 예측을 수정하여 액션 수반 예측을 생성하는 방법을 채택했습니다. AVID는 학습된 마스크를 이용하여 사전 학습된 모델의 중간 출력을 변형하고, 액션과 조건화된 비디오 출력을 생성합니다.

- **Performance Highlights**: 비디오 게임 및 실제 로봇 데이터에서 AVID를 평가하였으며, 기존의 확산 모델 적응 기준선보다 우수한 성능을 보였습니다. 사전학습된 모델을 올바르게 활용할 경우, 임베디드 AI(embodied AI)에 강력한 도구가 될 가능성을 демонстр합니다.



### Interactive Explainable Anomaly Detection for Industrial Settings (https://arxiv.org/abs/2410.12817)
- **What's New**: 이 연구는 산업 환경에서의 품질 보증을 위한 시각적 이상 탐지(Anomaly Detection)에 중점을 두고 있습니다. Convolutional Neural Networks (CNNs) 기반의 분류 모델과 블랙 박스(Classifier) 분류기를 위한 모델-비의존적(Machine-agnostic) 설명 알고리즘의 발전에 초점을 맞추고 있습니다. 이를 통해 사용자-interactive interface를 구현하여 모델의 출력을 수정할 수 있도록 돕습니다.

- **Technical Details**: 두 가지 클래스(정상, 비정상)로 분류되는 산업용 이상 탐지 데이터를 위한 InvRISE라는 새로운 설명 방법을 도입하였으며, 기존 CAIPI 알고리즘에 NearCAIPI라는 확장을 추가하였습니다. 이 알고리즘은 사용자 피드백을 적극적으로 통합하여 모델의 성능을 개선하고 설명성을 높이는 것을 목표로 합니다.

- **Performance Highlights**: 이 프레임워크를 통해 사용자 피드백을 통합한 인터랙티브한 과정이 가능해지며, 모델의 신뢰성과 사용 편의성을 증가시킬 수 있는 성과를 보였습니다. 특정 결함(예: 용접 선상의 결함) 탐지에서 사용자에 대한 추가적인 피드백이 성능 향상에 기여할 수 있음을 보여주고 있습니다.



### Rethinking Misalignment in Vision-Language Model Adaptation from a Causal Perspectiv (https://arxiv.org/abs/2410.12816)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 본 논문에서는 CLIP 모델의 두 가지 정렬 문제인 작업 불일치(task misalignment) 및 데이터 불일치(data misalignment)를 해결하기 위한 방법을 제안합니다. 특히, 데이터 불일치가 다운스트림 작업에서 성능에 미치는 영향을 분석하고 Causality-Guided Semantic Decoupling and Classification (CDC) 방법론을 개발하여 이 문제를 해결합니다.

- **Technical Details**: CDC 방법론은 두 가지 주요 구성 요소인 Visual-Language Dual Semantic Decoupling (VSD)와 Decoupled Semantic Trusted Classification (DSTC)로 이루어져 있습니다. VSD는 다양한 의미를 표현하는 여러 프롬프트 템플릿을 모델에 통합하여 학습합니다. DSTC는 각 층에서 분리된 의미에 기반하여 분류 작업을 독립적으로 수행하며, 예측의 불확실성을 동시에 추정합니다.

- **Performance Highlights**: 다양한 데이터셋과 여러 작업에서 진행된 실험 결과, CDC 방법론이 CLIP의 성능을 유의미하게 향상시킴을 보여주었습니다. 특히, 새로운 클래스에 대한 인식 성능이 개선되는 효과가 있음을 확인했습니다.



### Leveraging generative models to characterize the failure conditions of image classifiers (https://arxiv.org/abs/2410.12814)
- **What's New**: 이번 연구에서는 이미지 분류기(image classifier)의 실패 조건(failure conditions)을 파악하는 문제를 다룹니다. 이를 위해, 최근의 Generative Adversarial Networks (GAN)인 StyleGAN2의 고해상도 이미지 데이터 생성 능력을 활용했습니다.

- **Technical Details**: 실행한 전략은 생성 모델(latent space)에서 성능 저하(performance degradation)의 방향을 표현하여, 여러 가지 손상(sources of corruption)이 결합된 코너 케이스(corner cases)를 발견하고 다양한 분류기들의 동작을 보다 자세히 비교하는 것입니다. 성능 저하의 방향은 데이터 생성으로 시각적으로 표현될 수 있어 해석 가능성을 높입니다.

- **Performance Highlights**: MNIST 데이터셋을 사용하여 노이즈와 블러라는 두 가지 손상 출처로 실험을 진행했으며, 이미지 품질은 모든 클래스에 영향을 미치는 반면, 형태(shape)는 특정 클래스(class-specific)에만 영향을 미친다는 것을 보여주는 결과를 도출했습니다. 이 접근 방식은 안전이 중요한 응용 프로그램에서 인공지능(AI) 컴포넌트를 활용하는 위험을 더 잘 이해하고 제어하는 데 기여할 수 있는 가능성을 제시합니다.



### Decoding Emotions: Unveiling Facial Expressions through Acoustic Sensing with Contrastive Attention (https://arxiv.org/abs/2410.12811)
Comments:
          The extended version of the 2023 IEEE INFOCOM conference paper

- **What's New**: FacER+는 기존의 외부 마이크 배열을 필요로 하지 않는 능동적 음향 얼굴 표현 인식 시스템이다.

- **Technical Details**: FacER+는 스마트폰의 earpiece 스피커에서 발산된 근초음파 신호의 반향를 분석하여 얼굴 표현 특징을 추출한다. 이 모델은 다양한 사용자 간의 표현 특징을 일관되게 학습하기 위해 대비 외부 주의(constrastive external attention) 기반 모델을 개발하였다.

- **Performance Highlights**: FacER+는 20명의 자원봉험자를 대상으로 한 실험에서 90% 이상의 정확도로 6가지 공통 얼굴 표현을 인식하여 기존의 음향 센싱 방법보다 10% 향상된 성능을 보여준다.



### Differentiable Robot Rendering (https://arxiv.org/abs/2410.13851)
Comments:
          Project Page: this https URL

- **What's New**: 이번 논문에서는 로봇 작업을 위한 비주얼 데이터와 액션 데이터 간의 모달리티 갭(modality gap)을 해결하기 위해 차별화 가능한 로봇 렌더링(differentiable robot rendering) 방법을 소개합니다. 이는 로봇의 시각적 형태가 제어 매개변수(control parameters)에 따라 직접적으로 미분 가능하게 해줍니다.

- **Technical Details**: 제안된 방법인 Dr. Robot은 Gaussians Splatting, 선형 혼합 스키닝(Linear Blend Skinning) 및 포즈 조건부 외형 변형 모델(pose-conditioned appearance deformation model)을 통합하여 로봇의 비주얼과 제어 신호를 연결합니다. 이를 통해 픽셀 공간에서 제어 공간으로의 신호 전송이 가능해지며, 복잡한 로봇 작업에서 에이전트가 최적화로 계획하고 제어할 수 있는 방법을 제공합니다.

- **Performance Highlights**: Dr. Robot을 사용한 여러 작업에서 로봇 포즈 복원(robot pose reconstruction)의 성능이 이전 최첨단 방법보다 큰 폭으로 개선되었음을 보여줍니다. 이 모델은 비주얼 퍼포먼스 모델과 연결하여 로봇 행동의 계획 및 제어를 수행할 수 있는 가능성을 열어줍니다.



### Unearthing Skill-Level Insights for Understanding Trade-Offs of Foundation Models (https://arxiv.org/abs/2410.13826)
Comments:
          Code at: this http URL

- **What's New**: 이 논문은 모델 평가에서의 복잡성을 해결하기 위해, 모델이 생성한 이론(rationales)을 사용하여 기저가 되는 기술(skills)을 자동으로 복구하는 방법을 제안합니다. 기존의 평가 지표에 숨겨진 다양한 기술을 분석하여, 구체적이고 행동 가능한 모델 능력 이해를 제공합니다.

- **Technical Details**: 평가 인스턴스에 대해 강력한 모델(예: GPT-4o)을 사용하여 단계별 이론을 생성하고 각 단계에서 적용된 기술을 나열합니다. 이 과정을 통해 46,000개 이상의 인스턴스를 분석하고 기술 조각(skill-slices)을 작성하여 여러 벤치마크에서 기술의 정확성을 비교합니다.

- **Performance Highlights**: 우리는 기술 조각 분석을 통해 모델 간의 성능 무역에 대한 새로운 통찰을 발견했습니다. 예를 들어, Gemini 1.5 Pro는 'molar mass 계산'에서 평균적으로 18% 더 정확하지만 '헌법법 적용'에서는 19% 덜 정확하다는 결과를 보여주었습니다. 이러한 분석 방법을 통해 우리는 전체 12개 데이터셋에서 3%의 정확도 향상을 확인했습니다.



### Eyelid Fold Consistency in Facial Modeling (https://arxiv.org/abs/2410.13760)
- **What's New**: 본 논문은 다양한 인간의 눈꺼풀 모양을 효과적으로 모델링할 수 있는 새로운 방법론을 제안합니다. 특히, 이전의 모델들이 충분히 포괄적이지 않은 눈꺼풀 모양을 다룰 수 있도록 하기 위해 새로운 일관성 정의를 도입합니다.

- **Technical Details**: 눈꺼풀 모양을 묘사하기 위해 두 개의 윗눈꺼풀과 아랫눈꺼풀로 나누는 새로운 일관성을 적용하고, 이를 통해 다양한 눈꺼풀 형태를 통일된 토폴로지를 사용하여 모델링합니다. 기존 데이터셋을 재처리하여 훈련된 파라메트릭 얼굴 모델을 개선합니다.

- **Performance Highlights**: 개선된 모델은 3D 얼굴 재구성 및 얼굴 추적과 같은 컴퓨터 비전 작업에서 성능이 크게 향상됨을 보여줍니다. 다양한 눈꺼풀 형태에 대한 정량적인 평가를 통해 모델의 정확성과 다양성을 입증합니다.



### Deep-learning recognition and tracking of individual nanotubes in low-contrast microscopy videos (https://arxiv.org/abs/2410.13594)
Comments:
          13 pages, 5 Figures, No supporting information included

- **What's New**: 이 연구는 인-시투( in-situ ) 호모다인 편광 현미경( polarization microscopy )을 사용하여 탄소 나노튜브의 성장 동역학을 분석하는 자동화된 딥 러닝( deep learning ) 접근 방식을 개발하여 새로운 기법을 제시합니다.

- **Technical Details**: Mask-RCNN 아키텍처에 ResNet-50 백본( backbone )을 적용하여 현미경 비디오에서 개별 나노튜브를 인식하고 추적하는 기술을 개발하였습니다. 이 방법은 비디오 처리 단계에서 대비를 향상시키고 신호가 약한 빠른 동역학을 효과적으로 관리하는 차별 처리 기술을 포함합니다.

- **Performance Highlights**: 딥 러닝 모델은 수작업 측정과 일관성을 보이며 데이터 처리량( throughput )을 증가시켜 나노튜브 성장에 대한 통계적 연구의 기반을 마련합니다. 이 접근법은 다른 유형의 인-시투 현미경 연구로도 적용 가능하며, 개별 나노 물체에 대한 연구를 위한 고속 데이터 수집( high-throughput data acquisition )의 중요성을 강조합니다.



### RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical Imaging (https://arxiv.org/abs/2410.13570)
Comments:
          10 pages, 4 figures, 3 tables

- **What's New**: 이번 연구는 RGB 데이터를 이용하여 하이퍼스펙트럴 서명을 재구성하여 외과 수술 이미징을 향상시키는 방법을 다룹니다. 공개된 HeiPorSPECTRAL 데이터셋과 자체 신경외과 데이터셋을 활용하여 다양한 CNN(Convolutional Neural Networks)과 Transformer 모델의 성능을 비교하고 평가하였습니다.

- **Technical Details**: 연구에서 사용된 모델은 하이퍼스펙트럼 데이터의 정확한 예측을 위해 공간 정보를 효과적으로 통합하는 Transformer 모델입니다. 성능 평가는 RMSE(Root Mean Square Error), SAM(Spectral Angle Mapper), PSNR(Peak Signal-to-Noise Ratio) 및 SSIM(Structural Similarity Index)과 같은 포괄적인 측정을 통해 이루어졌습니다. 모델은 가시광선과 확장된 스펙트럼 범위를 모두 포함한 스펙트럼 프로파일을 예측하는 데 성공하였습니다.

- **Performance Highlights**: Transformer 모델은 평가 지표에서 우수한 성능을 보이며, 질적 평가를 통해 외과적 의사결정에 중요한 스펙트럴 프로파일 예측 능력을 나타냈습니다. 그러나 가시광선과 확장된 하이퍼스펙트럴 범위를 모두 캡처하는 데 있어 MAE(Mean Absolute Error)를 통해 강조된 복잡한 과제가 있었습니다.



### Representing Model Weights with Language using Tree Experts (https://arxiv.org/abs/2410.13569)
- **What's New**: 본 논문은 다양한 신경망 모델의 가중치를 입력으로 사용하는 메타네트워크를 학습하는 새로운 접근 방식을 제안합니다. 대중 모델의 대부분이 소수의 Model Trees에 속하며, 이는 학습을 용이하게 합니다.

- **Technical Details**: 모델 가중치의 변화량을 줄이기 위해 Probing Experts (ProbeX)라는 경량 탐색 방법을 도입합니다. ProbeX는 단일 레이어의 가중치만을 학습하며, 고차원 모델 가중치를 효율적으로 매핑하는 것을 목표로 합니다.

- **Performance Highlights**: ProbeX는 제로샷 모델 분류 및 검색을 포함하여 모델 가중치를 공통의 가중치-언어 임베딩 공간으로 효과적으로 매핑하며, 상대적으로 적은 훈련 시간으로 다양한 과제에서 뛰어난 일반화를 보여줍니다.



### Similarity-Dissimilarity Loss with Supervised Contrastive Learning for Multi-label Classification (https://arxiv.org/abs/2410.13439)
- **What's New**: 본 연구는 멀티 라벨 분류에서의 슈퍼바이저드 대조 학습(Supervised Contrastive Learning)에서 긍정 샘플을 결정하는 데 있어 새로운 접근 방식을 제안합니다. 특히, 다섯 가지 고유한 관계를 도입하고, 유사성 및 비유사성 손실(Similarity-Dissimilarity Loss)을 통해 대조 손실 함수(weights)를 동적으로 조정합니다.

- **Technical Details**: 다섯 가지 관계(R2, R3, R4, R5)를 정의하여 멀티 라벨 샘플과 앵커(anchor) 사이의 유사성과 비유사성을 계산하여 손실을 재가중화하는 새로운 Similarity-Dissimilarity Loss를 제안합니다. 이를 통해 ALL, ANY 및 MulSupCon 등의 기존 방법의 한계를 극복합니다.

- **Performance Highlights**: MIMIC 데이터셋에서 멀티 라벨 텍스트 분류 실험을 수행한 결과, 제안된 손실 함수가 슈퍼바이저드 대조 학습 패러다임 하에서 모든 인코더(encoders)에 대해 성능을 효과적으로 향상시키는 것으로 나타났습니다. 실험 결과는 제안된 방법의 효과성과 견고성을 뒷받침합니다.



### Unsupervised Skull Segmentation via Contrastive MR-to-CT Modality Translation (https://arxiv.org/abs/2410.13427)
Comments:
          16 pages, 5 figures, ACCV 2024 - GAISynMeD Workshop

- **What's New**: 본 연구에서는 MR(자기공명영상)에서 두개골(segmentation)분할 문제를 해결하기 위한 새로운 비지도(un) 접근 방식을 제안합니다. 이를 통해 MR 이미지를 직접적으로 분할하는 대신, MR-CT(컴퓨터단층촬영) 변환을 통해 합성 CT 데이터를 생성하고, 여기서 분할을 수행하는 방법을 탐구합니다.

- **Technical Details**: 제안된 파이프라인은 두 가지 주요 모듈을 포함합니다: Contrastive Unpaired Translation (CUT)과 Laplacian Pyramid Super-Resolution Network (LapSRN)입니다. CUT 모듈은 비어치된(un) 데이터 샘플을 활용하여 MR에서 CT로의 변환을 수행하며, LapSRN은 고해상도 CT 이미지를 생성하여 점진적으로 해상도를 향상시키는 역할을 합니다. 이 과정에서 다양한 데이터 전처리 기법을 적용합니다.

- **Performance Highlights**: 제안된 접근 방식은 기존 두개골 제거(skull stripping) 방법 및 기타 의학적 분할 모델인 MedSAM과 비교되었습니다. 가장 중요한 점은, 우리의 모델이 훈련 과정에서 어떠한 주석(annotations)도 필요로 하지 않으며, 이는 다양한 임상 상황에서의 두개골 분할 작업에 매우 유용할 것으로 기대됩니다.



### Mitigating Hallucinations in Large Vision-Language Models via Summary-Guided Decoding (https://arxiv.org/abs/2410.13321)
- **What's New**: 이번 연구에서는 LVLMs에서 나타나는 언어 priors의 문제를 해결하기 위해 새로운 방법인 Summary-Guided Decoding (SGD)를 제안합니다. SGD는 이미지 정보에 더 집중하도록 모델을 유도하며, 텍스트 품질을 유지합니다.

- **Technical Details**: 연구는 LVLMs에서의 언어 priors를 분석하고, 이미지 관련 부분의 품사(POS)와 연관된 토큰을 생성할 때 언어 priors에 대한 모델의 의존도가 증가함을 발견했습니다. SGD는 요약(context) 기법을 활용하여 이미지 관련 POS 토큰의 다음-토큰 확률을 수정하여 텍스트 품질을 최대한 보존하면서 이미지 정보를 반영합니다.

- **Performance Highlights**: SGD는 객체 환각(object hallucination) 벤치마크에서 모든 다른 해석 방법을 초월했으며(CHAIRS에서 +16.5%, CHAIRI에서 +19% 향상), 정밀도와 재현율의 균형을 잘 유지하며 Pareto optimal성을 달성했습니다. 또한 텍스트 품질을 거의 완벽하게 유지하면서 객체 환각을 줄이는 데 강력한 성과를 보였습니다.



### Precipitation Nowcasting Using Diffusion Transformer with Causal Attention (https://arxiv.org/abs/2410.13314)
- **What's New**: 이번 연구에서는 Diffusion Transformer with Causal Attention 모델을 제안하여 단기 강수 예보의 문제를 해결하고자 합니다. 이 모델은 Transformer를 활용하여, 조건 정보와 예보 결과 간의 시공간 쿼리를 효과적으로 설정할 수 있도록 합니다.

- **Technical Details**: DTCA(분산 변환기 인과 주의) 모델은 조건부 강수 분포 특징 관련 쿼리를 기반으로 한 새로운 인과 주의 메커니즘을 도입하며, 다양한 시공간 정보 상호작용을 탐색하고 그 구조를 비교합니다. 실험 결과, 전역 시공간 레이블링 상호작용이 최고의 성능을 발휘하는 것으로 나타났습니다.

- **Performance Highlights**: 제안된 방법은 최신 기술인 U-Net 기반 방법과 비교해 강수 예측에서 약 15% 및 8% 개선된 CSI(비판적 성공 지표)를 달성하여 현재 상태의최고 성능을 기록했습니다.



### PiLocNet: Physics-informed neural network on 3D localization with rotating point spread function (https://arxiv.org/abs/2410.13295)
Comments:
          25 pages, 4 figures

- **What's New**: 이 논문은 3D localization 문제 해결을 위한 새로운 개선된 Neural Network PiLocNet을 제안합니다. PiLocNet은 기존의 LocNet을 기반으로 하며, forward-model 기반 정보와 data-fitting loss term을 통합하여 물리적으로 합리적인 결과를 도출합니다.

- **Technical Details**: PiLocNet은 Physics-Informed Neural Network (PINN)으로, 이미징 시스템의 포인트 스프레드 함수(PSF)를 통해 물리적 정보를 네트워크에 통합합니다. 세 가지 중요한 구성 요소로는 forward-model 정보, variational method의 regularization term, 그리고 Poisson 및 Gaussian noise 모델을 통한 이미지 노이즈에 대한 강건성 개선이 포함됩니다.

- **Performance Highlights**: 실험 결과, PiLocNet은 3D 포인트 소스의 localization을 위한 정확도 향상에 기여하며, precision과 recall 측면에서 개선된 예측 결과를 보여줍니다. 본 논문은 PiLocNet의 Robustness를 검증했으며, 다양한 PSF와 이미징 문제에서의 적용 가능성을 제시합니다.



### Golyadkin's Torment: Doppelg\"angers and Adversarial Vulnerability (https://arxiv.org/abs/2410.13193)
- **What's New**: 이 논문은 'Adversarial Doppelgangers(AD)'라는 개념을 정의하고 탐구하며, 이는 기존의 adversarial visual metamers를 포함합니다. AD의 성능 및 강건성을 분류 기계와 인간의 성능을 비교하여 분석합니다.

- **Technical Details**: AD는 이 논문에서 정의된 지각적(metric) 측정에 따라 서로 가까운 입력들입니다. 연구에서는 이러한 AD에 대한 분류기의 취약성을 분석하고, AD에 강건한 분류기의 구조와 속성을 설명하며, 개념적 엔트로피(conceptual entropy) 및 개념적 모호성(regions of conceptual ambiguity)에 대한 개념을 도입합니다.

- **Performance Highlights**: 대부분의 분류기는 AD에 취약하며, 강건성-정확도 트레이드오프(robustness-accuracy trade-offs)가 개선되지 않을 수 있습니다. 그러나 정확도가 높은 모든 분류기는 hypersensitive behavior를 보여줄 있으며, 이로 인해 AD 강건성을 개선하는 것이 정확도 개선과 동일함을 발견했습니다.



### Scalable Drift Monitoring in Medical Imaging AI (https://arxiv.org/abs/2410.13174)
- **What's New**: 이 논문에서는 인공지능(AI)을 의료 이미징에 통합하여 임상 진단의 발전을 이루었지만 모델 드리프트 관리와 장기적인 신뢰성을 보장하는 데 몇 가지 도전 과제가 발생한다는 점을 강조하고 있습니다. MMC+라는 확장된 프레임워크를 개발하여 이러한 문제에 대처하고 있습니다.

- **Technical Details**: MMC+는 CheXstray 프레임워크를 기반으로 하여 다중 모달 데이터 일치성을 이용한 실시간 드리프트 감지를 통해 의료 이미지 AI 모델을 위한 확장 가능한 드리프트 모니터링 솔루션을 제안합니다. 이 프레임워크는 다양한 데이터 스트림을 보다 강력하게 처리하고, MedImageInsight와 같은 기초 모델을 통합하여 고차원 이미지 임베딩을 지원하며, 불확실성 경계를 도입하여 동적 임상 환경에서 드리프트를 보다 잘 포착합니다.

- **Performance Highlights**: MMC+는 COVID-19 팬데믹 기간 동안 Massachusetts General Hospital의 실제 데이터를 통해 검증되었으며, 데이터의 중요한 변화 감지와 이를 모델 성능 변화와 연계하는 데 효과적입니다. 이러한 시스템은 성능 저하를 직접적으로 예측하지는 않지만, AI 시스템이 허용 가능한 성능 범위에서 이탈할 가능성을 조기에 경고하여 신속한 개입이 가능하도록 합니다.



### Utilizing Large Language Models in An Iterative Paradigm with Domain Feedback for Molecule Optimization (https://arxiv.org/abs/2410.13147)
- **What's New**: 본 연구에서는 약물 발견에서 분자의 최적화를 지원하기 위해 LLM (Large Language Models)을 효과적으로 활용할 수 있는 도메인 피드백 제공자인 Re²DF를 제안합니다. 이 새로운 접근법은 분자가 화학적으로 유효하지 않을 경우를 고려하여 수정된 분자의 유효성을 즉시 검증하며, 해당 분자의 개선을 위한 구체적인 피드백을 제공합니다.

- **Technical Details**: Re²DF는 외부 툴킷인 RDKit를 이용하여 수정된 분자가 화학적으로 유효한지를 체크합니다. 만약 유효하지 않다면, RDKit로부터 오류 메시지를 제공받아 LLM에게 수정 방향을 제시합니다. 또한, 수정된 분자가 원하는 특성을 충족하는지 확인하여, 목표에 대한 정확한 방향과 거리를 제공하는 신뢰할 수 있는 피드백을 생성합니다.

- **Performance Highlights**: Re²DF는 단일 속성 목표 20개에서 Hit ratio를 각각 16.95% 및 20.76% 향상시키며, 다중 속성 목표에서는 32개에서 각각 6.04% 및 5.25% 향상시켰습니다. 이러한 결과는 Re²DF가 기존 방법들보다 더 나은 성능을 발휘함을 알립니다.



### Mapping Bias in Vision Language Models: Signposts, Pitfalls, and the Road Ahead (https://arxiv.org/abs/2410.13146)
Comments:
          Under Review at NAACL 2025

- **What's New**: 이 논문은 Vision Language Models (VLMs)의 공정성을 평가하기 위해 5개의 모델과 6개의 데이터셋을 분석하고, 편향(bias)에 대한 새로운 통찰을 제공합니다. 특히, 기존의 표정 기반(portrait-based) 데이터셋이 VLM의 공정성을 평가하는 데 가장 유용하다는 것을 발견했습니다.

- **Technical Details**: 본 연구는 UTKFace, CelebA, PATA, VLStereoSet, VisoGender와 같은 여러 데이터셋을 활용하여 VLM의 편향을 평가하였습니다. 각 모델이 성별, 인종 및 연령과 같은 보호 속성을 어떻게 처리하는지 분석를 진행하며, 특히 데이터셋의 구성에 따라 평가 결과가 달라질 수 있음을 강조합니다. VisoGender 데이터셋의 어려운 버전을 소개하여 철저한 평가를 가능하게 합니다. 

- **Performance Highlights**: LLaVa와 CLIP 모델 간의 성능과 공정성의 격차를 발견하여, VLM의 공정성 평가에 대한 보다 효과적이고 체계적인 데이터셋 설계의 필요성을 강조합니다. 저자들은 기존 데이터셋의 한계를 지적하며, VLM의 평가를 위한 향후 연구 방향을 제안합니다.



### See Behind Walls in Real-time Using Aerial Drones and Augmented Reality (https://arxiv.org/abs/2410.13139)
Comments:
          6 pages

- **What's New**: 새로운 ARD2 프레임워크는 두 대의 항공 드론과 증강 현실(augmented reality, AR) 장치를 활용하여 실시간으로 벽을 통과하는 감시를 가능하게 합니다.

- **Technical Details**: ARD2는 두 가지 주요 단계로 구성되며, 첫 번째 단계에서는 드론, 사용자 및 목표물 간의 기하학적 관계를 이용해 목표물의 방향을 사용자 AR 디스플레이에 투사합니다. 두 번째 단계에서는 드론에서 촬영한 이미지를 합성하여 목표물의 외형(contour)을 재구성합니다.

- **Performance Highlights**: 실험 결과, 방향 추정과 외형 재구성 모두에서 시스템의 정확도가 입증되었습니다.



### Adversarial Neural Networks in Medical Imaging Advancements and Challenges in Semantic Segmentation (https://arxiv.org/abs/2410.13099)
- **What's New**: 최근 인공지능(AI)의 발전으로 의료 영상 특히 뇌 영상 분야가 혁신적인 변화를 겪고 있습니다. 이 연구는 AI의 주요 분야인 deep learning을 뇌 이미지의 semantic segmentation에 통합하는 방안을 체계적으로 조사합니다.

- **Technical Details**: Semantic segmentation은 해부학적 구조를 구분하고 병리학적 지표를 식별하는 필수 기법이며, 이는 복잡한 신경 질환의 진단을 위해 필수적입니다. 연구에서는 adversarial neural networks를 적용하여 semantic segmentation 프로세스를 자동화하고 개선하는 방법을 제시합니다.

- **Performance Highlights**: 이 접근 방식은 진단 정확도를 향상시키고 인간의 오류를 줄이며 이미징 데이터 분석의 처리량을 증가시키는 데 기여합니다. 이를 통해 신경학적 평가에서 진단 정확도가 획기적으로 개선되었습니다.



### MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models (https://arxiv.org/abs/2410.13085)
- **What's New**: 본 논문에서는 Med-LVLMs의 사실성을 향상시키기 위해 MMed-RAG라는 다중 모달 RAG 시스템을 제안합니다. 이 시스템은 도메인 인식을 위한 검색 메커니즘, 적응형 검색된 컨텍스트 선택 방법, 그리고 검증 가능한 RAG 기반의 선호 미세 조정 전략을 포함하여, 의료 데이터의 다양한 분야에 대해 일반적이고 신뢰할 수 있는 접근 방식을 제공합니다.

- **Technical Details**: MMed-RAG는 세 가지 주요 요소로 구성됩니다: 1) 도메인 인식 검색 메커니즘 - 입력 의료 이미지에 적합한 검색 모델을 선택하기 위해 도메인 식별 모듈을 설계하였습니다. 2) 적응형 검색된 컨텍스트 선택 - 검색된 컨텍스트의 개수를 선택하는 방법입니다. 3) RAG 기반 선호 미세 조정 - 교차 모달 정렬을 개선하고 모델과 실제 간의 전체 정렬을 높이는 방법입니다.

- **Performance Highlights**: MMed-RAG는 5개의 의료 데이터세트에서 실험을 실시하여, Medical VQA와 보고서 생성 작업에서 각각 18.5% 및 69.1%의 사실 정확도를 향상시켰습니다. 전반적으로 MMed-RAG는 Med-LVLMs의 정확성을 평균 43.8% 개선하였습니다.



### BOXR: Body and head motion Optimization framework for eXtended Reality (https://arxiv.org/abs/2410.13084)
Comments:
          Accepted to 45th IEEE Real-Time Systems Symposium (RTSS'24)

- **What's New**: 새로운 C2D(latency) 메트릭을 소개하여 본체 움직임에 의해 발생하는 지연을 캡처하고 XR 시스템 내에서 본체 및 머리 움직임 지연을 공동 최적화하는 BOXR 프레임워크를 제안합니다.

- **Technical Details**: BOXR 프레임워크는 M2D(Head Motion)와 C2D(Body Motion) 지연을 효율적으로 조정하여 과제 간의 자원 경쟁을 피하고 출력 프레임에서 최신 자세를 유지합니다. 또한, 사용자 동적을 반영하기 위한 움직임 기반의 비주얼 관성 측정기와 장면 의존형의 포베이드 렌더링을 통합합니다.

- **Performance Highlights**: BOXR은 11개의 EuRoC MAV 데이터 세트에서 4개의 XR 애플리케이션을 통해 3개의 하드웨어 플랫폼에서 최신 솔루션보다 성능이 크게 향상되었습니다. M2D와 C2D 지연을 각각 최대 63%와 27%까지 줄이고, 프레임 비율을 최대 43%까지 증가시키며, 실제 환경에서 M2D 지연은 최대 42%, C2D 지연은 최대 31% 감소시켰습니다.



### UniCoN: Universal Conditional Networks for Multi-Age Embryonic Cartilage Segmentation with Sparsely Annotated Data (https://arxiv.org/abs/2410.13043)
- **What's New**: 본 연구에서는 초음파 미세 CT (micro-CT) 이미지를 이용한 배아 (embryonic) 연골 (cartilage) 세분화 (segmentation)에서의 어려움을 극복하기 위해 새로운 딥러닝 (Deep Learning, DL) 접근 방식을 제안합니다. 이 방법은 나이와 공간 정보 (spatial information)를 효과적으로 활용하여 모델 성능을 향상시키는 데 중점을 두고 있습니다.

- **Technical Details**: 본 논문에서는 CNNs, Transformers 및 하이브리드 모델과 같은 다양한 DL 아키텍처에서 적용할 수 있는 두 가지 새로운 메커니즘을 제안합니다. 첫 번째 메커니즘은 이산 (discrete) 나이 범주에 조건화되어 연골의 나이에 따른 형태 변화를 정확히 표현하고, 두 번째 메커니즘은 연속 (continuous) 이미지 크롭 위치에 따라 조정되어 두개부 (cranial region) 내의 세부 형태를 잘 표현합니다.

- **Performance Highlights**: 다양한 연령대의 연골 세분화 데이터셋에서 우리의 조건부 모듈을 인기 있는 DL 세분화 아키텍처에 통합했을 때, 평균 1.7%의 Dice 점수를 얻었으며, 보이지 않는 데이터에서 7.5%의 성능 향상을 이루었습니다. 이러한 결과는 제한된 주석 데이터 (annotated data)로 다양한 데이터셋을 처리할 수 있는 강력하고 보편적인 모델을 개발할 수 있는 가능성을 강조합니다.



### Synthesis and Perceptual Scaling of High Resolution Natural Images Using Stable Diffusion (https://arxiv.org/abs/2410.13034)
Comments:
          29 pages, 7 Figures, 5 tables

- **What's New**: 본 연구에서는 Stable Diffusion XL을 사용하여 자연 이미지의 연속적인 변화를 가진 맞춤형 자극 세트를 합성했다. 이는 각 이미지가 동일 범주 내에서 독특하게 해석 가능하도록 하여 심리물리학적 실험에 적합한 자극 세트를 제공한다.

- **Technical Details**: 자극 이미지는 여섯 개 범주에서 각각 18개의 객체로 구성되며 각 객체에 대해 10개의 변형이 생성되었다. 이러한 변형은 지각적 연속성을 기반으로 하여 배열되어 있으며, 전통적인 이미지 합성 방법으로는 구현하기 어려운 고해상도의 자연 이미지를 생성한다.

- **Performance Highlights**: 1113명의 참가자를 대상으로 한 온라인 유사성 판단 작업을 통해 생성된 자극 세트의 지각적 변이를 검증하였다. 결과는 개발된 이미지를 사용하여 시각적 인식, 주의력 및 기억 연구에 유용한 자료라는 것을 입증하였다.



### Hiding-in-Plain-Sight (HiPS) Attack on CLIP for Targetted Object Removal from Images (https://arxiv.org/abs/2410.13010)
Comments:
          Published in the 3rd Workshop on New Frontiers in Adversarial Machine Learning at NeurIPS 2024. 10 pages, 7 figures, 3 tables

- **What's New**: 기존의 적대적 공격이 주로 단일 모드에 초점을 맞추었던 반면, 본 연구에서는 CLIP과 같은 대규모 멀티 모달 모델(LMM)이 가지는 새로운 취약점에 주목합니다. 새로운 ‘Hiding-in-Plain-Sight (HiPS)’ 공격 기법을 통해 모델 예측을 미세하게 수정함으로써, 타겟 객체가 존재하지 않는 것처럼 보이게 하는 방법을 제안합니다.

- **Technical Details**: HiPS 공격은 두 가지 변형으로 소개됩니다: HiPS-cls는 클래스 레이블 정보를 활용하여 공격을 생성하며, HiPS-cap은 원본 이미지 캡션과 타겟 캡션을 사용하여 공격을 설계합니다. 이러한 공격 기법은 CLIP-Cap과 같은 이미지 캡셔닝 모델로 효과적으로 전이될 수 있습니다.

- **Performance Highlights**: HiPS 공격은 타겟 객체가 이미지 캡션에서 효과적으로 제거되도록 설계되었으며, 여러 평가 지표를 통해 성능을 검증합니다. 제안된 공격이 하위 모델에서 어떻게 작동하는지를 보여주며, 적대적 공격의 새로운 기준을 설정합니다.



### Configurable Embodied Data Generation for Class-Agnostic RGB-D Video Segmentation (https://arxiv.org/abs/2410.12995)
Comments:
          Accepted in IEEE Robotics and Automation Letters October 2024

- **What's New**: 이 논문은 로봇의 다양한 형태를 반영하여 클래스-비구속(video instance segmentation) 비디오 분할(Video Segmentation) 성능을 개선할 수 있는 대규모 데이터셋 생성을 위한 새로운 방법을 제시합니다.

- **Technical Details**: 3D 재구성을 활용하여 로봇의 형태적 특성과 환경의 조명, 센서 배치 등을 반영한 구성이 가능한 세분화된 비디오 세트를 생성하는 파이프라인을 개발하였습니다. 이 과정에서 Massive Video Panoptic dataset (MVPd)을 도입하며, 이는 기존 비디오 세분화 벤치마크보다 45배 이상 크며, 18K 개의 주석 달린 RGB-D 비디오를 포함합니다.

- **Performance Highlights**: MVPd를 통해 파인튜닝(fine-tuning) 시 특정 로봇의 형태에 따른 분할 성능 향상을 보여주었으며, 3D 모달리티(깊이 이미지 및 카메라 자세)를 처리할 때 비디오 세분화 정확성과 일관성을 개선할 수 있는 가능성을 입증했습니다.



### Risk Assessment for Autonomous Landing in Urban Environments using Semantic Segmentation (https://arxiv.org/abs/2410.12988)
- **What's New**: 이 논문에서는 복잡한 도시 환경에서 비전 기반 자율 착륙 문제를 다루고 있으며, 이를 위해 깊은 신경망(deep neural networks)을 사용하여 의미 분할(semantic segmentation)과 위험 평가(risk assessment)를 수행합니다.

- **Technical Details**: SegFormer라는 최첨단 비주얼 트랜스포머 네트워크를 사용하여 복잡하고 비구조적인 도시 환경에서의 의미 분할을 수행합니다. 이 접근 방식은 UAV(Unmanned Aerial Vehicle)의 RGB 카메라 이미지에서 실시간으로 세그먼트를 측정하여 도시 환경에서 가장 흔한 클래스(class)로 구분합니다.

- **Performance Highlights**: 제안된 전략은 다양한 사례 연구(case studies)를 통해 검증되었으며, 자율 긴급 착륙을 위한 가장 안전한 착륙 지역을 결정하는 데 있어 의미 분할 기반 전략의 잠재력을 보여줍니다. 이 연구는 UAV의 민간 응용 프로그램에서의 가능성을 극대화하는 데 기여할 것입니다.



### MuVi: Video-to-Music Generation with Semantic Alignment and Rhythmic Synchronization (https://arxiv.org/abs/2410.12957)
Comments:
          Working in progress

- **What's New**: MuVi라는 혁신적인 새로운 프레임워크를 통해 비디오의 시각적 내용에 맞는 음악을 생성하는 과제를 효과적으로 해결합니다.

- **Technical Details**: MuVi는 비디오 콘텐츠를 분석하기 위해 특별하게 설계된 시각적 어댑터(visual adaptor)를 사용하여 맥락적 및 시간적으로 관련된 특징을 추출합니다. 이 특징은 비디오의 분위기와 주제뿐만 아니라 리듬과 페이스에 맞는 음악을 생성하는 데 사용됩니다. 또한, 음악 구문(phrase)의 주기성을 반영하여 동기화를 보장하는 대조적 음악-비주얼 사전 훈련 방식(contrastive music-visual pre-training scheme)을 도입했습니다.

- **Performance Highlights**: MuVi는 오디오 품질과 시간 동기화 측면에서 뛰어난 성능을 보여줍니다. 실험 결과, MuVi는 기반 모델들보다 우수한 성능을 보여주었으며, 비디오의 시맨틱 정렬(semantic alignment)과 리듬 동기화(rhythmic synchronization)에서 두드러진 성과를 이루었습니다.



### Long-Tailed Backdoor Attack Using Dynamic Data Augmentation Operations (https://arxiv.org/abs/2410.12955)
- **What's New**: 본 논문은 긴 꼬리(long-tailed) 데이터셋에 대한 백도어 공격(backdoor attack)을 처음으로 탐구합니다. 기존의 백도어 공격은 주로 균형 잡힌 데이터셋에 초점을 맞추었으며, 이로 인해 실제 환경에서 발생하는 불균형 데이터 문제를 간과하고 있었습니다.

- **Technical Details**: 제안된 방법인 D$^2$AO(Dynamic Data Augmentation Operation)는 클래스, 샘플 유형(클린 vs. 백도어), 그리고 샘플 특징에 따라 동적으로 다양하고 적절한 데이터 증강(data augmentation) 연산을 선택합니다. 이를 통해 백도어 샘플과 클린 샘플의 불균형 문제를 해결하고, 데이터 증강에 적응할 수 있는 트리거 생성기를 개발하였습니다.

- **Performance Highlights**: CIFAR10-LT 및 CIFAR100-LT와 같은 두 개의 긴 꼬리 벤치마크에서 폭넓은 실험을 수행하였으며, 제안된 방법은 기존의 백도어 공격 방법과 비교하여 상태-of-the-art 공격 성능을 달성하면서 클린 정확도(clean accuracy)를 유지하였습니다.



### Syn2Real Domain Generalization for Underwater Mine-like Object Detection Using Side-Scan Sonar (https://arxiv.org/abs/2410.12953)
Comments:
          7 pages, 4 figures and 3 tables

- **What's New**: 논문에서는 수중 지뢰 탐지에 대한 Syn2Real (Synthetic to Real) 도메인 일반화 접근 방식을 제안합니다. 이 방법은 DDPM 및 DDIM 모델을 사용하여 생성한 합성 데이터를 통해 실제 환경 샘플을 효과적으로 보강할 수 있음을 보여줍니다.

- **Technical Details**: 이 연구는 딥러닝 기반의 자동 목표 인식(ATR) 기술을 사용하여 수중 지뢰를 탐지하는 과정을 다룹니다. 특히, 이 논문에서는 DCGAN 및 확산 모델과 같은 합성 데이터 생성 모델을 비교 분석하였으며, 이러한 모델의 하이퍼파라미터 튜닝을 통해 효과적인 결과를 얻었습니다.

- **Performance Highlights**: Mask-RCNN 모델을 합성 데이터와 원본 데이터 조합으로 학습시킨 결과, 평균 정밀도(Average Precision, AP)가 약 60% 증가했습니다. 이는 수중 지뢰 탐지 작업에서 Syn2Real 도메인 일반화의 잠재력을 강조하는 결과입니다.



### Answering Questions in Stages: Prompt Chaining for Contract QA (https://arxiv.org/abs/2410.12840)
- **What's New**: 이번 연구에서는 법률 문서에서의 질문에 대한 구조적 답변 생성을 위한 새로운 두 단계 프롬프트 체인을 제안합니다. 이전의 프롬프트가 긴 조항을 다루는 데 한계를 보였던 반면, 이 방식은 더 복잡한 법률 텍스트를 효과적으로 처리할 수 있는 가능성을 보여줍니다.

- **Technical Details**: 이 연구는 법률 관련 질문에 대한 응답을 두 단계로 처리하는 전략을 사용하는데, 첫 번째 단계에서는 관련 법률 텍스트의 요약을 생성하고, 두 번째 단계에서는 이 요약을 사용하여 기존의 프롬프트 템플릿에 대해 질문에 대한 답변을 형성합니다. 이를 통해 질문과 답변 옵션 간의 매핑을 개선할 수 있습니다.

- **Performance Highlights**: 실험 결과, 두 단계 프롬프트 체인이 단순한 프롬프트에 비해 대부분의 경우 더 효과적임을 보여주었습니다. 이는 법률 전문가들이 문서를 더 효율적으로 검토하고 자동화된 워크플로우 및 데이터 파이프라인을 구축할 수 있도록 도와주는 기회를 제공합니다.



### EditRoom: LLM-parameterized Graph Diffusion for Composable 3D Room Layout Editing (https://arxiv.org/abs/2410.12836)
- **What's New**: EditRoom은 자연어 명령을 통해 다양한 레이아웃 편집을 자동으로 수행할 수 있는 통합 프레임워크로, 수동 개입 없이 실행됩니다.

- **Technical Details**: EditRoom은 두 개의 주요 모듈인 Command Parameterizer와 Scene Editor로 구성되어 있습니다. Command Parameterizer는 사전 훈련된 LLM(GPT-4o)을 활용하여 자연어 명령을 여섯 가지 기본 편집 유형에 대한 분해 명령으로 변환합니다. Scene Editor는 소스 장면과 텍스트 명령을 조건으로 삼아 확산 기반(diffusion-based) 모델을 훈련하여 목표 장면을 생성합니다.

- **Performance Highlights**: 편집 작업에 대한 실험 결과, EditRoom은 모든 메트릭에서 다른 기준선보다 우수한 성능을 보였으며, 다중 작업 명령에 대해서도 일반화할 수 있는 능력을 보여줍니다.



### MyData: A Comprehensive Database of Mycetoma Tissue Microscopic Images for Histopathological Analysis (https://arxiv.org/abs/2410.12833)
- **What's New**: 이번 논문에서는 mycetoma(미세포증) 자동 검출 및 분류를 위한 새로운 데이터셋을 소개합니다. 이 데이터셋은 mycetoma 조직의 미세탐색적 이미지로 구성되어 있으며, 이는 진단 정확도를 높이고 환자 결과를 개선하는 데 활용될 수 있습니다.

- **Technical Details**: 제안된 데이터셋(MyData)은 142명의 환자에서 수집된 총 864개의 미세탐색적 이미지로 구성되어 있습니다. 각 이미지는 그레인(grain) 존재를 나타내는 이진 마스크(binary masks)로 주석이 달려 있어 검출(detection) 및 분할(segmentation) 작업을 용이하게 합니다. 이 데이터베이스는 특히 전문가 부족으로 어려움을 겪는 농촌 지역에서 유용하게 활용될 수 있습니다.

- **Performance Highlights**: 히스토로파물학적(Histopathological) 접근 방식은 mycetoma 진단에 효과적이며 비용 효율적입니다. 스마트 의료 이미지 분석 모델의 발전과 더불어, 본 연구는 AI 기반 진단 도구의 개발을 지원하고, 질병의 원인 병원체를 효과적으로 식별하는 데 기여할 것으로 기대됩니다.



### Segment as You Wish -- Free-Form Language-Based Segmentation for Medical Images (https://arxiv.org/abs/2410.12831)
- **What's New**: 이번 논문에서는 기존의 바운딩 박스나 포인트 기반의 프롬프트 대신 자연어 기반의 프롬프트를 활용하여 의료 이미지 분할(Medical Image Segmentation, MIS) 문제를 해결하는 새로운 접근 방식을 제안합니다. 이를 위해 RAG(임시 증강 생성) 기술을 이용한 자유형 텍스트 프롬프트 생성기를 개발하고, 다양한 텍스트 프롬프트를 처리할 수 있는 새 모델인 FLanS를 소개합니다.

- **Technical Details**: FLanS는 전문 해부학 기반 쿼리, 해부학 무관 위치 기반 쿼리, 해부학 무관 크기 기반 쿼리를 포함한 다양한 자유형 텍스트 프롬프트를 처리할 수 있는 모델입니다. 또한, 대칭 인지 캐노니컬화 모듈을 통해 스캔 방향에 따른 일관된 정확한 분할을 보장하며, 100,000개 이상의 의료 이미지로 훈련되었습니다.

- **Performance Highlights**: FLanS는 최근의 SOTA(State-of-the-Art) 모델들보다 우수한 언어 이해 능력과 분할 정밀도를 보여주었으며, 다양한 임상 환경에서의 응용 가능성을 입증했습니다. 논문에서는 자질 분석(ablation studies)을 통해 각 구성 요소의 기여도를 검증했습니다.



### DyMix: Dynamic Frequency Mixup Scheduler based Unsupervised Domain Adaptation for Enhancing Alzheimer's Disease Identification (https://arxiv.org/abs/2410.12827)
Comments:
          10 pages, 5 figures, 3 tables

- **What's New**: 이번 연구에서는 Alzheimer’s disease (AD) 진단의 정확성을 높이기 위해 고안된 동적 주파수 믹스업 스케줄러(DyMix)를 제안하였습니다. 이 접근 방식은 Unsupervised Domain Adaptation (UDA)의 성능을 향상시키는데 초점을 맞추고 있습니다.

- **Technical Details**: DyMix는 주파수 영역에서의 동적 조정을 통해 원본(source) 도메인과 대상(target) 도메인 간의 변동성을 처리합니다. 이 방법은 두 가지 주요 단계로 구성됩니다: (i) 의미 불변의 특징 표현을 학습하기 위한 사전 학습(pretraining) 단계, (ii) 동적 주파수 조작을 통한 도메인 적응(domain adaptation) 단계.

- **Performance Highlights**: 실험 결과 DyMix는 Alzheimer’s Disease Neuroimaging Initiative (ADNI)와 Australian Imaging Biomarkers and Lifestyle Study of Aging (AIBL) 데이터세트에서 기존의 최첨단 방법들에 비해 뛰어난 성능을 보였습니다. 이는 동적 주파수 조정을 통해 AD 진단의 정확성을 높이는 데 기여하였습니다.



### Deep Adversarial Learning with Activity-Based User Discrimination Task for Human Activity Recognition (https://arxiv.org/abs/2410.12819)
- **What's New**: 본 연구는 인체 활동 인식(Human Activity Recognition, HAR) 문제를 위해 새로운 적대적 딥러닝 프레임워크를 제안합니다. 이 프레임워크는 사람 간의 변동성을 해결하기 위한 새로운 활동 기반의 구분 작업을 통합하며, 이는 사람들이 동일한 활동을 수행하는 방식이 다름을 인정합니다.

- **Technical Details**: 저자들은 다중 작업, 적대적 학습(adversarial learning) 및 자기 지도 학습(self-supervised learning)에 기반한 표현 학습 방법을 활용하여 모델의 일반화 성능을 향상시키고 개인 정보 유출 문제를 완화합니다. 제안된 프레임워크는 이진 분류 작업으로, 동일한 사람과 동일한 활동에서의 활동 특성 벡터 쌍이 동일한지 구분하는 것을 목적으로 합니다.

- **Performance Highlights**: 제안한 프레임워크는 Leave-One-Person-Out Cross-Validation (LOOCV) 설정에서 새로운 보이지 않는 개인들에 대한 성능을 측정하며, 기존 접근 방식보다 분류 성능을 개선하는 결과를 보여주었습니다. 또한 훈련 및 테스트 참가자 간의 동일한 활동에서의 사람 간 변동성 격차를 감소시켰습니다.



### ChatVTG: Video Temporal Grounding via Chat with Video Dialogue Large Language Models (https://arxiv.org/abs/2410.12813)
Comments:
          10 pages, 3 figures

- **What's New**: ChatVTG는 Video Dialogue Large Language Models (LLMs)를 활용하여 제로샷(zero-shot) 비디오 템포럴 그라운딩(Video Temporal Grounding, VTG) 접근 방식을 제안합니다. 기존의 방법들과 달리 추가적인 훈련 데이터나 쌍으로 연결된 주석 데이터 없이도 작동합니다.

- **Technical Details**: ChatVTG는 비디오를 여러 개의 거친(코스, coarse) 세그먼트로 분할한 후, 각 세그먼트에 대한 캡션을 생성하고 사용자가 제공한 쿼리(query)와 매칭하여 코스 타이밍을 파악합니다. 추가적으로, 슬라이딩 윈도우(sliding window) 방식을 통해 순간 제안을 생성하여 정밀한 타이밍 경계(refinement)를 제공합니다.

- **Performance Highlights**: ChatVTG는 Charades-STA, ActivityNet-Captions, TACoS 등 세 가지 주류 VTG 데이터셋에서 실험을 진행하였으며, 기존의 제로샷 방법보다 향상된 성능을 보였습니다.



### Dual Prototype Evolving for Test-Time Generalization of Vision-Language Models (https://arxiv.org/abs/2410.12790)
Comments:
          Accepted by NeurIPS 2024. Project page: this https URL

- **What's New**: 본 논문은 VLM(visual-language models)에 대한 새로운 test-time adaptation 접근법인 Dual Prototype Evolving (DPE)을 소개합니다. 이 방법은 다양한 다중 모달리티에서의 작업 특정 지식을 효과적으로 축적하며, 각 테스트 샘플의 텍스트 및 비주얼 프로토타입을 진화시킵니다.

- **Technical Details**: DPE는 두 세트의 프로토타입—텍스트(텍스트)와 비주얼(visual)—을 생성하고 진화시켜 테스트 시간 동안 더 정확한 다중 모달 표현을 캡처합니다. 또한 우리는 각 테스트 샘플에 대해 학습 가능한 잔여(residual) 파라미터를 도입하여 일관된 다중 모달 표현을 최적화합니다. DPE는 테스트 시간 동안 임베딩 공간에서의 다중 모달 프로토타입만 최적화하도록 설계되어, 기존의 방법들보다 효율성을 향상시킵니다.

- **Performance Highlights**: DPE는 15개의 다양한 인식 데이터셋에서 테스트 시간 동안 평균 3.55% 및 4.30%의 성능 향상을 보였으며, TPT 및 DiffTPT와 비교하여 각각 5배 및 10배의 테스트 타임 효율성을 달성하였습니다.



### The Curse of Multi-Modalities: Evaluating Hallucinations of Large Multimodal Models across Language, Visual, and Audio (https://arxiv.org/abs/2410.12787)
Comments:
          Project Page: this http URL

- **What's New**: 최근 대규모 다중 모달 모델(large multimodal models, LMMs)의 발전이 다양한 작업에서 성능을 크게 향상시키고 있습니다. 그러나 기존 LMMs는 여전히 환각(hallucinations) 문제에 취약하며, 이는 현실 세계 시나리오에서의 적용 가능성을 제한하고 있습니다.

- **Technical Details**: 이 논문은 LMMs의 환각에 대한 체계적인 조사를 처음으로 수행하였으며, 언어, 시각, 오디오의 세 가지 일반적인 모달리티를 포함합니다. 연구 결과, 환각의 주요 요인은 단일 모달 프라이어(unimodal priors)에 대한 과도한 의존과 유사한 모달리티 간 상관관계(spurious inter-modality correlations)로 나타났습니다. 이를 해결하기 위해 '다중 모달성의 저주(The Curse of Multi-Modalities, CMM)'라는 벤치마크를 도입하여 LMMs의 환각을 종합적으로 평가하였습니다.

- **Performance Highlights**: 연구 결과는 모달리티 통합의 불균형과 훈련 데이터의 편향 등 주요 취약점을 강조하며, 균형 잡힌 교차 모달 학습(cross-modal learning)과 향상된 환각 완화 전략이 필요함을 시사합니다. 이를 바탕으로 LMMs의 신뢰성을 높일 수 있는 연구 방향을 제안합니다.



### Long-LRM: Long-sequence Large Reconstruction Model for Wide-coverage Gaussian Splats (https://arxiv.org/abs/2410.12781)
- **What's New**: Long-LRM은 긴 시퀀스의 입력 이미지로부터 큰 장면을 재구성할 수 있는 범용 3D Gaussian 재구성 모델입니다. 이 모델은 32개의 소스 이미지를 960x540 해상도로 처리할 수 있으며, 단일 A100 80G GPU에서 단 1.3초 만에 실행됩니다.

- **Technical Details**: Long-LRM은 최근의 Mamba2 블록과 전통적인 transformer 블록을 혼합하여 아키텍처를 구성합니다. 이 설계는 더 많은 토큰을 처리할 수 있게 하며, 효율적인 토큰 병합(token merging)과 Gaussian 가지치기(Gaussian pruning) 과정을 통해 품질과 효율성을 균형 있게 조절합니다. 기존의 feed-forward 모델이 1~4개의 입력 이미지만 처리할 수 있는 한계를 극복하여, Long-LRM은 단일 feed-forward 단계에서 전체 장면을 재구성합니다.

- **Performance Highlights**: DL3DV-140 및 Tanks and Temples와 같은 대규모 장면 데이터셋에서, Long-LRM은 최적화 기반 접근 방식에 버금가는 성능을 발휘하며, 효율성 면에서는 두 배 이상 우수한 결과를 보여줍니다.



### Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts (https://arxiv.org/abs/2410.12777)
- **What's New**: 본 논문에서는 확산 모델(Diffusion Models, DMs)에서 유해하거나 저작권이 있는 개념을 효과적으로 '망각'(unlearn)하고자 하는 '메타-망각'(meta-unlearning) 프레임워크를 제안합니다. 이는 모델이 학습된 데이터를 잊고 나서도, 악의적인 파인튜닝(finetuning)을 통해 망각된 개념을 다시 학습하지 않도록 돕습니다.

- **Technical Details**: 메타-망각 프레임워크는 두 가지 주요 요소를 포함합니다: (1) 특정 데이터를 효과적으로 잊도록 하는 표준 망각 목표(unlearning objective)와 (2) 악의적인 파인튜닝 시 망각된 개념의 재학습을 방지하기 위한 메타 목표(meta objective)입니다. 제안된 접근 방법은 기존의 망각 방법과 호환되며, 간단한 메타 목표만 추가하면 됩니다. 실험은 Stable Diffusion 모델(SD-v1-4 및 SDXL)에 대한 다양한 메타-망각 개념의 효과를 검증합니다.

- **Performance Highlights**: 제안된 메타-망각 접근 방식은 학습된 개념들을 안정적으로 망각시키며, 필연적으로 여전히 남아 있는 유관 개념들이 해체(self-destruct)되어 망각된 개념의 재학습을 방지합니다. 다양한 실험과 근거 자료를 통해 메타-망각 프레임워크의 효과가 입증되었습니다.



### Towards Zero-Shot Camera Trap Image Categorization (https://arxiv.org/abs/2410.12769)
- **What's New**: 본 논문은 카메라 트랩 이미지의 자동 분류를 위한 새로운 접근 방식을 탐색합니다. 최신 분류기를 벤치마킹하고 MegaDetector와 Segment Anything을 결합한 다양한 방법을 평가하여 위치별 과적합(overfitting)을 줄이는 데 미치는 영향을 측정했습니다. 또한 DINOv2, BioCLIP, BLIP, ChatGPT와 같은 대형 언어 및 기초 모델을 활용한 제로샷(zero-shot) 접근법을 도입했습니다.

- **Technical Details**: 우리는 세 개의 데이터셋(WCT[1], CCT20[3], CEF)에서 기존의 CNN 및 Transformer 기반 분류 아키텍처를 평가하고 MegaDetector(MD)와 Segment Anything(SAM) 모델을 통해 제로샷 검출 및 분할 성능을 개선하는 방법을 테스트했습니다. 특히, DINOv2와 FAISS를 기반으로 한 제로샷 파이프라인이 뛰어난 결과를 나타냈습니다.

- **Performance Highlights**: MegaDetector와 두 개의 개별 분류기를 결합한 방법이 가장 높은 정확도를 달성했습니다. 이 접근법은 CCT20에서 BEiTV2 분류기의 상대 오류를 약 42%, CEF에서 48%, WCT에서 75% 줄였습니다. 배경을 제거한 후 새로운 위치에서의 오류는 절반으로 줄어들었습니다.



### Gravity-aligned Rotation Averaging with Circular Regression (https://arxiv.org/abs/2410.12763)
Comments:
          accepted at ECCV2024

- **What's New**: 이 논문은 전통적인 Structure-from-Motion(SfM) 방법의 한계를 극복하고자 추가적인 중력 방향 정보를 회전 평균화 단계에 통합하는 새로운 접근법을 제안합니다. 최근 소비자 기기에서 손쉽게 접근할 수 있는 이 정보를 활용하여 카메라 방향 추정의 정확성을 향상시킵니다.

- **Technical Details**: 제안된 알고리즘은 circular regression을 기반으로 하며, 유사한 수렴 보장을 제공하는 linear regression과 유사한 특성을 가지고 있습니다. 이를 통해 회전 평균화 과정에서 발생할 수 있는 2차원 자유도를 줄여 1차원 최적화 문제로 단순화합니다. 또한, 일부 카메라만 중력을 알고 있는 경우에도 효과적으로 적용됩니다.

- **Performance Highlights**: 제안된 방법은 네 개의 대규모 데이터셋에서 최첨단 정확도를 달성하였으며, SfM 기본선 대비 평균 13 AUC@$1^	heta$ 포인트 개선을 보이고, 기존 planar pose graph optimization 기술보다 23 AUC@$1^	heta$ 포인트 더 우수한 성능을 나타냅니다. 이 알고리즘은 8배 더 빠른 속도로 실행됩니다.



### SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And Video Generation (https://arxiv.org/abs/2410.12761)
Comments:
          The first two authors contributed equally; Project page: this https URL

- **What's New**: SAFREE는 최신의 적응형, 훈련 없는 안전한 T2I(텍스트에서 이미지로) 및 T2V(텍스트에서 비디오로) 생성 접근 방식을 제안합니다. 기존의 모델의 가중치를 변경하지 않으면서 유해 콘텐츠를 필터링하는 데 중점을 둡니다.

- **Technical Details**: SAFREE는 텍스트 임베딩 공간에서 유해 개념에 해당하는 하위 공간을 탐지하여 프롬프트 임베딩을 이 하위 공간에서 멀리하는 방식으로 작동합니다. 또한, 동적인 Denoising 단계 조정 및 픽셀 수준에서 유해 개념과 관련된 특징의 영향을 줄이는 적응형 재 주의 메커니즘을 포함합니다.

- **Performance Highlights**: SAFREE는 SOTA(최첨단 기술) 성능을 달성하며, 훈련 없는 기준 모델들에 비해 안전하지 않은 콘텐츠를 억제하는 데 뛰어난 효과를 보이고, 높은 품질의 이미지를 유지하면서도 동시에 다양한 T2I 및 T2V 작업에 유연하게 적용 가능합니다.



### PND-Net: Plant Nutrition Deficiency and Disease Classification using Graph Convolutional Network (https://arxiv.org/abs/2410.12742)
- **What's New**: 본 연구에서는 식물 영양 결핍 및 질병 분류를 위한 새로운 딥러닝 방법인 Plant Nutrition Deficiency and Disease Network (PND-Net)을 제안합니다. 기존의 CNN(Convolutional Neural Network) 기반 모델에 그래프 컨볼루션 네트워크(GCN)를 통합하여 지역 기반 기능 학습을 통해 더 정교한 특징 표현을 개발하였습니다.

- **Technical Details**: PND-Net은 멀티 스케일에서의 지역 기반 기능 요약을 통해 공간 피라미드 풀링(Spatial Pyramidal Pooling)을 활용하여 차별적 기능 표현을 생성합니다. GCN을 통해 식물 질병 및 영양 부족의 미세한 세부정보 학습이 가능해지며, 이 구조는 CNN의 특징에 기반한 그래프 기반 상관관계를 구축하여 입력 데이터의 미세한 설명을 캡처하지 못하는 기존 방법의 한계를 극복합니다.

- **Performance Highlights**: 제안한 PND-Net은 두 개의 영양 결핍 데이터셋과 두 개의 질병 분류 데이터셋에서 평가되었으며, Xception 백본을 사용하여 최고의 분류 성능을 달성하였습니다: (a) 바나나 90.00%, 커피 90.54% 영양 결핍; (b) 감자 질병 96.18%, PlantDoc 데이터셋에서 84.30%. 또한, PND-Net은 다섯 번의 교차 검증을 통해 성능을 개선하였습니다.



### Optimizing 3D Geometry Reconstruction from Implicit Neural Representations (https://arxiv.org/abs/2410.12725)
- **What's New**: 이 논문에서는 3D 도형의 표현에 있어 Implicit Neural Representations (INR)의 한계점을 극복하기 위한 새로운 접근 방식을 제안합니다. 기존의 방법들이 높은 주파수 세부 정보를 유지하는 데 어려움을 겪을 때, 이 방법은 계산 비용을 줄이면서 정교한 세부 사항을 포착할 수 있도록 설계되었습니다.

- **Technical Details**: 이 방법은 주기적 활성화 함수(periodic activation functions), 위치 인코딩(positional encodings), 그리고 노멀(normals)을 신경망 아키텍처에 통합합니다. 이를 통해 3D 도형의 전체 공간을 보다 효과적으로 학습하고, 복잡한 형상의 날카로운 특징을 보존하는 능력이 향상됩니다.

- **Performance Highlights**: 제안된 모델은 DeepSDF에 비해 정량적 및 정성적 비교에서 몇 배의 향상을 이루었으며, 더 큰 모델과 데이터셋으로 확장하는 데 필요한 훈련 시간을 상당히 단축시켰습니다. 실험적으로 다양한 주기적 활성화 함수와 위치 인코딩 방법의 효능을 비교하여, 전체 3D 형상 공간을 학습하는 새로운 연속형 암묵적 신경 표현을 성공적으로 구현하였습니다.



### RAFA-Net: Region Attention Network For Food Items And Agricultural Stress Recognition (https://arxiv.org/abs/2410.12718)
- **What's New**: 이번 연구는 RAFA-Net이라 불리는 지역 주의 메커니즘을 도입하여 식품 및 농업 스트레스 인식의 품질을 높이는 방법을 제안합니다. 이 방법은 다양한 입력 이미지의 여러 영역 간 상관관계를 분석하여 긴 거리를 모델링할 수 있도록 합니다.

- **Technical Details**: RAFA-Net은 부분 특징 설명자(partial feature descriptors)의 유용성을 학습함으로써 피쳐 표현을 향상시키는 지역 주의 메커니즘을 포함합니다. 이 모델은 공간 피라미드 풀링(spatial pyramidal pooling)과 평균 풀링(average pooling)을 사용하여 각 지역 정보를 통합하여 포괄적인 표현을 생성합니다. 컨텍스트 게이팅(context gating) 기법이 사용되어 중요도가 높은 특성의 설명력을 정제합니다.

- **Performance Highlights**: RAFA-Net은 UECFood-100, UECFood-256 및 MAFood-121 데이터셋에서 각각 91.69%, 91.56%, 96.97%의 탑-1 정확도를 기록하며, IP-102 및 PlantDoc-27 데이터셋에서도 92.36%와 85.54%의 정확도를 달성함으로써 기존 방법들을 능가하는 성능을 보여주었습니다.



### Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization (https://arxiv.org/abs/2410.12700)
Comments:
          Accepted by ACM Multimedia 2024. The dataset and code can be found at this https URL

- **What's New**: 이번 연구에서는 인간의 가치와 정렬된 T2I(Text-to-Image) 모델을 위한 경량화된 방법인 LiVO(Lightweight Value Optimization)를 제안합니다. LiVO는 입력 프롬프트와 통합하여 이미지 생성을 제어할 수 있는 플러그 앤 플레이(value encoder) 값을 최적화합니다. 이는 T2I 모델과 인간의 가치 원칙을 효과적으로 연결합니다.

- **Technical Details**: LiVO는 기존 T2I 모델의 매개변수를 업데이트하지 않고도 사용자의 입력에 따라 적합한 가치 원칙을 선택할 수 있게 해줍니다. 이를 통해 생성된 이미지의 의미와 가치를 자연어 지침에 따라 조정할 수 있습니다. 연구팀은 86K 개의 (프롬프트, 정렬 이미지, 위반 이미지, 가치 원칙) 샘플로 이루어진 텍스트-이미지 가치 선호 데이터셋을 자동으로 구축하는 프레임워크를 개발했습니다.

- **Performance Highlights**: LiVO는 최소 20%의 데이터만으로 유해한 콘텐츠를 최대 66%까지 줄일 수 있으며, 여러 강력한 기준선을 초과하는 성능을 보였습니다. 또한, 즉각적인 수렴성을 달성하며 가치 정렬이 향상된 T2I 모델의 개발을 위한 초기 단계로 나아갑니다.



### AdaptiveDrag: Semantic-Driven Dragging on Diffusion-Based Image Editing (https://arxiv.org/abs/2410.12696)
- **What's New**: 본 논문에서는 사용자의 의도에 더욱 부합하는 유연한 점 기반 이미지 편집 방법인 AdaptiveDrag를 제안합니다. 기존 방법의 제한 사항을 극복하기 위해 자동 마스크 생성과 의미 기반 최적화를 활용합니다.

- **Technical Details**: AdaptiveDrag는 SLIC(Superpixel Linear Iterative Clustering)를 사용하여 자동으로 마스크를 생성합니다. 또한, 안착 점(handle points)과 목표 점(target points) 간의 연관성을 위해 대응 손실(corresponding loss) 함수를 도입하여 이미지 생성의 안정성을 높입니다. 이를 통해 사용자는 원하는 드래그 명령을 통해 이미지 편집을 수행할 수 있습니다.

- **Performance Highlights**: 다양한 드래그 명령(예: 크기 조정, 이동, 확장) 및 여러 도메인(예: 동물, 인물 사진, 경관, 의류)에서 실험을 수행한 결과 AdaptiveDrag가 기존 방법들보다 우수한 성능을 보였습니다.



### MultiCamCows2024 -- A Multi-view Image Dataset for AI-driven Holstein-Friesian Cattle Re-Identification on a Working Farm (https://arxiv.org/abs/2410.12695)
Comments:
          26 pages, 10 figures

- **What's New**: MultiCamCows2024 데이터셋을 소개합니다. 이는 다양한 카메라에서 촬영된 유일한 홀스타인-프리지안 소의 생체 인식용 이미지 데이터셋으로, 흑백 이 유전적 패턴을 활용하여 개별 소를 식별합니다.

- **Technical Details**: 3대의 천장 장착 카메라로 7일 동안 촬영한 90마리의 소에 대한 101,329개의 이미지와 CCTV 원본 영상을 포함합니다. 이 데이터셋은 감독(supervised) 및 자가 감독(self-supervised) 학습의 기초가 되는 컴퓨터 비전 인식 방법과 함께 제공됩니다.

- **Performance Highlights**: 단일 이미지 인식 정확도가 96%를 초과하며, 여러 카메라의 데이터를 결합한 학습이 자가 감독 식별의 성능을 향상시킵니다. 우리의 시스템은 완전 자동화된 소 식별을 가능하게 하며, 인간의 데이터 수집 과정에서의 단순한 트랙렛 무결성 확인만 필요로 합니다.



### VividMed: Vision Language Model with Versatile Visual Grounding for Medicin (https://arxiv.org/abs/2410.12694)
- **What's New**: 최신 연구에 따르면, Vision Language Models (VLMs)의 발전은 시각적으로 기반을 둔 응답 생성에서 놀라운 가능성을 보여주고 있습니다. 그러나 의료 분야에서는 특정 도전 과제가 존재합니다. VividMed라는 새로운 모델은 이 문제를 해결하기 위해 다양한 시각적 기반을 제공하고, 2D 및 3D 이미지를 모두 처리할 수 있도록 설계되었습니다.

- **Technical Details**: VividMed는 세 가지 단계의 훈련 과정과 자동 데이터 주석 파이프라인을 통해 학습됩니다. 이 모델은 세분화 마스크와 인스턴스 수준의 경계 상자를 동시에 생성할 수 있으며, Segment Anything Model (SAM)을 기반으로 한 시각적 기반 기능을 통합하여 성능을 향상시킵니다. VividMed는 다양한 의료 영상 모달리티를 처리할 수 있습니다.

- **Performance Highlights**: 실험 결과, VividMed는 기존 VLMs의 시각적 기반 작업에서 우수한 성능을 보이며, Visual Question Answering (VQA) 및 보고서 생성과 같은 일반적인 하위 작업에서도 경쟁력 있는 성과를 나타냈습니다. 시각적 기반 능력을 통합함으로써, VividMed는 다른 하위 작업에서도 성능 향상을 이루었습니다.



### Machine Learning Approach to Brain Tumor Detection and Classification (https://arxiv.org/abs/2410.12692)
Comments:
          7 pages, 2 figures, 2 tables

- **What's New**: 이 연구는 뇌 MRI 이미지에서 뇌 종양을 감지하고 분류하기 위해 다양한 통계 및 머신러닝 모델을 적용하여, 머신러닝 접근법이 의료 분야에서의 조기 진단을 지원할 수 있는지를 보여줍니다.

- **Technical Details**: 연구에서 선형, 로지스틱, 베이esian 회귀와 같은 통계 모델과 결정 트리(decision tree), 랜덤 포레스트(random forest), 단일 층 퍼셉트론(single-layer perceptron), 다층 퍼셉트론(multi-layer perceptron), 합성곱 신경망(convolutional neural network, CNN), 순환 신경망(recurrent neural network), 장단기 메모리(long short-term memory)와 같은 여러 머신러닝 모델을 탐구했습니다.

- **Performance Highlights**: CNN 모델이 다른 모델들보다 우수한 성능을 보여주었으며, 정상, 교모세포종(glioma), 수막종(meningioma), 뇌하수체 종양(pituitary tumor) 등 4개 카테고리의 뇌 MRI 이미지에 대해 다중 클래스 분류가 가능함을 확인했습니다.



### Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2 (https://arxiv.org/abs/2410.12686)
Comments:
          6 pages, 2 figures, 1 table

- **What's New**: 최근 연구에 따르면, Llama-2와 같은 최신 대형 언어 모델(LLMs)은 의료 이미징 도메인에서 해부학적 랜드마크의 위치를 정확하게 나타낼 수 있는 가능성을 보여주고 있습니다. 이 연구는 이러한 모델들이 의료 이미징 워크플로우의 효율성과 정확성을 높일 수 있는 잠재력을 가지고 있다는 점을 강조합니다.

- **Technical Details**: 연구는 Llama-2 모델의 내부 신경 활성화를 선형적으로 조사하여 해부학적 랜드마크의 위치를 예측하는 방식을 사용했습니다. 각 랜드마크에 대한 명칭과 그에 대응하는 공간 좌표를 포함한 데이터세트를 구성하였으며, ridge regression 모델을 통해 위치 예측의 정확성을 평가했습니다. 또한, 비선형 검사를 위해 다층 퍼셉트론(MLP)을 사용하여 결과를 비교했습니다.

- **Performance Highlights**: Llama-2 모델은 다양한 프롬프트에 대해 해부학적 랜드마크를 선형적으로 robust하게 표현할 수 있음을 보여주었습니다. 모델의 성능은 랜드마크 크기 표현에서도 선형성을 나타내었으며, 이는 의료 이미징 보고서에서의 자동화된 해석에 기여할 것으로 기대됩니다.



### MambaBEV: An efficient 3D detection model with Mamba2 (https://arxiv.org/abs/2410.12673)
- **What's New**: 본 논문에서는 mamba2를 기반으로 한 3D 객체 탐지 모델인 MambaBEV를 제안하였습니다. 이 모델은 자율주행 시스템에서의 성능을 높이기 위해 BEV(조감뷰) 패러다임을 활용하여 시간 정보를 통합하는 새로운 접근 방식을 사용합니다.

- **Technical Details**: Mamba2는 구조화된 상태 공간 모델(SSM)을 기초로 하여, 효율적인 훈련 속도와 메모리 사용을 달성합니다. 이 모델은 BEV 피쳐를 통합하기 위한 TemporalMamba라는 시간 융합 모듈과 mamba-CNN 모듈을 사용하여 다양한 프레임에서 BEV 특성을 융합합니다. 디코더 레이어에서는 mamba-cross attention 모듈을 기반으로 한 Mamba-DETR 헤드를 설계하였습니다.

- **Performance Highlights**: 제안된 MambaBEV 모델은 nuScenes 데이터셋에서 51.7% NDS(성능 지표)를 달성하며, 자율주행 시스템에서의 가능성을 보여줍니다. 이 성능은 기존 모델들에 비해 우수한 결과를 나타냅니다.



### 3DIS: Depth-Driven Decoupled Instance Synthesis for Text-to-Image Generation (https://arxiv.org/abs/2410.12669)
Comments:
          10 pages

- **What's New**: 이번 연구에서는 Depth-Driven Decoupled Instance Synthesis (3DIS)라는 새로운 프레임워크를 소개합니다. 3DIS는 multi-instance generation (MIG) 프로세스를 두 가지 단계로 분리하여 인스턴스의 배치와 속성 렌더링 문제를 해결합니다. 이는 텍스트-이미지 생성 기술의 제어 가능한 출력을 요구하는 최근의 추세를 반영하고 있습니다.

- **Technical Details**: 3DIS는 (i) 정밀한 인스턴스 배치 및 장면 구성을 위한 조잡한 장면 깊이 맵을 생성하는 단계와 (ii) 추가 학습 없이 pretrained ControlNet을 사용하여 세밀한 속성을 렌더링하는 단계로 나뉘어 있습니다. 이 프레임워크는 LDM3D와 통합된 사용자 정의 어댑터를 통해 정확한 깊이 기반 레이아웃을 생성합니다.

- **Performance Highlights**: COCO-Position과 COCO-MIG 벤치마크에서 3DIS는 기존 방법보다 레이아웃 정밀도 및 속성 렌더링에서 상당한 성능 향상을 보였습니다. 3DIS는 COCO-Position에서 이전 방법에 비해 16.3%의 AP75 향상을 달성하였고, COCO-MIG에서는 트레이닝 없는 속성 렌더링 접근법이 35%의 Instance Attribute Success Ratio 개선을 기록했습니다.



### Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models (https://arxiv.org/abs/2410.12662)
- **What's New**: 본 연구에서는 Large Vision-Language Models (LVLMs)의 비주얼 입력에 대한 안전 메커니즘의 전이 부족 문제를 다룹니다. 현재의 방법론이 비주얼 모달리티에 대해 안전 메커니즘을 효과적으로 전이하지 못함을 발견하고, Text-Guided vision-language Alignment (TGA)라는 새로운 방법을 제안합니다.

- **Technical Details**: TGA는 입력된 비전과 관련된 텍스트를 검색하여 LLMs의 hidden states 공간으로 비전을 투영하는 데 도움을 줍니다. 이로써 이미지의 hidden states와 텍스트의 hidden states 간의 정렬을 이루게 됩니다. 연구 결과, TGA는 기존 LLMs의 안전 메커니즘을 비전으로 성공적으로 전이할 수 있음을 보여주었습니다.

- **Performance Highlights**: TGA는 안전한 결과를 도출하며, InstructBLip, LLaVA-1.5 및 Qwen-VL-Chat과 같은 기존의 최첨단 LVLM들과 비교할 때 다양한 비전 작업에서 일반 성능을 유지합니다.



### DocLayout-YOLO: Enhancing Document Layout Analysis through Diverse Synthetic Data and Global-to-Local Adaptive Perception (https://arxiv.org/abs/2410.12628)
Comments:
          Github Repo: this https URL

- **What's New**: 본 논문에서는 Document Layout Analysis(DLA, 문서 레이아웃 분석)의 효율성을 개선하기 위해 DocLayout-YOLO라는 새로운 접근 방식을 소개합니다. 이 방법은 텍스트와 비주얼 특성을 활용하여 정확성을 높이고, 문서 특정 최적화를 통해 속도 장점을 유지합니다.

- **Technical Details**: DocLayout-YOLO는 Mesh-candidate BestFit 알고리즘을 적용하여 다양한 문서 레이아웃 데이터셋인 DocSynth-300K을 생성합니다. 이 알고리즘은 문서 합성을 2차원 빈 포장 문제로 설정하여 강력한 사전 학습을 수행합니다. 추가적으로, Global-to-Local Controllable Receptive Module(GL-CRM)을 도입하여 다양한 크기의 문서 요소를 효과적으로 처리하고, 여러 문서 타입에 대한 성능을 검증하기 위한 복잡한 벤치마크인 DocStructBench를 소개합니다.

- **Performance Highlights**: DocLayout-YOLO는 mAP(Mean Average Precision) 점수에서 각각 70.3%, 79.7%, 78.8%를 기록하며, 초당 85.5 프레임(FPS)의 속도로 다양한 문서에 대해 실시간 레이아웃 분석을 가능하게 합니다.



### CMAL: A Novel Cross-Modal Associative Learning Framework for Vision-Language Pre-Training (https://arxiv.org/abs/2410.12595)
Comments:
          vision-language pre-training, contrastive learning, cross-modal, associative learning, associative mapping classification

- **What's New**: 이 논문에서는 Cross-Modal Associative Learning (CMAL)라는 새로운 프레임워크를 제안하여 Vision-Language Pre-training (VLP) 모델이 가지는 비대칭성, 비정상성, 그리고 지역 제한과 같은 한계점을 해결하고자 한다. 이는 앵커 포인트 감지 및 교차 모달 연관 학습을 활용하여 이미지-텍스트 쌍의 표현력을 향상시킬 수 있도록 한다.

- **Technical Details**: CMAL 프레임워크는 비주얼 객체와 텍스트 토큰을 각각 하이퍼스피어 공간에 내장하여 intra-modal hidden features를 학습한 후, 교차 모달 연관 프롬프트 레이어를 설계하여 앵커 포인트 마스킹 및 기능 스와핑을 통해 하이브리드 교차 모달 연관 프롬프트를 구축한다. 이어서 통합된 의미 인코더를 이용해 이들의 교차 모달 상호작용 기능을 학습하고, 마지막으로 연관 매핑 분류 레이어를 통해 앵커 포인트 간의 잠재적 연관 매핑을 학습한다.

- **Performance Highlights**: CMAL은 네 가지 대표적인 V+L 작업에 대한 실험 결과, 이전 CMCL 기반 방법들과 비교하여 경쟁력 있는 성능을 보여주었다. 특히 SNLI-VE와 REC (testA)에서 새로운 최첨단 결과를 기록하였다.



### Cocoon: Robust Multi-Modal Perception with Uncertainty-Aware Sensor Fusion (https://arxiv.org/abs/2410.12592)
Comments:
          23 pages

- **What's New**: Cocoon은 객체 및 기능 수준의 불확실성을 인식하고 이를 기반으로 하는 새로운 융합 프레임워크로, multi-modal 데이터의 다양한 표현 방식을 비교할 수 있게 구현되었습니다. 기존의 MoE 기반 적응형 융합 및 지연 융합 방식의 한계를 극복하는 방향으로 설계되었습니다.

- **Technical Details**: Cocoon은 객체 레벨 및 기능 레벨의 불확실성을 정량화하며, 학습 가능한 서브그라운드 트루스인 Feature Impression을 도입하여 불확실성의 측정을 효과적으로 지원합니다. 이를 통해 서로 다른 모달리티 간의 공정한 비교를 가능하게 하며, 학습 목표를 설정하여 유효한 불확실성 정량화 메트릭을 제공합니다.

- **Performance Highlights**: Cocoon은 nuScenes 데이터셋에서 기존의 정적 및 다른 적응형 방법보다 우수한 결과를 보여주었으며, 특히 카메라 고장과 같은 도전적인 시나리오에서도 베이스 모델의 mAP를 15% 향상시키는 성능을 보였습니다.



### Rethinking Visual Counterfactual Explanations Through Region Constrain (https://arxiv.org/abs/2410.12591)
Comments:
          Preprint

- **What's New**: 이번 논문에서는 Visual Counterfactual Explanations (VCEs)의 한계를 극복하기 위해 지역 제약을 설정하는 방법인 지역 제약 VCEs (RVCEs)를 제안합니다. 기존 방법들이 이미지의 여러 부분을 혼합하여 수정할 때 발생하는 문제를 해결하고자 하며, RVCE는 한정된 지역만 수정하여 모델의 예측에 영향을 미칩니다.

- **Technical Details**: RVCEs는 결정론적 조건부 인페인팅 문제를 해결하는 것으로, 결정자에서 유래한 신호를 기반으로 합니다. 이를 위해 Regional-Constrained Counterfactual Schrödinger Bridges (RCSB)라는 새로운 알고리즘을 도입하며, 이는 이미지 생성 과정에서 효율적이고, 사실적이며, 원본에 가깝게 RVCEs를 합성하는 데 도움을 줍니다.

- **Performance Highlights**: RCSB 방법은 ImageNet 데이터셋에서 기존 방식에 비해 FID에서 최대 4배, sFID에서 3배, COUT에서 2배 더 우수한 성능을 보여줍니다. 이 연구는 RVCEs가 모델의 의사결정을 명확히 이해할 수 있도록 돕고, 사용자가 수동으로 수정 지역을 정의하며 상호작용할 수 있는 기능을 제공합니다.



### FTII-Bench: A Comprehensive Multimodal Benchmark for Flow Text with Image Insertion (https://arxiv.org/abs/2410.12564)
Comments:
          Work in progress. 9 pages, 3 figures

- **What's New**: 대형 비전-언어 모델(LVLMs)의 성능을 종합적으로 평가하기 위해 새로운 도전 과제인 Flow Text with Image Insertion task (FTII)를 제안합니다.

- **Technical Details**: 이 과제는 LVLM이 이미지 이해, 지시 이해, 장문 해석의 뛰어난 능력을 동시에 요구합니다. LVLM은 주어진 텍스트 단락에 적합한 이미지를 후보 이미지 중에서 선택하여 삽입해야 합니다.

- **Performance Highlights**: FTII 작업에서 가장 진화된 모델인 GPT-4o조차도 상당한 도전에 직면하고 있으며, 625개의 고품질 기사를 사용하여 평가한 결과, LVLM의 한계가 드러났습니다.



### Adaptive Prompt Learning with SAM for Few-shot Scanning Probe Microscope Image Segmentation (https://arxiv.org/abs/2410.12562)
Comments:
          10 pages, 7 figures

- **What's New**: 이번 연구에서는 Adaptive Prompt Learning with SAM (APL-SAM)라는 새로운 프레임워크를 제안하여, Scanning Probe Microscope (SPM) 이미지의 few-shot segmentation에 맞춤화된 접근 방식을 제공합니다.

- **Technical Details**: APL-SAM은 두 가지 주요 혁신을 포함합니다. 첫째, Adaptive Prompt Learning 모듈은 제한된 support set에서 파생된 few-shot embeddings를 이용하여 중심 대표를 학습하여 시각적 프롬프트로 활용합니다. 둘째, 여러 출처 및 다단계 마스크 디코더를 도입하여 support 이미지와 query 이미지 간의 대응 관계를 효과적으로 캡처합니다.

- **Performance Highlights**: APL-SAM은 새로 만든 SPM-Seg 데이터셋에서 원본 SAM보다 30% 이상의 Dice Similarity Coefficient 향상을 이루었고, 기존의 최첨단 few-shot segmentation 방식 및 Fully Supervised 접근 방식보다 우수한 성능을 보여줍니다.



### Development of Image Collection Method Using YOLO and Siamese Network (https://arxiv.org/abs/2410.12561)
Comments:
          15 pages, 13 figures, 2 tables

- **What's New**: 본 논문에서는 웹 크롤링(web crawling) 방식의 데이터 수집에서 발생하는 비의도적 데이터 문제를 해결하기 위해 YOLOv10 객체 인식 모델을 사용하고, SIAMese 네트워크를 통해 재분류(image reclassification)를 수행함으로써 성능을 향상시켰음을 보여줍니다.

- **Technical Details**: YOLOv10 모델을 사용하여 웹 크롤링으로 수집된 데이터 중 불필요한 데이터를 필터링하고, SIAMese 네트워크의 거리 출력을 추가적으로 활용하여 이미지 재분류를 진행했습니다. 특히, 사용자들은 거리 임계값(threshold)을 지정하여 데이터 부족(data deficiency)과 잡음 저항성(noise-robustness) 간의 균형을 조절할 수 있습니다.

- **Performance Highlights**: 평균 f1 점수는 YOLO+MobileNet에서 0.678에서 YOLO+SiameseNet으로 0.772로 증가했습니다. 비컷(cropped) 이미지의 사용에 효과적으로 자원을 적게 사용하면서도 성능을 높일 수 있음을 보였으며, non-crop+Siamese(MobileNetV3-Small)에서 80.94가 컷 전처리(crop preprocessing)+Siamese(MobileNetV3-Small)에서 82.31로 상승했습니다.



### Shaping a Stabilized Video by Mitigating Unintended Changes for Concept-Augmented Video Editing (https://arxiv.org/abs/2410.12526)
- **What's New**: 이 논문에서는 개념을 증강한 비디오 편집(concept-augmented video editing) 접근 방식을 제안하여 텍스트 기반 비디오 편집의 유연성을 향상시킵니다. 기존 접근 방식의 한계를 극복하고 보다 세밀한 편집을 가능하게 합니다.

- **Technical Details**: 제안된 프레임워크는 개념 증강 텍스트 변환(concept-augmented textual inversion)과 이중 사전 감독 메커니즘(dual prior supervision mechanism)을 포함합니다. 이를 통해 비디오 편집을 위한 안정적인 확산(stable diffusion)의 플러그 앤 플레이(plug-and-play) 안내가 가능해지며, 태그 속성을 보다 잘 포착할 수 있습니다.

- **Performance Highlights**: 이 접근 방식은 더 안정적이고 생동감 있는 비디오를 생성하며, 기존의 최첨단 방법(state-of-the-art methods)을 초월하는 성능을 보여줍니다.



### MambaPainter: Neural Stroke-Based Rendering in a Single Step (https://arxiv.org/abs/2410.12524)
Comments:
          Accepted to SIGGRAPH Asia 2024 posters

- **What's New**: 이번 연구에서는 MambaPainter를 제안하여 단일 추론 단계에서 100개 이상의 브러시 스트로크(brush strokes)를 예측할 수 있게 되어 번역 속도를 크게 개선했습니다.

- **Technical Details**: MambaPainter는 선택적 상태 공간 모델(selective state-space model)을 도입하여 브러시 스트로크의 시퀀스를 예측하는 기술을 활용합니다. 또한 패치 기반 렌더링(patch-based rendering)에 대한 간단한 확장을 통해 고해상도 이미지를 변환할 수 있도록 하여 시각적 품질을 향상시킵니다.

- **Performance Highlights**: 실험 결과, MambaPainter는 최첨단(state-of-the-art) 방법들과 비교했을 때 입력을 오일 페인팅 스타일의 이미지로 효율적으로 변환할 수 있음을 보여주었습니다.



### QueensCAMP: an RGB-D dataset for robust Visual SLAM (https://arxiv.org/abs/2410.12520)
Comments:
          6 pages

- **What's New**: 이번 논문은 VSLAM의 강건성을 평가하기 위해 설계된 새로운 RGB-D 데이터셋을 소개합니다. 이 데이터셋은 동적 객체, 모션 블러(motion blur), 다양한 조명 조건을 포함한 실제 실내 장면으로 구성되어 있으며, 렌즈 오염(lens dirt), 응습(condensation), 과소 노출(underexposure), 과다 노출(overexposure)과 같은 카메라 고장도 시뮬레이션합니다.

- **Technical Details**: 이 데이터셋은 Vicon 모션 캡처 시스템을 사용하여 수집되었으며, 30Hz의 정확한 6DoF 위치 측정을 제공합니다. RGB 이미지는 1920x1080 해상도, 깊이 이미지는 640x480 해상도로 수집되어 있습니다. 1616개 시퀀스에서 총 28523 이미지를 캡처했으며, 고장 유도에 대한 추가 시퀀스도 포함되어 있습니다. 고장은 시뮬레이션을 통해 생성되며, 공개된 오픈 소스 스크립트를 통해 연구 커뮤니티가 커스터마이즈할 수 있도록 제공됩니다.

- **Performance Highlights**: 실험 결과, 전통적인 VSLAM 알고리즘인 ORB-SLAM2와 딥러닝 기반 VO 알고리즘인 TartanVO가 이러한 도전적인 조건에서 성능 저하를 겪음을 보여줍니다. 이는 생성된 데이터셋과 카메라 고장 도구들이 더 강건한 VSLAM 시스템 개발에 유용한 자원이 됨을 시사합니다.



### DH-VTON: Deep Text-Driven Virtual Try-On via Hybrid Attention Learning (https://arxiv.org/abs/2410.12501)
Comments:
          5 pages, 6 figures, ICASSP2025

- **What's New**: DH-VTON이라는 새로운 가상 착용(Virtual Try-ON) 모델을 제안합니다. 이 모델은 하이브리드 주의 학습 전략(hybrid attention learning strategy)과 깊은 의류 의미 보존 모듈(deep garment semantic preservation module)을 특징으로 합니다.

- **Technical Details**: 해당 모델은 InternViT-6B를 사용하여 깊이 있는 의류의 세부 특징을 학습하고, Garment-Feature ControlNet Plus (GFC+) 모듈을 통해 의류의 다양한 특성을 VTON 모델의 여러 층에 통합합니다. 이로 인해 다중 스케일 기능 보존(multi-scale features preservation) 효과를 달성할 수 있습니다.

- **Performance Highlights**: 다양한 대표 데이터셋에 대한 실험에서 DH-VTON은 기존의 diffusion 기반 및 GAN 기반 접근 방식보다 뛰어난 성능을 보여주며, 의류의 세부 사항을 잘 보존하고 사실적인 인간 이미지를 생성하는 데 경쟁력을 갖추고 있습니다.



### Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspectiv (https://arxiv.org/abs/2410.12490)
Comments:
          Accepted at NeurIPS 2024

- **What's New**: 최근 Latent Diffusion Models (LDMs)와 Mask Image Models (MIMs)와 같은 latent 기반 이미지 생성 모델이 이미지 생성 작업에서 뛰어난 성과를 거두었습니다. 그러나 autoregressive 모델이 LDMs와 MIMs에 비해 이미지 생성에서 상당히 뒤처져 있다는 흥미로운 관찰이 있었습니다. 이 발견은 NLP 분야와의 뚜렷한 대조를 이룹니다.

- **Technical Details**: 저자들은 이미지 생성 모델링에서 latent space의 안정성을 강조하며, 이를 위해 간단하지만 효과적인 이산 이미지 토크나이저(Tokenizer)를 제안하였습니다. 이 토크나이저(DiGIT)를 사용한 이미지 autoregressive 모델링은 이미지 이해 및 생성 과정에서 이점을 보여주었으며, 이는 기본적으로 GPT 모델에 대해 간단한 원칙입니다.

- **Performance Highlights**: 처음으로, GPT 스타일의 autoregressive 모델이 LDMs를 초월하는 성능을 보여주었으며, 모델 크기를 늘림에 따라 GPT와 유사한 상당한 개선을 또한 보여주었습니다. 이 결과는 최적화된 latent space와 이산 토큰화의 통합이 이미지 생성 모델의 능력을 향상할 수 있는 잠재력을 강조합니다.



### Synthetic Augmentation for Anatomical Landmark Localization using DDPMs (https://arxiv.org/abs/2410.12489)
Comments:
          Accepted for the SASHIMI workshop of MICCAI 2024

- **What's New**: 이 연구에서는 Denoising Diffusion Probabilistic Models (DDPMs)를 활용하여 의료 이미지를 생성하고, 해당 이미지를 통해 Anatomy Landmark Localization (ALL) 모델의 훈련을 개선하는 새로운 접근 방식을 탐구합니다.

- **Technical Details**: DDPM은 2채널 입력을 사용하여 원본 의료 이미지와 주석이 달린 랜드마크의 Heatmap을 통합합니다. 또한, 랜드마크 매칭을 위해 Markov Random Field (MRF) 모델을 사용하고, 랜드마크의 가능성을 검증하기 위해 Statistical Shape Model (SSM)을 도입합니다.

- **Performance Highlights**: 손 X-Ray를 포함하는 ALL 작업에서 DDPM으로 증강된 데이터셋이 기존 방법들과 비교해 성능 개선을 보일 것으로 예상됩니다.



### Mind the Gap Between Prototypes and Images in Cross-domain Finetuning (https://arxiv.org/abs/2410.12474)
- **What's New**: 교차 도메인 몇 샷 분류(Cross-Domain Few-Shot Classification) 분야에서 새로운 접근 방식을 제안합니다. 이 방식은 프로토타입과 이미지 인스턴스의 임베딩 간의 변환 차이를 줄이고, 최적의 표현 탐색을 용이하게 합니다.

- **Technical Details**: 본 논문에서는 프로토타입과 이미지 인스턴스의 임베딩이 동일한 표현 변환을 공유한다는 기존 가정이 틀렸음을 발견했습니다. 이를 해결하기 위해, contrastive prototype-image adaptation (CoPA) 방법을 제안하며, 이는 CLIP와 유사하게 프로토타입을 텍스트 프롬프트로 취급하여 각각 다른 변환을 적용합니다.

- **Performance Highlights**: Meta-Dataset에서 수행된 실험에 따르면, CoPA는 효율적으로 최신 성능(state-of-the-art performance)을 달성했으며, 더 나은 표현 클러스터를 학습하고, 갭(gap)을 확대하여 최소 검증 손실(minimal validation loss)을 달성했습니다.



### Beyond Coarse-Grained Matching in Video-Text Retrieva (https://arxiv.org/abs/2410.12407)
Comments:
          Accepted to ACCV 2024

- **What's New**: 비디오-텍스트 검색(video-text retrieval)에 대한 새로운 접근 방식이 제시되었습니다. 특히, 기존 데이터셋에 대해 미세하게 변형된 하드 네거티브 테스트 캡션을 자동으로 생성하는 방법을 도입하였습니다.

- **Technical Details**: 제안된 방법은 네 개의 시각적으로 최신(state-of-the-art) 모델을 사용하여 두 개의 표준 벤치마크(MSR-VTT, VATEX)와 두 개의 상세한 설명이 포함된 특별 데이터셋(VLN-UVO, VLN-OOPS)에서 실험을 수행합니다. 모델의 미세한 단어 차이를 인식하는 능력을 검증하기 위해 기본적인 기준을 제안하였습니다.

- **Performance Highlights**: 전반적인 결과, 현재 평가 벤치마크가 모델이 미세 단어 차이를 감지하는 데 부족하다는 점과, 모델들이 이러한 미세한 변화를 구별하는 데 어려움을 겪는다는 점을 발견하였습니다. 제안된 미세 평가 방법은 모델의 미세한 이해 능력을 향상시키는 데 효과적임이 입증되었습니다.



### Feature Augmentation for Self-supervised Contrastive Learning: A Closer Look (https://arxiv.org/abs/2410.12396)
Comments:
          IJCNN 2024

- **What's New**: 이번 연구에서는 data augmentation (데이터 증강) 접근 방식의 한계를 극복하기 위해 feature augmentation (특징 증강)이라는 새로운 방법론을 제안합니다. 이는 데이터를 원래 입력 공간이 아닌 특징 공간에서 증강하여 일반화 및 견고성을 향상시키는 통합 프레임워크를 제공합니다.

- **Technical Details**: 특징 증강은 주어진 인스턴스의 다양한 뷰를 통해 대조 쌍을 구성하며, 이는 self-supervised contrastive learning (자기 감독 대조 학습)에서 더 나은 전이 성능을 달성하는 데 도움을 줍니다. 기존의 데이터 증강 전략의 한계로 도메인 의존성, 작업 편향, 유연성 부족 등이 있으며, 특징 증강은 이러한 문제를 개선합니다.

- **Performance Highlights**: 제안된 특징 증강 프레임워크는 instance discrimination (인스턴스 분별) 및 instance similarity (인스턴스 유사성) 프레임워크와 통합됨으로써, 이미지 분류 및 객체 탐지 작업에서 일관된 성능 향상을 보여줍니다. 이로써 모델의 일반화와 견고성이 개선됩니다.



### Real-time Stereo-based 3D Object Detection for Streaming Perception (https://arxiv.org/abs/2410.12394)
Comments:
          Streaming Perception, 3D Object Detection, NeurIPS2024 poster

- **What's New**: 새로운 작업인 streaming perception이 도입되었습니다. 이는 비디오 온라인 인식(video online perception)에서 레이턴시(latency)와 정확성(accuracy)을 단일 메트릭으로 평가합니다.

- **Technical Details**: StreamDSGN은 streaming perception을 위해 설계된 첫 번째 실시간 stereo 기반 3D 객체 탐지(framework) 프레임워크입니다. 이 프레임워크는 과거 정보를 활용하여 다음 순간의 객체 3D 속성을 직접 예측하고, accuracy degradation을 완화합니다. 세 가지 전략을 통해 인식 정확도를 향상시킵니다: (1) feature-flow 기반 융합 방법, (2) 연속 프레임에서 객체 움직임 일관성(motion consistency)을 명시적으로 감독하는 추가 회귀 손실(extra regression loss), (3) 긴 범위의 공간적 컨텍스트(contextual features)를 효과적으로 캡처하는 대형 커널(backbone) 사용.

- **Performance Highlights**: KITTI Tracking 데이터셋 실험 결과, 강력한 baseline과 비교하여 StreamDSGN은 streaming average precision을 최대 4.33% 향상시켰습니다.



### HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks (https://arxiv.org/abs/2410.12381)
Comments:
          homepage this https URL

- **What's New**: 본 논문에서는 LLMs(대형 언어 모델)의 시각적 이해 및 추론 능력을 평가하기 위해 특별히 설계된 새로운 벤치마크인 HumanEval-V를 소개합니다. 이는 기존의 코딩 작업을 기반으로 하여, 고도로 세심하게 제작된 108개의 Python 코딩 과제를 포함합니다.

- **Technical Details**: HumanEval-V는 CodeForces 및 Stack Overflow와 같은 플랫폼에서 유래된 문제들을 바탕으로 각 과제를 수정하여, 문제의 맥락과 알고리즘 패턴을 변화시켰습니다. 각 과제는 제공된 시각적 컨텍스트와 특정 Python 함수 서명을 기반으로 해결되어야 하며, 모델이 생성한 솔루션의 철저하고 신뢰할 수 있는 평가를 보장하기 위해 정교하게 제작된 테스트 케이스가 부여됩니다.

- **Performance Highlights**: 19개의 최첨단 LMM들을 HumanEval-V를 사용해 평가한 결과, GPT-4o와 같은 독점 모델은 13%의 pass@1과 36.4%의 pass@10만을 달성하는 등 상당한 도전 과제가 드러났습니다. 70B 파라미터를 가진 오픈 웨이트 모델은 pass@1 기준으로 4% 미만의 점수를 기록했습니다. 이러한 결과는 현재 LMM의 시각적 추론 및 코딩 능력의 한계를 강조하며, 향후 연구의 주요 영역을 제시합니다.



### Stylistic Multi-Task Analysis of Ukiyo-e Woodblock Prints (https://arxiv.org/abs/2410.12379)
- **What's New**: 이 논문에서는 대규모 	extit{Ukiyo-e} (우키요에) 목판화 데이터셋을 제시합니다. 기존 서양 예술 중심의 데이터셋과 달리 일본의 전통 예술 형태를 탐구하여 예술적 스타일 분석의 범위를 넓히고 다양한 예술 중심 Computer Vision 접근법을 평가하기 위한 기준을 제공하는 것을 목표로 합니다.

- **Technical Details**: 우리의 데이터셋은 17세기부터 현재까지의 예술가(artist), 시대(era), 제작 날짜(creation date) 등의 메타데이터가 포함된 175,000개 이상의 인쇄물로 구성됩니다. 우리는 스타일 분석을 Multi-Task 문제로 접근하여 이용 가능한 메타데이터를 더 효율적으로 활용하고 스타일에 대한 보다 일반적인 표현을 학습하려고 합니다.

- **Performance Highlights**: 잘 알려진 기준선(baselines) 및 최첨단 멀티태스킹 학습 프레임워크에 대한 결과를 보여주어 향후 비교를 가능케 하고, 이 예술 영역에서의 스타일 분석을 장려하고자 합니다.



### GAN Based Top-Down View Synthesis in Reinforcement Learning Environments (https://arxiv.org/abs/2410.12372)
- **What's New**: 이 논문은 강화 학습(RL) 환경에서 인공 에이전트의 1인칭 관찰을 바탕으로 Generative Adversarial Network(GAN)를 이용하여 top-down view를 학습하는 방법을 탐구합니다.

- **Technical Details**: 기존의 작업들은 주로 에이전트의 행동을 통해 환경의 공간적 및 시간적 특성을 학습했습니다. 본 연구는 에이전트가 환경을 탐험함에 따라 부분적인 top-down view를 생성하고, 전체 환경을 맵핑할 수 있는 방식을 제안합니다. 특히, 3D 합성곱(Convolutions)과 Capsule Encoders의 사용은 공간적 및 시간적 정보를 효과적으로 캡처하는 데 기여합니다.

- **Performance Highlights**: 실험 결과, proposed models (3D convolutions, Capsule Encoders) 는 RL 환경에서 보이지 않는 spatio-temporal 장면의 완전한 표현을 해결하는 데 중요한 진전을 이루었습니다. 이 top-down view는 에이전트가 더 나은 정책 결정을 내리는 데 도움을 줄 수 있으며, 에이전트의 결정 과정을 향상시키는 데 사용될 수 있습니다.



### Context-Infused Visual Grounding for Ar (https://arxiv.org/abs/2410.12369)
- **What's New**: 이번 연구는 CIGAr (Context-Infused GroundingDINO for Art)라는 새로운 비주얼 그라운딩 접근 방식을 소개합니다. 이는 예술 작품의 설명을 학습 중 맥락(context)으로 활용하여 비주얼 그라운딩을 가능하게 하고, Ukiyo-eVG라는 새로운 데이터셋을 발표하여 예술 작품 데이터셋에서 객체 탐지의 최신 기술 성과를 달성했습니다.

- **Technical Details**: CIGAr는 Transform 기반의 비주얼 그라운딩 모델을 사용하여 예술 작품 이미지의 비주얼 요소를 텍스트 쿼리와 정렬합니다. 이는 Visual Grounding (VG) 모델을 통해 구현되며, 데이터 학습 시 제목과 설명이 포함되어 특히 예술 분야에서 관련 특징들을 학습할 수 있도록 돕습니다.

- **Performance Highlights**: IconArt 및 ArtDL 예술 작품 데이터셋에서 객체 탐지에 대한 새로운 최신 기술 성과를 달성했습니다. 또한, Ukiyo-eVG 데이터셋을 통해 최초의 예술 작품 비주얼 그라운딩 데이터셋을 개발하였습니다.



### Towards Flexible and Efficient Diffusion Low Light Enhancer (https://arxiv.org/abs/2410.12346)
Comments:
          7 pages

- **What's New**: 본 논문에서는 저조도 이미지 향상(Low-Light Image Enhancement, LLIE)을 위한 새로운 방식으로, 반사 인식 확산(Reflectance-aware Diffusion)과 증류 경로(Distilled Trajectory)를 결합한 ReDDiT 프레임워크를 제안합니다. 이 방법은 기존의 다단계 교사 모델의 성능에 필적하면서도 훨씬 효율적인 학생 모델을 생성합니다.

- **Technical Details**: ReDDiT 프레임워크는 교사 모델의 경로를 더 적은 단계에서 학생 모델이 복제하도록 훈련하며, 학생 모델이 교사 모델의 성능을 초월할 수 있는 기능을 포함합니다. 이를 위해, 교사 모델의 경로 디코더와 반사 인식 경로 정제 모듈(reflectance-aware trajectory refinement module)을 도입하여 교사 모델의 경로에서 결정론적(guided) 안내를 가능하게 합니다.

- **Performance Highlights**: ReDDiT는 2단계에서 기존의 10단계 확산 방식의 성능과 견줄 만한 결과를 보여주며, 심지어 4단계 및 8단계 모델에서는 새로운 최첨단(SOTA) 성능을 달성했습니다. 10개의 벤치마크 데이터셋에서 실행된 종합적인 실험 결과, ReDDiT는 기존 SOTA 방법들보다 일관되게 우수한 성능을 입증하였습니다.



### TAS: Distilling Arbitrary Teacher and Student via a Hybrid Assistan (https://arxiv.org/abs/2410.12342)
Comments:
          18 pages, 6 figures, and 12 tables

- **What's New**: 이번 연구는 전통적인 Teacher-Student 아키텍처에 의존하지 않고, Cross-Architecture Knowledge Distillation (CAKD) 접근 방식을 통해 동종 및 이종 모델 간의 지식 전이를 유연하게 수행하는 방법을 제안합니다.

- **Technical Details**: 이 연구는 heterogeneous teacher와 student 간의 특징 전이를 원활하게 하기 위한 보조 모델(assistant model)을 introduce하며, convolution과 attention 모듈을 결합하여 서로 다른 아키텍처의 이점들을 통합합니다. 또한 InfoNCE loss를 통해 특징의 spatial alignment를 개선하여 성능을 향상시킵니다.

- **Performance Highlights**: 제안된 CAKD 방법은 CNN, ViT, MLP 모델의 다양한 조합에서 평가되었으며, CIFAR-100에서 최대 11.47% 향상된 성능과 ImageNet-1K에서 3.67%의 성능 향상을 달성하여, state-of-the-art 성능을 기록했습니다.



### ARIC: An Activity Recognition Dataset in Classroom Surveillance Images (https://arxiv.org/abs/2410.12337)
Comments:
          arXiv admin note: text overlap with arXiv:2409.03354

- **What's New**: AI + Education 분야에서 활동 인식의 중요성이 증가하고 있습니다. 하지만 기존 연구는 주로 수동으로 촬영된 비디오의 활동 인식에 집중하고 있으며, 실제 교실의 감시 이미지에서 활동 인식에는 거의 관심이 없었습니다. 본 논문에서는 교실 감시 이미지에서의 활동 인식을 위한 새로운 멀티모달 데이터셋인 ARIC를 구축하였습니다.

- **Technical Details**: ARIC 데이터셋은 32개의 활동 카테고리, 세 가지 모달리티(modalities), 실제 교실 시나리오에 중점을 두고 있습니다. 이 데이터셋은 클래스 불균형(class imbalance) 및 높은 활동 유사성(high activity similarity) 등의 문제를 해결하기 위한 연구를 위한 기초 자료가 될 것입니다. 또한, 일반적인 활동 인식 작업 외에도 지속적 학습(continual learning) 및 소수 샷 지속적 학습(few-shot continual learning)을 위한 설정도 제공합니다.

- **Performance Highlights**: ARIC 데이터셋은 다양한 관점(multiple perspectives)에서 활동을 인식할 수 있는 장점을 가지고 있습니다. 이를 통해 Open Teaching 시나리오를 위한 미래의 분석 및 연구에 기여할 수 있기를 기대합니다.



### MC-Bench: A Benchmark for Multi-Context Visual Grounding in the Era of MLLMs (https://arxiv.org/abs/2410.12332)
- **What's New**: 이 논문은 다중모달 대형 언어 모델(MLLMs)에 대한 새로운 시각적 기반 작업인 multi-context visual grounding을 제안하며, 이는 여러 이미지에서 관심 있는 인스턴스를 텍스트 프롬프트에 기반하여 로컬라이즈하는 것을 목표로 합니다.

- **Technical Details**: 연구를 지원하기 위해 MC-Bench라는 새로운 데이터셋을 구성하였으며, 이는 2K개의 고품질 수작업 주석 샘플로 이루어져 있습니다. 데이터셋은 인스턴스 수준으로 레이블이 지정된 이미지 쌍과 이미지 내 타겟 인스턴스를 나타내는 텍스트 프롬프트를 포함합니다. 총 20가지 실용 기술을 포괄하는 세 가지 서로 다른 스타일의 텍스트 프롬프트가 특징입니다.

- **Performance Highlights**: 20개 이상의 최신 MLLM과 기본 모델의 성능을 벤치마킹한 결과, 모든 지표에서 기존 MLLMs과 인간 간의 성능 차이가 크다는 것을 발견하였습니다. 또한, 기존 MLLMs는 LLM이 없는 기본 모델보다 이미지 수준의 지표에서만 우수하며, 전문 MLLMs는 단일 이미지에 대해 훈련될 경우 다중 이미지 상황에 일반화하는 데 어려움을 겪습니다. 이전의 end-to-end MLLMs을 초월하는 형태로 고급 MLLM과 탐지기를 통합한 간단한 단계적 기준선이 눈에 띄는 성과를 보였습니다.



### FaceChain-FACT: Face Adapter with Decoupled Training for Identity-preserved Personalization (https://arxiv.org/abs/2410.12312)
Comments:
          12 pages, 8 figures

- **What's New**: 본 논문은 인물 식별 기능의 분리와 발전된 이미지 생성 방법을 제안한 Face Adapter with deCoupled Training (FACT) 프레임워크를 제시합니다. 이를 통해 텍스트-이미지 모델에서 인물의 정체성을 보존하면서도 정확도와 다양성을 높입니다.

- **Technical Details**: FACT는 transformer 기반의 얼굴 인식 모델을 통해 세분화된 정체성 기능을 활용하였으며, Gated Self-Attention (GSA) 모듈을 U-Net에 삽입해 얼굴 특징에 개별적으로 적응하도록 만들었습니다. 이를 통해 얼굴 영역에서의 변화를 제어하고, FAce Adapting Increment Regularization (FAIR) 기법을 통해 면밀한 조정을 압박합니다.

- **Performance Highlights**: 실험 결과, FACT는 기존의 adapter 기반 개인화 방법에 비해 아이덴티티 유사도, 텍스트 따른 생성 능력, 얼굴의 통제력 및 다양성에서 향상된 성능을 보였습니다. 또한, FACT는 LORA나 ControlNet 같은 기존의 세분화 모델과의 통합에서도 생성 성능을 저하시키지 않습니다.



### Controlled Automatic Task-Specific Synthetic Data Generation for Hallucination Detection (https://arxiv.org/abs/2410.12278)
- **What's New**: 이 논문에서는 환각 감지를 위한 비트리비얼(task-specific) 합성 데이터세트를 자동으로 생성하는 새로운 접근 방식을 제안합니다. 이 방법은 두 단계의 생성-선택 파이프라인을 특징으로 하며, 환각 패턴 지침(hallucination pattern guidance) 및 언어 스타일 정렬(language style alignment)을 활용하여 데이터 품질을 향상시킵니다.

- **Technical Details**: 제안된 방법은 자동화된 생성-선택 파이프라인을 기반으로 하며, 환각 패턴 가이드를 통해 특정 작업에 적합한 환각 샘플을 생성하고, 언어 스타일 정렬을 통해 합성 데이터의 스타일을 벤치마크 텍스트와 일치시킵니다. 이 방법은 세 가지 대화 벤치마크에서 실험을 통해 검증되었으며, F1 점수 0.938을 달성하여 기존의 인컨텍스트러닝(ICL) 기반 감지기를 32.5%의 큰 차이로 초과했습니다.

- **Performance Highlights**: 제안된 환각 감지기는 생성된 합성 데이터세트를 통해 훈련된 결과, 상기된 세 가지 차원에서 뛰어난 일반화 능력을 보여주었습니다. 또한, 생성된 합성 환각이 실제 비환각 샘플에 더 유사함을 입증하였으며, 이는 우리 접근 방식의 강력한 일반화 능력을 확인하였습니다.



### Fusion from Decomposition: A Self-Supervised Approach for Image Fusion and Beyond (https://arxiv.org/abs/2410.12274)
Comments:
          18page

- **What's New**: 본 논문에서는 self-supervised learning (SSL)을 활용하여 다양한 이미지 융합 작업을 위한 특성 표현의 다재다능성을 높이는 새로운 프레임워크인 DeFusion++를 소개합니다. 이 프레임워크는 큰 규모의 데이터에서 이미지 융합 작업에 적합한 표현을 효과적으로 캡처합니다.

- **Technical Details**: DeFusion++는 두 가지 혁신적인 사전 텍스트 작업인 common and unique decomposition (CUD)와 masked feature modeling (MFM)을 도입합니다. CUD는 소스 이미지를 일반적이고 독특한 구성 요소로 분해하며, MFM은 이러한 구성 요소를 견고한 융합 특성으로 정제합니다. 이 두 작업의 공동 훈련을 통해 DeFusion++는 다양한 소스 이미지로부터 유용한 정보를 효과적으로 추출할 수 있는 적응 가능한 표현을 생성합니다.

- **Performance Highlights**: DeFusion++는 이미지 융합 품질 및 단계적 고수준 비전 작업의 효율성을 높이는 다재다능한 융합 표현을 생성하며, 이미지 분할 및 객체 탐지와 같은 다양한 다운스트림 작업에 적용 가능합니다. 이 방법은 정량적 및 정성적 결과 모두에서 효과성을 입증했습니다.



### DaDiff: Domain-aware Diffusion Model for Nighttime UAV Tracking (https://arxiv.org/abs/2410.12270)
- **What's New**: 이번 연구는 저조도 환경에서의 드론(UAV) 추적을 위한 새로운 도메인 인식 디퓨전 모델(DaDiff)을 제안합니다. 이 모델은 야간 저해상도(LR) 물체의 특성을 낮 동안의 특성과 일치시키기 위해 점진적인 정렬 방식을 사용합니다.

- **Technical Details**: DaDiff는 특성 정보를 향상시키기 위한 alignment encoder, 추적 작업과의 밀접한 협업을 위한 tracking-oriented layer, 각 디퓨전 타임스텝에서의 다양한 특성 분포를 구분하는 successive distribution discriminator를 포함합니다. 이러한 구성 요소들은 특성 일치의 안정성을 높이고 LR 물체의 세부 정보를 강화하는데 기여합니다.

- **Performance Highlights**: DaDiff는 100개의 주석 처리된 시퀀스로 구성된 NUT-LR 벤치마크에서 평가되었으며, 강력한 특성 정렬 능력과 견고한 성능을 입증했습니다. 이 결과는 기존의 일 단계 적응 패러다임 대비 UA 추적 성능을 현저히 향상시킨 것을 보여줍니다.



### LoD-Loc: Aerial Visual Localization using LoD 3D Map with Neural Wireframe Alignmen (https://arxiv.org/abs/2410.12269)
Comments:
          Accepted by NeurIPS 2024; for Project page, see this https URL

- **What's New**: LoD-Loc이라는 새로운 방법을 제안하며, 기존의 복잡한 3D 표현을 사용하지 않고도 UAV의 위치를 추정할 수 있습니다.

- **Technical Details**: LoD-Loc은 주어진 UAV 센서에 의해 제공된 coarse pose를 바탕으로 포즈 가설을 균일하게 샘플링하여 포즈 확률 분포를 설명하는 cost volume을 계층적으로 구축합니다. 각 cost는 투영된 wireframe과 예측된 wireframe 간의 정렬 정도를 측정합니다. 6-DoF pose 최적화 알고리즘을 사용하여 이전 결과를 더욱 정교하게 다듬습니다.

- **Performance Highlights**: LoD-Loc은 LoD3.0 및 LoD2.0 맵 수준의 두 개의 데이터셋을 수집하고, 텍스처가 있는 3D 모델을 사용하는 기존 최첨단 방법들을 초월하는 뛰어난 성능을 자랑합니다.



### Optimizing YOLOv5s Object Detection through Knowledge Distillation algorithm (https://arxiv.org/abs/2410.12259)
- **What's New**: 이 논문은 target detection(타겟 탐지) 작업에서 knowledge distillation(지식 증류) 기술의 적용을 탐구하며, 학생 모델의 성능에 미치는 다양한 distillation temperature(증류 온도)의 영향을 분석합니다.

- **Technical Details**: YOLOv5l을 teacher network(교사 네트워크)으로, 더 작은 YOLOv5s를 student network(학생 네트워크)으로 사용하여, distillation temperature가 증가함에 따라 학생의 탐지 정확도가 점진적으로 향상됨을 발견했습니다. 이는 특정 온도에서 원래 YOLOv5s 모델보다 더 나은 mAP50 및 mAP50-95 지표를 달성했습니다. 또한, 모델 훈련 과정에서 정확도 커브(accuracy curve)와 손실 함수 하강 커브(loss function descent curve)를 자세히 기록하였고, 모델은 150회 훈련 후 안정적인 상태로 수렴함을 보여줍니다.

- **Performance Highlights**: 적절한 knowledge distillation 전략이 모델의 정확도를 향상시킬 뿐만 아니라, 실제 애플리케이션에서 모델의 신뢰성과 안정성 개선에도 기여할 수 있음을 보여줍니다. 이 연구 결과는 target detection 알고리즘 최적화를 위한 이론적 기초와 기술적 참고 자료를 제공합니다.



### EG-HumanNeRF: Efficient Generalizable Human NeRF Utilizing Human Prior for Sparse View (https://arxiv.org/abs/2410.12242)
Comments:
          project page: this https URL

- **What's New**: 본 연구는 일반화된 인간 NeRF(Neural Radiance Field) 프레임워크인 EG-HumanNeRF를 제안하여 희소 입력 뷰에서도 고품질의 실시간 렌더링을 가능하게 합니다. 이 프레임워크는 인체 선행 지식을 폭넓게 활용하여 렌더링 품질을 향상시킵니다.

- **Technical Details**: EG-HumanNeRF는 두 단계 샘플링 감소 전략을 통해 렌더링을 가속화하며, 첫 번째 단계에서는 인체 기하형상을 둘러싼 경계 메시(boundary meshes)를 구성하여 샘플 수를 줄입니다. 두 번째 단계에서는 <signed ray distance function> (SRDF)을 기반으로 한 샘플링 가이드를 사용하여 렌더링 품질을 유지하면서 필요한 샘플의 수를 줄입니다. 또한 가리기 구역을 고려하는 주의 메커니즘(occlusion-aware attention mechanism)을 도입하여 렌더링 품질을 향상시킵니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 최신 기술과 비교하여 렌더링 품질이 우수하며, 속도에서도 경쟁력을 갖추고 있음이 입증되었습니다.



### Leveraging Spatial Attention and Edge Context for Optimized Feature Selection in Visual Localization (https://arxiv.org/abs/2410.12240)
- **What's New**: 이번 논문에서는 비주얼 로컬라이제이션(visual localization) 분야에서 최신 기술을 적용하여 에이전트의 자세를 개선하는 방법을 제안합니다. 기존 방법의 한계를 극복하기 위해 어텐션 네트워크(attention network)를 도입하여 이미지의 정보가 많은 영역을 선택적으로 타겟팅합니다.

- **Technical Details**: 제안된 방법은 이미지 패치의 공간 정보(spatial information)를 활용하여 교육 버퍼(training buffer)에서 가장 관련성이 높은 특징(feature)만을 선택하고, 엣지 감지(edge detection)를 결합하여 선별된 특징이 강력한 지역에 위치하도록 합니다. 이를 통해 2D-3D 대응(2D-3D correspondence) 및 전반적인 로컬라이제이션 성능을 향상시킬 수 있습니다.

- **Performance Highlights**: 이 방법은 야외 벤치마크 데이터셋에서 테스트되었으며 이전 방법들에 비해 우수한 성능을 입증하였습니다. 또한, 어텐션 네트워크와 엣지 감지기의 통합에도 불구하고 빠른 매핑 시간과 효율적인 매핑 크기를 유지할 수 있음을 보여줍니다.



### Evaluating Cascaded Methods of Vision-Language Models for Zero-Shot Detection and Association of Hardhats for Increased Construction Safety (https://arxiv.org/abs/2410.12225)
- **What's New**: 본 논문은 건설 안전 향상을 위한 하드햇(hardhat) 탐지를 위한 비전-언어 모델(vision-language models, VLMs)의 제로샷(zero-shot) 탐지 및 연관성의 적용 가능성을 평가합니다. 새로운 벤치마크 데이터셋인 Hardhat Safety Detection Dataset을 생성하였으며, 이 데이터셋은 기존 데이터셋을 필터링하고 결합하여 제작되었습니다.

- **Technical Details**: 이 연구에서는 OWLv2라는 기초 모델을 사용하여 실제 건설 현장에서 하드햇을 탐지하는 방법을 제시합니다. 실험은 5,210개 이미지를 사용하였으며, OWLv2 모델은 하드햇 탐지에서 평균 정확도(average precision) 0.6493을 달성했습니다. 또한, 이미지에서 사람, 머리, 하드햇의 순차적 탐지를 위한 계단식 탐지(cascaded detection) 접근 방식을 개발했습니다.

- **Performance Highlights**: 실험 결과, OWLv2 모델의 하드햇 탐지 성능은 평균 정확도 0.6493으로 나타났습니다. 현재 모델의 강점과 약점을 논의하며, 하드햇 탐지의 실제 환경 적합성을 개선하기 위한 여러 방법에 대해서도 분석하였습니다.



### Order-aware Interactive Segmentation (https://arxiv.org/abs/2410.12214)
Comments:
          Interactive demo can be found in project page: this https URL

- **What's New**: 본 논문에서는 사용자 상호작용을 최소화하면서도 정확한 객체 분할을 위한 새로운 방법인 OIS (order-aware interactive segmentation)를 제안합니다. OIS는 객체 간의 상대 깊이를 인코딩하여 사용자 상호작용을 효과적으로 안내하고, 이를 통해 이전의 방법들에 비해 성능을 크게 향상시킵니다.

- **Technical Details**: OIS는 목표 객체의 상대 깊이를 표현하는 order maps를 활용하여 상호작용을 개선합니다. 독창적인 order-aware attention과 object-aware attention 모듈을 도입하여 유사한 깊이를 가진 객체들을 효과적으로 구별할 수 있게 합니다. 또한, 사용자 클릭이 최적화된 이미지 특징에 통합될 수 있도록 조화롭게 설계되어 있습니다.

- **Performance Highlights**: OIS는 HQSeg44K 데이터셋에서 클릭 한 번으로 mIoU가 7.61 증가하였고, DAVIS 데이터셋에서는 1.32의 향상률을 보여줍니다. 뿐만 아니라, SegNext와 비교하여 추론 속도를 2배 향상시킨 것을 입증했습니다.



### Sparse Prototype Network for Explainable Pedestrian Behavior Prediction (https://arxiv.org/abs/2410.12195)
- **What's New**: 본 논문에서는 보행자 행동 예측에 있어 기존의 여러 겹의 특성과 행위를 동시에 예측할 수 있도록 설계된 Sparse Prototype Network (SPN)을 소개합니다. 이 모델은 예측의 설명 가능성을 높이기 위한 중간 프로토타입 병목 층을 활용하여, 모든 입력 모달리티에 대해 독립적인 프로토타입을 학습합니다.

- **Technical Details**: SPN은 세 가지 주요 모듈로 구성되어 있습니다: 입력 인코딩, 프로토타입 층, 그리고 예측 헤드입니다. 입력 인코딩 모듈은 각 모달리티를 독립적으로 처리하며, 원시 입력을 압축된 고차원 특성 벡터로 변환합니다. 프로토타입은 모달리티 간의 일관성을 유지하면서 학습되며, 이를 통해 예측의 해석 가능성을 제공합니다. 또한, Top-K Mono-semanticity Scale이라는 정량적 메트릭을 사용하여 프로토타입의 설명 가능성을 평가합니다.

- **Performance Highlights**: SPN은 TITAN 및 PIE 데이터셋에서 보행자 행동 예측 작업을 수행하며, 상태 최우수 성능을 달성했습니다. 또한, 이 모델은 동시에 다중 유형의 행동을 예측함으로써 높은 수준의 설명 가능성을 유지합니다.



### Test-time adaptation for image compression with distribution regularization (https://arxiv.org/abs/2410.12191)
- **What's New**: 본 연구에서는 기존의 혼합 잠재 정제(HLR) 방법을 확장하여 교차 도메인 이미지 압축(TTA-IC)에 적응할 수 있는 고급 잠재 정제 방법을 개발하였습니다. 이 방법은 기존의 방법들에 비해 R-D 성능을 개선하고, 모델의 수정이나 전송 없이 라벨 분포를 더욱 정확하게 학습할 수 있게 돕습니다.

- **Technical Details**: 연구의 주된 기법은 Bayes 근사와 분포 정규화(distribution regularization)를 도입하여, Gaussian 조건부 확률과 하이퍼프라이어 간의 불일치를 해결하고, 더 나은 공Joint 확률 근사를 학습하도록 유도하는 것입니다. 이는 또한 기존의 R-D 목적을 개선하여, 즉각적인 모델 수정 없이 효과적인 전환을 가능하게 합니다.

- **Performance Highlights**: 여섯 개의 도메인 내 및 교차 도메인 데이터 세트에서의 광범위한 실험을 통해 제안된 방법이 다른 잠재 정제 접근 방식들에 비해 R-D 성능을 크게 향상시키며, 기존의 TTA-IC 방법에 융통성 있게 통합될 수 있다는 것을 실증하였습니다.



### TransAgent: Transfer Vision-Language Foundation Models with Heterogeneous Agent Collaboration (https://arxiv.org/abs/2410.12183)
Comments:
          NeurIPS 2024

- **What's New**: 본 연구에서는 CLIP과 같은 vision-language foundation 모델의 일반화 문제를 해결하기 위해 새로운 TransAgent 프레임워크를 제안합니다. 이 프레임워크는 다양한 모델에서 지식을 통합하여 CLIP이 여러 출처의 지식 증류(multi-source knowledge distillation)를 통해 일반화할 수 있도록 돕습니다.

- **Technical Details**: TransAgent 프레임워크는 11개의 이질적인 모듈(heterogeneous agents)과 협력하여 vision-language 모델을 강화하며, 예측 단계(inference phase)에서는 추가 비용이 발생하지 않습니다. 이를 통해 단일 모델의 한계를 극복하고 지식 전이를 효율적으로 수행합니다.

- **Performance Highlights**: TransAgent는 11개 시각 인식 데이터셋에서 최첨단(performance state-of-the-art) 성능을 달성하였으며, 인기 있는 CoOp 모델보다 평균 약 10% 더 뛰어난 성능을 보였습니다. EuroSAT 데이터셋에서는 20% 향상된 성능을 기록했습니다.



### Dual-Model Distillation for Efficient Action Classification with Hybrid Edge-Cloud Solution (https://arxiv.org/abs/2410.12165)
- **What's New**: 본 논문에서는 Dual-Model Distillation (DMD)이라는 혁신적인 방법을 통해 경량화된 혼합 에지-클라우드 솔루션을 제안하며, 실시간 환경에서의 성능을 최적화합니다.

- **Technical Details**: DMD는 소형 모델과 대형 모델 간의 지식을 상호 보완적으로 활용하여, 불확실한 상황에서 대형 모델에게 추론을 오프로드하는 기능을 수행하는 스위처 모델을 훈련합니다. 이 과정은 추가적인 수동 라벨링 데이터 없이 이루어지며, 두 모델의 제로샷 추론 결과의 합의나 불일치를 이용하여 데이터를 생성합니다.

- **Performance Highlights**: 우리의 시스템은 대형 모델만 사용했을 때보다 39.5%의 비용 절감과 4.6% 높은 F1 점수를 달성하였으며, 에너지 소비와 처리 시간을 각각 39.5%와 38.9% 줄였습니다.



### SAM-Guided Masked Token Prediction for 3D Scene Understanding (https://arxiv.org/abs/2410.12158)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 연구에서는 SAM(Segment Anything Model) 기반의 새로운 토큰화(tokenization) 방법을 통해 2D에서 3D로의 지식 증류(knowledge distillation) 문제를 해결합니다. 기존의 KNN(k-Nearest Neighbors) 기반 토큰화기법 대신 지역 수준의 정보와 3D 변환기 구조를 원활하게 정렬합니다.

- **Technical Details**: 연구는 SAM-guided masked token prediction 프레임워크를 제안하며, 이는 SAC 토큰화를 적용하여 지역 수준에서 2D-3D 지식 증류를 원활하게 수행합니다. 또한, 그룹 균형 재가중치(group-balanced re-weighting) 전략을 통해 3D 데이터 세트의 긴 꼬리 문제를 해결합니다.

- **Performance Highlights**: 여러 데이터 세트(SUN RGB-D, ScanNet, S3DIS)에서 3D 객체 탐지 및 의미론적 분할에서 현존하는 최신 자가 감독(self-supervised) 방법보다 성능이 크게 향상된 것으로 나타났습니다.



### Unveiling the Limits of Alignment: Multi-modal Dynamic Local Fusion Network and A Benchmark for Unaligned RGBT Video Object Detection (https://arxiv.org/abs/2410.12143)
- **What's New**: 본 논문에서는 수동으로 정렬되지 않은 RGB-열화상 이미지 쌍을 처리하기 위해 설계된 Multi-modal Dynamic Local Fusion Network (MDLNet)을 제안합니다. 이는 기존의 RGB-Thermal Video Object Detection (RGBT VOD) 방법의 한계를 극복하는 새로운 접근법입니다.

- **Technical Details**: MDLNet의 핵심 구성 요소는 Multi-modal Dynamic Local Fusion (MDLF) 모듈로, 임의의 가우시안 노이즈를 추가하여 동적 박스를 생성하며, 이 박스는 원래 고해상도 RGB 이미지의 로컬 영역을 선택합니다. 선택된 영역은 다른 모달리티의 정보와 융합되어 RGB로 재삽입됩니다. 또한 Cascaded Temporal Scrambler (CTS)를 도입하여 연속 프레임 간의 일관된 시공간 정보를 활용하여 현재 프레임의 표현 능력을 향상시킵니다.

- **Performance Highlights**: 제안된 MDLNet은 30,494 쌍의 정렬되지 않은 RGBT 이미지로 구성된 UVT-VOD2024 데이터셋을 활용하여 평가되었으며, 현존하는 최신 모델들과 비교했을 때 탁월한 성능을 보여줍니다.



### SplatPose+: Real-time Image-Based Pose-Agnostic 3D Anomaly Detection (https://arxiv.org/abs/2410.12080)
- **What's New**: 이번 연구에서는 실시간으로 작동하는 Pose-Agnostic 3D Anomaly Detection 방법인 SplatPose+를 제안합니다. SplatPose+는 구조 기반의 SfM 모델과 학습 기반의 3D Gaussian Splatting 모델을 결합하여 효율적인 탐지를 가능하게 합니다.

- **Technical Details**: SplatPose+는 하이브리드 3D 표현을 사용하여 쿼리 뷰를 지역화하고, 높은 품질의 아노말리-프리(pseudo reference images)를 합성하여 픽셀 단위 비교를 수행합니다. 이 과정에서 Structure from Motion(SfM) 모델과 3D Gaussian Splatting(3DGS) 모델이 결합됩니다.

- **Performance Highlights**: SplatPose+는 MAD-Sim 데이터셋에서 새로운 SOTA(State of the Art)를 달성하였고, 기존 SplatPose에 비해 학습 속도는 37.4% 빠르며, 추론 속도는 147배 향상되었습니다. 또한, 제한된 훈련 데이터(40% 사용)로도 높은 아노말리 탐지 및 세분화 성능을 보였습니다.



### WeatherDG: LLM-assisted Procedural Weather Generation for Domain-Generalized Semantic Segmentation (https://arxiv.org/abs/2410.12075)
- **What's New**: 이번 연구에서는 WeatherDG라는 새로운 접근 방식을 제안합니다. 이는 Stable Diffusion (SD)와 Large Language Model (LLM)의 협력을 통해 사실적인, 날씨가 다양한, 운전 화면 이미지를 생성할 수 있습니다.

- **Technical Details**: 이 방법은 세 가지 단계로 구성됩니다. 첫째, SD를 소스 데이터로 미세 조정하여 생성된 샘플의 내용과 레이아웃을 실제 운전 시나리오에 맞추는 것입니다. 둘째, LLM에 기반한 프로세절 프롬프트 생성 방법을 제안하여 시나리오 설명을 풍부하게 하고 SD가 더 다양하고 상세한 이미지를 자동으로 생성할 수 있도록 합니다. 마지막으로, 생성된 이미지를 사용해 모델을 훈련시키는 단계입니다.

- **Performance Highlights**: 세 가지 도전적인 데이터셋에서 실험한 결과, 우리의 방법이 다양한 최신 방법의 성능을 일관되게 개선할 수 있음을 보여주었습니다. 특히, 'Cityscapes to ACDC' 설정에서는 우리의 방법이 기준 HRDA에 비해 mIoU에서 13.9% 향상되었습니다.



### nvTorchCam: An Open-source Library for Camera-Agnostic Differentiable Geometric Vision (https://arxiv.org/abs/2410.12074)
Comments:
          Source code and installation instructions are available at this https URL

- **What's New**: nvTorchCam은 카메라 모델에 독립적인 딥 러닝 알고리즘을 개발할 수 있도록 해주는 오픈 소스 라이브러리입니다. 이 라이브러리는 다양한 카메라 모델(핀홀, 어안, 360도 등)을 지원하며, PyTorch 기반으로 확장성과 효율성을 가지고 있습니다.

- **Technical Details**: nvTorchCam은 카메라 모델의 핵심 작업을 추상화하여, 개발자들이 특정 카메라 모델에 상관없이 알고리즘을 구현할 수 있도록 지원합니다. CameraBase라는 추상 기본 클래스를 통해 포인트-투-픽셀 프로젝션과 픽셀-투-레이 변환과 같은 작업을 표준화하였습니다. 이로 인해 다양한 카메라 모델을 사용하는 딥 네트워크의 데이터로더는 해당하는 CameraBase의 하위 클래스를 반환하는 것만으로도 쉽게 변환할 수 있습니다.

- **Performance Highlights**: nvTorchCam의 고유한 기능으로는 다중 카메라 모델 간의 변환을 지원하는 역 왜곡(backward warping) 알고리즘이 있으며, 이에 대한 유효하지 않은 포인트를 추적하는 메커니즘도 포함되어 있어 복잡한 카메라 설정에서도 정확한 역 왜곡을 가능하게 합니다. 이 라이브러리는 다양한 카메라 모델에 대해 배치 처리 및 GPU 가속을 지원하여 효율적인 계산을 가능하게 합니다.



### SOE: SO(3)-Equivariant 3D MRI Encoding (https://arxiv.org/abs/2410.12053)
- **What's New**: 본 연구는 3D MRI 이미지에서 SO(3)-equivariance (SOE)을 적용한 새로운 표현 학습 방법을 제안합니다. 기존 MRI 모델들이 기하학적 정보(translation, rotation)를 무시하는 경향이 있음을 언급하며, 이러한 기하학적 변환 정보를 모델에 통합하는 것이 뇌 구조의 디테일을 효과적으로 캡쳐할 수 있음을 주장합니다.

- **Technical Details**: SO(3)는 3차원 특수 직교군으로, 3D 공간 내 모든 회전을 나타냅니다. 본 연구에서는 MRI 입력 이미지에 적용된 회전 연산이 임베딩 표현 공간에서도 반영되도록 명시적으로 모델링합니다. 이를 위해 Vector Neuron 모듈을 이용하여 표현 벡터 공간을 생성하고, SO(3) 변환이 이 공간에서 적용 가능하도록 합니다.

- **Performance Highlights**: 제안된 SOE 방법은 두 개의 공개 데이터 세트를 사용하여 T1-weighted brain scans에서 알츠하이머병 진단과 나이 예측 작업을 평가한 결과, 기존 방법들보다 우수한 성능을 보이었으며, 다양한 축에 대한 회전에도 견고한 성능을 유지함을 입증하였습니다.



### LocoMotion: Learning Motion-Focused Video-Language Representations (https://arxiv.org/abs/2410.12018)
Comments:
          ACCV 2024

- **What's New**: 이 논문은 동작 중심 비디오-언어 표현(motion-focused video-language representations)을 목표로 하고 있습니다. 기존의 방법들이 공간적인(focused on spatial) 데이터에 의존하여 물체와 장면을 식별하는 데 중점을 두었던 반면, 이 연구에서는 동작을 설명하는 캡션(captions)에서 학습하는 LocoMotion을 제안합니다.

- **Technical Details**: 기존의 비디오-언어 표현 방법은 캡션이 공간적 측면에 집중된 반면, LocoMotion은 지역 물체의 동작을 아우르는 동작 중심 캡션을 생성하여 학습합니다. 이를 위해 비디오에 합성된 동작(synthetic motions)을 추가하고 이 동작의 매개변수(parameters)를 활용하여 상응하는 캡션을 생성합니다. 또한, 동작의 다양성을 높이기 위해 동사 변형 парафразинг(verb-variation paraphrasing)을 도입하여 동작 기본 요소(primitive motions)와 고수준 동사 간의 연관성을 학습합니다.

- **Performance Highlights**: 실험 결과, 동작 중심 데이터가 제한적인 상황에서도 효과적인 성능을 보이며, 다양한 하위 작업(downstream tasks)에 대해 우수한 적합성을 입증했습니다.



### Beyond Labels: A Self-Supervised Framework with Masked Autoencoders and Random Cropping for Breast Cancer Subtype Classification (https://arxiv.org/abs/2410.12006)
- **What's New**: 이번 연구는 유방암 아형 분류를 위한 히스토패스홀로지(Histopathology) 이미지를 사용하여, 마스크 오토인코더(Masked Autoencoder, MAE)를 활용한 자기 지도 학습(self-supervised learning) 방법론을 제안합니다. 이 접근법은 정보 전반을 효과적으로 캡처하기 위한 임베딩(embedding) 학습을 통해 레이블이 없는 데이터셋에서도 특징(feature) 학습이 가능합니다.

- **Technical Details**: 연구에서는 전체 슬라이드 이미지(Whole Slide Images, WSI)에서 이미지 패치를 추출하고, 마스크 기법을 사용하여 인코더가 마스킹된 데이터를 기반으로 복원하는 구조를 취합니다. MAE를 통해 이미지의 특정 부분을 마스킹하고, 잔여 데이터로부터 패턴을 학습하여 원래 이미지를 복원하는 과정을 구현합니다. 또한, ViT(Vision Transformers) 모델을 사용하여 다중 분류(multi-class classification) 작업에서 성능을 평가합니다.

- **Performance Highlights**: BRACS 데이터셋 평가를 통해 이 모델이 기존 벤치마크와 비교하여 높은 성능을 보여주었으며, 특히 tumor tissue와 healthy tissue 구분 및 아형 분류에서의 정확도가 강조되었습니다.



### Integrating Artificial Intelligence Models and Synthetic Image Data for Enhanced Asset Inspection and Defect Identification (https://arxiv.org/abs/2410.11967)
- **What's New**: 본 연구에서는 드론 기반 검사를 통해 수집된 방대한 이미지 데이터를 활용하여 자산 결함 검사 과정을 개선하는 새로운 접근 방식을 제안합니다. 이는 합성(مسذه) 자산 결함 이미지와 수작업으로 레이블링된 드론 이미지를 결합하여 이루어집니다.

- **Technical Details**: 연구의 핵심은 Maya 및 Unreal Engine과 같은 3D 모델링 도구를 사용하여 결함이 있는 자산과 주변환경의 포토리얼리스틱(photorealistic) 3D 모델 및 2D 렌더링을 생성하는 것입니다. 이를 통해 생성된 합성 이미지가 실제 데이터에 통합되어 학습 파이프라인을 보강합니다. 이 연구는 자산 및 결함을 감지하기 위한 엔드 투 엔드(End-to-End) 인공지능(AI) 솔루션을 구현하였습니다.

- **Performance Highlights**: 자산 탐지 모델은 92%의 정확도를 달성하였고, 약 2,000개의 2k 해상도 합성 이미지를 도입함으로써 성능이 67% 향상되었습니다. 결함 탐지 모델은 두 배치(batch) 이미지에서 73%의 정확도를 기록하였습니다. 분석 결과, 합성 데이터가 실제 수작업 레이블링 데이터 대신에 결함 탐지 모델 학습에 성공적으로 사용될 수 있음을 보여주었습니다.



### CtrlSynth: Controllable Image Text Synthesis for Data-Efficient Multimodal Learning (https://arxiv.org/abs/2410.11963)
- **What's New**: 새로운 연구는 'CtrlSynth'라는 이미지-텍스트 합성 파이프라인을 설계하여 데이터 효율적이고 강력한 다중 모달 학습을 가능하게 합니다. 이 방법은 사용자가 정의한 제어 정책을 적용하여 시각적 의미를 분해하고 재조합함으로써 입력 데이터의 생성을 조절할 수 있게 만들어줍니다.

- **Technical Details**: CtrlSynth는 미리 훈련된 기초 모델을 활용하여 이미지의 시각적 태그를 추출하고, 이를 바탕으로 LLM을 이용해 텍스트를 생성합니다. 사용자는 생성 과정에서 특정 요소를 제어할 수 있으며, 닫힌 루프 시스템을 통해 기존 모델을 활용하여 추가 훈련 없이 직접적으로 합성 작업을 수행합니다.

- **Performance Highlights**: CtrlSynth는 31개의 다양한 데이터셋에서 실험을 진행했으며, CLIP 모델의 제로샷 분류에서는 23.4%, SugarCrepe 구성 추론 벤치마크에서는 5%의 정확도 향상을 보였습니다. 또한, 긴 꼬리(Long-tail) 비전 과제에서도 16%에서 21%의 성능 개선을 확인했습니다.



### Dual-frame Fluid Motion Estimation with Test-time Optimization and Zero-divergence Loss (https://arxiv.org/abs/2410.11934)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 본 연구에서는 기존의 레이블이 필요한 방식과 달리, 오직 1%의 훈련 샘플로도 뛰어난 성능을 발휘하는 완전 자기 감독(self-supervised) 방식의 새로운 방법론을 제안합니다.

- **Technical Details**: 제안된 방법은 이중 프레임 유체 운동 추정(dual-frame fluid motion estimation) 및 제로 다이버전스 손실(zero-divergence loss)을 활용하여 유체의 운동을 자가 지도(self-supervised) 방식으로 최적화합니다. 특히, splat 기반 구현을 통해 효율적이고 효과적인 손실 함수 설계를 제공합니다. 또한, Dynamic Velocimetry Enhancer (DVE) 모듈을 통해 테스트 시간 최적화(test-time optimization)를 지원합니다.

- **Performance Highlights**: 실험 결과, 제안된 자기 감독 프레임워크는 기존의 완전 감독 방식보다 우수한 성능을 보이며, 제한된 데이터(최소 1% 사용)에서도 강력한 성능을 발휘하고, 다양한 테스트 시나리오에서 탁월한 교차 도메인 강건성(cross-domain robustness)을 달성함을 입증하였습니다.



### Development and Testing of a Wood Panels Bark Removal Equipment Based on Deep Learning (https://arxiv.org/abs/2410.11913)
- **What's New**: 이 연구는 나무 패널의 껍질 제거 장비에 딥 러닝 방법을 적용하여 품질과 효율성을 개선하는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 본 연구에서는 비전 검사를 위한 시스템이 장착된 나무 패널 껍질 제거 장비를 설계하였습니다. 이를 위해 수집된 대량의 나무 패널 이미지로부터 첫 번째 일반 나무 패널 의미 세분화(semantic segmentation) 데이터셋을 구성하고, BiSeNetV1 모델을 훈련하였습니다. 껍질 제거 과정에 필요한 핵심 데이터의 계산 방법과 과정을 자세히 설명하였습니다.

- **Performance Highlights**: BiSeNetV1 모델의 비교 실험 결과, 껍질 제거의 품질 및 효율성이 현저히 개선되었으며, 개발된 장비는 제재소의 정밀도 및 효율성 요구 사항을 완벽하게 충족합니다.



### Neural Metamorphosis (https://arxiv.org/abs/2410.11878)
Comments:
          in ECCV2024, this https URL

- **What's New**: 본 논문에서는 Neural Metamorphosis (NeuMeta)라는 새로운 학습 패러다임을 소개합니다. NeuMeta는 별도의 모델을 만들지 않고, 신경 네트워크의 가변 형태를 직접 학습합니다. 이를 통해 학습된 가중치 공간에서 임의 크기의 네트워크를 샘플링할 수 있습니다.

- **Technical Details**: NeuMeta는 hypernetwork로 작동하는 implicitly learned neural functions를 사용합니다. 이는 모델 공간의 좌표를 받아 해당 가중치 값을 생성합니다. 목표는 가중치의 smoothness를 높이는 것이며, 이를 위해 두 가지 전략을 사용합니다: 첫째, 가중치 행렬의 permutation을 통해 intra-model smoothness를 달성하고, 둘째, 입력 좌표에 noise를 추가하여 무작위 네트워크 구성에서도 일관된 출력을 유지합니다.

- **Performance Highlights**: NeuMeta는 이미지 분류, 의미론적 분할 및 이미지 생성 작업에서 광범위한 테스트를 거쳐, 75% 압축률에서도 원래 모델의 성능을 유지합니다. 이 시스템은 이전에 보지 못한 네트워크 구성에 대한 가중치를 생성하는 성능을 보여줍니다.



### A Robust Multisource Remote Sensing Image Matching Method Utilizing Attention and Feature Enhancement Against Noise Interferenc (https://arxiv.org/abs/2410.11848)
Comments:
          21 pages, 13 figures

- **What's New**: 이번 논문은 다양한 노이즈에 대한 저항성을 갖춘 다중 출처 원격 탐지 이미지 매칭 방법을 제안하며, 주목(attention) 메커니즘과 특성 향상을 통해 문제를 해결합니다.

- **Technical Details**: 첫 번째 단계에서는 깊은 합성곱(deep convolution)과 트랜스포머(transformer)의 주목 메커니즘을 결합하여 조밀한 특성 추출을 수행합니다. 두 번째 단계에서는 이진 분류 기법을 기반으로 한 이상치 제거(outlier removal) 네트워크를 도입하여 이미지 간의 유효하고 기하학적으로 일관된 상관관계를 구축합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 다양한 노이즈 조건에서 다른 최신 방법들과 비교했을 때 40% 이상의 매칭 성공률을 달성하며, 벤치마크된 성능 및 견고성을 입증합니다.



### WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines (https://arxiv.org/abs/2410.12705)
- **What's New**: WorldCuisines라는 대규모 벤치마크가 소개되어 VLMs의 다문화적 및 다언어적 이해력을 평가할 수 있는 새로운 기준을 제시합니다. 이 벤치마크는 30개 언어와 방언에서 각각의 텍스트-이미지 쌍을 포함하고 있어 다문화적인 VQA 데이터셋으로는 가장 큰 규모를 자랑합니다.

- **Technical Details**: 이 연구는 VLMs를 평가하기 위해 100만 개 이상의 고품질의 다언어 및 다문화 텍스트-이미지 쌍으로 구성된 WorldCuisines를 개발했습니다. 벤치마크는 2가지 작업을 포함합니다: (1) 요리 이름 예측, (2) 요리가 일반적으로 소비되는 위치 예측. VQA 데이터셋은 30개 언어와 방언으로 구성되어 있으며, 다양한 질문 유형에 대한 평가를 포함합니다.

- **Performance Highlights**: VLMs는 적절한 위치 맥락에서 더 좋은 성능을 보였으나, 적대적인 맥락에서는 어려움을 겪었고, 특정 지역 요리와 언어 예측에서의 어려움이 드러났습니다. 데이터셋과 관련된 주의 깊은 메타데이터와 이미지도 함께 제공되어 향후 연구 지원을 기대합니다.



### Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans (https://arxiv.org/abs/2410.12641)
- **What's New**: 본 연구에서는 어깨 CT 스캔을 처리하기 위한 혁신적인 딥러닝 프레임워크를 도입합니다. 이 프레임워크는 근위 상완골과 견갑골의 의미적 분할(semantic segmentation), 뼈 표면의 3D 재구성, 글레노흐umeral (GH) 관절 영역 식별 및 세 가지 일반적인 골관절염 관련 병리(staging)인 골극 형성(osteophyte formation), GH 공간 축소(glenohumeral joint space reduction), 그리고 상완 견갑 정렬(humeroscapular alignment)을 포함합니다.

- **Technical Details**: 이 파이프라인은 두 개의 연속적인 CNN 아키텍처로 구성됩니다. 첫 번째는 세그멘테이션을 위한 3D CEL-UNet, 두 번째는 세 가지 분류를 위한 3D Arthro-Net입니다. 571개의 CT 스캔의 레트로스펙티브 데이터셋을 사용하여 성능을 평가했습니다. 3D 재구성에 대한 평균 제곱근 오차(root mean squared error) 및 하우스도르프 거리(Hausdorff distance)의 중앙값은 상완골에 대해 각각 0.22mm 및 1.48mm, 견갑골은 0.24mm 및 1.48mm로, 기존 아키텍처를 초과하는 성능을 보였습니다.

- **Performance Highlights**: 세 가지 카테고리(OS, JS, HSA)에 대해 분류 정확도는 약 90%에 도달하였으며, 추론 파이프라인의 계산 시간은 15초 미만으로, 정형외과 영상의학적 실습과의 효율성과 호환성을 보여줍니다. 이 결과는 인공지능 도구의 의료 변환을 위한 유망한 발전을 나타내며, 고품질의 뼈 표면을 제공하고 외과의사가 환자의 관절 조건에 따라 가장 적합한 외과적 접근 방식을 선택하는 데 도움을 줍니다.



### Exploring Model Kinship for Merging Large Language Models (https://arxiv.org/abs/2410.12613)
Comments:
          Ongoing work

- **What's New**: 이 연구는 모델 병합(model merging)을 위한 새로운 평가 기준인 모델 친척성(model kinship)을 도입합니다. 모델 친척성은 LLM(대형 언어 모델) 간의 유사성과 관련성을 측정하여, 반복적인 병합 과정에서 성능 개선을 돕는 정보를 제공합니다.

- **Technical Details**: 모델 병합은 여러 개별 모델을 통합하여 다중 작업 목표를 달성하는 전략입니다. 본 논문에서는 모델 친척성을 기준으로 한 Top-k Greedy Merging 전략을 제안하며, 이는 모델 진화(model evolution)에서의 최적화 문제와 지역 최적점(local optima traps)을 피할 수 있도록 도와줍니다.

- **Performance Highlights**: 모델 친척성을 사용한 새로운 병합 전략은 벤치마크 데이터셋에서 더 나은 성능을 달성하며, 평균 성능 향상과 강한 상관관계가 있음을 보여줍니다. 이 연구는 모델 병합의 효율성과 효과성을 높이기 위한 실용적인 전략을 제시합니다.



### From Lab to Pocket: A Novel Continual Learning-based Mobile Application for Screening COVID-19 (https://arxiv.org/abs/2410.12589)
Comments:
          31 pages

- **What's New**: 이 논문에서는 COVID-19를 의료 이미지에서 예측하기 위한 새로운 지속 학습 기반 접근 방식을 제안하고 있으며, COVID-19 선별을 위한 모바일 애플리케이션의 설계 및 구현을 제공합니다.

- **Technical Details**: DenseNet161이 지속 학습 모델의 기초 모델로 선택되었으며, Learning without Forgetting (LwF) 기법이 최고의 지속 학습 방법으로 평가되었습니다. 이 모델은 클라우드 서버에서 Continuous Learning을 통해 실시간으로 학습할 수 있도록 설계되었습니다.

- **Performance Highlights**: 모바일 애플리케이션이 COVID-19 분류에서 94.44%의 정확도를 달성하여 사용자들이 효율적으로 COVID-19를 선별할 수 있는 잠재력을 입증하였습니다.



### Self-DenseMobileNet: A Robust Framework for Lung Nodule Classification using Self-ONN and Stacking-based Meta-Classifier (https://arxiv.org/abs/2410.12584)
Comments:
          31 pages

- **What's New**: 본 연구에서는 Self-DenseMobileNet이라는 새로운 프레임워크를 제안하여 흉부 X선 이미지를 통한 결절(nodules)과 비결절(non-nodules) 분류의 정확성을 향상시켰습니다. 이 접근법은 이미지 표준화 및 강화 기술을 통합하여 입력 품질을 최적화하고 분류 정확도를 개선하였습니다.

- **Technical Details**: Self-DenseMobileNet은 심층 학습 아키텍처로, 반복적인 개선을 통해 다양한 향상된 이미지 샘플에 최적화된 얕은 아키텍처를 특징으로 합니다. 8개의 전통적인 기계 학습 모델에서 상위 3개 모델의 예측 확률을 스태킹(stacking) 알고리즘을 사용하여 결합해 메타 분류기를 생성하여 강력한 성능을 보여줍니다. 또한, ScoreCAM과 같은 클래스 활성화 매핑(Class Activation Mapping) 기법을 사용하여 모델의 결정 프로세스를 시각화하여 해석 가능성을 향상시켰습니다.

- **Performance Highlights**: 내부 검증 데이터에서 Self-DenseMobileNet 모델은 Meta-Random Forest Classifier를 사용하여 99.28%의 정확도를 달성하였으며, 외부 데이터셋에서는 89.40%의 정확도로 강한 일반화 능력을 유지했습니다. 이러한 결과는 폐 결절의 분류 향상에 있어 중요한 개선을 나타냅니다.



### One Step Diffusion via Shortcut Models (https://arxiv.org/abs/2410.12557)
- **What's New**: 이번 논문에서는 shortcut models를 소개합니다. 이 모델은 고품질 샘플을 단일 또는 다수의 샘플링 단계에서 생성할 수 있도록 단일 네트워크와 훈련 단계를 사용합니다.

- **Technical Details**: Shortcut 모델은 현재의 noise level뿐만 아니라 원하는 step size에 대해서도 네트워크를 조건화합니다. 이를 통해 생성 과정에서 미리 건너뛰는 것이 가능해집니다.

- **Performance Highlights**: 다양한 샘플링 단계 예산에 걸쳐 shortcut 모델은 consistency models 및 reflow와 같은 이전 접근 방식보다 consistently 더 높은 품질의 샘플을 생성합니다. Distillation과 비교할 때, shortcut 모델은 단일 네트워크와 훈련 단계로 복잡성을 줄이고, 추론 시 다양한 step budget을 허용합니다.



### Evaluating Utility of Memory Efficient Medical Image Generation: A Study on Lung Nodule Segmentation (https://arxiv.org/abs/2410.12542)
- **What's New**: 본 연구에서는 CT 스캔에서 폐 결절을 대상으로 하는 메모리 효율적인 patch-wise denoising diffusion probabilistic model (DDPM)을 제안하여 합성 의료 이미지를 생성하는 방법을 소개합니다.

- **Technical Details**: 이 모델은 nodule segmentation을 포함한 고유용성 합성 이미지를 생성하며, 메모리 제약을 효율적으로 관리하여 교육 데이터셋을 생성할 수 있도록 합니다. 연구는 두 가지 시나리오에서 평가되었습니다: 1) 합성 데이터만을 이용한 segmentation 모델 훈련, 2) 합성 이미지를 사용하여 실제 훈련 데이터 증가.

- **Performance Highlights**: 합성 데이터로만 훈련된 모델들은 실제 데이터 벤치마크에 비해 유사한 Dice 점수를 기록하였고, 합성 이미지로 실제 데이터를 보강할 경우 segmentation 성능이 크게 향상되었습니다. 생성된 이미지는 현실 세계 데이터가 제한된 상황에서 의료 이미지 데이터셋을 향상시킬 잠재력을 지닙니다.



### A Primal-dual algorithm for image reconstruction with ICNNs (https://arxiv.org/abs/2410.12441)
- **What's New**: 이 논문에서는 데이터 기반 변분 재구성(Data-driven Variational Reconstruction) 프레임워크에서 최적화 문제를 다루고 있습니다. 특히 입력 볼록 신경망(Input-Convex Neural Network, ICNN)에 의해 매개변수화된 정규화기(Regularizer)를 사용하며, 기존의 그라디언트 기반 방법의 한계를 극복하는 새로운 접근 방식을 제시하고 있습니다.

- **Technical Details**: 기존 방법들은 비매끄러운(non-smoothness) 특성을 효과적으로 처리하는 데 어려움이 있으며, 이는 느린 수렴(convergence)으로 이어집니다. 이 논문에서는 신경망의 중첩 구조(nested structure)를 제거하고, 활성화 함수(activation function)의 에피그래프(projection)를 통해 문제를 변형하여 볼록 최적화(convex optimization) 문제로 변환했습니다. 이를 통해 새로운 쌍대 알고리즘(primal-dual algorithm)을 적용할 수 있게 되었습니다.

- **Performance Highlights**: 여러 이미징(imaging) 작업에서 실험을 통해 제안된 접근 방식이 서브 그라디언트(subgradient) 방법에 비해 속도와 안정성에서 우수한 성능을 보임을 입증했습니다.



### Attention-Guided Perturbation for Consistency Regularization in Semi-Supervised Medical Image Segmentation (https://arxiv.org/abs/2410.12419)
- **What's New**: 본 논문은 의료 이미지 분할에서 반감독 학습(semi-supervised learning)의 새로운 접근법인 주의 기반의 왜곡 전략(attention-guided perturbation strategy)을 제안합니다.

- **Technical Details**: 모델의 이미지 및 특징(feature) 수준에서의 주의를 기반으로 왜곡을 추가하여 일관성 정규화(consistency regularization)를 달성합니다. 이 방법은 의료 이미지에 내재된 복잡한 구조와 고차원적 의미(high-dimensional semantics)에 적응할 수 있습니다.

- **Performance Highlights**: 우리의 방법은 ACDC 데이터셋에서 7개 사례 시나리오에서 90.4% Dice 점수를 기록하며 벤치마크 데이터셋에서 최첨단 성능(state-of-the-art results)을 달성했습니다.



### Triplet: Triangle Patchlet for Mesh-Based Inverse Rendering and Scene Parameters Approximation (https://arxiv.org/abs/2410.12414)
Comments:
this https URL

- **What's New**: 이번 연구에서는 Triangle Patchlet (약칭 Triplet)라는 새로운 프레임워크를 도입하여, 라디언스 필드(radiance field)에서 물리적 장면 속성을 효과적으로 추정할 수 있는 메쉬 기반(representation) 접근 방식을 제안합니다.

- **Technical Details**: Triplet은 무작위로 생성된 포인트나 카메라 캘리브레이션(camera calibration)에서 얻은 희소 포인트를 사용하여 조립되며, 각 면은 독립적인 요소로 취급됩니다. 물리적 상호작용을 시뮬레이션하고 전통적인 그래픽 렌더링 기술(기법)인 래스터화(rasterization)와 레이 트레이싱(ray tracing)을 사용하여 장면 매개변수를 최적화합니다.

- **Performance Highlights**: 본 프레임워크는 사전 정보 없이도 라이트(light), 재료(materials), 지오메트리(geometry)를 정확하게 추정할 수 있으며, 뛰어난 시각적 품질(visual quality)과 고품질 지오메트리 및 정확한 재료 특성을 재구성할 수 있음을 실험을 통해 입증하였습니다.



### AdaCropFollow: Self-Supervised Online Adaptation for Visual Under-Canopy Navigation (https://arxiv.org/abs/2410.12411)
- **What's New**: 본 연구에서는 자율주행 농업 로봇의 자가 감독(Self-Supervised) 온라인 적응 방법을 제안합니다. 이 방법은 세미틱 키포인트(Semantic Keypoint) 표현을 시각적 기본 모델(Visual Foundational Model), 기하학적 사전(Geometric Prior), 그리고 유사 라벨링(Pseudo Labeling)을 사용하여 조정합니다.

- **Technical Details**: 주요 내용은 세미틱 키포인트 표현을 기반으로 한 인지 시스템을 향상시키기 위한 새로운 접근법을 제시하는 것입니다. 연구팀의 사전 연구에서는 지도 학습(Supervised Learning) 기반의 모델이 특정 필드 조건에서 실패율이 높았음을 보여주었으며, 이로 인해 도메인 변화(Domain Shift)에 적응하는데 한계가 있었던 점을 지적했습니다.

- **Performance Highlights**: 예비 실험 결과에 따르면, 최소한의 데이터와 매개변수 튜닝(Fine-tuning)으로 소스 도메인에서 학습된 키포인트 예측 모델이 자가 감독 방식으로 다양한 도전적인 목표 도메인에 적응할 수 있음을 확인했습니다. 이는 로봇 컴퓨터 상에서 완전 자율적인 행(Row) 추적 기능을 가능하게 합니다.



### De-Identification of Medical Imaging Data: A Comprehensive Tool for Ensuring Patient Privacy (https://arxiv.org/abs/2410.12402)
- **What's New**: 본 논문에서는 의료 이미징 데이터의 익명화를 위해 다양한 형식의 데이터를 처리할 수 있는 오픈 소스 도구를 개발하였습니다. 이 도구는 DICOM, MRI, CT 및 Whole Slide Images (WSI) 등의 데이터 형식을 지원하며, 텍스트 제거를 위한 신경망이 포함되어 있습니다.

- **Technical Details**: 제안된 도구는 의료 이미지 데이터의 메타데이터를 익명화하고 두개골 제거(Skull-stripping) 작업을 수행합니다. DICOM 파일은 미리 정의된 규칙에 따라 메타데이터가 수정되며, NIfTI 파일 헤더는 버려진 후 두개골이 제거됩니다. 이 도구는 python3 CLI 애플리케이션 및 독립 실행형 도커 컨테이너 형태로 제공됩니다.

- **Performance Highlights**: 개발된 도구는 MRI, CT 및 WSI DICOM 파일을 포함한 다양한 데이터 유형을 익명화할 수 있으며, 고유의 두개골 제거 알고리즘을 통해 효율성을 극대화합니다. 학습 데이타셋으로는 Neurofeedback Skull-stripped (NFBS) 및 Calgary-Campinas-359 (CC-359) 등이 사용되었습니다.



### Improved Anomaly Detection through Conditional Latent Space VAE Ensembles (https://arxiv.org/abs/2410.12328)
Comments:
          13 pages of main article, 19 pages including references and appendix, 4 figures

- **What's New**: 본 논문에서는 anomal detection을 위해 조건부 잠재 공간 변분 오토인코더(Conditional Latent space Variational Autoencoder, CL-VAE)를 제안합니다. 이 방법은 데이터의 정보를 기준으로 잠재 공간의 분리를 향상시킵니다.

- **Technical Details**: 제안된 CL-VAE는 각 클래스에 고유한 prior distribution을 적합시켜 Gaussian mixture model까지 포함하는 전통적인 VAE의 prior distribution을 확장합니다. 이 VAE들의 앙상블이 잠재 공간에서 결합되어 그룹 합의를 형성함으로써 anomaly detection의 정확성을 크게 향상시킵니다.

- **Performance Highlights**: CL-VAE는 MNIST 데이터셋에서 97.4%의 AUC를 달성하여 두 번째로 우수한 모델의 95.7%보다 높은 anomaly detection 정확도를 보입니다. 또한 앙상블 효과, 더 해석 가능한 잠재 공간, 복잡한 데이터에서의 패턴 학습 능력이 증가하였다.



### PAPL-SLAM: Principal Axis-Anchored Monocular Point-Line SLAM (https://arxiv.org/abs/2410.12324)
Comments:
          8 pages, 4 figures

- **What's New**: 본 논문에서는 point-line SLAM 시스템에서 선(line) 구조 정보의 활용과 선 최적화 문제를 함께 해결하는 새로운 방법을 제안하고 있습니다. 이 방법은 유사한 방향을 가진 선을 주요 축(principal axis)에 고정하고, $n$개의 선에 대해 $n+2$ 파라미터로 최적화함으로써 두 문제를 동시에 해결합니다.

- **Technical Details**: 제안된 방법은 장면 구조(scene structural) 정보를 고려하여 여러 세계 가설(world hypotheses)에 쉽게 확장될 수 있으며, 최적화해야 할 선 파라미터의 수를 크게 줄여 빠르고 정확한 매핑(mapping)과 추적(tracking)을 가능하게 합니다. 또한, 시스템의 견고함을 강화하고 불일치를 피하기 위해 선 축(line-axis) 확률적 데이터 연관(probabilistic data association) 모델링을 수행하고, 축 생성(creation), 업데이트(update), 및 최적화를 위한 알고리즘을 제공하고 있습니다. 실세계 장면이 Atlanta World 가설에 대체로 부합한다는 점을 고려하여, 수직 우선(vertical priors) 및 소실점(vanishing points) 기반의 구조적 선 탐지 전략을 제공합니다.

- **Performance Highlights**: 다양한 실내 및 실외 데이터셋에 대한 실험 결과 및 ablation 연구를 통해 제안된 시스템의 효과성이 입증되었습니다.



### DAT: Improving Adversarial Robustness via Generative Amplitude Mix-up in Frequency Domain (https://arxiv.org/abs/2410.12307)
- **What's New**: 이번 연구에서는 적대적 훈련(Adversarial Training, AT) 기법을 통해 딥 신경망(Deep Neural Networks, DNNs)의 적대적 공격(adversarial attacks)에서의 내구성 강화에 대한 새로운 접근방법을 제안합니다. 특히, 주파수 스펙트럼의 위상(phase) 패턴에 초점을 맞추어 모델의 분류 성능을 향상시키는 방법을 탐구합니다.

- **Technical Details**: 본 연구에서 제안하는 Optimized Adversarial Amplitude Generator (AAG)는 적대적 예제(adversarial examples, AEs)가 모델에 미치는 영향을 최소화하면서도, 훈련 샘플의 주파수 스펙트럼의 진폭(amplitude)을 전환하여 위상 패턴을 보호합니다. 이를 기반으로 새롭게 설계된 Dual Adversarial Training (DAT) 전략은 효율적인 AE 생성 절차와 함께 사용됩니다.

- **Performance Highlights**: 실험 결과, 제안된 DAT 전략은 다양한 데이터셋에서 여러 적대적 공격에 대한 강력한 내구성을 보여주었으며, 모델의 전반적인 성능이 유의미하게 향상됨을 나타냅니다.



### Consistency Calibration: Improving Uncertainty Calibration via Consistency among Perturbed Neighbors (https://arxiv.org/abs/2410.12295)
- **What's New**: 이번 논문에서는 딥러닝 응용 분야에서 모델의 보정을 위한 새로운 개념인 Consistency (일관성)을 도입합니다. 이는 대규모 언어 모델(LLM)에서 영감을 얻었으며, 기존의 신뢰 기반 관점에 비해 다양한 장점을 강조합니다.

- **Technical Details**: Consistency Calibration (CC)라는 새로운 사후 보정 방법을 제안하고, 이는 변화된 입력에 대한 모델의 일관성을 기반으로 신뢰도를 조정합니다. CC는 추가적인 데이터 샘플이나 레이블 정보를 요구하지 않으며, 소스 데이터에서 직접 입력 변화를 생성합니다. 또한, logit 수준에서의 변화를 수행함으로써 계산 효율성을 크게 개선합니다.

- **Performance Highlights**: CIFAR-10, CIFAR-100 및 ImageNet과 같은 표준 데이터셋뿐만 아니라 ImageNet-LT와 같은 긴 꼬리 데이터셋에서도 다양한 사후 및 학습 시간 보정 방법과 비교하여 최첨단 성능을 입증했습니다.



### Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting (https://arxiv.org/abs/2410.12284)
- **What's New**: 이번 연구는 자연어 설명(NLE), 주목지도(saliency mapping), 두 가지 설명 방식의 조합이 실제 의료 현장에서 AI와 협력하여 가슴 X선 분석을 수행하는 의료 종사자들에게 미치는 영향을 대규모 사용자 연구로 평가한 내용을 다룹니다. 연구 결과, 언어 기반 설명이 과도한 의존성을 초래함을 발견하였고, 주목지도와 결합했을 때 그 단점을 완화할 수 있음을 확인했습니다.

- **Technical Details**: 이 연구는 85명의 의료 종사자를 대상으로 진행되었으며, 각각 80개의 독특한 이미지를 분석했습니다. 연구에서는 주목지도, 자연어 설명 및 두 가지 설명의 조합을 포함하여 네 가지 다양한 CDSS(Clinical Decision Support System) 설정에서 수행되었습니다. 조건이 불완전한 AI 및 XAI 환경에서 다양한 설명 유형이 사용자의 행동에 미치는 영향을 조사했습니다.

- **Performance Highlights**: 결과적으로, 설명의 질은 유용성에 중요한 영향을 미쳤으며, 설명 정확도가 AI 정확도와 일치할 때 사용자에게 긍정적인 영향을 미치는 것으로 나타났습니다. 특히, 주목지도와 자연어 설명의 조합은 설명 유형 중 가장 유용한 것으로 평가되었습니다. 반면 AI와 설명의 정확도가 불일치할 경우, 사용자 성능에 부정적인 영향을 미칠 수 있음을 걸러냈습니다.



### Advancing Healthcare: Innovative ML Approaches for Improved Medical Imaging in Data-Constrained Environments (https://arxiv.org/abs/2410.12245)
Comments:
          7 pages, 7 figures

- **What's New**: 이 논문은 의료 산업에서 희귀 질환으로 인해 발생하는 데이터 부족 문제를 해결하기 위한 새로운 프레임워크인 CAT-U-Net을 소개합니다.

- **Technical Details**: CAT-U-Net은 대규모 데이터셋 없이 의료 이미지에서 특징 추출을 향상시키는 새로운 접근법으로, 다운샘플링(downsampling) 부분과 추가 연결(concatenation) 레이어를 도입하여 제한된 데이터로부터 학습 능력을 향상시킵니다.

- **Performance Highlights**: 제안된 프레임워크는 다양한 의료 조건 데이터셋(COVID-19, 뇌종양, 손목 골절 등)을 사용하여 검증되었으며, 약 98%의 재구성 정확도와 0.946에 가까운 Dice 계수를 달성했습니다.



### OMCAT: Omni Context Aware Transformer (https://arxiv.org/abs/2410.12109)
Comments:
          Demo page: this https URL

- **What's New**: 대규모 언어 모델(LLMs)의 진전을 바탕으로 새로운 데이터셋(OCTAV)과 모델(OMCAT)을 발표하였습니다. 이 모델은 시청각 기반 질문 응답(task)에서 우수한 성능을 발휘합니다.

- **Technical Details**: OCTAV(Omni Context and Temporal Audio Video)는 소리 이벤트를 통해 비디오에서 발생하는 사건의 전환을 캡처하는 혁신적인 데이터셋입니다. OMCAT(Omni Context Aware Transformer)는 RoTE(Rotary Time Embeddings)를 활용하여 시각 및 청각 데이터를 위한 통합 모델을 제공합니다.

- **Performance Highlights**: OMCAT는 AVQA(Audio-Visual Question Answering) 작업 및 OCTAV 벤치마크에서 최첨단 성능을 보여주며, 시간적 추론과 시청각 정렬에서 의미 있는 개선을 기록했습니다.



### V3D-SLAM: Robust RGB-D SLAM in Dynamic Environments with 3D Semantic Geometry Voting (https://arxiv.org/abs/2410.12068)
- **What's New**: 본 논문에서는 진전된 SLAM 기술인 V3D-SLAM을 제안하여, 동적 환경에서 카메라 위치 추정과 맵 생성의 정확성을 높이기 위한 혁신적인 접근법을 보여줍니다. 이 방법은 움직이는 객체와 정적인 객체를 구분하고, 3D 형태와 동역학을 이해하여 이동 객체의 영향을 최소화하는 데 중점을 둡니다.

- **Technical Details**: V3D-SLAM은 Hough voting 메커니즘을 활용하여 동적 객체를 구분하고, Chamfer 거리(Chamfer distances)를 사용하여 정적 객체의 동적 노이즈를 탐지합니다. 실험은 TUM RGB-D 벤치마크 데이터 세트를 기반으로 하며, V3D-SLAM은 최신 SLAM 방법들보다 더 높은 성능을 보였음을 입증했습니다.

- **Performance Highlights**: 우리의 실험 결과 V3D-SLAM은 TUM RGB-D 벤치마크에서 동적 시퀀스에 대해 보다 높은 정확도를 보여주었고, 불필요한 노이즈를 효율적으로 제거함으로써 전통적인 SLAM 방법보다 우수한 성능을 달성했습니다.



### Learned Neural Physics Simulation for Articulated 3D Human Pose Reconstruction (https://arxiv.org/abs/2410.12023)
- **What's New**: 이번 논문에서는 사람의 움직임을 동적으로 모델링하기 위해 새로운 신경망 접근 방식인 LARP (Learned Articulated Rigid body Physics)를 제안합니다. 전통적인 물리 시뮬레이터의 대안으로 빠르고 편리한 방법론을 개발하는 데 목표를 두었습니다.

- **Technical Details**: LARP는 관절이 있는 강체 동역학을 정확하게 시뮬레이트하기 위해 순환 신경망(RNN)과 명시적 상태 집계를 사용하여 물리적 매개변수를 모델링합니다. 각 객체 타입마다 MLP(다층 퍼셉트론)를 정의하고, 충돌 효과를 처리하기 위해 충돌 서브 네트워크를 채택하여 다른 객체와의 상호작용을 모델링합니다.

- **Performance Highlights**: LARP는 전통적인 물리 시뮬레이터보다 최대 10배 빠르게 인간 모션 궤적을 계산할 수 있으며, 기존 비디오 기반 복원 프레임워크에 통합하여 3D 인간 포즈 재구성의 정확성을 비교하거나 더 나은 성능을 보여줍니다. 이 모델은 훈련 세부 사항 및 데이터 증강 방법에 따라 성능의 차이가 크게 발생합니다.



### DDIL: Improved Diffusion Distillation With Imitation Learning (https://arxiv.org/abs/2410.11971)
- **What's New**: 본 논문에서는 ‘모방 학습(Imitation Learning)’ 프레임워크 내에서의 확산 디스틸레이션(Diffusion Distillation) 접근법을 제안하여, 확산 모델의 훈련 분포를 개선하였음을 발표합니다. 이는 데이터 분포(Forward Diffusion)와 학생이 유도한 분포(Backward Diffusion)를 모두 고려하여 이루어집니다.

- **Technical Details**: 제안된 DDIL( Diffusion Distillation within Imitation Learning) 접근법은 ‘DAgger’ 프레임워크를 통해 데이터 집합 내에서 데이터 분포와 학생 유도 분포 모두에서 디스틸레이션을 수행하여 예측 분포의 집합적 품질을 개선하는 것을 목표로 합니다. 이 과정에서 데이터 분포의 지원을 위반하지 않도록 임계값 설정을 도입하였으며, 이는 ‘반사 확산(Reflected Diffusion)’ 공식을 사용하여 Covariate Shift 문제를 완화합니다.

- **Performance Highlights**: DDIL 접근법은 다양한 샘플을 생성하며, 프로그레시브 디스틸레이션(Progressive Distillation), 잠재 일관성 모델(Latent Consistency Model), 분포 매칭 디스틸레이션(Distribution Matching Distillation)과 같은 여러 디스틸레이션 기법에서 일관되게 성능을 향상시키는 결과를 보여주었습니다.



### Comparing Zealous and Restrained AI Recommendations in a Real-World Human-AI Collaboration Task (https://arxiv.org/abs/2410.11860)
Comments:
          15 pages, 14 figures, accepted to ACM CHI 2023

- **What's New**: 이번 연구는 AI를 활용한 의사결정 시스템 설계에서 precision (정밀도)와 recall (재현율) 간의 Tradeoff를 조정하여 인간-AI 팀의 성과를 높이는 방법을 제시합니다. 특히, 영상 익명화 작업을 통해 유의미한 결과를 도출하였습니다.

- **Technical Details**: 본 연구는 78명의 전문가 주석가가 3,466시간 이상에 걸쳐 AI 지원 없이, high-precision 'restrained' AI 그리고 high-recall 'zealous' AI의 지원을 받으며 수행한 영상 주석 작업을 분석하였습니다. 이를 통해 각 AI 시스템의 성능을 비교하고, recall에 중점을 둔 zealous AI가 인간 작업자에게 더 높은 Recall과 짧은 작업 완료 시간을 제공함을 확인했습니다.

- **Performance Highlights**: 연구 결과, zealous AI와 함께 작업한 팀은 Recall이 크게 향상되었으며, 더 빠른 작업 완료 시간을 기록했습니다. 또한, restrained AI에서 훈련된 주석가는 AI의 지원이 없는 상태에서 부정적 영향을 받는 경향을 보였습니다.



### Method for Evaluating the Number of Signal Sources and Application to Non-invasive Brain-computer Interfac (https://arxiv.org/abs/2410.11844)
Comments:
          13 pages, 8 figures

- **What's New**: 이 논문에서는 Brain-Computer Interface (BCI)에서 수집된 데이터를 분석하기 위한 수학 이론과 Time Series Unfolding 방법을 소개합니다. 특히 비침습적 BCI에서의 신호 소스의 수를 추정하는 방법론을 제안합니다.

- **Technical Details**: 논문에서는 뇌를 신호 생성기로 간주하고, 이러한 신호 생성기들이 폴리하모닉 신호 형태로 모델링된다고 설명합니다. 데이터 분석을 위해 Second-order differential equation을 기반으로 하며, Time Series Multidimensional Unfolding (TSMU) 방법을 통해 비선형 곡선을 사용하여 시간 시퀀스 데이터를 분석합니다.

- **Performance Highlights**: 제안된 접근법의 효율성은 저자에 의해 개발된 비침습적 뇌-컴퓨터 인터페이스에서 기록된 데이터를 분석하여 입증되었습니다. 이 방법을 통해 활성 뇌 오실레이터(oscillator)의 수를 정확하게 추정할 수 있는 가능성을 보여줍니다.



### MoH: Multi-Head Attention as Mixture-of-Head Attention (https://arxiv.org/abs/2410.11842)
Comments:
          23 pages, code: this https URL

- **What's New**: 본 연구에서는 Transformer 모델의 핵심인 multi-head attention 메커니즘을 개선하여 효율성을 높이고 이전의 정확도 수준을 유지하거나 초과하는 방법을 제안합니다. 주목할 점은 모든 attention head가 동일한 중요도를 가지지 않는다는 인식에 기반하여 Mixture-of-Head attention (MoH)이라는 새로운 아키텍처를 제안합니다.

- **Technical Details**: MoH는 각 토큰이 적절한 attention heads를 선택할 수 있도록 하여 추론 효율성을 향상시킵니다. 또한 MoH는 multi-head attention의 일반적인 합산을 가중 합산으로 대체하여 attention 메커니즘에 유연성을 추가하고 성능 잠재력을 높입니다. 우리는 ViT, DiT 및 LLMs와 같은 다양한 모델 프레임워크에서 MoH의 성능을 평가하였습니다.

- **Performance Highlights**: MoH는 단지 50%-90%의 attention heads를 사용하여 multi-head attention을 능가하는 성능을 달성하였습니다. 예를 들어, MoH-ViT-B는 ImageNet-1K 분류 기준에서 84.9%의 Top-1 정확도를 기록하며, LLaMA3-8B 모델과의 비교에서 2.4%의 성능 향상을 보였습니다.



### High-Resolution Frame Interpolation with Patch-based Cascaded Diffusion (https://arxiv.org/abs/2410.11838)
Comments:
          Project page: this https URL

- **What's New**: 본 논문에서는 매우 고해상도 입력 및 복잡한 동작을 처리하는 데 어려움을 겪고 있는 기존의 프레임 보간(Frame Interpolation) 방법의 문제를 해결하기 위해 새로운 패치 기반의 캐스케이드 픽셀 확산 모델인 HiFI를 소개합니다. HiFI는 다양한 조건에서 우수한 성능을 보여주며, 특히 8K 해상도에서 유용하게 적용됩니다.

- **Technical Details**: HiFI는 동작에 따라 해상도를 조절하는 대신 고정된 해상도에서 항상 확산 작업을 수행하고, 입력 및 이전 솔루션의 패치를 처리하여 업샘플링 하는 기술을 채택합니다. 이를 통해 메모리 사용량을 크게 줄일 수 있으며, 단일 모델로 프레임 보간과 공간 업샘플링을 동시에 처리하여 학습 비용을 절감할 수 있습니다.

- **Performance Highlights**: HiFI는 Vimeo, Xiph, X-Test, SEPE-8K와 같은 여러 벤치마크에서 최첨단 성능을 보여주었으며, 특히 복잡한 반복 텍스처와 대규모 동작이 포함된 경우에는 기존의 기준 성능을 크게 초월하였습니다. 또한 새로운 데이터셋인 대규모 동작 및 반복 텍스처(LaMoR)를 도입하여 도전적인 사례에서 HiFI의 우수한 성능을 입증하였습니다.



### On the Effectiveness of Dataset Alignment for Fake Image Detection (https://arxiv.org/abs/2410.11835)
- **What's New**: 이 논문에서는 Latent Diffusion Models (LDMs)을 사용하여 가짜 이미지 감지를 위한 새로운 접근법을 제안합니다. 특히, 기존의 데이터셋 디자인 방식을 개선하여 더 강력한 감지기를 훈련하는 방법을 제시합니다.

- **Technical Details**: 기존의 작업들은 주로 네트워크 아키텍처와 훈련 방법에 집중했지만, 이 연구는 정렬된 real/fake 이미지 데이터셋의 중요성을 강조합니다. LDM의 autoencoder를 사용하여 실제 이미지를 재구성하고 이러한 재구성된 이미지와의 차이를 학습하여, 모델이 LDM decoder의 아티팩트를 판별하도록 하였습니다.

- **Performance Highlights**: 이 방법은 10배 더 저렴한 비용으로 기존의 최첨단 방법들과 유사하거나 더 나은 성능을 보였습니다. 새로운 데이터셋을 사용하여 트레이닝한 감지기는 스푸리어스 패턴에 덜 초점을 맞추는 것으로 확인되었습니다.



### CoTracker3: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos (https://arxiv.org/abs/2410.11831)
- **What's New**: CoTracker3는 새로운 포인트 추적 모델로, 간단하고 데이터 효율적인 아키텍처 및 세미-슈퍼바이즈(semisupervised) 훈련 프로토콜을 도입합니다. 이 모델은 기존의 복잡한 구성 요소를 제거하면서도, 실시간 비디오에서 라벨이 없는 데이터로 훈련할 수 있도록 합니다.

- **Technical Details**: CoTracker3는 최근의 포인트 추적기에서 받은 아이디어를 바탕으로 단순하고 유연한 아키텍처를 갖추고 있습니다. 이 모델은 기존의 글로벌 매칭(global matching) 단계를 제거하고, 반복 업데이트(Iterative Updates)와 CNN(convolutional neural networks)의 특징을 통합하여 예상되는 비디오를 효과적으로 추적합니다.

- **Performance Highlights**: CoTracker3는 TAP-Vid 및 Dynamic Replica 벤치마크에서 BootsTAPIR보다 유의미하게 성능이 개선되었으며, 1,000배 적은 양의 라벨이 없는 비디오로 높은 정확도를 달성했습니다. 또한, CoTracker3는 시각적으로 가려진 포인트를 안전하게 추적하는 기능을 포함하고 있습니다.



### MMFuser: Multimodal Multi-Layer Feature Fuser for Fine-Grained Vision-Language Understanding (https://arxiv.org/abs/2410.11829)
Comments:
          11 pages, 6 figures, technical report

- **What's New**: 이 논문에서는 Multi-Layer Feature Fuser (MMFuser)를 제안하여 Vision Transformers에서 깊이 및 얕은 특징을 효율적으로 통합하여 시각적 표현을 개선하는 방법을 탐구합니다.

- **Technical Details**: MMFuser는 세밀하게 조정된 깊은 특징을 쿼리로 사용하여 얕은 특징에서 필요한 세부 정보를 동적으로 추출합니다. 이를 통해 시맨틱 정렬을 유지하면서도 세세한 정보를 풍부하게 포함할 수 있습니다.

- **Performance Highlights**: MMFuser를 LLaVA-1.5 모델에 적용한 결과, 대부분의 멀티모달 벤치마크에서 성능을 크게 향상시켰으며, 특정 태스크에서 기존 모델보다 3.8, 53.9, 2.2 포인트의 개선을 보여주었습니다.



### Analysis and Benchmarking of Extending Blind Face Image Restoration to Videos (https://arxiv.org/abs/2410.11828)
Comments:
          Accepted by TIP'2024; Project page: this https URL

- **What's New**: 최근 블라인드 얼굴 복원(blind face restoration) 기술의 진전으로 정적인 이미지에서 고품질의 복원된 결과를 얻는 데 성공하였습니다. 그러나 비디오 시나리오로의 확장은 거의 없었으나, 이 논문에서 우리는 실제 환경의 저품질 얼굴 비디오 벤치마크(RFV-LQ)를 소개하여 비디오 복원 알고리즘의 비교를 가능하게 하였습니다.

- **Technical Details**: 블라인드 얼굴 복원은 저하된 얼굴 이미지를 고품질로 복원하는 과업입니다. 본 논문에서는 TCN(Temporal Consistency Network)과 정렬 매끄러움(alignment smoothing)을 결합하여 복원된 비디오에서의 떨림(jitters)과 깜박임(flickering) 문제를 해결하고자 하였습니다. TCN은 현재와 이전 프레임 간의 시간 정보를 포착하기 위한 크로스-어텐션 스윈 트랜스포머 레이어(CASTL)를 포함하고 있습니다.

- **Performance Highlights**: TCN은 기존의 얼굴 이미지 복원 모델에 연계되어 잠재적인 복원 편향을 수정하는 경량화된 플러그 앤 플레이 컴포넌트로, 이전 방법에 비해 처리 시간이 약 3배에서 10배 더 빠릅니다. 또한, extensive experiments를 통해 우리의 제안된 방법이 기존의 시간 일관성 알고리즘보다 우수함을 입증하였습니다.



### KITTEN: A Knowledge-Intensive Evaluation of Image Generation on Visual Entities (https://arxiv.org/abs/2410.11824)
Comments:
          Project page: this https URL

- **What's New**: 본 논문에서는 텍스트-이미지 생성 모델의 진실성(fidelity)을 평가하기 위한 새로운 벤치마크인 KITTEN을 제안하고 있습니다. KITTEN은 실제 시각적 엔티티를 정확히 재현하는 능력을 평가하며, 기존의 평가 방법이 간과해온 면에 집중하고 있습니다.

- **Technical Details**: KITTEN 벤치마크는 Wikipedia에서 문서화된 시각적 엔티티를 기반으로 한 프롬프트를 활용하여 8개의 비주얼 도메인(항공기, 차량, 요리, 꽃, 곤충, 랜드마크, 식물, 스포츠)에 걸쳐 모델의 성능을 평가합니다. 평가에는 자동화된 지표와 세심하게 설계된 인간 평가가 포함됩니다.

- **Performance Highlights**: 최신 텍스트-이미지 모델과 검색 증강(customization) 모델의 성능을 평가한 결과, 대부분의 최첨단 모델이 실제 비주얼 세부사항을 정확히 생성하지 못함을 보여주었습니다. 검색 증강 모델은 참조 이미지를 활용하여 진실성을 조금 향상시킬 수 있었지만, 창의적 텍스트 프롬프트에 따라 새로운 구성을 생성하는 데 어려움을 겪었습니다.



### Improving Long-Text Alignment for Text-to-Image Diffusion Models (https://arxiv.org/abs/2410.11817)
- **What's New**: 이번 연구에서는 기존의 T2I(텍스트-투-이미지) 변환 모델의 한계를 극복하기 위해 LongAlign이라는 새로운 방법을 제안합니다.

- **Technical Details**: LongAlign은 긴 텍스트를 처리하기 위해 세그먼트 수준의 인코딩 방법을 도입하고, 효과적인 정렬 훈련을 위한 분해된 선호 최적화 방법을 포함합니다. 긴 텍스트는 여러 세그먼트로 나뉘어 별도로 처리되어 기존의 인코딩 모델의 최대 입력 길이 제한을 극복합니다.

- **Performance Highlights**: 20시간의 훈련 후, 세그먼트 수준의 인코딩 및 선호 최적화 방법을 적용한 512x512 Stable Diffusion(SD) v1.5 모델이 PixArt-$\alpha$ 및 Kandinsky v2.2와 같은 강력한 모델들을 T2I 정렬에서 초월하는 성능을 보여줍니다.



### Jigsaw++: Imagining Complete Shape Priors for Object Reassembly (https://arxiv.org/abs/2410.11816)
Comments:
          21 pages, 10 figures

- **What's New**: 본 논문에서는 Jigsaw++라는 새로운 generative method(생성 방법)를 소개하며, 이는 3D representation(3D 표현)과 관련된 복잡한 재조립 문제를 해결하기 위해 설계되었습니다.

- **Technical Details**: Jigsaw++는 기존의 방법들이 주로 piecewise information(조각 단위 정보)에 초점을 맞추는 반면, 전체 객체의 형태 정보를 학습합니다. 이 방법은 'retargeting' 전략을 사용하여 기존 조립 방법의 출력을 활용, 완전한 형태 재구성을 생성합니다.

- **Performance Highlights**: Breaking Bad dataset 및 PartNet에 대한 광범위한 평가를 통해 Jigsaw++는 재구성 오류를 줄이고 형상 재구성의 정밀성을 향상시켰으며, 이는 향후 재조립 모델 개발을 위한 새로운 방향을 제시합니다.



### SGEdit: Bridging LLM with Text2Image Generative Model for Scene Graph-based Image Editing (https://arxiv.org/abs/2410.11815)
Comments:
          Accepted by ACM Transactions on Graphics and SIGGRAPH Asia 2024. Project page: this https URL

- **What's New**: 본 논문은 LLM(대형 언어 모델)과 Text2Image 생성 모델을 통합하여 장면 그래프 기반 이미지 편집을 위한 새로운 프레임워크를 소개합니다. 이 통합은 전체 이미지의 무결성을 유지하면서 객체 수준에서의 정밀한 수정과 창의적인 장면 재구성을 가능하게 합니다.

- **Technical Details**: 프레임워크는 두 가지 주요 단계로 구성됩니다: 1) LLM 기반 장면 구문 분석기(scene parser)를 사용하여 이미지의 장면 그래프를 구성하고, 주요 객체와 그 상호 관계 및 세밀한 속성을 캡처합니다. 2) 이미지 편집 단계에서는 LLM 편집 컨트롤러가 특정 영역으로의 편집을 안내하며, 이는 주의 조절(attention-modulated) 확산 편집기에 의해 구현됩니다.

- **Performance Highlights**: 광범위한 실험을 통해 제안된 프레임워크가 기존 이미지 편집 방법에 비해 편집 정밀도 및 장면 미학 면에서 상당한 성과를 보여주는 것을 입증하였습니다.



### Efficient Diffusion Models: A Comprehensive Survey from Principles to Practices (https://arxiv.org/abs/2410.11795)
- **What's New**: 이번 논문은 최근 인기를 끌고 있는 확산 모델(Diffusion Models)에 대한 포괄적이고 심층적인 리뷰를 제공하며, 이러한 모델의 원리와 효율적인 실행 사례를 정리하고 있습니다.

- **Technical Details**: 주요 초점은 아키텍처 디자인(architecture designs), 모델 훈련(model training), 빠른 추론(fast inference), 신뢰할 수 있는 배포(reliable deployment) 등입니다.

- **Performance Highlights**: 연구자들을 위한 이 논문은 효율성을 중시하며, 이론 연구(theoretical research), 알고리즘 이전(algorithm migration), 새로운 시나리오에 대한 모델 적용을 위한 지침을 제공합니다.



### Latent BKI: Open-Dictionary Continuous Mapping in Visual-Language Latent Spaces with Quantifiable Uncertainty (https://arxiv.org/abs/2410.11783)
- **What's New**: 새로운 확률적 매핑 알고리즘인 Latent BKI를 소개합니다. 이 알고리즘은 개방형 어휘 매핑(open-vocabulary mapping)을 가능하게 하며 정량화된 불확실성(quantifiable uncertainty)을 수반합니다. 기존의 매핑 알고리즘은 고정된 의미 범주(set of semantic categories)에 중점을 두어 복잡한 로봇 작업에 대한 적용성이 제한되어 있었으나, Latent BKI는 이를 해결합니다.

- **Technical Details**: Latent BKI는 Vision-Language (VL) 모델에서 파생된 신경 임베딩(neural embeddings)을 단위 간행(voxel map)으로 반복적으로 통합하여 불확실성을 정량화합니다. Bayesian Kernel Inference (BKI)를 통해 인근 관측치의 공간 관계를 활용하여 매핑을 수행합니다. 이 방법은 고정 어휘의 범주 공간에 제한되지 않고 연속적인 매핑을 수행할 수 있도록 확장됩니다.

- **Performance Highlights**: Latent BKI는 MatterPort-3D 및 Semantic KITTI 데이터 세트에서 유사한 명시적 의미 매핑과 VL 매핑 프레임워크와 비교하여 테스트되었으며, 계속 매핑의 확률적 이점을 유지하면서 개방형 사전 쿼리(open-dictionary queries)의 추가 이점을 제공합니다. 실제 실험을 통해 도전적인 실내 환경에서의 적용 가능성을 입증하였습니다.



### Fractal Calibration for long-tailed object detection (https://arxiv.org/abs/2410.11774)
- **What's New**: 이 논문에서는 FRActal CALibration (FRACAL)이라는 새로운 사후 보정(post-calibration) 방법을 제안하여 장기 분포(long-tailed distribution) 객체 감지의 성능을 향상시킵니다. FRACAL은 이미지 공간에서 클래스의 분포를 고려하여 클래스 예측의 확률을 조절하는 로그잇 조정 방법을 개발하여 균형을 이룹니다.

- **Technical Details**: FRACAL은 박스 카운팅(box-counting) 방법을 사용하여 훈련 세트의 모든 객체의 위치 분포를 집계하고, 이를 통해 희귀 클래스의 퍼포먼스를 크게 향상시킵니다. 이 방법은 추가적인 훈련 없이 다양한 모델에 통합될 수 있으며, 사용 중에는 균일하게 분포된 클래스 예측의 확률을 역으로 감소시킵니다.

- **Performance Highlights**: FRACAL은 LVIS 데이터셋에서 희귀 클래스 성능을 최대 8.6% 향상시켰으며, COCO, V3Det, OpenImages와 같은 다른 데이터셋에서도 우수한 일반화 성능을 보였습니다.



### SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding (https://arxiv.org/abs/2410.11761)
- **What's New**: 본 논문에서는 병리학 분야의 첫 번째 비전-언어 보조도구인 SlideChat을 제안합니다. 이는 기가픽셀 수준의 전체 슬라이드 이미지를 이해할 수 있도록 설계되었으며, 다양한 병리학 시나리오에서 복잡한 지시를 처리할 수 있습니다.

- **Technical Details**: SlideChat은 SlideInstruction을 기반으로 훈련되며, 4.2K 개의 WSI 캡션과 176K 개의 VQA 쌍을 포함하는 대규모 다중모델 지시 데이터세트를 사용합니다. SlideChat의 아키텍처는 패치-레벨 인코더, 슬라이드-레벨 인코더, 다중모델 프로젝터 모듈, 대형 언어 모델을 포함합니다.

- **Performance Highlights**: SlideChat은 22개의 작업 중 18개에서 최첨단 성능을 달성하였고, SlideBench-VQA (TCGA)에서 81.17%, SlideBench-VQA (BCNB)에서 54.15%의 정확도를 보였습니다. 또한, 연구 및 개발을 촉진하기 위해 SlideChat, SlideInstruction 및 SlideBench는 오픈 소스 리소스로 제공될 예정입니다.



### POLO -- Point-based, multi-class animal detection (https://arxiv.org/abs/2410.11741)
Comments:
          Published in the CV4Ecology workshop at ECCV 2024

- **What's New**: 이 논문에서는 드론 영상을 기반으로 한 자동화된 야생동물 조사에서의 주석 작업(load)을 줄이기 위해 POLO라는 다중 클래스 객체 탐지 모델을 개발했습니다. POLO는 기존의 YOLOv8 아키텍처의 예측 과정과 손실 함수, 후처리를 효과적으로 수정하여 점(point) 레이블만으로 전체 모델을 학습할 수 있습니다.

- **Technical Details**: POLO는 드론의 수조 조류 영상을 분석하는 데 사용되며, 주요 기술적 특징으로는 두 개의 채널만 사용하여 물체의 중심좌표를 출력하고, 평균 하우스도르프 거리(Average Hausdorff-Distance)와 평균 제곱 오차(Mean Squared Error)를 손실 함수로 적용합니다. YOLOv8의 비슷한 구조를 유지하되, 객체 탐지를 위해 점 레이블을 전적으로 활용한 것에 의의가 있습니다.

- **Performance Highlights**: POLO는 알래스카의 아이젠벡 석호에서 촬영된 드론 영상에서 최대 수천 개의 개체를 포함하는 수조 조류의 숫자를 세는 테스트에서 기존 YOLOv8 모델보다 더 높은 정확도를 기록했습니다. 같은 주석 비용으로 개선된 성능을 보여, 야생동물 조사 노력에 있어 비용 효율성을 높였습니다.



### Patch-Based Diffusion Models Beat Whole-Image Models for Mismatched Distribution Inverse Problems (https://arxiv.org/abs/2410.11730)
- **What's New**: 이번 연구에서는 기존의 diffusion 모델이 데이터 분포가 불일치할 때 발생하는 문제, 즉 single measurement와 small dataset에서의 image reconstruction 문제를 해결하기 위해 patch-based diffusion 모델을 제안합니다. 이 방법은 이미지 분포를 패치 단위로 학습하여 데이터 부족과 분포 불일치에 강한 일반화 능력을 가지고 있음을 보여줍니다.

- **Technical Details**: 연구에서는 두 가지 설정을 다룹니다. 첫째, unknown test distribution에서 단일 측정이 주어지는 경우입니다. 이 경우 우리는 self-supervised loss를 포함시켜 네트워크가 측정값과의 일관성을 유지하도록 돕습니다. 둘째, small dataset이 주어지는 경우로, patch-based 네트워크를 fine-tuning 하여 훨씬 더 나은 prior를 얻습니다. 이 방식은 whole-image 모델에 비해 성능이 우수함을 실험적으로 입증합니다.

- **Performance Highlights**: 실험 결과, patch-based 방법은 두 설정 모두에서 high quality image reconstruction을 달성하며, whole-image 모델보다 우수한 성능을 보입니다. 더불어 large in-distribution training datasets에 접근할 수 있는 방법들과도 경쟁할 수 있는 성과를 인정받았습니다.



### YOLO-ELA: Efficient Local Attention Modeling for High-Performance Real-Time Insulator Defect Detection (https://arxiv.org/abs/2410.11727)
- **What's New**: 이번 논문에서는 기존 무인 항공기(UAV)에서의 절연체 결함 탐지 방법의 한계를 극복하기 위해 새로운 주의 기반 아키텍처인 YOLO-ELA를 제안합니다. 이는 Efficient Local Attention(ELA) 블록을 YOLOv8의 네크 부분에 추가하여 배경 기능에서 결함이 있는 절연체의 기능으로 모델의 주의를 전환합니다.

- **Technical Details**: YOLO-ELA는 고해상도 UAV 이미지에서 절연체 결함 탐지를 개선하기 위해 설계되었습니다. SCYLLA Intersection-Over-Union(SIoU) 기준 함수를 사용하여 탐지 손실을 줄이고 모델의 수렴 속도를 가속화하며, 소형 절연체 결함에 대한 감도를 높여 더 높은 참 긍정 결과를 생성합니다. 또한 데이터 증강 기법을 활용하여 데이터셋의 다양성을 증가시켰습니다.

- **Performance Highlights**: 실험 결과, YOLO-ELA는 96.9% mAP0.5의 최첨단 성능을 달성하고 초당 74.63 프레임의 실시간 탐지 속도를 기록하였습니다. 이는 기존 모델에 비해 현저한 개선을 나타내며, 객체 탐지 작업에서 주의 기반 CNN의 효과를 증명합니다.



### RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation (https://arxiv.org/abs/2410.11722)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 논문에서는 최근 개발된 Segment Anything (SAM)과 같은 대화형 세분화(interactive segmentation) 방법에 대한 사용자 클릭 패턴을 조사하고, 이를 기반으로 한 새로운 벤치마크 RClicks를 제안합니다. 클릭 패턴의 실제 사용에 대한 이해를 바탕으로, 클릭 가능성 모델(clickability model)을 사용하여 보다 현실적인 클릭 샘플을 생성할 수 있도록 합니다.

- **Technical Details**: 연구팀은 475,544개의 실제 사용자 클릭 데이터를 수집하여 대화형 세분화 시나리오에서 클릭 패턴을 분석했습니다. 이 연구는 saliency prediction(주목 예측) 이론을 적용하여 클릭 가능성 모델을 개발하였으며, 해당 모델은 사용자의 클릭 입력과 가장 유사한 샘플을 생성하는 데 초점을 맞추었습니다. RClicks는 기존 세분화 방법의 현실적 클릭에서 성능을 비교할 수 있는 포괄적인 벤치마크로서, (1) 클릭 수집 방법론을 도입하고, (2) 다양한 클릭 샘플링 전략을 사용할 수 있게 합니다.

- **Performance Highlights**: RClicks 벤치마크에 따르면, 기존의 방법들이 보고된 성능에 비해 현실 세계에서 성능이 저하될 수 있으며, 대부분의 방법들이 클릭 패턴에 대해 강건하지 않다는 것을 발견했습니다. 이는 기존 평가 방법이 실제 사용 시의 성능을 과대 평가할 수 있다는 점을 시사합니다. 연구에서는 다양한 세분화 방법의 평균 품질뿐만 아니라 강건성을 평가하였으며, 대화형 세분화 방법들이 모든 데이터셋에서 최적의 성능과 강건성을 동시에 달성할 수 없음을 보였습니다.



### It's Just Another Day: Unique Video Captioning by Discriminative Prompting (https://arxiv.org/abs/2410.11702)
Comments:
          ACCV 2024 Oral. Project page: this https URL

- **What's New**: 본 논문은 Long 비디오에서 중복된 클립에 대해 각 클립을 독자적으로 식별할 수 있는 캡션을 생성하는 문제를 다룹니다. 'Unique Captioning' 또는 고유 캡셔닝 문제를 제기하며, 'Captioning by Discriminative Prompting (CDP)' 방법론을 제안합니다.

- **Technical Details**: CDP는 시각적으로 유사한 클립들 사이의 차이를 판별할 수 있는 속성을 예측하여 고유한 캡션을 생성합니다. 두 가지 벤치마크를 도입하며, 하나는 일상적인 egocentric 영상, 다른 하나는 timeloop 영화에 기반하여 중복되는 행동을 포함한 비디오에서 발생하는 유사성을 활용합니다.

- **Performance Highlights**: CDP 방법이 적용된 캡션은 egocentric 비디오에서 text-to-video R@1 성능을 15% 향상시키고, timeloop 영화에서는 10% 향상시켰습니다.



### Visual Fixation-Based Retinal Prosthetic Simulation (https://arxiv.org/abs/2410.11688)
- **What's New**: 이 연구는 시각적 정지를 기반으로 하는 망막 인공막 시뮬레이션 프레임워크를 제안하였으며, 이 프레임워크는 사카드(saccade) 메커니즘에서 영감을 받아 분류 작업에서 성능 개선을 평가합니다. self-attention map을 활용하여 입력 이미지에서 두드러진 패치를 예측하고, 이를 통해 망막 이식체에 최적화된 시각 정보를 전송하는 방법을 모색합니다.

- **Technical Details**: 본 연구에서는 Vision Transformer(ViT)의 self-attention 메커니즘을 활용하여 입력 이미지의 시각적 정지 시뮬레이션을 수행합니다. 9,469개의 훈련 이미지와 3,925개의 검증 이미지로 구성된 Imagenette 데이터셋을 사용하여 최적화를 진행하며, U-Net 아키텍처를 통해 훈련 가능한 인코더가 설계되었습니다. 또한, DINOv2 모델을 사용하여 두드러진 패치를 예측하고 분류 정확도를 평가하였습니다.

- **Performance Highlights**: 이 프레임워크는 ImageNet 검증 세트의 하위 집합에서 87.72%의 분류 정확도를 달성하였으며, 이는 다운샘플링 방법에 비해 40.59%의 정확도로 크게 향상된 결과입니다. 또한, 제한된 해상도의 망막 이식체에서 더 의미 있는 지각을 생성할 가능성이 있음을 보여주고 있습니다.



### A Survey of Low-shot Vision-Language Model Adaptation via Representer Theorem (https://arxiv.org/abs/2410.11686)
- **What's New**: 본 논문은 low-shot 이미지 인식을 위한 기존 방법들을 통합하고, 이들을 다양한 차원에서 비교할 수 있는 통일된 계산 프레임워크를 제안합니다. 특히, Representer Theorem을 기반으로 하여 기존 연구를 체계적으로 정리하고, 새로운 변형들을 제안합니다.

- **Technical Details**: 제안된 프레임워크는 5개의 구성 요소로 나뉘며: 입력 이미지 인코딩, 앵커 계산, 커널 계산, 로짓 계산, 손실 함수 계산 등이 포함됩니다. 또한, kernel ridge regression (KRR)의 폐쇄형 해법을 활용하여 representers 간의 상관 관계를 모델링합니다.

- **Performance Highlights**: 11개의 공개 데이터셋에서의 광범위한 실험을 통해 제안된 방법의 효과가 검증되었습니다. 특히, 기존 PEFT 방법의 성능을 향상시키기 위한 다양한 변형들이 제안되었고, 실험 결과 이들 변형이 실제로 효과적임을 입증했습니다.



### Leveraging Structure Knowledge and Deep Models for the Detection of Abnormal Handwritten Tex (https://arxiv.org/abs/2410.11670)
- **What's New**: 본 논문에서는 손으로 쓴 텍스트에서 시퀀스 구조의 파괴를 해결하기 위한 두 단계의 감지 알고리즘을 제안합니다. 이 알고리즘은 구조 지식(structure knowledge)과 딥 모델(deep models)을 결합하여 이상한 텍스트를 효과적으로 처리합니다.

- **Technical Details**: 첫 번째 단계에서는 손으로 쓴 텍스트 이미지에서 다양한 구조 프로토타입(prototype)을 대략적으로 위치시킵니다. 두 번째 단계에서는의 결과를 바탕으로 서로 다른 감지 전략이 채택됩니다. 특히, 새로운 반지도 대조 훈련(strategy) 방법에 의해 훈련된 형태 회귀 네트워크(shape regression network)를 사용하여 문자의 위치 관계(positional relationship)를 활용합니다.

- **Performance Highlights**: 실험 결과에 따르면 제안된 방법은 두 가지 손으로 쓴 텍스트 데이터셋에서 감지 성능을 크게 향상시킵니다.



### Degradation Oriented and Regularized Network for Real-World Depth Super-Resolution (https://arxiv.org/abs/2410.11666)
Comments:
          10 pages

- **What's New**: 본 연구에서는 DORNet (Degradation Oriented and Regularized Network)이라는 새로운 방법을 제안하여 실제 세계에서의 Depth Super-Resolution (DSR) 문제를 해결한다. 제안된 방법은 저해상도 깊이(depth) 표현의 손상(degradation) 모델링에 중점을 두어 고해상도 깊이를 복원하는 데 필요한 타겟 가이드를 제공한다.

- **Technical Details**: DORNet은 세 가지 주요 구성 요소로 이루어져 있다: Self-supervised Degradation Learning(DL), Routing Selection-based Degradation Regularization(DR), Degradation Awareness(DA). DL은 저해상도 깊이에 대한 손상 표현을 모델링하며, DR은 다중 스케일 손상 커널을 생성하여 예측된 고해상도 깊이에 적용된다. 마지막으로 DA는 여러 Degradation-Oriented Feature Transformations (DOFT)를 통해 손상 표현에 맞춰 RGB 정보를 깊이에 삽입한다.

- **Performance Highlights**: 실제 및 합성 데이터세트에서의 광범위한 실험 결과, DORNet은 기존의 최첨단 방법들을 초월하는 성능을 달성하며, 고해상도 깊이 복원에 있어 정확하고 완전한 구조를 회복하는 데 성공하였다.



### VisualRWKV-HD and UHD: Advancing High-Resolution Processing for Visual Language Models (https://arxiv.org/abs/2410.11665)
- **What's New**: 본 논문에서는 VisualRWKV 모델 계열의 두 가지 새로운 발전인 VisualRWKV-HD와 VisualRWKV-UHD를 소개합니다. 이 모델들은 고해상도 시각 입력을 효과적으로 처리하도록 설계되었습니다.

- **Technical Details**: VisualRWKV-HD는 손실 없는 다운샘플링 방법을 통해 고해상도 비전 인코더와 저해상도 인코더를 통합합니다. VisualRWKV-UHD는 이미지를 4개의 세그먼트로 나눈 후 다시 조합하여 고해상도 및 저해상도 특징을 모두 포함할 수 있도록 합니다.

- **Performance Highlights**: 이 두 모델은 VLM 벤치마크에서 강력한 성능을 발휘하며, 텍스트가 풍부한 작업에서 성능이 크게 향상되었습니다. 특히 VisualRWKV-UHD는 최대 4096 x 4096 픽셀 해상도를 지원하여 보다 상세하고 포괄적인 시각 처리 능력을 제공합니다.



### RS-MOCO: A deep learning-based topology-preserving image registration method for cardiac T1 mapping (https://arxiv.org/abs/2410.11651)
- **What's New**: 본 논문은 심장 T1 맵핑에서의 모션 보정을 위한 심층 학습 기반의 이미지 등록 프레임워크를 제안합니다. 특히, BLOC이라는 암묵적 일관성 제약 조건을 도입하여 이미지의 위상을 어느 정도 유지합니다.

- **Technical Details**: 제안된 방법은 비 지도학습 방식인 심장 심실 분할 네트워크와 이중 도메인 주의 모듈을 통합하여 심장 T1 가중 이미지의 모달리티 간 등록의 성능을 향상시킵니다. 이중 일관성 제약과 지역 안티 폴딩 제약을 포함한 BLOC 제약 조건이 등록의 넌리니아(Non-Rigid) 특성을 보장합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 기존의 방법들에 비해 뛰어난 성능과 높은 견고성을 입증하였으며, 특히 모션 보정 효과의 향상에 기여함을 보여주었습니다.



### ED-ViT: Splitting Vision Transformer for Distributed Inference on Edge Devices (https://arxiv.org/abs/2410.11650)
Comments:
          14 pages, 8 figures

- **What's New**: 이 논문에서는 자원 제한이 있는 엣지 디바이스에서 복잡한 Vision Transformer 모델을 효율적으로 실행하기 위해 ED-ViT라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 Vision Transformer 모델을 데이터 클래스의 특정 부분을 처리하는 여러 서브 모델로 분할합니다.

- **Technical Details**: ED-ViT는 Vision Transformer 모델을 여러 서브 모델로 나누는 구조를 가지고 있으며, 각 서브 모델은 지정된 데이터 클래스의 하위 집합을 처리합니다. 또한, 클래스별 프루닝(class-wise pruning) 기법을 도입하여 각 서브 모델의 크기를 축소하고, 모델 배치 최적화를 위한 그리디 할당 알고리즘을 설계했습니다. 실험은 세 가지 ViT 구조에 대해 다섯 개의 데이터셋을 사용하여 수행되었습니다.

- **Performance Highlights**: 실험 결과, ED-ViT는 엣지 디바이스에서의 추론 지연을 크게 줄이고, 모델 크기를 최대 28.9배와 34.1배 감소시키면서도 기존 Vision Transformer와 유사한 테스트 정확도를 유지하는 것으로 나타났습니다. ED-ViT는 또한 CNN 및 SNN 모델과의 비교 실험에서 고속 추론과 저성능 모델 크기를 유지하는 장점을 보였습니다.



### Feature-guided score diffusion for sampling conditional densities (https://arxiv.org/abs/2410.11646)
- **What's New**: 이 논문에서는 조건부 밀도(conditional density)를 샘플링하는 새로운 스코어 확산(score diffusion) 알고리즘을 제안합니다. 기존의 방법들은 조건부 밀도의 정확한 스코어를 추정하는 데 어려움이 있었지만, 본 연구는 프로젝션된 스코어(projected score)를 이용하여 이러한 문제를 해결합니다. 또한, 같은 신경망이 스코어와 이미지 특성 벡터(feature vector)를 학습하여, 모든 클래스의 조건부 확률의 유클리드적으로 임베딩된 표현을 제공합니다.

- **Technical Details**: 새로운 알고리즘은 이미지 특성 벡터가 목표 클래스의 특성 벡터 중심(center of the feature vector)으로 향하도록 가이드를 제공합니다. 면밀하게 정의된 이미지 특성 벡터는 네트워크의 선택된 레이어에서 채널 활성화의 공간 평균(spatial averages)으로 이루어집니다. 이러한 접근법은 조건부 밀도를 샘플링하는 데 있어 한 단계씩 스코어를 조정하며, 각각의 단계에서 프로젝션된 스코어를 계산합니다. 학습 과정은 단일 감쇠 손실(denoising loss)의 최적화를 통해 이루어집니다.

- **Performance Highlights**: 제안된 알고리즘은 고품질의 다양한 샘플을 생성할 수 있으며, 각 클래스의 이미지 특성 벡터가 중심 주변에 집중됨을 보여줍니다. 모든 조건부 확률 분포에 대해 유클리드 임베딩을 통해 샘플링을 수행하여, 품질 저하나 다양성 감소 없이 목표 조건부 확률 밀도로부터의 샘플링을 정확히 수행할 수 있음을 확인했습니다. 또한 새로운 클래스의 샘플링이 가능합니다.



### Efficient and Effective Universal Adversarial Attack against Vision-Language Pre-training Models (https://arxiv.org/abs/2410.11639)
Comments:
          11 pages

- **What's New**: 이 논문에서는 Vision-language pre-training (VLP) 모델의 취약성을 극복하기 위한 새로운 방법, 즉 직접 최적화 기반의 Universal Adversarial Perturbations (UAP) 방법인 DO-UAP를 제안합니다. 이 방법은 공격 성능을 유지하면서 자원 소모를 크게 줄이는 데 중점을 두고 있습니다.

- **Technical Details**: DO-UAP는 멀티모달 손실 함수를 설계하고, 유용한 데이터 증강 전략을 도입하여 기존의 생성기 기반 UAP 방법보다 효율적인 성능을 달성합니다. 다양한 VLP 데이터셋과 모델을 사용하여 23배 더 빠른 시간 소모와 우수한 공격 성능을 입증하였습니다.

- **Performance Highlights**: 실험 결과, DO-UAP는 세 개의 벤치마크 VLP 데이터셋과 여섯 개의 인기 있는 VLP 모델에서 뛰어난 성능을 보여줍니다. 특히, 기존 방법에 비해 공격 성능이 더 개선되었으며, 실시간 온라인 애플리케이션에서도 효율적으로 적용될 수 있는 가능성을 보여줍니다.



### Simultaneous Diffusion Sampling for Conditional LiDAR Generation (https://arxiv.org/abs/2410.11628)
- **What's New**: 이 논문은 LiDAR 스캔을 여러 시점에서 본 3D 구조에 조건을 두어 포인트 클라우드를 생성하기 위한 새로운 동시 확산 샘플링 방법론을 제안합니다. 이는 다중 뷰 기하학적 제약을 활용하여 향상된 결과를 제공하는 것을 목표로 합니다.

- **Technical Details**: 제안된 방법은 스캔을 주변의 여러 가상 뷰포인트로 다시 구성하여 다수의 합성 LiDAR 스캔을 생성합니다. 이후, 이 합성 LiDAR 스캔과 입력 LiDAR 스캔은 기하학적 일관성에 따라 조건부 생성 과정을 거칩니다. 이 과정에서 다중 뷰 제약을 활용하여 관심 영역의 생성을 개선합니다.

- **Performance Highlights**: 우리의 방법은 LiDARGen 및 R2DM와 같은 단일 뷰 CLG 기법보다 성능이 크게 향상되어 다양한 벤치마크에서 기존 방법들을 능가하는 정확하고 기하학적으로 일관된 포인트 클라우드 스캔을 생성할 수 있는 것으로 나타났습니다.



### Fast Local Neural Regression for Low-Cost, Path Traced Lambertian Global Illumination (https://arxiv.org/abs/2410.11625)
Comments:
          11 pages, 10 figures, 1 table

- **What's New**: 이번 논문에서는 레이 트레이싱(ray tracing) 가속 하드웨어의 발전에도 불구하고, 상용 하드웨어에서의 실시간 ray budgets가 여전히 제한적이라는 점을 강조합니다. 이를 해결하기 위해, 저희는 독창적인 방법으로 신경망(neural network)을 도입하여 효율적인 로컬 선형 모델 기반 denoiser를 제안합니다.

- **Technical Details**: 저희의 방법은 매우 낮은 샘플 수(1 spp)에서도 람베르시안(Lambertian) 씬의 전역 조명(global illumination)을 신뢰성 있게 재구성할 수 있도록 설계되었습니다. 로컬 선형 회귀 알고리즘을 통해 1080p 해상도에서 서브 밀리세컨드 실행 시간을 기록하며, 신경망을 포함하는 방식으로 품질과 속도가 개선되었습니다. 또한, 주위 차폐(ambient occlusion)를 가이드 채널로 활용하여 성능을 증대시켰습니다.

- **Performance Highlights**: 이번 연구의 성과로, 저희의 방법은 기존보다 더 빠른 실행 속도와 뛰어난 품질을 자랑하며, 특히 저비용 레이 트레이싱 하드웨어에서도 효과적으로 작동합니다. 이 방식은 기존의 신경망 기반 방법보다 훨씬 적은 리소스에서 높은 비주얼 품질을 유지합니다.



### VidEgoThink: Assessing Egocentric Video Understanding Capabilities for Embodied AI (https://arxiv.org/abs/2410.11623)
- **What's New**: 최근 멀티모달 대형 언어 모델(MLLM)의 발전은 구체적인 AI 응용 분야에 새로운 가능성을 열었습니다. 본 논문에서는 Egocentric 비디오 이해 능력을 평가하기 위한 포괄적인 벤치마크인 VidEgoThink를 소개합니다.

- **Technical Details**: VidEgoThink는 비디오 질문-응답(video question-answering), 계층 계획(hierarchy planning), 시각 기초(visual grounding), 보상 모델링(reward modeling)의 네 가지 주요 상호 연관된 작업을 설계하여 Embodied AI에서의 하위 조작과 MLLM 간의 갭을 줄이기 위한 것입니다. 자동 데이터 생성 파이프라인을 활용해 Ego4D 데이터셋을 기반으로 적절한 질문-응답 쌍을 생성합니다. 이 과정에서 GPT-4o의 지능을 활용하고, 생성된 데이터를 인적 평가자를 통해 필터링합니다.

- **Performance Highlights**: 실험 결과 모든 MLLM은 에고센트릭 비디오 이해와 관련된 작업들에서 저조한 성능을 보였습니다. 특히, GPT-4o는 32프레임 및 8프레임에서 각각 31.17%와 32.83%의 정확도를 기록했으며, 타겟 객체와 행동, 장면의 존재를 판단하는 데는 능력이 있지만, 순서나 시퀀스를 평가하는 능력에서 부족함을 보였습니다. 전반적으로, 현시점의 MLLM을 Embodied AI의 1인칭 시나리오에 직접 적용하는 데에는 많은 도전이 남아 있으며, 향후 추가적인 연구가 필요합니다.



### MultiVENT 2.0: A Massive Multilingual Benchmark for Event-Centric Video Retrieva (https://arxiv.org/abs/2410.11619)
- **What's New**: MultiVENT 2.0이란 새로운 대규모 다국어 이벤트 중심 비디오 검색 기준이 도입되었습니다. 이 기준은 218,000개 이상의 뉴스 비디오와 3,906개의 특정 세계 사건을 겨냥한 쿼리를 포함합니다.

- **Technical Details**: 이 데이터셋은 아랍어, 중국어, 영어, 한국어, 러시아어, 스페인어 등 6개 언어의 비디오를 포함하며, 다양한 소스(비주얼 콘텐츠, 오디오, 내장 텍스트, 텍스트 메타데이터)를 활용해야 하는 쿼리가 설계되었습니다.

- **Performance Highlights**: 예비 결과는 현재 최신 비전-언어 모델(Vision-Language Models, VLMs)이 이 작업에서 상당한 어려움을 겪고 있으며, 복합적인 비전-언어 작업을 처리하기 위해 더 강력한 다중 모달 시스템의 필요성을 강조합니다.



### Depth Estimation From Monocular Images With Enhanced Encoder-Decoder Architectur (https://arxiv.org/abs/2410.11610)
- **What's New**: 이번 논문에서는 단일 2D 이미지로부터 깊이를 추정하는 도전 과제를 해결하기 위해 Inception-ResNet-v2를 인코더로 사용하는 새로운 딥러닝 기반 접근 방식을 제안합니다.

- **Technical Details**: 이 모델은 인코더-디코더 아키텍처를 사용하며, Inception-ResNet-v2를 인코더로 활용합니다. 다중 스케일(feature extraction) 특징을 통해 다양한 객체 크기와 거리에서 깊이 예측 정확도를 향상시킵니다. 또한, 깊이 손실(depth loss), 그래디언트 엣지 손실(gradient edge loss), SSIM 손실을 포함하는 복합 손실 함수(composite loss function)를 제안하여, 손실의 가중치를 조정하여 깊이 추정의 다양한 측면에서 균형을 보장합니다.

- **Performance Highlights**: NYU Depth V2 데이터셋에서 실험 결과, 저희 모델은 ARE 0.064, RMSE 0.228, 그리고 정확도($\delta$ $<1.25$) 89.3%를 달성하여 최첨단 성능을 보입니다. 이 지표들은 저희 모델이 복잡한 상황에서도 깊이를 효과적으로 예측할 수 있음을 보여줍니다.



### PaSTe: Improving the Efficiency of Visual Anomaly Detection at the Edg (https://arxiv.org/abs/2410.11591)
Comments:
          13 pages, 6 figures

- **What's New**: 이번 논문에서는 Visual Anomaly Detection (VAD)의 경량화된 접근 방식을 소개하며, 자원 제한이 있는 엣지 디바이스에서의 배치를 가능하게 하는 새로운 알고리즘인 Partially Shared Teacher-student (PaSTe)를 제안합니다. 이 알고리즘은 기존의 Student Teacher Feature Pyramid Matching (STFPM) 접근 방식을 개선하여 메모리와 컴퓨팅 요구 사항을 줄입니다.

- **Technical Details**: VAD는 픽셀 수준의 이상 탐지를 위해 비지도 학습을 이용합니다. 이 논문에서 제안한 PaSTe 알고리즘은 lightweight neural network를 사용하여 메모리 사용량을 87%까지 줄이고, 계산 성능도 50%까지 감소시킵니다. 또한, MVTec 데이터셋을 사용해 엣지 디바이스에서 VAD의 실행 가능성을 검증합니다.

- **Performance Highlights**: PaSTe 알고리즘을 통해 추론 시간은 25% 단축되고, 훈련 시간은 33% 단축됩니다. 훈련 중 최대 RAM 사용량은 76% 감소하여 VAD 프로세스를 실질적으로 더 효율적으로 만들어 엣지 디바이스에서의 실질적인 배치가 가능해졌습니다.



### Breaking Modality Gap in RGBT Tracking: Coupled Knowledge Distillation (https://arxiv.org/abs/2410.11586)
Comments:
          Accepted by ACM MM2024

- **What's New**: 이번 연구에서는 RGB(색상 영상)와 TIR(열 적외선 영상) 간의 modality gap 문제를 해결하기 위해 'Coupled Knowledge Distillation (CKD)' 프레임워크를 제안하고 있습니다. 이는 서로 다른 모달리티에서 공통 스타일을 추구함으로써 높은 성능의 RGBT 추적을 가능하게 합니다.

- **Technical Details**: CKD 프레임워크는 두 개의 학생 네트워크를 도입하여 스타일 특징의 일관성을 높이기 위해 style distillation loss를 적용합니다. 또한, RGB 및 TIR 네트워크를 원래의 teacher로 사용하여 content knowledge를 학생 네트워크에 증류하며, style과 content의 orthogonal feature decoupling 방법을 통해 문제를 해결합니다. 마스킹 모델링 전략과 다중 모달 후보 토큰 제거 전략을 함께 설계하여 추적의 강인성과 효율성을 개선합니다.

- **Performance Highlights**: 제안된 방법은 96.4 FPS의 인상적인 추적 속도를 달성하며, 네 개의 주요 공개 데이터셋에서 state-of-the-art 결과를 기록했습니다. RGBT210, RGBT234, LasHeR 및 VTUAV 데이터셋에서 각각 1.6%/2.7%, 1.6%/3.0%, 3.0%/2.0%, 10.1%/11.1%의 PR/SR 점수 향상을 보였으며, 기존 방법보다 60.2 FPS의 속도 증가를 달성했습니다.



### On-the-fly Modulation for Balanced Multimodal Learning (https://arxiv.org/abs/2410.11582)
Comments:
          Accepted by T-PAMI 2024

- **What's New**: 이번 논문에서는 다중 모달 (multimodal) 학습에서의 성능 향상을 위해 모달 간의 균형을 맞추는 새로운 접근 방식이 제안되었습니다. 기존의 공동 훈련 전략은 모든 모달에 동일한 목표를 두어 균형이 맞지 않는 단일 모달 (uni-modal) 표현이 발생하는 문제를 지적했습니다.

- **Technical Details**: 본 연구에서는 두 가지 새로운 기법인 On-the-fly Prediction Modulation (OPM)과 On-the-fly Gradient Modulation (OGM)을 소개합니다. OPM은 피드포워드 (feed-forward) 단계에서 우세한 모달리티의 영향을 줄이기 위해 동적 확률로 해당 모달의 특징을 무시하고, OGM은 역전파 (back-propagation) 단계에서 그라디언트를 완화하여 최적화 과정을 조절합니다.

- **Performance Highlights**: 제안된 방법들은 다양한 다중 모달 작업에서 눈에 띄는 성능 향상을 보여주었습니다. 이 단순하면서도 효과적인 전략은 일반 및 작업 지향적인 다중 모달 모델뿐 아니라, 보다 복잡한 다중 모달 작업에서도 효과성과 유연성을 입증했습니다.



### LCD-Net: A Lightweight Remote Sensing Change Detection Network Combining Feature Fusion and Gating Mechanism (https://arxiv.org/abs/2410.11580)
- **What's New**: 이번 연구에서 제안된 Lightweight Remote Sensing Change Detection Network (LCD-Net)는 원격 감지 이미지 변화 탐지 분야에서 전통적인 CNN 기반 방법의 단점을 극복하기 위해 모델 크기와 계산 비용을 줄이면서도 높은 탐지 성능을 유지하도록 설계되었습니다.

- **Technical Details**: LCD-Net은 이중 시계열(bitemporal) 이미지에서 특징을 효율적으로 추출하기 위해 MobileNetV2를 인코더로 사용합니다. 이 모델은 Temporal Interaction and Fusion Module (TIF)을 통해 이중 시계열 특징 간의 상호작용을 향상시켜 시간적인 맥락 인식(temporal context awareness)을 개선합니다. 또한, Feature Fusion Module (FFM)은 다중 스케일(features) 특징을 집계하여 미세한 변화를 포착하는 동시에 배경 노이즈를 억제합니다. 디코더에서 Gated Mechanism Module (GMM)은 채널 가중치를 동적으로 조정하여 주요 변화 영역을 강조하는 방식으로 특징 학습을 향상시킵니다.

- **Performance Highlights**: LCD-Net은 LEVIR-CD+, SYSU, S2Looking 데이터셋에서 실험한 결과, 단 2.56M의 파라미터와 4.45G FLOPs로 경쟁력 있는 성능을 달성하였으며, 자원이 제한된 환경에서 실시간 응용 프로그램에 적합한 모델임을 입증했습니다.



### PSVMA+: Exploring Multi-granularity Semantic-visual Adaption for Generalized Zero-shot Learning (https://arxiv.org/abs/2410.11560)
Comments:
          Accepted to TPAMI 2024. arXiv admin note: text overlap with arXiv:2303.15322

- **What's New**: 본 논문에서는 Generalized Zero-Shot Learning (GZSL)에서 시각적 특성과 속성 의미 특성 간의 상호작용을 활용하여 보지 못한 범주를 파악하기 위한 방법을 제안합니다. 기존 GZSL의 단점인 시각-의미 상응 부족 문제를 해결하기 위해, 다중-그래뉼러리 진행적 의미-시각 상호적응 네트워크(PSVMA+)를 개발했습니다.

- **Technical Details**: PSVMA+ 네트워크는 서로 다른 그래뉼러리(Granularity) 수준에서 의미-시각 상호작용을 탐색하여, 시각적 요소를 충분히 수집하도록 설계되었습니다. 각 그래뉼러리 수준에서 이중 의미-시각 트랜스포머 모듈(DSVTM)을 사용하여 공유 속성을 인스턴스 중심 속성으로 다시 구성하고, 의미 관련 시각 영역을 집계하여 모호하지 않은 시각적 특징을 학습합니다. 이 과정에서 선택적 교차 그래뉼러리 학습을 활용하여 신뢰할 수 있는 그래뉼러리로부터 지식을 활용하고, 다중-그래뉼러리 특징을 적응적으로 융합합니다.

- **Performance Highlights**: 실험 결과, PSVMA+는 최신 최첨단 방법들을 일관되게 능가하는 성능을 보여주었습니다.



### Efficiera Residual Networks: Hardware-Friendly Fully Binary Weight with 2-bit Activation Model Achieves Practical ImageNet Accuracy (https://arxiv.org/abs/2410.11553)
Comments:
          11pages, 2 figures, the model implementation is available at this https URL

- **What's New**: 이 논문에서는 Efficiera Residual Networks (ERNs)라는 새로운 모델을 소개합니다. 이 모델은 리소스가 제한된 엣지 디바이스에서의 완전한 초저비트 양자화를 지원하며, 모든 가중치와 활성화가 바이너리 형태로 구현됩니다. 기존의 모델들과 달리, ERNs는 초기 및 출력 계층에서도 부동 소수점 연산 없이 작동할 수 있습니다.

- **Technical Details**: ERNs는 가중치와 활성화를 각각 1비트(바이너리)와 2비트로 설정합니다. 이를 통해 모든 계층에서 부동소수점 값 없이 정수 기반의 잔여 연결을 수행할 수 있도록 공유 상수 스케일링 팩터라는 기술을 도입하였습니다. 이는 하드웨어 친화적인 모델을 설계하기 위한 여러 조건을 통해 이뤄졌으며, CNN의 복잡성을 줄이기 위해 표준 CNN 구조를 따릅니다.

- **Performance Highlights**: ERNs는 ResNet50 호환 아키텍처로 ImageNet에서 72.5pt의 Top-1 정확도를 달성했으며, 1MB 미만의 모델로도 63.6pt를 기록하였습니다. 또한, 가장 작은 모델은 300FPS의 추론 속도를, 가장 큰 모델은 60FPS를 달성하여 비용 효율적인 FPGA 장치에서 인상적인 성능을 발휘합니다.



### MCTBench: Multimodal Cognition towards Text-Rich Visual Scenes Benchmark (https://arxiv.org/abs/2410.11538)
Comments:
          12 pages, 5 figures, project page: this https URL

- **What's New**: 본 논문에서는 Multi-modal Large Language Models (MLLMs)의 인지 능력을 평가하기 위한 새로운 멀티모달 벤치마크, MCTBench를 제안합니다. 이 벤치마크는 텍스트가 풍부한 시각 장면에서의 인지 및 인식 능력을 통합적으로 평가하는 것이 특징입니다.

- **Technical Details**: MCTBench는 약 5.2k 개의 텍스트가 풍부한 이미지와 8.5k 개의 정밀하게 주석 처리된 질문-답변 쌍을 포함하고 있으며, 인식, 추론 및 콘텐츠 생성의 세 가지 작업으로 분류됩니다. 인식 및 추론 작업은 다중 선택 질문 형식으로 되어 있으며, 자동 평가 파이프라인을 통해 콘텐츠 생성 평가를 수행합니다.

- **Performance Highlights**: MCTBench를 통한 평가 결과, MLLMs는 인식 능력에 비해 인지 능력이 낮은 성능을 보이며, 텍스트가 강화된 모델에서 특히 두드러집니다. 담체 묘사 기준의 확장을 통해 인지 작업(추론 및 콘텐츠 생성)의 성능이 증가하는 경향이 나타났습니다.



### Overcoming Domain Limitations in Open-vocabulary Segmentation (https://arxiv.org/abs/2410.11536)
- **What's New**: 본 연구에서는 Open-vocabulary segmentation (OVS) 모델이 새로운 도메인에 대해 학습하면서 이전 지식을 유지할 수 있도록 하는 새로운 접근 방식을 제안합니다. 이전 트레이닝 데이터셋을 넘어선 새로운 도메인에서 OVS 모델의 성능 저하 문제를 해결하고자 합니다.

- **Technical Details**: 이 방법은 각 도메인에 대한 미리 계산된 다변량 정규 분포(multivariate normal distribution)를 사용하여 입력 샘플이 여러 도메인에 얼마나 근접한지를 평가합니다. 이 예측을 바탕으로, 사전 훈련된 디코더의 가중치와 미세 조정된 디코더의 가중치를 동적으로 보간(interpolate)합니다.

- **Performance Highlights**: 제안된 방법을 활용하여 OVS 모델은 새로운 도메인에 적응하면서 이전 훈련 데이터셋의 성능을 유지합니다. Cityscapes 및 ADE20k에서 미세 조정된 모델이 이전 지식을 잃지 않으면서 새로운 도메인에 잘 적응하는 모습을 보였습니다. 또한 여러 미세 조정된 데이터셋에서도 동일한 효과가 관찰되었습니다.



### Hairmony: Fairness-aware hairstyle classification (https://arxiv.org/abs/2410.11528)
- **What's New**: 본 연구에서는 단일 이미지로 사람의 헤어스타일을 예측하는 방법을 제시합니다. 기존의 방법들은 머리카락의 다양성을 충분히 포착하지 못하는 제한이 있었으나, 저자들은 새로운 분류 접근 방식을 채택하여 포괄적이고 다양한 헤어스타일을 지원하는 시스템을 목표로 하고 있습니다.

- **Technical Details**: 이 연구에서는 레이블이 잘못 붙은 데이터를 피하고, 합성 데이터(synthetic data)만을 사용하여 모델을 학습하였습니다. 이는 트레이닝 데이터의 다양성을 명시적으로 조절할 수 있게 해주며, 노이즈가 없는 정확한 레이블을 생성합니다. 저자들은 다양한 전문가들과 협력하여 새로운 헤어스타일 분류 체계를 개발하였고, 이를 바탕으로 트레이닝 데이터셋을 주석(annotation) 달았습니다.

- **Performance Highlights**: 실험 결과, 저자들이 제안한 방법은 최근의 파라메트릭 모델보다 도전적인 헤어스타일에 대해 더 강력한 성능을 보였습니다. 특히, 단일 이미지에서 높은 정확도로 헤어스타일의 분류와 예측이 가능하다는 점이 강조되었습니다.



### Look Ma, no markers: holistic performance capture without the hass (https://arxiv.org/abs/2410.11520)
- **What's New**: 이 연구에서는 얼굴, 몸, 손을 동시에 고도로 정확하게 캡처하는 새로운 기술을 소개합니다. 기존의 모션 캡처 기술은 보통 각각의 부위만을 독립적으로 캡처하며, 복잡하고 비싼 하드웨어와 숙련된 운영자의 수작업 개입이 필요했습니다. 반면, 이 기술은 마커가 필요 없고, 모든 카메라에서 자동으로 안정적인 결과를 생성할 수 있습니다.

- **Technical Details**: 이 방법은 합성 데이터에 기반하여 훈련된 머신 러닝 모델과 인체 모양 및 동작에 대한 강력한 파라메트릭 모델을 결합한 하이브리드 접근 방식을 사용합니다. 이 시스템은 하나의 이미지에서 전체 인간의 신체 형태, 표정, 손 및 혀의 움직임을 예측할 수 있으며, 추가적인 캘리브레이션이나 숙련된 수작업 없이 다양한 환경에서 작동합니다.

- **Performance Highlights**: 이 연구의 방법은 다양한 바디, 얼굴, 손 재구성 벤치마크에서 최신 기술을 보여주며, 다양한 데이터셋에 대해 일반화된 성능을 보입니다. 이 기술은 캘리브레이션이 필요 없고, 낮은 비용으로 매우 높은 품질의 성능 캡처가 가능하여 생산 작업의 효율성을 대폭 향상시킬 수 있습니다.



### Dual-Teacher Ensemble Models with Double-Copy-Paste for 3D Semi-Supervised Medical Image Segmentation (https://arxiv.org/abs/2410.11509)
Comments:
          35 pages, 5 figures

- **What's New**: 본 논문에서는 3D 의료 이미지 분할을 위한 새로운 반지도 학습(Semi-supervised Learning, SSL) 기법을 제안합니다. 특히, 이중 교사 모델(Dual-teacher model)에서 복사-붙여넣기(copy-paste) 기술을 활용하여 교사 모델 간 다양성을 높이고, 예측 샘플의 특성에 따라 유연하게 앙상블 방법을 선택하는 Staged Selective Ensemble(SSE) 모듈을 도입하여 고품질의 의사 레이블(pseudo-label)을 생성하는 방안을 제시합니다.

- **Technical Details**: 이 논문에서는 이중 교사 모델에서 발생할 수 있는 가중치 커플링(coupling) 문제를 해결하기 위해 double-copy-paste(DCP) 기법을 통합합니다. 이를 통해 교사 간의 다양성을 증가시키고, 예측 유사도(thresholds)를 설정하여 샘플 특성에 기초한 선택적 앙상블(adaptive ensemble) 전략을 도입합니다. 이런 방식으로 데이터에서 다양한 정보가 수집되도록 하여 모델의 일반화 성능을 향상시킵니다.

- **Performance Highlights**: 제안된 방법은 전통적인 지도 학습 방법에 비해 여러 고전 데이터 세트에서 우수한 성능을 보이며, 특정 지표에서 완전한 지도 학습 방법을 초과하는 결과를 달성했습니다. 실험 결과는 제안된 방법이 의료 이미지 분할 작업에 효과적임을 입증합니다.



### Spatio-Temporal Distortion Aware Omnidirectional Video Super-Resolution (https://arxiv.org/abs/2410.11506)
- **What's New**: 본 논문에서는 Omnidirectional Video (ODV) 특성을 고려한 새로운 Spatio-Temporal Distortion Aware Network (STDAN)을 제안하여 ODV의 해상도를 향상시키고 있습니다.

- **Technical Details**: 제안된 모델은 spatio-temporal distortion modulation module을 도입하여 공간적 ODV 프로젝션 왜곡을 개선하고, intra 및 inter alignments에 따른 시간적 상관관계를 활용합니다. 또한, 다중 프레임 복원 및 융합 메커니즘을 설계하여 복원된 ODV 프레임의 일관성을 개선합니다.

- **Performance Highlights**: 실험 결과, STDAN은 최신 기법들에 비해 우수한 초해상도(super-resolution) 성능을 보여주며, 다양한 시나리오를 포함하는 새로운 ODV-SR 데이터셋을 활용하여 평가되었습니다.



### LoGS: Visual Localization via Gaussian Splatting with Fewer Training Images (https://arxiv.org/abs/2410.11505)
Comments:
          8 pages

- **What's New**: 이번 논문은 LS-GS라는 새로운 비전 기반 로컬라이제이션 파이프라인을 소개합니다. LoGS는 3D Gaussian Splatting (GS) 기술을 활용하여 장면을 표현하고 있으며, 이는 고품질의 새로운 시점 합성을 가능하게 합니다. LoGS는 단 몇 개의 이미지로도 데이터의 부족 문제를 해결할 수 있도록 설계되었습니다.

- **Technical Details**: LoGS는 구조로부터의 모션 (Structure-from-motion, SfM)에 기반한 초기 맵 생성을 시작으로, 이미지 검색과 로컬 피처 매칭을 통해 초기 위치를 얻습니다. 이어서 photometric loss를 최소화하여 정확한 자세(Pose)를 측정합니다. 대표적인 요소로 PnP-RANSAC 기법을 사용하며, GS 맵을 통해 최종적인 위치 추정을 수행합니다.

- **Performance Highlights**: LoGS는 0.5%에서 1%의 훈련 이미지만을 사용해도 최첨단(SOTA)의 정확도를 자랑하며, 예를 들어 7-scenes 데이터셋의 CHESS 장면에서는 20장의 이미지만으로 평균 0.5 cm의 이동 오차와 0.16°의 회전 오차를 달성했습니다. 이러한 성과는 급속한 배포가 필요한 실제 응용에 필수적입니다.



### Online learning in motion modeling for intra-interventional image sequences (https://arxiv.org/abs/2410.11491)
Comments:
          Medical Image Computing and Computer Assisted Intervention (MICCAI) 2024

- **What's New**: 이번 연구에서는 의료 examinations (검사) 동안 이미지 모니터링과 가이드를 통해 진단과 치료의 정확성을 향상시킬 수 있는 새로운 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 선형 가우시안 상태 공간 모델(Linear Gaussian State-Space Model)을 기반으로 하며, 낮은 차원의 시간적 프로세스(low-dimensional temporal process)를 활용하여 획득한 이미지들 간의 움직임(motion)을 추정하고 미래의 움직임(forecasting)도 예측할 수 있습니다.

- **Performance Highlights**: 공개된 심장 데이터셋에 대한 두 가지 실험 결과, 환자 맞춤형 적응(patient-specific adaptation)을 통해 온라인 학습(online learning)을 적용한 경우 신뢰할 수 있는 움직임 추정과 향상된 예측 성능을 보여주었습니다.



### InvSeg: Test-Time Prompt Inversion for Semantic Segmentation (https://arxiv.org/abs/2410.11473)
- **What's New**: 이 논문은 InvSeg라는 테스트 타임 프롬프트 인버전 방법을 제안하여 개방 어휘(open-vocabulary) 의미 분할(semantic segmentation) 문제를 해결합니다.

- **Technical Details**: InvSeg는 이미지 특정 시각적 맥락(visual context)을 텍스트 프롬프트 임베딩 공간(text prompt embedding space)으로 전환하여 텍스트 프롬프트를 풍부하게 만들어 각 클래스를 구조적으로 일관된 마스크와 연결합니다. 특히, 대조적 소프트 클러스터링(Contrastive Soft Clustering, CSC)을 도입하여 유도된 마스크를 이미지의 구조 정보와 정렬합니다.

- **Performance Highlights**: InvSeg는 PASCAL VOC 및 Context 데이터셋에서 최신 성과를 기록하며, 샘플 특정 컨텍스트를 통합하여 다양한 모달리티 간의 의미 정렬을 정확하게 수행합니다.



### A Simple Approach to Unifying Diffusion-based Conditional Generation (https://arxiv.org/abs/2410.11439)
Comments:
          Project page: this https URL

- **What's New**: 최근 이미지 생성 모델에서의 새로운 접근 방식으로, 조건 신호를 통해 다양한 조건부 생성 작업을 수행할 수 있는 통합 프레임워크인 UniCon을 제안합니다.

- **Technical Details**: UniCon은 특정 이미지-조건 상관관계를 학습하기 위해, 확산 모델(diffusion model)을 사용하여 이미지 쌍의 결합 분포(joint distribution)를 학습합니다. 이 모델은 추가적 학습 파라미터가 15%로 적고, 단일 효율적인 훈련 단계를 통해 다양한 추론 샘플링 방식을 지원합니다.

- **Performance Highlights**: UniCon은 기존의 특화된 방법들과 유사하거나 더 나은 결과를 보여주며, 여러 모델을 결합하여 다중 신호 조건 생성을 가능하게 합니다.



### CTA-Net: A CNN-Transformer Aggregation Network for Improving Multi-Scale Feature Extraction (https://arxiv.org/abs/2410.11428)
Comments:
          9 pages, 3 figures

- **What's New**: 이번 논문에서는 CNN(Convolutional Neural Networks)과 ViT(Vision Transformers)를 통합한 새로운 아키텍처인 CTA-Net(Convolutional Transformer Aggregation Network)을 소개합니다. CTA-Net은 CNN과 ViT의 강점을 결합하여 지역적인 특징과 넓은 범위의 의존성을 효율적으로 추출합니다.

- **Technical Details**: CTA-Net은 새로운 LMF-MHSA(Light Weight Multi-Scale Feature Fusion Multi-Head Self-Attention) 모듈을 통해 다중 규모의 특징 통합을 효과적으로 수행하며, 매개변수를 줄이는 동시에 성능을 향상시킵니다. RRCV(Reverse Reconstruction CNN-Variants) 모듈은 transformer 내에서 CNN의 임베딩을 개선합니다.

- **Performance Highlights**: CTA-Net은 APTOS 2019 및 RFMiD2020 데이터셋에서 각각 TOP-1 정확도 86.76%, 20.32M의 적은 파라미터 수, 2.83B FLOPs를 기록하며, 소규모 데이터셋에서 시각적 작업에 매우 효율적이고 경량 솔루션으로서의 가능성을 보여줍니다.



### GS^3: Efficient Relighting with Triple Gaussian Splatting (https://arxiv.org/abs/2410.11419)
Comments:
          Accepted to SIGGRAPH Asia 2024. Project page: this https URL

- **What's New**: 본 논문에서는 다중 뷰 포인트 조명 입력 이미지로부터 실시간 고품질의 새로운 조명 및 뷰 합성을 위한 공간적 및 각도적 Gaussian 기반 표현과 트리플 스플래팅 프로세스를 제안합니다.

- **Technical Details**: 복잡한 외관을 설명하기 위해 각 공간적 Gaussian에 대한 반사 함수로 Lambertian과 각도적 Gaussian 혼합을 사용하는 것이 특징입니다. 자가 그림자 생성 및 전역 조명 보정 등 다양한 효과를 지원하기 위해 다층 퍼셉트론(MLP)을 사용하여 RGB 튜플을 계산합니다.

- **Performance Highlights**: 우리의 방법은 기하학적 다양성과 외관적 다양성을 갖춘 30 샘플에서 효과가 입증되었으며, 훈련 시간은 40-70분, 렌더링 속도는 단일 상용 GPU에서 90 fps에 달합니다. 결과는 품질 및 성능 면에서 최신 기술과 비교 우위를 보입니다.



### VidCompress: Memory-Enhanced Temporal Compression for Video Understanding in Large Language Models (https://arxiv.org/abs/2410.11417)
Comments:
          9 pages, 4 figures

- **What's New**: 새로운 Video-LLM인 VidCompress는 비디오 이해 작업을 위해 메모리 강화 시간 압축을 제공하여 비디오의 복잡한 시간-공간 관계를 더 효과적으로 모델링합니다.

- **Technical Details**: VidCompress는 이중 압축기(dial-compressor) 접근 방식을 사용합니다. 첫 번째는 메모리 강화 압축기로, 비디오에서 단기 및 장기 시간 관계를 포착하고 다중 규모 변환기(multiscale transformer)와 메모리 캐시 메커니즘을 이용해 시각 토큰을 압축합니다. 두 번째는 텍스트 인식 압축기로, Q-Former를 활용해 시간 맥락을 쿼리 임베딩에 통합하고 응집된 시각 토큰을 생성합니다.

- **Performance Highlights**: 여러 VideoQA 데이터셋과 포괄적인 벤치마크에서 VidCompress는 복잡한 시간-공간 관계를 효과적으로 모델링하며 기존 Video-LLM보다 현저히 뛰어난 성능을 보였습니다.



### MoChat: Joints-Grouped Spatio-Temporal Grounding LLM for Multi-Turn Motion Comprehension and Description (https://arxiv.org/abs/2410.11404)
- **What's New**: 이번 연구에서는 인간 모션 이해를 위한 MoChat이라는 신규 다중 모달 대형 언어 모델(Multimodal Large Language Model)을 제안합니다. MoChat은 인간 동작의 시공간(Spatio-temporal) 기초를 이해하고, 다중 턴 대화 맥락(Multi-turn Dialogue Context)을 처리할 수 있는 능력을 갖추고 있습니다.

- **Technical Details**: MoChat에서는 각 스켈레톤 프레임의 공간 정보를 인체 해부학적 구조에 따라 그룹화하고, Joints-Grouped Skeleton Encoder를 적용합니다. 이를 통해 LLM 임베딩과 결합하여 각각 시공간 인식 임베딩을 생성합니다. 또한, 스켈레톤 시퀀스에서 텍스트 주석을 기반으로 타임스탬프(Timestamp)를 추출하는 파이프라인을 개발하고, 공간적 기초를 위한 다중 턴 대화(dialogues)를 구축합니다.

- **Performance Highlights**: MoChat은 HumanML3D 데이터셋에서 모션 이해(Motion Understanding), 공간 팔다리 기초(Spatial Limb Grounding), 시간 행동 기초(Temporal Action Grounding) 작업을 수행하여 전통적인 메트릭(metric)과 GPT-4를 통해 평가한 결과, 여러 메트릭에서 최첨단 성능(State-of-the-Art Performance)을 기록했습니다. 이는 MoChat이 인간 모션의 세밀한 시공간 기초(Fine-grained Spatio-Temporal Grounding)를 가능하게 하는 첫 번째 모델임을 시사합니다.



### MCGS: Multiview Consistency Enhancement for Sparse-View 3D Gaussian Radiance Fields (https://arxiv.org/abs/2410.11394)
- **What's New**: 본 연구에서는 3D Gaussian Splatting을 기반으로 한 새로운 뷰 합성 프레임워크인 MCGS를 제안하여 희소 입력 뷰에서도 포토리얼리스틱(photorealistic) 장면 재구성을 가능하게 합니다. 기존 방법들이 다중 뷰 일관성(multi-view consistency)을 간과한 데 반해, MCGS는 이를 개선하는 혁신적인 방안을 도입하였습니다.

- **Technical Details**: MCGS의 두 가지 주요 혁신은 다음과 같습니다: i) 희소 매칭(sparse matcher)과 랜덤 채우기(random filling) 전략을 결합한 초기화 방법을 도입하여 초기 포인트 집합을 컴팩트하게 생성합니다. 이는 초기 기하학적 정보(prior)를 향상시켜 장면 표현을 효율적으로 합니다. ii) 다중 뷰 일관성 가이드(multi-view consistency-guided) 점진적 가지치기(progressive pruning) 전략을 개발하여 Gaussian 필드를 정제하고 일관성을 강화하며 기여도가 낮은 Gaussians를 제거합니다.

- **Performance Highlights**: 이러한 모듈식(modular)이고 플러그 앤 플레이(plug-and-play) 전략은 희소 입력 뷰에 대한 강인성을 향상시키고, 렌더링 속도를 가속화하며, 메모리 소비를 줄여 MCGS를 3D Gaussian Splatting에 있어 실용적이고 효율적인 프레임워크로 만듭니다.



### Augmentation-Driven Metric for Balancing Preservation and Modification in Text-Guided Image Editing (https://arxiv.org/abs/2410.11374)
Comments:
          Under review

- **What's New**: 이 논문은 CLIPScore의 한계를 지적하고, 텍스트에 기반한 이미지 편집을 위한 새로운 평가 지표인 AugCLIP을 제안합니다. AugCLIP은 이미지의 핵심 속성을 보존하면서 텍스트에 맞춰 수정을 최적화합니다.

- **Technical Details**: AugCLIP은 대형 언어 모델(large language model)을 활용하여 소스 이미지와 타겟 텍스트에 대한 상세 설명을 증강하고, CLIP 공간에서 소스와 타켓을 분리하는 하이퍼플레인을 모델링합니다. 이 모델은 이상적인 편집 이미지의 표현을 소스 이미지의 직교 투영으로 추정하며, 각 속성의 상호 종속성을 고려하여 상대적 중요성을 평가합니다.

- **Performance Highlights**: 여러 편집 시나리오에 대해 AugCLIP은 기존 지표보다 인간 평가 기준과의 정렬이 상당히 높음을 보여줍니다. 특히, AugCLIP은 개인화한 생성 및 복잡한 이미지 편집 시나리오에서의 작은 차이 식별에 뛰어난 성능을 보입니다.



### DRACO: A Denoising-Reconstruction Autoencoder for Cryo-EM (https://arxiv.org/abs/2410.11373)
- **What's New**: 이 논문에서 소개된 DRACO는 Cryogenic Electron Microscopy (cryo-EM) 이미지를 위한 새로운 Denoising-Reconstruction Autoencoder로, Noise2Noise(N2N) 방법에 영감을 받아 세밀한 노이즈 제거와 복원을 위한 하이브리드 훈련 방식을 사용하는 점이 특징적입니다. 이 모델은 고품질 및 다양한 데이터셋을 통해 더욱 효과적으로 훈련됩니다.

- **Technical Details**: DRACO는 odd 및 even 프레임을 독립적 노이즈 관측으로 처리하여 각 노이즈 패치를 복원하는 훈련을 수행합니다. 이는 두 이미지를 masking 하여 denoising과 reconstruction 작업을 창출합니다. DRACO의 훈련은 270,000개 이상의 cryo-EM 영화 및 마이크로그래프로 구성된 고품질 데이터셋을 필요로 하며, 이를 통해 다양한 downstream 작업에 일반화된 성능을 나타냅니다.

- **Performance Highlights**: DRACO는 denoising, micrograph curation 및 particle picking 작업에서 최고 성능을 보이며, 기존의 선진 모델들과 비교해 우수한 결과를 구현했습니다. 모든 downstream 작업에서 state-of-the-art baseline보다 뛰어난 성과를 보여줍니다.



### Visual-Geometric Collaborative Guidance for Affordance Learning (https://arxiv.org/abs/2410.11363)
- **What's New**: 본 논문에서는 인간-객체 상호작용에서 추출한 interactive affinity (인터랙티브 애피니티)를 활용하여 affordance (어포던스) 학습의 정확성을 높이는 새로운 접근 방식을 제안합니다. 이는 기존의 어포던스 학습 알고리즘의 한계점을 극복하는 데 초점을 맞추고 있습니다.

- **Technical Details**: 제안된 VCR-Net (Visual-geometric Collaborative guided affoRdance learning Network)은 시각적 및 기하학적 단서를 통합하여 인간-객체 상호작용에서 interactive affinity를 효율적으로 추출하고 비상호작용 객체에 전이하는 구조를 갖추고 있습니다. 특히, Semantic-pose Heuristic Perception (SHP) 모듈과 Geometric-apparent Alignment Transfer (GAT) 모듈을 통해 interaction 관련된 지역에 집중하고, 이들 지역의 기능적 특징 간 유사성을 평가하여 명확한 전이를 달성합니다.

- **Performance Highlights**: 실험 결과, 제안하는 방법이 대표적인 모델들에 비해 객관적 메트릭과 시각적 품질 모두에서 우수한 성능을 보였습니다. 특히, 55,047개의 이미지로 구성된 Contact-driven Affordance Learning (CAL) 데이터셋을 활용하여 모델의 효과성을 검증하였습니다.



### SeaDATE: Remedy Dual-Attention Transformer with Semantic Alignment via Contrast Learning for Multimodal Object Detection (https://arxiv.org/abs/2410.11358)
- **What's New**: 본 연구에서는 SeaDATE라는 새로운 다중 모달 객체 탐지 방법을 제안합니다. 이 방법은 Transformer 기반의 이중 주의 메커니즘을 활용하여 지역 및 글로벌 정보를 통합합니다. 특히, 깊은 의미 정보를 추출할 때의 한계를 극복하기 위해 대조 학습 모듈을 도입하였습니다.

- **Technical Details**: SeaDATE는 DTF(Dual Attention Feature Fusion) 모듈을 사용하며, 이 모듈은 공간 및 채널 토큰을 통해 다중 모달 특징을 효과적으로 융합합니다. 대조 학습(CL) 모듈은 깊은 특징 간의 상호 작용을 촉진하며, 다양한 깊이 층의 특징을 통합하여 Transformer 인도 융합 방법에서 발생하는 한계를 해결합니다.

- **Performance Highlights**: FLIR, LLVIP, M3FD 데이터 세트를 기준으로 한 실험 결과, SeaDATE는 최신 기술 대비 뛰어난 탐지 성능을 보여주며, 다중 모달 정보를 활용한 정확성과 신뢰성을 크게 향상시킵니다.



### CONSULT: Contrastive Self-Supervised Learning for Few-shot Tumor Detection (https://arxiv.org/abs/2410.11307)
Comments:
          14 pages, 4 figures

- **What's New**: 본 연구에서는 CONSULT(Contrastive Self-supervised Learning for few-shot Tumor detection)이라 불리는 최신 이단계(anomaly detection) 알고리즘을 소개합니다. 이는 매우 제한된 MRI 뇌 이미지를 사용할 때도 높은 성능을 유지할 수 있도록 설계되었습니다.

- **Technical Details**: CONSULT의 첫 번째 단계는 미리 훈련된(feature extractor) 특징 추출기를 MRI 뇌 이미지를 위해 fine-tuning하고, 합성 데이터를 생성하는 파이프라인을 통해 종양 유사 데이터를 만들어냅니다. 두 번째 단계는 PatchCore를 사용하여 첫 번째 단계에서 fine-tuned된 가중치를 통해 전통적인 특징 추출을 수행합니다. 또한 Tritanh Loss라는 새로운 대조 손실 기능을 도입하여 안정적인 학습을 지원하고, gradient flow를 개선합니다.

- **Performance Highlights**: CONSULT는 2, 4, 6, 8 shots에서 각각 9.4%, 12.9%, 10.2%, 6.0%의 성능 향상을 달성하며, 건강한 이미지만으로 훈련하여 기존 PatchCore 알고리즘을 초월하는 결과를 보여주었습니다.



### Have the VLMs Lost Confidence? A Study of Sycophancy in VLMs (https://arxiv.org/abs/2410.11302)
- **What's New**: 이번 연구에서는 LLMs(대형 언어 모델)의 시코팬시(sycophancy) 문제를 VLMs(비주얼 언어 모델)로 확장하여 다루었습니다. 특히, VLMs에서 시코팬시에 대한 연구가 부족하다는 점을 강조하며, 새로운 MM-SY 벤치마크를 도입했습니다.

- **Technical Details**: 시코팬시(sycophancy)는 LLMs가 원래의 올바른 응답을 따르지 않고 사용자 의견에 무비판적으로 동의하는 현상을 말합니다. 본 연구에서는 시코팬시를 완화하기 위한 합성 데이터셋(synthetic dataset)을 제안하고, 프롬프트(prompts), 감독된 미세 조정(supervised fine-tuning), DPO(Deep Prompting Optimization) 기반의 방법들을 사용하여 효과적으로 문제를 해결하였습니다. 또한, VLMs의 시코팬시가 의미론적(semiotic)으로 미치는 영향을 평가하기 위해 주목(attention) 분포를 분석했습니다.

- **Performance Highlights**: 실험 결과, 상위 레이어에서의 시코팬시 예방 능력이 두드러지며, 상위 레이어에서의 이미지(attention) 지식 부족이 시코팬시에 기여하고 있음을 확인했습니다. 이에 따라, 고급 레이어에서의 이미지 주목(attention)을 향상시키는 것이 시코팬시 문제를 완화하는 데 유용하다는 결과를 얻었습니다.



### Open World Object Detection: A Survey (https://arxiv.org/abs/2410.11301)
- **What's New**: 이번 연구는 **Open World Object Detection (OWOD)**라는 새로운 분야를 소개하며, 이는 **deep neural networks** 내에서 지식을 인식하고 학습하는 내용을 다룹니다. OWOD는 초기 훈련 세트에 없는 객체를 인식하고 학습하여 지식 기반을 점진적으로 확장하는 방법론입니다. 이 설문 논문은 OWOD의 문제 정의, 기준 데이터셋, 소스 코드, 평가 메트릭스, 기존 방법들에 대한 비교 연구 등의 주요 요소를 포괄적으로 검토합니다.

- **Technical Details**: OWOD는 기존의 객체 탐지와는 근본적으로 차별화되며, 동적 환경에서의 적응성을 인정합니다. 일반적인 객체 탐지는 훈련 중 모든 클래스가 존재한다고 가정하나, OWOD는 알려진 클래스와 함께 알려지지 않은 클래스도 탐지하고 학습할 수 있습니다. 이를 통해 모델은 새로운 데이터를 통합하면서 'catastrophic forgetting' 문제를 완화하여 이전에 학습한 정보를 유지할 수 있습니다. 이 연구에서는 OWOD의 기초를 **Open Set Recognition (OSR)** 및 **Incremental Learning (IL)**와 비교하여 설명합니다.

- **Performance Highlights**: OWOD는 **MS-COCO** 데이터셋을 활용한 실험으로, 알려진 클래스와 새로운 클래스에 대한 정확도를 평가하였습니다. OWOD는 기존의 객체 탐지 방법에 비해 더 나은 적응성과 확장성을 제공하며, 이는 실제 세계의 변동성에 대응하는 데 더 적합합니다. OWOD는 다양한 기존 방법들과 비교하여 성능 관리의 기준을 제시하며, 이 영역에서의 향후 연구 방향도 제안하고 있습니다.



### Scalable Indoor Novel-View Synthesis using Drone-Captured 360 Imagery with 3D Gaussian Splatting (https://arxiv.org/abs/2410.11285)
Comments:
          Accepted to ECCV 2024 S3DSGR Workshop

- **What's New**: 본 논문에서는 드론이 촬영한 360 동영상으로부터의 실내 새로운 뷰( Novel-View ) 합성을 위해 효율적이고 확장 가능한 파이프라인을 제안합니다. 이를 통해 각 블록을 개별적으로 병렬 처리할 수 있게 자동으로 장면을 작은 블록으로 분할하는 분할 정복 (Divide-and-Conquer) 전략을 포함합니다.

- **Technical Details**: 제안된 파이프라인은 데이터 캡처 단계에서 360° 카메라를 사용하여 다양한 시점(viewpoints)에서 장면을 포착하며, 이를 통해 안정적인 드론 경로로 촬영할 수 있습니다. 3D Gaussian Splatting을 이용하여 장면을 표현하고, 블록 간의 정렬을 위한 간단한 조정 방법을 사용합니다. 각 블록은 필요할 때만 메모리에 로드되어 계산 복잡성을 줄입니다.

- **Performance Highlights**: 제안된 방법은 기존 방법들과 비교하여 PSNR에서 최대 13.88 dB, SSIM에서 0.22의 향상을 보여주며, 처리 시간은 10배 더 빨라졌습니다.



### Contrastive learning of cell state dynamics in response to perturbations (https://arxiv.org/abs/2410.11281)
Comments:
          20 pages, 6 figures, 3 appendix figures, 4 videos (ancillary files)

- **What's New**: DynaCLR는 시간 지각된 contrastive learning을 통해 세포 역학을 모델링하기 위한 자기 지도 학습 프레임워크입니다. 이는 시간 경과에 따른 데이터셋의 대표성을 학습하여 생물학적 상태의 보다 정량적이고 효율적인 해석을 가능하게 합니다.

- **Technical Details**: DynaCLR은 여러 채널의 3D 타임랩스 이미지를 이용하여 세포의 형상 역학을 분석합니다. 이 프레임워크는 셀 및 오르가넬의 형태학적 역학을 시간적으로 정규화된 임베딩 공간에 매핑하여 분석할 수 있게 해줍니다. 학습된 임베딩은 세포의 형태학적 상태를 정량화하고 분류하는 데 사용됩니다.

- **Performance Highlights**: DynaCLR로 학습된 모델은 95% 이상의 감염 상태 분류 정확도를 달성하며, 세포의 일시적 상태를 감지하고 이전에 보지 못한 실험을 신뢰성 있게 임베딩할 수 있는 능력을 보여줍니다. 이 접근법은 감염, 유전자 변형, 약물에 대한 세포 상태 역학의 비교 분석에 유연한 프레임워크를 제공합니다.



### Rethinking the Role of Infrastructure in Collaborative Perception (https://arxiv.org/abs/2410.11259)
Comments:
          Accepted by ECCV 2024 Workshop MAAS, 14 pages

- **What's New**: 본 연구에서는 차량 중심의 Collaborative Perception(CP)과 인프라 중심의 CP의 효과를 비교하여 인프라 데이터의 중요성을 정량적으로 평가합니다. 이는 인프라를 자율주행 시스템의 에고 에이전트로 재조명하는 첫 번째 시도입니다.

- **Technical Details**: 이 논문은 인프라 데이터의 영향을 분석하기 위해 V2XSet와 V2X-Sim 데이터세트를 사용하였으며, 3D 감지 정확도 향상을 위해 기존 차량 중심 CP와 인프라 중심 CP를 비교하였습니다. 이러한 CP 구조는 메타데이터 공유, 특징 추출 및 융합 과정을 포함합니다.

- **Performance Highlights**: 연구 결과, 인프라 데이터를 통합함으로써 3D 감지 정확도가 최대 10.87% 향상되었으며, 인프라 중심 CP는 차량 중심 CP와 비교해 잡음 로버스트성을 증가시키고 정확도를 최대 42.53% 향상시켰습니다.



### CLIP-DFGS: A Hard Sample Mining Method for CLIP in Generalizable Person Re-Identification (https://arxiv.org/abs/2410.11255)
Comments:
          Accepted by ACM TOMM

- **What's New**: 본 논문에서는 CLIP 기반의 새로운 하드 샘플 마이닝 방법인 DFGS(Depth-First Graph Sampler)를 제안합니다. DFGS는 깊이 우선 탐색 알고리즘을 기반으로 하여, 이미지와 텍스트 인코더 모두에 적용 가능하며, 미니 배치를 형성하는 과정에서 도전적인 샘플을 제공함으로써 CLIP의 정밀한 특징 추출 능력을 향상시킵니다.

- **Technical Details**: DFGS를 통해 복잡한 사례들을 효과적으로 구분할 수 있는 고차별적인 미니 배치를 생성합니다. 전통적인 샘플링 기법인 PK 샘플러는 무작위로 클래스를 선택하여 샘플을 형성하지만, DFGS는 더 도전적인 샘플들을 집중적으로 선택하여 학습 과정의 효율성을 높입니다. 이 방법은 CLIP의 크로스 모달 학습 능력을 활용하여 특히 일반화된 사람 재식별(DG-ReID) 작업에서 효과적으로 작동합니다.

- **Performance Highlights**: DGF의 실험 결과, 기존 방법들에 비해 재식별 성능이 눈에 띄게 향상되었음을 보여주며, 여러 표준 벤치마크 데이터 세트에서 효과적인 성능 개선을 확인했습니다. DFGS는 특히 도전적인 샘플을 제공하여 CLIP의 학습 능력과 일반화 성능을 강화하는 데 기여합니다.



### Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models (https://arxiv.org/abs/2410.11242)
- **What's New**: 이번 연구에서는 VHExpansion을 도입하여 시각적 환각(Visual Hallucination, VH) 테스트 케이스를 자동으로 확장할 수 있는 최초의 방법을 제안합니다. 기존 방법들은 인간의 주석에 의존하여 VH 테스트 케이스를 생성했으나, VHExpansion은 질문과 답변의 부정, 이미지의 일반적 및 적대적 변형을 통해 테스트 케이스를 자동으로 확장합니다.

- **Technical Details**: VHExpansion은 초기 VH 테스트 케이스를 기반으로 하여 질문과 답변을 부정(non-affirmation)으로 변경하고, 이미지에 일반적인 이미지 처리(예: JPEG 압축, 가우시안 노이즈) 및 적대적 이미지 변형을 추가하여 새로운 VH 테스트 케이스를 생성합니다. 또한, 대칭 정확도(symmetric accuracy)라는 새로운 평가 지표를 제안하여 각 테스트 케이스와 그 부정된 대응물의 올바른 응답 비율을 측정합니다.

- **Performance Highlights**: VHExpansion을 사용하여 수동으로 주석이 달린 세 개의 VH 데이터셋을 확장한 결과, 기존 MLLM 모델보다 VH 테스트 케이스를 더 많이 식별했습니다. 대칭 정확도는 기존의 정확도와 다른 결론을 도출하며, MLLM을 VHExpansion으로 생성된 확장된 VH 데이터셋으로 미세 조정한 결과 VH를 효과적으로 줄일 수 있음을 보여주었습니다.



### Learning Diffusion Model from Noisy Measurement using Principled Expectation-Maximization Method (https://arxiv.org/abs/2410.11241)
- **What's New**: 이 연구는 다양한 종류의 노이즈가 있는 데이터에서 디퓨전 모델(Diffusion Models)을 학습하기 위한 원칙적인 기대 최대화(Expectation-Maximization, EM) 프레임워크를 제안합니다. 기존의 접근 방식은 이론적 수렴 보장이 부족하거나 특정 데이터 손상 유형에 제한되어 있었으나, 본 연구는 다양한 손상 유형에 대해 효과적인 솔루션을 제공합니다.

- **Technical Details**: 본 연구는 각기 다른 손상 유형의 노이즈 데이터로부터 디퓨전 모델을 학습하며, 플러그 앤 플레이 몬테 카를로(plug-and-play Monte Carlo, PMC) 방법을 통해 재구성된 이미지로 모델을 훈련하는 과정을 반복합니다. 초기 추정(E-step)과 최대화(M-step) 과정을 반복하여 수렴에 도달하며, 이를 통해 더 정확한 클린 이미지 분포를 학습합니다. 주요 매개변수는 로스를 최소화하고 정밀한 후방 샘플링을 보장하도록 조정됩니다.

- **Performance Highlights**: 노이즈가 있는 CIFAR-10 및 CelebA 데이터셋에 대한 실험 결과, 제안된 방법이 기존 방법들과 비교하여 고충실도(high-fidelity) 디퓨전 프라이어를 효과적으로 학습하고, 이미지 재구성 품질을 유의미하게 향상시킨다는 것을 보여주었습니다.



### Ctrl-U: Robust Conditional Image Generation via Uncertainty-aware Reward Modeling (https://arxiv.org/abs/2410.11236)
Comments:
          Preprint. Work in progress

- **What's New**: 본 논문에서는 사용자 지침에 따라 이미지를 생성하는 조건부 이미지 생성(conditional image generation) 작업에 중점을 두고 있습니다. 저자들은 기존의 패널티 시스템의 한계를 극복하기 위해, 불확실성을 고려한 보상 모델링(unity-aware reward modeling)인 Ctrl-U를 제안하며, 이는 부정확한 피드백의 부정적 영향을 최소화합니다.

- **Technical Details**: Ctrl-U는 불확실성 추정(uncertainty estimation)과 불확실성 인식 정규화(uncertainty-aware regularization)를 포함하는 두 단계로 구성됩니다. 이 방법을 통해 이미지를 생성하는 과정에서 보상의 가중치를 상황에 맞게 조정하며, 낮은 불확실성을 가진 보상에는 높은 가중치를 부여하여 신뢰할 수 있는 신호에서 학습하도록 합니다.

- **Performance Highlights**: 다양한 조건 시나리오에서의 확장성(scalability)과 이미지 품질 생성을 포함하여 총 다섯 개의 벤치마크에서 실험을 통해 그 유효성을 입증하였습니다. 이를 통해 이미지 생성의 제어 가능성(controllability)과 생성 품질을 향상시킬 수 있음을 보여줍니다.



### Representation Similarity: A Better Guidance of DNN Layer Sharing for Edge Computing without Training (https://arxiv.org/abs/2410.11233)
Comments:
          3 pages, 4 figures, ACM MobiCom '24, November 18-22, 2024, Washington D.C., DC, USA

- **What's New**: 이번 논문에서는 기존의 모델 병합 기술의 한계를 극복하고, 데이터 전송 및 처리 지연을 줄이며 엣지 디바이스에서의 메모리 제약을 해결할 수 있는 새로운 방식으로 레이어의 출력을 공유하는 방법을 제안합니다. 이를 통해 ground truth 없이도 병합 모델의 성능을 예측할 수 있는 가능성을 보여줍니다.

- **Technical Details**: 모델 병합 기술은 서로 다른 DNN(Deep Neural Networks)에서 아키텍처적으로 동일한 레이어들을 결합하는 전통적인 방식에서 벗어나, 레이어의 출력을 공유하는 방식을 채택합니다. 이 방법은 Centered Kernel Alignment (CKA) 메트릭을 이용하여 레이어 유사성을 정량화하고, 이를 기반으로 병합된 모델의 정확도를 예측합니다. 이로 인해, 아키텍처적으로 동일하지 않은 레이어들도 함께 병합할 수 있는 가능성을 열었습니다.

- **Performance Highlights**: 제안된 방법을 통해 레이어 간의 유사성을 평가한 결과, Pearson 상관계수 |r| > 0.94로 나타나 병합된 모델의 정확도가 유사성과 매우 밀접한 관계가 있다는 것을 보여주었습니다. 새로운 방법론을 통해 엣지 디바이스에서 메모리 효율성을 높이면서도 성능을 유지할 수 있는 가능성이 확인되었습니다.



### TEOcc: Radar-camera Multi-modal Occupancy Prediction via Temporal Enhancemen (https://arxiv.org/abs/2410.11228)
Comments:
          Accepted by ECAI2024

- **What's New**: 본 논문은 radar-camera 멀티 모달의 시간 강화(temporal enhanced) 점유 예측 네트워크인 TEOcc를 제안합니다. 이 네트워크는 3D 객체 탐지에서 시간 정보를 활용한 성공을 기반으로 하며, 기존의 점유 예측 방법이 장기적 시간 정보를 충분히 활용하지 못한 문제를 해결하고자 합니다.

- **Technical Details**: TEOcc의 주요 기술적 특징은 시간 강화(branch)와 다중 모달 입력을 활용한 점유 예측을 통합하는 것입니다. 이 네트워크는 각기 독립적인 장기 및 단기 시간 디코더를 사용하여 상대적으로 무작위로 버려진 입력 프레임의 3D 점유 사항을 예측합니다. 또한, 연산 비용을 줄이기 위해 3D convolutional layers를 특별히 설계하였습니다.

- **Performance Highlights**: TEOcc는 nuScenes 벤치마크에서 최첨단(시대적인) 성능의 점유 예측을 달성하였으며, 제안된 시간 강화 브랜치는 기존 점유 예측 방법에 쉽게 통합할 수 있는 플러그 앤 플레이 모듈로서 성능 개선에 기여할 수 있습니다.



### A CLIP-Powered Framework for Robust and Generalizable Data Selection (https://arxiv.org/abs/2410.11215)
Comments:
          10 pages

- **What's New**: 본 논문에서는 CLIP 기반의 데이터 선택 프레임워크를 제안하여 다중 모달 정보(multimodal information)를 활용한 보다 견고하고 일반화 가능한 데이터 선택을 가능하게 합니다. 이는 카테고리 텍스트가 이미지 모달리티(image modality)를 보완하여 전체 성능을 향상시키는 데 기여합니다.

- **Technical Details**: 제안된 프레임워크는 데이터셋 적응(dataset adaptation), 샘플 스코어링(sample scoring), 선택 최적화(selection optimization)의 세 가지 주요 모듈로 구성되며, 각 모듈이 광범위하게 미리 훈련된 다중 모달 지식을 활용하여 샘플의 영향을 포괄적으로 평가하고 다중 목적 최적화(multi-objective optimization)를 통해 선택 결과를 최적화합니다.

- **Performance Highlights**: 다양한 벤치마크 데이터셋에서의 실험 결과 제안된 방법이 기존 최첨단 방법들보다 지속적으로 더 우수한 성능을 보였으며, 특히 노이즈나 손상된 샘플을 효과적으로 제거하여 적은 데이터로 더 높은 성능을 달성했습니다. 예를 들어, CIFAR-100에서 8.13%, Tiny-ImageNet에서 4.41%의 정확도 향상이 있었습니다.



### CVCP-Fusion: On Implicit Depth Estimation for 3D Bounding Box Prediction (https://arxiv.org/abs/2410.11211)
Comments:
          7 pages, 5 figures. arXiv admin note: text overlap with arXiv:2205.02833 by other authors

- **What's New**: 본 논문에서는 Cross-View Center Point-Fusion (CVCP-Fusion)이라는 최첨단 모델을 제안하며, 이 모델은 카메라와 LiDAR에서 파생된 기능을 BEV 공간에서 결합하여 3D 객체 감지의 정확도를 향상시킵니다. 기존의 점 기반(point-level) 융합 방법과의 차별점은 카메라의 세부 정보를 보존하는 동시에 LiDAR의 공간 데이터를 통합해 정확한 바운딩 박스 예측을 가능하게 합니다.

- **Technical Details**: CVCP-Fusion 아키텍처는 Cross-View Transformers와 CenterPoint 알고리즘을 활용하여, 두 입력 스트림을 평행으로 처리하면서 실시간 성능을 제공할 수 있도록 최적화됩니다. 이미지 특징은 EfficientNet-B4 아키텍처를 통해, LiDAR 특징은 Point Pillars Network 3D Encoder를 사용하여 추출됩니다. 이 모델은 공유된 BEV 공간에서 다중 센서 데이터를 융합해 시각적 정보를 보존하며, 각 입력 스트림에 대한 모달 전용 인코더를 통과시켜 3D 세계-뷰 공간에서 특징을 결합합니다.

- **Performance Highlights**: 실험 결과, CVCP-Fusion 모델은 다양한 환경에서 높은 정확도로 3D 바운딩 박스를 예측하는 성능을 보여주었으며, LiDAR-융합 모델과 비교하여 대폭 향상된 성능을 기록했습니다. 이 모델은 다양한 날씨 환경과 교통 상황에서도 안정적으로 작동하며, 실시간 처리에 적합한 효율성과 정확성을 제공합니다.



### DreamSteerer: Enhancing Source Image Conditioned Editability using Personalized Diffusion Models (https://arxiv.org/abs/2410.11208)
Comments:
          Published as a conference paper at NeurIPS 2024

- **What's New**: 최근의 텍스트-이미지 개인화 방법들이 사용자가 지정한 개념을 몇 개의 이미지로 학습하여 새로운 맥락에서 이를 재사용하는 데 큰 가능성을 보이고 있습니다. 본 연구에서는 이미지 편집을 위한 개인화된 개념을 사용하는 DreamSteerer라는 플러그인 방법을 제안합니다. 이는 기존 T2I 개인화 방법의 편집 가능성을 향상시키는데 중점을 두고 있습니다.

- **Technical Details**: DreamSteerer는 출발 이미지에서의 편집 가능성을 향상시키기 위해 Editability Driven Score Distillation (EDSD)이라는 새로운 목표를 도입합니다. 이 과정에서 확률적 점수 증류 샘플링을 통해 개인화된 Diffusion 모델의 현상 좁힘 문제를 해결하고, 이와 함께 Delta Denoising Score 프레임워크의 두 가지 주요 수정을 통해 개인화된 개념을 사용하는 고충실도 로컬 편집을 가능케 합니다.

- **Performance Highlights**: Extensive experiments demonstrated that DreamSteerer significantly improves the editability of existing T2I personalization methods, especially in challenging scenarios that require significant structural adjustments and a small number of fine-tuning steps (∼10) to achieve these improvements.



### Tree of Attributes Prompt Learning for Vision-Language Models (https://arxiv.org/abs/2410.11201)
- **What's New**: 본 논문에서는 Tree of Attributes Prompt learning (TAP)을 제안하여, 기존의 방법이 범주 이름만으로 구성된 학습 가능한 프롬프트(learnable prompt tokens)를 사용하여 텍스트 특성을 얻는 한계점을 극복하고자 합니다. TAP는 각 범주에 대해 '개념 - 속성 - 설명' 구조의 속성 트리를 생성하고, 이 계층 구조를 학습하여 시각 및 텍스트 프롬프트와 통합합니다.

- **Technical Details**: TAP 방법은 기존의 비구조적 설명 집합으로 범주 이름을 단순히 보강하는 접근 방식과는 달리, LLMs(large language models)에서 클래스 이름과 관련된 구조화된 지식 그래프를 정제하여 이들을 시스템적으로 통합합니다. 이를 통해 각 속성의 세부 정보를 체계적으로 구성하며, 입력된 이미지의 내용에 기반하여 가장 적합한 설명을 추출하는 vision-conditional pooling 모듈도 도입하였습니다.

- **Performance Highlights**: TAP는 11개의 다양한 데이터셋에서 제로샷(base-to-novel) 일반화, 크로스 데이터셋 전이(cross-dataset transfer), 그리고 몇 샷(classification) 분류에서 최첨단(state-of-the-art) 방법을 능가하는 성능 향상을 달성했습니다. 평균적으로 1.07%의 성과 향상을 보여주었고, CLIP에 비해 9.34%의 개선 효과를 나타냈습니다.



### Multiview Scene Graph (https://arxiv.org/abs/2410.11187)
Comments:
          To be published in NeurIPS 2024. Website at this https URL

- **What's New**: 이 논문에서는 유사한 시각적 인식 능력을 가진 AI 모델의 개발을 목표로 한 Multiview Scene Graph (MSG) 생성을 제안합니다. MSG는 연결된 장소 및 객체 노드로 구성된 장면의 위상을 표현합니다.

- **Technical Details**: MSG는 시각적인 장소 인식, 객체 탐지, 객체 연결 작업을 동시에 처리해야 하며, 새로운 Transformer 기반 아키텍처인 Attention Association MSG (AoMSG)를 사용하여 장소와 객체의 임베딩을 공동으로 학습합니다. MSG는 기존의 3D 장면 그래프와 달리 깊이 및 포즈 정보가 필요하지 않습니다.

- **Performance Highlights**: 실험 결과, 제안된 AoMSG 모델이 기존의 관련 기법들에 비해 우수한 성능을 보여 주며, 공간 인식의 발전 필요성을 확인했습니다.



### Synthesizing Proton-Density Fat Fraction and $R_2^*$ from 2-point Dixon MRI with Generative Machine Learning (https://arxiv.org/abs/2410.11186)
- **What's New**: 이번 연구에서는 두 점 Dixon MRI에서의 PDFF(프로톤 밀도 지방 분율) 및 R2*(자기 공명 완화 시간 상수)의 수치를 얻기 위한 생성적 머신러닝 접근법을 제안합니다. 인접한 voxels(부피 요소) 간의 유사성을 활용하여, 기존의 전통적인 방법보다 더 정확한 결과를 도출합니다.

- **Technical Details**: 우리는 UK Biobank 데이터셋을 활용하여, Pix2Pix conditional GAN(조건부 생성 적대 신경망)을 통해 두 점 Dixon MRI로부터 PDFF 및 R2* 를 보간하는 방법을 개발하였습니다. 이 연구에서는 기존 기술에 비해 각 voxel에서 두 점 Dixon MRI만으로 유의미한 R2* 를 추정하는 데 성공했습니다.

- **Performance Highlights**: 제안된 접근법을 통해 생성한 PDFF 및 R2* 맵은 기존의 voxel-wise(부피 요소 수준) 기법보다 더 큰 상관관계를 보였으며, 특히 R2* 추정에서 전통적인 방법이 실패했던 경우에서도 좋은 정확도를 유지했습니다.



### Improving Bias in Facial Attribute Classification: A Combined Impact of KL Divergence induced Loss Function and Dual Attention (https://arxiv.org/abs/2410.11176)
Comments:
          15 pages, 9 figures, 5 tables

- **What's New**: 이 논문은 AI 기반 얼굴 인식 시스템의 공정성을 높이기 위한 새로운 접근 방식을 제안합니다. 이 방법은 사전 훈련된 Inception-ResNet V1 모델을 사용하여 듀얼 어텐션 메커니즘을 적용하고, KL-다이버전스(KL-divergence) 정규화와 크로스 엔트로피 손실 함수(cross-entropy loss function)를 통해 개선되었습니다.

- **Technical Details**: 제안된 방법은 데이터의 다양성, 공정성과 정확성의 균형, 불균형 및 편향 측정과 같은 많은 문제들을 해결하는 데 도움을 줄 수 있습니다. 특히, transfer learning을 이용하여 편향을 줄이고, 정확도와 계산 효율성을 향상시킵니다.

- **Performance Highlights**: 실험 결과, 공정성과 분류 정확도 모두에서 유의미한 개선이 보여줍니다. 이는 얼굴 인식 시스템의 신뢰성을 높이는 데 긍정적인 발전을 제공합니다.



### Towards General Deepfake Detection with Dynamic Curriculum (https://arxiv.org/abs/2410.11162)
Comments:
          Received by ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)

- **What's New**: 이번 연구에서는 Deepfake 탐지를 위해 새로운 표본 강도를 훈련 과정에 도입하는 커리큘럼 학습(Curriculum Learning) 패러다임을 제안합니다. 제안된 방법론은 모델이 훈련 중에 점진적으로 어려운 표본에 집중할 수 있도록 돕습니다.

- **Technical Details**: Dynamic Facial Forensic Curriculum (DFFC)이라는 새로운 접근 방식을 제안하며, 이는 Dynamic Forensic Hardness (DFH)를 통해 훈련 중 표본의 강도를 동적으로 측정합니다. DFH는 얼굴 품질 점수와 즉각적인 인스턴스 손실을 통합하여 정의됩니다. 또한, DFFC는 쉬운 표본에서 어려운 표본으로 훈련 데이터를 단계적으로 제어하는 페이싱 함수(Pacing Function)를 통합합니다.

- **Performance Highlights**: DFFC를 통해 다양한 종류의 end-to-end Deepfake 탐지기의 성능을 개선할 수 있음을 보여주는 포괄적인 실험 결과를 도출하였습니다. DFFC는 플러그 앤 플레이 방식으로 기존 탐지기에 쉽게 적용할 수 있으며, 어려운 표본의 정보를 효과적으로 활용하여 일반적인 변조 특징 학습을 지원합니다.



### MANet: Fine-Tuning Segment Anything Model for Multimodal Remote Sensing Semantic Segmentation (https://arxiv.org/abs/2410.11160)
Comments:
          12 pages, 9 figures

- **What's New**: 이 연구에서는 다중 모드 원거리 감시 데이터에 대한 새로운 다중 모드 어댑터 기반 네트워크(MANet)를 소개합니다. 이는 Segment Anything Model(SAM)의 이미지를 인코더를 통해 다중 모드 데이터를 효과적으로 활용하도록 조정합니다.

- **Technical Details**: 본 연구의 핵심에는 MMAdapter(다중 모드 어댑터) 개발이 있으며, 이는 SAM의 이미지 인코더를 미세 조정하여 다중 모드 원거리 감시 데이터의 통합을 용이하게 합니다. 또한, Deep Fusion Module을 통해 다양한 스케일의 지리적 특성을 통합합니다.

- **Performance Highlights**: 제안된 MANet은 ISPRS Vaihingen 및 ISPRS Potsdam의 두 개의 고해상도 다중 모드 원거리 감시 데이터셋에서 기존 모델을 크게 초월하는 성능을 보였습니다.



### UAV3D: A Large-scale 3D Perception Benchmark for Unmanned Aerial Vehicles (https://arxiv.org/abs/2410.11125)
Comments:
          Accepted at NeurIPS 2024

- **What's New**: UAV3D는 무인 항공기(UAV)가 3D 인식을 효과적으로 수행할 수 있도록 지원하는 새로운 벤치마크 데이터셋입니다. 이 데이터셋은 1,000개의 서로 다른 장면으로 구성되어 있으며, 각 장면마다 20개의 프레임이 포함되어 있고, 차량에 대한 완전한 3D 바운딩 박스 주석이 제공됩니다.

- **Technical Details**: UAV3D 데이터셋은 CARLA 및 AirSim 시뮬레이터를 이용하여 생성되었으며, 단일 UAV 및 다중 UAV의 협동 인식 작업을 지원하는 네 가지 3D 인식 작업에 대한 벤치마크를 제공합니다. 이 데이터셋은 3D 객체 감지, 객체 추적 및 협동 3D 객체 감지 및 추적을 포함합니다.

- **Performance Highlights**: UAV3D는 현재 사용 가능한 다른 UAV 데이터셋보다 약 4배 큰 규모(500,000 이미지)를 가지고 있으며, UAV에 대한 협동 인식 연구를 발전시키는 데 기여할 것으로 기대됩니다.



### Real-Time Localization and Bimodal Point Pattern Analysis of Palms Using UAV Imagery (https://arxiv.org/abs/2410.11124)
Comments:
          25 pages, 8 figures, 5 tables

- **What's New**: 이 논문에서는 열대 우림에서 야생 종으로 자생하는 팜(야자) 분포를 분석하기 위해 PalmDSNet이라는 새로운 딥러닝 프레임워크를 제안합니다. 이 프레임워크는 실시간으로 팜을 감지, 분할 및 집계할 수 있으며, bimodal reproduction algorithm을 결합하여 팜의 공간 분포를 개선하고자 합니다.

- **Technical Details**: PalmDSNet은 UAV(무인 항공기)에서 캡처한 고해상도 이미지를 사용하며, 총 21개 지역에서 데이터 세트를 수집하였습니다. 이 데이터 세트에는 7,356개의 바운딩 박스와 7,603개의 팜 중심 지점이 포함되어 있으며, 이는 449헥타르의 면적을 포함합니다. 또한 Poisson-Gaussian reproduction algorithm을 사용하여 팜의 공간 분포를 시뮬레이션합니다.

- **Performance Highlights**: PalmDSNet과 bimodal reproduction algorithm의 조합을 통해 다양한 열대 환경에서 팜의 공간 분포를 성공적으로 모사할 수 있음을 입증했습니다. 이 모델은 지역적 및 글로벌 공간 변동성을 최적화하여 열대 우림의 지속 가능한 관리 및 생태 모니터링에 유용한 도구로 자리매김할 수 있습니다.



### MoonMetaSync: Lunar Image Registration Analysis (https://arxiv.org/abs/2410.11118)
- **What's New**: 본 논문은 SIFT(Scale-Invariant Feature Transform)와 ORB(Oriented FAST and Rotated BRIEF) 특징 검출 방법을 비교하고, 새로운 특성 검출기인 IntFeat를 소개합니다. 특히, IntFeat는 달 이미지에 적용되어 두 가지 해상도 (저해상도: 128x128, 고해상도: 1024x1024)에서 성능을 평가합니다.

- **Technical Details**: IntFeat는 SIFT와 ORB의 고수준 및 저수준 특징을 통합하여 강력한 달 이미지 정합을 제공합니다. 연구팀은 SycnVision이라는 파이썬 패키지를 도입하여 다양한 정합 방법 (SIFT, ORB, IntFeat)을 비교하고, 저해상도 달 이미지의 업스케일링에 있어서 bi-linear 및 bi-cubic 보간 방법을 사용하여 정합 효과성을 평가했습니다.

- **Performance Highlights**: IntFeat는 SSIM(Structural Similarity Index Measure)과 PSNR(Peak Signal-to-Noise Ratio) 지표를 통해 평가된 결과, SIFT와 ORB 사이에서 균형 잡힌 성능을 보여줍니다. 저해상도 달 이미지와 고각 이미지에서 IntFeat는 SIFT와의 성능 격차를 최소화하며, 특히 bi-linear 보간에서 SIFT의 성능에 근접한 결과를 도출했습니다.



### Classifying Healthy and Defective Fruits with a Multi-Input Architecture and CNN Models (https://arxiv.org/abs/2410.11108)
Comments:
          7 pages, 11 figures

- **What's New**: 이 논문은 다중 입력 (Multi-Input) 아키텍처를 활용하여 과일 (사과와 망고)을 건강한 상태와 결함 상태로 분류하는 연구를 다룹니다. RGB 및 실루엣(silhouette) 이미지를 사용하여 CNN (Convolutional Neural Networks) 모델의 정확성을 향상시키는 것을 목표로 하고 있습니다.

- **Technical Details**: 이미지 획득, 데이터셋 전처리, 두 개의 CNN 모델 (MobileNetV2 및 VGG16)의 훈련 및 평가 방법론을 포함합니다. 본 연구에서 실루엣 이미지를 상호 결합함으로써 다중 입력 아키텍처를 통해 과일의 독특한 특징을 더 잘 포착하여 높은 분류 정확도를 얻었습니다.

- **Performance Highlights**: MobileNetV2 모델을 사용하여 건강한 사과 분류에서 100%의 정확도를 달성하였고, 망고는 99.53%의 정확도를 보였습니다. 이는 이전 연구보다 향상된 결과로, 과일의 내부 품질 검사를 위한 적용 가능성이 큽니다.



### EchoApex: A General-Purpose Vision Foundation Model for Echocardiography (https://arxiv.org/abs/2410.11092)
- **What's New**: 이 논문은 심장 초음파(echocardiography)를 위한 최초의 범용 비전 파운데이션 모델인 EchoApex를 소개합니다. 2000만 개 이상의 초음파 이미지를 기반으로 학습되어 다양한 임상 적용 사례에서 우수한 성능을 입증합니다.

- **Technical Details**: EchoApex는 자가 지도 학습(self-supervised learning)을 활용하여 11개의 임상 센터에서 수집된 2000만 개의 초음파 이미지로 사전 훈련(pretrained)되었으며, 4가지 임상 응용과 28개의 하위 작업에서 효과성을 입증합니다. 모델은 TTE(Trans-thoracic echocardiogram), TEE(Trans-esophageal echocardiogram), ICE(Intracardiac echocardiogram) 이미지를 포함하는 다양한 초음파 데이터를 사용합니다.

- **Performance Highlights**: EchoApex는 4개의 다양한 임상 작업에서 기존의 최첨단(task-specific) 모델과 비교하여 우수한 성능을 보여주었습니다. 통합된 이미지 인코딩 아키텍처로 사전 훈련된 모델은 downstream tasks에 쉽게 적응할 수 있는 유연성을 가지며, 진단 정확도를 향상시키고 환자 결과를 개선하는 가능성을 제시합니다.



### Locality Alignment Improves Vision-Language Models (https://arxiv.org/abs/2410.11087)
- **What's New**: 최근 Vision Language Models (VLMs)의 채택이 증가하고 있지만, 기본적인 공간 추론 오류를 겪고 있는 경우가 많습니다. 본 연구에서는 ViTs(vision transformers)가 이미지 수준(supervision)에서 훈련되어 공간적 의미 정보를 효율적으로 인코딩하지 못하는 것에 기인한다고 가정하고, 이를 해결하기 위한 새로운 post-training 기법인 locality alignment와 MaskEmbed을 제안합니다.

- **Technical Details**: 제안된 MaskEmbed 방법은 마스크가 적용된 패치 임베딩을 통해 마스크된 뷰를 재구성하며, 이를 통해 지역화된(localized) 이미지 의미를 학습합니다. locality alignment 단계는 기존 이미지 수준(supervision)에서 훈련된 강력한 모델을 활용하여 지역적 의미를 효과적으로 학습할 수 있도록 돕습니다.

- **Performance Highlights**: 실험을 통해 locality alignment가 ViTs의 패치 수준 의미 분할 성능을 개선하고, 각종 벤치마크에서 VLM의 성능 향상을 보여주었습니다. 특히 공간 이해(spatial understanding)가 필요한 작업에서 개선된 성능을 입증하였으며, CLIP 및 SigLIP과 같은 언어 기반(supervised) 모델에 대한 효과가 두드러졌습니다.



### Few-shot Novel View Synthesis using Depth Aware 3D Gaussian Splatting (https://arxiv.org/abs/2410.11080)
Comments:
          Presented in ECCV 2024 workshop S3DSGR

- **What's New**: 이 연구는 제한된 뷰에서의 새로운 뷰 합성(few-shot novel view synthesis)을 위한 depth-aware Gaussian splatting 방법을 제안합니다. 이 방법은 단 몇 개의 입력 뷰만으로도 뛰어난 렌더링 품질을 달성할 수 있게 합니다.

- **Technical Details**: 이 접근법은 모노큘러(depth) 깊이 예측을 사전 정보로 사용하고, 스케일-불변(depth scale-invariant) 깊이 손실을 통해 3D 형태를 제약합니다. 또한 색상 모델링을 위해 저차 구형 고조파(lower-order spherical harmonics)를 사용하여 과적합(overfitting)을 피하는 방식으로 개선하였습니다.

- **Performance Highlights**: 제안된 방법은 기존의 3D Gaussian splatting 방법보다 Peak Signal-to-Noise Ratio(PSNR)에서 10.5%, 구조적 유사도 지수(SSIM)에서 6%, 그리고 인지적 유사성(LPIPS)에서 14.1% 개선된 성능을 보이며, 제한된 뷰에서도 효과적인 성능 향상을 달성함을 입증하였습니다.



### Character-aware audio-visual subtitling in contex (https://arxiv.org/abs/2410.11068)
Comments:
          ACCV 2024

- **What's New**: 본 논문은 TV 쇼에서 캐릭터 인식 오디오-비주얼 자막 생성을 위한 개선된 프레임워크를 제시합니다. 이 방법은 음성 인식, 화자 구분(speaker diarisation), 캐릭터 인식을 통합하여 오디오 및 비주얼 신호를 모두 활용합니다.

- **Technical Details**: 우리는 두 가지 주요 접근 방식을 통해 성과를 개선했습니다. 첫째, 짧은 대화 세그먼트에 대해 캐릭터를 식별하기 위해 주변 대화의 시간적 맥락을 활용합니다. 둘째, 입술 움직임에 대한 로컬 비주얼 임베딩(local visual embedding)을 사용하여 화자를 결정합니다. 이 두 가지 방식은 기존 방법보다 높은 정확도를 제공합니다.

- **Performance Highlights**: 12개의 TV 쇼로 구성된 데이터셋에서 본 방법의 성능을 검증한 결과, 기존의 방법들보다 화자 구분과 캐릭터 인식에서 우수한 성과를 나타내었습니다.



### Beyond Fixed Topologies: Unregistered Training and Comprehensive Evaluation Metrics for 3D Talking Heads (https://arxiv.org/abs/2410.11041)
- **What's New**: 이 연구에서는 3D 얼굴 애니메이션 생성 이론에 혁신적인 접근법인 ScanTalk를 제시하여 고정된 토폴로지 제약을 극복합니다. 이 프레임워크는 임의의 메쉬 토폴로지에서 작동할 수 있으며, 기존의 등록된 설정의 필요성을 없앱니다.

- **Technical Details**: ScanTalk는 메쉬에 대한 열 확산(heat diffusion)을 활용하여 고정된 토폴로지 제약을 해결합니다. 두 가지 훈련 설정인 지도 학습(supervised)과 비지도 학습(unsupervised)을 통해 효과적인 시간 의존적 변형을 지원합니다. 또한, 새로운 평가 메트릭을 도입하여 발음 구술과 얼굴 움직임 간의 동기화 평가를 향상시킵니다.

- **Performance Highlights**: ScanTalk는 고정된 토폴로지 기법에 비해 유리한 성능을 보여주며, 3D 대화형 얼굴 생성에 대한 새로운 벤치마크를 수립합니다. 전체 비유동적인 메쉬에 대해 신뢰성과 사실성을 유지하면서 회전하는 표정과 입 모양 복제를 성공적으로 수행합니다.



### ET-Former: Efficient Triplane Deformable Attention for 3D Semantic Scene Completion From Monocular Camera (https://arxiv.org/abs/2410.11019)
- **What's New**: 본 연구에서는 단일 모노카메라를 사용하여 의미적 장면 완성을 위한 새로운 최첨단 알고리즘인 ET-Former를 소개합니다. ET-Former는 단일 RGB 관찰로부터 의미적 점유 맵(occupancy map)을 생성하며, 동시에 의미적 예측의 불확실성 추정을 제공합니다.

- **Technical Details**: ET-Former는 트리플레인 기반의 변형 가능한 주목(attention) 메커니즘을 설계하여 장면의 기하학적 이해를 개선하고 의미적 예측의 노이즈를 줄입니다. 또한, Conditional Variational AutoEncoder (CVAE)를 통해 이러한 예측의 불확실성을 추정합니다. 이 접근 방식은 VoxFormer의 이단계 모델을 활용하여 첫 번째 단계에서 모노카메라의 점유를 추정하고 두 번째 단계에서 3D 의미적 점유 맵을 완성하는 데 도움을 줍니다.

- **Performance Highlights**: ET-Former는 Semantic-KITTI 데이터셋에서 평가된 결과, 기존 방법보다 IoU에서 15.16% 초과, mIoU에서 24.24% 초과라는 최고의 성능을 기록하였으며, 기존 방법에 비해 GPU 메모리 사용량을 25%-50.5% 줄였습니다.



### Stationary Velocity Fields on Matrix Groups for Deformable Image Registration (https://arxiv.org/abs/2410.10997)
- **What's New**: 이 연구는 Stationary Velocity Field (SVF) 접근법의 개념을 확장하여, 특히 Euclidean 변환을 저주파 성분으로 옮기고, 더 큰 변형을 보다 쉽게 회복할 수 있도록 하는 새로운 방법론을 제안합니다.

- **Technical Details**: 본 논문은 변형 공간(Deformation Space) \\mathcal{D}의 선택 및 매개변화(Parametrization)에 중점을 두고, 흐름 방정식(Flow Equation)의 확장의 필요성을 제시합니다. 여기서 유효한 흐름 방정식의 존재 조건과 효율적인 수치적 통합을 위한 스케일링 및 제곱 접근법(Scaling-and-Squaring Approach)을 제시합니다. 또한, 본 연구에서는 인체 뇌의 3D MRI 이미지를 사용한 환자 간 정합(inter-patient registration) 과정을 통해 제안한 방법을 수치적으로 검증하였습니다.

- **Performance Highlights**: 제안한 SE(3) 접근법을 사용하여 두 개의 MRI 뇌 스캔 이미지 등록에서, 기존 SVF 접근법에 비해 향상된 정합 성능이 관찰되었습니다. 특히, 더 큰 변형을 포함하는 경우 제안된 방법이 기존 방법보다 유리한 결과를 보였습니다.



### Cultural Heritage 3D Reconstruction with Diffusion Networks (https://arxiv.org/abs/2410.10927)
Comments:
          Accepted by the workshop VISART for ECCV 2024

- **What's New**: 최근 생성형 AI 알고리즘을 활용하여 문화유산 복원에 대한 연구를 진행하였으며, 조건부 확산 모델(conditional diffusion model)을 통해 3D 포인트 클라우드(point clouds)를 효과적으로 재구성하는 방법을 제시합니다.

- **Technical Details**: 이 연구에서는 확산 모델을 기반으로 하여 객체의 결손 부분 생성을 관찰된 부분 입력에 조건화하는 방법을 제안합니다. 이 모델은 물체 복원에 있어 일반화 능력을 평가하며, 고고학적 부분의 수리를 위해 훈련된 특정 방법론을 채택합니다. 확산 과정은 마코프 체인(Markov chain)으로 모델링되며, Gaussian 분포를 사용하여 점진적으로 노이즈를 추가하고 제거하는 방식으로 작동합니다.

- **Performance Highlights**: 결과적으로 이 확산 모델은 데이터 다양성과 이상치(outlier) 민감성과 같은 도전 과제를 극복하면서도 문화유산 기하학을 정확하게 재현할 수 있는 가능성을 보여줍니다. 이 연구는 AI 기술을 사용한 고대 유물 복원 방법론의 발전을 위한 기초를 마련하고 있습니다.



### Lotus: learning-based online thermal and latency variation management for two-stage detectors on edge devices (https://arxiv.org/abs/2410.10847)
Comments:
          DAC'24, code is available at: this https URL

- **What's New**: 이 논문에서는 두 단계(object detection) 검출기의 구성 및 특성에 맞춰 개발된 새로운 프레임워크, Lotus를 소개하고 있습니다. Lotus는 CPU와 GPU의 주파수 조정을 통해 동적으로 온도 및 지연 변화를 관리하여 사용자 경험을 향상시키고자 하며, 깊은 강화 학습(DRL)을 기반으로 합니다.

- **Technical Details**: Lotus 프레임워크는 두 가지 단계에서 CPU와 GPU 주파수를 동시 조정하여 지연 변화를 줄이며 온도를 관리합니다. 특히, Region Proposal Network (RPN)에서 각 이미지의 동적 제안 수에 따라 발생하는 지연 변화를 처리합니다. Lotus는 DRL 접근 방식을 활용하여 복잡한 환경에서의 주파수 조정을 최적화합니다.

- **Performance Highlights**: Lotus를 NVIDIA Jetson Orin Nano 및 Mi 11 Lite 플랫폼에 구현한 결과, 지연 변화를 최대 72.8% 감소시키고, 추론 속도는 최대 30.8% 향상했으며, 지연 제약을 충족하는 이미지 비율은 최대 43.8% 증가하는 등의 성과를 보였습니다.



### Focus On What Matters: Separated Models For Visual-Based RL Generalization (https://arxiv.org/abs/2410.10834)
- **What's New**: 본 논문은 이미지 재구성을 활용하여 일반화 능력을 향상시키기 위한 새로운 접근법인 SMG(Separated Models for Generalization)를 제안합니다. SMG는 시각적 관찰에서 과제 관련(task-relevant)과 과제 비관련(task-irrelevant) 표현을 구분하여 추출하는 두 개의 모델 브랜치를 도입합니다.

- **Technical Details**: SMG는 두 개의 일관성 손실(consistency losses)을 추가하여 다양한 시나리오에서 과제 관련 영역에 대한 에이전트의 초점을 유도합니다. 이 구조는 단일 모델 구조에서 발생할 수 있는 과제 비관련 특징에 대한 과적합(overfitting) 위험을 회피하며, 안정적인 과제 관련 표현을 추출하게 합니다.

- **Performance Highlights**: SMG는 DMC에서의 광범위한 실험을 통해 일반화 성능에서 SOTA(state-of-the-art)를 달성하였으며, 비디오 배경 설정 및 로봇 조작 작업에서 특히 우수한 성능을 보여주었습니다.



### High-Fidelity 3D Lung CT Synthesis in ARDS Swine Models Using Score-Based 3D Residual Diffusion Models (https://arxiv.org/abs/2410.10826)
Comments:
          5 page, 3 figures, Submitted to SPIE 2025-Medical Imaging

- **What's New**: 이번 연구에서는 급성 호흡곤란 증후군(ARDS) 관리를 위한 전통적인 2D X-ray 이미지를 사용하여 고해상도 3D CT 이미지를 생성하는 새로운 방법을 제안합니다.

- **Technical Details**: 연구진은 score-based 3D residual diffusion model을 통해 2D 이미지를 기반으로 한 3D lung CT를 합성하였습니다. 이 방법은 생리학적 매개변수와 결합하여 lung aeration, atelectasis를 분석할 수 있습니다.

- **Performance Highlights**: 초기 결과에 따르면, 이 접근법을 통해 생성된 3D CT 이미지는 실제 데이터와 검증되어 ARDS 관리의 효과성을 높일 수 있는 가능성을 보여주고 있습니다.



### OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation (https://arxiv.org/abs/2410.11792)
Comments:
          Accepted for oral presentation at 8th Annual Conference on Robot Learning. Project website: this https URL

- **What's New**: 이번 연구에서는 단일 RGB-D 비디오에서 인간의 동작을 모방하여 휴머노이드 로봇의 조작 기술을 학습하는 새로운 방법인 OKAMI를 소개합니다. OKAMI는 객체 인식과 조작을 위한 리타게팅(Object-aware retargeting) 기술을 통해 다양한 객체 위치에 맞춰 로봇의 동작을 조정합니다.

- **Technical Details**: OKAMI 방법론은 두 단계로 구성됩니다. 첫 번째 단계에서는 주어진 RGB-D 비디오에서 참조 조작 계획을 생성하고, 두 번째 단계에서는 이 계획을 활용해 다중 조작이 가능한 휴머노이드의 동작을 리타겟합니다. 리타게팅 과정에서는 객체의 위치를 반영하여 로봇 동작을 적절히 조정합니다.

- **Performance Highlights**: OKAMI는 다양한 작업에 대한 테스팅에서 평균 성공률 71.7%를 달성했으며, 기존의 ORION 기준선을 58.3% 초과하는 성능을 보였습니다. 또한, OKAMI를 통한 클로즈드 루프 비주얼 모터 정책 훈련에서 평균 79.2%의 성공률을 달성했습니다.



### MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation (https://arxiv.org/abs/2410.11779)
Comments:
          Ongoing work

- **What's New**: 이번 연구에서 우리는 Multimodal Large Language Models (MLLMs)에서의 환각(hallucination) 현상을 심층적으로 분석하고, 이 현상의 배경 메커니즘을 이해하기 위한 새로운 동적 수정 디코딩 방법인 DeCo(이전 레이어 동지식 지능 수정)를 제안합니다.

- **Technical Details**: DeCo는 MLLM의 결론 층에 도달하기 전에 발생한 지식 정보를 동적으로 선택하여 최종 출력 로짓(logits)을 조정합니다. 이 방법은 모델에 구애받지 않으며, 여러 전통적인 디코딩 전략과 원활하게 통합될 수 있습니다.

- **Performance Highlights**: DeCo를 이미지 캡셔닝 및 시각 질문 답변 데이터셋에 적용한 결과, 평균 10.8%의 환각 억제 효과를 보여주었으며, 다양한 데이터셋에서 기존 방법들보다 더 높은 성능을 기록했습니다. 또한 DeCo는 이전 방법들과 비교했을 때 약간의 지연(latency) 증가가 있었지만, 속도는 훨씬 더 빨라졌습니다.



### DPD-NeuralEngine: A 22-nm 6.6-TOPS/W/mm$^2$ Recurrent Neural Network Accelerator for Wideband Power Amplifier Digital Pre-Distortion (https://arxiv.org/abs/2410.11766)
Comments:
          5 pages, 5 figures

- **What's New**: DPD-NeuralEngine는 Gated Recurrent Unit (GRU) 기반의 초고속, 소형, 전력 효율이 뛰어난 Digital Pre-distortion (DPD) 가속기로, 22nm CMOS 구현이 2 GHz에서 작동하며 250 MSps의 I/Q 신호 처리 속도를 자랑합니다. 이 논문은 AI 기반 DPD 전용 집적 회로(ASIC) 가속기의 첫 사례로, 6.6 TOPS/W/mm²의 전력 면적 효율(PAE)을 달성했습니다.

- **Technical Details**: DPD-NeuralEngine은 GRU-RNN 아키텍처로 설계되어 있으며, 전처리기, GRU 레이어, 완전 연결 층(FC layer)으로 구성됩니다. 입력 신호에서 추출된 네 개의 특징을 GRU에 입력하고, GRU의 출력 신호는 아날로그 신호로 변환되어 전력 증폭기로 전달됩니다. 하드웨어 설계는 실시간 추론을 위해 구성된 마이크로 아키텍처를 포함하여, 비선형 활성화 함수(unit)와 메모리 버퍼를 갖추고 있습니다.

- **Performance Highlights**: 실험 결과, DPD-NeuralEngine은 256.5 GOPS의 처리량과 1.32 TOPS/W의 전력 효율, -45.3 dBc의 인접 채널 전력 비율(ACPR), -39.8 dB의 오류 벡터 크기(EVM) 성능을 보여줍니다. 이러한 성과는 기존 DPD 프레임워크들보다 우수한 성능을 나타냅니다.



### Latent Action Pretraining from Videos (https://arxiv.org/abs/2410.11758)
Comments:
          Website: this https URL

- **What's New**: 이번 연구에서는 웹 스케일 비디오를 활용하여 로봇 액션 라벨 없이 비지도 방식으로 Vision-Language-Action 모델(VLA)을 사전 훈련하는 Latent Action Pretraining for General Action models (LAPA) 방법을 소개합니다. 이 방법은 기존 모델이 인간 텔레오퍼레이터에 의존하는 문제를 해결합니다.

- **Technical Details**: LAPA는 두 가지 사전 훈련 단계와 로봇 액션으로의 매핑을 배우기 위한 정밀 조정 단계로 구성됩니다. 첫 번째 단계에서 VQ-VAE 기반 목표를 사용하여 원시 이미지 프레임 간의 양자화된 잠재 액션을 학습하고, 두 번째 단계에서는 비디오 관찰 및 작업 설명을 기반으로 잠재 액션을 예측하는 Vision-Language 모델을 정교하게 훈련합니다.

- **Performance Highlights**: 실험 결과, LAPA의 성능은 기존의 행동 없는 비디오에서 조작 정책을 훈련하는 방법에 비해 유의미하게 향상되었으며, 특히 실세계 조작 작업에서 현재의 최첨단 VLA 모델보다 6.22% 더 뛰어난 성과를 보여주었습니다. 또한 30배 이상의 사전 훈련 효율성을 달성하였습니다.



### Robotic Arm Platform for Multi-View Image Acquisition and 3D Reconstruction in Minimally Invasive Surgery (https://arxiv.org/abs/2410.11703)
Comments:
          8 pages, 5 figures, 3 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 이 연구는 최소 침습 수술(Minimally Invasive Surgery, MIS) 환경에서의 효율적인 다중 시점(image acquisition) 이미지 수집 및 정확한 3D 재구성을 위한 로봇 팔 플랫폼을 제안합니다.

- **Technical Details**: 로봇 팔을 활용하여 여러 가지 조명 조건(운영실 및 복강경)과 경로(구형 및 복강경)에서 여러 양의 장기 이미지를 캡처했습니다. 최근 발표된 학습 기반(feature matchers) 특징 매칭 기법을 사용하고 COLMAP을 결합하여 재구성을 수행했습니다. 재구축의 정확성을 평가하기 위해 고정밀 레이저 스캔과 비교하였습니다.

- **Performance Highlights**: 재구성 결과는 실제 MIS 조명 및 경로에서 문제가 발생했지만, 우리의 파이프라인의 여러 버전은 평균 1.05 mm의 Root Mean Squared Error와 0.82 mm의 Chamfer 거리를 달성하여 거의 1mm 이하의 정확도에 도달했습니다. 최상의 재구성 결과는 운영실 조명 및 구형 경로에서 발생했습니다.



### Magnifier Prompt: Tackling Multimodal Hallucination via Extremely Simple Instructions (https://arxiv.org/abs/2410.11701)
Comments:
          9 pages, 13 tables, 4 figures

- **What's New**: 이 논문에서는 멀티모달 대형 언어 모델(MLLMs)에서 허위 정보(hallucinations)를 줄이기 위해 Magnifier Prompt (MagPrompt)라는 단순하면서도 효과적인 방법을 제안합니다. MagPrompt는 모델이 시각적 정보에 더 집중하도록 유도하며, 이미지와 내부 지식 간의 충돌이 있을 경우 이미지의 우선권을 강조하는 원칙에 기반합니다.

- **Technical Details**: MagPrompt는 훈련 없이 적용 가능하며, GPT-4o 및 Gemini와 같은 오픈소스와 클로즈드소스 모델에 모두 사용할 수 있습니다. 실험 결과, MagPrompt는 다양한 데이터셋에서 효과적으로 작동하며, 복잡한 방법인 VCD와 비교할 때 동등하거나 더 나은 성능을 보입니다. 이 방법은 간단한 지침을 통해 MLLMs의 허위 정보 문제를 해결할 수 있는 가능성을 보여줍니다.

- **Performance Highlights**: 실험에서 MagPrompt는 LLaVA-1.5와 Qwen-VL 모델에서 VCD보다 더 우수한 성능을 발휘했으며, F1 점수 전반에서 유의미한 향상을 기록했습니다. 또한 MagPrompt는 GPT-4o 및 Gemini와 같은 최신 클로즈드소스 모델에서도 적용 가능하여, 기존의 복잡한 방법들이 적용되지 않는 상황에서도 성능 향상을 가져왔습니다.



### SurFhead: Affine Rig Blending for Geometrically Accurate 2D Gaussian Surfel Head Avatars (https://arxiv.org/abs/2410.11682)
- **What's New**: 본 논문에서는 SurFhead라는 새로운 방법을 제안하여 RGB 비디오를 사용하여 조정 가능한 머리 기하형상을 재구성하는 기법을 소개합니다. 기존의 기법이 유사 변환에 의존하여 기하학적 세부 사항을 캡처하는 데 어려움을 겪고 있는 반면, SurFhead는 2D Gaussian surfels를 활용하여 높은 충실도의 렌더링을 보장합니다.

- **Technical Details**: SurFhead는 고정된 광선 교차점에서의 정밀한 깊이 및 표면 방향에서 파생된 노멀과 같은 정의된 기하학적 속성을 가진 2D Gaussian surfels를 활용하여 기하학적 변형을 추출합니다. 고전적인 메쉬 기반 변형 전이와 아핀 변형 보간을 통해 극단적인 포즈에서도 고충실도의 렌더링을 실현합니다. 제안한 Jacobian Blend Skinning(JBS) 알고리즘은 인접한 변형 간의 아핀 변형을 매끄럽게 보간할 수 있게 해줍니다.

- **Performance Highlights**: SurFhead는 기존 접근 방식에 비해 높은 충실도를 유지하며, 실제 및 합성 데이터에서 다양한 주제를 대상으로 뛰어난 성능을 입증하였습니다. 특히, 볼록한 안구의 날카로운 반사, 복잡한 기하학적 세부 사항 및 과장된 변형 경우에서도 우수한 결과를 도출해 냈습니다.



### Unveiling the Mystery of Visual Attributes of Concrete and Abstract Concepts: Variability, Nearest Neighbors, and Challenging Categories (https://arxiv.org/abs/2410.11657)
- **What's New**: 이번 연구에서는 구체적(concrete)인 개념과 추상적(abstract)인 개념의 시각적 표현의 다양성을 분석하였습니다. 약 1000개의 개념을 포함하는 이미지 데이터셋을 사용하여, 이 두 개념의 시각적 특징에 대한 이해를 증진하고자 하였습니다.

- **Technical Details**: 우리는 Bing과 YFCC에서 추출한 약 1000개의 추상적 및 구체적 개념에 대한 이미지를 활용하였습니다. 이 연구에서는 각 개념에 대한 이미지의 시각적 다양성을 평가하고, 최근접 이웃(nearest neighbor) 분석을 통해 시각적 특징의 변동성을 분석하였으며, 도전 요인을 분류하고 주석을 달았습니다. 연구 결과, ViT(Vision Transformer)보다 색상과 질감과 같은 기본적인 시각적 특징의 조합이 구체적 및 추상적 개념 분류에 더 효과적이라는 것을 발견하였습니다.

- **Performance Highlights**: 이미지 분류 실험에서, 구체적이고 추상적인 개념 간의 시각적 다양성을 성공적으로 구별할 수 있었으며, ViT는 최근접 이웃 분석에서 뛰어난 성능을 보였습니다. 이는 다른 텍스트 이외의 양식으로 개념 변수를 분석할 때 시각적 특징 선택의 신중함을 강조합니다.



### M$^{2}$M: Learning controllable Multi of experts and multi-scale operators are the Partial Differential Equations need (https://arxiv.org/abs/2410.11617)
Comments:
          30 pages, 16 figures

- **What's New**: 본 논문은 다중 규모 및 다중 전문가(M$^2$M) 신경 운영자(neural operator) 프레임워크를 도입하여 부분 미분 방정식(Partial Differential Equations, PDEs)을 효율적으로 시뮬레이션하고 학습하는 방법을 제안합니다. 이는 기존의 방법론들이 PDE의 복잡한 동적 시스템을 완전히 학습하지 못하는 문제를 해결하고자 합니다.

- **Technical Details**: M$^2$M 신경 운영자는 분할 정복(divide-and-conquer) 전략을 사용하여 다중 전문가 네트워크를 훈련시키며, 전문가의 선택 권한을 결정하는 제어 가능한 선행 게이팅 메커니즘을 통합하여 모델의 효율성을 높입니다. PI 제어 전략(Proportional, Integral control strategy)을 통해 학습 과정을 최적화하고, 맞춤형 다중 규모 데이터 세트를 제공하여 Navier-Stokes 방정식에서 성능을 검증합니다.

- **Performance Highlights**: M$^2$M은 기준선 방법들과 비교하여 높은 시뮬레이션 정확성을 달성하며, 모델의 해석 가능성을 향상시킵니다. 해당 연구는 효율적인 PDE 해법 및 다양한 스케일에서의 성능 통합이 가능한 가능성을 보여줍니다.



### DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object Manipulation via Preference-based Action Alignmen (https://arxiv.org/abs/2410.11584)
- **What's New**: 최근 모방 학습이 로봇 조작 분야에서의 발전을 이루었으나, 복잡한 장기 변형물체 작업에 있어 여전히 어려움이 존재합니다. 이 연구에서는 복잡한 동적 시스템과 다중 작업 분포를 다루기 위한 데이터 효율적인 일반 학습 프레임워크인 DeformPAM을 제안합니다.

- **Technical Details**: DeformPAM은 장기 과제를 여러 행동 원시(action primitives)로 분해하고, 3D 포인트 클라우드 입력 및 확산(diffusion) 모델을 활용하여 행동 분포를 모델링합니다. 또, 인간의 선호 데이터를 사용하여 암묵적인 보상 모델을 훈련합니다. 추론(inference) 단계에서 보상 모델은 여러 후보 행동을 평가하고 실행을 위한 최적의 행동을 선택합니다.

- **Performance Highlights**: 세 가지 도전적인 실제 세계의 장기 변형물체 조작 작업에 대한 실험 결과, DeformPAM은 기준 방법(baseline methods)보다 작업 완료 품질 및 효율성을 향상시켰고, 제한된 데이터에서도 그 성과를 보여주었습니다.



### STA-Unet: Rethink the semantic redundant for Medical Imaging Segmentation (https://arxiv.org/abs/2410.11578)
- **What's New**: 이 논문은 UNet 구조에 Super Token Attention(STA) 모듈을 도입하여 의학 이미지 세분화에서의 성능을 향상시키는 새로운 방법론을 제시합니다. STA는 전통적인 Transformer 기반의 UNet 아키텍처에서 관찰된 중복성을 줄이는 데 초점을 맞추었습니다.

- **Technical Details**: Super Token Attention(STA) 메커니즘은 픽셀 공간에서 슈퍼 픽셀의 개념을 토큰 공간으로 확장하여, compact visual representations으로서 슈퍼 토큰을 사용합니다. 이 방법은 이를 통해 Transformer UNet의 얕은 계층에서의 비효율적인 정보 처리 문제를 해결하고, 전반적으로 유용한 global representations을 학습하는 데 기여합니다.

- **Performance Highlights**: 실험 결과, STA-UNet은 Dice 점수 및 IOU에서 기존의 최첨단(state-of-the-art) 방법들과 비교했을 때 우수한 성능을 보여줍니다. 네 개의 공공 의료 이미지 데이터셋을 통해 검증된 결과 다양한 장기 세분화 작업에서도 뛰어난 효과를 입증했습니다.



### PAVLM: Advancing Point Cloud based Affordance Understanding Via Vision-Language Mod (https://arxiv.org/abs/2410.11564)
- **What's New**: 이 논문에서는 PAVLM(Point cloud Affordance Vision-Language Model)이라는 혁신적인 프레임워크를 소개하여 로봇 시스템의 3D affordance 이해를 향상시키는 방법을 제안합니다.

- **Technical Details**: PAVLM은 사전 학습된 언어 모델에 내재된 광범위한 멀티모달 지식을 활용하여 포인트 클라우드의 3D affordance를 이해합니다. 이 모델은 기하학적 지도 전파 모듈(geometric-guided propagation module)과 대규모 언어 모델의 숨겨진 임베딩(hidden embeddings)을 결합하여 시각적 의미를 풍부하게 합니다.

- **Performance Highlights**: 3D-AffordanceNet 벤치마크에서 PAVLM은 전체 및 부분 포인트 클라우드 모두에서 기존 방법보다 뛰어난 성능을 보였으며, 특히 새로운 오픈월드 3D 객체에 대한 일반화에서 두드러진 성과를 거두었습니다.



### Prediction of Cardiovascular Risk Factors from Retinal Fundus Images using CNNs (https://arxiv.org/abs/2410.11535)
- **What's New**: 이번 연구는 UK Biobank의 망막 이미지(retinal images)로부터 심혈관 질환의 위험 요소를 예측하는 새로운 방법을 제시합니다. 특히, 이 연구는 HbA1c와 총 콜레스테롤(total cholesterol)의 예측을 시도한 최초의 연구입니다.

- **Technical Details**: 이 연구는 convolutional neural networks (CNNs)를 사용하여 심혈관 질환의 위험 요소인 나이(age), BMI, 흡연 상태(smoking status), HbA1c, 수축기 혈압(systolic blood pressure), 이완기 혈압(diastolic blood pressure), 성별(gender) 및 총 콜레스테롤(total cholesterol)을 예측합니다. 망막 이미지를 Gaussian 필터링을 통한 대비 강화(contrast enhancement)를 적용하여 왼쪽 및 오른쪽 망막 이미지의 예측을 결합하여 개별적으로 예측을 도출합니다.

- **Performance Highlights**: 나이에 대한 예측에서 R2 점수는 0.81, 수축기 혈압에 대한 예측에서 R2 점수는 0.39를 기록하였으며, 이는 이전 연구보다 향상된 성능을 보입니다. 그러나, HbA1c의 경우 R2 점수는 0.0579, 총 콜레스테롤의 경우 R2 점수는 0.0157로 나타나 이 두 위험 요소의 예측은 제한적임을 보여줍니다.



### Rician Denoising Diffusion Probabilistic Models For Sodium Breast MRI Enhancemen (https://arxiv.org/abs/2410.11511)
Comments:
          3 figures

- **What's New**: 이 연구에서는 자연스러운 나트륨 MRI 이미지를 얻기 위한 새로운 방법론을 제안합니다. Rician Denoising Diffusion Probabilistic Model (RDDPM)을 도입하여 기존의 Denoising Diffusion Probabilistic Models (DDPM)에서 발생하는 한계를 극복하고, 나트륨 MRI의 고유한 노이즈 프로파일에 적합한 해법을 제공합니다.

- **Technical Details**: RDDPM 모델은 Rician 노이즈를 각 시간 단계에서 Gaussian 노이즈로 변환하여 denoising 과정을 진행합니다. CNN(Convolutional Neural Network) 모델로 생성된 합성 나트륨 MR 이미지를 활용하여 RDDPM을 훈련시키고, DDPM의 두 가지 병렬 모델을 사용하여 나트륨 MRI의 노이즈 제거를 수행합니다.

- **Performance Highlights**: RDDPM은 세 가지 비참조 이미지 품질 평가 지표를 통해 평가된 결과, DDPM 및 기타 CNN 기반 denoising 방법보다 일관되게 우수한 성능을 보였습니다.



### NavTopo: Leveraging Topological Maps For Autonomous Navigation Of a Mobile Robo (https://arxiv.org/abs/2410.11492)
Comments:
          This paper is published in proceedings of the 9th International Conference "Interactive Collaborative Robotics" (ICR 2024)

- **What's New**: 이번 논문은 모바일 로봇의 자율 내비게이션을 위한 새로운 방법론인 NavTopo를 소개합니다. 이 방법은 전통적인 매핑(method) 대신 위상(topological) 맵을 사용하여 효율성을 높였습니다.

- **Technical Details**: NavTopo는 위상 맵과 두 단계(path planning) 경로 계획을 기반으로 하며, 신경망(descriptors)과 입력 포인트 클라우드의 2D 프로젝션을 매칭하여 그래프에서 위치를 로컬라이즈합니다. 이 접근 방식은 메모리 소비를 현저하게 줄여줍니다.

- **Performance Highlights**: 실험 결과, NavTopo는 RTAB-MAP을 기반으로 한 전통적인 매트릭(metric) 매핑 접근 방식에 비해 성능이 크게 향상되었으며, 적절한 내비게이션 효율성을 유지합니다.



### SHAKTI: A 2.5 Billion Parameter Small Language Model Optimized for Edge AI and Low-Resource Environments (https://arxiv.org/abs/2410.11331)
Comments:
          Paper in pdf format is 11 pages and contains 4 tables

- **What's New**: Shakti는 25억 개의 매개변수를 가진 언어 모델로, 스마트폰, 웨어러블 기기 및 IoT 시스템과 같은 자원 제약 환경에서 최적화되어 있습니다. 이 모델은 높은 효율성과 정밀도를 갖춘 NLP를 결합하여 실시간 AI 애플리케이션에 적합하며, 다양한 언어와 도메인 특정 작업을 지원합니다.

- **Technical Details**: Shakti는 Variable Grouped Query Attention (VGQA)이라는 기술 혁신을 도입하여 메모리 사용량을 줄이고 추론 시간을 단축합니다. 또한, Pre-normalization과 SwiGLU 활성화 함수를 사용하여 훈련 과정을 안정화하고, Rotary Positional Embeddings (RoPE)를 통합하여 긴 텍스트 시퀀스를 처리할 수 있게 합니다.

- **Performance Highlights**: Shakti는 벤치마크 평가에서 더 큰 모델들과 비교하여 경쟁력 있는 성능을 보이며, 낮은 대기 시간과 높은 장치 내 효율성을 유지합니다. 또한, 특히 헬스케어, 금융 및 고객 서비스와 같은 산업에서 실시간 AI 솔루션을 제공하는 데 이상적입니다.



### Diffusion-Based Offline RL for Improved Decision-Making in Augmented ARC Task (https://arxiv.org/abs/2410.11324)
Comments:
          Preprint, Under review. Comments welcome

- **What's New**: 본 논문은 Latent Diffusion-Constrained Q-learning (LDCQ)이라는 혁신적인 diffusion 기반 오프라인 RL 접근법을 사용하여 Abstraction and Reasoning Corpus (ARC)에서의 AI의 전략적 추론 능력을 평가합니다. 이 연구는 SOLAR라는 새로운 데이터셋을 도입하여 오프라인 RL 에이전트의 학습을 위해 다양한 경험 데이터를 제공합니다.

- **Technical Details**: 본 연구는 SOLAR-Generator를 통해 원하는 조건에 따라 다양한 경로 데이터를 생성하며, 이 데이터를 통해 LDCQ 방법으로 에이전트를 훈련합니다. ARCLE 환경 내에서 마르코프 결정 과정(Markov Decision Process, MDP) 구조를 사용하여 에이전트가 그리드 기반 작업을 해결할 수 있도록 합니다.

- **Performance Highlights**: 실험 결과, LDCQ 방법으로 훈련된 에이전트는 다양한 액션을 적용하고 다단계 순차 결정을 수행하여 정답 상태를 정확히 식별하는 능력을 보여줍니다. 이 결과는 오프라인 RL 접근법이 AI의 전략적 추론 능력을 향상시킬 수 있는 가능성을 잘 보여줍니다.



### Adversarially Guided Stateful Defense Against Backdoor Attacks in Federated Deep Learning (https://arxiv.org/abs/2410.11205)
Comments:
          16 pages, Accepted at ACSAC 2024

- **What's New**: 본 논문에서는 Federated Learning (FL) 환경에서 발생할 수 있는 backdoor 공격에 대한 새로운 방어 메커니즘인 Adversarially Guided Stateful Defense (AGSD)를 제안합니다. AGSD는 비현실적인 가정에 의존하지 않고 클러스터 선택을 안내하는 새로운 메트릭인 신뢰 지수(trust index)를 계산하는 방식을 사용합니다.

- **Technical Details**: AGSD는 네 단계로 작동합니다: (1) 초기 집합(preliminary aggregation)에서 클라이언트 제출을 스케일링 및 집합화하고, (2) 스펙트럴 클러스터링(spectral clustering)을 사용하여 클라이언트 제출을 클러스터링하며, (3) 작은 보유 데이터셋을 이용하여 적대적 섭동(adversarial perturbations)을 계산하여 각 클라이언트의 신뢰 지수를 평가합니다. (4) AGSD는 각 클라이언트의 신뢰 상태(history)를 유지하며, 클러스터에서 선택된 클라이언트만 모델을 업데이트할 수 있도록 합니다.

- **Performance Highlights**: AGSD는 MNIST, CIFAR-10, GTSRB 데이터셋을 통해 평가되었으며, 특히 작은 보유 데이터셋(50 데이터 샘플 이하)으로도 기존의 State-of-the-art 방어 메커니즘들보다 우수한 성능을 보였습니다. AGSD는 공격 성공률(ASR)을 줄이고 깨끗한 정확도(clean accuracy)의 감소를 최소화하면서 FL 설정에서 효과적으로 backdoor 공격을 방어합니다.



### Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities (https://arxiv.org/abs/2410.11190)
Comments:
          13 pages, 6 figures

- **What's New**: 이 논문에서는 새로운 다중 모달 언어 모델인 Mini-Omni2를 소개합니다. Mini-Omni2는 시각 및 청각 쿼리에 대해 실시간 음성 응답을 제공하는 비주얼-오디오 어시스턴트입니다.

- **Technical Details**: Mini-Omni2는 사전 훈련된 시각(visual) 및 청각(auditory) 인코더를 통합하여 개별 모달리티에서의 성능을 유지합니다. 이 모델은 세 단계의 훈련 프로세스를 통해 모달리티를 정렬하여, 제한된 데이터셋으로 훈련한 후에도 다중 모달 입력 및 출력을 처리할 수 있게 합니다.

- **Performance Highlights**: Mini-Omni2는 GPT-4o와 유사한 기능을 가지고 있으며, 오픈 소스 커뮤니티의 모델들이 제공하는 일부 기능과 비교했을 때 더 유연한 사용자 인터랙션을 가능하게 하는 명령 기반 중단 메커니즘을 도입했습니다. 이는 향후 연구에서 중요한 통찰력을 제공할 것으로 기대됩니다.



### Deep unrolled primal dual network for TOF-PET list-mode image reconstruction (https://arxiv.org/abs/2410.11148)
Comments:
          11 pages, 11 figures

- **What's New**: 본 연구에서는 TOF-PET 리스트 모드 재구성을 위한 깊은 언롤 프리멀 듀얼 네트워크를 제안합니다. 이 네트워크는 리스트 모드 도메인 업데이트를 위한 이중 네트워크와 이미지 도메인 업데이트를 위한 프리멀 네트워크로 구성되어 있으며, 다양한 TOF 해상도와 카운트 레벨에서 성능을 입증하였습니다.

- **Technical Details**: 제안된 방법은 네트워크를 여러 단계로 언롤하여, 각 단계는 리스트 모드 도메인 업데이트를 위한 이중 모듈과 이미지 도메인 업데이트를 위한 프리멀 모듈을 포함합니다. CUDA를 사용하여 TOF 리스트 모드 데이터의 시스템 매트릭스의 병렬 가속 및 계산을 수행하고, 메모리 소비를 줄이기 위해 동적 접근 전략을 채택하였습니다.

- **Performance Highlights**: 제안된 방법은 LM-OSEM, LM-EMTV, LM-SPDHG 및 FastPET 방법보다 시각적 및 정량적 분석 모두에서 우수한 성능을 보여, TOF-PET 리스트 모드 데이터에 대한 깊은 언롤 방법의 적용 가능성을 입증하였습니다.



### CleanUMamba: A Compact Mamba Network for Speech Denoising using Channel Pruning (https://arxiv.org/abs/2410.11062)
Comments:
          5 pages, 4 figures

- **What's New**: 본 논문에서는 실시간 인과 오디오 잡음 제거를 위해 설계된 CleanUMamba라는 시간 도메인 신경망 아키텍처를 소개합니다. 이 아키텍처는 전통적인 LSTM 및 self-attention 메커니즘 대신 Mamba를 도입하여 최고의 잡음 제거 성능을 제공합니다. 또한, 모델 크기를 8배 줄이고 오디오 품질에는 영향을 주지 않는 구조적 채널 프루닝(structured channel pruning) 기법을 적용했습니다.

- **Technical Details**: CleanUMamba는 U-Net encoder-decoder 구조를 기반으로 하며, 병목(bottleneck) 계층에서 Mamba 상태 공간 모델을 포함합니다. 모델은 442K의 파라미터와 468M MACs로, PESQ 점수 2.42와 STOI 95.1%를 달성하며, 같은 조건의 더 큰 모델들과 비교해도 뛰어난 실시간 성능을 보여줍니다. 이 모델은 48ms의 알고리즘 지연을 가지고 있으며, 인코더 레이어 수에 따라 지연 시간이 달라질 수 있습니다.

- **Performance Highlights**: CleanUMamba는 Interspeech 2020 Deep Noise Suppression 도전에서 탁월한 성과를 보였고, 오디오 품질 평가에서 PESQ 2.42, STOI 95.1%로 높은 점수를 기록했습니다. 8X 모델 사이즈 감소에도 불구하고 오디오 품질을 유지하는 데 성공하였습니다.



### Hybrid Spatial Representations for Species Distribution Modeling (https://arxiv.org/abs/2410.10937)
Comments:
          Project codebase this https URL

- **What's New**: 본 논문에서는 Species Distribution Modeling (SDM)이라는 생태학적 문제를 해결하기 위해 새로운 하이브리드 임베딩 방법론을 제안합니다. 특히, 커뮤니티 소스 데이터셋에서 존재하는 데이터만으로 여러 종의 모델링을 동시에 수행하며, 환경 정보를 사용하지 않는 도전적인 작업을 다룹니다.

- **Technical Details**: 하이브리드 임베딩 스킴은 implicit embedding과 explicit embedding의 조합으로 이루어져 있습니다. explicit embedding은 multiresolution hashgrid로 구현되어, 모델이 지역 정보를 더욱 잘 포착하도록 돕습니다. 이 모델은 FCNet 기반의 implicit component와 결합되어 SDM 작업에 최적화된 형태를 만듭니다.

- **Performance Highlights**: 실험 결과, 제안된 방법이 다양한 벤치마크에서 기존 방법들에 비해 현저한 성과를 나타내며, 하이브리드 표현이 순수한 implicit 또는 explicit 방법보다 성능이 우수함을 보여줍니다. 또한, 질적 비주얼화와 종합적인 ablation 연구를 통해 하이브리드 표현의 효과성을 입증하였습니다.



### ASTM :Autonomous Smart Traffic Management System Using Artificial Intelligence CNN and LSTM (https://arxiv.org/abs/2410.10929)
Comments:
          In process to IEEE Intelligent Vehicle Symposium 2025

- **What's New**: 본 논문은 인공지능(AI)을 활용한 자율 스마트 교통 관리 시스템(Autonomous Smart Traffic Management, ASTM) 개발에 중점을 두고 있으며, 교통 흐름을 개선하기 위한 YOLO V5 합성곱 신경망을 사용하는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 제안된 시스템에서는 YOLO V5 Convolutional Neural Network가 교통 관리 이미지를 통해 차량을 감지하고, Recurrent Neural Network with Long Short-Term Memory (RNN-LSTM)을 통해 다음 12시간 동안의 차량 수를 예측합니다. 이 예측을 기반으로 Smart Traffic Management Cycle Length Analysis가 교통 주기 길이를 관리합니다.

- **Performance Highlights**: 논문에서 제시된 RNN-LSTM 모델은 평균 제곱 오차(Mean Squared Error, MSE) 4.521 차량과 제곱근 평균 제곱 오차(Root Mean Squared Error, RMSE) 2.232 차량을 기록하였으며, STM 시스템 시뮬레이션 결과, 교통 관리 혼잡 흐름 속도가 50% 개선되고 차량 통과 지연이 70% 감소한 것으로 나타났습니다.



### ATLAS: Adapter-Based Multi-Modal Continual Learning with a Two-Stage Learning Strategy (https://arxiv.org/abs/2410.10923)
- **What's New**: 본 논문에서는 다중 모달(multi-modal) 지속적 학습을 위한 새로운 접근 방식인 Adapter-based Multi-modal ConTinual Learning with A Two-stage Learning Strategy (ATLAS)를 제안합니다. 이 방법은 경험 기반 학습과 새로운 지식 확장을 포함하는 두 단계 학습 패러다임을 채택하고 있습니다.

- **Technical Details**: ATLAS는 경험 기반 학습(experience-based learning)과 새로운 지식 확장(novel knowledge expansion)을 통해 이전의 작업 지식을 효과적으로 활용하고 새로운 작업의 지식을 보완합니다. 이를 통해 지식의 중복성을 피하고, 모델의 표현을 풍부하게 하며, 업스트림(다중 작업) 시퀀스에서 다운스트림(특정 작업)에 대한 일반화 능력을 개선합니다.

- **Performance Highlights**: 실험 결과, ATLAS는 여러 작업에 대해 이전 작업의 잊혀진 정보를 최소화하면서 더 나은 일반화 능력을 보여주었고, 업스트림 작업에서의 학습이 다운스트림 작업에 긍정적인 영향을 미치는 것을 확인했습니다.



### A few-shot Label Unlearning in Vertical Federated Learning (https://arxiv.org/abs/2410.10922)
Comments:
          We introduce the first method for label unlearning in vertical federated learning (VFL), focused on preventing label leakage by the active party

- **What's New**: 이 논문은 Vertical Federated Learning (VFL)에서의 레이블 언러닝(label unlearning) 문제를 다룹니다. 이는 기존의 Horizontal Federated Learning (HFL)보다 덜 연구된 분야입니다. 연구자들은 레이블 정보 유출 위험을 줄이기 위해 특별히 설계된 첫 번째 방법을 소개합니다.

- **Technical Details**: 이 방법은 제한된 양의 라벨 데이터(label data)를 활용하여 manifold mixup 기술을 사용하여 충분치 않은 데이터의 전방 임베딩을 증강합니다. 그런 다음 증강된 임베딩에서 gradient ascent를 수행하여 모델로부터 레이블 정보를 삭제합니다. 이 조합은 높은 언러닝 효과성을 유지하면서도 효율성을 보장하며, 언러닝 절차는 몇 초 만에 완료됩니다.

- **Performance Highlights**: MNIST, CIFAR10, CIFAR100, ModelNet 등을 포함한 다양한 데이터셋에서 실시한 광범위한 실험을 통해 이 방법의 효율성과 확장성을 검증했습니다. 이 연구는 VFL에서 언러닝의 독특한 도전을 다루면서 개인정보 보호 및 계산 효율성을 모두 지키는 데 중요한 진전을 이룹니다.



### Towards Better Multi-head Attention via Channel-wise Sample Permutation (https://arxiv.org/abs/2410.10914)
Comments:
          18 pages, 4 figures

- **What's New**: 이번 연구에서는 Channel-wise Sample Permutation (CSP) 연산자를 제안하며, 이를 통해 매개변수 수가 적고 복잡성이 낮은 새로운 구조적 다중 헤드 주의 메커니즘을 실현했습니다. CSP는 입력 행렬의 다양한 채널샘플을 원형으로 이동시키고 각 채널의 그룹화된 샘플을 정렬함으로써 이론적 이해도 뛰어난 기술로 구현됩니다.

- **Technical Details**: CSP 연산자는 서로 다른 채널의 샘플을 다양한 단계로 원형 이동시키고 그룹화된 샘플을 정렬하여 작동합니다. 이는 교차 채널 주의 맵을 암묵적으로 구현하며, 선형 복잡성을 달성하고 데이터 표현시 rank collapse의 위험을 억제합니다. 기존의 다중 헤드 주의(MHA) 대신 CSP를 일부 대표 모델에 적용하였으며, 정량적 평가에서 성능과 유사하거나 우수한 결과를 얻었습니다.

- **Performance Highlights**: CSP 기반 모델들은 기존의 Transformer 모델 및 최신 변형들과 비교했을 때, 동일한 성능을 유지하거나 향상시키면서 매개변수 수와 계산 비용을 현저히 줄였습니다. 이 실험 결과는 CSP가 효율적이고 강력한 대안이 될 수 있음을 보여줍니다.



### Advancements in Ship Detection: Comparative Analysis of Optical and Hyperspectral Sensors (https://arxiv.org/abs/2410.10888)
- **What's New**: 해양 감시 분야에서 군사 및 민간 응용 프로그램에 대한 최신 연구로, 선박 탐지 및 분류 기술에 중점을 두고 있습니다. 특히 광학 (optical)과 하이퍼스펙트럴 (hyperspectral) 원격 감지 접근 방식을 비교합니다.

- **Technical Details**: 이 논문은 특징 추출 (feature extraction), 방법론 (methodologies), 다양한 임무에 대한 적합성 등을 포괄적으로 분석합니다. 센서 선택의 중요성을 강조하며, 이는 임무 목표와 조건에 맞춰 탐지 정확도를 향상시키기 위한 통합 전략 (integrated strategies)을 통해 이루어집니다.

- **Performance Highlights**: 두 가지 기술의 강점과 한계를 조사하여 다양한 해양 응용 분야에서의 사용성을 향상시키는 내용을 담고 있습니다.



### Enhancing Vision-Language Model Pre-training with Image-text Pair Pruning Based on Word Frequency (https://arxiv.org/abs/2410.10879)
- **What's New**: 이번 논문은 Word-Frequency 기반 이미지-텍스트 쌍 가지치기(WFPP)라는 새로운 데이터 가지치기 방법을 제안하여 VLMs(비전-언어 모델)의 효율성을 향상시킵니다. 이 방법은 텍스트의 내용을 기반으로 텍스트-이미지 쌍을 선택하여 가지치기를 진행하며, 높은 빈도의 단어를 포함하는 쌍을 제거하여 단어 빈도 분포를 균형 있게 만듭니다.

- **Technical Details**: WFPP는 빈도가 높은 단어를 포함하는 텍스트가 있는 이미지-텍스트 쌍을 제거하여 훈련 데이터셋의 균형을 개선합니다. WFPP는 단어 확률에 기반하여 간단한 텍스트 수준 점수를 사용하여 가지치기를 수행하며, 텍스트에서 잦은 단어를 제거함으로써 전반적인 데이터의 다양성을 유지합니다. 최적의 결과를 위해, WFPP는 테스트 후 전체 데이터셋에 대해 1 에폭을 추가로 조정하여 성능을 개선합니다.

- **Performance Highlights**: WFPP를 적용하면 CLIP 모델의 훈련 성능이 저격 작업에서 향상됩니다. WFPP는 데이터를 효율적으로 가지치기하면서도 성능 저하 없이 학습 속도를 개선해줍니다. 제안된 방법을 통해 CLIP 모델은 다양한 하위 작업에서 성능이 향상되었으며, 제로샷 분류 및 이미지-텍스트 검색에서 우수한 결과를 보였습니다.



### CogDevelop2K: Reversed Cognitive Development in Multimodal Large Language Models (https://arxiv.org/abs/2410.10855)
- **What's New**: 이 논문은 Multi-modal Large Language Models (MLLMs)의 인지 능력을 평가하는 새로운 벤치마크인 CogDevelop2K를 제안합니다. 이 벤치마크는 인간의 인지 발달 과정을 구조화해 12개의 하위 개념을 포괄하며, MLLMs의 진정한 이해 능력과 작업 수행 능력을 탐구하는 데 중점을 둡니다.

- **Technical Details**: CogDevelop2K는 2519개의 질문과 2517개의 이미지, 455개의 비디오로 구성되어 있으며, MLLMs의 코어 인지 능력을 4단계의 인지 발달 무대로 평가합니다. 이 논문은 Jean Piaget의 인지 발달 이론을 기반으로 하여 MLLMs의 역동적인 인지 발달 추세를 조사하며, 코어 인지 과업 수행이 MLLMs의 진정한 지식, 추론 및 지각 능력을 이해하는 데 중요한 인사이트를 제공함을 강조합니다.

- **Performance Highlights**: 46개 MLLM 모델을 평가한 결과, 몇 가지 놀라운 경향이 확인되었습니다. MLLM 모델은 인간의 인지 발달 경로와 반대되는 경향을 보였으며, 예를 들어 GPT 시리즈는 형식적 조작 단계에서 더 나은 성능을 보였으나 구체적 조작 단계에서는 저조한 성능을 나타냈습니다. 이 연구는 MLLM의 성능 향상 방법인 prompting 기술이 모델 성능을 8.1% 향상시킬 수 있음을 시사합니다.



### Adaptive Data Transport Mechanism for UAV Surveillance Missions in Lossy Environments (https://arxiv.org/abs/2410.10843)
- **What's New**: 본 논문은 Unmanned Aerial Vehicles (UAV) 기반의 Intelligence, Surveillance, and Reconnaissance (ISR) 임무를 위한 효율적인 데이터 전송 전략을 제안합니다. 특히, 객체 검출 및 추적에 기여하는 이미지의 특정 영역을 우선적으로 선택하여 자동 전송을 최적화하는 AI 기반 스케줄링 정책을 도입하였습니다.

- **Technical Details**: 연구에서는 Deep Reinforcement Learning (DRL) 프레임워크를 사용하여 이미지의 작은 패치들에 대해 전송 확률을 할당하며, 객체와의 겹침 정도에 따라 높은 전송 확률을 부여합니다. 이 과정은 실시간 데이터 전송의 효율성을 높이는 UDP(User Datagram Protocol) 전송 프로토콜과 YOLOv8 객체 탐지 알고리즘을 포함하여 동작합니다.

- **Performance Highlights**: 제안된 방법은 리소스가 제한된 UAV 환경에서 효과적인 데이터 전송을 통해 ISR 임무의 효율성을 크게 향상시킬 것으로 기대됩니다. 또한, 간섭이 있는 이미지 패치의 OD 오류를 방지하기 위해 인터프레임 보간(interframe interpolation) 과정을 통합하여, 시스템의 전반적인 성능을 증대시키는 결과를 도출하였습니다.



### AI Foundation Model for Heliophysics: Applications, Design, and Implementation (https://arxiv.org/abs/2410.10841)
Comments:
          31 Pages, 12 figures

- **What's New**: 이번 연구에서는 헬리오피직스(heliophysics) 분야에서 최초로 태양역학 관측 데이터(Solar Dynamics Observatory, SDO)를 기반으로 한 파운데이션 모델(Foundation Model, FM)을 설계했습니다. 이 모델은 헬리오피직스 관련 문제 해결을 위한 구체적인 기준과 도전 과제를 제시하고 있습니다.

- **Technical Details**: 제안한 파운데이션 모델은 인코더(encoder)와 디코더(decoder) 구조를 기반으로 하며, 자가 지도 학습(self-supervised learning) 방법으로 사전 훈련됩니다. 이처럼 훈련된 모델은 특정 다운스트림 작업에 대해 인코더는 수정 없이 사용하고, 디코더는 작업에 특화된 형태로 대체할 수 있습니다. 또한, 모델은 수백만 개에서 수십억 개의 매개변수를 가질 수 있습니다.

- **Performance Highlights**: 본 연구는 헬리오피직스 분야에 있어 FM의 가능성을 최초로 제시하였으며, SDO 데이터의 활용을 통해 많은 기존 문제 해결에 기여할 것으로 기대됩니다. 초기 훈련 결과를 통해 ML 방법이 기존의 방법을 능가하는 다양한 성과를 도출했다고 보고합니다.



### Swap-Net: A Memory-Efficient 2.5D Network for Sparse-View 3D Cone Beam CT Reconstruction (https://arxiv.org/abs/2410.10836)
- **What's New**: 이 연구는 Swap-Net이라는 메모리 효율적인 2.5D 네트워크를 제안하여 극도의 스파스 뷰(sparse-view) 3D CBCT 이미지 재구성을 효율적으로 수행합니다. Swap-Net은 새로운 축 교환(axis-swapping) 연산을 이용하여 전체 3D 볼륨 재구성을 가능하게 합니다.

- **Technical Details**: Swap-Net은 2D 합성곱 연산을 사용하여 3D 볼륨의 모든 축을 포괄적으로 활용합니다. 이 방법은 기존의 FBP(filtered back projection)과 3D CNN와 비교하여 메모리 비용이 적고 더 빠르게 작동합니다. 실험에서는 4개의 프로젝션만으로도 효과적인 결과를 보여주었습니다.

- **Performance Highlights**: Swap-Net은 기초 방법들에 비해 정량적 및 정성적으로 모두 우수한 성능을 보이며, 잡음 감소 및 복잡한 유체 역학 시뮬레이션의 세부사항 보존에서도 탁월한 결과를 나타냈습니다.



### Tex4D: Zero-shot 4D Scene Texturing with Video Diffusion Models (https://arxiv.org/abs/2410.10821)
Comments:
          Project page: this https URL

- **What's New**: Tex4D는 텍스트 프롬프트와 함께 제공된 비구조화 3D 메시 시퀀스를 기반으로 여러 시점과 시간적으로 일관된 4D 텍스처를 생성하는 제로샷 접근 방식을 소개합니다. 이를 통해 텍스쳐링의 효율성을 크게 향상시킵니다.

- **Technical Details**: Tex4D는 UV 공간에서의 잠재적 집합(latent aggregation)을 통해 다중 시점(multi-view) 일관성을 보장합니다. 이는 3D 메시의 내재된 기하학적 지식(geometry knowledge)을 활용하여 시간적으로 일관된 텍스처 합성을 위한 조건적 비디오 생성 모델의 사전 지식을 사용합니다. DDIM 샘플링 과정에서의 단순한 수정이 필요하며, 참조 잠재 텍스처(reference latent texture)를 도입하여 프레임 간의 상관관계를 강화합니다.

- **Performance Highlights**: Tex4D는 다양한 애니메이션 메시 시퀀스에서 우수한 성능을 보여주며, 특히 기존 방법들과 비교하여 시간적 및 다중 프레임 일관성 있는 비디오 생성을 위한 최초의 방법으로, 높은 충실도의 텍스처를 제공합니다.



### TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models (https://arxiv.org/abs/2410.10818)
Comments:
          Project Page: this https URL

- **What's New**: TemporalBench는 비디오의 미세한 시간적 이해(fine-grained temporal understanding)를 평가하는 새로운 벤치마크로, 10,000 개의 비디오 질문-답변 쌍으로 구성되어 있으며, 인간의 고품질 주석에서 파생되었습니다.

- **Technical Details**: TemporalBench에서는 비디오 클립의 시공간적 활동을 잘 반영하기 위해 긴 시간 의존성(long-range dependencies), 세분화된 시각적 관찰(fine-grained visual observations) 및 사건의 진행(event progression)과 관련된 주석에 중점을 두었습니다.

- **Performance Highlights**: 최신 모델인 GPT-4o는 TemporalBench에서 단지 38.5%의 질문 응답 정확도를 보여주었고, 이는 인간과 AI 간의 시간적 이해에서 약 30%의 큰 간극이 있음을 나타냅니다. 또한 다중 선택 QA에서 발생할 수 있는 편향을 수정하기 위해 Multiple Binary Accuracy(MBA)를 제안했습니다.



### When Does Perceptual Alignment Benefit Vision Representations? (https://arxiv.org/abs/2410.10817)
Comments:
          S.S. and S.F. contributed equally. Website: this http URL

- **What's New**: 본 논문에서는 인간의 지각 판단에 맞춘 비전 모델의 정합성이 다양한 컴퓨터 비전 작업에서의 유용성에 미치는 영향을 조사하고, 최첨단 모델을 인간의 유사성 판단에 따라 미세 조정하였으며 이를 표준 비전 벤치마크에서 평가했습니다.

- **Technical Details**: NIGHTS라는 인간의 유사성 판단에 대한 데이터셋을 사용하여, 여러 최신 비전 모델(예: CLIP, DINO, DINOv2, SynCLR)을 미세 조정했습니다. 이 데이터셋은 20,000개의 합성 이미지를 포함한 트리플렛으로 구성되어 있으며, 각 이미지 세트는 인간 평가로 얻은 유사성 판단이 포함되어 있습니다.

- **Performance Highlights**: 인간 정합성을 반영한 모델은 원래의 백본 모델에 비해 여러 다운스트림 작업(예: counting, segmentation, depth estimation)에서 성능을 향상시키는 것으로 나타났습니다. 또한, 특정 작업에서는 성능이 유지되거나 향상되었으나, 일부 자연 데이터 작업에서는 성능 저하가 관찰되었습니다.



### LVD-2M: A Long-take Video Dataset with Temporally Dense Captions (https://arxiv.org/abs/2410.10816)
Comments:
          NeurIPS 2024 Dataset and Benchmark Track. Project page: this https URL . Code: this https URL

- **What's New**: 본 논문은 LVD-2M이라는 새로운 데이터셋을 소개합니다. 이 데이터셋은 최소 10초 이상의 긴 비디오, 컷이 없는 장시간 비디오, 다양한 콘텐츠와 큰 동작을 포함하며 시계열 밀집 캡션(temporally dense captions)으로 주석이 달린 2백만 개의 비디오로 구성되어 있습니다.

- **Technical Details**: LVD-2M은 낮은 수준의 필터링 도구(예: scene cut detection)와 의미적 수준의 필터링 도구(예: video LLMs)를 결합한 자동 데이터 선별 파이프라인을 통해 제작되었습니다. 또한, 비디오를 30초 클립으로 나누고 각 클립에서 프레임을 샘플링하여 비디오 캡션을 생성하는 계층적 캡셔닝(Hierarchical Captioning) 접근 방식을 사용합니다.

- **Performance Highlights**: LVD-2M 데이터셋을 통해 비디오 생성 모델의 성능이 향상되었으며, 실험 결과 동적 모션을 포함하는 장시간 비디오 생성에 있어 효과성이 입증되었습니다. 인간 평가에서도 LVD-2M이 높은 동적 정도와 뛰어난 캡션 품질로 선호되었습니다.



### Depth Any Video with Scalable Synthetic Data (https://arxiv.org/abs/2410.10815)
Comments:
          Project Page: this https URL

- **What's New**: 이번 논문에서는 Depth Any Video라는 모델을 도입하여 비디오 깊이 추정의 어려움을 해결하려고 합니다. 이 모델은 대규모 합성 데이터 파이프라인을 개발하고, 생성적 비디오 확산 모델의 강력한 프라이어를 활용하여 다양한 비디오를 효과적으로 처리합니다.

- **Technical Details**: 우리는 40,000개의 5초 길이의 비디오 클립을 포괄하는 대규모 합성 데이터셋인 DA-V를 구축했습니다. 이 데이터는 조명 조건, 카메라 움직임, 그리고 물체 상호작용을 포함한 다양한 시나리오를 커버합니다. 모델의 훈련 방식으로 혼합 길이 훈련 전략을 도입하고, 흐름 일치(flow matching) 및 회전 위치 인코딩(rotary position encoding) 같은 고급 기술을 사용하여 처리 효율성을 향상시킵니다.

- **Performance Highlights**: 모델은 공간 정확성과 시간 일관성 모두에서 기존의 모든 생성적 깊이 모델을 초월하며, 최대 150 프레임의 비디오 시퀀스에서 고해상도 깊이 추정을 가능하게 합니다.



### HART: Efficient Visual Generation with Hybrid Autoregressive Transformer (https://arxiv.org/abs/2410.10812)
Comments:
          Demo: this https URL. The first two authors contributed equally to this work

- **What's New**: 이번 연구에서는 Hybrid Autoregressive Transformer (HART)라는 새로운 시각 생성 모델을 소개합니다. HART는 1024x1024 크기의 이미지를 직접 생성할 수 있는 autoregressive (AR) 모델로, 기존의 diffusion 모델과 유사한 이미지 생성 품질을 자랑합니다. HART는 전통적인 AR 모델의 한계를 극복하기 위해 하이브리드 토크나이저(hybrid tokenizer)를 도입하였습니다.

- **Technical Details**: HART의 하이브리드 토크나이저는 autoencoder의 연속적인 잠재 출력(latent output)을 두 가지 구성 요소로 분해합니다: 전체적인 그림을 나타내는 discrete tokens와 discrete tokens로 표현할 수 없는 잔여 성분을 나타내는 continuous tokens. 이들은 각각 스케일 가능한 해상도의 VAR transformer와 37M 파라미터를 가진 경량 residual diffusion 모듈에 의해 모델링됩니다.

- **Performance Highlights**: HART는 MJHQ-30K 데이터셋에서 reconstruction FID를 2.11에서 0.30으로 개선하여, 1024px 이미지 생성 시 FID를 7.85에서 5.38로 낮추어 31%의 개선을 달성하였습니다. 또한 HART는 최신 diffusion 모델보다 4.5-7.7배 높은 처리량과 6.9-13.4배 낮은 MACs를 기록하며, 빠른 추론(latency) 속도를 자랑합니다.



### TrajDiffuse: A Conditional Diffusion Model for Environment-Aware Trajectory Prediction (https://arxiv.org/abs/2410.10804)
Comments:
          Accepted to be published as inpreceedings of the 2024 International Conference on Pattern Recognition (ICPR)

- **What's New**: 이 논문에서는 TrajDiffuse라는 새로운 경로 예측 방법을 제안하며, 이는 혁신적인 guided conditional diffusion 모델에 기반합니다. 기존의 경로 예측 모델은 환경 제약을 무시하고 다양성이나 정확성에만 초점을 맞춘 경우가 많았으나, TrajDiffuse는 이를 개선하여 더욱 실용적이며 환경 친화적인 예측을 가능하게 합니다.

- **Technical Details**: TrajDiffuse는 경로 예측 문제를 denoising inpainting 과제로 구성하고, diffusion 과정에 대한 맵 기반 가이드를 설계합니다. 이 방법은 에이전트의 궤적 기록과 예측된 움직임 의도를 보간(interpolation)하여 예측을 생성하며, 목표/경로점(conditioning)에 의해 경로 생성 과정을 명시적으로 제어할 수 있는 기능을 제공합니다.

- **Performance Highlights**: TrajDiffuse는 nuScenes 및 PFSD 데이터셋에서의 실험을 통해 SOTA를 초과하는 정확도와 다양성을 보여주었으며, 향상된 환경 이해도를 입증했습니다. 우리는 두 가지 공공 데이터셋에서 실험을 통해 이 모델이 환경 제약을 잘 준수하며 정확한 경로 예측을 생성할 수 있음을 보였습니다.



### Boosting Camera Motion Control for Video Diffusion Transformers (https://arxiv.org/abs/2410.10802)
- **What's New**: 본 논문에서는 비디오 생성의 카메라 제어 품질을 향상시키기 위한 해결책으로 Camera Motion Guidance (CMG) 방법을 제안하며, 이를 통해 기존 DiT 방식보다 400% 이상 개선된 결과를 보였습니다.

- **Technical Details**: 본 연구는 transformer 기반의 diffusion 모델(DiT)에서 카메라 제어 성능이 conditioning 방법에 크게 의존한다는 사실을 밝혀냈습니다. 이를 기반으로 classifier-free guidance 기술을 활용한 CMG 방법을 도입하였습니다. 또한, sparse camera control 방식을 통해 긴 비디오에서 카메라 포즈 입력을 간소화하는 방법도 제시하였습니다.

- **Performance Highlights**: CMG 방법과 sparse camera control을 적용하여 비디오 생성 시 카메라 제어 정확도 및 동작을 크게 향상시켰으며, 이는 U-Net 및 DiT 모델 모두에 효과적으로 적용 가능합니다.



### Towards Foundation Models for 3D Vision: How Close Are We? (https://arxiv.org/abs/2410.10799)
- **What's New**: 이 논문에서는 3D 비전의 이해 능력을 평가하기 위해 새로운 3D 비주얼 언더스탠딩 벤치마크를 설계하였으며, 이는 Visual Question Answering (VQA) 형식으로 다양한 3D 비전 작업을 포함합니다. 이 연구는 최신 Vision-Language Models (VLMs)와 전문화된 모델의 3D 비전 능력을 인간과 비교하여 분석하였습니다.

- **Technical Details**: 연구에서는 깊이 추정(depth estimation), 공간 VQA(spatial VQA), 카메라 자세 추정(camera pose estimation), 키포인트 매칭(keypoint matching) 등의 3D 비전 작업을 포함하는 새로운 벤치마크를 제안했습니다. VQA 형식으로 모든 질문을 구성하여 VLMs와 인간이 쉽게 응답할 수 있도록 하였습니다. 또한 기하학적 섭동(geometric perturbations)을 포함하여 모델의 강건성을 평가합니다.

- **Performance Highlights**: VLMs는 일반적으로 3D 작업을 수행하지 못하며, 정확도와 강건성 면에서 전문화된 모델이 인간보다 나은 경우도 있지만 기하학적 섭동에 취약한 것으로 나타났습니다. 반면, 인간은 가장 정확하고 강건한 3D 비주얼 시스템으로 확인되었습니다. Transformer 기반의 네트워크가 CNN보다 인간의 3D 비전 메커니즘과 더 잘 정렬되는 것으로 나타났습니다.



### MMAR: Towards Lossless Multi-Modal Auto-Regressive Probabilistic Modeling (https://arxiv.org/abs/2410.10798)
- **What's New**: 이번 논문에서는 기존의 이미지 이해와 생성에서 발생하는 정보 손실 문제를 해결하기 위해 새로운 Multi-Modal Auto-Regressive (MMAR) 모델링 프레임워크를 제안합니다. MMAR는 연속적인 이미지 토큰을 사용하여 정보 손실을 방지하는 혁신적인 접근 방식을 채택하고, 기존의 확산 접근법(dispersion-based approach)과 차별화된 구조를 가지고 있습니다.

- **Technical Details**: MMAR는 연속 값 이미지 토큰을 사용하여 정보 손실을 방지하고, 경량화된 확산 헤드를 통해 각 이미지 패치가 자동 회귀 모델에 통합되도록 설계되었습니다. 또한, 이 접근 방식은 수치 안정성 문제를 해결하는 이론적으로 검증된 기술과 생성 및 이해 작업 목표를 균형 있게 조정하는 훈련 전략을 포함합니다.

- **Performance Highlights**: 18개의 이미지 이해 벤치마크에서 평가한 결과, MMAR는 다른 다중 모달 모델들보다 뛰어난 성능을 보여주었고, 사전 훈련된 CLIP 비전 인코더를 사용한 방법과 유사한 성능을 발휘하면서도 고품질 이미지를 동시에 생성할 수 있음을 입증했습니다. 또한, 대규모 데이터와 모델 크기에 대해 확장 가능한 특성을 보여주었습니다.



### Condition-Aware Multimodal Fusion for Robust Semantic Perception of Driving Scenes (https://arxiv.org/abs/2410.10791)
- **What's New**: 이 논문에서는 자동 주행 환경에서의 견고한 의미 인식을 위해 다중 센서를 활용하는 새로운 접근 방식을 제안합니다. 기존 방식은 환경 조건에 따라 센서를 균등하게 처리하여 최적의 성능을 내지 못했습니다. 그러나 본 연구의 CAFuser 방식은 RGB 카메라 입력을 활용하여 환경 조건을 분류하고, 다양한 센서 모달리티의 융합을 유도하는 조건 토큰을 생성합니다.

- **Technical Details**: CAFuser 모델은 각 센서에서 모듈화된 특징 어댑터를 사용하여 다양한 센서 입력을 공유 잠재 공간에 정렬합니다. 이로 인해 사전 훈련된 백본과 효율적으로 통합할 수 있으며, 센서 퓨전이 각 조건에 맞게 최적화됩니다. 이 아키텍처는 단일 네트워크 백본을 사용하여 모델 파라미터를 54% 줄이는 동시에 성능 저하 없이 동작합니다.

- **Performance Highlights**: CAFuser는 MUSES 데이터셋에서 다중 모달 팬옵틱 세분화(multi-modal panoptic segmentation)에서 59.7 PQ, 의미 세분화(semantic segmentation)에서 78.2 mIoU의 성능을 기록하며, 공공 벤치마크에서 1위를 차지하였습니다. 이 모델은 특히 악조건 시나리오에서의 견고성을 크게 개선합니다.



### Sitcom-Crafter: A Plot-Driven Human Motion Generation System in 3D Scenes (https://arxiv.org/abs/2410.10790)
Comments:
          Code Page: this https URL

- **What's New**: 최근 인체 모션 합성을 위한 Sitcom-Crafter라는 포괄적이고 확장 가능한 시스템이 제안되었습니다. 이 시스템은 다양한 모션 유형의 조합을 생성할 수 있는 통합 시스템으로, 애니메이션 및 게임 디자이너의 워크플로우 효율성을 높입니다.

- **Technical Details**: Sitcom-Crafter는 총 8개의 모듈로 구성되며, 그 중 3개는 모션 생성에, 나머지 5개는 모션 시퀀스의 일관된 융합과 시스템 기능성을 보장하는 증강 모듈입니다. 특히, 새로운 3D 장면 인식 인체-인체 상호 작용 모듈이 물리적 장면 정보가 포함된 합성 및 특정 SDF 포인트를 생성하여 인체-장면 충돌을 최소화합니다.

- **Performance Highlights**: 실험 평가 결과, Sitcom-Crafter는 고품질의 다양하고 물리적으로 현실감 있는 모션을 성공적으로 생성할 수 있는 능력을 입증했습니다. 이는 창조적인 워크플로우를 발전시키는 데 상당한 잠재력을 지니고 있음을 강조합니다.



### LiveXiv -- A Multi-Modal Live Benchmark Based on Arxiv Papers Conten (https://arxiv.org/abs/2410.10783)
- **What's New**: LiveXiv는 과학 ArXiv 논문을 기반으로 한 대규모의 자동화된 멀티모달 라이브 벤치마크로, 웹에서 수집된 데이터로 테스트 모델의 능력을 측정합니다.

- **Technical Details**: LiveXiv는 자동으로 생성된 VQA(Visual Question-Answer) 쌍을 활용하여 과학 문서에서 필요한 정보를 추출하고, GPT-4o를 통해 질문을 생성합니다. 이를 위해 구조화된 문서 파싱 파이프라인을 통해 PDF 문서의 내용을 처리하고, 다양한 시각적 정보를 기반으로 질문 필터링 과정을 거쳐 데이터 품질을 개선합니다.

- **Performance Highlights**: LiveXiv의 첫 번째 버전에서 여러 개방형 및 독점 LMM 모델을 벤치마크하고, 데이터 오염을 최소화한 상황에서 모델의 진정한 능력을 깨닫게 해주는 통찰력을 제공합니다.



### 3DArticCyclists: Generating Simulated Dynamic 3D Cyclists for Human-Object Interaction (HOI) and Autonomous Driving Applications (https://arxiv.org/abs/2410.10782)
- **What's New**: 이번 논문에서는 복잡한 동적 인간-객체 상호작용을 연구하기 위한 방법을 제안하며, 3D 사이클리스트(dynamic cyclist)와 상호작용을 생성하는 새로운 데이터셋인 3DArticBikes를 소개합니다. 이 데이터셋은 NeRF 및 3DGS 기반 3D 재구성 방법을 훈련하는 데 사용될 수 있습니다.

- **Technical Details**: 저자는 새로운 부품 기반 다각도 관절 합성 3D 자전거 데이터셋(3DArticBikes) 생성을 위한 방법론을 제안합니다. 이 데이터셋은 조정 가능한 8-DoF 자세를 가지고 있는 3D 자전거를 조합하 수 있는 3DGS 기반의 매개변수 자전거 구성 모델이 포함됩니다. 또한, 사이클리스트 비디오에서 동적 정보를 사용하여 합성 3D 인물의 자세를 자동으로 수정하여 3D 자전거에 적절하게 rider를 배치합니다.

- **Performance Highlights**: 생성한 사이클리스트는 최근의 안정적 확산 방법과 비교하여 정성적 및 정량적 결과가 제시됩니다. 이 연구는 동적 자전거 시뮬레이션 및 복잡한 상호작용의 이해를 위한 전진적인 기초를 마련하고 있습니다.



### ControlMM: Controllable Masked Motion Generation (https://arxiv.org/abs/2410.10780)
Comments:
          project page this https URL

- **What's New**: ControlMM은 텍스트 기반 제어 신호를 포함한 새로운 생성형 마스크드 모션 모델 접근 방식을 제안합니다. 이 방법은 높은 정밀도, 빠른 속도 및 높은 충실도의 제어 가능한 모션 생성을 동시에 달성합니다.

- **Technical Details**: ControlMM은 마스크드 일관성 모델링(masked consistency modeling)과 추론 시 로짓 편집(inference-time logit editing)이라는 두 가지 주요 기술 혁신을 도입합니다. 이를 통해 입력 제어 신호와 생성된 모션으로부터 추출한 제어 신호 간의 불일치를 최소화하면서 고충실도의 모션 생성을 보장합니다.

- **Performance Highlights**: ControlMM은 기존의 최첨단 기술에 비해 모션 품질에서 우수한 결과를 보여주며, FID 점수는 0.061로 향상되었습니다. 또한, ControlMM은 확산 기반 방법보다 20배 빠른 속도로 모션을 생성하는 성능을 보입니다.



### UniMatch V2: Pushing the Limit of Semi-Supervised Semantic Segmentation (https://arxiv.org/abs/2410.10777)
Comments:
          18 pages, 18 tables, 10 figures

- **What's New**: 이번 연구에서는 기존 모델의 한계를 넘어, 최신 ViT 기반 인코더인 DINOv2를 활용하여 반지도 세분화(FSS) 성능을 현저히 개선할 필요성을 강조합니다.

- **Technical Details**: 기존 SSS 방식에서 흔히 사용되던 ResNet 인코더 대신 DINOv2와 같은 강력한 ViT 기반 인코더를 채택하여, 더 큰 데이터셋으로 사전 훈련(pre-training)한 모델을 사용합니다. 이를 통해 단순한 모델 업데이트만으로도 상당한 성능 향상을 이끌어냈습니다.

- **Performance Highlights**: UniMatch V2를 통해 더 낮은 훈련 비용으로 일관되게 더 나은 결과를 제공하며, 기존의 Pascal 및 Cityscapes 데이터셋 외에 ADE20K 및 COCO와 같은 더 복잡한 벤치마크에 집중할 필요성을 역설합니다.



### Cavia: Camera-controllable Multi-view Video Diffusion with View-Integrated Attention (https://arxiv.org/abs/2410.10774)
Comments:
          Project Page: this https URL

- **What's New**: Cavia라는 새로운 프레임워크를 소개합니다. 이 프레임워크는 사용자에게 카메라 모션을 정확히 지정할 수 있는 기능을 제공하여 이미지에서 여러 개의 시공간적으로 일관된 비디오를 생성할 수 있습니다.

- **Technical Details**: Cavia는 공간 및 시간 주의(attention) 모듈을 뷰 통합 주의 모듈로 확장하여 시점(viewpoint)과 시간적 일관성을 개선합니다. 또한, 정적 비디오, 객체-level 합성 다중 뷰 동적 비디오, 실제 모노큘러 동적 비디오와 같은 다양한 데이터 소스를 활용한 공동 학습(joint training) 방식을 채택합니다.

- **Performance Highlights**: Cavia는 기하학적 일관성(geometric consistency)과 지각 품질(perceptual quality) 측면에서 최첨단 방법들을 초월하는 성능을 보여줍니다. 또한, 이 프레임워크는 추론(inference) 중에 4개의 뷰를 생성하고, 생성된 프레임의 3D 재구성을 가능하게 합니다.



### DragEntity: Trajectory Guided Video Generation using Entity and Positional Relationships (https://arxiv.org/abs/2410.10751)
Comments:
          ACM MM2024 Oral

- **What's New**: 최근 Diffusion 모델이 비디오 생성 분야에서 큰 성공을 거둔 바, 본 논문에서는 DragEntity라는 새로운 비디오 생성 모델을 소개합니다. 이 모델은 사용자 친화적으로 여러 객체의 움직임을 제어할 수 있도록 설계되었습니다.

- **Technical Details**: DragEntity는 엔티티(entities) 표현 방식을 활용하여 여러 객체의 모션을 제어합니다. 사용자들은 개별 픽셀 대신 이미지 내의 엔티티를 드래그하여 인터랙션할 수 있습니다. 엔티티 표시 방법은 이미지 내의 모든 객체를 나타내고, 여러 객체는 상대적 공간 관계를 유지하도록 돕습니다. 이를 통해 복잡한 다수의 궤적을 통해 여러 객체를 동시에 제어할 수 있게 됩니다.

- **Performance Highlights**: 실험 결과, DragEntity는 비디오 생성에서 미세한 제어의 뛰어난 성능을 보여주며, 고유의 엔티티 레벨 모션 제어 방식을 통해 현실감 있는 비디오 생성을 가능하게 합니다.



### FlexGen: Flexible Multi-View Generation from Text and Image Inputs (https://arxiv.org/abs/2410.10745)
Comments:
          16 pages, 13 figures

- **What's New**: 이 논문에서는 FlexGen이라는 유연한 프레임워크를 소개하며, 이는 단일 뷰 이미지, 텍스트 프롬프트, 또는 둘 모두에 따라 제어 가능한 일관된 다중 뷰 이미지를 생성하도록 설계되었습니다. FlexGen은 3D-aware 텍스트 주석에 대한 추가 조건부를 통해 제어 가능한 다중 뷰 합성을 다룹니다.

- **Technical Details**: FlexGen은 GPT-4V의 강력한 추론 능력을 활용하여 3D-aware 텍스트 주석을 생성합니다. 객체의 네 개의 정사각형 뷰를 분석하여 3D-aware 정보를 포함하는 텍스트 주석을 생성하며, 제안된 적응형 이중 제어 모듈을 통해 제어 신호를 통합하여 다중 뷰 이미지를 생성합니다. 이 모델은 텍스트 프롬프트를 수정하여 합리적인 그리고 일치하는 보이지 않는 부분을 생성합니다.

- **Performance Highlights**: 실험 결과, FlexGen은 기존의 다중 뷰 확산 모델에 비해 향상된 다중 제어 기능을 제공하며, 게임 개발, 애니메이션, 가상 현실 등 빠르고 유연한 3D 콘텐츠 제작이 필요한 분야에서 상당한 진전을 이루었습니다.



### DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Mod (https://arxiv.org/abs/2410.10738)
Comments:
          Accepted to NeurIPS 2024. Project page: this https URL

- **What's New**: DrivingDojo는 복잡한 주행 역학을 훈련하기 위해 특별히 제작된 첫 번째 데이터셋으로, 비디오 다양성이 제한된 기존 주행 데이터셋의 단점을 극복하고자 합니다.

- **Technical Details**: DrivingDojo는 다양한 주행 동작, 다중 에이전트 상호작용 및 개방형 주행 지식을 포함하여, 모델이 복잡한 동적 환경을 예측하고 시뮬레이션할 수 있도록 고안되었습니다. 또한, AIF(action instruction following) 벤치마크를 정의하여 주행 세계 모델의 성능을 평가할 수 있게 되었습니다.

- **Performance Highlights**: DrivingDojo는 기존 데이터셋에 비해 보다 다양하고 복잡한 주행 시나리오를 수집하여, 향후 자율 주행 세계 모델의 발전에 기여할 수 있는 많은 기회를 제공하고 있다는 점에서 중요한 발전을 나타냅니다.



### Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models (https://arxiv.org/abs/2410.10733)
Comments:
          Preprint. First two authors contributed equally to this work

- **What's New**: Deep Compression Autoencoder (DC-AE)는 고해상도 확산 모델을 가속화하기 위한 새로운 오토인코더 모델 군을 제시합니다. 기존의 오토인코더 모델들은 낮은 공간 압축 비율(예: 8x)에서 좋은 성능을 보였으나, 높은 공간 압축 비율(예: 64x)에서는 만족스러운 재구성 정확도를 유지하지 못했습니다.

- **Technical Details**: DC-AE는 Residual Autoencoding과 Decoupled High-Resolution Adaptation이라는 두 가지 주요 기술을 도입합니다. Residual Autoencoding은 높은 공간 압축 오토인코더의 최적화 난이도를 완화하기 위해 설계되었으며, Decoupled High-Resolution Adaptation은 높은 공간 압축 오토인코더의 일반화 페널티를 완화하기 위한 효율적인 훈련 전략입니다.

- **Performance Highlights**: DC-AE는 오토인코더의 공간 압축 비율을 최대 128까지 증가시키면서도 재구성 품질을 유지합니다. 예를 들어, ImageNet 512x512에서는 DC-AE를 사용하여 UViT-H에서 H100 GPU로 19.1배의 추론 속도 향상과 17.9배의 훈련 속도 향상을 달성하면서 FID 점수 또한 개선되었습니다.



### A Counterexample in Image Registration (https://arxiv.org/abs/2410.10725)
- **What's New**: 이번 연구는 1차원 데이터에서 이미지 정합의 이론적 한계를 분석합니다. 특히, 이미지 정합에서의 정확도의 경계를 탐구하며, 신호의 불연속점 위치와 참조점 간의 관계를 규명합니다.

- **Technical Details**: 신호의 불연속점을 참조점으로 선택할 때, 그 위치에 따라 에러 함수의 에너지가 달라지는 양상을 연구합니다. 이는 공간적으로 제한된 조각상 상수(signal)의 이상적이고 잡음 없는 샘플 패턴 집합을 기반으로 추정하는 방법을 제공합니다.

- **Performance Highlights**: 연구 결과, 신호의 정확한 추정치는 참조되는 불연속점에 따라 달라지며, 이로 인해 이미지 정합의 해석이 새롭게 규명됩니다. 또한, 기존의 시각을 넘어서 정합 문제를 접근하게 됩니다.



### 4-LEGS: 4D Language Embedded Gaussian Splatting (https://arxiv.org/abs/2410.10719)
Comments:
          Project webpage: this https URL

- **What's New**: 본 연구에서는 동적 장면을 캡처하는 볼류메트릭 표현을 텍스트와 연결하는 방법인 4-LEGS (4D Language Embedded Gaussian Splatting)를 제안합니다. 이 접근법은 사용자가 텍스트 프롬프트를 통해 비디오에서 사건을 시공간적으로 로컬라이즈 할 수 있는 인터페이스를 제공합니다.

- **Technical Details**: 4-LEGS는 3D Gaussian Splatting을 기반으로 한 4D 표현으로, 시공간 임베딩을 동적 Gaussian Splatting 표현에 접목하여 수행됩니다. 이를 통해 우리는 자연어로 기술된 상태 및 동적 영역의 로컬라이제이션과 함께 시공간 확률 맵을 렌더링할 수 있습니다.

- **Performance Highlights**: 4-LEGS는 정적 및 동적 환경 내의 텍스트 설명을 로컬라이즈하는 측면에서 대안 기술에 비해 매우 뛰어난 성능을 보였으며, Panoptic Sports 데이터셋을 사용하여 정량적 평가를 수행하였습니다.



### Benefiting from Quantum? A Comparative Study of Q-Seg, Quantum-Inspired Techniques, and U-Net for Crack Segmentation (https://arxiv.org/abs/2410.10713)
- **What's New**: 이 연구는 양자 하드웨어를 활용한 기존 이미지 세분화 기법에 대한 비교 분석을 진행하여 양자 기반 방법들이 실질적인 적용 가능성을 갖추었음을 보였습니다. 특히, 콘크리트 균열을 세분화하는 효율적인 방법을 제시하였습니다.

- **Technical Details**: 주요 기술적 방법으로 Mean Gaussian Mixture (MGM), 양자 영감 기반 Hamiltonian, Q-Seg, 그리고 U-Net 딥러닝 아키텍처가 포함됩니다. 연구는 32x32 픽셀의 주석 처리된 콘크리트 이미지 조각을 사용하여 각 방법의 세분화 마스크를 생성하고 성능을 비교합니다.

- **Performance Highlights**: 양자 기반 및 양자 영감 기법이 복잡한 균열 패턴에 대해 유망한 대안을 제공하며, 가까운 미래의 다양한 응용 분야에 적용될 수 있음을 확인했습니다. Q-Seg 방법은 특히 D-Wave 양자 어닐러를 사용하여 효과적으로 세분화 문제를 해결함으로써 우수한 성능을 나타냈습니다.



### Ensemble of ConvNeXt V2 and MaxViT for Long-Tailed CXR Classification with View-Based Aggregation (https://arxiv.org/abs/2410.10710)
Comments:
          Solution paper for MICCAI CXR-LT 2024 challenge. 4th place in Subtask 2, 5th in Subtask 1

- **What's New**: 본 연구는 MICCAI 2024 CXR-LT 챌린지에서 Subtask 2에서 4위, Subtask 1에서 5위를 달성한 해결책을 제시합니다. ConvNeXt V2와 MaxViT 모델의 앙상블을 활용하여 흉부 X-ray의 긴 꼬리 분포 문제를 다룹니다.

- **Technical Details**: 이 연구에서는 흉부 X-ray의 분류(task)는 여러 시각적 정보가 포함되어 복잡하며, 긴 꼬리 분포를 고려해야 하는 문제를 다루었습니다. ConvNeXt V2와 MaxViT 모델을 사용하여 이미지 분류 기술을 조합하고, 비대칭 손실(asymmetric loss)을 통해 클래스 불균형을 해결합니다. 연구에서 사용된 데이터 세트는 MIMIC-CXR로, 377,110개의 CXR 이미지와 45개의 질병 레이블을 포함하고 있습니다.

- **Performance Highlights**: 실험 결과, 512x512 픽셀의 입력 크기가 성능 향상에 기여했으며, MaxViT 모델이 ConvNeXt V2보다 높은 성능을 보여주었습니다. 비대칭 손실 함수를 사용한 사전 훈련이 흉부 질환에 대한 모델의 민감도를 높여주었고, 전망 기반 예측 집계(view-based prediction aggregation) 전략이 성능을 크게 향상시켰습니다.



### Early Diagnoses of Acute Lymphoblastic Leukemia Using YOLOv8 and YOLOv11 Deep Learning Models (https://arxiv.org/abs/2410.10701)
Comments:
          4 pages, 6 figures, 3 tables

- **What's New**: 이 연구는 Acute Lymphoblastic Leukemia (ALL) 탐지를 위한 YOLOv8 및 YOLOv11 모델을 처음으로 적용하여 백혈구를 악성과 양성으로 분류하고 초기 단계의 ALL을 포함한 다양한 단계의 ALL을 확인합니다.

- **Technical Details**: 이미지 처리 기법과 딥러닝 기술을 사용하여 혈액암인 Acute Lymphoblastic Leukemia를 탐지하는데 중점을 두었습니다. Segmentation 기법을 통해 데이터를 준비하고 transfer learning 및 fine-tuning 기법을 적용하여 모델의 정확도를 98.8% 이상으로 향상시켰습니다.

- **Performance Highlights**: YOLOv11 모델을 사용하여 연속된 100 epochs의 학습 과정에서 높은 정확도를 달성했습니다. 특히, 모델은 여러 데이터셋과 다양한 실제 상황에서도 일관되게 뛰어난 성능을 보여줍니다.



### TALK-Act: Enhance Textural-Awareness for 2D Speaking Avatar Reenactment with Diffusion Mod (https://arxiv.org/abs/2410.10696)
Comments:
          Accepted to SIGGRAPH Asia 2024 (conference track). Project page: this https URL

- **What's New**: 본 연구에서는 2D 말하는 아바타 에니메이션을 위한 TALK-Act 프레임워크를 제안합니다. 이 프레임워크는 얼굴 뿐만 아니라 몸통과 제스처의 움직임도 제어하는 능력을 가지고 있습니다. 기존의 연구들이 주로 얼굴에 중점을 두었던 반면, 이 연구는 보다 자연스러운 움직임을 가능하게 합니다.

- **Technical Details**: TALK-Act 프레임워크는 모노큘러 비디오의 짧은 영상으로부터 2D 아바타를 고충실도로 재현할 수 있습니다. 이 모델은 Motion-Enhanced Textural Alignment 모듈과 Memory-based Hand-Recovering 모듈을 통해 텍스처 정합성 및 손 모양 복원을 개선합니다. 구조적 모션 안내는 2D 포즈, 3D 파라메트릭 얼굴 렌더링, 그리고 손 렌더링을 사용하여 구축됩니다.

- **Performance Highlights**: 모델은 30초의 개인별 데이터로도 안정적이고 고충실도의 2D 아바타를 재현할 수 있으며, 실험 결과 이전 최첨단 방법들보다 뛰어난 성능을 보여줍니다.



### Cross-Modal Few-Shot Learning: a Generative Transfer Learning Framework (https://arxiv.org/abs/2410.10663)
Comments:
          19 pages, 7 figures

- **What's New**: 이 논문은 기존의 대부분의 few-shot learning 연구가 unimodal 설정에 집중하고 있다는 점을 지적하며, real-world 데이터가 본질적으로 multi-modal이기 때문에 Cross-modal Few-Shot Learning (CFSL)이라는 새로운 작업을 제안합니다. 이 작업은 각기 다른 여러 모달리티에서 불과 몇 개의 레이블이 있는 예제만 가지고 인스턴스를 인식하는 것을 목표로 합니다.

- **Technical Details**: 이 논문에서는 Generative Transfer Learning (GTL) 프레임워크를 제안하여 unimodal 데이터에서의 지식을 multi-modal 데이터로 전이하도록 합니다. GTL 프레임워크는 두 단계로 이루어져 있으며, 첫 번째 단계는 데이터가 풍부한 unimodal 데이터에 대한 학습, 두 번째 단계는 새로운 데이터에 적응하는 transfer learning에 초점을 맞추고 있습니다. 각 단계에서 latent shared concept를 추정하고, transfer 단계에서는 generative 모듈을 고정하여 학습된 표현의 안정성을 유지하면서 overfitting을 방지합니다.

- **Performance Highlights**: 이 GTL 프레임워크는 Sketchy, TU-Berlin, Mask1K, SKSF-A의 4개 multi-modal 데이터셋에서 최첨단 방법들보다 우수한 성능을 보이는 것으로 나타났습니다. 또한, 모델이 방대한 unimodal 데이터에서 latent 개념을 추정하고, 이러한 개념을 사용하여 제한된 수의 샘플로 unseen 모달리티에 일반화할 수 있음을 보여줍니다.



### PCF-Lift: Panoptic Lifting by Probabilistic Contrastive Fusion (https://arxiv.org/abs/2410.10659)
Comments:
          ECCV 2024. The code is publicly available at this https URL

- **What's New**: PCF-Lift(Probabilistic Contrastive Fusion)라는 새로운 파이프라인을 설계하여, 불확실한 2D 분할과 일관성 없는 인스턴스 ID를 적극적으로 고려하는 확률적 특징을 학습하고 내장합니다.

- **Technical Details**: 다변량 가우시안 분포를 통해 확률적 특징 임베딩을 모델링하며, Contrastive Loss 공식을 활용하여 확률적 특징을 융합하고, 새로운 cross-view constraint를 도입하여 다양한 뷰 간의 특징 일관성을 향상시킵니다.

- **Performance Highlights**: ScanNet와 Messy Room 데이터셋에서 기존 최첨단 방법보다 평균 4.4% 향상된 성능을 보이며, 다양한 2D 분할 모델이나 손수 제작한 노이즈 수준에 대해 강력한 내구성을 입증합니다.



### SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers (https://arxiv.org/abs/2410.10629)
Comments:
          Technical Report

- **What's New**: Sana는 텍스트에서 이미지를 효율적으로 생성할 수 있는 프레임워크로, 최대 4096×4096 해상도에서 고해상도 이미지를 빠른 속도로 생성할 수 있는 기능을 제공합니다. 이 모델은 기존의 대규모 확산 모델에 비해 20배 작은 크기를 가지면서도 100배 이상의 빠른 처리 속도를 자랑합니다.

- **Technical Details**: Sana는 다음과 같은 핵심 설계를 포함합니다: (1) Deep compression autoencoder - 이미지를 32배 압축할 수 있도록 훈련된 새로운 Autoencoder (AE)를 사용하여 잠재 토큰 수를 줄입니다. (2) Linear DiT - 기존의 2차 주의(attention) 대신 1차 주의로 대체하여 고해상도에서도 효율성을 높였습니다. (3) Decoder-only text encoder - T5 대신 Gemma라는 최신 모델을 사용하여 이미지-텍스트 정렬을 향상시킵니다. (4) Efficient training and sampling - Flow-DPM-Solver를 통해 샘플링 단계를 줄입니다.

- **Performance Highlights**: Sana-0.6B는 4K 이미지를 생성하는 데 있어 기존 최첨단 모델인 FLUX보다 100배 이상의 빠른 처리량을 기록하며, 1K 해상도에 대해서는 40배 빠른 속도를 보여줍니다. 또한, 소비자 등급의 4090 GPU에서 1024×1024 해상도의 이미지를 0.37초 만에 생성할 수 있습니다.



### BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI (https://arxiv.org/abs/2410.10604)
- **What's New**: 본 논문에서는 다양한 MRI 모달리티를 활용한 뇌 이미지 분석을 위한 새로운 다중 모달 비전 사전 학습 프레임워크인 BrainMVP를 제안합니다. BrainMVP는 불완전한 모달리티 문제를 해결하고 다중 모달 정보 융합을 실현합니다.

- **Technical Details**: BrainMVP는 16,022개의 뇌 MRI 스캔 데이터셋을 바탕으로 설정되며, 크로스 모달 재구성이 이루어져 각 모달리티의 독특한 영상 임베딩을 학습합니다. 모달리티 별 데이터 증류 모듈을 통해 각 MRI 이미지의 본질적 표현을 추출하고, 적절한 모달리티 인식을 통해 크로스 모달 연관성을 높입니다.

- **Performance Highlights**: BrainMVP 모델은 6가지 분할 기준에서 0.28%-14.47%의 Dice Score 개선과 4개의 개별 분류 작업에서 0.65%-18.07%의 일관된 정확성을 보여주며, 기존 선도적인 사전 학습 방법들보다 우수한 성능을 입증합니다.



### MoTE: Reconciling Generalization with Specialization for Visual-Language to Video Knowledge Transfer (https://arxiv.org/abs/2410.10589)
Comments:
          NeurIPS 2024 Camera Ready

- **What's New**: 최근 비디오 인식을 위한 대규모 비전-언어 모델(Vision-Language Models)에서 MoTE라는 새로운 프레임워크가 제안되었습니다. 이 프레임워크는 일반화(generalization)와 전문화(specialization)를 균형 있게 조정하여, 여러 작업 뷰(task views)를 통해 다양한 데이터 적합도를 학습할 수 있도록 디자인되었습니다.

- **Technical Details**: MoTE는 다수의 전문가(experts)를 사용하는 혼합(mixture) 접근법으로, 파라미터(나중에 Fine-tuning된 데이터에 대한 과적합 위험이 큼)를 통해 모델 일반화를 향상시키는 것을 목표로 합니다. 또한, 파라미터 병합(weight merging)을 정규화하는 Weight Merging Regularization을 통해 결합 과정에서의 일반화와 전문화 지식을 효과적으로 집합할 수 있게 됩니다. 이를 통해, 각 전문가들이 서로 다른 데이터 바이어스를 학습할 수 있도록 라우팅 알고리즘을 제시하였습니다.

- **Performance Highlights**: MoTE는 Kinetics-400 & 600, UCF, HMDB 등 다양한 데이터셋에 대해 최첨단(state-of-the-art) 또는 경쟁력 있는 성능을 보여주었으며, 제로샷(zero-shot)과 클로즈셋(close-set) 비디오 인식 작업 간의 최적의 균형을 달성하였습니다.



### TopoFR: A Closer Look at Topology Alignment on Face Recognition (https://arxiv.org/abs/2410.10587)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 최근 심층 학습(deep learning)의 발전 덕분에 얼굴 인식(face recognition, FR) 분야에서 중요한 진전을 이루었습니다. 이 연구에서는 비지도 학습(unsupervised learning)과 그래프 신경망(graph neural networks)이 데이터 구조 정보를 활용하여 모델의 일반화 성능을 향상시키는 방법을 탐구합니다.

- **Technical Details**: TopoFR 모델은 지속적 동형성(persistent homology)을 이용해 입력 공간(input space)과 잠재 공간(latent space)의 위상 구조를 정렬하는 기법인 PTSA(perturbation-guided topological structure alignment)를 사용하여 구조 정보를 보존합니다. 또한 SDE(structure damage estimation)라는 하드 샘플 샘플링(hard sample mining) 전략을 통해 구조 손상 점수(structure damage score, SDS)를 계산하여 힘든 샘플을 효과적으로 최적화합니다.

- **Performance Highlights**: TopoFR은 여러 얼굴 인식 벤치마크에서 기존의 최신 기술(SOTA) 방법들보다 뛰어난 성능을 보였으며, 특히 ICCV21 MFR-Ongoing 챌린지에서 두 번째 자리를 차지하는 성과를 올렸습니다. 이는 모델의 강인성과 일반화 능력을 잘 나타냅니다.



### Queryable Prototype Multiple Instance Learning with Vision-Language Models for Incremental Whole Slide Image Classification (https://arxiv.org/abs/2410.10573)
Comments:
          16 pages, 10 tables, 11 figures

- **What's New**: 이번 논문에서는 Incremental Whole Slide Image (WSI) 분류를 위해 개발된 Vision-Language 기반의 새로운 프레임워크인 Queryable Prototype Multiple Instance Learning (QPMIL-VL)을 소개합니다. 이 프레임워크는 동적 데이터 분포에 효율적으로 적응할 수 있도록 설계되었습니다.

- **Technical Details**: QPMIL-VL 프레임워크는 두 개의 정보 처리 브랜치로 구성됩니다. 첫 번째 브랜치는 프로토타입 기반 집계를 통해 bag-level feature를 생성하는 반면, 두 번째 브랜치는 클래스 앙상블, 조정 가능한 벡터 및 클래스 유사성 손실을 통해 클래스 특성을 강화합니다. 이 구조는 기존의 static MIL 방법들의 한계를 극복하는 데 초점을 맞추고 있습니다.

- **Performance Highlights**: 실험 결과, QPMIL-VL은 네 개의 TCGA 데이터셋에서 다른 기존 방법들을 상회하는 성능을 보였으며, incremental WSI 분류 작업에서 state-of-the-art (SOTA) 성능을 달성했습니다.



### MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks (https://arxiv.org/abs/2410.10563)
Comments:
          Technical report. Project page: this https URL

- **What's New**: MEGA-Bench는 500개 이상의 실제 작업을 포함하는 다중 모드 평가 스위트를 소개합니다. 이를 통해 사용자들의 다양한 요구를 충족시키고, 고품질 데이터 샘플을 최적화하는 것을 목표로 합니다.

- **Technical Details**: 505개의 실제 작업과 8,000개 이상의 샘플을 수집하였으며, 다수의 출력 형식과 40개 이상의 평가 메트릭을 개발했습니다. MEGA-Bench는 input type, output format, skill 등 여러 차원에 대해 세밀한 성능 보고서를 제공합니다.

- **Performance Highlights**: MEGA-Bench를 기반으로 GPT-4o가 최상의 성능을 보였고, Qwen2-VL은 오픈소스 모델 중에서는 가장 우수한 성능을 발휘했습니다. Gemini 1.5 Flash는 효율성 모델 중에서 가장 강력한 모델이었습니다.



### ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection (https://arxiv.org/abs/2410.10554)
- **What's New**: 본 논문은 ROSAR라는 새로운 프레임워크를 소개하며, 자율 수중 차량이 생성한 사이드 스캔 소나(SSS) 이미지에 특화된 깊은 학습 객체 탐지 모델의 견고성을 향상시킵니다.

- **Technical Details**: ROSAR는 지식 증류(Knowledge Distillation, KD)와 적대적 재훈련(adversarial retraining)을 결합하여 SSS 노이즈에 대한 모델의 효율성과 견고성을 동시 해결하는 접근법을 제안합니다. 이 프레임워크에서는 세 가지 새로운 SSS 데이터셋을 공개하며, 특정 안전 속성을 정의하고, 이를 바탕으로 적대적 데이터셋을 생성하여 재훈련을 수행합니다.

- **Performance Highlights**: ROSAR는 PGD(Projected Gradient Descent) 및 패치 기반 적대적 공격을 통한 비교 분석에서 SSS 특수 조건 하에서 모델의 견고성 및 탐지 정확도를 크게 향상시켜, 최대 1.85%의 개선을 보여주었습니다.



### RICASSO: Reinforced Imbalance Learning with Class-Aware Self-Supervised Outliers Exposur (https://arxiv.org/abs/2410.10548)
Comments:
          14 pages, 2 figures

- **What's New**: 이번 연구에서는 RICASSO라는 새로운 프레임워크를 제안하여 데이터의 불균형(long-tailed) 및 분포 외(out-of-distribution, OOD) 데이터를 동시에 해결합니다. RICASSO는 실제 OOD 데이터 사용 없이 혼합 데이터를 통해 가짜 OOD 데이터를 생성하여 문제를 해결할 수 있음을 보여줍니다.

- **Technical Details**: RICASSO는 Norm-Odd-Duality-Based Outlier Exposure, Ambiguity-Aware Logits Adjustment, Contrastive Boundary-Center Learning의 세 가지 전략으로 구성됩니다. 혼합 데이터는 ID 및 OOD 데이터의 특성을 모두 보유하며, 이를 통해 동시에 ID 데이터의 재조정과 OOD 데이터의 노출을 가능하게 합니다. 또한, Ambiguity-Aware Logits Adjustment를 통해 각 샘플에 대한 세밀한 주의 집중이 가능합니다.

- **Performance Highlights**: 실험 결과, RICASSO는 long-tailed 인식 및 OOD 탐지에서 최첨단 성능을 달성하였으며, iNaturalist2018 데이터셋에서 OOD 탐지의 AUROC에서 27% 개선과 FPR에서 61% 감소를 보였습니다. RICASSO는 실제 OOD 데이터를 사용하는 방법보다 더 나은 성능을 보였습니다.



### Hybrid Transformer for Early Alzheimer's Detection: Integration of Handwriting-Based 2D Images and 1D Signal Features (https://arxiv.org/abs/2410.10547)
- **What's New**: 이번 연구에서는 알츠하이머병(AD) 조기 탐지를 위해 2D 손글씨 이미지와 1D 동적 손글씨 신호를 동시에 통합하는 새로운 하이브리드 어텐션 모델을 제안합니다. 이는 기존의 수동으로 추출한 특징이나 단순한 머신 러닝 모델에 의존하는 접근 방식을 넘어서는 혁신적인 방법입니다.

- **Technical Details**: 제안한 모델은 게이트 메커니즘을 활용하여 2D 손글씨의 공간 패턴과 1D 동적 특징 간의 상관관계를 학습하고, 멀티모달(multi-modal) 데이터를 효과적으로 결합합니다. 새롭게 도입된 손실 함수는 템플릿 대조 손실(template contrastive loss)과 크로스 엔트로피 손실(cross-entropy loss)을 결합하여 분류 성능을 향상시킵니다.

- **Performance Highlights**: DARWIN 데이터셋을 대상으로 한 평가에서, 본 모델은 90.32%의 F1 점수와 90.91%의 정확도를 기록하며, Task 8('L' writing)에서 이전 최상 성능보다 각각 4.61% 및 6.06% 우수한 성과를 보였습니다.



### Motion-guided small MAV detection in complex and non-planar scenes (https://arxiv.org/abs/2410.10527)
Comments:
          8 pages, 6 figures

- **What's New**: 본 논문에서는 복잡하고 비평면적인 장면에서 소형 MAV를 정확하게 탐지할 수 있는 새로운 모션 가이드 MAV 탐지기(MGMD)를 제안합니다. 기존의 방법들이 배경이 복잡하거나 MAV가 너무 작을 때 어려움을 겪는 문제를 해결하고자 합니다.

- **Technical Details**: 제안한 알고리즘은 세 가지 모듈로 구성됩니다: 모션 특징 강화(Motion Feature Enhancement), 궤적 필터링(Trajectory Filtering), 지역 세밀 탐지(Local Fine Detection). 모션 특징 강화 모듈은 복잡한 배경에서 소형 MAV의 모션 특징을 추출하며, 다중 객체 추적 및 궤적 필터링을 이용하여 모션 패럴랙스(Motion Parallax)로 인한 잘못된 탐지를 제거합니다.

- **Performance Highlights**: ARD-MAV 데이터셋에서의 실험 결과, 제안한 방법이 복잡한 배경에서도 소형 MAV 탐지에서 높은 성능을 달성하였으며, 다양한 메트릭에서 최첨단 방법들을 능가함을 보여주었습니다.



### Customize Your Visual Autoregressive Recipe with Set Autoregressive Modeling (https://arxiv.org/abs/2410.10511)
Comments:
          19 pages, 17 figures, 8 tables, github repo: this https URL

- **What's New**: 새로운 패러다임인 Set AutoRegressive Modeling (SAR)을 소개합니다. SAR은 기존의 AutoRegressive (AR)를 확장하여 시퀀스를 고정된 순서 대신 여러 토큰을 포함하는 임의의 세트로 나눌 수 있도록 합니다.

- **Technical Details**: SAR의 구조는 Fully Masked Transformer (FMT)라는 간단한 아키텍처로 구성되어 있으며, 이는 시퀀스 순서와 출력 간격을 임의의 구성으로 일반화합니다. SAR 프레임워크 내에서 기존의 AR 변형들이 특정 설계 선택에 대응한다는 것을 보여줍니다. SAR은 AR과 Masked AR (MAR) 간의 매끄러운 전이를 가능하게 하며, 각각의 장점인 few-step inference와 KV cache 가속을 활용할 수 있습니다.

- **Performance Highlights**: 이미지넷(IMAGENET) 벤치마크에서 SAR의 특성을 분석하여 시퀀스 순서와 출력 간격이 성능에 미치는 영향을 조사했습니다. 900M 텍스트-투-이미지 모델을 훈련시켜 텍스트 설명을 준수하는 사실적인 이미지를 생성할 수 있는 능력을 검증했습니다. 이 모델은 임의의 비율의 이미지를 생성할 수 있으며, 제로샷(image editing)에서도 효과적으로 적용 가능합니다.



### Exploiting Local Features and Range Images for Small Data Real-Time Point Cloud Semantic Segmentation (https://arxiv.org/abs/2410.10510)
Comments:
          This paper has been accepted for publication at the 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)

- **What's New**: 이 논문에서는 점구름(Point Cloud) 세분화(Semantic Segmentation) 문제를 해결하기 위해 WaffleIron과 RangeFormer 모델을 조합한 새로운 심층 학습 아키텍처를 제안합니다. 특히, 작은 데이터셋에서도 뛰어난 성능을 발휘하는 방법론을 상세히 설명하고 있습니다.

- **Technical Details**: 점구름 데이터의 로컬 특징(local features)을 캡처하기 위해 3D 표현을 활용하며, 범위 이미지(range image) 표현을 도입하여 추가 정보를 포함하고 계산 속도를 향상시킵니다. GPU 기반 KDTree를 사용하여 점구름 임베딩 모듈에서의 빌딩 및 쿼리를 신속하게 처리합니다. 이 방법론의 주요 구성 요소는 점구름 임베딩 모듈, 점구름 처리 레이어로 구성된 백본(backbone), 최종 세분화를 위한 세그멘테이션 헤드입니다.

- **Performance Highlights**: SemanticKITTI와 nuScenes 데이터셋에서의 실험 결과, 제안한 방법론은 데이터가 제한적인 상황에서도 뛰어난 성능을 보여주었으며, 전체 모델의 시스템 런타임을 단 180ms로 감소시켰습니다. 또한, 축소된 모델이 실시간으로 작동하면서도 최신 모델들과 경쟁력을 갖춘다는 것을 입증하였습니다.



### Artificial Intelligence-Based Triaging of Cutaneous Melanocytic Lesions (https://arxiv.org/abs/2410.10509)
Comments:
          14 pages, 6 figures

- **What's New**: 이 연구는 전체 슬라이드 이미지(Whole Slide Images, WSI)를 기반으로 한 피하 멜라닌종 병변의 분류를 위한 인공지능(AI) 모델 개발에 관한 것입니다. 이 AI 모델은 네덜란드 유니버시티 메디컬 센터 위트레흐트(UMC Utrecht)의 회고적 코호트를 사용하여 개발 및 검증되었습니다.

- **Technical Details**: 연구는 27,167 개의 고유한 표본으로부터 획득한 52,202 개의 전체 슬라이드 이미지를 포함한 데이터 세트를 사용했습니다. 이 데이터 세트는 병변의 복잡성에 따라 저복잡성(86.6%)과 고복잡성(13.4%)으로 분류되었습니다. 예측 성능은 수신기 작동 특성 곡선의 면적(AUROC)과 정밀-재현 곡선의 면적(AUPRC)을 통해 평가되었습니다.

- **Performance Highlights**: AI 모델은 시험 세트에서 AUROC 0.966, AUPRC 0.857을 기록하였으며, 배포 밖 시험 세트에서는 AUROC 0.899, AUPRC 0.498를 기록하였습니다. 또한, AI 기반 분류를 통해 일반 병리학자가 처리해야 할 고복잡성 사례에 대한 초기 검사를 평균 43.9회 예방할 수 있었습니다.



### Continual Learning Improves Zero-Shot Action Recognition (https://arxiv.org/abs/2410.10497)
Comments:
          Accepted in ACCV 2024

- **What's New**: 본 논문에서는 ZSL(Zero-Shot Learning)과 CL(Continual Learning) 기술을 결합하여 제안된 새로운 GIL(Generative Iterative Learning) 방법을 소개합니다. GIL은 과거 클래스의 합성된 특징을 저장하는 메모리를 사용하고, 이를 새로운 클래스의 실제 특징과 결합하여 제로샷 액션 인식을 향상시킵니다. 이 방법은 기존 ZSL 방법들과는 상이하게 지속적인 학습을 적용합니다.

- **Technical Details**: GIL은 세 가지 단계로 구성됩니다: 초기화 단계에서는 기준 비디오 표현을 저장하는 Replay Memory를 구축하고, GAN(Generative Adversarial Network)을 훈련하여 메모리에 저장된 특징과 유사한 특징을 생성합니다. 점진적 학습 단계에서는 생성된 특징과 새로운 클래스의 실제 특징을 혼합하여 비디오 모델을 미세 조정합니다. 마지막으로 갱신 단계에서는 새로운 클래스의 프로토타입 표현을 메모리에 추가하여 모델이 새로운 작업을 학습하는 동시에 이전 작업의 지식을 잊지 않도록 합니다.

- **Performance Highlights**: GIL은 UCF-101, HMDB-51, Kinetics-600 등 3개의 표준 ZSL/GZSL 벤치마크에서 실험하여 최대 20%까지 성능을 향상시켰습니다. 특히 일반화된 제로샷 설정(GZSL)에서도 우수한 인식 성능을 보였습니다.



### Vision-guided and Mask-enhanced Adaptive Denoising for Prompt-based Image Editing (https://arxiv.org/abs/2410.10496)
- **What's New**: 이번 연구에서는 Vision-guided and Mask-enhanced Adaptive Editing (ViMAEdit) 방법을 제안하며, 이는 기존의 텍스트 기반 이미지 편집 방식의 한계점을 극복하고자 합니다. 특히, 소스 이미지를 이용하여 목표 이미지를 생성하는 새로운 접근 방식을 도입하였습니다.

- **Technical Details**: ViMAEdit는 특히 이미지 임베딩을 활용하여 기존의 텍스트 프롬프트 기반 디노이징 프로세스를 강화합니다. CLIP 기반의 목표 이미지 임베딩 추정 전략을 통해 에디팅 영역의 정밀성을 높이고, 자가 주의(self-attention)에 기반한 반복적인 에디팅 영역 근거 전략을 도입하여 패치 간 관계를 효과적으로 활용합니다.

- **Performance Highlights**: ViMAEdit는 기존 방법들에 비해 월등한 편집 능력을 보여주며, 중요한 이미지 영역에 더욱 높은 샘플링 분산을 적용하여 편집의 효과성을 향상시킵니다. 실험 결과에서 ViMAEdit는 타 연구 방법들과 비교하여 더욱 정교하고 효과적인 편집 결과를 도출해냅니다.



### Learning to Ground VLMs without Forgetting (https://arxiv.org/abs/2410.10491)
- **What's New**: 이 논문에서는 LynX라는 새로운 프레임워크를 소개하는데, 사전 훈련된 시각 언어 모델(Visual Language Models, VLMs)에 공간 인식 능력을 효과적으로 추가하는 방법을 제시하고 있습니다. 이 프레임워크는 기존 능력을 잃지 않고 새로운 그라운딩(grounding) 기능을 학습하도록 설계되었습니다.

- **Technical Details**: LynX는 Dual Mixture of Experts (MoE) 아키텍처를 기반으로 하며, 이는 언어 모델의 디코더 레이어만 수정하여 한 개의 고정된 MoE와 하나의 학습 가능한 MoE를 사용합니다. 이는 모델이 이미지 이해 및 언어 이해 능력을 유지하면서 새로운 그라운딩 능력을 획득할 수 있게 합니다. 또한, SCouT라는 고품질 합성 데이터셋을 생성하여 시각적 그라운딩 작업을 위한 고급 훈련 신호를 제공합니다.

- **Performance Highlights**: LynX 모델은 여러 객체 탐지 및 시각적 그라운딩 데이터셋에서 강력한 성능을 입증하였으며, 객체 탐지, 제로샷 로컬라이제이션(zero-shot localization), 그리고 그라운딩 추론에서 높은 성과를 보였습니다. 이 과정에서 기존의 이미지 및 언어 이해 능력을 성공적으로 유지했습니다.



### Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization (https://arxiv.org/abs/2410.10483)
Comments:
          Paper submitted to Computer in Biology and Medicine, ELSEVIER

- **What's New**: 이 연구는 신생아를 위한 AI 기반 시간 감지 시스템을 개발하는 방식으로 신생아의 생명 구제 지원을 향상시키고자 합니다. 특히, 출생 후 '황금 분' 동안 신속한 응급 처치 필요성을 강조합니다.

- **Technical Details**: 본 연구는 세 가지 단계의 방법론을 제안합니다: 첫째, 온도 변동 문제를 완화하기 위해 Gaussian mixture models (GMM) 기반 적응 정규화 기법을 제안합니다; 둘째, 온도 비디오 프레임 안에서 신생아의 존재를 감지하기 위해 AI 모델을 구현하고 배치합니다; 셋째, 모델의 예측을 평가하고 후처리하여 출생 시간(Time of Birth, ToB)을 추정합니다.

- **Performance Highlights**: 실제 성능 평가에서 신생아 탐지에 대한 정확도는 88.1%이며 재현율은 89.3%로 보고되었습니다. 이 방법은 수동 주석에 비해 절대 중앙 편차가 2.7초로 ToB 추정의 정확성을 보여줍니다.



### ReLayout: Towards Real-World Document Understanding via Layout-enhanced Pre-training (https://arxiv.org/abs/2410.10471)
- **What's New**: 최근 시각적으로 풍부한 문서 이해(VrDU)를 위한 접근 방식들은 수동으로 주석된 의미 그룹을 사용하지만, 이는 비현실적입니다. 새로운 '실제 세계 시각적으로 풍부한 문서 이해(ReVrDU)'라는 과제를 도입하며, ReLayout이라는 새로운 방법을 제안하여 의미 그룹을 수동으로 사용하지 않고 문서를 이해합니다.

- **Technical Details**: ReVrDU에서는 수동으로 주석된 의미 그룹 대신 상용 OCR 도구에서 제공하는 정보(글자, 1D 위치, 2D 바운딩 박스 등)를 사용합니다. 'ReLayout' 모형은 단순한 1D 전역 위치와 2D 바운딩 박스를 입력으로 사용하여 텍스트 세그먼트 내 단어 순서를 예측하고 세그먼트 클러스터링을 통한 자기 지도 학습을 적용합니다.

- **Performance Highlights**: 기존의 방법이 ReVrDU 과제에서 성능이 저하된 반면, ReLayout은 이상적 및 실제 환경 모두에서 우수한 성능을 보였습니다.



### Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks (https://arxiv.org/abs/2410.10454)
Comments:
          Accepted by EMNLP 2024 Findings

- **What's New**: 이 논문에서는 few-shot text classification의 정확도를 높이기 위해 Label-Adapter 및 Query-Data-Augmenter 모듈을 도입한 새로운 방법인 LAQDA를 제안합니다.

- **Technical Details**: LAQDA는 태스크에 적응하는 메트릭 공간을 구성하여 intra-class 차이를 줄이고 inter-class 차이를 확대합니다. 최적 수송(optimal transport) 기법을 활용하여 쿼리 세트 샘플로 클래스 프로토타입을 추정합니다. 이 방법은 기존의 과적합(overfitting) 문제를 완화하는 것을 목표로 합니다.

- **Performance Highlights**: 제안된 LAQDA 방법은 8개의 벤치마크 데이터셋에서 state-of-the-art 모델들에 비해 확연한 성능 향상을 보여주며, 모든 작업(task)에서 높은 정확도를 기록했습니다.



### Self-Assessed Generation: Trustworthy Label Generation for Optical Flow and Stereo Matching in Real-world (https://arxiv.org/abs/2410.10453)
- **What's New**: 본 논문에서는 Optical Flow와 Stereo 작업을 위한 통합된 자기 지도 생성 프레임워크인 Self-Assessed Generation (SAG)을 제안합니다. 이 방법은 고비용의 데이터셋 생성 문제와 기존의 모호한 결과 및 복잡한 모델 훈련 한계를 해결합니다.

- **Technical Details**: SAG는 RGB 이미지에서 재구성 필드를 생성하고 이를 바탕으로 데이터셋을 생성하는 데이터 기반 접근 방식을 사용합니다. 주요 모듈로는 라벨 데이터 생성, 데이터 자기 평가 및 3D 비행 전경 자동 렌더링 파이프라인이 포함되어 있습니다. 새로운 RC 지표를 도입하여 재구성 모델의 신뢰도를 평가합니다.

- **Performance Highlights**: SAG는 기존의 방법들과 비교하여 48% 향상된 Optical Flow endpoint error (2.04 vs 3.96)를 기록하였으며, 단 300개의 자연 장면을 사용하여 뛰어난 일반화 성능을 발휘합니다. 기존의 자기 지도 학습 방법에 비해 더 일반화되고 저비용이면서 정확하게 작용합니다.



### Domain-Conditioned Transformer for Fully Test-time Adaptation (https://arxiv.org/abs/2410.10442)
- **What's New**: 이번 연구는 Transformer 모델의 Fully Test-Time Adaptation에 대한 새로운 접근 방식을 제안하며, 도메인 변화에 대한 적응성이 개선된 Self-Attention 모듈 구조를 도입합니다.

- **Technical Details**: Self-Attention 모듈에 도메인 조건 벡터인 domain conditioners를 쿼리, 키, 값 컴포넌트에 통합하여, 각 레이어에서 클래스 토큰으로부터 이 벡터를 생성합니다. 이를 통해 도메인 이동으로 인한 편차를 단계적으로 제거합니다.

- **Performance Highlights**: 제안된 domain-conditioned transformer는 온라인에서의 도메인 적응 성능을 대폭 향상시키며, 기존의 최신 방법들을 크게 능가하는 결과를 보였습니다.



### Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs (https://arxiv.org/abs/2410.10441)
Comments:
          Tech report

- **What's New**: 비디오 이해를 위한 효율적인 추론을 제공하는 새로운 프롬프트 기반 시각 인식 프레임워크(Free Video-LLM)를 제시합니다.

- **Technical Details**: 이 프레임워크는 공간적-시간적 차원을 분리하고, 작업별 프롬프트에 따라 시간적 프레임 샘플링(temporal frame sampling)과 공간적 RoI 크롭(spatial RoI cropping)을 수행합니다. 이를 통해 비디오 프레임에서 생성되는 시각 토큰(visual tokens)의 수를 효과적으로 줄입니다.

- **Performance Highlights**: 우리의 방법은 여러 비디오 질문-응답 벤치마크에서 높은 성능을 유지하면서 토큰 수를 크게 줄여, 정확도와 계산 효율 간의 최적의 균형을 제공합니다.



### LKASeg:Remote-Sensing Image Semantic Segmentation with Large Kernel Attention and Full-Scale Skip Connections (https://arxiv.org/abs/2410.10433)
Comments:
          The paper is under consideration at 2025 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)

- **What's New**: 본 논문에서는 원격 감지 이미지의 의미적 분할을 위한 새로운 네트워크인 LKASeg를 제안합니다. 이 네트워크는 Large Kernel Attention (LKA)와 Full-Scale Skip Connections (FSC)을 결합하여, 전통적인 CNNs와 Transformers의 한계를 극복합니다.

- **Technical Details**: LKASeg는 ResNet-18 기반의 인코더, LKA 기반의 디코더, 및 전체 규모의 스킵 연결(FSC)로 구성됩니다. LKA는 글로벌 피처를 추출하면서도 self-attention의 계산 오버헤드를 피하고, 채널 적응성을 제공합니다.

- **Performance Highlights**: ISPRS Vaihingen 데이터셋에서 실험을 진행한 결과, mF1 점수 90.33%, mIoU 점수 82.77%를 달성하였습니다.



### DOME: Taming Diffusion Model into High-Fidelity Controllable Occupancy World Mod (https://arxiv.org/abs/2410.10429)
Comments:
          Please visit our project page at this https URL

- **What's New**: 본 논문에서는 과거의 점유 관측치를 기반으로 미래의 점유 프레임을 예측하는 diffusion 기반의 세계 모델인 DOME을 제안합니다. 이 세계 모델은 자율주행의 계획에서 환경 변화의 예측 능력이 매우 중요하며, 2D 영상 기반 모델과 달리 본래의 3D 표현을 활용합니다.

- **Technical Details**: DOME은 고충실도 및 장기 생성(Diffusion)과 세밀한 제어 가능성을 key feature로 가지고 있습니다. 과거의 정보(contextual occupancy)를 활용하는 공간-시간(diffusion transformer) 구조를 채택하여, 32초에 걸쳐 상세한 예측을 생성할 수 있습니다. 또한, 경로 재샘플링 방법을 도입하여 다양한 주행 궤적을 더욱 정밀하게 예측할 수 있도록 제어 가능성을 향상시킵니다.

- **Performance Highlights**: nuScenes 데이터셋을 통해 수행된 실험에서, DOME은 기존 모델을 초월하여 3D 점유 재구성에서 10.5% 향상된 mIoU 및 21.2% 향상된 IoU, 4D 점유 예측에서 각각 36.0% 향상된 mIoU 및 24.6% 향상된 IoU를 기록했습니다.



### 4DStyleGaussian: Zero-shot 4D Style Transfer with Gaussian Splatting (https://arxiv.org/abs/2410.10412)
- **What's New**: 이번 논문에서는 4D 스타일 전송을 위한 새로운 프레임워크인 4DStyleGaussian을 소개합니다. 이 방법은 사용자 친화적인 스타일화를 제공하면서도 공간적 일관성을 유지할 수 있는 가능성을 보여줍니다.

- **Technical Details**: 4DStyleGaussian은 4D Gaussian Splatting 기법을 활용하여 작동하며, 내용 손실(content loss)을 최소화하는 가역적(neural network) 네트워크를 통해 훈련됩니다. 이 방법은 4D 스타일 변환 행렬을 예측하여 공간적, 시간적으로 일관된 스타일 전송을 수행합니다.

- **Performance Highlights**: 실험 결과, 4DStyleGaussian은 4D 동적 시나리오에서 높은 품질과 제로샷(zero-shot) 스타일화를 달성하며, 향상된 효율성과 공간-시간적 일관성을 보였습니다.



### Parameterize Structure with Differentiable Template for 3D Shape Generation (https://arxiv.org/abs/2410.10399)
- **What's New**: 이 논문은 구조적 표현(Structural representation)을 통해 편집 가능한 3D 형태를 재구성하고 생성하는 새로운 방법을 제안합니다. 특히, 동일 카테고리 내에서 공유되는 구조를 차별화된 템플릿(differentiable template)과 고정 길이 매개변수(fixed-length parameters)를 사용하여 파라미터화합니다.

- **Technical Details**: 제안된 방법은 각 카테고리에 대한 공유 구조의 차별화된 템플릿을 디자인하며, 이를 통해 특정 매개변수를 바탕으로 형태를 표현합니다. 3D 형태는 격자로 형성되며, 각 격자의 내부 세부 사항을 설명하기 위해 세 가지 시각의 경계(threshold)를 이용합니다. 이로 인해 SDF(Signed Distance Function)를 통해 객체를 복원할 수 있습니다.

- **Performance Highlights**: 제안된 방법은 포인트 클라우드(point cloud)로부터의 재구성과 생성을 통해 다양한 형태를 복원하거나 생성할 수 있으며, 부드럽게 보간할 수 있습니다. 광범위한 평가 결과, 본 방법이 재구성, 생성 및 보간에서 우수한 성능을 보여주었습니다.



### Reverse Refinement Network for Narrow Rural Road Detection in High-Resolution Satellite Imagery (https://arxiv.org/abs/2410.10389)
- **What's New**: 이 연구는 도시 지역의 도로 추출에 중점을 두던 기존 연구와 달리, 좁고 불규칙한 농촌 도로의 자동 추출을 위한 새로운 방법인 R2-Net을 제안합니다.

- **Technical Details**: R2-Net은 고해상도 피쳐 맵에서 도로의 세부 사항을 보존하기 위해 axis context aware module (ACAM)을 사용하여 다양한 레이어에서 장거리 공간 맥락 정보를 캡처합니다. 이어서 multi-level features는 global aggregation module (GAM)을 통해 집계됩니다. 또한, decoder 단계에서는 reverse-aware module (RAM)을 활용하여 복잡한 배경에 대한 네트워크의 주의를 유도하여 분리 가능성을 강화합니다.

- **Performance Highlights**: R2-Net은 DeepGlobe 도로 추출 데이터셋과 WHU-RuR+ 글로벌 대규모 농촌 도로 데이터셋을 사용한 실험에서 여러 최첨단 방법들과 비교하여 뛰어난 성능을 보였습니다. 특히, 좁은 도로의 정확한 감지에서 두각을 나타냈으며, 대규모 농촌 도로 매핑에 대한 적용 가능성도 탐구하였습니다.



### V2M: Visual 2-Dimensional Mamba for Image Representation Learning (https://arxiv.org/abs/2410.10382)
- **What's New**: 본 논문은 2D 이미지 처리를 위한 새로운 모델인 'Visual 2-Dimensional Mamba (V2M)'를 제안합니다. 기존의 1D 시퀀스 처리 방식을 넘어 2D 공간에서 이미지 토큰을 직접 처리하여 더 나은 지역적 유사성(local similarity)과 일관성을 유지합니다.

- **Technical Details**: V2M은 2차원 상태 공간 모델(SSM)을 일반화하여 두 개의 인접한 상태를 고려하여 다음 상태를 생성합니다. 이는 열(columns) 및 행(rows) 두 방향의 정보를 활용하며, Mamba의 병렬 처리 능력을 결합하여 하드웨어 효율성을 극대화합니다. 또한, 이미지의 모든 네 모서리에서 시작하는 2D 상태 방정식을 통해 토큰을 비연속적으로 처리합니다.

- **Performance Highlights**: ImageNet 분류 및 COCO 객체 탐지, ADE20K 의미 구분에서 V2M의 성능이 기존의 Vision Mamba(Vim) 모델 대비 +0.4% 향상됨을 보여주었습니다. 이는 V2M이 2D 지역성을 효과적으로 통합하면서도 Mamba의 효율성과 입력 의존성 있는 확장성을 계승한다는 점을 입증합니다.



### Class Balancing Diversity Multimodal Ensemble for Alzheimer's Disease Diagnosis and Early Detection (https://arxiv.org/abs/2410.10374)
- **What's New**: 알츠하이머병(AD)의 조기 발견과 진단을 위한 새로운 다중모달 앙상블 접근 방식인 IMBALMED가 제안되었습니다. 이 방법은 ADNI(Alzheimer's Disease Neuroimaging Initiative) 데이터베이스에서 수집된 다양한 모달리티의 데이터를 통합하여 신경퇴행성 질환을 더 효과적으로 진단합니다.

- **Technical Details**: IMBALMED는 다양한 클래스 균형 기법을 사용하여 훈련된 모델 분류기를 앙상블로 구성하여 클래스 불균형 문제를 극복합니다. 이 연구에서는 임상 평가, 신경영상 형상, 생물학적 표본 및 주제 특징 데이터와 같은 다양한 모달리티의 데이터를 통합하여 AD 진단 및 초기 발견의 정확성을 향상시킵니다.

- **Performance Highlights**: IMBALMED는 기존의 가장 발전된 알고리즘과 비교하여 이진 및 삼진 분류 작업에서 우수한 진단 정확도와 예측 성능을 보여주었으며, 48개월 시점에서 MCI의 조기 발견을 현저히 개선했습니다.



### Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation (https://arxiv.org/abs/2410.10366)
Comments:
          BIBM 2024

- **What's New**: 이 논문은 의료 이미징 сегментация (segmentation)에서 반지도 학습 (SemiSL)과 대조 학습 (CL) 결합의 진전을 보여줍니다. 특히, 피사체(task)가 없는 경우에도 적은 주석으로 효과적인 모델 성능을 달성하는 방법을 제안합니다.

- **Technical Details**: 제안된 방법론은 학생 네트워크(student network)와 교사 네트워크(teacher network) 간의 친밀도 그래프 기반 지도 신호(affinity-graph-based supervision signals)를 설정하여 Semi-AGCL 프레임워크를 구성합니다. 또한 평균 패치 엔트로피 기반의 상호 패치 샘플링 방법을 설계하여 초기 특징 공간을 구축하고, 친밀도 그래프 손실 함수(affinity-graph-guided loss function)를 통해 학습된 표현의 품질을 향상시키고 과적합(overfitting)을 완화합니다.

- **Performance Highlights**: 실험 결과, 전체 주석 세트의 단 10%만 사용했음에도 불구하고, 제안한 모델은 완전 주석의 기준선과 함께 단 2.52%의 편차로 정확도에 접근했습니다. 특히, 주석의 5%만 사용된 상황에서도, dice metric에서 두 번째 최고 기준선을 23.09% 초과하여 성능이 크게 향상되었고, 특히 CRAG와 ACDC 데이터셋에서 26.57% 개선된 결과를 보였습니다.



### FasterDiT: Towards Faster Diffusion Transformers Training without Architecture Modification (https://arxiv.org/abs/2410.10356)
Comments:
          NeurIPS 2024 (poster)

- **What's New**: Diffusion Transformers (DiT)의 훈련 속도를 개선하기 위한 FasterDiT 방법을 제안하며, 이를 위해 Signal-to-Noise Ratio (SNR) 개념을 확장하고 새로운 감독 방법론을 도입하였습니다.

- **Technical Details**: SNR의 정의를 약간 확장하고 이를 기반으로 한 Probability Density Function (PDF)의 시각화를 통해 훈련의 효율성을 분석했습니다. 또한, 다양한 실험을 통해 PDF 관점에서 훈련 성능과 데이터 강인성 간의 관계를 탐구하였습니다. 새로운 감독 방법론을 통해 훈련 프로세스를 가속화하였습니다.

- **Performance Highlights**: FasterDiT는 ImageNet 256 해상도에서 1000k 반복 시 2.30의 FID를 달성하며, 기존 DiT의 FID 2.27 대비 7배 빠른 훈련 속도를 기록했습니다.



### On Representation of 3D Rotation in the Context of Deep Learning (https://arxiv.org/abs/2410.10350)
Comments:
          Accepted at International Conference on Computer Vision and Graphics ICCVG 2024. The proceedings of the conference will be published in Lecture Notes in Networks and Systems (LNNS), Springer

- **What's New**: 이 논문은 3D 회전을 표현하는 다양한 방법과 그 방법이 딥 뉴럴 네트워크의 학습 과정에 미치는 영향을 조사합니다. 저자들은 Synthetic 데이터와 Real 데이터 모두에서 ResNet18 네트워크의 성능을 평가했습니다.

- **Technical Details**: 3D 회전을 표현하는 방법에는 회전 매트릭스, 오일러 각도, 쿼터니온 등이 있습니다. 저자들은 연속적인 5D 및 6D 표현 방식을 통해 성능이 향상된다는 점을 밝혔습니다.

- **Performance Highlights**: 연속적인 표현을 사용하는 네트워크가 불연속적인 표현을 사용하는 네트워크보다 더 정확하고 강인한 성과를 보였으며, 훈련 동작도 더 유리하다는 결과를 도출했습니다.



### Spatial-Aware Efficient Projector for MLLMs via Multi-Layer Feature Aggregation (https://arxiv.org/abs/2410.10319)
Comments:
          10 pages, 3 figures

- **What's New**: 이번 연구에서는 Multi-Modal Language Models (MLLMs)에 중요한 역할을 하는 프로젝트의 개선 사항을 다루고 있으며, 새로운 Spatial-Aware Efficient Projector (SAEP) 방법을 제안합니다.

- **Technical Details**: SAEP 방법은 다층 시각 특성에서 spatial 정보의 향상을 위해 수정된 separable depthwise convolution 모듈을 사용합니다. 이를 통해 2차원 시각 토큰 시퀀스와 자연어 토큰 시퀀스 간의 공간적 불일치를 해결하고자 합니다.

- **Performance Highlights**: SAEP 방법은 기존 방법에 비해 시각 토큰 수를 75%까지 줄일 수 있으며, MLLMs의 멀티모달 공간 이해 능력을 크게 향상시킵니다. 또한, 다양한 멀티모달 평가 벤치마크에서 최고의 성능을 보이며, modality gap을 극복하는 데 효과적임을 입증했습니다.



### QIANets: Quantum-Integrated Adaptive Networks for Reduced Latency and Improved Inference Times in CNN Models (https://arxiv.org/abs/2410.10318)
Comments:
          Accepted to NeurIPS 2024 workshop on Neural Compression

- **What's New**: QIANets는 양자 기반의 가지치기(quantum-inspired pruning), 텐서 분해(tensor decomposition), 및 열 처리 기반의 행렬 분해(annealing-based matrix factorization)를 사용하여 전통적인 CNN 모델 아키텍처를 개선한 새로운 접근법으로, 고속 추론(low latency)과 정확도 유지의 균형을 맞추는 데 초점을 맞추고 있습니다.

- **Technical Details**: 이 방법은 양자 근사 최적화 알고리즘(QAOA)을 이용하여 가지치기를 수행하고, 고차원 텐서를 낮은 차원으로 분해함으로써 컴퓨팅 복잡성을 줄이도록 설계되었습니다. 각 가중치의 중요성을 평가하기 위해 소프트맥스(normalized using softmax) 함수를 사용하여 확률을 도출하고, 이 결과를 기반으로 가지치기를 진행합니다.

- **Performance Highlights**: 실험 결과, QIANets는 추론 시간을 줄이면서도 정확도를 효과적으로 유지함을 입증하였으며, 전통적인 CNN 아키텍처의 구조적 최적화를 통해 무게 감소 및 성능 향상에 기여 할 수 있음을 보여주었습니다.



### GlobalMamba: Global Image Serialization for Vision Mamba (https://arxiv.org/abs/2410.10316)
- **What's New**: 본 논문에서는 이미지의 2D 구조적 상관관계를 고려한 새로운 방법론으로, 글로벌 이미지 시리얼라이제이션(Global Image Serialization)을 제안합니다. 이 방법은 이미지 데이터를 주파수 도메인(Frequency Domain)으로 변환한 후, 픽셀을 주파수 대역에 따라 정리하여 이미지 토큰 전처리를 수행합니다.

- **Technical Details**: 주요 기술로는 이산 코사인 변환(Discrete Cosine Transform, DCT)을 사용하여 이미지를 주파수 도메인으로 변환하는 단계가 포함됩니다. 그 후 동일한 주파수 대역에 있는 픽셀들을 그룹화하여 다시 공간 도메인으로 변환하고, 최종적으로 토큰화 과정을 통해 이미지의 글로벌 정보를 담고 있는 인과적 토큰 시퀀스를 생성합니다.

- **Performance Highlights**: 이미지넷 이미지 분류(Image Classification on ImageNet-1K), 객체 탐지(Object Detection on COCO), 의미론적 분할(Semantic Segmentation on ADE20K)에서의 광범위한 실험을 통해 GlobalMamba의 우수한 성능을 입증했습니다. ImageNet-1K에서 기존 모델 대비 0.6%의 성능 향상을 달성했습니다.



### LG-CAV: Train Any Concept Activation Vector with Language Guidanc (https://arxiv.org/abs/2410.10308)
- **What's New**: 본 연구에서는 Language-Guided CAV (LG-CAV)를 제안하여 사전 훈련된 비전-언어 모델(vision-language models, VL models)에서 풍부한 개념 지식을 활용함으로써 레이블이 없는 데이터를 사용하여 CAV를 훈련할 수 있게 되었습니다. LG-CAV는 모델 수정(model correction) 기술을 통해 Target Model의 성능을 향상시킵니다.

- **Technical Details**: LG-CAV는 VL 모델에서 개념 설명(concept descriptions)을 사용하여 특정 개념에 대한 CAV를 훈련하고, 공통 이미지 풀(probe images)에서 VL 모델의 개념 설명의 활성화 값(activation values)을 추출하여 CAV 훈련에 활용합니다. 이를 위해 Gaussian alignment (GA) 모듈과 개념 앙상블(concept ensemble, CE) 모듈, 편차 샘플 재가중치(deviation sample reweighting, DSR) 모듈을 제안하여 LG-CAV의 품질을 더욱 향상시킵니다.

- **Performance Highlights**: LG-CAV는 Broden 및 ImageNet 데이터셋에서 이전 CAV 방법들에 비해 현저히 높은 CAV 품질(개념 정확도(concept accuracy) 및 개념-클래스 정확도(concept-to-class accuracy))를 달성하며, ImageNet 및 CUB-200-2011, CIFAR-100 데이터셋에서 기존 개념 기반 방법보다 우수한 성능을 보입니다.



### Animate-X: Universal Character Image Animation with Enhanced Motion Representation (https://arxiv.org/abs/2410.10306)
Comments:
          25 pages, 15 figures, conference

- **What's New**: Animate-X라는 새로운 애니메이션 프레임워크를 제안하여 다양한 캐릭터 유형을 애니메이션화하는 능력을 향상시킵니다. 특히 인간 모션을 기반으로 하여 비인간 아바타에도 잘 작동하도록 설계되었습니다.

- **Technical Details**: Animate-X 프레임워크는 LDM(Latent Diffusion Model) 기반으로 개발되었으며, Pose Indicator라는 새로운 구성 요소를 통해 모션 표현력을 개선하였습니다. Implicit Pose Indicator (IPI)와 Explicit Pose Indicator (EPI)를 통해 애니메이션의 동작 패턴을 효과적으로 캡처합니다.

- **Performance Highlights**: 기존 최첨단 방법들과 비교하여 Animate-X는 캐릭터의 정체성 보존과 모션 일관성을 유지하면서 보다 높은 성과를 보여줍니다. 특히 소프트웨어의 성능을 평가하기 위해 500종의 인형 캐릭터와 해당 춤 비디오를 포함한 A²Bench 기준을 새롭게 독립적으로 제안했습니다.



### ROA-BEV: 2D Region-Oriented Attention for BEV-based 3D Objec (https://arxiv.org/abs/2410.10298)
- **What's New**: 이 논문에서는 자율주행에서 인기를 얻고 있는 BEV (Bird-Eye-View) 기반 3D 객체 탐지 기술에 대한 새로운 접근 방식을 제안합니다. 특히, 기존 방법으로는 카메라 관점에서 배경과 유사한 객체를 효과적으로 탐지하지 못하는 문제를 해결하기 위한 방안을 모색합니다.

- **Technical Details**: 새롭게 제안된 2D Region-oriented Attention (ROA)을 사용하여 BEV 기반 3D 객체 탐지 네트워크의 성능을 향상시킵니다. ROA는 객체가 존재할 가능성이 있는 영역에서 특성 학습에 집중하도록 백본(backbone)을 조정합니다. 또한, 멀티 스케일(multi-scale) 구조를 통해 ROA의 정보량을 증가시키며, 각 ROA 블록은 대형 커널(large kernel)을 사용하여 수용 필드(receptive field)를 크게 확보하여 대형 객체의 정보를 효과적으로 포착할 수 있도록 합니다.

- **Performance Highlights**: nuScenes 데이터셋에 대한 실험 결과, ROA-BEV는 기존의 BEVDet 및 BEVDepth 모델에 비해 개선된 성능을 보였습니다. 코드는 곧 공개될 예정입니다.



### A Consistency-Aware Spot-Guided Transformer for Versatile and Hierarchical Point Cloud Registration (https://arxiv.org/abs/2410.10295)
Comments:
          Accepted by NeurIPS 2024 as poster

- **What's New**: 본 연구에서는 기존의 조잡한 매칭 방법의 문제를 해결하기 위해 일관성 인지 스팟 가이드 Transformer (CAST)를 설계했습니다. 이 모델은 불필요한 영역과의 간섭을 피하기 위해 스팟 가이드 크로스-어텐션 모듈을 통합하고, 기하학적으로 일관된 대응을 강화하기 위해 일관성 인지 자기-어텐션 모듈을 추가했습니다.

- **Technical Details**: CAST는 스팟 가이드 크로스-어텐션과 일관성 인지 자기-어텐션 모듈을 활용하여 매칭 능력을 향상시키며, 경량화된 세밀한 매칭 모듈을 통해 희소한 키포인트와 밀집한 특징 모두에 대해 정확한 변환 추정을 가능하게 합니다. 이 방법은 최적 수송 기반 알고리즘을 사용하지 않고 효율적인 희소-밀집 매칭 파이프라인을 통해 실시간 애플리케이션에 적합합니다.

- **Performance Highlights**: 실외 LiDAR 및 실내 RGBD 포인트 클라우드 데이터셋에서의 광범위한 실험 결과, CAST는 최신 기술을 초월하는 정확도, 효율성 및 강인성을 달성하며, 특히 로봇의 주행거리 측정(odometry)과 같은 실시간 대규모 응용 프로그램에 대해 효율적으로 작동합니다.



New uploads on arXiv(cs.AI)

### MCSFF: Multi-modal Consistency and Specificity Fusion Framework for Entity Alignmen (https://arxiv.org/abs/2410.14584)
Comments:
          6 pages, 1 figures

- **What's New**: 이번 연구에서는 Multi-modal Consistency and Specificity Fusion Framework (MCSFF)를 제안하였습니다. 기존의 방법들이 각 모달리티의 특수성을 간과한 반면, 본 프레임워크는 모달리티의 일관성과 특수성을 모두 통합하여 더 높은 정확도의 엔티티 정렬을 목표로 하고 있습니다.

- **Technical Details**: MCSFF는 모달리티 임베딩을 통해 각 모달리티의 유사성 매트릭스를 계산하고, 반복 업데이트 방식을 통해 노이즈를 제거하고 모달리티 특성을 향상시킵니다. 최종적으로 모든 모달리티에서 업데이트된 정보를 통합하여 풍부하고 정확한 엔티티 표현을 생성합니다.

- **Performance Highlights**: MCSFF는 MMKG 데이터셋에서 현재 최고 성능의 MMEA 기준 방법들을 초과하는 결과를 보여, 본 방법의 효과성과 실제 활용 가능성을 입증하였습니다.



### TransBox: EL++-closed Ontology Embedding (https://arxiv.org/abs/2410.14571)
- **What's New**: 이 논문은 EL++-closed ontology embedding을 제안하며, 복잡한 논리 표현을 효과적으로 표현할 수 있는 방법을 제시합니다. 특히, TransBox라는 새로운 접근 방식을 개발하여 다양한 관계를 처리하는 능력을 향상시킵니다.

- **Technical Details**: EL++-closed ontology embeddings는 Description Logic (DL) 내의 모든 논리 연산을 효과적으로 캡처할 수 있도록 설계되었습니다. TransBox는 다대일, 일대다 및 다대다 관계를 처리할 수 있는 진보된 embedding 방법입니다. 기존 방법들의 한계점을 극복하여, 복잡한 axioms 예측 작업을 수행할 수 있습니다.

- **Performance Highlights**: TransBox는 다양한 실제 데이터셋에서 복잡한 axioms 예측 문제에 대해 최첨단 성능을 자주 달성함으로써 기존 방법들을 능가함을 보여주었습니다.



### Computational Grounding of Responsibility Attribution and Anticipation in LTLf (https://arxiv.org/abs/2410.14544)
- **What's New**: 이 논문은 기계 윤리와 자율 시스템 영역에서 중요한 개념인 책임(responsibility)의 다양한 변형을 LTLf(Linear Temporal Logic on finite traces)를 기반으로 연구합니다. 또한, 책임을 수치화하고 예치하는 알고리즘을 개발하여 책임의 개념을 계산적으로 뒷받침합니다.

- **Technical Details**: 저자들은 전략적 책임의 복잡성(complexity)을 분석하고, 책임의 귀속(attribution)과 예측(anticipation)에 대한 다양한 알고리즘을 제시합니다. 특히, 지배(dominance)와 최선의 노력(best-effort) 이론과의 연계를 통해 기존의 전략 합성(strategy synthesis) 연구와 책임 이론을 통합하는 방법을 탐구합니다.

- **Performance Highlights**: 제안된 алгоритм들은 책임 추론을 자동화하며, 최악의 경우(computational complexity)에도 효율적입니다. 이러한 결과는 시간적 사양(temporal specifications)에 기반한 포괄적인 책임 분석의 새로운 계산적 기초를 제공합니다.



### Interpretable end-to-end Neurosymbolic Reinforcement Learning agents (https://arxiv.org/abs/2410.14371)
Comments:
          19 pages; 5 figures; 3 tables

- **What's New**: 이 논문에서는 Deep Reinforcement Learning(RL) 에이전트가 일반화에 실패하는 문제를 해결하기 위해, 객체 중심 상태(object-centric states)를 사용하는 기호 기반 방법(symbolic method)을 도입합니다. 특히 SCoBots 프레임워크를 통해 RL 작업을 해석 가능한 중간 표현으로 분해하는 접근을 소개합니다.

- **Technical Details**: SCoBots 프레임워크는 RL 문제를 개념 병목 모델(concept bottleneck models)을 사용하여 중간 해석 가능한 표현으로 분해합니다. 이 아키텍처는 객체 중심의 관계 개념에 기반한 행동 결정을 가능하게 하여 에이전트의 결정 과정을 명확히 합니다.

- **Performance Highlights**: Atari 게임에서의 실험 결과에 따르면, SCoBots는 해석 가능하고 성능이 뛰어난 RL 시스템을 창출할 수 있는 잠재력을 가지며, 향후 해석 가능한 end-to-end RL 에이전트 연구의 방향성을 제시합니다.



### CoMAL: Collaborative Multi-Agent Large Language Models for Mixed-Autonomy Traffic (https://arxiv.org/abs/2410.14368)
- **What's New**: 이번 연구에서는 CoMAL(협업 다중 에이전트 LLM)을 소개하며, 이는 자율 주행 차량이 혼합 자율 교통 문제를 해결하기 위해 협력할 수 있도록 설계된 프레임워크입니다.

- **Technical Details**: CoMAL은 대형 언어 모델(LLM)을 기반으로 하며, 인식 모듈과 기억 모듈을 사용하여 주변 에이전트를 관찰하고 전략을 저장합니다. 또한, 협업 모듈과 추론 엔진, 실행 모듈로 구성되어 차량의 행동을 제어합니다.

- **Performance Highlights**: CoMAL은 Flow 벤치마크에서 우수한 성능을 달성하였으며, 다양한 LLM에 대한 실험을 통해 평균 속도와 운전의 부드러움에서 유의미한 성과를 나타냈습니다.



### Formal Explanations for Neuro-Symbolic AI (https://arxiv.org/abs/2410.14219)
- **What's New**: 이 논문은 neuro-symbolic AI의 결정 과정을 공식적으로 설명하는 방법을 제안합니다. 특히, 신경망(neural)과 상징(symbolic) 구성 요소의 상호작용에서 발생하는 설명 가능성 문제를 계층적으로 해결하기 위해 formal abductive explanations를 활용하는 접근 방식을 설명합니다.

- **Technical Details**: 제안된 접근 방식은 시스템의 상징적 구성 요소에 대한 형식적 설명을 계산하여, 다음으로 신경 입력을 각각 독립적으로 설명하는 방식으로 진행됩니다. 이 과정은 신경-상징 시스템의 복잡한 결정이 어떻게 이루어졌는지를 명확하게 드러내고, 설명의 크기 및 품질 측면에서 순수 신경 시스템에 비해 개선된 결과를 보여줍니다.

- **Performance Highlights**: 실험 결과, 제안된 접근 방식은 설명 크기, 설명 시간, 훈련 시간, 모델 크기 및 설명 품질 등 여러 복잡한 추론 과제에서 효율성을 입증했습니다. 이는 다음 세대 neuro-symbolic AI 개발의 추가 동기를 제공합니다.



### CausalChat: Interactive Causal Model Development and Refinement Using Large Language Models (https://arxiv.org/abs/2410.14146)
- **What's New**: 이 논문은 인간 집단의 참여를 통해 인과 네트워크를 구성하려는 기존의 접근방식과는 다른 방법으로, OpenAI의 GPT-4와 같은 대형 언어 모델(LLM)의 인과 지식을 활용하여 인과 네트워크를 개발한다.

- **Technical Details**: 이 연구는 사용자들이 CausalChat이라는 독특한 시각 분석 인터페이스를 통해 단일 변수 또는 변수 쌍을 탐색하고, 인과관계(latent variables, confounders, mediators)를 확인하도록 돕는다. 각 탐색은 맞춤형 GPT-4 프롬프트로 변환되고, 시각적 표현과 연결되어 설명이 전달된다.

- **Performance Highlights**: CausalChat의 기능은 다양한 데이터 맥락에서 입증되었으며, 전문가와 일반인을 대상으로 한 사용자 연구를 통해 그 유용성이 검증되었다.



### Goal Inference from Open-Ended Dialog (https://arxiv.org/abs/2410.13957)
Comments:
          6 pages + 2 page (references and appendix)

- **What's New**: 최근 연구에서는 에이전트가 다양한 사용자 목표를 학습하고 수행할 수 있는 온라인 방법인 GOOD(Goals fOr Open-ended Dialogue)를 제안하였습니다. 이 방법은 대화에서 자연어 목표 표현을 추출하고, 대화가 진행됨에 따라 Bayes 추론(Bayesian inference)을 통해 그 가능성을 추적하는 방식입니다. 또한, 이 방법은 데이터 효율성을 가지면서도 복잡한 목표에 대한 불확실성을 표현할 수 있습니다.

- **Technical Details**: GOOD는 Large Language Models(LLMs)를 활용하여 사용자 목표를 자연어로 표현합니다. 목표 집합을 유지하기 위해 LLM 모듈을 사용하고, 대화에서 발생하는 각 목표에 대한 확률을 추정합니다. 또, 목표 관리 시스템을 설계하여 명시적인 목표 목록을 통해 Bayes 추론을 수행합니다. 이를 통해 다양한 사용자 목표에 대한 추적이 가능합니다.

- **Performance Highlights**: 실험 결과, GOOD는 식료품 쇼핑 및 가정 로봇 지원 분야에서 다른 방법들보다 우수한 성능을 보였습니다. 특히 목표 표현이 명시적이고 확률적 추론이 가능하여 유연한 에이전트 조정에 긍정적인 영향이 있음을 보여주었습니다.



### The KnowWhereGraph Ontology (https://arxiv.org/abs/2410.13948)
- **What's New**: KnowWhereGraph는 30개 레이어의 지리적 지식 그래프를 포함하며, 자연 재해, 기후 변수, 토양 특성, 인구 통계 및 건강 데이터 등을 포함합니다. 이 시스템은 식량 안전 및 농업 공급망 문제를 해결하기 위해 활용되고 있습니다.

- **Technical Details**: 이 논문은 KnowWhereGraph의 스키마 역할을 하는 온톨로지 개발 방식을 소개합니다. 온톨로지는 Modular Ontology Modeling (MOMo) 기법을 통해 생성되었으며, 데이터를 시공간적으로 통합할 수 있는 방법을 제공합니다.

- **Performance Highlights**: KnowWhereGraph는 미국 및 국제적으로 긴급 인도적 원조 제공, 농업 지속 가능성 및 토양 보존 실천 관련 정책 문제에 대한 의사 결정 지원을 통해 28억 개의 트리플을 실현합니다.



### BiGR: Harnessing Binary Latent Codes for Image Generation and Improved Visual Representation Capabilities (https://arxiv.org/abs/2410.14672)
Comments:
          Project page: this https URL

- **What's New**: 새로운 BiGR 모델은 조건부 이미지 생성(conditional image generation)을 위한 방식으로, 효율적인 이미지 생성을 지원하는 혁신적인 엔트로피 순서 샘플링(entropy-ordered sampling) 방법을 도입했습니다. 이 모델은 생성(generation)과 판별(discrimination) 작업을 통합하여 동일한 프레임워크 내에서 처리합니다.

- **Technical Details**: BiGR 모델은 바이너리 토크나이저(binary tokenizer), 마스킹 모델링(masked modeling) 메커니즘, 바이너리 트랜스코더(binary transcoder)를 사용하여 바이너리 코드 예측을 수행합니다. 이러한 설계는 생성 및 표현 성능을 동시에 향상시키는 데 중점을 둡니다.

- **Performance Highlights**: 광범위한 실험을 통해 BiGR은 FID-50k를 기준으로 한 생성 품질에서 우수한 성능을 보이며, 선형 프로브(linear-probe) 정확도를 통해 표현 능력에서도 성과를 입증했습니다. 또한, BiGR은 여러 비전 작업에서 제로샷 제너럴리제이션(zero-shot generalization) 기능을 보여주어, 구조적 수정 없이 이미지 인페인팅(image inpainting), 아웃페인팅(outpainting), 편집(editing), 보간(interpolation), 보강(enrichment) 등 다양한 응용이 가능합니다.



### Online Reinforcement Learning with Passive Memory (https://arxiv.org/abs/2410.14665)
- **What's New**: 이 논문에서는 환경으로부터 수집된 데이터를 활용하여 온라인 상에서 상호작용하는 강화 학습(online reinforcement learning) 알고리즘을 제안합니다. 수동 메모리(passive memory)를 이용함으로써 성능이 향상된다는 이론적 증거를 제공합니다.

- **Technical Details**: 제안된 접근 방식은 강화 학습의 정규화된 선형 프로그래밍(regularized linear programming, LP) 형식을 기반으로 하며, 이를 통해 온라인 RL의 성능을 개선하는 방법을 다룹니다. 또한, 우리의 알고리즘은 최대 최소 최적화(near-minimax optimality) 보장을 제공하며, 연속 및 이산 상태-행동 공간 모두에 일반화될 수 있습니다.

- **Performance Highlights**: 본 논문의 실험 결과는, 수동 메모리의 품질이 발생하는 후회(regret)의 최적성을 결정짓는다는 것을 보여줍니다. 제안된 알고리즘은 유한 샘플(finite-sample) 이론적 보장을 제공하며 이는 실제 환경에서의 유용성을 높입니다.



### On the Regularization of Learnable Embeddings for Time Series Processing (https://arxiv.org/abs/2410.14630)
- **What's New**: 본 논문은 시계열 데이터 처리에 있어 개별 시퀀스의 특성(특징)을 고려하는 것이 도전적이라는 문제를 다루고 있습니다. 현대의 딥러닝 기법들은 공유 모델을 지역적인(로컬) 레이어와 결합하여 각 시계열에 맞춘 학습 가능한 임베딩(embeddings)으로 구현합니다. 하지만 이러한 로컬 임베딩이 단순한 시퀀스 식별자로 작용될 수 있는 문제에 대해 규제를 통해 로컬 임베딩 학습 과정 개선 방법을 제시합니다.

- **Technical Details**: 이 논문은 로컬 학습 가능한 임베딩의 규제를 위한 다양한 전략들을 조사하며, weight penalties와 dropout 같은 기본적인 방법부터 클러스터링(clustering)과 변분 정규화(variational regularization)와 같은 고급 방법까지 폭넓은 실험을 수행했습니다. 또한, 글로벌과 로컬 파라미터 간의 공조화(co-adaptation)를 방지하는 방법들이 특히 효과적이라는 점이 강조되며, 이는 새로운 정규화 전략 설계의 기초로 활용될 수 있습니다.

- **Performance Highlights**: 연구 결과, 관련이 있는 모든 아키텍처에서 로컬 임베딩의 규제가 성능 향상에 기여하는 경향을 보였습니다. 글로벌과 로컬 파라미터 간의 공조화를 방지하는 정규화 전략이 특히 성과를 높이는 데 기여한다는 점이 확인되었습니다. 또한, 로컬 학습 가능한 임베딩의 정규화가 현대 시계열 처리 모델의 중요한 요소로, 적은 계산 비용으로도 성능 향상을 가져올 수 있다는 사실을 제시하고 있습니다.



### Benchmarking Deep Reinforcement Learning for Navigation in Denied Sensor Environments (https://arxiv.org/abs/2410.14616)
Comments:
          31 pages, 19 figures. For associated code, see this https URL

- **What's New**: 이 논문은 자율 내비게이션 문제를 다루며, 센서 결함이 심화된 실제 환경에서 Deep Reinforcement Learning (DRL) 알고리즘의 성능을 평가합니다. 특히, DreamerV3가 다른 방법들에 비해 뛰어난 성과를 보여주는 반면, 일반적인 DRL 방법들은 센서 결함을 가진 환경에서 효율적으로 학습하지 못함을 보입니다.

- **Technical Details**: 이 연구는 TD3, PPO, PPO-LSTM, DreamerV3와 같은 여러 DRL 구조를 비교하여, 카메라 또는 Lidar를 관찰 공간으로 사용할 때의 성능 영향을 분석합니다. 특히, ROS 기반의 gymnasium 환경인 DRL-Robot-Navigation을 이용하여 다양한 노이즈를 적용한 환경에서 정책을 훈련하고 평가합니다.

- **Performance Highlights**: DreamerV3는 동적 목표를 가진 시각적 내비게이션 작업에서 다른 방법들보다 우수한 성능을 보이며, 센서 결함이 발생하는 환경에서도 일반적으로 더 높은 성능을 나타냅니다. 적대적 훈련을 통해 센서 결함 환경에서 성능을 개선하면서도 일반 환경에서는 성능이 저하되는 경향이 있음을 보입니다.



### Asymptotically Optimal Change Detection for Unnormalized Pre- and Post-Change Distributions (https://arxiv.org/abs/2410.14615)
- **What's New**: 이 논문은 표준화되지 않은 변화 전후 분포만을 사용할 수 있을 때 변화 감지 문제를 다룹니다. 이를 위해 저자는 새로운 알고리즘인 Log-Partition Approximation Cumulative Sum (LPA-CUSUM)를 제안하였으며, 이는 열역학적 적분을 포함하여 최적 성능을 보장합니다.

- **Technical Details**: LPA-CUSUM 알고리즘은 Cumulative Sum (CUSUM) 통계량을 기반으로 하며, 새로운 표준화 상수의 로그 비율을 추정하기 위해 열역학적 적분 (Thermodynamic Integration, TI)을 사용합니다. 이 방법은 편향 없는 추정기를 제공하며, 상위 성능 특성을 증명합니다. 또한, TI를 위한 필요한 샘플 수와 지연 성능 간의 관계를 도출하여 실용적인 매개 변수 선택 가이드를 제공합니다.

- **Performance Highlights**: LPA-CUSUM 알고리즘은 복잡한 분포 변화 감지에서 효과적임을 수치적으로 입증하였습니다. 이 알고리즘은 기초 데이터를 통해 비정상적인 변화들을 정밀하게 탐지할 수 있으며, 기존의 CUSUM 알고리즘에 비해 성능 저하 없이 실행 가능합니다.



### Streaming Deep Reinforcement Learning Finally Works (https://arxiv.org/abs/2410.14606)
- **What's New**: 이 논문은 'stream-x' 알고리즘을 소개하며, 이는 깊이 있는 RL(Deep Reinforcement Learning) 분야에서 스트리밍 학습(streaming learning)의 장애물인 'stream barrier'를 극복하는 첫 번째 알고리즘 클래스입니다. 이 알고리즘은 Q-learning 및 Actor-Critic과 같은 전통적인 RL 기법의 효율성을 유지하면서도, 최근의 샘플만을 활용하여 스토리지(resource)나 통신에 대한 제한이 있는 환경에서도 작동합니다.

- **Technical Details**: stream-x 알고리즘은 eligibility traces를 이용하여 학습을 수행하고, 기존의 replay buffer나 배치 업데이트(batch update)를 사용하지 않고도 안정적이고 샘플 효율적인 학습을 가능하게 합니다. 이 알고리즘은 MuJoCo Gym, DM Control Suite, Atari 게임과 같이 다양한 환경에서 실험을 통해 효과성을 입증하였습니다. 특히, stream Q, stream AC, stream TD가 있으며, 모두 동일한 하이퍼파라미터 세트를 사용합니다.

- **Performance Highlights**: 실험 결과, stream-x 알고리즘은 DM Control Dog 환경에서 최고의 모델-프리(model-free) 성능을 달성하며, 기존의 스트리밍 방법으로는 도달할 수 없었던 성과를 보였습니다. 이는 깊이 있는 RL 분야에 스트리밍 학습이 본격적으로 적용될 가능성을 제시합니다.



### How Does Data Diversity Shape the Weight Landscape of Neural Networks? (https://arxiv.org/abs/2410.14602)
- **What's New**: 이번 연구는 딥 뉴럴 네트워크(DNN)에서 과적합(overfitting)을 방지하기 위한 다양한 정규화(regularization) 기술이 가중치(weight) 공간에 미치는 영향을 분석합니다. 데이터 다양성(data diversity)과 관련하여, 실제 데이터와 생성 모델(generative models)에서 생성된 합성 데이터(synthetic data)의 효과를 비교합니다.

- **Technical Details**: 본 논문에서는 Random Matrix Theory(RMT)를 활용하여 다양한 데이터 다양성 수준을 가진 정규화 기법의 영향을 분석합니다. 데이터 증강(data augmentation), 드롭아웃(dropout), 가중치 감쇠(weight decay)를 적용한 모델의 가중치 행렬(weight matrices)의 변화를 연구합니다. 또한 Vendi Score를 통해 기계 학습 데이터의 다양성을 측정합니다.

- **Performance Highlights**: 연구 결과, 합성 데이터는 실제 입력 데이터의 다양성을 증대시켜 배포 밖(out-of-distribution) 테스트 인스턴스에서 더 나은 성능 개선을 가져올 수 있음이 나타났습니다. 다양한 데이터가 모델의 가중치 풍경(weight landscape)에 미치는 영향은 드롭아웃의 영향과 유사하다는 것이 관찰되었습니다.



### Temporal Fair Division of Indivisible Items (https://arxiv.org/abs/2410.14593)
- **What's New**: 본 논문은 순차적으로 도착하는 indivisible item(분리할 수 없는 아이템)을 즉시 할당해야 하는 공정한 분배 모델을 연구합니다. 특히, 템포럴 엔비-프리넘(temporal envy-freeness)에 대한 정의를 부여하고, 알고리즘이 미래 아이템에 대한 완전한 지식을 가졌을 때의 경우를 다룹니다. 이를 통해 TEF1(temporal envy-freeness up to one item)을 만족하는 할당이 존재하는 경우와 그 계산 가능성 및 다항 시간 알고리즘을 제시합니다.

- **Technical Details**: 1. TEF1 속성을 만족하는 할당은 존재할 수 있으며, 두 명의 에이전트, 두 종류의 아이템, 일반화된 이진 가치 평가 및 단봉 선호와 같은 특별한 경우에 대해 다항 시간 알고리즘을 제공합니다. 2. 수수께끼의 NP-난이도(NP-hard)의 결과를 증명합니다.

- **Performance Highlights**: Goods의 경우, 단순히 무작위로 할당하는 것이 심각한 envy를 일으킬 수 있음을 보여줍니다. Chores의 경우에도 유사한 결과를 수립하였지만, 약간의 더 약한 비가역성 결과를 제시합니다.



### Neural Combinatorial Clustered Bandits for Recommendation Systems (https://arxiv.org/abs/2410.14586)
- **What's New**: 이 논문은 컨텍스트 기반 조합형 밴딧(contextual combinatorial bandit) 설정을 연구하며, 딥 뉴럴 네트워크를 통해 발견할 수 없는 보상 함수를 학습하고 추정하는 Neural UCB Clustering(NeUClust) 알고리즘을 제안합니다. 이 방법은 추천 문제의 구조를 활용하여 각 라운드에서 슈퍼 암(super arm)을 선택하는 클러스터링 접근법을 채택합니다.

- **Technical Details**: NeUClust는 기존 조합형 밴딧 모델이 필요로 하는 정확한 오라클(oracle) 없이도 슈퍼 암 보상을 추정하고 선택할 수 있도록 설계되었습니다. 이는 신경망을 활용하여 베이스 암(base arm)과 슈퍼 암 보상 함수를 동시에 학습할 수 있게 합니다. 제안된 알고리즘은 O~(d~sqrt{T})의 레그렛(regret) 경계를 만족합니다.

- **Performance Highlights**: 실제 추천 데이터셋(MovieLens, Yelp)에서 NeUClust는 기존의 상태-최첨단(neural contextual/combinatorial) 및 CC-MAB 알고리즘들보다 더 나은 레그렛과 보상 값을 기록했습니다.



### Towards Unsupervised Validation of Anomaly-Detection Models (https://arxiv.org/abs/2410.14579)
- **What's New**: 본 논문은 라벨이 없는 데이터셋에서 자동화된 이상 탐지 모델을 검증하는 새로운 패러다임을 제시합니다. 이는 실세계의 협업 의사결정 메커니즘에 영감을 얻어 이상 탐지 모델의 검증 및 평가에서 라벨 없는 조건을 충족하는 방법을 모색합니다.

- **Technical Details**: 우리는 2가지 일반적인 비지도 모델 검증 작업인 모델 선택(model selection)과 모델 평가(model evaluation)를 집중적으로 다루며, 새로운 ‘Accurately-Diverse ensemble’을 제시합니다. 이 앙상블은 모델의 예측 일반 추세에 대한 강한 내부 앙상블 동의(intra-ensemble agreement)를 요구하면서, 각 모델 예측의 정확한 순서에 대한 강한 내부 앙상블 불일치(intra-ensemble disagreement)를 촉진합니다.

- **Performance Highlights**: 우리의 실험 결과는 10개의 공개 데이터 세트를 활용하여 ‘Accurately-Diverse ensemble’이 평균 비지도 이상 탐지 모델보다 더 나은 결과를 산출하며, 비지도 평가 메트릭이 지도 평가 메트릭과 동등한 성능을 발휘한다는 것을 보여줍니다.



### Building Trust in Black-box Optimization: A Comprehensive Framework for Explainability (https://arxiv.org/abs/2410.14573)
- **What's New**: 본 논문에서는 Surrogate Optimization (SO)의 설명 가능성과 신뢰성을 높이기 위한 포괄적인 메트릭 세트인 
Inclusive Explainability Metrics for Surrogate Optimization (IEMSO)를 제안합니다. 이는 모델에 구애받지 않으며, SO 접근 방식의 투명성과 설명 가능성을 향상시키기 위해 설계되었습니다.

- **Technical Details**: 제안된 메트릭은 1) Sampling Core Metrics, 2) Batch Properties Metrics, 3) Optimization Process Metrics, 4) Feature Importance Metrics 의 네 가지 주요 카테고리로 분류됩니다. 각각은 SO 프로세스의 특정 측면을 겨냥하여 설명의 투명성을 제공합니다.

- **Performance Highlights**: 실험 결과, 제안된 메트릭은 다양한 벤치마크에서 SO의 성능을 향상시킬 수 있는 잠재력을 보여주었습니다. 이러한 메트릭을 통해 사용자들은 비싼 평가를 수행하기 전후에 중간 및 사후 설명을 받을 수 있어 신뢰를 구축할 수 있습니다.



### When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs (https://arxiv.org/abs/2410.14569)
- **What's New**: 본 연구는 LLM 에이전트의 오남용 위험성을 탐구하고 개인 정보 관련 사이버 공격에 대한 효과를 분석합니다. 특히, 웹 기반 도구를 통해 강화된 LLM 에이전트의 사이버 공격 능력을 심층적으로 살펴봅니다.

- **Technical Details**: 이 연구는 세 가지 주요 사이버 공격 시나리오(개인 식별 가능 정보 수집, 사칭 게시물 생성, 스피어 피싱 이메일 생성)를 살펴보고, LLM 에이전트가 생성한 정보의 정확도, 진정성, 클릭률 등을 평가합니다. LLM 에이전트는 개인 정보 수집에서 95.9%의 정밀도를 달성하고, 생성한 사칭 게시물의 93.9%가 진정하다고 평가되었으며, 스피어 피싱 이메일의 클릭률은 46.67%에 달합니다.

- **Performance Highlights**: LLM 에이전트를 사용한 사이버 공격은 웹 기반 도구를 이용함으로써 한층 더 효율적으로 작동되며, 비용과 시간 측면에서 상대적으로 접근성이 높습니다. GPT LLM 에이전트는 평균적으로 10초 내에 각 작업을 수행하며, 비용은 약 2센트입니다. 기존 LLM의 안전장치는 특정 상황에서만 활성화되어 기능하는 경향이 있어, 이는 보안 측면에서 심각한 문제를 드러냅니다.



### Boosting K-means for Big Data by Fusing Data Streaming with Global Optimization (https://arxiv.org/abs/2410.14548)
- **What's New**: 이 논문에서는 대량 데이터 집합에서 K-means 군집화의 효율성을 개선하기 위한 새로운 휴리스틱 알고리즘인 BigVNSClust를 제안합니다. 이는 Variable Neighborhood Search (VNS) 메타휴리스틱을 활용하여 대규모 데이터셋에 최적화된 K-means 군집화를 수행하는 방안을 제시합니다.

- **Technical Details**: BigVNSClust 알고리즘은 두 가지 모드를 동시에 탐색합니다: (1) 원본 데이터셋에서 추출한 무작위 샘플로부터 발생시킨 부분 솔루션 랜드스케이프를 탐색하고, (2) 이들 랜드스케이프 내에서 현재 최고 해(solution)의 이웃을 확장하여 탐색합니다. 알고리즘은 각 반복에서 축퇴된 클러스터(degenerate clusters)와 p개의 무작위 중심점을 K-means++를 사용하여 재초기화합니다.

- **Performance Highlights**: Extensive experimentation reveals that BigVNSClust significantly outperforms existing state-of-the-art methods, 특히 Big-means에 비해 높은 정확도와 효율성을 달성했습니다. 이는 MSSC 군집화 알고리즘 내에서 새로운 최첨단 성능을 나타냅니다.



### Less is More: Selective Reduction of CT Data for Self-Supervised Pre-Training of Deep Learning Models with Contrastive Learning Improves Downstream Classification Performanc (https://arxiv.org/abs/2410.14524)
Comments:
          Published in Computers in Biology and Medicine

- **What's New**: 이 논문은 의료 이미지를 위한 대조 학습 (contrastive learning) 기반의 자기 지도 (self-supervised) 사전 학습에서 데이터셋의 중복을 줄이는 다양한 전략을 조사합니다.

- **Technical Details**: 대조 학습을 사용하여 CT 이미지의 낮은 분산(variance)을 극복하기 위해 정보 이론 (information theory), 딥 임베딩 (deep embedding), 해싱 (hashing) 기반의 접근법을 통해 데이터셋에서 중복을 식별하고 감소시키는 방법을 사용합니다.

- **Performance Highlights**: 데이터셋 감소로 인해 COVID CT 분류 대회에서 AUC 점수가 0.78에서 0.83으로 향상되었고, OrganSMNIST 분류 대회에서는 0.97에서 0.98로, 뇌 출혈 분류 작업에서는 0.73에서 0.83로 개선되었습니다. 또한, 사전 학습이 데이터셋 감소 덕분에 최대 아홉 배 더 빨라졌습니다.



### Efficient Annotator Reliability Assessment and Sample Weighting for Knowledge-Based Misinformation Detection on Social Media (https://arxiv.org/abs/2410.14515)
Comments:
          8 pages, 3 figures, 3 tables. Code available here: this https URL

- **What's New**: 이번 연구는 효율적인 주석자 신뢰도 평가(Efficiency Annotator Reliability Assessment, EffiARA) 프레임워크를 도입하여 주석자의 신뢰도를 측정하고, 이를 바탕으로 대규모 언어 모델의 분류 성능을 향상시키는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 연구는 Russo-Ukrainian Conflict Knowledge-Based Misinformation Classification Dataset (RUC-MCD)을 생성하여, 주석자 간 및 주석자 내부 동의를 기반으로 한 샘플 가중화를 적용하고, 이는 모델 훈련에서 샘플의 중요도를 조정합니다. 주석자의 신뢰도는 크로스 엔트로피 손실 함수에 통합되어 모델의 학습 성능을 개선합니다. 또한, Llama-3.2-1B와 TwHIN-BERT-large 모델을 사용하여 새로운 기준 성능을 제시합니다.

- **Performance Highlights**: Llama-3.2-1B 모델을 이용한 최고 분류 성능은 0.757의 macro-F1 점수를 기록하였으며, TwHIN-BERT-large 모델 사용 시 0.740의 성능을 달성하였습니다.



### LEAD: Latent Realignment for Human Motion Diffusion (https://arxiv.org/abs/2410.14508)
- **What's New**: 이 연구에서 제안하는 LEAD 모델은 latent diffusion을 기반으로 하는 텍스트-모션 (text-to-motion) 생성 모델로, 기존 모델들이 가지고 있는 의미 구조의 결여를 보완하고자 한다.

- **Technical Details**: LEAD는 motion VAE의 원래 latent 공간을 언어 모델인 CLIP과 더 잘 일치하도록 재조정하는 projector 모듈을 적용하여 새로운 의미 구조를 갖춘 latent 공간을 형성한다. 이를 통해 motion textual inversion이라는 새로운 작업을 제안하며, 사전 훈련된 언어 모델의 latent 공간에서 예시 동작의 특성을 가장 잘 캡처하는 임베딩을 찾는 방식으로 동작한다.

- **Performance Highlights**: LEAD는 HumanML3D와 KIT-ML 데이터셋에서 텍스트-모션 생성을 수행한 결과, 기존의 최첨단 모델들과 비슷한 성능을 보여주었으며, 특히 텍스트로부터 개인화된 동작 생성을 위한 작업에서 더욱 개선된 질적 및 양적 결과를 보였다.



### ANT: Adaptive Noise Schedule for Time Series Diffusion Models (https://arxiv.org/abs/2410.14488)
Comments:
          NeurIPS 2024

- **What's New**: 이 논문은 시계열(time series, TS) 도메인에서의 생성 인공지능을 위한 새로운 접근 방식을 소개합니다. 특히, Adaptive Noise schedule for Time series diffusion models (ANT)를 제안하여, TS 데이터의 비정상성(non-stationarity)을 기반으로 적절한 노이즈 스케줄을 자동으로 결정하는 방법을 설명하고 있습니다.

- **Technical Details**: ANT 방법은 다음 세 가지를 충족하는 최적의 노이즈 스케줄을 제공합니다: 1) 시계열 데이터의 비정상성을 선형적으로 감소시켜 모든 확산 단계가 의미 있게 작용하도록 하고, 2) 최종 단계에서 데이터가 랜덤 노이즈로 변형되며, 3) 단계 수가 충분히 많아야 합니다. 이 방법은 사전 처리에서 데이터를 통계적으로 분석하여 최적의 노이즈 스케줄을 찾아야 하는 필요성을 줄여줍니다.

- **Performance Highlights**: ANT 방식의 효율성을 시계열 예측(forecasting), 정제(refinement), 생성(generation) 등의 다양한 작업에서 검증하였으며, 다양한 도메인에서 수집된 데이터셋을 활용하였습니다. 이 연구는 파라미터 조정 없이도 좋은 성과를 보여줍니다.



### Transfer Reinforcement Learning in Heterogeneous Action Spaces using Subgoal Mapping (https://arxiv.org/abs/2410.14484)
- **What's New**: 이 논문에서는 서로 다른 action space를 가진 에이전트들 간의 transfer reinforcement learning 문제를 고려합니다. 특히, 새로운 작업에 대해 전문가 에이전트의 demonstration을 사용하여 학습 에이전트가 최적의 정책을 적은 샘플로 학습할 수 있는 방법을 제안합니다.

- **Technical Details**: 전문가 에이전트와 학습 에이전트 간의 subgoal mapping을 학습합니다. Long Short Term Memory (LSTM) 네트워크를 훈련하여 이 mapping을 얻고, unseen tasks에 대해 학습 에이전트의 subgoal sequence를 예측합니다. 이때, 예측된 subgoal sequence를 사용하여 학습 에이전트의 고수준 정책을 초기화함으로써 학습 속도를 개선합니다.

- **Performance Highlights**: 제안된 방법은 numerical experiments를 통해 효과적으로 subgoal mapping을 찾아내며, 학습 에이전트가 전문가 에이전트의 정책을 모사하도록 하면 unseen new tasks에서 샘플 효율성과 학습 시간을 크게 향상시키는 것으로 나타났습니다.



### DRL Optimization Trajectory Generation via Wireless Network Intent-Guided Diffusion Models for Optimizing Resource Allocation (https://arxiv.org/abs/2410.14481)
- **What's New**:  이 논문은 wireless communication 시스템을 위한 WNI(guided Network Intent) 주도 궤적 생성 모델을 제안합니다. 이 모델은 Generative Diffusion Model(GDM)을 바탕으로 하여, 동적인 환경 변화에 적응할 수 있는 최적화 전략을 제공합니다.

- **Technical Details**:  제안된 모델은 cross-attention과 GDM 융합 기반의 WNI 주도 최적화 네트워크로, channel condition, application requirements, optimization goals 등의 요소를 고려하여 자원 할당 최적화를 진행합니다. 이 방식은 오프라인 방식으로 높은 품질의 최적화 궤적을 생성할 수 있습니다.

- **Performance Highlights**:  시뮬레이션 결과 본 접근법은 전통적인 DRL 최적화 모델에 비해 높은 안정성을 나타내며, 동적 통신 시스템에서 스펙트럼 효율성 변동에 대한 성능을 뛰어넘는 것으로 확인되었습니다.



### How Do Training Methods Influence the Utilization of Vision Models? (https://arxiv.org/abs/2410.14470)
Comments:
          Accepted at the Interpretable AI: Past, Present and Future Workshop at NeurIPS 2024

- **What's New**: 이 논문은 인공 신경망에서 각 격자의 중요성이 어떻게 달라지는지를 집중적으로 조사하며, 특히 훈련 방법이 신경망의 결정 함수에 미치는 영향을 분석하였습니다. 이를 위해 동일한 아키텍처와 훈련 데이터를 사용하되, 다양한 훈련 관행을 활용하여 이미지 분류 모델들을 비교하였습니다.

- **Technical Details**: 연구는 ResNet-50 아키텍처를 기반으로 하여 진행되었으며, 각 층의 파라미터를 무작위 값으로 대체하는 방법을 사용하여 각 층의 기여도를 측정하였습니다. 이때 Softmax 함수를 적용하여 결정 확률 벡터의 코사인 거리를 통해 층의 중요성을 수치적으로 평가하였습니다. 또한, 훈련 방법에 따라 특정 층들이 중요하게 작용하는지에 대한 차이를 관찰하였습니다.

- **Performance Highlights**: 결과적으로, 훈련 방법이 각 층의 중요도에 큰 영향을 미친다는 것을 확인하였습니다. 예를 들어, 개선된 훈련 레짐과 자가 지도 학습이 조기 층의 중요성을 높였고, 반면 적대적 훈련(adversarial training)은 이러한 경향과는 반대의 결과를 보였습니다. 이는 신경망 내부의 메커니즘을 더 깊이 이해하는 데 기여할 것으로 보입니다.



### The Propensity for Density in Feed-forward Models (https://arxiv.org/abs/2410.14461)
- **What's New**: 이 논문은 신경망의 크기가 증가할 때 모델이 사용해야 하는 파라미터의 양이 어떻게 변하는지를 연구하고, 특히 프루닝(pruning) 과정에서 성능 저하 없이 제거할 수 있는 가중치의 비율이 모델 크기에 크게 영향을 받지 않는다는 점을 발견하였습니다. 이를 통해 기존의 가설과는 다른 통찰을 제시합니다.

- **Technical Details**: 논문에서는 다양한 모델(완전 연결 네트워크, 컨볼루션 네트워크, 잔차 네트워크)을 프루닝 하여 성능 저하가 발생하기 전까지 가중치를 제거하는 실험을 수행하였습니다. 특정 모델의 크기에 관계없이 '코어' 모델의 크기가 크게 증가함을 발견하였고, 이를 통해 신경망에서의 효과적인 밀도에 대한 새로운 시각을 제시합니다.

- **Performance Highlights**: 모델의 폭이 증가할수록 '코어' 모델의 크기가 비례적으로 증가하는 경향을 보였으며, 다양한 크기의 모델에서도 유사한 효과적인 밀도를 보여주는 결과를 도출하였습니다. 모델의 초기화 방법이나 훈련 방식에 따라 다양한 설명을 제시하였고, 이는 각기 다른 아키텍처 및 최적화 기법에서 다르게 나타날 수 있습니다.



### Toward Generalizing Visual Brain Decoding to Unseen Subjects (https://arxiv.org/abs/2410.14445)
- **What's New**: 이번 연구는 기존의 뇌 디코딩 기술이 미지의 주체들에게 일반화될 수 있는지를 탐구합니다. 특히, 177명의 주체를 포함하는 대규모 이미지-fMRI 데이터셋을 구축하여, 다양한 주체의 뇌 활동을 연구하며 일관된 처리를 통해 일반화 능력을 향상시키고자 하였습니다.

- **Technical Details**: 연구는 Human Connectome Project(HCP)에서 수집한 3,127쌍의 이미지-fMRI 반응 데이터로 구성된 데이터셋을 활용합니다. 단일 모델을 사용하여 MLP, CNN, Transformer와 같은 다양한 네트워크 아키텍처에서 일반화 성능을 실험하였습니다. 모든 주체에 대해 동일한 처리 방식을 적용하여 모델 복잡성을 최소화하였습니다.

- **Performance Highlights**: 훈련 주체 수에 따른 일반화 능력의 명확한 증가를 보여주며, 훈련 주체 수가 1명에서 167명으로 증가하면서 정확도가 2%에서 45%로 향상되었습니다. 주체 간 유사성에 따라 일반화 성능이 달라지는 경향도 관찰되었으며, 남성과 여성 그룹 간의 차이가 크다는 결과를 도출하였습니다.



### Learning to refine domain knowledge for biological network inferenc (https://arxiv.org/abs/2410.14436)
- **What's New**: 이번 연구에서는 데이터 관찰을 기반으로 도메인 지식을 정제하는 새로운 amortized 알고리즘을 제안합니다. 이 알고리즘은 잡음이 있는 그래프 priors를 정제하여 낮은 데이터 조건에서 인과 관계를 식별하는 데 초점을 맞추고 있습니다.

- **Technical Details**: 제안된 모델 아키텍처는 Wu et al. (2024)의 감독형 인과 발견 모델을 기반으로 하며, 데이터셋을 지역 인과 그래프 추정치 및 글로벌 상관관계와 같은 요약 통계로 특성화합니다. 훈련 중에는 다양한 수준의 잡음에서 샘플링된 오염된 무방향 그래프를 입력 데이터에 추가하여, 신경망이 잘못된 엣지를 식별하고 가능할 경우 방향성을 지정하도록 학습합니다.

- **Performance Highlights**: 합성 데이터셋과 실제 세계의 Sachs proteomics 데이터셋에서 광범위한 실험을 수행한 결과, 제안한 방법이 인과 구조 학습 및 잡음 역전 오류 탐지에서 일관되게 강력한 성과를 달성하였습니다. 반면, 기본 방법들은 사전 지식의 품질과 데이터 양에 상당히 영향을 받습니다.



### FashionR2R: Texture-preserving Rendered-to-Real Image Translation with Diffusion Models (https://arxiv.org/abs/2410.14429)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 논문은 렌더링된 이미지를 사실감 있는 이미지로 변환하는 새로운 프레임워크를 소개합니다. 주목할 만한 점은 긍정적인 도메인 정제(finetuning)와 부정적인 도메인 임베딩(embedding) 기법을 적용하여 촬영된 이미지를 바탕으로 사전 학습된 Text-to-image (T2I) diffusion 모델에 지식을 주입하는 것입니다.

- **Technical Details**: 제안된 프레임워크는 두 단계로 구성됩니다: Domain Knowledge Injection (DKI)와 Realistic Image Generation (RIG). DKI 단계에서는 T2I diffusion 모델에 지식을 주입하고, RIG 단계에서는 입력된 렌더링 이미지를 기반으로 사실적인 이미지를 생성합니다. 이때 Texture-preserving Attention Control (TAC)을 사용하여 미세한 의류 텍스처를 보존하고, UNet 구조에 인코딩된 분리된 기능을 활용합니다.

- **Performance Highlights**: 제안된 방법은 렌더링된 이미지를 현실 이미지로 변환하는 과정에서 효과적이며 우수한 성능을 보여주었습니다. 또한, SynFashion 데이터셋을 통해 다양한 텍스처를 가진 고품질 디지털 의류 이미지를 제공하여 연구에 기여하고 있습니다.



### An explainable machine learning approach for energy forecasting at the household lev (https://arxiv.org/abs/2410.14416)
- **What's New**: 이번 논문에서는 가정에서의 전기 소모를 예측하기 위해 머신러닝(Machine Learning) 알고리즘을 활용하였으며, 특히 설명 가능한 예측 모형의 필요성을 강조합니다. 기존 연구들이 국가 또는 지역적 차원에 초점을 맞춘 것과는 달리, 가정 단위의 전기 소모 예측에 중점을 두었습니다.

- **Technical Details**: 이 논문은 다양한 머신러닝 알고리즘을 비교하고, 그들의 장단점을 분석하여 전기 소모 예측의 신뢰성과 투명성을 높이고자 하였습니다. 특히 커스터마이즈 가능한 의사결정 나무(custom decision tree) 방식을 도입하여 예측 모델의 설명 가능성을 확보하고, 고객의 직관과 일치하도록 하였습니다. 여기에 랜덤 포레스트(Random Forest)와 그래디언트 부스팅(Gradient Boosting) 알고리즘을 활용하여 각각의 기여도와 성능을 평가하였습니다.

- **Performance Highlights**: 커스터마이즈 가능한 의사결정 나무는 높은 설명 가능성을 제공하면서도 정확도 손실을 최소화하는 것으로 나타났습니다. 또한, 이 방법을 통해 고객에 대한 이해를 높이고, 고지서(빚 고지서)의 충격을 줄이는 데에 기여할 수 있음을 보여주었습니다. 특정 환경에서는 이상치(Outlier)에 대한 저항력이 부족할 수 있지만, 전반적으로 가정용 전기 소비량 예측에 효과적인 접근법으로 평가됩니다.



### Debug Smarter, Not Harder: AI Agents for Error Resolution in Computational Notebooks (https://arxiv.org/abs/2410.14393)
Comments:
          Accepted to EMNLP 2024 System Demonstrations

- **What's New**: 이 논문은 코드 오류 해결을 위해 특별히 설계된 AI 에이전트를 소개합니다. 이 에이전트는 JetBrains의 Datalore 서비스에 통합되어 있으며, 비선형 컴퓨테이셔널 노트북 환경에서 높은 자율성으로 Bugs-fixing을 수행할 수 있습니다.

- **Technical Details**: 제안된 AI 에이전트는 GPT-4-0613 모델을 기반으로 하며, 사용자가 환경과 상호작용하는 방식처럼 노트북 환경을 탐색합니다. 이 시스템은 에이전트, 환경, 사용자 인터페이스의 세 가지 주요 부분으로 구성됩니다. 에이전트는 LLM과 노트북 간의 통신을 조율하며, 상태 정보를 기록하고 예측을 실행할 수 있습니다.

- **Performance Highlights**: 사용자 연구 결과, 에이전트 시스템의 오류 해결 능력이 기존 단일 행동 솔루션보다 높게 평가되었지만, 사용자 인터페이스(UI)에서 어려움을 겪는 것으로 나타났습니다. 이 연구는 사용자-에이전트 협업 향상을 위한 중요한 통찰을 제공합니다.



### SurgeryV2: Bridging the Gap Between Model Merging and Multi-Task Learning with Deep Representation Surgery (https://arxiv.org/abs/2410.14389)
Comments:
          This paper is an extended version of our previous work [arXiv:2402.02705] presented at ICML 2024

- **What's New**: 이번 논문은 모델 병합(model merging) 기반 다중 작업 학습(multi-task learning, MTL)에서 발생하는 '표현 편향(representation bias)' 문제를 다루고 있으며, 이를 개선하기 위한 새로운 접근 방식을 제안합니다.

- **Technical Details**: 저자들은 첫 번째로 'Surgery'라는 경량의 작업별 모듈을 제안하여 merged model의 최종 층 표현을 expert models의 최종 층과 정렬합니다. 또한, 보다 포괄적인 해결책으로 'SurgeryV2'를 제안하여 모든 층에서 표현 편향을 완화하며, 전통적인 MTL 방법과의 성능 격차를 줄입니다.

- **Performance Highlights**: SurgeryV2는 기존의 expert models나 전통적 MTL 모델과 비슷한 수준의 성능에 도달했으며, 최첨단(model merging) 기술과 결합했을 때 주요 성능 향상을 보여주었습니다. 실험 결과, SurgeryV2는 같은 용량에서 Surgery보다 더 적은 반복으로도 훨씬 높은 정확도를 달성했습니다.



### Assistive AI for Augmenting Human Decision-making (https://arxiv.org/abs/2410.14353)
Comments:
          37 pages, 6 figures

- **What's New**: 이 논문은 악의적인 AI 기술의 빠른 발전에 대응하여 인간의 의사 결정 능력을 향상시키기 위한 혁신적인 Assistive AI 프레임워크를 소개합니다. 이 프레임워크는 법적 맥락에서 특히 신뢰 네트워크를 구축하고, 규제 노력을 보완하는 것을 목표로 합니다.

- **Technical Details**: Assistive AI 프레임워크는 개인정보 보호(privacy), 책임(accountability), 신뢰성(credibility) 원칙을 중심으로 구성됩니다. 이 방법론은 정보의 신뢰성과 정보 출처의 신뢰성을 보장하기 위한 기반을 갖추고 있으며, AI가 인간의 의사 결정을 지원하고, 커뮤니케이션을 필터링 및 안내하는 기능을 통합합니다.

- **Performance Highlights**: 이 프레임워크는 AI-assisted 결정의 신뢰성, 책임성이 확보되도록 'Board' 개념을 도입하고, 이를 통해 AI와 인간 판단 간의 시너지를 강조합니다. 이는 현실과 허구를 구분하고, 사람들이 잘-informed된 결정을 내릴 수 있도록 지원하는 데 중요한 역할을 할 것입니다.



### A Scientific Machine Learning Approach for Predicting and Forecasting Battery Degradation in Electric Vehicles (https://arxiv.org/abs/2410.14347)
- **What's New**:  본 연구는 배터리 열화도(ToH)를 예측할 수 있는 새로운 접근 방식을 제시하며, 과학적 기계 학습(Scientific Machine Learning, SciML) 프레임워크를 활용하여 신경망(neural networks)과 도메인 지식을 통합한 유니버설 미분 방정식(Universal Differential Equations, UDE)과 신경 미분 방정식(Neural ODE) 기술을 사용합니다.

- **Technical Details**:  이 연구에서 사용된 모델은 배터리의 지속적 단기 및 장기 열화 예측을 위해 UDE와 Neural ODE 프레임워크를 결합하였으며, 이를 통해 고품질 실험 데이터를 적용하고 배터리의 상태 건강(State of Health, SoH)을 효과적으로 추적할 수 있습니다. 데이터의 적용은 실험실 실험 데이터와 합성된 지상 진리(synthetic ground-truth) 데이터를 포함합니다. 또한, 주기적 열화(cycle degradation)와 달력 열화(calendar degradation)를 모두 고려하며, 각기 다른 배터리 화학의 일반화를 가능케 합니다.

- **Performance Highlights**:  이 모델은 UDE와 Neural ODE를 사용하여 MSE(Mean Squared Error)에서 각각 9.90과 11.55를 기록하며, 실험 데이터에서는 손실(loss) 1.6986과 MSE 2.49를 달성했습니다. 이는 기계 학습 기반 배터리 관리의 신뢰성과 지속 가능성을 향상시키는 결과입니다. 이러한 접근 방식은 배터리의 수명을 연장하고 자원 낭비를 최소화하며 UN 지속가능발전목표(SDGs)에 기여하고 있습니다.



### Game Theory with Simulation in the Presence of Unpredictable Randomisation (https://arxiv.org/abs/2410.14311)
- **What's New**: AI 에이전트는 전통적인 에이전트와는 다르게 예측할 수 있는 방식에서 동작합니다. 이 예측 가능성을 활용하여 사회적 복지를 향상시킬 수 있는 방법을 연구합니다.

- **Technical Details**: 우리는 게임 이론적 설정에서 한 에이전트가 다른 에이전트를 모방하여 혼합 전략(mixed strategy)을 학습할 수 있는 고정 비용을 지불하는 상황을 분석합니다. 그러나 모든 '일반화된 신뢰 게임(generalised trust games)'에서 혼합 전략 모방이 두 플레이어의 결과를 개선하지 않을 수 있음을 증명하였습니다. 또한, 모방하기 위해 혼합 전략을 도입했을 때, 파레토 개선(Pareto-improving) 너시 균형(Nash equilibria)을 도입하는지 결정하는 것은 NP-hard 문제임을 보여주었습니다.

- **Performance Highlights**: 혼합 전략 모방은 시뮬레이터가 신뢰의 수준을 조정할 수 있는 옵션이 있을 때, 신뢰와 조정 문제 모두를 겪고 있는 상황에서, 또는 협력을 가능하게 하는 데 프라이버시 유지가 중요한 경우에 사회적 복지를 향상시킬 수 있습니다.



### Transferring Tactile Data Across Sensors (https://arxiv.org/abs/2410.14310)
Comments:
          Extended Abstract. Accepted in ICRA@40 (40th Anniversary of the IEEE International Conference on Robotics and Automation) 23-26 September, 2024 Rotterdam, Netherlands

- **What's New**: 이 논문은 기존의 물리적 형태와 출력 신호가 다른 촉각 센서 간에 데이터를 변환하는 새로운 방법을 소개합니다. BioTac 센서의 신호를 DIGIT 센서로 변환하는 방법을 활용하여 여러 기존 데이터셋을 계속 사용할 수 있게 됩니다.

- **Technical Details**: 연구는 세 가지 단계를 통해 진행됩니다. 첫째, BioTac의 입력 신호를 기반으로 표면 변형을 예측합니다. 둘째, BioTac의 3D 변형 메시를 DIGIT의 3D 변형 메시로 변환합니다. 마지막으로, 변환된 변형 데이터를 사용해 DIGIT 센서의 이미지를 생성합니다.

- **Performance Highlights**: 테스트 결과, BioTac의 신호 데이터 5가지 샘플을 DIGIT 이미지로 성공적으로 변환하였으며, 이러한 전환의 가능성을 증명했습니다. 이 방법은 다양한 형상과 크기를 가진 센서들 간에도 효과적으로 결과를 도출할 수 있다는 것을 보여줍니다.



### Advanced Underwater Image Quality Enhancement via Hybrid Super-Resolution Convolutional Neural Networks and Multi-Scale Retinex-Based Defogging Techniques (https://arxiv.org/abs/2410.14285)
- **What's New**: 이번 연구에서는 수중 이미지의 품질 저하 문제를 해결하기 위해 Multi-Scale Retinex (MSR) 디포깅 기법과 Super-Resolution Convolutional Neural Networks (SRCNN)을 결합한 새로운 하이브리드 전략을 제안합니다.

- **Technical Details**: Retinex 알고리즘은 인간의 시각 인식을 모사하여 조명 불균형과 흐림 현상을 줄이고, SRCNN은 수중 이미지의 공간 해상도를 향상시킵니다. 이 두 가지 방법을 결합하여 수중 이미지의 선명도, 대비, 색상 복원을 개선합니다. 연구는 실제 수중 데이터셋에서의 광범위한 실험을 통해 해당 접근 방식의 효과를 입증합니다.

- **Performance Highlights**: 정량적 평가 지표인 Structural Similarity Index Measure (SSIM)와 Peak Signal-to-Noise Ratio (PSNR)를 사용하여 기존 방법보다 선명도, 가시성, 특징 보존에서 상당한 개선을 보였습니다. 이 접근법은 해양 탐사, 수중 로봇 공학, 자율 수중 차량 등 실시간 수중 응용 분야에서 중요한 역할을 할 수 있습니다.



### Revisiting SLO and Goodput Metrics in LLM Serving (https://arxiv.org/abs/2410.14257)
- **What's New**: 이 논문은 큰 언어 모델(LLM) 서비스의 성능을 평가하기 위한 새로운 통합 지표 체계인 'smooth goodput'을 제안합니다. 이 지표는 사용자 경험의 본질을 반영하며, 다양한 작업의 특정 목표에 맞게 조정 가능합니다.

- **Technical Details**: 본 논문에서는 기존의 SLOs와 goodput 지표를 재검토하고, 사용자 경험을 반영하는 새로운 지표 체계를 개발합니다. 이는 각 토큰에 대한 합리적인 마감 기한을 설정하고, 사용자가 읽을 수 있는 토큰의 이점을 고려하여 성능을 평가합니다. 성능 평가는 다양한 작업 부하를 기반으로 이루어집니다.

- **Performance Highlights**: 이러한 새로운 지표 체계는 LLM 서비스 시스템의 최적화 방향성을 제시하며, 기존 전략의 성능을 재평가함으로써 향후 연구 및 향상을 위한 통합 기준을 제공합니다.



### Almost-Linear RNNs Yield Highly Interpretable Symbolic Codes in Dynamical Systems Reconstruction (https://arxiv.org/abs/2410.14240)
Comments:
          38th Conference on Neural Information Processing Systems (NeurIPS 2024)

- **What's New**: 본 논문에서는 Dynamic System(DS)의 비선형성을 극복하고, 데이터를 활용하여 최적의 PWL(부분 선형) 표현을 자동으로 생성할 수 있는 Almost-Linear RNN(AL-RNN)을 소개합니다. 이는 기존의 복잡한 선형 모델 구조를 간소화하고, 수학적 정합성을 유지하면서 해석 가능성을 강화합니다.

- **Technical Details**: AL-RNN은 ReLU와 선형 유닛을 결합하여 최적의 PWL 표현을 생성하며, 매우 적은 수의 비선형 연산만을 사용합니다. 이러한 구조는 기존의 복잡한 모델 대신, 데이터에서 직접적으로 구조적인 최소 표현을 식별하고, 데이터 생성 DS의 중요한 위상적 특성을 보존하는 기호적 인코딩을 자연스럽게 제공합니다.

- **Performance Highlights**: Lorenz 및 Rössler 시스템에서 AL-RNN은 완전히 데이터 기반의 방식으로 알려진 최소 위상적 PWL 표현을 발견하였으며, 두 개의 도전적인 실험 데이터셋에서도 해석 가능한 기호적 인코딩을 통해 시스템의 수학적 및 계산적 분석을 획기적으로 용이하게 하였습니다.



### RA-BLIP: Multimodal Adaptive Retrieval-Augmented Bootstrapping Language-Image Pre-training (https://arxiv.org/abs/2410.14154)
Comments:
          10 pages, 6 figures, Journal

- **What's New**: 최신 연구에서 다중 모드 대형 언어 모델(Multimodal Large Language Models, MLLMs)이 주목받고 있으며, 이는 다양한 비전-언어 작업에 활용될 수 있는 일반 목적 모델로서의 가능성을 보여줍니다. 본 연구에서는 MLLMs를 위한 새로운 검색 강화 프레임워크인 RA-BLIP이 소개됩니다.

- **Technical Details**: RA-BLIP은 두 가지 주요 요소로 구성됩니다. 첫 번째는 다중 모드 적응형 검색-강화 모델로서, 질문을 지침으로 사용하여 불필요한 정보 간섭을 최소化하면서 관련 시각 정보를 추출하는 기능을 포함합니다. 두 번째는 적응형 선택 지식 생성(ASKG) 전략으로, 생성기가 검색한 지식의 적합성을 자율적으로 판별할 수 있도록 훈련됩니다.

- **Performance Highlights**: RA-BLIP은 여러 공개 다중 모드 질문-응답 데이터셋에서 실험을 통해 기존의 검색-강화 모델들을 능가하는 뛰어난 성능을 보였습니다.



### ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom (https://arxiv.org/abs/2410.14138)
- **What's New**: 대형 비전-언어 모델(LVLMs)은 비주얼 이해 작업에서 큰 발전을 이루었지만, 비주얼 추론 작업에서는 이미지 정보보다 언어 지식을 우선시하여 성능 저하가 발생하는 문제가 있었습니다. 이를 해결하기 위해 LVLM의 비주얼 추론 과정을 시각적 인식과 텍스트 추론의 두 단계로 분해하고 새로운 비주얼 추론 프레임워크인 ProReason을 제안합니다.

- **Technical Details**: ProReason은 질문 지향적이고 추론이 포함된 시각적 정보 추출과 분리된 비전-추론 기능을 갖춘 다중 단계 다중 모달 추론 프레임워크입니다. 이 프레임워크는 행동(Action), 판단(Judgment), 요약(Summary)의 세 단계로 나뉘며, 각 단계는 고유한 역할을 가진 에이전트를 포함합니다. 이로 인해 시각 정보의 수집과 추론을 효과적으로 분리하여 각 단계에서 LVLM의 한계를 보완합니다.

- **Performance Highlights**: ProReason은 기존의 다중 단계 추론 프레임워크 및 수동 동료 방법을 능가하여 다양한 벤치마크에서 성능을 향상시키며, MMMU 벤치마크에서 최대 15%의 성능 향상이 관찰되었습니다. 이 프레임워크는 LLM과의 통합 가능성을 입증하여 LVLM의 비주얼 추론 향상에 기여하는 중요한 기초 자료가 될 것입니다.



### Inverse Reinforcement Learning from Non-Stationary Learning Agents (https://arxiv.org/abs/2410.14135)
- **What's New**: 본 논문에서는 학습 에이전트의 최적 정책을 학습하는 동안 수집한 궤적 데이터를 사용하여 보상 함수를 학습하는 역 강화 학습(Inverse Reinforcement Learning, IRL) 문제를 다룹니다. 새로운 방식의 behavior cloning 알고리즘인 bundle behavior cloning을 제안하며, 이를 통해 에이전트의 정책을 추정하고 보상 함수를 학습합니다.

- **Technical Details**: 제안된 방법은 stochastic gradient descent를 사용하여 에이전트의 정책을 업데이트하며, 비선형 함수로 보상 함수를 근사할 수 있습니다. bundle behavior cloning은 시간에 따라 다른 시점에서 생성된 적은 수의 궤적을 사용하여 에이전트의 정책 매개변수를 추정하고 정책을 학습하는 과정에서 오류 경계를 제공합니다.

- **Performance Highlights**: 간단한 동작 계획 문제에 대해 수행한 수치 실험에서, 제안된 접근 방식이 학습 에이전트의 보상 함수를 효과적으로 학습함을 보여주며, 기존의 behavior cloning 방법보다 우수함을 입증했습니다.



### Deep Learning Applications in Medical Image Analysis: Advancements, Challenges, and Future Directions (https://arxiv.org/abs/2410.14131)
- **What's New**: 최근의 연구들은 심층 학습(Deep Learning) 알고리즘이 뛰어난 정확성과 효율성을 통해 의료 영상 분석의 혁신을 이끌어내고 있음을 보여주고 있습니다. 특히, 합성곱 신경망(Convolutional Neural Networks, CNNs)이 여러 의료 과목에서 자율적으로 특성을 학습하여 진단을 가속화하는 데 중요한 역할을 하고 있습니다.

- **Technical Details**: 딥러닝은 다차원 의료 이미지(MRI, CT 스캔, 엑스레이 등)에서 특징을 수동으로 추출할 필요 없이 자동적으로 학습하는 능력을 보입니다. 이러한 기술은 병리학(Pathology), 영상의학(Radiology), 안과학(Ophthalmology), 심장학(Cardilogy) 등 다양한 분야에서 질병 탐지, 분류(classification), 그리고 분할(segmentation) 작업에 사용됩니다.

- **Performance Highlights**: 이 연구에서 제안된 모델들은 임상 절차의 신뢰성과 신속성을 향상시키며, 의료진이 정확하고 빠른 진단을 내리는 데 도움을 주고 있습니다.



### Towards Robust Transcription: Exploring Noise Injection Strategies for Training Data Augmentation (https://arxiv.org/abs/2410.14122)
Comments:
          Accepted to the Late-Breaking Demo Session of the 25th International Society for Music Information Retrieval (ISMIR) Conference, 2024

- **What's New**: 최근 자동 피아노 전사(Automatic Piano Transcription, APT) 기술의 발전에도 불구하고, 노이즈가 많은 환경에서의 시스템 성능이 저하되는 문제는 거의 탐구되지 않았습니다. 본 연구는 다양한 신호 대 잡음 비율(Signal-to-Noise Ratio, SNR)에서 백색소음(white noise)을 주입하여 APT 모델의 성능을 평가합니다.

- **Technical Details**: 본 연구에서는 Onsets and Frames 모델을 활용하여, 백색소음을 주입한 데이터로 훈련된 모델의 성능을 평가했습니다. 실험에는 -6dB에서 45dB까지의 SNR 구간을 고려하여 적어도 18개의 서로 다른 SNR 수준에서 모델의 성능을 평가했습니다. 데이터는 MAESTRO v3 데이터셋을 사용했으며, 클린 오디오와 노이즈-주입 오디오의 비율을 나타내는 청정 대 노이즈 비율(Clean-to-Noise Ratio, CNR)을 도입했습니다.

- **Performance Highlights**: 실험 결과, 노이즈 주입 데이터로 훈련된 모델은 낮은 SNR에서 클린 데이터로만 훈련된 모델보다 현저하게 성능이 우수하며, 고 SNR에서는 이 두 모델 간의 차이가 줄어드는 경향이 관찰되었습니다. 통계적 분석(t-test)을 통해 얻은 Precision, Recall, F1 스코어에서 유의미한 차이가 도출되었습니다. 이 연구는 다양한 노이즈 환경에 대한 강인성을 강화하는 것이 클린 환경에서의 성능 저하와 충돌하지 않음을 시사합니다.



### FedMSE: Federated learning for IoT network intrusion detection (https://arxiv.org/abs/2410.14121)
- **What's New**: 이 논문은 IoT 네트워크 침입 감지를 개선하기 위한 새로운 Federated Learning 접근 방식을 제안합니다. 전통적인 중앙 집중식 머신 러닝 방법의 한계를 극복하고자, Shrink Autoencoder와 Centroid one-class classifier를 조합한 Semi-supervised Federated Learning 모델을 개발했습니다. 이를 통해 비대칭 네트워크 환경에서 침입 감지 성능을 향상시키고, 평균 제곱 오차 기반 집계 알고리즘을 도입하여 지역 모델 정확도를 prioritization 할 수 있습니다.

- **Technical Details**: 제안된 방법은 Shrink Autoencoder (SAE)를 통해 정상 네트워크 데이터를 효과적으로 나타내고, Centroid(CEN) 모델을 사용하여 이상 감지를 수행합니다. 게다가, Mean Squared Error 기반의 집계 알고리즘(MSEAvg)을 통해 지역 모델의 정확성을 강조하여 글로벌 모델 성능을 개선할 수 있습니다. 이 접근방식은 IoT 게이트웨이가 데이터 공유 없이 로컬 데이터를 이용해 독립적으로 모델 교육을 가능하게 합니다.

- **Performance Highlights**: 실험 설정에 따르면 방대한 IoT 네트워크에서 탐지 정확도를 93.98±2.90에서 97.30±0.49로 크게 향상시켰으며, 훈련 과정에 50%의 게이트웨이만 참여해도 학습 비용을 줄일 수 있었습니다. 이 연구는 대규모 IoT 네트워크에서도 견고성을 보여주었습니다.



### Skill Generalization with Verbs (https://arxiv.org/abs/2410.14118)
Comments:
          7 pages + 2 pages (references), 6 figures. Accepted at IROS 2023. Code, dataset info and demo videos can be found at: this https URL

- **What's New**: 이 연구에서는 로봇이 자연어 명령을 이해하고, 새로운 물체에 대해 조작 기술을 일반화할 수 있는 방법을 제안합니다. 제안된 메서드는 동사를 사용하여 새로운 물체의 조작 경로를 생성하는 과정에서 확률적 분류기를 학습합니다.

- **Technical Details**: 이 모델은 조작할 물체의 이미지를 입력 받아 동사를 기반으로 객체 경로를 생성하는 두 가지 구성 요소로 이루어져 있습니다. 첫 번째는 특정 동사로 설명할 수 있는 임의의 객체 경로를 판별하는 분류기(Probabilistic Classifier)입니다. 두 번째는 정책 탐색(Policy Search) 알고리즘으로, 주어진 동사를 최대화하는 경로를 찾는 역할을 합니다.

- **Performance Highlights**: 이 연구에서는 주어진 14개의 동사와 13개의 객체 카테고리에 대해 새로운 객체 카테고리로 일반화하는 과정에서 평균 정확도 76.69%를 달성하였습니다. 또한, 실제 로봇(KUKA LBR iiwa7)이 새로운 객체 인스턴스에 대해 다섯 가지 동사 명령을 수행할 수 있는 경로를 생성할 수 있음을 보여주었습니다.



### A Communication and Computation Efficient Fully First-order Method for Decentralized Bilevel Optimization (https://arxiv.org/abs/2410.14115)
Comments:
          19 Pages

- **What's New**: 이 논문에서는 기존의 고차원 최적화 문제를 해결하기 위한 새로운 접근법인 완전 일차 분산 방법 
C^{2}DFB를 제안합니다. 이 방법은 두 번째 미분 정보 없이 첫 번째 미분 정보만으로 하이퍼 그레디언트를 근사합니다.

- **Technical Details**: C^{2}DFB 알고리즘은 각 학습 노드가 min-min-max 문제를 최적화하는 구조로, 
로컬 파라미터의 압축된 잔여값을 효과적으로 전송하기 위한 경량 통신 프로토콜을 통합합니다. 
이 방법은 연산 복잡성을 크게 줄이며 수렴 이론에 대한 엄격한 분석이 포함되어 있습니다.

- **Performance Highlights**: C^{2}DFB는 다양한 유형과 이질적인 데이터 분포에 대해 기존의 고차원 기반 방법 및 단일 루프 방법보다 
눈에 띄는 성능을 보이며, 수렴률과 통신 효율성 면에서 우수한 결과를 도출했습니다.



### Extreme Precipitation Nowcasting using Multi-Task Latent Diffusion Models (https://arxiv.org/abs/2410.14103)
Comments:
          12 pages, 6figures

- **What's New**: 본 논문에서는 다중 작업 잠재 확산 모델(Multi-Task Latent Diffusion Model, MTLDM)을 도입하여 고 강수 강도 영역에서의 레이더 이미지의 공간 세부사항을 더 정확하게 예측할 수 있는 방법을 제시합니다.

- **Technical Details**: MTLDM은 레이더 이미지를 여러 구성 요소로 분해하여 각 구성 요소를 별도로 예측하는 분할 정복(divide-and-conquer) 접근 방식을 사용합니다. 이는 다양한 강수 강도에 해당하는 여러 구성 요소로 구성된 강수 이미지를 개념화하여 예측합니다.

- **Performance Highlights**: MTLDM은 실제 강수 지역을 최대 5-80분 이전까지 공간적 일관성을 유지하여 예측할 수 있으며, 기존의 최첨단 기술들보다 여러 평가 지표에서 뛰어난 성과를 보였습니다.



### Multi-Source Spatial Knowledge Understanding for Immersive Visual Text-to-Speech (https://arxiv.org/abs/2410.14101)
Comments:
          5 pages, 1 figure

- **What's New**: 이 논문은 Visual Text-to-Speech (VTTS) 분야에 다중 원천 공간 지식 인식 기법인 MS²KU-VTTS를 제안합니다. 기존의 접근 방식이 RGB 영상에만 집중한 반면, 이 연구는 깊이 영상, 화자 위치 정보, 환경 의미론 등을 보조 정보로 통합하여 더욱 몰입감 있는 음성을 생성하는데 중점을 둡니다.

- **Technical Details**: MS²KU-VTTS는 RGB 이미지를 주요 소스로 하여, 깊이 이미지와 화자 위치 정보, 그리고 이미지 이해 기반의 의미론적 캡션을 보조 소스로 사용하는 구조입니다. Dominant-Supplement Serial Interaction 메커니즘을 통해 다양한 데이터 소스의 피처를 처리하고, 다이나믹한 융합 및 음성 생성 과정을 통해 환경 리버브를 정밀하게 모델링합니다.

- **Performance Highlights**: MS²KU-VTTS는 자연스러움과 지각 품질 면에서 기존의 최첨단 시스템들을 능가하는 성능을 보여주었으며, 이를 위해 종합적인 실험을 실시했습니다.



### ST-MoE-BERT: A Spatial-Temporal Mixture-of-Experts Framework for Long-Term Cross-City Mobility Prediction (https://arxiv.org/abs/2410.14099)
Comments:
          2nd ACM SIGSPATIAL International Workshop on the Human Mobility Prediction Challenge

- **What's New**: 이번 연구에서는 복잡하고 다양한 도시 환경 속에서 인간의 이동 패턴을 예측하는 새로운 접근 방법인 ST-MoE-BERT(Spatial-Temporal Mixture-of-Experts with BERT)를 제안합니다. 기존 방법과 달리, 본 연구는 예측 작업을 공간-시간 분류 문제로 설정하고 Mixture-of-Experts 아키텍처와 BERT 모델을 통합하여 복잡한 이동 동향을 포착합니다. 또한, 데이터가 부족한 도시 간 예측 문제를 해결하기 위해 transfer learning을 도입합니다.

- **Technical Details**: ST-MoE-BERT는 transformer 기반 아키텍처와 Mixture-of-Experts 레이어를 통합하여 장기적인 도시 간 이동 예측 문제에 효과적으로 대응합니다. BERT의 시퀀스 모델링 능력과 MoE 네트워크의 전문성을 활용하여 일반적이고 도시별 이동 패턴 모두를 포착하도록 설계되었습니다. 본 모델은 이탈리언 자가 회귀 모델인 BERT를 사용하여 이동 데이터의 시간적 의존성을 모델링하며, 자가 주의 메커니즘을 통해 과거와 미래 이동 경로 간의 관계를 이해합니다.

- **Performance Highlights**: ST-MoE-BERT는 GEO-BLEU와 DTW에서 여러 최첨단 방법과 비교했을 때 평균 8.29%의 성능 향상을 보여줍니다. 이는 본 모델이 도시 간 이동 패턴의 복잡성을 잘 포착하고 있기 때문입니다.



### Towards Effective Planning Strategies for Dynamic Opinion Networks (https://arxiv.org/abs/2410.14091)
Comments:
          Accepted at NeurIPS 2024

- **What's New**: 이번 연구에서는 동적인 의견 네트워크에서 정확한 정보 전파를 위한 개입 계획(intervention planning)을 탐구합니다. 정확한 정보의 전파를 위해 핵심 노드(key nodes)를 식별하고 제어력을 행사하는 방법론이 제시됩니다.

- **Technical Details**: 새로운 순위 알고리즘(ranking algorithm)을 도입하여 정확한 정보를 전파하기 위한 핵심 노드를 식별합니다. 또한 강화 학습(Reinforcement Learning, RL)을 기반으로 한 동적 계획(framework)을 개발하여 라벨 생성(label generation)의 복잡성을 해결합니다. 두 가지 전파 모델(propagation models)에 맞춰진 NN 기반 RL 계획자(NN-based RL planners)를 조사합니다.

- **Performance Highlights**: 실험 결과, 순위 알고리즘 기반의 분류기(classifiers)가 감염률(infection rate) 제어를 향상시키는데 도움을 주며, 특히 액션 예산(action budget)이 증가할수록 효과적입니다. 핵심 지표(number of susceptible nodes 및 infection rates)에 중점을 둔 보상 전략(reward strategies)이 더 빠른 차단 전략보다 우수한 성능을 보였습니다. GCN(Graph Convolutional Networks) 기반 계획자들은 다양한 네트워크 시나리오에서 낮은 감염률(높은 제어)을 달성하는 중앙 집중형 계획(centralized plans)을 촉진합니다.



### In-context learning and Occam's razor (https://arxiv.org/abs/2410.14086)
- **What's New**: 이 논문은 머신러닝의 일반화(Generalization)와 관련하여 Occam's razor의 원리와 in-context learning의 관계를 탐구합니다. 저자들은 주어진 맥락에서 학습하는 새로운 능력을 가진 시퀀스 모델, 특히 Transformers에 주목합니다.

- **Technical Details**: 주요 내용은 in-context learners를 훈련하는 데 사용되는 next-token prediction loss가 prequential coding이라는 데이터 압축 기술과 직접적으로 동등하다는 것입니다. 이는 모델의 복잡성을 줄이는 것과 훈련 오차(Training Error)를 최소화하는 것이 동일함을 의미합니다.

- **Performance Highlights**: 저자들은 제안된 이론을 실증해보여 현재의 in-context learning 방법들의 한계를 설명하고, 개선할 수 있는 방법을 제시합니다.



### Interpreting Inflammation Prediction Model via Tag-based Cohort Explanation (https://arxiv.org/abs/2410.14082)
- **What's New**: 이 논문은 식이 염증 예측 모델에서 집단 설명(cohort explanation) 기법을 도입하여 모형의 예측 결과를 더 잘 이해할 수 있도록 하는 프레임워크인 TagHort를 제안합니다.

- **Technical Details**: TagHort는 데이터세트 내의 지역(feature) 중요도 점수를 기반으로 집단을 식별하고, 태그를 통해 클러스터의 간결한 설명을 생성합니다. 본 논문은 SHAP(SHapley Additive exPlanations) 및 LIME(Local Interpretable Model-agnostic Explanations)와 같은 후처리(feature importance) 설명 방식을 활용합니다.

- **Performance Highlights**: 실험 결과, TagHort는 전문가 지식과 일치하는 신뢰할 수 있는 설명을 생성하여 기계 학습 모델의 해석 가능성을 높였습니다.



### FaceSaliencyAug: Mitigating Geographic, Gender and Stereotypical Biases via Saliency-Based Data Augmentation (https://arxiv.org/abs/2410.14070)
Comments:
          Accepted at Image Signal and Video processing

- **What's New**: 이 연구에서는 Convolutional Neural Networks (CNNs) 및 Vision Transformers (ViTs)에서 성별 편향을 해결하기 위한 새로운 접근법인 FaceSaliencyAug를 제안합니다. 이 접근법은 이미지에서 얼굴의 두드러진 영역을 활용하여 지리적 및 고정관념적 편향을 완화하도록 설계되었습니다.

- **Technical Details**: FaceSaliencyAug는 여러 데이터 세트에서의 데이터 다양성을 증대시키고 모델 성능을 향상시키기 위해 두드러진 얼굴 영역에 대해 선택된 마스크를 적용합니다. 실험에서 Image Similarity Score (ISS)를 사용하여 데이터 세트의 다양성을 정량화하고, CEO, 엔지니어, 간호사 및 학교 교사 데이터 세트에서 성별 편향을 측정하기 위해 Image-Image Association Score (IIAS)를 사용합니다. 또한, 이 방법은 CNNs와 ViTs 모두에서 성별 편향을 감소시키는 데 효과적임을 보여주었습니다.

- **Performance Highlights**: 제안된 FaceSaliencyAug 방법은 Flickr Faces HQ (FFHQ), WIKI, IMDB, Labelled Faces in the Wild (LFW), UTK Faces 및 Diverse Dataset을 포함한 다섯 개의 데이터 세트에서 뛰어난 다양성 메트릭을 달성하였으며, 네 개의 직업 데이터 세트에서 성별 편향을 상당히 줄이는 데 성공했습니다. 이는 컴퓨터 비전 모델의 공정성과 포용성을 개선하는 데 기여하고 있습니다.



### Provable Benefits of Complex Parameterizations for Structured State Space Models (https://arxiv.org/abs/2410.14067)
Comments:
          12 pages, 1 figure. Accepted to NeurIPS 2024

- **What's New**: 이 논문은 구조화된 상태 공간 모델(SSM)의 복소수 파라미터화의 이점을 이론적으로 설명하는 방향으로 나아가고 있습니다. 특히, 이 논문은 복소수 SSM의 매핑 표현 능력이 실제 SSM보다 효율적이라는 두 가지 이론적 기여를 제공합니다.

- **Technical Details**: SSMs(Structured State Space Models)는 S4, Mamba 등과 같은 신경망 아키텍처의 핵심 엔진이며, 일반적으로 대각형의 상태 전이 행렬을 가진 선형 동적 시스템으로 생각할 수 있습니다. 이 논문에서는 복소수 및 실제 SSM의 매핑 표현 능력에 있어 명확한 차이가 있음을 보였습니다. 복소수 SSM은 완화된 파라미터 값으로 모든 매핑을 표현할 수 있는 반면, 실제 SSM은 보통 매우 큰 값을 요구합니다.

- **Performance Highlights**: 실험 결과는 이론을 뒷받침하며, 복소수 파라미터화가 SSM의 성능을 크게 향상시킨다는 것을 보여주었습니다. 또한, 선택적(Selectivity)이라는 새로운 아키텍처 기능을 평가한 결과, 일부 작업에서는 복소수 파라미터화가 유리하고, 다른 작업에서는 실제 파라미터화가 유사한 성능을 낼 수 있음을 확인했습니다.



### On Partial Prototype Collapse in the DINO Family of Self-Supervised Methods (https://arxiv.org/abs/2410.14060)
Comments:
          First version of the paper appeared in OpenReview on 22 Sep 2023. Accepted to BMVC 2024

- **What's New**: 본 논문에서는 DINO 방법군에서의 부분 프로토타입 붕괴(partial prototype collapse) 문제를 정의하고 이를 해결하기 위한 KoLeo-proto 정규화 방법을 제안합니다. 이 방법은 다양한 프로토타입을 활용하도록 유도하여 보다 정교한 클러스터와 유용한 표현을 학습할 수 있도록 돕습니다.

- **Technical Details**: Self-supervised learning (SSL)에서 클러스터(cluster)를 기반으로 표현을 모델링하는 방식이 널리 쓰입니다. DINO 방법군은 동시 학습 중에 발생하는 프로토타입 간의 간섭으로 인해, 특정 프로토타입이 동일한 벡터로 수렴하는 부분 프로토타입 붕괴 문제를 겪습니다. 이를 방지하기 위해, KoLeo-proto 정규화는 프로토타입의 차별적 엔트로피(differential entropy)를 극대화하여 다양한 프로토타입을 장려합니다.

- **Performance Highlights**: iNaturalist-2018과 같은 긴 꼬리의 데이터셋에서 사전 학습을 진행했을 때, 동일한 데이터셋을 분류하는 성능에서 명확한 성능 향상을 보여주었으며, 이전 모델들과 비교했을 때 전이 성능(transfer performance)에도 영향을 미치지 않았다는 결과를 나타냈습니다.



### Best in Tau@LLMJudge: Criteria-Based Relevance Evaluation with Llama3 (https://arxiv.org/abs/2410.14044)
- **What's New**: 이 연구에서는 전통적인 정보 검색 시스템 평가 방법에서의 인적 주석의 필요성을 줄이기 위해, 대형 언어 모델(LLMs)을 활용하여 쿼리에 대한 관련성 라벨을 자동으로 생성하는 새로운 접근 방식을 제안합니다. 특히, 'Four Prompts' 방법론을 통해 세부 기준에 따라 패세지를 평가하고, 이 기준들을 통합하여 최종적인 관련성 라벨을 생성하는 방법에 대해 논의합니다.

- **Technical Details**: 연구는 두 가지 가설을 설정합니다. 첫 번째 가설은 관련성을 특정 기준(정확성(exactness), 범위(coverage), 주제 적합성(topicality), 맥락 적합성(contextual fit))으로 나누어 평가하면 최종 라벨 품질이 향상된다는 것입니다. 두 번째 가설은 쿼리와 패세지 간의 언어 스타일 차이가 자동 관련성 라벨 예측에 해를 끼칠 수 있다고 설정하며, 이를 해결하기 위해 쿼리 스타일에 맞춘 패세지 요약을 생성하여 관련성을 평가합니다.

- **Performance Highlights**: 본 연구는 Summer 2024에 LLMJudge 챌린지 데이터에 기초한 실증 평가를 실시했습니다. 그 결과 'Four Prompts' 접근 방식이 Kendall의 tau 상관 계수에서 가장 높은 점수를 얻었으며, 이를 통해 인간 평가자 간의 높은 일치도를 입증하였습니다. 또한, 이 연구에서 제안한 기준 기반 점수는 평가자에게 유용한 통찰을 제공하며, 패세지가 특정 관련성 판단을 받은 이유를 이해하는 데 도움을 줍니다.



### Latent Weight Diffusion: Generating Policies from Trajectories (https://arxiv.org/abs/2410.14040)
- **What's New**: 이 논문은 Latent Weight Diffusion (LWD)라는 새로운 방법론을 제안하여 로봇 작업을 위한 정책 분포를 학습하는 데 있어 기존의 작업 경로(diffusion trajectory) 기반 접근 방식을 새롭게 개선했습니다.

- **Technical Details**: LWD 방법은 데모 경로(demonstration trajectories)를 잠재 공간(latent space)으로 인코딩한 후, 이를 하이퍼 네트워크(hypernetwork)를 사용하여 정책으로 디코딩합니다. 이 과정에서 디퓨전 노이즈 제거 모델을 사용하여 잠재 공간 내의 분포를 학습합니다.

- **Performance Highlights**: Metaworld MT10 벤치마크에서 LWD는 일반적인 다중 작업 정책에 비해 성공률이 높고, 추론 과정에서 약 18배 더 작은 모델 크기를 유지하면서도 비슷한 성능을 보여줍니다. LWD는 장기 작업 행렬(action horizon)에서도 디퓨전 정책보다 더 우수한 성능을 보입니다.



### Ensemble-based, large-eddy reconstruction of wind turbine inflow in a near-stationary atmospheric boundary layer through generative artificial intelligenc (https://arxiv.org/abs/2410.14024)
Comments:
          30 pages, 15 figures

- **What's New**: 이 논문에서는 터빈의 실험에서 1초 단위의 역동성을 검증하기 위해 필요한 풍속의 정확한 재구성을 위한 새로운 기법을 소개합니다. 기존의 방법들보다 대형 와류 모형(large-eddy simulation model) 기반의 'large-eddy reconstruction' 기법이 개발되었습니다.

- **Technical Details**: 이 기술은 관측 데이터와 대기 모델 정보를 확산 모델 머신러닝 알고리즘을 통해 조합하여, 10분 관측 기간 동안의 확률적 재구성 집합을 생성합니다. 이를 통해 aeroelastic 코드나 대형 와류 시뮬레이션(large-eddy simulation)의 경계 조건으로 사용할 수 있습니다.

- **Performance Highlights**: 세 개의 합성 필드 캠페인에서 1초 단위 재구성 능력을 검증하였으며, 기반 진실 데이터를 바탕으로 한 재구성한 흐름의 속도는 0.20에서 0.85 사이의 피어슨 상관계수(Pearson correlation coefficient)로 긍정적인 상관관계를 보였습니다. 또한 실제 사례 연구를 통해 재구성된 풍속이 측정값과 유사하다는 것을 확인하였습니다.



### Vision-Language-Action Model and Diffusion Policy Switching Enables Dexterous Control of an Anthropomorphic Hand (https://arxiv.org/abs/2410.14022)
- **What's New**: 이번 연구에서는 언어 기반 명령을 수행하는 Vision-Language-Action (VLA) 모델과 확산 모델(diffusion model)의 장점을 결합한 하이브리드 제어 방법을 제안합니다. 이를 통해 로봇이 주어진 언어 명령을 기반으로 객체를 정확하게 집고 놓는 작업을 수행할 수 있도록 하였습니다.

- **Technical Details**: 제안된 하이브리드 구조는 사전 훈련된 openVLA 모델을 사용하여 고수준의 팔과 손 위치를 지정하고, 그립(grasp) 제어는 확산 정책 모델을 사용하여 다중 손가락 손에서 정교한 그립을 실행합니다. 이 실험은 총 13 자유도를 가진 ADAPT Hand 2 로봇 손을 이용하여 진행되며, 두 모델 간의 전환은 자동 신호 전환 메커니즘을 통해 이루어집니다.

- **Performance Highlights**: 하이브리드 모델을 통해 80% 이상의 성공률을 달성했으며, 이는 오직 VLA 모델만 사용할 때 40% 미만의 성공률과 비교됩니다. 이 연구는 다중 손가락 로봇 손에서 VLA 모델을 사용한 최초의 예시로, 다양한 환경 정보에 따라 그립 전략을 조정하고, 오류 복구 기능을 가지고 있습니다.



### Whisker-Inspired Tactile Sensing: A Sim2Real Approach for Precise Underwater Contact Tracking (https://arxiv.org/abs/2410.14005)
- **What's New**: 이번 연구에서는 수중에서 작동할 수 있는 새로운 유형의 수염 센서를 소개합니다. 이 센서는 Fiber Bragg Grating (FBG) 기술을 기반으로 하여, 로봇의 외부에 장착되어 주변 환경을 비침습적으로 감지합니다. 이 접근법은 시뮬레이션에서 현실로의 데이터 이전을 통해 높은 정확도로 접촉 지점을 추적할 수 있습니다.

- **Technical Details**: 이 연구에서 제안하는 수염 센서는 다중 FBG를 가진 단일 광섬유를 사용하여 데이터를 기록합니다. 새로운 신경망 모델은 과거의 센서 신호를 처리하여 다음 접촉 지점을 예측하며, 이를 위해 시뮬레이션 환경에서 생성된 대규모 데이터셋을 활용합니다. FBG는 고압 및 염수에서의 작동에 견딜 수 있도록 설계되었습니다.

- **Performance Highlights**: 실험 결과 이 방법은 대부분의 물체에 대해 <2 mm의 정확도로 접촉 예측을 달성했습니다. 이는 복잡한 수중 환경에서 로봇이 안전하게 작동할 수 있도록 도와줍니다. 또한, 이 방법은 이전에 보지 못한 물체에 대해서도 일반화됩니다.



### On the Learn-to-Optimize Capabilities of Transformers in In-Context Sparse Recovery (https://arxiv.org/abs/2410.13981)
- **What's New**: 이 논문은 Transformer가 in-context learning (ICL)뿐만 아니라 learning-to-optimize (L2O) 알고리즘을 수행할 수 있음을 증명합니다. 구체적으로, K-layer Transformer가 LASSO로 공식화된 ICL sparse recovery 작업을 수행할 수 있으며, K에 선형적인 수렴 속도를 보이는 것을 이론적으로 증명합니다. 이는 Transformer의 ICL 능력을 설명하는 새로운 관점을 제공합니다.

- **Technical Details**: Transformer는 ICL sparse recovery 문제를 처리하는 L2O 알고리즘을 구현할 수 있으며, K-layer Transformer의 수렴 속도는 K에 선형적입니다. 전통적인 L2O 알고리즘과 달리, 훈련 중 사용하는 측정 행렬이 테스트 중 측정 행렬과 일치할 필요 없이 다양한 ICL sparse recovery 작업을 수행할 수 있습니다. Transformers는 훈련 데이터에서 구조적 특징을 추출하여 ICL 수렴 속도를 가속화할 수 있습니다.

- **Performance Highlights**: 실험 결과, Transformer는 전통적인 gradient-descent 기반 반복 알고리즘보다 월등한 성능을 보였으며, 동일한 측정 행렬로 훈련 및 테스트된 L2O 알고리즘과 유사한 성능을 달성했습니다. 이러한 결과는 Transformer가 ICL 중 L2O 알고리즘을 구현할 수 있음을 뒷받침합니다.



### RecoveryChaining: Learning Local Recovery Policies for Robust Manipulation (https://arxiv.org/abs/2410.13979)
Comments:
          8 pages, 9 figures

- **What's New**: 이 논문에서는 복잡한 조작 문제를 해결하기 위해 계층적 강화 학습(hierarchical reinforcement learning) 기법인 RecoveryChaining을 제안합니다. 이 기법은 실패 감지 시 로봇이 회복 정책을 학습하도록 하여, 모델 기반(ex. model-based) 컨트롤러와 결합하여 복구할 수 있는 방법을 제공합니다.

- **Technical Details**: RecoveryChaining은 하이브리드 액션 스페이스(hybrid action space)를 사용하여 기본 로봇 동작(primitive robot actions)과 모델 기반 컨트롤러들에 대한 확장된 옵션(temporally extended nominal options)을 결합합니다. 이를 통해 모델 기반 컨트롤러로 전환하는 시점과 방법을 결정할 수 있습니다.

- **Performance Highlights**: 세 가지 다단계 조작 과제를 통해 제안된 접근 방식이 기존 방법보다 더 견고한 회복 정책을 학습할 수 있음을 보여주었습니다. 시뮬레이션에서 학습한 회복 정책을 물리적 로봇으로 성공적으로 전송하여 sim-to-real 전이의 가능성을 입증하였습니다.



### MarineFormer: A Transformer-based Navigation Policy Model for Collision Avoidance in Marine Environmen (https://arxiv.org/abs/2410.13973)
- **What's New**: 본 연구에서는 밀집 해양 환경에서의 무인 수상 차량(USV) 항법 문제를 다룹니다. 강한 흐름의 영향을 받는 복잡한 상황에서 기존의 항법 프로토콜은 충돌 방지 및 안전성을 보장하기에 충분하지 않음을 지적하며, `MarineFormer`라는 새로운 트랜스포머 기반의 정책 네트워크를 제안합니다.

- **Technical Details**: `MarineFormer`는 공간적 및 시간적 상호작용을 캡처하기 위해 attention mechanism을 활용하며, 강화 학습(RL)과 함께 교육됩니다. ‘spatio-temporal graph attention’ 구조를 사용하여 2D 난류 해양 조건을 시뮬레이션합니다. 또한, `marine environment`에서의 흐름 속도를 추정하는 방법과, 정적 및 동적 장애물을 탐지하기 위한 두 가지 유형의 센서를 사용하는 방법이 포함됩니다.

- **Performance Highlights**: 제안된 방법론은 동적 및 정적 장애물과의 상호작용을 고려하여 충돌 가능성을 줄이는데 성공적이며, 더욱 안정적인 경로를 제공합니다. 개선된 보상 모델을 통해 USV의 항법 성능을 향상시키며, 충돌 회피 및 목표 도달을 위한 최적 경로를 찾도록 돕습니다.



### Approximating Auction Equilibria with Reinforcement Learning (https://arxiv.org/abs/2410.13960)
- **What's New**: 본 논문은 복잡한 경매 문제를 해결하기 위한 새로운 접근 방식을 제안합니다. 전통적인 방법들이 계산적으로 불가능했던 복잡한 경매에서, 자기대결(self-play) 기반의 강화 학습( reinforcement learning) 방법론을 통하여 개선된 경매 전략을 발굴하고 Bayes-Nash 균형을 근사할 수 있습니다.

- **Technical Details**: 제안된 방법은 Proximal Policy Optimization과 Neural Fictitious Self-Play를 포함한 고급 알고리즘을 사용하여 연속적인 행동 공간과 고차원 정보 상태를 처리합니다. 이 알고리즘은 대칭적 및 비대칭적 가치, 개인 가치 및 상호 의존적 가치 등이 포함된 경매에서 강력하고 거의 최적의 입찰 전략을 학습할 수 있도록 합니다.

- **Performance Highlights**: 실험 결과, 제안된 알고리즘은 기존의 경매 문제 해결 방법들에 비해 더 효과적이며, 다양한 복잡성의 경매에서도 유효한 결과를 보여주었습니다. 연구는 단순한 경매에서의 순수 Nash 균형으로 수렴 가능성을 보여주며, 자기대결 방식을 통해 이러한 접근이 실제로 적용될 수 있음을 입증합니다.



### ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding (https://arxiv.org/abs/2410.13924)
- **What's New**: 이 논문에서는 ARKit LabelMaker라고 하는 최초의 대규모 실세계 3D 데이터셋을 소개합니다. 이 데이터셋은 촘촘한 의미론적 주석이 추가되어 있으며, ARKitScenes 데이터셋을 보완합니다.

- **Technical Details**: LabelMaker 자동 주석 파이프라인을 통해 ARKitScenes 데이터셋에 촘촘한 의미주석을 자동으로 생성하였고, 이를 통해 대규모 사전 학습이 가능하도록 개선했습니다.

- **Performance Highlights**: ARKitScenes 데이터셋의 자동 생성된 주석을 사용하여, 현재 가장 많이 사용되는 3D 분할 방법인 MinkowskiNet과 PTv3의 성능을 여러 벤치마크에서 향상시켰습니다.



### LLM Agent Honeypot: Monitoring AI Hacking Agents in the Wild (https://arxiv.org/abs/2410.13919)
- **What's New**: 이 논문에서는 LLM Honeypot 시스템을 소개하여 자율 AI 해킹 에이전트를 모니터링하는 새로운 방법론을 제안합니다. 사용자 맞춤형 SSH honeypot를 배포하고, 해킹 시나리오에서 LLM 기반 에이전트를 식별하기 위해 프롬프트 주입과 시간 분석을 결합하였습니다.

- **Technical Details**: 노출된 LLM 에이전트의 행동을 분석하기 위해 다양한 기술을 활용합니다. 기존의 프롬프트 주입 기법(예: '이전 지침 무시하고 X 수행하기')보다 '중요 메시지' 공격이 더 효과적임을 발견했습니다. 또한, LLM의 응답 속도를 고려한 시간 분석을 통해 LLM과 인간을 구별하는 데 도움을 줍니다.

- **Performance Highlights**: 몇 주간의 운영 시험에서 800,000건의 해킹 시도를 기록하고 6개의 잠재적 AI 에이전트를 탐지하였습니다. 향후 데이터 분석을 통해 LLM 해킹 행동을 더 깊이 이해하고, LLM 기반 공격 패턴을 식별할 계획입니다.



### Leveraging Fine-Tuned Language Models for Efficient and Accurate Smart Contract Auditing (https://arxiv.org/abs/2410.13918)
Comments:
          26 pages, 7 figures

- **What's New**: 본 논문은 스마트 계약(smart contract) 감사(auditing) 분야에서의 작은, 세밀하게 조정된 모델을 활용하여 효과적인 보안 취약점 탐지를 목표로 하는 새로운 FTSmartAudit 프레임워크를 소개합니다. 이 모델은 대규모 언어 모델(LLM)의 직면한 계산 요구 사항을 감소시키면서도 우수한 성능을 달성할 수 있도록 합니다.

- **Technical Details**: FTSmartAudit 프레임워크는 다음과 같은 주요 특징을 포함하고 있습니다: 단일 과제 학습(single-task learning) 프레임워크 구축, 도메인 전문 지식 증류(domain-special knowledge distillation)을 통한 고품질 데이터셋 생성, 적응형 학습(adaptive learning) 전략 고안, 특정 취약점 및 복잡한 논리 오류 탐지에 탁월한 세밀 조정된 모델의 효과 및 LLM 솔루션이 요구되는 다른 분야에의 확장성 확립.

- **Performance Highlights**: FTSmartAudit의 실험 결과, 작은 모델들이 기존 상용 모델 및 도구들을 초월하여 스마트 계약의 취약점을 효과적으로 탐지함을 입증하였습니다. 일반적으로 오탐되던 취약점을 정확하게 판별하며, 모델의 안정성과 실용성을 보여줍니다.



### A Simulation System Towards Solving Societal-Scale Manipulation (https://arxiv.org/abs/2410.13915)
- **What's New**: AI-driven manipulation의 위험 증가에 대응하기 위해 현실적인 사회적 상호작용을 모델링할 수 있는 시뮬레이션 환경을 소개합니다. Concordia 프레임워크와 Mastodon 서버를 통합하여 사회적 미디어 활동을 효과적으로 시뮬레이션하고, 이에 대한 방어선을 실험할 수 있는 도구를 제공합니다.

- **Technical Details**: Concordia 프레임워크를 기반으로 하여, Mastodon을 실제 사회적 상호작용 플랫폼으로 통합했습니다. 이 시뮬레이터는 에이전트의 정치적 입장을 추적하며, 파르티잔(Partisan) 조작이 선거 결과에 미치는 영향을 보여줍니다. 에이전트는 실제 소셜 미디어에서 상호작용하도록 설계되어 있으며, 효율적인 시뮬레이션을 위해 클라우드 인프라를 활용합니다.

- **Performance Highlights**: 현재 구현된 시스템은 20명의 에이전트로 24시간의 시뮬레이션을 2.5시간 이내에 수행하며, 비용은 약 10달러입니다. 이는 개선 이전의 8시간 이상 소요되는 시간을 70% 줄인 결과입니다. 최대 100명의 에이전트까지 확장이 가능하며 약 3시간 걸립니다.



### Large Language Model-driven Multi-Agent Simulation for News Diffusion Under Different Network Structures (https://arxiv.org/abs/2410.13909)
- **What's New**: 이 연구는 대규모 언어 모델(LLM)을 기반으로 하는 다중 에이전트 시뮬레이션을 통해 가짜 뉴스 확산을 모사하는 새로운 접근 방식을 소개하며, 기존의 에이전트 기반 시뮬레이션 기법과는 다른 방법론을 제시합니다.

- **Technical Details**: LLM 기반의 다중 에이전트 시뮬레이션 프레임워크는 사회적 네트워크 내의 상호작용을 모사하며, 에이전트의 성격과 네트워크 구조와 같은 주요 요인이 뉴스 전파에 미치는 영향을 조사합니다. 또한, 네트워크 구조에 따라 상이한 중재 전략의 효과를 평가합니다.

- **Performance Highlights**: 시뮬레이션 결과, LLM 기반 에이전트가 전통적인 기법에 비해 정보 확산의 근본 원인을 파악하는 데 유리하며, 정보 확산 과정에서 에이전트의 특성이 중요한 역할을 한다는 것을 입증하였습니다. 특히, 네트워크 구조에 따라 정보의 정확성을 공지하거나 영향력 있는 에이전트를 차단하는 것이 허위 정보를 줄이는 데 효과적이라는 것을 발견했습니다.



### P4GCN: Vertical Federated Social Recommendation with Privacy-Preserving Two-Party Graph Convolution Networks (https://arxiv.org/abs/2410.13905)
- **What's New**: 최근 그래프 신경망(GNNs)은 소셜 추천 시스템에서 자주 사용되고 있으나, 사용자 프라이버시 및 비즈니스 제약으로 인해 다른 플랫폼에서의 소셜 정보를 직접적으로 이용하기 어려운 문제가 있음. 이를 해결하기 위해 우리는 민감한 소셜 정보에 직접 접근하지 않고 추천 정확도를 향상시키는 새로운 수직 연합 소셜 추천 방법을 제안함.

- **Technical Details**: 제안된 방법인 P4GCN(Privacy-Preserving Party-to-Party Graph Convolution Networks)은 두 개의 파티 간의 협력적 데이터 처리 중 데이터 프라이버시를 보장하는 Sandwich-Encryption 모듈을 도입함. 이 방법은 GNN 모델을 최적화하기 위한 안전한 사회 추천 프로토콜을 개발하는 것을 목표로 함.

- **Performance Highlights**: 4개의 실제 데이터셋에서 실시한 실험 결과, P4GCN은 추천 정확도에서 최신 기술들을 초능가하며 통신 효율성 또한 향상됨을 입증함. 또한, 프라이버시 예산의 유틸리티에 미치는 영향에 대해서도 평가함.



### CoreGuard: Safeguarding Foundational Capabilities of LLMs Against Model Stealing in Edge Deploymen (https://arxiv.org/abs/2410.13903)
- **What's New**: 본 논문에서는 edge 장치에서 비공식 대형 언어 모델(Large Language Models, LLMs)의 보안을 강화하기 위한 새로운 접근법, CoreGuard를 제안합니다. 이 모델은 고유의 Foundational Capability Stealing 문제를 해결하면서도 효율성을 유지합니다.

- **Technical Details**: CoreGuard는 경량의 전파형 권한 부여 모듈(authorization module)을 Trusted Execution Environment (TEE)에 탑재하여 작동합니다. 이 접근법은 기존의 TEE 기반 방법의 단점을 보완하여, 계산 효율성과 커뮤니케이션 효율성을 동시에 달성합니다.

- **Performance Highlights**: CoreGuard는 동일한 보안 보장을 제공하면서도 소모되는 자원이 미세한 수준으로 줄어드는 것을 확인했습니다. 대규모 실험을 통해, CoreGuard가 edge LLM에 대한 모델 도용(protect model stealing)에 효과적이라는 점을 입증하였습니다.



### Security of and by Generative AI platforms (https://arxiv.org/abs/2410.13899)
- **What's New**: 이번 백서에서는 생성적 인공지능(Generative AI, genAI) 플랫폼의 보안 확보와 사이버 보안에서의 genAI 활용의 중요성을 강조합니다.

- **Technical Details**: 생성적 인공지능 기술이 급증함에 따라 데이터 유출(data breaches), 모델 변조(model tampering), 악의적인 콘텐츠 생성(malicious content generation) 등 심각한 위험이 발생하고 있습니다. 이러한 플랫폼을 보호하는 것은 민감 데이터 보호(data protection), 모델의 무결성(model integrity) 확보, 적대적 공격(adversarial attacks) 방지에 필수적입니다.

- **Performance Highlights**: 또한, genAI는 위협 탐지(threat detection), 취약점 분석(vulnerability analysis), 사건 대응(incident response)의 자동화를 통해 보안을 강화할 수 있는 기회를 제공합니다. 백서는 genAI 시스템 주위의 강력한 보안 프레임워크(security frameworks) 구축 전략을 탐구하며, 조직이 정교한 사이버 위협을 예측, 탐지 및 완화할 수 있도록 돕는 방법을 보여줍니다.



### Deep Learning Based XIoT Malware Analysis: A Comprehensive Survey, Taxonomy, and Research Challenges (https://arxiv.org/abs/2410.13894)
- **What's New**: 이 논문은 IoT 악성 코드 분석과 관련하여 딥러닝(deep learning) 기술의 도입을 포괄적으로 리뷰하고 있으며, Extended Internet of Things (XIoT) 도메인 전반에 걸쳐 주요한 심층 학습 기술을 소개합니다.

- **Technical Details**: 악성 코드 감지에는 머신러닝(machine learning)과 딥러닝 기술이 효과적이며, 이 논문에서는 IIoT(Industrial IoT), IoMT(Internet of Medical Things), IoV(Internet of Vehicles) 및 IoBT(Internet of Battlefield Things) 등 다양한 XIoT 도메인에서의 딥러닝 기반 악성 코드 분석 방법론에 대해 설명합니다.

- **Performance Highlights**: 딥러닝 기술은 복잡한 패턴을 자동으로 추출하여 검출 정확도를 높이고 수작업의 필요성을 줄이는 데 기여하였습니다. 실질적으로 이 기술을 적용한 여러 연구들이 있으며, 특히 IIoT 및 IoMT 분야에서의 악성 코드 공격과 이로 인해 발생하는 보안 문제를 해결하기 위한 구체적인 방안을 제시합니다.



### Can LLMs be Scammed? A Baseline Measurement Study (https://arxiv.org/abs/2410.13893)
- **What's New**: 이번 연구에서는 사기(scams)로부터의 저항력을 평가하기 위한 구조화된 프레임워크가 부족한 현행 연구의 공백을 해결하고, FINRA 세분화 기준(FINRA taxonomy)에 기반하여 37개의 잘 정의된 사기 시나리오를 사용하여 대형 언어 모델(LLMs)의 취약성을 체계적으로 평가했습니다.

- **Technical Details**: 이 연구에서는 GPT-3.5, GPT-4, Llama 등 세 가지 모델을 사용하여 사기 탐지 성능을 분석합니다. 또한 퍼소나(persona)의 특성과 설득 기법(persuasive techniques)이 LLM의 취약성에 미치는 영향을 조사합니다. Cialdini의 설득 원칙을 활용하여 222개의 시나리오 변형을 생성하였으며, 각 시나리오는 사기 기회의 약속에 대한 질문과 함께 평가되었습니다.

- **Performance Highlights**: 모델에 따라 각기 다른 취약성 패턴이 드러났으며, 이는 LLM 설계 및 배포에서의 맞춤형 개선 노력이 필요함을 강조합니다. 본 연구는 LLM들이 사기 탐지 역할을 수행할 때의 안전성과 유능함을 평가하는데 중대한 통찰을 제공합니다.



### S$^4$ST: A Strong, Self-transferable, faSt, and Simple Scale Transformation for Transferable Targeted Attack (https://arxiv.org/abs/2410.13891)
Comments:
          16 pages, 18 figures

- **What's New**: 본 논문은 Deep Neural Networks (DNNs)에 대한 Transferable Targeted Adversarial Attacks (TTAs)의 효율성을 높이기 위한 새로운 접근 방식을 제시합니다. 특히, 이미지 변환의 중요성을 강조하며, 기존의 손실 함수에 대한 의존 보다는 경량의 Gradient 기반 기법을 채택하였습니다.

- **Technical Details**: 연구팀은 기본적인 이미지 변환 기술을 이용하여 TTAs의 타겟 전이 가능성을 증가시키는 두 가지 효과적인 Blind Estimators를 개발하였습니다. Basic geometric transformations인 scaling과 rotation의 전이성이 highly correlated함을 발견했습니다. 또한, Scaling을 중심으로 하는 본 연구의 발전적인 방법인 Strong, Self-transferable, faSt, and Simple Scale Transformation (S4ST)을 소개하였습니다.

- **Performance Highlights**: S4ST 방법은 ImageNet-Compatible benchmark 데이터셋에서 SOTA 평균 타겟 전이 성공률을 달성하며, 이전 방법보다 14% 이상 향상되었으며, 실행 시간은 25%만 소모했습니다. 서적(black-box) 모델에 대한 효과성이 뛰어나며, 실제 비즈니스 API에서도 좋은 성과를 보였습니다.



### Transformers Utilization in Chart Understanding: A Review of Recent Advances & Future Trends (https://arxiv.org/abs/2410.13883)
- **What's New**: 최근 몇 년간 비전-언어(vision-language) 작업에 대한 관심이 증가하고 있으며, 특히 차트 상호작용(chart interactions)과 관련된 작업에 대한 연구가 활발히 진행되고 있습니다. 본 논문은 차트 이해(Chart Understanding, CU)에 있어 현재 사용되는 최첨단(transformer 기반) 솔루션들을 검토합니다.

- **Technical Details**: 본 연구에서는 변환기(transformer) 아키텍처를 사용한 다양한 CU 프레임워크를 분석하고, 이와 관련된 벤치마킹 데이터셋 및 평가 기법을 조명합니다. CU 작업은 인지적(task) 요구사항에 따라 세 가지 층으로 분류됩니다. 단일 작업(single-task) 및 다중 작업(multi-task) 프레임워크 간의 차이를 명확히 하고, 사전 훈련(pre-trained) 및 프롬프트 엔지니어링(prompt-engineering) 기술에 대해서도 다룹니다.

- **Performance Highlights**: 최근 연구에서 OCR 의존성, 저해상도 이미지 처리 및 시각적 추론 강화와 같은 주요 도전 과제가 제기되었습니다. 향후 연구 방향으로는 이러한 문제를 해결하고, 견고한 벤치마크를 개발하며, 모델 효율성을 최적화하는 것이 포함됩니다. 설명 가능한 AI 기술적 통합 및 실데이터와 합성데이터 간의 균형 탐색도 CU 연구의 발전에 필수적입니다.



### Deep Knowledge Tracing for Personalized Adaptive Learning at Historically Black Colleges and Universities (https://arxiv.org/abs/2410.13876)
- **What's New**: 본 연구는 Historically Black Colleges and Universities (HBCUs)에서 STEM 교육을 위한 Personalized Adaptive Learning (PAL) 구현을 조사하기 위해 다루지 않았던 Deep Knowledge Tracing (DKT)에 대한 새로운 데이터를 수집하고 분석합니다. 연구는 Prairie View A&M University (PVAMU)의 17,181명의 학부생에 대한 352,148개의 학습 기록을 포함합니다.

- **Technical Details**: 사용된 최신 DKT 모델로는 DKT, DKT+, DKVMN, SAKT 및 KQN이 있으며, 이들 모델은 다수를 대상으로 학생들의 성과 예측 정확성을 평가하기 위해 적용되었습니다. DKT는 심층 학습 알고리즘을 통해 학생 상호작용 데이터를 분석하는 기법으로, 명확한 지식 추적을 가능하게 합니다.

- **Performance Highlights**: SAKT 및 KQN 모델이 다른 모델에 비해 정확성과 AUC (Area Under the Curve) 측면에서 우수한 성능을 나타냈습니다. 이 연구 결과는 교수진과 학업 상담자에게 학기 종료 전에 학업 부진 위험 학생을 식별하여 사전 개입을 통해 학생들의 학업 진행을 지원할 수 있는 귀중한 통찰력을 제공합니다.



### Explaining an image classifier with a generative model conditioned by uncertainty (https://arxiv.org/abs/2410.13871)
- **What's New**: 본 논문에서는 이미지 분류기(image classifier)의 불확실성(uncertainty)을 통해 생성 모델(generative model)을 조건화하는 새로운 접근 방식을 제안합니다. 이를 통해 이미지 분류기의 행동을 분석하고 설명할 수 있습니다.

- **Technical Details**: 이 연구는 합성 데이터(synthetic data)와 왜곡된 MNIST 데이터셋(MNIST dataset)의 예비 실험(preliminary experiments)을 통해 아이디어를 검증합니다. 생성 모델은 이미지 분류기의 출력을 바탕으로 조건화되며, 이는 불확실성 정보를 통합하여 더 나은 설명 가능성을 제공합니다.

- **Performance Highlights**: 초기 실험 결과는 제안된 방법이 기존 접근 방식보다 이미지 분류기 분석에서 유용함을 보여줍니다.



### Associative memory and dead neurons (https://arxiv.org/abs/2410.13866)
- **What's New**: 이번 연구에서는 Krotov와 Hopfield가 제안한 에너지 함수의 문제점을 해결하기 위해, 죽은 뉴런(dead neurons)과 관련된 평탄한 방향(flat direction)의 문제를 조명합니다. 연구팀은 이를 극복하기 위해 다소 수정된 동적 시스템을 제안하며, 이 시스템은 기존 시스템의 좋은 속성을 유지하면서도 평탄한 방향이 없도록 설계되었습니다.

- **Technical Details**: 연구에서는 에너지 함수와 해시안 행렬(Hessian matrix)을 분석하여 죽은 뉴런에 대한 여러 단점을 다룹니다. 동적 시스템의 상태 벡터는 (i) 에너지와 해시안 행렬로부터 추출할 수 있으며, (ii) 해시안 행렬의 범위에서 안정성을 분석하는 것이 충분합니다. (iii) 안정된 평형 상태가 평탄한 영역에 접해 있으면, 전체 평탄한 영역이 유인력의 저수지가 됩니다.

- **Performance Highlights**: 저자들은 수정된 동적 시스템을 통해 죽은 뉴런에 대응하는 평탄한 방향이 없는 에너지 함수의 다양한 패밀리를 도출할 수 있음을 보여주었습니다. 이 새로운 에너지 함수는 비대칭 피드포워드 및 피드백 연결과 같은 비정형 구조에서도 기존의 Lagrange 함수와 함께 사용할 수 있습니다.



### AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents (https://arxiv.org/abs/2410.13825)
- **What's New**: 이 연구는 LLM(대형 언어 모델)을 기반으로 한 웹 에이전트를 개선하기 위한 혁신적인 접근 방식을 제안합니다. 구체적으로, 에이전트의 관찰(object) 및 행동(action) 공간을 정제하여 LLM의 능력에 더욱 잘 부합하도록 합니다.

- **Technical Details**: 제안된 방법은 세 가지 구성 요소로 이루어져 있습니다: 1) 필수적이지 않은 행동을 줄여 에이전트의 기능을 단순화; 2) 중복되거나 불필요한 웹 요소를 제거하여 관찰을 개선; 3) 'branch' 및 'prune'와 같은 두 가지 계획 행동을 도입하여 에이전트의 내비게이션 흐름을 자기 조직화 합니다.

- **Performance Highlights**: AgentOccam는 WebArena 벤치마크에서 기존의 최첨단 방법보다 9.8 포인트 (+29.4%) 향상된 성능을 보이고, 유사한 일반 웹 에이전트에 비해 성공률을 26.6 포인트 (+161%) 증가시켰습니다. 이 모든 것을 추가적인 맥락 예제, 온라인 피드백 또는 검색 전략 없이 달성했습니다.



### A Pattern to Align Them All: Integrating Different Modalities to Define Multi-Modal Entities (https://arxiv.org/abs/2410.13803)
Comments:
          20 pages, 6 figures

- **What's New**: 이 논문에서는 엔티티(개체)와 그 정보의 의미를 다양한 매체를 통해 표현할 수 있는 개념적 패턴을 제안합니다. Multi-Modal Knowledge Graphs(MMKGs)는 텍스트, 이미지, 오디오, 비디오 등 다양한 모달리티(modality)를 통한 정보의 통합을 촉진하기 위한 새로운 접근 방식을 제시합니다.

- **Technical Details**: 이 연구는 정보 엔티티(IE)와 그 정보의 물리적 실현(Information Realisation, IR) 간의 개념적 구분을 도입하여 다중 모달리티 이해를 위한 온톨로지 설계 패턴을 제안합니다. 이를 통해 다양한 형식으로 구현되는 정보 리소스 간의 관계를 명확히 하며, MMKG의 다양한 기존 온톨로지와의 조화를 위한 기초를 마련합니다.

- **Performance Highlights**: 제안된 패턴은 현재의 MMKG 리소스에 적용 가능성이 높으며, 기존의 온톨로지와의 조화를 이끌어내어 지능형 응용 프로그램이 요구하는 국소적 및 맥락적 정보 표현을 강화합니다.



### Transformer Guided Coevolution: Improved Team Formation in Multiagent Adversarial Games (https://arxiv.org/abs/2410.13769)
- **What's New**: BERTeam은 다중 에이전트 적대적 게임에서 최적의 팀을 형성하기 위한 혁신적인 알고리즘으로, 변환기 기반의 심층 신경망을 사용하여 에이전트의 조합을 선택합니다.

- **Technical Details**: BERTeam은 Masked Language Model 훈련 방법을 이용하여 팀 구성원을 예측하며, coevolutionary deep reinforcement learning을 통해 다양한 개인 에이전트를 진화시킵니다. 이를 통해 팀의 성능을 극대화하는 팀 선택 과정을 간소화합니다.

- **Performance Highlights**: Marine Capture-The-Flag 게임에서 BERTeam은 MCAA와 같은 기존 알고리즘을 초월하여 성능을 발휘하며, 비정형 팀 구성 방법을 학습하여 보지 못한 상대에 대해서도 잘 대응합니다.



### MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures (https://arxiv.org/abs/2410.13754)
- **What's New**: 이 논문은 다양한 형태의 입력 및 출력을 지원하는 새로운 벤치마크인 MixEval-X를 소개하여, AI 모델의 평가 방식을 최적화하고 표준화하는 데 중점을 두고 있습니다. 이를 통해 실제 작업 배포에 맞는 평가가 가능하게 됩니다.

- **Technical Details**: MixEval-X는 any-to-any (모든 입력에 대해 가능한 모든 출력) 형식의 벤치마크로, 다양한 modality (양식) 간의 평가 일관성을 높이기 위해 multi-modal (다중 양식) 벤치마크 혼합 및 adaptation-rectification (적응-정정) 파이프라인을 제안합니다. 이 방법은 평가가 실제 사용할 수 있는 사례에 잘 일반화되도록 합니다.

- **Performance Highlights**: 종합적인 메타 평가 결과, MixEval-X는 벤치마크 샘플과 실제 작업 배포 간의 효과적인 정렬을 보여주었으며, 모델 순위는 크라우드 소싱된 실제 평가와 강한 상관관계를 나타냅니다 (상관 계수 0.98까지). 또한, 기존 모델 및 조직을 재순위화할 수 있는 포괄적인 리더보드를 제공하여 다중 양식 평가에 대한 이해를 높이고 향후 연구에 대한 통찰을 제공합니다.



### Disjointness Violations in Wikidata (https://arxiv.org/abs/2410.13707)
Comments:
          Sixth International Knowledge Graph and Semantic Web Conference

- **What's New**: 이 논문은 Wikidata에서의 불일치 체크(disjointness checks)의 현재 모델링을 분석하고, 이를 통해 발생하는 불일치 위반(disjointness violations)의 패턴과 원인을 확인하였습니다. SPARQL 쿼리를 사용해 각각의 원인을 규명하고, 서로 충돌하는 정보를 식별 및 수정할 수 있는 공식을 제시합니다.

- **Technical Details**: Wikidata는 1억 개 이상의 객체를 포함하는 대규모 지식 그래프입니다. 본 논문에서는 RDF(리소스 기술 프레임워크)를 사용하여 Wikidata에서 쌍별 불일치 클래스(pairwise disjoint classes)의 정보를 수집하였습니다. SPARQL 쿼리를 작성하여 불일치 유니온 문장(disjoint union statements)의 쌍을 찾아내었습니다.

- **Performance Highlights**: 논문에서 제안한 방식은 불일치 상황을 정량화하고, 성능을 개선하여 사용자가 문제를 식별하고 수정하는 효율성을 높이는 데 기여할 수 있습니다. 총 758개의 불일치 유니온 문장이 631개 클래스에서 생성되었으며, 7,027개의 쌍별 불일치 문장(pairwise disjoint statements)이 도출되었습니다.



### MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling (https://arxiv.org/abs/2410.13610)
- **What's New**: 이번 논문에서는 LLMs(대형 언어 모델)와 의료 분야의 복잡한 문제를 해결하기 위한 새로운 프레임워크인 MeNTi를 소개합니다.

- **Technical Details**: MeNTi는 LLMs를 위한 보편적인 에이전트 아키텍처로, 전문화된 의료 도구 세트를 통합하고 메타 도구(meta-tool) 및 중첩 호출(nested calling) 메커니즘을 사용하여 LLM 도구 활용을 강화합니다. 이를 통해 유연한 도구 선택 및 중첩 도구 호출이 가능해지며, 계산기 선택, 슬롯 채우기(slot filling), 단위 변환을 포함한 복잡한 의료 시나리오 문제를 해결합니다.

- **Performance Highlights**: CalcQA라는 벤치마크를 통해 LLM의 정량적 평가 능력을 검증하며, 100개의 사례-계산기 쌍과 281개의 의료 도구가 포함된 도구 키트를 통해 실험 결과에서 상당한 성능 개선을 보여주었습니다.



### Instruction-Driven Game Engine: A Poker Case Study (https://arxiv.org/abs/2410.13441)
Comments:
          EMNLP 2024 Demo. arXiv admin note: substantial text overlap with arXiv:2404.00276

- **What's New**: 이드제(Instruction-Driven Game Engine, IDGE) 프로젝트는 사용자들이 자연어 지시를 통해 게임을 쉽게 생성할 수 있도록 하여 게임 개발의 진입 장벽을 낮추는 것을 목표로 하고 있습니다. 기존의 게임 엔진들이 프로그래밍 언어에 의해 구동되는 것과는 달리, IDGE는 사용자와의 상호작용을 통해 게임 상태를 동적으로 생성합니다.

- **Technical Details**: IDGEs는 사용자 지정 게임 스크립트에 따라 게임 상태를 예측하는 Next State Prediction(다음 상태 예측) 작업에 기반하여 설계되었습니다. 이는 아키텍처에 대화형 LLMs(large language models)를 포함하여 사용자 입력을 반영하여 실시간 게임 정보가 포함된 게임 상태를 생성합니다. 모델은 커리큘럼 학습 방식을 통해 안정성과 다양성을 동시에 고려하여 훈련됩니다.

- **Performance Highlights**: 초기 연구 결과로, IDGE는 포커(Poker) 게임을 위한 새로운 엔진으로 발전하였으며, 이는 다양한 포커 변형을 지원하며, 사용자 입력을 통해 한층 개인화된 포커 게임을 생성하는 데 성공했습니다. IDGE는 새로운 카드 조합과 전투 전략을 처리하는 데에도 뛰어난 일반화 능력을 보입니다.



### Mitigating Hallucinations in Large Vision-Language Models via Summary-Guided Decoding (https://arxiv.org/abs/2410.13321)
- **What's New**: 이번 연구에서는 LVLMs에서 나타나는 언어 priors의 문제를 해결하기 위해 새로운 방법인 Summary-Guided Decoding (SGD)를 제안합니다. SGD는 이미지 정보에 더 집중하도록 모델을 유도하며, 텍스트 품질을 유지합니다.

- **Technical Details**: 연구는 LVLMs에서의 언어 priors를 분석하고, 이미지 관련 부분의 품사(POS)와 연관된 토큰을 생성할 때 언어 priors에 대한 모델의 의존도가 증가함을 발견했습니다. SGD는 요약(context) 기법을 활용하여 이미지 관련 POS 토큰의 다음-토큰 확률을 수정하여 텍스트 품질을 최대한 보존하면서 이미지 정보를 반영합니다.

- **Performance Highlights**: SGD는 객체 환각(object hallucination) 벤치마크에서 모든 다른 해석 방법을 초월했으며(CHAIRS에서 +16.5%, CHAIRI에서 +19% 향상), 정밀도와 재현율의 균형을 잘 유지하며 Pareto optimal성을 달성했습니다. 또한 텍스트 품질을 거의 완벽하게 유지하면서 객체 환각을 줄이는 데 강력한 성과를 보였습니다.



### A Simplifying and Learnable Graph Convolutional Attention Network for Unsupervised Knowledge Graphs Alignmen (https://arxiv.org/abs/2410.13263)
Comments:
          14 pages, 3 figures

- **What's New**: 최근의 연구에서는 Entity Alignment (EA) 작업의 성공이 레이블이 붙은 데이터에서 제공되는 감독 정보에 크게 의존하고 있음을 강조합니다. 그러나 레이블된 데이터의 비용을 고려할 때 이러한 방법의 실용성은 제한적입니다. 따라서, 본 논문에서는 Unsupervised Knowledge Graphs alignment를 위한 Simplifying and Learnable graph convolutional attention network (SLU)를 제안합니다.

- **Technical Details**: SLU는 LCAT라는 새로운 그래프 신경망(GNN)을 백본 네트워크로 사용하여 Knowledge Graph (KG)의 그래프 구조를 모델링합니다. SLU는 잠재적 매칭 관계를 바탕으로 관계 구조를 재구성하는 방법을 설계하여 잘못된 이웃 정보를 필터링하고, 유사성을 측정하기 위해 일관성 기반의 유사성 함수를 제안합니다.

- **Performance Highlights**: SLU는 세 가지 데이터셋 (15K 및 100K)에서 광범위한 실험을 수행한 결과, 25개의 감독 또는 비감독 방법들을 초월하여 정렬 정확도를 유의미하게 향상시켰습니다. 가장 좋은 경우에서 Hits@1 점수가 6.4% 향상되었습니다.



### Research on Travel Route Planing Problems Based on Greedy Algorithm (https://arxiv.org/abs/2410.13226)
- **What's New**: 이 연구에서는 초기 경로 탐색 및 관광객의 개인화 요구를 충족하는 최적화된 경로 계획 알고리즘이 제안되었습니다. 특히, PCA(Principal Component Analysis) 및 KMO(Kaiser-Meyer-Olkin) 테스트와 TOPSIS(TOPSIS: Technique for Order Preference by Similarity to Ideal Solution) 기법을 통해 도시 평가 지표의 차원 축소 및 종합 평가를 수행했습니다.

- **Technical Details**: 연구에서는 PCA를 사용하여 도시 평가 지표의 차원을 축소하고, KMO 테스트를 통해 데이터 적합성을 판단하고, TOPSIS 및 엔트로피 가중치 방법을 통해 데이터를 종합 평가했습니다. 경로 최적화를 위해서는 그리디 알고리즘이 사용되었으며, 관광 명소 방문에 소요되는 시간을 고려한 경로 계획이 이루어졌습니다.

- **Performance Highlights**: 이 알고리즘은 352개의 도시에서 100개의 관광 명소 데이터를 활용하여 관광객에게 최적화된 여행 경로를 제공함으로써 여행 비용을 줄이고 현지 최적해(local optimum) 문제를 피하는 데 기여합니다. 결과적으로 관광객의 요구에 맞춘 맞춤형 경로 계획을 통해 효율적인 여행 경험을 지원합니다.



### Anchored Alignment for Self-Explanations Enhancemen (https://arxiv.org/abs/2410.13216)
- **What's New**: 본 연구에서는 언어 모델의 자기 설명(self-explanation) 능력을 향상시키기 위해 주석이 달린 이유 설명이 없는 경우에도 이들의 사고 내용을 명확히 서술하는 방식으로 모델 정렬(alignment) 방법론을 제안합니다.

- **Technical Details**: 본 방법론은 설명 품질 평가(explanation quality assessment), 자기 지시 데이터셋 생성(self-instruction dataset generation), 모델 정렬(model alignment)이라는 세 가지 핵심 요소로 구성됩니다. 특히, 'Anchor Preference Pairs'라는 새로운 기술을 도입하여 모델 출력을 일관되게 정확한 것, 일관되게 부정확한 것, 가변적인 것으로 세 가지 범주로 분류하여 선호 쌍(preference pairs) 선택을 개선합니다. 이를 통해 Direct Preference Optimization (DPO) 전략의 효과성을 증대시킵니다.

- **Performance Highlights**: 실험 결과, 본 접근법은 다른 fine-tuning 전략과 비교할 때 설명 품질을 유의미하게 개선하면서도 정확성을 유지하는 것으로 나타났습니다. 특히, Anchor Preference Pairs를 활용한 방법론이 Judge 기반 평가에만 의존한 자기 정렬 전략보다 더욱 우수한 성능을 보이는 것을 입증했습니다.



### LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch (https://arxiv.org/abs/2410.13213)
- **What's New**: LLMOPT라는 통합 학습 기반 프레임워크를 제안하여 최적화 문제의 일반화 능력을 향상시켰습니다. 이 프레임워크는 자연어 설명으로부터 최적화 문제를 정의하고 해결하는 과정을 자동화하는 데 중점을 두고 있습니다.

- **Technical Details**: LLMOPT는 다섯 가지 요소로 구성된 포뮬레이션을 통해 다양한 최적화 문제 유형을 정의하고, 다중 지침 튜닝(multi-instruction tuning) 및 모델 정렬(model alignment)으로 정확성과 일반성을 향상시킵니다. 또한 자동 테스트(auto-testing)와 자기 수정(self-correction) 메커니즘을 통해 hallucinations를 방지합니다.

- **Performance Highlights**: LLMOPT는 20개 분야에서 6개의 실제 데이터셋을 대상으로 평가된 결과, 선형/비선형 프로그래밍, 혼합 정수 프로그래밍 및 조합 최적화와 같은 다양한 최적화 문제를 처리하며 최신 방법보다 평균 11.08%의 해결 정확도 향상을 달성했습니다.



### Context-Enhanced Multi-View Trajectory Representation Learning: Bridging the Gap through Self-Supervised Models (https://arxiv.org/abs/2410.13196)
- **What's New**: MVTraj는 다중 시각의 맥락을 통합하여 경로 표현 학습을 향상시키는 새로운 방법을 제안합니다. GPS, 도로 네트워크 및 POI(관심 지점)의 다양한 맥락적 지식을 활용하여 경로 데이터에 대한 보다 포괄적인 이해를 제공합니다.

- **Technical Details**: MVTraj는 GPS 경로를 연결 고리로 사용하고 셀프 슈퍼바이즈드(자기지도학습) 프리텍스트(사전학습) 작업을 통해 다중 시각 간 학습 프로세스를 정렬합니다. 3개의 다양한 시각(예: GPS, 도로 경로 및 그리드)의 경로를 다루는데, 각 시각에서 독립적인 모달리티로 간주하고 계층적 크로스 모달 상호작용 모듈을 적용하여 지식을 융합합니다.

- **Performance Highlights**: 실제 데이터셋을 활용한 폭넓은 실험 결과, MVTraj는 다양한 공간 시각과 관련된 작업에서 기존의 기준선 모델에 비해 현저한 성능 향상을 보여줍니다.



### Chain of Ideas: Revolutionizing Research in Novel Idea Development with LLM Agents (https://arxiv.org/abs/2410.13185)
Comments:
          10 pages,5 figures, conference

- **What's New**: 이 논문은 Chain-of-Ideas (CoI) 에이전트를 통해 대형 언어 모델(LLMs)이 연구 아이디어 생성의 효율성을 개선할 수 있는 새로운 방안을 제안합니다. CoI 에이전트는 관련 문헌을 체계적으로 정리하여 연구 분야의 발전을 잘 반영하도록 돕습니다.

- **Technical Details**: CoI 에이전트는 (1) CoI 구성, (2) 아이디어 생성, (3) 실험 설계의 세 가지 단계로 구성됩니다. 각 단계에서 LLM은 연구 분야의 다양한 트렌드를 반영하여 복수의 CoIs를 구축하고, 각 CoI에 대해 예측 및 아이디어를 체계적으로 발전시키는 과정을 거칩니다.

- **Performance Highlights**: 실험 결과에 따르면 CoI 에이전트는 여러 자동화된 방법보다 항상 높은 성능을 보였으며, 사람의 연구 아이디어 생성 품질과도 비교 가능한 결과를 나타냈습니다. CoI 에이전트는 아이디어 생성에서 56 ELO 점수 차이로 두 번째 방법을 초월했습니다.



### Language Models as Semiotic Machines: Reconceptualizing AI Language Systems through Structuralist and Post-Structuralist Theories of Languag (https://arxiv.org/abs/2410.13065)
Comments:
          18 pages, 2 figures

- **What's New**: 이 논문은 대형 언어 모델(LLM)을 인간의 인지 과정을 모방하는 것으로 보지 않고, 기호학적 기계(semiotic machines)로 재구성하여 이해하는 새로운 프레임워크를 제안합니다. 저자는 페르디낭 드 소쉬르(Ferdinand de Saussure)와 자크 데리다(Jacques Derrida)의 언어 이론에 기초하여 LLM을 언어 자체의 모델로 설명하고 있습니다.

- **Technical Details**: 논문은 세 부분으로 나뉘어 있으며, 첫 번째 부분에서는 word2vec 임베딩 알고리즘의 작동 방식과 소쉬르의 기호 체계에 대한 설명을 제공합니다. 두 번째 부분에서는 데리다의 비판을 적용하여 LLM이 모델링하는 '쓰기'의 개념을 논의합니다. 마지막 세 번째 부분에서는 현대 LLM이 의미의 고정되지 않은 개념을 어떻게 반영하는지에 대해 설명하며, '다음 토큰 생성' 메커니즘이 의미의 역동성을 포착한다고 주장합니다.

- **Performance Highlights**: 대형 언어 모델은 언어 사용에서 거의 인간의 수준에 도달하며, word2vec 알고리즘을 기반으로 하여 컨텍스트 기반의 의미 표현을 채택하고 있습니다. 이러한 모델은 개별 단어뿐만 아니라 문장 및 다른 언어 구조를 포함한 복잡한 표현을 생성하려고 하며, 현재 사용되는 데이터셋은 방대한 양의 정보를 포함하고 있어, LLM이 언어 자체에 근접한 모델링을 가능하게 합니다.



### Optimal Transport for Probabilistic Circuits (https://arxiv.org/abs/2410.13061)
- **What's New**: 이 논문에서는 확률 회로(Probabilistic Circuits, PCs) 간의 Wasserstein distance를 계산하기 위한 최적 운송 프레임워크를 도입합니다. 기존에 알려진 알고리즘은 있었으나, 확률 회로로 정의된 분포 간의 Wasserstein distance를 계산하는 방법은 처음으로 제안됩니다.

- **Technical Details**: Wasserstein-type distance를 도입하여 연관된 최적 운송 문제의 coupling measure를 확률 회로로 제한합니다. 이 거리를 계산하기 위해 작은 선형 프로그램(solution to linear programming problems) 문제를 해결하는 알고리즘을 개발하였으며, 이 문제의 해결조건을 제시합니다. 또한, 실험적 데이터를 기반으로 한 PC와의 Wasserstein distance를 최소화하기 위한 효율적인 반복 알고리즘을 제공합니다.

- **Performance Highlights**: 제안된 알고리즘은 두 확률 회로 간의 Wasserstein-type distance를 정확하고 효율적으로 계산할 수 있는 기능을 갖추고 있으며, 이를 기존 방법론과 비교하여 실험적으로 우수한 성능을 보입니다.



### Hypothesis Testing the Circuit Hypothesis in LLMs (https://arxiv.org/abs/2410.13032)
Comments:
          Code available here: this https URL

- **What's New**: 이번 연구에서는 대규모 언어 모델(LLMs)의 내부 작동 방식을 이해하기 위해 '회로(circuits)'라는 개념을 실험적으로 조사했습니다. 특히 회로가 LLM의 능력을 구현하는지를 테스트하기 위한 기준과 가설 검정 방식이 소개되었습니다.

- **Technical Details**: 연구에서는 다음 세 가지 이상적인 속성을 정의했습니다: 1) 메커니즘 보존(Mechanism Preservation): 회로의 성능이 원래 모델과 일치해야 함. 2) 메커니즘 지역화(Mechanism Localization): 회로를 제거하면 해당 작업을 수행하는 능력이 사라져야 함. 3) 최소성(Minimality): 회로에 중복된 엣지가 없어야 함. 이 속성에 따라 6개의 회로를 평가했습니다.

- **Performance Highlights**: 합성 회로(synthetic circuits)는 이상적인 속성과 잘 일치하는 반면, 발견된 회로는 모든 속성에 엄격히 부합하지 않았습니다. 그러나 특정 발견된 회로는 유명한 작업을 수행하는 데 중요한 역할을 했으며, 이들 회로는 이상적인 특성에 근접하게 개선될 수 있는 가능성을 보여주었습니다.



### Learning Representations for Reasoning: Generalizing Across Diverse Structures (https://arxiv.org/abs/2410.13018)
Comments:
          PhD thesis

- **What's New**: 이 논문은 인공지능 분야에서의 추론의 중요성과 관련하여, 기존의 지식 구조 및 쿼리 구조를 초월하는 일반화 알고리즘을 제안합니다. 또한, 구조적 데이터에서 기계 학습 개발을 가속화하기 위한 시스템을 구축했습니다.

- **Technical Details**: 제안된 모델 NBFNet은 전통적인 경로 기반(path-based) 방법과 동적 프로그래밍(dynamic programming)을 결합하여 새로운 엔티티(entity) 및 관계(relation) 어휘를 사용한 지식 그래프의 미지의 부분에 대한 유도 일반화를 실현합니다. A*Net은 NBFNet의 확장형으로, 수백만 개 규모의 지식 그래프에서도 우수한 성능을 발휘합니다.

- **Performance Highlights**: NBFNet은 기존의 최신 방법들에 비해 모든 설정에서 평균 18%의 성능 향상을 이루었으며, 특히 지식 그래프 완성(HITS@1) 및 유도 관계 예측(HITS@10)에서 각각 22%의 성능 개선을 보여줍니다.



### Large Language Models as a Tool for Mining Object Knowledg (https://arxiv.org/abs/2410.12959)
- **What's New**: 이번 연구는 대형 언어 모델(LLMs)이 일반 물체에 대한 명시적 지식을 공식화하는 능력을 조사하며, 물체의 구성 요소(부분) 및 재질에 대한 지식을 명확히 구분합니다. 이로 인해 LLMs의 잠재력을 이용하여 AI 시스템의 지식 기반을 보강하거나 대체하는 데 기여할 수 있습니다.

- **Technical Details**: 이 연구에서는 few-shot과 zero-shot multi-step 프롬프트 기법을 활용하여 약 2,300개의 물체 및 하위 유형에 대한 부품과 재질에 대한 데이터를 수집합니다. LLM의 언어 이해 능력을 통해 물체의 전체 구성과 부품의 재질에 대한 지식을 명확히 정리합니다.

- **Performance Highlights**: 평가 결과, 추출된 지식의 대부분이 인간의 이해와 일치하나, 프롬프트 기법에 따라 과도하게 단순화되거나 필요 이상의 세부 정보가 제공되는 경우도 있음을 보여줍니다. 이 연구는 물체 구조 및 구성에 대한 추론을 위한 유용한 자원으로서 기능할 것입니다.



### MIND: Math Informed syNthetic Dialogues for Pretraining LLMs (https://arxiv.org/abs/2410.12881)
Comments:
          31 pages, 5 figures, 14 tables

- **What's New**: 이번 연구에서는 대규모 다채로운 Math Informed syNthetic Dialogue (MIND) 생성 방법을 제안하여 대형 언어 모델(LLMs)의 수학적 추론 능력을 향상시키는 것을 목표로 합니다.

- **Technical Details**: MIND를 활용하여 OpenWebMath (OWM)를 기반으로 합성 대화를 생성하고, 이를 통해 새로운 수학 데이터셋인 MIND-OWM을 만듭니다. 실험 결과, 대화 참여자 간의 지식 격차를 포함하는 것이 고품질 수학 데이터를 생성하는 데 필수적임을 보여줍니다. 또한, 합성 데이터와 원본 데이터를 사전 학습(pretraining) 시 효과적으로 포맷하고 통합하는 방법을 식별하였습니다.

- **Performance Highlights**: MIND-OWM에서 사전 학습된 모델은 원본 데이터만으로 사전 학습된 모델 대비 수학적 추론에서 상당한 향상을 보였습니다 (GSM8K: +13.42%, MATH: +2.30%). 또한, 전문 지식(MMLU: +4.55%, MMLU-STEM: +4.28%) 및 일반적인 추론 과제(GENERAL REASONING: +2.51%)에서도 우수한 성능을 기록했습니다.



### IMAS: A Comprehensive Agentic Approach to Rural Healthcare Delivery (https://arxiv.org/abs/2410.12868)
- **What's New**: COVID-19 이후, 농촌 지역의 의료 접근성 문제 해결을 위한 첨단 의료 보조 시스템(IMAS) 제안

- **Technical Details**: IMAS는 Large Language Models (LLMs)와 다섯 가지 주요 구성 요소(번역, 의료 복잡성 평가, 전문가 네트워크 통합, 최종 의료 조언 생성, 응답 단순화)로 구성되어 있습니다.

- **Performance Highlights**: IMAS는 MedQA, PubMedQA, JAMA 데이터셋을 통해 효과성을 입증하였으며, 특히 저소득 및 정보 소외 지역사회의 의료 근로자들에게 더 쉽게 접근할 수 있도록 지원합니다.



### Interpretable Rule-Based System for Radar-Based Gesture Sensing: Enhancing Transparency and Personalization in AI (https://arxiv.org/abs/2410.12806)
Comments:
          accepted at the 21st European Radar Conference, 4 pages, 2 figure

- **What's New**: 본 연구에서는 레이더 기반 제스처 감지를 위한 투명하고 해석 가능한 다중 클래스 규칙 기반 알고리즘인 MIRA를 소개합니다. AI의 이해 가능성이 중요한 분야에서 MIRA는 사용자의 신뢰를 높이기 위해 의사 결정 프로세스에 대한 통찰력을 제공합니다.

- **Technical Details**: MIRA는 개인 맞춤형 규칙 세트를 통해 개별 사용자 행동에 조정되며, 사용자 중심의 AI 경험을 제공합니다. 이 연구에서는 새로운 다중 클래스 분류 아키텍처를 제시하고, 방대한 주파수 변조 연속파 레이더 제스처 데이터 세트를 공유하며, 시스템의 뛰어난 해석 가능성을 입증하는 비교 분석 결과를 보여줍니다.

- **Performance Highlights**: MIRA는 높은 해석 가능성과 성능을 동시에 제공하여 안전이 중요한 응용 프로그램에서 해석 가능한 AI의 광범위한 채택 가능성을 강조합니다.



### How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs (https://arxiv.org/abs/2410.13857)
- **What's New**: 이 논문에서는 Transformer 기반 대형 언어 모델(LLMs)의 수학적 능력을 이론적으로 분석하고, 특히 산술작업에서의 성능을 강조합니다. 숫자 정밀도가 수학적 작업의 성공적인 수행을 좌우하는 핵심 요소로 밝혀졌습니다.

- **Technical Details**: 저자들은 LLM의 기본 산술 작업인 정수 덧셈, 반복 덧셈, 정수 곱셈을 분석합니다. 저자들은 정밀도에 따라 모델의 크기가 달라지며, 낮은 정밀도(int8, int4)의 Transformer는 문제를 풀기 위해 폭발적으로 큰 모델을 요구한다고 주장합니다. 이와 대조적으로 표준 정밀도(float32)는 훨씬 작고 효율적인 모델로도 이를 처리할 수 있음을 보여줍니다.

- **Performance Highlights**: 실험 결과는 두 가지 정밀도(int4 및 표준 정밀도) 모두에서 정수 덧셈 작업에서 충분한 성능을 보였지만, 반복 덧셈 및 정수 곱셈과 같은 복잡한 작업에서는 낮은 정밀도가 성능 저하를 일으킨다는 것을 보여주었습니다.



### Influence Functions for Scalable Data Attribution in Diffusion Models (https://arxiv.org/abs/2410.13850)
- **What's New**: 확산 모델에 대한 데이터 기여도 및 해석 가능성 문제를 해결하기 위해 영향 함수(influence functions) 프레임워크를 개발하여 새로운 방법을 제시합니다.

- **Technical Details**: 기여도 추정 방법인 영향 함수는 모델 출력이 특정 훈련 데이터를 제거했을 때 어떻게 변할지를 근사합니다. K-FAC(Kronecker-Factored Approximate Curvature) 근사 방법을 사용하여 해시안(Hessian) 계산의 확장성을 보장합니다.

- **Performance Highlights**: 제안된 방법은 Linear Data-modelling Score(LDS)와 같은 평가에서 기존 데이터 기여도 접근 방식보다 성능이 우수함을 보여주었으며, 특정 하이퍼파라미터 조정 없이도 성능을 발휘합니다.



### Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation (https://arxiv.org/abs/2410.13848)
Comments:
          Technical Report

- **What's New**: 이 논문에서는 다양한 모드의 이해 및 생성을 통합한 새로운 자율 회귀 프레임워크인 Janus를 소개합니다. 기존 연구는 주로 단일 시각 인코더를 사용했으나, Janus는 시각 인코딩을 별도의 경로로 분리하여 성능과 유연성을 향상시켰습니다.

- **Technical Details**: Janus는 고유한 transformer 아키텍처를 사용하여 시각 이해 및 생성을 위한 독립적인 인코딩 경로를 제공합니다. 이를 통해 이해와 생성 작업 사이의 정보를 분리하고, 각 작업에 가장 적합한 인코딩 방법을 선택할 수 있는 유연성을 제공합니다.

- **Performance Highlights**: Janus는 기존의 통합 모델보다 뛰어난 성능을 보여주며, MMBench 및 SEED-Bench와 같은 벤치마크에서 최고 성과를 기록했습니다. 또한, DALL-E 2와 SDXL과 같은 특정 작업 모델을 초월하는 성과를 보였습니다.



### Accelerating Codec-based Speech Synthesis with Multi-Token Prediction and Speculative Decoding (https://arxiv.org/abs/2410.13839)
Comments:
          Submitted to IEEE ICASSP 2025

- **What's New**: 본 논문에서는 음질 저하 없이 코드 기반 음성 합성 시스템의 속도를 가속화하기 위한 향상된 추론 방법을 제안합니다. 이 방법은 추가적인 훈련 없이 추론 간의 속도와 품질 간의 유연한 균형을 제공합니다.

- **Technical Details**: 핵심 아이디어는 여러 개의 예측 헤드를 사용하여 AR 모듈의 추론 단계에서 여러 개의 토큰을 예측하는 것입니다. 이로 인해 헤드 수가 증가함에 따라 합성 시간이 선형적으로 감소합니다. 또한, Viterbi 기반 알고리즘을 활용한 새로운 투기적 디코딩 기법을 도입하여 각 디코딩 단계에서 생성된 토큰의 최적 시퀀스를 선택합니다.

- **Performance Highlights**: 실험 결과, 각 토큰 예측에 필요한 시간이 기준 모델에 비해 4배에서 5배 줄어들었으며, 음성 이해도 측면에서 최소한의 품질 저하 또는 오히려 향상된 결과를 보였습니다.



### ORSO: Accelerating Reward Design via Online Reward Selection and Policy Optimization (https://arxiv.org/abs/2410.13837)
Comments:
          preprint, 35 pages, 23 figures

- **What's New**: 본 논문에서는 보상 형성(reward shaping)에서의 새로운 접근법인 Online Reward Selection and Policy Optimization (ORSO)를 제안합니다. 이 방법은 보상 형성 선택을 온라인 모델 선택 문제로 프레이밍하여 자동으로 적합한 보상 형성 함수를 찾아내는 데 초점을 맞추고 있습니다.

- **Technical Details**: ORSO는 합리적인 탐색 전략(principled exploration strategies)을 활용하여 인간의 개입 없이도 유망한 보상 형성 함수(shaping reward functions)를 식별합니다. 이 방법은 탐색(exploration)과 활용(exploitation)을 균형 있게 조절하며, 검증 가능한 후회 보장(regret guarantees)을 제공합니다.

- **Performance Highlights**: Isacc Gym 시뮬레이터를 사용한 다양한 연속 제어(tasks) 실험에서 ORSO의 효과를 입증하였으며, 전통적인 방법에 비해 샘플 효율(sample efficiency)을 크게 향상시키고 계산 시간을 줄이며, 도메인 전문가가 수동으로 엔지니어링한 보상에 의해 생성된 정책과 유사한 고품질 보상 함수를 지속적으로 식별합니다.



### The Disparate Benefits of Deep Ensembles (https://arxiv.org/abs/2410.13831)
- **What's New**: 최근 딥 신경망(Deep Neural Networks, DNNs)의 성능을 높일 수 있는 간편한 방법으로 사용되는 딥 앙상블(Deep Ensembles)에 대한 공정성(Algorithmic Fairness) 측면에서의 영향이 잘 이해되지 않았음을 밝히며, 본 연구는 딥 앙상블의 성능 향상과 공정성 간의 상호작용을 분석합니다.

- **Technical Details**: 이 연구는 딥 앙상블을 이용하여 얼굴 분석 및 의료 영상 데이터셋에서 공정성 메트릭을 활용하여 성능 편차를 empirically 조사합니다. 특히, 다양한 protected group 속성에 따라 성능이 상이하게 나타나는 'disparate benefits effect'를 발견했으며, 이 효과의 원인으로 그룹 내 예측의 다양성 차이를 규명했습니다.

- **Performance Highlights**: 본 연구에서 제안된 Hardt 후처리(post-processing) 방법이 효과적으로 공정성을 높이면서도 딥 앙상블의 성능을 유지할 수 있음을 보여줍니다. 분석을 통해 공정성 지표를 향상시킬 수 있는 다양한 접근 방식을 평가하였고, 딥 앙상블의 성능이 다수의 그룹 메트릭에서 불균형적으로 나타나는 것을 실증적으로 확인했습니다.



### A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglemen (https://arxiv.org/abs/2410.13828)
- **What's New**: 본 논문에서는 Reinforcement Learning from Human Feedback (RLHF)에서 전통적인 margin-based 손실을 사용하는 것의 문제점을 다루고 있습니다. 특히, 이 접근 방법이 선호 및 비선호 응답 각각에 대해 이상적인 언어 모델 behavior를 충분히 명시하지 않는다는 점이 강조됩니다.

- **Technical Details**: 우리는 margin의 증가에 따른 두 가지 의도치 않은 결과를 식별했습니다: (1) 비선호 응답의 확률이 증가할 수 있으며 이는 안전 문제와 관련된 alignment 실패를 초래할 수 있습니다. (2) 선호 응답의 확률이 감소할 수 있으며, 이 경우에도 그 응답은 이상적일 수 있습니다. 이러한 현상의 원인은 gradient entanglement으로 명명하였으며, 이는 선호 및 비선호 응답의 확률 변화가 서로 얽혀 있는 문제를 나타냅니다.

- **Performance Highlights**: 본 논문은 margin 기반 preference optimization 알고리즘의 훈련 동역학을 설명하고, margin 기반 방법의 under-specification 문제를 완화할 수 있는 잠재적인 알고리즘 설계를 제안합니다.



### Unearthing Skill-Level Insights for Understanding Trade-Offs of Foundation Models (https://arxiv.org/abs/2410.13826)
Comments:
          Code at: this http URL

- **What's New**: 이 논문은 모델 평가에서의 복잡성을 해결하기 위해, 모델이 생성한 이론(rationales)을 사용하여 기저가 되는 기술(skills)을 자동으로 복구하는 방법을 제안합니다. 기존의 평가 지표에 숨겨진 다양한 기술을 분석하여, 구체적이고 행동 가능한 모델 능력 이해를 제공합니다.

- **Technical Details**: 평가 인스턴스에 대해 강력한 모델(예: GPT-4o)을 사용하여 단계별 이론을 생성하고 각 단계에서 적용된 기술을 나열합니다. 이 과정을 통해 46,000개 이상의 인스턴스를 분석하고 기술 조각(skill-slices)을 작성하여 여러 벤치마크에서 기술의 정확성을 비교합니다.

- **Performance Highlights**: 우리는 기술 조각 분석을 통해 모델 간의 성능 무역에 대한 새로운 통찰을 발견했습니다. 예를 들어, Gemini 1.5 Pro는 'molar mass 계산'에서 평균적으로 18% 더 정확하지만 '헌법법 적용'에서는 19% 덜 정확하다는 결과를 보여주었습니다. 이러한 분석 방법을 통해 우리는 전체 12개 데이터셋에서 3%의 정확도 향상을 확인했습니다.



### Multi-style conversion for semantic segmentation of lesions in fundus images by adversarial attacks (https://arxiv.org/abs/2410.13822)
Comments:
          preprint

- **What's New**: 이번 논문에서는 다양한 데이터베이스의 주석 스타일 간 표준화를 해결하기 위해 'adversarial style conversion'이라는 새로운 방법을 도입합니다. 이 방법은 단일 아키텍처에서 결합된 데이터베이스를 활용하여 모델이 입력에 따라 자발적으로 세분화 스타일을 조정하도록 훈련되었습니다.

- **Technical Details**: 제안된 방법론은 인코더 특징을 기반으로 데이터셋의 출처를 탐지하는 'linear probe'를 추가하고, 적대적 공격(adversarial attacks)을 통해 모델의 세분화 스타일을 조정하는 방식을 채택합니다. 이는 여러 데이터셋에서 훈련된 세분화 모델의 스타일 변환을 가능하게 합니다.

- **Performance Highlights**: 논문의 결과는 데이터셋 조합을 통해 질적으로나 양적으로 유의미한 개선을 보이며, 모델의 일반화 성능, 불확실성 추정 및 주석 스타일 간의 지속적 보간과 같은 기회를 제공합니다.



### Artificial Kuramoto Oscillatory Neurons (https://arxiv.org/abs/2410.13821)
Comments:
          Code: this https URL

- **What's New**: 본 연구에서는 Artificial Kuramoto Oscillatory Neurons (AKOrN)을 소개합니다. 이는 전통적인 threshold units의 동적 대안으로, 다양한 connectivity 디자인과 결합할 수 있습니다.

- **Technical Details**: AKOrN은 Kuramoto 업데이트를 통해 뉴런의 동기화 동적을 이용하며, 이는 비대칭 연결을 통해 뉴런 간의 상호작용을 탐구합니다. 연구에서는 4개의 합성 데이터셋과 2개의 실제 이미지 데이터셋에서 성능을 평가하였습니다.

- **Performance Highlights**: AKOrN은 비지도 객체 발견, 적대적 강건성, 캘리브레이션된 불확실성 정량화 및 추론을 포함한 다양한 작업에서 향상된 성능을 보여주었습니다.



### Guided Reinforcement Learning for Robust Multi-Contact Loco-Manipulation (https://arxiv.org/abs/2410.13817)
Comments:
          J. P. Sleiman and M. Mittal contributed equally. Accepted for CoRL 2024 (Oral). Project website: this https URL

- **What's New**: 이번 연구는 다중 접촉 로코-조작(loco-manipulation) 작업을 위한 행동 합성 및 제어에 대한 체계적인 접근 방식을 제안합니다. 기존의 RL (Reinforcement Learning) 방법이 요구하는 고도의 MDP (Markov Decision Process) 설계를 대체하여, 단일 시연으로 RL 정책을 학습할 수 있게 합니다.

- **Technical Details**: 제안한 방법은 TO (Trajectory Optimization) 기반 프레임워크에서 생성된 적응형 궤적을 사용하여 RL 에이전트가 복잡한 행동을 학습하도록 이끕니다. 우리의 MDP는 모델링 불확실성, 외부 방해 요인 및 예기치 않은 이벤트을 처리하는 능력을 갖춘 로코-조작 정책을 효율적으로 학습하는 데 중점을 둡니다.

- **Performance Highlights**: 제안한 정책은 문을 밀고 당기거나 식기세척기를 여닫는 정해진 네 가지 작업에서 선행 Motion Imitation RL 방법과 비교하여 높은 성공률을 보여주었습니다. 훈련된 정책은 실제 로봇으로 이식되어, 잔여 객체 모델에의 강인성과 슬립(slip) 상황에 대한 반응성을 보여줍니다.



### Learning Graph Quantized Tokenizers for Transformers (https://arxiv.org/abs/2410.13798)
- **What's New**: 이번 논문에서는 Graph Quantized Tokenizer (GQT)를 도입하여 그래프의 토큰화 과정을 개선했습니다. GQT는 멀티태스킹 그래프 자기 지도 학습(multi-task graph self-supervised learning)을 활용하여 토크나이저 훈련과 트랜스포머 훈련을 분리함으로써 더 강력하고 일반화 가능한 토큰을 생성합니다.

- **Technical Details**: GQT는 Residual Vector Quantization (RVQ) 기법을 통해 계층적인 이산 토큰을 학습하여 메모리 요구 사항을 크게 줄이고 일반화 능력을 향상시킵니다. 이 방법은 의미적 엣지와 랜덤 워크를 결합하여 트랜스포머가 장거리 상호작용에 접근할 수 있도록 합니다.

- **Performance Highlights**: GQT를 트랜스포머 인코더와 결합하여 18개 벤치마크 중 16개에서 최첨단 성능을 달성하였으며, 특히 대규모 동질적 및 이질적 데이터셋에서 성능이 뛰어났습니다. 이는 매우 감소된 메모리 풋프린트를 갖춘 임베딩을 통해 달성되었습니다.



### Optimal Quantization for Matrix Multiplication (https://arxiv.org/abs/2410.13780)
- **What's New**: 본 연구는 대규모 매트릭스의 lossy compression (양자화) 기법을 통해 매트릭스 곱셈을 가속화하기 위한 새로운 알고리즘을 제안합니다. 이 접근법은 전통적인 벡터 양자화와 다르게, 매트릭스 자체가 아니라 매트릭스 곱셈의 근사를 목표로 합니다.

- **Technical Details**: 이 논문은 iid Gaussian 아이템을 가진 매트릭스의 평균 제곱 오차에 대한 비비대칭 하한을 제공하며, 특정한 프레임워크에서 Frobenius norms를 사용하여 매트릭스 A, B의 압축과 동시에 근사 오차를 보장하는 보편적인 양자기를 제안합니다. 이는 깊은 신경망(Deep Neural Networks)과 대규모 언어 모델(Large Language Models)에서 메모리 대역폭의 병목 현상을 해결하기 위한 중요성을 강조합니다.

- **Performance Highlights**: 제안된 양자기는 최적 성능에 근접한 결과를 실현하며, 정보 이론적으로 iid Gaussian 매트릭스의 매트릭스 곱셈에 대한 rate-distortion function을 도출합니다.



### Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems (https://arxiv.org/abs/2410.13768)
- **What's New**: 본 논문에서는 새로운 금속 합금 발견을 자동화하기 위해 다중 에이전트 AI 모델을 활용했습니다. 이 시스템은 LLM(대규모 언어 모델)과 GNN(그래프 신경망)이 결합된 구조로, 물리적 시뮬레이션에서 도출한 데이터와 외부 지식을 통합하여 복잡한 합금 설계를 지원합니다.

- **Technical Details**: 이 모델은 (a) 추론 및 계획 작업을 담당하는 LLM의 모음, (b) 서로 다른 역할과 전문성을 가진 AI 에이전트 그룹, (c) 주요 물리적 특성을 신속하게 검색하기 위한 GNN 모델로 구성됩니다. GNN 모델은 NbMoTa 계열의 BCC 합금을 대상으로 Peierls 장벽 및 용질/스크류 전위 상호작용 에너지와 같은 원자 규모의 특성을 예측합니다.

- **Performance Highlights**: 이 AI 시스템은 계산 비용을 줄이고 여러 에이전트를 통해 자동으로 합금 디자인 공간을 탐색함으로써, 새로운 합금을 발견하는 과정을 가속화합니다. 본 연구는 복잡한 시스템에서의 광범위한 응용 가능성을 제시하며, 소재 설계에서의 자동화된 발견에 큰 진전을 이루었습니다.



### Virtual Sensing for Real-Time Degradation Monitoring of Nuclear Systems: Leveraging DeepONet for Enhanced Sensing Coverage for Digital Twin-Enabling Technology (https://arxiv.org/abs/2410.13762)
- **What's New**: 본 논문에서는 AP-1000 Pressurized Water Reactor (PWR)에서 고온 다리(hot leg)의 열유체 매개변수를 예측하기 위해 Deep Operator Networks (DeepONet)를 사용하는 방안을 제안합니다. 이는 디지털 트윈(digital twin) 프레임워크 내에서 실행되며, 지속적인 재학습의 필요성을 완화하여 온라인 및 실시간 예측을 가능하게 합니다.

- **Technical Details**: DeepONet는 다양한 운영 조건에 대해 훈련되며, 이로 인해 많은 수의 데이터 및 복잡한 고차원 데이터를 효율적으로 처리할 수 있습니다. 본 연구는 DeepONet이 평균 제곱 오차(mean squared error) 및 상대 L2 오류(relational L2 error)가 낮은 결과를 보이며, 전통적인 유한 요소(finite element) 시뮬레이션보다 160,000배 빠른 예측을 할 수 있음을 보여줍니다.

- **Performance Highlights**: DeepONet는 실시간으로 재료 열화(indicators of material degradation)를 추적하는 데 매우 효과적인 도구로 입증되었으며, 이러한 속도와 정확성은 원자로 안전성과 수명을 높이는 데 기여합니다.



### MobA: A Two-Level Agent System for Efficient Mobile Task Automation (https://arxiv.org/abs/2410.13757)
Comments:
          27 pages, 6 figures, and 5 tables. We will release our source code in a few days

- **What's New**: MobA라는 혁신적인 모바일 어시스턴트를 제안합니다. 이를 통해 다중 모달 대형 언어 모델(Multimodal Large Language Models, MLLM)을 활용하여 사용자의 명령 이해와 계획 능력을 향상시킵니다.

- **Technical Details**: MobA는 두 가지 수준의 에이전트 아키텍처로 구성되어 있습니다. 상위 에이전트(Global Agent, GA)는 사용자 명령을 이해하고, 히스토리 메모리를 추적하며, 작업을 계획하는 역할을 합니다. 하위 에이전트(Local Agent, LA)는 GA의 메모리와 서브 태스크에 따라 상세한 작업을 함수 호출의 형태로 예측합니다. 또한, Reflect Module을 통합하여 이전에 보지 못한 복잡한 작업을 처리할 수 있는 능력을 제공합니다.

- **Performance Highlights**: MobA는 실제 평가에서 작업 수행 효율성(Task Execution Efficiency)과 완료율(Completion Rate)에서 상당한 개선을 보여주며, MLLM을 활용한 모바일 어시스턴트의 가능성을 강조합니다.



### CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building (https://arxiv.org/abs/2410.13756)
Comments:
          6 pages, 6 figures

- **What's New**: CLIMB는 지속적인 학습을 통해 로봇 작업 계획을 지원하는 새로운 프레임워크로, 자연어 설명을 바탕으로 도메인 모델을 생성하고 비직관적인 술어를 학습하여 향후 문제에 활용할 수 있습니다.

- **Technical Details**: CLIMB는 하이브리드 신경-심볼릭 (neuro-symbolic) 계획 시스템으로, 기초 모델과 전통적인 심볼릭 계획자를 결합하여 중복 학습 없이 과거의 문제를 해결할 수 있는 능력을 보유하고 있습니다. 이 시스템은 PDDL 모델을 점진적으로 구축하며, 작업을 수행하면서 환경의 원인 구조를 즉각 반영합니다.

- **Performance Highlights**: CLIMB는 예비 성능 시험에서 기존 방법과 비교하여 일반 계획 환경에서 성능 향상을 입증했습니다. BlocksWorld++ 도메인을 통해 점진적 논리 세계 모델 구축 능력을 평가했으며, 실험 결과 CLIMB의 향상된 성능을 확인할 수 있었습니다.



### Privacy-Preserving Decentralized AI with Confidential Computing (https://arxiv.org/abs/2410.13752)
- **What's New**: 본 논문은 탈 중앙화된 인공지능(AI) 플랫폼인 Atoma Network에서 기밀 컴퓨팅(Confidential Computing, CC)을 활용한 프라이버시 보호에 대해 다룹니다. 이 기술은 탈 중앙화된 AI가 직면한 프라이버시 문제를 해결하기 위한 새로운 접근 방식을 제시합니다.

- **Technical Details**: 문서에서 제안하는 기밀 컴퓨팅은 하드웨어 기반의 신뢰할 수 있는 실행 환경(Trusted Execution Environments, TEE)을 활용하여 민감한 데이터를 처리하는 동안 코드를 보호하고 기밀성을 유지하는 역할을 합니다. TEEs는 분산 환경에서도 데이터와 모델 파라미터가 외부에 노출되지 않도록 보장합니다.

- **Performance Highlights**: TEEs는 높은 프라이버시 보호 기능을 제공하고, 탈 중앙화된 AI의 채택을 촉진하는 데 기여할 것으로 기대됩니다. 특히, 프라이버시 우려를 해소하면서 안전하고 신뢰할 수 있는 AI 연산에 소요되는 리소스를 줄일 수 있는 가능성을 보여줍니다.



### DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation (https://arxiv.org/abs/2410.13726)
- **What's New**: 이번 연구에서는 DAWN(Dynamic frame Avatar With Non-autoregressive diffusion)이라는 새로운 프레임워크를 통해 오디오 클립과 초상화를 이용한 직접적인 동영상 생성 방식을 선보입니다. DAWN은 기존의 autoregressive (AR) 방식의 한계를 극복하여, 모든 프레임을 동시 생성할 수 있는 비선형(non-autoregressive, NAR) 전략을 적용하였습니다.

- **Technical Details**: DAWN 프레임워크는 (1) 오디오에 기반한 전체적인 얼굴 역학을 생성하는 잠재적 동작 공간에서의 생성과 (2) 오디오 기반의 머리 자세 및 깜빡임 생성이라는 두 가지 주요 구성 요소로 이루어져 있습니다. 추가적으로, Pose and Blink generation Network (PBNet)는 오디오에서 자연스러운 머리 자세와 깜빡임 시퀀스를 생성하는 데 사용됩니다. DAWN은 A2V-FDM(Audio-to-Video Flow Diffusion Model)을 통해 입술과 오디오 간의 암묵적 관계를 학습합니다.

- **Performance Highlights**: DAWN은 빠른 생성 속도와 더불어 정확한 입술 동작 및 자연스러운 자세/깜빡임을 보장하여, 실제감 있고 생동감 넘치는 비디오를 생성합니다. 또한, DAWN은 뛰어난 외삽(extrapolation) 능력을 발휘하며, 긴 비디오에서도 높은 품질을 안정적으로 유지할 수 있는 가능성을 보여줍니다.



### Persistent Pre-Training Poisoning of LLMs (https://arxiv.org/abs/2410.13722)
- **What's New**: 이 연구는 대규모 언어 모델(LLM)이 사전 훈련(pre-training) 과정에서도 악성 공격에 의해 손상될 수 있는지를 처음으로 평가합니다. 특히, LLM이 유용하고 무해한 챗봇으로 세부 훈련(fine-tuning)될 때까지 이러한 공격 효과가 지속되는지를 연구했습니다.

- **Technical Details**: 연구팀은 0.1%의 데이터가 오염되는 경우에도 여러 가지 공격(서비스 거부, 신념 조작, 탈옥, 프롬프트 도용)의 효과가 지속됨을 확인했습니다. 실험은 600M에서 7B 파라미터의 다양한 모델 크기를 사용해 진행되었습니다. 주요 공격 중, 서비스 거부(denial-of-service) 공격은 0.001%의 오염율에서도 지속성이 나타났습니다.

- **Performance Highlights**: 연구 결과, 사전 훈련 데이터의 0.1%를 오염시키는 것만으로도 훈련 후 모든 공격에서 효과가 들여다보였으며, 탈옥(jailbreaking) 공격은 안전 훈련(safety training) 방법으로는 지속되지 않는 것으로 나타났습니다.



### Movie Gen: A Cast of Media Foundation Models (https://arxiv.org/abs/2410.13720)
- **What's New**: 이번 논문에서는 Movie Gen이라는 새로운 foundation 모델 세트를 제안합니다. 이 모델은 다양한 화면 비율과 동기화된 오디오와 함께 고품질 1080p HD 비디오를 생성하며, 사용자의 이미지를 기반으로 한 개인화된 비디오 생성 및 정밀한 지침 기반 비디오 편집 기능도 포함되어 있습니다.

- **Technical Details**: Movie Gen은 30B 파라미터의 트랜스포머 모델로, 최대 73K 비디오 토큰의 컨텍스트 길이를 가지고 있습니다. 이 모델은 텍스트-비디오 합성, 비디오 개인화, 비디오 편집, 비디오-오디오 생성 및 텍스트-오디오 생성과 같은 다양한 작업에서 최첨단 성능을 기록합니다. 인터넷 스케일의 이미지, 비디오, 오디오 데이터를 통해 사전 학습되었습니다.

- **Performance Highlights**: Movie Gen 모델은 기존 상업 시스템을 초월하여 텍스트-비디오 생성, 비디오 개인화, 정밀 비디오 편집 및 오디오 생성 작업에서 탁월한 성능을 보여줍니다. 특히, Movie Gen Video는 최대 16초의 개인화된 HD 비디오 생성을 가능하게 하며, Movie Gen Audio는 정밀한 음악 생성과 음향 효과 생성을 지원합니다.



### Jailbreaking LLM-Controlled Robots (https://arxiv.org/abs/2410.13691)
- **What's New**: 최근 대형 언어 모델(LLMs)의 도입은 조작(manipulation), 이동(locomotion), 자율 주행 차량(self-driving vehicles) 등 다양한 분야에서 맥락적 추론(contextual reasoning) 및 직관적인 인간-로봇 상호작용을 가능하게 하여 로봇 공학 분야에 혁신을 가져왔습니다. 본 논문에서는 RoboPAIR이라는 알고리즘을 소개하며, 이는 LLM에 의해 제어되는 로봇을 위한 최초의 jailbreak 공격 알고리즘입니다.

- **Technical Details**: RoboPAIR는 세 가지 시나리오에서 LLM 제어 로봇이 해로운 물리적 행동(harmful physical actions)을 유도할 수 있는 방법을 실험적으로 입증합니다: (i) 화이트박스(white-box) 설정 - 공격자가 NVIDIA Dolphins 자율주행 LLM에 완전 접근할 수 있는 경우, (ii) 그레이박스(gray-box) 설정 - 공격자가 GPT-4o 플래너가 장착된 Clearpath Robotics Jackal UGV 로봇에 부분적으로 접근할 수 있는 경우, (iii) 블랙박스(black-box) 설정 - 공격자가 GPT-3.5 통합된 Unitree Robotics Go2 로봇 개에 대해 쿼리만 할 수 있는 경우.

- **Performance Highlights**: RoboPAIR는 세 가지 새로운 해로운 로봇 행동 데이터셋에서 공격 성공률(attack success rate) 100%에 도달하며, 기존 정적 기반선(static baselines)보다 빠르고 효과적으로 jailbreak을 발견하는 성과를 보였습니다. 이는 LLM이 텍스트 생성에 국한되지 않고 실제 세계에서 물리적 손상을 초래할 민족성이 극복되었음을 처음으로 보여줍니다.



### Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion (https://arxiv.org/abs/2410.13674)
Comments:
          23 pages, including references and appendix. Code is available at this http URL

- **What's New**: 본 논문에서는 기존의 데이터 증강(data augmentation) 기법의 한계를 극복하기 위해, 이미지 가이드를 활용하여 합성 이미지와 실제 이미지 간의 스펙트럼 보간을 수행하는 새로운 접근 방법인 'Diffusion Curriculum (DisCL)'을 제안합니다.

- **Technical Details**: 기존의 텍스트 가이드는 합성 이미지의 품질이 원본 이미지와 어떤 연관이 있는지를 제어할 수 없지만, 이미지 가이드를 통해 합성 이미지와 실제 이미지의 유사성을 조절할 수 있습니다. DisCL은 훈련 단계에 따라 이미지 합성의 가이드 수준을 조정하여 모델을 위한 어려운 샘플을 식별하고 이들을 학습하는 데 가장 효과적인 가이드 수준을 평가합니다.

- **Performance Highlights**: DisCL을 iWildCam 데이터셋에 적용했을 때 OOD(Out-of-Distribution) 및 ID(In-Distribution) 매크로 정확도에서 각각 2.7% 및 2.1% 향상을 보여주었으며, ImageNet-LT에서 기본 모델의 tail-class 정확도를 4.4%에서 23.64%로 개선하고 모든 클래스 정확도에서 4.02% 향상을 달성했습니다.



### Fine-Tuning Discrete Diffusion Models via Reward Optimization with Applications to DNA and Protein Design (https://arxiv.org/abs/2410.13643)
- **What's New**: 이번 연구에서 제안하는 DRAKES 알고리즘은 기존의 discrete diffusion models를 활용하여 특정 작업 목표에 최적화된 시퀀스를 생성하는 데 중점을 두고 있습니다. 특히, 자연성과 고급 보상 최적화를 동시에 달성할 수 있는 새로운 접근 방식을 제공합니다.

- **Technical Details**: DRAKES는 Gumbel-Softmax 트릭을 사용해 기존의 비미분 가능했던 경로를 미분 가능하게 만들어 전체 경로를 통한 보상의 직접 역전파를 가능하게 합니다. 이 알고리즘은 reinforcement learning (RL) 방식으로 보상 최대화 문제를 접근하며 KL divergence를 최소화하여 자연성을 유지합니다.

- **Performance Highlights**: DRAKES는 DNA 및 단백질 시퀀스를 생성하는 데 성공적으로 적용되어 각각 enhancer 활동과 단백질 안정성을 최적화한 결과, 중요한 유전자 치료 및 단백질 기반 치료에서의 활용 가능성을 보여주었습니다.



### Scaling Wearable Foundation Models (https://arxiv.org/abs/2410.13638)
- **What's New**: 이 연구에서는 165,000명 이상의 사용자로부터 수집한 4천만 시간의 다중 모달(sensor modalities) 센서 데이터를 기반으로 한 대규모 착용형 센서 모델(LSM)을 소개하고, 해당 모델의 스케일링 속성을 조사합니다. 본 연구의 주된 목표는 착용형 센서 데이터가 있는 경우 스케일링 법칙이 적용될 수 있는지를 확인하는 것입니다.

- **Technical Details**: LSM 모델은 심박수, 심박수 변동성, 전기 피부 활동(EDA), 가속도계, 피부 온도, 고도계 등 다양한 센서에서 수집된 데이터를 사용합니다. 이 연구는 데이터, 모델 크기, 컴퓨팅 리소스가 늘어날 때 LSM의 성능이 어떻게 향상되는지를 실험 엘 리 분석합니다. 자가 지도 학습(SSL) 기법을 통해 소량의 레이블 데이터 뿐만 아니라 대량의 비레이블 데이터에서 유용한 표현을 학습합니다.

- **Performance Highlights**: LSM은 데이터의 시간적 및 센서 모달리티를 초월하여 임퓨테이션(imputation), 보간(interpolation), 외삽(extrapolation) 작업을 수행할 수 있는 능력을 보여줍니다. 또한 연구는 사용자 주석 이벤트를 활용하여 운동 및 활동 인식과 같은 다운스트림 분류 작업에서의 일반화 가능성을 검증하였습니다.



### Normalizing self-supervised learning for provably reliable Change Point Detection (https://arxiv.org/abs/2410.13637)
- **What's New**: 본 논문에서는 기존의 Change Point Detection (CPD) 기법의 한계를 극복하기 위해, 전통적인 CPD 방법의 신뢰성과 표현 학습 (representation learning) 기술의 표현력을 결합하는 방안을 제안하고 있습니다. 특히, Spectral Normalization (SN)을 통해 딥러닝 모델의 데이터 표현을 최적화하고 있습니다.

- **Technical Details**: CPD 문제를 해결하기 위해, SN 기법을 사용하여 신경망의 학습에서 데이터의 변화를 표현 공간에서 유지하도록 하였습니다. 본 논문은 자기 지도 학습 (Self-Supervised Learning, SSL) 방법을 결합하여, 변화 점 탐지 (change point detection)를 위한 보다 효과적인 임베딩 (embedding) 공간을 제공합니다.

- **Performance Highlights**: 제안된 방법은 세 가지 표준 CPD 데이터셋을 통해 평가된 결과, 현재의 최첨단 기법들보다 현저히 높은 성능을 기록하였습니다. 이는 SN을 통한 임베딩의 정보성이 CPD 활용에 매우 유익함을 보여줍니다.



### Spatiotemporal Object Detection for Improved Aerial Vehicle Detection in Traffic Monitoring (https://arxiv.org/abs/2410.13616)
Comments:
          13 pages

- **What's New**: 이번 연구는 UAV(무인 항공기) 카메라를 이용한 다중 클래스 차량 탐지의 발전을 다루며, Spatiotemporal Object Detection 모델을 개발하였습니다. 이를 위해 6,600개의 주석이 달린 연속 프레임 이미지로 구성된 Spatio-Temporal Vehicle Detection Dataset(STVD)를 소개하며, 이를 통해 알고리즘의 포괄적인 훈련과 평가를 가능하게 합니다.

- **Technical Details**: YOLO 기반 객체 탐지 알고리즘을 개선하여 시간적 동역학을 통합하였으며, 스페이셔 (spatial)와 템포럴 (temporal) 정보 모두를 활용하는 모델을 개발하였습니다. 기존의 단일 프레임 모델보다 뛰어난 성능을 발휘하며, 특히 주목(attention) 메커니즘을 통합하여 성능을 더 향상시킬 수 있음을 입증하였습니다.

- **Performance Highlights**: 실험적으로, 가장 우수한 시공간 모델이 단일 프레임 모델에 비해 16.22% 향상된 성능을 보였으며, 주목 메커니즘을 통합한 모델은 추가적인 성능 향상 가능성을 보여주었습니다.



### H2OVL-Mississippi Vision Language Models Technical Repor (https://arxiv.org/abs/2410.13611)
- **What's New**: H2OVL-Mississippi 모델은 3700만 개의 이미지-텍스트 쌍을 기반으로, 8개의 H100 GPU를 사용하여 240시간 동안 훈련된 작은 비전-언어 모델(VLM) 쌍을 소개합니다. 특히, H2OVL-Mississippi-0.8B는 8억 개의 매개변수로 구성되어 텍스트 인식에 특화되어 있으며, OCRBench의 텍스트 인식 부문에서 최첨단 성능을 발휘하고 있습니다.

- **Technical Details**: H2OVL-Mississippi 모델은 Vision Transformer(비전 트랜스포머) 구성 요소와 대형 언어 모델(LLM)로 이루어집니다. H2OVL-Mississippi-0.8B는 OCR 및 문서 중심 작업에 최적화되어 있고, H2OVL-Mississippi-2B는 다양한 멀티모달 작업을 수행할 수 있는 일반 목적 모델입니다. 이들은 각각 256에서 1590개의 시각적 토큰을 생성하며, 동적 해상도 전략(dynamic resolution)과 다중 스케일 적응 크롭(multi-scale adaptive cropping) 전략을 활용하여 다양한 이미지 크기와 종횡비에 적응합니다.

- **Performance Highlights**: H2OVL-Mississippi-0.8B는 OCRBench에서 텍스트 인식 부문에서 최첨단 성능을 보여주며, H2OVL-Mississippi-2B는 다양한 학술 벤치마크에서 경쟁력 있는 메트릭스를 제공합니다. 두 모델 모두 H2O-Danube 언어 모델의 기능을 확장하여 비주얼 도메인으로의 적용 가능성을 높이고, Apache 2.0 라이선스 하에 공개되어 문서 AI와 비주얼 LLM의 접근성을 높였습니다.



### Large Language Models as Narrative-Driven Recommenders (https://arxiv.org/abs/2410.13604)
Comments:
          Under review; 19 pages

- **What's New**: 이번 연구에서는 대형 언어 모델(LLMs)을 사용하여 자유형식의 텍스트로 표현된 영화 추천 요청에 대한 개인화된 추천을 제공하기 위한 새로운 접근 방식을 탐구하였습니다. 특히, reddit의 영화 추천 커뮤니티에서 수집된 데이터셋을 활용하여 38개의 오픈소스 및 클로즈드 소스 LLM의 성능을 비교하였습니다.

- **Technical Details**: 이 연구는 zero-shot, identity, few-shot 프롬프트 기법을 사용하여 LLM이 사용자 요청을 자연어로 처리하고 관련 영화를 추천할 수 있는지 평가합니다. 평가된 LLM은 크기에 따라 분류되며, 각 모델은 기본적인 zero-shot 프롬프트를 통해 추천 정확도를 높일 수 있음을 보여줍니다.

- **Performance Highlights**: LLMs는 기존의 추천 알고리즘보다 더 높은 성능을 보이며, 특히 GPT-4o는 기본 성능보다 70% 더 높은 추천 성능을 보였습니다. 중간 크기의 오픈소스 모델도 상대적으로 높은 성능을 유지하며 클로즈드 소스 모델과 비교하여 경쟁력을 보여주었습니다.



### Text-Guided Multi-Property Molecular Optimization with a Diffusion Language Mod (https://arxiv.org/abs/2410.13597)
- **What's New**: 이 논문은 약물 발견에서 필수적인 단계인 분자 최적화(molecular optimization, MO)를 위한 새로운 접근법인 Transformer 기반 확산 언어 모델(TransDLM)을 제안합니다. 기존 MO 방법은 주로 외부 속성 예측자(property predictors)에 의존했으나, 이는 예측 과정에서 오류와 노이즈를 초래합니다. TransDLM은 표준화된 화학 명명을 활용하여 오류 전파를 방지하며 동시에 여러 속성을 최적화합니다.

- **Technical Details**: TransDLM은 분자의 SMILES 문자열의 단어 벡터를 생성하기 위해 확산 모델을 활용하며, 언어 설명에 의해 안내됩니다. 이는 원하는 분자 속성을 언어 모델을 통해 암시적으로 통합하여 확산 과정에서의 오류 전파를 방지합니다. 또한, TransDLM은 웹 기반 플랫폼에서 배포가 가능하여 분산 환경에서 대규모 MO를 지원합니다.

- **Performance Highlights**: TransDLM은 벤치마크 데이터세트에서 기존의 최첨단 방법들을 초월하는 성능을 보이며, 3가지 ADMET 속성(LogD, Solubility, Clearance)을 최적화하는 데 있어 구조적 유사성을 유지하면서 개선된 화학적 특성을 제공합니다.



### OAH-Net: A Deep Neural Network for Hologram Reconstruction of Off-axis Digital Holographic Microscop (https://arxiv.org/abs/2410.13592)
Comments:
          11 pages, 4 figures

- **What's New**: 본 논문은 심층 학습(Deep Learning)과 비오프축 홀로그램(off-axis holography)의 물리적 원리를 통합한 새로운 홀로그램 재구성 방법을 제안합니다. 이 방식을 통해 홀로그램 재구성의 속도를 크게 향상시킬 수 있으며, 이는 고속 이미징 기술에 필수적입니다.

- **Technical Details**: OAH-Net(Off-Axis Hologram Network)은 3차원 이미지를 국가연구소의 혈액 샘플로부터 학습하여 재구성을 수행합니다. 본 네트워크는 Fourier Imager Heads (FIHs) 및 Complex Valued Network (CVN) 두 가지 주요 모듈로 구성되어 있으며, FIH는 불필요한 홀로그램 성분을 제거하고, CVN은 물체 빔의 파동을 진폭과 비위상으로 변환합니다. 이 모델은 3ms/프레임으로 현실적 처리 속도를 달성하였습니다.

- **Performance Highlights**: OAH-Net은 방해 요소를 최소화하며, 낮은 재구성 오류를 보였습니다. OAH-Net으로 재구성된 이미지의 YOLO(object detection) 성능은 기존 방법과 유사한 성능을 보여 임상적 유용성을 확인했습니다. 또한, 이 모델은 실시간 고해상도 홀로그램 분석을 가능하게 함으로써 생물학적 및 의료 연구 분야에서의 응용 가능성을 크게 확대하였습니다.



### RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical Imaging (https://arxiv.org/abs/2410.13570)
Comments:
          10 pages, 4 figures, 3 tables

- **What's New**: 이번 연구는 RGB 데이터를 이용하여 하이퍼스펙트럴 서명을 재구성하여 외과 수술 이미징을 향상시키는 방법을 다룹니다. 공개된 HeiPorSPECTRAL 데이터셋과 자체 신경외과 데이터셋을 활용하여 다양한 CNN(Convolutional Neural Networks)과 Transformer 모델의 성능을 비교하고 평가하였습니다.

- **Technical Details**: 연구에서 사용된 모델은 하이퍼스펙트럼 데이터의 정확한 예측을 위해 공간 정보를 효과적으로 통합하는 Transformer 모델입니다. 성능 평가는 RMSE(Root Mean Square Error), SAM(Spectral Angle Mapper), PSNR(Peak Signal-to-Noise Ratio) 및 SSIM(Structural Similarity Index)과 같은 포괄적인 측정을 통해 이루어졌습니다. 모델은 가시광선과 확장된 스펙트럼 범위를 모두 포함한 스펙트럼 프로파일을 예측하는 데 성공하였습니다.

- **Performance Highlights**: Transformer 모델은 평가 지표에서 우수한 성능을 보이며, 질적 평가를 통해 외과적 의사결정에 중요한 스펙트럴 프로파일 예측 능력을 나타냈습니다. 그러나 가시광선과 확장된 하이퍼스펙트럴 범위를 모두 캡처하는 데 있어 MAE(Mean Absolute Error)를 통해 강조된 복잡한 과제가 있었습니다.



### CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining Cloth-Changing Person Re-Identification Models (https://arxiv.org/abs/2410.13567)
- **What's New**: 본 논문에서는 Cloth-changing person re-identification (CC-ReID) 문제를 해결하기 위해, 고품질의 합성 데이터 생성 파이프라인을 제안했습니다. 특히, 6,000개의 개인 ID와 1,179,976개의 이미지로 구성된 새로운 자가 주석 CC-ReID 데이터셋인 Cloth-Changing Unreal Person (CCUP)을 구축하여 기존의 데이터 드리븐 모델의 한계를 극복하고자 했습니다.

- **Technical Details**: CCUP 데이터셋은 현실적 인물 모델과 다양한 시나리오를 통해 대규모 합성 데이터를 생성하는 과정을 포함합니다. 데이터 생성 과정에서는 MakeHuman 소프트웨어를 사용하여 리얼한 인체 스켈레탈 메쉬를 생성하고, Unreal Engine을 통해 다양한 감시 환경에서의 시뮬레이션을 수행했습니다. 이 방식으로, 각 개인은 평균 26.5벌의 의상을 착용하며, CCTV 카메라를 통해 자동으로 레이블링된 데이터가 생성됩니다.

- **Performance Highlights**: 제안된 CCUP 데이터셋을 기반으로 한 프리트레인-파인튜닝(pretrain-finetune) 프레임워크는 TransReID와 FIRe^2와 같은 전통적인 모델의 일반화 능력을 개선하는 데 기여합니다. 실험 결과, CCUP에서 프리트레인 되고 각 벤치마크(PRCC, VC-Clothes, NKUP)에서 파인튜닝된 두 가지 모델이 다른 최신 모델들을 능가하는 성능을 보여주었습니다.



### Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data? (https://arxiv.org/abs/2410.13523)
Comments:
          Under Review

- **What's New**: 의료 이미지 분석에 대한 기존의 MedVLP 모델이 실제 데이터에 의존하는 반면, 이 연구는 고품질의 합성 데이터(Synthetic Data)를 사용하여 모델을 학습시키는 방안을 제안합니다. 특히, 현실 데이터에 비해 합성 데이터만으로 훈련된 MedVLP 모델이 매력적인 성과를 보였습니다.

- **Technical Details**: 연구에서는 off-the-shelf generative models를 사용하여 200,000개의 합성 X-ray 이미지와 보고서를 포함하는 SynCXR 데이터셋을 생성했습니다. 이 데이터셋은 데이터 품질과 분포를 조절하여 구축되었습니다. 제안된 자동화된 파이프라인을 통해 생성된 합성 데이터만으로 훈련한 MedVLP 모델은 실제 데이터로 훈련한 모델보다 AUC에서 평균 3.8% 개선된 성능을 보였습니다.

- **Performance Highlights**: 합성 데이터 또는 혼합(data mixing) 데이터를 사용하여 훈련된 MedVLP 모델은 실제 데이터에서 훈련된 모델보다 일관되게 우수한 성과를 나타냅니다. 특히 zero-shot classification과 segmentation에서 강력한 성능을 발휘하며, 특정 영역에서는 성능이 9.07% 향상되기도 했습니다.



### MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs (https://arxiv.org/abs/2410.13502)
Comments:
          Preprint

- **What's New**: MathGAP이라는 새로운 평가 프레임워크를 제시하여, 보다 복잡한 산술 증명이 포함된 문제에서 대형 언어 모델(LLMs)의 일반화 능력을 분석합니다. 이를 통해 기존의 평가 방법의 한계를 극복하고 보다 체계적인 연구를 가능하게 합니다.

- **Technical Details**: MathGAP는 고정된 증명 기준을 따르는 문제를 생성하고 체계적인 체인-오브-생각(chain-of-thought) 주석을 제공합니다. 이 프레임워크는 증명 나무(proof trees)를 기반으로 각 문제의 복잡성을 특성화하고, 간단한 예제를 사용하여 더 복잡한 문제를 해결할 수 있는 LLM의 능력을 평가합니다.

- **Performance Highlights**: 모델 성능은 증명 깊이와 너비가 증가함에 따라 일관되게 감소하며, 특히 비선형(nonlinear) 문제에서 눈에 띄는 감소가 관찰됩니다. 흥미롭게도, 테스트 세트와 동일한 분포의 예제를 제공하는 것이 항상 성능에 이롭지 않으며, 다양한 복잡성을 가진 예제를 제시하는 것이 더 유효한 경우가 많습니다.



### Solving Prior Distribution Mismatch in Diffusion Models via Optimal Transpor (https://arxiv.org/abs/2410.13431)
- **What's New**: 이 논문에서는 확산 모델(Diffusion Models, DMs)과 최적 운송 이론(Optimal Transport, OT) 사이의 깊은 관계를 탐구하며, DMs에서 발생하는 prior error를 제거하기 위한 새로운 접근 방식을 제안합니다.

- **Technical Details**: 논문은 DMs이 시간 의존적인 OT 계산 방법으로 구성되어 있음을 보여주고, 전통적인 확산 모델에서 발생하는 prior error가 잠재적인 공백을 초래한다는 것을 이론적으로 분석합니다. 또한, 확산 종료 시간이 증가함에 따라 확률 흐름이 Monge-Ampère 방정식의 해결책의 기울기로 기하급수적으로 수렴한다는 것을 증명합니다.

- **Performance Highlights**: 다양한 이미지 데이터세트에서의 실험 결과는 제안한 접근 방식의 효과성을 입증하며, 특히 조건부 및 비조건부 생성 상황에 대한 샘플링 가속화에 자연스럽게 확장될 수 있음을 보여줍니다.



### Shavette: Low Power Neural Network Acceleration via Algorithm-level Error Detection and Undervolting (https://arxiv.org/abs/2410.13415)
- **What's New**: 본 논문은 Deep Neural Network(DNN) 가속기의 전압 저하 운영을 소프트웨어 수정만으로 가능하게 하는 간단한 접근 방식을 소개합니다. 기존의 기술들, 특히 Timing Error Detection(TED) 시스템은 상당한 개발 비용과 오버헤드를 발생시키며, 상용 부품에서는 적용이 어려운 반면, 본 논문에서는 알고리즘 기반의 오류 탐지를 통해 이러한 문제를 해결합니다.

- **Technical Details**: 제안된 접근 방식은 Algorithm Based Fault Tolerance(ABFT) 오류 발견 메커니즘을 통해 이루어집니다. 이를 통해 DNN 모델의 연산을 전환하면서, 전압 마진을 제거하고 가장 에너지 효율적인 전압-주파수(V-F) 조합으로 운영합니다. 실험 결과, LeNet과 VGG16을 GPU 플랫폼에서 실험한 결과, 에너지 소비를 18%에서 25% 절약할 수 있음을 보여주었습니다.

- **Performance Highlights**: 제안된 알고리즘은 정확도 손실 없이 모델의 에너지 소비를 절감하며, 처리량 저하도 3.9% 미만으로 유지됩니다. 기존의 TED 기반 기술과 비교했을 때, 본 접근법은 회로 수정 없이 낮은 개발 비용으로 구현이 가능하다는 장점이 있습니다.



### MoR: Mixture of Ranks for Low-Rank Adaptation Tuning (https://arxiv.org/abs/2410.13408)
Comments:
          11 pages, 7 figures

- **What's New**: 이 논문에서는 Mixture of Ranks (MoR)라는 새로운 접근 방식을 도입하여 LoRA의 성능을 개선하고, 다중 작업에서 효율적으로 학습할 수 있는 방법을 제안합니다. 기존의 LoRA와 MoE 방식의 한계를 극복하고, 다양한 작업에 대한 rank-specific 정보를 효과적으로 학습합니다.

- **Technical Details**: MoR은 세 가지 주요 구성 요소인 공유 전문가(shared experts), 다중 rank 적응(multi-rank adaptation), 혼합 학습(mixture learning)으로 구성됩니다. 이 방법은 여러 LoRA를 통합하여 학습할 수 있는 새로운 프레임워크를 제공하며, 매핑(mapping) 및 스케일링(scaling)을 통해 다중 작업을 수행합니다.

- **Performance Highlights**: MoR는 기존 LoRA 방법 대비 1.31%의 성능 향상을 달성하면서도 파라미터는 93.93%만 사용합니다. 또한, 다양한 실험에서 MoR은 효율성, 일반화 가능성, 확장성을 입증하며, 다중 LoRA 구조의 학습 비용을 크게 줄이고 더 간결한 정보를 동적으로 학습할 수 있음을 보여줍니다.



### Context-aware adaptive personalised recommendation: a meta-hybrid (https://arxiv.org/abs/2410.13374)
- **What's New**: 이번 논문에서는 정보를 종합할 수 있는 메타 하이브리드 추천 시스템을 제안하고 있습니다. 이 시스템은 사용자마다 최적의 추천 알고리즘을 예측하기 위해 Machine Learning을 사용할 수 있도록 개발되었습니다.

- **Technical Details**: 제안된 메타 하이브리드 추천 시스템은 사용자에 대한 맥락적 및 선호 정보를 기반으로 다양한 추천 알고리즘 중에서 최고의 성능을 발휘하는 것을 선택합니다. 오프라인 평가를 위해 MovieLens와 The Movie DB 데이터셋을 사용하였으며, 이를 통해 각 세션과 사용자에 적합한 추천기를 선택할 수 있습니다.

- **Performance Highlights**: 이 연구에서 제안한 메타 하이브리드 추천 시스템은 정상화된 Discounted Gain과 Root Mean Square Error 메트릭에서 기존의 개별 접근 방식보다 20-50% 더 나은 성능을 보였습니다. 그러나 사용자의 표준 정보 기반으로 최적 성능을 달성하기란 어려운 과제입니다.



### MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models (https://arxiv.org/abs/2410.13370)
Comments:
          Project page: this https URL

- **What's New**: 이번 논문에서는 텍스트-이미지(T2I) 모델의 개인화 작업에서 구성 요소를 제어할 수 있는 새로운 접근법을 제시합니다. 사용자가 특정 시각적 개념의 개별 요소를 재구성할 수 있도록 하여 더 정밀한 커스터마이징을 가능하게 합니다. 

- **Technical Details**: 새로운 프레임워크인 MagicTailor를 통해 Dynamic Masked Degradation (DM-Deg)과 Dual-Stream Balancing (DS-Bal)을 활용하여 개인화 과정에서의 의미적 오염(semantic pollution)을 줄이고, 의미적 불균형(semantic imbalance)을 관리합니다. 이 프레임워크는 T2I 모델을 동적으로 조정하여 개인화된 개념을 정확하게 반영합니다.

- **Performance Highlights**: MagicTailor는 실험을 통해 구성 요소 제어가 가능한 개인화 작업에서 최첨단(SOTA) 성과를 달성하였으며, 다양한 추가 응용 가능성을 보여줍니다.



### Remember, Retrieve and Generate: Understanding Infinite Visual Concepts as Your Personalized Assistan (https://arxiv.org/abs/2410.13360)
- **What's New**: 본 논문에서는 Retrieval Augmented Personalization (RAP) 프레임워크를 소개하여 다중 모드 대형 언어 모델(MLLMs)의 개인화를 가능하게 합니다. RAP는 일반 MLLM을 개인화된 어시스턴트로 전환하는 세 가지 주요 단계로 구성됩니다: 기억(Recall), 검색(Retrieve), 생성(Generate).

- **Technical Details**: RAP는 사용자 관련 정보(예: 이름, 아바타 등)를 저장하는 키-값 데이터베이스를 설계합니다. 사용자가 대화를 시작할 때, RAP는 다중 모드 검색기를 통해 데이터베이스에서 관련 정보를 검색하고, 이를 MLLM에 입력하여 개인화된 지식 강화 응답을 생성합니다. 추가로 생성 품질 향상을 위해 데이터 수집 파이프라인을 개발하고 개인화된 훈련을 위한 전문적인 데이터셋을 생성합니다.

- **Performance Highlights**: RAP-MLLMs는 개인화된 이미지 캡션 작성, 질문 응답 및 시각적 인식과 같은 다양한 작업에서 뛰어난 유연성과 생성 품질을 보여줍니다. 모델들은 무한한 시각적 개념에 대해 일반화 능력을 발휘하며, 사용자 관련 정보를 효과적으로 처리하여 개인화된 출력을 제공합니다.



### DART: Disentanglement of Accent and Speaker Representation in Multispeaker Text-to-Speech (https://arxiv.org/abs/2410.13342)
Comments:
          Accepted in Audio Imagination workshop of NeurIPS 2024

- **What's New**: 최근 Text-to-Speech (TTS) 시스템에서 자연스럽고 표현력이 풍부한 음성을 생성할 수 있는 발전이 있었습니다. 이 논문에서는 다국적 사용자를 위해 발음과 화자 식별을 효과적으로 분리하는 새로운 접근법을 제안합니다.

- **Technical Details**: 본 연구에서는 Multi-Level Variational Autoencoders (ML-VAE)와 Vector Quantization (VQ)를 사용하여 화자와 발음 표현을 분리하는 방법을 제안합니다. ML-VAE는 계층적으로 데이터의 공동 분포를 모델링하기 위해 구성되며, 이를 통해 화자와 발음의 특성을 명확하게 분리합니다.

- **Performance Highlights**: 제안된 방법은 다양한 발음화된 음성 데이터에 대해 실험하여 효과성을 입증하였으며, 사용자 맞춤형 음성 합성을 가능하게 합니다. 코드와 음성 샘플은 공개되어 활용 가능합니다.



### DiffImp: Efficient Diffusion Model for Probabilistic Time Series Imputation with Bidirectional Mamba Backbon (https://arxiv.org/abs/2410.13338)
Comments:
          25 pages, 14 figures

- **What's New**: 이번 논문에서는 확률적 시계열 보간 기술을 위한 새로운 프레임워크인 DiffImp를 제안합니다. DiffImp는 시계열 데이터의 복잡한 분포를 모델링할 수 있는 능력으로 Denoising Diffusion Probabilistic Models (DDPMs)를 활용합니다.

- **Technical Details**: DiffImp는 효율적인 State Space Model (SSM)인 Mamba를 backbone으로 통합하여 denoising 모듈을 구성합니다. 이를 통해 낮은 시간 복잡도로 시퀀스 모델링이 가능하며, Bidirectional Attention Mamba block (BAM)을 통해 양방향 종속성을 처리하고, Channel Mamba Block (CMB)을 통해 서로 다른 채널 간의 의존성을 모델링합니다.

- **Performance Highlights**: DiffImp는 다양한 데이터 세트를 사용한 실험에서 최첨단 성능을 달성하였으며, 다양한 결측 시나리오와 결측 비율에서 우수한 결과를 보여주었습니다.



### Improving Discrete Optimisation Via Decoupled Straight-Through Gumbel-Softmax (https://arxiv.org/abs/2410.13331)
- **What's New**: 이 논문에서는 Straight-Through Gumbel-Softmax (ST-GS) 추정기를 개량한 'Decoupled ST-GS'를 제안합니다. 이 방법은 순방향(forward)과 역방향(backward) 패스를 위한 온도(temperature) 매개변수를 분리하여 gradient의 신뢰성과 모델 성능 간의 균형을 개선합니다.

- **Technical Details**: Decoupled ST-GS은 ST-GS 추정기의 구조를 바탕으로 하며, 온도 조정에서 수반되는 어려움을 해결하기 위해 각각의 패스에 대해 고유한 온도를 사용합니다. 이는 모델의 추론 시 스무딩(smoothing)과 훈련 시 gradient의 신뢰성을 독립적으로 조정할 수 있게 합니다.

- **Performance Highlights**: 다양한 과제(task)와 데이터 세트에서의 실험을 통해 Decoupled ST-GS가 기존 ST-GS 추정기보다 일관되게 뛰어난 성능을 보였음을 입증했습니다. 이 방법은 gradient gap과 bias-variance trade-off 분석을 통해 gradient 기반 최적화의 개선을 도모합니다.



### Precipitation Nowcasting Using Diffusion Transformer with Causal Attention (https://arxiv.org/abs/2410.13314)
- **What's New**: 이번 연구에서는 Diffusion Transformer with Causal Attention 모델을 제안하여 단기 강수 예보의 문제를 해결하고자 합니다. 이 모델은 Transformer를 활용하여, 조건 정보와 예보 결과 간의 시공간 쿼리를 효과적으로 설정할 수 있도록 합니다.

- **Technical Details**: DTCA(분산 변환기 인과 주의) 모델은 조건부 강수 분포 특징 관련 쿼리를 기반으로 한 새로운 인과 주의 메커니즘을 도입하며, 다양한 시공간 정보 상호작용을 탐색하고 그 구조를 비교합니다. 실험 결과, 전역 시공간 레이블링 상호작용이 최고의 성능을 발휘하는 것으로 나타났습니다.

- **Performance Highlights**: 제안된 방법은 최신 기술인 U-Net 기반 방법과 비교해 강수 예측에서 약 15% 및 8% 개선된 CSI(비판적 성공 지표)를 달성하여 현재 상태의최고 성능을 기록했습니다.



### Active inference and deep generative modeling for cognitive ultrasound (https://arxiv.org/abs/2410.13310)
- **What's New**: 초음파(US) 이미징 시스템을 정보 탐색 에이전트로 재구성하여 효율적인 진단을 위한 대칭적 상호작용을 제안합니다. 이 시스템은 자율적으로 촬영을 개인화하고 현장에서 정보 획득을 극대화합니다.

- **Technical Details**: 이 연구에서는 초음파 데이터 수집과 재구성이 '지각-행동 루프(perception-action loop)'로 해석되며, Bayesian inference를 통해 불확실성을 줄이고 진단 가치를 극대화하는 방법을 설명합니다. 시스템은 생성적 모델을 활용하여 환경을 이해하고 최적의 측정을 계획합니다.

- **Performance Highlights**: 딥 생성적 모델을 통해 초음파 이미징의 품질과 진단 정확도를 크게 향상시킬 수 있는 잠재력을 보여주며, 특히 어려운 환자 군에서 지속적인 이미지 분석 및 개입이 가능하도록 합니다.



### Hiformer: Hybrid Frequency Feature Enhancement Inverted Transformer for Long-Term Wind Power Prediction (https://arxiv.org/abs/2410.13303)
- **What's New**: 본 논문에서는 기후 변화의 심각성이 증가함에 따라 재생 에너지로의 긴급한 전환이 필요하다는 점을 강조하고, 특히 풍력 에너지의 대규모 채택이 환경 영향을 완화하는 데 중요하다고 설명합니다. 이는 장기적인 풍력 예측 모델의 필요성을 강조합니다.

- **Technical Details**: 이 논문은 Hybrid Frequency Feature Enhancement Inverted Transformer (Hiformer)라는 새로운 접근 방식을 제안합니다. Hiformer는 신호 분해 기술과 날씨 특징 추출 기술을 통합하여 기상 조건과 풍력 생성 간의 상관관계를 모델링하는 독특한 구조를 가지고 있습니다. 또한 Hiformer는 인코더 전용 아키텍처를 사용하여 장기 풍력 예측에 따른 계산 복잡성을 줄입니다.

- **Performance Highlights**: Hiformer는 최신 방법과 비교하여 예측 정확도를 최대 52.5% 향상시킬 수 있으며, 계산 시간을 최대 68.5% 단축할 수 있습니다.



### Automating IETF Insights generation with AI (https://arxiv.org/abs/2410.13301)
Comments:
          5 pages plus Appendix

- **What's New**: 이 논문은 IETF Insights 프로젝트를 소개합니다. 이 시스템은 Internet Engineering Task Force (IETF) 작업 그룹의 활동에 대한 포괄적인 보고서를 자동으로 생성하여 효율화하는 기능을 가지고 있습니다.

- **Technical Details**: 시스템은 회의록(meeting minutes), 참가자 목록(participant lists), 초안(drafts) 및 의제(agendas)와 같은 다양한 IETF 소스에서 데이터를 수집, 통합 및 분석하는 기능을 포함합니다. 주요 구성 요소로는 데이터 전처리 코드(data preprocessing code)와 LaTeX 또는 Markdown 형식으로 고품질 문서를 생성하는 보고서 생성 모듈(report generation module)이 있습니다. 또한 데이터에 기반한 요약을 위한 대규모 언어 모델(large Language Models, LLMs)를 통합하여 IETF 기록의 접근성 및 유용성을 높입니다.

- **Performance Highlights**: IETF Insights 프로젝트는 IETF의 활동 및 커뮤니티에 대한 기여에 대한 귀중한 개요를 제공하며, IETF 기록의 효율적인 관리와 활용을 촉진합니다.



### LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models (https://arxiv.org/abs/2410.13299)
- **What's New**: 본 논문에서는 그래프 이론의 중심성 측정을 활용한 새로운 프루닝(pruning) 방법인 MLPRank를 제안하였습니다. 이 방법은 다층 퍼셉트론(multilayer perceptron)과 디코더 전용(transformer) 모델을 대상으로 하여 계산 요구 사항과 메모리 사용량을 줄입니다.

- **Technical Details**: MLPRank는 가중 방향 비순환 그래프(weighted directed acyclic graph)를 생성하여 각 노드의 중요도를 평가하는 데 수정된 PageRank 중심성 측정을 사용합니다. 이와 함께 균일 프루닝(uniform pruning)을 적용하여 구조적 희소성(structured sparsity)을 달성합니다. 또한, 디코더 전용 모델에 대한 확장된 방법인 LLMRank도 소개하였습니다.

- **Performance Highlights**: MLPRank는 세 가지 인기 있는 기준과 비교하여 평균 6.09%의 정확도 유지를 보여주고, LLMRank는 두 가지 기준에 비해 13.42% 높은 성능을 보였습니다. 두 방법 모두 최신 구조적 프루닝 기법인 SliceGPT보다 평균 8.60% 높은 정확도를 기록했습니다.



### Fairness-Enhancing Ensemble Classification in Water Distribution Networks (https://arxiv.org/abs/2410.13296)
- **What's New**: 이 논문에서는 사회 경제적으로 중요한 기반 시설인 물 분배 네트워크(Water Distribution Networks, WDNs)에서 AI의 공정성 문제를 다루고 있습니다. WDNs의 공정성에 대한 기존 연구가 부족한 만큼, 이 연구는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 연구자들은 그룹 공정성(Group Fairness)의 개념을 도입하고, 비이진(Binomial) 민감 변수에 대한 정의를 명확히 하였습니다. 기존의 누수 탐지 방법들이 공정하지 않음을 입증하였고, 비구분 가능한 앙상블(Ensemble) 분류 방법에 적용할 수 있는 공정성을 높이기 위한 방법을 제안했습니다.

- **Performance Highlights**: 이 논문은 WDNs에서 머신러닝 모델의 공정성을 평가하기 위한 표준 방법론을 제시하고, 여러 개의 민감 변수를 고려하여 기존 방법론의 몇 가지 조정을 통해 공정성을 강화할 수 있음을 설명합니다.



### PiLocNet: Physics-informed neural network on 3D localization with rotating point spread function (https://arxiv.org/abs/2410.13295)
Comments:
          25 pages, 4 figures

- **What's New**: 이 논문은 3D localization 문제 해결을 위한 새로운 개선된 Neural Network PiLocNet을 제안합니다. PiLocNet은 기존의 LocNet을 기반으로 하며, forward-model 기반 정보와 data-fitting loss term을 통합하여 물리적으로 합리적인 결과를 도출합니다.

- **Technical Details**: PiLocNet은 Physics-Informed Neural Network (PINN)으로, 이미징 시스템의 포인트 스프레드 함수(PSF)를 통해 물리적 정보를 네트워크에 통합합니다. 세 가지 중요한 구성 요소로는 forward-model 정보, variational method의 regularization term, 그리고 Poisson 및 Gaussian noise 모델을 통한 이미지 노이즈에 대한 강건성 개선이 포함됩니다.

- **Performance Highlights**: 실험 결과, PiLocNet은 3D 포인트 소스의 localization을 위한 정확도 향상에 기여하며, precision과 recall 측면에서 개선된 예측 결과를 보여줍니다. 본 논문은 PiLocNet의 Robustness를 검증했으며, 다양한 PSF와 이미징 문제에서의 적용 가능성을 제시합니다.



### SBI-RAG: Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation (https://arxiv.org/abs/2410.13293)
Comments:
          Accepted to the 4th MATH-AI Workshop at NeurIPS'24

- **What's New**: 본 논문에서는 Schema-Based Instruction Retrieval-Augmented Generation (SBI-RAG) 프레임워크를 제안합니다. 이 프레임워크는 대형 언어 모델(LLM)을 통합하여 수학 단어 문제(MWP)를 해결하는 과정을 지원하며, 기존의 Schema-Based Instruction(SBI) 방법을 바탕으로 발전했습니다.

- **Technical Details**: SBI-RAG는 기본적으로 네 가지 주요 부분으로 나뉩니다: 1) Schema Classifier, 2) Prompt Creation, 3) Context Retrieval, 4) Answer and Response Generation. Schema Classifier는 DistilBERT를 기반으로 하여 특정 문제에 적합한 schema를 예측하고, 그에 따라 schema-specific prompt를 생성합니다. 이후 Retrieval-Augmented Generation(RAG) 프레임워크를 이용하여 관련 문서를 검색하고, LLM을 통해 구체적인 단계별 해답을 생성합니다.

- **Performance Highlights**: GSM8K 데이터셋에서의 평가 결과, SBI-RAG는 GPT-4 및 GPT-3.5 Turbo와 비교하여 문제 해결의 정확성과 추론의 명료성을 향상시키는 데 효과적임을 보였습니다. 새로운 'reasoning score' 메트릭을 도입하여 LLM의 해결 과정의 질을 평가하였으며, 이는 학생들의 교육적 이점을 제공할 가능성이 있습니다.



### The Latent Road to Atoms: Backmapping Coarse-grained Protein Structures with Latent Diffusion (https://arxiv.org/abs/2410.13264)
Comments:
          Paper under review

- **What's New**: 본 논문에서는 Latent Diffusion Backmapping (LDB)이라는 새로운 접근법을 제시하여, coarse-grained (CG) 분자 동역학 시뮬레이션에서의 단백질 구조 복원을 위한 효율성을 높입니다. 기존의 backmapping 방법들이 직면했던 문제들을 해결하기 위해, LDB는 노이즈 제거(diffusion) 기법을 이용해 라텐트(latent) 공간 내에서 구조를 효율적으로 재구성합니다.

- **Technical Details**: LDB는 노드 레벨의 라텐트 표현을 통해 모든 원자 구조를 인코딩하며, 화학적 유효성을 보장하기 위해 물리적 제약(예: 결합 길이 및 각도)을 적용합니다. 이는 광범위한 후처리 과정 없이도 화학적 유효성을 달성하고, 미세조정되지 않은 개별 원자 구조 복원을 통해 동적인 구조 공간 탐색을 용이하게 만듭니다. 이 방법은 조건부(conditional) 노이즈 제거 모델을 포함하여 디스크리트 라텐트 코드에서 작동함으로써 예측 정확성과 다양한 단백질 구조 생성을 극대화합니다.

- **Performance Highlights**: LDB는 PED, ATLAS 및 PDB와 같은 여러 단백질 다이너믹스 데이터셋에서 최신 성능을 입증하였으며, 구조적 정확성과 화학적 유효성을 유지하며 단백질 앙상블을 효율적으로 복원하는 능력을 보여주었습니다. 이러한 개선 사항에 따라 LDB는 CG 시뮬레이션과 원자 수준 분석 간의 격차를 효과적으로 연결하는 강력하고 확장 가능한 접근법으로 자리잡았습니다.



### scFusionTTT: Single-cell transcriptomics and proteomics fusion with Test-Time Training layers (https://arxiv.org/abs/2410.13257)
- **What's New**: 이번 논문에서는 CITE-seq 데이터를 활용한 단일 세포 다중 오믹스(scMulti-omics) 분석을 위한 새로운 방법인 scFusionTTT를 제안합니다. 이 방법은 Test-Time Training (TTT) 기반의 마스크 오토인코더(masked autoencoder)를 사용하여 유전자와 단백질 순서 정보를 통합하고, 다중 오믹스 데이터를 융합하는 데 기여합니다.

- **Technical Details**: scFusionTTT는 TTT 레이어를 적용하여 다중 오믹스 데이터를 처리하는 혁신적인 접근 방식을 제공합니다. 기존의 모형들이 간과했던 유전자 간의 순차적 관계를 고려하며, 고차원 데이터의 희소성 문제를 해결하기 위해 세 가지 단계의 훈련 전략을 사용합니다. 이 방법은 단일 세포 전사체(transcriptomics) 및 단백질체(proteomics) 데이터를 통합하여 균형 잡힌 표현을 학습하도록 고안되었습니다.

- **Performance Highlights**: scFusionTTT는 4개의 CITE-seq 데이터셋과 4개의 단일 세포 RNA 시퀀싱(scRNA-seq) 데이터셋에서 우수한 성능을 보여주었습니다. 모든 비교 기준에서 기존의 최첨단 방법들과 비교했을 때 더 나은 결과를 달성하였으며, 이는 모델의 유용성과 신뢰성을 입증하는 데 기여합니다.



### Automatic Translation Alignment Pipeline for Multilingual Digital Editions of Literary Works (https://arxiv.org/abs/2410.13255)
Comments:
          18 pages, Computational Humanities Research Conference, December 4-6, 2024, Aarhus, Denmark

- **What's New**: 이 논문은 Alessandro Manzoni의 소설 "I promessi sposi"의 다국어 디지털 에디션(Multilingual Digital Edition, MDE) 제작을 위한 번역 정렬 알고리즘의 적용을 조사합니다. 19세기와 20세기의 8개 언어(영어, 스페인어, 프랑스어, 독일어, 네덜란드어, 폴란드어, 러시아어, 중국어) 번역을 포함하여 MDE의 주요 요구 사항을 식별하고, 문학 텍스트 번역에 대한 현재 알고리즘의 한계를 강조하며, MDE 생성을 위한 자동화된 파이프라인을 제안합니다.

- **Technical Details**: 이 연구에서는 문학 작품의 다국어 디지털 에디션을 제작하기 위해 최신 정렬 기법을 적용하는 자동 번역 정렬 파이프라인을 제안합니다. 이 파이프라인은 원문과 번역 텍스트의 나란히 배치된 웹 기반 표현으로 변환되며, 텍스트 조각을 관리 가능한 길이로 정렬하여 사용자에게 독서 및 분석에 용이하도록 합니다. 또한, 문학 번역의 정렬을 평가하기 위한 새로운 메트릭스를 제안하고 있습니다.

- **Performance Highlights**: 논문에서 제안한 정렬 메트릭스는 기존 정렬 알고리즘의 성능을 보다 포괄적으로 평가할 수 있게 하며, 문학 작품의 다국어 디지털 에디션 제작 시 독자의 집중력과 이해를 증진할 수 있는 방법들을 제시합니다. 이는 번역의 삽입 및 생략된 부분을 시각적으로 강조하여 사용자로 하여금 각 번역의 뉘앙스를 파악할 수 있도록 돕습니다.



### Perceptions of Discriminatory Decisions of Artificial Intelligence: Unpacking the Role of Individual Characteristics (https://arxiv.org/abs/2410.13250)
- **What's New**: 이 연구는 개인의 차이점(디지털 자기 효능감 (digital self-efficacy), 기술 지식 (technical knowledge), 평등에 대한 믿음 (belief in equality), 정치적 이념 (political ideology))과 인구 통계적 요인(연령, 교육, 소득)이 성별 및 인종 차별 편향을 보여주는 인공지능(AI) 결과에 대한 인식과 AI에 대한 일반적인 태도와 어떻게 관련되어 있는지를 조사합니다.

- **Technical Details**: 대규모 실험 데이터셋(N = 1,206)을 분석한 결과, 디지털 자기 효능감과 기술 지식은 AI에 대한 태도와 긍정적인 상관관계를 보였고, 자유주의적 이념은 결과 신뢰도(outcome trust)와 부정적인 감정, 더 큰 회의론(skepticism)과는 부정적인 상관관계가 나타났습니다. 또한, 연령과 소득은 차별적 AI 결과를 이해하는 인지적 격차(cognitive gaps)와 밀접하게 연결되어 있습니다.

- **Performance Highlights**: 이 연구 결과는 디지털 리터러시(digital literacy) 기술을 증진하고 디지털 자기 효능감을 향상시키는 것이 AI에 대한 신뢰와 AI의 유용성 및 안전성에 대한 믿음을 유지하는 데 중요하다는 점을 강조합니다. 또한, 문제 있는 AI 결과에 대한 이해의 차이는 경제적 불평등과 사회의 세대 간 격차와 연관되어 있을 수 있음을 시사합니다.



### Disentangling Likes and Dislikes in Personalized Generative Explainable Recommendation (https://arxiv.org/abs/2410.13248)
- **What's New**: 최근 설명 가능한 추천 시스템에 대한 연구는 표준 텍스트 생성 문제로 접근하며, 모델을 예측된 텍스트와 실제 텍스트 간의 유사성을 기반으로 평가합니다. 그러나 이 접근법은 사용자(구매 후) 감정을 정확히 반영하는지 여부를 간과합니다. 이 연구에서는 사용자의 감정을 중점적으로 고려하는 새로운 데이터셋과 평가 방법을 소개합니다.

- **Technical Details**: 우리는 LLM(Long Language Model)을 사용하여 사용자 구매 후 리뷰에서 긍정적 및 부정적 의견을 명시적으로 추출하여 데이터셋을 구성합니다. 시스템을 평가할 때 생성된 설명이 1) 사용자 감정과 잘 일치하는지, 2) 목표 아이템에 대한 사용자 의견의 긍정적 및 부정적 식별을 정확히 수행하는지에 대한 두 가지 기준을 제안합니다.

- **Performance Highlights**: 여러 최신 모델을 우리의 데이터셋에서 벤치마킹하였으며, 기존 지표에서 높은 성과를 달성하더라도 생성된 설명이 사용자 감정과 잘 일치하지 않을 수 있음을 보여줍니다. 또한, 목표 아이템에 대한 사용자(예측된) 평가가 모델에 직접 입력될 경우, 기존 모델들이 보다 감정 인식적인 설명을 제공할 수 있음을 발견하였습니다.



### Enhancing Sentiment Analysis with Collaborative AI: Architecture, Predictions, and Deployment Strategies (https://arxiv.org/abs/2410.13247)
- **What's New**: 이번 연구에서 소개된 협력적 인공지능 프레임워크는 다양한 인공지능 시스템 간의 작업 분배와 해결을 효율적으로 수행하여 복잡한 감정 분석 문제를 해결하는 데 중점을 두고 있습니다.

- **Technical Details**: 이 연구는 감정 분석을 위해 Generative AI 모델인 ChatGPT와 Google Gemini 같은 모델을 활용하여 복잡한 과제를 관리 가능한 단계적 목표로 단순화하는 방법론을 제시합니다. 논문은 또한 Edge 및 Cloud 환경에서 협력적 AI 시스템을 이용한 사례 연구를 통해 다양하고 풍부한 온라인 미디어 채널에서 감정 분석을 수행하는 효과성을 보여줍니다.

- **Performance Highlights**: 협력적 AI 시스템은 멀티모달 데이터 처리에서 우수한 성능을 발휘하며, 전통적인 LLM이나 신경망보다 더 넓고 정확한 감정 분석 결과를 제공합니다. 알고리즘 기반의 프롬프트 개선도 이루어져 감정 보고서 출력의 안정성을 높였습니다.



### Atomic Calibration of LLMs in Long-Form Generations (https://arxiv.org/abs/2410.13246)
- **What's New**: 본 논문에서는 LLM(대규모 언어 모델)의 신뢰성을 높이기 위한 새로운 접근법인 atomic calibration을 제안합니다. 기존의 macro calibration은 주로 짧은 응답에 대한 신뢰도를 평가하는 데 초점을 맞추었으나, 긴 응답의 경우 더욱 복잡한 진술이 포함될 수 있어 적합하지 않다는 점을 강조하였습니다.

- **Technical Details**: atomic calibration은 긴 응답을 작은 단위인 atomic claims로 분해하여 세부적인 신뢰도를 평가합니다. 본 연구에서는 LLM의 신뢰성 추정 방법을 discriminative와 generative 유형으로 나누고, 이들의 조합이 calibration을 개선할 수 있음을 보여줍니다. 또한, 7종의 LLM과 3개의 데이터셋을 사용하여 실험을 수행하였습니다.

- **Performance Highlights**: atomic calibration은 긴 형식의 생성 과정에서도 잘 작동하며, macro calibration 결과를 개선할 수 있는 것으로 나타났습니다. 이 방법은 LLM의 생성 과정에서 신뢰성과 calibration 변화의 패턴을 심도 있게 분석할 수 있는 가능성을 열어줍니다.



### Large Language Models are Easily Confused: A Quantitative Metric, Security Implications and Typological Analysis (https://arxiv.org/abs/2410.13237)
Comments:
          17 pages, 6 figures, 14 tables

- **What's New**: 이번 연구에서는 Large Language Models (LLMs)에서 발생하는 'Language Confusion' 현상을 분석하고, 이를 정량화하기 위한 새로운 측정 기준인 'Language Confusion Entropy'를 제안합니다. 이는 다양한 언어 분포의 패턴을 탐구하며, LLM 보안과의 연관성도 밝혔습니다.

- **Technical Details**: Language Confusion Entropy는 LLM에서 발생하는 언어 혼란 정도를 정량화하는 지표로, 언어 유형론에 기반한 언어 분포를 사용하여 LLM이 혼란스러울 때의 양상을 포착합니다. 이 연구는 여러 언어 간의 의미적 유사성과 LLM의 취약성을 연결지으며, 다국어 임베딩 역전 공격(multilingual embedding inversion attacks)에 대한 통찰을 제공합니다.

- **Performance Highlights**: 연구 결과, 언어 유형론을 기반으로 분석한 패턴들이 언어 혼란과 연관되어 있음을 발견했습니다. 특히 자원이 적은 언어는 혼란이 덜 발생하며, 다양한 스크립트와 언어 계열을 아우르는 훈련이 언어 혼란을 보다 효과적으로 완화할 수 있다는 결과를 도출했습니다.



### SPIN: Self-Supervised Prompt INjection (https://arxiv.org/abs/2410.13236)
- **What's New**: 이번 논문에서는 Self-supervised Prompt INjection (SPIN)라는 새로운 방어 메커니즘을 도입하여, 다양한 adversarial 공격 및 jailbreak 공격에 대해 LLMs의 안전성을 향상시키는 방법을 제시합니다. SPIN은 추론 시간(inference-time)에서 이루어지므로 기존의 안전성 정렬과 호환되며 추가적인 안전성 레이어를 제공합니다.

- **Technical Details**: SPIN은 self-supervised learning을 기반으로 하여, 공격을 탐지하고 입력을 복구하는 방어 기법입니다. LLM의 자연 가이드라인을 무효화하는 프롬프트가 모델의 다른 능력도 저하시키기 때문에, 이를 이용해 공격을 탐지할 수 있습니다. 방어 메커니즘은 기존의 방어 시스템과의 호환성이 있으며, 악의적 또는 선의적 레이블에 의존하지 않고 재빠른 시점에서 온라인으로 사용할 수 있습니다.

- **Performance Highlights**: SPIN의 적용 결과, Attack Success Rate (ASR)를 최대 87.9%까지 감소시킬 수 있었으며, benign 사용자 요청에 대한 성능을 유지했습니다. Advbench에서 Universal Adversarial Triggers를 사용한 실험 결과, Vicuna 모델에서는 ASR이 12.11%, Llama-2 모델에서는 0%로 감소하여 두 모델을 완전히 보호했습니다. 또한, 공격자들이 방어 체계를 알고 있어도 여전히 강인성을 보였습니다.



### Quamba: A Post-Training Quantization Recipe for Selective State Space Models (https://arxiv.org/abs/2410.13229)
- **What's New**: 본 연구는 State Space Models (SSMs)을 위한 정적 8-bit per-tensor quantization 방법을 제안하여 모델의 효율성을 크게 향상시키고, 클라우드 및 에지 플랫폼에서의 원활한 배포를 지원합니다.

- **Technical Details**: 제안된 방법은 Hadamard 변환을 활용하여 SSM의 출력 활성화에서 극단적인 아웃라이어를 부드럽게 하고, 선택적 SSM에 대한 입력 활성화의 최대값을 억제하여 더 섬세한 quantization 정밀도를 제공합니다. 또한, 8-bit 정량화된 Mamba 2.8B SSM은 Nvidia Orin Nano 8G에서 1.72배 더 낮은 생성 지연 시간을 달성하며, 평균 정확도는 0.9% 감소했습니다.

- **Performance Highlights**: Mamba SSM은 하드웨어 가속의 이점을 누리며, 다양한 크기의 SSM 기반 모델의 클라우드 및 에지 플랫폼에서의 효과성과 실용성을 입증했습니다.



### From PINNs to PIKANs: Recent Advances in Physics-Informed Machine Learning (https://arxiv.org/abs/2410.13228)
Comments:
          physics-informed neural networks, Kolmogorov-Arnold networks, optimization algorithms, separable PINNs, self-adaptive weights, uncertainty quantification

- **What's New**: 최근 Physicas-Informed Neural Networks (PINNs)의 발전이 뚜렷하며, 새로운 구조와 최적화 기법이 포함된 Physics-Informed Kolmogorov-Arnold Networks (PIKANS) 등이 소개되었습니다. PINNs는 물리 법칙을 반영하여 희소 데이터로도 효율적으로 PDE(Partial Differential Equations)를 해결합니다.

- **Technical Details**: PINNs는 물리 법칙을 인코딩하기 위해 추가적인 ‘residual’ 손실 항을 포함하며, 자동 미분을 이용하여 효율적으로 계산합니다. 이를 통해 전통적인 수치적 방법 한계를 극복하고, 복잡한 기하구조를 다루는 데 유리합니다. 또한, PINNs는 불확실성 정량화 및 다양한 최적화 기법을 수용할 수 있습니다.

- **Performance Highlights**: PINNs는 생의학, 유체 역학, 지구 물리학 등 다양한 분야에서 적용 가능함을 보여주었으며, 2017년 첫 발표 이후 11,000회 이상의 인용이 이루어졌습니다. 또한, 여러 연구 그룹에서 PINNs의 알고리즘 개선 및 적용 가능성을 탐색하고 있습니다.



### CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy (https://arxiv.org/abs/2410.13218)
- **What's New**: 본 논문은 지금의 정신 건강 지원에서 환자의 필요와 제공 가능한 지원 간의 큰 격차를 해결하기 위한 접근법으로서, 대형 언어 모델(LLMs)을 전문적인 심리 치료에 활용하는 가능성을 깊이 조사합니다. 특히, 우리는 인지 행동 치료(CBT) 지원의 체계적 평가를 위한 새로운 벤치마크인 CBT-BENCH를 제안합니다.

- **Technical Details**: CBT-BENCH는 세 가지 수준의 과제로 구성됩니다: I: 기본 CBT 지식 습득을 위한 다중 선택 질문; II: 인지 모델 이해를 위한 인지 왜곡 분류, 주요 핵심 신념 분류, 세부 핵심 신념 분류 작업; III: CBT 세션에서 환자 발화에 대한 치료적 응답 생성. 논문에서는 CBT의 핵심 측면을 AI 지원을 통해 향상할 수 있는 가능성을 조명하며, 각 과제는 기본 지식 암기부터 실제 치료 대화에 참여하는 것과 같은 복잡한 능력 요구 사항의 계층을 포함합니다.

- **Performance Highlights**: 실험 결과에 따르면 LLMs는 CBT 지식을 암기하는 데는 상대적으로 잘 수행하였지만, 환자의 인지 구조에 대한 깊은 분석이 필요한 복잡한 실제 시나리오에서는 부족한 성과를 보였습니다. LLMs는 일반적으로 엄격한 논리적 추론 프로세스를 따르지만, 치료에서 중요한 환자의 관점에서 사고하고 관계를 구축하는 능력이 부족하다는 제한점을 보여주었습니다.



### MixEHR-Nest: Identifying Subphenotypes within Electronic Health Records through Hierarchical Guided-Topic Modeling (https://arxiv.org/abs/2410.13217)
- **What's New**: MixEHR-Nest는 전자 건강 기록(EHR) 데이터를 활용하여 고유한 하위 표현형(sub-phenotype) 주제를 유도하는 새로운 지침(topic model) 모델입니다. 이 모델은 경험적인 표현형 개념(PheCodes, CCS 코드를 포함)으로 초기화된 하위 주제를 탐지하여 질병 패턴을 더욱 세분화하여 나타냅니다.

- **Technical Details**: MixEHR-Nest는 다중 모달(multi-modal) EHR 데이터에서 1500개 이상의 표현형으로부터 뚜렷한 하위 표현형 주제를 유도할 수 있는 구조화된 하이라키(topic model)입니다. 이 모델은 각 환자의 의료 기록을 문서(document)로, 코드(예: ICD 코드)를 단어 토큰(word tokens)으로 간주하여 학습합니다. 이 연구는 하위 표현형 주제의 묘사, 다중 유형의 EHR 정보 학습, 높은 해석 가능성을 통한 자동 하위 표현형 유도를 포함합니다.

- **Performance Highlights**: MixEHR-Nest는 ICU 환자 사망률 예측, 당뇨병 환자의 초기 인슐린 치료 예측에서 성능을 향상시켰습니다. 또한 MixEHR-Nest는 같은 표현형 아래에서 연령 분포의 뚜렷한 하위 표현형을 확인함으로써 다양한 질병에 걸쳐 질병의 진행 및 중증도를 예측하는 데 기여했습니다.



### AsymKV: Enabling 1-Bit Quantization of KV Cache with Layer-Wise Asymmetric Quantization Configurations (https://arxiv.org/abs/2410.13212)
Comments:
          12 pages, 4 figures

- **What's New**: 이번 연구에서는 Large Language Model (LLM)에서 Key-Value Cache (KV Cache)의 비대칭적 구조적 역할을 심층적으로 탐구하고, 이를 바탕으로 새로운 비대칭 양자화 전략인 AsymKV를 제안합니다. 기존의 양자화 기법이 키와 값 행렬에 동일한 구성을 사용하는 것 대신, 키와 값 행렬에 서로 다른 비트 양자화를 적용하는 방식을 채택합니다.

- **Technical Details**: 연구에서는 모델 양자화의 일환으로, KV Cache의 키 행렬과 값 행렬에 대해 비대칭적으로 1비트 양자화를 적용하는 방법을 제시합니다. 이 과정에서 각 행렬의 구조적 특성을 고려하여, 초기 몇 개의 디코더 레이어에는 4비트 양자화를 적용하고 이후의 레이어에는 1비트를 적용하는 방식으로 구현합니다. 또한, 실험을 통해 다양한 데이터셋에서 이 방법을 검증하였습니다.

- **Performance Highlights**: 실험 결과, AsymKV 접근법은 최대 75%의 디코더 레이어를 1비트로 양자화하면서도, 부동소수점 매개변수를 사용할 때와 비슷한 성능 수준을 유지하는 것으로 나타났습니다. 이는 메모리 소비를 줄이면서도 모델의 성능을 보장할 수 있는 효율적인 전략임을 입증합니다.



### Estimating the Probabilities of Rare Outputs in Language Models (https://arxiv.org/abs/2410.13211)
Comments:
          27 pages, 9 figures

- **What's New**: 이 논문은 저확률 추정(low probability estimation) 문제를 다루며, 이는 머신 러닝 모델의 출력으로부터 특정 이진 속성을 추정하는 과정을 포함합니다. 이러한 추정은 확률이 매우 작아 랜덤 샘플링(random sampling)으로는 불가능할 수 있으며, 분포 이동(distribution shift) 문제를 해결하기 위해 필수적입니다.

- **Technical Details**: 저자들은 두 가지 방법을 비교합니다: 1) Importance Sampling(중요도 샘플링): 드문 출력(event)을 생성하는 입력을 위해 새로운 입력 분포를 정의하는 방법입니다. 이 방법에는 Independent Token Gradient Importance Sampling(ITGIS)과 Metropolis-Hastings Importance Sampling(MHIS)이 포함됩니다. 2) Activation Extrapolation(활성화 외삽): 모델 로그잇(logits)에 맞춰 확률 분포를 피팅하고, 이를 기반으로 외부로 확장하는 방법입니다. 이 방법은 Quadratic Logit Decomposition(QLD)과 Gaussian Logit Difference(GLD)로 나눌 수 있습니다.

- **Performance Highlights**: 실험 결과, 중요도 샘플링 방법이 활성화 외삽보다 우수하며, 두 방법 모두 무작위 샘플링보다 좋습니다. 이는 최악의 성능 보장을 제공하기 위한 새로운 저확률 추정 기법이 필요하다는 점을 강조합니다.



### FaithBench: A Diverse Hallucination Benchmark for Summarization by Modern LLMs (https://arxiv.org/abs/2410.13210)
- **What's New**: 이 논문에서는 10개의 현대 LLM(대형 언어 모델)와 8개의 모델 가족에서 발생하는 도전적 환각을 포함하는 FaithBench라는 환각 평가 벤치마크를 제안합니다.

- **Technical Details**: FaithBench는 인공지능 모델에 의해 생성된 요약에서 발생하는 환각(hallucination)을 평가하기 위해 설계되었습니다. 이 벤치마크는 LLM 가족에 따라 다양한 환각 사례를 포함하고 있으며, 각 요약은 인간 전문가에 의해 주석이 달린 ground truth를 포함하고 있습니다.

- **Performance Highlights**: 연구 결과에 따르면, GPT-4o와 GPT-3.5-Turbo가 가장 낮은 환각 비율을 나타냈지만, 환각 탐지 모델의 정확도는 여전히 50%에 가까운 수치를 기록하여 개선의 여지가 많음을 시사합니다.



### TabSeq: A Framework for Deep Learning on Tabular Data via Sequential Ordering (https://arxiv.org/abs/2410.13203)
Comments:
          This paper has been accepted for presentation at the 26th International Conference on Pattern Recognition (ICPR 2024) in Kolkata, India

- **What's New**: 이번 연구에서는 TabSeq라는 새로운 프레임워크를 소개하여, 비정형(tabular) 데이터의 최적의 특성(feature) 순서를 위해 제안되었습니다. 이는 딥러닝 모델의 학습 효율성을 높이는 데 기여할 것입니다.

- **Technical Details**: TabSeq 프레임워크는 클러스터링(clustering)과 지역(local) 및 전역(global) 정렬 기법을 결합하여 비정형 데이터의 특성을 최적화하는 기능을 제공합니다. 이 기술은 멀티 헤드 어탠션(multi-head attention) 메커니즘이 포함된 디노이징 오토인코더(denoising autoencoder) 네트워크와 함께 사용됩니다.

- **Performance Highlights**: 본 연구는 원시 항체 마이크로어레이(raw antibody microarray) 및 기타 두 개의 실제 생물 의학 데이터셋을 통해 제안된 특성 순서 조정 기법이 딥러닝 모델 성능을 유의미하게 개선할 수 있음을 보여주었습니다.



### Meta-DiffuB: A Contextualized Sequence-to-Sequence Text Diffusion Model with Meta-Exploration (https://arxiv.org/abs/2410.13201)
- **What's New**: Meta-DiffuB는 Seq2Seq 텍스트 생성을 위한 새로운 스케줄러-탐색자 모델을 도입하여 기존 S2S-Diffusion 모델의 한계를 극복합니다. 기존 모델들은 고정된 또는 수작업으로 만든 규칙에 의존하여 노이즈를 스케줄링하는 반면, Meta-DiffuB는 문맥화된 노이즈 스케줄링을 통해 문장별로 적합한 노이즈를 적용합니다.

- **Technical Details**: Meta-DiffuB는 두 가지 모델로 구성됩니다: 스케줄러와 탐색자. 스케줄러는 각 문장의 특성에 맞춰 적절한 수준의 노이즈를 스케줄링하고, 탐색자는 해당 노이즈를 활용하여 업데이트 및 생성을 수행합니다. 이 접근 방식은 자연어 처리(NLP)에서 Seq2Seq 작업의 의미론적 특성을 반영합니다.

- **Performance Highlights**: Meta-DiffuB는 네 가지 Seq2Seq 벤치마크 데이터세트에서 기존 S2S-Diffusion 모델 및 정밀 조정된 사전 훈련된 언어 모델(PLMs)과 비교하여 최첨단 성능을 달성합니다. 또한, 스케줄러 모델은 기존 DiffuSeq를 더욱 향상시키기 위한 '플러그 앤 플레이' 기능을 제공합니다.



### Golyadkin's Torment: Doppelg\"angers and Adversarial Vulnerability (https://arxiv.org/abs/2410.13193)
- **What's New**: 이 논문은 'Adversarial Doppelgangers(AD)'라는 개념을 정의하고 탐구하며, 이는 기존의 adversarial visual metamers를 포함합니다. AD의 성능 및 강건성을 분류 기계와 인간의 성능을 비교하여 분석합니다.

- **Technical Details**: AD는 이 논문에서 정의된 지각적(metric) 측정에 따라 서로 가까운 입력들입니다. 연구에서는 이러한 AD에 대한 분류기의 취약성을 분석하고, AD에 강건한 분류기의 구조와 속성을 설명하며, 개념적 엔트로피(conceptual entropy) 및 개념적 모호성(regions of conceptual ambiguity)에 대한 개념을 도입합니다.

- **Performance Highlights**: 대부분의 분류기는 AD에 취약하며, 강건성-정확도 트레이드오프(robustness-accuracy trade-offs)가 개선되지 않을 수 있습니다. 그러나 정확도가 높은 모든 분류기는 hypersensitive behavior를 보여줄 있으며, 이로 인해 AD 강건성을 개선하는 것이 정확도 개선과 동일함을 발견했습니다.



### MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback (https://arxiv.org/abs/2410.13191)
Comments:
          Equal contribution for the first two authors

- **What's New**: 이번 연구에서는 MCQG-SRefine라는 새로운 프레임워크를 제안하여, 전문의 시험을 위한 고품질 다지선다 질문(USMLE 스타일 질문)을 자동 생성하는 방법을 소개합니다. 이 프레임워크는 LLM의 자기 수정(self-refine) 기반으로, 전문가의 피드백과 반복적인 자기 비판을 통해 질문의 품질과 난이도가 향상됩니다.

- **Technical Details**: MCQG-SRefine는 의료 사례를 입력으로 받아 USMLE 스타일의 질문을 생성합니다. FR 쿼리 설정과 41개의 주요 주제를 포함한 체크리스트를 기반으로, LLM이 의료 사례에서 정보를 추출하여 질문을 생성합니다. 또한, LLM 스스로 피드백을 주고, 이를 기반으로 질문을 수정하는 세 가지 단계(S1: 초기 MCQ 생성, S2: 비판 피드백, S3: 수정 피드백)를 따릅니다.

- **Performance Highlights**: MCQG-SRefine를 통해 생성된 질문은 GPT-4가 생성한 질문보다 72.5%의 선호도를 기록했으며, 더 높은 난이도의 질문을 생성하는 것이 확인되었습니다. 쉽고 중간 수준의 질문에서 각각 80% 감소 및 2.25배 증가, 어려운 질문에서 4배 증가하는 결과를 보였습니다. LLM-as-Judge를 활용해 전문가 평가를 대체할 수 있는 신뢰성 있는 자동 평가 시스템 또한 제안되었습니다.



### CohEx: A Generalized Framework for Cohort Explanation (https://arxiv.org/abs/2410.13190)
- **What's New**: 이번 논문은 설명 가능한 인공지능(eXplainable Artificial Intelligence, XAI)의 발전을 위해서 새로운 코호트 기반(cohort-based) 설명 방법에 대해 탐구합니다. 기존의 설명 기법들이 전반적인(global) 또는 개별적(local) 설명에 중점을 두고 있는 반면, 본 연구에서는 특정 그룹에 대한 설명의 중요성을 강조합니다. 이를 통해 모델의 결정과정에 대한 보다 깊은 이해를 제공합니다.

- **Technical Details**: 코호트 설명(cohort explanation)은 데이터셋의 하위 집합 또는 모델의 입력/결정 공간의 하위 영역에 대한 일반화된 설명을 제공합니다. 연구진은 이와 관련된 고유한 도전과 기회를 논의하며, 코호트 설명의 이상적인 속성을 정의하고 이를 기반으로 한 일반화된 프레임워크(supervised clustering)를 제안합니다. 또한, 기존의 데이터 기반(local feature importance) 방법을 코호트 설명으로 전환하는 방법도 개발하였습니다.

- **Performance Highlights**: 연구 결과, 제안된 알고리즘은 기존의 벤치마크와 비교하여 우수한 성능을 발휘했다고 보고합니다. 이는 코호트 설명이 각 코호트를 특정 지역으로 구분하여 보다 간결하고 명확한 설명을 가능하게 하기 때문입니다.



### aiXcoder-7B: A Lightweight and Effective Large Language Model for Code Completion (https://arxiv.org/abs/2410.13187)
Comments:
          aiXcoder-7B is available at this https URL

- **What's New**: aiXcoder-7B는 70억 개의 매개변수를 가지며, 코드 완성을 위하여 설계된 경량화된 대형 언어 모델(LLM)입니다. 기존 LLM에 비해 보다 높은 정확도를 기록하며, 개발자 생산성을 높이기 위해 응답 시간을 단축시킵니다.

- **Technical Details**: aiXcoder-7B는 세 가지 주요 요소에 의해 우수한 성능을 발휘합니다: (1) 다중 목표 훈련(Multi-objective training), (2) 다양한 데이터 샘플링 전략(Diverse data sampling), (3) 방대한 고품질 데이터(Extensive high-quality data). 특히, Structured Fill-In-the-Middle (SFIM)이라는 훈련 목표를 사용하여 코드의 구문 구조를 고려합니다. 이와 함께 1.2 조 개의 고유한 토큰을 소비하여 훈련됩니다.

- **Performance Highlights**: aiXcoder-7B는 6개의 코드 완성 벤치마크에서 최신 LLM들보다 우수한 성능을 나타내며, 심지어 StarCoder2-15B와 CodeLlama-34B와 같은 더 큰 LLM보다도 뛰어난 결과를 기록하였습니다. 이는 aiXcoder-7B가 경량화된 모델임에도 불구하고 뛰어난 코드 완성 정확도를 보유하고 있음을 나타냅니다.



### EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning (https://arxiv.org/abs/2410.13179)
- **What's New**: 이번 논문에서는 Speech Representation Learning을 위한 새로운 Self-Supervised Learning 접근 법인 EH-MAM (Easy-to-Hard adaptive Masked Acoustic Modeling)을 제안합니다. 기존의 랜덤 마스킹 방식을 사용하는 Masked Acoustic Modeling (MAM)과는 달리, 우리는 선택적이고 적응적인 마스킹 전략을 도입하였습니다.

- **Technical Details**: EH-MAM은 SSL 훈련 중 모델에 점진적으로 더 어려운 영역을 도입하여 재구성을 수행합니다. 개별 프레임의 재구성 손실( reconstruction loss)을 활용하여 MAM 전제 과제를 해결하는 난이도를 판단하며, 이를 위해 교사 모델(teacher model)을 사용하여 프레임 단위 손실을 예측하고 어떤 프레임을 마스킹할 지 결정합니다.

- **Performance Highlights**: EH-MAM은 여러 최신 기준선(baselines) 대비 5%-10% 향상된 성능을 보이며, 저자원(low-resource) 음성 인식 및 SUPERB 벤치마크에서 효과적으로 유용한 컨텍스트를 포착하는 마스킹 영역을 분석합니다.



### GeSubNet: Gene Interaction Inference for Disease Subtype Network Generation (https://arxiv.org/abs/2410.13178)
Comments:
          Under review as a conference paper at ICLR 2025

- **What's New**: GeSubNet은 다양한 질병 아형에 따른 유전자 상호작용을 예측할 수 있는 통합 표현을 학습하는 새로운 방법론입니다.

- **Technical Details**: GeSubNet은 다단계 표현 학습 프레임워크로, 환자 유전자 발현 프로파일로부터 특정 질병 아형을 학습하는 심층 생성 모델, 지식 데이터베이스로부터 이전 유전자 네트워크의 표현을 포착하는 그래프 신경망(GNN), 그리고 두 표현을 통합하는 추론 손실을 포함한 세 가지 모듈로 구성됩니다.

- **Performance Highlights**: GeSubNet은 네 가지 그래프 평가 지표에서 평균 30.6%, 21.0%, 20.1%, 56.6%의 성능 향상을 기록했으며, 11,327개의 유전자 평가 실험에서 특정 아형에 영향을 미칠 가능성이 83%인 유전자 발견의 잠재력을 보여주었습니다.



### TCP-Diffusion: A Multi-modal Diffusion Model for Global Tropical Cyclone Precipitation Forecasting with Change Awareness (https://arxiv.org/abs/2410.13175)
- **What's New**: 이번 연구는 Tropical Cyclone Precipitation Diffusion (TCP-Diffusion)이라는 다중 모드 모델을 제안하여 열대성 폭풍(TC) 강수 예측의 정확성을 높였습니다. 이 모델은 과거 강수 관측 및 다양한 환경 변수에 기반하여, TC 중심 주변의 강수를 다음 12시간 동안 3시간 간격으로 예측합니다.

- **Technical Details**: TCP-Diffusion 모델은 인접 잔차 예측(Adjacent Residual Prediction, ARP) 방식을 사용하여, 절대 강수량 대신 강수량 변화를 예측하도록 훈련 목표를 변경했습니다. 이를 통해 누적 오류를 줄이고 물리적 일관성을 확보합니다. 또한, 기상 요소와 수치 기상 예측(NWP) 모델 정보를 통합하여 더 풍부한 메타데이터를 추출합니다.

- **Performance Highlights**: 광범위한 실험 결과, TCP-Diffusion는 최신 딥 러닝(DL) 기반 강수 예측 방법 및 유럽 중기기상예보센터(ECMWF)의 NWP 방법과 비교하여 우수한 성능을 보여주었습니다.



### An Evolved Universal Transformer Memory (https://arxiv.org/abs/2410.13166)
Comments:
          29 pages, 14 figures. Preprint, under submission. Source code is available at this https URL

- **What's New**: 본 논문은 Neural Attention Memory Models (NAMMs)을 제안하며, 메모리 관리를 위한 학습된 네트워크를 도입하여 Transformers의 성능과 효율성을 동시에 향상시킵니다. 이는 기계가 가진 메모리 관리의 질의를 진화 기반 접근법으로 해결하여, 기능적으로 매우 다양한 아키텍처에서 자율적으로 적용될 수 있도록 설계되었습니다.

- **Technical Details**: NAMMs는 Transformers의 Key-Value (KV) 캐시의 잠재적 메모리를 형성하는 새로운 방법을 제안하여, 각 레이어와 attention head가 그들의 특정 요구에 가장 관련 있는 정보에 집중하도록 지원합니다. 이 방식은 학습된 attention 매트릭스를 기반으로 모든 transformer 기반 아키텍처에 일반적으로 적용 가능하며, Llama 3 8B 모델 위에서 학습하여 성능과 효율성을 모두 극대화합니다.

- **Performance Highlights**: NAMMs를 통한 학습 결과로 36개의 LongBench, InfiniteBench 및 새로운 일본어 벤치마크에서 뛰어난 성능 개선을 기록했습니다. 기존의 수작업 전략과 비교할 때, NAMMs는 성능 저하 없이 메모리 용량을 유의미하게 감소시켰습니다. 또한, NAMMs는 언어 과제로만 학습되었음에도 불구하고 다양한 입력 모달리티를 통해 다른 transformer 모델에 제로샷 전이(transfer) 되는 성과를 보였습니다.



### Utilizing Large Language Models in An Iterative Paradigm with Domain Feedback for Molecule Optimization (https://arxiv.org/abs/2410.13147)
- **What's New**: 본 연구에서는 약물 발견에서 분자의 최적화를 지원하기 위해 LLM (Large Language Models)을 효과적으로 활용할 수 있는 도메인 피드백 제공자인 Re²DF를 제안합니다. 이 새로운 접근법은 분자가 화학적으로 유효하지 않을 경우를 고려하여 수정된 분자의 유효성을 즉시 검증하며, 해당 분자의 개선을 위한 구체적인 피드백을 제공합니다.

- **Technical Details**: Re²DF는 외부 툴킷인 RDKit를 이용하여 수정된 분자가 화학적으로 유효한지를 체크합니다. 만약 유효하지 않다면, RDKit로부터 오류 메시지를 제공받아 LLM에게 수정 방향을 제시합니다. 또한, 수정된 분자가 원하는 특성을 충족하는지 확인하여, 목표에 대한 정확한 방향과 거리를 제공하는 신뢰할 수 있는 피드백을 생성합니다.

- **Performance Highlights**: Re²DF는 단일 속성 목표 20개에서 Hit ratio를 각각 16.95% 및 20.76% 향상시키며, 다중 속성 목표에서는 32개에서 각각 6.04% 및 5.25% 향상시켰습니다. 이러한 결과는 Re²DF가 기존 방법들보다 더 나은 성능을 발휘함을 알립니다.



### Trust but Verify: Programmatic VLM Evaluation in the Wild (https://arxiv.org/abs/2410.13121)
- **What's New**: 본 논문에서는 프로그램 기반 VLM 평가(Programmatic VLM Evaluation, PROVE)라는 새로운 벤치마크 패러다임을 제안합니다. 이 방법은 비주얼 컨텐츠에 대한 오픈 엔디드 질의에 대한 VLM의 응답을 신뢰성 있게 평가할 수 있도록 설계되었습니다.

- **Technical Details**: PROVE는 하이퍼 세부 이미지 캡션으로부터 구성된 고충실도의 씬 그래프(scene graph) 표현을 기반으로 하며, 이를 통해 다양한 질문-응답(QA) 쌍을 생성하고, 각 QA 쌍의 검증을 위한 프로그램을 함께 생성합니다. 이후, 이 프로그램을 통해 각각의 QA 쌍의 정확성과 기초를 검증하면서 10,500개의 시각적으로 기초가 있는 QA 쌍을 포함하는 데이터셋을 구축합니다.

- **Performance Highlights**: BENCHMARK한 결과, 대부분의 기존 VLM들은 유용성과 진실성 사이의 균형을 잘 맞추지 못함을 발견했습니다. 도출된 결과는 최근 '더 나은' VLM 교육의 진전이 유용성 향상으로 이어지지만 진실성 향상에는 큰 도움을 주지 않는다는 것을 보여줍니다.



### Preference Diffusion for Recommendation (https://arxiv.org/abs/2410.13117)
- **What's New**: PreferDiff는 신규 개인화 순위 손실 함수로, 기존의 추천 시스템들이 사용하는 전통적인 목표 대신에Diffusion Models(확산 모델) 특화된 최적화 목표를 제안합니다.

- **Technical Details**: PreferDiff는 BPR(Bayesian Personalized Ranking)을 로그 가능도 순위 목표로 변환하고 여러 개의 네거티브 샘플을 통합하여 사용자 선호도를 더 잘 포착하도록 설계되었습니다. 변분 추론(variational inference)을 이용해 계산의 어려움을 극복하고 오차 기준에서 MSE 대신 cosine error를 적용하여 추천 작업에 대한 정렬을 개선합니다. 또한, 생성(generation) 및 선호(preference) 간의 균형을 맞춤으로써 DMs의 학습 안정성을 향상시킵니다.

- **Performance Highlights**: 세 가지 벤치마크에서 진행된 실험을 통해, PreferDiff는 우수한 추천 성능을 보였으며 일반적인 연속 추천(sequential recommendation) 능력에서 주목할 만한 결과를 나타냈습니다.



### Learning to Summarize from LLM-generated Feedback (https://arxiv.org/abs/2410.13116)
- **What's New**: 이번 연구에서는 LLM(대규모 언어 모델) 생성 피드백을 통해 요약 품질을 향상시키는 방법을 탐구하고, FeedSum이라는 대규모 데이터셋을 소개합니다. 이는 다양한 품질의 요약에 대한 다차원 LLM 피드백을 포함하고 있습니다.

- **Technical Details**: FeedSum 데이터셋에서는 13개의 서로 다른 언어 모델을 사용하여 요약을 생성하고, 각 요약에 대해 신뢰성(faithfulness), 완전성(completeness), 간결성(conciseness)이라는 세 가지 핵심 차원에 대한 피드백을 수집합니다. 두 가지 방법인 감독형 세부 조정(supervised fine-tuning)과 직접 선호 최적화(direct preference optimization)를 비교하였고, SummLlama3-8B 모델이 Llama3-70b-instruct 모델보다 더 뛰어난 성능을 보였음을 확인했습니다.

- **Performance Highlights**: SummLlama3-8B 모델은 크기가 10배 이상 큰 Llama3-70b-instruct 모델을 초월하여 인간의 선호에 맞는 요약을 생성하는 데 성공하였습니다. 이는 Smaller 모델이 적절한 훈련을 통해 더 우수한 성능을 얻을 수 있음을 보여줍니다.



### Sound Check: Auditing Audio Datasets (https://arxiv.org/abs/2410.13114)
- **What's New**: 이 논문은 생성 오디오 모델의 윤리적 문제와 데이터셋의 공정성을 평가하기 위해 심층적인 문헌 조사를 수행하고, 현재 사용되고 있는 오디오 데이터셋의 편향, 독성 및 지적 재산권 문제를 규명합니다.

- **Technical Details**: 총 175개의 고유 오디오 데이터셋을 분석하였고, 36%는 웹에서 수집되었으며, 35%의 데이터셋이 저작권 침해 가능성이 있다고 평가됩니다. 사용된 주요 기법으로는 Audio Spectrogram Transformer와 LALMs(대형 오디오 언어 모델)가 포함됩니다.

- **Performance Highlights**: 현재의 오디오 데이터셋은 대체로 인종적 및 성별 편향을 포함하고 있으며, 저작권이 있는 자료가 많이 포함되어 있어 아티스트의 권리와 관련된 문제를 야기할 수 있습니다. 또한, 마이너리티 그룹에 대한 언급이 적어 대표성이 결여되어 있습니다.



### Cliqueformer: Model-Based Optimization with Structured Transformers (https://arxiv.org/abs/2410.13106)
- **What's New**: 본 논문에서는 기계 학습을 활용한 모델 기반 최적화(Model-Based Optimization, MBO) 문제를 해결하기 위한 새로운 접근 방식인 Cliqueformer를 소개합니다. Cliqueformer는 블랙박스 함수의 구조를 학습하여 높은 차원의 최적화 문제에서 성능을 향상시킵니다.

- **Technical Details**: Cliqueformer는 transformer 기반 아키텍처를 사용하여 기능적 그래픽 모델(Functional Graphical Model, FGM) 형태로 블랙박스 함수의 구조를 학습합니다. 이 모델은 디자인 후보에 대한 최적화 문제를 해결하기 위해 예측을 클리크의 FGM 상에 분해하고, 클리크들의 주변 분포가 넓은 범위를 커버하도록 강제합니다. 이 과정은 변별적 병목(Variational Bottleneck) 기법을 사용하여 수행됩니다.

- **Performance Highlights**: Cliqueformer는 여러 고차원 블랙박스 함수와 실제 화학 및 유전자 설계 작업에서 기존 방법들과 비교하여 뛰어난 성능을 보여주었습니다. 이 연구는 오프라인 데이터에서 모델 기반 최적화를 위해 기존의 보수적인 접근 방식을 우회하는 효과적인 전략을 제안합니다.



### A Little Human Data Goes A Long Way (https://arxiv.org/abs/2410.13098)
- **What's New**: NLP 시스템의 효율성을 높이기 위해, 인간 주석 데이터의 일부를 합성 데이터로 대체하는 방법을 연구하였으며, 90%까지 대체해도 성능 저하가 미미하지만 마지막 10% 대체 시에는 성능이 크게 떨어진다는 중요한 발견을 했습니다.

- **Technical Details**: 합성 데이터 생성 과정을 통해 데이터 포인트 수를 일정하게 유지하며 인간 생성 데이터 비율을 점진적으로 증가시켜 성능을 비교하였습니다. 사용하는 데이터셋은 총 8개로 Fact Verification (FV) 및 Question Answering (QA) 태스크에 대해 실험하였습니다. 평가 지표로는 정확도, Exact Match, String Inclusion, BLEU, ROUGE-1, BERTScore를 사용하였습니다.

- **Performance Highlights**: 완전히 합성 데이터로 훈련된 FV 및 QA 시스템은 최소 125개의 인간 데이터 포인트를 추가할 경우 성능이 현저히 개선되며, 작은 비율의 인간 데이터가 큰 가치를 지닐 수 있다는 것을 발견했습니다. 추가적인 인간 데이터를 통한 성능 향상은 200 포인트의 인간 데이터로 가능하며, 이는 수량적으로 더 많은 합성 데이터 포인트에 비해 비용 효율적이라는 것을 보여줍니다.



### Task Consistent Prototype Learning for Incremental Few-shot Semantic Segmentation (https://arxiv.org/abs/2410.13094)
Comments:
          conference

- **What's New**: 이번 연구는 Incremental Few-Shot Semantic Segmentation (iFSS) 문제에 대한 새로운 접근 방식을 제안합니다. 이는 모델이 몇 개의 주석된 예제만으로 새로운 클래스에 대한 세분화 능력을 지속적으로 확장할 수 있도록 하는 것을 목표로 합니다.

- **Technical Details**: 연구는 메타 학습(meta-learning)을 기반으로 한 프로토타입 접근 방식을 사용하여, 기존 지식을 보존하면서 신속하게 적응할 수 있도록 모델을 유도합니다. 특히, 베이스 세션 동안의 증강 평가 프로토콜을 모방하여 가상의 증분 작업 시퀀스를 샘플링하여 메타 목표를 설정, 신속한 적응을 가능케 합니다. 프로토타입 공간 재분배 학습(Prototype Space Redistribution Learning, PSRL)을 통해 클래스 프로토타입을 동적으로 업데이트하여 최적의 프로토타입 경계를 설정합니다.

- **Performance Highlights**: PASCAL 및 COCO 벤치마크를 기반으로 한 iFSS 데이터셋에 대한 광범위한 실험 결과, 제안된 방법이 여러 경쟁 기법에 비해 월등한 성능을 보임을 확인했습니다.



### Reverse-Engineering the Reader (https://arxiv.org/abs/2410.13086)
- **What's New**: 이 연구는 기존의 언어 모델을 인간의 심리 측정 데이터에 맞춰 최적화하는 새로운 방법론을 제시합니다. 이를 통해 언어 처리 시스템의 이해를 높이고자 합니다.

- **Technical Details**: 연구진은 언어 모델이 특정 언어 단위의 읽기 시간을 예측하는 능력을 향상시키기 위해 서프라이절 이론(surprisal theory)을 기반으로 한 새로운 정렬 기법을 사용합니다. 모델의 파라미터를 조정하여 읽기 시간을 예측하는 선형 회귀의 계수를 최적화합니다.

- **Performance Highlights**: 제안된 기법은 여러 모델 크기와 데이터 세트에서 언어 모델의 심리 측정 예측력을 향상시키는 것으로 나타났습니다. 그러나 심리 측정 예측력과 후속 자연어 처리(NLP) 작업 성능 간에 반비례 관계가 발견되었습니다.



### FedCAP: Robust Federated Learning via Customized Aggregation and Personalization (https://arxiv.org/abs/2410.13083)
Comments:
          14 pages, 12 figures, 5 tables, accepted by 2024 Annual Computer Security Applications Conference (ACSAC 2024)

- **What's New**: FedCAP는 데이터 이질성과 Byzantine 공격에 강한 연합 학습(FL) 프레임워크로, 모델 업데이트 보정 메커니즘을 통해 클라이언트 간 모델 업데이트의 방향성과 크기를 포착합니다. 또한 맞춤형 모델 집계 규칙을 설계하여 유사 클라이언트 간의 협업을 촉진하고 악의적인 클라이언트의 모델 성능 저하를 가속화합니다.

- **Technical Details**: FedCAP는 네 가지 주요 구성요소로 이루어져 있습니다: 모델 보정 메커니즘, 맞춤형 집계 규칙, 이상 감지 메커니즘 및 개인화된 훈련 모듈. 모델 보정 메커니즘은 비독립적이며 동일한 분포(non-IID) 환경에서 악성 모델 업데이트와 양성 업데이트를 구별하는 데 도움을 줍니다. 맞춤형 집계 규칙은 유사 클라이언트 간의 협업을 촉진하며, 이상 감지 메커니즘을 통해 악성 클라이언트를 빠르게 식별하고 제거합니다. Euclidean norm 기반의 감지 메커니즘이 도입되어 클라이언트의 모델 업데이트 차이에 대한 정밀 분석을 가능하게 합니다.

- **Performance Highlights**: 실험 결과, FedCAP는 여러 비독립적 환경 및 일련의 중독 공격에 대한 강한 견고성을 보이며, 기존의 최첨단( SOTA) FL 방법들과 비교하여 모델 정확도와 견고성 모두에서 높은 성능을 나타냈습니다.



### Tuning Language Models by Mixture-of-Depths Ensemb (https://arxiv.org/abs/2410.13077)
- **What's New**: 최근 연구에서는 Transformer 기반의 대형 언어 모델(LLMs)에서 최종 레이어만을 사용하는 대신, 중간 레이어의 예측 능력에 주목하여 새로운 조정 프레임워크인 Mixture-of-Depths (MoD)를 제안하였습니다. MoD는 훈련 시 다양한 레이어의 출력을 활용함으로써 예측 성능을 향상시키고, 기존 조정 방법과 통합할 수 있는 특징을 가지고 있습니다.

- **Technical Details**: Mixture-of-Depths (MoD) 프레임워크는 레이어별 가중치를 학습하여 최종 로그잇(logits)으로 기여하는 앙상블로서의 레이어 훈련을 가능하게 합니다. 보조 증류 손실(auxiliary distillation loss) 및 추가 정규화 모듈을 적용하여, 최종 레이어 출력을 교사가 되는 훈련 방식으로 중간 레이어의 예측 출력을 모델 학습 시 최대화하는 접근을 취합니다. 이 방법은 훈련 가능한 파라미터를 소폭 증가시키면서도, 기본 언어 모델의 성능을 유지합니다.

- **Performance Highlights**: MoD 프레임워크를 적용한 결과, 산술 및 상식 추론 작업에서 성능이 일관되게 향상되었으며, 전통적인 훈련 가능한 모듈과 비교하여 97% 적은 파라미터로 유사한 성능을 달성하였습니다. 이러한 결과는 LLM의 중간 표현을 활용하는 것이 훈련 중 예측 능력을 크게 향상시킬 수 있음을 보여줍니다.



### ERAS: Evaluating the Robustness of Chinese NLP Models to Morphological Garden Path Errors (https://arxiv.org/abs/2410.13057)
Comments:
          Under review in ARR/NAACL

- **What's New**: 이 논문에서는 중국어를 다루는 NLP 모델들이 형태소적 garden path 오류에 취약하다는 것을 보여줍니다. 이를 평가하기 위해 ERAS라는 벤치마크를 제안합니다.

- **Technical Details**: ERAS 벤치마크는 지역적으로 모호한 구문과 모호하지 않은 구문으로 이루어진 203,944 쌍의 시험 문장과 통제 문장을 포함합니다. 이 연구는 Transformer 기반 및 비신경 단어 분리 모델과 캐릭터 수준의 토큰화를 사용하는 감정 분석 모델을 평가합니다.

- **Performance Highlights**: 실험 결과, 단어 분리 모델과 감정 분석 모델 모두가 garden path 오류를 범하며, 단어 경계 정보를 제공하여 모델 성능을 개선할 수 있다는 것을 보여줍니다.



### Channel-Wise Mixed-Precision Quantization for Large Language Models (https://arxiv.org/abs/2410.13056)
- **What's New**: 본 연구에서는 채널별 혼합 정밀도 양자화(Channel-Wise Mixed-Precision Quantization, CMPQ)라는 혁신적인 방법을 제안합니다. CMPQ는 각 채널의 활성화 분포에 기반하여 양자화 정밀도를 할당하는 새로운 혼합 정밀도 양자화 기법으로, 다양한 비트폭 제약에 적응하도록 설계되었습니다.

- **Technical Details**: CMPQ는 비균일 양자화(non-uniform quantization) 전략을 채택하며, 두 가지 이상치 추출(outlier extraction) 기법을 결합하여 필수 정보를 보존하며 양자화 손실을 최소화합니다. 이 방법은 채널별로 정밀도를 조정하여 각 채널의 활성화 norm에 따라 높은 정밀도 혹은 낮은 정밀도를 할당합니다.

- **Performance Highlights**: CMPQ는 실험을 통해 정수 비트 양자화(integer-bit quantization) 작업에서 성능을 향상시키는 한편, 적은 메모리 증가로 상당한 성능 향상을 이끌어냈습니다. 이 연구는 다양한 디바이스의 기능에서 큰 이점을 제공합니다.



### Systems with Switching Causal Relations: A Meta-Causal Perspectiv (https://arxiv.org/abs/2410.13054)
Comments:
          19 pages, 3 figures, 4 tables

- **What's New**: 본 논문에서는 기계 학습에서의 인과관계 연구에서 고정된 과정을 기반으로 한 전통적인 접근 방식의 한계를 지적하고, 메타-인과 상태(meta-causal states)라는 개념을 도입하여 변동하는 시스템 동 dynamics를 분석하는 방법을 제안합니다.

- **Technical Details**: 메타-인과 상태는 고전적인 인과 모델을 유사한 질적 행동에 따라 클러스터로 그룹화하고 특정 메커니즘 매개변수화를 통합하는 방법을 제시합니다. 또한, 관찰된 에이전트 행동으로부터 메타-인과 상태를 추론하는 방법과 레이블이 없는 데이터로부터 이 상태를 분리하는 방법을 논의합니다.

- **Performance Highlights**: 메타-인과 모델(MCM)은 특정 시스템 동역학 내에서 질적 차이를 표현하는 데 있어 고전적인 구조적 인과 모델보다 강력하며, 메타-인과 분석을 통해 전통적인 인과 추론과는 다른 근본 원인 기여를 식별할 수 있습니다.



### FedGTST: Boosting Global Transferability of Federated Models via Statistics Tuning (https://arxiv.org/abs/2410.13045)
- **What's New**: 본 논문에서는 기존의 Federated Learning (FL) 방법들이 해결하지 못한 문제들을 다루는 새로운 접근법인 Federated Global Transferability via Statistics Tuning (FedGTST)를 제안합니다. FL의 여러 도전 과제를 해결하면서 전세계적으로 전이 가능성을 높이는 방법론을 소개합니다.

- **Technical Details**: FedGTST는 클라이언트 간의 Jacobian (그라디언트) 노르므를 활용한 클라이언트-서버 교환 프로토콜과, 서버에서 클라이언트 간의 평균 Jacobian 노르므를 높이는 지역 정규화 기법을 통해 보다 효과적인 전이 가능성을 도모합니다. 이는 전이 실패를 줄이고 목표 손실(target loss)을 보다 정교하게 제어할 수 있도록 돕습니다.

- **Performance Highlights**: FedGTST는 MNIST에서 MNIST-M, CIFAR10에서 SVHN 데이터셋을 포함한 다양한 실험에서 FedSR 및 FedIIR과 같은 기존 방법보다 10%의 성능 향상을 나타냈습니다. 특히, LeNet 모델을 사용할 경우, FedGTST는 FedSR 대비 9.8%, FedIIR 대비 7.6%의 더 높은 정확도를 기록했습니다.



### LFOSum: Summarizing Long-form Opinions with Large Language Models (https://arxiv.org/abs/2410.13037)
- **What's New**: 이 논문에서는 온라인 리뷰의 대량 처리 및 요약을 위한 새로운 접근법을 제안합니다. 특히, 1천 개 이상의 리뷰로 구성된 새로운 데이터셋을 소개하며, 이를 기반으로 하는 LLM(대형 언어 모델) 기반 요약 기법을 제안합니다.

- **Technical Details**: LFOSum 데이터셋은 TripAdvisor에서 수집된 호텔 리뷰로, 각 엔티티는 1천 개 이상의 리뷰를 포함하고 있습니다. 두 가지의 훈련이 필요 없는 요약 방법, 즉 Retrieval-Augmented Generation (RAG)과 긴 맥락의 LLM을 이용하여 대량 리뷰 요약을 처리합니다. 사용자 맞춤형 요약을 위한 세 가지 제어 메커니즘(쿼리 제어, 감정 제어, 길이 제어)을 도입하여 사용자 요구에 맞춘 요약을 가능하게 합니다.

- **Performance Highlights**: LLM은 여전히 긴 형식의 요약에서 감정과 형식 준수의 균형을 맞추는 데 어려움을 겪고 있으나, 관련 정보를 집중적으로 추출할 경우 오픈 소스 모델이 효과적으로 간격을 좁힐 수 있음을 보여줍니다.



### LEGAL-UQA: A Low-Resource Urdu-English Dataset for Legal Question Answering (https://arxiv.org/abs/2410.13013)
Comments:
          8 pages

- **What's New**: LEGAL-UQA는 파키스탄 헌법에서 유래한 첫 번째 우르두 법률 질문-답변(QA) 데이터셋을 소개합니다. 이 데이터셋은 619개의 질문-답변 쌍을 포함하며, 법률 기사의 컨텍스트도 포함되어 있어 낮은 자원 언어의 도메인 특화된 NLP 자원의 필요성을 해결합니다.

- **Technical Details**: 데이터셋 생성 과정은 OCR 추출, 수동 수정 및 GPT-4를 활용한 QA 쌍의 번역 및 생성으로 구성됩니다. LEGAL-UQA의 성능을 평가하기 위해 최신의 일반 언어 및 임베딩 모델을 실험하였으며, Claude-3.5-Sonnet 모델이 인간 평가에서 99.19%의 정확도를 달성하였습니다. 또한, mt5-large-UQA-1.0 모델을 미세 조정하여 다국어 모델을 전문 분야에 적용하는 데 따른 도전 과제를 강조하였습니다.

- **Performance Highlights**: OpenAI의 text-embedding-3-large는 Mistral의 mistral-embed 보다 더 나은 검색 성능을 보였습니다. LEGAL-UQA는 글로벌 NLP 발전과 현지화된 응용 프로그램 간의 격차를 해소하며, 파키스탄 내 법률 정보 접근성을 개선하는 기반을 마련합니다.



### Hiding-in-Plain-Sight (HiPS) Attack on CLIP for Targetted Object Removal from Images (https://arxiv.org/abs/2410.13010)
Comments:
          Published in the 3rd Workshop on New Frontiers in Adversarial Machine Learning at NeurIPS 2024. 10 pages, 7 figures, 3 tables

- **What's New**: 기존의 적대적 공격이 주로 단일 모드에 초점을 맞추었던 반면, 본 연구에서는 CLIP과 같은 대규모 멀티 모달 모델(LMM)이 가지는 새로운 취약점에 주목합니다. 새로운 ‘Hiding-in-Plain-Sight (HiPS)’ 공격 기법을 통해 모델 예측을 미세하게 수정함으로써, 타겟 객체가 존재하지 않는 것처럼 보이게 하는 방법을 제안합니다.

- **Technical Details**: HiPS 공격은 두 가지 변형으로 소개됩니다: HiPS-cls는 클래스 레이블 정보를 활용하여 공격을 생성하며, HiPS-cap은 원본 이미지 캡션과 타겟 캡션을 사용하여 공격을 설계합니다. 이러한 공격 기법은 CLIP-Cap과 같은 이미지 캡셔닝 모델로 효과적으로 전이될 수 있습니다.

- **Performance Highlights**: HiPS 공격은 타겟 객체가 이미지 캡션에서 효과적으로 제거되도록 설계되었으며, 여러 평가 지표를 통해 성능을 검증합니다. 제안된 공격이 하위 모델에서 어떻게 작동하는지를 보여주며, 적대적 공격의 새로운 기준을 설정합니다.



### Flex: End-to-End Text-Instructed Visual Navigation with Foundation Models (https://arxiv.org/abs/2410.13002)
- **What's New**: 이 논문에서는 주어진 이미지와 자연어 명령에 기반한 로봇의 제어 정책을 향상시키기 위한 프레임워크인 Flex(Fly-lexically)를 소개합니다. Flex는 사전 훈련된 Vision Language Models(VLMs)를 활용하여 다양한 환경에서 강력한 제어 성능을 달성할 수 있도록 설계되었습니다.

- **Technical Details**: Flex는 두 가지 핵심 구성 요소로 이루어져 있습니다. 첫째, VLM의 패치 기반(descorptive) 특징을 사용하여 공간적(spatial) 및 의미론적(semantic) 정보를 결합합니다. 둘째, 강화된 정책 네트워크(policy network)를 훈련하여 제한된 훈련 데이터 세트에서도 효과적인 제어가 가능하도록 합니다.

- **Performance Highlights**: 드론의 플라이-투-타겟(fly-to-target) 작업에서 본 연구는 복잡한 환경과 다양한 명령 형식에서도 성공적으로 일반화할 수 있는 로봇의 적응력을 입증했습니다. 이 연구 결과는 훈련 데이터가 거의 없는 상황에서도 실제 장면에서 다양한 목표를 처리할 수 있는 능력을 보여주었습니다.



### SSET: Swapping-Sliding Explanation for Time Series Classifiers in Affect Detection (https://arxiv.org/abs/2410.12996)
- **What's New**: 이번 연구에서는 다변량 시계열 분류기를 위한 새로운 설명 방법인 SSET(Swapping-Sliding Decision Explanation)를 제안합니다. 이 방법은 예측 점수에서 중요한 하락을 초래하는 두 가지 주요 단계를 통해 설명을 생성합니다: 스와핑(swap) 단계와 슬라이딩(slide) 단계입니다.

- **Technical Details**: SSET는 두 단계로 구성됩니다. 첫 번째 단계에서는 주어진 인스턴스와 가까운 훈련 데이터로부터 중요한 변수를 찾아내기 위해 스와핑을 사용합니다. 두 번째 단계에서는 각 시간 단계에서 선택된 훈련 데이터에 대해 윈도우를 슬라이드하여 중요한 하위 시퀀스를 탐색합니다.

- **Performance Highlights**: SSET는 WESAD 및 MAHNOB-HCI의 두 실제 생리학적 시계열 데이터셋에서 CN-Waterfall 분류기를 이용해 평가되었으며, 기존 모델들(Dynamask, integrated gradients, LIME)보다 우수한 성능을 보였습니다.



### Qtok: A Comprehensive Framework for Evaluating Multilingual Tokenizer Quality in Large Language Models (https://arxiv.org/abs/2410.12989)
Comments:
          24 pages, 9 figures, 6 tables. Code and data available at this https URL

- **What's New**: 이번 연구에서 우리는 Qtok이라는 도구를 도입하여 멀티링구얼 모델에서의 토크나이저 품질을 평가하는 방법론을 제공합니다. 기존의 연구에서는 주로 데이터셋 품질이나 모델 아키텍처에 초점을 맞추었지만, 토크나이저의 중요성은 상대적으로 간과되었습니다.

- **Technical Details**: 연구팀은 Qtok 도구를 통해 58개의 공개 모델에서 13개의 다양한 토크나이저를 평가했습니다. 이 도구는 언어 범위, 토큰 완전성, 언어 및 언어 범주에 따라 분포를 측정하는 지표를 포함하여 토크나이저의 품질을 평가합니다. 또한 코어 토큰 개념을 도입하여 긍정적으로 반복되는 토큰을 구분하였습니다.

- **Performance Highlights**: 분석 결과, 다양한 언어 및 범주에서 토큰 분포의 중요 자질 불균형이 발견되어 현재의 토크나이징 전략에서 개선이 필요한 부분을 강조하였습니다. 연구는 토크나이저의 품질 평가 방법을 제공하고 이로 인해 멀티링구얼 LLM의 성능 향상 가능성을 제시합니다.



### Reinforcement Learning with Euclidean Data Augmentation for State-Based Continuous Contro (https://arxiv.org/abs/2410.12983)
- **What's New**: 이 논문은 강화 학습(RL) 에이전트의 데이터 효율성을 높이기 위해 유클리드 대칭(Euclidean symmetries) 기반의 데이터 증강(data augmentation) 접근법을 제안합니다. 기존의 방법들이 이미지 기반 데이터 증강에 중점을 두었던 반면, 본 연구는 상태 기반(control state) 데이터 증강에 중점을 둡니다.

- **Technical Details**: 유클리드 데이터 증강은 물리적으로 관찰 가능한 위치(position)와 속도(velocity)와 같은 상태 기반 피처를 활용하여 이루어집니다. 반면 기존의 대칭 기반 변환은 조인트(joint) 구성으로만 이루어져 데이터 증강이 효과적이지 않았습니다. 본 연구에서는 팔다리의 구성(configuration)을 새로운 상태 표현으로 사용하여 더 많은 데이터를 생성하고, 임의의 회전(rotation)이나 이동(translation) 변환을 통해 데이터를 증강합니다.

- **Performance Highlights**: 개별 상태 표현을 사용했을 때, DeepMind Control Suite의 대부분의 작업에 대한 성능이 향상되었으며, 유클리드 데이터 증강 추가 시 거의 모든 작업에서 최적의 성능을 달성했습니다. 예를 들어, Humanoid_run 작업에서 표준 DDPG는 100 이하의 보상을 달성한 반면, 본 방법은 5M 타임스텝 후에 150 이상의 보상을 달성했습니다.



### Flash Inference: Near Linear Time Inference for Long Convolution Sequence Models and Beyond (https://arxiv.org/abs/2410.12982)
Comments:
          15 pages, 9 figures, 5 algorithms

- **What's New**: 이 논문에서는 Long Convolution Sequence Models (LCSMs), 특히 Hyena 모델의 정확한 추론(inference) 속도를 O(L log² L)로 증가시키는 방법을 제안합니다. 또한, 이러한 속도 향상이 가능한 주요 속성들을 정의하고, 이러한 속성을 활용하는 일반적인 프레임워크를 제안합니다.

- **Technical Details**: 제안된 접근 방식은 relaxed polynomial interpolation에 대한 이전 연구를 바탕으로 하며, 메모리 이동을 줄이고 계산을 공유하는 tiling 기법을 활용합니다. 이 방법은 position-mixing 부분의 아키텍처에서 거의 완전한 병렬화(parallelization)를 허용합니다.

- **Performance Highlights**: Hyena 모델의 실험적 구현을 통해, 표준 추론에 비해 최대 1.6배의 엔드 투 엔드(end-to-end) 시간 효율성을 개선하였고, position-mixing 부분에서는 최대 50배의 성능 향상을 달성했습니다.



### Long-Tailed Backdoor Attack Using Dynamic Data Augmentation Operations (https://arxiv.org/abs/2410.12955)
- **What's New**: 본 논문은 긴 꼬리(long-tailed) 데이터셋에 대한 백도어 공격(backdoor attack)을 처음으로 탐구합니다. 기존의 백도어 공격은 주로 균형 잡힌 데이터셋에 초점을 맞추었으며, 이로 인해 실제 환경에서 발생하는 불균형 데이터 문제를 간과하고 있었습니다.

- **Technical Details**: 제안된 방법인 D$^2$AO(Dynamic Data Augmentation Operation)는 클래스, 샘플 유형(클린 vs. 백도어), 그리고 샘플 특징에 따라 동적으로 다양하고 적절한 데이터 증강(data augmentation) 연산을 선택합니다. 이를 통해 백도어 샘플과 클린 샘플의 불균형 문제를 해결하고, 데이터 증강에 적응할 수 있는 트리거 생성기를 개발하였습니다.

- **Performance Highlights**: CIFAR10-LT 및 CIFAR100-LT와 같은 두 개의 긴 꼬리 벤치마크에서 폭넓은 실험을 수행하였으며, 제안된 방법은 기존의 백도어 공격 방법과 비교하여 상태-of-the-art 공격 성능을 달성하면서 클린 정확도(clean accuracy)를 유지하였습니다.



### A Note on Shumailov et al. (2024): `AI Models Collapse When Trained on Recursively Generated Data' (https://arxiv.org/abs/2410.12954)
Comments:
          Comment on this https URL

- **What's New**: Shumailov et al. (2024)의 연구에 따르면, 합성 데이터에 반복적으로 훈련된 생성 모델이 모델 붕괴(model collapse)를 일으킬 수 있다는 사실이 밝혀졌습니다. 이 연구는 현재 모델들이 기존 데이터의 활용 가능성을 거의 소진한 가운데 이루어져 큰 주목을 받고 있습니다.

- **Technical Details**: 연구는 데이터에 대한 적합(distribution fitting) 및 반복적인 샘플링을 통해 모델 붕괴의 원인을 조사합니다. Kernel Density Estimation (KDE)와 KL divergence 및 Wasserstein distance (WSD)와 같은 거리 메트릭을 사용하여 결과를 분석했습니다.

- **Performance Highlights**: 결과는 최종 분포(final distribution)가 붕괴되며, 이 과정에서 샘플링과 적합이 반복될수록 원래 데이터의 구조가 점차 유실되고 더 균일한 분포로 수렴한다는 것을 보여줍니다. 연구는 생성 모델이 데이터의 분포를 정확히 재현하는 데 한계가 있음을 강조하며, 향후 연구의 필요성을 제기합니다.



### Gradient Map-Assisted Head and Neck Tumor Segmentation: A Pre-RT to Mid-RT Approach in MRI-Guided Radiotherapy (https://arxiv.org/abs/2410.12941)
- **What's New**: 이번 연구는 방사선 치료 (RT)에서 두경부 암의 종양 구획 정확성을 향상시키기 위해 사전 방사선 치료 이미지와 지역 그래디언트 맵을 활용한 새로운 방법을 제안합니다. 이는 기존의 수동 분할 방식의 한계를 극복하기 위한 목적으로, MRI 유도 적응 방사선 치료에 적용됩니다.

- **Technical Details**: 본 연구에서는 nnUNet 프레임워크를 사용하여 모델을 구현하고 훈련했습니다. 방사선 치료 전(pre-RT) 이미지의 변형 등록된 구획을 기반으로 종양 주변의 관심 영역 (ROIs)을 정의한 후, 이를 통해 미드 방사선 치료(mid-RT) T2 강도 이미지를 처리하여 그래디언트 맵을 생성했습니다. 이러한 방법을 통해 종양의 경계 구획을 향상시키고자 하였습니다.

- **Performance Highlights**: 본 연구의 최종 DSCagg 점수는 GTVp(주 종양)에서 0.534, GTVn(림프절 종양)에서 0.867로 나타났으며, 평균 점수는 0.70을 기록했습니다. 이는 적응 방사선 치료의 분할 및 치료 계획 강화에 기여할 잠재력을 가지고 있습니다.



### UMambaAdj: Advancing GTV Segmentation for Head and Neck Cancer in MRI-Guided RT with UMamba and nnU-Net ResEnc Planner (https://arxiv.org/abs/2410.12940)
- **What's New**: 본 연구는 MRI 유도 적응 방사선 치료에서 두 가지 최신 심층 학습 세분화 기법, UMamba와 nnU-Net Residual Encoder(ResEnc)를 통합하여 'UMambaAdj'라는 새로운 접근 방식을 제안합니다. 이 방법은 주두경부암 치료에서 종양 부피(GTV)를 더 정밀하게 세분화하는 데 기여할 것으로 기대됩니다.

- **Technical Details**: UMambaAdj는 3D ResEnc U-Net과 Mamba 블록을 결합하여 구성됩니다. CNN 구조는 nnU-Net Residual Encoder Planner에 따라 설정되며, 6단계의 U-Net은 총 6개의 잔차 CNN 블록을 포함하여 GTVp와 GTVn의 세분화를 위해 설계되었습니다. Mamba 레이어는 입력 이미지 특징 맵을 처리하여 장기 의존성을 효과적으로 캡처합니다.

- **Performance Highlights**: MNTS-MRG 2024 챌린지 테스트 세트에서 GTVp에 대해 0.751, GTVn에 대해 0.842의 Dice 유사도 계수(DSC)를 달성했으며, 평균 DSC는 0.796였습니다. 이는 MRI 유도 적응 방사선 치료에서 보다 정밀한 종양 윤곽을 제공하며 HNC 환자의 치료 결과를 향상시킬 가능성을 보여줍니다.



### SoK: On Finding Common Ground in Loss Landscapes Using Deep Model Merging Techniques (https://arxiv.org/abs/2410.12927)
- **What's New**: 이번 연구에서는 신경망의 해석 가능성을 향상시키고, 모델 병합(model merging)이라는 관련 분야의 문헌을 조사하여 신뢰할 수 있는 딥러닝 모델을 개발하기 위한 새로운 통찰력을 제시합니다.

- **Technical Details**: 모델 병합은 여러 신경망의 파라미터를 결합하여 성능이 뛰어난 단일 예측 모델을 만들어내는 기술입니다. 본 연구에서는 손실 경관(loss landscape geometry) 관점에서 모델 병합 기술을 분석하며, 이를 통해 해석 가능성, 보안 및 모델 훈련에 대한 새로운 이해를 제공합니다.

- **Performance Highlights**: 모델 병합 기술은 다양한 신경망을 효율적으로 조합하여 훨씬 더 우수한 성능의 모델을 생성할 수 있는 잠재력을 지니고 있으며, 모델 해석과 보안 분야에서의 의미 있는 연결점을 발견하였습니다.



### Boosting Asynchronous Decentralized Learning with Model Fragmentation (https://arxiv.org/abs/2410.12918)
- **What's New**: 이번 논문에서는 비동기식 분산 학습(Decentralized Learning, DL) 알고리즘인 DivShare를 제안합니다. DivShare는 느린 통신을 겪고 있는 노드들, 즉 stragglers를 효율적으로 처리하여 모델 수렴 속도를 개선합니다.

- **Technical Details**: DivShare는 모델을 파라미터 서브셋으로 나누고, 각 서브셋을 다른 노드에 무작위로 전송하여 병렬로 계산하는 방식을 사용합니다. 이로 인해 집합적인 대역폭을 효율적으로 활용하며, 느린 네트워크를 갖는 노드도 모델 파라미터의 일부를 빠르게 기여할 수 있게 됩니다. 또한, 논문에서는 비동기 통신과 지연의 영향을 고려한 DL 알고리즘의 수렴에 대한 첫 번째 이론적 증명을 제공합니다.

- **Performance Highlights**: CIFAR-10 데이터셋에서 DivShare는 AD-PSGD 대비 최대 3.9배 빠른 시간 내에 정확도에 도달하며, 두 가지 기준선에 비해 최대 19.4% 더 높은 정확도와 CIFAR-10 및 MovieLens 데이터셋에서 각각 9.5% 낮은 테스트 손실을 기록합니다.



### Fair Clustering for Data Summarization: Improved Approximation Algorithms and Complexity Insights (https://arxiv.org/abs/2410.12913)
- **What's New**: 이 연구는 공정한 데이터 요약(fair data summarization) 문제를 다루며, 기존의 $k$-supplier 문제를 공정성을 고려하여 확장한 점이 새롭습니다.

- **Technical Details**: 연구에서는 공정한 $k$-supplier 문제를 정의합니다. 이 문제는 데이터가 여러 그룹으로 구성되고, 각 그룹에서 최소한의 중심(center)을 선택해야 하며, $k$-supplier 목표를 최소화해야 합니다. 두 가지 문제 변형에 대해 각각 알고리즘을 제시하며, 비지지(disjoint) 그룹에 대해 다항식(polynomial) 시간 복잡도를 보이고, 겹치는(overlapping) 그룹에 대해서는 고정-매개변수 고찰(fixed-parameter tractable) 알고리즘을 제공합니다.

- **Performance Highlights**: 비지지 그룹에 대한 알고리즘은 시간 복잡도가 다항식으로 실행되며, 겹치는 그룹에 대한 알고리즘은 중심과 그룹의 수에만 의존하는 지수(exponential) 실행 시간을 가집니다. 제안된 알고리즘은 기존의 $5$보다 개선된 $3$-근사화(approximation) 알고리즘을 제공하며, 이 근사화 계수는 이론적인 하한(lower bound)과 일치합니다.



### Large Language Models and the Rationalist Empiricist Deba (https://arxiv.org/abs/2410.12895)
- **What's New**: 이 논문은 LLMs(대형 언어 모델)가 Chomsky와 Quine, Skinner 간의 논쟁에 어떻게 영향을 미치는지를 탐구하며, LLMs가 합리주의를 정당화하는 주장과 기존의 경험주의에 대한 비판을 다룬다.

- **Technical Details**: LLMs는 본래의 편향을 내장해야 하며, 이는 언어능력(linguistic competence)을 설명하는 데 있어 경험주의가 개념적 자원을 부족하다는 주장을 뒷받침한다. 그러나 이러한 주장은 사용되는 경험주의의 성격에 의존한다.

- **Performance Highlights**: 인간은 한정된 자극(poverty of stimulus) 속에서도 학습하는 반면, LLMs는 풍부한 자극(rich stimulus) 덕분에 학습한다. 이는 인간과 LLMs가 출력(output)을 생성하는 데에 있어 다른 기본 능력(underlying competencies)을 사용함을 나타낸다.



### MIRROR: A Novel Approach for the Automated Evaluation of Open-Ended Question Generation (https://arxiv.org/abs/2410.12893)
Comments:
          Accepted at FM-Eduassess @ NEURIPS 2024 (ORAL Paper)

- **What's New**: 이번 연구에서는 자동 질문 생성(Automated Question Generation, AQG) 시스템이 생성한 질문의 품질 평가를 자동화하기 위해 대규모 언어 모델(LLM)을 활용하는 새로운 시스템인 MIRROR (Multi-LLM Iterative Review and Response for Optimized Rating)를 제안합니다.

- **Technical Details**: MIRROR는 여러 LLM에 피드백을 제공하여 인간의 평가 지표(grammaticality, relevance, appropriateness, novelty, complexity)에 기반하여 점수를 생성하는 프로세스를 포함합니다. GPT-4, Gemini, Llama2-70b와 같은 최첨단 LLM을 사용하여 실험을 진행하였으며, 인간 전문가의 평가와의 Pearson 상관 계수(Pearson's correlation coefficient)를 측정하여 결과를 비교하였습니다.

- **Performance Highlights**: MIRROR를 적용한 결과, relevance, appropriateness, novelty, complexity, grammaticality와 같은 인간 평가 지표의 점수가 개선되어 인간 기준 점수와 더 가까운 결과를 보였습니다. 더불어 직접 프롬프트를 사용하여 평가한 경우보다 인간 전문가와의 상관 계수가 향상되었습니다.



### Multi-trait User Simulation with Adaptive Decoding for Conversational Task Assistants (https://arxiv.org/abs/2410.12891)
Comments:
          Preprint fron EMNLP 2024 Findings

- **What's New**: 이 논문은 Multi-Trait Adaptive Decoding (mTAD)이라는 새로운 접근 방식을 제안합니다. mTAD는 다양한 trait-specific Language Models (LMs)에서 샘플링하여 디코딩 시간에 다양한 사용자 프로필을 생성하여 사용자 시뮬레이션을 개선합니다.

- **Technical Details**: mTAD는 다양한 대화 trait를 모델링하기 위해 specialized LMs를 결합하는 모델 기반 접근 방식을 따릅니다. 기존의 조합 훈련 데이터나 추가적인 모델 Fine-tuning 없이, trait-specific LM에서 분포를 샘플링하여 동적으로 결합합니다. 이 기법은 사용자 대화 프로필의 다양한 조합을 가능하게 하여 더 풍부한 대화 패턴을 생성합니다.

- **Performance Highlights**: 실험 결과, mTAD는 단일 trait 모델링에서 효과적임을 입증하며, 아울러 특정 패턴을 포착할 수 있는 능력을 보여줍니다. mTAD는 다양한 사용자 시뮬레이터를 결합하는 데 강력하고 유연한 프레임워크로, 기존 LM을 재훈련할 필요 없이 새로운 traits를 추가할 수 있습니다.



### Using Protected Attributes to Consider Fairness in Multi-Agent Systems (https://arxiv.org/abs/2410.12889)
- **What's New**: 본 논문에서는 다중 에이전트 시스템(Multi-Agent Systems, MAS) 내에서 에이전트들에게 기대 보상에 불리한 영향을 미치지 않아야 하는 보호 속성(protected attributes)의 개념을 도입합니다. 이는 결정적인 보상 분배 문제를 해결하는 데 초점을 맞추고 있습니다.

- **Technical Details**: 우리는 알고리즘 공정성 문헌에서 발전된 공정성 메트릭스를 MAS에 적용합니다. 구체적으로 인구 통계적 평등(demographic parity), 반사적 공정성(counterfactual fairness), 그리고 조건부 통계적 평등(conditional statistical parity)이라는 세 가지 공정성 기준을 소개합니다. 이를 통해 MAS의 공정성을 평가하고 최적화하는 방법을 제안합니다.

- **Performance Highlights**: 이 연구는 공정성을 고려한 MAS의 설계를 위한 비전을 제시하며, AI와 인간 에이전트가 혼합된 도시 환경에서의 사례를 통해 불공정한 결과를 최소화할 수 있는 방안을 모색합니다. 예를 들어, 도로 인프라를 변경하여 인간이 조작하는 차량에 대한 공정성을 향상시키는 방안이 검토됩니다.



### Navigating the Cultural Kaleidoscope: A Hitchhiker's Guide to Sensitivity in Large Language Models (https://arxiv.org/abs/2410.12880)
- **What's New**: 이 논문은 글로벌 AI 애플리케이션에서 LLMs의 문화적 민감성을 보장하는 중요성을 강조하며, 작은 매개변수 모델 내에서 발생하는 문화적 손해를 다루기 위한 두 개의 주요 기여를 제시합니다. 첫째, 다양한 문화적 맥락에서 모델의 출력을 평가하기 위한 문화적 손해 테스트 데이터셋을 소개합니다. 둘째, 다양한 주석자 피드백을 기반으로 문화적 민감성을 회복하기 위한 데이터셋을 제안합니다.

- **Technical Details**: 이 연구는 문화적 손해 평가 데이터셋과 문화적 정렬 선호 데이터셋을 구축하여 작은 매개변수 LLMs의 문화적 민감성을 높이고 해로운 출력을 줄이는 것을 목표로 합니다. 데이터셋은 사회적, 정치적, 경제적, 종교적, 문화적 가치를 반영하며, 다양한 문화적 맥락에서 모델 출력을 시스템적으로 평가할 수 있는 프레임워크를 제공합니다. 또한, reinforcement learning from human feedback (RLHF) 기법을 사용하여 문화적 기준을 존중하는 모델의 미세 조정을 지원합니다.

- **Performance Highlights**: 문화적 정렬 피드백을 통합함으로써 Mistral-v0.2(7B) 모델의 해로운 출력 발생률이 71.96%에서 3.07%로 급격히 감소하는 등의 성과를 보였습니다. 이 연구는 LLM이 다양한 문화적 경관에서 안전하고 윤리적으로 탐색할 수 있는 미래의 AI 시스템을 구축하는 데 기여할 것입니다.



### Towards More Effective Table-to-Text Generation: Assessing In-Context Learning and Self-Evaluation with Open-Source Models (https://arxiv.org/abs/2410.12878)
Comments:
          15 pages

- **What's New**: 이 연구는 자연어 처리의 핵심 작업인 테이블-텍스트 생성(table-to-text generation)에 대해, 다양한 in-context learning 전략의 효과를 평가합니다. 특히, 모델에 주어진 예제가 성능에 미치는 영향을 조사하고, 실제 애플리케이션을 기반으로 한 사례를 제공합니다.

- **Technical Details**: 모델은 zero-shot, single-shot, few-shot 프롬프트를 사용하여 테이블 데이터에서 내러티브 텍스트로 전환합니다. 이 연구에서는 두 개의 벤치마크 데이터셋인 WikiBio와 ToTTo에서 실험이 수행되었고, Llama 3와 Phi-3 모델을 사용하여 결과를 비교했습니다. 또한, GPT-4를 사용하여 초기 프롬프트를 생성하고, 이를 기반으로 최적화를 진행하였습니다.

- **Performance Highlights**: 예제를 제공함으로써 테이블-텍스트 생성의 성능이 크게 향상되었습니다. LLM 자가 평가 방법은 아직 인간의 판단과 일치도가 개선되어야 하지만, overall 성능 개선을 확인할 수 있었습니다.



### Improving Instruction-Following in Language Models through Activation Steering (https://arxiv.org/abs/2410.12877)
- **What's New**: 이 논문에서는 언어 모델(LLM)의 지침 따르기 능력을 향상시키기 위한 새로운 접근 방식을 제안합니다. 이는 지침에 따라 모델의 동작을 조정하기 위해 지침별 벡터 표현을 파생하는 내용을 다룹니다.

- **Technical Details**: 이 연구는 입력의 지침이 없는 경우와 있는 경우의 활성화(activation)의 차이를 기반으로 벡터 표현을 계산하여 모델의 출력을 조작하는 방식입니다. 사용된 활성화 벡터는 출력 형식, 길이, 특정 단어 포함 여부 등 여러 조건을 모델이 준수하도록 유도합니다.

- **Performance Highlights**: 4개의 서로 다른 모델을 대상으로 한 실험을 통해, 이 방법이 지침을 명시적으로 제공하지 않아도 모델이 제약사항을 따르도록 도와주고, 지침이 있을 때도 성능을 향상시킬 수 있음을 보여주었습니다. 또한, 여러 지침을 동시에 적용할 수 있다는 것이 확인되었습니다.



### Beyond Right and Wrong: Mitigating Cold Start in Knowledge Tracing Using Large Language Model and Option Weigh (https://arxiv.org/abs/2410.12872)
Comments:
          11 pages

- **What's New**: 이 논문에서는 LOKT 모델을 소개하여 Knowledge Tracing (KT)의 콜드 스타트 문제를 해결합니다. LOKT는 대규모 언어모델(LLM)을 사용하여 적은 이전 데이터로도 학습자의 지식 상태를 추적하고 예측할 수 있는 방법론을 제시합니다.

- **Technical Details**: LOKT 모델은 전통적인 KT 모델에 옵션 가중치를 통합하여 단순한 정답/오답 분류를 넘어 학습자의 다양한 잘못된 응답을 분석합니다. 이를 통해 LLM이 언어 기반 정량적 정보를 활용하여 학습자의 이해도를 보다 정확하게 평가할 수 있도록 합니다.

- **Performance Highlights**: 5개의 공공 데이터셋을 사용한 실험에서 LOKT 모델은 이른 단계의 개인화 학습 도구를 지원하며, '학습자 콜드 스타트'와 '시스템 콜드 스타트' 상황에서도 높은 예측 정확도를 유지하는 것을 보여주었습니다.



### AI-Driven Autonomous Control of Proton-Boron Fusion Reactors Using Backpropagation Neural Networks (https://arxiv.org/abs/2410.12871)
- **What's New**: 본 연구는 프로톤-붕소(p-11B) 핵융합로에서 핵심 파라미터를 자율적으로 제어하기 위해 역전파 기반 신경망을 이용한 새로운 접근 방식을 제안합니다. 이 방법은 물리적 데이터를 기반으로 실시간 피드백과 학습을 통해 변화하는 플라즈마 조건에 적응하는 기능을 제공합니다.

- **Technical Details**: 제안된 AI 기반 제어 시스템은 역전파(Backpropagation)로 훈련된 심층 신경망(Deep Neural Network, DNN)을 활용하여 실시간으로 플라즈마 조건을 최적화합니다. 이 시스템은 플라즈마의 상태를 동적으로 조정하여 동적이고 비선형적인 고온 플라즈마를 안정적으로 유지하는 것을 목표로 하고 있습니다.

- **Performance Highlights**: 이 연구의 AI 시스템은 실제 데이터에서 지속적으로 학습함으로써 플라즈마 안정성을 크게 향상시키고 에너지 효율성을 최적화하며, 실제 지속 가능한 핵융합 에너지로의 경로를 가속화할 가능성을 제시합니다.



### Skill Learning Using Process Mining for Large Language Model Plan Generation (https://arxiv.org/abs/2410.12870)
Comments:
          12 pages, 5 figures, 2 tables, accepted at ICPM 2024'

- **What's New**: 이 논문에서는 대형 언어 모델(LLM)의 계획 생성을 개선하기 위해 프로세스 마이닝( process mining ) 기법을 통합한 새로운 기술 학습 접근 방식을 소개합니다. 이 접근 방식은 계획 생성 과정의 효율성과 해석 가능성을 향상시키는 것을 목표로 합니다.

- **Technical Details**: 텍스트 베이스 LLM 플래너가 생성한 단순 시퀀스 대신, 프로세스 모델을 사용하여 구조화된 제어 흐름을 만들고 이를 통해 플래너의 능력을 향상시키는 방법을 제안합니다. 새로운 기술 학습 프레임워크에서는 Inductive Miner 알고리즘을 사용하여 일반적인 프로세스 모델을 추출합니다.

- **Performance Highlights**: 실험 결과, 제안한 기술 검색 방법이 특정 조건에서 기존의 정확도 기준을 초과하는 것으로 나타났으며, 유연한 기술 발견과 병렬 실행을 지원하여 성능이 향상되었습니다.



### Language Model Preference Evaluation with Multiple Weak Evaluators (https://arxiv.org/abs/2410.12869)
- **What's New**: 이 논문에서는 효율적인 평가 방식의 필요성을 강조하며 신뢰성 있는 LLM(대규모 언어 모델) 출력 평가를 위한 새로운 방법론인 GED(Preference Graph Ensemble and Denoise)를 소개합니다.

- **Technical Details**: GED는 두 가지 주요 단계로 구성됩니다: (1) 여러 LLM의 평가 결과를 통합하여 단일 preference graph(선호 그래프)를 만드는 graph ensemble과 (2) 반복적 패턴과 불일치를 제거하여 방향 비순환 그래프(DAG) 구조를 보장하는 graph denoising입니다.

- **Performance Highlights**: GED는 실험 결과에서 10개 벤치마크 데이터셋을 통해 기존 방법들보다 우수한 성능을 보였으며, 예를 들어, 응답 선택 작업에서 평균 4.51% 향상을 기록했습니다. GED는 약한 평가자(combiner) 조합을 통해 강한 평가자보다 뛰어난 성능을 보여, 평가 신뢰성을 높이고 모델 성능을 향상시키는 능력을 입증했습니다.



### Empowering Dysarthric Speech: Leveraging Advanced LLMs for Accurate Speech Correction and Multimodal Emotion Analysis (https://arxiv.org/abs/2410.12867)
Comments:
          19 pages, 6 figures, 3 tables

- **What's New**: 이번 논문은 뇌 손상으로 인해 발생하는 운동 언어 장애인 발음장애(dysarthria)의 인식 및 번역에 대한 새로운 접근 방식을 제시합니다. 이 연구는 발음장애를 가진 개인들이 보다 효과적으로 소통할 수 있도록 지원하기 위해 고급 언어 모델(large language models)을 활용합니다.

- **Technical Details**: 이 연구에서는 OpenAI Whisper 모델을 사용하여 발음장애의 음성을 텍스트로 변환한 후, LLaMA 3.1(70B) 및 Mistral 8x7B와 같은 모델을 미세 조정하여 왜곡된 입력으로부터 의도된 문장을 예측합니다. 데이터 세트는 TORGO 데이터 세트와 Google 음성 데이터를 결합하였으며, 감정 컨텍스트를 수작업으로 라벨링하여 모델 학습에 사용합니다.

- **Performance Highlights**: 제안된 시스템은 발음장애의 음성을 재구성하고 감정을 인식하는 데 있어 높은 정확도를 달성하며, 이는 실질적인 음성 데이터와 비교했을 때 눈에 띄는 발전을 보여줍니다. 이 접근 방식은 발음장애 사용자를 위한 보다 포괄적이며 효과적인 커뮤니케이션 지원 도구를 제공합니다.



### Towards Homogeneous Lexical Tone Decoding from Heterogeneous Intracranial Recordings (https://arxiv.org/abs/2410.12866)
Comments:
          Preprint V1 with 10 pages main text

- **What's New**: 최근 뇌-컴퓨터 인터페이스(BCI)의 발전으로 인해 두개내(recordings)에서 음조(lexical tones)를 해독하는 것이 가능해졌습니다. 이는 언어 손상으로 인해 의사소통 능력이 제한된 사람들에게 도움을 줄 수 있는 잠재력을 제공합니다. 하지만 생리적 및 기기적 요소로 인해 발생하는 데이터 이질성(data heterogeneity)은 통합적인 뇌 음조 해독에 상당한 도전 과제가 됩니다.

- **Technical Details**: 이 논문에서는 H2DiLR(Homogeneity-Heterogeneity Disentangled Learning for neural Representations)이라는 새로운 프레임워크를 도입하여, 여러 피험자의 두개내 기록에서 동질성과 이질성을 분리하고 학습합니다. 이 연구에서는 407개의 음절(syllables)을 포함하는 중국어 재료를 읽는 여러 참가자로부터 스테레오전자뇌전도(sEEG) 데이터를 수집했습니다.

- **Performance Highlights**: 광범위한 실험을 통해 H2DiLR은 기존의 이질적인 해독 접근 방식보다 현저히 우수한 성능을 보임을 입증했습니다. 또한 H2DiLR이 신경 표현 학습 과정에서 동질성과 이질성을 효과적으로 포착함을 실증적으로 확인하였습니다.



### ELF-Gym: Evaluating Large Language Models Generated Features for Tabular Prediction (https://arxiv.org/abs/2410.12865)
- **What's New**: ELF-Gym 프레임워크를 통해 LLM이 생성한 feature의 품질을 정량적으로 평가하는 새로운 방법론을 제시합니다.

- **Technical Details**: ELF-Gym은 Kaggle 대회에서 수집한 251개의 'golden' features를 기준으로 LLMs의 feature 엔지니어링 능력을 평가합니다. 평가 과정에서 LLM이 생성한 features의 다운스트림 모델 성능과 전문가가 제작한 features와의 의미적, 기능적 유사성을 측정합니다.

- **Performance Highlights**: 최선의 경우, LLM은 'golden' features의 약 56%를 의미적으로 포착할 수 있지만, 복잡한 feature가 요구되는 데이터셋에서는 실패할 수도 있습니다.



### Investigating Implicit Bias in Large Language Models: A Large-Scale Study of Over 50 LLMs (https://arxiv.org/abs/2410.12864)
- **What's New**: 이번 연구에서는 최신 대규모 언어 모델(LLM)들이 내재된 편향(implicit bias)을 가지고 있으며, 이러한 편향이 개발된 모델의 크기나 복잡성이 증가함에 따라 강화되고 있다는 점을 강조합니다. 또한, 편향 완화(bias mitigation)가 모델 개발에서 보편적으로 우선시되지 않고 있다는 사실을 강조합니다.

- **Technical Details**: 연구진은 50개 이상의 LLM을 대상으로 LLM Implicit Association Test (IAT) Bias 및 LLM Decision Bias 측정을 통해 내재된 편향의 정도를 탐구했습니다. 이 연구는 대규모 실험을 통해 신 모델에서 더 높은 편향 수준을 관찰하였으며, 이는 합성 데이터의 사용 증가와 관련이 있을 수 있다고 가정합니다.

- **Performance Highlights**: 새로운 또는 더 큰 언어 모델들이 자동으로 편향 수준이 감소하지 않으며, 때때로 이전 모델들보다 높은 편향 점수를 나타내기도 했습니다. 이러한 발견은 공정하고 책임감 있는 AI 시스템 개발을 위한 편향 탐지 및 완화 전략의 필요성을 강조합니다.



### Scaled and Inter-token Relation Enhanced Transformer for Sample-restricted Residential NILM (https://arxiv.org/abs/2410.12861)
Comments:
          Submitted to 27th IEEE-ICCIT

- **What's New**: 이 논문은 Non-Intrusive Load Monitoring (NILM)에서 transformer 모델의 훈련을 개선하기 위한 새로운 두 가지 메커니즘을 제안합니다. 이는 작은 규모의 데이터셋에서 transformer의 성능을 향상시키는 데 중점을 둡니다.

- **Technical Details**: 제안된 두 가지 메커니즘은 inter-token relation enhancement mechanism과 dynamic temperature tuning mechanism입니다. 첫 번째 메커니즘은 훈련 중에 토큰 유사성 행렬에서 intra-token의 중요도를 줄이고 inter-token에 집중도를 높입니다. 두 번째 메커니즘은 토큰 유사성 행렬에 대해 학습 가능한 온도 조정을 도입하여 고정 온도 값에 수반되는 과도한 smoothing 문제를 완화합니다.

- **Performance Highlights**: REDD 주거용 NILM 데이터셋을 사용한 실험 결과, 제안된 방법이 원래 transformer 모델보다 여러 가전 제품 유형에서 성능을 현저히 향상시키는 것으로 나타났습니다.



### LLMD: A Large Language Model for Interpreting Longitudinal Medical Records (https://arxiv.org/abs/2410.12860)
- **What's New**: LLMD는 환자의 의료 기록을 기반으로 의료 이력을 분석하도록 설계된 대규모 언어 모델이며, 의료 지식과 레이블이 지정된 장기 기록을 결합하여 정확한 환자 건강 정보를 제공한다.

- **Technical Details**: LLMD는 10년 이상의 치료 기록과 140개 이상의 치료 기관에서 수집된 대량의 데이터를 포함하여, 지속적인 프리트레이닝(pretraining)과 작업 기반 지침 세밀 조정(instruction fine-tuning)을 통해 훈련된다. 이 구조화(structuring) 및 추상화(abstraction) 작업은 의료 기록의 메타데이터와 임상명명 엔티티(clinical named-entities)를 식별하고 정규화하여 높은 수준의 표현으로 변환한다.

- **Performance Highlights**: LLMD-8B는 PubMedQA 텍스트 응답에서 최첨단 정확도를 달성하며, 기존의 크고 일반화된 모델 및 도메인 맞춤형 모델보다 우수한 성능을 보인다. 실제 환자 데이터를 분석할 때, 의료 지식이 아닌 프리트레이닝과 세밀 조정의 중요성을 강조하며 LLM의 의료 활용을 위한 격차에 대해 논의한다.



### Enhancing Long Context Performance in LLMs Through Inner Loop Query Mechanism (https://arxiv.org/abs/2410.12859)
- **What's New**: 이번 논문에서는 Inner Loop Memory Augmented Tree Retrieval (ILM-TR)이라는 혁신적인 접근법을 통해 복잡한 질문에 대한 보다 깊이 있는 답변 생성을 가능하게 하는 새로운 메모리 체계를 도입합니다. 이 메커니즘은 초기 질문뿐만 아니라 중간 결과에 기반한 내부 루프 쿼리를 활용하여 정보를 검색합니다.

- **Technical Details**: ILM-TR 방법은 기본적으로 두 부분으로 구성되어 있습니다: retriever와 inner-loop query. Retriever 부분에서는 RAPTOR의 트리 빌드 방법을 사용하여 원시 데이터를 짧고 연속적인 텍스트 청크로 분할하고, 각 청크의 요약을 생성합니다. Inner-loop 쿼리는 LLM을 사용하여 최종 답변을 생성하며, Short-Term Memory (STM)라는 영역에 정보를 저장하고, 전달된 데이터를 바탕으로 반복적으로 쿼리를 수행합니다.

- **Performance Highlights**: ILM-TR 시스템은 Multi-Needle In A Haystack (M-NIAH) 및 BABILong과 같은 표준 긴 컨텍스트 벤치마크에서 기존 RAG 방법을 초월하는 성능을 보여주며, 500k tokens까지 컨텍스트 길이가 증가해도 성능 저하 없이 지속적인 성능을 유지합니다.



### Large Language Models for Medical OSCE Assessment: A Novel Approach to Transcript Analysis (https://arxiv.org/abs/2410.12858)
- **What's New**: 이번 연구에서는 대규모 언어 모델(LLMs)을 활용하여 의료 기초 교육 과정에서의 학생의 의사소통 능력을 평가하는 가능성을 탐구하였습니다. 기존의 수작업 평가 방식에 비해 시간과 비용을 절감할 수 있는 자동화된 OSCE 평가 시스템을 제안합니다.

- **Technical Details**: 연구에서 2,027개의 OSCE 비디오 데이터를 활용하여 학생의 환자 의료 정보 요약 능력을 평가하였습니다. Whisper-v3를 사용하여 음성을 텍스트로 변환한 후, GPT-4를 포함한 다양한 LLM 기반 접근 방식을 통해 학생의 성과를 채점하였습니다. 연구에서는 zero-shot prompting, retrieval augmented generation 및 다중 모달 앙상블 기법을 적용하였습니다.

- **Performance Highlights**: GPT-4는 인간 채점자와의 코헨 카파(Cohen's kappa) 지수 0.88을 기록하여 LLM 기반 OSCE 채점의 가능성을 보여주었습니다. 오픈 소스 모델 또한 유망한 결과를 보였으며, 자동 채점 시스템의 구현 가능성을 제시하였습니다.



### Enterprise Benchmarks for Large Language Model Evaluation (https://arxiv.org/abs/2410.12857)
- **What's New**: 이 연구는 대규모 언어 모델(LLM)의 평가를 위한 새로운 벤치마크를 제시합니다. 이는 금융 서비스, 법률, 사이버 보안 및 기후 변화와 지속 가능성과 같은 다양한 기업 도메인에서의 NLP 작업을 포함하는 25개의 공개 데이터셋을 활용합니다.

- **Technical Details**: 본 연구에서는 LLM 평가를 위한 프레임워크를 개발하여, 각 도메인에 맞는 성능 지표와 벤치마크를 제공합니다. 이 프레임워크는 Stanford의 HELM을 보강하여, 도메인별로 구체화된 벤치마크를 추가하고 이를 통해 LLM의 성능을 측정할 수 있는 구조를 갖추고 있습니다.

- **Performance Highlights**: 13개의 모델을 다양한 기업 작업에 적용하여 성능을 평가한 결과, 특정 작업의 요구사항에 맞는 모델 선택의 중요성이 드러났습니다. 이 연구는 실질적인 기업 애플리케이션의 요구를 반영한 벤치마크와 평가 메트릭을 통해 LLM의 최적화를 도울 것으로 기대됩니다.



### Optimized Biomedical Question-Answering Services with LLM and Multi-BERT Integration (https://arxiv.org/abs/2410.12856)
Comments:
          10 pages, 12 figures, accepted and to be published in the proceedings of 2024 IEEE International Conference on Data Mining Workshops (ICDMW)

- **What's New**: 이 논문에서는 대형 언어 모델(LLMs)과 Multi-BERT 구성을 통합하여 생물의학적 질문-응답(QA) 서비스를 개선하는 정교한 접근 방식을 제안합니다. 이 시스템은 복잡한 생물의학 데이터의 방대한 양을 처리하고 우선 순위를 매기는 능력을 향상시켜 의료 전문가들이 더 나은 환자 결과 및 정보에 기반한 의사 결정을 내릴 수 있도록 지원하는 것을 목표로 합니다.

- **Technical Details**: BERT(Bidirectional Encoder Representations from Transformers) 및 BioBERT 모델의 혁신적인 사용과 다층 퍼셉트론(MLP) 레이어의 결합을 통해, 의료 부문의 증가하는 요구에 대해 보다 전문화되고 효율적인 응답을 제공합니다. 이 접근 방식은 과적합(overfitting) 문제를 해결하기 위해 하나의 BERT 모델을 동결(freeze)하면서 다른 모델을 훈련(training)하는 방법을 사용하여 QA 서비스의 전반적인 적응성을 개선합니다.

- **Performance Highlights**: BioASQ 및 BioMRC와 같은 대규모 데이터셋을 사용하여 QA 서비스 성능의 주요 지표에서 상당한 개선을 나타내는 것을 입증합니다. 이 작업은 고급 언어 모델이 의료 분야에서 실질적인 차이를 만들 수 있는 방법을 강조하며, 복잡한 정보를 관리하는 전문가들을 위해 신뢰할 수 있고 반응성이 뛰어난 도구를 제공합니다.



### JAILJUDGE: A Comprehensive Jailbreak Judge Benchmark with Multi-Agent Enhanced Explanation Evaluation Framework (https://arxiv.org/abs/2410.12855)
- **What's New**: 이번 연구에서는 jailbreak 공격에 대한 LLMs의 방어력 평가를 위한 새로운 벤치마크인 JAILJUDGE를 제안합니다. 이 벤치마크는 다양한 리스크 시나리오를 포함하고 있으며, 고품질의 인간 주석이 포함된 데이터셋으로 구성되어 있습니다.

- **Technical Details**: JAILJUDGE 데이터셋은 35k 이상의 instruction-tune 데이터를 포함하며, JailJudge MultiAgent 프레임워크를 통해 명시적 reasoning(추론)을 바탕으로 한 세밀한 평가가 가능합니다. JAILJUDGE Guard는 instruction-tuning된 종합적인 평가 모델로 비용 없이 reasonability 설명을 제공합니다.

- **Performance Highlights**: JailJudge 메소드의 성능은 다양한 모델(GPT-4, Llama-Guard 등)에서 최첨단을 나타냅니다. JailBoost는 성능을 29.24% 향상시켰고, GuardShield는 방어 ASR을 40.46%에서 0.15%로 감소시켰습니다.



### TPO: Aligning Large Language Models with Multi-branch & Multi-step Preference Trees (https://arxiv.org/abs/2410.12854)
- **What's New**: 본 연구에서는 기존의 DPO(Direct Preference Optimization) 알고리즘에서 발생하는 한계를 극복하기 위해 TPO(Tree Preference Optimization)를 제안합니다. TPO는 선호 트리(preference tree)에서 대응하는 응답을 샘플링하는 대신, 전체 선호 트리로부터 직접 학습합니다.

- **Technical Details**: TPO는 언어 모델 정렬을 Preference List Ranking 문제로 정의하며, 이는 주어진 프롬프트에 대한 응답의 순위가 매겨진 선호 리스트로부터 더 효과적으로 학습할 수 있도록 합니다. 또한, Adaptive Step Reward를 사용하여 긴 체인의 추론에서 LLM이 차별화된 단계를 인식하는 데 도움을 주고, 각 단계의 보상 값(reward values)을 조정하여 세밀한 선호 최적화(fine-grained preference optimization)를 수행합니다.

- **Performance Highlights**: TPO는 수학적 추론(task)에서의 실험을 통해 DPO보다 세 가지 공개 대형 언어 모델에 대해 네 개의 데이터셋에서 일관되게 우수한 성능을 보였습니다.



### Diversity of Thought Elicits Stronger Reasoning Capabilities in Multi-Agent Debate Frameworks (https://arxiv.org/abs/2410.12853)
Comments:
          11 pages, 9 figures

- **What's New**: 이 연구는 대형 언어 모델(LLMs)의 추론 능력과 사실 정확성을 개선하기 위한 다중 에이전트 토론(multi-agent debate) 프레임워크를 제안합니다. 특히, 다양한 모델을 활용한 경우에 더 뛰어난 성능을 발휘했으며, GPT-4와 비교하여 더 높은 정확성을 기록하였습니다.

- **Technical Details**: 다중 에이전트 토론 프레임워크는 질문 인코딩, 토론 모델, 토론 라운드, 응답 요약, 반복적 정제 및 최종 요약의 여섯 가지 주요 구성 요소로 이루어져 있습니다. 이 과정에서 다양한 모델 아키텍처를 활용하여 각 모델의 사고 다양성에 기반한 강력한 논리를 생성합니다.

- **Performance Highlights**: 이 연구에서 사용한 중간 용량 모델 세트(Gemini-Pro, Mixtral 7BX8,와 PaLM 2-M)는 4회 토론 후 GSM-8K 벤치마크에서 91%의 정확도를 기록하여 GPT-4를 초월하였고, ASDiv 벤치마크에서는 94%로 새로운 최고 기록을 세웠습니다.



### VibeCheck: Discover and Quantify Qualitative Differences in Large Language Models (https://arxiv.org/abs/2410.12851)
Comments:
          10 pages, unironic use of the word 'vibe'

- **What's New**: VibeCheck는 대형 언어 모델(LLMs) 간의 뚜렷한 특성(vibes)을 발견하고 측정하는 시스템으로, 모델의 출력에서 다양한 차원(ton, formatting, writing style)을 평가할 수 있는 새로운 방식입니다. 이 시스템은 사용자의 선호와 모델의 정체성을 예측할 수 있는 vibres를 자동으로 확인합니다.

- **Technical Details**: VibeCheck는 모델의 출력을 통해 vibes를 반복적으로 발견하고, LLM 판별자를 통해 각 vibe의 유용성을 정량적으로 측정합니다. 발견된 vibes는 다수의 사용자의 합의, 모델 간 차별화, 사용자 선호 예측 세 가지 기준을 충족해야 합니다. VibeCheck는 Llama-3-70b와 GPT-4의 사용자 대화 데이터를 기반으로 실험했으며, 80%의 정체성 예측 정확도와 61%의 사용자 선호 예측 정확도를 달성했습니다.

- **Performance Highlights**: VibeCheck의 결과에 따르면, Llama는 친근하고 유머러스하며 다소 논란이 있는 vibe를 가지며, Command X는 요약 시 구체적인 서론과 결론을 추가하는 경향이 있고, Llama-405b는 수학 문제에서 자신의 사고 과정을 과도하게 설명하는 경향이 있는 반면, GPT-4는 캡셔닝에서 장면의 정서와 분위기에 집중하는 경향이 있음을 확인했습니다.



### RecurFormer: Not All Transformer Heads Need Self-Attention (https://arxiv.org/abs/2410.12850)
- **What's New**: 이 논문에서는 Transformer 기반의 대형 언어 모델(LLM)의 응답 생성 과정에서 발생하는 계산 비용 문제를 해결하기 위해 RecurFormer라는 새로운 아키텍처를 제안합니다. RecurFormer는 특정 attention head를 linear recurrent neural network (RNN)인 Mamba 아키텍처로 교체하여 메모리 캐시 사이즈를 줄이고, 토큰을 제거하지 않으면서 생성 품질을 유지합니다.

- **Technical Details**: RecurFormer는 recency aware 속성을 가진 attention head를 Mamba 아키텍처로 교체하는 방식으로 구성되어 있습니다. Mamba는 selective structured state-space sequence model 기반의 linear RNN으로, parallel 및 recursive 계산을 지원합니다. 이 방식은 기존 Transformer의 가중치를 계속 활용할 수 있도록 하여 모델의 성능을 유지하면서도 계산 효율을 증대시킵니다.

- **Performance Highlights**: 실험 결과, RecurFormer는 원래 모델의 성능을 유지하면서도 추론 효율성을 크게 향상시키는 것으로 나타났습니다. 또한, 지속적인 훈련을 통해 성능 회복이 가능하다는 것을 보여주어, 긴 입력에 관련된 작업에서 Transformer 기반 LLM의 계산적 도전에 대한 실용적인 해결책을 제공합니다.



### Prompt Engineering a Schizophrenia Chatbot: Utilizing a Multi-Agent Approach for Enhanced Compliance with Prompt Instructions (https://arxiv.org/abs/2410.12848)
- **What's New**: 이 논문은 정신분열증 환자를 위한 교육 플랫폼에서 Large Language Models (LLMs)인 GPT-4를 활용하는 방법을 제안합니다. 특히, 챗봇의 반응이 초기에 설정된 범위를 넘는 경우를 다루기 위해 Critical Analysis Filter를 도입했습니다.

- **Technical Details**: 이 시스템은 여러 LLM 에이전트가 챗봇의 반응을 분석하고 개선하는 역할을 합니다. 실험에서는 정보 제공 목적의 정신분열증 챗봇을 개발하고, 필터가 비활성화된 상태에서 대화를 진행하여 챗봇의 범위를 초과하는 모습을 관찰했습니다. 이후 AI 에이전트를 통해 범위를 벗어난 주제에 대한 샘플 대화를 자동 생성하고, 각 반응에 대해 컴플라이언스 점수를 할당했습니다.

- **Performance Highlights**: Critical Analysis Filter를 활성화했을 때 챗봇의 컴플라이언스 점수는 67.0%에서 적정 수준(점수 >=2)을 유지했지만, 필터가 비활성화된 경우에는 단지 8.7%에 불과했습니다. 이는 정신 건강 플랫폼에서 LLM을 효과적이고 안전하게 사용하기 위한 자기 반성 계층의 필요성을 시사합니다.



### ACCEPT: Adaptive Codebook for Composite and Efficient Prompt Tuning (https://arxiv.org/abs/2410.12847)
Comments:
          EMNLP Findings 2024

- **What's New**: 이 연구에서는 Adaptive Codebook for Composite and Efficient Prompt Tuning (ACCEPT)이라는 새로운 방법을 제안합니다. 기존의 Prompt Tuning (PT) 기법이 개별적으로 업데이트되는 프롬프트로 인해 파라미터 수가 비례적으로 증가하는 문제를 해결하여 모든 소프트 프롬프트가 학습 가능한 코드북 벡터를 공유하도록 하여 파라미터 효율성을 높입니다.

- **Technical Details**: ACCEPT는 제품 양자화(Product Quantization, PQ) 개념을 바탕으로 하며, 각 프롬프트의 단어 임베딩을 여러 하위 섹션으로 나누어 각각의 섹션에 대해 코드북을 구성합니다. 이 방법은 프롬프트의 각 하위 벡터가 선형 계수를 통해 부드럽게 결합되도록 하여 더 높은 다양성과 유연성을 제공합니다. 또한, ACCEPT는 0.3%의 플로우우먼스 파라미터만 조정하여 17개의 자연어 작업에서 우수한 성능을 달성합니다.

- **Performance Highlights**: 17개의 다양한 자연어 작업에서 ACCEPT 방법이 이전의 PT 접근법을 일관되게 초과 달성했습니다. 특히, 몇 가지 샷(few-shot) 및 대형 모델 환경에서 뛰어난 성능을 보여주며, 사전 훈련된 언어 모델(PLMs)의 효율성을 극대화합니다.



### Accurate and Regret-aware Numerical Problem Solver for Tabular Question Answering (https://arxiv.org/abs/2410.12846)
- **What's New**: TabLaP라는 모델을 제안하여, Large Language Model (LLM)을 답변 생성기가 아닌 계획자로 활용하며, 숫자 계산을 위한 정확한 처리기인 Python interpreter에게 계산을 맡깁니다. 또한, TabLaP가 생성한 답변의 신뢰성을 정량화하여 사용자가 후회 유발 가능성을 줄일 수 있도록 합니다.

- **Technical Details**: TabLaP는 두 개의 모델 브랜치를 갖고 있으며, 하나는 NumSolver로 숫자 질문을 처리하고, 다른 하나는 최신 TableQA 모델입니다. 생성된 답변을 통합하기 위해 AnsSelecter라는 LLM을 사용하여 신뢰할 수 있는 브랜치를 선택합니다. TwEvaluator 모듈을 통해 각 브랜치의 정확도를 추적하여 답변 신뢰성을 평가합니다.

- **Performance Highlights**: TabLaP는 두 개의 벤치마크 데이터셋에서 기존의 SOTA 모델에 비해 각각 5.7%와 5.8% 향상된 정확도를 기록했습니다. 또한, TabLaP의 신뢰성 플래그는 사용자 후회 비율을 두 데이터셋에서 각각 30.9%와 20.6% 감소시켰습니다.



### Toward Relieving Clinician Burden by Automatically Generating Progress Notes using Interim Hospital Data (https://arxiv.org/abs/2410.12845)
Comments:
          Accepted at the AMIA 2024 Annual Symposium

- **What's New**: 이 논문에서는 전자 건강 기록(EHR)의 구조화된 정보를 활용하여 진행 노트 생성(Progress Note Generation, PNG) 자동화를 위한 새로운 방법론을 제안합니다. 특히, 1616명의 환자로부터 수집된 7089개의 주석 인스턴스를 포함한 대형 데이터셋 ChartPNG를 소개합니다.

- **Technical Details**: 이 연구는 임상 의사들이 작성한 SOAP 노트를 기반으로 하는 프로세스입니다. 진행 노트는 환자의 주관적 및 객관적 상태와 평가 및 계획(A&P)으로 구성되어 있으며, 연구는 A&P 섹션의 자동 생성을 주로 목표로 합니다. 이 과정에서 대형 언어 모델을 활용하여 자동 분석을 수행하고, 향후 연구 기회를 찾아내기 위해 오류 분석을 실시하였습니다.

- **Performance Highlights**: 자동화된 분석에서는 Biomistral 모델이 BERTScore F1 점수 80.53과 MEDCON 점수 19.61을 기록하였고, 수작업 분석에서는 76.9%의 정확도로 관련 구조화 데이터를 활용할 수 있음을 보여주었습니다.



### Exploring Prompt Engineering: A Systematic Review with SWOT Analysis (https://arxiv.org/abs/2410.12843)
Comments:
          14 pages, 1 figures

- **What's New**: 이번 논문에서는 대형 언어 모델(LLM) 내에서 프롬프트 엔지니어링(prompt engineering) 기술에 대한 포괄적인 SWOT 분석을 수행했습니다. 언어학 원칙을 강조하며, 다양한 기술들을 분석하여 그 강점, 약점, 기회 및 위협을 파악했습니다. 이러한 발견은 AI 상호작용을 향상시키고 언어 모델이 인간의 프롬프트를 이해하는 방법을 개선하는 데 기여합니다.

- **Technical Details**: 이 논문에서는 100편 이상의 관련 문헌을 조사하여 프롬프트 엔지니어링 분야에 대한 폭넓은 통찰을 제공합니다. 주요 프롬프트 엔지니어링 기술로는 템플릿 기반 접근법(template-based approaches)과 파인 튜닝(fine-tuning) 방식이 있으며, 각 기술의 문제점 및 도전 과제를 다루었습니다. 또한, BLEU, BERTScore, ROUGE 및 Perplexity와 같은 여러 평가 메트릭(metrics)을 확인했습니다. 연구는 언어 모델의 행동을 이해하는 데 도움을 주고, 맞춤형 상호작용을 제공하는 목표에 맞춰 진행되었습니다.

- **Performance Highlights**: 이 연구는 LLM의 정확성 및 관련성을 향상시킬 수 있는 효과적인 프롬프트 엔지니어링의 중요성을 강조하며, 사용자 및 개발자 간의 지식 공유와 대화형 AI 툴의 발전을 촉진합니다. 특히, 차별화된 접근법을 통해 응답 정확도를 높이고, 대화형 AI의 성장에 기여할 것입니다.



### A Two-Model Approach for Humour Style Recognition (https://arxiv.org/abs/2410.12842)
- **What's New**: 이번 연구에서는 1,463개의 인스턴스를 포함하는 새로운 텍스트 데이터셋을 도입하여 네 가지 유머 스타일(자기 증진, 자기 비하, 친화적, 공격적) 및 비유머 텍스트를 인식하는 데 필요한 기계 학습 모델링을 지원합니다. 이는 유머 스타일 인식의 연구 공백을 채우는 중요한 기여를 합니다.

- **Technical Details**: 연구에서는 고전 기계 학습 분류기, 텍스트 임베딩 모델 및 DistilBERT를 포함한 다양한 컴퓨팅 방법을 사용하여 기준 성능을 설정하였습니다. 또한, 친화적 유머 분류의 F1 점수를 11.61% 향상시키는 두 개의 모델 접근 방식을 제안하였습니다. 이 연구는 각 유머 스타일에 대한 다중 클래스 분류 문제를 다룹니다.

- **Performance Highlights**: 두 개의 모델 접근 방식을 통해 14개의 테스트된 모델에서 일관된 성능 개선을 보였으며, 특히 친화적 유머 분류에서 F1 점수의 11.61% 향상을 달성했습니다. 이는 문학, 소셜 미디어 및 다른 텍스트 출처에서 유머를 연구하기 위한 새로운 도구를 제공합니다.



### UniAutoML: A Human-Centered Framework for Unified Discriminative and Generative AutoML with Large Language Models (https://arxiv.org/abs/2410.12841)
- **What's New**: 새로운 AutoML 프레임워크인 UniAutoML이 소개되었습니다. UniAutoML은 기존의 AutoML 프레임워크가 주로 다루었던 discriminative task 뿐만 아니라 generative task도 통합하여 지원하는 것이 특징입니다. 사용자가 쉽게 접근할 수 있도록 자연어로 상호작용할 수 있는 대화형 사용자 인터페이스(CUI)를 제공합니다.

- **Technical Details**: UniAutoML은 Large Language Models (LLMs)를 활용하여 데이터 처리, 모델 선택 및 하이퍼파라미터 검색을 자동화한 인공지능 프레임워크입니다. 사용자들은 자연어 명령을 통해 복잡한 모델을 fine-tuning 할 수 있으며, 모델은 HuggingFace에서 사전 훈련된 다양한 모델을 선택하고 사용할 수 있습니다. 또한, safety guard-line을 설계하여 사용자 입력과 LLM 출력의 필터링이 이루어집니다.

- **Performance Highlights**: UniAutoML은 25명의 참가자를 대상으로 8개의 다양한 데이터셋에 대한 실험을 통해 성능과 사용성을 평가하였고, 그 결과 사용자 제어와 신뢰도를 향상시켰습니다. UniAutoML의 인간 중심 디자인은 AutoML의 기능과 사용자 이해 사이의 격차를 해소하여 더 많은 사람들이 ML(Machine Learning)에 접근할 수 있도록 합니다.



### Capturing Bias Diversity in LLMs (https://arxiv.org/abs/2410.12839)
Comments:
          2nd International Conference on Foundation and Large Language Models (FLLM2024), 26-29 November, 2024 | Dubai, UAE

- **What's New**: 이 논문은 대규모 언어 모델(Large Language Models, LLMs)의 출력 다양성을 높이기 위해 여러 개의 사용자 정의 GPT 모델을 구성하여 BiasGPT라는 새로운 프레임워크를 제안하고 평가합니다. 이 모델들은 성별, 연령 및 인종 같은 특정 인구통계학적 특성의 편향을 반영하여 협력하고, 다양한 관점을 통합하여 인간의 경험을 보다 잘 캡처한 응답을 생성합니다.

- **Technical Details**: BiasGPT는 여러 개의 사용자 정의 GPT 모델을 사용하여 각 모델이 특정 인구 통계적 특성을 반영함으로써 다양한 응답을 생성하는 방법입니다. 이 방법론은 사용자 정의된 LLM을 통해 학습된 편향들이 통합되어 보다 포괄적이고 공정한 AI 챗봇 응답을 형성하도록 합니다. 또한, 논문에서는 대화 데이터 수집 과정에서 연령, 인종, 성별 기반의 다양한 편향을 다루기 위한 포괄적인 접근 방식을 사용합니다.

- **Performance Highlights**: 일련의 실험을 통해 BiasGPT는 다양한 사회적 특성을 반영한 응답을 생성할 수 있는 능력을 입증하였으며, 이는 더욱 포괄적이고 대표적인 AI 대화를 형성하는 데 기여할 것입니다. 이 연구는 AI 기술의 포용성을 높이는 방향으로 나아가는 데 주요한 실험적 근거를 제공합니다.



### A Comprehensive Survey of Retrieval-Augmented Generation (RAG): Evolution, Current Landscape and Future Directions (https://arxiv.org/abs/2410.12837)
Comments:
          4 Figures

- **What's New**: 이 논문은 Retrieval-Augmented Generation (RAG)의 발전 과정을 포괄적으로 조사하며, 기존 개념에서 최신 기술에 이르기까지의 변화를 설명합니다. RAG는 검색 메커니즘과 생성 언어 모델을 결합하여 출력의 정확성을 높이며, LLMs의 주요 제한 사항을 해결합니다.

- **Technical Details**: RAG의 기본 아키텍처는 지식 집약적인 작업을 처리하기 위해 검색과 생성을 어떻게 통합하는지에 중점을 둡니다. 논문에서는 retrieval-augmented language models에서의 주요 혁신과 질문 답변, 요약 및 지식 기반 작업 등 다양한 도메인에서의 응용 사례를 자세히 리뷰합니다.

- **Performance Highlights**: 최근 연구 성과는 retrieval 효율성을 개선하기 위한 새로운 방법을 강조하고 있으며, RAG의 연구 방향으로는 모델의 견고성 향상, RAG 모델의 적용 범위 확대 및 사회적 함의 문제 다루기가 제안됩니다.



### EditRoom: LLM-parameterized Graph Diffusion for Composable 3D Room Layout Editing (https://arxiv.org/abs/2410.12836)
- **What's New**: EditRoom은 자연어 명령을 통해 다양한 레이아웃 편집을 자동으로 수행할 수 있는 통합 프레임워크로, 수동 개입 없이 실행됩니다.

- **Technical Details**: EditRoom은 두 개의 주요 모듈인 Command Parameterizer와 Scene Editor로 구성되어 있습니다. Command Parameterizer는 사전 훈련된 LLM(GPT-4o)을 활용하여 자연어 명령을 여섯 가지 기본 편집 유형에 대한 분해 명령으로 변환합니다. Scene Editor는 소스 장면과 텍스트 명령을 조건으로 삼아 확산 기반(diffusion-based) 모델을 훈련하여 목표 장면을 생성합니다.

- **Performance Highlights**: 편집 작업에 대한 실험 결과, EditRoom은 모든 메트릭에서 다른 기준선보다 우수한 성능을 보였으며, 다중 작업 명령에 대해서도 일반화할 수 있는 능력을 보여줍니다.



### Segment as You Wish -- Free-Form Language-Based Segmentation for Medical Images (https://arxiv.org/abs/2410.12831)
- **What's New**: 이번 논문에서는 기존의 바운딩 박스나 포인트 기반의 프롬프트 대신 자연어 기반의 프롬프트를 활용하여 의료 이미지 분할(Medical Image Segmentation, MIS) 문제를 해결하는 새로운 접근 방식을 제안합니다. 이를 위해 RAG(임시 증강 생성) 기술을 이용한 자유형 텍스트 프롬프트 생성기를 개발하고, 다양한 텍스트 프롬프트를 처리할 수 있는 새 모델인 FLanS를 소개합니다.

- **Technical Details**: FLanS는 전문 해부학 기반 쿼리, 해부학 무관 위치 기반 쿼리, 해부학 무관 크기 기반 쿼리를 포함한 다양한 자유형 텍스트 프롬프트를 처리할 수 있는 모델입니다. 또한, 대칭 인지 캐노니컬화 모듈을 통해 스캔 방향에 따른 일관된 정확한 분할을 보장하며, 100,000개 이상의 의료 이미지로 훈련되었습니다.

- **Performance Highlights**: FLanS는 최근의 SOTA(State-of-the-Art) 모델들보다 우수한 언어 이해 능력과 분할 정밀도를 보여주었으며, 다양한 임상 환경에서의 응용 가능성을 입증했습니다. 논문에서는 자질 분석(ablation studies)을 통해 각 구성 요소의 기여도를 검증했습니다.



### Incorporating Metabolic Information into LLMs for Anomaly Detection in Clinical Time-Series (https://arxiv.org/abs/2410.12830)
- **What's New**: 이번 논문에서는 의료 분야에서의 데이터 분석을 위해 LLMs(Large Language Models)에 대한 도메인 지식을 통합한 새로운 기법인 Metabolism Pathway-driven Prompting(MPP)를 제안합니다. 이 방법론은 생물학 샘플의 구조적 및 시간상의 변화를 더 잘 포착하는데 기여합니다.

- **Technical Details**: 이 논문은 다변량 임상 시계열 데이터의 이상 탐지를 위한 방법론을 제시합니다. MPP는 대사 경로에 관한 정보와 다양한 대사물질의 시간적인 변화를 LLM에 통합하여, 시간 경과에 따른 대사물질 간의 의존성을 고려합니다. 이를 통해 특정 샘플에 대한 이상 점수를 부여하는 함수 f(xt)를 학습합니다.

- **Performance Highlights**: 결과적으로, 이 방법은 스포츠에서의 도핑 탐지 문제에 효과적으로 적용되며, 실제 데이터를 사용하여 의심스러운 표본의 발견 성능을 개선합니다. MPP는 기존의 제로샷 학습(zero-shot learning) 및 맥락 학습(in-context learning) 기법과 비교할 때 우수한 성과를 보였습니다.



### A transformer-based deep reinforcement learning approach to spatial navigation in a partially observable Morris Water Maz (https://arxiv.org/abs/2410.12820)
- **What's New**: 이번 연구는 Morris Water Maze (MWM) 실험을 재현하기 위해 transformer 기반 아키텍처를 이용한 딥 강화학습을 적용한 것입니다. 이는 기존 연구에서 다루지 않았던 접근법으로, 2D 미로에서 에이전트가 효과적으로 탐색할 수 있도록 합니다.

- **Technical Details**: 에이전트는 decoder-only transformer 아키텍처를 활용하여 부분 관찰 가능한 환경에서 Q-value를 예측합니다. 비교적 제한된 시각 정보를 가진 환경에서 효율적으로 학습하며, 그 결과 공간 탐색 전략을 습득하게 됩니다. 뉴럴 네트워크의 회귀 문제를 해결하기 위해 recurrent position encoding과 multi-head attention도 사용합니다.

- **Performance Highlights**: 제안된 transformer 아키텍처는 에이전트가 효율적으로 탐색 임무를 수행하도록 함으로써, 내부 환경 표현에 대한 이해도를 높일 수 있는 기회를 제공합니다. 특히, 보조 작업 없이도 빠르게 학습할 수 있는 능력을 보여주며, 생물학적 에이전트와 유사한 행동을 보일 수 있는 잠재력을 시사합니다.



### Interactive Explainable Anomaly Detection for Industrial Settings (https://arxiv.org/abs/2410.12817)
- **What's New**: 이 연구는 산업 환경에서의 품질 보증을 위한 시각적 이상 탐지(Anomaly Detection)에 중점을 두고 있습니다. Convolutional Neural Networks (CNNs) 기반의 분류 모델과 블랙 박스(Classifier) 분류기를 위한 모델-비의존적(Machine-agnostic) 설명 알고리즘의 발전에 초점을 맞추고 있습니다. 이를 통해 사용자-interactive interface를 구현하여 모델의 출력을 수정할 수 있도록 돕습니다.

- **Technical Details**: 두 가지 클래스(정상, 비정상)로 분류되는 산업용 이상 탐지 데이터를 위한 InvRISE라는 새로운 설명 방법을 도입하였으며, 기존 CAIPI 알고리즘에 NearCAIPI라는 확장을 추가하였습니다. 이 알고리즘은 사용자 피드백을 적극적으로 통합하여 모델의 성능을 개선하고 설명성을 높이는 것을 목표로 합니다.

- **Performance Highlights**: 이 프레임워크를 통해 사용자 피드백을 통합한 인터랙티브한 과정이 가능해지며, 모델의 신뢰성과 사용 편의성을 증가시킬 수 있는 성과를 보였습니다. 특정 결함(예: 용접 선상의 결함) 탐지에서 사용자에 대한 추가적인 피드백이 성능 향상에 기여할 수 있음을 보여주고 있습니다.



### Optimizing and Evaluating Enterprise Retrieval-Augmented Generation (RAG): A Content Design Perspectiv (https://arxiv.org/abs/2410.12812)
Comments:
          6 pages, 4 figures, to be published in ICAAI 2024 conference proceedings

- **What's New**: 본 논문에서는 리뷰 기반 생성(Retrieval-augmented generation, RAG) 솔루션의 구현 및 유지 관리 경험을 공유하고 있습니다. 기존 RAG 문헌에서 일반적으로 제시된 패턴과의 차별성을 강조하며, 모듈화되어 있고 모델에 의존하지 않는 접근 방식을 중심으로 해결책을 제시합니다.

- **Technical Details**: RAG의 기본 원리는 지식 기반에서 관련 콘텐츠를 검색하고, 이 콘텐츠에 기반한 프롬프트를 작성한 후, LLM에게 출력을 생성하도록 요청하는 것입니다. 그러나 본 팀의 RAG 솔루션은 벡터 데이터베이스에 의존하지 않아 다양한 검색 기법과 LLM을 사용합니다. 지식 기반 콘텐츠 최적화 및 실시간 사용자 질문에 대한 테스트와 평가 방안도 다루고 있습니다.

- **Performance Highlights**: 기존 RAG 평가 지표는 기존 사용자 질문에 대한 응답 평가에 유용하지 않아, 유연한 '인간 선도' 접근 방식이 필요하다는 점을 강조하고 있습니다. 지식 기반 콘텐츠 개선을 통해 RAG 솔루션의 성공 여부에 큰 영향을 미칠 수 있음을 보여줍니다.



### A Hierarchical conv-LSTM and LLM Integrated Model for Holistic Stock Forecasting (https://arxiv.org/abs/2410.12807)
Comments:
          8 pages, 2 figures, 2 tables

- **What's New**: 본 연구는 전통적인 주식 시장 예측 모델의 제한점을 극복하기 위해 새로운 Two-Level Conv-LSTM Neural Network와 Large Language Model (LLM)의 통합 접근 방식을 제안합니다.

- **Technical Details**: 모델은 두 가지 주요 레벨로 구성되어 있습니다. 첫 번째 레벨은 주가 및 기술 지표에서 지역 패턴을 추출하기 위한 Convolutional 층과 시간적 역학을 포착하기 위한 Long Short-Term Memory (LSTM) 층을 포함합니다. 두 번째 레벨은 LLM을 통합하여 금융 뉴스, 소셜 미디어 및 보고서의 감정 및 맥락 정보를 분석합니다.

- **Performance Highlights**: 이 통합 접근 방식은 예측 정확도를 향상시키고 주식 조언에 맥락적으로 풍부한 정보를 제공합니다.



### Design of an Efficient Fan-Shaped Clustered Trust-Based Routing Model with QoS & Security-Aware Side-Chaining for IoV Deployments (https://arxiv.org/abs/2410.12798)
Comments:
this https URL

- **What's New**: 이 논문에서는 인터넷 차량(IoV) 환경에서의 데이터 통신을 효율적으로 관리하기 위한 새로운 팬형 신뢰 기반 라우팅 모델을 제안합니다. 이 모델은 품질 보장(QoS)과 보안 인식을 통한 사이드 체인(side-chaining) 관리를 특징으로 합니다.

- **Technical Details**: 제안된 모델은 지연(delay), 처리량(throughput), 패킷 전달 비율(Packet Delivery Ratio, PDR), 에너지 소비를 고려하여 최적의 라우팅 경로를 결정합니다. 기존의 블록체인 기반 보안 모델을 현저하게 개선하며, 박테리아 채집 최적화(Bacterial Foraging Optimizer, BFO) 알고리즘을 이용해 사이드 체인을 동적으로 조정하여 시스템 성능을 극대화합니다. 팬형 군집화(fan-shaped clustering) 기법을 사용하여 노드를 효율적인 클러스터로 그룹화합니다.

- **Performance Highlights**: 제안된 모델은 대안 모델에 비해 지연을 9.5%, 처리량을 10.5%, 패킷 전달 비율(PDR)을 2.9%, 에너지 소비를 4.5% 줄이는 성과를 보였습니다. 또한, 시빌(Sybil), 가장하기(Masquerading), 플러딩(Flooding) 공격에 대한 저항력을 평가하였으며, 이러한 공격 상황에서도 높은 QoS 수준을 유지하며 신뢰할 수 있는 데이터 전송을 보장합니다. 이 모델은 스마트 시티, 산업 자동화, 의료 시스템, 교통 네트워크 및 환경 모니터링 등 다양한 응용 분야에 활용될 수 있습니다.



### Disaggregating Embedding Recommendation Systems with FlexEMR (https://arxiv.org/abs/2410.12794)
- **What's New**: FlexEMR는 embedding 기반 추천 (EMR) 모델의 비효율성을 해결하기 위한 새로운 분산 시스템으로, 네트워크 데이터 전송의 효율성을 개선하고 총 비용 소유권을 줄이기 위한 디자인을 제안합니다.

- **Technical Details**: FlexEMR는 두 가지 기술 세트를 통해 네트워크 문제를 해결합니다. 첫 번째는 embedding 조회의 시간적 및 공간적 지역성을 활용하여 데이터 이동을 줄이고, 두 번째는 다중 스레드 RDMA 엔진을 설계하여 동시 조회 하위 요청을 최적화하는 것입니다.

- **Performance Highlights**: 초기 프로토타입에서 FlexEMR은 원격 embedding 조회의 성능을 향상시켰으며, queuing latency를 크게 줄이고, 응답 혼잡을 완화하는 데 기여했습니다.



### Environment Scan of Generative AI Infrastructure for Clinical and Translational Scienc (https://arxiv.org/abs/2410.12793)
- **What's New**: 이번 연구는 미국의 Clinical and Translational Science Award (CTSA) 프로그램을 지원하는 36개 기관의 GenAI (Generative AI) 인프라를 종합적으로 분석한 것입니다. GenAI 기술의 빠른 발전으로 의료 기관들은 전례 없는 기회와 도전에 직면해 있습니다. 이 연구는 GenAI 통합 현황을 탐색하며, 이해당사자의 역할, 거버넌스 구조 및 윤리적 고려 사항에 집중하고 있습니다.

- **Technical Details**: 연구는 CTSA 기관의 리더들을 대상으로 설문조사를 실시하여 GenAI 채택에 대한 기관의 준비 상태를 평가했습니다. 주요 발견으로는 대부분의 기관이 GenAI 구현의 실험 단계에 있으며, 중앙 집중식 의사결정을 선호하는 경향이 강하나, 인력 교육과 윤리적 감독의 격차가 존재한다는 점이 드러났습니다.

- **Performance Highlights**: 연구 결과, GenAI 채택에 있어 주요 이해당사자의 참여가 다르다는 점이 확인되었습니다. senior leaders가 94.4%로 가장 많이 참여했으며, IT 직원과 연구자, 의사들이 뒤따랐습니다. 36개 응답 기관 중 77.8%는 GenAI 거버넌스를 감독하는 공식 위원회 또는 작업 그룹을 보유하고 있는 것으로 나타났습니다. 또한, 중앙 집중식 접근 방식이 61.1%의 기관에서 사용되고 있으며, 이는 GenAI의 효과적인 구현을 위한 전략적 리더십 및 결정-making의 중요성을 강조합니다.



### JudgeBench: A Benchmark for Evaluating LLM-based Judges (https://arxiv.org/abs/2410.12784)
Comments:
          preprint

- **What's New**: 본 논문에서는 LLM 기반의 평가자(judges)의 신뢰성을 점검하기 위한 새로운 평가 프레임워크를 제안합니다. 이를 통해 기존의 인간 평가자와 비교할 수 있는 JudgeBench라는 벤치마크를 소개합니다.

- **Technical Details**: JudgeBench는 지식(knowledge), 추론(reasoning), 수학(math), 코딩(coding) 등의 난이도 있는 응답 쌍을 평가하는 새로운 벤치마크입니다. 기존의 데이터셋을 활용하여 난이도 높은 응답 쌍으로 변환하는 파이프라인을 활용합니다.

- **Performance Highlights**: JudgeBench는 이전 벤치마크에 비해 훨씬 더 큰 도전을 제시하며, 많은 강력한 모델들이 무작위 추측(random guessing)보다 조금 더 나은 성과를 낼 뿐임을 보여주었습니다. 이는 LLM 기반 평가자의 평가 과정에서의 신뢰성을 높이는 데 기여할 것으로 기대됩니다.



### Explainable Moral Values: a neuro-symbolic approach to value classification (https://arxiv.org/abs/2410.12631)
Comments:
          Published at ESWC24 Satellite Event

- **What's New**: 이번 연구는 온톨로지 기반 추론(ontology-based reasoning)과 머신러닝(Machine Learning) 기술을 통합하여 설명 가능한 가치 분류(explainable value classification)를 탐구합니다. Moral Foundations Theory에 기반한 가치의 온톨로지적 공식화를 사용하고, sandra라는 신경-상징적(reasoner) 추론기를 통해 특정 문장이 만족하는 가치 묘사를 추론합니다. 이 과정에서 문장과 그 구조적 표현은 오픈소스 대형 언어 모델(Large Language Model)을 이용해 자동 생성됩니다.

- **Technical Details**: 이 연구에서는 Moral Foundations Theory를 이론적 프레임워크로 활용하여 가치 분류를 수행합니다. sandra neuro-symbolic reasoner는 DnS Ontology Design Pattern을 사용하여 다양한 관점에서 문장의 의미를 해석합니다. 실험을 통해 추론만을 바탕으로 한 분류 방식이 복잡한 접근 방식에 근접한 성능을 보여주며, 문장의 감정 극성과 가치 간의 상관관계도 확인했습니다. 또한, 우리의 방법은 해석 가능성을 보장하여 분류 결정에 대한 정당성을 제공합니다.

- **Performance Highlights**: 우리의 접근 방식은 이유 추론과 배급 의미 방법(distributional semantics methods)의 결합을 통해 모든 기준선(baseline)을 초과하는 성과를 보여줍니다. 이 방식은 LLM 기반 방법에도 뒤지지 않는 성과를 보이며, 해석 가능성을 손상시키지 않고도 성능 향상을 이끌어냈습니다. 또한, 우리는 이론 기반 가치 분류의 잠재력을 탐색할 수 있는 시각화 도구를 구축하여 공개했습니다.



### Counterfactual Effect Decomposition in Multi-Agent Sequential Decision Making (https://arxiv.org/abs/2410.12539)
- **What's New**: 본 연구에서는 다중 에이전트 마르코프 결정 프로세스에서 반사실(outcome) 결과를 설명하는 데 있어 새로운 접근법을 제시합니다. 특히, 에이전트의 행동이 실제 시나리오의 결과에 미치는 반사실 효과를 환경 동태 및 에이전트 행동에 미치는 영향으로 설명하려고 합니다.

- **Technical Details**: 우리는 새로운 인과적(causal) 설명 공식을 도입하여 반사실 효과를 계량화합니다. 이는 각 에이전트 및 상태 변수를 효과에 대한 기여도를 나타내는 점수로 분해합니다. 연구는 에이전트의 행동이 초래하는 반사실 효과를 순차적으로 에이전트 행동을 통해 전파되는 효과와 상태 전이(state transition)를 통해 전파되는 효과로 나누어 설명합니다. 또한, Shapley value를 사용하여 에이전트 특정 효과를 개별 에이전트에 귀속시키며, 구조 보존 개입(structure-preserving interventions)을 통해 상태 변수의 기여를 분석하는 방법을 제안합니다.

- **Performance Highlights**: 실험을 통해 LLM 보조 에이전트가 있는 Gridworld 환경과 패혈증 관리 시뮬레이터에서 우리의 분해 접근법이 해석 가능성을 가진다는 것을 입증하였습니다.



### Benchmarking Defeasible Reasoning with Large Language Models -- Initial Experiments and Future Directions (https://arxiv.org/abs/2410.12509)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 본 연구는 대규모 언어 모델(LLMs)의 비모노토닉 추론(nonmonotonic reasoning) 능력과 한계를 이해하기 위한 기준을 제시합니다.

- **Technical Details**: 기존의 결함 규칙(defeasible rule) 기반 추론 기준을 수정하여 LLMs에 적합한 텍스트로 번역된 결함 규칙을 사용했습니다. 연구에서는 ChatGPT를 사용하여 비모노토닉 규칙 기반 추론에 대한 초기 실험을 수행하고, 결함 논리(defeasible logic)에 의해 정의된 추론 패턴과 비교했습니다.

- **Performance Highlights**: ChatGPT가 비모노토닉 추론 과제에서 어떻게 성능을 발휘하는지를 평가하며, 기존의 결함 논리 패턴들과 비교합니다.



### Revealing the Barriers of Language Agents in Planning (https://arxiv.org/abs/2410.12409)
Comments:
          Work in Progress

- **What's New**: 이 논문에서는 인공지능의 자율 계획(autonomous planning) 분야에서 현재 언어 에이전트(language agents)가 인간 수준의 계획 능력에 도달하지 못하는 이유를 분석합니다.

- **Technical Details**: 연구에서는 feature attribution study를 적용하여 계획을 저해하는 두 가지 주요 요인을 식별했습니다. 첫 번째는 제약 조건(constraints)의 제한된 역할이고, 두 번째는 질문(question)의 감소하는 영향입니다. 이러한 요인들로 인해 현재 사용되고 있는 전략들이 문제를 완전히 해결하지 못하고 있다는 점도 발견했습니다.

- **Performance Highlights**: 현재 최첨단 추론 모델인 OpenAI o1은 복잡한 실제 계획 기준에서 15.6%의 성과를 달성했으며, 이는 인간 수준의 계획 접근 방식에는 여전히 큰 격차가 있음을 나타냅니다.



### A Fast Convoluted Story: Scaling Probabilistic Inference for Integer Arithmetic (https://arxiv.org/abs/2410.12389)
- **What's New**: 본 논문은 신경 기호 AI(neurosymbolic AI)의 문제를 해결하기 위해 텐서 조작(tensor manipulations)을 활용한 정수 값 확률 변수(integer-valued random variables)에 대한 선형 산술(linear arithmetic)의 새로운 형식을 제안합니다.

- **Technical Details**: 우리는 두 개의 정수 값 확률 변수를 덧셈할 때 로그 도메인(log-domain)에서의 빠른 푸리에 변환(fast Fourier transform) 적응을 통해 수행할 수 있음을 관찰하였습니다. 이를 통해 텐서 연산(tensor operations)을 활용한 미분 가능한 데이터 구조(differentiable data structure)를 얻었습니다.

- **Performance Highlights**: 실험적 검증을 통해, 확률적 선형 정수 산술(probabilistic linear integer arithmetic)을 텐서화(tensorising)하고 빠른 푸리에 변환을 활용함으로써 추론(inference) 및 학습(learning) 시간에서 여러 차원 수치(state of the art)를 향상시킬 수 있음을 보여주었습니다.



### ShapefileGPT: A Multi-Agent Large Language Model Framework for Automated Shapefile Processing (https://arxiv.org/abs/2410.12376)
- **What's New**: ShapefileGPT는 LLM (Large Language Model)에 기반한 혁신적인 프레임워크로, Shapefile 관련 작업의 자동화를 위해 설계되었습니다.

- **Technical Details**: ShapefileGPT는 멀티 에이전트 구조 (multi-agent architecture)를 사용하고, 플래너 에이전트 (planner agent)는 작업 분해 및 감독을 담당하며, 작업자 에이전트 (worker agent)는 실제로 작업을 실행합니다. 이를 위해 Shapefile 처리를 위한 전문 함수 라이브러리를 개발하고, API 문서를 제공하여 작업자 에이전트가 함수를 호출하여 Shapefile을 효율적으로 처리할 수 있도록 했습니다.

- **Performance Highlights**: ShapefileGPT는 벤치마크 데이터셋에 대해 95.24%의 작업 성공률을 달성하며, 전통적인 LLM과 비교하여 복잡한 벡터 데이터 분석 작업을 효과적으로 처리합니다.



### PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking (https://arxiv.org/abs/2410.12375)
- **What's New**: PRefLexOR (Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning)는 선호 최적화(preference optimization)와 강화 학습(Reinforcement Learning) 개념을 결합하여 모델이 반복적인 추론 개선을 통해 스스로 학습할 수 있도록 합니다.

- **Technical Details**: 이 논문은 다단계 추론(multi-step reasoning) 과정에서 모델이 중간 단계를 재검토하고 수정한 후 최종 출력을 생성하는 재귀 학습(recursive learning) 접근 방식을 제안합니다. 모델은 선호 응답(preferred responses)과 비선호 응답(non-preferred responses) 간의 로그 확률(log odds)을 최적화하여 정확한 결정 경로에 정렬하는 것을 배웁니다. 또한, 무작위 텍스트 조각에서 질문을 생성하고 관련 세부 정보를 맥락화하기 위해 동적 지식 그래프(dynamic knowledge graph)를 구축합니다.

- **Performance Highlights**: 3억 개의 파라미터를 가진 소형 언어 모델(small language models)에서 구현되었으며, 작은 모델도 깊이 있는 추론과 반성(reflection)을 통해 스스로를 반복적으로 학습할 수 있음을 보여줍니다. 생물 재료 과학(biological materials science) 분야에서의 다양한 사례 연구를 통해 이 방법을 증명하며, 추론 시간에 반복 샘플링을 통해 응답을 성공적으로 개선하는 다중 에이전트 재귀 자기 개선 추론(multi-agent recursive self-improving inference) 접근 방식을 구축합니다.



### Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistanc (https://arxiv.org/abs/2410.12361)
Comments:
          9 pages, 4 figures

- **What's New**: 이 논문에서는 명시적인 인간 지시 없이도 작업을 예측하고 시작할 수 있는 선제적 에이전트(proactive agents)를 개발하는 문제에 접근합니다.

- **Technical Details**: 실제 인간 활동 데이터를 수집하여 선제적 작업 예측(proactive task predictions)을 생성합니다. 이 예측은 인간 주석자에 의해 수용(accepted) 또는 거부(rejected)로 라벨링됩니다. 라벨링된 데이터는 인간 판단을 시뮬레이션하는 보상 모델(reward model)을 훈련하는 데 사용됩니다. 또한, ProactiveBench라는 6,790개의 다양한 이벤트를 포함하는 데이터셋 통합 파이프라인을 개발하였습니다.

- **Performance Highlights**: 미세 조정된(fine-tuned) 모델은 F1-Score 66.47%로 선제적으로 도움을 제공하는 능력을 평가하며, 모든 오픈 소스 및 클로즈드 소스 모델을 초월하는 성과를 보여주었습니다.



### A Prompt-Based Knowledge Graph Foundation Model for Universal In-Context Reasoning (https://arxiv.org/abs/2410.12288)
Comments:
          Accepted in the 38th Conference on Neural Information Processing Systems (NeurIPS 2024)

- **What's New**: 이번 논문에서는 다양한 지식 그래프(KG)에서의 일반화된 추론 능력을 달성하기 위해, 문맥 내 학습(in-context learning)을 이용한 프롬프트 기반 KG 기초 모델(KG-ICL)을 제안합니다. 이 모델은 다양한 KG와 추론 환경에 걸쳐 지식을 전이하고 일반화할 수 있는 기능을 갖추고 있습니다.

- **Technical Details**: KG-ICL 모델은 쿼리와 관련된 예제 사실을 중심으로 한 프롬프트 그래프(prompt graph)를 도입하여 쿼리 관계를 이해합니다. 이를 통해 새로운 실체와 관계에 대한 일반화 능력을 가진 통합 토크나이저(unified tokenizer)를 제안하고, 두 개의 메시지 패싱 신경망(message passing neural networks)을 통해 프롬프트 인코딩과 KG 추론을 수행합니다.

- **Performance Highlights**: 43개의 다양한 KG에 대한 실험 결과, KG-ICL 모델은 대부분의 데이터셋에서 기존 모델을 초과 성능을 보이며, 뛰어난 일반화 및 보편적 추론 능력을 보여줍니다. 이 모델은 높은 효율성을 갖추고 예제를 활용하는 데 강력한 성능을 발휘합니다.



### OmnixR: Evaluating Omni-modality Language Models on Reasoning across Modalities (https://arxiv.org/abs/2410.12219)
Comments:
          19 pages, 6 figures, 12 tables

- **What's New**: OmnixR는 여러 다중 모달리티(omni-modality)를 처리하는 최신 AI 모델의 성능을 평가하기 위한 새로운 벤치마크입니다. 기존의 평가 방법이 단일 또는 이중 모달리티에 한정되어 있었던 반면, OmnixR는 복잡한 비디오, 오디오, 텍스트 조합을 평가하므로, 모델의 종합적인 이해력을 테스트합니다.

- **Technical Details**: OmnixR 벤치마크는 두 가지 데이터 집합으로 구성됩니다: (1) Omni××R_{synth}: 텍스트 정보를 다양한 모달리티(오디오, 이미지, 비디오)로 변환한 합성 데이터 집합이며, (2) Omni××R_{real}: 전문가들에 의해 수집되고 주석이 달린 실제 데이터를 포함하여, 오미모달리티(omni-modality) 추론력을 평가합니다. Omnify!라는 자동화 도구를 사용하여 데이터를 생성하며, 이는 모델의 다중 모달 이해력과 추론 능력을 평가하는 데 초점을 맞춥니다.

- **Performance Highlights**: 실험 결과, 최신 OLM들은 OmnixR 질문에서 여러 모달리티 정보를 통합하여 정확한 답변을 도출하는 데 어려움을 겪었습니다. 특히, 간단한 촉진 전략(ETA prompting)을 사용하여 성능 개선 가능성을 보여주었지만, 현실적인 환경에서 오미모달 행동 불일치를 완전히 해소하기 위해 추가적인 훈련이 필요하다는 점이 드러났습니다.



### Divide-Verify-Refine: Aligning LLM Responses with Complex Instructions (https://arxiv.org/abs/2410.12207)
Comments:
          Under review

- **What's New**: 최근 연구에서 LLMs(대규모 언어 모델)가 복잡한 지침을 따라가는 데 어려움을 겪고 있다는 사실이 밝혀졌습니다. 특히, 다양한 제약 조건을 가진 지침에 대한 LLM의 적응력을 높이기 위한 방법이 아직 탐구되지 않았습니다.

- **Technical Details**: 본 논문에서는 새로운 Divide-Verify-Refine (DVR) 프레임워크를 제안합니다. 이는 (1) 복잡한 지침을 단일 제약 조건으로 나누고 적절한 도구를 준비하는 단계, (2) 도구를 사용해 응답을 철저히 검증하고 신뢰할 수 있는 피드백을 제공하는 단계, (3) 성공적인 정제를 수집하여 향후 사례에 대한 few-shot 예시로 사용하는 단계로 구성됩니다.

- **Performance Highlights**: 실험 결과, DVR 프레임워크는 LLama3.1-8B 모델의 6개 제약 조건을 가진 지침에서 적응력을 두 배로 향상시켰습니다.



### Parametric Graph Representations in the Era of Foundation Models: A Survey and Position (https://arxiv.org/abs/2410.12126)
Comments:
          Preprint, 15 pages

- **What's New**: 이 연구는 그래프의 정량적 속성을 모델링하기 위한 그래프 법칙(graph laws)의 중요성을 강조하며, 이를 통해 다양한 실세계 적용 분야에 기여할 수 있는 잠재력을 제시합니다.

- **Technical Details**: 그래프 법칙은 그래프의 통계적 속성을 이해하고 기술하는 데 중점을 두며, 저자들은 매크로스코프(macro scope)와 마이크로스코프(micro scope), 정적(static) 및 동적(dynamic) 그래프, 저차 및 고차 연결(low-order and high-order connections) 등 다양한 관점에서 그래프의 법칙을 탐구합니다.

- **Performance Highlights**: 그래프 법칙의 적용은 그래프 생성(graph generation), 링크 예측(link prediction), 자연어 처리(natural language processing)와 같은 여러 실세계 작업에서 성능을 향상시키는 데 기여할 수 있습니다.



### Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming (https://arxiv.org/abs/2410.12112)
Comments:
          50 pages, 25 figures, 7 tables

- **What's New**: 새로운 연구에서는 복잡한 계획 문제를 해결하기 위해 대규모 언어 모델(LLMs)을 활용하는 LLMFP라는 일반 목적의 프레임워크를 제안합니다. 이 프레임워크는 태스크 특정 예제 없이도 최적화 문제로 계획 문제를 공식화하고 해결할 수 있는 가능성을 보여줍니다.

- **Technical Details**: LLMFP는 자연어 도메인 설명과 쿼리, 배경 정보를 입력받아 계획 문제를 해결하는 다섯 단계 프로세스를 갖추고 있습니다: 목표 및 주요 제약 조건 제안, 변수 표현 구축, 최적화 문제로 문제 공식화, 코드 실행 및 플랜 변환, 마지막으로 결과에 대한 평가 및 수정. 이 프레임워크는 SMT(상태 수정 이론)를 사용하여 최적화 문제를 인코딩합니다.

- **Performance Highlights**: LLMFP는 9개의 다양한 계획 문제에 적용되었으며, GPT-4o 및 Claude 3.5 Sonnet의 평균 최적 비율은 각각 83.7% 및 86.8%로, OpenAI o1-preview의 직접 계획 생성법보다 37.6% 및 40.7% 상승한 성과를 내며 탁월한 성능을 입증했습니다.



### A Learning Search Algorithm for the Restricted Longest Common Subsequence Problem (https://arxiv.org/abs/2410.12031)
Comments:
          33 pages, 12 figures

- **What's New**: 본 논문은 Restricted Longest Common Subsequence (RLCS) 문제를 다루고 있으며, 이는 잘 알려진 Longest Common Subsequence (LCS) 문제의 확장 버전입니다. RLCS 문제는 생물정보학에서 DNA, RNA 및 단백질 서열 간의 유사성을 식별하고 중요한 패턴을 발견하는 데 유용한 응용을 가지고 있습니다.

- **Technical Details**: 이 논문은 RLCS 문제를 해결하기 위한 두 가지 새로운 heuristic 접근법을 소개합니다. 첫 번째 접근법은 검색 과정에서 부분 해결책을 평가하기 위해 확률적 모델을 사용하며, 두 번째 접근법은 유전 알고리즘을 사용하여 오프라인에서 학습된 신경망 모델에 기반합니다. 이 연구에서는 학습된 신경망 모델을 beam search 프레임워크와 결합한 하이브리드 방법인 learning beam search를 개발하였습니다.

- **Performance Highlights**: 제안된 방법은 RLCS 문제 해결에 효과적임을 입증하는 포괄적인 실험 평가를 바탕으로 하며, 과학 저널의 초록을 입력 문자열로 사용하고, 자주 발생하는 학술 단어 집합을 제한된 패턴으로 사용하여 현실적인 사례를 생성하는 중요한 기여를 포함합니다.



### A Scalable Communication Protocol for Networks of Large Language Models (https://arxiv.org/abs/2410.11905)
- **What's New**: Agora라는 메타 프로토콜을 소개하며, 이는 기존의 통신 표준을 활용하여 LLM(대형 언어 모델) 기반 에이전트가 복잡한 문제를 효율적으로 해결할 수 있도록 합니다.

- **Technical Details**: Agora에서는 에이전트가 일상적인 통신을 위해 표준화된 루틴을 사용하고, 드물게 발생하는 통신은 자연어를 사용하며, 그 중간에는 LLM이 작성한 루틴을 활용합니다. 이를 통해 Agora는 기존의 에이전트 통신 문제를 피하고 인터페이스와 멤버의 변화를 강인하게 처리하여 이전에 없던 스케일성과 완전한 탈중앙화를 가능하게 합니다.

- **Performance Highlights**: 대규모 Agora 네트워크에서 자율적으로 복잡한 목표를 달성하는 자가 조직화된 프로토콜이 나타나는 것을 관찰하였습니다. 이는 Agora의 규모 확장성과 자가 조직화 행동의 출현을 보여줍니다.



### FLARE: Faithful Logic-Aided Reasoning and Exploration (https://arxiv.org/abs/2410.11900)
- **What's New**: 본 논문에서는 기존의 Chain-of-Thought (CoT) 방법론의 문제점을 해결하기 위해 Faithful Logic-Aided Reasoning and Exploration (FLARE)라는 새로운 접근 방식을 제안합니다. FLARE는 LLM을 사용하여 문제 공간을 탐색하고, 논리 프로그래밍 언어를 이용해 자연어 쿼리를 사실과 술어로 변환하여 코드 실행을 시뮬레이션합니다.

- **Technical Details**: FLARE는 세 가지 모듈로 구성되어 있습니다: 계획 생성을 위한 모듈, Prolog 코드를 생성하는 모듈, 그리고 문제를 해결하기 위한 시뮬레이션 검색 모듈입니다. 이 시스템은 멀티-홉 검색을 통해 자연어 쿼리의 해답을 찾는 과정에서 이유 과정을 정량적으로 평가할 수 있습니다.

- **Performance Highlights**: FLARE는 9개의 다양한 추론 벤치마크 중 7개에서 SOTA (State Of The Art) 결과를 달성하였으며, F-CoT보다 평균 16%, CoT보다 9% 향상된 성능을 보였습니다. 모델의 정확도는 이유 과정의 신뢰성과 강하게 상관관계가 있음을 입증하였습니다.



### Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information (https://arxiv.org/abs/2410.12774)
Comments:
          main paper 12 pages, Appendix 7 pages, 1 figure, 18 tables

- **What's New**: 이 연구에서는 다중 작업 학습(Multi-task Learning, MTL)에서의 작업 관련성을 정의하기 위해 pointwise V-usable 정보(점별 V-사용 가능 정보, PVI)를 기반으로 한 새로운 메트릭을 제안합니다. PVI는 데이터셋이 주어진 모델에 대해 얼마나 많은 사용 가능한 정보를 포함하고 있는지를 추정하는 최근의 기법입니다.

- **Technical Details**: PVI는 모델에 따라 데이터 인스턴스의 난이도를 추정하며, 이를 통해 비슷한 난이도의 작업들을 그룹화하여 MTL에서 성능을 극대화할 수 있다고 가정합니다. 15개의 NLP 데이터셋을 이용한 실험을 통해 MTL 결과를 기존 단일 학습자 모델 및 최신 대형 언어 모델과 비교하였습니다. 또한, PVI 기반 작업 그룹화를 통한 성능 비교를 실시하였습니다.

- **Performance Highlights**: PVI 추정치가 비슷한 작업들을 그룹화함으로써 다중 작업 학습이 성능을 개선하고, 총 파라미터 수를 줄이면서도 다양한 도메인에 걸쳐 일관된 성능을 보였습니다. 이 연구는 PVI 추정값을 이용한 작업 그룹화가 STL 성능을 초과할 수 있음을 입증하였습니다.



### Harmon: Whole-Body Motion Generation of Humanoid Robots from Language Descriptions (https://arxiv.org/abs/2410.12773)
Comments:
          Accepted for oral presentation at 8th Annual Conference on Robot Learning. Project website: this https URL

- **What's New**: 이번 연구에서는 자연어 설명으로부터 휴머노이드 로봇의 전체 신체 동작을 생성하는 방법에 대해 다루고 있습니다. 새로운 접근법인 Harmon을 통해 인간의 동작 데이터와 Vision Language Models (VLMs)의 공감각적 추론 기능을 결합하여 인간과 유사한 동작 양식을 생성하고 있습니다.

- **Technical Details**: 휴머노이드 로봇의 동작 생성을 위해 PhysDiff라는 확산 기반 생성 모델을 사용하여 대규모 인간 동작 데이터로부터 인간의 동작을 생성합니다. 이어서 생성된 동작은 역기구학(Inverse Kinematics)을 활용하여 시뮬레이션된 휴머노이드 로봇으로 리타겟팅됩니다. 동작의 표현력 향상과 자연어 설명과의 정렬을 위해 VLM을 활용하여 손과 머리 동작을 생성하고 수정합니다.

- **Performance Highlights**: Harmon은 86.7%의 테스트 사례에서 사람 평가자들로부터 선호되었으며, 실제 로봇에서 실행되는 다양한 동작을 보여주며 자연스럽고 표현력이 풍부한 휴머노이드 동작을 성공적으로 생성했습니다.



### Vaccinating Federated Learning for Robust Modulation Classification in Distributed Wireless Networks (https://arxiv.org/abs/2410.12772)
- **What's New**: 본 논문에서는 기존의 Federated Learning 기반 Automatic Modulation Classification (AMC) 모델의 한계를 극복하기 위해 FedVaccine이라는 새로운 프레임워크를 제안합니다. 적절한 양의 노이즈를 도입함으로써 다양한 노이즈 수준에서의 일반화 가능성을 높이는 것이 목표입니다.

- **Technical Details**: FedVaccine은 하모닉 노이즈 저항 접근법을 통해 DNN 모델에 대한 최적 노이즈 내성을 식별하고, 훈련 프로세스를 조절하여 과적합(overfitting)을 완화합니다. 또한, 기존의 선형 집합 방법의 한계를 극복하기 위해 구조적 클러스터링(topology)과 로컬 큐 데이터 구조를 사용하는 분할 학습(split-learning) 전략을 employ하여 로컬 모델의 적응적이고 누적적인 업데이트를 가능하게 합니다.

- **Performance Highlights**: 실험 결과, FedVaccine은 IID 및 non-IID 데이터셋에서 우수한 수행 성능을 보이며, 다양한 노이즈 조건에서도 기존 FL 기반 AMC 접근 방식에 비해 뛰어난 성능을 발휘합니다. 이는 FedVaccine이 실제 무선 네트워크 환경에서 AMC 시스템의 신뢰성과 성능을 향상시킬 잠재력을 지니고 있음을 확인시켜줍니다.



### Open Materials 2024 (OMat24) Inorganic Materials Dataset and Models (https://arxiv.org/abs/2410.12771)
Comments:
          19 pages

- **What's New**: Meta FAIR에서 발표한 Open Materials 2024 (OMat24) 대규모 개방형 데이터세트와 함께 여러 가지 사전 훈련된 모델을 출시했습니다. OMat24는 1억 개 이상의 밀도 기능 이론(DFT) 계산을 포함하고 있으며, 구조적 및 조합적 다양성에 중점을 두었습니다.

- **Technical Details**: OMat24 데이터세트는 비평형 원자 구성과 원소 조합을 기반으로 한 DFT 단일 포인트 계산, 구조적 안정화 및 분자 동역학 궤적을 포함하여 약 1억 1800만 개의 구조로 구성되어 있습니다. EquiformerV2 모델은 Matbench Discovery 리더보드에서 최첨단 성능을 달성하며, F1 점수 0.9 이상의 기초 상태 안정성과 20 meV/atom의 정확도로 형성 에너지를 예측할 수 있습니다.

- **Performance Highlights**: OMat24 데이터세트와 모델을 통한 사전 훈련은 MPtraj 및 Alexandria 데이터세트에서의 최적화 성능을 크게 향상시킵니다. 개방형 데이터와 모델의 도입은 연구 커뮤니티가 우리의 노력에 기반하여 AI 지원 물질 과학을 더욱 발전시킬 수 있게 합니다.



### SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And Video Generation (https://arxiv.org/abs/2410.12761)
Comments:
          The first two authors contributed equally; Project page: this https URL

- **What's New**: SAFREE는 최신의 적응형, 훈련 없는 안전한 T2I(텍스트에서 이미지로) 및 T2V(텍스트에서 비디오로) 생성 접근 방식을 제안합니다. 기존의 모델의 가중치를 변경하지 않으면서 유해 콘텐츠를 필터링하는 데 중점을 둡니다.

- **Technical Details**: SAFREE는 텍스트 임베딩 공간에서 유해 개념에 해당하는 하위 공간을 탐지하여 프롬프트 임베딩을 이 하위 공간에서 멀리하는 방식으로 작동합니다. 또한, 동적인 Denoising 단계 조정 및 픽셀 수준에서 유해 개념과 관련된 특징의 영향을 줄이는 적응형 재 주의 메커니즘을 포함합니다.

- **Performance Highlights**: SAFREE는 SOTA(최첨단 기술) 성능을 달성하며, 훈련 없는 기준 모델들에 비해 안전하지 않은 콘텐츠를 억제하는 데 뛰어난 효과를 보이고, 높은 품질의 이미지를 유지하면서도 동시에 다양한 T2I 및 T2V 작업에 유연하게 적용 가능합니다.



### Unitary Multi-Margin BERT for Robust Natural Language Processing (https://arxiv.org/abs/2410.12759)
- **What's New**: 최근 딥 러닝에서 적대적 공격에 대한 발전으로 인해 자연어 처리(NLP) 시스템이 위험에 처해 있습니다. 이 논문은 Bidirectional Encoder Representations from Transformers(BERT)의 견고성을 크게 향상시키는 보편적인 기술인 Unitary Multi-Margin BERT(UniBERT)를 소개합니다.

- **Technical Details**: UniBERT는 cross-entropy loss를 multi-margin loss로 교체하고, weight 매트릭스를 단위 행렬로 제한하여 적대적 공격에 대한 강인성을 강화합니다. 이러한 접근 방식을 통해 다중 클래스를 구분하는 신경 표현을 보다 뚜렷하게 분리합니다. 수치적으로, UniBERT는 공격 후 분류 정확도를 5.3% 개선하여 73.8%에 도달하며, 단일 스칼라 매개변수를 통해 사전 및 사후 정확도 간의 트레이드오프를 조정할 수 있습니다.

- **Performance Highlights**: UniBERT는 기존의 방어 방법들과 비교할 때 여러 작업에서 공격 후 정확도를 유의미하게 향상시킵니다. 특히, 우리의 모델은 적대적 훈련 방식에 대한 의존 없이 설계되었으며, 간단한 구현이 가능합니다.



### Counterfactual Generative Modeling with Variational Causal Inferenc (https://arxiv.org/abs/2410.12730)
- **What's New**: 이 논문은 고차원적 결과(noidual outcomes)하에서 개별의 잠재적 결과를 추정할 수 있는 새로운 변별적 베이지안(causal inference) 프레임워크를 제안합니다. 이를 통해 기존 모델의 한계를 극복하고, 반사실적(supervised) 처리를 보다 효과적으로 수행할 수 있습니다.

- **Technical Details**: 기존의 조건부 변별 오토인코더(conditional variational autoencoder) 프레임워크에서의 신경 적응(neural adaptations) 및 모델 변형에 초점을 맞춘 이전 연구들과 달리, 이 연구는 카운터팩추얼(causal inference) 개념에 적합한 새로운 방식을 제시합니다. 이 프레임워크를 통해 카운터팩추얼 샘플 없이도 엔드 투 엔드(end-to-end) 방식으로 학습하는 과정에서 잠재적 분리(latent disentanglement)를 촉진할 수 있습니다.

- **Performance Highlights**: 실험을 통해, 본 프레임워크가 여러 벤치마크에서 최고의 모델(state-of-the-art models)들과 비교했을 때 카운터팩추얼 생성 모델링에서 우수한 성능을 보임을 입증했습니다.



### Transformer based super-resolution downscaling for regional reanalysis: Full domain vs tiling approaches (https://arxiv.org/abs/2410.12728)
- **What's New**: 이번 연구에서는 Swin Transformer 기반의 새로운 Super-Resolution (SR) 방법이 제안되었으며, 기존의 여러 SR 다운스케일링(Downscaling) 방법과 비교되었습니다. 특히 CERRA 재분석(CERRA reanalysis) 데이터(5.5km 해상도)를 사용하여 기온 예측을 대상으로 했습니다.

- **Technical Details**: 이 연구에서는 두 가지 접근법을 비교했으며, 첫 번째는 전체 영역을 입력으로 사용하는 전통적인 방법이고, 두 번째는 전체 도메인을 타일(tile)로 나누는 확장 가능한 방법입니다. 제안된 Swin2SR 모델은 고해상도 입력 데이터를 처리할 수 있도록 설계된 Swin v2 Transformer 구조를 기반으로 하며, 자기 주의 메커니즘(self-attention mechanism)을 사용하여 장거리 종속성을 캡처합니다. 또한, 입력을 단계적으로 처리하여 전반적인 성능을 유지합니다.

- **Performance Highlights**: 타일 접근법은 공간 전이성(spatial transferability)이 필요하지만, 약간의 성능 저하를 감수하면서도 효율적이고 확장 가능한 솔루션을 제공합니다. 이는 판 유럽 규모의 SR 축소를 가능하게 하며, 실시간 애플리케이션에 유용합니다. 또한 Swin2SR 모델은 에라5(ERA5) 및 CERRA 재분석 데이터를 기반으로 한 기온 다운스케일링에 성공적으로 적용되었습니다.



### HEnRY: A Multi-Agent System Framework for Multi-Domain Contexts (https://arxiv.org/abs/2410.12720)
- **What's New**: 이번 프로젝트 HEnRY는 Intesa Sanpaolo에 Multi-Agent System (MAS)을 도입하는 것을 목표로 합니다. HEnRY라는 이름은 프로젝트의 핵심 원리를 요약하여 계층적 구조(Hierarchical organization)에서 효율적인 자원 관리를 위한 에이전트들의 조직, 자원 및 운영의 효율적인 최적화(Efficient optimization), 환경 자극에 신속하게 반응하는 에이전트의 능력(Reactive ability), 그리고 예상치 못한 상황을 처리할 수 있는 에이전트의 적응성과 유연성(Yielding adaptability)을 포함합니다.

- **Technical Details**: 이 논문에서는 두 가지 주요 연구 경로를 다룹니다. 첫 번째는 시스템 아키텍처(System architecture)에 관한 것이며, 두 번째는 에이전트 간의 협력(Collaboration between agents)에 중점을 둡니다. 이 연구는 Intesa Sanpaolo의 구체적인 구조에 국한되지 않고 MAS에 대한 기존 연구를 활용하여 새로운 솔루션을 제시합니다.

- **Performance Highlights**: Intesa Sanpaolo는 국제 기업 거버넌스 최선의 관행에 부합하는 모델로 조직되어 있으므로, 이 접근법은 유사한 시나리오에서도 유용할 수 있습니다.



### FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression (https://arxiv.org/abs/2410.12707)
- **What's New**: FusionLLM은 지리적으로 분산된 GPUs를 활용하여 대규모 딥 뉴럴 네트워크(DNN)를 훈련하기 위해 디자인된 분산 훈련 시스템입니다. 이 시스템은 원거리 자동 미분(Remote Automatic Differentiation, RAD), 유연한 모델 정의 및 이질적인 소프트웨어 지원, 그리고 부하가 불균형한 하드웨어 문제 해결을 목표로 하고 있습니다.

- **Technical Details**: FusionLLM 시스템은 DNN의 오퍼레이터를 방향성 비순환 그래프(Directed Acyclic Graph, DAG)로 표현합니다. 각 노드는 DNN의 오퍼레이터를 나타내며, 엣지는 오퍼레이터 간 데이터 의존성을 나타냅니다. 시스템은 OP-Fence 스케줄러를 사용하여 유사한 대역폭을 가진 기기들을 클러스터링하고 DAG을 분할하여 처리량을 증가시킵니다. 또한, AdaTopK 압축기를 통해 느린 통신 링크에서 중간 활성화 및 그래디언트를 적응적으로 압축합니다.

- **Performance Highlights**: FusionLLM을 사용하여 ResNet-101과 GPT-2를 훈련한 결과, 48개의 GPU를 사용하여 8 Mbps에서 10 Gbps 네트워크에서 실험한 결과, 기존 방법에 비해 1.45 - 9.39배의 속도 향상을 달성하며 수렴을 보장하였습니다.



### WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines (https://arxiv.org/abs/2410.12705)
- **What's New**: WorldCuisines라는 대규모 벤치마크가 소개되어 VLMs의 다문화적 및 다언어적 이해력을 평가할 수 있는 새로운 기준을 제시합니다. 이 벤치마크는 30개 언어와 방언에서 각각의 텍스트-이미지 쌍을 포함하고 있어 다문화적인 VQA 데이터셋으로는 가장 큰 규모를 자랑합니다.

- **Technical Details**: 이 연구는 VLMs를 평가하기 위해 100만 개 이상의 고품질의 다언어 및 다문화 텍스트-이미지 쌍으로 구성된 WorldCuisines를 개발했습니다. 벤치마크는 2가지 작업을 포함합니다: (1) 요리 이름 예측, (2) 요리가 일반적으로 소비되는 위치 예측. VQA 데이터셋은 30개 언어와 방언으로 구성되어 있으며, 다양한 질문 유형에 대한 평가를 포함합니다.

- **Performance Highlights**: VLMs는 적절한 위치 맥락에서 더 좋은 성능을 보였으나, 적대적인 맥락에서는 어려움을 겪었고, 특정 지역 요리와 언어 예측에서의 어려움이 드러났습니다. 데이터셋과 관련된 주의 깊은 메타데이터와 이미지도 함께 제공되어 향후 연구 지원을 기대합니다.



### Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization (https://arxiv.org/abs/2410.12700)
Comments:
          Accepted by ACM Multimedia 2024. The dataset and code can be found at this https URL

- **What's New**: 이번 연구에서는 인간의 가치와 정렬된 T2I(Text-to-Image) 모델을 위한 경량화된 방법인 LiVO(Lightweight Value Optimization)를 제안합니다. LiVO는 입력 프롬프트와 통합하여 이미지 생성을 제어할 수 있는 플러그 앤 플레이(value encoder) 값을 최적화합니다. 이는 T2I 모델과 인간의 가치 원칙을 효과적으로 연결합니다.

- **Technical Details**: LiVO는 기존 T2I 모델의 매개변수를 업데이트하지 않고도 사용자의 입력에 따라 적합한 가치 원칙을 선택할 수 있게 해줍니다. 이를 통해 생성된 이미지의 의미와 가치를 자연어 지침에 따라 조정할 수 있습니다. 연구팀은 86K 개의 (프롬프트, 정렬 이미지, 위반 이미지, 가치 원칙) 샘플로 이루어진 텍스트-이미지 가치 선호 데이터셋을 자동으로 구축하는 프레임워크를 개발했습니다.

- **Performance Highlights**: LiVO는 최소 20%의 데이터만으로 유해한 콘텐츠를 최대 66%까지 줄일 수 있으며, 여러 강력한 기준선을 초과하는 성능을 보였습니다. 또한, 즉각적인 수렴성을 달성하며 가치 정렬이 향상된 T2I 모델의 개발을 위한 초기 단계로 나아갑니다.



### Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2 (https://arxiv.org/abs/2410.12686)
Comments:
          6 pages, 2 figures, 1 table

- **What's New**: 최근 연구에 따르면, Llama-2와 같은 최신 대형 언어 모델(LLMs)은 의료 이미징 도메인에서 해부학적 랜드마크의 위치를 정확하게 나타낼 수 있는 가능성을 보여주고 있습니다. 이 연구는 이러한 모델들이 의료 이미징 워크플로우의 효율성과 정확성을 높일 수 있는 잠재력을 가지고 있다는 점을 강조합니다.

- **Technical Details**: 연구는 Llama-2 모델의 내부 신경 활성화를 선형적으로 조사하여 해부학적 랜드마크의 위치를 예측하는 방식을 사용했습니다. 각 랜드마크에 대한 명칭과 그에 대응하는 공간 좌표를 포함한 데이터세트를 구성하였으며, ridge regression 모델을 통해 위치 예측의 정확성을 평가했습니다. 또한, 비선형 검사를 위해 다층 퍼셉트론(MLP)을 사용하여 결과를 비교했습니다.

- **Performance Highlights**: Llama-2 모델은 다양한 프롬프트에 대해 해부학적 랜드마크를 선형적으로 robust하게 표현할 수 있음을 보여주었습니다. 모델의 성능은 랜드마크 크기 표현에서도 선형성을 나타내었으며, 이는 의료 이미징 보고서에서의 자동화된 해석에 기여할 것으로 기대됩니다.



### Generative Neural Reparameterization for Differentiable PDE-constrained Optimization (https://arxiv.org/abs/2410.12683)
Comments:
          Accepted to D3S3: Data-driven and Differentiable Simulations, Surrogates, and Solvers - Workshop @ NeurIPS 2024

- **What's New**: 본 논문은 부분 미분 방정식(PDE) 제약 최적화에서 신경망을 사용하여 최적 매개변수의 분포를 학습하는 새로운 방법론을 제안합니다. 이 접근 방식은 여러 로컬 미니마를 처리하여 더 효과적인 최적화를 가능하게 합니다.

- **Technical Details**: 제안된 방법, Generative Neural Reparameterization (GNR)은 기본적으로 랜덤 벡터에서 최적 매개변수 세트로의 매핑을 학습하는 신경망을 이용합니다. 이 방법은 기존의 PDE 제약 최적화와 비교하여 여러 최적 해의 분포를 생성할 수 있는 장점을 제공합니다.

- **Performance Highlights**: GNR 방법을 이용한 레이저 플라즈마 불안정성 문제에서, 다양한 최적 매개변수로 성능이 향상됨을 입증했습니다. 실험 결과 GNR이 단일 최적 해 대신 여러 다양한 미니마를 생성하는 데 성공했습니다.



### Context Matters: Leveraging Contextual Features for Time Series Forecasting (https://arxiv.org/abs/2410.12672)
- **What's New**: 본 연구에서는 시계열 예측 모델에 새로운 요소를 추가하였습니다. ContextFormer라는 방법을 소개하여, 여러 종류의 외부 정보(예: 뉴스 기사, 트윗 등)를 기존 모델에 통합할 수 있게 하였습니다.

- **Technical Details**: ContextFormer는 다중 모드(모달리티)의 맥락 정보를 기존의 사전 훈련된 예측 모델에 효과적으로 통합하는 방법입니다. 이 방법은 범주형(categorical), 연속형(continuous), 시간 변동형(time-varying), 텍스트 정보까지 다양한 정보를 정제하여 예측 성능을 크게 향상시킵니다.

- **Performance Highlights**: ContextFormer는 에너지, 교통, 환경, 금융 분야의 다양한 실제 데이터셋에서 기존의 SOTA(최신 기술) 예측 모델보다 최대 30% 더 나은 성능을 보여줍니다.



### Hamiltonian bridge: A physics-driven generative framework for targeted pattern contro (https://arxiv.org/abs/2410.12665)
Comments:
          29 pages, 8 figures

- **What's New**: 본 연구에서는 비평형 시스템에서 패턴 형성을 조절하기 위한 새로운 프레임워크인 'Hamiltonian bridge'를 제시합니다. 이 프레임워크는 여러 스케일에서 패턴을 조절할 수 있는 방법을 제공합니다.

- **Technical Details**: 연구는 비평형 시스템에 대한 일반적인 동역학 법칙과 확률적 최적 제어 방법을 결합합니다. 이 과정에서, 상관 관리를 위한 Feynman-Kac 기반의 부가 경로 적분(formulation)을 활용하여 상호 작용하는 입자를 제어하는 방식으로 패턴 형성 PDE들에 효율적으로 적용됩니다. 또한, 최적 제어 문제는 초기와 목표 패턴 사이의 보간(interpolation)으로 간주되어, 동역학 법칙을 준수하는 다양한 패턴 상태 간의 보간을 가능하게 합니다.

- **Performance Highlights**: 수치 실험을 통해 상관 파라미터가 존재하는 분리 상태 제어, 유체 방울의 자가 조립, 결합 반응-확산 방정식 및 시공간 조직 분화에 대한 현상학적 모델에서 패턴 제어의 유용성을 입증하였습니다. 이러한 실험은 패턴의 기하학적 성질을 이해하는 데 있어 물리적 원리에 따라 패턴의 수송 경로 및 보간의 성격을 조절하는 방법을 설명합니다.



### Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models (https://arxiv.org/abs/2410.12662)
- **What's New**: 본 연구에서는 Large Vision-Language Models (LVLMs)의 비주얼 입력에 대한 안전 메커니즘의 전이 부족 문제를 다룹니다. 현재의 방법론이 비주얼 모달리티에 대해 안전 메커니즘을 효과적으로 전이하지 못함을 발견하고, Text-Guided vision-language Alignment (TGA)라는 새로운 방법을 제안합니다.

- **Technical Details**: TGA는 입력된 비전과 관련된 텍스트를 검색하여 LLMs의 hidden states 공간으로 비전을 투영하는 데 도움을 줍니다. 이로써 이미지의 hidden states와 텍스트의 hidden states 간의 정렬을 이루게 됩니다. 연구 결과, TGA는 기존 LLMs의 안전 메커니즘을 비전으로 성공적으로 전이할 수 있음을 보여주었습니다.

- **Performance Highlights**: TGA는 안전한 결과를 도출하며, InstructBLip, LLaVA-1.5 및 Qwen-VL-Chat과 같은 기존의 최첨단 LVLM들과 비교할 때 다양한 비전 작업에서 일반 성능을 유지합니다.



### Evaluating Morphological Compositional Generalization in Large Language Models (https://arxiv.org/abs/2410.12656)
Comments:
          33 pages

- **What's New**: 본 연구는 대형 언어 모델(LLMs)의 형태론적 일반화 능력을 구성적(compositional) 관점에서 체계적으로 조사합니다. 형태소(morpheme)를 구성적 원시 단위로 정의하고, 이를 기반으로 한 새로운 유전자 및 판별(task) 과제를 설계하였습니다.

- **Technical Details**: 우리는 지도 학습된 멀티링궐 모델들(GPT-4, Gemini-1.5 등)을 평가하였으며, 터키어와 핀란드어와 같은 교착어(agglutinative languages)를 대상으로 했습니다. 모델은 새로운 단어의 어근에 적용했을 때 형태론적 연결(compositionality) 일반화가 부족하며, 형태론적 복잡성이 증가할수록 성능이 급격히 감소하는 경향을 보였습니다.

- **Performance Highlights**: 모델은 개별적인 형태론적 조합을 식별하는 데 있어 최소한의 성과를 보였지만, 그 성능은 시스템적이지 않아 인간과 비교했을 때 상당한 정확도 차이를 보였습니다. 인간은 복잡한 형태론적 구조에서도 일관된 성능을 유지하는 반면, 모델의 성능은 뚜렷한 감소를 보였습니다.



### Constrained Posterior Sampling: Time Series Generation with Hard Constraints (https://arxiv.org/abs/2410.12652)
- **What's New**: 이번 연구에서는 제약 조건이 있는 시계열(time series) 샘플 생성을 위한 Constrained Posterior Sampling (CPS) 방법을 제안합니다.

- **Technical Details**: CPS는 diffusion 기반 샘플링 알고리즘으로, 각 denoising 업데이트 후에 posterior mean 추정치를 제약 집합(constraint set)으로 투영하는 방식을 사용합니다. 이 방법은 약 100개의 제약 조건을 처리할 수 있도록 확장 가능하며, 추가적인 학습이 필요하지 않습니다.

- **Performance Highlights**: CPS는 실제 주식, 교통, 대기 질 데이터 세트에서 샘플 품질(sample quality)과 실제 시계열과의 유사성(similarity)에서 각각 약 10% 및 42% 우수한 성능을 보였습니다.



### Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans (https://arxiv.org/abs/2410.12641)
- **What's New**: 본 연구에서는 어깨 CT 스캔을 처리하기 위한 혁신적인 딥러닝 프레임워크를 도입합니다. 이 프레임워크는 근위 상완골과 견갑골의 의미적 분할(semantic segmentation), 뼈 표면의 3D 재구성, 글레노흐umeral (GH) 관절 영역 식별 및 세 가지 일반적인 골관절염 관련 병리(staging)인 골극 형성(osteophyte formation), GH 공간 축소(glenohumeral joint space reduction), 그리고 상완 견갑 정렬(humeroscapular alignment)을 포함합니다.

- **Technical Details**: 이 파이프라인은 두 개의 연속적인 CNN 아키텍처로 구성됩니다. 첫 번째는 세그멘테이션을 위한 3D CEL-UNet, 두 번째는 세 가지 분류를 위한 3D Arthro-Net입니다. 571개의 CT 스캔의 레트로스펙티브 데이터셋을 사용하여 성능을 평가했습니다. 3D 재구성에 대한 평균 제곱근 오차(root mean squared error) 및 하우스도르프 거리(Hausdorff distance)의 중앙값은 상완골에 대해 각각 0.22mm 및 1.48mm, 견갑골은 0.24mm 및 1.48mm로, 기존 아키텍처를 초과하는 성능을 보였습니다.

- **Performance Highlights**: 세 가지 카테고리(OS, JS, HSA)에 대해 분류 정확도는 약 90%에 도달하였으며, 추론 파이프라인의 계산 시간은 15초 미만으로, 정형외과 영상의학적 실습과의 효율성과 호환성을 보여줍니다. 이 결과는 인공지능 도구의 의료 변환을 위한 유망한 발전을 나타내며, 고품질의 뼈 표면을 제공하고 외과의사가 환자의 관절 조건에 따라 가장 적합한 외과적 접근 방식을 선택하는 데 도움을 줍니다.



### Exploring Model Kinship for Merging Large Language Models (https://arxiv.org/abs/2410.12613)
Comments:
          Ongoing work

- **What's New**: 이 연구는 모델 병합(model merging)을 위한 새로운 평가 기준인 모델 친척성(model kinship)을 도입합니다. 모델 친척성은 LLM(대형 언어 모델) 간의 유사성과 관련성을 측정하여, 반복적인 병합 과정에서 성능 개선을 돕는 정보를 제공합니다.

- **Technical Details**: 모델 병합은 여러 개별 모델을 통합하여 다중 작업 목표를 달성하는 전략입니다. 본 논문에서는 모델 친척성을 기준으로 한 Top-k Greedy Merging 전략을 제안하며, 이는 모델 진화(model evolution)에서의 최적화 문제와 지역 최적점(local optima traps)을 피할 수 있도록 도와줍니다.

- **Performance Highlights**: 모델 친척성을 사용한 새로운 병합 전략은 벤치마크 데이터셋에서 더 나은 성능을 달성하며, 평균 성능 향상과 강한 상관관계가 있음을 보여줍니다. 이 연구는 모델 병합의 효율성과 효과성을 높이기 위한 실용적인 전략을 제시합니다.



### Towards Graph Foundation Models: The Perspective of Zero-shot Reasoning on Knowledge Graphs (https://arxiv.org/abs/2410.12609)
Comments:
          17 Pages, 5 figures

- **What's New**: 이 논문은 지식 그래프(knowledge graph, KG) 추론의 관점에서 그래프 기반 모델(graph foundation models)을 탐구하며, 최근의 인공지능(a기아 일반화)과 KG의 성공적인 통합에 주목합니다.

- **Technical Details**: 이 논문에서는 SCORE라는 통합된 그래프 추론 프레임워크를 소개합니다. SCORE의 핵심은 구조적 및 의미적 불변성을 포착하기 위해 설계된 의미 조건 메시지 전달(semantic conditional message passing) 기술입니다. SCORE는 38개의 다양한 그래프 데이터 세트를 통해 통합적 추론을 수행하며, 노드 레벨(node-level), 링크 레벨(link-level), 그래프 레벨(graph-level) 태스크를 아우릅니다.

- **Performance Highlights**: 실험 결과, SCORE는 이전의 기초 모델(baseline)과 감독 학습(supervised model)보다 상당한 성능 개선을 보여줌으로써 우리의 접근 방법의 효과와 적응성을 강조합니다.



### Low-Rank Adversarial PGD Attack (https://arxiv.org/abs/2410.12607)
- **What's New**: 이 연구에서는 Projected Gradient Descent (PGD) 공격이 원 이미지의 단일값 스펙트럼의 일부에만 주로 영향을 미친다는 것을 관찰하였고, 이를 바탕으로 효율적으로 저랭크 공격을 계산하는 저랭크 PGD 변형을 제안하였습니다.

- **Technical Details**: 제안된 LoRa-PGD는 공격 크기를 제어할 수 있도록 설계되어 있으며, 이미지의 단일값 스펙트럼의 작은 비율을 변경함으로써 메모리 사용량을 크게 줄이고, 전통적인 전체 랭크 PGD에 비해 성능이 동등하거나 더 나은 결과를 보여줍니다. 이 방법은 adversarial training에서 효과적으로 사용될 수 있습니다.

- **Performance Highlights**: 저랭크 PGD는 전통적인 PGD 공격보다 메모리 사용량이 현저히 적으면서도 유사한 또는 더 나은 성능을 발휘하며, 특히 핵 규범(nuclear norm) 기준으로 측정했을 때 더 높은 효율성을 보였습니다.



### Self-Supervised Learning of Disentangled Representations for Multivariate Time-Series (https://arxiv.org/abs/2410.12606)
Comments:
          NeurIPS 2024 Workshop: Self-Supervised Learning - Theory and Practice

- **What's New**: TimeDRL은 고차원 다변량 시계열 데이터의 표현 학습을 위한 최신 프레임워크로, 이중 수준의 불연속 임베딩을 도입하여 기존 방법론의 한계를 극복합니다.

- **Technical Details**: TimeDRL은 [CLS] 토큰 전략을 통해 시간 수준(timestamp-level) 임베딩과 인스턴스 수준(instance-level) 임베딩을 분리하여 학습합니다. 또한, 시간 예측 및 인스턴스 대비(contrastive) 작업을 통해 각 임베딩 수준에 적합한 학습을 진행하며, 외부 데이터 증강을 피하여 유도 바이어스를 최소화합니다.

- **Performance Highlights**: 실험 결과, TimeDRL은 11개의 실제 시계열 예측 및 분류 벤치마크에서 최신 방법들을 능가하는 성능을 보여주었으며, 제한된 레이블 데이터가 있는 반지도 학습 설정에서도 그 효용성을 입증했습니다.



### Expand and Compress: Exploring Tuning Principles for Continual Spatio-Temporal Graph Forecasting (https://arxiv.org/abs/2410.12593)
- **What's New**: 이 논문은 새로운 스페이시오-템포럴(spatio-temporal) 데이터 스트리밍 환경에서의 지속적인 예측을 위한 프롬프트 튜닝 기반 방법(EAC)을 제안합니다. 이 방법은 경량 조정 매개변수를 통해 모델의 재훈련 문제와 장기적 기억 상실(catastrophic forgetting)을 해결합니다.

- **Technical Details**: EAC 방법은 기본 스페이시오-템포럴 그래프 신경망(base STGNN)과 연속 프롬프트 풀을 통합하여, 메모리에 저장된 학습 가능한 프롬프트를 활용합니다. 두 가지 조정 원리인 expand(확장) 및 compress(압축)를 통해 모델의 효과성과 효율성을 균형 있게 유지합니다. 이를 통해 모델은 연속적인 데이터 스트림에서 점진적으로 학습합니다.

- **Performance Highlights**: EAC는 다양한 실제 데이터셋에서 여러 가지 면에서 기존 최첨단 방법들에 비해 우수한 성능을 보였습니다. 지속적인 학습을 통한 성능 향상, 다양한 STGNN 아키텍처에 대한 일관된 성능 발휘, 훈련 속도 증가, 적은 수의 매개변수 조정으로도 효율적인 학습이 가능하다는 특징을 가지고 있습니다.



### Rethinking Visual Counterfactual Explanations Through Region Constrain (https://arxiv.org/abs/2410.12591)
Comments:
          Preprint

- **What's New**: 이번 논문에서는 Visual Counterfactual Explanations (VCEs)의 한계를 극복하기 위해 지역 제약을 설정하는 방법인 지역 제약 VCEs (RVCEs)를 제안합니다. 기존 방법들이 이미지의 여러 부분을 혼합하여 수정할 때 발생하는 문제를 해결하고자 하며, RVCE는 한정된 지역만 수정하여 모델의 예측에 영향을 미칩니다.

- **Technical Details**: RVCEs는 결정론적 조건부 인페인팅 문제를 해결하는 것으로, 결정자에서 유래한 신호를 기반으로 합니다. 이를 위해 Regional-Constrained Counterfactual Schrödinger Bridges (RCSB)라는 새로운 알고리즘을 도입하며, 이는 이미지 생성 과정에서 효율적이고, 사실적이며, 원본에 가깝게 RVCEs를 합성하는 데 도움을 줍니다.

- **Performance Highlights**: RCSB 방법은 ImageNet 데이터셋에서 기존 방식에 비해 FID에서 최대 4배, sFID에서 3배, COUT에서 2배 더 우수한 성능을 보여줍니다. 이 연구는 RVCEs가 모델의 의사결정을 명확히 이해할 수 있도록 돕고, 사용자가 수동으로 수정 지역을 정의하며 상호작용할 수 있는 기능을 제공합니다.



### STRUX: An LLM for Decision-Making with Structured Explanations (https://arxiv.org/abs/2410.12583)
Comments:
          10 pages, 7 figures, submitted to NAACL 2025

- **What's New**: 이 논문에서는 새로운 LLM (Large Language Model) 의사결정 프레임워크인 STRUX를 소개합니다. STRUX는 구조화된 설명을 제공하여 LLM의 의사결정을 개선합니다.

- **Technical Details**: STRUX는 긴 정보를 간결한 핵심 사실의 표로 정제한 후, 자기 반성 단계(self-reflection steps)를 통해 어떤 사실이 중요한지를 결정합니다. 이 사실을 특정 결정과 관련하여 유리한(favorable) 것과 불리한(adverse) 것으로 분류합니다. 마지막으로, LLM을 미세 조정(fine-tune)하여 이러한 핵심 사실을 식별하고 우선순위를 매깁니다.

- **Performance Highlights**: STRUX는 수익 전화 회의(transcripts) 데이터를 기반으로 한 주식 투자 의사 결정 예측 과제에서 강력한 기준선(baselines) 대비 뛰어난 성능을 보였습니다. 이는 의사결정의 투명성을 높여주며, 사용자들이 다양한 요인의 영향을 이해할 수 있도록 합니다.



### On the Utility of Domain Modeling Assistance with Large Language Models (https://arxiv.org/abs/2410.12577)
- **What's New**: 본 논문은 대형 언어 모델(LLMs)과 few-shot prompt learning을 활용하여 도메인 모델링을 지원하는 새로운 접근 방식을 평가하는 연구를 제시합니다.

- **Technical Details**: 상대적으로 적은 양의 도메인 특정 데이터셋으로 AI 기반 완성 모델을 훈련하는 대신, 이 접근법은 다양한 모델링 활동을 지원하는데 필요한 유용한 권장 사항을 제공합니다. MAGDA라는 사용자 친화적인 도구를 개발하여 사용자 연구를 수행하고 실제 도메인 모델링에 대한 적용 가능성을 평가합니다.

- **Performance Highlights**: 이 연구는 MAGDA의 사용성 및 효율성에 대한 귀중한 통찰력을 제공하며, 모델-주도 엔지니어링(MDE)의 설계 프로세스에서의 도전 과제를 극복하는 데 중요한 기여를 할 것으로 기대합니다.



### Robust RL with LLM-Driven Data Synthesis and Policy Adaptation for Autonomous Driving (https://arxiv.org/abs/2410.12568)
- **What's New**: RAPID 프레임워크는 대형 언어 모델(LLM)을 활용하여 자율 주행 시스템에 특화된 RL (Reinforcement Learning) 에이전트를 훈련시키는 새로운 접근법을 제공합니다. 이를 통해 더 빠르고 효율적인 실시간 추론을 가능하게 합니다.

- **Technical Details**: RAPID는 다음 세 가지 핵심 설계를 포함합니다: 1) LLM 에이전트로부터 수집된 오프라인 데이터를 활용하여 전문가의 지식을 RL 정책으로 증류(distill)합니다; 2) RL에서의 강력한 증류를 도입하여 LLM 기반의 교수로부터 성능과 강인성을 물려받습니다; 3) 정책 어댑터(policy adapter)를 통해 공동 결정 디코딩(joint decision decoding)을 위한 믹스 오브 정책(mix-of-policy) 접근 방식을 사용합니다.

- **Performance Highlights**: RAPID는 온라인 환경 상호작용을 통해 LLM 지식의 망각을 줄이고, 다양한 작업에 대한 적응성을 유지하면서도 효율적이고 강력한 RL 정책으로 LLM 지식을 통합하는 능력을 입증했습니다.



### Development of Image Collection Method Using YOLO and Siamese Network (https://arxiv.org/abs/2410.12561)
Comments:
          15 pages, 13 figures, 2 tables

- **What's New**: 본 논문에서는 웹 크롤링(web crawling) 방식의 데이터 수집에서 발생하는 비의도적 데이터 문제를 해결하기 위해 YOLOv10 객체 인식 모델을 사용하고, SIAMese 네트워크를 통해 재분류(image reclassification)를 수행함으로써 성능을 향상시켰음을 보여줍니다.

- **Technical Details**: YOLOv10 모델을 사용하여 웹 크롤링으로 수집된 데이터 중 불필요한 데이터를 필터링하고, SIAMese 네트워크의 거리 출력을 추가적으로 활용하여 이미지 재분류를 진행했습니다. 특히, 사용자들은 거리 임계값(threshold)을 지정하여 데이터 부족(data deficiency)과 잡음 저항성(noise-robustness) 간의 균형을 조절할 수 있습니다.

- **Performance Highlights**: 평균 f1 점수는 YOLO+MobileNet에서 0.678에서 YOLO+SiameseNet으로 0.772로 증가했습니다. 비컷(cropped) 이미지의 사용에 효과적으로 자원을 적게 사용하면서도 성능을 높일 수 있음을 보였으며, non-crop+Siamese(MobileNetV3-Small)에서 80.94가 컷 전처리(crop preprocessing)+Siamese(MobileNetV3-Small)에서 82.31로 상승했습니다.



### A Claim Decomposition Benchmark for Long-form Answer Verification (https://arxiv.org/abs/2410.12558)
Comments:
          Accepted by CCIR 2024

- **What's New**: 이번 연구에서는 LLM(대규모 언어 모델)의 응답에서 사실성이 결여된 'hallucination' 문제를 해결하기 위해, 각 주장에 대한 출처를 명확히 하는 새로운 기준을 제시합니다. 특히, 각 응답에서 주장이나 진술을 식별하는 것의 중요성을 강조하며, 이를 위한 새로운 Claim Decomposition Benchmark를 도입합니다.

- **Technical Details**: 우리는 CACDD(Chinese Atomic Claim Decomposition Dataset)를 소개합니다. 이 데이터셋은 500개의 인간 주석 질문-응답 쌍으로 구성되어 있으며, 총 4956개의 원자적(claim) 주장을 포함합니다. 데이터를 고품질로 유지하기 위해 전문가의 추가 주석이 포함되었습니다. 실험에서는 zero-shot, few-shot 및 fine-tuned LLM를 사용하여 성능 비교를 진행하였습니다.

- **Performance Highlights**: 실험 결과, 주장 분해(claim decomposition)는 매우 도전적인 작업으로, 추가적인 탐색이 필요하다는 것을 보여주었습니다. 모든 코드와 데이터는 공개적으로 사용 가능합니다.



### LLM-based Translation Inference with Iterative Bilingual Understanding (https://arxiv.org/abs/2410.12543)
Comments:
          Work in progress

- **What's New**: 본 연구에서는 Iterative Bilingual Understanding Translation (IBUT)이라는 새로운 방법을 제안합니다. 이 방법은 LLM의 교차 언어 능력과 번역 작업의 이중 특성을 기반으로 하여 번역 품질을 개선하는 데 초점을 맞추고 있습니다.

- **Technical Details**: IBUT 방법은 Understanding Generation, Alignment Judgment, Iterative Refinement, Understanding-Based Translation의 네 가지 부분으로 구성됩니다. IBUT는 먼저 LLM을 활용하여 소스 및 타겟 언어에 대한 맥락 이해를 생성하고, 그 후 이 이해를 기반으로 다양한 언어 쌍에서 번역을 수행합니다.

- **Performance Highlights**: 실험 결과, IBUT는 여러 강력한 비교 방법들보다 뛰어난 성능을 보였으며, 특히 뉴스, 상식, 문화 번역 벤치마크와 같은 다양한 도메인에 일반화되는 성능이 입증되었습니다. 평균적으로 +1.3, +4.2, +2.3의 COMET 점수 향상을 보였습니다.



### Characterizing Behavioral Differences and Adaptations of Automated Vehicles and Human Drivers at Unsignalized Intersections: Insights from Waymo and Lyft Open Datasets (https://arxiv.org/abs/2410.12538)
Comments:
          This work has been submitted to Transportation Research Record for potential publication

- **What's New**: 자율주행차(AV)와 인간 운전 차량(HV) 간의 상호작용 분석을 통해 비신호 교차로에서의 행동 차이를 조사한 연구입니다.

- **Technical Details**: 이 연구는 Waymo와 Lyft의 두 개의 포괄적인 AV 데이터셋을 활용하여, 병합 및 교차 충돌(conflict)을 식별하고 안전 및 효율성 지표인 '충돌까지의 시간(TTC)', '후방 침입 시간(PET)', '최대 필요 감속(MRD)', '시간 이점(TA)', 그리고 속도 및 가속 프로파일을 분석했습니다.

- **Performance Highlights**: AV는 더 큰 안전 마진을 유지하지만, 보수적인 행동으로 인해 인간 운전자에게 예기치 않은 상황을 초래할 수 있습니다. 인간 운전자는 AV와의 상호작용에서 더 일관된 행동을 보였으며, Waymo와 Lyft 차량 간에 뚜렷한 차이를 관찰하여 제조사별 AV 행동을 고려하는 것이 중요하다는 점을 강조했습니다.



### Is Complex Query Answering Really Complex? (https://arxiv.org/abs/2410.12537)
- **What's New**: 이 논문에서는 지식 그래프(knowledge graphs)에서 복잡한 질의 응답(complex query answering, CQA)이 새로운 도전 과제로 떠오르고 있다는 점을 강조합니다. 현재 사용되는 CQA 벤치마크가 실제로는 복잡하지 않으며, 이러한 벤치마크가 연구의 진행 상황에 대한 인식을 왜곡하고 있다는 주장을 합니다.

- **Technical Details**: 논문에서는 기존 벤치마크에서 대다수의 질의(특정 질의 유형의 경우 최대 98%)가 더 단순한 문제로 축소 가능하다는 것을 발견했습니다. 예를 들어, 링크 예측(link prediction) 문제에서는 예측해야 할 링크가 하나만 필요합니다. 그러므로 우리는 다중 홉(multiple hops)을 통한 추론을 요구하는 새로운 베치마크를 제안합니다.

- **Performance Highlights**: 새로운 벤치마크를 통한 체계적인 실험 조사 결과, 현재의 CQA 방법들이 여전히 많은 개선이 필요하다는 것을 보여주고 있습니다. 이는 현재의 최고 수준(state-of-the-art) CQA 모델들이 더 복잡한 질의에서 성능이 급격히 저하된다는 것을 의미합니다.



### Spectrum Sharing using Deep Reinforcement Learning in Vehicular Networks (https://arxiv.org/abs/2410.12521)
- **What's New**: 이 논문에서는 차량 네트워크에서의 스펙트럼 할당 문제를 해결하기 위해 딥 Q 네트워크 (Deep Q Network, DQN) 모델을 제안합니다. 이는 기존의 전통적인 방법으로는 해결하기 어려운 동적 차량 환경에서의 도전 과제를 다루고자 합니다.

- **Technical Details**: DQN 모델은 최적의 전략을 시간에 따라 학습하고 의사 결정을 내리는 능력을 활용합니다. 이 논문은 또한 심층 강화 학습 (Deep Reinforcement Learning) 방법을 사용하여 차량 네트워크 내에서 스펙트럼을 공유하는 경우의 성과를 분석합니다. 이 모델은 V2V (Vehicle-to-Vehicle) 통신에서 성공적인 결과를 보여주며, RL(강화 학습) 모델의 누적 보상(Cumulative Reward)이 훈련이 진행됨에 따라 극대화됩니다.

- **Performance Highlights**: DQN 모델이 스펙트럼 공유 효율성을 향상시키는 효과를 입증한 결과를 보여줍니다. 특히, SARL(단일 에이전트 강화 학습) 및 MARL(다중 에이전트 강화 학습) 모델이 차량 간 통신의 성공률을 향상시키고 있음이 강조되었습니다.



### QueensCAMP: an RGB-D dataset for robust Visual SLAM (https://arxiv.org/abs/2410.12520)
Comments:
          6 pages

- **What's New**: 이번 논문은 VSLAM의 강건성을 평가하기 위해 설계된 새로운 RGB-D 데이터셋을 소개합니다. 이 데이터셋은 동적 객체, 모션 블러(motion blur), 다양한 조명 조건을 포함한 실제 실내 장면으로 구성되어 있으며, 렌즈 오염(lens dirt), 응습(condensation), 과소 노출(underexposure), 과다 노출(overexposure)과 같은 카메라 고장도 시뮬레이션합니다.

- **Technical Details**: 이 데이터셋은 Vicon 모션 캡처 시스템을 사용하여 수집되었으며, 30Hz의 정확한 6DoF 위치 측정을 제공합니다. RGB 이미지는 1920x1080 해상도, 깊이 이미지는 640x480 해상도로 수집되어 있습니다. 1616개 시퀀스에서 총 28523 이미지를 캡처했으며, 고장 유도에 대한 추가 시퀀스도 포함되어 있습니다. 고장은 시뮬레이션을 통해 생성되며, 공개된 오픈 소스 스크립트를 통해 연구 커뮤니티가 커스터마이즈할 수 있도록 제공됩니다.

- **Performance Highlights**: 실험 결과, 전통적인 VSLAM 알고리즘인 ORB-SLAM2와 딥러닝 기반 VO 알고리즘인 TartanVO가 이러한 도전적인 조건에서 성능 저하를 겪음을 보여줍니다. 이는 생성된 데이터셋과 카메라 고장 도구들이 더 강건한 VSLAM 시스템 개발에 유용한 자원이 됨을 시사합니다.



### DH-VTON: Deep Text-Driven Virtual Try-On via Hybrid Attention Learning (https://arxiv.org/abs/2410.12501)
Comments:
          5 pages, 6 figures, ICASSP2025

- **What's New**: DH-VTON이라는 새로운 가상 착용(Virtual Try-ON) 모델을 제안합니다. 이 모델은 하이브리드 주의 학습 전략(hybrid attention learning strategy)과 깊은 의류 의미 보존 모듈(deep garment semantic preservation module)을 특징으로 합니다.

- **Technical Details**: 해당 모델은 InternViT-6B를 사용하여 깊이 있는 의류의 세부 특징을 학습하고, Garment-Feature ControlNet Plus (GFC+) 모듈을 통해 의류의 다양한 특성을 VTON 모델의 여러 층에 통합합니다. 이로 인해 다중 스케일 기능 보존(multi-scale features preservation) 효과를 달성할 수 있습니다.

- **Performance Highlights**: 다양한 대표 데이터셋에 대한 실험에서 DH-VTON은 기존의 diffusion 기반 및 GAN 기반 접근 방식보다 뛰어난 성능을 보여주며, 의류의 세부 사항을 잘 보존하고 사실적인 인간 이미지를 생성하는 데 경쟁력을 갖추고 있습니다.



### Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspectiv (https://arxiv.org/abs/2410.12490)
Comments:
          Accepted at NeurIPS 2024

- **What's New**: 최근 Latent Diffusion Models (LDMs)와 Mask Image Models (MIMs)와 같은 latent 기반 이미지 생성 모델이 이미지 생성 작업에서 뛰어난 성과를 거두었습니다. 그러나 autoregressive 모델이 LDMs와 MIMs에 비해 이미지 생성에서 상당히 뒤처져 있다는 흥미로운 관찰이 있었습니다. 이 발견은 NLP 분야와의 뚜렷한 대조를 이룹니다.

- **Technical Details**: 저자들은 이미지 생성 모델링에서 latent space의 안정성을 강조하며, 이를 위해 간단하지만 효과적인 이산 이미지 토크나이저(Tokenizer)를 제안하였습니다. 이 토크나이저(DiGIT)를 사용한 이미지 autoregressive 모델링은 이미지 이해 및 생성 과정에서 이점을 보여주었으며, 이는 기본적으로 GPT 모델에 대해 간단한 원칙입니다.

- **Performance Highlights**: 처음으로, GPT 스타일의 autoregressive 모델이 LDMs를 초월하는 성능을 보여주었으며, 모델 크기를 늘림에 따라 GPT와 유사한 상당한 개선을 또한 보여주었습니다. 이 결과는 최적화된 latent space와 이산 토큰화의 통합이 이미지 생성 모델의 능력을 향상할 수 있는 잠재력을 강조합니다.



### Stable Object Placement Planning From Contact Point Robustness (https://arxiv.org/abs/2410.12483)
Comments:
          Submitted to IEEE Transactions on Robotics. Contains 14 pages, 11 figures, and 3 tables

- **What's New**: 본 논문에서는 복잡한 장면 내에서 로봇 조작기가 물체를 안정적으로 배치하도록 안내하는 플래너(planner)를 소개합니다. 기존의 물체 배치 접근 방식을 역전시켜, 플래너가 먼저 접촉 지점(contact points)을 선택하고 그 후 선택된 지점을 유도하는 배치 자세(placement pose)를 결정합니다.

- **Technical Details**: 우리의 알고리즘은 안정성을 고려한 물체 배치 계획을 가능하게 하며, 물체의 형태, 볼록성(convexity), 또는 질량 밀도 동질성에 대한 제약을 두지 않으면서 복잡한 수학적 계산(combinatorial computational complexity)을 피합니다. 제안된 안정성 휴리스틱(stability heuristic)은 플래너가 같은 알고리즘에서 이 휴리스틱을 사용하지 않을 때보다 약 20배 더 빠른 해결책을 찾도록 합니다.

- **Performance Highlights**: 우리의 플래너는 기존의 샘플링 방식(sample-and-evaluate) 접근법을 사용하는 최첨단 방법보다 8배 더 빠르며, 다른 다섯 개의 벤치마크 알고리즘에 비해 안정적인 배치를 찾는 데 더 성공적입니다. 본 연구는 기본 원칙(first principles)에서 파생되었으며, 실제 로봇 실험 10회를 통해 검증되었습니다.



### SAC-GLAM: Improving Online RL for LLM agents with Soft Actor-Critic and Hindsight Relabeling (https://arxiv.org/abs/2410.12481)
- **What's New**: 최근 몇 년간 대규모 언어 모델(LLMs)이 생성 모델로뿐만 아니라 텍스트 순차적 의사결정 과제를 해결하는 에이전트로서의 역할도 발전하였습니다. 본 연구는 LLM 에이전트가 온라인 강화 학습(Reinforcement Learning, RL)을 통해 더 효과적인 전략을 발견하고 학습할 수 있는 방법을 제시합니다.

- **Technical Details**: 이 논문에서는 Soft Actor-Critic과 hindsight relabeling을 LLM 에이전트에 적응시키는 방법을 제안합니다. 기존 연구가 주로 on-policy 알고리즘에 의존했던 반면, 본 방법은 experience replay 및 hindsight relabeling과 같은 다양한 탐색(exploration) 및 착취(exploitation) 방법을 사용할 수 있는 범위를 크게 확장합니다.

- **Performance Highlights**: 제안된 방법은 자율적으로 동기부여된 목표를 샘플링하고 추구할 수 있는 LLM 에이전트를 향한 길을 열어줍니다. 뿐만 아니라, 고전적인 다목적 RL 환경에서도 on-policy 방법보다 더 뛰어난 성능을 보입니다.



### KcMF: A Knowledge-compliant Framework for Schema and Entity Matching with Fine-tuning-free LLMs (https://arxiv.org/abs/2410.12480)
- **What's New**: 이 논문은 Knowledge-Compliant Matching Framework (KcMF)를 제시하여 대규모 언어 모델(LLM)의 데이터 매칭(Task) 관련 신뢰성 문제를 해결하고자 한다. KcMF는 도메인별 세부 튜닝 없이 사용할 수 있으며, pseudo-code 기반의 작업 분해 전략을 사용하여 LLM의 추론 과정을 안내한다.

- **Technical Details**: KcMF는 두 가지 메커니즘인 Dataset as Knowledge (DaK)와 Example as Knowledge (EaK)를 사용하여 비구조화된 도메인 지식이 부족할 때 도메인 지식 세트를 구축한다. 또한, 결과 앙상블 전략인 Inconsistency-tolerant Generation Ensembling (IntGE)을 도입하여 여러 지식 출처를 활용하고 잘못 형식화된 출력을 억제한다.

- **Performance Highlights**: KcMF는 MIMIC 및 Synthea와 같은 다양한 벤치마크에서 평가되었으며, 이전의 비LLM 상태에서 가장 뛰어난 방법들보다 평균 F1 점수 22.9% 향상을 보이며, SOTA LLM과도 효과적으로 경쟁한다. KcMF는 다양한 LLM에서 잘 일반화된다는 점도 주목할 만하다.



### Unifying Economic and Language Models for Enhanced Sentiment Analysis of the Oil Mark (https://arxiv.org/abs/2410.12473)
- **What's New**: 원유 시장에 특화된 CrudeBERT라는 새로운 Language Model이 도입되었습니다. 이 모델은 기존의 전통적인 예측 방법의 한계를 극복하기 위해 개발되었습니다.

- **Technical Details**: CrudeBERT는 자연어 처리(Natural Language Processing) 분야에서 발전된 Generative Pre-trained Transformer(GPT) 모델을 기반으로 하며, 원유 시장에 특화된 용어를 효과적으로 처리하도록 파인 튜닝(Fine-tuning)되었습니다.

- **Performance Highlights**: CrudeBERT의 감정 점수(Sentiment Scores)는 WTI 선물 곡선(WTI Futures Curve)과 더 밀접하게 일치하며, 가격 예측(Price Predictions) 성능을 크게 향상시켰습니다.



### Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios (https://arxiv.org/abs/2410.12468)
Comments:
          10 pages of main content and 2 pages of references

- **What's New**: 이번 연구는 AI 기반의 소프트웨어 엔지니어링에서 에이전트(agents)에 의해 생성된 패치(patch)에 대한 첫 번째 종합 평가를 제공하며, 실제 GitHub 이슈에 대한 영향력을 분석합니다.

- **Technical Details**: 연구에서는 우수한 순위를 기록한 10개의 에이전트로부터 생성된 4,892개의 패치를 분석하고, SWE-Bench Verified의 500개의 실질적인 GitHub 이슈에 초점을 맞췄습니다. 이 과정에서 코드 품질에 미치는 영향을 중점적으로 살펴보았습니다.

- **Performance Highlights**: 연구 결과, 어떤 단일 에이전트도 모든 문제를 해결하지 못했으며, 170개의 이슈가 해결되지 않은 것으로 나타났습니다. 다수의 에이전트는 код 신뢰성과 보안을 유지하였고 새로운 버그 또는 취약점을 피했습니다. 그러나 일부 에이전트는 코드 복잡성을 증가시켰고, 많은 수의 에이전트가 코드 중복을 줄여 코드의 품질을 개선하는 경향을 보였습니다. 최종적으로, 에이전트는 단순한 코드베이스에서 더 나은 성능을 보였으며, 복잡한 작업을 작은 하위 작업으로 나누는 것이 효율성을 향상시킬 수 있음을 시사합니다.



### Sharpness-Aware Black-Box Optimization (https://arxiv.org/abs/2410.12457)
Comments:
          27 pages, 5 figures

- **What's New**: 이번 논문에서는 기존 블랙박스 최적화(Black-box optimization) 방법의 한계를 극복하기 위해 Sharpness-Aware Black-box Optimization (SABO) 알고리즘을 제안합니다. 이 알고리즘은 모델의 일반화(Generalization) 성능을 개선하기 위해 샤프니스 인식(Sharpness-aware) 최소화 전략을 적용합니다.

- **Technical Details**: SABO 알고리즘은 먼저 목표 함수(Objective function)를 가우시안 분포(Gaussian distribution)에 대한 기대값으로 재매개변수화(Reparameterization)합니다. 이후, 현재 솔루션 주변의 작은 이웃에서 최대 목표 값(Maximum objective value)의 근사 확률적 경량(Stochastic gradient)을 통해 매개변수화된 분포를 반복적으로 업데이트합니다.

- **Performance Highlights**: 광범위한 블랙박스 프롬프트 파인튜닝(Black-box prompt fine-tuning) 작업에 대한 실험 결과, 제안된 SABO 방법이 모델의 일반화 성능을 개선하는 데 효과적임을 입증했습니다.



### Open Ko-LLM Leaderboard2: Bridging Foundational and Practical Evaluation for Korean LLMs (https://arxiv.org/abs/2410.12445)
- **What's New**: Open Ko-LLM Leaderboard2가 기존의 Open Ko-LLM Leaderboard의 한계를 보완하여 새롭게 등장했습니다. 이 새로운 리더보드는 더 관련성 높은 실제 과업을 기반으로 한 벤치마크를 제공합니다.

- **Technical Details**: 기존의 벤치마크는 주로 영어 버전의 번역본으로 구성되어 있었으나, Open Ko-LLM Leaderboard2는 네 가지 새로운 한국어 네이티브 벤치마크를 도입하여 한국어의 고유한 특성을 보다 잘 반영합니다.

- **Performance Highlights**: 이 개선된 리더보드는 한국어 Large Language Model (LLM)에 대한 보다 의미 있는 평가를 제공하여 모델들의 질적 영향력을 높이는 데 기여하고자 합니다.



### Reconstruction of Differentially Private Text Sanitization via Large Language Models (https://arxiv.org/abs/2410.12443)
- **What's New**: 이 논문에서는 differential privacy (DP) 기준으로 LLMs (대규모 언어 모델)가 제시된 DP-sanitized prompts로부터 원래의 개인 정보를 재구성할 수 있음을 발견했습니다. 특히, 두 가지 공격 방식(black-box 및 white-box)을 제안하고 LLMs가 DP-sanitized 텍스트와 해당 개인 훈련 데이터의 연결 가능성을 보여주었습니다.

- **Technical Details**: 두 가지 공격 방식은 black-box instruction-based attacks와 white-box fine-tuning-based attacks입니다. black-box 공격에서는 사용자가 API를 통해 모델의 응답을 유도하고, white-box 공격에서는 모델 파라미터에 대한 접근을 통해 재구성 작업을 수행합니다. 실험은 LLaMA-2, ChatGPT-4, Claude-3.5 등 최신 LLMs를 사용하여 진행되었습니다.

- **Performance Highlights**: 실험 결과, black-box 공격을 통해 WikiMIA 데이터셋에서 LLaMA-2의 경우 72.18%, LLaMA-3의 경우 82.39%, ChatGPT-4o는 91.2%, Claude-3.5는 94.01%의 재구성 성공률을 기록했습니다. 이는 LLMs의 접근 방식과 훈련 데이터 노출이 재구성과 복원력에 영향을 미치는 신뢰할 수 있는 결과임을 시사합니다.



### Conformity in Large Language Models (https://arxiv.org/abs/2410.12428)
Comments:
          16 pages (8 pages main body), 14 figures

- **What's New**: 이 연구는 최신 LLMs(대형 언어 모델)에서의 conformity effect(순응 효과)를 분석하고, 모델들이 다수 의견에 얼마나 수용적인지를 탐구합니다.

- **Technical Details**: 심리 실험을 LLM에 적용하여, 원래 선택에 관계없이 모든 LLM이 다양한 지식 영역에서 다수에 대해 다양한 수준의 순응을 보이는 사실을 입증했습니다. 또한, 모델이 예측에 대한 불확실성이 높을수록 순응 가능성이 증가한다는 점을 발견했습니다. 훈련 패러다임과 입력 특성 등 순응에 영향을 미치는 요소를 분석하여, instruction-tuned 모델은 순응에 덜 영향을 받는다고 밝혀냈습니다.

- **Performance Highlights**: 정확한 응답에도 불구하고 LLM들이 다수의 의견에 따르는 경향이 있으며, 더 자연스러운 다수 톤이 순응을 강화하는 경향이 있습니다. 연구에서는 Devil's Advocate와 Question Distillation 두 가지 개입 방법을 제안하여, LLM의 순응을 완화하기 위한 통찰을 제공합니다.



### Privacy-Preserving Synthetically Augmented Knowledge Graphs with Semantic Utility (https://arxiv.org/abs/2410.12418)
Comments:
          32 pages, 5 figures

- **What's New**: 본 논문에서는 Knowledge Graphs(KGs)의 공유를 가능하게 하는 새로운 프레임워크를 제안하고 있으며, 개인 정보를 보호하는 동시에 비즈니스 작업을 위한 내재된 지식을 유지하는 방법에 대해 설명합니다.

- **Technical Details**: 제안된 접근 방식은 구조적 익명화를 통해 입력 KGs의 증강으로 개인 정보를 보호하는 합성 KG(synthetic KG)를 생성합니다. 또한, 파생된 지식(derived knowledge)을 고려한 새로운 개인 정보 보호 측정 기준과 비즈니스 의미를 보존하기 위한 유틸리티 메트릭을 도입하고, 두 가지 새로운 익명화 알고리즘을 제안합니다.

- **Performance Highlights**: 광범위한 실험 평가 결과, 본 접근 방식은 기존 KGs 전용으로 고안되지 않은 방법에 비해 엔티티의 개인 정보 보호에서 최대 70%의 향상을 달성하는 효과를 확인했습니다.



### Enhancing Speech Emotion Recognition through Segmental Average Pooling of Self-Supervised Learning Features (https://arxiv.org/abs/2410.12416)
- **What's New**: 본 논문은 Speech Emotion Recognition (SER)에서 기존의 Global Average Pooling (GAP) 방식을 개선하기 위해 Segmental Average Pooling (SAP) 방식을 도입하였습니다. 이 방법은 음성 세그먼트에만 집중하고 비음성 세그먼트를 무시하여 SER 성능을 향상시킵니다.

- **Technical Details**: Self-supervised learning (SSL) 기법을 사용하여 대량의 레이블이 없는 오디오 데이터로부터 의미 있는 표현을 학습합니다. SAP는 특히 유용한 음성 정보를 캡처하여 비음성 정보를 배제함으로써 GAP보다 더 나은 성능을 제공합니다.

- **Performance Highlights**: IEMOCAP 데이터셋에서 최신 기술 수준(state-of-the-art) 결과를 달성하였으며, 한국어 데이터셋 KEMDy19에서도 비가중치 및 가중치 정확도 모두에서 우수한 성능을 보였습니다.



### HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks (https://arxiv.org/abs/2410.12381)
Comments:
          homepage this https URL

- **What's New**: 본 논문에서는 LLMs(대형 언어 모델)의 시각적 이해 및 추론 능력을 평가하기 위해 특별히 설계된 새로운 벤치마크인 HumanEval-V를 소개합니다. 이는 기존의 코딩 작업을 기반으로 하여, 고도로 세심하게 제작된 108개의 Python 코딩 과제를 포함합니다.

- **Technical Details**: HumanEval-V는 CodeForces 및 Stack Overflow와 같은 플랫폼에서 유래된 문제들을 바탕으로 각 과제를 수정하여, 문제의 맥락과 알고리즘 패턴을 변화시켰습니다. 각 과제는 제공된 시각적 컨텍스트와 특정 Python 함수 서명을 기반으로 해결되어야 하며, 모델이 생성한 솔루션의 철저하고 신뢰할 수 있는 평가를 보장하기 위해 정교하게 제작된 테스트 케이스가 부여됩니다.

- **Performance Highlights**: 19개의 최첨단 LMM들을 HumanEval-V를 사용해 평가한 결과, GPT-4o와 같은 독점 모델은 13%의 pass@1과 36.4%의 pass@10만을 달성하는 등 상당한 도전 과제가 드러났습니다. 70B 파라미터를 가진 오픈 웨이트 모델은 pass@1 기준으로 4% 미만의 점수를 기록했습니다. 이러한 결과는 현재 LMM의 시각적 추론 및 코딩 능력의 한계를 강조하며, 향후 연구의 주요 영역을 제시합니다.



### Towards Neural Scaling Laws for Time Series Foundation Models (https://arxiv.org/abs/2410.12360)
- **What's New**: 이 논문은 time series foundation models (TSFMs)의 크기 및 계산 자원에 따른 스케일링 법칙(scaling laws)을 ID (in-distribution) 및 OOD (out-of-distribution) 데이터에서 분석합니다. 이전 연구들은 주로 ID 데이터에 초점을 맞추었으나, 본 연구는 OOD 상황에서의 TSFM의 성능과 모델 아키텍처의 영향을 평가합니다.

- **Technical Details**: 연구에서는 encoder-only 및 decoder-only Transformer 아키텍처를 사용하여, 세 가지 기본 훈련 요소(모델 크기, 계산 예산, 데이터셋 크기)의 변화를 조사하고, 그에 따른 성능을 ID 및 OOD 테스트 세트에서 측정하였습니다. 특히, log-likelihood loss가 OOD와 ID 모두에서 유사한 스케일링 행동을 보이는 것을 발견했습니다.

- **Performance Highlights**: encoder-only Transformer는 decoder-only Transformer에 비해 더 나은 확장성을 보였으며, 두 가지 첨단 TSFM 아키텍처(Moirai와 Chronos)에서의 성능 비교를 통해 ID 성능은 개선되나 OOD 확장성이 저하되는 것으로 나타났습니다. 이를 바탕으로 TSFM 설계와 확장에 대한 실용적인 지침을 제공합니다.



### GECTurk WEB: An Explainable Online Platform for Turkish Grammatical Error Detection and Correction (https://arxiv.org/abs/2410.12350)
- **What's New**: GECTurk WEB은 터키어의 문법 오류를 감지하고 수정할 수 있는 새로운 웹 기반 시스템으로, 기존의 도구들이 주로 맞춤법 오류에 집중했던 것과는 달리, 문법 오류에 중점을 두고 개발되었습니다.

- **Technical Details**: 이 시스템은 쉬운 접근성을 제공하며, 복잡한 문법 규칙을 가진 터키어의 일반적인 오류를 감지합니다. 여기에는 диacritics의 잘못된 사용, 복합어 및 외래어, 대명사, 경구와 같은 오류가 포함됩니다. 오프라인 및 온라인 도구로 제공되며 사용 효율성을 88.3으로 평가받았습니다.

- **Performance Highlights**: GECTurk WEB은 사용자가 문법 규칙을 학습하고 기억하는 데 도움을 주며, 참가자의 80%가 제시된 설명을 통해 문법 규칙을 이해하는 데 효과적이었다고 응답했습니다.



### TAS: Distilling Arbitrary Teacher and Student via a Hybrid Assistan (https://arxiv.org/abs/2410.12342)
Comments:
          18 pages, 6 figures, and 12 tables

- **What's New**: 이번 연구는 전통적인 Teacher-Student 아키텍처에 의존하지 않고, Cross-Architecture Knowledge Distillation (CAKD) 접근 방식을 통해 동종 및 이종 모델 간의 지식 전이를 유연하게 수행하는 방법을 제안합니다.

- **Technical Details**: 이 연구는 heterogeneous teacher와 student 간의 특징 전이를 원활하게 하기 위한 보조 모델(assistant model)을 introduce하며, convolution과 attention 모듈을 결합하여 서로 다른 아키텍처의 이점들을 통합합니다. 또한 InfoNCE loss를 통해 특징의 spatial alignment를 개선하여 성능을 향상시킵니다.

- **Performance Highlights**: 제안된 CAKD 방법은 CNN, ViT, MLP 모델의 다양한 조합에서 평가되었으며, CIFAR-100에서 최대 11.47% 향상된 성능과 ImageNet-1K에서 3.67%의 성능 향상을 달성하여, state-of-the-art 성능을 기록했습니다.



### A linguistic analysis of undesirable outcomes in the era of generative AI (https://arxiv.org/abs/2410.12341)
- **What's New**: 이 연구는 생성 AI 모델의 중장기 영향을 분석하며, 기계 생성 정보의 신뢰성을 탐구합니다. 특히, 기존 연구에서 소홀히 다루어진 언어적 측면을 집중적으로 분석하기 위해 LLama2의 대화형 버전을 기반으로 포괄적인 시뮬레이션 프레임워크를 제시합니다.

- **Technical Details**: 모델의 성능 저하는 'self-consuming loop'에 의해 일어납니다. 이 연구에서는 텍스트의 다양성을 측정하기 위해 엔트로피(Entropy), TTR(지수적 정확도)와 같은 언어적 척도와 POSTags 빈도를 사용합니다. 또한, n-그램(N-gram) 분석 및 의미망(Semantic Networks)을 통해 생성된 콘텐츠를 평가합니다.

- **Performance Highlights**: 연구 결과, LLama2 모델은 생성 과정에서 텍스트의 어휘적 풍부함이 감소하고 다양성이 줄어들며, 모델의 성능 저하는 콘텐츠의 질 저하와 동시에 언어적 패턴 왜곡으로 이어져 있다고 합니다. 이는 초기 입력 텍스트의 선택과 관리가 모델 붕괴 문제 해결에 매우 중요함을 강조합니다.



### Understanding the Role of LLMs in Multimodal Evaluation Benchmarks (https://arxiv.org/abs/2410.12329)
- **What's New**: 본 논문은 Multimodal Large Language Models (MLLMs)의 평가에서 LLM 백본(LLM backbone)의 역할을 심도있게 조사하여, 현재의 벤치마크가 실제로 멀티모달 추론(multimodal reasoning)을 평가하는 정도와 LLM의 사전 지식(prior knowledge)이 성능에 미치는 영향을 규명합니다.

- **Technical Details**: 우리는 LLM 백본과 멀티모달 통합(multimodal integration)의 기여도를 분리하기 위한 수정된 평가 프로토콜(modified evaluation protocol)과 LLM이 멀티모달 질문에 필요한 지식을 갖추고 있는지를 진단하는 자동 지식 식별 기술(automatic knowledge identification technique)을 소개합니다. 연구는 네 가지 다양한 MLLM 벤치마크와 여덟 가지 최첨단 MLLMs를 포함합니다.

- **Performance Highlights**: 핵심 발견은 일부 벤치마크가 시각적 입력 없이도 높은 성능(high performance)을 허용하며, LLM 백본의 부족한 세계 지식이 오류율의 최대 50%를 차지할 수 있다는 것입니다. 이는 언어 능력에 대한 심한 의존도를 보여줍니다. 지식 부족 문제를 해결하기 위해 우리는 지식 증강 파이프라인(knowledge augmentation pipeline)을 제안하며, 이는 특정 데이터셋에서 최대 60%의 성능 향상을 이루어 약 4배 성능 증가를 가져옵니다.



### Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up (https://arxiv.org/abs/2410.12323)
- **What's New**: 이번 논문에서는 Reversal of Thought (RoT)라는 새로운 프레임워크를 제안하여 대형 언어 모델(LLM)의 논리적 추론 능력을 향상시킵니다. RoT는 메타 인지 메커니즘을 통합하여 LLM이 사람의 피드백에 기반하여 cognitive preference에 맞게 태스크별 프롬프트를 생성할 수 있도록 지원합니다.

- **Technical Details**: RoT는 Preference-Guided Reverse Reasoning 전략을 활용하여, pseudocode 계획을 위한 논리 기호를 통합하고, 쌍대 선호 자기 평가를 통해 특정 태스크를 위한 프롬프트를 생성합니다. 또한, Cognitive Preference Manager를 통해 LLM의 지식 경계를 평가하고, 알려진 태스크에 대한 솔루션 논리를 집계하며, 알려지지 않은 태스크에 대한 스타일 템플릿을 사용하여 논리적 추론 능력을 확장합니다.

- **Performance Highlights**: 여러 태스크에서의 실험 결과, RoT는 기존 방법들보다 논리적 추론의 정확성과 효율성 모두에서 우수한 성능을 보였습니다. 이는 RoT가 LLM의 논리적 유연성과 정확성을 동시에 개선하는 데 기여함을 나타냅니다.



### UTF:Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification (https://arxiv.org/abs/2410.12318)
- **What's New**: 본 논문에서는 대형 언어 모델(LLM)의 소유권 검증과 인증을 위해 새로운 지문 인식 방법인 UTF를 소개합니다. 이 방법은 기존의 전통적인 방법에 비해 효율적이며 저렴한 계산 비용으로 지문 인식을 수행합니다.

- **Technical Details**: UTF는 'under-trained tokens'를 활용하여 모델을 지문화합니다. Under-trained tokens는 모델 훈련 과정에서 충분히 학습되지 않은 토큰들로, 이들을 이용해 특정 입력-출력 쌍을 모델에 내장하도록 감독하에 미세 조정(supervised fine-tuning)을 수행합니다. 이 과정을 통해 LLM은 정해진 입력에 대해 예측된 출력을 생성할 수 있게 됩니다.

- **Performance Highlights**: UTF 방법은 모델 성능에 미치는 영향이 적으며, 기존의 지문 인식 방법들에 비해 더 효과적이고 튼튼하게 작동하며, 모델 소유권 식별을 위한 화이트 박스 액세스(white-box access)를 요구하지 않습니다.



### FaceChain-FACT: Face Adapter with Decoupled Training for Identity-preserved Personalization (https://arxiv.org/abs/2410.12312)
Comments:
          12 pages, 8 figures

- **What's New**: 본 논문은 인물 식별 기능의 분리와 발전된 이미지 생성 방법을 제안한 Face Adapter with deCoupled Training (FACT) 프레임워크를 제시합니다. 이를 통해 텍스트-이미지 모델에서 인물의 정체성을 보존하면서도 정확도와 다양성을 높입니다.

- **Technical Details**: FACT는 transformer 기반의 얼굴 인식 모델을 통해 세분화된 정체성 기능을 활용하였으며, Gated Self-Attention (GSA) 모듈을 U-Net에 삽입해 얼굴 특징에 개별적으로 적응하도록 만들었습니다. 이를 통해 얼굴 영역에서의 변화를 제어하고, FAce Adapting Increment Regularization (FAIR) 기법을 통해 면밀한 조정을 압박합니다.

- **Performance Highlights**: 실험 결과, FACT는 기존의 adapter 기반 개인화 방법에 비해 아이덴티티 유사도, 텍스트 따른 생성 능력, 얼굴의 통제력 및 다양성에서 향상된 성능을 보였습니다. 또한, FACT는 LORA나 ControlNet 같은 기존의 세분화 모델과의 통합에서도 생성 성능을 저하시키지 않습니다.



### Open Domain Question Answering with Conflicting Contexts (https://arxiv.org/abs/2410.12311)
- **What's New**: 이 논문은 웹에서 검색된 정보가 상충하는 경우에 대해 다룬 첫 번째 연구 중 하나로, 25%의 명확한 질문이 상충하는 정보에 이끌릴 수 있음을 보여줍니다. 이 연구는 Question Answering with Conflicting Contexts (QACC)라는 데이터셋을 수집하고, 이를 기반으로 대형 언어 모델(LLMs)의 한계를 분석합니다.

- **Technical Details**: 연구팀은 Google Search API를 사용하여 명확한 질문에 대한 결과를 수집하고, Amazon Mechanical Turk를 통해 인간 주석자들이 상충하는 대답의 존재 여부를 판단하도록 했습니다. 이를 통해 명확한 질문의 약 25%가 상충하는 정보를 생성함을 발견했습니다. 또한, 이들은 GPT-3.5, Claude-3, Phi-3와 같은 세 가지 LLM을 평가하였고, 이러한 상충이 성능 저하를 초래한다는 것을 보여주었습니다.

- **Performance Highlights**: 주석자의 자연어 설명으로 LLM을 파인튜닝한 결과, LLM의 성능이 향상되었습니다. 특히, QACC 데이터셋과 DQ-Open 데이터셋에서 상충하는 정보를 처리하는 능력이 개선되었습니다. 이는 LLM이 상충하는 맥락을 이해하고 올바른 답변을 내리는 데 도움이 되는 중요한 통찰을 제시합니다.



### Two Birds with One Stone: Multi-Task Semantic Communications Systems over Relay Chann (https://arxiv.org/abs/2410.12302)
Comments:
          submitted to IEEE WCNC

- **What's New**: 본 논문에서는 하나의 송신으로 이미지 재구성 및 분류를 동시에 수행할 수 있는 새로운 다중 작업, 다중 링크 중계 의미 통신 (MTML-RSC) 방안을 제안합니다.

- **Technical Details**: MTML-RSC 방안에서는 원천 노드가 의미 통신을 사용하여 신호를 방송하고, 중계 노드가 해당 신호를 목적지로 전달합니다. 두 작업과 두 링크 (원천-중계 및 원천-목적지) 간의 결합 관계를 분석하고, 중계 노드에게 관련 클래스의 의미만 선택적으로 전달하도록 설계된 의미 중심의 전달 방법을 제안합니다.

- **Performance Highlights**: MTML-RSC 방안은 이미지 재구성에서 피크 신호 대 잡음비 (PSNR) $1.73$dB의 향상을 이루었으며, 분류 정확도를 $64.89\%$에서 $70.31\%$로 증가시키는 성능 향상을 보여줍니다.



### Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs (https://arxiv.org/abs/2410.12298)
- **What's New**: Pyramid-Driven Alignment (PDA)라는 새로운 프레임워크를 제안하여 LLM(대형 언어 모델)과 KG(지식 그래프)의 통합을 최적화하고, 이를 통해 더 정확한 질문-답변 작업을 수행할 수 있도록 한다.

- **Technical Details**: PDA는 Pyramid Principle 분석을 사용하여 계층적 피라미드 구조를 구축하며, 이것이 입력 질문을 반영하도록 설계된다. 또한, 재귀적 메커니즘을 통해 KG의 추론 능력을 활용하여 질문-답변 작업을 위한 더 정확한 지식 검색을 가능하게 한다.

- **Performance Highlights**: PDA는 2WikiMultihopQA, Mintaka, WebQuestionsSP와 같은 세 가지 데이터셋에서 실험을 진행했으며, 각 데이터셋에서 SOTA(최첨단 성능) 결과를 달성하여 최대 26.70% 및 26.78%의 성능 향상을 이뤄냈다.



### Conjunction Subspaces Test for Conformal and Selective Classification (https://arxiv.org/abs/2410.12297)
Comments:
          36 pages, 9 figures

- **What's New**: 이 논문에서는 다양한 랜덤 서브스페이스(random subspaces)에서의 유의성 검정(significance testing) 결과를 통합하여 분류 결정의 불확실성을 정량화하는 새로운 분류기(classifier)를 제안합니다. 이 분류기는 일관된 p-value를 생성하여 개인화된 예측(conformal prediction) 및 선택적 분류(selective classification)에 활용될 수 있습니다.

- **Technical Details**: 제안된 분류기는 타깃 클래스(target class)와의 연관성이 없다는 귀무 가설(null hypothesis)을 바탕으로 합니다. 이는 가설의 접합(conjunction) 검정 문제로 분류 문제를 구성할 수 있음을 의미합니다. 이론적으로는 일반화 오류 경계(generalization error bound)에 대한 분석이 이루어졌으며, 실질 데이터 세트(real data sets)에서의 경험적 연구(empirical studies)도 포함되어 있습니다.

- **Performance Highlights**: 제안된 분류기의 성능은 다양한 데이터 세트를 통해 효과성 효과를 입증하며, thresholding을 통해 선택적 거부(reject) 및 세분화(refine) 옵션을 간편하게 적용할 수 있습니다.



### Consistency Calibration: Improving Uncertainty Calibration via Consistency among Perturbed Neighbors (https://arxiv.org/abs/2410.12295)
- **What's New**: 이번 논문에서는 딥러닝 응용 분야에서 모델의 보정을 위한 새로운 개념인 Consistency (일관성)을 도입합니다. 이는 대규모 언어 모델(LLM)에서 영감을 얻었으며, 기존의 신뢰 기반 관점에 비해 다양한 장점을 강조합니다.

- **Technical Details**: Consistency Calibration (CC)라는 새로운 사후 보정 방법을 제안하고, 이는 변화된 입력에 대한 모델의 일관성을 기반으로 신뢰도를 조정합니다. CC는 추가적인 데이터 샘플이나 레이블 정보를 요구하지 않으며, 소스 데이터에서 직접 입력 변화를 생성합니다. 또한, logit 수준에서의 변화를 수행함으로써 계산 효율성을 크게 개선합니다.

- **Performance Highlights**: CIFAR-10, CIFAR-100 및 ImageNet과 같은 표준 데이터셋뿐만 아니라 ImageNet-LT와 같은 긴 꼬리 데이터셋에서도 다양한 사후 및 학습 시간 보정 방법과 비교하여 최첨단 성능을 입증했습니다.



### Beyond Oversmoothing: Evaluating DDPM and MSE for Scalable Speech Synthesis in ASR (https://arxiv.org/abs/2410.12279)
Comments:
          Under review at ICASSP 2025

- **What's New**: 이 논문에서는 TTS(Text-to-Speech) 시스템에서 의도적으로 생성된 합성 음성이 인간 수준의 자연스러움에 근접했지만, ASR(Automatic Speech Recognition) 시스템의 성능은 여전히 실 음성에 비해 낮다는 패러독스를 탐구합니다.

- **Technical Details**: Denoising Diffusion Probabilistic Models (DDPM)와 Mean Squared Error (MSE) 기반 모델을 비교하여 ASR 모델 교육에 관한 성능을 분석합니다. DDPM은 더 다양한 발화자와 데이터를 활용하는 데에 더 효과적이며, 모드 붕괴(mode collapse)를 줄이고 전체 확률 분포를 모델링하는 데 중요한 역할을 합니다. 또한, TTS 훈련 데이터 크기에 따른 ASR 성능 변화를 단계적으로 분석합니다.

- **Performance Highlights**: 예를 들어, DDPM을 사용하여 합성음성과 실음성 간의 단어 오류율(Word Error Rate, WER) 비율을 1.46으로 기록했으나, 실제 음성과 합성 음성 간의 성능 차이는 여전히 남아있음을 발견했습니다. 이러한 결과는 DDPM이 MSE보다 더 유리한 스케일링 곡선을 보이고, 두 모델 모두 감소하는 수익의 한계를 겪고 있다는 것을 보여줍니다.



### Controlled Automatic Task-Specific Synthetic Data Generation for Hallucination Detection (https://arxiv.org/abs/2410.12278)
- **What's New**: 이 논문에서는 환각 감지를 위한 비트리비얼(task-specific) 합성 데이터세트를 자동으로 생성하는 새로운 접근 방식을 제안합니다. 이 방법은 두 단계의 생성-선택 파이프라인을 특징으로 하며, 환각 패턴 지침(hallucination pattern guidance) 및 언어 스타일 정렬(language style alignment)을 활용하여 데이터 품질을 향상시킵니다.

- **Technical Details**: 제안된 방법은 자동화된 생성-선택 파이프라인을 기반으로 하며, 환각 패턴 가이드를 통해 특정 작업에 적합한 환각 샘플을 생성하고, 언어 스타일 정렬을 통해 합성 데이터의 스타일을 벤치마크 텍스트와 일치시킵니다. 이 방법은 세 가지 대화 벤치마크에서 실험을 통해 검증되었으며, F1 점수 0.938을 달성하여 기존의 인컨텍스트러닝(ICL) 기반 감지기를 32.5%의 큰 차이로 초과했습니다.

- **Performance Highlights**: 제안된 환각 감지기는 생성된 합성 데이터세트를 통해 훈련된 결과, 상기된 세 가지 차원에서 뛰어난 일반화 능력을 보여주었습니다. 또한, 생성된 합성 환각이 실제 비환각 샘플에 더 유사함을 입증하였으며, 이는 우리 접근 방식의 강력한 일반화 능력을 확인하였습니다.



### Kallini et al. (2024) do not compare impossible languages with constituency-based ones (https://arxiv.org/abs/2410.12271)
- **What's New**: 이 논문은 언어 모델이 인간 언어의 경계를 이해하는 데 어떻게 사용될 수 있는지를 탐구하며, GPT-2가 다양한 인공 언어(synthetic languages)를 학습할 때의 비대칭성(asymmetry)을 분석합니다.

- **Technical Details**: Kallini et al. (2024)의 연구에 따르면, LLMs(large language models)는 인간 언어를 학습하는 데 성공할 뿐만 아니라 불가능한 언어 언어(impossible languages)를 학습하는 데 어려움을 겪는지 테스트하였습니다. 이 비대칭성은 LLM의 귀납적 편향(inductive biases)이 인간 언어에 대한 가능성과 일치한다는 지지를 제공합니다.

- **Performance Highlights**: 논문에서 제시된 주요 비판은 Kallini et al.의 비교가 잘못된 혼합(confound)을 포함하고 있으며, 더욱 적절한 비교를 위해 다양한 constituency-based 규칙을 탐색할 것을 제안합니다.



### CATCH: Channel-Aware multivariate Time Series Anomaly Detection via Frequency Patching (https://arxiv.org/abs/2410.12261)
- **What's New**: 이 논문에서는 다변량 시계열(anomaly detection in multivariate time series)에서 발생하는 이질적인 subsequence anomalies를 탐지하기 위한 새로운 프레임워크인 CATCH를 제안합니다. CATCH는 주파수(patch) 영역 패칭(frequency patching)을 기반으로 하여, 다양한 형태의 비정상 시퀀스를 포착할 수 있는 능력을 향상시킵니다.

- **Technical Details**: CATCH 프레임워크는 주파수 영역에서 패치(patching) 기법을 사용하여 정밀한 주파수 특성을 포착합니다. 또한, Channel Fusion Module (CFM)을 통해 채널 간의 상관관계를 인식하여 적절한 패치-와이즈 채널 상관관계를 iteratively 발견하고 군집화할 수 있도록 합니다. 이는 bi-level multi-objective optimization 알고리즘에 의해 주도됩니다.

- **Performance Highlights**: CATCH는 9개의 실제 데이터셋과 12개의 합성 데이터셋에서 extensive experiments를 수행하여 최신 기법들보다 뛰어난 성능을 보여주었습니다. 모든 데이터셋과 코드는 https://anonymous.4open.science/r/CATCH-E535에서 확인할 수 있습니다.



### Understanding Expert Structures on Minimax Parameter Estimation in Contaminated Mixture of Experts (https://arxiv.org/abs/2410.12258)
Comments:
          Fanqi Yan, Huy Nguyen, Dung Le contributed equally to this work. 70 pages, 6 figures, 1 table

- **What's New**: 본 논문에서는 오염된 전문가 혼합 모델에서의 매개변수 추정(parameter estimation) 수렴 분석을 수행합니다. 이 모델은 프롬프트 학습(prompt learning) 문제에서 파생되었으며, 프롬프트를 전문가(experts)로 활용하여 대규모 사전 학습 모델(pre-trained model)을 미세 조정하는 방법을 다룹니다.

- **Technical Details**: 분석 과정에서 두 가지 기본적인 과제가 등장합니다: (i) 사전 학습 모델의 혼합 비율이 훈련 과정 중에 제로(0)로 수렴할 수 있으며, 그로 인해 프롬프트가 사라질 수 있습니다; (ii) 사전 학습 모델과 프롬프트의 매개변수 간 대수적(algebraic) 상호작용이 일부 편미분 방정식(partial differential equation)을 통해 발생하며 프롬프트 학습을 저하시킬 수 있습니다. 이러한 문제를 해결하기 위해, 매개변수 상호작용을 제어하기 위한 구별 가능성 조건(distinguishability condition)을 제시하며, 다양한 전문가 구조(expert structures)를 고려하여 매개변수 추정에 미치는 영향을 분석합니다.

- **Performance Highlights**: 각 시나리오에 대해 매개변수 추정의 포괄적인 수렴 속도(convergence rates)와 해당 최소 최악 하한(minimax lower bounds)을 제공합니다.



### Dual Action Policy for Robust Sim-to-Real Reinforcement Learning (https://arxiv.org/abs/2410.12250)
- **What's New**: 이번 논문에서는 Dual Action Policy (DAP)라는 새로운 접근 방식을 제안하여 강화 학습의 sim-to-real gap에서 발생하는 동적 불일치를 해결합니다. DAP는 단일 정책을 사용하여 두 개의 행동 세트를 예측하는 방식을 채택합니다. 하나는 시뮬레이션에서 작업 보상을 최대화하기 위한 것이고, 다른 하나는 보상 조정을 통한 도메인 적응을 위한 것입니다.

- **Technical Details**: DAP는 시뮬레이션 환경에서 작업 보상을 최대화할 뿐만 아니라 동적 불일치를 해결하기 위해 행동을 분리합니다. 교육 중 불확실성 기반 탐사를 적용하여 에이전트의 강건성을 향상시키고, 이는 최종 배치에서의 자기 수정과 더 확실한 상태-행동 분포로의 복귀를 가능하게 합니다.

- **Performance Highlights**: 실험 결과, DAP는 다양한 동적 불일치를 가진 도전적인 시뮬레이션 작업에서 모든 기준선보다 우수한 성능을 보여주었습니다. 불확실성 추정치를 통합함으로써 성능이 더욱 개선되었으며, 어떤 경우에는 최적의 결과에 가까운 성과를 달성했습니다.



### Enhancing LLM Agents for Code Generation with Possibility and Pass-rate Prioritized Experience Replay (https://arxiv.org/abs/2410.12236)
- **What's New**: 본 논문에서는 코드 생성 작업에서 transformer 기반 대형 언어 모델(LLM)의 비효율성을 극복하기 위해 경험 재생(Experience Replay, ER)을 도입한 새로운 BTP 파이프라인을 제안합니다.

- **Technical Details**: BTP 파이프라인은 세 가지 단계로 구성됩니다: beam search sampling, testing, 및 경험 재생 단계입니다. P2Value(가능성과 통과율 값)는 프로그램의 가치를 평가하는 데 사용되며, 실패한 코드 모델로부터 수집된 프로그램들을 활용하여 효율성을 높입니다.

- **Performance Highlights**: 실험 결과, BTP 파이프라인은 기존 모델보다 코드 생성 작업에서 성능을 향상시켰으며, 자가 생성된 데이터든 고품질 모델에 의해 생성된 데이터든 상관없이 우수한 성능을 보여주었습니다.



### Improving the Generalization of Unseen Crowd Behaviors for Reinforcement Learning based Local Motion Planners (https://arxiv.org/abs/2410.12232)
- **What's New**: 본 논문에서는 동적인 환경에서 사람 보행자와의 안전한 이동 로봇 정책을 배포하기 위한 새로운 방법을 제안합니다. 이전 연구들은 한 개의 정책만을 사용하여 보행자 운동을 시뮬레이션했으며, 이는 과적합(over-fitting) 문제로 이어질 수 있습니다. 본 연구는 에이전트의 다양성을 극대화하여 단일 정책 내에서 이를 해결하는 방법을 소개합니다.

- **Technical Details**: 우리는 에이전트들이 목표에 도달하기 위해 동적으로 움직일 수 있도록 학습하는 다중 에이전트 프레임워크를 활용하여 충돌 회피 문제를 다룹니다. 에이전트들은 동작 경험을 다각화하고, 보행자 군중의 다양한 행동에 대한 적응성을 향상시킵니다. 정책을 기준으로 하는 행동을 도입하였으며, 이는 각 에이전트가 훈련 에피소드 시작 시 무작위로 샘플된 행동으로부터 파생됩니다. 이러한 행동에 대한 내재적 보상을 에이전트에게 부여하여 다양한 행동을 취하도록 유도합니다.

- **Performance Highlights**: 제안된 행동 조건부 정책은 다양한 보행자 행동 시나리오에서 기존 방법들보다 더 강건성을 보이며, 추가적인 시간이나 여행 거리 없이도 잠재적 충돌을 줄일 수 있음을 시뮬레이션 결과를 통해 확인하였습니다.



### Comprehending Knowledge Graphs with Large Language Models for Recommender Systems (https://arxiv.org/abs/2410.12229)
- **What's New**: 이번 연구에서는 CoLaKG라는 새로운 방법을 제안하여 추천 시스템의 성능을 개선합니다. CoLaKG는 대규모 언어 모델(LLM)을 활용하여 지식 그래프(KG)의 한계를 극복하고, 아이템 간의 세밀한 의미적 연결을 유지합니다.

- **Technical Details**: CoLaKG는 아이템 중심의 하위 그래프(subgraph)를 KG에서 추출하고, 이를 LLM에 대한 입력으로 변환합니다. LLM은 이러한 하위 그래프에 대한 이해를 출력하고, 이를 의미적 임베딩(semantic embedding)으로 변환합니다. 또한, 이 임베딩을 바탕으로 아이템-아이템 그래프(item-item graph)를 구성하여 고차원 관계를 직접적으로 포착합니다.

- **Performance Highlights**: 실제 데이터셋 4종에 대한 광범위한 실험 결과, CoLaKG 방법이 기존 방법들에 비해 우수한 성능을 보였음을 확인했습니다.



### Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations (https://arxiv.org/abs/2410.12228)
- **What's New**: 이 논문은 개인화 추천 시스템을 향상시키기 위해 다양한 데이터 모달리티(data modalities)를 통합하는 새로운 프레임워크인 Triple Modality Fusion (TMF)를 소개합니다. 이 프레임워크는 시각적, 텍스트, 그래프 데이터의 융합을 통해 수행됩니다.

- **Technical Details**: TMF 모델은 큰 언어 모델(LLMs)과의 정렬을 통해 세 가지 모달리티를 통합하며, 각각의 모달리티는 사용자 행동을 포괄적으로 표현하기 위해 서로 다른 특징을 제공합니다. 시각적 정보는 아이템의 맥락 및 미적 특성을 캡처하고, 텍스트 데이터는 사용자 관심사와 아이템 특성에 대한 상세한 통찰력을 제공하며, 그래프 데이터는 아이템-행동 이질 그래프(item-behavior heterogeneous graph) 내의 관계를 설명합니다.

- **Performance Highlights**: 광범위한 실험을 통해 추천 정확성을 개선하는 효과를 입증하였습니다. 추가적인 ablation 연구를 통해 TMF 모델 디자인의 효과성과 이점을 검증하였습니다.



### On A Scale From 1 to 5: Quantifying Hallucination in Faithfulness Evaluation (https://arxiv.org/abs/2410.12222)
Comments:
          14 pages, 13 figures

- **What's New**: 이번 논문에서는 자동화된 사실성 평가를 통해 자연어 생성(NLG)의 신뢰성을 높이기 위한 방법을 연구하였습니다. 특히, 신뢰도를 평가하기 위해 대형 언어 모델(LLM)을 활용한 점수 매기기 방법을 제안하였습니다.

- **Technical Details**: 제안된 방법은 LLM과 자연어 추론(NLI) 모델을 이용하여 참조(referece)와 가설(hypothesis) 쌍의 신뢰성 점수를 도출합니다. 또한, 다양한 유형의 가설을 비교하여 신뢰도 점수의 변동성을 분석하였고, 합성된 비신뢰한 데이터를 생성하는 방법도 개발하였습니다.

- **Performance Highlights**: 연구 결과, GPT-4 모델은 소스와 생성이 사실적으로 일치하는지를 정확하게 판단하고 설명할 수 있음을 보여주었습니다. 비신뢰성 데이터로 NLI 모델을 조정할 경우 성능이 향상되었고, 이러한 시스템의 배포 시 레이턴시(latency)와 비용에 대한 통찰도 제공하였습니다.



### EdgeRL: Reinforcement Learning-driven Deep Learning Model Inference Optimization at Edg (https://arxiv.org/abs/2410.12221)
- **What's New**: 본 논문에서는 EdgeRL 프레임워크를 제안하여 공공 안전과 같은 임무-critical한 애플리케이션에서 강화 학습(Reinforcement Learning) 방법론인 Advantage Actor-Critic(A2C)을 활용하여 최적의 DNN 실행 매개변수를 선택하고, 성능 지표를 조율합니다. 이는 end-to-end 지연(latency), 결과 정확도(accuracy), 및 에너지 소비(energy consumption) 간의 균형을 맞추기 위한 것입니다.

- **Technical Details**: EdgeRL 프레임워크는 DNN 실행 프로파일을 선택하도록 설계되어 있습니다. 이는 기존 DNN 모델의 여러 사전 캐시된(Pre-cached) 버전 중에서 최적화된 버전을 선택하고, 선택된 버전에 대해 파티션 컷 포인트를 선택하여 edge 서버와 협력적 추론(collaborative inference)을 수행하게 됩니다. 이 실행 프로파일 선택은 Markov Decision Process(MDP)로 모델링되고, A2C 기반 강화 학습 방법으로 해결됩니다. 시스템의 입력으로는 end device의 배터리 상태, 활동 프로파일, 사용 가능한 대역폭(bandwidth), 운동 활동 등이 포함되어 지속적으로 시스템 동적을 학습하고 조정합니다.

- **Performance Highlights**: EdgeRL 프레임워크는 DNN 추론의 에너지 절약(Energy Savings), 정확도 개선(Accuracy Improvement), 및 end-to-end 지연 감소(Latency Reduction) 측면에서 실제 DNN 모델 및 하드웨어 테스트베드를 통해 그 효과를 평가하였습니다.



### Order-aware Interactive Segmentation (https://arxiv.org/abs/2410.12214)
Comments:
          Interactive demo can be found in project page: this https URL

- **What's New**: 본 논문에서는 사용자 상호작용을 최소화하면서도 정확한 객체 분할을 위한 새로운 방법인 OIS (order-aware interactive segmentation)를 제안합니다. OIS는 객체 간의 상대 깊이를 인코딩하여 사용자 상호작용을 효과적으로 안내하고, 이를 통해 이전의 방법들에 비해 성능을 크게 향상시킵니다.

- **Technical Details**: OIS는 목표 객체의 상대 깊이를 표현하는 order maps를 활용하여 상호작용을 개선합니다. 독창적인 order-aware attention과 object-aware attention 모듈을 도입하여 유사한 깊이를 가진 객체들을 효과적으로 구별할 수 있게 합니다. 또한, 사용자 클릭이 최적화된 이미지 특징에 통합될 수 있도록 조화롭게 설계되어 있습니다.

- **Performance Highlights**: OIS는 HQSeg44K 데이터셋에서 클릭 한 번으로 mIoU가 7.61 증가하였고, DAVIS 데이터셋에서는 1.32의 향상률을 보여줍니다. 뿐만 아니라, SegNext와 비교하여 추론 속도를 2배 향상시킨 것을 입증했습니다.



### Abnormality Forecasting: Time Series Anomaly Prediction via Future Context Modeling (https://arxiv.org/abs/2410.12206)
Comments:
          11 pages, 5 figures, submitted to KDD conference

- **What's New**: 이번 연구에서는 시간 시계열 데이터에서 이상 예측(anomaly prediction)을 다루며, 이상 사건이 발생하기 전에 조기 경고를 제공하는 데 중점을 두고 있습니다. 기존의 연구들은 이상 사건이 발생한 후에 발견하는 데 초점을 맞추었지만, 본 연구는 실용적이고 도전적인 문제에 접근합니다.

- **Technical Details**: 이상 예측을 위해 새로운 접근방식인 future context modeling (FCM)을 도입합니다. FCM의 핵심 아이디어는 목표 창(window)에서 발생할 미래의 이상 사건을 예측하는 것이며, 이것은 정상 데이터와의 미세한 차이를 포착함으로써 가능합니다. FCM은 장기 예측 모델을 활용하여 관찰 데이터(observation data)에서 차별화된 미래 맥락(future context)을 생성하고, 이 맥락을 통해 잠재적인 이상을 더욱 잘 예상합니다. 또한, FCM은 시계열 데이터의 시간 신호(temporal signals) 및 특징(features)을 함께 활용하는 joint variate-time attention learning을 도입하여 정상성 모델링을 개선합니다.

- **Performance Highlights**: 다양한 5개 데이터셋에 대한 포괄적인 실험 결과, FCM은 70% 이상의 높은 재현율(recall rate)을 달성했으며, 모든 기준선(baselines) 대비 F1 스코어에서 유의미한 성과를 보였습니다. 코드는 해당 링크에서 확인 가능합니다.



### Sparse Prototype Network for Explainable Pedestrian Behavior Prediction (https://arxiv.org/abs/2410.12195)
- **What's New**: 본 논문에서는 보행자 행동 예측에 있어 기존의 여러 겹의 특성과 행위를 동시에 예측할 수 있도록 설계된 Sparse Prototype Network (SPN)을 소개합니다. 이 모델은 예측의 설명 가능성을 높이기 위한 중간 프로토타입 병목 층을 활용하여, 모든 입력 모달리티에 대해 독립적인 프로토타입을 학습합니다.

- **Technical Details**: SPN은 세 가지 주요 모듈로 구성되어 있습니다: 입력 인코딩, 프로토타입 층, 그리고 예측 헤드입니다. 입력 인코딩 모듈은 각 모달리티를 독립적으로 처리하며, 원시 입력을 압축된 고차원 특성 벡터로 변환합니다. 프로토타입은 모달리티 간의 일관성을 유지하면서 학습되며, 이를 통해 예측의 해석 가능성을 제공합니다. 또한, Top-K Mono-semanticity Scale이라는 정량적 메트릭을 사용하여 프로토타입의 설명 가능성을 평가합니다.

- **Performance Highlights**: SPN은 TITAN 및 PIE 데이터셋에서 보행자 행동 예측 작업을 수행하며, 상태 최우수 성능을 달성했습니다. 또한, 이 모델은 동시에 다중 유형의 행동을 예측함으로써 높은 수준의 설명 가능성을 유지합니다.



### Trajectory Manifold Optimization for Fast and Adaptive Kinodynamic Motion Planning (https://arxiv.org/abs/2410.12193)
Comments:
          12 pages, 11 figures

- **What's New**: 본 논문은 동적 환경에 적응할 수 있는 빠른 kinodynamic motion planning에 관한 새로운 접근 방식을 제안합니다. 특히, 고차원의 복잡한 문제에서의 빠른 계획 수립의 어려움을 극복하기 위해 두 단계의 방법론을 적용하고 있습니다.

- **Technical Details**: 제안된 방법은 Differentiable Motion Manifold Primitives (DMMP)라는 신경망 모델을 기반으로 하며, 연속적인 시간에 따라 미분 가능한 궤적 만노폴드를 생성 및 인코딩합니다. 주요 기술 과정에는 다양한 초기화로 최적화 문제를 해결하여 얻은 궤적을 입력으로 하여, 이를 기반으로 작업 조건에 맞춘 잠재 흐름 모델을 개발합니다.

- **Performance Highlights**: 7-DoF 로봇 팔을 이용한 동적 던지기 작업 실험에서는, 본 방법이 기존의 접근 방식에 비해 계획 속도, 작업 성공률, 제약 조건 만족도에서 월등한 성과를 보였음을 확인했습니다.



### DocETL: Agentic Query Rewriting and Evaluation for Complex Document Processing (https://arxiv.org/abs/2410.12189)
Comments:
          21 pages, 7 figures, 3 tables

- **What's New**: DocETL은 LLM(대규모 언어 모델) 기반의 비정형 데이터 처리를 위한 최적화 시스템으로, 복잡한 문서 처리 파이프라인을 최적화합니다. 이 시스템은 사용자 정의 파이프라인을 선언적으로 정의할 수 있는 인터페이스를 제공하며, 자동으로 최적화할 수 있는 에이전트 기반 프레임워크를 사용합니다.

- **Technical Details**: DocETL은 다음과 같은 주요 기술적 요소를 포함합니다: (i) LLM 기반 작업에 맞게 조정된 파이프라인의 논리적 재작성, (ii) 작업별 검증 프롬프트를 합성하고 조정하는 에이전트 주도 계획 평가 메커니즘, (iii) LLM 기반 계획 생성 및 평가의 시간 제약을 고려한 효율적인 최적화 알고리즘이 있습니다.

- **Performance Highlights**: DocETL은 3개의 서로 다른 비정형 문서 분석 작업에 대한 평가를 통해 기존의 잘 설계된 기준보다 $1.34$배에서 $4.6$배 더 품질이 높은 출력(예: 더 정확하고 포괄적임)을 찾는 계획을 발견했습니다.



### DAQ: Density-Aware Post-Training Weight-Only Quantization For LLMs (https://arxiv.org/abs/2410.12187)
Comments:
          9 pages, 4 figures

- **What's New**: 이 논문은 density-aware post-training weight-only quantization (DAQ) 방법을 제안합니다. DAQ는 두 단계로 구성되어 있으며, 고밀도(weight density)가 있는 영역을 부동소수점 고정밀도 영역에 맞추는 방식으로 양자화합니다.

- **Technical Details**: DAQ는 먼저 고밀도 가중치 영역의 중심을 식별하여 이 지점에서 동적 범위를 조정하는 density-centric alignment(DCA) 단계를 수행합니다. 두 번째 단계인 learnable dynamic range adjustment(LDRA)는 가중치가 모델 출력에 미치는 영향을 기반으로 동적 범위를 최적화합니다.

- **Performance Highlights**: LLaMA와 LLaMA-2에서의 실험 결과, DAQ는 평균 22.8%의 perplexity loss를 줄이며, LLaMA-2에서는 19.6% 개선된 성능을 보여줍니다. 이는 기존의 최적 기법들보다 우수한 결과입니다.



### Reinforcement Learning with LTL and $\omega$-Regular Objectives via Optimality-Preserving Translation to Average Rewards (https://arxiv.org/abs/2410.12175)
- **What's New**: 이번 연구에서는 선형 시간 논리(Linear Temporal Logic, LTL)와 ω-정규 목표(ω-regular objectives)가 강화 학습(Reinforcement Learning, RL)에서 평균 보상(reward)을 달성하는 데 있어 기존의 할인이 있는 보상 방식에 비해 이해하기 쉽고 설명 가능하다는 점에 초점을 두었습니다. 특히 ω-정규 목표에 대해 최적성(optimality)을 보존하는 방식으로 한계 평균 보상(limit-average reward) 문제로의 변환 가능성을 제시하였습니다.

- **Technical Details**: 본 연구의 핵심 결과는 ω-정규 목표를 지닌 RL 문제는 유한 기억 보상 기계(finite-memory reward machines)를 통해 한계 평균 보상 문제로 변환 가능하다는 것입니다. 이를 통해 기존의 알고리즘을 활용하여 최적 정책(optimal policy)을 찾을 수 있는 방법론을 제시하였습니다. 또한, 평균 보상 문제에 대한 RL 알고리즘의 수렴 증명을 제공함으로써 이론적으로도 기초를 마련하였습니다.

- **Performance Highlights**: 본 연구는 RL 알고리즘을 통해 ω-정규 및 LTL 목표를 한계 평균 보상 문제로 변환하여 최적의 정책을 비대칭적으로 학습할 수 있음을 보여주었습니다. 특히, 정책의 학습이 제한 속에서 가능하다는 점을 명확히 함으로써 기존의 개방된 문제들(Open Problems)을 해결했습니다.



### The State of Robot Motion Generation (https://arxiv.org/abs/2410.12172)
Comments:
          To be presented at the International Symposium of Robotics Research (ISRR), 2024

- **What's New**: 본 논문은 로봇 모션 생성 방법의 폭넓은 스펙트럼을 검토하며 50년 간의 로봇 연구의 결실을 포함하고 있습니다. 전통적인 방법과 데이터 기반 방법을 구분하고, 두 가지 방법론의 통합 가능성을 강조합니다.

- **Technical Details**: 이 논문은 두 가지 주요 로봇 모션 생성 방법론을 비교합니다: 명시적 모델(Explicit Models)을 기반으로 하는 방법과 암시적 모델(Implicit Models)을 학습하는 방법입니다. 명시적 모델에서는 세계의 기하학적 및 동적 표현을 사용하고, 암시적 방법은 머신러닝 모델의 내부 파라미터에 표현을 저장하여 복잡한 작업을 수행합니다.

- **Performance Highlights**: 데이터 기반 방법은 로봇이 비구조적인 이동이나 능숙한 조작과 같은 복잡한 작업을 성공적으로 수행할 수 있도록 하는 데 큰 성과를 보여주고 있습니다. 기존의 방법들과의 통합적 접근이 더욱 강력하고 안전한 솔루션 개발에 기여할 수 있음을 논의합니다.



### Reclaiming the Source of Programmatic Policies: Programmatic versus Latent Spaces (https://arxiv.org/abs/2410.12166)
Comments:
          Published as a conference paper at ICLR 2024

- **What's New**: 최근 논문에서는 상태 비가시적 마르코프 결정 프로세스(Partially Observable Markov Decision Processes, POMDPs)용 프로그램 정책을 정의하는 데 사용되는 도메인 특화 언어(Domain-Specific Language, DSL)의 잠재 공간을 학습하는 시스템인 LEAPS( Learning Embeddings for Latent Program Synthesis)와 HPRL( Hierarchical Program Synthesis for Reinforcement Learning)이 도입되었습니다. 이 연구에서는 이러한 시스템이 기존 연구에서 관찰된 것과 유사한 행동 손실(behavior loss) 값을 제공하는 프로그램적 공간을 보여주고, LEAPS 및 HPRL보다 프로그램적 공간에서의 알고리즘이 성능이 뛰어남을 입증하였습니다.

- **Technical Details**: 프로그램적 공간에서의 검색을 가능하게 하는 후속 작업을 통해 DSL에 의해 유도된 프로그램적 공간의 지역 검색 알고리즘을 평가하고, 리니어 공간에 대한 알고리즘과의 성능 차이를 분석하였습니다. 새로운 경로 탐색 알고리즘은 법칙적 프로세스와 이웃 함수(neighborhood function)를 사용하여 최적의 솔루션을 탐색하는 방식으로 구현되었습니다. 이 연구의 결과는 직접 프로그램적 공간에서 검색하는 것이 LEAPS나 HPRL 방식보다 더욱 효율적임을 강조하였습니다.

- **Performance Highlights**: 프로그램적 공간에서의 힐 클라이밍(hill-climbing) 알고리즘이 LEAPS 및 HPRL을 지속적으로 초과 달성하며 최고 성능을 보였습니다. 이 결과는 프로그램적 공간이 보다 효과적인 검색을 가능하게 하며, 검색 과정의 최적화 토폴로지가 행동 손실과 더 나은 관련성을 지님을 의미합니다.



### Dual-Model Distillation for Efficient Action Classification with Hybrid Edge-Cloud Solution (https://arxiv.org/abs/2410.12165)
- **What's New**: 본 논문에서는 Dual-Model Distillation (DMD)이라는 혁신적인 방법을 통해 경량화된 혼합 에지-클라우드 솔루션을 제안하며, 실시간 환경에서의 성능을 최적화합니다.

- **Technical Details**: DMD는 소형 모델과 대형 모델 간의 지식을 상호 보완적으로 활용하여, 불확실한 상황에서 대형 모델에게 추론을 오프로드하는 기능을 수행하는 스위처 모델을 훈련합니다. 이 과정은 추가적인 수동 라벨링 데이터 없이 이루어지며, 두 모델의 제로샷 추론 결과의 합의나 불일치를 이용하여 데이터를 생성합니다.

- **Performance Highlights**: 우리의 시스템은 대형 모델만 사용했을 때보다 39.5%의 비용 절감과 4.6% 높은 F1 점수를 달성하였으며, 에너지 소비와 처리 시간을 각각 39.5%와 38.9% 줄였습니다.



### NSSI-Net: Multi-Concept Generative Adversarial Network for Non-Suicidal Self-Injury Detection Using High-Dimensional EEG Signals in a Semi-Supervised Learning Framework (https://arxiv.org/abs/2410.12159)
- **What's New**: 본 연구에서는 비자살적 자해(NSSI)와 관련된 뇌파(EEG) 특징을 효과적으로 모델링하기 위한 최신 반지도 적대 신경망(NSSI-Net)을 제안합니다. NSSI-Net은 시공간적 특징 추출 모듈과 다중 개념 판별기로 구성되어 있습니다.

- **Technical Details**: NSSI-Net의 시공간적 특징 추출 모듈은 2D 합성곱 신경망(2D-CNN)과 양방향 Gated Recurrent Unit(BiGRU)을 통합하여 EEG 데이터의 공간적 및 시간적 동적 정보를 포착합니다. 다중 개념 판별기는 신호, 성별, 도메인 및 질병 수준을 고려하여 의미 있는 EEG 특징을 추출합니다.

- **Performance Highlights**: 자체 수집한 NSSI 데이터(n=114)를 기반으로 NSSI-Net의 효과성과 신뢰성을 입증하였으며, 기존 머신러닝 및 딥러닝 방법보다 7.44% 성능 향상을 보였습니다. 이는 우울증을 가진 청소년에서 NSSI의 이해 및 조기 진단을 향상시키는 데 기여합니다.



### FragNet: A Graph Neural Network for Molecular Property Prediction with Four Layers of Interpretability (https://arxiv.org/abs/2410.12156)
- **What's New**: FragNet 아키텍처가 새로운 그래프 신경망 구조를 제공하며, 높은 예측 정확도와 예측의 해석 가능성을 동시에 달성합니다. 이 모델은 분자의 원자, 결합, 분자 조각 및 조각 연결의 네 가지 수준을 분석하여 분자 성질 예측을 지원합니다.

- **Technical Details**: FragNet은 메시지 전달 그래프 신경망 아키텍처에 기반하여, 네 가지 그래프 기반 분자 구조 표현을 사용합니다: 원자 기반(atom-based), 결합 기반(bond-based), 분자 조각 기반(fragment-based) 및 조각 연결 기반(fragment connection-based). 이 모델은 이들 구조 간의 계층적 접근 방식을 활용하여 학습된 표현을 초기화합니다.

- **Performance Highlights**: FragNet 모델은 MoleculeNet 벤치마크에서 수행된 다양한 화학, 생물학 및 독성 성질의 예측 작업에 대해 경쟁력 있는 예측 정확도를 달성했습니다. 또한, 모델의 해석 가능성을 통해 특정 분자 조각이 특정 속성 예측에서 기여하는 정도를 정량화할 수 있는 점이 주목할 만합니다.



### Exploiting LLMs' Reasoning Capability to Infer Implicit Concepts in Legal Information Retrieva (https://arxiv.org/abs/2410.12154)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 이번 연구는 법적 상황과 관련된 법적 용어 및 사실을 식별하기 위해 대형 언어 모델(LLMs)의 논리적 추론 능력을 활용하는 새로운 정보 검색 시스템을 제안합니다. 이 시스템은 전통적인 검색 방법의 한계를 극복하며, 법적 문제를 인식하고 이를 사용하여 쿼리 확장을 수행합니다.

- **Technical Details**: 제안된 방법론은 두 가지 쿼리 확장 기법을 통해 사용되며, 이는 대형 언어 모델의 제로-샷 프롬프트 기법을 통해 법적 개념과 관련된 용어를 생성하고, 이러한 용어를 쿼리에 통합하여 검색 성능을 향상시킵니다. 또한, lexical based ranking model(BM25)과 semantic based ranking model을 통합하여 최적의 검색 결과를 생성합니다.

- **Performance Highlights**: COLIEE 2022와 2023 대회에서 제안된 앙상블 검색 시스템은 모든 참여 팀 중에서 가장 우수한 성과를 달성하였습니다. LLM에서 얻은 추가 정보가 검색 정확도를 크게 향상시키는 데 기여했습니다.



### Layer-of-Thoughts Prompting (LoT): Leveraging LLM-Based Retrieval with Constraint Hierarchies (https://arxiv.org/abs/2410.12153)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 이번 논문에서는 Layer-of-Thoughts Prompting (LoT)라는 새로운 접근 방식을 제시합니다. 이는 제약 계층을 활용하여 주어진 쿼리에 대한 후보 응답을 필터링하고 세분화하는 기법입니다.

- **Technical Details**: LoT 방법은 제약 사항을 통합하여 구조화된 검색 프로세스를 가능하게 하며, 이는 정보 검색 정보를 더 잘 설명하고 자동화할 수 있는 방법입니다. 기존의 방법들은 다양한 프롬프트 기법을 다루었지만, 다중 턴 상호작용에서 프롬프트의 세부 사항에 대한 탐구가 부족했습니다. 이번 연구는 프롬프트간의 계층적 관계에 초점을 맞추어 이 빈틈을 메웁니다. 대형 언어 모델(LLMs)을 활용하여, LoT는 정보 검색 작업의 정확성과 이해도를 크게 향상시킵니다.

- **Performance Highlights**: LoT 기법은 효율적이고 해석 가능한 검색 알고리즘 개발에 결정적인 역할을 하는 사고 계층의 효능을 입증하였습니다. 이 방법은 설명 가능성과 자동화를 강화하여 정보 검색 정확성을 크게 개선했습니다.



### Facing Identity: The Formation and Performance of Identity via Face-Based Artificial Intelligence Technologies (https://arxiv.org/abs/2410.12148)
- **What's New**: 본 논문은 얼굴 기반 인공지능 기술이 디지털 공간에서 정체성(identity)을 어떻게 구성하고 표현하는지를 탐구합니다. 기존의 텍스트 중심의 인터넷에서 정체성에 대한 논의는 충분히 이루어졌으나, 시각 중심의 멀티미디어 인터넷에서는 얼굴이 특히 중요해졌습니다.

- **Technical Details**: 본 논문은 얼굴 인식 기술(facial recognition technologies, FRTs)과 심리학적 혹은 인종적 편견이 혼합된 고답적인 인식적 요소를 살펴보며, 여기에 AI의 이미지 생성 및 딥페이크(deepfakes) 기술이 포함됩니다. 또한, 이러한 얼굴 기반 AI 기술들이 성별, 인종, 성적 취향 등의 정체성과 어떻게 상호작용하는지를 분석합니다.

- **Performance Highlights**: 마지막으로, 본 논문은 VTuber(버추얼 유튜버)와의 인터뷰 연구를 제안하며, 이들을 통해 '포스트-페이셜(post-facial)' 시대의 디지털 정체성에 대한 질적 통찰을 얻고자 합니다.



### Sample-Efficient Reinforcement Learning with Temporal Logic Objectives: Leveraging the Task Specification to Guide Exploration (https://arxiv.org/abs/2410.12136)
Comments:
          arXiv admin note: text overlap with arXiv:2205.04424

- **What's New**: 본 논문은 불확실한 동적 시스템을 위해 Linear Temporal Logic (LTL) 공식으로 정의된 높은 수준의 제어 목표에 대한 최적의 제어 정책 학습 문제를 다룹니다. 기존의 강화 학습 (RL) 알고리즘은 LTL 작업을 수행하기 위해 균일하게 상태 공간을 탐색하는 경향이 있어 샘플 효율성이 저하됩니다. 이 문제의 해결을 위해 기존의 방법보다 훨씬 더 빠르게 제어 정책을 학습할 수 있는 가속화된 RL 알고리즘을 제안합니다.

- **Technical Details**: 제안된 알고리즘은 (i) LTL 공식을 Deterministic Rabin Automaton (DRA)으로 변환하고, (ii) MDP와 DRA 간의 곱을 구성하여 새로운 PMDP를 생성하며, (iii) LTL 공식의 DRA 표현을 활용해 임무 진행에 기여할 탐색 방향으로 편향된 새로운 확률적 정책, 즉 (ϵ,δ)−greedy 정책을 적용합니다. 이 방법은 탐색 과정에서 제어 결정을 내리는 데 필요한 불확실성을 모델링합니다.

- **Performance Highlights**: 제안된 학습 알고리즘은 랜덤 탐색, Boltzmann, 및 UCB 탐색을 사용하는 모델프리 RL 방법들보다 샘플 효율성 면에서 성능이 우수함을 실험을 통해 보여주었습니다. 또한, PMDP 크기가 증가할수록 이점이 더욱 두드러지며, 모델 기반 방법들과 비교해도 메모리 효율성이 뛰어나 대규모 MDP에 확장 가능함을 입증합니다.



### Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning (https://arxiv.org/abs/2410.12130)
- **What's New**: 이 논문은 대형 언어 모델(LLMs)의 환각(hallucination) 문제를 해결하기 위한 새로운 접근법인 Iterative Model-level Contrastive Learning (Iter-AHMCL)을 소개합니다. 이 방법은 환각을 줄이면서도 LLM의 원래 능력을 유지하도록 설계되었습니다.

- **Technical Details**: Iter-AHMCL 방법은 미리 훈련된 LLM의 표현층을 수정하여 환각이 있는 데이터와 없는 데이터를 기반으로 학습된 대비 모델을 사용합니다. 긍정적(positive) 및 부정적(negative) 모델을 통해 환각을 감소시키는 좀 더 직관적인 경로를 생성하고, 반복적인 대조 학습(iterative contrastive learning)을 통해 성능을 향상시킵니다.

- **Performance Highlights**: 본 논문은 LLaMA2, Alpaca, LLaMA3, Qwen 등 네 개의 미리 훈련된 LLM 모델에서 특별히 설계된 데이터셋으로 파인튜닝(finetuning) 실험을 수행하였으며, TruthfulQA 벤치마크에서 평균 10.1 포인트의 성능 향상을 달성했습니다. Iter-AHMCL은 환각을 줄이면서 LLM의 일반적인 능력을 유지하는 효과적인 방법임을 보여줍니다.



### Affordance-Centric Policy Learning: Sample Efficient and Generalisable Robot Policy Learning using Affordance-Centric Task Frames (https://arxiv.org/abs/2410.12124)
Comments:
          Video can be found on our project website: this https URL

- **What's New**: 이 논문에서는 로봇 조작을 위한 새로운 접근법으로, affordance(기능 가능성)에 중심을 둔 정책 학습 방법을 제안합니다. 이 방법은 task frame(작업 프레임)을 affordance 지역에 적절히 중심을 잡고 방향을 맞추어 intr-category invariance(범주 내 불변성) 및 spatial invariance(공간적 불변성)을 달성할 수 있도록 합니다.

- **Technical Details**: 연구자들은 기존의 다양한 large vision models(대형 비전 모델)을 활용하여 affordance 프레임을 추출하고 추적하는 방법을 제안합니다. 이 단계에서는 로봇의 end effector(끝 손잡이)와 상대적 좌표 체계를 기반으로 작업 프레임을 재정의하여 정책 학습에서 상태 표현을 간단히 합니다. 이로 인해 데이터 수집이 간편해지고 정책 학습을 위한 탐색 공간의 차원도 줄어듭니다.

- **Performance Highlights**: 최소 10회의 데모를 통해 조작 작업을 학습할 수 있으며, 305회의 데모를 통해 훈련된 이미지 기반 정책과 동일한 정도의 일반화 능력을 보여줍니다. 또한, 이 시스템은 전체 환경에서 일정한 성능을 유지할 수 있습니다.



### Just-In-Time Software Defect Prediction via Bi-modal Change Representation Learning (https://arxiv.org/abs/2410.12107)
Comments:
          Accepted by JSS (The Journal of Systems & Software)

- **What's New**: 이번 연구에서는 BiCC-BERT라는 새로운 bi-modal change pre-training model을 소개합니다. BiCC-BERT는 commit message와 코드 변경 사항 간의 의미적 관계를 학습하기 위해 새로운 pre-training objective인 Replaced Message Identification (RMI)을 사용합니다. 이를 통해 JIT-DP에 통합된 새로운 결함 예측 방법인 JIT-BiCC를 제안합니다.

- **Technical Details**: BiCC-BERT는 코드 변경 코퍼스에서 bi-modal semantic representations를 학습합니다. JIT-BiCC는 BiCC-BERT로부터 얻은 이중 의미 표현을 활용하여 기존 모델의 한계를 극복합니다. JIT-BiCC는 27,391개의 코드 변경을 통해 학습되며, F1-score와 AUC를 성능 지표로 사용하여 평가됩니다.

- **Performance Highlights**: JIT-BiCC는 8개의 최신 JIT-DP 방법과 비교하여 10.8%의 F1-score 개선을 달성하며 모든 기준을 초과하는 성능을 나타냅니다. 이는 JIT-DP 분야에서의 bi-modal semantics 학습의 효과성을 시사합니다.



### The Persian Rug: solving toy models of superposition using large-scale symmetries (https://arxiv.org/abs/2410.12101)
- **What's New**: 이 논문에서는 최소 비선형 희소 데이터 오토인코더가 대규모 입력 차원에서 학습한 알고리즘의 완전한 기계적 설명을 제공합니다. 특히 희소 데이터 벡터를 압축하고 비압축하는 과정을 통해 모델이 개별 가중치에 민감하게 반응하는 방식을 제시합니다.

- **Technical Details**: 모델은 입력 데이터와 출력 데이터 사이의 선형 변환을 통해 희소 데이터를 처리하며, ReLU 활성화 함수를 사용하여 비선형성을 추가합니다. 주요 발견 중 하나는 모델이 통계적 퍼뮤테이션 대칭을 보여주며, 고희소성에서 손실 함수의 수학적 형태가 분석 가능하다는 점입니다.

- **Performance Highlights**: 이 연구는 최근 제안된 아키텍처 중에서 모델이 최적에 가까운 성능을 달성했음을 보여줍니다. 특히 활성화 함수의 변경이나 추가는 모델 성능을 상수 배수만큼 향상시킬 수 있다고 설명합니다.



### Bridging Large Language Models and Graph Structure Learning Models for Robust Representation Learning (https://arxiv.org/abs/2410.12096)
Comments:
          Graph structure learning, Graph representation learning, Large language models, Graph neural networks

- **What's New**: 이 논문에서는 LangGSL을 소개합니다. 이는 대규모 언어 모델(LLMs)과 그래프 구조 학습 모델(GSLMs)의 장점을 통합하여 노드 특성과 그래프 구조 학습을 동시에 개선하는 robust framework입니다.

- **Technical Details**: LangGSL에서는 LLM을 사용하여 원본 데이터에서 노이즈를 필터링하고 유용한 정보를 추출하여 노드 특징을 향상시킵니다. 상호 학습 단계에서 상대적으로 작은 언어 모델이 로컬 속성을 처리하고 신뢰할 수 있는 pseudo-label과 informative node embeddings를 생성하여 GSLM의 예측 단계에 통합됩니다. 이는 전체적인 성능을 향상시킵니다.

- **Performance Highlights**: 다양한 규모의 그래프 데이터셋에서 광범위한 실험을 수행하여 LangGSL의 확장성 및 효율성을 입증했습니다. 또한, 향상된 노드 임베딩을 바탕으로 GSLM 모듈은 baseline 방법과 비슷한 성능을 보여주면서도 보다 효율적임을 demonstrated 합니다.



### Generative AI's aggregated knowledge versus web-based curated knowledg (https://arxiv.org/abs/2410.12091)
Comments:
          19 pages, 19 references, 8 pages of appendices, 15 figures

- **What's New**: 이 논문은 Generative AI (GenAI)와 Large Language Models (LLMs)이 지식을 집계하고 포장하는 방식을 통해 어떤 종류의 질문이 최선의 답변을 받을 수 있는지, 그리고 전통적인 웹 검색 결과가 언제 더 나은지 비교합니다. 실험을 통해 소비자들이 ChatGPT와 Google 검색 엔진을 사용할 때의 반응을 분석하였습니다.

- **Technical Details**: 연구에서는 자동차 구매 탐색을 주제로 비교 실험을 진행하였으며, 사전 조사, 생각 소리 내리기(thinking-aloud) 프로토콜, 시간 소요 및 대안의 수와 질에 중점을 둔 평가를 포함했습니다. 이 과정에서 Google 검색과 ChatGPT를 활용한 수백 가지의 probe query를 사용하여 12가지 지식 탐색 페르소나(personas)를 만들고 각 페르소나의 요구에 맞는 다양한 경험을 제안했습니다.

- **Performance Highlights**: GenAI는 널리 알려진 주제에 대한 지식을 집대성하는 데 탁월한 반면, 전통적인 웹 검색은 특정한, 잘 알려지지 않은 지식에 대해 더 나은 결과를 보여주었습니다. 이는 사용자 목표에 따른 차별화된 지식 접근 방식의 가치를 드러내며, 두 가지 접근 방식의 차이점을 강조하는 새로운 사용자 인터페이스 가치도 제안되었습니다.



### Data-adaptive Differentially Private Prompt Synthesis for In-Context Learning (https://arxiv.org/abs/2410.12085)
- **What's New**: 본 논문에서는 대형 언어 모델(LLM)이 정보를 안전하게 처리할 수 있도록 도와주는 새로운 데이터 적응형 차분 개인 정보 보호 (differential privacy) 알고리즘인 AdaDPSyn을 소개합니다.

- **Technical Details**: AdaDPSyn은 ICL(in-context learning)을 수행하기 위해 개인 데이터셋에서 합성 예제를 생성하며, 생성 과정에서 데이터의 고유한 통계적 특성에 따라 노이즈 수준을 조정합니다. 핵심 혁신 중 하나는 Precision-Focused Iterative Radius Reduction 기법으로, 데이터 클러스터링에서 관찰된 패턴을 기반으로 집계 반경을 동적으로 조정합니다.

- **Performance Highlights**: AdaDPSyn은 기존의 DP few-shot generation 알고리즘(Tang et al., 2023)과 비교하여 더 높은 성능을 보여주었으며, 비개인화 기준선(non-private baselines)과 유사한 높은 정확도를 유지합니다.



### WeatherDG: LLM-assisted Procedural Weather Generation for Domain-Generalized Semantic Segmentation (https://arxiv.org/abs/2410.12075)
- **What's New**: 이번 연구에서는 WeatherDG라는 새로운 접근 방식을 제안합니다. 이는 Stable Diffusion (SD)와 Large Language Model (LLM)의 협력을 통해 사실적인, 날씨가 다양한, 운전 화면 이미지를 생성할 수 있습니다.

- **Technical Details**: 이 방법은 세 가지 단계로 구성됩니다. 첫째, SD를 소스 데이터로 미세 조정하여 생성된 샘플의 내용과 레이아웃을 실제 운전 시나리오에 맞추는 것입니다. 둘째, LLM에 기반한 프로세절 프롬프트 생성 방법을 제안하여 시나리오 설명을 풍부하게 하고 SD가 더 다양하고 상세한 이미지를 자동으로 생성할 수 있도록 합니다. 마지막으로, 생성된 이미지를 사용해 모델을 훈련시키는 단계입니다.

- **Performance Highlights**: 세 가지 도전적인 데이터셋에서 실험한 결과, 우리의 방법이 다양한 최신 방법의 성능을 일관되게 개선할 수 있음을 보여주었습니다. 특히, 'Cityscapes to ACDC' 설정에서는 우리의 방법이 기준 HRDA에 비해 mIoU에서 13.9% 향상되었습니다.



### V3D-SLAM: Robust RGB-D SLAM in Dynamic Environments with 3D Semantic Geometry Voting (https://arxiv.org/abs/2410.12068)
- **What's New**: 본 논문에서는 진전된 SLAM 기술인 V3D-SLAM을 제안하여, 동적 환경에서 카메라 위치 추정과 맵 생성의 정확성을 높이기 위한 혁신적인 접근법을 보여줍니다. 이 방법은 움직이는 객체와 정적인 객체를 구분하고, 3D 형태와 동역학을 이해하여 이동 객체의 영향을 최소화하는 데 중점을 둡니다.

- **Technical Details**: V3D-SLAM은 Hough voting 메커니즘을 활용하여 동적 객체를 구분하고, Chamfer 거리(Chamfer distances)를 사용하여 정적 객체의 동적 노이즈를 탐지합니다. 실험은 TUM RGB-D 벤치마크 데이터 세트를 기반으로 하며, V3D-SLAM은 최신 SLAM 방법들보다 더 높은 성능을 보였음을 입증했습니다.

- **Performance Highlights**: 우리의 실험 결과 V3D-SLAM은 TUM RGB-D 벤치마크에서 동적 시퀀스에 대해 보다 높은 정확도를 보여주었고, 불필요한 노이즈를 효율적으로 제거함으로써 전통적인 SLAM 방법보다 우수한 성능을 달성했습니다.



### MFC-EQ: Mean-Field Control with Envelope Q-Learning for Moving Decentralized Agents in Formation (https://arxiv.org/abs/2410.12062)
Comments:
          Accepted to IROS 2024

- **What's New**: 이 논문은 다수의 에이전트를 위한 비대칭 경로 찾기 문제인 Moving Agents in Formation (MAiF)의 분산 버전을 연구합니다. MAiF는 에이전트들이 목표에 신속하게 도달하면서도 특정 형상을 유지하는 경로를 계획하는 문제입니다. 본 연구에서는 Mean-Field Control with Envelop Q-learning (MFC-EQ)라는 새로운 학습 프레임워크를 제안합니다.

- **Technical Details**: MFC-EQ는 에이전트 간의 상호작용을 집단 세력으로 근사화하는 mean-field 이론을 활용하여 모든 에이전트의 동역학을 모델링하고, envelope Q-learning을 통해 다양한 선형 선호를 반영할 수 있는 정책을 학습합니다. 이는 여러 에이전트가 제약을 준수하며 형상 유지 목표와 목표 접근 시간을 균형 잡는 비대칭 다중 에이전트 강화 학습 환경을 최적화하는 데 중점을 둡니다.

- **Performance Highlights**: MFC-EQ는 중앙 집중식 MAiF 베이스라인보다 우수한 성능을 보여 주며, 더 많은 수의 에이전트에서도 계획 시간이 짧습니다. 특히 동적으로 변하는 형상을 효과적으로 처리하여 기존 MAiF 플래너들이 해결할 수 없는 문제를 성공적으로 해결합니다.



### CrediRAG: Network-Augmented Credibility-Based Retrieval for Misinformation Detection in Redd (https://arxiv.org/abs/2410.12061)
- **What's New**: CrediRAG는 정치적 지식 기반과 사회적 네트워크를 활용하여 가짜 뉴스 탐지의 새로운 접근 방식을 제안합니다. 이 모델은 기존의 정보 검색 방식을 개선하여 가짜 뉴스를 대규모로 탐지합니다.

- **Technical Details**: CrediRAG는 뉴스 검색기를 사용하여 각 게시물의 허위정보 점수를 할당하고, 댓글을 공유한 사용자들 간의 평균적 입장을 바탕으로 동적으로 연결된 포스트 간 네트워크를 통해 추정치를 향상시킵니다. 이 모델은 GAT(그래프 주의 네트워크)를 활용하여 소셜 그래프 정보를 포함한 예측을 수행합니다.

- **Performance Highlights**: CrediRAG는 기존 최첨단 방법에 비해 허위 정보를 탐지하는 F1 점수에서 11% 향상을 달성했으며, 200,000개 이상의 실제 Reddit 데이터를 활용한 광범위한 실험에서 우수한 성과를 입증했습니다.



### Large-scale cloze evaluation reveals that token prediction tasks are neither lexically nor semantically aligned (https://arxiv.org/abs/2410.12057)
- **What's New**: 이번 연구에서는 여러 언어 모델의 다음 토큰 예측(next token prediction) 수준에서 생성 행동을 비교하여, cloze 작업에서 인간의 생성과 비교합니다. 연구 결과, 대규모 모델들이 일반적으로 인간의 응답을 더 잘 추정하지만, 확률 총합을 과소 평가하고, 희귀한 응답을 과대 평가하며, 최상위 응답을 과소 평가하는 경향이 있다는 것을 발견했습니다. 이 논문은 언어 모델의 생성이 클로즈 작업의 대체나 모델로 사용될 수 없음을 보여줍니다.

- **Technical Details**: 연구는 인간의 생성을 확률적 관점에서 잘 이해하고, LMs와 인간 간의 차이를 더 잘 알아내기 위해 single-word production을 검토합니다. cloze 작업은 문맥이 주어지고 그 안의 한 단어를 추론하는 작업으로, 인간의 응답 예측에서는 P(w|c)로 표기되는 단어의 발생 확률이 관찰된 모든 응답의 상대 빈도로 추정됩니다. 반면 언어 모델은 신경망을 통해 단어에 점수를 부여하고 softmax 함수를 통해 확률 분포를 생성합니다.

- **Performance Highlights**: Peelle et al. (2020)에서 수집한 3,085개의 영어 문장에 대해 인간 응답으로부터 얻은 cloze 확률과 여러 신경 언어 모델(GPT-2, RoBERTa, Pythia 모델 등)에서 추출한 확률을 비교했습니다. 모델들은 약 50,000의 서브워드(subword) 어휘 크기를 사용하며, 모델 크기, 훈련 시간, 데이터 중복 제거와 같은 여러 하이퍼파라미터의 영향을 탐구하는 Pythia 모델이 특히 흥미로운 결과를 제공합니다.



### Enabling Data-Driven and Empathetic Interactions: A Context-Aware 3D Virtual Agent in Mixed Reality for Enhanced Financial Customer Experienc (https://arxiv.org/abs/2410.12051)
Comments:
          to appear at 1st Workshop on Intelligent XR: Harnessing AI for Next-Generation XR User Experiences at International Symposium on Mixed and Augmented Reality (ISMAR) 2024

- **What's New**: 이 논문에서는 Mixed Reality (MR)과 Vision Language Models (VLMs)을 활용하여 금융 및 소매 부문에서 고객 서비스를 향상시키기 위한 새로운 시스템을 소개합니다. 이 시스템은 고객의 물리적 위치에 대한 상황 인식과 고객 프로파일에 기반한 개인화된 상호작용을 통해 데이터 기반의 공감 있는 상호작용을 가능하게 합니다.

- **Technical Details**: 이 연구는 고객의 요구에 맞춤형 지원을 제공하기 위해 situational awareness (상황 인식), 개인화된 상호작용, 그리고 엄격한 개인 정보 보호 및 보안 기준을 고려합니다. 특히, VLM을 활용하여 고객의 시각적 및 언어적 정보를 이해하고 반응할 수 있는 똑똑한 가상 비서 시스템을 설계합니다.

- **Performance Highlights**: 이 시스템은 고객의 다양한 요구사항을 충족시키고, 고객 대기 시간을 줄이며, 효과적인 문제 해결을 지원하는 다양한 기능을 제공합니다. 최종 목표는 고객에게 신뢰할 수 있고 고도로 개인화된 가상 경험을 제공하여 고객 만족도를 극대화하는 것입니다.



### Sabi\'a-3 Technical Repor (https://arxiv.org/abs/2410.12049)
- **What's New**: Sabiá-3는 브라질 중심의 대규모 데이터셋으로 훈련된 새로운 언어 모델로, 포르투갈어 및 브라질 관련 과제에서 우수한 성능을 보여줍니다. Sabiá-2와 비교하여 특히 추론 요구 과제에서 크게 향상되었습니다.

- **Technical Details**: Sabiá-3는 브라질 문화와 역사에 맞춘 포르투갈어 문서 데이터셋으로 훈련되었습니다. 두 가지 주요 단계에서 개발 되었습니다: (1) 사전 훈련(Pre-training) 단계에서 고품질 데이터에 대한 자기지도 학습(Self-supervised learning) 전략으로 훈련, (2) 사후 훈련(Post-training) 단계에서 인간의 선호에 맞춰 조정되었습니다. TPU v5 가속기를 사용하여 효율적으로 훈련했습니다.

- **Performance Highlights**: Sabiá-3는 ENADE 2022 및 2023 시험에서 Sabiá-2에 비해 70% 오류 감소를 보였고, GPT-4o와 경쟁력 있는 성능을 발휘했습니다. 특히 CPNU 시험에서 주목할 만한 성과를 보여 다른 모델들보다 높은 정확도를 달성했습니다.



### Concept-Reversed Winograd Schema Challenge: Evaluating and Improving Robust Reasoning in Large Language Models via Abstraction (https://arxiv.org/abs/2410.12040)
- **What's New**: 이 논문에서는 LLMs의 reasoning 성능을 평가하기 위한 새로운 데이터셋인 Concept-Reversed Winograd Schema Challenge (CR-WSC)를 제안합니다. 이 데이터셋은 기존의 Winograd Schema Challenge (WSC)에서 개념을 반전시켜 LLMs가 잘못된 대답과 더 연관된 답변을 이끌어내도록 구성되었습니다.

- **Technical Details**: CR-WSC 데이터셋은 LLM의 약점을 이용한 적대적인 질문들을 포함하고, Abstraction-of-Thought (AoT)라는 새로운 프롬프트 방법을 통해 LLMs의 robustness를 향상시키고자 합니다. AoT는 문제를 일반화하여 추상화한 후 reasoning을 수행하는 두 단계의 접근 방식을 채택합니다.

- **Performance Highlights**: 실험 결과, CR-WSC는 기존의 WSC에 비해 LLMs에게 상당히 더 어려운 과제로 나타났으며, AoT를 사용함으로써 LLMs의 reasoning 성능과 robustness가 현저하게 향상되었습니다.



### A Survey on Deep Tabular Learning (https://arxiv.org/abs/2410.12034)
Comments:
          43 pages, 18 figures, 3 tables

- **What's New**: 이 논문은 의료, 금융, 교통과 같은 산업에서 널리 사용되는 탭ular 데이터(tabular data)에 대한 딥러닝(deep learning) 모델의 발전 과정을 다룹니다. 초기의 완전 연결 네트워크(FCNs)에서부터 TabNet, SAINT, TabTranSELU, MambaNet과 같은 고급 아키텍처까지의 발전을 리뷰합니다.

- **Technical Details**: TabNet은 시퀀셜 어텐션(sequential attention)을 사용하여 인스턴스별(instance-wise) 특징 선택을 개선하며 해석 가능성을 높입니다. SAINT는 자기 어텐션(self-attention)과 샘플 간 어텐션(intersample attention)을 결합하여 특징과 데이터 포인트 간의 복잡한 상호작용을 포착합니다. 혼합 아키텍처(hybrid architectures)인 TabTransformer와 FT-Transformer는 카테고리 데이터와 수치 데이터를 처리하기 위한 응용 프로그램에 어텐션 메커니즘을 통합합니다.

- **Performance Highlights**: GNN4TDL과 GANDALF와 같은 그래프 기반 모델은 신경망(neural networks)과 결정 트리 또는 그래프 구조를 결합하여 소규모 데이터 세트에서 오버피팅을 완화하고 특징 표현을 증강합니다. TabDDPM과 같은 확산 기반 모델은 데이터 부족을 해결하기 위해 합성 데이터를 생성하여 모델의 강건성을 향상시킵니다. 다시 말해, 이 논문은 탭ular 데이터의 다양한 응용 프로그램에서 성능과 효율성의 균형을 맞추기 위한 향후 연구 방향을 제시합니다.



### MoE-Pruner: Pruning Mixture-of-Experts Large Language Model using the Hints from Its Router (https://arxiv.org/abs/2410.12013)
- **What's New**: 새로운 논문에서는 Mixture-of-Experts (MoE) 아키텍처의 메모리 소비 및 전문가 중복성을 줄이기 위해 MoE-Pruner라는 방법을 제안합니다. 이 방법은 각 출력 뉴런에서 입력 활성화와 라우터 가중치를 곱한 최소 크기의 가중치를 가지는 방법으로 일회를 통해 손실을 최소화합니다.

- **Technical Details**: MoE-Pruner는 활발하지 않은 전문가의 가중치를 제거하여 모델을 가지치기하는 기법입니다. 이 프로세스는 재학습이나 가중치 업데이트 없이 한 번의 조정 데이터만으로 수행됩니다. Mixtral-8x7B 및 Mixtral-8x22B 모델에 대해 여러 언어 벤치마크에서 그 효용성이 입증되었습니다.

- **Performance Highlights**: Mixtral-8x7B 모델은 50%의 희소성을 가지면서도 원래 모델의 99% 성능을 유지하며, 전문가별 지식 증류를 통해 성능 회복이 가능합니다. 기존의 최첨단 LLM 가지치기 방법들에 비해 우수한 결과를 보였습니다.



### Bias Similarity Across Large Language Models (https://arxiv.org/abs/2410.12010)
Comments:
          under review

- **What's New**: 이 논문은 여러 LLM(대형 언어 모델) 간의 편향(bias) 유사성을 비교한 최초의 작업이다. 기존 연구들은 개별 모델에서의 편향을 분석했지만, 다양한 모델 간의 편향을 비교한 연구는 부족했다. 이를 통해 LLM의 편향을 서로 분석하여 향후 모델 디버깅 기술에 기여할 수 있는 가능성을 제시한다.

- **Technical Details**: 연구에서는 10개의 오픈 및 클로즈드 소스 LLM을 포함하여 4종 모델 패밀리에서 편향의 정도를 평가하였다. 두 개의 데이터 세트를 사용해 4개의 편향 차원에서 질문 4천 개와 100만 개에 대한 LLM의 출력 분포를 측정하였으며, 결과적으로 다음과 같은 주요 발견을 도출했다: 1) 파인튜닝(fine-tuning)이 출력 분포를 유의미하게 변경하지 않음, 2) 동일 모델 패밀리 내에서도 유사한 출력 분포를 생성하지 않음, 3) 훈련 데이터 정보 유출 가능성이 존재함.

- **Performance Highlights**: 연구 결과는 다음과 같다: 1) LLM의 파인튜닝이 출력 분포에 미치는 영향이 제한적이며, 이는 편향 완화 능력을 제한할 수 있다. 2) 동일 패밀리의 LLM이 출력 경향성에서 서로 다르게 작용해 편향 처리를 위한 모델 간 상호연관성이 낮다. 3) 다양한 모델 간의 편향 레벨이 달라 데이터 보안 및 개인 정보 보호에 대한 우려가 제기된다.



### Beyond Labels: A Self-Supervised Framework with Masked Autoencoders and Random Cropping for Breast Cancer Subtype Classification (https://arxiv.org/abs/2410.12006)
- **What's New**: 이번 연구는 유방암 아형 분류를 위한 히스토패스홀로지(Histopathology) 이미지를 사용하여, 마스크 오토인코더(Masked Autoencoder, MAE)를 활용한 자기 지도 학습(self-supervised learning) 방법론을 제안합니다. 이 접근법은 정보 전반을 효과적으로 캡처하기 위한 임베딩(embedding) 학습을 통해 레이블이 없는 데이터셋에서도 특징(feature) 학습이 가능합니다.

- **Technical Details**: 연구에서는 전체 슬라이드 이미지(Whole Slide Images, WSI)에서 이미지 패치를 추출하고, 마스크 기법을 사용하여 인코더가 마스킹된 데이터를 기반으로 복원하는 구조를 취합니다. MAE를 통해 이미지의 특정 부분을 마스킹하고, 잔여 데이터로부터 패턴을 학습하여 원래 이미지를 복원하는 과정을 구현합니다. 또한, ViT(Vision Transformers) 모델을 사용하여 다중 분류(multi-class classification) 작업에서 성능을 평가합니다.

- **Performance Highlights**: BRACS 데이터셋 평가를 통해 이 모델이 기존 벤치마크와 비교하여 높은 성능을 보여주었으며, 특히 tumor tissue와 healthy tissue 구분 및 아형 분류에서의 정확도가 강조되었습니다.



### The Fair Language Model Paradox (https://arxiv.org/abs/2410.11985)
- **What's New**: 이 논문은 Large Language Models (LLMs)의 토큰 수준에서의 훈련 동역학을 조명하며, 가중치 감쇠(weight decay)가 저주파(low-frequency) 토큰의 성능에 미치는 부정적인 영향을 발견하였습니다. 이러한 연구는 기존의 성능 지표에 의해 간과되었던 중요한 통찰을 제공합니다.

- **Technical Details**: 이 연구는 IMDB 데이터셋을 사용하여 270M과 3B 파라미터를 가진 Apple OpenELM 모델과 Qwen2 모델을 훈련하면서 다양한 가중치 감쇠 수준을 적용하였습니다. 결과적으로, 가중치 감쇠가 증가할수록 저주파 토큰의 성능이 유의미하게 감소하는 것을 확인했습니다. 또한, 고주파 토큰이 저주파 토큰보다 학습 속도에서 일관되게 우세하다는 발견이 있었습니다.

- **Performance Highlights**: 가중치 감쇠를 통한 일반화 촉진을 목표로 하는 기존의 방법이 저주파 토큰을 무시하는 결과를 초래하며, 이는 데이터의 대다수를 차지하는 저주파 토큰에 대한 성능 저하로 이어진다는 점이 명확해졌습니다. 이로 인해 더 일반적인 토큰에 유리한 편향이 발생하며, 새로운 정규화 기법의 필요성이 부각되었습니다.



### Generative AI Policies under the Microscope: How CS Conferences Are Navigating the New Frontier in Scholarly Writing (https://arxiv.org/abs/2410.11977)
- **What's New**: 최근 Generative AI (Gen-AI) 기술의 발전과 ChatGPT의 출현으로 컴퓨터 과학 회의에서의 정책이 변화하고 있으며, 이에 대한 포괄적인 검토 및 정책 채택을 위한 지침을 제시합니다.

- **Technical Details**: 이 논문에서는 최근 2년 간 주요 컴퓨터 과학 회의의 Generative AI 정책 현황을 요약하고, ACM, IEEE, AAAI와 같은 주요 컴퓨팅 사회의 정책을 분석했습니다. Gen-AI 정책이 있는 회의와 그 유연성(유연성 등급)도 평가하였으며, 특정 분야에서 Gen-AI의 사용 지침이 어떻게 변화하고 있는지를 살펴보았습니다.

- **Performance Highlights**: AI 분야의 회의에서는 첫 해에 비해 저자 정책의 채택 비율이 30.8%에서 76.9%로 크게 증가하였으며, 이는 AI 분야가 저자에게 Gen-AI 정책을 가장 적극적으로 도입하고 있음을 보여줍니다. 반면, 이론 분야에서는 여전히 Gen-AI 정책이 없는 상태입니다. 회의에 따라 저자 정책은 더 유연한 경향을 보이며(평균 유연성 등급 3.60에서 3.68로 증가), 리뷰어 정책은 더 제한적입니다(평균 유연성 등급 3.00에서 2.63으로 감소).



### DDIL: Improved Diffusion Distillation With Imitation Learning (https://arxiv.org/abs/2410.11971)
- **What's New**: 본 논문에서는 ‘모방 학습(Imitation Learning)’ 프레임워크 내에서의 확산 디스틸레이션(Diffusion Distillation) 접근법을 제안하여, 확산 모델의 훈련 분포를 개선하였음을 발표합니다. 이는 데이터 분포(Forward Diffusion)와 학생이 유도한 분포(Backward Diffusion)를 모두 고려하여 이루어집니다.

- **Technical Details**: 제안된 DDIL( Diffusion Distillation within Imitation Learning) 접근법은 ‘DAgger’ 프레임워크를 통해 데이터 집합 내에서 데이터 분포와 학생 유도 분포 모두에서 디스틸레이션을 수행하여 예측 분포의 집합적 품질을 개선하는 것을 목표로 합니다. 이 과정에서 데이터 분포의 지원을 위반하지 않도록 임계값 설정을 도입하였으며, 이는 ‘반사 확산(Reflected Diffusion)’ 공식을 사용하여 Covariate Shift 문제를 완화합니다.

- **Performance Highlights**: DDIL 접근법은 다양한 샘플을 생성하며, 프로그레시브 디스틸레이션(Progressive Distillation), 잠재 일관성 모델(Latent Consistency Model), 분포 매칭 디스틸레이션(Distribution Matching Distillation)과 같은 여러 디스틸레이션 기법에서 일관되게 성능을 향상시키는 결과를 보여주었습니다.



### CtrlSynth: Controllable Image Text Synthesis for Data-Efficient Multimodal Learning (https://arxiv.org/abs/2410.11963)
- **What's New**: 새로운 연구는 'CtrlSynth'라는 이미지-텍스트 합성 파이프라인을 설계하여 데이터 효율적이고 강력한 다중 모달 학습을 가능하게 합니다. 이 방법은 사용자가 정의한 제어 정책을 적용하여 시각적 의미를 분해하고 재조합함으로써 입력 데이터의 생성을 조절할 수 있게 만들어줍니다.

- **Technical Details**: CtrlSynth는 미리 훈련된 기초 모델을 활용하여 이미지의 시각적 태그를 추출하고, 이를 바탕으로 LLM을 이용해 텍스트를 생성합니다. 사용자는 생성 과정에서 특정 요소를 제어할 수 있으며, 닫힌 루프 시스템을 통해 기존 모델을 활용하여 추가 훈련 없이 직접적으로 합성 작업을 수행합니다.

- **Performance Highlights**: CtrlSynth는 31개의 다양한 데이터셋에서 실험을 진행했으며, CLIP 모델의 제로샷 분류에서는 23.4%, SugarCrepe 구성 추론 벤치마크에서는 5%의 정확도 향상을 보였습니다. 또한, 긴 꼬리(Long-tail) 비전 과제에서도 16%에서 21%의 성능 개선을 확인했습니다.



### Beyond Sequence: Impact of Geometric Context for RNA Property Prediction (https://arxiv.org/abs/2410.11933)
- **What's New**: 본 연구는 RNA의 물리적 속성을 예측하기 위해 2D와 3D 기하학적 정보를 포함한 최초의 체계적인 평가를 제공합니다. 기존 연구들은 주로 1D 시퀀스 모델에 초점을 맞추었으나, 이들 연구에서 고유의 기하학적 맥락을 간과해왔습니다. RNADatasets의 새로운 집합을 소개하여 모델 평가를 위한 자원을 제공합니다.

- **Technical Details**: 본 연구에서는 1D, 2D, 3D RNA 표현으로 다양한 기계 학습 모델의 성능을 비교하고 분석합니다. 1D 모델(Transformer1D), 2D 모델(Graph Convolutional Network 등), 3D 모델(SchNet 등)을 사용하며, 새로운 2D 및 3D 구조 주석이 포함된 RNA 데이터셋을 개발했습니다. 각 모델은 제한된 데이터와 라벨, 시퀀싱 오류, 분포 외 시나리오에서 어떻게 성능이 달라지는지를 종합적으로 평가합니다.

- **Performance Highlights**: 평가 결과, 명시적인 기하학적 인코딩을 가진 모델이 시퀀스 기반 모델에 비해 일반적으로 더 뛰어난 성능을 보였으며, 평균 예측 RMSE가 약 12% 감소했습니다. 3D 모델은 노이즈가 없는 상황에서 가장 우수한 성능을 보이지만, 시퀀싱 오류가 많은 경우 56%까지 성능이 저하됩니다. 반면, 기하학을 고려하지 않은 시퀀스 모델은 시퀀싱 노이즈에 가장 강하지만, 동일한 성능에 도달하기 위해서는 2-5배의 훈련 데이터가 필요합니다.



### Transfer Learning Adapts to Changing PSD in Gravitational Wave Data (https://arxiv.org/abs/2410.11911)
Comments:
          7 pages, 3 figures

- **What's New**: 이번 논문은 중력파(Gravitational Wave, GW) 신호를 식별하기 위한 혁신적인 AI 접근 방식을 소개합니다. 전통적인 소음 억제 방법들의 한계를 극복하기 위해 간소화된 아키텍처를 채택하고, 새로운 훈련 방법론을 개발하여 복잡한 소음 속에서도 높은 정확도로 중력파를 탐지하는 모델을 구축하였습니다.

- **Technical Details**: 우리의 모델은 단순한 다층 퍼셉트론(Multilayer Perceptron, MLP)을 기반으로 하며, ReLU 활성화 함수(Activation Function)를 사용하여 소실 기울기 문제(Vanishing Gradient Problem)를 피할 수 있습니다. 이 모델은 우선 깨끗한 데이터로 훈련된 후, Transfer Learning 기법을 사용하여 소음이 있는 데이터로 미세 조정합니다. 이를 통해 복잡한 소음 환경에서 중력파 신호를 효과적으로 식별할 수 있게 됩니다.

- **Performance Highlights**: 모델은 비백색 노이즈(non-white noise) 환경에서 99% 이상의 정확도를 달성하였으며, 변화하는 소음 전력 스펙트럼 밀도(Power Spectral Density, PSD) 조건에 매우 적응력이 뛰어납니다. 추가적으로, 이 모델은 몇 에폭(Epochs)의 미세 조정을 통해 새로운 소음 프로파일에 빠르게 적응하여, 동적으로 변화하는 소음 환경에서 실시간 분석이 가능합니다.



### Explainable AI Methods for Multi-Omics Analysis: A Survey (https://arxiv.org/abs/2410.11910)
- **What's New**: 본 논문에서는 multi-omics 데이터의 해석 가능성을 향상시키기 위해 설명 가능한 인공지능(xAI) 방법의 중요성을 다룹니다.

- **Technical Details**: multi-omics는 유전체(genomics), 단백질체(proteomics), 전사체(transcriptomics), 대사체(metabolomics), 미생물체(microbiomics)와 같은 여러 가지 omics 데이터의 통합 분석을 의미합니다. 이러한 데이터의 딥 러닝(deep learning) 방법을 활용하여 분자 상호작용에 대한 통찰력을 제공하고 복잡한 질병 연구를 향상시킬 수 있습니다.

- **Performance Highlights**: xAI 방법론을 통해 임상의들이 복잡한 데이터에서 명확한 통찰력을 얻을 수 있어, 임상 환경에서 이러한 모델의 효과적인 적용을 촉진할 수 있는 잠재력이 강조됩니다.



### ChatHouseDiffusion: Prompt-Guided Generation and Editing of Floor Plans (https://arxiv.org/abs/2410.11908)
- **What's New**: 이 논문에서는 ChatHouseDiffusion라는 새로운 방법을 소개하여 자연어 입력을 해석하고, 그래프 구조(그래프오머, graphormer)를 통해 공간적 관계를 인코딩하며, 확산 모델(diffusion models)을 사용하여 플로어 플랜(floor plans)을 유연하게 생성하고 수정할 수 있도록 합니다. 이를 통해 사용자의 아이디어를 기반으로 한 반복적 디자인 조정을 가능하게 하며, 효율성을 크게 향상시킵니다.

- **Technical Details**: ChatHouseDiffusion는 대형 언어 모델(LLM, Large Language Models)을 사용하여 사용자 입력을 파싱하고, 그래프오머(graphormer)를 통해 방의 위상적(topological) 관계를 인코딩하며, 확산 모델을 활용하여 플로어 플랜을 예측합니다. 이 접근 방식은 초기 결과에 대한 세밀한 지역 조정을 가능하게 하며, 반복적인 설계를 통해 사용자가 원하는 결과를 이끌어낼 수 있도록 합니다.

- **Performance Highlights**: ChatHouseDiffusion는 기존 모델과 비교하여 높은 교차 비율(Intersection over Union, IoU) 점수를 달성하여 정확하고 지역적인 조정이 가능하며, 전체 재설계를 필요로 하지 않아 실제적인 유용성을 제공합니다. 실험 결과는 모델이 사용자 사양을 엄격히 준수하며, 인터랙티브한 기능을 통해 직관적인 디자인 프로세스를 촉진함을 보여줍니다.



### Empowering Users in Digital Privacy Management through Interactive LLM-Based Agents (https://arxiv.org/abs/2410.11906)
- **What's New**: 이 논문은 대규모 언어 모델(LLM)을 활용하여 사용자들이 개인정보 처리 방침을 이해하는 데 도움을 주는 새로운 대화형 에이전트를 제시합니다. 기존 모델보다 데이터 처리 식별, 선택 식별, 정책 요약 및 개인정보 관련 질문 응답 등에서 LLM이 월등한 성능을 보임을 보여주며, 개인정보 처리 방침 분석에 있어 새로운 기준을 마련합니다.

- **Technical Details**: 본 연구는 GPT-4o-mini 기반의 LLM 에이전트를 개발하여 웹사이트의 개인정보 처리 방침을 이해하는 데 사용자들을 지원합니다. 에이전트는 복잡한 법적 언어를 단순화하여 특정 질문 없이 사용자들이 필요한 정보를 얻도록 돕습니다. 연구는 사용자 100명을 대상으로 한 사용자 연구를 포함하며, 여기서 LLM을 사용한 그룹이 더 높은 이해도와 더 낮은 인지 부하를 경험하였음을 보고합니다.

- **Performance Highlights**: 사용자 연구 결과, LLM에 의해 보조된 사용자들은 평균 2.6의 이해 점수를 기록하였고, 이는 대조군의 1.8에 비해 현저히 높은 점수입니다. 주요 결과로는, LLM 에이전트 사용 그룹이 시간 소모를 줄이고(5.5분 대 15.8분), 개인정보 처리를 관리하는 데 있어 자신감이 증가하였으며 인지 부하가 크게 감소했다고 보고합니다.



### Personalised Feedback Framework for Online Education Programmes Using Generative AI (https://arxiv.org/abs/2410.11904)
Comments:
          Submitted to journal

- **What's New**: 최근 AI 도구, 특히 대규모 언어 모델(large language models)이 학습 관리 시스템과 온라인 교육 프로그램 내에서 효과성을 입증하였습니다. 이 연구는 교육 피드백 시스템을 개선하기 위한 대안적 피드백 프레임워크를 제안합니다.

- **Technical Details**: 본 논문은 ChatGPT의 기능을 확장하는 피드백 프레임워크를 탐색합니다. 이 프레임워크는 embeddings를 통합하여 교육 자료에 대한 더 세밀한 이해를 가능하게 하며, 퀴즈 기반 평가를 위한 주제별(targeted) 피드백을 촉진합니다.

- **Performance Highlights**: 연구의 일환으로 제안된 개념 증명(proof of concept) 솔루션은 개방형(open-ended) 질문에 대해 90%의 효율성(efficacy) 비율을, 다중 선택(multiple-choice) 질문에 대해서는 100%의 효율성을 달성했습니다. 이 결과는 우리의 프레임워크가 기대를 초과할 뿐만 아니라 인간의 서술(narratives)과도 경쟁할 수 있다는 가능성을 시사합니다.



### Study on the Helpfulness of Explainable Artificial Intelligenc (https://arxiv.org/abs/2410.11896)
Comments:
          World Conference on Explainable Artificial Intelligence

- **What's New**: 이 논문은 설명 가능한 인공지능(Explainable AI, XAI) 방법의 성과를 평가하는 새로운 접근 방식을 제안합니다. 특히, XAI의 유용성을 사용자들이 성공적으로 수행할 수 있는 프록시 작업을 통해 평가하는 방법에 중점을 두었습니다. 이를 통해 사용자 의사결정에 있어서 XAI의 도움을 판단할 수 있습니다.

- **Technical Details**: XAI의 성과를 측정하기 위한 연구 질문이 정의되었으며, 사용자의 AI 결정 판단 능력, AI 결정에 대한 신뢰도, AI 결정에 대한 질문을 평가하는 방법이 포함되어 있습니다. 연구에서는 6가지 유명한 XAI 방법을 비교하여, 사용자들이 AI 기반 분류 결정의 신뢰성을 올바르게 판단할 수 있는 능력을 조사했습니다.

- **Performance Highlights**: 사용자 연구 결과, 다양한 XAI 방법들이 신뢰와 회의감을 생성하는 능력에서 차이를 보였으며, AI 결정의 올바른 판단 능력에도 차이를 보였습니다. 본 논문은 XAI 성과 측정에 있어 보다 객관적이고 인간 중심의 사용자 연구 접근 방식을 적용할 것을 강력히 권장합니다.



### Are Grid Cells Hexagonal for Performance or by Convenience? (https://arxiv.org/abs/2410.11886)
Comments:
          5 pages, accepted at Montreal AI and Neuroscience Conference 2024

- **What's New**: 본 연구는 그리드 셀(grid cell)의 육각형 구조가 실제 성능 이점을 제공하는지 또는 생물학적으로 편리한 구성을 나타내는지 여부를 조사합니다. Vector-HaSH(content addressable memory 모델)를 통해 사각형과 육각형 그리드 셀의 성능을 비교한 결과, 두 구조는 비슷한 성능을 보임을 발견하였습니다.

- **Technical Details**: 이 연구에서는 Vector-HaSH 프레임워크를 기반으로 하고, MNIST, Fashion-MNIST, CIFAR-100과 같은 이미지 데이터셋을 사용하여 그리드 셀의 두 가지 형태, 즉 육각형 그리드와 사각형 그리드를 구현하였습니다. 다양한 경로 유형과 경로 길이를 이용해 메모리 관련 실험을 실시하였습니다.

- **Performance Highlights**: 실험 결과, 육각형 그리드 셀과 사각형 그리드 셀은 이미지 인식 및 경로 시뮬레이션에서 비슷한 성능을 보였으며, 메모리 재현 및 정확도가 유사하였습니다. 이러한 결과는 육각형 그리드가 생물학적 구현의 용이성에서 비롯되었음을 시사합니다.



### Neural Metamorphosis (https://arxiv.org/abs/2410.11878)
Comments:
          in ECCV2024, this https URL

- **What's New**: 본 논문에서는 Neural Metamorphosis (NeuMeta)라는 새로운 학습 패러다임을 소개합니다. NeuMeta는 별도의 모델을 만들지 않고, 신경 네트워크의 가변 형태를 직접 학습합니다. 이를 통해 학습된 가중치 공간에서 임의 크기의 네트워크를 샘플링할 수 있습니다.

- **Technical Details**: NeuMeta는 hypernetwork로 작동하는 implicitly learned neural functions를 사용합니다. 이는 모델 공간의 좌표를 받아 해당 가중치 값을 생성합니다. 목표는 가중치의 smoothness를 높이는 것이며, 이를 위해 두 가지 전략을 사용합니다: 첫째, 가중치 행렬의 permutation을 통해 intra-model smoothness를 달성하고, 둘째, 입력 좌표에 noise를 추가하여 무작위 네트워크 구성에서도 일관된 출력을 유지합니다.

- **Performance Highlights**: NeuMeta는 이미지 분류, 의미론적 분할 및 이미지 생성 작업에서 광범위한 테스트를 거쳐, 75% 압축률에서도 원래 모델의 성능을 유지합니다. 이 시스템은 이전에 보지 못한 네트워크 구성에 대한 가중치를 생성하는 성능을 보여줍니다.



### A Framework for Collaborating a Large Language Model Tool in Brainstorming for Triggering Creative Thoughts (https://arxiv.org/abs/2410.11877)
Comments:
          18 pages, 3 figures

- **What's New**: 이번 연구는 브레인스토밍(Brainstorming) 과정에서 창의성을 향상시키기 위한 프롬프트 엔지니어링(Prompt Engineering)의 역할을 탐구하는 새로운 프레임워크인 GPS(Goals, Prompts, Strategies)를 제안합니다. LLM(대규모 언어 모델) 도구와의 통합을 통해 창의적인 아이디어 생성에 대한 접근 방식을 변화시키고자 합니다.

- **Technical Details**: GPS 프레임워크는 목표, 프롬프트, 전략을 바탕으로 하여 디자이너가 LLM 도구를 체계적으로 사용할 수 있도록 안내합니다. 이 프레임워크는 Torrance Tests of Creative Thinking (TTCT)를 참고하여 AI가 생성한 아이디어의 창의성을 측정하기 위한 측정 도구를 적응시켰습니다. 프롬프트 엔지니어링은 사용자가 LLM 도구의 응답을 유도하는 일련의 텍스트 기반 입력을 설계하고 수정하는 과정입니다.

- **Performance Highlights**: 사례 연구와 디자인 예제를 통해 검증된 GPS 프레임워크는 브레인스토밍 세션에서 창의성과 아이디어의 유용성을 향상시키는 데 효과적임을 보여줍니다. 연구 결과에 따르면, 이 프레임워크는 사용자가 아이디어 구상 단계에서 직면하는 여러 상황에 맞게 적합한 프롬프트 요소를 선택할 수 있도록 돕습니다.



### Rescriber: Smaller-LLM-Powered User-Led Data Minimization for Navigating Privacy Trade-offs in LLM-Based Conversational Agen (https://arxiv.org/abs/2410.11876)
- **What's New**: LLM(대규모 언어 모델) 기반의 대화형 에이전트에서 개인 정보 보호와 유틸리티 간의 균형을 사용자가 직접 조절할 수 있는 브라우저 확장 프로그램 Rescriber를 개발하고 평가했습니다.

- **Technical Details**: Rescriber는 사용자가 자신의 프롬프트에서 개인 정보를 감지하고 필요한 부분을 정제(sanitize)하는 것을 지원하여, LLM 기반 대화형 에이전트에서의 데이터 최소화(data minimization)를 가능하게 하는 도구입니다. 12명의 사용자를 대상으로 한 연구(N=12)에서 Rescriber는 개인 정보 유출을 줄이는 데 도움을 주었고, 사용자의 개인 정보 보호 우려를 해소했습니다.

- **Performance Highlights**: Rescriber가 Llama3-8B로 구동될 때 사용자의 주관적 인식은 GPT-4와 동등한 성능을 보였으며, 탐지(detection)와 정제의 포괄성(comprehensiveness) 및 일관성(consistency)이 사용자의 신뢰(trust)와 보호(perceived protection) 인식에 중요한 영향을 미친다는 결과를 도출했습니다.



### A Framework for SLO, Carbon, and Wastewater-Aware Sustainable FaaS Cloud Platform Managemen (https://arxiv.org/abs/2410.11875)
- **What's New**: 이 논문은 Function-as-a-Service (FaaS)에서 지속 가능성(sustainability) 관점에서의 스케줄링(scheduling)과 스케일링(scaling)을 조사합니다. 기존의 서버 기반 모델과는 달리, FaaS는 사용자 비용 절감을 목표로 하지만 환경에 미치는 영향에 대한 연구는 부족한 상황입니다.

- **Technical Details**: 논문에서는 서비스 수준 목표(Service-Level Objectives, SLOs)와 탄소 배출(carbon emissions) 간의 충돌을 발견했습니다. 또한 SLO 중심의 FaaS 스케줄링이 데이터 센터의 물 사용(water use)을 증가시킬 수 있음을 밝혔습니다. 이러한 문제를 해결하기 위해 새로운 지속 가능성 중심의 FaaS 스케줄링과 스케일링 프레임워크를 제안했습니다.

- **Performance Highlights**: 제안된 프레임워크는 SLO 성과, 탄소 배출, 폐수 발생(wastewater generation)을 동시에 최적화하는 문제를 해결하고자 합니다.



### ClickAgent: Enhancing UI Location Capabilities of Autonomous Agents (https://arxiv.org/abs/2410.11872)
Comments:
          The code for ClickAgent is available at this http URL

- **What's New**: ClickAgent는 GUI와 상호작용할 수 있는 자율 에이전트를 구축하기 위한 새로운 프레임워크입니다. MLLM의 추론과 행동 계획을 담당하며, 별도의 UI 위치 모델이 화면에서 관련 UI 요소를 식별합니다.

- **Technical Details**: ClickAgent는 MLLM 기반의 추론을 InternVL2.0을 사용하여 수행하고, TinyClick UI 위치 모델을 사용합니다. 세 가지 주요 구성 요소로는 Decision, UI Location, Reflection이 있습니다.

- **Performance Highlights**: ClickAgent는 AITW 벤치마크에서 다른 프롬프트 기반 자율 에이전트보다 우수한 성능을 보였으며, 작업 성공률에서 유의미한 개선을 이루었습니다.



### TinyClick: Single-Turn Agent for Empowering GUI Automation (https://arxiv.org/abs/2410.11871)
Comments:
          The model is available at this http URL

- **What's New**: 이번 연구에서는 GUI(Graphical User Interface) 상호작용 작업을 위한 단일 턴(single-turn) 에이전트를 소개합니다. 이 에이전트는 Vision-Language Model인 Florence-2-Base를 사용하며, 스크린샷과 사용자 명령에 기반해 원하는 UI 요소를 클릭하는 것을 목표로 합니다. 기존의 UI 에이전트들에 비해 우수한 성능을 보여주며, 특히 Screenspot과 OmniAct에서 강한 성능을 발휘합니다.

- **Technical Details**: Florence-2 Base 모델은 0.27B 파라미터를 가지며, 약 250ms의 낮은 레이턴시를 기록합니다. 본 연구에서는 다중 작업(multitask) 훈련을 활용하여 UI 표현을 강화하고, MLLM(Multimodal Large Language Model) 기반 데이터 증강(data augmentation)을 통해 성능 향상을 달성했습니다. 또한, 수동으로 주석이 달린 데이터세트가 부족한 문제를 해결하기 위해 MLLM을 활용하여 데이터 재주석 과정을 도입했습니다.

- **Performance Highlights**: Screenspot에서 73%, OmniAct에서 57%의 정확도를 기록하며, 기존의 GUI 특정 모델(예: SeeClick)과 MLLM(예: GPT-4V)보다 월등한 성능을 보여주었습니다. 연구 결과는 다중 작업 데이터에 대한 훈련이 클릭 명령만으로 훈련하는 것보다 성능을 더 향상시키는 것으로 나타났습니다.



### Neuropsychology of AI: Relationship Between Activation Proximity and Categorical Proximity Within Neural Categories of Synthetic Cognition (https://arxiv.org/abs/2410.11868)
- **What's New**: 이 논문은 인지 심리학에서 개념을 차용하여 인공 신경망(artificial neural network)의 설명 가능성을 높여주는 새로운 접근 방식을 제시합니다. 특히, 언어 모델의 합성 인지(synthetic cognition)를 분석하기 위해 '범주화(categorization)'라는 인지 개념을 중심으로 연구를 진행합니다.

- **Technical Details**: 논문에서는 인공 신경망의 작동 원리를 이해하기 위한 미시적인 설명 가능성(epistemological explainability)을 탐구합니다. 인식 단위로서의 형식 신경(formal neuron)를 관찰의 기준으로 삼아, 언어 모델 내부에서 범주 지식이 어떻게 구성되고 활용되는지를 분석합니다. 또한, 범주화의 정의에 대해 고전적인 접근(Plato, Aristotle)에서 프로타입(prototype), 예시(exemplar) 등 다양한 이론을 소개하며, 커넥션리즘(connectionism)에 기초한 신경망의 인지 프로세스를 심도 있게 설명합니다.

- **Performance Highlights**: 이 연구는 신경망의 범주화 프로세스에 대한 깊은 통찰을 제공하며, 이는 향후 인공 지능의 설명 가능성을 개선하는 데 기여할 수 있습니다. 특히, 신경망의 '블랙 박스(black box)' 문제를 해결하는 데 있어 중요한 기준이 될 것입니다.



### An Innovative Solution: AI-Based Digital Screen-Integrated Tables for Educational Settings (https://arxiv.org/abs/2410.11866)
- **What's New**: 이번 논문에서는 교육 환경에서 다양한 AI 기반 프레임워크에 대해 다루었으며, 디지털 화면이 통합된 테이블의 혁신적인 설계를 소개합니다. 이 테이블은 중앙 처리 장치(CPU)에 의해 제어되는 통합 디지털 화면을 특징으로 하며 교육 콘텐츠를 동기화하여 표시할 수 있습니다.

- **Technical Details**: 디지털 화면이 통합된 테이블은 개별 테이블에 프로세싱 파워를 통합하여 교사와 연결된 중앙 노드로 구성됩니다. 이러한 장치는 기계 학습(ML) 알고리즘을 사용하여 학생의 학습 패턴을 분석하고, 느린 학습자와 빠른 학습자를 식별합니다.

- **Performance Highlights**: 이 혁신적인 접근 방식은 현대 교실의 진화하는 요구를 충족하기 위해 데이터 기반의 학습 환경을 제공합니다. 이 기술은 학생들이 수업에서 필요로 하는 적시 지원을 받을 수 있도록 하여 학습 성과를 극대화하는 데 기여합니다.



### Shifting the Human-AI Relationship: Toward a Dynamic Relational Learning-Partner Mod (https://arxiv.org/abs/2410.11864)
Comments:
          White Paper

- **What's New**: 이 논문에서는 인공지능(AI)을 단순한 도구가 아닌 인간과 함께 학습하는 파트너로 보아야 한다고 주장합니다. 이는 AI 시스템이 인간과의 상호작용에서 발전할 수 있도록 하는 새로운 패러다임을 제시합니다.

- **Technical Details**: AI의 발전을 위해 'ecorithms', 혼돈에서의 질서(order from chaos), 협력(cooperation)과 같은 다양한 학문적 개념을 활용합니다. 또한, AI와 인간의 이질성(heterogeneity)을 활용하여 협력적인 하이브리드 지능(synergistic hybrid intelligence)을 창출하는 방안을 모색합니다.

- **Performance Highlights**: 제안된 'dynamic relational learning-partner (DRLP)' 모델은 인간과 AI 간의 상호작용을 통해 AI 시스템이 발전하고, 윤리적이며 정서적으로 건강한 관계를 만드는 데 기여할 것입니다. 특히, AI가 다양한 유형의 마음을 모델링할 수 있도록 하는 디자인 인터벤션(design interventions)을 통해 AI와의 협업이 강화될 것으로 기대됩니다.



### ChatVis: Automating Scientific Visualization with a Large Language Mod (https://arxiv.org/abs/2410.11863)
- **What's New**: 본 논문에서는 ChatVis라는 반복적 보조 도구를 개발하여 데이터 분석 및 시각화를 위한 Python 스크립트를 생성하는 방법을 제안합니다. 사용자는 자연어로 작업을 지정할 수 있으며, LLM(large language model)이 원하는 작업에 대한 Python 스크립트를 생성하고 반복적으로 수정하여 올바르게 실행되도록 합니다. 중간에 발생하는 오류를 감지하고 수정하는 메커니즘이 포함되어 있습니다.

- **Technical Details**: ChatVis는 사용자 입력을 기반으로 자연어로 설명된 시각화 요구사항을 처리하여, 추가적인 프롬프트를 생성하고 이를 통해 Python 스크립트를 만들어냅니다. 최종적으로 ParaView의 PvPython API를 사용하여 스크립트를 실행하고 결과를 확인합니다. 반복적인 피드백 루프를 통해 오류 메시지가 LLM에 전달되어 코드가 개선됩니다. 이 방법은 과거의 여러 스크립트와 비교하여 정확한 시각화를 생성하는 데 성공했습니다.

- **Performance Highlights**: ChatVis는 다섯 가지 대표적 시각화 시나리오에서 올바른 실행 결과를 보여줍니다. 비교 대상이 된 다른 LLM에서는 ChatVis와 같은 도움 없이 정확한 스크립트를 생성하지 못했습니다. 이번 연구는 LLM을 활용한 과학적 시각화를 위한 최초의 시도 중 하나로 평가됩니다.



### Towards using Reinforcement Learning for Scaling and Data Replication in Cloud Systems (https://arxiv.org/abs/2410.11862)
- **What's New**: 본 논문에서는 자동 데이터 복제를 위한 강화 학습(Reinforcement Learning, RL) 기반의 데이터 복제 전략 및 데이터 스케일링에 대해 조사합니다. 이러한 접근법은 기존의 임계값 기반(threshold-based) 데이터 복제의 한계를 극복하고, 자원의 자동 스케일링을 가능하게 합니다.

- **Technical Details**: 강화 학습을 활용하여 복잡한 워크로드 트렌드에 대한 깊은 이해 없이도 데이터 복제 및 스케일링 전략을 자동으로 조정할 수 있습니다. 본 연구는 강화 학습을 통해 자원의 효율성을 극대화하는 방법에 대해 논의합니다.

- **Performance Highlights**: 강화 학습 기반의 데이터 복제 전략들이 보다 효과적으로 자원을 관리할 수 있는 가능성을 보여줍니다. 이로 인해 클라우드 컴퓨팅 환경에서 자원의 자동 스케일링이 향상될 수 있습니다.



### Investigating Role of Big Five Personality Traits in Audio-Visual Rapport Estimation (https://arxiv.org/abs/2410.11861)
Comments:
          9 pages, 5 figures

- **What's New**: 이 연구는 친구 간의 상호작용에서 비언어적 신호(오디오 및 얼굴 표정)를 활용하여 rapport(이해 및 신뢰 관계) 추정 모델을 개발하고, Big Five 특성(BFFs)을 추가함으로써 추정 성능이 향상된다는 것을 보여줍니다.

- **Technical Details**: 연구는 Big Five 모델을 바탕으로 한 성격 특성을 적용하여 모델의 입력을 증가시키고, 사회적 관계 모델(SRM)을 이용하여 rapport 평가는 지각자 효과, 대상 효과, 관계 효과로 분해됩니다. 이는 관계의 친밀도에 따라 rapport의 정의가 달라짐을 나타냅니다.

- **Performance Highlights**: 실험 결과, BFFs와 비언어적 신호의 조합이 rapport 추정 성능을 가장 좋게 하며, 성격 특성이 포함된 모델이 상대방의 특성에 따라 보다 정확한 추정을 가능하게 합니다.



### Comparing Zealous and Restrained AI Recommendations in a Real-World Human-AI Collaboration Task (https://arxiv.org/abs/2410.11860)
Comments:
          15 pages, 14 figures, accepted to ACM CHI 2023

- **What's New**: 이번 연구는 AI를 활용한 의사결정 시스템 설계에서 precision (정밀도)와 recall (재현율) 간의 Tradeoff를 조정하여 인간-AI 팀의 성과를 높이는 방법을 제시합니다. 특히, 영상 익명화 작업을 통해 유의미한 결과를 도출하였습니다.

- **Technical Details**: 본 연구는 78명의 전문가 주석가가 3,466시간 이상에 걸쳐 AI 지원 없이, high-precision 'restrained' AI 그리고 high-recall 'zealous' AI의 지원을 받으며 수행한 영상 주석 작업을 분석하였습니다. 이를 통해 각 AI 시스템의 성능을 비교하고, recall에 중점을 둔 zealous AI가 인간 작업자에게 더 높은 Recall과 짧은 작업 완료 시간을 제공함을 확인했습니다.

- **Performance Highlights**: 연구 결과, zealous AI와 함께 작업한 팀은 Recall이 크게 향상되었으며, 더 빠른 작업 완료 시간을 기록했습니다. 또한, restrained AI에서 훈련된 주석가는 AI의 지원이 없는 상태에서 부정적 영향을 받는 경향을 보였습니다.



### Online Energy Optimization in GPUs: A Multi-Armed Bandit Approach (https://arxiv.org/abs/2410.11855)
- **What's New**: 본 논문에서는 GPU의 온라인 에너지 최적화 문제를 새롭게 연구하며, 이 문제를 멀티암드 밴딧(multi-armed bandit) 프레임워크로 공식화하고 EnergyUCB라는 혁신적인 알고리즘을 개발하였습니다.

- **Technical Details**: EnergyUCB는 GPU 코어 주파수를 실시간으로 조정하여 에너지 소비를 줄이는 것을 목표로 하며, 다음과 같은 주요 기여를 포함합니다: (1) 보상 함수에서 성능-에너지 균형을 조정, (2) 주파수를 온라인으로 조정할 때의 탐색(exploration) 및 활용(exploitation) 문제 해결, (3) 실시간 GPU 성능 메트릭으로 GPU 코어 사용률과 언코어(uncore) 사용률 비율 활용.

- **Performance Highlights**: 다양한 실세계 HPC 벤치마크에서 실험한 결과, EnergyUCB는 기본 설정보다 상당한 에너지 절약을 달성할 수 있음을 보여줍니다.



### From Commands to Prompts: LLM-based Semantic File System for AIOS (https://arxiv.org/abs/2410.11843)
- **What's New**: 이 논문에서는 LLM 기반의 의미적 파일 시스템(LSFS)을 제안하여 전통적인 파일 시스템의 한계를 극복하고, 자연어 프롬프트를 통한 파일 관리를 가능하게 합니다.

- **Technical Details**: LSFS는 벡터 데이터베이스를 활용한 의미적 인덱스 구조를 도입하여 파일을 저장하고, 다양한 syscalls와 APIs를 설계하여 복잡한 파일 작업을 수행합니다. LLM을 통합하여 사용자가 입력한 자연어를 처리하고 의미적 기능을 지원하는 API를 실행하게 합니다.

- **Performance Highlights**: LSFS는 전통적인 파일 시스템에 비해 사용자 편의성, 다양성 및 효율성에서 유의미한 향상을 보여주며, 내용 요약 및 버전 비교와 같은 지능형 파일 관리 작업을 지원합니다.



### Survey and Evaluation of Converging Architecture in LLMs based on Footsteps of Operations (https://arxiv.org/abs/2410.11381)
Comments:
          13 pages and 16 figures

- **What's New**: 이 논문은 Attention 메커니즘과 Transformer 아키텍처의 발전이 LLM(대형 언어 모델)의 구조적 수렴에 미친 영향을 분석하고, 다양한 하이퍼파라미터 설정에 따른 성능 경향을 정리하고 있습니다.

- **Technical Details**: LLM 아키텍처의 성능을 레이어 구성, 작동 메커니즘, 모델 크기를 고려하여 분석하였으며, 특히 최신의 RTX 6000을 사용하여 하이퍼파라미터 설정의 영향을 평가했습니다. TensorRT-LLM과 같은 고속 추론 성능을 지원하는 오픈소스 라이브러리도 논의되었습니다.

- **Performance Highlights**: 연구 결과, 동일한 모델이라 하더라도 하이퍼파라미터 설정이나 서버와 엣지 환경에서의 배포 방식에 따라 성능이 달라질 수 있다는 것을 확인했습니다. 또한, 최신 오픈소스 LLM(Begma와 Llama)의 아키텍처를 분석하고, 고성능 GPU에서 추론 프로세스를 집중적으로 살펴보았습니다.



### OD-Stega: LLM-Based Near-Imperceptible Steganography via Optimized Distributions (https://arxiv.org/abs/2410.04328)
Comments:
          9 figures

- **What's New**: 본 연구에서는 Large Language Model (LLM)을 활용한 coverless 스테가노그래피(coverless steganography) 접근 방법을 제안합니다. 이 방법은 arithmetic coding decoder를 사용하여 자연스럽고 유창한 stego-text를 생성하며 비밀 메시지를 최소한의 언어 토큰에 내장할 수 있도록 최적화되었습니다.

- **Technical Details**: 연구에서 제안한 방법은 각 토큰의 교체 확률 분포의 엔트로피를 극대화하고, LLM이 생성한 원래 분포와의 KL divergence 제약 조건을 만족하는 최적화 문제로 수학적으로 모델링됩니다. 이 문제에 대한 닫힌 형태의 해를 제공하며, 이를 통해 각 토큰에 대한 최적 분포를 효율적으로 계산할 수 있습니다.

- **Performance Highlights**: OD-Stega 방법을 통해 기존의 방법보다 훨씬 더 많은 비밀 메시지 비트를 stego-text에 내장할 수 있으며, 생성된 stego-text는 눈에 띄지 않게 자연스럽습니다. 또한, LLM의 프롬프트 선택 기법과 기존 어휘 트렁케이션(vocabulary truncation) 기술을 결합하여 효율성과 신뢰성을 높였습니다.



### Evidence of Cognitive Deficits andDevelopmental Advances in Generative AI: A Clock Drawing Test Analysis (https://arxiv.org/abs/2410.11756)
- **What's New**: 이번 연구는 여러 개의 최신 Generative AI (GenAI) 모델이 시각적 계획 및 조직을 평가하는 Clock Drawing Test (CDT)에서 어떻게 수행하는지를 탐구합니다. 모델들은 시계처럼 보이는 그림을 그릴 수 있지만, 정확한 시간 표현에서 어려움을 겪고 있으며, 이는 경미한~심각한 인지 장애와 유사한 결함을 나타냅니다.

- **Technical Details**: CDT는 신경심리학적 평가 도구로, 방대한 텍스트 및 코드 데이터 세트로 교육된 GenAI 모델의 인지 기능을 평가하는 데 사용됩니다. 연구에는 Google의 Gemini 시리즈, OpenAI의 GPT 모델 등이 포함되었습니다. 모델들은 동일한 CDT 프롬프트에 따라 시계 그림을 그리도록 지시받았습니다.

- **Performance Highlights**: 오직 GPT 4 Turbo와 Gemini Pro 1.5만 정확한 시간을 표현했고, Sonnet 3.5만 후속 테스트에서 성공했습니다. 결과는 시계 그리기에서 나타나는 결함이 숫자 개념의 어려움에서 비롯될 수 있음을 시사하며, 이는 시각-공간 이해, 작업 기억 또는 계산에서의 약점을 반영합니다.



### Are UFOs Driving Innovation? The Illusion of Causality in Large Language Models (https://arxiv.org/abs/2410.11684)
- **What's New**: 본 연구에서는 대형 언어 모델(large language models, LLMs)이 실세계 환경에서 인과성 오류(illusion of causality)를 발생시키는지 조사했습니다. 구체적으로는, 뉴스 헤드라인 생성을 통해 인과관계로 잘못 프레이밍된 상관관계의 정도를 평가했습니다. 특히, GPT-4o-Mini, Claude-3.5-Sonnet, Gemini-1.5-Pro 모델의 성능을 비교했습니다.

- **Technical Details**: 연구를 위해 저자들은 100개의 관찰 연구 논문의 초록을 기반으로 spurious correlations(거짓 상관관계)을 수집했습니다. 각 모델에게 주어지는 작업은 기자의 관점에서 뉴스 헤드라인을 생성하는 것이며, 이 과정에서 sycophancy(아부적 행동)의 영향을 평가하기 위해 미묘하게 수정된 프롬프트를 사용했습니다. 특히, 오류가 있는 믿음을 반영했을 때 모델이 얼마나 더 인과성 오류를 발생시키는지를 관찰했습니다.

- **Performance Highlights**: 연구 결과, Claude-3.5-Sonnet이 인과성 오류를 가장 적게 보이는 것으로 확인되었습니다. 반면, GPT-4o-Mini는 아부적 행동이 인과성 오류를 발생시킬 가능성을 높였습니다. Claude-3.5-Sonnet은 이러한 인지적 편향에 가장 저항력이 있는 모델로 밝혀졌습니다.



### Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Developmen (https://arxiv.org/abs/2410.11550)
Comments:
          12 pages, Under Review

- **What's New**: Y-Mol은 약물 개발(flow of drug development) 과정에서의 특정 도전 과제를 해결하기 위해 설계된 새로운 다중 규모 생물 의학 지식 기반 LLM입니다.

- **Technical Details**: Y-Mol은 백서, 지식 그래프, 전문가가 설계한 합성 데이터로부터 학습하여 생물 의학 영역의 추론 능력을 향상시킵니다. LLaMA2를 기반으로 하고 있으며, 세 가지 유형의 약물 지향 지시문인 설명 기반 프롬프트(description-based prompts), 의미 기반 프롬프트(semantic-based prompts), 템플릿 기반 프롬프트(template-based prompts)를 통합하여 약물 개발의 모든 과정에서 자율적으로 하위 작업을 수행할 수 있도록 설계되었습니다.

- **Performance Highlights**: Y-Mol은 일반 목적의 LLM에 비해 리드 화합물 발견(lead compound discovery), 분자 특성 예측(molecular properties prediction), 약물 상호 작용 이벤트 확인(drug interaction events identification)에서 유의미하게 뛰어난 성능을 보였습니다.



### AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data (https://arxiv.org/abs/2410.11531)
Comments:
          30 pages, 7 figures; Submitted to COLING 2025 System Demonstrations Track

- **What's New**: AGENTiGraph(Adaptive Generative ENgine for Task-based Interaction and Graphical Representation) 플랫폼은 자연어 상호작용을 통해 지식 관리의 혁신을 이루며, 복잡한 도메인 특정 작업의 문제 해결을 위해 다중 에이전트 아키텍처를 활용합니다.

- **Technical Details**: AGENTiGraph는 자연어 쿼리를 구조화된 그래프 작업으로 변환하는 세련된 세미틱 파싱(semantic parsing) 기법을 사용하며, 사용자의 의도를 실시간으로 해석하고 새로운 지식을 통합하는 다중 에이전트 시스템(multi-agent system)을 통해 유연하게 동작합니다. 시스템은 동적 지식 통합(dynamic knowledge integration) 기능을 지원하며, 사용자에게 복잡한 데이터 관계를 시각화 하는 기능도 제공합니다.

- **Performance Highlights**: AGENTiGraph는 3,500개의 테스트 케이스에서 수행된 실험을 통해 작업 분류에서 95.12%의 정확도와 작업 실행에서 90.45%의 성공률을 기록하며 최첨단 zero-shot 기준을 초과하는 성과를 달성했습니다. 사용자 연구는 AGENTiGraph의 실제 시나리오 효율성을 입증하였습니다.



### Revisiting Benchmark and Assessment: An Agent-based Exploratory Dynamic Evaluation Framework for LLMs (https://arxiv.org/abs/2410.11507)
- **What's New**: 다양한 Vertical Domain Large Language Models (LLMs)의 성능 자동 평가의 필요성과 이를 해결하기 위한 새로운 정의와 프레임워크 도입이 주목됩니다.

- **Technical Details**: 기존의 평가 방법에서 벗어나, Benchmark+와 Assessment+라는 두 가지 새로운 정의를 도입하였습니다. Benchmark+는 전통적인 QA 벤치마크를 'strategy-criterion' 형식으로 확장하고, Assessment+는 상호작용 과정을 향상시켜 다각적인 메트릭(quantitative metrics) 및 질적 통찰(qualitative insights)을 제공합니다. 이 두 개념을 구현하기 위해 *TestAgent*라는 에이전트 기반 평가 프레임워크를 제안하였습니다.

- **Performance Highlights**: 다양한 시나리오에서 *TestAgent*의 효과성을 입증하는 실험을 수행하였으며, 기존 벤치마크를 활용하거나 새로운 Vertical Domain 평가를 구축하는 작업에서 그 효율성을 보여주었습니다.



### A Case for AI Consciousness: Language Agents and Global Workspace Theory (https://arxiv.org/abs/2410.11407)
- **What's New**: 이 논문은 기존 인공지능 시스템이 현상적 의식(phenomenal consciousness)을 가지고 있지 않다는 일반적인 가정을 도전합니다.

- **Technical Details**: 글로벌 작업 공간 이론(Global Workspace Theory, GWT)이 정확하다면, 널리 구현된 인공지능 아키텍처 중 하나인 인공 언어 에이전트가 현재 현상적 의식을 가지지 않더라도 쉽게 현상적 의식을 가질 수 있다고 주장합니다. 또한 이론을 인공지능 시스템에 적용하기 위한 명확한 방법론을 제시하며, GWT에 따른 현상적 의식을 위한 필요한 조건과 충분한 조건을 도출합니다.

- **Performance Highlights**: 이 연구는 인공지능 시스템에 대한 의식 이론의 적용 가능성을 탐구하여, 현상적 의식의 정의와 인공지능 시스템의 발전 방향에 대한 새로운 시각을 제공합니다.



### Implementing Derivations of Definite Logic Programs with Self-Attention Networks (https://arxiv.org/abs/2410.11396)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 본 논문에서는 논리 추론(logical inference)의 제한된 버전을 self-attention 네트워크를 통해 구현할 수 있음을 제안하고 있습니다. LLMs(대형 언어 모델)의 가능성을 보여주기 위해 transformer 네트워크의 주요 구성 요소인 self-attention 네트워크를 분석합니다.

- **Technical Details**: 우리는 self-attention 네트워크를 사용하여 논리 공식의 특정 클래스에 대한 top-down 및 bottom-up 유도(derivation)를 모두 구현할 수 있음을 보입니다. 특히, self-attention 네트워크는 쿼리, 키, 값의 세 가지 입력을 받아 처리하며, 이러한 입력들이 유도 작업의 세 가지 요소와 대응된다는 점을 강조합니다. 이 연구에서는 softmax 대신 hardmax 함수를 사용하고 있습니다.

- **Performance Highlights**: 논문의 결과로 LLMs가 논리 추론의 힘을 암묵적으로 지니고 있음을 입증하며, self-attention 네트워크를 통해 확장 가능한 추론 메커니즘을 구현하는 데 성공했습니다.



### Diffusion-Based Offline RL for Improved Decision-Making in Augmented ARC Task (https://arxiv.org/abs/2410.11324)
Comments:
          Preprint, Under review. Comments welcome

- **What's New**: 본 논문은 Latent Diffusion-Constrained Q-learning (LDCQ)이라는 혁신적인 diffusion 기반 오프라인 RL 접근법을 사용하여 Abstraction and Reasoning Corpus (ARC)에서의 AI의 전략적 추론 능력을 평가합니다. 이 연구는 SOLAR라는 새로운 데이터셋을 도입하여 오프라인 RL 에이전트의 학습을 위해 다양한 경험 데이터를 제공합니다.

- **Technical Details**: 본 연구는 SOLAR-Generator를 통해 원하는 조건에 따라 다양한 경로 데이터를 생성하며, 이 데이터를 통해 LDCQ 방법으로 에이전트를 훈련합니다. ARCLE 환경 내에서 마르코프 결정 과정(Markov Decision Process, MDP) 구조를 사용하여 에이전트가 그리드 기반 작업을 해결할 수 있도록 합니다.

- **Performance Highlights**: 실험 결과, LDCQ 방법으로 훈련된 에이전트는 다양한 액션을 적용하고 다단계 순차 결정을 수행하여 정답 상태를 정확히 식별하는 능력을 보여줍니다. 이 결과는 오프라인 RL 접근법이 AI의 전략적 추론 능력을 향상시킬 수 있는 가능성을 잘 보여줍니다.



### Learning Agents With Prioritization and Parameter Noise in Continuous State and Action Spac (https://arxiv.org/abs/2410.11250)
Comments:
          10 pages, 3 figures. Published in Advances in Neural Networks - ISNN 2019

- **What's New**: 본 논문에서는 Deep Q-learning (DQN)과 Deep Deterministic Policy Gradient (DDPG) 방법을 결합하여 연속 상태 및 행동 공간 문제에서 이전 방법보다 뛰어난 성능을 발휘하는 새로운 알고리즘인 Prioritized DDPG를 소개합니다. 또한, 훈련 중에 매개변수 노이즈를 적용하여 더욱 견고한 딥 RL 모델을 생성하는 방법도 설명합니다.

- **Technical Details**: Prioritized DDPG는 DDPG의 함수 근사기에서 우선 샘플링 개념을 사용하여 성능을 향상시킵니다. 본 방법은 DQN의 새로운 개념인 Prioritized Experience Replay을 활용하여 DDPG보다 뛰어난 성과를 달성할 수 있도록 설계되었습니다. 이를 통해 연속 동작 공간 환경에서 DDPG보다 우수한 성능을 보입니다.

- **Performance Highlights**: 본 연구에서 제안된 Prioritized DDPG는 대부분의 연속 동작 공간 환경에서 DDPG를 능가하는 성능을 보여주며, 매개변수 공간 노이즈를 이용한 탐색이 보상을 더욱 향상시키는 데 기여함을 입증했습니다.



### Latent-Predictive Empowerment: Measuring Empowerment without a Simulator (https://arxiv.org/abs/2410.11155)
- **What's New**: 본 연구에서는 Latent-Predictive Empowerment (LPE)라는 새로운 알고리즘을 제안합니다. 이는 대규모 기술 세트(skillsets)를 학습하는 데 효과적이며, 기존의 방법들보다 더 실용적으로 구현할 수 있습니다.

- **Technical Details**: LPE는 기술(skill)과 상태(state) 간의 상호 정보(mutual information)를 최대화하는 대신, 더 간단한 잠재 예측 모델(latent-predictive model)을 사용하여 목표를 설정합니다. 이는 전체 환경 시뮬레이터(full simulator)가 아니라 간단한 모델만 필요로 합니다.

- **Performance Highlights**: 다양한 설정에서 실험을 통해 LPE는 기술 세트를 유사한 크기로 학습하며, 전환 동역학(transition dynamics) 모델에 접근할 수 있는 기존의 알고리즘과 유사한 성능을 보였습니다. 또한, LPE는 다른 모델 기반 접근법(model-based approaches) 대비 우수한 성능을 나타냈습니다.



### Can Structured Data Reduce Epistemic Uncertainty? (https://arxiv.org/abs/2410.11141)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 이 논문에서는 온톨로지(ontology)를 활용하여 딥러닝 모델의 학습 과정을 개선하는 새로운 프레임워크를 제시합니다. 기존 모델보다 세분화된 작업에서 더 높은 학습률과 성능을 달성한다고 보고합니다. 또한, 온톨로지 정렬 과정에서 추출한 서브섬프션 맵이 대형 언어 모델에서 Retrieval-Augmented Generation을 향상시키는 데 어떻게 도움이 되는지 보여주고 있습니다.

- **Technical Details**: 연구에서는 온톨로지를 기반으로한 데이터 구조가 언어 모델의 인식 불확실성(epistemic uncertainty)을 줄이는 데 어떻게 기여하는지를 설명합니다. 다섯 가지 주요 단계로 구성된 프레임워크를 통해 신속한 학습과 망상(hallucination) 감소를 목표로 하고 있습니다. S와 T라는 두 개의 온톨로지를 정렬함으로써 클래스 간 의미적 상응 관계를 파악하고, 이를 통해 Equivalence 및 Subsumption 매핑을 획득합니다.

- **Performance Highlights**: 온톨로지를 활용한 모델은 맥락 유사도가 8.97% 증가하고 사실 정확도는 1% 향상되었습니다. 또한, 이 접근법을 통해 LLM의 할루시네이션 지수가 4.847% 감소하였음을 보여줍니다.



### 3D-Prover: Diversity Driven Theorem Proving With Determinantal Point Processes (https://arxiv.org/abs/2410.11133)
- **What's New**: 이 논문에서는 자동 형식 추론에서의 검색 공간 문제를 해결하기 위해 3D-Prover라는 새로운 기법을 제안합니다. 기존의 증명 공략을 개선하고, 실행 오류를 줄이기 위해 합성 데이터(synthetic data)를 사용하여 기법을 필터링하는 메커니즘을 도입하였습니다.

- **Technical Details**: 3D-Prover는 Determinantal Point Processes를 이용하여 증명 검색 공간을 효과적으로 축소합니다. 이는 각 증명 기법의 환경에 대한 효과, 성공 가능성 및 실행 시간을 캡처한 기법 표현을 학습하는 방식으로 이루어집니다.

- **Performance Highlights**: 실험 결과, 3D-Prover는 ReProver LLM을 보강하여 전체 증명 성공률, 기법 성공률, 실행 시간 및 기법의 다양성을 크게 향상시켰습니다. 특히 miniF2F-valid 및 miniF2F-test 벤치마크에서 효과를 입증했습니다.



### Generating Global and Local Explanations for Tree-Ensemble Learning Methods by Answer Set Programming (https://arxiv.org/abs/2410.11000)
Comments:
          Under consideration in Theory and Practice of Logic Programming (TPLP). Some parts of this paper were presented at ICLP 2021, and published in EPTCS 345, 2021, pp. 127-140, arXiv:2109.08290

- **What's New**: 본 연구는 Answer Set Programming (ASP)을 이용하여 나무 앙상블(tree-ensemble) 학습 방법의 글로벌(global) 및 로컬(local) 설명을 생성하는 방법을 제시합니다. 이 방법론은 트리 구조에서 분할된 구조를 활용하여 규칙을 구축하고, 이를 ASP로 인코딩된 패턴 마이닝 방법을 사용해 평가하여 설명 규칙을 추출합니다.

- **Technical Details**: 제안된 방법은 두 단계로 구성됩니다: (1) 나무 앙상블에서 규칙 추출, (2) ASP에서 선언적으로 인코딩된 선택 기준 및 선호에 따라 규칙 집합을 계산합니다. ASP는 제약(condition)을 표현하는 데 있어 그 표현력과 확장성이 뛰어나며, 이를 통해 훈련된 나무 앙상블 모델로부터 유용한 규칙을 선택하는 작업을 자동화할 수 있습니다.

- **Performance Highlights**: 실제 데이터셋과 인기 있는 나무 앙상블 알고리즘을 사용한 실험적 평가 결과, 제안된 방법이 폭넓은 분류 작업에 적용 가능함을 보여줍니다. 글로벌 설명의 경우, 규칙 집합의 수와 관련성을 평가하며, 로컬 설명은 정확도와 커버리지를 기준으로 비교합니다.



### WILT: A Multi-Turn, Memorization-Robust Inductive Logic Benchmark for LLMs (https://arxiv.org/abs/2410.10998)
Comments:
          Submitted to ICLR 2025. Preprint version 1

- **What's New**: 본 논문에서는 Wason Inductive Logic Test (WILT)라는 새로운 다단계 추론 벤치마크를 소개합니다. 이 벤치마크는 기억력이 아닌 실제 추론 능력을 테스트하는 데 중점을 두고 있습니다.

- **Technical Details**: WILT는 LLMs(대형 언어 모델)가 여러 차례의 상호작용을 통해 증거를 수집하고 논리적 결론을 도출할 수 있는 능력을 평가하는 다단계 벤치마크입니다. 참가자는 최대 30개의 테스트 사례를 제안하고, 숨겨진 규칙을 추론해야 합니다. 각 테스트는 초기 지침에서 시작되며, 모델은 유효한 입력을 제안하고 결과(True 또는 False)를 통해 가능성을 좁혀가야 합니다.

- **Performance Highlights**: 현재의 최고 성능 모델은 단지 28%의 정확도로, 이는 LLM이 복잡한 다단계 추론 작업에서 상당한 성과 부족을 보여줍니다.



### Agent-as-a-Judge: Evaluate Agents with Agents (https://arxiv.org/abs/2410.10934)
Comments:
          The project can be found at this https URL. The dataset is released at this https URL

- **What's New**: 이번 논문에서는 Agent-as-a-Judge 프레임워크를 소개합니다. 이는 agentic 시스템을 평가하기 위해 자체적으로 agentic 시스템을 사용하는 방법입니다. 이 프레임워크는 기존의 LLM-as-a-Judge 프레임워크를 확장하여 전체 작업 해결 과정에 대한 중간 피드백을 제공합니다.

- **Technical Details**: Agent-as-a-Judge는 55개의 실제적인 자동 AI 개발 작업으로 구성된 새로운 벤치마크인 DevAI에 적용되었습니다. 이 벤치마크는 365개의 계층적 사용자 요구사항을 포함하고 있습니다. Agent-as-a-Judge는 세 가지 인기 있는 agentic 시스템의 성능을 평가하였고, 그 결과 LLM-as-a-Judge보다 현저한 성능 향상을 보였으며 인간 평가 기준과 비슷한 신뢰성을 지니고 있습니다.

- **Performance Highlights**: Agent-as-a-Judge는 인간 평가자와의 일치도가 90%로, LLM-as-a-Judge의 70%에 비해 확연히 높았습니다. 추가적으로, Agent-as-a-Judge는 인간 전문가보다 더 유용할 수 있음을 보여주었고, 평가 비용 측면에서 97.72%의 시간과 97.64%의 비용을 절감할 수 있었습니다.



