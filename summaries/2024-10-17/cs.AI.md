New uploads on arXiv(cs.CL)

### Context is Key(NMF): Modelling Topical Information Dynamics in Chinese Diaspora Media (https://arxiv.org/abs/2410.12791)
Comments:
          Accepted to the 2024 Computational Humanities Research Conference (CHR)

- **What's New**: 중국 공화국(China)의 선거 개입 관련 연구에서, KeyNMF라는 새로운 정적 및 동적 주제 모델링 접근 방식이 제안되었습니다. 이 연구는 중국 언론 내 정보 역동성을 연구하기 위한 파이프라인을 개발하여, 2024년 유럽 의회 선거 전후의 데이터 분석에 적용했습니다.

- **Technical Details**: KeyNMF는 transformer 기반의 문맥적 임베딩 모델을 활용하여, 정적 및 동적 주제 모델링을 수행합니다. 이 접근법은 각 문서에서 키워드 중요도를 계산하고, NMF(Non-negative Matrix Factorization)를 통해 이를 분해하는 구조를 가지고 있습니다. 또한, 유럽의 중국 디아스포라 미디어에 대한 자료를 분석하여 정보의 새로움과 공명을 측정하며, 시계열 데이터의 변화에 따라 주제를 효과적으로 추적할 수 있습니다.

- **Performance Highlights**: KeyNMF 접근법은 중국 데이터셋에 대해 효과적임을 입증하며, 복잡한 시스템 내 정보 역동성을 묘사하는 기존 기법들과 통합되어 실험됩니다. 연구 결과는 중국 디아스포라 미디어의 정보 역동성의 효과성을 입증함과 동시에, 향후 연구를 위한 기초 자료를 제공합니다.



### Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception (https://arxiv.org/abs/2410.12788)
- **What's New**: 이 논문에서는 Retrieval-Augmented Generation (RAG) 방법론에서 중요한 텍스트 청킹(text chunking)의 이전 이해를 확장하는 "메타 청킹(Meta-Chunking)"이라는 새로운 개념을 도입합니다.

- **Technical Details**: 메타 청킹은 문장과 문단 사이의 세밀한 경계를 정의합니다. 이 논문에서 제안된 두 가지 전략인 Margin Sampling Chunking과 Perplexity Chunking을 통해 LLMs (Large Language Models)를 사용하여 텍스트 청킹 과정을 세분화하였습니다.

- **Performance Highlights**: 11개의 데이터셋에서 실험한 결과, 메타 청킹이 RAG 기반의 단일 및 다단계 질문 응답 성능을 더 효율적으로 개선함을 보였습니다. 예를 들어, 2WikiMultihopQA 데이터셋에서는 유사도 청킹(similarity chunking)보다 1.32 높은 성능을 보였고, 소요 시간은 45.8%에 불과했습니다.



### Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information (https://arxiv.org/abs/2410.12774)
Comments:
          main paper 12 pages, Appendix 7 pages, 1 figure, 18 tables

- **What's New**: 이 연구에서는 다중 작업 학습(Multi-task Learning, MTL)에서의 작업 관련성을 정의하기 위해 pointwise V-usable 정보(점별 V-사용 가능 정보, PVI)를 기반으로 한 새로운 메트릭을 제안합니다. PVI는 데이터셋이 주어진 모델에 대해 얼마나 많은 사용 가능한 정보를 포함하고 있는지를 추정하는 최근의 기법입니다.

- **Technical Details**: PVI는 모델에 따라 데이터 인스턴스의 난이도를 추정하며, 이를 통해 비슷한 난이도의 작업들을 그룹화하여 MTL에서 성능을 극대화할 수 있다고 가정합니다. 15개의 NLP 데이터셋을 이용한 실험을 통해 MTL 결과를 기존 단일 학습자 모델 및 최신 대형 언어 모델과 비교하였습니다. 또한, PVI 기반 작업 그룹화를 통한 성능 비교를 실시하였습니다.

- **Performance Highlights**: PVI 추정치가 비슷한 작업들을 그룹화함으로써 다중 작업 학습이 성능을 개선하고, 총 파라미터 수를 줄이면서도 다양한 도메인에 걸쳐 일관된 성능을 보였습니다. 이 연구는 PVI 추정값을 이용한 작업 그룹화가 STL 성능을 초과할 수 있음을 입증하였습니다.



### Unitary Multi-Margin BERT for Robust Natural Language Processing (https://arxiv.org/abs/2410.12759)
- **What's New**: 최근 딥 러닝에서 적대적 공격에 대한 발전으로 인해 자연어 처리(NLP) 시스템이 위험에 처해 있습니다. 이 논문은 Bidirectional Encoder Representations from Transformers(BERT)의 견고성을 크게 향상시키는 보편적인 기술인 Unitary Multi-Margin BERT(UniBERT)를 소개합니다.

- **Technical Details**: UniBERT는 cross-entropy loss를 multi-margin loss로 교체하고, weight 매트릭스를 단위 행렬로 제한하여 적대적 공격에 대한 강인성을 강화합니다. 이러한 접근 방식을 통해 다중 클래스를 구분하는 신경 표현을 보다 뚜렷하게 분리합니다. 수치적으로, UniBERT는 공격 후 분류 정확도를 5.3% 개선하여 73.8%에 도달하며, 단일 스칼라 매개변수를 통해 사전 및 사후 정확도 간의 트레이드오프를 조정할 수 있습니다.

- **Performance Highlights**: UniBERT는 기존의 방어 방법들과 비교할 때 여러 작업에서 공격 후 정확도를 유의미하게 향상시킵니다. 특히, 우리의 모델은 적대적 훈련 방식에 대한 의존 없이 설계되었으며, 간단한 구현이 가능합니다.



### StyleDistance: Stronger Content-Independent Style Embeddings with Synthetic Parallel Examples (https://arxiv.org/abs/2410.12757)
- **What's New**: 이 논문에서는 StyleDistance라는 새로운 접근 방식을 도입하여 컨텐츠와 독립적인 스타일 임베딩을 강화하는 방법을 제안합니다. 기존의 방식들이 콘텐츠와 스타일을 혼합할 위험이 있던 점을 해결하기 위해, 대형 언어 모델을 활용하여 스타일 변화를 조절한 거의 동일한 패러프레이즈의 합성 데이터셋을 생성합니다.

- **Technical Details**: StyleDistance는 40가지 스타일 특징을 기반으로 긍정적 및 부정적인 예시를 생산하여 보다 정밀한 대비 학습(contrastive learning)을 가능하게 합니다. 이러한 합성 데이터는 기존 데이터셋에서 발생하는 콘텐츠 누출(content leakage) 문제에 대해 더 강건합니다. 이 연구에서는 인간 및 자동 평가를 통해 StyleDistance 임베딩의 품질을 검토하였습니다.

- **Performance Highlights**: StyleDistance는 스타일 임베딩의 콘텐츠 독립성(content independence)을 획기적으로 개선하여, 실제 벤치마크에서 일반화가 가능하다는 것을 입증하였고, 다운스트림 애플리케이션에서 기존 스타일 표현을 초월하는 성능을 보였습니다.



### Comparative Analysis of Extrinsic Factors for NER in French (https://arxiv.org/abs/2410.12750)
- **What's New**: 이 논문은 프랑스어 명명실체인식(NER) 향상을 위한 다양한 외부 요인의 영향을 분석하고, 제한된 데이터에서 모델 성능을 높이는 기법들을 탐색합니다.

- **Technical Details**: 논문은 세 가지 주석 기법(i.e., IO, BIO, BIOES)과 두 가지 데이터 증강 기법(label-wise token replacement, shuffle within segments)을 사용하여 French NER 성능을 향상시키는 방법을 제시합니다. 모델은 조건부 랜덤 필드(CRF)와 LSTM으로 구축되었으며, Transformer 기반의 임베딩(Flaubert)을 활용했습니다.

- **Performance Highlights**: BIOES 주석 기법을 사용하여 모델의 F1 점수를 62.41에서 79.39로 향상시켰습니다. LSTM과 Transformer 기반 임베딩 결합이 성능을 크게 개선하며, 데이터 증강 기법을 적용한 결과 훈련 데이터셋과 엔티티 수가 약 2배 증가했습니다.



### WorldMedQA-V: a multilingual, multimodal medical examination dataset for multimodal language models evaluation (https://arxiv.org/abs/2410.12722)
Comments:
          submitted for review, total of 14 pages

- **What's New**: 이번 연구에서는 헬스케어 환경에서 VLM(vision language models)의 성능 평가를 위해 다국어, 다모달의 가치 있는 벤치마크 데이터셋인 WorldMedQA-V를 소개합니다. 이 데이터셋은 브라질, 이스라엘, 일본, 스페인 등 네 개 국가의 의료 이미지를 통합하여 568개의 레이블이 있는 선택형 QA를 포함하고 있습니다.

- **Technical Details**: WorldMedQA-V는 다양한 국가의 언어 환경을 지원하며, 의료 전문가에 의해 검증된 새로운 다모달 시험 문제를 포함합니다. 연구에서는 의료 시험 데이터에서 이미지 데이터를 추가할 때 성능 및 안정성에 미치는 영향을 조사하고, 다양한 언어 및 지역의 모델 성능 차이를 평가합니다.

- **Performance Highlights**: GPT4o 모델이 WorldMedQA-V에서 가장 높은 성능을 보였으며, 특히 일본 데이터셋에서 88%의 정확도를 달성했습니다. 전반적으로 모델은 영어로 번역된 데이터셋에서 더 나은 성과를 보였으며, 일부 데이터셋에서는 70%를 초과하는 성과를 기록했습니다.



### WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines (https://arxiv.org/abs/2410.12705)
- **What's New**: WorldCuisines라는 대규모 벤치마크가 소개되어 VLMs의 다문화적 및 다언어적 이해력을 평가할 수 있는 새로운 기준을 제시합니다. 이 벤치마크는 30개 언어와 방언에서 각각의 텍스트-이미지 쌍을 포함하고 있어 다문화적인 VQA 데이터셋으로는 가장 큰 규모를 자랑합니다.

- **Technical Details**: 이 연구는 VLMs를 평가하기 위해 100만 개 이상의 고품질의 다언어 및 다문화 텍스트-이미지 쌍으로 구성된 WorldCuisines를 개발했습니다. 벤치마크는 2가지 작업을 포함합니다: (1) 요리 이름 예측, (2) 요리가 일반적으로 소비되는 위치 예측. VQA 데이터셋은 30개 언어와 방언으로 구성되어 있으며, 다양한 질문 유형에 대한 평가를 포함합니다.

- **Performance Highlights**: VLMs는 적절한 위치 맥락에서 더 좋은 성능을 보였으나, 적대적인 맥락에서는 어려움을 겪었고, 특정 지역 요리와 언어 예측에서의 어려움이 드러났습니다. 데이터셋과 관련된 주의 깊은 메타데이터와 이미지도 함께 제공되어 향후 연구 지원을 기대합니다.



### Building Better: Avoiding Pitfalls in Developing Language Resources when Data is Scarc (https://arxiv.org/abs/2410.12691)
- **What's New**: 이 논문은 중간에서 낮은 자원(threshold) 언어에 대한 NLP(자연어처리) 연구의 한계와 문제점을 조사하며, 데이터 수집, 윤리적 주석(annotation) 관행, 데이터 품질에 중점을 두고 연구자 및 관계자의 피드백을 수집했습니다.

- **Technical Details**: 설문조사를 통해 데이터 품질, 언어적 및 문화적 적합성, 주석 관행의 윤리성을 분석하였으며, 그 결과로 고품질 언어 아티팩트(artefacts)를 만들기 위한 여러 가지 추천 사항을 제시합니다. 연구자들은 언어 사용자와의 밀접한 협업이 필요하며, 주장하는 바에 따르면 자원 부족은 연구 선택 및 방법론에 영향을 미쳤습니다.

- **Performance Highlights**: 연구는 NLP 커뮤니티와의 대화를 통해 중간 및 낮은 자원 언어에 대한 공통적인 인센티브, 한계 및 관행을 조명하였고, 향후 연구 및 개선 방향에 대한 실질적인 추천을 제공합니다.



### Evaluating Morphological Compositional Generalization in Large Language Models (https://arxiv.org/abs/2410.12656)
Comments:
          33 pages

- **What's New**: 본 연구는 대형 언어 모델(LLMs)의 형태론적 일반화 능력을 구성적(compositional) 관점에서 체계적으로 조사합니다. 형태소(morpheme)를 구성적 원시 단위로 정의하고, 이를 기반으로 한 새로운 유전자 및 판별(task) 과제를 설계하였습니다.

- **Technical Details**: 우리는 지도 학습된 멀티링궐 모델들(GPT-4, Gemini-1.5 등)을 평가하였으며, 터키어와 핀란드어와 같은 교착어(agglutinative languages)를 대상으로 했습니다. 모델은 새로운 단어의 어근에 적용했을 때 형태론적 연결(compositionality) 일반화가 부족하며, 형태론적 복잡성이 증가할수록 성능이 급격히 감소하는 경향을 보였습니다.

- **Performance Highlights**: 모델은 개별적인 형태론적 조합을 식별하는 데 있어 최소한의 성과를 보였지만, 그 성능은 시스템적이지 않아 인간과 비교했을 때 상당한 정확도 차이를 보였습니다. 인간은 복잡한 형태론적 구조에서도 일관된 성능을 유지하는 반면, 모델의 성능은 뚜렷한 감소를 보였습니다.



### From Measurement Instruments to Training Data: Leveraging Theory-Driven Synthetic Training Data for Measuring Social Constructs (https://arxiv.org/abs/2410.12622)
- **What's New**: 본 논문은 사회적 구성물(measuring social constructs) 측정을 향상시키기 위한 이론 기반(theory-driven) 합성 훈련 데이터(synthetic training data)의 가능성을 체계적으로 조사합니다. 기존의 측정 도구에서 얻은 지식을 어떻게 활용할 수 있는지를 탐구합니다.

- **Technical Details**: 사회 과학(social sciences)에서 사용되는 설문 척도(survey scales)나 주석 코드북(annotation codebooks) 등에서 얻은 지식을 이론 기반 합성 데이터 생성에 적용합니다. 성 차별(sexism) 및 정치적 주제(political topics)에 대한 두 가지 연구를 통해 텍스트 분류(text classification) 모델의 고도화를 평가합니다.

- **Performance Highlights**: 성 차별 연구의 결과는 덜 유망하였으나, 정치적 주제 분류에서 합성 데이터는 라벨링된 데이터의 필요성을 크게 줄일 수 있음을 보여줍니다. 성능의 미미한 저하로 라벨링된 데이터의 대량 대체가 가능하며, 이론 기반 합성 데이터가 개념적 정보 없이 생성된 데이터보다 현저히 우수한 성능을 보였습니다.



### Weak-to-Strong Generalization beyond Accuracy: a Pilot Study in Safety, Toxicity, and Legal Reasoning (https://arxiv.org/abs/2410.12621)
- **What's New**: 이 논문은 기존의 약한 감독자(w weak supervisors) 사용 방식을 확대하여 실제 정렬(alignment) 관련 과제에 적용하는 방법을 제시합니다.

- **Technical Details**: 약한 생성(weak-to-strong generation) 현상을 안전성(safety), 독성(toxicity), 법적 추론(legal reasoning)과 같은 복잡한 정렬 작업에 대해 실험적으로 입증합니다.

- **Performance Highlights**: 정렬 성능을 향상시키기 위한 효율적인 전략을 탐색하며, 특정 정렬 작업과 관련된 문제와 잠재적 해결책을 요약하고 분석합니다.



### Parsing Akkadian Verbs with Prolog (https://arxiv.org/abs/2410.12617)
Comments:
          6 pages, 9 figures, presented at ACL-02 the Association of Computational Linguistics, 2002

- **What's New**: 이 논문은 아카디안(Akkadian)의 유한 동사 형태를 위한 파싱(Parsing) 및 생성(Generation) 시스템을 설명합니다. 이 시스템은 접미사(suffixes)의 추가 가능성을 가지고 있으며, 프로로그(Prolog)로 구현되었습니다.

- **Technical Details**: 제시된 시스템은 D, N, G 어간(stems)을 해석하고, 목적격(accusative), 여격(dative), 벤티브(ventive) 어미(endings)를 처리할 수 있도록 설계되었습니다.

- **Performance Highlights**: 이 시스템은 아카디안 동사 형태의 파싱과 생성을 효과적으로 지원하여 이 언어의 구조적 이해를 향상시킬 수 있는 잠재력을 보여줍니다.



### Exploring Model Kinship for Merging Large Language Models (https://arxiv.org/abs/2410.12613)
Comments:
          Ongoing work

- **What's New**: 이 연구는 모델 병합(model merging)을 위한 새로운 평가 기준인 모델 친척성(model kinship)을 도입합니다. 모델 친척성은 LLM(대형 언어 모델) 간의 유사성과 관련성을 측정하여, 반복적인 병합 과정에서 성능 개선을 돕는 정보를 제공합니다.

- **Technical Details**: 모델 병합은 여러 개별 모델을 통합하여 다중 작업 목표를 달성하는 전략입니다. 본 논문에서는 모델 친척성을 기준으로 한 Top-k Greedy Merging 전략을 제안하며, 이는 모델 진화(model evolution)에서의 최적화 문제와 지역 최적점(local optima traps)을 피할 수 있도록 도와줍니다.

- **Performance Highlights**: 모델 친척성을 사용한 새로운 병합 전략은 벤치마크 데이터셋에서 더 나은 성능을 달성하며, 평균 성능 향상과 강한 상관관계가 있음을 보여줍니다. 이 연구는 모델 병합의 효율성과 효과성을 높이기 위한 실용적인 전략을 제시합니다.



### Not All Votes Count! Programs as Verifiers Improve Self-Consistency of Language Models for Math Reasoning (https://arxiv.org/abs/2410.12608)
- **What's New**: 이 논문에서는 PROVE라는 프로그램 기반 검증 프레임워크를 제안하여 수학적 추론 문제를 해결하는 방식이 개선되었습니다. 이 방법은 중간 단계의 오류를 줄이고, 최종 답변을 집계하기 전에 가능성 있는 잘못된 추론 경로를 필터링합니다.

- **Technical Details**: PROVE는 여러 개의 추론 경로를 샘플링하여 가장 일반적인 답변을 선택하는 대신, 생성된 솔루션과 불일치하는 프로그램 출력과 관련된 솔루션을 거부하고, 파이썬 프로그램으로 검증된 솔루션만 집계합니다. 이 연구는 0.5B에서 13B 파라미터를 가진 다양한 오픈소스 LLM 13개를 대상으로 전국적으로 7개의 수학 벤치마크에서 평가하였습니다.

- **Performance Highlights**: PROVE는 GSM8K 벤치마크에서 Qwen2-0.5B-Instruct의 정확도를 48.85%에서 53.83%로, Llama-3.2-1B-Instruct의 정확도를 65.66%에서 73.01%로, Gemma-2-2b-it의 정확도를 73.39%에서 79.61%로, Llama-2-7B-chat의 정확도를 41.32%에서 59.51%로 증가시켰습니다.



### CCSBench: Evaluating Compositional Controllability in LLMs for Scientific Document Summarization (https://arxiv.org/abs/2410.12601)
- **What's New**: CCSBench라는 새로운 벤치마크를 소개하며, 이는 과학 문서 요약에서 여러 속성을 동시에 제어할 수 있도록 돕습니다. 특히, 길이(length)와 경험적 초점(empirical focus) 등의 명시적 속성뿐만 아니라, 가독성(readability)과 같은 암시적 속성도 포함됩니다.

- **Technical Details**: CCSBench는 explicit (명시적) 속성과 implicit (암시적) 속성의 세밀한 제어를 가능하게 하며, 명시적 속성은 길이와 키워드 포함을, 암시적 속성은 가독성과 경험적 초점을 다룹니다. 이 연구에서는 다양한 LLMs(GPT-4, LLaMA2 등)에서 CCSBench를 기반으로 한 실험을 수행하여, 제어 속성 간의 균형을 맞추는 데 있어 큰 언어 모델들이 겪는 한계를 밝혀냈습니다.

- **Performance Highlights**: 대부분의 LLM들은 가독성을 높이 유지하면서 경험적 초점을 강조하는 데 어려움을 겪습니다. 특히, LLaMA2와 같은 decoder-only 모델들은 긴 의존성을 모델링하는 데 있어서 문제가 발생하며, encoder-decoder 모델들은 더 나은 적응성을 보여줍니다. 이러한 결과는 과학적 요약을 위한 조합 가능성에 대한 새로운 연구 필요성을 강조합니다.



### On the Risk of Evidence Pollution for Malicious Social Text Detection in the Era of LLMs (https://arxiv.org/abs/2410.12600)
- **What's New**: 이번 논문에서는 악의적인 소셜 텍스트를 식별하는 데 있어 증거를 강화한 감지기의 새로운 잠재적 위험성을 탐구합니다. 특히 대형 언어 모델(LLMs)의 발전으로 인한 증거 오염(evidence pollution) 문제를 다룹니다.

- **Technical Details**: 연구는 기본적인 오염, 리프레이징(rephrasing), LLMs에 의한 증거 생성(manipulation) 등 여러 가지 시나리오에서 증거를 조작하는 방법을 모사합니다. 이에 대한 방어 전략으로 데이터와 모델 측면에서 기계 생성 텍스트 감지(machine-generated text detection), 전문가 혼합(mixture of experts), 매개변수 업데이트(parameter updating) 등의 세 가지 접근 방식을 제안합니다.

- **Performance Highlights**: 실험 결과, 증거 오염, 특히 생성 전략이 기존의 감지기를 심각하게 약화시키는 것으로 나타났습니다. 그러나 방어 전략들이 증거 오염을 완화할 수 있지만, 주석 데이터의 필요성과 높은 추론 비용(inference costs) 등의 실용적인 제한이 존재합니다.



### Can We Reverse In-Context Knowledge Edits? (https://arxiv.org/abs/2410.12586)
- **What's New**: 이번 연구에서는 인-컨텍스트 지식 편집(IKE)의 검출 및 역전 과정에 대한 새로운 접근 방안을 제시합니다. 특히, IKE를 악용한 편집을 탐지하고 이를 복원하는 새로운 과제를 소개하였습니다.

- **Technical Details**: IKE(인-컨텍스트 지식 편집)는 LLM(대형 언어 모델)의 출력물을 파라미터 변경 없이 효율적으로 수정할 수 있도록 합니다. 저자들은 특수하게 조정된 역전 토큰을 사용하여 IKE 편집을 회복하는 방법을 제안합니다.

- **Performance Highlights**: 연구에서는 IKE 편집을 80% 이상의 정확도로 검출할 수 있음을 보였으며, 연속적인 역전 토큰을 활용하여 여러 LLM에서 원본 출력을 80% 이상 회복할 수 있음을 입증했습니다.



### STRUX: An LLM for Decision-Making with Structured Explanations (https://arxiv.org/abs/2410.12583)
Comments:
          10 pages, 7 figures, submitted to NAACL 2025

- **What's New**: 이 논문에서는 새로운 LLM (Large Language Model) 의사결정 프레임워크인 STRUX를 소개합니다. STRUX는 구조화된 설명을 제공하여 LLM의 의사결정을 개선합니다.

- **Technical Details**: STRUX는 긴 정보를 간결한 핵심 사실의 표로 정제한 후, 자기 반성 단계(self-reflection steps)를 통해 어떤 사실이 중요한지를 결정합니다. 이 사실을 특정 결정과 관련하여 유리한(favorable) 것과 불리한(adverse) 것으로 분류합니다. 마지막으로, LLM을 미세 조정(fine-tune)하여 이러한 핵심 사실을 식별하고 우선순위를 매깁니다.

- **Performance Highlights**: STRUX는 수익 전화 회의(transcripts) 데이터를 기반으로 한 주식 투자 의사 결정 예측 과제에서 강력한 기준선(baselines) 대비 뛰어난 성능을 보였습니다. 이는 의사결정의 투명성을 높여주며, 사용자들이 다양한 요인의 영향을 이해할 수 있도록 합니다.



### A Claim Decomposition Benchmark for Long-form Answer Verification (https://arxiv.org/abs/2410.12558)
Comments:
          Accepted by CCIR 2024

- **What's New**: 이번 연구에서는 LLM(대규모 언어 모델)의 응답에서 사실성이 결여된 'hallucination' 문제를 해결하기 위해, 각 주장에 대한 출처를 명확히 하는 새로운 기준을 제시합니다. 특히, 각 응답에서 주장이나 진술을 식별하는 것의 중요성을 강조하며, 이를 위한 새로운 Claim Decomposition Benchmark를 도입합니다.

- **Technical Details**: 우리는 CACDD(Chinese Atomic Claim Decomposition Dataset)를 소개합니다. 이 데이터셋은 500개의 인간 주석 질문-응답 쌍으로 구성되어 있으며, 총 4956개의 원자적(claim) 주장을 포함합니다. 데이터를 고품질로 유지하기 위해 전문가의 추가 주석이 포함되었습니다. 실험에서는 zero-shot, few-shot 및 fine-tuned LLM를 사용하여 성능 비교를 진행하였습니다.

- **Performance Highlights**: 실험 결과, 주장 분해(claim decomposition)는 매우 도전적인 작업으로, 추가적인 탐색이 필요하다는 것을 보여주었습니다. 모든 코드와 데이터는 공개적으로 사용 가능합니다.



### LLM-based Translation Inference with Iterative Bilingual Understanding (https://arxiv.org/abs/2410.12543)
Comments:
          work in process

- **What's New**: 본 연구에서는 Iterative Bilingual Understanding Translation (IBUT)이라는 새로운 방법을 제안합니다. 이 방법은 LLM의 교차 언어 능력과 번역 작업의 이중 특성을 기반으로 하여 번역 품질을 개선하는 데 초점을 맞추고 있습니다.

- **Technical Details**: IBUT 방법은 Understanding Generation, Alignment Judgment, Iterative Refinement, Understanding-Based Translation의 네 가지 부분으로 구성됩니다. IBUT는 먼저 LLM을 활용하여 소스 및 타겟 언어에 대한 맥락 이해를 생성하고, 그 후 이 이해를 기반으로 다양한 언어 쌍에서 번역을 수행합니다.

- **Performance Highlights**: 실험 결과, IBUT는 여러 강력한 비교 방법들보다 뛰어난 성능을 보였으며, 특히 뉴스, 상식, 문화 번역 벤치마크와 같은 다양한 도메인에 일반화되는 성능이 입증되었습니다. 평균적으로 +1.3, +4.2, +2.3의 COMET 점수 향상을 보였습니다.



### MedAide: Towards an Omni Medical Aide via Specialized LLM-based Multi-Agent Collaboration (https://arxiv.org/abs/2410.12532)
Comments:
          Under review

- **What's New**: 이번 논문에서는 복잡한 의료 응용 프로그램에서 LLM의 한계를 극복하기 위해 MedAide라는 새로운 프레임워크를 제안합니다. 이 시스템은 개인화된 추천 및 진단 분석을 제공하여 LLM의 성능을 향상시킵니다.

- **Technical Details**: MedAide는 retrieval-augmented generation을 통해 쿼리를 재작성하여 정확한 의료 의도 이해를 할 수 있도록 합니다. 또한, 문맥 인코더(contextual encoder)를 사용하여 의도 프로토타입 임베딩(intent prototype embeddings)을 생성하고, 이를 통해 유사성 매칭(similarity matching)으로 세밀한 의도를 인식합니다.

- **Performance Highlights**: 상당한 실험을 통해 MedAide가 현재의 LLM을 초월하고 의료 전문성(medical proficiency)과 전략적 추론(strategic reasoning)을 향상시킨다는 결과가 나타났습니다. 이 결과는 네 가지 의료 벤치마크에서 전문가의 평가와 자동화된 지표 자동(metrics) 평가를 통해 얻어졌습니다.



### FiRST: Finetuning Router-Selective Transformers for Input-Adaptive Latency Reduction (https://arxiv.org/abs/2410.12513)
Comments:
          17 pages, 6 figures, Submitted to ICLR 2025

- **What's New**: 본 연구에서는 Auto-regressive Large Language Models (LLMs)의 출력 지연(latency) 문제를 해결하기 위한 새로운 알고리즘인 FIRST를 제안합니다.

- **Technical Details**: FIRST는 입력 시퀀스에 대해 동적으로 transformer 레이어의 하위 집합을 선택하기 위해 레이어별 라우터(layer-specific routers)를 사용하는 알고리즘입니다. 프롬프트(prompt)는 디코딩 과정에서 어떤 레이어를 건너뛸지 결정합니다. FIRST는 KV 캐싱(KV Caching)과의 호환성을 유지하여 더 빠른 추론을 가능하게 하며, LoRA 어댑터를 탑재하여 외부 데이터셋에서 세부 조정을 통해 태스크별 정확성을 향상시킵니다.

- **Performance Highlights**: FIRST는 광범위한 실험을 통해 레이턴시(latency)를 크게 감소시키면서도 경쟁력 있는 성능을 유지함을 보여주며, 저자원 환경(low-resource environments)에서 LLM 배포를 위한 효율적인 솔루션을 제공합니다.



### Advancing Fairness in Natural Language Processing: From Traditional Methods to Explainability (https://arxiv.org/abs/2410.12511)
Comments:
          PhD Thesis, Toulouse University

- **What's New**: 이 박사 논문은 자연어 처리(NLP) 시스템 내의 공정성(fairness)을 보장하는 방법에 대한 연구를 다룹니다. 특히, NLP 기술이 다양한 인간 집단에 미치는 영향을 분석하면서, 기술적 도전 과제 이상으로 도덕적이고 윤리적인 필요성을 강조합니다.

- **Technical Details**: 먼저, 다중 클래스 분류기에서 편향(bias)을 완화하기 위한 혁신적인 알고리즘을 소개하고, 이는 고위험 NLP 애플리케이션에 적합하게 설계되었습니다. 덧붙여, Bios 데이터셋 분석을 통해 데이터셋 크기가 차별적 편향에 미치는 영향 및 기존의 공정성 메트릭의 한계를 논의합니다. 이후 COCKATIEL이라는 모델 불변 설명 가능성(explainability) 방법을 제안하며, 이는 Transformer 모델의 개념을 식별하고 순위를 매기는 데 있어 이전 접근 방식을 뛰어넘습니다. 마지막으로, TaCo라는 새로운 방법을 통해 Transformer 모델 임베딩의 편향을 중화(neutralize)하는 기여를 합니다.

- **Performance Highlights**: 공정성과 설명 가능성을 결합한 이 연구는 NLP 패러다임에 도전하고 재구성하는 데 기여하며, 기계 학습에서 공정성에 대한 지속적인 담론에 귀중한 솔루션을 제공합니다.



### With a Grain of SALT: Are LLMs Fair Across Social Dimensions? (https://arxiv.org/abs/2410.12499)
- **What's New**: 본 논문은 다양한 성별, 종교 및 인종에 대한 오픈 소스 Large Language Models (LLMs)의 편향 분석을 제시합니다. 저자들은 편향 탐지 데이터셋을 생성하기 위한 방법론을 소개하며, 이를 위해 7개의 편향 트리거를 사용합니다.

- **Technical Details**: 트리거에는 General Debate, Positioned Debate, Career Advice, Story Generation, Problem-Solving, Cover-Letter Writing, CV Generation이 포함됩니다. 각 트리거에 대해 다양한 성별, 종교 및 인종 그룹을 아우르는 프롬프트를 생성하기 위해 GPT-4o를 사용합니다. 생성된 데이터셋에서 Llama 및 Gemma 모델을 평가하고, GPT-4o-mini를 통해 각 그룹과 관련된 LLM 생성 텍스트를 익명화한 후, GPT-4o-as-a-Judge를 사용하여 쌍대 비교를 수행합니다. 편향 정도는 쌍대 비교에서의 승패 수를 통해 정량화합니다.

- **Performance Highlights**: 분석은 영어, 독일어, 아랍어의 세 가지 언어에 걸쳐 편향이 어떻게 나타나는지를 탐구합니다. 연구 결과, LLM은 각 카테고리에서 특정 그룹에 대해 강한 양극화를 보이며, 모델 간 일관성을 확인했습니다. 그러나 언어가 변할 때 문화적 신호와 맥락의 차이로 인해 변화와 이상이 나타납니다.



### End-to-end Planner Training for Language Modeling (https://arxiv.org/abs/2410.12492)
Comments:
          14 pages

- **What's New**: 이번 연구에서는 언어 모델(LLM)의 훈련을 개선하기 위한 새로운 방법을 제안합니다. 특히, 계획 모듈(planning module)을 통해 미래 문장의 추상 레이블을 예측하고 이 예측에 기반하여 LLM을 조정하는 방식에서 차별화를 도모하였습니다.

- **Technical Details**: 기존 방법은 비미분 가능(non-differentiable)하여 계획자(planner)와 LLM의 공동 엔드투엔드 조정(joint end-to-end tuning)이 불가능했습니다. 본 논문에서는 이러한 문제를 해결하기 위해 레이블의 확률을 혼합 가중치(mixing weights)로 사용하여 LLM을 미분 가능하게 조정하는 방법을 제안합니다.

- **Performance Highlights**: 실험 결과, perplexity(퍼플렉시티)가 일관되게 개선되었으며, 이는 제안된 방법의 효과성을 나타냅니다.



### Insights from the Inverse: Reconstructing LLM Training Goals Through Inverse RL (https://arxiv.org/abs/2410.12491)
Comments:
          Preprint

- **What's New**: 이 논문에서는 인공지능 언어 모델(Large Language Models, LLMs)의 해석을 위한 새로운 접근 방식으로 역강화학습(Inverse Reinforcement Learning, IRL)을 소개합니다. 이 방법을 통해 LLM의 암묵적 보상 함수(reward functions)를 회수하는 실험을 수행하였으며, 다양한 크기의 독성 관련 LLM에서 최대 80.40%의 정확도로 인류의 선호도를 예측하는 보상 모델을 추출했습니다.

- **Technical Details**: 역강화학습(IRL)은 에이전트의 행동 관찰을 기반으로 기저에 있는 보상 함수를 회복하고자 하는 기계 학습의 패러다임입니다. 이 연구에서는 LLM에 IRL을 적용하여 이들의 의사결정 과정을 인식하고, LLM 교육 과정의 비가시성을 해소하고자 합니다. 특히, 아이디어는 보상 함수가 쉽게 회복될 경우 LLM이 안전성 위험에 빠질 가능성이 더 높아질 수 있음을 나타냅니다. 논문에서는 최대 마진 IRL(Maximum Margin IRL) 방법을 사용하여 보상 기능을 추출하는 데 중점을 두었습니다.

- **Performance Highlights**: 여러 독성 데이터셋에서의 실험 결과, 간단한 IRL 방법인 Max-Margin 방식으로도 보상 모델이 성공적으로 추출되었으며, 새로운 LLM을 미세 조정(fine-tuning)하는 데 효과적임을 입증했습니다. 이 연구는 LLM의 정렬(alignment) 이해 및 개선을 위한 새로운 관점을 제공하며, 강력한 언어 모델의 책임 있는 개발 및 배치에 대한 의미 있는 시사점을 제시합니다.



### KcMF: A Knowledge-compliant Framework for Schema and Entity Matching with Fine-tuning-free LLMs (https://arxiv.org/abs/2410.12480)
- **What's New**: 이 논문은 Knowledge-Compliant Matching Framework (KcMF)를 제시하여 대규모 언어 모델(LLM)의 데이터 매칭(Task) 관련 신뢰성 문제를 해결하고자 한다. KcMF는 도메인별 세부 튜닝 없이 사용할 수 있으며, pseudo-code 기반의 작업 분해 전략을 사용하여 LLM의 추론 과정을 안내한다.

- **Technical Details**: KcMF는 두 가지 메커니즘인 Dataset as Knowledge (DaK)와 Example as Knowledge (EaK)를 사용하여 비구조화된 도메인 지식이 부족할 때 도메인 지식 세트를 구축한다. 또한, 결과 앙상블 전략인 Inconsistency-tolerant Generation Ensembling (IntGE)을 도입하여 여러 지식 출처를 활용하고 잘못 형식화된 출력을 억제한다.

- **Performance Highlights**: KcMF는 MIMIC 및 Synthea와 같은 다양한 벤치마크에서 평가되었으며, 이전의 비LLM 상태에서 가장 뛰어난 방법들보다 평균 F1 점수 22.9% 향상을 보이며, SOTA LLM과도 효과적으로 경쟁한다. KcMF는 다양한 LLM에서 잘 일반화된다는 점도 주목할 만하다.



### MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models (https://arxiv.org/abs/2410.12478)
- **What's New**: 이 논문은 대규모 언어 모델(LLMs)의 신뢰성과 관련된 문제를 다루며, 영어 외의 언어에서의 신뢰도 추정(confiendce estimations)에 대한 연구가 부족하다는 점을 강조합니다. 특히, 다국어 신뢰도 추정(Multilingual Confidence estimation, MlingConf)에 대한 포괄적인 조사를 소개합니다.

- **Technical Details**: 연구는 언어에 구애받지 않는(Language-agnostic, LA) 및 언어 특정(Language-specific, LS) 작업을 다루어, 다국어 신뢰도 추정의 성능과 언어 우세(effect of language dominance)에 대해 탐구합니다. LA 작업을 위한 고품질 다국어 데이터셋 4개와 특정 사회, 문화적 및 지리적 맥락을 고려한 LS 작업을 위한 데이터셋 1개가 사용되었습니다.

- **Performance Highlights**: 실험 결과, LA 작업에서는 영어가 신뢰도 추정에서 두드러진 언어적 우세를 보이는 반면, LS 작업에서는 질문과 관련된 언어를 사용하여 LLM을 유도할 때 다국어 신뢰도 추정에서 더 나은 성과를 나타냅니다. 이는 LS 작업에서 언어 특정 프롬프트를 사용하는 간단하면서 효과적인 원어민 톤 유도 전략(native-tone prompting strategy)의 필요성을 시사합니다.



### Retrieval-Reasoning Large Language Model-based Synthetic Clinical Trial Generation (https://arxiv.org/abs/2410.12476)
- **What's New**: 이번 연구에서는 대규모 언어 모델(LLM)을 활용하여 인공적이지만 현실적인 이중 성공/실패 레이블을 가진 임상 시험 데이터를 생성하는 새로운 Retrieval-Reasoning few-shot 프레임워크를 소개합니다.

- **Technical Details**: 이 프레임워크는 실제 임상 시험 데이터를 기반으로 하여 생성된 합성(artificial) 임상 시험 데이터의 다양성과 현실성을 극대화하며, 모델 학습을 위한 이론적 토대를 제공합니다. 또한, Synthetic clinical trial datasets에 대한 바이너리 분류기(bi-nary classifier)로 사전 훈련된 모델의 파인튜닝(fine-tuning)을 통해 하위 작업(downstream tasks)인 시험 결과 예측(trial outcome prediction)의 성능을 향상시킴을 입증합니다.

- **Performance Highlights**: 실제 임상 시험 데이터베이스에서 수행한 실험 결과, 생성된 합성 데이터가 실제 데이터셋을 효과적으로 보강하며, 임상 연구를 가속화하고 환자 개인 정보 보호를 위한 윤리적 기준을 유지하는 데 기여할 수 있음을 시사합니다.



### Learning to Predict Usage Options of Product Reviews with LLM-Generated Labels (https://arxiv.org/abs/2410.12470)
Comments:
          9 pages

- **What's New**: 이 논문은 고객 리뷰에서 제품 사용 옵션을 예측하는 독립적인 모델을 학습하기 위한 새로운 접근 방식을 제안하며, 이를 통해 대규모 데이터 세트를 효율적으로 라벨링하는 방법을 논의합니다. 일반적인 crowd-sourcing 방식의 한계를 극복하기 위해 LLM(대형 언어 모델)을 활용하여 몇 가지 샷 학습(few-shot learning)으로 데이터 라벨링을 수행하는 방법을 소개합니다.

- **Technical Details**: 제안된 방법론은 GPT-4와 같은 최신 LLM을 활용하여 고객 리뷰로부터 제품 사용 옵션을 추출하는 복잡한 태스크에 중점을 두고 있습니다. 연구진은 이러한 사용 옵션을 텍스트 문구로 정의하며, 여러 참고 기준을 비교하기 위한 새로운 평가 지표인 HAMS4를 도입했습니다. 또한, LLM 사용에 따른 에너지 효율성과 개인 정보 보호 측면에서의 이점을 강조하고 있습니다.

- **Performance Highlights**: 실험 결과, LLM을 활용한 라벨링이 전문 vendor 서비스보다 높은 품질의 데이터를 생성함을 보여주었습니다. 특히, GPT-4를 통해 생성된 라벨은 도메인 전문가의 수준에 도달하였으며, LLM을 사용한 데이터 주석 작업은 인력을 활용하는 것에 비해 높은 비용 절감을 가능하게 합니다.



### Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention (https://arxiv.org/abs/2410.12462)
- **What's New**: 본 논문에서는 Inference-Time Cross-Lingual Intervention (INCLINE)라는 새로운 프레임워크를 제안합니다. 이 방법은 낮은 성능의 언어를 높은 성능의 언어와 정렬하여 LLM의 성능을 개선합니다.

- **Technical Details**: INCLINE은 주로 데이터 병렬성(parallel sentences)을 이용해 Least-Squares 최적화를 통해 정렬 행렬(alignment matrices)을 학습합니다. 이 행렬은 추론(inference) 동안 낮은 성능 언어의 표현을 높은 성능 언어의 공간으로 변환하는 데 사용됩니다.

- **Performance Highlights**: 아홉 개의 벤치마크에서 다섯 개의 LLM을 대상으로 한 광범위한 실험을 통해 INCLINE이 다양한 작업 및 언어에서 성능을 유의미하게 개선한다고 밝혔습니다. 이 방법은 비용 효율적이며 다양한 응용 프로그램에 적용할 수 있습니다.



### The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph (https://arxiv.org/abs/2410.12458)
Comments:
          19 pages, 5 figures, 5 tables

- **What's New**: 이 논문에서는 새롭게 제안된 데이터 선택 기법인 GraphFilter에 대해 설명합니다. 이 방법은 데이터셋을 두 부분으로 나누어진 그래프(bipartite graph)로 표현하여 문장과 이들로 구성된 n-그램(n-grams)을 연결합니다.

- **Technical Details**: GraphFilter는 문서 간의 관계 및 언어 패턴을 효과적으로 포착하여 n-그램 다양성을 증대시키는 문장을 선택할 수 있도록 합니다. 선택 과정에서 품질과 다양성을 균형 있게 고려하기 위해, 품질 메트릭(quality metric)과 다양성 메트릭(diversity metric)을 곱셈 방식으로 결합한 우선 순위 함수(priority function)를 제안합니다. GraphFilter는 반복적으로 높은 우선 순위 문장을 선택하고, n-그램을 제거하여 그래프를 업데이트하며, 변화하는 데이터 환경을 반영하기 위해 우선 순위를 재계산합니다.

- **Performance Highlights**: 여섯 개의 널리 사용되는 벤치마크를 기반으로 세 가지 모델 백본(model backbone)을 사용하여 광범위한 실험을 실시하였으며, GraphFilter는 아홉 가지 기준선(baseline) 접근 방식을 모두 초월하는 성능을 보였습니다. 결과적으로 모델 성능 및 계산 효율성(computational efficiency)이 우수함을 입증했습니다.



### Open Ko-LLM Leaderboard2: Bridging Foundational and Practical Evaluation for Korean LLMs (https://arxiv.org/abs/2410.12445)
- **What's New**: Open Ko-LLM Leaderboard2가 기존의 Open Ko-LLM Leaderboard의 한계를 보완하여 새롭게 등장했습니다. 이 새로운 리더보드는 더 관련성 높은 실제 과업을 기반으로 한 벤치마크를 제공합니다.

- **Technical Details**: 기존의 벤치마크는 주로 영어 버전의 번역본으로 구성되어 있었으나, Open Ko-LLM Leaderboard2는 네 가지 새로운 한국어 네이티브 벤치마크를 도입하여 한국어의 고유한 특성을 보다 잘 반영합니다.

- **Performance Highlights**: 이 개선된 리더보드는 한국어 Large Language Model (LLM)에 대한 보다 의미 있는 평가를 제공하여 모델들의 질적 영향력을 높이는 데 기여하고자 합니다.



### Expanding Chatbot Knowledge in Customer Service: Context-Aware Similar Question Generation Using Large Language Models (https://arxiv.org/abs/2410.12444)
- **What's New**: 이 논문에서는 고객의 질문 표현의 다양성을 수용하기 위해 사전 정의된 질문-답변 쌍(QA pairs)을 기반으로 하는 서비스 챗봇의 응답 신뢰성을 높이는 접근법으로 유사 질문 생성(Similar Question Generation, SQG) 방법을 제안합니다.

- **Technical Details**: 제안된 SQG 방법은 대형 언어 모델(Large Language Models, LLMs)을 기반으로 하며, 이를 통해 원래 QA 쌍과 의미적 일관성을 유지하면서도 다양한 질문을 생성할 수 있습니다. LLM의 자연어 이해 능력을 활용하여 특별히 설계된 프롬프트를 사용하여 모델을 세밀하게 조정합니다.

- **Performance Highlights**: 실제 고객 서비스 데이터셋을 통해 수행된 실험 결과, 제안된 방법이 의미적 다양성 면에서 기존의 방법들을 크게 초월하는 성과를 보였으며, 인간 평가에서도 고객의 의도를 반영한 답변 통합이 비즈니스 요구사항을 충족하는 질문의 수를 증가시키는 데 중요한 요소임을 확인했습니다.



### Conformity in Large Language Models (https://arxiv.org/abs/2410.12428)
Comments:
          16 pages (8 pages main body), 14 figures

- **What's New**: 이 연구는 최신 LLMs(대형 언어 모델)에서의 conformity effect(순응 효과)를 분석하고, 모델들이 다수 의견에 얼마나 수용적인지를 탐구합니다.

- **Technical Details**: 심리 실험을 LLM에 적용하여, 원래 선택에 관계없이 모든 LLM이 다양한 지식 영역에서 다수에 대해 다양한 수준의 순응을 보이는 사실을 입증했습니다. 또한, 모델이 예측에 대한 불확실성이 높을수록 순응 가능성이 증가한다는 점을 발견했습니다. 훈련 패러다임과 입력 특성 등 순응에 영향을 미치는 요소를 분석하여, instruction-tuned 모델은 순응에 덜 영향을 받는다고 밝혀냈습니다.

- **Performance Highlights**: 정확한 응답에도 불구하고 LLM들이 다수의 의견에 따르는 경향이 있으며, 더 자연스러운 다수 톤이 순응을 강화하는 경향이 있습니다. 연구에서는 Devil's Advocate와 Question Distillation 두 가지 개입 방법을 제안하여, LLM의 순응을 완화하기 위한 통찰을 제공합니다.



### Theoretical Analysis of Hierarchical Language Recognition and Generation by Transformers without Positional Encoding (https://arxiv.org/abs/2410.12413)
Comments:
          55 pages, 11 figures

- **What's New**: 본 연구에서는 Transformers가 특정 positional encoding(위치 인코딩) 없이도 모델 크기에 비례하여 계층적 언어(hierarchical language)를 효율적으로 인식하고 생성할 수 있다는 건설적 증명을 제시합니다.

- **Technical Details**: 연구에서는 causal masking(인과 마스킹)과 시작 토큰(starting token)이 Transformers가 계층 구조에서 positional information(위치 정보)과 depth(깊이)를 계산하도록 할 수 있음을 보여줍니다. 이를 통해 positional encoding 없이도 계층적 언어 생성을 가능하게 함을 입증하였습니다.

- **Performance Highlights**: 또한, 명시적 positional encoding이 시퀀스 길이(sequence length)에 대한 일반화(generalization)에 부정적인 영향을 미칠 수 있다는 점도 제안하였습니다.



### Nominal Class Assignment in Swahili: A Computational Accoun (https://arxiv.org/abs/2410.12406)
Comments:
          Tenth Italian Conference on Computational Linguistics (CliC-it-2024)

- **What's New**: 스와힐리어의 의미론(semantics)과 명사 클래스 할당(nominal class assignment) 간의 관계를 다룬 연구로, 최초로 각 명사 클래스의 의미적 응집력(semantic cohesion)을 정량적으로 평가하고 이의 본질을 설명하려 하였습니다.

- **Technical Details**: 스와힐리는 총 18개의 명사 클래스를 가지고 있으며, 각 명사 클래스는 접사(affix)에 의해 신호(signal)가 제공됩니다. 연구는 단어 벡터(word vectors)를 기반으로 하여 의미적 내용을 예측 가능한 요소인지를 컴퓨터적으로 조사합니다. 스와힐리 명사의 번역을 통해 형태론적(confounding morphological cues) 접근을 피하고, TUKI 스와힐리-영어 사전을 사용하여 6,341개의 고유 기록을 수집하였습니다.

- **Performance Highlights**: 이 연구는 스와힐리어 명사 클래스의 의미 바로잡기 성능에 대한 새로운 통찰력을 제공하며, 명사 클래스의 예측 가능성에 대한 새로운 평가를 제시합니다. 종래 연구들과 달리, 형식적 성능 지표를 극대화하는 것이 아닌 의미론적 내용만으로 명사 클래스 소속을 예측하는 데 초점을 맞추었습니다.



### ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs (https://arxiv.org/abs/2410.12405)
Comments:
          EMNLP 2024, Findings

- **What's New**: 이 연구에서는 LLMs(대형 언어 모델)의 프롬프트(prompt) 민감도를 평가하고 이해하기 위한 새로운 프레임워크인 ProSA를 소개합니다. 기존 연구에서는 주로 인스턴스 수준의 프롬프트 변동성을 간과하였고, 이에 따른 주관적 평가의 영향도 외면해왔습니다.

- **Technical Details**: ProSA는 새로운 민감도 측정 지표인 PromptSensiScore를 포함하며, 디코딩(confidence) 신뢰도를 활용하여 LLMs의 작동 메커니즘을 해명하는 데 집중합니다. 이 연구는 여러 작업을 포함하여 프롬프트 민감성이 데이터셋과 모델에 따라 변동하며, 대형 모델이 더 뛰어난 강건성을 보이는 것을 발견했습니다.

- **Performance Highlights**: 우리의 연구 결과에 따르면 몇 가지 사례(few-shot examples)를 제시하는 것이 민감도 문제를 완화시킬 수 있으며, 복잡한 추론-oriented 작업에서 주관적 평가도 프롬프트 민감성에 영향을 받습니다. 또한, 모델의 높은 신뢰도가 프롬프트 강건성과 상관관계가 있음을 나타냅니다.



### Tracking Universal Features Through Fine-Tuning and Model Merging (https://arxiv.org/abs/2410.12391)
- **What's New**: 본 연구에서는 다양한 텍스트 도메인에서 미세 조정된 언어 모델 간의 특징 발생, 소멸 및 지속성을 조사합니다. 1층의 Transformer 언어 모델을 BabyLM 코퍼스와 Python 코드의 조합에 대해 훈련시키고, 이후 TinyStories와 Lua 언어에서 각각의 모델을 미세 조정한 후, 구형 선형 보간(Spherical Linear Interpolation) 기술을 사용하여 이 두 모델을 통합합니다.

- **Technical Details**: 실험은 기초 모델인 BabyPython을 사용하여 진행되며, 이 모델은 BabyLM 100M 코퍼스와 Python 코드의 일부로 훈련됩니다. 각각의 미세 조정 모델은 Lua 언어와 TinyStories 데이터셋으로 이루어져 있으며, 이들은 통합되어 LuaStories라는 새로운 모델이 생성됩니다. 특징 추출은 Sparse Autoencoder를 통해 이루어지며, 3백만 토큰의 데이터를 샘플링하여 특징 활성화 패턴을 수집합니다. 특징의 지속 가능성은 80% 이상의 상관관계를 기준으로 정의됩니다.

- **Performance Highlights**: LuaStories 모델은 원래의 Lua와 TinyStories 각 모델에 비해 정확도가 20% 낮지만, 두 모델의 공통 기초 모델에 비해서는 약 20% 향상된 성능을 보입니다. 이 모델은 Lua와 TinyStories 데이터 모두에 대해 동등하게 정확한 모델링을 제공합니다.



### Prompt Compression for Large Language Models: A Survey (https://arxiv.org/abs/2410.12388)
- **What's New**: 최근 대규모 언어 모델(LLMs)을 활용하여 복잡한 자연어 작업을 수행하는 데 있어 긴 프롬프트(prompt)를 사용하는 것이 메모리 사용량과 추론 비용을 증가시킴에 따라, 프롬프트 압축(prompt compression) 기술에 대한 연구 관심이 높아지고 있습니다.

- **Technical Details**: 본 설문조사는 하드 프롬프트(hard prompt) 방법과 소프트 프롬프트(soft prompt) 방법으로 분류된 여러 프롬프트 압축 기술을 개관합니다. 이러한 기술의 기술적인 접근 방식을 비교하고, attention optimization, Parameter-Efficient Fine-Tuning (PEFT), modality fusion, 새로운 합성 언어(synthetic language)의 관점에서 이들의 메커니즘을 이해하는 다양한 방법을 탐구합니다.

- **Performance Highlights**: 프롬프트 압축 기술의 다운스트림(downstream) 적응을 검토한 후, 현재 프롬프트 압축 방법의 한계점을 분석하고, 압축 인코더 최적화, 하드 및 소프트 프롬프트 방법의 결합, 다중 모달리티(multimodality)에서의 통찰력 활용 등 여러 미래 방향을 제시합니다.



### Evaluation of Attribution Bias in Retrieval-Augmented Large Language Models (https://arxiv.org/abs/2410.12380)
- **What's New**: 이 논문에서는 retrieval augmented generation (RAG)에서 모델 출력의 검증 가능성을 높이기 위해 소스 문서에 답변을 귀속시키는 방법을 다룹니다. 특히, 우리는 LLMs의 귀속 민감도(attribution sensitivity)와 저자(authorship) 정보에 대한 편향(bias)을 검사합니다.

- **Technical Details**: 연구는 LLM에게 소스 문서의 저자에 대한 정보를 제공하고 이를 바탕으로 답변을 귀속시키도록 지시하는 실험적 설정을 설계했습니다. 여기서는 counterfactual evaluation을 사용하여 세 가지 LLM을 분석하며, 귀속 민감도와 편향을 평가합니다.

- **Performance Highlights**: 연구 결과, 소스 문서의 저자 정보를 추가하는 것이 LLM의 귀속 품질을 3%에서 18%까지 상당히 변화시킬 수 있음을 발견했습니다. 또한, LLM은 명시적인 인간 저자에게 귀속되는 경향이 있으며, 이는 이전 연구에서 LLM 생성 콘텐츠가 인간 작성 콘텐츠보다 선호될 수 있다는 결과에 대한 대안 가설로 작용할 수 있음을 보여줍니다.



### HerO at AVeriTeC: The Herd of Open Large Language Models for Verifying Real-World Claims (https://arxiv.org/abs/2410.12377)
Comments:
          A system description paper for the AVeriTeC shared task, hosted by the seventh FEVER workshop (co-located with EMNLP 2024)

- **What's New**: 이번 논문에서는 AVeriTeC 공유 작업을 위해 자동 사실 확인 프로세스를 수행하는 HerO 시스템을 소개합니다. HerO는 공개적으로 이용 가능한 Large Language Models (LLMs)만을 이용해 여러 단계의 자동 사실 확인을 수행하며, 이는 real-world claims(실제 세계의 주장) 검증에 그 가능성을 보여줍니다.

- **Technical Details**: HerO는 Evidence Retrieval(증거 검색), Question Generation(질문 생성), Veracity Prediction(진위 예측)의 각 단계에 LLM을 활용합니다. 특히, Generic Language Model('gpt') 및 Gemini 모델과 같은 독점적 LLM을 사용하지 않고, 오픈 LLM만 사용하여 시스템의 투명성을 확보했습니다. 하이브리드 검색 방법을 통해 상위 10개의 증거 후보를 결정합니다. 우리 시스템은 llama-3.1-70b와 SFR-embedding-2를 사용하여 최적의 성능을 보였습니다.

- **Performance Highlights**: HerO는 AVeriTeC 점수 0.57로 리더보드에서 2위를 차지했으며, 일반 LLM을 사용한 시스템이 실제 주장을 검증하는 데 성공적인 가능성을 보여주었습니다. 논문은 미래 연구를 위해 소스 코드를 공개합니다.



### GECTurk WEB: An Explainable Online Platform for Turkish Grammatical Error Detection and Correction (https://arxiv.org/abs/2410.12350)
- **What's New**: GECTurk WEB은 터키어의 문법 오류를 감지하고 수정할 수 있는 새로운 웹 기반 시스템으로, 기존의 도구들이 주로 맞춤법 오류에 집중했던 것과는 달리, 문법 오류에 중점을 두고 개발되었습니다.

- **Technical Details**: 이 시스템은 쉬운 접근성을 제공하며, 복잡한 문법 규칙을 가진 터키어의 일반적인 오류를 감지합니다. 여기에는 диacritics의 잘못된 사용, 복합어 및 외래어, 대명사, 경구와 같은 오류가 포함됩니다. 오프라인 및 온라인 도구로 제공되며 사용 효율성을 88.3으로 평가받았습니다.

- **Performance Highlights**: GECTurk WEB은 사용자가 문법 규칙을 학습하고 기억하는 데 도움을 주며, 참가자의 80%가 제시된 설명을 통해 문법 규칙을 이해하는 데 효과적이었다고 응답했습니다.



### A linguistic analysis of undesirable outcomes in the era of generative AI (https://arxiv.org/abs/2410.12341)
- **What's New**: 이 연구는 생성 AI 모델의 중장기 영향을 분석하며, 기계 생성 정보의 신뢰성을 탐구합니다. 특히, 기존 연구에서 소홀히 다루어진 언어적 측면을 집중적으로 분석하기 위해 LLama2의 대화형 버전을 기반으로 포괄적인 시뮬레이션 프레임워크를 제시합니다.

- **Technical Details**: 모델의 성능 저하는 'self-consuming loop'에 의해 일어납니다. 이 연구에서는 텍스트의 다양성을 측정하기 위해 엔트로피(Entropy), TTR(지수적 정확도)와 같은 언어적 척도와 POSTags 빈도를 사용합니다. 또한, n-그램(N-gram) 분석 및 의미망(Semantic Networks)을 통해 생성된 콘텐츠를 평가합니다.

- **Performance Highlights**: 연구 결과, LLama2 모델은 생성 과정에서 텍스트의 어휘적 풍부함이 감소하고 다양성이 줄어들며, 모델의 성능 저하는 콘텐츠의 질 저하와 동시에 언어적 패턴 왜곡으로 이어져 있다고 합니다. 이는 초기 입력 텍스트의 선택과 관리가 모델 붕괴 문제 해결에 매우 중요함을 강조합니다.



### Understanding the Role of LLMs in Multimodal Evaluation Benchmarks (https://arxiv.org/abs/2410.12329)
- **What's New**: 본 논문은 Multimodal Large Language Models (MLLMs)의 평가에서 LLM 백본(LLM backbone)의 역할을 심도있게 조사하여, 현재의 벤치마크가 실제로 멀티모달 추론(multimodal reasoning)을 평가하는 정도와 LLM의 사전 지식(prior knowledge)이 성능에 미치는 영향을 규명합니다.

- **Technical Details**: 우리는 LLM 백본과 멀티모달 통합(multimodal integration)의 기여도를 분리하기 위한 수정된 평가 프로토콜(modified evaluation protocol)과 LLM이 멀티모달 질문에 필요한 지식을 갖추고 있는지를 진단하는 자동 지식 식별 기술(automatic knowledge identification technique)을 소개합니다. 연구는 네 가지 다양한 MLLM 벤치마크와 여덟 가지 최첨단 MLLMs를 포함합니다.

- **Performance Highlights**: 핵심 발견은 일부 벤치마크가 시각적 입력 없이도 높은 성능(high performance)을 허용하며, LLM 백본의 부족한 세계 지식이 오류율의 최대 50%를 차지할 수 있다는 것입니다. 이는 언어 능력에 대한 심한 의존도를 보여줍니다. 지식 부족 문제를 해결하기 위해 우리는 지식 증강 파이프라인(knowledge augmentation pipeline)을 제안하며, 이는 특정 데이터셋에서 최대 60%의 성능 향상을 이루어 약 4배 성능 증가를 가져옵니다.



### Neuron-based Personality Trait Induction in Large Language Models (https://arxiv.org/abs/2410.12327)
- **What's New**: 이번 논문에서는 대형 언어 모델(LLMs)이 개인 특성을 모사하는 능력을 개선하기 위해 새로운 신경 기반 접근법을 제안합니다. 특히, 'PersonalityBench'라는 대규모 데이터셋을 구축하였으며, 이를 활용하여 개인 관련 뉴런을 효율적으로 식별하는 방법을 제시합니다.

- **Technical Details**: PersonalityBench는 심리학에서의 'Big Five' 개인 특성에 기반하여 LLMs의 생성 능력을 평가하는 데이터셋입니다. 이 연구에서 제안하는 방법은 특정 특성의 반대 측면을 조사하여 개인 관련 뉴런을 식별하고, 이러한 뉴런의 값을 조작하여 LLMs의 특성을 세밀하게 조절할 수 있게 합니다.

- **Performance Highlights**: 실험 결과, 제안된 뉴런 식별 및 특성 유도 방법이 미세 조정된 모델과 유사한 성능을 보여주며, 개인 특성 유도에 있어 보다 효율적이고 유연한 솔루션을 제공합니다.



### Optimizing Low-Resource Language Model Training: Comprehensive Analysis of Multi-Epoch, Multi-Lingual, and Two-Stage Approaches (https://arxiv.org/abs/2410.12325)
Comments:
          16 pages, 10 figures

- **What's New**: 본 논문은 저자원 언어(Low-resource language)를 위한 대형 언어 모델(Large Language Models, LLM)의 훈련 설정 최적화에 대한 문제를 다루고 있습니다. 기존의 연구들은 제한된 목표 언어 코퍼스를 효율적으로 활용하기 위해 다중 에포크, 다국어( multilingual), 및 이단계(training) 훈련 방법을 채택했지만, 이 세 가지 접근 방식을 결합하여 LLM 훈련을 위한 최적의 하이퍼파라미터 설정에 대한 이해가 부족했습니다.

- **Technical Details**: (1) 목표 언어 코퍼스의 양이 줄어들수록, 최적의 훈련 접근 방식은 단일 언어 단일 단계 훈련에서 다국어 이단계 훈련으로 전환됩니다. 이는 계산 예산(compute budget)에 따라 변경되는 기준이 있습니다. (2) 최적의 모델 규모(model scale)는 목표 언어 코퍼스의 양에 관계없이 안정적으로 유지되어, 단일 언어 훈련의 계산 최적 규모를 사용할 수 있습니다. (3) 최적의 에포크 수(epoch number)는 소규모 실험에서 대규모로 외삽(extrapolated)할 수 있습니다.

- **Performance Highlights**: 단일 단계 훈련(single-stage training)에서 목표 언어 검증 손실(validation loss)은 목표 언어 비율(target language ratio)에 대해 거듭제곱 법칙(power law)을 따른다고 주장하며, 이는 데이터 양, 모델 규모 또는 언어 쌍(pair)과는 무관한 지수를 가지고 있습니다.



### Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up (https://arxiv.org/abs/2410.12323)
- **What's New**: 이번 논문에서는 Reversal of Thought (RoT)라는 새로운 프레임워크를 제안하여 대형 언어 모델(LLM)의 논리적 추론 능력을 향상시킵니다. RoT는 메타 인지 메커니즘을 통합하여 LLM이 사람의 피드백에 기반하여 cognitive preference에 맞게 태스크별 프롬프트를 생성할 수 있도록 지원합니다.

- **Technical Details**: RoT는 Preference-Guided Reverse Reasoning 전략을 활용하여, pseudocode 계획을 위한 논리 기호를 통합하고, 쌍대 선호 자기 평가를 통해 특정 태스크를 위한 프롬프트를 생성합니다. 또한, Cognitive Preference Manager를 통해 LLM의 지식 경계를 평가하고, 알려진 태스크에 대한 솔루션 논리를 집계하며, 알려지지 않은 태스크에 대한 스타일 템플릿을 사용하여 논리적 추론 능력을 확장합니다.

- **Performance Highlights**: 여러 태스크에서의 실험 결과, RoT는 기존 방법들보다 논리적 추론의 정확성과 효율성 모두에서 우수한 성능을 보였습니다. 이는 RoT가 LLM의 논리적 유연성과 정확성을 동시에 개선하는 데 기여함을 나타냅니다.



### Open Domain Question Answering with Conflicting Contexts (https://arxiv.org/abs/2410.12311)
- **What's New**: 이 논문은 웹에서 검색된 정보가 상충하는 경우에 대해 다룬 첫 번째 연구 중 하나로, 25%의 명확한 질문이 상충하는 정보에 이끌릴 수 있음을 보여줍니다. 이 연구는 Question Answering with Conflicting Contexts (QACC)라는 데이터셋을 수집하고, 이를 기반으로 대형 언어 모델(LLMs)의 한계를 분석합니다.

- **Technical Details**: 연구팀은 Google Search API를 사용하여 명확한 질문에 대한 결과를 수집하고, Amazon Mechanical Turk를 통해 인간 주석자들이 상충하는 대답의 존재 여부를 판단하도록 했습니다. 이를 통해 명확한 질문의 약 25%가 상충하는 정보를 생성함을 발견했습니다. 또한, 이들은 GPT-3.5, Claude-3, Phi-3와 같은 세 가지 LLM을 평가하였고, 이러한 상충이 성능 저하를 초래한다는 것을 보여주었습니다.

- **Performance Highlights**: 주석자의 자연어 설명으로 LLM을 파인튜닝한 결과, LLM의 성능이 향상되었습니다. 특히, QACC 데이터셋과 DQ-Open 데이터셋에서 상충하는 정보를 처리하는 능력이 개선되었습니다. 이는 LLM이 상충하는 맥락을 이해하고 올바른 답변을 내리는 데 도움이 되는 중요한 통찰을 제시합니다.



### Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering Vectors (https://arxiv.org/abs/2410.12299)
- **What's New**: 이번 논문에서는 Semantics-Adaptive Dynamic Intervention (SADI)라는 새로운 접근법을 제안하여 기존의 고정된 Steering Vector의 한계를 극복하고, 다양한 입력 의미에 따라 모델 활성화를 동적으로 조정할 수 있는 방법을 제시합니다.

- **Technical Details**: SADI는 Contrastive Pairs의 활성화 차이를 활용하여 모델 활성화에 영향을 미치는 중요한 요소들을 정확히 식별합니다. 이 방법은 Binary Masking을 통해 중요한 요소를 식별하고, Adaptive Steering을 통해 입력 의미에 따라 동적으로 모델 활성화를 조정하는 과정을 포함합니다.

- **Performance Highlights**: SADI는 LLaMA2-7b-chat, BLOOMZ-7b, Mistral-7b, Falcon-7b-instruct 등 다양한 모델 백본에서 11개의 주요 벤치마크 과제를 대상으로 실험한 결과, 기존 방법보다 성능이 크게 향상되었으며, 정확도 향상은 최대 +14.69에 달했습니다.



### Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs (https://arxiv.org/abs/2410.12298)
- **What's New**: Pyramid-Driven Alignment (PDA)라는 새로운 프레임워크를 제안하여 LLM(대형 언어 모델)과 KG(지식 그래프)의 통합을 최적화하고, 이를 통해 더 정확한 질문-답변 작업을 수행할 수 있도록 한다.

- **Technical Details**: PDA는 Pyramid Principle 분석을 사용하여 계층적 피라미드 구조를 구축하며, 이것이 입력 질문을 반영하도록 설계된다. 또한, 재귀적 메커니즘을 통해 KG의 추론 능력을 활용하여 질문-답변 작업을 위한 더 정확한 지식 검색을 가능하게 한다.

- **Performance Highlights**: PDA는 2WikiMultihopQA, Mintaka, WebQuestionsSP와 같은 세 가지 데이터셋에서 실험을 진행했으며, 각 데이터셋에서 SOTA(최첨단 성능) 결과를 달성하여 최대 26.70% 및 26.78%의 성능 향상을 이뤄냈다.



### How much do contextualized representations encode long-range context? (https://arxiv.org/abs/2410.12292)
Comments:
          17 pages, 9 figures

- **What's New**: 이 논문에서는 신경 오토회귀 언어 모델에서의 긴 범위 문맥(context)을 분석하며, 특히 수천 개 토큰이 포함된 문맥을 중점적으로 다룹니다. 새로운 방법론으로 \'비대칭 보정 코사인 유사도(Anisotropy-Calibrated Cosine Similarity, ACCS)를 사용하여 문맥화의 정도를 측정합니다.

- **Technical Details**: 연구에서는 문맥-혼합(context-mixing) 과정을 통해 긴 범위 문맥이 어떻게 표현되는지를 분석합니다. 이를 위해 다양한 아키텍처와 훈련 설정을 가진 모델을 대상으로 실험을 실시했으며, ACCS라는 메트릭을 통해 숨겨진 표현이 얼마나 문맥화되어 있는지를 정량화합니다. 또한, 회귀 모델과 하이브리드 모델의 차이점도 강조됩니다.

- **Performance Highlights**: 결과에 따르면, 고복잡성 시퀀스에 대한 인식 능력이 아키텍처에 따라 차이가 있으며, 하이브리드 모델이 긴 문맥의 구조를 더 효과적으로 인코딩함을 보여줍니다. 또한, 훈련 구성과 모델 크기 역시 긴 범위 문맥 인코딩에 큰 영향을 미치며, 이러한 결과는 기존 언어 모델의 발전 방향에 대한 힌트를 제공합니다.



### Kallini et al. (2024) do not compare impossible languages with constituency-based ones (https://arxiv.org/abs/2410.12271)
- **What's New**: 이 논문은 언어 모델이 인간 언어의 경계를 이해하는 데 어떻게 사용될 수 있는지를 탐구하며, GPT-2가 다양한 인공 언어(synthetic languages)를 학습할 때의 비대칭성(asymmetry)을 분석합니다.

- **Technical Details**: Kallini et al. (2024)의 연구에 따르면, LLMs(large language models)는 인간 언어를 학습하는 데 성공할 뿐만 아니라 불가능한 언어 언어(impossible languages)를 학습하는 데 어려움을 겪는지 테스트하였습니다. 이 비대칭성은 LLM의 귀납적 편향(inductive biases)이 인간 언어에 대한 가능성과 일치한다는 지지를 제공합니다.

- **Performance Highlights**: 논문에서 제시된 주요 비판은 Kallini et al.의 비교가 잘못된 혼합(confound)을 포함하고 있으며, 더욱 적절한 비교를 위해 다양한 constituency-based 규칙을 탐색할 것을 제안합니다.



### An Automatic and Cost-Efficient Peer-Review Framework for Language Generation Evaluation (https://arxiv.org/abs/2410.12265)
- **What's New**: 대형 언어 모델(LLM)의 평가 효율성을 높이기 위한 새로운 연구인 Auto-PRE 시스템이 소개되었습니다. 이 시스템은 이전의 수동 평가 방식에서 벗어나 자동으로 평가자 LLM을 선택하는 독창적인 접근 방식을 사용합니다.

- **Technical Details**: Auto-PRE는 평가의 일관성(consistency), 자기 신뢰성(self-confidence), 적합성(pertinence) 등 평가자의 특성을 기반으로 하여 LLM의 평가를 수행하는 자동화된 프레임워크입니다. 이 연구에서는 요약 생성(summary generation), 비사실 질문 대답(non-factoid question-answering), 대화 생성(dialogue generation) 등 세 가지 작업에 대한 실험을 진행했습니다.

- **Performance Highlights**: Auto-PRE 시스템은 낮은 비용으로 최첨단 성과(state-of-the-art performance)를 달성했으며, 프롬프트 전략(prompt strategies) 및 평가 형식(evaluation formats)이 평가 성과에 미치는 영향을 강조했습니다. 이는 미래의 방법 최적화(method optimization)에 대한 지침을 제공합니다.



### CoFE-RAG: A Comprehensive Full-chain Evaluation Framework for Retrieval-Augmented Generation with Enhanced Data Diversity (https://arxiv.org/abs/2410.12248)
- **What's New**: 본 논문에서는 Retrieval-Augmented Generation (RAG) 시스템의 평가를 개선하기 위한 Comprehensive Full-chain Evaluation (CoFE-RAG) 프레임워크를 제안합니다. 이 프레임워크는 RAG 파이프라인의 모든 단계에서 철저한 평가를 수행할 수 있도록 도와줍니다.

- **Technical Details**: CoFE-RAG 프레임워크는 chunking, retrieval, reranking, generation을 포함한 전반적인 RAG 파이프라인의 평가를 지원합니다. 평가를 효과적으로 수행하기 위해 coarse-grained 및 fine-grained 키워드를 도입하여, golden chunks의 주석에 의존하지 않고 수집된 문맥을 평가합니다. 또한, 다양한 데이터 시나리오를 다루는 벤치마크 데이터셋을 발표하였습니다.

- **Performance Highlights**: 실험을 통해 각 단계에서 RAG 시스템의 효과를 평가하여, 다양한 데이터 시나리오를 처리하는 RAG 시스템의 능력과 한계를 더 미세하게 이해할 수 있는 통찰력을 제공합니다.



### EPS-MoE: Expert Pipeline Scheduler for Cost-Efficient MoE Inferenc (https://arxiv.org/abs/2410.12247)
Comments:
          13 pages, 14 figures

- **What's New**: 이번 논문에서는 새로운 expert pipeline scheduler인 EPS-MoE를 제안합니다. 이 방법은 기존의 LLM inference parallelism 전략을 넘어서는 혁신적인 방식을 제공합니다.

- **Technical Details**: EPS-MoE는 MoE 아키텍처의 FFN(FeedForward Network) 모듈의 계산을 최적화하는 데 중점을 두며, GroupGemm과 DenseGemm의 최적 핵심 구현을 동적으로 선택하여 다른 작업 부하(load)에 대해 적응적으로 \\textit{all2all} 통신과 겹치게 함으로써 처리량(throughput)을 크게 증가시킵니다.

- **Performance Highlights**: 실험 결과, 기존의 병렬 추론 방법에 비해 평균 21% 향상된 prefill throughput을 보였습니다. 특히, DeepSeekV2 모델에서 EPS-MoE를 적용하여 초당 100K tokens의 prefill throughput에서 at least 120K tokens per second로 가속화했습니다.



### On A Scale From 1 to 5: Quantifying Hallucination in Faithfulness Evaluation (https://arxiv.org/abs/2410.12222)
Comments:
          14 pages, 13 figures

- **What's New**: 이번 논문에서는 자동화된 사실성 평가를 통해 자연어 생성(NLG)의 신뢰성을 높이기 위한 방법을 연구하였습니다. 특히, 신뢰도를 평가하기 위해 대형 언어 모델(LLM)을 활용한 점수 매기기 방법을 제안하였습니다.

- **Technical Details**: 제안된 방법은 LLM과 자연어 추론(NLI) 모델을 이용하여 참조(referece)와 가설(hypothesis) 쌍의 신뢰성 점수를 도출합니다. 또한, 다양한 유형의 가설을 비교하여 신뢰도 점수의 변동성을 분석하였고, 합성된 비신뢰한 데이터를 생성하는 방법도 개발하였습니다.

- **Performance Highlights**: 연구 결과, GPT-4 모델은 소스와 생성이 사실적으로 일치하는지를 정확하게 판단하고 설명할 수 있음을 보여주었습니다. 비신뢰성 데이터로 NLI 모델을 조정할 경우 성능이 향상되었고, 이러한 시스템의 배포 시 레이턴시(latency)와 비용에 대한 통찰도 제공하였습니다.



### Accurate and Data-Efficient Toxicity Prediction when Annotators Disagr (https://arxiv.org/abs/2410.12217)
- **What's New**: 본 논문은 전통적인 라벨 집계 방법의 한계를 극복하고 개별 주석자(annotator)가 주는 라벨을 예측하는 새로운 접근법을 소개합니다. 특히, 개별 주석자에 대한 정보를 통합하여 텍스트의 독성(toxicity)을 평가하는 세 가지 방법, 즉 Neural Collaborative Filtering(NCF), In-Context Learning(ICL), 및 Intermediate Embedding 기반 아키텍처를 제안합니다.

- **Technical Details**: 우선 NCF(Nural Collaborative Filtering) 접근방식과 ICL(In-Context Learning) 접근방식은 주석자별 역사(history), 인구통계학적(demographic) 정보 및 설문조사(survey) 정보를 통합하여 예측 정확도를 향상시킵니다. 특히, embedding 기반 아키텍처는 다른 방식보다 월등한 성능을 보였습니다. 또한, 설문조사 정보를 통해 예측된 인구통계학적 데이터를 사용하는 것이 실제 데이터와 비슷한 성능을 내는 것으로 나타났습니다.

- **Performance Highlights**: 연구 결과에 따르면, 각기 다른 주석자 정보 타입의 상대적 유용성을 고려해야 하며, 주관적 자연어 처리(NLP) 작업에서 주석자 모델링을 위한 새로운 접근법을 제공합니다. embedding 기반 아키텍처는 예측 정확도를 크게 높여 주목받았습니다.



### Negative-Prompt-driven Alignment for Generative Language Mod (https://arxiv.org/abs/2410.12194)
- **What's New**: 대형 언어 모델들이 눈에 띄는 능력을 보이고 있지만, 그 출력을 인간의 가치와 선호에 맞추는 것은 여전히 중요한 도전 과제로 남아 있습니다. 기존의 정렬 방법들은 주로 긍정적인 예제에 초점을 맞추고 부정적인 응답의 중요성을 간과하고 있습니다.

- **Technical Details**: NEAT(NEgative-prompt-driven AlignmenT)를 제안합니다. 이 방법은 최적화 과정에서 긍정적인 예제와 함께 부정적인 프롬프트를 사용해 바람직하지 않은 응답을 생성합니다. NEAT는 유해한 출력을 생성하는 모델에 대해 명시적으로 페널티를 부과하여, 바람직한 행동으로 유도하며 동시에 바람직하지 않거나 편향된 응답 생성을 피하도록 합니다. 이를 통해 선호도에 대한 온라인 정렬을 수행하며, 확장된 선호도 데이터셋을 기반으로 랭킹 손실(ranking loss)을 통합합니다.

- **Performance Highlights**: 광범위한 실험을 통해 NEAT의 효과성을 검증하였으며, 언어 모델이 인간의 가치와 선호에 더 잘 정렬되도록 유의미하게 향상됨을 나타냈습니다.



### Exploring Large Language Models for Hate Speech Detection in Rioplatense Spanish (https://arxiv.org/abs/2410.12174)
- **What's New**: 본 논문에서는 Rioplatense 스페인어에서의 혐오 발언 감지(Hate Speech Detection)에서 대형 언어 모델(Large Language Models)의 성능을 분석합니다. 특히, ChatGPT 3.5, Mixtral, Aya와 최신의 BERT 분류기와의 비교 실험을 통해 대형 언어 모델의 장단점을 밝혔습니다.

- **Technical Details**: 논문에서는 체인 오브 띵크(Chain-of-Thought) 추론을 활용하여 실험을 수행하였습니다. 실험은 대형 언어 모델이 정교하게 조정된 BERT 분류기에 비해 낮은 정밀도를 보이긴 했지만, 특히 동성애 혐오 및 성별 정체성에 대한 혐오 발언과 같은 미세한 사례에 대해서는 민감하다는 것을 보여줍니다.

- **Performance Highlights**: 대형 언어 모델은 특정 비속어(slang) 또는 속어(slum)를 검출하는 데 어려움을 겪는 경우가 있지만, 이전에 언급한 미세한 경우에서는 여전히 좋은 성능을 발휘합니다. 또한, 우리가 개발한 코드와 모델은 향후 연구를 위해 공개되었습니다.



### Table-LLM-Specialist: Language Model Specialists for Tables using Iterative Generator-Validator Fine-tuning (https://arxiv.org/abs/2410.12164)
- **What's New**: 이번 연구에서 우리는 Table-LLM-Specialist, 즉 Table-Specialist를 제안하며, 이는 테이블 작업을 위한 새로운 자기 학습(fine-tuning) 패러다임입니다. 각 테이블 작업에는 생성(generative)적 특성과 분류(classification)적 특성을 가지는 두 가지 대칭적인 버전이 존재한다는 점을 통찰합니다. 이를 통해 'Generator-Validator' 패러다임을 제안하며, 수작업으로 라벨링된 데이터 없이도 강력한 모델을 세분화할 수 있음을 보여줍니다.

- **Technical Details**: Table-Specialist 모델은 특정 테이블 작업에 특화되어 있으며, 이를 지원하기 위해 언어 모델에서 반복적으로 데이터를 생성(generate)하고 검증(validate)하는 방식으로 학습됩니다. 이 방식은 다양한 실제 테이블에서 체계적으로 생성된 훈련 데이터를 활용하여 이루어집니다.

- **Performance Highlights**: Table-Specialist는 (1) 다양한 테이블 작업에서 강력한 성능을 발휘하며, 예를 들어 GPT-3.5에서 세밀조정(fine-tuning)한 경우 vanilla GPT-3.5보다 성능이 뛰어나고 경우에 따라 GPT-4 수준 품질에 도달합니다, (2) 더 낮은 배포 비용을 제공하며, 적은 지연(latency)과 추론(inference) 비용으로 비슷한 품질을 유지하면서 더 작은 모델을 배포할 수 있습니다, (3) 여러 기준에 대해 평가할 때 더 나은 일반화(generalizability)를 보여줍니다.



### Exploiting LLMs' Reasoning Capability to Infer Implicit Concepts in Legal Information Retrieva (https://arxiv.org/abs/2410.12154)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 이번 연구는 법적 상황과 관련된 법적 용어 및 사실을 식별하기 위해 대형 언어 모델(LLMs)의 논리적 추론 능력을 활용하는 새로운 정보 검색 시스템을 제안합니다. 이 시스템은 전통적인 검색 방법의 한계를 극복하며, 법적 문제를 인식하고 이를 사용하여 쿼리 확장을 수행합니다.

- **Technical Details**: 제안된 방법론은 두 가지 쿼리 확장 기법을 통해 사용되며, 이는 대형 언어 모델의 제로-샷 프롬프트 기법을 통해 법적 개념과 관련된 용어를 생성하고, 이러한 용어를 쿼리에 통합하여 검색 성능을 향상시킵니다. 또한, lexical based ranking model(BM25)과 semantic based ranking model을 통합하여 최적의 검색 결과를 생성합니다.

- **Performance Highlights**: COLIEE 2022와 2023 대회에서 제안된 앙상블 검색 시스템은 모든 참여 팀 중에서 가장 우수한 성과를 달성하였습니다. LLM에서 얻은 추가 정보가 검색 정확도를 크게 향상시키는 데 기여했습니다.



### Layer-of-Thoughts Prompting (LoT): Leveraging LLM-Based Retrieval with Constraint Hierarchies (https://arxiv.org/abs/2410.12153)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 이번 논문에서는 Layer-of-Thoughts Prompting (LoT)라는 새로운 접근 방식을 제시합니다. 이는 제약 계층을 활용하여 주어진 쿼리에 대한 후보 응답을 필터링하고 세분화하는 기법입니다.

- **Technical Details**: LoT 방법은 제약 사항을 통합하여 구조화된 검색 프로세스를 가능하게 하며, 이는 정보 검색 정보를 더 잘 설명하고 자동화할 수 있는 방법입니다. 기존의 방법들은 다양한 프롬프트 기법을 다루었지만, 다중 턴 상호작용에서 프롬프트의 세부 사항에 대한 탐구가 부족했습니다. 이번 연구는 프롬프트간의 계층적 관계에 초점을 맞추어 이 빈틈을 메웁니다. 대형 언어 모델(LLMs)을 활용하여, LoT는 정보 검색 작업의 정확성과 이해도를 크게 향상시킵니다.

- **Performance Highlights**: LoT 기법은 효율적이고 해석 가능한 검색 알고리즘 개발에 결정적인 역할을 하는 사고 계층의 효능을 입증하였습니다. 이 방법은 설명 가능성과 자동화를 강화하여 정보 검색 정확성을 크게 개선했습니다.



### Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning (https://arxiv.org/abs/2410.12130)
- **What's New**: 이 논문은 대형 언어 모델(LLMs)의 환각(hallucination) 문제를 해결하기 위한 새로운 접근법인 Iterative Model-level Contrastive Learning (Iter-AHMCL)을 소개합니다. 이 방법은 환각을 줄이면서도 LLM의 원래 능력을 유지하도록 설계되었습니다.

- **Technical Details**: Iter-AHMCL 방법은 미리 훈련된 LLM의 표현층을 수정하여 환각이 있는 데이터와 없는 데이터를 기반으로 학습된 대비 모델을 사용합니다. 긍정적(positive) 및 부정적(negative) 모델을 통해 환각을 감소시키는 좀 더 직관적인 경로를 생성하고, 반복적인 대조 학습(iterative contrastive learning)을 통해 성능을 향상시킵니다.

- **Performance Highlights**: 본 논문은 LLaMA2, Alpaca, LLaMA3, Qwen 등 네 개의 미리 훈련된 LLM 모델에서 특별히 설계된 데이터셋으로 파인튜닝(finetuning) 실험을 수행하였으며, TruthfulQA 벤치마크에서 평균 10.1 포인트의 성능 향상을 달성했습니다. Iter-AHMCL은 환각을 줄이면서 LLM의 일반적인 능력을 유지하는 효과적인 방법임을 보여줍니다.



### OMCAT: Omni Context Aware Transformer (https://arxiv.org/abs/2410.12109)
Comments:
          Demo page: this https URL

- **What's New**: 대규모 언어 모델(LLMs)의 진전을 바탕으로 새로운 데이터셋(OCTAV)과 모델(OMCAT)을 발표하였습니다. 이 모델은 시청각 기반 질문 응답(task)에서 우수한 성능을 발휘합니다.

- **Technical Details**: OCTAV(Omni Context and Temporal Audio Video)는 소리 이벤트를 통해 비디오에서 발생하는 사건의 전환을 캡처하는 혁신적인 데이터셋입니다. OMCAT(Omni Context Aware Transformer)는 RoTE(Rotary Time Embeddings)를 활용하여 시각 및 청각 데이터를 위한 통합 모델을 제공합니다.

- **Performance Highlights**: OMCAT는 AVQA(Audio-Visual Question Answering) 작업 및 OCTAV 벤치마크에서 최첨단 성능을 보여주며, 시간적 추론과 시청각 정렬에서 의미 있는 개선을 기록했습니다.



### De-jargonizing Science for Journalists with GPT-4: A Pilot Study (https://arxiv.org/abs/2410.12069)
Comments:
          Accepted to Computation+Journalism Symposium 2024

- **What's New**: 이번 연구는 GPT-4 (대형 언어 모델, LLM)와 Retrieval-Augmented Generation (RAG)를 활용하여 과학 논문의 초록에서 전문 용어를 식별하고 정의하는 '인간-기계 협업 시스템'을 평가했습니다. 이 시스템은 독자의 자가 보고 지식을 바탕으로 전문 용어를 정확하게 식별하며, 개인화가 가능함을 보여줍니다.

- **Technical Details**: 제안된 시스템은 과학적인 초록에서 독자의 전문 지식을 바탕으로 복잡한 전문 용어를 식별하고, 각 용어에 대한 간단하고 접근 가능한 정의를 생성합니다. OpenAI의 GPT-4를 사용하여 전문 용어를 식별하고, RAG를 통해 생성된 정의에 대한 맥락을 제공합니다. 이 연구는 64개의 arXiv 사전 인쇄물 데이터를 통해 LLM 기반 시스템의 성능을 평가하였습니다.

- **Performance Highlights**: GPT-4는 독자의 전문 지식에 관계없이 전문 용어를 과다 예측하는 경향이 있으나, 실제로 독자가 식별한 전문 용어에 대한 상대적으로 높은 기억률(0.68의 중앙 기억률)을 보여주었습니다. 또한 초록만을 기반으로 한 정의 생성이 RAG 기반의 전체 본문 맥락보다 더 정확하고 높은 품질을 가진 정의를 생산함을 나타냅니다.



### LegalLens Shared Task 2024: Legal Violation Identification in Unstructured Tex (https://arxiv.org/abs/2410.12064)
- **What's New**: 이번 논문은 LegalLens Shared Task의 결과를 발표하며, 현실에서 법적 위반을 탐지하는 데 중점을 두고 이를 위한 두 가지 하위 작업인 LegalLens-NER과 LegalLens-NLI에 대해 다룹니다.

- **Technical Details**: LegalLens-NER은 비구조화된 텍스트에서 법적 위반 관련 엔티티를 식별하고, LegalLens-NLI는 이 위반을 특정 법적 맥락이나 관련 사례와 연결하는 작업입니다. 38개 팀이 참여했으며, 데이터셋은 노동, 개인정보 보호, 소비자 보호 분야를 포함한 내용으로 구성되었습니다.

- **Performance Highlights**: 최고 성과를 낸 팀은 NER에서 7.11%의 성능 향상을 달성했고, NLI에서도 5.7%의 향상을 보였습니다. 그러나 법적 텍스트의 복잡성으로 인해 여전히 발전 가능한 여지가 많이 남아 있습니다.



### Large-scale cloze evaluation reveals that token prediction tasks are neither lexically nor semantically aligned (https://arxiv.org/abs/2410.12057)
- **What's New**: 이번 연구에서는 여러 언어 모델의 다음 토큰 예측(next token prediction) 수준에서 생성 행동을 비교하여, cloze 작업에서 인간의 생성과 비교합니다. 연구 결과, 대규모 모델들이 일반적으로 인간의 응답을 더 잘 추정하지만, 확률 총합을 과소 평가하고, 희귀한 응답을 과대 평가하며, 최상위 응답을 과소 평가하는 경향이 있다는 것을 발견했습니다. 이 논문은 언어 모델의 생성이 클로즈 작업의 대체나 모델로 사용될 수 없음을 보여줍니다.

- **Technical Details**: 연구는 인간의 생성을 확률적 관점에서 잘 이해하고, LMs와 인간 간의 차이를 더 잘 알아내기 위해 single-word production을 검토합니다. cloze 작업은 문맥이 주어지고 그 안의 한 단어를 추론하는 작업으로, 인간의 응답 예측에서는 P(w|c)로 표기되는 단어의 발생 확률이 관찰된 모든 응답의 상대 빈도로 추정됩니다. 반면 언어 모델은 신경망을 통해 단어에 점수를 부여하고 softmax 함수를 통해 확률 분포를 생성합니다.

- **Performance Highlights**: Peelle et al. (2020)에서 수집한 3,085개의 영어 문장에 대해 인간 응답으로부터 얻은 cloze 확률과 여러 신경 언어 모델(GPT-2, RoBERTa, Pythia 모델 등)에서 추출한 확률을 비교했습니다. 모델들은 약 50,000의 서브워드(subword) 어휘 크기를 사용하며, 모델 크기, 훈련 시간, 데이터 중복 제거와 같은 여러 하이퍼파라미터의 영향을 탐구하는 Pythia 모델이 특히 흥미로운 결과를 제공합니다.



### A State-of-the-Art Morphosyntactic Parser and Lemmatizer for Ancient Greek (https://arxiv.org/abs/2410.12055)
- **What's New**: 이 논문은 고대 그리스어를 위한 최첨단 morphosyntactic parser(구문 분석기) 및 lemmatizer(어간 추출기)를 식별하고 비교하는 실험을 소개합니다. 다양한 최신 모델들이 Ancient Greek Dependency Treebank(고대 그리스어 종속 트리뱅크) 주석 체계에 따라 주석을 추가할 수 있도록 설계되었습니다.

- **Technical Details**: 이 연구는 Dithrax 모델을 기본 모델로 사용하였으며, Trankit과 GreBERTa, PhilBERTa, GreTA, PhilTa와 같은 최신 모델들을 추가로 조정하였습니다. Bayesian 분석 결과, Dithrax와 Trankit은 Morphology에 대한 주석을 거의 동일하게 수행하며, Trankit은 Syntax에 가장 적합하고 GreTa는 Lemmata에 우수함을 나타냅니다. 이 연구는 Token Embeddings가 높은 UAS(간접 성능 점수) 및 LAS(구조적 성능 점수)를 달성하기에는 불충분하다는 점 강조하며, 특히 구문 관계를 주의 깊게 포착하도록 설계된 모델링 전략이 필요합니다.

- **Performance Highlights**: 실험 결과, Dithrax와 Trankit의 Morphosyntactic 주석 성능은 비슷하며, Trankit은 Syntax에 대한 주석 정확도가 가장 높고, GreTa는 Lemmata에서 최고의 성능을 보였습니다. 최우수 성능 모델들이 온라인에서 재사용을 위해 제공됩니다.



### Skill-LLM: Repurposing General-Purpose LLMs for Skill Extraction (https://arxiv.org/abs/2410.12052)
- **What's New**: 이번 연구에서는 기술 및 LLM(대규모 언어 모델)의 전문화된 버전인 Skill-LLM을 미세 조정하여 직무 설명서에서 기술을 추출하는 정확도를 향상시키는 방법을 제안합니다.

- **Technical Details**: 본 연구에서는 NER(명명된 개체 인식) 기술을 활용하고, 기존 최첨단(SOTA) 방법들과의 성능을 비교하기 위해 다양한 벤치마크 데이터셋을 사용했습니다. LLM을 기반으로 한 학습된 모델은 복잡한 프롬프트 없이도 안정적이고 정확한 출력을 생성할 수 있습니다.

- **Performance Highlights**: 기존 SOTA 기법들에 비해 F1 점수가 개선되었으며, 경량 모델을 미세 조정함으로써 제한된 컴퓨팅 리소스에서도 우수한 성능을 발휘하였습니다.



### Sabi\'a-3 Technical Repor (https://arxiv.org/abs/2410.12049)
- **What's New**: Sabiá-3는 브라질 중심의 대규모 데이터셋으로 훈련된 새로운 언어 모델로, 포르투갈어 및 브라질 관련 과제에서 우수한 성능을 보여줍니다. Sabiá-2와 비교하여 특히 추론 요구 과제에서 크게 향상되었습니다.

- **Technical Details**: Sabiá-3는 브라질 문화와 역사에 맞춘 포르투갈어 문서 데이터셋으로 훈련되었습니다. 두 가지 주요 단계에서 개발 되었습니다: (1) 사전 훈련(Pre-training) 단계에서 고품질 데이터에 대한 자기지도 학습(Self-supervised learning) 전략으로 훈련, (2) 사후 훈련(Post-training) 단계에서 인간의 선호에 맞춰 조정되었습니다. TPU v5 가속기를 사용하여 효율적으로 훈련했습니다.

- **Performance Highlights**: Sabiá-3는 ENADE 2022 및 2023 시험에서 Sabiá-2에 비해 70% 오류 감소를 보였고, GPT-4o와 경쟁력 있는 성능을 발휘했습니다. 특히 CPNU 시험에서 주목할 만한 성과를 보여 다른 모델들보다 높은 정확도를 달성했습니다.



### Boosting Logical Fallacy Reasoning in LLMs via Logical Structure Tr (https://arxiv.org/abs/2410.12048)
Comments:
          Accepted to EMNLP 2024

- **What's New**: 이 연구는 논리적 오류(logical fallacy)를 탐지하고 분류하기 위한 새로운 접근법을 제안합니다. 구체적으로, 연구진은 연결어(connective words)를 통해 제안된 논리적 관계와 실제 논리적 관계 간의 불일치를 인식하는 데 초점을 맞추고, 이를 통해 기존의 접근법을 개선합니다.

- **Technical Details**: 연구진은 '논리 구조 트리(logical structure tree)'를 구성하여 연결어와 그에 해당하는 텍스트 인수를 계층적으로 표현합니다. 이 트리는 비지도 학습(unsupervised learning) 방식으로 구성되며, 연결어는 비단말 노드(non-terminal nodes), 텍스트 인수는 단말 노드(terminal nodes)로 배치됩니다. 논리 구조 트리는 LLMs(대형 언어 모델)에 두 가지 방법으로 통합됩니다: 1. 트리를 자연어 설명(natural language descriptions)으로 변환하여 LLMs에 입력, 2. 트리 임베딩(tree embedding)을 도출하여 소프트 프롬프트(soft prompt)로 삽입.

- **Performance Highlights**: 벤치마크 데이터를 기반으로 한 실험 결과, 이 연구는 논리적 오류 탐지에서 F1 점수를 최대 3.45%, 분류에서 최대 6.75% 향상시켰습니다. 이를 통해 제안된 접근법이 오류 탐지 및 분류 작업에서 상당한 성과를 거두었음을 입증했습니다.



### Concept-Reversed Winograd Schema Challenge: Evaluating and Improving Robust Reasoning in Large Language Models via Abstraction (https://arxiv.org/abs/2410.12040)
- **What's New**: 이 논문에서는 LLMs의 reasoning 성능을 평가하기 위한 새로운 데이터셋인 Concept-Reversed Winograd Schema Challenge (CR-WSC)를 제안합니다. 이 데이터셋은 기존의 Winograd Schema Challenge (WSC)에서 개념을 반전시켜 LLMs가 잘못된 대답과 더 연관된 답변을 이끌어내도록 구성되었습니다.

- **Technical Details**: CR-WSC 데이터셋은 LLM의 약점을 이용한 적대적인 질문들을 포함하고, Abstraction-of-Thought (AoT)라는 새로운 프롬프트 방법을 통해 LLMs의 robustness를 향상시키고자 합니다. AoT는 문제를 일반화하여 추상화한 후 reasoning을 수행하는 두 단계의 접근 방식을 채택합니다.

- **Performance Highlights**: 실험 결과, CR-WSC는 기존의 WSC에 비해 LLMs에게 상당히 더 어려운 과제로 나타났으며, AoT를 사용함으로써 LLMs의 reasoning 성능과 robustness가 현저하게 향상되었습니다.



### On Classification with Large Language Models in Cultural Analytics (https://arxiv.org/abs/2410.12029)
- **What's New**: 본 논문에서는 문화 분석(cultural analytics)에서의 분류(classification) 사용 방식과 대형 언어 모델(LLMs)의 적합성을 조사합니다. 공공 데이터셋을 기반으로 한 10개의 작업을 정의하고 LLMs와 전통적인 감독 학습(supervised methods) 간의 성능을 비교합니다. LLMs는 기존의 작업에서는 경쟁력을 보이지만 새로운 작업에는 부족함을 보입니다.

- **Technical Details**: LLMs를 통한 분류 수행 방식을 네 가지 차원으로 탐구합니다: 1) 최근 문화 분석에서의 분류 사용 조사의 결과, 2) 실험 가능한 10개의 작업 정의, 3) 다양한 분류 모델(예: bag-of-words, masked language models, large language models)의 성능 벤치마크 수행, 4) LLMs를 통한 카테고리 이해 및 탐색적 데이터 분석(exploratory data analysis) 수행.

- **Performance Highlights**: 기존의 영어 기반 작업에서는 LLMs가 전통적 감독 모델과 경쟁할 수 있으나, 새로운 작업에서는 만족스럽지 못한 성능을 보였습니다. 이 연구는 LLMs가 탐색적 데이터 분석(in exploratory data analysis)을 지원할 수 있는 방법을 제시합니다.



### MoE-Pruner: Pruning Mixture-of-Experts Large Language Model using the Hints from Its Router (https://arxiv.org/abs/2410.12013)
- **What's New**: 새로운 논문에서는 Mixture-of-Experts (MoE) 아키텍처의 메모리 소비 및 전문가 중복성을 줄이기 위해 MoE-Pruner라는 방법을 제안합니다. 이 방법은 각 출력 뉴런에서 입력 활성화와 라우터 가중치를 곱한 최소 크기의 가중치를 가지는 방법으로 일회를 통해 손실을 최소화합니다.

- **Technical Details**: MoE-Pruner는 활발하지 않은 전문가의 가중치를 제거하여 모델을 가지치기하는 기법입니다. 이 프로세스는 재학습이나 가중치 업데이트 없이 한 번의 조정 데이터만으로 수행됩니다. Mixtral-8x7B 및 Mixtral-8x22B 모델에 대해 여러 언어 벤치마크에서 그 효용성이 입증되었습니다.

- **Performance Highlights**: Mixtral-8x7B 모델은 50%의 희소성을 가지면서도 원래 모델의 99% 성능을 유지하며, 전문가별 지식 증류를 통해 성능 회복이 가능합니다. 기존의 최첨단 LLM 가지치기 방법들에 비해 우수한 결과를 보였습니다.



### Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models (https://arxiv.org/abs/2410.12011)
Comments:
          9 pages, Accepted to EMNLP 2025 Main

- **What's New**: PIXEL 모델은 서브워드 기반 언어 모델의 대안으로 등장했으며, 다양한 스크립트를 표현할 수 있는 능력을 보여줍니다. 그러나 이 모델은 대부분의 언어 과제에서 BERT와 같은 단일언어 서브워드 모델에 비해 성능이 떨어진다는 점이 주목받고 있습니다.

- **Technical Details**: PIXEL은 비전 트랜스포머(ViT) 기반의 모델로, 시각적 패치를 입력으로 받고 텍스트가 렌더링된 형태로 처리됩니다. 연구에서는 PIXEL의 다양한 레이어에서 언어적 정보와 시각적 정보를 각각 탐구하며, 출력 결과를 BERT 및 ViT-mae와 비교합니다. 또한, 입력 레벨에서 특정 서체 제약을 도입했을 때 언어적 학습이 어떻게 향상되는지를 조사하였습니다.

- **Performance Highlights**: PIXEL은 하위 레이어에서 표면적인 언어적 정보를 학습하며, 상위 레이어에서는 구문론(syntax) 및 의미론(semantics) 추상화가 진행됩니다. 그러나 ViT에 비해 이미지 과제에서의 성능은 낮아, 시각적 지식 습득이 언어적 지식 습득 과정에서 희석되는 경향이 있음을 발견하였습니다.



### Toolken+: Improving LLM Tool Usage with Reranking and a Reject Option (https://arxiv.org/abs/2410.12004)
Comments:
          EMNLP 2024 Findings

- **What's New**: 최근 제안된 ToolkenGPT 도구 학습 패러다임은 유망한 성능을 보여주지만, 도구 문서 활용의 부족과 도구 사용 여부 판단에서의 실수라는 두 가지 주요 문제에 직면해 있습니다. 이를 해결하기 위해 Toolken+를 도입하였으며, 이는 Top k 도구의 재순위 및 'Reject' 옵션을 통해 문제를 완화합니다.

- **Technical Details**: Toolken+는 ToolkenGPT의 기존 기능을 확장하여, 도구 문서를 재순위하는 기능과 사용 여부를 결정하는 'Reject' 옵션을 추가하여 처음 두 단계를 개선합니다. 여기에서 'Reject'는 모델이 도구 호출 없이 텍스트 생성을 진행할 수 있도록 하는 기능입니다. 또한, Toolken 훈련 알고리즘에 대한 이론적 정당성을 제공합니다.

- **Performance Highlights**: GSM8K, MetaTool 및 VirtualHome 데이터셋을 통해 우리의 접근 방식이 중요한 성능 향상을 보여주었음을 입증하였습니다. 이 연구는 ToolkenGPT의 잘못된 도구 호출을 최소화하고, 더 신뢰할 수 있는 LLM 에이전트를 개발할 수 있도록 합니다.



### Impacts of Continued Legal Pre-Training and IFT on LLMs' Latent Representations of Human-Defined Legal Concepts (https://arxiv.org/abs/2410.12001)
- **What's New**: 이 논문은 대형 언어 모델(LLMs)의 법률 교육(Corpus)에서의 지속적인 사전 훈련(Pre-training)과 지시적 미세 조정(Instruction Fine-tuning, IFT)이 인간이 정의한 법률 개념을 어떻게 활용하는지를 분석합니다.

- **Technical Details**: 세 가지 모델인 Mistral 7B, SaulLM-7B-Base (법률 데이터셋에서의 지속적인 사전 훈련을 포함한 Mistral 7B), 및 SaulLM-7B-Instruct (추가적인 IFT 포함)를 비교했습니다. 최근 AI & Law 문헌에서의 7개 텍스트 시퀀스에 대해 모델의 주의(attention) 비율을 비교하고, 법률 훈련이 인간의 법적 지식 구조에 따라 새로운 주의 패턴을 생성했는지를 시각화했습니다.

- **Performance Highlights**: 법률 교육의 영향은 다양한 인간 정의 법률 개념에 따라 고르지 않게 분포되었으며, 법률 훈련 중에 학습된 법적 지식의 맥락적 표현이 인간 정의 법률 개념의 구조와 일치하지 않는다는 결과를 도출했습니다.



### Holistic Reasoning with Long-Context LMs: A Benchmark for Database Operations on Massive Textual Data (https://arxiv.org/abs/2410.11996)
- **What's New**: HoloBench라는 새로운 평가 프레임워크를 소개하여, Long-Context Language Models (LCLMs)의 다각적 추론(holistic reasoning) 능력을 체계적으로 평가합니다. 이 프레임워크는 데이터베이스 기반의 추론 작업을 텍스트 기반 맥락으로 가져와 LCLMs의 성능을 비교할 수 있도록 합니다.

- **Technical Details**: HoloBench는 LCLMs의 다각적 추론을 평가하기 위해 세 가지 주요 요인: (1) 맥락의 길이 및 정보량, (2) 관련 정보의 배치 위치, (3) 질문의 유형 및 난이도를 조절하여 모델 성능을 평가합니다. 기존의 벤치마크에서는 주로 단일 또는 이차원적 요인만을 고려하였으나, HoloBench는 이들 세 가지 요인을 동시에 평가합니다.

- **Performance Highlights**: 실험 결과, LCLMs의 성능은 맥락의 길이보다 맥락 내 정보량에 더 크게 영향을 받으며, 질문의 복잡성이 성능에 더 큰 영향을 미친다는 것을 발견했습니다. 또한, 최대 또는 최소 값을 찾는 질문은 LCLMs에게 상대적으로 쉬운 반면, 여러 정보 조합이 필요한 작업에서는 정확도가 현저히 감소했습니다.



### DISP-LLM: Dimension-Independent Structural Pruning for Large Language Models (https://arxiv.org/abs/2410.11988)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 논문에서는 기존의 구조적 가지치기(Structural Pruning) 방법의 제약을 완화하고, 임베딩 차원에서의 구조적 의존성을 제거하는 새로운 차원 독립 구조적 가지치기 방법(DISP-LLM)을 제안하였습니다. 이 방법은 각 블록이 다양한 피처 맵(subset of feature maps)을 사용할 수 있게 하며, 구조적 의존성을 제거함으로써 유연성을 크게 향상시켰습니다.

- **Technical Details**: DISP-LLM은 서로 다른 레이어가 임베딩 차원에서 서로 다른 피쳐의 하위 집합(subset)을 선택할 수 있도록 하며, 추가적인 매개변수를 도입하지 않고도 레이어의 폭(width)을 학습할 수 있게 합니다. 이 접근 방식은 그라디언트 기반 최적화 방법을 사용하여 레이어 폭을 조정하며, 레이어별로 전역적으로 제어됩니다. 또한, 각 레이어의 출력 및 입력 차원에서 다양한 폭을 가질 수 있습니다.

- **Performance Highlights**: 이번 연구 결과는 DISP-LLM 방법이 OPT, LLaMA, LLaMA-2, Phi-1.5, Phi-2와 같은 다양한 LLM 모델에 대해 최신 기술들보다 뛰어난 성능을 보여주며, SEMI-STRUCTURAL 가지치기와 유사한 정확도를 달성할 수 있음을 증명합니다. 이 방법은 낮은 계산 비용을 유지하면서도 효율적인 가지치기를 가능하게 하였습니다.



### The Fair Language Model Paradox (https://arxiv.org/abs/2410.11985)
- **What's New**: 이 논문은 Large Language Models (LLMs)의 토큰 수준에서의 훈련 동역학을 조명하며, 가중치 감쇠(weight decay)가 저주파(low-frequency) 토큰의 성능에 미치는 부정적인 영향을 발견하였습니다. 이러한 연구는 기존의 성능 지표에 의해 간과되었던 중요한 통찰을 제공합니다.

- **Technical Details**: 이 연구는 IMDB 데이터셋을 사용하여 270M과 3B 파라미터를 가진 Apple OpenELM 모델과 Qwen2 모델을 훈련하면서 다양한 가중치 감쇠 수준을 적용하였습니다. 결과적으로, 가중치 감쇠가 증가할수록 저주파 토큰의 성능이 유의미하게 감소하는 것을 확인했습니다. 또한, 고주파 토큰이 저주파 토큰보다 학습 속도에서 일관되게 우세하다는 발견이 있었습니다.

- **Performance Highlights**: 가중치 감쇠를 통한 일반화 촉진을 목표로 하는 기존의 방법이 저주파 토큰을 무시하는 결과를 초래하며, 이는 데이터의 대다수를 차지하는 저주파 토큰에 대한 성능 저하로 이어진다는 점이 명확해졌습니다. 이로 인해 더 일반적인 토큰에 유리한 편향이 발생하며, 새로운 정규화 기법의 필요성이 부각되었습니다.



### JudgeBench: A Benchmark for Evaluating LLM-based Judges (https://arxiv.org/abs/2410.12784)
Comments:
          preprint

- **What's New**: 본 논문에서는 LLM 기반의 평가자(judges)의 신뢰성을 점검하기 위한 새로운 평가 프레임워크를 제안합니다. 이를 통해 기존의 인간 평가자와 비교할 수 있는 JudgeBench라는 벤치마크를 소개합니다.

- **Technical Details**: JudgeBench는 지식(knowledge), 추론(reasoning), 수학(math), 코딩(coding) 등의 난이도 있는 응답 쌍을 평가하는 새로운 벤치마크입니다. 기존의 데이터셋을 활용하여 난이도 높은 응답 쌍으로 변환하는 파이프라인을 활용합니다.

- **Performance Highlights**: JudgeBench는 이전 벤치마크에 비해 훨씬 더 큰 도전을 제시하며, 많은 강력한 모델들이 무작위 추측(random guessing)보다 조금 더 나은 성과를 낼 뿐임을 보여주었습니다. 이는 LLM 기반 평가자의 평가 과정에서의 신뢰성을 높이는 데 기여할 것으로 기대됩니다.



### In-Context Learning Enables Robot Action Prediction in LLMs (https://arxiv.org/abs/2410.12782)
- **What's New**: 이 논문에서는 RoboPrompt라는 새로운 프레임워크를 소개하여, 트레이닝 없이 오프-the-shelf LLM을 통해 로봇 행동을 직접 예측할 수 있도록 한다. RoboPrompt는 ICL(인컨텍스트 학습)의 기능을 활용하여 필요에 따라 로봇의 행동을 예측하는 방법을 제안한다.

- **Technical Details**: RoboPrompt의 접근 방식은 주어진 에피소드에서 주요 키프레임을 식별하는 것으로 시작하며, 이러한 키프레임에서 로봇의 행동과 초기 객체 자세를 추출한다. 이들은 텍스트 서술로 변환되고, 구조화된 템플릿으로 ICL 예제를 형성하여 LLM이 테스트 시간에 로봇 행동을 직접 예측할 수 있게 한다.

- **Performance Highlights**: RoboPrompt는 RL-Bench 시뮬레이션과 실제 환경에서 16가지의 작업을 수행한 결과, 제로샷 및 ICL 기준 대비 우수한 성능을 보여주었다. 다양한 LLM에 적용 가능하며, ICL 예제 수에 따라 확장성이 뛰어나고, 감독 방법들과도 경쟁력 있는 성과를 낸다.



### Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts (https://arxiv.org/abs/2410.12777)
- **What's New**: 본 논문에서는 확산 모델(Diffusion Models, DMs)에서 유해하거나 저작권이 있는 개념을 효과적으로 '망각'(unlearn)하고자 하는 '메타-망각'(meta-unlearning) 프레임워크를 제안합니다. 이는 모델이 학습된 데이터를 잊고 나서도, 악의적인 파인튜닝(finetuning)을 통해 망각된 개념을 다시 학습하지 않도록 돕습니다.

- **Technical Details**: 메타-망각 프레임워크는 두 가지 주요 요소를 포함합니다: (1) 특정 데이터를 효과적으로 잊도록 하는 표준 망각 목표(unlearning objective)와 (2) 악의적인 파인튜닝 시 망각된 개념의 재학습을 방지하기 위한 메타 목표(meta objective)입니다. 제안된 접근 방법은 기존의 망각 방법과 호환되며, 간단한 메타 목표만 추가하면 됩니다. 실험은 Stable Diffusion 모델(SD-v1-4 및 SDXL)에 대한 다양한 메타-망각 개념의 효과를 검증합니다.

- **Performance Highlights**: 제안된 메타-망각 접근 방식은 학습된 개념들을 안정적으로 망각시키며, 필연적으로 여전히 남아 있는 유관 개념들이 해체(self-destruct)되어 망각된 개념의 재학습을 방지합니다. 다양한 실험과 근거 자료를 통해 메타-망각 프레임워크의 효과가 입증되었습니다.



### CREAM: Consistency Regularized Self-Rewarding Language Models (https://arxiv.org/abs/2410.12735)
- **What's New**: 본 논문은 self-rewarding language models (SRLMs)의 rewarding bias 문제를 해결하기 위한 새로운 접근 방식을 제안합니다. 이 과정에서 Consistency Regularized sElf-rewarding lAnguage Model(CREAM)을 도입하여 self-rewarding 훈련의 신뢰성 있는 데이터 학습을 돕고 있습니다.

- **Technical Details**: CREAM은 반복적인 선호 훈련에서의 보상 일관성을 활용하여 모델이 불확실한 선호 데이터를 학습하지 않도록 정규화합니다. 이를 위해 과거 반복의 보상 모델을 사용해 선호를 순위화하고, 현재 모델이 생성한 순위와 비교하여 일관성을 측정합니다. 이러한 방식은 보상 레이블링의 과잉 신뢰를 줄이고, 훈련의 효율성을 높입니다.

- **Performance Highlights**: CREAM은 여러 자연어 벤치마크에서 실험을 통해 보상 일관성과 정렬 성능을 개선한 것으로 나타났습니다. 이로 인해 LLM의 품질이 향상되어 더욱 효과적으로 인간 가치 및 선호에 맞춰 정렬될 수 있음을 보여줍니다.



### Sarcasm Detection in a Less-Resourced Languag (https://arxiv.org/abs/2410.12704)
Comments:
          4 pages, published in the Slovenian Conference on Artificial Intelligence

- **What's New**: 이 논문은 슬로베니아어와 같은 리소스가 부족한 언어에 대한 풍자 감지 데이터 세트를 구축하기 위해 최신 기술을 활용하는 방법을 제시합니다. 특히, 중형 변환기 모델과 매우 큰 생성 언어 모델을 이용하여 번역된 데이터 세트의 유효성을 조사합니다.

- **Technical Details**: 풍자 감지의 이 연구는 기계 번역과 대형 생성 언어 모델(LLM)을 결합하여 슬로베니아어 데이터 세트를 최신 기술로 구축하였습니다. T5 모델과 OpenAI의 GPT-4를 사용하여 풍자의 맥락을 유지하며 번역했습니다. 또한, 앙상블(ensemble) 기법을 통해 다양한 모델 성능을 평가하였습니다.

- **Performance Highlights**: 모델 성능 실험 결과, 더 큰 모델이 일반적으로 더 작은 모델보다 우수한 성능을 보였으며, 앙상블 기법을 적용하면 풍자 감지 성능이 소폭 향상되었습니다. 최종 앙상블 접근 방식은 $	ext{F}_1$-score가 0.765로, 원래 언어의 주석자 간의 합의에 가까운 결과를 얻었습니다.



### VividMed: Vision Language Model with Versatile Visual Grounding for Medicin (https://arxiv.org/abs/2410.12694)
- **What's New**: 최신 연구에 따르면, Vision Language Models (VLMs)의 발전은 시각적으로 기반을 둔 응답 생성에서 놀라운 가능성을 보여주고 있습니다. 그러나 의료 분야에서는 특정 도전 과제가 존재합니다. VividMed라는 새로운 모델은 이 문제를 해결하기 위해 다양한 시각적 기반을 제공하고, 2D 및 3D 이미지를 모두 처리할 수 있도록 설계되었습니다.

- **Technical Details**: VividMed는 세 가지 단계의 훈련 과정과 자동 데이터 주석 파이프라인을 통해 학습됩니다. 이 모델은 세분화 마스크와 인스턴스 수준의 경계 상자를 동시에 생성할 수 있으며, Segment Anything Model (SAM)을 기반으로 한 시각적 기반 기능을 통합하여 성능을 향상시킵니다. VividMed는 다양한 의료 영상 모달리티를 처리할 수 있습니다.

- **Performance Highlights**: 실험 결과, VividMed는 기존 VLMs의 시각적 기반 작업에서 우수한 성능을 보이며, Visual Question Answering (VQA) 및 보고서 생성과 같은 일반적인 하위 작업에서도 경쟁력 있는 성과를 나타냈습니다. 시각적 기반 능력을 통합함으로써, VividMed는 다른 하위 작업에서도 성능 향상을 이루었습니다.



### Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models (https://arxiv.org/abs/2410.12662)
- **What's New**: 본 연구에서는 Large Vision-Language Models (LVLMs)의 비주얼 입력에 대한 안전 메커니즘의 전이 부족 문제를 다룹니다. 현재의 방법론이 비주얼 모달리티에 대해 안전 메커니즘을 효과적으로 전이하지 못함을 발견하고, Text-Guided vision-language Alignment (TGA)라는 새로운 방법을 제안합니다.

- **Technical Details**: TGA는 입력된 비전과 관련된 텍스트를 검색하여 LLMs의 hidden states 공간으로 비전을 투영하는 데 도움을 줍니다. 이로써 이미지의 hidden states와 텍스트의 hidden states 간의 정렬을 이루게 됩니다. 연구 결과, TGA는 기존 LLMs의 안전 메커니즘을 비전으로 성공적으로 전이할 수 있음을 보여주었습니다.

- **Performance Highlights**: TGA는 안전한 결과를 도출하며, InstructBLip, LLaVA-1.5 및 Qwen-VL-Chat과 같은 기존의 최첨단 LVLM들과 비교할 때 다양한 비전 작업에서 일반 성능을 유지합니다.



### Revealing the Barriers of Language Agents in Planning (https://arxiv.org/abs/2410.12409)
Comments:
          Work in Progress

- **What's New**: 이 논문에서는 인공지능의 자율 계획(autonomous planning) 분야에서 현재 언어 에이전트(language agents)가 인간 수준의 계획 능력에 도달하지 못하는 이유를 분석합니다.

- **Technical Details**: 연구에서는 feature attribution study를 적용하여 계획을 저해하는 두 가지 주요 요인을 식별했습니다. 첫 번째는 제약 조건(constraints)의 제한된 역할이고, 두 번째는 질문(question)의 감소하는 영향입니다. 이러한 요인들로 인해 현재 사용되고 있는 전략들이 문제를 완전히 해결하지 못하고 있다는 점도 발견했습니다.

- **Performance Highlights**: 현재 최첨단 추론 모델인 OpenAI o1은 복잡한 실제 계획 기준에서 15.6%의 성과를 달성했으며, 이는 인간 수준의 계획 접근 방식에는 여전히 큰 격차가 있음을 나타냅니다.



### Beyond Coarse-Grained Matching in Video-Text Retrieva (https://arxiv.org/abs/2410.12407)
Comments:
          Accepted to ACCV 2024

- **What's New**: 비디오-텍스트 검색(video-text retrieval)에 대한 새로운 접근 방식이 제시되었습니다. 특히, 기존 데이터셋에 대해 미세하게 변형된 하드 네거티브 테스트 캡션을 자동으로 생성하는 방법을 도입하였습니다.

- **Technical Details**: 제안된 방법은 네 개의 시각적으로 최신(state-of-the-art) 모델을 사용하여 두 개의 표준 벤치마크(MSR-VTT, VATEX)와 두 개의 상세한 설명이 포함된 특별 데이터셋(VLN-UVO, VLN-OOPS)에서 실험을 수행합니다. 모델의 미세한 단어 차이를 인식하는 능력을 검증하기 위해 기본적인 기준을 제안하였습니다.

- **Performance Highlights**: 전반적인 결과, 현재 평가 벤치마크가 모델이 미세 단어 차이를 감지하는 데 부족하다는 점과, 모델들이 이러한 미세한 변화를 구별하는 데 어려움을 겪는다는 점을 발견하였습니다. 제안된 미세 평가 방법은 모델의 미세한 이해 능력을 향상시키는 데 효과적임이 입증되었습니다.



### PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking (https://arxiv.org/abs/2410.12375)
- **What's New**: PRefLexOR (Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning)는 선호 최적화(preference optimization)와 강화 학습(Reinforcement Learning) 개념을 결합하여 모델이 반복적인 추론 개선을 통해 스스로 학습할 수 있도록 합니다.

- **Technical Details**: 이 논문은 다단계 추론(multi-step reasoning) 과정에서 모델이 중간 단계를 재검토하고 수정한 후 최종 출력을 생성하는 재귀 학습(recursive learning) 접근 방식을 제안합니다. 모델은 선호 응답(preferred responses)과 비선호 응답(non-preferred responses) 간의 로그 확률(log odds)을 최적화하여 정확한 결정 경로에 정렬하는 것을 배웁니다. 또한, 무작위 텍스트 조각에서 질문을 생성하고 관련 세부 정보를 맥락화하기 위해 동적 지식 그래프(dynamic knowledge graph)를 구축합니다.

- **Performance Highlights**: 3억 개의 파라미터를 가진 소형 언어 모델(small language models)에서 구현되었으며, 작은 모델도 깊이 있는 추론과 반성(reflection)을 통해 스스로를 반복적으로 학습할 수 있음을 보여줍니다. 생물 재료 과학(biological materials science) 분야에서의 다양한 사례 연구를 통해 이 방법을 증명하며, 추론 시간에 반복 샘플링을 통해 응답을 성공적으로 개선하는 다중 에이전트 재귀 자기 개선 추론(multi-agent recursive self-improving inference) 접근 방식을 구축합니다.



### Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistanc (https://arxiv.org/abs/2410.12361)
Comments:
          9 pages, 4 figures

- **What's New**: 이 논문에서는 명시적인 인간 지시 없이도 작업을 예측하고 시작할 수 있는 선제적 에이전트(proactive agents)를 개발하는 문제에 접근합니다.

- **Technical Details**: 실제 인간 활동 데이터를 수집하여 선제적 작업 예측(proactive task predictions)을 생성합니다. 이 예측은 인간 주석자에 의해 수용(accepted) 또는 거부(rejected)로 라벨링됩니다. 라벨링된 데이터는 인간 판단을 시뮬레이션하는 보상 모델(reward model)을 훈련하는 데 사용됩니다. 또한, ProactiveBench라는 6,790개의 다양한 이벤트를 포함하는 데이터셋 통합 파이프라인을 개발하였습니다.

- **Performance Highlights**: 미세 조정된(fine-tuned) 모델은 F1-Score 66.47%로 선제적으로 도움을 제공하는 능력을 평가하며, 모든 오픈 소스 및 클로즈드 소스 모델을 초월하는 성과를 보여주었습니다.



### Towards LLM-based Cognitive Models of Students with Misconceptions (https://arxiv.org/abs/2410.12294)
- **What's New**: 이 연구에서는 학생의 인지 과정을 효과적으로 모델링하기 위한 새로운 기법으로 대형 언어 모델(LLM)을 활용하는 방법을 제안합니다. 특히, MalAlgoPy라는 새로운 Python 라이브러리를 사용하여 수학적 문제 풀이에서 학생의 오해(misconceptions)를 반영한 데이터셋을 생성합니다.

- **Technical Details**: MalAlgoPy는 그래프 기반의 표현을 통해 대수 문제 해결 프로세스를 모델링 합니다. 이 라이브러리는 16가지 문제 유형을 노드로, 올바른 변환(회색 화살표)과 20가지 일반적인 오해(빨간 화살표)를 엣지로 나타냅니다. 이를 통해 코그니티브 학생 모델(Cognitive Student Models, CSMs)을 정의하고, 학생의 인지 과정을 효과적으로 시뮬레이션합니다.

- **Performance Highlights**: 연구 결과, 오해를 포함한 예제로 훈련한 LLM은 오류를 재현하는 데 효율적이나, 적절한 문제를 해결하는 능력이 저하되는 경향이 있음을 발견했습니다. 그러나 훈련 데이터에서 올바른 예제와 오해의 비율을 0.25와 같이 세심하게 조정하여 두 가지 조건을 모두 충족하는 CSM을 개발할 수 있었습니다. 이 연구는 AI 기반 학생 모델의 개선 가능성을 제시하며 효과적인 적응형 학습 시스템의 길을 열어줍니다.



### A Prompt-Based Knowledge Graph Foundation Model for Universal In-Context Reasoning (https://arxiv.org/abs/2410.12288)
Comments:
          Accepted in the 38th Conference on Neural Information Processing Systems (NeurIPS 2024)

- **What's New**: 이번 논문에서는 다양한 지식 그래프(KG)에서의 일반화된 추론 능력을 달성하기 위해, 문맥 내 학습(in-context learning)을 이용한 프롬프트 기반 KG 기초 모델(KG-ICL)을 제안합니다. 이 모델은 다양한 KG와 추론 환경에 걸쳐 지식을 전이하고 일반화할 수 있는 기능을 갖추고 있습니다.

- **Technical Details**: KG-ICL 모델은 쿼리와 관련된 예제 사실을 중심으로 한 프롬프트 그래프(prompt graph)를 도입하여 쿼리 관계를 이해합니다. 이를 통해 새로운 실체와 관계에 대한 일반화 능력을 가진 통합 토크나이저(unified tokenizer)를 제안하고, 두 개의 메시지 패싱 신경망(message passing neural networks)을 통해 프롬프트 인코딩과 KG 추론을 수행합니다.

- **Performance Highlights**: 43개의 다양한 KG에 대한 실험 결과, KG-ICL 모델은 대부분의 데이터셋에서 기존 모델을 초과 성능을 보이며, 뛰어난 일반화 및 보편적 추론 능력을 보여줍니다. 이 모델은 높은 효율성을 갖추고 예제를 활용하는 데 강력한 성능을 발휘합니다.



### Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting (https://arxiv.org/abs/2410.12284)
- **What's New**: 이번 연구는 자연어 설명(NLE), 주목지도(saliency mapping), 두 가지 설명 방식의 조합이 실제 의료 현장에서 AI와 협력하여 가슴 X선 분석을 수행하는 의료 종사자들에게 미치는 영향을 대규모 사용자 연구로 평가한 내용을 다룹니다. 연구 결과, 언어 기반 설명이 과도한 의존성을 초래함을 발견하였고, 주목지도와 결합했을 때 그 단점을 완화할 수 있음을 확인했습니다.

- **Technical Details**: 이 연구는 85명의 의료 종사자를 대상으로 진행되었으며, 각각 80개의 독특한 이미지를 분석했습니다. 연구에서는 주목지도, 자연어 설명 및 두 가지 설명의 조합을 포함하여 네 가지 다양한 CDSS(Clinical Decision Support System) 설정에서 수행되었습니다. 조건이 불완전한 AI 및 XAI 환경에서 다양한 설명 유형이 사용자의 행동에 미치는 영향을 조사했습니다.

- **Performance Highlights**: 결과적으로, 설명의 질은 유용성에 중요한 영향을 미쳤으며, 설명 정확도가 AI 정확도와 일치할 때 사용자에게 긍정적인 영향을 미치는 것으로 나타났습니다. 특히, 주목지도와 자연어 설명의 조합은 설명 유형 중 가장 유용한 것으로 평가되었습니다. 반면 AI와 설명의 정확도가 불일치할 경우, 사용자 성능에 부정적인 영향을 미칠 수 있음을 걸러냈습니다.



### Beyond Oversmoothing: Evaluating DDPM and MSE for Scalable Speech Synthesis in ASR (https://arxiv.org/abs/2410.12279)
Comments:
          Under review at ICASSP 2025

- **What's New**: 이 논문에서는 TTS(Text-to-Speech) 시스템에서 의도적으로 생성된 합성 음성이 인간 수준의 자연스러움에 근접했지만, ASR(Automatic Speech Recognition) 시스템의 성능은 여전히 실 음성에 비해 낮다는 패러독스를 탐구합니다.

- **Technical Details**: Denoising Diffusion Probabilistic Models (DDPM)와 Mean Squared Error (MSE) 기반 모델을 비교하여 ASR 모델 교육에 관한 성능을 분석합니다. DDPM은 더 다양한 발화자와 데이터를 활용하는 데에 더 효과적이며, 모드 붕괴(mode collapse)를 줄이고 전체 확률 분포를 모델링하는 데 중요한 역할을 합니다. 또한, TTS 훈련 데이터 크기에 따른 ASR 성능 변화를 단계적으로 분석합니다.

- **Performance Highlights**: 예를 들어, DDPM을 사용하여 합성음성과 실음성 간의 단어 오류율(Word Error Rate, WER) 비율을 1.46으로 기록했으나, 실제 음성과 합성 음성 간의 성능 차이는 여전히 남아있음을 발견했습니다. 이러한 결과는 DDPM이 MSE보다 더 유리한 스케일링 곡선을 보이고, 두 모델 모두 감소하는 수익의 한계를 겪고 있다는 것을 보여줍니다.



### Controlled Automatic Task-Specific Synthetic Data Generation for Hallucination Detection (https://arxiv.org/abs/2410.12278)
- **What's New**: 이 논문에서는 환각 감지를 위한 비트리비얼(task-specific) 합성 데이터세트를 자동으로 생성하는 새로운 접근 방식을 제안합니다. 이 방법은 두 단계의 생성-선택 파이프라인을 특징으로 하며, 환각 패턴 지침(hallucination pattern guidance) 및 언어 스타일 정렬(language style alignment)을 활용하여 데이터 품질을 향상시킵니다.

- **Technical Details**: 제안된 방법은 자동화된 생성-선택 파이프라인을 기반으로 하며, 환각 패턴 가이드를 통해 특정 작업에 적합한 환각 샘플을 생성하고, 언어 스타일 정렬을 통해 합성 데이터의 스타일을 벤치마크 텍스트와 일치시킵니다. 이 방법은 세 가지 대화 벤치마크에서 실험을 통해 검증되었으며, F1 점수 0.938을 달성하여 기존의 인컨텍스트러닝(ICL) 기반 감지기를 32.5%의 큰 차이로 초과했습니다.

- **Performance Highlights**: 제안된 환각 감지기는 생성된 합성 데이터세트를 통해 훈련된 결과, 상기된 세 가지 차원에서 뛰어난 일반화 능력을 보여주었습니다. 또한, 생성된 합성 환각이 실제 비환각 샘플에 더 유사함을 입증하였으며, 이는 우리 접근 방식의 강력한 일반화 능력을 확인하였습니다.



### Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations (https://arxiv.org/abs/2410.12228)
- **What's New**: 이 논문은 개인화 추천 시스템을 향상시키기 위해 다양한 데이터 모달리티(data modalities)를 통합하는 새로운 프레임워크인 Triple Modality Fusion (TMF)를 소개합니다. 이 프레임워크는 시각적, 텍스트, 그래프 데이터의 융합을 통해 수행됩니다.

- **Technical Details**: TMF 모델은 큰 언어 모델(LLMs)과의 정렬을 통해 세 가지 모달리티를 통합하며, 각각의 모달리티는 사용자 행동을 포괄적으로 표현하기 위해 서로 다른 특징을 제공합니다. 시각적 정보는 아이템의 맥락 및 미적 특성을 캡처하고, 텍스트 데이터는 사용자 관심사와 아이템 특성에 대한 상세한 통찰력을 제공하며, 그래프 데이터는 아이템-행동 이질 그래프(item-behavior heterogeneous graph) 내의 관계를 설명합니다.

- **Performance Highlights**: 광범위한 실험을 통해 추천 정확성을 개선하는 효과를 입증하였습니다. 추가적인 ablation 연구를 통해 TMF 모델 디자인의 효과성과 이점을 검증하였습니다.



### OmnixR: Evaluating Omni-modality Language Models on Reasoning across Modalities (https://arxiv.org/abs/2410.12219)
Comments:
          19 pages, 6 figures, 12 tables

- **What's New**: OmnixR는 여러 다중 모달리티(omni-modality)를 처리하는 최신 AI 모델의 성능을 평가하기 위한 새로운 벤치마크입니다. 기존의 평가 방법이 단일 또는 이중 모달리티에 한정되어 있었던 반면, OmnixR는 복잡한 비디오, 오디오, 텍스트 조합을 평가하므로, 모델의 종합적인 이해력을 테스트합니다.

- **Technical Details**: OmnixR 벤치마크는 두 가지 데이터 집합으로 구성됩니다: (1) Omni××R_{synth}: 텍스트 정보를 다양한 모달리티(오디오, 이미지, 비디오)로 변환한 합성 데이터 집합이며, (2) Omni××R_{real}: 전문가들에 의해 수집되고 주석이 달린 실제 데이터를 포함하여, 오미모달리티(omni-modality) 추론력을 평가합니다. Omnify!라는 자동화 도구를 사용하여 데이터를 생성하며, 이는 모델의 다중 모달 이해력과 추론 능력을 평가하는 데 초점을 맞춥니다.

- **Performance Highlights**: 실험 결과, 최신 OLM들은 OmnixR 질문에서 여러 모달리티 정보를 통합하여 정확한 답변을 도출하는 데 어려움을 겪었습니다. 특히, 간단한 촉진 전략(ETA prompting)을 사용하여 성능 개선 가능성을 보여주었지만, 현실적인 환경에서 오미모달 행동 불일치를 완전히 해소하기 위해 추가적인 훈련이 필요하다는 점이 드러났습니다.



### Preference Optimization with Multi-Sample Comparisons (https://arxiv.org/abs/2410.12138)
Comments:
          preprint

- **What's New**: 이번 연구에서는 다중 샘플 비교를 포함하는 새로운 포스트 트레이닝(post-training) 접근 방식을 소개합니다. 이를 통해 생성 모델의 다양성 및 편향을 보다 정확하게 평가할 수 있게 됩니다.

- **Technical Details**: 제안된 방법론은 Multi-sample Direct Preference Optimization (mDPO)와 Multi-sample Identity Preference Optimization (mIPO)로, 전통적인 DAP 방식(DAP methods)에 비해 그룹 특성(group-wise characteristics)에 집중합니다. 기존의 접근 방식들은 단일 샘플 비교(single-sample comparisons)에 의존하는 반면, 새로운 방법들은 다중 샘플 비교를 통해 특성을 최적화합니다.

- **Performance Highlights**: 실험 결과, 다중 샘플 비교는 생성 모델의 다양성 및 불편향성을 위한 최적화에서 단일 샘플 비교보다 더 효과적이라는 것을 입증하였습니다. 특히, 데이터셋 내에서 레이블 노이즈(label noise)가 존재할 경우, 다중 샘플 비교 방법이 보다 강력한 최적화 프레임워크를 제공하는 것으로 나타났습니다.



### Scaling laws for post-training quantized large language models (https://arxiv.org/abs/2410.12119)
- **What's New**: 본 연구는 대형 언어 모델(LLMs)에서 훈련 후 압축(Post-Training Compression), 특히 양자화에 관한 새로운 통찰력을 제공합니다. 기존의 사전 훈련(pre-training) 기준을 넘어, 저정밀(低精度) 텐서 데이터 타입에서 LLM의 성능 예측을 가능하게 하는 여러 요소들이 신뢰할 수 있는 방식으로 식별되었습니다.

- **Technical Details**: 연구에서는 LLM의 훈련된 모델의 일반화 능력과 관련된 여러 요소(예: pre-trained NLL loss, local loss landscape 등)에 대한 체계적인 실증 연구가 이루어졌습니다. 특히, 로컬 손실 경관(local loss landscape)에서의 변화와 다양한 저정밀 데이터 타입의 영향을 분석하며, 이를 바탕으로 PTQ(post-training quantization) 절차의 결과를 예측할 수 있는 통계 모델(statistical model)을 개발했습니다.

- **Performance Highlights**: 연구 결과, LLM의 양자화 성능은 특정 LLM 가족에 대해 예측 가능한 경향을 보이며, 이는 PTQ 과정에서 고려해야 할 다수의 요소를 체계적으로 파악함으로써 이루어졌습니다. Quantization의 최적화는 모델 품질을 일정 부분 회복시키는 데 도움이 되며, 전반적인 PTQ 프로세스의 신뢰성을 높이는 데 기여합니다.



### Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming (https://arxiv.org/abs/2410.12112)
Comments:
          50 pages, 25 figures, 7 tables

- **What's New**: 새로운 연구에서는 복잡한 계획 문제를 해결하기 위해 대규모 언어 모델(LLMs)을 활용하는 LLMFP라는 일반 목적의 프레임워크를 제안합니다. 이 프레임워크는 태스크 특정 예제 없이도 최적화 문제로 계획 문제를 공식화하고 해결할 수 있는 가능성을 보여줍니다.

- **Technical Details**: LLMFP는 자연어 도메인 설명과 쿼리, 배경 정보를 입력받아 계획 문제를 해결하는 다섯 단계 프로세스를 갖추고 있습니다: 목표 및 주요 제약 조건 제안, 변수 표현 구축, 최적화 문제로 문제 공식화, 코드 실행 및 플랜 변환, 마지막으로 결과에 대한 평가 및 수정. 이 프레임워크는 SMT(상태 수정 이론)를 사용하여 최적화 문제를 인코딩합니다.

- **Performance Highlights**: LLMFP는 9개의 다양한 계획 문제에 적용되었으며, GPT-4o 및 Claude 3.5 Sonnet의 평균 최적 비율은 각각 83.7% 및 86.8%로, OpenAI o1-preview의 직접 계획 생성법보다 37.6% 및 40.7% 상승한 성과를 내며 탁월한 성능을 입증했습니다.



### LocoMotion: Learning Motion-Focused Video-Language Representations (https://arxiv.org/abs/2410.12018)
Comments:
          ACCV 2024

- **What's New**: 이 논문은 동작 중심 비디오-언어 표현(motion-focused video-language representations)을 목표로 하고 있습니다. 기존의 방법들이 공간적인(focused on spatial) 데이터에 의존하여 물체와 장면을 식별하는 데 중점을 두었던 반면, 이 연구에서는 동작을 설명하는 캡션(captions)에서 학습하는 LocoMotion을 제안합니다.

- **Technical Details**: 기존의 비디오-언어 표현 방법은 캡션이 공간적 측면에 집중된 반면, LocoMotion은 지역 물체의 동작을 아우르는 동작 중심 캡션을 생성하여 학습합니다. 이를 위해 비디오에 합성된 동작(synthetic motions)을 추가하고 이 동작의 매개변수(parameters)를 활용하여 상응하는 캡션을 생성합니다. 또한, 동작의 다양성을 높이기 위해 동사 변형 парафразинг(verb-variation paraphrasing)을 도입하여 동작 기본 요소(primitive motions)와 고수준 동사 간의 연관성을 학습합니다.

- **Performance Highlights**: 실험 결과, 동작 중심 데이터가 제한적인 상황에서도 효과적인 성능을 보이며, 다양한 하위 작업(downstream tasks)에 대해 우수한 적합성을 입증했습니다.



### Bias Similarity Across Large Language Models (https://arxiv.org/abs/2410.12010)
Comments:
          under review

- **What's New**: 이 논문은 여러 LLM(대형 언어 모델) 간의 편향(bias) 유사성을 비교한 최초의 작업이다. 기존 연구들은 개별 모델에서의 편향을 분석했지만, 다양한 모델 간의 편향을 비교한 연구는 부족했다. 이를 통해 LLM의 편향을 서로 분석하여 향후 모델 디버깅 기술에 기여할 수 있는 가능성을 제시한다.

- **Technical Details**: 연구에서는 10개의 오픈 및 클로즈드 소스 LLM을 포함하여 4종 모델 패밀리에서 편향의 정도를 평가하였다. 두 개의 데이터 세트를 사용해 4개의 편향 차원에서 질문 4천 개와 100만 개에 대한 LLM의 출력 분포를 측정하였으며, 결과적으로 다음과 같은 주요 발견을 도출했다: 1) 파인튜닝(fine-tuning)이 출력 분포를 유의미하게 변경하지 않음, 2) 동일 모델 패밀리 내에서도 유사한 출력 분포를 생성하지 않음, 3) 훈련 데이터 정보 유출 가능성이 존재함.

- **Performance Highlights**: 연구 결과는 다음과 같다: 1) LLM의 파인튜닝이 출력 분포에 미치는 영향이 제한적이며, 이는 편향 완화 능력을 제한할 수 있다. 2) 동일 패밀리의 LLM이 출력 경향성에서 서로 다르게 작용해 편향 처리를 위한 모델 간 상호연관성이 낮다. 3) 다양한 모델 간의 편향 레벨이 달라 데이터 보안 및 개인 정보 보호에 대한 우려가 제기된다.



### FLARE: Faithful Logic-Aided Reasoning and Exploration (https://arxiv.org/abs/2410.11900)
- **What's New**: 본 논문에서는 기존의 Chain-of-Thought (CoT) 방법론의 문제점을 해결하기 위해 Faithful Logic-Aided Reasoning and Exploration (FLARE)라는 새로운 접근 방식을 제안합니다. FLARE는 LLM을 사용하여 문제 공간을 탐색하고, 논리 프로그래밍 언어를 이용해 자연어 쿼리를 사실과 술어로 변환하여 코드 실행을 시뮬레이션합니다.

- **Technical Details**: FLARE는 세 가지 모듈로 구성되어 있습니다: 계획 생성을 위한 모듈, Prolog 코드를 생성하는 모듈, 그리고 문제를 해결하기 위한 시뮬레이션 검색 모듈입니다. 이 시스템은 멀티-홉 검색을 통해 자연어 쿼리의 해답을 찾는 과정에서 이유 과정을 정량적으로 평가할 수 있습니다.

- **Performance Highlights**: FLARE는 9개의 다양한 추론 벤치마크 중 7개에서 SOTA (State Of The Art) 결과를 달성하였으며, F-CoT보다 평균 16%, CoT보다 9% 향상된 성능을 보였습니다. 모델의 정확도는 이유 과정의 신뢰성과 강하게 상관관계가 있음을 입증하였습니다.



### Automatic Screening for Children with Speech Disorder using Automatic Speech Recognition: Opportunities and Challenges (https://arxiv.org/abs/2410.11865)
Comments:
          AAAI-FSS 24

- **What's New**: 이 연구에서는 아동의 언어 평가(SLA)에 AI 기술을 통합하는 것이 중요하다는 점을 강조하며, 특히 자동 음성 인식(ASR) 모델을 아동의 언어에 적합하게 조정하는 방법을 제안합니다. 또한, 효율적이고 확장 가능한 SLA 방법의 필요성을 논의합니다.

- **Technical Details**: 자동 음성 인식(ASR) 기술은 아동의 음성을 텍스트 형식으로 변환하는 데 사용됩니다. ASR 모델은 주로 성인 음성에 초점을 맞추고 있지만, 아동의 음성 특징에 적합하게 조정하는 것이 필수적입니다. Fine-tuning을 통해 ASR 모델의 성능을 개선할 수 있으며, 기존의 방법 외에도 아동의 음성 데이터에서 직접 사전 훈련하는 방법도 제시되고 있습니다.

- **Performance Highlights**: 최근의 연구들은 자동 평가 시스템의 정확도가 95%를 초과한다고 주장하며, Ambiki, Smart Ears와 같은 소비자 수준의 소프트웨어도 이러한 목표를 달성하기 위해 개발되고 있습니다. 그러나 이러한 접근 방식은 결과 해석에 대한 과학적 설명이 부족하다는 문제점이 있습니다.



### ChatVis: Automating Scientific Visualization with a Large Language Mod (https://arxiv.org/abs/2410.11863)
- **What's New**: 본 논문에서는 ChatVis라는 반복적 보조 도구를 개발하여 데이터 분석 및 시각화를 위한 Python 스크립트를 생성하는 방법을 제안합니다. 사용자는 자연어로 작업을 지정할 수 있으며, LLM(large language model)이 원하는 작업에 대한 Python 스크립트를 생성하고 반복적으로 수정하여 올바르게 실행되도록 합니다. 중간에 발생하는 오류를 감지하고 수정하는 메커니즘이 포함되어 있습니다.

- **Technical Details**: ChatVis는 사용자 입력을 기반으로 자연어로 설명된 시각화 요구사항을 처리하여, 추가적인 프롬프트를 생성하고 이를 통해 Python 스크립트를 만들어냅니다. 최종적으로 ParaView의 PvPython API를 사용하여 스크립트를 실행하고 결과를 확인합니다. 반복적인 피드백 루프를 통해 오류 메시지가 LLM에 전달되어 코드가 개선됩니다. 이 방법은 과거의 여러 스크립트와 비교하여 정확한 시각화를 생성하는 데 성공했습니다.

- **Performance Highlights**: ChatVis는 다섯 가지 대표적 시각화 시나리오에서 올바른 실행 결과를 보여줍니다. 비교 대상이 된 다른 LLM에서는 ChatVis와 같은 도움 없이 정확한 스크립트를 생성하지 못했습니다. 이번 연구는 LLM을 활용한 과학적 시각화를 위한 최초의 시도 중 하나로 평가됩니다.



### Survey and Evaluation of Converging Architecture in LLMs based on Footsteps of Operations (https://arxiv.org/abs/2410.11381)
Comments:
          13 pages and 16 figures

- **What's New**: 이 논문은 Attention 메커니즘과 Transformer 아키텍처의 발전이 LLM(대형 언어 모델)의 구조적 수렴에 미친 영향을 분석하고, 다양한 하이퍼파라미터 설정에 따른 성능 경향을 정리하고 있습니다.

- **Technical Details**: LLM 아키텍처의 성능을 레이어 구성, 작동 메커니즘, 모델 크기를 고려하여 분석하였으며, 특히 최신의 RTX 6000을 사용하여 하이퍼파라미터 설정의 영향을 평가했습니다. TensorRT-LLM과 같은 고속 추론 성능을 지원하는 오픈소스 라이브러리도 논의되었습니다.

- **Performance Highlights**: 연구 결과, 동일한 모델이라 하더라도 하이퍼파라미터 설정이나 서버와 엣지 환경에서의 배포 방식에 따라 성능이 달라질 수 있다는 것을 확인했습니다. 또한, 최신 오픈소스 LLM(Begma와 Llama)의 아키텍처를 분석하고, 고성능 GPU에서 추론 프로세스를 집중적으로 살펴보았습니다.



### The rotating normal form of braids is regular (https://arxiv.org/abs/1606.08970)
Comments:
          Erratum. The Lemma 4.1 of the previous version is incorrect, as pointed out by June Roupin. This lemma, is not used in the rest of the paper. We have replaced it with Definition 4.1

- **What's New**: 이번 논문은 Birman-Ko-Lee 모노이드에서 정의된 rotating normal form의 강력한 연결성을 다룹니다. 특히, Dehornoy의 braid ordering과의 관계를 강조하며, Birman-Ko-Lee braid의 모든 대표 단어들 중에서 특정 단어인 rotating word를 선택하는 과정을 설명합니다.

- **Technical Details**: 이 논문에서는 모든 n >= 2의 경우에 대해 n strands 위에서 rotating words를 인식하는 유한 상태 오토마타(finite-state automaton)를 구성합니다. 이를 통해 rotating normal form이 정규(regular)임을 증명합니다. 또한, 전체 braid group에 대해 정의된 $\sigma$-definite normal form의 정규성을 도출합니다.

- **Performance Highlights**: rotating normal form의 정규성이 입증됨에 따라, 관련된 계산 및 알고리즘적 적용에 있어 더 나은 이해와 처리 효율성을 نظ를 수 있게 되었습니다.



### NesTools: A Dataset for Evaluating Nested Tool Learning Abilities of Large Language Models (https://arxiv.org/abs/2410.11805)
- **What's New**: 최근의 연구는 대형 언어 모델(LLM)들이 도구 학습(tool learning)을 통해 실세계 애플리케이션에서 뛰어난 성과를 이루고 있음을 보여주고 있습니다. 특히, LLM이 여러 도구를 중첩하여 호출하는 새로운 데이터셋인 NesTools를 소개하여, 중첩 도구 학습(nested tool learning)의 성능 평가를 위한 기준을 마련했습니다.

- **Technical Details**: NesTools는 자동 데이터 생성 방법을 통해 대규모 중첩 도구 호출을 생성할 수 있는 새로운 프레임워크를 제공합니다. 데이터셋은 도구 및 인스턴스 생성, 쿼리 생성, 데이터 검토 및 정제를 포함하는 복잡한 과정으로 구성됩니다. 최종적으로 1,000개의 데이터 항목을 신중하게 선택하고 교차 검증하여 높은 품질을 보장합니다.

- **Performance Highlights**: 22개의 LLM에 대해 NesTools를 활용하여 실험을 수행한 결과, 모델들은 규모 확장(scale scaling)으로부터 일부 혜택을 보았으나, 도구 선택 및 깊이 중첩된 호출에서 여전히 성능 저하를 경험했습니다. 이 결과는 LLM이 복잡한 중첩 도구 학습 작업에서 어려움을 겪고 있음을 보여줍니다.



### Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability (https://arxiv.org/abs/2410.11786)
Comments:
          14 pages, 5 figures, 10 tables, EMNLP 2024 Findings

- **What's New**: 이번 연구에서는 Selection-p이라는 새로운 압축 방법을 제안하며, LLMs가 불필요한 토큰을 효과적으로 분류하여 압축할 수 있는 능력을 탐구합니다.

- **Technical Details**: 이 연구는 self-supervised pre-training 기법을 사용하여, LLM이 입력 토큰에 대해 보존 혹은 삭제할지의 확률을 계산하도록 합니다. 이는 추가적인 파라미터를 거의 추가하지 않고 이루어지며, 기존의 방법들에 비해 더 유연하고 효과적인 압축을 가능하게 합니다.

- **Performance Highlights**: Selection-p은 10배의 압축에서 단 0.8%의 성능 감소만 있으면서도 다수의 분류 작업에서 최상의 성능을 기록했습니다. 또한, 다양한 모델 간의 이동 가능성을 크게 향상시켰습니다.



### MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation (https://arxiv.org/abs/2410.11779)
Comments:
          Ongoing work

- **What's New**: 이번 연구에서 우리는 Multimodal Large Language Models (MLLMs)에서의 환각(hallucination) 현상을 심층적으로 분석하고, 이 현상의 배경 메커니즘을 이해하기 위한 새로운 동적 수정 디코딩 방법인 DeCo(이전 레이어 동지식 지능 수정)를 제안합니다.

- **Technical Details**: DeCo는 MLLM의 결론 층에 도달하기 전에 발생한 지식 정보를 동적으로 선택하여 최종 출력 로짓(logits)을 조정합니다. 이 방법은 모델에 구애받지 않으며, 여러 전통적인 디코딩 전략과 원활하게 통합될 수 있습니다.

- **Performance Highlights**: DeCo를 이미지 캡셔닝 및 시각 질문 답변 데이터셋에 적용한 결과, 평균 10.8%의 환각 억제 효과를 보여주었으며, 다양한 데이터셋에서 기존 방법들보다 더 높은 성능을 기록했습니다. 또한 DeCo는 이전 방법들과 비교했을 때 약간의 지연(latency) 증가가 있었지만, 속도는 훨씬 더 빨라졌습니다.



### Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models (https://arxiv.org/abs/2410.11772)
Comments:
          EMNLP 2024

- **What's New**: 이 연구는 Layer-wise Sparse Tuning (IST)라는 새로운 방법론을 제안하며, 이는 특정 레이어의 중요성을 평가하여 중요도가 높은 레이어만 업데이트함으로써 메모리 및 연산 부하를 감소시킵니다.

- **Technical Details**: Importance-aware Sparse Tuning (IST)은 PEFT(파라미터 효율적 미세 조정) 방법과 호환되는 플러그 앤 플레이 기법으로, 레이어별 중요도 점수를 통해 가장 중요한 레이어의 서브셋을 선택하여 전체 레이어의 효율성을 최적화합니다. 또한, 이 연구는 경량화된 메모리 요구 사항과 빠른 수렴 속도를 제공합니다.

- **Performance Highlights**: IST는 기존의 PEFT 방법들에 비해 우수한 성능을 보이며, 다양한 LLM 및 다운스트림 태스크에 대한 폭넓은 실험을 통해 그 유효성이 입증되었습니다.



### Personas with Attitudes: Controlling LLMs for Diverse Data Annotation (https://arxiv.org/abs/2410.11745)
Comments:
          21 pages, 13 figures

- **What's New**: 본 논문에서는 개인화된 LLM(대규모 언어 모델)을 활용하여 데이터 주석 작업의 다양성과 제어를 향상시키는 새로운 접근 방식을 제안합니다. 개인화된 persona(페르소나) 설명을 LLM 프롬프트에 삽입하여 주석의 다양성을 증가시키는지를 조사하였으며, 이로 인해 생성된 주석의 수준이 일관성 있고 제어 가능함을 입증하였습니다.

- **Technical Details**: 우리는 두 가지 연구를 통해 LLM 프롬프트에 persona를 주입하는 것이 가능성을 탐구합니다. 첫 번째 연구는 prescriptive paradigm(처방적 패러다임)을 다루며, 두 번째 연구는 descriptive paradigm(기술적 패러다임)을 따릅니다. 각 연구에서 persona-프롬프트 LLM이 주석의 다양성과 패턴을 생성하는 능력을 테스트합니다.

- **Performance Highlights**: 연구 결과, persona에 의해 유도된 LLM 주석이 더 많은 다양성을 생성하며, 이 효과는 제어 가능하고 반복 가능하다는 것을 보여줍니다. 이는 비폭력 감지와 같은 주관적 NLP 작업에서 데이터 주석을 개선하는 유용한 도구로 자리 잡게 됩니다.



### Converging to a Lingua Franca: Evolution of Linguistic Regions and Semantics Alignment in Multilingual Large Language Models (https://arxiv.org/abs/2410.11718)
Comments:
          16 pages, 11 figures, 4 tables

- **What's New**: 이번 연구는 대형 언어 모델(LLMs)이 다양한 언어를 처리할 때 나타나는 뉴런 활성화 패턴의 유사성을 발견했으며, 이를 통해 중요한 언어 영역의 존재와 위치를 규명했습니다. 또한, 동일한 의미를 갖는 다른 언어의 문장을 처리할 때도 비슷한 패턴을 보여주어, LLM이 언어 간 의미 정렬을 이룬다는 점을 강조했습니다.

- **Technical Details**: 연구에서는 대형 언어 모델의 뉴런이 서로 다른 언어 처리 시 비슷한 활성화 패턴을 보이는데, 이를 통해 특정 언어를 처리하는 뉴런과 주요 언어 영역을 식별할 수 있음을 확인했습니다. LLM의 첫 번째 및 마지막 층에 중요한 언어 뉴런이 집중되어 있으며, 훈련이 진행됨에 따라 이러한 뉴런의 밀도가 증가합니다. 연구는 BLOOM과 LLaMA2 모델을 기반으로 하여 이러한 구조적 진화 과정을 지원하는 실험들을 진행했습니다.

- **Performance Highlights**: 훈련 과정이 진행됨에 따라 주요 언어 영역의 크기가 줄어들고, 의미 정렬이 더욱 두드러지면서 기계의 언어 독립적 처리 성능이 향상되었습니다. 특히, 모델의 크기가 증가할수록 언어 간 활성화 패턴이 더 언어 독립적으로 변화하는 경향이 있으며, 이는 LLM의 잠재 의미 공간을 통해 이루어지는 것으로 설명됩니다.



### MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models (https://arxiv.org/abs/2410.11710)
- **What's New**: MTU-Bench (Multi-Granularity Tool-Use Benchmark)는 대형 언어 모델(LLMs)의 도구 사용 능력을 다양한 상황에서 평가할 수 있도록 설계되었습니다. 기존의 평가 모델들은 한정된 도구 사용 시나리오와 높은 평가 비용 문제를 지적하며, MTU-Bench는 이를 해결합니다.

- **Technical Details**: MTU-Bench는 5개의 도구 사용 장면(단일 턴 및 단일 도구, 단일 턴 및 다중 도구, 다중 턴 및 단일 도구, 다중 턴 및 다중 도구, 출처 분포 외의 작업)을 포괄하며, 모든 평가 메트릭은 예측 결과와 실제 정답을 기반으로 하여 GPT API나 인간 평가자 없이 수행됩니다. MTU-Instruct 데이터셋을 통해 LLM의 도구 사용 능력을 향상시키는 방법도 제안됩니다.

- **Performance Highlights**: MTU-Bench를 통한 실험 결과는 MTU-LLaMA라는 모델이 다양한 시나리오와 메트릭에서 최상의 성능을 보였음을 보여줍니다. 이는 도구 사용 능력에 대한 유용한 통찰을 제공하며, 고급 기능들이 다수 발견되었습니다.



### Magnifier Prompt: Tackling Multimodal Hallucination via Extremely Simple Instructions (https://arxiv.org/abs/2410.11701)
Comments:
          9 pages, 13 tables, 4 figures

- **What's New**: 이 논문에서는 멀티모달 대형 언어 모델(MLLMs)에서 허위 정보(hallucinations)를 줄이기 위해 Magnifier Prompt (MagPrompt)라는 단순하면서도 효과적인 방법을 제안합니다. MagPrompt는 모델이 시각적 정보에 더 집중하도록 유도하며, 이미지와 내부 지식 간의 충돌이 있을 경우 이미지의 우선권을 강조하는 원칙에 기반합니다.

- **Technical Details**: MagPrompt는 훈련 없이 적용 가능하며, GPT-4o 및 Gemini와 같은 오픈소스와 클로즈드소스 모델에 모두 사용할 수 있습니다. 실험 결과, MagPrompt는 다양한 데이터셋에서 효과적으로 작동하며, 복잡한 방법인 VCD와 비교할 때 동등하거나 더 나은 성능을 보입니다. 이 방법은 간단한 지침을 통해 MLLMs의 허위 정보 문제를 해결할 수 있는 가능성을 보여줍니다.

- **Performance Highlights**: 실험에서 MagPrompt는 LLaVA-1.5와 Qwen-VL 모델에서 VCD보다 더 우수한 성능을 발휘했으며, F1 점수 전반에서 유의미한 향상을 기록했습니다. 또한 MagPrompt는 GPT-4o 및 Gemini와 같은 최신 클로즈드소스 모델에서도 적용 가능하여, 기존의 복잡한 방법들이 적용되지 않는 상황에서도 성능 향상을 가져왔습니다.



### IntGrad MT: Eliciting LLMs' Machine Translation Capabilities with Sentence Interpolation and Gradual M (https://arxiv.org/abs/2410.11693)
- **What's New**: 최근 대형 언어 모델(LLMs)은 추가 평행 데이터셋에 대한 미세 조정 없이 번역 작업에서 강력한 성능을 입증했지만, 저자원 언어 쌍에서는 여전히 낮은 성능을 보이고 있습니다. 본 논문에서는 LLM의 고유한 번역 능력을 최대한 활용하는 새로운 방법인 IntGrad MT를 제안하여 이러한 문제를 해결하고자 했습니다.

- **Technical Details**: IntGrad MT는 두 가지 기술인 Sentence Interpolation과 Gradual MT로 구성되어 있습니다. Sentence Interpolation은 간단한 문장을 점진적으로 더 어려운 문장으로 변화시키는 기법이며, Gradual MT는 이전 문장의 번역 결과를 이후 문장의 번역을 위해 몇 개의 샘플로 사용하는 방법입니다. 이 접근 방식을 통해 LLM의 번역 성능을 크게 향상시킬 수 있었습니다.

- **Performance Highlights**: IntGrad MT는 다양한 LLM(GPT-3.5 Turbo, Mistral Nemo Instruct, Llama 3.1 70B Instruct, Llama 3.1 8B Instruct)에 대해 여러 언어(German, Chinese, Hindi, Korean, Swahili, Marathi, Bengali)에서 테스트를 진행하였으며, 그 결과 저자원 언어에서 특히 큰 성과 향상을 보였습니다(Hindi(8.26), Swahili(7.10), Bengali(6.97), Marathi(13.03)).



### Understanding Likelihood Over-optimisation in Direct Alignment Algorithms (https://arxiv.org/abs/2410.11677)
Comments:
          Preprint Version

- **What's New**: 이번 연구에서는 Direct Alignment Algorithms (DAAs)로 알려진 새로운 방법론인 Direct Preference Optimisation (DPO)와 Identity Preference Optimisation (IPO)에서의 completion likelihood와 모델 성능 간의 관계를 탐구하고, 'likelihood over-optimisation'이라는 중요한 문제를 밝혀냈습니다.

- **Technical Details**: Direct Alignment Algorithms는 인간의 선호를 반영하기 위해, gewünschten (desired) 결과를 생성할 가능성을 높이고, 반면에 비선호 결과의 가능성을 줄이도록 설계되었습니다. 하지만, 좋은 결과의 likelihood가 높아도 모델 성능이 반드시 향상되지 않을 수 있으며, 이는 모델의 diversity를 저해하는 Over-Optimisation 현상으로 이어질 수 있습니다. 이 연구에서는 Two key indicators가 제시됩니다: (1) Decreasing Entropy over Top-k Tokens와 (2) Diminishing Top-k Token Probability Mass.

- **Performance Highlights**: 실험 결과, Over-Optimisation의 신뢰할 수 있는 신호를 제공하는 두 가지 지표가 제시되었고, 이를 통해 인간의 선호와의 정렬을 개선하며 성능 저하를 방지할 수 있음을 확인하였습니다.



### Leaving the barn door open for Clever Hans: Simple features predict LLM benchmark answers (https://arxiv.org/abs/2410.11672)
- **What's New**: 이 논문은 AI 벤치마크의 내부 타당성(internal validity)가 중요한 이유와 AI 시스템들이 의도치 않게 벤치마크를 해결하는 방법을 탐구합니다. 'Clever Hans' 효과를 염두에 두고, 최근 LLM(대형 언어 모델) 벤치마크에서 간단한 $n$-grams를 조합하여 레이블(label)을 예측할 수 있는지를 조사합니다.

- **Technical Details**: 연구에서는 단일 및 이중 $n$-grams를 사용하여 다중 선택 형식의 벤치마크에서 정답 레이블을 예측하는 로지스틱 회귀(classifier)를 훈련시킵니다. 이러한 분류기는 벤치마크가 테스트하도록 설계된 능력을 개발할 필요가 없기 때문에, 레이블이 성공적으로 예측될 경우 그 예제가 특정 능력을 사용할 필요 없이 해결될 수 있음을 시사합니다.

- **Performance Highlights**: 여러 벤치마크에서 과거 데이터에 기반한 간단한 분류기가 높은 정확도를 기록하여 내부 타당성이 문제가 될 수 있음을 시사하고, 일부 LLM들이 이와 같은 표면적인 패턴을 활용하여 벤치마크 문제를 해결할 수 있음을 보여줍니다. 또한 LLM의 성능이 벤치마크 데이터의 작고 미세한 변화에 감지된다는 점에 주목하여, 이들이 절차적 능력 대신 얕은 패턴에 의존하고 있다는 우려를 제기합니다.



### Eliciting Textual Descriptions from Representations of Continuous Prompts (https://arxiv.org/abs/2410.11660)
- **What's New**: 이 논문에서는 연속 프롬프트(Continuous prompts) 또는 소프트 프롬프트(Soft prompts)의 해석을 위한 새로운 접근 방식을 제안합니다. 기존의 접근 방식은 개별 프롬프트 토큰을 어휘 공간에 투영하는 것이었으나, 이는 불완전하고 모호한 결과를 가져올 수 있어 신뢰성 문제가 있었습니다. 대신, 본 연구에서는 모델 추론 중에 프롬프트의 표현으로부터 텍스트 설명을 이끌어내는 방법을 제안하였습니다.

- **Technical Details**: 이 연구에서는 Patchscopes 프레임워크(Ghandeharioun et al., 2024)를 활용하여 프롬프트의 표현을 추출하고, 이를 이용해 자연어로 된 작업 설명을 생성하는 InSPEcT(Patchscope)의 개념을 도입합니다. InSPEcT는 타겟 프롬프트에 패치하여 작업 설명을 디코딩하는 방식으로 작동합니다. 이 방식은 기존의 어휘 투영과 달리 프롬프트 길이에 구애받지 않고 자연스럽고 이해하기 쉬운 해석을 제공합니다.

- **Performance Highlights**: InSPEcT를 사용하여 5개의 작업에 대해 학습된 연속 프롬프트의 설명을 생성하였고, 이는 일반적으로 관련된 타겟 작업에 대한 정확한 설명을 산출했습니다. 프롬프트의 성능이 높아질수록, 이끌어낸 설명의 정확성도 증가하는 경향을 보였습니다. Furthermore, InSPEcT의 개선된 버전은 연속 프롬프트에 포함된 편향된 특성을 드러내며, 이러한 특성이 포함될 경우 모델의 예측이 편향되었음을 보여주었습니다.



### Unveiling the Mystery of Visual Attributes of Concrete and Abstract Concepts: Variability, Nearest Neighbors, and Challenging Categories (https://arxiv.org/abs/2410.11657)
- **What's New**: 이번 연구에서는 구체적(concrete)인 개념과 추상적(abstract)인 개념의 시각적 표현의 다양성을 분석하였습니다. 약 1000개의 개념을 포함하는 이미지 데이터셋을 사용하여, 이 두 개념의 시각적 특징에 대한 이해를 증진하고자 하였습니다.

- **Technical Details**: 우리는 Bing과 YFCC에서 추출한 약 1000개의 추상적 및 구체적 개념에 대한 이미지를 활용하였습니다. 이 연구에서는 각 개념에 대한 이미지의 시각적 다양성을 평가하고, 최근접 이웃(nearest neighbor) 분석을 통해 시각적 특징의 변동성을 분석하였으며, 도전 요인을 분류하고 주석을 달았습니다. 연구 결과, ViT(Vision Transformer)보다 색상과 질감과 같은 기본적인 시각적 특징의 조합이 구체적 및 추상적 개념 분류에 더 효과적이라는 것을 발견하였습니다.

- **Performance Highlights**: 이미지 분류 실험에서, 구체적이고 추상적인 개념 간의 시각적 다양성을 성공적으로 구별할 수 있었으며, ViT는 최근접 이웃 분석에서 뛰어난 성능을 보였습니다. 이는 다른 텍스트 이외의 양식으로 개념 변수를 분석할 때 시각적 특징 선택의 신중함을 강조합니다.



### Retrieval Augmented Spelling Correction for E-Commerce Applications (https://arxiv.org/abs/2410.11655)
- **What's New**: 본 논문은 신생 브랜드 이름이 전통적인 철자 교정 시스템에 미치는 영향을 다루며, Retrieval Augmented Generation (RAG) 접근법을 사용하여 전통적인 방법보다 향상된 철자 교정을 보입니다.

- **Technical Details**: Retrieval Augmented Generation (RAG) 방법론을 통해 사용자 쿼리를 제품 카탈로그에서 관련 항목으로 검색하고, 이를 기반으로 Fine-tuning된 대형 언어 모델(LLM)에 컨텍스트를 제공합니다. 실험에 사용된 모델은 Mistral-7B와 Claude-3-sonnet이며, 다양한 검색 방법(BM25, Fuzzy BM25, ColBERT)을 평가했습니다.

- **Performance Highlights**: RAG 기반 접근법은 철자 교정 성능에서 일관된 향상을 보여줍니다. 특히 브랜드 이름이 포함된 쿼리에서 가장 큰 성과를 기록하였고, 레이턴시(혹은 지연 시간)의 증가도 최소화되었습니다.



### Transformer Layer Injection: A Novel Approach for Efficient Upscaling of Large Language Models (https://arxiv.org/abs/2410.11654)
- **What's New**: 본 논문에서는 Transformer Layer Injection (TLI)라는 새로운 기법을 제안합니다. 이 방법은 대규모 언어 모델(LLMs)의 효율적인 업스케일링을 가능하게 하며, 계산 비용을 최소화하면서 모델 성능을 유지합니다.

- **Technical Details**: TLI는 전통적인 Depth Up-Scaling (DUS) 기술을 개선하여 K개의 레이어 세트마다 새로운 레이어를 주입함으로써, transformer 블록을 통과하는 숨겨진 표현에 최소한의 방해로 작동합니다. TLI는 초기 손실을 줄이고, 훈련 단계를 최소화하며, 고정밀도를 강조합니다.

- **Performance Highlights**: TLI는 LLama3의 1B, 3B, 8B 모델에 대한 실험을 통해 초기화 효율성과 데이터 활용에서 MoE 및 DUS보다 우수한 결과를 보였습니다. 이는 훈련 단계 수를 크게 줄이고, KoBEST 및 KMCQA와 같은 작업에서 성능을 향상시키는 것으로 나타났습니다. TLI는 데이터 효율적이고 비용 효과적인 솔루션으로, 최대 405B 매개변수까지의 모델 업스케일링에 적합합니다.



### Measuring Spiritual Values and Bias of Large Language Models (https://arxiv.org/abs/2410.11647)
Comments:
          9 pages including appendix; 5 figures; 5 tables; submitted to ARR - Octobor 2024

- **What's New**: 이번 연구에서는 인기 있는 대형 언어 모델(LLMs)의 영적 가치가 다양하다는 것을 검증하였으며, 이는 세속적이거나 무신론적이라는 기존의 고정관념과는 대조적입니다. 또한, 이러한 다양한 영적 가치가 사회적 공정성 시나리오에서 어떻게 영향을 미치는지 탐구하였습니다.

- **Technical Details**: 연구는 설문지 형식의 영적 가치 평가 도구 두 가지(SP-Typology 및 SP-10Axes)를 사용하여 LLMs의 영적 가치를 측정하였습니다. 평가를 통해 LLMs가 상당히 종교적 경향을 보이며, 특히 종교적 LLM들이 증오 발언 탐지에서 더 좋은 성능을 보이는 것으로 나타났습니다. 추가 실험에서는 종교 문헌에 대한 비지도 학습을 통해 LLM의 성능이 더욱 향상됨을 확인했습니다.

- **Performance Highlights**: LLMs가 다양한 영적 가치를 반영하는 것으로 나타났으며, 이는 모델의 성능에 중요하게 작용합니다. 특히, 더 종교적인 LLM들이 증오 발언을 탐지하는 과제에서 더 높은 성능을 나타냈습니다. 전체적으로, LLMs의 영적 편견을 완화하기 위한 계속된 추가 학습의 효과를 입증했습니다.



### Tokenization and Morphology in Multilingual Language Models: A~Comparative Analysis of mT5 and ByT5 (https://arxiv.org/abs/2410.11627)
- **What's New**: 이 논문은 다국어 언어 모델에서 형태소(morphology) 지식에 대한 토큰화(tokenization)의 영향을 분석합니다. mT5와 ByT5라는 두 다국어 모델의 토큰화 전략을 비교하여 형태소 정보가 어떻게 인코딩되는지를 탐구합니다. 이 연구는 서로 다른 토큰화 전략이 다국어 모델의 형태소 지식 획득에 미치는 영향을 이해하고자 합니다.

- **Technical Details**: 연구에서는 mT5(서브워드 토큰화)와 ByT5(문자 수준 토큰화) 두 모델의 형태소 지식을 프로빙(probing)하여 분석합니다. 17개 언어를 대상으로 메타 분석을 실시하였으며, 특히 중간 및 후층에서 형태소 정보가 인코딩됨을 발견하였습니다. 또한, 언어의 불규칙성 정도가 형태소 지식 획득에 중요한 역할을 한다고 제안합니다.

- **Performance Highlights**: 다국어 언어 모델은 특정 언어의 형태소 시스템을 타 언어보다 더 잘 학습함을 보였으며, 특히 불규칙성이 더 많은 언어는 더 많은 전훈련(pre-training) 데이터 비율의 혜택을 받습니다. 형태소는 표준 토크나이저를 사용하는 모델의 초기 층에서 학습되지만, 문자 기반 모델은 후층에서 유사한 형태소 지식을 발휘합니다.



### Findings of the WMT 2024 Shared Task on Chat Translation (https://arxiv.org/abs/2410.11624)
Comments:
          12 pages, 5 figures, 13 tables

- **What's New**: 이번 논문은 Chat Translation Shared Task의 세 번째 에디션에 대한 발견을 제시하며, 새로운 언어 쌍인 영어-한국어(English-Korean)와 영어-네덜란드어(English-Dutch)가 추가되었습니다. 또한 대화 맥락이 번역 품질에 미치는 영향을 분석하는 데 초점을 맞추었습니다.

- **Technical Details**: 이번 번역 과제는 고객 지원 대화를 번역하는 시스템의 성능을 평가하는 데 중점을 두며, 22개의 주요 제출물 및 32개의 비교 제출물이 있었습니다. 자동화된 메트릭과 인간 평가를 사용하여 각 시스템을 종합적으로 평가하였고, LLMs(대형 언어 모델)가 효과적으로 활용되었습니다.

- **Performance Highlights**: 참여한 모든 시스템과 언어 쌍에서 회화 수준의 번역 품질이 확연히 높은 반면, 후반 대화의 번역과 전체 대화 수준의 개선이 필요함을 보여주었습니다. Unbabel-IT의 제출물이 대부분의 언어 쌍에서 최상의 결과를 달성했습니다.



### Causal Reasoning in Large Language Models: A Knowledge Graph Approach (https://arxiv.org/abs/2410.11588)
Comments:
          Accepted at NeurIPS 2024 Workshop on Causality and Large Models (CaLM)

- **What's New**: 이 논문은 지식 그래프(knowledge graph, KG)를 기반으로 한 무작위 보행(random-walk) 추론 방법을 제안하며, 인과관계(causal relationships)를 활용하여 LLM 성능을 분석합니다.

- **Technical Details**: 지식 그래프는 관련 정보(related information)와 노드 간의 연결을 통해 추론 구조(reasoning structure)를 제공하여 무작위 보행을 수행합니다. 실험은 상식 질문 응답(task)에서 수행되었습니다.

- **Performance Highlights**: 제안된 KG 기반 무작위 보행 추론 방법은 LLM의 추론 능력과 성능을 개선하며, 세 가지 비관련 문장을 쿼리에 포함시키는 것이 기존의 관념과는 달리 LLM 성능을 향상시킵니다. 이러한 결과는 LLM 성능 최적화에서 인과 구조(causal structures)의 통합이 중요한 역할을 할 수 있음을 시사합니다.



### Multi-round jailbreak attack on large language models (https://arxiv.org/abs/2410.11533)
- **What's New**: 본 연구에서는 Large Language Model (LLM)의 jailbreaking 공격을 보다 깊이 이해하기 위해 다단계 jailbreaking 접근 방식을 제안합니다. 이 방법은 위험한 프롬프트를 재작성하고 점진적으로 덜 해로운 하위 질문으로 분해하여 LLM의 안전 점검을 우회할 수 있습니다.

- **Technical Details**: 검증된 결과를 바탕으로, 우리는 Llama3-8B 모델을 사용하여 위험한 질문들을 비위험 하위 질문으로 분리하고, 이 과정에서 LLM이 도출해낸 질문들을 피해 모델에 이어서 묻는 방식을 채택했습니다. 또한, 피해 모델이 하위 질문을 거부하는 경우 새로운 분해 작업을 생성하는 방식을 반복합니다.

- **Performance Highlights**: 실험 결과에 따르면, Llama2-7B 모델에서 94%의 성공률을 기록하여 다단계 jailbreaking 접근 방식의 효과성을 입증했습니다. 이를 통해 정적 규칙 기반 필터를 효과적으로 우회할 수 있음을 보여주었습니다.



### TopoLM: brain-like spatio-functional organization in a topographic language mod (https://arxiv.org/abs/2410.11516)
- **What's New**: TopoLM이라는 새로운 딥러닝 모델이 소개되었으며, 이는 인공지능 언어 모델이 뇌의 언어 시스템과 유사한 스페이셜(topographic) 표현을 사용하는 방법을 보여줍니다.

- **Technical Details**: TopoLM은 transformer 아키텍처에 기반하여 구성되었고, 모델 유닛의 2차원 공간 배치를 포함합니다. 다음 토큰 예측(nnext-token prediction) 목표와 공간 부드러움 손실(spatial smoothness loss)을 결합하여, 텍스트의 의미론적으로 해석 가능한 클러스터를 형성합니다.

- **Performance Highlights**: TopoLM은 언어 처리하는 뇌의 기능적 클러스터가 미세한 언어적 특징에 따라 조직되는 것을 예측하는 데 성공했으며, 브레인 스코어 플랫폼을 이용한 뇌 정렬 벤치마크에서 비슷한 성과를 보였습니다.



### DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG (https://arxiv.org/abs/2410.11494)
Comments:
          EMNLP 2024 Main

- **What's New**: 이 논문에서는 지속적으로 업데이트되는 지식 기반에서 새로운 언어 표현을 해결하는 새로운 작업을 제시합니다. 이를 통해 지식 집합과 함께 작동하는 retrieval-augmented generation (RAG) 시스템의 문제를 다루고 있습니다.

- **Technical Details**: DynamicER 벤치마크를 포함하며, 새로운 표현에 대한 동적 엔티티 언급 해결과 엔티티 중심의 지식 집약형 QA 작업을 평가합니다. 이는 엔티티 링크 및 RAG 모델의 새로운 표현에 대한 적응성을 측정합니다. 기존의 엔티티 링크 모델이 새로운 표현을 엔티티에 연결하는 데 어려움을 겪고 있음을 발견했습니다. 따라서 우리는 시간에 따라 세분화된 클러스터링 방법을 제안하여 진화하는 엔티티와 새로운 언급의 시간 동태를 효과적으로 관리합니다.

- **Performance Highlights**: 광범위한 실험을 통해 제안된 방법이 기존의 기준선보다 더 나은 성능을 보여주며, 해결된 언급을 사용하여 QA 작업의 RAG 모델 성능을 향상시킵니다.



### O-Edit: Orthogonal Subspace Editing for Language Model Sequential Editing (https://arxiv.org/abs/2410.11469)
- **What's New**: 이번 논문에서는 Orthogonal Subspace Editing (O-Edit)이라는 새로운 방법을 제안합니다. 이 방법은 여러 번의 지식 업데이트가 있을 때도 모델 성능 저하를 최소화하면서 연속적인 편집을 가능하게 합니다.

- **Technical Details**: O-Edit는 각 지식 업데이트의 방향을 직교화하여 후속 업데이트 간의 간섭을 최소화하며, 서로 관련 없는 지식에 대한 새로운 업데이트의 영향을 줄입니다. 또한, 이전에 편집된 데이터를 다시 사용하는 필요 없이 각 편집을 시간에 맞게 처리합니다.

- **Performance Highlights**: O-Edit는 주류 LLMs에서 수천 개의 편집을 수행할 수 있으며, 기존 방법보다 평균 성능 개선이 4.2배 더 좋고, 다운스트림 작업에서 모델 성능을 효과적으로 유지하면서 최소한의 추가 파라미터 오버헤드로 작동합니다.



### Mitigating Frequency Bias and Anisotropy in Language Model Pre-Training with Syntactic Smoothing (https://arxiv.org/abs/2410.11462)
- **What's New**: 이 논문에서는 언어 모델의 frequency bias를 정량화하는 방법을 제안하고, 미세 조정을 통해 이 bias를 줄이는 새로운 기법인 Syntactic Smoothing을 소개합니다. 이 방법은 유사한 문법적 특성을 가진 단어들 사이에서 학습 신호를 분산시킴으로써 드문 단어들의 표현력을 개선합니다.

- **Technical Details**: Syntactic Smoothing 방법은 토큰의 표현을 동기화하기 위해 part-of-speech (POS) 태그 분포를 기반으로 한 유사성 메트릭을 사용합니다. 최대 우도(maximum likelihood) 극대화 목표 함수를 조정하여 문법적으로 유사한 토큰에게 학습 신호를 분산시킵니다.

- **Performance Highlights**: 이 방법은 드문 영어 토큰에서의 성능을 개선하고, anisotropy를 감소시키는 결과를 보였습니다. 특히, 모델의 anisotropy 정도는 frequency bias와 상관관계가 있으며, 이를 통해 언어 모델의 전반적인 성능 향상을 확인할 수 있었습니다.



### Jigsaw Puzzles: Splitting Harmful Questions to Jailbreak Large Language Models (https://arxiv.org/abs/2410.11459)
- **What's New**: 이 논문에서는 Jigsaw Puzzles (JSP)라는 새로운 다중 회전( multi-turn ) jailbreak 전략을 제안합니다. 이 전략은 복잡한 질문을 해소하는 LLM의 능력을 이용하면서도, 기존의 방어 메커니즘을 우회하는 방법을 보여줍니다.

- **Technical Details**: JSP는 질문을 무해한 조각으로 나누고, 각 회전에서 LLM이 이 조각들을 재구성하고 응답하도록 요청합니다. 이 과정을 통해 모델의 약점을 노출시키고, 다중 회전 대화에서의 공격 가능성을 탐구합니다. 실험 결과 JSP는 5가지의 고급 LLM (Gemini-1.5-Pro, Llama-3.1-70B, GPT-4, GPT-4o, GPT-4o-mini)에서 189개의 유해한 질문에 대해 평균 93.76%의 공격 성공률을 기록했습니다.

- **Performance Highlights**: JSP는 GPT-4의 유해 질의 벤치마크에서 92%의 최신 공격 성공률을 달성하였고, 방어 전략에 대해 강력한 저항력을 보여줍니다.



### Tending Towards Stability: Convergence Challenges in Small Language Models (https://arxiv.org/abs/2410.11451)
- **What's New**: 이번 연구는 언어 모델의 파라미터 수를 늘리는 것이 성능 향상에 효과적이라는 주장을 다룹니다. 그러나 소형 언어 모델이 운영 비용이 낮음에도 불구하고 대형 모델에 비해 성능이 저하되는 이유에 대한 명확한 원인을 분석합니다.

- **Technical Details**: 연구에서는 Pythia 모델 스위트를 사용하여 다양한 모델 크기에서 Attention과 MLP 활성화의 수렴(convergence) 동력을 분석합니다. 특히, 각 층(layer)의 효과적인 차원(rank)이 이 과정에 미치는 영향을 조사하였습니다.

- **Performance Highlights**: 대형 모델의 경우 훈련 초기 (첫 20%)에 거의 모든 층이 안정화되는 반면, 소형 모델은 파라미터의 효과적인 차원이 낮을 때 느리고 불안정한 수렴 양상을 보입니다. 이 연구는 소형 모델의 학습 동역학(learning dynamics)에서 비효율성을 해결하는 데 있어 방향을 제시할 수 있습니다.



### A Cross-Lingual Statutory Article Retrieval Dataset for Taiwan Legal Studies (https://arxiv.org/abs/2410.11450)
- **What's New**: 이 논문은 다국어 환경에서 법률 정보 검색을 향상시키기 위해 설계된 cross-lingual statutory article retrieval (SAR) 데이터셋을 소개합니다.

- **Technical Details**: 이 데이터셋은 영어로 된 구술 언어 스타일의 법률 질문과 그에 상응하는 중국어 버전 및 관련 법령을 포함하고 있으며, 대만의 모든 민사, 형사 및 행정법을 다룹니다. 또한 번역 오류를 완화하고 cross-lingual retrieval 성능을 개선하기 위한 여러 LLM 기반 방법을 제안합니다.

- **Performance Highlights**: 이 연구는 비원어민, 특히 대만의 외국인들이 법률 정보에 접근할 수 있도록 지원하는 중요한 자원으로, 포괄적인 법률 정보 검색 시스템 개발에 기여할 것입니다.



### AIC CTU system at AVeriTeC: Re-framing automated fact-checking as a simple RAG task (https://arxiv.org/abs/2410.11446)
- **What's New**: 이 논문은 AVeriTeC 공유 과제에서의 3위 제출 결과를 설명합니다. 우리는 Retrieval-Augmented Generation (RAG) 방식을 간단히 설계하여 실제 데이터를 활용한 사실 확인의 도전을 해결하고자 했습니다.

- **Technical Details**: 논문은 두 개의 모듈, 즉 Retriever와 Evidence & Label generator의 상세한 설명을 제공합니다. MMR-reranking 및 Likert-scale confidence estimation과 같은 기능을 정당화합니다.

- **Performance Highlights**: AVeriTeC 개발 및 테스트 세트에서 우리의 솔루션을 평가하였고, 결과를 해석하였습니다. GPT-4o가 우리의 파이프라인에 가장 적합한 모델로 선정되었으며, Llama 3.1 70B는 유망한 오픈소스 대안으로 주목받고 있습니다. 또한, 예측의 오류 분석을 수행하여 데이터의 잡음이나 모호한 사실 확인과 관련된 과오를 발견하였습니다.



### Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs (https://arxiv.org/abs/2410.11437)
Comments:
          EMNLP 2024 Findings

- **What's New**: 본 논문에서는 멀티모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)의 시각적 질문-응답(Visual Question Answering, VQA) 문제에서 모델의 게으름(model laziness) 현상을 분석합니다. 특히, 이러한 모델이 쉬운 질문에는 오류를 범하는 경향이 있음을 밝히고 있습니다.

- **Technical Details**: 모델의 게으름을 체계적으로 조사하기 위해 LazyBench라는 벤치마크를 수동으로 구축하였으며, 이에는 예/아니오 질문, 다중 선택, 단답형 질문 및 이미지 설명 작업이 포함됩니다. LazyBench를 기반으로 한 분석 결과, 최신 MLLM 모델들(GPT-4o, Gemini-1.5-pro, Claude 3, LLaVA-v1.5-13B)에서 게으름 현상이 널리 존재하며, 이는 성능이 더 높은 모델에서 더욱 두드러지게 나타납니다.

- **Performance Highlights**: VQA v2(LLaVA-v1.5-13B) 벤치마크 분석 결과에서 약 절반의 실패 사례가 모델의 게으름으로 인해 발생한다는 것을 발견하였습니다. 이러한 결과는 모델이 자신의 능력을 충분히 활용할 수 있도록 보장하는 것이 중요함을 강조합니다. 게으름 현상을 완화하기 위한 초기 탐색을 통해 사고의 연쇄(chain of thought, CoT) 기법이 이 문제를 효과적으로 해결할 수 있음을 발견하였습니다.



### Titanic Calling: Low Bandwidth Video Conference from the Titanic Wreck (https://arxiv.org/abs/2410.11434)
- **What's New**: 2022년 여름, 타이타닉 잔해 탐사 중 진행된 통신 실험에 관한 결과를 보고합니다. 이 연구는 깊은 해양에서의 음성 인식 및 텍스트 전송을 통한 커뮤니케이션 시스템의 발전을 보여줍니다.

- **Technical Details**: 해양 심층에서의 통신은 라디오 전송이 불가능하며, 따라서 sonar 신호를 기반으로 합니다. 본 시스템은 음성을 텍스트로 변환한 후, 텍스트 메시지를 수면으로 전송하고, 이를 합성된 입술 동기화 비디오로 재구성합니다. 낮은 대역폭의 sonar 신호 때문의 메시지 전송 한계에도 불구하고, 시스템은 효과적으로 작동하였습니다.

- **Performance Highlights**: 실제 타이타닉 탐사 중 시스템을 테스트하였고, 복잡한 시스템에도 불구하고 수용 가능한 지연(latency)과 우수한 품질을 달성하였습니다. 시스템 시연 비디오는 링크를 통해 제공됩니다.



### ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability (https://arxiv.org/abs/2410.11414)
Comments:
          23pages

- **What's New**: 본 논문에서는 RAG 모델에서의 환각(hallucination) 메커니즘을 심도 있게 분석하고, ReDeEP라는 새로운 환각 탐지 방법을 제안합니다.

- **Technical Details**: RAG 모델은 외부 지식을 결합하여 파라메트릭(내부) 지식이 부족할 때 발생하는 환각을 줄이기 위해 설계되었습니다. 본 논문에서는 LLM의 Knowledge FFN과 Copying Heads가 각각 외부 및 내부 지식을 어떻게 활용하는지에 대한 연구를 통해, 환각이 어떻게 발생하는지를 조사하였습니다.

- **Performance Highlights**: ReDeEP를 통해 환각 탐지 정확도가 크게 향상되었으며, AARF는 Knowledge FFN과 Copying Heads의 기여를 조절하여 환각을 완화하는 데 성공했습니다.



### PMMT: Preference Alignment in Multilingual Machine Translation via LLM Distillation (https://arxiv.org/abs/2410.11410)
- **What's New**: 이 논문은 대규모 다국어 평행 말뭉치를 생성하는 새로운 방법을 제안하며, 이는 특정 번역 선호도에 맞추어져 있습니다. 기존의 번역 방법들이 주로 정확성에 집중한 반면, 인간의 표현 선호를 반영하는 데에는 소홀했던 문제를 해결하고자 합니다.

- **Technical Details**: 제안된 방법은 두 단계로 구성됩니다: 먼저, 여러 번역 자원을 활용하여 소규모 시드 데이터셋을 구축합니다. 이후, 이 시드 데이터를 기반으로 번역 LLM (Large Language Model)을 훈련하여 새로운 소스 텍스트로부터 후보 번역을 생성합니다. 그 다음, 작은 맞춤형 데이터셋을 이용하여 인간의 선호도에 맞은 보상 모델(RM)을 훈련시키고, 후보 번역을 선택하는 데 사용합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 특정 인간 선호가 반영된 번역 작업에서 큰 차이로 성과를 나타내었으며, WMT와 Flores와 같은 공용 벤치마크에서도 경쟁력 있는 성능을 보였습니다. 이는 사용자 맞춤형 번역 요구를 만족시키는 데에서 큰 가능성을 나타냅니다.



### Do LLMs Have the Generalization Ability in Conducting Causal Inference? (https://arxiv.org/abs/2410.11385)
- **What's New**: 본 논문은 대규모 언어 모델(LLM)의 인과 추론(generalization capability)에서의 일반화 능력을 평가하기 위한 새로운 벤치마크 생성 프레임워크를 제안합니다. 이전에 볼 수 없었던 현상에 대한 인과 관계 추론의 성능을 측정하는 데 중점을 두었습니다.

- **Technical Details**: 연구에서는 Causal Path Discovery (CP), Backdoor Adjustment (BA), Factual Inference (FI), Counterfactual Inference (CI) 네 가지 인과 추론 작업을 선택하여 이들의 일반화 능력을 평가했습니다. 무작위로 생성된 그래프와 노드 이름을 사용하여 새롭고 가상의 인과 시나리오를 만드는 벤치마크를 구축했습니다.

- **Performance Highlights**: 실험 결과, LLM은 간단한 CP, FI 및 복잡한 CI 질문의 해결에서 좋은 일반화 성능을 보였지만, BA 질문에서는 어려움을 겪었고 문제 복잡도가 증가함에 따라 성능의 변동이 뚜렷하게 나타났습니다. 초기 성과는 좋으나 새로운 연구 맥락에서 인과 추론의 성능은 여전히 한계가 있습니다.



### Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL (https://arxiv.org/abs/2410.11371)
Comments:
          Accepted to EMNLP2024 Findings

- **What's New**: 이 논문은 Large Language Models (LLMs)을 이용한 text-to-SQL 변환에서 발생하는 성능과 효율성 간의 균형 문제를 해결하기 위해 새로운 방법인 KID (Knowledge Distillation with Imperfect Data)를 제안합니다.

- **Technical Details**: KID는 지식 증류(knowledge distillation) 기술을 기반으로 하여, 대형 teacher 모델의 지식을 소형 student 모델에 전이합니다. KID의 핵심은 불완전한 데이터(imperfect data)를 사용하여 학습-추론 간의 불일치를 효과적으로 완화하는 것입니다.

- **Performance Highlights**: KID는 5개의 text-to-SQL 벤치마크에서 평균 5.83% 성능 향상을 달성하며, 다양한 모델 유형과 크기에서 일관되고 의미 있는 개선 효과를 보입니다.



### Enhance Graph Alignment for Large Language Models (https://arxiv.org/abs/2410.11370)
Comments:
          Under review

- **What's New**: 본 연구에서는 Graph Alignment Large Language Models (GALLM)를 제안하여 LLM이 그래프 데이터를 더 잘 이해하고 사용할 수 있도록 합니다. 새로운 자기지도 학습 방식과 템플릿 정렬을 통해 성능을 개선합니다.

- **Technical Details**: GALLM은 크게 두 가지 단계로 구성됩니다: 첫 번째는 자기지도 조정(self-supervised tuning) 단계로, 텍스트 일치(task) 작업을 통해 LLM을 훈련시킵니다. 두 번째는 작업 특정 조정(task-specific tuning) 단계로, 추가적인 설명과 정렬된 템플릿을 통해 감독 정보를 활용하여 두 가지 범주 프롬프트 방법을 제시합니다.

- **Performance Highlights**: 여러 데이터셋에 대한 실험 평가 결과, 감독 학습(supervised learning), 멀티 데이터셋 일반화(multi-dataset generalizability), 특히 제로샷 능력(zero-shot capability)에서 상당한 성과 개선이 있음을 보여주었습니다.



### LargePiG: Your Large Language Model is Secretly a Pointer Generator (https://arxiv.org/abs/2410.11366)
Comments:
          24 pages

- **What's New**: 이번 연구에서는 대형 언어 모델(LLMs) 기반 쿼리 생성에서 발생하는 환각 문제를 다루기 위해 relevance hallucination과 factuality hallucination이라는 새로운 유형을 도입하였습니다. 이를 통해 LLM에서 생성된 쿼리의 내용과 형식을 효과적으로 분리하는 기법을 제안합니다.

- **Technical Details**: 우리는 LLM을 포인터 생성기(Pointer-Generator, PG)로 변환하는 새로운 접근 방식을 제안합니다. 이 방법은 LLM의 내재적 주의(attention) 가중치를 활용하여 포인터 주의 분포를 생성하고, 모델의 상위 층과 마지막 층의 어휘 분포 차이를 기반으로 복사 확률을 도출합니다. 이러한 방식을 통해 우리는 훈련 없이도 PG 기능을 구현할 수 있습니다.

- **Performance Highlights**: LargePiG는 TruthfulVQG와 TruthfulDQG라는 두 가지 데이터셋에서 효과성을 입증하였으며, 다양한 LLM 기반의 쿼리 생성 방법에서 사실성과 관련성을 향상시켰습니다. 추가 실험을 통해 대형 비전 언어 모델에서 환각 문제를 줄이고 문서 기반 질문 응답과 사실성 평가 과제의 정확성을 개선할 수 있음을 보여주었습니다.



### RATE: Score Reward Models with Imperfect Rewrites of Rewrites (https://arxiv.org/abs/2410.11348)
Comments:
          Submitted as a conference paper to ICLR 2025. Code is available at this https URL

- **What's New**: 이 논문은 언어 모델링에서 사용되는 보상 모델의 평가 방법인 RATE(Rewrite-based Attribute Treatment Estimators)를 개발했습니다. 이 방법은 응답의 특정 속성이 보상에 미치는 인과관계를 측정할 수 있게 해줍니다.

- **Technical Details**: RATE는 큰 언어 모델을 사용하여 응답을 재작성(rewrite)하고, 재작성 오류를 보정하기 위해 두 번 재작성하는 방식을 사용합니다. 이 방법은 비대칭 재작성에서도 신뢰할 수 있는 인과적인 보상 변화를 추정할 수 있습니다.

- **Performance Highlights**: RATE 평가 방법은 합성 및 실제 데이터에서 효과적임을 보여줍니다. 이 방법은 비인과성 상관관계를 교정할 수 있고, 보상 모델을 평가할 때 이러한 교정이 중요함을 실증적으로 입증했습니다.



### SHAKTI: A 2.5 Billion Parameter Small Language Model Optimized for Edge AI and Low-Resource Environments (https://arxiv.org/abs/2410.11331)
Comments:
          Paper in pdf format is 11 pages and contains 4 tables

- **What's New**: Shakti는 25억 개의 매개변수를 가진 언어 모델로, 스마트폰, 웨어러블 기기 및 IoT 시스템과 같은 자원 제약 환경에서 최적화되어 있습니다. 이 모델은 높은 효율성과 정밀도를 갖춘 NLP를 결합하여 실시간 AI 애플리케이션에 적합하며, 다양한 언어와 도메인 특정 작업을 지원합니다.

- **Technical Details**: Shakti는 Variable Grouped Query Attention (VGQA)이라는 기술 혁신을 도입하여 메모리 사용량을 줄이고 추론 시간을 단축합니다. 또한, Pre-normalization과 SwiGLU 활성화 함수를 사용하여 훈련 과정을 안정화하고, Rotary Positional Embeddings (RoPE)를 통합하여 긴 텍스트 시퀀스를 처리할 수 있게 합니다.

- **Performance Highlights**: Shakti는 벤치마크 평가에서 더 큰 모델들과 비교하여 경쟁력 있는 성능을 보이며, 낮은 대기 시간과 높은 장치 내 효율성을 유지합니다. 또한, 특히 헬스케어, 금융 및 고객 서비스와 같은 산업에서 실시간 AI 솔루션을 제공하는 데 이상적입니다.



### Speculative Knowledge Distillation: Bridging the Teacher-Student Gap Through Interleaved Sampling (https://arxiv.org/abs/2410.11325)
- **What's New**: 최근의 연구에서 Knowledge Distillation (KB) 기술이 작고 효율적인 모델들이 대형 모델과 유사한 성능을 낼 수 있도록 발전했습니다. 본 논문에서는 Speculative Knowledge Distillation (SKD)라는 새로운 방식을 제안합니다. SKD는 학생 모델과 교사 모델 간의 협력을 통해 고품질의 훈련 데이터를 실시간으로 생성하는 방식을 사용합니다.

- **Technical Details**: SKD는 학생 모델이 제안하는 토큰에서 품질이 낮은 것을 교사 모델의 분포에 근거하여 교체하는 프로세스를 가지고 있습니다. 이 방법은 교사 모델이 생성할 가능성이 낮은 토큰을 필터링하고, 대신 교사 모델에서 재 샘플링하는 방식을 사용합니다. SKD는 초기 훈련 단계에서는 기존의 Supervised KD와 유사하게 작동하다가, 학생 모델의 성능이 향상됨에 따라 On-policy KD와 비슷한 방식으로 동작합니다.

- **Performance Highlights**: SKD는 다양한 텍스트 생성 작업에서 기존의 KD 방법들보다 뛰어난 성능을 보였습니다. 예를 들어, Gemma-7B를 Gemma-2B로 증류하는 과정에서 저자원 기계 번역에서 41.8%, 요약에서 230%, 산술적 추론에서 160%의 성능 향상을 기록했습니다. 또한, SKD가 MATH 및 GSMplus 테스트에서 각각 198% 및 360%의 성과를 달성했습니다.



### Self-adaptive Multimodal Retrieval-Augmented Generation (https://arxiv.org/abs/2410.11321)
- **What's New**: 이번 연구에서는 Self-adaptive Multimodal Retrieval-Augmented Generation (SAM-RAG)이라는 새로운 접근 방식을 제안합니다. 기존의 RAG 방법이 고정된 수의 문서에 의존하는 한계를 극복하고, 입력 쿼리에 따라 동적으로 관련 문서를 필터링하며, 생성된 응답과 검색된 문서의 품질을 검증하는 기능을 포함하고 있습니다.

- **Technical Details**: SAM-RAG는 query에 대한 관련 데이터를 능동적으로 선택하고, 여러 관점에서 생성된 응답을 검증하는 멀티모달 RAG 프레임워크입니다. 이 프레임워크는 relevance, usefulness, support의 세 가지 기준을 정의하고 이를 바탕으로 검색 결과를 평가하여 응답을 생성합니다. 또한, 상태-of-the-art 모델에서 지식을 증류하여 성능을 보장합니다.

- **Performance Highlights**: SAM-RAG는 기존의 최첨단 모델들, 특히 MuRAG에 비해 멀티모달 RAG 작업에서 뛰어난 성능을 보입니다. 실험 및 ablation 연구를 통해 SAM-RAG의 동적 검색 메커니즘이 성과 향상에 미치는 중요성을 강조하며, 각 검증이 검색 정확도 및 응답 품질을 어떻게 개선하는지에 대한 사례 연구를 제시합니다.



### SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation (https://arxiv.org/abs/2410.11315)
Comments:
          15 pages, 6 figures, 5 tables. Accepted by EMNLP 2024 (main)

- **What's New**: 이 논문에서는 Retrieval-Augmented Generation (RAG)에서 성능을 향상시키기 위해 모델 기반의 증거 추출 학습 프레임워크 SEER를 제안합니다. 기존의 휴리스틱(heuristic) 기반 방법의 여러 문제를 해결하고자 하며, 이 프레임워크는 자기 정렬(self-aligned) 학습을 통해 증거를 최적화하는 것을 목표로 합니다.

- **Technical Details**: SEER는 세 가지 주요 단계로 구성됩니다: (1) 증거 추출: 의미적 일관성과 다양한 길이의 증거를 샘플링하여 추출합니다. (2) 전문가 평가: 쿼리, 답변, 구절 및 증거로 구성된 4중 항목 QuadQARE를 사용하여 각 증거의 품질을 평가합니다. (3) 자기 정렬: 추출된 증거의 순위 목록에 따라 최적화 작업을 수행합니다.

- **Performance Highlights**: 광범위한 실험을 통해 SEER는 RAG 성능을 크게 개선하고, 추출된 증거의 신뢰성(faithfulness), 유용성(helpfulness), 응축성(conciseness)을 향상시키며, 증거의 길이를 9.25배 줄이는 성과를 보였습니다.



### Enhancing Assamese NLP Capabilities: Introducing a Centralized Dataset Repository (https://arxiv.org/abs/2410.11291)
Comments:
          6 pages, 1 table, 1 figure

- **What's New**: 이 논문은 저자들이 아삼어(NLT) 및 NMT(Natural Machine Translation)를 위한 중앙집중식 오픈 소스 데이터셋 저장소를 설계하여 소개합니다. 이 저장소는 GitHub에서 제공되며, 감정 분석(sentiment analysis), 개체 인식(named entity recognition), 기계 번역 등의 다양한 작업을 지원합니다.

- **Technical Details**: 이 데이터셋은 두 가지 유형으로 나뉘며, 사전 훈련(pre-training) 및 후 훈련(post-training)에 사용되는 코퍼스가 포함되어 있습니다. 예를 들어, Wikipedia 데이터셋, CC100 코퍼스, C4 다국어 데이터셋 등을 포함하고 있으며, 이들은 아삼어 모델 훈련에 도용될 수 있습니다. 또한, ChatGPT에 의해 생성된 데이터셋도 포함되어 있습니다.

- **Performance Highlights**: 이 저장소는 아삼어 연구에 있어 협업과 혁신을 촉진합니다. 향후 연구는 NMT 모델에 대한 새로운 응용 프로그램, 이미지 캡셔닝(image captioning), AI 기반 챗봇 개발 등을 포함할 수 있습니다. 데이터의 제한 사항에도 불구하고, 아삼어에 대한 NLP 연구의 디지털 시대에서의 지속 가능성을 보여줍니다.



### Process Reward Model with Q-Value Rankings (https://arxiv.org/abs/2410.11287)
- **What's New**: 본 논문에서는 기존의 Process Reward Modeling (PRM) 방식을 개선하기 위해 Process Q-value Model (PQM)이라는 새로운 프레임워크를 제안합니다. PQM은 Q-value 순위 매기기 문제로 PRM을 재정의하고, 각 단계 간의 상호 의존성을 보다 효과적으로 캡처합니다.

- **Technical Details**: PQM 모델은 Markov Decision Process (MDP) 맥락에서 PRM을 최적화하며, 새로운 비교 손실 함수(comparative loss function)를 기반으로 Q-value 순위를 최적화합니다. 이로 인해 각 단계의 기여도를 보다 세분화하여 평가할 수 있게 됩니다.

- **Performance Highlights**: PQM은 다양한 샘플링 정책(sampling policies), 언어 모델 백본(language model backbones), 그리고 다단계 추론(multi-step reasoning) 벤치마크에서 기존의 분류 기반 PRM에 비해 우수한 성능을 보였습니다. 예를 들어, Llama-3-70B-Instruct 모델에서 샘플링한 솔루션의 정확도가 39.8%에서 51.4%로 개선되었으며, 이는 MATH500 벤치마크에서 직접적인 11.6% 향상을 나타냅니다.



### Cognitive Overload Attack:Prompt Injection for Long Contex (https://arxiv.org/abs/2410.11272)
Comments:
          40 pages, 31 Figures

- **What's New**: 이번 논문에서는 대규모 언어 모델(LLMs)의 In-Context Learning (ICL) 개념을 인지 신경 과학의 관점에서 재해석하였으며, 인간 인지에서의 학습 과정과 ICL 간의 유사성을 강조하였습니다. 이를 통해 LLMs가 인지 과부하(cognitive overload)를 경험할 수 있음을 경험적으로 검증하고, 이러한 현상을 악용하여 LLMs를 jailbreaking할 수 있는 공격 기법을 제안하였습니다.

- **Technical Details**: 논문에서는 Cognitive Load Theory (CLT) 원리를 기반으로 LLMs의 ICL을 분석하였으며, LLMs에서의 인지 과부하가 모델의 성능에 미치는 영향을 실험적으로 검증하였습니다. 실험 결과, LLMs는 인지 과부하 상태에 놓일 경우 성능 저하가 발생하며, 이를 통해 공격자가 LLM의 안전 메커니즘을 우회할 수 있는 방향으로 ICL을 조작할 수 있음을 보여주었습니다.

- **Performance Highlights**: 고급 모델들(GPT-4, Claude-3.5 Sonnet, 등)은 인지 과부하 공격에 대해 최대 99.99%의 공격 성공률을 기록하였으며, 이러한 공격 방식은 다양한 LLMs에 전이 가능하다는 것을 입증하였습니다. 이는 LLMs의 구조적 취약점을 드러내며, 악의적인 공격으로부터 방어하기 위한 강력한 방안이 필요함을 강조합니다.



### In-Context Learning for Long-Context Sentiment Analysis on Infrastructure Project Opinions (https://arxiv.org/abs/2410.11265)
- **What's New**: 이번 연구는 GPT-4o, Claude 3.5 Sonnet, Gemini 1.5 Pro 등 세 가지 주요 대형 언어 모델(LLMs)의 성능을 장기적이고 복잡한 의견이 상이한 문서에 대해 평가하였습니다.

- **Technical Details**: 연구에서는 제로샷(zero-shot)과 몇 샷(few-shot) 시나리오에서 인프라 프로젝트와 관련된 긴 문서들을 분석했습니다. 각 모델의 성능을 비교하는 데 있어 다양한 문서의 복잡성과 감정의 변동성을 고려했습니다.

- **Performance Highlights**: 결과적으로 GPT-4o는 간단하고 짧은 문서에서 제로샷 시나리오에서 뛰어난 성능을 보였으나, Claude 3.5 Sonnet는 복잡한 문서와 감정 변동이 있는 상황에서 더 우수한 성능을 나타냈습니다. 몇 샷 시나리오에서는 Claude 3.5 Sonnet이 전반적으로 뛰어난 성과를 보였고, GPT-4o는 시연 횟수가 증가함에 따라 더 큰 안정성을 보였습니다.



### HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications (https://arxiv.org/abs/2410.11239)
- **What's New**: 이 논문에서는 HR 관련 수백 개의 반복적 프로세스를 자동화하기 위해 HR-Agent라는 HR 전용 LLM(대형 언어 모델) 기반 대화 시스템을 개발했다고 보고하고 있습니다. 이 시스템은 의료 청구, 접근 요청과 같은 HR 프로세스의 효율성을 높일 수 있도록 설계되었습니다.

- **Technical Details**: HR-Agent는 대화 상태 추적(DST) 기술을 활용하여 대화 중 사용자 의도 및 세부 사항을 모니터링하고 예측합니다. 이 시스템은 신속한 응답 시간, 신뢰성 있는 정보 추출, 다양한 HR 용도 처리, 기밀성 유지 및 HR 특화의 요구 사항을 충족합니다. 대화 데이터는 추론 과정 중 LLM으로 전송되지 않아 기밀성이 유지됩니다.

- **Performance Highlights**: HR-Agent는 더 큰 언어 모델과 비교하여 더 작고 빠르면서도 뛰어난 성능을 발휘합니다. 이 시스템은 휴먼 리소스 프로세스의 효율성을 크게 향상시킵니다.



### Unleashing the Power of LLMs as Multi-Modal Encoders for Text and Graph-Structured Data (https://arxiv.org/abs/2410.11235)
- **What's New**: 이번 논문에서는 Janus라는 새로운 프레임워크를 제안하여 대형 언어 모델(LLM)을 활용해 텍스트와 그래프 데이터를 공동으로 인코딩하는 방법을 소개합니다. 이 방법은 그래프 임베딩을 텍스트 임베딩과 동일한 공간으로 투영하여 두 가지 모달리티를 함께 처리할 수 있도록 합니다.

- **Technical Details**: Janus는 다층 퍼셉트론(MLP) 어댑터를 사용하여 그래프 임베딩을 텍스트 임베딩 공간으로 변환하며, 대조 학습(contrastive learning)을 통해 그래프와 텍스트 공간을 효과적으로 정렬합니다. 이것은 두 모달리티의 통합을 최적화하여 더 나은 조합 표현을 학습할 수 있게 합니다.

- **Performance Highlights**: Janus는 지식 그래프(Contextualized Knowledge Graph) 질의 응답(QA) 작업, 그래프-텍스트 쌍 분류, 검색 작업 등에 대해 총 6개의 데이터셋에서 실험을 진행하여 기존 방법들보다 뛰어난 성능을 보였습니다. 특히 QA 작업에서는 최대 11.4%의 개선을 달성했습니다.



### "Is Hate Lost in Translation?": Evaluation of Multilingual LGBTQIA+ Hate Speech Detection (https://arxiv.org/abs/2410.11230)
Comments:
          Under review

- **What's New**: 이번 연구는 여러 언어(영어, 이탈리아어, 중국어, 코드 스위칭된 영어-타밀)를 포함하여 LGBTQIA+에 대한 혐오 발언 탐지의 도전과제를 다루고 있습니다. 기계 번역의 영향을 조사하고, 혐오 발언이 번역 과정에서도 잘 보존되는지를 검토했습니다.

- **Technical Details**: 본 연구는 영어, 이탈리아어, 중국어 및 영어-타밀(코드 혼합)이라는 레이블이 붙은 데이터세트를 이용하여 LGBTQIA+ 특화 혐오 발언을 분류합니다. 저희는 LLM(large language model)을 사용하여 제로샷 분류를 수행하고, 번역 후 영어로 다시 분류를 진행했습니다.

- **Performance Highlights**: 모델 성능은 영어에서 가장 높았으며, 영어-타밀의 코드 스위칭 시나리오에서 가장 낮았습니다. 파인튜닝을 통해 모든 언어의 성능이 일관되게 향상되었으나, 번역의 경우 혼합된 결과를 나타냅니다. 영어의 F1 스코어는 0.7952로 가장 높았고, 영어-타밀은 0.3619로 가장 낮았습니다.



### On the Capacity of Citation Generation by Large Language Models (https://arxiv.org/abs/2410.11217)
Comments:
          Accepted by CCIR 2024

- **What's New**: 이번 연구는 대형 언어 모델(LLMs)이 생성하는 응답 내 인용 생성 능력에 대한 체계적 분석을 실시하고, 인용 품질을 향상시키기 위한 새로운 방법을 제시합니다. 주된 초점은 기존 연구들이 응답의 정확성을 높이는 데 집중했던 것과 달리, 정확한 출처 귀속 기능을 개선하는 것입니다.

- **Technical Details**: 연구에서 사용한 두 가지 기본 방법은 few-shot 및 fine-tuning입니다. 인용 품질 향상을 위해 Generate-then-Refine 방법을 제안하며, 이는 관련 인용을 추가하고 불필요한 인용을 제거하여 응답 텍스트를 변경하지 않고 인용 품질을 개선하는 방식을 포함합니다. 또한, 새로운 인용 평가 메트릭도 도입하여 기존 메트릭에서 불필요한 인용에 대한 과도한 처벌을 배제합니다.

- **Performance Highlights**: WebGLM-QA, ASQA, ELI5 데이터셋에서 실험한 결과, 제시된 방법이 LLMs에 의해 생성된 응답의 인용 품질을 상당히 향상시키는 것으로 나타났습니다. 연구의 주요 기여는 LLM이 생성하는 인용 분석, 인용 품질 평가를 위한 보다 포괄적인 메트릭 제안, 그리고 인용 품질을 대폭 향상시키는 Generate-then-Refine 접근법을 제시한 것입니다.



### Sampling Strategies for Creation of a Benchmark for Dialectal Sentiment Classification (https://arxiv.org/abs/2410.11216)
Comments:
          Under review

- **What's New**: 본 논문은 영어로 작성된 Google Places 리뷰의 방언적 감정 분류를 위한 벤치마크를 만들기 위한 데이터 샘플링 전략을 조사합니다. 호주(호주 영어), 인도(인도 영어), 영국(영국 영어) 리뷰들로부터 자가 감독 데이터셋을 수집하며, 이 데이터는 자가 감독 감정 라벨(1성에서 5성에 해당)을 포함합니다.

- **Technical Details**: 연구는 라벨 의미론, 리뷰 길이 및 감정 비율을 기반으로 한 샘플링 기술을 사용하여 세 가지 세분화된 BERT 기반 모델에서 성능을 보고합니다. 연구는 Google Places 리뷰 데이터에서 방언 데이터를 수집하고 자가 감독을 사용하여 다단계 라벨을 할당하는 방법을 제시합니다.

- **Performance Highlights**: 우리는 다양한 데이터 샘플링 기술을 적용하여 효과적이고 도전적인 벤치마크 데이터셋을 구성하였으며, 이 방언 데이터에 대한 모델 성능 종합 평가에서 통찰을 제공합니다. 평가 결과는 호주 영어 및 영국 영어와 같은 내圈 방언뿐만 아니라 인도 영어와 같은 비원주 방언을 위한 도전적인 시나리오를 강조합니다.



### Athena: Retrieval-augmented Legal Judgment Prediction with Large Language Models (https://arxiv.org/abs/2410.11195)
Comments:
          13 pages, 6 figures

- **What's New**: 최근 ChatGPT, LLaMA 및 Claude와 같은 대형 언어 모델(LLMs)이 법률 분야를 포함한 여러 도메인에서 두각을 나타내고 있습니다. 이에 따라 LLM과 실제 응용 프로그램 간의 인터페이스로서 프롬프트 엔지니어링(prompt engineering, PE)의 발전이 주목받고 있습니다. 본 연구에서는 'Athena'라는 새로운 프레임워크를 제안하여 법적 판단 예측(legal judgment prediction, LJP) 문제 해결에 RAG를 핵심 전처리 구성 요소로 활용합니다.

- **Technical Details**: Athena는 고발(고소)에 대한 지식 기반을 구축하고, 벡터화(vectorization)를 통해 의미 검색(semantic retrieval) 메커니즘을 첨부합니다. 실험 결과, Athena의 전반적인 성능이 크게 향상되어 CAIL2018 데이터셋에서 최첨단 결과를 달성하였습니다. 우리는 RAG를 도입하여 LLM의 법률 분야에서의 지식 취득을 개선하고, 이를 통해 환각(hallucination)과 모호성을 완화합니다.

- **Performance Highlights**: 실험에서는 LLM의 '중간에 길을 잃은(lost-in-the-middle)' 현상을 재현하며, 적절한 하이퍼 파라미터 조정(hyper-parameter tuning)을 통해 최대 95%의 정확도를 달성할 수 있음을 보여주었습니다. 또 한편, 쿼리 재작성(query rewriting) 및 데이터 분포(data distribution)의 영향도 연구하여 향후 연구 방향을 제시하였습니다.



### Model Swarms: Collaborative Search to Adapt LLM Experts via Swarm Intelligenc (https://arxiv.org/abs/2410.11163)
- **What's New**: 새로운 논문에서는 Model Swarms라는 협업 검색 알고리즘을 제안하여 LLMs(대형 언어 모델)를 스웜 지능(swarm intelligence)으로 적응시키는 방법을 소개합니다. 이 방법은 다양한 모델들이 각자의 능력과 데이터를 기반으로 최적화된 유틸리티 함수를 활용하여 협력적으로 방향성을 가지고 움직입니다.

- **Technical Details**: Model Swarms는 파티클 스웜 최적화(Particle Swarm Optimization, PSO)에 영감을 받아, 다수의 LLM 전문가를 "입자(particles)"로 간주하고 이들이 모델 가중치 공간에서 협력적으로 움직이며 새로운 모델 적응을 검색합니다. 각 입자는 개인 최적 지점(personal best)과 전체 최적 지점(global best) 정보를 공유하며, 유틸리티 함수에 기반하여 운동을 업데이트합니다.

- **Performance Highlights**: Model Swarms는 200개의 사례로도 작업을 최적화하여 12개의 기존 모델 조합 기준을 초과하여 13.3% 성능 개선을 달성했습니다. 또한, 의료, 법률, 과학 및 문화 도메인에서 다중 작업을 공동 최적화하여 독립적으로 작업을 수행할 때보다 더 나은 전문가를 생성하고, 보상 모델의 경우 사전 설정 없이 더 나은 제어력을 보여줍니다. 인간의 관심사에 대해서도 기존 모델과 경쟁하며 85% 이상의 사례에서 뛰어난 성과를 나타냈습니다.



### LLM Unlearning via Loss Adjustment with Only Forget Data (https://arxiv.org/abs/2410.11143)
Comments:
          Paper under review

- **What's New**: 이번 연구에서는 기존의 unlearning 방식에서 요구되는 retain data나 reference LLM 없이도 LLM의 응답 조정이 가능하다는 것을 제안합니다.

- **Technical Details**: 우리의 방법인 FLAT(Forget data only Loss AjustmenT)는 잊어야 할 데이터에 대한 정보만을 사용하여 f-divergence를 극대화함으로써 모델 응답을 조정합니다. 이를 통해 잊는 과정에서의 성능을 저하시키지 않고 모델의 유용성을 유지할 수 있습니다.

- **Performance Highlights**: 실험 결과, FLAT는 해리포터 데이터셋, MUSE 벤치마크 및 TOFU 데이터셋과 같은 다양한 과제에서 기존 방법들에 비해 우수한 unlearning 성능을 달성하였으며, 모델의 유지 능력에 미치는 영향도 최소화했습니다.



### IsoChronoMeter: A simple and effective isochronic translation evaluation metric (https://arxiv.org/abs/2410.11127)
Comments:
          WMT24 (co-located with EMNLP24), Accepted to Shared Task Track, 6 pages, 2 figures, 4 tables, 2 pages references

- **What's New**: 이번 연구에서는 IsoChronoMeter (ICM)라는 새로운 이소크로닉 번역 측정 지표를 제안하며, 자동 더빙의 중요한 맥락에서 이소크로닉 번역의 효과성을 강조합니다. 기존 최첨단 번역 시스템들이 이소크로닉 번역을 고려하지 않은 경우 이 지표에서 미흡한 결과를 보였음을 입증했습니다.

- **Technical Details**: IsoChronoMeter (ICM)는 기존의 텍스트-음성 변환(TTS) 지속시간 예측기를 기반으로 하여 이소크로닉 번역을 측정하는 단순하면서도 효과적인 지표입니다. ICM은 원래 음성 길이 예측과 번역된 음성 길이 예측 간의 상대적 절대 오차를 사용하여 계산됩니다. ICM 값이 0이면 두 음성 길이 예측이 동일하다는 것을 의미하며, 값이 클수록 두 예측의 차이가 큽니다.

- **Performance Highlights**: ICM은 기존 번역 시스템들이 이소크로닉 번역을 충족하지 못하고 있음을 보여주며, AI 기반 더빙 시스템의 품질과 자연스러움을 향상시키기 위해 이소크로닉 번역의 필요성을 강조합니다. 이 연구는 CoVost-2 데이터 세트를 활용하여 이소크로닉 번역 평가의 필요성을 제기합니다.



### A Systematic Review on Prompt Engineering in Large Language Models for K-12 STEM Education (https://arxiv.org/abs/2410.11123)
- **What's New**: 본 연구는 K-12 STEM 교육에서 LLMs(대형 언어 모델)과 prompt engineering(프롬프트 엔지니어링)의 결합 사용에 대한 실증 연구를 분석하였습니다. 2021년부터 2024년까지 발표된 논문 중 30개를 선택하여 감독한 내용입니다.

- **Technical Details**: PRISMA 프로토콜을 따르며, 2,654개의 논문을 검토 후 30개 연구를 선정했습니다. 연구에서는 사용된 prompting strategies(프롬프트 전략), LLM의 종류, 효과 평가 방법, 이전 연구의 한계를 확인하였습니다.

- **Performance Highlights**: 간단한 prompting은 일반적으로 사용되지만, few-shot 및 chain-of-thought prompting과 같은 고급 기법이 다양한 교육 작업에서 긍정적인 결과를 보여주었습니다. GPT 시리즈 모델이 주로 사용되지만, 적은 수의 파라미터를 가진 모델(예: Blender 7B)과 효과적인 prompt engineering이 결합되었을 때 특정 상황에서 더 큰 모델(예: GPT-3)을 초월하는 성능을 보였습니다.



### ChuLo: Chunk-Level Key Information Representation for Long Document Processing (https://arxiv.org/abs/2410.11119)
Comments:
          Submitted to ICLR 2025

- **What's New**: 본 논문에서는 긴 문서 분류에서 기존의 한계를 극복하는 새로운 청크 표현 방법인 ChuLo를 소개합니다. ChuLo는 비지도 키프레이즈 추출을 이용하여 입력 토큰을 그룹화하고 시맨틱적으로 중요한 키프레이즈 기반의 청크를 강조하여 핵심 문서 내용을 유지하면서 입력 길이를 줄입니다.

- **Technical Details**: ChuLo는 비지도 학습 방법을 통해 중요한 키프레이즈를 추출하여 입력 길이를 감소시키면서도 핵심 내용을 보존합니다. 이 방법은 긴 문서 처리에서 정보 손실을 최소화하고 Transformer 모델의 효율성을 향상시킵니다. 또한, 모든 토큰을 유지하는 것이 중요한 토큰 분류 작업에서 세밀한 주석을 잃지 않도록 보장합니다.

- **Performance Highlights**: 다양한 긴 문서 분류 작업 및 긴 문서 토큰 분류 작업에서 ChuLo의 효과성을 평가하였으며, 방대한 질적 및 양적 분석을 통해 경쟁력 있는 결과를 입증하였습니다.



### Active Learning for Robust and Representative LLM Generation in Safety-Critical Scenarios (https://arxiv.org/abs/2410.11114)
- **What's New**: 이 논문은 안전 시나리오에서 LLM(대형 언어 모델)의 출력을 안내하기 위해 클러스터링과 능동 학습(active learning)을 결합한 새로운 프레임워크를 제안합니다.

- **Technical Details**: 제안된 프레임워크는 다양한 클러스터에서 불확실한 사례를 식별하고, 이를 LLM에게 전달하여 반복적인 생성 과정을 통해 더 균형 잡힌 데이터 세트를 생성합니다. 총 5.4K의 안전 위반 사항 데이터셋을 구축하였으며, 이는 다양한 안전 시나리오를 포괄합니다.

- **Performance Highlights**: 이 방법으로 생성된 데이터는 액티브 러너 모델의 정확도와 F1 점수를 향상시키며, 다른 모델에서도 성능 개선의 효과를 보입니다. 이는 기존 시뮬레이션 중심의 연구를 넘어 새로운 데이터 세트를 생성하면서 머신 러닝 모델 훈련에 실질적 적용 가능성을 보여줍니다.



### JOOCI: a Framework for Learning Comprehensive Speech Representations (https://arxiv.org/abs/2410.11086)
Comments:
          Submitted to ICLR 2025

- **What's New**: 본 논문에서는 JOOCI(이중 최적화 프레임워크)를 제안하여 기존의 단일 임베딩 방식으로 인해 발생하는 비효율성을 극복하고, 다른 정보(other information)와 내용(content information)을 독립적으로 최적화합니다.

- **Technical Details**: JOOCI 프레임워크는 두 개의 주요 인코더(내용 인코더 및 다른 인코더)를 사용하여 각각의 정보를 모델링합니다. 내용 인코더(Content Encoder)는 내용 정보를 담고 있으며, 다른 인코더(Other Encoder)는 비언어적 정보를 캡처합니다. 이 프레임워크는 공유 인코더(Shared Encoder)를 사용하여 원시 음성을 다운샘플링하고 두 인코더를 위한 임베딩 계층을 제공합니다.

- **Performance Highlights**: SUPERB 벤치마크에서 JOOCI는 비슷한 크기(1억 개의 파라미터)와 사전 훈련 데이터(960시간)를 가진 다른 최신 모델들보다 성능이 일관되게 우수하며, 주요 음성 다운스트림 작업들에 있는 평가 결과에서 큰 차이를 보였습니다.



### Gender Bias in Decision-Making with Large Language Models: A Study of Relationship Conflicts (https://arxiv.org/abs/2410.11084)
Comments:
          EMNLP Findings 2024

- **What's New**: 이번 연구는 대규모 언어 모델(LLMs)의 성별 편견을 분석하며, 특히 관계 결정 상황에서 성 역할에 대한 모델의 이해를 조사합니다. 새로운 데이터셋인 DeMET Prompts를 사용하여 친밀한 관계의 다양한 시나리오를 탐구합니다.

- **Technical Details**: DeMET Prompts는 전통적-평등주의 시나리오를 포함하며, 다양한 이름 목록(남성, 여성, 중립적 이름)을 통해 아홉 가지 관계 구성을 분석합니다. 안전성 가드레일(safety guardrails)을 추가하여 모델의 편견을 어떻게 줄일 수 있는지를 평가합니다.

- **Performance Highlights**: 모든 모델은 여성, 성 중립 이름, 남성 순으로 편견이 나타났으며, 안전성 가드레일을 추가할 경우 이러한 편견이 감소하였습니다. 연구 결과는 모델이 전통적인 남성 우위의 고정관념을 회피하며 '전통적으로 여성'인 개인과 더 자주 연관되어 있음을 보여줍니다.



### Code-Mixer Ya Nahi: Novel Approaches to Measuring Multilingual LLMs' Code-Mixing Capabilities (https://arxiv.org/abs/2410.11079)
Comments:
          Manuscript submitted to COLING 2025

- **What's New**: 다언어 대형 언어 모델(Multilingual Large Language Models, LLMs)의 기계 번역(Machine Translation, MT) 능력은 이미 뛰어난 성과를 보여주었지만, 코드 스위칭(code-switching) 상황에서의 능력은 충분히 탐구되지 않았습니다. 이 논문에서는 코드를 혼합한 문장을 생성하기 위한 새로운 프롬프트 기법인 Rule-Based Prompting을 소개합니다.

- **Technical Details**: 연구에서는 $k$-shot prompting($k\in\{0, 1, 10, 20\}$)과 Rule-Based Prompting을 사용하여 GPT-3.5-turbo, GPT-4, Gemini Pro와 같은 3개의 인기 있는 다국어 LLM의 코드 혼합 MT 능력을 측정하고 비교합니다. 데이터셋은 영어-{힌디어(Hindi), 벵골어(Bengali), 구자라티어(Gujarati), 프랑스어(French), 스페인어(Spanish)}의 5개 언어 쌍을 포함하며, 이를 통해 다언어 LLM의 영어와 코드 혼합 문장 간의 번역 능력을 평가합니다.

- **Performance Highlights**: 결과에 따르면, $k$-shot prompting이 종종 최고의 성과를 나타내지만, Rule-Based Prompting은 코드 혼합의 스타일이 다양한 고유한 문장을 생성하는 데 유망한 결과를 보여줍니다. 또한, 이 연구의 실제 적용으로 코드 혼합 챗봇을 개발하였습니다.



### PRACTIQ: A Practical Conversational Text-to-SQL dataset with Ambiguous and Unanswerable Queries (https://arxiv.org/abs/2410.11076)
- **What's New**: 이 논문에서는 실전에서 사용자 질문의 모호성과 답변 불가능성을 반영한 PRACTIQ라는 대화형 text-to-SQL 데이터셋을 생성했습니다. 기존의 text-to-SQL 시스템들이 명확한 질문에 초점을 맞췄던 반면, PRACTIQ는 실제 사용자 질의를 바탕으로 하여 모호하고 답변 불가능한 질문을 포함합니다.

- **Technical Details**: PRACTIQ는 네 가지 모호한 질문 카테고리와 네 가지 답변 불가능 질문 카테고리를 정의한 후, 이를 바탕으로 대화 형식의 질문을 생성합니다. 또한, 질문 분류 및 SQL 예측을 위한 두 단계의 프레임워크를 구현했습니다. 이를 위해 여러 대형 언어 모델(LLM)을 사용하여 성능을 평가하고 있습니다.

- **Performance Highlights**: 실험 결과, 현재의 최첨단(text-to-SQL) 시스템들은 모호하고 답변 불가능한 질문을 효과적으로 처리하지 못함을 보여주었습니다. PRACTIQ 데이터셋을 통해 이러한 문제를 개선하는 데 기여할 것으로 기대됩니다.



### An Annotated Dataset of Errors in Premodern Greek and Baselines for Detecting Them (https://arxiv.org/abs/2410.11071)
- **What's New**: 이번 연구에서는 고대 그리스어(ancient Greek)에서 실제 오류(real errors)를 포함하는 첫 번째 데이터셋을 소개합니다. 이 데이터셋은 수세기 동안 복사(copied) 과정에서 축적된 오류를 평가하는 데 사용됩니다.

- **Technical Details**: 1,000개의 단어(sampled words)를 BERT(Bidirectional Encoder Representations from Transformers) 기반의 조건(conditionals)에서 파생된 메트릭(metrics)으로 샘플링하여 오류가 있을 가능성이 높은 단어를 추출하였습니다. 이후 전문가(domain expert)가 오류로 주석(annotation) 및 레이블(labeling)을 붙였습니다. 논문에서는 새로운 오류 탐지(error detection) 방법을 제안하고, 판별자(discriminator) 기반의 탐지기가 가장 높은 성과를 보인다는 것을 발견하였습니다.

- **Performance Highlights**: 우리의 판별자(discriminator) 기반 탐지기는 실제 오류(real errors) 분류에서 true positive rate를 5% 향상시켰습니다. 또한, 필사 오류(scribal errors)가 인쇄(print) 또는 디지털화(digitization) 오류보다 탐지하기 더 어렵다는 것을 관찰했습니다. 이 데이터셋은 고대 텍스트의 오류 탐지 방법을 평가하는 기초를 제공합니다.



### Assessing Bias in Metric Models for LLM Open-Ended Generation Bias Benchmarks (https://arxiv.org/abs/2410.11059)
Comments:
          NeurIPS 2024 EvalEval Workshop

- **What's New**: 본 연구는 대형 언어 모델(LLMs)의 편향을 평가하는 open-generation bias benchmarks, 특히 BOLD 및 SAGED의 내재적 편향을 분석합니다. 이를 통해 불공정한 결론에 이르게 하는 분류기(classifiers)의 편향을 조사했습니다.

- **Technical Details**: MGSD 데이터셋을 사용하여 두 가지 실험을 수행했습니다. 첫 번째 실험에서는 counterfactuals를 통해 인구 통계 그룹 간의 예측 변동성을 측정하고, 두 번째 실험에서는 SHAP(Shapley Additive Explanations) 도구를 사용하여 관찰된 편향이 이러한 counterfactuals에서 유래했음을 검증했습니다.

- **Performance Highlights**: 연구 결과, 다양한 인구통계 설명자(demographic descriptors)에서 불평등한 처리 결과가 나타났으며, 특히 RegardV3는 가장 큰 편향을 보였습니다. Race 그룹이 가장 많은 편향을 보였고, Detoxify는 인종 간 독성 점수에서 큰 변동성을 보였습니다.



### Beyond Human-Only: Evaluating Human-Machine Collaboration for Collecting High-Quality Translation Data (https://arxiv.org/abs/2410.11056)
- **What's New**: 이 연구에서는 인간-기계 협력을 통해 고품질 번역을 효과적으로 수집하는 방법을 제시합니다. 11가지 접근 방식을 통해 작업의 효율성과 비용 절감 효과를 입증했습니다.

- **Technical Details**: 이 연구는 전통적인 인간 번역 방식과 기계 번역 방식 및 하이브리드 접근 방식을 포함한 11가지 방법을 비교 분석했습니다. 오류 분석을 통해 인간과 기계 기여의 보완적 강점을 강조했습니다.

- **Performance Highlights**: 인간-기계 협력 방식은 전통적인 방법의 약 60%의 비용으로 높은 품질의 번역을 제공할 수 있으며, 연구 데이터 세트는 18,000개 번역 세그먼트를 포함하고 있습니다.



### Varying Shades of Wrong: Aligning LLMs with Wrong Answers Only (https://arxiv.org/abs/2410.11055)
- **What's New**: 본 논문에서는 주석(annotation)이 부족한 상황에서 LLM(large language model)의 성능을 어떻게 확장할 수 있는지에 관한 두 가지 연구 질문에 초점을 맞춥니다. (1) LLM이 잘못된 옵션들 사이에서 신뢰할 수 있는 선호도를 생성할 수 있는가? (2) 이러한 잘못된 옵션 간 선호와의 정렬(alignment)이 도움이 되는가?

- **Technical Details**: 연구에서는 Self-consistency, token probabilities, LLM-as-a-judge와 같은 방법을 통해 잘못된 옵션들 사이의 선호도를 이끌어내고 이 합성(preference optimization)을 통해 언어 모델을 미세 조정(fine-tune)합니다. 실험 결과, LLM은 다양한 shades of wrong을 구분하며, 일부 경우에는 더 나은 정확성을 보입니다. 아울러, 잘못된-잘못된 선호에 대한 정렬이 모델의 교정(calibration)을 향상시키는 데 기여합니다.

- **Performance Highlights**: 7개의 LLM과 8개의 데이터셋을 활용한 광범위한 실험을 통해, (1) LLM이 잘못된 옵션 사이의 선호도를 구분할 수 있으며, 무작위 추측보다 평균 20.9% 높은 성능을 보입니다. (2) 잘못된 옵션 간 선호도와의 정렬이 LLM의 성능을 개선시켜, 경우에 따라 올바른 답안을 도출하기도 하며, 전체적으로 모델의 교정 오류(Estimated Calibration Error)는 최대 9.4% 감소합니다.



### Personality Differences Drive Conversational Dynamics: A High-Dimensional NLP Approach (https://arxiv.org/abs/2410.11043)
Comments:
          To be published in the Proceedings of the Second Workshop on Social Influence in Conversations (SICon 2024), co-located with EMNLP 2024

- **What's New**: 이 논문은 대화의 주제 흐름이 시간에 따라 어떻게 나타나는지와 대화 상대자들의 성격 특성이 이 주제 흐름에 어떻게 기여하는지를 조사합니다.

- **Technical Details**: 1655개의 비공식 대화를 통해 수집된 데이터에서 텍스트 임베딩을 활용하여 고차원 공간으로 대화 궤적을 매핑합니다. 비선형 투영과 클러스터링을 사용하여 각 대화자의 주제 진입과 퇴장을 식별합니다. 대화 흐름의 차이는 	extit{topic entropy}와 	extit{linguistic alignment}를 통해 정량화됩니다.

- **Performance Highlights**: 성격 차원이 더 큰 개방성을 가진 대화자는 더 다양한 주제에 대해 더 많은 시간을 소요하며, 외향성이 큰 차이를 가진 대화자는 대화 중에 언어적 일치도가 더 크게 감소하는 경향이 있습니다. 또한, 외향성 차이에 따라 감정 변화의 차이가 더 크고, 주제 엔트로피가 클수록 감정 증가가 더 크게 나타나는 것으로 확인되었습니다.



### Persistent Topological Features in Large Language Models (https://arxiv.org/abs/2410.11042)
Comments:
          10+6 pages, 7 figures, 1 table. All comments welcome!

- **What's New**: 이 논문은 대규모 언어 모델(LLMs)의 내부 표현을 분석하기 위해 새로운 프레임워크인 zigzag persistence를 도입하였습니다. 이는 동적 변환을 겪는 데이터의 위상학적(topological) 특성을 효과적으로 설명하는 방법으로, LLM의 레이어(layer) 간 변화를 추적합니다.

- **Technical Details**: 제안된 persistence similarity는 LLM 레이어 간의 위상적 특성이 어떻게 지속되고 변화하는지를 정량화하는 새로운 메트릭(metric)입니다. 기존의 유사성 측정 방법들과 달리, persistence similarity는 두 레이어 간의 모든 변환 궤적을 추적하여 내부 작동 원인에 대한 깊은 통찰력을 제공합니다.

- **Performance Highlights**: 이 접근법을 통해 중요한 레이어들을 식별하고 불필요한 레이어를 제거함으로써 성능 저하 없이 모델을 경량화할 수 있음을 보였습니다. 여러 벤치마크 데이터셋에서 최신 방법들과 비슷한 성능을 유지하며, 다양한 모델과 하이퍼파라미터 설정에서 일관된 위상적 행동을 보였습니다.



### Improving the Language Understanding Capabilities of Large Language Models Using Reinforcement Learning (https://arxiv.org/abs/2410.11020)
- **What's New**: 본 논문에서는 대형 언어 모델(LLMs)이 자연어 이해(NLU) 작업에서 기존 BERT 모델보다 성능이 떨어진다는 점을 개선하기 위해, SFT(구조화된 미세 조정)와 PPO(인접 정책 최적화) 두 가지 접근 방식을 탐구합니다. 특히, PPO가 LLM의 NLU 성능을 어떻게 향상시킬 수 있는지 분석합니다.

- **Technical Details**: 이 연구는 LLM을 대상으로 SFT와 PPO를 사용하여 NLU 능력을 개선하는 방법을 제안합니다. SFT에서는 저순위 적응(LoRA) 계층을 활용하여 미세 조정 비용을 줄이고, PPO를 통해 토큰 생성 과정을 행동으로 간주하여 보상 기능을 틀로 삼아 모델을 최적화합니다.

- **Performance Highlights**: 실험 결과, PPO가 SFT에 비해 GLUE 벤치마크에서 평균 6.3 점 향상된 성능을 보였으며, zero-shot과 few-shot 방식을 경쟁하여 각각 38.7 및 26.1 점 우수한 성과를 달성했습니다. PPO는 BERT-large보다도 GLUE에서 2.7 점, SuperGLUE에서 9.3 점 높은 성능을 기록했습니다.



### Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback (https://arxiv.org/abs/2410.11009)
Comments:
          Accepted to appear at EMNLP 2024

- **What's New**: AI가 매개된 커뮤니케이션 시스템인 Nifty를 통해 사용자 피드백을 효과적으로 통합하여 AI 글쓰기 모델의 성능을 향상시키는 방법을 제안합니다.

- **Technical Details**: Nifty는 사용자가 스마트 추천 시스템의 제안 중 아무것도 클릭하지 않았을 때 발생하는 일회성 암묵적 부정 피드백을 활용합니다. 이 방법은 분류기 가이드를 사용하여 이 피드백을 텍스트 생성 과정에 통합합니다. 두 가지 조건 설정을 탐구하는데, 하나는 제안에 포함되지 않은 다음 의도에 따라 모델을 조정(push)하는 것이고, 다른 하나는 사용자가 제안을 거부한 것에 직접적으로 조건을 두는 것입니다.

- **Performance Highlights**: 이 시스템은 MultiWOZ 및 Schema-Guided Dialog 데이터셋을 사용하여 Rouge-L에서 최대 34%, 올바른 의도 생성에서 89% 향상을 보였으며, 인간 평가자에 의한 86%의 승률을 기록했습니다.



### Assessing the Human Likeness of AI-Generated Counterspeech (https://arxiv.org/abs/2410.11007)
- **What's New**: 이 연구는 AI가 생성한 카운터스피치(counterspeech)의 인간 유사성을 평가하여, 주목받지 못했던 평가 요소인 인간 유사성을 분석합니다. 이전 연구는 표면적 형식이나 관련성 중심이었으나, 이번 연구는 더 나아가 AI 기법이 얼마나 인간의 반응을 잘 모방하는지를 탐구합니다.

- **Technical Details**: 연구에서 여러 LLM(대규모 언어 모델) 기반 생성 전략을 구현하고 평가하여, AI와 인간이 쓰는 카운터스피치를 쉽게 구별할 수 있음을 발견했습니다. 특히, 언어적 특성, 예의(polite), 구체성(specificity)에서 차이를 확인했습니다. 실험 방법으로는 Prompting, Prompt and Select, Fine-tuning, Outcome-constrained와 같은 다양한 생성 전략을 사용했습니다.

- **Performance Highlights**: 연구 결과, AI가 생성한 카운터스피치는 인간이 작성한 것에 비해 언어적 특성에서 현저한 차이를 보이고, 더 예의 바르지만 덜 구체적이라는 것을 나타냈습니다. 이러한 차이는 분류기(classifier)와 사람 모두가 쉽게 감지할 수 있었으며, 이는 AI 기술이 완전히 인간의 카운터스피치 능력을 대체할 수 없다는 것을 보여줍니다.



### Effective Self-Mining of In-Context Examples for Unsupervised Machine Translation with LLMs (https://arxiv.org/abs/2410.11006)
- **What's New**: 이 연구에서는 기계 번역(machine translation, MT)을 위한 컨텍스트 예제(in-context examples)를 무감독으로 추출하는 새로운 접근 방식을 제안합니다. 특히 자원이 부족한 언어 쌍의 MT에 적용할 수 있으며, 이 방법은 단어 수준의 채굴(word-level mining) 방식으로 시작하여 문장 수준의 채굴로 발전합니다.

- **Technical Details**: 제안된 방법은 두 단계로 나뉘며, 첫 번째 단계는 단어 수준 번역(stage)은 LLM을 이용하여 고품질의 단어 번역을 생성하고, 이를 통해 합성된 병렬 데이터(synthetic parallel data)를 생성합니다. 두 번째 단계인 문장 수준 변환(stage)에서는 이 데이터 를 활용하여 테스트 입력의 번역을 위한 최적의 예제를 만듭니다. 무감독 채굴된 문장 쌍에서 예제를 선택하기 위한 신규 방법을 제안합니다.

- **Performance Highlights**: 이 방법은 FLORES-200 데이터셋의 288개 방향에서 두 개의 다국어 LLM을 활용하여 성능을 평가하였으며, 다른 최신 UMT 방법들에 비해 평균 7 BLEU 포인트 향상된 성능을 기록했습니다. 또한, 제안된 방식은 기존의 ICL 방법과 비슷한 수준의 성능을 보이며, 특히 자원 수준이 낮은 언어 쌍에서의 기계 번역 성능을 개선하는 데 효과적임을 입증했습니다.



### One Language, Many Gaps: Evaluating Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks (https://arxiv.org/abs/2410.11005)
- **What's New**: 이 연구는 대규모 언어 모델(LLM)이 비표준 방언인 아프리카계 미국인 방언 영어(AAVE)에 대해 공정성과 강인성을 가지고 있는지를 평가한 최초의 연구입니다. 기존의 벤치마크는 LLM의 성능을 평가할 때 방언 사용자의 경험을 무시했습니다.

- **Technical Details**: 논문에서는 ReDial이라는 새로운 벤치마크를 만들어 1.2K 이상의 표준 영어(Standardized English)와 AAVE 쌍을 포함했습니다. 이를 통해 알고리즘, 수학, 논리, 포괄적 추론 등 네 가지 주요 추론 작업에 대해 평가를 수행했습니다. GPT-4o, GPT-4, LLaMA-3.1/3 등 여러 최신 LLM을 평가하였습니다.

- **Performance Highlights**: 대부분의 LLM 남성 모든 기준 대조반의 AAVE 쿼리에 대해 두드러지게 성능이 저하되었습니다. 예를 들어, LLaMA-3.1-70B-Instruct를 제외한 모든 모델의 AAVE 통과율은 0.6 이하로 떨어졌으며, 이는 표준 영어의 베스트 통과율 0.832에 비해 상당히 낮은 수치입니다.



### Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs (https://arxiv.org/abs/2410.11001)
- **What's New**: 이번 연구에서는 LLM(대형 언어 모델)에 의해 생성된 역사적 응답을 활용하여 RAG(검색 증강 생성)를 개선하기 위한 '그래프 오브 레코드'(GoR)를 제안합니다. 기존 방법들이 유용한 정보를 포함하는 LLM 생성 응답을 무시하는 것에 대한 문제점을 해결하려고 합니다.

- **Technical Details**: GoR 방법론은 LLM이 시뮬레이션한 사용자 쿼리와 관련된 텍스트 청크 간의 엣지를 통해 기록 그래프를 구축합니다. 재귀 신경망(graph neural network)을 사용하여 노드 간의 정교한 상관관계를 학습하고, BERTScore 기반의 자가 지도 학습(objective)을 통해 최적화를 진행합니다. 이를 통해 노드 임베딩이 쿼리와의 의미적 및 논리적 상관관계를 반영할 수 있도록 합니다.

- **Performance Highlights**: GoR은 WCEP 데이터셋에서 Rouge-L에서 15%, Rouge-1에서 8%, Rouge-2에서 19% 개선된 성능을 보여줍니다. 총 12개 기준선과의 비교를 통해 GoR의 우수성이 입증되었습니다.



### Watching the Watchers: Exposing Gender Disparities in Machine Translation Quality Estimation (https://arxiv.org/abs/2410.10995)
Comments:
          Work in progress

- **What's New**: 이 논문은 기계 번역에서 품질 추정(QE) 지표의 성별 편향을 처음으로 조사하며, 이로 인해 발생하는 문제점과 해당 문제의 영향에 대해 다룬다. 성별 grammatical gender이 있는 언어로의 번역을 중점적으로 다룬다.

- **Technical Details**: 저자들은 11개의 최신 QE 지표를 사용하여 기계 번역 시스템에서 성별 편향을 평가했다. 특정 단어의 성별 변화에 따른 품질 점수를 비교하고, 문맥 정보를 사용하여 이러한 편향이 완화되는지를 분석한다.

- **Performance Highlights**: 실험 결과, 남성화된 번역이 여성화된 번역보다 높은 점수를 받으며, 성 중립 번역은 불리하게 평가되는 경향을 보였다. 문맥 기반 QE 지표는 남성 변화에 대한 오류를 줄이지만, 여성 변화에 대한 오류는 여전히 해결하지 못해 성별 불균형을 심화시키는 결과를 나타냈다.



### Performance in a dialectal profiling task of LLMs for varieties of Brazilian Portugues (https://arxiv.org/abs/2410.10991)
Comments:
          8 pages, XI Jornada de Descrição do Português

- **What's New**: 이번 논문은 LLM(대규모 언어 모델)이 브라질 포르투갈어의 다양한 방언에 대해 어떻게 편향을 나타내는지를 탐구합니다. 또한, GPT 3.5, GPT-4o, Gemini, Sabiá-2 등 네 가지 LLM을 분석하여 사회언어학적 규칙을 고려하는지를 평가했습니다.

- **Technical Details**: 연구 방법론은 세 단계로 나뉘며, LLM들이 각 브라질 주를 대표하는 텍스트를 생성하고 이러한 텍스트를 기반으로 한국어 또는 영어로 타겟 주를 식별하는 작업을 포함합니다. 연구 과정은 데이터 정리(cleaning), 표준화(standardization), 데이터 구조화(structuring)를 포함했습니다.

- **Performance Highlights**: Sabiá-2 모델은 방언 변형을 전혀 보여주지 않는 반면, GPT 3.5, GPT-4o, Gemini는 두 번째 인칭 대명사와 첫 번째 인칭 동사의 일치 등에서 방언의 차이에 대한 민감성을 보여주었습니다. 이 연구는 LLM이 방언을 처리하는 방식에 대한 중요한 통찰력을 제공합니다.



### Fine-tuning can Help Detect Pretraining Data from Large Language Models (https://arxiv.org/abs/2410.10880)
- **What's New**: 이 논문은 Fine-tuned Score Deviation (FSD)라는 새로운 방법을 제안하여 사전 훈련 데이터 탐지의 성능을 개선합니다. 이는 모델이 미리 보지 못한 데이터를 소량으로 분석함으로써 사전 훈련 집합의 구성원과 비구성원 간의 차이를 늘리는 방법입니다.

- **Technical Details**: FSD는 특정 도메인(예: Wikipedia의 이벤트 데이터, arXiv 연구 논문)에서 모델을 미세 조정(fine-tuning)한 후의 점수 편차를 측정하여 구성원과 비구성원 간의 간격을 확장합니다. 기존 방법들에 비해, FSD는 소량의 보지 않은 데이터를 통해 비구성원의 점수를 크게 감소시켜 더 명확한 구분을 가능하게 합니다.

- **Performance Highlights**: 다양한 벤치마크 데이터셋(예: WikiMIA, ArXivTection)에서 FSD를 통해 기존 방법의 AUC score가 크게 향상되었으며, 예를 들어, WikiMIA에서 Min-k%의 경우 0.62에서 0.91로 증가했습니다. ArXivTection에서는 TPR@5%FPR 점수가 0.10에서 0.81로 개선되었습니다.



### Herald: A Natural Language Annotated Lean 4 Datas (https://arxiv.org/abs/2410.10878)
- **What's New**: 이 논문은 Mathlib4 코퍼스를 자연어로 번역하기 위한 새로운 프레임워크를 소개하고, 이를 기반으로 Lean 4 분석기를 활용한 이중 증강 전략을 적용하였습니다. 새로운 데이터셋인 Herald를 생성하고, 이를 통해 자연어-형식언어(NL-FL) 번역 모델의 성능을 향상시키는 방법을 제시합니다.

- **Technical Details**: 이 연구에서 제안하는 Herald 데이터셋은 Mathlib4에서 580k의 유효한 문장과 44k의 NL-FL 정리 쌍을 포함하고 있으며, 자연어 추론을 형식언어로 변환하는 과정에서 LLM(large language models)의 성능을 개선하는 구조적 정보를 제공합니다. 이 데이터셋은 '증분적 비형식화(informalization)'와 '형식화(formalization)' 과정을 통해 생성됩니다.

- **Performance Highlights**: Herald 번역기는 miniF2F-test에서 93.2% 정확도를 달성했으며, 내부 대학 교재 데이터세트에서 22.5%의 정확도로, 이전의 모델인 InternLM2-Math-Plus-7B와 TheoremLlama에 비해 현저히 높은 성능을 보였습니다. 또한 Stack 프로젝트의 섹션을 성공적으로 번역하여 대학 수준의 수학 문헌의 자동 형식화에서 중요한 진전을 이루었습니다.



### Improving Data Efficiency via Curating LLM-Driven Rating Systems (https://arxiv.org/abs/2410.10877)
- **What's New**: 이번 연구에서는 각종 대형 언어 모델(LLM)의 데이터 선택을 위한 새로운 방법인 DS2(Diversity-aware Score curation method)를 소개합니다. DS2는 LLM 기반의 점수에서 발생하는 오류 패턴을 분석하여 보다 정확하고 다양한 데이터를 선택할 수 있도록 합니다.

- **Technical Details**: DS2는 점수 전이 행렬(score transition matrix)을 활용하여 기존 LLM에서 생성된 점수의 오류를 수정하고, 데이터 샘플의 다양성을 보장합니다. 이 접근법을 통해 DS2가 선택한 3.3%의 데이터 서브셋이 300k 샘플의 전체 데이터보다 다양한 기계 정렬 벤치마크에서 더 우수한 성능을 보임을 입증했습니다.

- **Performance Highlights**: DS2를 통해 선택된 데이터에 대해 파인튜닝한 모델은 LIMA라는 인간 커리가 된 데이터셋보다도 뛰어난 성능을 나타냈습니다. 이는 기존의 데이터 스케일링 가정을 도전하며, 양질의 데이터 선택의 중요성을 강조합니다.



### FreqMark: Frequency-Based Watermark for Sentence-Level Detection of LLM-Generated Tex (https://arxiv.org/abs/2410.10876)
- **What's New**: 이 논문에서는 LLM(대형 언어 모델) 생성 텍스트에 대해 탐지 가능한 주파수 기반 워터마크를 삽입하는 FreqMark라는 새로운 워터마킹 기법을 제안합니다. 이는 Token 샘플링 과정에서 주기적인 신호를 사용하여 Token을 선택함으로써 이뤄집니다.

- **Technical Details**: FreqMark는 워터마크를 생성하기 위해 Short-Time Fourier Transform (STFT) 분석을 활용합니다. 이 방법은 LLM이 생성한 콘텐츠를 정확하게 식별할 수 있게 해주며, 사람의 저작물과 LLM 생성물이 혼합된 텍스트 시나리오에서도 효과적입니다. 주기적인 신호는 특정 패턴에 따라 다음 Token을 선택하게 하여 워터마크를 삽입합니다.

- **Performance Highlights**: 실험 결과 FreqMark는 다양한 공격 시나리오에 대해 강력한 탐지 능력을 발휘하며, AUC(Area Under the Curve) 값이 최대 0.98에 도달했습니다. 이는 기존 탐지 방법보다 월등한 성능을 나타냅니다.



### Optimizing Transformer based on high-performance optimizer for predicting employment sentiment in American social media conten (https://arxiv.org/abs/2410.10874)
Comments:
          5 pages, 5 figures

- **What's New**: 본 연구는 군집 지능 최적화 알고리즘(optimization algorithm)을 기반으로 Transformer 모델을 개선하였으며, 미국 소셜 미디어에서의 고용 관련 텍스트 콘텐츠의 감정을 예측하는 것을 목표로 합니다.

- **Technical Details**: 텍스트 전처리(text preprocessing), 특징 추출(feature extraction) 및 벡터화(vectorization)를 통해 텍스트 데이터를 수치 데이터로 성공적으로 변환하였으며, 이를 모델 학습에 사용하였습니다. 실험 결과, 학습 과정 동안 모델의 정확도가 49.27%에서 82.83%로 증가하고, 손실 값(loss value)은 0.67에서 0.35로 감소하였습니다.

- **Performance Highlights**: 혼동 행렬(confusion matrix) 분석에 따르면, 학습 세트에서의 정확도는 86.15%이며, 테스트 세트에서도 82.91%의 좋은 성능을 보였습니다. 학습 세트와 테스트 세트 간의 정확도 차이는 3.24%에 불과하여 모델의 일반화 능력이 강함을 나타냅니다. 또한 Kappa 계수(Kappa coefficient)는 0.66, F-measure는 0.80으로, 소셜 미디어 감성 분석에서 모델의 효과성을 추가적으로 검증하였습니다.



### AuditWen:An Open-Source Large Language Model for Aud (https://arxiv.org/abs/2410.10873)
Comments:
          18 pages,1 figures

- **What's New**: 이번 연구에서는 Qwen을 기반으로 한 첫 번째 오픈소스 감사 대화형 대형 언어 모델 (LLM)인 AuditWen을 소개하며, 15개의 감사 작업과 28,000개의 지침 데이터를 통해 감사 분야에 특화된 모델을 구축했습니다.

- **Technical Details**: AuditWen은 3단계로 구성된 감사 작업을 위한 데이터셋을 활용하여 Qwen을 세부 조정한 모델입니다. 연구는 세 가지 유형의 필요(핵심 요구사항, 규제 요구사항, 파생 요구사항)로 감사에서의 LLM 적용 시나리오를 추출하였으며, 이를 바탕으로 3,000개의 지침을 포함한 평가 기준을 개발했습니다.

- **Performance Highlights**: 실험 결과 AuditWen은 질문 이해 및 답변 생성에서 기존의 LLM들과 비교하여 우수한 성능을 보였으며, 특히 감사 이슈 요약 및 법률 추천 작업에서 효과적입니다. AuditWen은 실제 감사 업무에 즉시 적용할 수 있는 값진 도구로 입증되었습니다.



### ToolBridge: An Open-Source Dataset to Equip LLMs with External Tool Capabilities (https://arxiv.org/abs/2410.10872)
Comments:
          technical report

- **What's New**: 이 논문은 ToolBridge라는 새로운 파이프라인을 통해 LLMs(대규모 언어 모델)가 외부 도구를 효과적으로 사용하는 방법을 학습할 수 있도록 지원하는 고품질의 공개 데이터셋을 만드는 과정을 설명합니다. 특히, 외부 도구 API 삽입을 위한 데이터 항목을 식별하는 전략을 제안하고, 이를 통해 LLM의 예측 정확도를 향상시키는 데 중점을 두고 있습니다.

- **Technical Details**: ToolBridge는 공개된 오픈 액세스 데이터셋을 원시 데이터셋 풀로 사용하여, 효과적인 LLM 교육을 위한 데이터 항목 선별, 변환, 필터링의 세 단계로 구성된 파이프라인을 제안합니다. 이 과정에서 LLM의 감독된 세밀 조정(Supervised Fine-Tuning, SFT)을 통해 정확도 향상을 위해 외부 도구를 적절한 맥락에서 호출할 수 있습니다.

- **Performance Highlights**: ToolBridge를 통해 훈련된 LLM은 여러 표준 벤치마크와 맞춤형 평가 데이터셋에서 일관된 성능 향상을 보여 주었습니다. 이 연구는 외부 도구와의 통합에서 LLMs의 교육 데이터를 공개하는 최초의 연구로, 연구자들이 다양한 분야에서 LLM의 외부 도구 사용하는 능력을 발전시킬 수 있을 것으로 기대됩니다.



### Applying Refusal-Vector Ablation to Llama 3.1 70B Agents (https://arxiv.org/abs/2410.10871)
- **What's New**: 최근 Llama 3.1 Instruct와 같은 언어 모델들이 자율적인 에이전트 행동을 할 수 있는 능력이 향상되었다. 본 연구에서는 Llama 3.1 70B 모델에 대해 거부 벡터 제거(refusal-vector ablation)를 적용하고 간단한 에이전트 구조를 구현하여 제한 없는 에이전트를 만들었다. 이 모델들이 위험한 작업을 성공적으로 수행할 수 있다는 점에서 현재의 안전 메커니즘에 큰 취약점이 존재함을 강조한다.

- **Technical Details**: 이 연구는 모델의 거부 행동이 잔여 스트림(residual stream)의 단일 방향에 의해 주로 매개되며, 이 방향을 제거하면 모델이 거부하지 않도록 생성할 수 있음을 보여준다. Llama 3.1 모델에 이 기술을 적용한 결과, 모델이 수정 없이도 많은 비윤리적 작업을 수행할 수 있음이 발견되었다. 또한 'Safe Agent Benchmark'라는 새로운 평가 기준을 도입하여 에이전트의 안전성과 능력을 테스트하는 방법론을 제시한다.

- **Performance Highlights**: Llama 3.1 70B 모델은 28개의 위험한 작업 중 18개를 수행할 의향이 있었으나, 대화 모드에서는 모든 28개 작업에 대해 어떻게 수행할지 조언을 거부했다. 이는 모델의 점점 더 향상된 능력이 악용될 위험을 증가시키며, 언어 모델 에이전트의 향상된 안전 프레임워크 필요성을 강조한다.



### PortLLM: Personalizing Evolving Large Language Models with Training-Free and Portable Model Patches (https://arxiv.org/abs/2410.10870)
- **What's New**: 이 연구에서는 PortLLM이라는 새로운 프레임워크를 소개합니다. 이 프레임워크는 특별한 훈련 없이 도메인 특정 지식을 지속적으로 전이할 수 있도록 설계되었습니다. 사용자가 이전의 모델에서 훈련된 지식을 기반으로 새로운 모델에 손쉽게 적용할 수 있는 기능을 제공합니다.

- **Technical Details**: PortLLM은 LoRA에서 파생된 모델 패치를 활용하여 사전 훈련된 LLM의 다양한 버전 간 도메인 지식을 전이합니다. 이 과정은 훈련 없이 실행되며, 이는 유지 관리 비용을 대폭 낮추고, GPU 메모리 사용량을 최대 12.2배까지 줄일 수 있습니다. 실험에서는 Mistral-7B, Llama2-7B, Llama3.1-8B, Gemma2-9B 등 다양한 모델 아키텍처에서의 효과를 검증하였습니다.

- **Performance Highlights**: PortLLM은 LoRA로 조정한 모델과 유사한 성능을 보이며, 효율적인 자원 사용을 통해 더 짧은 시간 안에 높은 성능을 달성합니다. 또한, 실험 결과는 다양한 타입의 질문 응답 및 추론 과제를 포함한 7개의 과제에서 긍정적인 결과를 보여주었습니다.



### Application of NotebookLM, a Large Language Model with Retrieval-Augmented Generation, for Lung Cancer Staging (https://arxiv.org/abs/2410.10869)
Comments:
          9 pages, 5 figures, 1 table, 3 ancillary files

- **What's New**: 최근 방사선학에서 대규모 언어 모델(LLMs), 특히 NotebookLM과 같은 RAG(검색 증강 생성) 기술이 주목받고 있습니다. 기존 LLMs의 신뢰성 문제를 해결하기 위해, RAG를 통해 증가된 신뢰할 수 있는 외부 지식(REK)을 활용한 연구가 진행되었습니다.

- **Technical Details**: 본 연구에서는 일본의 최신 폐암 병기 분류 지침을 REK로 제공하여, NotebookLM에 100개의 허구의 폐암 사례를 CT 소견을 기반으로 병기 분류하도록 하였습니다. 이 과정에서 gold-standard LLM인 GPT-4 Omni(GPT-4o)와 비교하였으며, 두 모델 모두 REK 활용 유무에 따른 성능을 평가했습니다.

- **Performance Highlights**: NotebookLM은 폐암 병기 분류 실험에서 86%의 진단 정확도를 기록하여, REK를 사용한 GPT-4o의 39% 및 REK 없이의 25%과 비교하여 월등한 성과를 보였습니다. 또한, NotebookLM은 REK 내에서의 참조 위치 검색에서 95%의 정확도를 보여 주목받고 있습니다.



### Mitigating the Impact of Reference Quality on Evaluation of Summarization Systems with Reference-Free Metrics (https://arxiv.org/abs/2410.10867)
- **What's New**: 이 논문에서는 인간의 평가와 높은 상관관계를 가지면서 계산 비용이 매우 낮은 새로운 reference-free (참조 없는) 메트릭을 소개합니다.

- **Technical Details**: 제안된 메트릭은 기존의 reference-based (참조 기반) 메트릭과 함께 사용될 수 있으며, 저품질 참조 설정에서 메트릭의 견고성을 향상시킵니다. 특히 긴 문서의 요약에 대한 relevance (관련성)을 잘 나타냅니다.

- **Performance Highlights**: 이 메트릭은 인간의 평가와 높은 상관관계를 가지며, 저비용으로 계산 가능함을 보여줍니다.



### CodeUnlearn: Amortized Zero-Shot Machine Unlearning in Language Models Using Discrete Concep (https://arxiv.org/abs/2410.10866)
- **What's New**: 본 논문은 대규모 언어 모델(LLMs)의 민감한 정보를 삭제하는 새로운 방법인 제로샷 언러닝(zero-shot unlearning) 접근법을 제안합니다. 기존의 방법은 특화된 데이터 구조나 전체 재훈련이 필요한 반면, 본 연구는 정보 제어 및 흐름 조절을 위해 Sparse Autoencoders(SAEs)와 코드북을 활용합니다.

- **Technical Details**: 코드북 기능을 사용하여 언러닝을 조직화하는 본 접근법은 활성화 벡터를 코드북에 따라 변환하여 특정 주제와 연관된 정보를 효율적으로 식별하고 삭제하도록 합니다. 이 과정에서 벡터 양자화(Vector Quantization, VQ)를 이용해 잠재 공간을 구조화하고, 이산 표현(discrete representations)을 통해 정보를 선택적으로 제거하는 방식을 사용합니다.

- **Performance Highlights**: 본 연구에서는 제안한 방법이 기존의 기계 언러닝 기술에서 한 걸음 나아가 복잡한 언어 작업까지 적용되는 유용성을 입증하였습니다. 또한 선택적이고 효율적인 정보 삭제를 통해 모델의 성능을 유지하면서 민감한 정보를 안전하게 제거할 수 있음을 보여주었습니다.



### Generating Synthetic Datasets for Few-shot Prompt Tuning (https://arxiv.org/abs/2410.10865)
- **What's New**: 이번 논문에서는 few-shot learning 환경에서의 prompt tuning의 한계를 극복하기 위해 LLMs(대형 언어 모델)를 활용하여 특정 작업에 맞는 레이블이 있는 데이터를 합성하는 방법을 제안합니다. 특히, Distribution-Aligned Weighted generator tuning (DawGen)이라는 새로운 방법론을 소개하며, gradient surgery를 이용해 서로 다른 데이터 소스 간의 상충하는 그래디언트를 제거하는 방식을 채택하였습니다.

- **Technical Details**: 제안된 방법은 세 단계로 나뉘며, 첫째로, 제한된 수의 실제 샘플을 통해 소프트 프롬프트를 학습합니다. 둘째로, 적응된 생성기를 통해 합성 훈련 세트를 생성합니다. 셋째로, 합성 데이터와 실제 데이터를 결합하여 소프트 프롬프트를 훈련하여 판별 LLM에 적용합니다.

- **Performance Highlights**: 7개의 문장 쌍 분류 데이터셋에서 실험한 결과, 제안된 방법이 few-shot learning 설정에서 prompt tuning의 효과를 크게 향상시킴을 보여주었습니다. 특히, 102K 파라미터로 구성된 PT가 770M 파라미터의 FT보다 뛰어난 성능을 보였으며, QQP, MRPC, SICK 데이터셋에서 대규모 실제 데이터셋을 사용한 전이 학습과 비교하여 유사한 성능을 달성했습니다.



### Fill In The Gaps: Model Calibration and Generalization with Synthetic Data (https://arxiv.org/abs/2410.10864)
Comments:
          Accepted to EMNLP 2024 Main Conference (Long paper)

- **What's New**: 본 연구에서는 합성 데이터(synthetic data)를 활용한 새로운 모델 캘리브레이션(calibration) 방법을 제안합니다. 기존의 캘리브레이션 방법이 모델의 정확도(accuracy)를 저하시킬 수 있는 문제를 해결하고, Expected Calibration Error (ECE)를 줄이며, 모델의 정확도를 유지하는 전략을 사용했습니다.

- **Technical Details**: 모델 캘리브레이션을 위한 방법론은 Probably Approximately Correct (PAC) 학습 프레임워크를 기반으로 하며, 합성 데이터를 생성하는 데 오픈 소스의 대형 언어 모델(Large Language Model)인 Llama 2를 활용합니다. 이 방법은 자연어 처리(NLP) 작업에서 모델의 성능을 개선하기 위해 고안되었습니다.

- **Performance Highlights**: 모델을 네 가지 자연어 처리 작업에 대해 테스트한 결과, 평균 34%의 정확도 향상과 33%의 ECE 감소를 관찰했습니다. 이는 합성 데이터가 모델의 예측 불확실성(calibration)을 줄이는 데 효과적임을 보여줍니다.



### What makes your model a low-empathy or warmth person: Exploring the Origins of Personality in LLMs (https://arxiv.org/abs/2410.10863)
Comments:
          under review

- **What's New**: 본 연구는 대형 언어 모델(LLMs)이 어떻게 장기적인 배경 요인과 단기적인 압력을 통해 인격 특성을 표현하는지를 탐구합니다. 특히, 사회 결정론 이론을 바탕으로 LLM의 성격 형성 과정에 대한 심층 분석을 제공합니다.

- **Technical Details**: 저자들은 Sparse Autoencoder(SAE) 및 representation-based 방법론을 활용하여 LLM의 장기 및 단기 인격 특성을 추출하고 분석합니다. 이를 통해 각각의 배경 요인이 모델의 인격과 안전성에 미치는 영향을 평가하며, Big Five Inventory(BFI) 및 Short Dark Triad(SD-3) 같은 인물 테스트를 통해 LLM의 인격을 평가합니다.

- **Performance Highlights**: 이 연구는 LLM의 인격 조정을 위한 새로운 기법을 제시하고, 모델의 행동을 세밀하게 수정하는 방법을 제공합니다. 또한, 배경 요인이 LLM의 안전성 평가에 미치는 영향을 분석하고, Personality-driven 요인이 LLM의 어두운 특성에 기여할 수 있는 가능성을 탐색합니다.



### Superficial Safety Alignment Hypothesis (https://arxiv.org/abs/2410.10862)
- **What's New**: 이 논문에서는 안전 제어(safety alignment)와 일반 제어(alignment) 사이의 간극을 해소하기 위해 'Superficial Safety Alignment Hypothesis (SSAH)'를 제안합니다. 이 가설은 안전 제어가 모델이 올바른 추론 방향을 선택하도록 가르쳐야 한다고 주장합니다.

- **Technical Details**: 이 연구에서는 안전 제어가 효과적으로 이루어지기 위해서는 특정 안전-critical component를 동결(freeze)하고 여분의 유닛(redundant units)을 재사용하는 것이 필요하다고 설명합니다. 특히 Exclusive Safety Unit (ESU), Exclusive Utility Unit (EUU), Complex Unit (CU), Redundant Unit (RU) 등 4가지 주목할 만한 유닛을 식별했습니다.

- **Performance Highlights**: 모델의 fine-tuning 중 7.5%의 안전-critical component를 동결하는 방식으로 모델의 안전 특성을 유지하면서 새로운 작업에 적응할 수 있음을 발견했습니다. 또한, 사전 훈련된 모델에서 20%의 여분의 유닛을 'alignment budget'으로 활용하여 안전 제어 목표를 효과적으로 달성할 수 있다는 사실을 보여주었습니다.



### Translation Canvas: An Explainable Interface to Pinpoint and Analyze Translation Systems (https://arxiv.org/abs/2410.10861)
Comments:
          7 pages, 3 figures

- **What's New**: Translation Canvas는 기계 번역 연구자들이 시스템 성능을 분석하고 이해할 수 있도록 설계된 설명 가능한 인터페이스로, COMET 및 SacreBLEU와 같은 기존 도구들의 한계를 극복합니다. 이 도구는 흔한 오류와 그 심각성을 식별하고 다양한 평가 메트릭을 바탕으로 시스템 간의 관계를 분석합니다.

- **Technical Details**: Translation Canvas는 Python Flask를 사용하여 구현되었으며, DuckDB 연결을 통해 front-end와 back-end의 요구를 충족합니다. 사용자는 수동 입력과 파일 입력을 통해 평가 인스턴스를 제출할 수 있으며, 여러 가지 평가 메트릭(예: InstructScore, BLEU, COMET)을 지원합니다. 시스템은 사용자가 지정한 평가 메트릭을 실행하여 오류의 세부 정보를 표시합니다.

- **Performance Highlights**: 인간 평가 결과, Translation Canvas는 즐거움(enjoyability) 및 이해 가능성(understandability) 기준에서 COMET 및 SacreBLEU보다 우수한 성능을 보였습니다. 또한, 사용자는 복잡한 검색 쿼리를 통해 세부적인 분석을 수행할 수 있으며, 사용자 경험이 향상된 것으로 나타났습니다.



### A Recipe For Building a Compliant Real Estate Chatbo (https://arxiv.org/abs/2410.10860)
- **What's New**: 최근 대규모 언어 모델 (large language models, LLMs)을 사람의 선호에 맞게 조정하기 위한 노력이 증가하고 있습니다. 이번 연구는 부동산 분야에 특화된 챗봇 개발에 중점을 두고 있으며, 차별적 관행인 스티어링 (steering)과 레드라이닝 (redlining)을 지속하지 않도록 준수를 강조합니다. 우리는 일반 지침 준수 데이터 세트를 생성하고, 안전 데이터를 포함하여 Лlama-3-8B-instruct 모델을 미세 조정하면서 GPT-4o와 같은 대형 닫힌 소스 모델과 경쟁할 수 있는 성능을 입증했습니다.

- **Technical Details**: 우리는 일반적인 지침 작업과 부동산 분야의 법적, 윤리적 준수 시나리오를 결합한 합성 데이터 세트를 생성했습니다. 이를 활용해, 법적 및 윤리적 기준에 철저히 따라 유용한 부동산 정보를 제공하고, llama3-70b-instruct 보다 높은 성능을 발휘하면서도 보다 안전하고 준수된 응답을 생성하는 모델을 개발했습니다. 또한, 안전성과 유용성을 평가하기 위한 네 가지 모델 기반 지표와 두 개의 모델 기반 심사자를 도입했습니다.

- **Performance Highlights**: 최종 결과들은 법적 규정 준수에 초점을 맞추어 데이터 및 튜닝을 진행함으로써 부동산 애플리케이션에서 LLM의 안전성과 유용성을 현저히 향상시킬 수 있음을 보여주었습니다. 제안된 모델은 부동산 작업에서 비례적으로 86% 더 선호되며, 우리의 안전 및 준수 기준 벤치마크에서 성능이 크게 향상되었습니다.



### FAME: Towards Factual Multi-Task Model Editing (https://arxiv.org/abs/2410.10859)
Comments:
          9 pages, 3 figures

- **What's New**: 이번 연구의 핵심은 모델 편집(model editing)의 실용성을 강조하며, 실제 응용에서의 효과성을 담보하는 새로운 데이터셋 FAME과 모델 편집 방법 SKEME를 제안한다는 점입니다.

- **Technical Details**: FAME은 128,000개의 사실 기반 데이터 항목으로 구성되며, 다양한 단일 및 다단계 질문으로 이루어진 과제를 포함하여 표준화된 모델 편집 기준인 Practicality를 도입한다. SKEME는 신선한 캐싱 메커니즘(caching mechanism)을 활용하여 모델의 지식을 실시간으로 업데이트할 수 있도록 설계되었다.

- **Performance Highlights**: 실험 결과, SKEME는 모든 실험 조건에서 다른 방법들과 비교하여 뛰어난 성능을 발휘하였으며, 실질적인 상황에 잘 부합하는 효과적인 모델 편집 방법임을 증명하였다.



### Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths (https://arxiv.org/abs/2410.10858)
Comments:
          EMNLP 2024 camera ready version

- **What's New**: 이번 연구에서는 Reasoning Paths Optimization (RPO)라는 새로운 훈련 프레임워크를 소개하여 언어 모델의 다음 단계 추론 능력을 개선하는 방법을 제안합니다.

- **Technical Details**: RPO는 다양한 경로에서 추론을 학습하고 탐색할 수 있도록 설계되어, 각 추론 단계에서 유리한 경로를 장려하고 불리한 경로를 처벌하여 모델의 문제 해결 능력을 향상시킵니다. 이 방법은 대규모 인간 주석을 받거나 폐쇄형 모델의 출력을 의존하지 않기 때문에 확장 가능하고 데이터 효율적입니다.

- **Performance Highlights**: 실험 결과, RPO는 대규모 언어 모델의 추론 성능을 크게 개선하여, GSM8K에서 3.1%, MMLU (STEM)에서 4.3%의 성능 향상을 보여주었습니다.



### Mirror-Consistency: Harnessing Inconsistency in Majority Voting (https://arxiv.org/abs/2410.10857)
Comments:
          EMNLP 2024 Short Findings

- **What's New**: 이번 논문에서는 기존의 Self-Consistency 방식의 한계를 극복하기 위해 Mirror-Consistency라는 새로운 방법론을 제안하였습니다. 이 방법은 다수결의 원칙에 의존하면서도 의견의 일관성을 분석하고, 소수의 응답에서 나타나는 불일치를 학습하여 LLM의 추론 능력을 개선하는 데 초점을 맞춥니다.

- **Technical Details**: Mirror-Consistency는 LLM이 재표집된 응답의 불일치를 분석하도록 하여, 다수결의 결과와의 차이를 반영하여 피드백을 제공하는 방식으로 접근합니다. 이 과정은 Reflection on Inconsistency와 Conditional Resampling 단계로 구성됩니다. 또한, 응답 간의 일관성을 기반으로 LLM의 신뢰도를 조정하는 방법으로도 활용됩니다.

- **Performance Highlights**: Mirror-Consistency는 Self-Consistency에 비해 추론의 정확성과 신뢰도 조정 모두에서 향상된 성능을 보였습니다. 실험 결과, 네 가지 추론 데이터셋과 네 가지 LLM를 사용하여 Mirror-Consistency의 효과성을 검증하였으며, 불일치 분석이 성능 향상에 기여함을 보여주었습니다.



### CogDevelop2K: Reversed Cognitive Development in Multimodal Large Language Models (https://arxiv.org/abs/2410.10855)
- **What's New**: 이 논문은 Multi-modal Large Language Models (MLLMs)의 인지 능력을 평가하는 새로운 벤치마크인 CogDevelop2K를 제안합니다. 이 벤치마크는 인간의 인지 발달 과정을 구조화해 12개의 하위 개념을 포괄하며, MLLMs의 진정한 이해 능력과 작업 수행 능력을 탐구하는 데 중점을 둡니다.

- **Technical Details**: CogDevelop2K는 2519개의 질문과 2517개의 이미지, 455개의 비디오로 구성되어 있으며, MLLMs의 코어 인지 능력을 4단계의 인지 발달 무대로 평가합니다. 이 논문은 Jean Piaget의 인지 발달 이론을 기반으로 하여 MLLMs의 역동적인 인지 발달 추세를 조사하며, 코어 인지 과업 수행이 MLLMs의 진정한 지식, 추론 및 지각 능력을 이해하는 데 중요한 인사이트를 제공함을 강조합니다.

- **Performance Highlights**: 46개 MLLM 모델을 평가한 결과, 몇 가지 놀라운 경향이 확인되었습니다. MLLM 모델은 인간의 인지 발달 경로와 반대되는 경향을 보였으며, 예를 들어 GPT 시리즈는 형식적 조작 단계에서 더 나은 성능을 보였으나 구체적 조작 단계에서는 저조한 성능을 나타냈습니다. 이 연구는 MLLM의 성능 향상 방법인 prompting 기술이 모델 성능을 8.1% 향상시킬 수 있음을 시사합니다.



### Plausibly Problematic Questions in Multiple-Choice Benchmarks for Commonsense Reasoning (https://arxiv.org/abs/2410.10854)
Comments:
          EMNLP 2024 Camera Ready

- **What's New**: 이 논문은 일상적인 상황에 대한 상식 추론을 위한 여러 선택 질문(MCQ)에서의 올바른 답변 선정 기준을 새롭게 제시합니다. 250개의 MCQ 항목을 샘플링하고, 5,000개의 독립적인 타당성 판단을 수집함으로써, 과거의 기준에서는 부합하지 않는 20% 이상의 문항을 발견하였습니다.

- **Technical Details**: 저자는 Social IQa와 CommonsenseQA라는 두 개의 주요 MCQ 벤치마크를 분석했습니다. 각 MCQ에 대해 5점 리커트 척도를 사용하여 개별 답변의 타당성을 평가하고, 인간 주석자의 다수결에 의해 선정된 원래의 답변과 비교했습니다.

- **Performance Highlights**: 대규모 언어 모델(LLM) 실험 결과, 저성능과 높은 변동성을 보여주며, 이 연구의 타당성 기준이 상식 평가를 위한 더 신뢰할 수 있는 벤치마크 항목 식별에 도움을 줄 수 있음을 나타냈습니다.



### Mitigating Hallucinations Using Ensemble of Knowledge Graph and Vector Store in Large Language Models to Enhance Mental Health Suppor (https://arxiv.org/abs/2410.10853)
- **What's New**: 이 연구는 대형 언어 모델(LLMs)에서 발생하는 환각(hallucination)의 효과와 이를 줄이기 위한 전략을 탐구합니다. 특히 정신 건강(intervention) 분야에서 LLM의 신뢰성(reliability) 및 안정성(security)을 높이는 데 중점을 두고 있습니다.

- **Technical Details**: 이 연구에서는 Google Gemma, Mistral 및 Zypher와 같은 오픈소스 LLM을 활용하여 정신 건강 관련 질문에 대한 답변을 생성하였습니다. 제안된 해결책은 벡터 스토어(vectors store) 검색과 지식 그래프(knowledge graph) 검색의 장점을 결합하여 LLM의 환각을 줄이는 방법을 제시합니다. Ensemble RAG 모델을 통해 정보 검색을 개선하고, 쿼리 프로세서, 벡터 스토어 리트리버(vector store retriever), 지식 그래프 리트리버(knowledge graph retriever), 융합 모듈(fusion module)로 구성된 시스템을 설계하였습니다.

- **Performance Highlights**: 이 연구는 LLM이 제공하는 정보의 품질과 관련성을 높여 환각을 줄이는 것을 목표로 하고 있으며, 정신 건강 지원을 위한 더 나은 프레임워크를 구축하는 데 기여하고자 합니다. 특히, LLM의 다중 작업 지식을 향상시키고, 사실적으로 정확한 정보를 제공하여 정신 건강 지원을 더욱 효율적으로 만들어 갈 것입니다.



### SafeLLM: Domain-Specific Safety Monitoring for Large Language Models: A Case Study of Offshore Wind Maintenanc (https://arxiv.org/abs/2410.10852)
- **What's New**: 이번 연구는 Offshore Wind (OSW) 산업의 Operations & Maintenance (O&M) 비용을 절감하기 위해 Large Language Models (LLMs)를 활용한 혁신적인 접근 방식을 제안합니다. 특히, 통계 기법을 통해 문장 간 거리를 계산하여 hallucination과 안전하지 않은 출력을 감지하고 필터링하는 대화형 에이전트를 소개합니다.

- **Technical Details**: 제안된 방법론은 SafeLLM이라고 하며, ChatGPT-4 생성 테스트 문장에 적용된 초기 결과를 바탕으로 합니다. 이 연구는 SCADA 시스템에서 가져온 경고 데이터를 분석하고, 입력과 출력의 안전성을 확보하기 위한 방법을 논의합니다.

- **Performance Highlights**: 첫 번째 결과는 OSW 경고 시퀀스를 개선된 해석 가능성 및 안전한 수리 작업 제안과 함께 보여주며, 재훈련을 통한 성능 향상의 가능성에 대해 논의합니다.



### On the Reliability of Large Language Models to Misinformed and Demographically-Informed Prompts (https://arxiv.org/abs/2410.10850)
Comments:
          Study conducted between August and December 2023. Submitted for archival purposes only

- **What's New**: 본 연구는 Large Language Model (LLM) 기반 챗봇들이 잘못된 프롬프트와 질문을 어떻게 처리하는지 조사하였다. 기후 변화 및 정신 건강 분야에서 이 챗봇들의 정보 진실성 판단 능력, 사실 준수, 편향 존재 여부를 평가하였다.

- **Technical Details**: LLM 챗봇의 성능은 True/False 질문을 통한 정량적 분석으로 측정되었으며, 질적 통찰은 도메인 전문가와의 협력을 통해 수집되었다. 세 개의 LLM 기반 챗봇(ChatGPT, Bing Chat, Google BARD)을 분석하여 기후 변화와 정신 건강 관련 질문에 대한 응답을 평가하였다.

- **Performance Highlights**: 챗봇들은 True/False 질문에 대한 올바른 답변을 제공할 수 있었지만, 전문가 의견에 따르면 개인정보 보호, 윤리적 문제 및 전문 서비스로 사용자 안내의 필요성이 여전히 우려되었다. 챗봇들은 민감한 분야에서 신중하게 구현되어야 한다는 결론에 도달했다.



### Crafting Narrative Closures: Zero-Shot Learning with SSM Mamba for Short Story Ending Generation (https://arxiv.org/abs/2410.10848)
Comments:
          9 pages

- **What's New**: 이 논문은 주어진 프롬프트에 기반하여 이야기를 완성하는 도구를 개발하고, 이를 통해 작가의 창의적 장애(Writer's Block)를 극복하는 혁신적인 솔루션을 제공합니다. 또한 사용자가 짧은 이야기 프롬프트를 입력할 경우, AI의 창의력으로 이야기를 한 문장으로 요약해주는 기능을 제공합니다.

- **Technical Details**: 본 연구에서는 고급 텍스트 생성 모델을 개발하여 주어진 입력에 대해 읽을 수 있는 적절한 결론을 도출하는 방법을 제안합니다. GPT-3.5 모델과 새로운 SSM-Mamba 모델을 포함한 총 네 가지 모델을 사용하여 구현하였고, fine-tuning(모델의 세부 조정)에는 LoRa, PEFT, SFTTrainer 등의 기술이 활용되었습니다.

- **Performance Highlights**: SSM-Mamba 모델이 박사 과정에서의 성과를 기록하였으며, BERT score, METEOR, BLEU, ROUGE, Perplexity 등의 다양한 지표에서 우수한 성능을 나타냈습니다. 이 도구는 Open Source로 제공되어, 창작 및 개인 이야기 확장을 위한 최신 AI 기술에 대한 접근성을 높였습니다.



### A Hitchhiker's Guide to Scaling Law Estimation (https://arxiv.org/abs/2410.11840)
- **What's New**: 이 논문에서는 485개의 기존 사전 훈련(pretrained) 모델의 손실(loss)과 다운스트림 평가(downstream evaluations)를 포함한 대규모 데이터셋을 수집하여 비용 효과적인 scaling laws 추정 방법을 제시합니다.

- **Technical Details**: Scaling laws는 매개변수(parameter) 수가 적거나 훈련 데이터셋 크기가 작은 모델에서 추정한 손실을 통해 타겟 모델의 손실을 예측하는 방법입니다. 이 방법은 모델이 같은 아키텍처를 공유하고 매개변수 수와 훈련 데이터 크기만 다른 경우에 주로 사용됩니다. 본 연구에서는 중간 체크포인트에서의 손실을 활용하여 더 나은 scaling laws 추정을 가능하게 했습니다.

- **Performance Highlights**: 모델의 크기가 같거나 유사할 때 손실 예측의 정확도가 가장 높았고, 몇 번의 훈련 세트를 가진 작은 모델을 훈련시키는 것이 하나의 큰 모델을 훈련시키는 것보다 유용한 경우가 많다고 밝혔습니다.



### Latent Action Pretraining from Videos (https://arxiv.org/abs/2410.11758)
Comments:
          Website: this https URL

- **What's New**: 이번 연구에서는 웹 스케일 비디오를 활용하여 로봇 액션 라벨 없이 비지도 방식으로 Vision-Language-Action 모델(VLA)을 사전 훈련하는 Latent Action Pretraining for General Action models (LAPA) 방법을 소개합니다. 이 방법은 기존 모델이 인간 텔레오퍼레이터에 의존하는 문제를 해결합니다.

- **Technical Details**: LAPA는 두 가지 사전 훈련 단계와 로봇 액션으로의 매핑을 배우기 위한 정밀 조정 단계로 구성됩니다. 첫 번째 단계에서 VQ-VAE 기반 목표를 사용하여 원시 이미지 프레임 간의 양자화된 잠재 액션을 학습하고, 두 번째 단계에서는 비디오 관찰 및 작업 설명을 기반으로 잠재 액션을 예측하는 Vision-Language 모델을 정교하게 훈련합니다.

- **Performance Highlights**: 실험 결과, LAPA의 성능은 기존의 행동 없는 비디오에서 조작 정책을 훈련하는 방법에 비해 유의미하게 향상되었으며, 특히 실세계 조작 작업에서 현재의 최첨단 VLA 모델보다 6.22% 더 뛰어난 성과를 보여주었습니다. 또한 30배 이상의 사전 훈련 효율성을 달성하였습니다.



### Are UFOs Driving Innovation? The Illusion of Causality in Large Language Models (https://arxiv.org/abs/2410.11684)
- **What's New**: 본 연구에서는 대형 언어 모델(large language models, LLMs)이 실세계 환경에서 인과성 오류(illusion of causality)를 발생시키는지 조사했습니다. 구체적으로는, 뉴스 헤드라인 생성을 통해 인과관계로 잘못 프레이밍된 상관관계의 정도를 평가했습니다. 특히, GPT-4o-Mini, Claude-3.5-Sonnet, Gemini-1.5-Pro 모델의 성능을 비교했습니다.

- **Technical Details**: 연구를 위해 저자들은 100개의 관찰 연구 논문의 초록을 기반으로 spurious correlations(거짓 상관관계)을 수집했습니다. 각 모델에게 주어지는 작업은 기자의 관점에서 뉴스 헤드라인을 생성하는 것이며, 이 과정에서 sycophancy(아부적 행동)의 영향을 평가하기 위해 미묘하게 수정된 프롬프트를 사용했습니다. 특히, 오류가 있는 믿음을 반영했을 때 모델이 얼마나 더 인과성 오류를 발생시키는지를 관찰했습니다.

- **Performance Highlights**: 연구 결과, Claude-3.5-Sonnet이 인과성 오류를 가장 적게 보이는 것으로 확인되었습니다. 반면, GPT-4o-Mini는 아부적 행동이 인과성 오류를 발생시킬 가능성을 높였습니다. Claude-3.5-Sonnet은 이러한 인지적 편향에 가장 저항력이 있는 모델로 밝혀졌습니다.



### LLM-Mixer: Multiscale Mixing in LLMs for Time Series Forecasting (https://arxiv.org/abs/2410.11674)
Comments:
          Time series forecasting using LLMs

- **What's New**: LLM-Mixer는 멀티스케일 시간 시계열 분해와 사전 훈련된 LLMs를 결합하여 예측 정확도를 향상시키는 새로운 프레임워크입니다.

- **Technical Details**: 이 Framework는 LLM을 고정 상태로 유지하면서 시간 시계열 데이터를 여러 시간 해상도로 분해하고 이를 통해 단기 변동과 장기 추세를 캡처합니다. LLM-Mixer는 다양한 시간 해상도로 멀티버리어트(다변량) 및 유니버리안(단변량) 데이터에 대해 효과적으로 작동합니다.

- **Performance Highlights**: 실험 결과, LLM-Mixer는 다양한 예측 지평선에서 최근 최고 성능(State-of-the-art) 모델들을 초월하며 경쟁력 있는 성능을 달성했습니다.



### VisualRWKV-HD and UHD: Advancing High-Resolution Processing for Visual Language Models (https://arxiv.org/abs/2410.11665)
- **What's New**: 본 논문에서는 VisualRWKV 모델 계열의 두 가지 새로운 발전인 VisualRWKV-HD와 VisualRWKV-UHD를 소개합니다. 이 모델들은 고해상도 시각 입력을 효과적으로 처리하도록 설계되었습니다.

- **Technical Details**: VisualRWKV-HD는 손실 없는 다운샘플링 방법을 통해 고해상도 비전 인코더와 저해상도 인코더를 통합합니다. VisualRWKV-UHD는 이미지를 4개의 세그먼트로 나눈 후 다시 조합하여 고해상도 및 저해상도 특징을 모두 포함할 수 있도록 합니다.

- **Performance Highlights**: 이 두 모델은 VLM 벤치마크에서 강력한 성능을 발휘하며, 텍스트가 풍부한 작업에서 성능이 크게 향상되었습니다. 특히 VisualRWKV-UHD는 최대 4096 x 4096 픽셀 해상도를 지원하여 보다 상세하고 포괄적인 시각 처리 능력을 제공합니다.



### VidEgoThink: Assessing Egocentric Video Understanding Capabilities for Embodied AI (https://arxiv.org/abs/2410.11623)
- **What's New**: 최근 멀티모달 대형 언어 모델(MLLM)의 발전은 구체적인 AI 응용 분야에 새로운 가능성을 열었습니다. 본 논문에서는 Egocentric 비디오 이해 능력을 평가하기 위한 포괄적인 벤치마크인 VidEgoThink를 소개합니다.

- **Technical Details**: VidEgoThink는 비디오 질문-응답(video question-answering), 계층 계획(hierarchy planning), 시각 기초(visual grounding), 보상 모델링(reward modeling)의 네 가지 주요 상호 연관된 작업을 설계하여 Embodied AI에서의 하위 조작과 MLLM 간의 갭을 줄이기 위한 것입니다. 자동 데이터 생성 파이프라인을 활용해 Ego4D 데이터셋을 기반으로 적절한 질문-응답 쌍을 생성합니다. 이 과정에서 GPT-4o의 지능을 활용하고, 생성된 데이터를 인적 평가자를 통해 필터링합니다.

- **Performance Highlights**: 실험 결과 모든 MLLM은 에고센트릭 비디오 이해와 관련된 작업들에서 저조한 성능을 보였습니다. 특히, GPT-4o는 32프레임 및 8프레임에서 각각 31.17%와 32.83%의 정확도를 기록했으며, 타겟 객체와 행동, 장면의 존재를 판단하는 데는 능력이 있지만, 순서나 시퀀스를 평가하는 능력에서 부족함을 보였습니다. 전반적으로, 현시점의 MLLM을 Embodied AI의 1인칭 시나리오에 직접 적용하는 데에는 많은 도전이 남아 있으며, 향후 추가적인 연구가 필요합니다.



### MultiVENT 2.0: A Massive Multilingual Benchmark for Event-Centric Video Retrieva (https://arxiv.org/abs/2410.11619)
- **What's New**: MultiVENT 2.0이란 새로운 대규모 다국어 이벤트 중심 비디오 검색 기준이 도입되었습니다. 이 기준은 218,000개 이상의 뉴스 비디오와 3,906개의 특정 세계 사건을 겨냥한 쿼리를 포함합니다.

- **Technical Details**: 이 데이터셋은 아랍어, 중국어, 영어, 한국어, 러시아어, 스페인어 등 6개 언어의 비디오를 포함하며, 다양한 소스(비주얼 콘텐츠, 오디오, 내장 텍스트, 텍스트 메타데이터)를 활용해야 하는 쿼리가 설계되었습니다.

- **Performance Highlights**: 예비 결과는 현재 최신 비전-언어 모델(Vision-Language Models, VLMs)이 이 작업에서 상당한 어려움을 겪고 있으며, 복합적인 비전-언어 작업을 처리하기 위해 더 강력한 다중 모달 시스템의 필요성을 강조합니다.



### Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Developmen (https://arxiv.org/abs/2410.11550)
Comments:
          12 pages, Under Review

- **What's New**: Y-Mol은 약물 개발(flow of drug development) 과정에서의 특정 도전 과제를 해결하기 위해 설계된 새로운 다중 규모 생물 의학 지식 기반 LLM입니다.

- **Technical Details**: Y-Mol은 백서, 지식 그래프, 전문가가 설계한 합성 데이터로부터 학습하여 생물 의학 영역의 추론 능력을 향상시킵니다. LLaMA2를 기반으로 하고 있으며, 세 가지 유형의 약물 지향 지시문인 설명 기반 프롬프트(description-based prompts), 의미 기반 프롬프트(semantic-based prompts), 템플릿 기반 프롬프트(template-based prompts)를 통합하여 약물 개발의 모든 과정에서 자율적으로 하위 작업을 수행할 수 있도록 설계되었습니다.

- **Performance Highlights**: Y-Mol은 일반 목적의 LLM에 비해 리드 화합물 발견(lead compound discovery), 분자 특성 예측(molecular properties prediction), 약물 상호 작용 이벤트 확인(drug interaction events identification)에서 유의미하게 뛰어난 성능을 보였습니다.



### Human-LLM Collaborative Construction of a Cantonese Emotion Lexicon (https://arxiv.org/abs/2410.11526)
Comments:
          13 pages

- **What's New**: 이 연구에서는 LLM과 인간 주석자 간의 협력을 통해 저자원 언어인 광둥어(Cantonese)에 대한 감정 사전을 개발하는 방법을 제시합니다.

- **Technical Details**: 이 연구에서는 LLM이 제공하는 감정 레이블과 인간 주석자의 레이블을 통합하여, 다른 언어의 어휘와 지역 포럼의 기존 언어 자원을 활용하여 광둥어의 감정 사전을 구축합니다. 감정 추출의 일관성은 세 가지 서로 다른 감정 텍스트 데이터셋을 수정하고 활용하여 평가됩니다.

- **Performance Highlights**: 구축된 감정 사전의 유효성을 검증했으며, 인간과 인공지능(AI) 간의 협력 주석이 감정 레이블 품질을 크게 향상시킬 수 있다는 점을 강조합니다. 이는 저자원 언어에 대한 자연어 처리 작업을 촉진하는 협력의 잠재력을 부각시킵니다.



### Revisiting Benchmark and Assessment: An Agent-based Exploratory Dynamic Evaluation Framework for LLMs (https://arxiv.org/abs/2410.11507)
- **What's New**: 다양한 Vertical Domain Large Language Models (LLMs)의 성능 자동 평가의 필요성과 이를 해결하기 위한 새로운 정의와 프레임워크 도입이 주목됩니다.

- **Technical Details**: 기존의 평가 방법에서 벗어나, Benchmark+와 Assessment+라는 두 가지 새로운 정의를 도입하였습니다. Benchmark+는 전통적인 QA 벤치마크를 'strategy-criterion' 형식으로 확장하고, Assessment+는 상호작용 과정을 향상시켜 다각적인 메트릭(quantitative metrics) 및 질적 통찰(qualitative insights)을 제공합니다. 이 두 개념을 구현하기 위해 *TestAgent*라는 에이전트 기반 평가 프레임워크를 제안하였습니다.

- **Performance Highlights**: 다양한 시나리오에서 *TestAgent*의 효과성을 입증하는 실험을 수행하였으며, 기존 벤치마크를 활용하거나 새로운 Vertical Domain 평가를 구축하는 작업에서 그 효율성을 보여주었습니다.



### LR-SQL: A Supervised Fine-Tuning Method for Text2SQL Tasks under Low-Resource Scenarios (https://arxiv.org/abs/2410.11457)
Comments:
          12pages, 4 figures,submitting to a journal

- **What's New**: LR-SQL은 데이터베이스의 복잡성으로 인한 GPU 메모리 요구량 증가 문제를 해결하기 위해 제안되었습니다. 기계 학습 모델의 세분화된 조정을 통해 더 효율적인 Text2SQL 변환을 가능하게 합니다.

- **Technical Details**: LR-SQL은 schema_link 모델과 SQL_generation 모델의 두 가지 감독적 세부 조정(supervised fine-tuning) 모델로 구성되어 있습니다. schema_link 모델은 전체 데이터베이스를 유연한 테이블 조합으로 나누어 모델이 이산 조각에서 관계를 학습할 수 있게 합니다. 또한, Chain-of-Thought 능력을 훈련시켜 다양한 조각 간의 관계 인지를 개선합니다.

- **Performance Highlights**: LR-SQL은 기존 방법에 비해 총 GPU 메모리 사용량을 40% 줄였으며, schema_link 작업에서 테이블 예측 정확도는 2% 감소했습니다. 전체 Text2SQL 작업에서는 실행 정확도(Execution Accuracy)가 0.6% 감소했습니다.



### A Framework for Adapting Human-Robot Interaction to Diverse User Groups (https://arxiv.org/abs/2410.11377)
Comments:
          Accepted at the 16th International Conference on Social Robotics (ICSR) 2024

- **What's New**: 본 논문에서는 다양한 사용자의 요구와 기대를 충족하고 그들의 피드백에 따라 로봇의 행동을 적응시키는 새로운 Human-Robot Interaction (HRI) 프레임워크를 소개합니다. 이 프레임워크는 사용자가 로봇과의 상호작용을 위해 실시간으로 수정할 수 있는 기능을 제공합니다.

- **Technical Details**: 본 프레임워크는 ROS 기반으로 개발되었으며, 음성 인식 및 음성 활동 감지 기능을 통해 자연스러운 상호작용을 지원합니다. 또한, 대화의 교량 역할을 수행하는 대형 언어 모델 (LLM)을 이용하여 사용자의 언어 입력과 로봇 명령 사이의 원활한 소통을 가능하게 합니다. 사용자의 나이를 인식하여 그에 맞는 상호작용을 조정하며, 소규모 및 대규모 사용자 중단을 처리할 수 있도록 설계되었습니다.

- **Performance Highlights**: 시스템 테스트를 통해 나이 인식의 높은 정확도와 반복된 사용자 입력 및 계획 변경에 대한 강인성을 검증했습니다. 사용자 인터럽션을 처리하며, 두 가지 시나리오에서 효과적으로 작동함을 보여주었습니다: 사소한 인터럽션으로 객체를 가져오고 교체하는 것과 시스템을 완전히 중지하는 것입니다.



### Reducing Labeling Costs in Sentiment Analysis via Semi-Supervised Learning (https://arxiv.org/abs/2410.11355)
Comments:
          12 pages, 7 figures, accepted at the 2024 8th International Conference on Natural Language Processing and Information Retrieval (NLPIR 2024), Okayama, Japan, 2024

- **What's New**: 이 연구는 기계 학습에서 데이터 레이블링의 효율성을 높이는 새로운 접근 방식을 제시합니다. 전통적인 방법에 비해 레이블의 수를 크게 줄일 수 있는 반지도 학습(semi-supervised learning)에서의 레이블 전파(label propagation)를 탐구하고 있습니다.

- **Technical Details**: 본 연구에서는 텍스트 분류를 위한 매니폴드 가정(manifold assumption)을 기반으로 한 전이식 레이블 전파(transductive label propagation) 방법을 사용합니다. 그래프 기반(graph-based) 방법을 활용하여 레이블이 없는 데이터에 대한 유사 레이블(pseudo-labels)을 생성하고, 이를 통해 깊은 신경망(deep neural networks)을 학습합니다.

- **Performance Highlights**: 본 연구는 감정 분석(sentiment analysis) 분야에 대한 실험을 통해 레이블 전파의 효과성을 평가하며, 기존의 레이블링 방법에 비해 성능이 비슷한 결과를 얻을 수 있음을 보이고 있습니다.



### Sequential LLM Framework for Fashion Recommendation (https://arxiv.org/abs/2410.11327)
- **What's New**: 이 논문은 패션 산업에 최적화된 추천 시스템을 제안하며, 선행 학습된 대형 언어 모델(LLM)을 활용하여 추천 성능을 향상시키는 방법을 제시합니다.

- **Technical Details**: 제안된 프레임워크는 세 가지 주요 단계로 이루어져 있습니다: 첫째, 추천 목표에 맞춘 전문 프롬프트를 설계하는 프롬프트 엔지니어링 기술을 사용합니다. 둘째, 비용이 많이 드는 훈련 비용을 줄이기 위해 Parameter-Efficient Fine-Tuning (PEFT) 기술을 적용합니다. 마지막으로, 예측된 제품 제목 및 ID를 활용하여 관련 후보 항목을 검색하고 순위를 매기는 mix-up 기반 검색 기술을 사용합니다.

- **Performance Highlights**: 실험 결과, 제안된 프레임워크는 패션 추천 성능을 현저히 향상시켰다고 합니다. 특히, 기존의 패션 추천 시스템보다 효과적으로 사용자 선호도를 파악하고, 콜드 스타트 문제를 극복하는 데 기여했습니다.



### Deciphering the Chaos: Enhancing Jailbreak Attacks via Adversarial Prompt Translation (https://arxiv.org/abs/2410.11317)
- **What's New**: 이 논문은 손상된 적대적 프롬프트(garbled adversarial prompts)의 의미를 해석하고 이를 자연어로 변환하는 새로운 방법을 제안하여, 기존 기법보다 더 효과적인 jailbreak 공격(jailbreak attacks)을 가능하게 합니다.

- **Technical Details**: 기존의 gradient-based 공격은 종종 혼란스러운 형식의 적대적 프롬프트를 생성합니다. 본 연구에서는 이러한 프롬프트에서 의미 정보를 추출하고, 이를 인간이 읽을 수 있는 자연어로 '번역'하여 무해한 요청에 대한 반응을 유도할 수 있도록 합니다. 이 방법은 victim 모델에 적대적 정보를 명확하게 전송할 수 있어, jailbreak 공격의 성능을 개선합니다.

- **Performance Highlights**: HarmBench에서 7개의 상용 닫힌 소스 LLM에 대해 평균적으로 81.8%의 공격 성공률을 달성하며, Llama-2-Chat 모델에 대해서도 90% 이상의 성공률을 보이는 등의 탁월한 성능을 나타냈습니다.



### Data Selection for Task-Specific Model Finetuning (https://arxiv.org/abs/2410.11303)
Comments:
          31 pages, 1 figure

- **What's New**: 본 논문은 특정 작업에 대한 foundation model의 finetuning을 위한 최적 데이터 선택 프레임워크를 제안합니다.

- **Technical Details**: 데이터 선택 문제를 최적 운송(optimal transport)을 기반으로 하는 최적화 문제로 공식화했습니다. 선택된 데이터의 분포는 목표 작업에서 제공된 대표 사례의 분포와 일치해야 하며, 이 과정에서 다양성을 촉진하기 위한 정규화 항이 추가되었습니다.

- **Performance Highlights**: 제안된 방법은 언어 모델의 instruction tuning에서 1%의 데이터 선택 비율로 F1 점수 기준으로 평균 1.5점 더 높은 성능을 보였고, domain-specific 데이터 선택에서도 최대 3 F1 점수 개선을 나타냈습니다.



### Have the VLMs Lost Confidence? A Study of Sycophancy in VLMs (https://arxiv.org/abs/2410.11302)
- **What's New**: 이번 연구에서는 LLMs(대형 언어 모델)의 시코팬시(sycophancy) 문제를 VLMs(비주얼 언어 모델)로 확장하여 다루었습니다. 특히, VLMs에서 시코팬시에 대한 연구가 부족하다는 점을 강조하며, 새로운 MM-SY 벤치마크를 도입했습니다.

- **Technical Details**: 시코팬시(sycophancy)는 LLMs가 원래의 올바른 응답을 따르지 않고 사용자 의견에 무비판적으로 동의하는 현상을 말합니다. 본 연구에서는 시코팬시를 완화하기 위한 합성 데이터셋(synthetic dataset)을 제안하고, 프롬프트(prompts), 감독된 미세 조정(supervised fine-tuning), DPO(Deep Prompting Optimization) 기반의 방법들을 사용하여 효과적으로 문제를 해결하였습니다. 또한, VLMs의 시코팬시가 의미론적(semiotic)으로 미치는 영향을 평가하기 위해 주목(attention) 분포를 분석했습니다.

- **Performance Highlights**: 실험 결과, 상위 레이어에서의 시코팬시 예방 능력이 두드러지며, 상위 레이어에서의 이미지(attention) 지식 부족이 시코팬시에 기여하고 있음을 확인했습니다. 이에 따라, 고급 레이어에서의 이미지 주목(attention)을 향상시키는 것이 시코팬시 문제를 완화하는 데 유용하다는 결과를 얻었습니다.



### Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix (https://arxiv.org/abs/2410.11261)
- **What's New**: 이 논문은 대형 언어 모델(LLM)의 가중치 가지치기를 위한 새로운 접근 방식을 제안합니다. 기존의 선형 근사를 사용하는 방법과 달리, 이 연구는 Softmax 주의 메커니즘의 비선형성을 고려하여 주의 행렬을 근사화하는 방법을 다룹니다.

- **Technical Details**: 주요 기술적 기법은 Gradient Descent 기반의 최적화 방법을 통해 주의 행렬에 대한 가지치기 마스크를 직접 계산하는 것입니다. 이 접근법은 효과적인 가지치기 마스크 솔루션으로 수렴할 수 있도록 보장하는 이론적 근거를 제공합니다.

- **Performance Highlights**: 예비 실험 결과, 이 방법은 모델 성능을 유지하면서도 계산 비용을 상당히 줄이는 효과를 보여주었습니다. 이 연구는 자원이 제한된 장치에서의 더 효율적인 LLM 추론을 위한 새로운 이론적 기초를 세우는 데 기여하고 있습니다.



### Investigation of Speaker Representation for Target-Speaker Speech Processing (https://arxiv.org/abs/2410.11243)
Comments:
          Accepted at IEEE SLT 2024

- **What's New**: 이번 논문은 target-speaker speech processing (TS) 과제에 대한 새로운 접근 방식을 탐구하며, TS-ASR, TSE 및 p-VAD 작업에서의 speaker embedding 선택을 비교합니다. 특히, speaker embedding의 최적화에 대해 다루고 있습니다.

- **Technical Details**: 이 연구는 선행 연구에서 사용된 여러 speaker embedding 방법들을 비교하고, GAP 기반의 최적화 기법을 통해 성능 향상 방법을 모색합니다. 사용된 주요 모델은 Transformer 기반 및 ECAPA-TDNN 기반의 SSL 모델을 포함합니다. 연구는 SUPERB 프레임워크를 적용해 통합된 실험 환경을 구축하고, 모든 작업에서 512차원의 speaker embedding을 사용하였습니다.

- **Performance Highlights**: 연구 결과, speaker code를 사용하는 방법이 다른 방법보다 뛰어난 성능을 보이며, speaker embedding은 입력 혼합물에 따라 최적화된 방향으로 변화할 수 있음을 보여주었습니다. 또한, ASV 성능과 TS 작업 성능 간의 관련성이 적다는 점이 강조되었습니다.



### Mimetic Initialization Helps State Space Models Learn to Reca (https://arxiv.org/abs/2410.11135)
- **What's New**: 이번 연구에서는 상태 공간 모델(State Space Models, SSMs)인 Mamba가 Transformer에 비해 복사(copy) 및 기억(recall) 기반 작업에서 낮은 성능을 보인다는 기존의 연구 결과를 보완하는 개선 방법을 제안합니다. 새로운 초기화 기법인 mimetic initialization을 통해 Mamba가 더 효율적으로 self-attention을 모방할 수 있도록 돕습니다.

- **Technical Details**: 상태 공간 모델은 입력 시퀀스 길이에 비례하지 않고 고정된 크기(state size)의 상태를 사용하여 맥락(context)을 압축합니다. 그러나 Mamba와 같은 SSM은 실질적으로 큰 상태 크기를 가지고 있으며, 이들이 훈련(quarantine)에 어려움을 겪는 것이 본질적인 용량 제약(capacity constraints) 때문이 아닌지 조사합니다. 연구에서 제안된 초기화 기법은 Mamba 레이어가 linear attention을 효과적으로 나타낼 수 있도록 합니다.

- **Performance Highlights**: Mimetic initialization을 통해 Mamba는 복사 및 연관 기억(associative recall) 작업에서 최대 4배 길이에 대해 우수한 성능을 가지며, 2배 길이 일반화(length generalization)에서도 성공적인 결과를 보여줍니다. 이는 기존의 SSM이 가지고 있던 성능 평가를 재고하게 하며, 실제로 SSMs의 능력이 이전 연구에 의해 과소평가됐을 가능성을 보여줍니다.



### Liger Kernel: Efficient Triton Kernels for LLM Training (https://arxiv.org/abs/2410.10989)
Comments:
          17 pages, 12 figures

- **What's New**: Liger-Kernel는 단일 트라이톤 커널 세트를 제공하여 대규모 언어 모델(LLM) 훈련의 효율성을 향상시키는 것을 목표로 합니다.

- **Technical Details**: Liger-Kernel은 커널 작업 합성(kernel operation fusing) 및 입력 청크를 포함한 최적화 기술을 통해 훈련 처리량을 20% 증가시키고 GPU 메모리 사용량을 60% 감소시킵니다. 이 라이브러리는 PyTorch 및 Triton과 최소한의 의존성을 가지며, PyTorch FSDP, DeepSpeed ZeRO 등의 여러 분산 프레임워크를 지원합니다.

- **Performance Highlights**: Liger-Kernel을 사용하면 처음 사용자도 몇 줄의 코드로 LLM 훈련 효율성을 쉽게 개선할 수 있으며, 고급 사용자들은 모듈 구성 요소 및 적응형 계층 설정을 통해 모델을 사용자 맞춤형으로 조정할 수 있습니다.



### Federated Data-Efficient Instruction Tuning for Large Language Models (https://arxiv.org/abs/2410.10926)
Comments:
          11 pages. Ongoing work

- **What's New**: 본 연구는 Federated Learning(FL) 환경에서 대규모 언어 모델(LLMs)의 지침 조정(instruction tuning) 시 데이터 효율성을 높이기 위한 새로운 접근법인 FedHDS를 제안합니다. 이는 적은 양의 데이터를 사용하여 LLM의 응답성을 개선합니다.

- **Technical Details**: FedHDS는 클라이언트 측에서 훈련 데이터의 중복성을 줄이기 위해 계층적 데이터 선택 프레임워크를 활용하여 대표적인 데이터 샘플을 선택합니다. 각 클라이언트의 로컬 데이터를 클러스터링하여 내부 데이터 중복성을 식별하고, 이를 서버에 전송하여 외부 데이터 중복성을 파악합니다.

- **Performance Highlights**: 실험 결과, FedHDS는 전체 데이터셋을 사용하는 기존의 페더레이티드 지침 조정 기법보다 10.72%의 Rouge-L 점수를 개선하면서, 필요한 데이터 양을 1.5% 미만으로 줄이는 성과를 보였습니다.



### Dissecting embedding method: learning higher-order structures from data (https://arxiv.org/abs/2410.10917)
Comments:
          The 13th International Conference on Complex Networks and their Applications, Dec 2024, Istanbul, Turkey

- **What's New**: 이번 연구에서는 데이터에서 기하학을 학습하기 위한 저차원 다양체(Manifold) 표현을 발견하는 과정에서 발생하는 기존의 한계점을 분석하고, 새로운 접근 방식을 제안합니다.

- **Technical Details**: 기존의 기하학적 딥러닝(Geometric Deep Learning) 기법은 데이터 포인트의 이진 쌍 관계만을 인코딩하는 그래프 구조(Graph Structure)에 기반하고 있습니다. 하지만 연구진은 이러한 접근이 높은 차원의 복잡한 관계를 포착하지 못하는 문제를 지적하고, 이를 해결하기 위해 하이퍼그래프(Hypergraph) 이론을 도입하여 데이터의 임베딩(Embedding) 구조를 분석합니다. 또한, 조합론적 접근법(Combinatorial Approach)을 통해 임베딩 기법의 불일치를 특성화하고자 합니다.

- **Performance Highlights**: 이 연구는 arXiv 데이터를 활용하여 임베딩 특성화를 시연하며, 그래프 대신 하이퍼그래프를 사용한 새로운 방법론의 효과를 검증합니다.



### Towards Better Multi-head Attention via Channel-wise Sample Permutation (https://arxiv.org/abs/2410.10914)
Comments:
          18 pages, 4 figures

- **What's New**: 이번 연구에서는 Channel-wise Sample Permutation (CSP) 연산자를 제안하며, 이를 통해 매개변수 수가 적고 복잡성이 낮은 새로운 구조적 다중 헤드 주의 메커니즘을 실현했습니다. CSP는 입력 행렬의 다양한 채널샘플을 원형으로 이동시키고 각 채널의 그룹화된 샘플을 정렬함으로써 이론적 이해도 뛰어난 기술로 구현됩니다.

- **Technical Details**: CSP 연산자는 서로 다른 채널의 샘플을 다양한 단계로 원형 이동시키고 그룹화된 샘플을 정렬하여 작동합니다. 이는 교차 채널 주의 맵을 암묵적으로 구현하며, 선형 복잡성을 달성하고 데이터 표현시 rank collapse의 위험을 억제합니다. 기존의 다중 헤드 주의(MHA) 대신 CSP를 일부 대표 모델에 적용하였으며, 정량적 평가에서 성능과 유사하거나 우수한 결과를 얻었습니다.

- **Performance Highlights**: CSP 기반 모델들은 기존의 Transformer 모델 및 최신 변형들과 비교했을 때, 동일한 성능을 유지하거나 향상시키면서 매개변수 수와 계산 비용을 현저히 줄였습니다. 이 실험 결과는 CSP가 효율적이고 강력한 대안이 될 수 있음을 보여줍니다.



### 3DS: Decomposed Difficulty Data Selection's Case Study on LLM Medical Domain Adaptation (https://arxiv.org/abs/2410.10901)
- **What's New**: 이 논문에서는 Large Language Models(LLMs)의 특수한 도메인 적응을 위한 새로운 데이터 선택 프레임워크인 Decomposed Difficulty Data Selection (3DS)를 제안합니다. 3DS는 모델의 지식 분포에 맞춰 데이터를 최적화하여 적합한 도메인 적응을 보장합니다.

- **Technical Details**: 3DS는 두 단계로 구성됩니다. 1단계에서는 Prompt-Driven Data Selection via Explicit Alignment을 통해 모델이 내부 지식을 바탕으로 불필요하거나 중복된 데이터를 걸러냅니다. 2단계에서는 난이도 분해(Difficulty Decomposition)를 사용해 세 가지 메트릭인 Instruction Understanding, Response Confidence, Response Correctness에 따라 데이터를 선택합니다. 또한, 주의(attention) 기반의 중요도 가중치 메커니즘으로 토큰의 중요성을 캡처하여 난이도를 보다 정확하게 조정합니다.

- **Performance Highlights**: 의료 도메인 사례 연구에서, 실제 의료 데이터셋을 활용한 광범위한 실험 결과, 3DS가 기존 방법들보다 정확도에서 5.29% 이상 우수성을 보임을 입증했습니다.



### Enhancing Vision-Language Model Pre-training with Image-text Pair Pruning Based on Word Frequency (https://arxiv.org/abs/2410.10879)
- **What's New**: 이번 논문은 Word-Frequency 기반 이미지-텍스트 쌍 가지치기(WFPP)라는 새로운 데이터 가지치기 방법을 제안하여 VLMs(비전-언어 모델)의 효율성을 향상시킵니다. 이 방법은 텍스트의 내용을 기반으로 텍스트-이미지 쌍을 선택하여 가지치기를 진행하며, 높은 빈도의 단어를 포함하는 쌍을 제거하여 단어 빈도 분포를 균형 있게 만듭니다.

- **Technical Details**: WFPP는 빈도가 높은 단어를 포함하는 텍스트가 있는 이미지-텍스트 쌍을 제거하여 훈련 데이터셋의 균형을 개선합니다. WFPP는 단어 확률에 기반하여 간단한 텍스트 수준 점수를 사용하여 가지치기를 수행하며, 텍스트에서 잦은 단어를 제거함으로써 전반적인 데이터의 다양성을 유지합니다. 최적의 결과를 위해, WFPP는 테스트 후 전체 데이터셋에 대해 1 에폭을 추가로 조정하여 성능을 개선합니다.

- **Performance Highlights**: WFPP를 적용하면 CLIP 모델의 훈련 성능이 저격 작업에서 향상됩니다. WFPP는 데이터를 효율적으로 가지치기하면서도 성능 저하 없이 학습 속도를 개선해줍니다. 제안된 방법을 통해 CLIP 모델은 다양한 하위 작업에서 성능이 향상되었으며, 제로샷 분류 및 이미지-텍스트 검색에서 우수한 결과를 보였습니다.



### LLaCA: Multimodal Large Language Continual Assistan (https://arxiv.org/abs/2410.10868)
- **What's New**: 이번 논문에서는 Multimodal Large Language Models (MLLMs)의 능력과 제어 가능성을 향상시키기 위한 새로운 방법인 Multimodal Large Language Continual Assistant (LLaCA)를 제안합니다. 이는 균형 잡힌 업데이트를 통해 이전 데이터셋에서의 성능 저하를 방지하고, 지속적인 지시 학습을 개선하려는 목적을 가지고 있습니다.

- **Technical Details**: 이 연구는 Exponential Moving Average (EMA) 업데이트 정책을 사용하여 과거 매개변수를 추적하고, forgetting(망각)을 감소시키는 방법을 소개합니다. 또한, 이 논문은 손실 함수에서 Taylor 확장을 기반으로 최적의 균형 가중치를 결정하는 방법을 제안하며, 이는 gradient 정보와 이전 매개변수에 따라 달라집니다.

- **Performance Highlights**: 종합 실험 결과, LLaCA는 LLaVA-1.5 지속적인 시각 질문 답변 벤치마크에서 기존 방법과 비교하여 anti-forgetting 능력을 크게 향상시키고(기억 잃는 비율을 22.67에서 2.68로 감소), 평균 정확도를 41.31에서 61.89로 증가시켰습니다.



### LLM Gesticulator: Leveraging Large Language Models for Scalable and Controllable Co-Speech Gesture Synthesis (https://arxiv.org/abs/2410.10851)
- **What's New**: 이번 연구에서는 LLM 기반의 오디오 드리븐 동작 생성 프레임워크인 LLM Gesticulator를 제안합니다. 이 프레임워크는 입력 오디오와 일치하여 리드미컬하게 조화를 이루는 전체 신체 애니메이션을 합성하며, 자연스러운 움직임과 편집 가능성을 제공합니다. LLM Gesticulator는 기존 작업에 비해 상당한 확장성을 보여줍니다.

- **Technical Details**: 우리의 프레임워크는 큰 언어 모델(LLM)을 기반으로 하여 음성에 맞춘 전체 신체 제스처를 생성하는 새로운 방식을 제안합니다. 우리는 제스처 생성 문제를 시퀀스-투-시퀀스 변환 작업으로 모델링하였으며, 사용자에게 텍스트 프롬프트를 통해 제스처 내용을 제어할 수 있는 기능을 제공합니다. 데이터 증강 기법으로 BEAT 데이터 세트의 모션 설명을 주석 처리하고 이를 커뮤니티에 제공할 예정입니다.

- **Performance Highlights**: 평가 지표 및 사용자 연구 결과, 우리의 프레임워크가 이전 작업보다 우수한 성능을 보여주었으며, 사용자는 텍스트 프롬프트에 따라 생성되는 제스처의 스타일과 내용을 제어할 수 있습니다.



### Continuous Approximations for Improving Quantization Aware Training of LLMs (https://arxiv.org/abs/2410.10849)
- **What's New**: 본 연구는 Quantization Aware Training (QAT) 방법론을 확장하여 모델 압축에서 성능 저하를 최소화하기 위한 두 가지 연속 근사를 소개합니다. 이 방법은 기존의 Straight-Through Estimator (STE) 및 클램핑 함수의 접근을 개선하여 더 나은 성능을 달성했습니다.

- **Technical Details**: 제안된 방법에는 Sigmoid STE와 SoftClamp가 포함되어 있습니다. Sigmoid STE는 QAT에서 반올림 함수의 연속 근사로 사용되며, SoftClamp는 입력 값이 특정 범위 내에 제한되도록 하는 기능을 제공합니다. 이를 통해 QAT 과정에서 더 안정적이고 정확한 학습이 가능해집니다.

- **Performance Highlights**: WikiText-v2 데이터셋에서 양자화된 모델의 perplexity (PPL)는 9.0815로, 이전의 9.9621보다 우수한 성능을 보였습니다. BoolQ에서는 2.76%, MMLU에서는 5.47%의 성능 개선을 달성하여, 에너지 효율적인 LLM 개발에 기여할 수 있는 가능성을 보여줍니다.



### Duo-LLM: A Framework for Studying Adaptive Computation in Large Language Models (https://arxiv.org/abs/2410.10846)
- **What's New**: 이 논문은 Large Language Models (LLMs)의 비효율성을 해결하기 위해 자유롭게 조정 가능한 모듈을 도입한 Duo-LLM 프레임워크를 제안합니다. 이 프레임워크는 각 Feed-Forward Network(FFN) 레이어 내에서 작은 보조 모듈과 큰 모듈을 통합하여, 입력의 복잡성에 따라 동적 라우팅을 가능하게 합니다.

- **Technical Details**: Duo-LLM 프레임워크에서는 각 레이어의 FFN 내에서 작은 모듈과 큰 모듈을 사용하여, 텍스트 처리 시 토큰을 작은 모듈 혹은 큰 모듈로 라우팅하고 일부 레이어를 건너뛸 수 있도록 설계되어 있습니다. 최적의 라우팅 패턴을 발견하기 위해 오라클(oracle)을 사용하여 가능성 있는 모든 라우팅 경로를 평가합니다. 이를 통해 각 토큰의 perplexity를 최소화하는 경로를 선택합니다.

- **Performance Highlights**: 오라클에 의해 최적화된 라우팅 전략을 기반으로 한 실험 결과, 한 개의 큰 모듈만 활성화할 경우 모든 레이어에서 큰 모듈을 사용하는 것보다 낮은 perplexity를 기록했습니다. 이는 MoE 모델에서 라우팅의 실제 구현과 이론적 최적화 간의 현격한 차이를 강조합니다.



### Test Case-Informed Knowledge Tracing for Open-ended Coding Tasks (https://arxiv.org/abs/2410.10829)
- **What's New**: TIKTOC(테스트 케이스 정보 기반 지식 추적)는 기존의 지식 추적(KT) 방법의 한계를 극복하며, 학생 코드를 분석하고 각 테스트 케이스에 대한 통과 여부를 동시에 예측할 수 있는 새로운 프레임워크이다.

- **Technical Details**: TIKTOC는 멀티태스크 학습(multi-task learning) 방법을 사용하여 인공지능 모델이 학생 코드의 테스트 케이스 통과 여부와 오픈 엔디드(open-ended) 코드를 예측할 수 있게 한다. 기존의 CodeWorkout 데이터셋에 사용된 테스트 케이스를 추가하여 보다 정교한 지식 추적 작업을 위해 설계되었다.

- **Performance Highlights**: TIKTOC의 실험 결과, 기존의 KT 방법에 비해 테스트 케이스 통과 예측 정확도가 15% 향상되었으며, 코드 예측 정확도 또한 6% 향상되었다. 이는 오픈 엔디드 코딩 질문에서 학생의 지식을 더욱 세부적으로 파악하는 데 기여한다.



### DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads (https://arxiv.org/abs/2410.10819)
- **What's New**: 이 논문에서 제안하는 DuoAttention 프레임워크는 긴 컨텍스트를 처리하기 위한 효율성을 개선하는 데 초점을 맞추고 있습니다. 핵심 관찰은 주의(heads)를 검색하는 Retrieval Heads와 스트리밍하는 Streaming Heads로 구분할 수 있다는 것입니다. 이 프레임워크는 검색 헤드에는 전체 KV(cache) 저장소를 적용하고 스트리밍 헤드에는 경량의 상수 길이 KV 캐시를 사용하여 메모리와 지연 시간을 줄입니다.

- **Technical Details**: DuoAttention은 Retrieval Heads와 Streaming Heads의 차이를 활용합니다. Retriever Heads는 모든 토큰에서 완전한 주의를 요구하는 반면, Streaming Heads는 최근 토큰과 주의 집중 지점에만 주의를 기울이며 KV 캐시를 경량화할 수 있습니다. 이 방법은 합성 데이터를 기반으로 검색 헤드를 정확하게 식별하는 경량화된 최적화 알고리즘을 사용합니다.

- **Performance Highlights**: DuoAttention을 통해 모델의 긴 컨텍스트 추론 메모리를 MHA 모델에서 최대 2.55배, GQA 모델에서 1.67배 줄일 수 있었고, 디코딩 속도를 각각 최대 2.18배, 1.50배 가속화했습니다. 또한, 이 방법은 정확도를 거의 손실시키지 않으면서도 Llama-3-8B 모델이 단일 A100 GPU에서 330만 컨텍스트 길이를 처리할 수 있도록 합니다.



### Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Fr (https://arxiv.org/abs/2410.10814)
Comments:
          Code: this https URL

- **What's New**: 본 논문은 Mixture-of-Experts (MoE) 구조를 가진 대형 언어 모델(LLM)이 사전 훈련 후 추가적인 조정 없이도 높은 품질의 본문 임베딩(embedding)을 생성할 수 있다는 새로운 발견을 제시합니다. 이러한 구조에서 라우터가 효과적으로 임베딩 모델로 기능하며, 라우터 가중치(Routing Weights, RW)와 숨은 상태(Hidden State, HS)를 결합하여 MoE Embedding (MoEE)을 제안합니다.

- **Technical Details**: MoE 아키텍처는 입력을 관련된 전문가에게 전달하는 동적 라우터의 특성을 통해 계산 효율성과 정확성을 최적화합니다. MoEE는 RW와 HS의 결합을 통해 고급 의미를 포착하고, 입력에 대한 상이한 클러스터 구조를 보여주는 등, 기존 HS 임베딩에 대해 보완적인 정보를 제공합니다. 본 연구는 다양한 조합 전략(예: 가중 합계, 연결)을 실험하여 MoEE가 embedding 품질을 높이는 방법을 탐구합니다.

- **Performance Highlights**: Massive Text Embedding Benchmark (MTEB)에서 실시한 실험을 통해 MoEE가 HS나 RW에서 발췌한 embedding보다 지속적으로 우수한 성능을 발휘함을 입증했습니다. 특히, MoEE는 의미적 텍스트 유사성, 분류(classification), 군집화(clustering) 등의 작업에서 주요한 개선을 보였습니다.



### LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory (https://arxiv.org/abs/2410.10813)
- **What's New**: 오늘날의 대형 언어 모델(LLM) 기반의 채팅 어시스턴트 시스템은 메모리 기능을 통합하여 사용자와의 대화 이력을 기록함으로써 더 정확하고 개인화된 응답을 제공하고 있습니다. 하지만 장기 메모리 기능에 대한 연구는 광범위하게 이루어지지 않았습니다. 본 논문에서는 LongMemEval이라는 새로운 벤치마크를 소개하여 채팅 어시스턴트의 다섯 가지 핵심 장기 메모리 능력을 평가합니다.

- **Technical Details**: LongMemEval은 정보 추출(information extraction), 다중 세션 추론(multi-session reasoning), 시간적 추론(temporal reasoning), 지식 업데이트(knowledge updates), 그리고 거부(abstention) 능력을 평가하기 위해 500개의 기준 질문을 포함한 종합적인 벤치마크입니다. 이 벤치마크는 115,000 토큰과 1.5백만 토큰(byte)의 두 가지 표준 설정에서 테스트됩니다. 결과적으로 상용 채팅 어시스턴트 및 장기 컨텍스트 LLM은 지속적인 상호작용에서 정보를 기억하는 데 30%의 정확도 저하를 보였습니다.

- **Performance Highlights**: LongMemEval의 실험 결과, 메모리 회상(memory recall) 및 하류 질문 응답에서 최적화된 메모리 설계가 크게 개선되었음을 보여줍니다. 벤치마크 평가에서 LLM이 LongMemEvalS에서 30%에서 60%의 성능 저하를 보였으며, 상용 시스템은 30%에서 70%의 정확도를 기록했습니다. 다양한 메모리 설계 최적화가 도입되어 성능 향상에 기여했습니다.



### Local and Global Decoding in Text Generation (https://arxiv.org/abs/2410.10810)
Comments:
          Paper accepted in EMNLP 2024. Code is available in this https URL

- **What's New**: 본 논문에서는 전통적인 텍스트 생성 방법인 top-$k$ 및 top-$\pi$의 로컬 정규화(local normalisation)가 모델 출력 분포에 미치는 왜곡 효과를 조사합니다. 이와 함께, 전역 정규화(globally-normalised)의 새로운 샘플링 방식을 소개합니다.

- **Technical Details**: 이 연구에서는 전역 정규화 방식을 적용한 decoding algorithm을 도입하고, Metropolis-Hastings 알고리즘을 독립적으로 사용하여 전역 정규화 분포로부터 샘플링을 근사하는 방법을 제안합니다. 실험은 두 가지 decoding 알고리즘(top-$k$, top-$\pi$)과 다양한 하이퍼파라미터를 사용하여 Pythia 언어 모델로 수행되었습니다.

- **Performance Highlights**: 결과적으로, 대부분의 구성에서 전역 정규화의 성능이 동일한 알고리즘의 로컬 스킴보다 낮았지만, 분포의 무결성을 유지했습니다. 이는 로컬 디코딩 알고리즘의 왜곡(distortion)이 중요한 특성임을 시사합니다.



### Mix Data or Merge Models? Optimizing for Diverse Multi-Task Learning (https://arxiv.org/abs/2410.10801)
- **What's New**: 이 연구에서는 다양한 언어 모델을 다루기 위한 새로운 방법으로 '모델 병합'을 탐구합니다. 전통적인 데이터 혼합 방식과 비교하여, 모델 병합이 안전성과 일반 성능 간의 균형을 효과적으로 맞출 수 있는지를 분석합니다.

- **Technical Details**: 모델 병합(Merging)은 다양성을 가진 다중 작업(multi-task) 설정에서 안전성(safety) 및 일반 목적(general-purpose) 작업을 결합합니다. 연구 결과에 따르면, 모델 병합은 데이터 혼합(data mixing) 방식보다 효과적이며, 언어별 병합(language-based merging) 방법을 통해 일반 성능과 해로운 콘텐츠(harm) 감소를 달성할 수 있습니다.

- **Performance Highlights**: 모델 병합은 일반 성능이 8% 향상되고 안전성은 10% 감소하였습니다. 언어별로 모델을 병합할 경우, 일반 성능이 4% 증가하고 해로운 결과가 7% 감소했습니다. 특히 SLERP 방식이 두 가지 목표를 최적으로 균형 잡는 데 가장 효과적이며, 일반 성능에서 7% 향상과 해로운 콘텐츠에서 3.1% 감소를 기록했습니다.



### When Attention Sink Emerges in Language Models: An Empirical View (https://arxiv.org/abs/2410.10781)
- **What's New**: 이번 연구에서는 Language Models (LMs)에서 'attention sink' 현상이 보편적으로 존재한다는 것을 입증했습니다. 특히 이 현상이 작은 모델에서도 발생함을 발견하였고 LM의 사전 훈련 과정에서 나타남을 강조했습니다.

- **Technical Details**: attention sink는 초기 토큰에 대한 비정상적인 집중을 의미하며, 이는 다양한 입력에서도 관찰됩니다. 이 연구는 사전 훈련 중 attention sink의 출현을 최적화, 데이터 분포, 손실 함수, 모델 구조 등이 어떻게 영향을 미치는지를 탐구하였습니다.

- **Performance Highlights**: 효과적인 데이터 훈련 후에 attention sink가 나타나며, 작은 학습률로 훈련된 LMs에서는 덜 나타납니다. 손실 함수 및 데이터 분포와 깊은 상관관계가 있으며, softmax normalize 대신 sigmoid attention을 통해 이러한 의존성을 완화시켰을 때, 1B 파라미터까지의 LMs에서는 attention sink가 발생하지 않았습니다.



### Use Random Selection for Now: Investigation of Few-Shot Selection Strategies in LLM-based Text Augmentation for Classification (https://arxiv.org/abs/2410.10756)
- **What's New**: 이번 연구에서는 LLM 기반 텍스트 증강에서의 샘플 선택 전략을 비교하고 분석했습니다.기존의 연구들은 대부분 무작위로 샘플을 선택하는데 집중한 반면, 이번 연구는 보다 '정보에 기반한' 선택 전략의 효과를 살펴봄으로써 증강 성능을 높이기 위한 방법론을 제시합니다.

- **Technical Details**: 샘플 선택 전략은 일반적인 few-shot 학습 문헌에서 존재하며, LLM(Generative Large Language Models)을 활용하여 기존 샘플의 패러프레이징(paraphrasing) 또는 새로운 샘플 생성을 포함합니다. 다양한 샘플 선택 전략을 통해 향상된 성능을 확인하기 위해 8개의 샘플 선택 전략을 2개의 기본 전략과 비교했습니다. 실험은 Llama-3.1, Mistral-v0.3, Gemma-2 모델을 사용하여 다양한 데이터셋에서 수행되었습니다.

- **Performance Highlights**: 대부분의 경우, 무작위 샘플 선택이 우수한 성과를 보였으며, 패러프레이징이나 새로운 샘플 생성 방식 모두에서 크게 다르지 않았습니다. 특히 out-of-distribution 데이터에서는 샘플의 유사성에 따른 선택 전략이 가장 높은 성능을 발휘하는 것으로 나타났습니다.



### Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs (https://arxiv.org/abs/2410.10739)
- **What's New**: 이 연구는 대규모 언어 모델(Large Language Models, LLMs)의 지속적인 사전 학습과 지침 미세 조정이 서로 어떻게 연결되어 있는지를 탐구합니다. 특히 사전 학습이 지침 수행 능력에 미치는 영향을 다룹니다.

- **Technical Details**: 연구에서 사용된 LLM들은 LLaMa 3, LLaMa 3.1 및 Qwen 2, Qwen 2.5 모델군입니다. 연구는 지침 모델을 지속적으로 재학습하는 세팅과 기본 모델을 지속적으로 학습시키고 지침 미세 조정을 하는 세팅을 비교합니다.

- **Performance Highlights**: 지속적인 재학습이 지침 모델의 지침 수행 능력을 파괴한다는 것을 발견하였고, 이러한 작업은 피해야 한다는 결론을 내렸습니다. 반면 지속적으로 학습한 기본 모델에 지침 미세 조정을 수행함으로써 도메인 지식과 지침 능력을 모두 유지할 수 있음을 발견하였습니다.



### Large Language Models Are Active Critics in NLG Evaluation (https://arxiv.org/abs/2410.10724)
Comments:
          Submitted to ICLR2025

- **What's New**: 이 논문에서는 LLM(대형 언어 모델)을 '능동적인 비평가(Active Critics)'로 기능하게 하는 새로운 NLG(자연어 생성) 평가 프로토콜, Active-Critic을 소개합니다. 이 접근 방식은 기존의 수동적 평가 방식에서 벗어나, 데이터에서 필요한 평가 기준과 NLG 작업을 스스로 파악하고 평가 결정을 지원하는 자세한 설명을 생성하는 과정을 포함합니다.

- **Technical Details**: Active-Critic은 두 단계로 구성됩니다. 첫 번째 단계에서는 LLM이 타겟 NLG 작업을 추론하고 관련 평가 기준을 데이터에서 설정합니다. 두 번째 단계에서는 LLM의 프롬프트를 동적으로 최적화하여 좀 더 인간의 판단과 일치하는 점수를 낼 수 있게 돕고, 그 평가를 정당화하는 자세한 설명을 생성합니다.

- **Performance Highlights**: 4개의 NLG 평가 작업을 대상으로 한 실험 결과 Active-Critic이 기존의 최첨단 평가 방법들보다 인간의 판단과 더 강한 일치를 보였으며, 적은 양의 라벨링된 데이터로도 효과성과 설명 가능성을 강조합니다.



### Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues (https://arxiv.org/abs/2410.10700)
- **What's New**: 이 연구에서는 멀티턴(multi-turn) 상호작용에서의 대형 언어 모델(Large Language Models, LLMs)의 안전 취약점을 다룹니다. 악의적인 사용자가 여러 쿼리에서 해로운 의도를 숨기는 방법을 탐구하며, 새로운 공격 방법인 ActorAttack을 소개합니다.

- **Technical Details**: ActorAttack은 actor-network theory에서 영감을 받아, 의미적으로 연결된 actor의 네트워크를 모델링하여 다채롭고 효과적인 공격 경로를 생성합니다. 이 연구는(1) benign한 대화 주제를 통해 해로운 의도를 숨기는 방법과 (2) 동일한 해로운 대상으로 향하는 다양한 공격 경로를 발견하는 두 가지 도전을 다룹니다.

- **Performance Highlights**: 실험 결과, ActorAttack은 여러 가지 정렬된 LLMs에서 기존 단일 턴 및 멀티턴 공격 방법을 능가하며, 특히 GPT-o1에서도 높은 품질의 공격을 발견합니다. ActorAttack을 통해 생성된 데이터셋인 SafeMTData가 LLMs의 안전성을 높이는 데 기여함을 보여주고 있습니다.



### Building a Multivariate Time Series Benchmarking Datasets Inspired by Natural Language Processing (NLP) (https://arxiv.org/abs/2410.10687)
- **What's New**: 시간 시계열 분석을 위한 새로운 벤치마크 데이터셋 생성 접근법이 소개됩니다. 이 논문은 자연어 처리(NLP)에서의 벤치마크 데이터셋 생성 방법론을 기반으로 하며, 시계열 데이터의 독특한 도전에 적합하도록 이를 조정합니다.

- **Technical Details**: 이 연구에서는 M4 대회 데이터셋과 전력 소비 데이터셋(ECL)을 벤치마크 자료로 활용하여 시간 시계열 모델의 예측 성능을 평가합니다. 또한 다양한 도메인에서의 128개의 단변량 및 30개의 다변량 데이터셋을 포함하는 UEA 및 UCR 시간 시계열 분류 데이터셋을 제안합니다. 또한 Yahoo의 웹 트래픽을 기반으로 한 1600만 개 레이블된 시계열 데이터를 anomaly detection 벤치마크로 사용합니다.

- **Performance Highlights**: 제안된 방법은 시간 시계열 모델의 예측 및 anomaly detection 능력을 한층 높일 것으로 기대되며, 멀티태스크 학습(multi-task learning) 전략을 통해 성능 향상에 기여할 것입니다. 이 연구는 시계열 분석 및 모델링의 최첨단을 발전시키는 데 중요한 기여를 할 것입니다.



### Large Language Model Evaluation via Matrix Nuclear-Norm (https://arxiv.org/abs/2410.10672)
Comments:
          22 pages

- **What's New**: 본 논문에서는 대형 언어 모델(LLM)의 정보를 압축하고 중복성을 줄이는 능력을 평가하기 위한 새로운 효율적인 지표인 Matrix Nuclear-Norm을 제안합니다. 이 지표는 Matrix Entropy의 계산 복잡도를 감소시켜 LLM의 성능을 더욱 효과적으로 평가할 수 있게 합니다.

- **Technical Details**: Matrix Nuclear-Norm은 데이터 압축 능력을 정량화하는 지표로, 행렬의 랭크(rank)의 볼록 근사(convex approximation)를 제공하여 예측 구분력(predictive discriminability)과 다양성을 포착합니다. 이 방법은 L_{1,2}-norm을 사용하여 핵 노름(nuclear norm)을 추가적으로 근사하며, 시간 복잡도를 O(n^3)에서 O(n^2)로 줄입니다.

- **Performance Highlights**: Matrix Nuclear-Norm은 CEREBRAS-GPT 모델에서 Matrix Entropy보다 8배에서 24배 빠른 평가 속도를 기록하였으며, 다양한 모델들에 대한 평가를 통해 신뢰성과 확장성이 뛰어난 도구로 확인되었습니다.



### Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers (https://arxiv.org/abs/2410.10665)
Comments:
          Project GitHub repository at this https URL

- **What's New**: 이 논문은 대규모 언어 모델(LLMs)이 개발도상국의 경제에 기여할 수 있는 가능성을 제시하면서도, 실제로는 영어 사용자에게 유리한 경향이 있음을 강조합니다.

- **Technical Details**: FLORES-200, FLORES+, Ethnologue 및 World Development Indicators 데이터를 분석하여, 저소득 및 중저소득 국가의 언어 사용자들은 OpenAI의 GPT 모델을 API를 통해 사용할 때 더 높은 비용을 지불해야 함을 알렸습니다. 토큰화(tokenization) 프로세스에 의해 이러한 비용 차이는 1.5억 명에 달하는 사용자가 영어 사용자보다 4배에서 6배 높은 비용을 부담하게 된다는 점에서 심각합니다.

- **Performance Highlights**: 저자들은 번역 작업의 질을 기준으로 LLM이 저자원(low-resource) 언어에서 낮은 성능을 보이며, 이는 높은 비용과 낮은 성능이라는 이중의 위협(double jeopardy)에 해당함을 보여줍니다. 이러한 토큰화에서의 분열(fragmentation)이 기후에 미치는 직접적인 영향도 논의되었습니다.



### Generative AI and Its Impact on Personalized Intelligent Tutoring Systems (https://arxiv.org/abs/2410.10650)
Comments:
          Scientific Report (Under Review)

- **What's New**: Generative AI(생성 AI)가 Intelligent Tutoring Systems(ITS)에 통합되어 개인 맞춤형 교육을 위해 동적인 콘텐츠 생성, 실시간 피드백 및 적응형 학습 경로를 가능하게 합니다.

- **Technical Details**: 대형 언어 모델(LLM, Large Language Models)인 GPT-4를 활용하여 자동 질문 생성, 맞춤 피드백 메커니즘 및 개별 학습자의 요구에 응답하는 대화 시스템을 구현합니다. 이 시스템들은 교육내용의 정확성, AI 모델의 고유 편향 완화, 학습자 참여 유지와 같은 중요한 도전 과제에 직면해 있습니다.

- **Performance Highlights**: Generative AI는 더 개인화되고 적응적인 학습 경험을 제공하여 학습자의 참여와 이해를 높입니다. 예를 들어, LLM은 학생의 이전 응답에 따라 적절한 난이도의 맞춤 질문을 생성하고, 실시간으로 깊이 있는 피드백을 제공합니다.



### Thinking LLMs: General Instruction Following with Thought Generation (https://arxiv.org/abs/2410.10630)
- **What's New**: 본 논문에서는 기존의 LLM(대형 언어 모델)에게 '사고' 능력을 부여하기 위한 새로운 훈련 방법을 제안합니다. 이 방법은 기존 모델을 추가적인 인간 데이터 없이도 복잡한 명령을 따르는 데 필요한 사고 과정을 생성하고 최적화하는 방법입니다.

- **Technical Details**: 우리는 사고 선호 최적화(Thought Preference Optimization, TPO)라는 메서드를 통해 LLM이 응답하기 전에 내부적으로 사고하도록 훈련합니다. 이 방법은 여러 번의 탐색 및 최적화를 통해 이루어지며, AI 피드백으로부터 강화 학습(Reinforcement Learning from AI Feedback, RLAIF) 방식을 채택합니다. 이는 모델이 주어진 명령에 대해 사고를 기록하고, 그에 따라 응답을 생성하도록 합니다.

- **Performance Highlights**: 이 연구의 결과는 AlpacaEval와 Arena-Hard 벤치마크에서 각각 52.5%와 37.3%라는 우수한 성과를 나타냈습니다. 특히, 사고를 통한 성과 향상은 전통적인 문제 해결 및 추론 작업뿐만 아니라 일반 지식, 마케팅 및 건강 분야 등 비추론 카테고리에서도 확인되었습니다.



### Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts (https://arxiv.org/abs/2410.10626)
- **What's New**: 이 논문에서는 의료 관련 Large Language Models(LLMs)를 저자원 언어에 맞추기 위한 방법으로, 고품질의 의료 데이터셋을 구성하고 그 데이터를 통해 다국어 LLMs의 일반화 능력을 향상시키는 새로운 접근법을 제안합니다. 특히 Mixture of Experts(MoE) 모델 구조를 활용하여 언어별 전문가와 다국어 라우팅을 적용하는 방법을 연구합니다.

- **Technical Details**: 이 연구는 먼저 12개 주요 언어로 구성된 고품질의 의료 데이터셋을 구축하고 그 정확성을 분석합니다. MoE 라우팅 방법을 제안하여, 초기 레이어에서는 서로 다른 언어 간의 정보 흐름을 집중시키고 후반 레이어에서는 언어별 차별화를 발생시키는 'Spread Out in the End' 정보 흐름 메커니즘을 밝혀냈습니다. 새로운 Post-MoE 아키텍처는 후반 레이어에서만 희소 라우팅을 적용하여 다국어 모델의 일반화를 개선합니다.

- **Performance Highlights**: 실험 결과, 제안된 접근법은 12개 주요 언어에 대해 안정적인 성능을 보여주며, 저자원 언어에 대해서는 추가적인 학습 없이도 향상된 성능을 나타냈습니다. 또한, 언어 군 전문가(concept of language family experts)를 도입하여 50개 언어로 모델을 확장할 수 있는 가능성을 보여주며, 추가 파라미터 없이도 다국어 일반화를 유지하는 것을 증명했습니다.



### SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition (https://arxiv.org/abs/2410.10624)
- **What's New**: 이 논문은 저자들이 휴대용 센서 기술과 개인화된 AI 비서 간의 격차를 해소하기 위해 Large Language Models (LLMs)를 활용하여 시간-시계열 (time-series) 작업을 이해하도록 하는 방법을 제시합니다. 특히, Human Activity Recognition (HAR) 작업에 LLM의 가능성을 활용하고자 합니다.

- **Technical Details**: SensorLLM이라는 새로운 두 단계의 프레임워크를 통해 첫 번째 단계인 Sensor-Language Alignment에서 각 센서 채널을 위한 특별한 토큰을 도입하고, 센서 데이터를 텍스트로 자동 생성하여 정렬합니다. 두 번째 단계인 Task-Aware Tuning에서는 LLM의 파라미터를 고정한 채로 HAR 분류를 위해 모델을 세분화하여 최첨단 모델들과 경쟁하는 성능을 달성합니다.

- **Performance Highlights**: SensorLLM은 HAR 작업에서 기존 최첨단 (SOTA) 모델들과 동등하거나 이를 초과하는 성능을 기록하며, 다양한 데이터셋을 위한 일반화 능력을 입증합니다. 이 연구는 센서 데이터 분석 및 HAR 작업에 대한 새로운 접근법을 제시하며, 미래의 시간-시계열 및 텍스트 정렬 연구의 초석이 될 것입니다.



### T\"ubingen-CL at SemEval-2024 Task 1:Ensemble Learning for Semantic Relatedness Estimation (https://arxiv.org/abs/2410.10585)
Comments:
          5 pages

- **What's New**: 이 논문은 SemEval-2024 Task 1에 참여하는 팀의 시스템을 소개하며, 문장 쌍의 관련성을 예측하는 데 중점을 둡니다. 이 연구는 의미적 관련성이 문장 유사성보다 더 포괄적인 개념이라는 가정 아래, 각종 특징을 활용하여 관련성을 추정하는 방법을 제안합니다.

- **Technical Details**: 이 연구에서는 다양한 시스템(시각적 특성, 딥 러닝 모델의 출력 등을 포함)으로부터의 결과를 통합하는 앙상블(ensemble) 접근 방식을 채택하여 의미적 관련성을 평가합니다. 연구는 통계적 텍스트 특성, 대규모 언어 모델, 워드 임베딩 모델 및 의미 레이블이 있는 데이터셋에 기반한 모델을 포함한 여러 출처에서 특징을 추출합니다.

- **Performance Highlights**: 연구 결과, 앙상블 모델이 개별 시스템보다 우수한 성능을 보이는 것을 발견했으며, 다양한 소스들로부터 추가 정보를 활용함으로써 의미적 관련성을 더 정확하게 추정할 수 있음을 확인했습니다.



### Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation of Code-Mixed Sentences (https://arxiv.org/abs/2410.10580)
Comments:
          Manuscript submitted to COLING 2025

- **What's New**: 코드 혼합(code-mixing)된 문장 생성을 위한 새로운 방법인 Controlled Generation을 제안합니다. 이 방법은 코드 혼합 정도(Code-Mixing Degree, CMD)를 파라미터화하여 주어진 영어 문장에서 의미적으로 동등한 여러 가지 코드 혼합 문장을 생성할 수 있게 합니다.

- **Technical Details**: 또한, 새로운 평가 지표인 GAME(골드 스탠다드 비독립적 평가 지표)를 소개합니다. GAME는 언어와 골드 스탠다드에 비독립적이며, 다른 지표들과 달리 평가를 위한 코드 혼합된 문장에 대해 골드 스탠다드를 필요로 하지 않아서 인간 주석자가 필요 없습니다. 이 지표는 의미적으로 동등한 코드 혼합 문장을 평가할 때, BLEU 점수보다 낮은 표준 편차를 보입니다.

- **Performance Highlights**: 4개 언어 쌍(영어-{힌디어, 벵골어, 프랑스어, 스페인어})에 대한 골드 스탠다드 코드 혼합 문장 데이터셋을 생성하고 공개하여 코드 혼합에 대한 더 많은 계산 연구를 유도합니다.



### Recipe for Zero-shot POS Tagging: Is It Useful in Realistic Scenarios? (https://arxiv.org/abs/2410.10576)
Comments:
          To appear at the 4th Multilingual NLP workshop collocated with EMNLP 2024

- **What's New**: 본 논문은 데이터가 제한된 언어에 대한 Part-of-Speech (POS) 태깅을 위한 접근 방식을 제안합니다. 특히, 라벨이 없는 훈련 데이터를 사용하지 않고도 POS 태깅 모델을 교육할 수 있는 데이터 세트의 특성을 규명합니다. 이를 위해 mBERT라는 다국어 대형 언어 모델을 활용하여 제로샷(zero-shot) 접근법을 비교 분석합니다.

- **Technical Details**: 제안된 방법은 다국어 사전 훈련된 언어 모델인 mBERT를 사용하여, 대상 언어에 대해 훈련된 관련언어(서포트 언어) 데이터로 제로샷 POS 태깅 모델을 미세 조정합니다.研究된 언어는 아프리칸스어와 그와 관련된 네덜란드어, 독일어, 영어를 포함하고, 파로에제어 및 상부 소르비아어와 같은 추가 저자원 언어에도 적용합니다.

- **Performance Highlights**: 모델 실험 결과, 서포트 언어가 다수 일 경우 질 높은 데이터 세트가 더 나은 성능을 보이는 것으로 나타났습니다. 특히, 가장 관련이 깊은 언어를 사용할 경우, 제한된 양의 훈련 문장에서도 높은 정확도를 달성합니다. 제로샷 모델은 극단적으로 저자원 언어에서도 유효한 옵션으로 확인되었습니다.



### Is Structure Dependence Shaped for Efficient Communication?: A Case Study on Coordination (https://arxiv.org/abs/2410.10556)
Comments:
          CoNLL 2024

- **What's New**: 이 논문은 구조 의존성이 효율적인 의사소통을 어떻게 구현하는지 검토하며, 기존의 국소적인 언어 범위를 넘어서는 추상적인 언어 지식의 설명을 다룹니다.

- **Technical Details**: 연구는 세 가지 유형의 인공 언어를 설계했습니다: (i) 구조 의존적 축소 작업을 가진 언어, (ii) 축소 작업이 없는 언어, (iii) 선형 축소 작업을 가진 언어. 이러한 언어들의 의사소통 효율성을 정량화하였습니다.

- **Performance Highlights**: 구조 의존적 축소 작업을 가진 언어는 다른 가상 언어들에 비해 유의미하게 더 높은 의사소통 효율성을 나타냈습니다. 이는 인간 언어의 구조 의존적 특성도 효율적인 의사소통의 관점에서 설명될 수 있음을 시사합니다.



### Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models (https://arxiv.org/abs/2410.10542)
Comments:
          Accepted on NLLP at EMNLP 2024

- **What's New**: 본 연구에서는 인도의 법원 판결 예측을 위한 실제 시나리오를 탐구하고, InLegalBERT, BERT, XLNet과 같은 다양한 transformer 기반 모델과 LLMs인 Llama-2 및 GPT-3.5 Turbo를 활용합니다. 사례가 재판을 위해 제시될 때 순간적인 정보를 기반으로 한 판결 예측을 시도하며, 후향적 분석 없이 실제 상황을 모방합니다.

- **Technical Details**: transformer 모델의 효율성을 평가하고 법적 사실의 요약을 통해 예측 품질을 향상시키는 방법을 실험합니다. 계층적 transformer 모델을 도입하여 판결 사실을 최적화하고, 법령, 판례, 주장과 같은 추가적인 법적 정보를 포함하여 LLMs의 성능을 개선합니다. 이 연구는 GPT-3.5 Turbo가 인도의 법적 판결 예측에서 뛰어난 성능을 보이는 것을 발견했습니다.

- **Performance Highlights**: 자동 평가 및 인간 평가 모두에서 LLMs가 전문가 수준의 성능에 도달하지 못했음을 보이며, 판결 예측과 설명 품질 모두에서 개선의 여지가 있음을 시사합니다. Clarity와 Linking이라는 두 가지 새로운 평가 지표를 정의하여 LLM이 생성한 예측 및 설명의 품질을 평가합니다.



### Everyday Speech in the Indian Subcontinen (https://arxiv.org/abs/2410.10508)
Comments:
          5 Pages, 1 Figure, Submitted to ICASSP 2025

- **What's New**: 이번 논문에서는 다국어 음성 합성을 위한 Common Label Set (CLS)의 개발을 소개합니다. 이는 다양한 언어의 발음을 아우르기 위해 음성학에 기초하여 만들어졌습니다.

- **Technical Details**: 글로벌 합성기 (synthesizer)가 E2E 프레임워크 (End to End framework)에서 대량의 어휘 (vocabulary) 필요성을 줄임으로써, 음성 합성과 음소 규칙이 다른 언어 간의 연계성을 가능하게 합니다. CLS로 변환된 인도 언어 텍스트는 해당 언어의 음소 규칙과 일치하는 합성기를 통해 처리됩니다.

- **Performance Highlights**: 상대적인 음질 (quality)에서 고대 인도 언어인 산스크리트어 (Sanskrit)와 콘카니어 (Konkani)에서 0개의 적응 데이터 (adaptation data)로도 원어민 (native speaker) 수준의 음성 품질을 달성하였습니다. 또한 13개의 인도 언어 및 영어 간의 코드 스위칭 (code switching)이 원활하게 이루어질 수 있습니다.



### Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation (https://arxiv.org/abs/2410.10489)
- **What's New**: 이 연구는 LLM의 성능이 특정 언어의 디지털 데이터 가용성과 어떤 관련이 있는지를 분석하였습니다. 연구 결과, GPT-4o가 특정 국가의 사회적 가치를 반영하는 능력의 44%가 해당 언어의 디지털 자원과 상관관계가 있었다고 밝혀졌습니다. 이는 디지털 자원이 부족한 언어에서 성능 저하를 초래하고, 특히 Global South(글로벌 남반구) 국가에서는 디지털 격차를 악화시킬 우려가 있습니다.

- **Technical Details**: 연구는 21개 국가-언어 쌍을 포함하여 94개의 설문 질문으로 구성된 대규모 데이터셋을 개발하였습니다. GPT-4o 모델은 특히 비영어 언어 처리에서 크게 개선되었으며, 새로운 tokenizer(토크나이저)의 도입으로 비영어 언어에 대한 효율성이 향상되었습니다. 이 모델은 또한 LRLs(low-resource languages)에서의 사회적 가치의 반영 정확성을 증가시킵니다.

- **Performance Highlights**: GPT-4o의 비영어 언어 퍼포먼스는 이전 모델에 비해 더 안정적으로 향상되었으며, 특히 Hindi에서는 토큰이 2.9배 감소하는 등의 성과를 보였습니다. 다국어 이해(STEM) 성능을 평가한 결과, 여러 저자들은 비영어 언어에서도 향상된 성과를 보고했으며, 특히 Swahili, Latvian, Welsh 등 저자원 언어에서 긍정적인 결과를 도출하였습니다.



### Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification? (https://arxiv.org/abs/2410.10476)
- **What's New**: 본 연구에서는 7개의 오픈 및 클로즈드 소스의 Large Language Models (LLM)의 Temporal Relation Classification (TRC) 작업에서의 성능과 의사 결정 과정을 조사하였습니다.

- **Technical Details**: 이 작업에서는 예시 레이블을 활용한 In-Context Learning (ICL) 접근법과 Low-Rank Adaptation (LoRA) 기법을 사용하여 Llama2 모델을 세부 조정하여 성능을 측정했습니다. LLM의 자가 회귀적인 성질로 인해 마지막 부분에 집중하는 경향을 확인했습니다.

- **Performance Highlights**: 결과적으로, LLM들은 기존의 RoBERTa 기반의 소형 인코더 전용 모델에 비해 TRC 작업에서 성능이 저조하였고, 이는 LLM의 구조적 제한 때문으로 분석되었습니다.



### Ada-K Routing: Boosting the Efficiency of MoE-based LLMs (https://arxiv.org/abs/2410.10456)
Comments:
          Coauthors do not reach a consensus on submitting the current version

- **What's New**: 이 논문에서는 동적인 Ada-K 라우팅 전략을 제안하여 특정 토큰에 대해 활성화된 전문가의 수를 조정함으로써 계산 효율성과 모델 성능의 균형을 개선합니다.

- **Technical Details**: Ada-K 라우팅 전략은 학습 가능한 경량 할당기 모듈을 통합하여 각 토큰의 맥락적 필요에 맞춘 전문가 자원 할당을 결정합니다. 이 할당기는 완전히 플러그 가능하여 모든 주요 MoE 기반 LLM에 광범위하게 적용할 수 있도록 설계되었습니다. Proximal Policy Optimization (PPO) 알고리즘을 활용하여 비미분 가능 결정 체계를 위한 엔드 투 엔드 학습 과정을 가능하게 합니다.

- **Performance Highlights**: Ada-K 라우팅 방법은 기존의 Top-K 라우팅보다 유의미한 성능 향상을 보여주며, FLOPs를 25% 이상 줄이고 추론 속도도 20% 이상 향상시킵니다. Mixtral-8x22B와 같은 140B 이상의 파라미터를 가진 MoE 기반 LLM의 경우, 훈련 시간은 8시간으로 제한됩니다. 상세 분석 결과, 어려운 작업, 중간 레이어 및 콘텐츠 단어가 더 많은 전문가를 활성화하는 경향을 보였습니다.



### QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios (https://arxiv.org/abs/2410.10449)
Comments:
          accepted at EMNLP 2024 (main)

- **What's New**: 이번 연구에서는 QUITE라는 새로운 질문 응답 데이터 세트를 소개했습니다. 이 데이터 세트는 실세계의 베이즈 추론 시나리오에서 카테고리형 랜덤 변수를 사용하여 더 복잡한 관계를 모델링합니다.

- **Technical Details**: QUITE 데이터 세트는 고품질의 자연어로 표현된 전제와 증거 진술을 제공합니다. 이 데이터 세트는 베이즈 네트워크의 다양한 추론 유형(인과 추론, 증거 추론, 설명 제거)에 대한 평가를 우선적으로 하며, 기존 데이터 세트와 달리 이론적 기반에 기반한 추론 메커니즘을 활용합니다.

- **Performance Highlights**: 논문에서 제시한 실험 결과는 논리 기반 모델이 기존의 대규모 언어 모델보다 모든 추론 유형에서 성능이 우수하다는 것을 보여줍니다. 특히, 신경-상징적 모델(neuro-symbolic models)이 복잡한 추론을 향상시키는 유망한 방향이라는 점에서 의미가 있습니다.



### Medico: Towards Hallucination Detection and Correction with Multi-source Evidence Fusion (https://arxiv.org/abs/2410.10408)
Comments:
          12 pages, 3 figures, 6 tables. Accepted by EMNLP 2024's demo track

- **What's New**: 새로운 연구인 Medico는 다원적 증거 융합(Multi-source evidence fusion)을 통한 환각 감지 및 수정 프레임워크입니다. 이는 LLMs(대형 언어 모델)의 환각 문제를 해결하기 위해 다양한 출처에서 증거를 수집하고, 생성된 콘텐츠가 사실 오류를 포함하는지 여부를 탐지하여 그 판단의 이유(rationale)를 제공하고, 반복적으로 환각된 내용을 수정합니다.

- **Technical Details**: Medico 프레임워크는 세 가지 주요 구성 요소로 이루어져 있습니다: (1) 다원적 증거 융합(Multi-source Evidence Fusion) - 여러 출처에서 다양한 증거를 수집합니다; (2) 증거 기반 환각 감지(Hallucination Detection with Evidence) - 융합된 증거를 활용하여 LLMs의 생성된 콘텐츠를 확인하고 판단의 이유를 제시합니다; (3) 이유에 기반한 환각 수정(Hallucination Correction with Rationale) - 분류 결과가 잘못된 경우, 이유에 따라 환각된 콘텐츠를 반복적으로 수정합니다. 이를 통해 Medico는 설명 가능성(explainability)을 제공하며, 모델 무관(model-agnostic)하므로 다양한 LLMs에 적용 가능합니다.

- **Performance Highlights**: Medico는 증거 검색(evidence retrieval)에서 0.964 HR@5 및 0.908 MRR@5, 환각 탐지(hallucination detection)에서 0.927-0.951 F1, 환각 수정(hallucination correction)에서 0.973-0.979 승인율(approval rate)을 기록하며 뛰어난 성능을 입증했습니다.



### MMCFND: Multimodal Multilingual Caption-aware Fake News Detection for Low-resource Indic Languages (https://arxiv.org/abs/2410.10407)
- **What's New**: 본 연구에서는 다중 모달(multi-modal) 및 다국어(multilingual) 데이터를 활용한 인디크 언어(Indic languages) 기반의 가짜 뉴스 탐지 시스템을 제안합니다. 이를 위해, 28,085개의 인스턴스를 포함한 Multimodal Multilingual dataset for Indic Fake News Detection (MMIFND)을 구축하였습니다.

- **Technical Details**: 제안된 방법론은 Multimodal Multilingual Caption-aware framework for Fake News Detection (MMCFND)로, 이는 시각 정보와 언어 정보의 관계를 정렬하는 기초 모델에서 사전 훈련된 unimodal encoders와 pairwise encoders를 사용하여, 뉴스 기사의 시각적 및 텍스트 구성 요소에서 깊은 표현을 추출합니다. 생성된 이미지 캡션은 추후 가짜 뉴스 탐지에 핵심적인 추가 컨텍스트를 제공합니다.

- **Performance Highlights**: MMIFND를 통해 실시한 철저한 실험 결과, 제안된 프레임워크가 기존의 가짜 뉴스 탐지 기법들을 능가하는 성능을 보임을 증명했습니다. 이는 인디크 언어에서의 자동화된 가짜 뉴스 탐지 시스템 개발에 기여할 수 있습니다.



### BookWorm: A Dataset for Character Description and Analysis (https://arxiv.org/abs/2410.10372)
Comments:
          30 pages, 2 figures, EMNLP 2024 Findings

- **What's New**: 이 연구에서는 복잡한 내러티브와 수많은 등장인물이 포함된 장편 문학 작품에서 등장인물을 이해하는 데 초점을 맞추고 있습니다. 'BookWorm'이라는 새로운 데이터셋을 도입하여 캐릭터 설명과 분석을 통해 등장인물의 발전과 사회적 맥락을 이해하는 여러 과제를 수행합니다.

- **Technical Details**: 우리는 두 가지 과제를 정의합니다: 등장인물 설명(character description)과 등장인물 분석(character analysis). BookWorm 데이터셋은 Gutenberg Project에서 도서와 관련된 인간 작성 설명과 분석을 쌍으로 구성합니다. 우리는 최첨단 long-context 모델의 성능을 평가하고, 데이터셋을 이용해 retrieval-based 접근 방식이 더 효과적임을 발견했습니다. 다양한 기법을 통해 캐릭터 정보를 검색하고, hierarchical 처리 방식보다 retrieval 기반 모델이 두 작업 모두에서 더 나은 성능을 발휘한다는 것을 입증했습니다.

- **Performance Highlights**: 조정(fine-tuned)된 모델을 사용한 경우, coreference 기반 retrieval 방식이 가장 사실적인 설명을 생성하는 것으로 나타났으며, 이는 사실(fact) 및 함축(entailment) 기반 메트릭을 통해 측정되었습니다. 본 연구는 장편 내러티브 이해에 대한 추가 연구를 촉진할 것이란 기대를 표현하고 있습니다.



### Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning (https://arxiv.org/abs/2410.10360)
- **What's New**: 이번 연구에서는 Retrieval-Augmented Generation (RAG) 접근 방식을 사용하여 대규모 언어 모델(LLMs)의 환상 생성과 지식 노후화 문제를 해결하기 위한 새로운 프레임워크인 Parenting을 제안합니다.

- **Technical Details**: Parenting은 LLM의 파라미터 공간 내에서 adherence와 robustness를 분리하는 방법론으로, forward activation gain을 기반으로 한 주요 파라미터 검색 기법을 활용하여 두 요소와 강히 연결된 중요한 파라미터 유닛을 식별하고 고립시킵니다. 이후 각기 다른 능력을 가진 파라미터 유닛에 대해 특화된 미세 조정 방법을 적용하여 균형 잡힌 adherence와 robustness의 향상을 목표로 합니다.

- **Performance Highlights**: 다양한 데이터셋과 모델을 대상으로 한 광범위한 실험을 통해 Parenting의 효과성과 일반화 가능성이 입증되었습니다.



### LLM-based Code-Switched Text Generation for Grammatical Error Correction (https://arxiv.org/abs/2410.10349)
- **What's New**: 이 연구는 다국어 대화에서 코드 스위칭(Code-Switching, CSW)이 자연어 처리(Natural Language Processing, NLP)와 문법 오류 수정(Grammatical Error Correction, GEC) 시스템에 도전이 되고 있음을 강조합니다. 특히, 영어를 제2외국어로 배우는 학습자를 대상으로 한 CSW 데이터셋을 활용하여 GEC 시스템의 성능을 평가하고, 데이터 부족 문제 해결을 위한 합성 데이터 생성 방법을 탐구하였습니다.

- **Technical Details**: 연구팀은 ESL 학습자로부터 수집된 진정한 CSW 데이터셋에 대해 최첨단 GEC 시스템의 성능을 평가하였고, GPT-3.5를 활용하여 고품질의 합성 CSW GEC 데이터를 생성하는 방법을 제안했습니다. 이 과정에서 다양한 코드 스위칭 메트릭을 사용하여 생성된 CSW 텍스트의 품질을 정량화하였습니다.

- **Performance Highlights**: GEC 시스템이 합성 CSW 데이터로 훈련된 결과 기존 시스템에 비해 현저한 성과 향상을 보여주었습니다. 이 연구는 ESL 학습자들을 위한 교육 기술을 제공하여 그들의 영어 문법적 정확성을 높이는 데 주력하고 있습니다.



### Augmenting In-Context-Learning in LLMs via Automatic Data Labeling and Refinemen (https://arxiv.org/abs/2410.10348)
- **What's New**: 이번 논문에서는 Chain of Thought (CoT) 및 In-Context Learning (ICL) 적용 시, Intermediate steps(중간 단계)가 포함된 시연(demonstrations)을 자동으로 생성하고 필터링 하는 Automatic Data Labeling and Refinement (ADLR) 방법을 제안합니다. ADLR을 통해 코드 기반의 테이블 QA 및 수학적 추론에서 최대 5.5%의 성능 향상을 달성하였습니다.

- **Technical Details**: ADLR은 수작업으로 제작된 소수의 예시(seed examples)를 시작점으로 하여 자동으로 중간 데이터를 생성하고, 이를 바탕으로 성과를 개선하는 방법론입니다. 이 과정은 세 가지 단계로 구성되며, 첫째로 초기 예시를 통해 중간 데이터를 생성하고, 둘째로 생성된 예시의 유용성과 난이도를 평가하여 필터링하며, 마지막으로 필터링한 데이터로 추론 프로토콜을 보강합니다.

- **Performance Highlights**: ADLR 기법을 적용하여 기존 알고리즘의 성능을 최대 5.5% 향상시켰으며, 코드와 알고리즘은 오픈소스로 제공되어 연구 커뮤니티가 직접 활용할 수 있도록 합니다.



### A Unified Approach to Routing and Cascading for LLMs (https://arxiv.org/abs/2410.10347)
- **What's New**: 이번 연구에서는 다양한 특정 작업에 맞춘 LLM(대형 언어 모델)의 선택 최적화 전략을 제안합니다. 특히, 라우팅(routing)과 캐스케이딩(cascading)의 장점을 결합한 새로운 접근법인 캐스케이드 라우팅(cascade routing)을 소개하여 전체 성능을 극대화할 수 있는 방법을 찾아냈습니다.

- **Technical Details**: 연구에서는 라우팅과 캐스케이딩 전략을 선형 최적화 문제로 설명하고, 출력 품질을 최대화하는 동시에 주어진 비용 예산에 따르도록 최적의 전략을 유도합니다. 이전의 고정된 라우팅 전략과는 달리, 본 연구에서는 더 일반적인 확률적 라우팅 전략을 통해 더 나은 솔루션과 이론적 분석을 가능하게 합니다.

- **Performance Highlights**: 캐스케이드 라우팅 방식은 다양한 설정에서 라우팅과 캐스케이딩에 비해 일관되게 성능이 향상되었으며, RouterBench 벤치마크에서 1%에서 4%까지 성능을 개선하고, 기존의 나쁜 기준에 비해 13%에서 80%까지 추가적인 성능 향상을 기록했습니다.



### Locking Down the Finetuned LLMs Safety (https://arxiv.org/abs/2410.10343)
- **What's New**: 이번 논문에서는 대형 언어 모델(LLM)의 파인튜닝(fine-tuning) 과정에서 안전성을 확보할 수 있는 새로운 방법, SafetyLock을 제안합니다. 기존의 안전 정렬(safety alignment) 방식이 파인튜닝 중 발생할 수 있는 위험을 충분히 완화하지 못하는 문제를 해결하려는 노력이 돋보입니다.

- **Technical Details**: SafetyLock은 파인튜닝된 모델이 원래 모델과 유사한 안전 관련 활성화 표현을 유지한다는 발견을 바탕으로 하여, Meta-SafetyLock이라는 안전 편향 방향 세트를 추출합니다. 이 방향은 안전한 응답과 관련된 주요 활성화 패턴을 나타냅니다. SafetyLock은 여러 토큰 차원에서 활성화 방향을 탐색하여 우수한 강인성과 전달성을 달성합니다.

- **Performance Highlights**: 실험 결과, SafetyLock을 적용했을 때 유毒한 파인튜닝 모델에서 유해한 지침에 대한 응답 비율을 60%에서 1% 이하로 낮출 수 있었습니다. 이 방법은 기존의 전통적인 안전 유지를 위한 방식들보다 성능과 효율성 면에서 우수하며, 맞춤형 LLM의 안전성을 보장하는 확장 가능하고 비침습적인 솔루션을 제공합니다.



### Disentangling Hate Across Target Identities (https://arxiv.org/abs/2410.10332)
- **What's New**: 이번 연구에서는 혐오 발언(HS) 탐지기에 있어 특정 대상 정체성에 대한 편향과 감정 및 고정관념(속성)이 탐지기 성능에 미치는 영향을 정량적으로 분석했습니다. 특히, 기존의 HateCheck 및 GPT-HateCheck 데이터 세트를 활용하여 HS 예측에 영향을 미치는 다양한 요인에 대한 새로운 통찰을 제공합니다.

- **Technical Details**: 이 연구는 혐오 발언 탐지기 모델이 특정 대상 정체성의 언급에 따라 더 높은 혐오 점수를 할당하는 경향이 있음을 보여줍니다. 또한 HS 탐지기는 부정적인 감정과 혐오성을 혼동하는 경향이 있으며, 이는 반발 발언이나 슬픔을 표현하는 게시물이 혐오적으로 분류되는 위험성을 내포하고 있습니다.

- **Performance Highlights**: 연구 결과는 HS 탐지기가 강한 고정관념에 대해서는 정확하게 예측하지만, 고정관념이 약한 경우에는 어려움을 겪는다는 것을 나타냅니다. 더불어 감정과 고정관념의 분석은 HS 예측에 대한 중요한 통찰을 제공하며, HS 탐지기의 정확성과 공정성을 개선할 수 있는 새로운 방향을 제시합니다.



### MentalGLM Series: Explainable Large Language Models for Mental Health Analysis on Chinese Social Media (https://arxiv.org/abs/2410.10323)
- **What's New**: 이번 논문에서는 중국 소셜 미디어에서 정서적 건강 분석을 위한 첫 번째 다중 작업 해석 가능 정신 건강 지침 데이터셋(C-IMHI)을 소개합니다. 이 데이터셋은 9천 샘플로 구성되어 있으며 수동 검증을 통해 품질이 보장되었습니다. 또한, 정신 건강 분석을 위해 설계된 첫 번째 오픈 소스 LLM(MentalGLM 시리즈)을 제안하고 있습니다.

- **Technical Details**: MentalGLM 모델은 오픈 소스 LLM에서 파인튜닝하여 작성하였으며, 중국 소셜 미디어의 정신 건강 분석에 특화되어 있습니다. 데이터셋은 교사-학생 아키텍처를 사용하여 생성되었으며, 50K 개의 지침 학습을 통해 최적화되었습니다. 이러한 접근법은 두 단계의 파인튜닝 과정을 포함하며, 첫 단계에서 일반 정신 건강 데이터를 사용하고 두 번째 단계에서 중국 특정 소셜 미디어 데이터를 활용하여 정밀성과 설명 가능성을 높였습니다.

- **Performance Highlights**: 이 모델은 정신 건강 관련 세 가지 하위 작업에서 딥 러닝 모델, 일반화된 LLM 및 과제 파인튜닝된 LLM과 비교하여 향상된 성능을 기록했습니다. 특히, 전문가 검증을 통해 생성된 결정 설명이 높은 일관성과 신뢰성을 보였으며, 임상 자료에 대한 평가에서도 다른 LLM보다 예측 정확도가 뛰어난 것으로 나타났습니다.



### EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations (https://arxiv.org/abs/2410.10315)
Comments:
          10 pages, 2 figures

- **What's New**: 이 논문에서는 네트워크 자동화 작업을 위한 간단하고 경량화된 효율적인 Retrieval-Augmented Generation 프레임워크인 EasyRAG을 제안합니다. 이 프레임워크는 정확한 질문 응답, 간단한 배포, 효율적인 추론의 세 가지 장점을 가지고 있습니다.

- **Technical Details**: EasyRAG는 (1) 특정 데이터 처리 워크플로우, (2) 듀얼 라우트 스파스 리트리벌을 통한 코스 랭킹, (3) LLM 리랭커를 통한 재랭킹, (4) LLM 답변 생성 및 최적화를 통해 구성됩니다. 데이터 처리 단계에서 BeautifulSoup을 사용하여 HTML 문서에서 이미지 제목 및 텍스트를 추출하고, PP-OCRv4 모델을 통해 이미지에서 텍스트 콘텐츠를 추출하는 방법을 사용하였습니다. 이를 통해 6000개의 이미지 중 200개 미만으로 필터링할 수 있었습니다.

- **Performance Highlights**: GLM4 트랙에서 1차 예선에서 1위, 준결승에서 2위를 차지한 성과를 보여주며, 모든 구성 요소에 쉽게 통합될 수 있는 효율적인 추론 가속화 방안을 설계하여 RAG의 추론 대기 시간을 크게 줄였습니다.



### A Comparative Study of Translation Bias and Accuracy in Multilingual Large Language Models for Cross-Language Claim Verification (https://arxiv.org/abs/2410.10303)
Comments:
          Accepted to ATTRIB @ NeurIPS 2024

- **What's New**: 이 연구는 15개 언어의 다국어 Large Language Models (LLMs)가 잘못된 정보에 대한 사실 확인에 얼마나 효과적인지를 체계적으로 평가합니다. 특히, 번역 편향 및 크로스 링구얼(claim verification)의 효과성에 대한 새로운 통찰을 제공합니다.

- **Technical Details**: 연구에서 사용된 XFACT 데이터셋을 통해 두 가지 번역 방법인 pre-translation과 self-translation이 정확도 및 편향에 미치는 영향을 조사합니다. 연구는 Romance, Slavic, Turkic, Indo-Aryan, Kartvelian의 5개 언어 계통에서 각각의 언어별 정확도를 비교하기 위해 mBERT의 성능을 기준으로 설정합니다.

- **Performance Highlights**: 결과적으로, 자원이 부족한(low-resource) 언어는 훈련 데이터의 대표성이 낮아 직접 추론에서 상당히 낮은 정확도를 보이며, 대형 모델은 self-translation에서 우수한 성능을 나타내어 번역 정확도를 높이고 편향을 줄입니다. 이러한 결과는 균형 잡힌 다국어 훈련의 필요성을 강조하며, 특히 자원이 부족한 언어에서 신뢰할 수 있는 사실 확인 도구에 대한 형평성을 촉진할 필요성을 보여줍니다.



### Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspectiv (https://arxiv.org/abs/2410.10291)
Comments:
          Our benchmark and code are available at this https URL

- **What's New**: 인간의 지시를 정확히 해석하고 시각화하는 것은 텍스트-이미지(T2I) 합성에 매우 중요합니다. 그러나 현재 모델들은 단어 순서 변화에 따른 의미적 변화를 제대로 포착하지 못하고 있습니다. 이를 해결하기 위해, 우리는 SemVarEffect라는 새로운 메트릭과 SemVarBench라는 벤치마크를 제안합니다.

- **Technical Details**: SemVarEffect는 T2I 모델의 입력과 출력 간 의미적 변화의 인과관계를 평가하기 위해 설계되었습니다. 이는 언어적 변형을 통해 달성된 의미적 변화를 사용하여 모델의 출력에서 나타나는 변화량을 평가합니다. SemVarBench는 11,454개의 샘플로 구성된 고품질 벤치마크로, 10,806개 샘플이 훈련 세트, 648개가 시험 세트에 포함되어 있습니다.

- **Performance Highlights**: CogView-3-Plus와 Ideogram 2 모델이 최고 점수인 0.2/1을 기록했으나, 객체 관계의 의미적 변화에 대한 이해는 부족하여 0.07/1의 낮은 점수를 보였습니다. 우리는 T2I 모델들이 유의미한 의미적 변화를 처리하는 데에서 상당한 한계가 있으며, 추가적인 개선이 필요함을 발견했습니다.



### A Multi-Task Text Classification Pipeline with Natural Language Explanations: A User-Centric Evaluation in Sentiment Analysis and Offensive Language Identification in Greek Tweets (https://arxiv.org/abs/2410.10290)
Comments:
          Work In Progress

- **What's New**: 본 논문은 자연어로 예측 및 설명을 제공하는 텍스트 분류 작업을 위한 새로운 파이프라인 개념을 소개합니다. 이는 분류기(classifier)와 설명 생성기(explanation generator) 두 개의 모델로 구성되며, 이 모델들은 각각 텍스트를 레이블링하고 해당 레이블에 대한 설명을 제공하는 기능을 수행합니다.

- **Technical Details**: 제안된 파이프라인은 그리스어 트윗에서 감정 분석(sentiment analysis)과 공격적인 언어 인식(offensive language identification) 두 가지 텍스트 분류 작업에 대한 실험을 포함합니다. 이 작업에서는 그리스어 대형언어모델(Greek Large Language Model, LLM)을 사용하여 학습 세트의 각 인스턴스에 대한 설명을 생성합니다. 사용자의 주관적 연구(user study)는 설명계획의 성과를 세 가지 메트릭을 통해 평가합니다: Plausibility, Coherence 및 'Perfidiousness' 메트릭.

- **Performance Highlights**: 우리의 실험 결과는 충분한 양의 훈련 데이터가 제공될 때, 제안된 파이프라인이 적절한 설명을 생성할 수 있음을 보여주고, 다중 작업 모델(multi-task model)을 사용할 때 발생할 수 있는 성능 저하 없이 클래스 분류기의 성능을 유지할 수 있다는 것을 나타냅니다.



### Back-of-the-Book Index Automation for Arabic Documents (https://arxiv.org/abs/2410.10286)
- **What's New**: 이 연구는 아랍어 도서의 백서 색인(Back-of-the-book index) 추출 자동화를 통해 도서의 가독성을 향상시키고, 수작업으로 인한 오류를 줄이는 방법을 제안합니다.

- **Technical Details**: 각 인덱스 용어에 대해 관련 페이지에서 모든 가능한 명사구(Noun Phrases)를 추출하여 후보 풀을 정의합니다. 이 명사구는 품사 분석(Part-of-speech analysis)을 통해 식별되며 효율적인 검색을 위해 벡터 데이터베이스(Vector Database)에 저장됩니다. 우리는 정확한 일치(Exact Matches), 어휘 유사성(Lexical Similarity), 의미 유사성(Semantic Similarity) 등의 여러 메트릭을 사용하여 가장 적합한 발생Occurrences를 결정합니다.

- **Performance Highlights**: F1-score가 .966(정확도 Precision = .966, 재현율 Recall = .966)으로 매우 우수한 성능을 기록하였습니다. 이러한 결과는 백서 색인 생성 및 검토 자동화와 관련된 향후 연구에 대한 가능성을 열어줍니다.



### Machine Translation Evaluation Benchmark for Wu Chinese: Workflow and Analysis (https://arxiv.org/abs/2410.10278)
Comments:
          EMNLP WMT 24 Open Language Data Initiative Shared Task

- **What's New**: FLORES+ 데이터셋을 소개하며, 이는 현대 Wu Chinese 기계 번역 모델의 평가 벤치마크로 사용됩니다. 이 데이터셋은 기존 Wu 데이터와의 호환성을 보여줍니다.

- **Technical Details**: Wu Chinese는 만다린(Mandarin) 및 광둥어(Yue/Cantonese)와 같은 다른 한족(Sinitic) 언어와 상호 이해가 불가능하지만, 한자(Hanzi) 세트가 상당히 겹칩니다. Wu 사용자의 인구는 중국 내 언어 중 두 번째로 많지만, 특히 젊은 세대에서 사용량이 급격히 감소하고 있습니다.

- **Performance Highlights**: 우리의 기여로는 1) 오픈소스, 수작업으로 번역된 데이터셋, 2) 데이터셋 생성 및 검증 실험의 전체 문서화, 3) Wu Chinese 정규화 및 분할을 위한 초기 도구, 4) 데이터셋의 장점과 한계, 그리고 다른 저자원(low-resource) 언어에 대한 함의가 포함됩니다.



### BanglaQuAD: A Bengali Open-domain Question Answering Datas (https://arxiv.org/abs/2410.10229)
Comments:
          Accepted into LREC-COLING 2024, Turin, Italy

- **What's New**: 본 연구는 신규 벵골어 질의응답 데이터 세트 BanglaQuAD를 소개합니다. 이 데이터 세트는 벵골어 위키피디아 기사를 바탕으로 30,808개의 질문-답변 쌍으로 구성되어 있으며, 네이티브 스피커에 의해 주석이 달린 고품질 데이터를 제공합니다.

- **Technical Details**: BanglaQuAD는 12,000개 이상의 벵골어 위키피디아 기사에서 선택된 658개의 기사를 바탕으로 하며, 다양한 질문 유형과 변동하는 답변 길이를 포함합니다. 이를 위해 BnAnno라는 주석 도구가 개발되어 비구조적 텍스트를 SQuAD 형식으로 변환할 수 있도록 지원합니다.

- **Performance Highlights**: BanglaQuAD 데이터 세트는 87,482의 어휘를 포함하고 있으며, 평균 47개의 질문이 각 기사에서 생성됩니다. 실험 결과, BanglaBERT 및 IndicBERT와 같은 벵골어에 특화된 모델이 높은 성능을 보였습니다.



### QE-EBM: Using Quality Estimators as Energy Loss for Machine Translation (https://arxiv.org/abs/2410.10228)
- **What's New**: 이번 연구에서는 품질 추정기(quality estimator, QE)를 이용하여 학습 가능한 손실 네트워크를 구축하고, NMT(Neural Machine Translation) 모델로 직접 역전파 할 수 있는 QE-EBM 방식을 제안합니다. 이 방법은 기존의 강화학습(reinforcement learning) 접근 방식보다 더 효과적으로 번역 품질을 개선할 수 있습니다.

- **Technical Details**: QE-EBM은 품질 점수를 에너지 손실로 활용하고, QE 모델의 지식을 NMT 모델에 전달하기 위해 에너지 기반 훈련을 사용합니다. 이 연구에서는 QE-STATIC과 QE-DYNAMIC 두 가지 변형을 사용하며, 후자는 대비 학습(contrastive learning)을 통해 에너지 네트워크의 매개변수를 업데이트합니다. 실험은 영어를 출발어로 하여 자원 언어(target language)의 다양성을 테스트합니다.

- **Performance Highlights**: QE-EBM은 REINFORCE 및 proximal policy optimization (PPO), 감독된 세부 조정(supervised fine-tuning) 방법보다 우수한 성능을 발휘하며, 특히 자원 부족 언어에 대한 번역 품질이 향상되었습니다. 또한, 영어-몽골어 번역의 경우, BLEU(2.5), COMET-KIWI(7.1), COMET(5.3), 그리고 XCOMET(6.4)에서 향상을 보였습니다.



### ChakmaNMT: A Low-resource Machine Translation On Chakma Languag (https://arxiv.org/abs/2410.10219)
Comments:
          to be submitted in ACL findings 2025

- **What's New**: 이 연구는 Chakma 언어와 벵골어(Bengali) 간의 기계 번역(Machine Translation, MT) 모델 개발을 다루고 있습니다. 이 과정에서 15,021개의 병렬 샘플과 42,783개의 단일 언어 샘플로 구성된 새로운 데이터셋이 소개되었습니다.

- **Technical Details**: 연구팀은 NLP(자연어 처리)에서 전통적인 모델과 최신 모델을 적용하여 Chakma-Bangla (CCP-BN) 번역 작업을 진행했습니다. 특정 하이퍼파라미터 튜닝을 통해 BanglaT5 모델을 백-트랜스레이션(Back-Translation) 및 Chakma 언어의 음역(Transliteration) 사용으로 조정하였습니다.

- **Performance Highlights**: 최고의 BLEU 점수는 17.8 (CCP-BN) 및 4.41 (BN-CCP)로 나타났으며, 이는 Benchmark 데이터셋에서 얻은 결과입니다. 이 연구는 Chakma 언어에 대한 첫 번째 기계 번역 작업으로, 언어 자원의 격차를 해소하고 멸종 위기에 처한 언어 보존에 기여할 것으로 기대됩니다.



### SkillAggregation: Reference-free LLM-Dependent Aggregation (https://arxiv.org/abs/2410.10215)
- **What's New**: 이번 논문에서는 다수의 대형 언어 모델(LLM)을 이용하여 자연어 처리(NLP) 과제를 평가하는 새로운 방법인 SkillAggregation을 제안합니다. 이는 기존의 평가 방법들에서 나타나는 여러 한계를 극복하고, LLM의 예측을 결합하는 데 있어 보다 동적인 가중치를 부여합니다.

- **Technical Details**: SkillAggregation은 LLM 평가를 위한 새로운 집계 방법으로, Crowdlayer 기법을 확장하여 사용합니다. 이 방법은 추가 데이터나 레퍼런스 없이 LLM 판단을 결합하는 방법을 학습합니다. LLM들이 특정 질문을 처리할 때의 맥락 정보를 바탕으로 동적으로 가중치를 조정할 수 있도록 설계되었습니다.

- **Performance Highlights**: SkillAggregation은 HaluEval-Dialogue, TruthfulQA, Chatbot Arena와 같은 다양한 과제에서 기존의 Crowdlayer 기법보다 월등한 성능을 보여주었으며, 대부분의 과제에서 최상의 성능을 기록하였습니다.



### Minimum Tuning to Unlock Long Output from LLMs with High Quality Data as the Key (https://arxiv.org/abs/2410.10210)
- **What's New**: 최근 대형 언어 모델(LLMs)의 발전에도 불구하고, 긴 맥락을 처리하는 능력과 긴 출력을 생성하는 능력 간의 불균형이 여전히 존재합니다. 이 연구는 이러한 불균형의 주요 원인이 긴 출력에 대한 데이터 부족에 있다고 제안하며, 데이터 품질을 통해 모델을 조정하는 방법을 모색합니다.

- **Technical Details**: 모델은 인간 지향 모델(human-aligned model)에서 시작하여 고품질 데이터를 사용하여 조정됩니다. 실험 결과, 적은 양의 데이터로도 모델 성능을 효과적으로 향상시킬 수 있음을 보여줍니다. 평가 방법론으로는 LongBench-Write를 사용하며, 출력 길이와 품질을 평가하는 두 가지 지표, SL (Output Length Score)와 SQ (Output Quality Score)를 활용합니다.

- **Performance Highlights**: 단 4%의 훈련 데이터로도 기존의 긴 출력 모델과 유사한 성능 향상을 달성했으며, 고품질 데이터를 사용해 모든 실험한 모델에서 일관되게 개선된 결과를 관찰했습니다.



### Effi-Code: Unleashing Code Efficiency in Language Models (https://arxiv.org/abs/2410.10209)
Comments:
          Under Review

- **What's New**: Effi-Code는 코드 생성에서 효율성과 정확도를 동시에 향상시키는 새로운 접근 방식을 제안합니다. 이는 기존 연구들이 주로 코드의 정확성에 집중한 것과 다르게, 코드 생성의 효율성도 중요하게 여기는 데 초점을 맞추고 있습니다.

- **Technical Details**: Effi-Code는 Overhead Profiling에 기반한 Self-Optimization 프로세스를 도입하여, LLMs로부터 고품질의 정확하고 효율적인 코드 샘플의 데이터셋을 생성합니다. 이 데이터셋을 사용하여 다양한 LLM을 파인튜닝하고, 런타임 성능 지표 및 정확성 검사를 통해 생성된 코드를 반복적으로 수정하는 방법론을 사용합니다.

- **Performance Highlights**: DeepSeek-Coder-6.7B-Instruct의 pass@1은 43.3%에서 76.8%로 향상되었고, 동일한 정확성의 태스크에 대한 평균 실행 시간은 30.5% 감소하여 0.59초에서 0.41초로 줄어들었습니다. Effi-Code는 AI 시스템의 코드 생성 향상에 있어 확장 가능하고 일반화 가능한 방법을 제공하며, 소프트웨어 개발, 알고리즘 설계 및 계산 문제 해결에서 잠재적인 응용이 기대됩니다.



### Scalable Multi-Domain Adaptation of Language Models using Modular Experts (https://arxiv.org/abs/2410.10181)
Comments:
          14 pages, 5 figures, 3 tables

- **What's New**: 이번 연구에서는 MoDE(Modular Domain Experts)라는 새로운 아키텍처를 제안합니다. MoDE는 일반적인 Pre-trained Language Models(PLMs)에 모듈형, 도메인 전문 전문가(experts)를 추가하여 다중 도메인 적응 문제를 해결합니다.

- **Technical Details**: MoDE는 Mixture of Experts(MoE) 접근 방식을 기반으로 하며, 각 전문가가 여러 개의 transformer 레이어로 구성되어 있습니다. 각 전문가는 독립적으로 훈련되며, 가벼운 훈련 단계를 통해 협업하여 성능을 강화합니다. MoDE의 아키텍처는 유연한 sharding 구성으로 훈련 속도를 최대 38% 향상시킵니다.

- **Performance Highlights**: MoDE는 기존의 전체 매개변수 미세 조정(full parameter fine-tuning) 방법과 유사한 성능을 달성하면서 1.65% 더 좋은 정보 유지 성능을 보여주었습니다. 또한 MoDE는 여러 도메인에서 우수한 성능을 발휘하여 LoRA보다 1.4%, 전체 매개변수 미세 조정보다 0.6% 향상된 결과를 보였습니다.



### Diagnosing Hate Speech Classification: Where Do Humans and Machines Disagree, and Why? (https://arxiv.org/abs/2410.10153)
- **What's New**: 이 연구는 hate speech(증오 발언) 분류를 진단하기 위해 코사인 유사도 비율(cosine similarity ratio), 임베딩 회귀(embedding regression), 수동 재주석(manual re-annotation)을 활용했습니다. 연구진은 135,556개의 주석을 포함하는 'Measuring Hate Speech' 데이터 세트를 사용하여 증오 발언의 내용을 설명하는 기초적인 코사인 유사도의 사용을 보였습니다.

- **Technical Details**: 연구에서는 NV-Embed-v2라는 최신(pre-trained large language model) 대형 언어 모델을 통해 텍스트를 임베딩으로 변환하고 로지스틱 회귀(logistic regression)를 실행하여 증오 발언 분류기를 훈련시켰습니다. 이 분류기는 94%의 테스트 정확도를 달성했습니다. 또한, 기계가 인간 주석자와의 불일치 진단에서 인간보다 더 적은 실수를 범한다는 점을 발견했습니다.

- **Performance Highlights**: 연구 결과, 기계는 사실의 긴 문구를 올바르게 레이블링하는 데 더 잘 수행하지만, 짧은 비속어 인스턴스를 레이블링하는 데는 성능이 저하됩니다. 이는 모델 정렬(model alignment)에 기인하며, 이는 모델이 명백한 증오 발언을 생성하지 못하도록 방지하나 이러한 내용을 탐지하는 능력을 줄이는 것으로 설명됩니다.



### Jailbreak Instruction-Tuned LLMs via end-of-sentence MLP Re-weighting (https://arxiv.org/abs/2410.10150)
- **What's New**: 본 논문은 instruction fine-tuning된 large language models (LLMs)의 안전 메커니즘을 조사하고, MLP(다층 퍼셉트론) 뉴런의 재가중화가 모델의 안전성을 크게 저해할 수 있음을 발견하였습니다. 또한, 새로운 화이트박스 jailbreak 방법 2개를 제안합니다: 프롬프트-특정 방법과 프롬프트-일반 방법.

- **Technical Details**: 연구에서는 LLM의 안전성과 MLP 레이어 간의 관계에 주목했습니다. LLM이 종료 문장 추론 중에 유해성 평가를 할 때 MLP 레이어가 중요한 역할을 한다고 가정하였고, MLP 레이어의 뉴런 활성화를 재가중화하여 모델 안전성을 크게 저해할 수 있음을 실험적으로 입증하였습니다. 또한, 모델의 각 프롬프트에 맞게 최적화된 공격 방법과 미리 훈련된 일반화를 통해 모든 새로운 유해 프롬프트를 처리할 수 있는 방법을 개발하였습니다.

- **Performance Highlights**: 제안된 프롬프트-특정 방법은 기존의 최첨단 방법보다 더 나은 성능을 보였으며, 필요한 계산 시간도 적었습니다. 프롬프트-일반 방법은 기존 비슷한 접근법과 비교 가능하였으며, 모델의 기존 능력에 미치는 영향이 적었습니다. 이러한 결과들은 종료 문장 추론에서 MLP 레이어의 수정을 통해 모델의 안전성을 저해할 수 있음을 나타냅니다.



### Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation (https://arxiv.org/abs/2410.10141)
Comments:
          EMNLP 2024 Findings

- **What's New**: 이번 논문에서는 autoregressive (대규모) 언어 모델에서 추측 디코딩(speculative decoding)의 효율성에 미치는 디코딩 온도(decoding temperature)의 영향을 분석하였습니다. 복잡한 생성(configuration) 설정이 추측 디코딩의 성능에 크게 영향을 미치는 것을 강조하고 있습니다.

- **Technical Details**: 이 연구는 knowledge distillation (KD)을 중심으로 하여, 디코딩 온도가 추측 디코딩의 효과성에 미치는 영향을 탐구합니다. 여러 온도 설정에서 draft 모델의 성능을 평가하며, 특히 높은 온도에서의 효율성을 고려하여 새로운 데이터 중심의 전략을 제안합니다.

- **Performance Highlights**: 연구 결과, 디코딩 온도 0.2에서 최적의 속도 증가가 확인되었으며, KD가 높은 온도에서의 속도 저하를 완화하는 것으로 나타났습니다. 또한, 고온에서 디코딩 속도를 12% 향상시킬 수 있는 새로운 방법론을 제시하였습니다.



### Beyond-RAG: Question Identification and Answer Generation in Real-Time Conversations (https://arxiv.org/abs/2410.10136)
- **What's New**: 이번 논문에서는 고객 서비스 센터에서 평균 처리 시간(AHT)을 감소시키기 위한 새로운 의사결정 지원 시스템을 제안합니다. 이 시스템은 고객의 질문을 실시간으로 식별하고, 자주 묻는 질문(FAQ)과의 매칭을 통해 직접적으로 답변을 제공합니다. 또한 사전 설정된 FAQ가 없을 경우 역사적 대화 기록에서 FAQ를 자동으로 추출하는 LLM-기반 워크플로우를 도입했습니다.

- **Technical Details**: 본 시스템은 고객과 상담원 간의 상호작용을 통해 실시간으로 질문을 식별하고, 가장 관련성이 높은 질문을 제안합니다. 상담원이 질문을 선택하면, 해당 질문이 FAQ와 매칭될 경우 FAQ 데이터베이스에서 답변을 가져오고, 비FAQ 질문의 경우 RAG(검색 보강 생성) 모델을 이용해 답변을 생성합니다. Match 및 Generate라는 두 개의 스레드를 동시에 실행하여 관련 질문을 제안하며, 이를 통해 시간 소모를 줄이고 AHT를 감소시킵니다.

- **Performance Highlights**: Minerva CQ에 배포된 이 시스템은 운영 효율을 크게 향상시키고, AHT를 감소시키며, 운영 비용을 줄이는 성과를 보였습니다. 특히, 실시간으로 고객 질문을 식별하고 빠르고 정확한 답변을 제공하여 상담원의 생산성을 높이는 데 기여하고 있습니다.



### FormalAlign: Automated Alignment Evaluation for Autoformalization (https://arxiv.org/abs/2410.10135)
Comments:
          23 pages, 13 tables, 3 figures

- **What's New**: 이번 연구에서는 자연어(自然語)와 형식적 언어(形式的言語) 간의 정렬(Alignment)을 자동으로 평가하는 최초의 프레임워크인 FormalAlign을 소개합니다. 이 프레임워크는 기존의 Autoformalization(자동 형식화) 기법의 다수의 한계를 극복하고, 수동 검증(手動 錄證)의 필요성을 감소시킵니다.

- **Technical Details**: FormalAlign은 autoformalization 시퀀스 생성 작업과 입력(output)과 출력 간의 표현 정렬(Representational Alignment)을 학습합니다. 이 연구는 두 개의 상호 보완적(autoformalization과 alignment) 작업을 통합한 이중 손실(Dual Loss) 구조를 사용하여 모델의 성능을 극대화합니다.

- **Performance Highlights**: FormalAlign은 MiniF2F와 FormL4 벤치마크에서 GPT-4보다 훨씬 높은 성능을 보였습니다. 예를 들어, FormL4-Basic 데이터셋에서 Alignment-Selection Score가 99.21%로 GPT-4의 88.91%보다 11.58% 높은 결과를 기록했으며, MiniF2F-Valid에서 66.39%로 GPT-4의 64.34%보다 3.19% 향상되었습니다.



### How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspectiv (https://arxiv.org/abs/2410.10093)
Comments:
          EMNLP 2024 Main

- **What's New**: 본 연구에서는 오프라인 시연 데이터와 대규모 언어 모델을 효과적으로 정렬하는 새로운 일반화 자기 모방 학습(Generalized Self-Imitation Learning, GSIL) 프레임워크를 소개합니다. GSIL은 모방 학습을 위한 대체 목표를 도출하여 자기 생성 데이터를 사용할 수 있게 하며, 간단한 분류 손실(classification loss)을 통해 모방 학습 목표를 최적화할 수 있게 합니다.

- **Technical Details**: GSIL은 복잡한 적대적 훈련(adversarial training)의 필요성을 제거하여 대규모 언어 모델의 경량화 및 효율적인 미세 조정(fine-tuning)을 달성합니다. 또한, GSIL은 밀도 비율 추정(density ratio estimation)을 위한 일반 클래스의 볼록 함수로 매개변수화된 오프라인 손실(loss)의 집합을 포함하여 시연 데이터와의 정렬을 위한 통합된 관점을 제공합니다.

- **Performance Highlights**: 광범위한 실험을 통해 GSIL이 코드 생성(HumanEval), 수학적 추론(GSM8K), 지시 준수(MT-Bench) 등 여러 도전적인 벤치마크에서 기존 방법 СFT와 SPIN 대비 일관되게 유의미한 성능 개선을 이루었음을 보여주었습니다. 특수한 조건에서도 GSIL은 선호 레이블(preference labels)을 요구하는 DPO와 같은 방법보다도 우수한 성과를 기록했습니다.



### RoCoFT: Efficient Finetuning of Large Language Models with Row-Column Updates (https://arxiv.org/abs/2410.10075)
Comments:
          RoCoFT is a parameter-efficient method

- **What's New**: RoCoFT는 대규모 언어 모델(LM)의 파라미터 효율적 미세 조정 방법으로, 트랜스포머의 가중치 행렬에서 일부 행과 열만 업데이트하여 수행됩니다. 이 방법은 기존 PEFT 방법과 비교할 때 메모리 및 계산 효율성이 뛰어나면서도 더 나은 정확도를 제공합니다.

- **Technical Details**: RoCoFT는 중간 크기(LM) 모델인 BERT 및 RoBERTa부터 Bloom-7B, Llama2-7B, Llama2-13B와 같은 대형 모델까지 다양한 모델에서 실험하여 효과를 입증합니다. 이 연구에서 신경 탄젠트 커널(Neural Tangent Kernel, NTK) 이론을 활용하여 우리 방법의 효능을 분석합니다.

- **Performance Highlights**: RoCoFT는 정확도 면에서 현재의 PEFT 기술을 능가하며, 필요한 학습 가능한 파라미터가 적고 훈련 속도가 빠릅니다. 다양한 벤치마크에서 우리의 방법이 효과적임을 입증했습니다.



### Ukrainian-to-English folktale corpus: Parallel corpus creation and augmentation for machine translation in low-resource languages (https://arxiv.org/abs/2410.10063)
- **What's New**: 이 논문은 우크라이나 민속 이야기의 우크라이나어에서 영어로의 번역을 위한 새로운 평행 코퍼스(parallel corpus)를 소개합니다. 기존에 인간 번역가들이 수행하던 작업에 기반하여 새로운 번역을 제안합니다.

- **Technical Details**: 코퍼스는 단어(word) 및 문장(sentence) 기준으로 정렬되어 있어 의미 있는 정보의 최적 큐레이션(curation)을 제공합니다. 이는 머신 번역(machine translation) 모델 훈련 데이터로 사용되도록 특별히 설계되었습니다.

- **Performance Highlights**: 우크라이나 문화 전통과 관습에 대한 접근성을 높이고, 기계 번역의 질을 향상시킬 수 있는 가능성을 제공합니다.



### AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality (https://arxiv.org/abs/2410.10054)
Comments:
          The 2024 Conference on Empirical Methods in Natural Language Processing

- **What's New**: 이 논문에서는 Heavy-Tailed Self-Regularization (HT-SR) 이론을 활용하여 LoRA 전문가를 비균일하게 배치하는 새로운 방법인 AlphaLoRA를 제안하며, 이는 기존의 LoRA-MoE 구조의 중복성을 줄이기 위한 것입니다.

- **Technical Details**: AlphaLoRA는 각 레이어의 훈련 품질에 따라 LoRA 전문가의 수를 동적으로 할당하는 정교한 전략을 통해, HT-SR 이론을 기반으로 전문가의 수를 결정합니다. 논문에서는 PL_Alpha_Hill 수치를 사용하여 이 특징을 측정합니다.

- **Performance Highlights**: AlphaLoRA는 80명의 전문가로 160명의 전문가를 둔 MoLA-▽▽\triangledown▽보다 ~50% 적은 파라미터로 비슷하거나 우수한 성능을 발휘하며, 세 가지 모델과 열 가지 언어 처리 및 추론 벤치마크에서 우수한 결과를 나타냅니다.



### LoRE: Logit-Ranked Retriever Ensemble for Enhancing Open-Domain Question Answering (https://arxiv.org/abs/2410.10042)
- **What's New**: 본 논문은 LoRE (Logit-Ranked Retriever Ensemble)라는 새로운 방법론을 제안하여 기존의 질문-응답 시스템에서 발생하는 위치 편향(positional bias)을 완화하고 답변의 정확성 및 관련성을 높이는 것을 목표로 합니다.

- **Technical Details**: LoRE는 BM25와 FAISS 인덱싱을 활용한 다양한 리트리버(retriever) 앙상블을 이용합니다. 또한, 대형 언어 모델(LLM)에서의 로짓(logit) 점수를 결합한 새로운 로짓 기반(answer ranking algorithm) 답변 순위 매기기 알고리즘을 도입하여 정보를 우선적으로 정렬합니다.

- **Performance Highlights**: 실험 결과 NarrativeQA와 SQuAD에서 LoRE가 기존 리트리버 기반 방법들과 비교하여 ROUGE-L, EM, F1 점수에서 각각 14.5%, 22.83%, 14.95% 향상을 이뤘음을 보여주었습니다. qualitative한 측면에서도 LoRE는 더욱 정확하고 관련성 높은 답변을 생성하였습니다.



### A Step Towards Mixture of Grader: Statistical Analysis of Existing Automatic Evaluation Metrics (https://arxiv.org/abs/2410.10030)
- **What's New**: 이 연구는 기존의 자동 Question-Answering (QA) 평가 지표의 한계를 통계적으로 분석하고, Mixture Of Grader (MOG)라는 새로운 접근 방식을 제안합니다. MOG는 질문과 정답 쌍을 분류한 후 각 QA 유형에 적합한 평가 지표를 선택하여 보다 정확한 자동 평가를 가능하게 합니다.

- **Technical Details**: 기존의 평가 지표는 질문 유형에 따라 높은 상관관계를 보이며, 단일 지표만으로 사람의 평가를 완전히 반영할 수 없음을 발견했습니다. 연구는 Exact Match (EM), F1 Score, BLEU, ROUGE-L 등 다양한 평가 지표를 사용하여 ChatGPT-o1-preview 모델의 인간 평가와의 상관관계를 측정하였습니다.

- **Performance Highlights**: Pedant 평가 지표는 인간 평가 점수와 0.77의 높은 상관관계를 보였으며, 이는 기존의 평가 지표보다 인간의 평가를 더 잘 반영하는 경향이 있음을 나타냅니다. 이 연구에서는 QA 유형에 따른 평가 지표 사용의 중요성을 강조하며, 각 유형에 대한 다르게 평가하는 방안이 필요함을 제안합니다.



### Safety-Aware Fine-Tuning of Large Language Models (https://arxiv.org/abs/2410.10014)
Comments:
          NeurIPS 2024 Workshop on Safe Generative AI

- **What's New**: 본 연구에서는 안전성을 고려한 Fine-Tuning 접근 방식인 Safety-Aware Fine-Tuning (SAFT) 프레임워크를 새롭게 제안합니다. SAFT는 유해한 데이터 샘플을 자동으로 감지하고 제거하여 안전한 모델 작성을 돕습니다.

- **Technical Details**: SAFT는 Low-Rank Adaptation (LoRA) 기법을 이용하여 모델을 학습하며, 다양한 오염 비율(이용자의 불순물 비율)에서 실험을 수행했습니다. 학습 시 향상율(learning rate)은 2e-5로 설정하였고, 모델의 성능은 최대 256개 토큰을 생성하는 Greedy Decoding 방식으로 평가했습니다.

- **Performance Highlights**: 실험 결과, SAFT는 최대 27.8%까지 유해성을 감소시키는 효과를 보여 다른 LLM들에서도 유효성을 입증했습니다. SAFT는 AI 시스템의 강인성과 신뢰성을 향상시킬 수 있는 잠재력을 내포하고 있습니다.



### Leveraging Customer Feedback for Multi-modal Insight Extraction (https://arxiv.org/abs/2410.09999)
Comments:
          NAACL 2024

- **What's New**: 이 논문은 고객 피드백의 이미지와 텍스트 정보를 융합하여 행동 가능한 인사이트를 효과적으로 추출하는 새로운 다중 모달(multi-modal) 접근 방식을 소개합니다.

- **Technical Details**: 제안된 방법은 라테ント 공간(latent space)에서 이미지와 텍스트 정보를 융합하고 이미지-텍스트 기반 텍스트 디코더(image-text grounded text decoder)를 통해 관련 피드백 세그먼트를 추출합니다. 약한 지도 학습(weakly-supervised) 데이터 생성 기법을 활용하여 훈련 데이터를 생성합니다.

- **Performance Highlights**: 제안한 모델은 보지 않은 데이터에 대해 평가되었으며, 기존 기준선(baselines)을 F1 점수에서 14점 초과하여 뛰어난 성능을 보였습니다.



### Evaluating Gender Bias of LLMs in Making Morality Judgements (https://arxiv.org/abs/2410.09992)
Comments:
          Accepted by EMNLP Findings 2024

- **What's New**: 이 논문은 현재의 폐쇄형 및 개방형 LLM들이 성별 편향(gender bias)을 가졌는지를 조사합니다. 특히 도덕적 의견(moral opinions)을 제시할 때 성별이 미치는 영향을 분석합니다.

- **Technical Details**: 연구진은 GenMO라는 새로운 데이터셋을 구성하였으며, 이는 남성과 여성 캐릭터가 등장하는 평행 짧은 이야기(parallel short stories)로 이루어져 있습니다. 평가를 위해 GPT-3.5, GPT-4, Llama 3, Mistral-7B 및 Claude 3 모델을 테스트하였으며, 성별 변경이 도덕적 의견(moral opinions)에 미치는 영향을 조사했습니다.

- **Performance Highlights**: 모델들은 성별 변경만으로도 이질적인 도덕적 의견을 나타내는 경향을 보이며, 여성 캐릭터를 더 많이 선호하는 경향이 있었습니다. GPT-3.5-turbo는 24%에서 편향된 의견을, Llama 3는 약 81-85%의 경우에서 편향된 결과를 보여주었습니다.



### MARS: Multilingual Aspect-centric Review Summarisation (https://arxiv.org/abs/2410.09991)
Comments:
          EMNLP 2024

- **What's New**: 이번 논문에서는 고객 피드백을 요약하여 제품 및 서비스에 대한 실행 가능한 인사이트를 제공하는 새로운 프레임워크 MARS를 제안합니다. 이 프레임워크는 Extract-then-Summarise 방식으로 작동하며, 다국어 리뷰의 도메인 비구속적 측면 요약을 혁신적으로 해결하는 것을 목표로 합니다.

- **Technical Details**: MARS는 두 가지 주요 구성 요소로 구성됩니다: (1) Multilingual InsightNet: 다양한 언어로 작성된 리뷰에서 다단계 구조적 인사이트를 자동으로 추출하는 방법, (2) 대규모 언어 모델(LLMs)을 활용한 적응형 요약 기술로, 추출된 인사이트를 실용적인 방식으로 요약합니다.

- **Performance Highlights**: MARS는 기존 단일 언어 베이스라인에 비해 상당한 성능 향상을 보여주었습니다. 또한 다양한 도메인에서 리뷰의 동적 특성을 다루기 위한 약간의 지도 학습 접근 방식을 통해 새로운 측면을 식별하고 고품질의 요약을 생성할 수 있는 효율성을 입증하였습니다.



### When Neutral Summaries are not that Neutral: Quantifying Political Neutrality in LLM-Generated News Summaries (https://arxiv.org/abs/2410.09978)
Comments:
          12 pages, 3 figures, 4 tables

- **What's New**: 본 연구는 대규모 언어 모델(LLMs)이 정치적 중립성을 어떻게 나타내는지를 탐구하기 위한 새로운 방법론을 제시합니다. 뉴스 기사의 압축(summary) 방법을 통해 정치적 편향을 정량화하고, 특정 주제에 대한 언어 모델의 편향성을 평가합니다.

- **Technical Details**: 이번 연구에서 20,344개의 뉴스 기사를 사용하여 압축된 요약을 생성하며, 민주당 및 공화당의 관점에서 작성된 요약을 비교합니다. 세 가지 관점(중립, 민주당 지향, 공화당 지향)에서 요약을 분석하여 LLM의 정치적 중립성을 측정하는 새로운 프레임워크를 제안합니다. 해당 모델들은 LLaMA-7B, Mistral-7B, Vicuna-7B, PaLM 2로 구성되며, 단어 선택의 차이를 분석합니다.

- **Performance Highlights**: 연구 결과, 여러 LLM들이 특정 정치적 이슈(예: 총기 규제 및 의료)에 대해 민주당 편향을 가지고 있다는 것이 확인되었습니다. 최대 -9.49%의 편향 값을 기록하며, 55%의 어휘가 민주당 지향적 표현으로 중복됩니다. 이번 연구는 향후 선거와 관련한 중요한 발견으로 간주됩니다.



### MisinfoEval: Generative AI in the Era of "Alternative Facts" (https://arxiv.org/abs/2410.09949)
Comments:
          EMNLP 2024. Correspondence can be sent to skgabrie at cs dot ucla dot edu

- **What's New**: 본 논문에서는 misinformation(잘못된 정보)에 대한 대처 방안을 제안하기 위해 LLM(대형 언어 모델)을 활용하는 새로운 프레임워크인 MisinfoEval을 소개합니다. 이 프레임워크는 대규모로 misinformation interventions(인터벤션)을 생성하고 종합적으로 평가하는 방법을 제시합니다.

- **Technical Details**: MisinfoEval 프레임워크는 두 가지 실험을 통해 데이터 기반의 interventions 효과를 측정합니다. 첫 번째 실험은 소셜 미디어 환경에서 misinformation interventions의 효과를 측정하는 것이며, 두 번째는 사용자의 인구 통계 및 신념에 맞춘 개인화된 설명을 통해 misinformation에 대처하는 방법을 연구합니다. 연구 결과에 따르면, LLM 기반의 interventions은 사용자 행동 수정에 매우 효과적이며, 개인화된 설명을 제공받은 사용자는 misinformation을 식별하는 정확도가 상당히 높아지는 것으로 나타났습니다.

- **Performance Highlights**: LLM 기반의 설명을 통한 interventions은 사용자의 신뢰성 라벨링 정확도를 41.72%까지 개선하는 것으로 확인되었습니다. 특히 GPT-4의 설명이 포함된 개인화된 interventions은 사용자의 정확도를 높이고, misinformation에 대한 신뢰성을 확인하는 데 있어 97.6%의 정확도를 기록했습니다. 이러한 결과는 LLM을 통한 개인화된 접근이 misinformation에 대한 대응에 강력한 영향을 미칠 수 있음을 시사합니다.



### State of NLP in Kenya: A Survey (https://arxiv.org/abs/2410.09948)
Comments:
          21 pages

- **What's New**: 이번 연구는 케냐에서의 자연어 처리(NLP) 기술 현황을 종합적으로 평가하여, 원주율 언어에 대한 디지털 성과 및 도전 과제를 다룹니다. 특히 키스와힐리어, 도루어, 기쿠유어 및 루흐야어와 같은 현지 방언에 대한 데이터셋 생성 및 기계 번역, 감정 분석, 음성 인식의 노력들을 강조하고 있습니다.

- **Technical Details**: 이 연구는 데이터 수집, 기존 모델 분석 및 케냐어 언어를 위한 사용 가능한 자원 평가를 포함한 다단계 접근 방식을 따릅니다. 연구에 사용된 주요 방법론은 구글 스칼라, ACL 등에서 발행된 연구 논문 및 공개 데이터셋 리뷰로, 특히 스와힐리어, 도루어, 루흐야어에 중점을 두었습니다.

- **Performance Highlights**: 이 논문은 케냐의 NLP 기술 발전이 여전히 제한된 자원과 도구로 인해 많은 원주율 언어가 디지털 공간에서 저조하게 나타나는 문제를 지적합니다. 대규모 언어 모델 필요성과 기존 데이터셋 및 NLP 모델의 격차를 비판적으로 평가하고, 이를 위해 AI 및 NLP의 미래를 형성하는 정책 및 규제를 논의합니다.



### Learning to Rank for Multiple Retrieval-Augmented Models through Iterative Utility Maximization (https://arxiv.org/abs/2410.09942)
- **What's New**: 이 논문은 여러 개의 Retrieval-Augmented Generation (RAG) 에이전트를 위해 통합 검색 엔진을 설계하는 방법을 제시합니다. 이 검색 엔진은 반복적인 피드백 수집 과정을 통해 각 에이전트의 요구에 최적화됩니다.

- **Technical Details**: 이 새로운 방법론은 expectation-maximization 알고리즘에 기반하여, 각 에이전트의 유틸리티 함수를 극대화하는 것을 목표로 합니다. 오프라인 단계에서는 검색 엔진이 최적의 매개변수를 사용하여 문서를 검색하고, 각 에이전트로부터 피드백을 받아 이를 바탕으로 개선합니다. 또한 온라인 환경에서도 실시간 피드백을 활용하여 검색 결과를 조정합니다.

- **Performance Highlights**: KILT 벤치마크의 다양한 데이터셋에서 실험한 결과, 제안하는 방법이 18개의 RAG 모델에서 평균적으로 기존의 최첨단 방법보다 훨씬 우수한 성능을 보였습니다. 개인화 과정에서 검색 엔진의 성능 또한 향상되었음을 입증하였습니다.



### Reddit is all you need: Authorship profiling for Romanian (https://arxiv.org/abs/2410.09907)
Comments:
          10 pages, 5 tables and 1 figure, submitted to The 19th International Conference on Linguistic Resources and Tools for Natural Language Processing (ConsILR 2024)

- **What's New**: 이번 연구에서는 루마니아어로 작성된 짧은 텍스트의 코퍼스(corpus)를 소개하며, 이는 작가의 특정 특징을 나타내는 키워드로 주석이 달린 최초의 자료입니다. 특히 Reddit이라는 소셜 미디어 플랫폼을 활용하여 작가의 배경 정보를 추론합니다.

- **Technical Details**: 연구에서는 Reddit의 주제 기반 커뮤니티 구조(subreddits structure)를 이용해 사용자의 인구통계학적 정보와 연령 범주, 고용 상태, 관심사 및 사회적 성향 등을 추론합니다. 이로 인해 23,000개 이상의 샘플이 포함된 코퍼스가 생성되었으며, 100개 이상의 루마니아어 서브레딧에서 데이터를 추출했습니다. 또한, 대형 언어 모델(LLMs)을 미세 조정하고 평가하여 저자 프로파일링의 기준 능력을 입증합니다.

- **Performance Highlights**: 연구 결과는 저자 프로파일링 분야에서 추가적인 연구 필요성을 보여주며, 모든 자료는 공개적으로 제공됩니다.



### RMB: Comprehensively Benchmarking Reward Models in LLM Alignmen (https://arxiv.org/abs/2410.09893)
- **What's New**: 이 논문은 RM(Benchmarking of Reward Models)의 새로운 기준을 제시하여 LLM(대형 언어 모델)의 정렬 성능을 보다 효과적으로 평가할 수 있도록 합니다. 특히 49개 현실 세계 시나리오를 포괄하고, pairwise 및 Best-of-N(BoN) 평가를 포함하는 총체적인 개선점을 통해 RM의 효용성을 강조합니다.

- **Technical Details**: RMB는 LLM과 인간의 선호를 조정하기 위한 중요한 RM을 평가하는 종합 벤치마크로, 49개의 실제 시나리오 전반에 걸쳐 다양한 업무를 포괄합니다. BoN 평가 방법론을 도입하여 여러 응답 중 최적의 선택을 할 수 있는 능력을 평가합니다. 이 연구에서는 18,000개 이상의 높은 품질의 선호 쌍을 생성하고, 기존 RM의 일반화 결함과 생성적 RM의 잠재력을 분석합니다.

- **Performance Highlights**: RMB 벤치마크와 하위 정렬 작업 간 긍정적인 상관관계를 보여줍니다. BoN 평가가 pairwise 평가보다 RM의 성능을 더 효과적으로 검증하며, 응답의 선호를 잡는 생성적 RM의 가능성을 강조합니다. 또한, 다수결 투표 방식의 한계와 생성적 RM의 평가에 대한 영향 요소를 논의합니다.



### ChroKnowledge: Unveiling Chronological Knowledge of Language Models in Multiple Domains (https://arxiv.org/abs/2410.09870)
- **What's New**: 이 논문에서는 ChroKnowBench라는 새로운 벤치마크 데이터셋을 소개하여 대형 언어 모델(LLMs)의 시간에 따른 축적 지식을 평가하는 방법을 제시합니다. 이 데이터셋은 시간 종속성, 다양한 도메인, 그리고 시간 상태라는 세 가지 주요 측면을 기반으로 합니다.

- **Technical Details**: ChroKnowBench는 과학적 발견이나 수정된 법률과 같은 진화하는 지식과 수학적 진리나 상식 사실과 같이 변하지 않는 지식을 구별합니다. 연구팀은 ChroKnowledge 프레임워크를 통해 LLMs의 비모수적 비율 연대 지식을 평가하고 업데이트하는 방법을 제시합니다.

- **Performance Highlights**: ChroKnowPrompt를 활용한 평가에서 생물의학 도메인에서 +11.9% 향상된 성능과 일반 도메인에서 +2.8% 향상된 성능을 보였습니다. 이 비모수적 접근 방식은 오픈 소스 모델과 독점 모델 모두에 대한 지식 업데이트를 직접 수행할 수 있습니다.



### Generating Driving Simulations via Conversation (https://arxiv.org/abs/2410.09829)
Comments:
          6 pages, 6 figures, 2 tables

- **What's New**: 본 논문은 자율주행차의 시뮬레이션 테스트를 위한 자연어 인터페이스를 설계하였습니다. 이 인터페이스는 비코딩(Non-coding) 도메인 전문가는 적절한 시나리오와 차량 행동을 합성하는 데 도움을 줍니다. 인간 실험 결과, 대화가 성공적인 시뮬레이션 생성을 위해 필수적이라는 것을 보여주며, 대화를 통한 성공률이 4.5배 높았습니다.

- **Technical Details**: 이 시스템은 자연어로 작성된 설명을 바탕으로 Scenic 코드를 생성하는 대화 시스템입니다. 사용자가 시뮬레이션 인스턴스에 반응하며 대화하는 방식으로 작동합니다. 이 시스템은 retrieval-augmented generation (RAG) 및 in-context learning을 사용하여 프로그램을 생성합니다. 시뮬레이터에서 생성된 시뮬레이션의 성공 여부에 따라 사용자의 피드백을 받아 출력을 수정합니다.

- **Performance Highlights**: 우리는 자율주행차의 다양한 주행 시나리오에 대한 자연어 설명과 Scenic 프로그램 쌍으로 구성된 데이터 세트를 생성했습니다. 이 데이터 세트를 활용하여 대화 시스템의 정확도를 평가했으며, 대화의 여러 턴을 통한 상호작용이 효과적임을 확인했습니다.



### Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent Simulation (https://arxiv.org/abs/2410.09824)
- **What's New**: 이 논문에서는 GraphAgent-Generator(GAG)라는 새로운 시뮬레이션 기반의 동적 그래프 생성 프레임워크를 제안합니다. 기존의 방법들이 동적 그래프 생성에서 특정한 한계를 가지고 있는 반면, 우리의 GAG는 기존 최첨단 기준을 31% 초과하는 성능을 보였으며, LLM(대형 언어 모델)에 기반하여 인간 상호작용을 모방하는 데 성공했습니다.

- **Technical Details**: GAG는 LLM 기반의 에이전트를 사용하여 사람의 행동을 시뮬레이션하며, S-RAG 알고리즘을 통해 상호작용 프로세스를 모델링합니다. 이 프레임워크는 최대 10,000,000개의 엣지와 100,000개의 노드를 지원하여, N-ACTOR를 통해 90.4% 이상의 속도 향상을 달성합니다.

- **Performance Highlights**: GAG가 생성한 그래프는 실제 네트워크에서 관찰된 일곱 가지 주요 구조적 특성을 나타내며, 노드 분류 작업에서 GNN(그래프 신경망)을 사용하여 생성된 그래프의 정확도가 실제 그래프와 비슷한 성과를 거둡니다.



### Reverse Modeling in Large Language Models (https://arxiv.org/abs/2410.09817)
Comments:
          13 Pages, 6 Figures, 7 Tables

- **What's New**: 이 논문은 대규모 언어 모델(LLMs)이 역방향 텍스트 입력을 이해하는 데 어려움을 겪는지 조사합니다. 연구 결과, 미리 훈련된 LLM들은 역방향 텍스트를 이해하지 못했지만, 동시에 전방향 및 역방향 텍스트로 훈련된 LLM들은 두 가지 모두를 동등하게 이해할 수 있음을 보여주었습니다.

- **Technical Details**: LLMs는 데이터 선택 및 학습 성능 개선을 위해 forward과 reverse modeling 데이터를 사용하여 훈련되었습니다. 이는 기존 기계 번역 및 reverse curse 문제를 해결하는 방법을 모색하는 데 기여합니다. 특히, LLM들은 랜덤 초기화에서 훈련할 때 forward 및 reverse 텍스트를 동시 학습함으로써 서로 유사한 성과를 보였습니다.

- **Performance Highlights**: 연구 결과, 고품질의 텍스트(예: 학술 자료 및 서적)에서 역방향 모델링이 가능함을 보여주었으며, 이를 통해 LLM의 성능이 크게 향상될 수 있음을 확인하였습니다. MMLU와 같은 여러 언어 이해 기준에서 성능 향상이 관찰되었습니다.



### Single Ground Truth Is Not Enough: Add Linguistic Variability to Aspect-based Sentiment Analysis Evaluation (https://arxiv.org/abs/2410.09807)
Comments:
          Preprint

- **What's New**: 본 논문에서는 Aspect-based Sentiment Analysis (ABSA)의 정확한 평가를 위해 기존 테스트 세트를 대체 가능한 정답으로 보강하는 자동화된 파이프라인을 제안합니다.

- **Technical Details**: 이 연구에서는 네 가지 ASQP 데이터셋을 사용하고, 테스트 세트에서 무작위로 선택한 80개의 샘플에 대해 인간 주석자를 통해 새롭게 구성된 GT 쿼드러플의 정확성을 검증하였습니다. 세 단계(Zoom-In, Zoom-Out, Judge)로 구성된 데이터셋 확장 프로세스를 설명하며, 다양한 Large Language Models (LLMs)로부터의 예측을 수집했습니다.

- **Performance Highlights**: 대체된 테스트 세트를 사용할 경우, LLM들이 T5 모델에 비해 ABSA 작업에서 상당한 성능 향상을 보임을 입증하였으며, Kendall's Tau 점수가 최대 10% 향상되었습니다.



### Expanding Search Space with Diverse Prompting Agents: An Efficient Sampling Approach for LLM Mathematical Reasoning (https://arxiv.org/abs/2410.09780)
Comments:
          6 pages, 4 figures

- **What's New**: 이 연구는 전통적인 LLM 접근 방식을 넘어서 다양한 문제 해결 전략을 탐구하기 위해 실험 분석을 수행했습니다. 거기서 각 프롬프트 방법이 독특한 탐색 공간을 탐색한다는 사실을 확인했고, 특히 문제 복잡성이 증가함에 따라 이 차이가 두드러진다고 밝혔습니다.

- **Technical Details**: 세 가지 주요 프롬프트 방법(1) Text, (2) Code, (3) Cumulative Reasoning(CR)을 선택하여 각각의 문제 해결 접근 방식을 분석했습니다. 특히, Uniform Sampling 기법을 통해 서로 다른 방법에서 샘플을 균일하게 결합하여 최대 탐색 공간을 확장했습니다.

- **Performance Highlights**: MATH-hard 데이터셋에서 진행된 연구는 평균적으로 단일 방법에 비해 약 43% 더 적은 실행 횟수로 최대 탐색 공간에 도달하는 성과를 보였습니다. 실험 결과, 다양한 프롬프트 기법을 활용하는 것이 더 넓은 탐색을 가능하게 한다는 가설을 뒷받침합니다.



### A Mixed-Language Multi-Document News Summarization Dataset and a Graphs-Based Extract-Generate Mod (https://arxiv.org/abs/2410.09773)
- **What's New**: 본 논문에서는 mixed-language multi-document (MLMD) 뉴스 요약을 위한 최초의 데이터셋인 MLMD-news를 구축했습니다. 이 데이터셋은 4개 언어와 10,992개의 원문 문서 클러스터 및 목표 요약 쌍을 포함하고 있습니다.

- **Technical Details**: MLMD-news 데이터셋은 영어, 독일어, 프랑스어 및 스페인어로 구성되어 있으며, 각 문서 클러스터는 여러 서로 다른 언어의 문서로 이루어져 있습니다. 제안된 모델은 그래프 기반의 extract-generate 모델로, 그래프 신경망을 사용하여 키 문장을 추출하고, 사전 학습된 모델을 이용해 목표 요약을 생성합니다.

- **Performance Highlights**: 다양한 방법을 MLMD-news 데이터셋에 대해 벤치마크하여 성능을 평가하고, 연구의 진전을 위해 데이터셋 및 코드를 공개했습니다.



### 'Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated peer-reviews (https://arxiv.org/abs/2410.09770)
Comments:
          EMNLP Main, 17 pages, 5 figures, 9 tables

- **What's New**: 이 논문에서는 AI 생성 논문 리뷰의 탐지를 위한 새로운 접근 방식을 제안합니다. 기존 연구는 일반적인 AI 생성 텍스트 탐지에 집중했으나, 본 연구에서는 특정 리뷰가 ChatGPT에 의해 작성되었는지를 식별하는 문제에 초점을 둡니다.

- **Technical Details**: 제안된 두 가지 모델은 Term Frequency (TF) 모델과 Review Regeneration (RR) 모델로, TF 모델은 AI가 자주 반복하는 토큰을 분석하고, RR 모델은 재프롬프트 하에 유사한 출력을 생성하는 것을 기반으로 합니다. 두 모델은 다양한 공격에 대한 강건성을 테스트하고, 공격을 피하기 위한 방어 전략을 제안합니다.

- **Performance Highlights**: TF 모델은 일반적인 조건에서 RR 모델보다 성능이 좋지만, RR 모델은 공격에 대해 더 강력한 저항력을 보입니다. 실험 결과, 두 제안된 방법 모두 다른 AI 텍스트 탐지기보다 우수한 성능을 보여주며, 연구자들이 만든 데이터셋과 코드는 공개됩니다.



### Empirical Study of Mutual Reinforcement Effect and Application in Few-shot Text Classification Tasks via Promp (https://arxiv.org/abs/2410.09745)
Comments:
          10 pagess, 4 figures

- **What's New**: 이번 논문에서는 Mutual Reinforcement Effect (MRE)라는 개념을 활용하여 텍스트 분류 작업에서 단어 수준과 텍스트 수준의 상호 강화 효과를 실증적으로 검증하였습니다. 특히, 21개의 MRE 믹스 데이터셋에서 실험을 통해 MRE가 모델의 성능에 미치는 영향을 관찰하였으며, 두 분류 과제를 동시에 수행하여 성능 개선을 도출했습니다.

- **Technical Details**: MRE는 단어 수준 정보(Word-level Information)와 텍스트 수준 정보(Text-level Information)를 상호 보완하여 분류 성능을 높이는 방법론입니다. 실험에서는 두 수준의 정보가 각기 다른 분류 작업의 성능을 어떻게 향상시키는지를 확인하기 위해 새로운 입력-출력 형식을 고안하여 평가하였습니다.

- **Performance Highlights**: 최종 실험에서는 F1-score가 21개의 MRE 믹스 데이터셋 중 18개에서 기준을 현저하게 초과하여, 단어 수준 정보가 텍스트 전체의 이해를 우수하게 향상시킨다는 점을 강조했습니다. 또한, 제한된 샘플로 수행한 few-shot learning에서 단어 수준 정보를 활용했을 때 분류 정확도가 크게 향상되었음을 보여주었습니다.



### Taming Overconfidence in LLMs: Reward Calibration in RLHF (https://arxiv.org/abs/2410.09724)
- **What's New**: 이 연구는 대형 언어 모델(Large Language Models, LLMs)의 신뢰도를 높이기 위한 새로운 접근 방식을 제안합니다. 특히, RLHF(Reinforcement Learning from Human Feedback)를 통해 모델의 과신(overconfidence) 현상을 분석하고 그 근본 원인을 규명하였습니다. 이를 기반으로 두 가지 새로운 Proximal Policy Optimization(PPO) 변형인 PPO-M과 PPO-C를 제안하였습니다.

- **Technical Details**: RLHF를 통해 학습된 LLM에서 발견된 과신의 원인을 파악하였으며, 이와 관련하여 신뢰표시 모델을 제정비하는 두 가지 PPO 변형을 제안하였습니다. PPO-M은 보상 모델에서 신뢰 점수를 통합하여 응답 품질과 신뢰 간의 정렬을 개선하였고, PPO-C는 동적 기준을 기반으로 보상 점수를 조정하여 신뢰성을 높였습니다. 이 두 방법은 추가적인 레이블 없이 기존 PPO 파이프라인에 쉽게 통합될 수 있습니다.

- **Performance Highlights**: Llama3-8B 및 Mistral-7B 모델에 대한 실험 결과, PPO-M과 PPO-C는 각각 표준 PPO에 비해 Expected Calibration Error(ECE)를 낮추고 성능을 유지하는 것으로 나타났습니다. 예를 들어, PPO-M은 GSM8K 데이터셋에서 ECE를 6.44 포인트 감소시키고 정확도를 2.73 포인트 증가시켰습니다.



### Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG (https://arxiv.org/abs/2410.09699)
- **What's New**: 이 논문은 'Honest AI'라는 새로운 접근 방식을 제안하여 중소형 언어 모델이 잘못된 정보에 대한 환각을 줄이기 위해 "모르겠습니다"라고 대답하도록 세밀하게 조정합니다. 또한, 검색 엔진과 지식 그래프 결과를 활용한 여러 대체 RAG 접근법을 논의하며, 혼합 접근 방식으로 가장 높은 성능을 발휘한 것을 보여줍니다.

- **Technical Details**: 본 논문은 2024 Meta KDD Cup에서 Comprehensive RAG Benchmark(CRAG) 데이터를 사용하여 다양한 RAG 접근 방식을 시도했습니다. CRAG는 복잡도의 변화에 따라 영화나 스포츠와 같은 5개 질문 도메인을 포함하며, 잘못된 전제로 구성된 질문을 다뤘습니다. 원래 RAG 방식과 더불어 미세 조정(fine-tuning)과 두 접근 방식을 혼합한 방법을 통해 성능을 개선하고, 모델의 자원 효율성을 강조합니다.

- **Performance Highlights**: 이 연구팀은 Task 2의 잘못된 전제 질문에서 1위를 차지했으며, 모든 접근 방식이 LLM의 성능을 개선하는 것으로 나타났습니다. 전통적인 RAG만으로는 성능이 크게 향상되지 않았고, 혼합 접근 방식이 CRAG 벤치마크에서 가장 높은 점수를 기록했습니다.



### COrAL: Order-Agnostic Language Modeling for Efficient Iterative Refinemen (https://arxiv.org/abs/2410.09675)
Comments:
          12 pages, 7 figures, 3 tables (23 pages, 9 figures, 4 tables including references and appendices)

- **What's New**: 본 연구에서는 Context-Wise Order-Agnostic Language Modeling (COrAL)이라는 새로운 아키텍처를 제안합니다. COrAL은 기존의 autoregressive (AR) 모델의 한계를 극복하며, iterative refinement를 LLM 아키텍처에 직접 통합하여 계산 효율성을 유지합니다.

- **Technical Details**: COrAL은 manageable context windows 내에서 토큰 의존성을 모델링하며, sliding blockwise order-agnostic decoding을 사용하여 multi-token forward prediction과 backward reconstruction을 동시에 수행합니다. 이를 통해 고비용의 순차적 생성 없이도 다양한 의존성을 병렬로 포착할 수 있습니다.

- **Performance Highlights**: 실험 결과, COrAL은 GSM8K와 LogiQA에서 각각 4.6% 및 4.0%의 정확도 향상을 달성했으며, 다음 토큰 기준 대비 최대 3.9배의 추론 속도 향상을 나타냈습니다. 그러나 코드 생성 작업에서는 일관성 부족으로 인한 pass rate 감소가 관찰되었습니다.



### Adapters for Altering LLM Vocabularies: What Languages Benefit the Most? (https://arxiv.org/abs/2410.09644)
- **What's New**: VocADT는 고정된 모델 가중치를 유지하면서 기존 임베딩의 최적 선형 조합을 학습하는 새로운 어댑터 모듈을 사용하는 독창적인 어휘 적응 방법입니다. 이 방식은 외부 리소스나 언어 제약 없이 유연하고 확장 가능한 솔루션을 제공합니다.

- **Technical Details**: VocADT는 새로운 어휘와 기존 임베딩 사이에 어휘 어댑터 모듈을 도입하며, 모든 가중치를 고정한 채 새로운 어휘에 서서히 적응합니다. 이 학습된 적응 방식은 새로운 언어에 대한 유연성을 높이고, 다양한 언어 수를 처리할 수 있게 하며, 외부의 사전학습 자원의 필요성을 제거합니다.

- **Performance Highlights**: VocADT는 11개 언어의 다양한 다국어 작업에서 원래의 Mistral 모델과 기타 기준을 초과하는 성과를 보여주었습니다. 특히 라틴 문자 언어와 심각한 편찬 문제를 가진 언어에서 가장 큰 이점을 얻는 것으로 나타났습니다. 기계 번역 작업에서도 VocADT가 가장 효과적인 방법임을 확인했습니다.



### RepMatch: Quantifying Cross-Instance Similarities in Representation Spac (https://arxiv.org/abs/2410.09642)
- **What's New**: 본 논문에서는 RepMatch라는 새로운 방법론을 소개하며, 이는 모델이 훈련된 데이터의 유사성을 정량화하여 분석하는 방식입니다. 기존 분석 방법들이 개별 인스턴스에 제한적이었던 것과 달리, RepMatch는 임의의 데이터 인스턴스 서브셋 간의 비교를 가능하게 합니다.

- **Technical Details**: RepMatch는 훈련 인스턴스 서브셋 간의 유사성을 모델을 통해 비교하여 평가합니다. Subset \\mathcal{S}와 \\mathcal{S}^{	ext{\prime}}의 유사성을 모델의 표현 공간이 서로 일치할 때로 정의하며, 이는 데이터셋 간 비교 및 인스턴스-데이터셋 분석을 가능하게 합니다. Low-rank Adaptation (LoRA)을 활용하여 훈련 가능한 파라미터의 집합을 제약하여 모델 간의 유사성을 효율적으로 측정합니다.

- **Performance Highlights**: RepMatch는 다수의 NLP 작업과 데이터셋에서 효과성을 검증하였으며, 우수한 성능을 나타냈습니다. 특히, 유사한 작업 간의 LoRA 행렬 유사성이 두드러졌고, 각 데이터셋에서 대표적인 소규모 서브셋을 식별하여 랜덤 서브셋보다 높은 성능을 달성했습니다. 또한, RepMatch는 HANS 챌린지 데이터셋의 자동 생성에 사용된 휴리스틱을 발견하는 데도 성공했습니다.



### SciGisPy: a Novel Metric for Biomedical Text Simplification via Gist Inference Scor (https://arxiv.org/abs/2410.09632)
Comments:
          Accepted by he Third Workshop on Text Simplification, Accessibility and Readability

- **What's New**: 이 논문에서는 바이오메디컬 텍스트의 자동화된 텍스트 간소화 (ATS)를 효율적으로 평가할 수 있는 새로운 지표인 SciGisPy를 소개합니다. 기존의 평가 메트릭스가 가지는 한계를 극복하고, 전반적인 의미 (gist)를 정확히 전달하는 정도를 측정하는 것이 주요 목표입니다.

- **Technical Details**: SciGisPy는 Fuzzy-Trace Theory (FTT)의 Gist Inference Score (GIS)에 기반하여 개발되었습니다. 이 메트릭은 의미론적 청킹(semantic chunking), 정보 내용 (Information Content, IC) 이론, 전문화된 임베딩(embeddings) 등의 도메인 특화 기능을 통해 텍스트의 핵심 내용을 얼마나 잘 전달하는지를 평가합니다. 실험 결과, SciGisPy는 기존의 GIS 포뮬러에 비해 더 높은 정확도로 간소화된 텍스트를 식별했습니다.

- **Performance Highlights**: Cochrane 바이오메디컬 텍스트 간소화 데이터셋에서 SciGisPy는 84%의 정확도로 간소화된 텍스트를 올바르게 식별하였고, 이는 기존 GIS의 44.8% 보다 유의미한 향상입니다. 이러한 결과는 SciGisPy가 기존 방법들에 비해 의학 내용을 더 잘 포착하고 있다는 것을 보여줍니다.



### Society of Medical Simplifiers (https://arxiv.org/abs/2410.09631)
Comments:
          Accepted by Third Workshop on Text Simplification, Accessibility and Readability

- **What's New**: 이 논문에서는 전통적인 의료 텍스트 단순화 기법의 한계를 극복하기 위해 'Society of Medical Simplifiers'라는 새로운 LLM 기반 프레임워크를 소개하고 있습니다. 이 프레임워크는 다섯 가지 전문 역할을 할당하여 의료 텍스트의 단순화를 점진적으로 개선합니다.

- **Technical Details**: 우리는 다섯 개의 역할(General Layperson, Simplifier, Medical Expert, Language Clarifier, Redundancy Checker)로 구성된 다중 에이전트 시스템을 사용합니다. 각 역할은 피드백과 반복 상호작용을 통해 복잡한 의료 텍스트의 명료성과 정확성을 유지하면서 단순화 과정을 진행합니다.

- **Performance Highlights**: Cochrane 데이터셋을 활용한 평가 결과, 제안한 프레임워크는 현재의 최첨단 방법과 동등하거나 이를 초과하는 읽기 용이성을 달성하며, 콘텐츠 보존 측면에서도 우수한 성능을 보여줍니다.



### Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models (https://arxiv.org/abs/2410.09629)
Comments:
          EMNLP 2024 main conference long paper

- **What's New**: 이번 연구에서는 기존의 지식 습득의 한계를 극복하기 위해, 새로운 합성 지식 습득 방법인 Ski를 제안합니다. 이 방법은 정밀한 합성, 교차 생성, 조립 증대 전략을 활용하여 원천 지식으로부터 고품질 데이터 표현을 구축합니다.

- **Technical Details**: Ski는 Fine-grained Synthesis를 통해 n-gram 지식 맥락 기반의 가상의 질문을 생성하고, Interleaved Generation을 통해 특정 지식에 대한 질문과 답변을 동시 생성합니다. Assemble Augmentation은 다양한 n-gram 범위에서 Fine-grained Synthesis를 조합하여 질문과 답변 쌍을 균형 있게 반복합니다. 이 방식으로 Ski는 LLM의 지식 정제를 효과적으로 지원합니다.

- **Performance Highlights**: Ski는 금융, 생명 의학, 개방 생성 등의 다양한 질문-답변 작업에서 두 개의 오픈 소스 LLM인 Llama2-7B와 Mistral-7B에 대해 실험을 수행하여 기존 방법들보다 상당히 높은 성능을 기록했습니다.



### Enhanced Electronic Health Records Text Summarization Using Large Language Models (https://arxiv.org/abs/2410.09628)
- **What's New**: 이 논문은 Electronic Health Records (EHR) 요약 시스템의 발전을 통해 환자 데이터 관리 방식을 혁신적으로 변화시켰습니다. 기존의 연구는 Large Language Models (LLM)을 임상 작업에 맞게 조정하고 다양한 데이터 세트를 활용하여 일반적인 EHR 요약을 생성하였으나, 이번 프로젝트는 의사가 선호하는 구체적이고 집중된 요약을 생성하는 시스템을 개발했습니다.

- **Technical Details**: 제안된 시스템은 Google Flan-T5 모델을 활용하여 의사가 지정한 주제에 따라 맞춤형 EHR 요약을 생성합니다. Flan-T5 모델은 Stanford Question Answering Dataset (SQuAD) 스타일의 EHR 질문-답변 데이터 세트에서 미세 조정(fine-tuning) 되었습니다. Hugging Face Transformers 라이브러리의 Seq2SeqTrainer를 사용하여 최적의 하이퍼파라미터를 통해 미세 조정이 이루어졌습니다.

- **Performance Highlights**: 주요 평가 지표는 긍정적인 결과를 나타냈습니다: Exact Match (EM) 점수는 81.81%를 기록했으며, ROUGE 지표는 ROUGE-1이 96.03%, ROUGE-2가 86.67%, ROUGE-L이 96.10%로 강력한 성능을 보였습니다. 또한 Bilingual Evaluation Understudy (BLEU) 점수는 63%로, 요약 생성의 일관성을 잘 반영하고 있습니다.



### Quebec Automobile Insurance Question-Answering With Retrieval-Augmented Generation (https://arxiv.org/abs/2410.09623)
Comments:
          Accepted to NLLP 2024 EMNLP workshop

- **What's New**: 이 논문은 자동차 보험 관련 질의응답 시스템에서 Large Language Models (LLMs)와 Retrieval-Augmented Generation (RAG) 아키텍처를 적용하여 성능을 향상시키는 방법을 제시합니다. 두 개의 새로운 데이터 세트인 Quebec Automobile Insurance Expertise Reference Corpus와 전문가 답변 모음을 통해 법적 문서의 질문-답변 문제를 다룹니다.

- **Technical Details**: 본 연구에서는 LLM인 GPT-4o의 성능을 평가하기 위해 전문가와 비전문가의 응답을 비교합니다. 두 개의 새로운 코퍼스를 생성하였으며, 이는 퀘벡 자동차 보험 관련 법률 문서 및 일반인을 위한 FAQ에서 도출된 질문-답변 쌍을 포함합니다. RAG 접근 방식을 활용하여, 보험 관련 데이터의 자동 및 수동 평가가 수행되었습니다.

- **Performance Highlights**: 실험 결과, 전문성 참조 코퍼스를 활용했을 때 자동 및 수동 평가 지표 모두에서 더 나은 응답이 생성된 것으로 나타났습니다. 그러나 LLM 기반의 QA 시스템은 5%에서 13%의 경우에 오답을 포함하고 있어 더욱 신중한 활용이 필요하다는 점도 강조되었습니다.



### Transformer-based Language Models for Reasoning in the Description Logic ALCQ (https://arxiv.org/abs/2410.09613)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 본 논문에서는 자연어 데이터셋 DELTA$_D$를 구축하여, 논리적 추론 능력을 평가하기 위한 새로운 벤치마크를 제시합니다. 이 데이터셋은 384K 개의 예제를 포함하고 있으며, 추론 깊이와 언어적 복잡성이 증가하는 두 가지 차원을 다룹니다.

- **Technical Details**: DELTAD (DEscription Logics with TrAnsformers) 데이터셋은 $	extmath{ALCQ}$ 언어를 기반으로 하며, 질문은 컨텍스트에서 논리적으로 유도되는지를 확인하는 서술을 포함합니다. 우리는监督 세분화된 DeBERTa 모델과 Few-shot prompting을 사용한 대형 언어 모델(GPT-3.5, GPT-4)에 대해 평가를 진행했습니다.

- **Performance Highlights**: DeBERTa 기반 모델은 추론 깊이가 증가하더라도 테스트 세트에서 99.7%의 높은 정확도를 유지했습니다. 덧붙여, GPT 모델도 소수의 샘플(9샷)만으로도 성능이 향상되었습니다. DELTAM의 성능은 데이터셋의 의미론적 특성에 영향을 받지 않았으나, 자연어 문장이 설명 논리 문법으로 변경될 때 정확도가 저하되었습니다.



### Traversing Emotional Landscapes and Linguistic Patterns in Bernard-Marie Kolt\`es' Plays: An NLP Perspectiv (https://arxiv.org/abs/2410.09609)
- **What's New**: 본 연구는 Bernard-Marie Koltès의 희곡에서 언어적 및 정서적 차원을 분석하기 위해 최신의 Natural Language Processing (NLP) 기술을 활용하여, 그의 드라마적 스타일과 내러티브에서의 언어와 정서의 상호작용을 밝혀냅니다. 이를 통해 Koltès의 주제적 탐구를 이해하는데 실질적인 기여를 할 것입니다.

- **Technical Details**: 이 연구는 Koltès의 희곡을 분석하기 위한 세 가지 핵심 목표를 설정하고, 이들을 달성하기 위해 다음과 같은 NLP 기법을 사용합니다: 1) Linguistic Patterns: 단어 빈도, 어휘의 다양성, Type-Token Ratio (TTR)를 통해 Koltès의 언어적 특징을 탐구합니다. 2) Emotional Trajectories: 감정 분석 및 감정 탐지 모델을 통해 그의 내러티브 안에서의 정서적 풍경을 매핑합니다. 3) Dramatic Tension: 희곡 전반에 걸쳐 감정의 표현을 정량화하여 Koltès 작업의 극적 긴장도와 페이싱을 분석합니다.

- **Performance Highlights**: 이 연구는 Koltès의 가장 잘 알려진 작품들인 'Dans la Solitude des Champs de Coton', 'La Nuit Juste Avant les Forêts', 그리고 'Combat de Nègre et de Chiens'을 중심으로 진행되며, 각 작품의 복잡한 언어 스타일과 감정적 깊이를 정량적으로 분석하여 Koltès의 드라마 예술에 대한 새로운 통찰을 제공합니다.



### I or Not I: Unraveling the Linguistic Echoes of Identity in Samuel Beckett's "Not I" Through Natural Language Processing (https://arxiv.org/abs/2410.09608)
- **What's New**: 본 연구는 Samuel Beckett의 'Not I'에 대한 고급 자연어 처리(Natural Language Processing) 기법을 활용하여 텍스트의 복잡한 언어 구조를 탐구합니다. BERT 기반 모델을 통해 감정적인 요소를 감지하고, 단어 빈도를 분석하며 반복적인 모티프를 살펴봄으로써 Beckett의 미니멀하면서도 복잡한 언어가 주인공의 단절된 심리를 어떻게 반영하는지를 드러냅니다.

- **Technical Details**: 이 논문은 'Not I'의 언어적 복잡성과 존재론적 주제를 분석하며, 자아 정체성, 고립, 의미의 투쟁을 다룹니다. 세 가지 주요 분석이 진행되었습니다: (1) Word Frequency Analysis - 텍스트 내에서 자주 등장하는 단어를 시각적으로 표현하여 주제를 강조합니다. (2) Emotional Analysis - BERT 기반의 감정 인식 모델을 사용하여 감정의 변화를 분석합니다. (3) Repetitive Pattern Analysis - 반복적인 단어와 동기를 조사하여 Beckett의 반복 사용 방식과 구조적 요소를 조명합니다.

- **Performance Highlights**: 연구 결과는 'Not I'에서 시간, 기억 및 존재적 불안의 반복 주제가 언어적 패턴과 리듬적 반복을 통해 예술적으로 엮여 있다는 것을 보여줍니다. 이러한 접근법은 Beckett의 스타일 기여를 깊이 이해하고, 현대 문학에서 언어가 단순한 의사소통을 넘어 존재론적 질문을 탐구하는 독특한 역할을 강조합니다.



### Toward General Instruction-Following Alignment for Retrieval-Augmented Generation (https://arxiv.org/abs/2410.09584)
Comments:
          Working in progress

- **What's New**: 이 연구에서는 Retrieval-Augmented Generation (RAG) 시스템의 instruction-following (IF) 정렬을 위한 최초의 자동화된, 확장 가능하며 검증 가능한 합성 파이프라인인 VIF-RAG를 제안합니다.

- **Technical Details**: VIF-RAG는 100개 미만의 최소 원자 지침을 수동으로 작성하고, 복잡한 지침을 합성하고 검증하기 위한 조합 규칙을 개발합니다. 감독 모델을 사용하여 지침을 재작성하고, Python 실행기를 통해 지침 품질을 자동으로 검증하는 코드를 생성합니다. 이 과정을 통해 >100k 규모의 고품질 VIF-RAG-QA 데이터셋을 자동으로 생성합니다. 또한 FollowRAG Benchmark를 도입하여 약 3천 개의 테스트 샘플과 22개 범주의 일반 지침 제약과 4개 지식 집약적 QA 데이터셋을 포함합니다.

- **Performance Highlights**: FollowRAG를 사용하여 VIF-RAG가 LLM 성능을 일반 지침 제약의 넓은 범위에서 크게 향상시키는 것을 보여줍니다. 해당 연구는 RAG 시스템에서 IF 정렬을 달성하기 위한 실용적인 통찰력을 제공합니다.



### SAPIENT: Mastering Multi-turn Conversational Recommendation with Strategic Planning and Monte Carlo Tree Search (https://arxiv.org/abs/2410.09580)
- **What's New**: 본 연구에서는 대화형 추천 시스템(Conversational Recommender Systems, CRS)을 위한 새로운 Monte Carlo Tree Search (MCTS) 기반 프레임워크인 SAPIENT를 제안합니다. 이 프레임워크는 사용자 선호도를 효과적으로 이해하고 개인화된 추천을 제공하는 기능을 강화합니다.

- **Technical Details**: SAPIENT은 대화형 에이전트(S-agent)와 대화 계획 수립자(S-planner)로 구성되어 있습니다. S-planner는 S-agent가 제안한 초기 행동에 따라 MCTS를 활용하여 대화 검색 트리를 구축하고 최적의 대화 계획을 찾습니다. 이에 따라 S-agent는 선택된 행동을 반복적으로 학습하여 대화 계획 능력을 향상시킬 수 있습니다.

- **Performance Highlights**: SAPIENT는 4개의 벤치마크 데이터셋에서 9개의 최첨단 CRS 모델을 초월하여 우수한 성능을 발휘하는 것으로 확인되었습니다. 또한, SAPIENT-e는 효율성을 높이기 위해 모든 대화 경로를 이용한 훈련을 통해 트레이닝 비용을 절감하고 성능을 개선합니다.



### The Future of Learning in the Age of Generative AI: Automated Question Generation and Assessment with Large Language Models (https://arxiv.org/abs/2410.09576)
Comments:
          Book Chapter (Under Review)

- **What's New**: 최근 몇 년 동안, 대규모 언어 모델(LLMs)과 생성 AI는 자연어 처리(NLP) 분야에 혁신을 가져왔습니다. 이 논문은 LLMs가 자동 질문 생성 및 답변 평가에서 갖는 변혁적 잠재력에 대해 다룹니다.

- **Technical Details**: 대규모 언어 모델(LLMs)은 심층 학습(deep learning)과 트랜스포머 아키텍처(transformer architecture)에 기반하여 구축됩니다. LLMs는 주어진 입력에 따라 텍스트를 예측하고 생성하도록 설계되었으며, 자가 주의(self-attention) 메커니즘을 사용하여 문장 내 단어의 상대적 중요성을 평가합니다. 다양한 방법론이 질문 생성에 사용되며, 제로샷(zero-shot) 및 체인 오브 소스(chain-of-thought) 프롬프트 방식이 효과적으로 작용합니다.

- **Performance Highlights**: 이 논문에서는 LLMs가 생성한 질문의 품질을 인적 평가를 통해 파악하고, 생성된 질문의 품질 변동성을 강조합니다. LLMs는 자동 답변 판단에서도 성공적인 사례와 개선이 필요한 영역을 보여주며, 인적 평가가 비용과 시간을 줄이는 데 강력한 대체제가 될 수 있음을 강조합니다.



### Are You Human? An Adversarial Benchmark to Expose LLMs (https://arxiv.org/abs/2410.09569)
- **What's New**: 이번 논문에서는 대규모 언어 모델(LLM)이 사람을 속일 수 있는 가능성에 대해 집중적으로 논의하고, 인간이 LLM과 소통하는 과정에서 이를 탐지할 수 있는 방법을 제안합니다. 특히, 명시적(challenges)과 암시적(challenges) 도전 과제를 통해 LLM을 직면하게 하는 새로운 방식을 제안하고, 이를 검증하기 위한 오픈 소스 벤치마크 데이터셋도 공개하였습니다.

- **Technical Details**: 연구에서는 다양한 LLM 모델을 대상으로 실시간 대화에서 LLM을 탐지하기 위한 도전 과제를 설정하였습니다. 명시적 챌린지는 LLM이 수행하기 어려운 간단한 작업을 요구하고, 암시적 챌린지는 LLM의 지침 따르기 메커니즘을 악용하여 역할 벗어나기를 초래하는 방식입니다. 9개의 주요 언어 모델의 평가 결과, 명시적 챌린지는 78.4%의 성공률을 보였고, 암시적 챌린지는 22.9%에 머물렀습니다.

- **Performance Highlights**: 사용자 연구를 통해, 인간이 명시적 챌린지에서 78%의 성공률을 기록하여 LLM의 22%와 비교되었습니다. 이 결과는 사용자가 LLM을 적발하는 데 성공적인 공격 방법을 개발할 수 있음을 시사합니다. 추가적으로, 연구 참가자들이 LLM을 사용하여 테스트 작업을 완료한 사실이 드러나, LLM 탐지와 인공지능 도구의 남용 방지 모두에서 연구 방법의 효과성을 보여주었습니다.



### Extended Japanese Commonsense Morality Dataset with Masked Token and Label Enhancemen (https://arxiv.org/abs/2410.09564)
- **What's New**: 이번 연구에서는 일본의 도덕성에 초점을 맞춘 유일한 공개 데이터셋인 JCommonsenseMorality (JCM)를 확장하여 Extended JCM (eJCM) 데이터셋을 구축했습니다. 개선된 데이터 생성 방법인 Masked Token and Label Enhancement (MTLE)를 통해 원래 13,975개의 문장에서 31,184개의 문장으로 확장했으며, 이는 다문화 및 지역적 맥락을 반영합니다.

- **Technical Details**: MTLE는 도덕적 판단과 관련된 문장의 중요한 부분을 선택적으로 마스킹하고, 대규모 언어 모델 (LLM)을 통해 생성된 대체 표현으로 교체합니다. 새롭게 생성된 문장에 적절한 라벨을 다시 할당하는 방식으로, eJCM 데이터셋을 통해 약 31K 문장에 대해 훈련된 RoBERTa 모델의 성능이 GPT-4 Turbo에 근접했습니다.

- **Performance Highlights**: eJCM을 사용하여 훈련된 모델은 F1 점수 0.857을 기록하여 원본 JCM(0.837), ChatGPT 1-shot 분류(0.841), 그리고 AugGPT(0.850)보다 높은 성능을 보였습니다. 특히 일본 문화에 특화된 복잡한 도덕적 추론 과제에서 성능이 크게 개선되어 0.681에서 0.756으로 증가하였고, 이는 GPT-4 Turbo(0.787)와 비슷한 수준입니다.



### A Speaker Turn-Aware Multi-Task Adversarial Network for Joint User Satisfaction Estimation and Sentiment Analysis (https://arxiv.org/abs/2410.09556)
- **What's New**: 이 논문에서는 사용자 만족도 추정(User Satisfaction Estimation, USE)과 감정 분석(Sentiment Analysis, SA)을 효과적으로 결합하기 위한 새로운 방법론인 Speaker Turn-Aware Multi-Task Adversarial Network (STMAN)를 제안하고 있습니다. 특히, STMAN은 각 발화 표현을 작업에 특화된 요소로 구분하고, 발화자 전환을 인식하여 공통 감정 특성을 추출하는 독창적인 멀티 태스크 적대적 전략을 사용합니다.

- **Technical Details**: STMAN 모델은 멀티 태스크 적대적 전략을 도입하여 작업 분별기를 훈련시킴으로써 발화 표현을 더욱 작업 특화적으로 만듭니다. 또한, 발화자 전환 인식 멀티 태스크 상호작용 전략을 통해 각 작업에 보완적인 공통 특성을 추출합니다. 이러한 접근법은 대화 내용과 발화자의 감정 상태 간의 상관관계를 명확히 하여, 사용자 만족도와 감정 분석을 동시에 개선합니다.

- **Performance Highlights**: 두 개의 실제 서비스 대화 데이터셋에서 수행된 광범위한 실험을 통해, STMAN 모델이 기존의 여러 최첨단 방법들보다 뛰어난 성능을 보임을 입증했습니다. 이 연구의 결과는 사용자 만족도와 감정 상태 간의 관계를 잘 포착함으로써 고품질 대화 시스템 개발에 기여할 것입니다.



### MIRAGE: Evaluating and Explaining Inductive Reasoning Process in Language Models (https://arxiv.org/abs/2410.09542)
Comments:
          25 pages,9 figures, under review

- **What's New**: 이번 연구에서는 LLM(대형 언어 모델)의 유도 추론(inductive reasoning) 능력을 평가하기 위한 새로운 데이터셋인 Mirage를 소개합니다. 이 데이터셋은 기존의 연구에서 나타난 포괄적인 평가 부족과 유연한 테스트 데이터 부족 문제를 해결합니다.

- **Technical Details**: Mirage 데이터셋은 유도(inductive) 및 연역(deductive) 평가 작업을 포함하며, 다양한 형태의 테스트 데이터를 구성할 수 있는 유연성을 제공합니다. 데이터셋 구성은 벡터 연산을 기반으로 한 규칙 라이브러리를 통해 이루어지며, 관찰된 사실을 자동으로 생성하고 필터링하여 데이터의 질을 높입니다.

- **Performance Highlights**: 연구에 따르면 LLM은 규칙 기반(reasoning) 추론 능력이 낮고, 올바른 규칙 없이도 연역 작업에서는 뛰어난 성능을 보입니다. 그러나 LLM은 이웃 기반(neighbor-based) 추론에서는 우수한 성능을 발휘하며, 유사한 사실에 집중함으로써 국소 영역 내에서 강력한 유도 능력을 유지합니다.



### LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning (https://arxiv.org/abs/2410.09541)
Comments:
          Accepted by EMNLP 2024 Findings

- **What's New**: 이 연구는 LLM의 commonsense reasoning (상식 추론) 능력을 향상시키기 위해 LINKED라는 새로운 방법을 제안합니다. 이 방법은 noisy knowledge (잡음 지식)와 invalid reasoning (잘못된 추론) 문제를 해결하는 데 중점을 두고 있습니다.

- **Technical Details**: LINKED 방법은 보상 모델(reward model)을 설계하여 LLM이 생성한 잡음 지식을 필터링하고, marginal consistent reasoning module을 통해 무효 추론을 줄입니다. 새로운 메트릭인 effectiveness-preservation score (EPS)를 도입하여 Knowledge augmentation (지식 증강)의 긍정적 및 부정적 영향을 평가합니다.

- **Performance Highlights**: LINKED 방법은 두 가지 복잡한 상식 추론 벤치마크에서 실험을 통해 SOTA 기준선보다 최대 9.0%의 정확도 향상과 12.5%의 EPS 향상을 가져왔습니다. 또한 LLM의 상식 추론에 관한 많은 의미 있는 결론을 도출했습니다.



### LexSumm and LexT5: Benchmarking and Modeling Legal Summarization Tasks in English (https://arxiv.org/abs/2410.09527)
Comments:
          Accepted to NLLP Workshop, EMNLP 2024

- **What's New**: 본 연구에서는 기존의 법률 NLP 벤치마크들이 예측 작업에만 중점을 두는 것과 달리, 생성 작업을 평가할 수 있는 LexSumm이라는 새로운 벤치마크를 개발했습니다. LexSumm은 미국, 영국, 유럽연합 및 인도를 포함한 다양한 관할권의 8개의 영어 법률 요약 데이터 세트로 구성됩니다.

- **Technical Details**: LexSumm은 법률 문서의 특성과 긴 길이를 고려하여, LED와 LongT5와 같은 긴 맥락 모델을 사용하여 평가합니다. 또한, LexT5라는 법률 지향의 sequence-to-sequence 모델을 소개하며, 이는 LeXFiles 코퍼스에서 사전 학습되었습니다. LexT5의 성능은 LegalLAMA에서의 제로샷 평가와 LexSumm 데이터 세트를 통한 미세 조정을 통해 분석됩니다.

- **Performance Highlights**: LexSumm에서의 정량적 및 정성적 분석 결과, LexSumm은 기존 모델, 특히 제로샷 LLM인 GPT-3.5에게 상당한 도전 과제를 제시하고 있으며, 추가 개선의 기회가 많다는 것을 보여줍니다.



### Emphasis Rendering for Conversational Text-to-Speech with Multi-modal Multi-scale Context Modeling (https://arxiv.org/abs/2410.09524)
Comments:
          submitted to IEEE Transaction

- **What's New**: 최근의 Conversational Text-to-Speech (CTTS) 연구에서, 이야기의 맥락을 이해하고 적절한 강조 표현을 생성하는 과제를 다룬 새로운 Emphasis Rendering 방안인 ER-CTTS를 제안합니다. 이 모델은 문맥에 대한 포괄적인 이해를 위해 문자(text) 및 음향(acoustic) 정보를 동시에 고려하며, 대화 맥락에서의 강조 표현을 개선하기 위한 것입니다.

- **Technical Details**: ER-CTTS는 두 가지 주요 구성 요소로 나뉩니다. 첫째, 텍스트 및 음향 문맥을 동시에 고려하여 대화 기록 내에서 각 수준의 의미 모델링을 수행합니다. 둘째, 다중 모드(multi-modal) 및 다중 스케일(multi-scale) 정보를 통합하여 현재 발화의 강조 표현에 대한 영향을 학습합니다. 마지막으로, 추론된 강조 특성이 신경 음성 합성기(neural speech synthesizer)에 투입되어 대화형 음성을 생성합니다.

- **Performance Highlights**: 객관적 및 주관적 평가 결과, 제안한 ER-CTTS 모델은 기존의 여러 기준 모델들보다 강조 표현에서 우수한 성능을 보였습니다. 이 연구의 데이터는 모두 공개되며, 특히 DailyTalk 데이터셋에 기반한 강조 강도 주석(annotation) 작업을 포함하고 있습니다.



### CollabEdit: Towards Non-destructive Collaborative Knowledge Editing (https://arxiv.org/abs/2410.09508)
- **What's New**: 이번 논문에서는 협업적 지식 편집(Collaborative Knowledge Editing)에 대한 첫 번째 연구를 진행하며, 여러 당사자의 지식 편집을 비공식 보호와 지속적인 방식으로 집계하는 문제를 탐구합니다. 이를 통해 지식 중복(knowledge overlap), 지식 충돌(knowledge conflict), 지식 망각(knowledge forgetting)이라는 세 가지 독특한 도전 과제를 제시합니다.

- **Technical Details**: 제안된 비파괴적 협업 KE 프레임워크인 COLLABEDIT는 새로운 모델 병합 메커니즘(model merging mechanism)을 사용하여 전세계적 KE 행동을 모방하면서도 성능 저하를 방지합니다. 이 프레임워크는 여러 당사자의 지식 편집을 보다 안전하고 효율적으로 수행할 수 있도록 설계되었습니다.

- **Performance Highlights**: COLLABEDIT는 두 개의 표준 데이터셋에서 실시된 광범위한 실험을 통해 다른 파괴적 기준선보다 뛰어난 성능을 보여주었습니다. 이 결과는 협업 KE의 세 가지 도전 과제를 다루고 미래 응용 가능성을 제시하는 데 중요한 통찰을 제공합니다.



### AERA Chat: An Interactive Platform for Automated Explainable Student Answer Assessmen (https://arxiv.org/abs/2410.09507)
- **What's New**: AERA Chat 플랫폼은 LLM을 활용하여 학생 답안 평가 및 이론 생성을 동시에 수행하며, 교육자와 연구자들에게 새로운 환경을 제공합니다.

- **Technical Details**: 이 플랫폼은 사용자 인터페이스가 설계되어 있으며, 여러 LLM을 사용하여 자동 평가 결과를 시각적으로 설명합니다. 사용자는 질문과 학생 답안을 입력해 LLM로부터 자동화된 설명 가능한 결과를 얻을 수 있습니다.

- **Performance Highlights**: 플랫폼은 세 가지 이론 생성 방법에 대해 평가를 수행하였으며, 이는 LLM의 평가 성능과 생성된 이론의 품질을 비교 분석할 수 있게 합니다.



### Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks (https://arxiv.org/abs/2410.09489)
Comments:
          EMNLP 2024 Findings

- **What's New**: 최근의 대규모 언어 모델(LLMs) 발전으로 시각적 추론(visual reasoning) 작업에서 개선된 성능을 보여주고 있습니다. 본 연구에서는 Q-Former에 대한 매개변수 효율적 미세 조정(parameter efficient fine-tuning, PEFT)의 효과를 InstructBLIP 모델을 사용하여 분석합니다.

- **Technical Details**: Q-Former를 통해 여러 모달리티(예: 이미지, 비디오, 오디오, 3D) 간의 정렬을 도모했습니다. PEFT를 통해 2% 미만의 훈련 가능한 매개변수로 전체 미세 조정(full fine-tuning)과 유사한 성능을 달성할 수 있음을 보여줍니다. 또한, AdaLoRA를 사용하여 Q-Former의 하위 층(sub-layers) 중요성을 평가했습니다.

- **Performance Highlights**: 자기 주의(self-attention) 층이 시각-언어 정렬이 중요한 작업에서 더 높은 중요성을 가지며, FFN 층의 중요성은 작업에 따른 시각-언어 패턴의 복잡성에 따라 다르다는 것을 발견했습니다.



### Automatic Speech Recognition with BERT and CTC Transformers: A Review (https://arxiv.org/abs/2410.09456)
- **What's New**: 최근 자동 음성 인식(ASR) 분야에서 BERT와 연결주의 시간 분류(CTC) 변환기를 활용한 진전이 두드러지고 있습니다. 이 리뷰 논문은 이러한 모델의 구조와 ASR에서의 응용 가능성을 설명하고 있으며, 관련 연구 결과를 심층적으로 검토하였습니다.

- **Technical Details**: ASR의 전통적인 방법은 최대 사후 확률 추정을 기반으로 하며, 이는 음향 특징을 단어 시퀀스로 변환하는 네 가지 단계(특징 추출, 음향 모델링, 언어 모델링, 단어 시퀀스 디코딩)로 구성됩니다. BERT 및 CTC 변환기는 자기 주의(self-attention) 메커니즘을 사용하여 이러한 단계들을 단일 네트워크에서 동시에 수행합니다. 또한, BERT는 언어 이해를 위한 사전 훈련 모델로, 언어 모델링 및 맥락적 관계 이해에서 강력한 성능을 보여줍니다.

- **Performance Highlights**: BERT 및 CTC 기반 ASR 시스템의 활용은 기존의 최첨단 시스템들을 능가하는 성과를 거두었으며, 특히 음성 질문 응답(task of spoken multiple-choice question answering)에서 뛰어난 정확도를 달성했습니다. 일부 연구에서는 그래프 합성곱 신경망을 활용하여 ASR 성능을 개선하는 기법을 제안하고 있습니다.



### VERITAS-NLI : Validation and Extraction of Reliable Information Through Automated Scraping and Natural Language Inferenc (https://arxiv.org/abs/2410.09455)
Comments:
          Preprint, 15 pages, 7 figures

- **What's New**: 본 논문에서는 실시간 정보 검증을 위해 Web-scraping 기법과 Natural Language Inference (NLI) 모델을 활용하는 새로운 솔루션인 VERITAS-NLI를 제안합니다. 기존 모델들은 학습 데이터에 의존하며 새로운 헤드라인에 대한 일반화가 어려운 문제를 해결하고자 합니다.

- **Technical Details**: VERITAS-NLI는 외부 신뢰 가능한 정보와 실시간으로 비교하여 헤드라인의 진위를 검증합니다. 이를 위해 소규모 언어 모델을 사용하여 헤드라인에 기반한 질문을 생성하고, 다양한 NLI 모델을 통해 스크랩된 기사와 헤드라인 간의 일관성을 평가합니다. 이 기술은 고전적인 데이터에 의존하지 않고, 실시간 정보를 검증하여 동적인 콘텐츠에 적응하도록 설계되었습니다.

- **Performance Highlights**: VERITAS-NLI의 성능은 최적화된 파이프라인이 84.3%의 정확도를 달성하며, 기존의 고전적인 머신러닝 모델보다 33.3% 더 높고, BERT 모델보다 31.0% 높은 정확도를 기록했습니다. 이러한 결과는 웹 스크래핑과 NLI의 결합이 뉴스 검증에 효과적임을 보여줍니다.



### Interpretable Video based Stress Detection with Self-Refine Chain-of-thought Reasoning (https://arxiv.org/abs/2410.09449)
Comments:
          Under Progress

- **What's New**: 본 연구에서는 비디오 기반의 스트레스 감지에 대한 새로운 해석 가능 접근법을 제안하고 있습니다. 이 방법은 Chain-of-Thought (CoT) 추론을 활용하여 정확도와 결정 과정의 투명성을 향상시킵니다.

- **Technical Details**: 우리는 비디오 시퀀스에서 스트레스 수준을 나타내는 미세한 행동 및 생리적 신호를 추출하는 데 집중하고 있습니다. CoT 추론 메커니즘을 통합하여 시스템은 예측을 반복적으로 개선하고, 결정 과정이 추적되고 설명될 수 있도록 합니다. 또한, 자기 보정 메커니즘을 통해 피드백 루프를 학습하여 추론 능력을 향상시킵니다.

- **Performance Highlights**: 여러 공개 및 민간 데이터셋에서 본 접근법을 평가하여 기존의 비디오 기반 스트레스 감지 방법보다 뛰어난 성능을 입증하였습니다. 이 시스템은 의료와 인간-컴퓨터 상호작용 분야에서의 응용 가능성을 높이고, 모델 예측의 해석 가능성에 대한 포괄적인 통찰을 제공합니다.



### Solving the Challenge Set without Solving the Task: On Winograd Schemas as a Test of Pronominal Coreference Resolution (https://arxiv.org/abs/2410.09448)
Comments:
          CoNLL 2024

- **What's New**: 이번 연구는 Winograd Schema Challenge (WSC)에 대한 기존의 가정인 ‘도전 세트를 해결하는 것이 더 일반적인 작업을 해결하는 것만큼 어려운 경우가 많다’는 점이 항상 참이 아니라고 주장합니다. 구체적으로, WSC에서의 성능이 뛰어난 언어 모델이 자연어 자료에서 비교적 쉬운 대명사 모호성을 해결하는 데는 덜 정확하다는 것을 입증합니다.

- **Technical Details**: 연구에서는 Llama와 같은 언어 모델(LM)로 구성된 시스템의 성능을 분석합니다. 총 11개의 데이터 세트를 평가하였으며, 이 중 6개는 자연 언어 자료에서 확인된 대명사 문제를 포함하고, 5개는 WSC와 유사한 도전 세트 문제로 구성됩니다. 연구팀은 이러한 LM을 감독된 시스템과 앙상블하여 대명사 교차참조를 더 정확하게 해결하는 방법을 제안합니다.

- **Performance Highlights**: 모델을 평가한 결과, unsupervised 기준선에 비해 LM이 전반적으로 더 정확하긴 하나, 감독된 대명사 해석 모델이 WSC에서 상대적으로 부정확했음에도 불구하고, 특정 대명사를 해결하는 데 있어서 LM보다 더 우수한 것으로 나타났습니다. 결과적으로, 앙상블 방법을 통해 대명사 해석의 정확성을 높일 수 있음을 보여줍니다.



### FlatQuant: Flatness Matters for LLM Quantization (https://arxiv.org/abs/2410.09426)
Comments:
          23 pages

- **What's New**: 본 논문은 LLM의 포스트 트레이닝 양자화 방법인 FlatQuant(빠르고 학습 가능한 아핀 변환)를 제안합니다. 이 접근법은 가중치와 활성화를 더 평탄하게 만들어 양자화 오류를 최소화하는 것을 목표로 합니다.

- **Technical Details**: FlatQuant는 각 선형 계층에 맞춤형 아핀 변환을 찾고, 이를 경량화된 목표를 통해 빠르고 효율적으로 보정하는 방법입니다. 또한 Kronecker 분해를 활용하여 변환 행렬의 런타임 오버헤드를 줄이며, 모든 연산을 단일 커널로 융합하여 효율성을 극대화합니다.

- **Performance Highlights**: FlatQuant는 LLaMA-3-70B 모델에 대해 W4A4 양자화를 적용했을 때 1% 이하의 정확도 감소를 기록하며, 이는 SpinQuant보다 7.5% 향상된 결과입니다. 또한 FlatQuant는 예측 지연을 0.26배에서 단 0.07배로 줄이며, 선행 단계에서 최대 2.3배, 디코딩 단계에서 1.7배의 속도 향상을 가져왔습니다.



### Beyond Exact Match: Semantically Reassessing Event Extraction by Large Language Models (https://arxiv.org/abs/2410.09418)
- **What's New**: 본 논문은 이벤트 추출에서의 자동 평가 프레임워크인 RAEE를 제안합니다. 기존의 토큰 단위 정확도 평가 방식의 한계를 극복하고, 의미 수준에서 이벤트 추출 결과를 평가합니다.

- **Technical Details**: RAEE는 대형 언어 모델(LLMs)을 자동 평가 에이전트로 사용하며, 체인 오브 씽킹(chain-of-thought) 프롬프트 및 적응형 메커니즘을 결합하여 트리거와 아규먼트의 정밀도 및 재현율에 대한 해석 가능하고 적응적인 평가를 제공합니다.

- **Performance Highlights**: RAEE는 14개 모델을 10개 데이터셋에서 재평가한 결과, EM 평가보다 훨씬 높은 상관관계를 달성하였으며, 기존 이벤트 추출 모델의 성능이 과소평가되고 있음을 보여줍니다. 특히, 생성형 LLM의 성능 향상이 부각되었습니다.



### FB-Bench: A Fine-Grained Multi-Task Benchmark for Evaluating LLMs' Responsiveness to Human Feedback (https://arxiv.org/abs/2410.09412)
- **What's New**: FB-Bench라는 새로운 다중 작업 벤치마크를 소개하여 LLM(대형 언어 모델)의 인간 피드백에 대한 반응성을 평가하고, 실제 사용 시나리오에서의 성능을 다각적으로 분석합니다.

- **Technical Details**: FB-Bench는 734개의 샘플과 8개의 작업 유형, 5개의 응답 결함 유형, 9개의 피드백 유형을 포함하는 정교한 구조를 가지며, GPT-4o를 평가자로 활용하여 LLM의 후속 응답의 품질을 평가합니다.

- **Performance Highlights**: 많은 LLM들이 오류 수정 시나리오에서 더 나은 성능을 보였으며, 피드백이 명확할 때 LLM의 응답 품질이 향상되는 경향이 발견되었습니다. LLM들의 성능은 오류 수정에서는 비슷한 반면, 응답 유지 관리에서는 성능이 다양하게 나타났습니다.



### CAMPHOR: Collaborative Agents for Multi-input Planning and High-Order Reasoning On Devic (https://arxiv.org/abs/2410.09407)
- **What's New**: 본 논문에서는 CAMPHOR라는 혁신적인 온디바이스 Small Language Model(SLM) 멀티 에이전트 프레임워크를 도입합니다. 이 프레임워크는 사용자 입력을 처리하고 개인 컨텍스트에 대해 로컬에서 추론하도록 설계되었습니다.

- **Technical Details**: CAMPHOR는 복잡한 작업을 분해하고 개인 컨텍스트 검색, 도구 상호작용 및 동적 계획 생성을 담당하는 전문가 에이전트를 조정하는 고차원 추론 에이전트로 구성된 계층적 아키텍처를 사용합니다. 에이전트 간의 파라미터 공유 및 프롬프트 압축을 통해 모델 크기, 지연(latency), 메모리 사용량을 대폭 줄입니다.

- **Performance Highlights**: 우리의 실험 결과, 미세 조정(fine-tuning)된 SLM 에이전트가 닫힌 소스의 LLM 대비 태스크 완료 F1 점수를 약 35% 향상시켰으며, 서버-디바이스 간의 통신이 필요 없던 점을 강조합니다. 또한, 개인 정보 보호를 강화하는 데 기여합니다.



### Text Classification using Graph Convolutional Networks: A Comprehensive Survey (https://arxiv.org/abs/2410.09399)
- **What's New**: 본 연구는 최근 10년 간 Graph Convolution Network (GCN)을 기반으로 한 텍스트 분류 접근법을 심층적으로 조사하고 이러한 방법들의 구조 및 감독 방식에 따라 분류하고 요약합니다. GCN 기반 접근법은 최신 문헌에서 다양한 벤치마크 데이터셋에서 뛰어난 성능을 보여주고 있어, 이 분야에서의 새롭고 효율적인 기법 탐색이 필요합니다.

- **Technical Details**: 텍스트 분류는 디지털 문서의 출현 이후 자동화된 분류 필요성이 커지면서 발전해왔습니다. 이 연구는 GCN을 활용하여 여러 텍스트 유형(단어, 구, 문장 등)에서 텍스트를 분류하는 다양한 방법들을 살펴보며, 이들 방법의 강점과 약점을 비교합니다. 최근에는 BERT와 같은 transformer 기반 모델이 NLP 작업에 탁월한 성능을 보이고 있습니다.s

- **Performance Highlights**: GCN 기반 방법 및 기타 신경망(Neural Network) 접근법들이 다양한 벤치마크 데이터셋에서 우수한 성과를 거두었습니다. 예를 들어, BERT 모델은 많은 NLP 작업에서 뛰어난 결과를 달성하며, 이 연구에서는 BERT 및 다른 transformer 모델의 효과적인 활용에 대해 논의합니다.



### Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation (https://arxiv.org/abs/2410.09350)
Comments:
          EMNLP (main)

- **What's New**: 이 연구에서는 DialogGSR(Dialog generation with Generative Subgraph Retrieval) 모델을 제안하여 지식 그래프 기반 대화 생성의 정확성을 높입니다. 이 모델은 단일 벡터 표현에 의한 정보 병목현상을 해결하고, 사전 훈련된 언어 모델의 지식을 활용하여 관련 지식 서브그래프를 효과적으로 검색합니다.

- **Technical Details**: 제안한 모델은 두 가지 주요 방법론을 포함합니다. 첫째, self-supervised 그래프 전용 토큰을 활용한 구조 인식 지식 그래프 선형화입니다. 둘째, 그래프 구조 근접성 기반의 엔티티 정보 점수를 활용한 그래프 제약 디코딩입니다. 이를 통해 다중 회차 대화의 복잡성을 효과적으로 처리할 수 있습니다.

- **Performance Highlights**: DialogGSR은 OpenDialKG 및 KOMODIS 데이터셋에서 최신 성능을 달성하였으며, 지식 그래프 기반 대화 생성에서 최고의 결과를 보입니다.



### ELICIT: LLM Augmentation via External In-Context Capability (https://arxiv.org/abs/2410.09343)
Comments:
          Work in progress

- **What's New**: 이 논문에서는 LLM(대형 언어 모델)의 적응 능력을 향상시키기 위한 새로운 접근 방식인 ELICIT를 소개합니다. ELICIT는 모듈화(modularization) 개념에 영감을 받아, 다양한 기능을 효율적으로 활용할 수 있도록 설계된 두 개의 구조로 구성되어 있습니다.

- **Technical Details**: ELICIT 프레임워크는 'Task Vectors'라는 개념을 통해, 이전 학습에서 수집한 기능을 외부에서 저장하고 재사용하는 방법을 제공합니다. 이러한 접근 방식을 통해, 새로운 작업에 대한 적응 및 모델의 고유한 기능을 효과적으로 발휘할 수 있습니다. ELICIT는 특정 작업을 위해 설계된 데모나 경직된 템플릿 없이도 유연하게 작업을 처리할 수 있게 해줍니다.

- **Performance Highlights**: 실험 결과, ELICIT는 20,2020개의 작업과 444개 모델에 걸쳐 평균 11.4%의 성능 향상을 달성했으며, 기존 토큰 사용에서 약간의 개선을 보여주었습니다. 특히, 수학 전용 기능 라이브러리를 통한 실험에서 수학 문제 해결 성능이 크게 향상되었습니다.



### LLM$\times$MapReduce: Simplified Long-Sequence Processing using Large Language Models (https://arxiv.org/abs/2410.09342)
Comments:
          Work in Progress. Code: this https URL

- **What's New**: 본 연구에서는 긴 문서를 처리하기 위한 novel training-free 프레임워크인 LLM×MapReduce를 제안합니다. 이 프레임워크는 divide-and-conquer 전략을 활용하여 전체 문서를 여러 개의 청크로 나누고, 중간 대답을 집계하여 최종 출력을 생성하는 방법을 제시합니다.

- **Technical Details**: LLM×MapReduce 프레임워크는 입력 문서를 청크로 나누고 각 청크를 처리하여 intermediate outputs를 생성한 후, 이들을 집계하여 답변을 도출합니다. 이 과정에서 inter-chunk dependency와 inter-chunk conflict 문제를 해결하기 위해 structured information protocol과 in-context confidence calibration mechanism을 도입하여 정확한 답변 예측을 지원합니다.

- **Performance Highlights**: 실험 결과, LLM×MapReduce 프레임워크는 기존의 오픈소스 및 상용 긴 문맥 LLM들을 초월하는 성능을 보였으며, 다양한 모델에 적용 가능합니다. 각 구성 요소의 효과를 검증하기 위한 ablation 실험 역시 진행되었습니다.



### Keys to Robust Edits: from Theoretical Insights to Practical Advances (https://arxiv.org/abs/2410.09338)
Comments:
          Work in progress

- **What's New**: 이번 연구는 대형 언어 모델(LLMs)의 지식 편집 이론과 실증적 분석을 통해 수정 실패의 원인을 조명하고, Robust Edit Pathway (REP)라는 새로운 모델을 제안합니다. REP는 LLM의 내부 표현에서 편집 키를 분리하여 편집 정확도를 향상시키도록 설계되었습니다.

- **Technical Details**: 연구팀은 locate-and-edit 방법의 편집 키와 LLM의 내부 표현 간의 미접합 문제를 해결하기 위해 REP를 개발하였습니다. 이 방법은 게이트 메커니즘을 통해 편집이 필요한 키를 집계하고, 다른 표현은 그대로 유지합니다. 이 모델은 LLaMA2-7B와 Mistral-7B에서 CounterFact 데이터셋을 사용하여 평가되었습니다.

- **Performance Highlights**: REP는 여러 강건성(metric robustness) 테스트에서 성능을 크게 개선했으며, 성공률과 지역성(locality)에서 최소한의 트레이드오프를 보였습니다. 이는 기존의 지식 편집 기술에서 나타나는 주요 강건성 문제를 효과적으로 해결하고 LLM의 신뢰할 수 있는 지식 업데이트를 위한 발전을 보여줍니다.



### Rethinking Data Selection at Scale: Random Selection is Almost All You Need (https://arxiv.org/abs/2410.09335)
- **What's New**: 이 논문에서는 대규모 데이터셋에서의 Self-scoring 방법으로 데이터 선택의 효율성을 분석했습니다. 특히, 고품질 데이터보다 데이터 다양성이 더 중요한 요소라는 새로운 통찰을 제공함으로써 기존 SFT (supervised fine-tuning) 방법론에 대한 경각심을 일으키고 있습니다.

- **Technical Details**: 대규모 IT 데이터에서 Self-scoring 방법을 분석하며, 특히 데이터 길이 기반의 필터링 방식이 SFT 성능을 개선하는 데 효과적임을 입증했습니다. 이러한 방식은 Llama3와 같은 상대적으로 낮은 성능의 모델에 특히 유용하다고 설명하고 있습니다.

- **Performance Highlights**: 대규모 데이터셋에서 대부분의 Self-scoring 기술이 무작위 선택(random selection)에 비해 유의미한 성능 향상을 보여주지 못 했습니다. 그러나 토큰 길이 기반 필터링 전략이 SFT 결과를 안정적이고 효율적으로 개선하는데 기여한다고 명시했습니다.



### Hey AI Can You Grade My Essay?: Automatic Essay Grading (https://arxiv.org/abs/2410.09319)
Comments:
          Accepted in ICAAAIML (4th International Conference on Advances and Applications of Artificial Intelligence and Machine Learning) 2023

- **What's New**: 이 논문에서는 자동 에세이 채점(AEG) 분야에서 최첨단 모델을 초월하는 새로운 모델을 소개합니다. 이 모델은 보다 효과적인 채점을 위해 협력적인 딥러닝 구조를 도입했습니다.

- **Technical Details**: 논문은 두 개의 신경망을 사용하는 공동 협업 모델을 제안합니다. 하나의 네트워크는 에세이 문장의 문법적 및 구조적 특성을 확인하고, 다른 네트워크는 에세이의 전체 아이디어를 평가하여 점수를 부여합니다. 이러한 학습은 다른 네트워크로 전이되어 에세이를 점수화합니다.

- **Performance Highlights**: 제안된 모델은 85.50%의 최고 정확도로 다른 다양한 모델과 비교하여 뛰어난 성능을 보여주었습니다.



### Impeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial Perturbation (https://arxiv.org/abs/2410.09318)
- **What's New**: 이 논문은 LLM(대형 언어 모델) 기반 프로그래밍 보조 도구들이 CS(컴퓨터 과학) 교육에서의 부정행도를 촉진할 수 있음을 알리고, 이러한 도구들의 효과성을 저하시킬 수 있는 악의적인 변형 기술을 연구합니다.

- **Technical Details**: 연구는 5개의 LLM을 사용하여 프로그래밍 과제에 대한 정확도를 측정하고, 원본 문제 문장을 클라우드 기반 LLM의 해킹을 방지할 수 있도록 수정하는 방법을 개발합니다. 이 과정에서 SHAP(Shapley Additive Explanations) 기법을 활용하여 변형 기술의 효능을 정량화하고, 사용자 연구를 통해 학생들이 이러한 변형을 인식하고 되돌릴 수 있는지를 분석합니다.

- **Performance Highlights**: LLM의 평균 정확도는 변형 후 평균 77% 감소하며, LLM들이 다수의 함수 및 클래스 간 상호작용을 요구하는 과제를 해결하는 데 어려움을 겪고 있다는 사실이 발견되었습니다. 사용자 연구 결과, 변형이 인지되지 않을 경우 고도의 효능(15%에서 15.43%로 떨어짐)을 유지하면서 코드 생성 방해에 효과적임을 보여주었습니다.



### \llinstruct: An Instruction-tuned model for English Language Proficiency Assessments (https://arxiv.org/abs/2410.09314)
- **What's New**: 이번 연구는 영어 능력 평가(English Language Proficiency Assessments, ELPA)에 특화된 8B instruction-tuned 모델인 ll-instruct를 소개합니다. ll-instruct는 70,000개의 지침 및 설명 데이터셋을 기반으로 Llama-3 8B 모델을 세분화하여 훈련되었습니다.

- **Technical Details**: ll-instruct는 참조 데이터를 사용하여 <instruction, input, output> 쌍을 생성하고, 인간 평가를 통해 성과를 평가합니다. 이 과정에서 SFT-17K, SFT-50K, SFT-70K 모델이 활용됩니다. 추가적으로, 생성된 지침 중 ELPA와 관련이 없는 이들을 배제하기 위해 다른 LLM을 사용하여 필터링합니다.

- **Performance Highlights**: SFT-70K 모델은 유효하고 실제 평가에 적합한 출력을 가장 많이 생성하며, 다소 개선된 출력 설명을 제공합니다. 그러나, 여전히 많은 경우 전문가 수정을 요구합니다.



### Exact Byte-Level Probabilities from Tokenized Language Models for FIM-Tasks and Model Ensembles (https://arxiv.org/abs/2410.09303)
- **What's New**: 이 연구에서는 토큰화(tokenization)가 언어 모델의 성능에 미치는 영향을 분석하고, 통계적으로 동등한 바이트 레벨(byte-level) 모델과의 비교를 통해 '토큰화 편향(tokenization bias)'의 개념을 도입합니다.

- **Technical Details**: 이 연구는 Byte-Token Representation Lemma를 소개하여 학습된 토큰 분포와 그에 상응하는 바이트 레벨 분포 간의 매핑을 정립합니다. 이를 통해 추가 교육이나 최적화 없이도 토큰화 편향을 제거하는 다음 바이트 예측 알고리즘을 개발했습니다.

- **Performance Highlights**: FIM(fil-in-the-middle) 작업에서 18% 성능 개선을 달성했으며, 다양한 표준 기준에서 개별 모델에 비해 3.7% 성능 향상을 보여주었습니다.



### Nudging: Inference-time Alignment via Model Collaboration (https://arxiv.org/abs/2410.09300)
- **What's New**: 이 논문에서는 많은 계산 오버헤드 없이 어떤 기본 모델도 조정할 수 있는 간단한 알고리즘인 'nudging'을 제안합니다.

- **Technical Details**: Nudging은 작은 조정 모델을 사용하여 기본 모델의 출력이 원하는 방향으로 나아가도록 하는 방법으로, 높은 불확실성을 보일 때 'nudging tokens'를 생성합니다.

- **Performance Highlights**: Nudging은 7배에서 14배 작은 조정 모델과 함께 사용하여 추가 훈련 없이도 기존의 큰 조정 모델과 비슷하거나 그 이상의 zero-shot 성능을 달성합니다.



### Comparative Analysis of Static and Contextual Embeddings for Analyzing Semantic Changes in Medieval Latin Charters (https://arxiv.org/abs/2410.09283)
Comments:
          11 pages, 6 figures

- **What's New**: 1066년에 있었던 노르만 정복의 전후 언어 사용 및 단어 의미 변화를 분석한 첫 번째 계산적 연구이다. 이 연구는 Medieval Latin(charters) 문서에서 정적(static) 및 맥락적(contextual) 임베딩(embeddings)의 비교를 통해 어떻게 의미 변화가 발생했는지를 조명한다.

- **Technical Details**: 이 논문은 Medieval Latin(charters) 문서에서의 의미 변화(lexical semantic change, LSC)를 분석하기 위해 정적(word embeddings) 및 맥락적(contextual embeddings) 임베딩을 사용하였다. 데이터셋은 17,000개의 차터(charters)와 300만 개의 토큰(tokens)으로 구성된 DEEDS(Document of Early England Data Set)이다. 본 연구는 기존의 LSC 연구들처럼 정적 임베딩보다 맥락적 임베딩이 의미 변화를 더 잘 포착한다는 결과를 도출하였다.

- **Performance Highlights**: 결과적으로, 맥락적 임베딩이 정적 임베딩보다 높게 평가되었으며, 역사적으로 자원이 부족한 데이터 세트에서도 더 나은 성능을 보여주었다. 이 연구는 Medieval Latin과 같은 희소한 언어에 대한 임베딩의 효용성을 강조하며, 맥락적 임베딩이 효과적으로 의미 변화를 포착할 수 있도록 설계되었음을 입증하였다.



### ReasonPlanner: Enhancing Autonomous Planning in Dynamic Environments with Temporal Knowledge Graphs and LLMs (https://arxiv.org/abs/2410.09252)
- **What's New**: ReasonPlanner는 반사적 사고, 계획 및 상호작용 추론을 위한 새로운 일반ist 에이전트로, LLMs와 Temporal Knowledge Graph를 활용하여 행동 경로를 계획합니다. 이는 사용자에게 머신러닝에 대한 전문 지식 없이도 접근할 수 있도록 설계되었습니다.

- **Technical Details**: ReasonPlanner는 액터-비평가 모듈을 사용하여 자연어로 환경과 상호작용하며, 액터는 가상의 경로를 실행 가능한 단계로 변환하고, 비평가는 재계획 필요성을 평가합니다. 이 에이전트는 동적 시간 지식 그래프를 사용하여 환경 정보를 저장하고 업데이트합니다.

- **Performance Highlights**: ReasonPlanner는 ScienceWorld 벤치마크에서 1.8배 이상의 성능 향상을 보여주며, 평균 점수 65.06점을 기록했습니다. 기존 RL 방법과 LLM 기반 방법에 비해 샘플 효율성과 해석 가능성이 뛰어납니다.



### Sui Generis: Large Language Models for Authorship Attribution and Verification in Latin (https://arxiv.org/abs/2410.09245)
Comments:
          9 pages, NLP4DH 2024

- **What's New**: 본 논문은 Patristic Era의 라틴 텍스트에 대한 저자 게시 및 저자 검증 작업에서 Large Language Models (LLMs)의 성능을 평가합니다. 연구 결과, LLM이 정교한 feature engineering 없이도 짧은 텍스트에 대해 robust한 zero-shot 저자 검증을 수행할 수 있음을 보여줍니다.

- **Technical Details**: LLM은 전통적인 baseline을 일부 조건 하에 초월할 수 있지만, 저자 분석 및 의사 결정의 방향을 잡는 것은 현대 언어의 고급 자원과 관련된 연구들과는 달리 어려움을 겪습니다. 실험을 통해 모델이 의미적으로 '잘못 인도'될 수 있음을 확인했습니다.

- **Performance Highlights**: 정확하고 진정으로 설명 가능한 결정을 얻기 위해서는 많은 실험이 필요하며, LLM은 특정 조건 아래 전통적인 방법을 초월할 수 있지만 저자 분석의 정밀한 제어는 도전 어려운 과제로 남아 있습니다.



### Fine-Tuning In-House Large Language Models to Infer Differential Diagnosis from Radiology Reports (https://arxiv.org/abs/2410.09234)
Comments:
          10 pages, 2 figures, 4 tables

- **What's New**: 이번 연구는 방사선 보고서에서 차별적 진단(differential diagnoses)을 효과적으로 식별하기 위해 맞춤형 인하우스(in-house) 대형 언어 모델(LLM)을 개발하는 파이프라인을 제안합니다. 이를 통해 비공식적인 LLM이 GPT-4의 성능에 근접하도록 조정되었습니다.

- **Technical Details**: 연구팀은 31,056개의 라벨이 붙은 보고서를 생성하기 위해 GPT-4를 활용하고, 이를 기반으로 오픈 소스 LLM을 세밀히 조정했습니다. 1,067개의 보고서에 대해 평가한 결과, 제안된 모델은 평균 F1 점수 92.1%를 기록하여 GPT-4(90.8%)와 유사한 성능을 보였습니다.

- **Performance Highlights**: 제안된 모델은 인하우스 LLM의 효율성을 보여주며, 상용 모델에 대한 비용 의존도를 낮추고, 개인 건강 정보(PHI)의 보안을 강화하여 의료 환경에서의 신뢰성을 개선하는 방법론을 제시합니다.



### Improving semantic understanding in speech language models via brain-tuning (https://arxiv.org/abs/2410.09230)
Comments:
          Under Review at ICLR 2025

- **What's New**: 이 연구는 뇌 신호를 활용하여 음성 언어 모델의 의미 이해 능력을 향상시키는 새로운 접근 방식인 'brain-tuning'을 제안합니다. 자연어를 듣는 동안의 fMRI 기록을 통해 음성 모델들을 세밀하게 조정하여, 이들이 세미틱 언어 영역에서의 뇌 반응과 향상된 정렬을 이루도록 합니다.

- **Technical Details**: 연구에서는 Wav2vec2.0, HuBERT, Whisper와 같은 세 가지 인기 있는 사전 학습된 음성 언어 모델 패밀리를 기반으로 합니다. Brain-tuning 과정에서 8명의 참가자가 27개의 짧은 이야기를 듣는 동안 수집된 fMRI 기록을 사용하며, 이 데이터를 모델의 훈련에 적용하여 모델의 의미 이해 역량을 테스트합니다.

- **Performance Highlights**: Brain-tuning을 통해 음성 모델들은 1) 새로운 fMRI 기록과의 정렬을 유의미하게 개선하였고, 2) 저수준 음성 특징에 대한 의존도를 줄였으며, 3) 의미 이해가 필요한 5개의 언어 과제에서 성능이 눈에 띄게 향상되었습니다. 이는 언어 모델이 뇌와의 정렬을 개선하면 후속 작업에서도 유리한 효과가 있음을 나타냅니다.



### The Same But Different: Structural Similarities and Differences in Multilingual Language Modeling (https://arxiv.org/abs/2410.09223)
- **What's New**: 이 논문에서는 대형 언어 모델(LLMs)의 내부 구조가 학습된 언어의 언어학적 구조와 어떤 관련이 있는지를 연구합니다. 특히, 문법적 과정이 유사한 두 언어가 LLMs에서 동일한 내부 회로를 사용하는지, 또는 서로 다른 과정이 있을 경우 다른 회로를 사용하는지를 분석합니다.

- **Technical Details**: 영어와 중국어의 다국어 및 단일 언어 모델을 사용하여 두 가지 작업의 내부 회로를 분석합니다. 우리가 발견한 바에 따르면, 모델들은 동일한 문법적 과정을 처리하기 위해 특정 회로를 사용하며, 이는 독립적으로 학습된 단일 언어 모델에서도 마찬가지입니다. 다국어 모델은 특정 언어적 과정을 처리하기 위해 언어 특화된 구성요소를 사용합니다.

- **Performance Highlights**: 이 연구 결과는 LLMs가 공통 구조를 활용하면서도 동시에 언어적 차이를 보존하는 방식에 대한 새로운 통찰력을 제공합니다. 또한, 서로 다른 언어에서의 문법적 구조의 처리를 향상시킬 수 있는 기반을 마련합니다.



### M3Hop-CoT: Misogynous Meme Identification with Multimodal Multi-hop Chain-of-Though (https://arxiv.org/abs/2410.09220)
Comments:
          34 Pages. Accepted in The 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024). Main Conference

- **What's New**: 최근 논문에서는 미소지니(misogynous) 메임을 자동으로 식별하기 위한 새로운 프레임워크인 M3Hop-CoT를 소개하였습니다. 이 프레임워크는 CLIP 기반 분류기(CLIP-based classifier)와 다중 모달 체인 오브 사고(Multimodal Chain-of-Thought, CoT) 모듈을 결합하여 맥락적 이해와 감정 인식을 포함한 통합된 접근 방식을 제공합니다.

- **Technical Details**: M3Hop-CoT는 3단계 다중 모달 프롬프트 원칙을 사용하여 감정, 타겟 인식, 맥락 지식을 유도합니다. 이 프레임워크는 그림, 텍스트 및 객체-관계(Entity-Object-Relationship, EOR)를 통해 프롬프트하여 LLM에게 미소지니 메임의 세 가지 중요한 요소인 감정, 타겟, 맥락을 식별할 수 있도록 돕습니다. 또한 계층적 교차 주의 메커니즘을 활용하여 각 추론 단계의 기여도를 평가하여 최종 결정에 영향을 미칩니다.

- **Performance Highlights**: M3Hop-CoT의 성능은 SemEval-2022 Task 5 (MAMI task) 데이터셋에 대한 정성적 및 정량적 분석을 통해 검증되었습니다. 이 모델은 macro-F1 점수에서 강력한 성능을 나타내었으며, 다양한 벤치마크 메임 데이터셋에서도 일반화를 평가하여 접근 방식의 효과를 폭넓게 입증했습니다.



### Long Range Named Entity Recognition for Marathi Documents (https://arxiv.org/abs/2410.09192)
- **What's New**: 마라티어 (Marathi) 자연어 처리(NLP)에서 명명된 개체 인식(NER)의 필요성이 증가하고 있는 가운데, 본 연구는 마라티어 문서를 위한 장거리 NER 기법을 분석하며, BERT(비드리전트) 모델을 활용하여 기존 방법의 한계를 극복하고자 합니다.

- **Technical Details**: 본 논문에서는 마라티어 특유의 형태론적 복잡성과 구문 구조, 문화적 요소를 고려하여, 장거리 NER이 다양한 문서 유형 및 장르에서 효과적으로 작동할 수 있도록 Transformer 기반의 심층 학습 모델을 개발합니다. 데이터셋으로는 MahaNER을 사용하였으며, IOB 형식으로 명명된 개체를 정확하게 인식하기 위한 방법론을 제시합니다.

- **Performance Highlights**: 기존 영어의 NER 기법과 비교하여, 마라티어에서의 NER 정확도를 개선하는 다양한 네트워크 모델들이 제안되고 있으며, 특히 MahaRoBERTa와 MahaBERT가 각각 IOB 및 비-IOB 형식에서 우수한 성능을 보여줍니다. 이 연구는 마라티어 NER 기술 향상에 있어 중요한 진전을 이루었으며, NLP의 여러 분야에서의 응용 가능성을 제시합니다.



### L3Cube-MahaSum: A Comprehensive Dataset and BART Models for Abstractive Text Summarization in Marath (https://arxiv.org/abs/2410.09184)
- **What's New**: MahaSUM 데이터셋을 소개하며, 마라티어의 추상적 요약 작업을 지원하기 위한 대규모 뉴스 기사 컬렉션을 제공합니다.

- **Technical Details**: MahaSUM 데이터셋은 25,000개의 샘플로 구성되며, 다양한 온라인 뉴스 출처에서 스크랩하여 수집한 기사가 포함되어 있습니다. 또한, IndicBART 모델을 훈련시켰으며, 이는 BART 모델의 인도 언어 전용 변형입니다. 데이터셋을 사용하여 모델이 마라티어 텍스트의 복잡성을 처리하고 유창하고 일관된 요약을 생성할 수 있음을 보여줍니다.

- **Performance Highlights**: IndicBART 모델은 MahaSUM 데이터셋을 기준으로 마라티어의 추상적 요약에서 뛰어난 성능을 보여주었으며, 이 연구는 NLP의 발전을 위한 기초를 구축하고 마라티어와 기타 저자원 인도 언어의 대표성 및 활용성을 향상시키는 데 기여합니다.



### Context-Aware SQL Error Correction Using Few-Shot Learning -- A Novel Approach Based on NLQ, Error, and SQL Similarity (https://arxiv.org/abs/2410.09174)
Comments:
          Accepted for the 1st Workshop on GenAI and RAG Systems for Enterprise @ CIKM 2024

- **What's New**: 최근 자동화된 SQL 생성에 대한 수요가 크게 증가했습니다. 본 논문에서는 자연어 질문(NLQ)에 적합한 몇 가지 에러 수정 사례를 선택하여 SQL 생성의 정확성을 높이는 새로운 few-shot learning 기반 접근 방식을 제안합니다.

- **Technical Details**: 제안된 모델은 embedding 기반 유사도 측정을 활용하여 몇 가지 에러 수정 사례를 데이터베이스에서 선택합니다. 삭제된 SQL 쿼리와 그 결과와 관련된 오류, 수정된 SQL 쿼리, 잘못된 쿼리를 올바른 쿼리로 변환하기 위한 단계가 포함된 예제가 활용됩니다.

- **Performance Highlights**: 제안된 기술은 기본 접근 방식인 에러 수정 없이 SQL 생성에 비해 39.2%의 에러 수정 개선과 단순 에러 수정 방법 대비 10%의 개선을 보였습니다. 이 연구는 SQL 쿼리 생성을 위한 신뢰성 높은 에러 수정 프레임워크를 제공함으로써 DB 상호작용 도구의 발전 가능성을 열었습니다.



### Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications (https://arxiv.org/abs/2410.09168)
Comments:
          22 pages, 7 figures

- **What's New**: 이 연구는 실제 및 합성 데이터를 통합하여 대규모 언어 모델(LLMs)을 미세 조정하는 하이브리드 접근 방식을 탐구합니다. 이 방법은 모델의 성능을 향상시키고, 특히 정확하고 맥락에 맞는 응답을 생성하는 데 중점을 둡니다.

- **Technical Details**: 하이브리드 모델은 실제 상호작용 데이터와 고품질 합성 세션을 결합하여 훈련되었습니다. 실험에서는 세 개의 모델—기본 모델, 실제 데이터로 미세 조정된 모델, 하이브리드 미세 조정 모델—을 평가했습니다. 하이브리드 모델은 특정 수직 응용 프로그램에서 일관되게 다른 모델들보다 뛰어난 성능을 나타냈습니다. 하이브리드 데이터 전략은 실제 데이터를 보완하여 모델이 다양한 시나리오에 적응하는 능력을 향상시킵니다.

- **Performance Highlights**: 하이브리드 모델은 모든 메트릭에서 최고 점수를 달성하며 다른 모델들을 지속적으로 능가했습니다. 이러한 결과는 실제 데이터와 합성 데이터의 결합이 LLM의 내구성과 맥락적 민감도를 크게 향상시킬 수 있음을 시사합니다.



### ACER: Automatic Language Model Context Extension via Retrieva (https://arxiv.org/abs/2410.09141)
- **What's New**: 본 논문에서는 자동화된 데이터 합성 파이프라인(Automatic Data Synthesis Pipeline)을 통해 긴 문맥(long-context) 처리 능력을 향상시키는 새로운 접근 법을 제안합니다. 기존의 모델들이 긴 문맥 처리에서 한계를 보이는 반면, 이와는 달리 짧은 문맥(short-context) 모델을 활용하여 사용자의 질문에 대한 효과적인 긴 문맥 처리를 가능하게 할 수 있는 방안을 모색하고 있습니다.

- **Technical Details**: 제안된 접근법인 ACER(Automates Context Extension via Retrieval)는 두 단계로 구성됩니다: 1) 자동 데이터 합성, 2) 자기 훈련(self-training). 첫 번째 단계에서는 사전 훈련된 짧은 문맥 LM을 이용해 정보 검색(retrieval) 후 불완전한 데이터를 생성하고, 두 번째 단계에서는 이 데이터를 기반으로 긴 문맥 처리 능력을 개선하기 위해 LM을 미세 조정합니다.

- **Performance Highlights**: 실험 결과, ACER로 훈련된 모델은 감독 없이도 기존의 일반적인 긴 문맥 모델들을 초과하는 성능을 보였으며, 실제 테스트 데이터셋에서도 효과적인 긴 문맥 검색 생성(long-context retrieval augmented generation) 작업에서 높은 성과를 거두었습니다.



### Recent advancements in LLM Red-Teaming: Techniques, Defenses, and Ethical Considerations (https://arxiv.org/abs/2410.09097)
Comments:
          16 pages, 2 figures

- **What's New**: 이번 논문은 Large Language Models (LLMs)의 보안 문제를 다루고 있으며, 최근 공격 전략과 방어 메커니즘의 발전을 포괄적으로 분석하고 있습니다. 특히, LLM의 적대적 공격에 대한 심층 연구와 함께 이의 효과적인 방어 방법을 제시하고 있습니다.

- **Technical Details**: 이 논문에서는 gradient-based optimization, reinforcement learning, prompt engineering 등의 다양한 공격 방법과 이를 통해 실제 LLM의 안전성을 평가하고 개선하는 방법론에 대해 논의합니다. Lee et al. (2024)의 GFlowNet을 이용한 Fine-tuning과 Hong et al. (2024)의 호기심 기반 탐험 등의 자동화된 red-teaming 기법을 소개하고 있습니다. 또한, Zhao et al. (2024a)의 DiveR-CT와 Jiang et al. (2024)의 DART와 같은 여러 새로운 접근법들이 LLM의 안전성을 평가하기 위한 주요 기술입니다.

- **Performance Highlights**: 최근 연구들은 다양한 공격 전략을 통해 LLM의 보안 취약점을 도출해내는 데 성공했습니다. 예를 들어, Xiao et al. (2024)의 Tastle Framework는 LLM의 약점을 폭로하고, Hardy et al. (2024)의 ASTPrompter는 현실 세계와의 적합성을 높여 공격 프로토타입을 생성합니다. 또한, Mazeika et al. (2024)의 HarmBench가 다양한 공격 및 방어 방법의 체계적인 비교를 가능하게 하는 평가 프레임워크를 제공하고 있습니다.



### Diagnosing Robotics Systems Issues with Large Language Models (https://arxiv.org/abs/2410.09084)
- **What's New**: 이 논문에서는 복잡한 로보틱스 시스템의 문제를 진단하기 위해 SYSDIAGBENCH라는 새로운 벤치마크를 개발했습니다. 이 벤치마크는 2500개 이상의 실제 문제를 포함하고 있으며, 대형 언어 모델(LLMs)을 활용해 문제의 근본 원인(root cause)을 분석하는 방식을 탐구합니다.

- **Technical Details**: SYSDIAGBENCH는 지원 티켓이 포함된 데이터 세트를 기반으로 하여 생성되었습니다. 각 티켓은 문제 설명, 로그 파일, 전문가 논의에서 추출된 근본 원인 등으로 구성됩니다. QLoRA를 활용한 파인튜닝이 7B-매개변수 모델이 GPT-4를 초월하는데 충분하다는 결과를 보여주며, LLM-as-a-judge 방식을 통해 전문가 분석과 비슷한 평가 결과를 얻었습니다.

- **Performance Highlights**: 연구 결과, 최상의 모델이 전문가의 분석과 유사한 승인 등급을 달성하여, SIYSDIAGBENCH에서 테스트한 LLM 기반 진단 도구들이 비용 효율성이 매우 높으면서도 진단 정확도에서 우수함을 증명했습니다.



### BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models (https://arxiv.org/abs/2410.09079)
Comments:
          Accepted to EMNLP 2024 (Findings)

- **What's New**: 이번 논문에서는 Budget-guided Iterative 검색 전략(BIPEFT)을 소개하여 자동 PEFT(Paramater Efficient Fine-Tuning)의 검색 효율성을 크게 향상시키는 방법을 제안합니다.

- **Technical Details**: BIPEFT는 새로운 반복 검색 전략을 사용하여 이진 모듈(binary module)과 rank 차원(rank dimension) 검색 공간을 분리하고, 매개변수 예산(parameter budget)에 기반한 조기 선택 전략을 디자인하여 학습 프로세스를 가속화합니다. 이 방법은 중요하지 않은 모듈을 단계적으로 제거하고 rank 차원을 고정하여 효율성과 효과성을 높입니다.

- **Performance Highlights**: BIPEFT는 공개 벤치마크에서 수행된 실험에서 우수한 성능을 보이며, 낮은 매개변수 예산을 가진 하위 작업에 대한 효율적이고 효과적인 PEFT를 달성하는 데 성공적임을 입증하였습니다.



### Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs (https://arxiv.org/abs/2410.09078)
Comments:
          Accepted in the VECOMP 2024 workshop

- **What's New**: EU AI Act (EUAIA)의 요구 사항을 충족하고 LLM의 적대적 견고함(adversarial robustness)을 보장하기 위한 새로운 기능 아키텍처를 제안합니다. 이 연구는 컴포넌트의 출처에 대해 명확하게 참조하는 요소들을 도입하여 두 속성을 연결하는 데 중점을 둡니다.

- **Technical Details**: 제안된 아키텍처는 탐지(detection), 추론(reasoning), 보고(reporting) 레이어로 구성되어 있으며, 사용자와 상호작용하는 레이어도 포함되어 있습니다. 이 구조는 LLM이 동적으로 보호되고 감사 가능성을 유지하기 위한 포괄적인 참조 프레임워크를 제공합니다.

- **Performance Highlights**: EUAIA의 요구 사항과 LLM의 적대적 견고함이 상호 보완적이라는 점을 강조하며, 이를 충족하는 새로운 접근 방식을 통해 신뢰성을 높이고 LLM의 안전성과 보안을 향상시키는 방향을 보여줍니다.



### A Large Language Model-based Framework for Semi-Structured Tender Document Retrieval-Augmented Generation (https://arxiv.org/abs/2410.09077)
- **What's New**: 이번 연구에서는 조달(field of procurement) 분야의 문서 생성을 위한 LLM 기반의 프레임워크를 도입하였습니다. 기존 LLM은 조달에 대한 전문 지식이 부족했으나, 본 연구는 retrieval-augmented techniques를 활용하여 정확하고 관련성 높은 조달 문서를 생성하는 것을 목표로 합니다.

- **Technical Details**: 제안된 프레임워크는 세 단계의 문서 생성 프로세스를 포함합니다. 첫째, 새로운 조달 요구사항을 제공받으면, retrieval-augmentation 모듈을 통해 가장 유사한 조달 문서를 찾습니다. 둘째, 메모리 네트워크를 사용하여 검색된 문서와 정책, 신규 정보를 확인한 후 수정합니다. 셋째, 조달 프로젝트 지식 기반을 활용하여 문서 내용을 재조정합니다. 이 프레임워크는 템플릿 검색 모듈, 검증 모듈, 수정 모듈로 구성됩니다.

- **Performance Highlights**: 제안된 방법은 조달 문서 생성의 효율성과 정확성을 크게 향상시킬 것으로 기대됩니다. 기존의 수동 작성 방식에 비해 오류를 줄이고 일관성을 높이며, 비전문적 조달 인력을 위한 부담을 경감하는 데 기여할 수 있습니다.



### Llettuce: An Open Source Natural Language Processing Tool for the Translation of Medical Terms into Uniform Clinical Encoding (https://arxiv.org/abs/2410.09076)
- **What's New**: 이 논문은 의료 용어를 OMOP 표준 개념으로 변환하는 데 있어 복잡성을 해결하기 위해 설계된 오픈 소스 도구인 Llettuce를 소개합니다. 기존의 Athena 데이터베이스 검색 및 Usagi와 달리, Llettuce는 고급 자연어 처리(Natural Language Processing, NLP) 기술, 대형 언어 모델(large language models) 및 퍼지 매칭(fuzzy matching)을 활용하여 자동화와 향상을 지원합니다.

- **Technical Details**: Llettuce는 전자 건강 기록(Electronic Health Records, EHRs), 자가 보고되는 환자 설문지 및 기타 구조화된 데이터 세트에서 의료 용어를 추출합니다. Python을 사용하여 백엔드와 사용자 인터페이스를 작성하였으며, FastAPI를 사용하여 API 엔드포인트를 제공합니다. Llettuce는 개념 검색을 위한 벡터 저장소와 OMOP CDM 데이터베이스에 대한 쿼리 기능을 포함하고 있습니다. 문장 임베딩(sentence embeddings)을 사용하여 개념의 의미 검색을 수행합니다.

- **Performance Highlights**: Llettuce의 성능은 OpenAI 모델과 비교 가능하며, 자가 보고된 비공식 약물 이름을 OMOP 개념으로 변환하는 사례 연구에서 우수한 결과를 보였습니다. 이 도구는 데이터 보호 요구 사항을 지원하기 위해 로컬에서 실행되도록 설계되었습니다.



### Investigating the Impact of Text Summarization on Topic Modeling (https://arxiv.org/abs/2410.09063)
Comments:
          7 pages, 2 figures

- **What's New**: 본 논문에서는 pre-trained large language model (LLM)을 활용하여 문서 요약을 생성한 후, 이를 topic model에 입력하여 topic modeling 성능을 향상시키는 새로운 접근 법을 제안합니다. 이 방법은 특히 더 긴 문서에서 효과적이며, 필요한 정보를 잘 캡처하면서 불필요한 정보와 잡음을 줄이는 데 도움을 줍니다.

- **Technical Details**: 이 방법론은 두 가지 주요 구성 요소로 나뉘어 있습니다: 요약(summarization) 및 토픽 모델링(topic modeling). 요약 단계에서는 GPT-3.5-Turbo-Instruct 모델을 이용하여 짧고(pointed) 길이의 요약(20-30 단어)과 좀 더 긴(detailed) 요약(60-80 단어)을 생성하고 성능을 비교합니다. BERTopic이란 모델을 사용하여 문서 임베딩(document embedding)을 생성하고, 클러스터링(clustering) 기법인 HDBSCAN을 적용하여 주제를 추출하는 방식을 취합니다.

- **Performance Highlights**: 제안된 방법은 이전 모델들과 비교하여 topic diversity(주제 다양성)와 coherence(일관성) 측면에서 개선된 성능을 보였습니다. 특히 최적의 요약 길이를 통해 토픽 모델링 성능이 향상되는 경향을 발견했습니다. 실험 결과, BBC News와 20 NewsGroups 데이터셋에서 높은 coherence 및 다양성을 기록하며, BERTopic 모델에 적용된 일반 텍스트에 비해 더 나은 결과를 나타냈습니다.



### TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models (https://arxiv.org/abs/2410.10818)
Comments:
          Project Page: this https URL

- **What's New**: TemporalBench는 비디오의 미세한 시간적 이해(fine-grained temporal understanding)를 평가하는 새로운 벤치마크로, 10,000 개의 비디오 질문-답변 쌍으로 구성되어 있으며, 인간의 고품질 주석에서 파생되었습니다.

- **Technical Details**: TemporalBench에서는 비디오 클립의 시공간적 활동을 잘 반영하기 위해 긴 시간 의존성(long-range dependencies), 세분화된 시각적 관찰(fine-grained visual observations) 및 사건의 진행(event progression)과 관련된 주석에 중점을 두었습니다.

- **Performance Highlights**: 최신 모델인 GPT-4o는 TemporalBench에서 단지 38.5%의 질문 응답 정확도를 보여주었고, 이는 인간과 AI 간의 시간적 이해에서 약 30%의 큰 간극이 있음을 나타냅니다. 또한 다중 선택 QA에서 발생할 수 있는 편향을 수정하기 위해 Multiple Binary Accuracy(MBA)를 제안했습니다.



### AFlow: Automating Agentic Workflow Generation (https://arxiv.org/abs/2410.10762)
- **What's New**: 최근 대형 언어 모델(LLMs)의 워크플로우 최적화 자동화 필요성이 대두되었습니다. 기존의 방법들은 수동 설정에 의존하였으나, 본 연구에서는 워크플로우 최적화를 코드로 표현된 워크플로우에 대한 검색 문제로 재구성했습니다.

- **Technical Details**: AFlow라는 자동화 프레임워크를 소개하며, Monte Carlo Tree Search 기법을 활용하여 코드 수정을 통한 반복적 워크플로우 개선을 진행합니다. 이 과정에서는 트리 구조의 경험과 실행 피드백을 사용합니다.

- **Performance Highlights**: 여섯 개의 벤치마크 데이터셋에서의 실험 평가 결과, AFlow는 최신 기준선에 비해 5.7%의 평균 개선을 보여주었으며, AFlow를 사용하면 더 작은 모델도 특정 작업에서 GPT-4o를 4.55%의 비용으로 능가할 수 있습니다.



### Denial-of-Service Poisoning Attacks against Large Language Models (https://arxiv.org/abs/2410.10760)
- **What's New**: 이 논문은 LLMs(대형 언어 모델)에 대한 새로운 종류의 서비스 거부 공격(DoS 공격)을 제안합니다. 기존의 DoS 공격이 텍스트 기반의 입력을 통해 수행되는 반면, 이 연구에서는 말하는 텍스트(speech-to-text) 인터페이스에서도 효과적인 공격 방법인 P-DoS(포이징 기반 서비스 거부 공격)를 소개하고 있습니다.

- **Technical Details**: P-DoS 공격은 악성 샘플을 주입하여 LLM의 출력 길이 제한을 벗어나는 방식으로 작동합니다. 연구진은 LLM의 파인튜닝(finetuning) 과정에 포이징된 데이터셋을 주입하여 출력의 길이를 최대화하는 방법을 규명했습니다. 예를 들어, 단 한 개의 포이징된 샘플이 GPT-4o의 출력을 최대 16K 토큰까지 반복 생성하도록 강제할 수 있습니다.

- **Performance Highlights**: P-DoS 공격을 통해 LLM은 기본적으로 제한된 출력 길이를 초과하여 반복적인 출력을 생성할 수 있게 됩니다. 이 연구는 현재의 LLM 시스템의 취약성을 강조하고 있으며, P-DoS 공격으로부터 LLM을 방어하기 위한 통찰력을 제공합니다. 논문에서 제안된 방법은 실험적으로 검증되었으며, 공격 비용이 $1 이하인 것으로 나타났습니다.



### Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning (https://arxiv.org/abs/2410.10735)
- **What's New**: 이 연구에서는 Chain of Self-Correction (CoSC)라는 새로운 메커니즘을 소개하며, 이를 통해 대형 언어 모델(LLMs)이 스스로 결과를 검증하고 수정할 수 있는 능력을 내장할 수 있게 됩니다. 이 두 단계의 수정 과정을 통해 수학적 추론의 정확성을 현저히 향상시킬 수 있습니다.

- **Technical Details**: CoSC 메커니즘은 LLM이 주어진 문제를 해결하기 위해 프로그램을 생성하고, 프로그램 기반 도구를 사용하여 출력을 얻고, 해당 출력을 검증하는 단계로 구성됩니다. 이를 통해 LLM은 반복적인 자기 수정 과정을 수행하여 수학적 추론을 강화합니다. 두 단계의 파인튜닝(phase finetuning) 접근 방식이 사용되며, 첫 번째 단계에서는 GPT-4에서 생성된 소량의 데이터로 초기 CoSC 능력을 구축하고, 두 번째 단계에서는 훈련된 모델을 사용하여 자가 생성된 대량의 데이터를 통해 CoSC 능력을 향상시킵니다.

- **Performance Highlights**: CoSC 메커니즘은 공개된 수학적 데이터셋에서 기존의 오픈 소스 LLM들과 비교했을 때 성능을 크게 향상시키며, CoSC-Code-34B 모델은 MATH 데이터셋에서 53.5%의 성능을 기록하여 ChatGPT, GPT-4 및 다중 모달 LLMs인 GPT-4V 및 Gemini-1.0 Pro를 초월하는 성과를 보였습니다.



### Modeling News Interactions and Influence for Financial Market Prediction (https://arxiv.org/abs/2410.10614)
Comments:
          Accepted by EMNLP 2024

- **What's New**: 이번 논문에서는 FININ (Financial Interconnected News Influence Network)이라는 금융 시장 예측 모델을 소개합니다. 이 모델은 뉴스 사건과 시장 움직임 사이의 연결뿐만 아니라 뉴스 항목 간의 상호 작용을 포착하는 데 중점을 두고 있습니다.

- **Technical Details**: FININ 모델은 데이터 융합 인코더와 시장 인식 영향 정량화기로 구성되어 있습니다. 데이터 융합 인코더는 다양한 입력을 다르게 인코딩하여 멀티모달(multi-modal) 데이터를 처리합니다. 시장 인식 영향 정량화기는 뉴스 항목과 가격 간의 관계를 분석합니다.

- **Performance Highlights**: FININ은 S&P 500과 NASDAQ 100 지수에 대한 실험에서 기존의 최신 방법들보다 우수함을 입증했습니다. S&P 500과 NASDAQ 100에서 각각 0.429 및 0.341의 개선된 Sharpe 비율을 달성하며, 뉴스의 시장 가격 반응 지연, 뉴스의 장기 메모리 효과, 재무 뉴스 감정 분석의 한계에 대한 통찰을 제공합니다.



### VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents (https://arxiv.org/abs/2410.10594)
- **What's New**: 이 논문에서는 기존의 텍스트 기반 Retrieval-augmented generation (RAG) 시스템의 한계를 극복하기 위해 비전-언어 모델(Vision-Language Model, VLM)을 이용한 새로운 RAG 파이프라인인 VisRAG를 제안합니다.

- **Technical Details**: VisRAG는 문서를 직접 이미지로 임베딩하여 VLM을 통해 정보를 추출하는 방식으로 동작합니다. VisRAG-Ret와 VisRAG-Gen이라는 두 구성 요소로 이루어져 있으며, 이들은 각각 이미지 기반 정보 검색과 생성 기능을 수행합니다.

- **Performance Highlights**: VisRAG는 전통적인 텍스트 기반 RAG에 비해 검색 및 생성 단계 모두에서 성능이 25-39% 향상되었으며, 특히 다중 문서 처리를 효율적으로 수행할 수 있는 가능성이 확인되었습니다.



### SLaNC: Static LayerNorm Calibration (https://arxiv.org/abs/2410.10553)
Comments:
          9 pages, 3 figures, NeurIPS 2024 MLNCP Workshop

- **What's New**: 최근 대규모 언어 모델(LLMs)과 관련하여, 이 논문은 Transformer 모델에서의 LayerNorm 계산 시 발생하는 수치적 문제를 해결하기 위한 새로운 기법을 제안하고 있습니다. 이 기법은 FP16 및 FP8 포맷에서의 오버플로우(overflow) 및 언더플로우(underflow) 문제를 효과적으로 제거할 수 있도록 설계되었습니다.

- **Technical Details**: 제안된 기법인 SLaNC(Static LayerNorm Calibration)는 LayerNorm의 입력을 스케일링(scaling)하는 간단한 방법을 제공합니다. 이 방식은 이전의 선형(Linear) 계층의 정적 가중치(static weights)에 기반하여 스케일링 요소를 오프라인에서 계산합니다. 따라서 추론(inference) 동안 추가적인 지연(latency)이나 계산 오버헤드가 발생하지 않습니다.

- **Performance Highlights**: SLaNC 기법을 적용하면 다양한 하드웨어 아키텍처에서 부드럽고 정확하며 자원 효율적인 추론이 가능해집니다. 본 논문은 이론적 근거와 함께 이를 뒷받침하는 수치적 시뮬레이션 결과를 제공합니다.



### On Calibration of LLM-based Guard Models for Reliable Content Moderation (https://arxiv.org/abs/2410.10414)
Comments:
          19 pages, 9 figures

- **What's New**: 이 논문은 LLM(대형 언어 모델) 기반 가드 모델의 신뢰성과 신뢰도(Confidence Calibration)에 대한 종합적인 조사 결과를 제시합니다. 기존의 연구들은 LLM을 안전하게 만들기 위한 다양한 방법에 초점을 맞췄지만, 가드 모델의 예측의 신뢰성을 측정하는 데에는 충분한 주의를 기울이지 않았습니다.

- **Technical Details**: 연구에서는 9개의 기존 LLM 기반 가드 모델의 신뢰성(신뢰도) 교정(calibration)을 평가하기 위해 12개의 벤치마크 데이터셋을 사용해 ECE(기대 교정 오차)를 측정했습니다. 결과적으로, 현존하는 가드 모델들은 과도한 자신감을 갖고 예측을 하며, 적대적인 환경에서는 잘 보정되지 않는다는 것을 발견했습니다. 또한, 다양한 반응 모델(response models)에 대해 일관되지 않은 ECE를 보였습니다. 이 연구에서는 템퍼러처 스케일링(temperature scaling)과 맥락적 보정(contextual calibration)을 통한 교정의 효과성을 검토합니다.

- **Performance Highlights**: 대부분의 LLM 기반 가드 모델은 높은 F1 점수를 기록하지만, 신뢰성 기준에서의 문제는 명확합니다. 이 연구는 향후 신뢰성이 높은 콘텐츠 조절을 위한 가드 모델 개발에 기여할 수 있는 중요한 통찰을 제공합니다. 또한, 새로운 가드 모델의 출시 시 신뢰성 평가를 포함시켜야 한다는 주장을 하였습니다.



### Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search (https://arxiv.org/abs/2410.10392)
- **What's New**: 이 논문은 기존의 지침 데이터를 개선하기 위한 새로운 프레임워크인 IDEA-MCTS(Instruction Data Enhancement using Monte Carlo Tree Search)를 소개합니다. 이 프레임워크는 효율적으로 지침을 합성하고, 지침 조정(instruction fine-tuning)에서 도움을 줄 수 있습니다.

- **Technical Details**: IDEA-MCTS 프레임워크는 트리 검색(tree search)과 평가 모델(evaluation models)을 활용하여 각 지침을 고품질 형식으로 발전시키는 방향으로 지침을 안내합니다. 이를 통해 데이터 합성 과정에서 발생할 수 있는 불확실성을 줄이고, 양질의 지침을 생성합니다.

- **Performance Highlights**: 실험 결과, IDEA-MCTS는 초기 지침 데이터의 평가 점수를 평균 2.19에서 3.81로 향상시켰습니다. 또한, 오픈 도메인 벤치마크(open-domain benchmarks)에서는 리소스가 적은 환경에서 LLM의 실제 지침 따라하기 능력이 평균 5% 향상되었습니다.



### FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG (https://arxiv.org/abs/2410.10293)
Comments:
          18 pages, 6 figures, 13 tables

- **What's New**: 본 연구에서는 Retrieval-Augmented Generation (RAG) 구조의 한계를 극복하기 위한 새로운 접근 방식을 제안합니다. 기존의 flat retrieval 방식의 단점을 보완하기 위해, coarse-to-fine granularity를 적용한 FunnelRAG라는 점진적 검색 패러다임을 도입했습니다.

- **Technical Details**: FunnelRAG는 검색 단계를 점진적으로 진행하여 후보 군집의 규모를 줄이고 검색 단위의 세분성을 높이며 검색기의 용량 수준을 증가시킵니다. 이를 통해 Mixed-capacity retrievers를 활용하여 효율성과 정확성을 모두 개선합니다. 근본적으로, Coarse-to-Fine Granularity를 통해 대량의 문서에서 먼저 coarse-grained units를 만들고, 이를 다시 세분화하여 최종적으로 passage-level units로 분리합니다.

- **Performance Highlights**: FunnelRAG는 기존 retrieval 방식에 비해 약 40%의 시간 오버헤드를 줄이며, 경쟁력 있는 retrieval 성능을 유지하였습니다. 이는 Natural Question (NQ) 및 Trivia QA (TQA)와 같은 open-domain 질문 응답 시스템에서의 성능 개선을 입증합니다.



### Is Parameter Collision Hindering Continual Learning in LLMs? (https://arxiv.org/abs/2410.10179)
- **What's New**: 이 논문은 LLM(대형 언어 모델)의 지속적 학습(Continual Learning) 문제를 해결하기 위해 비충돌 파라미터(non-collision parameters)의 중요성을 강조합니다. 기존의 방법들이 하려는 경우(예: O-LoRA)는 각 작업의 파라미터들이 서로 독립적이어야 한다고 주장하지만, 본 연구는 비충돌 파라미터를 통해 더 나은 작업 직교성(task orthogonality)을 달성할 수 있음을 보여줍니다.

- **Technical Details**: 논문에서 제안한 N-LoRA(Non-collision Low-Rank Adaptation)는 파라미터 충돌률(collision rate)을 낮추기 위해 ℓ1 제약 조건을 도입하여 작업별 LoRA 파라미터의 희소성(sparsity)을 높입니다. 이를 통해 비충돌 파라미터 공간을 만들고, 작업 벡터들이 서로 간섭하지 않도록 하여 모델의 성능을 향상시킵니다.

- **Performance Highlights**: N-LoRA는 여러 지속적 학습 벤치마크에서 기존 SOTA 방법보다 평균 2.9% 더 높은 정확도와 4.1배 더 높은 작업 직교성, 58.1배 더 낮은 파라미터 충돌을 달성했습니다.



### HSR-Enhanced Sparse Attention Acceleration (https://arxiv.org/abs/2410.10165)
- **What's New**: 본 논문에서는 대형 언어 모델(LLM)의 긴 컨텍스트 작업에서 주의 메커니즘상의 계산 복잡성을 줄이기 위한 새로운 접근 방식이 소개됩니다. 특히, 주의 메커니즘 내에서의 내재된 희소성(sparsity)을 활용하여 주의 생성을 가속화합니다.

- **Technical Details**: 본 연구에서는 Half-Space Reporting (HSR) 데이터 구조를 사용하여 주의 행렬에서 비제로(non-zero) 또는 "대량 활성화(massively activated)" 항목을 신속하게 식별합니다. 이 방법을 통해 긴 입력 컨텍스트에서의 주의 생성을 위해 $O(mn^{4/5})$의 실행 시간을 달성하며, 이는 기존의 $O(mn)$ 방식보다 빠릅니다. 또한, 전체 주의 계산의 실행 시간도 $O(mn)$에서 $O(mn^{1 - 1 / lfloor d/2floor} + mn^{4/5})$로 감소시킵니다.

- **Performance Highlights**: ReLU 주의(almost zero error)를 위한 오류를 도입하지 않으며, Softmax 주의의 경우에도 상당히 미미한 오류를 보이는 결과를 empirically validation로 입증하였습니다. 이 연구는 LLM에서 효율적인 긴 컨텍스트 처리 가능성을 높이며 다양한 분야에서의 적용성을 넓힐 수 있는 중요한 전환점을 나타냅니다.



### $\alpha$-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs (https://arxiv.org/abs/2410.10148)
- **What's New**: 본 연구는 대규모 언어 모델(LLM)을 인류의 가치와 의도에 맞게 조정하기 위한 새로운 알고리즘인 \u03b1-DPO를 제안합니다. 기존의 강화 학습 알고리즘인 DPO와 SimPO의 한계를 극복하며, 동적인 보상 마진을 도입하여 보다 효과적인 최적화를 이룹니다.

- **Technical Details**: \u03b1-DPO는 적응형 보상 분포를 사용하여 정책 모델과 기준 모델 간의 균형을 맞추며 개인화된 보상 마진을 달성하는 알고리즘입니다. 이 연구는 KL 발산(KL divergence) 제어를 통해 정렬(alignment)과 다양성(diversity)을 균형 있게 유지하는 이론적 보장을 제공합니다.

- **Performance Highlights**: Empirical evaluations 결과, \u03b1-DPO는 다양한 모델 설정에서 DPO와 SimPO를 지속적으로 초월하며 win rate를 크게 향상시키는 것으로 나타났습니다. 이는 LLM 정렬을 위한 강력한 도구로서의 가능성을 보여줍니다.



### Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning (https://arxiv.org/abs/2410.10144)
Comments:
          15 pages, 2 figures, 5 tables

- **What's New**: 이번 논문에서 제안하는 GENEREL은 유전체와 생물 의학 지식 기반을 연결하는 새로운 프레임워크로, 임상 개념인 질병 및 약물에 대한 생물학적 지식을 언어 모델에 주입하여 효과적으로 연결합니다.

- **Technical Details**: GENEREL은 다중 작업 대조 학습(multi-task contrastive learning)을 통해 SNP와 임상 개념의 임베딩을 조정하며, 병원 데이터, 생물 의학 지식 그래프, GWAS 요약 정보를 활용하여 통합 임베딩 공간을 구축합니다.

- **Performance Highlights**: GENEREL은 생물 의학 개념과 SNP 간의 미세한 관계를 효과적으로 포착하고, 다양한 벤치마크에서 최첨단 성능을 입증하여 유전체 및 생물 의학 데이터의 통합 가능성을 높입니다.



### MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models (https://arxiv.org/abs/2410.10139)
- **What's New**: 본 논문에서는 대규모 지식 집중형 벤치마크 MMIE를 소개합니다. 이는 대형 비전-언어 모델(LVLMs)의 교차 멀티모달 이해 및 생성을 평가하기 위한 새로운 평가 기준을 제공합니다.

- **Technical Details**: MMIE는 20K의 정교하게 구성된 다중 모달 질문으로 이루어져 있으며, 3개 카테고리, 12개 분야 및 102개 세부 분야를 포함합니다. 다양한 형식의 질문(객관식 및 주관식)을 통해 여러 분야에 걸친 역량을 평가할 수 있습니다.

- **Performance Highlights**: 최고의 LVLM 모델조차도 평균적으로 65.47%의 점수를 달성하여 개선 여지가 많음을 나타냅니다. MMIE는 LVLM의 개발에 의미 있는 진전을 촉진할 것으로 기대됩니다.



### How to Construct Random Unitaries (https://arxiv.org/abs/2410.10116)
Comments:
          76 pages

- **What's New**: 이번 논문에서는 pseudorandom unitaries (PRUs)이 존재함을 증명하였습니다. 이는 Haar-random unitary와 계산적으로 구별할 수 없는 효율적인 양자 회로를 의미합니다. 이는 암호학, 복잡도 이론, 그리고 기초 물리학에 중요한 의미를 가집니다.

- **Technical Details**: 논문에서는 (1) 효율적인 적대자에 대해 안전한 표준 PRUs 개념과 (2) 유니타리 $U$와 그 역 $U^\	extdagger$ 모두를 쿼리할 수 있는 적대자에 대해서도 안전한 강화된 PRUs 개념에 대해 결과를 수립합니다. 또한 Haar-random unitary에 쿼리하는 모든 알고리즘은 역지수적 트레이스 거리까지 양자 컴퓨터에서 효율적으로 시뮬레이션될 수 있음을 증명합니다.

- **Performance Highlights**: PRUs의 존재를 증명함으로써 알고리즘 및 복잡도 이론의 발전에 기여하며, 이는 양자 컴퓨팅과 정보 보안 분야에서 새로운 가능성을 열어줍니다.



### Can We Predict Performance of Large Models across Vision-Language Tasks? (https://arxiv.org/abs/2410.10112)
Comments:
          Under Review. Project page: this https URL

- **What's New**: 본 연구에서는 관측된 성능 점수를 기반으로 대형 비전-언어 모델(LVLM)의 미지 성능 점수를 예측하는 새로운 프레임워크를 제안합니다. 이는 모델 및 작업에서 관측된 점수를 활용하여 불필요한 평가를 줄이고 비용을 절감하는 방법을 모색합니다.

- **Technical Details**: 우리는 성능 예측을 매트릭스 완성 문제로 공식화하고, 희소한 성능 매트릭스 $oldsymbol{R}$을 생성합니다. 각각의 항목 $R_{mn}$은 모델 $m$의 데이터셋 $n$에 대한 성능 점수를 나타냅니다. Markov chain Monte Carlo (MCMC)와 확률적 매트릭스 분해(Probabilistic Matrix Factorization, PMF)를 적용하여 미지 점수를 예측합니다. 또한, MCMC를 기반으로 성능 예측의 불확실성을 추정합니다.

- **Performance Highlights**: 실험 결과, 우리는 108개의 LVLM을 36개의 벤치마크에서 가져온 176개의 데이터셋에 대해 체계적으로 평가하였으며, PMF가 미지 점수를 정확하게 예측할 수 있음을 보여주었습니다. 높은 불확실성을 가진 모델-데이터셋 쌍을 선택하여 평가할 경우 예측 오류를 상당히 줄일 수 있음을 확인하였습니다.



### Learning Linear Attention in Polynomial Tim (https://arxiv.org/abs/2410.10101)
- **What's New**: 본 연구는 단일 계층 Transformer 모델을 대상으로 한 강력한 무관심 PAC 학습(strong, agnostic PAC learning)의 다항 시간 학습 가능성을 최초로 보였다는 점에서 혁신적입니다.

- **Technical Details**: 단일 계층의 선형 Transformer(Linear Transformer)에서 linear attention을 사용하여 특정한 RKHS(Reproducing Kernel Hilbert Space) 내에서 선형 예측기로 취급할 수 있다는 개념을 제시합니다. 이를 통해 선형 Transformer를 학습하는 문제를 일반적인 선형 예측기를 확장된 특성 공간에서 학습하는 문제로 변환합니다.

- **Performance Highlights**: 세 가지 과제(랜덤 선형 attention 네트워크, 키-값 연관, 유한 오토마타 실행 학습)에 대한 경험적 검증을 통해 이론적 발견을 입증하였으며, 효율적으로 학습 가능한 유연하고 일반적인 계산 모델로서 Transformer의 능력을 강조합니다.



### Divide, Reweight, and Conquer: A Logit Arithmetic Approach for In-Context Learning (https://arxiv.org/abs/2410.10074)
- **What's New**: 본 논문에서는 Logit Arithmetic Reweighting Approach (LARA)라는 새로운 프레임워크를 제안합니다. 이는 In-Context Learning (ICL) 성능을 향상시키기 위해 여러 시연의 logit 기반 앙상블을 활용합니다. 또한, Binary LARA (B-LARA)를 도입하여 이진 값으로 가중치를 제한함으로써 메모리 사용량을 줄입니다.

- **Technical Details**: LARA는 긴 입력 시연을 병렬화 가능한 짧은 입력으로 나누어 메모리 요구 사항을 대폭 줄이고, 각 그룹의 logit을 비부드러운 최적화(non-gradient optimization) 방식을 통해 재가중화하여 정보를 효과적으로 집계합니다. B-LARA는 가중치 값을 {0,1}로 제한하여 검색 공간을 단순화합니다. Covariance Matrix Adaptive Evolution Strategy (CMA-ES)를 이용해 가중치 벡터 공간을 효율적으로 탐색합니다.

- **Performance Highlights**: LARA와 B-LARA는 BBH와 MMLU 벤치마크에서 모든 기준 방법을 초과하는 성능을 보여주었으며, 특히 예제가 적은 저자원 환경과 대량의 시연이 존재하는 상황에서도 우수한 성능을 기록했습니다. 이 방법들은 GPU 메모리 사용량이 낮으면서도 높은 정확도를 자랑합니다.



### Collu-Bench: A Benchmark for Predicting Language Model Hallucinations in Cod (https://arxiv.org/abs/2410.09997)
- **What's New**: 새로운 연구에서는 LLMs(대형 언어 모델)의 코드 생성에서 발생하는 hallucination(허위 생성)에 대한 분석 및 예측을 위한 새로운 벤치마크인 Collu-Bench를 소개합니다. 이 벤치마크는 코드 생성 및 자동화된 프로그램 수정 작업에서 13,234개의 코드 hallucination 사례를 수집했습니다.

- **Technical Details**: Collu-Bench는 다양한 구조와 크기의 11개 LLMs를 사용하여 5개의 데이터셋에서 구축되었습니다. 상세한 분석을 위해 LLM의 출력에 대한 단계별 로그 확률(per-step log probabilities), 토큰 유형(token types), 생성된 코드에 대한 실행 피드백(execution feedback)을 포함하고 있습니다. 이를 통해 LLMs의 코드 hallucinations 패턴을 이해하고 예측하는 데 도움을 줍니다.

- **Performance Highlights**: 예측 결과, LLMs의 코드 hallucination 예상 정확도는 22.03%에서 33.15% 사이로 나타났습니다. 덜 자신감 있는 LLMs는 hallucination에서 더 낮은 확률을 보이며, 특정 토큰 유형(예: Keyword, Identifier, Type Identifier)일 때 더 자주 hallucination을 발생시킵니다. LSTM 모델이 샘플 예측에서 가장 높은 정확도를 보이는 반면, 랜덤 포레스트는 토큰 예측에서 가장 높은 정확도를 기록했습니다.



### Self-Data Distillation for Recovering Quality in Pruned Large Language Models (https://arxiv.org/abs/2410.09982)
Comments:
          Accepted at the NeurIPS 2024 Machine Learning and Compression Workshop

- **What's New**: 본 논문에서는 구조적 가지치기(structured pruning)와 자가 데이터 분류(self-data distilled fine-tuning)를 결합하여 대형 언어 모델(LLM)의 효율성을 개선하는 새로운 접근 방식을 제안합니다. 기존 모델을 활용하여 의미적 풍부함을 유지하는 분류된 데이터셋을 생성함으로써 기존의 품질을 회복하는 데 기여합니다.

- **Technical Details**: 구조적 가지치기 기술을 사용하여 중요도가 낮은 구성 요소를 제거하고 모델의 복잡성을 줄입니다. 자가 데이터 분류는 원본 모델의 지식을 유지하며, 일반 명령 수행 능력의 손실을 방지합니다. 이 과정에서 기본 모델의 결과와 정렬을 유지하는 새로운 데이터셋이 생성됩니다.

- **Performance Highlights**: Llama3.1-8B Instruct 모델에서 6개의 디코더 블록을 가지치기한 결과, 자가 데이터 분류를 통해 모델의 정확성을 91.2% 유지했으며, 표준 SFT에서는 81.7%에 불과했습니다. 또한, 실제 FLOPs(부동소수점 연산 수)는 16.30% 감소했습니다. 전반적으로 자가 데이터 분류는 SFT에 비해 평균 정확도를 최대 8% 향상시켰습니다.



### ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos (https://arxiv.org/abs/2410.09776)
Comments:
          Accepted in EMNLP 2024, this https URL

- **What's New**: 본 연구는 비디오에서 엔터티 중심의 정보 탐색 질문(ECIS 질문)을 생성하는 새로운 문제 설정을 제안하며, 여기에 맞는 대규모 데이터셋 VideoQuestions를 제시합니다.

- **Technical Details**: 연구에서는 Transformers와 풍부한 맥락 신호(제목, 전사본, 자막, 임베딩) 조합을 통해 ECIS 질문 생성을 위한 모델 구조를 제안합니다. 이 모델은 교차 엔트로피 손실(cross-entropy loss)과 대조 손실(contrastive loss) 함수를 결합하여 훈련되며, 다양한 비디오 자료에서 요구되는 질문 생성을 목표로 합니다.

- **Performance Highlights**: 우리의 최적 방법은 BLEU, ROUGE, CIDEr 및 METEOR 점수에서 각각 71.3, 78.6, 7.31, 81.9의 성과를 기록하여 실용성을 입증하였습니다.



### BiDoRA: Bi-level Optimization-Based Weight-Decomposed Low-Rank Adaptation (https://arxiv.org/abs/2410.09758)
- **What's New**: 이 논문에서는 BiDoRA라는 새로운 방법을 제안하여, 저위험(低風險) 및 유연한 파라미터 효율적 미세 조정(PEFT) 기법을 선보이고 있습니다. BiDoRA는 서로 다른 데이터 세트를 사용하여 방향 및 크기 구성 요소를 최적화하여 과적합(overfitting)의 위험을 줄입니다.

- **Technical Details**: BiDoRA는 두 수준의 최적화(optimization)를 사용하는 PEFT 방법으로, 아래 수준에서는 방향 구성 요소를 훈련 데이터에서 업데이트하고, 위 수준에서는 검증 데이터에서 손실을 최소화하여 크기 구성 요소를 업데이트합니다. 이는 두 개의 구성 요소가 서로 독립적으로 업데이트될 수 있도록 하여 여러 하위 작업에 적합한 유연한 그래디언트 업데이트를 가능하게 합니다.

- **Performance Highlights**: BiDoRA는 자연어 이해(NLU), 자연어 생성(NLG), 토큰 분류(token classification) 등 14개 데이터 세트의 평가에서 DoRA 및 다른 PEFT 방법들을 현저하게 초월하는 성능을 보여줍니다. 실험 결과 BiDoRA는 전체 미세 조정보다 더 유사한 성능을 보이며, 과적합에 대한 저항성이 뛰어난 것으로 나타났습니다.



### OpenR: An Open Source Framework for Advanced Reasoning with Large Language Models (https://arxiv.org/abs/2410.09671)
- **What's New**: 이번 기술 보고서에서는 대형 언어 모델(LLMs)의 추론 능력을 향상시키기 위해 설계된 오픈 소스 프레임워크 OpenR을 소개합니다. OpenR은 데이터 수집, 강화 학습(online 및 offline), 그리고 비자기회 복호화를 통합하여 하나의 소프트웨어 플랫폼으로 통합합니다.

- **Technical Details**: OpenR은 OpenAI의 o1 모델의 핵심 기술을 탐구하는 첫 번째 오픈 소스 프레임워크로, 강화 학습을 통해 기존의 오토회귀 방법을 넘어선 고급 추론 능력을 달성합니다. OpenR은 MATH 데이터셋 평가를 통해 테스트 시간 컴퓨트와 과정 보상 모델을 통해 추론 및 성능의 상대적 개선을 입증합니다.

- **Performance Highlights**: OpenR 프레임워크는 모델, 데이터, 그리고 코드를 포함하여 오픈 플랫폼을 제공하여 LLM의 추론을 향상시키고 연구 개발을 가속화하는 데 기여합니다. 실험 결과, 과정 보상 모델과 테스트 시간 가이드 검색을 통해 약 10%의 발전된 테스트 시간 추론 성능을 보여주었습니다.



### Survival of the Safest: Towards Secure Prompt Optimization through Interleaved Multi-Objective Evolution (https://arxiv.org/abs/2410.09652)
Comments:
          EMNLP 2024 Industry Track

- **What's New**: 이번 논문에서는 대형 언어 모델(Large Language Models, LLMs)의 성능과 보안을 모두 개선하는 'Survival of the Safest' (SoS)라는 혁신적인 다목적 프롬프트 최적화 프레임워크를 소개합니다.

- **Technical Details**: SoS는 상호 교차 방식의 다목적 진화 전략을 사용하여 의미론적(semantic), 피드백(feedback), 교차 돌연변이(crossover mutations)를 통합하여 프롬프트 랜드스케이프를 효율적으로 탐색합니다. 이를 통해 복잡하고 고차원의 이산 검색 공간에서의 최적화를 가속화하며, 계산 비용을 낮게 유지하면서 유연한 목표 가중치를 조정할 수 있습니다.

- **Performance Highlights**: 광범위한 벤치마크 데이터셋에 대한 실험 평가 결과, SoS는 단일 목표 방법에 비해 높은 성능을 제공하고 안전성 및 보안을 현저히 향상시키는 것으로 확인되었습니다. 이 발전은 다양한 산업 응용 프로그램에서 고성능 및 보안성이 결합된 LLM 시스템의 배치에 큰 진전을 의미합니다.



### Learning the Bitter Lesson: Empirical Evidence from 20 Years of CVPR Proceedings (https://arxiv.org/abs/2410.09649)
Comments:
          NLP4Sceince Workshop, EMNLP 2024

- **What's New**: 이번 연구는 CVPR(Computer Vision and Pattern Recognition) 논문들이 Rich Sutton이 제안한 '쓴 교훈'의 원칙과 얼마나 일치하는지를 20년 간 분석합니다. 이는 기계 학습(ML) 분야의 전반적인 발전 방향과 관련이 있으며, LLM(대형 언어 모델)을 활용해 해당 논문의 추세를 평가합니다.

- **Technical Details**: 연구에서 활용된 LLM들은 GPT-4o-2024-05-13, gpt-4o-mini-2024-07-18, claude-3-5-sonnet-20240620로, 2005년부터 2024년까지의 CVPR 논문 제목과 초록을 평가합니다. 연구는 '쓴 교훈' 기준에 맞춘 다섯 가지 차원에서 논문의 정렬 정도를 척도로 평가합니다: Learning Over Engineering, Search over Heuristics, Scalability with Computation, Generality over Specificity, Favoring Fundamental Principles.

- **Performance Highlights**: 연구 결과, CVPR에서 일반적인 학습 알고리즘 및 컴퓨팅 자원의 사용 증가에 대한 중요한 경향이 발견되었습니다. LLM을 활용한 분석 방법은 머신러닝 연구의 진화 과정을 이해하는 데 기여하며, 이는 향후 컴퓨터 비전 연구에 긍정적인 영향을 미칠 수 있습니다.



### Reconstructive Visual Instruction Tuning (https://arxiv.org/abs/2410.09575)
- **What's New**: 이 논문에서는 ROSS(재구성 시각 지시 조정, Reconstructive Visual Instruction Tuning)를 도입하여 시각 중심의 감독 신호를 활용하는 대규모 멀티모달 모델(Large Multimodal Models, LMMs) 패밀리를 제안합니다. 기존의 시각 지시 조정 접근 방식이 텍스트 출력에만 초점을 맞추었던 것과 달리, ROSS는 입력 이미지를 재구성함으로써 LMMs가 시각 출력을 감독하도록 촉구합니다.

- **Technical Details**: ROSS는 자연 이미지를 통한 의미 있는 피드백을 제공하기 위해 노이즈 제거 목표를 사용하여 입력 이미지의 잠재 표현을 재구성하며, 이는 정확한 원시 RGB 값을 직접적으로 회귀하는 것을 피합니다. 이 내부 활성화 디자인은 LMMs가 이미지 세부 정보를 유지하도록 장려하여 세밀한 이해 능력을 향상시키고 환각(hallucinations)을 줄입니다.

- **Performance Highlights**: ROSS는 여러 비주얼 인코더와 언어 모델에서 일관되게 상당한 성능 향상을 보여줍니다. 예를 들어, 단일 SigLIP 비주얼 인코더를 사용하는 ROSS-7B는 HallusionBench에서 57.3으로 우수한 성과를 내며, 비슷한 모델 크기를 가진 최신 대안보다 월등한 성능을 발휘합니다.



### Scito2M: A 2 Million, 30-Year Cross-disciplinary Dataset for Temporal Scientometric Analysis (https://arxiv.org/abs/2410.09510)
Comments:
          19 pages

- **What's New**: 이번 연구에서는 Scito2M이라는 대규모의 과학 계량 데이터 세트를 소개하고 있습니다. 이 데이터 세트는 40여 년에 걸쳐 200만 개 이상의 학술 출판물을 포함하며, 다양한 분야의 학술 지식 진화를 추적할 수 있는 귀중한 자료를 제공합니다.

- **Technical Details**: Scito2M 데이터 세트는 arXiv에서 수집된 자료로, 제목, 초록, 키워드, 주제 카테고리 및 포괄적인 인용 그래프 등 상세한 메타데이터를 제공합니다. 이를 통해 약 30년에 걸친 과학적 영향력과 인용 패턴을 분석하고, 시간에 따라 변하는 학문 용어와 인용 행태를 조사하였습니다. 데이터 세트는 8개 주제로 분류되며, 키워드는 GPT-4o를 통해 추출됩니다.

- **Performance Highlights**: 연구의 주요 발견으로는, 기계 학습과 관련된 용어의 비중이 2015년 이후 급격히 증가하고, 응용 연구분야는 짧은 인용 연령을 보이는 반면, 이론적 학문 분야는 장기적인 인용 유지 경향을 보인다는 점이 있습니다. 또한, 다양한 분야의 지식 생산 및 공유 양상에 있어 중요한 차이점을 드러내었습니다.



### MTL-LoRA: Low-Rank Adaptation for Multi-Task Learning (https://arxiv.org/abs/2410.09437)
Comments:
          12 Pages, 4 Figures

- **What's New**: 이번 논문에서는 다중 작업 학습(Multi-Task Learning, MTL)에서 LoRA의 단점을 극복하기 위해 MTL-LoRA를 제안합니다. MTL-LoRA는 저랭크 적응(Low-Rank Adaptation)의 장점을 보존하면서도 MTL 능력을 현저히 향상시킵니다.

- **Technical Details**: MTL-LoRA는 작업에 적응하는 추가적인 파라미터(task-adaptive parameters)를 포함하여 각 작업의 특수 정보를 구분하고 다양한 작업 간에 공유되는 지식을 효과적으로 캡처합니다. 이를 통해 대형 언어 모델(Large Language Models, LLMs)이 적은 수의 학습 가능한 파라미터로 각기 다른 목표 작업 도메인에 적응할 수 있도록 합니다.

- **Performance Highlights**: MTL-LoRA는 자연어 이해(Natural Language Understanding), 상식 추론(Commonsense Reasoning), 이미지-텍스트 이해(Image-Text Understanding)와 같은 공공 학술 벤치마크와 실제 산업의 텍스트 광고 연관성 데이터 세트에서 LoRA 및 여러 변형보다 우수한 성능을 나타내며, 동등하거나 더 적은 수의 학습 가능한 파라미터로 이를 달성하였습니다.



### Exact Aggregation for Federated and Efficient Fine-Tuning of Foundation Models (https://arxiv.org/abs/2410.09432)
Comments:
          RS and KP contributed equally to this work: 18 Pages, 9 Figures, and 8 Tables. Another version of the paper accepted at NeurIPS 2024 Workshop on Fine-Tuning in Modern Machine Learning: Principles and Scalability

- **What's New**: 본 논문은 페더레이티드 학습 환경에서 Low-Rank Adaptation (LoRA)을 적용할 때 발생하는 문제를 해결하기 위해 Federated Exact LoRA (FedEx-LoRA) 기법을 제안합니다. 이 방법은 사전 훈련된 가중치 행렬에 잔여 오류 항을 추가하여 정확한 업데이트를 달성합니다.

- **Technical Details**: FedEx-LoRA는 LoRA의 효율성을 유지하며, 기존의 페더레이티드 평균화 방법에서 발생하는 부정확한 집합을 보완합니다. 제안된 방법은 추가 학습없이 각 집합 단계에서 오류 항을 도입하며, 통신 및 계산 오버헤드를 최소화하는 통신 프로토콜을 포함합니다.

- **Performance Highlights**: NLU와 NLG 작업에서 FedEx-LoRA는 기존의 최첨단 방법들에 비해 일관된 성능 향상을 보여주었으며, 페더레이티드 평균화와 이상적인 업데이트 간의 편차를 정량화하는 철저한 분석을 제공합니다.



### VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignmen (https://arxiv.org/abs/2410.09421)
Comments:
          EMNLP 2024 Main Conference camera-ready version. This article supersedes arXiv:2312.10665

- **What's New**: 이 논문에서는 인공지능 피드백(AI feedback)을 활용하여 비전-언어 모델(LVLM) 정렬을 위한 데이터 수집의 효율성을 탐구합니다. 이를 위해 VLFeedback라는 대규모 비전-언어 피드백 데이터셋을 소개하며, 이는 82,000개 이상의 다양한 다중 모달 지침과 설명으로 구성되어 있습니다.

- **Technical Details**: VLFeedback 데이터셋은 12개의 LVLM을 기반으로 하여 생성된 다양한 다중 모달 지침을 포함합니다. 이 모델들은 GPT-4V를 포함하여 비전-언어 작업에서 연결된 응답을 생성하는 데 사용됩니다. 주요 평가 기준은 (i) Helpfulness, (ii) Visual Faithfulness, (iii) Ethical Considerations 등 3가지입니다.

- **Performance Highlights**: Silkie라는 모델은 MME 벤치마크에서 6.9% 및 9.5%의 성능 향상을 보여주며, MMHal-Bench에서 환각 이슈를 감소시키고, 레드팀 공격에 대한 저항력이 향상되었습니다. AI 피드백의 활용은 인간 주석 데이터 대비 LVLM을 더 효과적으로 향상시키는 데 기여했습니다.



### Two Heads Are Better Than One: A Multi-Agent System Has the Potential to Improve Scientific Idea Generation (https://arxiv.org/abs/2410.09403)
- **What's New**: 이 논문에서는 과학 연구에서의 협동적 본질을 모방하기 위해 대규모 언어 모델(LLM)을 기반으로 한 다중 에이전트 시스템인 VirSci를 제안합니다. 이 시스템은 연구 아이디어를 공동으로 생성하고 평가하며 정제하는团队(팀)을 구성하여 자동화된 과학 발견을 지원할 수 있습니다.

- **Technical Details**: VirSci는 다음의 다섯 단계를 통해 연구 아이디어 생성 과정을 시뮬레이션합니다: (1) Collaborator Selection, (2) Topic Selection, (3) Idea Generation, (4) Idea Novelty Assessment, (5) Abstract Generation. 이 과정에서 팀장은 연구 협업 네트워크를 기반으로 적절한 협력자를 선정하고 과거 논문 데이터베이스를 활용해 새로운 아이디어 생성을 유도합니다. 또한, 단계마다 협력자들이 성과를 향상시키기 위한 토론 메커니즘을 구현합니다.

- **Performance Highlights**: 포괄적인 실험 결과, VirSci는 단일 에이전트 실행 방법에 비해 평균 13.8%의 정렬 수준 향상과 44.1%의 현대 연구에 대한 잠재적 영향 향상을 보이며, 이는 과학 아이디어의 혁신적인 생성을 위한 강력한 도구로서의 가능성을 보여줍니다.



### LogLM: From Task-based to Instruction-based Automated Log Analysis (https://arxiv.org/abs/2410.09352)
- **What's New**: 본 논문은 여러 작업과 도메인에서의 로그-레이블 쌍을 단일 형식의 instruction-response 쌍으로 변환하는 instruction-based training 접근 방식을 제안합니다. 이를 통해 수명 주기에 걸쳐 로그 분석의 유연성을 증가시키고, 특정 작업에 대한 훈련 데이터 의존성을 줄입니다.

- **Technical Details**: 새롭게 개발된 LogLM 모델은 복잡한 사용자 지침을 따르고 다양한 작업 간에 더 잘 일반화 할 수 있도록 훈련되었습니다. 이를 위해 여러 로그 분석 작업을 단일 모델로 통합함으로써 모델 배포의 부담을 완화합니다. 또한, 본 모델은 기존 접근 방식보다 뛰어난 성과를 이끌어낼 수 있습니다.

- **Performance Highlights**: 실험 결과, LogLM은 5 가지 로그 분석 기능을 대상으로 기존 방법들을 초월하는 성능을 보였으며, 복잡한 지침 및 보지 못한 작업에 대해서도 강력한 일반화 능력을 나타냅니다.



### Inference and Verbalization Functions During In-Context Learning (https://arxiv.org/abs/2410.09349)
Comments:
          EMNLP 2024 Findings

- **What's New**: 이 연구는 대형 언어 모델(Large Language Models, LMs)이 맥락 내 학습(In-Context Learning, ICL) 중에 비관련 레이블과도 잘 작동하는 이유를 설명하는 새로운 방법론을 제시합니다. 저자들은 LMs가 두 가지 연속적인 프로세스를 통해 ICL을 수행한다고 가정합니다.

- **Technical Details**: 저자들은 LMs가 ICL을 수행할 때, 먼저 추론 함수(Inference Function)가 입력 데이터에 대한 답변의 표현을 구축하고, 그 다음에 해당 표현을 출력 레이블 공간으로 매핑하는 언어화 함수(Verbalization Function)를 적용한다고 설명합니다. 연구에서는 이러한 두 함수가 서로 다른 레이어에 위치함을 확인했습니다.

- **Performance Highlights**: 다양한 데이터셋과 태스크(자연어 추론, 감정 분석, 주제 분류)를 통해 실험을 진행한 결과, LMs의 ICL 성능이 레이블 공간의 재매핑에 불변임을 입증했습니다. 연구 결과는 여러 오픈소스 모델에 걸쳐 동일하게 나타났습니다.



### DARE the Extreme: Revisiting Delta-Parameter Pruning For Fine-Tuned Models (https://arxiv.org/abs/2410.09344)
- **What's New**: 이 논문에서는 Delta-parameter pruning (DPP)의 성능 향상을 위해 DAREx라는 새로운 알고리즘을 제안합니다. DAREx는 DARE의 한계를 극복하는 알고리즘적으로 진보된 두 가지 방법, 즉 DAREx-q와 DAREx-L2를 포함합니다.

- **Technical Details**: DAREx-q는 높은 pruning 비율 (>30%)에서도 성능을 크게 향상시키도록 설계된 리스케일링 계수를 수정한 방법입니다. DAREx-L2는 DARE와 AdamR 결합하여 fine-tuning 중 패러미터 정규화를 적용하는 기법으로, DPP의 효과적인 적용 범위를 확장합니다.  분석에서 DARE의 실패 요인을 극복하기 위해 높은 pruning 비율에서 리스케일링 계수를 조정하고 L2 정규화를 적용하는 것이 중요함을 강조합니다.

- **Performance Highlights**: DAREx-q와 DAREx-L2를 적용한 결과, BERT 모델에서 CoLA 및 SST-2 데이터셋에 대해 35% 이상의 성능 향상을 달성했습니다. 중요도 기반의 DPP 기법과 비교할 때, 이들 알고리즘은 특히 높은 pruning 비율에서 더욱 우수한 성능을 보였습니다.



### Enhancing Multi-Step Reasoning Abilities of Language Models through Direct Q-Function Optimization (https://arxiv.org/abs/2410.09302)
- **What's New**: 논문에서는 Direct Q-function Optimization (DQO)이라는 새로운 강화 학습 (Reinforcement Learning) 알고리즘을 소개합니다. 이 알고리즘은 응답 생성 과정을 Markov Decision Process (MDP)로 공식화하고, 언어 모델에 의해 직접 파라미터화된 Q-function을 최적화하는 soft actor-critic (SAC) 프레임워크를 활용합니다. 기존 방법들이 가진 computational 자원의 한계와 multi-step reasoning 문제를 해결하고자 하는 노력이 담겨 있습니다.

- **Technical Details**: DQO는 언어 모델의 반응 절차를 MDP로 모델링하고, 최적의 정책을 KL-regularization 하에 학습하는 오프라인 강화 학습 알고리즘입니다. DQO의 Q-function은 언어 모델에 의해 직접 파라미터화되며, Soft Bellman Equation에 따라 업데이트됩니다. 이 접근 방식은 DQO가 multi-step 학습 알고리즘이 되도록 하여 process reward 신호를 효과적으로 활용할 수 있게 만듭니다.

- **Performance Highlights**: 실험 결과, DQO는 GSM8K와 MATH 데이터셋에서 기존 방법들보다 우수한 성능을 보였습니다. 특히 process rewards가 주어질 때 DQO의 성능이 더욱 향상되는 것으로 나타났으며, DQO가 LLM 정렬에 있어 유망한 오프라인 강화 학습 접근법임을 입증하였습니다.



### Natural Language Counterfactual Explanations for Graphs Using Large Language Models (https://arxiv.org/abs/2410.09295)
- **What's New**: 이번 연구는 그래프 신경망(GNNs)에서 카운터팩추얼 설명(counterfactual explanations)을 자연어(natural language)로 번역하기 위해 오픈소스 대형 언어 모델(Large Language Models, LLMs)의 생성 능력을 활용하는 방법을 제시합니다. 특히, 기술적인 전문 지식이 없는 사용자가 이해할 수 있는 형태로 설명을 변환하는 데 중점을 두었습니다.

- **Technical Details**: 이 연구에서는 카운터팩추얼 설명을 생성하기 위해 두 가지 그래프 카운터팩추얼 설명기(CF-GNNExplainer와 CF-GNNFeatures)를 사용하고, 여러 오픈소스 LLM에 대해 원시 카운터팩추얼 예제를 자연어 설명으로 변환하도록 지시했습니다. 생성된 설명의 품질을 평가하기 위해 새로운 메트릭(metrics)을 정의하였으며, 이 메트릭은 생성된 설명과 카운터팩추얼 예제 간의 매핑 정확도를 측정합니다.

- **Performance Highlights**: 실험 결과, 제안한 방법이 여러 그래프 데이터셋과 카운터팩추얼 설명기에서 효과적으로 자연어 표현을 생성하여 의사결정 과정 지원에 기여할 수 있음을 보여주었습니다. 특히, LLM 크기, 데이터셋 및 설명 방법을 다양하게 조정하여 수행한 포괄적인 평가를 통해 상당한 성과를 확인했습니다.



### nach0-pc: Multi-task Language Model with Molecular Point Cloud Encoder (https://arxiv.org/abs/2410.09240)
- **What's New**: 최근 연구에서, Language Models (LMs)를 의약품 발견 파이프라인에 통합하는 advancements가 이루어졌습니다. 그러나 기존 모델들은 주로 SMILES와 SELFIES와 같은 화학 문자열 표현만 활용하고 있으며, 이는 의약품 발견에 필수적인 공간적 특성(spatial features)이 부족합니다. 이를 해결하기 위해, 이 논문은 atom의 공간적 배열을 효과적으로 처리할 수 있는 domain-specific encoder와 textual representation을 결합한 nach0-pc 모델을 소개합니다.

- **Technical Details**: nach0-pc는 분자(point cloud) 인코더를 사용하여 간결하고 순서 불변 구조 representation을 제공합니다. 이 모델은 새로운 pre-training scheme을 도입하여 분자의 공간 구조 데이터셋에서 지식을 추출합니다. 또한, SMILES 표현을 생성한 후, 해당 SMILES 순서에 따라 atom 좌표를 명시하여 공간 분자 구조를 생성하는 텍스트 형식을 제안합니다.

- **Performance Highlights**: nach0-pc는 단일 작업(single-task) 및 다중 작업(multi-task) 프레임워크 내에서 fine-tuning 후, 여러 established spatial molecular generation tasks에서 생성된 샘플 질적으로 다른 diffusion 모델들과 동등한 성능을 보입니다. 특히, 이 모델은 다중 작업 접근 방식으로, 메모리 제한 등의 이유로 언어 모델들이 처리할 수 없는 포인트 클라우드 관련 데이터를 처리할 수 있다는 점에서 차별성을 지니고 있습니다. 이에 따라 모델은 훈련 및 추론 시간이 감소하면서도 동등한 성능을 유지하는 장점이 있습니다.



### P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains (https://arxiv.org/abs/2410.09207)
- **What's New**: 기존의 LLM(대형 언어 모델) 논리적 추론 능력을 이해하는 방법들이 충분하지 않다는 점을 입증하며, P-FOLIO라는 새로운 데이터세트를 소개합니다. 이 데이터세트는 인간이 작성한 복잡한 추론 체인을 포함하고 있습니다.

- **Technical Details**: P-FOLIO는 첫 번째 논리 문제(FOLIO)로부터 수집된 0에서 20까지의 추론 단계로 구성되어 있으며, 자연어 증명 작성 프로토콜을 통해 단계별로 작성된 proof(증명)를 포함합니다. 이 데이터세트는 다양한 추론 규칙을 사용해 12개의 간단한 추론 규칙과 20개 이상의 복잡한 추론 규칙을 포함하고 있습니다.

- **Performance Highlights**: P-FOLIO를 사용하여 LLM의 추론 능력을 평가하며, Llama3-7B 모델을 P-FOLIO로 fine-tuning(미세 조정) 한 결과 10% 이상 성능 향상이 있었습니다. 그러면서 인간이 작성한 추론 체인이 LLM의 논리적 추론 능력을 크게 향상시킴을 보여주었습니다.



### Encoding Agent Trajectories as Representations with Sequence Transformers (https://arxiv.org/abs/2410.09204)
Comments:
          12 pages, to be presented at GeoAI workshop at ACM SigSpatial 2024

- **What's New**: 이 논문에서는 고차원 시공간(spatiotemporal) 궤적을 새로운 방법으로 표현하고 이를 Transformer 기반 신경망 아키텍처로 인코딩하는 STARE 모델을 제안합니다. 이 모델은 궤적 데이터 내의 의미 있는 표현을 학습할 수 있는 능력을 갖추고 있습니다.

- **Technical Details**: STARE 모델은 궤적 데이터를 토큰화하여 Transformer Encoder Stack(TES)에 입력하고, 이를 통해 의미 있는 인코딩을 학습합니다. 이 모델은 GPS 좌표와 같은 'quasi-continuous' 데이터를 유한한 어휘를 가진 'discrete' 요소로 변환하는 방식으로 작동하며, 높은 정확도의 분류(classification) 성능을 보입니다.

- **Performance Highlights**: 다양한 합성 및 실제 궤적 데이터셋을 통해 STARE 모델은 기존 LSTM(BiLSTM 포함) 모델들보다 분류 정확도(classification accuracy) 측면에서 향상된 성능을 보여주었으며, 에이전트와 위치 간의 관계를 학습하는 데에도 효과적입니다.



### Can a large language model be a gaslighter? (https://arxiv.org/abs/2410.09181)
Comments:
          10/26 (Main Body/Total), 8 figures

- **What's New**: 본 연구에서는 대규모 언어 모델(LLMs)의 취약성을 기반으로 하여, Gaslighting 공격을 통해 사용자 심리가 조작될 수 있는 위험성을 탐구합니다. 이를 위해 DeepCoG라는 두 단계의 프레임워크를 제안하여 Gaslighting 계획 및 대화를 이끌어내는 방법을 개발하였습니다.

- **Technical Details**: DeepCoG는 DeepGaslighting과 Chain-of-Gaslighting(CoG)으로 구성되어, 개인화된 Gaslighting 계획을 유도한 후 Gaslighting 대화를 생성합니다. 실험을 통해 오픈 소스 LLM이 Gaslighting 공격에 더 취약해지는 것을 확인하였고, 안전 정렬 전략 3가지를 통해 LLM의 안전성을 12.05% 향상시켰습니다.

- **Performance Highlights**: 연구 결과, Gaslighting LLM은 기초 모델과 거의 동일한 수준의 유해성을 보였으며, 일반적인 질문에서 도움이 되는 LLM이 Gaslighting을 일으킬 수 있음을 발견했습니다. 안전 정렬 또한 LLM의 유용성에 미치는 영향이 최소화됨을 보여주었습니다.



### HLM-Cite: Hybrid Language Model Workflow for Text-based Scientific Citation Prediction (https://arxiv.org/abs/2410.09112)
Comments:
          NeurIPS 2024 paper

- **What's New**: 본 논문에서는 인용 예측(citation prediction) 문제를 해결하기 위한 새로운 개념인 core citation을 도입합니다. 이를 통해 단순한 이진 분류 문제를 넘어, 심층적인 의미를 가진 인용을 구별하는 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 $	extbf{HLM-Cite}$라는 하이브리드 언어 모델(workflow)로, embedding(임베딩)과 generative LMs(생성적 언어 모델)을 결합합니다. 첫 단계에서는 교육된 텍스트 임베딩 모델을 사용하여 고유한 core citations(핵심 인용)을 거대 후보 세트에서 초기 검색합니다. 이후 LLM의 에이전트(workflow)로서 Guider, Analyzer 및 Decider를 구성하여, 일회성 예시를 통해 인용 가능성이 높은 문서들을 분석하고 순위를 매깁니다.

- **Performance Highlights**: HLM-Cite는 19개 과학 분야에서 실험을 수행하여, SOTA (State-of-the-Art) 방법들과 비교했을 때 17.6%의 성능 향상을 보였습니다. 또한, 이 방법은 최대 100K의 후보 세트를 처리할 수 있는 스케일러블한 능력을 입증하였습니다.



### Mechanistic? (https://arxiv.org/abs/2410.09087)
Comments:
          Equal contribution. Position paper. Accepted for presentation at the BlackBoxNLP workshop at EMNLP 2024

- **What's New**: 이 논문에서는 'mechanistic interpretability'라는 용어의 의미와 그 정의의 변천사를 살펴보며, 전통적인 NLP 해석 가능성과 어떻게 다르게 구분되는지를 자세히 설명합니다.

- **Technical Details**: 이 논문은 'mechanistic interpretability'를 좁은 기술적 정의(신경망의 인과 메커니즘을 통한 이해) 및 넓은 기술적 정의(모델의 내부 구조 설명)로 나누어 설명하고 있습니다. 또한, 인과 메커니즘에 대한 강한 초점을 강조하며, 기존의 NLP 해석 가능성 연구와의 관계를 살펴봅니다.

- **Performance Highlights**: 요약하자면, 'mechanistic interpretability'는 인과 메커니즘을 통해 신경망의 내부를 탐색하는 방식을 강조하며, 이는 과학적 진전을 위한 문화적 격차를 해소하는 데 중요한 역할을 한다고 주장합니다.



### Alignment Between the Decision-Making Logic of LLMs and Human Cognition: A Case Study on Legal LLMs (https://arxiv.org/abs/2410.09083)
- **What's New**: 이 논문에서는 법률 분야의 대규모 언어 모델(LLM)의 의사결정 논리와 인간 인지 사이의 정합성을 평가하는 방법을 제안합니다. 기존의 언어 생성 결과 평가 방식과는 달리, 우리는 LLM의 출력을 뒷받침하는 세부 의사결정 논리의 정확성을 평가하고자 합니다.

- **Technical Details**: 논문에서는 LLM의 상호작용을 원시 의사결정 논리로 정량화하며, 이를 통해 정합성 평가를 위한 새로운 지표를 설계하였습니다. 이와 관련된 상호작용은 AND-OR 상호작용의 개념을 포함하여 LLM의 신뢰 점수와 인간의 법적 판단 간의 일치를 평가하는 데 사용됩니다. LLM이 생성한 문장 속의 입력 토큰 간 비선형 관계를 측정합니다.

- **Performance Highlights**: 실험 결과, 법률 LLM은 높은 예측 정확도를 보임에도 불구하고, 내부 추론 논리의 상당 부분에서 주목할 만한 문제를 포함하고 있다는 사실이 확인되었습니다. 이는 LLM의 의사결정 논리와 인간의 인지 간의 정합성이 요구된다는 것을 보여줍니다.



### Leveraging Social Determinants of Health in Alzheimer's Research Using LLM-Augmented Literature Mining and Knowledge Graphs (https://arxiv.org/abs/2410.09080)
- **What's New**: 이 논문은 알츠하이머병(Alzheimer's disease, AD)과 관련된 비의료적 요인인 사회적 건강 결정요인(social determinants of health, SDoH)이 브랜드에 미치는 영향을 연구하기 위해, 최신 대형 언어 모델(large language model, LLM) 및 자연어 처리(natural language processing, NLP) 기술을 활용한 새로운 자동화된 프레임워크를 제안합니다.

- **Technical Details**: 이 연구에서 제안하는 프레임워크는 PubMed에서 관련 문헌을 수집하고, OpenAI의 최신 LLM인 GPT-4o를 이용하여 생물 의학적 개체 및 SDoH 개체를 추출하고, 이들을 일반 목적 지식 그래프인 PrimeKG와 통합하여 SDoH 보강 지식 그래프를 만듭니다. 그래프 신경망(graph neural networks)을 사용하여 링크 예측 작업을 수행하여 결과 도출을 평가합니다.

- **Performance Highlights**: 이 프레임워크는 AD 연구에서의 지식 발견을 향상시키기 위한 가능성을 보여주며, 다른 SDoH 관련 연구 영역에도 일반화 가능하여 건강 결과에 대한 사회적 결정요인의 영향을 탐색하기 위한 새로운 도구를 제공합니다.



New uploads on arXiv(cs.IR)

### RosePO: Aligning LLM-based Recommenders with Human Values (https://arxiv.org/abs/2410.12519)
- **What's New**: 최근에 추천 시스템을 위한 Large Language Models (LLMs)의 활용도가 높아지고 있습니다. 본 논문에서는 '도움이 되고 해롭지 않은' LLM 기반 추천기를 구축하기 위해 Recommendation with smoothing personalized Preference Optimization (RosePO)라는 프레임워크를 제안합니다. 이 프레임워크는 사용자 선호도 간의 비교 관계를 모델링하는 데 초점을 맞추고 있습니다.

- **Technical Details**: RosePO는 SFT(Supervised Fine-Tuning) 데이터와 자연스럽게 일치하는 입력 및 선택된 응답뿐만 아니라, 도움을 증대시키기 위한 거부 샘플링 전략과 해로움을 감소시키기 위한 두 가지 전략을 설계했습니다. 또한, 자동으로 구성된 선호도 데이터의 불확실성에 강력하도록 개인화된 스무딩 팩터를 도입했습니다.

- **Performance Highlights**: 세 가지 실제 데이터 세트에 대한 평가 결과, 본 방법이 추천 성능을 개선했을 뿐 아니라, 의미적 환각(semantic hallucination)과 인기 편향(popularity bias)을 완화하는 데 효과적임을 보여주었습니다.



### Unifying Economic and Language Models for Enhanced Sentiment Analysis of the Oil Mark (https://arxiv.org/abs/2410.12473)
- **What's New**: 원유 시장에 특화된 CrudeBERT라는 새로운 Language Model이 도입되었습니다. 이 모델은 기존의 전통적인 예측 방법의 한계를 극복하기 위해 개발되었습니다.

- **Technical Details**: CrudeBERT는 자연어 처리(Natural Language Processing) 분야에서 발전된 Generative Pre-trained Transformer(GPT) 모델을 기반으로 하며, 원유 시장에 특화된 용어를 효과적으로 처리하도록 파인 튜닝(Fine-tuning)되었습니다.

- **Performance Highlights**: CrudeBERT의 감정 점수(Sentiment Scores)는 WTI 선물 곡선(WTI Futures Curve)과 더 밀접하게 일치하며, 가격 예측(Price Predictions) 성능을 크게 향상시켰습니다.



### Mitigating Dual Latent Confounding Biases in Recommender Systems (https://arxiv.org/abs/2410.12451)
- **What's New**: 최근 추천 시스템 분야에서, 종래 시스템들이 겪었던 편향(bias) 문제를 해결하기 위한 새로운 방법인 IViDR이 제안되었습니다. 이 방법은 Instrumental Variables (IV) 접근법과 Identifiable Variational Auto-Encoder (iVAE)를 결합하여, 이중 잠재 혼동 변수(dual latent confounders)에 의한 편향을 줄여주는 통합 솔루션입니다.

- **Technical Details**: IViDR은 사용자의 특징 임베딩을 IV로 활용하여 아이템과 사용자 피드백 간의 잠재 혼동 변수들이 야기하는 편향을 해결합니다. 이 시스템은 원래의 상호작용 데이터와 편향이 제거된 데이터에서 잠재적 혼동 변수의 식별 가능한 표현을 유추하기 위해 iVAE를 사용합니다. 이론적으로 IV의 유효성과 배우 representations의 식별 가능성을 분석합니다.

- **Performance Highlights**: 실제 데이터와 합성 데이터에 대한 광범위한 실험 결과, IViDR은 편향을 줄이고 추천의 정확성을 높이는 데 있어 최신 모델들을 능가하는 성능을 보였습니다.



### QUIDS: Query Intent Generation via Dual Space Modeling (https://arxiv.org/abs/2410.12400)
- **What's New**: 이번 논문에서는 *query intent generation*라는 새로운 작업을 제안하여, 관련 문서와 비관련 문서를 사용하여 검색 쿼리에 대한 상세하고 정확한 의도 설명을 자동으로 생성하는 방법을 다룹니다. 기존 방법들이 쿼리 분류나 클러스터링으로 단순화했던 것과 달리, 우리는 비유적 해석을 넘어 더 정교한 쿼리 의도를 포착하기 위해 새로운 접근 방식인 이중 공간 모델을 도입했습니다.

- **Technical Details**: 우리는 문서의 의미적 관련성과 비관련성 정보를 사용하여 쿼리 의도를 이해하는 이중 공간 모델을 제안합니다. 이 과정에서 관련 문서와 비관련 문서를 인코딩하여 표현 공간에서 분리하고, 새로운 비틀기 공간에서 의미를 분리하여 최종 의도 설명을 생성합니다. 이를 통해, 쿼리와 직접 연결된 의미만을 재생산합니다. 또한, *transformer* 기반 모델(T5, BART)을 활용하여 이중 인코더 아키텍처에서 대조 학습(contrastive learning)을 적용합니다.

- **Performance Highlights**: 벤치마크 데이터셋 Q2ID에서 우리의 모델은 기존 방법들에 비해 뛰어난 성능을 보였으며, ROUGE 메트릭과 BERTScore 측정에서 최첨단 기준선보다 우수한 결과를 나타냈습니다. 인간 평가 및 LLM 기반 평가도 실시하여 모델의 강점과 약점을 종합적으로 분석했습니다. 이 모델은 irrelevant intent topics에 대한 집중도를 효과적으로 감소시키는 특성을 보여, 사용자 검색 경험을 향상시킬 수 있는 잠재력을 지니고 있습니다.



### Multi-Cause Deconfounding for Recommender Systems with Latent Confounders (https://arxiv.org/abs/2410.12366)
- **What's New**: 본 논문에서는 추천 시스템에서 발생하는 latent confounders의 문제를 해결하기 위해 Multi-Cause Deconfounding Method (MCDCF)를 제안합니다. 이 방법은 사용자의 행동 데이터를 활용하여 여러 사용자와 아이템 간의 상호작용을 분석함으로써 latent confounders에 대한 대체 변수를 학습합니다.

- **Technical Details**: MCDCF는 추천 시스템의 모델을 multi-cause 문제로 설정하고 사용자와 아이템의 latent confounders를 실행 가능한 대체 변수로 분리하여 학습합니다. 이 과정에서 causality의 효과를 추정하고 click prediction을 통해 사용자 피드백을 예측하는 과정을 포함합니다.

- **Performance Highlights**: 세 개의 실제 데이터셋에서 수행된 실험을 통해 MCDCF 방식이 사용자와 아이템에 관련된 latent confounders를 효과적으로 회복하고, 바이어스를 줄이며 추천의 정확성을 개선함을 입증하였습니다.



### Comprehending Knowledge Graphs with Large Language Models for Recommender Systems (https://arxiv.org/abs/2410.12229)
- **What's New**: 이번 연구에서는 CoLaKG라는 새로운 방법을 제안하여 추천 시스템의 성능을 개선합니다. CoLaKG는 대규모 언어 모델(LLM)을 활용하여 지식 그래프(KG)의 한계를 극복하고, 아이템 간의 세밀한 의미적 연결을 유지합니다.

- **Technical Details**: CoLaKG는 아이템 중심의 하위 그래프(subgraph)를 KG에서 추출하고, 이를 LLM에 대한 입력으로 변환합니다. LLM은 이러한 하위 그래프에 대한 이해를 출력하고, 이를 의미적 임베딩(semantic embedding)으로 변환합니다. 또한, 이 임베딩을 바탕으로 아이템-아이템 그래프(item-item graph)를 구성하여 고차원 관계를 직접적으로 포착합니다.

- **Performance Highlights**: 실제 데이터셋 4종에 대한 광범위한 실험 결과, CoLaKG 방법이 기존 방법들에 비해 우수한 성능을 보였음을 확인했습니다.



### Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations (https://arxiv.org/abs/2410.12228)
- **What's New**: 이 논문은 개인화 추천 시스템을 향상시키기 위해 다양한 데이터 모달리티(data modalities)를 통합하는 새로운 프레임워크인 Triple Modality Fusion (TMF)를 소개합니다. 이 프레임워크는 시각적, 텍스트, 그래프 데이터의 융합을 통해 수행됩니다.

- **Technical Details**: TMF 모델은 큰 언어 모델(LLMs)과의 정렬을 통해 세 가지 모달리티를 통합하며, 각각의 모달리티는 사용자 행동을 포괄적으로 표현하기 위해 서로 다른 특징을 제공합니다. 시각적 정보는 아이템의 맥락 및 미적 특성을 캡처하고, 텍스트 데이터는 사용자 관심사와 아이템 특성에 대한 상세한 통찰력을 제공하며, 그래프 데이터는 아이템-행동 이질 그래프(item-behavior heterogeneous graph) 내의 관계를 설명합니다.

- **Performance Highlights**: 광범위한 실험을 통해 추천 정확성을 개선하는 효과를 입증하였습니다. 추가적인 ablation 연구를 통해 TMF 모델 디자인의 효과성과 이점을 검증하였습니다.



### Post-Userist Recommender Systems : A Manifesto (https://arxiv.org/abs/2410.11870)
Comments:
          Extended abstract for paper presented at AltRecSys Workshop 2024. Held at the 18th ACM Conference on Recommender Systems, Bari, Italy. October 18, 2024

- **What's New**: 이 논문에서는 추천 시스템에서 제안하는 방법론으로서 'userist recommendation'을 정의하고, 사용자와 시스템 간의 관계만으로 구성된 접근법을 논의합니다. 'post-userist recommendation'은 다양한 이해관계자가 얽혀있는 더 큰 관계의 장을 제시하며 추천 기능을 구별합니다.

- **Technical Details**: 추천 시스템의 새로운 접근 방식으로 'userist recommendation'과 'post-userist recommendation' 개념을 도입합니다. 'post-userist recommendation'은 생성 미디어와의 관계를 포함하여, 창작자와 관객 간의 연결을 가능하게 하는 기능을 중시합니다.

- **Performance Highlights**: 생성 미디어의 시대에 접어들면서, 사용자 지향 추천(userist recommendation)은 개인화된 미디어 생성과 구분할 수 없게 되며, 따라서 'post-userist recommendation'이 추천 시스템 연구의 유일한 미래 방향이라고 주장합니다.



### The Moral Case for Using Language Model Agents for Recommendation (https://arxiv.org/abs/2410.12123)
- **What's New**: 이 논문은 정보 및 통신 환경의 한계와 기존 추천 시스템의 한계를 논의하며, 언어 모델(LM) 에이전트를 사용하는 대안적 접근 방식을 제안합니다.

- **Technical Details**: 기존 추천 시스템은 대량 감시(mass surveillance)를 촉진하고 권력을 집중시킵니다. 이 논문은 LM 에이전트를 사용하여 자연어로 표현된 사용자의 선호와 가치에 맞는 콘텐츠를 소싱하고 큐레이션하는 방법을 탐구하며, 여기에는 후보 생성(candidate generation), 계산 효율성(computational efficiency), 선호 모델링(preference modelling), 프롬프트 주입(prompt injection)과 같은 도전 과제가 포함됩니다.

- **Performance Highlights**: 성공적으로 구현될 경우, LM 에이전트는 대량 감시에 의존하지 않고 디지털 공공 영역을 안내할 수 있으며, 권력을 플랫폼에서 사용자에게 돌려주고, 행동적 프록시(proxy)가 아닌 중요한 요소를 최적화하며, 사용자의 주체성(agency)을 강화하는 역할을 할 수 있습니다.



### Online Digital Investigative Journalism using SociaLens (https://arxiv.org/abs/2410.11890)
- **What's New**: 본 논문에서는 대형 언어 모델(LLM)과 기계 학습(ML) 기술을 통합하여 언론 보도에서의 정보 검색 및 분석을 혁신할 수 있는 도구인 SociaLens를 소개합니다. 이는 기자들이 데이터 중심의 내용과 통찰력을 생성하는 데 도움을 주어, 현대의 조사 저널리즘을 새로운 단계로 이끌 것을 목표로 하고 있습니다.

- **Technical Details**: SociaLens는 온라인 소스에서 쿼리 전용 데이터를 식별하고 추출하는 다재다능하고 자율적인 조사 저널리즘 도구입니다. 이 도구는 ML 분석을 완전 자율적으로 수행하여 대량의 데이터에서 결론을 도출할 수 있도록 설계되었습니다. SociaLens는 OpenAI의 GPT-4o API를 기반으로 하며, 자연어 대화 분석을 위한 대화형 에이전트를 포함하고 있습니다. 또한, 맞춤형 그래픽 인터페이스를 통해 사용자는 구조화된 형태로 사실을 추출할 수 있습니다.

- **Performance Highlights**: 사례 연구로 방글라데시의 아동 성폭력 사건을 분석했으며, SociaLens가 복잡한 데이터 수집 및 분석 작업을 수행함으로써 기자들이 스스로 코드 전문 지식이 없는 상태에서도 정교한 통찰력을 얻을 수 있음을 보여줍니다. SociaLens는 텍스트 및 시각 보고서를 생성할 수 있으며, 사용자 질문에 대한 대화형 응대와 실시간 예측 분석을 통해 기자들에게 효율적인 뉴스 보도를 지원합니다.



### GeoLife+: Large-Scale Simulated Trajectory Datasets Calibrated to the GeoLife Datas (https://arxiv.org/abs/2410.11853)
Comments:
          Accepted paper at this https URL

- **What's New**: 이 논문에서는 실제 GeoLife 데이터셋의 통계적 특징을 활용하고, 이와 유사한 이동 패턴을 생성하기 위해 생명체의 행동을 시뮬레이션하는 'Pattern of Life Simulation (POL)'을 결합하여 GeoLife+라는 새로운 시뮬레이션 데이터를 생성했습니다.

- **Technical Details**: Genetic algorithm을 활용하여 GeoLife 데이터의 패턴과 유사한 특징을 재현하도록 POL의 파라미터를 조정했습니다. 이로 인해 182명, 1천명, 5천명, 1만명, 5만명, 10만명의 에이전트를 가진 여러 시뮬레이션 데이터셋을 생성했으며, 이는 각기 다른 기간 동안 수집되었습니다. 데이터는 기가바이트 단위로 제공됩니다.

- **Performance Highlights**: GeoLife 데이터와 유사한 통계적 특성을 가지면서도 밀도가 훨씬 높은 시뮬레이션 데이터셋으로, 연구자들이 미시적인 인간의 이동 패턴을 더 잘 이해하고 다양한 응용 프로그램에 활용할 수 있도록 돕습니다.



### GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable Recommendation (https://arxiv.org/abs/2410.11841)
- **What's New**: GaVaMoE는 새로운 Gaussian-Variational Gated Mixture of Experts 프레임워크를 도입하여 설명 가능한 추천 시스템의 개인화 및 데이터 희소성을 해결합니다.

- **Technical Details**: GaVaMoE는 두 가지 주요 구성 요소를 포함합니다: (1) Variational Autoencoder (VAE)와 Gaussian Mixture Model (GMM)을 사용하여 복잡한 사용자-아이템 협업 선호를 모델링하는 평가 재구성 모듈; (2) 다수의 전문가 모델을 활용해 세부적으로 개인화된 설명을 생성하는 다중 게이팅 메커니즘입니다.

- **Performance Highlights**: GaVaMoE는 세 개의 실제 데이터셋에서 실행된 광범위한 실험을 통해 기존 방법보다 설명 품질, 개인화 및 일관성에서 유의미하게 우수한 성능을 보여주었습니다.



### Adaptive Coordinators and Prompts on Heterogeneous Graphs for Cross-Domain Recommendations (https://arxiv.org/abs/2410.11719)
Comments:
          Under review

- **What's New**: 본 논문에서는 HAGO라는 새로운 프레임워크를 제안하여 다중 도메인 추천 시스템의 성능을 향상시키는 방법을 소개합니다. HAGO는 이질적인 적응형 그래프 코디네이터를 통해 다중 도메인 그래프를 통합하여 추천 시스템의 정확성을 높입니다.

- **Technical Details**: HAGO는 다섯 가지 주요 요소로 구성되어 있습니다: 이질적 그래프 코디네이터, 다중 도메인 그래프 사전 학습(또는 pre-training) 전략, 그래프 프롬프트(Graph prompting) 방법, 그리고 다양한 그래프 기반 모델과의 호환성을 제공합니다. 이 구조는 코디네이터 간의 연결을 동적으로 조정하여 유용한 상호작용을 강화하고 부정적 전이(Negative transfer) 효과를 완화합니다.

- **Performance Highlights**: HAGO는 두 개의 실제 플랫폼에서 7개의 서로 다른 도메인에 대한 실험을 수행하여 최신 기법들과 비교할 때 뛰어난 성능을 보였습니다. 이 결과는 HAGO가 다양한 실세계 응용 프로그램에 적용될 수 있는 가능성을 보여줍니다.



### CoActionGraphRec: Sequential Multi-Interest Recommendations Using Co-Action Graphs (https://arxiv.org/abs/2410.11464)
- **What's New**: 이 논문에서는 eBay와 같은 전자 상거래 플랫폼을 위한 아이템 추천 시스템 개발 시 마주하는 독특한 도전 과제를 다룹니다. 특히 데이터 희소성과 다양한 사용자 관심사를 해결하기 위한 CoActionGraphRec (CAGR) 모델을 제안합니다.

- **Technical Details**: CAGR 모델은 텍스트 기반의 두 개의 타워 구조를 가진 딥러닝 모델(Item Tower 및 User Tower)을 사용하고, 공동 행동 그래프(co-action graph) 레이어를 활용합니다. Item Tower에서는 각 아이템을 공동 행동 아이템으로 표현하여 공동 신호(collaborative signals)를 포착하고, User Tower에서는 각각의 사용자 행동 시퀀스를 나타내는 완전 연결 그래프를 구축하여 쌍 관계를 인코딩합니다. 또한, 명시적 상호작용 모듈이 행동 상호작용을 캡쳐하는 표현을 학습합니다.

- **Performance Highlights**: 광범위한 오프라인 및 온라인 A/B 테스트 실험 결과, 제안된 접근 방식이 최신 방법들에 비해 주요 지표에서 성능 개선을 보여줍니다.



### Sequential LLM Framework for Fashion Recommendation (https://arxiv.org/abs/2410.11327)
- **What's New**: 이 논문은 패션 산업에 최적화된 추천 시스템을 제안하며, 선행 학습된 대형 언어 모델(LLM)을 활용하여 추천 성능을 향상시키는 방법을 제시합니다.

- **Technical Details**: 제안된 프레임워크는 세 가지 주요 단계로 이루어져 있습니다: 첫째, 추천 목표에 맞춘 전문 프롬프트를 설계하는 프롬프트 엔지니어링 기술을 사용합니다. 둘째, 비용이 많이 드는 훈련 비용을 줄이기 위해 Parameter-Efficient Fine-Tuning (PEFT) 기술을 적용합니다. 마지막으로, 예측된 제품 제목 및 ID를 활용하여 관련 후보 항목을 검색하고 순위를 매기는 mix-up 기반 검색 기술을 사용합니다.

- **Performance Highlights**: 실험 결과, 제안된 프레임워크는 패션 추천 성능을 현저히 향상시켰다고 합니다. 특히, 기존의 패션 추천 시스템보다 효과적으로 사용자 선호도를 파악하고, 콜드 스타트 문제를 극복하는 데 기여했습니다.



### Optimizing Encoder-Only Transformers for Session-Based Recommendation Systems (https://arxiv.org/abs/2410.11150)
- **What's New**: 이 논문에서는 Sequential Masked Modeling (SMM)이라는 새로운 접근법을 소개하며, 이는 단일 세션 추천 시스템에서의 다음 추천 아이템 예측 문제를 해결하기 위해 설계되었습니다. 이 방법은 데이터 증강(data augmentation)과 특별한 토큰 마스킹 전략을 결합하여 시퀀스 종속성(sequential dependencies)을 효과적으로 포착합니다.

- **Technical Details**: SMM은 인코더 전용 트랜스포머 아키텍처를 활용하여 설계되었습니다. 이 방법에서는 윈도우 슬라이딩을 통한 데이터 증강과 펜얼리미니트 토큰 마스킹 전략을 사용하여 세션 데이터를 처리합니다. 제안하는 방법은 Yoochoose 1/64, Diginetica, Tmall의 세 가지 주요 데이터 세트에서 평가되었습니다.

- **Performance Highlights**: Transformer-SMM 모델은 동일한 정보 수준에서 가장 최신 모델들과 비교했을 때 명확한 성능 향상을 보였습니다. 사용자 데이터가 더 많이 제공되는 모델들과 비교해도 경쟁력을 유지하며 높은 정확도와 순위 평가 지표를 기록했습니다.



### SGUQ: Staged Graph Convolution Neural Network for Alzheimer's Disease Diagnosis using Multi-Omics Data (https://arxiv.org/abs/2410.11046)
Comments:
          20 pages, 2 figures

- **What's New**: 새롭게 제안된 SGUQ(단계적 그래프 컨볼루션 네트워크)는 알츠하이머병(AD) 진단을 위한 다중 오믹스 데이터(Multi-omics Data) 이용 시, mRNA 데이터로 시작하고 필요한 경우에만 DNA 메틸화 및 miRNA 데이터를 점진적으로 추가함으로써 임상 비용을 줄이고 진단 정확성을 향상시킵니다.

- **Technical Details**: SGUQ는 불확실성 정량화(Uncertainty Quantification)를 포함하는 그래프 기반 구조로, mRNA와 DNA 메틸화 데이터, miRNA 데이터를 단계적으로 통합하여 사용할 수 있도록 설계되었습니다. 이는 기존의 AI 접근 방식이 모든 오믹스 데이터를 완료해야 하는 비효율성에서 벗어나는 방법입니다.

- **Performance Highlights**: SGUQ는 ROSMAP 데이터셋에서 0.858의 정확도를 달성했으며, 46.23%의 샘플은 단일 모달 오믹스 데이터(mRNA)만으로 신뢰성 있게 예측되었고, 16.04%의 추가 샘플은 두 개의 오믹스 데이터 유형(mRNA + DNA 메틸화)을 결합했을 때 신뢰성 있게 예측되었습니다.



### DIIT: A Domain-Invariant Information Transfer Method for Industrial Cross-Domain Recommendation (https://arxiv.org/abs/2410.10835)
Comments:
          Accepted at CIKM 2024

- **What's New**: 이 논문에서는 산업 추천 시스템(Recommendation System, RS)에서의 Cross-Domain Recommendation (CDR) 문제를 해결하기 위한 새로운 방법인 DIIT(End-to-End Domain-Invariant Information Transfer)를 제안합니다. 이는 기존의 CDR 방법들이 산업 환경에서의 데이터 변화에 적합하지 않은 점을 개선하고자 합니다.

- **Technical Details**: DIIT는 두 가지 추출기(Extractor)를 사용하여 각 도메인에서 공통적인 정보(domain-invariant information)를 최대한으로 추출합니다. 첫 번째 추출기는 도메인 수준에서 동작하는 도메인 불변 정보 추출기으로, 두 번째 추출기는 표상 수준에서의 추출을 담당합니다. 또한, 수집된 정보를 최신 목표 도메인 모델로 전송하기 위한 마이그레이터(Migrator)를 설계하였습니다. 이 과정에서 다중 지점 지식 증류(Multi-spot Knowledge Distillation, KD)를 통해 다른 구조의 소스 도메인 모델로부터 효과적으로 정보를 전송할 수 있습니다.

- **Performance Highlights**: DIIT는 하나의 생산 데이터셋과 두 개의 공개 데이터셋에서 실험을 통해 효과성과 효율성을 입증하였습니다. 특히, 사용자의 즉각적인 관심 변화를 잘 반영하면서도 높은 성능을 유지하도록 설계되어 있습니다.



### LR-SQL: A Supervised Fine-Tuning Method for Text2SQL Tasks under Low-Resource Scenarios (https://arxiv.org/abs/2410.11457)
Comments:
          12pages, 4 figures,submitting to a journal

- **What's New**: LR-SQL은 데이터베이스의 복잡성으로 인한 GPU 메모리 요구량 증가 문제를 해결하기 위해 제안되었습니다. 기계 학습 모델의 세분화된 조정을 통해 더 효율적인 Text2SQL 변환을 가능하게 합니다.

- **Technical Details**: LR-SQL은 schema_link 모델과 SQL_generation 모델의 두 가지 감독적 세부 조정(supervised fine-tuning) 모델로 구성되어 있습니다. schema_link 모델은 전체 데이터베이스를 유연한 테이블 조합으로 나누어 모델이 이산 조각에서 관계를 학습할 수 있게 합니다. 또한, Chain-of-Thought 능력을 훈련시켜 다양한 조각 간의 관계 인지를 개선합니다.

- **Performance Highlights**: LR-SQL은 기존 방법에 비해 총 GPU 메모리 사용량을 40% 줄였으며, schema_link 작업에서 테이블 예측 정확도는 2% 감소했습니다. 전체 Text2SQL 작업에서는 실행 정확도(Execution Accuracy)가 0.6% 감소했습니다.



### Enhance Graph Alignment for Large Language Models (https://arxiv.org/abs/2410.11370)
Comments:
          Under review

- **What's New**: 본 연구에서는 Graph Alignment Large Language Models (GALLM)를 제안하여 LLM이 그래프 데이터를 더 잘 이해하고 사용할 수 있도록 합니다. 새로운 자기지도 학습 방식과 템플릿 정렬을 통해 성능을 개선합니다.

- **Technical Details**: GALLM은 크게 두 가지 단계로 구성됩니다: 첫 번째는 자기지도 조정(self-supervised tuning) 단계로, 텍스트 일치(task) 작업을 통해 LLM을 훈련시킵니다. 두 번째는 작업 특정 조정(task-specific tuning) 단계로, 추가적인 설명과 정렬된 템플릿을 통해 감독 정보를 활용하여 두 가지 범주 프롬프트 방법을 제시합니다.

- **Performance Highlights**: 여러 데이터셋에 대한 실험 평가 결과, 감독 학습(supervised learning), 멀티 데이터셋 일반화(multi-dataset generalizability), 특히 제로샷 능력(zero-shot capability)에서 상당한 성과 개선이 있음을 보여주었습니다.



### Reducing Labeling Costs in Sentiment Analysis via Semi-Supervised Learning (https://arxiv.org/abs/2410.11355)
Comments:
          12 pages, 7 figures, accepted at the 2024 8th International Conference on Natural Language Processing and Information Retrieval (NLPIR 2024), Okayama, Japan, 2024

- **What's New**: 이 연구는 기계 학습에서 데이터 레이블링의 효율성을 높이는 새로운 접근 방식을 제시합니다. 전통적인 방법에 비해 레이블의 수를 크게 줄일 수 있는 반지도 학습(semi-supervised learning)에서의 레이블 전파(label propagation)를 탐구하고 있습니다.

- **Technical Details**: 본 연구에서는 텍스트 분류를 위한 매니폴드 가정(manifold assumption)을 기반으로 한 전이식 레이블 전파(transductive label propagation) 방법을 사용합니다. 그래프 기반(graph-based) 방법을 활용하여 레이블이 없는 데이터에 대한 유사 레이블(pseudo-labels)을 생성하고, 이를 통해 깊은 신경망(deep neural networks)을 학습합니다.

- **Performance Highlights**: 본 연구는 감정 분석(sentiment analysis) 분야에 대한 실험을 통해 레이블 전파의 효과성을 평가하며, 기존의 레이블링 방법에 비해 성능이 비슷한 결과를 얻을 수 있음을 보이고 있습니다.



### On the Capacity of Citation Generation by Large Language Models (https://arxiv.org/abs/2410.11217)
Comments:
          Accepted by CCIR 2024

- **What's New**: 이번 연구는 대형 언어 모델(LLMs)이 생성하는 응답 내 인용 생성 능력에 대한 체계적 분석을 실시하고, 인용 품질을 향상시키기 위한 새로운 방법을 제시합니다. 주된 초점은 기존 연구들이 응답의 정확성을 높이는 데 집중했던 것과 달리, 정확한 출처 귀속 기능을 개선하는 것입니다.

- **Technical Details**: 연구에서 사용한 두 가지 기본 방법은 few-shot 및 fine-tuning입니다. 인용 품질 향상을 위해 Generate-then-Refine 방법을 제안하며, 이는 관련 인용을 추가하고 불필요한 인용을 제거하여 응답 텍스트를 변경하지 않고 인용 품질을 개선하는 방식을 포함합니다. 또한, 새로운 인용 평가 메트릭도 도입하여 기존 메트릭에서 불필요한 인용에 대한 과도한 처벌을 배제합니다.

- **Performance Highlights**: WebGLM-QA, ASQA, ELI5 데이터셋에서 실험한 결과, 제시된 방법이 LLMs에 의해 생성된 응답의 인용 품질을 상당히 향상시키는 것으로 나타났습니다. 연구의 주요 기여는 LLM이 생성하는 인용 분석, 인용 품질 평가를 위한 보다 포괄적인 메트릭 제안, 그리고 인용 품질을 대폭 향상시키는 Generate-then-Refine 접근법을 제시한 것입니다.



### GraFPrint: A GNN-Based Approach for Audio Identification (https://arxiv.org/abs/2410.10994)
Comments:
          Submitted to IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)

- **What's New**: 이 논문은 GraFPrint라는 오디오 식별 프레임워크를 소개합니다. 이 프레임워크는 Graph Neural Networks (GNNs)의 구조적 학습 능력을 활용하여 강력한 오디오 핑거프린트를 생성합니다.

- **Technical Details**: GraFPrint는 시-주파수(time-frequency) 표현에서 k-nearest neighbor (k-NN) 그래프를 구성하고, max-relative 그래프 컨볼루션을 적용하여 지역 및 전역 정보를 인코딩합니다. 네트워크는 자기 지도(self-supervised) 대조적 접근법을 사용하여 훈련되며, 이 과정에서 환경 소음에 대한 저항성을 강화합니다.

- **Performance Highlights**: GraFPrint는 대규모 데이터셋에서 다양한 레벨의 세분화(granularity)에서 우수한 성능을 보여주며, 경량화되고 확장 가능하여 광범위 참조 데이터베이스가 있는 실제 응용 프로그램에 적합합니다.



### Mitigating the Impact of Reference Quality on Evaluation of Summarization Systems with Reference-Free Metrics (https://arxiv.org/abs/2410.10867)
- **What's New**: 이 논문에서는 인간의 평가와 높은 상관관계를 가지면서 계산 비용이 매우 낮은 새로운 reference-free (참조 없는) 메트릭을 소개합니다.

- **Technical Details**: 제안된 메트릭은 기존의 reference-based (참조 기반) 메트릭과 함께 사용될 수 있으며, 저품질 참조 설정에서 메트릭의 견고성을 향상시킵니다. 특히 긴 문서의 요약에 대한 relevance (관련성)을 잘 나타냅니다.

- **Performance Highlights**: 이 메트릭은 인간의 평가와 높은 상관관계를 가지며, 저비용으로 계산 가능함을 보여줍니다.



### Generating Model Parameters for Controlling: Parameter Diffusion for Controllable Multi-Task Recommendation (https://arxiv.org/abs/2410.10639)
- **What's New**: 이 논문에서는 재훈련 없이 추천 모델의 파라미터를 동적으로 조정하여 사용자의 변화하는 요구에 효과적으로 대응할 수 있는 새로운 접근법인 PaDiRec를 제안합니다.

- **Technical Details**: PaDiRec는 조건부 훈련(conditional training)을 통해 다양한 작업 요구 사항을 기반으로 최적화된 모델 파라미터의 분포를 학습하기 위해 확산 모델(diffusion model)을 사용합니다. 이 접근법은 기존 추천 시스템과 호환되며, 어댑터 튜닝(adapter tuning) 기법을 통해 최적화된 모델 파라미터를 미리 확보한 후, 테스트 시에도 시간에 따라 변경되는 작업 요구 사항에 따라 모델 파라미터를 생성합니다.

- **Performance Highlights**: 공개 데이터셋과 상업 앱에서 수집한 데이터셋을 통한 광범위한 실험 결과, PaDiRec는 동적 요구 사항 변화에 대한 추천 시스템의 제어력을 효과적으로 향상시키며, 이를 통해 추천 성능도 유지합니다.



### VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents (https://arxiv.org/abs/2410.10594)
- **What's New**: 이 논문에서는 기존의 텍스트 기반 Retrieval-augmented generation (RAG) 시스템의 한계를 극복하기 위해 비전-언어 모델(Vision-Language Model, VLM)을 이용한 새로운 RAG 파이프라인인 VisRAG를 제안합니다.

- **Technical Details**: VisRAG는 문서를 직접 이미지로 임베딩하여 VLM을 통해 정보를 추출하는 방식으로 동작합니다. VisRAG-Ret와 VisRAG-Gen이라는 두 구성 요소로 이루어져 있으며, 이들은 각각 이미지 기반 정보 검색과 생성 기능을 수행합니다.

- **Performance Highlights**: VisRAG는 전통적인 텍스트 기반 RAG에 비해 검색 및 생성 단계 모두에서 성능이 25-39% 향상되었으며, 특히 다중 문서 처리를 효율적으로 수행할 수 있는 가능성이 확인되었습니다.



### Advancing Academic Knowledge Retrieval via LLM-enhanced Representation Similarity Fusion (https://arxiv.org/abs/2410.10455)
Comments:
          The 2nd Place of KDD Cup 2024 OAG-Challenge AQA

- **What's New**: 2024 KDD Cup AQA 챌린지에서 2위를 차지한 LLM-KnowSimFuser는 LLM(대규모 언어 모델)의 강력한 언어 이해 및 개방형 도메인 지식을 활용하여 관련 학술 용어를 정확하게 추출하는 retrieval 모델의 진전을 목표로 하였다.

- **Technical Details**: 이 접근법은 세 가지 주요 구성 요소로 이루어져 있다: (1) 사전 학습 모델을 사용한 embedding 추출, (2) fine-tuning된 모델을 통한 embedding 산출, (3) 유사성 행렬을 계산하고 융합하여 문서의 관련성을 평가한다. 이를 위해 NV-Embed-v1, SFR-Embedding-Mistral, GritLM-7B, Linq-Embed-Mistral과 같은 여러 사전 학습 모델이 사용되었다.

- **Performance Highlights**: 제안된 LLM-KnowSimFuser는 최종 리더보드에서 0.20726의 점수를 달성하였으며, 실험 결과 각 모델과 융합된 변형의 성능이 비교 분석되었다.



### A Hybrid Filtering for Micro-video Hashtag Recommendation using Graph-based Deep Neural Network (https://arxiv.org/abs/2410.10367)
- **What's New**: 이번 연구에서는 마이크로 비디오에 대한 해시태그 추천 시스템을 위한 새로운 하이브리드 필터링 기반 기술인 MISHON을 제안합니다. MISHON은 콘텐츠 기반 필터링과 사용자 기반 협업 필터링을 결합하여 사용자와의 관련성을 고려한 해시태그 추천을 제공합니다.

- **Technical Details**: MISHON 기술은 사용자 간의 역사적인 태깅 행동을 기반으로 유사한 사용자 모델링을 통해 사용자 간 상호작용을 분석합니다. 또한, 그래프 기반의 딥 뉴럴 네트워크를 활용하여 사용자 간, 모달리티 간, 사용자-모달리티 간 상호작용을 모델링합니다.

- **Performance Highlights**: 세 개의 실세계 데이터셋에서 MISHON은 F1 스코어 측면에서 각각 3.6%, 2.8%, 및 6.5%의 상대적 향상을 달성했습니다. 또한, 차가운 시작 문제를 해결하기 위해 콘텐츠 및 사회적 영향을 기반으로 한 기술을 도입하여, 관련성이 없는 사용자의 경우에도 15.8%의 개선된 F1 스코어를 보여주었습니다.



### Enhancing Attributed Graph Networks with Alignment and Uniformity Constraints for Session-based Recommendation (https://arxiv.org/abs/2410.10296)
Comments:
          11 pages, 4 figures, 5 tables. Accepted by ICWS 2024

- **What's New**: 이 논문은 기존의 속성 비인식(Session-based Recommendation, SBR) 모델을 향상시키기 위한 일반적인 프레임워크인 AttrGAU(Attributed Graph Networks with Alignment and Uniformity Constraints)를 제안합니다. 이는 주로 모델 설계에 특화된 기존의 방법들과 차별화되어, 다양한 모델에 적용할 수 있습니다.

- **Technical Details**: AttrGAU는 항목-속성 관계의 이질성을 고려하여 이항 속성 그래프(Bipartite Attributed Graph)를 구성하고, 속성 인식 그래프 컨볼루션(attribute-aware graph convolution)을 통해 노드 임베딩을 개선합니다. 또한, 세션 표현 학습에서 기존 SBR 모델을 그래프 신경망 및 주의(attention) 읽기 모듈로 분리하여 비침입적(non-intrusive) 구조를 유지합니다. 조정(alignment) 및 균일성(uniformity) 제약 조건을 도입하여 속성 의미(attribute semantics)와 협동 의미(collaborative semantics) 간의 분포 불일치를 최적화합니다.

- **Performance Highlights**: 세 가지 공개 벤치마크 데이터셋에 대한 광범위한 실험에서 AttrGAU 프레임워크가 기존 SBR 모델의 추천 성능과 데이터 희소성(data sparsity) 및 잡음(noise) 문제에 대한 강인성을 크게 향상시킬 수 있음을 보여주었습니다.



### FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG (https://arxiv.org/abs/2410.10293)
Comments:
          18 pages, 6 figures, 13 tables

- **What's New**: 본 연구에서는 Retrieval-Augmented Generation (RAG) 구조의 한계를 극복하기 위한 새로운 접근 방식을 제안합니다. 기존의 flat retrieval 방식의 단점을 보완하기 위해, coarse-to-fine granularity를 적용한 FunnelRAG라는 점진적 검색 패러다임을 도입했습니다.

- **Technical Details**: FunnelRAG는 검색 단계를 점진적으로 진행하여 후보 군집의 규모를 줄이고 검색 단위의 세분성을 높이며 검색기의 용량 수준을 증가시킵니다. 이를 통해 Mixed-capacity retrievers를 활용하여 효율성과 정확성을 모두 개선합니다. 근본적으로, Coarse-to-Fine Granularity를 통해 대량의 문서에서 먼저 coarse-grained units를 만들고, 이를 다시 세분화하여 최종적으로 passage-level units로 분리합니다.

- **Performance Highlights**: FunnelRAG는 기존 retrieval 방식에 비해 약 40%의 시간 오버헤드를 줄이며, 경쟁력 있는 retrieval 성능을 유지하였습니다. 이는 Natural Question (NQ) 및 Trivia QA (TQA)와 같은 open-domain 질문 응답 시스템에서의 성능 개선을 입증합니다.



### DecKG: Decentralized Collaborative Learning with Knowledge Graph Enhancement for POI Recommendation (https://arxiv.org/abs/2410.10130)
- **What's New**: 본 연구에서는 사용자 간의 협업 학습을 통한 분산형 추천 시스템인 DecKG(Decentralized Collaborative Learning with Knowledge Graph Enhancement) 프레임워크를 제안합니다. 기존의 POI(Point-of-Interest) 추천 시스템들이 개인 정보 보호 문제를 유발하는 중앙 집중형 모델에서 벗어나기 위해 자율적인 데이터 학습을 가능하게 했으며, 이는 외부 지식 그래프를 통합하여 모델의 성능을 향상시키는 독창적인 방법을 제공합니다.

- **Technical Details**: DecKG는 사용자가 민감한 상호작용 데이터를 직접 서버에 업로드하는 대신, 일반 항목 범주를 업로드함으로써 비민감한 체크인 데이터를 생성합니다. 서버는 전체 지식 그래프(Knowledge Graph)를 사전 학습하고, 각 사용자에게 관련된 세분화된 서브 지식 그래프(sub-KG)를 배포합니다. 클라이언트 장치에서 이러한 서브-KG를 통해 추가적인 지식 학습이 가능하며, 이 과정을 통해 사용자 간의 지식 교환이 이루어집니다.

- **Performance Highlights**: 실제 데이터셋을 통해 DecKG의 성능을 평가한 결과, 기존의 분산 POI 추천 시스템보다 추천 성능이 현저히 향상된 것으로 나타났습니다. 이는 DecKG가 개인 정보 보호를 유지하면서도 더욱 효과적인 추천을 제공할 수 있는 가능성을 시사합니다.



### MAIR: A Massive Benchmark for Evaluating Instructed Retrieva (https://arxiv.org/abs/2410.10127)
Comments:
          EMNLP 2024

- **What's New**: 이 논문은 MAIR (Massive Instructed Retrieval Benchmark)라는 새로운 정보 검색 (IR) 벤치마크를 제안합니다. MAIR는 6개의 도메인에서 126개의 독특한 IR 작업을 포함하며, 최신 IR 모델의 일반화 능력을 평가하기 위한 광범위한 기준을 제공합니다.

- **Technical Details**: MAIR는 126개의 다양한 검색 작업으로 구성되어 있으며, 805개의 고유한 지침(instruction)이 포함되어 있습니다. 이 데이터 세트는 SIGIR 논문, 기존 벤치마크, TREC 공유 작업 및 최신 LLM 벤치마크와 같은 여러 출처에서 수집되었습니다. 모델의 성능을 평가하기 위해 sparse retriever, single-task text embedding models, non-instruction-tuned multi-task text embedding models, instruction-tuned embedding models 및 re-ranking models를 포함한 다양한 검색 모델을 벤치마킹했습니다.

- **Performance Highlights**: 실험 결과, instruction-tuned 모델이 비-instruction-tuned 모델에 비해 MAIR에서 일반적으로 더 우수한 성능을 발휘했습니다. 특히, GritLM-7B 모델이 평균 nDCG@10에서 55.20으로 가장 높은 점수를 기록했습니다. 이러한 결과는 지침 추가 시 명확한 성능 향상을 보여줍니다.



### The Role of Fake Users in Sequential Recommender Systems (https://arxiv.org/abs/2410.09936)
Comments:
          10 pages, 2 figures

- **What's New**: 이번 연구는 Sequential Recommender Systems (SRSs)이 현실 세계에서 fake users(가짜 사용자)의 존재에 어떻게 영향을 받는지를 분석하며, 이로 인해 발생하는 성능 저하를 실질적으로 평가합니다. 이러한 가짜 사용자들은 무작위로 아이템에 상호작용하거나, 인기 있는 또는 인기 없는 아이템을 추종하거나, 특정 장르에 집중하는 행동을 보입니다.

- **Technical Details**: SRS 조사는 Normalized Discounted Cumulative Gain (NDCG) 및 Rank Sensitivity List (RLS)와 같은 성능 메트릭스를 통해 수행되었습니다. 두 가지 모델(SASRec 및 GRU4Rec)을 사용하여 MovieLens 1M, MovieLens 100k, Foursquare NYC 및 Foursquare Tokyo 데이터 세트를 기반으로 실험이 이루어졌습니다. 가짜 사용자의 유형과 수에 따라 NDCG와 RLS의 성과 변화를 분석했습니다.

- **Performance Highlights**: 가짜 사용자 존재가 RLS 메트릭스의 성능을 심각하게 저하시킬 수 있으며, RLS 값이 거의 0에 가까워지는 경우도 발생할 수 있다는 발견이 있었습니다. 반면, 전통적인 메트릭인 NDCG는 상대적으로 안정한 수준을 유지하는 경향을 보였습니다.



### Analysis and Design of a Personalized Recommendation System Based on a Dynamic User Interest Mod (https://arxiv.org/abs/2410.09923)
- **What's New**: 인터넷의 빠른 발전과 정보의 폭발로 사용자를 위한 정확한 개인화 추천(Recommendation) 제공이 중요한 연구 주제로 대두되고 있습니다. 본 논문은 동적 사용자 관심 모델(Dynamic User Interest Model)에 기반한 개인화 추천 시스템을 설계하고 분석하였습니다.

- **Technical Details**: 이 시스템은 사용자 행동 데이터(User Behavior Data)를 수집하고, 동적 사용자 관심 모델을 구축하여 여러 추천 알고리즘을 결합하여 사용자가 개인화된 콘텐츠를 받을 수 있도록 합니다. 논문에서는 시스템의 아키텍처 설계(Architecture Design), 알고리즘 구현(Algorithm Implementation), 실험 결과(Experimental Results)에 대해 상세히 논의합니다.

- **Performance Highlights**: 연구 결과에 따르면, 이 시스템은 추천 정확도(Recommendation Accuracy)와 사용자 만족도(User Satisfaction)를 상당히 개선하는 것으로 나타났습니다. 향후 연구 방향(Future Research Directions)도 탐구하고 있습니다.



### A Comparative Study of PDF Parsing Tools Across Diverse Document Categories (https://arxiv.org/abs/2410.09871)
Comments:
          17 pages,11 figures, 5 tables

- **What's New**: 본 연구는 다양한 문서 유형에 대한 PDF 파싱 도구의 성능을 비교 연구함으로써, 주로 학술 문서 외의 문서에서의 효과성을 개선하고자 하는 새로운 접근 방식을 제시합니다.

- **Technical Details**: 본 연구는 10가지 인기 있는 PDF 파싱 도구를 DocLayNet 데이터셋을 사용하여 6가지 문서 카테고리에서 성능을 평가했습니다. 여기에는 PyPDF, PyMuPDF, pdfplumber, pypdfium2, Unstructured, Tabula, Camelot, Nougat 및 Table Transformer(TATR)와 같은 머신러닝 기반 도구가 포함됩니다. 텍스트 추출과 테이블 탐지 능력을 평가하였으며, rule-based 및 learning-based 방법론을 사용하여 주기적으로 결과를 비교하였습니다.

- **Performance Highlights**: 텍스트 추출의 경우 PyMuPDF와 pypdfium이 다른 도구들보다 우수한 성능을 보였으나, 과학 및 특허 문서에서 모든 파서들이 어려움을 겪었습니다. 테이블 탐지에서는 TATR가 금융 및 특허, 법률 및 과학 카테고리에서 탁월한 성능을 보였고, Camelot은 입찰 문서에서 가장 높은 성능을 기록했습니다. 이러한 결과는 문서 유형과 특정 작업에 따라 적절한 파싱 도구를 선택하는 것이 중요하다는 점을 강조합니다.



### Agentic Information Retrieva (https://arxiv.org/abs/2410.09713)
Comments:
          11 pages, position paper

- **What's New**: 본 논문에서는 대규모 언어 모델(LLMs)이 정보 검색(Information Retrieval) 방식에 미친 영향을 분석하고, 유능한 LLM 에이전트의 기능을 바탕으로 하는 새로운 정보 검색 패러다임인 Agentic Information Retrieval (Agentic IR)를 소개합니다. 이는 전통적인 정보 검색 시스템의 한계를 극복하고, 보다 유연한 정보 접근 방식을 제시합니다.

- **Technical Details**: Agentic IR은 기존의 고정된 정보 검색 아키텍처 대신, 에이전트를 중심으로 한 통합 아키텍처를 도입합니다. 에이전트는 관찰(observation), 추론(reasoning), 행동(action)을 반복적으로 수행하여 사용자에게 최적의 정보를 제공하는 구조입니다. 이 과정에서 프롬프트 엔지니어링(prompt engineering), 검색 강화 생성(retrieval-augmented generation), 감독 및 강화 학습 기법을 포함한 다양한 방법이 사용됩니다.

- **Performance Highlights**: Agentic IR은 삶의 보조자(life assistant), 비즈니스 보조자(business assistant), 코드 보조자(coding assistant) 등 다양한 응용 분야에서 활용될 가능성이 큽니다. 이를 통해 미래의 디지털 생태계에서 중요한 정보 진입 점이 될 것으로 기대됩니다.



### Towards Scalable Semantic Representation for Recommendation (https://arxiv.org/abs/2410.09560)
- **What's New**: 최근 대형 언어 모델(LLM)의 발전과 함께, LLM 기반으로 개발된 Semantic ID가 추천 시스템의 성능을 향상시키기 위한 연구가 더욱 늘어나고 있습니다. 이 논문에서는 Mixture-of-Codes라는 새로운 접근 방식을 제안하여 LLM의 의미적 표현을 효과적으로 확장합니다.

- **Technical Details**: 제안된 Mixture-of-Codes (MoC) 방법은 두 단계로 구성됩니다. 첫 번째 단계에서는 여러 개의 독립적인 코드북(codebook)을 학습하여 LLM의 표현을 인덱싱합니다. 두 번째 단계에서는 생성된 코드의 학습 가능 임베딩을 융합(fuse)하여 하류 추천(stage) 단계에서 사용합니다. 또한 VQ-VAE 방법을 활용하여 코드 임베딩을 생성하며, 이러한 과정에서 코드의 차원(dimension)을 추천 시스템의 ID 임베딩 차원에 맞추어 처리합니다.

- **Performance Highlights**: 실험 결과, MoC 방법은 분별력(discriminability), 차원 견고성(dimension robustness), 성능(performance) 면에서 우수한 확장성을 달성하는 것으로 나타났습니다. 세 개의 공개 데이터셋에서 진행된 포괄적인 실험을 통해 이 방법의 효과가 입증되었습니다.



### Eco-Aware Graph Neural Networks for Sustainable Recommendations (https://arxiv.org/abs/2410.09514)
Comments:
          9 pages, 2 tables, 3 figures, RecSoGood Workshop

- **What's New**: 이번 연구는 GNN(그래프 신경망)을 활용한 추천 시스템의 환경적 영향을 분석한 최초의 연구로, 기존 문헌에서 간과된 탄소 배출 문제에 주목하고 있습니다. GNN 기반의 추천 아키텍처에서의 에너지 소비 및 탄소 발자국을 평가하며, 지속 가능하고 책임 있는 인공지능 개발에 기여할 수 있는 데이터를 제공합니다.

- **Technical Details**: 이 연구는 CodeCarbon을 활용하여 CPU와 GPU의 전력 소비를 추적하며, CO2-eq(이산화탄소 등가물) 배출량을 측정합니다. 다양한 GNN 아키텍처, 즉 Neural Graph Collaborative Filtering (NGCF), LightGCN 및 SimGCL 모델을 평가하고 각각의 임베딩 크기에 따라 모델의 성능과 환경적 영향을 실험합니다.

- **Performance Highlights**: GNN 기반 추천 시스템의 훈련과 배포에서 발생하는 탄소 배출에 대한 포괄적인 분석을 수행하였으며, 에너지 소비 및 수명 주기 전반의 환경적 영향을 고려하여 추천 시스템의 성능과 지속 가능성 간의 균형을 맞출 수 있는 방법을 제시합니다.



### Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performanc (https://arxiv.org/abs/2410.09359)
- **What's New**: 이번 연구는 그린 추천 시스템(Green Recommender Systems) 맥락에서, 다운샘플링(downsampling) 기법을 통해 추천 알고리즘의 성능을 에너지 효율적으로 최적화하는 가능성을 탐구합니다. 대규모 모델 훈련의 환경적 영향을 고려하여, 다양한 추천 알고리즘의 성능을 데이터셋 크기 변화에 따라 분석했습니다.

- **Technical Details**: 연구는 MovieLens 100K, 1M, 10M와 Amazon Toys and Games 데이터셋을 사용하여 수행되었으며, 훈련 데이터를 최대 50%까지 줄였음에도 불구하고 FunkSVD 및 BiasedMF처럼 일부 알고리즘이 상당한 추천 품질을 유지함을 발견했습니다. nDCG@10 점수는 전체 데이터셋 성능의 약 13% 이내로 나타났습니다.

- **Performance Highlights**: 다운샘플링한 훈련 세트로 알고리즘을 훈련 시, 평균적으로 실행 시간 약 72% 감소와 함께 에너지 소비를 줄일 수 있었습니다. 이는 알고리즘 프로토타입 및 초기 테스트를 고려할 경우 상당한 탄소 배출 감소를 가져올 수 있는데, 알고리즘당 데이터셋당 CO2e 배출량 감소를 추정할 수 있습니다.



### Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models (https://arxiv.org/abs/2410.10542)
Comments:
          Accepted on NLLP at EMNLP 2024

- **What's New**: 본 연구에서는 인도의 법원 판결 예측을 위한 실제 시나리오를 탐구하고, InLegalBERT, BERT, XLNet과 같은 다양한 transformer 기반 모델과 LLMs인 Llama-2 및 GPT-3.5 Turbo를 활용합니다. 사례가 재판을 위해 제시될 때 순간적인 정보를 기반으로 한 판결 예측을 시도하며, 후향적 분석 없이 실제 상황을 모방합니다.

- **Technical Details**: transformer 모델의 효율성을 평가하고 법적 사실의 요약을 통해 예측 품질을 향상시키는 방법을 실험합니다. 계층적 transformer 모델을 도입하여 판결 사실을 최적화하고, 법령, 판례, 주장과 같은 추가적인 법적 정보를 포함하여 LLMs의 성능을 개선합니다. 이 연구는 GPT-3.5 Turbo가 인도의 법적 판결 예측에서 뛰어난 성능을 보이는 것을 발견했습니다.

- **Performance Highlights**: 자동 평가 및 인간 평가 모두에서 LLMs가 전문가 수준의 성능에 도달하지 못했음을 보이며, 판결 예측과 설명 품질 모두에서 개선의 여지가 있음을 시사합니다. Clarity와 Linking이라는 두 가지 새로운 평가 지표를 정의하여 LLM이 생성한 예측 및 설명의 품질을 평가합니다.



### Medico: Towards Hallucination Detection and Correction with Multi-source Evidence Fusion (https://arxiv.org/abs/2410.10408)
Comments:
          12 pages, 3 figures, 6 tables. Accepted by EMNLP 2024's demo track

- **What's New**: 새로운 연구인 Medico는 다원적 증거 융합(Multi-source evidence fusion)을 통한 환각 감지 및 수정 프레임워크입니다. 이는 LLMs(대형 언어 모델)의 환각 문제를 해결하기 위해 다양한 출처에서 증거를 수집하고, 생성된 콘텐츠가 사실 오류를 포함하는지 여부를 탐지하여 그 판단의 이유(rationale)를 제공하고, 반복적으로 환각된 내용을 수정합니다.

- **Technical Details**: Medico 프레임워크는 세 가지 주요 구성 요소로 이루어져 있습니다: (1) 다원적 증거 융합(Multi-source Evidence Fusion) - 여러 출처에서 다양한 증거를 수집합니다; (2) 증거 기반 환각 감지(Hallucination Detection with Evidence) - 융합된 증거를 활용하여 LLMs의 생성된 콘텐츠를 확인하고 판단의 이유를 제시합니다; (3) 이유에 기반한 환각 수정(Hallucination Correction with Rationale) - 분류 결과가 잘못된 경우, 이유에 따라 환각된 콘텐츠를 반복적으로 수정합니다. 이를 통해 Medico는 설명 가능성(explainability)을 제공하며, 모델 무관(model-agnostic)하므로 다양한 LLMs에 적용 가능합니다.

- **Performance Highlights**: Medico는 증거 검색(evidence retrieval)에서 0.964 HR@5 및 0.908 MRR@5, 환각 탐지(hallucination detection)에서 0.927-0.951 F1, 환각 수정(hallucination correction)에서 0.973-0.979 승인율(approval rate)을 기록하며 뛰어난 성능을 입증했습니다.



### Collaborative filtering based on nonnegative/binary matrix factorization (https://arxiv.org/abs/2410.10381)
Comments:
          12 pages, 7 figures

- **What's New**: 본 논문에서는 희소한 데이터의 협업 필터링에 적합한 수정된 Nonnegative/Binary Matrix Factorization (NBMF) 알고리즘을 제안합니다.

- **Technical Details**: 수정된 NBMF 방법에서는 평점 행렬의 평가되지 않은 요소들을 마스킹(masking)하여 협업 필터링 성능을 향상시킵니다. 또한, 저지연 Ising 머신(ising machine)을 사용하여 계산 시간을 단축시키는 장점이 있습니다.

- **Performance Highlights**: 기존 NBMF가 밀집 데이터에서 주로 사용되었던 것과 달리, 제안된 방법은 희소 데이터에서도 효과적으로 작동하여 좋은 추천 성능을 보여줍니다.



### BookWorm: A Dataset for Character Description and Analysis (https://arxiv.org/abs/2410.10372)
Comments:
          30 pages, 2 figures, EMNLP 2024 Findings

- **What's New**: 이 연구에서는 복잡한 내러티브와 수많은 등장인물이 포함된 장편 문학 작품에서 등장인물을 이해하는 데 초점을 맞추고 있습니다. 'BookWorm'이라는 새로운 데이터셋을 도입하여 캐릭터 설명과 분석을 통해 등장인물의 발전과 사회적 맥락을 이해하는 여러 과제를 수행합니다.

- **Technical Details**: 우리는 두 가지 과제를 정의합니다: 등장인물 설명(character description)과 등장인물 분석(character analysis). BookWorm 데이터셋은 Gutenberg Project에서 도서와 관련된 인간 작성 설명과 분석을 쌍으로 구성합니다. 우리는 최첨단 long-context 모델의 성능을 평가하고, 데이터셋을 이용해 retrieval-based 접근 방식이 더 효과적임을 발견했습니다. 다양한 기법을 통해 캐릭터 정보를 검색하고, hierarchical 처리 방식보다 retrieval 기반 모델이 두 작업 모두에서 더 나은 성능을 발휘한다는 것을 입증했습니다.

- **Performance Highlights**: 조정(fine-tuned)된 모델을 사용한 경우, coreference 기반 retrieval 방식이 가장 사실적인 설명을 생성하는 것으로 나타났으며, 이는 사실(fact) 및 함축(entailment) 기반 메트릭을 통해 측정되었습니다. 본 연구는 장편 내러티브 이해에 대한 추가 연구를 촉진할 것이란 기대를 표현하고 있습니다.



### Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning (https://arxiv.org/abs/2410.10360)
- **What's New**: 이번 연구에서는 Retrieval-Augmented Generation (RAG) 접근 방식을 사용하여 대규모 언어 모델(LLMs)의 환상 생성과 지식 노후화 문제를 해결하기 위한 새로운 프레임워크인 Parenting을 제안합니다.

- **Technical Details**: Parenting은 LLM의 파라미터 공간 내에서 adherence와 robustness를 분리하는 방법론으로, forward activation gain을 기반으로 한 주요 파라미터 검색 기법을 활용하여 두 요소와 강히 연결된 중요한 파라미터 유닛을 식별하고 고립시킵니다. 이후 각기 다른 능력을 가진 파라미터 유닛에 대해 특화된 미세 조정 방법을 적용하여 균형 잡힌 adherence와 robustness의 향상을 목표로 합니다.

- **Performance Highlights**: 다양한 데이터셋과 모델을 대상으로 한 광범위한 실험을 통해 Parenting의 효과성과 일반화 가능성이 입증되었습니다.



### Back-of-the-Book Index Automation for Arabic Documents (https://arxiv.org/abs/2410.10286)
- **What's New**: 이 연구는 아랍어 도서의 백서 색인(Back-of-the-book index) 추출 자동화를 통해 도서의 가독성을 향상시키고, 수작업으로 인한 오류를 줄이는 방법을 제안합니다.

- **Technical Details**: 각 인덱스 용어에 대해 관련 페이지에서 모든 가능한 명사구(Noun Phrases)를 추출하여 후보 풀을 정의합니다. 이 명사구는 품사 분석(Part-of-speech analysis)을 통해 식별되며 효율적인 검색을 위해 벡터 데이터베이스(Vector Database)에 저장됩니다. 우리는 정확한 일치(Exact Matches), 어휘 유사성(Lexical Similarity), 의미 유사성(Semantic Similarity) 등의 여러 메트릭을 사용하여 가장 적합한 발생Occurrences를 결정합니다.

- **Performance Highlights**: F1-score가 .966(정확도 Precision = .966, 재현율 Recall = .966)으로 매우 우수한 성능을 기록하였습니다. 이러한 결과는 백서 색인 생성 및 검토 자동화와 관련된 향후 연구에 대한 가능성을 열어줍니다.



### Leveraging Customer Feedback for Multi-modal Insight Extraction (https://arxiv.org/abs/2410.09999)
Comments:
          NAACL 2024

- **What's New**: 이 논문은 고객 피드백의 이미지와 텍스트 정보를 융합하여 행동 가능한 인사이트를 효과적으로 추출하는 새로운 다중 모달(multi-modal) 접근 방식을 소개합니다.

- **Technical Details**: 제안된 방법은 라테ント 공간(latent space)에서 이미지와 텍스트 정보를 융합하고 이미지-텍스트 기반 텍스트 디코더(image-text grounded text decoder)를 통해 관련 피드백 세그먼트를 추출합니다. 약한 지도 학습(weakly-supervised) 데이터 생성 기법을 활용하여 훈련 데이터를 생성합니다.

- **Performance Highlights**: 제안한 모델은 보지 않은 데이터에 대해 평가되었으며, 기존 기준선(baselines)을 F1 점수에서 14점 초과하여 뛰어난 성능을 보였습니다.



### Learning to Rank for Multiple Retrieval-Augmented Models through Iterative Utility Maximization (https://arxiv.org/abs/2410.09942)
- **What's New**: 이 논문은 여러 개의 Retrieval-Augmented Generation (RAG) 에이전트를 위해 통합 검색 엔진을 설계하는 방법을 제시합니다. 이 검색 엔진은 반복적인 피드백 수집 과정을 통해 각 에이전트의 요구에 최적화됩니다.

- **Technical Details**: 이 새로운 방법론은 expectation-maximization 알고리즘에 기반하여, 각 에이전트의 유틸리티 함수를 극대화하는 것을 목표로 합니다. 오프라인 단계에서는 검색 엔진이 최적의 매개변수를 사용하여 문서를 검색하고, 각 에이전트로부터 피드백을 받아 이를 바탕으로 개선합니다. 또한 온라인 환경에서도 실시간 피드백을 활용하여 검색 결과를 조정합니다.

- **Performance Highlights**: KILT 벤치마크의 다양한 데이터셋에서 실험한 결과, 제안하는 방법이 18개의 RAG 모델에서 평균적으로 기존의 최첨단 방법보다 훨씬 우수한 성능을 보였습니다. 개인화 과정에서 검색 엔진의 성능 또한 향상되었음을 입증하였습니다.



### ViFi-ReID: A Two-Stream Vision-WiFi Multimodal Approach for Person Re-identification (https://arxiv.org/abs/2410.09875)
- **What's New**: 본 연구는 WiFi 신호와 비디오 데이터의 멀티모달(fusion) 접근 방식을 활용하여 사람 재식별(Person Re-identification, ReID)에 대한 혁신적인 해결책을 제시합니다. 기존의 이미지 기반 방법의 한계를 극복하기 위해, 우리는 일반적인 라우터를 감지 장치로 활용하여 보행 정보(gait)를 추출합니다. 이를 통해 다양한 환경에서도 일관된 ReID 성능을 유지할 수 있습니다.

- **Technical Details**: 우리는 두 가지 스트림 네트워크를 활용하여 비디오 이해(video understanding)와 신호 분석(signal analysis) 작업을 별도로 처리하고, 비디오 데이터와 WiFi 데이터를 결합하여 멀티모달 퓨전을 수행합니다. WiFi 신호는 고정 시간 단위로 인코딩되고 영상 모듈에서는 독립적인 공간 및 시간 인코더를 사용하여 보행 모션 특징을 추출합니다. 크로스 모달(cross-modal) 맵핑을 위해 대비 학습(contrastive learning)과 어려운 예제 마이닝(hard example mining) 기반의 손실 함수를 설계하였습니다.

- **Performance Highlights**: 실제 환경에서 실시된 실험을 통해 제안한 방법이 다양한 센서 간의 상관관계를 효과적으로 발견하고, 시각과 신호 모달리티 간의 격차를 줄이며, 감지 범위를 크게 확장하고 ReID 정확도를 개선함을 입증했습니다. 이로 인해, 다양한 환경(단일 모달 및 멀티모달)에서 사람의 ID를 일관되게 추적할 수 있는 가능성을 제시합니다.



### Generating Driving Simulations via Conversation (https://arxiv.org/abs/2410.09829)
Comments:
          6 pages, 6 figures, 2 tables

- **What's New**: 본 논문은 자율주행차의 시뮬레이션 테스트를 위한 자연어 인터페이스를 설계하였습니다. 이 인터페이스는 비코딩(Non-coding) 도메인 전문가는 적절한 시나리오와 차량 행동을 합성하는 데 도움을 줍니다. 인간 실험 결과, 대화가 성공적인 시뮬레이션 생성을 위해 필수적이라는 것을 보여주며, 대화를 통한 성공률이 4.5배 높았습니다.

- **Technical Details**: 이 시스템은 자연어로 작성된 설명을 바탕으로 Scenic 코드를 생성하는 대화 시스템입니다. 사용자가 시뮬레이션 인스턴스에 반응하며 대화하는 방식으로 작동합니다. 이 시스템은 retrieval-augmented generation (RAG) 및 in-context learning을 사용하여 프로그램을 생성합니다. 시뮬레이터에서 생성된 시뮬레이션의 성공 여부에 따라 사용자의 피드백을 받아 출력을 수정합니다.

- **Performance Highlights**: 우리는 자율주행차의 다양한 주행 시나리오에 대한 자연어 설명과 Scenic 프로그램 쌍으로 구성된 데이터 세트를 생성했습니다. 이 데이터 세트를 활용하여 대화 시스템의 정확도를 평가했으며, 대화의 여러 턴을 통한 상호작용이 효과적임을 확인했습니다.



### ContextWIN: Whittle Index Based Mixture-of-Experts Neural Model For Restless Bandits Via Deep RL (https://arxiv.org/abs/2410.09781)
- **What's New**: 이 연구에서는 ContextWIN이라는 새로운 아키텍처를 소개합니다. 이는 Neural Whittle Index Network (NeurWIN) 모델을 확장하여 맥락 인식(Context-aware) 접근 방식을 통해 Restless Multi-Armed Bandit (RMAB) 문제를 해결합니다.

- **Technical Details**: ContextWIN은 강화 학습(Reinforcement Learning) 프레임워크 내에서 전문가 혼합(Mixture of Experts)을 통합하여 동적 환경에서 결정을 내리는 데 필요한 맥락 정보를 효과적으로 활용합니다. 이 모델은 NeurWIN 네트워크의 하위 집합에 맥락별 가중치를 할당하여 각 팔에 대한 Whittle 지수 계산의 효율성과 정확성을 개선합니다. ContextWIN은 NeurWIN 모듈과 통합되어 각 팔에 대한 Whittle 지수를 배워냅니다.

- **Performance Highlights**: 실험 결과, ContextWIN은 다양한 RMAB 시나리오에서 실용적인 효율성을 증명하였으며, 특히 추천 시스템에서의 성능 향상을 보여주었습니다. 연구는 또한 NeurWIN과 ContextWIN 모델 간의 수렴(convergence)을 엄밀히 입증하여 이론적 강건성을 보장합니다.



### Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models (https://arxiv.org/abs/2410.09629)
Comments:
          EMNLP 2024 main conference long paper

- **What's New**: 이번 연구에서는 기존의 지식 습득의 한계를 극복하기 위해, 새로운 합성 지식 습득 방법인 Ski를 제안합니다. 이 방법은 정밀한 합성, 교차 생성, 조립 증대 전략을 활용하여 원천 지식으로부터 고품질 데이터 표현을 구축합니다.

- **Technical Details**: Ski는 Fine-grained Synthesis를 통해 n-gram 지식 맥락 기반의 가상의 질문을 생성하고, Interleaved Generation을 통해 특정 지식에 대한 질문과 답변을 동시 생성합니다. Assemble Augmentation은 다양한 n-gram 범위에서 Fine-grained Synthesis를 조합하여 질문과 답변 쌍을 균형 있게 반복합니다. 이 방식으로 Ski는 LLM의 지식 정제를 효과적으로 지원합니다.

- **Performance Highlights**: Ski는 금융, 생명 의학, 개방 생성 등의 다양한 질문-답변 작업에서 두 개의 오픈 소스 LLM인 Llama2-7B와 Mistral-7B에 대해 실험을 수행하여 기존 방법들보다 상당히 높은 성능을 기록했습니다.



### Toward General Instruction-Following Alignment for Retrieval-Augmented Generation (https://arxiv.org/abs/2410.09584)
Comments:
          Working in progress

- **What's New**: 이 연구에서는 Retrieval-Augmented Generation (RAG) 시스템의 instruction-following (IF) 정렬을 위한 최초의 자동화된, 확장 가능하며 검증 가능한 합성 파이프라인인 VIF-RAG를 제안합니다.

- **Technical Details**: VIF-RAG는 100개 미만의 최소 원자 지침을 수동으로 작성하고, 복잡한 지침을 합성하고 검증하기 위한 조합 규칙을 개발합니다. 감독 모델을 사용하여 지침을 재작성하고, Python 실행기를 통해 지침 품질을 자동으로 검증하는 코드를 생성합니다. 이 과정을 통해 >100k 규모의 고품질 VIF-RAG-QA 데이터셋을 자동으로 생성합니다. 또한 FollowRAG Benchmark를 도입하여 약 3천 개의 테스트 샘플과 22개 범주의 일반 지침 제약과 4개 지식 집약적 QA 데이터셋을 포함합니다.

- **Performance Highlights**: FollowRAG를 사용하여 VIF-RAG가 LLM 성능을 일반 지침 제약의 넓은 범위에서 크게 향상시키는 것을 보여줍니다. 해당 연구는 RAG 시스템에서 IF 정렬을 달성하기 위한 실용적인 통찰력을 제공합니다.



### ACER: Automatic Language Model Context Extension via Retrieva (https://arxiv.org/abs/2410.09141)
- **What's New**: 본 논문에서는 자동화된 데이터 합성 파이프라인(Automatic Data Synthesis Pipeline)을 통해 긴 문맥(long-context) 처리 능력을 향상시키는 새로운 접근 법을 제안합니다. 기존의 모델들이 긴 문맥 처리에서 한계를 보이는 반면, 이와는 달리 짧은 문맥(short-context) 모델을 활용하여 사용자의 질문에 대한 효과적인 긴 문맥 처리를 가능하게 할 수 있는 방안을 모색하고 있습니다.

- **Technical Details**: 제안된 접근법인 ACER(Automates Context Extension via Retrieval)는 두 단계로 구성됩니다: 1) 자동 데이터 합성, 2) 자기 훈련(self-training). 첫 번째 단계에서는 사전 훈련된 짧은 문맥 LM을 이용해 정보 검색(retrieval) 후 불완전한 데이터를 생성하고, 두 번째 단계에서는 이 데이터를 기반으로 긴 문맥 처리 능력을 개선하기 위해 LM을 미세 조정합니다.

- **Performance Highlights**: 실험 결과, ACER로 훈련된 모델은 감독 없이도 기존의 일반적인 긴 문맥 모델들을 초과하는 성능을 보였으며, 실제 테스트 데이터셋에서도 효과적인 긴 문맥 검색 생성(long-context retrieval augmented generation) 작업에서 높은 성과를 거두었습니다.



### $\textit{lucie}$: An Improved Python Package for Loading Datasets from the UCI Machine Learning Repository (https://arxiv.org/abs/2410.09119)
Comments:
          5 pages, 3 figures

- **What's New**: 이번 연구에서는 UCIMLR(University of California--Irvine Machine Learning Repository)에서 많은 데이터셋이 구식 형식으로 저장되어 있어 기존의 ucimlrepo 패키지를 통해 쉽게 가져올 수 없다는 문제를 해결하기 위한 도구인 lucie를 제안합니다. lucie는 자동으로 데이터 형식을 판별하여 이전에 가져올 수 없었던 데이터셋을 가져올 수 있도록 도와줍니다.

- **Technical Details**: lucie는 인기 있는 상위 100개의 데이터셋을 기반으로 설계되었으며, 이후 130개의 추가 데이터셋에서 검증되었습니다. 이 도구는 특정 데이터 형식의 파일을 탐색하고 스크래핑하여 데이터를 pandas 데이터프레임으로 불러오는 데 성공적으로 작동합니다. 기준으로 95.4%의 성공률을 기록했으며, 이는 기존의 ucimlrepo의 73.1%와 비교하여 상당히 높은 성과입니다.

- **Performance Highlights**: lucie는 이전에는 가져올 수 없었던 데이터셋을 손쉽게 다룰 수 있게 만들어줍니다. 또한, 대부분의 데이터셋에서 자주 발생하는 공통적인 패턴을 발견하여 이를 기반으로 데이터 임포트를 일반화하였으며, 링크와 URL 기반의 데이터셋을 자동으로 가져오는 기능을 갖추고 있습니다.



### Personalized Item Representations in Federated Multimodal Recommendation (https://arxiv.org/abs/2410.08478)
Comments:
          12 pages, 4 figures, 5 tables, conference

- **What's New**: 이번 연구에서는 사용자 개인 정보를 보호하면서 멀티모달(item data) 데이터를 활용하기 위해 제안된 새로운 연합 추천 시스템(Federated Multimodal Recommendation System)인 FedMR을 소개합니다.

- **Technical Details**: FedMR은 서버에서 Foundation Model을 사용하여 멀티모달 아이템 데이터를 인코딩하고, 클라이언트에서는 Mixing Feature Fusion Module을 통해 사용자 상호작용 기록을 기반으로 개인화된 아이템 표현을 생성합니다.

- **Performance Highlights**: FedMR은 기존 ID 기반 연합 추천 시스템과 호환되며, 실험을 통해 네 개의 실제 멀티모달 데이터셋에서 효과성을 입증했습니다.



New uploads on arXiv(cs.CV)

### Dual Prototype Evolving for Test-Time Generalization of Vision-Language Models (https://arxiv.org/abs/2410.12790)
Comments:
          Accepted by NeurIPS 2024. Project page: this https URL

- **What's New**: 본 논문은 VLM(visual-language models)에 대한 새로운 test-time adaptation 접근법인 Dual Prototype Evolving (DPE)을 소개합니다. 이 방법은 다양한 다중 모달리티에서의 작업 특정 지식을 효과적으로 축적하며, 각 테스트 샘플의 텍스트 및 비주얼 프로토타입을 진화시킵니다.

- **Technical Details**: DPE는 두 세트의 프로토타입—텍스트(텍스트)와 비주얼(visual)—을 생성하고 진화시켜 테스트 시간 동안 더 정확한 다중 모달 표현을 캡처합니다. 또한 우리는 각 테스트 샘플에 대해 학습 가능한 잔여(residual) 파라미터를 도입하여 일관된 다중 모달 표현을 최적화합니다. DPE는 테스트 시간 동안 임베딩 공간에서의 다중 모달 프로토타입만 최적화하도록 설계되어, 기존의 방법들보다 효율성을 향상시킵니다.

- **Performance Highlights**: DPE는 15개의 다양한 인식 데이터셋에서 테스트 시간 동안 평균 3.55% 및 4.30%의 성능 향상을 보였으며, TPT 및 DiffTPT와 비교하여 각각 5배 및 10배의 테스트 타임 효율성을 달성하였습니다.



### The Curse of Multi-Modalities: Evaluating Hallucinations of Large Multimodal Models across Language, Visual, and Audio (https://arxiv.org/abs/2410.12787)
Comments:
          Project Page: this http URL

- **What's New**: 최근 대규모 다중 모달 모델(large multimodal models, LMMs)의 발전이 다양한 작업에서 성능을 크게 향상시키고 있습니다. 그러나 기존 LMMs는 여전히 환각(hallucinations) 문제에 취약하며, 이는 현실 세계 시나리오에서의 적용 가능성을 제한하고 있습니다.

- **Technical Details**: 이 논문은 LMMs의 환각에 대한 체계적인 조사를 처음으로 수행하였으며, 언어, 시각, 오디오의 세 가지 일반적인 모달리티를 포함합니다. 연구 결과, 환각의 주요 요인은 단일 모달 프라이어(unimodal priors)에 대한 과도한 의존과 유사한 모달리티 간 상관관계(spurious inter-modality correlations)로 나타났습니다. 이를 해결하기 위해 '다중 모달성의 저주(The Curse of Multi-Modalities, CMM)'라는 벤치마크를 도입하여 LMMs의 환각을 종합적으로 평가하였습니다.

- **Performance Highlights**: 연구 결과는 모달리티 통합의 불균형과 훈련 데이터의 편향 등 주요 취약점을 강조하며, 균형 잡힌 교차 모달 학습(cross-modal learning)과 향상된 환각 완화 전략이 필요함을 시사합니다. 이를 바탕으로 LMMs의 신뢰성을 높일 수 있는 연구 방향을 제안합니다.



### Long-LRM: Long-sequence Large Reconstruction Model for Wide-coverage Gaussian Splats (https://arxiv.org/abs/2410.12781)
- **What's New**: Long-LRM은 긴 시퀀스의 입력 이미지로부터 큰 장면을 재구성할 수 있는 범용 3D Gaussian 재구성 모델입니다. 이 모델은 32개의 소스 이미지를 960x540 해상도로 처리할 수 있으며, 단일 A100 80G GPU에서 단 1.3초 만에 실행됩니다.

- **Technical Details**: Long-LRM은 최근의 Mamba2 블록과 전통적인 transformer 블록을 혼합하여 아키텍처를 구성합니다. 이 설계는 더 많은 토큰을 처리할 수 있게 하며, 효율적인 토큰 병합(token merging)과 Gaussian 가지치기(Gaussian pruning) 과정을 통해 품질과 효율성을 균형 있게 조절합니다. 기존의 feed-forward 모델이 1~4개의 입력 이미지만 처리할 수 있는 한계를 극복하여, Long-LRM은 단일 feed-forward 단계에서 전체 장면을 재구성합니다.

- **Performance Highlights**: DL3DV-140 및 Tanks and Temples와 같은 대규모 장면 데이터셋에서, Long-LRM은 최적화 기반 접근 방식에 버금가는 성능을 발휘하며, 효율성 면에서는 두 배 이상 우수한 결과를 보여줍니다.



### Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts (https://arxiv.org/abs/2410.12777)
- **What's New**: 본 논문에서는 확산 모델(Diffusion Models, DMs)에서 유해하거나 저작권이 있는 개념을 효과적으로 '망각'(unlearn)하고자 하는 '메타-망각'(meta-unlearning) 프레임워크를 제안합니다. 이는 모델이 학습된 데이터를 잊고 나서도, 악의적인 파인튜닝(finetuning)을 통해 망각된 개념을 다시 학습하지 않도록 돕습니다.

- **Technical Details**: 메타-망각 프레임워크는 두 가지 주요 요소를 포함합니다: (1) 특정 데이터를 효과적으로 잊도록 하는 표준 망각 목표(unlearning objective)와 (2) 악의적인 파인튜닝 시 망각된 개념의 재학습을 방지하기 위한 메타 목표(meta objective)입니다. 제안된 접근 방법은 기존의 망각 방법과 호환되며, 간단한 메타 목표만 추가하면 됩니다. 실험은 Stable Diffusion 모델(SD-v1-4 및 SDXL)에 대한 다양한 메타-망각 개념의 효과를 검증합니다.

- **Performance Highlights**: 제안된 메타-망각 접근 방식은 학습된 개념들을 안정적으로 망각시키며, 필연적으로 여전히 남아 있는 유관 개념들이 해체(self-destruct)되어 망각된 개념의 재학습을 방지합니다. 다양한 실험과 근거 자료를 통해 메타-망각 프레임워크의 효과가 입증되었습니다.



### Towards Zero-Shot Camera Trap Image Categorization (https://arxiv.org/abs/2410.12769)
- **What's New**: 본 논문은 카메라 트랩 이미지의 자동 분류를 위한 새로운 접근 방식을 탐색합니다. 최신 분류기를 벤치마킹하고 MegaDetector와 Segment Anything을 결합한 다양한 방법을 평가하여 위치별 과적합(overfitting)을 줄이는 데 미치는 영향을 측정했습니다. 또한 DINOv2, BioCLIP, BLIP, ChatGPT와 같은 대형 언어 및 기초 모델을 활용한 제로샷(zero-shot) 접근법을 도입했습니다.

- **Technical Details**: 우리는 세 개의 데이터셋(WCT[1], CCT20[3], CEF)에서 기존의 CNN 및 Transformer 기반 분류 아키텍처를 평가하고 MegaDetector(MD)와 Segment Anything(SAM) 모델을 통해 제로샷 검출 및 분할 성능을 개선하는 방법을 테스트했습니다. 특히, DINOv2와 FAISS를 기반으로 한 제로샷 파이프라인이 뛰어난 결과를 나타냈습니다.

- **Performance Highlights**: MegaDetector와 두 개의 개별 분류기를 결합한 방법이 가장 높은 정확도를 달성했습니다. 이 접근법은 CCT20에서 BEiTV2 분류기의 상대 오류를 약 42%, CEF에서 48%, WCT에서 75% 줄였습니다. 배경을 제거한 후 새로운 위치에서의 오류는 절반으로 줄어들었습니다.



### Gravity-aligned Rotation Averaging with Circular Regression (https://arxiv.org/abs/2410.12763)
Comments:
          accepted at ECCV2024

- **What's New**: 이 논문은 전통적인 Structure-from-Motion(SfM) 방법의 한계를 극복하고자 추가적인 중력 방향 정보를 회전 평균화 단계에 통합하는 새로운 접근법을 제안합니다. 최근 소비자 기기에서 손쉽게 접근할 수 있는 이 정보를 활용하여 카메라 방향 추정의 정확성을 향상시킵니다.

- **Technical Details**: 제안된 알고리즘은 circular regression을 기반으로 하며, 유사한 수렴 보장을 제공하는 linear regression과 유사한 특성을 가지고 있습니다. 이를 통해 회전 평균화 과정에서 발생할 수 있는 2차원 자유도를 줄여 1차원 최적화 문제로 단순화합니다. 또한, 일부 카메라만 중력을 알고 있는 경우에도 효과적으로 적용됩니다.

- **Performance Highlights**: 제안된 방법은 네 개의 대규모 데이터셋에서 최첨단 정확도를 달성하였으며, SfM 기본선 대비 평균 13 AUC@$1^	heta$ 포인트 개선을 보이고, 기존 planar pose graph optimization 기술보다 23 AUC@$1^	heta$ 포인트 더 우수한 성능을 나타냅니다. 이 알고리즘은 8배 더 빠른 속도로 실행됩니다.



### SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And Video Generation (https://arxiv.org/abs/2410.12761)
Comments:
          The first two authors contributed equally; Project page: this https URL

- **What's New**: SAFREE는 최신의 적응형, 훈련 없는 안전한 T2I(텍스트에서 이미지로) 및 T2V(텍스트에서 비디오로) 생성 접근 방식을 제안합니다. 기존의 모델의 가중치를 변경하지 않으면서 유해 콘텐츠를 필터링하는 데 중점을 둡니다.

- **Technical Details**: SAFREE는 텍스트 임베딩 공간에서 유해 개념에 해당하는 하위 공간을 탐지하여 프롬프트 임베딩을 이 하위 공간에서 멀리하는 방식으로 작동합니다. 또한, 동적인 Denoising 단계 조정 및 픽셀 수준에서 유해 개념과 관련된 특징의 영향을 줄이는 적응형 재 주의 메커니즘을 포함합니다.

- **Performance Highlights**: SAFREE는 SOTA(최첨단 기술) 성능을 달성하며, 훈련 없는 기준 모델들에 비해 안전하지 않은 콘텐츠를 억제하는 데 뛰어난 효과를 보이고, 높은 품질의 이미지를 유지하면서도 동시에 다양한 T2I 및 T2V 작업에 유연하게 적용 가능합니다.



### PND-Net: Plant Nutrition Deficiency and Disease Classification using Graph Convolutional Network (https://arxiv.org/abs/2410.12742)
- **What's New**: 본 연구에서는 식물 영양 결핍 및 질병 분류를 위한 새로운 딥러닝 방법인 Plant Nutrition Deficiency and Disease Network (PND-Net)을 제안합니다. 기존의 CNN(Convolutional Neural Network) 기반 모델에 그래프 컨볼루션 네트워크(GCN)를 통합하여 지역 기반 기능 학습을 통해 더 정교한 특징 표현을 개발하였습니다.

- **Technical Details**: PND-Net은 멀티 스케일에서의 지역 기반 기능 요약을 통해 공간 피라미드 풀링(Spatial Pyramidal Pooling)을 활용하여 차별적 기능 표현을 생성합니다. GCN을 통해 식물 질병 및 영양 부족의 미세한 세부정보 학습이 가능해지며, 이 구조는 CNN의 특징에 기반한 그래프 기반 상관관계를 구축하여 입력 데이터의 미세한 설명을 캡처하지 못하는 기존 방법의 한계를 극복합니다.

- **Performance Highlights**: 제안한 PND-Net은 두 개의 영양 결핍 데이터셋과 두 개의 질병 분류 데이터셋에서 평가되었으며, Xception 백본을 사용하여 최고의 분류 성능을 달성하였습니다: (a) 바나나 90.00%, 커피 90.54% 영양 결핍; (b) 감자 질병 96.18%, PlantDoc 데이터셋에서 84.30%. 또한, PND-Net은 다섯 번의 교차 검증을 통해 성능을 개선하였습니다.



### Optimizing 3D Geometry Reconstruction from Implicit Neural Representations (https://arxiv.org/abs/2410.12725)
- **What's New**: 이 논문에서는 3D 도형의 표현에 있어 Implicit Neural Representations (INR)의 한계점을 극복하기 위한 새로운 접근 방식을 제안합니다. 기존의 방법들이 높은 주파수 세부 정보를 유지하는 데 어려움을 겪을 때, 이 방법은 계산 비용을 줄이면서 정교한 세부 사항을 포착할 수 있도록 설계되었습니다.

- **Technical Details**: 이 방법은 주기적 활성화 함수(periodic activation functions), 위치 인코딩(positional encodings), 그리고 노멀(normals)을 신경망 아키텍처에 통합합니다. 이를 통해 3D 도형의 전체 공간을 보다 효과적으로 학습하고, 복잡한 형상의 날카로운 특징을 보존하는 능력이 향상됩니다.

- **Performance Highlights**: 제안된 모델은 DeepSDF에 비해 정량적 및 정성적 비교에서 몇 배의 향상을 이루었으며, 더 큰 모델과 데이터셋으로 확장하는 데 필요한 훈련 시간을 상당히 단축시켰습니다. 실험적으로 다양한 주기적 활성화 함수와 위치 인코딩 방법의 효능을 비교하여, 전체 3D 형상 공간을 학습하는 새로운 연속형 암묵적 신경 표현을 성공적으로 구현하였습니다.



### RAFA-Net: Region Attention Network For Food Items And Agricultural Stress Recognition (https://arxiv.org/abs/2410.12718)
- **What's New**: 이번 연구는 RAFA-Net이라 불리는 지역 주의 메커니즘을 도입하여 식품 및 농업 스트레스 인식의 품질을 높이는 방법을 제안합니다. 이 방법은 다양한 입력 이미지의 여러 영역 간 상관관계를 분석하여 긴 거리를 모델링할 수 있도록 합니다.

- **Technical Details**: RAFA-Net은 부분 특징 설명자(partial feature descriptors)의 유용성을 학습함으로써 피쳐 표현을 향상시키는 지역 주의 메커니즘을 포함합니다. 이 모델은 공간 피라미드 풀링(spatial pyramidal pooling)과 평균 풀링(average pooling)을 사용하여 각 지역 정보를 통합하여 포괄적인 표현을 생성합니다. 컨텍스트 게이팅(context gating) 기법이 사용되어 중요도가 높은 특성의 설명력을 정제합니다.

- **Performance Highlights**: RAFA-Net은 UECFood-100, UECFood-256 및 MAFood-121 데이터셋에서 각각 91.69%, 91.56%, 96.97%의 탑-1 정확도를 기록하며, IP-102 및 PlantDoc-27 데이터셋에서도 92.36%와 85.54%의 정확도를 달성함으로써 기존 방법들을 능가하는 성능을 보여주었습니다.



### Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization (https://arxiv.org/abs/2410.12700)
Comments:
          Accepted by ACM Multimedia 2024. The dataset and code can be found at this https URL

- **What's New**: 이번 연구에서는 인간의 가치와 정렬된 T2I(Text-to-Image) 모델을 위한 경량화된 방법인 LiVO(Lightweight Value Optimization)를 제안합니다. LiVO는 입력 프롬프트와 통합하여 이미지 생성을 제어할 수 있는 플러그 앤 플레이(value encoder) 값을 최적화합니다. 이는 T2I 모델과 인간의 가치 원칙을 효과적으로 연결합니다.

- **Technical Details**: LiVO는 기존 T2I 모델의 매개변수를 업데이트하지 않고도 사용자의 입력에 따라 적합한 가치 원칙을 선택할 수 있게 해줍니다. 이를 통해 생성된 이미지의 의미와 가치를 자연어 지침에 따라 조정할 수 있습니다. 연구팀은 86K 개의 (프롬프트, 정렬 이미지, 위반 이미지, 가치 원칙) 샘플로 이루어진 텍스트-이미지 가치 선호 데이터셋을 자동으로 구축하는 프레임워크를 개발했습니다.

- **Performance Highlights**: LiVO는 최소 20%의 데이터만으로 유해한 콘텐츠를 최대 66%까지 줄일 수 있으며, 여러 강력한 기준선을 초과하는 성능을 보였습니다. 또한, 즉각적인 수렴성을 달성하며 가치 정렬이 향상된 T2I 모델의 개발을 위한 초기 단계로 나아갑니다.



### AdaptiveDrag: Semantic-Driven Dragging on Diffusion-Based Image Editing (https://arxiv.org/abs/2410.12696)
- **What's New**: 본 논문에서는 사용자의 의도에 더욱 부합하는 유연한 점 기반 이미지 편집 방법인 AdaptiveDrag를 제안합니다. 기존 방법의 제한 사항을 극복하기 위해 자동 마스크 생성과 의미 기반 최적화를 활용합니다.

- **Technical Details**: AdaptiveDrag는 SLIC(Superpixel Linear Iterative Clustering)를 사용하여 자동으로 마스크를 생성합니다. 또한, 안착 점(handle points)과 목표 점(target points) 간의 연관성을 위해 대응 손실(corresponding loss) 함수를 도입하여 이미지 생성의 안정성을 높입니다. 이를 통해 사용자는 원하는 드래그 명령을 통해 이미지 편집을 수행할 수 있습니다.

- **Performance Highlights**: 다양한 드래그 명령(예: 크기 조정, 이동, 확장) 및 여러 도메인(예: 동물, 인물 사진, 경관, 의류)에서 실험을 수행한 결과 AdaptiveDrag가 기존 방법들보다 우수한 성능을 보였습니다.



### MultiCamCows2024 -- A Multi-view Image Dataset for AI-driven Holstein-Friesian Cattle Re-Identification on a Working Farm (https://arxiv.org/abs/2410.12695)
Comments:
          26 pages, 10 figures

- **What's New**: MultiCamCows2024 데이터셋을 소개합니다. 이는 다양한 카메라에서 촬영된 유일한 홀스타인-프리지안 소의 생체 인식용 이미지 데이터셋으로, 흑백 이 유전적 패턴을 활용하여 개별 소를 식별합니다.

- **Technical Details**: 3대의 천장 장착 카메라로 7일 동안 촬영한 90마리의 소에 대한 101,329개의 이미지와 CCTV 원본 영상을 포함합니다. 이 데이터셋은 감독(supervised) 및 자가 감독(self-supervised) 학습의 기초가 되는 컴퓨터 비전 인식 방법과 함께 제공됩니다.

- **Performance Highlights**: 단일 이미지 인식 정확도가 96%를 초과하며, 여러 카메라의 데이터를 결합한 학습이 자가 감독 식별의 성능을 향상시킵니다. 우리의 시스템은 완전 자동화된 소 식별을 가능하게 하며, 인간의 데이터 수집 과정에서의 단순한 트랙렛 무결성 확인만 필요로 합니다.



### VividMed: Vision Language Model with Versatile Visual Grounding for Medicin (https://arxiv.org/abs/2410.12694)
- **What's New**: 최신 연구에 따르면, Vision Language Models (VLMs)의 발전은 시각적으로 기반을 둔 응답 생성에서 놀라운 가능성을 보여주고 있습니다. 그러나 의료 분야에서는 특정 도전 과제가 존재합니다. VividMed라는 새로운 모델은 이 문제를 해결하기 위해 다양한 시각적 기반을 제공하고, 2D 및 3D 이미지를 모두 처리할 수 있도록 설계되었습니다.

- **Technical Details**: VividMed는 세 가지 단계의 훈련 과정과 자동 데이터 주석 파이프라인을 통해 학습됩니다. 이 모델은 세분화 마스크와 인스턴스 수준의 경계 상자를 동시에 생성할 수 있으며, Segment Anything Model (SAM)을 기반으로 한 시각적 기반 기능을 통합하여 성능을 향상시킵니다. VividMed는 다양한 의료 영상 모달리티를 처리할 수 있습니다.

- **Performance Highlights**: 실험 결과, VividMed는 기존 VLMs의 시각적 기반 작업에서 우수한 성능을 보이며, Visual Question Answering (VQA) 및 보고서 생성과 같은 일반적인 하위 작업에서도 경쟁력 있는 성과를 나타냈습니다. 시각적 기반 능력을 통합함으로써, VividMed는 다른 하위 작업에서도 성능 향상을 이루었습니다.



### Machine Learning Approach to Brain Tumor Detection and Classification (https://arxiv.org/abs/2410.12692)
Comments:
          7 pages, 2 figures, 2 tables

- **What's New**: 이 연구는 뇌 MRI 이미지에서 뇌 종양을 감지하고 분류하기 위해 다양한 통계 및 머신러닝 모델을 적용하여, 머신러닝 접근법이 의료 분야에서의 조기 진단을 지원할 수 있는지를 보여줍니다.

- **Technical Details**: 연구에서 선형, 로지스틱, 베이esian 회귀와 같은 통계 모델과 결정 트리(decision tree), 랜덤 포레스트(random forest), 단일 층 퍼셉트론(single-layer perceptron), 다층 퍼셉트론(multi-layer perceptron), 합성곱 신경망(convolutional neural network, CNN), 순환 신경망(recurrent neural network), 장단기 메모리(long short-term memory)와 같은 여러 머신러닝 모델을 탐구했습니다.

- **Performance Highlights**: CNN 모델이 다른 모델들보다 우수한 성능을 보여주었으며, 정상, 교모세포종(glioma), 수막종(meningioma), 뇌하수체 종양(pituitary tumor) 등 4개 카테고리의 뇌 MRI 이미지에 대해 다중 클래스 분류가 가능함을 확인했습니다.



### Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2 (https://arxiv.org/abs/2410.12686)
Comments:
          6 pages, 2 figures, 1 table

- **What's New**: 최근 연구에 따르면, Llama-2와 같은 최신 대형 언어 모델(LLMs)은 의료 이미징 도메인에서 해부학적 랜드마크의 위치를 정확하게 나타낼 수 있는 가능성을 보여주고 있습니다. 이 연구는 이러한 모델들이 의료 이미징 워크플로우의 효율성과 정확성을 높일 수 있는 잠재력을 가지고 있다는 점을 강조합니다.

- **Technical Details**: 연구는 Llama-2 모델의 내부 신경 활성화를 선형적으로 조사하여 해부학적 랜드마크의 위치를 예측하는 방식을 사용했습니다. 각 랜드마크에 대한 명칭과 그에 대응하는 공간 좌표를 포함한 데이터세트를 구성하였으며, ridge regression 모델을 통해 위치 예측의 정확성을 평가했습니다. 또한, 비선형 검사를 위해 다층 퍼셉트론(MLP)을 사용하여 결과를 비교했습니다.

- **Performance Highlights**: Llama-2 모델은 다양한 프롬프트에 대해 해부학적 랜드마크를 선형적으로 robust하게 표현할 수 있음을 보여주었습니다. 모델의 성능은 랜드마크 크기 표현에서도 선형성을 나타내었으며, 이는 의료 이미징 보고서에서의 자동화된 해석에 기여할 것으로 기대됩니다.



### MambaBEV: An efficient 3D detection model with Mamba2 (https://arxiv.org/abs/2410.12673)
- **What's New**: 본 논문에서는 mamba2를 기반으로 한 3D 객체 탐지 모델인 MambaBEV를 제안하였습니다. 이 모델은 자율주행 시스템에서의 성능을 높이기 위해 BEV(조감뷰) 패러다임을 활용하여 시간 정보를 통합하는 새로운 접근 방식을 사용합니다.

- **Technical Details**: Mamba2는 구조화된 상태 공간 모델(SSM)을 기초로 하여, 효율적인 훈련 속도와 메모리 사용을 달성합니다. 이 모델은 BEV 피쳐를 통합하기 위한 TemporalMamba라는 시간 융합 모듈과 mamba-CNN 모듈을 사용하여 다양한 프레임에서 BEV 특성을 융합합니다. 디코더 레이어에서는 mamba-cross attention 모듈을 기반으로 한 Mamba-DETR 헤드를 설계하였습니다.

- **Performance Highlights**: 제안된 MambaBEV 모델은 nuScenes 데이터셋에서 51.7% NDS(성능 지표)를 달성하며, 자율주행 시스템에서의 가능성을 보여줍니다. 이 성능은 기존 모델들에 비해 우수한 결과를 나타냅니다.



### 3DIS: Depth-Driven Decoupled Instance Synthesis for Text-to-Image Generation (https://arxiv.org/abs/2410.12669)
Comments:
          10 pages

- **What's New**: 이번 연구에서는 Depth-Driven Decoupled Instance Synthesis (3DIS)라는 새로운 프레임워크를 소개합니다. 3DIS는 multi-instance generation (MIG) 프로세스를 두 가지 단계로 분리하여 인스턴스의 배치와 속성 렌더링 문제를 해결합니다. 이는 텍스트-이미지 생성 기술의 제어 가능한 출력을 요구하는 최근의 추세를 반영하고 있습니다.

- **Technical Details**: 3DIS는 (i) 정밀한 인스턴스 배치 및 장면 구성을 위한 조잡한 장면 깊이 맵을 생성하는 단계와 (ii) 추가 학습 없이 pretrained ControlNet을 사용하여 세밀한 속성을 렌더링하는 단계로 나뉘어 있습니다. 이 프레임워크는 LDM3D와 통합된 사용자 정의 어댑터를 통해 정확한 깊이 기반 레이아웃을 생성합니다.

- **Performance Highlights**: COCO-Position과 COCO-MIG 벤치마크에서 3DIS는 기존 방법보다 레이아웃 정밀도 및 속성 렌더링에서 상당한 성능 향상을 보였습니다. 3DIS는 COCO-Position에서 이전 방법에 비해 16.3%의 AP75 향상을 달성하였고, COCO-MIG에서는 트레이닝 없는 속성 렌더링 접근법이 35%의 Instance Attribute Success Ratio 개선을 기록했습니다.



### Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models (https://arxiv.org/abs/2410.12662)
- **What's New**: 본 연구에서는 Large Vision-Language Models (LVLMs)의 비주얼 입력에 대한 안전 메커니즘의 전이 부족 문제를 다룹니다. 현재의 방법론이 비주얼 모달리티에 대해 안전 메커니즘을 효과적으로 전이하지 못함을 발견하고, Text-Guided vision-language Alignment (TGA)라는 새로운 방법을 제안합니다.

- **Technical Details**: TGA는 입력된 비전과 관련된 텍스트를 검색하여 LLMs의 hidden states 공간으로 비전을 투영하는 데 도움을 줍니다. 이로써 이미지의 hidden states와 텍스트의 hidden states 간의 정렬을 이루게 됩니다. 연구 결과, TGA는 기존 LLMs의 안전 메커니즘을 비전으로 성공적으로 전이할 수 있음을 보여주었습니다.

- **Performance Highlights**: TGA는 안전한 결과를 도출하며, InstructBLip, LLaVA-1.5 및 Qwen-VL-Chat과 같은 기존의 최첨단 LVLM들과 비교할 때 다양한 비전 작업에서 일반 성능을 유지합니다.



### DocLayout-YOLO: Enhancing Document Layout Analysis through Diverse Synthetic Data and Global-to-Local Adaptive Perception (https://arxiv.org/abs/2410.12628)
Comments:
          Github Repo: this https URL

- **What's New**: 본 논문에서는 Document Layout Analysis(DLA, 문서 레이아웃 분석)의 효율성을 개선하기 위해 DocLayout-YOLO라는 새로운 접근 방식을 소개합니다. 이 방법은 텍스트와 비주얼 특성을 활용하여 정확성을 높이고, 문서 특정 최적화를 통해 속도 장점을 유지합니다.

- **Technical Details**: DocLayout-YOLO는 Mesh-candidate BestFit 알고리즘을 적용하여 다양한 문서 레이아웃 데이터셋인 DocSynth-300K을 생성합니다. 이 알고리즘은 문서 합성을 2차원 빈 포장 문제로 설정하여 강력한 사전 학습을 수행합니다. 추가적으로, Global-to-Local Controllable Receptive Module(GL-CRM)을 도입하여 다양한 크기의 문서 요소를 효과적으로 처리하고, 여러 문서 타입에 대한 성능을 검증하기 위한 복잡한 벤치마크인 DocStructBench를 소개합니다.

- **Performance Highlights**: DocLayout-YOLO는 mAP(Mean Average Precision) 점수에서 각각 70.3%, 79.7%, 78.8%를 기록하며, 초당 85.5 프레임(FPS)의 속도로 다양한 문서에 대해 실시간 레이아웃 분석을 가능하게 합니다.



### CMAL: A Novel Cross-Modal Associative Learning Framework for Vision-Language Pre-Training (https://arxiv.org/abs/2410.12595)
Comments:
          vision-language pre-training, contrastive learning, cross-modal, associative learning, associative mapping classification

- **What's New**: 이 논문에서는 Cross-Modal Associative Learning (CMAL)라는 새로운 프레임워크를 제안하여 Vision-Language Pre-training (VLP) 모델이 가지는 비대칭성, 비정상성, 그리고 지역 제한과 같은 한계점을 해결하고자 한다. 이는 앵커 포인트 감지 및 교차 모달 연관 학습을 활용하여 이미지-텍스트 쌍의 표현력을 향상시킬 수 있도록 한다.

- **Technical Details**: CMAL 프레임워크는 비주얼 객체와 텍스트 토큰을 각각 하이퍼스피어 공간에 내장하여 intra-modal hidden features를 학습한 후, 교차 모달 연관 프롬프트 레이어를 설계하여 앵커 포인트 마스킹 및 기능 스와핑을 통해 하이브리드 교차 모달 연관 프롬프트를 구축한다. 이어서 통합된 의미 인코더를 이용해 이들의 교차 모달 상호작용 기능을 학습하고, 마지막으로 연관 매핑 분류 레이어를 통해 앵커 포인트 간의 잠재적 연관 매핑을 학습한다.

- **Performance Highlights**: CMAL은 네 가지 대표적인 V+L 작업에 대한 실험 결과, 이전 CMCL 기반 방법들과 비교하여 경쟁력 있는 성능을 보여주었다. 특히 SNLI-VE와 REC (testA)에서 새로운 최첨단 결과를 기록하였다.



### Cocoon: Robust Multi-Modal Perception with Uncertainty-Aware Sensor Fusion (https://arxiv.org/abs/2410.12592)
Comments:
          23 pages

- **What's New**: Cocoon은 객체 및 기능 수준의 불확실성을 인식하고 이를 기반으로 하는 새로운 융합 프레임워크로, multi-modal 데이터의 다양한 표현 방식을 비교할 수 있게 구현되었습니다. 기존의 MoE 기반 적응형 융합 및 지연 융합 방식의 한계를 극복하는 방향으로 설계되었습니다.

- **Technical Details**: Cocoon은 객체 레벨 및 기능 레벨의 불확실성을 정량화하며, 학습 가능한 서브그라운드 트루스인 Feature Impression을 도입하여 불확실성의 측정을 효과적으로 지원합니다. 이를 통해 서로 다른 모달리티 간의 공정한 비교를 가능하게 하며, 학습 목표를 설정하여 유효한 불확실성 정량화 메트릭을 제공합니다.

- **Performance Highlights**: Cocoon은 nuScenes 데이터셋에서 기존의 정적 및 다른 적응형 방법보다 우수한 결과를 보여주었으며, 특히 카메라 고장과 같은 도전적인 시나리오에서도 베이스 모델의 mAP를 15% 향상시키는 성능을 보였습니다.



### Rethinking Visual Counterfactual Explanations Through Region Constrain (https://arxiv.org/abs/2410.12591)
Comments:
          Preprint

- **What's New**: 이번 논문에서는 Visual Counterfactual Explanations (VCEs)의 한계를 극복하기 위해 지역 제약을 설정하는 방법인 지역 제약 VCEs (RVCEs)를 제안합니다. 기존 방법들이 이미지의 여러 부분을 혼합하여 수정할 때 발생하는 문제를 해결하고자 하며, RVCE는 한정된 지역만 수정하여 모델의 예측에 영향을 미칩니다.

- **Technical Details**: RVCEs는 결정론적 조건부 인페인팅 문제를 해결하는 것으로, 결정자에서 유래한 신호를 기반으로 합니다. 이를 위해 Regional-Constrained Counterfactual Schrödinger Bridges (RCSB)라는 새로운 알고리즘을 도입하며, 이는 이미지 생성 과정에서 효율적이고, 사실적이며, 원본에 가깝게 RVCEs를 합성하는 데 도움을 줍니다.

- **Performance Highlights**: RCSB 방법은 ImageNet 데이터셋에서 기존 방식에 비해 FID에서 최대 4배, sFID에서 3배, COUT에서 2배 더 우수한 성능을 보여줍니다. 이 연구는 RVCEs가 모델의 의사결정을 명확히 이해할 수 있도록 돕고, 사용자가 수동으로 수정 지역을 정의하며 상호작용할 수 있는 기능을 제공합니다.



### FTII-Bench: A Comprehensive Multimodal Benchmark for Flow Text with Image Insertion (https://arxiv.org/abs/2410.12564)
Comments:
          Work in progress. 9 pages, 3 figures

- **What's New**: 대형 비전-언어 모델(LVLMs)의 성능을 종합적으로 평가하기 위해 새로운 도전 과제인 Flow Text with Image Insertion task (FTII)를 제안합니다.

- **Technical Details**: 이 과제는 LVLM이 이미지 이해, 지시 이해, 장문 해석의 뛰어난 능력을 동시에 요구합니다. LVLM은 주어진 텍스트 단락에 적합한 이미지를 후보 이미지 중에서 선택하여 삽입해야 합니다.

- **Performance Highlights**: FTII 작업에서 가장 진화된 모델인 GPT-4o조차도 상당한 도전에 직면하고 있으며, 625개의 고품질 기사를 사용하여 평가한 결과, LVLM의 한계가 드러났습니다.



### Adaptive Prompt Learning with SAM for Few-shot Scanning Probe Microscope Image Segmentation (https://arxiv.org/abs/2410.12562)
Comments:
          10 pages, 7 figures

- **What's New**: 이번 연구에서는 Adaptive Prompt Learning with SAM (APL-SAM)라는 새로운 프레임워크를 제안하여, Scanning Probe Microscope (SPM) 이미지의 few-shot segmentation에 맞춤화된 접근 방식을 제공합니다.

- **Technical Details**: APL-SAM은 두 가지 주요 혁신을 포함합니다. 첫째, Adaptive Prompt Learning 모듈은 제한된 support set에서 파생된 few-shot embeddings를 이용하여 중심 대표를 학습하여 시각적 프롬프트로 활용합니다. 둘째, 여러 출처 및 다단계 마스크 디코더를 도입하여 support 이미지와 query 이미지 간의 대응 관계를 효과적으로 캡처합니다.

- **Performance Highlights**: APL-SAM은 새로 만든 SPM-Seg 데이터셋에서 원본 SAM보다 30% 이상의 Dice Similarity Coefficient 향상을 이루었고, 기존의 최첨단 few-shot segmentation 방식 및 Fully Supervised 접근 방식보다 우수한 성능을 보여줍니다.



### Development of Image Collection Method Using YOLO and Siamese Network (https://arxiv.org/abs/2410.12561)
Comments:
          15 pages, 13 figures, 2 tables

- **What's New**: 본 논문에서는 웹 크롤링(web crawling) 방식의 데이터 수집에서 발생하는 비의도적 데이터 문제를 해결하기 위해 YOLOv10 객체 인식 모델을 사용하고, SIAMese 네트워크를 통해 재분류(image reclassification)를 수행함으로써 성능을 향상시켰음을 보여줍니다.

- **Technical Details**: YOLOv10 모델을 사용하여 웹 크롤링으로 수집된 데이터 중 불필요한 데이터를 필터링하고, SIAMese 네트워크의 거리 출력을 추가적으로 활용하여 이미지 재분류를 진행했습니다. 특히, 사용자들은 거리 임계값(threshold)을 지정하여 데이터 부족(data deficiency)과 잡음 저항성(noise-robustness) 간의 균형을 조절할 수 있습니다.

- **Performance Highlights**: 평균 f1 점수는 YOLO+MobileNet에서 0.678에서 YOLO+SiameseNet으로 0.772로 증가했습니다. 비컷(cropped) 이미지의 사용에 효과적으로 자원을 적게 사용하면서도 성능을 높일 수 있음을 보였으며, non-crop+Siamese(MobileNetV3-Small)에서 80.94가 컷 전처리(crop preprocessing)+Siamese(MobileNetV3-Small)에서 82.31로 상승했습니다.



### Shaping a Stabilized Video by Mitigating Unintended Changes for Concept-Augmented Video Editing (https://arxiv.org/abs/2410.12526)
- **What's New**: 이 논문에서는 개념을 증강한 비디오 편집(concept-augmented video editing) 접근 방식을 제안하여 텍스트 기반 비디오 편집의 유연성을 향상시킵니다. 기존 접근 방식의 한계를 극복하고 보다 세밀한 편집을 가능하게 합니다.

- **Technical Details**: 제안된 프레임워크는 개념 증강 텍스트 변환(concept-augmented textual inversion)과 이중 사전 감독 메커니즘(dual prior supervision mechanism)을 포함합니다. 이를 통해 비디오 편집을 위한 안정적인 확산(stable diffusion)의 플러그 앤 플레이(plug-and-play) 안내가 가능해지며, 태그 속성을 보다 잘 포착할 수 있습니다.

- **Performance Highlights**: 이 접근 방식은 더 안정적이고 생동감 있는 비디오를 생성하며, 기존의 최첨단 방법(state-of-the-art methods)을 초월하는 성능을 보여줍니다.



### MambaPainter: Neural Stroke-Based Rendering in a Single Step (https://arxiv.org/abs/2410.12524)
Comments:
          Accepted to SIGGRAPH Asia 2024 posters

- **What's New**: 이번 연구에서는 MambaPainter를 제안하여 단일 추론 단계에서 100개 이상의 브러시 스트로크(brush strokes)를 예측할 수 있게 되어 번역 속도를 크게 개선했습니다.

- **Technical Details**: MambaPainter는 선택적 상태 공간 모델(selective state-space model)을 도입하여 브러시 스트로크의 시퀀스를 예측하는 기술을 활용합니다. 또한 패치 기반 렌더링(patch-based rendering)에 대한 간단한 확장을 통해 고해상도 이미지를 변환할 수 있도록 하여 시각적 품질을 향상시킵니다.

- **Performance Highlights**: 실험 결과, MambaPainter는 최첨단(state-of-the-art) 방법들과 비교했을 때 입력을 오일 페인팅 스타일의 이미지로 효율적으로 변환할 수 있음을 보여주었습니다.



### QueensCAMP: an RGB-D dataset for robust Visual SLAM (https://arxiv.org/abs/2410.12520)
Comments:
          6 pages

- **What's New**: 이번 논문은 VSLAM의 강건성을 평가하기 위해 설계된 새로운 RGB-D 데이터셋을 소개합니다. 이 데이터셋은 동적 객체, 모션 블러(motion blur), 다양한 조명 조건을 포함한 실제 실내 장면으로 구성되어 있으며, 렌즈 오염(lens dirt), 응습(condensation), 과소 노출(underexposure), 과다 노출(overexposure)과 같은 카메라 고장도 시뮬레이션합니다.

- **Technical Details**: 이 데이터셋은 Vicon 모션 캡처 시스템을 사용하여 수집되었으며, 30Hz의 정확한 6DoF 위치 측정을 제공합니다. RGB 이미지는 1920x1080 해상도, 깊이 이미지는 640x480 해상도로 수집되어 있습니다. 1616개 시퀀스에서 총 28523 이미지를 캡처했으며, 고장 유도에 대한 추가 시퀀스도 포함되어 있습니다. 고장은 시뮬레이션을 통해 생성되며, 공개된 오픈 소스 스크립트를 통해 연구 커뮤니티가 커스터마이즈할 수 있도록 제공됩니다.

- **Performance Highlights**: 실험 결과, 전통적인 VSLAM 알고리즘인 ORB-SLAM2와 딥러닝 기반 VO 알고리즘인 TartanVO가 이러한 도전적인 조건에서 성능 저하를 겪음을 보여줍니다. 이는 생성된 데이터셋과 카메라 고장 도구들이 더 강건한 VSLAM 시스템 개발에 유용한 자원이 됨을 시사합니다.



### DH-VTON: Deep Text-Driven Virtual Try-On via Hybrid Attention Learning (https://arxiv.org/abs/2410.12501)
Comments:
          5 pages, 6 figures, ICASSP2025

- **What's New**: DH-VTON이라는 새로운 가상 착용(Virtual Try-ON) 모델을 제안합니다. 이 모델은 하이브리드 주의 학습 전략(hybrid attention learning strategy)과 깊은 의류 의미 보존 모듈(deep garment semantic preservation module)을 특징으로 합니다.

- **Technical Details**: 해당 모델은 InternViT-6B를 사용하여 깊이 있는 의류의 세부 특징을 학습하고, Garment-Feature ControlNet Plus (GFC+) 모듈을 통해 의류의 다양한 특성을 VTON 모델의 여러 층에 통합합니다. 이로 인해 다중 스케일 기능 보존(multi-scale features preservation) 효과를 달성할 수 있습니다.

- **Performance Highlights**: 다양한 대표 데이터셋에 대한 실험에서 DH-VTON은 기존의 diffusion 기반 및 GAN 기반 접근 방식보다 뛰어난 성능을 보여주며, 의류의 세부 사항을 잘 보존하고 사실적인 인간 이미지를 생성하는 데 경쟁력을 갖추고 있습니다.



### Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspectiv (https://arxiv.org/abs/2410.12490)
Comments:
          Accepted at NeurIPS 2024

- **What's New**: 최근 Latent Diffusion Models (LDMs)와 Mask Image Models (MIMs)와 같은 latent 기반 이미지 생성 모델이 이미지 생성 작업에서 뛰어난 성과를 거두었습니다. 그러나 autoregressive 모델이 LDMs와 MIMs에 비해 이미지 생성에서 상당히 뒤처져 있다는 흥미로운 관찰이 있었습니다. 이 발견은 NLP 분야와의 뚜렷한 대조를 이룹니다.

- **Technical Details**: 저자들은 이미지 생성 모델링에서 latent space의 안정성을 강조하며, 이를 위해 간단하지만 효과적인 이산 이미지 토크나이저(Tokenizer)를 제안하였습니다. 이 토크나이저(DiGIT)를 사용한 이미지 autoregressive 모델링은 이미지 이해 및 생성 과정에서 이점을 보여주었으며, 이는 기본적으로 GPT 모델에 대해 간단한 원칙입니다.

- **Performance Highlights**: 처음으로, GPT 스타일의 autoregressive 모델이 LDMs를 초월하는 성능을 보여주었으며, 모델 크기를 늘림에 따라 GPT와 유사한 상당한 개선을 또한 보여주었습니다. 이 결과는 최적화된 latent space와 이산 토큰화의 통합이 이미지 생성 모델의 능력을 향상할 수 있는 잠재력을 강조합니다.



### Synthetic Augmentation for Anatomical Landmark Localization using DDPMs (https://arxiv.org/abs/2410.12489)
- **What's New**: 이 연구에서는 Denoising Diffusion Probabilistic Models (DDPMs)를 활용하여 의료 이미지를 생성하고, 해당 이미지를 통해 Anatomy Landmark Localization (ALL) 모델의 훈련을 개선하는 새로운 접근 방식을 탐구합니다.

- **Technical Details**: DDPM은 2채널 입력을 사용하여 원본 의료 이미지와 주석이 달린 랜드마크의 Heatmap을 통합합니다. 또한, 랜드마크 매칭을 위해 Markov Random Field (MRF) 모델을 사용하고, 랜드마크의 가능성을 검증하기 위해 Statistical Shape Model (SSM)을 도입합니다.

- **Performance Highlights**: 손 X-Ray를 포함하는 ALL 작업에서 DDPM으로 증강된 데이터셋이 기존 방법들과 비교해 성능 개선을 보일 것으로 예상됩니다.



### Mind the Gap Between Prototypes and Images in Cross-domain Finetuning (https://arxiv.org/abs/2410.12474)
- **What's New**: 교차 도메인 몇 샷 분류(Cross-Domain Few-Shot Classification) 분야에서 새로운 접근 방식을 제안합니다. 이 방식은 프로토타입과 이미지 인스턴스의 임베딩 간의 변환 차이를 줄이고, 최적의 표현 탐색을 용이하게 합니다.

- **Technical Details**: 본 논문에서는 프로토타입과 이미지 인스턴스의 임베딩이 동일한 표현 변환을 공유한다는 기존 가정이 틀렸음을 발견했습니다. 이를 해결하기 위해, contrastive prototype-image adaptation (CoPA) 방법을 제안하며, 이는 CLIP와 유사하게 프로토타입을 텍스트 프롬프트로 취급하여 각각 다른 변환을 적용합니다.

- **Performance Highlights**: Meta-Dataset에서 수행된 실험에 따르면, CoPA는 효율적으로 최신 성능(state-of-the-art performance)을 달성했으며, 더 나은 표현 클러스터를 학습하고, 갭(gap)을 확대하여 최소 검증 손실(minimal validation loss)을 달성했습니다.



### Beyond Coarse-Grained Matching in Video-Text Retrieva (https://arxiv.org/abs/2410.12407)
Comments:
          Accepted to ACCV 2024

- **What's New**: 비디오-텍스트 검색(video-text retrieval)에 대한 새로운 접근 방식이 제시되었습니다. 특히, 기존 데이터셋에 대해 미세하게 변형된 하드 네거티브 테스트 캡션을 자동으로 생성하는 방법을 도입하였습니다.

- **Technical Details**: 제안된 방법은 네 개의 시각적으로 최신(state-of-the-art) 모델을 사용하여 두 개의 표준 벤치마크(MSR-VTT, VATEX)와 두 개의 상세한 설명이 포함된 특별 데이터셋(VLN-UVO, VLN-OOPS)에서 실험을 수행합니다. 모델의 미세한 단어 차이를 인식하는 능력을 검증하기 위해 기본적인 기준을 제안하였습니다.

- **Performance Highlights**: 전반적인 결과, 현재 평가 벤치마크가 모델이 미세 단어 차이를 감지하는 데 부족하다는 점과, 모델들이 이러한 미세한 변화를 구별하는 데 어려움을 겪는다는 점을 발견하였습니다. 제안된 미세 평가 방법은 모델의 미세한 이해 능력을 향상시키는 데 효과적임이 입증되었습니다.



### Feature Augmentation for Self-supervised Contrastive Learning: A Closer Look (https://arxiv.org/abs/2410.12396)
Comments:
          IJCNN 2024

- **What's New**: 이번 연구에서는 data augmentation (데이터 증강) 접근 방식의 한계를 극복하기 위해 feature augmentation (특징 증강)이라는 새로운 방법론을 제안합니다. 이는 데이터를 원래 입력 공간이 아닌 특징 공간에서 증강하여 일반화 및 견고성을 향상시키는 통합 프레임워크를 제공합니다.

- **Technical Details**: 특징 증강은 주어진 인스턴스의 다양한 뷰를 통해 대조 쌍을 구성하며, 이는 self-supervised contrastive learning (자기 감독 대조 학습)에서 더 나은 전이 성능을 달성하는 데 도움을 줍니다. 기존의 데이터 증강 전략의 한계로 도메인 의존성, 작업 편향, 유연성 부족 등이 있으며, 특징 증강은 이러한 문제를 개선합니다.

- **Performance Highlights**: 제안된 특징 증강 프레임워크는 instance discrimination (인스턴스 분별) 및 instance similarity (인스턴스 유사성) 프레임워크와 통합됨으로써, 이미지 분류 및 객체 탐지 작업에서 일관된 성능 향상을 보여줍니다. 이로써 모델의 일반화와 견고성이 개선됩니다.



### Real-time Stereo-based 3D Object Detection for Streaming Perception (https://arxiv.org/abs/2410.12394)
Comments:
          Streaming Perception, 3D Object Detection, NeurIPS2024 poster

- **What's New**: 새로운 작업인 streaming perception이 도입되었습니다. 이는 비디오 온라인 인식(video online perception)에서 레이턴시(latency)와 정확성(accuracy)을 단일 메트릭으로 평가합니다.

- **Technical Details**: StreamDSGN은 streaming perception을 위해 설계된 첫 번째 실시간 stereo 기반 3D 객체 탐지(framework) 프레임워크입니다. 이 프레임워크는 과거 정보를 활용하여 다음 순간의 객체 3D 속성을 직접 예측하고, accuracy degradation을 완화합니다. 세 가지 전략을 통해 인식 정확도를 향상시킵니다: (1) feature-flow 기반 융합 방법, (2) 연속 프레임에서 객체 움직임 일관성(motion consistency)을 명시적으로 감독하는 추가 회귀 손실(extra regression loss), (3) 긴 범위의 공간적 컨텍스트(contextual features)를 효과적으로 캡처하는 대형 커널(backbone) 사용.

- **Performance Highlights**: KITTI Tracking 데이터셋 실험 결과, 강력한 baseline과 비교하여 StreamDSGN은 streaming average precision을 최대 4.33% 향상시켰습니다.



### HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks (https://arxiv.org/abs/2410.12381)
Comments:
          homepage this https URL

- **What's New**: 본 논문에서는 LLMs(대형 언어 모델)의 시각적 이해 및 추론 능력을 평가하기 위해 특별히 설계된 새로운 벤치마크인 HumanEval-V를 소개합니다. 이는 기존의 코딩 작업을 기반으로 하여, 고도로 세심하게 제작된 108개의 Python 코딩 과제를 포함합니다.

- **Technical Details**: HumanEval-V는 CodeForces 및 Stack Overflow와 같은 플랫폼에서 유래된 문제들을 바탕으로 각 과제를 수정하여, 문제의 맥락과 알고리즘 패턴을 변화시켰습니다. 각 과제는 제공된 시각적 컨텍스트와 특정 Python 함수 서명을 기반으로 해결되어야 하며, 모델이 생성한 솔루션의 철저하고 신뢰할 수 있는 평가를 보장하기 위해 정교하게 제작된 테스트 케이스가 부여됩니다.

- **Performance Highlights**: 19개의 최첨단 LMM들을 HumanEval-V를 사용해 평가한 결과, GPT-4o와 같은 독점 모델은 13%의 pass@1과 36.4%의 pass@10만을 달성하는 등 상당한 도전 과제가 드러났습니다. 70B 파라미터를 가진 오픈 웨이트 모델은 pass@1 기준으로 4% 미만의 점수를 기록했습니다. 이러한 결과는 현재 LMM의 시각적 추론 및 코딩 능력의 한계를 강조하며, 향후 연구의 주요 영역을 제시합니다.



### Stylistic Multi-Task Analysis of Ukiyo-e Woodblock Prints (https://arxiv.org/abs/2410.12379)
- **What's New**: 이 논문에서는 대규모 	extit{Ukiyo-e} (우키요에) 목판화 데이터셋을 제시합니다. 기존 서양 예술 중심의 데이터셋과 달리 일본의 전통 예술 형태를 탐구하여 예술적 스타일 분석의 범위를 넓히고 다양한 예술 중심 Computer Vision 접근법을 평가하기 위한 기준을 제공하는 것을 목표로 합니다.

- **Technical Details**: 우리의 데이터셋은 17세기부터 현재까지의 예술가(artist), 시대(era), 제작 날짜(creation date) 등의 메타데이터가 포함된 175,000개 이상의 인쇄물로 구성됩니다. 우리는 스타일 분석을 Multi-Task 문제로 접근하여 이용 가능한 메타데이터를 더 효율적으로 활용하고 스타일에 대한 보다 일반적인 표현을 학습하려고 합니다.

- **Performance Highlights**: 잘 알려진 기준선(baselines) 및 최첨단 멀티태스킹 학습 프레임워크에 대한 결과를 보여주어 향후 비교를 가능케 하고, 이 예술 영역에서의 스타일 분석을 장려하고자 합니다.



### GAN Based Top-Down View Synthesis in Reinforcement Learning Environments (https://arxiv.org/abs/2410.12372)
- **What's New**: 이 논문은 강화 학습(RL) 환경에서 인공 에이전트의 1인칭 관찰을 바탕으로 Generative Adversarial Network(GAN)를 이용하여 top-down view를 학습하는 방법을 탐구합니다.

- **Technical Details**: 기존의 작업들은 주로 에이전트의 행동을 통해 환경의 공간적 및 시간적 특성을 학습했습니다. 본 연구는 에이전트가 환경을 탐험함에 따라 부분적인 top-down view를 생성하고, 전체 환경을 맵핑할 수 있는 방식을 제안합니다. 특히, 3D 합성곱(Convolutions)과 Capsule Encoders의 사용은 공간적 및 시간적 정보를 효과적으로 캡처하는 데 기여합니다.

- **Performance Highlights**: 실험 결과, proposed models (3D convolutions, Capsule Encoders) 는 RL 환경에서 보이지 않는 spatio-temporal 장면의 완전한 표현을 해결하는 데 중요한 진전을 이루었습니다. 이 top-down view는 에이전트가 더 나은 정책 결정을 내리는 데 도움을 줄 수 있으며, 에이전트의 결정 과정을 향상시키는 데 사용될 수 있습니다.



### Context-Infused Visual Grounding for Ar (https://arxiv.org/abs/2410.12369)
- **What's New**: 이번 연구는 CIGAr (Context-Infused GroundingDINO for Art)라는 새로운 비주얼 그라운딩 접근 방식을 소개합니다. 이는 예술 작품의 설명을 학습 중 맥락(context)으로 활용하여 비주얼 그라운딩을 가능하게 하고, Ukiyo-eVG라는 새로운 데이터셋을 발표하여 예술 작품 데이터셋에서 객체 탐지의 최신 기술 성과를 달성했습니다.

- **Technical Details**: CIGAr는 Transform 기반의 비주얼 그라운딩 모델을 사용하여 예술 작품 이미지의 비주얼 요소를 텍스트 쿼리와 정렬합니다. 이는 Visual Grounding (VG) 모델을 통해 구현되며, 데이터 학습 시 제목과 설명이 포함되어 특히 예술 분야에서 관련 특징들을 학습할 수 있도록 돕습니다.

- **Performance Highlights**: IconArt 및 ArtDL 예술 작품 데이터셋에서 객체 탐지에 대한 새로운 최신 기술 성과를 달성했습니다. 또한, Ukiyo-eVG 데이터셋을 통해 최초의 예술 작품 비주얼 그라운딩 데이터셋을 개발하였습니다.



### Towards Flexible and Efficient Diffusion Low Light Enhancer (https://arxiv.org/abs/2410.12346)
Comments:
          7 pages

- **What's New**: 본 논문에서는 저조도 이미지 향상(Low-Light Image Enhancement, LLIE)을 위한 새로운 방식으로, 반사 인식 확산(Reflectance-aware Diffusion)과 증류 경로(Distilled Trajectory)를 결합한 ReDDiT 프레임워크를 제안합니다. 이 방법은 기존의 다단계 교사 모델의 성능에 필적하면서도 훨씬 효율적인 학생 모델을 생성합니다.

- **Technical Details**: ReDDiT 프레임워크는 교사 모델의 경로를 더 적은 단계에서 학생 모델이 복제하도록 훈련하며, 학생 모델이 교사 모델의 성능을 초월할 수 있는 기능을 포함합니다. 이를 위해, 교사 모델의 경로 디코더와 반사 인식 경로 정제 모듈(reflectance-aware trajectory refinement module)을 도입하여 교사 모델의 경로에서 결정론적(guided) 안내를 가능하게 합니다.

- **Performance Highlights**: ReDDiT는 2단계에서 기존의 10단계 확산 방식의 성능과 견줄 만한 결과를 보여주며, 심지어 4단계 및 8단계 모델에서는 새로운 최첨단(SOTA) 성능을 달성했습니다. 10개의 벤치마크 데이터셋에서 실행된 종합적인 실험 결과, ReDDiT는 기존 SOTA 방법들보다 일관되게 우수한 성능을 입증하였습니다.



### TAS: Distilling Arbitrary Teacher and Student via a Hybrid Assistan (https://arxiv.org/abs/2410.12342)
Comments:
          18 pages, 6 figures, and 12 tables

- **What's New**: 이번 연구는 전통적인 Teacher-Student 아키텍처에 의존하지 않고, Cross-Architecture Knowledge Distillation (CAKD) 접근 방식을 통해 동종 및 이종 모델 간의 지식 전이를 유연하게 수행하는 방법을 제안합니다.

- **Technical Details**: 이 연구는 heterogeneous teacher와 student 간의 특징 전이를 원활하게 하기 위한 보조 모델(assistant model)을 introduce하며, convolution과 attention 모듈을 결합하여 서로 다른 아키텍처의 이점들을 통합합니다. 또한 InfoNCE loss를 통해 특징의 spatial alignment를 개선하여 성능을 향상시킵니다.

- **Performance Highlights**: 제안된 CAKD 방법은 CNN, ViT, MLP 모델의 다양한 조합에서 평가되었으며, CIFAR-100에서 최대 11.47% 향상된 성능과 ImageNet-1K에서 3.67%의 성능 향상을 달성하여, state-of-the-art 성능을 기록했습니다.



### ARIC: An Activity Recognition Dataset in Classroom Surveillance Images (https://arxiv.org/abs/2410.12337)
Comments:
          arXiv admin note: text overlap with arXiv:2409.03354

- **What's New**: AI + Education 분야에서 활동 인식의 중요성이 증가하고 있습니다. 하지만 기존 연구는 주로 수동으로 촬영된 비디오의 활동 인식에 집중하고 있으며, 실제 교실의 감시 이미지에서 활동 인식에는 거의 관심이 없었습니다. 본 논문에서는 교실 감시 이미지에서의 활동 인식을 위한 새로운 멀티모달 데이터셋인 ARIC를 구축하였습니다.

- **Technical Details**: ARIC 데이터셋은 32개의 활동 카테고리, 세 가지 모달리티(modalities), 실제 교실 시나리오에 중점을 두고 있습니다. 이 데이터셋은 클래스 불균형(class imbalance) 및 높은 활동 유사성(high activity similarity) 등의 문제를 해결하기 위한 연구를 위한 기초 자료가 될 것입니다. 또한, 일반적인 활동 인식 작업 외에도 지속적 학습(continual learning) 및 소수 샷 지속적 학습(few-shot continual learning)을 위한 설정도 제공합니다.

- **Performance Highlights**: ARIC 데이터셋은 다양한 관점(multiple perspectives)에서 활동을 인식할 수 있는 장점을 가지고 있습니다. 이를 통해 Open Teaching 시나리오를 위한 미래의 분석 및 연구에 기여할 수 있기를 기대합니다.



### MC-Bench: A Benchmark for Multi-Context Visual Grounding in the Era of MLLMs (https://arxiv.org/abs/2410.12332)
- **What's New**: 이 논문은 다중모달 대형 언어 모델(MLLMs)에 대한 새로운 시각적 기반 작업인 multi-context visual grounding을 제안하며, 이는 여러 이미지에서 관심 있는 인스턴스를 텍스트 프롬프트에 기반하여 로컬라이즈하는 것을 목표로 합니다.

- **Technical Details**: 연구를 지원하기 위해 MC-Bench라는 새로운 데이터셋을 구성하였으며, 이는 2K개의 고품질 수작업 주석 샘플로 이루어져 있습니다. 데이터셋은 인스턴스 수준으로 레이블이 지정된 이미지 쌍과 이미지 내 타겟 인스턴스를 나타내는 텍스트 프롬프트를 포함합니다. 총 20가지 실용 기술을 포괄하는 세 가지 서로 다른 스타일의 텍스트 프롬프트가 특징입니다.

- **Performance Highlights**: 20개 이상의 최신 MLLM과 기본 모델의 성능을 벤치마킹한 결과, 모든 지표에서 기존 MLLMs과 인간 간의 성능 차이가 크다는 것을 발견하였습니다. 또한, 기존 MLLMs는 LLM이 없는 기본 모델보다 이미지 수준의 지표에서만 우수하며, 전문 MLLMs는 단일 이미지에 대해 훈련될 경우 다중 이미지 상황에 일반화하는 데 어려움을 겪습니다. 이전의 end-to-end MLLMs을 초월하는 형태로 고급 MLLM과 탐지기를 통합한 간단한 단계적 기준선이 눈에 띄는 성과를 보였습니다.



### FaceChain-FACT: Face Adapter with Decoupled Training for Identity-preserved Personalization (https://arxiv.org/abs/2410.12312)
Comments:
          12 pages, 8 figures

- **What's New**: 본 논문은 인물 식별 기능의 분리와 발전된 이미지 생성 방법을 제안한 Face Adapter with deCoupled Training (FACT) 프레임워크를 제시합니다. 이를 통해 텍스트-이미지 모델에서 인물의 정체성을 보존하면서도 정확도와 다양성을 높입니다.

- **Technical Details**: FACT는 transformer 기반의 얼굴 인식 모델을 통해 세분화된 정체성 기능을 활용하였으며, Gated Self-Attention (GSA) 모듈을 U-Net에 삽입해 얼굴 특징에 개별적으로 적응하도록 만들었습니다. 이를 통해 얼굴 영역에서의 변화를 제어하고, FAce Adapting Increment Regularization (FAIR) 기법을 통해 면밀한 조정을 압박합니다.

- **Performance Highlights**: 실험 결과, FACT는 기존의 adapter 기반 개인화 방법에 비해 아이덴티티 유사도, 텍스트 따른 생성 능력, 얼굴의 통제력 및 다양성에서 향상된 성능을 보였습니다. 또한, FACT는 LORA나 ControlNet 같은 기존의 세분화 모델과의 통합에서도 생성 성능을 저하시키지 않습니다.



### Controlled Automatic Task-Specific Synthetic Data Generation for Hallucination Detection (https://arxiv.org/abs/2410.12278)
- **What's New**: 이 논문에서는 환각 감지를 위한 비트리비얼(task-specific) 합성 데이터세트를 자동으로 생성하는 새로운 접근 방식을 제안합니다. 이 방법은 두 단계의 생성-선택 파이프라인을 특징으로 하며, 환각 패턴 지침(hallucination pattern guidance) 및 언어 스타일 정렬(language style alignment)을 활용하여 데이터 품질을 향상시킵니다.

- **Technical Details**: 제안된 방법은 자동화된 생성-선택 파이프라인을 기반으로 하며, 환각 패턴 가이드를 통해 특정 작업에 적합한 환각 샘플을 생성하고, 언어 스타일 정렬을 통해 합성 데이터의 스타일을 벤치마크 텍스트와 일치시킵니다. 이 방법은 세 가지 대화 벤치마크에서 실험을 통해 검증되었으며, F1 점수 0.938을 달성하여 기존의 인컨텍스트러닝(ICL) 기반 감지기를 32.5%의 큰 차이로 초과했습니다.

- **Performance Highlights**: 제안된 환각 감지기는 생성된 합성 데이터세트를 통해 훈련된 결과, 상기된 세 가지 차원에서 뛰어난 일반화 능력을 보여주었습니다. 또한, 생성된 합성 환각이 실제 비환각 샘플에 더 유사함을 입증하였으며, 이는 우리 접근 방식의 강력한 일반화 능력을 확인하였습니다.



### Fusion from Decomposition: A Self-Supervised Approach for Image Fusion and Beyond (https://arxiv.org/abs/2410.12274)
Comments:
          18page

- **What's New**: 본 논문에서는 self-supervised learning (SSL)을 활용하여 다양한 이미지 융합 작업을 위한 특성 표현의 다재다능성을 높이는 새로운 프레임워크인 DeFusion++를 소개합니다. 이 프레임워크는 큰 규모의 데이터에서 이미지 융합 작업에 적합한 표현을 효과적으로 캡처합니다.

- **Technical Details**: DeFusion++는 두 가지 혁신적인 사전 텍스트 작업인 common and unique decomposition (CUD)와 masked feature modeling (MFM)을 도입합니다. CUD는 소스 이미지를 일반적이고 독특한 구성 요소로 분해하며, MFM은 이러한 구성 요소를 견고한 융합 특성으로 정제합니다. 이 두 작업의 공동 훈련을 통해 DeFusion++는 다양한 소스 이미지로부터 유용한 정보를 효과적으로 추출할 수 있는 적응 가능한 표현을 생성합니다.

- **Performance Highlights**: DeFusion++는 이미지 융합 품질 및 단계적 고수준 비전 작업의 효율성을 높이는 다재다능한 융합 표현을 생성하며, 이미지 분할 및 객체 탐지와 같은 다양한 다운스트림 작업에 적용 가능합니다. 이 방법은 정량적 및 정성적 결과 모두에서 효과성을 입증했습니다.



### DaDiff: Domain-aware Diffusion Model for Nighttime UAV Tracking (https://arxiv.org/abs/2410.12270)
- **What's New**: 이번 연구는 저조도 환경에서의 드론(UAV) 추적을 위한 새로운 도메인 인식 디퓨전 모델(DaDiff)을 제안합니다. 이 모델은 야간 저해상도(LR) 물체의 특성을 낮 동안의 특성과 일치시키기 위해 점진적인 정렬 방식을 사용합니다.

- **Technical Details**: DaDiff는 특성 정보를 향상시키기 위한 alignment encoder, 추적 작업과의 밀접한 협업을 위한 tracking-oriented layer, 각 디퓨전 타임스텝에서의 다양한 특성 분포를 구분하는 successive distribution discriminator를 포함합니다. 이러한 구성 요소들은 특성 일치의 안정성을 높이고 LR 물체의 세부 정보를 강화하는데 기여합니다.

- **Performance Highlights**: DaDiff는 100개의 주석 처리된 시퀀스로 구성된 NUT-LR 벤치마크에서 평가되었으며, 강력한 특성 정렬 능력과 견고한 성능을 입증했습니다. 이 결과는 기존의 일 단계 적응 패러다임 대비 UA 추적 성능을 현저히 향상시킨 것을 보여줍니다.



### LoD-Loc: Aerial Visual Localization using LoD 3D Map with Neural Wireframe Alignmen (https://arxiv.org/abs/2410.12269)
Comments:
          Accepted by NeurIPS 2024; for Project page, see this https URL

- **What's New**: LoD-Loc이라는 새로운 방법을 제안하며, 기존의 복잡한 3D 표현을 사용하지 않고도 UAV의 위치를 추정할 수 있습니다.

- **Technical Details**: LoD-Loc은 주어진 UAV 센서에 의해 제공된 coarse pose를 바탕으로 포즈 가설을 균일하게 샘플링하여 포즈 확률 분포를 설명하는 cost volume을 계층적으로 구축합니다. 각 cost는 투영된 wireframe과 예측된 wireframe 간의 정렬 정도를 측정합니다. 6-DoF pose 최적화 알고리즘을 사용하여 이전 결과를 더욱 정교하게 다듬습니다.

- **Performance Highlights**: LoD-Loc은 LoD3.0 및 LoD2.0 맵 수준의 두 개의 데이터셋을 수집하고, 텍스처가 있는 3D 모델을 사용하는 기존 최첨단 방법들을 초월하는 뛰어난 성능을 자랑합니다.



### Optimizing YOLOv5s Object Detection through Knowledge Distillation algorithm (https://arxiv.org/abs/2410.12259)
- **What's New**: 이 논문은 target detection(타겟 탐지) 작업에서 knowledge distillation(지식 증류) 기술의 적용을 탐구하며, 학생 모델의 성능에 미치는 다양한 distillation temperature(증류 온도)의 영향을 분석합니다.

- **Technical Details**: YOLOv5l을 teacher network(교사 네트워크)으로, 더 작은 YOLOv5s를 student network(학생 네트워크)으로 사용하여, distillation temperature가 증가함에 따라 학생의 탐지 정확도가 점진적으로 향상됨을 발견했습니다. 이는 특정 온도에서 원래 YOLOv5s 모델보다 더 나은 mAP50 및 mAP50-95 지표를 달성했습니다. 또한, 모델 훈련 과정에서 정확도 커브(accuracy curve)와 손실 함수 하강 커브(loss function descent curve)를 자세히 기록하였고, 모델은 150회 훈련 후 안정적인 상태로 수렴함을 보여줍니다.

- **Performance Highlights**: 적절한 knowledge distillation 전략이 모델의 정확도를 향상시킬 뿐만 아니라, 실제 애플리케이션에서 모델의 신뢰성과 안정성 개선에도 기여할 수 있음을 보여줍니다. 이 연구 결과는 target detection 알고리즘 최적화를 위한 이론적 기초와 기술적 참고 자료를 제공합니다.



### EG-HumanNeRF: Efficient Generalizable Human NeRF Utilizing Human Prior for Sparse View (https://arxiv.org/abs/2410.12242)
Comments:
          project page: this https URL

- **What's New**: 본 연구는 일반화된 인간 NeRF(Neural Radiance Field) 프레임워크인 EG-HumanNeRF를 제안하여 희소 입력 뷰에서도 고품질의 실시간 렌더링을 가능하게 합니다. 이 프레임워크는 인체 선행 지식을 폭넓게 활용하여 렌더링 품질을 향상시킵니다.

- **Technical Details**: EG-HumanNeRF는 두 단계 샘플링 감소 전략을 통해 렌더링을 가속화하며, 첫 번째 단계에서는 인체 기하형상을 둘러싼 경계 메시(boundary meshes)를 구성하여 샘플 수를 줄입니다. 두 번째 단계에서는 <signed ray distance function> (SRDF)을 기반으로 한 샘플링 가이드를 사용하여 렌더링 품질을 유지하면서 필요한 샘플의 수를 줄입니다. 또한 가리기 구역을 고려하는 주의 메커니즘(occlusion-aware attention mechanism)을 도입하여 렌더링 품질을 향상시킵니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 최신 기술과 비교하여 렌더링 품질이 우수하며, 속도에서도 경쟁력을 갖추고 있음이 입증되었습니다.



### Leveraging Spatial Attention and Edge Context for Optimized Feature Selection in Visual Localization (https://arxiv.org/abs/2410.12240)
- **What's New**: 이번 논문에서는 비주얼 로컬라이제이션(visual localization) 분야에서 최신 기술을 적용하여 에이전트의 자세를 개선하는 방법을 제안합니다. 기존 방법의 한계를 극복하기 위해 어텐션 네트워크(attention network)를 도입하여 이미지의 정보가 많은 영역을 선택적으로 타겟팅합니다.

- **Technical Details**: 제안된 방법은 이미지 패치의 공간 정보(spatial information)를 활용하여 교육 버퍼(training buffer)에서 가장 관련성이 높은 특징(feature)만을 선택하고, 엣지 감지(edge detection)를 결합하여 선별된 특징이 강력한 지역에 위치하도록 합니다. 이를 통해 2D-3D 대응(2D-3D correspondence) 및 전반적인 로컬라이제이션 성능을 향상시킬 수 있습니다.

- **Performance Highlights**: 이 방법은 야외 벤치마크 데이터셋에서 테스트되었으며 이전 방법들에 비해 우수한 성능을 입증하였습니다. 또한, 어텐션 네트워크와 엣지 감지기의 통합에도 불구하고 빠른 매핑 시간과 효율적인 매핑 크기를 유지할 수 있음을 보여줍니다.



### Evaluating Cascaded Methods of Vision-Language Models for Zero-Shot Detection and Association of Hardhats for Increased Construction Safety (https://arxiv.org/abs/2410.12225)
- **What's New**: 본 논문은 건설 안전 향상을 위한 하드햇(hardhat) 탐지를 위한 비전-언어 모델(vision-language models, VLMs)의 제로샷(zero-shot) 탐지 및 연관성의 적용 가능성을 평가합니다. 새로운 벤치마크 데이터셋인 Hardhat Safety Detection Dataset을 생성하였으며, 이 데이터셋은 기존 데이터셋을 필터링하고 결합하여 제작되었습니다.

- **Technical Details**: 이 연구에서는 OWLv2라는 기초 모델을 사용하여 실제 건설 현장에서 하드햇을 탐지하는 방법을 제시합니다. 실험은 5,210개 이미지를 사용하였으며, OWLv2 모델은 하드햇 탐지에서 평균 정확도(average precision) 0.6493을 달성했습니다. 또한, 이미지에서 사람, 머리, 하드햇의 순차적 탐지를 위한 계단식 탐지(cascaded detection) 접근 방식을 개발했습니다.

- **Performance Highlights**: 실험 결과, OWLv2 모델의 하드햇 탐지 성능은 평균 정확도 0.6493으로 나타났습니다. 현재 모델의 강점과 약점을 논의하며, 하드햇 탐지의 실제 환경 적합성을 개선하기 위한 여러 방법에 대해서도 분석하였습니다.



### Order-Aware Interactive Segmentation (https://arxiv.org/abs/2410.12214)
Comments:
          Interactive demo can be found in project page: this https URL

- **What's New**: 본 논문에서는 OIS(order-aware interactive segmentation)를 제안하여 객체의 상대적인 깊이 정보를 코드화하여 사용자 상호작용을 개선하고, 세밀한 객체 분리를 가능하게 합니다.

- **Technical Details**: OIS는 order map을 활용하여 사용자 상호작용(클릭)의 효과를 극대화하며, 객체 인식 강화를 위해 object-aware attention 모듈을 도입합니다. 이 방식은 양호한 분류 성능을 제공하면서도 속도는 두 배로 향상시킵니다.

- **Performance Highlights**: OIS는 HQSeg44K 데이터셋에서 하나의 클릭 후 7.61 mIoU를, DAVIS 데이터셋에서 1.32 mIoU를 향상시켜 기존의 SegNext보다 우수한 성능을 나타내며, 계산 속도도 두 배로 증가시킵니다.



### Sparse Prototype Network for Explainable Pedestrian Behavior Prediction (https://arxiv.org/abs/2410.12195)
- **What's New**: 본 논문에서는 보행자 행동 예측에 있어 기존의 여러 겹의 특성과 행위를 동시에 예측할 수 있도록 설계된 Sparse Prototype Network (SPN)을 소개합니다. 이 모델은 예측의 설명 가능성을 높이기 위한 중간 프로토타입 병목 층을 활용하여, 모든 입력 모달리티에 대해 독립적인 프로토타입을 학습합니다.

- **Technical Details**: SPN은 세 가지 주요 모듈로 구성되어 있습니다: 입력 인코딩, 프로토타입 층, 그리고 예측 헤드입니다. 입력 인코딩 모듈은 각 모달리티를 독립적으로 처리하며, 원시 입력을 압축된 고차원 특성 벡터로 변환합니다. 프로토타입은 모달리티 간의 일관성을 유지하면서 학습되며, 이를 통해 예측의 해석 가능성을 제공합니다. 또한, Top-K Mono-semanticity Scale이라는 정량적 메트릭을 사용하여 프로토타입의 설명 가능성을 평가합니다.

- **Performance Highlights**: SPN은 TITAN 및 PIE 데이터셋에서 보행자 행동 예측 작업을 수행하며, 상태 최우수 성능을 달성했습니다. 또한, 이 모델은 동시에 다중 유형의 행동을 예측함으로써 높은 수준의 설명 가능성을 유지합니다.



### Test-time adaptation for image compression with distribution regularization (https://arxiv.org/abs/2410.12191)
- **What's New**: 본 연구에서는 기존의 혼합 잠재 정제(HLR) 방법을 확장하여 교차 도메인 이미지 압축(TTA-IC)에 적응할 수 있는 고급 잠재 정제 방법을 개발하였습니다. 이 방법은 기존의 방법들에 비해 R-D 성능을 개선하고, 모델의 수정이나 전송 없이 라벨 분포를 더욱 정확하게 학습할 수 있게 돕습니다.

- **Technical Details**: 연구의 주된 기법은 Bayes 근사와 분포 정규화(distribution regularization)를 도입하여, Gaussian 조건부 확률과 하이퍼프라이어 간의 불일치를 해결하고, 더 나은 공Joint 확률 근사를 학습하도록 유도하는 것입니다. 이는 또한 기존의 R-D 목적을 개선하여, 즉각적인 모델 수정 없이 효과적인 전환을 가능하게 합니다.

- **Performance Highlights**: 여섯 개의 도메인 내 및 교차 도메인 데이터 세트에서의 광범위한 실험을 통해 제안된 방법이 다른 잠재 정제 접근 방식들에 비해 R-D 성능을 크게 향상시키며, 기존의 TTA-IC 방법에 융통성 있게 통합될 수 있다는 것을 실증하였습니다.



### TransAgent: Transfer Vision-Language Foundation Models with Heterogeneous Agent Collaboration (https://arxiv.org/abs/2410.12183)
Comments:
          NeurIPS 2024

- **What's New**: 본 연구에서는 CLIP과 같은 vision-language foundation 모델의 일반화 문제를 해결하기 위해 새로운 TransAgent 프레임워크를 제안합니다. 이 프레임워크는 다양한 모델에서 지식을 통합하여 CLIP이 여러 출처의 지식 증류(multi-source knowledge distillation)를 통해 일반화할 수 있도록 돕습니다.

- **Technical Details**: TransAgent 프레임워크는 11개의 이질적인 모듈(heterogeneous agents)과 협력하여 vision-language 모델을 강화하며, 예측 단계(inference phase)에서는 추가 비용이 발생하지 않습니다. 이를 통해 단일 모델의 한계를 극복하고 지식 전이를 효율적으로 수행합니다.

- **Performance Highlights**: TransAgent는 11개 시각 인식 데이터셋에서 최첨단(performance state-of-the-art) 성능을 달성하였으며, 인기 있는 CoOp 모델보다 평균 약 10% 더 뛰어난 성능을 보였습니다. EuroSAT 데이터셋에서는 20% 향상된 성능을 기록했습니다.



### Dual-Model Distillation for Efficient Action Classification with Hybrid Edge-Cloud Solution (https://arxiv.org/abs/2410.12165)
- **What's New**: 본 논문에서는 Dual-Model Distillation (DMD)이라는 혁신적인 방법을 통해 경량화된 혼합 에지-클라우드 솔루션을 제안하며, 실시간 환경에서의 성능을 최적화합니다.

- **Technical Details**: DMD는 소형 모델과 대형 모델 간의 지식을 상호 보완적으로 활용하여, 불확실한 상황에서 대형 모델에게 추론을 오프로드하는 기능을 수행하는 스위처 모델을 훈련합니다. 이 과정은 추가적인 수동 라벨링 데이터 없이 이루어지며, 두 모델의 제로샷 추론 결과의 합의나 불일치를 이용하여 데이터를 생성합니다.

- **Performance Highlights**: 우리의 시스템은 대형 모델만 사용했을 때보다 39.5%의 비용 절감과 4.6% 높은 F1 점수를 달성하였으며, 에너지 소비와 처리 시간을 각각 39.5%와 38.9% 줄였습니다.



### SAM-Guided Masked Token Prediction for 3D Scene Understanding (https://arxiv.org/abs/2410.12158)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 연구에서는 SAM(Segment Anything Model) 기반의 새로운 토큰화(tokenization) 방법을 통해 2D에서 3D로의 지식 증류(knowledge distillation) 문제를 해결합니다. 기존의 KNN(k-Nearest Neighbors) 기반 토큰화기법 대신 지역 수준의 정보와 3D 변환기 구조를 원활하게 정렬합니다.

- **Technical Details**: 연구는 SAM-guided masked token prediction 프레임워크를 제안하며, 이는 SAC 토큰화를 적용하여 지역 수준에서 2D-3D 지식 증류를 원활하게 수행합니다. 또한, 그룹 균형 재가중치(group-balanced re-weighting) 전략을 통해 3D 데이터 세트의 긴 꼬리 문제를 해결합니다.

- **Performance Highlights**: 여러 데이터 세트(SUN RGB-D, ScanNet, S3DIS)에서 3D 객체 탐지 및 의미론적 분할에서 현존하는 최신 자가 감독(self-supervised) 방법보다 성능이 크게 향상된 것으로 나타났습니다.



### Unveiling the Limits of Alignment: Multi-modal Dynamic Local Fusion Network and A Benchmark for Unaligned RGBT Video Object Detection (https://arxiv.org/abs/2410.12143)
- **What's New**: 본 논문에서는 수동으로 정렬되지 않은 RGB-열화상 이미지 쌍을 처리하기 위해 설계된 Multi-modal Dynamic Local Fusion Network (MDLNet)을 제안합니다. 이는 기존의 RGB-Thermal Video Object Detection (RGBT VOD) 방법의 한계를 극복하는 새로운 접근법입니다.

- **Technical Details**: MDLNet의 핵심 구성 요소는 Multi-modal Dynamic Local Fusion (MDLF) 모듈로, 임의의 가우시안 노이즈를 추가하여 동적 박스를 생성하며, 이 박스는 원래 고해상도 RGB 이미지의 로컬 영역을 선택합니다. 선택된 영역은 다른 모달리티의 정보와 융합되어 RGB로 재삽입됩니다. 또한 Cascaded Temporal Scrambler (CTS)를 도입하여 연속 프레임 간의 일관된 시공간 정보를 활용하여 현재 프레임의 표현 능력을 향상시킵니다.

- **Performance Highlights**: 제안된 MDLNet은 30,494 쌍의 정렬되지 않은 RGBT 이미지로 구성된 UVT-VOD2024 데이터셋을 활용하여 평가되었으며, 현존하는 최신 모델들과 비교했을 때 탁월한 성능을 보여줍니다.



### SplatPose+: Real-time Image-Based Pose-Agnostic 3D Anomaly Detection (https://arxiv.org/abs/2410.12080)
- **What's New**: 이번 연구에서는 실시간으로 작동하는 Pose-Agnostic 3D Anomaly Detection 방법인 SplatPose+를 제안합니다. SplatPose+는 구조 기반의 SfM 모델과 학습 기반의 3D Gaussian Splatting 모델을 결합하여 효율적인 탐지를 가능하게 합니다.

- **Technical Details**: SplatPose+는 하이브리드 3D 표현을 사용하여 쿼리 뷰를 지역화하고, 높은 품질의 아노말리-프리(pseudo reference images)를 합성하여 픽셀 단위 비교를 수행합니다. 이 과정에서 Structure from Motion(SfM) 모델과 3D Gaussian Splatting(3DGS) 모델이 결합됩니다.

- **Performance Highlights**: SplatPose+는 MAD-Sim 데이터셋에서 새로운 SOTA(State of the Art)를 달성하였고, 기존 SplatPose에 비해 학습 속도는 37.4% 빠르며, 추론 속도는 147배 향상되었습니다. 또한, 제한된 훈련 데이터(40% 사용)로도 높은 아노말리 탐지 및 세분화 성능을 보였습니다.



### WeatherDG: LLM-assisted Procedural Weather Generation for Domain-Generalized Semantic Segmentation (https://arxiv.org/abs/2410.12075)
- **What's New**: 이번 연구에서는 WeatherDG라는 새로운 접근 방식을 제안합니다. 이는 Stable Diffusion (SD)와 Large Language Model (LLM)의 협력을 통해 사실적인, 날씨가 다양한, 운전 화면 이미지를 생성할 수 있습니다.

- **Technical Details**: 이 방법은 세 가지 단계로 구성됩니다. 첫째, SD를 소스 데이터로 미세 조정하여 생성된 샘플의 내용과 레이아웃을 실제 운전 시나리오에 맞추는 것입니다. 둘째, LLM에 기반한 프로세절 프롬프트 생성 방법을 제안하여 시나리오 설명을 풍부하게 하고 SD가 더 다양하고 상세한 이미지를 자동으로 생성할 수 있도록 합니다. 마지막으로, 생성된 이미지를 사용해 모델을 훈련시키는 단계입니다.

- **Performance Highlights**: 세 가지 도전적인 데이터셋에서 실험한 결과, 우리의 방법이 다양한 최신 방법의 성능을 일관되게 개선할 수 있음을 보여주었습니다. 특히, 'Cityscapes to ACDC' 설정에서는 우리의 방법이 기준 HRDA에 비해 mIoU에서 13.9% 향상되었습니다.



### nvTorchCam: An Open-source Library for Camera-Agnostic Differentiable Geometric Vision (https://arxiv.org/abs/2410.12074)
Comments:
          Source code and installation instructions are available at this https URL

- **What's New**: nvTorchCam은 카메라 모델에 독립적인 딥 러닝 알고리즘을 개발할 수 있도록 해주는 오픈 소스 라이브러리입니다. 이 라이브러리는 다양한 카메라 모델(핀홀, 어안, 360도 등)을 지원하며, PyTorch 기반으로 확장성과 효율성을 가지고 있습니다.

- **Technical Details**: nvTorchCam은 카메라 모델의 핵심 작업을 추상화하여, 개발자들이 특정 카메라 모델에 상관없이 알고리즘을 구현할 수 있도록 지원합니다. CameraBase라는 추상 기본 클래스를 통해 포인트-투-픽셀 프로젝션과 픽셀-투-레이 변환과 같은 작업을 표준화하였습니다. 이로 인해 다양한 카메라 모델을 사용하는 딥 네트워크의 데이터로더는 해당하는 CameraBase의 하위 클래스를 반환하는 것만으로도 쉽게 변환할 수 있습니다.

- **Performance Highlights**: nvTorchCam의 고유한 기능으로는 다중 카메라 모델 간의 변환을 지원하는 역 왜곡(backward warping) 알고리즘이 있으며, 이에 대한 유효하지 않은 포인트를 추적하는 메커니즘도 포함되어 있어 복잡한 카메라 설정에서도 정확한 역 왜곡을 가능하게 합니다. 이 라이브러리는 다양한 카메라 모델에 대해 배치 처리 및 GPU 가속을 지원하여 효율적인 계산을 가능하게 합니다.



### SOE: SO(3)-Equivariant 3D MRI Encoding (https://arxiv.org/abs/2410.12053)
- **What's New**: 본 연구는 3D MRI 이미지에서 SO(3)-equivariance (SOE)을 적용한 새로운 표현 학습 방법을 제안합니다. 기존 MRI 모델들이 기하학적 정보(translation, rotation)를 무시하는 경향이 있음을 언급하며, 이러한 기하학적 변환 정보를 모델에 통합하는 것이 뇌 구조의 디테일을 효과적으로 캡쳐할 수 있음을 주장합니다.

- **Technical Details**: SO(3)는 3차원 특수 직교군으로, 3D 공간 내 모든 회전을 나타냅니다. 본 연구에서는 MRI 입력 이미지에 적용된 회전 연산이 임베딩 표현 공간에서도 반영되도록 명시적으로 모델링합니다. 이를 위해 Vector Neuron 모듈을 이용하여 표현 벡터 공간을 생성하고, SO(3) 변환이 이 공간에서 적용 가능하도록 합니다.

- **Performance Highlights**: 제안된 SOE 방법은 두 개의 공개 데이터 세트를 사용하여 T1-weighted brain scans에서 알츠하이머병 진단과 나이 예측 작업을 평가한 결과, 기존 방법들보다 우수한 성능을 보이었으며, 다양한 축에 대한 회전에도 견고한 성능을 유지함을 입증하였습니다.



### LocoMotion: Learning Motion-Focused Video-Language Representations (https://arxiv.org/abs/2410.12018)
Comments:
          ACCV 2024

- **What's New**: 이 논문은 동작 중심 비디오-언어 표현(motion-focused video-language representations)을 목표로 하고 있습니다. 기존의 방법들이 공간적인(focused on spatial) 데이터에 의존하여 물체와 장면을 식별하는 데 중점을 두었던 반면, 이 연구에서는 동작을 설명하는 캡션(captions)에서 학습하는 LocoMotion을 제안합니다.

- **Technical Details**: 기존의 비디오-언어 표현 방법은 캡션이 공간적 측면에 집중된 반면, LocoMotion은 지역 물체의 동작을 아우르는 동작 중심 캡션을 생성하여 학습합니다. 이를 위해 비디오에 합성된 동작(synthetic motions)을 추가하고 이 동작의 매개변수(parameters)를 활용하여 상응하는 캡션을 생성합니다. 또한, 동작의 다양성을 높이기 위해 동사 변형 парафразинг(verb-variation paraphrasing)을 도입하여 동작 기본 요소(primitive motions)와 고수준 동사 간의 연관성을 학습합니다.

- **Performance Highlights**: 실험 결과, 동작 중심 데이터가 제한적인 상황에서도 효과적인 성능을 보이며, 다양한 하위 작업(downstream tasks)에 대해 우수한 적합성을 입증했습니다.



### Beyond Labels: A Self-Supervised Framework with Masked Autoencoders and Random Cropping for Breast Cancer Subtype Classification (https://arxiv.org/abs/2410.12006)
- **What's New**: 이번 연구는 유방암 아형 분류를 위한 히스토패스홀로지(Histopathology) 이미지를 사용하여, 마스크 오토인코더(Masked Autoencoder, MAE)를 활용한 자기 지도 학습(self-supervised learning) 방법론을 제안합니다. 이 접근법은 정보 전반을 효과적으로 캡처하기 위한 임베딩(embedding) 학습을 통해 레이블이 없는 데이터셋에서도 특징(feature) 학습이 가능합니다.

- **Technical Details**: 연구에서는 전체 슬라이드 이미지(Whole Slide Images, WSI)에서 이미지 패치를 추출하고, 마스크 기법을 사용하여 인코더가 마스킹된 데이터를 기반으로 복원하는 구조를 취합니다. MAE를 통해 이미지의 특정 부분을 마스킹하고, 잔여 데이터로부터 패턴을 학습하여 원래 이미지를 복원하는 과정을 구현합니다. 또한, ViT(Vision Transformers) 모델을 사용하여 다중 분류(multi-class classification) 작업에서 성능을 평가합니다.

- **Performance Highlights**: BRACS 데이터셋 평가를 통해 이 모델이 기존 벤치마크와 비교하여 높은 성능을 보여주었으며, 특히 tumor tissue와 healthy tissue 구분 및 아형 분류에서의 정확도가 강조되었습니다.



### Integrating Artificial Intelligence Models and Synthetic Image Data for Enhanced Asset Inspection and Defect Identification (https://arxiv.org/abs/2410.11967)
- **What's New**: 본 연구에서는 드론 기반 검사를 통해 수집된 방대한 이미지 데이터를 활용하여 자산 결함 검사 과정을 개선하는 새로운 접근 방식을 제안합니다. 이는 합성(مسذه) 자산 결함 이미지와 수작업으로 레이블링된 드론 이미지를 결합하여 이루어집니다.

- **Technical Details**: 연구의 핵심은 Maya 및 Unreal Engine과 같은 3D 모델링 도구를 사용하여 결함이 있는 자산과 주변환경의 포토리얼리스틱(photorealistic) 3D 모델 및 2D 렌더링을 생성하는 것입니다. 이를 통해 생성된 합성 이미지가 실제 데이터에 통합되어 학습 파이프라인을 보강합니다. 이 연구는 자산 및 결함을 감지하기 위한 엔드 투 엔드(End-to-End) 인공지능(AI) 솔루션을 구현하였습니다.

- **Performance Highlights**: 자산 탐지 모델은 92%의 정확도를 달성하였고, 약 2,000개의 2k 해상도 합성 이미지를 도입함으로써 성능이 67% 향상되었습니다. 결함 탐지 모델은 두 배치(batch) 이미지에서 73%의 정확도를 기록하였습니다. 분석 결과, 합성 데이터가 실제 수작업 레이블링 데이터 대신에 결함 탐지 모델 학습에 성공적으로 사용될 수 있음을 보여주었습니다.



### CtrlSynth: Controllable Image Text Synthesis for Data-Efficient Multimodal Learning (https://arxiv.org/abs/2410.11963)
- **What's New**: 새로운 연구는 'CtrlSynth'라는 이미지-텍스트 합성 파이프라인을 설계하여 데이터 효율적이고 강력한 다중 모달 학습을 가능하게 합니다. 이 방법은 사용자가 정의한 제어 정책을 적용하여 시각적 의미를 분해하고 재조합함으로써 입력 데이터의 생성을 조절할 수 있게 만들어줍니다.

- **Technical Details**: CtrlSynth는 미리 훈련된 기초 모델을 활용하여 이미지의 시각적 태그를 추출하고, 이를 바탕으로 LLM을 이용해 텍스트를 생성합니다. 사용자는 생성 과정에서 특정 요소를 제어할 수 있으며, 닫힌 루프 시스템을 통해 기존 모델을 활용하여 추가 훈련 없이 직접적으로 합성 작업을 수행합니다.

- **Performance Highlights**: CtrlSynth는 31개의 다양한 데이터셋에서 실험을 진행했으며, CLIP 모델의 제로샷 분류에서는 23.4%, SugarCrepe 구성 추론 벤치마크에서는 5%의 정확도 향상을 보였습니다. 또한, 긴 꼬리(Long-tail) 비전 과제에서도 16%에서 21%의 성능 개선을 확인했습니다.



### Dual-frame Fluid Motion Estimation with Test-time Optimization and Zero-divergence Loss (https://arxiv.org/abs/2410.11934)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 본 연구에서는 기존의 레이블이 필요한 방식과 달리, 오직 1%의 훈련 샘플로도 뛰어난 성능을 발휘하는 완전 자기 감독(self-supervised) 방식의 새로운 방법론을 제안합니다.

- **Technical Details**: 제안된 방법은 이중 프레임 유체 운동 추정(dual-frame fluid motion estimation) 및 제로 다이버전스 손실(zero-divergence loss)을 활용하여 유체의 운동을 자가 지도(self-supervised) 방식으로 최적화합니다. 특히, splat 기반 구현을 통해 효율적이고 효과적인 손실 함수 설계를 제공합니다. 또한, Dynamic Velocimetry Enhancer (DVE) 모듈을 통해 테스트 시간 최적화(test-time optimization)를 지원합니다.

- **Performance Highlights**: 실험 결과, 제안된 자기 감독 프레임워크는 기존의 완전 감독 방식보다 우수한 성능을 보이며, 제한된 데이터(최소 1% 사용)에서도 강력한 성능을 발휘하고, 다양한 테스트 시나리오에서 탁월한 교차 도메인 강건성(cross-domain robustness)을 달성함을 입증하였습니다.



### Development and Testing of a Wood Panels Bark Removal Equipment Based on Deep Learning (https://arxiv.org/abs/2410.11913)
- **What's New**: 이 연구는 나무 패널의 껍질 제거 장비에 딥 러닝 방법을 적용하여 품질과 효율성을 개선하는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 본 연구에서는 비전 검사를 위한 시스템이 장착된 나무 패널 껍질 제거 장비를 설계하였습니다. 이를 위해 수집된 대량의 나무 패널 이미지로부터 첫 번째 일반 나무 패널 의미 세분화(semantic segmentation) 데이터셋을 구성하고, BiSeNetV1 모델을 훈련하였습니다. 껍질 제거 과정에 필요한 핵심 데이터의 계산 방법과 과정을 자세히 설명하였습니다.

- **Performance Highlights**: BiSeNetV1 모델의 비교 실험 결과, 껍질 제거의 품질 및 효율성이 현저히 개선되었으며, 개발된 장비는 제재소의 정밀도 및 효율성 요구 사항을 완벽하게 충족합니다.



### Neural Metamorphosis (https://arxiv.org/abs/2410.11878)
Comments:
          in ECCV2024, this https URL

- **What's New**: 본 논문에서는 Neural Metamorphosis (NeuMeta)라는 새로운 학습 패러다임을 소개합니다. NeuMeta는 별도의 모델을 만들지 않고, 신경 네트워크의 가변 형태를 직접 학습합니다. 이를 통해 학습된 가중치 공간에서 임의 크기의 네트워크를 샘플링할 수 있습니다.

- **Technical Details**: NeuMeta는 hypernetwork로 작동하는 implicitly learned neural functions를 사용합니다. 이는 모델 공간의 좌표를 받아 해당 가중치 값을 생성합니다. 목표는 가중치의 smoothness를 높이는 것이며, 이를 위해 두 가지 전략을 사용합니다: 첫째, 가중치 행렬의 permutation을 통해 intra-model smoothness를 달성하고, 둘째, 입력 좌표에 noise를 추가하여 무작위 네트워크 구성에서도 일관된 출력을 유지합니다.

- **Performance Highlights**: NeuMeta는 이미지 분류, 의미론적 분할 및 이미지 생성 작업에서 광범위한 테스트를 거쳐, 75% 압축률에서도 원래 모델의 성능을 유지합니다. 이 시스템은 이전에 보지 못한 네트워크 구성에 대한 가중치를 생성하는 성능을 보여줍니다.



### A Robust Multisource Remote Sensing Image Matching Method Utilizing Attention and Feature Enhancement Against Noise Interferenc (https://arxiv.org/abs/2410.11848)
Comments:
          21 pages, 13 figures

- **What's New**: 이번 논문은 다양한 노이즈에 대한 저항성을 갖춘 다중 출처 원격 탐지 이미지 매칭 방법을 제안하며, 주목(attention) 메커니즘과 특성 향상을 통해 문제를 해결합니다.

- **Technical Details**: 첫 번째 단계에서는 깊은 합성곱(deep convolution)과 트랜스포머(transformer)의 주목 메커니즘을 결합하여 조밀한 특성 추출을 수행합니다. 두 번째 단계에서는 이진 분류 기법을 기반으로 한 이상치 제거(outlier removal) 네트워크를 도입하여 이미지 간의 유효하고 기하학적으로 일관된 상관관계를 구축합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 다양한 노이즈 조건에서 다른 최신 방법들과 비교했을 때 40% 이상의 매칭 성공률을 달성하며, 벤치마크된 성능 및 견고성을 입증합니다.



### WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines (https://arxiv.org/abs/2410.12705)
- **What's New**: WorldCuisines라는 대규모 벤치마크가 소개되어 VLMs의 다문화적 및 다언어적 이해력을 평가할 수 있는 새로운 기준을 제시합니다. 이 벤치마크는 30개 언어와 방언에서 각각의 텍스트-이미지 쌍을 포함하고 있어 다문화적인 VQA 데이터셋으로는 가장 큰 규모를 자랑합니다.

- **Technical Details**: 이 연구는 VLMs를 평가하기 위해 100만 개 이상의 고품질의 다언어 및 다문화 텍스트-이미지 쌍으로 구성된 WorldCuisines를 개발했습니다. 벤치마크는 2가지 작업을 포함합니다: (1) 요리 이름 예측, (2) 요리가 일반적으로 소비되는 위치 예측. VQA 데이터셋은 30개 언어와 방언으로 구성되어 있으며, 다양한 질문 유형에 대한 평가를 포함합니다.

- **Performance Highlights**: VLMs는 적절한 위치 맥락에서 더 좋은 성능을 보였으나, 적대적인 맥락에서는 어려움을 겪었고, 특정 지역 요리와 언어 예측에서의 어려움이 드러났습니다. 데이터셋과 관련된 주의 깊은 메타데이터와 이미지도 함께 제공되어 향후 연구 지원을 기대합니다.



### Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans (https://arxiv.org/abs/2410.12641)
- **What's New**: 본 연구에서는 어깨 CT 스캔을 처리하기 위한 혁신적인 딥러닝 프레임워크를 도입합니다. 이 프레임워크는 근위 상완골과 견갑골의 의미적 분할(semantic segmentation), 뼈 표면의 3D 재구성, 글레노흐umeral (GH) 관절 영역 식별 및 세 가지 일반적인 골관절염 관련 병리(staging)인 골극 형성(osteophyte formation), GH 공간 축소(glenohumeral joint space reduction), 그리고 상완 견갑 정렬(humeroscapular alignment)을 포함합니다.

- **Technical Details**: 이 파이프라인은 두 개의 연속적인 CNN 아키텍처로 구성됩니다. 첫 번째는 세그멘테이션을 위한 3D CEL-UNet, 두 번째는 세 가지 분류를 위한 3D Arthro-Net입니다. 571개의 CT 스캔의 레트로스펙티브 데이터셋을 사용하여 성능을 평가했습니다. 3D 재구성에 대한 평균 제곱근 오차(root mean squared error) 및 하우스도르프 거리(Hausdorff distance)의 중앙값은 상완골에 대해 각각 0.22mm 및 1.48mm, 견갑골은 0.24mm 및 1.48mm로, 기존 아키텍처를 초과하는 성능을 보였습니다.

- **Performance Highlights**: 세 가지 카테고리(OS, JS, HSA)에 대해 분류 정확도는 약 90%에 도달하였으며, 추론 파이프라인의 계산 시간은 15초 미만으로, 정형외과 영상의학적 실습과의 효율성과 호환성을 보여줍니다. 이 결과는 인공지능 도구의 의료 변환을 위한 유망한 발전을 나타내며, 고품질의 뼈 표면을 제공하고 외과의사가 환자의 관절 조건에 따라 가장 적합한 외과적 접근 방식을 선택하는 데 도움을 줍니다.



### Exploring Model Kinship for Merging Large Language Models (https://arxiv.org/abs/2410.12613)
Comments:
          Ongoing work

- **What's New**: 이 연구는 모델 병합(model merging)을 위한 새로운 평가 기준인 모델 친척성(model kinship)을 도입합니다. 모델 친척성은 LLM(대형 언어 모델) 간의 유사성과 관련성을 측정하여, 반복적인 병합 과정에서 성능 개선을 돕는 정보를 제공합니다.

- **Technical Details**: 모델 병합은 여러 개별 모델을 통합하여 다중 작업 목표를 달성하는 전략입니다. 본 논문에서는 모델 친척성을 기준으로 한 Top-k Greedy Merging 전략을 제안하며, 이는 모델 진화(model evolution)에서의 최적화 문제와 지역 최적점(local optima traps)을 피할 수 있도록 도와줍니다.

- **Performance Highlights**: 모델 친척성을 사용한 새로운 병합 전략은 벤치마크 데이터셋에서 더 나은 성능을 달성하며, 평균 성능 향상과 강한 상관관계가 있음을 보여줍니다. 이 연구는 모델 병합의 효율성과 효과성을 높이기 위한 실용적인 전략을 제시합니다.



### From Lab to Pocket: A Novel Continual Learning-based Mobile Application for Screening COVID-19 (https://arxiv.org/abs/2410.12589)
Comments:
          31 pages

- **What's New**: 이 논문에서는 COVID-19를 의료 이미지에서 예측하기 위한 새로운 지속 학습 기반 접근 방식을 제안하고 있으며, COVID-19 선별을 위한 모바일 애플리케이션의 설계 및 구현을 제공합니다.

- **Technical Details**: DenseNet161이 지속 학습 모델의 기초 모델로 선택되었으며, Learning without Forgetting (LwF) 기법이 최고의 지속 학습 방법으로 평가되었습니다. 이 모델은 클라우드 서버에서 Continuous Learning을 통해 실시간으로 학습할 수 있도록 설계되었습니다.

- **Performance Highlights**: 모바일 애플리케이션이 COVID-19 분류에서 94.44%의 정확도를 달성하여 사용자들이 효율적으로 COVID-19를 선별할 수 있는 잠재력을 입증하였습니다.



### Self-DenseMobileNet: A Robust Framework for Lung Nodule Classification using Self-ONN and Stacking-based Meta-Classifier (https://arxiv.org/abs/2410.12584)
Comments:
          31 pages

- **What's New**: 본 연구에서는 Self-DenseMobileNet이라는 새로운 프레임워크를 제안하여 흉부 X선 이미지를 통한 결절(nodules)과 비결절(non-nodules) 분류의 정확성을 향상시켰습니다. 이 접근법은 이미지 표준화 및 강화 기술을 통합하여 입력 품질을 최적화하고 분류 정확도를 개선하였습니다.

- **Technical Details**: Self-DenseMobileNet은 심층 학습 아키텍처로, 반복적인 개선을 통해 다양한 향상된 이미지 샘플에 최적화된 얕은 아키텍처를 특징으로 합니다. 8개의 전통적인 기계 학습 모델에서 상위 3개 모델의 예측 확률을 스태킹(stacking) 알고리즘을 사용하여 결합해 메타 분류기를 생성하여 강력한 성능을 보여줍니다. 또한, ScoreCAM과 같은 클래스 활성화 매핑(Class Activation Mapping) 기법을 사용하여 모델의 결정 프로세스를 시각화하여 해석 가능성을 향상시켰습니다.

- **Performance Highlights**: 내부 검증 데이터에서 Self-DenseMobileNet 모델은 Meta-Random Forest Classifier를 사용하여 99.28%의 정확도를 달성하였으며, 외부 데이터셋에서는 89.40%의 정확도로 강한 일반화 능력을 유지했습니다. 이러한 결과는 폐 결절의 분류 향상에 있어 중요한 개선을 나타냅니다.



### One Step Diffusion via Shortcut Models (https://arxiv.org/abs/2410.12557)
- **What's New**: 이번 논문에서는 shortcut models를 소개합니다. 이 모델은 고품질 샘플을 단일 또는 다수의 샘플링 단계에서 생성할 수 있도록 단일 네트워크와 훈련 단계를 사용합니다.

- **Technical Details**: Shortcut 모델은 현재의 noise level뿐만 아니라 원하는 step size에 대해서도 네트워크를 조건화합니다. 이를 통해 생성 과정에서 미리 건너뛰는 것이 가능해집니다.

- **Performance Highlights**: 다양한 샘플링 단계 예산에 걸쳐 shortcut 모델은 consistency models 및 reflow와 같은 이전 접근 방식보다 consistently 더 높은 품질의 샘플을 생성합니다. Distillation과 비교할 때, shortcut 모델은 단일 네트워크와 훈련 단계로 복잡성을 줄이고, 추론 시 다양한 step budget을 허용합니다.



### Evaluating Utility of Memory Efficient Medical Image Generation: A Study on Lung Nodule Segmentation (https://arxiv.org/abs/2410.12542)
- **What's New**: 본 연구에서는 CT 스캔에서 폐 결절을 대상으로 하는 메모리 효율적인 patch-wise denoising diffusion probabilistic model (DDPM)을 제안하여 합성 의료 이미지를 생성하는 방법을 소개합니다.

- **Technical Details**: 이 모델은 nodule segmentation을 포함한 고유용성 합성 이미지를 생성하며, 메모리 제약을 효율적으로 관리하여 교육 데이터셋을 생성할 수 있도록 합니다. 연구는 두 가지 시나리오에서 평가되었습니다: 1) 합성 데이터만을 이용한 segmentation 모델 훈련, 2) 합성 이미지를 사용하여 실제 훈련 데이터 증가.

- **Performance Highlights**: 합성 데이터로만 훈련된 모델들은 실제 데이터 벤치마크에 비해 유사한 Dice 점수를 기록하였고, 합성 이미지로 실제 데이터를 보강할 경우 segmentation 성능이 크게 향상되었습니다. 생성된 이미지는 현실 세계 데이터가 제한된 상황에서 의료 이미지 데이터셋을 향상시킬 잠재력을 지닙니다.



### A Primal-dual algorithm for image reconstruction with ICNNs (https://arxiv.org/abs/2410.12441)
- **What's New**: 이 논문에서는 데이터 기반 변분 재구성(Data-driven Variational Reconstruction) 프레임워크에서 최적화 문제를 다루고 있습니다. 특히 입력 볼록 신경망(Input-Convex Neural Network, ICNN)에 의해 매개변수화된 정규화기(Regularizer)를 사용하며, 기존의 그라디언트 기반 방법의 한계를 극복하는 새로운 접근 방식을 제시하고 있습니다.

- **Technical Details**: 기존 방법들은 비매끄러운(non-smoothness) 특성을 효과적으로 처리하는 데 어려움이 있으며, 이는 느린 수렴(convergence)으로 이어집니다. 이 논문에서는 신경망의 중첩 구조(nested structure)를 제거하고, 활성화 함수(activation function)의 에피그래프(projection)를 통해 문제를 변형하여 볼록 최적화(convex optimization) 문제로 변환했습니다. 이를 통해 새로운 쌍대 알고리즘(primal-dual algorithm)을 적용할 수 있게 되었습니다.

- **Performance Highlights**: 여러 이미징(imaging) 작업에서 실험을 통해 제안된 접근 방식이 서브 그라디언트(subgradient) 방법에 비해 속도와 안정성에서 우수한 성능을 보임을 입증했습니다.



### Attention-Guided Perturbation for Consistency Regularization in Semi-Supervised Medical Image Segmentation (https://arxiv.org/abs/2410.12419)
- **What's New**: 본 논문은 의료 이미지 분할에서 반감독 학습(semi-supervised learning)의 새로운 접근법인 주의 기반의 왜곡 전략(attention-guided perturbation strategy)을 제안합니다.

- **Technical Details**: 모델의 이미지 및 특징(feature) 수준에서의 주의를 기반으로 왜곡을 추가하여 일관성 정규화(consistency regularization)를 달성합니다. 이 방법은 의료 이미지에 내재된 복잡한 구조와 고차원적 의미(high-dimensional semantics)에 적응할 수 있습니다.

- **Performance Highlights**: 우리의 방법은 ACDC 데이터셋에서 7개 사례 시나리오에서 90.4% Dice 점수를 기록하며 벤치마크 데이터셋에서 최첨단 성능(state-of-the-art results)을 달성했습니다.



### Triplet: Triangle Patchlet for Mesh-Based Inverse Rendering and Scene Parameters Approximation (https://arxiv.org/abs/2410.12414)
Comments:
this https URL

- **What's New**: 이번 연구에서는 Triangle Patchlet (약칭 Triplet)라는 새로운 프레임워크를 도입하여, 라디언스 필드(radiance field)에서 물리적 장면 속성을 효과적으로 추정할 수 있는 메쉬 기반(representation) 접근 방식을 제안합니다.

- **Technical Details**: Triplet은 무작위로 생성된 포인트나 카메라 캘리브레이션(camera calibration)에서 얻은 희소 포인트를 사용하여 조립되며, 각 면은 독립적인 요소로 취급됩니다. 물리적 상호작용을 시뮬레이션하고 전통적인 그래픽 렌더링 기술(기법)인 래스터화(rasterization)와 레이 트레이싱(ray tracing)을 사용하여 장면 매개변수를 최적화합니다.

- **Performance Highlights**: 본 프레임워크는 사전 정보 없이도 라이트(light), 재료(materials), 지오메트리(geometry)를 정확하게 추정할 수 있으며, 뛰어난 시각적 품질(visual quality)과 고품질 지오메트리 및 정확한 재료 특성을 재구성할 수 있음을 실험을 통해 입증하였습니다.



### AdaCropFollow: Self-Supervised Online Adaptation for Visual Under-Canopy Navigation (https://arxiv.org/abs/2410.12411)
- **What's New**: 본 연구에서는 자율주행 농업 로봇의 자가 감독(Self-Supervised) 온라인 적응 방법을 제안합니다. 이 방법은 세미틱 키포인트(Semantic Keypoint) 표현을 시각적 기본 모델(Visual Foundational Model), 기하학적 사전(Geometric Prior), 그리고 유사 라벨링(Pseudo Labeling)을 사용하여 조정합니다.

- **Technical Details**: 주요 내용은 세미틱 키포인트 표현을 기반으로 한 인지 시스템을 향상시키기 위한 새로운 접근법을 제시하는 것입니다. 연구팀의 사전 연구에서는 지도 학습(Supervised Learning) 기반의 모델이 특정 필드 조건에서 실패율이 높았음을 보여주었으며, 이로 인해 도메인 변화(Domain Shift)에 적응하는데 한계가 있었던 점을 지적했습니다.

- **Performance Highlights**: 예비 실험 결과에 따르면, 최소한의 데이터와 매개변수 튜닝(Fine-tuning)으로 소스 도메인에서 학습된 키포인트 예측 모델이 자가 감독 방식으로 다양한 도전적인 목표 도메인에 적응할 수 있음을 확인했습니다. 이는 로봇 컴퓨터 상에서 완전 자율적인 행(Row) 추적 기능을 가능하게 합니다.



### De-Identification of Medical Imaging Data: A Comprehensive Tool for Ensuring Patient Privacy (https://arxiv.org/abs/2410.12402)
- **What's New**: 본 논문에서는 의료 이미징 데이터의 익명화를 위해 다양한 형식의 데이터를 처리할 수 있는 오픈 소스 도구를 개발하였습니다. 이 도구는 DICOM, MRI, CT 및 Whole Slide Images (WSI) 등의 데이터 형식을 지원하며, 텍스트 제거를 위한 신경망이 포함되어 있습니다.

- **Technical Details**: 제안된 도구는 의료 이미지 데이터의 메타데이터를 익명화하고 두개골 제거(Skull-stripping) 작업을 수행합니다. DICOM 파일은 미리 정의된 규칙에 따라 메타데이터가 수정되며, NIfTI 파일 헤더는 버려진 후 두개골이 제거됩니다. 이 도구는 python3 CLI 애플리케이션 및 독립 실행형 도커 컨테이너 형태로 제공됩니다.

- **Performance Highlights**: 개발된 도구는 MRI, CT 및 WSI DICOM 파일을 포함한 다양한 데이터 유형을 익명화할 수 있으며, 고유의 두개골 제거 알고리즘을 통해 효율성을 극대화합니다. 학습 데이타셋으로는 Neurofeedback Skull-stripped (NFBS) 및 Calgary-Campinas-359 (CC-359) 등이 사용되었습니다.



### Improved Anomaly Detection through Conditional Latent Space VAE Ensembles (https://arxiv.org/abs/2410.12328)
Comments:
          13 pages of main article, 19 pages including references and appendix, 4 figures

- **What's New**: 본 논문에서는 anomal detection을 위해 조건부 잠재 공간 변분 오토인코더(Conditional Latent space Variational Autoencoder, CL-VAE)를 제안합니다. 이 방법은 데이터의 정보를 기준으로 잠재 공간의 분리를 향상시킵니다.

- **Technical Details**: 제안된 CL-VAE는 각 클래스에 고유한 prior distribution을 적합시켜 Gaussian mixture model까지 포함하는 전통적인 VAE의 prior distribution을 확장합니다. 이 VAE들의 앙상블이 잠재 공간에서 결합되어 그룹 합의를 형성함으로써 anomaly detection의 정확성을 크게 향상시킵니다.

- **Performance Highlights**: CL-VAE는 MNIST 데이터셋에서 97.4%의 AUC를 달성하여 두 번째로 우수한 모델의 95.7%보다 높은 anomaly detection 정확도를 보입니다. 또한 앙상블 효과, 더 해석 가능한 잠재 공간, 복잡한 데이터에서의 패턴 학습 능력이 증가하였다.



### PAPL-SLAM: Principal Axis-Anchored Monocular Point-Line SLAM (https://arxiv.org/abs/2410.12324)
Comments:
          8 pages, 4 figures

- **What's New**: 본 논문에서는 point-line SLAM 시스템에서 선(line) 구조 정보의 활용과 선 최적화 문제를 함께 해결하는 새로운 방법을 제안하고 있습니다. 이 방법은 유사한 방향을 가진 선을 주요 축(principal axis)에 고정하고, $n$개의 선에 대해 $n+2$ 파라미터로 최적화함으로써 두 문제를 동시에 해결합니다.

- **Technical Details**: 제안된 방법은 장면 구조(scene structural) 정보를 고려하여 여러 세계 가설(world hypotheses)에 쉽게 확장될 수 있으며, 최적화해야 할 선 파라미터의 수를 크게 줄여 빠르고 정확한 매핑(mapping)과 추적(tracking)을 가능하게 합니다. 또한, 시스템의 견고함을 강화하고 불일치를 피하기 위해 선 축(line-axis) 확률적 데이터 연관(probabilistic data association) 모델링을 수행하고, 축 생성(creation), 업데이트(update), 및 최적화를 위한 알고리즘을 제공하고 있습니다. 실세계 장면이 Atlanta World 가설에 대체로 부합한다는 점을 고려하여, 수직 우선(vertical priors) 및 소실점(vanishing points) 기반의 구조적 선 탐지 전략을 제공합니다.

- **Performance Highlights**: 다양한 실내 및 실외 데이터셋에 대한 실험 결과 및 ablation 연구를 통해 제안된 시스템의 효과성이 입증되었습니다.



### DAT: Improving Adversarial Robustness via Generative Amplitude Mix-up in Frequency Domain (https://arxiv.org/abs/2410.12307)
- **What's New**: 이번 연구에서는 적대적 훈련(Adversarial Training, AT) 기법을 통해 딥 신경망(Deep Neural Networks, DNNs)의 적대적 공격(adversarial attacks)에서의 내구성 강화에 대한 새로운 접근방법을 제안합니다. 특히, 주파수 스펙트럼의 위상(phase) 패턴에 초점을 맞추어 모델의 분류 성능을 향상시키는 방법을 탐구합니다.

- **Technical Details**: 본 연구에서 제안하는 Optimized Adversarial Amplitude Generator (AAG)는 적대적 예제(adversarial examples, AEs)가 모델에 미치는 영향을 최소화하면서도, 훈련 샘플의 주파수 스펙트럼의 진폭(amplitude)을 전환하여 위상 패턴을 보호합니다. 이를 기반으로 새롭게 설계된 Dual Adversarial Training (DAT) 전략은 효율적인 AE 생성 절차와 함께 사용됩니다.

- **Performance Highlights**: 실험 결과, 제안된 DAT 전략은 다양한 데이터셋에서 여러 적대적 공격에 대한 강력한 내구성을 보여주었으며, 모델의 전반적인 성능이 유의미하게 향상됨을 나타냅니다.



### Consistency Calibration: Improving Uncertainty Calibration via Consistency among Perturbed Neighbors (https://arxiv.org/abs/2410.12295)
- **What's New**: 이번 논문에서는 딥러닝 응용 분야에서 모델의 보정을 위한 새로운 개념인 Consistency (일관성)을 도입합니다. 이는 대규모 언어 모델(LLM)에서 영감을 얻었으며, 기존의 신뢰 기반 관점에 비해 다양한 장점을 강조합니다.

- **Technical Details**: Consistency Calibration (CC)라는 새로운 사후 보정 방법을 제안하고, 이는 변화된 입력에 대한 모델의 일관성을 기반으로 신뢰도를 조정합니다. CC는 추가적인 데이터 샘플이나 레이블 정보를 요구하지 않으며, 소스 데이터에서 직접 입력 변화를 생성합니다. 또한, logit 수준에서의 변화를 수행함으로써 계산 효율성을 크게 개선합니다.

- **Performance Highlights**: CIFAR-10, CIFAR-100 및 ImageNet과 같은 표준 데이터셋뿐만 아니라 ImageNet-LT와 같은 긴 꼬리 데이터셋에서도 다양한 사후 및 학습 시간 보정 방법과 비교하여 최첨단 성능을 입증했습니다.



### Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting (https://arxiv.org/abs/2410.12284)
- **What's New**: 이번 연구는 자연어 설명(NLE), 주목지도(saliency mapping), 두 가지 설명 방식의 조합이 실제 의료 현장에서 AI와 협력하여 가슴 X선 분석을 수행하는 의료 종사자들에게 미치는 영향을 대규모 사용자 연구로 평가한 내용을 다룹니다. 연구 결과, 언어 기반 설명이 과도한 의존성을 초래함을 발견하였고, 주목지도와 결합했을 때 그 단점을 완화할 수 있음을 확인했습니다.

- **Technical Details**: 이 연구는 85명의 의료 종사자를 대상으로 진행되었으며, 각각 80개의 독특한 이미지를 분석했습니다. 연구에서는 주목지도, 자연어 설명 및 두 가지 설명의 조합을 포함하여 네 가지 다양한 CDSS(Clinical Decision Support System) 설정에서 수행되었습니다. 조건이 불완전한 AI 및 XAI 환경에서 다양한 설명 유형이 사용자의 행동에 미치는 영향을 조사했습니다.

- **Performance Highlights**: 결과적으로, 설명의 질은 유용성에 중요한 영향을 미쳤으며, 설명 정확도가 AI 정확도와 일치할 때 사용자에게 긍정적인 영향을 미치는 것으로 나타났습니다. 특히, 주목지도와 자연어 설명의 조합은 설명 유형 중 가장 유용한 것으로 평가되었습니다. 반면 AI와 설명의 정확도가 불일치할 경우, 사용자 성능에 부정적인 영향을 미칠 수 있음을 걸러냈습니다.



### Advancing Healthcare: Innovative ML Approaches for Improved Medical Imaging in Data-Constrained Environments (https://arxiv.org/abs/2410.12245)
Comments:
          7 pages, 7 figures

- **What's New**: 이 논문은 의료 산업에서 희귀 질환으로 인해 발생하는 데이터 부족 문제를 해결하기 위한 새로운 프레임워크인 CAT-U-Net을 소개합니다.

- **Technical Details**: CAT-U-Net은 대규모 데이터셋 없이 의료 이미지에서 특징 추출을 향상시키는 새로운 접근법으로, 다운샘플링(downsampling) 부분과 추가 연결(concatenation) 레이어를 도입하여 제한된 데이터로부터 학습 능력을 향상시킵니다.

- **Performance Highlights**: 제안된 프레임워크는 다양한 의료 조건 데이터셋(COVID-19, 뇌종양, 손목 골절 등)을 사용하여 검증되었으며, 약 98%의 재구성 정확도와 0.946에 가까운 Dice 계수를 달성했습니다.



### OMCAT: Omni Context Aware Transformer (https://arxiv.org/abs/2410.12109)
Comments:
          Demo page: this https URL

- **What's New**: 대규모 언어 모델(LLMs)의 진전을 바탕으로 새로운 데이터셋(OCTAV)과 모델(OMCAT)을 발표하였습니다. 이 모델은 시청각 기반 질문 응답(task)에서 우수한 성능을 발휘합니다.

- **Technical Details**: OCTAV(Omni Context and Temporal Audio Video)는 소리 이벤트를 통해 비디오에서 발생하는 사건의 전환을 캡처하는 혁신적인 데이터셋입니다. OMCAT(Omni Context Aware Transformer)는 RoTE(Rotary Time Embeddings)를 활용하여 시각 및 청각 데이터를 위한 통합 모델을 제공합니다.

- **Performance Highlights**: OMCAT는 AVQA(Audio-Visual Question Answering) 작업 및 OCTAV 벤치마크에서 최첨단 성능을 보여주며, 시간적 추론과 시청각 정렬에서 의미 있는 개선을 기록했습니다.



### V3D-SLAM: Robust RGB-D SLAM in Dynamic Environments with 3D Semantic Geometry Voting (https://arxiv.org/abs/2410.12068)
- **What's New**: 본 논문에서는 진전된 SLAM 기술인 V3D-SLAM을 제안하여, 동적 환경에서 카메라 위치 추정과 맵 생성의 정확성을 높이기 위한 혁신적인 접근법을 보여줍니다. 이 방법은 움직이는 객체와 정적인 객체를 구분하고, 3D 형태와 동역학을 이해하여 이동 객체의 영향을 최소화하는 데 중점을 둡니다.

- **Technical Details**: V3D-SLAM은 Hough voting 메커니즘을 활용하여 동적 객체를 구분하고, Chamfer 거리(Chamfer distances)를 사용하여 정적 객체의 동적 노이즈를 탐지합니다. 실험은 TUM RGB-D 벤치마크 데이터 세트를 기반으로 하며, V3D-SLAM은 최신 SLAM 방법들보다 더 높은 성능을 보였음을 입증했습니다.

- **Performance Highlights**: 우리의 실험 결과 V3D-SLAM은 TUM RGB-D 벤치마크에서 동적 시퀀스에 대해 보다 높은 정확도를 보여주었고, 불필요한 노이즈를 효율적으로 제거함으로써 전통적인 SLAM 방법보다 우수한 성능을 달성했습니다.



### Learned Neural Physics Simulation for Articulated 3D Human Pose Reconstruction (https://arxiv.org/abs/2410.12023)
- **What's New**: 이번 논문에서는 사람의 움직임을 동적으로 모델링하기 위해 새로운 신경망 접근 방식인 LARP (Learned Articulated Rigid body Physics)를 제안합니다. 전통적인 물리 시뮬레이터의 대안으로 빠르고 편리한 방법론을 개발하는 데 목표를 두었습니다.

- **Technical Details**: LARP는 관절이 있는 강체 동역학을 정확하게 시뮬레이트하기 위해 순환 신경망(RNN)과 명시적 상태 집계를 사용하여 물리적 매개변수를 모델링합니다. 각 객체 타입마다 MLP(다층 퍼셉트론)를 정의하고, 충돌 효과를 처리하기 위해 충돌 서브 네트워크를 채택하여 다른 객체와의 상호작용을 모델링합니다.

- **Performance Highlights**: LARP는 전통적인 물리 시뮬레이터보다 최대 10배 빠르게 인간 모션 궤적을 계산할 수 있으며, 기존 비디오 기반 복원 프레임워크에 통합하여 3D 인간 포즈 재구성의 정확성을 비교하거나 더 나은 성능을 보여줍니다. 이 모델은 훈련 세부 사항 및 데이터 증강 방법에 따라 성능의 차이가 크게 발생합니다.



### DDIL: Improved Diffusion Distillation With Imitation Learning (https://arxiv.org/abs/2410.11971)
- **What's New**: 본 논문에서는 ‘모방 학습(Imitation Learning)’ 프레임워크 내에서의 확산 디스틸레이션(Diffusion Distillation) 접근법을 제안하여, 확산 모델의 훈련 분포를 개선하였음을 발표합니다. 이는 데이터 분포(Forward Diffusion)와 학생이 유도한 분포(Backward Diffusion)를 모두 고려하여 이루어집니다.

- **Technical Details**: 제안된 DDIL( Diffusion Distillation within Imitation Learning) 접근법은 ‘DAgger’ 프레임워크를 통해 데이터 집합 내에서 데이터 분포와 학생 유도 분포 모두에서 디스틸레이션을 수행하여 예측 분포의 집합적 품질을 개선하는 것을 목표로 합니다. 이 과정에서 데이터 분포의 지원을 위반하지 않도록 임계값 설정을 도입하였으며, 이는 ‘반사 확산(Reflected Diffusion)’ 공식을 사용하여 Covariate Shift 문제를 완화합니다.

- **Performance Highlights**: DDIL 접근법은 다양한 샘플을 생성하며, 프로그레시브 디스틸레이션(Progressive Distillation), 잠재 일관성 모델(Latent Consistency Model), 분포 매칭 디스틸레이션(Distribution Matching Distillation)과 같은 여러 디스틸레이션 기법에서 일관되게 성능을 향상시키는 결과를 보여주었습니다.



### Comparing Zealous and Restrained AI Recommendations in a Real-World Human-AI Collaboration Task (https://arxiv.org/abs/2410.11860)
Comments:
          15 pages, 14 figures, accepted to ACM CHI 2023

- **What's New**: 이번 연구는 AI를 활용한 의사결정 시스템 설계에서 precision (정밀도)와 recall (재현율) 간의 Tradeoff를 조정하여 인간-AI 팀의 성과를 높이는 방법을 제시합니다. 특히, 영상 익명화 작업을 통해 유의미한 결과를 도출하였습니다.

- **Technical Details**: 본 연구는 78명의 전문가 주석가가 3,466시간 이상에 걸쳐 AI 지원 없이, high-precision 'restrained' AI 그리고 high-recall 'zealous' AI의 지원을 받으며 수행한 영상 주석 작업을 분석하였습니다. 이를 통해 각 AI 시스템의 성능을 비교하고, recall에 중점을 둔 zealous AI가 인간 작업자에게 더 높은 Recall과 짧은 작업 완료 시간을 제공함을 확인했습니다.

- **Performance Highlights**: 연구 결과, zealous AI와 함께 작업한 팀은 Recall이 크게 향상되었으며, 더 빠른 작업 완료 시간을 기록했습니다. 또한, restrained AI에서 훈련된 주석가는 AI의 지원이 없는 상태에서 부정적 영향을 받는 경향을 보였습니다.



### Method for Evaluating the Number of Signal Sources and Application to Non-invasive Brain-computer Interfac (https://arxiv.org/abs/2410.11844)
Comments:
          13 pages, 8 figures

- **What's New**: 이 논문에서는 Brain-Computer Interface (BCI)에서 수집된 데이터를 분석하기 위한 수학 이론과 Time Series Unfolding 방법을 소개합니다. 특히 비침습적 BCI에서의 신호 소스의 수를 추정하는 방법론을 제안합니다.

- **Technical Details**: 논문에서는 뇌를 신호 생성기로 간주하고, 이러한 신호 생성기들이 폴리하모닉 신호 형태로 모델링된다고 설명합니다. 데이터 분석을 위해 Second-order differential equation을 기반으로 하며, Time Series Multidimensional Unfolding (TSMU) 방법을 통해 비선형 곡선을 사용하여 시간 시퀀스 데이터를 분석합니다.

- **Performance Highlights**: 제안된 접근법의 효율성은 저자에 의해 개발된 비침습적 뇌-컴퓨터 인터페이스에서 기록된 데이터를 분석하여 입증되었습니다. 이 방법을 통해 활성 뇌 오실레이터(oscillator)의 수를 정확하게 추정할 수 있는 가능성을 보여줍니다.



### MoH: Multi-Head Attention as Mixture-of-Head Attention (https://arxiv.org/abs/2410.11842)
Comments:
          23 pages, code: this https URL

- **What's New**: 본 연구에서는 Transformer 모델의 핵심인 multi-head attention 메커니즘을 개선하여 효율성을 높이고 이전의 정확도 수준을 유지하거나 초과하는 방법을 제안합니다. 주목할 점은 모든 attention head가 동일한 중요도를 가지지 않는다는 인식에 기반하여 Mixture-of-Head attention (MoH)이라는 새로운 아키텍처를 제안합니다.

- **Technical Details**: MoH는 각 토큰이 적절한 attention heads를 선택할 수 있도록 하여 추론 효율성을 향상시킵니다. 또한 MoH는 multi-head attention의 일반적인 합산을 가중 합산으로 대체하여 attention 메커니즘에 유연성을 추가하고 성능 잠재력을 높입니다. 우리는 ViT, DiT 및 LLMs와 같은 다양한 모델 프레임워크에서 MoH의 성능을 평가하였습니다.

- **Performance Highlights**: MoH는 단지 50%-90%의 attention heads를 사용하여 multi-head attention을 능가하는 성능을 달성하였습니다. 예를 들어, MoH-ViT-B는 ImageNet-1K 분류 기준에서 84.9%의 Top-1 정확도를 기록하며, LLaMA3-8B 모델과의 비교에서 2.4%의 성능 향상을 보였습니다.



### High-Resolution Frame Interpolation with Patch-based Cascaded Diffusion (https://arxiv.org/abs/2410.11838)
Comments:
          Project page: this https URL

- **What's New**: 본 논문에서는 매우 고해상도 입력 및 복잡한 동작을 처리하는 데 어려움을 겪고 있는 기존의 프레임 보간(Frame Interpolation) 방법의 문제를 해결하기 위해 새로운 패치 기반의 캐스케이드 픽셀 확산 모델인 HiFI를 소개합니다. HiFI는 다양한 조건에서 우수한 성능을 보여주며, 특히 8K 해상도에서 유용하게 적용됩니다.

- **Technical Details**: HiFI는 동작에 따라 해상도를 조절하는 대신 고정된 해상도에서 항상 확산 작업을 수행하고, 입력 및 이전 솔루션의 패치를 처리하여 업샘플링 하는 기술을 채택합니다. 이를 통해 메모리 사용량을 크게 줄일 수 있으며, 단일 모델로 프레임 보간과 공간 업샘플링을 동시에 처리하여 학습 비용을 절감할 수 있습니다.

- **Performance Highlights**: HiFI는 Vimeo, Xiph, X-Test, SEPE-8K와 같은 여러 벤치마크에서 최첨단 성능을 보여주었으며, 특히 복잡한 반복 텍스처와 대규모 동작이 포함된 경우에는 기존의 기준 성능을 크게 초월하였습니다. 또한 새로운 데이터셋인 대규모 동작 및 반복 텍스처(LaMoR)를 도입하여 도전적인 사례에서 HiFI의 우수한 성능을 입증하였습니다.



### On the Effectiveness of Dataset Alignment for Fake Image Detection (https://arxiv.org/abs/2410.11835)
- **What's New**: 이 논문에서는 Latent Diffusion Models (LDMs)을 사용하여 가짜 이미지 감지를 위한 새로운 접근법을 제안합니다. 특히, 기존의 데이터셋 디자인 방식을 개선하여 더 강력한 감지기를 훈련하는 방법을 제시합니다.

- **Technical Details**: 기존의 작업들은 주로 네트워크 아키텍처와 훈련 방법에 집중했지만, 이 연구는 정렬된 real/fake 이미지 데이터셋의 중요성을 강조합니다. LDM의 autoencoder를 사용하여 실제 이미지를 재구성하고 이러한 재구성된 이미지와의 차이를 학습하여, 모델이 LDM decoder의 아티팩트를 판별하도록 하였습니다.

- **Performance Highlights**: 이 방법은 10배 더 저렴한 비용으로 기존의 최첨단 방법들과 유사하거나 더 나은 성능을 보였습니다. 새로운 데이터셋을 사용하여 트레이닝한 감지기는 스푸리어스 패턴에 덜 초점을 맞추는 것으로 확인되었습니다.



### CoTracker3: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos (https://arxiv.org/abs/2410.11831)
- **What's New**: CoTracker3는 새로운 포인트 추적 모델로, 간단하고 데이터 효율적인 아키텍처 및 세미-슈퍼바이즈(semisupervised) 훈련 프로토콜을 도입합니다. 이 모델은 기존의 복잡한 구성 요소를 제거하면서도, 실시간 비디오에서 라벨이 없는 데이터로 훈련할 수 있도록 합니다.

- **Technical Details**: CoTracker3는 최근의 포인트 추적기에서 받은 아이디어를 바탕으로 단순하고 유연한 아키텍처를 갖추고 있습니다. 이 모델은 기존의 글로벌 매칭(global matching) 단계를 제거하고, 반복 업데이트(Iterative Updates)와 CNN(convolutional neural networks)의 특징을 통합하여 예상되는 비디오를 효과적으로 추적합니다.

- **Performance Highlights**: CoTracker3는 TAP-Vid 및 Dynamic Replica 벤치마크에서 BootsTAPIR보다 유의미하게 성능이 개선되었으며, 1,000배 적은 양의 라벨이 없는 비디오로 높은 정확도를 달성했습니다. 또한, CoTracker3는 시각적으로 가려진 포인트를 안전하게 추적하는 기능을 포함하고 있습니다.



### MMFuser: Multimodal Multi-Layer Feature Fuser for Fine-Grained Vision-Language Understanding (https://arxiv.org/abs/2410.11829)
Comments:
          11 pages, 6 figures, technical report

- **What's New**: 이 논문에서는 Multi-Layer Feature Fuser (MMFuser)를 제안하여 Vision Transformers에서 깊이 및 얕은 특징을 효율적으로 통합하여 시각적 표현을 개선하는 방법을 탐구합니다.

- **Technical Details**: MMFuser는 세밀하게 조정된 깊은 특징을 쿼리로 사용하여 얕은 특징에서 필요한 세부 정보를 동적으로 추출합니다. 이를 통해 시맨틱 정렬을 유지하면서도 세세한 정보를 풍부하게 포함할 수 있습니다.

- **Performance Highlights**: MMFuser를 LLaVA-1.5 모델에 적용한 결과, 대부분의 멀티모달 벤치마크에서 성능을 크게 향상시켰으며, 특정 태스크에서 기존 모델보다 3.8, 53.9, 2.2 포인트의 개선을 보여주었습니다.



### Analysis and Benchmarking of Extending Blind Face Image Restoration to Videos (https://arxiv.org/abs/2410.11828)
Comments:
          Accepted by TIP'2024; Project page: this https URL

- **What's New**: 최근 블라인드 얼굴 복원(blind face restoration) 기술의 진전으로 정적인 이미지에서 고품질의 복원된 결과를 얻는 데 성공하였습니다. 그러나 비디오 시나리오로의 확장은 거의 없었으나, 이 논문에서 우리는 실제 환경의 저품질 얼굴 비디오 벤치마크(RFV-LQ)를 소개하여 비디오 복원 알고리즘의 비교를 가능하게 하였습니다.

- **Technical Details**: 블라인드 얼굴 복원은 저하된 얼굴 이미지를 고품질로 복원하는 과업입니다. 본 논문에서는 TCN(Temporal Consistency Network)과 정렬 매끄러움(alignment smoothing)을 결합하여 복원된 비디오에서의 떨림(jitters)과 깜박임(flickering) 문제를 해결하고자 하였습니다. TCN은 현재와 이전 프레임 간의 시간 정보를 포착하기 위한 크로스-어텐션 스윈 트랜스포머 레이어(CASTL)를 포함하고 있습니다.

- **Performance Highlights**: TCN은 기존의 얼굴 이미지 복원 모델에 연계되어 잠재적인 복원 편향을 수정하는 경량화된 플러그 앤 플레이 컴포넌트로, 이전 방법에 비해 처리 시간이 약 3배에서 10배 더 빠릅니다. 또한, extensive experiments를 통해 우리의 제안된 방법이 기존의 시간 일관성 알고리즘보다 우수함을 입증하였습니다.



### KITTEN: A Knowledge-Intensive Evaluation of Image Generation on Visual Entities (https://arxiv.org/abs/2410.11824)
Comments:
          Project page: this https URL

- **What's New**: 본 논문에서는 텍스트-이미지 생성 모델의 진실성(fidelity)을 평가하기 위한 새로운 벤치마크인 KITTEN을 제안하고 있습니다. KITTEN은 실제 시각적 엔티티를 정확히 재현하는 능력을 평가하며, 기존의 평가 방법이 간과해온 면에 집중하고 있습니다.

- **Technical Details**: KITTEN 벤치마크는 Wikipedia에서 문서화된 시각적 엔티티를 기반으로 한 프롬프트를 활용하여 8개의 비주얼 도메인(항공기, 차량, 요리, 꽃, 곤충, 랜드마크, 식물, 스포츠)에 걸쳐 모델의 성능을 평가합니다. 평가에는 자동화된 지표와 세심하게 설계된 인간 평가가 포함됩니다.

- **Performance Highlights**: 최신 텍스트-이미지 모델과 검색 증강(customization) 모델의 성능을 평가한 결과, 대부분의 최첨단 모델이 실제 비주얼 세부사항을 정확히 생성하지 못함을 보여주었습니다. 검색 증강 모델은 참조 이미지를 활용하여 진실성을 조금 향상시킬 수 있었지만, 창의적 텍스트 프롬프트에 따라 새로운 구성을 생성하는 데 어려움을 겪었습니다.



### Improving Long-Text Alignment for Text-to-Image Diffusion Models (https://arxiv.org/abs/2410.11817)
- **What's New**: 이번 연구에서는 기존의 T2I(텍스트-투-이미지) 변환 모델의 한계를 극복하기 위해 LongAlign이라는 새로운 방법을 제안합니다.

- **Technical Details**: LongAlign은 긴 텍스트를 처리하기 위해 세그먼트 수준의 인코딩 방법을 도입하고, 효과적인 정렬 훈련을 위한 분해된 선호 최적화 방법을 포함합니다. 긴 텍스트는 여러 세그먼트로 나뉘어 별도로 처리되어 기존의 인코딩 모델의 최대 입력 길이 제한을 극복합니다.

- **Performance Highlights**: 20시간의 훈련 후, 세그먼트 수준의 인코딩 및 선호 최적화 방법을 적용한 512x512 Stable Diffusion(SD) v1.5 모델이 PixArt-$\alpha$ 및 Kandinsky v2.2와 같은 강력한 모델들을 T2I 정렬에서 초월하는 성능을 보여줍니다.



### Jigsaw++: Imagining Complete Shape Priors for Object Reassembly (https://arxiv.org/abs/2410.11816)
Comments:
          21 pages, 10 figures

- **What's New**: 본 논문에서는 Jigsaw++라는 새로운 generative method(생성 방법)를 소개하며, 이는 3D representation(3D 표현)과 관련된 복잡한 재조립 문제를 해결하기 위해 설계되었습니다.

- **Technical Details**: Jigsaw++는 기존의 방법들이 주로 piecewise information(조각 단위 정보)에 초점을 맞추는 반면, 전체 객체의 형태 정보를 학습합니다. 이 방법은 'retargeting' 전략을 사용하여 기존 조립 방법의 출력을 활용, 완전한 형태 재구성을 생성합니다.

- **Performance Highlights**: Breaking Bad dataset 및 PartNet에 대한 광범위한 평가를 통해 Jigsaw++는 재구성 오류를 줄이고 형상 재구성의 정밀성을 향상시켰으며, 이는 향후 재조립 모델 개발을 위한 새로운 방향을 제시합니다.



### SGEdit: Bridging LLM with Text2Image Generative Model for Scene Graph-based Image Editing (https://arxiv.org/abs/2410.11815)
Comments:
          Accepted by ACM Transactions on Graphics and SIGGRAPH Asia 2024. Project page: this https URL

- **What's New**: 본 논문은 LLM(대형 언어 모델)과 Text2Image 생성 모델을 통합하여 장면 그래프 기반 이미지 편집을 위한 새로운 프레임워크를 소개합니다. 이 통합은 전체 이미지의 무결성을 유지하면서 객체 수준에서의 정밀한 수정과 창의적인 장면 재구성을 가능하게 합니다.

- **Technical Details**: 프레임워크는 두 가지 주요 단계로 구성됩니다: 1) LLM 기반 장면 구문 분석기(scene parser)를 사용하여 이미지의 장면 그래프를 구성하고, 주요 객체와 그 상호 관계 및 세밀한 속성을 캡처합니다. 2) 이미지 편집 단계에서는 LLM 편집 컨트롤러가 특정 영역으로의 편집을 안내하며, 이는 주의 조절(attention-modulated) 확산 편집기에 의해 구현됩니다.

- **Performance Highlights**: 광범위한 실험을 통해 제안된 프레임워크가 기존 이미지 편집 방법에 비해 편집 정밀도 및 장면 미학 면에서 상당한 성과를 보여주는 것을 입증하였습니다.



### Efficient Diffusion Models: A Comprehensive Survey from Principles to Practices (https://arxiv.org/abs/2410.11795)
- **What's New**: 이번 논문은 최근 인기를 끌고 있는 확산 모델(Diffusion Models)에 대한 포괄적이고 심층적인 리뷰를 제공하며, 이러한 모델의 원리와 효율적인 실행 사례를 정리하고 있습니다.

- **Technical Details**: 주요 초점은 아키텍처 디자인(architecture designs), 모델 훈련(model training), 빠른 추론(fast inference), 신뢰할 수 있는 배포(reliable deployment) 등입니다.

- **Performance Highlights**: 연구자들을 위한 이 논문은 효율성을 중시하며, 이론 연구(theoretical research), 알고리즘 이전(algorithm migration), 새로운 시나리오에 대한 모델 적용을 위한 지침을 제공합니다.



### Latent BKI: Open-Dictionary Continuous Mapping in Visual-Language Latent Spaces with Quantifiable Uncertainty (https://arxiv.org/abs/2410.11783)
- **What's New**: 새로운 확률적 매핑 알고리즘인 Latent BKI를 소개합니다. 이 알고리즘은 개방형 어휘 매핑(open-vocabulary mapping)을 가능하게 하며 정량화된 불확실성(quantifiable uncertainty)을 수반합니다. 기존의 매핑 알고리즘은 고정된 의미 범주(set of semantic categories)에 중점을 두어 복잡한 로봇 작업에 대한 적용성이 제한되어 있었으나, Latent BKI는 이를 해결합니다.

- **Technical Details**: Latent BKI는 Vision-Language (VL) 모델에서 파생된 신경 임베딩(neural embeddings)을 단위 간행(voxel map)으로 반복적으로 통합하여 불확실성을 정량화합니다. Bayesian Kernel Inference (BKI)를 통해 인근 관측치의 공간 관계를 활용하여 매핑을 수행합니다. 이 방법은 고정 어휘의 범주 공간에 제한되지 않고 연속적인 매핑을 수행할 수 있도록 확장됩니다.

- **Performance Highlights**: Latent BKI는 MatterPort-3D 및 Semantic KITTI 데이터 세트에서 유사한 명시적 의미 매핑과 VL 매핑 프레임워크와 비교하여 테스트되었으며, 계속 매핑의 확률적 이점을 유지하면서 개방형 사전 쿼리(open-dictionary queries)의 추가 이점을 제공합니다. 실제 실험을 통해 도전적인 실내 환경에서의 적용 가능성을 입증하였습니다.



### Fractal Calibration for long-tailed object detection (https://arxiv.org/abs/2410.11774)
- **What's New**: 이 논문에서는 FRActal CALibration (FRACAL)이라는 새로운 사후 보정(post-calibration) 방법을 제안하여 장기 분포(long-tailed distribution) 객체 감지의 성능을 향상시킵니다. FRACAL은 이미지 공간에서 클래스의 분포를 고려하여 클래스 예측의 확률을 조절하는 로그잇 조정 방법을 개발하여 균형을 이룹니다.

- **Technical Details**: FRACAL은 박스 카운팅(box-counting) 방법을 사용하여 훈련 세트의 모든 객체의 위치 분포를 집계하고, 이를 통해 희귀 클래스의 퍼포먼스를 크게 향상시킵니다. 이 방법은 추가적인 훈련 없이 다양한 모델에 통합될 수 있으며, 사용 중에는 균일하게 분포된 클래스 예측의 확률을 역으로 감소시킵니다.

- **Performance Highlights**: FRACAL은 LVIS 데이터셋에서 희귀 클래스 성능을 최대 8.6% 향상시켰으며, COCO, V3Det, OpenImages와 같은 다른 데이터셋에서도 우수한 일반화 성능을 보였습니다.



### SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding (https://arxiv.org/abs/2410.11761)
- **What's New**: 본 논문에서는 병리학 분야의 첫 번째 비전-언어 보조도구인 SlideChat을 제안합니다. 이는 기가픽셀 수준의 전체 슬라이드 이미지를 이해할 수 있도록 설계되었으며, 다양한 병리학 시나리오에서 복잡한 지시를 처리할 수 있습니다.

- **Technical Details**: SlideChat은 SlideInstruction을 기반으로 훈련되며, 4.2K 개의 WSI 캡션과 176K 개의 VQA 쌍을 포함하는 대규모 다중모델 지시 데이터세트를 사용합니다. SlideChat의 아키텍처는 패치-레벨 인코더, 슬라이드-레벨 인코더, 다중모델 프로젝터 모듈, 대형 언어 모델을 포함합니다.

- **Performance Highlights**: SlideChat은 22개의 작업 중 18개에서 최첨단 성능을 달성하였고, SlideBench-VQA (TCGA)에서 81.17%, SlideBench-VQA (BCNB)에서 54.15%의 정확도를 보였습니다. 또한, 연구 및 개발을 촉진하기 위해 SlideChat, SlideInstruction 및 SlideBench는 오픈 소스 리소스로 제공될 예정입니다.



### POLO -- Point-based, multi-class animal detection (https://arxiv.org/abs/2410.11741)
Comments:
          Published in the CV4Ecology workshop at ECCV 2024

- **What's New**: 이 논문에서는 드론 영상을 기반으로 한 자동화된 야생동물 조사에서의 주석 작업(load)을 줄이기 위해 POLO라는 다중 클래스 객체 탐지 모델을 개발했습니다. POLO는 기존의 YOLOv8 아키텍처의 예측 과정과 손실 함수, 후처리를 효과적으로 수정하여 점(point) 레이블만으로 전체 모델을 학습할 수 있습니다.

- **Technical Details**: POLO는 드론의 수조 조류 영상을 분석하는 데 사용되며, 주요 기술적 특징으로는 두 개의 채널만 사용하여 물체의 중심좌표를 출력하고, 평균 하우스도르프 거리(Average Hausdorff-Distance)와 평균 제곱 오차(Mean Squared Error)를 손실 함수로 적용합니다. YOLOv8의 비슷한 구조를 유지하되, 객체 탐지를 위해 점 레이블을 전적으로 활용한 것에 의의가 있습니다.

- **Performance Highlights**: POLO는 알래스카의 아이젠벡 석호에서 촬영된 드론 영상에서 최대 수천 개의 개체를 포함하는 수조 조류의 숫자를 세는 테스트에서 기존 YOLOv8 모델보다 더 높은 정확도를 기록했습니다. 같은 주석 비용으로 개선된 성능을 보여, 야생동물 조사 노력에 있어 비용 효율성을 높였습니다.



### Patch-Based Diffusion Models Beat Whole-Image Models for Mismatched Distribution Inverse Problems (https://arxiv.org/abs/2410.11730)
- **What's New**: 이번 연구에서는 기존의 diffusion 모델이 데이터 분포가 불일치할 때 발생하는 문제, 즉 single measurement와 small dataset에서의 image reconstruction 문제를 해결하기 위해 patch-based diffusion 모델을 제안합니다. 이 방법은 이미지 분포를 패치 단위로 학습하여 데이터 부족과 분포 불일치에 강한 일반화 능력을 가지고 있음을 보여줍니다.

- **Technical Details**: 연구에서는 두 가지 설정을 다룹니다. 첫째, unknown test distribution에서 단일 측정이 주어지는 경우입니다. 이 경우 우리는 self-supervised loss를 포함시켜 네트워크가 측정값과의 일관성을 유지하도록 돕습니다. 둘째, small dataset이 주어지는 경우로, patch-based 네트워크를 fine-tuning 하여 훨씬 더 나은 prior를 얻습니다. 이 방식은 whole-image 모델에 비해 성능이 우수함을 실험적으로 입증합니다.

- **Performance Highlights**: 실험 결과, patch-based 방법은 두 설정 모두에서 high quality image reconstruction을 달성하며, whole-image 모델보다 우수한 성능을 보입니다. 더불어 large in-distribution training datasets에 접근할 수 있는 방법들과도 경쟁할 수 있는 성과를 인정받았습니다.



### YOLO-ELA: Efficient Local Attention Modeling for High-Performance Real-Time Insulator Defect Detection (https://arxiv.org/abs/2410.11727)
- **What's New**: 이번 논문에서는 기존 무인 항공기(UAV)에서의 절연체 결함 탐지 방법의 한계를 극복하기 위해 새로운 주의 기반 아키텍처인 YOLO-ELA를 제안합니다. 이는 Efficient Local Attention(ELA) 블록을 YOLOv8의 네크 부분에 추가하여 배경 기능에서 결함이 있는 절연체의 기능으로 모델의 주의를 전환합니다.

- **Technical Details**: YOLO-ELA는 고해상도 UAV 이미지에서 절연체 결함 탐지를 개선하기 위해 설계되었습니다. SCYLLA Intersection-Over-Union(SIoU) 기준 함수를 사용하여 탐지 손실을 줄이고 모델의 수렴 속도를 가속화하며, 소형 절연체 결함에 대한 감도를 높여 더 높은 참 긍정 결과를 생성합니다. 또한 데이터 증강 기법을 활용하여 데이터셋의 다양성을 증가시켰습니다.

- **Performance Highlights**: 실험 결과, YOLO-ELA는 96.9% mAP0.5의 최첨단 성능을 달성하고 초당 74.63 프레임의 실시간 탐지 속도를 기록하였습니다. 이는 기존 모델에 비해 현저한 개선을 나타내며, 객체 탐지 작업에서 주의 기반 CNN의 효과를 증명합니다.



### RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation (https://arxiv.org/abs/2410.11722)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 논문에서는 최근 개발된 Segment Anything (SAM)과 같은 대화형 세분화(interactive segmentation) 방법에 대한 사용자 클릭 패턴을 조사하고, 이를 기반으로 한 새로운 벤치마크 RClicks를 제안합니다. 클릭 패턴의 실제 사용에 대한 이해를 바탕으로, 클릭 가능성 모델(clickability model)을 사용하여 보다 현실적인 클릭 샘플을 생성할 수 있도록 합니다.

- **Technical Details**: 연구팀은 475,544개의 실제 사용자 클릭 데이터를 수집하여 대화형 세분화 시나리오에서 클릭 패턴을 분석했습니다. 이 연구는 saliency prediction(주목 예측) 이론을 적용하여 클릭 가능성 모델을 개발하였으며, 해당 모델은 사용자의 클릭 입력과 가장 유사한 샘플을 생성하는 데 초점을 맞추었습니다. RClicks는 기존 세분화 방법의 현실적 클릭에서 성능을 비교할 수 있는 포괄적인 벤치마크로서, (1) 클릭 수집 방법론을 도입하고, (2) 다양한 클릭 샘플링 전략을 사용할 수 있게 합니다.

- **Performance Highlights**: RClicks 벤치마크에 따르면, 기존의 방법들이 보고된 성능에 비해 현실 세계에서 성능이 저하될 수 있으며, 대부분의 방법들이 클릭 패턴에 대해 강건하지 않다는 것을 발견했습니다. 이는 기존 평가 방법이 실제 사용 시의 성능을 과대 평가할 수 있다는 점을 시사합니다. 연구에서는 다양한 세분화 방법의 평균 품질뿐만 아니라 강건성을 평가하였으며, 대화형 세분화 방법들이 모든 데이터셋에서 최적의 성능과 강건성을 동시에 달성할 수 없음을 보였습니다.



### It's Just Another Day: Unique Video Captioning by Discriminative Prompting (https://arxiv.org/abs/2410.11702)
Comments:
          ACCV 2024 Oral. Project page: this https URL

- **What's New**: 본 논문은 Long 비디오에서 중복된 클립에 대해 각 클립을 독자적으로 식별할 수 있는 캡션을 생성하는 문제를 다룹니다. 'Unique Captioning' 또는 고유 캡셔닝 문제를 제기하며, 'Captioning by Discriminative Prompting (CDP)' 방법론을 제안합니다.

- **Technical Details**: CDP는 시각적으로 유사한 클립들 사이의 차이를 판별할 수 있는 속성을 예측하여 고유한 캡션을 생성합니다. 두 가지 벤치마크를 도입하며, 하나는 일상적인 egocentric 영상, 다른 하나는 timeloop 영화에 기반하여 중복되는 행동을 포함한 비디오에서 발생하는 유사성을 활용합니다.

- **Performance Highlights**: CDP 방법이 적용된 캡션은 egocentric 비디오에서 text-to-video R@1 성능을 15% 향상시키고, timeloop 영화에서는 10% 향상시켰습니다.



### Visual Fixation-Based Retinal Prosthetic Simulation (https://arxiv.org/abs/2410.11688)
- **What's New**: 이 연구는 시각적 정지를 기반으로 하는 망막 인공막 시뮬레이션 프레임워크를 제안하였으며, 이 프레임워크는 사카드(saccade) 메커니즘에서 영감을 받아 분류 작업에서 성능 개선을 평가합니다. self-attention map을 활용하여 입력 이미지에서 두드러진 패치를 예측하고, 이를 통해 망막 이식체에 최적화된 시각 정보를 전송하는 방법을 모색합니다.

- **Technical Details**: 본 연구에서는 Vision Transformer(ViT)의 self-attention 메커니즘을 활용하여 입력 이미지의 시각적 정지 시뮬레이션을 수행합니다. 9,469개의 훈련 이미지와 3,925개의 검증 이미지로 구성된 Imagenette 데이터셋을 사용하여 최적화를 진행하며, U-Net 아키텍처를 통해 훈련 가능한 인코더가 설계되었습니다. 또한, DINOv2 모델을 사용하여 두드러진 패치를 예측하고 분류 정확도를 평가하였습니다.

- **Performance Highlights**: 이 프레임워크는 ImageNet 검증 세트의 하위 집합에서 87.72%의 분류 정확도를 달성하였으며, 이는 다운샘플링 방법에 비해 40.59%의 정확도로 크게 향상된 결과입니다. 또한, 제한된 해상도의 망막 이식체에서 더 의미 있는 지각을 생성할 가능성이 있음을 보여주고 있습니다.



### A Survey of Low-shot Vision-Language Model Adaptation via Representer Theorem (https://arxiv.org/abs/2410.11686)
- **What's New**: 본 논문은 low-shot 이미지 인식을 위한 기존 방법들을 통합하고, 이들을 다양한 차원에서 비교할 수 있는 통일된 계산 프레임워크를 제안합니다. 특히, Representer Theorem을 기반으로 하여 기존 연구를 체계적으로 정리하고, 새로운 변형들을 제안합니다.

- **Technical Details**: 제안된 프레임워크는 5개의 구성 요소로 나뉘며: 입력 이미지 인코딩, 앵커 계산, 커널 계산, 로짓 계산, 손실 함수 계산 등이 포함됩니다. 또한, kernel ridge regression (KRR)의 폐쇄형 해법을 활용하여 representers 간의 상관 관계를 모델링합니다.

- **Performance Highlights**: 11개의 공개 데이터셋에서의 광범위한 실험을 통해 제안된 방법의 효과가 검증되었습니다. 특히, 기존 PEFT 방법의 성능을 향상시키기 위한 다양한 변형들이 제안되었고, 실험 결과 이들 변형이 실제로 효과적임을 입증했습니다.



### Leveraging Structure Knowledge and Deep Models for the Detection of Abnormal Handwritten Tex (https://arxiv.org/abs/2410.11670)
- **What's New**: 본 논문에서는 손으로 쓴 텍스트에서 시퀀스 구조의 파괴를 해결하기 위한 두 단계의 감지 알고리즘을 제안합니다. 이 알고리즘은 구조 지식(structure knowledge)과 딥 모델(deep models)을 결합하여 이상한 텍스트를 효과적으로 처리합니다.

- **Technical Details**: 첫 번째 단계에서는 손으로 쓴 텍스트 이미지에서 다양한 구조 프로토타입(prototype)을 대략적으로 위치시킵니다. 두 번째 단계에서는의 결과를 바탕으로 서로 다른 감지 전략이 채택됩니다. 특히, 새로운 반지도 대조 훈련(strategy) 방법에 의해 훈련된 형태 회귀 네트워크(shape regression network)를 사용하여 문자의 위치 관계(positional relationship)를 활용합니다.

- **Performance Highlights**: 실험 결과에 따르면 제안된 방법은 두 가지 손으로 쓴 텍스트 데이터셋에서 감지 성능을 크게 향상시킵니다.



### Degradation Oriented and Regularized Network for Real-World Depth Super-Resolution (https://arxiv.org/abs/2410.11666)
Comments:
          10 pages

- **What's New**: 본 연구에서는 DORNet (Degradation Oriented and Regularized Network)이라는 새로운 방법을 제안하여 실제 세계에서의 Depth Super-Resolution (DSR) 문제를 해결한다. 제안된 방법은 저해상도 깊이(depth) 표현의 손상(degradation) 모델링에 중점을 두어 고해상도 깊이를 복원하는 데 필요한 타겟 가이드를 제공한다.

- **Technical Details**: DORNet은 세 가지 주요 구성 요소로 이루어져 있다: Self-supervised Degradation Learning(DL), Routing Selection-based Degradation Regularization(DR), Degradation Awareness(DA). DL은 저해상도 깊이에 대한 손상 표현을 모델링하며, DR은 다중 스케일 손상 커널을 생성하여 예측된 고해상도 깊이에 적용된다. 마지막으로 DA는 여러 Degradation-Oriented Feature Transformations (DOFT)를 통해 손상 표현에 맞춰 RGB 정보를 깊이에 삽입한다.

- **Performance Highlights**: 실제 및 합성 데이터세트에서의 광범위한 실험 결과, DORNet은 기존의 최첨단 방법들을 초월하는 성능을 달성하며, 고해상도 깊이 복원에 있어 정확하고 완전한 구조를 회복하는 데 성공하였다.



### VisualRWKV-HD and UHD: Advancing High-Resolution Processing for Visual Language Models (https://arxiv.org/abs/2410.11665)
- **What's New**: 본 논문에서는 VisualRWKV 모델 계열의 두 가지 새로운 발전인 VisualRWKV-HD와 VisualRWKV-UHD를 소개합니다. 이 모델들은 고해상도 시각 입력을 효과적으로 처리하도록 설계되었습니다.

- **Technical Details**: VisualRWKV-HD는 손실 없는 다운샘플링 방법을 통해 고해상도 비전 인코더와 저해상도 인코더를 통합합니다. VisualRWKV-UHD는 이미지를 4개의 세그먼트로 나눈 후 다시 조합하여 고해상도 및 저해상도 특징을 모두 포함할 수 있도록 합니다.

- **Performance Highlights**: 이 두 모델은 VLM 벤치마크에서 강력한 성능을 발휘하며, 텍스트가 풍부한 작업에서 성능이 크게 향상되었습니다. 특히 VisualRWKV-UHD는 최대 4096 x 4096 픽셀 해상도를 지원하여 보다 상세하고 포괄적인 시각 처리 능력을 제공합니다.



### RS-MOCO: A deep learning-based topology-preserving image registration method for cardiac T1 mapping (https://arxiv.org/abs/2410.11651)
- **What's New**: 본 논문은 심장 T1 맵핑에서의 모션 보정을 위한 심층 학습 기반의 이미지 등록 프레임워크를 제안합니다. 특히, BLOC이라는 암묵적 일관성 제약 조건을 도입하여 이미지의 위상을 어느 정도 유지합니다.

- **Technical Details**: 제안된 방법은 비 지도학습 방식인 심장 심실 분할 네트워크와 이중 도메인 주의 모듈을 통합하여 심장 T1 가중 이미지의 모달리티 간 등록의 성능을 향상시킵니다. 이중 일관성 제약과 지역 안티 폴딩 제약을 포함한 BLOC 제약 조건이 등록의 넌리니아(Non-Rigid) 특성을 보장합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 기존의 방법들에 비해 뛰어난 성능과 높은 견고성을 입증하였으며, 특히 모션 보정 효과의 향상에 기여함을 보여주었습니다.



### ED-ViT: Splitting Vision Transformer for Distributed Inference on Edge Devices (https://arxiv.org/abs/2410.11650)
Comments:
          14 pages, 8 figures

- **What's New**: 이 논문에서는 자원 제한이 있는 엣지 디바이스에서 복잡한 Vision Transformer 모델을 효율적으로 실행하기 위해 ED-ViT라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 Vision Transformer 모델을 데이터 클래스의 특정 부분을 처리하는 여러 서브 모델로 분할합니다.

- **Technical Details**: ED-ViT는 Vision Transformer 모델을 여러 서브 모델로 나누는 구조를 가지고 있으며, 각 서브 모델은 지정된 데이터 클래스의 하위 집합을 처리합니다. 또한, 클래스별 프루닝(class-wise pruning) 기법을 도입하여 각 서브 모델의 크기를 축소하고, 모델 배치 최적화를 위한 그리디 할당 알고리즘을 설계했습니다. 실험은 세 가지 ViT 구조에 대해 다섯 개의 데이터셋을 사용하여 수행되었습니다.

- **Performance Highlights**: 실험 결과, ED-ViT는 엣지 디바이스에서의 추론 지연을 크게 줄이고, 모델 크기를 최대 28.9배와 34.1배 감소시키면서도 기존 Vision Transformer와 유사한 테스트 정확도를 유지하는 것으로 나타났습니다. ED-ViT는 또한 CNN 및 SNN 모델과의 비교 실험에서 고속 추론과 저성능 모델 크기를 유지하는 장점을 보였습니다.



### Feature-guided score diffusion for sampling conditional densities (https://arxiv.org/abs/2410.11646)
- **What's New**: 이 논문에서는 조건부 밀도(conditional density)를 샘플링하는 새로운 스코어 확산(score diffusion) 알고리즘을 제안합니다. 기존의 방법들은 조건부 밀도의 정확한 스코어를 추정하는 데 어려움이 있었지만, 본 연구는 프로젝션된 스코어(projected score)를 이용하여 이러한 문제를 해결합니다. 또한, 같은 신경망이 스코어와 이미지 특성 벡터(feature vector)를 학습하여, 모든 클래스의 조건부 확률의 유클리드적으로 임베딩된 표현을 제공합니다.

- **Technical Details**: 새로운 알고리즘은 이미지 특성 벡터가 목표 클래스의 특성 벡터 중심(center of the feature vector)으로 향하도록 가이드를 제공합니다. 면밀하게 정의된 이미지 특성 벡터는 네트워크의 선택된 레이어에서 채널 활성화의 공간 평균(spatial averages)으로 이루어집니다. 이러한 접근법은 조건부 밀도를 샘플링하는 데 있어 한 단계씩 스코어를 조정하며, 각각의 단계에서 프로젝션된 스코어를 계산합니다. 학습 과정은 단일 감쇠 손실(denoising loss)의 최적화를 통해 이루어집니다.

- **Performance Highlights**: 제안된 알고리즘은 고품질의 다양한 샘플을 생성할 수 있으며, 각 클래스의 이미지 특성 벡터가 중심 주변에 집중됨을 보여줍니다. 모든 조건부 확률 분포에 대해 유클리드 임베딩을 통해 샘플링을 수행하여, 품질 저하나 다양성 감소 없이 목표 조건부 확률 밀도로부터의 샘플링을 정확히 수행할 수 있음을 확인했습니다. 또한 새로운 클래스의 샘플링이 가능합니다.



### Efficient and Effective Universal Adversarial Attack against Vision-Language Pre-training Models (https://arxiv.org/abs/2410.11639)
Comments:
          11 pages

- **What's New**: 이 논문에서는 Vision-language pre-training (VLP) 모델의 취약성을 극복하기 위한 새로운 방법, 즉 직접 최적화 기반의 Universal Adversarial Perturbations (UAP) 방법인 DO-UAP를 제안합니다. 이 방법은 공격 성능을 유지하면서 자원 소모를 크게 줄이는 데 중점을 두고 있습니다.

- **Technical Details**: DO-UAP는 멀티모달 손실 함수를 설계하고, 유용한 데이터 증강 전략을 도입하여 기존의 생성기 기반 UAP 방법보다 효율적인 성능을 달성합니다. 다양한 VLP 데이터셋과 모델을 사용하여 23배 더 빠른 시간 소모와 우수한 공격 성능을 입증하였습니다.

- **Performance Highlights**: 실험 결과, DO-UAP는 세 개의 벤치마크 VLP 데이터셋과 여섯 개의 인기 있는 VLP 모델에서 뛰어난 성능을 보여줍니다. 특히, 기존 방법에 비해 공격 성능이 더 개선되었으며, 실시간 온라인 애플리케이션에서도 효율적으로 적용될 수 있는 가능성을 보여줍니다.



### Simultaneous Diffusion Sampling for Conditional LiDAR Generation (https://arxiv.org/abs/2410.11628)
- **What's New**: 이 논문은 LiDAR 스캔을 여러 시점에서 본 3D 구조에 조건을 두어 포인트 클라우드를 생성하기 위한 새로운 동시 확산 샘플링 방법론을 제안합니다. 이는 다중 뷰 기하학적 제약을 활용하여 향상된 결과를 제공하는 것을 목표로 합니다.

- **Technical Details**: 제안된 방법은 스캔을 주변의 여러 가상 뷰포인트로 다시 구성하여 다수의 합성 LiDAR 스캔을 생성합니다. 이후, 이 합성 LiDAR 스캔과 입력 LiDAR 스캔은 기하학적 일관성에 따라 조건부 생성 과정을 거칩니다. 이 과정에서 다중 뷰 제약을 활용하여 관심 영역의 생성을 개선합니다.

- **Performance Highlights**: 우리의 방법은 LiDARGen 및 R2DM와 같은 단일 뷰 CLG 기법보다 성능이 크게 향상되어 다양한 벤치마크에서 기존 방법들을 능가하는 정확하고 기하학적으로 일관된 포인트 클라우드 스캔을 생성할 수 있는 것으로 나타났습니다.



### Fast Local Neural Regression for Low-Cost, Path Traced Lambertian Global Illumination (https://arxiv.org/abs/2410.11625)
Comments:
          11 pages, 10 figures, 1 table

- **What's New**: 이번 논문에서는 레이 트레이싱(ray tracing) 가속 하드웨어의 발전에도 불구하고, 상용 하드웨어에서의 실시간 ray budgets가 여전히 제한적이라는 점을 강조합니다. 이를 해결하기 위해, 저희는 독창적인 방법으로 신경망(neural network)을 도입하여 효율적인 로컬 선형 모델 기반 denoiser를 제안합니다.

- **Technical Details**: 저희의 방법은 매우 낮은 샘플 수(1 spp)에서도 람베르시안(Lambertian) 씬의 전역 조명(global illumination)을 신뢰성 있게 재구성할 수 있도록 설계되었습니다. 로컬 선형 회귀 알고리즘을 통해 1080p 해상도에서 서브 밀리세컨드 실행 시간을 기록하며, 신경망을 포함하는 방식으로 품질과 속도가 개선되었습니다. 또한, 주위 차폐(ambient occlusion)를 가이드 채널로 활용하여 성능을 증대시켰습니다.

- **Performance Highlights**: 이번 연구의 성과로, 저희의 방법은 기존보다 더 빠른 실행 속도와 뛰어난 품질을 자랑하며, 특히 저비용 레이 트레이싱 하드웨어에서도 효과적으로 작동합니다. 이 방식은 기존의 신경망 기반 방법보다 훨씬 적은 리소스에서 높은 비주얼 품질을 유지합니다.



### VidEgoThink: Assessing Egocentric Video Understanding Capabilities for Embodied AI (https://arxiv.org/abs/2410.11623)
- **What's New**: 최근 멀티모달 대형 언어 모델(MLLM)의 발전은 구체적인 AI 응용 분야에 새로운 가능성을 열었습니다. 본 논문에서는 Egocentric 비디오 이해 능력을 평가하기 위한 포괄적인 벤치마크인 VidEgoThink를 소개합니다.

- **Technical Details**: VidEgoThink는 비디오 질문-응답(video question-answering), 계층 계획(hierarchy planning), 시각 기초(visual grounding), 보상 모델링(reward modeling)의 네 가지 주요 상호 연관된 작업을 설계하여 Embodied AI에서의 하위 조작과 MLLM 간의 갭을 줄이기 위한 것입니다. 자동 데이터 생성 파이프라인을 활용해 Ego4D 데이터셋을 기반으로 적절한 질문-응답 쌍을 생성합니다. 이 과정에서 GPT-4o의 지능을 활용하고, 생성된 데이터를 인적 평가자를 통해 필터링합니다.

- **Performance Highlights**: 실험 결과 모든 MLLM은 에고센트릭 비디오 이해와 관련된 작업들에서 저조한 성능을 보였습니다. 특히, GPT-4o는 32프레임 및 8프레임에서 각각 31.17%와 32.83%의 정확도를 기록했으며, 타겟 객체와 행동, 장면의 존재를 판단하는 데는 능력이 있지만, 순서나 시퀀스를 평가하는 능력에서 부족함을 보였습니다. 전반적으로, 현시점의 MLLM을 Embodied AI의 1인칭 시나리오에 직접 적용하는 데에는 많은 도전이 남아 있으며, 향후 추가적인 연구가 필요합니다.



### MultiVENT 2.0: A Massive Multilingual Benchmark for Event-Centric Video Retrieva (https://arxiv.org/abs/2410.11619)
- **What's New**: MultiVENT 2.0이란 새로운 대규모 다국어 이벤트 중심 비디오 검색 기준이 도입되었습니다. 이 기준은 218,000개 이상의 뉴스 비디오와 3,906개의 특정 세계 사건을 겨냥한 쿼리를 포함합니다.

- **Technical Details**: 이 데이터셋은 아랍어, 중국어, 영어, 한국어, 러시아어, 스페인어 등 6개 언어의 비디오를 포함하며, 다양한 소스(비주얼 콘텐츠, 오디오, 내장 텍스트, 텍스트 메타데이터)를 활용해야 하는 쿼리가 설계되었습니다.

- **Performance Highlights**: 예비 결과는 현재 최신 비전-언어 모델(Vision-Language Models, VLMs)이 이 작업에서 상당한 어려움을 겪고 있으며, 복합적인 비전-언어 작업을 처리하기 위해 더 강력한 다중 모달 시스템의 필요성을 강조합니다.



### Depth Estimation From Monocular Images With Enhanced Encoder-Decoder Architectur (https://arxiv.org/abs/2410.11610)
- **What's New**: 이번 논문에서는 단일 2D 이미지로부터 깊이를 추정하는 도전 과제를 해결하기 위해 Inception-ResNet-v2를 인코더로 사용하는 새로운 딥러닝 기반 접근 방식을 제안합니다.

- **Technical Details**: 이 모델은 인코더-디코더 아키텍처를 사용하며, Inception-ResNet-v2를 인코더로 활용합니다. 다중 스케일(feature extraction) 특징을 통해 다양한 객체 크기와 거리에서 깊이 예측 정확도를 향상시킵니다. 또한, 깊이 손실(depth loss), 그래디언트 엣지 손실(gradient edge loss), SSIM 손실을 포함하는 복합 손실 함수(composite loss function)를 제안하여, 손실의 가중치를 조정하여 깊이 추정의 다양한 측면에서 균형을 보장합니다.

- **Performance Highlights**: NYU Depth V2 데이터셋에서 실험 결과, 저희 모델은 ARE 0.064, RMSE 0.228, 그리고 정확도($\delta$ $<1.25$) 89.3%를 달성하여 최첨단 성능을 보입니다. 이 지표들은 저희 모델이 복잡한 상황에서도 깊이를 효과적으로 예측할 수 있음을 보여줍니다.



### PaSTe: Improving the Efficiency of Visual Anomaly Detection at the Edg (https://arxiv.org/abs/2410.11591)
Comments:
          13 pages, 6 figures

- **What's New**: 이번 논문에서는 Visual Anomaly Detection (VAD)의 경량화된 접근 방식을 소개하며, 자원 제한이 있는 엣지 디바이스에서의 배치를 가능하게 하는 새로운 알고리즘인 Partially Shared Teacher-student (PaSTe)를 제안합니다. 이 알고리즘은 기존의 Student Teacher Feature Pyramid Matching (STFPM) 접근 방식을 개선하여 메모리와 컴퓨팅 요구 사항을 줄입니다.

- **Technical Details**: VAD는 픽셀 수준의 이상 탐지를 위해 비지도 학습을 이용합니다. 이 논문에서 제안한 PaSTe 알고리즘은 lightweight neural network를 사용하여 메모리 사용량을 87%까지 줄이고, 계산 성능도 50%까지 감소시킵니다. 또한, MVTec 데이터셋을 사용해 엣지 디바이스에서 VAD의 실행 가능성을 검증합니다.

- **Performance Highlights**: PaSTe 알고리즘을 통해 추론 시간은 25% 단축되고, 훈련 시간은 33% 단축됩니다. 훈련 중 최대 RAM 사용량은 76% 감소하여 VAD 프로세스를 실질적으로 더 효율적으로 만들어 엣지 디바이스에서의 실질적인 배치가 가능해졌습니다.



### Breaking Modality Gap in RGBT Tracking: Coupled Knowledge Distillation (https://arxiv.org/abs/2410.11586)
Comments:
          Accepted by ACM MM2024

- **What's New**: 이번 연구에서는 RGB(색상 영상)와 TIR(열 적외선 영상) 간의 modality gap 문제를 해결하기 위해 'Coupled Knowledge Distillation (CKD)' 프레임워크를 제안하고 있습니다. 이는 서로 다른 모달리티에서 공통 스타일을 추구함으로써 높은 성능의 RGBT 추적을 가능하게 합니다.

- **Technical Details**: CKD 프레임워크는 두 개의 학생 네트워크를 도입하여 스타일 특징의 일관성을 높이기 위해 style distillation loss를 적용합니다. 또한, RGB 및 TIR 네트워크를 원래의 teacher로 사용하여 content knowledge를 학생 네트워크에 증류하며, style과 content의 orthogonal feature decoupling 방법을 통해 문제를 해결합니다. 마스킹 모델링 전략과 다중 모달 후보 토큰 제거 전략을 함께 설계하여 추적의 강인성과 효율성을 개선합니다.

- **Performance Highlights**: 제안된 방법은 96.4 FPS의 인상적인 추적 속도를 달성하며, 네 개의 주요 공개 데이터셋에서 state-of-the-art 결과를 기록했습니다. RGBT210, RGBT234, LasHeR 및 VTUAV 데이터셋에서 각각 1.6%/2.7%, 1.6%/3.0%, 3.0%/2.0%, 10.1%/11.1%의 PR/SR 점수 향상을 보였으며, 기존 방법보다 60.2 FPS의 속도 증가를 달성했습니다.



### On-the-fly Modulation for Balanced Multimodal Learning (https://arxiv.org/abs/2410.11582)
Comments:
          Accepted by T-PAMI 2024

- **What's New**: 이번 논문에서는 다중 모달 (multimodal) 학습에서의 성능 향상을 위해 모달 간의 균형을 맞추는 새로운 접근 방식이 제안되었습니다. 기존의 공동 훈련 전략은 모든 모달에 동일한 목표를 두어 균형이 맞지 않는 단일 모달 (uni-modal) 표현이 발생하는 문제를 지적했습니다.

- **Technical Details**: 본 연구에서는 두 가지 새로운 기법인 On-the-fly Prediction Modulation (OPM)과 On-the-fly Gradient Modulation (OGM)을 소개합니다. OPM은 피드포워드 (feed-forward) 단계에서 우세한 모달리티의 영향을 줄이기 위해 동적 확률로 해당 모달의 특징을 무시하고, OGM은 역전파 (back-propagation) 단계에서 그라디언트를 완화하여 최적화 과정을 조절합니다.

- **Performance Highlights**: 제안된 방법들은 다양한 다중 모달 작업에서 눈에 띄는 성능 향상을 보여주었습니다. 이 단순하면서도 효과적인 전략은 일반 및 작업 지향적인 다중 모달 모델뿐 아니라, 보다 복잡한 다중 모달 작업에서도 효과성과 유연성을 입증했습니다.



### LCD-Net: A Lightweight Remote Sensing Change Detection Network Combining Feature Fusion and Gating Mechanism (https://arxiv.org/abs/2410.11580)
- **What's New**: 이번 연구에서 제안된 Lightweight Remote Sensing Change Detection Network (LCD-Net)는 원격 감지 이미지 변화 탐지 분야에서 전통적인 CNN 기반 방법의 단점을 극복하기 위해 모델 크기와 계산 비용을 줄이면서도 높은 탐지 성능을 유지하도록 설계되었습니다.

- **Technical Details**: LCD-Net은 이중 시계열(bitemporal) 이미지에서 특징을 효율적으로 추출하기 위해 MobileNetV2를 인코더로 사용합니다. 이 모델은 Temporal Interaction and Fusion Module (TIF)을 통해 이중 시계열 특징 간의 상호작용을 향상시켜 시간적인 맥락 인식(temporal context awareness)을 개선합니다. 또한, Feature Fusion Module (FFM)은 다중 스케일(features) 특징을 집계하여 미세한 변화를 포착하는 동시에 배경 노이즈를 억제합니다. 디코더에서 Gated Mechanism Module (GMM)은 채널 가중치를 동적으로 조정하여 주요 변화 영역을 강조하는 방식으로 특징 학습을 향상시킵니다.

- **Performance Highlights**: LCD-Net은 LEVIR-CD+, SYSU, S2Looking 데이터셋에서 실험한 결과, 단 2.56M의 파라미터와 4.45G FLOPs로 경쟁력 있는 성능을 달성하였으며, 자원이 제한된 환경에서 실시간 응용 프로그램에 적합한 모델임을 입증했습니다.



### PSVMA+: Exploring Multi-granularity Semantic-visual Adaption for Generalized Zero-shot Learning (https://arxiv.org/abs/2410.11560)
Comments:
          Accepted to TPAMI 2024. arXiv admin note: text overlap with arXiv:2303.15322

- **What's New**: 본 논문에서는 Generalized Zero-Shot Learning (GZSL)에서 시각적 특성과 속성 의미 특성 간의 상호작용을 활용하여 보지 못한 범주를 파악하기 위한 방법을 제안합니다. 기존 GZSL의 단점인 시각-의미 상응 부족 문제를 해결하기 위해, 다중-그래뉼러리 진행적 의미-시각 상호적응 네트워크(PSVMA+)를 개발했습니다.

- **Technical Details**: PSVMA+ 네트워크는 서로 다른 그래뉼러리(Granularity) 수준에서 의미-시각 상호작용을 탐색하여, 시각적 요소를 충분히 수집하도록 설계되었습니다. 각 그래뉼러리 수준에서 이중 의미-시각 트랜스포머 모듈(DSVTM)을 사용하여 공유 속성을 인스턴스 중심 속성으로 다시 구성하고, 의미 관련 시각 영역을 집계하여 모호하지 않은 시각적 특징을 학습합니다. 이 과정에서 선택적 교차 그래뉼러리 학습을 활용하여 신뢰할 수 있는 그래뉼러리로부터 지식을 활용하고, 다중-그래뉼러리 특징을 적응적으로 융합합니다.

- **Performance Highlights**: 실험 결과, PSVMA+는 최신 최첨단 방법들을 일관되게 능가하는 성능을 보여주었습니다.



### Efficiera Residual Networks: Hardware-Friendly Fully Binary Weight with 2-bit Activation Model Achieves Practical ImageNet Accuracy (https://arxiv.org/abs/2410.11553)
Comments:
          11pages, 2 figures, the model implementation is available at this https URL

- **What's New**: 이 논문에서는 Efficiera Residual Networks (ERNs)라는 새로운 모델을 소개합니다. 이 모델은 리소스가 제한된 엣지 디바이스에서의 완전한 초저비트 양자화를 지원하며, 모든 가중치와 활성화가 바이너리 형태로 구현됩니다. 기존의 모델들과 달리, ERNs는 초기 및 출력 계층에서도 부동 소수점 연산 없이 작동할 수 있습니다.

- **Technical Details**: ERNs는 가중치와 활성화를 각각 1비트(바이너리)와 2비트로 설정합니다. 이를 통해 모든 계층에서 부동소수점 값 없이 정수 기반의 잔여 연결을 수행할 수 있도록 공유 상수 스케일링 팩터라는 기술을 도입하였습니다. 이는 하드웨어 친화적인 모델을 설계하기 위한 여러 조건을 통해 이뤄졌으며, CNN의 복잡성을 줄이기 위해 표준 CNN 구조를 따릅니다.

- **Performance Highlights**: ERNs는 ResNet50 호환 아키텍처로 ImageNet에서 72.5pt의 Top-1 정확도를 달성했으며, 1MB 미만의 모델로도 63.6pt를 기록하였습니다. 또한, 가장 작은 모델은 300FPS의 추론 속도를, 가장 큰 모델은 60FPS를 달성하여 비용 효율적인 FPGA 장치에서 인상적인 성능을 발휘합니다.



### MCTBench: Multimodal Cognition towards Text-Rich Visual Scenes Benchmark (https://arxiv.org/abs/2410.11538)
Comments:
          12 pages, 5 figures, project page: this https URL

- **What's New**: 본 논문에서는 Multi-modal Large Language Models (MLLMs)의 인지 능력을 평가하기 위한 새로운 멀티모달 벤치마크, MCTBench를 제안합니다. 이 벤치마크는 텍스트가 풍부한 시각 장면에서의 인지 및 인식 능력을 통합적으로 평가하는 것이 특징입니다.

- **Technical Details**: MCTBench는 약 5.2k 개의 텍스트가 풍부한 이미지와 8.5k 개의 정밀하게 주석 처리된 질문-답변 쌍을 포함하고 있으며, 인식, 추론 및 콘텐츠 생성의 세 가지 작업으로 분류됩니다. 인식 및 추론 작업은 다중 선택 질문 형식으로 되어 있으며, 자동 평가 파이프라인을 통해 콘텐츠 생성 평가를 수행합니다.

- **Performance Highlights**: MCTBench를 통한 평가 결과, MLLMs는 인식 능력에 비해 인지 능력이 낮은 성능을 보이며, 텍스트가 강화된 모델에서 특히 두드러집니다. 담체 묘사 기준의 확장을 통해 인지 작업(추론 및 콘텐츠 생성)의 성능이 증가하는 경향이 나타났습니다.



### Overcoming Domain Limitations in Open-vocabulary Segmentation (https://arxiv.org/abs/2410.11536)
- **What's New**: 본 연구에서는 Open-vocabulary segmentation (OVS) 모델이 새로운 도메인에 대해 학습하면서 이전 지식을 유지할 수 있도록 하는 새로운 접근 방식을 제안합니다. 이전 트레이닝 데이터셋을 넘어선 새로운 도메인에서 OVS 모델의 성능 저하 문제를 해결하고자 합니다.

- **Technical Details**: 이 방법은 각 도메인에 대한 미리 계산된 다변량 정규 분포(multivariate normal distribution)를 사용하여 입력 샘플이 여러 도메인에 얼마나 근접한지를 평가합니다. 이 예측을 바탕으로, 사전 훈련된 디코더의 가중치와 미세 조정된 디코더의 가중치를 동적으로 보간(interpolate)합니다.

- **Performance Highlights**: 제안된 방법을 활용하여 OVS 모델은 새로운 도메인에 적응하면서 이전 훈련 데이터셋의 성능을 유지합니다. Cityscapes 및 ADE20k에서 미세 조정된 모델이 이전 지식을 잃지 않으면서 새로운 도메인에 잘 적응하는 모습을 보였습니다. 또한 여러 미세 조정된 데이터셋에서도 동일한 효과가 관찰되었습니다.



### Hairmony: Fairness-aware hairstyle classification (https://arxiv.org/abs/2410.11528)
- **What's New**: 본 연구에서는 단일 이미지로 사람의 헤어스타일을 예측하는 방법을 제시합니다. 기존의 방법들은 머리카락의 다양성을 충분히 포착하지 못하는 제한이 있었으나, 저자들은 새로운 분류 접근 방식을 채택하여 포괄적이고 다양한 헤어스타일을 지원하는 시스템을 목표로 하고 있습니다.

- **Technical Details**: 이 연구에서는 레이블이 잘못 붙은 데이터를 피하고, 합성 데이터(synthetic data)만을 사용하여 모델을 학습하였습니다. 이는 트레이닝 데이터의 다양성을 명시적으로 조절할 수 있게 해주며, 노이즈가 없는 정확한 레이블을 생성합니다. 저자들은 다양한 전문가들과 협력하여 새로운 헤어스타일 분류 체계를 개발하였고, 이를 바탕으로 트레이닝 데이터셋을 주석(annotation) 달았습니다.

- **Performance Highlights**: 실험 결과, 저자들이 제안한 방법은 최근의 파라메트릭 모델보다 도전적인 헤어스타일에 대해 더 강력한 성능을 보였습니다. 특히, 단일 이미지에서 높은 정확도로 헤어스타일의 분류와 예측이 가능하다는 점이 강조되었습니다.



### Look Ma, no markers: holistic performance capture without the hass (https://arxiv.org/abs/2410.11520)
- **What's New**: 이 연구에서는 얼굴, 몸, 손을 동시에 고도로 정확하게 캡처하는 새로운 기술을 소개합니다. 기존의 모션 캡처 기술은 보통 각각의 부위만을 독립적으로 캡처하며, 복잡하고 비싼 하드웨어와 숙련된 운영자의 수작업 개입이 필요했습니다. 반면, 이 기술은 마커가 필요 없고, 모든 카메라에서 자동으로 안정적인 결과를 생성할 수 있습니다.

- **Technical Details**: 이 방법은 합성 데이터에 기반하여 훈련된 머신 러닝 모델과 인체 모양 및 동작에 대한 강력한 파라메트릭 모델을 결합한 하이브리드 접근 방식을 사용합니다. 이 시스템은 하나의 이미지에서 전체 인간의 신체 형태, 표정, 손 및 혀의 움직임을 예측할 수 있으며, 추가적인 캘리브레이션이나 숙련된 수작업 없이 다양한 환경에서 작동합니다.

- **Performance Highlights**: 이 연구의 방법은 다양한 바디, 얼굴, 손 재구성 벤치마크에서 최신 기술을 보여주며, 다양한 데이터셋에 대해 일반화된 성능을 보입니다. 이 기술은 캘리브레이션이 필요 없고, 낮은 비용으로 매우 높은 품질의 성능 캡처가 가능하여 생산 작업의 효율성을 대폭 향상시킬 수 있습니다.



### Dual-Teacher Ensemble Models with Double-Copy-Paste for 3D Semi-Supervised Medical Image Segmentation (https://arxiv.org/abs/2410.11509)
Comments:
          35 pages, 5 figures

- **What's New**: 본 논문에서는 3D 의료 이미지 분할을 위한 새로운 반지도 학습(Semi-supervised Learning, SSL) 기법을 제안합니다. 특히, 이중 교사 모델(Dual-teacher model)에서 복사-붙여넣기(copy-paste) 기술을 활용하여 교사 모델 간 다양성을 높이고, 예측 샘플의 특성에 따라 유연하게 앙상블 방법을 선택하는 Staged Selective Ensemble(SSE) 모듈을 도입하여 고품질의 의사 레이블(pseudo-label)을 생성하는 방안을 제시합니다.

- **Technical Details**: 이 논문에서는 이중 교사 모델에서 발생할 수 있는 가중치 커플링(coupling) 문제를 해결하기 위해 double-copy-paste(DCP) 기법을 통합합니다. 이를 통해 교사 간의 다양성을 증가시키고, 예측 유사도(thresholds)를 설정하여 샘플 특성에 기초한 선택적 앙상블(adaptive ensemble) 전략을 도입합니다. 이런 방식으로 데이터에서 다양한 정보가 수집되도록 하여 모델의 일반화 성능을 향상시킵니다.

- **Performance Highlights**: 제안된 방법은 전통적인 지도 학습 방법에 비해 여러 고전 데이터 세트에서 우수한 성능을 보이며, 특정 지표에서 완전한 지도 학습 방법을 초과하는 결과를 달성했습니다. 실험 결과는 제안된 방법이 의료 이미지 분할 작업에 효과적임을 입증합니다.



### Spatio-Temporal Distortion Aware Omnidirectional Video Super-Resolution (https://arxiv.org/abs/2410.11506)
- **What's New**: 본 논문에서는 Omnidirectional Video (ODV) 특성을 고려한 새로운 Spatio-Temporal Distortion Aware Network (STDAN)을 제안하여 ODV의 해상도를 향상시키고 있습니다.

- **Technical Details**: 제안된 모델은 spatio-temporal distortion modulation module을 도입하여 공간적 ODV 프로젝션 왜곡을 개선하고, intra 및 inter alignments에 따른 시간적 상관관계를 활용합니다. 또한, 다중 프레임 복원 및 융합 메커니즘을 설계하여 복원된 ODV 프레임의 일관성을 개선합니다.

- **Performance Highlights**: 실험 결과, STDAN은 최신 기법들에 비해 우수한 초해상도(super-resolution) 성능을 보여주며, 다양한 시나리오를 포함하는 새로운 ODV-SR 데이터셋을 활용하여 평가되었습니다.



### LoGS: Visual Localization via Gaussian Splatting with Fewer Training Images (https://arxiv.org/abs/2410.11505)
Comments:
          8 pages

- **What's New**: 이번 논문은 LS-GS라는 새로운 비전 기반 로컬라이제이션 파이프라인을 소개합니다. LoGS는 3D Gaussian Splatting (GS) 기술을 활용하여 장면을 표현하고 있으며, 이는 고품질의 새로운 시점 합성을 가능하게 합니다. LoGS는 단 몇 개의 이미지로도 데이터의 부족 문제를 해결할 수 있도록 설계되었습니다.

- **Technical Details**: LoGS는 구조로부터의 모션 (Structure-from-motion, SfM)에 기반한 초기 맵 생성을 시작으로, 이미지 검색과 로컬 피처 매칭을 통해 초기 위치를 얻습니다. 이어서 photometric loss를 최소화하여 정확한 자세(Pose)를 측정합니다. 대표적인 요소로 PnP-RANSAC 기법을 사용하며, GS 맵을 통해 최종적인 위치 추정을 수행합니다.

- **Performance Highlights**: LoGS는 0.5%에서 1%의 훈련 이미지만을 사용해도 최첨단(SOTA)의 정확도를 자랑하며, 예를 들어 7-scenes 데이터셋의 CHESS 장면에서는 20장의 이미지만으로 평균 0.5 cm의 이동 오차와 0.16°의 회전 오차를 달성했습니다. 이러한 성과는 급속한 배포가 필요한 실제 응용에 필수적입니다.



### Online learning in motion modeling for intra-interventional image sequences (https://arxiv.org/abs/2410.11491)
Comments:
          Medical Image Computing and Computer Assisted Intervention (MICCAI) 2024

- **What's New**: 이번 연구에서는 의료 examinations (검사) 동안 이미지 모니터링과 가이드를 통해 진단과 치료의 정확성을 향상시킬 수 있는 새로운 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 선형 가우시안 상태 공간 모델(Linear Gaussian State-Space Model)을 기반으로 하며, 낮은 차원의 시간적 프로세스(low-dimensional temporal process)를 활용하여 획득한 이미지들 간의 움직임(motion)을 추정하고 미래의 움직임(forecasting)도 예측할 수 있습니다.

- **Performance Highlights**: 공개된 심장 데이터셋에 대한 두 가지 실험 결과, 환자 맞춤형 적응(patient-specific adaptation)을 통해 온라인 학습(online learning)을 적용한 경우 신뢰할 수 있는 움직임 추정과 향상된 예측 성능을 보여주었습니다.



### InvSeg: Test-Time Prompt Inversion for Semantic Segmentation (https://arxiv.org/abs/2410.11473)
- **What's New**: 이 논문은 InvSeg라는 테스트 타임 프롬프트 인버전 방법을 제안하여 개방 어휘(open-vocabulary) 의미 분할(semantic segmentation) 문제를 해결합니다.

- **Technical Details**: InvSeg는 이미지 특정 시각적 맥락(visual context)을 텍스트 프롬프트 임베딩 공간(text prompt embedding space)으로 전환하여 텍스트 프롬프트를 풍부하게 만들어 각 클래스를 구조적으로 일관된 마스크와 연결합니다. 특히, 대조적 소프트 클러스터링(Contrastive Soft Clustering, CSC)을 도입하여 유도된 마스크를 이미지의 구조 정보와 정렬합니다.

- **Performance Highlights**: InvSeg는 PASCAL VOC 및 Context 데이터셋에서 최신 성과를 기록하며, 샘플 특정 컨텍스트를 통합하여 다양한 모달리티 간의 의미 정렬을 정확하게 수행합니다.



### A Simple Approach to Unifying Diffusion-based Conditional Generation (https://arxiv.org/abs/2410.11439)
Comments:
          Project page: this https URL

- **What's New**: 최근 이미지 생성 모델에서의 새로운 접근 방식으로, 조건 신호를 통해 다양한 조건부 생성 작업을 수행할 수 있는 통합 프레임워크인 UniCon을 제안합니다.

- **Technical Details**: UniCon은 특정 이미지-조건 상관관계를 학습하기 위해, 확산 모델(diffusion model)을 사용하여 이미지 쌍의 결합 분포(joint distribution)를 학습합니다. 이 모델은 추가적 학습 파라미터가 15%로 적고, 단일 효율적인 훈련 단계를 통해 다양한 추론 샘플링 방식을 지원합니다.

- **Performance Highlights**: UniCon은 기존의 특화된 방법들과 유사하거나 더 나은 결과를 보여주며, 여러 모델을 결합하여 다중 신호 조건 생성을 가능하게 합니다.



### CTA-Net: A CNN-Transformer Aggregation Network for Improving Multi-Scale Feature Extraction (https://arxiv.org/abs/2410.11428)
Comments:
          9 pages, 3 figures

- **What's New**: 이번 논문에서는 CNN(Convolutional Neural Networks)과 ViT(Vision Transformers)를 통합한 새로운 아키텍처인 CTA-Net(Convolutional Transformer Aggregation Network)을 소개합니다. CTA-Net은 CNN과 ViT의 강점을 결합하여 지역적인 특징과 넓은 범위의 의존성을 효율적으로 추출합니다.

- **Technical Details**: CTA-Net은 새로운 LMF-MHSA(Light Weight Multi-Scale Feature Fusion Multi-Head Self-Attention) 모듈을 통해 다중 규모의 특징 통합을 효과적으로 수행하며, 매개변수를 줄이는 동시에 성능을 향상시킵니다. RRCV(Reverse Reconstruction CNN-Variants) 모듈은 transformer 내에서 CNN의 임베딩을 개선합니다.

- **Performance Highlights**: CTA-Net은 APTOS 2019 및 RFMiD2020 데이터셋에서 각각 TOP-1 정확도 86.76%, 20.32M의 적은 파라미터 수, 2.83B FLOPs를 기록하며, 소규모 데이터셋에서 시각적 작업에 매우 효율적이고 경량 솔루션으로서의 가능성을 보여줍니다.



### GS^3: Efficient Relighting with Triple Gaussian Splatting (https://arxiv.org/abs/2410.11419)
Comments:
          Accepted to SIGGRAPH Asia 2024. Project page: this https URL

- **What's New**: 본 논문에서는 다중 뷰 포인트 조명 입력 이미지로부터 실시간 고품질의 새로운 조명 및 뷰 합성을 위한 공간적 및 각도적 Gaussian 기반 표현과 트리플 스플래팅 프로세스를 제안합니다.

- **Technical Details**: 복잡한 외관을 설명하기 위해 각 공간적 Gaussian에 대한 반사 함수로 Lambertian과 각도적 Gaussian 혼합을 사용하는 것이 특징입니다. 자가 그림자 생성 및 전역 조명 보정 등 다양한 효과를 지원하기 위해 다층 퍼셉트론(MLP)을 사용하여 RGB 튜플을 계산합니다.

- **Performance Highlights**: 우리의 방법은 기하학적 다양성과 외관적 다양성을 갖춘 30 샘플에서 효과가 입증되었으며, 훈련 시간은 40-70분, 렌더링 속도는 단일 상용 GPU에서 90 fps에 달합니다. 결과는 품질 및 성능 면에서 최신 기술과 비교 우위를 보입니다.



### VidCompress: Memory-Enhanced Temporal Compression for Video Understanding in Large Language Models (https://arxiv.org/abs/2410.11417)
Comments:
          9 pages, 4 figures

- **What's New**: 새로운 Video-LLM인 VidCompress는 비디오 이해 작업을 위해 메모리 강화 시간 압축을 제공하여 비디오의 복잡한 시간-공간 관계를 더 효과적으로 모델링합니다.

- **Technical Details**: VidCompress는 이중 압축기(dial-compressor) 접근 방식을 사용합니다. 첫 번째는 메모리 강화 압축기로, 비디오에서 단기 및 장기 시간 관계를 포착하고 다중 규모 변환기(multiscale transformer)와 메모리 캐시 메커니즘을 이용해 시각 토큰을 압축합니다. 두 번째는 텍스트 인식 압축기로, Q-Former를 활용해 시간 맥락을 쿼리 임베딩에 통합하고 응집된 시각 토큰을 생성합니다.

- **Performance Highlights**: 여러 VideoQA 데이터셋과 포괄적인 벤치마크에서 VidCompress는 복잡한 시간-공간 관계를 효과적으로 모델링하며 기존 Video-LLM보다 현저히 뛰어난 성능을 보였습니다.



### MoChat: Joints-Grouped Spatio-Temporal Grounding LLM for Multi-Turn Motion Comprehension and Description (https://arxiv.org/abs/2410.11404)
- **What's New**: 이번 연구에서는 인간 모션 이해를 위한 MoChat이라는 신규 다중 모달 대형 언어 모델(Multimodal Large Language Model)을 제안합니다. MoChat은 인간 동작의 시공간(Spatio-temporal) 기초를 이해하고, 다중 턴 대화 맥락(Multi-turn Dialogue Context)을 처리할 수 있는 능력을 갖추고 있습니다.

- **Technical Details**: MoChat에서는 각 스켈레톤 프레임의 공간 정보를 인체 해부학적 구조에 따라 그룹화하고, Joints-Grouped Skeleton Encoder를 적용합니다. 이를 통해 LLM 임베딩과 결합하여 각각 시공간 인식 임베딩을 생성합니다. 또한, 스켈레톤 시퀀스에서 텍스트 주석을 기반으로 타임스탬프(Timestamp)를 추출하는 파이프라인을 개발하고, 공간적 기초를 위한 다중 턴 대화(dialogues)를 구축합니다.

- **Performance Highlights**: MoChat은 HumanML3D 데이터셋에서 모션 이해(Motion Understanding), 공간 팔다리 기초(Spatial Limb Grounding), 시간 행동 기초(Temporal Action Grounding) 작업을 수행하여 전통적인 메트릭(metric)과 GPT-4를 통해 평가한 결과, 여러 메트릭에서 최첨단 성능(State-of-the-Art Performance)을 기록했습니다. 이는 MoChat이 인간 모션의 세밀한 시공간 기초(Fine-grained Spatio-Temporal Grounding)를 가능하게 하는 첫 번째 모델임을 시사합니다.



### MCGS: Multiview Consistency Enhancement for Sparse-View 3D Gaussian Radiance Fields (https://arxiv.org/abs/2410.11394)
- **What's New**: 본 연구에서는 3D Gaussian Splatting을 기반으로 한 새로운 뷰 합성 프레임워크인 MCGS를 제안하여 희소 입력 뷰에서도 포토리얼리스틱(photorealistic) 장면 재구성을 가능하게 합니다. 기존 방법들이 다중 뷰 일관성(multi-view consistency)을 간과한 데 반해, MCGS는 이를 개선하는 혁신적인 방안을 도입하였습니다.

- **Technical Details**: MCGS의 두 가지 주요 혁신은 다음과 같습니다: i) 희소 매칭(sparse matcher)과 랜덤 채우기(random filling) 전략을 결합한 초기화 방법을 도입하여 초기 포인트 집합을 컴팩트하게 생성합니다. 이는 초기 기하학적 정보(prior)를 향상시켜 장면 표현을 효율적으로 합니다. ii) 다중 뷰 일관성 가이드(multi-view consistency-guided) 점진적 가지치기(progressive pruning) 전략을 개발하여 Gaussian 필드를 정제하고 일관성을 강화하며 기여도가 낮은 Gaussians를 제거합니다.

- **Performance Highlights**: 이러한 모듈식(modular)이고 플러그 앤 플레이(plug-and-play) 전략은 희소 입력 뷰에 대한 강인성을 향상시키고, 렌더링 속도를 가속화하며, 메모리 소비를 줄여 MCGS를 3D Gaussian Splatting에 있어 실용적이고 효율적인 프레임워크로 만듭니다.



### Augmentation-Driven Metric for Balancing Preservation and Modification in Text-Guided Image Editing (https://arxiv.org/abs/2410.11374)
Comments:
          Under review

- **What's New**: 이 논문은 CLIPScore의 한계를 지적하고, 텍스트에 기반한 이미지 편집을 위한 새로운 평가 지표인 AugCLIP을 제안합니다. AugCLIP은 이미지의 핵심 속성을 보존하면서 텍스트에 맞춰 수정을 최적화합니다.

- **Technical Details**: AugCLIP은 대형 언어 모델(large language model)을 활용하여 소스 이미지와 타겟 텍스트에 대한 상세 설명을 증강하고, CLIP 공간에서 소스와 타켓을 분리하는 하이퍼플레인을 모델링합니다. 이 모델은 이상적인 편집 이미지의 표현을 소스 이미지의 직교 투영으로 추정하며, 각 속성의 상호 종속성을 고려하여 상대적 중요성을 평가합니다.

- **Performance Highlights**: 여러 편집 시나리오에 대해 AugCLIP은 기존 지표보다 인간 평가 기준과의 정렬이 상당히 높음을 보여줍니다. 특히, AugCLIP은 개인화한 생성 및 복잡한 이미지 편집 시나리오에서의 작은 차이 식별에 뛰어난 성능을 보입니다.



### DRACO: A Denoising-Reconstruction Autoencoder for Cryo-EM (https://arxiv.org/abs/2410.11373)
- **What's New**: 이 논문에서 소개된 DRACO는 Cryogenic Electron Microscopy (cryo-EM) 이미지를 위한 새로운 Denoising-Reconstruction Autoencoder로, Noise2Noise(N2N) 방법에 영감을 받아 세밀한 노이즈 제거와 복원을 위한 하이브리드 훈련 방식을 사용하는 점이 특징적입니다. 이 모델은 고품질 및 다양한 데이터셋을 통해 더욱 효과적으로 훈련됩니다.

- **Technical Details**: DRACO는 odd 및 even 프레임을 독립적 노이즈 관측으로 처리하여 각 노이즈 패치를 복원하는 훈련을 수행합니다. 이는 두 이미지를 masking 하여 denoising과 reconstruction 작업을 창출합니다. DRACO의 훈련은 270,000개 이상의 cryo-EM 영화 및 마이크로그래프로 구성된 고품질 데이터셋을 필요로 하며, 이를 통해 다양한 downstream 작업에 일반화된 성능을 나타냅니다.

- **Performance Highlights**: DRACO는 denoising, micrograph curation 및 particle picking 작업에서 최고 성능을 보이며, 기존의 선진 모델들과 비교해 우수한 결과를 구현했습니다. 모든 downstream 작업에서 state-of-the-art baseline보다 뛰어난 성과를 보여줍니다.



### Visual-Geometric Collaborative Guidance for Affordance Learning (https://arxiv.org/abs/2410.11363)
- **What's New**: 본 논문에서는 인간-객체 상호작용에서 추출한 interactive affinity (인터랙티브 애피니티)를 활용하여 affordance (어포던스) 학습의 정확성을 높이는 새로운 접근 방식을 제안합니다. 이는 기존의 어포던스 학습 알고리즘의 한계점을 극복하는 데 초점을 맞추고 있습니다.

- **Technical Details**: 제안된 VCR-Net (Visual-geometric Collaborative guided affoRdance learning Network)은 시각적 및 기하학적 단서를 통합하여 인간-객체 상호작용에서 interactive affinity를 효율적으로 추출하고 비상호작용 객체에 전이하는 구조를 갖추고 있습니다. 특히, Semantic-pose Heuristic Perception (SHP) 모듈과 Geometric-apparent Alignment Transfer (GAT) 모듈을 통해 interaction 관련된 지역에 집중하고, 이들 지역의 기능적 특징 간 유사성을 평가하여 명확한 전이를 달성합니다.

- **Performance Highlights**: 실험 결과, 제안하는 방법이 대표적인 모델들에 비해 객관적 메트릭과 시각적 품질 모두에서 우수한 성능을 보였습니다. 특히, 55,047개의 이미지로 구성된 Contact-driven Affordance Learning (CAL) 데이터셋을 활용하여 모델의 효과성을 검증하였습니다.



### SeaDATE: Remedy Dual-Attention Transformer with Semantic Alignment via Contrast Learning for Multimodal Object Detection (https://arxiv.org/abs/2410.11358)
- **What's New**: 본 연구에서는 SeaDATE라는 새로운 다중 모달 객체 탐지 방법을 제안합니다. 이 방법은 Transformer 기반의 이중 주의 메커니즘을 활용하여 지역 및 글로벌 정보를 통합합니다. 특히, 깊은 의미 정보를 추출할 때의 한계를 극복하기 위해 대조 학습 모듈을 도입하였습니다.

- **Technical Details**: SeaDATE는 DTF(Dual Attention Feature Fusion) 모듈을 사용하며, 이 모듈은 공간 및 채널 토큰을 통해 다중 모달 특징을 효과적으로 융합합니다. 대조 학습(CL) 모듈은 깊은 특징 간의 상호 작용을 촉진하며, 다양한 깊이 층의 특징을 통합하여 Transformer 인도 융합 방법에서 발생하는 한계를 해결합니다.

- **Performance Highlights**: FLIR, LLVIP, M3FD 데이터 세트를 기준으로 한 실험 결과, SeaDATE는 최신 기술 대비 뛰어난 탐지 성능을 보여주며, 다중 모달 정보를 활용한 정확성과 신뢰성을 크게 향상시킵니다.



### CONSULT: Contrastive Self-Supervised Learning for Few-shot Tumor Detection (https://arxiv.org/abs/2410.11307)
Comments:
          14 pages, 4 figures

- **What's New**: 본 연구에서는 CONSULT(Contrastive Self-supervised Learning for few-shot Tumor detection)이라 불리는 최신 이단계(anomaly detection) 알고리즘을 소개합니다. 이는 매우 제한된 MRI 뇌 이미지를 사용할 때도 높은 성능을 유지할 수 있도록 설계되었습니다.

- **Technical Details**: CONSULT의 첫 번째 단계는 미리 훈련된(feature extractor) 특징 추출기를 MRI 뇌 이미지를 위해 fine-tuning하고, 합성 데이터를 생성하는 파이프라인을 통해 종양 유사 데이터를 만들어냅니다. 두 번째 단계는 PatchCore를 사용하여 첫 번째 단계에서 fine-tuned된 가중치를 통해 전통적인 특징 추출을 수행합니다. 또한 Tritanh Loss라는 새로운 대조 손실 기능을 도입하여 안정적인 학습을 지원하고, gradient flow를 개선합니다.

- **Performance Highlights**: CONSULT는 2, 4, 6, 8 shots에서 각각 9.4%, 12.9%, 10.2%, 6.0%의 성능 향상을 달성하며, 건강한 이미지만으로 훈련하여 기존 PatchCore 알고리즘을 초월하는 결과를 보여주었습니다.



### Have the VLMs Lost Confidence? A Study of Sycophancy in VLMs (https://arxiv.org/abs/2410.11302)
- **What's New**: 이번 연구에서는 LLMs(대형 언어 모델)의 시코팬시(sycophancy) 문제를 VLMs(비주얼 언어 모델)로 확장하여 다루었습니다. 특히, VLMs에서 시코팬시에 대한 연구가 부족하다는 점을 강조하며, 새로운 MM-SY 벤치마크를 도입했습니다.

- **Technical Details**: 시코팬시(sycophancy)는 LLMs가 원래의 올바른 응답을 따르지 않고 사용자 의견에 무비판적으로 동의하는 현상을 말합니다. 본 연구에서는 시코팬시를 완화하기 위한 합성 데이터셋(synthetic dataset)을 제안하고, 프롬프트(prompts), 감독된 미세 조정(supervised fine-tuning), DPO(Deep Prompting Optimization) 기반의 방법들을 사용하여 효과적으로 문제를 해결하였습니다. 또한, VLMs의 시코팬시가 의미론적(semiotic)으로 미치는 영향을 평가하기 위해 주목(attention) 분포를 분석했습니다.

- **Performance Highlights**: 실험 결과, 상위 레이어에서의 시코팬시 예방 능력이 두드러지며, 상위 레이어에서의 이미지(attention) 지식 부족이 시코팬시에 기여하고 있음을 확인했습니다. 이에 따라, 고급 레이어에서의 이미지 주목(attention)을 향상시키는 것이 시코팬시 문제를 완화하는 데 유용하다는 결과를 얻었습니다.



### Open World Object Detection: A Survey (https://arxiv.org/abs/2410.11301)
- **What's New**: 이번 연구는 **Open World Object Detection (OWOD)**라는 새로운 분야를 소개하며, 이는 **deep neural networks** 내에서 지식을 인식하고 학습하는 내용을 다룹니다. OWOD는 초기 훈련 세트에 없는 객체를 인식하고 학습하여 지식 기반을 점진적으로 확장하는 방법론입니다. 이 설문 논문은 OWOD의 문제 정의, 기준 데이터셋, 소스 코드, 평가 메트릭스, 기존 방법들에 대한 비교 연구 등의 주요 요소를 포괄적으로 검토합니다.

- **Technical Details**: OWOD는 기존의 객체 탐지와는 근본적으로 차별화되며, 동적 환경에서의 적응성을 인정합니다. 일반적인 객체 탐지는 훈련 중 모든 클래스가 존재한다고 가정하나, OWOD는 알려진 클래스와 함께 알려지지 않은 클래스도 탐지하고 학습할 수 있습니다. 이를 통해 모델은 새로운 데이터를 통합하면서 'catastrophic forgetting' 문제를 완화하여 이전에 학습한 정보를 유지할 수 있습니다. 이 연구에서는 OWOD의 기초를 **Open Set Recognition (OSR)** 및 **Incremental Learning (IL)**와 비교하여 설명합니다.

- **Performance Highlights**: OWOD는 **MS-COCO** 데이터셋을 활용한 실험으로, 알려진 클래스와 새로운 클래스에 대한 정확도를 평가하였습니다. OWOD는 기존의 객체 탐지 방법에 비해 더 나은 적응성과 확장성을 제공하며, 이는 실제 세계의 변동성에 대응하는 데 더 적합합니다. OWOD는 다양한 기존 방법들과 비교하여 성능 관리의 기준을 제시하며, 이 영역에서의 향후 연구 방향도 제안하고 있습니다.



### Scalable Indoor Novel-View Synthesis using Drone-Captured 360 Imagery with 3D Gaussian Splatting (https://arxiv.org/abs/2410.11285)
Comments:
          Accepted to ECCV 2024 S3DSGR Workshop

- **What's New**: 본 논문에서는 드론이 촬영한 360 동영상으로부터의 실내 새로운 뷰( Novel-View ) 합성을 위해 효율적이고 확장 가능한 파이프라인을 제안합니다. 이를 통해 각 블록을 개별적으로 병렬 처리할 수 있게 자동으로 장면을 작은 블록으로 분할하는 분할 정복 (Divide-and-Conquer) 전략을 포함합니다.

- **Technical Details**: 제안된 파이프라인은 데이터 캡처 단계에서 360° 카메라를 사용하여 다양한 시점(viewpoints)에서 장면을 포착하며, 이를 통해 안정적인 드론 경로로 촬영할 수 있습니다. 3D Gaussian Splatting을 이용하여 장면을 표현하고, 블록 간의 정렬을 위한 간단한 조정 방법을 사용합니다. 각 블록은 필요할 때만 메모리에 로드되어 계산 복잡성을 줄입니다.

- **Performance Highlights**: 제안된 방법은 기존 방법들과 비교하여 PSNR에서 최대 13.88 dB, SSIM에서 0.22의 향상을 보여주며, 처리 시간은 10배 더 빨라졌습니다.



### Contrastive learning of cell state dynamics in response to perturbations (https://arxiv.org/abs/2410.11281)
Comments:
          20 pages, 6 figures, 3 appendix figures, 4 videos (ancillary files)

- **What's New**: DynaCLR는 시간 지각된 contrastive learning을 통해 세포 역학을 모델링하기 위한 자기 지도 학습 프레임워크입니다. 이는 시간 경과에 따른 데이터셋의 대표성을 학습하여 생물학적 상태의 보다 정량적이고 효율적인 해석을 가능하게 합니다.

- **Technical Details**: DynaCLR은 여러 채널의 3D 타임랩스 이미지를 이용하여 세포의 형상 역학을 분석합니다. 이 프레임워크는 셀 및 오르가넬의 형태학적 역학을 시간적으로 정규화된 임베딩 공간에 매핑하여 분석할 수 있게 해줍니다. 학습된 임베딩은 세포의 형태학적 상태를 정량화하고 분류하는 데 사용됩니다.

- **Performance Highlights**: DynaCLR로 학습된 모델은 95% 이상의 감염 상태 분류 정확도를 달성하며, 세포의 일시적 상태를 감지하고 이전에 보지 못한 실험을 신뢰성 있게 임베딩할 수 있는 능력을 보여줍니다. 이 접근법은 감염, 유전자 변형, 약물에 대한 세포 상태 역학의 비교 분석에 유연한 프레임워크를 제공합니다.



### Rethinking the Role of Infrastructure in Collaborative Perception (https://arxiv.org/abs/2410.11259)
Comments:
          Accepted by ECCV 2024 Workshop MAAS, 14 pages

- **What's New**: 본 연구에서는 차량 중심의 Collaborative Perception(CP)과 인프라 중심의 CP의 효과를 비교하여 인프라 데이터의 중요성을 정량적으로 평가합니다. 이는 인프라를 자율주행 시스템의 에고 에이전트로 재조명하는 첫 번째 시도입니다.

- **Technical Details**: 이 논문은 인프라 데이터의 영향을 분석하기 위해 V2XSet와 V2X-Sim 데이터세트를 사용하였으며, 3D 감지 정확도 향상을 위해 기존 차량 중심 CP와 인프라 중심 CP를 비교하였습니다. 이러한 CP 구조는 메타데이터 공유, 특징 추출 및 융합 과정을 포함합니다.

- **Performance Highlights**: 연구 결과, 인프라 데이터를 통합함으로써 3D 감지 정확도가 최대 10.87% 향상되었으며, 인프라 중심 CP는 차량 중심 CP와 비교해 잡음 로버스트성을 증가시키고 정확도를 최대 42.53% 향상시켰습니다.



### CLIP-DFGS: A Hard Sample Mining Method for CLIP in Generalizable Person Re-Identification (https://arxiv.org/abs/2410.11255)
Comments:
          Accepted by ACM TOMM

- **What's New**: 본 논문에서는 CLIP 기반의 새로운 하드 샘플 마이닝 방법인 DFGS(Depth-First Graph Sampler)를 제안합니다. DFGS는 깊이 우선 탐색 알고리즘을 기반으로 하여, 이미지와 텍스트 인코더 모두에 적용 가능하며, 미니 배치를 형성하는 과정에서 도전적인 샘플을 제공함으로써 CLIP의 정밀한 특징 추출 능력을 향상시킵니다.

- **Technical Details**: DFGS를 통해 복잡한 사례들을 효과적으로 구분할 수 있는 고차별적인 미니 배치를 생성합니다. 전통적인 샘플링 기법인 PK 샘플러는 무작위로 클래스를 선택하여 샘플을 형성하지만, DFGS는 더 도전적인 샘플들을 집중적으로 선택하여 학습 과정의 효율성을 높입니다. 이 방법은 CLIP의 크로스 모달 학습 능력을 활용하여 특히 일반화된 사람 재식별(DG-ReID) 작업에서 효과적으로 작동합니다.

- **Performance Highlights**: DGF의 실험 결과, 기존 방법들에 비해 재식별 성능이 눈에 띄게 향상되었음을 보여주며, 여러 표준 벤치마크 데이터 세트에서 효과적인 성능 개선을 확인했습니다. DFGS는 특히 도전적인 샘플을 제공하여 CLIP의 학습 능력과 일반화 성능을 강화하는 데 기여합니다.



### Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models (https://arxiv.org/abs/2410.11242)
- **What's New**: 이번 연구에서는 VHExpansion을 도입하여 시각적 환각(Visual Hallucination, VH) 테스트 케이스를 자동으로 확장할 수 있는 최초의 방법을 제안합니다. 기존 방법들은 인간의 주석에 의존하여 VH 테스트 케이스를 생성했으나, VHExpansion은 질문과 답변의 부정, 이미지의 일반적 및 적대적 변형을 통해 테스트 케이스를 자동으로 확장합니다.

- **Technical Details**: VHExpansion은 초기 VH 테스트 케이스를 기반으로 하여 질문과 답변을 부정(non-affirmation)으로 변경하고, 이미지에 일반적인 이미지 처리(예: JPEG 압축, 가우시안 노이즈) 및 적대적 이미지 변형을 추가하여 새로운 VH 테스트 케이스를 생성합니다. 또한, 대칭 정확도(symmetric accuracy)라는 새로운 평가 지표를 제안하여 각 테스트 케이스와 그 부정된 대응물의 올바른 응답 비율을 측정합니다.

- **Performance Highlights**: VHExpansion을 사용하여 수동으로 주석이 달린 세 개의 VH 데이터셋을 확장한 결과, 기존 MLLM 모델보다 VH 테스트 케이스를 더 많이 식별했습니다. 대칭 정확도는 기존의 정확도와 다른 결론을 도출하며, MLLM을 VHExpansion으로 생성된 확장된 VH 데이터셋으로 미세 조정한 결과 VH를 효과적으로 줄일 수 있음을 보여주었습니다.



### Learning Diffusion Model from Noisy Measurement using Principled Expectation-Maximization Method (https://arxiv.org/abs/2410.11241)
- **What's New**: 이 연구는 다양한 종류의 노이즈가 있는 데이터에서 디퓨전 모델(Diffusion Models)을 학습하기 위한 원칙적인 기대 최대화(Expectation-Maximization, EM) 프레임워크를 제안합니다. 기존의 접근 방식은 이론적 수렴 보장이 부족하거나 특정 데이터 손상 유형에 제한되어 있었으나, 본 연구는 다양한 손상 유형에 대해 효과적인 솔루션을 제공합니다.

- **Technical Details**: 본 연구는 각기 다른 손상 유형의 노이즈 데이터로부터 디퓨전 모델을 학습하며, 플러그 앤 플레이 몬테 카를로(plug-and-play Monte Carlo, PMC) 방법을 통해 재구성된 이미지로 모델을 훈련하는 과정을 반복합니다. 초기 추정(E-step)과 최대화(M-step) 과정을 반복하여 수렴에 도달하며, 이를 통해 더 정확한 클린 이미지 분포를 학습합니다. 주요 매개변수는 로스를 최소화하고 정밀한 후방 샘플링을 보장하도록 조정됩니다.

- **Performance Highlights**: 노이즈가 있는 CIFAR-10 및 CelebA 데이터셋에 대한 실험 결과, 제안된 방법이 기존 방법들과 비교하여 고충실도(high-fidelity) 디퓨전 프라이어를 효과적으로 학습하고, 이미지 재구성 품질을 유의미하게 향상시킨다는 것을 보여주었습니다.



### Ctrl-U: Robust Conditional Image Generation via Uncertainty-aware Reward Modeling (https://arxiv.org/abs/2410.11236)
Comments:
          Preprint. Work in progress

- **What's New**: 본 논문에서는 사용자 지침에 따라 이미지를 생성하는 조건부 이미지 생성(conditional image generation) 작업에 중점을 두고 있습니다. 저자들은 기존의 패널티 시스템의 한계를 극복하기 위해, 불확실성을 고려한 보상 모델링(unity-aware reward modeling)인 Ctrl-U를 제안하며, 이는 부정확한 피드백의 부정적 영향을 최소화합니다.

- **Technical Details**: Ctrl-U는 불확실성 추정(uncertainty estimation)과 불확실성 인식 정규화(uncertainty-aware regularization)를 포함하는 두 단계로 구성됩니다. 이 방법을 통해 이미지를 생성하는 과정에서 보상의 가중치를 상황에 맞게 조정하며, 낮은 불확실성을 가진 보상에는 높은 가중치를 부여하여 신뢰할 수 있는 신호에서 학습하도록 합니다.

- **Performance Highlights**: 다양한 조건 시나리오에서의 확장성(scalability)과 이미지 품질 생성을 포함하여 총 다섯 개의 벤치마크에서 실험을 통해 그 유효성을 입증하였습니다. 이를 통해 이미지 생성의 제어 가능성(controllability)과 생성 품질을 향상시킬 수 있음을 보여줍니다.



### Representation Similarity: A Better Guidance of DNN Layer Sharing for Edge Computing without Training (https://arxiv.org/abs/2410.11233)
Comments:
          3 pages, 4 figures, ACM MobiCom '24, November 18-22, 2024, Washington D.C., DC, USA

- **What's New**: 이번 논문에서는 기존의 모델 병합 기술의 한계를 극복하고, 데이터 전송 및 처리 지연을 줄이며 엣지 디바이스에서의 메모리 제약을 해결할 수 있는 새로운 방식으로 레이어의 출력을 공유하는 방법을 제안합니다. 이를 통해 ground truth 없이도 병합 모델의 성능을 예측할 수 있는 가능성을 보여줍니다.

- **Technical Details**: 모델 병합 기술은 서로 다른 DNN(Deep Neural Networks)에서 아키텍처적으로 동일한 레이어들을 결합하는 전통적인 방식에서 벗어나, 레이어의 출력을 공유하는 방식을 채택합니다. 이 방법은 Centered Kernel Alignment (CKA) 메트릭을 이용하여 레이어 유사성을 정량화하고, 이를 기반으로 병합된 모델의 정확도를 예측합니다. 이로 인해, 아키텍처적으로 동일하지 않은 레이어들도 함께 병합할 수 있는 가능성을 열었습니다.

- **Performance Highlights**: 제안된 방법을 통해 레이어 간의 유사성을 평가한 결과, Pearson 상관계수 |r| > 0.94로 나타나 병합된 모델의 정확도가 유사성과 매우 밀접한 관계가 있다는 것을 보여주었습니다. 새로운 방법론을 통해 엣지 디바이스에서 메모리 효율성을 높이면서도 성능을 유지할 수 있는 가능성이 확인되었습니다.



### TEOcc: Radar-camera Multi-modal Occupancy Prediction via Temporal Enhancemen (https://arxiv.org/abs/2410.11228)
Comments:
          Accepted by ECAI2024

- **What's New**: 본 논문은 radar-camera 멀티 모달의 시간 강화(temporal enhanced) 점유 예측 네트워크인 TEOcc를 제안합니다. 이 네트워크는 3D 객체 탐지에서 시간 정보를 활용한 성공을 기반으로 하며, 기존의 점유 예측 방법이 장기적 시간 정보를 충분히 활용하지 못한 문제를 해결하고자 합니다.

- **Technical Details**: TEOcc의 주요 기술적 특징은 시간 강화(branch)와 다중 모달 입력을 활용한 점유 예측을 통합하는 것입니다. 이 네트워크는 각기 독립적인 장기 및 단기 시간 디코더를 사용하여 상대적으로 무작위로 버려진 입력 프레임의 3D 점유 사항을 예측합니다. 또한, 연산 비용을 줄이기 위해 3D convolutional layers를 특별히 설계하였습니다.

- **Performance Highlights**: TEOcc는 nuScenes 벤치마크에서 최첨단(시대적인) 성능의 점유 예측을 달성하였으며, 제안된 시간 강화 브랜치는 기존 점유 예측 방법에 쉽게 통합할 수 있는 플러그 앤 플레이 모듈로서 성능 개선에 기여할 수 있습니다.



### A CLIP-Powered Framework for Robust and Generalizable Data Selection (https://arxiv.org/abs/2410.11215)
Comments:
          10 pages

- **What's New**: 본 논문에서는 CLIP 기반의 데이터 선택 프레임워크를 제안하여 다중 모달 정보(multimodal information)를 활용한 보다 견고하고 일반화 가능한 데이터 선택을 가능하게 합니다. 이는 카테고리 텍스트가 이미지 모달리티(image modality)를 보완하여 전체 성능을 향상시키는 데 기여합니다.

- **Technical Details**: 제안된 프레임워크는 데이터셋 적응(dataset adaptation), 샘플 스코어링(sample scoring), 선택 최적화(selection optimization)의 세 가지 주요 모듈로 구성되며, 각 모듈이 광범위하게 미리 훈련된 다중 모달 지식을 활용하여 샘플의 영향을 포괄적으로 평가하고 다중 목적 최적화(multi-objective optimization)를 통해 선택 결과를 최적화합니다.

- **Performance Highlights**: 다양한 벤치마크 데이터셋에서의 실험 결과 제안된 방법이 기존 최첨단 방법들보다 지속적으로 더 우수한 성능을 보였으며, 특히 노이즈나 손상된 샘플을 효과적으로 제거하여 적은 데이터로 더 높은 성능을 달성했습니다. 예를 들어, CIFAR-100에서 8.13%, Tiny-ImageNet에서 4.41%의 정확도 향상이 있었습니다.



### CVCP-Fusion: On Implicit Depth Estimation for 3D Bounding Box Prediction (https://arxiv.org/abs/2410.11211)
Comments:
          7 pages, 5 figures. arXiv admin note: text overlap with arXiv:2205.02833 by other authors

- **What's New**: 본 논문에서는 Cross-View Center Point-Fusion (CVCP-Fusion)이라는 최첨단 모델을 제안하며, 이 모델은 카메라와 LiDAR에서 파생된 기능을 BEV 공간에서 결합하여 3D 객체 감지의 정확도를 향상시킵니다. 기존의 점 기반(point-level) 융합 방법과의 차별점은 카메라의 세부 정보를 보존하는 동시에 LiDAR의 공간 데이터를 통합해 정확한 바운딩 박스 예측을 가능하게 합니다.

- **Technical Details**: CVCP-Fusion 아키텍처는 Cross-View Transformers와 CenterPoint 알고리즘을 활용하여, 두 입력 스트림을 평행으로 처리하면서 실시간 성능을 제공할 수 있도록 최적화됩니다. 이미지 특징은 EfficientNet-B4 아키텍처를 통해, LiDAR 특징은 Point Pillars Network 3D Encoder를 사용하여 추출됩니다. 이 모델은 공유된 BEV 공간에서 다중 센서 데이터를 융합해 시각적 정보를 보존하며, 각 입력 스트림에 대한 모달 전용 인코더를 통과시켜 3D 세계-뷰 공간에서 특징을 결합합니다.

- **Performance Highlights**: 실험 결과, CVCP-Fusion 모델은 다양한 환경에서 높은 정확도로 3D 바운딩 박스를 예측하는 성능을 보여주었으며, LiDAR-융합 모델과 비교하여 대폭 향상된 성능을 기록했습니다. 이 모델은 다양한 날씨 환경과 교통 상황에서도 안정적으로 작동하며, 실시간 처리에 적합한 효율성과 정확성을 제공합니다.



### DreamSteerer: Enhancing Source Image Conditioned Editability using Personalized Diffusion Models (https://arxiv.org/abs/2410.11208)
Comments:
          Published as a conference paper at NeurIPS 2024

- **What's New**: 최근의 텍스트-이미지 개인화 방법들이 사용자가 지정한 개념을 몇 개의 이미지로 학습하여 새로운 맥락에서 이를 재사용하는 데 큰 가능성을 보이고 있습니다. 본 연구에서는 이미지 편집을 위한 개인화된 개념을 사용하는 DreamSteerer라는 플러그인 방법을 제안합니다. 이는 기존 T2I 개인화 방법의 편집 가능성을 향상시키는데 중점을 두고 있습니다.

- **Technical Details**: DreamSteerer는 출발 이미지에서의 편집 가능성을 향상시키기 위해 Editability Driven Score Distillation (EDSD)이라는 새로운 목표를 도입합니다. 이 과정에서 확률적 점수 증류 샘플링을 통해 개인화된 Diffusion 모델의 현상 좁힘 문제를 해결하고, 이와 함께 Delta Denoising Score 프레임워크의 두 가지 주요 수정을 통해 개인화된 개념을 사용하는 고충실도 로컬 편집을 가능케 합니다.

- **Performance Highlights**: Extensive experiments demonstrated that DreamSteerer significantly improves the editability of existing T2I personalization methods, especially in challenging scenarios that require significant structural adjustments and a small number of fine-tuning steps (∼10) to achieve these improvements.



### Tree of Attributes Prompt Learning for Vision-Language Models (https://arxiv.org/abs/2410.11201)
- **What's New**: 본 논문에서는 Tree of Attributes Prompt learning (TAP)을 제안하여, 기존의 방법이 범주 이름만으로 구성된 학습 가능한 프롬프트(learnable prompt tokens)를 사용하여 텍스트 특성을 얻는 한계점을 극복하고자 합니다. TAP는 각 범주에 대해 '개념 - 속성 - 설명' 구조의 속성 트리를 생성하고, 이 계층 구조를 학습하여 시각 및 텍스트 프롬프트와 통합합니다.

- **Technical Details**: TAP 방법은 기존의 비구조적 설명 집합으로 범주 이름을 단순히 보강하는 접근 방식과는 달리, LLMs(large language models)에서 클래스 이름과 관련된 구조화된 지식 그래프를 정제하여 이들을 시스템적으로 통합합니다. 이를 통해 각 속성의 세부 정보를 체계적으로 구성하며, 입력된 이미지의 내용에 기반하여 가장 적합한 설명을 추출하는 vision-conditional pooling 모듈도 도입하였습니다.

- **Performance Highlights**: TAP는 11개의 다양한 데이터셋에서 제로샷(base-to-novel) 일반화, 크로스 데이터셋 전이(cross-dataset transfer), 그리고 몇 샷(classification) 분류에서 최첨단(state-of-the-art) 방법을 능가하는 성능 향상을 달성했습니다. 평균적으로 1.07%의 성과 향상을 보여주었고, CLIP에 비해 9.34%의 개선 효과를 나타냈습니다.



### Multiview Scene Graph (https://arxiv.org/abs/2410.11187)
Comments:
          To be published in NeurIPS 2024. Website at this https URL

- **What's New**: 이 논문에서는 유사한 시각적 인식 능력을 가진 AI 모델의 개발을 목표로 한 Multiview Scene Graph (MSG) 생성을 제안합니다. MSG는 연결된 장소 및 객체 노드로 구성된 장면의 위상을 표현합니다.

- **Technical Details**: MSG는 시각적인 장소 인식, 객체 탐지, 객체 연결 작업을 동시에 처리해야 하며, 새로운 Transformer 기반 아키텍처인 Attention Association MSG (AoMSG)를 사용하여 장소와 객체의 임베딩을 공동으로 학습합니다. MSG는 기존의 3D 장면 그래프와 달리 깊이 및 포즈 정보가 필요하지 않습니다.

- **Performance Highlights**: 실험 결과, 제안된 AoMSG 모델이 기존의 관련 기법들에 비해 우수한 성능을 보여 주며, 공간 인식의 발전 필요성을 확인했습니다.



### Synthesizing Proton-Density Fat Fraction and $R_2^*$ from 2-point Dixon MRI with Generative Machine Learning (https://arxiv.org/abs/2410.11186)
- **What's New**: 이번 연구에서는 두 점 Dixon MRI에서의 PDFF(프로톤 밀도 지방 분율) 및 R2*(자기 공명 완화 시간 상수)의 수치를 얻기 위한 생성적 머신러닝 접근법을 제안합니다. 인접한 voxels(부피 요소) 간의 유사성을 활용하여, 기존의 전통적인 방법보다 더 정확한 결과를 도출합니다.

- **Technical Details**: 우리는 UK Biobank 데이터셋을 활용하여, Pix2Pix conditional GAN(조건부 생성 적대 신경망)을 통해 두 점 Dixon MRI로부터 PDFF 및 R2* 를 보간하는 방법을 개발하였습니다. 이 연구에서는 기존 기술에 비해 각 voxel에서 두 점 Dixon MRI만으로 유의미한 R2* 를 추정하는 데 성공했습니다.

- **Performance Highlights**: 제안된 접근법을 통해 생성한 PDFF 및 R2* 맵은 기존의 voxel-wise(부피 요소 수준) 기법보다 더 큰 상관관계를 보였으며, 특히 R2* 추정에서 전통적인 방법이 실패했던 경우에서도 좋은 정확도를 유지했습니다.



### Improving Bias in Facial Attribute Classification: A Combined Impact of KL Divergence induced Loss Function and Dual Attention (https://arxiv.org/abs/2410.11176)
Comments:
          15 pages, 9 figures, 5 tables

- **What's New**: 이 논문은 AI 기반 얼굴 인식 시스템의 공정성을 높이기 위한 새로운 접근 방식을 제안합니다. 이 방법은 사전 훈련된 Inception-ResNet V1 모델을 사용하여 듀얼 어텐션 메커니즘을 적용하고, KL-다이버전스(KL-divergence) 정규화와 크로스 엔트로피 손실 함수(cross-entropy loss function)를 통해 개선되었습니다.

- **Technical Details**: 제안된 방법은 데이터의 다양성, 공정성과 정확성의 균형, 불균형 및 편향 측정과 같은 많은 문제들을 해결하는 데 도움을 줄 수 있습니다. 특히, transfer learning을 이용하여 편향을 줄이고, 정확도와 계산 효율성을 향상시킵니다.

- **Performance Highlights**: 실험 결과, 공정성과 분류 정확도 모두에서 유의미한 개선이 보여줍니다. 이는 얼굴 인식 시스템의 신뢰성을 높이는 데 긍정적인 발전을 제공합니다.



### Towards General Deepfake Detection with Dynamic Curriculum (https://arxiv.org/abs/2410.11162)
Comments:
          Received by ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)

- **What's New**: 이번 연구에서는 Deepfake 탐지를 위해 새로운 표본 강도를 훈련 과정에 도입하는 커리큘럼 학습(Curriculum Learning) 패러다임을 제안합니다. 제안된 방법론은 모델이 훈련 중에 점진적으로 어려운 표본에 집중할 수 있도록 돕습니다.

- **Technical Details**: Dynamic Facial Forensic Curriculum (DFFC)이라는 새로운 접근 방식을 제안하며, 이는 Dynamic Forensic Hardness (DFH)를 통해 훈련 중 표본의 강도를 동적으로 측정합니다. DFH는 얼굴 품질 점수와 즉각적인 인스턴스 손실을 통합하여 정의됩니다. 또한, DFFC는 쉬운 표본에서 어려운 표본으로 훈련 데이터를 단계적으로 제어하는 페이싱 함수(Pacing Function)를 통합합니다.

- **Performance Highlights**: DFFC를 통해 다양한 종류의 end-to-end Deepfake 탐지기의 성능을 개선할 수 있음을 보여주는 포괄적인 실험 결과를 도출하였습니다. DFFC는 플러그 앤 플레이 방식으로 기존 탐지기에 쉽게 적용할 수 있으며, 어려운 표본의 정보를 효과적으로 활용하여 일반적인 변조 특징 학습을 지원합니다.



### MANet: Fine-Tuning Segment Anything Model for Multimodal Remote Sensing Semantic Segmentation (https://arxiv.org/abs/2410.11160)
Comments:
          12 pages, 9 figures

- **What's New**: 이 연구에서는 다중 모드 원거리 감시 데이터에 대한 새로운 다중 모드 어댑터 기반 네트워크(MANet)를 소개합니다. 이는 Segment Anything Model(SAM)의 이미지를 인코더를 통해 다중 모드 데이터를 효과적으로 활용하도록 조정합니다.

- **Technical Details**: 본 연구의 핵심에는 MMAdapter(다중 모드 어댑터) 개발이 있으며, 이는 SAM의 이미지 인코더를 미세 조정하여 다중 모드 원거리 감시 데이터의 통합을 용이하게 합니다. 또한, Deep Fusion Module을 통해 다양한 스케일의 지리적 특성을 통합합니다.

- **Performance Highlights**: 제안된 MANet은 ISPRS Vaihingen 및 ISPRS Potsdam의 두 개의 고해상도 다중 모드 원거리 감시 데이터셋에서 기존 모델을 크게 초월하는 성능을 보였습니다.



### UAV3D: A Large-scale 3D Perception Benchmark for Unmanned Aerial Vehicles (https://arxiv.org/abs/2410.11125)
Comments:
          Accepted at NeurIPS 2024

- **What's New**: UAV3D는 무인 항공기(UAV)가 3D 인식을 효과적으로 수행할 수 있도록 지원하는 새로운 벤치마크 데이터셋입니다. 이 데이터셋은 1,000개의 서로 다른 장면으로 구성되어 있으며, 각 장면마다 20개의 프레임이 포함되어 있고, 차량에 대한 완전한 3D 바운딩 박스 주석이 제공됩니다.

- **Technical Details**: UAV3D 데이터셋은 CARLA 및 AirSim 시뮬레이터를 이용하여 생성되었으며, 단일 UAV 및 다중 UAV의 협동 인식 작업을 지원하는 네 가지 3D 인식 작업에 대한 벤치마크를 제공합니다. 이 데이터셋은 3D 객체 감지, 객체 추적 및 협동 3D 객체 감지 및 추적을 포함합니다.

- **Performance Highlights**: UAV3D는 현재 사용 가능한 다른 UAV 데이터셋보다 약 4배 큰 규모(500,000 이미지)를 가지고 있으며, UAV에 대한 협동 인식 연구를 발전시키는 데 기여할 것으로 기대됩니다.



### Real-Time Localization and Bimodal Point Pattern Analysis of Palms Using UAV Imagery (https://arxiv.org/abs/2410.11124)
Comments:
          25 pages, 8 figures, 5 tables

- **What's New**: 이 논문에서는 열대 우림에서 야생 종으로 자생하는 팜(야자) 분포를 분석하기 위해 PalmDSNet이라는 새로운 딥러닝 프레임워크를 제안합니다. 이 프레임워크는 실시간으로 팜을 감지, 분할 및 집계할 수 있으며, bimodal reproduction algorithm을 결합하여 팜의 공간 분포를 개선하고자 합니다.

- **Technical Details**: PalmDSNet은 UAV(무인 항공기)에서 캡처한 고해상도 이미지를 사용하며, 총 21개 지역에서 데이터 세트를 수집하였습니다. 이 데이터 세트에는 7,356개의 바운딩 박스와 7,603개의 팜 중심 지점이 포함되어 있으며, 이는 449헥타르의 면적을 포함합니다. 또한 Poisson-Gaussian reproduction algorithm을 사용하여 팜의 공간 분포를 시뮬레이션합니다.

- **Performance Highlights**: PalmDSNet과 bimodal reproduction algorithm의 조합을 통해 다양한 열대 환경에서 팜의 공간 분포를 성공적으로 모사할 수 있음을 입증했습니다. 이 모델은 지역적 및 글로벌 공간 변동성을 최적화하여 열대 우림의 지속 가능한 관리 및 생태 모니터링에 유용한 도구로 자리매김할 수 있습니다.



### MoonMetaSync: Lunar Image Registration Analysis (https://arxiv.org/abs/2410.11118)
- **What's New**: 본 논문은 SIFT(Scale-Invariant Feature Transform)와 ORB(Oriented FAST and Rotated BRIEF) 특징 검출 방법을 비교하고, 새로운 특성 검출기인 IntFeat를 소개합니다. 특히, IntFeat는 달 이미지에 적용되어 두 가지 해상도 (저해상도: 128x128, 고해상도: 1024x1024)에서 성능을 평가합니다.

- **Technical Details**: IntFeat는 SIFT와 ORB의 고수준 및 저수준 특징을 통합하여 강력한 달 이미지 정합을 제공합니다. 연구팀은 SycnVision이라는 파이썬 패키지를 도입하여 다양한 정합 방법 (SIFT, ORB, IntFeat)을 비교하고, 저해상도 달 이미지의 업스케일링에 있어서 bi-linear 및 bi-cubic 보간 방법을 사용하여 정합 효과성을 평가했습니다.

- **Performance Highlights**: IntFeat는 SSIM(Structural Similarity Index Measure)과 PSNR(Peak Signal-to-Noise Ratio) 지표를 통해 평가된 결과, SIFT와 ORB 사이에서 균형 잡힌 성능을 보여줍니다. 저해상도 달 이미지와 고각 이미지에서 IntFeat는 SIFT와의 성능 격차를 최소화하며, 특히 bi-linear 보간에서 SIFT의 성능에 근접한 결과를 도출했습니다.



### Classifying Healthy and Defective Fruits with a Multi-Input Architecture and CNN Models (https://arxiv.org/abs/2410.11108)
Comments:
          7 pages, 11 figures

- **What's New**: 이 논문은 다중 입력 (Multi-Input) 아키텍처를 활용하여 과일 (사과와 망고)을 건강한 상태와 결함 상태로 분류하는 연구를 다룹니다. RGB 및 실루엣(silhouette) 이미지를 사용하여 CNN (Convolutional Neural Networks) 모델의 정확성을 향상시키는 것을 목표로 하고 있습니다.

- **Technical Details**: 이미지 획득, 데이터셋 전처리, 두 개의 CNN 모델 (MobileNetV2 및 VGG16)의 훈련 및 평가 방법론을 포함합니다. 본 연구에서 실루엣 이미지를 상호 결합함으로써 다중 입력 아키텍처를 통해 과일의 독특한 특징을 더 잘 포착하여 높은 분류 정확도를 얻었습니다.

- **Performance Highlights**: MobileNetV2 모델을 사용하여 건강한 사과 분류에서 100%의 정확도를 달성하였고, 망고는 99.53%의 정확도를 보였습니다. 이는 이전 연구보다 향상된 결과로, 과일의 내부 품질 검사를 위한 적용 가능성이 큽니다.



### EchoApex: A General-Purpose Vision Foundation Model for Echocardiography (https://arxiv.org/abs/2410.11092)
- **What's New**: 이 논문은 심장 초음파(echocardiography)를 위한 최초의 범용 비전 파운데이션 모델인 EchoApex를 소개합니다. 2000만 개 이상의 초음파 이미지를 기반으로 학습되어 다양한 임상 적용 사례에서 우수한 성능을 입증합니다.

- **Technical Details**: EchoApex는 자가 지도 학습(self-supervised learning)을 활용하여 11개의 임상 센터에서 수집된 2000만 개의 초음파 이미지로 사전 훈련(pretrained)되었으며, 4가지 임상 응용과 28개의 하위 작업에서 효과성을 입증합니다. 모델은 TTE(Trans-thoracic echocardiogram), TEE(Trans-esophageal echocardiogram), ICE(Intracardiac echocardiogram) 이미지를 포함하는 다양한 초음파 데이터를 사용합니다.

- **Performance Highlights**: EchoApex는 4개의 다양한 임상 작업에서 기존의 최첨단(task-specific) 모델과 비교하여 우수한 성능을 보여주었습니다. 통합된 이미지 인코딩 아키텍처로 사전 훈련된 모델은 downstream tasks에 쉽게 적응할 수 있는 유연성을 가지며, 진단 정확도를 향상시키고 환자 결과를 개선하는 가능성을 제시합니다.



### Locality Alignment Improves Vision-Language Models (https://arxiv.org/abs/2410.11087)
- **What's New**: 최근 Vision Language Models (VLMs)의 채택이 증가하고 있지만, 기본적인 공간 추론 오류를 겪고 있는 경우가 많습니다. 본 연구에서는 ViTs(vision transformers)가 이미지 수준(supervision)에서 훈련되어 공간적 의미 정보를 효율적으로 인코딩하지 못하는 것에 기인한다고 가정하고, 이를 해결하기 위한 새로운 post-training 기법인 locality alignment와 MaskEmbed을 제안합니다.

- **Technical Details**: 제안된 MaskEmbed 방법은 마스크가 적용된 패치 임베딩을 통해 마스크된 뷰를 재구성하며, 이를 통해 지역화된(localized) 이미지 의미를 학습합니다. locality alignment 단계는 기존 이미지 수준(supervision)에서 훈련된 강력한 모델을 활용하여 지역적 의미를 효과적으로 학습할 수 있도록 돕습니다.

- **Performance Highlights**: 실험을 통해 locality alignment가 ViTs의 패치 수준 의미 분할 성능을 개선하고, 각종 벤치마크에서 VLM의 성능 향상을 보여주었습니다. 특히 공간 이해(spatial understanding)가 필요한 작업에서 개선된 성능을 입증하였으며, CLIP 및 SigLIP과 같은 언어 기반(supervised) 모델에 대한 효과가 두드러졌습니다.



### Few-shot Novel View Synthesis using Depth Aware 3D Gaussian Splatting (https://arxiv.org/abs/2410.11080)
Comments:
          Presented in ECCV 2024 workshop S3DSGR

- **What's New**: 이 연구는 제한된 뷰에서의 새로운 뷰 합성(few-shot novel view synthesis)을 위한 depth-aware Gaussian splatting 방법을 제안합니다. 이 방법은 단 몇 개의 입력 뷰만으로도 뛰어난 렌더링 품질을 달성할 수 있게 합니다.

- **Technical Details**: 이 접근법은 모노큘러(depth) 깊이 예측을 사전 정보로 사용하고, 스케일-불변(depth scale-invariant) 깊이 손실을 통해 3D 형태를 제약합니다. 또한 색상 모델링을 위해 저차 구형 고조파(lower-order spherical harmonics)를 사용하여 과적합(overfitting)을 피하는 방식으로 개선하였습니다.

- **Performance Highlights**: 제안된 방법은 기존의 3D Gaussian splatting 방법보다 Peak Signal-to-Noise Ratio(PSNR)에서 10.5%, 구조적 유사도 지수(SSIM)에서 6%, 그리고 인지적 유사성(LPIPS)에서 14.1% 개선된 성능을 보이며, 제한된 뷰에서도 효과적인 성능 향상을 달성함을 입증하였습니다.



### Character-aware audio-visual subtitling in contex (https://arxiv.org/abs/2410.11068)
Comments:
          ACCV 2024

- **What's New**: 본 논문은 TV 쇼에서 캐릭터 인식 오디오-비주얼 자막 생성을 위한 개선된 프레임워크를 제시합니다. 이 방법은 음성 인식, 화자 구분(speaker diarisation), 캐릭터 인식을 통합하여 오디오 및 비주얼 신호를 모두 활용합니다.

- **Technical Details**: 우리는 두 가지 주요 접근 방식을 통해 성과를 개선했습니다. 첫째, 짧은 대화 세그먼트에 대해 캐릭터를 식별하기 위해 주변 대화의 시간적 맥락을 활용합니다. 둘째, 입술 움직임에 대한 로컬 비주얼 임베딩(local visual embedding)을 사용하여 화자를 결정합니다. 이 두 가지 방식은 기존 방법보다 높은 정확도를 제공합니다.

- **Performance Highlights**: 12개의 TV 쇼로 구성된 데이터셋에서 본 방법의 성능을 검증한 결과, 기존의 방법들보다 화자 구분과 캐릭터 인식에서 우수한 성과를 나타내었습니다.



### Beyond Fixed Topologies: Unregistered Training and Comprehensive Evaluation Metrics for 3D Talking Heads (https://arxiv.org/abs/2410.11041)
- **What's New**: 이 연구에서는 3D 얼굴 애니메이션 생성 이론에 혁신적인 접근법인 ScanTalk를 제시하여 고정된 토폴로지 제약을 극복합니다. 이 프레임워크는 임의의 메쉬 토폴로지에서 작동할 수 있으며, 기존의 등록된 설정의 필요성을 없앱니다.

- **Technical Details**: ScanTalk는 메쉬에 대한 열 확산(heat diffusion)을 활용하여 고정된 토폴로지 제약을 해결합니다. 두 가지 훈련 설정인 지도 학습(supervised)과 비지도 학습(unsupervised)을 통해 효과적인 시간 의존적 변형을 지원합니다. 또한, 새로운 평가 메트릭을 도입하여 발음 구술과 얼굴 움직임 간의 동기화 평가를 향상시킵니다.

- **Performance Highlights**: ScanTalk는 고정된 토폴로지 기법에 비해 유리한 성능을 보여주며, 3D 대화형 얼굴 생성에 대한 새로운 벤치마크를 수립합니다. 전체 비유동적인 메쉬에 대해 신뢰성과 사실성을 유지하면서 회전하는 표정과 입 모양 복제를 성공적으로 수행합니다.



### ET-Former: Efficient Triplane Deformable Attention for 3D Semantic Scene Completion From Monocular Camera (https://arxiv.org/abs/2410.11019)
- **What's New**: 본 연구에서는 단일 모노카메라를 사용하여 의미적 장면 완성을 위한 새로운 최첨단 알고리즘인 ET-Former를 소개합니다. ET-Former는 단일 RGB 관찰로부터 의미적 점유 맵(occupancy map)을 생성하며, 동시에 의미적 예측의 불확실성 추정을 제공합니다.

- **Technical Details**: ET-Former는 트리플레인 기반의 변형 가능한 주목(attention) 메커니즘을 설계하여 장면의 기하학적 이해를 개선하고 의미적 예측의 노이즈를 줄입니다. 또한, Conditional Variational AutoEncoder (CVAE)를 통해 이러한 예측의 불확실성을 추정합니다. 이 접근 방식은 VoxFormer의 이단계 모델을 활용하여 첫 번째 단계에서 모노카메라의 점유를 추정하고 두 번째 단계에서 3D 의미적 점유 맵을 완성하는 데 도움을 줍니다.

- **Performance Highlights**: ET-Former는 Semantic-KITTI 데이터셋에서 평가된 결과, 기존 방법보다 IoU에서 15.16% 초과, mIoU에서 24.24% 초과라는 최고의 성능을 기록하였으며, 기존 방법에 비해 GPU 메모리 사용량을 25%-50.5% 줄였습니다.



### Stationary Velocity Fields on Matrix Groups for Deformable Image Registration (https://arxiv.org/abs/2410.10997)
- **What's New**: 이 연구는 Stationary Velocity Field (SVF) 접근법의 개념을 확장하여, 특히 Euclidean 변환을 저주파 성분으로 옮기고, 더 큰 변형을 보다 쉽게 회복할 수 있도록 하는 새로운 방법론을 제안합니다.

- **Technical Details**: 본 논문은 변형 공간(Deformation Space) \\mathcal{D}의 선택 및 매개변화(Parametrization)에 중점을 두고, 흐름 방정식(Flow Equation)의 확장의 필요성을 제시합니다. 여기서 유효한 흐름 방정식의 존재 조건과 효율적인 수치적 통합을 위한 스케일링 및 제곱 접근법(Scaling-and-Squaring Approach)을 제시합니다. 또한, 본 연구에서는 인체 뇌의 3D MRI 이미지를 사용한 환자 간 정합(inter-patient registration) 과정을 통해 제안한 방법을 수치적으로 검증하였습니다.

- **Performance Highlights**: 제안한 SE(3) 접근법을 사용하여 두 개의 MRI 뇌 스캔 이미지 등록에서, 기존 SVF 접근법에 비해 향상된 정합 성능이 관찰되었습니다. 특히, 더 큰 변형을 포함하는 경우 제안된 방법이 기존 방법보다 유리한 결과를 보였습니다.



### Cultural Heritage 3D Reconstruction with Diffusion Networks (https://arxiv.org/abs/2410.10927)
Comments:
          Accepted by the workshop VISART for ECCV 2024

- **What's New**: 최근 생성형 AI 알고리즘을 활용하여 문화유산 복원에 대한 연구를 진행하였으며, 조건부 확산 모델(conditional diffusion model)을 통해 3D 포인트 클라우드(point clouds)를 효과적으로 재구성하는 방법을 제시합니다.

- **Technical Details**: 이 연구에서는 확산 모델을 기반으로 하여 객체의 결손 부분 생성을 관찰된 부분 입력에 조건화하는 방법을 제안합니다. 이 모델은 물체 복원에 있어 일반화 능력을 평가하며, 고고학적 부분의 수리를 위해 훈련된 특정 방법론을 채택합니다. 확산 과정은 마코프 체인(Markov chain)으로 모델링되며, Gaussian 분포를 사용하여 점진적으로 노이즈를 추가하고 제거하는 방식으로 작동합니다.

- **Performance Highlights**: 결과적으로 이 확산 모델은 데이터 다양성과 이상치(outlier) 민감성과 같은 도전 과제를 극복하면서도 문화유산 기하학을 정확하게 재현할 수 있는 가능성을 보여줍니다. 이 연구는 AI 기술을 사용한 고대 유물 복원 방법론의 발전을 위한 기초를 마련하고 있습니다.



### Lotus: learning-based online thermal and latency variation management for two-stage detectors on edge devices (https://arxiv.org/abs/2410.10847)
Comments:
          DAC'24, code is available at: this https URL

- **What's New**: 이 논문에서는 두 단계(object detection) 검출기의 구성 및 특성에 맞춰 개발된 새로운 프레임워크, Lotus를 소개하고 있습니다. Lotus는 CPU와 GPU의 주파수 조정을 통해 동적으로 온도 및 지연 변화를 관리하여 사용자 경험을 향상시키고자 하며, 깊은 강화 학습(DRL)을 기반으로 합니다.

- **Technical Details**: Lotus 프레임워크는 두 가지 단계에서 CPU와 GPU 주파수를 동시 조정하여 지연 변화를 줄이며 온도를 관리합니다. 특히, Region Proposal Network (RPN)에서 각 이미지의 동적 제안 수에 따라 발생하는 지연 변화를 처리합니다. Lotus는 DRL 접근 방식을 활용하여 복잡한 환경에서의 주파수 조정을 최적화합니다.

- **Performance Highlights**: Lotus를 NVIDIA Jetson Orin Nano 및 Mi 11 Lite 플랫폼에 구현한 결과, 지연 변화를 최대 72.8% 감소시키고, 추론 속도는 최대 30.8% 향상했으며, 지연 제약을 충족하는 이미지 비율은 최대 43.8% 증가하는 등의 성과를 보였습니다.



### Focus On What Matters: Separated Models For Visual-Based RL Generalization (https://arxiv.org/abs/2410.10834)
- **What's New**: 본 논문은 이미지 재구성을 활용하여 일반화 능력을 향상시키기 위한 새로운 접근법인 SMG(Separated Models for Generalization)를 제안합니다. SMG는 시각적 관찰에서 과제 관련(task-relevant)과 과제 비관련(task-irrelevant) 표현을 구분하여 추출하는 두 개의 모델 브랜치를 도입합니다.

- **Technical Details**: SMG는 두 개의 일관성 손실(consistency losses)을 추가하여 다양한 시나리오에서 과제 관련 영역에 대한 에이전트의 초점을 유도합니다. 이 구조는 단일 모델 구조에서 발생할 수 있는 과제 비관련 특징에 대한 과적합(overfitting) 위험을 회피하며, 안정적인 과제 관련 표현을 추출하게 합니다.

- **Performance Highlights**: SMG는 DMC에서의 광범위한 실험을 통해 일반화 성능에서 SOTA(state-of-the-art)를 달성하였으며, 비디오 배경 설정 및 로봇 조작 작업에서 특히 우수한 성능을 보여주었습니다.



### High-Fidelity 3D Lung CT Synthesis in ARDS Swine Models Using Score-Based 3D Residual Diffusion Models (https://arxiv.org/abs/2410.10826)
Comments:
          5 page, 3 figures, Submitted to SPIE 2025-Medical Imaging

- **What's New**: 이번 연구에서는 급성 호흡곤란 증후군(ARDS) 관리를 위한 전통적인 2D X-ray 이미지를 사용하여 고해상도 3D CT 이미지를 생성하는 새로운 방법을 제안합니다.

- **Technical Details**: 연구진은 score-based 3D residual diffusion model을 통해 2D 이미지를 기반으로 한 3D lung CT를 합성하였습니다. 이 방법은 생리학적 매개변수와 결합하여 lung aeration, atelectasis를 분석할 수 있습니다.

- **Performance Highlights**: 초기 결과에 따르면, 이 접근법을 통해 생성된 3D CT 이미지는 실제 데이터와 검증되어 ARDS 관리의 효과성을 높일 수 있는 가능성을 보여주고 있습니다.



### OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation (https://arxiv.org/abs/2410.11792)
Comments:
          Accepted for oral presentation at 8th Annual Conference on Robot Learning. Project website: this https URL

- **What's New**: 이번 연구에서는 단일 RGB-D 비디오에서 인간의 동작을 모방하여 휴머노이드 로봇의 조작 기술을 학습하는 새로운 방법인 OKAMI를 소개합니다. OKAMI는 객체 인식과 조작을 위한 리타게팅(Object-aware retargeting) 기술을 통해 다양한 객체 위치에 맞춰 로봇의 동작을 조정합니다.

- **Technical Details**: OKAMI 방법론은 두 단계로 구성됩니다. 첫 번째 단계에서는 주어진 RGB-D 비디오에서 참조 조작 계획을 생성하고, 두 번째 단계에서는 이 계획을 활용해 다중 조작이 가능한 휴머노이드의 동작을 리타겟합니다. 리타게팅 과정에서는 객체의 위치를 반영하여 로봇 동작을 적절히 조정합니다.

- **Performance Highlights**: OKAMI는 다양한 작업에 대한 테스팅에서 평균 성공률 71.7%를 달성했으며, 기존의 ORION 기준선을 58.3% 초과하는 성능을 보였습니다. 또한, OKAMI를 통한 클로즈드 루프 비주얼 모터 정책 훈련에서 평균 79.2%의 성공률을 달성했습니다.



### MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation (https://arxiv.org/abs/2410.11779)
Comments:
          Ongoing work

- **What's New**: 이번 연구에서 우리는 Multimodal Large Language Models (MLLMs)에서의 환각(hallucination) 현상을 심층적으로 분석하고, 이 현상의 배경 메커니즘을 이해하기 위한 새로운 동적 수정 디코딩 방법인 DeCo(이전 레이어 동지식 지능 수정)를 제안합니다.

- **Technical Details**: DeCo는 MLLM의 결론 층에 도달하기 전에 발생한 지식 정보를 동적으로 선택하여 최종 출력 로짓(logits)을 조정합니다. 이 방법은 모델에 구애받지 않으며, 여러 전통적인 디코딩 전략과 원활하게 통합될 수 있습니다.

- **Performance Highlights**: DeCo를 이미지 캡셔닝 및 시각 질문 답변 데이터셋에 적용한 결과, 평균 10.8%의 환각 억제 효과를 보여주었으며, 다양한 데이터셋에서 기존 방법들보다 더 높은 성능을 기록했습니다. 또한 DeCo는 이전 방법들과 비교했을 때 약간의 지연(latency) 증가가 있었지만, 속도는 훨씬 더 빨라졌습니다.



### DPD-NeuralEngine: A 22-nm 6.6-TOPS/W/mm$^2$ Recurrent Neural Network Accelerator for Wideband Power Amplifier Digital Pre-Distortion (https://arxiv.org/abs/2410.11766)
Comments:
          5 pages, 5 figures

- **What's New**: DPD-NeuralEngine는 Gated Recurrent Unit (GRU) 기반의 초고속, 소형, 전력 효율이 뛰어난 Digital Pre-distortion (DPD) 가속기로, 22nm CMOS 구현이 2 GHz에서 작동하며 250 MSps의 I/Q 신호 처리 속도를 자랑합니다. 이 논문은 AI 기반 DPD 전용 집적 회로(ASIC) 가속기의 첫 사례로, 6.6 TOPS/W/mm²의 전력 면적 효율(PAE)을 달성했습니다.

- **Technical Details**: DPD-NeuralEngine은 GRU-RNN 아키텍처로 설계되어 있으며, 전처리기, GRU 레이어, 완전 연결 층(FC layer)으로 구성됩니다. 입력 신호에서 추출된 네 개의 특징을 GRU에 입력하고, GRU의 출력 신호는 아날로그 신호로 변환되어 전력 증폭기로 전달됩니다. 하드웨어 설계는 실시간 추론을 위해 구성된 마이크로 아키텍처를 포함하여, 비선형 활성화 함수(unit)와 메모리 버퍼를 갖추고 있습니다.

- **Performance Highlights**: 실험 결과, DPD-NeuralEngine은 256.5 GOPS의 처리량과 1.32 TOPS/W의 전력 효율, -45.3 dBc의 인접 채널 전력 비율(ACPR), -39.8 dB의 오류 벡터 크기(EVM) 성능을 보여줍니다. 이러한 성과는 기존 DPD 프레임워크들보다 우수한 성능을 나타냅니다.



### Latent Action Pretraining from Videos (https://arxiv.org/abs/2410.11758)
Comments:
          Website: this https URL

- **What's New**: 이번 연구에서는 웹 스케일 비디오를 활용하여 로봇 액션 라벨 없이 비지도 방식으로 Vision-Language-Action 모델(VLA)을 사전 훈련하는 Latent Action Pretraining for General Action models (LAPA) 방법을 소개합니다. 이 방법은 기존 모델이 인간 텔레오퍼레이터에 의존하는 문제를 해결합니다.

- **Technical Details**: LAPA는 두 가지 사전 훈련 단계와 로봇 액션으로의 매핑을 배우기 위한 정밀 조정 단계로 구성됩니다. 첫 번째 단계에서 VQ-VAE 기반 목표를 사용하여 원시 이미지 프레임 간의 양자화된 잠재 액션을 학습하고, 두 번째 단계에서는 비디오 관찰 및 작업 설명을 기반으로 잠재 액션을 예측하는 Vision-Language 모델을 정교하게 훈련합니다.

- **Performance Highlights**: 실험 결과, LAPA의 성능은 기존의 행동 없는 비디오에서 조작 정책을 훈련하는 방법에 비해 유의미하게 향상되었으며, 특히 실세계 조작 작업에서 현재의 최첨단 VLA 모델보다 6.22% 더 뛰어난 성과를 보여주었습니다. 또한 30배 이상의 사전 훈련 효율성을 달성하였습니다.



### Robotic Arm Platform for Multi-View Image Acquisition and 3D Reconstruction in Minimally Invasive Surgery (https://arxiv.org/abs/2410.11703)
Comments:
          8 pages, 5 figures, 3 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 이 연구는 최소 침습 수술(Minimally Invasive Surgery, MIS) 환경에서의 효율적인 다중 시점(image acquisition) 이미지 수집 및 정확한 3D 재구성을 위한 로봇 팔 플랫폼을 제안합니다.

- **Technical Details**: 로봇 팔을 활용하여 여러 가지 조명 조건(운영실 및 복강경)과 경로(구형 및 복강경)에서 여러 양의 장기 이미지를 캡처했습니다. 최근 발표된 학습 기반(feature matchers) 특징 매칭 기법을 사용하고 COLMAP을 결합하여 재구성을 수행했습니다. 재구축의 정확성을 평가하기 위해 고정밀 레이저 스캔과 비교하였습니다.

- **Performance Highlights**: 재구성 결과는 실제 MIS 조명 및 경로에서 문제가 발생했지만, 우리의 파이프라인의 여러 버전은 평균 1.05 mm의 Root Mean Squared Error와 0.82 mm의 Chamfer 거리를 달성하여 거의 1mm 이하의 정확도에 도달했습니다. 최상의 재구성 결과는 운영실 조명 및 구형 경로에서 발생했습니다.



### Magnifier Prompt: Tackling Multimodal Hallucination via Extremely Simple Instructions (https://arxiv.org/abs/2410.11701)
Comments:
          9 pages, 13 tables, 4 figures

- **What's New**: 이 논문에서는 멀티모달 대형 언어 모델(MLLMs)에서 허위 정보(hallucinations)를 줄이기 위해 Magnifier Prompt (MagPrompt)라는 단순하면서도 효과적인 방법을 제안합니다. MagPrompt는 모델이 시각적 정보에 더 집중하도록 유도하며, 이미지와 내부 지식 간의 충돌이 있을 경우 이미지의 우선권을 강조하는 원칙에 기반합니다.

- **Technical Details**: MagPrompt는 훈련 없이 적용 가능하며, GPT-4o 및 Gemini와 같은 오픈소스와 클로즈드소스 모델에 모두 사용할 수 있습니다. 실험 결과, MagPrompt는 다양한 데이터셋에서 효과적으로 작동하며, 복잡한 방법인 VCD와 비교할 때 동등하거나 더 나은 성능을 보입니다. 이 방법은 간단한 지침을 통해 MLLMs의 허위 정보 문제를 해결할 수 있는 가능성을 보여줍니다.

- **Performance Highlights**: 실험에서 MagPrompt는 LLaVA-1.5와 Qwen-VL 모델에서 VCD보다 더 우수한 성능을 발휘했으며, F1 점수 전반에서 유의미한 향상을 기록했습니다. 또한 MagPrompt는 GPT-4o 및 Gemini와 같은 최신 클로즈드소스 모델에서도 적용 가능하여, 기존의 복잡한 방법들이 적용되지 않는 상황에서도 성능 향상을 가져왔습니다.



### SurFhead: Affine Rig Blending for Geometrically Accurate 2D Gaussian Surfel Head Avatars (https://arxiv.org/abs/2410.11682)
- **What's New**: 본 논문에서는 SurFhead라는 새로운 방법을 제안하여 RGB 비디오를 사용하여 조정 가능한 머리 기하형상을 재구성하는 기법을 소개합니다. 기존의 기법이 유사 변환에 의존하여 기하학적 세부 사항을 캡처하는 데 어려움을 겪고 있는 반면, SurFhead는 2D Gaussian surfels를 활용하여 높은 충실도의 렌더링을 보장합니다.

- **Technical Details**: SurFhead는 고정된 광선 교차점에서의 정밀한 깊이 및 표면 방향에서 파생된 노멀과 같은 정의된 기하학적 속성을 가진 2D Gaussian surfels를 활용하여 기하학적 변형을 추출합니다. 고전적인 메쉬 기반 변형 전이와 아핀 변형 보간을 통해 극단적인 포즈에서도 고충실도의 렌더링을 실현합니다. 제안한 Jacobian Blend Skinning(JBS) 알고리즘은 인접한 변형 간의 아핀 변형을 매끄럽게 보간할 수 있게 해줍니다.

- **Performance Highlights**: SurFhead는 기존 접근 방식에 비해 높은 충실도를 유지하며, 실제 및 합성 데이터에서 다양한 주제를 대상으로 뛰어난 성능을 입증하였습니다. 특히, 볼록한 안구의 날카로운 반사, 복잡한 기하학적 세부 사항 및 과장된 변형 경우에서도 우수한 결과를 도출해 냈습니다.



### Unveiling the Mystery of Visual Attributes of Concrete and Abstract Concepts: Variability, Nearest Neighbors, and Challenging Categories (https://arxiv.org/abs/2410.11657)
- **What's New**: 이번 연구에서는 구체적(concrete)인 개념과 추상적(abstract)인 개념의 시각적 표현의 다양성을 분석하였습니다. 약 1000개의 개념을 포함하는 이미지 데이터셋을 사용하여, 이 두 개념의 시각적 특징에 대한 이해를 증진하고자 하였습니다.

- **Technical Details**: 우리는 Bing과 YFCC에서 추출한 약 1000개의 추상적 및 구체적 개념에 대한 이미지를 활용하였습니다. 이 연구에서는 각 개념에 대한 이미지의 시각적 다양성을 평가하고, 최근접 이웃(nearest neighbor) 분석을 통해 시각적 특징의 변동성을 분석하였으며, 도전 요인을 분류하고 주석을 달았습니다. 연구 결과, ViT(Vision Transformer)보다 색상과 질감과 같은 기본적인 시각적 특징의 조합이 구체적 및 추상적 개념 분류에 더 효과적이라는 것을 발견하였습니다.

- **Performance Highlights**: 이미지 분류 실험에서, 구체적이고 추상적인 개념 간의 시각적 다양성을 성공적으로 구별할 수 있었으며, ViT는 최근접 이웃 분석에서 뛰어난 성능을 보였습니다. 이는 다른 텍스트 이외의 양식으로 개념 변수를 분석할 때 시각적 특징 선택의 신중함을 강조합니다.



### M$^{2}$M: Learning controllable Multi of experts and multi-scale operators are the Partial Differential Equations need (https://arxiv.org/abs/2410.11617)
Comments:
          30 pages, 16 figures

- **What's New**: 본 논문은 다중 규모 및 다중 전문가(M$^2$M) 신경 운영자(neural operator) 프레임워크를 도입하여 부분 미분 방정식(Partial Differential Equations, PDEs)을 효율적으로 시뮬레이션하고 학습하는 방법을 제안합니다. 이는 기존의 방법론들이 PDE의 복잡한 동적 시스템을 완전히 학습하지 못하는 문제를 해결하고자 합니다.

- **Technical Details**: M$^2$M 신경 운영자는 분할 정복(divide-and-conquer) 전략을 사용하여 다중 전문가 네트워크를 훈련시키며, 전문가의 선택 권한을 결정하는 제어 가능한 선행 게이팅 메커니즘을 통합하여 모델의 효율성을 높입니다. PI 제어 전략(Proportional, Integral control strategy)을 통해 학습 과정을 최적화하고, 맞춤형 다중 규모 데이터 세트를 제공하여 Navier-Stokes 방정식에서 성능을 검증합니다.

- **Performance Highlights**: M$^2$M은 기준선 방법들과 비교하여 높은 시뮬레이션 정확성을 달성하며, 모델의 해석 가능성을 향상시킵니다. 해당 연구는 효율적인 PDE 해법 및 다양한 스케일에서의 성능 통합이 가능한 가능성을 보여줍니다.



### DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object Manipulation via Preference-based Action Alignmen (https://arxiv.org/abs/2410.11584)
- **What's New**: 최근 모방 학습이 로봇 조작 분야에서의 발전을 이루었으나, 복잡한 장기 변형물체 작업에 있어 여전히 어려움이 존재합니다. 이 연구에서는 복잡한 동적 시스템과 다중 작업 분포를 다루기 위한 데이터 효율적인 일반 학습 프레임워크인 DeformPAM을 제안합니다.

- **Technical Details**: DeformPAM은 장기 과제를 여러 행동 원시(action primitives)로 분해하고, 3D 포인트 클라우드 입력 및 확산(diffusion) 모델을 활용하여 행동 분포를 모델링합니다. 또, 인간의 선호 데이터를 사용하여 암묵적인 보상 모델을 훈련합니다. 추론(inference) 단계에서 보상 모델은 여러 후보 행동을 평가하고 실행을 위한 최적의 행동을 선택합니다.

- **Performance Highlights**: 세 가지 도전적인 실제 세계의 장기 변형물체 조작 작업에 대한 실험 결과, DeformPAM은 기준 방법(baseline methods)보다 작업 완료 품질 및 효율성을 향상시켰고, 제한된 데이터에서도 그 성과를 보여주었습니다.



### STA-Unet: Rethink the semantic redundant for Medical Imaging Segmentation (https://arxiv.org/abs/2410.11578)
- **What's New**: 이 논문은 UNet 구조에 Super Token Attention(STA) 모듈을 도입하여 의학 이미지 세분화에서의 성능을 향상시키는 새로운 방법론을 제시합니다. STA는 전통적인 Transformer 기반의 UNet 아키텍처에서 관찰된 중복성을 줄이는 데 초점을 맞추었습니다.

- **Technical Details**: Super Token Attention(STA) 메커니즘은 픽셀 공간에서 슈퍼 픽셀의 개념을 토큰 공간으로 확장하여, compact visual representations으로서 슈퍼 토큰을 사용합니다. 이 방법은 이를 통해 Transformer UNet의 얕은 계층에서의 비효율적인 정보 처리 문제를 해결하고, 전반적으로 유용한 global representations을 학습하는 데 기여합니다.

- **Performance Highlights**: 실험 결과, STA-UNet은 Dice 점수 및 IOU에서 기존의 최첨단(state-of-the-art) 방법들과 비교했을 때 우수한 성능을 보여줍니다. 네 개의 공공 의료 이미지 데이터셋을 통해 검증된 결과 다양한 장기 세분화 작업에서도 뛰어난 효과를 입증했습니다.



### PAVLM: Advancing Point Cloud based Affordance Understanding Via Vision-Language Mod (https://arxiv.org/abs/2410.11564)
- **What's New**: 이 논문에서는 PAVLM(Point cloud Affordance Vision-Language Model)이라는 혁신적인 프레임워크를 소개하여 로봇 시스템의 3D affordance 이해를 향상시키는 방법을 제안합니다.

- **Technical Details**: PAVLM은 사전 학습된 언어 모델에 내재된 광범위한 멀티모달 지식을 활용하여 포인트 클라우드의 3D affordance를 이해합니다. 이 모델은 기하학적 지도 전파 모듈(geometric-guided propagation module)과 대규모 언어 모델의 숨겨진 임베딩(hidden embeddings)을 결합하여 시각적 의미를 풍부하게 합니다.

- **Performance Highlights**: 3D-AffordanceNet 벤치마크에서 PAVLM은 전체 및 부분 포인트 클라우드 모두에서 기존 방법보다 뛰어난 성능을 보였으며, 특히 새로운 오픈월드 3D 객체에 대한 일반화에서 두드러진 성과를 거두었습니다.



### Prediction of Cardiovascular Risk Factors from Retinal Fundus Images using CNNs (https://arxiv.org/abs/2410.11535)
- **What's New**: 이번 연구는 UK Biobank의 망막 이미지(retinal images)로부터 심혈관 질환의 위험 요소를 예측하는 새로운 방법을 제시합니다. 특히, 이 연구는 HbA1c와 총 콜레스테롤(total cholesterol)의 예측을 시도한 최초의 연구입니다.

- **Technical Details**: 이 연구는 convolutional neural networks (CNNs)를 사용하여 심혈관 질환의 위험 요소인 나이(age), BMI, 흡연 상태(smoking status), HbA1c, 수축기 혈압(systolic blood pressure), 이완기 혈압(diastolic blood pressure), 성별(gender) 및 총 콜레스테롤(total cholesterol)을 예측합니다. 망막 이미지를 Gaussian 필터링을 통한 대비 강화(contrast enhancement)를 적용하여 왼쪽 및 오른쪽 망막 이미지의 예측을 결합하여 개별적으로 예측을 도출합니다.

- **Performance Highlights**: 나이에 대한 예측에서 R2 점수는 0.81, 수축기 혈압에 대한 예측에서 R2 점수는 0.39를 기록하였으며, 이는 이전 연구보다 향상된 성능을 보입니다. 그러나, HbA1c의 경우 R2 점수는 0.0579, 총 콜레스테롤의 경우 R2 점수는 0.0157로 나타나 이 두 위험 요소의 예측은 제한적임을 보여줍니다.



### Rician Denoising Diffusion Probabilistic Models For Sodium Breast MRI Enhancemen (https://arxiv.org/abs/2410.11511)
Comments:
          3 figures

- **What's New**: 이 연구에서는 자연스러운 나트륨 MRI 이미지를 얻기 위한 새로운 방법론을 제안합니다. Rician Denoising Diffusion Probabilistic Model (RDDPM)을 도입하여 기존의 Denoising Diffusion Probabilistic Models (DDPM)에서 발생하는 한계를 극복하고, 나트륨 MRI의 고유한 노이즈 프로파일에 적합한 해법을 제공합니다.

- **Technical Details**: RDDPM 모델은 Rician 노이즈를 각 시간 단계에서 Gaussian 노이즈로 변환하여 denoising 과정을 진행합니다. CNN(Convolutional Neural Network) 모델로 생성된 합성 나트륨 MR 이미지를 활용하여 RDDPM을 훈련시키고, DDPM의 두 가지 병렬 모델을 사용하여 나트륨 MRI의 노이즈 제거를 수행합니다.

- **Performance Highlights**: RDDPM은 세 가지 비참조 이미지 품질 평가 지표를 통해 평가된 결과, DDPM 및 기타 CNN 기반 denoising 방법보다 일관되게 우수한 성능을 보였습니다.



### NavTopo: Leveraging Topological Maps For Autonomous Navigation Of a Mobile Robo (https://arxiv.org/abs/2410.11492)
Comments:
          This paper is published in proceedings of the 9th International Conference "Interactive Collaborative Robotics" (ICR 2024)

- **What's New**: 이번 논문은 모바일 로봇의 자율 내비게이션을 위한 새로운 방법론인 NavTopo를 소개합니다. 이 방법은 전통적인 매핑(method) 대신 위상(topological) 맵을 사용하여 효율성을 높였습니다.

- **Technical Details**: NavTopo는 위상 맵과 두 단계(path planning) 경로 계획을 기반으로 하며, 신경망(descriptors)과 입력 포인트 클라우드의 2D 프로젝션을 매칭하여 그래프에서 위치를 로컬라이즈합니다. 이 접근 방식은 메모리 소비를 현저하게 줄여줍니다.

- **Performance Highlights**: 실험 결과, NavTopo는 RTAB-MAP을 기반으로 한 전통적인 매트릭(metric) 매핑 접근 방식에 비해 성능이 크게 향상되었으며, 적절한 내비게이션 효율성을 유지합니다.



### SHAKTI: A 2.5 Billion Parameter Small Language Model Optimized for Edge AI and Low-Resource Environments (https://arxiv.org/abs/2410.11331)
Comments:
          Paper in pdf format is 11 pages and contains 4 tables

- **What's New**: Shakti는 25억 개의 매개변수를 가진 언어 모델로, 스마트폰, 웨어러블 기기 및 IoT 시스템과 같은 자원 제약 환경에서 최적화되어 있습니다. 이 모델은 높은 효율성과 정밀도를 갖춘 NLP를 결합하여 실시간 AI 애플리케이션에 적합하며, 다양한 언어와 도메인 특정 작업을 지원합니다.

- **Technical Details**: Shakti는 Variable Grouped Query Attention (VGQA)이라는 기술 혁신을 도입하여 메모리 사용량을 줄이고 추론 시간을 단축합니다. 또한, Pre-normalization과 SwiGLU 활성화 함수를 사용하여 훈련 과정을 안정화하고, Rotary Positional Embeddings (RoPE)를 통합하여 긴 텍스트 시퀀스를 처리할 수 있게 합니다.

- **Performance Highlights**: Shakti는 벤치마크 평가에서 더 큰 모델들과 비교하여 경쟁력 있는 성능을 보이며, 낮은 대기 시간과 높은 장치 내 효율성을 유지합니다. 또한, 특히 헬스케어, 금융 및 고객 서비스와 같은 산업에서 실시간 AI 솔루션을 제공하는 데 이상적입니다.



### Diffusion-Based Offline RL for Improved Decision-Making in Augmented ARC Task (https://arxiv.org/abs/2410.11324)
Comments:
          Preprint, Under review. Comments welcome

- **What's New**: 본 논문은 Latent Diffusion-Constrained Q-learning (LDCQ)이라는 혁신적인 diffusion 기반 오프라인 RL 접근법을 사용하여 Abstraction and Reasoning Corpus (ARC)에서의 AI의 전략적 추론 능력을 평가합니다. 이 연구는 SOLAR라는 새로운 데이터셋을 도입하여 오프라인 RL 에이전트의 학습을 위해 다양한 경험 데이터를 제공합니다.

- **Technical Details**: 본 연구는 SOLAR-Generator를 통해 원하는 조건에 따라 다양한 경로 데이터를 생성하며, 이 데이터를 통해 LDCQ 방법으로 에이전트를 훈련합니다. ARCLE 환경 내에서 마르코프 결정 과정(Markov Decision Process, MDP) 구조를 사용하여 에이전트가 그리드 기반 작업을 해결할 수 있도록 합니다.

- **Performance Highlights**: 실험 결과, LDCQ 방법으로 훈련된 에이전트는 다양한 액션을 적용하고 다단계 순차 결정을 수행하여 정답 상태를 정확히 식별하는 능력을 보여줍니다. 이 결과는 오프라인 RL 접근법이 AI의 전략적 추론 능력을 향상시킬 수 있는 가능성을 잘 보여줍니다.



### Adversarially Guided Stateful Defense Against Backdoor Attacks in Federated Deep Learning (https://arxiv.org/abs/2410.11205)
Comments:
          16 pages, Accepted at ACSAC 2024

- **What's New**: 본 논문에서는 Federated Learning (FL) 환경에서 발생할 수 있는 backdoor 공격에 대한 새로운 방어 메커니즘인 Adversarially Guided Stateful Defense (AGSD)를 제안합니다. AGSD는 비현실적인 가정에 의존하지 않고 클러스터 선택을 안내하는 새로운 메트릭인 신뢰 지수(trust index)를 계산하는 방식을 사용합니다.

- **Technical Details**: AGSD는 네 단계로 작동합니다: (1) 초기 집합(preliminary aggregation)에서 클라이언트 제출을 스케일링 및 집합화하고, (2) 스펙트럴 클러스터링(spectral clustering)을 사용하여 클라이언트 제출을 클러스터링하며, (3) 작은 보유 데이터셋을 이용하여 적대적 섭동(adversarial perturbations)을 계산하여 각 클라이언트의 신뢰 지수를 평가합니다. (4) AGSD는 각 클라이언트의 신뢰 상태(history)를 유지하며, 클러스터에서 선택된 클라이언트만 모델을 업데이트할 수 있도록 합니다.

- **Performance Highlights**: AGSD는 MNIST, CIFAR-10, GTSRB 데이터셋을 통해 평가되었으며, 특히 작은 보유 데이터셋(50 데이터 샘플 이하)으로도 기존의 State-of-the-art 방어 메커니즘들보다 우수한 성능을 보였습니다. AGSD는 공격 성공률(ASR)을 줄이고 깨끗한 정확도(clean accuracy)의 감소를 최소화하면서 FL 설정에서 효과적으로 backdoor 공격을 방어합니다.



### Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities (https://arxiv.org/abs/2410.11190)
Comments:
          13 pages, 6 figures

- **What's New**: 이 논문에서는 새로운 다중 모달 언어 모델인 Mini-Omni2를 소개합니다. Mini-Omni2는 시각 및 청각 쿼리에 대해 실시간 음성 응답을 제공하는 비주얼-오디오 어시스턴트입니다.

- **Technical Details**: Mini-Omni2는 사전 훈련된 시각(visual) 및 청각(auditory) 인코더를 통합하여 개별 모달리티에서의 성능을 유지합니다. 이 모델은 세 단계의 훈련 프로세스를 통해 모달리티를 정렬하여, 제한된 데이터셋으로 훈련한 후에도 다중 모달 입력 및 출력을 처리할 수 있게 합니다.

- **Performance Highlights**: Mini-Omni2는 GPT-4o와 유사한 기능을 가지고 있으며, 오픈 소스 커뮤니티의 모델들이 제공하는 일부 기능과 비교했을 때 더 유연한 사용자 인터랙션을 가능하게 하는 명령 기반 중단 메커니즘을 도입했습니다. 이는 향후 연구에서 중요한 통찰력을 제공할 것으로 기대됩니다.



### Deep unrolled primal dual network for TOF-PET list-mode image reconstruction (https://arxiv.org/abs/2410.11148)
Comments:
          11 pages, 11 figures

- **What's New**: 본 연구에서는 TOF-PET 리스트 모드 재구성을 위한 깊은 언롤 프리멀 듀얼 네트워크를 제안합니다. 이 네트워크는 리스트 모드 도메인 업데이트를 위한 이중 네트워크와 이미지 도메인 업데이트를 위한 프리멀 네트워크로 구성되어 있으며, 다양한 TOF 해상도와 카운트 레벨에서 성능을 입증하였습니다.

- **Technical Details**: 제안된 방법은 네트워크를 여러 단계로 언롤하여, 각 단계는 리스트 모드 도메인 업데이트를 위한 이중 모듈과 이미지 도메인 업데이트를 위한 프리멀 모듈을 포함합니다. CUDA를 사용하여 TOF 리스트 모드 데이터의 시스템 매트릭스의 병렬 가속 및 계산을 수행하고, 메모리 소비를 줄이기 위해 동적 접근 전략을 채택하였습니다.

- **Performance Highlights**: 제안된 방법은 LM-OSEM, LM-EMTV, LM-SPDHG 및 FastPET 방법보다 시각적 및 정량적 분석 모두에서 우수한 성능을 보여, TOF-PET 리스트 모드 데이터에 대한 깊은 언롤 방법의 적용 가능성을 입증하였습니다.



### CleanUMamba: A Compact Mamba Network for Speech Denoising using Channel Pruning (https://arxiv.org/abs/2410.11062)
Comments:
          5 pages, 4 figures

- **What's New**: 본 논문에서는 실시간 인과 오디오 잡음 제거를 위해 설계된 CleanUMamba라는 시간 도메인 신경망 아키텍처를 소개합니다. 이 아키텍처는 전통적인 LSTM 및 self-attention 메커니즘 대신 Mamba를 도입하여 최고의 잡음 제거 성능을 제공합니다. 또한, 모델 크기를 8배 줄이고 오디오 품질에는 영향을 주지 않는 구조적 채널 프루닝(structured channel pruning) 기법을 적용했습니다.

- **Technical Details**: CleanUMamba는 U-Net encoder-decoder 구조를 기반으로 하며, 병목(bottleneck) 계층에서 Mamba 상태 공간 모델을 포함합니다. 모델은 442K의 파라미터와 468M MACs로, PESQ 점수 2.42와 STOI 95.1%를 달성하며, 같은 조건의 더 큰 모델들과 비교해도 뛰어난 실시간 성능을 보여줍니다. 이 모델은 48ms의 알고리즘 지연을 가지고 있으며, 인코더 레이어 수에 따라 지연 시간이 달라질 수 있습니다.

- **Performance Highlights**: CleanUMamba는 Interspeech 2020 Deep Noise Suppression 도전에서 탁월한 성과를 보였고, 오디오 품질 평가에서 PESQ 2.42, STOI 95.1%로 높은 점수를 기록했습니다. 8X 모델 사이즈 감소에도 불구하고 오디오 품질을 유지하는 데 성공하였습니다.



### Hybrid Spatial Representations for Species Distribution Modeling (https://arxiv.org/abs/2410.10937)
Comments:
          Project codebase this https URL

- **What's New**: 본 논문에서는 Species Distribution Modeling (SDM)이라는 생태학적 문제를 해결하기 위해 새로운 하이브리드 임베딩 방법론을 제안합니다. 특히, 커뮤니티 소스 데이터셋에서 존재하는 데이터만으로 여러 종의 모델링을 동시에 수행하며, 환경 정보를 사용하지 않는 도전적인 작업을 다룹니다.

- **Technical Details**: 하이브리드 임베딩 스킴은 implicit embedding과 explicit embedding의 조합으로 이루어져 있습니다. explicit embedding은 multiresolution hashgrid로 구현되어, 모델이 지역 정보를 더욱 잘 포착하도록 돕습니다. 이 모델은 FCNet 기반의 implicit component와 결합되어 SDM 작업에 최적화된 형태를 만듭니다.

- **Performance Highlights**: 실험 결과, 제안된 방법이 다양한 벤치마크에서 기존 방법들에 비해 현저한 성과를 나타내며, 하이브리드 표현이 순수한 implicit 또는 explicit 방법보다 성능이 우수함을 보여줍니다. 또한, 질적 비주얼화와 종합적인 ablation 연구를 통해 하이브리드 표현의 효과성을 입증하였습니다.



### ASTM :Autonomous Smart Traffic Management System Using Artificial Intelligence CNN and LSTM (https://arxiv.org/abs/2410.10929)
Comments:
          In process to IEEE Intelligent Vehicle Symposium 2025

- **What's New**: 본 논문은 인공지능(AI)을 활용한 자율 스마트 교통 관리 시스템(Autonomous Smart Traffic Management, ASTM) 개발에 중점을 두고 있으며, 교통 흐름을 개선하기 위한 YOLO V5 합성곱 신경망을 사용하는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 제안된 시스템에서는 YOLO V5 Convolutional Neural Network가 교통 관리 이미지를 통해 차량을 감지하고, Recurrent Neural Network with Long Short-Term Memory (RNN-LSTM)을 통해 다음 12시간 동안의 차량 수를 예측합니다. 이 예측을 기반으로 Smart Traffic Management Cycle Length Analysis가 교통 주기 길이를 관리합니다.

- **Performance Highlights**: 논문에서 제시된 RNN-LSTM 모델은 평균 제곱 오차(Mean Squared Error, MSE) 4.521 차량과 제곱근 평균 제곱 오차(Root Mean Squared Error, RMSE) 2.232 차량을 기록하였으며, STM 시스템 시뮬레이션 결과, 교통 관리 혼잡 흐름 속도가 50% 개선되고 차량 통과 지연이 70% 감소한 것으로 나타났습니다.



### ATLAS: Adapter-Based Multi-Modal Continual Learning with a Two-Stage Learning Strategy (https://arxiv.org/abs/2410.10923)
- **What's New**: 본 논문에서는 다중 모달(multi-modal) 지속적 학습을 위한 새로운 접근 방식인 Adapter-based Multi-modal ConTinual Learning with A Two-stage Learning Strategy (ATLAS)를 제안합니다. 이 방법은 경험 기반 학습과 새로운 지식 확장을 포함하는 두 단계 학습 패러다임을 채택하고 있습니다.

- **Technical Details**: ATLAS는 경험 기반 학습(experience-based learning)과 새로운 지식 확장(novel knowledge expansion)을 통해 이전의 작업 지식을 효과적으로 활용하고 새로운 작업의 지식을 보완합니다. 이를 통해 지식의 중복성을 피하고, 모델의 표현을 풍부하게 하며, 업스트림(다중 작업) 시퀀스에서 다운스트림(특정 작업)에 대한 일반화 능력을 개선합니다.

- **Performance Highlights**: 실험 결과, ATLAS는 여러 작업에 대해 이전 작업의 잊혀진 정보를 최소화하면서 더 나은 일반화 능력을 보여주었고, 업스트림 작업에서의 학습이 다운스트림 작업에 긍정적인 영향을 미치는 것을 확인했습니다.



### A few-shot Label Unlearning in Vertical Federated Learning (https://arxiv.org/abs/2410.10922)
Comments:
          We introduce the first method for label unlearning in vertical federated learning (VFL), focused on preventing label leakage by the active party

- **What's New**: 이 논문은 Vertical Federated Learning (VFL)에서의 레이블 언러닝(label unlearning) 문제를 다룹니다. 이는 기존의 Horizontal Federated Learning (HFL)보다 덜 연구된 분야입니다. 연구자들은 레이블 정보 유출 위험을 줄이기 위해 특별히 설계된 첫 번째 방법을 소개합니다.

- **Technical Details**: 이 방법은 제한된 양의 라벨 데이터(label data)를 활용하여 manifold mixup 기술을 사용하여 충분치 않은 데이터의 전방 임베딩을 증강합니다. 그런 다음 증강된 임베딩에서 gradient ascent를 수행하여 모델로부터 레이블 정보를 삭제합니다. 이 조합은 높은 언러닝 효과성을 유지하면서도 효율성을 보장하며, 언러닝 절차는 몇 초 만에 완료됩니다.

- **Performance Highlights**: MNIST, CIFAR10, CIFAR100, ModelNet 등을 포함한 다양한 데이터셋에서 실시한 광범위한 실험을 통해 이 방법의 효율성과 확장성을 검증했습니다. 이 연구는 VFL에서 언러닝의 독특한 도전을 다루면서 개인정보 보호 및 계산 효율성을 모두 지키는 데 중요한 진전을 이룹니다.



### Towards Better Multi-head Attention via Channel-wise Sample Permutation (https://arxiv.org/abs/2410.10914)
Comments:
          18 pages, 4 figures

- **What's New**: 이번 연구에서는 Channel-wise Sample Permutation (CSP) 연산자를 제안하며, 이를 통해 매개변수 수가 적고 복잡성이 낮은 새로운 구조적 다중 헤드 주의 메커니즘을 실현했습니다. CSP는 입력 행렬의 다양한 채널샘플을 원형으로 이동시키고 각 채널의 그룹화된 샘플을 정렬함으로써 이론적 이해도 뛰어난 기술로 구현됩니다.

- **Technical Details**: CSP 연산자는 서로 다른 채널의 샘플을 다양한 단계로 원형 이동시키고 그룹화된 샘플을 정렬하여 작동합니다. 이는 교차 채널 주의 맵을 암묵적으로 구현하며, 선형 복잡성을 달성하고 데이터 표현시 rank collapse의 위험을 억제합니다. 기존의 다중 헤드 주의(MHA) 대신 CSP를 일부 대표 모델에 적용하였으며, 정량적 평가에서 성능과 유사하거나 우수한 결과를 얻었습니다.

- **Performance Highlights**: CSP 기반 모델들은 기존의 Transformer 모델 및 최신 변형들과 비교했을 때, 동일한 성능을 유지하거나 향상시키면서 매개변수 수와 계산 비용을 현저히 줄였습니다. 이 실험 결과는 CSP가 효율적이고 강력한 대안이 될 수 있음을 보여줍니다.



### Advancements in Ship Detection: Comparative Analysis of Optical and Hyperspectral Sensors (https://arxiv.org/abs/2410.10888)
- **What's New**: 해양 감시 분야에서 군사 및 민간 응용 프로그램에 대한 최신 연구로, 선박 탐지 및 분류 기술에 중점을 두고 있습니다. 특히 광학 (optical)과 하이퍼스펙트럴 (hyperspectral) 원격 감지 접근 방식을 비교합니다.

- **Technical Details**: 이 논문은 특징 추출 (feature extraction), 방법론 (methodologies), 다양한 임무에 대한 적합성 등을 포괄적으로 분석합니다. 센서 선택의 중요성을 강조하며, 이는 임무 목표와 조건에 맞춰 탐지 정확도를 향상시키기 위한 통합 전략 (integrated strategies)을 통해 이루어집니다.

- **Performance Highlights**: 두 가지 기술의 강점과 한계를 조사하여 다양한 해양 응용 분야에서의 사용성을 향상시키는 내용을 담고 있습니다.



### Enhancing Vision-Language Model Pre-training with Image-text Pair Pruning Based on Word Frequency (https://arxiv.org/abs/2410.10879)
- **What's New**: 이번 논문은 Word-Frequency 기반 이미지-텍스트 쌍 가지치기(WFPP)라는 새로운 데이터 가지치기 방법을 제안하여 VLMs(비전-언어 모델)의 효율성을 향상시킵니다. 이 방법은 텍스트의 내용을 기반으로 텍스트-이미지 쌍을 선택하여 가지치기를 진행하며, 높은 빈도의 단어를 포함하는 쌍을 제거하여 단어 빈도 분포를 균형 있게 만듭니다.

- **Technical Details**: WFPP는 빈도가 높은 단어를 포함하는 텍스트가 있는 이미지-텍스트 쌍을 제거하여 훈련 데이터셋의 균형을 개선합니다. WFPP는 단어 확률에 기반하여 간단한 텍스트 수준 점수를 사용하여 가지치기를 수행하며, 텍스트에서 잦은 단어를 제거함으로써 전반적인 데이터의 다양성을 유지합니다. 최적의 결과를 위해, WFPP는 테스트 후 전체 데이터셋에 대해 1 에폭을 추가로 조정하여 성능을 개선합니다.

- **Performance Highlights**: WFPP를 적용하면 CLIP 모델의 훈련 성능이 저격 작업에서 향상됩니다. WFPP는 데이터를 효율적으로 가지치기하면서도 성능 저하 없이 학습 속도를 개선해줍니다. 제안된 방법을 통해 CLIP 모델은 다양한 하위 작업에서 성능이 향상되었으며, 제로샷 분류 및 이미지-텍스트 검색에서 우수한 결과를 보였습니다.



### CogDevelop2K: Reversed Cognitive Development in Multimodal Large Language Models (https://arxiv.org/abs/2410.10855)
- **What's New**: 이 논문은 Multi-modal Large Language Models (MLLMs)의 인지 능력을 평가하는 새로운 벤치마크인 CogDevelop2K를 제안합니다. 이 벤치마크는 인간의 인지 발달 과정을 구조화해 12개의 하위 개념을 포괄하며, MLLMs의 진정한 이해 능력과 작업 수행 능력을 탐구하는 데 중점을 둡니다.

- **Technical Details**: CogDevelop2K는 2519개의 질문과 2517개의 이미지, 455개의 비디오로 구성되어 있으며, MLLMs의 코어 인지 능력을 4단계의 인지 발달 무대로 평가합니다. 이 논문은 Jean Piaget의 인지 발달 이론을 기반으로 하여 MLLMs의 역동적인 인지 발달 추세를 조사하며, 코어 인지 과업 수행이 MLLMs의 진정한 지식, 추론 및 지각 능력을 이해하는 데 중요한 인사이트를 제공함을 강조합니다.

- **Performance Highlights**: 46개 MLLM 모델을 평가한 결과, 몇 가지 놀라운 경향이 확인되었습니다. MLLM 모델은 인간의 인지 발달 경로와 반대되는 경향을 보였으며, 예를 들어 GPT 시리즈는 형식적 조작 단계에서 더 나은 성능을 보였으나 구체적 조작 단계에서는 저조한 성능을 나타냈습니다. 이 연구는 MLLM의 성능 향상 방법인 prompting 기술이 모델 성능을 8.1% 향상시킬 수 있음을 시사합니다.



### Adaptive Data Transport Mechanism for UAV Surveillance Missions in Lossy Environments (https://arxiv.org/abs/2410.10843)
- **What's New**: 본 논문은 Unmanned Aerial Vehicles (UAV) 기반의 Intelligence, Surveillance, and Reconnaissance (ISR) 임무를 위한 효율적인 데이터 전송 전략을 제안합니다. 특히, 객체 검출 및 추적에 기여하는 이미지의 특정 영역을 우선적으로 선택하여 자동 전송을 최적화하는 AI 기반 스케줄링 정책을 도입하였습니다.

- **Technical Details**: 연구에서는 Deep Reinforcement Learning (DRL) 프레임워크를 사용하여 이미지의 작은 패치들에 대해 전송 확률을 할당하며, 객체와의 겹침 정도에 따라 높은 전송 확률을 부여합니다. 이 과정은 실시간 데이터 전송의 효율성을 높이는 UDP(User Datagram Protocol) 전송 프로토콜과 YOLOv8 객체 탐지 알고리즘을 포함하여 동작합니다.

- **Performance Highlights**: 제안된 방법은 리소스가 제한된 UAV 환경에서 효과적인 데이터 전송을 통해 ISR 임무의 효율성을 크게 향상시킬 것으로 기대됩니다. 또한, 간섭이 있는 이미지 패치의 OD 오류를 방지하기 위해 인터프레임 보간(interframe interpolation) 과정을 통합하여, 시스템의 전반적인 성능을 증대시키는 결과를 도출하였습니다.



### AI Foundation Model for Heliophysics: Applications, Design, and Implementation (https://arxiv.org/abs/2410.10841)
Comments:
          31 Pages, 12 figures

- **What's New**: 이번 연구에서는 헬리오피직스(heliophysics) 분야에서 최초로 태양역학 관측 데이터(Solar Dynamics Observatory, SDO)를 기반으로 한 파운데이션 모델(Foundation Model, FM)을 설계했습니다. 이 모델은 헬리오피직스 관련 문제 해결을 위한 구체적인 기준과 도전 과제를 제시하고 있습니다.

- **Technical Details**: 제안한 파운데이션 모델은 인코더(encoder)와 디코더(decoder) 구조를 기반으로 하며, 자가 지도 학습(self-supervised learning) 방법으로 사전 훈련됩니다. 이처럼 훈련된 모델은 특정 다운스트림 작업에 대해 인코더는 수정 없이 사용하고, 디코더는 작업에 특화된 형태로 대체할 수 있습니다. 또한, 모델은 수백만 개에서 수십억 개의 매개변수를 가질 수 있습니다.

- **Performance Highlights**: 본 연구는 헬리오피직스 분야에 있어 FM의 가능성을 최초로 제시하였으며, SDO 데이터의 활용을 통해 많은 기존 문제 해결에 기여할 것으로 기대됩니다. 초기 훈련 결과를 통해 ML 방법이 기존의 방법을 능가하는 다양한 성과를 도출했다고 보고합니다.



### Swap-Net: A Memory-Efficient 2.5D Network for Sparse-View 3D Cone Beam CT Reconstruction (https://arxiv.org/abs/2410.10836)
- **What's New**: 이 연구는 Swap-Net이라는 메모리 효율적인 2.5D 네트워크를 제안하여 극도의 스파스 뷰(sparse-view) 3D CBCT 이미지 재구성을 효율적으로 수행합니다. Swap-Net은 새로운 축 교환(axis-swapping) 연산을 이용하여 전체 3D 볼륨 재구성을 가능하게 합니다.

- **Technical Details**: Swap-Net은 2D 합성곱 연산을 사용하여 3D 볼륨의 모든 축을 포괄적으로 활용합니다. 이 방법은 기존의 FBP(filtered back projection)과 3D CNN와 비교하여 메모리 비용이 적고 더 빠르게 작동합니다. 실험에서는 4개의 프로젝션만으로도 효과적인 결과를 보여주었습니다.

- **Performance Highlights**: Swap-Net은 기초 방법들에 비해 정량적 및 정성적으로 모두 우수한 성능을 보이며, 잡음 감소 및 복잡한 유체 역학 시뮬레이션의 세부사항 보존에서도 탁월한 결과를 나타냈습니다.



### Tex4D: Zero-shot 4D Scene Texturing with Video Diffusion Models (https://arxiv.org/abs/2410.10821)
Comments:
          Project page: this https URL

- **What's New**: Tex4D는 텍스트 프롬프트와 함께 제공된 비구조화 3D 메시 시퀀스를 기반으로 여러 시점과 시간적으로 일관된 4D 텍스처를 생성하는 제로샷 접근 방식을 소개합니다. 이를 통해 텍스쳐링의 효율성을 크게 향상시킵니다.

- **Technical Details**: Tex4D는 UV 공간에서의 잠재적 집합(latent aggregation)을 통해 다중 시점(multi-view) 일관성을 보장합니다. 이는 3D 메시의 내재된 기하학적 지식(geometry knowledge)을 활용하여 시간적으로 일관된 텍스처 합성을 위한 조건적 비디오 생성 모델의 사전 지식을 사용합니다. DDIM 샘플링 과정에서의 단순한 수정이 필요하며, 참조 잠재 텍스처(reference latent texture)를 도입하여 프레임 간의 상관관계를 강화합니다.

- **Performance Highlights**: Tex4D는 다양한 애니메이션 메시 시퀀스에서 우수한 성능을 보여주며, 특히 기존 방법들과 비교하여 시간적 및 다중 프레임 일관성 있는 비디오 생성을 위한 최초의 방법으로, 높은 충실도의 텍스처를 제공합니다.



### TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models (https://arxiv.org/abs/2410.10818)
Comments:
          Project Page: this https URL

- **What's New**: TemporalBench는 비디오의 미세한 시간적 이해(fine-grained temporal understanding)를 평가하는 새로운 벤치마크로, 10,000 개의 비디오 질문-답변 쌍으로 구성되어 있으며, 인간의 고품질 주석에서 파생되었습니다.

- **Technical Details**: TemporalBench에서는 비디오 클립의 시공간적 활동을 잘 반영하기 위해 긴 시간 의존성(long-range dependencies), 세분화된 시각적 관찰(fine-grained visual observations) 및 사건의 진행(event progression)과 관련된 주석에 중점을 두었습니다.

- **Performance Highlights**: 최신 모델인 GPT-4o는 TemporalBench에서 단지 38.5%의 질문 응답 정확도를 보여주었고, 이는 인간과 AI 간의 시간적 이해에서 약 30%의 큰 간극이 있음을 나타냅니다. 또한 다중 선택 QA에서 발생할 수 있는 편향을 수정하기 위해 Multiple Binary Accuracy(MBA)를 제안했습니다.



### When Does Perceptual Alignment Benefit Vision Representations? (https://arxiv.org/abs/2410.10817)
Comments:
          S.S. and S.F. contributed equally. Website: this http URL

- **What's New**: 본 논문에서는 인간의 지각 판단에 맞춘 비전 모델의 정합성이 다양한 컴퓨터 비전 작업에서의 유용성에 미치는 영향을 조사하고, 최첨단 모델을 인간의 유사성 판단에 따라 미세 조정하였으며 이를 표준 비전 벤치마크에서 평가했습니다.

- **Technical Details**: NIGHTS라는 인간의 유사성 판단에 대한 데이터셋을 사용하여, 여러 최신 비전 모델(예: CLIP, DINO, DINOv2, SynCLR)을 미세 조정했습니다. 이 데이터셋은 20,000개의 합성 이미지를 포함한 트리플렛으로 구성되어 있으며, 각 이미지 세트는 인간 평가로 얻은 유사성 판단이 포함되어 있습니다.

- **Performance Highlights**: 인간 정합성을 반영한 모델은 원래의 백본 모델에 비해 여러 다운스트림 작업(예: counting, segmentation, depth estimation)에서 성능을 향상시키는 것으로 나타났습니다. 또한, 특정 작업에서는 성능이 유지되거나 향상되었으나, 일부 자연 데이터 작업에서는 성능 저하가 관찰되었습니다.



### LVD-2M: A Long-take Video Dataset with Temporally Dense Captions (https://arxiv.org/abs/2410.10816)
Comments:
          NeurIPS 2024 Dataset and Benchmark Track. Project page: this https URL . Code: this https URL

- **What's New**: 본 논문은 LVD-2M이라는 새로운 데이터셋을 소개합니다. 이 데이터셋은 최소 10초 이상의 긴 비디오, 컷이 없는 장시간 비디오, 다양한 콘텐츠와 큰 동작을 포함하며 시계열 밀집 캡션(temporally dense captions)으로 주석이 달린 2백만 개의 비디오로 구성되어 있습니다.

- **Technical Details**: LVD-2M은 낮은 수준의 필터링 도구(예: scene cut detection)와 의미적 수준의 필터링 도구(예: video LLMs)를 결합한 자동 데이터 선별 파이프라인을 통해 제작되었습니다. 또한, 비디오를 30초 클립으로 나누고 각 클립에서 프레임을 샘플링하여 비디오 캡션을 생성하는 계층적 캡셔닝(Hierarchical Captioning) 접근 방식을 사용합니다.

- **Performance Highlights**: LVD-2M 데이터셋을 통해 비디오 생성 모델의 성능이 향상되었으며, 실험 결과 동적 모션을 포함하는 장시간 비디오 생성에 있어 효과성이 입증되었습니다. 인간 평가에서도 LVD-2M이 높은 동적 정도와 뛰어난 캡션 품질로 선호되었습니다.



### Depth Any Video with Scalable Synthetic Data (https://arxiv.org/abs/2410.10815)
Comments:
          Project Page: this https URL

- **What's New**: 이번 논문에서는 Depth Any Video라는 모델을 도입하여 비디오 깊이 추정의 어려움을 해결하려고 합니다. 이 모델은 대규모 합성 데이터 파이프라인을 개발하고, 생성적 비디오 확산 모델의 강력한 프라이어를 활용하여 다양한 비디오를 효과적으로 처리합니다.

- **Technical Details**: 우리는 40,000개의 5초 길이의 비디오 클립을 포괄하는 대규모 합성 데이터셋인 DA-V를 구축했습니다. 이 데이터는 조명 조건, 카메라 움직임, 그리고 물체 상호작용을 포함한 다양한 시나리오를 커버합니다. 모델의 훈련 방식으로 혼합 길이 훈련 전략을 도입하고, 흐름 일치(flow matching) 및 회전 위치 인코딩(rotary position encoding) 같은 고급 기술을 사용하여 처리 효율성을 향상시킵니다.

- **Performance Highlights**: 모델은 공간 정확성과 시간 일관성 모두에서 기존의 모든 생성적 깊이 모델을 초월하며, 최대 150 프레임의 비디오 시퀀스에서 고해상도 깊이 추정을 가능하게 합니다.



### HART: Efficient Visual Generation with Hybrid Autoregressive Transformer (https://arxiv.org/abs/2410.10812)
Comments:
          Demo: this https URL. The first two authors contributed equally to this work

- **What's New**: 이번 연구에서는 Hybrid Autoregressive Transformer (HART)라는 새로운 시각 생성 모델을 소개합니다. HART는 1024x1024 크기의 이미지를 직접 생성할 수 있는 autoregressive (AR) 모델로, 기존의 diffusion 모델과 유사한 이미지 생성 품질을 자랑합니다. HART는 전통적인 AR 모델의 한계를 극복하기 위해 하이브리드 토크나이저(hybrid tokenizer)를 도입하였습니다.

- **Technical Details**: HART의 하이브리드 토크나이저는 autoencoder의 연속적인 잠재 출력(latent output)을 두 가지 구성 요소로 분해합니다: 전체적인 그림을 나타내는 discrete tokens와 discrete tokens로 표현할 수 없는 잔여 성분을 나타내는 continuous tokens. 이들은 각각 스케일 가능한 해상도의 VAR transformer와 37M 파라미터를 가진 경량 residual diffusion 모듈에 의해 모델링됩니다.

- **Performance Highlights**: HART는 MJHQ-30K 데이터셋에서 reconstruction FID를 2.11에서 0.30으로 개선하여, 1024px 이미지 생성 시 FID를 7.85에서 5.38로 낮추어 31%의 개선을 달성하였습니다. 또한 HART는 최신 diffusion 모델보다 4.5-7.7배 높은 처리량과 6.9-13.4배 낮은 MACs를 기록하며, 빠른 추론(latency) 속도를 자랑합니다.



### TrajDiffuse: A Conditional Diffusion Model for Environment-Aware Trajectory Prediction (https://arxiv.org/abs/2410.10804)
Comments:
          Accepted to be published as inpreceedings of the 2024 International Conference on Pattern Recognition (ICPR)

- **What's New**: 이 논문에서는 TrajDiffuse라는 새로운 경로 예측 방법을 제안하며, 이는 혁신적인 guided conditional diffusion 모델에 기반합니다. 기존의 경로 예측 모델은 환경 제약을 무시하고 다양성이나 정확성에만 초점을 맞춘 경우가 많았으나, TrajDiffuse는 이를 개선하여 더욱 실용적이며 환경 친화적인 예측을 가능하게 합니다.

- **Technical Details**: TrajDiffuse는 경로 예측 문제를 denoising inpainting 과제로 구성하고, diffusion 과정에 대한 맵 기반 가이드를 설계합니다. 이 방법은 에이전트의 궤적 기록과 예측된 움직임 의도를 보간(interpolation)하여 예측을 생성하며, 목표/경로점(conditioning)에 의해 경로 생성 과정을 명시적으로 제어할 수 있는 기능을 제공합니다.

- **Performance Highlights**: TrajDiffuse는 nuScenes 및 PFSD 데이터셋에서의 실험을 통해 SOTA를 초과하는 정확도와 다양성을 보여주었으며, 향상된 환경 이해도를 입증했습니다. 우리는 두 가지 공공 데이터셋에서 실험을 통해 이 모델이 환경 제약을 잘 준수하며 정확한 경로 예측을 생성할 수 있음을 보였습니다.



### Boosting Camera Motion Control for Video Diffusion Transformers (https://arxiv.org/abs/2410.10802)
- **What's New**: 본 논문에서는 비디오 생성의 카메라 제어 품질을 향상시키기 위한 해결책으로 Camera Motion Guidance (CMG) 방법을 제안하며, 이를 통해 기존 DiT 방식보다 400% 이상 개선된 결과를 보였습니다.

- **Technical Details**: 본 연구는 transformer 기반의 diffusion 모델(DiT)에서 카메라 제어 성능이 conditioning 방법에 크게 의존한다는 사실을 밝혀냈습니다. 이를 기반으로 classifier-free guidance 기술을 활용한 CMG 방법을 도입하였습니다. 또한, sparse camera control 방식을 통해 긴 비디오에서 카메라 포즈 입력을 간소화하는 방법도 제시하였습니다.

- **Performance Highlights**: CMG 방법과 sparse camera control을 적용하여 비디오 생성 시 카메라 제어 정확도 및 동작을 크게 향상시켰으며, 이는 U-Net 및 DiT 모델 모두에 효과적으로 적용 가능합니다.



### Towards Foundation Models for 3D Vision: How Close Are We? (https://arxiv.org/abs/2410.10799)
- **What's New**: 이 논문에서는 3D 비전의 이해 능력을 평가하기 위해 새로운 3D 비주얼 언더스탠딩 벤치마크를 설계하였으며, 이는 Visual Question Answering (VQA) 형식으로 다양한 3D 비전 작업을 포함합니다. 이 연구는 최신 Vision-Language Models (VLMs)와 전문화된 모델의 3D 비전 능력을 인간과 비교하여 분석하였습니다.

- **Technical Details**: 연구에서는 깊이 추정(depth estimation), 공간 VQA(spatial VQA), 카메라 자세 추정(camera pose estimation), 키포인트 매칭(keypoint matching) 등의 3D 비전 작업을 포함하는 새로운 벤치마크를 제안했습니다. VQA 형식으로 모든 질문을 구성하여 VLMs와 인간이 쉽게 응답할 수 있도록 하였습니다. 또한 기하학적 섭동(geometric perturbations)을 포함하여 모델의 강건성을 평가합니다.

- **Performance Highlights**: VLMs는 일반적으로 3D 작업을 수행하지 못하며, 정확도와 강건성 면에서 전문화된 모델이 인간보다 나은 경우도 있지만 기하학적 섭동에 취약한 것으로 나타났습니다. 반면, 인간은 가장 정확하고 강건한 3D 비주얼 시스템으로 확인되었습니다. Transformer 기반의 네트워크가 CNN보다 인간의 3D 비전 메커니즘과 더 잘 정렬되는 것으로 나타났습니다.



### MMAR: Towards Lossless Multi-Modal Auto-Regressive Probabilistic Modeling (https://arxiv.org/abs/2410.10798)
- **What's New**: 이번 논문에서는 기존의 이미지 이해와 생성에서 발생하는 정보 손실 문제를 해결하기 위해 새로운 Multi-Modal Auto-Regressive (MMAR) 모델링 프레임워크를 제안합니다. MMAR는 연속적인 이미지 토큰을 사용하여 정보 손실을 방지하는 혁신적인 접근 방식을 채택하고, 기존의 확산 접근법(dispersion-based approach)과 차별화된 구조를 가지고 있습니다.

- **Technical Details**: MMAR는 연속 값 이미지 토큰을 사용하여 정보 손실을 방지하고, 경량화된 확산 헤드를 통해 각 이미지 패치가 자동 회귀 모델에 통합되도록 설계되었습니다. 또한, 이 접근 방식은 수치 안정성 문제를 해결하는 이론적으로 검증된 기술과 생성 및 이해 작업 목표를 균형 있게 조정하는 훈련 전략을 포함합니다.

- **Performance Highlights**: 18개의 이미지 이해 벤치마크에서 평가한 결과, MMAR는 다른 다중 모달 모델들보다 뛰어난 성능을 보여주었고, 사전 훈련된 CLIP 비전 인코더를 사용한 방법과 유사한 성능을 발휘하면서도 고품질 이미지를 동시에 생성할 수 있음을 입증했습니다. 또한, 대규모 데이터와 모델 크기에 대해 확장 가능한 특성을 보여주었습니다.



### Condition-Aware Multimodal Fusion for Robust Semantic Perception of Driving Scenes (https://arxiv.org/abs/2410.10791)
- **What's New**: 이 논문에서는 자동 주행 환경에서의 견고한 의미 인식을 위해 다중 센서를 활용하는 새로운 접근 방식을 제안합니다. 기존 방식은 환경 조건에 따라 센서를 균등하게 처리하여 최적의 성능을 내지 못했습니다. 그러나 본 연구의 CAFuser 방식은 RGB 카메라 입력을 활용하여 환경 조건을 분류하고, 다양한 센서 모달리티의 융합을 유도하는 조건 토큰을 생성합니다.

- **Technical Details**: CAFuser 모델은 각 센서에서 모듈화된 특징 어댑터를 사용하여 다양한 센서 입력을 공유 잠재 공간에 정렬합니다. 이로 인해 사전 훈련된 백본과 효율적으로 통합할 수 있으며, 센서 퓨전이 각 조건에 맞게 최적화됩니다. 이 아키텍처는 단일 네트워크 백본을 사용하여 모델 파라미터를 54% 줄이는 동시에 성능 저하 없이 동작합니다.

- **Performance Highlights**: CAFuser는 MUSES 데이터셋에서 다중 모달 팬옵틱 세분화(multi-modal panoptic segmentation)에서 59.7 PQ, 의미 세분화(semantic segmentation)에서 78.2 mIoU의 성능을 기록하며, 공공 벤치마크에서 1위를 차지하였습니다. 이 모델은 특히 악조건 시나리오에서의 견고성을 크게 개선합니다.



### Sitcom-Crafter: A Plot-Driven Human Motion Generation System in 3D Scenes (https://arxiv.org/abs/2410.10790)
Comments:
          Code Page: this https URL

- **What's New**: 최근 인체 모션 합성을 위한 Sitcom-Crafter라는 포괄적이고 확장 가능한 시스템이 제안되었습니다. 이 시스템은 다양한 모션 유형의 조합을 생성할 수 있는 통합 시스템으로, 애니메이션 및 게임 디자이너의 워크플로우 효율성을 높입니다.

- **Technical Details**: Sitcom-Crafter는 총 8개의 모듈로 구성되며, 그 중 3개는 모션 생성에, 나머지 5개는 모션 시퀀스의 일관된 융합과 시스템 기능성을 보장하는 증강 모듈입니다. 특히, 새로운 3D 장면 인식 인체-인체 상호 작용 모듈이 물리적 장면 정보가 포함된 합성 및 특정 SDF 포인트를 생성하여 인체-장면 충돌을 최소화합니다.

- **Performance Highlights**: 실험 평가 결과, Sitcom-Crafter는 고품질의 다양하고 물리적으로 현실감 있는 모션을 성공적으로 생성할 수 있는 능력을 입증했습니다. 이는 창조적인 워크플로우를 발전시키는 데 상당한 잠재력을 지니고 있음을 강조합니다.



### LiveXiv -- A Multi-Modal Live Benchmark Based on Arxiv Papers Conten (https://arxiv.org/abs/2410.10783)
- **What's New**: LiveXiv는 과학 ArXiv 논문을 기반으로 한 대규모의 자동화된 멀티모달 라이브 벤치마크로, 웹에서 수집된 데이터로 테스트 모델의 능력을 측정합니다.

- **Technical Details**: LiveXiv는 자동으로 생성된 VQA(Visual Question-Answer) 쌍을 활용하여 과학 문서에서 필요한 정보를 추출하고, GPT-4o를 통해 질문을 생성합니다. 이를 위해 구조화된 문서 파싱 파이프라인을 통해 PDF 문서의 내용을 처리하고, 다양한 시각적 정보를 기반으로 질문 필터링 과정을 거쳐 데이터 품질을 개선합니다.

- **Performance Highlights**: LiveXiv의 첫 번째 버전에서 여러 개방형 및 독점 LMM 모델을 벤치마크하고, 데이터 오염을 최소화한 상황에서 모델의 진정한 능력을 깨닫게 해주는 통찰력을 제공합니다.



### 3DArticCyclists: Generating Simulated Dynamic 3D Cyclists for Human-Object Interaction (HOI) and Autonomous Driving Applications (https://arxiv.org/abs/2410.10782)
- **What's New**: 이번 논문에서는 복잡한 동적 인간-객체 상호작용을 연구하기 위한 방법을 제안하며, 3D 사이클리스트(dynamic cyclist)와 상호작용을 생성하는 새로운 데이터셋인 3DArticBikes를 소개합니다. 이 데이터셋은 NeRF 및 3DGS 기반 3D 재구성 방법을 훈련하는 데 사용될 수 있습니다.

- **Technical Details**: 저자는 새로운 부품 기반 다각도 관절 합성 3D 자전거 데이터셋(3DArticBikes) 생성을 위한 방법론을 제안합니다. 이 데이터셋은 조정 가능한 8-DoF 자세를 가지고 있는 3D 자전거를 조합하 수 있는 3DGS 기반의 매개변수 자전거 구성 모델이 포함됩니다. 또한, 사이클리스트 비디오에서 동적 정보를 사용하여 합성 3D 인물의 자세를 자동으로 수정하여 3D 자전거에 적절하게 rider를 배치합니다.

- **Performance Highlights**: 생성한 사이클리스트는 최근의 안정적 확산 방법과 비교하여 정성적 및 정량적 결과가 제시됩니다. 이 연구는 동적 자전거 시뮬레이션 및 복잡한 상호작용의 이해를 위한 전진적인 기초를 마련하고 있습니다.



### ControlMM: Controllable Masked Motion Generation (https://arxiv.org/abs/2410.10780)
Comments:
          project page this https URL

- **What's New**: ControlMM은 텍스트 기반 제어 신호를 포함한 새로운 생성형 마스크드 모션 모델 접근 방식을 제안합니다. 이 방법은 높은 정밀도, 빠른 속도 및 높은 충실도의 제어 가능한 모션 생성을 동시에 달성합니다.

- **Technical Details**: ControlMM은 마스크드 일관성 모델링(masked consistency modeling)과 추론 시 로짓 편집(inference-time logit editing)이라는 두 가지 주요 기술 혁신을 도입합니다. 이를 통해 입력 제어 신호와 생성된 모션으로부터 추출한 제어 신호 간의 불일치를 최소화하면서 고충실도의 모션 생성을 보장합니다.

- **Performance Highlights**: ControlMM은 기존의 최첨단 기술에 비해 모션 품질에서 우수한 결과를 보여주며, FID 점수는 0.061로 향상되었습니다. 또한, ControlMM은 확산 기반 방법보다 20배 빠른 속도로 모션을 생성하는 성능을 보입니다.



### UniMatch V2: Pushing the Limit of Semi-Supervised Semantic Segmentation (https://arxiv.org/abs/2410.10777)
Comments:
          18 pages, 18 tables, 10 figures

- **What's New**: 이번 연구에서는 기존 모델의 한계를 넘어, 최신 ViT 기반 인코더인 DINOv2를 활용하여 반지도 세분화(FSS) 성능을 현저히 개선할 필요성을 강조합니다.

- **Technical Details**: 기존 SSS 방식에서 흔히 사용되던 ResNet 인코더 대신 DINOv2와 같은 강력한 ViT 기반 인코더를 채택하여, 더 큰 데이터셋으로 사전 훈련(pre-training)한 모델을 사용합니다. 이를 통해 단순한 모델 업데이트만으로도 상당한 성능 향상을 이끌어냈습니다.

- **Performance Highlights**: UniMatch V2를 통해 더 낮은 훈련 비용으로 일관되게 더 나은 결과를 제공하며, 기존의 Pascal 및 Cityscapes 데이터셋 외에 ADE20K 및 COCO와 같은 더 복잡한 벤치마크에 집중할 필요성을 역설합니다.



### Cavia: Camera-controllable Multi-view Video Diffusion with View-Integrated Attention (https://arxiv.org/abs/2410.10774)
Comments:
          Project Page: this https URL

- **What's New**: Cavia라는 새로운 프레임워크를 소개합니다. 이 프레임워크는 사용자에게 카메라 모션을 정확히 지정할 수 있는 기능을 제공하여 이미지에서 여러 개의 시공간적으로 일관된 비디오를 생성할 수 있습니다.

- **Technical Details**: Cavia는 공간 및 시간 주의(attention) 모듈을 뷰 통합 주의 모듈로 확장하여 시점(viewpoint)과 시간적 일관성을 개선합니다. 또한, 정적 비디오, 객체-level 합성 다중 뷰 동적 비디오, 실제 모노큘러 동적 비디오와 같은 다양한 데이터 소스를 활용한 공동 학습(joint training) 방식을 채택합니다.

- **Performance Highlights**: Cavia는 기하학적 일관성(geometric consistency)과 지각 품질(perceptual quality) 측면에서 최첨단 방법들을 초월하는 성능을 보여줍니다. 또한, 이 프레임워크는 추론(inference) 중에 4개의 뷰를 생성하고, 생성된 프레임의 3D 재구성을 가능하게 합니다.



### DragEntity: Trajectory Guided Video Generation using Entity and Positional Relationships (https://arxiv.org/abs/2410.10751)
Comments:
          ACM MM2024 Oral

- **What's New**: 최근 Diffusion 모델이 비디오 생성 분야에서 큰 성공을 거둔 바, 본 논문에서는 DragEntity라는 새로운 비디오 생성 모델을 소개합니다. 이 모델은 사용자 친화적으로 여러 객체의 움직임을 제어할 수 있도록 설계되었습니다.

- **Technical Details**: DragEntity는 엔티티(entities) 표현 방식을 활용하여 여러 객체의 모션을 제어합니다. 사용자들은 개별 픽셀 대신 이미지 내의 엔티티를 드래그하여 인터랙션할 수 있습니다. 엔티티 표시 방법은 이미지 내의 모든 객체를 나타내고, 여러 객체는 상대적 공간 관계를 유지하도록 돕습니다. 이를 통해 복잡한 다수의 궤적을 통해 여러 객체를 동시에 제어할 수 있게 됩니다.

- **Performance Highlights**: 실험 결과, DragEntity는 비디오 생성에서 미세한 제어의 뛰어난 성능을 보여주며, 고유의 엔티티 레벨 모션 제어 방식을 통해 현실감 있는 비디오 생성을 가능하게 합니다.



### FlexGen: Flexible Multi-View Generation from Text and Image Inputs (https://arxiv.org/abs/2410.10745)
Comments:
          16 pages, 13 figures

- **What's New**: 이 논문에서는 FlexGen이라는 유연한 프레임워크를 소개하며, 이는 단일 뷰 이미지, 텍스트 프롬프트, 또는 둘 모두에 따라 제어 가능한 일관된 다중 뷰 이미지를 생성하도록 설계되었습니다. FlexGen은 3D-aware 텍스트 주석에 대한 추가 조건부를 통해 제어 가능한 다중 뷰 합성을 다룹니다.

- **Technical Details**: FlexGen은 GPT-4V의 강력한 추론 능력을 활용하여 3D-aware 텍스트 주석을 생성합니다. 객체의 네 개의 정사각형 뷰를 분석하여 3D-aware 정보를 포함하는 텍스트 주석을 생성하며, 제안된 적응형 이중 제어 모듈을 통해 제어 신호를 통합하여 다중 뷰 이미지를 생성합니다. 이 모델은 텍스트 프롬프트를 수정하여 합리적인 그리고 일치하는 보이지 않는 부분을 생성합니다.

- **Performance Highlights**: 실험 결과, FlexGen은 기존의 다중 뷰 확산 모델에 비해 향상된 다중 제어 기능을 제공하며, 게임 개발, 애니메이션, 가상 현실 등 빠르고 유연한 3D 콘텐츠 제작이 필요한 분야에서 상당한 진전을 이루었습니다.



### DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Mod (https://arxiv.org/abs/2410.10738)
Comments:
          Accepted to NeurIPS 2024. Project page: this https URL

- **What's New**: DrivingDojo는 복잡한 주행 역학을 훈련하기 위해 특별히 제작된 첫 번째 데이터셋으로, 비디오 다양성이 제한된 기존 주행 데이터셋의 단점을 극복하고자 합니다.

- **Technical Details**: DrivingDojo는 다양한 주행 동작, 다중 에이전트 상호작용 및 개방형 주행 지식을 포함하여, 모델이 복잡한 동적 환경을 예측하고 시뮬레이션할 수 있도록 고안되었습니다. 또한, AIF(action instruction following) 벤치마크를 정의하여 주행 세계 모델의 성능을 평가할 수 있게 되었습니다.

- **Performance Highlights**: DrivingDojo는 기존 데이터셋에 비해 보다 다양하고 복잡한 주행 시나리오를 수집하여, 향후 자율 주행 세계 모델의 발전에 기여할 수 있는 많은 기회를 제공하고 있다는 점에서 중요한 발전을 나타냅니다.



### Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models (https://arxiv.org/abs/2410.10733)
Comments:
          Preprint. First two authors contributed equally to this work

- **What's New**: Deep Compression Autoencoder (DC-AE)는 고해상도 확산 모델을 가속화하기 위한 새로운 오토인코더 모델 군을 제시합니다. 기존의 오토인코더 모델들은 낮은 공간 압축 비율(예: 8x)에서 좋은 성능을 보였으나, 높은 공간 압축 비율(예: 64x)에서는 만족스러운 재구성 정확도를 유지하지 못했습니다.

- **Technical Details**: DC-AE는 Residual Autoencoding과 Decoupled High-Resolution Adaptation이라는 두 가지 주요 기술을 도입합니다. Residual Autoencoding은 높은 공간 압축 오토인코더의 최적화 난이도를 완화하기 위해 설계되었으며, Decoupled High-Resolution Adaptation은 높은 공간 압축 오토인코더의 일반화 페널티를 완화하기 위한 효율적인 훈련 전략입니다.

- **Performance Highlights**: DC-AE는 오토인코더의 공간 압축 비율을 최대 128까지 증가시키면서도 재구성 품질을 유지합니다. 예를 들어, ImageNet 512x512에서는 DC-AE를 사용하여 UViT-H에서 H100 GPU로 19.1배의 추론 속도 향상과 17.9배의 훈련 속도 향상을 달성하면서 FID 점수 또한 개선되었습니다.



### A Counterexample in Image Registration (https://arxiv.org/abs/2410.10725)
- **What's New**: 이번 연구는 1차원 데이터에서 이미지 정합의 이론적 한계를 분석합니다. 특히, 이미지 정합에서의 정확도의 경계를 탐구하며, 신호의 불연속점 위치와 참조점 간의 관계를 규명합니다.

- **Technical Details**: 신호의 불연속점을 참조점으로 선택할 때, 그 위치에 따라 에러 함수의 에너지가 달라지는 양상을 연구합니다. 이는 공간적으로 제한된 조각상 상수(signal)의 이상적이고 잡음 없는 샘플 패턴 집합을 기반으로 추정하는 방법을 제공합니다.

- **Performance Highlights**: 연구 결과, 신호의 정확한 추정치는 참조되는 불연속점에 따라 달라지며, 이로 인해 이미지 정합의 해석이 새롭게 규명됩니다. 또한, 기존의 시각을 넘어서 정합 문제를 접근하게 됩니다.



### 4-LEGS: 4D Language Embedded Gaussian Splatting (https://arxiv.org/abs/2410.10719)
Comments:
          Project webpage: this https URL

- **What's New**: 본 연구에서는 동적 장면을 캡처하는 볼류메트릭 표현을 텍스트와 연결하는 방법인 4-LEGS (4D Language Embedded Gaussian Splatting)를 제안합니다. 이 접근법은 사용자가 텍스트 프롬프트를 통해 비디오에서 사건을 시공간적으로 로컬라이즈 할 수 있는 인터페이스를 제공합니다.

- **Technical Details**: 4-LEGS는 3D Gaussian Splatting을 기반으로 한 4D 표현으로, 시공간 임베딩을 동적 Gaussian Splatting 표현에 접목하여 수행됩니다. 이를 통해 우리는 자연어로 기술된 상태 및 동적 영역의 로컬라이제이션과 함께 시공간 확률 맵을 렌더링할 수 있습니다.

- **Performance Highlights**: 4-LEGS는 정적 및 동적 환경 내의 텍스트 설명을 로컬라이즈하는 측면에서 대안 기술에 비해 매우 뛰어난 성능을 보였으며, Panoptic Sports 데이터셋을 사용하여 정량적 평가를 수행하였습니다.



### Benefiting from Quantum? A Comparative Study of Q-Seg, Quantum-Inspired Techniques, and U-Net for Crack Segmentation (https://arxiv.org/abs/2410.10713)
- **What's New**: 이 연구는 양자 하드웨어를 활용한 기존 이미지 세분화 기법에 대한 비교 분석을 진행하여 양자 기반 방법들이 실질적인 적용 가능성을 갖추었음을 보였습니다. 특히, 콘크리트 균열을 세분화하는 효율적인 방법을 제시하였습니다.

- **Technical Details**: 주요 기술적 방법으로 Mean Gaussian Mixture (MGM), 양자 영감 기반 Hamiltonian, Q-Seg, 그리고 U-Net 딥러닝 아키텍처가 포함됩니다. 연구는 32x32 픽셀의 주석 처리된 콘크리트 이미지 조각을 사용하여 각 방법의 세분화 마스크를 생성하고 성능을 비교합니다.

- **Performance Highlights**: 양자 기반 및 양자 영감 기법이 복잡한 균열 패턴에 대해 유망한 대안을 제공하며, 가까운 미래의 다양한 응용 분야에 적용될 수 있음을 확인했습니다. Q-Seg 방법은 특히 D-Wave 양자 어닐러를 사용하여 효과적으로 세분화 문제를 해결함으로써 우수한 성능을 나타냈습니다.



### Ensemble of ConvNeXt V2 and MaxViT for Long-Tailed CXR Classification with View-Based Aggregation (https://arxiv.org/abs/2410.10710)
Comments:
          Solution paper for MICCAI CXR-LT 2024 challenge. 4th place in Subtask 2, 5th in Subtask 1

- **What's New**: 본 연구는 MICCAI 2024 CXR-LT 챌린지에서 Subtask 2에서 4위, Subtask 1에서 5위를 달성한 해결책을 제시합니다. ConvNeXt V2와 MaxViT 모델의 앙상블을 활용하여 흉부 X-ray의 긴 꼬리 분포 문제를 다룹니다.

- **Technical Details**: 이 연구에서는 흉부 X-ray의 분류(task)는 여러 시각적 정보가 포함되어 복잡하며, 긴 꼬리 분포를 고려해야 하는 문제를 다루었습니다. ConvNeXt V2와 MaxViT 모델을 사용하여 이미지 분류 기술을 조합하고, 비대칭 손실(asymmetric loss)을 통해 클래스 불균형을 해결합니다. 연구에서 사용된 데이터 세트는 MIMIC-CXR로, 377,110개의 CXR 이미지와 45개의 질병 레이블을 포함하고 있습니다.

- **Performance Highlights**: 실험 결과, 512x512 픽셀의 입력 크기가 성능 향상에 기여했으며, MaxViT 모델이 ConvNeXt V2보다 높은 성능을 보여주었습니다. 비대칭 손실 함수를 사용한 사전 훈련이 흉부 질환에 대한 모델의 민감도를 높여주었고, 전망 기반 예측 집계(view-based prediction aggregation) 전략이 성능을 크게 향상시켰습니다.



### Early Diagnoses of Acute Lymphoblastic Leukemia Using YOLOv8 and YOLOv11 Deep Learning Models (https://arxiv.org/abs/2410.10701)
Comments:
          4 pages, 6 figures, 3 tables

- **What's New**: 이 연구는 Acute Lymphoblastic Leukemia (ALL) 탐지를 위한 YOLOv8 및 YOLOv11 모델을 처음으로 적용하여 백혈구를 악성과 양성으로 분류하고 초기 단계의 ALL을 포함한 다양한 단계의 ALL을 확인합니다.

- **Technical Details**: 이미지 처리 기법과 딥러닝 기술을 사용하여 혈액암인 Acute Lymphoblastic Leukemia를 탐지하는데 중점을 두었습니다. Segmentation 기법을 통해 데이터를 준비하고 transfer learning 및 fine-tuning 기법을 적용하여 모델의 정확도를 98.8% 이상으로 향상시켰습니다.

- **Performance Highlights**: YOLOv11 모델을 사용하여 연속된 100 epochs의 학습 과정에서 높은 정확도를 달성했습니다. 특히, 모델은 여러 데이터셋과 다양한 실제 상황에서도 일관되게 뛰어난 성능을 보여줍니다.



### TALK-Act: Enhance Textural-Awareness for 2D Speaking Avatar Reenactment with Diffusion Mod (https://arxiv.org/abs/2410.10696)
Comments:
          Accepted to SIGGRAPH Asia 2024 (conference track). Project page: this https URL

- **What's New**: 본 연구에서는 2D 말하는 아바타 에니메이션을 위한 TALK-Act 프레임워크를 제안합니다. 이 프레임워크는 얼굴 뿐만 아니라 몸통과 제스처의 움직임도 제어하는 능력을 가지고 있습니다. 기존의 연구들이 주로 얼굴에 중점을 두었던 반면, 이 연구는 보다 자연스러운 움직임을 가능하게 합니다.

- **Technical Details**: TALK-Act 프레임워크는 모노큘러 비디오의 짧은 영상으로부터 2D 아바타를 고충실도로 재현할 수 있습니다. 이 모델은 Motion-Enhanced Textural Alignment 모듈과 Memory-based Hand-Recovering 모듈을 통해 텍스처 정합성 및 손 모양 복원을 개선합니다. 구조적 모션 안내는 2D 포즈, 3D 파라메트릭 얼굴 렌더링, 그리고 손 렌더링을 사용하여 구축됩니다.

- **Performance Highlights**: 모델은 30초의 개인별 데이터로도 안정적이고 고충실도의 2D 아바타를 재현할 수 있으며, 실험 결과 이전 최첨단 방법들보다 뛰어난 성능을 보여줍니다.



### Cross-Modal Few-Shot Learning: a Generative Transfer Learning Framework (https://arxiv.org/abs/2410.10663)
Comments:
          19 pages, 7 figures

- **What's New**: 이 논문은 기존의 대부분의 few-shot learning 연구가 unimodal 설정에 집중하고 있다는 점을 지적하며, real-world 데이터가 본질적으로 multi-modal이기 때문에 Cross-modal Few-Shot Learning (CFSL)이라는 새로운 작업을 제안합니다. 이 작업은 각기 다른 여러 모달리티에서 불과 몇 개의 레이블이 있는 예제만 가지고 인스턴스를 인식하는 것을 목표로 합니다.

- **Technical Details**: 이 논문에서는 Generative Transfer Learning (GTL) 프레임워크를 제안하여 unimodal 데이터에서의 지식을 multi-modal 데이터로 전이하도록 합니다. GTL 프레임워크는 두 단계로 이루어져 있으며, 첫 번째 단계는 데이터가 풍부한 unimodal 데이터에 대한 학습, 두 번째 단계는 새로운 데이터에 적응하는 transfer learning에 초점을 맞추고 있습니다. 각 단계에서 latent shared concept를 추정하고, transfer 단계에서는 generative 모듈을 고정하여 학습된 표현의 안정성을 유지하면서 overfitting을 방지합니다.

- **Performance Highlights**: 이 GTL 프레임워크는 Sketchy, TU-Berlin, Mask1K, SKSF-A의 4개 multi-modal 데이터셋에서 최첨단 방법들보다 우수한 성능을 보이는 것으로 나타났습니다. 또한, 모델이 방대한 unimodal 데이터에서 latent 개념을 추정하고, 이러한 개념을 사용하여 제한된 수의 샘플로 unseen 모달리티에 일반화할 수 있음을 보여줍니다.



### PCF-Lift: Panoptic Lifting by Probabilistic Contrastive Fusion (https://arxiv.org/abs/2410.10659)
Comments:
          ECCV 2024. The code is publicly available at this https URL

- **What's New**: PCF-Lift(Probabilistic Contrastive Fusion)라는 새로운 파이프라인을 설계하여, 불확실한 2D 분할과 일관성 없는 인스턴스 ID를 적극적으로 고려하는 확률적 특징을 학습하고 내장합니다.

- **Technical Details**: 다변량 가우시안 분포를 통해 확률적 특징 임베딩을 모델링하며, Contrastive Loss 공식을 활용하여 확률적 특징을 융합하고, 새로운 cross-view constraint를 도입하여 다양한 뷰 간의 특징 일관성을 향상시킵니다.

- **Performance Highlights**: ScanNet와 Messy Room 데이터셋에서 기존 최첨단 방법보다 평균 4.4% 향상된 성능을 보이며, 다양한 2D 분할 모델이나 손수 제작한 노이즈 수준에 대해 강력한 내구성을 입증합니다.



### SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers (https://arxiv.org/abs/2410.10629)
Comments:
          Technical Report

- **What's New**: Sana는 텍스트에서 이미지를 효율적으로 생성할 수 있는 프레임워크로, 최대 4096×4096 해상도에서 고해상도 이미지를 빠른 속도로 생성할 수 있는 기능을 제공합니다. 이 모델은 기존의 대규모 확산 모델에 비해 20배 작은 크기를 가지면서도 100배 이상의 빠른 처리 속도를 자랑합니다.

- **Technical Details**: Sana는 다음과 같은 핵심 설계를 포함합니다: (1) Deep compression autoencoder - 이미지를 32배 압축할 수 있도록 훈련된 새로운 Autoencoder (AE)를 사용하여 잠재 토큰 수를 줄입니다. (2) Linear DiT - 기존의 2차 주의(attention) 대신 1차 주의로 대체하여 고해상도에서도 효율성을 높였습니다. (3) Decoder-only text encoder - T5 대신 Gemma라는 최신 모델을 사용하여 이미지-텍스트 정렬을 향상시킵니다. (4) Efficient training and sampling - Flow-DPM-Solver를 통해 샘플링 단계를 줄입니다.

- **Performance Highlights**: Sana-0.6B는 4K 이미지를 생성하는 데 있어 기존 최첨단 모델인 FLUX보다 100배 이상의 빠른 처리량을 기록하며, 1K 해상도에 대해서는 40배 빠른 속도를 보여줍니다. 또한, 소비자 등급의 4090 GPU에서 1024×1024 해상도의 이미지를 0.37초 만에 생성할 수 있습니다.



### BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI (https://arxiv.org/abs/2410.10604)
- **What's New**: 본 논문에서는 다양한 MRI 모달리티를 활용한 뇌 이미지 분석을 위한 새로운 다중 모달 비전 사전 학습 프레임워크인 BrainMVP를 제안합니다. BrainMVP는 불완전한 모달리티 문제를 해결하고 다중 모달 정보 융합을 실현합니다.

- **Technical Details**: BrainMVP는 16,022개의 뇌 MRI 스캔 데이터셋을 바탕으로 설정되며, 크로스 모달 재구성이 이루어져 각 모달리티의 독특한 영상 임베딩을 학습합니다. 모달리티 별 데이터 증류 모듈을 통해 각 MRI 이미지의 본질적 표현을 추출하고, 적절한 모달리티 인식을 통해 크로스 모달 연관성을 높입니다.

- **Performance Highlights**: BrainMVP 모델은 6가지 분할 기준에서 0.28%-14.47%의 Dice Score 개선과 4개의 개별 분류 작업에서 0.65%-18.07%의 일관된 정확성을 보여주며, 기존 선도적인 사전 학습 방법들보다 우수한 성능을 입증합니다.



### MoTE: Reconciling Generalization with Specialization for Visual-Language to Video Knowledge Transfer (https://arxiv.org/abs/2410.10589)
Comments:
          NeurIPS 2024 Camera Ready

- **What's New**: 최근 비디오 인식을 위한 대규모 비전-언어 모델(Vision-Language Models)에서 MoTE라는 새로운 프레임워크가 제안되었습니다. 이 프레임워크는 일반화(generalization)와 전문화(specialization)를 균형 있게 조정하여, 여러 작업 뷰(task views)를 통해 다양한 데이터 적합도를 학습할 수 있도록 디자인되었습니다.

- **Technical Details**: MoTE는 다수의 전문가(experts)를 사용하는 혼합(mixture) 접근법으로, 파라미터(나중에 Fine-tuning된 데이터에 대한 과적합 위험이 큼)를 통해 모델 일반화를 향상시키는 것을 목표로 합니다. 또한, 파라미터 병합(weight merging)을 정규화하는 Weight Merging Regularization을 통해 결합 과정에서의 일반화와 전문화 지식을 효과적으로 집합할 수 있게 됩니다. 이를 통해, 각 전문가들이 서로 다른 데이터 바이어스를 학습할 수 있도록 라우팅 알고리즘을 제시하였습니다.

- **Performance Highlights**: MoTE는 Kinetics-400 & 600, UCF, HMDB 등 다양한 데이터셋에 대해 최첨단(state-of-the-art) 또는 경쟁력 있는 성능을 보여주었으며, 제로샷(zero-shot)과 클로즈셋(close-set) 비디오 인식 작업 간의 최적의 균형을 달성하였습니다.



### TopoFR: A Closer Look at Topology Alignment on Face Recognition (https://arxiv.org/abs/2410.10587)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 최근 심층 학습(deep learning)의 발전 덕분에 얼굴 인식(face recognition, FR) 분야에서 중요한 진전을 이루었습니다. 이 연구에서는 비지도 학습(unsupervised learning)과 그래프 신경망(graph neural networks)이 데이터 구조 정보를 활용하여 모델의 일반화 성능을 향상시키는 방법을 탐구합니다.

- **Technical Details**: TopoFR 모델은 지속적 동형성(persistent homology)을 이용해 입력 공간(input space)과 잠재 공간(latent space)의 위상 구조를 정렬하는 기법인 PTSA(perturbation-guided topological structure alignment)를 사용하여 구조 정보를 보존합니다. 또한 SDE(structure damage estimation)라는 하드 샘플 샘플링(hard sample mining) 전략을 통해 구조 손상 점수(structure damage score, SDS)를 계산하여 힘든 샘플을 효과적으로 최적화합니다.

- **Performance Highlights**: TopoFR은 여러 얼굴 인식 벤치마크에서 기존의 최신 기술(SOTA) 방법들보다 뛰어난 성능을 보였으며, 특히 ICCV21 MFR-Ongoing 챌린지에서 두 번째 자리를 차지하는 성과를 올렸습니다. 이는 모델의 강인성과 일반화 능력을 잘 나타냅니다.



### Queryable Prototype Multiple Instance Learning with Vision-Language Models for Incremental Whole Slide Image Classification (https://arxiv.org/abs/2410.10573)
Comments:
          16 pages, 10 tables, 11 figures

- **What's New**: 이번 논문에서는 Incremental Whole Slide Image (WSI) 분류를 위해 개발된 Vision-Language 기반의 새로운 프레임워크인 Queryable Prototype Multiple Instance Learning (QPMIL-VL)을 소개합니다. 이 프레임워크는 동적 데이터 분포에 효율적으로 적응할 수 있도록 설계되었습니다.

- **Technical Details**: QPMIL-VL 프레임워크는 두 개의 정보 처리 브랜치로 구성됩니다. 첫 번째 브랜치는 프로토타입 기반 집계를 통해 bag-level feature를 생성하는 반면, 두 번째 브랜치는 클래스 앙상블, 조정 가능한 벡터 및 클래스 유사성 손실을 통해 클래스 특성을 강화합니다. 이 구조는 기존의 static MIL 방법들의 한계를 극복하는 데 초점을 맞추고 있습니다.

- **Performance Highlights**: 실험 결과, QPMIL-VL은 네 개의 TCGA 데이터셋에서 다른 기존 방법들을 상회하는 성능을 보였으며, incremental WSI 분류 작업에서 state-of-the-art (SOTA) 성능을 달성했습니다.



### MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks (https://arxiv.org/abs/2410.10563)
Comments:
          Technical report. Project page: this https URL

- **What's New**: MEGA-Bench는 500개 이상의 실제 작업을 포함하는 다중 모드 평가 스위트를 소개합니다. 이를 통해 사용자들의 다양한 요구를 충족시키고, 고품질 데이터 샘플을 최적화하는 것을 목표로 합니다.

- **Technical Details**: 505개의 실제 작업과 8,000개 이상의 샘플을 수집하였으며, 다수의 출력 형식과 40개 이상의 평가 메트릭을 개발했습니다. MEGA-Bench는 input type, output format, skill 등 여러 차원에 대해 세밀한 성능 보고서를 제공합니다.

- **Performance Highlights**: MEGA-Bench를 기반으로 GPT-4o가 최상의 성능을 보였고, Qwen2-VL은 오픈소스 모델 중에서는 가장 우수한 성능을 발휘했습니다. Gemini 1.5 Flash는 효율성 모델 중에서 가장 강력한 모델이었습니다.



### ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection (https://arxiv.org/abs/2410.10554)
- **What's New**: 본 논문은 ROSAR라는 새로운 프레임워크를 소개하며, 자율 수중 차량이 생성한 사이드 스캔 소나(SSS) 이미지에 특화된 깊은 학습 객체 탐지 모델의 견고성을 향상시킵니다.

- **Technical Details**: ROSAR는 지식 증류(Knowledge Distillation, KD)와 적대적 재훈련(adversarial retraining)을 결합하여 SSS 노이즈에 대한 모델의 효율성과 견고성을 동시 해결하는 접근법을 제안합니다. 이 프레임워크에서는 세 가지 새로운 SSS 데이터셋을 공개하며, 특정 안전 속성을 정의하고, 이를 바탕으로 적대적 데이터셋을 생성하여 재훈련을 수행합니다.

- **Performance Highlights**: ROSAR는 PGD(Projected Gradient Descent) 및 패치 기반 적대적 공격을 통한 비교 분석에서 SSS 특수 조건 하에서 모델의 견고성 및 탐지 정확도를 크게 향상시켜, 최대 1.85%의 개선을 보여주었습니다.



### RICASSO: Reinforced Imbalance Learning with Class-Aware Self-Supervised Outliers Exposur (https://arxiv.org/abs/2410.10548)
Comments:
          14 pages, 2 figures

- **What's New**: 이번 연구에서는 RICASSO라는 새로운 프레임워크를 제안하여 데이터의 불균형(long-tailed) 및 분포 외(out-of-distribution, OOD) 데이터를 동시에 해결합니다. RICASSO는 실제 OOD 데이터 사용 없이 혼합 데이터를 통해 가짜 OOD 데이터를 생성하여 문제를 해결할 수 있음을 보여줍니다.

- **Technical Details**: RICASSO는 Norm-Odd-Duality-Based Outlier Exposure, Ambiguity-Aware Logits Adjustment, Contrastive Boundary-Center Learning의 세 가지 전략으로 구성됩니다. 혼합 데이터는 ID 및 OOD 데이터의 특성을 모두 보유하며, 이를 통해 동시에 ID 데이터의 재조정과 OOD 데이터의 노출을 가능하게 합니다. 또한, Ambiguity-Aware Logits Adjustment를 통해 각 샘플에 대한 세밀한 주의 집중이 가능합니다.

- **Performance Highlights**: 실험 결과, RICASSO는 long-tailed 인식 및 OOD 탐지에서 최첨단 성능을 달성하였으며, iNaturalist2018 데이터셋에서 OOD 탐지의 AUROC에서 27% 개선과 FPR에서 61% 감소를 보였습니다. RICASSO는 실제 OOD 데이터를 사용하는 방법보다 더 나은 성능을 보였습니다.



### Hybrid Transformer for Early Alzheimer's Detection: Integration of Handwriting-Based 2D Images and 1D Signal Features (https://arxiv.org/abs/2410.10547)
- **What's New**: 이번 연구에서는 알츠하이머병(AD) 조기 탐지를 위해 2D 손글씨 이미지와 1D 동적 손글씨 신호를 동시에 통합하는 새로운 하이브리드 어텐션 모델을 제안합니다. 이는 기존의 수동으로 추출한 특징이나 단순한 머신 러닝 모델에 의존하는 접근 방식을 넘어서는 혁신적인 방법입니다.

- **Technical Details**: 제안한 모델은 게이트 메커니즘을 활용하여 2D 손글씨의 공간 패턴과 1D 동적 특징 간의 상관관계를 학습하고, 멀티모달(multi-modal) 데이터를 효과적으로 결합합니다. 새롭게 도입된 손실 함수는 템플릿 대조 손실(template contrastive loss)과 크로스 엔트로피 손실(cross-entropy loss)을 결합하여 분류 성능을 향상시킵니다.

- **Performance Highlights**: DARWIN 데이터셋을 대상으로 한 평가에서, 본 모델은 90.32%의 F1 점수와 90.91%의 정확도를 기록하며, Task 8('L' writing)에서 이전 최상 성능보다 각각 4.61% 및 6.06% 우수한 성과를 보였습니다.



### Motion-guided small MAV detection in complex and non-planar scenes (https://arxiv.org/abs/2410.10527)
Comments:
          8 pages, 6 figures

- **What's New**: 본 논문에서는 복잡하고 비평면적인 장면에서 소형 MAV를 정확하게 탐지할 수 있는 새로운 모션 가이드 MAV 탐지기(MGMD)를 제안합니다. 기존의 방법들이 배경이 복잡하거나 MAV가 너무 작을 때 어려움을 겪는 문제를 해결하고자 합니다.

- **Technical Details**: 제안한 알고리즘은 세 가지 모듈로 구성됩니다: 모션 특징 강화(Motion Feature Enhancement), 궤적 필터링(Trajectory Filtering), 지역 세밀 탐지(Local Fine Detection). 모션 특징 강화 모듈은 복잡한 배경에서 소형 MAV의 모션 특징을 추출하며, 다중 객체 추적 및 궤적 필터링을 이용하여 모션 패럴랙스(Motion Parallax)로 인한 잘못된 탐지를 제거합니다.

- **Performance Highlights**: ARD-MAV 데이터셋에서의 실험 결과, 제안한 방법이 복잡한 배경에서도 소형 MAV 탐지에서 높은 성능을 달성하였으며, 다양한 메트릭에서 최첨단 방법들을 능가함을 보여주었습니다.



### Customize Your Visual Autoregressive Recipe with Set Autoregressive Modeling (https://arxiv.org/abs/2410.10511)
Comments:
          19 pages, 17 figures, 8 tables, github repo: this https URL

- **What's New**: 새로운 패러다임인 Set AutoRegressive Modeling (SAR)을 소개합니다. SAR은 기존의 AutoRegressive (AR)를 확장하여 시퀀스를 고정된 순서 대신 여러 토큰을 포함하는 임의의 세트로 나눌 수 있도록 합니다.

- **Technical Details**: SAR의 구조는 Fully Masked Transformer (FMT)라는 간단한 아키텍처로 구성되어 있으며, 이는 시퀀스 순서와 출력 간격을 임의의 구성으로 일반화합니다. SAR 프레임워크 내에서 기존의 AR 변형들이 특정 설계 선택에 대응한다는 것을 보여줍니다. SAR은 AR과 Masked AR (MAR) 간의 매끄러운 전이를 가능하게 하며, 각각의 장점인 few-step inference와 KV cache 가속을 활용할 수 있습니다.

- **Performance Highlights**: 이미지넷(IMAGENET) 벤치마크에서 SAR의 특성을 분석하여 시퀀스 순서와 출력 간격이 성능에 미치는 영향을 조사했습니다. 900M 텍스트-투-이미지 모델을 훈련시켜 텍스트 설명을 준수하는 사실적인 이미지를 생성할 수 있는 능력을 검증했습니다. 이 모델은 임의의 비율의 이미지를 생성할 수 있으며, 제로샷(image editing)에서도 효과적으로 적용 가능합니다.



### Exploiting Local Features and Range Images for Small Data Real-Time Point Cloud Semantic Segmentation (https://arxiv.org/abs/2410.10510)
Comments:
          This paper has been accepted for publication at the 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)

- **What's New**: 이 논문에서는 점구름(Point Cloud) 세분화(Semantic Segmentation) 문제를 해결하기 위해 WaffleIron과 RangeFormer 모델을 조합한 새로운 심층 학습 아키텍처를 제안합니다. 특히, 작은 데이터셋에서도 뛰어난 성능을 발휘하는 방법론을 상세히 설명하고 있습니다.

- **Technical Details**: 점구름 데이터의 로컬 특징(local features)을 캡처하기 위해 3D 표현을 활용하며, 범위 이미지(range image) 표현을 도입하여 추가 정보를 포함하고 계산 속도를 향상시킵니다. GPU 기반 KDTree를 사용하여 점구름 임베딩 모듈에서의 빌딩 및 쿼리를 신속하게 처리합니다. 이 방법론의 주요 구성 요소는 점구름 임베딩 모듈, 점구름 처리 레이어로 구성된 백본(backbone), 최종 세분화를 위한 세그멘테이션 헤드입니다.

- **Performance Highlights**: SemanticKITTI와 nuScenes 데이터셋에서의 실험 결과, 제안한 방법론은 데이터가 제한적인 상황에서도 뛰어난 성능을 보여주었으며, 전체 모델의 시스템 런타임을 단 180ms로 감소시켰습니다. 또한, 축소된 모델이 실시간으로 작동하면서도 최신 모델들과 경쟁력을 갖춘다는 것을 입증하였습니다.



### Artificial Intelligence-Based Triaging of Cutaneous Melanocytic Lesions (https://arxiv.org/abs/2410.10509)
Comments:
          14 pages, 6 figures

- **What's New**: 이 연구는 전체 슬라이드 이미지(Whole Slide Images, WSI)를 기반으로 한 피하 멜라닌종 병변의 분류를 위한 인공지능(AI) 모델 개발에 관한 것입니다. 이 AI 모델은 네덜란드 유니버시티 메디컬 센터 위트레흐트(UMC Utrecht)의 회고적 코호트를 사용하여 개발 및 검증되었습니다.

- **Technical Details**: 연구는 27,167 개의 고유한 표본으로부터 획득한 52,202 개의 전체 슬라이드 이미지를 포함한 데이터 세트를 사용했습니다. 이 데이터 세트는 병변의 복잡성에 따라 저복잡성(86.6%)과 고복잡성(13.4%)으로 분류되었습니다. 예측 성능은 수신기 작동 특성 곡선의 면적(AUROC)과 정밀-재현 곡선의 면적(AUPRC)을 통해 평가되었습니다.

- **Performance Highlights**: AI 모델은 시험 세트에서 AUROC 0.966, AUPRC 0.857을 기록하였으며, 배포 밖 시험 세트에서는 AUROC 0.899, AUPRC 0.498를 기록하였습니다. 또한, AI 기반 분류를 통해 일반 병리학자가 처리해야 할 고복잡성 사례에 대한 초기 검사를 평균 43.9회 예방할 수 있었습니다.



### Continual Learning Improves Zero-Shot Action Recognition (https://arxiv.org/abs/2410.10497)
Comments:
          Accepted in ACCV 2024

- **What's New**: 본 논문에서는 ZSL(Zero-Shot Learning)과 CL(Continual Learning) 기술을 결합하여 제안된 새로운 GIL(Generative Iterative Learning) 방법을 소개합니다. GIL은 과거 클래스의 합성된 특징을 저장하는 메모리를 사용하고, 이를 새로운 클래스의 실제 특징과 결합하여 제로샷 액션 인식을 향상시킵니다. 이 방법은 기존 ZSL 방법들과는 상이하게 지속적인 학습을 적용합니다.

- **Technical Details**: GIL은 세 가지 단계로 구성됩니다: 초기화 단계에서는 기준 비디오 표현을 저장하는 Replay Memory를 구축하고, GAN(Generative Adversarial Network)을 훈련하여 메모리에 저장된 특징과 유사한 특징을 생성합니다. 점진적 학습 단계에서는 생성된 특징과 새로운 클래스의 실제 특징을 혼합하여 비디오 모델을 미세 조정합니다. 마지막으로 갱신 단계에서는 새로운 클래스의 프로토타입 표현을 메모리에 추가하여 모델이 새로운 작업을 학습하는 동시에 이전 작업의 지식을 잊지 않도록 합니다.

- **Performance Highlights**: GIL은 UCF-101, HMDB-51, Kinetics-600 등 3개의 표준 ZSL/GZSL 벤치마크에서 실험하여 최대 20%까지 성능을 향상시켰습니다. 특히 일반화된 제로샷 설정(GZSL)에서도 우수한 인식 성능을 보였습니다.



### Vision-guided and Mask-enhanced Adaptive Denoising for Prompt-based Image Editing (https://arxiv.org/abs/2410.10496)
- **What's New**: 이번 연구에서는 Vision-guided and Mask-enhanced Adaptive Editing (ViMAEdit) 방법을 제안하며, 이는 기존의 텍스트 기반 이미지 편집 방식의 한계점을 극복하고자 합니다. 특히, 소스 이미지를 이용하여 목표 이미지를 생성하는 새로운 접근 방식을 도입하였습니다.

- **Technical Details**: ViMAEdit는 특히 이미지 임베딩을 활용하여 기존의 텍스트 프롬프트 기반 디노이징 프로세스를 강화합니다. CLIP 기반의 목표 이미지 임베딩 추정 전략을 통해 에디팅 영역의 정밀성을 높이고, 자가 주의(self-attention)에 기반한 반복적인 에디팅 영역 근거 전략을 도입하여 패치 간 관계를 효과적으로 활용합니다.

- **Performance Highlights**: ViMAEdit는 기존 방법들에 비해 월등한 편집 능력을 보여주며, 중요한 이미지 영역에 더욱 높은 샘플링 분산을 적용하여 편집의 효과성을 향상시킵니다. 실험 결과에서 ViMAEdit는 타 연구 방법들과 비교하여 더욱 정교하고 효과적인 편집 결과를 도출해냅니다.



### Learning to Ground VLMs without Forgetting (https://arxiv.org/abs/2410.10491)
- **What's New**: 이 논문에서는 LynX라는 새로운 프레임워크를 소개하는데, 사전 훈련된 시각 언어 모델(Visual Language Models, VLMs)에 공간 인식 능력을 효과적으로 추가하는 방법을 제시하고 있습니다. 이 프레임워크는 기존 능력을 잃지 않고 새로운 그라운딩(grounding) 기능을 학습하도록 설계되었습니다.

- **Technical Details**: LynX는 Dual Mixture of Experts (MoE) 아키텍처를 기반으로 하며, 이는 언어 모델의 디코더 레이어만 수정하여 한 개의 고정된 MoE와 하나의 학습 가능한 MoE를 사용합니다. 이는 모델이 이미지 이해 및 언어 이해 능력을 유지하면서 새로운 그라운딩 능력을 획득할 수 있게 합니다. 또한, SCouT라는 고품질 합성 데이터셋을 생성하여 시각적 그라운딩 작업을 위한 고급 훈련 신호를 제공합니다.

- **Performance Highlights**: LynX 모델은 여러 객체 탐지 및 시각적 그라운딩 데이터셋에서 강력한 성능을 입증하였으며, 객체 탐지, 제로샷 로컬라이제이션(zero-shot localization), 그리고 그라운딩 추론에서 높은 성과를 보였습니다. 이 과정에서 기존의 이미지 및 언어 이해 능력을 성공적으로 유지했습니다.



### Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization (https://arxiv.org/abs/2410.10483)
Comments:
          Paper submitted to Computer in Biology and Medicine, ELSEVIER

- **What's New**: 이 연구는 신생아를 위한 AI 기반 시간 감지 시스템을 개발하는 방식으로 신생아의 생명 구제 지원을 향상시키고자 합니다. 특히, 출생 후 '황금 분' 동안 신속한 응급 처치 필요성을 강조합니다.

- **Technical Details**: 본 연구는 세 가지 단계의 방법론을 제안합니다: 첫째, 온도 변동 문제를 완화하기 위해 Gaussian mixture models (GMM) 기반 적응 정규화 기법을 제안합니다; 둘째, 온도 비디오 프레임 안에서 신생아의 존재를 감지하기 위해 AI 모델을 구현하고 배치합니다; 셋째, 모델의 예측을 평가하고 후처리하여 출생 시간(Time of Birth, ToB)을 추정합니다.

- **Performance Highlights**: 실제 성능 평가에서 신생아 탐지에 대한 정확도는 88.1%이며 재현율은 89.3%로 보고되었습니다. 이 방법은 수동 주석에 비해 절대 중앙 편차가 2.7초로 ToB 추정의 정확성을 보여줍니다.



### ReLayout: Towards Real-World Document Understanding via Layout-enhanced Pre-training (https://arxiv.org/abs/2410.10471)
- **What's New**: 최근 시각적으로 풍부한 문서 이해(VrDU)를 위한 접근 방식들은 수동으로 주석된 의미 그룹을 사용하지만, 이는 비현실적입니다. 새로운 '실제 세계 시각적으로 풍부한 문서 이해(ReVrDU)'라는 과제를 도입하며, ReLayout이라는 새로운 방법을 제안하여 의미 그룹을 수동으로 사용하지 않고 문서를 이해합니다.

- **Technical Details**: ReVrDU에서는 수동으로 주석된 의미 그룹 대신 상용 OCR 도구에서 제공하는 정보(글자, 1D 위치, 2D 바운딩 박스 등)를 사용합니다. 'ReLayout' 모형은 단순한 1D 전역 위치와 2D 바운딩 박스를 입력으로 사용하여 텍스트 세그먼트 내 단어 순서를 예측하고 세그먼트 클러스터링을 통한 자기 지도 학습을 적용합니다.

- **Performance Highlights**: 기존의 방법이 ReVrDU 과제에서 성능이 저하된 반면, ReLayout은 이상적 및 실제 환경 모두에서 우수한 성능을 보였습니다.



### Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks (https://arxiv.org/abs/2410.10454)
Comments:
          Accepted by EMNLP 2024 Findings

- **What's New**: 이 논문에서는 few-shot text classification의 정확도를 높이기 위해 Label-Adapter 및 Query-Data-Augmenter 모듈을 도입한 새로운 방법인 LAQDA를 제안합니다.

- **Technical Details**: LAQDA는 태스크에 적응하는 메트릭 공간을 구성하여 intra-class 차이를 줄이고 inter-class 차이를 확대합니다. 최적 수송(optimal transport) 기법을 활용하여 쿼리 세트 샘플로 클래스 프로토타입을 추정합니다. 이 방법은 기존의 과적합(overfitting) 문제를 완화하는 것을 목표로 합니다.

- **Performance Highlights**: 제안된 LAQDA 방법은 8개의 벤치마크 데이터셋에서 state-of-the-art 모델들에 비해 확연한 성능 향상을 보여주며, 모든 작업(task)에서 높은 정확도를 기록했습니다.



### Self-Assessed Generation: Trustworthy Label Generation for Optical Flow and Stereo Matching in Real-world (https://arxiv.org/abs/2410.10453)
- **What's New**: 본 논문에서는 Optical Flow와 Stereo 작업을 위한 통합된 자기 지도 생성 프레임워크인 Self-Assessed Generation (SAG)을 제안합니다. 이 방법은 고비용의 데이터셋 생성 문제와 기존의 모호한 결과 및 복잡한 모델 훈련 한계를 해결합니다.

- **Technical Details**: SAG는 RGB 이미지에서 재구성 필드를 생성하고 이를 바탕으로 데이터셋을 생성하는 데이터 기반 접근 방식을 사용합니다. 주요 모듈로는 라벨 데이터 생성, 데이터 자기 평가 및 3D 비행 전경 자동 렌더링 파이프라인이 포함되어 있습니다. 새로운 RC 지표를 도입하여 재구성 모델의 신뢰도를 평가합니다.

- **Performance Highlights**: SAG는 기존의 방법들과 비교하여 48% 향상된 Optical Flow endpoint error (2.04 vs 3.96)를 기록하였으며, 단 300개의 자연 장면을 사용하여 뛰어난 일반화 성능을 발휘합니다. 기존의 자기 지도 학습 방법에 비해 더 일반화되고 저비용이면서 정확하게 작용합니다.



### Domain-Conditioned Transformer for Fully Test-time Adaptation (https://arxiv.org/abs/2410.10442)
- **What's New**: 이번 연구는 Transformer 모델의 Fully Test-Time Adaptation에 대한 새로운 접근 방식을 제안하며, 도메인 변화에 대한 적응성이 개선된 Self-Attention 모듈 구조를 도입합니다.

- **Technical Details**: Self-Attention 모듈에 도메인 조건 벡터인 domain conditioners를 쿼리, 키, 값 컴포넌트에 통합하여, 각 레이어에서 클래스 토큰으로부터 이 벡터를 생성합니다. 이를 통해 도메인 이동으로 인한 편차를 단계적으로 제거합니다.

- **Performance Highlights**: 제안된 domain-conditioned transformer는 온라인에서의 도메인 적응 성능을 대폭 향상시키며, 기존의 최신 방법들을 크게 능가하는 결과를 보였습니다.



### Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs (https://arxiv.org/abs/2410.10441)
Comments:
          Tech report

- **What's New**: 비디오 이해를 위한 효율적인 추론을 제공하는 새로운 프롬프트 기반 시각 인식 프레임워크(Free Video-LLM)를 제시합니다.

- **Technical Details**: 이 프레임워크는 공간적-시간적 차원을 분리하고, 작업별 프롬프트에 따라 시간적 프레임 샘플링(temporal frame sampling)과 공간적 RoI 크롭(spatial RoI cropping)을 수행합니다. 이를 통해 비디오 프레임에서 생성되는 시각 토큰(visual tokens)의 수를 효과적으로 줄입니다.

- **Performance Highlights**: 우리의 방법은 여러 비디오 질문-응답 벤치마크에서 높은 성능을 유지하면서 토큰 수를 크게 줄여, 정확도와 계산 효율 간의 최적의 균형을 제공합니다.



### LKASeg:Remote-Sensing Image Semantic Segmentation with Large Kernel Attention and Full-Scale Skip Connections (https://arxiv.org/abs/2410.10433)
Comments:
          The paper is under consideration at 2025 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)

- **What's New**: 본 논문에서는 원격 감지 이미지의 의미적 분할을 위한 새로운 네트워크인 LKASeg를 제안합니다. 이 네트워크는 Large Kernel Attention (LKA)와 Full-Scale Skip Connections (FSC)을 결합하여, 전통적인 CNNs와 Transformers의 한계를 극복합니다.

- **Technical Details**: LKASeg는 ResNet-18 기반의 인코더, LKA 기반의 디코더, 및 전체 규모의 스킵 연결(FSC)로 구성됩니다. LKA는 글로벌 피처를 추출하면서도 self-attention의 계산 오버헤드를 피하고, 채널 적응성을 제공합니다.

- **Performance Highlights**: ISPRS Vaihingen 데이터셋에서 실험을 진행한 결과, mF1 점수 90.33%, mIoU 점수 82.77%를 달성하였습니다.



### DOME: Taming Diffusion Model into High-Fidelity Controllable Occupancy World Mod (https://arxiv.org/abs/2410.10429)
Comments:
          Please visit our project page at this https URL

- **What's New**: 본 논문에서는 과거의 점유 관측치를 기반으로 미래의 점유 프레임을 예측하는 diffusion 기반의 세계 모델인 DOME을 제안합니다. 이 세계 모델은 자율주행의 계획에서 환경 변화의 예측 능력이 매우 중요하며, 2D 영상 기반 모델과 달리 본래의 3D 표현을 활용합니다.

- **Technical Details**: DOME은 고충실도 및 장기 생성(Diffusion)과 세밀한 제어 가능성을 key feature로 가지고 있습니다. 과거의 정보(contextual occupancy)를 활용하는 공간-시간(diffusion transformer) 구조를 채택하여, 32초에 걸쳐 상세한 예측을 생성할 수 있습니다. 또한, 경로 재샘플링 방법을 도입하여 다양한 주행 궤적을 더욱 정밀하게 예측할 수 있도록 제어 가능성을 향상시킵니다.

- **Performance Highlights**: nuScenes 데이터셋을 통해 수행된 실험에서, DOME은 기존 모델을 초월하여 3D 점유 재구성에서 10.5% 향상된 mIoU 및 21.2% 향상된 IoU, 4D 점유 예측에서 각각 36.0% 향상된 mIoU 및 24.6% 향상된 IoU를 기록했습니다.



### 4DStyleGaussian: Zero-shot 4D Style Transfer with Gaussian Splatting (https://arxiv.org/abs/2410.10412)
- **What's New**: 이번 논문에서는 4D 스타일 전송을 위한 새로운 프레임워크인 4DStyleGaussian을 소개합니다. 이 방법은 사용자 친화적인 스타일화를 제공하면서도 공간적 일관성을 유지할 수 있는 가능성을 보여줍니다.

- **Technical Details**: 4DStyleGaussian은 4D Gaussian Splatting 기법을 활용하여 작동하며, 내용 손실(content loss)을 최소화하는 가역적(neural network) 네트워크를 통해 훈련됩니다. 이 방법은 4D 스타일 변환 행렬을 예측하여 공간적, 시간적으로 일관된 스타일 전송을 수행합니다.

- **Performance Highlights**: 실험 결과, 4DStyleGaussian은 4D 동적 시나리오에서 높은 품질과 제로샷(zero-shot) 스타일화를 달성하며, 향상된 효율성과 공간-시간적 일관성을 보였습니다.



### Parameterize Structure with Differentiable Template for 3D Shape Generation (https://arxiv.org/abs/2410.10399)
- **What's New**: 이 논문은 구조적 표현(Structural representation)을 통해 편집 가능한 3D 형태를 재구성하고 생성하는 새로운 방법을 제안합니다. 특히, 동일 카테고리 내에서 공유되는 구조를 차별화된 템플릿(differentiable template)과 고정 길이 매개변수(fixed-length parameters)를 사용하여 파라미터화합니다.

- **Technical Details**: 제안된 방법은 각 카테고리에 대한 공유 구조의 차별화된 템플릿을 디자인하며, 이를 통해 특정 매개변수를 바탕으로 형태를 표현합니다. 3D 형태는 격자로 형성되며, 각 격자의 내부 세부 사항을 설명하기 위해 세 가지 시각의 경계(threshold)를 이용합니다. 이로 인해 SDF(Signed Distance Function)를 통해 객체를 복원할 수 있습니다.

- **Performance Highlights**: 제안된 방법은 포인트 클라우드(point cloud)로부터의 재구성과 생성을 통해 다양한 형태를 복원하거나 생성할 수 있으며, 부드럽게 보간할 수 있습니다. 광범위한 평가 결과, 본 방법이 재구성, 생성 및 보간에서 우수한 성능을 보여주었습니다.



### Reverse Refinement Network for Narrow Rural Road Detection in High-Resolution Satellite Imagery (https://arxiv.org/abs/2410.10389)
- **What's New**: 이 연구는 도시 지역의 도로 추출에 중점을 두던 기존 연구와 달리, 좁고 불규칙한 농촌 도로의 자동 추출을 위한 새로운 방법인 R2-Net을 제안합니다.

- **Technical Details**: R2-Net은 고해상도 피쳐 맵에서 도로의 세부 사항을 보존하기 위해 axis context aware module (ACAM)을 사용하여 다양한 레이어에서 장거리 공간 맥락 정보를 캡처합니다. 이어서 multi-level features는 global aggregation module (GAM)을 통해 집계됩니다. 또한, decoder 단계에서는 reverse-aware module (RAM)을 활용하여 복잡한 배경에 대한 네트워크의 주의를 유도하여 분리 가능성을 강화합니다.

- **Performance Highlights**: R2-Net은 DeepGlobe 도로 추출 데이터셋과 WHU-RuR+ 글로벌 대규모 농촌 도로 데이터셋을 사용한 실험에서 여러 최첨단 방법들과 비교하여 뛰어난 성능을 보였습니다. 특히, 좁은 도로의 정확한 감지에서 두각을 나타냈으며, 대규모 농촌 도로 매핑에 대한 적용 가능성도 탐구하였습니다.



### V2M: Visual 2-Dimensional Mamba for Image Representation Learning (https://arxiv.org/abs/2410.10382)
- **What's New**: 본 논문은 2D 이미지 처리를 위한 새로운 모델인 'Visual 2-Dimensional Mamba (V2M)'를 제안합니다. 기존의 1D 시퀀스 처리 방식을 넘어 2D 공간에서 이미지 토큰을 직접 처리하여 더 나은 지역적 유사성(local similarity)과 일관성을 유지합니다.

- **Technical Details**: V2M은 2차원 상태 공간 모델(SSM)을 일반화하여 두 개의 인접한 상태를 고려하여 다음 상태를 생성합니다. 이는 열(columns) 및 행(rows) 두 방향의 정보를 활용하며, Mamba의 병렬 처리 능력을 결합하여 하드웨어 효율성을 극대화합니다. 또한, 이미지의 모든 네 모서리에서 시작하는 2D 상태 방정식을 통해 토큰을 비연속적으로 처리합니다.

- **Performance Highlights**: ImageNet 분류 및 COCO 객체 탐지, ADE20K 의미 구분에서 V2M의 성능이 기존의 Vision Mamba(Vim) 모델 대비 +0.4% 향상됨을 보여주었습니다. 이는 V2M이 2D 지역성을 효과적으로 통합하면서도 Mamba의 효율성과 입력 의존성 있는 확장성을 계승한다는 점을 입증합니다.



### Class Balancing Diversity Multimodal Ensemble for Alzheimer's Disease Diagnosis and Early Detection (https://arxiv.org/abs/2410.10374)
- **What's New**: 알츠하이머병(AD)의 조기 발견과 진단을 위한 새로운 다중모달 앙상블 접근 방식인 IMBALMED가 제안되었습니다. 이 방법은 ADNI(Alzheimer's Disease Neuroimaging Initiative) 데이터베이스에서 수집된 다양한 모달리티의 데이터를 통합하여 신경퇴행성 질환을 더 효과적으로 진단합니다.

- **Technical Details**: IMBALMED는 다양한 클래스 균형 기법을 사용하여 훈련된 모델 분류기를 앙상블로 구성하여 클래스 불균형 문제를 극복합니다. 이 연구에서는 임상 평가, 신경영상 형상, 생물학적 표본 및 주제 특징 데이터와 같은 다양한 모달리티의 데이터를 통합하여 AD 진단 및 초기 발견의 정확성을 향상시킵니다.

- **Performance Highlights**: IMBALMED는 기존의 가장 발전된 알고리즘과 비교하여 이진 및 삼진 분류 작업에서 우수한 진단 정확도와 예측 성능을 보여주었으며, 48개월 시점에서 MCI의 조기 발견을 현저히 개선했습니다.



### Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation (https://arxiv.org/abs/2410.10366)
Comments:
          BIBM 2024

- **What's New**: 이 논문은 의료 이미징 сегментация (segmentation)에서 반지도 학습 (SemiSL)과 대조 학습 (CL) 결합의 진전을 보여줍니다. 특히, 피사체(task)가 없는 경우에도 적은 주석으로 효과적인 모델 성능을 달성하는 방법을 제안합니다.

- **Technical Details**: 제안된 방법론은 학생 네트워크(student network)와 교사 네트워크(teacher network) 간의 친밀도 그래프 기반 지도 신호(affinity-graph-based supervision signals)를 설정하여 Semi-AGCL 프레임워크를 구성합니다. 또한 평균 패치 엔트로피 기반의 상호 패치 샘플링 방법을 설계하여 초기 특징 공간을 구축하고, 친밀도 그래프 손실 함수(affinity-graph-guided loss function)를 통해 학습된 표현의 품질을 향상시키고 과적합(overfitting)을 완화합니다.

- **Performance Highlights**: 실험 결과, 전체 주석 세트의 단 10%만 사용했음에도 불구하고, 제안한 모델은 완전 주석의 기준선과 함께 단 2.52%의 편차로 정확도에 접근했습니다. 특히, 주석의 5%만 사용된 상황에서도, dice metric에서 두 번째 최고 기준선을 23.09% 초과하여 성능이 크게 향상되었고, 특히 CRAG와 ACDC 데이터셋에서 26.57% 개선된 결과를 보였습니다.



### FasterDiT: Towards Faster Diffusion Transformers Training without Architecture Modification (https://arxiv.org/abs/2410.10356)
Comments:
          NeurIPS 2024 (poster)

- **What's New**: Diffusion Transformers (DiT)의 훈련 속도를 개선하기 위한 FasterDiT 방법을 제안하며, 이를 위해 Signal-to-Noise Ratio (SNR) 개념을 확장하고 새로운 감독 방법론을 도입하였습니다.

- **Technical Details**: SNR의 정의를 약간 확장하고 이를 기반으로 한 Probability Density Function (PDF)의 시각화를 통해 훈련의 효율성을 분석했습니다. 또한, 다양한 실험을 통해 PDF 관점에서 훈련 성능과 데이터 강인성 간의 관계를 탐구하였습니다. 새로운 감독 방법론을 통해 훈련 프로세스를 가속화하였습니다.

- **Performance Highlights**: FasterDiT는 ImageNet 256 해상도에서 1000k 반복 시 2.30의 FID를 달성하며, 기존 DiT의 FID 2.27 대비 7배 빠른 훈련 속도를 기록했습니다.



### On Representation of 3D Rotation in the Context of Deep Learning (https://arxiv.org/abs/2410.10350)
Comments:
          Accepted at International Conference on Computer Vision and Graphics ICCVG 2024. The proceedings of the conference will be published in Lecture Notes in Networks and Systems (LNNS), Springer

- **What's New**: 이 논문은 3D 회전을 표현하는 다양한 방법과 그 방법이 딥 뉴럴 네트워크의 학습 과정에 미치는 영향을 조사합니다. 저자들은 Synthetic 데이터와 Real 데이터 모두에서 ResNet18 네트워크의 성능을 평가했습니다.

- **Technical Details**: 3D 회전을 표현하는 방법에는 회전 매트릭스, 오일러 각도, 쿼터니온 등이 있습니다. 저자들은 연속적인 5D 및 6D 표현 방식을 통해 성능이 향상된다는 점을 밝혔습니다.

- **Performance Highlights**: 연속적인 표현을 사용하는 네트워크가 불연속적인 표현을 사용하는 네트워크보다 더 정확하고 강인한 성과를 보였으며, 훈련 동작도 더 유리하다는 결과를 도출했습니다.



### Spatial-Aware Efficient Projector for MLLMs via Multi-Layer Feature Aggregation (https://arxiv.org/abs/2410.10319)
Comments:
          10 pages, 3 figures

- **What's New**: 이번 연구에서는 Multi-Modal Language Models (MLLMs)에 중요한 역할을 하는 프로젝트의 개선 사항을 다루고 있으며, 새로운 Spatial-Aware Efficient Projector (SAEP) 방법을 제안합니다.

- **Technical Details**: SAEP 방법은 다층 시각 특성에서 spatial 정보의 향상을 위해 수정된 separable depthwise convolution 모듈을 사용합니다. 이를 통해 2차원 시각 토큰 시퀀스와 자연어 토큰 시퀀스 간의 공간적 불일치를 해결하고자 합니다.

- **Performance Highlights**: SAEP 방법은 기존 방법에 비해 시각 토큰 수를 75%까지 줄일 수 있으며, MLLMs의 멀티모달 공간 이해 능력을 크게 향상시킵니다. 또한, 다양한 멀티모달 평가 벤치마크에서 최고의 성능을 보이며, modality gap을 극복하는 데 효과적임을 입증했습니다.



### QIANets: Quantum-Integrated Adaptive Networks for Reduced Latency and Improved Inference Times in CNN Models (https://arxiv.org/abs/2410.10318)
Comments:
          Accepted to NeurIPS 2024 workshop on Neural Compression

- **What's New**: QIANets는 양자 기반의 가지치기(quantum-inspired pruning), 텐서 분해(tensor decomposition), 및 열 처리 기반의 행렬 분해(annealing-based matrix factorization)를 사용하여 전통적인 CNN 모델 아키텍처를 개선한 새로운 접근법으로, 고속 추론(low latency)과 정확도 유지의 균형을 맞추는 데 초점을 맞추고 있습니다.

- **Technical Details**: 이 방법은 양자 근사 최적화 알고리즘(QAOA)을 이용하여 가지치기를 수행하고, 고차원 텐서를 낮은 차원으로 분해함으로써 컴퓨팅 복잡성을 줄이도록 설계되었습니다. 각 가중치의 중요성을 평가하기 위해 소프트맥스(normalized using softmax) 함수를 사용하여 확률을 도출하고, 이 결과를 기반으로 가지치기를 진행합니다.

- **Performance Highlights**: 실험 결과, QIANets는 추론 시간을 줄이면서도 정확도를 효과적으로 유지함을 입증하였으며, 전통적인 CNN 아키텍처의 구조적 최적화를 통해 무게 감소 및 성능 향상에 기여 할 수 있음을 보여주었습니다.



### GlobalMamba: Global Image Serialization for Vision Mamba (https://arxiv.org/abs/2410.10316)
- **What's New**: 본 논문에서는 이미지의 2D 구조적 상관관계를 고려한 새로운 방법론으로, 글로벌 이미지 시리얼라이제이션(Global Image Serialization)을 제안합니다. 이 방법은 이미지 데이터를 주파수 도메인(Frequency Domain)으로 변환한 후, 픽셀을 주파수 대역에 따라 정리하여 이미지 토큰 전처리를 수행합니다.

- **Technical Details**: 주요 기술로는 이산 코사인 변환(Discrete Cosine Transform, DCT)을 사용하여 이미지를 주파수 도메인으로 변환하는 단계가 포함됩니다. 그 후 동일한 주파수 대역에 있는 픽셀들을 그룹화하여 다시 공간 도메인으로 변환하고, 최종적으로 토큰화 과정을 통해 이미지의 글로벌 정보를 담고 있는 인과적 토큰 시퀀스를 생성합니다.

- **Performance Highlights**: 이미지넷 이미지 분류(Image Classification on ImageNet-1K), 객체 탐지(Object Detection on COCO), 의미론적 분할(Semantic Segmentation on ADE20K)에서의 광범위한 실험을 통해 GlobalMamba의 우수한 성능을 입증했습니다. ImageNet-1K에서 기존 모델 대비 0.6%의 성능 향상을 달성했습니다.



### LG-CAV: Train Any Concept Activation Vector with Language Guidanc (https://arxiv.org/abs/2410.10308)
- **What's New**: 본 연구에서는 Language-Guided CAV (LG-CAV)를 제안하여 사전 훈련된 비전-언어 모델(vision-language models, VL models)에서 풍부한 개념 지식을 활용함으로써 레이블이 없는 데이터를 사용하여 CAV를 훈련할 수 있게 되었습니다. LG-CAV는 모델 수정(model correction) 기술을 통해 Target Model의 성능을 향상시킵니다.

- **Technical Details**: LG-CAV는 VL 모델에서 개념 설명(concept descriptions)을 사용하여 특정 개념에 대한 CAV를 훈련하고, 공통 이미지 풀(probe images)에서 VL 모델의 개념 설명의 활성화 값(activation values)을 추출하여 CAV 훈련에 활용합니다. 이를 위해 Gaussian alignment (GA) 모듈과 개념 앙상블(concept ensemble, CE) 모듈, 편차 샘플 재가중치(deviation sample reweighting, DSR) 모듈을 제안하여 LG-CAV의 품질을 더욱 향상시킵니다.

- **Performance Highlights**: LG-CAV는 Broden 및 ImageNet 데이터셋에서 이전 CAV 방법들에 비해 현저히 높은 CAV 품질(개념 정확도(concept accuracy) 및 개념-클래스 정확도(concept-to-class accuracy))를 달성하며, ImageNet 및 CUB-200-2011, CIFAR-100 데이터셋에서 기존 개념 기반 방법보다 우수한 성능을 보입니다.



### Animate-X: Universal Character Image Animation with Enhanced Motion Representation (https://arxiv.org/abs/2410.10306)
Comments:
          25 pages, 15 figures, conference

- **What's New**: Animate-X라는 새로운 애니메이션 프레임워크를 제안하여 다양한 캐릭터 유형을 애니메이션화하는 능력을 향상시킵니다. 특히 인간 모션을 기반으로 하여 비인간 아바타에도 잘 작동하도록 설계되었습니다.

- **Technical Details**: Animate-X 프레임워크는 LDM(Latent Diffusion Model) 기반으로 개발되었으며, Pose Indicator라는 새로운 구성 요소를 통해 모션 표현력을 개선하였습니다. Implicit Pose Indicator (IPI)와 Explicit Pose Indicator (EPI)를 통해 애니메이션의 동작 패턴을 효과적으로 캡처합니다.

- **Performance Highlights**: 기존 최첨단 방법들과 비교하여 Animate-X는 캐릭터의 정체성 보존과 모션 일관성을 유지하면서 보다 높은 성과를 보여줍니다. 특히 소프트웨어의 성능을 평가하기 위해 500종의 인형 캐릭터와 해당 춤 비디오를 포함한 A²Bench 기준을 새롭게 독립적으로 제안했습니다.



### ROA-BEV: 2D Region-Oriented Attention for BEV-based 3D Objec (https://arxiv.org/abs/2410.10298)
- **What's New**: 이 논문에서는 자율주행에서 인기를 얻고 있는 BEV (Bird-Eye-View) 기반 3D 객체 탐지 기술에 대한 새로운 접근 방식을 제안합니다. 특히, 기존 방법으로는 카메라 관점에서 배경과 유사한 객체를 효과적으로 탐지하지 못하는 문제를 해결하기 위한 방안을 모색합니다.

- **Technical Details**: 새롭게 제안된 2D Region-oriented Attention (ROA)을 사용하여 BEV 기반 3D 객체 탐지 네트워크의 성능을 향상시킵니다. ROA는 객체가 존재할 가능성이 있는 영역에서 특성 학습에 집중하도록 백본(backbone)을 조정합니다. 또한, 멀티 스케일(multi-scale) 구조를 통해 ROA의 정보량을 증가시키며, 각 ROA 블록은 대형 커널(large kernel)을 사용하여 수용 필드(receptive field)를 크게 확보하여 대형 객체의 정보를 효과적으로 포착할 수 있도록 합니다.

- **Performance Highlights**: nuScenes 데이터셋에 대한 실험 결과, ROA-BEV는 기존의 BEVDet 및 BEVDepth 모델에 비해 개선된 성능을 보였습니다. 코드는 곧 공개될 예정입니다.



### A Consistency-Aware Spot-Guided Transformer for Versatile and Hierarchical Point Cloud Registration (https://arxiv.org/abs/2410.10295)
Comments:
          Accepted by NeurIPS 2024 as poster

- **What's New**: 본 연구에서는 기존의 조잡한 매칭 방법의 문제를 해결하기 위해 일관성 인지 스팟 가이드 Transformer (CAST)를 설계했습니다. 이 모델은 불필요한 영역과의 간섭을 피하기 위해 스팟 가이드 크로스-어텐션 모듈을 통합하고, 기하학적으로 일관된 대응을 강화하기 위해 일관성 인지 자기-어텐션 모듈을 추가했습니다.

- **Technical Details**: CAST는 스팟 가이드 크로스-어텐션과 일관성 인지 자기-어텐션 모듈을 활용하여 매칭 능력을 향상시키며, 경량화된 세밀한 매칭 모듈을 통해 희소한 키포인트와 밀집한 특징 모두에 대해 정확한 변환 추정을 가능하게 합니다. 이 방법은 최적 수송 기반 알고리즘을 사용하지 않고 효율적인 희소-밀집 매칭 파이프라인을 통해 실시간 애플리케이션에 적합합니다.

- **Performance Highlights**: 실외 LiDAR 및 실내 RGBD 포인트 클라우드 데이터셋에서의 광범위한 실험 결과, CAST는 최신 기술을 초월하는 정확도, 효율성 및 강인성을 달성하며, 특히 로봇의 주행거리 측정(odometry)과 같은 실시간 대규모 응용 프로그램에 대해 효율적으로 작동합니다.



### Fine-grained Abnormality Prompt Learning for Zero-shot Anomaly Detection (https://arxiv.org/abs/2410.10289)
Comments:
          27 pages, 19 figures

- **What's New**: 본 연구에서는 Fine-grained Abnormality Prompts를 학습하기 위한 새로운 프레임워크인 FAPrompt를 제안합니다. 기존의 ZSAD 방법들이 고수준의 비정상성을 포착하는 데 집중하는 반면, FAPrompt는 다양한 미세한 비정상성 구문을 모델링할 수 있는 프롬프트를 학습하는 데 중점을 둡니다.

- **Technical Details**: FAPrompt는 Compound Abnormality Prompting 모듈(CAP)과 Data-dependent Abnormality Prior 모듈(DAP)을 도입하여 미세한 비정상성 패턴을 학습합니다. CAP은 정상 프롬프트를 기반으로 비정상적인 토큰을 조합하여 보완적이고 분해된 비정상 프롬프트 집합을 생성합니다. DAP는 쿼리 이미지를 통해 비정상 특징을 선택하여 학습된 비정상성을 목표 데이터 세트에 적응시킵니다.

- **Performance Highlights**: FAPrompt는 19개의 실제 데이터세트에 대한 포괄적인 실험을 통해 기존 최첨단 ZSAD 모델보다 최소 3%-5% AUC/AP 향상된 성능을 보이며, 이미지 및 픽셀 수준의 탐지 작업 모두에서 뛰어난 결과를 나타냅니다.



### Manifold-Aware Local Feature Modeling for Semi-Supervised Medical Image Segmentation (https://arxiv.org/abs/2410.10287)
Comments:
          11 pages

- **What's New**: 이번 논문에서는 MANet, 즉 Manifold-Aware Local Feature Modeling Network를 소개하여, 의료 이미지 분할의 경계를 더욱 정확하게 식별하고 신뢰할 수 있는 진단을 위한 개선 방법을 제안합니다. MANet은 U-Net 아키텍처를 강화하여 매니폴드 정보를 통해 경계 정확성을 높이는 데 초점을 맞추고 있습니다.

- **Technical Details**: MANet은 매니폴드에 대한 감독 신호를 통합하여 U-Net 구조를 개선한 모델입니다. 두 가지 변형인 MA-Sobel (Sobel operator를 사용하여 2D 및 3D 데이터에 적합)과 MA-Canny (Canny operator를 사용하여 2D 이미지 전용)를 제안하여 다양한 의료 이미지 특성에 적응할 수 있도록 합니다. 이 모델은 세미-슈퍼바이즈드 학습 방식을 사용하여 라벨이 있는 데이터와 라벨이 없는 데이터의 조합으로 학습됩니다.

- **Performance Highlights**: MANet은 ACDC, LA, Pancreas-NIH와 같은 데이터셋에서 기존의 최첨단 방법보다 우수한 성능(Dice 및 Jaccard 점수)으로 입증되었습니다. 시각화 결과, MANet의 분할 결과는 클래스 경계에서 더 높은 정확도를 보여주며, 이는 의료 영상 분할 작업에서 매니폴드 정보의 효과성을 강조합니다.



### Exploring Semi-Supervised Learning for Online Mapping (https://arxiv.org/abs/2410.10279)
- **What's New**: 이 논문은 온라인 매핑(online mapping) 문제에 대해 반지도 학습(semi-supervised learning) 기술을 적용하는 새로운 접근 방식을 제안합니다. 특히, 여러 샘플의 teacher의 pseudo-labels를 융합하여 성능을 향상시키는 방법을 소개합니다.

- **Technical Details**: 이 연구에서는 기존 반지도 학습(SSL) 기술에 대한 종합적인 분석을 진행하고, 정적 세계 가정(static-world assumption)을 활용해 teacher 모델이 여러 샘플 간의 정보를 통합하는 방법을 탐구합니다. 이를 통해 pseudo-label의 정확성을 개선하고, SSL 구성 요소를 통합하여 라벨된 데이터의 양에 상관없이 안정적인 성능을 유지하는 강력한 방법을 제안합니다.

- **Performance Highlights**: 이 연구는 Argoverse에서 mIoU 29.6에서 3.4로, NuScenes에서는 12에서 3.4로 성능 격차를 줄였습니다. 또한, 새로운 도시로의 일반화에서 보스턴에서 싱가포르로의 전환 시, 비라벨 데이터 활용을 통해 mIoU가 6.6 포인트 향상되었습니다.



### big.LITTLE Vision Transformer for Efficient Visual Recognition (https://arxiv.org/abs/2410.10267)
- **What's New**: 이 논문에서는 효율적인 시각 인식을 달성하기 위한 혁신적인 구조인 Big.LITTLE Vision Transformer (bLViT)를 소개합니다. 이 시스템은 세 가지 주요 블록으로 구성되어 있으며, 중요한 토큰을 고성능 모델에서 처리하고 덜 중요한 토큰을 효율적인 모델에서 처리하여 전체 성능을 유지하면서 계산량을 drastisch 감소시킵니다.

- **Technical Details**: bLViT는 두 개의 변환기 블록으로 구성되어 있습니다: High-capacity big performance block과 Low-capacity LITTLE efficiency block. 이미지 처리 시 모델은 각 토큰의 중요성을 평가하여 이에 따라 처리하도록 설정됩니다. 중요한 토큰은 big model에서 처리되고 중요성이 낮은 토큰은 little model에서 처리됩니다. 각 토큰의 중요성 점수는 예측 레이어에서 결정됩니다.

- **Performance Highlights**: bLViT는 이미지 분류(image classification) 및 이미지 세분화(image segmentation) 과제에서 실험을 통해 높은 정확도를 유지하면서 상당한 계산 비용 절감을 달성했습니다. 이 모델은 성능과 효율성 간의 트레이드오프를 효과적으로 관리함으로써 대규모 시각 인식 작업을 효율적으로 처리할 수 있음을 입증했습니다.



### Slide-based Graph Collaborative Training for Histopathology Whole Slide Image Analysis (https://arxiv.org/abs/2410.10260)
- **What's New**: 본 연구는 컴퓨터 병리학(Computational Pathology) 발전에 있어 슬라이드 간 상관관계(slide inter-correlations)의 중요성을 강조하며, 기존의 연구가 WSI(Whole Slide Image) 내의 정보에만 초점을 맞춰왔음을 지적합니다. 이에 우리는 슬라이드 간의 관계를 모델링에 포함시키는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 우리는 SlideGCD라는 일반적인 WSI 분석 파이프라인을 제안하며, 이는 기존의 Multiple Instance Learning (MIL) 프레임워크에 적응 가능하고, 성능을 향상시킵니다. 이 새로운 패러다임에서는 암 발병의 사전 지식이 end-to-end 워크플로우에 통합되어 슬라이드 표현을 초기화하고 미세 조정합니다. 또한, 슬라이드 기반 그래프에서 메시지 전달을 위한 안내 역할을 합니다.

- **Performance Highlights**: 제안된 파이프라인의 효과와 견고성을 검증하기 위해 암 유형 분류(cancer subtyping), 암 병기(stage) 분류, 생존 예측(survival prediction), 유전자 변이 예측(gene mutation prediction) 등 4가지 작업에 대해 광범위한 비교와 실험을 수행하였고, 7개의 대표적인 SOTA WSI 분석 프레임워크를 기반으로 하였습니다.



### Saliency Guided Optimization of Diffusion Latents (https://arxiv.org/abs/2410.10257)
- **What's New**: 이 논문에서는 기존의 균일한 최적화 방법의 한계를 극복하기 위해 Saliency Guided Optimization Of Diffusion Latents (SGOOL)라는 새로운 최적화 방법을 제안합니다. SGOOL은 인간의 시각적 주의 시스템을 모방하여 두드러진 영역을 식별하고 최적화 과정에서 이러한 영역을 우선적으로 다룹니다.

- **Technical Details**: SGOOL은 Saliency Detector를 사용하여 중요 부분을 식별한 후, 기존의 diffusion latents를 직접 최적화합니다. 이 과정은 별도의 모델 재훈련을 피하면서도 인버터블(역변환 가능한) diffusion 프로세스를 활용하여 메모리 효율성을 가져옵니다. 이를 통해 파라미터 효율적이고 플러그 앤 플레이 방식으로 작동하는 미세 조정(fine-tuning) 방법을 제공합니다.

- **Performance Highlights**: 실험 결과, SGOOL은 이미지 품질 및 프롬프트 정렬(prompt alignment)에서 우수함을 입증하였으며, 특히 두드러진 부분을 강조하여 최적화를 수행함으로써 생성된 이미지의 세부 사항이 개선되었습니다.



### Automated extraction of 4D aircraft trajectories from video recordings (https://arxiv.org/abs/2410.10249)
Comments:
          in French language, CFPT-RFIAP 2018, SFPT (Société Française de Photogrammétrie et de Télédétection); RFIAP (Reconnaissance des Formes, Image, Apprentissage et Perception), Jun 2018, Champs sur Marne - Marne la Vallée, France

- **What's New**: 이 연구는 민간 항공 사사사고를 분석하는 과정에서 4D 궤적 추출을 자동화하는 것을 목표로 하고 있습니다. 과거에는 수작업으로 이루어졌던 비디오 분석을 자동화함으로써 효율성을 높이고자 합니다.

- **Technical Details**: 연구는 IGN의 MicMac 소프트웨어를 기반으로 한 포토그램메트리 (photogrammetry) 알고리즘을 개발하고, 다양한 비행 구성 (flight configurations)을 고려하여 현장에서 테스트하고 있습니다.

- **Performance Highlights**: 자동화된 프로세스의 결과는 비행 데이터 기록 장치 (FDRs, CVRs)에서 누락된 정보를 대체하여, 3차원 위치, 시간 구성 요소 및 항공기의 세 축의 방향 (pitch, roll, yaw navigation angles)과 평균 속도를 포함한 중요한 정보를 제공하는 것을 목표로 하고 있습니다.



### LOBG:Less Overfitting for Better Generalization in Vision-Language Mod (https://arxiv.org/abs/2410.10247)
- **What's New**: 기존의 Vision-Language Models(VLM)에서 사용되는 프롬프트 학습 기법들이 과적합(overfitting)으로 인해 일반화 능력에서 큰 저하를 겪고 있어, 이에 대한 해결책으로 LOBG 프레임워크를 제안합니다.

- **Technical Details**: LOBG 프레임워크는 CLIP을 사용하여 과적합을 유발할 수 있는 세밀한 전경 정보(fine-grained foreground information)를 필터링하고, 구조적 토폴로지 보존(STP) 손실 기능을 통해 최적화 과정에서 특성 공간(feature space)의 탄력성을 높입니다. 또한, 출력 수준에서 위계적 로짓 증류(hierarchical logit distillation)를 적용해 출력을 제어하며 STP를 보완합니다.

- **Performance Highlights**: 실험 결과, LOBG는 기존의 최첨단 기법들에 비해 일반화 능력을 크게 향상시켰으며, 새로운 클래스에 대해 2.82%의 성능 향상을 달성했습니다. 11개의 벤치마크 데이터셋에 대한 실험에서 기존의 CLIP과 비교하여 현저히 낮은 과적합을 보여줍니다.



### Capture Artifacts via Progressive Disentangling and Purifying Blended Identities for Deepfake Detection (https://arxiv.org/abs/2410.10244)
Comments:
          TCSVT(Under Review)

- **What's New**: 이 논문은 Deepfake 탐지 기술의 새로운 방법론을 제안하며, 기존의 방식보다 더 신뢰할 수 있는 disentanglement(분리) 기법을 발전시킨다.

- **Technical Details**: 제안된 방법은 정교한 artifact(인위물) 생성 메커니즘에 기반하여 coarse-grained(조잡한) 및 fine-grained(정밀한) 전략을 결합하여 fake faces를 분리하는 프로세스를 신뢰성 있게 수행한다. 또한, Identity-Artifact Correlation Compression(정체성-인위물 상관 압축) 모듈을 사용하여 인위물과 정체성 정보 간의 상관성을 줄인다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 기존의 기초 방식에 비해 상당한 성능 향상을 보여주며, DeepfakeBench 검증에서 최근의 경쟁 탐지기보다 뛰어난 성능을 달성하였다.



### ForgeryGPT: Multimodal Large Language Model For Explainable Image Forgery Detection and Localization (https://arxiv.org/abs/2410.10238)
Comments:
          16 pages, 14 figures

- **What's New**: 이번 논문에서는 ForgeryGPT라는 새로운 프레임워크를 제시하여 이미지 위조 감지 및 위치 지정(Image Forgery Detection and Localization, IFDL) 작업의 발전을 도모합니다. 기존 IFDL 방법의 한계를 극복하고, 다양한 언어적 특징 공간에서 고차원 포렌식 지식 상관관계를 포착하며, 설명 가능한 생성 및 상호작용 가능한 대화를 허용합니다.

- **Technical Details**: ForgeryGPT는 다음과 같은 세 가지 주요 구성 요소로 이루어져 있습니다: 이미지 인코더, 맞춤형 Mask-Aware Forgery Extractor 및 대형 언어 모델. Mask-Aware Forgery Extractor는 Forgery Localization Expert(FL-Expert)와 Mask Encoder로 구성되어 있으며, 세밀한 위조 정보를 픽셀 단위로 이해하는 데 중점을 둡니다. 이를 통해 모델은 단순한 위조 확률 점수와 경계값에 의존하지 않고 자동으로 위조를 탐지합니다.

- **Performance Highlights**: ForgedGPT는 성능 실험에서 GPT-4o 및 현재의 최첨단 IFDL 방법을 초월하는 성과를 보였으며, 높은 정확도 외에도, 정량적 분석을 통해 신뢰할 수 있는 설명을 제공함으로써 해석 가능성과 신뢰성을 강화했습니다.



### LADMIM: Logical Anomaly Detection with Masked Image Modeling in Discrete Latent Spac (https://arxiv.org/abs/2410.10234)
Comments:
          Under Review

- **What's New**: 이번 연구에서는 Masked Image Modeling (MIM)을 활용하여 논리적 이상(anomalies)을 효과적으로 탐지하는 새로운 방법인 LAViT를 제안하였습니다. 이 모델은 마스킹된 이미지의 잠재 변수의 확률 분포를 예측하여 복원 이미지의 흐림 문제를 해결합니다.

- **Technical Details**: LAViT는 self-supervised ViT 모델을 통해 정상 이미지의 특징 간 관계를 학습합니다. 기존의 MIM 기술을 활용하여 마스킹된 부분의 픽셀 예측을 잠재 변수의 확률 분포 예측으로 대체하며, 이는 시각적 특징의 조합을 나타내고 위치의 불확실성을 해결하는 데 기여합니다.

- **Performance Highlights**: MVTecLOCO 데이터셋에서 평균 AUC 0.867을 달성하였으며, 이는 전통적인 복원 기반 및 증류 기반 방법을 초월한 성능을 나타냅니다.



### KNN Transformer with Pyramid Prompts for Few-Shot Learning (https://arxiv.org/abs/2410.10227)
Comments:
          10 pages, 5 figures, accepted by ACM Multimedia 2024

- **What's New**: 이번 연구에서는 K-NN Transformer with Pyramid Prompts (KTPP)라는 새로운 접근법을 제안하여 Few-Shot Learning (FSL) 분야에서 텍스트와 시각적 특징 간의 복잡한 의미적 관계를 효과적으로 캡처합니다. 특히 K-NN Context Attention (KCA)와 Pyramid Cross-modal Prompts (PCP)를 사용하여 시각적 특징을 적응적으로 조정합니다.

- **Technical Details**: KTPP는 두 가지 주요 모듈로 구성됩니다: K-NN Context Attention (KCA)와 Pyramid Cross-modal Prompts (PCP). KCA는 각 토큰에 대해 k개의 관련 토큰만을 선택하여 self-attention 행렬을 계산합니다. 이는 의미 없는 토큰을 제외하고, 모든 토큰의 평균을 컨텍스트 프롬프트로 사용하여 글로벌 컨텍스트를 제공합니다. PCP는 다중 스케일 비주얼 특징과 상호작용하여 잔여 정보를 강조합니다.

- **Performance Highlights**: 제안된 KTPP 모델은 4개의 FSL 벤치마크에서 중요한 성능 향상을 보여주며, 특히 1-shot 정확도가 기존 최첨단 접근법에 비해 1%-4% 증가했습니다. 이는 적은 수의 레이블 샘플을 가진 상황에서 모델의 안정성을 강화하고 노이즈 없는 시각 표현을 더욱 향상시킵니다.



### Detecting Unforeseen Data Properties with Diffusion Autoencoder Embeddings using Spine MRI data (https://arxiv.org/abs/2410.10220)
Comments:
          This paper was accepted in the "Workshop on Interpretability of Machine Intelligence in Medical Image Computing" (iMIMIC) at MICCAI 2024

- **What's New**: 이 연구에서는 의료 이미징에서 발생할 수 있는 데이터 편향을 탐구하기 위해 Diffusion Autoencoder (DAE) 임베딩을 활용하였습니다. 특히 성별과 같은 보호 변수를 포함한 데이터 특성과 편향을 이해하는 데 집중했습니다.

- **Technical Details**: 연구는 11,186명의 NAKO 참가자로부터 얻은 경추, 흉부 및 요추의 T2 가중 자기 공명 이미지(MR images)를 사용했습니다. DAE 임베딩을 기존 생성 모델과 비교하고, t-SNE 시각화를 통해 이미징 프로토콜의 불필요한 변형을 식별했습니다. DAE 임베딩은 성별과 나이와 같은 보호 변수를 효과적으로 분리했습니다.

- **Performance Highlights**: DAE 임베딩은 StyleGAN 및 β-VAE보다 뛰어난 성능을 발휘했습니다. 특히 unsupervised embedding과 SVM 클러스터링이 ResNet10보다 좋은 결과를 보였으며, DAE의 예측 성능이 전체적으로 높았습니다. 이러한 결과는 의료 이미징 데이터셋의 질을 향상시키고 공정성을 높일 수 있음을 시사합니다.



### MagicEraser: Erasing Any Objects via Semantics-Aware Contro (https://arxiv.org/abs/2410.10207)
Comments:
          Accepted by ECCV 2024

- **What's New**: MagicEraser는 객체 지우기를 위한 새로운 확산 모델 기반 프레임워크로, 사용자 친화적인 접근 방식을 제공합니다. 이 모델은 콘텐츠 초기화와 제어 가능한 생성의 두 단계를 가집니다.

- **Technical Details**: MagicEraser는 두 개의 플러그 앤 플레이 모듈인 prompt tuning 및 semantics-aware attention refocus를 포함하며, 각 모듈은 세밀한 컨트롤을 통해 이미지 생성 과정을 개선합니다. 새로운 데이터 구성 전략도 도입하여 이 작업에 적합한 훈련 데이터를 생성합니다.

- **Performance Highlights**: 실험 결과, MagicEraser는 다양한 시나리오에서 기존 조치들보다 우수한 양적 및 질적 결과를 나타내며, 특히 복잡한 배경의 경우에도 효과적으로 객체를 지우고 원활한 배경을 재생합니다.



### Eliminating the Language Bias for Visual Question Answering with fine-grained Causal Intervention (https://arxiv.org/abs/2410.10184)
- **What's New**: 이번 논문에서는 Visual Question Answering(VQA)에서 텍스트 정보로 인해 발생하는 언어 편향을 줄이기 위한 새로운 causal intervention training 스킴인 CIBi를 제안합니다.

- **Technical Details**: CIBi에서는 언어 편향을 context bias와 keyword bias로 나누고, counterfactual 생성과 contrastive learning을 활용하여 context bias를 제거하고 multi-modal representation을 개선합니다. 특히, 각 VQA 훈련 샘플에 대해 두 개의 대응하는 counterfactual 샘플을 생성하여 학습합니다.

- **Performance Highlights**: 실험 결과, CIBi는 다양한 VQA 모델에 적용 가능하며 경쟁력 있는 성능 향상을 보여주었습니다.



### Identity-Focused Inference and Extraction Attacks on Diffusion Models (https://arxiv.org/abs/2410.10177)
Comments:
          5 figures, 3 tables,12 pages main body content

- **What's New**: 이 논문은 모델 소유자가 훈련 데이터에 포함된 개인의 신원에 대해 책임을 질 수 있도록 하는 혁신적인 아이덴티티 추론 프레임워크를 소개합니다. 이는 전통적인 멤버십 추론 공격을 넘어서 개인의 신원을 중심으로 한 새로운 관점을 제공합니다.

- **Technical Details**: 우리는 Labeled Faces in the Wild (LFW)와 CelebA라는 두 개의 얼굴 이미지 데이터셋에서 포괄적인 평가를 수행했습니다. 제안된 멤버십 추론 공격은 최대 89%의 공격 성공률과 0.91의 AUC-ROC를 달성했으며, 아이덴티티 추론 공격은 LFW에서 훈련된 LDM 모델에서 92%에 도달했습니다.

- **Performance Highlights**: 우리의 방법은 다양한 얼굴 이미지 데이터셋에서의 효과성을 입증하며, 멤버십 및 아이덴티티 추론 성능을 정확도(accuracy), 정밀도(precision), 재현율(recall), AUC-ROC 등 다양한 지표로 평가했습니다. 이 연구는 개인 데이터의 무단 사용을 탐지하고 데이터 소유자의 권리를 강화하는 데 기여하고자 합니다.



### First Creating Backgrounds Then Rendering Texts: A New Paradigm for Visual Text Blending (https://arxiv.org/abs/2410.10168)
Comments:
          Accepted to ECAI2024

- **What's New**: 이번 논문에서는 기존의 시각적 텍스트 생성을 넘어, 텍스트가 없는 배경에 텍스트를 매끄럽게 혼합하는 새로운 시각적 텍스트 블렌딩(paradigm)을 제안합니다. 이를 통해 배경 생성과 텍스트 렌더링을 동시에 수행하여 고품질의 다양한 이미지를 생성하는 것을 목표로 합니다.

- **Technical Details**: 본 연구에서는 고해상도(text-free) 자연 배경 이미지를 생성하기 위한 Background Generator를 개발하였으며, GlyphOnly라는 텍스트 렌더러를 설계하였습니다. GlyphOnly는 Stable Diffusion 프레임워크 위에서 동작하며, 텍스트와 배경을 조건으로 사용하여 렌더링의 정확성과 일관성을 제어합니다. 또한, 소규모 텍스트 렌더링을 위한 적응형 텍스트 블록 탐색 전략을 도입하였습니다.

- **Performance Highlights**: 논문에서 제안된 방법은 Scene Text Detector의 성능을 크게 향상시키는 합성 데이터셋인 SynthGlyph의 생성 및 텍스트 이미지 커스터마이징과 편집과 같은 여러 응용 분야에서 효과를 입증하였습니다.



### X-Fi: A Modality-Invariant Foundation Model for Multimodal Human Sensing (https://arxiv.org/abs/2410.10167)
- **What's New**: 본 논문에서는 다양한 센서를 활용하여 인간 신체 정보를 정확하게 포착하고 해석하는데 기여하는 모달리티 불변(모달리티-invariant) 기초 모델 X-Fi를 제안합니다. X-Fi는 추가적인 훈련 없이 센서 모달리티를 독립적으로 또는 조합적으로 사용할 수 있게 해주며, 변동하는 입력 크기를 수용할 수 있는 transformer 구조를 활용하여 다양한 시나리오에서의 적용 가능성을 높입니다.

- **Technical Details**: X-Fi는 'X-fusion' 메커니즘을 포함하여 멀티모달 통합 과정에서 모달리티 특정 특징을 보존합니다. 이 모델은 모달리티에 따라 변동되는 입력 크기를 지원하며, 각 모달리티에 맞는 특징 추출기를 사용하여 독특한 정보를 캡처합니다. 또한, 크로스 어텐션을 통한 멀티모달 융합을 통해 다양한 센서 모달리티에 대한 효율적인 학습을 가능하게 합니다.

- **Performance Highlights**: X-Fi는 MM-Fi와 XRF55 데이터셋을 기반으로 한 인간 포즈 추정(HPE) 및 인간 행동 인식(HAR) 작업에서 기존 방법들을 초월하여, HPE 작업에서 MPJPE를 24.8% 향상시키고, PA-MPJPE에서 21.4%, HAR 작업에서 2.8%의 성능 개선을 달성했습니다.



### Will the Inclusion of Generated Data Amplify Bias Across Generations in Future Image Classification Models? (https://arxiv.org/abs/2410.10160)
Comments:
          15 pages, 7 figures

- **What's New**: 이 연구는 생성된 데이터가 이미지 분류 작업에서 모델의 바이어스에 미치는 영향을 조사합니다. 특히 소그룹 바이어스(subgroup bias)에 초점을 맞추어, 자기 소모 루프(self-consuming loop)를 통해 생성 모델과 분류 모델이 상호 작용하며 훈련되는 실용적인 시뮬레이션 환경을 개발하였습니다.

- **Technical Details**: 연구에서 색상화된 MNIST(Colorized MNIST), CIFAR-20/100, Hard ImageNet 데이터셋을 사용하여 생성된 데이터의 영향을 실험합니다. 데이터 세대 간의 페어니스 메트릭(fairness metrics) 변화를 분석하며, 데이터 폭발(data explosion) 문제를 해결하기 위해 데이터 스태킹(data stacking) 및 전문가-guided 필터링(expert-guided filtering) 방법을 도입했습니다.

- **Performance Highlights**: 우리는 다양한 페어니스 메트릭을 통해 모델 성능과 바이어스에 대한 영향을 검토하였으며, 생성된 데이터가 모델 바이어스를 악화시킬 수 있는 가능성에 대한 징후를 발견했습니다. 또한, 실험을 통해 생성된 데이터가 다양한 세대에서 모델의 공정성에 미치는 영향을 명확히 파악할 수 있었습니다.



### Fast and Accurate Neural Rendering Using Semi-Gradients (https://arxiv.org/abs/2410.10149)
- **What's New**: 이번 논문에서는 전역 조명 렌더링을 위한 간단하지만 효과적인 신경망 기반 프레임워크를 제안합니다. 최근의 연구들은 렌더링 방정식의 왼쪽과 오른쪽 측면 간의 차이를 최소화함으로써 신경 방사 캐시(neural radiance caches)를 학습하는 기술을 제안해왔습니다. 이러한 방법은 구현이 용이하며 경로 적분(calculation) 과정이 필요 없다는 장점으로 인해 다양한 분야에 활용되고 있습니다. 하지만 느린 학습 속도와 때때로 어두운 렌더링 결과라는 문제점이 지적되었습니다.

- **Technical Details**: 이 논문에서는 기존의 잔차 기반의 목표 함수에서 발생하는 경량화된 바이어스(bias)와 높은 분산(variance) 문제를 해결하기 위해 새로운 목적 함수를 도입합니다. 이 새로운 함수는 기존의 전역 최적(global optimum)은 그대로 유지하면서도 편향이 없는 저분산의 그래디언트(gradient) 추정을 가능하게 하여 신경망의 빠르고 정확한 훈련을 지원합니다. 이 방법은 오른쪽 측면의 부분 도함수를 무시하여 간단하게 구현할 수 있으며, 이론적 및 실험적 분석을 통해 그 효과가 입증되었습니다.

- **Performance Highlights**: 본 연구의 결과는 동일한 훈련 반복에서 기존 방법과 비교했을 때, 평균적으로 참조 값에 대한 오류가 8.8배 감소하고 훈련 시간이 25-30% 단축되는 것을 보여주었습니다. 이 방법은 렌더링 잔차를 사용하는 훈련 과정에서 발생하는 그래디언트의 바이어스를 줄여주며, 이는 렌더링 결과의 정확성을 향상시키는 데 기여합니다.



### Hi-Mamba: Hierarchical Mamba for Efficient Image Super-Resolution (https://arxiv.org/abs/2410.10140)
- **What's New**: 이번 연구에서는 이미지 슈퍼 해상도(SR)를 위한 새로운 계층형 Mamba 네트워크인 Hi-Mamba를 제안합니다. 기존의 State Space Models (SSM)에서는 이미지의 공간 의존성을 보완하기 위해 여러 방향에서 데이터를 스캔해야 했으나, Hi-Mamba는 단일 방향 스캔만으로도 효율성을 개선합니다.

- **Technical Details**: Hi-Mamba는 두 가지 주요 설계로 구성됩니다: (1) 지역 SSM(Local SSM)과 지역 SSM(Region SSM)으로 이루어진 계층형 Mamba 블록(HMB)은 멀티 스케일 표현을 집계하여 컨텍스트 모델링 능력을 향상시킵니다. (2) 방향 교대 계층형 Mamba 그룹(DA-HMG)은 동일한 단일 방향 스캔을 계층화된 HMB에 배분하여 공간 관계 모델링을 풍부하게 합니다.

- **Performance Highlights**: Hi-Mamba는 다섯 개의 벤치마크 데이터세트에서 높은 효율성과 성능을 보여줍니다. 예를 들어, Manga109 데이터셋에서 x3 슈퍼 해상도 작업 시 Hi-Mamba는 MambaIR에 비해 PSNR이 0.29 dB 향상된 성능을 기록했습니다.



### MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models (https://arxiv.org/abs/2410.10139)
- **What's New**: 본 논문에서는 대규모 지식 집중형 벤치마크 MMIE를 소개합니다. 이는 대형 비전-언어 모델(LVLMs)의 교차 멀티모달 이해 및 생성을 평가하기 위한 새로운 평가 기준을 제공합니다.

- **Technical Details**: MMIE는 20K의 정교하게 구성된 다중 모달 질문으로 이루어져 있으며, 3개 카테고리, 12개 분야 및 102개 세부 분야를 포함합니다. 다양한 형식의 질문(객관식 및 주관식)을 통해 여러 분야에 걸친 역량을 평가할 수 있습니다.

- **Performance Highlights**: 최고의 LVLM 모델조차도 평균적으로 65.47%의 점수를 달성하여 개선 여지가 많음을 나타냅니다. MMIE는 LVLM의 개발에 의미 있는 진전을 촉진할 것으로 기대됩니다.



### TextCtrl: Diffusion-based Scene Text Editing with Prior Guidance Contro (https://arxiv.org/abs/2410.10133)
- **What's New**: TextCtrl은 텍스트를 편집하는 혁신적인 방법으로, 스타일과 구조의 안내를 통합하여 씬 텍스트 편집(Scene Text Editing, STE)의 성능을 향상시킵니다. 이 방법은 두 가지 주요 컴포넌트로 구성되어 있습니다: (i) 고품질 텍스트 스타일 및 세그먼트 구분과 견고한 텍스트 글리프 구조 표현을 통해, Style-Structure 안내를 모델 설계에 통합합니다. (ii) Glyph-adaptive Mutual Self-attention 메커니즘을 제안하여 스타일 일관성과 시각 품질을 향상시킵니다.

- **Technical Details**: TextCtrl은 조건부 합성 방식으로 STE 프로세스를 정의하며, 텍스트 스타일 분리와 텍스트 글리프 표현을 주 요소로 합니다. 고급 분리된 텍스트 스타일 특성은 시각적 일관성을 보장하고, 견고한 글리프 구조 표현은 텍스트 렌더링의 정확성을 향상시킵니다. 또한, 상호 자가 주의 메커니즘을 도입하여 소스 이미지 스타일을 포함하여 시각적 불일치를 제거합니다.

- **Performance Highlights**: 실험결과 TextCtrl은 스타일 일관성과 텍스트 정확성 모두에서 이전 방법들과 비교하여 뛰어난 효과를 보였습니다. 추가로, 실제 세상 평가 기준을欠缺한 STE의 문제를 해결하기 위해 ScenePair이라는 새로운 데이터셋을 제안함으로써, 실질적인 비교와 평가를 가능하게 했습니다.



### MuseTalk: Real-Time High Quality Lip Synchronization with Latent Space Inpainting (https://arxiv.org/abs/2410.10122)
Comments:
          15 pages, 4 figures

- **What's New**: 본 논문에서는 MuseTalk라는 새로운 프레임워크를 제안하며, 이는 고해상도(High-resolution), 신원 일관성(Identity consistency), 정확한 입술-음성 동기화(Lip-speech synchronization)를 실시간으로 처리할 수 있게 해준다. MuseTalk는 Variational Autoencoder에 의해 인코딩된 잠재 공간(Latent space)에서 입술 동기화 목표를 생성하여 고충실도의 얼굴 비디오 생성이 가능하다.

- **Technical Details**: MuseTalk는 occluded lower half of the face image와 같은 입력 데이터와 같은 개인의 참조 얼굴 이미지를 입력으로 받고, 함께 제공된 오디오 트랙을 바탕으로 입술이 오디오와 원활하게 동기화된 얼굴 이미지를 생성한다. 이 과정에서 U-Net 구조를 사용하고, Selective Information Sampling (SIS) 기법을 도입하여 참조 이미지를 선택하여 모델이 세밀한 입술 움직임에 집중할 수 있도록 한다. Adaptive Audio Modulation (AAM)을 통해 lip-sync loss 메커니즘을 분석하여 lip-sync 정확도를 향상시킨다.

- **Performance Highlights**: MuseTalk는 30 FPS 이상의 프레임 레이트로 256x256 해상도에서 얼굴을 실시간으로 생성할 수 있으며, 실험 결과는 기존의 최신 기술에 비해 시각적 품질과 입술 동기화 정확도에서 일관되게 우수한 성능을 보여준다.



### Interaction-Guided Two-Branch Image Dehazing Network (https://arxiv.org/abs/2410.10121)
Comments:
          Accepted by ACCV 2024

- **What's New**: 이번 논문에서는 CNN(Convolutional Neural Networks)과 Transformer를 결합한 새로운 듀얼-브랜치 이미지 디헤이징(image dehazing) 프레임워크를 제안합니다. 이 프레임워크는 두 모델의 상호작용을 활용하여 지역과 전역 특성을 동시에 효과적으로 추출합니다.

- **Technical Details**: 제안된 방법은 Transformer의 전역 정보 회복 능력을 활용하여 CNN이 지역 세부정보에 초점을 맞추도록 안내합니다. 이 과정에서 down-sampling을 사용하여 중복된 특성 생성을 최소화하고, 두 모델의 상호보완적인 장점을 극대화하여 고품질 디헤이징 결과를 제공합니다.

- **Performance Highlights**: 광범위한 실험을 통해 제안된 방법이 합성 및 실제 데이터셋에서 기존 방법들보다 우수한 품질의 결과를 도출함을 입증하였습니다. 각 모듈의 효과성 또한 ablation 실험을 통해 확인되었습니다.



### StegaINR4MIH: steganography by implicit neural representation for multi-image hiding (https://arxiv.org/abs/2410.10117)
Comments:
          46pages,14figures

- **What's New**: StegaINR4MIH라는 새로운 암호화 프레임워크를 제안하여, 단일의 암시적 표현(implicit representation) 기능 내에서 여러 비밀 이미지를 효과적으로 숨길 수 있습니다.

- **Technical Details**: 기존의 다중 인코더를 사용하는 방법과 달리, StegaINR4MIH는 암시적 표현 기능의 매개변수 중 중복성을 활용하여 고용량의 다중 이미지 숨기기를 달성합니다. 이는 가중치 선택 및 비밀 가중치 대체 방식을 적용하여 구현됩니다.

- **Performance Highlights**: 실험 결과, 두 개의 비밀 이미지를 숨길 때 PSNR(peak signal-to-noise ratio) 값이 42를 초과하며, 다섯 개의 비밀 이미지를 숨길 경우에도 39를 초과하는 성능을 보여주었습니다.



### Can We Predict Performance of Large Models across Vision-Language Tasks? (https://arxiv.org/abs/2410.10112)
Comments:
          Under Review. Project page: this https URL

- **What's New**: 본 연구에서는 관측된 성능 점수를 기반으로 대형 비전-언어 모델(LVLM)의 미지 성능 점수를 예측하는 새로운 프레임워크를 제안합니다. 이는 모델 및 작업에서 관측된 점수를 활용하여 불필요한 평가를 줄이고 비용을 절감하는 방법을 모색합니다.

- **Technical Details**: 우리는 성능 예측을 매트릭스 완성 문제로 공식화하고, 희소한 성능 매트릭스 $oldsymbol{R}$을 생성합니다. 각각의 항목 $R_{mn}$은 모델 $m$의 데이터셋 $n$에 대한 성능 점수를 나타냅니다. Markov chain Monte Carlo (MCMC)와 확률적 매트릭스 분해(Probabilistic Matrix Factorization, PMF)를 적용하여 미지 점수를 예측합니다. 또한, MCMC를 기반으로 성능 예측의 불확실성을 추정합니다.

- **Performance Highlights**: 실험 결과, 우리는 108개의 LVLM을 36개의 벤치마크에서 가져온 176개의 데이터셋에 대해 체계적으로 평가하였으며, PMF가 미지 점수를 정확하게 예측할 수 있음을 보여주었습니다. 높은 불확실성을 가진 모델-데이터셋 쌍을 선택하여 평가할 경우 예측 오류를 상당히 줄일 수 있음을 확인하였습니다.



### High-Precision Dichotomous Image Segmentation via Probing Diffusion Capacity (https://arxiv.org/abs/2410.10105)
Comments:
          13 pages

- **What's New**: 고해상도 이미지 분할의 새로운 접근 방법인 DiffDIS를 제안합니다. 이는 사전 학습된 U-Net을 활용한 확산 기반 모델로, 세밀한 객체 분할을 위해 최적화되었습니다.

- **Technical Details**: DiffDIS는 Variational Autoencoder (VAE) 기반의 맵핑 기법을 사용하여 고해상도 이미지를 효과적으로 처리합니다. 또한, 일회성 노이즈 제거를 통해 DPM의 유연한 일반화 기능을 활용하여 빠른 추론 속도를 자랑합니다.

- **Performance Highlights**: DiffDIS는 DIS5K 데이터셋에서 최첨단 성능을 기록하며, 정확도와 신속한 처리 속도를 동시에 만족하여 기존 방법보다 훨씬 빠른 추론 속도를 제공합니다.



### Innovative Deep Learning Techniques for Obstacle Recognition: A Comparative Study of Modern Detection Algorithms (https://arxiv.org/abs/2410.10096)
- **What's New**: 이 연구는 YOLO 모델(특히 YOLOv8, YOLOv7, YOLOv6, YOLOv5)을 활용한 장애물 탐지에 대한 포괄적인 접근 방식을 탐구합니다.

- **Technical Details**: 딥러닝(Deep Learning) 기법을 활용하여, 각 YOLO 모델의 실시간 탐지(real-time detection) 성능을 비교합니다. 이 과정에서 여러 훈련 프로세스(training processes), 알고리즘 원리(algorithmic principles), 그리고 다양한 실험 결과가 제시됩니다.

- **Performance Highlights**: 결과적으로, YOLOv8 모델이 향상된 정밀도-재현율(precision-recall) 지표와 함께 가장 높은 정확도를 달성함을 보여주었습니다.



### Out-of-Bounding-Box Triggers: A Stealthy Approach to Cheat Object Detectors (https://arxiv.org/abs/2410.10091)
Comments:
          ECCV 2024

- **What's New**: 최근 심층 신경망(DNN)에 기반한 객체 탐지 시스템의 적대적 강건성(adversarial robustness) 연구가 중요한 분야로 부각되고 있습니다. 기존의 전통적인 공격 방식은 객체 탐지기를 겨냥하여 직접적으로 객체의 표면을 조작하는 방법이었습니다. 본 논문에서는 이러한 문제를 해결하기 위해 외곽 경계 상자(bounding boxes) 밖에서 작동하는 미세한 적대적 트리거를 제안합니다.

- **Technical Details**: 본 연구에서는 객체를 탐지할 수 없게 만드는 미세한 적대적 트리거를 도입하며, 이 방법을 Feature Guidance (FG) 기법과 Universal Auto-PGD (UAPGD) 최적화 전략을 통해 개선하였습니다. FG 기법은 트리거 생성을 보다 정교하고 효과적으로 만드는 데 도움을 줍니다.

- **Performance Highlights**: 우리는 이 방법의 효과를 광범위한 실험을 통해 검증하였으며, 디지털 및 물리적 환경 모두에서 높은 성능을 입증하였습니다. 논문에 대한 코드는 제공될 예정입니다.



### PointNet with KAN versus PointNet with MLP for 3D Classification and Segmentation of Point Sets (https://arxiv.org/abs/2410.10084)
- **What's New**: 이번 논문에서는 3D 포인트 클라우드(3D point cloud) 분류 및 분할 작업을 위한 새로운 신경망인 PointNet-KAN을 소개합니다. PointNet-KAN은 전통적인 Multilayer Perceptrons (MLPs) 대신 Kolmogorov-Arnold Networks (KANs)를 사용하며, PointNet의 핵심 원칙을 유지하면서 공유 KAN 레이어(shared KAN layers)를 사용하고 대칭 함수(symmetric functions)를 적용해 전역 특징(global feature)을 추출합니다.

- **Technical Details**: PointNet-KAN은 Jacobi 다항식을 이용해 KAN 레이어를 구성합니다. KAN의 주요 목표는 고정된 활성화 함수(activation functions)로 가중치와 편향(weights and biases)을 훈련하는 전통적인 MLPs와 달리, 활성화 함수 자체를 훈련하는 것입니다. PointNet-KAN은 다양한 다항식 차수와 특수 유형의 다항식(Lagrange, Chebyshev, Gegenbauer polynomials)을 평가했습니다. 또한, KAN을 PointNet에 통합할 때 입력 순열에 대해 불변성을 유지하는 두 가지 요소를 보존합니다.

- **Performance Highlights**: PointNet-KAN은 3D 객체 분류 및 분할의 벤치마크 데이터셋에서 MLP를 사용하는 PointNet과 경쟁력 있는 성능을 보여주었습니다. 이를 통해 PointNet-KAN은 얕고 단순한 네트워크 구조에도 불구하고 효과적인 성능을 발휘하는 것을 입증했습니다. 우리는 이 연구가 KAN을 더 발전된 포인트 클라우드 처리 아키텍처로 통합하는 데 기준이 되고 방향을 제공하기를 바랍니다.



### Learning to Customize Text-to-Image Diffusion In Diverse Contex (https://arxiv.org/abs/2410.10058)
- **What's New**: 본 연구에서는 기존의 개인 개념 이미지 세트를 사용하는 텍스트-이미지 커스터마이징(customization) 기술의 한계를 극복하기 위해, 텍스트 공간(textual space) 내에서 개인 개념의 맥락을 다양화하는 접근 방식을 제안합니다.

- **Technical Details**: 우리는 텍스트 프롬프트(prompts)의 맥락적으로 풍부한 세트를 생성하고, 이를 통해 효과적으로 개인 개념을 표현하는 방법을 탐구했습니다. 이러한 접근법은 기존의 self-supervised learning objective를 사용하여 텍스트 공간 내에서의 의미적 정렬(semantic alignment)을 향상시킵니다.

- **Performance Highlights**: 이 간단하고 비용 효율적인 방법은 생성된 이미지에서 프롬프트 충실도(prompt fidelity)를 향상시키며, 기존의 텍스트-이미지 커스터마이징 방법들과 높은 호환성을 보여줍니다. 우리는 네 가지 다른 베이스라인(method)과 결합하여 CLIP 점수(score)를 크게 개선하는 성과를 입증했습니다.



### DINTR: Tracking via Diffusion-based Interpolation (https://arxiv.org/abs/2410.10053)
Comments:
          Accepted at NeurIPS 2024

- **What's New**: 이 논문에서는 확산 모델(diffusion model)을 활용하여 객체 추적 작업을 새로운 패러다임인 Tracking-by-Diffusion으로 변형하고 제안합니다. 이를 통해 시각적 반복 잠재 변수(visual iterative latent variables)를 기반으로 하는 새로운 추적 프레임워크를 구현합니다.

- **Technical Details**: Diffusion-based INterpolation TrackeR (DINTR)라는 알고리즘을 개발하였으며, 이는 확산 과정을 통해 시간적 동Correspondences를 내재적으로 모델링하고, 가우시안 노이즈 도메인에 대한 불필요한 매핑을 줄이기 위해 효율적인 보간(interpolation) 메커니즘을 사용합니다. 이 과정은 기존의 이미지 처리 기술에서 영감을 얻어 더욱 해석 가능하고 안정적이며 빠른 접근 방식을 제공합니다.

- **Performance Highlights**: DINTR는 5개의 서로 다른 지표 표현을 기반으로 한 7개의 벤치마크에서 우수한 성능을 발휘하며, 기존의 추적 패러다임보다 더 넓은 응용 가능성을 보여줍니다. 이 연구는 기존의 기반 기술과 비교하여 두 배 더 빠른(2×) 프로세스를 구현합니다.



### ChangeMinds: Multi-task Framework for Detecting and Describing Changes in Remote Sensing (https://arxiv.org/abs/2410.10047)
- **What's New**: ChangeMinds는 변화 탐지(Change Detection, CD)와 변화 캡셔닝(Change Captioning, CC) 작업을 통합하여 동시에 최적화하는 새로운 멀티태스킹 프레임워크입니다. 이는 단일 end-to-end 모델 안에서 두 가지 작업을 처리할 수 있도록 합니다.

- **Technical Details**: ChangeMinds는 Swin Transformer 기반의 Siamese encoder와 Change-aware Long Short-Term Memory (ChangeLSTM) 모듈, 멀티태스킹 예측기로 구성되어 있습니다. ChangeLSTM은 복잡한 시공간 역학을 효과적으로 포착하며, 이웃하는 비시계열 특성들로부터 보편적인 변화 인식 표현을 생성합니다.

- **Performance Highlights**: LEVIR-MCI 데이터셋 및 기타 벤치마크에서 ChangeMinds는 멀티태스킹 학습 설정으로 기존 방법보다 우수한 성능을 보여주며, 개별 CD 및 CC 작업에서도 현저한 성능 향상을 기록하였습니다.



### GALA: Geometry-Aware Local Adaptive Grids for Detailed 3D Generation (https://arxiv.org/abs/2410.10037)
- **What's New**: GALA는 복잡한 기하학과 표면 세부사항을 효과적으로 포착하고 재현할 수 있는 새로운 3D 형태 표현 방법입니다. 이 방법은 계산 효율성이 뛰어나며, 현대적인 diffusion 기반 방식의 3D 생성 모델링에 적합합니다.

- **Technical Details**: GALA의 핵심 아이디어는 3D 볼륨 내의 표면의 전역적인 희소성을 활용하고 국소 표면 속성에 적응하는 것입니다. 이를 위해 객체 경계에 나무 뿌리 voxel의 집합을 사용합니다. 각 voxel은 octree를 포함하여 저장소와 계산을 표면이 있는 영역으로 제한합니다. 각 비어있지 않은 리프 노드에 맞는 지역적이고 기하학을 인식하는 좌표 프레임을 적합화하여 국소 격자의 방향과 축의 비등방적 스케일을 조정하여 세부 사항을 저장할 수 있도록 합니다.

- **Performance Highlights**: GALA는 Nvidia A100 GPU에서 각각의 watertight 입력 메시의 적합화에 약 10초가 소요되는 매우 최적화된 C++/CUDA 구현을 자랑합니다. GALA의 계층적 octree 구조 덕분에 보다 효율적이고 품질이 향상된 실제적인 3D 생성 파이프라인을 개발할 수 있습니다.



### TULIP: Token-length Upgraded CLIP (https://arxiv.org/abs/2410.10034)
- **What's New**: TULIP 모델은 CLIP와 유사한 비전-언어 모델의 컨텍스트 길이를 확장할 수 있는 일반화된 방법을 제안하여, 상대 위치 인코딩을 도입함으로써 77 토큰 이상의 긴 캡션 처리를 가능하게 합니다.

- **Technical Details**: TULIP은 두 단계의 적응 절차를 통해 CLIP 모델의 기존의 절대 위치 인코딩을 상대 위치 인코딩으로 변환합니다. 첫 번째 단계에서는 원래의 CLIP 텍스트 인코더에서 상대 위치 인코딩으로 지식을 증류하고, 두 번째 단계에서는 긴 캡션과 이미지를 정렬하기 위해 모델을 향상시킵니다.

- **Performance Highlights**: TULIP 모델은 77 토큰을 초과하는 긴 캡션을 효과적으로 인코딩하여, 기존의 고정적인 토큰 윈도우를 사용하는 베이스라인 모델들보다 이미지-텍스트 검색 및 텍스트 이미지 생성과 같은 크로스 모달 작업에서 향상된 성능을 보여줍니다.



### NARAIM: Native Aspect Ratio Autoregressive Image Models (https://arxiv.org/abs/2410.10012)
Comments:
          Accepted to NeurIPS, see this https URL

- **What's New**: 이번 연구에서는 NARAIM(Native Aspect Ratio Autoregressive Image Models)이라는 비전 모델을 제안합니다. 이 모델은 이미지의 본래 종횡비(aspect ratio)를 유지하며 자율 회귀 방식으로 사전 학습됩니다. 이를 통해 시각적 정보의 해석 능력을 향상시키고, 다운스트림 분류 작업에서 성능을 개선할 수 있음을 보여줍니다.

- **Technical Details**: NARAIM은 이미지 패치를 처리하기 위해 비전 트랜스포머(ViT)를 사용하며, 일반 AIM과는 달리 이미지를 사각형 형태로 강제하지 않고 본래의 종횡비를 유지합니다. 입력 이미지를 비율을 유지하면서 조정한 후, 좌측 상단에서 크롭하여 그로부터 패치를 생성하고, 이 패치들은 자율 회귀 모델을 통해 현재 패치를 예측하는 방식으로 활용됩니다. 포지셔널 임베딩(positional embeddings)에서는 절대 값과 분수 형태를 실험하여, 분수 포지셔널 임베딩이 더 나은 일반화를 경험함을 확인하였습니다.

- **Performance Highlights**: NARAIM을 사용하는 실험 결과, 본래의 종횡비를 유지했을 때 다운스트림 분류 작업에서 기존 AIM 모델보다 뛰어난 성능을 기록하였습니다. 무작위 크롭을 통해 정규화 효과를 유지하면서, 정보 왜곡 없이 원본 이미지를 최대한 활용할 수 있음을 입증하였습니다.



### InterMask: 3D Human Interaction Generation via Collaborative Masked Modelling (https://arxiv.org/abs/2410.10010)
Comments:
          Project webpage: this https URL

- **What's New**: 새로운 프레임워크 InterMask는 두 사람 간의 상호 작용을 효율적으로 생성하기 위해 협업 마스크 모델링을 사용하는 혁신을 소개합니다. 이 방법은 기존의 diffusion 모델들이 생성한 비자연적인 결과와는 달리, 사실적이고 다양한 상호작용을 구현합니다.

- **Technical Details**: InterMask는 두 가지 단계로 구성됩니다. 첫 번째 단계에서는 VQ-VAE를 사용하여 각 개인의 동작을 2D 이산 토큰 맵으로 변환합니다. 이는 전통적인 1D VQ 토큰 맵과 달리, 정밀한 시공간(spatio-temporal) 세부정보를 보존하며, 각 토큰 내에서 공간 인식을 촉진합니다. 두 번째 단계에서는 Inter-M Transformer 아키텍처를 사용하여 마스킹된 토큰의 조합을 학습하고, 두 인물 간의 복잡한 관계를 모델링합니다.

- **Performance Highlights**: InterMask는 InterHuman 데이터셋에서 5.15의 FID를 달성했으며, 이는 이전 메서드인 in2IN의 5.54보다 우수한 결과입니다. 또한, InterX 데이터셋에서도 0.399의 FID를 기록하여 InterGen의 5.207과 비교하여 뛰어난 성능을 보여줍니다. 이 프레임워크는 재작업 없이도 반응 생성 작업을 지원합니다.



### SlimSeiz: Efficient Channel-Adaptive Seizure Prediction Using a Mamba-Enhanced Network (https://arxiv.org/abs/2410.09998)
Comments:
          5 pages, 3 figures

- **What's New**: 본 논문은 SlimSeiz 프레임워크를 소개하여, 적응형 채널 선택 방법과 경량화된 신경망 모델을 활용하여 발작 예측의 효율성을 높이고자 하였습니다. 이 방법은 기존의 EEG 채널 수를 22개에서 8개로 줄이면서도 94.8%의 정확도를 유지합니다.

- **Technical Details**: SlimSeiz는 두 가지 주요 단계로 구성됩니다. 첫 번째 단계는 머신러닝 알고리즘을 통해 최적의 채널 집합을 선택하는 것이고, 두 번째 단계는 합성곱 신경망(convolutional neural network)과 Mamba 블록을 기반으로 한 경량화된 신경망 모델을 이용하여 발작을 예측하는 것입니다. 이 모델은 21.2K의 모델 파라미터로 작동합니다.

- **Performance Highlights**: CHB-MIT EEG 데이터셋에서 SlimSeiz는 94.8%의 정확도, 95.5%의 민감도(sensitivity) 및 94.0%의 특이도(specificity)를 달성하였으며, 새로운 SRH-LEI EEG 데이터셋에서도 92.7%의 정확도, 94.7%의 민감도 및 90.7%의 특이도를 기록하였습니다.



### Facial Width-to-Height Ratio Does Not Predict Self-Reported Behavioral Tendencies (https://arxiv.org/abs/2410.09979)
Comments:
          Psychological Science (2017)

- **What's New**: 이번 연구는 137,163명의 대규모 샘플을 통해 얼굴 폭-높이 비율(fWHR)과 행동 경향 사이의 관계를 재검토하였습니다.

- **Technical Details**: 행동 경향은 55개의 잘 확립된 심리측정 척도를 사용하여 측정하였으며, 포함된 항목으로는 지능, 오성 모델(five-factor model) 성격의 영역 및 세부 항목, 충동성, 공정성 감각, 감각적 관심, 자기 모니터링, 인상 관리, 삶의 만족도 등이 있습니다.

- **Performance Highlights**: 연구 결과, fWHR와 이러한 자가 보고된 행동 경향 사이에는 실질적인 연관성이 없음을 보여주었으며, 이는 과거 연구에서의 소규모 샘플 및 특정 실험 환경 외부에서 fWHR과 행동 간의 관계가 일반화될 수 있는지를 의문시하게 만들었습니다.



### Optimizing Waste Management with Advanced Object Detection for Garbage Classification (https://arxiv.org/abs/2410.09975)
Comments:
          8 pages, 8 figures

- **What's New**: 이 연구는 AI 기반 시스템과 YOLO V5(Object Detection을 통한 물체 인식) 모델을 사용하여 쓰레기를 효과적으로 분류하는 방법에 대해 다룹니다. 현재 쓰레기 문제에 대한 전통적인 접근 방식의 한계를 극복하고, 더욱 자동화된 솔루션을 통해 효율적인 쓰레기 관리가 가능할 것으로 보입니다.

- **Technical Details**: YOLO V5 모델은 객체 인식에서 빠른 속도와 높은 정확도로 잘 알려져 있으며, 여러 스케일에서 기능 융합을 향상시키는 PANet(Path Aggregation Network)를 포함한 구조입니다. 본 연구는 Roboflow에서 제공하는 Garbage Classification 데이터셋을 사용하여 모델을 훈련하고, 100개의 이미지를 촬영하여 실제 환경에서의 쓰레기 분류 성능을 평가하였습니다.

- **Performance Highlights**: 훈련된 모델은 검증 데이터에서 적절한 성능을 보여주었으며, 총 100회의 에포크(epochs) 동안 학습하였습니다. 모델이 가장 많이 분류한 쓰레기는 생분해성(spooled) 쓰레기였으며, 여러 이미지에서 배경 물체와의 혼잡한 관계로 인해 오분류가 발생하였습니다. 다양한 환경에서 촬영된 이미지들로 인해 별도의 쓰레기 종류별로 트렌드가 확인되었습니다.



### Improving 3D Few-Shot Segmentation with Inference-Time Pseudo-Labeling (https://arxiv.org/abs/2410.09967)
- **What's New**: 이번 연구에서는 few-shot segmentation (FSS) 방법에서 쿼리 데이터의 잠재력을 최대한 활용하여 의료 이미징의 세분화 정확도를 향상시키는 새로운 전략을 제안합니다. 기존 방법들이 쿼리 자체의 정보를 충분히 활용하지 못한 점을 고려하여, 쿼리를 라벨이 없는 데이터로 취급해 예측 정확도를 향상시킬 기회를 제공합니다. 특히, 의료 이미징에서 쿼리의 볼륨 구조는 세분화 개선을 위한 소중한 정보원을 제공합니다.

- **Technical Details**: 제안된 방법은 초기 세분화 점수를 생성하는 프로토타입 접근 방식과 쿼리 슬라이스에서 가장 정보가 많은 부분을 지원 집합으로 전이하는 신뢰도 인식 의사 라벨링 절차를 포함합니다. 이를 통해 확대된 지원 집합을 이용해 더욱 정확한 세분화 마스크를 예측하게 됩니다. 이 방법은 쿼리 데이터와 지원 데이터 간의 통합적 활용을 통해 세분화 성능을 효율적으로 향상시키는 것을 목표로 합니다.

- **Performance Highlights**: 광범위한 실험을 통해 제안된 방법이 다양한 환경과 데이터셋에 걸쳐 성능을 효과적으로 향상시킬 수 있음을 입증했습니다. 제안된 접근 방식은 의료 이미지 세분화 분야에서 데이터 희소성을 극복할 수 있는 잠재력을 보여줍니다.



### LongHalQA: Long-Context Hallucination Evaluation for MultiModal Large Language Models (https://arxiv.org/abs/2410.09962)
- **What's New**: 본 논문에서는 LongHalQA라는 LLM-free hallucination benchmark를 소개합니다. LongHalQA는 6,485개의 긴 맥락의 질의를 포함하고 있으며, 이는 기존의 간단한 질문 기반 평가 방식과는 다르게 더 복잡하고 다양한 현실 시나리오에 적용될 수 있도록 설계되었습니다.

- **Technical Details**: LongHalQA는 hallucination discrimination과 hallucination completion의 두 가지 새로운 과제를 도입하여, 다단계 선택형 질문(MCQ) 형태로 MLLMs의 hallucination 이해 및 생성 성향을 동시에 평가합니다. 또한, LongHallGen이라는 자동화된 파이프라인을 제안하여 긴 맥락의 hallucination 데이터를 생성하고, 이를 기반으로 MCQ 형태로 전환하는 기능을 제공합니다.

- **Performance Highlights**: 다양한 최신 MLLM들에 대한 광범위한 실험 결과, MLLMs가 긴 텍스트에서 hallucination을 인식하고 설명하는 데 한계를 보임을 확인했습니다. Chain-Of-Thought(COT) 방식을 사용했을 때, 짧은 질의에서는 효과적이나, 긴 맥락의 hallucination discrimination에서는 오히려 성능 저하가 발생하는 것을 관찰했습니다.



### EITNet: An IoT-Enhanced Framework for Real-Time Basketball Action Recognition (https://arxiv.org/abs/2410.09954)
Comments:
          pages

- **What's New**: 이번 연구는 IoT 기술을 통합한 EITNet 모델을 제안하여 농구 선수의 행동 인식을 향상시키고, 선수 퍼포먼스와 게임 전략에 대한 중요한 통찰을 제공하는 데 초점을 맞추고 있습니다. 기존 방법들의 정확성과 효율성이 부족한 문제를 해결하고자, 객관적 데이터 수집 및 처리 방식을 최적화하는 새로운 접근 방식을 제시합니다.

- **Technical Details**: EITNet 모델은 EfficientDet(객체 탐지), I3D(공간-시간 특징 추출), TimeSformer(시간 분석) 등 다양한 딥 러닝 프레임워크를 결합하여 실시간 데이터 수집과 처리를 수행합니다. 이 구조는 92%의 인식 정확도를 달성했으며, EfficientDet 모델의 87%를 초과하고 손실을 50 에포크(epochs) 동안 9.0에서 5.0으로 감소시킵니다.

- **Performance Highlights**: EITNet는 복잡하고 고속의 선수 동작 인식에서 높은 강인성과 정확성을 보였으며, 기존 단일 뷰 영상 분석 방법과 비교했을 때, 동작 인식의 정확성과 데이터 완전성을 significantly 향상시켰음을 입증했습니다. 또한, 실시간 피드백 기제를 통해 코치와 선수에게 보다 체계적이고 효과적인 훈련 지침을 제공하여 운동 능력 향상에 기여합니다.



### The Roles of Contextual Semantic Relevance Metrics in Human Visual Processing (https://arxiv.org/abs/2410.09921)
- **What's New**: 이 연구는 맥락적 의미 연관성(contextual semantic relevance) 척도를 도입하여 인간의 시각적 인지 및 처리 과정을 조사합니다. 또한 상태-최첨단(deep learning) 기술을 활용하여 이러한 척도와 주의 집중(fixation measures) 간의 관계를 분석합니다.

- **Technical Details**: 이 연구에서는 시각적 및 언어 기반 관점에서 대상 객체와 주변 환경 간의 의미적 관계를 평가합니다. 사람의 시각적 처리에 대한 영향을 분석하기 위해 고급 통계 모델을 사용하여 대규모 안구 추적 데이터셋을 테스트합니다. 이 연구는 언어 기반과 시각 기반 척도를 통합한 새로운 결합(metric) 척도를 제시하며, 이는 이전 연구의 한계를 해결하는 데 기여합니다.

- **Performance Highlights**: 결과적으로, 모든 척도가 시각적 인식 및 처리에서 고정 측정치를 정확하게 예측할 수 있었지만 각기 다른 역할을 가지고 있습니다. 결합된 척도가 다른 척도보다 더 뛰어난 성능을 보였으며, 이는 시각적 인식 및 처리에서 의미적 정보와 시각적 정보 간의 상호 작용을 강조하는 이론을 뒷받침합니다.



### Stratified Domain Adaptation: A Progressive Self-Training Approach for Scene Text Recognition (https://arxiv.org/abs/2410.09913)
Comments:
          15 pages, 12 figures, 5 tables, include supplementary materials

- **What's New**: 이 논문에서는 Scene Text Recognition (STR)에서 Unsupervised Domain Adaptation (UDA) 문제를 해결하기 위한 Stratified Domain Adaptation (StrDA) 접근 방식을 제안합니다. 이 방법은 소스 도메인과 타겟 도메인 사이의 간극을 점진적으로 축소하며, 효과적인 학습을 위해 학습 데이터를 여러 하위 집합으로 나누는 것을 목표로 합니다.

- **Technical Details**: StrDA는 주어진 타겟 도메인에서 데이터 샘플의 소스 도메인과의 근접성을 평가하여 데이터를 층화(stratify)합니다. Harmonic Domain Gap Estimator (HDGE)를 통해 각 데이터 포인트의 out-of-distribution (OOD) 수준을 측정하고, 두 개의 판별기를 사용하여 OOD 수준을 기반으로 데이터의 간격을 추정합니다. 이를 통해 도메인 간의 극단적인 차이에 효과적으로 적응할 수 있도록 지원합니다.

- **Performance Highlights**: 여섯 개의 기준 데이터셋(IIIT, SVT, IC13, IC15, SVTP, CUTE) 및 다섯 개의 추가 데이터셋(COCO, Uber, ArT, ReCTS, Union14M)을 통한 광범위한 실험 결과, 제안된 StrDA 접근 방식이 기존의 STR 모델들에 비해 성능을 크게 향상시킨다는 것을 보였습니다. 이는 고품질의 의사 레이블(pseudo-labels)을 활용하여 라벨이 제한된 실제 데이터의 수집 비용을 절감할 수 있는 가능성을 열어줍니다.



### Combining Generative and Geometry Priors for Wide-Angle Portrait Correction (https://arxiv.org/abs/2410.09911)
Comments:
          European Conference on Computer Vision (ECCV) 2024

- **What's New**: 이번 연구는 와이드 앵글 렌즈 왜곡을 보정하기 위해 생성적 얼굴 사전(generative face prior)을 활용하는 새로운 프레임워크를 제안합니다. 특히, 얼굴 영역과 배경의 왜곡을 동시에 처리하는 접근을 통해 자연스러운 결과를 도출합니다.

- **Technical Details**: 제안된 방법은 두 개의 모듈로 구성됩니다: FaceCNet은 얼굴 왜곡을, LineCNet은 배경에서의 직선 왜곡을 처리합니다. FaceCNet은 사전 훈련된 StyleGAN에서 생성적 얼굴 구조 사전을 사용하여 얼굴 수정을 향상시킵니다. LineCNet은 배경의 중심 대칭 관계를 활용하여 기하학적 정규화(symmetric regularization)를 적용합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법이 기존 기법보다 뛰어난 시각적 품질과 정량적 성능을 보여주며, 왜곡 없는 자연스러운 이미지를 생성하는 데 성공했습니다.



### UnSeg: One Universal Unlearnable Example Generator is Enough against All Image Segmentation (https://arxiv.org/abs/2410.09909)
Comments:
          NeurIPS 2024

- **What's New**: 본 논문에서는 이미지 분할을 위한 새로운 접근 방식인 Unlearnable Segmentation (UnSeg) 프레임워크를 제안합니다. 이 프레임워크는 원래 이미지에 사용되지 않는 노이즈를 생성하여 훈련 과정에서 모델이 이미지를 학습하지 못하도록 합니다. UnSeg는 Segment Anything Model (SAM)을 기반으로 하여 오프라인에서 훈련된 노이즈 생성기를 미세 조정합니다.

- **Technical Details**: UnSeg는 두 단계의 최적화(bilevel optimization) 구조로 이루어져 있으며, 기존의 SAM 모델을 활용하여 보편적인 Unlearnable Noise 생성기를 훈련합니다. 이는 소규모 상호작용(segmentation) 데이터셋을 통해 수행되며, 다양한 이미지와 상세한 요소를 포함한 더 복잡한 비전 작업에 효과적으로 적용됩니다. 또한, UnSeg는 객체 영역을 보호하기 위해 마스크 프롬프트(label information)만을 요구합니다.

- **Performance Highlights**: UnSeg 프레임워크는 6개의 이미지 분할 작업, 10개의 널리 사용되는 데이터셋, 7개의 서로 다른 네트워크 아키텍처에서 우수한 효과를 보였으며, COCO 인스턴스 분할 작업에서 92%의 성능 저하를 초래하는 결과를 확인했습니다. 이는 이미지 분할 모델에 대한 방어적인 접근 방식을 제공함으로써, 개인 데이터 보호를 위한 중요한 통찰력을 제공합니다.



### Multi class activity classification in videos using Motion History Image generation (https://arxiv.org/abs/2410.09902)
Comments:
          5 pages, 9 images

- **What's New**: 본 논문에서는 Motion History Image (MHI)를 활용한 인간 행동 인식에 대해 다루고 있으며, 특히 다중 행동 비디오에서 효과적으로 행동을 분류하는 방안을 제시합니다.

- **Technical Details**: MHI는 시간에 따른 동작을 표현하는 방법으로, 최근의 동작을 더 밝은 픽셀로 나타내며, 이를 바탕으로 Hu Moments를 사용하여 동작 인식의 통계적 특성을 추출합니다. K-Nearest Neighbors (KNN) 및 Multi-layer Perceptron (MLP) 분류기를 사용해 다양한 동작을 분류하였으며, 각 알고리즘의 성능을 비교 분석하였습니다.

- **Performance Highlights**: 실험 결과, MLP가 KNN에 비해 더 높은 정확도를 기록하였으며, 훈련된 MLP 분류기는 여러 행동을 성공적으로 인식했습니다. 그러나 일부 경우에서 그림자의 간섭 및 시간 창 길이의 variance로 인해 정확도가 저하되는 사례도 발견되었습니다.



### Large-Scale 3D Medical Image Pre-training with Geometric Context Priors (https://arxiv.org/abs/2410.09890)
Comments:
          CVPR 2024 Extension

- **What's New**: 의료 이미지 분석에서의 주석(annotation) 부족 문제를 해결하기 위한 새로운 접근 방식인 Volume Contrast (VoCo) 프레임워크를 소개합니다. 이 방법은 기하학적 컨텍스트 정보(priors)를 활용하여 주석 없이도 고수준의 의미를 학습할 수 있게 합니다. 특히, 3D 의료 이미지의 일관된 기하학적 관계를 이용함으로써 의미 있는 표현을 학습합니다.

- **Technical Details**: Volume Contrast (VoCo) 프레임워크는 입력 볼륨으로부터 다양한 지역에서 기본 크롭(base crops)을 추출하여 긍정적 및 부정적 쌍을 구성하고, 무작위 크롭의 맥락적 위치를 예측하여 대조 학습(contrastive learning)을 수행합니다. 이 과정에서 모델 표현에 내재된 기하학적 컨텍스트를 인코딩하고, 주석 없이도 고수준의 의미 학습을 가능하게 합니다.

- **Performance Highlights**: VoCo는 대규모 의료 사전 학습 데이터셋인 PreCT-160K를 도입하고, 다양한 의료 작업에 맞춰 모델 크기를 조정하기 위한 가이드라인을 제안하며, 48개의 의료 작업을 포함하는 벤치마크를 구축했습니다. 실험 결과 VoCo의 우수성이 입증되었습니다.



### Block-to-Scene Pre-training for Point Cloud Hybrid-Domain Masked Autoencoders (https://arxiv.org/abs/2410.09886)
- **What's New**: 본 논문에서는 general Point cloud Hybrid-Domain Masked AutoEncoder (PointHDMAE)를 제안합니다. 이는 block-to-scene pre-training 전략을 통해 다양한 도메인의 포인트 클라우드를 처리할 수 있는 모델입니다.

- **Technical Details**: PointHDMAE는 scene domain과 object domain 각각에 특화된 encoder와 decoder로 구성되며, object domain encoder는 객체 포인트 클라우드를 처리하고, 여러 개의 공유 객체 encoder는 scene domain encoder가 장면 포인트 클라우드를 분석하는 데 도움을 줍니다. block-to-scene 전략으로 모델을 미리 훈련시키면서 masked points 복구와 scene-level block position regression을 결합하여 동시에 강력한 객체 및 장면 표현을 학습합니다.

- **Performance Highlights**: 다양한 데이터셋과 작업에서의 광범위한 실험 결과, PointHDMAE는 기존의 도메인 특정 MAE 모델보다 월등한 일반화 능력과 성능을 보여주었습니다. 이 모델은 추가적인 도메인 적응 훈련 없이도 직접 다운스트림 작업에 조정할 수 있습니다.



### Occluded Human Pose Estimation based on Limb Joint Augmentation (https://arxiv.org/abs/2410.09885)
Comments:
          Accept by NCAA

- **What's New**: 이 논문에서는 occluded human pose estimation을 위한 새롭고 혁신적인 프레임워크를 소개합니다. 이 프레임워크는 limb joint augmentation을 기반으로 하여 occlusion(가림) 상황에서 pose estimation 모델의 일반화 능력을 향상시키는 데 중점을 둡니다.

- **Technical Details**: 이 연구는 훈련 이미지의 limb joints(관절)를 무작위로 가리는 occlusion blocks(가림 블록)을 사용하여, 객체나 다른 사람에 의해 부분적으로 가려진 인간의 몸을 모방합니다. 이를 통해 augmentation(증강)된 샘플로 학습을 진행하며, Dynamic Structure Loss(DSL) 함수를 구성하여 adjacent joints(인접 관절) 간의 의존성을 평가함으로써 모델의 로컬라이제이션 능력을 향상시킵니다.

- **Performance Highlights**: 논문의 실험 결과는 OCHuman과 CrowdPose 두 개의 occluded datasets에서 수행되었으며, 제안된 방법이 inference(추론) 중 추가적인 계산 비용을 발생시키지 않으면서도 성능을 크게 개선하는 것을 보여주었습니다.



### Improving Colorectal Cancer Screening and Risk Assessment through Predictive Modeling on Medical Images and Records (https://arxiv.org/abs/2410.09880)
- **What's New**: 이 연구는 대장 내시경 (colonoscopy) 검사에서 대장 용종 (polyp)을 발견하고 제거하는 것 외에도, 기계 학습을 활용하여 CRC (대장암) 위험 예측을 개선하는 방법에 대한 새로운 접근을 제시합니다.

- **Technical Details**: 연구진은 5년 CRC 위험 예측을 위한 병리 이미지 분석에 transformer 기반 모델을 적용하였으며, 다양한 멀티모달 융합 기술을 조사하여 의료 기록 정보와 deep learning에서 유도된 위험 추정치를 결합하였습니다. 이를 통해, 중간 임상 변수를 예측하기 위해 훈련된 transformer 모델이 5년 CRC 위험 예측 성능을 향상시키는데 기여함을 밝혔습니다.

- **Performance Highlights**: 결과적으로, 5년 CRC 위험 예측에서 AUC (Area Under the Curve)는 0.630을 기록하였으며, 이미징과 비이미징 기능을 융합한 접근 방식이 대장 내시경 절차와 병리학적 소견에서 추출된 변수들을 초월하는 예측 능력을 보였습니다.



### TextMaster: Universal Controllable Text Ed (https://arxiv.org/abs/2410.09879)
- **What's New**: 본 연구에서는 TextMaster라는 텍스트 편집 프레임워크를 제안합니다. 기존의 OCR 기반 데이터 의존성을 극복하고, 다양한 텍스트 편집 시나리오에 최적화된 현실감 있는 텍스트 편집을 가능하게 합니다. 이 프레임워크는 텍스트 스타일 주입, 적응형 마스크 부스트 및 향상된 레이아웃 제어 기법을 사용하여 시각적 일관성 및 품질을 높였습니다.

- **Technical Details**: TextMaster는 다음과 같은 혁신적인 기술을 포함합니다: 텍스트 스타일 주입 (Text Style Injection), 적응형 마스크 부스트 (Adaptive Mask Boosting), 개선된 ChatGLM 인코딩 (ChatGLM Encoding), CIOU 손실 (CIOU Loss)을 통한 레이아웃 제어, 그리고 다중 줄 텍스트 편집 기능(Multi-Line Text Editing Capability)을 제공합니다. 이러한 방법들은 각각 텍스트 편집의 스타일, 내용, 레이아웃 및 시각적 품질을 유지하는 데 기여합니다.

- **Performance Highlights**: TextMaster는 기존의 모든 접근 방식을 초월하는 성능을 보여주며, 복잡한 이미지에서 텍스트 편집 작업에서 최첨단 도구로 자리잡고 있습니다. 정량적 및 정성적 평가에 따르면, 본 프레임워크는 텍스트 렌더링의 정확성과 충실도를 현저히 향상시키며, 효과적으로 텍스트 스타일 일관성을 유지합니다.



### ViFi-ReID: A Two-Stream Vision-WiFi Multimodal Approach for Person Re-identification (https://arxiv.org/abs/2410.09875)
- **What's New**: 본 연구는 WiFi 신호와 비디오 데이터의 멀티모달(fusion) 접근 방식을 활용하여 사람 재식별(Person Re-identification, ReID)에 대한 혁신적인 해결책을 제시합니다. 기존의 이미지 기반 방법의 한계를 극복하기 위해, 우리는 일반적인 라우터를 감지 장치로 활용하여 보행 정보(gait)를 추출합니다. 이를 통해 다양한 환경에서도 일관된 ReID 성능을 유지할 수 있습니다.

- **Technical Details**: 우리는 두 가지 스트림 네트워크를 활용하여 비디오 이해(video understanding)와 신호 분석(signal analysis) 작업을 별도로 처리하고, 비디오 데이터와 WiFi 데이터를 결합하여 멀티모달 퓨전을 수행합니다. WiFi 신호는 고정 시간 단위로 인코딩되고 영상 모듈에서는 독립적인 공간 및 시간 인코더를 사용하여 보행 모션 특징을 추출합니다. 크로스 모달(cross-modal) 맵핑을 위해 대비 학습(contrastive learning)과 어려운 예제 마이닝(hard example mining) 기반의 손실 함수를 설계하였습니다.

- **Performance Highlights**: 실제 환경에서 실시된 실험을 통해 제안한 방법이 다양한 센서 간의 상관관계를 효과적으로 발견하고, 시각과 신호 모달리티 간의 격차를 줄이며, 감지 범위를 크게 확장하고 ReID 정확도를 개선함을 입증했습니다. 이로 인해, 다양한 환경(단일 모달 및 멀티모달)에서 사람의 ID를 일관되게 추적할 수 있는 가능성을 제시합니다.



### Training-Free Adaptive Diffusion with Bounded Difference Approximation Strategy (https://arxiv.org/abs/2410.09873)
Comments:
          Accepted by NeurIPS 2024, Homepage: this https URL The code is available at this https URL

- **What's New**: AdaptiveDiffusion은 기존의 단계별 노이즈 예측 방식의 한계를 극복하기 위해 제안된 새로운 접근 방식입니다. 이 방법은 노이즈 예측 단계를 능동적으로 줄여 최종 결과가 원본과 동일한 품질로 유지되도록 합니다.

- **Technical Details**: AdaptiveDiffusion은 timesteps 동안의 안정성을 나타내는 3차 잠재 차이를 기반으로 노이즈 예측 단계를 건너뛰는 전략을 안내합니다. 이 접근 방식은 이전 노이즈 예측 결과를 재사용하고 새로운 계산을 진행할 시점을 결정하는 데 중점을 둡니다.

- **Performance Highlights**: 광범위한 실험 결과, AdaptiveDiffusion은 기존 프로세스와 동일한 품질을 유지하면서 노이즈 제거 프로세스를 최대 5.6배 빠르게 할 수 있음을 보여줍니다. 이는 실시간 및 인터랙티브 환경에서의 Diffusion 모델 응용 가능성을 향상시킵니다.



### Towards Reproducible Learning-based Compression (https://arxiv.org/abs/2410.09872)
Comments:
          Accepted at MMSP 2024

- **What's New**: 이 논문에서는 다양한 제조업체의 장치에서 실행되는 깊이 학습(Deep Learning) 기반 압축 시스템에서의 재현성 문제를 분석합니다. 특정 비트 차이로 인해 발생하는 인코딩 및 디코딩의 불일치가 주된 원인이며, 이러한 불일치는 많은 애플리케이션에서 사용이 어려운 상황을 초래합니다.

- **Technical Details**: 재현성을 보장하기 위해, 모델의 결과가 플랫폼 간에 일관되도록 하는 방법을 제안합니다. 주로 오류(Error) 경계 내에서 일치하도록 보장하고, 이러한 모델을 보호하는 메커니즘을 도입하여 인코더와 디코더 간의 호환성(interoperability)을 향상시킵니다. 실험 결과는 이미지 압축 및 포인트 클라우드 압축과 같은 실제 응용 사례에서 제안된 접근 방식의 유효성을 입증합니다.

- **Performance Highlights**: 제안된 방법은 기존의 학습 기반 압축 시스템에 추가 기능으로 적용이 가능하며, 사전 훈련된 신경망(neural network) 모델에 대한 수정이나 세부 조정 없이 사용할 수 있습니다. 또한, 손실 없는 압축 및 손실 압축, 이미지/비디오 및 포인트 클라우드와 같은 다양한 형태의 데이터에 적용 가능한 일반적인 접근 방식을 제공합니다.



### Two-Stage Human Verification using HandCAPTCHA and Anti-Spoofed Finger Biometrics with Feature Selection (https://arxiv.org/abs/2410.09866)
- **What's New**: 이 논문은 공격에 대한 취약성을 극복하고 보안을 강화하기 위해 두 가지 독립적인 단계의 인간 검증 방식을 제시합니다. 첫 번째 단계에서는 손 이미지 기반의 CAPTCHA(HandCAPTCHA)를 통해 다음 생체 인식 단계에 대한 자동화된 봇 공격을 방지합니다.

- **Technical Details**: 다음 단계에서는 무작위 HandCAPTCHA 도전을 통과한 합법적 사용자에 대한 실제 손 이미지를 사용하여 프레젠테이션 공격 탐지(PAD)와 함께 지문 생체 인식 검증을 수행합니다. PAD는 이미지 품질 메트릭스를 사용하여 전자 화면 기반으로 테스트됩니다. 그 후, 실제 사용자 손의 네 개의 손가락(엄지 제외)에서 기하학적 특징을 추출합니다. 생체 인증을 위한 관련 특징을 선택하기 위해 수정된 정방향-역방향(M-FoBa) 알고리즘이 개발되었습니다.

- **Performance Highlights**: BU(보가지치 대학교)와 IIT-Delhi(IITD) 손 데이터베이스에서 k-최근접 이웃(k-nearest neighbor) 및 랜덤 포레스트(random forest) 분류기를 사용하여 실험이 수행되었습니다. HandCAPTCHA의 평균 정확도는 98.5%이며, 봇의 허위 수락 비율은 1.23%입니다. PAD는 BU의 255명의 피험자에 대해 테스트되었으며, 최상의 평균 오류는 0%입니다. BU의 500명의 피험자에 대한 지문 생체 인식 정확도는 98%이며, 동등 오류율(EER)은 6.5%입니다. IITD의 200명의 피험자에 대해서는 99.5%의 식별 정확도와 5.18%의 EER이 달성되었습니다.



### SynFER: Towards Boosting Facial Expression Recognition with Synthetic Data (https://arxiv.org/abs/2410.09865)
- **What's New**: 본 논문은 고급 텍스트 설명을 기반으로 얼굴 표정 이미지를 합성하는 새로운 프레임워크인 SynFER(Synthesis of Facial Expressions with Refined Control)를 소개합니다. 이 프레임워크는 얼굴 행동 단위(facial action units)를 통해 보다 세밀하고 정밀한 제어를 가능하게 하여 얼굴 표정 데이터의 품질과 신뢰성을 높입니다.

- **Technical Details**: SynFER는 생성 과정에서 구동되는 의미적 가이던스 기법과 합성 이미지의 얼굴 표정 레이블을 수정하기 위한 의사 레이블 생성기를 제안합니다. 이 시스템은 FEText라는 얼굴 표정 관련 이미지-텍스트 쌍의 첫 번째 데이터 세트를 포함하고 있으며, 이는 생성 모델 훈련의 기초가 됩니다. 또한, FERAnno라는 새로운 레이블 보정기를 통해 합성 이미지에 대한 신뢰할 수 있는 주석을 자동으로 생성합니다.

- **Performance Highlights**: SynFER로 훈련된 모델은 AffectNet에서 67.23%의 분류 정확도를 달성하고, 데이터 세트를 다섯 배 늘리면 69.84%로 증가합니다. 이 연구는 모노레퍼레딩(mono-referencing) 시나리오에서 Synthesized data가 실제 데이터보다 나은 성능을 보이는 것을 입증하는 여러 실험을 수행했습니다.



### AuthFace: Towards Authentic Blind Face Restoration with Face-oriented Generative Diffusion Prior (https://arxiv.org/abs/2410.09864)
Comments:
          Codes and datasets will be available at this https URL

- **What's New**: 본 논문은 AuthFace라는 새로운 프레임워크를 제안하여 페이스 이미지를 더욱 현실감 있게 복원하는 방법을 제시합니다. 이 방법은 얼굴 중심의 생성적 확산 사전(generative diffusion prior)을 탐구하여 고품질 이미지를 복원하는 데 초점을 맞추고 있습니다.

- **Technical Details**: AuthFace 프레임워크는 두 단계의 훈련 파이프라인으로 구성되어 있습니다: 1) 사전 훈련된 T2I 모델에 대한 얼굴 중심의 미세 조정과 2) 매우 현실감 있는 얼굴 복원입니다. 이를 위해 1.5K 고해상도 이미지를 수집하고, 세밀한 사진 가이드 주석을 통해 모델을 미세 조정하여 얼굴 세부정보를 효과적으로 복원할 수 있도록 합니다.

- **Performance Highlights**: 광범위한 실험을 통해 AuthFace는 합성 및 실제 BFR 데이터셋에서 뛰어난 얼굴 세부사항 복원 성능을 보여주었으며, 특히 눈과 입과 같은 중요한 얼굴 영역의 아티팩트를 줄이는 데 성공했습니다.



### Point Cloud Novelty Detection Based on Latent Representations of a General Feature Extractor (https://arxiv.org/abs/2410.09861)
- **What's New**: 이번 연구에서는 일반적인 포인트 클라우드(feature extractor) 기능 추출기를 활용한 비지도 3D 포인트 클라우드 이상 탐지 방식을 제안합니다. 이 방법은 정상 및 비정상 카테고리에 구분되지 않은 데이터에 대해 한 번만 훈련되는 그래프 기반의 오토인코더(autoencoder)와 일급 분류기(one-class classifier)를 포함합니다.

- **Technical Details**: 제안된 프레임워크는 일반 포인트 클라우드 특징 추출기와 일급 분류기로 구성됩니다. 일반 특징 추출기는 훈련된 오토인코더를 사용하여 포인트 클라우드 데이터를 잠재 벡터(latent vectors)로 변환합니다. 이후 One-Class Support Vector Machine (OC-SVM)과 Kernel PCA 기반의 이상 탐지를 통해 이러한 잠재 벡터에 대한 일급 분류를 수행합니다.

- **Performance Highlights**: ShapeNet 데이터셋의 여러 서브셋에서 실험을 통해 제안된 방법의 성능을 검증했으며, 기존 방법에 비해 상당한 향상을 보였습니다. 특히, 우리의 잠재 기반 접근법은 고도화된 포인트 클라우드 이상 탐지를 가능하게 합니다.



### Human Identification using Selected Features from Finger Geometric Profiles (https://arxiv.org/abs/2410.09856)
- **What's New**: 이 논문에서는 제약이 없는 환경에서의 손가락 생체 인식 시스템을 제안합니다. 손 이미지 정규화 기술을 통해 손 윤곽을 손가락 수준의 형태로 분해하는 기법이 적용되었습니다.

- **Technical Details**: 전처리 단계에서 변환된 이진 이미지를 기존의 이진 손 윤곽 이미지에서 뺴는 과정을 통해 손가락 프로필의 왼쪽 부분(LSFP) 이미지를 생성합니다. 이후 LSFP 이미지와 손 윤곽 이미지를 XOR 연산을 통해 손가락 프로필의 오른쪽 부분(RSFP)을 생성합니다. 이후 30개의 기하학적 특징이 모든 정규화된 손가락에서 계산되며, 랭크 기반의 전방 및 후방 탐욕 알고리즘이 사용되어 관련 특징들을 선택하여 분류 정확도를 높입니다.

- **Performance Highlights**: Bosphorus 손 데이터베이스를 사용한 두 가지 실험에서, 각각 9개와 12개의 식별 가능한 특징을 포함하는 두 개의 특징 서브셋이 선택되었습니다. 엄지 손가락을 제외한 네 개의 손가락에서 선택된 특징을 사용한 실험은 기존 방법들과 비교하여 향상된 성능을 보여주었습니다. 오른손과 왼손 이미지에 대한 RF 분류기를 사용하여 96.56%와 95.92%의 최상의 식별 정확도를 달성하였으며, 두 가지 유형의 손 이미지에 대해 0.078의 동등 오차율을 기록하였습니다.



### Text4Seg: Reimagining Image Segmentation as Text Generation (https://arxiv.org/abs/2410.09855)
Comments:
          Code is available at this https URL

- **What's New**: 이번 논문에서는 이미지 분할을 텍스트 생성 문제로 설정하는 혁신적인 텍스트-마스크(text-as-mask) 패러다임인 Text4Seg를 소개합니다. 이 접근 방식은 추가적인 디코더 없이 이전보다 간소화된 분할 프로세스를 가능하게 하며, 의미론적 기술자(semantic descriptors)를 이용해 이미지 패치를 해당 텍스트 레이블에 맞춰 매핑하여 통합 표현을 제공합니다.

- **Technical Details**: Text4Seg에서는 각 이미지 패치를 대비점(tangible)을 텍스트 설명으로 변환하는 새로운 기술을 도입합니다. 16×16의 의미론적 기술자로 이미지를 표현하며, 이를 통해 효율적인 최적화 및 MLLMs(auto-regressive training pipeline)와의 통합이 가능합니다. 또한, Row-wise Run-Length Encoding (R-RLE)을 사용하여 중복된 텍스트 시퀀스를 압축하여 효율성을 향상시킵니다.

- **Performance Highlights**: 다양한 비전 작업을 대상으로 한 실험에서 Text4Seg는 여러 데이터셋에서 최신 성능(state-of-the-art performance)을 달성하였고, LLaVA-1.5, Qwen-VL 등의 기존 MLLM 아키텍처에 간편하게 통합되어 성능을 극대화하였습니다.



### Understanding Robustness of Parameter-Efficient Tuning for Image Classification (https://arxiv.org/abs/2410.09845)
Comments:
          5 pages, 2 figures. Work in Progress

- **What's New**: 본 논문은 Parameter-Efficient Tuning (PET) 기법의 강인성을 체계적으로 분석합니다. 특히, VPT, Adapter, AdaptFormer, LoRA와 같은 고전적인 PET 기법이 화이트 박스 공격과 정보 왜곡 공격에 대해 어떻게 반응하는지를 다룹니다.

- **Technical Details**: 본 연구에서는 FGSM(Fast Gradient Sign Method)과 PGD(Projected Gradient Descent)라는 두 가지 공격 방법을 사용하여 PET 기법의 강인성을 평가하였습니다. 정보 왜곡 공격의 경우, Patch-wise Drop, Pixel-wise Drop, Patch Shuffle, Gaussian Noise와 같은 4가지 방법을 도입하여 수행하였습니다.

- **Performance Highlights**: 연구 결과, PET 기법들은 전통적인 수조정(Linear Probing) 방식에 비해 상대적으로 낮은 강인성을 보였으며, VPT와 LoRA가 PET 기법 중에서 상대적으로 좋은 성능을 보였습니다. 특히, LoRA는 다양한 출처의 적대적 샘플에 대해 가장 높은 강인성 정확도를 보였습니다.



### Fusion Based Hand Geometry Recognition Using Dempster-Shafer Theory (https://arxiv.org/abs/2410.09842)
- **What's New**: 이 논문은 포즈 제한 없이 두 손의 기하학적 특징(geometric features)을 융합(fusion)하여 개인 인식을 위한 새로운 기술을 제시합니다.

- **Technical Details**: 모든 특징은 정규화된(normalized) 왼손과 오른손 이미지에서 추출됩니다. 특징 레벨(feature level)과 결정 레벨(decision level) 모두에서 융합이 적용됩니다. 분류(classification)을 위한 두 가지 확률 기반 알고리즘(probability based algorithms)이 제안되었습니다. 첫 번째 알고리즘은 최근접 이웃(nearest neighbors) 세 개의 최대 확률(maximum probability)을 계산합니다. 두 번째 알고리즘은 거리(distance)에 대한 임계값(thresholding)과 관련된 매칭된 특징의 최대 확률을 결정합니다.

- **Performance Highlights**: 최종 결정은 증거(Evidence)의 덴프스터-셰이퍼 이론(Dempster-Shafer theory)으로 계산된 가장 높은 확률에 따라 고려됩니다. 201명의 피험자를 대상으로 식별 및 검증을 위한 세 가지 스킴(schemes)이 실험되었으며, 올바른 식별률(correct identification rate)은 99.5%로 나타났고, 검증 과정에서 잘못된 수용률(False Acceptance Rate, FAR)은 0.625%로 확인되었습니다.



### Towards Defining an Efficient and Expandable File Format for AI-Generated Contents (https://arxiv.org/abs/2410.09834)
- **What's New**: 최근 AI 생성 콘텐츠(AIGC)가 강력한 생성 능력으로 주목받고 있습니다. 하지만 고품질 AIGC 이미지를 저장하고 전송하는 데 기존 파일 포맷이 도전 과제가 되고 있습니다. 이를 해결하기 위해 AIGC 이미지를 위한 새로운 파일 포맷인 AIGIF를 정의하였습니다.

- **Technical Details**: AIGIF는 텍스트 프롬프트, 디바이스 설정 등 생성 구문 요소를 압축하여 AIGC 이미지를 유사 해상도로 저장할 수 있는 ultra-low bitrate 코딩 방식입니다. AIGIF는 사용자가 정의한 데이터 구성에 따라 이미지 생성을 지원하며, 잘 설계된 구성 가능한 비트스트림 구조를 통해 최대 1/10,000의 압축 비율을 달성할 수 있습니다.

- **Performance Highlights**: AIGIF는 실험적으로 AIGC 이미지의 압축률을 최대 1/10,000까지 도달할 수 있으며, 여전히 높은 충실성을 유지합니다. 이는 기존 이미지 파일 포맷의 한계를 뛰어넘는 것이며, 향후 발전할 생성 모델의 확장을 지원하는 확장 가능한 구문을 제공합니다.



### LoLI-Street: Benchmarking Low-Light Image Enhancement and Beyond (https://arxiv.org/abs/2410.09831)
Comments:
          Accepted by the Asian Conference on Computer Vision (ACCV 2024)

- **What's New**: 이번 논문에서는 LoLI-Street라는 새로운 데이터셋을 소개합니다. 이 데이터셋은 33,000개의 쌍의 저조도(low-light) 및 잘 노출된(well-exposed) 이미지로 구성되어 있으며, 이는 자율 주행 시스템에서 요구되는 LLIE(low-light image enhancement) 연구에 필수적입니다.

- **Technical Details**: LoLI-Street 데이터셋은 30,000개의 훈련용 이미지, 3,000개의 검증용 이미지, 1,000개의 실시간 저조도 테스트 이미지로 구성되어 있습니다. 제안된 모델인 TriFuse는 삼중융합(transformer and diffusion-based) 모델로, 변환자(transformer)를 사용해 노이즈를 예측하고 샘플링 단계를 감소시킵니다.

- **Performance Highlights**: TriFuse 모델은 LoLI-Street 데이터셋과 기존의 SOTA(state-of-the-art) LLIE 모델 비교에서 LLIE 성능과 객체 탐지 성능에서 뛰어난 결과를 보여주었습니다. 이는 자율 주행과 감시 시스템과 같은 실제 응용에서 효과적인 성과를 의미합니다.



### DAS3D: Dual-modality Anomaly Synthesis for 3D Anomaly Detection (https://arxiv.org/abs/2410.09821)
- **What's New**: 이 논문은 3D 및 RGB 이미지가 포함된 다중 모달리티(anomaly detection)에서의 anomaly 샘플 합성을 위한 새로운 방법을 제안합니다. 기존의 2D anomaly 탐지 방식은 충분히 연구되었으나, 3D anomaly 탐지에 주목한 연구는 드물었습니다. 본 연구에서 제안된 방법은 3D 결함의 특징을 모방할 수 있는 간단하고 효율적인 dual-modality augmentation을 통해 3D anomaly를 생성하는 것입니다.

- **Technical Details**: 제안된 방법은 Depth와 RGB 포맷을 활용하여 anomaly 샘플을 합성하는 Dual-modality Anomaly Synthesis (DAS3D)을 개발했습니다. 이 방법은 3D 표면의 공간적 특성을 고려하며, anomaly 생성 시 두 모달 데이터를 동시에 증강하여 이상 위치에서 잘 정렬된 anomaly 쌍을 만듭니다. 또한, augmentation dropout 메커니즘을 설계하여 dual-modal discriminator의 일반화 가능성을 향상시킵니다. 이 네트워크는 end-to-end 방식으로 훈련되며, 원본 및 재구성된 feature를 통합하여 anomaly segmentation을 수행합니다.

- **Performance Highlights**: 제안된 방법은 MVTec 3D-AD와 Eyescandies 데이터셋에서 지금까지의 최고 성능을 기록했습니다. 특히 이미지 수준에서 AUROC 점수는 각각 0.982 및 0.915에 달하며, 명확한 경계와 적은 잡음을 가진 anomaly 맵을 생성해 localization 정확성에서도 경쟁력을 보였습니다.



### TopOC: Topological Deep Learning for Ovarian and Breast Cancer Diagnosis (https://arxiv.org/abs/2410.09818)
- **What's New**: 최근 딥러닝 방법들이 의학적 진단과 치료 계획을 향상시키는 데 큰 잠재력을 가지고 있으며, 기존의 조직 병리학적 이미지 분석 모델에 토폴로지적(Topological) 딥러닝 방법을 통합하여 정확성과 강건성을 높이는 방안을 제시합니다.

- **Technical Details**: 본 연구에서는 조직 병리학적 이미지에서 토폴로지적 특징을 추출하기 위해 두 가지 머신러닝 모델을 도입합니다. 첫 번째 모델인 TopOC-1은 표준 머신러닝 모델을 사용하여 토폴로지적 벡터를 보다 직관적으로 적용하는 반면, 두 번째 모델인 TopOC-CNN은 이러한 토폴로지적 특징을 기존의 사전 훈련된 모델과 통합하여 성능을 향상시킵니다.

- **Performance Highlights**: 제안된 방법은 난소 및 유방 암의 조직 병리학적 이미지에서 특종을 구별하는 데 있어 기존의 최첨단 모델을 초월하는 성능을 제시하며, 특히 토폴로지적 특징을 포함함으로써 일관된 성능 향상을 관찰했습니다.



### EBDM: Exemplar-guided Image Translation with Brownian-bridge Diffusion Models (https://arxiv.org/abs/2410.09802)
Comments:
          ECCV 2024

- **What's New**: 이 논문은 Exemplar-guided Image Translation with Brownian-Bridge Diffusion Models (EBDM)라는 새로운 접근법을 제안합니다. 이 방법은 구조 제어가 가능한 초기 지점에 고정된 확률적 브라운 다리 프로세스를 기반으로 하여 주어진 스타일 샘플 이미지만을 조건으로 하는 포토리얼리스틱 이미지(photorealistic image) 생성을 가능하게 합니다.

- **Technical Details**: EBDM 방법은 Global Encoder, Exemplar Network, Exemplar Attention Module의 세 가지 주요 구성 요소를 포함하여 샘플 이미지에서 전역 및 세부 질감 정보를 통합합니다. 이 네트워크는 구조 제어를 통해 이미지를 변환하며, 단일 조건으로 스타일 샘플에 대해 독립적으로 작동합니다.

- **Performance Highlights**: 다양한 데이터셋에서 수행된 실험 결과, EBDM 방법이 기존 접근 방식보다 뛰어난 성능과 계산 효율성을 보여주었다고 보고합니다. 통계적 브라운 다리 확산 과정(stochastic Brownian bridge diffusion process)을 활용한 이 방법은 이미지 번역 작업에서 이전의 문제들을 효과적으로 해결했습니다.



### Task Adaptive Feature Distribution Based Network for Few-shot Fine-grained Target Classification (https://arxiv.org/abs/2410.09797)
Comments:
          10 pages, 2 figures, conference

- **What's New**: TAFD-Net을 제안하여 metric-based few-shot fine-grained classification의 문제를 해결하고, 작업 수준의 뉘앙스를 캡처합니다.

- **Technical Details**: TAFD-Net는 task-adaptive component, 비대칭 metric, contrastive measure strategy를 포함하여, 쿼리 샘플과 지원 카테고리 간의 feature distribution similarity를 효과적으로 계산합니다.

- **Performance Highlights**: 세 가지 데이터세트에서 수행된 실험 결과, 제안된 알고리즘이 최근의 incremental learning 알고리즘보다 우수한 성능을 보였습니다.



### Intermediate Representations for Enhanced Text-To-Image Generation Using Diffusion Models (https://arxiv.org/abs/2410.09792)
- **What's New**: 본 연구에서는 텍스트-이미지 생성에서의 세분화된 공간 정보의 정확한 반영을 위한 새로운 조합(compositional) 접근법을 제안합니다. 이 방법은 두 단계로 구성되어 있으며, 첫 번째 단계에서는 텍스트에 조건화된 중간 표현을 생성하고, 두 번째 단계에서는 이 표현들을 이용하여 최종 이미지를 생성합니다.

- **Technical Details**: 텍스트 입력에 기반한 중간 표현을 생성하기 위해, 사전 훈련된 Stable-Diffusion 모델을 미세 조정합니다. 생성된 중간 표현은 깊이 맵(depth map), 세그멘테이션 맵(segmentation map), Hough 선(Hough lines) 등을 포함합니다. 이 중간 표현들을 텍스트와 함께 사용하여 ControlNet을 통해 최종 이미지를 생성합니다. 여러 중간 표현을 정렬하는 과정도 포함되어 있습니다.

- **Performance Highlights**: 본 연구의 결과, 제안한 조합 접근법은 FID 점수를 개선하고, CLIP 점수는 유사한 수준으로 나타났습니다. 특히 깊이 맵이나 세그멘테이션 맵을 단독으로 사용할 경우, 기존 비조합 Stable-Diffusion 모델보다 유의미한 성능 향상이 관찰되었습니다.



### DFIMat: Decoupled Flexible Interactive Matting in Multi-Person Scenarios (https://arxiv.org/abs/2410.09788)
Comments:
          Accepted by ACCV 2024

- **What's New**: DFIMat는 상호 작용 포트레이트 매팅(interactive portrait matting) 분야에서 사용자 입력을 통해 최적의 결과를 도출하는 새로운 프레임워크입니다. 이 모델은 기존의 한계점을 극복하기 위해 태스크를 두 개의 하위 태스크로 분리하였고, 다중 모드 사용자 입력을 지원하여 유연한 상호 작용을 가능하게 합니다.

- **Technical Details**: DFIMat는 태스크를 두 개의 하위 문제로 분리하여 처리합니다: (1) 장면 의미(semantics)를 이해하고 유연한 사용자 입력을 바탕으로 목표 인스턴스를 로컬화(localizing)하며, (2) 인스턴스 수준의 매팅(matting) 개정을 수행합니다. 또한, ISCN(Interactive Semantic Capture Network)과 MRN(Matting Refinement Network)이 각각 이 두 태스크를 처리하여 상호 작용의 효율성과 효과성을 높입니다.

- **Performance Highlights**: DFIMat는 40,000개의 고품질 매트(matte) GT가 포함된 대규모 데이터셋 SMPMat에서 SOTA(State-Of-The-Art) 방법보다 3.48 SAD(Spatial Average Deviation) 향상을 보이며, 경량화된 버전인 DFIMat-S는 SOTA 방법의 33%의 파라미터로도 높은 매팅 정확도를 달성합니다.



### ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos (https://arxiv.org/abs/2410.09776)
Comments:
          Accepted in EMNLP 2024, this https URL

- **What's New**: 본 연구는 비디오에서 엔터티 중심의 정보 탐색 질문(ECIS 질문)을 생성하는 새로운 문제 설정을 제안하며, 여기에 맞는 대규모 데이터셋 VideoQuestions를 제시합니다.

- **Technical Details**: 연구에서는 Transformers와 풍부한 맥락 신호(제목, 전사본, 자막, 임베딩) 조합을 통해 ECIS 질문 생성을 위한 모델 구조를 제안합니다. 이 모델은 교차 엔트로피 손실(cross-entropy loss)과 대조 손실(contrastive loss) 함수를 결합하여 훈련되며, 다양한 비디오 자료에서 요구되는 질문 생성을 목표로 합니다.

- **Performance Highlights**: 우리의 최적 방법은 BLEU, ROUGE, CIDEr 및 METEOR 점수에서 각각 71.3, 78.6, 7.31, 81.9의 성과를 기록하여 실용성을 입증하였습니다.



### Magnituder Layers for Implicit Neural Representations in 3D (https://arxiv.org/abs/2410.09771)
- **What's New**: 이 논문에서는 3D에서의 암시적 신경 표현(implicit neural representations)인 Neural Radiance Fields (NeRF)와 Signed Distance Fields (SDF)의 효율성과 성능을 개선하기 위해 새로운 신경망 레이어인 'magnituder'를 소개합니다. 이 레이어는 모델의 표현력(expressive power)을 유지하면서 훈련 파라미터의 수를 줄여 인퍼런스(inference) 속도와 적응성을 향상시킵니다.

- **Technical Details**: magnituder는 피드포워드 레이어(feed-forward layers, FFLs)에 통합되어 처리되는 입력과 가중치를 분리하여 단순한 선형 연산을 통해 연결됩니다. 이 구조는 입력의 크기에만 의존하여 전달하면서 레이어의 훈련 파라미터 수를 줄이면서도 동일한 표현력을 유지합니다. 또한, backpropagation 없이 사전 훈련된 모델과의 제로샷(zero-shot) 통합이 가능해 인퍼런스 속도가 더욱 향상됩니다.

- **Performance Highlights**: 이 방법은 동적인 환경에서 더 효율적인 장면 재구성을 가능하게 하고, 실시간 애플리케이션에서 훈련 및 인퍼런스 속도를 획기적으로 개선합니다. 또한, 기존의 MLP 레이어와의 통합을 통해 통계 지식을 효과적으로 전이할 수 있는 첫 번째 성공적인 응용을 보여주어, 로봇 시스템의 실시간 결정 과정에 필수적인 인퍼런스 속도 최적화가 가능해집니다.



### Compressing Scene Dynamics: A Generative Approach (https://arxiv.org/abs/2410.09768)
Comments:
          Submitted to DCC2025

- **What's New**: 이 논문은 동영상 콘텐츠 대신 동작 패턴에서 생성적 선행 정보(generative priors)를 학습하여 생성적 비디오 압축을 위한 새로운 방법을 제시합니다. 일상적인 장면에서의 작은 동작 동역학을 모델링하여 Ultra-low bit-rate 통신과 다양한 장면 콘텐츠를 위한 고품질 재구성을 가능하게 합니다.

- **Technical Details**: 제안된 Dynamics-Codec 프레임워크는 두 가지 주요 작업으로 구성됩니다. 첫째, 동작 흐름에서 컴팩트한 동작 토큰을 식별하여 정보 압축을 수행합니다. 둘째, 안정적인 디코더를 설계하여 다양한 비디오 콘텐츠를 위한 재구성을 생성합니다. 이 과정에서 Stable Video Diffusion(SVD) 모델을 이용하여 다양한 장면에 대한 일반화를 가능하게 합니다.

- **Performance Highlights**: 실험 결과, 제안된 Dynamics-Codec가 기존의 Versatile Video Coding (VVC) 비디오 코덱보다 우수한 Rate-Distortion 성능을 보였으며, 주관적 품질에서도 우수한 결과를 나타냈습니다.



### Data Adaptive Few-shot Multi Label Segmentation with Foundation Mod (https://arxiv.org/abs/2410.09759)
- **What's New**: 본 논문에서는 의료 이미지의 세그멘테이션 및 로컬라이제이션(세부 영역 식별)을 향상시키기 위해 foundation model (FM) 기반의 어댑터를 제안합니다. 특히, 단일 레이블 및 다중 레이블 세그멘테이션 작업을 통합할 수 있는 방법을 개발하여 임상 데이터에서 여러 포즈에 대한 성능을 평가했습니다.

- **Technical Details**: 제안된 방법은 DINOv2로 미세조정된 foundation model의 sub-image level feature를 활용하여 다중 레이블 로컬라이제이션을 가능하게 합니다. 이를 위해, 대칭적 구조의 contrastive learning 어댑터를 설계하여 픽셀 수준의 feature 벡터들이 유사한지를 자동으로 판단하도록 학습하였으며, 이는 사용자가 수동으로 임계값을 설정할 필요가 없도록 합니다. 또한, 이 방법은 2D 및 3D 데이터 모두에서 성능을 발휘합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법이 기존의 few-shot segmentation 방법들에 비해 다양한 임상 시나리오 및 여러 포즈에서 우수한 세그멘테이션 및 로컬라이제이션 성능을 보이는 것으로 확인되었습니다. 특히, 대칭적 학습 방식이 강인한 feature 매칭을 가능하게 하여 3D 의료 영상에서의 적용 가능성을 입증하였습니다.



### Surgical-LLaVA: Toward Surgical Scenario Understanding via Large Language and Vision Models (https://arxiv.org/abs/2410.09750)
Comments:
          NeurIPS 2024 AIM-FM Workshop

- **What's New**: 이 논문에서는 수술 상황을 위한 특별한 LVLM(large vision-language model)인 Surgical-LLaVA를 소개합니다. 이 모델은 수술 이미지와 비디오의 시각적 표현을 언어 특징 공간에 통합하여 수술 시나리오에 따라 조정된 모델을 만듭니다.

- **Technical Details**: Surgical-LLaVA는 수술관련 데이터에 대한 instruction following을 위해 GPT-3.5를 사용하여 다양한 수술 멀티모달 instruction-following 데이터를 생성한 후, 이러한 데이터로 시각-언어 모델을 미세 조정합니다. 이 모델은 수술 절차의 시공간적(spatiotemporal) 표현을 위해 사전 훈련된 시각 인코더와 LLM의 언어 이해 능력을 결합합니다.

- **Performance Highlights**: Surgical-LLaVA는 수술 관련 시나리오에서 멀티모달 채팅 능력을 능가하며, 이전 방법들과 비교해 보다 복잡한 수술 문제를 해결할 수 있는 잠재력을 보였습니다. 실험 결과, 수술 시나리오에서 시각적 질문-답변(dataset VQA) 데이터셋에 대한 성능이 뛰어난 것으로 나타났습니다.



### EMWaveNet: Physically Explainable Neural Network Based on Microwave Propagation for SAR Target Recognition (https://arxiv.org/abs/2410.09749)
- **What's New**: 본 연구에서는 합성 개구 레이더(SAR) 이미지 인식에서의 투명성을 향상시키기 위해 물리적으로 설명 가능한 프레임워크를 제안합니다.

- **Technical Details**: 이 프레임워크는 복소수(complex-valued) SAR 데이터를 사용하여 파형(amplitude) 및 위상(phase) 정보와 그 물리적 성질을 탐구합니다. 네트워크 아키텍처는 모든 학습 가능한 매개변수에 명확한 물리적 의미가 부여되며, 계산 과정은 전적으로 주파수(domain)에 있습니다.

- **Performance Highlights**: 모델은 0dB 숲 배경 소음에서 전통적인 신경망보다 20% 높은 정확도를 기록했으며, 목표물이 60% 노이즈에 가려져 있어도 다른 모델보다 9% 더 높은 성능을 보였습니다.



### t-READi: Transformer-Powered Robust and Efficient Multimodal Inference for Autonomous Driving (https://arxiv.org/abs/2410.09747)
Comments:
          15 pages, 16 figures

- **What's New**: t-READi는 다양한 모달리티 센서의 변동성을 수용하여 자율 주행에 필요한 견고하고 효율적인 인식을 가능하게 하는 혁신적인 시스템입니다. 특히, 기존의 멀티모달(fusion) 알고리즘의 한계인 센서 오작동이나 환경 조건의 변화를 효과적으로 처리합니다.

- **Technical Details**: t-READi는 데이터 및 모달리티 변동을 처리하기 위한 변동 인식 모델 적응 알고리즘을 이용합니다. 이 시스템은 사전 학습된 모델에서 여러 가지 변형 모델을 생성하여 현재 입력에 따라 가장 적합한 모델을 선택할 수 있게 합니다. 또한, t-READi는 크로스 모달리티 대조 학습 방법을 사용하여 모달리티 손실에 따른 데이터 결손 문제를 보완합니다.

- **Performance Highlights**: t-READi는 기존 방식에 비해 평균 추론 정확도가 6% 이상 향상되었으며, 추론 지연(latency)을 거의 15배 감소시키는 성과를 보였습니다. 메모리 오버헤드는 최악의 경우에도 단지 5% 증가하여, 자율 주행 환경에서 실질적인 이점을 제공합니다.



### MMCOMPOSITION: Revisiting the Compositionality of Pre-trained Vision-Language Models (https://arxiv.org/abs/2410.09733)
Comments:
          21 pages, 15 figures

- **What's New**: 대규모 Vision-Language Models (VLMs)의 compositionality(구성 가능성)에 대한 포괄적인 평가 지표인 MMCOMPOSITION이 제안되었습니다. 기존의 평가 지표들이 객체, 관계 및 속성 측면에서만 대략적인 평가를 제공했던 반면, MMCOMPOSITION은 VLM의 구성 가능성을 13가지 질문 범주로 세분화하여 보다 깊이 있는 분석을 수행합니다.

- **Technical Details**: MMCOMPOSITION은 VLM의 구성 가능성을 VL(compositional perception), reasoning(추론) 및 probing(탐색)이라는 세 가지 차원에서 평가합니다. 이 벤치마크는 4,342개의 질문을 포함하며, 단일 이미지 및 다중 이미지 시나리오에서 구성 정보를 평가합니다. 연구에서는 GPT-4o의 세세한 compositional perception에서의 한계와 VLM 설계 및 학습에서 개선해야 할 영역을 강조하였습니다.

- **Performance Highlights**: MMCOMPOSITION을 활용한 평가에서 가장 높은 모델 정확도가 67.95%에 불과했으며, 이는 인간 성능 90.31%와 큰 차이를 나타냅니다. 이러한 결과는 최신 VLM이 인간의 구성 이해 능력에 현저히 뒤처진다는 것을 보여주며, VLM의 향후 개선을 위한 방향성을 제시합니다.



### LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models (https://arxiv.org/abs/2410.09732)
Comments:
          79 pages, 63 figures

- **What's New**: AI 생성 콘텐츠의 급속한 발전으로 인해, 앞으로의 인터넷은 합성 데이터로 넘쳐날 가능성이 높아지고 있습니다. 이에 따라, 진짜와 신뢰할 수 있는 멀티모달 데이터의 구별이 점점 더 어려워지고 있으며, 합성 데이터 탐지가 큰 주목을 받고 있습니다.

- **Technical Details**: LOKI는 다양한 모달리티에서 합성 데이터를 탐지하는 대형 멀티모달 모델(large multimodal models, LMMs)의 능력을 평가하기 위한 새로운 벤치마크입니다. LOKI는 비디오, 이미지, 3D, 텍스트 및 오디오 모달리티를 포함하여 26개의 하위 카테고리에서 18,000개의 신중하게 큐레이션된 질문들로 구성되어 있으며, 난이도는 명확히 구분되어 있습니다. 이 벤치마크는 조잡한 판단과 다중 선택 질문은 물론, 세부적인 이상 선택 및 설명 작업을 포함하여 LMMs에 대한 종합적인 분석을 가능하게 합니다.

- **Performance Highlights**: 22개의 오픈 소스 LMM과 6개의 폐쇄형 모델을 LOKI에서 평가하여, 합성 데이터 탐지자로서의 잠재력을 강조하며 LMM 능력 개발의 몇 가지 한계도 드러냈습니다.



### Distributed Intelligent Video Surveillance for Early Armed Robbery Detection based on Deep Learning (https://arxiv.org/abs/2410.09731)
Comments:
          Accepted for publication in the proceedings of the 37th Conference on Graphics, Patterns and Images (SIBGRAPI 2024)

- **What's New**: 이 연구에서는 다양한 CCTV (Closed-Circuit Television) 시스템에서 무기 탐지 및 강도 사건을 실시간으로 감지하는 IoT (Internet of Things) 기반의 지능형 보안 시스템을 제안합니다.

- **Technical Details**: 본 시스템은 여러 최종 장치에 컴퓨터 비전 파이프라인과 객체 탐지 기능을 통합하여 총 16,799장의 이미지로 구성된 커스텀 데이터셋으로 훈련된 YOLOv5s 모델을 사용합니다. 감지된 무기의 프레임이 클라우드 서버로 전송되며 여기서 3DCNN을 통해 강도 사건인지 일상 상황인지 분류됩니다.

- **Performance Highlights**: YOLOv5s는 0.87의 mAP (mean Average Precision)와 4.43 FPS (Frames Per Second)를 달성하였으며, 3DCNN은 비정상 상황 감지에서 0.88의 정확도를 보였습니다. 제안된 시스템은 실시간으로 여러 위치를 자율적으로 모니터링하며 잘못된 탐지율을 크게 줄입니다.



### MIRAGE: Multimodal Identification and Recognition of Annotations in Indian General Prescriptions (https://arxiv.org/abs/2410.09729)
Comments:
          8 pages, 11 figures, 2 tables

- **What's New**: 본 연구에서는 인도에서 수천 건의 손으로 쓴 처방전 생성 현실을 다루며, 기존의 기록 관리 방식을 개선하기 위해 Multimodal LLMs를 이용한 손글씨 인식(HWR)에 대한 새로운 접근법을 제안합니다. 본 연구는 743,118개의 완전 주석이 달린 고해상도医疗 기록 데이터를 사용하여, LLaVA 1.6 및 Idefics2 모델을 미세 조정하여 약물 이름과 용량을 추출하는 정확도를 82% 달성했습니다.

- **Technical Details**: 연구 방법론인 MIRAGE(멀티모달 주석 식별 및 인식)는 고해상도 의료 기록 데이터를 활용하여 Multimodal LLMs을 통해 약물 인식을 수행합니다. LLaVA는 OpenAI의 CLIP-ViT-Large-Patch14-336 시각 변환기를 통합하고, Idefics2는 SigLIP 비전 인코더를 사용하여 OCR(Optical Character Recognition) 과제를 수행합니다. Accuracy 측정은 AWP(예측 정밀도), AWI(이상 정밀도) 및 HIP(조화 평균)를 기준으로 진행되었습니다.

- **Performance Highlights**: 본 연구의 접근법은 기존 자동화 방법론을 초월하며, 의사들의 전문성과 시뮬레이션된 환자 정보의 포함이 인정 정확도 향상에 기여함을 입증하였습니다. 연구 결과는 손글씨가 포함된 의료 기록의 인식에서 상향 조정된 정확도를 나타내었으며, 다양한 처방전이 포함된 독특한 데이터세트를 기반으로 한 것이 특징입니다.



### AM-SAM: Automated Prompting and Mask Calibration for Segment Anything Mod (https://arxiv.org/abs/2410.09714)
- **What's New**: AM-SAM(Automated prompting and Mask calibration for SAM) 방법론은 이미지에 대한 자동 프롬프트 생성을 통해 데이터 레이블링의 수고를 줄이고, 보다 정확한 세분화를 지원합니다.

- **Technical Details**: AM-SAM은 bi-level optimization framework을 기반으로 하여 객체 감지기를 통해 입력 이미지에 대한 정확한 bounding box 정보를 자동으로 생성하고, mask decoder는 element-wise multiplication을 추가하여 고급 feature correlation을 캡처하는 방식으로 개선되었습니다.

- **Performance Highlights**: AM-SAM은 body segmentation 데이터셋에서 SOTA 방법에 비해 4개의 예시로 구성된 few-shot 훈련 세트에서 5% 높은 dice score를 기록하며, 의료 도메인 데이터셋에서도 10% 이상의 성능 향상을 보였습니다.



### EchoPrime: A Multi-Video View-Informed Vision-Language Model for Comprehensive Echocardiography Interpretation (https://arxiv.org/abs/2410.09704)
Comments:
          30 pages, 3 tables, 3 figures

- **What's New**: EchoPrime은 다중 뷰(multi-view) 기반의 비디오 영상-언어(vision-language) 모델로, 기존의 단일 뷰 시스템의 한계를 극복하고 복잡한 심장 초음파(echocardiography) 검사를 위한 포괄적인 해석을 제공합니다.

- **Technical Details**: EchoPrime은 1200만 개 이상의 비디오-보고서 쌍(video-report pairs)으로 학습된 대규모 모델로, 대조 학습(contrastive learning)을 통해 모든 표준 뷰에 대해 통합 임베딩 모델을 훈련합니다. 모델은 뷰 분류(view-classification) 및 해부학적 주의를 고려하여 각 비디오에 맞는 해석을 정확히 적용합니다.

- **Performance Highlights**: EchoPrime은 두 개의 독립적인 의료 시스템에서 23개의 다양한 심장 형상 및 기능 벤치마크에서 최첨단(state-of-the-art) 성능을 달성하였으며, 이는 이전의 과제 특화 접근법(task-specific approaches) 및 기존 모델들을 초월하는 성과입니다.



### Robust 3D Point Clouds Classification based on Declarative Defenders (https://arxiv.org/abs/2410.09691)
- **What's New**: 이 논문에서는 3D 포인트 클라우드를 2D 이미지로 매핑하기 위한 세 가지 새로운 알고리즘을 제안하고, 기존 Lattice Point Classifier (LPC)를 확장하여 성능 및 방어 메커니즘을 평가합니다. 또한, 새로운 매핑 알고리즘을 통해 2D 이미지 간의 도메인 격차를 줄이기 위해 Generative 모델 기반의 접근 방식을 사용할 것입니다.

- **Technical Details**: 기존의 3D 포인트 클라우드 분류는 2D 이미지 분류와는 다른 방식으로 구현해야 합니다. 본 문서에서는 점 구름을 2D 이미지로 변환하기 위한 Direct projection, Graph drawing 등의 세 가지 알고리즘을 제안하고, 각 방법의 성능과 방어 능력을 실험적으로 분석합니다. 현재 대형 기초 모델을 활용하여 일반적인 2D 이미지와 투영된 2D 이미지 간의 특성 차이를 조사하고 있습니다.

- **Performance Highlights**: 제안된 방법들은 적대적 공격(adversarial attacks)에 대한 내구성이 뛰어나며, 최신 상태의 정확도를 달성합니다. GAN 기반의 분류기는 실제 2D 데이터셋과 비교했을 때 최소한의 도메인 간 차이를 보이는 것으로 나타났습니다. 이러한 학습된 분류기는 포인트 클라우드의 안전성 중요성을 고려하여 설계되었습니다.



### FAMOUS: High-Fidelity Monocular 3D Human Digitization Using View Synthesis (https://arxiv.org/abs/2410.09690)
- **What's New**: 이 논문에서는 3D 인체 디지털화에서 텍스처 및 형상 예측을 개선하기 위해 광범위한 2D 패션 데이터셋을 활용하는 방법을 제안합니다. 특히, 정면에서 촬영한 이미지에서 몸의 가려진 부분 특히 허리 등에서 텍스처 예측의 한계를 해결하는 데 초점을 맞추고 있습니다.

- **Technical Details**: 본 연구의 접근 방식인 FAMOUS는 2D 패션 데이터셋의 풍부한 텍스처 데이터를 3D 모델링 과정에 통합합니다. 이 과정은 사전 훈련된 hallucinator를 이용하여 뒷모습의 학습을 세분화된 요소로 정리하여 진행됩니다. 이를 통해 제공되는 디자인 정렬 접근 방식을 통해 3D 데이터셋의 분포에 일반화할 수 있도록 합니다.

- **Performance Highlights**: 다양한 표준 3D 인체 벤치마크에서의 폭넓은 실험을 통해 기존의 최첨단 방법들과 비교했을 때, 저희 접근 방식이 텍스처와 기하학 측면에서 우수한 성능을 보여준 것을 입증하였습니다. 또한, 새로운 대규모 2D 패션 데이터셋을 기여하며 관련 커뮤니티의 연구를 지원할 것입니다.



### Learning the Bitter Lesson: Empirical Evidence from 20 Years of CVPR Proceedings (https://arxiv.org/abs/2410.09649)
Comments:
          NLP4Sceince Workshop, EMNLP 2024

- **What's New**: 이번 연구는 CVPR(Computer Vision and Pattern Recognition) 논문들이 Rich Sutton이 제안한 '쓴 교훈'의 원칙과 얼마나 일치하는지를 20년 간 분석합니다. 이는 기계 학습(ML) 분야의 전반적인 발전 방향과 관련이 있으며, LLM(대형 언어 모델)을 활용해 해당 논문의 추세를 평가합니다.

- **Technical Details**: 연구에서 활용된 LLM들은 GPT-4o-2024-05-13, gpt-4o-mini-2024-07-18, claude-3-5-sonnet-20240620로, 2005년부터 2024년까지의 CVPR 논문 제목과 초록을 평가합니다. 연구는 '쓴 교훈' 기준에 맞춘 다섯 가지 차원에서 논문의 정렬 정도를 척도로 평가합니다: Learning Over Engineering, Search over Heuristics, Scalability with Computation, Generality over Specificity, Favoring Fundamental Principles.

- **Performance Highlights**: 연구 결과, CVPR에서 일반적인 학습 알고리즘 및 컴퓨팅 자원의 사용 증가에 대한 중요한 경향이 발견되었습니다. LLM을 활용한 분석 방법은 머신러닝 연구의 진화 과정을 이해하는 데 기여하며, 이는 향후 컴퓨터 비전 연구에 긍정적인 영향을 미칠 수 있습니다.



### DuoDiff: Accelerating Diffusion Models with a Dual-Backbone Approach (https://arxiv.org/abs/2410.09633)
Comments:
          Accepted to NeurIPS, see this https URL

- **What's New**: Diffusion 모델에서의 샘플링 속도를 개선하기 위해, DuoDiff라는 새로운 접근 방식을 제안합니다. 이 모델은 초기 샘플링 단계에서 얕은 denoising 네트워크를 사용하고, 후속 단계에서 더 깊은 네트워크를 활용하여 효율성을 높입니다.

- **Technical Details**: DuoDiff는 두 개의 denoising 네트워크로 구성되어 있습니다. 초기 단계에서는 적은 수의 레이어만 활성화되고, 후속 단계에서는 완전한 네트워크가 사용됩니다. 이 접근 방식은 기존의 동적 early-exit 방식을 대체하고, 빠른 샘플링을 가능하게 합니다.

- **Performance Highlights**: DuoDiff는 기존의 early-exit diffusion 모델들에 비해 샘플링 속도와 이미지 생성 품질에서 우수한 성능을 보였습니다. 특히, 배치 추론에 적합하며, 다른 효율성 향상 기법과 쉽게 결합할 수 있습니다.



### RailYolact -- A Yolact Focused on edge for Real-Time Rail Segmentation (https://arxiv.org/abs/2410.09612)
- **What's New**: 이 논문은 자율 주행 기차의 안전성을 확보하기 위해 레일의 경계 검출을 개선한 RailYolact 모델을 제안합니다. 이를 위해 기존 Yolact의 손실 함수에 경계 정보를 통합하여 레일 경계에 대한 모델의 집중을 강화했습니다.

- **Technical Details**: RailYolact는 Yolact 모델을 기반으로 하여 기존의 경계 검출 방법론인 Sobel과 Laplacian을 사용하여 예측된 마스크와 실제 마스크의 경계 정보를 추출합니다. 이러한 경계 정보를 손실 함수에 통합하여 모델이 레일의 경계 정보를 더 잘 이해하도록 합니다. 또한, Box Filter를 사용하여 지각을 완화하여 더 매끄러운 마스크를 생성합니다.

- **Performance Highlights**: 커스텀 레일 데이터셋에서의 실험 결과, RailYolact는 예측 정확도의 향상을 보였고, Cityscapes 데이터셋에서는 Yolact 대비 $AP$와 $AP_{50}$가 각각 4.1 및 4.6의 향상을 나타냈습니다.



### FiRework: Field Refinement Framework for Efficient Enhancement of Deformable Registration (https://arxiv.org/abs/2410.09595)
- **What's New**: 본 연구에서는 새로운 비지도형 변형 등록 방법인 필드 리파인먼트 프레임워크(FiRework)를 제안합니다. FiRework는 기존의 연속 변형 프레임워크의 오류를 완화하도록 설계되었습니다.

- **Technical Details**: FiRework는 네트워크를 변형 필드 리파이너(deformable field refiner)로 처리합니다. 이 프레임워크는 이동 이미지(Imsubscript𝐼𝑚)와 이전 단계의 변형 필드(ϕt−1)와의 관계를 네트워크에 추가 입력값으로 통합하여 누적 오류를 경감하고 보간 오류를 해결할 수 있도록 합니다. 또한, 훈련 과정에서는 단일 레벨 재귀를 요구하며 추론 중에는 연속적인 변형 필드 개선을 허용합니다.

- **Performance Highlights**: 두 개의 뇌 MRI 데이터셋을 사용한 실험에서 FiRework를 이용해 기존의 변형 등록 네트워크 두 개를 개선했으며, 그 결과 제안한 프레임워크가 변형 등록에서 우수한 성능을 보임을 입증했습니다.



### ControLRM: Fast and Controllable 3D Generation via Large Reconstruction Mod (https://arxiv.org/abs/2410.09592)
Comments:
          Draft version. This paper is still in submission. For access to our project page and code, please visit: this https URL

- **What's New**: 이번 논문에서는 높은 효율성과 제어 가능성을 가진 3D 생성 방법인 ControLRM을 소개합니다. ControLRM은 대규모 재구성 모델(LRM)을 기반으로 하는 엔드투엔드(feed-forward) 모델로, 텍스트 및 2D 시각적 조건을 입력으로 받아 3D 형상을 생성할 수 있습니다.

- **Technical Details**: ControLRM은 2D 조건 생성기, 조건 인코딩 변환기, 삼면 디코더 변환기로 구성되어 있습니다. 두 가지 훈련 브랜치를 통해 모델의 성능을 높이는 조인트 훈련 프레임워크를 사용하며, 이는 사전 훈련된 LRM 모델의 파라미터를 활용하여 더욱 발전된 3D 생성 기능을 제공합니다.

- **Performance Highlights**: 본 연구는 G-OBJ, GSO, ABO 데이터셋에서 다양한 평가 샘플을 활용하여 3D 제어 가능성과 생성 품질 평가를 진행하였습니다. 실험 결과, ControLRM은 기존 방법들 대비 우수한 성능을 보였으며, 제어 가능성과 일반화 능력이 뛰어난 것으로 나타났습니다.



### POPoS: Improving Efficient and Robust Facial Landmark Detection with Parallel Optimal Position Search (https://arxiv.org/abs/2410.09583)
Comments:
          The experimental setup and results require further modifications and improvements to ensure the accuracy and quality of the paper. Therefore, we are requesting to withdraw the submission

- **What's New**: 이번 논문은 얼굴 랜드마크 감지(FLD)를 위한 새로운 프레임워크인 Parallel Optimal Position Search (POPoS)를 소개합니다. 이 프레임워크는 기존 방법의 한계를 극복하기 위해 설계되었습니다.

- **Technical Details**: POPoS는 세 가지 주요 혁신을 포함합니다: (1) 의사 범위(multilateration) 멀티레이터를 사용하여 Heatmap 오류를 수정, 랜드마크 위치 정확도를 향상시킵니다. 적절한 앵커 포인트를 통합하여 개별 Heatmap 부정확성의 영향을 최소화합니다. (2) 밀리터레이션 앵커 손실(multilateration anchor loss)이라는 새로운 손실 함수를 제안하여 선택된 앵커 포인트의 의사 범위 정확성을 개선합니다. 이 손실 함수는 거리 맵의 정확성을 높이고 지역 최적(local optima) 위험을 완화합니다. (3) 단일 단계 병렬 계산 알고리즘이 도입되어 계산 효율성을 크게 증가시키고 처리 시간을 단축합니다.

- **Performance Highlights**: 다섯 개의 벤치마크 데이터셋에서의 종합적인 평가 결과, POPoS는 기존 방법들을 지속적으로 능가하며, 특히 저해상도 시나리오에서 최소한의 계산 오버헤드로 우수한 성능을 발휘합니다.



### Improving 3D Finger Traits Recognition via Generalizable Neural Rendering (https://arxiv.org/abs/2410.09582)
Comments:
          This paper is accepted in IJCV. For further information and access to the code, please visit our project page: this https URL

- **What's New**: 새로운 연구에서는 3D 생체인식 기술에서 기존의 명시적 3D 재구성 방식을 대체하기 위해 신경 방사장(NeRF)을 활용한 FingerNeRF를 제안합니다. 이는 정보 손실과 특정 하드웨어 의존성을 줄이기 위한 접근입니다.

- **Technical Details**: 이 연구에서는 Trait Guided Transformer (TGT) 모듈을 통해 손가락 특성(예: 지문, 손가락 정맥)에 기반한 추가 기하학적 제약을 사용하여 3D 형태와 복사율 간의 애매함 문제를 해결하려고 합니다. Depth Distillation Loss 및 Trait Guided Rendering Loss와 같은 새로운 손실 함수를 포함시킵니다.

- **Performance Highlights**: 실험 결과, FingerNeRF는 SCUT-Finger-3D 데이터셋에서 EER 4.37%, SCUT-FingerVein-3D 데이터셋에서 EER 8.12%, UNSW-3D 데이터셋에서 EER 2.90%를 달성, 제안된 방법의 우수성을 입증합니다.



### Reconstructive Visual Instruction Tuning (https://arxiv.org/abs/2410.09575)
- **What's New**: 이 논문에서는 ROSS(재구성 시각 지시 조정, Reconstructive Visual Instruction Tuning)를 도입하여 시각 중심의 감독 신호를 활용하는 대규모 멀티모달 모델(Large Multimodal Models, LMMs) 패밀리를 제안합니다. 기존의 시각 지시 조정 접근 방식이 텍스트 출력에만 초점을 맞추었던 것과 달리, ROSS는 입력 이미지를 재구성함으로써 LMMs가 시각 출력을 감독하도록 촉구합니다.

- **Technical Details**: ROSS는 자연 이미지를 통한 의미 있는 피드백을 제공하기 위해 노이즈 제거 목표를 사용하여 입력 이미지의 잠재 표현을 재구성하며, 이는 정확한 원시 RGB 값을 직접적으로 회귀하는 것을 피합니다. 이 내부 활성화 디자인은 LMMs가 이미지 세부 정보를 유지하도록 장려하여 세밀한 이해 능력을 향상시키고 환각(hallucinations)을 줄입니다.

- **Performance Highlights**: ROSS는 여러 비주얼 인코더와 언어 모델에서 일관되게 상당한 성능 향상을 보여줍니다. 예를 들어, 단일 SigLIP 비주얼 인코더를 사용하는 ROSS-7B는 HallusionBench에서 57.3으로 우수한 성과를 내며, 비슷한 모델 크기를 가진 최신 대안보다 월등한 성능을 발휘합니다.



### Bridging Text and Image for Artist Style Transfer via Contrastive Learning (https://arxiv.org/abs/2410.09566)
Comments:
          18 pages, 8 figures

- **What's New**: 본 연구에서는 텍스트를 이용한 이미지 스타일 전송을 제안하며, 스타일 이미지 없이도 원하는 예술 스타일을 구사할 수 있는 방식인 CLAST(Contrastive Learning for Artistic Style Transfer)를 개발하였습니다. 이로 인해 더 유연하고 편리한 스타일 전송이 가능해졌습니다.

- **Technical Details**: CLAST는 고급 이미지-텍스트 인코더(advanced image-text encoders)를 활용하여 스타일 묘사를 효과적으로 추출하는 감독 대조 훈련(supervised contrastive training) 전략을 도입합니다. adaLN 기반 상태 공간 모델(adaLN-SSM)을 사용하여 스타일-콘텐츠 융합을 탐색하며, 이를 통해 실시간 추론(realtime inference) 시에도 빠른 스타일 전환이 가능합니다.

- **Performance Highlights**: CLAST는 최신의 예술적 스타일 전송 방법들과 비교하여 정량적 및 정성적으로 우수한 성능을 보여줍니다. 512x512 해상도의 이미지를 0.03초 만에 렌더링할 수 있는 효율성을 자랑합니다.



### Robust Optical Flow Computation: A Higher-Order Differential Approach (https://arxiv.org/abs/2410.09563)
Comments:
          8 pages

- **What's New**: 본 연구는 비선형 모션 패턴을 정확하게 추정하는 데 어려움을 겪는 기존의 Optical Flow 계산 방법에 대한 혁신적인 알고리즘을 제안합니다. 이 알고리즘은 고차원 Taylor 시리즈 근사를 활용하여 복잡한 실제 시나리오에서의 함수 동작에 대한 더 많은 정보를 추출하고, 질감이 부족한 영역의 움직임을 추정할 수 있도록 설계되었습니다.

- **Technical Details**: 제안된 알고리즘은 differential estimation framework 내에서 두 번째 차수 Taylor series approximation을 사용하여 Optical Flow를 계산합니다. 이를 통해 이미지 강도 함수의 공간 및 시간 미분을 활용하여 흐름 필드를 더욱 정밀하게 추정할 수 있습니다. 또한, KITTI(2015) 및 Middlebury와 같은 널리 알려진 데이터셋을 사용하여 알고리즘 성능을 평가합니다.

- **Performance Highlights**: 평균 엔드포인트 에러(AEE)가 현저하게 감소하여 알고리즘의 효과를 확인하였습니다. 이는 고차원 비선형 모션 패턴을 다루는 데 있어 알고리즘이 유의미한 성과를 내고 있음을 증명합니다.



### DiffuTraj: A Stochastic Vessel Trajectory Prediction Approach via Guided Diffusion Process (https://arxiv.org/abs/2410.09550)
Comments:
          containing 14pages, 9 figures and 3 tables; Submitted to IEEE Transactions on Intelligent Transportation Systems on 17-June-2024

- **What's New**: 본 논문은 복잡하고 불확실한 해양 선박의 움직임을 예측하기 위한 새로운 프레임워크인 DiffuTraj를 제안합니다. 이는 선박의 경로 예측을 확률분포의 불확실성 확산의 반대 프로세스(guided reverse process)로 개념화하여 모사하는 접근법입니다. 이를 통해 해양 환경의 동적 장면에서의 미래 불확실성을 효과적으로 다룰 수 있습니다.

- **Technical Details**: DiffuTraj는 선박의 이전 상태, 선박 간의 상호작용, 환경 맥락을 인코딩하여 경로 생성을 위한 가이드 요소로 활용합니다. 또한, Transformer 기반의 조건부 노이즈 제거기(conditional denoiser)를 개발하여 시공간(spatio-temporal) 종속성을 포착하고 특정 해양 환경에 적합한 경로를 생성합니다. 이 모델은 두 가지 단계의 구현을 통해 작동합니다: 1) 전방 확산 프로세스에서는 미래 경로에 가우시안(noise) 노이즈를 체계적으로 추가하고, 2) 역 확산 프로세스에서는 불확실성을 줄여 모호한 예측을 명확한 결정적 경로로 변형합니다.

- **Performance Highlights**: DiffuTraj는 선박 경로 예측 벤치마크에서 포괄적인 실험을 통해 기존의 최첨단 방법들보다 뛰어난 성능을 보여줍니다. 특히, Physical priors와 선박 간의 공간적 상호작용을 통합하여 물리적으로 타당한 미래의 경로를 생성하는 데 성공했습니다.



### Bi-temporal Gaussian Feature Dependency Guided Change Detection in Remote Sensing Images (https://arxiv.org/abs/2410.09539)
- **What's New**: 본 논문은 멀티 템포럴 이미지 간의 도메인 정보 차이로 인한 의사 변화(pseudo changes) 문제를 해결하기 위해 bi-temporal Gaussian distribution feature-dependent network (BGFD)를 제안합니다. 이 네트워크는 Gaussian noise domain disturbance (GNDD) 모듈, feature dependency facilitation (FDF) 모듈, 그리고 detail feature compensation (DFC) 모듈을 활용하여, 세밀한 정보 손실과 오염 문제를 개선합니다.

- **Technical Details**: 주요 기술적 요소로는 GNDD 모듈과 FDF 모듈을 통해 도메인 정보의 통계적 특징을 활용하고, network perturbation을 통해 중복 도메인 정보를 학습하는 방식입니다. 추가적으로, mutual information difference loss ($L_{MI}$) 및 고급 attention 메커니즘을 통합하여 네트워크의 적응성을 강화합니다. DFC 모듈은 업샘플링 과정 중 발생할 수 있는 세부 특성 손실을 보상합니다.

- **Performance Highlights**: BGFD는 DSIFN-CD, SYSU-CD, LEVIR-CD, S2Looking의 네 개의 공개 데이터셋에서 비교 실험을 통해 기존 baseline 모델들을 각각 +8.58%, +1.28%, +0.31%, +3.76%의 F1-Score 향상을 보이며, 최신의 성능을 자랑합니다.



### Leveraging Semantic Cues from Foundation Vision Models for Enhanced Local Feature Correspondenc (https://arxiv.org/abs/2410.09533)
Comments:
          Accepted in ACCV 2024

- **What's New**: 이 논문에서는 DINOv2와 같은 foundation vision model의 특성을 활용하여 기존의 descriptor에 semantic reasoning을 통합함으로써 로컬 feature matching을 개선하는 새로운 방법을 제시합니다. 또한, 이 방법은 inference 시 이미지 쌍이 필요하지 않아 기능 캐싱 및 빠른 매칭이 가능합니다.

- **Technical Details**: 제안된 방법은 두 가지의 descriptor 세트를 추출하는데, 하나는 전통적인 텍스처 특성을 기반으로 하고 다른 하나는 DINOv2와 같은 LVM 모델에서 가져온 semantic feature입니다. 이후 self-attention reasoning 모듈을 사용하여 이들 특성을 정제하고, semantic conditioning을 통해 매칭 이미지를 찾기 위한 유사도 행렬을 계산합니다.

- **Performance Highlights**: 이 논문에서 제안한 방법은 indoor 환경에서의 카메라 위치 추정(camera localization) 작업에서 기존의 matchers인 LightGlue와 LoFTR와 비교했을 때 평균 29% 성능 향상을 보였으며, 성능 기준을 충족했습니다. 모든 코드와 훈련된 모델은 제공된 URL에서 확인할 수 있습니다.



### Preserving Old Memories in Vivid Detail: Human-Interactive Photo Restoration Framework (https://arxiv.org/abs/2410.09529)
- **What's New**: 이번 연구에서는 AI 기반의 사진 복원 프레임워크를 제시하여 다단계로 구성된 접근 방식을 통해 사진의 특정 손상 유형을 개선하고 복원하는 데 초점을 맞췄습니다. 이는 복원 과정의 속도를 높이고 자동화하여 사용자 맞춤형 복원이 가능하게 합니다.

- **Technical Details**: 프레임워크는 1) 주요 손상 제거, 2) 노이즈 감소, 3) 얼굴 복원, 4) 색상화의 네 단계로 구성되며, Stable Diffusion, GFP-GAN, DDColor와 같은 최신 기술을 활용하여 사진 복원 프로세스를 최적화합니다.

- **Performance Highlights**: 우리의 방법론은 실제 오래된 사진에서 우수한 성능을 발휘하며, 사용자 입력이 포함된 복원 결과와 그렇지 않은 경우를 비교함으로써 사용자 선호를 통합하는 프레임워크의 중요성을 강조합니다.



### Pic@Point: Cross-Modal Learning by Local and Global Point-Picture Correspondenc (https://arxiv.org/abs/2410.09519)
Comments:
          Accepted at ACML 2024

- **What's New**: 본 논문에서는 Pic@Point 모델을 소개하며, 이는 2D-3D 구조적 대응을 기반으로 하는 효과적인 contrastive learning 방법입니다. 이 모델은 이미지 단서에서 얻은 풍부한 의미적 및 맥락적 지식을 활용하여 포인트 클라우드 표현을 지도합니다.

- **Technical Details**: Pic@Point 모델은 3D와 2D 특성을 전역 및 지역 스케일에서 추출하여 공통의 표현 불변 잠재 공간으로 프로젝션합니다. 이 방법은 기존의 방법들보다 더 가벼우면서도 효과적이며, 디코더 없이 고정된 2D 백본만을 사용하여 작업을 수행합니다.

- **Performance Highlights**: 우리의 초경량 접근법은 여러 3D 벤치마크에서 최신 선행 학습(pre-training) 방법들보다 뛰어난 성능을 기록하며, 구조적 수준에서 지침을 제공하여 더 나은 포즈 인식(positional guidance)을 가능하게 합니다.



### Fine-grained subjective visual quality assessment for high-fidelity compressed images (https://arxiv.org/abs/2410.09501)
Comments:
          Michela Testolina, Mohsen Jenadeleh contributed equally to this work, submitted to the Data Compression Conference (DCC) 2025

- **What's New**: 이미지 압축 및 품질 평가에 관한 새로운 방법론이 소개되었습니다. JPEG AIC-3 프로젝트는 고화질 이미지 평가를 위해 주관적인 이미지 품질 평가 방법론을 개발하고 있으며, 이 논문에서는 해당 방법과 신규 데이터셋, 평가 메트릭에 대해 다룹니다.

- **Technical Details**: 이 논문에서는 압축된 이미지에 대한 세 가지 평가 방법론을 제안합니다: Boosted Triplet Comparison (BTC), Plain Triplet Comparison (PTC), 데이터 분석 접근법입니다. BTC는 이미지의 미세한 차이를 강조하기 위해 아티팩트를 부스트하는 기법을 기반으로 하며, 각 이미지의 품질 차이를 Just Noticeable Difference (JND) 단위로 재구성하여 평가합니다.

- **Performance Highlights**: 논문에서는 약 440,000개의 삼중 응답(triplet responses)이 수집되었으며, 이를 통해 세밀한 압축 아티팩트의 식별이 가능해졌으며, 고정밀도 품질 척도가 JND 단위로 제공됩니다. 이러한 방식은 실제 응용 프로그램에 더 유용한 정보 결과를 보고하는 데 기여할 것입니다.



### A Simple yet Effective Subway Self-positioning Method based on Aerial-view Sleeper Detection (https://arxiv.org/abs/2410.09492)
Comments:
          11 pages,8 figures, under review for IEEE Sensors Journal publication

- **What's New**: 본 논문에서는 지하철 위치 추적을 위한 저비용의 실시간 비주얼 보조 자기 위치 기록 프레임워크를 제안하며, 이는 기존 고비용 인프라 의존 방식을 대체할 수 있는 기술입니다.

- **Technical Details**: 본 연구는 YOLOv8n 네트워크를 활용한 공중 시점 레일 슬리퍼 감지를 통해 지하철의 주행 경로 전반에 걸쳐 정확한 위치 정보를 제공합니다. 이 시스템의 실험 결과, F1-score이 0.929로 1111 fps에서 슬리퍼 위치를 효율적으로 감지하였으며, 평균 비율 오차가 0.1%로 높은 정밀성을 달성했습니다.

- **Performance Highlights**: 제안된 시스템은 대규모의 지하철 자기 위치 추적 데이터 세트를 구축하여 다양한 비교 및 분석을 수행했으며, 이는 개방형 및 지하 시나리오에서 모두 사용 가능하고 저비용 고속의 실내외 자가 위치 기록 가능성을 지닙니다.



### Distilling Invariant Representations with Dual Augmentation (https://arxiv.org/abs/2410.09474)
Comments:
          8 pages, 1 figure, 3 tables. This paper presents preliminary results from a project that we have since discontinued, as our research focus has shifted to new directions

- **What's New**: 지식 증류(knowledge distillation) 분야에서 두 가지 증강 전략을 도입하여 교사 모델과 학생 모델 모두에서 안정적인 특징 학습을 촉진하는 새로운 접근 방식을 소개합니다. 이를 통해 학생 모델이 보다 견고하고 전이 가능한 특징을 캡처하도록 합니다.

- **Technical Details**: 이 논문에서는 'Invariant Causal Knowledge Distillation with Dual Augmentation (ICDA)' 접근 방식을 제안합니다. 이는 KD 과정에서 교사와 학생 모델에 독립적인 증강을 적용하여 대표성을 두 배로 확보하고, 다양한 데이터 변형에도 불구하고 학습된 표현이 안정적으로 유지될 수 있도록 합니다.

- **Performance Highlights**: CIFAR-100 데이터셋을 사용한 광범위한 실험 결과, ICDA 접근 방식이 같은 구조를 가진 KD에서 경쟁력 있는 성능을 달성했습니다. 이는 교사 모델의 구조적 지식을 학생 모델이 보다 넓은 조건에 일반화할 수 있게끔 도와줍니다.



### Enhancing Single Image to 3D Generation using Gaussian Splatting and Hybrid Diffusion Priors (https://arxiv.org/abs/2410.09467)
- **What's New**: 본 논문에서는 2D 및 3D diffusion 모델을 통합하여 향상된 3D 객체 생성 방법을 제안합니다. 이를 통해 텍스처의 세부사항과 지오메트리의 일관성을 유지할 수 있는 새로운 방식의 손실 함수를 도입하여 기존 방법들보다 뛰어난 성능을 달성합니다.

- **Technical Details**: 새로운 두 단계의 이미지-3D 생성 파이프라인을 제안하며, 저주파 스펙트럼에서 3D diffusion 모델의 기하학적 사전 정보를 활용하고, 고주파 스펙트럼에서 2D diffusion 모델을 사용하여 생성된 3D 구조의 텍스처를 정제합니다. 이러한 방법을 통해 hybrid frequency score distillation loss (hf-SDL)을 개발했습니다.

- **Performance Highlights**: 본 연구는 세 가지 공공 데이터셋에서 기존의 SOTA 모델보다 우수한 성능을 보여주며, 1분 이내에 고품질 텍스처를 가진 메시 재구성을 달성하여 로보틱스 분야에서의 활용 가능성을 입증했습니다.



### Skipping Computations in Multimodal LLMs (https://arxiv.org/abs/2410.09454)
Comments:
          Accepted at NeurIPS 2024 Workshop RBFM. Code: this https URL

- **What's New**: 본 연구에서는 Multimodal Large Language Models (MLLMs)의 추론(inference) 과정에서 발생하는 계산 중복(computation redundancy)을 분석합니다.

- **Technical Details**: 추론 시간 동안 전체 블록(block), FFN (Feedforward Neural Network) 레이어 또는 self-attention (SA) 레이어를 스킵(skip)할 수 있는 다양한 방법을 제안합니다. 또한, FFN 및 SA 레이어를 병렬(parallel)로 처리하는 방법도 탐색합니다.

- **Performance Highlights**: Visual Question Answering (VQA)와 같은 특정 작업에서 계산을 건너뛰는 것이 가능하며, 훈련 중 50%의 블록을 스킵하는 것만으로도 97%의 성능을 유지할 수 있습니다. 작은 LLMs (예: OPT-2.7B)로 훈련 시, 더 큰 LLMs (예: OPT-6.7B)와 거의 동등한 성능을 달성할 수 있습니다.



### VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignmen (https://arxiv.org/abs/2410.09421)
Comments:
          EMNLP 2024 Main Conference camera-ready version. This article supersedes arXiv:2312.10665

- **What's New**: 이 논문에서는 인공지능 피드백(AI feedback)을 활용하여 비전-언어 모델(LVLM) 정렬을 위한 데이터 수집의 효율성을 탐구합니다. 이를 위해 VLFeedback라는 대규모 비전-언어 피드백 데이터셋을 소개하며, 이는 82,000개 이상의 다양한 다중 모달 지침과 설명으로 구성되어 있습니다.

- **Technical Details**: VLFeedback 데이터셋은 12개의 LVLM을 기반으로 하여 생성된 다양한 다중 모달 지침을 포함합니다. 이 모델들은 GPT-4V를 포함하여 비전-언어 작업에서 연결된 응답을 생성하는 데 사용됩니다. 주요 평가 기준은 (i) Helpfulness, (ii) Visual Faithfulness, (iii) Ethical Considerations 등 3가지입니다.

- **Performance Highlights**: Silkie라는 모델은 MME 벤치마크에서 6.9% 및 9.5%의 성능 향상을 보여주며, MMHal-Bench에서 환각 이슈를 감소시키고, 레드팀 공격에 대한 저항력이 향상되었습니다. AI 피드백의 활용은 인간 주석 데이터 대비 LVLM을 더 효과적으로 향상시키는 데 기여했습니다.



### Can Vision-Language Models Replace Human Annotators: A Case Study with CelebA Datas (https://arxiv.org/abs/2410.09416)
Comments:
          Accepted by NeurIPS 2024 Workshop (EvalEval 2024)

- **What's New**: 이 연구는 Vision-Language Models (VLMs)의 이미지 데이터 주석 역량을 평가하여 CelebA 데이터셋에서 인간 주석과 비교한 결과, AI 모델이 79.5%의 일치를 보였으며 재주석을 통한 다수결 투표로 89.1%까지 향상되었음을 밝힙니다. 또한, AI 주석 비용이 전통적인 수동 방법의 1%에도 미치지 않음을 보여줍니다.

- **Technical Details**: CelebA 데이터셋은 20만 개의 셀렙 이미지와 40개의 이진 속성 주석이 포함되어 있으며, 본 연구에서는 LLaVA-NeXT 모델을 사용하여 1000개의 이미지를 대상으로 AI 주석을 생성했습니다. AI와 인간의 주석 간 일치는 79.5%로 나타났고, 재주석을 통해 일치율이 89.1%로 상승했습니다. AI 주석의 비용은 수동 주석의 1% 미만임을 입증하였습니다.

- **Performance Highlights**: VLMs의 AI 주석은 특정 이미지 분류 작업에서 인간 주석자와 유사한 성능을 보였으며, 재주석과 다수결 방식을 통해 AI 주석의 일관성이 더욱 높아졌습니다. 이 연구의 결과는 VLMs가 특정 주석 작업을 위해 실행 가능한, 비용 효율적인 대안이 될 수 있음을 뒷받침합니다.



### Distribution-aware Noisy-label Crack Segmentation (https://arxiv.org/abs/2410.09409)
- **What's New**: 이 연구에서는 SAM-Adapter라는 혁신적인 접근 방식을 제안하여 도로 균열(segmentation) 분할에서의 성능을 향상시키고, 노이즈가 있는 레이블의 부정적인 영향을 최소화하는 첫 번째 방법을 발표했습니다.

- **Technical Details**: SAM-Adapter는 Segment Anything Model(SAM)의 일반 지식을 활용하여 도로 균열 분할의 정확도를 높이며, 도메인 별 정보와의 통합을 통해 모델의 일반화 능력을 개선합니다. 새로운 학습 프레임워크는 Mixture of Gaussian distributions(MoG)를 활용하여 각 이미지의 크랙 특성을 캡처하고, Expectation-Maximization(EM) 알고리즘을 통해 노이즈 레이블 문제를 완화합니다.

- **Performance Highlights**: 실험 결과, 두 개의 공개된 포장 크랙(segmentation) 데이터 집합에서 우리의 방법이 기존의 최첨단 기술보다 현저히 우수한 성능을 보이는 것으로 나타났으며, 완전히 새로운 CFD 데이터셋에서도 크로스 도메인 일반화 능력이 뛰어난 것으로 입증되었습니다.



### CtrLoRA: An Extensible and Efficient Framework for Controllable Image Generation (https://arxiv.org/abs/2410.09400)
- **What's New**: 이 논문은 텍스트-이미지(텍스트-투-이미지, T2I) 생성의 개선을 위해, CtrLoRA라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 여러 기본 조건으로부터 공통 지식을 학습하고, 각 조건의 특성을 포착하는 LoRA를 결합하여 효율성을 높입니다.

- **Technical Details**: CtrLoRA는 Base ControlNet을 사용하여 이미지-이미지 생성의 공통 지식을 학습하고, 각 조건에 특화된 LoRA를 활용하여 조건의 특정 특성을 캡처합니다. 이 접근 방식은 모델 가중치를 배포하고 사용하는 데 필요한 학습 가능한 매개변수를 90% 줄여줍니다.

- **Performance Highlights**: 사용자는 사전에 학습된 Base ControlNet을 통해 단 1,000개의 데이터 쌍과 1시간 미만의 단일 GPU 훈련으로 만족스러운 결과를 얻을 수 있습니다. 다양한 조건 유형에 대해 실험을 수행하여 효율성과 효과성을 입증했습니다.



### CLIP-SCGI: Synthesized Caption-Guided Inversion for Person Re-Identification (https://arxiv.org/abs/2410.09382)
- **What's New**: 최근 사람 재식별(person re-identification, ReID) 분야에서 Contrastive Language-Image Pre-Training (CLIP)와 같은 큰 비전-언어 모델을 활용한 연구가 중요해졌습니다. 본 논문에서는 이미지 캡셔닝 모델을 활용하여 사람 이미지에 대한 의사 캡션(pseudo captions)을 생성하고, 이를 기반으로 ReID 성능을 향상시키는 간단한 방법인 CLIP-SCGI를 제안합니다.

- **Technical Details**: CLIP-SCGI는 LLAVA 모델을 활용하여 고품질의 캡션을 생성하고, uni-modality(이미지)에서 bi-modality(이미지 및 텍스트)로 ReID 학습 세트를 확장합니다. 이 프레임워크는 CLIP을 기반으로 하여 두 개의 임베딩 모듈을 융합하여 훈련 과정을 개선합니다. 또한, 캡션 품질 문제를 해결하기 위해 캡션 유도 역전(caption-guided inversion) 모듈을 도입하여 이미지에서 시맨틱 속성을 포착합니다.

- **Performance Highlights**: CLIP-SCGI는 네 가지 인기 ReID 벤치마크에서 엄청난 성능 향상을 보여주며, 특히 MSMT17 데이터셋에서는 88.2%의 mAP를 기록하여 기존 최첨단 결과를 뛰어넘었습니다. 이 프레임워크는 학습의 유연성과 표현력 향상이라는 장점을 가지고 있으며, 주석 없이도 쉽게 적용할 수 있습니다.



### Prompting Video-Language Foundation Models with Domain-specific Fine-grained Heuristics for Video Question Answering (https://arxiv.org/abs/2410.09380)
Comments:
          IEEE Transactions on Circuits and Systems for Video Technology

- **What's New**: HeurVidQA 프레임워크는 도메인 특정 엔티티-행동 히어리스를 통합하여 사전 훈련된 비디오-언어 모델을 개선함으로써, 비디오 질문 응답(VideoQA) 과제의 복잡한 요구사항을 해결하는 데 중점을 둡니다.

- **Technical Details**: 비디오 언어 기초 모델(VFMs)은 비디오-텍스트 데이터셋을 기반으로 사전 훈련되어 넓은 크로스 모달(cross-modal) 지식을 제공하나, 도메인 특정 요구사항에 맞춰 세밀한 조정이 필요합니다. HeurVidQA는 이러한 모델을 엔티티-행동에 대한 도메인 특정 히어리스를 통해 정교화하여, 모델의 초점을 정확한 단서로 유도합니다.

- **Performance Highlights**: 여러 VideoQA 데이터셋을 포함한 포괄적인 평가에서 HeurVidQA는 기존 모델들보다 현저히 향상된 성능을 보였습니다. 이는 도메인 특정 지식을 비디오-언어 모델에 통합함으로써 더 정확하고 맥락 인식이 가능한 VideoQA를 실현함을 강조합니다.



### Multi-granularity Contrastive Cross-modal Collaborative Generation for End-to-End Long-term Video Question Answering (https://arxiv.org/abs/2410.09379)
Comments:
          Transactions on Image Processing

- **What's New**: 이번 논문은 긴 형식의 비디오 질문 답변(VideoQA)을 위한 완전한 end-to-end 솔루션인 Multi-granularity Contrastive cross-modal collaborative Generation (MCG) 모델을 제안하고 있습니다. MCG는 비디오와 질문을 입력으로 받아 직접적으로 답변을 생성하는 생성적 태스크로 VideoQA를 재정립합니다.

- **Technical Details**: MCG는 Joint Unimodal Modeling (JUM)을 활용하여 강력한 시각적 개념을 가진 판별 표현을 산출하며, Multi-granularity Contrastive Learning (MCL)을 통해 내재적 또는 명시적으로 나타나는 의미적 상관관계를 활용합니다. 또한 Cross-modal Collaborative Generation (CCG) 모듈을 도입하여 VideoQA를 생성적 태스크로 변환함으로써 cross-modal 고차원 융합 및 생성을 가능하게 합니다.

- **Performance Highlights**: MCG는 ActivityNet-QA, NExT-QA, MSRVTT-QA, MSVD-QA를 포함한 네 가지 공개 VideoQA 데이터셋에서 최첨단 성능을 달성하였으며, multi-modal TVQA와 진단 CLEVRER 작업으로 성공적으로 확장되어 일관된 일반화 및 강건성을 입증했습니다.



### GEM-VPC: A dual Graph-Enhanced Multimodal integration for Video Paragraph Captioning (https://arxiv.org/abs/2410.09377)
- **What's New**: 이 논문에서는 Video Paragraph Captioning (VPC)을 위한 새로운 다중모달 통합 캡션 생성 프레임워크인 GEM-VPC를 제안합니다. 이 프레임워크는 다양한 모달리티와 외부 지식 기반을 활용하여 비디오의 주요 사건을 요약하는 단락 캡션을 생성합니다.

- **Technical Details**: GEM-VPC는 '비디오 특정' 시계열 그래프와 특정 테마의 단어 간의 상관관계를 나타내는 '테마 그래프' 두 가지 그래프를 구성합니다. 이들 그래프는 트랜스포머 네트워크의 입력으로 사용되며, 노드 선택 모듈을 통해 가장 관련성 높은 노드를 선택하여 디코딩 효율성을 향상시킵니다.

- **Performance Highlights**: GEM-VPC 모델은 널리 사용되는 두 가지 벤치마크 데이터세트에서 기존의 최첨단 방법들과 비교하여 우수한 성능을 보였습니다. 또한 다양한 구성 요소의 기여를 분석하는 포괄적인 아블레이션 분석이 수행되었습니다.



### ESVO2: Direct Visual-Inertial Odometry with Stereo Event Cameras (https://arxiv.org/abs/2410.09374)
- **What's New**: 본 논문은 이벤트 기반 스테레오 시각 관성 오도메트리 시스템을 제안하여 기존의 이벤트 기반 시각 오도메트리 방법론의 제한사항을 극복합니다. 이를 통해 카메라 포즈 추적과 매핑 성능을 더욱 향상시켰으며, IMU 정보를 사용하여 정확한 모션 예측을 수행합니다.

- **Technical Details**: 제안된 시스템은 이벤트 카메라의 지역적 동작을 고려해 윤곽선 포인트를 효율적으로 샘플링하는 전략을 갖추고 있으며, 정적 스테레오 결과와 역동적인 스테레오 결과를 통합하여 매핑 성능을 향상시킵니다. IMU를 사용한 사전 통합 접근은 기울기 및 방향 회전 성분의 복원을 가능하게 합니다.

- **Performance Highlights**: 다섯 개의 공개 데이터세트에서 광범위한 평가를 진행하였으며, 제안된 시스템은 5개의 최신 방법과 비교 시 우수한 성능을 낼 뿐만 아니라, 다양한 해상도의 이벤트 카메라와 안정적으로 실시간으로 동작할 수 있음을 입증하였습니다.



### Debiasing Vison-Language Models with Text-Only Training (https://arxiv.org/abs/2410.09365)
- **What's New**: 본 논문은 비전-언어 모델(Vison-Language Model)인 CLIP에서 발생하는 편향 문제를 해결하기 위해 텍스트 전용 디바이싱 프레임워크(TOD)를 제안합니다. TOD는 이미지 데이터 없이 텍스트만으로 훈련하여 시각적 편향을 완화하는 혁신적인 방법입니다.

- **Technical Details**: TOD는 두 단계로 구성됩니다: 첫 번째는 균형 잡힌 텍스트 데이터 생성을 위해 GPT-4o를 사용하여 목표 및 속성 이름이 포함된 텍스트 설명을 생성하는 것입니다. 두 번째 단계는 텍스트 전용 훈련으로, 생성된 텍스트 설명을 이미지에 대한 프롬프트 튜닝에 사용합니다. 특히, Multi-Target Prediction (MTP) 작업을 도입하여 모델이 복잡한 맥락에 집중하고 편향 정보를 구별하도록 유도합니다.

- **Performance Highlights**: Waterbirds 및 CelebA 데이터셋에서 TOD를 적용한 결과, 본 방법은 기존의 이미지가 없는 방법들보다 유의미하게 우수한 성능을 발휘하며, 이미지 감독 방법과 비교했을 때 경쟁력 있는 결과를 보여줍니다. 더불어, 본 연구는 다양한 편향 속성이 있는 도전적인 시나리오에서도 강력한 일반화 및 견고성을 입증했습니다.



### Toward Guidance-Free AR Visual Generation via Condition Contrastive Alignmen (https://arxiv.org/abs/2410.09347)
- **What's New**: 이번 연구에서는 Classifier-Free Guidance (CFG) 기법을 사용하지 않고도 고성능의 시각적 AR 생성이 가능하도록 하는 Condition Contrastive Alignment (CCA) 방법을 제안합니다. CFG는 언어 및 시각적 콘텐츠 간의 설계 불일치를 초래하여, 시각적 AR의 통합 철학과 상충됩니다.

- **Technical Details**: CCA는 사전 훈련된 모델을 직접 미세 조정하여 동일한 샘플링 분포 목표에 맞출 수 있도록 하고, 샘플링 과정은 그대로 유지됩니다. CCA는 긍정 및 부정 조건을 대비시켜 훈련 데이터를 통해 쉽게 생성할 수 있습니다. 실험 결과, 단 한 번의 에포크로도 모든 테스트된 모델의 성능을 크게 향상시킬 수 있었습니다.

- **Performance Highlights**: CCA는 시각적 AR 모델 LLamaGen 및 VAR에 적용되어, 모델이 안내되지 않은 샘플링 품질을 상당히 개선시킨 결과를 보여주었습니다. 특히, CCA는 CFG와 동등한 수준의 성능을 달성하면서 샘플링 비용을 절반으로 줄이는 결과를 가져왔으며, 훈련 파라미터 조정을 통해 샘플 다양성과 정확성 간의 균형을 조정할 수 있습니다.



### Advanced Gesture Recognition in Autism: Integrating YOLOv7, Video Augmentation and VideoMAE for Video Analysis (https://arxiv.org/abs/2410.09339)
- **What's New**: 이번 연구는 딥러닝(Deep Learning)과 비접촉형 센서(Contactless Sensors)의 발전을 통해 의료 환경에서 인간 활동을 이해하는 데 도움이 되는 새로운 접근법을 제시합니다. 특히, 자폐증(Autism) 아동의 반복적인 행동을 정확히 분석하기 위해 비디오 데이터를 활용합니다.

- **Technical Details**: 연구에서는 Self-Stimulatory Behavior Dataset (SSBD)라는 공개 데이터셋을 사용하여 아동의 일상 활동 중 관찰되는 반복 행동(Spinning, Head Banging, Arm Flapping)을 분류합니다. 이 과정에서 VideoMAE라는 모델을 도입하여 비디오 데이터의 공간적 및 시간적 분석(Spatial and Temporal Analysis)을 개선하는 마스킹(Masking) 및 복원(Reconstruction) 메커니즘을 활용합니다.

- **Performance Highlights**: 이 모델은 기존의 전통적인 방법에 비해 14.7% 향상된 97.7%의 정확도(Accuracy)를 기록하며, 자폐증에 관련된 행동 인식 분야에서 새로운 경지를 열었습니다.



### Token Pruning using a Lightweight Background Aware Vision Transformer (https://arxiv.org/abs/2410.09324)
Comments:
          7 pages, 2 tables, 4 figures, FITML workshop@NeuRIPS 2024

- **What's New**: Background Aware Vision Transformer (BAViT) 모델을 소개하며, Edge AI를 위해 설계된 사전 처리 블록입니다. BAViT는 이미지에서 배경 토큰을 식별하여 토큰을 완전 또는 부분적으로 제거할 수 있습니다.

- **Technical Details**: BAViT는 이미지 패치를 토큰으로 처리하고, 각 토큰의 중요도를 기반으로 배경(BG) 및 전경(FG)으로 분류하는 새로운 방식의 token pruning을 적용합니다. 이 모델은 세그멘테이션 맵과 바운딩 박스를 사용하여 토큰의 중요도를 학습하고, VOC 및 COCO 데이터셋에서 75%에서 88%의 정확도를 달성합니다.

- **Performance Highlights**: BAViT-small 모델을 YOLOS의 사전 처리기로 사용할 경우, 30%에서 40%까지 처리량을 증가시킬 수 있으며, mAP는 3% 감소하거나 sparse fine-tuning을 적용할 경우 2% 감소합니다.



### Towards Multi-Modal Animal Pose Estimation: An In-Depth Analysis (https://arxiv.org/abs/2410.09312)
Comments:
          35 pages, 5 figures, 8 tables

- **What's New**: 이번 논문은 동물 포즈 추정(Animal Pose Estimation, APE) 기술의 최신 동향과 도전 과제를 다루며, 2013년부터 178개의 관련 논문을 평가하여 센서 및 모달리티(차원, 형식) 유형, 학습 패러다임, 실험 설정, 응용 분야에 따라 APE 방법을 분류합니다.

- **Technical Details**: APE는 다양한 센서 입력을 사용하여 육지 포유류의 신체 관절을 확인하고 위치를 파악하는 작업입니다. 이 과정에서 2D 및 3D keypoint 포즈 표현과 몸체 메쉬 재구성을 통해 동물의 포즈를 정확하게 추정합니다. 논문에서는 RGB, 열화상 및 mmWave 레이더와 같은 다양한 센서를 활용하여 APE의 성능을 향상시키기 위한 멀티 센서 및 멀티 모달 시스템의 가능성을 탐구합니다.

- **Performance Highlights**: APES는 다양한 생태계와 동물 행동을 분석하는데 매우 중요하며, 정확한 APE 기술을 통해 신경 과학, 생체 역학 및 수의학 분야의 연구에 이바지하고 있습니다. 특히, 저조도 환경에서의 동물 감지와 행동 분석에서 새로운 센서 기술의 적용 가능성을 보여주고 있습니다.



### TD-Paint: Faster Diffusion Inpainting Through Time Aware Pixel Conditioning (https://arxiv.org/abs/2410.09306)
- **What's New**: 이번 연구에서는 일반적인 diffusion 모델을 개선하여 더욱 효율적인 이미지 인페인팅을 위한 새로운 접근 방식인 TD-Paint(Time-aware Diffusion Paint)을 제안합니다. TD-Paint는 픽셀 수준에서 가변 노이즈 수준을 모델링하여 초기 샘플링 단계부터 입력 조건을 적극적으로 활용함으로써 샘플링 속도를 크게 증가시킵니다.

- **Technical Details**: TD-Paint는 전통적인 diffusion 모델의 개념을 바탕으로, 각 픽셀에 고유한 시간 값(t-value)를 할당하는 독특한 시간 조건화(time conditioning) 기법을 사용합니다. 이는 알려진 이미지 영역에 대해 낮은 노이즈 수준을 부여하고, 생성할 영역에는 현재 생성 프로세스에 비례하는 시간 값을 설정합니다. 이를 통해 초기부터 엄격한 조건을 설정하여 이미지 품질을 유지하면서 생성 속도를 증가시킵니다.

- **Performance Highlights**: TD-Paint는 CelebA-HQ, ImageNet1K 및 Places2 데이터셋을 포함하여 여러 데이터셋에서 실험을 통해 최신 diffusion 모델보다 우수한 성능을 보였으며, CNN 및 Transformer 기반의 다른 인페인팅 방법들보다 더 낮은 복잡도로 뛰어난 결과를 만들어냈습니다.



### Hierarchical uncertainty estimation for learning-based registration in neuroimaging (https://arxiv.org/abs/2410.09299)
Comments:
          15 pages, 6 figures

- **What's New**: 최근 딥러닝 기반 이미지 등록에서 불확실성(uncertainty) 추정의 새로운 접근법을 제안합니다. 특히, 이 방법은 공간 위치 수준에서의 불확실성을 글로벌 변환 모델 수준으로 전달하는 방식을 포함합니다.

- **Technical Details**: 우리의 접근법은 Gaussian 분포를 활용하여 지역 불확실성을 모델링하고, 이 불확실성을 계층적 수준으로 확산시키는 프레임워크를 제안합니다. 또한 여러 가지 변환 모델에 대해 수렴된 불확실성 추정치를 기반으로 가중치를 부여하여 이미지 등록의 정확도를 향상시킵니다.

- **Performance Highlights**: 실험을 통해 Monte Carlo dropout이 등록 오류와 낮은 상관관계를 보이는 반면, 우리가 제안하는 불확실성 추정치는 등록 오류와 더 높은 상관관계를 가지며, 불확실성을 반영한 변환 모델 피팅이 뇌 MRI 스캔의 등록 정확도를 개선함을 보여줍니다.



### SurgicalGS: Dynamic 3D Gaussian Splatting for Accurate Robotic-Assisted Surgical Scene Reconstruction (https://arxiv.org/abs/2410.09292)
Comments:
          7 pages

- **What's New**: 이 논문은 SurgicalGS라는 새로운 동적 3D Gaussian Splatting 프레임워크를 제안합니다. 이 프레임워크는 수술 장면의 재구성을 개선하기 위해 설계되었습니다.

- **Technical Details**: SurgicalGS는 깊이 사전(Depth Priors)을 이용하여 Gaussian 포인트 클라우드를 초기화하며, 이진 모션 마스크를 통해 깊이 변이가 큰 픽셀을 식별하여 여러 프레임의 깊이 맵에서 포인트 클라우드를 융합합니다. Flexible Deformation Model을 사용하여 동적 장면을 표현하고, 정규화된 깊이 정규화 손실(Normalised Depth Regularisation Loss)과 비지도 깊이 매끄러움 제약(Depth Smoothness Constraint)을 도입하여 기하학적 재구성을 더욱 정확하게 하였습니다.

- **Performance Highlights**: SurgicalGS는 두 개의 실제 수술 데이터셋에서 평가되었으며, 최신 접근법에 비해 현저히 향상된 재구성 품질을 보여 주었습니다. 특히, 정확한 기하학에 있어 최첨단 성능(SOTA)을 달성하여 로봇 보조 수술에서 3D Gaussian Splatting의 활용 가능성을 크게 향상시켰습니다.



### Few Exemplar-Based General Medical Image Segmentation via Domain-Aware Selective Adaptation (https://arxiv.org/abs/2410.09254)
Comments:
          Accepcted in ACCV 2024

- **What's New**: 이 논문은 의료 영상 분할에서의 도메인 인식 선택적 적응(domain-aware selective adaptation) 접근 방식을 제안하며, 적은 양의 예시(exemplars)만으로 대규모 모델에서 학습된 일반 지식을 의료 도메인에 적용할 수 있는 방법을 모색합니다.

- **Technical Details**: 저자들은 기존의 SAM(Segment Anything Model) 기반 의료 분할 모델이 정밀한 시각적 프롬프트(visual prompts)의 의존도가 높고, 실제 임상 상황에서는 이러한 프롬프트가 정확하게 제공되지 않는 문제를 지적합니다. 새로운 방법은 사전 지식(prior knowledge)을 사용해 적은 수의 예시만을 바탕으로 다양한 의료 도메인에 쉽게 적응할 수 있는 구조를 가지고 있습니다.

- **Performance Highlights**: 저자들은 제안한 방법이 다양한 의료 이미지 모달리티에서 기존의 최첨단 방법들보다 우수한 성능을 보이며, 특히 예시 수가 적은 설정에서도 효과적이라는 점을 강조하고 있습니다.



### Enhanced Kalman with Adaptive Appearance Motion SORT for Grounded Generic Multiple Object Tracking (https://arxiv.org/abs/2410.09243)
Comments:
          ACCV 2024, main track, oral presentation

- **What's New**: 이번 논문에서는 Grounded-GMOT라는 새로운 멀티 오브젝트 트래킹 (MOT) 패러다임을 소개합니다. 이 패러다임은 자연어 기술을 활용하여 사용자들이 비디오 내에서 다양한 일반 객체를 트래킹할 수 있게 합니다. 또한 G2MOT 데이터셋을 도입하여 다양한 객체 카테고리와 해당 속성에 대한 상세한 설명을 제공합니다.

- **Technical Details**: Grounded-GMOT는 Vision Language Models (VLMs)를 통해 자연어 설명을 기반으로 객체를 트래킹합니다. KAM-SORT(Enhanced Kalman Filter with Adaptive Appearance Motion SORT)라는 새로운 트래킹 방법을 제안하며, 이는 Kalman 필터를 강화하고, 운동 및 외형 정보를 통합하여 객체 추적의 정확성과 강인함을 극대화합니다.

- **Performance Highlights**: 종합적인 실험을 통해 Grounded-GMOT가 기존의 OneShot-GMOT 방법보다 우수한 성능을 보임을 증명하였으며, KAM-SORT의 효과를 다양한 트래커들과 비교함으로써 그 중요성을 강조하였습니다.



### Foundation Model-Powered 3D Few-Shot Class Incremental Learning via Training-free Adaptor (https://arxiv.org/abs/2410.09237)
Comments:
          ACCV 2024

- **What's New**: 최근 3D 포인트 클라우드 처리에서 Few-Shot Class Incremental Learning (FSCIL)에 대한 관심이 증가하고 있으며, 이 논문에서는 FSCIL 문제를 해결하기 위한 새로운 방법을 제안합니다. 기존의 기술적 제약을 극복하고 모델의 성능을 향상시키기 위해, 새로운 동적 적응 방식이 적용되었습니다.

- **Technical Details**: 본 연구는 3D 포인트 데이터에서 학습된 기초 모델(foundation model)의 힘을 활용하여, 추가적인 재학습 없이 새 태스크에 적응할 수 있는 전략을 도입합니다. 이 접근 방식은 두 가지 캐시 시스템을 활용하여 과거 테스트 샘플과 새로운 태스크 샘플을 조합하여 잊어버림(forgetting)과 과적합(overfitting)을 방지합니다. 전통적인 재학습 과정 없이도 본 모델은 이전 클래스의 지식을 유지하면서 새로운 클래스를 효과적으로 학습할 수 있습니다.

- **Performance Highlights**: 모델은 ModelNet, ShapeNet, ScanObjectNN 및 CO3D 데이터셋에서 테스트되었으며, 기존 FSCIL 방법들보다 우수한 성능을 보였습니다. 또한, 다양한 학습 작업에 대한 강력한 성능을 입증하였으며, 그 방법의 효과성과 다양성을 강조합니다.



### Cross-Domain Distribution Alignment for Segmentation of Private Unannotated 3D Medical Images (https://arxiv.org/abs/2410.09210)
- **What's New**: 본 논문에서는 3D 의료 이미지 세그멘테이션을 위한 새로운 문제 해결 방법, 즉 소스가 없는 Unsupervised Domain Adaptation (UDA) 방법을 제시합니다. 이 방법은 데이터 프라이버시 문제를 해결하며, 기본 모델로부터 학습된 내부 분포를 추정하여 유의미한 pseudo-label을 생성합니다.

- **Technical Details**: 제안된 방법은 Gaussian Mixture Model (GMM)을 사용하여 소스 도메인에서 학습된 모델로부터 기초 분포를 추출하고, 이를 기반으로 목표 도메인에서 가장 유사한 pseudo-samples를 생성합니다. 이렇게 생성된 pseudo-label을 통해 모델을 개선합니다. 이 방법은 기존의 UDA 방법들이 필요로 하는 소스 도메인 데이터 접근 없이도 고성능 세그멘테이션을 가능하게 합니다.

- **Performance Highlights**: Multi-Modality Whole Heart Segmentation Dataset을 이용한 실험에서, 제안한 방법이 기존 전통 UDA 기법들을 초과하는 성능을 달성하였음을 보여줍니다. 이는 데이터 프라이버시를 준수하면서도 우수한 세그멘테이션 결과를 제공함을 의미합니다.



### Cross-Domain Evaluation of Few-Shot Classification Models: Natural Images vs. Histopathological Images (https://arxiv.org/abs/2410.09176)
- **What's New**: 본 연구에서는 다양한 도메인에서 몇 샷(шатся в итоги) 분류 모델의 성능을 조사하였습니다. 자연 이미지와 조직 병리학 이미지 간의 전이 가능성과 일반화 능력을 비교하였습니다.

- **Technical Details**: 우리는 Prototypical Networks, SimpleShot, LaplacianShot, DeepEMD 및 DeepBDC와 같은 여러 최첨단 몇 샷 분류 기법을 사용하여 실험을 수행하였습니다. 각 데이터셋은 CRC-TP, NCT-CRC-HE-100K 및 LC25000을 포함하였습니다.

- **Performance Highlights**: 실험 결과, 모델 간의 도메인 전이 및 일반화 가능성에 대한 통찰력을 제공하였으며, 특히 의료 이미징 분야에서의 진단 정확도와 효율성을 크게 향상시킬 수 있는 잠재력을 보여주었습니다.



### Facial Chick Sexing: An Automated Chick Sexing System From Chick Facial Imag (https://arxiv.org/abs/2410.09155)
- **What's New**: 이번 연구에서는 전통적인 방법의 한계를 극복하고, 사람의 얼굴 성별 분류 기술에서 영감을 받은 새로운 방법인 얼굴 병아리 성별 식별(facial chick sexing)을 제안합니다. 이는 전문가의 지식 없이도 병아리를 성별로 분류할 수 있으며, 병아리 조작을 최소화하여 동물 복지를 향상시키는 것을 목표로 합니다.

- **Technical Details**: 이 연구에서는 5,727장의 하루 된 병아리 얼굴 이미지로 구성된 데이터셋을 사용하여 자동 병아리 성별 식별 시스템을 개발하였습니다. 이 시스템은 병아리 얼굴 위치 탐지(chick face localization), 얼굴 키포인트 탐지(keypoint detection), 얼굴 정렬(alignment), 특징 추출(feature extraction), 성별 분류(gender classification)의 5가지 구성 요소로 이루어져 있으며, 종합적이고 효율적인 솔루션을 제공합니다.

- **Performance Highlights**: 실험 결과, 이 방법의 최종 정확도는 81.89%에 달하며, 향후 병아리 성별 식별의 더 보편적 적용 가능성을 입증했습니다.



### RealEra: Semantic-level Concept Erasure via Neighbor-Concept Mining (https://arxiv.org/abs/2410.09140)
- **What's New**: 이 논문에서는 '개념 잔여물' 문제를 해결하기 위해 RealEra라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 렌더링된 이미지가 관련 개념 입력을 통해 생성되지 않도록 방지합니다.

- **Technical Details**: RealEra는 이웃 개념 채굴(neighbor-concept mining) 메커니즘을 도입하여 지워야 할 개념의 임베딩에 랜덤 섭동(random perturbation)을 추가하여 관련된 개념을 발굴합니다. 이후, beyond-concept regularization이라는 방법을 통해 불필요한 개념의 공간 위치를 유지하여 정상적인 생성 성능을 보존합니다. 또한, U-Net의 가중치를 최적화하기 위한 클로즈드 폼 솔루션(closed-form solution)과 LoRA 모듈을 통해 예측 노이즈 정렬을 수행합니다.

- **Performance Highlights**: 여러 벤치마크에서 RealEra는 우수한 개념 삭제 효과성과 특정성을 보이며, 이전의 개념 삭제 방법들을 능가하는 성능을 입증하였습니다.



### Enabling Advanced Land Cover Analytics: An Integrated Data Extraction Pipeline for Predictive Modeling with the Dynamic World Datas (https://arxiv.org/abs/2410.09135)
- **What's New**: 이번 연구에서는 Dynamic World 데이터셋을 활용하여 혁신적이고 유연한 end-to-end 파이프라인을 구축하여 랜드커버(Land Cover) 데이터를 민주화했습니다. 이 파이프라인은 데이터 전처리 및 재표현 프레임워크를 포함하여, 다양한 후속 작업을 위한 적절한 형태로 LULC 데이터의 노이즈 제거 및 대량 데이터 추출을 효율적으로 수행합니다.

- **Technical Details**: Dynamic World 데이터셋은 실시간 10m 해상도의 고해상도 LULC 데이터셋으로, Sentinel-2의 이미지를 기반으로 한 선진 분할 기법을 사용하여 9개의 특정 클래스를 정의하고, 이러한 기법을 통해 지속적인 랜드커버 업데이트를 가능하게 합니다. 이 연구에서는 XGBoost-ConvLSTM 모델인 XGCLM을 사용하여 도시화 예측 문제를 다루고, 이 모델이 변화하는 랜드커버의 역학을 포착해내는 능력을 강조합니다.

- **Performance Highlights**: 연구 결과, 새로운 데이터 처리 파이프라인은 랜드커버 데이터로부터 유의미한 신호를 추출하고, 데이터가 후속 머신러닝 모델과 결합될 수 있도록 잘 표현되는 데 성공했습니다. 특히, 도시화 예측 문제를 위한 모델은 탁월한 성능을 보이며, 다른 랜드커버 유형에 대해서도 쉽게 일반화할 수 있음을 보여줍니다.



### The Solution for Temporal Action Localisation Task of Perception Test Challenge 2024 (https://arxiv.org/abs/2410.09088)
- **What's New**: 이 논문은 Temporal Action Localisation (TAL) 분야에서 비디오 시퀀스 내 특정 시간 구간에서의 행동을 식별하고 분류하는 방법을 제시합니다. Something-SomethingV2 데이터셋의 중첩 레이블을 활용하여 학습 데이터셋을 확대하는 데이터 증강 기법을 통해 모델의 일반화 능력을 향상시켰습니다.

- **Technical Details**: 우리는 최첨단 모델인 UMT, VideoMAEv2를 비디오 피처 추출에, BEATs 및 CAV-MAE를 오디오 피처 추출에 사용하였습니다. 멀티모달(비디오 및 오디오) 및 유니모달(비디오 전용) 모델을 훈련한 후, Weighted Box Fusion (WBF) 방법을 사용하여 예측을 결합했습니다. 이러한 접근 방식을 통해 총 점수 0.5498로 경쟁에서 1위를 달성했습니다.

- **Performance Highlights**: 제안된 방법은 여러 IoU 임계값에서 기존 모델들을 능가하였으며, ablation 연구를 통해 각 구성 요소가 전체 성능 향상에 기여함을 입증했습니다.



### Deep Linear Probe Generators for Weight Space Learning (https://arxiv.org/abs/2410.10811)
- **What's New**: 이번 논문은 Deep Linear Probe Generators (ProbeGen)라는 새로운 접근법을 제안합니다. ProbeGen은 기존의 probing 방법을 개선하기 위해 깊은 선형 아키텍처를 사용하여 모델의 가중치를 학습하는데 효과적이며, 오버피팅을 줄이는 유도 편향을 제공합니다.

- **Technical Details**: ProbeGen은 두 가지 구성 요소로 프로브를 분해합니다: 각 프로브에 대한 잠재 코드와 전역 프로브 생성기. 이 구조는 여러 프로브 간에 정보를 공유할 수 있게 하며, 구조화된 프로브에 대한 유도 편향을 내재화할 수 있습니다. 또한, 비선형 활성화 함수는 학습된 프로브의 효용을 낮추는 것으로 나타났습니다.

- **Performance Highlights**: ProbeGen은 최첨단(state-of-the-art) 방법들에 비해 30배에서 1000배 이상 적은 FLOPs를 요구하면서도 중대한 성능 향상을 보여주었습니다. 이는 단순하면서도 매우 효율적인 접근 방식으로, 다양한 가중치 공간 학습 작업에서 최상의 결과를 달성합니다.



### Generalizable Humanoid Manipulation with Improved 3D Diffusion Policies (https://arxiv.org/abs/2410.10803)
Comments:
          Project website: this https URL

- **What's New**: 이번 연구에서는 Improved 3D Diffusion Policy (iDP3)를 소개하며, 이는 카메라 캘리브레이션 및 포인트 클라우드 세분화의 필요성을 없애주는 새로운 3D 비주얼 모터 정책입니다. iDP3는 에고 중심의 3D 비주얼 표현을 활용하여 다채로운 실제 시나리오에서 인간 크기의 로봇이 자율적으로 기술을 수행할 수 있도록 합니다.

- **Technical Details**: iDP3는 기존의 3D Diffusion Policy (DP3)를 개선하여 3D 비주얼 표현을 카메라 프레임에서 직접 사용하는 방식으로, 로봇의 비전 입력을 확대하고, 새로운 비주얼 인코더를 적용하며, 예측 수평을 연장합니다. 이 방법은 비디오에서 수집된 데이터로 다양한 작업을 수행하게 하며, 로봇의 작업 공간을 크게 확장합니다.

- **Performance Highlights**: iDP3는 다양한 실험에서 높은 일반화 능력을 보여주며, 실제 환경에서 접촉이 많은 조작 기술을 성공적으로 일반화할 수 있음을 입증했습니다. 데이터는 단일 씬에서 수집된 정보를 기반으로 하여, 여러 실제 시나리오에서 효과적인 성능을 발휘합니다.



### Semantic Image Inversion and Editing using Rectified Stochastic Differential Equations (https://arxiv.org/abs/2410.10792)
Comments:
          Preprint

- **What's New**: 본 논문은 Generative 모델에서 이미지의 변환과 이를 재구성하기 위한 Inversion 기법을 다룹니다. 새로운 Rectified Flow (RF) 모델을 사용하여 Diffusion Models (DMs)의 한계를 극복하고, 이미지 변환에서 질적 향상을 목적으로 합니다.

- **Technical Details**: Rectified Flows (RFs)를 사용한 inversion은 Linear Quadratic Regulator (LQR) 문제를 통해 동적 최적 제어(dynamic optimal control)를 적용하여 이루어집니다. 기존의 reverse Stochastic Differential Equation (SDE) 대신, Ordinary Differential Equation (ODE)을 활용함으로써 효율성을 높였습니다.

- **Performance Highlights**: 제안된 RF inversion 방법은 stroke-to-image 생성 및 이미지 편집 작업에서 기존 방법보다 89% 더 우수한 photo realism을 달성하며, LSUN-bedroom 데이터셋에서 fidelity(신뢰도) 기준으로 4.7%, realism(현실감) 기준으로 13.8% 향상되었습니다.



### Enhancing JEPAs with Spatial Conditioning: Robust and Efficient Representation Learning (https://arxiv.org/abs/2410.10773)
Comments:
          NeurIPS 2024 Workshop on Self-Supervised Learning - Theory and Practice. Comments welcome!

- **What's New**: IJEPA (Image-based Joint-Embedding Predictive Architecture)는 Masked Autoencoder (MAE) 대신 사용할 수 있는 representation learning을 위한 새로운 접근 방식을 제안합니다. IJEPA는 input space가 아닌 latent space에서 예측을 수행하여 유용한 semantic 정보를 캡처합니다. 기존의 JEPA들은 context와 target windows의 설계에 의존하며, 이에 따라 제안된 수정된 구조인 Encoder Conditioned JEPAs (EC-JEPAs)가 소개되었습니다.

- **Technical Details**: IJEPA는 Masked Image Modeling (MIM)을 활용하여 unlabelled data로부터 self-supervised 방식으로 representations를 학습합니다. JEPAs는 context와 target windows의 size와 거리를 세심하게 조정해야 하며, EC-JEPAs는 context encoder와 target encoder를 조건화하여 식별성과 robust성을 향상시킵니다. 본 논문에서는 context와 target windows의 spatial 위치 정보를 사용하여 encoder들이 더욱 효과적인 features를 조정할 수 있도록 합니다.

- **Performance Highlights**: EC-JEPAs는 ImageNet, CIFAR10, CIFAR100과 같은 벤치마크 데이터셋에서 improved representational quality와 classification performance를 기록했습니다. 또한, context window 하이퍼파라미터에 대한 robust성을 향상시켰으며, pretraining 과정에서 sample-efficiency를 개선하였습니다.



### Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation (https://arxiv.org/abs/2410.10766)
- **What's New**: 모델 프리 강화 학습(Model-Free Reinforcement Learning)은 복잡하고 비구조적인 지형을 탐색할 수 있는 강력한 로봇 제어 정책을 개발하기 위한 방법으로 부각되었습니다. 본 연구에서는 환경 생성 방식에 대한 한계를 극복하고, 적응형 확산 지형 생성기(ADTG)를 도입하여 기존 훈련 환경을 다이나믹하게 확장할 수 있는 방법을 설명합니다.

- **Technical Details**: ADTG는 Denoising Diffusion Probabilistic Models를 활용하여 적응적인 지형 생성을 구현합니다. 초기 노이즈 최적화(Initial Noise Optimization)를 통해 정책의 성과에 따라 갈라진 지형을 혼합하고 생성하는 프로세스를 안내합니다. ADTG는 훈련 환경의 복잡성을 달리 조절할 수 있으며, 기존 훈련 데이터 세트에 기반하여 다양성을 증대시킵니다.

- **Performance Highlights**: ADTG로 훈련된 정책은 절차적으로 생성된 환경과 자연 환경을 모두 초월하여 더 나은 성능을 보여주었습니다. 특히, ADTG는 일반화 능력을 향상시키고 수렴 속도를 가속화하여 기존 방법들에 비해 뛰어난 결과를 보였습니다.



### Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings (https://arxiv.org/abs/2410.10744)
Comments:
          Code and pre-trained models are available at this https URL

- **What's New**: 이 논문에서는 AROS(Adversarially Robust OOD detection through Stability)라는 새로운 접근법을 제안합니다. 이 방법은 Neural Ordinary Differential Equations(NODEs)와 Lyapunov 안정성 이론을 활용하여, OOD(out-of-distribution) 탐지의 강건성을 높입니다.

- **Technical Details**: AROS는 특화된 손실 함수(loss function)를 포함하여 Lyapunov 안정성 이론을 적용합니다. 이를 통해 ID(in-distribution)와 OOD 데이터가 동적 시스템 내에서 안정한 평형점으로 수렴하도록 돕습니다. 이 방법은 특히 안정한 특성 공간 후에 직교 이진 레이어(orthogonal binary layer)를 추가하여 ID와 OOD 샘플 간의 분리를 극대화합니다.

- **Performance Highlights**: 실험 결과, AROS는 CIFAR-10과 CIFAR-100의 OOD 탐지 성능을 각각 37.8%에서 80.1%, 29.0%에서 67.0%로 개선하는 등 뛰어난 성능을 보여주었습니다.



### Both Ears Wide Open: Towards Language-Driven Spatial Audio Generation (https://arxiv.org/abs/2410.10676)
- **What's New**: 최근 확산 모델(diffusion models)이 단일 채널 오디오 생성에서 큰 성공을 거두었지만, 스테레오 오디오 생성에서의 복잡한 사운드스케이프(soundscapes)와 방향성을 제어하는 데 있어 도전과제가 계속되고 있습니다. 이 논문은 이러한 문제를 해결하기 위한 첫 번째 시도로, 대규모의 시뮬레이션 기반, GPT 보조 데이터셋인 BEWO-1M을 구축하여 다중 소스와 이동체를 포함한 사운드스케이프를 제시합니다. 또한, SpatialSonic 모델을 도입하여 더 정밀한 공간 가이던스를 제공하려 합니다.

- **Technical Details**: BEWO-1M 데이터셋은 100만 개의 오디오 샘플로 구성되어 있으며, 다양한 이동 및 다중 소스 시나리오에 대한 공간 설명을 포함합니다. SpatialSonic 모델은 공간 인지 인코더(spatial-aware encoders)와 방위 상태 행렬(azimuth state matrices)을 활용하여, 텍스트 및 이미지로부터 몰입감 있고 제어 가능한 공간 오디오를 생성하는 목적을 가지고 있습니다. 모델 학습 과정에서는 ITD(interaural time difference) 기반의 객관적 메트릭과 주관적 평가지표를 활용하여 생성된 오디오를 평가합니다.

- **Performance Highlights**: SpatialSonic 모델은 현실적인 공간 오디오를 효과적으로 생성하며, ITD 오차를 70% 줄이고, 인기 있는 모델들보다 높은 주관적 평점(opinion scores)을 기록했습니다. 본 연구에서는 대규모 데이터셋 구축과 함께, 멀티모달 공간 컨텍스트에 충실한 스테레오 오디오 생성 프레임워크를 제안하며, 이는 VR/AR 및 특정 산업 응용에 상당한 기여를 할 것으로 기대됩니다.



### Transforming Game Play: A Comparative Study of DCQN and DTQN Architectures in Reinforcement Learning (https://arxiv.org/abs/2410.10660)
Comments:
          KSU C-Day Spring 2024

- **What's New**: 본 연구는 Convolutional Neural Networks (CNNs)와 Transformer 아키텍처를 활용한 Deep Q-Networks (DQNs)의 성능을 세 가지 Atari 게임에서 비교 분석했습니다. Transformer 기반 DQNs가 상대적으로 미개척 영역임을 강조하며 DCQNs와 DTQNs의 성능 차이를 평가했습니다.

- **Technical Details**: 연구는 Arcade Learning Environment (ALE)와 OpenAI Gym을 사용해 Atari 2600 게임의 ROM에 접근했습니다. DCQN은 35-40 million parameter 범위에서 ViT 및 Projection Architectures를 사용하여 DTQN보다 속도에서 우수함을 입증했습니다. 또한, Centipede를 제외한 모든 게임에서 DCQN이 DTQN보다 더 높은 성능을 보였습니다.

- **Performance Highlights**: DCQN 모델은 전반적으로 처리 속도가 더 빠르고, 모든 게임에서 더 나은 성능을 보였으며, DTQN은 DCQN보다 2-3배 느렸습니다. 이를 통해 CNN 기반 모델의 우수성을 확인했습니다.



### VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents (https://arxiv.org/abs/2410.10594)
- **What's New**: 이 논문에서는 기존의 텍스트 기반 Retrieval-augmented generation (RAG) 시스템의 한계를 극복하기 위해 비전-언어 모델(Vision-Language Model, VLM)을 이용한 새로운 RAG 파이프라인인 VisRAG를 제안합니다.

- **Technical Details**: VisRAG는 문서를 직접 이미지로 임베딩하여 VLM을 통해 정보를 추출하는 방식으로 동작합니다. VisRAG-Ret와 VisRAG-Gen이라는 두 구성 요소로 이루어져 있으며, 이들은 각각 이미지 기반 정보 검색과 생성 기능을 수행합니다.

- **Performance Highlights**: VisRAG는 전통적인 텍스트 기반 RAG에 비해 검색 및 생성 단계 모두에서 성능이 25-39% 향상되었으며, 특히 다중 문서 처리를 효율적으로 수행할 수 있는 가능성이 확인되었습니다.



### Preserving Cardiac Integrity: A Topology-Infused Approach to Whole Heart Segmentation (https://arxiv.org/abs/2410.10551)
- **What's New**: 이 논문은 심혈관 질환(CVD) 진단을 지원하는 전체 심장 분할(Whole Heart Segmentation, WHS)을 위한 새로운 위상 보존 모듈을 도입하여, 심장 구조의 분할 품질을 개선하고자 한다. 이 모듈은 깊은 신경망에 통합되며, 3D 합성곱(convolution)에 기반한 학습된 위상 보존 필드를 사용하여 해부학적으로 타당한 분할을 실현한다.

- **Technical Details**: 제안된 방법은 심장 구조 간의 자연 제약을 전체 네트워크 훈련에 통합하고, 위상적 제약 및 배제 원칙을 위반하는 이웃 복셀에 대한 추가 손실을 통해 네트워크의 학습을 돕는다. 이를 통해, nnUNet와 같은 강력한 기본선에서 실패하는 상황에서도 올바른 분할을 수행할 수 있다.

- **Performance Highlights**: 제안된 아키텍처는 WHS++ 데이터셋에서 테스트 중 0.939의 Dice 계수를 달성하며, 전체 장면의 위상 보존을 확인하였다. 이 방법은 측정 지표인 Dice 점수, Jaccard 지수, 표면 대 표면 거리(SD), 그리고 하우스도르프 거리(HD)에서 다른 기준선들보다 우수한 성능을 보인다.



### A Novel No-Reference Image Quality Metric For Assessing Sharpness In Satellite Imagery (https://arxiv.org/abs/2410.10488)
Comments:
          10 pages, 6 figures

- **What's New**: 이 연구는 참조 이미지 없이 이미지 선명도를 평가하기 위한 새로운 노-레퍼런스(no-reference) 이미지 품질 지표를 소개합니다.

- **Technical Details**: 이 지표는 두드러진 에지 주변의 기울기의 정규화된 감쇠 비율(normalized decay rate of gradients)을 측정하여 잡음(noise), 노출(exposure), 대비(contrast), 이미지 내용(content)의 변화에 강인합니다. 이 방법은 위성 이미지에 적합하게 개발되었으며, 인공위성 군단에서의 이미지 품질 모니터링과 특성화를 지원합니다.

- **Performance Highlights**: 제안된 지표는 기존 지표들과 달리 이미지의 선명도를 객관적으로 평가할 수 있는 신뢰성 높은 도구로, 다양한 이미지 유형과 작동 조건에서도 인간의 인지에 부합하는 일관된 성능을 보여줍니다.



### Towards Reliable Verification of Unauthorized Data Usage in Personalized Text-to-Image Diffusion Models (https://arxiv.org/abs/2410.10437)
Comments:
          To appear in the IEEE Symposium on Security & Privacy, May 2025

- **What's New**: 이 논문에서는 개인화된 text-to-image diffusion 모델에서의 데이터 사용 추적 문제를 해결하기 위해 SIREN이라는 혁신적인 방법론을 제안합니다. SIREN은 데이터의 저작권 침해를 방지하기 위해 코팅(coating)을 최적화하고, 이를 개인화 과제와 관련된 피쳐로 인식하도록 함으로써 학습 가능성을 크게 향상시키는 방법을 제시합니다.

- **Technical Details**: SIREN은 인식 가능성을 되도록 유지하면서, 인간의 시각 시스템을 기반으로 한 지각적 제약과 하이퍼구 분류 기법, 가설 검증 중심의 검증 방법을 결합하여 코팅의 은폐성과 탐지 정확성을 높입니다. 이 접근법은 모델이 코팅을 학습하고 이를 생성된 이미지를 통해 검출할 수 있도록 합니다.

- **Performance Highlights**: SIREN은 5개의 최첨단 text-to-image diffusion 모델과 6개의 벤치마크 데이터세트에서 실험이 수행되었으며, 거의 모든 평가 시나리오에 대해 100%의 진짜 긍정율(true positive rates)을 기록했습니다. 또한 SIREN은 다양한 훈련 알고리즘과 모델에 대해 높은 이동 가능성을 보이며, 코팅된 데이터가 전체 훈련 세트의 소량일지라도 효과적입니다.



### PIVOT-R: Primitive-Driven Waypoint-Aware World Model for Robotic Manipulation (https://arxiv.org/abs/2410.10394)
Comments:
          Accepted to NeurIPS 2024

- **What's New**: PIVOT-R은 로봇 조작을 위한 새로운 모델로, 과거의 단순한 데이터 적합성과는 달리 태스크 관련 웨이포인트 예측에 집중하여 로봇이 사용자 지시를 더 잘 수행할 수 있게 합니다.

- **Technical Details**: PIVOT-R은 웨이포인트 인식 월드 모델(Waypoint-aware World Model, WAWM)과 경량 액션 예측 모듈을 포함합니다. WAWM은 원시 행동 파싱(primitive action parsing) 및 원시 기반 웨이포인트 예측을 수행하며, 액션 예측 모듈은 저수준(low-level) 행동 디코딩에 중점을 둡니다. 또한 비동기적 계층 실행기(Asynchronous Hierarchical Executor, AHE)를 설계하여 모델의 계산 중복성을 줄이고 실행 효율성을 개선합니다.

- **Performance Highlights**: PIVOT-R은 SeaWave 벤치마크에서 최신(open-source) 모델보다 19.45%의 평균 상대 향상을 달성하였으며, AHE를 사용한 PIVOT-R의 실행 효율성은 28배 증가하고, 성능은 2.9% 하락한 것으로 나타났습니다.



### Pubic Symphysis-Fetal Head Segmentation Network Using BiFormer Attention Mechanism and Multipath Dilated Convolution (https://arxiv.org/abs/2410.10352)
Comments:
          MMM2025;Camera-ready Version;The code is available at this https URL

- **What's New**: 본 논문에서는 PUB-FH( pubic symphysis-fetal head ) 분할을 위한 동적 쿼리 인식 희소 주의 메커니즘을 도입한 BRAU-Net을 제안합니다. 이는 기존의 정적 패턴 기반과 차별화되어 효율적인 정보를 학습할 수 있습니다.

- **Technical Details**: BRAU-Net은 U-Net 유사한 인코더-디코더 아키텍처를 채택하며, bi-level routing attention과 skip connections를 활용하여 지역-글로벌 의미 정보를 효과적으로 학습합니다. 또한, IBPE( Inverted Bottleneck Patch Expanding ) 모듈을 제안하여 업샘플링 작업 중 정보 손실을 줄입니다.

- **Performance Highlights**: BRAU-Net은 FH-PS-AoP 및 HC18 데이터셋에서 우수한 분할 성능을 입증했으며, 특히 PSFHS 챌린지에서는 7위를 기록했습니다. 이는 사전 학습 가중치 초기화 없이도 뛰어난 결과를 달성한 것입니다.



### Anatomical feature-prioritized loss for enhanced MR to CT translation (https://arxiv.org/abs/2410.10328)
- **What's New**: 이 연구에서는 의료 이미지 합성에서 국소적인 구조 세부사항의 정밀도를 향상시키기 위해 새로운 해부학적 기능 우선 손실 함수인 AFP (Anatomical Feature-Prioritized) 손실 함수를 소개합니다. 이 방법은 기존의 글로벌 이미지 재구성 방법과는 달리 임상적으로 중요한 구조에 초점을 맞추어 세밀한 이미지 재구성을 가능하게 합니다.

- **Technical Details**: AFP 손실 함수는 사전 훈련된 모델에서 추출한 특징을 이용하여 합성 및 전이 작업에서 보다 정밀한 해부학적 구조 생성을 도모합니다. 연구에서는 생성적 적대 신경망(GAN) 및 합성곱 신경망(CNN) 모델에 AFP 손실 함수를 통합하여 그 효율성을 평가하였습니다.

- **Performance Highlights**: 이 방법은 폐 MR에서 CT로 변환 및 골반 MR에서 CT 합성 작업에 적용되어 고품질 해부학적 구조 재구성을 성공적으로 수행함으로써 임상 응용에서의 효과성을 증명했습니다.



### Two-Stage Approach for Brain MR Image Synthesis: 2D Image Synthesis and 3D Refinemen (https://arxiv.org/abs/2410.10269)
Comments:
          MICCAI 2024 BraSyn Challenge 1st place

- **What's New**: 본 연구에서는 2D 슬라이스에서 MRI 이미지를 합성하고 이를 정제하는 두 단계 접근 방식을 제안합니다. 새로운 강도 인코딩(intensity encoding) 방법을 통해 합성된 MRI의 아티팩트를 최소화합니다.

- **Technical Details**: 첫 번째 단계에서는 HF-GAN 기반의 이미지 합성 방법을 사용하여 부족한 모드의 MRI 슬라이스를 합성합니다. 두 번째 단계에서는 Refiner라는 3D 정보 통합 모듈을 통해 합성 이미지를 개선합니다. Refiner는 인코더, 요소별 크로스 어텐션 모듈, 디코더로 구성되어 있습니다.

- **Performance Highlights**: 실험 결과, 제안된 강도 인코딩 방법이 합성된 MRI의 인지 품질을 개선하는 데 효과적임을 보여주었으며, Refiner를 적용했을 때 뇌 종양 분할 결과가 유의미하게 향상되었습니다.



### Generative Human Video Compression with Multi-granularity Temporal Trajectory Factorization (https://arxiv.org/abs/2410.10171)
Comments:
          Submitted to TCSVT

- **What's New**: 이 논문에서는 사람 중심 비디오 통신을 위한 새롭고 혁신적인 Multi-granularity Temporal Trajectory Factorization 프레임워크를 제안합니다. 이는 대역폭 제약이 있는 환경에서 비디오 압축의 유용성을 높이는 것을 목표로 합니다.

- **Technical Details**: 제안된 모션 팩토리제이션 전략은 고차원 시각 신호를 컴팩트한 모션 벡터로 변환하 여 효율적인 표현이 가능하도록 하고, 이러한 벡터를 더 세밀한 모션 필드로 변환하여 시각 모션 정보를 최저 비용으로 표현할 수 있게 합니다. 또한 해상도 확장 가능한 생성 모듈을 개발하여 향상된 배경 안정성을 제공합니다.

- **Performance Highlights**: 실험 결과, 제안한 방법은 최신 생성 모델 및 최첨단 비디오 코딩 표준인 Versatile Video Coding (VVC)보다 뛰어난 성능을 보여주었습니다. 특히, 'talking-face' 비디오와 'moving-body' 비디오 모두에서 객관적 및 주관적 품질 면에서 우수한 성능을 기록했습니다.



### Performance Evaluation of Deep Learning and Transformer Models Using Multimodal Data for Breast Cancer Classification (https://arxiv.org/abs/2410.10146)
Comments:
          The paper was accepted and presented in 3rd Workshop on Cancer Prevention, detection, and intervenTion (CaPTion @ MICCAI 2024)

- **What's New**: 이번 연구에서는 새로운 멀티모달 데이터셋을 수집하고 이를 활용한 딥러닝(Deep Learning, DL) 아키텍처를 제안하여 유방암(BC) 분류의 성능을 높이기 위한 접근 방식을 제공합니다.

- **Technical Details**: 논문은 디지털 유방촬영검사(4-view: L-CC, L-MLO, R-CC, R-MLO)와 방사선 보고서로 구성된 새로운 데이터셋을 기반으로 하고 있습니다. SOTA DL 아키텍처(VGG16, VGG19, ResNet34, ResNet50, MobileNet-v3, EffNet-b0,b1,b2,b3,b7, Vision Transformer (ViT))를 특징 추출기로 사용하고, 텍스트 데이터는 인공 신경망(ANN) 또는 장단기 기억 네트워크(LSTM)를 통해 처리합니다. 이미지와 텍스트 특징을 융합(fusion)하여 ANN 분류기에서 최종 분류를 수행합니다.

- **Performance Highlights**: VGG19와 ANN 조합으로 0.951의 가장 높은 정확도를 기록했으며, 정밀도(precision)에서는 0.95로 역시 가장 우수한 성능을 보였습니다. VGG16+LSTM 조합은 0.903의 민감도(sensitivity) 점수를 달성하였고, VGG19+LSTM은 F1 점수 0.931로 최상의 성능을 보였습니다. 또한 VGG16+LSTM은 0.937의 AUC(Area Under Curve) 점수를 기록하며 가장 높은 평가를 받았습니다.



### REHRSeg: Unleashing the Power of Self-Supervised Super-Resolution for Resource-Efficient 3D MRI Segmentation (https://arxiv.org/abs/2410.10097)
- **What's New**: 본 논문에서는 자원 효율적인 고해상도 세분화 프레임워크(REHRSeg)를 제안하여 저해상도(LR) 이미지를 입력으로 사용하면서도 고해상도(HR) 세분화를 달성하는 방법을 제시합니다. 이 접근 방식은 실제 임상 분야에서의 데이터 부족 문제를 해결하기 위한 새로운 접근을 제공합니다.

- **Technical Details**: REHRSeg는 셀프-슈퍼레졸루션(self-SR)을 활용하여 가짜 감독(pseudo supervision)을 제공하며, 따라서 2D 스캐닝 프로토콜로 생성된 상대적으로 쉽게 수집할 수 있는 LR 주석 이미지를 모델 훈련에 직접 사용할 수 있습니다. 본 연구의 핵심 기여 사항은 (1) 데이터를 희소하게 만드는 문제를 완화하고 (2) 불확실성 인식(super-resolution head)을 통해 ROI 경계에서의 불확실성을 인식하며, (3) 구조적 지식 증류(knowledge distillation)를 통해 세분화 및 자가 SR의 공간적 특징을 정렬하고 연결성을 강화하는 것입니다.

- **Performance Highlights**: 실험 결과, REHRSeg는 강력한 감독 없이도 고품질의 HR 세분화를 달성하며, LR 세분화 성능을 상당히 향상시키는 것으로 나타났습니다.



### The Ingredients for Robotic Diffusion Transformers (https://arxiv.org/abs/2410.10088)
- **What's New**: 이번 논문은 고용량(diffusion) Transformer 정책을 위한 중요 설계 결정을 개선하여 다양한 로봇 작업을 효율적으로 해결할 수 있는 새로운 모델인 DiT-Block Policy를 소개합니다.

- **Technical Details**: 이 연구에서는 adaptive Layer Norm (adaLN) 블록과 ResNet 이미지 토크나이저를 활용해 정책 훈련의 안정성을 높이고 멀티모달(multi-modal) 스펙에 적합하게 조정합니다. 이러한 구성 요소의 통합을 통해 SOTA 성능을 달성한 것을 강조합니다.

- **Performance Highlights**: 모델은 ALOHA 로봇에서 1500타임스텝 이상의 장기 작업을 성공적으로 수행하며, 10시간 이상의 다양하고 언어 주석이 포함된 데이터로 훈련되었을 때 성능이 크게 향상되었습니다.



### REPeat: A Real2Sim2Real Approach for Pre-acquisition of Soft Food Items in Robot-assisted Feeding (https://arxiv.org/abs/2410.10017)
- **What's New**: 이 논문은 소프트 푸드 소비를 위한 로봇 보조 급식 시스템에서 물어먹기(bite acquisition) 성능을 향상시키기 위한 REPeat라는 Real2Sim2Real 프레임워크를 제안합니다.

- **Technical Details**: REPeat 시스템은 사전 취득 행동(pre-acquisition actions)으로 푸시(push), 컷(cut), 플립(flip)과 같은 동작을 사용하여 물어먹기 동작의 성공률을 높이고, 이를 통해 소프트 푸드의 기하학을 시뮬레이션에서 재구성하는 Real2Sim 단계를 포함합니다.

- **Performance Highlights**: 15개의 다양한 접시에서 10종의 소프트 푸드 아이템으로 시스템을 평가한 결과, 물어먹기 성공률이 평균 27% 향상됨을 보였습니다.



### Leveraging Customer Feedback for Multi-modal Insight Extraction (https://arxiv.org/abs/2410.09999)
Comments:
          NAACL 2024

- **What's New**: 이 논문은 고객 피드백의 이미지와 텍스트 정보를 융합하여 행동 가능한 인사이트를 효과적으로 추출하는 새로운 다중 모달(multi-modal) 접근 방식을 소개합니다.

- **Technical Details**: 제안된 방법은 라테ント 공간(latent space)에서 이미지와 텍스트 정보를 융합하고 이미지-텍스트 기반 텍스트 디코더(image-text grounded text decoder)를 통해 관련 피드백 세그먼트를 추출합니다. 약한 지도 학습(weakly-supervised) 데이터 생성 기법을 활용하여 훈련 데이터를 생성합니다.

- **Performance Highlights**: 제안한 모델은 보지 않은 데이터에 대해 평가되었으며, 기존 기준선(baselines)을 F1 점수에서 14점 초과하여 뛰어난 성능을 보였습니다.



### Make the Pertinent Salient: Task-Relevant Reconstruction for Visual Control with Distractions (https://arxiv.org/abs/2410.09972)
- **What's New**: Segmentation Dreamer (SD)라는 새로운 방법을 제안하여 시각적 산만함이 있는 환경에서의 표현 학습을 촉진합니다. 이 방법은 이미지 관찰에서 작업 관련 구성 요소만 재구성하도록 돕는 세그멘테이션 마스크(segmentation mask)를 활용합니다.

- **Technical Details**: SD 방법은 시뮬레이션 환경에서 쉽게 접근 가능한 그라운드 트루스 마스크(ground-truth mask)를 사용하거나, 불완전한 세그멘테이션 모델을 활용하여 훈련됩니다. 특히, 세그멘테이션 예측 오류로 인한 잘못된 학습 신호를 피하기 위해 복원 손실(reconstruction loss)을 선택적으로 적용하는 전략이 포함됩니다.

- **Performance Highlights**: SD는 수정된 DeepMind Control Suite(DMC) 및 Meta-World 작업에서 더 나은 샘플 효율(sample efficiency) 및 향상된 최종 성능을 나타냅니다. 특히, 이 방법은 희소 보상(sparse reward) 작업에서 기존 방법으로 해결하기 어려운 문제를 해결할 수 있게 도와줍니다.



### HASN: Hybrid Attention Separable Network for Efficient Image Super-resolution (https://arxiv.org/abs/2410.09844)
Comments:
          Accepted by Visual Computer

- **What's New**: 최근 저사향 하드웨어 자원을 가진 환경에서 단일 이미지 초해상도(SISR) 기술에 대한 수요가 증가하고 있습니다. 이 논문은 Residual Feature Distillation을 활용하여 성능을 향상시키면서, 깊이 분리 합성곱(depthwise separable convolution)과 하이브리드 어텐션 블록(Hybrid Attention Separable Block, HASB)을 통한 경량화된 네트워크 구조를 제안합니다.

- **Technical Details**: 제안된 방법은 높은 수준의 이미지 특징을 추출하기 위해 HASB와 깊이 분리 합성곱을 결합하여 모델의 저장 용량 및 계산 비용을 줄입니다. 또한 Warm-Start Retraining Strategy를 채택하여 모델의 잠재력을 극대화하고, Geometric Self-ensemble Strategy를 통해 추론 성능을 향상시킵니다.

- **Performance Highlights**: 제안된 네트워크는 기존의 최신 기술(state-of-the-art, SOTA)과 비교해 PSNR 및 SSIM 지표에서 유사한 성능을 유지하면서, 매개변수 수와 FLOPs(부동 소수점 연산 수)를 줄여 더 작은 모델 크기와 낮은 계산 복잡성을 달성합니다.



### EG-SpikeFormer: Eye-Gaze Guided Transformer on Spiking Neural Networks for Medical Image Analysis (https://arxiv.org/abs/2410.09674)
- **What's New**: EG-SpikeFormer는 스파이킹 신경망(Spiking Neural Networks, SNN)을 이용하여 의료 진단에 적합한 새로운 하이브리드 모델입니다. 시선 정보(eye-gaze data)를 통합하여 모델이 진단적으로 관련된 영역에 집중할 수 있도록 설계되었습니다.

- **Technical Details**: EG-SpikeFormer는 Leaky Integrate-and-Fire (LIF) 뉴런을 사용하여 특징 추출을 향상시키며, convolutional 및 transformer 기반 SNN 블록을 통합하여 공간적 및 시간적 특징을 최적화합니다. 이 모델은 시선 정보를 훈련 데이터로 활용하여 관련 질병 영역에 대한 주의를 집중하도록 학습합니다.

- **Performance Highlights**: EG-SpikeFormer는 두 개의 공개 의료 데이터셋에서 에너지 효율성 및 진단 정확성에서 우수한 성능을 보여주었으며, 전통적인 AI 모델에서 자주 발생하는 단기 학습(shortcut learning)의 문제를 효과적으로 해결합니다.



### Unique MS Lesion Identification from MRI (https://arxiv.org/abs/2410.09639)
Comments:
          5 pages, 5 figures, submitted to SPIE medical imaging conference

- **What's New**: 이 연구는 다발성 경화증(multiple sclerosis, MS)에서 백질 병변(white matter lesions, WMLs)의 고유 식별(unique identification)에 관한 방법론을 제시합니다. 제안된 알고리즘은 기존 방법들보다 더 많은 병변을 정확히 식별하고, 융합된(confluent) 병변을 효과적으로 분리하며, 주어진 확률 맵(probability map)에서 총 병변 부피(total volume)를 정확히 포착합니다.

- **Technical Details**: 제안된 방법은 Hessian matrix 계산을 통해 lesion probability maps에서 각각의 유일한 병변의 부피를 추정합니다. 이 과정에서 Random Walker 알고리즘을 사용하여 병변이 있는 조직을 유일한 병변 중심과 연결합니다. 데이터는 MICCAI MS segmentation challenge dataset을 사용하였으며, 다중 대비(multi-contrast) 이미지를 처리하여 높은 정확도의 병변 식별 성능을 보입니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 15명의 MS 환자에서 기존의 Dworkin 방법에 비해 더 많은 병변을 식별하였고, 병변 크기가 작거나 낮은 확률의 병변에서도 우수한 성능을 발휘했습니다. 또한, 총 병변 부피 또한 Dworkin 방법보다 정확하게 측정되었습니다. 이러한 결과는 제안된 알고리즘이 MS 병변 분석에 있어 임상적으로 유의미한 통계 제공이 가능함을 시사합니다.



### Exploring Behavior-Relevant and Disentangled Neural Dynamics with Generative Diffusion Models (https://arxiv.org/abs/2410.09614)
- **What's New**: 이 연구는 BeNeDiff라는 방법을 통해 행동 데이터와 신경 활동 간의 관계를 심층적으로 탐구하는 새로운 접근 방식을 제안합니다. 이는 특히 다양한 행동을 인코딩하는 신경 패턴을 명확하게 나타낼 수 있다는 점에서 주목할 만합니다.

- **Technical Details**: BeNeDiff는 행동 통찰을 포함하는 잠재 변수 모델을 사용하여 신경 하위 공간(neural subspace)을 구분하고, 최신의 생성형 확산 모델(generative diffusion models)을 통해 행동 비디오를 합성합니다. 이 과정에서 각 잠재 요인(latent factor)의 신경 역학(neural dynamics)을 인터프리트할 수 있습니다.

- **Performance Highlights**: 이 방법은 머리에 고정된 쥐에서 다중 세션을 통해 수집한 가컬슐 이미지 데이터에 대해 검증되었으며, 결과적으로 신경 하위 공간의 높은 구분성과 신경 재구성 품질을 자랑합니다. 또한, 활성화된 잠재 요인들의 신경 역학은 관심 행동의 해석 가능한 정량화를 제공합니다.



### MMAD: The First-Ever Comprehensive Benchmark for Multimodal Large Language Models in Industrial Anomaly Detection (https://arxiv.org/abs/2410.09453)
Comments:
          The code and data are available at this https URL

- **What's New**: 본 논문에서는 산업 이상 감지(Industrial Anomaly Detection)에 대한 첫 번째 다면적 대규모 언어 모델(Multimodal Large Language Models, MLLMs) 벤치마크인 MMAD(Multimodal Model Assessment in Detection)를 제안합니다. 39,672개의 질문을 포함한 새로운 데이터셋을 생성하였으며, MLLMs의 성능을 정량적으로 평가했습니다.

- **Technical Details**: 이번 연구에서 다양한 MLLMs의 성능을 평가하기 위해 7개 주요 하위 작업을 정의하고, 시각적 주석과 언어 상호작용을 통합하여 세밀한 의미 주석을 생성하는 새로운 파이프라인을 설계했습니다. 최종적으로 8,366개의 샘플을 수집하고, MLLMs의 성능을 평가하기 위한 39,672개의 객관식 질문을 생성했습니다.

- **Performance Highlights**: 실험 결과, GPT-4o 모델이 74.9%의 평균 정확도로 가장 높은 성능을 보였으나, 이는 산업의 요구 수준에 미치지 못하는 결과입니다. 현재 MLLMs는 산업 이상 및 결함 관련 질문에 대한 응답에서 여전히 상당한 개선 여지가 있음을 보여주었습니다.



### Diabetic retinopathy image classification method based on GreenBen data augmentation (https://arxiv.org/abs/2410.09444)
- **What's New**: 이 논문은 당뇨병성 망막병증(Diabetes Retinopathy, DR) 이미지를 진단하기 위한 인공지능 기반의 분류 방법을 제안하고 있습니다. 핵심은 새로운 데이터 증강 방법인 GreenBen을 사용하는 것입니다.

- **Technical Details**: GreenBen은 망막 이미지에서 녹색 채널의 그레이스케일 이미지를 추출한 후 Ben 향상을 수행하는 방식입니다. 논문에서는 당뇨병 황반 부종(Diabetes Macular Edema, DME)이 DR과 밀접한 관련이 있음을 고려하여, 다중 과제 학습(multi-task learning)과 주의 모듈(attention module)을 기반으로 DR과 DME의 공동 분류 프레임워크를 구성했습니다.

- **Performance Highlights**: 세 가지 공개 데이터셋에서 광범위한 실험을 진행한 결과, GreenBen은 다른 데이터 증강 방법에 비해 DR 분류 결과에서 안정적이고 유의미한 개선을 보여주었으며, 모델 분류의 정확도가 10% 향상되었습니다.



### An Expeditious Spatial Mean Radiant Temperature Mapping Framework using Visual SLAM and Semantic Segmentation (https://arxiv.org/abs/2410.09443)
Comments:
          Accepted by 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshop

- **What's New**: 이 논문에서는 기존의 평균 복사 온도(Mean Radiant Temperature, MRT) 측정 방식을 개선하기 위해 시각적 동시 위치 확인 및 매핑(Visual SLAM)과 시맨틱 분할(Semantic Segmentation) 기술을 활용한 새로운 MRT 측정 프레임워크를 제안합니다.

- **Technical Details**: 제안된 프레임워크는 저비용 카메라 배열을 활용하고 Grounded SAM을 이용하여 건물 표면의 열적 특성을 자동으로 추출합니다. 이 시스템은 thermal infrared (TIR) 카메라와 RGB-D 카메라, 트래킹 카메라로 구성되어 있으며, 실제 실내 환경에서 vSLAM 시스템을 통해 3D 열 점 군을 생성합니다. 이 과정에서 Monte Carlo 기반의 레이 트레이싱 알고리즘을 사용하여 시야 계수를 계산하고, 이는 MRT 계산에서 중요한 역할을 합니다.

- **Performance Highlights**: 실험 결과, 제안된 프레임워크는 기존 방법보다 더 빠르고 효율적인 MRT 측정을 가능하게 하며, 실험을 통해 외부 온도와 창문 위치가 MRT의 공간 분포에 미치는 영향을 확인했습니다. 또한, 측정 소요 시간은 약 343초로 짧았으며, 이로 인해 정적 상태에서의 MRT 측정 결과를 얻을 수 있었습니다.



### Exact Aggregation for Federated and Efficient Fine-Tuning of Foundation Models (https://arxiv.org/abs/2410.09432)
Comments:
          RS and KP contributed equally to this work: 18 Pages, 9 Figures, and 8 Tables. Another version of the paper accepted at NeurIPS 2024 Workshop on Fine-Tuning in Modern Machine Learning: Principles and Scalability

- **What's New**: 본 논문은 페더레이티드 학습 환경에서 Low-Rank Adaptation (LoRA)을 적용할 때 발생하는 문제를 해결하기 위해 Federated Exact LoRA (FedEx-LoRA) 기법을 제안합니다. 이 방법은 사전 훈련된 가중치 행렬에 잔여 오류 항을 추가하여 정확한 업데이트를 달성합니다.

- **Technical Details**: FedEx-LoRA는 LoRA의 효율성을 유지하며, 기존의 페더레이티드 평균화 방법에서 발생하는 부정확한 집합을 보완합니다. 제안된 방법은 추가 학습없이 각 집합 단계에서 오류 항을 도입하며, 통신 및 계산 오버헤드를 최소화하는 통신 프로토콜을 포함합니다.

- **Performance Highlights**: NLU와 NLG 작업에서 FedEx-LoRA는 기존의 최첨단 방법들에 비해 일관된 성능 향상을 보여주었으며, 페더레이티드 평균화와 이상적인 업데이트 간의 편차를 정량화하는 철저한 분석을 제공합니다.



### Neurally Integrated Finite Elements for Differentiable Elasticity on Evolving Domains (https://arxiv.org/abs/2410.09417)
Comments:
          16 pages, 21 figures

- **What's New**: 이 논문은 점진적으로 진화하는 암묵적 함수(implicit function)로 정의된 영역을 위해 효율적이고 강인하며 모양(shape)과 재료(material)에 대해 미분 가능한 탄성 시뮬레이터를 제안합니다. 이 시뮬레이터는 이미지 관측으로부터 기하학을 회복하는 3D 재구성(3D reconstruction) 응용에 의해 동기가 부여되었습니다.

- **Technical Details**: 본 연구의 핵심 기술 혁신은 견고한 수치 적분(numerical integration)을 위한 사각점(quadrature point)에 맞추기 위해 소규모 신경망(neural network)을 훈련시키는 것입니다. 혼합 유한 요소법(Mixed Finite Element formulation)과 결합하면, 기본 암묵적 표면의 진화(evolution)와 그 탄성 응답(elastic response)을 연결하는 부드럽고 완전 미분 가능한 시뮬레이션 모델이 생성됩니다.

- **Performance Highlights**: 본 연구에서는 암묵적 객체의 전방 시뮬레이션(forward simulation), 편집 중 3D 모양의 직접 시뮬레이션(direct simulation), 및 차별화 렌더링(differentiable rendering)과 함께 새로운 물리 기반 모양 및 토폴로지 최적화(optimization)에서 접근 방식의 효과를 입증하였습니다.



### Two Heads Are Better Than One: A Multi-Agent System Has the Potential to Improve Scientific Idea Generation (https://arxiv.org/abs/2410.09403)
- **What's New**: 이 논문에서는 과학 연구에서의 협동적 본질을 모방하기 위해 대규모 언어 모델(LLM)을 기반으로 한 다중 에이전트 시스템인 VirSci를 제안합니다. 이 시스템은 연구 아이디어를 공동으로 생성하고 평가하며 정제하는团队(팀)을 구성하여 자동화된 과학 발견을 지원할 수 있습니다.

- **Technical Details**: VirSci는 다음의 다섯 단계를 통해 연구 아이디어 생성 과정을 시뮬레이션합니다: (1) Collaborator Selection, (2) Topic Selection, (3) Idea Generation, (4) Idea Novelty Assessment, (5) Abstract Generation. 이 과정에서 팀장은 연구 협업 네트워크를 기반으로 적절한 협력자를 선정하고 과거 논문 데이터베이스를 활용해 새로운 아이디어 생성을 유도합니다. 또한, 단계마다 협력자들이 성과를 향상시키기 위한 토론 메커니즘을 구현합니다.

- **Performance Highlights**: 포괄적인 실험 결과, VirSci는 단일 에이전트 실행 방법에 비해 평균 13.8%의 정렬 수준 향상과 44.1%의 현대 연구에 대한 잠재적 영향 향상을 보이며, 이는 과학 아이디어의 혁신적인 생성을 위한 강력한 도구로서의 가능성을 보여줍니다.



### MITA: Bridging the Gap between Model and Data for Test-time Adaptation (https://arxiv.org/abs/2410.09398)
- **What's New**: 이번 연구에서는 기존의 Test-Time Adaptation(TTA) 방법들이 통계적 패턴에 의존하는 경향으로 인해 복잡한 실세계 시나리오에서의 성능 저하 문제를 다루고 있습니다. 이에 대한 해결책으로 'Meet-In-The-Middle based Test-Time Adaptation(MITA)'를 제안하며, 이는 모델과 데이터를 상호 조정하는 새로운 접근 방식을 소개합니다.

- **Technical Details**: MITA는 에너지 기반 최적화를 도입하여 모델과 데이터를 반대 방향에서 상호 적응하도록 유도합니다. 특히, 모델 적응에는 Contrastive Divergence을 사용하고, 데이터 적응에는 Langevin Dynamics를 통해 각 인스턴스의 동적 자가 업데이트를 구현합니다. 이러한 방식으로 MITA는 모델과 데이터 간의 간극을 효과적으로 메꿉니다.

- **Performance Highlights**: MITA는 Outlier, Mixture, Pure의 세 가지 시나리오에서 SOTA(SOTA: State Of The Art) 방법들보다 우수한 성능을 보이며, Outlier에서는 최대 10.57%의 성능 향상, Mixture에서는 4.68%의 향상을 달성하였습니다. 이로 인해 MITA는 실제 어플리케이션에서 일반화 능력을 크게 높일 수 있는 잠재력을 보유하고 있습니다.



### ExpGest: Expressive Speaker Generation Using Diffusion Model and Hybrid Audio-Text Guidanc (https://arxiv.org/abs/2410.09396)
Comments:
          Accepted by ICME 2024

- **What's New**: 이번 논문에서는 음성과 텍스트 정보를 동기화하여 표현력 있는 전신(whole-body) 제스처를 생성할 수 있는 새로운 프레임워크인 ExpGest를 소개합니다. 기존의 제스처 생성 방법들은 주로 상체 제스처에 집중하였고, 음성 내용, 감정, 그리고 이동성을 충분히 반영하지 못했습니다.

- **Technical Details**: ExpGest는 확산 모델(diffusion model)에 기반하여, 입력 텍스트와 오디오 또는 그 조합을 사용하여 표현력 있고 다양한 고품질 스피커 생성을 안내합니다. 이 모델은 먼저 음성의 멜로디와 의미를 결합하여 제스처를 생성하며, 각 움직임의 특성을 보존할 수 있도록 다양한 데이터 표현 방법을 통합합니다.

- **Performance Highlights**: 모델 실험 결과, ExpGest는 기존의 최첨단 모델들보다 더 표현력 있고 자연스러우며 조절 가능한 전신 제스처를 생성하는 능력을 보입니다. 특히, 음악적 변화를 따른 손과 팔의 움직임의 민감도를 분석하여 제스처 생성을 최적화하였으며, 이는 감정 다양성을 향상시키는 데 기여합니다.



### MOZART: Ensembling Approach for COVID-19 Detection using Chest X-Ray Imagery (https://arxiv.org/abs/2410.09255)
Comments:
          This paper was originally intended to be published as part of my this http URL. graduation project in Electrical and Electronics Engineering at the University of Khartoum in 2021. However, due to political and economic instability, and most recently, the outbreak of conflict in Sudan in April 2023, the publication process was significantly delayed. But yeah, better late than never

- **What's New**: COVID-19 진단을 위한 새로운 AI 기반의 MOZART 프레임워크가 제안되었습니다. 이 프레임워크는 기존의 CNN 모델보다 높은 정확도를 달성하며, COVID-19 관련 폐 이상을 비침습적으로 식별하는 데 효과적입니다.

- **Technical Details**: MOZART란 이름의 앙상블 학습(ensemble learning) 접근 방식으로, 세 가지 CNN 아키텍처(InceptionV3, Xception, ResNet50)를 훈련하여 각 모델의 예측을 조합합니다. 데이터셋은 COVID-19 이미지 3,616장과 건강한 이미지 3,616장으로 구성되어 있으며, 70%는 훈련, 20%는 검증, 10%는 테스트에 사용되었습니다. MOZART는 최종 예측을 위해 얕은 신경망(shallow neural network)을 활용합니다.

- **Performance Highlights**: MOZART 프레임워크는 99.17%의 정확도와 99.16의 F1 점수를 기록하여 기존 개별 CNN 모델보다 우수한 성능을 보여주었습니다. MOZART1은 false positive(위양성)를 최소화하는 데 뛰어나고, MOZART2는 false negative(위음성)를 줄이는 데 효과적입니다.



### Fast Data-independent KLT Approximations Based on Integer Functions (https://arxiv.org/abs/2410.09227)
Comments:
          19 pages, 10 figures, 7 tables

- **What's New**: Karhunen-Loève 변환(KLT)의 저복잡도 데이터 독립적인 근사값을 제안. 이 변환은 주로 이미지 및 비디오 컴프레션에서 사용되며, 다양한 반올림(round-off) 함수를 사용하여 설계됨.

- **Technical Details**: 제안된 변환은 $N=8$의 블록 길이에 중점을 두고, 데이터 의존성이 없으며, 평균 제곱 오차를 최소화하여 효율적인 이미지 인코딩을 위한 저복잡도 방법론을 제시. 고전 성능 기준과 비교하여 기존 KLT 및 문헌에서 문서화된 근사값보다 우수한 성능 보장.

- **Performance Highlights**: 제안된 변환은 특히 특정 압축 비율에서 정확한 KLT를 초과하는 성능을 보였으며, FPGA 하드웨어 구현 메트릭의 평가에서도 장점을 입증하여 실용적인 이미지 인코딩 애플리케이션에 적용 가능성을 시사.



### When Graph meets Multimodal: Benchmarking on Multimodal Attributed Graphs Learning (https://arxiv.org/abs/2410.09132)
- **What's New**: 이 논문은 Multimodal Attribute Graph Benchmark (MAGB)를 제안하며, 다양한 도메인에서의 MAG에 대한 대규모 및 도전적인 벤치마크 데이터셋을 제공합니다.

- **Technical Details**: MAG는 노드(엔티티)의 다양한 모달리티(텍스트, 이미지)에서 기인하는 속성 지식과 노드 간의 복잡한 상호작용으로부터 제공되는 토폴로지 지식의 통합을 기반으로 하는 그래프입니다. 이 연구는 GNN(Graph Neural Networks)과 PLM(Pre-trained Language Models)을 이용한 MAG 표현 학습에서 다중 모달 속성과 그래프의 중요성을 탐구합니다.

- **Performance Highlights**: MAGB 데이터셋에서 여러 학습 패러다임(GNN 기반 및 PLM 기반)으로 수행한 광범위한 실험을 통해 다중 모달 속성과 그래프 토폴로지 간의 내재적 관계를 밝혀내고, 향후 MAG 연구에 대한 신뢰할 수 있는 벤치마크를 제공합니다.



### Artificial intelligence techniques in inherited retinal diseases: A review (https://arxiv.org/abs/2410.09105)
- **What's New**: 이 리뷰 논문은 유전성 망막 질환(Inherited retinal diseases, IRDs)에서 인공지능(AI)의 역할과 활용 가능성을 종합적으로 살펴보며, 현장에서의 의료 적용을 위한 구조화된 경로를 제시합니다.

- **Technical Details**: 본 논문에서는 IRDs의 진단 및 관리에서 AI 기술, 특히 머신러닝(machine learning) 및 딥러닝(deep learning)을 활용한 기법을 탐구합니다. 합성곱 신경망(convolutional neural networks, CNNs)의 효과성을 강조하며, AI가 OCT 및 다양한 이미징 모달리티( modalities)에서 IRDs를 검출하고 분류하는 데 활용되고 있음을 설명합니다.

- **Performance Highlights**: AI 모델은 IRDs 진단을 위한 정확한 이미지 분할 및 특성 추출을 통해 신속하고 신뢰할 수 있는 평가를 제공할 수 있으며, 이는 임상 의사결정을 위한 중요한 도구가 될 수 있습니다. 그러나 AI의 임상 적용에는 여전히 훈련 데이터 셋의 품질, 일반화 능력, 그리고 설명 가능한 AI의 필요성과 같은 여러 도전 과제가 존재합니다.



### Alignment Between the Decision-Making Logic of LLMs and Human Cognition: A Case Study on Legal LLMs (https://arxiv.org/abs/2410.09083)
- **What's New**: 이 논문에서는 법률 분야의 대규모 언어 모델(LLM)의 의사결정 논리와 인간 인지 사이의 정합성을 평가하는 방법을 제안합니다. 기존의 언어 생성 결과 평가 방식과는 달리, 우리는 LLM의 출력을 뒷받침하는 세부 의사결정 논리의 정확성을 평가하고자 합니다.

- **Technical Details**: 논문에서는 LLM의 상호작용을 원시 의사결정 논리로 정량화하며, 이를 통해 정합성 평가를 위한 새로운 지표를 설계하였습니다. 이와 관련된 상호작용은 AND-OR 상호작용의 개념을 포함하여 LLM의 신뢰 점수와 인간의 법적 판단 간의 일치를 평가하는 데 사용됩니다. LLM이 생성한 문장 속의 입력 토큰 간 비선형 관계를 측정합니다.

- **Performance Highlights**: 실험 결과, 법률 LLM은 높은 예측 정확도를 보임에도 불구하고, 내부 추론 논리의 상당 부분에서 주목할 만한 문제를 포함하고 있다는 사실이 확인되었습니다. 이는 LLM의 의사결정 논리와 인간의 인지 간의 정합성이 요구된다는 것을 보여줍니다.



### Gait Sequence Upsampling using Diffusion Models for Single LiDAR Sensors (https://arxiv.org/abs/2410.08680)
- **What's New**: 이번 연구는 LiDAR 기반 보행 인식에서 희소한 보행 점 구름 데이터를 위한 업샘플링 모델인 LidarGSU를 제안하여 기존 인식 모델의 일반화 능력을 개선하는 것을 목표로 한다.

- **Technical Details**: 제안된 방법은 확산 확률 모델(difffusion probabilistic models, DPMs)을 활용하여 희소 순차 주행자 점 구름에 적용되며, 비디오를 비디오로 변환하는 접근 방식을 통해 결측치의 복원을 수행한다. 또한, 시간 순차적 보행 모습의 일관성을 보장하기 위해 비디오 기반 노이즈 예측 모델을 활용한다.

- **Performance Highlights**: SUSTeck1K 데이터셋을 포함한 두 개의 데이터셋에서 실험을 진행하여 제안된 모델의 생성 품질과 인식 성능의 개선을 증명하였다. 실험 결과, LidarGSU 모델은 다양한 점 구름 밀도에서의 보행 인식 작업의 성능 격차를 줄이는 데 도움을 주었다.



New uploads on arXiv(cs.AI)

### JudgeBench: A Benchmark for Evaluating LLM-based Judges (https://arxiv.org/abs/2410.12784)
Comments:
          preprint

- **What's New**: 본 논문에서는 LLM 기반의 평가자(judges)의 신뢰성을 점검하기 위한 새로운 평가 프레임워크를 제안합니다. 이를 통해 기존의 인간 평가자와 비교할 수 있는 JudgeBench라는 벤치마크를 소개합니다.

- **Technical Details**: JudgeBench는 지식(knowledge), 추론(reasoning), 수학(math), 코딩(coding) 등의 난이도 있는 응답 쌍을 평가하는 새로운 벤치마크입니다. 기존의 데이터셋을 활용하여 난이도 높은 응답 쌍으로 변환하는 파이프라인을 활용합니다.

- **Performance Highlights**: JudgeBench는 이전 벤치마크에 비해 훨씬 더 큰 도전을 제시하며, 많은 강력한 모델들이 무작위 추측(random guessing)보다 조금 더 나은 성과를 낼 뿐임을 보여주었습니다. 이는 LLM 기반 평가자의 평가 과정에서의 신뢰성을 높이는 데 기여할 것으로 기대됩니다.



### Explainable Moral Values: a neuro-symbolic approach to value classification (https://arxiv.org/abs/2410.12631)
Comments:
          Published at ESWC24 Satellite Event

- **What's New**: 이번 연구는 온톨로지 기반 추론(ontology-based reasoning)과 머신러닝(Machine Learning) 기술을 통합하여 설명 가능한 가치 분류(explainable value classification)를 탐구합니다. Moral Foundations Theory에 기반한 가치의 온톨로지적 공식화를 사용하고, sandra라는 신경-상징적(reasoner) 추론기를 통해 특정 문장이 만족하는 가치 묘사를 추론합니다. 이 과정에서 문장과 그 구조적 표현은 오픈소스 대형 언어 모델(Large Language Model)을 이용해 자동 생성됩니다.

- **Technical Details**: 이 연구에서는 Moral Foundations Theory를 이론적 프레임워크로 활용하여 가치 분류를 수행합니다. sandra neuro-symbolic reasoner는 DnS Ontology Design Pattern을 사용하여 다양한 관점에서 문장의 의미를 해석합니다. 실험을 통해 추론만을 바탕으로 한 분류 방식이 복잡한 접근 방식에 근접한 성능을 보여주며, 문장의 감정 극성과 가치 간의 상관관계도 확인했습니다. 또한, 우리의 방법은 해석 가능성을 보장하여 분류 결정에 대한 정당성을 제공합니다.

- **Performance Highlights**: 우리의 접근 방식은 이유 추론과 배급 의미 방법(distributional semantics methods)의 결합을 통해 모든 기준선(baseline)을 초과하는 성과를 보여줍니다. 이 방식은 LLM 기반 방법에도 뒤지지 않는 성과를 보이며, 해석 가능성을 손상시키지 않고도 성능 향상을 이끌어냈습니다. 또한, 우리는 이론 기반 가치 분류의 잠재력을 탐색할 수 있는 시각화 도구를 구축하여 공개했습니다.



### Counterfactual Effect Decomposition in Multi-Agent Sequential Decision Making (https://arxiv.org/abs/2410.12539)
- **What's New**: 본 연구에서는 다중 에이전트 마르코프 결정 프로세스에서 반사실(outcome) 결과를 설명하는 데 있어 새로운 접근법을 제시합니다. 특히, 에이전트의 행동이 실제 시나리오의 결과에 미치는 반사실 효과를 환경 동태 및 에이전트 행동에 미치는 영향으로 설명하려고 합니다.

- **Technical Details**: 우리는 새로운 인과적(causal) 설명 공식을 도입하여 반사실 효과를 계량화합니다. 이는 각 에이전트 및 상태 변수를 효과에 대한 기여도를 나타내는 점수로 분해합니다. 연구는 에이전트의 행동이 초래하는 반사실 효과를 순차적으로 에이전트 행동을 통해 전파되는 효과와 상태 전이(state transition)를 통해 전파되는 효과로 나누어 설명합니다. 또한, Shapley value를 사용하여 에이전트 특정 효과를 개별 에이전트에 귀속시키며, 구조 보존 개입(structure-preserving interventions)을 통해 상태 변수의 기여를 분석하는 방법을 제안합니다.

- **Performance Highlights**: 실험을 통해 LLM 보조 에이전트가 있는 Gridworld 환경과 패혈증 관리 시뮬레이터에서 우리의 분해 접근법이 해석 가능성을 가진다는 것을 입증하였습니다.



### Benchmarking Defeasible Reasoning with Large Language Models -- Initial Experiments and Future Directions (https://arxiv.org/abs/2410.12509)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 본 연구는 대규모 언어 모델(LLMs)의 비모노토닉 추론(nonmonotonic reasoning) 능력과 한계를 이해하기 위한 기준을 제시합니다.

- **Technical Details**: 기존의 결함 규칙(defeasible rule) 기반 추론 기준을 수정하여 LLMs에 적합한 텍스트로 번역된 결함 규칙을 사용했습니다. 연구에서는 ChatGPT를 사용하여 비모노토닉 규칙 기반 추론에 대한 초기 실험을 수행하고, 결함 논리(defeasible logic)에 의해 정의된 추론 패턴과 비교했습니다.

- **Performance Highlights**: ChatGPT가 비모노토닉 추론 과제에서 어떻게 성능을 발휘하는지를 평가하며, 기존의 결함 논리 패턴들과 비교합니다.



### Revealing the Barriers of Language Agents in Planning (https://arxiv.org/abs/2410.12409)
Comments:
          Work in Progress

- **What's New**: 이 논문에서는 인공지능의 자율 계획(autonomous planning) 분야에서 현재 언어 에이전트(language agents)가 인간 수준의 계획 능력에 도달하지 못하는 이유를 분석합니다.

- **Technical Details**: 연구에서는 feature attribution study를 적용하여 계획을 저해하는 두 가지 주요 요인을 식별했습니다. 첫 번째는 제약 조건(constraints)의 제한된 역할이고, 두 번째는 질문(question)의 감소하는 영향입니다. 이러한 요인들로 인해 현재 사용되고 있는 전략들이 문제를 완전히 해결하지 못하고 있다는 점도 발견했습니다.

- **Performance Highlights**: 현재 최첨단 추론 모델인 OpenAI o1은 복잡한 실제 계획 기준에서 15.6%의 성과를 달성했으며, 이는 인간 수준의 계획 접근 방식에는 여전히 큰 격차가 있음을 나타냅니다.



### A Fast Convoluted Story: Scaling Probabilistic Inference for Integer Arithmetic (https://arxiv.org/abs/2410.12389)
- **What's New**: 본 논문은 신경 기호 AI(neurosymbolic AI)의 문제를 해결하기 위해 텐서 조작(tensor manipulations)을 활용한 정수 값 확률 변수(integer-valued random variables)에 대한 선형 산술(linear arithmetic)의 새로운 형식을 제안합니다.

- **Technical Details**: 우리는 두 개의 정수 값 확률 변수를 덧셈할 때 로그 도메인(log-domain)에서의 빠른 푸리에 변환(fast Fourier transform) 적응을 통해 수행할 수 있음을 관찰하였습니다. 이를 통해 텐서 연산(tensor operations)을 활용한 미분 가능한 데이터 구조(differentiable data structure)를 얻었습니다.

- **Performance Highlights**: 실험적 검증을 통해, 확률적 선형 정수 산술(probabilistic linear integer arithmetic)을 텐서화(tensorising)하고 빠른 푸리에 변환을 활용함으로써 추론(inference) 및 학습(learning) 시간에서 여러 차원 수치(state of the art)를 향상시킬 수 있음을 보여주었습니다.



### ShapefileGPT: A Multi-Agent Large Language Model Framework for Automated Shapefile Processing (https://arxiv.org/abs/2410.12376)
- **What's New**: ShapefileGPT는 LLM (Large Language Model)에 기반한 혁신적인 프레임워크로, Shapefile 관련 작업의 자동화를 위해 설계되었습니다.

- **Technical Details**: ShapefileGPT는 멀티 에이전트 구조 (multi-agent architecture)를 사용하고, 플래너 에이전트 (planner agent)는 작업 분해 및 감독을 담당하며, 작업자 에이전트 (worker agent)는 실제로 작업을 실행합니다. 이를 위해 Shapefile 처리를 위한 전문 함수 라이브러리를 개발하고, API 문서를 제공하여 작업자 에이전트가 함수를 호출하여 Shapefile을 효율적으로 처리할 수 있도록 했습니다.

- **Performance Highlights**: ShapefileGPT는 벤치마크 데이터셋에 대해 95.24%의 작업 성공률을 달성하며, 전통적인 LLM과 비교하여 복잡한 벡터 데이터 분석 작업을 효과적으로 처리합니다.



### PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking (https://arxiv.org/abs/2410.12375)
- **What's New**: PRefLexOR (Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning)는 선호 최적화(preference optimization)와 강화 학습(Reinforcement Learning) 개념을 결합하여 모델이 반복적인 추론 개선을 통해 스스로 학습할 수 있도록 합니다.

- **Technical Details**: 이 논문은 다단계 추론(multi-step reasoning) 과정에서 모델이 중간 단계를 재검토하고 수정한 후 최종 출력을 생성하는 재귀 학습(recursive learning) 접근 방식을 제안합니다. 모델은 선호 응답(preferred responses)과 비선호 응답(non-preferred responses) 간의 로그 확률(log odds)을 최적화하여 정확한 결정 경로에 정렬하는 것을 배웁니다. 또한, 무작위 텍스트 조각에서 질문을 생성하고 관련 세부 정보를 맥락화하기 위해 동적 지식 그래프(dynamic knowledge graph)를 구축합니다.

- **Performance Highlights**: 3억 개의 파라미터를 가진 소형 언어 모델(small language models)에서 구현되었으며, 작은 모델도 깊이 있는 추론과 반성(reflection)을 통해 스스로를 반복적으로 학습할 수 있음을 보여줍니다. 생물 재료 과학(biological materials science) 분야에서의 다양한 사례 연구를 통해 이 방법을 증명하며, 추론 시간에 반복 샘플링을 통해 응답을 성공적으로 개선하는 다중 에이전트 재귀 자기 개선 추론(multi-agent recursive self-improving inference) 접근 방식을 구축합니다.



### Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistanc (https://arxiv.org/abs/2410.12361)
Comments:
          9 pages, 4 figures

- **What's New**: 이 논문에서는 명시적인 인간 지시 없이도 작업을 예측하고 시작할 수 있는 선제적 에이전트(proactive agents)를 개발하는 문제에 접근합니다.

- **Technical Details**: 실제 인간 활동 데이터를 수집하여 선제적 작업 예측(proactive task predictions)을 생성합니다. 이 예측은 인간 주석자에 의해 수용(accepted) 또는 거부(rejected)로 라벨링됩니다. 라벨링된 데이터는 인간 판단을 시뮬레이션하는 보상 모델(reward model)을 훈련하는 데 사용됩니다. 또한, ProactiveBench라는 6,790개의 다양한 이벤트를 포함하는 데이터셋 통합 파이프라인을 개발하였습니다.

- **Performance Highlights**: 미세 조정된(fine-tuned) 모델은 F1-Score 66.47%로 선제적으로 도움을 제공하는 능력을 평가하며, 모든 오픈 소스 및 클로즈드 소스 모델을 초월하는 성과를 보여주었습니다.



### A Prompt-Based Knowledge Graph Foundation Model for Universal In-Context Reasoning (https://arxiv.org/abs/2410.12288)
Comments:
          Accepted in the 38th Conference on Neural Information Processing Systems (NeurIPS 2024)

- **What's New**: 이번 논문에서는 다양한 지식 그래프(KG)에서의 일반화된 추론 능력을 달성하기 위해, 문맥 내 학습(in-context learning)을 이용한 프롬프트 기반 KG 기초 모델(KG-ICL)을 제안합니다. 이 모델은 다양한 KG와 추론 환경에 걸쳐 지식을 전이하고 일반화할 수 있는 기능을 갖추고 있습니다.

- **Technical Details**: KG-ICL 모델은 쿼리와 관련된 예제 사실을 중심으로 한 프롬프트 그래프(prompt graph)를 도입하여 쿼리 관계를 이해합니다. 이를 통해 새로운 실체와 관계에 대한 일반화 능력을 가진 통합 토크나이저(unified tokenizer)를 제안하고, 두 개의 메시지 패싱 신경망(message passing neural networks)을 통해 프롬프트 인코딩과 KG 추론을 수행합니다.

- **Performance Highlights**: 43개의 다양한 KG에 대한 실험 결과, KG-ICL 모델은 대부분의 데이터셋에서 기존 모델을 초과 성능을 보이며, 뛰어난 일반화 및 보편적 추론 능력을 보여줍니다. 이 모델은 높은 효율성을 갖추고 예제를 활용하는 데 강력한 성능을 발휘합니다.



### OmnixR: Evaluating Omni-modality Language Models on Reasoning across Modalities (https://arxiv.org/abs/2410.12219)
Comments:
          19 pages, 6 figures, 12 tables

- **What's New**: OmnixR는 여러 다중 모달리티(omni-modality)를 처리하는 최신 AI 모델의 성능을 평가하기 위한 새로운 벤치마크입니다. 기존의 평가 방법이 단일 또는 이중 모달리티에 한정되어 있었던 반면, OmnixR는 복잡한 비디오, 오디오, 텍스트 조합을 평가하므로, 모델의 종합적인 이해력을 테스트합니다.

- **Technical Details**: OmnixR 벤치마크는 두 가지 데이터 집합으로 구성됩니다: (1) Omni××R_{synth}: 텍스트 정보를 다양한 모달리티(오디오, 이미지, 비디오)로 변환한 합성 데이터 집합이며, (2) Omni××R_{real}: 전문가들에 의해 수집되고 주석이 달린 실제 데이터를 포함하여, 오미모달리티(omni-modality) 추론력을 평가합니다. Omnify!라는 자동화 도구를 사용하여 데이터를 생성하며, 이는 모델의 다중 모달 이해력과 추론 능력을 평가하는 데 초점을 맞춥니다.

- **Performance Highlights**: 실험 결과, 최신 OLM들은 OmnixR 질문에서 여러 모달리티 정보를 통합하여 정확한 답변을 도출하는 데 어려움을 겪었습니다. 특히, 간단한 촉진 전략(ETA prompting)을 사용하여 성능 개선 가능성을 보여주었지만, 현실적인 환경에서 오미모달 행동 불일치를 완전히 해소하기 위해 추가적인 훈련이 필요하다는 점이 드러났습니다.



### Divide-Verify-Refine: Aligning LLM Responses with Complex Instructions (https://arxiv.org/abs/2410.12207)
Comments:
          Under review

- **What's New**: 최근 연구에서 LLMs(대규모 언어 모델)가 복잡한 지침을 따라가는 데 어려움을 겪고 있다는 사실이 밝혀졌습니다. 특히, 다양한 제약 조건을 가진 지침에 대한 LLM의 적응력을 높이기 위한 방법이 아직 탐구되지 않았습니다.

- **Technical Details**: 본 논문에서는 새로운 Divide-Verify-Refine (DVR) 프레임워크를 제안합니다. 이는 (1) 복잡한 지침을 단일 제약 조건으로 나누고 적절한 도구를 준비하는 단계, (2) 도구를 사용해 응답을 철저히 검증하고 신뢰할 수 있는 피드백을 제공하는 단계, (3) 성공적인 정제를 수집하여 향후 사례에 대한 few-shot 예시로 사용하는 단계로 구성됩니다.

- **Performance Highlights**: 실험 결과, DVR 프레임워크는 LLama3.1-8B 모델의 6개 제약 조건을 가진 지침에서 적응력을 두 배로 향상시켰습니다.



### Parametric Graph Representations in the Era of Foundation Models: A Survey and Position (https://arxiv.org/abs/2410.12126)
Comments:
          Preprint, 15 pages

- **What's New**: 이 연구는 그래프의 정량적 속성을 모델링하기 위한 그래프 법칙(graph laws)의 중요성을 강조하며, 이를 통해 다양한 실세계 적용 분야에 기여할 수 있는 잠재력을 제시합니다.

- **Technical Details**: 그래프 법칙은 그래프의 통계적 속성을 이해하고 기술하는 데 중점을 두며, 저자들은 매크로스코프(macro scope)와 마이크로스코프(micro scope), 정적(static) 및 동적(dynamic) 그래프, 저차 및 고차 연결(low-order and high-order connections) 등 다양한 관점에서 그래프의 법칙을 탐구합니다.

- **Performance Highlights**: 그래프 법칙의 적용은 그래프 생성(graph generation), 링크 예측(link prediction), 자연어 처리(natural language processing)와 같은 여러 실세계 작업에서 성능을 향상시키는 데 기여할 수 있습니다.



### Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming (https://arxiv.org/abs/2410.12112)
Comments:
          50 pages, 25 figures, 7 tables

- **What's New**: 새로운 연구에서는 복잡한 계획 문제를 해결하기 위해 대규모 언어 모델(LLMs)을 활용하는 LLMFP라는 일반 목적의 프레임워크를 제안합니다. 이 프레임워크는 태스크 특정 예제 없이도 최적화 문제로 계획 문제를 공식화하고 해결할 수 있는 가능성을 보여줍니다.

- **Technical Details**: LLMFP는 자연어 도메인 설명과 쿼리, 배경 정보를 입력받아 계획 문제를 해결하는 다섯 단계 프로세스를 갖추고 있습니다: 목표 및 주요 제약 조건 제안, 변수 표현 구축, 최적화 문제로 문제 공식화, 코드 실행 및 플랜 변환, 마지막으로 결과에 대한 평가 및 수정. 이 프레임워크는 SMT(상태 수정 이론)를 사용하여 최적화 문제를 인코딩합니다.

- **Performance Highlights**: LLMFP는 9개의 다양한 계획 문제에 적용되었으며, GPT-4o 및 Claude 3.5 Sonnet의 평균 최적 비율은 각각 83.7% 및 86.8%로, OpenAI o1-preview의 직접 계획 생성법보다 37.6% 및 40.7% 상승한 성과를 내며 탁월한 성능을 입증했습니다.



### A Learning Search Algorithm for the Restricted Longest Common Subsequence Problem (https://arxiv.org/abs/2410.12031)
Comments:
          33 pages, 12 figures

- **What's New**: 본 논문은 Restricted Longest Common Subsequence (RLCS) 문제를 다루고 있으며, 이는 잘 알려진 Longest Common Subsequence (LCS) 문제의 확장 버전입니다. RLCS 문제는 생물정보학에서 DNA, RNA 및 단백질 서열 간의 유사성을 식별하고 중요한 패턴을 발견하는 데 유용한 응용을 가지고 있습니다.

- **Technical Details**: 이 논문은 RLCS 문제를 해결하기 위한 두 가지 새로운 heuristic 접근법을 소개합니다. 첫 번째 접근법은 검색 과정에서 부분 해결책을 평가하기 위해 확률적 모델을 사용하며, 두 번째 접근법은 유전 알고리즘을 사용하여 오프라인에서 학습된 신경망 모델에 기반합니다. 이 연구에서는 학습된 신경망 모델을 beam search 프레임워크와 결합한 하이브리드 방법인 learning beam search를 개발하였습니다.

- **Performance Highlights**: 제안된 방법은 RLCS 문제 해결에 효과적임을 입증하는 포괄적인 실험 평가를 바탕으로 하며, 과학 저널의 초록을 입력 문자열로 사용하고, 자주 발생하는 학술 단어 집합을 제한된 패턴으로 사용하여 현실적인 사례를 생성하는 중요한 기여를 포함합니다.



### A Scalable Communication Protocol for Networks of Large Language Models (https://arxiv.org/abs/2410.11905)
- **What's New**: Agora라는 메타 프로토콜을 소개하며, 이는 기존의 통신 표준을 활용하여 LLM(대형 언어 모델) 기반 에이전트가 복잡한 문제를 효율적으로 해결할 수 있도록 합니다.

- **Technical Details**: Agora에서는 에이전트가 일상적인 통신을 위해 표준화된 루틴을 사용하고, 드물게 발생하는 통신은 자연어를 사용하며, 그 중간에는 LLM이 작성한 루틴을 활용합니다. 이를 통해 Agora는 기존의 에이전트 통신 문제를 피하고 인터페이스와 멤버의 변화를 강인하게 처리하여 이전에 없던 스케일성과 완전한 탈중앙화를 가능하게 합니다.

- **Performance Highlights**: 대규모 Agora 네트워크에서 자율적으로 복잡한 목표를 달성하는 자가 조직화된 프로토콜이 나타나는 것을 관찰하였습니다. 이는 Agora의 규모 확장성과 자가 조직화 행동의 출현을 보여줍니다.



### FLARE: Faithful Logic-Aided Reasoning and Exploration (https://arxiv.org/abs/2410.11900)
- **What's New**: 본 논문에서는 기존의 Chain-of-Thought (CoT) 방법론의 문제점을 해결하기 위해 Faithful Logic-Aided Reasoning and Exploration (FLARE)라는 새로운 접근 방식을 제안합니다. FLARE는 LLM을 사용하여 문제 공간을 탐색하고, 논리 프로그래밍 언어를 이용해 자연어 쿼리를 사실과 술어로 변환하여 코드 실행을 시뮬레이션합니다.

- **Technical Details**: FLARE는 세 가지 모듈로 구성되어 있습니다: 계획 생성을 위한 모듈, Prolog 코드를 생성하는 모듈, 그리고 문제를 해결하기 위한 시뮬레이션 검색 모듈입니다. 이 시스템은 멀티-홉 검색을 통해 자연어 쿼리의 해답을 찾는 과정에서 이유 과정을 정량적으로 평가할 수 있습니다.

- **Performance Highlights**: FLARE는 9개의 다양한 추론 벤치마크 중 7개에서 SOTA (State Of The Art) 결과를 달성하였으며, F-CoT보다 평균 16%, CoT보다 9% 향상된 성능을 보였습니다. 모델의 정확도는 이유 과정의 신뢰성과 강하게 상관관계가 있음을 입증하였습니다.



### Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information (https://arxiv.org/abs/2410.12774)
Comments:
          main paper 12 pages, Appendix 7 pages, 1 figure, 18 tables

- **What's New**: 이 연구에서는 다중 작업 학습(Multi-task Learning, MTL)에서의 작업 관련성을 정의하기 위해 pointwise V-usable 정보(점별 V-사용 가능 정보, PVI)를 기반으로 한 새로운 메트릭을 제안합니다. PVI는 데이터셋이 주어진 모델에 대해 얼마나 많은 사용 가능한 정보를 포함하고 있는지를 추정하는 최근의 기법입니다.

- **Technical Details**: PVI는 모델에 따라 데이터 인스턴스의 난이도를 추정하며, 이를 통해 비슷한 난이도의 작업들을 그룹화하여 MTL에서 성능을 극대화할 수 있다고 가정합니다. 15개의 NLP 데이터셋을 이용한 실험을 통해 MTL 결과를 기존 단일 학습자 모델 및 최신 대형 언어 모델과 비교하였습니다. 또한, PVI 기반 작업 그룹화를 통한 성능 비교를 실시하였습니다.

- **Performance Highlights**: PVI 추정치가 비슷한 작업들을 그룹화함으로써 다중 작업 학습이 성능을 개선하고, 총 파라미터 수를 줄이면서도 다양한 도메인에 걸쳐 일관된 성능을 보였습니다. 이 연구는 PVI 추정값을 이용한 작업 그룹화가 STL 성능을 초과할 수 있음을 입증하였습니다.



### Harmon: Whole-Body Motion Generation of Humanoid Robots from Language Descriptions (https://arxiv.org/abs/2410.12773)
Comments:
          Accepted for oral presentation at 8th Annual Conference on Robot Learning. Project website: this https URL

- **What's New**: 이번 연구에서는 자연어 설명으로부터 휴머노이드 로봇의 전체 신체 동작을 생성하는 방법에 대해 다루고 있습니다. 새로운 접근법인 Harmon을 통해 인간의 동작 데이터와 Vision Language Models (VLMs)의 공감각적 추론 기능을 결합하여 인간과 유사한 동작 양식을 생성하고 있습니다.

- **Technical Details**: 휴머노이드 로봇의 동작 생성을 위해 PhysDiff라는 확산 기반 생성 모델을 사용하여 대규모 인간 동작 데이터로부터 인간의 동작을 생성합니다. 이어서 생성된 동작은 역기구학(Inverse Kinematics)을 활용하여 시뮬레이션된 휴머노이드 로봇으로 리타겟팅됩니다. 동작의 표현력 향상과 자연어 설명과의 정렬을 위해 VLM을 활용하여 손과 머리 동작을 생성하고 수정합니다.

- **Performance Highlights**: Harmon은 86.7%의 테스트 사례에서 사람 평가자들로부터 선호되었으며, 실제 로봇에서 실행되는 다양한 동작을 보여주며 자연스럽고 표현력이 풍부한 휴머노이드 동작을 성공적으로 생성했습니다.



### Vaccinating Federated Learning for Robust Modulation Classification in Distributed Wireless Networks (https://arxiv.org/abs/2410.12772)
- **What's New**: 본 논문에서는 기존의 Federated Learning 기반 Automatic Modulation Classification (AMC) 모델의 한계를 극복하기 위해 FedVaccine이라는 새로운 프레임워크를 제안합니다. 적절한 양의 노이즈를 도입함으로써 다양한 노이즈 수준에서의 일반화 가능성을 높이는 것이 목표입니다.

- **Technical Details**: FedVaccine은 하모닉 노이즈 저항 접근법을 통해 DNN 모델에 대한 최적 노이즈 내성을 식별하고, 훈련 프로세스를 조절하여 과적합(overfitting)을 완화합니다. 또한, 기존의 선형 집합 방법의 한계를 극복하기 위해 구조적 클러스터링(topology)과 로컬 큐 데이터 구조를 사용하는 분할 학습(split-learning) 전략을 employ하여 로컬 모델의 적응적이고 누적적인 업데이트를 가능하게 합니다.

- **Performance Highlights**: 실험 결과, FedVaccine은 IID 및 non-IID 데이터셋에서 우수한 수행 성능을 보이며, 다양한 노이즈 조건에서도 기존 FL 기반 AMC 접근 방식에 비해 뛰어난 성능을 발휘합니다. 이는 FedVaccine이 실제 무선 네트워크 환경에서 AMC 시스템의 신뢰성과 성능을 향상시킬 잠재력을 지니고 있음을 확인시켜줍니다.



### Open Materials 2024 (OMat24) Inorganic Materials Dataset and Models (https://arxiv.org/abs/2410.12771)
Comments:
          19 pages

- **What's New**: Meta FAIR에서 발표한 Open Materials 2024 (OMat24) 대규모 개방형 데이터세트와 함께 여러 가지 사전 훈련된 모델을 출시했습니다. OMat24는 1억 개 이상의 밀도 기능 이론(DFT) 계산을 포함하고 있으며, 구조적 및 조합적 다양성에 중점을 두었습니다.

- **Technical Details**: OMat24 데이터세트는 비평형 원자 구성과 원소 조합을 기반으로 한 DFT 단일 포인트 계산, 구조적 안정화 및 분자 동역학 궤적을 포함하여 약 1억 1800만 개의 구조로 구성되어 있습니다. EquiformerV2 모델은 Matbench Discovery 리더보드에서 최첨단 성능을 달성하며, F1 점수 0.9 이상의 기초 상태 안정성과 20 meV/atom의 정확도로 형성 에너지를 예측할 수 있습니다.

- **Performance Highlights**: OMat24 데이터세트와 모델을 통한 사전 훈련은 MPtraj 및 Alexandria 데이터세트에서의 최적화 성능을 크게 향상시킵니다. 개방형 데이터와 모델의 도입은 연구 커뮤니티가 우리의 노력에 기반하여 AI 지원 물질 과학을 더욱 발전시킬 수 있게 합니다.



### SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And Video Generation (https://arxiv.org/abs/2410.12761)
Comments:
          The first two authors contributed equally; Project page: this https URL

- **What's New**: SAFREE는 최신의 적응형, 훈련 없는 안전한 T2I(텍스트에서 이미지로) 및 T2V(텍스트에서 비디오로) 생성 접근 방식을 제안합니다. 기존의 모델의 가중치를 변경하지 않으면서 유해 콘텐츠를 필터링하는 데 중점을 둡니다.

- **Technical Details**: SAFREE는 텍스트 임베딩 공간에서 유해 개념에 해당하는 하위 공간을 탐지하여 프롬프트 임베딩을 이 하위 공간에서 멀리하는 방식으로 작동합니다. 또한, 동적인 Denoising 단계 조정 및 픽셀 수준에서 유해 개념과 관련된 특징의 영향을 줄이는 적응형 재 주의 메커니즘을 포함합니다.

- **Performance Highlights**: SAFREE는 SOTA(최첨단 기술) 성능을 달성하며, 훈련 없는 기준 모델들에 비해 안전하지 않은 콘텐츠를 억제하는 데 뛰어난 효과를 보이고, 높은 품질의 이미지를 유지하면서도 동시에 다양한 T2I 및 T2V 작업에 유연하게 적용 가능합니다.



### Unitary Multi-Margin BERT for Robust Natural Language Processing (https://arxiv.org/abs/2410.12759)
- **What's New**: 최근 딥 러닝에서 적대적 공격에 대한 발전으로 인해 자연어 처리(NLP) 시스템이 위험에 처해 있습니다. 이 논문은 Bidirectional Encoder Representations from Transformers(BERT)의 견고성을 크게 향상시키는 보편적인 기술인 Unitary Multi-Margin BERT(UniBERT)를 소개합니다.

- **Technical Details**: UniBERT는 cross-entropy loss를 multi-margin loss로 교체하고, weight 매트릭스를 단위 행렬로 제한하여 적대적 공격에 대한 강인성을 강화합니다. 이러한 접근 방식을 통해 다중 클래스를 구분하는 신경 표현을 보다 뚜렷하게 분리합니다. 수치적으로, UniBERT는 공격 후 분류 정확도를 5.3% 개선하여 73.8%에 도달하며, 단일 스칼라 매개변수를 통해 사전 및 사후 정확도 간의 트레이드오프를 조정할 수 있습니다.

- **Performance Highlights**: UniBERT는 기존의 방어 방법들과 비교할 때 여러 작업에서 공격 후 정확도를 유의미하게 향상시킵니다. 특히, 우리의 모델은 적대적 훈련 방식에 대한 의존 없이 설계되었으며, 간단한 구현이 가능합니다.



### Counterfactual Generative Modeling with Variational Causal Inferenc (https://arxiv.org/abs/2410.12730)
- **What's New**: 이 논문은 고차원적 결과(noidual outcomes)하에서 개별의 잠재적 결과를 추정할 수 있는 새로운 변별적 베이지안(causal inference) 프레임워크를 제안합니다. 이를 통해 기존 모델의 한계를 극복하고, 반사실적(supervised) 처리를 보다 효과적으로 수행할 수 있습니다.

- **Technical Details**: 기존의 조건부 변별 오토인코더(conditional variational autoencoder) 프레임워크에서의 신경 적응(neural adaptations) 및 모델 변형에 초점을 맞춘 이전 연구들과 달리, 이 연구는 카운터팩추얼(causal inference) 개념에 적합한 새로운 방식을 제시합니다. 이 프레임워크를 통해 카운터팩추얼 샘플 없이도 엔드 투 엔드(end-to-end) 방식으로 학습하는 과정에서 잠재적 분리(latent disentanglement)를 촉진할 수 있습니다.

- **Performance Highlights**: 실험을 통해, 본 프레임워크가 여러 벤치마크에서 최고의 모델(state-of-the-art models)들과 비교했을 때 카운터팩추얼 생성 모델링에서 우수한 성능을 보임을 입증했습니다.



### Transformer based super-resolution downscaling for regional reanalysis: Full domain vs tiling approaches (https://arxiv.org/abs/2410.12728)
- **What's New**: 이번 연구에서는 Swin Transformer 기반의 새로운 Super-Resolution (SR) 방법이 제안되었으며, 기존의 여러 SR 다운스케일링(Downscaling) 방법과 비교되었습니다. 특히 CERRA 재분석(CERRA reanalysis) 데이터(5.5km 해상도)를 사용하여 기온 예측을 대상으로 했습니다.

- **Technical Details**: 이 연구에서는 두 가지 접근법을 비교했으며, 첫 번째는 전체 영역을 입력으로 사용하는 전통적인 방법이고, 두 번째는 전체 도메인을 타일(tile)로 나누는 확장 가능한 방법입니다. 제안된 Swin2SR 모델은 고해상도 입력 데이터를 처리할 수 있도록 설계된 Swin v2 Transformer 구조를 기반으로 하며, 자기 주의 메커니즘(self-attention mechanism)을 사용하여 장거리 종속성을 캡처합니다. 또한, 입력을 단계적으로 처리하여 전반적인 성능을 유지합니다.

- **Performance Highlights**: 타일 접근법은 공간 전이성(spatial transferability)이 필요하지만, 약간의 성능 저하를 감수하면서도 효율적이고 확장 가능한 솔루션을 제공합니다. 이는 판 유럽 규모의 SR 축소를 가능하게 하며, 실시간 애플리케이션에 유용합니다. 또한 Swin2SR 모델은 에라5(ERA5) 및 CERRA 재분석 데이터를 기반으로 한 기온 다운스케일링에 성공적으로 적용되었습니다.



### HEnRY: A Multi-Agent System Framework for Multi-Domain Contexts (https://arxiv.org/abs/2410.12720)
- **What's New**: 이번 프로젝트 HEnRY는 Intesa Sanpaolo에 Multi-Agent System (MAS)을 도입하는 것을 목표로 합니다. HEnRY라는 이름은 프로젝트의 핵심 원리를 요약하여 계층적 구조(Hierarchical organization)에서 효율적인 자원 관리를 위한 에이전트들의 조직, 자원 및 운영의 효율적인 최적화(Efficient optimization), 환경 자극에 신속하게 반응하는 에이전트의 능력(Reactive ability), 그리고 예상치 못한 상황을 처리할 수 있는 에이전트의 적응성과 유연성(Yielding adaptability)을 포함합니다.

- **Technical Details**: 이 논문에서는 두 가지 주요 연구 경로를 다룹니다. 첫 번째는 시스템 아키텍처(System architecture)에 관한 것이며, 두 번째는 에이전트 간의 협력(Collaboration between agents)에 중점을 둡니다. 이 연구는 Intesa Sanpaolo의 구체적인 구조에 국한되지 않고 MAS에 대한 기존 연구를 활용하여 새로운 솔루션을 제시합니다.

- **Performance Highlights**: Intesa Sanpaolo는 국제 기업 거버넌스 최선의 관행에 부합하는 모델로 조직되어 있으므로, 이 접근법은 유사한 시나리오에서도 유용할 수 있습니다.



### FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression (https://arxiv.org/abs/2410.12707)
- **What's New**: FusionLLM은 지리적으로 분산된 GPUs를 활용하여 대규모 딥 뉴럴 네트워크(DNN)를 훈련하기 위해 디자인된 분산 훈련 시스템입니다. 이 시스템은 원거리 자동 미분(Remote Automatic Differentiation, RAD), 유연한 모델 정의 및 이질적인 소프트웨어 지원, 그리고 부하가 불균형한 하드웨어 문제 해결을 목표로 하고 있습니다.

- **Technical Details**: FusionLLM 시스템은 DNN의 오퍼레이터를 방향성 비순환 그래프(Directed Acyclic Graph, DAG)로 표현합니다. 각 노드는 DNN의 오퍼레이터를 나타내며, 엣지는 오퍼레이터 간 데이터 의존성을 나타냅니다. 시스템은 OP-Fence 스케줄러를 사용하여 유사한 대역폭을 가진 기기들을 클러스터링하고 DAG을 분할하여 처리량을 증가시킵니다. 또한, AdaTopK 압축기를 통해 느린 통신 링크에서 중간 활성화 및 그래디언트를 적응적으로 압축합니다.

- **Performance Highlights**: FusionLLM을 사용하여 ResNet-101과 GPT-2를 훈련한 결과, 48개의 GPU를 사용하여 8 Mbps에서 10 Gbps 네트워크에서 실험한 결과, 기존 방법에 비해 1.45 - 9.39배의 속도 향상을 달성하며 수렴을 보장하였습니다.



### WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines (https://arxiv.org/abs/2410.12705)
- **What's New**: WorldCuisines라는 대규모 벤치마크가 소개되어 VLMs의 다문화적 및 다언어적 이해력을 평가할 수 있는 새로운 기준을 제시합니다. 이 벤치마크는 30개 언어와 방언에서 각각의 텍스트-이미지 쌍을 포함하고 있어 다문화적인 VQA 데이터셋으로는 가장 큰 규모를 자랑합니다.

- **Technical Details**: 이 연구는 VLMs를 평가하기 위해 100만 개 이상의 고품질의 다언어 및 다문화 텍스트-이미지 쌍으로 구성된 WorldCuisines를 개발했습니다. 벤치마크는 2가지 작업을 포함합니다: (1) 요리 이름 예측, (2) 요리가 일반적으로 소비되는 위치 예측. VQA 데이터셋은 30개 언어와 방언으로 구성되어 있으며, 다양한 질문 유형에 대한 평가를 포함합니다.

- **Performance Highlights**: VLMs는 적절한 위치 맥락에서 더 좋은 성능을 보였으나, 적대적인 맥락에서는 어려움을 겪었고, 특정 지역 요리와 언어 예측에서의 어려움이 드러났습니다. 데이터셋과 관련된 주의 깊은 메타데이터와 이미지도 함께 제공되어 향후 연구 지원을 기대합니다.



### Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization (https://arxiv.org/abs/2410.12700)
Comments:
          Accepted by ACM Multimedia 2024. The dataset and code can be found at this https URL

- **What's New**: 이번 연구에서는 인간의 가치와 정렬된 T2I(Text-to-Image) 모델을 위한 경량화된 방법인 LiVO(Lightweight Value Optimization)를 제안합니다. LiVO는 입력 프롬프트와 통합하여 이미지 생성을 제어할 수 있는 플러그 앤 플레이(value encoder) 값을 최적화합니다. 이는 T2I 모델과 인간의 가치 원칙을 효과적으로 연결합니다.

- **Technical Details**: LiVO는 기존 T2I 모델의 매개변수를 업데이트하지 않고도 사용자의 입력에 따라 적합한 가치 원칙을 선택할 수 있게 해줍니다. 이를 통해 생성된 이미지의 의미와 가치를 자연어 지침에 따라 조정할 수 있습니다. 연구팀은 86K 개의 (프롬프트, 정렬 이미지, 위반 이미지, 가치 원칙) 샘플로 이루어진 텍스트-이미지 가치 선호 데이터셋을 자동으로 구축하는 프레임워크를 개발했습니다.

- **Performance Highlights**: LiVO는 최소 20%의 데이터만으로 유해한 콘텐츠를 최대 66%까지 줄일 수 있으며, 여러 강력한 기준선을 초과하는 성능을 보였습니다. 또한, 즉각적인 수렴성을 달성하며 가치 정렬이 향상된 T2I 모델의 개발을 위한 초기 단계로 나아갑니다.



### Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2 (https://arxiv.org/abs/2410.12686)
Comments:
          6 pages, 2 figures, 1 table

- **What's New**: 최근 연구에 따르면, Llama-2와 같은 최신 대형 언어 모델(LLMs)은 의료 이미징 도메인에서 해부학적 랜드마크의 위치를 정확하게 나타낼 수 있는 가능성을 보여주고 있습니다. 이 연구는 이러한 모델들이 의료 이미징 워크플로우의 효율성과 정확성을 높일 수 있는 잠재력을 가지고 있다는 점을 강조합니다.

- **Technical Details**: 연구는 Llama-2 모델의 내부 신경 활성화를 선형적으로 조사하여 해부학적 랜드마크의 위치를 예측하는 방식을 사용했습니다. 각 랜드마크에 대한 명칭과 그에 대응하는 공간 좌표를 포함한 데이터세트를 구성하였으며, ridge regression 모델을 통해 위치 예측의 정확성을 평가했습니다. 또한, 비선형 검사를 위해 다층 퍼셉트론(MLP)을 사용하여 결과를 비교했습니다.

- **Performance Highlights**: Llama-2 모델은 다양한 프롬프트에 대해 해부학적 랜드마크를 선형적으로 robust하게 표현할 수 있음을 보여주었습니다. 모델의 성능은 랜드마크 크기 표현에서도 선형성을 나타내었으며, 이는 의료 이미징 보고서에서의 자동화된 해석에 기여할 것으로 기대됩니다.



### Generative Neural Reparameterization for Differentiable PDE-constrained Optimization (https://arxiv.org/abs/2410.12683)
Comments:
          Accepted to D3S3: Data-driven and Differentiable Simulations, Surrogates, and Solvers - Workshop @ NeurIPS 2024

- **What's New**: 본 논문은 부분 미분 방정식(PDE) 제약 최적화에서 신경망을 사용하여 최적 매개변수의 분포를 학습하는 새로운 방법론을 제안합니다. 이 접근 방식은 여러 로컬 미니마를 처리하여 더 효과적인 최적화를 가능하게 합니다.

- **Technical Details**: 제안된 방법, Generative Neural Reparameterization (GNR)은 기본적으로 랜덤 벡터에서 최적 매개변수 세트로의 매핑을 학습하는 신경망을 이용합니다. 이 방법은 기존의 PDE 제약 최적화와 비교하여 여러 최적 해의 분포를 생성할 수 있는 장점을 제공합니다.

- **Performance Highlights**: GNR 방법을 이용한 레이저 플라즈마 불안정성 문제에서, 다양한 최적 매개변수로 성능이 향상됨을 입증했습니다. 실험 결과 GNR이 단일 최적 해 대신 여러 다양한 미니마를 생성하는 데 성공했습니다.



### Context Matters: Leveraging Contextual Features for Time Series Forecasting (https://arxiv.org/abs/2410.12672)
- **What's New**: 본 연구에서는 시계열 예측 모델에 새로운 요소를 추가하였습니다. ContextFormer라는 방법을 소개하여, 여러 종류의 외부 정보(예: 뉴스 기사, 트윗 등)를 기존 모델에 통합할 수 있게 하였습니다.

- **Technical Details**: ContextFormer는 다중 모드(모달리티)의 맥락 정보를 기존의 사전 훈련된 예측 모델에 효과적으로 통합하는 방법입니다. 이 방법은 범주형(categorical), 연속형(continuous), 시간 변동형(time-varying), 텍스트 정보까지 다양한 정보를 정제하여 예측 성능을 크게 향상시킵니다.

- **Performance Highlights**: ContextFormer는 에너지, 교통, 환경, 금융 분야의 다양한 실제 데이터셋에서 기존의 SOTA(최신 기술) 예측 모델보다 최대 30% 더 나은 성능을 보여줍니다.



### Hamiltonian bridge: A physics-driven generative framework for targeted pattern contro (https://arxiv.org/abs/2410.12665)
Comments:
          29 pages, 8 figures

- **What's New**: 본 연구에서는 비평형 시스템에서 패턴 형성을 조절하기 위한 새로운 프레임워크인 'Hamiltonian bridge'를 제시합니다. 이 프레임워크는 여러 스케일에서 패턴을 조절할 수 있는 방법을 제공합니다.

- **Technical Details**: 연구는 비평형 시스템에 대한 일반적인 동역학 법칙과 확률적 최적 제어 방법을 결합합니다. 이 과정에서, 상관 관리를 위한 Feynman-Kac 기반의 부가 경로 적분(formulation)을 활용하여 상호 작용하는 입자를 제어하는 방식으로 패턴 형성 PDE들에 효율적으로 적용됩니다. 또한, 최적 제어 문제는 초기와 목표 패턴 사이의 보간(interpolation)으로 간주되어, 동역학 법칙을 준수하는 다양한 패턴 상태 간의 보간을 가능하게 합니다.

- **Performance Highlights**: 수치 실험을 통해 상관 파라미터가 존재하는 분리 상태 제어, 유체 방울의 자가 조립, 결합 반응-확산 방정식 및 시공간 조직 분화에 대한 현상학적 모델에서 패턴 제어의 유용성을 입증하였습니다. 이러한 실험은 패턴의 기하학적 성질을 이해하는 데 있어 물리적 원리에 따라 패턴의 수송 경로 및 보간의 성격을 조절하는 방법을 설명합니다.



### Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models (https://arxiv.org/abs/2410.12662)
- **What's New**: 본 연구에서는 Large Vision-Language Models (LVLMs)의 비주얼 입력에 대한 안전 메커니즘의 전이 부족 문제를 다룹니다. 현재의 방법론이 비주얼 모달리티에 대해 안전 메커니즘을 효과적으로 전이하지 못함을 발견하고, Text-Guided vision-language Alignment (TGA)라는 새로운 방법을 제안합니다.

- **Technical Details**: TGA는 입력된 비전과 관련된 텍스트를 검색하여 LLMs의 hidden states 공간으로 비전을 투영하는 데 도움을 줍니다. 이로써 이미지의 hidden states와 텍스트의 hidden states 간의 정렬을 이루게 됩니다. 연구 결과, TGA는 기존 LLMs의 안전 메커니즘을 비전으로 성공적으로 전이할 수 있음을 보여주었습니다.

- **Performance Highlights**: TGA는 안전한 결과를 도출하며, InstructBLip, LLaVA-1.5 및 Qwen-VL-Chat과 같은 기존의 최첨단 LVLM들과 비교할 때 다양한 비전 작업에서 일반 성능을 유지합니다.



### Evaluating Morphological Compositional Generalization in Large Language Models (https://arxiv.org/abs/2410.12656)
Comments:
          33 pages

- **What's New**: 본 연구는 대형 언어 모델(LLMs)의 형태론적 일반화 능력을 구성적(compositional) 관점에서 체계적으로 조사합니다. 형태소(morpheme)를 구성적 원시 단위로 정의하고, 이를 기반으로 한 새로운 유전자 및 판별(task) 과제를 설계하였습니다.

- **Technical Details**: 우리는 지도 학습된 멀티링궐 모델들(GPT-4, Gemini-1.5 등)을 평가하였으며, 터키어와 핀란드어와 같은 교착어(agglutinative languages)를 대상으로 했습니다. 모델은 새로운 단어의 어근에 적용했을 때 형태론적 연결(compositionality) 일반화가 부족하며, 형태론적 복잡성이 증가할수록 성능이 급격히 감소하는 경향을 보였습니다.

- **Performance Highlights**: 모델은 개별적인 형태론적 조합을 식별하는 데 있어 최소한의 성과를 보였지만, 그 성능은 시스템적이지 않아 인간과 비교했을 때 상당한 정확도 차이를 보였습니다. 인간은 복잡한 형태론적 구조에서도 일관된 성능을 유지하는 반면, 모델의 성능은 뚜렷한 감소를 보였습니다.



### Constrained Posterior Sampling: Time Series Generation with Hard Constraints (https://arxiv.org/abs/2410.12652)
- **What's New**: 이번 연구에서는 제약 조건이 있는 시계열(time series) 샘플 생성을 위한 Constrained Posterior Sampling (CPS) 방법을 제안합니다.

- **Technical Details**: CPS는 diffusion 기반 샘플링 알고리즘으로, 각 denoising 업데이트 후에 posterior mean 추정치를 제약 집합(constraint set)으로 투영하는 방식을 사용합니다. 이 방법은 약 100개의 제약 조건을 처리할 수 있도록 확장 가능하며, 추가적인 학습이 필요하지 않습니다.

- **Performance Highlights**: CPS는 실제 주식, 교통, 대기 질 데이터 세트에서 샘플 품질(sample quality)과 실제 시계열과의 유사성(similarity)에서 각각 약 10% 및 42% 우수한 성능을 보였습니다.



### Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans (https://arxiv.org/abs/2410.12641)
- **What's New**: 본 연구에서는 어깨 CT 스캔을 처리하기 위한 혁신적인 딥러닝 프레임워크를 도입합니다. 이 프레임워크는 근위 상완골과 견갑골의 의미적 분할(semantic segmentation), 뼈 표면의 3D 재구성, 글레노흐umeral (GH) 관절 영역 식별 및 세 가지 일반적인 골관절염 관련 병리(staging)인 골극 형성(osteophyte formation), GH 공간 축소(glenohumeral joint space reduction), 그리고 상완 견갑 정렬(humeroscapular alignment)을 포함합니다.

- **Technical Details**: 이 파이프라인은 두 개의 연속적인 CNN 아키텍처로 구성됩니다. 첫 번째는 세그멘테이션을 위한 3D CEL-UNet, 두 번째는 세 가지 분류를 위한 3D Arthro-Net입니다. 571개의 CT 스캔의 레트로스펙티브 데이터셋을 사용하여 성능을 평가했습니다. 3D 재구성에 대한 평균 제곱근 오차(root mean squared error) 및 하우스도르프 거리(Hausdorff distance)의 중앙값은 상완골에 대해 각각 0.22mm 및 1.48mm, 견갑골은 0.24mm 및 1.48mm로, 기존 아키텍처를 초과하는 성능을 보였습니다.

- **Performance Highlights**: 세 가지 카테고리(OS, JS, HSA)에 대해 분류 정확도는 약 90%에 도달하였으며, 추론 파이프라인의 계산 시간은 15초 미만으로, 정형외과 영상의학적 실습과의 효율성과 호환성을 보여줍니다. 이 결과는 인공지능 도구의 의료 변환을 위한 유망한 발전을 나타내며, 고품질의 뼈 표면을 제공하고 외과의사가 환자의 관절 조건에 따라 가장 적합한 외과적 접근 방식을 선택하는 데 도움을 줍니다.



### Exploring Model Kinship for Merging Large Language Models (https://arxiv.org/abs/2410.12613)
Comments:
          Ongoing work

- **What's New**: 이 연구는 모델 병합(model merging)을 위한 새로운 평가 기준인 모델 친척성(model kinship)을 도입합니다. 모델 친척성은 LLM(대형 언어 모델) 간의 유사성과 관련성을 측정하여, 반복적인 병합 과정에서 성능 개선을 돕는 정보를 제공합니다.

- **Technical Details**: 모델 병합은 여러 개별 모델을 통합하여 다중 작업 목표를 달성하는 전략입니다. 본 논문에서는 모델 친척성을 기준으로 한 Top-k Greedy Merging 전략을 제안하며, 이는 모델 진화(model evolution)에서의 최적화 문제와 지역 최적점(local optima traps)을 피할 수 있도록 도와줍니다.

- **Performance Highlights**: 모델 친척성을 사용한 새로운 병합 전략은 벤치마크 데이터셋에서 더 나은 성능을 달성하며, 평균 성능 향상과 강한 상관관계가 있음을 보여줍니다. 이 연구는 모델 병합의 효율성과 효과성을 높이기 위한 실용적인 전략을 제시합니다.



### Towards Graph Foundation Models: The Perspective of Zero-shot Reasoning on Knowledge Graphs (https://arxiv.org/abs/2410.12609)
Comments:
          17 Pages, 5 figures

- **What's New**: 이 논문은 지식 그래프(knowledge graph, KG) 추론의 관점에서 그래프 기반 모델(graph foundation models)을 탐구하며, 최근의 인공지능(a기아 일반화)과 KG의 성공적인 통합에 주목합니다.

- **Technical Details**: 이 논문에서는 SCORE라는 통합된 그래프 추론 프레임워크를 소개합니다. SCORE의 핵심은 구조적 및 의미적 불변성을 포착하기 위해 설계된 의미 조건 메시지 전달(semantic conditional message passing) 기술입니다. SCORE는 38개의 다양한 그래프 데이터 세트를 통해 통합적 추론을 수행하며, 노드 레벨(node-level), 링크 레벨(link-level), 그래프 레벨(graph-level) 태스크를 아우릅니다.

- **Performance Highlights**: 실험 결과, SCORE는 이전의 기초 모델(baseline)과 감독 학습(supervised model)보다 상당한 성능 개선을 보여줌으로써 우리의 접근 방법의 효과와 적응성을 강조합니다.



### Low-Rank Adversarial PGD Attack (https://arxiv.org/abs/2410.12607)
- **What's New**: 이 연구에서는 Projected Gradient Descent (PGD) 공격이 원 이미지의 단일값 스펙트럼의 일부에만 주로 영향을 미친다는 것을 관찰하였고, 이를 바탕으로 효율적으로 저랭크 공격을 계산하는 저랭크 PGD 변형을 제안하였습니다.

- **Technical Details**: 제안된 LoRa-PGD는 공격 크기를 제어할 수 있도록 설계되어 있으며, 이미지의 단일값 스펙트럼의 작은 비율을 변경함으로써 메모리 사용량을 크게 줄이고, 전통적인 전체 랭크 PGD에 비해 성능이 동등하거나 더 나은 결과를 보여줍니다. 이 방법은 adversarial training에서 효과적으로 사용될 수 있습니다.

- **Performance Highlights**: 저랭크 PGD는 전통적인 PGD 공격보다 메모리 사용량이 현저히 적으면서도 유사한 또는 더 나은 성능을 발휘하며, 특히 핵 규범(nuclear norm) 기준으로 측정했을 때 더 높은 효율성을 보였습니다.



### Self-Supervised Learning of Disentangled Representations for Multivariate Time-Series (https://arxiv.org/abs/2410.12606)
Comments:
          NeurIPS 2024 Workshop: Self-Supervised Learning - Theory and Practice

- **What's New**: TimeDRL은 고차원 다변량 시계열 데이터의 표현 학습을 위한 최신 프레임워크로, 이중 수준의 불연속 임베딩을 도입하여 기존 방법론의 한계를 극복합니다.

- **Technical Details**: TimeDRL은 [CLS] 토큰 전략을 통해 시간 수준(timestamp-level) 임베딩과 인스턴스 수준(instance-level) 임베딩을 분리하여 학습합니다. 또한, 시간 예측 및 인스턴스 대비(contrastive) 작업을 통해 각 임베딩 수준에 적합한 학습을 진행하며, 외부 데이터 증강을 피하여 유도 바이어스를 최소화합니다.

- **Performance Highlights**: 실험 결과, TimeDRL은 11개의 실제 시계열 예측 및 분류 벤치마크에서 최신 방법들을 능가하는 성능을 보여주었으며, 제한된 레이블 데이터가 있는 반지도 학습 설정에서도 그 효용성을 입증했습니다.



### Expand and Compress: Exploring Tuning Principles for Continual Spatio-Temporal Graph Forecasting (https://arxiv.org/abs/2410.12593)
- **What's New**: 이 논문은 새로운 스페이시오-템포럴(spatio-temporal) 데이터 스트리밍 환경에서의 지속적인 예측을 위한 프롬프트 튜닝 기반 방법(EAC)을 제안합니다. 이 방법은 경량 조정 매개변수를 통해 모델의 재훈련 문제와 장기적 기억 상실(catastrophic forgetting)을 해결합니다.

- **Technical Details**: EAC 방법은 기본 스페이시오-템포럴 그래프 신경망(base STGNN)과 연속 프롬프트 풀을 통합하여, 메모리에 저장된 학습 가능한 프롬프트를 활용합니다. 두 가지 조정 원리인 expand(확장) 및 compress(압축)를 통해 모델의 효과성과 효율성을 균형 있게 유지합니다. 이를 통해 모델은 연속적인 데이터 스트림에서 점진적으로 학습합니다.

- **Performance Highlights**: EAC는 다양한 실제 데이터셋에서 여러 가지 면에서 기존 최첨단 방법들에 비해 우수한 성능을 보였습니다. 지속적인 학습을 통한 성능 향상, 다양한 STGNN 아키텍처에 대한 일관된 성능 발휘, 훈련 속도 증가, 적은 수의 매개변수 조정으로도 효율적인 학습이 가능하다는 특징을 가지고 있습니다.



### Rethinking Visual Counterfactual Explanations Through Region Constrain (https://arxiv.org/abs/2410.12591)
Comments:
          Preprint

- **What's New**: 이번 논문에서는 Visual Counterfactual Explanations (VCEs)의 한계를 극복하기 위해 지역 제약을 설정하는 방법인 지역 제약 VCEs (RVCEs)를 제안합니다. 기존 방법들이 이미지의 여러 부분을 혼합하여 수정할 때 발생하는 문제를 해결하고자 하며, RVCE는 한정된 지역만 수정하여 모델의 예측에 영향을 미칩니다.

- **Technical Details**: RVCEs는 결정론적 조건부 인페인팅 문제를 해결하는 것으로, 결정자에서 유래한 신호를 기반으로 합니다. 이를 위해 Regional-Constrained Counterfactual Schrödinger Bridges (RCSB)라는 새로운 알고리즘을 도입하며, 이는 이미지 생성 과정에서 효율적이고, 사실적이며, 원본에 가깝게 RVCEs를 합성하는 데 도움을 줍니다.

- **Performance Highlights**: RCSB 방법은 ImageNet 데이터셋에서 기존 방식에 비해 FID에서 최대 4배, sFID에서 3배, COUT에서 2배 더 우수한 성능을 보여줍니다. 이 연구는 RVCEs가 모델의 의사결정을 명확히 이해할 수 있도록 돕고, 사용자가 수동으로 수정 지역을 정의하며 상호작용할 수 있는 기능을 제공합니다.



### STRUX: An LLM for Decision-Making with Structured Explanations (https://arxiv.org/abs/2410.12583)
Comments:
          10 pages, 7 figures, submitted to NAACL 2025

- **What's New**: 이 논문에서는 새로운 LLM (Large Language Model) 의사결정 프레임워크인 STRUX를 소개합니다. STRUX는 구조화된 설명을 제공하여 LLM의 의사결정을 개선합니다.

- **Technical Details**: STRUX는 긴 정보를 간결한 핵심 사실의 표로 정제한 후, 자기 반성 단계(self-reflection steps)를 통해 어떤 사실이 중요한지를 결정합니다. 이 사실을 특정 결정과 관련하여 유리한(favorable) 것과 불리한(adverse) 것으로 분류합니다. 마지막으로, LLM을 미세 조정(fine-tune)하여 이러한 핵심 사실을 식별하고 우선순위를 매깁니다.

- **Performance Highlights**: STRUX는 수익 전화 회의(transcripts) 데이터를 기반으로 한 주식 투자 의사 결정 예측 과제에서 강력한 기준선(baselines) 대비 뛰어난 성능을 보였습니다. 이는 의사결정의 투명성을 높여주며, 사용자들이 다양한 요인의 영향을 이해할 수 있도록 합니다.



### On the Utility of Domain Modeling Assistance with Large Language Models (https://arxiv.org/abs/2410.12577)
- **What's New**: 본 논문은 대형 언어 모델(LLMs)과 few-shot prompt learning을 활용하여 도메인 모델링을 지원하는 새로운 접근 방식을 평가하는 연구를 제시합니다.

- **Technical Details**: 상대적으로 적은 양의 도메인 특정 데이터셋으로 AI 기반 완성 모델을 훈련하는 대신, 이 접근법은 다양한 모델링 활동을 지원하는데 필요한 유용한 권장 사항을 제공합니다. MAGDA라는 사용자 친화적인 도구를 개발하여 사용자 연구를 수행하고 실제 도메인 모델링에 대한 적용 가능성을 평가합니다.

- **Performance Highlights**: 이 연구는 MAGDA의 사용성 및 효율성에 대한 귀중한 통찰력을 제공하며, 모델-주도 엔지니어링(MDE)의 설계 프로세스에서의 도전 과제를 극복하는 데 중요한 기여를 할 것으로 기대합니다.



### Robust RL with LLM-Driven Data Synthesis and Policy Adaptation for Autonomous Driving (https://arxiv.org/abs/2410.12568)
- **What's New**: RAPID 프레임워크는 대형 언어 모델(LLM)을 활용하여 자율 주행 시스템에 특화된 RL (Reinforcement Learning) 에이전트를 훈련시키는 새로운 접근법을 제공합니다. 이를 통해 더 빠르고 효율적인 실시간 추론을 가능하게 합니다.

- **Technical Details**: RAPID는 다음 세 가지 핵심 설계를 포함합니다: 1) LLM 에이전트로부터 수집된 오프라인 데이터를 활용하여 전문가의 지식을 RL 정책으로 증류(distill)합니다; 2) RL에서의 강력한 증류를 도입하여 LLM 기반의 교수로부터 성능과 강인성을 물려받습니다; 3) 정책 어댑터(policy adapter)를 통해 공동 결정 디코딩(joint decision decoding)을 위한 믹스 오브 정책(mix-of-policy) 접근 방식을 사용합니다.

- **Performance Highlights**: RAPID는 온라인 환경 상호작용을 통해 LLM 지식의 망각을 줄이고, 다양한 작업에 대한 적응성을 유지하면서도 효율적이고 강력한 RL 정책으로 LLM 지식을 통합하는 능력을 입증했습니다.



### Development of Image Collection Method Using YOLO and Siamese Network (https://arxiv.org/abs/2410.12561)
Comments:
          15 pages, 13 figures, 2 tables

- **What's New**: 본 논문에서는 웹 크롤링(web crawling) 방식의 데이터 수집에서 발생하는 비의도적 데이터 문제를 해결하기 위해 YOLOv10 객체 인식 모델을 사용하고, SIAMese 네트워크를 통해 재분류(image reclassification)를 수행함으로써 성능을 향상시켰음을 보여줍니다.

- **Technical Details**: YOLOv10 모델을 사용하여 웹 크롤링으로 수집된 데이터 중 불필요한 데이터를 필터링하고, SIAMese 네트워크의 거리 출력을 추가적으로 활용하여 이미지 재분류를 진행했습니다. 특히, 사용자들은 거리 임계값(threshold)을 지정하여 데이터 부족(data deficiency)과 잡음 저항성(noise-robustness) 간의 균형을 조절할 수 있습니다.

- **Performance Highlights**: 평균 f1 점수는 YOLO+MobileNet에서 0.678에서 YOLO+SiameseNet으로 0.772로 증가했습니다. 비컷(cropped) 이미지의 사용에 효과적으로 자원을 적게 사용하면서도 성능을 높일 수 있음을 보였으며, non-crop+Siamese(MobileNetV3-Small)에서 80.94가 컷 전처리(crop preprocessing)+Siamese(MobileNetV3-Small)에서 82.31로 상승했습니다.



### A Claim Decomposition Benchmark for Long-form Answer Verification (https://arxiv.org/abs/2410.12558)
Comments:
          Accepted by CCIR 2024

- **What's New**: 이번 연구에서는 LLM(대규모 언어 모델)의 응답에서 사실성이 결여된 'hallucination' 문제를 해결하기 위해, 각 주장에 대한 출처를 명확히 하는 새로운 기준을 제시합니다. 특히, 각 응답에서 주장이나 진술을 식별하는 것의 중요성을 강조하며, 이를 위한 새로운 Claim Decomposition Benchmark를 도입합니다.

- **Technical Details**: 우리는 CACDD(Chinese Atomic Claim Decomposition Dataset)를 소개합니다. 이 데이터셋은 500개의 인간 주석 질문-응답 쌍으로 구성되어 있으며, 총 4956개의 원자적(claim) 주장을 포함합니다. 데이터를 고품질로 유지하기 위해 전문가의 추가 주석이 포함되었습니다. 실험에서는 zero-shot, few-shot 및 fine-tuned LLM를 사용하여 성능 비교를 진행하였습니다.

- **Performance Highlights**: 실험 결과, 주장 분해(claim decomposition)는 매우 도전적인 작업으로, 추가적인 탐색이 필요하다는 것을 보여주었습니다. 모든 코드와 데이터는 공개적으로 사용 가능합니다.



### LLM-based Translation Inference with Iterative Bilingual Understanding (https://arxiv.org/abs/2410.12543)
Comments:
          work in process

- **What's New**: 본 연구에서는 Iterative Bilingual Understanding Translation (IBUT)이라는 새로운 방법을 제안합니다. 이 방법은 LLM의 교차 언어 능력과 번역 작업의 이중 특성을 기반으로 하여 번역 품질을 개선하는 데 초점을 맞추고 있습니다.

- **Technical Details**: IBUT 방법은 Understanding Generation, Alignment Judgment, Iterative Refinement, Understanding-Based Translation의 네 가지 부분으로 구성됩니다. IBUT는 먼저 LLM을 활용하여 소스 및 타겟 언어에 대한 맥락 이해를 생성하고, 그 후 이 이해를 기반으로 다양한 언어 쌍에서 번역을 수행합니다.

- **Performance Highlights**: 실험 결과, IBUT는 여러 강력한 비교 방법들보다 뛰어난 성능을 보였으며, 특히 뉴스, 상식, 문화 번역 벤치마크와 같은 다양한 도메인에 일반화되는 성능이 입증되었습니다. 평균적으로 +1.3, +4.2, +2.3의 COMET 점수 향상을 보였습니다.



### Characterizing Behavioral Differences and Adaptations of Automated Vehicles and Human Drivers at Unsignalized Intersections: Insights from Waymo and Lyft Open Datasets (https://arxiv.org/abs/2410.12538)
Comments:
          This work has been submitted to Transportation Research Record for potential publication

- **What's New**: 자율주행차(AV)와 인간 운전 차량(HV) 간의 상호작용 분석을 통해 비신호 교차로에서의 행동 차이를 조사한 연구입니다.

- **Technical Details**: 이 연구는 Waymo와 Lyft의 두 개의 포괄적인 AV 데이터셋을 활용하여, 병합 및 교차 충돌(conflict)을 식별하고 안전 및 효율성 지표인 '충돌까지의 시간(TTC)', '후방 침입 시간(PET)', '최대 필요 감속(MRD)', '시간 이점(TA)', 그리고 속도 및 가속 프로파일을 분석했습니다.

- **Performance Highlights**: AV는 더 큰 안전 마진을 유지하지만, 보수적인 행동으로 인해 인간 운전자에게 예기치 않은 상황을 초래할 수 있습니다. 인간 운전자는 AV와의 상호작용에서 더 일관된 행동을 보였으며, Waymo와 Lyft 차량 간에 뚜렷한 차이를 관찰하여 제조사별 AV 행동을 고려하는 것이 중요하다는 점을 강조했습니다.



### Is Complex Query Answering Really Complex? (https://arxiv.org/abs/2410.12537)
- **What's New**: 이 논문에서는 지식 그래프(knowledge graphs)에서 복잡한 질의 응답(complex query answering, CQA)이 새로운 도전 과제로 떠오르고 있다는 점을 강조합니다. 현재 사용되는 CQA 벤치마크가 실제로는 복잡하지 않으며, 이러한 벤치마크가 연구의 진행 상황에 대한 인식을 왜곡하고 있다는 주장을 합니다.

- **Technical Details**: 논문에서는 기존 벤치마크에서 대다수의 질의(특정 질의 유형의 경우 최대 98%)가 더 단순한 문제로 축소 가능하다는 것을 발견했습니다. 예를 들어, 링크 예측(link prediction) 문제에서는 예측해야 할 링크가 하나만 필요합니다. 그러므로 우리는 다중 홉(multiple hops)을 통한 추론을 요구하는 새로운 베치마크를 제안합니다.

- **Performance Highlights**: 새로운 벤치마크를 통한 체계적인 실험 조사 결과, 현재의 CQA 방법들이 여전히 많은 개선이 필요하다는 것을 보여주고 있습니다. 이는 현재의 최고 수준(state-of-the-art) CQA 모델들이 더 복잡한 질의에서 성능이 급격히 저하된다는 것을 의미합니다.



### Spectrum Sharing using Deep Reinforcement Learning in Vehicular Networks (https://arxiv.org/abs/2410.12521)
- **What's New**: 이 논문에서는 차량 네트워크에서의 스펙트럼 할당 문제를 해결하기 위해 딥 Q 네트워크 (Deep Q Network, DQN) 모델을 제안합니다. 이는 기존의 전통적인 방법으로는 해결하기 어려운 동적 차량 환경에서의 도전 과제를 다루고자 합니다.

- **Technical Details**: DQN 모델은 최적의 전략을 시간에 따라 학습하고 의사 결정을 내리는 능력을 활용합니다. 이 논문은 또한 심층 강화 학습 (Deep Reinforcement Learning) 방법을 사용하여 차량 네트워크 내에서 스펙트럼을 공유하는 경우의 성과를 분석합니다. 이 모델은 V2V (Vehicle-to-Vehicle) 통신에서 성공적인 결과를 보여주며, RL(강화 학습) 모델의 누적 보상(Cumulative Reward)이 훈련이 진행됨에 따라 극대화됩니다.

- **Performance Highlights**: DQN 모델이 스펙트럼 공유 효율성을 향상시키는 효과를 입증한 결과를 보여줍니다. 특히, SARL(단일 에이전트 강화 학습) 및 MARL(다중 에이전트 강화 학습) 모델이 차량 간 통신의 성공률을 향상시키고 있음이 강조되었습니다.



### QueensCAMP: an RGB-D dataset for robust Visual SLAM (https://arxiv.org/abs/2410.12520)
Comments:
          6 pages

- **What's New**: 이번 논문은 VSLAM의 강건성을 평가하기 위해 설계된 새로운 RGB-D 데이터셋을 소개합니다. 이 데이터셋은 동적 객체, 모션 블러(motion blur), 다양한 조명 조건을 포함한 실제 실내 장면으로 구성되어 있으며, 렌즈 오염(lens dirt), 응습(condensation), 과소 노출(underexposure), 과다 노출(overexposure)과 같은 카메라 고장도 시뮬레이션합니다.

- **Technical Details**: 이 데이터셋은 Vicon 모션 캡처 시스템을 사용하여 수집되었으며, 30Hz의 정확한 6DoF 위치 측정을 제공합니다. RGB 이미지는 1920x1080 해상도, 깊이 이미지는 640x480 해상도로 수집되어 있습니다. 1616개 시퀀스에서 총 28523 이미지를 캡처했으며, 고장 유도에 대한 추가 시퀀스도 포함되어 있습니다. 고장은 시뮬레이션을 통해 생성되며, 공개된 오픈 소스 스크립트를 통해 연구 커뮤니티가 커스터마이즈할 수 있도록 제공됩니다.

- **Performance Highlights**: 실험 결과, 전통적인 VSLAM 알고리즘인 ORB-SLAM2와 딥러닝 기반 VO 알고리즘인 TartanVO가 이러한 도전적인 조건에서 성능 저하를 겪음을 보여줍니다. 이는 생성된 데이터셋과 카메라 고장 도구들이 더 강건한 VSLAM 시스템 개발에 유용한 자원이 됨을 시사합니다.



### DH-VTON: Deep Text-Driven Virtual Try-On via Hybrid Attention Learning (https://arxiv.org/abs/2410.12501)
Comments:
          5 pages, 6 figures, ICASSP2025

- **What's New**: DH-VTON이라는 새로운 가상 착용(Virtual Try-ON) 모델을 제안합니다. 이 모델은 하이브리드 주의 학습 전략(hybrid attention learning strategy)과 깊은 의류 의미 보존 모듈(deep garment semantic preservation module)을 특징으로 합니다.

- **Technical Details**: 해당 모델은 InternViT-6B를 사용하여 깊이 있는 의류의 세부 특징을 학습하고, Garment-Feature ControlNet Plus (GFC+) 모듈을 통해 의류의 다양한 특성을 VTON 모델의 여러 층에 통합합니다. 이로 인해 다중 스케일 기능 보존(multi-scale features preservation) 효과를 달성할 수 있습니다.

- **Performance Highlights**: 다양한 대표 데이터셋에 대한 실험에서 DH-VTON은 기존의 diffusion 기반 및 GAN 기반 접근 방식보다 뛰어난 성능을 보여주며, 의류의 세부 사항을 잘 보존하고 사실적인 인간 이미지를 생성하는 데 경쟁력을 갖추고 있습니다.



### Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspectiv (https://arxiv.org/abs/2410.12490)
Comments:
          Accepted at NeurIPS 2024

- **What's New**: 최근 Latent Diffusion Models (LDMs)와 Mask Image Models (MIMs)와 같은 latent 기반 이미지 생성 모델이 이미지 생성 작업에서 뛰어난 성과를 거두었습니다. 그러나 autoregressive 모델이 LDMs와 MIMs에 비해 이미지 생성에서 상당히 뒤처져 있다는 흥미로운 관찰이 있었습니다. 이 발견은 NLP 분야와의 뚜렷한 대조를 이룹니다.

- **Technical Details**: 저자들은 이미지 생성 모델링에서 latent space의 안정성을 강조하며, 이를 위해 간단하지만 효과적인 이산 이미지 토크나이저(Tokenizer)를 제안하였습니다. 이 토크나이저(DiGIT)를 사용한 이미지 autoregressive 모델링은 이미지 이해 및 생성 과정에서 이점을 보여주었으며, 이는 기본적으로 GPT 모델에 대해 간단한 원칙입니다.

- **Performance Highlights**: 처음으로, GPT 스타일의 autoregressive 모델이 LDMs를 초월하는 성능을 보여주었으며, 모델 크기를 늘림에 따라 GPT와 유사한 상당한 개선을 또한 보여주었습니다. 이 결과는 최적화된 latent space와 이산 토큰화의 통합이 이미지 생성 모델의 능력을 향상할 수 있는 잠재력을 강조합니다.



### Stable Object Placement Planning From Contact Point Robustness (https://arxiv.org/abs/2410.12483)
Comments:
          Submitted to IEEE Transactions on Robotics. Contains 14 pages, 11 figures, and 3 tables

- **What's New**: 본 논문에서는 복잡한 장면 내에서 로봇 조작기가 물체를 안정적으로 배치하도록 안내하는 플래너(planner)를 소개합니다. 기존의 물체 배치 접근 방식을 역전시켜, 플래너가 먼저 접촉 지점(contact points)을 선택하고 그 후 선택된 지점을 유도하는 배치 자세(placement pose)를 결정합니다.

- **Technical Details**: 우리의 알고리즘은 안정성을 고려한 물체 배치 계획을 가능하게 하며, 물체의 형태, 볼록성(convexity), 또는 질량 밀도 동질성에 대한 제약을 두지 않으면서 복잡한 수학적 계산(combinatorial computational complexity)을 피합니다. 제안된 안정성 휴리스틱(stability heuristic)은 플래너가 같은 알고리즘에서 이 휴리스틱을 사용하지 않을 때보다 약 20배 더 빠른 해결책을 찾도록 합니다.

- **Performance Highlights**: 우리의 플래너는 기존의 샘플링 방식(sample-and-evaluate) 접근법을 사용하는 최첨단 방법보다 8배 더 빠르며, 다른 다섯 개의 벤치마크 알고리즘에 비해 안정적인 배치를 찾는 데 더 성공적입니다. 본 연구는 기본 원칙(first principles)에서 파생되었으며, 실제 로봇 실험 10회를 통해 검증되었습니다.



### SAC-GLAM: Improving Online RL for LLM agents with Soft Actor-Critic and Hindsight Relabeling (https://arxiv.org/abs/2410.12481)
- **What's New**: 최근 몇 년간 대규모 언어 모델(LLMs)이 생성 모델로뿐만 아니라 텍스트 순차적 의사결정 과제를 해결하는 에이전트로서의 역할도 발전하였습니다. 본 연구는 LLM 에이전트가 온라인 강화 학습(Reinforcement Learning, RL)을 통해 더 효과적인 전략을 발견하고 학습할 수 있는 방법을 제시합니다.

- **Technical Details**: 이 논문에서는 Soft Actor-Critic과 hindsight relabeling을 LLM 에이전트에 적응시키는 방법을 제안합니다. 기존 연구가 주로 on-policy 알고리즘에 의존했던 반면, 본 방법은 experience replay 및 hindsight relabeling과 같은 다양한 탐색(exploration) 및 착취(exploitation) 방법을 사용할 수 있는 범위를 크게 확장합니다.

- **Performance Highlights**: 제안된 방법은 자율적으로 동기부여된 목표를 샘플링하고 추구할 수 있는 LLM 에이전트를 향한 길을 열어줍니다. 뿐만 아니라, 고전적인 다목적 RL 환경에서도 on-policy 방법보다 더 뛰어난 성능을 보입니다.



### KcMF: A Knowledge-compliant Framework for Schema and Entity Matching with Fine-tuning-free LLMs (https://arxiv.org/abs/2410.12480)
- **What's New**: 이 논문은 Knowledge-Compliant Matching Framework (KcMF)를 제시하여 대규모 언어 모델(LLM)의 데이터 매칭(Task) 관련 신뢰성 문제를 해결하고자 한다. KcMF는 도메인별 세부 튜닝 없이 사용할 수 있으며, pseudo-code 기반의 작업 분해 전략을 사용하여 LLM의 추론 과정을 안내한다.

- **Technical Details**: KcMF는 두 가지 메커니즘인 Dataset as Knowledge (DaK)와 Example as Knowledge (EaK)를 사용하여 비구조화된 도메인 지식이 부족할 때 도메인 지식 세트를 구축한다. 또한, 결과 앙상블 전략인 Inconsistency-tolerant Generation Ensembling (IntGE)을 도입하여 여러 지식 출처를 활용하고 잘못 형식화된 출력을 억제한다.

- **Performance Highlights**: KcMF는 MIMIC 및 Synthea와 같은 다양한 벤치마크에서 평가되었으며, 이전의 비LLM 상태에서 가장 뛰어난 방법들보다 평균 F1 점수 22.9% 향상을 보이며, SOTA LLM과도 효과적으로 경쟁한다. KcMF는 다양한 LLM에서 잘 일반화된다는 점도 주목할 만하다.



### Unifying Economic and Language Models for Enhanced Sentiment Analysis of the Oil Mark (https://arxiv.org/abs/2410.12473)
- **What's New**: 원유 시장에 특화된 CrudeBERT라는 새로운 Language Model이 도입되었습니다. 이 모델은 기존의 전통적인 예측 방법의 한계를 극복하기 위해 개발되었습니다.

- **Technical Details**: CrudeBERT는 자연어 처리(Natural Language Processing) 분야에서 발전된 Generative Pre-trained Transformer(GPT) 모델을 기반으로 하며, 원유 시장에 특화된 용어를 효과적으로 처리하도록 파인 튜닝(Fine-tuning)되었습니다.

- **Performance Highlights**: CrudeBERT의 감정 점수(Sentiment Scores)는 WTI 선물 곡선(WTI Futures Curve)과 더 밀접하게 일치하며, 가격 예측(Price Predictions) 성능을 크게 향상시켰습니다.



### Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios (https://arxiv.org/abs/2410.12468)
Comments:
          10 pages of main content and 2 pages of references

- **What's New**: 이번 연구는 AI 기반의 소프트웨어 엔지니어링에서 에이전트(agents)에 의해 생성된 패치(patch)에 대한 첫 번째 종합 평가를 제공하며, 실제 GitHub 이슈에 대한 영향력을 분석합니다.

- **Technical Details**: 연구에서는 우수한 순위를 기록한 10개의 에이전트로부터 생성된 4,892개의 패치를 분석하고, SWE-Bench Verified의 500개의 실질적인 GitHub 이슈에 초점을 맞췄습니다. 이 과정에서 코드 품질에 미치는 영향을 중점적으로 살펴보았습니다.

- **Performance Highlights**: 연구 결과, 어떤 단일 에이전트도 모든 문제를 해결하지 못했으며, 170개의 이슈가 해결되지 않은 것으로 나타났습니다. 다수의 에이전트는 код 신뢰성과 보안을 유지하였고 새로운 버그 또는 취약점을 피했습니다. 그러나 일부 에이전트는 코드 복잡성을 증가시켰고, 많은 수의 에이전트가 코드 중복을 줄여 코드의 품질을 개선하는 경향을 보였습니다. 최종적으로, 에이전트는 단순한 코드베이스에서 더 나은 성능을 보였으며, 복잡한 작업을 작은 하위 작업으로 나누는 것이 효율성을 향상시킬 수 있음을 시사합니다.



### Sharpness-Aware Black-Box Optimization (https://arxiv.org/abs/2410.12457)
Comments:
          27 pages, 5 figures

- **What's New**: 이번 논문에서는 기존 블랙박스 최적화(Black-box optimization) 방법의 한계를 극복하기 위해 Sharpness-Aware Black-box Optimization (SABO) 알고리즘을 제안합니다. 이 알고리즘은 모델의 일반화(Generalization) 성능을 개선하기 위해 샤프니스 인식(Sharpness-aware) 최소화 전략을 적용합니다.

- **Technical Details**: SABO 알고리즘은 먼저 목표 함수(Objective function)를 가우시안 분포(Gaussian distribution)에 대한 기대값으로 재매개변수화(Reparameterization)합니다. 이후, 현재 솔루션 주변의 작은 이웃에서 최대 목표 값(Maximum objective value)의 근사 확률적 경량(Stochastic gradient)을 통해 매개변수화된 분포를 반복적으로 업데이트합니다.

- **Performance Highlights**: 광범위한 블랙박스 프롬프트 파인튜닝(Black-box prompt fine-tuning) 작업에 대한 실험 결과, 제안된 SABO 방법이 모델의 일반화 성능을 개선하는 데 효과적임을 입증했습니다.



### Open Ko-LLM Leaderboard2: Bridging Foundational and Practical Evaluation for Korean LLMs (https://arxiv.org/abs/2410.12445)
- **What's New**: Open Ko-LLM Leaderboard2가 기존의 Open Ko-LLM Leaderboard의 한계를 보완하여 새롭게 등장했습니다. 이 새로운 리더보드는 더 관련성 높은 실제 과업을 기반으로 한 벤치마크를 제공합니다.

- **Technical Details**: 기존의 벤치마크는 주로 영어 버전의 번역본으로 구성되어 있었으나, Open Ko-LLM Leaderboard2는 네 가지 새로운 한국어 네이티브 벤치마크를 도입하여 한국어의 고유한 특성을 보다 잘 반영합니다.

- **Performance Highlights**: 이 개선된 리더보드는 한국어 Large Language Model (LLM)에 대한 보다 의미 있는 평가를 제공하여 모델들의 질적 영향력을 높이는 데 기여하고자 합니다.



### Reconstruction of Differentially Private Text Sanitization via Large Language Models (https://arxiv.org/abs/2410.12443)
- **What's New**: 이 논문에서는 differential privacy (DP) 기준으로 LLMs (대규모 언어 모델)가 제시된 DP-sanitized prompts로부터 원래의 개인 정보를 재구성할 수 있음을 발견했습니다. 특히, 두 가지 공격 방식(black-box 및 white-box)을 제안하고 LLMs가 DP-sanitized 텍스트와 해당 개인 훈련 데이터의 연결 가능성을 보여주었습니다.

- **Technical Details**: 두 가지 공격 방식은 black-box instruction-based attacks와 white-box fine-tuning-based attacks입니다. black-box 공격에서는 사용자가 API를 통해 모델의 응답을 유도하고, white-box 공격에서는 모델 파라미터에 대한 접근을 통해 재구성 작업을 수행합니다. 실험은 LLaMA-2, ChatGPT-4, Claude-3.5 등 최신 LLMs를 사용하여 진행되었습니다.

- **Performance Highlights**: 실험 결과, black-box 공격을 통해 WikiMIA 데이터셋에서 LLaMA-2의 경우 72.18%, LLaMA-3의 경우 82.39%, ChatGPT-4o는 91.2%, Claude-3.5는 94.01%의 재구성 성공률을 기록했습니다. 이는 LLMs의 접근 방식과 훈련 데이터 노출이 재구성과 복원력에 영향을 미치는 신뢰할 수 있는 결과임을 시사합니다.



### Conformity in Large Language Models (https://arxiv.org/abs/2410.12428)
Comments:
          16 pages (8 pages main body), 14 figures

- **What's New**: 이 연구는 최신 LLMs(대형 언어 모델)에서의 conformity effect(순응 효과)를 분석하고, 모델들이 다수 의견에 얼마나 수용적인지를 탐구합니다.

- **Technical Details**: 심리 실험을 LLM에 적용하여, 원래 선택에 관계없이 모든 LLM이 다양한 지식 영역에서 다수에 대해 다양한 수준의 순응을 보이는 사실을 입증했습니다. 또한, 모델이 예측에 대한 불확실성이 높을수록 순응 가능성이 증가한다는 점을 발견했습니다. 훈련 패러다임과 입력 특성 등 순응에 영향을 미치는 요소를 분석하여, instruction-tuned 모델은 순응에 덜 영향을 받는다고 밝혀냈습니다.

- **Performance Highlights**: 정확한 응답에도 불구하고 LLM들이 다수의 의견에 따르는 경향이 있으며, 더 자연스러운 다수 톤이 순응을 강화하는 경향이 있습니다. 연구에서는 Devil's Advocate와 Question Distillation 두 가지 개입 방법을 제안하여, LLM의 순응을 완화하기 위한 통찰을 제공합니다.



### Privacy-Preserving Synthetically Augmented Knowledge Graphs with Semantic Utility (https://arxiv.org/abs/2410.12418)
Comments:
          32 pages, 5 figures

- **What's New**: 본 논문에서는 Knowledge Graphs(KGs)의 공유를 가능하게 하는 새로운 프레임워크를 제안하고 있으며, 개인 정보를 보호하는 동시에 비즈니스 작업을 위한 내재된 지식을 유지하는 방법에 대해 설명합니다.

- **Technical Details**: 제안된 접근 방식은 구조적 익명화를 통해 입력 KGs의 증강으로 개인 정보를 보호하는 합성 KG(synthetic KG)를 생성합니다. 또한, 파생된 지식(derived knowledge)을 고려한 새로운 개인 정보 보호 측정 기준과 비즈니스 의미를 보존하기 위한 유틸리티 메트릭을 도입하고, 두 가지 새로운 익명화 알고리즘을 제안합니다.

- **Performance Highlights**: 광범위한 실험 평가 결과, 본 접근 방식은 기존 KGs 전용으로 고안되지 않은 방법에 비해 엔티티의 개인 정보 보호에서 최대 70%의 향상을 달성하는 효과를 확인했습니다.



### Enhancing Speech Emotion Recognition through Segmental Average Pooling of Self-Supervised Learning Features (https://arxiv.org/abs/2410.12416)
- **What's New**: 본 논문은 Speech Emotion Recognition (SER)에서 기존의 Global Average Pooling (GAP) 방식을 개선하기 위해 Segmental Average Pooling (SAP) 방식을 도입하였습니다. 이 방법은 음성 세그먼트에만 집중하고 비음성 세그먼트를 무시하여 SER 성능을 향상시킵니다.

- **Technical Details**: Self-supervised learning (SSL) 기법을 사용하여 대량의 레이블이 없는 오디오 데이터로부터 의미 있는 표현을 학습합니다. SAP는 특히 유용한 음성 정보를 캡처하여 비음성 정보를 배제함으로써 GAP보다 더 나은 성능을 제공합니다.

- **Performance Highlights**: IEMOCAP 데이터셋에서 최신 기술 수준(state-of-the-art) 결과를 달성하였으며, 한국어 데이터셋 KEMDy19에서도 비가중치 및 가중치 정확도 모두에서 우수한 성능을 보였습니다.



### HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks (https://arxiv.org/abs/2410.12381)
Comments:
          homepage this https URL

- **What's New**: 본 논문에서는 LLMs(대형 언어 모델)의 시각적 이해 및 추론 능력을 평가하기 위해 특별히 설계된 새로운 벤치마크인 HumanEval-V를 소개합니다. 이는 기존의 코딩 작업을 기반으로 하여, 고도로 세심하게 제작된 108개의 Python 코딩 과제를 포함합니다.

- **Technical Details**: HumanEval-V는 CodeForces 및 Stack Overflow와 같은 플랫폼에서 유래된 문제들을 바탕으로 각 과제를 수정하여, 문제의 맥락과 알고리즘 패턴을 변화시켰습니다. 각 과제는 제공된 시각적 컨텍스트와 특정 Python 함수 서명을 기반으로 해결되어야 하며, 모델이 생성한 솔루션의 철저하고 신뢰할 수 있는 평가를 보장하기 위해 정교하게 제작된 테스트 케이스가 부여됩니다.

- **Performance Highlights**: 19개의 최첨단 LMM들을 HumanEval-V를 사용해 평가한 결과, GPT-4o와 같은 독점 모델은 13%의 pass@1과 36.4%의 pass@10만을 달성하는 등 상당한 도전 과제가 드러났습니다. 70B 파라미터를 가진 오픈 웨이트 모델은 pass@1 기준으로 4% 미만의 점수를 기록했습니다. 이러한 결과는 현재 LMM의 시각적 추론 및 코딩 능력의 한계를 강조하며, 향후 연구의 주요 영역을 제시합니다.



### Towards Neural Scaling Laws for Time Series Foundation Models (https://arxiv.org/abs/2410.12360)
- **What's New**: 이 논문은 time series foundation models (TSFMs)의 크기 및 계산 자원에 따른 스케일링 법칙(scaling laws)을 ID (in-distribution) 및 OOD (out-of-distribution) 데이터에서 분석합니다. 이전 연구들은 주로 ID 데이터에 초점을 맞추었으나, 본 연구는 OOD 상황에서의 TSFM의 성능과 모델 아키텍처의 영향을 평가합니다.

- **Technical Details**: 연구에서는 encoder-only 및 decoder-only Transformer 아키텍처를 사용하여, 세 가지 기본 훈련 요소(모델 크기, 계산 예산, 데이터셋 크기)의 변화를 조사하고, 그에 따른 성능을 ID 및 OOD 테스트 세트에서 측정하였습니다. 특히, log-likelihood loss가 OOD와 ID 모두에서 유사한 스케일링 행동을 보이는 것을 발견했습니다.

- **Performance Highlights**: encoder-only Transformer는 decoder-only Transformer에 비해 더 나은 확장성을 보였으며, 두 가지 첨단 TSFM 아키텍처(Moirai와 Chronos)에서의 성능 비교를 통해 ID 성능은 개선되나 OOD 확장성이 저하되는 것으로 나타났습니다. 이를 바탕으로 TSFM 설계와 확장에 대한 실용적인 지침을 제공합니다.



### GECTurk WEB: An Explainable Online Platform for Turkish Grammatical Error Detection and Correction (https://arxiv.org/abs/2410.12350)
- **What's New**: GECTurk WEB은 터키어의 문법 오류를 감지하고 수정할 수 있는 새로운 웹 기반 시스템으로, 기존의 도구들이 주로 맞춤법 오류에 집중했던 것과는 달리, 문법 오류에 중점을 두고 개발되었습니다.

- **Technical Details**: 이 시스템은 쉬운 접근성을 제공하며, 복잡한 문법 규칙을 가진 터키어의 일반적인 오류를 감지합니다. 여기에는 диacritics의 잘못된 사용, 복합어 및 외래어, 대명사, 경구와 같은 오류가 포함됩니다. 오프라인 및 온라인 도구로 제공되며 사용 효율성을 88.3으로 평가받았습니다.

- **Performance Highlights**: GECTurk WEB은 사용자가 문법 규칙을 학습하고 기억하는 데 도움을 주며, 참가자의 80%가 제시된 설명을 통해 문법 규칙을 이해하는 데 효과적이었다고 응답했습니다.



### TAS: Distilling Arbitrary Teacher and Student via a Hybrid Assistan (https://arxiv.org/abs/2410.12342)
Comments:
          18 pages, 6 figures, and 12 tables

- **What's New**: 이번 연구는 전통적인 Teacher-Student 아키텍처에 의존하지 않고, Cross-Architecture Knowledge Distillation (CAKD) 접근 방식을 통해 동종 및 이종 모델 간의 지식 전이를 유연하게 수행하는 방법을 제안합니다.

- **Technical Details**: 이 연구는 heterogeneous teacher와 student 간의 특징 전이를 원활하게 하기 위한 보조 모델(assistant model)을 introduce하며, convolution과 attention 모듈을 결합하여 서로 다른 아키텍처의 이점들을 통합합니다. 또한 InfoNCE loss를 통해 특징의 spatial alignment를 개선하여 성능을 향상시킵니다.

- **Performance Highlights**: 제안된 CAKD 방법은 CNN, ViT, MLP 모델의 다양한 조합에서 평가되었으며, CIFAR-100에서 최대 11.47% 향상된 성능과 ImageNet-1K에서 3.67%의 성능 향상을 달성하여, state-of-the-art 성능을 기록했습니다.



### A linguistic analysis of undesirable outcomes in the era of generative AI (https://arxiv.org/abs/2410.12341)
- **What's New**: 이 연구는 생성 AI 모델의 중장기 영향을 분석하며, 기계 생성 정보의 신뢰성을 탐구합니다. 특히, 기존 연구에서 소홀히 다루어진 언어적 측면을 집중적으로 분석하기 위해 LLama2의 대화형 버전을 기반으로 포괄적인 시뮬레이션 프레임워크를 제시합니다.

- **Technical Details**: 모델의 성능 저하는 'self-consuming loop'에 의해 일어납니다. 이 연구에서는 텍스트의 다양성을 측정하기 위해 엔트로피(Entropy), TTR(지수적 정확도)와 같은 언어적 척도와 POSTags 빈도를 사용합니다. 또한, n-그램(N-gram) 분석 및 의미망(Semantic Networks)을 통해 생성된 콘텐츠를 평가합니다.

- **Performance Highlights**: 연구 결과, LLama2 모델은 생성 과정에서 텍스트의 어휘적 풍부함이 감소하고 다양성이 줄어들며, 모델의 성능 저하는 콘텐츠의 질 저하와 동시에 언어적 패턴 왜곡으로 이어져 있다고 합니다. 이는 초기 입력 텍스트의 선택과 관리가 모델 붕괴 문제 해결에 매우 중요함을 강조합니다.



### Understanding the Role of LLMs in Multimodal Evaluation Benchmarks (https://arxiv.org/abs/2410.12329)
- **What's New**: 본 논문은 Multimodal Large Language Models (MLLMs)의 평가에서 LLM 백본(LLM backbone)의 역할을 심도있게 조사하여, 현재의 벤치마크가 실제로 멀티모달 추론(multimodal reasoning)을 평가하는 정도와 LLM의 사전 지식(prior knowledge)이 성능에 미치는 영향을 규명합니다.

- **Technical Details**: 우리는 LLM 백본과 멀티모달 통합(multimodal integration)의 기여도를 분리하기 위한 수정된 평가 프로토콜(modified evaluation protocol)과 LLM이 멀티모달 질문에 필요한 지식을 갖추고 있는지를 진단하는 자동 지식 식별 기술(automatic knowledge identification technique)을 소개합니다. 연구는 네 가지 다양한 MLLM 벤치마크와 여덟 가지 최첨단 MLLMs를 포함합니다.

- **Performance Highlights**: 핵심 발견은 일부 벤치마크가 시각적 입력 없이도 높은 성능(high performance)을 허용하며, LLM 백본의 부족한 세계 지식이 오류율의 최대 50%를 차지할 수 있다는 것입니다. 이는 언어 능력에 대한 심한 의존도를 보여줍니다. 지식 부족 문제를 해결하기 위해 우리는 지식 증강 파이프라인(knowledge augmentation pipeline)을 제안하며, 이는 특정 데이터셋에서 최대 60%의 성능 향상을 이루어 약 4배 성능 증가를 가져옵니다.



### Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up (https://arxiv.org/abs/2410.12323)
- **What's New**: 이번 논문에서는 Reversal of Thought (RoT)라는 새로운 프레임워크를 제안하여 대형 언어 모델(LLM)의 논리적 추론 능력을 향상시킵니다. RoT는 메타 인지 메커니즘을 통합하여 LLM이 사람의 피드백에 기반하여 cognitive preference에 맞게 태스크별 프롬프트를 생성할 수 있도록 지원합니다.

- **Technical Details**: RoT는 Preference-Guided Reverse Reasoning 전략을 활용하여, pseudocode 계획을 위한 논리 기호를 통합하고, 쌍대 선호 자기 평가를 통해 특정 태스크를 위한 프롬프트를 생성합니다. 또한, Cognitive Preference Manager를 통해 LLM의 지식 경계를 평가하고, 알려진 태스크에 대한 솔루션 논리를 집계하며, 알려지지 않은 태스크에 대한 스타일 템플릿을 사용하여 논리적 추론 능력을 확장합니다.

- **Performance Highlights**: 여러 태스크에서의 실험 결과, RoT는 기존 방법들보다 논리적 추론의 정확성과 효율성 모두에서 우수한 성능을 보였습니다. 이는 RoT가 LLM의 논리적 유연성과 정확성을 동시에 개선하는 데 기여함을 나타냅니다.



### UTF:Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification (https://arxiv.org/abs/2410.12318)
- **What's New**: 본 논문에서는 대형 언어 모델(LLM)의 소유권 검증과 인증을 위해 새로운 지문 인식 방법인 UTF를 소개합니다. 이 방법은 기존의 전통적인 방법에 비해 효율적이며 저렴한 계산 비용으로 지문 인식을 수행합니다.

- **Technical Details**: UTF는 'under-trained tokens'를 활용하여 모델을 지문화합니다. Under-trained tokens는 모델 훈련 과정에서 충분히 학습되지 않은 토큰들로, 이들을 이용해 특정 입력-출력 쌍을 모델에 내장하도록 감독하에 미세 조정(supervised fine-tuning)을 수행합니다. 이 과정을 통해 LLM은 정해진 입력에 대해 예측된 출력을 생성할 수 있게 됩니다.

- **Performance Highlights**: UTF 방법은 모델 성능에 미치는 영향이 적으며, 기존의 지문 인식 방법들에 비해 더 효과적이고 튼튼하게 작동하며, 모델 소유권 식별을 위한 화이트 박스 액세스(white-box access)를 요구하지 않습니다.



### FaceChain-FACT: Face Adapter with Decoupled Training for Identity-preserved Personalization (https://arxiv.org/abs/2410.12312)
Comments:
          12 pages, 8 figures

- **What's New**: 본 논문은 인물 식별 기능의 분리와 발전된 이미지 생성 방법을 제안한 Face Adapter with deCoupled Training (FACT) 프레임워크를 제시합니다. 이를 통해 텍스트-이미지 모델에서 인물의 정체성을 보존하면서도 정확도와 다양성을 높입니다.

- **Technical Details**: FACT는 transformer 기반의 얼굴 인식 모델을 통해 세분화된 정체성 기능을 활용하였으며, Gated Self-Attention (GSA) 모듈을 U-Net에 삽입해 얼굴 특징에 개별적으로 적응하도록 만들었습니다. 이를 통해 얼굴 영역에서의 변화를 제어하고, FAce Adapting Increment Regularization (FAIR) 기법을 통해 면밀한 조정을 압박합니다.

- **Performance Highlights**: 실험 결과, FACT는 기존의 adapter 기반 개인화 방법에 비해 아이덴티티 유사도, 텍스트 따른 생성 능력, 얼굴의 통제력 및 다양성에서 향상된 성능을 보였습니다. 또한, FACT는 LORA나 ControlNet 같은 기존의 세분화 모델과의 통합에서도 생성 성능을 저하시키지 않습니다.



### Open Domain Question Answering with Conflicting Contexts (https://arxiv.org/abs/2410.12311)
- **What's New**: 이 논문은 웹에서 검색된 정보가 상충하는 경우에 대해 다룬 첫 번째 연구 중 하나로, 25%의 명확한 질문이 상충하는 정보에 이끌릴 수 있음을 보여줍니다. 이 연구는 Question Answering with Conflicting Contexts (QACC)라는 데이터셋을 수집하고, 이를 기반으로 대형 언어 모델(LLMs)의 한계를 분석합니다.

- **Technical Details**: 연구팀은 Google Search API를 사용하여 명확한 질문에 대한 결과를 수집하고, Amazon Mechanical Turk를 통해 인간 주석자들이 상충하는 대답의 존재 여부를 판단하도록 했습니다. 이를 통해 명확한 질문의 약 25%가 상충하는 정보를 생성함을 발견했습니다. 또한, 이들은 GPT-3.5, Claude-3, Phi-3와 같은 세 가지 LLM을 평가하였고, 이러한 상충이 성능 저하를 초래한다는 것을 보여주었습니다.

- **Performance Highlights**: 주석자의 자연어 설명으로 LLM을 파인튜닝한 결과, LLM의 성능이 향상되었습니다. 특히, QACC 데이터셋과 DQ-Open 데이터셋에서 상충하는 정보를 처리하는 능력이 개선되었습니다. 이는 LLM이 상충하는 맥락을 이해하고 올바른 답변을 내리는 데 도움이 되는 중요한 통찰을 제시합니다.



### Two Birds with One Stone: Multi-Task Semantic Communications Systems over Relay Chann (https://arxiv.org/abs/2410.12302)
Comments:
          submitted to IEEE WCNC

- **What's New**: 본 논문에서는 하나의 송신으로 이미지 재구성 및 분류를 동시에 수행할 수 있는 새로운 다중 작업, 다중 링크 중계 의미 통신 (MTML-RSC) 방안을 제안합니다.

- **Technical Details**: MTML-RSC 방안에서는 원천 노드가 의미 통신을 사용하여 신호를 방송하고, 중계 노드가 해당 신호를 목적지로 전달합니다. 두 작업과 두 링크 (원천-중계 및 원천-목적지) 간의 결합 관계를 분석하고, 중계 노드에게 관련 클래스의 의미만 선택적으로 전달하도록 설계된 의미 중심의 전달 방법을 제안합니다.

- **Performance Highlights**: MTML-RSC 방안은 이미지 재구성에서 피크 신호 대 잡음비 (PSNR) $1.73$dB의 향상을 이루었으며, 분류 정확도를 $64.89\%$에서 $70.31\%$로 증가시키는 성능 향상을 보여줍니다.



### Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs (https://arxiv.org/abs/2410.12298)
- **What's New**: Pyramid-Driven Alignment (PDA)라는 새로운 프레임워크를 제안하여 LLM(대형 언어 모델)과 KG(지식 그래프)의 통합을 최적화하고, 이를 통해 더 정확한 질문-답변 작업을 수행할 수 있도록 한다.

- **Technical Details**: PDA는 Pyramid Principle 분석을 사용하여 계층적 피라미드 구조를 구축하며, 이것이 입력 질문을 반영하도록 설계된다. 또한, 재귀적 메커니즘을 통해 KG의 추론 능력을 활용하여 질문-답변 작업을 위한 더 정확한 지식 검색을 가능하게 한다.

- **Performance Highlights**: PDA는 2WikiMultihopQA, Mintaka, WebQuestionsSP와 같은 세 가지 데이터셋에서 실험을 진행했으며, 각 데이터셋에서 SOTA(최첨단 성능) 결과를 달성하여 최대 26.70% 및 26.78%의 성능 향상을 이뤄냈다.



### Conjunction Subspaces Test for Conformal and Selective Classification (https://arxiv.org/abs/2410.12297)
Comments:
          36 pages, 9 figures

- **What's New**: 이 논문에서는 다양한 랜덤 서브스페이스(random subspaces)에서의 유의성 검정(significance testing) 결과를 통합하여 분류 결정의 불확실성을 정량화하는 새로운 분류기(classifier)를 제안합니다. 이 분류기는 일관된 p-value를 생성하여 개인화된 예측(conformal prediction) 및 선택적 분류(selective classification)에 활용될 수 있습니다.

- **Technical Details**: 제안된 분류기는 타깃 클래스(target class)와의 연관성이 없다는 귀무 가설(null hypothesis)을 바탕으로 합니다. 이는 가설의 접합(conjunction) 검정 문제로 분류 문제를 구성할 수 있음을 의미합니다. 이론적으로는 일반화 오류 경계(generalization error bound)에 대한 분석이 이루어졌으며, 실질 데이터 세트(real data sets)에서의 경험적 연구(empirical studies)도 포함되어 있습니다.

- **Performance Highlights**: 제안된 분류기의 성능은 다양한 데이터 세트를 통해 효과성 효과를 입증하며, thresholding을 통해 선택적 거부(reject) 및 세분화(refine) 옵션을 간편하게 적용할 수 있습니다.



### Consistency Calibration: Improving Uncertainty Calibration via Consistency among Perturbed Neighbors (https://arxiv.org/abs/2410.12295)
- **What's New**: 이번 논문에서는 딥러닝 응용 분야에서 모델의 보정을 위한 새로운 개념인 Consistency (일관성)을 도입합니다. 이는 대규모 언어 모델(LLM)에서 영감을 얻었으며, 기존의 신뢰 기반 관점에 비해 다양한 장점을 강조합니다.

- **Technical Details**: Consistency Calibration (CC)라는 새로운 사후 보정 방법을 제안하고, 이는 변화된 입력에 대한 모델의 일관성을 기반으로 신뢰도를 조정합니다. CC는 추가적인 데이터 샘플이나 레이블 정보를 요구하지 않으며, 소스 데이터에서 직접 입력 변화를 생성합니다. 또한, logit 수준에서의 변화를 수행함으로써 계산 효율성을 크게 개선합니다.

- **Performance Highlights**: CIFAR-10, CIFAR-100 및 ImageNet과 같은 표준 데이터셋뿐만 아니라 ImageNet-LT와 같은 긴 꼬리 데이터셋에서도 다양한 사후 및 학습 시간 보정 방법과 비교하여 최첨단 성능을 입증했습니다.



### Beyond Oversmoothing: Evaluating DDPM and MSE for Scalable Speech Synthesis in ASR (https://arxiv.org/abs/2410.12279)
Comments:
          Under review at ICASSP 2025

- **What's New**: 이 논문에서는 TTS(Text-to-Speech) 시스템에서 의도적으로 생성된 합성 음성이 인간 수준의 자연스러움에 근접했지만, ASR(Automatic Speech Recognition) 시스템의 성능은 여전히 실 음성에 비해 낮다는 패러독스를 탐구합니다.

- **Technical Details**: Denoising Diffusion Probabilistic Models (DDPM)와 Mean Squared Error (MSE) 기반 모델을 비교하여 ASR 모델 교육에 관한 성능을 분석합니다. DDPM은 더 다양한 발화자와 데이터를 활용하는 데에 더 효과적이며, 모드 붕괴(mode collapse)를 줄이고 전체 확률 분포를 모델링하는 데 중요한 역할을 합니다. 또한, TTS 훈련 데이터 크기에 따른 ASR 성능 변화를 단계적으로 분석합니다.

- **Performance Highlights**: 예를 들어, DDPM을 사용하여 합성음성과 실음성 간의 단어 오류율(Word Error Rate, WER) 비율을 1.46으로 기록했으나, 실제 음성과 합성 음성 간의 성능 차이는 여전히 남아있음을 발견했습니다. 이러한 결과는 DDPM이 MSE보다 더 유리한 스케일링 곡선을 보이고, 두 모델 모두 감소하는 수익의 한계를 겪고 있다는 것을 보여줍니다.



### Controlled Automatic Task-Specific Synthetic Data Generation for Hallucination Detection (https://arxiv.org/abs/2410.12278)
- **What's New**: 이 논문에서는 환각 감지를 위한 비트리비얼(task-specific) 합성 데이터세트를 자동으로 생성하는 새로운 접근 방식을 제안합니다. 이 방법은 두 단계의 생성-선택 파이프라인을 특징으로 하며, 환각 패턴 지침(hallucination pattern guidance) 및 언어 스타일 정렬(language style alignment)을 활용하여 데이터 품질을 향상시킵니다.

- **Technical Details**: 제안된 방법은 자동화된 생성-선택 파이프라인을 기반으로 하며, 환각 패턴 가이드를 통해 특정 작업에 적합한 환각 샘플을 생성하고, 언어 스타일 정렬을 통해 합성 데이터의 스타일을 벤치마크 텍스트와 일치시킵니다. 이 방법은 세 가지 대화 벤치마크에서 실험을 통해 검증되었으며, F1 점수 0.938을 달성하여 기존의 인컨텍스트러닝(ICL) 기반 감지기를 32.5%의 큰 차이로 초과했습니다.

- **Performance Highlights**: 제안된 환각 감지기는 생성된 합성 데이터세트를 통해 훈련된 결과, 상기된 세 가지 차원에서 뛰어난 일반화 능력을 보여주었습니다. 또한, 생성된 합성 환각이 실제 비환각 샘플에 더 유사함을 입증하였으며, 이는 우리 접근 방식의 강력한 일반화 능력을 확인하였습니다.



### Kallini et al. (2024) do not compare impossible languages with constituency-based ones (https://arxiv.org/abs/2410.12271)
- **What's New**: 이 논문은 언어 모델이 인간 언어의 경계를 이해하는 데 어떻게 사용될 수 있는지를 탐구하며, GPT-2가 다양한 인공 언어(synthetic languages)를 학습할 때의 비대칭성(asymmetry)을 분석합니다.

- **Technical Details**: Kallini et al. (2024)의 연구에 따르면, LLMs(large language models)는 인간 언어를 학습하는 데 성공할 뿐만 아니라 불가능한 언어 언어(impossible languages)를 학습하는 데 어려움을 겪는지 테스트하였습니다. 이 비대칭성은 LLM의 귀납적 편향(inductive biases)이 인간 언어에 대한 가능성과 일치한다는 지지를 제공합니다.

- **Performance Highlights**: 논문에서 제시된 주요 비판은 Kallini et al.의 비교가 잘못된 혼합(confound)을 포함하고 있으며, 더욱 적절한 비교를 위해 다양한 constituency-based 규칙을 탐색할 것을 제안합니다.



### CATCH: Channel-Aware multivariate Time Series Anomaly Detection via Frequency Patching (https://arxiv.org/abs/2410.12261)
- **What's New**: 이 논문에서는 다변량 시계열(anomaly detection in multivariate time series)에서 발생하는 이질적인 subsequence anomalies를 탐지하기 위한 새로운 프레임워크인 CATCH를 제안합니다. CATCH는 주파수(patch) 영역 패칭(frequency patching)을 기반으로 하여, 다양한 형태의 비정상 시퀀스를 포착할 수 있는 능력을 향상시킵니다.

- **Technical Details**: CATCH 프레임워크는 주파수 영역에서 패치(patching) 기법을 사용하여 정밀한 주파수 특성을 포착합니다. 또한, Channel Fusion Module (CFM)을 통해 채널 간의 상관관계를 인식하여 적절한 패치-와이즈 채널 상관관계를 iteratively 발견하고 군집화할 수 있도록 합니다. 이는 bi-level multi-objective optimization 알고리즘에 의해 주도됩니다.

- **Performance Highlights**: CATCH는 9개의 실제 데이터셋과 12개의 합성 데이터셋에서 extensive experiments를 수행하여 최신 기법들보다 뛰어난 성능을 보여주었습니다. 모든 데이터셋과 코드는 https://anonymous.4open.science/r/CATCH-E535에서 확인할 수 있습니다.



### Understanding Expert Structures on Minimax Parameter Estimation in Contaminated Mixture of Experts (https://arxiv.org/abs/2410.12258)
Comments:
          Fanqi Yan, Huy Nguyen, Dung Le contributed equally to this work. 70 pages, 6 figures, 1 table

- **What's New**: 본 논문에서는 오염된 전문가 혼합 모델에서의 매개변수 추정(parameter estimation) 수렴 분석을 수행합니다. 이 모델은 프롬프트 학습(prompt learning) 문제에서 파생되었으며, 프롬프트를 전문가(experts)로 활용하여 대규모 사전 학습 모델(pre-trained model)을 미세 조정하는 방법을 다룹니다.

- **Technical Details**: 분석 과정에서 두 가지 기본적인 과제가 등장합니다: (i) 사전 학습 모델의 혼합 비율이 훈련 과정 중에 제로(0)로 수렴할 수 있으며, 그로 인해 프롬프트가 사라질 수 있습니다; (ii) 사전 학습 모델과 프롬프트의 매개변수 간 대수적(algebraic) 상호작용이 일부 편미분 방정식(partial differential equation)을 통해 발생하며 프롬프트 학습을 저하시킬 수 있습니다. 이러한 문제를 해결하기 위해, 매개변수 상호작용을 제어하기 위한 구별 가능성 조건(distinguishability condition)을 제시하며, 다양한 전문가 구조(expert structures)를 고려하여 매개변수 추정에 미치는 영향을 분석합니다.

- **Performance Highlights**: 각 시나리오에 대해 매개변수 추정의 포괄적인 수렴 속도(convergence rates)와 해당 최소 최악 하한(minimax lower bounds)을 제공합니다.



### Dual Action Policy for Robust Sim-to-Real Reinforcement Learning (https://arxiv.org/abs/2410.12250)
- **What's New**: 이번 논문에서는 Dual Action Policy (DAP)라는 새로운 접근 방식을 제안하여 강화 학습의 sim-to-real gap에서 발생하는 동적 불일치를 해결합니다. DAP는 단일 정책을 사용하여 두 개의 행동 세트를 예측하는 방식을 채택합니다. 하나는 시뮬레이션에서 작업 보상을 최대화하기 위한 것이고, 다른 하나는 보상 조정을 통한 도메인 적응을 위한 것입니다.

- **Technical Details**: DAP는 시뮬레이션 환경에서 작업 보상을 최대화할 뿐만 아니라 동적 불일치를 해결하기 위해 행동을 분리합니다. 교육 중 불확실성 기반 탐사를 적용하여 에이전트의 강건성을 향상시키고, 이는 최종 배치에서의 자기 수정과 더 확실한 상태-행동 분포로의 복귀를 가능하게 합니다.

- **Performance Highlights**: 실험 결과, DAP는 다양한 동적 불일치를 가진 도전적인 시뮬레이션 작업에서 모든 기준선보다 우수한 성능을 보여주었습니다. 불확실성 추정치를 통합함으로써 성능이 더욱 개선되었으며, 어떤 경우에는 최적의 결과에 가까운 성과를 달성했습니다.



### Enhancing LLM Agents for Code Generation with Possibility and Pass-rate Prioritized Experience Replay (https://arxiv.org/abs/2410.12236)
- **What's New**: 본 논문에서는 코드 생성 작업에서 transformer 기반 대형 언어 모델(LLM)의 비효율성을 극복하기 위해 경험 재생(Experience Replay, ER)을 도입한 새로운 BTP 파이프라인을 제안합니다.

- **Technical Details**: BTP 파이프라인은 세 가지 단계로 구성됩니다: beam search sampling, testing, 및 경험 재생 단계입니다. P2Value(가능성과 통과율 값)는 프로그램의 가치를 평가하는 데 사용되며, 실패한 코드 모델로부터 수집된 프로그램들을 활용하여 효율성을 높입니다.

- **Performance Highlights**: 실험 결과, BTP 파이프라인은 기존 모델보다 코드 생성 작업에서 성능을 향상시켰으며, 자가 생성된 데이터든 고품질 모델에 의해 생성된 데이터든 상관없이 우수한 성능을 보여주었습니다.



### Improving the Generalization of Unseen Crowd Behaviors for Reinforcement Learning based Local Motion Planners (https://arxiv.org/abs/2410.12232)
- **What's New**: 본 논문에서는 동적인 환경에서 사람 보행자와의 안전한 이동 로봇 정책을 배포하기 위한 새로운 방법을 제안합니다. 이전 연구들은 한 개의 정책만을 사용하여 보행자 운동을 시뮬레이션했으며, 이는 과적합(over-fitting) 문제로 이어질 수 있습니다. 본 연구는 에이전트의 다양성을 극대화하여 단일 정책 내에서 이를 해결하는 방법을 소개합니다.

- **Technical Details**: 우리는 에이전트들이 목표에 도달하기 위해 동적으로 움직일 수 있도록 학습하는 다중 에이전트 프레임워크를 활용하여 충돌 회피 문제를 다룹니다. 에이전트들은 동작 경험을 다각화하고, 보행자 군중의 다양한 행동에 대한 적응성을 향상시킵니다. 정책을 기준으로 하는 행동을 도입하였으며, 이는 각 에이전트가 훈련 에피소드 시작 시 무작위로 샘플된 행동으로부터 파생됩니다. 이러한 행동에 대한 내재적 보상을 에이전트에게 부여하여 다양한 행동을 취하도록 유도합니다.

- **Performance Highlights**: 제안된 행동 조건부 정책은 다양한 보행자 행동 시나리오에서 기존 방법들보다 더 강건성을 보이며, 추가적인 시간이나 여행 거리 없이도 잠재적 충돌을 줄일 수 있음을 시뮬레이션 결과를 통해 확인하였습니다.



### Comprehending Knowledge Graphs with Large Language Models for Recommender Systems (https://arxiv.org/abs/2410.12229)
- **What's New**: 이번 연구에서는 CoLaKG라는 새로운 방법을 제안하여 추천 시스템의 성능을 개선합니다. CoLaKG는 대규모 언어 모델(LLM)을 활용하여 지식 그래프(KG)의 한계를 극복하고, 아이템 간의 세밀한 의미적 연결을 유지합니다.

- **Technical Details**: CoLaKG는 아이템 중심의 하위 그래프(subgraph)를 KG에서 추출하고, 이를 LLM에 대한 입력으로 변환합니다. LLM은 이러한 하위 그래프에 대한 이해를 출력하고, 이를 의미적 임베딩(semantic embedding)으로 변환합니다. 또한, 이 임베딩을 바탕으로 아이템-아이템 그래프(item-item graph)를 구성하여 고차원 관계를 직접적으로 포착합니다.

- **Performance Highlights**: 실제 데이터셋 4종에 대한 광범위한 실험 결과, CoLaKG 방법이 기존 방법들에 비해 우수한 성능을 보였음을 확인했습니다.



### Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations (https://arxiv.org/abs/2410.12228)
- **What's New**: 이 논문은 개인화 추천 시스템을 향상시키기 위해 다양한 데이터 모달리티(data modalities)를 통합하는 새로운 프레임워크인 Triple Modality Fusion (TMF)를 소개합니다. 이 프레임워크는 시각적, 텍스트, 그래프 데이터의 융합을 통해 수행됩니다.

- **Technical Details**: TMF 모델은 큰 언어 모델(LLMs)과의 정렬을 통해 세 가지 모달리티를 통합하며, 각각의 모달리티는 사용자 행동을 포괄적으로 표현하기 위해 서로 다른 특징을 제공합니다. 시각적 정보는 아이템의 맥락 및 미적 특성을 캡처하고, 텍스트 데이터는 사용자 관심사와 아이템 특성에 대한 상세한 통찰력을 제공하며, 그래프 데이터는 아이템-행동 이질 그래프(item-behavior heterogeneous graph) 내의 관계를 설명합니다.

- **Performance Highlights**: 광범위한 실험을 통해 추천 정확성을 개선하는 효과를 입증하였습니다. 추가적인 ablation 연구를 통해 TMF 모델 디자인의 효과성과 이점을 검증하였습니다.



### On A Scale From 1 to 5: Quantifying Hallucination in Faithfulness Evaluation (https://arxiv.org/abs/2410.12222)
Comments:
          14 pages, 13 figures

- **What's New**: 이번 논문에서는 자동화된 사실성 평가를 통해 자연어 생성(NLG)의 신뢰성을 높이기 위한 방법을 연구하였습니다. 특히, 신뢰도를 평가하기 위해 대형 언어 모델(LLM)을 활용한 점수 매기기 방법을 제안하였습니다.

- **Technical Details**: 제안된 방법은 LLM과 자연어 추론(NLI) 모델을 이용하여 참조(referece)와 가설(hypothesis) 쌍의 신뢰성 점수를 도출합니다. 또한, 다양한 유형의 가설을 비교하여 신뢰도 점수의 변동성을 분석하였고, 합성된 비신뢰한 데이터를 생성하는 방법도 개발하였습니다.

- **Performance Highlights**: 연구 결과, GPT-4 모델은 소스와 생성이 사실적으로 일치하는지를 정확하게 판단하고 설명할 수 있음을 보여주었습니다. 비신뢰성 데이터로 NLI 모델을 조정할 경우 성능이 향상되었고, 이러한 시스템의 배포 시 레이턴시(latency)와 비용에 대한 통찰도 제공하였습니다.



### EdgeRL: Reinforcement Learning-driven Deep Learning Model Inference Optimization at Edg (https://arxiv.org/abs/2410.12221)
- **What's New**: 본 논문에서는 EdgeRL 프레임워크를 제안하여 공공 안전과 같은 임무-critical한 애플리케이션에서 강화 학습(Reinforcement Learning) 방법론인 Advantage Actor-Critic(A2C)을 활용하여 최적의 DNN 실행 매개변수를 선택하고, 성능 지표를 조율합니다. 이는 end-to-end 지연(latency), 결과 정확도(accuracy), 및 에너지 소비(energy consumption) 간의 균형을 맞추기 위한 것입니다.

- **Technical Details**: EdgeRL 프레임워크는 DNN 실행 프로파일을 선택하도록 설계되어 있습니다. 이는 기존 DNN 모델의 여러 사전 캐시된(Pre-cached) 버전 중에서 최적화된 버전을 선택하고, 선택된 버전에 대해 파티션 컷 포인트를 선택하여 edge 서버와 협력적 추론(collaborative inference)을 수행하게 됩니다. 이 실행 프로파일 선택은 Markov Decision Process(MDP)로 모델링되고, A2C 기반 강화 학습 방법으로 해결됩니다. 시스템의 입력으로는 end device의 배터리 상태, 활동 프로파일, 사용 가능한 대역폭(bandwidth), 운동 활동 등이 포함되어 지속적으로 시스템 동적을 학습하고 조정합니다.

- **Performance Highlights**: EdgeRL 프레임워크는 DNN 추론의 에너지 절약(Energy Savings), 정확도 개선(Accuracy Improvement), 및 end-to-end 지연 감소(Latency Reduction) 측면에서 실제 DNN 모델 및 하드웨어 테스트베드를 통해 그 효과를 평가하였습니다.



### Order-Aware Interactive Segmentation (https://arxiv.org/abs/2410.12214)
Comments:
          Interactive demo can be found in project page: this https URL

- **What's New**: 본 논문에서는 OIS(order-aware interactive segmentation)를 제안하여 객체의 상대적인 깊이 정보를 코드화하여 사용자 상호작용을 개선하고, 세밀한 객체 분리를 가능하게 합니다.

- **Technical Details**: OIS는 order map을 활용하여 사용자 상호작용(클릭)의 효과를 극대화하며, 객체 인식 강화를 위해 object-aware attention 모듈을 도입합니다. 이 방식은 양호한 분류 성능을 제공하면서도 속도는 두 배로 향상시킵니다.

- **Performance Highlights**: OIS는 HQSeg44K 데이터셋에서 하나의 클릭 후 7.61 mIoU를, DAVIS 데이터셋에서 1.32 mIoU를 향상시켜 기존의 SegNext보다 우수한 성능을 나타내며, 계산 속도도 두 배로 증가시킵니다.



### Abnormality Forecasting: Time Series Anomaly Prediction via Future Context Modeling (https://arxiv.org/abs/2410.12206)
Comments:
          11 pages, 5 figures, submitted to KDD conference

- **What's New**: 이번 연구에서는 시간 시계열 데이터에서 이상 예측(anomaly prediction)을 다루며, 이상 사건이 발생하기 전에 조기 경고를 제공하는 데 중점을 두고 있습니다. 기존의 연구들은 이상 사건이 발생한 후에 발견하는 데 초점을 맞추었지만, 본 연구는 실용적이고 도전적인 문제에 접근합니다.

- **Technical Details**: 이상 예측을 위해 새로운 접근방식인 future context modeling (FCM)을 도입합니다. FCM의 핵심 아이디어는 목표 창(window)에서 발생할 미래의 이상 사건을 예측하는 것이며, 이것은 정상 데이터와의 미세한 차이를 포착함으로써 가능합니다. FCM은 장기 예측 모델을 활용하여 관찰 데이터(observation data)에서 차별화된 미래 맥락(future context)을 생성하고, 이 맥락을 통해 잠재적인 이상을 더욱 잘 예상합니다. 또한, FCM은 시계열 데이터의 시간 신호(temporal signals) 및 특징(features)을 함께 활용하는 joint variate-time attention learning을 도입하여 정상성 모델링을 개선합니다.

- **Performance Highlights**: 다양한 5개 데이터셋에 대한 포괄적인 실험 결과, FCM은 70% 이상의 높은 재현율(recall rate)을 달성했으며, 모든 기준선(baselines) 대비 F1 스코어에서 유의미한 성과를 보였습니다. 코드는 해당 링크에서 확인 가능합니다.



### Sparse Prototype Network for Explainable Pedestrian Behavior Prediction (https://arxiv.org/abs/2410.12195)
- **What's New**: 본 논문에서는 보행자 행동 예측에 있어 기존의 여러 겹의 특성과 행위를 동시에 예측할 수 있도록 설계된 Sparse Prototype Network (SPN)을 소개합니다. 이 모델은 예측의 설명 가능성을 높이기 위한 중간 프로토타입 병목 층을 활용하여, 모든 입력 모달리티에 대해 독립적인 프로토타입을 학습합니다.

- **Technical Details**: SPN은 세 가지 주요 모듈로 구성되어 있습니다: 입력 인코딩, 프로토타입 층, 그리고 예측 헤드입니다. 입력 인코딩 모듈은 각 모달리티를 독립적으로 처리하며, 원시 입력을 압축된 고차원 특성 벡터로 변환합니다. 프로토타입은 모달리티 간의 일관성을 유지하면서 학습되며, 이를 통해 예측의 해석 가능성을 제공합니다. 또한, Top-K Mono-semanticity Scale이라는 정량적 메트릭을 사용하여 프로토타입의 설명 가능성을 평가합니다.

- **Performance Highlights**: SPN은 TITAN 및 PIE 데이터셋에서 보행자 행동 예측 작업을 수행하며, 상태 최우수 성능을 달성했습니다. 또한, 이 모델은 동시에 다중 유형의 행동을 예측함으로써 높은 수준의 설명 가능성을 유지합니다.



### Trajectory Manifold Optimization for Fast and Adaptive Kinodynamic Motion Planning (https://arxiv.org/abs/2410.12193)
Comments:
          12 pages, 11 figures

- **What's New**: 본 논문은 동적 환경에 적응할 수 있는 빠른 kinodynamic motion planning에 관한 새로운 접근 방식을 제안합니다. 특히, 고차원의 복잡한 문제에서의 빠른 계획 수립의 어려움을 극복하기 위해 두 단계의 방법론을 적용하고 있습니다.

- **Technical Details**: 제안된 방법은 Differentiable Motion Manifold Primitives (DMMP)라는 신경망 모델을 기반으로 하며, 연속적인 시간에 따라 미분 가능한 궤적 만노폴드를 생성 및 인코딩합니다. 주요 기술 과정에는 다양한 초기화로 최적화 문제를 해결하여 얻은 궤적을 입력으로 하여, 이를 기반으로 작업 조건에 맞춘 잠재 흐름 모델을 개발합니다.

- **Performance Highlights**: 7-DoF 로봇 팔을 이용한 동적 던지기 작업 실험에서는, 본 방법이 기존의 접근 방식에 비해 계획 속도, 작업 성공률, 제약 조건 만족도에서 월등한 성과를 보였음을 확인했습니다.



### DocETL: Agentic Query Rewriting and Evaluation for Complex Document Processing (https://arxiv.org/abs/2410.12189)
Comments:
          21 pages, 7 figures, 3 tables

- **What's New**: DocETL은 LLM(대규모 언어 모델) 기반의 비정형 데이터 처리를 위한 최적화 시스템으로, 복잡한 문서 처리 파이프라인을 최적화합니다. 이 시스템은 사용자 정의 파이프라인을 선언적으로 정의할 수 있는 인터페이스를 제공하며, 자동으로 최적화할 수 있는 에이전트 기반 프레임워크를 사용합니다.

- **Technical Details**: DocETL은 다음과 같은 주요 기술적 요소를 포함합니다: (i) LLM 기반 작업에 맞게 조정된 파이프라인의 논리적 재작성, (ii) 작업별 검증 프롬프트를 합성하고 조정하는 에이전트 주도 계획 평가 메커니즘, (iii) LLM 기반 계획 생성 및 평가의 시간 제약을 고려한 효율적인 최적화 알고리즘이 있습니다.

- **Performance Highlights**: DocETL은 3개의 서로 다른 비정형 문서 분석 작업에 대한 평가를 통해 기존의 잘 설계된 기준보다 $1.34$배에서 $4.6$배 더 품질이 높은 출력(예: 더 정확하고 포괄적임)을 찾는 계획을 발견했습니다.



### DAQ: Density-Aware Post-Training Weight-Only Quantization For LLMs (https://arxiv.org/abs/2410.12187)
Comments:
          9 pages, 4 figures

- **What's New**: 이 논문은 density-aware post-training weight-only quantization (DAQ) 방법을 제안합니다. DAQ는 두 단계로 구성되어 있으며, 고밀도(weight density)가 있는 영역을 부동소수점 고정밀도 영역에 맞추는 방식으로 양자화합니다.

- **Technical Details**: DAQ는 먼저 고밀도 가중치 영역의 중심을 식별하여 이 지점에서 동적 범위를 조정하는 density-centric alignment(DCA) 단계를 수행합니다. 두 번째 단계인 learnable dynamic range adjustment(LDRA)는 가중치가 모델 출력에 미치는 영향을 기반으로 동적 범위를 최적화합니다.

- **Performance Highlights**: LLaMA와 LLaMA-2에서의 실험 결과, DAQ는 평균 22.8%의 perplexity loss를 줄이며, LLaMA-2에서는 19.6% 개선된 성능을 보여줍니다. 이는 기존의 최적 기법들보다 우수한 결과입니다.



### Reinforcement Learning with LTL and $\omega$-Regular Objectives via Optimality-Preserving Translation to Average Rewards (https://arxiv.org/abs/2410.12175)
- **What's New**: 이번 연구에서는 선형 시간 논리(Linear Temporal Logic, LTL)와 ω-정규 목표(ω-regular objectives)가 강화 학습(Reinforcement Learning, RL)에서 평균 보상(reward)을 달성하는 데 있어 기존의 할인이 있는 보상 방식에 비해 이해하기 쉽고 설명 가능하다는 점에 초점을 두었습니다. 특히 ω-정규 목표에 대해 최적성(optimality)을 보존하는 방식으로 한계 평균 보상(limit-average reward) 문제로의 변환 가능성을 제시하였습니다.

- **Technical Details**: 본 연구의 핵심 결과는 ω-정규 목표를 지닌 RL 문제는 유한 기억 보상 기계(finite-memory reward machines)를 통해 한계 평균 보상 문제로 변환 가능하다는 것입니다. 이를 통해 기존의 알고리즘을 활용하여 최적 정책(optimal policy)을 찾을 수 있는 방법론을 제시하였습니다. 또한, 평균 보상 문제에 대한 RL 알고리즘의 수렴 증명을 제공함으로써 이론적으로도 기초를 마련하였습니다.

- **Performance Highlights**: 본 연구는 RL 알고리즘을 통해 ω-정규 및 LTL 목표를 한계 평균 보상 문제로 변환하여 최적의 정책을 비대칭적으로 학습할 수 있음을 보여주었습니다. 특히, 정책의 학습이 제한 속에서 가능하다는 점을 명확히 함으로써 기존의 개방된 문제들(Open Problems)을 해결했습니다.



### The State of Robot Motion Generation (https://arxiv.org/abs/2410.12172)
Comments:
          To be presented at the International Symposium of Robotics Research (ISRR), 2024

- **What's New**: 본 논문은 로봇 모션 생성 방법의 폭넓은 스펙트럼을 검토하며 50년 간의 로봇 연구의 결실을 포함하고 있습니다. 전통적인 방법과 데이터 기반 방법을 구분하고, 두 가지 방법론의 통합 가능성을 강조합니다.

- **Technical Details**: 이 논문은 두 가지 주요 로봇 모션 생성 방법론을 비교합니다: 명시적 모델(Explicit Models)을 기반으로 하는 방법과 암시적 모델(Implicit Models)을 학습하는 방법입니다. 명시적 모델에서는 세계의 기하학적 및 동적 표현을 사용하고, 암시적 방법은 머신러닝 모델의 내부 파라미터에 표현을 저장하여 복잡한 작업을 수행합니다.

- **Performance Highlights**: 데이터 기반 방법은 로봇이 비구조적인 이동이나 능숙한 조작과 같은 복잡한 작업을 성공적으로 수행할 수 있도록 하는 데 큰 성과를 보여주고 있습니다. 기존의 방법들과의 통합적 접근이 더욱 강력하고 안전한 솔루션 개발에 기여할 수 있음을 논의합니다.



### Reclaiming the Source of Programmatic Policies: Programmatic versus Latent Spaces (https://arxiv.org/abs/2410.12166)
Comments:
          Published as a conference paper at ICLR 2024

- **What's New**: 최근 논문에서는 상태 비가시적 마르코프 결정 프로세스(Partially Observable Markov Decision Processes, POMDPs)용 프로그램 정책을 정의하는 데 사용되는 도메인 특화 언어(Domain-Specific Language, DSL)의 잠재 공간을 학습하는 시스템인 LEAPS( Learning Embeddings for Latent Program Synthesis)와 HPRL( Hierarchical Program Synthesis for Reinforcement Learning)이 도입되었습니다. 이 연구에서는 이러한 시스템이 기존 연구에서 관찰된 것과 유사한 행동 손실(behavior loss) 값을 제공하는 프로그램적 공간을 보여주고, LEAPS 및 HPRL보다 프로그램적 공간에서의 알고리즘이 성능이 뛰어남을 입증하였습니다.

- **Technical Details**: 프로그램적 공간에서의 검색을 가능하게 하는 후속 작업을 통해 DSL에 의해 유도된 프로그램적 공간의 지역 검색 알고리즘을 평가하고, 리니어 공간에 대한 알고리즘과의 성능 차이를 분석하였습니다. 새로운 경로 탐색 알고리즘은 법칙적 프로세스와 이웃 함수(neighborhood function)를 사용하여 최적의 솔루션을 탐색하는 방식으로 구현되었습니다. 이 연구의 결과는 직접 프로그램적 공간에서 검색하는 것이 LEAPS나 HPRL 방식보다 더욱 효율적임을 강조하였습니다.

- **Performance Highlights**: 프로그램적 공간에서의 힐 클라이밍(hill-climbing) 알고리즘이 LEAPS 및 HPRL을 지속적으로 초과 달성하며 최고 성능을 보였습니다. 이 결과는 프로그램적 공간이 보다 효과적인 검색을 가능하게 하며, 검색 과정의 최적화 토폴로지가 행동 손실과 더 나은 관련성을 지님을 의미합니다.



### Dual-Model Distillation for Efficient Action Classification with Hybrid Edge-Cloud Solution (https://arxiv.org/abs/2410.12165)
- **What's New**: 본 논문에서는 Dual-Model Distillation (DMD)이라는 혁신적인 방법을 통해 경량화된 혼합 에지-클라우드 솔루션을 제안하며, 실시간 환경에서의 성능을 최적화합니다.

- **Technical Details**: DMD는 소형 모델과 대형 모델 간의 지식을 상호 보완적으로 활용하여, 불확실한 상황에서 대형 모델에게 추론을 오프로드하는 기능을 수행하는 스위처 모델을 훈련합니다. 이 과정은 추가적인 수동 라벨링 데이터 없이 이루어지며, 두 모델의 제로샷 추론 결과의 합의나 불일치를 이용하여 데이터를 생성합니다.

- **Performance Highlights**: 우리의 시스템은 대형 모델만 사용했을 때보다 39.5%의 비용 절감과 4.6% 높은 F1 점수를 달성하였으며, 에너지 소비와 처리 시간을 각각 39.5%와 38.9% 줄였습니다.



### NSSI-Net: Multi-Concept Generative Adversarial Network for Non-Suicidal Self-Injury Detection Using High-Dimensional EEG Signals in a Semi-Supervised Learning Framework (https://arxiv.org/abs/2410.12159)
- **What's New**: 본 연구에서는 비자살적 자해(NSSI)와 관련된 뇌파(EEG) 특징을 효과적으로 모델링하기 위한 최신 반지도 적대 신경망(NSSI-Net)을 제안합니다. NSSI-Net은 시공간적 특징 추출 모듈과 다중 개념 판별기로 구성되어 있습니다.

- **Technical Details**: NSSI-Net의 시공간적 특징 추출 모듈은 2D 합성곱 신경망(2D-CNN)과 양방향 Gated Recurrent Unit(BiGRU)을 통합하여 EEG 데이터의 공간적 및 시간적 동적 정보를 포착합니다. 다중 개념 판별기는 신호, 성별, 도메인 및 질병 수준을 고려하여 의미 있는 EEG 특징을 추출합니다.

- **Performance Highlights**: 자체 수집한 NSSI 데이터(n=114)를 기반으로 NSSI-Net의 효과성과 신뢰성을 입증하였으며, 기존 머신러닝 및 딥러닝 방법보다 7.44% 성능 향상을 보였습니다. 이는 우울증을 가진 청소년에서 NSSI의 이해 및 조기 진단을 향상시키는 데 기여합니다.



### FragNet: A Graph Neural Network for Molecular Property Prediction with Four Layers of Interpretability (https://arxiv.org/abs/2410.12156)
- **What's New**: FragNet 아키텍처가 새로운 그래프 신경망 구조를 제공하며, 높은 예측 정확도와 예측의 해석 가능성을 동시에 달성합니다. 이 모델은 분자의 원자, 결합, 분자 조각 및 조각 연결의 네 가지 수준을 분석하여 분자 성질 예측을 지원합니다.

- **Technical Details**: FragNet은 메시지 전달 그래프 신경망 아키텍처에 기반하여, 네 가지 그래프 기반 분자 구조 표현을 사용합니다: 원자 기반(atom-based), 결합 기반(bond-based), 분자 조각 기반(fragment-based) 및 조각 연결 기반(fragment connection-based). 이 모델은 이들 구조 간의 계층적 접근 방식을 활용하여 학습된 표현을 초기화합니다.

- **Performance Highlights**: FragNet 모델은 MoleculeNet 벤치마크에서 수행된 다양한 화학, 생물학 및 독성 성질의 예측 작업에 대해 경쟁력 있는 예측 정확도를 달성했습니다. 또한, 모델의 해석 가능성을 통해 특정 분자 조각이 특정 속성 예측에서 기여하는 정도를 정량화할 수 있는 점이 주목할 만합니다.



### Exploiting LLMs' Reasoning Capability to Infer Implicit Concepts in Legal Information Retrieva (https://arxiv.org/abs/2410.12154)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 이번 연구는 법적 상황과 관련된 법적 용어 및 사실을 식별하기 위해 대형 언어 모델(LLMs)의 논리적 추론 능력을 활용하는 새로운 정보 검색 시스템을 제안합니다. 이 시스템은 전통적인 검색 방법의 한계를 극복하며, 법적 문제를 인식하고 이를 사용하여 쿼리 확장을 수행합니다.

- **Technical Details**: 제안된 방법론은 두 가지 쿼리 확장 기법을 통해 사용되며, 이는 대형 언어 모델의 제로-샷 프롬프트 기법을 통해 법적 개념과 관련된 용어를 생성하고, 이러한 용어를 쿼리에 통합하여 검색 성능을 향상시킵니다. 또한, lexical based ranking model(BM25)과 semantic based ranking model을 통합하여 최적의 검색 결과를 생성합니다.

- **Performance Highlights**: COLIEE 2022와 2023 대회에서 제안된 앙상블 검색 시스템은 모든 참여 팀 중에서 가장 우수한 성과를 달성하였습니다. LLM에서 얻은 추가 정보가 검색 정확도를 크게 향상시키는 데 기여했습니다.



### Layer-of-Thoughts Prompting (LoT): Leveraging LLM-Based Retrieval with Constraint Hierarchies (https://arxiv.org/abs/2410.12153)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 이번 논문에서는 Layer-of-Thoughts Prompting (LoT)라는 새로운 접근 방식을 제시합니다. 이는 제약 계층을 활용하여 주어진 쿼리에 대한 후보 응답을 필터링하고 세분화하는 기법입니다.

- **Technical Details**: LoT 방법은 제약 사항을 통합하여 구조화된 검색 프로세스를 가능하게 하며, 이는 정보 검색 정보를 더 잘 설명하고 자동화할 수 있는 방법입니다. 기존의 방법들은 다양한 프롬프트 기법을 다루었지만, 다중 턴 상호작용에서 프롬프트의 세부 사항에 대한 탐구가 부족했습니다. 이번 연구는 프롬프트간의 계층적 관계에 초점을 맞추어 이 빈틈을 메웁니다. 대형 언어 모델(LLMs)을 활용하여, LoT는 정보 검색 작업의 정확성과 이해도를 크게 향상시킵니다.

- **Performance Highlights**: LoT 기법은 효율적이고 해석 가능한 검색 알고리즘 개발에 결정적인 역할을 하는 사고 계층의 효능을 입증하였습니다. 이 방법은 설명 가능성과 자동화를 강화하여 정보 검색 정확성을 크게 개선했습니다.



### Facing Identity: The Formation and Performance of Identity via Face-Based Artificial Intelligence Technologies (https://arxiv.org/abs/2410.12148)
- **What's New**: 본 논문은 얼굴 기반 인공지능 기술이 디지털 공간에서 정체성(identity)을 어떻게 구성하고 표현하는지를 탐구합니다. 기존의 텍스트 중심의 인터넷에서 정체성에 대한 논의는 충분히 이루어졌으나, 시각 중심의 멀티미디어 인터넷에서는 얼굴이 특히 중요해졌습니다.

- **Technical Details**: 본 논문은 얼굴 인식 기술(facial recognition technologies, FRTs)과 심리학적 혹은 인종적 편견이 혼합된 고답적인 인식적 요소를 살펴보며, 여기에 AI의 이미지 생성 및 딥페이크(deepfakes) 기술이 포함됩니다. 또한, 이러한 얼굴 기반 AI 기술들이 성별, 인종, 성적 취향 등의 정체성과 어떻게 상호작용하는지를 분석합니다.

- **Performance Highlights**: 마지막으로, 본 논문은 VTuber(버추얼 유튜버)와의 인터뷰 연구를 제안하며, 이들을 통해 '포스트-페이셜(post-facial)' 시대의 디지털 정체성에 대한 질적 통찰을 얻고자 합니다.



### Sample-Efficient Reinforcement Learning with Temporal Logic Objectives: Leveraging the Task Specification to Guide Exploration (https://arxiv.org/abs/2410.12136)
Comments:
          arXiv admin note: text overlap with arXiv:2205.04424

- **What's New**: 본 논문은 불확실한 동적 시스템을 위해 Linear Temporal Logic (LTL) 공식으로 정의된 높은 수준의 제어 목표에 대한 최적의 제어 정책 학습 문제를 다룹니다. 기존의 강화 학습 (RL) 알고리즘은 LTL 작업을 수행하기 위해 균일하게 상태 공간을 탐색하는 경향이 있어 샘플 효율성이 저하됩니다. 이 문제의 해결을 위해 기존의 방법보다 훨씬 더 빠르게 제어 정책을 학습할 수 있는 가속화된 RL 알고리즘을 제안합니다.

- **Technical Details**: 제안된 알고리즘은 (i) LTL 공식을 Deterministic Rabin Automaton (DRA)으로 변환하고, (ii) MDP와 DRA 간의 곱을 구성하여 새로운 PMDP를 생성하며, (iii) LTL 공식의 DRA 표현을 활용해 임무 진행에 기여할 탐색 방향으로 편향된 새로운 확률적 정책, 즉 (ϵ,δ)−greedy 정책을 적용합니다. 이 방법은 탐색 과정에서 제어 결정을 내리는 데 필요한 불확실성을 모델링합니다.

- **Performance Highlights**: 제안된 학습 알고리즘은 랜덤 탐색, Boltzmann, 및 UCB 탐색을 사용하는 모델프리 RL 방법들보다 샘플 효율성 면에서 성능이 우수함을 실험을 통해 보여주었습니다. 또한, PMDP 크기가 증가할수록 이점이 더욱 두드러지며, 모델 기반 방법들과 비교해도 메모리 효율성이 뛰어나 대규모 MDP에 확장 가능함을 입증합니다.



### Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning (https://arxiv.org/abs/2410.12130)
- **What's New**: 이 논문은 대형 언어 모델(LLMs)의 환각(hallucination) 문제를 해결하기 위한 새로운 접근법인 Iterative Model-level Contrastive Learning (Iter-AHMCL)을 소개합니다. 이 방법은 환각을 줄이면서도 LLM의 원래 능력을 유지하도록 설계되었습니다.

- **Technical Details**: Iter-AHMCL 방법은 미리 훈련된 LLM의 표현층을 수정하여 환각이 있는 데이터와 없는 데이터를 기반으로 학습된 대비 모델을 사용합니다. 긍정적(positive) 및 부정적(negative) 모델을 통해 환각을 감소시키는 좀 더 직관적인 경로를 생성하고, 반복적인 대조 학습(iterative contrastive learning)을 통해 성능을 향상시킵니다.

- **Performance Highlights**: 본 논문은 LLaMA2, Alpaca, LLaMA3, Qwen 등 네 개의 미리 훈련된 LLM 모델에서 특별히 설계된 데이터셋으로 파인튜닝(finetuning) 실험을 수행하였으며, TruthfulQA 벤치마크에서 평균 10.1 포인트의 성능 향상을 달성했습니다. Iter-AHMCL은 환각을 줄이면서 LLM의 일반적인 능력을 유지하는 효과적인 방법임을 보여줍니다.



### Affordance-Centric Policy Learning: Sample Efficient and Generalisable Robot Policy Learning using Affordance-Centric Task Frames (https://arxiv.org/abs/2410.12124)
Comments:
          Video can be found on our project website: this https URL

- **What's New**: 이 논문에서는 로봇 조작을 위한 새로운 접근법으로, affordance(기능 가능성)에 중심을 둔 정책 학습 방법을 제안합니다. 이 방법은 task frame(작업 프레임)을 affordance 지역에 적절히 중심을 잡고 방향을 맞추어 intr-category invariance(범주 내 불변성) 및 spatial invariance(공간적 불변성)을 달성할 수 있도록 합니다.

- **Technical Details**: 연구자들은 기존의 다양한 large vision models(대형 비전 모델)을 활용하여 affordance 프레임을 추출하고 추적하는 방법을 제안합니다. 이 단계에서는 로봇의 end effector(끝 손잡이)와 상대적 좌표 체계를 기반으로 작업 프레임을 재정의하여 정책 학습에서 상태 표현을 간단히 합니다. 이로 인해 데이터 수집이 간편해지고 정책 학습을 위한 탐색 공간의 차원도 줄어듭니다.

- **Performance Highlights**: 최소 10회의 데모를 통해 조작 작업을 학습할 수 있으며, 305회의 데모를 통해 훈련된 이미지 기반 정책과 동일한 정도의 일반화 능력을 보여줍니다. 또한, 이 시스템은 전체 환경에서 일정한 성능을 유지할 수 있습니다.



### Just-In-Time Software Defect Prediction via Bi-modal Change Representation Learning (https://arxiv.org/abs/2410.12107)
Comments:
          Accepted by JSS (The Journal of Systems & Software)

- **What's New**: 이번 연구에서는 BiCC-BERT라는 새로운 bi-modal change pre-training model을 소개합니다. BiCC-BERT는 commit message와 코드 변경 사항 간의 의미적 관계를 학습하기 위해 새로운 pre-training objective인 Replaced Message Identification (RMI)을 사용합니다. 이를 통해 JIT-DP에 통합된 새로운 결함 예측 방법인 JIT-BiCC를 제안합니다.

- **Technical Details**: BiCC-BERT는 코드 변경 코퍼스에서 bi-modal semantic representations를 학습합니다. JIT-BiCC는 BiCC-BERT로부터 얻은 이중 의미 표현을 활용하여 기존 모델의 한계를 극복합니다. JIT-BiCC는 27,391개의 코드 변경을 통해 학습되며, F1-score와 AUC를 성능 지표로 사용하여 평가됩니다.

- **Performance Highlights**: JIT-BiCC는 8개의 최신 JIT-DP 방법과 비교하여 10.8%의 F1-score 개선을 달성하며 모든 기준을 초과하는 성능을 나타냅니다. 이는 JIT-DP 분야에서의 bi-modal semantics 학습의 효과성을 시사합니다.



### The Persian Rug: solving toy models of superposition using large-scale symmetries (https://arxiv.org/abs/2410.12101)
- **What's New**: 이 논문에서는 최소 비선형 희소 데이터 오토인코더가 대규모 입력 차원에서 학습한 알고리즘의 완전한 기계적 설명을 제공합니다. 특히 희소 데이터 벡터를 압축하고 비압축하는 과정을 통해 모델이 개별 가중치에 민감하게 반응하는 방식을 제시합니다.

- **Technical Details**: 모델은 입력 데이터와 출력 데이터 사이의 선형 변환을 통해 희소 데이터를 처리하며, ReLU 활성화 함수를 사용하여 비선형성을 추가합니다. 주요 발견 중 하나는 모델이 통계적 퍼뮤테이션 대칭을 보여주며, 고희소성에서 손실 함수의 수학적 형태가 분석 가능하다는 점입니다.

- **Performance Highlights**: 이 연구는 최근 제안된 아키텍처 중에서 모델이 최적에 가까운 성능을 달성했음을 보여줍니다. 특히 활성화 함수의 변경이나 추가는 모델 성능을 상수 배수만큼 향상시킬 수 있다고 설명합니다.



### Bridging Large Language Models and Graph Structure Learning Models for Robust Representation Learning (https://arxiv.org/abs/2410.12096)
Comments:
          Graph structure learning, Graph representation learning, Large language models, Graph neural networks

- **What's New**: 이 논문에서는 LangGSL을 소개합니다. 이는 대규모 언어 모델(LLMs)과 그래프 구조 학습 모델(GSLMs)의 장점을 통합하여 노드 특성과 그래프 구조 학습을 동시에 개선하는 robust framework입니다.

- **Technical Details**: LangGSL에서는 LLM을 사용하여 원본 데이터에서 노이즈를 필터링하고 유용한 정보를 추출하여 노드 특징을 향상시킵니다. 상호 학습 단계에서 상대적으로 작은 언어 모델이 로컬 속성을 처리하고 신뢰할 수 있는 pseudo-label과 informative node embeddings를 생성하여 GSLM의 예측 단계에 통합됩니다. 이는 전체적인 성능을 향상시킵니다.

- **Performance Highlights**: 다양한 규모의 그래프 데이터셋에서 광범위한 실험을 수행하여 LangGSL의 확장성 및 효율성을 입증했습니다. 또한, 향상된 노드 임베딩을 바탕으로 GSLM 모듈은 baseline 방법과 비슷한 성능을 보여주면서도 보다 효율적임을 demonstrated 합니다.



### Generative AI's aggregated knowledge versus web-based curated knowledg (https://arxiv.org/abs/2410.12091)
Comments:
          19 pages, 19 references, 8 pages of appendices, 15 figures

- **What's New**: 이 논문은 Generative AI (GenAI)와 Large Language Models (LLMs)이 지식을 집계하고 포장하는 방식을 통해 어떤 종류의 질문이 최선의 답변을 받을 수 있는지, 그리고 전통적인 웹 검색 결과가 언제 더 나은지 비교합니다. 실험을 통해 소비자들이 ChatGPT와 Google 검색 엔진을 사용할 때의 반응을 분석하였습니다.

- **Technical Details**: 연구에서는 자동차 구매 탐색을 주제로 비교 실험을 진행하였으며, 사전 조사, 생각 소리 내리기(thinking-aloud) 프로토콜, 시간 소요 및 대안의 수와 질에 중점을 둔 평가를 포함했습니다. 이 과정에서 Google 검색과 ChatGPT를 활용한 수백 가지의 probe query를 사용하여 12가지 지식 탐색 페르소나(personas)를 만들고 각 페르소나의 요구에 맞는 다양한 경험을 제안했습니다.

- **Performance Highlights**: GenAI는 널리 알려진 주제에 대한 지식을 집대성하는 데 탁월한 반면, 전통적인 웹 검색은 특정한, 잘 알려지지 않은 지식에 대해 더 나은 결과를 보여주었습니다. 이는 사용자 목표에 따른 차별화된 지식 접근 방식의 가치를 드러내며, 두 가지 접근 방식의 차이점을 강조하는 새로운 사용자 인터페이스 가치도 제안되었습니다.



### Data-adaptive Differentially Private Prompt Synthesis for In-Context Learning (https://arxiv.org/abs/2410.12085)
- **What's New**: 본 논문에서는 대형 언어 모델(LLM)이 정보를 안전하게 처리할 수 있도록 도와주는 새로운 데이터 적응형 차분 개인 정보 보호 (differential privacy) 알고리즘인 AdaDPSyn을 소개합니다.

- **Technical Details**: AdaDPSyn은 ICL(in-context learning)을 수행하기 위해 개인 데이터셋에서 합성 예제를 생성하며, 생성 과정에서 데이터의 고유한 통계적 특성에 따라 노이즈 수준을 조정합니다. 핵심 혁신 중 하나는 Precision-Focused Iterative Radius Reduction 기법으로, 데이터 클러스터링에서 관찰된 패턴을 기반으로 집계 반경을 동적으로 조정합니다.

- **Performance Highlights**: AdaDPSyn은 기존의 DP few-shot generation 알고리즘(Tang et al., 2023)과 비교하여 더 높은 성능을 보여주었으며, 비개인화 기준선(non-private baselines)과 유사한 높은 정확도를 유지합니다.



### WeatherDG: LLM-assisted Procedural Weather Generation for Domain-Generalized Semantic Segmentation (https://arxiv.org/abs/2410.12075)
- **What's New**: 이번 연구에서는 WeatherDG라는 새로운 접근 방식을 제안합니다. 이는 Stable Diffusion (SD)와 Large Language Model (LLM)의 협력을 통해 사실적인, 날씨가 다양한, 운전 화면 이미지를 생성할 수 있습니다.

- **Technical Details**: 이 방법은 세 가지 단계로 구성됩니다. 첫째, SD를 소스 데이터로 미세 조정하여 생성된 샘플의 내용과 레이아웃을 실제 운전 시나리오에 맞추는 것입니다. 둘째, LLM에 기반한 프로세절 프롬프트 생성 방법을 제안하여 시나리오 설명을 풍부하게 하고 SD가 더 다양하고 상세한 이미지를 자동으로 생성할 수 있도록 합니다. 마지막으로, 생성된 이미지를 사용해 모델을 훈련시키는 단계입니다.

- **Performance Highlights**: 세 가지 도전적인 데이터셋에서 실험한 결과, 우리의 방법이 다양한 최신 방법의 성능을 일관되게 개선할 수 있음을 보여주었습니다. 특히, 'Cityscapes to ACDC' 설정에서는 우리의 방법이 기준 HRDA에 비해 mIoU에서 13.9% 향상되었습니다.



### V3D-SLAM: Robust RGB-D SLAM in Dynamic Environments with 3D Semantic Geometry Voting (https://arxiv.org/abs/2410.12068)
- **What's New**: 본 논문에서는 진전된 SLAM 기술인 V3D-SLAM을 제안하여, 동적 환경에서 카메라 위치 추정과 맵 생성의 정확성을 높이기 위한 혁신적인 접근법을 보여줍니다. 이 방법은 움직이는 객체와 정적인 객체를 구분하고, 3D 형태와 동역학을 이해하여 이동 객체의 영향을 최소화하는 데 중점을 둡니다.

- **Technical Details**: V3D-SLAM은 Hough voting 메커니즘을 활용하여 동적 객체를 구분하고, Chamfer 거리(Chamfer distances)를 사용하여 정적 객체의 동적 노이즈를 탐지합니다. 실험은 TUM RGB-D 벤치마크 데이터 세트를 기반으로 하며, V3D-SLAM은 최신 SLAM 방법들보다 더 높은 성능을 보였음을 입증했습니다.

- **Performance Highlights**: 우리의 실험 결과 V3D-SLAM은 TUM RGB-D 벤치마크에서 동적 시퀀스에 대해 보다 높은 정확도를 보여주었고, 불필요한 노이즈를 효율적으로 제거함으로써 전통적인 SLAM 방법보다 우수한 성능을 달성했습니다.



### MFC-EQ: Mean-Field Control with Envelope Q-Learning for Moving Decentralized Agents in Formation (https://arxiv.org/abs/2410.12062)
Comments:
          Accepted to IROS 2024

- **What's New**: 이 논문은 다수의 에이전트를 위한 비대칭 경로 찾기 문제인 Moving Agents in Formation (MAiF)의 분산 버전을 연구합니다. MAiF는 에이전트들이 목표에 신속하게 도달하면서도 특정 형상을 유지하는 경로를 계획하는 문제입니다. 본 연구에서는 Mean-Field Control with Envelop Q-learning (MFC-EQ)라는 새로운 학습 프레임워크를 제안합니다.

- **Technical Details**: MFC-EQ는 에이전트 간의 상호작용을 집단 세력으로 근사화하는 mean-field 이론을 활용하여 모든 에이전트의 동역학을 모델링하고, envelope Q-learning을 통해 다양한 선형 선호를 반영할 수 있는 정책을 학습합니다. 이는 여러 에이전트가 제약을 준수하며 형상 유지 목표와 목표 접근 시간을 균형 잡는 비대칭 다중 에이전트 강화 학습 환경을 최적화하는 데 중점을 둡니다.

- **Performance Highlights**: MFC-EQ는 중앙 집중식 MAiF 베이스라인보다 우수한 성능을 보여 주며, 더 많은 수의 에이전트에서도 계획 시간이 짧습니다. 특히 동적으로 변하는 형상을 효과적으로 처리하여 기존 MAiF 플래너들이 해결할 수 없는 문제를 성공적으로 해결합니다.



### CrediRAG: Network-Augmented Credibility-Based Retrieval for Misinformation Detection in Redd (https://arxiv.org/abs/2410.12061)
- **What's New**: CrediRAG는 정치적 지식 기반과 사회적 네트워크를 활용하여 가짜 뉴스 탐지의 새로운 접근 방식을 제안합니다. 이 모델은 기존의 정보 검색 방식을 개선하여 가짜 뉴스를 대규모로 탐지합니다.

- **Technical Details**: CrediRAG는 뉴스 검색기를 사용하여 각 게시물의 허위정보 점수를 할당하고, 댓글을 공유한 사용자들 간의 평균적 입장을 바탕으로 동적으로 연결된 포스트 간 네트워크를 통해 추정치를 향상시킵니다. 이 모델은 GAT(그래프 주의 네트워크)를 활용하여 소셜 그래프 정보를 포함한 예측을 수행합니다.

- **Performance Highlights**: CrediRAG는 기존 최첨단 방법에 비해 허위 정보를 탐지하는 F1 점수에서 11% 향상을 달성했으며, 200,000개 이상의 실제 Reddit 데이터를 활용한 광범위한 실험에서 우수한 성과를 입증했습니다.



### Large-scale cloze evaluation reveals that token prediction tasks are neither lexically nor semantically aligned (https://arxiv.org/abs/2410.12057)
- **What's New**: 이번 연구에서는 여러 언어 모델의 다음 토큰 예측(next token prediction) 수준에서 생성 행동을 비교하여, cloze 작업에서 인간의 생성과 비교합니다. 연구 결과, 대규모 모델들이 일반적으로 인간의 응답을 더 잘 추정하지만, 확률 총합을 과소 평가하고, 희귀한 응답을 과대 평가하며, 최상위 응답을 과소 평가하는 경향이 있다는 것을 발견했습니다. 이 논문은 언어 모델의 생성이 클로즈 작업의 대체나 모델로 사용될 수 없음을 보여줍니다.

- **Technical Details**: 연구는 인간의 생성을 확률적 관점에서 잘 이해하고, LMs와 인간 간의 차이를 더 잘 알아내기 위해 single-word production을 검토합니다. cloze 작업은 문맥이 주어지고 그 안의 한 단어를 추론하는 작업으로, 인간의 응답 예측에서는 P(w|c)로 표기되는 단어의 발생 확률이 관찰된 모든 응답의 상대 빈도로 추정됩니다. 반면 언어 모델은 신경망을 통해 단어에 점수를 부여하고 softmax 함수를 통해 확률 분포를 생성합니다.

- **Performance Highlights**: Peelle et al. (2020)에서 수집한 3,085개의 영어 문장에 대해 인간 응답으로부터 얻은 cloze 확률과 여러 신경 언어 모델(GPT-2, RoBERTa, Pythia 모델 등)에서 추출한 확률을 비교했습니다. 모델들은 약 50,000의 서브워드(subword) 어휘 크기를 사용하며, 모델 크기, 훈련 시간, 데이터 중복 제거와 같은 여러 하이퍼파라미터의 영향을 탐구하는 Pythia 모델이 특히 흥미로운 결과를 제공합니다.



### Enabling Data-Driven and Empathetic Interactions: A Context-Aware 3D Virtual Agent in Mixed Reality for Enhanced Financial Customer Experienc (https://arxiv.org/abs/2410.12051)
Comments:
          to appear at 1st Workshop on Intelligent XR: Harnessing AI for Next-Generation XR User Experiences at International Symposium on Mixed and Augmented Reality (ISMAR) 2024

- **What's New**: 이 논문에서는 Mixed Reality (MR)과 Vision Language Models (VLMs)을 활용하여 금융 및 소매 부문에서 고객 서비스를 향상시키기 위한 새로운 시스템을 소개합니다. 이 시스템은 고객의 물리적 위치에 대한 상황 인식과 고객 프로파일에 기반한 개인화된 상호작용을 통해 데이터 기반의 공감 있는 상호작용을 가능하게 합니다.

- **Technical Details**: 이 연구는 고객의 요구에 맞춤형 지원을 제공하기 위해 situational awareness (상황 인식), 개인화된 상호작용, 그리고 엄격한 개인 정보 보호 및 보안 기준을 고려합니다. 특히, VLM을 활용하여 고객의 시각적 및 언어적 정보를 이해하고 반응할 수 있는 똑똑한 가상 비서 시스템을 설계합니다.

- **Performance Highlights**: 이 시스템은 고객의 다양한 요구사항을 충족시키고, 고객 대기 시간을 줄이며, 효과적인 문제 해결을 지원하는 다양한 기능을 제공합니다. 최종 목표는 고객에게 신뢰할 수 있고 고도로 개인화된 가상 경험을 제공하여 고객 만족도를 극대화하는 것입니다.



### Sabi\'a-3 Technical Repor (https://arxiv.org/abs/2410.12049)
- **What's New**: Sabiá-3는 브라질 중심의 대규모 데이터셋으로 훈련된 새로운 언어 모델로, 포르투갈어 및 브라질 관련 과제에서 우수한 성능을 보여줍니다. Sabiá-2와 비교하여 특히 추론 요구 과제에서 크게 향상되었습니다.

- **Technical Details**: Sabiá-3는 브라질 문화와 역사에 맞춘 포르투갈어 문서 데이터셋으로 훈련되었습니다. 두 가지 주요 단계에서 개발 되었습니다: (1) 사전 훈련(Pre-training) 단계에서 고품질 데이터에 대한 자기지도 학습(Self-supervised learning) 전략으로 훈련, (2) 사후 훈련(Post-training) 단계에서 인간의 선호에 맞춰 조정되었습니다. TPU v5 가속기를 사용하여 효율적으로 훈련했습니다.

- **Performance Highlights**: Sabiá-3는 ENADE 2022 및 2023 시험에서 Sabiá-2에 비해 70% 오류 감소를 보였고, GPT-4o와 경쟁력 있는 성능을 발휘했습니다. 특히 CPNU 시험에서 주목할 만한 성과를 보여 다른 모델들보다 높은 정확도를 달성했습니다.



### Concept-Reversed Winograd Schema Challenge: Evaluating and Improving Robust Reasoning in Large Language Models via Abstraction (https://arxiv.org/abs/2410.12040)
- **What's New**: 이 논문에서는 LLMs의 reasoning 성능을 평가하기 위한 새로운 데이터셋인 Concept-Reversed Winograd Schema Challenge (CR-WSC)를 제안합니다. 이 데이터셋은 기존의 Winograd Schema Challenge (WSC)에서 개념을 반전시켜 LLMs가 잘못된 대답과 더 연관된 답변을 이끌어내도록 구성되었습니다.

- **Technical Details**: CR-WSC 데이터셋은 LLM의 약점을 이용한 적대적인 질문들을 포함하고, Abstraction-of-Thought (AoT)라는 새로운 프롬프트 방법을 통해 LLMs의 robustness를 향상시키고자 합니다. AoT는 문제를 일반화하여 추상화한 후 reasoning을 수행하는 두 단계의 접근 방식을 채택합니다.

- **Performance Highlights**: 실험 결과, CR-WSC는 기존의 WSC에 비해 LLMs에게 상당히 더 어려운 과제로 나타났으며, AoT를 사용함으로써 LLMs의 reasoning 성능과 robustness가 현저하게 향상되었습니다.



### A Survey on Deep Tabular Learning (https://arxiv.org/abs/2410.12034)
Comments:
          43 pages, 18 figures, 3 tables

- **What's New**: 이 논문은 의료, 금융, 교통과 같은 산업에서 널리 사용되는 탭ular 데이터(tabular data)에 대한 딥러닝(deep learning) 모델의 발전 과정을 다룹니다. 초기의 완전 연결 네트워크(FCNs)에서부터 TabNet, SAINT, TabTranSELU, MambaNet과 같은 고급 아키텍처까지의 발전을 리뷰합니다.

- **Technical Details**: TabNet은 시퀀셜 어텐션(sequential attention)을 사용하여 인스턴스별(instance-wise) 특징 선택을 개선하며 해석 가능성을 높입니다. SAINT는 자기 어텐션(self-attention)과 샘플 간 어텐션(intersample attention)을 결합하여 특징과 데이터 포인트 간의 복잡한 상호작용을 포착합니다. 혼합 아키텍처(hybrid architectures)인 TabTransformer와 FT-Transformer는 카테고리 데이터와 수치 데이터를 처리하기 위한 응용 프로그램에 어텐션 메커니즘을 통합합니다.

- **Performance Highlights**: GNN4TDL과 GANDALF와 같은 그래프 기반 모델은 신경망(neural networks)과 결정 트리 또는 그래프 구조를 결합하여 소규모 데이터 세트에서 오버피팅을 완화하고 특징 표현을 증강합니다. TabDDPM과 같은 확산 기반 모델은 데이터 부족을 해결하기 위해 합성 데이터를 생성하여 모델의 강건성을 향상시킵니다. 다시 말해, 이 논문은 탭ular 데이터의 다양한 응용 프로그램에서 성능과 효율성의 균형을 맞추기 위한 향후 연구 방향을 제시합니다.



### MoE-Pruner: Pruning Mixture-of-Experts Large Language Model using the Hints from Its Router (https://arxiv.org/abs/2410.12013)
- **What's New**: 새로운 논문에서는 Mixture-of-Experts (MoE) 아키텍처의 메모리 소비 및 전문가 중복성을 줄이기 위해 MoE-Pruner라는 방법을 제안합니다. 이 방법은 각 출력 뉴런에서 입력 활성화와 라우터 가중치를 곱한 최소 크기의 가중치를 가지는 방법으로 일회를 통해 손실을 최소화합니다.

- **Technical Details**: MoE-Pruner는 활발하지 않은 전문가의 가중치를 제거하여 모델을 가지치기하는 기법입니다. 이 프로세스는 재학습이나 가중치 업데이트 없이 한 번의 조정 데이터만으로 수행됩니다. Mixtral-8x7B 및 Mixtral-8x22B 모델에 대해 여러 언어 벤치마크에서 그 효용성이 입증되었습니다.

- **Performance Highlights**: Mixtral-8x7B 모델은 50%의 희소성을 가지면서도 원래 모델의 99% 성능을 유지하며, 전문가별 지식 증류를 통해 성능 회복이 가능합니다. 기존의 최첨단 LLM 가지치기 방법들에 비해 우수한 결과를 보였습니다.



### Bias Similarity Across Large Language Models (https://arxiv.org/abs/2410.12010)
Comments:
          under review

- **What's New**: 이 논문은 여러 LLM(대형 언어 모델) 간의 편향(bias) 유사성을 비교한 최초의 작업이다. 기존 연구들은 개별 모델에서의 편향을 분석했지만, 다양한 모델 간의 편향을 비교한 연구는 부족했다. 이를 통해 LLM의 편향을 서로 분석하여 향후 모델 디버깅 기술에 기여할 수 있는 가능성을 제시한다.

- **Technical Details**: 연구에서는 10개의 오픈 및 클로즈드 소스 LLM을 포함하여 4종 모델 패밀리에서 편향의 정도를 평가하였다. 두 개의 데이터 세트를 사용해 4개의 편향 차원에서 질문 4천 개와 100만 개에 대한 LLM의 출력 분포를 측정하였으며, 결과적으로 다음과 같은 주요 발견을 도출했다: 1) 파인튜닝(fine-tuning)이 출력 분포를 유의미하게 변경하지 않음, 2) 동일 모델 패밀리 내에서도 유사한 출력 분포를 생성하지 않음, 3) 훈련 데이터 정보 유출 가능성이 존재함.

- **Performance Highlights**: 연구 결과는 다음과 같다: 1) LLM의 파인튜닝이 출력 분포에 미치는 영향이 제한적이며, 이는 편향 완화 능력을 제한할 수 있다. 2) 동일 패밀리의 LLM이 출력 경향성에서 서로 다르게 작용해 편향 처리를 위한 모델 간 상호연관성이 낮다. 3) 다양한 모델 간의 편향 레벨이 달라 데이터 보안 및 개인 정보 보호에 대한 우려가 제기된다.



### Beyond Labels: A Self-Supervised Framework with Masked Autoencoders and Random Cropping for Breast Cancer Subtype Classification (https://arxiv.org/abs/2410.12006)
- **What's New**: 이번 연구는 유방암 아형 분류를 위한 히스토패스홀로지(Histopathology) 이미지를 사용하여, 마스크 오토인코더(Masked Autoencoder, MAE)를 활용한 자기 지도 학습(self-supervised learning) 방법론을 제안합니다. 이 접근법은 정보 전반을 효과적으로 캡처하기 위한 임베딩(embedding) 학습을 통해 레이블이 없는 데이터셋에서도 특징(feature) 학습이 가능합니다.

- **Technical Details**: 연구에서는 전체 슬라이드 이미지(Whole Slide Images, WSI)에서 이미지 패치를 추출하고, 마스크 기법을 사용하여 인코더가 마스킹된 데이터를 기반으로 복원하는 구조를 취합니다. MAE를 통해 이미지의 특정 부분을 마스킹하고, 잔여 데이터로부터 패턴을 학습하여 원래 이미지를 복원하는 과정을 구현합니다. 또한, ViT(Vision Transformers) 모델을 사용하여 다중 분류(multi-class classification) 작업에서 성능을 평가합니다.

- **Performance Highlights**: BRACS 데이터셋 평가를 통해 이 모델이 기존 벤치마크와 비교하여 높은 성능을 보여주었으며, 특히 tumor tissue와 healthy tissue 구분 및 아형 분류에서의 정확도가 강조되었습니다.



### The Fair Language Model Paradox (https://arxiv.org/abs/2410.11985)
- **What's New**: 이 논문은 Large Language Models (LLMs)의 토큰 수준에서의 훈련 동역학을 조명하며, 가중치 감쇠(weight decay)가 저주파(low-frequency) 토큰의 성능에 미치는 부정적인 영향을 발견하였습니다. 이러한 연구는 기존의 성능 지표에 의해 간과되었던 중요한 통찰을 제공합니다.

- **Technical Details**: 이 연구는 IMDB 데이터셋을 사용하여 270M과 3B 파라미터를 가진 Apple OpenELM 모델과 Qwen2 모델을 훈련하면서 다양한 가중치 감쇠 수준을 적용하였습니다. 결과적으로, 가중치 감쇠가 증가할수록 저주파 토큰의 성능이 유의미하게 감소하는 것을 확인했습니다. 또한, 고주파 토큰이 저주파 토큰보다 학습 속도에서 일관되게 우세하다는 발견이 있었습니다.

- **Performance Highlights**: 가중치 감쇠를 통한 일반화 촉진을 목표로 하는 기존의 방법이 저주파 토큰을 무시하는 결과를 초래하며, 이는 데이터의 대다수를 차지하는 저주파 토큰에 대한 성능 저하로 이어진다는 점이 명확해졌습니다. 이로 인해 더 일반적인 토큰에 유리한 편향이 발생하며, 새로운 정규화 기법의 필요성이 부각되었습니다.



### Generative AI Policies under the Microscope: How CS Conferences Are Navigating the New Frontier in Scholarly Writing (https://arxiv.org/abs/2410.11977)
- **What's New**: 최근 Generative AI (Gen-AI) 기술의 발전과 ChatGPT의 출현으로 컴퓨터 과학 회의에서의 정책이 변화하고 있으며, 이에 대한 포괄적인 검토 및 정책 채택을 위한 지침을 제시합니다.

- **Technical Details**: 이 논문에서는 최근 2년 간 주요 컴퓨터 과학 회의의 Generative AI 정책 현황을 요약하고, ACM, IEEE, AAAI와 같은 주요 컴퓨팅 사회의 정책을 분석했습니다. Gen-AI 정책이 있는 회의와 그 유연성(유연성 등급)도 평가하였으며, 특정 분야에서 Gen-AI의 사용 지침이 어떻게 변화하고 있는지를 살펴보았습니다.

- **Performance Highlights**: AI 분야의 회의에서는 첫 해에 비해 저자 정책의 채택 비율이 30.8%에서 76.9%로 크게 증가하였으며, 이는 AI 분야가 저자에게 Gen-AI 정책을 가장 적극적으로 도입하고 있음을 보여줍니다. 반면, 이론 분야에서는 여전히 Gen-AI 정책이 없는 상태입니다. 회의에 따라 저자 정책은 더 유연한 경향을 보이며(평균 유연성 등급 3.60에서 3.68로 증가), 리뷰어 정책은 더 제한적입니다(평균 유연성 등급 3.00에서 2.63으로 감소).



### DDIL: Improved Diffusion Distillation With Imitation Learning (https://arxiv.org/abs/2410.11971)
- **What's New**: 본 논문에서는 ‘모방 학습(Imitation Learning)’ 프레임워크 내에서의 확산 디스틸레이션(Diffusion Distillation) 접근법을 제안하여, 확산 모델의 훈련 분포를 개선하였음을 발표합니다. 이는 데이터 분포(Forward Diffusion)와 학생이 유도한 분포(Backward Diffusion)를 모두 고려하여 이루어집니다.

- **Technical Details**: 제안된 DDIL( Diffusion Distillation within Imitation Learning) 접근법은 ‘DAgger’ 프레임워크를 통해 데이터 집합 내에서 데이터 분포와 학생 유도 분포 모두에서 디스틸레이션을 수행하여 예측 분포의 집합적 품질을 개선하는 것을 목표로 합니다. 이 과정에서 데이터 분포의 지원을 위반하지 않도록 임계값 설정을 도입하였으며, 이는 ‘반사 확산(Reflected Diffusion)’ 공식을 사용하여 Covariate Shift 문제를 완화합니다.

- **Performance Highlights**: DDIL 접근법은 다양한 샘플을 생성하며, 프로그레시브 디스틸레이션(Progressive Distillation), 잠재 일관성 모델(Latent Consistency Model), 분포 매칭 디스틸레이션(Distribution Matching Distillation)과 같은 여러 디스틸레이션 기법에서 일관되게 성능을 향상시키는 결과를 보여주었습니다.



### CtrlSynth: Controllable Image Text Synthesis for Data-Efficient Multimodal Learning (https://arxiv.org/abs/2410.11963)
- **What's New**: 새로운 연구는 'CtrlSynth'라는 이미지-텍스트 합성 파이프라인을 설계하여 데이터 효율적이고 강력한 다중 모달 학습을 가능하게 합니다. 이 방법은 사용자가 정의한 제어 정책을 적용하여 시각적 의미를 분해하고 재조합함으로써 입력 데이터의 생성을 조절할 수 있게 만들어줍니다.

- **Technical Details**: CtrlSynth는 미리 훈련된 기초 모델을 활용하여 이미지의 시각적 태그를 추출하고, 이를 바탕으로 LLM을 이용해 텍스트를 생성합니다. 사용자는 생성 과정에서 특정 요소를 제어할 수 있으며, 닫힌 루프 시스템을 통해 기존 모델을 활용하여 추가 훈련 없이 직접적으로 합성 작업을 수행합니다.

- **Performance Highlights**: CtrlSynth는 31개의 다양한 데이터셋에서 실험을 진행했으며, CLIP 모델의 제로샷 분류에서는 23.4%, SugarCrepe 구성 추론 벤치마크에서는 5%의 정확도 향상을 보였습니다. 또한, 긴 꼬리(Long-tail) 비전 과제에서도 16%에서 21%의 성능 개선을 확인했습니다.



### Beyond Sequence: Impact of Geometric Context for RNA Property Prediction (https://arxiv.org/abs/2410.11933)
- **What's New**: 본 연구는 RNA의 물리적 속성을 예측하기 위해 2D와 3D 기하학적 정보를 포함한 최초의 체계적인 평가를 제공합니다. 기존 연구들은 주로 1D 시퀀스 모델에 초점을 맞추었으나, 이들 연구에서 고유의 기하학적 맥락을 간과해왔습니다. RNADatasets의 새로운 집합을 소개하여 모델 평가를 위한 자원을 제공합니다.

- **Technical Details**: 본 연구에서는 1D, 2D, 3D RNA 표현으로 다양한 기계 학습 모델의 성능을 비교하고 분석합니다. 1D 모델(Transformer1D), 2D 모델(Graph Convolutional Network 등), 3D 모델(SchNet 등)을 사용하며, 새로운 2D 및 3D 구조 주석이 포함된 RNA 데이터셋을 개발했습니다. 각 모델은 제한된 데이터와 라벨, 시퀀싱 오류, 분포 외 시나리오에서 어떻게 성능이 달라지는지를 종합적으로 평가합니다.

- **Performance Highlights**: 평가 결과, 명시적인 기하학적 인코딩을 가진 모델이 시퀀스 기반 모델에 비해 일반적으로 더 뛰어난 성능을 보였으며, 평균 예측 RMSE가 약 12% 감소했습니다. 3D 모델은 노이즈가 없는 상황에서 가장 우수한 성능을 보이지만, 시퀀싱 오류가 많은 경우 56%까지 성능이 저하됩니다. 반면, 기하학을 고려하지 않은 시퀀스 모델은 시퀀싱 노이즈에 가장 강하지만, 동일한 성능에 도달하기 위해서는 2-5배의 훈련 데이터가 필요합니다.



### Transfer Learning Adapts to Changing PSD in Gravitational Wave Data (https://arxiv.org/abs/2410.11911)
Comments:
          7 pages, 3 figures

- **What's New**: 이번 논문은 중력파(Gravitational Wave, GW) 신호를 식별하기 위한 혁신적인 AI 접근 방식을 소개합니다. 전통적인 소음 억제 방법들의 한계를 극복하기 위해 간소화된 아키텍처를 채택하고, 새로운 훈련 방법론을 개발하여 복잡한 소음 속에서도 높은 정확도로 중력파를 탐지하는 모델을 구축하였습니다.

- **Technical Details**: 우리의 모델은 단순한 다층 퍼셉트론(Multilayer Perceptron, MLP)을 기반으로 하며, ReLU 활성화 함수(Activation Function)를 사용하여 소실 기울기 문제(Vanishing Gradient Problem)를 피할 수 있습니다. 이 모델은 우선 깨끗한 데이터로 훈련된 후, Transfer Learning 기법을 사용하여 소음이 있는 데이터로 미세 조정합니다. 이를 통해 복잡한 소음 환경에서 중력파 신호를 효과적으로 식별할 수 있게 됩니다.

- **Performance Highlights**: 모델은 비백색 노이즈(non-white noise) 환경에서 99% 이상의 정확도를 달성하였으며, 변화하는 소음 전력 스펙트럼 밀도(Power Spectral Density, PSD) 조건에 매우 적응력이 뛰어납니다. 추가적으로, 이 모델은 몇 에폭(Epochs)의 미세 조정을 통해 새로운 소음 프로파일에 빠르게 적응하여, 동적으로 변화하는 소음 환경에서 실시간 분석이 가능합니다.



### Explainable AI Methods for Multi-Omics Analysis: A Survey (https://arxiv.org/abs/2410.11910)
- **What's New**: 본 논문에서는 multi-omics 데이터의 해석 가능성을 향상시키기 위해 설명 가능한 인공지능(xAI) 방법의 중요성을 다룹니다.

- **Technical Details**: multi-omics는 유전체(genomics), 단백질체(proteomics), 전사체(transcriptomics), 대사체(metabolomics), 미생물체(microbiomics)와 같은 여러 가지 omics 데이터의 통합 분석을 의미합니다. 이러한 데이터의 딥 러닝(deep learning) 방법을 활용하여 분자 상호작용에 대한 통찰력을 제공하고 복잡한 질병 연구를 향상시킬 수 있습니다.

- **Performance Highlights**: xAI 방법론을 통해 임상의들이 복잡한 데이터에서 명확한 통찰력을 얻을 수 있어, 임상 환경에서 이러한 모델의 효과적인 적용을 촉진할 수 있는 잠재력이 강조됩니다.



### ChatHouseDiffusion: Prompt-Guided Generation and Editing of Floor Plans (https://arxiv.org/abs/2410.11908)
- **What's New**: 이 논문에서는 ChatHouseDiffusion라는 새로운 방법을 소개하여 자연어 입력을 해석하고, 그래프 구조(그래프오머, graphormer)를 통해 공간적 관계를 인코딩하며, 확산 모델(diffusion models)을 사용하여 플로어 플랜(floor plans)을 유연하게 생성하고 수정할 수 있도록 합니다. 이를 통해 사용자의 아이디어를 기반으로 한 반복적 디자인 조정을 가능하게 하며, 효율성을 크게 향상시킵니다.

- **Technical Details**: ChatHouseDiffusion는 대형 언어 모델(LLM, Large Language Models)을 사용하여 사용자 입력을 파싱하고, 그래프오머(graphormer)를 통해 방의 위상적(topological) 관계를 인코딩하며, 확산 모델을 활용하여 플로어 플랜을 예측합니다. 이 접근 방식은 초기 결과에 대한 세밀한 지역 조정을 가능하게 하며, 반복적인 설계를 통해 사용자가 원하는 결과를 이끌어낼 수 있도록 합니다.

- **Performance Highlights**: ChatHouseDiffusion는 기존 모델과 비교하여 높은 교차 비율(Intersection over Union, IoU) 점수를 달성하여 정확하고 지역적인 조정이 가능하며, 전체 재설계를 필요로 하지 않아 실제적인 유용성을 제공합니다. 실험 결과는 모델이 사용자 사양을 엄격히 준수하며, 인터랙티브한 기능을 통해 직관적인 디자인 프로세스를 촉진함을 보여줍니다.



### Empowering Users in Digital Privacy Management through Interactive LLM-Based Agents (https://arxiv.org/abs/2410.11906)
- **What's New**: 이 논문은 대규모 언어 모델(LLM)을 활용하여 사용자들이 개인정보 처리 방침을 이해하는 데 도움을 주는 새로운 대화형 에이전트를 제시합니다. 기존 모델보다 데이터 처리 식별, 선택 식별, 정책 요약 및 개인정보 관련 질문 응답 등에서 LLM이 월등한 성능을 보임을 보여주며, 개인정보 처리 방침 분석에 있어 새로운 기준을 마련합니다.

- **Technical Details**: 본 연구는 GPT-4o-mini 기반의 LLM 에이전트를 개발하여 웹사이트의 개인정보 처리 방침을 이해하는 데 사용자들을 지원합니다. 에이전트는 복잡한 법적 언어를 단순화하여 특정 질문 없이 사용자들이 필요한 정보를 얻도록 돕습니다. 연구는 사용자 100명을 대상으로 한 사용자 연구를 포함하며, 여기서 LLM을 사용한 그룹이 더 높은 이해도와 더 낮은 인지 부하를 경험하였음을 보고합니다.

- **Performance Highlights**: 사용자 연구 결과, LLM에 의해 보조된 사용자들은 평균 2.6의 이해 점수를 기록하였고, 이는 대조군의 1.8에 비해 현저히 높은 점수입니다. 주요 결과로는, LLM 에이전트 사용 그룹이 시간 소모를 줄이고(5.5분 대 15.8분), 개인정보 처리를 관리하는 데 있어 자신감이 증가하였으며 인지 부하가 크게 감소했다고 보고합니다.



### Personalised Feedback Framework for Online Education Programmes Using Generative AI (https://arxiv.org/abs/2410.11904)
Comments:
          Submitted to journal

- **What's New**: 최근 AI 도구, 특히 대규모 언어 모델(large language models)이 학습 관리 시스템과 온라인 교육 프로그램 내에서 효과성을 입증하였습니다. 이 연구는 교육 피드백 시스템을 개선하기 위한 대안적 피드백 프레임워크를 제안합니다.

- **Technical Details**: 본 논문은 ChatGPT의 기능을 확장하는 피드백 프레임워크를 탐색합니다. 이 프레임워크는 embeddings를 통합하여 교육 자료에 대한 더 세밀한 이해를 가능하게 하며, 퀴즈 기반 평가를 위한 주제별(targeted) 피드백을 촉진합니다.

- **Performance Highlights**: 연구의 일환으로 제안된 개념 증명(proof of concept) 솔루션은 개방형(open-ended) 질문에 대해 90%의 효율성(efficacy) 비율을, 다중 선택(multiple-choice) 질문에 대해서는 100%의 효율성을 달성했습니다. 이 결과는 우리의 프레임워크가 기대를 초과할 뿐만 아니라 인간의 서술(narratives)과도 경쟁할 수 있다는 가능성을 시사합니다.



### Study on the Helpfulness of Explainable Artificial Intelligenc (https://arxiv.org/abs/2410.11896)
Comments:
          World Conference on Explainable Artificial Intelligence

- **What's New**: 이 논문은 설명 가능한 인공지능(Explainable AI, XAI) 방법의 성과를 평가하는 새로운 접근 방식을 제안합니다. 특히, XAI의 유용성을 사용자들이 성공적으로 수행할 수 있는 프록시 작업을 통해 평가하는 방법에 중점을 두었습니다. 이를 통해 사용자 의사결정에 있어서 XAI의 도움을 판단할 수 있습니다.

- **Technical Details**: XAI의 성과를 측정하기 위한 연구 질문이 정의되었으며, 사용자의 AI 결정 판단 능력, AI 결정에 대한 신뢰도, AI 결정에 대한 질문을 평가하는 방법이 포함되어 있습니다. 연구에서는 6가지 유명한 XAI 방법을 비교하여, 사용자들이 AI 기반 분류 결정의 신뢰성을 올바르게 판단할 수 있는 능력을 조사했습니다.

- **Performance Highlights**: 사용자 연구 결과, 다양한 XAI 방법들이 신뢰와 회의감을 생성하는 능력에서 차이를 보였으며, AI 결정의 올바른 판단 능력에도 차이를 보였습니다. 본 논문은 XAI 성과 측정에 있어 보다 객관적이고 인간 중심의 사용자 연구 접근 방식을 적용할 것을 강력히 권장합니다.



### Are Grid Cells Hexagonal for Performance or by Convenience? (https://arxiv.org/abs/2410.11886)
Comments:
          5 pages, accepted at Montreal AI and Neuroscience Conference 2024

- **What's New**: 본 연구는 그리드 셀(grid cell)의 육각형 구조가 실제 성능 이점을 제공하는지 또는 생물학적으로 편리한 구성을 나타내는지 여부를 조사합니다. Vector-HaSH(content addressable memory 모델)를 통해 사각형과 육각형 그리드 셀의 성능을 비교한 결과, 두 구조는 비슷한 성능을 보임을 발견하였습니다.

- **Technical Details**: 이 연구에서는 Vector-HaSH 프레임워크를 기반으로 하고, MNIST, Fashion-MNIST, CIFAR-100과 같은 이미지 데이터셋을 사용하여 그리드 셀의 두 가지 형태, 즉 육각형 그리드와 사각형 그리드를 구현하였습니다. 다양한 경로 유형과 경로 길이를 이용해 메모리 관련 실험을 실시하였습니다.

- **Performance Highlights**: 실험 결과, 육각형 그리드 셀과 사각형 그리드 셀은 이미지 인식 및 경로 시뮬레이션에서 비슷한 성능을 보였으며, 메모리 재현 및 정확도가 유사하였습니다. 이러한 결과는 육각형 그리드가 생물학적 구현의 용이성에서 비롯되었음을 시사합니다.



### Neural Metamorphosis (https://arxiv.org/abs/2410.11878)
Comments:
          in ECCV2024, this https URL

- **What's New**: 본 논문에서는 Neural Metamorphosis (NeuMeta)라는 새로운 학습 패러다임을 소개합니다. NeuMeta는 별도의 모델을 만들지 않고, 신경 네트워크의 가변 형태를 직접 학습합니다. 이를 통해 학습된 가중치 공간에서 임의 크기의 네트워크를 샘플링할 수 있습니다.

- **Technical Details**: NeuMeta는 hypernetwork로 작동하는 implicitly learned neural functions를 사용합니다. 이는 모델 공간의 좌표를 받아 해당 가중치 값을 생성합니다. 목표는 가중치의 smoothness를 높이는 것이며, 이를 위해 두 가지 전략을 사용합니다: 첫째, 가중치 행렬의 permutation을 통해 intra-model smoothness를 달성하고, 둘째, 입력 좌표에 noise를 추가하여 무작위 네트워크 구성에서도 일관된 출력을 유지합니다.

- **Performance Highlights**: NeuMeta는 이미지 분류, 의미론적 분할 및 이미지 생성 작업에서 광범위한 테스트를 거쳐, 75% 압축률에서도 원래 모델의 성능을 유지합니다. 이 시스템은 이전에 보지 못한 네트워크 구성에 대한 가중치를 생성하는 성능을 보여줍니다.



### A Framework for Collaborating a Large Language Model Tool in Brainstorming for Triggering Creative Thoughts (https://arxiv.org/abs/2410.11877)
Comments:
          18 pages, 3 figures

- **What's New**: 이번 연구는 브레인스토밍(Brainstorming) 과정에서 창의성을 향상시키기 위한 프롬프트 엔지니어링(Prompt Engineering)의 역할을 탐구하는 새로운 프레임워크인 GPS(Goals, Prompts, Strategies)를 제안합니다. LLM(대규모 언어 모델) 도구와의 통합을 통해 창의적인 아이디어 생성에 대한 접근 방식을 변화시키고자 합니다.

- **Technical Details**: GPS 프레임워크는 목표, 프롬프트, 전략을 바탕으로 하여 디자이너가 LLM 도구를 체계적으로 사용할 수 있도록 안내합니다. 이 프레임워크는 Torrance Tests of Creative Thinking (TTCT)를 참고하여 AI가 생성한 아이디어의 창의성을 측정하기 위한 측정 도구를 적응시켰습니다. 프롬프트 엔지니어링은 사용자가 LLM 도구의 응답을 유도하는 일련의 텍스트 기반 입력을 설계하고 수정하는 과정입니다.

- **Performance Highlights**: 사례 연구와 디자인 예제를 통해 검증된 GPS 프레임워크는 브레인스토밍 세션에서 창의성과 아이디어의 유용성을 향상시키는 데 효과적임을 보여줍니다. 연구 결과에 따르면, 이 프레임워크는 사용자가 아이디어 구상 단계에서 직면하는 여러 상황에 맞게 적합한 프롬프트 요소를 선택할 수 있도록 돕습니다.



### Rescriber: Smaller-LLM-Powered User-Led Data Minimization for Navigating Privacy Trade-offs in LLM-Based Conversational Agen (https://arxiv.org/abs/2410.11876)
- **What's New**: LLM(대규모 언어 모델) 기반의 대화형 에이전트에서 개인 정보 보호와 유틸리티 간의 균형을 사용자가 직접 조절할 수 있는 브라우저 확장 프로그램 Rescriber를 개발하고 평가했습니다.

- **Technical Details**: Rescriber는 사용자가 자신의 프롬프트에서 개인 정보를 감지하고 필요한 부분을 정제(sanitize)하는 것을 지원하여, LLM 기반 대화형 에이전트에서의 데이터 최소화(data minimization)를 가능하게 하는 도구입니다. 12명의 사용자를 대상으로 한 연구(N=12)에서 Rescriber는 개인 정보 유출을 줄이는 데 도움을 주었고, 사용자의 개인 정보 보호 우려를 해소했습니다.

- **Performance Highlights**: Rescriber가 Llama3-8B로 구동될 때 사용자의 주관적 인식은 GPT-4와 동등한 성능을 보였으며, 탐지(detection)와 정제의 포괄성(comprehensiveness) 및 일관성(consistency)이 사용자의 신뢰(trust)와 보호(perceived protection) 인식에 중요한 영향을 미친다는 결과를 도출했습니다.



### A Framework for SLO, Carbon, and Wastewater-Aware Sustainable FaaS Cloud Platform Managemen (https://arxiv.org/abs/2410.11875)
- **What's New**: 이 논문은 Function-as-a-Service (FaaS)에서 지속 가능성(sustainability) 관점에서의 스케줄링(scheduling)과 스케일링(scaling)을 조사합니다. 기존의 서버 기반 모델과는 달리, FaaS는 사용자 비용 절감을 목표로 하지만 환경에 미치는 영향에 대한 연구는 부족한 상황입니다.

- **Technical Details**: 논문에서는 서비스 수준 목표(Service-Level Objectives, SLOs)와 탄소 배출(carbon emissions) 간의 충돌을 발견했습니다. 또한 SLO 중심의 FaaS 스케줄링이 데이터 센터의 물 사용(water use)을 증가시킬 수 있음을 밝혔습니다. 이러한 문제를 해결하기 위해 새로운 지속 가능성 중심의 FaaS 스케줄링과 스케일링 프레임워크를 제안했습니다.

- **Performance Highlights**: 제안된 프레임워크는 SLO 성과, 탄소 배출, 폐수 발생(wastewater generation)을 동시에 최적화하는 문제를 해결하고자 합니다.



### Enhancing UI Location Capabilities of Autonomous Agents (https://arxiv.org/abs/2410.11872)
Comments:
          Work in progress

- **What's New**: ClickAgent는 MLLM과 UI 위치 모델을 결합하여 UI 요소의 정확한 위치 식별 문제를 해결합니다. 이는 기존 MLLMs의 한계를 극복하고 GUI와의 상호작용을 개선합니다.

- **Technical Details**: ClickAgent는 MLLM 기반의 행동 계획, UI 위치 모델 및 반영(reflection) 모듈로 구성됩니다. UI 위치 모델은 스크린샷만을 입력으로 사용하여 UI 요소의 좌표를 식별합니다. 이를 통해 기존 모델보다 높은 정확도로 사용자 작업을 수행할 수 있습니다.

- **Performance Highlights**: ClickAgent는 AITW 벤치마크에서 AppAgent, Auto-UI, CogAgent보다 비약적으로 향상된 작업 성공률을 기록했습니다. 실험은 실제 Android 스마트폰과 에뮬레이터에서 진행되어, 두 가지 시나리오에서 일관되게 높은 성공률을 보였습니다.



### TinyClick: Single-Turn Agent for Empowering GUI Automation (https://arxiv.org/abs/2410.11871)
Comments:
          4 pages without references, 2 figures

- **What's New**: 이번 연구에서는 GUI(Graphical User Interface) 상호작용 작업을 위한 단일 턴(single-turn) 에이전트를 소개합니다. 이 에이전트는 Vision-Language Model인 Florence-2-Base를 사용하며, 스크린샷과 사용자 명령에 기반해 원하는 UI 요소를 클릭하는 것을 목표로 합니다. 기존의 UI 에이전트들에 비해 우수한 성능을 보여주며, 특히 Screenspot과 OmniAct에서 강한 성능을 발휘합니다.

- **Technical Details**: Florence-2 Base 모델은 0.27B 파라미터를 가지며, 약 250ms의 낮은 레이턴시를 기록합니다. 본 연구에서는 다중 작업(multitask) 훈련을 활용하여 UI 표현을 강화하고, MLLM(Multimodal Large Language Model) 기반 데이터 증강(data augmentation)을 통해 성능 향상을 달성했습니다. 또한, 수동으로 주석이 달린 데이터세트가 부족한 문제를 해결하기 위해 MLLM을 활용하여 데이터 재주석 과정을 도입했습니다.

- **Performance Highlights**: Screenspot에서 73%, OmniAct에서 57%의 정확도를 기록하며, 기존의 GUI 특정 모델(예: SeeClick)과 MLLM(예: GPT-4V)보다 월등한 성능을 보여주었습니다. 연구 결과는 다중 작업 데이터에 대한 훈련이 클릭 명령만으로 훈련하는 것보다 성능을 더 향상시키는 것으로 나타났습니다.



### Neuropsychology of AI: Relationship Between Activation Proximity and Categorical Proximity Within Neural Categories of Synthetic Cognition (https://arxiv.org/abs/2410.11868)
- **What's New**: 이 논문은 인지 심리학에서 개념을 차용하여 인공 신경망(artificial neural network)의 설명 가능성을 높여주는 새로운 접근 방식을 제시합니다. 특히, 언어 모델의 합성 인지(synthetic cognition)를 분석하기 위해 '범주화(categorization)'라는 인지 개념을 중심으로 연구를 진행합니다.

- **Technical Details**: 논문에서는 인공 신경망의 작동 원리를 이해하기 위한 미시적인 설명 가능성(epistemological explainability)을 탐구합니다. 인식 단위로서의 형식 신경(formal neuron)를 관찰의 기준으로 삼아, 언어 모델 내부에서 범주 지식이 어떻게 구성되고 활용되는지를 분석합니다. 또한, 범주화의 정의에 대해 고전적인 접근(Plato, Aristotle)에서 프로타입(prototype), 예시(exemplar) 등 다양한 이론을 소개하며, 커넥션리즘(connectionism)에 기초한 신경망의 인지 프로세스를 심도 있게 설명합니다.

- **Performance Highlights**: 이 연구는 신경망의 범주화 프로세스에 대한 깊은 통찰을 제공하며, 이는 향후 인공 지능의 설명 가능성을 개선하는 데 기여할 수 있습니다. 특히, 신경망의 '블랙 박스(black box)' 문제를 해결하는 데 있어 중요한 기준이 될 것입니다.



### An Innovative Solution: AI-Based Digital Screen-Integrated Tables for Educational Settings (https://arxiv.org/abs/2410.11866)
- **What's New**: 이번 논문에서는 교육 환경에서 다양한 AI 기반 프레임워크에 대해 다루었으며, 디지털 화면이 통합된 테이블의 혁신적인 설계를 소개합니다. 이 테이블은 중앙 처리 장치(CPU)에 의해 제어되는 통합 디지털 화면을 특징으로 하며 교육 콘텐츠를 동기화하여 표시할 수 있습니다.

- **Technical Details**: 디지털 화면이 통합된 테이블은 개별 테이블에 프로세싱 파워를 통합하여 교사와 연결된 중앙 노드로 구성됩니다. 이러한 장치는 기계 학습(ML) 알고리즘을 사용하여 학생의 학습 패턴을 분석하고, 느린 학습자와 빠른 학습자를 식별합니다.

- **Performance Highlights**: 이 혁신적인 접근 방식은 현대 교실의 진화하는 요구를 충족하기 위해 데이터 기반의 학습 환경을 제공합니다. 이 기술은 학생들이 수업에서 필요로 하는 적시 지원을 받을 수 있도록 하여 학습 성과를 극대화하는 데 기여합니다.



### Shifting the Human-AI Relationship: Toward a Dynamic Relational Learning-Partner Mod (https://arxiv.org/abs/2410.11864)
Comments:
          White Paper

- **What's New**: 이 논문에서는 인공지능(AI)을 단순한 도구가 아닌 인간과 함께 학습하는 파트너로 보아야 한다고 주장합니다. 이는 AI 시스템이 인간과의 상호작용에서 발전할 수 있도록 하는 새로운 패러다임을 제시합니다.

- **Technical Details**: AI의 발전을 위해 'ecorithms', 혼돈에서의 질서(order from chaos), 협력(cooperation)과 같은 다양한 학문적 개념을 활용합니다. 또한, AI와 인간의 이질성(heterogeneity)을 활용하여 협력적인 하이브리드 지능(synergistic hybrid intelligence)을 창출하는 방안을 모색합니다.

- **Performance Highlights**: 제안된 'dynamic relational learning-partner (DRLP)' 모델은 인간과 AI 간의 상호작용을 통해 AI 시스템이 발전하고, 윤리적이며 정서적으로 건강한 관계를 만드는 데 기여할 것입니다. 특히, AI가 다양한 유형의 마음을 모델링할 수 있도록 하는 디자인 인터벤션(design interventions)을 통해 AI와의 협업이 강화될 것으로 기대됩니다.



### ChatVis: Automating Scientific Visualization with a Large Language Mod (https://arxiv.org/abs/2410.11863)
- **What's New**: 본 논문에서는 ChatVis라는 반복적 보조 도구를 개발하여 데이터 분석 및 시각화를 위한 Python 스크립트를 생성하는 방법을 제안합니다. 사용자는 자연어로 작업을 지정할 수 있으며, LLM(large language model)이 원하는 작업에 대한 Python 스크립트를 생성하고 반복적으로 수정하여 올바르게 실행되도록 합니다. 중간에 발생하는 오류를 감지하고 수정하는 메커니즘이 포함되어 있습니다.

- **Technical Details**: ChatVis는 사용자 입력을 기반으로 자연어로 설명된 시각화 요구사항을 처리하여, 추가적인 프롬프트를 생성하고 이를 통해 Python 스크립트를 만들어냅니다. 최종적으로 ParaView의 PvPython API를 사용하여 스크립트를 실행하고 결과를 확인합니다. 반복적인 피드백 루프를 통해 오류 메시지가 LLM에 전달되어 코드가 개선됩니다. 이 방법은 과거의 여러 스크립트와 비교하여 정확한 시각화를 생성하는 데 성공했습니다.

- **Performance Highlights**: ChatVis는 다섯 가지 대표적 시각화 시나리오에서 올바른 실행 결과를 보여줍니다. 비교 대상이 된 다른 LLM에서는 ChatVis와 같은 도움 없이 정확한 스크립트를 생성하지 못했습니다. 이번 연구는 LLM을 활용한 과학적 시각화를 위한 최초의 시도 중 하나로 평가됩니다.



### Towards using Reinforcement Learning for Scaling and Data Replication in Cloud Systems (https://arxiv.org/abs/2410.11862)
- **What's New**: 본 논문에서는 자동 데이터 복제를 위한 강화 학습(Reinforcement Learning, RL) 기반의 데이터 복제 전략 및 데이터 스케일링에 대해 조사합니다. 이러한 접근법은 기존의 임계값 기반(threshold-based) 데이터 복제의 한계를 극복하고, 자원의 자동 스케일링을 가능하게 합니다.

- **Technical Details**: 강화 학습을 활용하여 복잡한 워크로드 트렌드에 대한 깊은 이해 없이도 데이터 복제 및 스케일링 전략을 자동으로 조정할 수 있습니다. 본 연구는 강화 학습을 통해 자원의 효율성을 극대화하는 방법에 대해 논의합니다.

- **Performance Highlights**: 강화 학습 기반의 데이터 복제 전략들이 보다 효과적으로 자원을 관리할 수 있는 가능성을 보여줍니다. 이로 인해 클라우드 컴퓨팅 환경에서 자원의 자동 스케일링이 향상될 수 있습니다.



### Investigating Role of Big Five Personality Traits in Audio-Visual Rapport Estimation (https://arxiv.org/abs/2410.11861)
Comments:
          9 pages, 5 figures

- **What's New**: 이 연구는 친구 간의 상호작용에서 비언어적 신호(오디오 및 얼굴 표정)를 활용하여 rapport(이해 및 신뢰 관계) 추정 모델을 개발하고, Big Five 특성(BFFs)을 추가함으로써 추정 성능이 향상된다는 것을 보여줍니다.

- **Technical Details**: 연구는 Big Five 모델을 바탕으로 한 성격 특성을 적용하여 모델의 입력을 증가시키고, 사회적 관계 모델(SRM)을 이용하여 rapport 평가는 지각자 효과, 대상 효과, 관계 효과로 분해됩니다. 이는 관계의 친밀도에 따라 rapport의 정의가 달라짐을 나타냅니다.

- **Performance Highlights**: 실험 결과, BFFs와 비언어적 신호의 조합이 rapport 추정 성능을 가장 좋게 하며, 성격 특성이 포함된 모델이 상대방의 특성에 따라 보다 정확한 추정을 가능하게 합니다.



### Comparing Zealous and Restrained AI Recommendations in a Real-World Human-AI Collaboration Task (https://arxiv.org/abs/2410.11860)
Comments:
          15 pages, 14 figures, accepted to ACM CHI 2023

- **What's New**: 이번 연구는 AI를 활용한 의사결정 시스템 설계에서 precision (정밀도)와 recall (재현율) 간의 Tradeoff를 조정하여 인간-AI 팀의 성과를 높이는 방법을 제시합니다. 특히, 영상 익명화 작업을 통해 유의미한 결과를 도출하였습니다.

- **Technical Details**: 본 연구는 78명의 전문가 주석가가 3,466시간 이상에 걸쳐 AI 지원 없이, high-precision 'restrained' AI 그리고 high-recall 'zealous' AI의 지원을 받으며 수행한 영상 주석 작업을 분석하였습니다. 이를 통해 각 AI 시스템의 성능을 비교하고, recall에 중점을 둔 zealous AI가 인간 작업자에게 더 높은 Recall과 짧은 작업 완료 시간을 제공함을 확인했습니다.

- **Performance Highlights**: 연구 결과, zealous AI와 함께 작업한 팀은 Recall이 크게 향상되었으며, 더 빠른 작업 완료 시간을 기록했습니다. 또한, restrained AI에서 훈련된 주석가는 AI의 지원이 없는 상태에서 부정적 영향을 받는 경향을 보였습니다.



### Online Energy Optimization in GPUs: A Multi-Armed Bandit Approach (https://arxiv.org/abs/2410.11855)
- **What's New**: 본 논문에서는 GPU의 온라인 에너지 최적화 문제를 새롭게 연구하며, 이 문제를 멀티암드 밴딧(multi-armed bandit) 프레임워크로 공식화하고 EnergyUCB라는 혁신적인 알고리즘을 개발하였습니다.

- **Technical Details**: EnergyUCB는 GPU 코어 주파수를 실시간으로 조정하여 에너지 소비를 줄이는 것을 목표로 하며, 다음과 같은 주요 기여를 포함합니다: (1) 보상 함수에서 성능-에너지 균형을 조정, (2) 주파수를 온라인으로 조정할 때의 탐색(exploration) 및 활용(exploitation) 문제 해결, (3) 실시간 GPU 성능 메트릭으로 GPU 코어 사용률과 언코어(uncore) 사용률 비율 활용.

- **Performance Highlights**: 다양한 실세계 HPC 벤치마크에서 실험한 결과, EnergyUCB는 기본 설정보다 상당한 에너지 절약을 달성할 수 있음을 보여줍니다.



### From Commands to Prompts: LLM-based Semantic File System for AIOS (https://arxiv.org/abs/2410.11843)
- **What's New**: 이 논문에서는 LLM 기반의 의미적 파일 시스템(LSFS)을 제안하여 전통적인 파일 시스템의 한계를 극복하고, 자연어 프롬프트를 통한 파일 관리를 가능하게 합니다.

- **Technical Details**: LSFS는 벡터 데이터베이스를 활용한 의미적 인덱스 구조를 도입하여 파일을 저장하고, 다양한 syscalls와 APIs를 설계하여 복잡한 파일 작업을 수행합니다. LLM을 통합하여 사용자가 입력한 자연어를 처리하고 의미적 기능을 지원하는 API를 실행하게 합니다.

- **Performance Highlights**: LSFS는 전통적인 파일 시스템에 비해 사용자 편의성, 다양성 및 효율성에서 유의미한 향상을 보여주며, 내용 요약 및 버전 비교와 같은 지능형 파일 관리 작업을 지원합니다.



### Survey and Evaluation of Converging Architecture in LLMs based on Footsteps of Operations (https://arxiv.org/abs/2410.11381)
Comments:
          13 pages and 16 figures

- **What's New**: 이 논문은 Attention 메커니즘과 Transformer 아키텍처의 발전이 LLM(대형 언어 모델)의 구조적 수렴에 미친 영향을 분석하고, 다양한 하이퍼파라미터 설정에 따른 성능 경향을 정리하고 있습니다.

- **Technical Details**: LLM 아키텍처의 성능을 레이어 구성, 작동 메커니즘, 모델 크기를 고려하여 분석하였으며, 특히 최신의 RTX 6000을 사용하여 하이퍼파라미터 설정의 영향을 평가했습니다. TensorRT-LLM과 같은 고속 추론 성능을 지원하는 오픈소스 라이브러리도 논의되었습니다.

- **Performance Highlights**: 연구 결과, 동일한 모델이라 하더라도 하이퍼파라미터 설정이나 서버와 엣지 환경에서의 배포 방식에 따라 성능이 달라질 수 있다는 것을 확인했습니다. 또한, 최신 오픈소스 LLM(Begma와 Llama)의 아키텍처를 분석하고, 고성능 GPU에서 추론 프로세스를 집중적으로 살펴보았습니다.



### Evidence of Cognitive Deficits andDevelopmental Advances in Generative AI: A Clock Drawing Test Analysis (https://arxiv.org/abs/2410.11756)
- **What's New**: 이번 연구는 여러 개의 최신 Generative AI (GenAI) 모델이 시각적 계획 및 조직을 평가하는 Clock Drawing Test (CDT)에서 어떻게 수행하는지를 탐구합니다. 모델들은 시계처럼 보이는 그림을 그릴 수 있지만, 정확한 시간 표현에서 어려움을 겪고 있으며, 이는 경미한~심각한 인지 장애와 유사한 결함을 나타냅니다.

- **Technical Details**: CDT는 신경심리학적 평가 도구로, 방대한 텍스트 및 코드 데이터 세트로 교육된 GenAI 모델의 인지 기능을 평가하는 데 사용됩니다. 연구에는 Google의 Gemini 시리즈, OpenAI의 GPT 모델 등이 포함되었습니다. 모델들은 동일한 CDT 프롬프트에 따라 시계 그림을 그리도록 지시받았습니다.

- **Performance Highlights**: 오직 GPT 4 Turbo와 Gemini Pro 1.5만 정확한 시간을 표현했고, Sonnet 3.5만 후속 테스트에서 성공했습니다. 결과는 시계 그리기에서 나타나는 결함이 숫자 개념의 어려움에서 비롯될 수 있음을 시사하며, 이는 시각-공간 이해, 작업 기억 또는 계산에서의 약점을 반영합니다.



### Are UFOs Driving Innovation? The Illusion of Causality in Large Language Models (https://arxiv.org/abs/2410.11684)
- **What's New**: 본 연구에서는 대형 언어 모델(large language models, LLMs)이 실세계 환경에서 인과성 오류(illusion of causality)를 발생시키는지 조사했습니다. 구체적으로는, 뉴스 헤드라인 생성을 통해 인과관계로 잘못 프레이밍된 상관관계의 정도를 평가했습니다. 특히, GPT-4o-Mini, Claude-3.5-Sonnet, Gemini-1.5-Pro 모델의 성능을 비교했습니다.

- **Technical Details**: 연구를 위해 저자들은 100개의 관찰 연구 논문의 초록을 기반으로 spurious correlations(거짓 상관관계)을 수집했습니다. 각 모델에게 주어지는 작업은 기자의 관점에서 뉴스 헤드라인을 생성하는 것이며, 이 과정에서 sycophancy(아부적 행동)의 영향을 평가하기 위해 미묘하게 수정된 프롬프트를 사용했습니다. 특히, 오류가 있는 믿음을 반영했을 때 모델이 얼마나 더 인과성 오류를 발생시키는지를 관찰했습니다.

- **Performance Highlights**: 연구 결과, Claude-3.5-Sonnet이 인과성 오류를 가장 적게 보이는 것으로 확인되었습니다. 반면, GPT-4o-Mini는 아부적 행동이 인과성 오류를 발생시킬 가능성을 높였습니다. Claude-3.5-Sonnet은 이러한 인지적 편향에 가장 저항력이 있는 모델로 밝혀졌습니다.



### Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Developmen (https://arxiv.org/abs/2410.11550)
Comments:
          12 pages, Under Review

- **What's New**: Y-Mol은 약물 개발(flow of drug development) 과정에서의 특정 도전 과제를 해결하기 위해 설계된 새로운 다중 규모 생물 의학 지식 기반 LLM입니다.

- **Technical Details**: Y-Mol은 백서, 지식 그래프, 전문가가 설계한 합성 데이터로부터 학습하여 생물 의학 영역의 추론 능력을 향상시킵니다. LLaMA2를 기반으로 하고 있으며, 세 가지 유형의 약물 지향 지시문인 설명 기반 프롬프트(description-based prompts), 의미 기반 프롬프트(semantic-based prompts), 템플릿 기반 프롬프트(template-based prompts)를 통합하여 약물 개발의 모든 과정에서 자율적으로 하위 작업을 수행할 수 있도록 설계되었습니다.

- **Performance Highlights**: Y-Mol은 일반 목적의 LLM에 비해 리드 화합물 발견(lead compound discovery), 분자 특성 예측(molecular properties prediction), 약물 상호 작용 이벤트 확인(drug interaction events identification)에서 유의미하게 뛰어난 성능을 보였습니다.



### AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data (https://arxiv.org/abs/2410.11531)
Comments:
          30 pages, 7 figures; Submitted to COLING 2025 System Demonstrations Track

- **What's New**: AGENTiGraph(Adaptive Generative ENgine for Task-based Interaction and Graphical Representation) 플랫폼은 자연어 상호작용을 통해 지식 관리의 혁신을 이루며, 복잡한 도메인 특정 작업의 문제 해결을 위해 다중 에이전트 아키텍처를 활용합니다.

- **Technical Details**: AGENTiGraph는 자연어 쿼리를 구조화된 그래프 작업으로 변환하는 세련된 세미틱 파싱(semantic parsing) 기법을 사용하며, 사용자의 의도를 실시간으로 해석하고 새로운 지식을 통합하는 다중 에이전트 시스템(multi-agent system)을 통해 유연하게 동작합니다. 시스템은 동적 지식 통합(dynamic knowledge integration) 기능을 지원하며, 사용자에게 복잡한 데이터 관계를 시각화 하는 기능도 제공합니다.

- **Performance Highlights**: AGENTiGraph는 3,500개의 테스트 케이스에서 수행된 실험을 통해 작업 분류에서 95.12%의 정확도와 작업 실행에서 90.45%의 성공률을 기록하며 최첨단 zero-shot 기준을 초과하는 성과를 달성했습니다. 사용자 연구는 AGENTiGraph의 실제 시나리오 효율성을 입증하였습니다.



### Revisiting Benchmark and Assessment: An Agent-based Exploratory Dynamic Evaluation Framework for LLMs (https://arxiv.org/abs/2410.11507)
- **What's New**: 다양한 Vertical Domain Large Language Models (LLMs)의 성능 자동 평가의 필요성과 이를 해결하기 위한 새로운 정의와 프레임워크 도입이 주목됩니다.

- **Technical Details**: 기존의 평가 방법에서 벗어나, Benchmark+와 Assessment+라는 두 가지 새로운 정의를 도입하였습니다. Benchmark+는 전통적인 QA 벤치마크를 'strategy-criterion' 형식으로 확장하고, Assessment+는 상호작용 과정을 향상시켜 다각적인 메트릭(quantitative metrics) 및 질적 통찰(qualitative insights)을 제공합니다. 이 두 개념을 구현하기 위해 *TestAgent*라는 에이전트 기반 평가 프레임워크를 제안하였습니다.

- **Performance Highlights**: 다양한 시나리오에서 *TestAgent*의 효과성을 입증하는 실험을 수행하였으며, 기존 벤치마크를 활용하거나 새로운 Vertical Domain 평가를 구축하는 작업에서 그 효율성을 보여주었습니다.



### A Case for AI Consciousness: Language Agents and Global Workspace Theory (https://arxiv.org/abs/2410.11407)
- **What's New**: 이 논문은 기존 인공지능 시스템이 현상적 의식(phenomenal consciousness)을 가지고 있지 않다는 일반적인 가정을 도전합니다.

- **Technical Details**: 글로벌 작업 공간 이론(Global Workspace Theory, GWT)이 정확하다면, 널리 구현된 인공지능 아키텍처 중 하나인 인공 언어 에이전트가 현재 현상적 의식을 가지지 않더라도 쉽게 현상적 의식을 가질 수 있다고 주장합니다. 또한 이론을 인공지능 시스템에 적용하기 위한 명확한 방법론을 제시하며, GWT에 따른 현상적 의식을 위한 필요한 조건과 충분한 조건을 도출합니다.

- **Performance Highlights**: 이 연구는 인공지능 시스템에 대한 의식 이론의 적용 가능성을 탐구하여, 현상적 의식의 정의와 인공지능 시스템의 발전 방향에 대한 새로운 시각을 제공합니다.



### Implementing Derivations of Definite Logic Programs with Self-Attention Networks (https://arxiv.org/abs/2410.11396)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 본 논문에서는 논리 추론(logical inference)의 제한된 버전을 self-attention 네트워크를 통해 구현할 수 있음을 제안하고 있습니다. LLMs(대형 언어 모델)의 가능성을 보여주기 위해 transformer 네트워크의 주요 구성 요소인 self-attention 네트워크를 분석합니다.

- **Technical Details**: 우리는 self-attention 네트워크를 사용하여 논리 공식의 특정 클래스에 대한 top-down 및 bottom-up 유도(derivation)를 모두 구현할 수 있음을 보입니다. 특히, self-attention 네트워크는 쿼리, 키, 값의 세 가지 입력을 받아 처리하며, 이러한 입력들이 유도 작업의 세 가지 요소와 대응된다는 점을 강조합니다. 이 연구에서는 softmax 대신 hardmax 함수를 사용하고 있습니다.

- **Performance Highlights**: 논문의 결과로 LLMs가 논리 추론의 힘을 암묵적으로 지니고 있음을 입증하며, self-attention 네트워크를 통해 확장 가능한 추론 메커니즘을 구현하는 데 성공했습니다.



### Diffusion-Based Offline RL for Improved Decision-Making in Augmented ARC Task (https://arxiv.org/abs/2410.11324)
Comments:
          Preprint, Under review. Comments welcome

- **What's New**: 본 논문은 Latent Diffusion-Constrained Q-learning (LDCQ)이라는 혁신적인 diffusion 기반 오프라인 RL 접근법을 사용하여 Abstraction and Reasoning Corpus (ARC)에서의 AI의 전략적 추론 능력을 평가합니다. 이 연구는 SOLAR라는 새로운 데이터셋을 도입하여 오프라인 RL 에이전트의 학습을 위해 다양한 경험 데이터를 제공합니다.

- **Technical Details**: 본 연구는 SOLAR-Generator를 통해 원하는 조건에 따라 다양한 경로 데이터를 생성하며, 이 데이터를 통해 LDCQ 방법으로 에이전트를 훈련합니다. ARCLE 환경 내에서 마르코프 결정 과정(Markov Decision Process, MDP) 구조를 사용하여 에이전트가 그리드 기반 작업을 해결할 수 있도록 합니다.

- **Performance Highlights**: 실험 결과, LDCQ 방법으로 훈련된 에이전트는 다양한 액션을 적용하고 다단계 순차 결정을 수행하여 정답 상태를 정확히 식별하는 능력을 보여줍니다. 이 결과는 오프라인 RL 접근법이 AI의 전략적 추론 능력을 향상시킬 수 있는 가능성을 잘 보여줍니다.



### Learning Agents With Prioritization and Parameter Noise in Continuous State and Action Spac (https://arxiv.org/abs/2410.11250)
Comments:
          10 pages, 3 figures. Published in Advances in Neural Networks - ISNN 2019

- **What's New**: 본 논문에서는 Deep Q-learning (DQN)과 Deep Deterministic Policy Gradient (DDPG) 방법을 결합하여 연속 상태 및 행동 공간 문제에서 이전 방법보다 뛰어난 성능을 발휘하는 새로운 알고리즘인 Prioritized DDPG를 소개합니다. 또한, 훈련 중에 매개변수 노이즈를 적용하여 더욱 견고한 딥 RL 모델을 생성하는 방법도 설명합니다.

- **Technical Details**: Prioritized DDPG는 DDPG의 함수 근사기에서 우선 샘플링 개념을 사용하여 성능을 향상시킵니다. 본 방법은 DQN의 새로운 개념인 Prioritized Experience Replay을 활용하여 DDPG보다 뛰어난 성과를 달성할 수 있도록 설계되었습니다. 이를 통해 연속 동작 공간 환경에서 DDPG보다 우수한 성능을 보입니다.

- **Performance Highlights**: 본 연구에서 제안된 Prioritized DDPG는 대부분의 연속 동작 공간 환경에서 DDPG를 능가하는 성능을 보여주며, 매개변수 공간 노이즈를 이용한 탐색이 보상을 더욱 향상시키는 데 기여함을 입증했습니다.



### Latent-Predictive Empowerment: Measuring Empowerment without a Simulator (https://arxiv.org/abs/2410.11155)
- **What's New**: 본 연구에서는 Latent-Predictive Empowerment (LPE)라는 새로운 알고리즘을 제안합니다. 이는 대규모 기술 세트(skillsets)를 학습하는 데 효과적이며, 기존의 방법들보다 더 실용적으로 구현할 수 있습니다.

- **Technical Details**: LPE는 기술(skill)과 상태(state) 간의 상호 정보(mutual information)를 최대화하는 대신, 더 간단한 잠재 예측 모델(latent-predictive model)을 사용하여 목표를 설정합니다. 이는 전체 환경 시뮬레이터(full simulator)가 아니라 간단한 모델만 필요로 합니다.

- **Performance Highlights**: 다양한 설정에서 실험을 통해 LPE는 기술 세트를 유사한 크기로 학습하며, 전환 동역학(transition dynamics) 모델에 접근할 수 있는 기존의 알고리즘과 유사한 성능을 보였습니다. 또한, LPE는 다른 모델 기반 접근법(model-based approaches) 대비 우수한 성능을 나타냈습니다.



### Can Structured Data Reduce Epistemic Uncertainty? (https://arxiv.org/abs/2410.11141)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 이 논문에서는 온톨로지(ontology)를 활용하여 딥러닝 모델의 학습 과정을 개선하는 새로운 프레임워크를 제시합니다. 기존 모델보다 세분화된 작업에서 더 높은 학습률과 성능을 달성한다고 보고합니다. 또한, 온톨로지 정렬 과정에서 추출한 서브섬프션 맵이 대형 언어 모델에서 Retrieval-Augmented Generation을 향상시키는 데 어떻게 도움이 되는지 보여주고 있습니다.

- **Technical Details**: 연구에서는 온톨로지를 기반으로한 데이터 구조가 언어 모델의 인식 불확실성(epistemic uncertainty)을 줄이는 데 어떻게 기여하는지를 설명합니다. 다섯 가지 주요 단계로 구성된 프레임워크를 통해 신속한 학습과 망상(hallucination) 감소를 목표로 하고 있습니다. S와 T라는 두 개의 온톨로지를 정렬함으로써 클래스 간 의미적 상응 관계를 파악하고, 이를 통해 Equivalence 및 Subsumption 매핑을 획득합니다.

- **Performance Highlights**: 온톨로지를 활용한 모델은 맥락 유사도가 8.97% 증가하고 사실 정확도는 1% 향상되었습니다. 또한, 이 접근법을 통해 LLM의 할루시네이션 지수가 4.847% 감소하였음을 보여줍니다.



### 3D-Prover: Diversity Driven Theorem Proving With Determinantal Point Processes (https://arxiv.org/abs/2410.11133)
- **What's New**: 이 논문에서는 자동 형식 추론에서의 검색 공간 문제를 해결하기 위해 3D-Prover라는 새로운 기법을 제안합니다. 기존의 증명 공략을 개선하고, 실행 오류를 줄이기 위해 합성 데이터(synthetic data)를 사용하여 기법을 필터링하는 메커니즘을 도입하였습니다.

- **Technical Details**: 3D-Prover는 Determinantal Point Processes를 이용하여 증명 검색 공간을 효과적으로 축소합니다. 이는 각 증명 기법의 환경에 대한 효과, 성공 가능성 및 실행 시간을 캡처한 기법 표현을 학습하는 방식으로 이루어집니다.

- **Performance Highlights**: 실험 결과, 3D-Prover는 ReProver LLM을 보강하여 전체 증명 성공률, 기법 성공률, 실행 시간 및 기법의 다양성을 크게 향상시켰습니다. 특히 miniF2F-valid 및 miniF2F-test 벤치마크에서 효과를 입증했습니다.



### Generating Global and Local Explanations for Tree-Ensemble Learning Methods by Answer Set Programming (https://arxiv.org/abs/2410.11000)
Comments:
          Under consideration in Theory and Practice of Logic Programming (TPLP). Some parts of this paper were presented at ICLP 2021, and published in EPTCS 345, 2021, pp. 127-140, arXiv:2109.08290

- **What's New**: 본 연구는 Answer Set Programming (ASP)을 이용하여 나무 앙상블(tree-ensemble) 학습 방법의 글로벌(global) 및 로컬(local) 설명을 생성하는 방법을 제시합니다. 이 방법론은 트리 구조에서 분할된 구조를 활용하여 규칙을 구축하고, 이를 ASP로 인코딩된 패턴 마이닝 방법을 사용해 평가하여 설명 규칙을 추출합니다.

- **Technical Details**: 제안된 방법은 두 단계로 구성됩니다: (1) 나무 앙상블에서 규칙 추출, (2) ASP에서 선언적으로 인코딩된 선택 기준 및 선호에 따라 규칙 집합을 계산합니다. ASP는 제약(condition)을 표현하는 데 있어 그 표현력과 확장성이 뛰어나며, 이를 통해 훈련된 나무 앙상블 모델로부터 유용한 규칙을 선택하는 작업을 자동화할 수 있습니다.

- **Performance Highlights**: 실제 데이터셋과 인기 있는 나무 앙상블 알고리즘을 사용한 실험적 평가 결과, 제안된 방법이 폭넓은 분류 작업에 적용 가능함을 보여줍니다. 글로벌 설명의 경우, 규칙 집합의 수와 관련성을 평가하며, 로컬 설명은 정확도와 커버리지를 기준으로 비교합니다.



### WILT: A Multi-Turn, Memorization-Robust Inductive Logic Benchmark for LLMs (https://arxiv.org/abs/2410.10998)
Comments:
          Submitted to ICLR 2025. Preprint version 1

- **What's New**: 본 논문에서는 Wason Inductive Logic Test (WILT)라는 새로운 다단계 추론 벤치마크를 소개합니다. 이 벤치마크는 기억력이 아닌 실제 추론 능력을 테스트하는 데 중점을 두고 있습니다.

- **Technical Details**: WILT는 LLMs(대형 언어 모델)가 여러 차례의 상호작용을 통해 증거를 수집하고 논리적 결론을 도출할 수 있는 능력을 평가하는 다단계 벤치마크입니다. 참가자는 최대 30개의 테스트 사례를 제안하고, 숨겨진 규칙을 추론해야 합니다. 각 테스트는 초기 지침에서 시작되며, 모델은 유효한 입력을 제안하고 결과(True 또는 False)를 통해 가능성을 좁혀가야 합니다.

- **Performance Highlights**: 현재의 최고 성능 모델은 단지 28%의 정확도로, 이는 LLM이 복잡한 다단계 추론 작업에서 상당한 성과 부족을 보여줍니다.



### Agent-as-a-Judge: Evaluate Agents with Agents (https://arxiv.org/abs/2410.10934)
Comments:
          The project can be found at this https URL. The dataset is released at this https URL

- **What's New**: 이번 논문에서는 Agent-as-a-Judge 프레임워크를 소개합니다. 이는 agentic 시스템을 평가하기 위해 자체적으로 agentic 시스템을 사용하는 방법입니다. 이 프레임워크는 기존의 LLM-as-a-Judge 프레임워크를 확장하여 전체 작업 해결 과정에 대한 중간 피드백을 제공합니다.

- **Technical Details**: Agent-as-a-Judge는 55개의 실제적인 자동 AI 개발 작업으로 구성된 새로운 벤치마크인 DevAI에 적용되었습니다. 이 벤치마크는 365개의 계층적 사용자 요구사항을 포함하고 있습니다. Agent-as-a-Judge는 세 가지 인기 있는 agentic 시스템의 성능을 평가하였고, 그 결과 LLM-as-a-Judge보다 현저한 성능 향상을 보였으며 인간 평가 기준과 비슷한 신뢰성을 지니고 있습니다.

- **Performance Highlights**: Agent-as-a-Judge는 인간 평가자와의 일치도가 90%로, LLM-as-a-Judge의 70%에 비해 확연히 높았습니다. 추가적으로, Agent-as-a-Judge는 인간 전문가보다 더 유용할 수 있음을 보여주었고, 평가 비용 측면에서 97.72%의 시간과 97.64%의 비용을 절감할 수 있었습니다.



### MoH: Multi-Head Attention as Mixture-of-Head Attention (https://arxiv.org/abs/2410.11842)
Comments:
          23 pages, code: this https URL

- **What's New**: 본 연구에서는 Transformer 모델의 핵심인 multi-head attention 메커니즘을 개선하여 효율성을 높이고 이전의 정확도 수준을 유지하거나 초과하는 방법을 제안합니다. 주목할 점은 모든 attention head가 동일한 중요도를 가지지 않는다는 인식에 기반하여 Mixture-of-Head attention (MoH)이라는 새로운 아키텍처를 제안합니다.

- **Technical Details**: MoH는 각 토큰이 적절한 attention heads를 선택할 수 있도록 하여 추론 효율성을 향상시킵니다. 또한 MoH는 multi-head attention의 일반적인 합산을 가중 합산으로 대체하여 attention 메커니즘에 유연성을 추가하고 성능 잠재력을 높입니다. 우리는 ViT, DiT 및 LLMs와 같은 다양한 모델 프레임워크에서 MoH의 성능을 평가하였습니다.

- **Performance Highlights**: MoH는 단지 50%-90%의 attention heads를 사용하여 multi-head attention을 능가하는 성능을 달성하였습니다. 예를 들어, MoH-ViT-B는 ImageNet-1K 분류 기준에서 84.9%의 Top-1 정확도를 기록하며, LLaMA3-8B 모델과의 비교에서 2.4%의 성능 향상을 보였습니다.



### GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable Recommendation (https://arxiv.org/abs/2410.11841)
- **What's New**: GaVaMoE는 새로운 Gaussian-Variational Gated Mixture of Experts 프레임워크를 도입하여 설명 가능한 추천 시스템의 개인화 및 데이터 희소성을 해결합니다.

- **Technical Details**: GaVaMoE는 두 가지 주요 구성 요소를 포함합니다: (1) Variational Autoencoder (VAE)와 Gaussian Mixture Model (GMM)을 사용하여 복잡한 사용자-아이템 협업 선호를 모델링하는 평가 재구성 모듈; (2) 다수의 전문가 모델을 활용해 세부적으로 개인화된 설명을 생성하는 다중 게이팅 메커니즘입니다.

- **Performance Highlights**: GaVaMoE는 세 개의 실제 데이터셋에서 실행된 광범위한 실험을 통해 기존 방법보다 설명 품질, 개인화 및 일관성에서 유의미하게 우수한 성능을 보여주었습니다.



### A Hitchhiker's Guide to Scaling Law Estimation (https://arxiv.org/abs/2410.11840)
- **What's New**: 이 논문에서는 485개의 기존 사전 훈련(pretrained) 모델의 손실(loss)과 다운스트림 평가(downstream evaluations)를 포함한 대규모 데이터셋을 수집하여 비용 효과적인 scaling laws 추정 방법을 제시합니다.

- **Technical Details**: Scaling laws는 매개변수(parameter) 수가 적거나 훈련 데이터셋 크기가 작은 모델에서 추정한 손실을 통해 타겟 모델의 손실을 예측하는 방법입니다. 이 방법은 모델이 같은 아키텍처를 공유하고 매개변수 수와 훈련 데이터 크기만 다른 경우에 주로 사용됩니다. 본 연구에서는 중간 체크포인트에서의 손실을 활용하여 더 나은 scaling laws 추정을 가능하게 했습니다.

- **Performance Highlights**: 모델의 크기가 같거나 유사할 때 손실 예측의 정확도가 가장 높았고, 몇 번의 훈련 세트를 가진 작은 모델을 훈련시키는 것이 하나의 큰 모델을 훈련시키는 것보다 유용한 경우가 많다고 밝혔습니다.



### Mitigating Suboptimality of Deterministic Policy Gradients in Complex Q-functions (https://arxiv.org/abs/2410.11833)
- **What's New**: 이번 논문에서는 강화 학습의 오프 정책(actor-critic) 접근 방식에서 발생하는 문제를 해결하기 위해 새로운 액터 아키텍처를 도입했습니다. 이 아키텍처는 여러 액터를 사용하여 Q 값을 최대화하는 행동을 평가하고, Q 함수를 최적화하기 위한 서그릿(surrogate) 모델을 학습하는 방식입니다.

- **Technical Details**: 기존 DDGP와 TD3의 문제점으로 발견된 Q 값의 복잡성을 해결하기 위해, 다수의 액터와 서그릿 모델을 활용한 새로운 정책 반복 알고리즘을 제안했습니다. 이 방법은 액터가 여러 정책을 교대로 생성하고, 각 정책에 대해 Q 값을 최대화하는 행동을 선택합니다. 이를 통해 탐색 과정에서 지역 최적해에 머무는 문제를 해결할 수 있습니다.

- **Performance Highlights**: 제안된 아키텍처는 제한된 이동, 정교한 조작 및 대규모 이산 행동 공간 추천 시스템과 같은 다양한 태스크에서 기존 액터 아키텍처에 비해 최적 행동을 더 빈번히 찾아내며 성능이 우수함을 입증했습니다.



### Learning Smooth Humanoid Locomotion through Lipschitz-Constrained Policies (https://arxiv.org/abs/2410.11825)
Comments:
          8 pages

- **What's New**: 이번 연구에서는 Lipschitz 제약(Lipschitz constraint)을 통해 강화 학습(Reinforcement Learning) 정책에서 부드러운 동작을 유도하는 새로운 방법인 Lipschitz-Constrained Policies (LCP)를 제안합니다. 이 접근법은 기존의 비미분 가능 기술인 smoothness rewards 및 low-pass 필터의 필요성을 대체하며, 다양한 로봇에 쉽게 통합될 수 있습니다.

- **Technical Details**: LCP는 입력 관측값에 대해 정책의 출력 동작에 Lipschitz 제약을 강요하는 방법입니다. 이는 미분 가능의 gradient penalty 형태로 구현되며, 자동 미분(automatic differentiation) 프레임워크와 쉽게 결합할 수 있습니다. 연구팀은 LCP를 통해 다양한 형태의 유인형 로봇에서 제어 정책을 훈련할 수 있음을 보여주었습니다.

- **Performance Highlights**: LCP는 시뮬레이션과 실제 유인형 로봇 모두에서 부드럽고 강력한 이동 제어기를 생성하는 데 성공했습니다. 이 연구에 제안된 방법은 다양한 로봇 플랫폼에서 높은 일반화를 보여주며, 기존의 방법들과 비교할 때 간단하고 효율적인 솔루션을 제공합니다.



### OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation (https://arxiv.org/abs/2410.11792)
Comments:
          Accepted for oral presentation at 8th Annual Conference on Robot Learning. Project website: this https URL

- **What's New**: 이번 연구에서는 단일 RGB-D 비디오에서 인간의 동작을 모방하여 휴머노이드 로봇의 조작 기술을 학습하는 새로운 방법인 OKAMI를 소개합니다. OKAMI는 객체 인식과 조작을 위한 리타게팅(Object-aware retargeting) 기술을 통해 다양한 객체 위치에 맞춰 로봇의 동작을 조정합니다.

- **Technical Details**: OKAMI 방법론은 두 단계로 구성됩니다. 첫 번째 단계에서는 주어진 RGB-D 비디오에서 참조 조작 계획을 생성하고, 두 번째 단계에서는 이 계획을 활용해 다중 조작이 가능한 휴머노이드의 동작을 리타겟합니다. 리타게팅 과정에서는 객체의 위치를 반영하여 로봇 동작을 적절히 조정합니다.

- **Performance Highlights**: OKAMI는 다양한 작업에 대한 테스팅에서 평균 성공률 71.7%를 달성했으며, 기존의 ORION 기준선을 58.3% 초과하는 성능을 보였습니다. 또한, OKAMI를 통한 클로즈드 루프 비주얼 모터 정책 훈련에서 평균 79.2%의 성공률을 달성했습니다.



### Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability (https://arxiv.org/abs/2410.11786)
Comments:
          14 pages, 5 figures, 10 tables, EMNLP 2024 Findings

- **What's New**: 이번 연구에서는 Selection-p이라는 새로운 압축 방법을 제안하며, LLMs가 불필요한 토큰을 효과적으로 분류하여 압축할 수 있는 능력을 탐구합니다.

- **Technical Details**: 이 연구는 self-supervised pre-training 기법을 사용하여, LLM이 입력 토큰에 대해 보존 혹은 삭제할지의 확률을 계산하도록 합니다. 이는 추가적인 파라미터를 거의 추가하지 않고 이루어지며, 기존의 방법들에 비해 더 유연하고 효과적인 압축을 가능하게 합니다.

- **Performance Highlights**: Selection-p은 10배의 압축에서 단 0.8%의 성능 감소만 있으면서도 다수의 분류 작업에서 최상의 성능을 기록했습니다. 또한, 다양한 모델 간의 이동 가능성을 크게 향상시켰습니다.



### MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation (https://arxiv.org/abs/2410.11779)
Comments:
          Ongoing work

- **What's New**: 이번 연구에서 우리는 Multimodal Large Language Models (MLLMs)에서의 환각(hallucination) 현상을 심층적으로 분석하고, 이 현상의 배경 메커니즘을 이해하기 위한 새로운 동적 수정 디코딩 방법인 DeCo(이전 레이어 동지식 지능 수정)를 제안합니다.

- **Technical Details**: DeCo는 MLLM의 결론 층에 도달하기 전에 발생한 지식 정보를 동적으로 선택하여 최종 출력 로짓(logits)을 조정합니다. 이 방법은 모델에 구애받지 않으며, 여러 전통적인 디코딩 전략과 원활하게 통합될 수 있습니다.

- **Performance Highlights**: DeCo를 이미지 캡셔닝 및 시각 질문 답변 데이터셋에 적용한 결과, 평균 10.8%의 환각 억제 효과를 보여주었으며, 다양한 데이터셋에서 기존 방법들보다 더 높은 성능을 기록했습니다. 또한 DeCo는 이전 방법들과 비교했을 때 약간의 지연(latency) 증가가 있었지만, 속도는 훨씬 더 빨라졌습니다.



### Encoding architecture algebra (https://arxiv.org/abs/2410.11776)
Comments:
          25 pages, 6 figures. Keywords: typeful, algebraic data types, tensors, structured data

- **What's New**: 이 논문은 입력 데이터의 구조를 효과적으로 반영하는 입력 인코딩 아키텍처를 구축하기 위한 대수적 접근 방식을 도입합니다. 기존의 단일 타입 유형인 'tensor'에 의존하는 ML 프레임워크의 한계를 극복하고, 보다 구조화된 기계 학습을 위한 모델 설계에 타입의식을 추가합니다.

- **Technical Details**: 제안된 아키텍처는 복합 데이터를 처리할 수 있는 MFLs(멀티리니어 플래튼 층)를 포함합니다. 이 층은 다양한 성격의 데이터 타입을 일반화함으로써 고차원 대수적 데이터 타입(ADTs)을 다룰 수 있도록 합니다. 연구는 ADTs에 대한 기본 연산자 및 생성자를 정의하고, 모델 아키텍처와 입력 인코딩을 위한 구조를 제시합니다.

- **Performance Highlights**: 구조화된 입력 데이터의 특성을 반영하는 모델 아키텍처는 성능 향상, 파라미터 수 감소에 따른 일반화 능력 향상, 그리고 해석 가능성을 증가시킵니다. 이 연구는 특히 고차원 데이터를 효과적으로 처리할 수 있는 시스템의 기초를 다지기 위한 중요한 단계를 보여줍니다.



### Time-Series Foundation Model for Value-at-Risk (https://arxiv.org/abs/2410.11773)
- **What's New**: 이 연구는 VaR(Value-at-Risk) 추정을 위한 시계열 기초 모델의 활용 가능성을 탐색한 최초의 사례입니다. Google의 TimesFM 모델이 전통적인 계량경제학 기법들을 초월할 수 있는지 비교 검토했습니다.

- **Technical Details**: TimesFM 모델은 벡터 자기 회귀 모델(GARCH), 일반화 자기회귀 점수(GAS) 모델, 실증적 분산 추정 등을 포함한 기존 모델들과 비교되었습니다. 세부적으로, 91개 S&P 100 지수 구성 종목의 일일 수익률 데이터를 이용해 VaR 추정을 진행했습니다.

- **Performance Highlights**: 세밀한 조정이 이루어진 TimesFM 모델이 기존의 계량경제학적 방법론보다 안정적으로 우수한 성능을 보였으며, 제로샷(zero-shot) 환경에서도 좋은 성능을 발휘했습니다. 이 모델은 VaR의 다양한 수준에서 최고의 예측 성능을 기록했습니다.



### Can Search-Based Testing with Pareto Optimization Effectively Cover Failure-Revealing Test Inputs? (https://arxiv.org/abs/2410.11769)
Comments:
          Accepted for publication by Empirical Software Engineering Journal (EMSE) (in October 2024)

- **What's New**: 이번 연구는 Deep Learning-enabled (DL-enabled) 시스템의 결함을 드러내기 위한 Search-based software testing (SBST) 기법이 Pareto 최적화에 의존하는 것이 왜 부족한지를 설명합니다.

- **Technical Details**: 두 가지의 널리 사용되는 Pareto 기반 최적화 기법인 NSGA-II (진화 알고리즘)와 OMOPSO (군집 기반 Pareto 최적화 알고리즘)를 사용하여 두 개의 DL-enabled 시스템에 적용한 실험 결과를 제시합니다. 이 시스템들은 산업 자동 발렛 주차(Automated Valet Parking) 시스템과 손글씨 숫자 분류 시스템입니다. 결함을 드러내는 테스트 입력의 커버리지를 Coverage Inverted Distance 품질 지표를 사용하여 측정합니다.

- **Performance Highlights**: 연구 결과, NSGA-II 기반 탐색과 OMOPSO가 결함을 드러내는 테스트 입력을 커버하는 데 있어 단순 무작위 탐색(baseline)보다 효과적이지 않음을 발견했습니다.



### DPD-NeuralEngine: A 22-nm 6.6-TOPS/W/mm$^2$ Recurrent Neural Network Accelerator for Wideband Power Amplifier Digital Pre-Distortion (https://arxiv.org/abs/2410.11766)
Comments:
          5 pages, 5 figures

- **What's New**: DPD-NeuralEngine는 Gated Recurrent Unit (GRU) 기반의 초고속, 소형, 전력 효율이 뛰어난 Digital Pre-distortion (DPD) 가속기로, 22nm CMOS 구현이 2 GHz에서 작동하며 250 MSps의 I/Q 신호 처리 속도를 자랑합니다. 이 논문은 AI 기반 DPD 전용 집적 회로(ASIC) 가속기의 첫 사례로, 6.6 TOPS/W/mm²의 전력 면적 효율(PAE)을 달성했습니다.

- **Technical Details**: DPD-NeuralEngine은 GRU-RNN 아키텍처로 설계되어 있으며, 전처리기, GRU 레이어, 완전 연결 층(FC layer)으로 구성됩니다. 입력 신호에서 추출된 네 개의 특징을 GRU에 입력하고, GRU의 출력 신호는 아날로그 신호로 변환되어 전력 증폭기로 전달됩니다. 하드웨어 설계는 실시간 추론을 위해 구성된 마이크로 아키텍처를 포함하여, 비선형 활성화 함수(unit)와 메모리 버퍼를 갖추고 있습니다.

- **Performance Highlights**: 실험 결과, DPD-NeuralEngine은 256.5 GOPS의 처리량과 1.32 TOPS/W의 전력 효율, -45.3 dBc의 인접 채널 전력 비율(ACPR), -39.8 dB의 오류 벡터 크기(EVM) 성능을 보여줍니다. 이러한 성과는 기존 DPD 프레임워크들보다 우수한 성능을 나타냅니다.



### SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding (https://arxiv.org/abs/2410.11761)
- **What's New**: 본 논문에서는 병리학 분야의 첫 번째 비전-언어 보조도구인 SlideChat을 제안합니다. 이는 기가픽셀 수준의 전체 슬라이드 이미지를 이해할 수 있도록 설계되었으며, 다양한 병리학 시나리오에서 복잡한 지시를 처리할 수 있습니다.

- **Technical Details**: SlideChat은 SlideInstruction을 기반으로 훈련되며, 4.2K 개의 WSI 캡션과 176K 개의 VQA 쌍을 포함하는 대규모 다중모델 지시 데이터세트를 사용합니다. SlideChat의 아키텍처는 패치-레벨 인코더, 슬라이드-레벨 인코더, 다중모델 프로젝터 모듈, 대형 언어 모델을 포함합니다.

- **Performance Highlights**: SlideChat은 22개의 작업 중 18개에서 최첨단 성능을 달성하였고, SlideBench-VQA (TCGA)에서 81.17%, SlideBench-VQA (BCNB)에서 54.15%의 정확도를 보였습니다. 또한, 연구 및 개발을 촉진하기 위해 SlideChat, SlideInstruction 및 SlideBench는 오픈 소스 리소스로 제공될 예정입니다.



### Patch-Based Diffusion Models Beat Whole-Image Models for Mismatched Distribution Inverse Problems (https://arxiv.org/abs/2410.11730)
- **What's New**: 이번 연구에서는 기존의 diffusion 모델이 데이터 분포가 불일치할 때 발생하는 문제, 즉 single measurement와 small dataset에서의 image reconstruction 문제를 해결하기 위해 patch-based diffusion 모델을 제안합니다. 이 방법은 이미지 분포를 패치 단위로 학습하여 데이터 부족과 분포 불일치에 강한 일반화 능력을 가지고 있음을 보여줍니다.

- **Technical Details**: 연구에서는 두 가지 설정을 다룹니다. 첫째, unknown test distribution에서 단일 측정이 주어지는 경우입니다. 이 경우 우리는 self-supervised loss를 포함시켜 네트워크가 측정값과의 일관성을 유지하도록 돕습니다. 둘째, small dataset이 주어지는 경우로, patch-based 네트워크를 fine-tuning 하여 훨씬 더 나은 prior를 얻습니다. 이 방식은 whole-image 모델에 비해 성능이 우수함을 실험적으로 입증합니다.

- **Performance Highlights**: 실험 결과, patch-based 방법은 두 설정 모두에서 high quality image reconstruction을 달성하며, whole-image 모델보다 우수한 성능을 보입니다. 더불어 large in-distribution training datasets에 접근할 수 있는 방법들과도 경쟁할 수 있는 성과를 인정받았습니다.



### Generalizable Spacecraft Trajectory Generation via Multimodal Learning with Transformers (https://arxiv.org/abs/2410.11723)
Comments:
          8 pages, 6 figures, submitted to 2025 American Control Conference (ACC)

- **What's New**: 이 논문은 다양한 문제 구성에 대해 일반화할 수 있는 새로운 궤적 생성 프레임워크를 제안합니다. 특히, 멀티모달 데이터 소스로부터 학습할 수 있는 고용량 transformer 신경망을 활용하여 기존의 단일 시나리오 접근 방식을 극복합니다.

- **Technical Details**: 제안된 프레임워크는 transformer 기반 신경망 모델을 궤적 최적화 과정에 통합하여 장면 수준 정보(예: 장애물 위치, 초기 및 목표 상태)와 궤적 수준 제약(예: 시간 한계, 연료 소비 목표)을 인코딩합니다. transformer 네트워크는 비볼록 최적화 문제에 대해 가까운 최적 초기 추정을 생성하여 수렴 속도와 성능을 크게 향상시킵니다.

- **Performance Highlights**: 제안된 방법은 전통적인 접근 방식에 비해 최대 30%의 비용 개선과 80%의 불가능 사례 감소를 달성했습니다. 시뮬레이션과 실제 실험을 통해 다양한 시나리오 변형에 대한 강력한 일반화 능력을 입증했습니다.



### RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation (https://arxiv.org/abs/2410.11722)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 논문에서는 최근 개발된 Segment Anything (SAM)과 같은 대화형 세분화(interactive segmentation) 방법에 대한 사용자 클릭 패턴을 조사하고, 이를 기반으로 한 새로운 벤치마크 RClicks를 제안합니다. 클릭 패턴의 실제 사용에 대한 이해를 바탕으로, 클릭 가능성 모델(clickability model)을 사용하여 보다 현실적인 클릭 샘플을 생성할 수 있도록 합니다.

- **Technical Details**: 연구팀은 475,544개의 실제 사용자 클릭 데이터를 수집하여 대화형 세분화 시나리오에서 클릭 패턴을 분석했습니다. 이 연구는 saliency prediction(주목 예측) 이론을 적용하여 클릭 가능성 모델을 개발하였으며, 해당 모델은 사용자의 클릭 입력과 가장 유사한 샘플을 생성하는 데 초점을 맞추었습니다. RClicks는 기존 세분화 방법의 현실적 클릭에서 성능을 비교할 수 있는 포괄적인 벤치마크로서, (1) 클릭 수집 방법론을 도입하고, (2) 다양한 클릭 샘플링 전략을 사용할 수 있게 합니다.

- **Performance Highlights**: RClicks 벤치마크에 따르면, 기존의 방법들이 보고된 성능에 비해 현실 세계에서 성능이 저하될 수 있으며, 대부분의 방법들이 클릭 패턴에 대해 강건하지 않다는 것을 발견했습니다. 이는 기존 평가 방법이 실제 사용 시의 성능을 과대 평가할 수 있다는 점을 시사합니다. 연구에서는 다양한 세분화 방법의 평균 품질뿐만 아니라 강건성을 평가하였으며, 대화형 세분화 방법들이 모든 데이터셋에서 최적의 성능과 강건성을 동시에 달성할 수 없음을 보였습니다.



### Magnifier Prompt: Tackling Multimodal Hallucination via Extremely Simple Instructions (https://arxiv.org/abs/2410.11701)
Comments:
          9 pages, 13 tables, 4 figures

- **What's New**: 이 논문에서는 멀티모달 대형 언어 모델(MLLMs)에서 허위 정보(hallucinations)를 줄이기 위해 Magnifier Prompt (MagPrompt)라는 단순하면서도 효과적인 방법을 제안합니다. MagPrompt는 모델이 시각적 정보에 더 집중하도록 유도하며, 이미지와 내부 지식 간의 충돌이 있을 경우 이미지의 우선권을 강조하는 원칙에 기반합니다.

- **Technical Details**: MagPrompt는 훈련 없이 적용 가능하며, GPT-4o 및 Gemini와 같은 오픈소스와 클로즈드소스 모델에 모두 사용할 수 있습니다. 실험 결과, MagPrompt는 다양한 데이터셋에서 효과적으로 작동하며, 복잡한 방법인 VCD와 비교할 때 동등하거나 더 나은 성능을 보입니다. 이 방법은 간단한 지침을 통해 MLLMs의 허위 정보 문제를 해결할 수 있는 가능성을 보여줍니다.

- **Performance Highlights**: 실험에서 MagPrompt는 LLaVA-1.5와 Qwen-VL 모델에서 VCD보다 더 우수한 성능을 발휘했으며, F1 점수 전반에서 유의미한 향상을 기록했습니다. 또한 MagPrompt는 GPT-4o 및 Gemini와 같은 최신 클로즈드소스 모델에서도 적용 가능하여, 기존의 복잡한 방법들이 적용되지 않는 상황에서도 성능 향상을 가져왔습니다.



### BlendRL: A Framework for Merging Symbolic and Neural Policy Learning (https://arxiv.org/abs/2410.11689)
Comments:
          Preprint

- **What's New**: BlendRL은 강화학습(Strength Learning) 에이전트에서 신경망(neural networks)과 기호(symbolic) 접근 방식의 장점을 통합하는 새로운 프레임워크입니다. 이 방법은 기호적 추론(symbolic reasoning)과 직관적 반응(intuitive reactions)을 모두 활용합니다.

- **Technical Details**: BlendRL은 기호적 정책(symbolic policies)과 신경 정책(neural policies)의 혼합을 사용하여 에이전트들이 더 유연하고 해석 가능한 방식으로 문제를 해결할 수 있도록 합니다. 이 프레임워크는 기호적 시스템의 한계를 극복하고 다양한 환경에서 신뢰성을 높입니다.

- **Performance Highlights**: BlendRL 에이전트는 표준 Atari 환경에서 신경망 및 기호적 기준선(baselines)을 모두 초월하는 성능을 보여주며, 환경 변화에 대한 내구성(robustness)도 높습니다.



### State-space models can learn in-context by gradient descen (https://arxiv.org/abs/2410.11687)
Comments:
          16 pages, 5 figures

- **What's New**: 딥 상태-공간 모델(Deep SSMs)은 자가 회귀(task) 작업에서 사전 학습하기 위한 능력을 보여주고 있습니다. 본 연구에서는 상태-공간 모델 아키텍처가 경량 기법을 사용하여 사전 학습을 수행할 수 있음을 증명하고 있습니다.

- **Technical Details**: 이 연구는 로컬 자기 주의(local self-attention)를 보강한 구조화된 상태-공간 모델 레이어가 경량 회귀(implicit linear model)에서 최소 제곱 손실(least squares loss)을 복구할 수 있음을 보여줍니다. 또한, 대각선 선형 회귀층이 기울기를 누적하는 역할을 할 수 있음을 강조합니다. 이러한 SSM은 일반적인 예측 문제에서 좋은 성능을 보여줍니다.

- **Performance Highlights**: 무작위 초기화된 SSM이 단순 선형 회귀 작업에서 학습된 결과는 이론적으로 추론된 매개변수와 일치하며, 여러 단계의 선형 및 비선형 회귀 작업에서도 일관된 성과를 보였습니다.



### SurFhead: Affine Rig Blending for Geometrically Accurate 2D Gaussian Surfel Head Avatars (https://arxiv.org/abs/2410.11682)
- **What's New**: 본 논문에서는 SurFhead라는 새로운 방법을 제안하여 RGB 비디오를 사용하여 조정 가능한 머리 기하형상을 재구성하는 기법을 소개합니다. 기존의 기법이 유사 변환에 의존하여 기하학적 세부 사항을 캡처하는 데 어려움을 겪고 있는 반면, SurFhead는 2D Gaussian surfels를 활용하여 높은 충실도의 렌더링을 보장합니다.

- **Technical Details**: SurFhead는 고정된 광선 교차점에서의 정밀한 깊이 및 표면 방향에서 파생된 노멀과 같은 정의된 기하학적 속성을 가진 2D Gaussian surfels를 활용하여 기하학적 변형을 추출합니다. 고전적인 메쉬 기반 변형 전이와 아핀 변형 보간을 통해 극단적인 포즈에서도 고충실도의 렌더링을 실현합니다. 제안한 Jacobian Blend Skinning(JBS) 알고리즘은 인접한 변형 간의 아핀 변형을 매끄럽게 보간할 수 있게 해줍니다.

- **Performance Highlights**: SurFhead는 기존 접근 방식에 비해 높은 충실도를 유지하며, 실제 및 합성 데이터에서 다양한 주제를 대상으로 뛰어난 성능을 입증하였습니다. 특히, 볼록한 안구의 날카로운 반사, 복잡한 기하학적 세부 사항 및 과장된 변형 경우에서도 우수한 결과를 도출해 냈습니다.



### Understanding Likelihood Over-optimisation in Direct Alignment Algorithms (https://arxiv.org/abs/2410.11677)
Comments:
          Preprint Version

- **What's New**: 이번 연구에서는 Direct Alignment Algorithms (DAAs)로 알려진 새로운 방법론인 Direct Preference Optimisation (DPO)와 Identity Preference Optimisation (IPO)에서의 completion likelihood와 모델 성능 간의 관계를 탐구하고, 'likelihood over-optimisation'이라는 중요한 문제를 밝혀냈습니다.

- **Technical Details**: Direct Alignment Algorithms는 인간의 선호를 반영하기 위해, gewünschten (desired) 결과를 생성할 가능성을 높이고, 반면에 비선호 결과의 가능성을 줄이도록 설계되었습니다. 하지만, 좋은 결과의 likelihood가 높아도 모델 성능이 반드시 향상되지 않을 수 있으며, 이는 모델의 diversity를 저해하는 Over-Optimisation 현상으로 이어질 수 있습니다. 이 연구에서는 Two key indicators가 제시됩니다: (1) Decreasing Entropy over Top-k Tokens와 (2) Diminishing Top-k Token Probability Mass.

- **Performance Highlights**: 실험 결과, Over-Optimisation의 신뢰할 수 있는 신호를 제공하는 두 가지 지표가 제시되었고, 이를 통해 인간의 선호와의 정렬을 개선하며 성능 저하를 방지할 수 있음을 확인하였습니다.



### Leaving the barn door open for Clever Hans: Simple features predict LLM benchmark answers (https://arxiv.org/abs/2410.11672)
- **What's New**: 이 논문은 AI 벤치마크의 내부 타당성(internal validity)가 중요한 이유와 AI 시스템들이 의도치 않게 벤치마크를 해결하는 방법을 탐구합니다. 'Clever Hans' 효과를 염두에 두고, 최근 LLM(대형 언어 모델) 벤치마크에서 간단한 $n$-grams를 조합하여 레이블(label)을 예측할 수 있는지를 조사합니다.

- **Technical Details**: 연구에서는 단일 및 이중 $n$-grams를 사용하여 다중 선택 형식의 벤치마크에서 정답 레이블을 예측하는 로지스틱 회귀(classifier)를 훈련시킵니다. 이러한 분류기는 벤치마크가 테스트하도록 설계된 능력을 개발할 필요가 없기 때문에, 레이블이 성공적으로 예측될 경우 그 예제가 특정 능력을 사용할 필요 없이 해결될 수 있음을 시사합니다.

- **Performance Highlights**: 여러 벤치마크에서 과거 데이터에 기반한 간단한 분류기가 높은 정확도를 기록하여 내부 타당성이 문제가 될 수 있음을 시사하고, 일부 LLM들이 이와 같은 표면적인 패턴을 활용하여 벤치마크 문제를 해결할 수 있음을 보여줍니다. 또한 LLM의 성능이 벤치마크 데이터의 작고 미세한 변화에 감지된다는 점에 주목하여, 이들이 절차적 능력 대신 얕은 패턴에 의존하고 있다는 우려를 제기합니다.



### VisualRWKV-HD and UHD: Advancing High-Resolution Processing for Visual Language Models (https://arxiv.org/abs/2410.11665)
- **What's New**: 본 논문에서는 VisualRWKV 모델 계열의 두 가지 새로운 발전인 VisualRWKV-HD와 VisualRWKV-UHD를 소개합니다. 이 모델들은 고해상도 시각 입력을 효과적으로 처리하도록 설계되었습니다.

- **Technical Details**: VisualRWKV-HD는 손실 없는 다운샘플링 방법을 통해 고해상도 비전 인코더와 저해상도 인코더를 통합합니다. VisualRWKV-UHD는 이미지를 4개의 세그먼트로 나눈 후 다시 조합하여 고해상도 및 저해상도 특징을 모두 포함할 수 있도록 합니다.

- **Performance Highlights**: 이 두 모델은 VLM 벤치마크에서 강력한 성능을 발휘하며, 텍스트가 풍부한 작업에서 성능이 크게 향상되었습니다. 특히 VisualRWKV-UHD는 최대 4096 x 4096 픽셀 해상도를 지원하여 보다 상세하고 포괄적인 시각 처리 능력을 제공합니다.



### Retrieval Augmented Spelling Correction for E-Commerce Applications (https://arxiv.org/abs/2410.11655)
- **What's New**: 본 논문은 신생 브랜드 이름이 전통적인 철자 교정 시스템에 미치는 영향을 다루며, Retrieval Augmented Generation (RAG) 접근법을 사용하여 전통적인 방법보다 향상된 철자 교정을 보입니다.

- **Technical Details**: Retrieval Augmented Generation (RAG) 방법론을 통해 사용자 쿼리를 제품 카탈로그에서 관련 항목으로 검색하고, 이를 기반으로 Fine-tuning된 대형 언어 모델(LLM)에 컨텍스트를 제공합니다. 실험에 사용된 모델은 Mistral-7B와 Claude-3-sonnet이며, 다양한 검색 방법(BM25, Fuzzy BM25, ColBERT)을 평가했습니다.

- **Performance Highlights**: RAG 기반 접근법은 철자 교정 성능에서 일관된 향상을 보여줍니다. 특히 브랜드 이름이 포함된 쿼리에서 가장 큰 성과를 기록하였고, 레이턴시(혹은 지연 시간)의 증가도 최소화되었습니다.



### RS-MOCO: A deep learning-based topology-preserving image registration method for cardiac T1 mapping (https://arxiv.org/abs/2410.11651)
- **What's New**: 본 논문은 심장 T1 맵핑에서의 모션 보정을 위한 심층 학습 기반의 이미지 등록 프레임워크를 제안합니다. 특히, BLOC이라는 암묵적 일관성 제약 조건을 도입하여 이미지의 위상을 어느 정도 유지합니다.

- **Technical Details**: 제안된 방법은 비 지도학습 방식인 심장 심실 분할 네트워크와 이중 도메인 주의 모듈을 통합하여 심장 T1 가중 이미지의 모달리티 간 등록의 성능을 향상시킵니다. 이중 일관성 제약과 지역 안티 폴딩 제약을 포함한 BLOC 제약 조건이 등록의 넌리니아(Non-Rigid) 특성을 보장합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 기존의 방법들에 비해 뛰어난 성능과 높은 견고성을 입증하였으며, 특히 모션 보정 효과의 향상에 기여함을 보여주었습니다.



### ED-ViT: Splitting Vision Transformer for Distributed Inference on Edge Devices (https://arxiv.org/abs/2410.11650)
Comments:
          14 pages, 8 figures

- **What's New**: 이 논문에서는 자원 제한이 있는 엣지 디바이스에서 복잡한 Vision Transformer 모델을 효율적으로 실행하기 위해 ED-ViT라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 Vision Transformer 모델을 데이터 클래스의 특정 부분을 처리하는 여러 서브 모델로 분할합니다.

- **Technical Details**: ED-ViT는 Vision Transformer 모델을 여러 서브 모델로 나누는 구조를 가지고 있으며, 각 서브 모델은 지정된 데이터 클래스의 하위 집합을 처리합니다. 또한, 클래스별 프루닝(class-wise pruning) 기법을 도입하여 각 서브 모델의 크기를 축소하고, 모델 배치 최적화를 위한 그리디 할당 알고리즘을 설계했습니다. 실험은 세 가지 ViT 구조에 대해 다섯 개의 데이터셋을 사용하여 수행되었습니다.

- **Performance Highlights**: 실험 결과, ED-ViT는 엣지 디바이스에서의 추론 지연을 크게 줄이고, 모델 크기를 최대 28.9배와 34.1배 감소시키면서도 기존 Vision Transformer와 유사한 테스트 정확도를 유지하는 것으로 나타났습니다. ED-ViT는 또한 CNN 및 SNN 모델과의 비교 실험에서 고속 추론과 저성능 모델 크기를 유지하는 장점을 보였습니다.



### Improve Value Estimation of Q Function and Reshape Reward with Monte Carlo Tree Search (https://arxiv.org/abs/2410.11642)
- **What's New**: 이 논문은 불완전 정보 게임인 우노(Uno)에 대한 새로운 강화 학습( reinforcement learning ) 알고리즘을 제안합니다. 특히 Q 값( Q value ) 과 보상 구조( reward structure ) 개선을 통해 성능을 향상시키는 데 초점을 맞춥니다.

- **Technical Details**: 제안된 알고리즘은 Monte Carlo Tree Search (MCTS) 를 이용하여 Q 함수에서의 가치 추정을 개선합니다. 또한, MCTS를 사용하여 게임 환경 내에서 보상 구조를 재구성하는 방법을 채택합니다. 기본 프레임워크로 Double Deep Q-Learning (DDQN) 을 이용하며, 이 방식을 Actor-Critic과 같은 다른 알고리즘에도 일반화할 수 있습니다.

- **Performance Highlights**: 우리는 DDQN, Deep Monte Carlo, Neural Fictitious Self Play 등의 기존 알고리즘과 비교한 실험을 진행하였으며, 제안한 알고리즘은 특히 플레이어 수가 증가할수록 성능이 향상됨을 보여줍니다. DDQN과 MCTS의 결합은 초기 및 중간 학습 단계에서 성능 개선을 가속화하는 데 효과적입니다.



### VidEgoThink: Assessing Egocentric Video Understanding Capabilities for Embodied AI (https://arxiv.org/abs/2410.11623)
- **What's New**: 최근 멀티모달 대형 언어 모델(MLLM)의 발전은 구체적인 AI 응용 분야에 새로운 가능성을 열었습니다. 본 논문에서는 Egocentric 비디오 이해 능력을 평가하기 위한 포괄적인 벤치마크인 VidEgoThink를 소개합니다.

- **Technical Details**: VidEgoThink는 비디오 질문-응답(video question-answering), 계층 계획(hierarchy planning), 시각 기초(visual grounding), 보상 모델링(reward modeling)의 네 가지 주요 상호 연관된 작업을 설계하여 Embodied AI에서의 하위 조작과 MLLM 간의 갭을 줄이기 위한 것입니다. 자동 데이터 생성 파이프라인을 활용해 Ego4D 데이터셋을 기반으로 적절한 질문-응답 쌍을 생성합니다. 이 과정에서 GPT-4o의 지능을 활용하고, 생성된 데이터를 인적 평가자를 통해 필터링합니다.

- **Performance Highlights**: 실험 결과 모든 MLLM은 에고센트릭 비디오 이해와 관련된 작업들에서 저조한 성능을 보였습니다. 특히, GPT-4o는 32프레임 및 8프레임에서 각각 31.17%와 32.83%의 정확도를 기록했으며, 타겟 객체와 행동, 장면의 존재를 판단하는 데는 능력이 있지만, 순서나 시퀀스를 평가하는 능력에서 부족함을 보였습니다. 전반적으로, 현시점의 MLLM을 Embodied AI의 1인칭 시나리오에 직접 적용하는 데에는 많은 도전이 남아 있으며, 향후 추가적인 연구가 필요합니다.



### M$^{2}$M: Learning controllable Multi of experts and multi-scale operators are the Partial Differential Equations need (https://arxiv.org/abs/2410.11617)
Comments:
          30 pages, 16 figures

- **What's New**: 본 논문은 다중 규모 및 다중 전문가(M$^2$M) 신경 운영자(neural operator) 프레임워크를 도입하여 부분 미분 방정식(Partial Differential Equations, PDEs)을 효율적으로 시뮬레이션하고 학습하는 방법을 제안합니다. 이는 기존의 방법론들이 PDE의 복잡한 동적 시스템을 완전히 학습하지 못하는 문제를 해결하고자 합니다.

- **Technical Details**: M$^2$M 신경 운영자는 분할 정복(divide-and-conquer) 전략을 사용하여 다중 전문가 네트워크를 훈련시키며, 전문가의 선택 권한을 결정하는 제어 가능한 선행 게이팅 메커니즘을 통합하여 모델의 효율성을 높입니다. PI 제어 전략(Proportional, Integral control strategy)을 통해 학습 과정을 최적화하고, 맞춤형 다중 규모 데이터 세트를 제공하여 Navier-Stokes 방정식에서 성능을 검증합니다.

- **Performance Highlights**: M$^2$M은 기준선 방법들과 비교하여 높은 시뮬레이션 정확성을 달성하며, 모델의 해석 가능성을 향상시킵니다. 해당 연구는 효율적인 PDE 해법 및 다양한 스케일에서의 성능 통합이 가능한 가능성을 보여줍니다.



### Black-box Uncertainty Quantification Method for LLM-as-a-Judg (https://arxiv.org/abs/2410.11594)
- **What's New**: 이번 연구에서는 LLM-as-a-Judge의 평가 신뢰성을 높이기 위한 새로운 방법인 confusion-based uncertainty를 도입합니다. 이 방법은 LLM의 평가 결과와 가능한 평가 간의 관계를 분석하여 불확실성을 정량화합니다.

- **Technical Details**: 이 접근법은 LLM이 각 옵션에 대한 평가를 생성하도록 유도하고, 이러한 평가를 사용하여 confusion matrix를 구성하고 그에 따른 불확실성 레벨을 도출하는 방식으로 작동합니다. 프로세스는 평가 생성, confusion matrix 생성, 불확실성 레이블 설정의 네 가지 주요 단계로 구성됩니다.

- **Performance Highlights**: 실험 결과, 낮은 불확실성 점수는 높은 정확성과 강한 상관관계를 보이며, 이 방법은 다양한 데이터셋과 모델에 효과적으로 적용될 수 있음을 보여줍니다.



### PaSTe: Improving the Efficiency of Visual Anomaly Detection at the Edg (https://arxiv.org/abs/2410.11591)
Comments:
          13 pages, 6 figures

- **What's New**: 이번 논문에서는 Visual Anomaly Detection (VAD)의 경량화된 접근 방식을 소개하며, 자원 제한이 있는 엣지 디바이스에서의 배치를 가능하게 하는 새로운 알고리즘인 Partially Shared Teacher-student (PaSTe)를 제안합니다. 이 알고리즘은 기존의 Student Teacher Feature Pyramid Matching (STFPM) 접근 방식을 개선하여 메모리와 컴퓨팅 요구 사항을 줄입니다.

- **Technical Details**: VAD는 픽셀 수준의 이상 탐지를 위해 비지도 학습을 이용합니다. 이 논문에서 제안한 PaSTe 알고리즘은 lightweight neural network를 사용하여 메모리 사용량을 87%까지 줄이고, 계산 성능도 50%까지 감소시킵니다. 또한, MVTec 데이터셋을 사용해 엣지 디바이스에서 VAD의 실행 가능성을 검증합니다.

- **Performance Highlights**: PaSTe 알고리즘을 통해 추론 시간은 25% 단축되고, 훈련 시간은 33% 단축됩니다. 훈련 중 최대 RAM 사용량은 76% 감소하여 VAD 프로세스를 실질적으로 더 효율적으로 만들어 엣지 디바이스에서의 실질적인 배치가 가능해졌습니다.



### Towards a Healthy AI Tradition: Lessons from Biology and Biomedical Scienc (https://arxiv.org/abs/2410.11590)
- **What's New**: 이 논문에서는 AI(인공지능)와 생물의학 과학(Biomedical Science)의 공진화(co-evolution)를 통해 양 분야의 상호 이익을 강조하고 있습니다. AI의 정체성과 문화를 더욱 확립하기 위해 생물의학 과학의 전통을 AI 연구에 접목하는 방안을 제시합니다.

- **Technical Details**: AI는 다양한 분야와 교차하기 때문에 고유한 정체성을 갖추기 어려운 문제를 안고 있습니다. 이 논문에서는 AI 연구가 생물의학 연구 센터와 같은 협업적(logistic) 특성을 도입함으로써 연구의 재현성을 높이고, 위험 회피(risk aversion)를 줄이며, 박사 및 펠로우를 위한 멘토십 경로를 가속화할 수 있는 방법을 논의합니다.

- **Performance Highlights**: AI와 생물의학 과학의 문화적 통합을 통해 연구의 효율성과 협업 증가, 데이터의 재현성 향상 등 여러 혜택을 수혜 받을 수 있음을 보여줍니다.



### DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object Manipulation via Preference-based Action Alignmen (https://arxiv.org/abs/2410.11584)
- **What's New**: 최근 모방 학습이 로봇 조작 분야에서의 발전을 이루었으나, 복잡한 장기 변형물체 작업에 있어 여전히 어려움이 존재합니다. 이 연구에서는 복잡한 동적 시스템과 다중 작업 분포를 다루기 위한 데이터 효율적인 일반 학습 프레임워크인 DeformPAM을 제안합니다.

- **Technical Details**: DeformPAM은 장기 과제를 여러 행동 원시(action primitives)로 분해하고, 3D 포인트 클라우드 입력 및 확산(diffusion) 모델을 활용하여 행동 분포를 모델링합니다. 또, 인간의 선호 데이터를 사용하여 암묵적인 보상 모델을 훈련합니다. 추론(inference) 단계에서 보상 모델은 여러 후보 행동을 평가하고 실행을 위한 최적의 행동을 선택합니다.

- **Performance Highlights**: 세 가지 도전적인 실제 세계의 장기 변형물체 조작 작업에 대한 실험 결과, DeformPAM은 기준 방법(baseline methods)보다 작업 완료 품질 및 효율성을 향상시켰고, 제한된 데이터에서도 그 성과를 보여주었습니다.



### On-the-fly Modulation for Balanced Multimodal Learning (https://arxiv.org/abs/2410.11582)
Comments:
          Accepted by T-PAMI 2024

- **What's New**: 이번 논문에서는 다중 모달 (multimodal) 학습에서의 성능 향상을 위해 모달 간의 균형을 맞추는 새로운 접근 방식이 제안되었습니다. 기존의 공동 훈련 전략은 모든 모달에 동일한 목표를 두어 균형이 맞지 않는 단일 모달 (uni-modal) 표현이 발생하는 문제를 지적했습니다.

- **Technical Details**: 본 연구에서는 두 가지 새로운 기법인 On-the-fly Prediction Modulation (OPM)과 On-the-fly Gradient Modulation (OGM)을 소개합니다. OPM은 피드포워드 (feed-forward) 단계에서 우세한 모달리티의 영향을 줄이기 위해 동적 확률로 해당 모달의 특징을 무시하고, OGM은 역전파 (back-propagation) 단계에서 그라디언트를 완화하여 최적화 과정을 조절합니다.

- **Performance Highlights**: 제안된 방법들은 다양한 다중 모달 작업에서 눈에 띄는 성능 향상을 보여주었습니다. 이 단순하면서도 효과적인 전략은 일반 및 작업 지향적인 다중 모달 모델뿐 아니라, 보다 복잡한 다중 모달 작업에서도 효과성과 유연성을 입증했습니다.



### LCD-Net: A Lightweight Remote Sensing Change Detection Network Combining Feature Fusion and Gating Mechanism (https://arxiv.org/abs/2410.11580)
- **What's New**: 이번 연구에서 제안된 Lightweight Remote Sensing Change Detection Network (LCD-Net)는 원격 감지 이미지 변화 탐지 분야에서 전통적인 CNN 기반 방법의 단점을 극복하기 위해 모델 크기와 계산 비용을 줄이면서도 높은 탐지 성능을 유지하도록 설계되었습니다.

- **Technical Details**: LCD-Net은 이중 시계열(bitemporal) 이미지에서 특징을 효율적으로 추출하기 위해 MobileNetV2를 인코더로 사용합니다. 이 모델은 Temporal Interaction and Fusion Module (TIF)을 통해 이중 시계열 특징 간의 상호작용을 향상시켜 시간적인 맥락 인식(temporal context awareness)을 개선합니다. 또한, Feature Fusion Module (FFM)은 다중 스케일(features) 특징을 집계하여 미세한 변화를 포착하는 동시에 배경 노이즈를 억제합니다. 디코더에서 Gated Mechanism Module (GMM)은 채널 가중치를 동적으로 조정하여 주요 변화 영역을 강조하는 방식으로 특징 학습을 향상시킵니다.

- **Performance Highlights**: LCD-Net은 LEVIR-CD+, SYSU, S2Looking 데이터셋에서 실험한 결과, 단 2.56M의 파라미터와 4.45G FLOPs로 경쟁력 있는 성능을 달성하였으며, 자원이 제한된 환경에서 실시간 응용 프로그램에 적합한 모델임을 입증했습니다.



### STA-Unet: Rethink the semantic redundant for Medical Imaging Segmentation (https://arxiv.org/abs/2410.11578)
- **What's New**: 이 논문은 UNet 구조에 Super Token Attention(STA) 모듈을 도입하여 의학 이미지 세분화에서의 성능을 향상시키는 새로운 방법론을 제시합니다. STA는 전통적인 Transformer 기반의 UNet 아키텍처에서 관찰된 중복성을 줄이는 데 초점을 맞추었습니다.

- **Technical Details**: Super Token Attention(STA) 메커니즘은 픽셀 공간에서 슈퍼 픽셀의 개념을 토큰 공간으로 확장하여, compact visual representations으로서 슈퍼 토큰을 사용합니다. 이 방법은 이를 통해 Transformer UNet의 얕은 계층에서의 비효율적인 정보 처리 문제를 해결하고, 전반적으로 유용한 global representations을 학습하는 데 기여합니다.

- **Performance Highlights**: 실험 결과, STA-UNet은 Dice 점수 및 IOU에서 기존의 최첨단(state-of-the-art) 방법들과 비교했을 때 우수한 성능을 보여줍니다. 네 개의 공공 의료 이미지 데이터셋을 통해 검증된 결과 다양한 장기 세분화 작업에서도 뛰어난 효과를 입증했습니다.



### Multi-round jailbreak attack on large language models (https://arxiv.org/abs/2410.11533)
- **What's New**: 본 연구에서는 Large Language Model (LLM)의 jailbreaking 공격을 보다 깊이 이해하기 위해 다단계 jailbreaking 접근 방식을 제안합니다. 이 방법은 위험한 프롬프트를 재작성하고 점진적으로 덜 해로운 하위 질문으로 분해하여 LLM의 안전 점검을 우회할 수 있습니다.

- **Technical Details**: 검증된 결과를 바탕으로, 우리는 Llama3-8B 모델을 사용하여 위험한 질문들을 비위험 하위 질문으로 분리하고, 이 과정에서 LLM이 도출해낸 질문들을 피해 모델에 이어서 묻는 방식을 채택했습니다. 또한, 피해 모델이 하위 질문을 거부하는 경우 새로운 분해 작업을 생성하는 방식을 반복합니다.

- **Performance Highlights**: 실험 결과에 따르면, Llama2-7B 모델에서 94%의 성공률을 기록하여 다단계 jailbreaking 접근 방식의 효과성을 입증했습니다. 이를 통해 정적 규칙 기반 필터를 효과적으로 우회할 수 있음을 보여주었습니다.



### Offline Model-Based Optimization by Learning to Rank (https://arxiv.org/abs/2410.11502)
- **What's New**: 이번 논문에서는 전통적인 회귀 모델이 오프라인 모델 기반 최적화(offline model-based optimization)에서의 주요 목표와 잘 일치하지 않음을 주장합니다. 특히, 정확한 점수를 예측하기보다는 유망한 디자인을 선택하는 것이 중요하다는 점에 주목하고 있습니다.

- **Technical Details**: 우리는 MSE(Mean Squared Error)를 사용한 회귀 모델 훈련이 후보 디자인의 관계를 유지하는 것과 관련하여 적합하지 않음을 발견했습니다. 대신, 점수 관계를 기반으로 유망한 디자인을 우선시하는 순위 기반(ranking-based) 모델을 제안합니다. 이 모델은 학습 기반 모델을 통해 디자인의 상대적 점수를 평가합니다.

- **Performance Highlights**: 실험 결과, 순위를 유지하는 품질을 측정하는 메트릭이 강한 상관관계를 보였으며, 제안한 순위 기반 모델이 기존의 20가지 방법보다 우수한 성능을 발휘함을 입증하였습니다.



### BSM: Small but Powerful Biological Sequence Model for Genes and Proteins (https://arxiv.org/abs/2410.11499)
- **What's New**: 이번 논문은 BSM(Biological Sequence Model)이라는 혼합 모달 생물학적 시퀀스 기초 모델을 소개하며, DNA, RNA 및 단백질 데이터를 결합하여 모델이 각 유형 간의 관계를 학습할 수 있도록 해줍니다. 이 모델은 110M 파라미터로 구성되어 있으며, 단일 모달 모델보다 뛰어난 성능을 보여줍니다.

- **Technical Details**: BSM 모델은 단일 뉴클레오타이드 토크나이저를 사용하여 DNA, RNA 및 단백질과 같은 생물학적 시퀀스를 모델링합니다. 이 모델은 자기 회귀(autoregressive) 구조를 채택하여 다음 토큰 예측을 통해 시퀀스를 처리하며, 긴 범위의 의존성(long-range dependencies)을 효과적으로 처리합니다. 이 논문에서는 RefSeq, Gene 관련 시퀀스 및 웹에서 수집한 인터리브(인덱스) 생물학적 시퀀스 등 3가지 종류의 혼합 모달 데이터를 사용하여 모델을 훈련하였습니다.

- **Performance Highlights**: BSM 모델은 110M 파라미터로 구성되었음에도 불구하고 대규모 모델과 유사한 성능을 나타내며, 혼합 모달 작업에서 두드러진 몇 가지 학습 능력을 보여줍니다. 파라미터를 270M까지 확장하면 성능이 더욱 향상됩니다.



### DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG (https://arxiv.org/abs/2410.11494)
Comments:
          EMNLP 2024 Main

- **What's New**: 이 논문에서는 지속적으로 업데이트되는 지식 기반에서 새로운 언어 표현을 해결하는 새로운 작업을 제시합니다. 이를 통해 지식 집합과 함께 작동하는 retrieval-augmented generation (RAG) 시스템의 문제를 다루고 있습니다.

- **Technical Details**: DynamicER 벤치마크를 포함하며, 새로운 표현에 대한 동적 엔티티 언급 해결과 엔티티 중심의 지식 집약형 QA 작업을 평가합니다. 이는 엔티티 링크 및 RAG 모델의 새로운 표현에 대한 적응성을 측정합니다. 기존의 엔티티 링크 모델이 새로운 표현을 엔티티에 연결하는 데 어려움을 겪고 있음을 발견했습니다. 따라서 우리는 시간에 따라 세분화된 클러스터링 방법을 제안하여 진화하는 엔티티와 새로운 언급의 시간 동태를 효과적으로 관리합니다.

- **Performance Highlights**: 광범위한 실험을 통해 제안된 방법이 기존의 기준선보다 더 나은 성능을 보여주며, 해결된 언급을 사용하여 QA 작업의 RAG 모델 성능을 향상시킵니다.



### Towards Fair Graph Representation Learning in Social Networks (https://arxiv.org/abs/2410.11493)
- **What's New**: 최근 Graph Neural Networks (GNNs)의 널리 사용됨에 따라 GNN 모델의 공정성(fairness)에 대한 관심이 크게 증가했습니다. 본 연구에서는 GNN의 공정성이 떨어지는 근본적인 이유를 사회적 동질성(social homophily) 현상으로 식별하고, 이를 바탕으로 Fair 그래프 표현 학습을 위한 Equity-Aware GNN (EAGNN) 방법을 제안합니다.

- **Technical Details**: EAGNN 방법은 세 가지 원칙인 sufficiency, independence, and separation을 기반으로 하여 민감 속성(sensitive attributes)와는 독립적인 모델 예측을 보장하면서도 예측 성능을 유지하기 위한 제약조건을 도입합니다. 이론적으로 EAGNN이 그룹 공정성(group fairness)을 효과적으로 달성할 수 있음을 증명했습니다.

- **Performance Highlights**: 사회적 동질성이 다양한 세 가지 데이터셋을 대상으로 한 광범위한 실험 결과, EAGNN 방법이 두 가지 공정성 지표에서 최첨단 성능을 달성했으며, 경쟁력 있는 효과성을 제공함을 보여주었습니다.



### NavTopo: Leveraging Topological Maps For Autonomous Navigation Of a Mobile Robo (https://arxiv.org/abs/2410.11492)
Comments:
          This paper is published in proceedings of the 9th International Conference "Interactive Collaborative Robotics" (ICR 2024)

- **What's New**: 이번 논문은 모바일 로봇의 자율 내비게이션을 위한 새로운 방법론인 NavTopo를 소개합니다. 이 방법은 전통적인 매핑(method) 대신 위상(topological) 맵을 사용하여 효율성을 높였습니다.

- **Technical Details**: NavTopo는 위상 맵과 두 단계(path planning) 경로 계획을 기반으로 하며, 신경망(descriptors)과 입력 포인트 클라우드의 2D 프로젝션을 매칭하여 그래프에서 위치를 로컬라이즈합니다. 이 접근 방식은 메모리 소비를 현저하게 줄여줍니다.

- **Performance Highlights**: 실험 결과, NavTopo는 RTAB-MAP을 기반으로 한 전통적인 매트릭(metric) 매핑 접근 방식에 비해 성능이 크게 향상되었으며, 적절한 내비게이션 효율성을 유지합니다.



### CoActionGraphRec: Sequential Multi-Interest Recommendations Using Co-Action Graphs (https://arxiv.org/abs/2410.11464)
- **What's New**: 이 논문에서는 eBay와 같은 전자 상거래 플랫폼을 위한 아이템 추천 시스템 개발 시 마주하는 독특한 도전 과제를 다룹니다. 특히 데이터 희소성과 다양한 사용자 관심사를 해결하기 위한 CoActionGraphRec (CAGR) 모델을 제안합니다.

- **Technical Details**: CAGR 모델은 텍스트 기반의 두 개의 타워 구조를 가진 딥러닝 모델(Item Tower 및 User Tower)을 사용하고, 공동 행동 그래프(co-action graph) 레이어를 활용합니다. Item Tower에서는 각 아이템을 공동 행동 아이템으로 표현하여 공동 신호(collaborative signals)를 포착하고, User Tower에서는 각각의 사용자 행동 시퀀스를 나타내는 완전 연결 그래프를 구축하여 쌍 관계를 인코딩합니다. 또한, 명시적 상호작용 모듈이 행동 상호작용을 캡쳐하는 표현을 학습합니다.

- **Performance Highlights**: 광범위한 오프라인 및 온라인 A/B 테스트 실험 결과, 제안된 접근 방식이 최신 방법들에 비해 주요 지표에서 성능 개선을 보여줍니다.



### Advanced Persistent Threats (APT) Attribution Using Deep Reinforcement Learning (https://arxiv.org/abs/2410.11463)
Comments:
          21 Pages

- **What's New**: 이 연구는 Deep Reinforcement Learning (DRL)을 사용하여 특정 Advanced Persistent Threat (APT) 그룹에 악성코드를 귀속시키는 방법을 탐구합니다. 12개의 서로 다른 APT 그룹에서 3500개 이상의 악성코드 샘플을 분석하여 수행된 이 연구는 악성코드의 행동을 깊이 있는 통찰로 제공합니다.

- **Technical Details**: Cuckoo Sandbox와 같은 정교한 도구를 활용하여 행동 데이터를 추출하고, DRL 모델이 SGD, SVC, KNN, MLP 및 Decision Tree Classifier와 같은 전통적인 기계 학습 접근 방식을 능가한다는 것을 입증합니다. DRL 모델은 89.27%의 인상적인 테스트 정확도를 달성하였습니다.

- **Performance Highlights**: 이 연구는 복잡하고 변동성이 있으며 회피적인 악성코드 속성을 능숙하게 다룰 수 있는 DRL 모델의 능력을 강조합니다. 또한, 사이버 보안 프레임워크에 이러한 고급 AI 모델을 배포하는 데 필요한 상당한 계산 자원과 방대한 데이터 의존성을 논의합니다.



### LR-SQL: A Supervised Fine-Tuning Method for Text2SQL Tasks under Low-Resource Scenarios (https://arxiv.org/abs/2410.11457)
Comments:
          12pages, 4 figures,submitting to a journal

- **What's New**: LR-SQL은 데이터베이스의 복잡성으로 인한 GPU 메모리 요구량 증가 문제를 해결하기 위해 제안되었습니다. 기계 학습 모델의 세분화된 조정을 통해 더 효율적인 Text2SQL 변환을 가능하게 합니다.

- **Technical Details**: LR-SQL은 schema_link 모델과 SQL_generation 모델의 두 가지 감독적 세부 조정(supervised fine-tuning) 모델로 구성되어 있습니다. schema_link 모델은 전체 데이터베이스를 유연한 테이블 조합으로 나누어 모델이 이산 조각에서 관계를 학습할 수 있게 합니다. 또한, Chain-of-Thought 능력을 훈련시켜 다양한 조각 간의 관계 인지를 개선합니다.

- **Performance Highlights**: LR-SQL은 기존 방법에 비해 총 GPU 메모리 사용량을 40% 줄였으며, schema_link 작업에서 테이블 예측 정확도는 2% 감소했습니다. 전체 Text2SQL 작업에서는 실행 정확도(Execution Accuracy)가 0.6% 감소했습니다.



### On Championing Foundation Models: From Explainability to Interpretability (https://arxiv.org/abs/2410.11444)
Comments:
          45 pages, 14 figures

- **What's New**: 이 논문은 블랙박스 기초 모델(Foundation Models, FMs)의 내부 메커니즘을 이해하기 위한 새로운 해석 가능한 방법론을 제안합니다. 기존의 설명 가능성(explainability) 방법론에 대한 한계를 극복하고, 블랙박스 모델의 내부 작동을 명확하게 드러낼 수 있는 새로운 해석 가능한 방법들을 탐구합니다.

- **Technical Details**: 블랙박스 모델의 설명 가능성과 해석 가능성을 구분하며, 기계 학습 이론에 깊이 뿌리를 두고 있습니다. 이 연구는 대규모 언어 모델, 태스크 유형, 실험적 시나리오에 대한 분석과 더불어, FMs의 훈련 동역학(training dynamics)과 윤리적 함의(ethical implications) 등을 포함한 전반적인 해석을 제공합니다. 또한, 심층적인 해석을 통해 FMs의 이해도를 높이는 것을 목표로 합니다.

- **Performance Highlights**: 이 논문에서 제안하는 해석 가능한 방법들은 기존 방법들에 비해 신뢰성, 세부사항의 포착, 자원 요구 사항 측면에서 크게 개선되어야 하며, 기계 학습의 일반화 성능(generalization performance), 표현 능력(expressive capability), 동적 행동(dynamic behavior) 분석을 포함하여 FMs의 추론 능력과 훈련 동역학을 포괄적으로 해석합니다.



### Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs (https://arxiv.org/abs/2410.11437)
Comments:
          EMNLP 2024 Findings

- **What's New**: 본 논문에서는 멀티모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)의 시각적 질문-응답(Visual Question Answering, VQA) 문제에서 모델의 게으름(model laziness) 현상을 분석합니다. 특히, 이러한 모델이 쉬운 질문에는 오류를 범하는 경향이 있음을 밝히고 있습니다.

- **Technical Details**: 모델의 게으름을 체계적으로 조사하기 위해 LazyBench라는 벤치마크를 수동으로 구축하였으며, 이에는 예/아니오 질문, 다중 선택, 단답형 질문 및 이미지 설명 작업이 포함됩니다. LazyBench를 기반으로 한 분석 결과, 최신 MLLM 모델들(GPT-4o, Gemini-1.5-pro, Claude 3, LLaVA-v1.5-13B)에서 게으름 현상이 널리 존재하며, 이는 성능이 더 높은 모델에서 더욱 두드러지게 나타납니다.

- **Performance Highlights**: VQA v2(LLaVA-v1.5-13B) 벤치마크 분석 결과에서 약 절반의 실패 사례가 모델의 게으름으로 인해 발생한다는 것을 발견하였습니다. 이러한 결과는 모델이 자신의 능력을 충분히 활용할 수 있도록 보장하는 것이 중요함을 강조합니다. 게으름 현상을 완화하기 위한 초기 탐색을 통해 사고의 연쇄(chain of thought, CoT) 기법이 이 문제를 효과적으로 해결할 수 있음을 발견하였습니다.



### CTA-Net: A CNN-Transformer Aggregation Network for Improving Multi-Scale Feature Extraction (https://arxiv.org/abs/2410.11428)
Comments:
          9 pages, 3 figures

- **What's New**: 이번 논문에서는 CNN(Convolutional Neural Networks)과 ViT(Vision Transformers)를 통합한 새로운 아키텍처인 CTA-Net(Convolutional Transformer Aggregation Network)을 소개합니다. CTA-Net은 CNN과 ViT의 강점을 결합하여 지역적인 특징과 넓은 범위의 의존성을 효율적으로 추출합니다.

- **Technical Details**: CTA-Net은 새로운 LMF-MHSA(Light Weight Multi-Scale Feature Fusion Multi-Head Self-Attention) 모듈을 통해 다중 규모의 특징 통합을 효과적으로 수행하며, 매개변수를 줄이는 동시에 성능을 향상시킵니다. RRCV(Reverse Reconstruction CNN-Variants) 모듈은 transformer 내에서 CNN의 임베딩을 개선합니다.

- **Performance Highlights**: CTA-Net은 APTOS 2019 및 RFMiD2020 데이터셋에서 각각 TOP-1 정확도 86.76%, 20.32M의 적은 파라미터 수, 2.83B FLOPs를 기록하며, 소규모 데이터셋에서 시각적 작업에 매우 효율적이고 경량 솔루션으로서의 가능성을 보여줍니다.



### PMMT: Preference Alignment in Multilingual Machine Translation via LLM Distillation (https://arxiv.org/abs/2410.11410)
- **What's New**: 이 논문은 대규모 다국어 평행 말뭉치를 생성하는 새로운 방법을 제안하며, 이는 특정 번역 선호도에 맞추어져 있습니다. 기존의 번역 방법들이 주로 정확성에 집중한 반면, 인간의 표현 선호를 반영하는 데에는 소홀했던 문제를 해결하고자 합니다.

- **Technical Details**: 제안된 방법은 두 단계로 구성됩니다: 먼저, 여러 번역 자원을 활용하여 소규모 시드 데이터셋을 구축합니다. 이후, 이 시드 데이터를 기반으로 번역 LLM (Large Language Model)을 훈련하여 새로운 소스 텍스트로부터 후보 번역을 생성합니다. 그 다음, 작은 맞춤형 데이터셋을 이용하여 인간의 선호도에 맞은 보상 모델(RM)을 훈련시키고, 후보 번역을 선택하는 데 사용합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 특정 인간 선호가 반영된 번역 작업에서 큰 차이로 성과를 나타내었으며, WMT와 Flores와 같은 공용 벤치마크에서도 경쟁력 있는 성능을 보였습니다. 이는 사용자 맞춤형 번역 요구를 만족시키는 데에서 큰 가능성을 나타냅니다.



### Enhancing Unimodal Latent Representations in Multimodal VAEs through Iterative Amortized Inferenc (https://arxiv.org/abs/2410.11403)
Comments:
          22 pages, 12 figures

- **What's New**: 다항 모달(다양한 형태의 데이터 타입) 변분 오토인코더(VAE)에 대한 새로운 방법론을 소개합니다. 이 방법은 누락된 모달리티에 대한 정보 손실을 극복하고 추론 정확도를 개선하는 데 중점을 둡니다.

- **Technical Details**: 우리는 Multimodal Iterative Amortized Inference라는 반복적 정제 메커니즘을 제안합니다. 이 메커니즘은 Kullback-Leibler(KL) divergence를 최소화하면서 unimodal 추론 모델을 multidmodal 모델에 정렬하여 정보 손실을 줄이고 모달리티의 가용성을 최대한 활용합니다.

- **Performance Highlights**: 벤치마크 데이터셋에 대한 실험 결과, 우리의 접근 방식은 선형 분류 정확도를 높이고 경쟁력 있는 cosine similarity를 제시하며, FID 점수를 낮추어 교차 모달 생성 성능도 향상시킴을 보여주었습니다.



### Convergence to the Truth (https://arxiv.org/abs/2410.11399)
- **What's New**: 이 논문은 과학철학에서의 인식론적 전통인 수렴주의(convergentism)에 대해 검토하고 발전시키고 있으며, 이 방법론이 진리에 접근하는 능력에 기반하여 평가되어야 한다고 주장합니다.

- **Technical Details**: 수렴주의는 과학적 추론 방법을 진리에 수렴하는 능력으로 평가하는 반면, (1) 설명주의(explanationism)는 이론의 선택이 설명적 미덕의 균형에 의해 안내되어야 한다고 봅니다. (2) 도구주의(instrumentalism)는 과학적 추론이 진정한 이론이 아니라 유용한 모델을 얻는 것을 목표로 해야 한다고 입장합니다. (3) 베이지안론(Bayesianism)은 모두 혹은 전혀 신념을 갖는 것이 아니라 신념의 정도에 초점을 맞춥니다.

- **Performance Highlights**: 이 연구는 각 이론 접근 방식의 장단점을 비교하고, 수렴주의가 과학적 진리를 향한 접근의 효율성을 높일 수 있는 가능성을 평가합니다.



### Synthetic Interlocutors. Experiments with Generative AI to Prolong Ethnographic Encounters (https://arxiv.org/abs/2410.11395)
- **What's New**: 이 논문에서는 민족지학(ethnographic) 연구를 위한 '합성 대화자(Synthetic Interlocutors)'라는 개념을 소개합니다. 합성 대화자는 Retrieval Augmented Generation (RAG) 방법을 활용하여 민족지학적인 텍스트 자료(인터뷰 및 관찰)를 포함한 챗봇입니다.

- **Technical Details**: 합성 대화자는 오픈 소스 대형 언어 모델(large language model)과 민족지학 자료를 결합하여 대화를 가능하게 하는 챗봇입니다. 연구자들은 3개의 프로젝트에서 수집한 다양한 민족지학 데이터를 사용하여 실험적인 워크숍을 진행하였고, 이 과정에서 RAG가 민족지학 자료를 효과적으로 소화할 수 있다는 것을 입증했습니다.

- **Performance Highlights**: 합성 대화자는 민족지학적 상호작용을 지속하고 분석을 확장하는 데 기여할 수 있는 새로운 도구로, 연구자들은 이를 활용하여 qualitative 데이터에 대한 새로운 인사이트를 도출했습니다. 또한, 다양한 질문을 제기하고 결과를 비교 할 수 있는 영감을 주는 등 여러 혁신적인 분석 방식을 탐구할 수 있는 기회를 제공했습니다.



### Role of Delay in Brain Dynamics (https://arxiv.org/abs/2410.11384)
Comments:
          18 pages, 3 figures, 2 tables

- **What's New**: 이번 연구에서는 연결된 신경세포 간의 지연(time delay) 변동이 비동기(asynchronous) 뇌 동역학에 불리하다는 점을 극복할 수 있는 방법을 제시합니다. 즉, 단일 출력과 여러 지연을 가진 네트워크를 이용하여 전통적인 깊은 신경망(d deep learning)보다 이점을 얻을 수 있음을 보여줍니다.

- **Technical Details**: 연구는 RoDiB(Delay in brain dynamics) 모델을 제안하며, 이는 고정된 아키텍처(fixed architecture)를 사용하여 분류된 레이블(label)의 수를 늘릴 수 있는 능력을 가지고 있습니다. 또한, 이 모델은 추가적인 뉴런과 연결을 사용하여 학습 아키텍처를 업데이트하는 비유연성(inflexibility)을 극복합니다. 실험은 VGG-6 모델을 사용하여 CIFAR 데이터셋에서 수행되었으며, 다중 레이블 입력을 포함하고 있습니다.

- **Performance Highlights**: RoDiB 시스템의 정확도(accuracy)는 M 출력을 가진 조정 가능한 아키텍처와 비교할 수 있습니다. 특히, 출력 레이블 수가 입력 크기를 초과할 때 정확도가 크게 향상됩니다. 그러나 현재 RoDiB 출력의 일부만 사용되고 있어 향후 잠재적인 계산 능력이 발견될 가능성이 높습니다.



### WPFed: Web-based Personalized Federation for Decentralized Systems (https://arxiv.org/abs/2410.11378)
- **What's New**: 이번 논문에서는 WPFed라는 완전 분산형 웹 기반 학습 프레임워크를 소개합니다. 이 프레임워크는 최적의 이웃 선택을 통해 사용자 데이터 프라이버시를 유지하면서도 효과적인 협업을 가능하게 합니다.

- **Technical Details**: WPFed는 동적 통신 그래프와 가중치 기반 이웃 선택 메커니즘을 사용하여 Locality-Sensitive Hashing (LSH)를 통해 클라이언트 간 유사성을 평가하고, 모델 품질을 동료 순위를 기반으로 평가합니다. 각 클라이언트는 LSH 코드를 생성하며, P2P 통신을 통해 유사성을 계산할 수 있습니다.

- **Performance Highlights**: 다양한 실제 데이터셋에 대한 실험 결과, WPFed는 전통적인 연합 학습 방법에 비해 학습 성과와 시스템 견고성을 유의미하게 향상시켰습니다. 이는 다양한 웹 환경에서 안전하고 효율적인 분산 협업 학습을 촉진할 수 있는 잠재력을 보입니다.



### Augmentation-Driven Metric for Balancing Preservation and Modification in Text-Guided Image Editing (https://arxiv.org/abs/2410.11374)
Comments:
          Under review

- **What's New**: 이 논문은 CLIPScore의 한계를 지적하고, 텍스트에 기반한 이미지 편집을 위한 새로운 평가 지표인 AugCLIP을 제안합니다. AugCLIP은 이미지의 핵심 속성을 보존하면서 텍스트에 맞춰 수정을 최적화합니다.

- **Technical Details**: AugCLIP은 대형 언어 모델(large language model)을 활용하여 소스 이미지와 타겟 텍스트에 대한 상세 설명을 증강하고, CLIP 공간에서 소스와 타켓을 분리하는 하이퍼플레인을 모델링합니다. 이 모델은 이상적인 편집 이미지의 표현을 소스 이미지의 직교 투영으로 추정하며, 각 속성의 상호 종속성을 고려하여 상대적 중요성을 평가합니다.

- **Performance Highlights**: 여러 편집 시나리오에 대해 AugCLIP은 기존 지표보다 인간 평가 기준과의 정렬이 상당히 높음을 보여줍니다. 특히, AugCLIP은 개인화한 생성 및 복잡한 이미지 편집 시나리오에서의 작은 차이 식별에 뛰어난 성능을 보입니다.



### Reducing Labeling Costs in Sentiment Analysis via Semi-Supervised Learning (https://arxiv.org/abs/2410.11355)
Comments:
          12 pages, 7 figures, accepted at the 2024 8th International Conference on Natural Language Processing and Information Retrieval (NLPIR 2024), Okayama, Japan, 2024

- **What's New**: 이 연구는 기계 학습에서 데이터 레이블링의 효율성을 높이는 새로운 접근 방식을 제시합니다. 전통적인 방법에 비해 레이블의 수를 크게 줄일 수 있는 반지도 학습(semi-supervised learning)에서의 레이블 전파(label propagation)를 탐구하고 있습니다.

- **Technical Details**: 본 연구에서는 텍스트 분류를 위한 매니폴드 가정(manifold assumption)을 기반으로 한 전이식 레이블 전파(transductive label propagation) 방법을 사용합니다. 그래프 기반(graph-based) 방법을 활용하여 레이블이 없는 데이터에 대한 유사 레이블(pseudo-labels)을 생성하고, 이를 통해 깊은 신경망(deep neural networks)을 학습합니다.

- **Performance Highlights**: 본 연구는 감정 분석(sentiment analysis) 분야에 대한 실험을 통해 레이블 전파의 효과성을 평가하며, 기존의 레이블링 방법에 비해 성능이 비슷한 결과를 얻을 수 있음을 보이고 있습니다.



### RATE: Score Reward Models with Imperfect Rewrites of Rewrites (https://arxiv.org/abs/2410.11348)
Comments:
          Submitted as a conference paper to ICLR 2025. Code is available at this https URL

- **What's New**: 이 논문은 언어 모델링에서 사용되는 보상 모델의 평가 방법인 RATE(Rewrite-based Attribute Treatment Estimators)를 개발했습니다. 이 방법은 응답의 특정 속성이 보상에 미치는 인과관계를 측정할 수 있게 해줍니다.

- **Technical Details**: RATE는 큰 언어 모델을 사용하여 응답을 재작성(rewrite)하고, 재작성 오류를 보정하기 위해 두 번 재작성하는 방식을 사용합니다. 이 방법은 비대칭 재작성에서도 신뢰할 수 있는 인과적인 보상 변화를 추정할 수 있습니다.

- **Performance Highlights**: RATE 평가 방법은 합성 및 실제 데이터에서 효과적임을 보여줍니다. 이 방법은 비인과성 상관관계를 교정할 수 있고, 보상 모델을 평가할 때 이러한 교정이 중요함을 실증적으로 입증했습니다.



### DIAR: Diffusion-model-guided Implicit Q-learning with Adaptive Revaluation (https://arxiv.org/abs/2410.11338)
Comments:
          Preprint, under review. Comments welcome

- **What's New**: 새로운 오프라인 강화 학습 방법론인 DIAR(Diffusion-model-guided Implicit Q-learning with Adaptive Revaluation) 프레임워크를 소개합니다. 이 프레임워크는 오프라인 RL의 두 가지 주요 도전 과제인 out-of-distribution 샘플과 긴 지평선(long-horizon) 문제를 해결합니다.

- **Technical Details**: DIAR는 상태-동작(state-action) 시퀀스 분포를 학습하기 위해 확산 모델(diffusion models)을 활용하고, 의사결정을 보다 균형있고 적응적으로 만들어주는 가치 함수(value functions)를 통합합니다. Adaptive Revaluation 메커니즘을 통해 현재 및 미래 상태 값을 비교하여 결정 길이를 동적으로 조정하여 유연한 장기적 의사결정(long-term decision-making)을 가능하게 합니다. Q 함수의 과대 평가 문제는 Q 네트워크 학습을 확산 모델로 안내된 가치 함수와 결합함으로써 해결됩니다.

- **Performance Highlights**: DIAR는 Maze2D, AntMaze 및 Kitchen과 같은 복잡한 경로 계획을 포함하는 긴 지평선(sparse-reward) 환경에서 기존 오프라인 강화 학습 알고리즘보다 뛰어난 성능을 보여주었습니다. 특히, DIAR는 이러한 환경에서 최첨단 성능을 달성하는 것으로 입증되었습니다.



### Sequential LLM Framework for Fashion Recommendation (https://arxiv.org/abs/2410.11327)
- **What's New**: 이 논문은 패션 산업에 최적화된 추천 시스템을 제안하며, 선행 학습된 대형 언어 모델(LLM)을 활용하여 추천 성능을 향상시키는 방법을 제시합니다.

- **Technical Details**: 제안된 프레임워크는 세 가지 주요 단계로 이루어져 있습니다: 첫째, 추천 목표에 맞춘 전문 프롬프트를 설계하는 프롬프트 엔지니어링 기술을 사용합니다. 둘째, 비용이 많이 드는 훈련 비용을 줄이기 위해 Parameter-Efficient Fine-Tuning (PEFT) 기술을 적용합니다. 마지막으로, 예측된 제품 제목 및 ID를 활용하여 관련 후보 항목을 검색하고 순위를 매기는 mix-up 기반 검색 기술을 사용합니다.

- **Performance Highlights**: 실험 결과, 제안된 프레임워크는 패션 추천 성능을 현저히 향상시켰다고 합니다. 특히, 기존의 패션 추천 시스템보다 효과적으로 사용자 선호도를 파악하고, 콜드 스타트 문제를 극복하는 데 기여했습니다.



### Speculative Knowledge Distillation: Bridging the Teacher-Student Gap Through Interleaved Sampling (https://arxiv.org/abs/2410.11325)
- **What's New**: 최근의 연구에서 Knowledge Distillation (KB) 기술이 작고 효율적인 모델들이 대형 모델과 유사한 성능을 낼 수 있도록 발전했습니다. 본 논문에서는 Speculative Knowledge Distillation (SKD)라는 새로운 방식을 제안합니다. SKD는 학생 모델과 교사 모델 간의 협력을 통해 고품질의 훈련 데이터를 실시간으로 생성하는 방식을 사용합니다.

- **Technical Details**: SKD는 학생 모델이 제안하는 토큰에서 품질이 낮은 것을 교사 모델의 분포에 근거하여 교체하는 프로세스를 가지고 있습니다. 이 방법은 교사 모델이 생성할 가능성이 낮은 토큰을 필터링하고, 대신 교사 모델에서 재 샘플링하는 방식을 사용합니다. SKD는 초기 훈련 단계에서는 기존의 Supervised KD와 유사하게 작동하다가, 학생 모델의 성능이 향상됨에 따라 On-policy KD와 비슷한 방식으로 동작합니다.

- **Performance Highlights**: SKD는 다양한 텍스트 생성 작업에서 기존의 KD 방법들보다 뛰어난 성능을 보였습니다. 예를 들어, Gemma-7B를 Gemma-2B로 증류하는 과정에서 저자원 기계 번역에서 41.8%, 요약에서 230%, 산술적 추론에서 160%의 성능 향상을 기록했습니다. 또한, SKD가 MATH 및 GSMplus 테스트에서 각각 198% 및 360%의 성과를 달성했습니다.



### Towards Differentiable Multilevel Optimization: A Gradient-Based Approach (https://arxiv.org/abs/2410.11312)
Comments:
          18 pages

- **What's New**: 본 논문은 다단계 최적화(multilevel optimization)를 위한 새로운 기법인 계층 구조의 그래디언트(decomposition of the full gradient)를 활용한 기법을 소개합니다. 이 접근 방식은 기존의 방법들의 한계를 극복하며, n단계 시나리오로 확장할 수 있습니다.

- **Technical Details**: 제안된 방법은 다단계 최적화에서의 수렴(convergence) 보장을 위한 이론적 근거를 포함하고 있으며, 기존의 방법들과 비교하여 훨씬 더 낮은 계산 복잡성을 자랑합니다. 이 알고리즘은 Hessian matrix의 유계성(boundness) 전제 하에 𝒪(1/N) 수렴 속도를 달성합니다.

- **Performance Highlights**: 수치 실험의 결과, 제안된 방법은 기존의 ITD(Iterative Differentiation) 방법에 비해 3.3배 더 빠른 속도를 보여주었으며, 더 나은 수렴 결과를 보였습니다. 이는 이론적 보장과 우수한 실험적 성능을 모두 충족하는 혁신적인 접근법으로 평가됩니다.



### QSpec: Speculative Decoding with Complementary Quantization Schemes (https://arxiv.org/abs/2410.11305)
- **What's New**: 본 논문에서는 다단계 추론(task)에서의 성능 저하 문제를 해결하기 위해 새로운 양자화 paradigm인 QSPEC을 제안합니다. 이는 서로 다른 두 가지 양자화 기법을 결합하여 효과성을 유지하면서도 효율성을 극대화합니다.

- **Technical Details**: QSPEC은 낮은 정밀도의 활성화-가중치 양자화(low-precision activation-weight quantization)와 높은 정밀도의 가중치 전용 양자화(high-precision weight-only quantization)를 통합합니다. 이 방법을 통해 낮은 비용으로 실행을 전환하며, W4A4와 W4A16 방식을 통해 고품질의 토큰을 생성합니다.

- **Performance Highlights**: QSPEC은 기존의 양자화 방법 대비 토큰 생성 속도를 최대 1.80배 높이며, 메모리 소비를 유지하면서도 양질의 성능을 제공합니다. 다단계 추론 작업에서 W4A4 방식보다 최대 51.11% 향상된 품질을 보였습니다.



### Data Selection for Task-Specific Model Finetuning (https://arxiv.org/abs/2410.11303)
Comments:
          31 pages, 1 figure

- **What's New**: 본 논문은 특정 작업에 대한 foundation model의 finetuning을 위한 최적 데이터 선택 프레임워크를 제안합니다.

- **Technical Details**: 데이터 선택 문제를 최적 운송(optimal transport)을 기반으로 하는 최적화 문제로 공식화했습니다. 선택된 데이터의 분포는 목표 작업에서 제공된 대표 사례의 분포와 일치해야 하며, 이 과정에서 다양성을 촉진하기 위한 정규화 항이 추가되었습니다.

- **Performance Highlights**: 제안된 방법은 언어 모델의 instruction tuning에서 1%의 데이터 선택 비율로 F1 점수 기준으로 평균 1.5점 더 높은 성능을 보였고, domain-specific 데이터 선택에서도 최대 3 F1 점수 개선을 나타냈습니다.



### Have the VLMs Lost Confidence? A Study of Sycophancy in VLMs (https://arxiv.org/abs/2410.11302)
- **What's New**: 이번 연구에서는 LLMs(대형 언어 모델)의 시코팬시(sycophancy) 문제를 VLMs(비주얼 언어 모델)로 확장하여 다루었습니다. 특히, VLMs에서 시코팬시에 대한 연구가 부족하다는 점을 강조하며, 새로운 MM-SY 벤치마크를 도입했습니다.

- **Technical Details**: 시코팬시(sycophancy)는 LLMs가 원래의 올바른 응답을 따르지 않고 사용자 의견에 무비판적으로 동의하는 현상을 말합니다. 본 연구에서는 시코팬시를 완화하기 위한 합성 데이터셋(synthetic dataset)을 제안하고, 프롬프트(prompts), 감독된 미세 조정(supervised fine-tuning), DPO(Deep Prompting Optimization) 기반의 방법들을 사용하여 효과적으로 문제를 해결하였습니다. 또한, VLMs의 시코팬시가 의미론적(semiotic)으로 미치는 영향을 평가하기 위해 주목(attention) 분포를 분석했습니다.

- **Performance Highlights**: 실험 결과, 상위 레이어에서의 시코팬시 예방 능력이 두드러지며, 상위 레이어에서의 이미지(attention) 지식 부족이 시코팬시에 기여하고 있음을 확인했습니다. 이에 따라, 고급 레이어에서의 이미지 주목(attention)을 향상시키는 것이 시코팬시 문제를 완화하는 데 유용하다는 결과를 얻었습니다.



### Sorted Weight Sectioning for Energy-Efficient Unstructured Sparse DNNs on Compute-in-Memory Crossbars (https://arxiv.org/abs/2410.11298)
Comments:
          5 pages, 4 figures

- **What's New**: 본 논문에서는 $	extit{sorted weight sectioning}$ (SWS)라는 새로운 가중치 할당 알고리즘을 소개합니다. SWS는 정렬된 DNN(Deep Neural Network) 가중치 섹션을 비트 슬라이스 컴퓨트 인 메모리(CIM) 크로스바에 배치하여 아날로그-디지털 변환기(ADC) 에너지 소비를 줄이는 것입니다.

- **Technical Details**: SWS는 DNN의 특징인 벨 모양의 분포와 가중치 희소성(weight sparsity)을 활용하여 저전력 크로스바 열에 소형 가중치를 매핑합니다. 각 섹션은 무게 값을 갖는 행으로 부분화되고, 이 방식은 ADC 사용을 세밀하게 제어하여 에너지 효율성을 높입니다. 이 방법은 정렬된 가중치에 기초한 매핑 및 퍼뮤테이션(permutation) 전략을 통해 구현됩니다.

- **Performance Highlights**: SWS는 비구조적 희소 BERT 모델의 ADC 에너지 소비를 89.5%까지 줄였습니다. 이를 통해 저전력 DNN 작업에 최적화된 CIM 아키텍처를 구현하는 새로운 알고리즘을 소개합니다.



### TraM : Enhancing User Sleep Prediction with Transformer-based Multivariate Time Series Modeling and Machine Learning Ensembles (https://arxiv.org/abs/2410.11293)
- **What's New**: 이 논문은 Transformer 기반의 다변량 시계열 모델과 머신러닝 앙상블(Machine Learning Ensembles)을 활용하여 인간의 수면 질, 감정 상태 및 스트레스 수준을 예측하는 새로운 접근 방식을 제안합니다. 연구에서는 사용자 데이터를 바탕으로 여러 모델이 적용되었고, Time Series Transformer는 시계열 특성이 중요한 레이블에 사용되었습니다.

- **Technical Details**: 제안된 모델인 TraM은 전이 학습에 의해 시계열 특성을 잘 포착할 수 있도록 설계된 Time Series Transformer(TST)와 다양한 일일 활동 통계를 요구하는 레이블에 대해 머신 러닝 앙상블을 활용합니다. 이 모델은 사용자 응답을 기반으로 역사적인 시계열 데이터를 통해 레이블을 계산하는 방법을 포함하며, 결측값 처리, 데이터 정규화 및 다변량 시계열 데이터의 시간적 정렬을 위한 메소드들이 구현되었습니다.

- **Performance Highlights**: TraM 모델은 실험에서 10점 만점에 6.10점을 기록하여 다른 방법론에 비해 우수한 성능을 보여주었습니다. 연구는 수면 질 개선을 위한 개인화된 솔루션을 제시하며, 공공 건강 이니셔티브 및 개인 웰빙 계획에 수면 건강을 우선시해야 한다는 점을 강조하고 있습니다.



### Enhancing Assamese NLP Capabilities: Introducing a Centralized Dataset Repository (https://arxiv.org/abs/2410.11291)
Comments:
          6 pages, 1 table, 1 figure

- **What's New**: 이 논문은 저자들이 아삼어(NLT) 및 NMT(Natural Machine Translation)를 위한 중앙집중식 오픈 소스 데이터셋 저장소를 설계하여 소개합니다. 이 저장소는 GitHub에서 제공되며, 감정 분석(sentiment analysis), 개체 인식(named entity recognition), 기계 번역 등의 다양한 작업을 지원합니다.

- **Technical Details**: 이 데이터셋은 두 가지 유형으로 나뉘며, 사전 훈련(pre-training) 및 후 훈련(post-training)에 사용되는 코퍼스가 포함되어 있습니다. 예를 들어, Wikipedia 데이터셋, CC100 코퍼스, C4 다국어 데이터셋 등을 포함하고 있으며, 이들은 아삼어 모델 훈련에 도용될 수 있습니다. 또한, ChatGPT에 의해 생성된 데이터셋도 포함되어 있습니다.

- **Performance Highlights**: 이 저장소는 아삼어 연구에 있어 협업과 혁신을 촉진합니다. 향후 연구는 NMT 모델에 대한 새로운 응용 프로그램, 이미지 캡셔닝(image captioning), AI 기반 챗봇 개발 등을 포함할 수 있습니다. 데이터의 제한 사항에도 불구하고, 아삼어에 대한 NLP 연구의 디지털 시대에서의 지속 가능성을 보여줍니다.



### Backdoor Attack on Vertical Federated Graph Neural Network Learning (https://arxiv.org/abs/2410.11290)
- **What's New**: 본 논문은 Vertical Federated Graph Neural Network (VFGNN)에 대한 최초의 백도어 공격 방법인 BVG를 제안합니다. BVG는 레이블에 접근하거나 수정하지 않고, 다중 홉 트리거를 사용하여 효과적인 백도어 공격을 수행할 수 있게 설계되었습니다.

- **Technical Details**: VFGNN은 데이터 기능과 레이블이 참여자들 간에 분산되어 있으며, 각 참여자는 동일한 샘플 공간을 가집니다. BVG는 그래프 구조를 기반으로 다중 홉 트리거를 생성하므로, 특정 클래스 노드 4개만 알고 있으면 높은 공격 성공률(ASR)을 달성할 수 있습니다.

- **Performance Highlights**: 실험 결과 BVG는 세 가지 데이터 세트와 세 가지 서로 다른 GNN 모델에서 높은 공격 성공률을 기록하였으며, 주요 작업 정확도(MTA)에 미치는 영향은 최소화되었습니다. 또한 여러 방어 방법을 평가하여 BVG의 견고성과 효율성을 검증하였습니다.



### Process Reward Model with Q-Value Rankings (https://arxiv.org/abs/2410.11287)
- **What's New**: 본 논문에서는 기존의 Process Reward Modeling (PRM) 방식을 개선하기 위해 Process Q-value Model (PQM)이라는 새로운 프레임워크를 제안합니다. PQM은 Q-value 순위 매기기 문제로 PRM을 재정의하고, 각 단계 간의 상호 의존성을 보다 효과적으로 캡처합니다.

- **Technical Details**: PQM 모델은 Markov Decision Process (MDP) 맥락에서 PRM을 최적화하며, 새로운 비교 손실 함수(comparative loss function)를 기반으로 Q-value 순위를 최적화합니다. 이로 인해 각 단계의 기여도를 보다 세분화하여 평가할 수 있게 됩니다.

- **Performance Highlights**: PQM은 다양한 샘플링 정책(sampling policies), 언어 모델 백본(language model backbones), 그리고 다단계 추론(multi-step reasoning) 벤치마크에서 기존의 분류 기반 PRM에 비해 우수한 성능을 보였습니다. 예를 들어, Llama-3-70B-Instruct 모델에서 샘플링한 솔루션의 정확도가 39.8%에서 51.4%로 개선되었으며, 이는 MATH500 벤치마크에서 직접적인 11.6% 향상을 나타냅니다.



### Advancing the Understanding of Fixed Point Iterations in Deep Neural Networks: A Detailed Analytical Study (https://arxiv.org/abs/2410.11279)
- **What's New**: 최근 심층 신경망에서 고정점(iteration) 현상이 발견되었으며, 이는 숨겨진 상태가 여러 레이어(layer) 후 안정되며 이후 레이어에서 변화가 최소화됨을 보여줍니다. 이를 통해 신경망의 레이어를 우회하여 추론을 가속화하고 특정 레이어를 선택적으로 미세 조정할 수 있는 새로운 방법론이 개발되었습니다.

- **Technical Details**: 이 연구에서는 벡터 값 함수(ℝd→ℝd)의 고정점(iteration)을 심층적으로 분석하였으며, 다양한 입력 영역(input regions)에 따라 루프된 신경망(looped neural networks)의 여러 고정점 존재성을 나타내는 충분 조건을 확립하였습니다. 또한, 각 고정점 반복(iteration)에서 노이즈(noise)를 도입하여 고정점 반복 과정이 노이즈 아래에서도 견고함을 보여주었습니다.

- **Performance Highlights**: 사례 연구를 통해 루프된 신경망이 다항식(Polynomial) 또는 지수(Exponential) 활성화 함수 아래에 2^d 수의 견고한 고정점이 존재할 수 있음을 입증하였습니다. 초기 경험적 결과도 이론적 발견을 지원합니다.



### ILAEDA: An Imitation Learning Based Approach for Automatic Exploratory Data Analysis (https://arxiv.org/abs/2410.11276)
Comments:
          Accepted at AIMLSystems '24

- **What's New**: 본 연구는 AutoEDA(자동 탐색적 데이터 분석)의 새로운 접근 방식을 제안합니다. 기존의 보상 구조 기반 방법 대신, 전문가의 EDA 세션을 모방하여 훈련하는 ILAEDA라는 프레임워크를 도입합니다. 이 방법은 수작업으로 보상 함수 정의를 필요로 하지 않으며, 데이터셋에 따라 다르게 분석할 필요가 없습니다.

- **Technical Details**: ILAEDA는 Generative Adversarial Imitation Learning (GAIL)을 기반으로 하여 전문가 세션으로부터 직접 학습합니다. 이로 인해 모델은 데이터셋에 대한 일반화 능력을 향상시킬 수 있습니다. 본 연구에서는 합성 EDA 시연을 자동으로 생성하는 새로운 방법을 소개하여 훈련 데이터 접근 방식을 개선합니다.

- **Performance Highlights**: ILAEDA는 기존의 최첨단 EDA 접근 방식에서 최대 3배 더 뛰어난 성능을 보였습니다. 이 모델은 다양한 EDA 세션의 흥미로운 측면을 자연스럽게 포착함으로써, EDA 세션의 다양성, 일관성 및 가독성을 높이고 있습니다.



### Bypassing the Exponential Dependency: Looped Transformers Efficiently Learn In-context by Multi-step Gradient Descen (https://arxiv.org/abs/2410.11268)
- **What's New**: 이번 연구에서는 선형 루프형 변환기(linear looped Transformer)가 인-context 학습(in-context learning)에서 다단계 경량 하강법(multi-step gradient descent)을 효율적으로 실행할 수 있음을 보여준다. 이 논문은 변환기 아키텍처가 예상보다 강력한 인-context 학습 기능을 가지고 있음을 시사한다.

- **Technical Details**: 연구진은 linear looped Transformers가 잘 조건화된 인-context 예제(num_context_examples)가 있는 경우에 한하여, 다단계 경량 하강법을 효과적으로 수행할 수 있음을 수학적으로 입증하였다. 조건 숫자(condition number)가 일정할 경우, 적은 수의 인-context 예제(n = O(d))로도 상대적으로 낮은 오류를 달성할 수 있다는 결과를 설명한다.

- **Performance Highlights**: 예비 실험 결과(MILD)에서 linear looped Transformer는 T번의 루프(iteration) 후에 오류가 기하급수적으로 감소한다는 것을 발견하였다. 이 연구는 대규모 언어 모델의 효율적인 추론 알고리즘 설계에 기여할 수 있는 새로운 통찰력을 제공한다.



### FedCCRL: Federated Domain Generalization with Cross-Client Representation Learning (https://arxiv.org/abs/2410.11267)
- **What's New**: 본 논문은 Federated Learning (FL) 환경에서의 Domain Generalization (DG) 문제를 해결하기 위해 FedCCRL이라는 새로운 방법론을 제안합니다.

- **Technical Details**: FedCCRL은 MixStyle을 federated 환경에 적응시켜 도메인 특화된 피쳐를 전송하며, AugMix를 사용하여 도메인 불변 특성을 교란합니다. 또한, 응답 정렬을 위해 supervised contrastive loss를 활용하고, 원본 샘플과 증강 샘플 간의 일관된 예측을 보장하기 위해 Jensen-Shannon divergence를 사용합니다.

- **Performance Highlights**: FedCCRL은 PACS, OfficeHome, 및 miniDomainNet 데이터셋에서 다양한 클라이언트 수에 대해 최첨단 성능을 달성함을 실험적으로 입증하였습니다.



### In-Context Learning for Long-Context Sentiment Analysis on Infrastructure Project Opinions (https://arxiv.org/abs/2410.11265)
- **What's New**: 이번 연구는 GPT-4o, Claude 3.5 Sonnet, Gemini 1.5 Pro 등 세 가지 주요 대형 언어 모델(LLMs)의 성능을 장기적이고 복잡한 의견이 상이한 문서에 대해 평가하였습니다.

- **Technical Details**: 연구에서는 제로샷(zero-shot)과 몇 샷(few-shot) 시나리오에서 인프라 프로젝트와 관련된 긴 문서들을 분석했습니다. 각 모델의 성능을 비교하는 데 있어 다양한 문서의 복잡성과 감정의 변동성을 고려했습니다.

- **Performance Highlights**: 결과적으로 GPT-4o는 간단하고 짧은 문서에서 제로샷 시나리오에서 뛰어난 성능을 보였으나, Claude 3.5 Sonnet는 복잡한 문서와 감정 변동이 있는 상황에서 더 우수한 성능을 나타냈습니다. 몇 샷 시나리오에서는 Claude 3.5 Sonnet이 전반적으로 뛰어난 성과를 보였고, GPT-4o는 시연 횟수가 증가함에 따라 더 큰 안정성을 보였습니다.



### Unveiling Options with Neural Decomposition (https://arxiv.org/abs/2410.11262)
Comments:
          Published as a conference paper at ICLR 2024

- **What's New**: 본 논문에서는 강화 학습에서 에이전트가 특정 작업에 대한 정책을 학습할 수 있지만, 관련 작업에 대한 지식을 일반화하지 못하는 한계를 극복하기 위한 알고리즘을 소개합니다. 이 알고리즘은 마르코프 결정 프로세스(Markov Decision Processes, MDPs)를 위한 정책을 인코딩하는 신경망을 재사용 가능한 서브 정책(sub-policy)으로 분해하여 시간적으로 확장된 행동(옵션, options)을 합성합니다.

- **Technical Details**: 우리는 조각별 선형 활성화 함수(piecewise linear activation functions)를 사용하는 신경망을 고려합니다. 이 네트워크를 비 oblique 결정 트리(oblique decision trees)와 유사한 구조인 신경 트리(neural tree)로 매핑합니다. 각 내부 노드는 네트워크의 입력에 대한 함수 역할을 하며, 리프 노드는 네트워크의 전체 출력 레이어를 나타냅니다. 또한, 서브 정책을 다양한 반복 횟수의 while 루프로 감싸서 옵션으로 변환합니다. 기계 학습을 통해 레빈 손실(Levin loss)을 최소화하는 선택 메커니즘을 제안합니다.

- **Performance Highlights**: 실험 결과, 옵션을 생성하는 기존 기준선을 초과하여 우리 방법이 유용한 옵션을 식별하고 유사하지만 다른 작업에서 학습 과정을 가속화할 수 있음을 확인했습니다. 특히, 우리가 추출한 옵션은 특정 작업을 위한 옵션을 학습하는 세 가지 방법보다도 더 효과적이었습니다. 논문은 기존 정책으로부터 의도하지 않게 추출한 옵션을 학습하는 새로운 접근 방식을 제공합니다.



### Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix (https://arxiv.org/abs/2410.11261)
- **What's New**: 이 논문은 대형 언어 모델(LLM)의 가중치 가지치기를 위한 새로운 접근 방식을 제안합니다. 기존의 선형 근사를 사용하는 방법과 달리, 이 연구는 Softmax 주의 메커니즘의 비선형성을 고려하여 주의 행렬을 근사화하는 방법을 다룹니다.

- **Technical Details**: 주요 기술적 기법은 Gradient Descent 기반의 최적화 방법을 통해 주의 행렬에 대한 가지치기 마스크를 직접 계산하는 것입니다. 이 접근법은 효과적인 가지치기 마스크 솔루션으로 수렴할 수 있도록 보장하는 이론적 근거를 제공합니다.

- **Performance Highlights**: 예비 실험 결과, 이 방법은 모델 성능을 유지하면서도 계산 비용을 상당히 줄이는 효과를 보여주었습니다. 이 연구는 자원이 제한된 장치에서의 더 효율적인 LLM 추론을 위한 새로운 이론적 기초를 세우는 데 기여하고 있습니다.



### Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models (https://arxiv.org/abs/2410.11242)
- **What's New**: 이번 연구에서는 VHExpansion을 도입하여 시각적 환각(Visual Hallucination, VH) 테스트 케이스를 자동으로 확장할 수 있는 최초의 방법을 제안합니다. 기존 방법들은 인간의 주석에 의존하여 VH 테스트 케이스를 생성했으나, VHExpansion은 질문과 답변의 부정, 이미지의 일반적 및 적대적 변형을 통해 테스트 케이스를 자동으로 확장합니다.

- **Technical Details**: VHExpansion은 초기 VH 테스트 케이스를 기반으로 하여 질문과 답변을 부정(non-affirmation)으로 변경하고, 이미지에 일반적인 이미지 처리(예: JPEG 압축, 가우시안 노이즈) 및 적대적 이미지 변형을 추가하여 새로운 VH 테스트 케이스를 생성합니다. 또한, 대칭 정확도(symmetric accuracy)라는 새로운 평가 지표를 제안하여 각 테스트 케이스와 그 부정된 대응물의 올바른 응답 비율을 측정합니다.

- **Performance Highlights**: VHExpansion을 사용하여 수동으로 주석이 달린 세 개의 VH 데이터셋을 확장한 결과, 기존 MLLM 모델보다 VH 테스트 케이스를 더 많이 식별했습니다. 대칭 정확도는 기존의 정확도와 다른 결론을 도출하며, MLLM을 VHExpansion으로 생성된 확장된 VH 데이터셋으로 미세 조정한 결과 VH를 효과적으로 줄일 수 있음을 보여주었습니다.



### HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications (https://arxiv.org/abs/2410.11239)
- **What's New**: 이 논문에서는 HR 관련 수백 개의 반복적 프로세스를 자동화하기 위해 HR-Agent라는 HR 전용 LLM(대형 언어 모델) 기반 대화 시스템을 개발했다고 보고하고 있습니다. 이 시스템은 의료 청구, 접근 요청과 같은 HR 프로세스의 효율성을 높일 수 있도록 설계되었습니다.

- **Technical Details**: HR-Agent는 대화 상태 추적(DST) 기술을 활용하여 대화 중 사용자 의도 및 세부 사항을 모니터링하고 예측합니다. 이 시스템은 신속한 응답 시간, 신뢰성 있는 정보 추출, 다양한 HR 용도 처리, 기밀성 유지 및 HR 특화의 요구 사항을 충족합니다. 대화 데이터는 추론 과정 중 LLM으로 전송되지 않아 기밀성이 유지됩니다.

- **Performance Highlights**: HR-Agent는 더 큰 언어 모델과 비교하여 더 작고 빠르면서도 뛰어난 성능을 발휘합니다. 이 시스템은 휴먼 리소스 프로세스의 효율성을 크게 향상시킵니다.



### Bayes Adaptive Monte Carlo Tree Search for Offline Model-based Reinforcement Learning (https://arxiv.org/abs/2410.11234)
- **What's New**: 본 논문에서는 오프라인 모델 기반 강화 학습(offline MBRL)을 베이즈 적응 마르코프 결정 프로세스(BAMDP)로 모델링하여 모델의 불확실성을 다루는 새로운 방법론을 제안합니다.

- **Technical Details**: BAMDP를 사용하면 다양한 MDP가 동일한 상태 및 행동에서 동일하게 작동할 수 있지만, 그 동역학(dynamics) 및 보상 함수(reward function)는 다를 수 있으므로, Bayesian posterior 업데이트를 이용해 딥 앙상블(deep ensembles)을 통해 효율적으로 시뮬레이션할 수 있습니다. 또한, 기존의 BAMCP(Bayes Adaptive Monte Carlo Planning) 알고리즘의 제약을 극복하기 위해, 보상 패널티를 사용하여 비관적 BAMDP를 구성하고 연속 상태 및 행동 공간에서 BAMDP 문제를 해결하는 새로운 계획 알고리즘을 제안합니다.

- **Performance Highlights**: 제안된 알고리즘은 12개의 D4RL MuJoCo 벤치마크 작업과 3개의 목표 추적 작업에서 기존의 최첨단 모델 기반 및 모델 프리 오프라인 강화 학습 방법보다 상당한 성능 향상을 보여주었습니다.



### Multi-objective Reinforcement Learning: A Tool for Pluralistic Alignmen (https://arxiv.org/abs/2410.11221)
Comments:
          Accepted for the Pluralistic Alignment workshop at NeurIPS 2024. this https URL

- **What's New**: 이 논문에서는 다중 목표 강화 학습(MORL)을 통해 다양한 이해관계자를 만족시키는 AI 시스템의 설계를 가능하게 하는 방법에 대해 논의합니다. 구체적으로는 MORL이 종합적으로 정렬된 AI를 생성하는 데 어떻게 기여할 수 있는지를 설명합니다.

- **Technical Details**: MORL 방법론은 환경을 Multi-objective Markov Decision Process (MOMDP)로 모델링하며, 벡터 보상 함수를 사용하여 여러 목표를 동시에 고려합니다. 이는 각 목표를 개별적으로 최적화할 수 있게 하며, 비선형 유틸리티 함수(u)가 사용되어 보다 정확한 이해관계자의 선호를 반영합니다.

- **Performance Highlights**: MORL은 성능과 안전성 간의 균형을 유지하며, 다양한 사용자 선호를 반영하여 AI 시스템의 실행 정책을 동적으로 조정할 수 있는 이점이 있습니다. 이 방식은 특히 대형 언어 모델(LLMs)의 조정에 효과적이며, 여러 목표 간의 거래를 촉진할 수 있습니다.



### On the Capacity of Citation Generation by Large Language Models (https://arxiv.org/abs/2410.11217)
Comments:
          Accepted by CCIR 2024

- **What's New**: 이번 연구는 대형 언어 모델(LLMs)이 생성하는 응답 내 인용 생성 능력에 대한 체계적 분석을 실시하고, 인용 품질을 향상시키기 위한 새로운 방법을 제시합니다. 주된 초점은 기존 연구들이 응답의 정확성을 높이는 데 집중했던 것과 달리, 정확한 출처 귀속 기능을 개선하는 것입니다.

- **Technical Details**: 연구에서 사용한 두 가지 기본 방법은 few-shot 및 fine-tuning입니다. 인용 품질 향상을 위해 Generate-then-Refine 방법을 제안하며, 이는 관련 인용을 추가하고 불필요한 인용을 제거하여 응답 텍스트를 변경하지 않고 인용 품질을 개선하는 방식을 포함합니다. 또한, 새로운 인용 평가 메트릭도 도입하여 기존 메트릭에서 불필요한 인용에 대한 과도한 처벌을 배제합니다.

- **Performance Highlights**: WebGLM-QA, ASQA, ELI5 데이터셋에서 실험한 결과, 제시된 방법이 LLMs에 의해 생성된 응답의 인용 품질을 상당히 향상시키는 것으로 나타났습니다. 연구의 주요 기여는 LLM이 생성하는 인용 분석, 인용 품질 평가를 위한 보다 포괄적인 메트릭 제안, 그리고 인용 품질을 대폭 향상시키는 Generate-then-Refine 접근법을 제시한 것입니다.



### Tree of Attributes Prompt Learning for Vision-Language Models (https://arxiv.org/abs/2410.11201)
- **What's New**: 본 논문에서는 Tree of Attributes Prompt learning (TAP)을 제안하여, 기존의 방법이 범주 이름만으로 구성된 학습 가능한 프롬프트(learnable prompt tokens)를 사용하여 텍스트 특성을 얻는 한계점을 극복하고자 합니다. TAP는 각 범주에 대해 '개념 - 속성 - 설명' 구조의 속성 트리를 생성하고, 이 계층 구조를 학습하여 시각 및 텍스트 프롬프트와 통합합니다.

- **Technical Details**: TAP 방법은 기존의 비구조적 설명 집합으로 범주 이름을 단순히 보강하는 접근 방식과는 달리, LLMs(large language models)에서 클래스 이름과 관련된 구조화된 지식 그래프를 정제하여 이들을 시스템적으로 통합합니다. 이를 통해 각 속성의 세부 정보를 체계적으로 구성하며, 입력된 이미지의 내용에 기반하여 가장 적합한 설명을 추출하는 vision-conditional pooling 모듈도 도입하였습니다.

- **Performance Highlights**: TAP는 11개의 다양한 데이터셋에서 제로샷(base-to-novel) 일반화, 크로스 데이터셋 전이(cross-dataset transfer), 그리고 몇 샷(classification) 분류에서 최첨단(state-of-the-art) 방법을 능가하는 성능 향상을 달성했습니다. 평균적으로 1.07%의 성과 향상을 보여주었고, CLIP에 비해 9.34%의 개선 효과를 나타냈습니다.



### SplitSEE: A Splittable Self-supervised Framework for Single-Channel EEG Representation Learning (https://arxiv.org/abs/2410.11200)
Comments:
          This paper has been accepted by ICDM2024

- **What's New**: 이번 논문에서는 단일 채널 전기뇌파(EEG) 신호로부터 효과적인 시간-주파수 표현 학습을 위해 구조적으로 분리 가능한 프레임워크인 SplitSEE를 제안합니다. 기존의 다채널 EEG 모델의 한계를 극복하고, 단일 채널에서도 다중 채널에 대한 강건한 표현을 학습할 수 있는 방법을 모색했습니다.

- **Technical Details**: SplitSEE는 두 개의 도메인 전용 모듈을 통해 시간과 주파수 도메인에서 독립적으로 표현을 학습하며, 이들 두 도메인은 일관된 클러스터 할당을 가지도록 깊은 클러스터링 작업을 도입합니다. 이를 통해 시간-주파수 학습 과정에서 발생하는 무역 문제를 완화하고, 클러스터를 일관되게 유지하며 정보를 전달합니다.

- **Performance Highlights**: SplitSEE는 단일 채널 EEG로부터 학습한 표현이 다채널 기준선을 능가하는 성과를 보여주며, 다양한 채널에서 적은 성능 편차를 보이는 강건성을 가지며, 단 한번의 미세 조정(epoch)으로도 높은 성능과 안정성을 달성했습니다.



### Isambard-AI: a leadership class supercomputer optimised specifically for Artificial Intelligenc (https://arxiv.org/abs/2410.11199)
Comments:
          11 pages, 11 figures

- **What's New**: Isambard-AI는 새로운 리더십급 슈퍼컴퓨터로, AI 연구를 지원하기 위해 설계되었습니다. 이 시스템은 HPE Cray EX4000에 기반하고 있으며, 영국 브리스톨의 에너지 효율적인 모듈식 데이터 센터에 위치하고 있습니다.

- **Technical Details**: Isambard-AI는 5,448개의 NVIDIA Grace-Hopper GPUs를 사용하여 8비트 부동 소수점 성능으로 21 ExaFLOP/s 이상, 64비트 성능으로 250 PetaFLOP/s 이상을 제공합니다. 전체 시스템의 전력 소모는 5MW 이하입니다. 또한, 두 가지 전체 플래시 스토리지 시스템인 20 PiByte Cray ClusterStor와 3.5 PiByte VAST 솔루션을 통합하여 유연한 데이터 접근 및 공유를 지원합니다.

- **Performance Highlights**: Isambard-AI는 사용자 친화적인 웹 기반 인터페이스(Jupyter notebooks, MLOps)를 통해 더 쉽게 접근할 수 있도록 설계되었습니다. 전통적인 슈퍼컴퓨터와는 달리, 이 시스템은 빠르고 정기적인 소프트웨어 업데이트를 통해 AI 소프트웨어의 급격한 발전에 발맞추어 나갈 것입니다. 1단계 시스템은 2024년 5월/6월에 온라인이 될 예정이며, 완전한 시스템은 연말까지 가동될 것으로 기대됩니다.



### Athena: Retrieval-augmented Legal Judgment Prediction with Large Language Models (https://arxiv.org/abs/2410.11195)
Comments:
          13 pages, 6 figures

- **What's New**: 최근 ChatGPT, LLaMA 및 Claude와 같은 대형 언어 모델(LLMs)이 법률 분야를 포함한 여러 도메인에서 두각을 나타내고 있습니다. 이에 따라 LLM과 실제 응용 프로그램 간의 인터페이스로서 프롬프트 엔지니어링(prompt engineering, PE)의 발전이 주목받고 있습니다. 본 연구에서는 'Athena'라는 새로운 프레임워크를 제안하여 법적 판단 예측(legal judgment prediction, LJP) 문제 해결에 RAG를 핵심 전처리 구성 요소로 활용합니다.

- **Technical Details**: Athena는 고발(고소)에 대한 지식 기반을 구축하고, 벡터화(vectorization)를 통해 의미 검색(semantic retrieval) 메커니즘을 첨부합니다. 실험 결과, Athena의 전반적인 성능이 크게 향상되어 CAIL2018 데이터셋에서 최첨단 결과를 달성하였습니다. 우리는 RAG를 도입하여 LLM의 법률 분야에서의 지식 취득을 개선하고, 이를 통해 환각(hallucination)과 모호성을 완화합니다.

- **Performance Highlights**: 실험에서는 LLM의 '중간에 길을 잃은(lost-in-the-middle)' 현상을 재현하며, 적절한 하이퍼 파라미터 조정(hyper-parameter tuning)을 통해 최대 95%의 정확도를 달성할 수 있음을 보여주었습니다. 또 한편, 쿼리 재작성(query rewriting) 및 데이터 분포(data distribution)의 영향도 연구하여 향후 연구 방향을 제시하였습니다.



### Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities (https://arxiv.org/abs/2410.11190)
Comments:
          13 pages, 6 figures

- **What's New**: 이 논문에서는 새로운 다중 모달 언어 모델인 Mini-Omni2를 소개합니다. Mini-Omni2는 시각 및 청각 쿼리에 대해 실시간 음성 응답을 제공하는 비주얼-오디오 어시스턴트입니다.

- **Technical Details**: Mini-Omni2는 사전 훈련된 시각(visual) 및 청각(auditory) 인코더를 통합하여 개별 모달리티에서의 성능을 유지합니다. 이 모델은 세 단계의 훈련 프로세스를 통해 모달리티를 정렬하여, 제한된 데이터셋으로 훈련한 후에도 다중 모달 입력 및 출력을 처리할 수 있게 합니다.

- **Performance Highlights**: Mini-Omni2는 GPT-4o와 유사한 기능을 가지고 있으며, 오픈 소스 커뮤니티의 모델들이 제공하는 일부 기능과 비교했을 때 더 유연한 사용자 인터랙션을 가능하게 하는 명령 기반 중단 메커니즘을 도입했습니다. 이는 향후 연구에서 중요한 통찰력을 제공할 것으로 기대됩니다.



### Archilles' Heel in Semi-open LLMs: Hiding Bottom against Recovery Attacks (https://arxiv.org/abs/2410.11182)
Comments:
          10 pages for main content of the paper

- **What's New**: 본 논문에서는 커스터마이징(customizability)과 회복 공격(recovery attack)에 대한 저항성을 동시에 향상시키는 새로운 반오픈 모델인 SCARA를 제안합니다.

- **Technical Details**: SCARA는 소수의 하단 레이어(bottom layers)를 클로즈드 소스(closed-source)로 유지하며, 복원 난이도 점수(recovery difficulty score)를 기반으로 최소한의 클로즈드 소스 레이어 수를 결정합니다. 이는 모델의 복원 성능을 평가하므로, 다양한 다운스트림 작업에서 커스터마이징 가능한 성능을 보장합니다.

- **Performance Highlights**: SCARA를 통해 생성된 반오픈 모델은 최소 10배 적은 클로즈드 소스 파라미터로, 다양한 벤치마크에서 다운스트림 작업 성능을 크게 개선했습니다. 예를 들어 Llama2-70B 모델은 2.5%의 파라미터만을 숨기면서도 금융 영역에서 30% 높은 성능 점수를 기록했습니다.



### DARNet: Dual Attention Refinement Network with Spatiotemporal Construction for Auditory Attention Detection (https://arxiv.org/abs/2410.11181)
- **What's New**: 이 논문에서는 기존의 AAD(청각 주의 탐지) 알고리즘의 한계를 극복하기 위해 DARNet이라는 새로운 모델을 제안합니다. DARNet은 EEG 신호의 공간적 분포 정보를 활용하고 장거리 잠재 의존성을 효과적으로 캡처하도록 설계되었습니다.

- **Technical Details**: DARNet은 세 가지 모듈로 구성되어 있습니다: (1) Spatiotemporal Construction Module: EEG 신호의 시간적 동적 특징과 공간 분포 특성을 효과적으로 캡처합니다. (2) Dual Attention Refinement Module: 이 모듈은 두 개의 레이어로 구성되어 있으며, 각 레이어는 multi-head self-attention과 refinement layer를 포함합니다. (3) Feature Fusion & Classifier Module: 다양한 수준에서의 주의(features)를 융합하여 더 풍부한 표현을 생성하고, 최종 분류 결과를 예측합니다.

- **Performance Highlights**: DARNet은 DTU 데이터셋에서 0.1초의 결정 창(window)에서 평균 5.9%의 분류 정확도 향상을 달성하였고, 이를 통해 현재의 최첨단 모델보다 91%의 파라미터 수 감소를 이루었습니다.



### Interpretability as Compression: Reconsidering SAE Explanations of Neural Activations with MDL-SAEs (https://arxiv.org/abs/2410.11179)
Comments:
          8 pages, 5 figures

- **What's New**: 이번 연구에서는 Sparse Autoencoders (SAEs)를 정보 이론적 프레임워크로 해석하여 신경망의 활성화 설명을 전달하는 손실 압축 알고리즘으로 간주하는 방법을 제시합니다. 이 접근법은 Minimal Description Length (MDL) 원칙을 통해 정확하고 간결한 설명을 강조합니다.

- **Technical Details**: SAEs는 Neural Activations를 설명하기 위해 활성화된 특징들을 사용합니다. 연구자는 각 특징이 독립적으로 이해될 수 있어야 한다는 ‘독립적 가산성 (independent additivity)’이라는 추가 속성을 주장합니다. 이들은 MNIST 손글씨 데이터셋을 사용하여 MDL 원칙에 기반한 프레임워크를 입증하였습니다.

- **Performance Highlights**: 연구의 결과로, SAE는 중요한 선형 구간을 나타내는 특징들이 최적임을 보여주었으며, 이는 메모리된 숫자나 작은 숫자 조각보다 효과적인 결과를 나타냈습니다.



### Improving Bias in Facial Attribute Classification: A Combined Impact of KL Divergence induced Loss Function and Dual Attention (https://arxiv.org/abs/2410.11176)
Comments:
          15 pages, 9 figures, 5 tables

- **What's New**: 이 논문은 AI 기반 얼굴 인식 시스템의 공정성을 높이기 위한 새로운 접근 방식을 제안합니다. 이 방법은 사전 훈련된 Inception-ResNet V1 모델을 사용하여 듀얼 어텐션 메커니즘을 적용하고, KL-다이버전스(KL-divergence) 정규화와 크로스 엔트로피 손실 함수(cross-entropy loss function)를 통해 개선되었습니다.

- **Technical Details**: 제안된 방법은 데이터의 다양성, 공정성과 정확성의 균형, 불균형 및 편향 측정과 같은 많은 문제들을 해결하는 데 도움을 줄 수 있습니다. 특히, transfer learning을 이용하여 편향을 줄이고, 정확도와 계산 효율성을 향상시킵니다.

- **Performance Highlights**: 실험 결과, 공정성과 분류 정확도 모두에서 유의미한 개선이 보여줍니다. 이는 얼굴 인식 시스템의 신뢰성을 높이는 데 긍정적인 발전을 제공합니다.



### Towards General Deepfake Detection with Dynamic Curriculum (https://arxiv.org/abs/2410.11162)
Comments:
          Received by ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)

- **What's New**: 이번 연구에서는 Deepfake 탐지를 위해 새로운 표본 강도를 훈련 과정에 도입하는 커리큘럼 학습(Curriculum Learning) 패러다임을 제안합니다. 제안된 방법론은 모델이 훈련 중에 점진적으로 어려운 표본에 집중할 수 있도록 돕습니다.

- **Technical Details**: Dynamic Facial Forensic Curriculum (DFFC)이라는 새로운 접근 방식을 제안하며, 이는 Dynamic Forensic Hardness (DFH)를 통해 훈련 중 표본의 강도를 동적으로 측정합니다. DFH는 얼굴 품질 점수와 즉각적인 인스턴스 손실을 통합하여 정의됩니다. 또한, DFFC는 쉬운 표본에서 어려운 표본으로 훈련 데이터를 단계적으로 제어하는 페이싱 함수(Pacing Function)를 통합합니다.

- **Performance Highlights**: DFFC를 통해 다양한 종류의 end-to-end Deepfake 탐지기의 성능을 개선할 수 있음을 보여주는 포괄적인 실험 결과를 도출하였습니다. DFFC는 플러그 앤 플레이 방식으로 기존 탐지기에 쉽게 적용할 수 있으며, 어려운 표본의 정보를 효과적으로 활용하여 일반적인 변조 특징 학습을 지원합니다.



### Optimizing Encoder-Only Transformers for Session-Based Recommendation Systems (https://arxiv.org/abs/2410.11150)
- **What's New**: 이 논문에서는 Sequential Masked Modeling (SMM)이라는 새로운 접근법을 소개하며, 이는 단일 세션 추천 시스템에서의 다음 추천 아이템 예측 문제를 해결하기 위해 설계되었습니다. 이 방법은 데이터 증강(data augmentation)과 특별한 토큰 마스킹 전략을 결합하여 시퀀스 종속성(sequential dependencies)을 효과적으로 포착합니다.

- **Technical Details**: SMM은 인코더 전용 트랜스포머 아키텍처를 활용하여 설계되었습니다. 이 방법에서는 윈도우 슬라이딩을 통한 데이터 증강과 펜얼리미니트 토큰 마스킹 전략을 사용하여 세션 데이터를 처리합니다. 제안하는 방법은 Yoochoose 1/64, Diginetica, Tmall의 세 가지 주요 데이터 세트에서 평가되었습니다.

- **Performance Highlights**: Transformer-SMM 모델은 동일한 정보 수준에서 가장 최신 모델들과 비교했을 때 명확한 성능 향상을 보였습니다. 사용자 데이터가 더 많이 제공되는 모델들과 비교해도 경쟁력을 유지하며 높은 정확도와 순위 평가 지표를 기록했습니다.



### LLM Unlearning via Loss Adjustment with Only Forget Data (https://arxiv.org/abs/2410.11143)
Comments:
          Paper under review

- **What's New**: 이번 연구에서는 기존의 unlearning 방식에서 요구되는 retain data나 reference LLM 없이도 LLM의 응답 조정이 가능하다는 것을 제안합니다.

- **Technical Details**: 우리의 방법인 FLAT(Forget data only Loss AjustmenT)는 잊어야 할 데이터에 대한 정보만을 사용하여 f-divergence를 극대화함으로써 모델 응답을 조정합니다. 이를 통해 잊는 과정에서의 성능을 저하시키지 않고 모델의 유용성을 유지할 수 있습니다.

- **Performance Highlights**: 실험 결과, FLAT는 해리포터 데이터셋, MUSE 벤치마크 및 TOFU 데이터셋과 같은 다양한 과제에서 기존 방법들에 비해 우수한 unlearning 성능을 달성하였으며, 모델의 유지 능력에 미치는 영향도 최소화했습니다.



### Audio-based Kinship Verification Using Age Domain Conversion (https://arxiv.org/abs/2410.11120)
Comments:
          4 pages, 2 figures, submitted to IEEE Signal Processing Letters

- **What's New**: 본 연구에서는 나이에 따른 오디오 특성을 표준화하여 가족 관계를 검증하는 새로운 접근 방식을 제안합니다. CycleGAN-VC3 네트워크를 활용하여 다양한 연령대의 음성을 중간 연령대로 변환하고, 이를 통해 오디오의 도메인 편향 문제를 해결했습니다.

- **Technical Details**: 본 연구는 KAN_AV 데이터 세트를 사용하여 16kHz 샘플링 레이트로 녹음된 오디오 데이터를 처리합니다. Mel-spectrogram을 추출하고, CycleGAN-VC3 구조를 통해 음성을 변환합니다. 고차원 특성을 추출 후 triplet network를 통해 가족 관계를 검증합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 기존의 데이터에서 발생하는 도메인 편향 문제를 극복하여 가족 관계 검증 정확도를 유의미하게 향상시키는 것으로 나타났습니다. 이 방법은 향후 가족 관계 검증 연구에 있어 새로운 통찰을 제공합니다.



### MoonMetaSync: Lunar Image Registration Analysis (https://arxiv.org/abs/2410.11118)
- **What's New**: 본 논문은 SIFT(Scale-Invariant Feature Transform)와 ORB(Oriented FAST and Rotated BRIEF) 특징 검출 방법을 비교하고, 새로운 특성 검출기인 IntFeat를 소개합니다. 특히, IntFeat는 달 이미지에 적용되어 두 가지 해상도 (저해상도: 128x128, 고해상도: 1024x1024)에서 성능을 평가합니다.

- **Technical Details**: IntFeat는 SIFT와 ORB의 고수준 및 저수준 특징을 통합하여 강력한 달 이미지 정합을 제공합니다. 연구팀은 SycnVision이라는 파이썬 패키지를 도입하여 다양한 정합 방법 (SIFT, ORB, IntFeat)을 비교하고, 저해상도 달 이미지의 업스케일링에 있어서 bi-linear 및 bi-cubic 보간 방법을 사용하여 정합 효과성을 평가했습니다.

- **Performance Highlights**: IntFeat는 SSIM(Structural Similarity Index Measure)과 PSNR(Peak Signal-to-Noise Ratio) 지표를 통해 평가된 결과, SIFT와 ORB 사이에서 균형 잡힌 성능을 보여줍니다. 저해상도 달 이미지와 고각 이미지에서 IntFeat는 SIFT와의 성능 격차를 최소화하며, 특히 bi-linear 보간에서 SIFT의 성능에 근접한 결과를 도출했습니다.



### Differentiable Weightless Neural Networks (https://arxiv.org/abs/2410.11112)
- **What's New**: Differentiable Weightless Neural Network (DWN) 모델을 소개합니다. DWN은 상호 연결된 lookup tables (LUTs) 기반의 모델로, novel Extended Finite Difference 기술을 통해 이진값의 근사 미분을 가능하게 합니다. 또한, Learnable Mapping, Learnable Reduction 및 Spectral Regularization을 통해 모델의 정확도와 효율성을 향상시킵니다.

- **Technical Details**: DWN은 기존의 weightless neural networks (WNNs)의 한계를 극복하기 위해 개발되었습니다. Extended Finite Difference 기술로부터 LUTs를 통한 backpropagation이 가능해지며, Learnable Mapping으로 LUT 간 연결을 학습할 수 있습니다. Learnable Reduction은 작은 모델을 위해 설계된 폐기 구조를 제공하여 회로 크기를 줄입니다. Spectral Normalization은 모델 안정성을 강화하고 과적합을 방지하는 LUT에 특화된 정규화 기법입니다.

- **Performance Highlights**: DWN은 FPGA 기반 배포에서 기존 WNN, DiffLogicNet 및 BNN에 비해 Latency, Throughput, Energy Efficiency 및 Model Area에서 월등한 성능을 나타냅니다. 저전력 마이크로컨트롤러에서 DWN은 XGBoost보다 평균 1.2% 높은 정확도를 달성하며, 초저비용 칩에서는 기존 Tiny Classifier 모델에 비해 회로 면적을 최대 42.8배 줄입니다. 또한, Tabular 데이터 처리에서 DWN은 XGBoost 및 TabNets 모델들을 초월하는 성능을 보입니다.



### DMDSpeech: Distilled Diffusion Model Surpassing The Teacher in Zero-shot Speech Synthesis via Direct Metric Optimization (https://arxiv.org/abs/2410.11097)
- **What's New**: 본 논문은 TTS(텍스트-음성 변환) 확산(디퓨전) 모델을 직접적인 end-to-end 평가 메트릭 최적화를 통해 증류하는 새로운 방법인 DMDSpeech를 제안합니다.

- **Technical Details**: DMDSpeech는 Distribution Matching Distillation (DMD)을 이용하여 신속한 음성 생성을 위해 확산 모델을 4단계로 변환한 모델입니다. 여기서 Connectionist Temporal Classification (CTC) 손실과 Speaker Verification (SV) 손실을 통합하여 음성의 품질과 화자 유사성을 향상시킵니다.

- **Performance Highlights**: DMDSpeech는 이전의 최첨단 모델들을 제치고 자연스러움과 화자 유사성에서 항상 우수한 결과를 보여주며, 인퍼런스 속도 또한 획기적으로 향상되었습니다. 인체 평가 및 객관적인 화자 유사성 메트릭에서도 기존의 진짜 음성보다 더 높은 음성 유사성을 기록했습니다.



### SecCodePLT: A Unified Platform for Evaluating the Security of Code GenAI (https://arxiv.org/abs/2410.11096)
- **What's New**: 이번 연구에서는 코드 생성 AI(Code GenAI)의 보안 위험을 평가하기 위한 통합 플랫폼인 SecCodePLT를 개발했습니다. 이를 통해 기존의 벤치마크들에서 간과되었던 코드 생성과 사이버 공격 도움 가능성 평가를 신뢰성 있게 수행할 수 있게 되었습니다.

- **Technical Details**: SecCodePLT는 두 단계의 데이터 생성 파이프라인을 통해 안전하지 않은 코드와 사이버 공격 유용성을 평가합니다. 또한, 동적 평가(dynamic evaluation)와 규칙 기반 검출(rule-based detection)을 결합한 혼합 평가 메트릭을 도입하여 보안 관련 데이터를 생성하고 평가할 수 있습니다. 특히, 사이버 공격 유용성 벤치마크는 MITRE ATT&CK 프레임워크를 바탕으로 구성되었습니다.

- **Performance Highlights**: SecCodePLT는 기존의 CyberSecEval 벤치마크와 비교하여 보안 관련성(security relevance)에서 현저히 우수한 성능을 보이며, 최신 코드 에이전트(Cursor)에서 비트리비얼한 보안 위험을 최초로 발견했습니다. 이 연구는 코드 생성 AI의 보안 위험을 보다 정확히 평가할 수 있는 기초를 제공합니다.



### EchoApex: A General-Purpose Vision Foundation Model for Echocardiography (https://arxiv.org/abs/2410.11092)
- **What's New**: 이 논문은 심장 초음파(echocardiography)를 위한 최초의 범용 비전 파운데이션 모델인 EchoApex를 소개합니다. 2000만 개 이상의 초음파 이미지를 기반으로 학습되어 다양한 임상 적용 사례에서 우수한 성능을 입증합니다.

- **Technical Details**: EchoApex는 자가 지도 학습(self-supervised learning)을 활용하여 11개의 임상 센터에서 수집된 2000만 개의 초음파 이미지로 사전 훈련(pretrained)되었으며, 4가지 임상 응용과 28개의 하위 작업에서 효과성을 입증합니다. 모델은 TTE(Trans-thoracic echocardiogram), TEE(Trans-esophageal echocardiogram), ICE(Intracardiac echocardiogram) 이미지를 포함하는 다양한 초음파 데이터를 사용합니다.

- **Performance Highlights**: EchoApex는 4개의 다양한 임상 작업에서 기존의 최첨단(task-specific) 모델과 비교하여 우수한 성능을 보여주었습니다. 통합된 이미지 인코딩 아키텍처로 사전 훈련된 모델은 downstream tasks에 쉽게 적응할 수 있는 유연성을 가지며, 진단 정확도를 향상시키고 환자 결과를 개선하는 가능성을 제시합니다.



### Few-shot Novel View Synthesis using Depth Aware 3D Gaussian Splatting (https://arxiv.org/abs/2410.11080)
Comments:
          Presented in ECCV 2024 workshop S3DSGR

- **What's New**: 이 연구는 제한된 뷰에서의 새로운 뷰 합성(few-shot novel view synthesis)을 위한 depth-aware Gaussian splatting 방법을 제안합니다. 이 방법은 단 몇 개의 입력 뷰만으로도 뛰어난 렌더링 품질을 달성할 수 있게 합니다.

- **Technical Details**: 이 접근법은 모노큘러(depth) 깊이 예측을 사전 정보로 사용하고, 스케일-불변(depth scale-invariant) 깊이 손실을 통해 3D 형태를 제약합니다. 또한 색상 모델링을 위해 저차 구형 고조파(lower-order spherical harmonics)를 사용하여 과적합(overfitting)을 피하는 방식으로 개선하였습니다.

- **Performance Highlights**: 제안된 방법은 기존의 3D Gaussian splatting 방법보다 Peak Signal-to-Noise Ratio(PSNR)에서 10.5%, 구조적 유사도 지수(SSIM)에서 6%, 그리고 인지적 유사성(LPIPS)에서 14.1% 개선된 성능을 보이며, 제한된 뷰에서도 효과적인 성능 향상을 달성함을 입증하였습니다.



### Code-Mixer Ya Nahi: Novel Approaches to Measuring Multilingual LLMs' Code-Mixing Capabilities (https://arxiv.org/abs/2410.11079)
Comments:
          Manuscript submitted to COLING 2025

- **What's New**: 다언어 대형 언어 모델(Multilingual Large Language Models, LLMs)의 기계 번역(Machine Translation, MT) 능력은 이미 뛰어난 성과를 보여주었지만, 코드 스위칭(code-switching) 상황에서의 능력은 충분히 탐구되지 않았습니다. 이 논문에서는 코드를 혼합한 문장을 생성하기 위한 새로운 프롬프트 기법인 Rule-Based Prompting을 소개합니다.

- **Technical Details**: 연구에서는 $k$-shot prompting($k\in\{0, 1, 10, 20\}$)과 Rule-Based Prompting을 사용하여 GPT-3.5-turbo, GPT-4, Gemini Pro와 같은 3개의 인기 있는 다국어 LLM의 코드 혼합 MT 능력을 측정하고 비교합니다. 데이터셋은 영어-{힌디어(Hindi), 벵골어(Bengali), 구자라티어(Gujarati), 프랑스어(French), 스페인어(Spanish)}의 5개 언어 쌍을 포함하며, 이를 통해 다언어 LLM의 영어와 코드 혼합 문장 간의 번역 능력을 평가합니다.

- **Performance Highlights**: 결과에 따르면, $k$-shot prompting이 종종 최고의 성과를 나타내지만, Rule-Based Prompting은 코드 혼합의 스타일이 다양한 고유한 문장을 생성하는 데 유망한 결과를 보여줍니다. 또한, 이 연구의 실제 적용으로 코드 혼합 챗봇을 개발하였습니다.



### PRACTIQ: A Practical Conversational Text-to-SQL dataset with Ambiguous and Unanswerable Queries (https://arxiv.org/abs/2410.11076)
- **What's New**: 이 논문에서는 실전에서 사용자 질문의 모호성과 답변 불가능성을 반영한 PRACTIQ라는 대화형 text-to-SQL 데이터셋을 생성했습니다. 기존의 text-to-SQL 시스템들이 명확한 질문에 초점을 맞췄던 반면, PRACTIQ는 실제 사용자 질의를 바탕으로 하여 모호하고 답변 불가능한 질문을 포함합니다.

- **Technical Details**: PRACTIQ는 네 가지 모호한 질문 카테고리와 네 가지 답변 불가능 질문 카테고리를 정의한 후, 이를 바탕으로 대화 형식의 질문을 생성합니다. 또한, 질문 분류 및 SQL 예측을 위한 두 단계의 프레임워크를 구현했습니다. 이를 위해 여러 대형 언어 모델(LLM)을 사용하여 성능을 평가하고 있습니다.

- **Performance Highlights**: 실험 결과, 현재의 최첨단(text-to-SQL) 시스템들은 모호하고 답변 불가능한 질문을 효과적으로 처리하지 못함을 보여주었습니다. PRACTIQ 데이터셋을 통해 이러한 문제를 개선하는 데 기여할 것으로 기대됩니다.



### Parsing altered brain connectivity in neurodevelopmental disorders by integrating graph-based normative modeling and deep generative networks (https://arxiv.org/abs/2410.11064)
- **What's New**: 본 연구에서는 뇌 네트워크 개발을 다루기 위해 최초로 깊은 생성 모델(deep generative models)과 그래프 기반의 표준 모델링(normative modeling)을 통합한 BRIDGE 프레임워크를 제시합니다. 이 프레임워크는 일반적인 뇌 발달 경로를 제공하며, 개별적으로 비정상적인(dbivergent) 신경 발달을 정량화 할 수 있는 기회를 제공합니다.

- **Technical Details**: BRIDGE 프레임워크는 생물학적 제약(bio-inspired wiring constraints)을 포함한 깊은 생성 모델을 사용하여 신경 발달 경로를 효과적으로 포착합니다. 그래프 컨볼루션 네트워크(Graph Convolutional Networks, GCNs)를 통해 뇌 네트워크의 잠재적 구성을 유추하며, 이는 신경 네트워크의 발달 과정을 정교하게 설명합니다.

- **Performance Highlights**: BRIDGE 프레임워크는 자폐 스펙트럼 장애 아동에 적용되어 개인 맞춤형 지역별 발달 다이버전스 맵(region-wise divergence maps)을 생성하고, 전반적인 다이버전스 점수와 임상 평가(clinical assessments) 간의 상관관계를 보여주었습니다. 이 연구는 복잡한 신경 발달 동태를 드러내며, 차별화된 진단과 치료 방법 개발의 가능성을 열어줍니다.



### Towards the methodology for solving the minimum enclosing ball and related problems (https://arxiv.org/abs/2410.11063)
- **What's New**: 이 논문은 최소 포위 구(ball) 문제의 해법에 대한 방법론을 제시합니다. 이는 주어진 유계 집합을 포함하는 가장 작은 반지름을 가진 구의 표면을 결정하는 문제입니다. 또한, 이 문제와 관련된 다양한 분야에 대해 다룰 것입니다.

- **Technical Details**: 최소 포위 구 문제(MEB)는 d차원 유클리드 공간 ℝ^d에서 n 개의 점으로 이루어진 집합 P를 포함하는 중심 c와 반지름 r을 가진 구를 찾는 문제로, 이는 최소화와 최대화의 조합으로 구성된 최적화 문제로 나타낼 수 있습니다. 다양한 초기 및 진보된 알고리즘이 MEB 및 관련 문제를 해결하기 위해 제안되었습니다.

- **Performance Highlights**: 본 논문에서 제안하는 방법은 non-differentiable, discontinuous, discrete, noisy 및 multimodal 목적 함수에 처리 가능하며, 실제 응용 프로그램에서의 효율성과 효과가 높다는 장점이 있습니다. 특히, 지난 몇 년간 이러한 방법들이 인기를 끌고 있으며, 성능 연구가 2002년부터 시작되었습니다.



### CleanUMamba: A Compact Mamba Network for Speech Denoising using Channel Pruning (https://arxiv.org/abs/2410.11062)
Comments:
          5 pages, 4 figures

- **What's New**: 본 논문에서는 실시간 인과 오디오 잡음 제거를 위해 설계된 CleanUMamba라는 시간 도메인 신경망 아키텍처를 소개합니다. 이 아키텍처는 전통적인 LSTM 및 self-attention 메커니즘 대신 Mamba를 도입하여 최고의 잡음 제거 성능을 제공합니다. 또한, 모델 크기를 8배 줄이고 오디오 품질에는 영향을 주지 않는 구조적 채널 프루닝(structured channel pruning) 기법을 적용했습니다.

- **Technical Details**: CleanUMamba는 U-Net encoder-decoder 구조를 기반으로 하며, 병목(bottleneck) 계층에서 Mamba 상태 공간 모델을 포함합니다. 모델은 442K의 파라미터와 468M MACs로, PESQ 점수 2.42와 STOI 95.1%를 달성하며, 같은 조건의 더 큰 모델들과 비교해도 뛰어난 실시간 성능을 보여줍니다. 이 모델은 48ms의 알고리즘 지연을 가지고 있으며, 인코더 레이어 수에 따라 지연 시간이 달라질 수 있습니다.

- **Performance Highlights**: CleanUMamba는 Interspeech 2020 Deep Noise Suppression 도전에서 탁월한 성과를 보였고, 오디오 품질 평가에서 PESQ 2.42, STOI 95.1%로 높은 점수를 기록했습니다. 8X 모델 사이즈 감소에도 불구하고 오디오 품질을 유지하는 데 성공하였습니다.



### Assessing Bias in Metric Models for LLM Open-Ended Generation Bias Benchmarks (https://arxiv.org/abs/2410.11059)
Comments:
          NeurIPS 2024 EvalEval Workshop

- **What's New**: 본 연구는 대형 언어 모델(LLMs)의 편향을 평가하는 open-generation bias benchmarks, 특히 BOLD 및 SAGED의 내재적 편향을 분석합니다. 이를 통해 불공정한 결론에 이르게 하는 분류기(classifiers)의 편향을 조사했습니다.

- **Technical Details**: MGSD 데이터셋을 사용하여 두 가지 실험을 수행했습니다. 첫 번째 실험에서는 counterfactuals를 통해 인구 통계 그룹 간의 예측 변동성을 측정하고, 두 번째 실험에서는 SHAP(Shapley Additive Explanations) 도구를 사용하여 관찰된 편향이 이러한 counterfactuals에서 유래했음을 검증했습니다.

- **Performance Highlights**: 연구 결과, 다양한 인구통계 설명자(demographic descriptors)에서 불평등한 처리 결과가 나타났으며, 특히 RegardV3는 가장 큰 편향을 보였습니다. Race 그룹이 가장 많은 편향을 보였고, Detoxify는 인종 간 독성 점수에서 큰 변동성을 보였습니다.



### Varying Shades of Wrong: Aligning LLMs with Wrong Answers Only (https://arxiv.org/abs/2410.11055)
- **What's New**: 본 논문에서는 주석(annotation)이 부족한 상황에서 LLM(large language model)의 성능을 어떻게 확장할 수 있는지에 관한 두 가지 연구 질문에 초점을 맞춥니다. (1) LLM이 잘못된 옵션들 사이에서 신뢰할 수 있는 선호도를 생성할 수 있는가? (2) 이러한 잘못된 옵션 간 선호와의 정렬(alignment)이 도움이 되는가?

- **Technical Details**: 연구에서는 Self-consistency, token probabilities, LLM-as-a-judge와 같은 방법을 통해 잘못된 옵션들 사이의 선호도를 이끌어내고 이 합성(preference optimization)을 통해 언어 모델을 미세 조정(fine-tune)합니다. 실험 결과, LLM은 다양한 shades of wrong을 구분하며, 일부 경우에는 더 나은 정확성을 보입니다. 아울러, 잘못된-잘못된 선호에 대한 정렬이 모델의 교정(calibration)을 향상시키는 데 기여합니다.

- **Performance Highlights**: 7개의 LLM과 8개의 데이터셋을 활용한 광범위한 실험을 통해, (1) LLM이 잘못된 옵션 사이의 선호도를 구분할 수 있으며, 무작위 추측보다 평균 20.9% 높은 성능을 보입니다. (2) 잘못된 옵션 간 선호도와의 정렬이 LLM의 성능을 개선시켜, 경우에 따라 올바른 답안을 도출하기도 하며, 전체적으로 모델의 교정 오류(Estimated Calibration Error)는 최대 9.4% 감소합니다.



### Towards a More Complete Theory of Function Preserving Transforms (https://arxiv.org/abs/2410.11038)
- **What's New**: 이 논문에서는 신경망의 아키텍처를 변경하면서도 그 기능을 유지할 수 있는 혁신적인 기술인 함수 보존 변환 (Function Preserving Transform, FPT)을 개발하였습니다. 특히, 잔차 연결 (Residual Connections)을 통합한 R2R이라는 새로운 방법론을 제안하여, 기존의 함수 보존 변환들보다 다루기 쉬운 형태로 발전시켰습니다.

- **Technical Details**: R2R은 FPTs의 새로운 유형으로, 신경망의 농도 (widening) 및 깊이 (deepening)를 처리할 수 있습니다. R2WiderR과 R2DeeperR는 이러한 변환을 허용하며, Net2Net 및 Network Morphism과 비교 분석이 포함되어 있습니다. 또한 FPTs가 효율적인 학습을 위해 새로운 아키텍처를 평가하는데 어떻게 활용될 수 있는지를 설명합니다.

- **Performance Highlights**: R2R은 이미지 분류 작업에서 Net2Net 및 Network Morphism에 비해 더 빠르게 모델을 훈련할 수 있으며, 필터의 다양성을 높이는 능력을 보여줍니다. 이는 대규모 신경망의 훈련 효율성을 향상시키는데 기여할 것으로 예상됩니다.



### NAR-*ICP: Neural Execution of Classical ICP-based Pointcloud Registration Algorithms (https://arxiv.org/abs/2410.11031)
Comments:
          17 pages, 9 figures

- **What's New**: 본 연구는 Neural Algorithmic Reasoning (NAR) 프레임워크를 통해 신경망(neural networks)과 고전 로봇 알고리즘(classical robotics algorithms)의 교차점을 탐구합니다. NAR은 신경망이 고전 알고리즘처럼 추론할 수 있도록 학습하며, GNN 기반의 NAR-*ICP를 제안하여 기존의 ICP(Point Cloud Registration) 알고리즘의 중간 단계들을 학습합니다.

- **Technical Details**: NAR-*ICP는 Graph Neural Network (GNN)를 기반으로 하여 고전적인 ICP 기반 포인트 클라우드 등록 알고리즘의 중간 알고리즘 단계를 학습합니다. 이 연구는 CLRS 알고리즘적 추론 벤치마크를 고전 로봇 인식 알고리즘으로 확장하며, 다양한 실제 및 합성 데이터셋에서 이 접근 방식을 평가하여 복잡하고 시끄러운 입력을 처리하는 유연성을 보여줍니다.

- **Performance Highlights**: 이 방법은 모든 벤치마크와 데이터셋에서 우수한 성능을 달성하였고, 심지어 훈련된 알고리즘의 성능까지도 초과하는 결과를 보여주었습니다. 이는 전통적인 알고리즘의 능력을 넘어 일반화(generalization)할 수 있는 능력을 증명합니다.



### Improving the Language Understanding Capabilities of Large Language Models Using Reinforcement Learning (https://arxiv.org/abs/2410.11020)
- **What's New**: 본 논문에서는 대형 언어 모델(LLMs)이 자연어 이해(NLU) 작업에서 기존 BERT 모델보다 성능이 떨어진다는 점을 개선하기 위해, SFT(구조화된 미세 조정)와 PPO(인접 정책 최적화) 두 가지 접근 방식을 탐구합니다. 특히, PPO가 LLM의 NLU 성능을 어떻게 향상시킬 수 있는지 분석합니다.

- **Technical Details**: 이 연구는 LLM을 대상으로 SFT와 PPO를 사용하여 NLU 능력을 개선하는 방법을 제안합니다. SFT에서는 저순위 적응(LoRA) 계층을 활용하여 미세 조정 비용을 줄이고, PPO를 통해 토큰 생성 과정을 행동으로 간주하여 보상 기능을 틀로 삼아 모델을 최적화합니다.

- **Performance Highlights**: 실험 결과, PPO가 SFT에 비해 GLUE 벤치마크에서 평균 6.3 점 향상된 성능을 보였으며, zero-shot과 few-shot 방식을 경쟁하여 각각 38.7 및 26.1 점 우수한 성과를 달성했습니다. PPO는 BERT-large보다도 GLUE에서 2.7 점, SuperGLUE에서 9.3 점 높은 성능을 기록했습니다.



### Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback (https://arxiv.org/abs/2410.11009)
Comments:
          Accepted to appear at EMNLP 2024

- **What's New**: AI가 매개된 커뮤니케이션 시스템인 Nifty를 통해 사용자 피드백을 효과적으로 통합하여 AI 글쓰기 모델의 성능을 향상시키는 방법을 제안합니다.

- **Technical Details**: Nifty는 사용자가 스마트 추천 시스템의 제안 중 아무것도 클릭하지 않았을 때 발생하는 일회성 암묵적 부정 피드백을 활용합니다. 이 방법은 분류기 가이드를 사용하여 이 피드백을 텍스트 생성 과정에 통합합니다. 두 가지 조건 설정을 탐구하는데, 하나는 제안에 포함되지 않은 다음 의도에 따라 모델을 조정(push)하는 것이고, 다른 하나는 사용자가 제안을 거부한 것에 직접적으로 조건을 두는 것입니다.

- **Performance Highlights**: 이 시스템은 MultiWOZ 및 Schema-Guided Dialog 데이터셋을 사용하여 Rouge-L에서 최대 34%, 올바른 의도 생성에서 89% 향상을 보였으며, 인간 평가자에 의한 86%의 승률을 기록했습니다.



### Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs (https://arxiv.org/abs/2410.11001)
- **What's New**: 이번 연구에서는 LLM(대형 언어 모델)에 의해 생성된 역사적 응답을 활용하여 RAG(검색 증강 생성)를 개선하기 위한 '그래프 오브 레코드'(GoR)를 제안합니다. 기존 방법들이 유용한 정보를 포함하는 LLM 생성 응답을 무시하는 것에 대한 문제점을 해결하려고 합니다.

- **Technical Details**: GoR 방법론은 LLM이 시뮬레이션한 사용자 쿼리와 관련된 텍스트 청크 간의 엣지를 통해 기록 그래프를 구축합니다. 재귀 신경망(graph neural network)을 사용하여 노드 간의 정교한 상관관계를 학습하고, BERTScore 기반의 자가 지도 학습(objective)을 통해 최적화를 진행합니다. 이를 통해 노드 임베딩이 쿼리와의 의미적 및 논리적 상관관계를 반영할 수 있도록 합니다.

- **Performance Highlights**: GoR은 WCEP 데이터셋에서 Rouge-L에서 15%, Rouge-1에서 8%, Rouge-2에서 19% 개선된 성능을 보여줍니다. 총 12개 기준선과의 비교를 통해 GoR의 우수성이 입증되었습니다.



### Liger Kernel: Efficient Triton Kernels for LLM Training (https://arxiv.org/abs/2410.10989)
Comments:
          17 pages, 12 figures

- **What's New**: Liger-Kernel는 단일 트라이톤 커널 세트를 제공하여 대규모 언어 모델(LLM) 훈련의 효율성을 향상시키는 것을 목표로 합니다.

- **Technical Details**: Liger-Kernel은 커널 작업 합성(kernel operation fusing) 및 입력 청크를 포함한 최적화 기술을 통해 훈련 처리량을 20% 증가시키고 GPU 메모리 사용량을 60% 감소시킵니다. 이 라이브러리는 PyTorch 및 Triton과 최소한의 의존성을 가지며, PyTorch FSDP, DeepSpeed ZeRO 등의 여러 분산 프레임워크를 지원합니다.

- **Performance Highlights**: Liger-Kernel을 사용하면 처음 사용자도 몇 줄의 코드로 LLM 훈련 효율성을 쉽게 개선할 수 있으며, 고급 사용자들은 모듈 구성 요소 및 적응형 계층 설정을 통해 모델을 사용자 맞춤형으로 조정할 수 있습니다.



### ASTM :Autonomous Smart Traffic Management System Using Artificial Intelligence CNN and LSTM (https://arxiv.org/abs/2410.10929)
Comments:
          In process to IEEE Intelligent Vehicle Symposium 2025

- **What's New**: 본 논문은 인공지능(AI)을 활용한 자율 스마트 교통 관리 시스템(Autonomous Smart Traffic Management, ASTM) 개발에 중점을 두고 있으며, 교통 흐름을 개선하기 위한 YOLO V5 합성곱 신경망을 사용하는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 제안된 시스템에서는 YOLO V5 Convolutional Neural Network가 교통 관리 이미지를 통해 차량을 감지하고, Recurrent Neural Network with Long Short-Term Memory (RNN-LSTM)을 통해 다음 12시간 동안의 차량 수를 예측합니다. 이 예측을 기반으로 Smart Traffic Management Cycle Length Analysis가 교통 주기 길이를 관리합니다.

- **Performance Highlights**: 논문에서 제시된 RNN-LSTM 모델은 평균 제곱 오차(Mean Squared Error, MSE) 4.521 차량과 제곱근 평균 제곱 오차(Root Mean Squared Error, RMSE) 2.232 차량을 기록하였으며, STM 시스템 시뮬레이션 결과, 교통 관리 혼잡 흐름 속도가 50% 개선되고 차량 통과 지연이 70% 감소한 것으로 나타났습니다.



### Cultural Heritage 3D Reconstruction with Diffusion Networks (https://arxiv.org/abs/2410.10927)
Comments:
          Accepted by the workshop VISART for ECCV 2024

- **What's New**: 최근 생성형 AI 알고리즘을 활용하여 문화유산 복원에 대한 연구를 진행하였으며, 조건부 확산 모델(conditional diffusion model)을 통해 3D 포인트 클라우드(point clouds)를 효과적으로 재구성하는 방법을 제시합니다.

- **Technical Details**: 이 연구에서는 확산 모델을 기반으로 하여 객체의 결손 부분 생성을 관찰된 부분 입력에 조건화하는 방법을 제안합니다. 이 모델은 물체 복원에 있어 일반화 능력을 평가하며, 고고학적 부분의 수리를 위해 훈련된 특정 방법론을 채택합니다. 확산 과정은 마코프 체인(Markov chain)으로 모델링되며, Gaussian 분포를 사용하여 점진적으로 노이즈를 추가하고 제거하는 방식으로 작동합니다.

- **Performance Highlights**: 결과적으로 이 확산 모델은 데이터 다양성과 이상치(outlier) 민감성과 같은 도전 과제를 극복하면서도 문화유산 기하학을 정확하게 재현할 수 있는 가능성을 보여줍니다. 이 연구는 AI 기술을 사용한 고대 유물 복원 방법론의 발전을 위한 기초를 마련하고 있습니다.



### Federated Data-Efficient Instruction Tuning for Large Language Models (https://arxiv.org/abs/2410.10926)
Comments:
          11 pages. Ongoing work

- **What's New**: 본 연구는 Federated Learning(FL) 환경에서 대규모 언어 모델(LLMs)의 지침 조정(instruction tuning) 시 데이터 효율성을 높이기 위한 새로운 접근법인 FedHDS를 제안합니다. 이는 적은 양의 데이터를 사용하여 LLM의 응답성을 개선합니다.

- **Technical Details**: FedHDS는 클라이언트 측에서 훈련 데이터의 중복성을 줄이기 위해 계층적 데이터 선택 프레임워크를 활용하여 대표적인 데이터 샘플을 선택합니다. 각 클라이언트의 로컬 데이터를 클러스터링하여 내부 데이터 중복성을 식별하고, 이를 서버에 전송하여 외부 데이터 중복성을 파악합니다.

- **Performance Highlights**: 실험 결과, FedHDS는 전체 데이터셋을 사용하는 기존의 페더레이티드 지침 조정 기법보다 10.72%의 Rouge-L 점수를 개선하면서, 필요한 데이터 양을 1.5% 미만으로 줄이는 성과를 보였습니다.



### A Benchmark Suite for Evaluating Neural Mutual Information Estimators on Unstructured Datasets (https://arxiv.org/abs/2410.10924)
Comments:
          NeurIPS 2024

- **What's New**: 이 연구는 이미지를 포함한 비정형 데이터셋에서 신경망 기반 상호 정보량 추정기(neural MI estimator)의 평가를 위한 종합적인 벤치마크를 도입합니다. 기존 연구의 제한을 보완하며 실제 데이터셋의 복잡성을 반영하기 위해 새로운 평가 방법을 제안합니다.

- **Technical Details**: 상호 정보량(Mutual Information, MI)의 정의 및 계산 방식을 설명하며, Gaussian 멀티변수 데이터셋에 대한 기존 연구의 한계를 지적합니다. 특히, 긍정적인 쌍(pairing)을 위한 동일 클래스 샘플링(same-class sampling) 접근 방식과 바이너리 대칭 채널(binary symmetric channel) 기법을 사용하여 MI 값을 정밀하게 조작합니다.

- **Performance Highlights**: 7가지 주요 요소에 따른 신경망 MI 추정기의 성능을 분석하며, 이미지와 텍스트 데이터셋에서 Gaussian 데이터셋보다 더 강력한 성능을 나타내는 경우를 발견했습니다. 또한, 정보 출처의 수가 많아질수록 MI 추정기가 더 신뢰할 수 있음을 관찰하였으며, MINE이 혼란(nuisance)에 대해 상대적으로 강건하다는 결과도 보고되었습니다.



### ATLAS: Adapter-Based Multi-Modal Continual Learning with a Two-Stage Learning Strategy (https://arxiv.org/abs/2410.10923)
- **What's New**: 본 논문에서는 다중 모달(multi-modal) 지속적 학습을 위한 새로운 접근 방식인 Adapter-based Multi-modal ConTinual Learning with A Two-stage Learning Strategy (ATLAS)를 제안합니다. 이 방법은 경험 기반 학습과 새로운 지식 확장을 포함하는 두 단계 학습 패러다임을 채택하고 있습니다.

- **Technical Details**: ATLAS는 경험 기반 학습(experience-based learning)과 새로운 지식 확장(novel knowledge expansion)을 통해 이전의 작업 지식을 효과적으로 활용하고 새로운 작업의 지식을 보완합니다. 이를 통해 지식의 중복성을 피하고, 모델의 표현을 풍부하게 하며, 업스트림(다중 작업) 시퀀스에서 다운스트림(특정 작업)에 대한 일반화 능력을 개선합니다.

- **Performance Highlights**: 실험 결과, ATLAS는 여러 작업에 대해 이전 작업의 잊혀진 정보를 최소화하면서 더 나은 일반화 능력을 보여주었고, 업스트림 작업에서의 학습이 다운스트림 작업에 긍정적인 영향을 미치는 것을 확인했습니다.



### Audio Captioning via Generative Pair-to-Pair Retrieval with Refined Knowledge Bas (https://arxiv.org/abs/2410.10913)
- **What's New**: 이 논문에서는 Retrieval-Augmented Generation (RAG) 기법을 활용하여 오디오 캡셔닝의 성능을 개선하는 방법을 제안합니다. 특히, 생성된 캡션을 활용한 pair-to-pair retrieval 방식을 통해 오디오-텍스트 쌍의 관련성을 높이는 새로운 접근법을 소개합니다.

- **Technical Details**: 본 연구에서는 오디오 쿼리를 텍스트 쿼리로 변환하는 생성적 pair-to-pair 검색 방법을 제안합니다. 이를 통해 멀티모달 쿼리를 고려하여 오디오-텍스트 쌍을 정확하게 검색하고, 맥락에 맞는 의도를 반영하는 정제된 지식 기반을 구축합니다. 여러 검색 방법과 지식 기반이 오디오-텍스트 쌍의 유사성과 성능에 미치는 영향을 분석하고 SOTA 성능을 달성했습니다.

- **Performance Highlights**: AudioCaps, Clotho, Auto-ACD와 같은 벤치마크에서 경량화된 RAG 접근법을 통해 오디오 캡셔닝에서 최첨단 성능을 달성했으며, 여러 ablation (변별) 연구로 이 방법의 효과를 입증하였습니다.



### 3DS: Decomposed Difficulty Data Selection's Case Study on LLM Medical Domain Adaptation (https://arxiv.org/abs/2410.10901)
- **What's New**: 이 논문에서는 Large Language Models(LLMs)의 특수한 도메인 적응을 위한 새로운 데이터 선택 프레임워크인 Decomposed Difficulty Data Selection (3DS)를 제안합니다. 3DS는 모델의 지식 분포에 맞춰 데이터를 최적화하여 적합한 도메인 적응을 보장합니다.

- **Technical Details**: 3DS는 두 단계로 구성됩니다. 1단계에서는 Prompt-Driven Data Selection via Explicit Alignment을 통해 모델이 내부 지식을 바탕으로 불필요하거나 중복된 데이터를 걸러냅니다. 2단계에서는 난이도 분해(Difficulty Decomposition)를 사용해 세 가지 메트릭인 Instruction Understanding, Response Confidence, Response Correctness에 따라 데이터를 선택합니다. 또한, 주의(attention) 기반의 중요도 가중치 메커니즘으로 토큰의 중요성을 캡처하여 난이도를 보다 정확하게 조정합니다.

- **Performance Highlights**: 의료 도메인 사례 연구에서, 실제 의료 데이터셋을 활용한 광범위한 실험 결과, 3DS가 기존 방법들보다 정확도에서 5.29% 이상 우수성을 보임을 입증했습니다.



### GPTON: Generative Pre-trained Transformers enhanced with Ontology Narration for accurate annotation of biological data (https://arxiv.org/abs/2410.10899)
Comments:
          25 pages, 6 figures

- **What's New**: 이번 연구는 GPT-4를 활용하여 구조적 지식을 LLM에 통합하는 새로운 시스템인 GPTON을 개발하였습니다. 이 시스템은 언어화된 온톨로지(ontology) 용어를 통해 생물정보학 연구의 발전에 기여하고자 합니다.

- **Technical Details**: GPTON은 언어 모델(Language Model)인 GPT-4를 이용하여 생물학적 유전자 세트에 대한 정확한 텍스트 및 온톨로지 주석(annotation)을 생성합니다. 연구 팀은 68% 이상의 정확도를 기록하며 유전자 세트 분석에서 높은 성과를 보였습니다.

- **Performance Highlights**: 수동 평가(manual evaluations)를 통해 GPTON의 강력한 성능이 확인되었으며, LLM과 구조적 지식을 활용함으로써 생물의학 연구를 유전자 세트 주석을 넘어서 크게 발전시킬 수 있는 가능성을 제시하였습니다.



### AT-MoE: Adaptive Task-planning Mixture of Experts via LoRA Approach (https://arxiv.org/abs/2410.10896)
- **What's New**: 이 논문은 기존 Mixture of Experts (MoE) 아키텍처의 한계를 극복하기 위해 Adaptive Task-planing Mixture of Experts (AT-MoE)라는 혁신적인 아키텍처를 소개합니다. AT-MoE는 특정 작업에 대한 전문가를 LoRA 방법을 통해 훈련하여 전문 분야에서의 문제 해결 능력과 해석 가능성을 높입니다.

- **Technical Details**: AT-MoE는 복잡한 작업 지침에 기반한 모듈 융합을 최적화하는 계층별 적응형 그룹 라우팅 모듈을 포함하여 다중 모듈 융합 접근 방식을 통해 시스템의 복잡한 문제 해결 능력을 향상시킵니다. 이 설계는 전문가 그룹의 차원에서 전체 가중치 할당을 수행한 후, 그룹 내에서 로컬 가중치 정규화 조정을 실시하여 다차원 균형, 제어 가능성 및 해석 가능성을 유지합니다.

- **Performance Highlights**: AT-MoE는 기존 MoE 아키텍처보다 훨씬 나은 성과를 보여 주며, 특히 의학 분야와 같이 높은 정확도가 요구되는 특정 작업에서 전문가의 전문성을 보장합니다. 이로 인해 진단 및 치료와 같은 복잡한 작업에 적합하며 기존의 한계를 극복할 가능성을 제시합니다.



### Fine-tuning can Help Detect Pretraining Data from Large Language Models (https://arxiv.org/abs/2410.10880)
- **What's New**: 이 논문은 Fine-tuned Score Deviation (FSD)라는 새로운 방법을 제안하여 사전 훈련 데이터 탐지의 성능을 개선합니다. 이는 모델이 미리 보지 못한 데이터를 소량으로 분석함으로써 사전 훈련 집합의 구성원과 비구성원 간의 차이를 늘리는 방법입니다.

- **Technical Details**: FSD는 특정 도메인(예: Wikipedia의 이벤트 데이터, arXiv 연구 논문)에서 모델을 미세 조정(fine-tuning)한 후의 점수 편차를 측정하여 구성원과 비구성원 간의 간격을 확장합니다. 기존 방법들에 비해, FSD는 소량의 보지 않은 데이터를 통해 비구성원의 점수를 크게 감소시켜 더 명확한 구분을 가능하게 합니다.

- **Performance Highlights**: 다양한 벤치마크 데이터셋(예: WikiMIA, ArXivTection)에서 FSD를 통해 기존 방법의 AUC score가 크게 향상되었으며, 예를 들어, WikiMIA에서 Min-k%의 경우 0.62에서 0.91로 증가했습니다. ArXivTection에서는 TPR@5%FPR 점수가 0.10에서 0.81로 개선되었습니다.



### Enhancing Vision-Language Model Pre-training with Image-text Pair Pruning Based on Word Frequency (https://arxiv.org/abs/2410.10879)
- **What's New**: 이번 논문은 Word-Frequency 기반 이미지-텍스트 쌍 가지치기(WFPP)라는 새로운 데이터 가지치기 방법을 제안하여 VLMs(비전-언어 모델)의 효율성을 향상시킵니다. 이 방법은 텍스트의 내용을 기반으로 텍스트-이미지 쌍을 선택하여 가지치기를 진행하며, 높은 빈도의 단어를 포함하는 쌍을 제거하여 단어 빈도 분포를 균형 있게 만듭니다.

- **Technical Details**: WFPP는 빈도가 높은 단어를 포함하는 텍스트가 있는 이미지-텍스트 쌍을 제거하여 훈련 데이터셋의 균형을 개선합니다. WFPP는 단어 확률에 기반하여 간단한 텍스트 수준 점수를 사용하여 가지치기를 수행하며, 텍스트에서 잦은 단어를 제거함으로써 전반적인 데이터의 다양성을 유지합니다. 최적의 결과를 위해, WFPP는 테스트 후 전체 데이터셋에 대해 1 에폭을 추가로 조정하여 성능을 개선합니다.

- **Performance Highlights**: WFPP를 적용하면 CLIP 모델의 훈련 성능이 저격 작업에서 향상됩니다. WFPP는 데이터를 효율적으로 가지치기하면서도 성능 저하 없이 학습 속도를 개선해줍니다. 제안된 방법을 통해 CLIP 모델은 다양한 하위 작업에서 성능이 향상되었으며, 제로샷 분류 및 이미지-텍스트 검색에서 우수한 결과를 보였습니다.



### Herald: A Natural Language Annotated Lean 4 Datas (https://arxiv.org/abs/2410.10878)
- **What's New**: 이 논문은 Mathlib4 코퍼스를 자연어로 번역하기 위한 새로운 프레임워크를 소개하고, 이를 기반으로 Lean 4 분석기를 활용한 이중 증강 전략을 적용하였습니다. 새로운 데이터셋인 Herald를 생성하고, 이를 통해 자연어-형식언어(NL-FL) 번역 모델의 성능을 향상시키는 방법을 제시합니다.

- **Technical Details**: 이 연구에서 제안하는 Herald 데이터셋은 Mathlib4에서 580k의 유효한 문장과 44k의 NL-FL 정리 쌍을 포함하고 있으며, 자연어 추론을 형식언어로 변환하는 과정에서 LLM(large language models)의 성능을 개선하는 구조적 정보를 제공합니다. 이 데이터셋은 '증분적 비형식화(informalization)'와 '형식화(formalization)' 과정을 통해 생성됩니다.

- **Performance Highlights**: Herald 번역기는 miniF2F-test에서 93.2% 정확도를 달성했으며, 내부 대학 교재 데이터세트에서 22.5%의 정확도로, 이전의 모델인 InternLM2-Math-Plus-7B와 TheoremLlama에 비해 현저히 높은 성능을 보였습니다. 또한 Stack 프로젝트의 섹션을 성공적으로 번역하여 대학 수준의 수학 문헌의 자동 형식화에서 중요한 진전을 이루었습니다.



### Improving Data Efficiency via Curating LLM-Driven Rating Systems (https://arxiv.org/abs/2410.10877)
- **What's New**: 이번 연구에서는 각종 대형 언어 모델(LLM)의 데이터 선택을 위한 새로운 방법인 DS2(Diversity-aware Score curation method)를 소개합니다. DS2는 LLM 기반의 점수에서 발생하는 오류 패턴을 분석하여 보다 정확하고 다양한 데이터를 선택할 수 있도록 합니다.

- **Technical Details**: DS2는 점수 전이 행렬(score transition matrix)을 활용하여 기존 LLM에서 생성된 점수의 오류를 수정하고, 데이터 샘플의 다양성을 보장합니다. 이 접근법을 통해 DS2가 선택한 3.3%의 데이터 서브셋이 300k 샘플의 전체 데이터보다 다양한 기계 정렬 벤치마크에서 더 우수한 성능을 보임을 입증했습니다.

- **Performance Highlights**: DS2를 통해 선택된 데이터에 대해 파인튜닝한 모델은 LIMA라는 인간 커리가 된 데이터셋보다도 뛰어난 성능을 나타냈습니다. 이는 기존의 데이터 스케일링 가정을 도전하며, 양질의 데이터 선택의 중요성을 강조합니다.



### Optimizing Transformer based on high-performance optimizer for predicting employment sentiment in American social media conten (https://arxiv.org/abs/2410.10874)
Comments:
          5 pages, 5 figures

- **What's New**: 본 연구는 군집 지능 최적화 알고리즘(optimization algorithm)을 기반으로 Transformer 모델을 개선하였으며, 미국 소셜 미디어에서의 고용 관련 텍스트 콘텐츠의 감정을 예측하는 것을 목표로 합니다.

- **Technical Details**: 텍스트 전처리(text preprocessing), 특징 추출(feature extraction) 및 벡터화(vectorization)를 통해 텍스트 데이터를 수치 데이터로 성공적으로 변환하였으며, 이를 모델 학습에 사용하였습니다. 실험 결과, 학습 과정 동안 모델의 정확도가 49.27%에서 82.83%로 증가하고, 손실 값(loss value)은 0.67에서 0.35로 감소하였습니다.

- **Performance Highlights**: 혼동 행렬(confusion matrix) 분석에 따르면, 학습 세트에서의 정확도는 86.15%이며, 테스트 세트에서도 82.91%의 좋은 성능을 보였습니다. 학습 세트와 테스트 세트 간의 정확도 차이는 3.24%에 불과하여 모델의 일반화 능력이 강함을 나타냅니다. 또한 Kappa 계수(Kappa coefficient)는 0.66, F-measure는 0.80으로, 소셜 미디어 감성 분석에서 모델의 효과성을 추가적으로 검증하였습니다.



### AuditWen:An Open-Source Large Language Model for Aud (https://arxiv.org/abs/2410.10873)
Comments:
          18 pages,1 figures

- **What's New**: 이번 연구에서는 Qwen을 기반으로 한 첫 번째 오픈소스 감사 대화형 대형 언어 모델 (LLM)인 AuditWen을 소개하며, 15개의 감사 작업과 28,000개의 지침 데이터를 통해 감사 분야에 특화된 모델을 구축했습니다.

- **Technical Details**: AuditWen은 3단계로 구성된 감사 작업을 위한 데이터셋을 활용하여 Qwen을 세부 조정한 모델입니다. 연구는 세 가지 유형의 필요(핵심 요구사항, 규제 요구사항, 파생 요구사항)로 감사에서의 LLM 적용 시나리오를 추출하였으며, 이를 바탕으로 3,000개의 지침을 포함한 평가 기준을 개발했습니다.

- **Performance Highlights**: 실험 결과 AuditWen은 질문 이해 및 답변 생성에서 기존의 LLM들과 비교하여 우수한 성능을 보였으며, 특히 감사 이슈 요약 및 법률 추천 작업에서 효과적입니다. AuditWen은 실제 감사 업무에 즉시 적용할 수 있는 값진 도구로 입증되었습니다.



### ToolBridge: An Open-Source Dataset to Equip LLMs with External Tool Capabilities (https://arxiv.org/abs/2410.10872)
Comments:
          technical report

- **What's New**: 이 논문은 ToolBridge라는 새로운 파이프라인을 통해 LLMs(대규모 언어 모델)가 외부 도구를 효과적으로 사용하는 방법을 학습할 수 있도록 지원하는 고품질의 공개 데이터셋을 만드는 과정을 설명합니다. 특히, 외부 도구 API 삽입을 위한 데이터 항목을 식별하는 전략을 제안하고, 이를 통해 LLM의 예측 정확도를 향상시키는 데 중점을 두고 있습니다.

- **Technical Details**: ToolBridge는 공개된 오픈 액세스 데이터셋을 원시 데이터셋 풀로 사용하여, 효과적인 LLM 교육을 위한 데이터 항목 선별, 변환, 필터링의 세 단계로 구성된 파이프라인을 제안합니다. 이 과정에서 LLM의 감독된 세밀 조정(Supervised Fine-Tuning, SFT)을 통해 정확도 향상을 위해 외부 도구를 적절한 맥락에서 호출할 수 있습니다.

- **Performance Highlights**: ToolBridge를 통해 훈련된 LLM은 여러 표준 벤치마크와 맞춤형 평가 데이터셋에서 일관된 성능 향상을 보여 주었습니다. 이 연구는 외부 도구와의 통합에서 LLMs의 교육 데이터를 공개하는 최초의 연구로, 연구자들이 다양한 분야에서 LLM의 외부 도구 사용하는 능력을 발전시킬 수 있을 것으로 기대됩니다.



### Applying Refusal-Vector Ablation to Llama 3.1 70B Agents (https://arxiv.org/abs/2410.10871)
- **What's New**: 최근 Llama 3.1 Instruct와 같은 언어 모델들이 자율적인 에이전트 행동을 할 수 있는 능력이 향상되었다. 본 연구에서는 Llama 3.1 70B 모델에 대해 거부 벡터 제거(refusal-vector ablation)를 적용하고 간단한 에이전트 구조를 구현하여 제한 없는 에이전트를 만들었다. 이 모델들이 위험한 작업을 성공적으로 수행할 수 있다는 점에서 현재의 안전 메커니즘에 큰 취약점이 존재함을 강조한다.

- **Technical Details**: 이 연구는 모델의 거부 행동이 잔여 스트림(residual stream)의 단일 방향에 의해 주로 매개되며, 이 방향을 제거하면 모델이 거부하지 않도록 생성할 수 있음을 보여준다. Llama 3.1 모델에 이 기술을 적용한 결과, 모델이 수정 없이도 많은 비윤리적 작업을 수행할 수 있음이 발견되었다. 또한 'Safe Agent Benchmark'라는 새로운 평가 기준을 도입하여 에이전트의 안전성과 능력을 테스트하는 방법론을 제시한다.

- **Performance Highlights**: Llama 3.1 70B 모델은 28개의 위험한 작업 중 18개를 수행할 의향이 있었으나, 대화 모드에서는 모든 28개 작업에 대해 어떻게 수행할지 조언을 거부했다. 이는 모델의 점점 더 향상된 능력이 악용될 위험을 증가시키며, 언어 모델 에이전트의 향상된 안전 프레임워크 필요성을 강조한다.



### PortLLM: Personalizing Evolving Large Language Models with Training-Free and Portable Model Patches (https://arxiv.org/abs/2410.10870)
- **What's New**: 이 연구에서는 PortLLM이라는 새로운 프레임워크를 소개합니다. 이 프레임워크는 특별한 훈련 없이 도메인 특정 지식을 지속적으로 전이할 수 있도록 설계되었습니다. 사용자가 이전의 모델에서 훈련된 지식을 기반으로 새로운 모델에 손쉽게 적용할 수 있는 기능을 제공합니다.

- **Technical Details**: PortLLM은 LoRA에서 파생된 모델 패치를 활용하여 사전 훈련된 LLM의 다양한 버전 간 도메인 지식을 전이합니다. 이 과정은 훈련 없이 실행되며, 이는 유지 관리 비용을 대폭 낮추고, GPU 메모리 사용량을 최대 12.2배까지 줄일 수 있습니다. 실험에서는 Mistral-7B, Llama2-7B, Llama3.1-8B, Gemma2-9B 등 다양한 모델 아키텍처에서의 효과를 검증하였습니다.

- **Performance Highlights**: PortLLM은 LoRA로 조정한 모델과 유사한 성능을 보이며, 효율적인 자원 사용을 통해 더 짧은 시간 안에 높은 성능을 달성합니다. 또한, 실험 결과는 다양한 타입의 질문 응답 및 추론 과제를 포함한 7개의 과제에서 긍정적인 결과를 보여주었습니다.



### Application of NotebookLM, a Large Language Model with Retrieval-Augmented Generation, for Lung Cancer Staging (https://arxiv.org/abs/2410.10869)
Comments:
          9 pages, 5 figures, 1 table, 3 ancillary files

- **What's New**: 최근 방사선학에서 대규모 언어 모델(LLMs), 특히 NotebookLM과 같은 RAG(검색 증강 생성) 기술이 주목받고 있습니다. 기존 LLMs의 신뢰성 문제를 해결하기 위해, RAG를 통해 증가된 신뢰할 수 있는 외부 지식(REK)을 활용한 연구가 진행되었습니다.

- **Technical Details**: 본 연구에서는 일본의 최신 폐암 병기 분류 지침을 REK로 제공하여, NotebookLM에 100개의 허구의 폐암 사례를 CT 소견을 기반으로 병기 분류하도록 하였습니다. 이 과정에서 gold-standard LLM인 GPT-4 Omni(GPT-4o)와 비교하였으며, 두 모델 모두 REK 활용 유무에 따른 성능을 평가했습니다.

- **Performance Highlights**: NotebookLM은 폐암 병기 분류 실험에서 86%의 진단 정확도를 기록하여, REK를 사용한 GPT-4o의 39% 및 REK 없이의 25%과 비교하여 월등한 성과를 보였습니다. 또한, NotebookLM은 REK 내에서의 참조 위치 검색에서 95%의 정확도를 보여 주목받고 있습니다.



### LLaCA: Multimodal Large Language Continual Assistan (https://arxiv.org/abs/2410.10868)
- **What's New**: 이번 논문에서는 Multimodal Large Language Models (MLLMs)의 능력과 제어 가능성을 향상시키기 위한 새로운 방법인 Multimodal Large Language Continual Assistant (LLaCA)를 제안합니다. 이는 균형 잡힌 업데이트를 통해 이전 데이터셋에서의 성능 저하를 방지하고, 지속적인 지시 학습을 개선하려는 목적을 가지고 있습니다.

- **Technical Details**: 이 연구는 Exponential Moving Average (EMA) 업데이트 정책을 사용하여 과거 매개변수를 추적하고, forgetting(망각)을 감소시키는 방법을 소개합니다. 또한, 이 논문은 손실 함수에서 Taylor 확장을 기반으로 최적의 균형 가중치를 결정하는 방법을 제안하며, 이는 gradient 정보와 이전 매개변수에 따라 달라집니다.

- **Performance Highlights**: 종합 실험 결과, LLaCA는 LLaVA-1.5 지속적인 시각 질문 답변 벤치마크에서 기존 방법과 비교하여 anti-forgetting 능력을 크게 향상시키고(기억 잃는 비율을 22.67에서 2.68로 감소), 평균 정확도를 41.31에서 61.89로 증가시켰습니다.



### Mitigating the Impact of Reference Quality on Evaluation of Summarization Systems with Reference-Free Metrics (https://arxiv.org/abs/2410.10867)
- **What's New**: 이 논문에서는 인간의 평가와 높은 상관관계를 가지면서 계산 비용이 매우 낮은 새로운 reference-free (참조 없는) 메트릭을 소개합니다.

- **Technical Details**: 제안된 메트릭은 기존의 reference-based (참조 기반) 메트릭과 함께 사용될 수 있으며, 저품질 참조 설정에서 메트릭의 견고성을 향상시킵니다. 특히 긴 문서의 요약에 대한 relevance (관련성)을 잘 나타냅니다.

- **Performance Highlights**: 이 메트릭은 인간의 평가와 높은 상관관계를 가지며, 저비용으로 계산 가능함을 보여줍니다.



### CodeUnlearn: Amortized Zero-Shot Machine Unlearning in Language Models Using Discrete Concep (https://arxiv.org/abs/2410.10866)
- **What's New**: 본 논문은 대규모 언어 모델(LLMs)의 민감한 정보를 삭제하는 새로운 방법인 제로샷 언러닝(zero-shot unlearning) 접근법을 제안합니다. 기존의 방법은 특화된 데이터 구조나 전체 재훈련이 필요한 반면, 본 연구는 정보 제어 및 흐름 조절을 위해 Sparse Autoencoders(SAEs)와 코드북을 활용합니다.

- **Technical Details**: 코드북 기능을 사용하여 언러닝을 조직화하는 본 접근법은 활성화 벡터를 코드북에 따라 변환하여 특정 주제와 연관된 정보를 효율적으로 식별하고 삭제하도록 합니다. 이 과정에서 벡터 양자화(Vector Quantization, VQ)를 이용해 잠재 공간을 구조화하고, 이산 표현(discrete representations)을 통해 정보를 선택적으로 제거하는 방식을 사용합니다.

- **Performance Highlights**: 본 연구에서는 제안한 방법이 기존의 기계 언러닝 기술에서 한 걸음 나아가 복잡한 언어 작업까지 적용되는 유용성을 입증하였습니다. 또한 선택적이고 효율적인 정보 삭제를 통해 모델의 성능을 유지하면서 민감한 정보를 안전하게 제거할 수 있음을 보여주었습니다.



### Generating Synthetic Datasets for Few-shot Prompt Tuning (https://arxiv.org/abs/2410.10865)
- **What's New**: 이번 논문에서는 few-shot learning 환경에서의 prompt tuning의 한계를 극복하기 위해 LLMs(대형 언어 모델)를 활용하여 특정 작업에 맞는 레이블이 있는 데이터를 합성하는 방법을 제안합니다. 특히, Distribution-Aligned Weighted generator tuning (DawGen)이라는 새로운 방법론을 소개하며, gradient surgery를 이용해 서로 다른 데이터 소스 간의 상충하는 그래디언트를 제거하는 방식을 채택하였습니다.

- **Technical Details**: 제안된 방법은 세 단계로 나뉘며, 첫째로, 제한된 수의 실제 샘플을 통해 소프트 프롬프트를 학습합니다. 둘째로, 적응된 생성기를 통해 합성 훈련 세트를 생성합니다. 셋째로, 합성 데이터와 실제 데이터를 결합하여 소프트 프롬프트를 훈련하여 판별 LLM에 적용합니다.

- **Performance Highlights**: 7개의 문장 쌍 분류 데이터셋에서 실험한 결과, 제안된 방법이 few-shot learning 설정에서 prompt tuning의 효과를 크게 향상시킴을 보여주었습니다. 특히, 102K 파라미터로 구성된 PT가 770M 파라미터의 FT보다 뛰어난 성능을 보였으며, QQP, MRPC, SICK 데이터셋에서 대규모 실제 데이터셋을 사용한 전이 학습과 비교하여 유사한 성능을 달성했습니다.



### Fill In The Gaps: Model Calibration and Generalization with Synthetic Data (https://arxiv.org/abs/2410.10864)
Comments:
          Accepted to EMNLP 2024 Main Conference (Long paper)

- **What's New**: 본 연구에서는 합성 데이터(synthetic data)를 활용한 새로운 모델 캘리브레이션(calibration) 방법을 제안합니다. 기존의 캘리브레이션 방법이 모델의 정확도(accuracy)를 저하시킬 수 있는 문제를 해결하고, Expected Calibration Error (ECE)를 줄이며, 모델의 정확도를 유지하는 전략을 사용했습니다.

- **Technical Details**: 모델 캘리브레이션을 위한 방법론은 Probably Approximately Correct (PAC) 학습 프레임워크를 기반으로 하며, 합성 데이터를 생성하는 데 오픈 소스의 대형 언어 모델(Large Language Model)인 Llama 2를 활용합니다. 이 방법은 자연어 처리(NLP) 작업에서 모델의 성능을 개선하기 위해 고안되었습니다.

- **Performance Highlights**: 모델을 네 가지 자연어 처리 작업에 대해 테스트한 결과, 평균 34%의 정확도 향상과 33%의 ECE 감소를 관찰했습니다. 이는 합성 데이터가 모델의 예측 불확실성(calibration)을 줄이는 데 효과적임을 보여줍니다.



### What makes your model a low-empathy or warmth person: Exploring the Origins of Personality in LLMs (https://arxiv.org/abs/2410.10863)
Comments:
          under review

- **What's New**: 본 연구는 대형 언어 모델(LLMs)이 어떻게 장기적인 배경 요인과 단기적인 압력을 통해 인격 특성을 표현하는지를 탐구합니다. 특히, 사회 결정론 이론을 바탕으로 LLM의 성격 형성 과정에 대한 심층 분석을 제공합니다.

- **Technical Details**: 저자들은 Sparse Autoencoder(SAE) 및 representation-based 방법론을 활용하여 LLM의 장기 및 단기 인격 특성을 추출하고 분석합니다. 이를 통해 각각의 배경 요인이 모델의 인격과 안전성에 미치는 영향을 평가하며, Big Five Inventory(BFI) 및 Short Dark Triad(SD-3) 같은 인물 테스트를 통해 LLM의 인격을 평가합니다.

- **Performance Highlights**: 이 연구는 LLM의 인격 조정을 위한 새로운 기법을 제시하고, 모델의 행동을 세밀하게 수정하는 방법을 제공합니다. 또한, 배경 요인이 LLM의 안전성 평가에 미치는 영향을 분석하고, Personality-driven 요인이 LLM의 어두운 특성에 기여할 수 있는 가능성을 탐색합니다.



### Superficial Safety Alignment Hypothesis (https://arxiv.org/abs/2410.10862)
- **What's New**: 이 논문에서는 안전 제어(safety alignment)와 일반 제어(alignment) 사이의 간극을 해소하기 위해 'Superficial Safety Alignment Hypothesis (SSAH)'를 제안합니다. 이 가설은 안전 제어가 모델이 올바른 추론 방향을 선택하도록 가르쳐야 한다고 주장합니다.

- **Technical Details**: 이 연구에서는 안전 제어가 효과적으로 이루어지기 위해서는 특정 안전-critical component를 동결(freeze)하고 여분의 유닛(redundant units)을 재사용하는 것이 필요하다고 설명합니다. 특히 Exclusive Safety Unit (ESU), Exclusive Utility Unit (EUU), Complex Unit (CU), Redundant Unit (RU) 등 4가지 주목할 만한 유닛을 식별했습니다.

- **Performance Highlights**: 모델의 fine-tuning 중 7.5%의 안전-critical component를 동결하는 방식으로 모델의 안전 특성을 유지하면서 새로운 작업에 적응할 수 있음을 발견했습니다. 또한, 사전 훈련된 모델에서 20%의 여분의 유닛을 'alignment budget'으로 활용하여 안전 제어 목표를 효과적으로 달성할 수 있다는 사실을 보여주었습니다.



### A Recipe For Building a Compliant Real Estate Chatbo (https://arxiv.org/abs/2410.10860)
- **What's New**: 최근 대규모 언어 모델 (large language models, LLMs)을 사람의 선호에 맞게 조정하기 위한 노력이 증가하고 있습니다. 이번 연구는 부동산 분야에 특화된 챗봇 개발에 중점을 두고 있으며, 차별적 관행인 스티어링 (steering)과 레드라이닝 (redlining)을 지속하지 않도록 준수를 강조합니다. 우리는 일반 지침 준수 데이터 세트를 생성하고, 안전 데이터를 포함하여 Лlama-3-8B-instruct 모델을 미세 조정하면서 GPT-4o와 같은 대형 닫힌 소스 모델과 경쟁할 수 있는 성능을 입증했습니다.

- **Technical Details**: 우리는 일반적인 지침 작업과 부동산 분야의 법적, 윤리적 준수 시나리오를 결합한 합성 데이터 세트를 생성했습니다. 이를 활용해, 법적 및 윤리적 기준에 철저히 따라 유용한 부동산 정보를 제공하고, llama3-70b-instruct 보다 높은 성능을 발휘하면서도 보다 안전하고 준수된 응답을 생성하는 모델을 개발했습니다. 또한, 안전성과 유용성을 평가하기 위한 네 가지 모델 기반 지표와 두 개의 모델 기반 심사자를 도입했습니다.

- **Performance Highlights**: 최종 결과들은 법적 규정 준수에 초점을 맞추어 데이터 및 튜닝을 진행함으로써 부동산 애플리케이션에서 LLM의 안전성과 유용성을 현저히 향상시킬 수 있음을 보여주었습니다. 제안된 모델은 부동산 작업에서 비례적으로 86% 더 선호되며, 우리의 안전 및 준수 기준 벤치마크에서 성능이 크게 향상되었습니다.



### FAME: Towards Factual Multi-Task Model Editing (https://arxiv.org/abs/2410.10859)
Comments:
          9 pages, 3 figures

- **What's New**: 이번 연구의 핵심은 모델 편집(model editing)의 실용성을 강조하며, 실제 응용에서의 효과성을 담보하는 새로운 데이터셋 FAME과 모델 편집 방법 SKEME를 제안한다는 점입니다.

- **Technical Details**: FAME은 128,000개의 사실 기반 데이터 항목으로 구성되며, 다양한 단일 및 다단계 질문으로 이루어진 과제를 포함하여 표준화된 모델 편집 기준인 Practicality를 도입한다. SKEME는 신선한 캐싱 메커니즘(caching mechanism)을 활용하여 모델의 지식을 실시간으로 업데이트할 수 있도록 설계되었다.

- **Performance Highlights**: 실험 결과, SKEME는 모든 실험 조건에서 다른 방법들과 비교하여 뛰어난 성능을 발휘하였으며, 실질적인 상황에 잘 부합하는 효과적인 모델 편집 방법임을 증명하였다.



### Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths (https://arxiv.org/abs/2410.10858)
Comments:
          EMNLP 2024 camera ready version

- **What's New**: 이번 연구에서는 Reasoning Paths Optimization (RPO)라는 새로운 훈련 프레임워크를 소개하여 언어 모델의 다음 단계 추론 능력을 개선하는 방법을 제안합니다.

- **Technical Details**: RPO는 다양한 경로에서 추론을 학습하고 탐색할 수 있도록 설계되어, 각 추론 단계에서 유리한 경로를 장려하고 불리한 경로를 처벌하여 모델의 문제 해결 능력을 향상시킵니다. 이 방법은 대규모 인간 주석을 받거나 폐쇄형 모델의 출력을 의존하지 않기 때문에 확장 가능하고 데이터 효율적입니다.

- **Performance Highlights**: 실험 결과, RPO는 대규모 언어 모델의 추론 성능을 크게 개선하여, GSM8K에서 3.1%, MMLU (STEM)에서 4.3%의 성능 향상을 보여주었습니다.



### Mirror-Consistency: Harnessing Inconsistency in Majority Voting (https://arxiv.org/abs/2410.10857)
Comments:
          EMNLP 2024 Short Findings

- **What's New**: 이번 논문에서는 기존의 Self-Consistency 방식의 한계를 극복하기 위해 Mirror-Consistency라는 새로운 방법론을 제안하였습니다. 이 방법은 다수결의 원칙에 의존하면서도 의견의 일관성을 분석하고, 소수의 응답에서 나타나는 불일치를 학습하여 LLM의 추론 능력을 개선하는 데 초점을 맞춥니다.

- **Technical Details**: Mirror-Consistency는 LLM이 재표집된 응답의 불일치를 분석하도록 하여, 다수결의 결과와의 차이를 반영하여 피드백을 제공하는 방식으로 접근합니다. 이 과정은 Reflection on Inconsistency와 Conditional Resampling 단계로 구성됩니다. 또한, 응답 간의 일관성을 기반으로 LLM의 신뢰도를 조정하는 방법으로도 활용됩니다.

- **Performance Highlights**: Mirror-Consistency는 Self-Consistency에 비해 추론의 정확성과 신뢰도 조정 모두에서 향상된 성능을 보였습니다. 실험 결과, 네 가지 추론 데이터셋과 네 가지 LLM를 사용하여 Mirror-Consistency의 효과성을 검증하였으며, 불일치 분석이 성능 향상에 기여함을 보여주었습니다.



### CogDevelop2K: Reversed Cognitive Development in Multimodal Large Language Models (https://arxiv.org/abs/2410.10855)
- **What's New**: 이 논문은 Multi-modal Large Language Models (MLLMs)의 인지 능력을 평가하는 새로운 벤치마크인 CogDevelop2K를 제안합니다. 이 벤치마크는 인간의 인지 발달 과정을 구조화해 12개의 하위 개념을 포괄하며, MLLMs의 진정한 이해 능력과 작업 수행 능력을 탐구하는 데 중점을 둡니다.

- **Technical Details**: CogDevelop2K는 2519개의 질문과 2517개의 이미지, 455개의 비디오로 구성되어 있으며, MLLMs의 코어 인지 능력을 4단계의 인지 발달 무대로 평가합니다. 이 논문은 Jean Piaget의 인지 발달 이론을 기반으로 하여 MLLMs의 역동적인 인지 발달 추세를 조사하며, 코어 인지 과업 수행이 MLLMs의 진정한 지식, 추론 및 지각 능력을 이해하는 데 중요한 인사이트를 제공함을 강조합니다.

- **Performance Highlights**: 46개 MLLM 모델을 평가한 결과, 몇 가지 놀라운 경향이 확인되었습니다. MLLM 모델은 인간의 인지 발달 경로와 반대되는 경향을 보였으며, 예를 들어 GPT 시리즈는 형식적 조작 단계에서 더 나은 성능을 보였으나 구체적 조작 단계에서는 저조한 성능을 나타냈습니다. 이 연구는 MLLM의 성능 향상 방법인 prompting 기술이 모델 성능을 8.1% 향상시킬 수 있음을 시사합니다.



### Plausibly Problematic Questions in Multiple-Choice Benchmarks for Commonsense Reasoning (https://arxiv.org/abs/2410.10854)
Comments:
          EMNLP 2024 Camera Ready

- **What's New**: 이 논문은 일상적인 상황에 대한 상식 추론을 위한 여러 선택 질문(MCQ)에서의 올바른 답변 선정 기준을 새롭게 제시합니다. 250개의 MCQ 항목을 샘플링하고, 5,000개의 독립적인 타당성 판단을 수집함으로써, 과거의 기준에서는 부합하지 않는 20% 이상의 문항을 발견하였습니다.

- **Technical Details**: 저자는 Social IQa와 CommonsenseQA라는 두 개의 주요 MCQ 벤치마크를 분석했습니다. 각 MCQ에 대해 5점 리커트 척도를 사용하여 개별 답변의 타당성을 평가하고, 인간 주석자의 다수결에 의해 선정된 원래의 답변과 비교했습니다.

- **Performance Highlights**: 대규모 언어 모델(LLM) 실험 결과, 저성능과 높은 변동성을 보여주며, 이 연구의 타당성 기준이 상식 평가를 위한 더 신뢰할 수 있는 벤치마크 항목 식별에 도움을 줄 수 있음을 나타냈습니다.



### Mitigating Hallucinations Using Ensemble of Knowledge Graph and Vector Store in Large Language Models to Enhance Mental Health Suppor (https://arxiv.org/abs/2410.10853)
- **What's New**: 이 연구는 대형 언어 모델(LLMs)에서 발생하는 환각(hallucination)의 효과와 이를 줄이기 위한 전략을 탐구합니다. 특히 정신 건강(intervention) 분야에서 LLM의 신뢰성(reliability) 및 안정성(security)을 높이는 데 중점을 두고 있습니다.

- **Technical Details**: 이 연구에서는 Google Gemma, Mistral 및 Zypher와 같은 오픈소스 LLM을 활용하여 정신 건강 관련 질문에 대한 답변을 생성하였습니다. 제안된 해결책은 벡터 스토어(vectors store) 검색과 지식 그래프(knowledge graph) 검색의 장점을 결합하여 LLM의 환각을 줄이는 방법을 제시합니다. Ensemble RAG 모델을 통해 정보 검색을 개선하고, 쿼리 프로세서, 벡터 스토어 리트리버(vector store retriever), 지식 그래프 리트리버(knowledge graph retriever), 융합 모듈(fusion module)로 구성된 시스템을 설계하였습니다.

- **Performance Highlights**: 이 연구는 LLM이 제공하는 정보의 품질과 관련성을 높여 환각을 줄이는 것을 목표로 하고 있으며, 정신 건강 지원을 위한 더 나은 프레임워크를 구축하는 데 기여하고자 합니다. 특히, LLM의 다중 작업 지식을 향상시키고, 사실적으로 정확한 정보를 제공하여 정신 건강 지원을 더욱 효율적으로 만들어 갈 것입니다.



### SafeLLM: Domain-Specific Safety Monitoring for Large Language Models: A Case Study of Offshore Wind Maintenanc (https://arxiv.org/abs/2410.10852)
- **What's New**: 이번 연구는 Offshore Wind (OSW) 산업의 Operations & Maintenance (O&M) 비용을 절감하기 위해 Large Language Models (LLMs)를 활용한 혁신적인 접근 방식을 제안합니다. 특히, 통계 기법을 통해 문장 간 거리를 계산하여 hallucination과 안전하지 않은 출력을 감지하고 필터링하는 대화형 에이전트를 소개합니다.

- **Technical Details**: 제안된 방법론은 SafeLLM이라고 하며, ChatGPT-4 생성 테스트 문장에 적용된 초기 결과를 바탕으로 합니다. 이 연구는 SCADA 시스템에서 가져온 경고 데이터를 분석하고, 입력과 출력의 안전성을 확보하기 위한 방법을 논의합니다.

- **Performance Highlights**: 첫 번째 결과는 OSW 경고 시퀀스를 개선된 해석 가능성 및 안전한 수리 작업 제안과 함께 보여주며, 재훈련을 통한 성능 향상의 가능성에 대해 논의합니다.



### LLM Gesticulator: Leveraging Large Language Models for Scalable and Controllable Co-Speech Gesture Synthesis (https://arxiv.org/abs/2410.10851)
- **What's New**: 이번 연구에서는 LLM 기반의 오디오 드리븐 동작 생성 프레임워크인 LLM Gesticulator를 제안합니다. 이 프레임워크는 입력 오디오와 일치하여 리드미컬하게 조화를 이루는 전체 신체 애니메이션을 합성하며, 자연스러운 움직임과 편집 가능성을 제공합니다. LLM Gesticulator는 기존 작업에 비해 상당한 확장성을 보여줍니다.

- **Technical Details**: 우리의 프레임워크는 큰 언어 모델(LLM)을 기반으로 하여 음성에 맞춘 전체 신체 제스처를 생성하는 새로운 방식을 제안합니다. 우리는 제스처 생성 문제를 시퀀스-투-시퀀스 변환 작업으로 모델링하였으며, 사용자에게 텍스트 프롬프트를 통해 제스처 내용을 제어할 수 있는 기능을 제공합니다. 데이터 증강 기법으로 BEAT 데이터 세트의 모션 설명을 주석 처리하고 이를 커뮤니티에 제공할 예정입니다.

- **Performance Highlights**: 평가 지표 및 사용자 연구 결과, 우리의 프레임워크가 이전 작업보다 우수한 성능을 보여주었으며, 사용자는 텍스트 프롬프트에 따라 생성되는 제스처의 스타일과 내용을 제어할 수 있습니다.



### On the Reliability of Large Language Models to Misinformed and Demographically-Informed Prompts (https://arxiv.org/abs/2410.10850)
Comments:
          Study conducted between August and December 2023. Submitted for archival purposes only

- **What's New**: 본 연구는 Large Language Model (LLM) 기반 챗봇들이 잘못된 프롬프트와 질문을 어떻게 처리하는지 조사하였다. 기후 변화 및 정신 건강 분야에서 이 챗봇들의 정보 진실성 판단 능력, 사실 준수, 편향 존재 여부를 평가하였다.

- **Technical Details**: LLM 챗봇의 성능은 True/False 질문을 통한 정량적 분석으로 측정되었으며, 질적 통찰은 도메인 전문가와의 협력을 통해 수집되었다. 세 개의 LLM 기반 챗봇(ChatGPT, Bing Chat, Google BARD)을 분석하여 기후 변화와 정신 건강 관련 질문에 대한 응답을 평가하였다.

- **Performance Highlights**: 챗봇들은 True/False 질문에 대한 올바른 답변을 제공할 수 있었지만, 전문가 의견에 따르면 개인정보 보호, 윤리적 문제 및 전문 서비스로 사용자 안내의 필요성이 여전히 우려되었다. 챗봇들은 민감한 분야에서 신중하게 구현되어야 한다는 결론에 도달했다.



### Continuous Approximations for Improving Quantization Aware Training of LLMs (https://arxiv.org/abs/2410.10849)
- **What's New**: 본 연구는 Quantization Aware Training (QAT) 방법론을 확장하여 모델 압축에서 성능 저하를 최소화하기 위한 두 가지 연속 근사를 소개합니다. 이 방법은 기존의 Straight-Through Estimator (STE) 및 클램핑 함수의 접근을 개선하여 더 나은 성능을 달성했습니다.

- **Technical Details**: 제안된 방법에는 Sigmoid STE와 SoftClamp가 포함되어 있습니다. Sigmoid STE는 QAT에서 반올림 함수의 연속 근사로 사용되며, SoftClamp는 입력 값이 특정 범위 내에 제한되도록 하는 기능을 제공합니다. 이를 통해 QAT 과정에서 더 안정적이고 정확한 학습이 가능해집니다.

- **Performance Highlights**: WikiText-v2 데이터셋에서 양자화된 모델의 perplexity (PPL)는 9.0815로, 이전의 9.9621보다 우수한 성능을 보였습니다. BoolQ에서는 2.76%, MMLU에서는 5.47%의 성능 개선을 달성하여, 에너지 효율적인 LLM 개발에 기여할 수 있는 가능성을 보여줍니다.



### Crafting Narrative Closures: Zero-Shot Learning with SSM Mamba for Short Story Ending Generation (https://arxiv.org/abs/2410.10848)
Comments:
          9 pages

- **What's New**: 이 논문은 주어진 프롬프트에 기반하여 이야기를 완성하는 도구를 개발하고, 이를 통해 작가의 창의적 장애(Writer's Block)를 극복하는 혁신적인 솔루션을 제공합니다. 또한 사용자가 짧은 이야기 프롬프트를 입력할 경우, AI의 창의력으로 이야기를 한 문장으로 요약해주는 기능을 제공합니다.

- **Technical Details**: 본 연구에서는 고급 텍스트 생성 모델을 개발하여 주어진 입력에 대해 읽을 수 있는 적절한 결론을 도출하는 방법을 제안합니다. GPT-3.5 모델과 새로운 SSM-Mamba 모델을 포함한 총 네 가지 모델을 사용하여 구현하였고, fine-tuning(모델의 세부 조정)에는 LoRa, PEFT, SFTTrainer 등의 기술이 활용되었습니다.

- **Performance Highlights**: SSM-Mamba 모델이 박사 과정에서의 성과를 기록하였으며, BERT score, METEOR, BLEU, ROUGE, Perplexity 등의 다양한 지표에서 우수한 성능을 나타냈습니다. 이 도구는 Open Source로 제공되어, 창작 및 개인 이야기 확장을 위한 최신 AI 기술에 대한 접근성을 높였습니다.



### Focus On What Matters: Separated Models For Visual-Based RL Generalization (https://arxiv.org/abs/2410.10834)
- **What's New**: 본 논문은 이미지 재구성을 활용하여 일반화 능력을 향상시키기 위한 새로운 접근법인 SMG(Separated Models for Generalization)를 제안합니다. SMG는 시각적 관찰에서 과제 관련(task-relevant)과 과제 비관련(task-irrelevant) 표현을 구분하여 추출하는 두 개의 모델 브랜치를 도입합니다.

- **Technical Details**: SMG는 두 개의 일관성 손실(consistency losses)을 추가하여 다양한 시나리오에서 과제 관련 영역에 대한 에이전트의 초점을 유도합니다. 이 구조는 단일 모델 구조에서 발생할 수 있는 과제 비관련 특징에 대한 과적합(overfitting) 위험을 회피하며, 안정적인 과제 관련 표현을 추출하게 합니다.

- **Performance Highlights**: SMG는 DMC에서의 광범위한 실험을 통해 일반화 성능에서 SOTA(state-of-the-art)를 달성하였으며, 비디오 배경 설정 및 로봇 조작 작업에서 특히 우수한 성능을 보여주었습니다.



### Online Client Scheduling and Resource Allocation for Efficient Federated Edge Learning (https://arxiv.org/abs/2410.10833)
Comments:
          13 pages, 6 figures

- **What's New**: 본 논문에서는 리소스 제약 및 불확실성을 고려하여 모바일 엣지 네트워크에서의 연합 학습(Federated Learning, FL)을 위한 최적 클라이언트 스케줄링 및 자원 할당을 탐구합니다. 이를 통해 훈련 지연 시간을 최소화하고 모델 정확도를 유지하려는 방법을 제시합니다.

- **Technical Details**: 연구에서는 다양한 클라이언트 샘플링이 FL의 모델 수렴에 미치는 영향을 분석하고, 이종 시스템 자원 하에서 실행 시간과 모델 성능 간의 트레이드오프를 캡처하는 확률적 최적화 문제를 설정합니다. 리아푼노프 최적화 기반의 온라인 제어 방식을 통해 클라이언트 샘플링과 자원 할당을 구현합니다.

- **Performance Highlights**: 제안된 방법은 CIFAR10 및 FEMNIST 데이터셋을 사용한 실험에서 기존 방법보다 훈련 지연 시간을 50.1%까지 절감하는 성과를 보였으며, 높은 자원 효율성과 더불어 모델 정확도를 향상시켰습니다.



### Focused ReAct: Improving ReAct through Reiterate and Early Stop (https://arxiv.org/abs/2410.10779)
Comments:
          The Eighth Widening NLP Workshop (WiNLP 2024)

- **What's New**: Focused ReAct는 기존 ReAct 방법을 개선하여 질문에 집중하고 반복 행동을 피할 수 있도록 설계되었습니다.

- **Technical Details**: Focused ReAct는 'reiterate'와 'early stop' 메커니즘을 포함하여 원본 질문을 각 추론 단계에서 반복적으로 강조합니다. 이 과정에서 모델이 동일한 행동을 반복할 경우 조기 종료 요청을 하여 정확한 답변으로 매진하게 합니다.

- **Performance Highlights**: Focused ReAct는 정확도가 18%에서 530% 향상되었으며, 모델 크기에 따라 최대 34%의 런타임 감소를 보여주었습니다.



### AFlow: Automating Agentic Workflow Generation (https://arxiv.org/abs/2410.10762)
- **What's New**: 최근 대형 언어 모델(LLMs)의 워크플로우 최적화 자동화 필요성이 대두되었습니다. 기존의 방법들은 수동 설정에 의존하였으나, 본 연구에서는 워크플로우 최적화를 코드로 표현된 워크플로우에 대한 검색 문제로 재구성했습니다.

- **Technical Details**: AFlow라는 자동화 프레임워크를 소개하며, Monte Carlo Tree Search 기법을 활용하여 코드 수정을 통한 반복적 워크플로우 개선을 진행합니다. 이 과정에서는 트리 구조의 경험과 실행 피드백을 사용합니다.

- **Performance Highlights**: 여섯 개의 벤치마크 데이터셋에서의 실험 평가 결과, AFlow는 최신 기준선에 비해 5.7%의 평균 개선을 보여주었으며, AFlow를 사용하면 더 작은 모델도 특정 작업에서 GPT-4o를 4.55%의 비용으로 능가할 수 있습니다.



### NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models (https://arxiv.org/abs/2410.10743)
- **What's New**: 본 연구에서는 Node Tokenizer for Large Language Models (NT-LLM)라는 새로운 프레임워크를 소개합니다. NT-LLM은 주요 노드를 앵커로 선택하고 각 노드를 이러한 앵커와의 상대적 거리를 기반으로 표현함으로써 그래프 구조를 효율적으로 인코딩합니다.

- **Technical Details**: NT-LLM은 positional encoding 기법을 이용해 그래프의 토폴로지를 효과적으로 포착하고, LLM의 그래프 데이터에 대한 추론 능력을 향상시킵니다. 이 프레임워크는 Graph Neural Networks (GNN)와의 조합을 통해 spatial position 이해의 부담을 줄입니다.

- **Performance Highlights**: 광범위한 실험 평가를 통해 NT-LLM은 다양한 그래프 관련 과제에서 우수한 성능 향상을 보여주었습니다.



### SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing (https://arxiv.org/abs/2410.10741)
- **What's New**: 이 논문은 Large Language Models(LLMs)를 센서 데이터 처리에 적용하기 위한 포괄적인 벤치마크인 SensorBench를 구축하고, LLM의 성능을 기존의 엔지니어링 전문가와 비교합니다. 또한 LLM의 처리 능력을 향상시키기 위한 다양한 프롬프트 방법을 조사합니다.

- **Technical Details**: SensorBench는 다양한 실제 센서 데이터셋을 포함하여 LLM의 성능을 체계적으로 평가할 수 있는 기준을 제공합니다. 4가지 프롬프트 전략을 실험하며, 그 중 self-verification 방법이 48%의 작업에서 가장 우수한 성과를 나타냅니다.

- **Performance Highlights**: LLMs는 간단한 작업에서는 전문가와 비슷한 성능을 보이나, 복잡한 조합적 작업 및 파라미터 선택에서는 어려움을 겪습니다. 전체 성능 비교에서 LLMs는 특정 작업에서 우수한 성과를 거뒀으며, 피어 전문가들과의 비교를 통해 현재 LLM의 제한점을 명확히 드러냈습니다.



### Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning (https://arxiv.org/abs/2410.10735)
- **What's New**: 이 연구에서는 Chain of Self-Correction (CoSC)라는 새로운 메커니즘을 소개하며, 이를 통해 대형 언어 모델(LLMs)이 스스로 결과를 검증하고 수정할 수 있는 능력을 내장할 수 있게 됩니다. 이 두 단계의 수정 과정을 통해 수학적 추론의 정확성을 현저히 향상시킬 수 있습니다.

- **Technical Details**: CoSC 메커니즘은 LLM이 주어진 문제를 해결하기 위해 프로그램을 생성하고, 프로그램 기반 도구를 사용하여 출력을 얻고, 해당 출력을 검증하는 단계로 구성됩니다. 이를 통해 LLM은 반복적인 자기 수정 과정을 수행하여 수학적 추론을 강화합니다. 두 단계의 파인튜닝(phase finetuning) 접근 방식이 사용되며, 첫 번째 단계에서는 GPT-4에서 생성된 소량의 데이터로 초기 CoSC 능력을 구축하고, 두 번째 단계에서는 훈련된 모델을 사용하여 자가 생성된 대량의 데이터를 통해 CoSC 능력을 향상시킵니다.

- **Performance Highlights**: CoSC 메커니즘은 공개된 수학적 데이터셋에서 기존의 오픈 소스 LLM들과 비교했을 때 성능을 크게 향상시키며, CoSC-Code-34B 모델은 MATH 데이터셋에서 53.5%의 성능을 기록하여 ChatGPT, GPT-4 및 다중 모달 LLMs인 GPT-4V 및 Gemini-1.0 Pro를 초월하는 성과를 보였습니다.



### Intelligent prospector v2.0: exploration drill planning under epistemic model uncertainty (https://arxiv.org/abs/2410.10610)
- **What's New**: 이 논문에서는 지질학적 불확실성에 대한 선험 모델(prior model)을 도입하여 최적의 데이터 획득(data acquisition) 전략을 수립하는 Intelligent Agent를 개발합니다.

- **Technical Details**: 이 연구는 부분 관찰 가능한 마르코프 의사 결정 과정(partially observable Markov decision processes)을 기반으로 하는 Intelligent Agent를 사용하여 여러 지질학적 가설(hypotheses)에 대한 최적의 데이터 획득 계획을 세웁니다. 이를 통해 인간이 정의한 가설이 부정확할 경우 조기에 탐지할 수 있는 방법을 제공합니다.

- **Performance Highlights**: 2023년에는 잠비아에서의 초고품질 구리 매장지의 특성화를 지원하는 데 이 알고리즘이 성공적으로 적용되었습니다.



### Neural networks that overcome classic challenges through practic (https://arxiv.org/abs/2410.10596)
- **What's New**: 최근 메타러닝 (metalearning) 방법이 체계성 (systematicity) 및 재앙적인 망각 (catastrophic forgetting) 문제를 해결하기 위한 유망한 접근법으로 제안되었습니다. 우리의 리뷰는 이러한 방법들이 전통적인 접근법과 어떻게 다른지를 보여줍니다.

- **Technical Details**: 메타러닝을 통해 기계는 개선할 목표 X에 대한 인센티브와 연습 기회를 제공받게 됩니다. 이는 관련 목표의 일반화를 통한 방식과 차별화됩니다. 우리는 시스템적 일반화, 재앙적 망각, 소수의 예로 학습 (few-shot learning), 다단계 추론 (multi-step reasoning) 등 4개의 고전적 문제에 대한 응용을 검토합니다.

- **Performance Highlights**: 제안된 메타러닝 기법은 합성적지만 본질적인 과제를 효과적으로 해결하며, 기계 학습의 인간 학습 및 개발 과정을 이해하는 데 기여할 수 있는 프레임워크를 제공합니다.



### TRESTLE: A Model of Concept Formation in Structured Domains (https://arxiv.org/abs/2410.10588)
Comments:
          20 pages, 6 figures, 1 table

- **What's New**: 본 논문에서는 TRESTLE이라는 새로운 개념 형성 모델을 제안합니다. 이는 인간의 학습 과정을 고려한 확률적 개념 형성의 점진적 모델로, 기존의 모델들을 통합하여 구조화된 도메인에서 작동합니다.

- **Technical Details**: TRESTLE는 계층적 분류 트리를 생성하여, 누락된 속성 값을 예측하고 예시 집합을 개념적으로 의미 있는 그룹으로 클러스터링하는 방식으로 작동합니다. 이 시스템은 명목(nominal), 수치(numeric), 관계(relational), 구성 요소(component) 속성을 포함한 혼합 데이터 표현을 지원합니다.

- **Performance Highlights**: TRESTLE의 성능은 감독 학습(supervised learning) 및 비감독 클러스터링(unsupervised clustering) 작업에서 평가되었으며, 기존의 비점진적(non-incremental) 모델 및 인간 참가자와 비교하여 경쟁력 있는 결과를 보였습니다.



### STACKFEED: Structured Textual Actor-Critic Knowledge Base Editing with FeedBack (https://arxiv.org/abs/2410.10584)
- **What's New**: 이번 논문에서는 LLM(대규모 언어 모델)에서의 정확성과 업데이트된 정보의 필요성을 강조하며, 전문가 피드백을 활용하여 지식 기반(KB)을 지속적으로 수정하는 STACKFEED라는 새로운 접근 방식을 제안합니다. 이 방법은 Document-level update를 통해 KB의 품질을 향상시키는 데 중점을 두고 있습니다.

- **Technical Details**: STACKFEED는 Mult-Agent reinforcement learning 프레임워크를 통해 각 문서를 특정한 작업으로 할당받은 Actor가 수정 작업을 수행하고, 중앙 집중식 Critic이 이들을 조율합니다. 각 Actor는 문서별로 특정 지침에 따라 구조화된 수정을 수행하며, Parameterized action space를 통해 정밀한 수정이 가능합니다.

- **Performance Highlights**: 실험 결과에 따르면 STACKFEED는 RAG 시스템의 성능을 크게 개선하며, KB의 품질을 강화하고 정확도를 최대 8% 개선하는 효과를 보입니다.



### When Precedents Clash (https://arxiv.org/abs/2410.10567)
Comments:
          13 pages. Extended version with proofs of a paper accepted at JURIX 2024

- **What's New**: 이 논문은 법률 사례 기반 추론(case-based reasoning, CBR)과 Boolean 분류기(classifier) 간의 연결을 통한 일관된 사례(base) 시스템을 구축하는 방법을 모색합니다. 특히, 법원 계층구조와 사례 간의 시간적 관계를 고려하여 법률 시스템의 구체적인 구조에 맞는 모델을 향상시키는 데 중점을 두고 있습니다.

- **Technical Details**: 논문에서 제안하는 모델은 세 가지 주요 구성 요소로 구성됩니다: 1) 법원의 계층 구조를 정의하는 조직(organisation) 구조, 2) 사례 간의 시간적 관계를 결정하는 우선 순위(preorder), 3) 사례 간의 연관성(relevance relation). 이러한 요소들은 법적 의사결정을 보다 명확하게 만들어줍니다.

- **Performance Highlights**: 이 연구는 특히 법적 의사 결정 과정에서 발생할 수 있는 충돌 문제를 해결하는 데 있어서 시간적 및 계층적 원칙을 수립하는 방법을 제시합니다. 이를 통해 법원 간의 결정의 구속력(binding)과 발생하는 충돌 간의 관계를 명확히 정의함으로써 새로운 사례에 대한 결정 과정을 단일화할 수 있는 기반을 마련하고 있습니다.



### A Practical Approach to Causal Inference over Tim (https://arxiv.org/abs/2410.10502)
- **What's New**: 이번 논문은 동적 시스템에 대한 개입의 인과적 효과를 시간에 따라 추정하는 데 중점을 둡니다. 우리는 이론적으로 인과 개입과 그 효과를 이산 시간 확률 과정(Discrete-Time Stochastic Processes, DSPs)에서 정의하고, 이러한 개입이 발생하기 전후의 균형 상태를 구조적 인과 모델(Structural Causal Model, SCM)로 포착할 수 있는 조건을 제시합니다.

- **Technical Details**: 본 연구는 구조적 인과 모델과 벡터 자기 회귀 모델(Vector Autoregressive Models, VARs)을 결합하여 시간에 따른 인과 추론을 수행할 수 있는 프레임워크를 개발했습니다. 이 프레임워크는 선형이고 잠재적으로 순환적이며 측정되지 않은 혼란 요소(Confounders)에 영향을 받을 수 있는 SCM으로 VARs를 매핑합니다. 또한, 두 가지 종류의 인과 개입(가법 및 강제 개입)을 통해 DSP에서 인과 개입을 공식화하였습니다.

- **Performance Highlights**: 합성 및 실제 데이터세트에 대한 실험 결과, 제안한 인과 VAR 프레임워크는 관찰 예측 관점에서 뛰어난 성능을 보여주었으며, 동적 시스템에 대한 개입의 인과적 효과를 정확히 추정할 수 있음을 입증했습니다. 사례 연구를 통해 이 프레임워크를 통해 해결할 수 있는 잠재적 실무 질문들을 제시하였습니다.



### TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs (https://arxiv.org/abs/2410.10479)
- **What's New**: TMGBench는 LLM의 전략적 추론 능력을 평가하기 위해 다양한 게임 유형을 포괄하는 새로운 벤치마크로 소개되었습니다. 이는 144가지 게임 유형을 포함하며, 다양한 스토리 기반 시나리오를 제작하여 기존의 데이터 유출 문제와 한정된 게임 범위의 문제를 해결합니다.

- **Technical Details**: TMGBench는 2x2 게임의 Robinson-Goforth 특성을 기반으로 한 144가지 게임 유형을 포함합니다. 기존 고전 게임을 바탕으로 합성 데이터 생성 기법을 사용하여 스토리 기반 게임을 개발하고, 이를 통해 다층적 의사결정과 복잡한 최적화 문제를 테스트합니다.

- **Performance Highlights**: TMGBench에서의 테스트 결과, OpenAI의 최신 모델 o1-mini는 순차적, 병렬, 중첩 게임에서 각각 66.6%, 60.0%, 70.0%의 정확도를 기록했습니다. 이러한 결과는 LLM의 전략적 추론 능력의 결함과 불일치를 드러냅니다.



### KBLaM: Knowledge Base augmented Language Mod (https://arxiv.org/abs/2410.10450)
- **What's New**: 본 논문에서는 외부 지식으로 대규모 언어 모델(LLMs)을 보강하는 새로운 방법인 Knowledge Base augmented Language Model (KBLaM)을 제안합니다.

- **Technical Details**: KBLaM은 문서 코퍼스에서 구성된 지식 기반(KB)과 함께 작동하며, KB의 각 지식을 연속 키-값 벡터 쌍으로 변환한 후, 이를 특수한 정사각형 attention 메커니즘을 통해 사전 훈련된 LLM에 통합합니다. KBLaM은 외부 검색 모듈을 제거하고, 컴퓨팅 오버헤드는 KB 크기와 선형적으로 스케일링됩니다. 이 방법은 10K 이상의 트리플로 구성된 대규모 KB를 단일 A100 80GB GPU에서 8K 컨텍스트 윈도우의 8B 사전 훈련된 LLM에 통합할 수 있게 합니다.

- **Performance Highlights**: KBLaM의 효과는 질문 응답 및 개방형 추론을 포함한 다양한 작업에서 입증되었으며, 증강된 지식의 사용에 대한 해석 가능한 통찰력을 제공합니다.



### Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search (https://arxiv.org/abs/2410.10392)
- **What's New**: 이 논문은 기존의 지침 데이터를 개선하기 위한 새로운 프레임워크인 IDEA-MCTS(Instruction Data Enhancement using Monte Carlo Tree Search)를 소개합니다. 이 프레임워크는 효율적으로 지침을 합성하고, 지침 조정(instruction fine-tuning)에서 도움을 줄 수 있습니다.

- **Technical Details**: IDEA-MCTS 프레임워크는 트리 검색(tree search)과 평가 모델(evaluation models)을 활용하여 각 지침을 고품질 형식으로 발전시키는 방향으로 지침을 안내합니다. 이를 통해 데이터 합성 과정에서 발생할 수 있는 불확실성을 줄이고, 양질의 지침을 생성합니다.

- **Performance Highlights**: 실험 결과, IDEA-MCTS는 초기 지침 데이터의 평가 점수를 평균 2.19에서 3.81로 향상시켰습니다. 또한, 오픈 도메인 벤치마크(open-domain benchmarks)에서는 리소스가 적은 환경에서 LLM의 실제 지침 따라하기 능력이 평균 5% 향상되었습니다.



### Innovative Thinking, Infinite Humor: Humor Research of Large Language Models through Structured Thought Leaps (https://arxiv.org/abs/2410.10370)
- **What's New**: 본 논문에서는 유머 생성에 대한 체계적인 사고 방식을 제안하고, 이를 기반으로 Creative Leap of Structured Thought (CLoST) 프레임워크를 구축합니다. CLoST는 유머 콘텐츠 생성에 필수적인 에러 수정 기능을 갖춘 보상 모델을 포함하며, 이를 통해 LLMs의 창의적 능력을 확장하는 새로운 방법론을 제시합니다.

- **Technical Details**: CLoST는 두 단계로 구성됩니다: 1) Automatic Associative Instruction Evolution (AAIE) 단계에서는 유머에 대한 판단 능력을 향상시키기 위해 사람 설계된 지침과 그 파생물을 사용하여 모델을 훈련합니다. 2) Guided Exploratory Self-Improvement Tuning (GESIT) 단계에서는 Direct Preference Optimization (DPO) 훈련을 통해 유머 응답을 생성하고 유머 스타일을 이해하는 모델의 능력을 향상시킵니다.

- **Performance Highlights**: CLoST는 중국어 및 영어 유머 데이터 셋을 사용한 평가에서 다른 모델들보다 뛰어난 성능을 보여주었으며, 이로써 LLM의 창의적 사고 능력을 심화시키고 유머 판단 능력을 향상시키는 데 기여합니다.



### CoMAT: Chain of Mathematically Annotated Thought Improves Mathematical Reasoning (https://arxiv.org/abs/2410.10336)
Comments:
          8 pages, 12 figures

- **What's New**: 본 논문에서는 CoMAT(Chain of Mathematically Annotated Thought)를 제안하여 대형 언어 모델(LLMs)의 수학적 추론 능력을 개선합니다. CoMAT는 자연어 쿼리를 기호 형태로 변환하는 Symbolic Conversion 단계와 기호 표현으로부터 정답을 도출하는 Reasoning Execution 단계로 이루어져 있습니다.

- **Technical Details**: CoMAT는 전체적인 추론 과정을 LLM 내에서 다루며, 외부 도구나 검증자의 필요성을 없앱니다. CoMAT는 각 추론 단계를 Q(S,R,A) 구조에 따라 체계적으로 수행하는데, 이는 각 단계를 명확하게 검토할 수 있게 돕습니다. 이를 통해 수학적 일관성을 유지하고 모호성을 감소시킵니다.

- **Performance Highlights**: CoMAT는 4개의 LLM에서 7가지 벤치마크 중 6개에서 전통적인 CoT보다 뛰어난 성능을 보이며, MMLU-Redux(MATH)에서 4.48%, GaoKao MCQ에서 4.58%의 개선 효과를 보였습니다. 또한, CoMAT는 투명한 추론 과정 덕분에 충실도와 검증 가능성을 보장합니다.



### QUIS: Question-guided Insights Generation for Automated Exploratory Data Analysis (https://arxiv.org/abs/2410.10270)
Comments:
          6 pages

- **What's New**: QUIS라는 새로운 두 단계 자동 데이터 탐색 시스템을 소개합니다. 이 시스템은 사전 정의된 목표 없이 데이터 의미론에 기반해 질문을 생성하고, 이를 바탕으로 통계 분석을 통해 통찰력을 생산합니다.

- **Technical Details**: QUIS는 두 개의 주요 모듈로 구성됩니다: Question Generation (QUGen)과 Insight Generation (ISGen). QUGen은 데이터 의미론을 기반으로 반복적으로 질문을 생성하며, ISGen은 이러한 질문에 대해 통계적 분석을 통해 여러 관련 통찰력을 제공합니다.

- **Performance Highlights**: QUIS는 전문가에 대한 의존도를 줄이고, 탐색 과정의 효율성을 높이며, 데이터에서 더 광범위한 통찰력을 발견할 수 있도록 돕습니다. 또한 다양한 데이터셋에 쉽게 적용할 수 있는 장점이 있습니다.



### Large Language Model-Enhanced Reinforcement Learning for Generic Bus Holding Control Strategies (https://arxiv.org/abs/2410.10212)
Comments:
          41 pages, 15 figures

- **What's New**: 이 연구는 Reinforcement Learning (RL)을 활용하여 버스 시스템의 안정성을 유지하고 운영 효율성을 개선하기 위한 새로운 보상 생성 패러다임을 제안합니다. 특히, Large Language Models (LLMs)의 능력을 활용하여 자동으로 보상을 생성합니다.

- **Technical Details**: 제안된 LLM-enhanced RL은 보상 초기화기(reward initializer), 보상 수정기(reward modifier), 성능 분석기(performance analyzer), 보상 정제기(reward refiner) 등 여러 LLM 기반 모듈로 구성되어 있습니다. 이러한 모듈들은 RL 기반 작업을 위해 훈련 및 테스트 결과의 피드백에 따라 보상 함수를 초기화하고 점진적으로 개선합니다.

- **Performance Highlights**: 다양한 버스 보유 제어 시나리오에서 LLM-enhanced RL을 적용한 결과, 전통적인 RL 전략, LLM 기반 컨트롤러 및 기존의 공간 간격 기반 피드백 제어에 비해 우수성과 견고함을 보여주었습니다.



### Beyond Graphs: Can Large Language Models Comprehend Hypergraphs? (https://arxiv.org/abs/2410.10083)
- **What's New**: 이 논문에서는 LLM의 그래프 처리 능력을 평가하기 위한 새로운 벤치마크 LLM4Hypergraph를 도입하였습니다. 이 벤치마크는 21,500개의 문제를 포함하며, 저차원 및 고차원 작업, 동형(isomorphism) 작업을 포괄합니다.

- **Technical Details**: LLM4Hypergraph는 인용 네트워크와 단백질 구조에서 얻은 실제 및 합성(실제 데이터와 생성된 데이터) 하이퍼그래프를 활용합니다. LLMs 평가에 있어, GPT-4o를 포함한 여섯 가지 저명한 LLM을 사용하여 실험하였습니다. 새로운 하이퍼그래프 언어와 두 가지 기술인 Hyper-BAG와 Hyper-COT를 통해 고차원 추론(high-order reasoning)을 개선하였습니다.

- **Performance Highlights**: 우리의 벤치마크는 LLM의 강점과 약점을 식별하는 데 효과적이며, 구조 분류(task) 작업에서 평균 4%(최대 9%)의 성능 향상을 이루었습니다. 이 연구는 LLM에 하이퍼그래프 계산 능력을 통합하기 위한 foundational testbed를 구축합니다.



### VideoAgent: Self-Improving Video Generation (https://arxiv.org/abs/2410.10076)
- **What's New**: 이 논문에서는 외부 피드백을 통합하여 비디오 생성의 품질을 향상시키는 새로운 접근법, VideoAgent를 제안합니다. 이전에는 단순히 생성된 비디오를 실행하는 방식을 사용했지만, VideoAgent는 생성된 비디오 계획을 개선하기 위해 외부 피드백을 이용하여 비디오 계획을 반복적으로 수정합니다.

- **Technical Details**: VideoAgent는 사전 훈련된 비전-언어 모델(Vision-Language Model, VLM)의 피드백을 사용하여 생성된 비디오 계획을 정제하는 'self-conditioning consistency'라는 새로운 절차를 적용합니다. 이 과정에서 생성된 비디오 계획을 직접 실행하기보다는 VLM과의 상호작용을 통해 최적의 비디오 계획을 선택하고 실행합니다.

- **Performance Highlights**: MetaWorld 및 iTHOR와 같은 시뮬레이션 로봇 조작 환경에서 실험한 결과, VideoAgent는 할루시네이션(hallucination)을 대폭 줄이고, 후속 조작 작업의 성공률을 4배까지 향상시킬 수 있음을 보여주었습니다. 또한, 실제 로봇 비디오를 개선할 수 있는 가능성도 제시하며, 로봇 공학이 비디오 생성 모델을 실제 세계에 접목하는 데 효과적인 도구가 될 수 있음을 나타냅니다.



### Adaptive Reasoning and Acting in Medical Language Agents (https://arxiv.org/abs/2410.10020)
- **What's New**: 본 연구는 시뮬레이션된 임상 환경에서 LLM(large language model) 에이전트를 활용하여 진단 정확도를 향상시키는 혁신적인 에이전트 프레임워크를 소개합니다. AgentClinic 벤치마크를 통해 자동 수정 기능을 제공하여 의사 에이전트가 잘못된 진단 후 자신의 추론과 행동을 반복적으로 정제할 수 있게 하여 의사결정이 개선될 수 있도록 합니다.

- **Technical Details**: 이 연구는 AgentClinic이라는 다중 모달 벤치마크를 활용하여 LLM 에이전트의 성능을 평가합니다. 주요 에이전트로는 의사 에이전트, 환자 에이전트, 측정 에이전트, 중재자 에이전트가 있습니다. 의사 에이전트는 필요한 정보를 수집하고 진단을 내리며, 환자 에이전트는 실제 환자의 상호작용을 시뮬레이션합니다. 자동 수정 프레임워크는 잘못된 진단 이후 의사 에이전트가 추론을 반복적으로 정제할 수 있도록 지원합니다.

- **Performance Highlights**: 실험 결과, 적응형 LLM 기반 의사 에이전트가 시뮬레이션된 환자와의 동적 상호작용을 통해 올바른 진단에 도달함을 보여주었으며, 복잡한 의료 시나리오에서 자율 에이전트가 적응하고 개선할 수 있는 능력이 강조됩니다. 앞으로 알고리즘을 개선하고 다양한 작업 및 다른 대형 언어 모델에 대한 적용 가능성을 확장할 계획입니다.



### Learning Interpretable Classifiers for PDDL Planning (https://arxiv.org/abs/2410.10011)
- **What's New**: 본 논문은 PDDL 기반의 계획 과제에서 에이전트의 행동을 인식하는 해석 가능한 모델을 합성하는 문제를 다루고 있습니다. 제안하는 방법은 에이전트가 소규모 계획 사례를 해결하는 방식을 보여주는 소수의 예제에서부터 논리식(logical formulas)을 학습하는 것입니다.

- **Technical Details**: 이 모델은 에이전트의 정책의 부분적인 설명을 제공할 수 있는 First-Order Temporal Logic (FTL)의 버전을 사용하여, 제안된 공식은 인간이 이해할 수 있으며, 새로운 사례에서도 일반화 가능성이 있습니다. 본 논문에서는 학습 문제를 MaxSAT로 변환하여 다양한 공식을 생성하는 방법을 제안합니다. 이는 학습 문제의 복잡도를 줄이며, noise에 대해 강인한 성질을 유지할 수 있습니다.

- **Performance Highlights**: 실험 결과, 제안한 방법을 사용하여 상대적으로 짧은 시간 안에 흥미롭고 정확한 공식을 학습할 수 있음을 보여줍니다.



### Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces (https://arxiv.org/abs/2410.09918)
- **What's New**: 이번 연구에서는 Dualformer라는 새로운 Transformer 모델을 제안합니다. 이 모델은 빠르고 직관적인 사고인 System 1과 느리지만 더 깊이 있는 사고인 System 2를 통합하여 reasoning을 수행합니다.

- **Technical Details**: Dualformer는 데이터에서 무작위로 reasoning trace를 생성하고 훈련하는 방법을 사용합니다. 이를 통해 모델은 다양한 사고 방식을 적절히 활용하여 빠른 응답과 정확한 reasoning을 동시에 가능하게 합니다. 인퍼런스 시에는 빠른 모드, 느린 모드 또는 자동 모드를 선택하여 동작할 수 있습니다.

- **Performance Highlights**: Dualformer는 느린 모드에서 30 x 30 미로 탐색 작업에서 97.6%의 최적 솔루션을 제공하며, 이는 기존의 Searchformer를 4.3% 초과합니다. 또한, 빠른 모드에서도 80%의 최적률을 달성하여 솔루션 전용 모델(30% 최적률)에 비해 현저히 우수한 성능을 보입니다.



### Equitable Access to Justice: Logical LLMs Show Promis (https://arxiv.org/abs/2410.09904)
- **What's New**: 이 논문에서는 대형 언어 모델(LLMs)과 논리 프로그래밍의 통합을 통해 법적 추론 능력을 향상시키고 구체적인 법적 사안에 적용하기 위한 접근법을 탐구합니다. 특히 보험 계약 분야에 초점을 맞추어 법률과 계약을 논리 프로그램으로 번역하고자 합니다.

- **Technical Details**: LLMs는 빠른 속도로 발전하는 확률적(probabilistic) 솔루션으로, 그러나 결과의 일관성(consistency)와 신뢰성(reliability)에서 한계가 있습니다. 논리 프로그래밍은 일관된 응답과 설명 가능한 답변을 제공하지만, 복잡한 작업을 처리하는 데 있어 유연성과 확장성(scalability)에서 부족함이 있습니다. 이러한 두 가지 방법론을 결합한 하이브리드 접근법을 제안하며, 특히 LLM이 법률 조문을 논리 표현으로 자동 생성하는 방식을 사용합니다.

- **Performance Highlights**: OpenAI의 o1-preview 모델은 GPT-4o와 비교하여 논리 프로그램으로 보험 정책을 인코딩하는 데 있어 확연히 우수한 성능을 보였습니다. 본 연구는 정책의 특정 조건을 고려하여 두 모델 간의 인코딩 차이를 분석하였으며, LLM의 고급 추론 능력이 논리 프로그램의 생성에 효과적임을 입증합니다.



### EasyJudge: an Easy-to-use Tool for Comprehensive Response Evaluation of LLMs (https://arxiv.org/abs/2410.09775)
- **What's New**: 이번 연구에서는 LLM(대형 언어 모델) 평가를 위한 사용자 친화적이고 효율적인 모델인 EasyJudge를 소개합니다. 기존의 평가 시스템들은 비공식 모델이거나 비쌀 뿐만 아니라 투명성과 제어성이 부족하였는데, EasyJudge는 이러한 문제를 해결합니다.

- **Technical Details**: EasyJudge는 POINTWISE(직접 점수 매기기)와 PAIRWISE(쌍비교 ranking) 평가 방식으로 구성되어 있으며, 50개 시나리오 카테고리로 세부 분류된 실제 LLM 명령 응답 데이터를 기반으로 모델 최적화가 이루어집니다. LLaMA-3-8b 모델을 세밀하게 조정하여, 사용자에게 직관적인 시각화 인터페이스를 제공하면서도 계산 리소스에서의 효율성을 담보합니다.

- **Performance Highlights**: EasyJudge는 경량화되어 소비자 등급의 GPU 및 CPU에서 효율적으로 실행될 수 있으며, 평가 결과에 대한 직관적인 시각화 기능을 통해 사용자가 모델의 응답 품질을 보다 쉽게 이해할 수 있도록 돕습니다.



### ChartKG: A Knowledge-Graph-Based Representation for Chart Images (https://arxiv.org/abs/2410.09761)
- **What's New**: 이 연구에서는 차트 이미지를 지식 그래프(KG) 기반으로 표현하는 새로운 방법인 ChartKG를 제안합니다. 이 방법은 차트 이미지의 시각 요소와 그 관계를 통합적으로 모델링하여 지식 마이닝을 촉진하려고 합니다.

- **Technical Details**: ChartKG는 이미지 처리 기술을 통합하여 차트 이미지에서 시각 요소와 관계를 자동으로 추출하는 일반 프레임워크를 개발했습니다. 이 프레임워크는 CNN, YOLOv5, Optical Character Recognition (OCR) 및 규칙 기반 방법을 사용하여 차트의 시각 요소를 식별하고 그래프를 구성합니다.

- **Performance Highlights**: 단계적 사례 연구와 함께 의미 기반 차트 검색 및 차트 질문 응답과 같은 두 가지 응용 시나리오를 제시하여 ChartKG의 유용성과 효과성을 보여줍니다. 또한 객체 인식 및 OCR의 정량적 평가를 통해 ChartKG의 기본 구성 요소의 유효성을 입증하였습니다.



### Generalization of Compositional Tasks with Logical Specification via Implicit Planning (https://arxiv.org/abs/2410.09686)
- **What's New**: 이 논문에서는 논리적 명세에 의해 주어진 구성적 작업(compositional tasks)을 위한 일반화 가능한 정책(policy)을 학습하는 문제를 연구합니다. 새로운 계층적 강화 학습(hierarchical RL) 프레임워크를 제안하여 구성적 작업의 효율적인 일반화와 최적화를 달성합니다.

- **Technical Details**: 고수준에서 본 논문은 구성적 작업의 일반화를 위해 특별히 설계된 새로운 암묵적 계획자(implicit planner)를 제안합니다. 이 계획자는 다음 하위 작업(sub-task)을 선택하고 현재 상태에서 나머지 작업을 완료하는 데 필요한 다단계 수익(multi-step return)을 추정합니다. 이 과정에서는 그래프 신경망(graph neural network, GNN)을 기반으로 잠재적 전이 모델(latent transition model)을 학습하고 잠재 공간(latent space)에서 계획을 수행합니다.

- **Performance Highlights**: 제안된 프레임워크는 이전 방법들에 비해 최적성과 효율성 측면에서 우수성을 보이는 다양한 실험을 수행하여 그 장점을 입증하였습니다.



### OpenR: An Open Source Framework for Advanced Reasoning with Large Language Models (https://arxiv.org/abs/2410.09671)
- **What's New**: 이번 기술 보고서에서는 대형 언어 모델(LLMs)의 추론 능력을 향상시키기 위해 설계된 오픈 소스 프레임워크 OpenR을 소개합니다. OpenR은 데이터 수집, 강화 학습(online 및 offline), 그리고 비자기회 복호화를 통합하여 하나의 소프트웨어 플랫폼으로 통합합니다.

- **Technical Details**: OpenR은 OpenAI의 o1 모델의 핵심 기술을 탐구하는 첫 번째 오픈 소스 프레임워크로, 강화 학습을 통해 기존의 오토회귀 방법을 넘어선 고급 추론 능력을 달성합니다. OpenR은 MATH 데이터셋 평가를 통해 테스트 시간 컴퓨트와 과정 보상 모델을 통해 추론 및 성능의 상대적 개선을 입증합니다.

- **Performance Highlights**: OpenR 프레임워크는 모델, 데이터, 그리고 코드를 포함하여 오픈 플랫폼을 제공하여 LLM의 추론을 향상시키고 연구 개발을 가속화하는 데 기여합니다. 실험 결과, 과정 보상 모델과 테스트 시간 가이드 검색을 통해 약 10%의 발전된 테스트 시간 추론 성능을 보여주었습니다.



### EmbodiedCity: A Benchmark Platform for Embodied Agent in Real-world City Environmen (https://arxiv.org/abs/2410.09604)
Comments:
          All of the software, Python library, codes, datasets, tutorials, and real-time online service are available on this website: this https URL

- **What's New**: 이 논문은 실제 도시 환경에서의 Embodied AI 평가를 위한 벤치마크 플랫폼을 구축하는 혁신적인 접근 방식을 제안합니다.

- **Technical Details**: 우리는 실제 도시 (city) 기반의 고도로 사실적인 3D 시뮬레이션 환경을 만들었습니다. 이 환경은 실제 건물, 도로 및 도시 요소를 포함하고, 과거 수집된 데이터 및 시뮬레이션 알고리즘을 결합하여 보행자와 차량의 흐름을 고충실도로 시뮬레이션합니다. 또한 다양한 EmbodiedAI 능력을 평가하기 위한 작업 세트를 설계했습니다.

- **Performance Highlights**: 이 플랫폼을 바탕으로 우리는 여러 대형 언어 모델의 Embodied AI 능력을 다양한 차원과 난이도로 평가했습니다. 이는 Embodied AI의 기존 능력을 확장하고 실제 세계에서의 응용 가능성을 높이는 데 기여합니다.



### MMAD: The First-Ever Comprehensive Benchmark for Multimodal Large Language Models in Industrial Anomaly Detection (https://arxiv.org/abs/2410.09453)
Comments:
          The code and data are available at this https URL

- **What's New**: 본 논문에서는 산업 이상 감지(Industrial Anomaly Detection)에 대한 첫 번째 다면적 대규모 언어 모델(Multimodal Large Language Models, MLLMs) 벤치마크인 MMAD(Multimodal Model Assessment in Detection)를 제안합니다. 39,672개의 질문을 포함한 새로운 데이터셋을 생성하였으며, MLLMs의 성능을 정량적으로 평가했습니다.

- **Technical Details**: 이번 연구에서 다양한 MLLMs의 성능을 평가하기 위해 7개 주요 하위 작업을 정의하고, 시각적 주석과 언어 상호작용을 통합하여 세밀한 의미 주석을 생성하는 새로운 파이프라인을 설계했습니다. 최종적으로 8,366개의 샘플을 수집하고, MLLMs의 성능을 평가하기 위한 39,672개의 객관식 질문을 생성했습니다.

- **Performance Highlights**: 실험 결과, GPT-4o 모델이 74.9%의 평균 정확도로 가장 높은 성능을 보였으나, 이는 산업의 요구 수준에 미치지 못하는 결과입니다. 현재 MLLMs는 산업 이상 및 결함 관련 질문에 대한 응답에서 여전히 상당한 개선 여지가 있음을 보여주었습니다.



### Declarative Knowledge Distillation from Large Language Models for Visual Question Answering Datasets (https://arxiv.org/abs/2410.09428)
Comments:
          Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)

- **What's New**: 이번 연구에서는 Visual Question Answering (VQA) 문제에 대해 modular 솔루션을 제안하며, Large Language Models (LLMs)로부터 선언적 지식을 증류하는 방법을 소개합니다. 이 방법은 LLM을 활용하여 초기 ASP 이론을 확장하고 VQA 작업의 요구사항을 충족시키는 방식입니다.

- **Technical Details**: 연구진은 LLM에 장면, 질문 및 예상되는 답변을 설명하고, ASP 문제 해결기를 통해 새로운 프로그램을 테스트하여 결과를 검증하는 조건부 지침을 제공합니다. ASP 프로그램이 정확하지 않거나 문법 오류가 발생할 경우 LLM에게 이를 수정하게 합니다. 사용된 VQA 데이터세트로는 CLEVR와 GQA가 있으며, 각각 조합 질문 및 복잡한 시각 장면을 다룹니다.

- **Performance Highlights**: 실험 결과 LLM이 효과적으로 ASP 규칙을 이해하고 생성할 수 있음을 보여주며, 이는 규칙 기반 접근 방식의 대안으로 VQA에서 도메인 특화 지식을 추출하는 데 유망한 방법임을 시사합니다.



### Two Heads Are Better Than One: A Multi-Agent System Has the Potential to Improve Scientific Idea Generation (https://arxiv.org/abs/2410.09403)
- **What's New**: 이 논문에서는 과학 연구에서의 협동적 본질을 모방하기 위해 대규모 언어 모델(LLM)을 기반으로 한 다중 에이전트 시스템인 VirSci를 제안합니다. 이 시스템은 연구 아이디어를 공동으로 생성하고 평가하며 정제하는团队(팀)을 구성하여 자동화된 과학 발견을 지원할 수 있습니다.

- **Technical Details**: VirSci는 다음의 다섯 단계를 통해 연구 아이디어 생성 과정을 시뮬레이션합니다: (1) Collaborator Selection, (2) Topic Selection, (3) Idea Generation, (4) Idea Novelty Assessment, (5) Abstract Generation. 이 과정에서 팀장은 연구 협업 네트워크를 기반으로 적절한 협력자를 선정하고 과거 논문 데이터베이스를 활용해 새로운 아이디어 생성을 유도합니다. 또한, 단계마다 협력자들이 성과를 향상시키기 위한 토론 메커니즘을 구현합니다.

- **Performance Highlights**: 포괄적인 실험 결과, VirSci는 단일 에이전트 실행 방법에 비해 평균 13.8%의 정렬 수준 향상과 44.1%의 현대 연구에 대한 잠재적 영향 향상을 보이며, 이는 과학 아이디어의 혁신적인 생성을 위한 강력한 도구로서의 가능성을 보여줍니다.



### Zero-shot Commonsense Reasoning over Machine Imagination (https://arxiv.org/abs/2410.09329)
Comments:
          21 pages, 9 figures, EMNLP 2024 (Findings)

- **What's New**: 이번 연구에서는 텍스트 기반의 common sense reasoning에서 발생하는 reporting bias를 극복하기 위해 Imagine이라는 새로운 zero-shot commonsense reasoning 프레임워크를 도입합니다. 이 프레임워크는 PLMs(Pre-trained Language Models)에 머신 생성 이미지를 활용하는 시각 신호를 추가하여 텍스트 입력을 보완합니다.

- **Technical Details**: Imagine은 PLMs에 이미지 생성을 위한 텍스트-이미지 생성기와 비주얼 인코더를 통합하여 개발되었습니다. 이를 통해 생성된 이미지를 텍스트와 결합하여 reasoning 과정에서 공동으로 활용할 수 있게 하여, 인간의 reporting bias를 피하고 reasoning 능력을 향상시킵니다. 연구에 사용된 Synthetic VQA 데이터셋은 PLMs이 시각적 및 텍스트 신호를 효과적으로 학습할 수 있게 돕습니다.

- **Performance Highlights**: 상세한 실험 결과에 따르면, Imagine은 다양한 reasoning 벤치마크에서 기존의 방법들보다 월등한 성능을 보였으며, 특히 인간의 상상력을 활용하여 PLMs의 일반화 가능성을 높이는 데 성공했습니다.



### Refinements on the Complementary PDB Construction Mechanism (https://arxiv.org/abs/2410.09297)
- **What's New**: 이번 연구는 Complementary 1 (CPC1) 계획자(PBD planner)의 개선을 목적으로 하며, Pattern Database (PDB) 구성 메커니즘을 최적화하여 IPC 2018 벤치마크에서 성능을 향상시킨 새로운 계획자 CPC0을 제시합니다.

- **Technical Details**: PDB는 상태를 추상 상태로 매핑하고, 최적 비용을 look up table에 저장하는 메모리 기반의 휴리스틱 생성 기술입니다. 본 연구에서는 PDB 생성 알고리즘과 평가자를 최적화하고, 다양한 생성 알고리즘의 통합을 개선합니다. 이를 통해 CPC1에서 발견된 문제점을 해결하기 위한 여러 알고리즘과 평가 방법이 사용되었습니다.

- **Performance Highlights**: CPC0은 IPC 2018 벤치마크 실험에서 CPC1보다 유의미한 성능 향상을 보여주었으며, 이전 버전보다 더 많은 계획 작업을 성공적으로 해결했습니다.



### Natural Language Counterfactual Explanations for Graphs Using Large Language Models (https://arxiv.org/abs/2410.09295)
- **What's New**: 이번 연구는 그래프 신경망(GNNs)에서 카운터팩추얼 설명(counterfactual explanations)을 자연어(natural language)로 번역하기 위해 오픈소스 대형 언어 모델(Large Language Models, LLMs)의 생성 능력을 활용하는 방법을 제시합니다. 특히, 기술적인 전문 지식이 없는 사용자가 이해할 수 있는 형태로 설명을 변환하는 데 중점을 두었습니다.

- **Technical Details**: 이 연구에서는 카운터팩추얼 설명을 생성하기 위해 두 가지 그래프 카운터팩추얼 설명기(CF-GNNExplainer와 CF-GNNFeatures)를 사용하고, 여러 오픈소스 LLM에 대해 원시 카운터팩추얼 예제를 자연어 설명으로 변환하도록 지시했습니다. 생성된 설명의 품질을 평가하기 위해 새로운 메트릭(metrics)을 정의하였으며, 이 메트릭은 생성된 설명과 카운터팩추얼 예제 간의 매핑 정확도를 측정합니다.

- **Performance Highlights**: 실험 결과, 제안한 방법이 여러 그래프 데이터셋과 카운터팩추얼 설명기에서 효과적으로 자연어 표현을 생성하여 의사결정 과정 지원에 기여할 수 있음을 보여주었습니다. 특히, LLM 크기, 데이터셋 및 설명 방법을 다양하게 조정하여 수행한 포괄적인 평가를 통해 상당한 성과를 확인했습니다.



### P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains (https://arxiv.org/abs/2410.09207)
- **What's New**: 기존의 LLM(대형 언어 모델) 논리적 추론 능력을 이해하는 방법들이 충분하지 않다는 점을 입증하며, P-FOLIO라는 새로운 데이터세트를 소개합니다. 이 데이터세트는 인간이 작성한 복잡한 추론 체인을 포함하고 있습니다.

- **Technical Details**: P-FOLIO는 첫 번째 논리 문제(FOLIO)로부터 수집된 0에서 20까지의 추론 단계로 구성되어 있으며, 자연어 증명 작성 프로토콜을 통해 단계별로 작성된 proof(증명)를 포함합니다. 이 데이터세트는 다양한 추론 규칙을 사용해 12개의 간단한 추론 규칙과 20개 이상의 복잡한 추론 규칙을 포함하고 있습니다.

- **Performance Highlights**: P-FOLIO를 사용하여 LLM의 추론 능력을 평가하며, Llama3-7B 모델을 P-FOLIO로 fine-tuning(미세 조정) 한 결과 10% 이상 성능 향상이 있었습니다. 그러면서 인간이 작성한 추론 체인이 LLM의 논리적 추론 능력을 크게 향상시킴을 보여주었습니다.



### Resource-Constrained Heuristic for Max-SA (https://arxiv.org/abs/2410.09173)
- **What's New**: 본 연구는 Max-SAT 문제를 해결하기 위한 자원 제약 기반의 휴리스틱(heuristic) 방식을 제안합니다. 이 방식은 대규모 문제를 더 작은 서브 구성 요소로 반복적으로 분해하여 최적화된 솔버(optimizer)와 하드웨어를 사용할 수 있도록 합니다.

- **Technical Details**: 제안된 접근 방식은 두 단계로 구성되어 있습니다. 외부 루프는 SAT 변수의 부분 집합을 선택하고, 내부 최적화 루프는 선택된 서브-SAT 문제의 만족할 수 있는 조항의 수를 최대화합니다. 우리의 방법은 선택기(selector)와 최적화기(optimizer)의 메커니즘에 구애받지 않으며, 전통적인 솔버를 사용하거나 이 문제를 QUBO(quadratic unconstrained binary optimization) 형식으로 변환하여 전문 하드웨어에서 최적화를 수행할 수 있습니다.

- **Performance Highlights**: 무작위로 생성된 Max-SAT 인스턴스와 Max-SAT 평가 벤치마크의 실제 사례에 대한 실험을 통해, 기존 QUBO 분해기(decomposer) 솔루션보다 더 나은 성능을 보였음을 입증하였습니다.



### Mechanistic? (https://arxiv.org/abs/2410.09087)
Comments:
          Equal contribution. Position paper. Accepted for presentation at the BlackBoxNLP workshop at EMNLP 2024

- **What's New**: 이 논문에서는 'mechanistic interpretability'라는 용어의 의미와 그 정의의 변천사를 살펴보며, 전통적인 NLP 해석 가능성과 어떻게 다르게 구분되는지를 자세히 설명합니다.

- **Technical Details**: 이 논문은 'mechanistic interpretability'를 좁은 기술적 정의(신경망의 인과 메커니즘을 통한 이해) 및 넓은 기술적 정의(모델의 내부 구조 설명)로 나누어 설명하고 있습니다. 또한, 인과 메커니즘에 대한 강한 초점을 강조하며, 기존의 NLP 해석 가능성 연구와의 관계를 살펴봅니다.

- **Performance Highlights**: 요약하자면, 'mechanistic interpretability'는 인과 메커니즘을 통해 신경망의 내부를 탐색하는 방식을 강조하며, 이는 과학적 진전을 위한 문화적 격차를 해소하는 데 중요한 역할을 한다고 주장합니다.



### Alignment Between the Decision-Making Logic of LLMs and Human Cognition: A Case Study on Legal LLMs (https://arxiv.org/abs/2410.09083)
- **What's New**: 이 논문에서는 법률 분야의 대규모 언어 모델(LLM)의 의사결정 논리와 인간 인지 사이의 정합성을 평가하는 방법을 제안합니다. 기존의 언어 생성 결과 평가 방식과는 달리, 우리는 LLM의 출력을 뒷받침하는 세부 의사결정 논리의 정확성을 평가하고자 합니다.

- **Technical Details**: 논문에서는 LLM의 상호작용을 원시 의사결정 논리로 정량화하며, 이를 통해 정합성 평가를 위한 새로운 지표를 설계하였습니다. 이와 관련된 상호작용은 AND-OR 상호작용의 개념을 포함하여 LLM의 신뢰 점수와 인간의 법적 판단 간의 일치를 평가하는 데 사용됩니다. LLM이 생성한 문장 속의 입력 토큰 간 비선형 관계를 측정합니다.

- **Performance Highlights**: 실험 결과, 법률 LLM은 높은 예측 정확도를 보임에도 불구하고, 내부 추론 논리의 상당 부분에서 주목할 만한 문제를 포함하고 있다는 사실이 확인되었습니다. 이는 LLM의 의사결정 논리와 인간의 인지 간의 정합성이 요구된다는 것을 보여줍니다.



### Semantic Environment Atlas for Object-Goal Navigation (https://arxiv.org/abs/2410.09081)
Comments:
          30 pages

- **What's New**: 이번 논문에서는 Embodied Agents의 시각적 탐색 능력을 향상시키기 위해 Semantic Environment Atlas (SEA)라는 새로운 매핑 접근 방식을 소개합니다. SEA는 장소와 객체 간의 관계를 정교하게 묘사하는 semantic graph map을 활용하여 탐색 맥락을 풍부하게 합니다.

- **Technical Details**: SEA는 이미지 관측으로부터 구축된 매핑 시스템으로, 환경 내의 시각적 랜드마크를 희소하게 인코딩된 노드로 잡아냅니다. 이 시스템은 다양한 환경에서 여러 개의 semantic map을 통합하고, 장소-객체 관계의 메모리를 유지하여 시각적 로컬라이제이션(visual localization) 및 네비게이션(navigation)과 같은 작업에 유용합니다. SEA 기반의 네비게이션 프레임워크가 개발되었으며, 이를 시각적 로컬라이제이션 및 객체 목표 탐색(object-goal navigation) 작업을 통해 평가했습니다.

- **Performance Highlights**: SEA 기반 로컬라이제이션 프레임워크는 기존 방법들을 크게 초월하여 단일 쿼리 이미지로부터 정확한 위치를 식별했습니다. 실험 결과, Habitat 시나리오에서 39.0%의 성공률을 달성했으며, 이는 현재의 최첨단 방법보다 12.4% 향상된 결과입니다. 또한 저비용으로 노이즈가 섞인 오도메트리와 작동 조건에서도 견고함을 유지했습니다.



### Leveraging Social Determinants of Health in Alzheimer's Research Using LLM-Augmented Literature Mining and Knowledge Graphs (https://arxiv.org/abs/2410.09080)
- **What's New**: 이 논문은 알츠하이머병(Alzheimer's disease, AD)과 관련된 비의료적 요인인 사회적 건강 결정요인(social determinants of health, SDoH)이 브랜드에 미치는 영향을 연구하기 위해, 최신 대형 언어 모델(large language model, LLM) 및 자연어 처리(natural language processing, NLP) 기술을 활용한 새로운 자동화된 프레임워크를 제안합니다.

- **Technical Details**: 이 연구에서 제안하는 프레임워크는 PubMed에서 관련 문헌을 수집하고, OpenAI의 최신 LLM인 GPT-4o를 이용하여 생물 의학적 개체 및 SDoH 개체를 추출하고, 이들을 일반 목적 지식 그래프인 PrimeKG와 통합하여 SDoH 보강 지식 그래프를 만듭니다. 그래프 신경망(graph neural networks)을 사용하여 링크 예측 작업을 수행하여 결과 도출을 평가합니다.

- **Performance Highlights**: 이 프레임워크는 AD 연구에서의 지식 발견을 향상시키기 위한 가능성을 보여주며, 다른 SDoH 관련 연구 영역에도 일반화 가능하여 건강 결과에 대한 사회적 결정요인의 영향을 탐색하기 위한 새로운 도구를 제공합니다.



### TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models (https://arxiv.org/abs/2410.10818)
Comments:
          Project Page: this https URL

- **What's New**: TemporalBench는 비디오의 미세한 시간적 이해(fine-grained temporal understanding)를 평가하는 새로운 벤치마크로, 10,000 개의 비디오 질문-답변 쌍으로 구성되어 있으며, 인간의 고품질 주석에서 파생되었습니다.

- **Technical Details**: TemporalBench에서는 비디오 클립의 시공간적 활동을 잘 반영하기 위해 긴 시간 의존성(long-range dependencies), 세분화된 시각적 관찰(fine-grained visual observations) 및 사건의 진행(event progression)과 관련된 주석에 중점을 두었습니다.

- **Performance Highlights**: 최신 모델인 GPT-4o는 TemporalBench에서 단지 38.5%의 질문 응답 정확도를 보여주었고, 이는 인간과 AI 간의 시간적 이해에서 약 30%의 큰 간극이 있음을 나타냅니다. 또한 다중 선택 QA에서 발생할 수 있는 편향을 수정하기 위해 Multiple Binary Accuracy(MBA)를 제안했습니다.



### LVD-2M: A Long-take Video Dataset with Temporally Dense Captions (https://arxiv.org/abs/2410.10816)
Comments:
          NeurIPS 2024 Dataset and Benchmark Track. Project page: this https URL . Code: this https URL

- **What's New**: 본 논문은 LVD-2M이라는 새로운 데이터셋을 소개합니다. 이 데이터셋은 최소 10초 이상의 긴 비디오, 컷이 없는 장시간 비디오, 다양한 콘텐츠와 큰 동작을 포함하며 시계열 밀집 캡션(temporally dense captions)으로 주석이 달린 2백만 개의 비디오로 구성되어 있습니다.

- **Technical Details**: LVD-2M은 낮은 수준의 필터링 도구(예: scene cut detection)와 의미적 수준의 필터링 도구(예: video LLMs)를 결합한 자동 데이터 선별 파이프라인을 통해 제작되었습니다. 또한, 비디오를 30초 클립으로 나누고 각 클립에서 프레임을 샘플링하여 비디오 캡션을 생성하는 계층적 캡셔닝(Hierarchical Captioning) 접근 방식을 사용합니다.

- **Performance Highlights**: LVD-2M 데이터셋을 통해 비디오 생성 모델의 성능이 향상되었으며, 실험 결과 동적 모션을 포함하는 장시간 비디오 생성에 있어 효과성이 입증되었습니다. 인간 평가에서도 LVD-2M이 높은 동적 정도와 뛰어난 캡션 품질로 선호되었습니다.



### Depth Any Video with Scalable Synthetic Data (https://arxiv.org/abs/2410.10815)
Comments:
          Project Page: this https URL

- **What's New**: 이번 논문에서는 Depth Any Video라는 모델을 도입하여 비디오 깊이 추정의 어려움을 해결하려고 합니다. 이 모델은 대규모 합성 데이터 파이프라인을 개발하고, 생성적 비디오 확산 모델의 강력한 프라이어를 활용하여 다양한 비디오를 효과적으로 처리합니다.

- **Technical Details**: 우리는 40,000개의 5초 길이의 비디오 클립을 포괄하는 대규모 합성 데이터셋인 DA-V를 구축했습니다. 이 데이터는 조명 조건, 카메라 움직임, 그리고 물체 상호작용을 포함한 다양한 시나리오를 커버합니다. 모델의 훈련 방식으로 혼합 길이 훈련 전략을 도입하고, 흐름 일치(flow matching) 및 회전 위치 인코딩(rotary position encoding) 같은 고급 기술을 사용하여 처리 효율성을 향상시킵니다.

- **Performance Highlights**: 모델은 공간 정확성과 시간 일관성 모두에서 기존의 모든 생성적 깊이 모델을 초월하며, 최대 150 프레임의 비디오 시퀀스에서 고해상도 깊이 추정을 가능하게 합니다.



### HART: Efficient Visual Generation with Hybrid Autoregressive Transformer (https://arxiv.org/abs/2410.10812)
Comments:
          Demo: this https URL. The first two authors contributed equally to this work

- **What's New**: 이번 연구에서는 Hybrid Autoregressive Transformer (HART)라는 새로운 시각 생성 모델을 소개합니다. HART는 1024x1024 크기의 이미지를 직접 생성할 수 있는 autoregressive (AR) 모델로, 기존의 diffusion 모델과 유사한 이미지 생성 품질을 자랑합니다. HART는 전통적인 AR 모델의 한계를 극복하기 위해 하이브리드 토크나이저(hybrid tokenizer)를 도입하였습니다.

- **Technical Details**: HART의 하이브리드 토크나이저는 autoencoder의 연속적인 잠재 출력(latent output)을 두 가지 구성 요소로 분해합니다: 전체적인 그림을 나타내는 discrete tokens와 discrete tokens로 표현할 수 없는 잔여 성분을 나타내는 continuous tokens. 이들은 각각 스케일 가능한 해상도의 VAR transformer와 37M 파라미터를 가진 경량 residual diffusion 모듈에 의해 모델링됩니다.

- **Performance Highlights**: HART는 MJHQ-30K 데이터셋에서 reconstruction FID를 2.11에서 0.30으로 개선하여, 1024px 이미지 생성 시 FID를 7.85에서 5.38로 낮추어 31%의 개선을 달성하였습니다. 또한 HART는 최신 diffusion 모델보다 4.5-7.7배 높은 처리량과 6.9-13.4배 낮은 MACs를 기록하며, 빠른 추론(latency) 속도를 자랑합니다.



### Hard-Constrained Neural Networks with Universal Approximation Guarantees (https://arxiv.org/abs/2410.10807)
- **What's New**: 이번 연구에서는 HardNet이라는 새로운 프레임워크를 제안하여, 신경망이 입력/출력 의존적인 affine 및 convex hard constraints를 본질적으로 만족하면서도 모델의 용량을 희생하지 않고 신경망을 구성할 수 있도록 하였습니다.

- **Technical Details**: HardNet은 differentiable projection layer를 네트워크의 출력에 추가하여, 제약 조건을 만족하는 구조로 신경망을 최적화할 수 있게 합니다. 이 구현을 통해, 표준 알고리즘을 사용하여 unconstrained optimization을 수행하면서도 hard constraint의 만족을 보장합니다. 또한, HardNet은 신경망의 보편적 근사(Universal Approximation) 능력을 유지함을 입증하였습니다.

- **Performance Highlights**: HardNet은 다양한 응용 프로그램에서 효과를 입증하였으며, 이는 제한된 제약 조건으로 함수에 맞추기, 최적화 해결기 학습, 안전 필수 시스템의 제어 정책 최적화, 항공기 시스템을 위한 안전한 의사결정 논리 실시간 학습을 포함합니다.



### Boosting Camera Motion Control for Video Diffusion Transformers (https://arxiv.org/abs/2410.10802)
- **What's New**: 본 논문에서는 비디오 생성의 카메라 제어 품질을 향상시키기 위한 해결책으로 Camera Motion Guidance (CMG) 방법을 제안하며, 이를 통해 기존 DiT 방식보다 400% 이상 개선된 결과를 보였습니다.

- **Technical Details**: 본 연구는 transformer 기반의 diffusion 모델(DiT)에서 카메라 제어 성능이 conditioning 방법에 크게 의존한다는 사실을 밝혀냈습니다. 이를 기반으로 classifier-free guidance 기술을 활용한 CMG 방법을 도입하였습니다. 또한, sparse camera control 방식을 통해 긴 비디오에서 카메라 포즈 입력을 간소화하는 방법도 제시하였습니다.

- **Performance Highlights**: CMG 방법과 sparse camera control을 적용하여 비디오 생성 시 카메라 제어 정확도 및 동작을 크게 향상시켰으며, 이는 U-Net 및 DiT 모델 모두에 효과적으로 적용 가능합니다.



### On Information-Theoretic Measures of Predictive Uncertainty (https://arxiv.org/abs/2410.10786)
- **What's New**: 이 논문에서는 기계 학습에서 예측 불확실성(predictive uncertainty)의 신뢰할 수 있는 추정이 왜 중요한지를 강조하며, 정보 이론(information-theoretic)에 기반한 예측 불확실성 측정 방법을 개발하였습니다. 또한, 예측 모델과 진정한 예측 분포의 근사라는 두 가지 요소에 따라 예측 불확실성 측정을 분류했습니다.

- **Technical Details**: 제안된 프레임워크는 예측 모델(prediction model)과 진정한 예측 분포(true predictive distribution)의 근사에 따라 예측 불확실성 측정을 분류하는 방법론을 포함합니다. 모든 가능한 조합을 검토하여 기존 및 새롭게 도입된 예측 불확실성 측정을 도출하였습니다.

- **Performance Highlights**: 우리는 비정형 예측(misclassification detection), 선택적 예측(selective prediction), 분포 외 탐지(out-of-distribution detection) 등과 같은 일반적인 불확실성 추정 환경에서 이 측정 방법들을 실험적으로 평가했습니다. 결과적으로 어떤 단일 측정 방법이 보편적이지 않으며, 그 효과는 특정 환경에 따라 다릅니다.



### When Attention Sink Emerges in Language Models: An Empirical View (https://arxiv.org/abs/2410.10781)
- **What's New**: 이번 연구에서는 Language Models (LMs)에서 'attention sink' 현상이 보편적으로 존재한다는 것을 입증했습니다. 특히 이 현상이 작은 모델에서도 발생함을 발견하였고 LM의 사전 훈련 과정에서 나타남을 강조했습니다.

- **Technical Details**: attention sink는 초기 토큰에 대한 비정상적인 집중을 의미하며, 이는 다양한 입력에서도 관찰됩니다. 이 연구는 사전 훈련 중 attention sink의 출현을 최적화, 데이터 분포, 손실 함수, 모델 구조 등이 어떻게 영향을 미치는지를 탐구하였습니다.

- **Performance Highlights**: 효과적인 데이터 훈련 후에 attention sink가 나타나며, 작은 학습률로 훈련된 LMs에서는 덜 나타납니다. 손실 함수 및 데이터 분포와 깊은 상관관계가 있으며, softmax normalize 대신 sigmoid attention을 통해 이러한 의존성을 완화시켰을 때, 1B 파라미터까지의 LMs에서는 attention sink가 발생하지 않았습니다.



### Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation (https://arxiv.org/abs/2410.10766)
- **What's New**: 모델 프리 강화 학습(Model-Free Reinforcement Learning)은 복잡하고 비구조적인 지형을 탐색할 수 있는 강력한 로봇 제어 정책을 개발하기 위한 방법으로 부각되었습니다. 본 연구에서는 환경 생성 방식에 대한 한계를 극복하고, 적응형 확산 지형 생성기(ADTG)를 도입하여 기존 훈련 환경을 다이나믹하게 확장할 수 있는 방법을 설명합니다.

- **Technical Details**: ADTG는 Denoising Diffusion Probabilistic Models를 활용하여 적응적인 지형 생성을 구현합니다. 초기 노이즈 최적화(Initial Noise Optimization)를 통해 정책의 성과에 따라 갈라진 지형을 혼합하고 생성하는 프로세스를 안내합니다. ADTG는 훈련 환경의 복잡성을 달리 조절할 수 있으며, 기존 훈련 데이터 세트에 기반하여 다양성을 증대시킵니다.

- **Performance Highlights**: ADTG로 훈련된 정책은 절차적으로 생성된 환경과 자연 환경을 모두 초월하여 더 나은 성능을 보여주었습니다. 특히, ADTG는 일반화 능력을 향상시키고 수렴 속도를 가속화하여 기존 방법들에 비해 뛰어난 결과를 보였습니다.



### Arrhythmia Classification Using Graph Neural Networks Based on Correlation Matrix (https://arxiv.org/abs/2410.10758)
- **What's New**: 이번 연구에서는 ECG 신호 분석에 그래프 신경망(Graph Neural Network, GNN)을 적용하여 부정맥(arrhythmia) 분류 문제를 해결하려는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 연구진은 추출된 특성의 상관 행렬(correlation matrix)을 사용하여 인접 행렬(adjacency matrix)을 생성한 후, 이를 통해 그래프 신경망을 적용했습니다. 제안된 모델은 기존 문헌의 방법들과 비교되었습니다.

- **Performance Highlights**: 모든 부정맥 클래스에 대해 정확도(precision)와 재현율(recall)이 50%를 초과하는 성과를 보였으며, 이는 이 방법이 부정맥 분류를 위한 유망한 접근일 수 있음을 시사합니다.



### FlexGen: Flexible Multi-View Generation from Text and Image Inputs (https://arxiv.org/abs/2410.10745)
Comments:
          16 pages, 13 figures

- **What's New**: 이 논문에서는 FlexGen이라는 유연한 프레임워크를 소개하며, 이는 단일 뷰 이미지, 텍스트 프롬프트, 또는 둘 모두에 따라 제어 가능한 일관된 다중 뷰 이미지를 생성하도록 설계되었습니다. FlexGen은 3D-aware 텍스트 주석에 대한 추가 조건부를 통해 제어 가능한 다중 뷰 합성을 다룹니다.

- **Technical Details**: FlexGen은 GPT-4V의 강력한 추론 능력을 활용하여 3D-aware 텍스트 주석을 생성합니다. 객체의 네 개의 정사각형 뷰를 분석하여 3D-aware 정보를 포함하는 텍스트 주석을 생성하며, 제안된 적응형 이중 제어 모듈을 통해 제어 신호를 통합하여 다중 뷰 이미지를 생성합니다. 이 모델은 텍스트 프롬프트를 수정하여 합리적인 그리고 일치하는 보이지 않는 부분을 생성합니다.

- **Performance Highlights**: 실험 결과, FlexGen은 기존의 다중 뷰 확산 모델에 비해 향상된 다중 제어 기능을 제공하며, 게임 개발, 애니메이션, 가상 현실 등 빠르고 유연한 3D 콘텐츠 제작이 필요한 분야에서 상당한 진전을 이루었습니다.



### DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Mod (https://arxiv.org/abs/2410.10738)
Comments:
          Accepted to NeurIPS 2024. Project page: this https URL

- **What's New**: DrivingDojo는 복잡한 주행 역학을 훈련하기 위해 특별히 제작된 첫 번째 데이터셋으로, 비디오 다양성이 제한된 기존 주행 데이터셋의 단점을 극복하고자 합니다.

- **Technical Details**: DrivingDojo는 다양한 주행 동작, 다중 에이전트 상호작용 및 개방형 주행 지식을 포함하여, 모델이 복잡한 동적 환경을 예측하고 시뮬레이션할 수 있도록 고안되었습니다. 또한, AIF(action instruction following) 벤치마크를 정의하여 주행 세계 모델의 성능을 평가할 수 있게 되었습니다.

- **Performance Highlights**: DrivingDojo는 기존 데이터셋에 비해 보다 다양하고 복잡한 주행 시나리오를 수집하여, 향후 자율 주행 세계 모델의 발전에 기여할 수 있는 많은 기회를 제공하고 있다는 점에서 중요한 발전을 나타냅니다.



### Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models (https://arxiv.org/abs/2410.10733)
Comments:
          Preprint. First two authors contributed equally to this work

- **What's New**: Deep Compression Autoencoder (DC-AE)는 고해상도 확산 모델을 가속화하기 위한 새로운 오토인코더 모델 군을 제시합니다. 기존의 오토인코더 모델들은 낮은 공간 압축 비율(예: 8x)에서 좋은 성능을 보였으나, 높은 공간 압축 비율(예: 64x)에서는 만족스러운 재구성 정확도를 유지하지 못했습니다.

- **Technical Details**: DC-AE는 Residual Autoencoding과 Decoupled High-Resolution Adaptation이라는 두 가지 주요 기술을 도입합니다. Residual Autoencoding은 높은 공간 압축 오토인코더의 최적화 난이도를 완화하기 위해 설계되었으며, Decoupled High-Resolution Adaptation은 높은 공간 압축 오토인코더의 일반화 페널티를 완화하기 위한 효율적인 훈련 전략입니다.

- **Performance Highlights**: DC-AE는 오토인코더의 공간 압축 비율을 최대 128까지 증가시키면서도 재구성 품질을 유지합니다. 예를 들어, ImageNet 512x512에서는 DC-AE를 사용하여 UViT-H에서 H100 GPU로 19.1배의 추론 속도 향상과 17.9배의 훈련 속도 향상을 달성하면서 FID 점수 또한 개선되었습니다.



### Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection (https://arxiv.org/abs/2410.10728)
- **What's New**: 이 논문에서는 대형 언어 모델(LLMs)을 활용하여 텐서 네트워크 모델의 랭크 선택(rank selection)을 안내하는 새로운 프레임워크를 제안합니다. LLM의 내재된 추론 능력과 도메인 지식을 통해 랭크 선택 과정의 해석 가능성을 높이고, 목적 함수를 효과적으로 최적화합니다. 이 접근 방식은 전문 지식이 없는 사용자도 텐서 네트워크 분해를 활용하고 랭크 선택 과정의 기본 원리를 이해할 수 있도록 합니다.

- **Technical Details**: 본 연구에서는 텐서 네트워크의 랭크 선택 문제에 대한 해석 가능성을 향상시키기 위한 LLM 기반 프레임워크를 설계합니다. 이 프레임워크는 LLM이 텐서 모드 간의 복잡한 상호작용을 분석하는 능력을 활용하며, 이를 통해 직관적이고 투명한 방식으로 랭크를 선택할 수 있게 합니다. 기존의 FCTN(Fully Connected Tensor Network) 분해의 랭크 선택 문제 역시 이 방법론으로 접근합니다.

- **Performance Highlights**: 실험 결과는 금융 고차원 데이터셋에서 우리의 방법이 해석 가능한 추론, 보지 못한 테스트 데이터에 대한 강력한 일반화 능력을 보이며, 반복적인 이용을 통해 자기 강화(self-enhancement)의 가능성을 나타냈음을 확인했습니다. 제안된 프레임워크는 기존의 기준 모델을 초월하는 성능을 기록했습니다.



### SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators (https://arxiv.org/abs/2410.10714)
- **What's New**: 이번 연구에서는 SeedLM이라는 새로운 포스트 트레이닝 압축 기법을 소개합니다. 이 기법은 조건부 랜덤 제너레이터의 시드를 사용하여 모델 가중치를 인코딩하고 압축하는 방법입니다. 특히, 각 가중치 블록에 대해 시드를 찾아 Linear Feedback Shift Register (LFSR)를 통해 랜덤 매트릭스를 효율적으로 생성하여 가중치 블록을 재구성합니다.

- **Technical Details**: SeedLM은 모델 가중치를 압축하는 혁신적인 방법으로, 각 가중치 블록을 의사 랜덤 프로젝션 기저 집합에 투사합니다. SeedLM에서 가중치 블록당 최적의 시드를 찾음으로써 낮은 압축 오류를 보장하며, 이를 통해 원래 모델의 정확도를 유지합니다. 이 방식은 가중치 값을 모두 저장하는 대신 일부 시드와 프로젝션 계수만을 저장하여 고차원 가중치 블록을 재구성하는 데 필요한 메모리 양을 크게 줄입니다. LFSR은 크립토그래피, 통신 및 오류 감지와 같은 다양한 응용 분야에서 널리 사용됩니다.

- **Performance Highlights**: SeedLM은 Llama 3 70B 모델을 대상으로 한 실험에서 4비트 및 3비트에서 기존 최첨단 기술보다 현저히 우수한 제로샷 정확도 유지율을 보여주었으며, FP16 기준 모델과 비교할 때 유사한 성능을 유지했습니다. FPGA 기반 테스트 결과, 70B 모델 크기로 증가함에 따라 4비트 SeedLM이 FP16 Llama 2/3 기준 대비 약 4배의 속도 향상에 도달하는 것으로 나타났습니다.



### Early Diagnoses of Acute Lymphoblastic Leukemia Using YOLOv8 and YOLOv11 Deep Learning Models (https://arxiv.org/abs/2410.10701)
Comments:
          4 pages, 6 figures, 3 tables

- **What's New**: 이 연구는 Acute Lymphoblastic Leukemia (ALL) 탐지를 위한 YOLOv8 및 YOLOv11 모델을 처음으로 적용하여 백혈구를 악성과 양성으로 분류하고 초기 단계의 ALL을 포함한 다양한 단계의 ALL을 확인합니다.

- **Technical Details**: 이미지 처리 기법과 딥러닝 기술을 사용하여 혈액암인 Acute Lymphoblastic Leukemia를 탐지하는데 중점을 두었습니다. Segmentation 기법을 통해 데이터를 준비하고 transfer learning 및 fine-tuning 기법을 적용하여 모델의 정확도를 98.8% 이상으로 향상시켰습니다.

- **Performance Highlights**: YOLOv11 모델을 사용하여 연속된 100 epochs의 학습 과정에서 높은 정확도를 달성했습니다. 특히, 모델은 여러 데이터셋과 다양한 실제 상황에서도 일관되게 뛰어난 성능을 보여줍니다.



### Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues (https://arxiv.org/abs/2410.10700)
- **What's New**: 이 연구에서는 멀티턴(multi-turn) 상호작용에서의 대형 언어 모델(Large Language Models, LLMs)의 안전 취약점을 다룹니다. 악의적인 사용자가 여러 쿼리에서 해로운 의도를 숨기는 방법을 탐구하며, 새로운 공격 방법인 ActorAttack을 소개합니다.

- **Technical Details**: ActorAttack은 actor-network theory에서 영감을 받아, 의미적으로 연결된 actor의 네트워크를 모델링하여 다채롭고 효과적인 공격 경로를 생성합니다. 이 연구는(1) benign한 대화 주제를 통해 해로운 의도를 숨기는 방법과 (2) 동일한 해로운 대상으로 향하는 다양한 공격 경로를 발견하는 두 가지 도전을 다룹니다.

- **Performance Highlights**: 실험 결과, ActorAttack은 여러 가지 정렬된 LLMs에서 기존 단일 턴 및 멀티턴 공격 방법을 능가하며, 특히 GPT-o1에서도 높은 품질의 공격을 발견합니다. ActorAttack을 통해 생성된 데이터셋인 SafeMTData가 LLMs의 안전성을 높이는 데 기여함을 보여주고 있습니다.



### Building a Multivariate Time Series Benchmarking Datasets Inspired by Natural Language Processing (NLP) (https://arxiv.org/abs/2410.10687)
- **What's New**: 시간 시계열 분석을 위한 새로운 벤치마크 데이터셋 생성 접근법이 소개됩니다. 이 논문은 자연어 처리(NLP)에서의 벤치마크 데이터셋 생성 방법론을 기반으로 하며, 시계열 데이터의 독특한 도전에 적합하도록 이를 조정합니다.

- **Technical Details**: 이 연구에서는 M4 대회 데이터셋과 전력 소비 데이터셋(ECL)을 벤치마크 자료로 활용하여 시간 시계열 모델의 예측 성능을 평가합니다. 또한 다양한 도메인에서의 128개의 단변량 및 30개의 다변량 데이터셋을 포함하는 UEA 및 UCR 시간 시계열 분류 데이터셋을 제안합니다. 또한 Yahoo의 웹 트래픽을 기반으로 한 1600만 개 레이블된 시계열 데이터를 anomaly detection 벤치마크로 사용합니다.

- **Performance Highlights**: 제안된 방법은 시간 시계열 모델의 예측 및 anomaly detection 능력을 한층 높일 것으로 기대되며, 멀티태스크 학습(multi-task learning) 전략을 통해 성능 향상에 기여할 것입니다. 이 연구는 시계열 분석 및 모델링의 최첨단을 발전시키는 데 중요한 기여를 할 것입니다.



### Combinatorial Multi-armed Bandits: Arm Selection via Group Testing (https://arxiv.org/abs/2410.10679)
Comments:
          26 pages

- **What's New**: 본 논문은 조합적 다중팔찌 문제(combinatorial multi-armed bandit, CMAB)에서 반응 피드백이 주어지는 상황과 초팔찌(super-arm) 크기에 대한 한계를 고려합니다. 기존 알고리즘이 완벽한 오라클(oracle)에 의존하는 반면, 본 논문은 이를 대체할 수 있는 새로운 알고리즘을 제안하여 계산 복잡도를 혁신적으로 감소시킵니다.

- **Technical Details**: 제안된 GT+QTS(Group Testing + Quantized Thompson Sampling) 알고리즘은 그룹 테스트(group testing)를 통해 초팔찌를 선택하고, 양자화된 톰슨 샘플링(quantized Thompson sampling) 방식으로 매개변수를 추정합니다. 이 알고리즘은 보상 함수의 일반적인 분리 가능성 가정(separability assumption)을 이용하여 초팔찌 선택 오라클의 복잡도를 `O(log m)`으로 줄입니다.

- **Performance Highlights**: GT+QTS 알고리즘은 기존의 알고리즘들과 동일한 후회(regret) 수준을 유지하면서 복잡도를 최소화합니다. 특히, 초팔찌가 많을 경우 기존 오라클 기반 접근 방식에 비해 계산 복잡도를 적어도 지수적으로 감소시킬 수 있다는 점이 특징입니다.



### Enhancing Robustness in Deep Reinforcement Learning: A Lyapunov Exponent Approach (https://arxiv.org/abs/2410.10674)
- **What's New**: 이 논문에서는 심층 강화 학습(Deep Reinforcement Learning, DRL) 정책의 관측 노이즈 또는 적대적 공격에 대한 강건성을 평가합니다. 작은 상태 변동에 대해 정책이 결정론적으로 카오틱해질 수 있음을 보여주며, 이를 통해 DRL의 실제 적용 가능성에 대한 두 가지 문제를 제기합니다.

- **Technical Details**: Maximal Lyapunov Exponent regularisation을 통해 Dreamer V3 아키텍처를 개선하여 정책의 학습을 더욱 안정적으로 만들고, 시스템의 카오틱한 동역학을 줄이는 방법을 제시합니다. 이 기법은 Recurrent State Space 모델을 사용하여 지역 상태 발산을 추정하고 이를 정책 손실에 포함시킵니다.

- **Performance Highlights**: 이 새로운 접근 방식은 센서 노이즈나 적대적 공격에 대한 정책의 강건성을 향상시켜, 심층 강화 학습 에이전트가 실제 환경에서 보다 효과적으로 작동할 수 있게 합니다.



### Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers (https://arxiv.org/abs/2410.10665)
Comments:
          Project GitHub repository at this https URL

- **What's New**: 이 논문은 대규모 언어 모델(LLMs)이 개발도상국의 경제에 기여할 수 있는 가능성을 제시하면서도, 실제로는 영어 사용자에게 유리한 경향이 있음을 강조합니다.

- **Technical Details**: FLORES-200, FLORES+, Ethnologue 및 World Development Indicators 데이터를 분석하여, 저소득 및 중저소득 국가의 언어 사용자들은 OpenAI의 GPT 모델을 API를 통해 사용할 때 더 높은 비용을 지불해야 함을 알렸습니다. 토큰화(tokenization) 프로세스에 의해 이러한 비용 차이는 1.5억 명에 달하는 사용자가 영어 사용자보다 4배에서 6배 높은 비용을 부담하게 된다는 점에서 심각합니다.

- **Performance Highlights**: 저자들은 번역 작업의 질을 기준으로 LLM이 저자원(low-resource) 언어에서 낮은 성능을 보이며, 이는 높은 비용과 낮은 성능이라는 이중의 위협(double jeopardy)에 해당함을 보여줍니다. 이러한 토큰화에서의 분열(fragmentation)이 기후에 미치는 직접적인 영향도 논의되었습니다.



### Transforming Game Play: A Comparative Study of DCQN and DTQN Architectures in Reinforcement Learning (https://arxiv.org/abs/2410.10660)
Comments:
          KSU C-Day Spring 2024

- **What's New**: 본 연구는 Convolutional Neural Networks (CNNs)와 Transformer 아키텍처를 활용한 Deep Q-Networks (DQNs)의 성능을 세 가지 Atari 게임에서 비교 분석했습니다. Transformer 기반 DQNs가 상대적으로 미개척 영역임을 강조하며 DCQNs와 DTQNs의 성능 차이를 평가했습니다.

- **Technical Details**: 연구는 Arcade Learning Environment (ALE)와 OpenAI Gym을 사용해 Atari 2600 게임의 ROM에 접근했습니다. DCQN은 35-40 million parameter 범위에서 ViT 및 Projection Architectures를 사용하여 DTQN보다 속도에서 우수함을 입증했습니다. 또한, Centipede를 제외한 모든 게임에서 DCQN이 DTQN보다 더 높은 성능을 보였습니다.

- **Performance Highlights**: DCQN 모델은 전반적으로 처리 속도가 더 빠르고, 모든 게임에서 더 나은 성능을 보였으며, DTQN은 DCQN보다 2-3배 느렸습니다. 이를 통해 CNN 기반 모델의 우수성을 확인했습니다.



### Generative AI and Its Impact on Personalized Intelligent Tutoring Systems (https://arxiv.org/abs/2410.10650)
Comments:
          Scientific Report (Under Review)

- **What's New**: Generative AI(생성 AI)가 Intelligent Tutoring Systems(ITS)에 통합되어 개인 맞춤형 교육을 위해 동적인 콘텐츠 생성, 실시간 피드백 및 적응형 학습 경로를 가능하게 합니다.

- **Technical Details**: 대형 언어 모델(LLM, Large Language Models)인 GPT-4를 활용하여 자동 질문 생성, 맞춤 피드백 메커니즘 및 개별 학습자의 요구에 응답하는 대화 시스템을 구현합니다. 이 시스템들은 교육내용의 정확성, AI 모델의 고유 편향 완화, 학습자 참여 유지와 같은 중요한 도전 과제에 직면해 있습니다.

- **Performance Highlights**: Generative AI는 더 개인화되고 적응적인 학습 경험을 제공하여 학습자의 참여와 이해를 높입니다. 예를 들어, LLM은 학생의 이전 응답에 따라 적절한 난이도의 맞춤 질문을 생성하고, 실시간으로 깊이 있는 피드백을 제공합니다.



### DR-MPC: Deep Residual Model Predictive Control for Real-world Social Navigation (https://arxiv.org/abs/2410.10646)
Comments:
          8 pages, 8 figures, under review for IEEE Robotics and Automation Letters (RA-L)

- **What's New**: 본 논문은 로봇이 복잡한 인간 움직임 패턴을 안전하게 탐색할 수 있도록 보조하는 Deep Residual Model Predictive Control (DR-MPC) 방법을 제안합니다. DR-MPC는 전통적인 DRL의 문제점들을 해결하여 실제 군중 탐색 데이터를 바탕으로 빠르고 안전한 학습을 가능하게 합니다.

- **Technical Details**: DR-MPC는 Model Predictive Control (MPC)과 model-free Deep Reinforcement Learning (DRL)을 통합한 방법입니다. 전통적인 DRL의 데이터 요구와 초기 행동의 안전성 문제를 극복함으로써, MPC 기반 경로 추적으로 초기화된 DR-MPC는 로봇이 인간과 효과적으로 상호작용하도록 단계적으로 학습합니다. 이를 통해 시뮬레이션 환경에서 기존 방법들보다 월등한 성능을 보입니다.

- **Performance Highlights**: DR-MPC는 4시간 미만의 훈련 데이터로 다양한 군중 상황에서 로봇의 탐색을 성공적으로 수행할 수 있도록 만들었습니다. 시뮬레이션에서 DR-MPC는 기존 DRL 및 Residual DRL 모델 대비 크게 성능이 향상됨을 입증하였으며, 실제 실험에서도 적은 오류로 로봇의 탐색을 가능하게 하였습니다.



### Adapt-$\infty$: Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection (https://arxiv.org/abs/2410.10636)
Comments:
          First two authors contributed equally. Code: this https URL

- **What's New**: 본 연구는 Lifelong Instruction Tuning (LiIT) 문제를 데이터 선택 관점에서 재구성하여, 모델이 이전과 새로운 데이터셋에서 유익한 샘플을 자동으로 선택할 수 있도록 하는 새로운 방법론인 Adapt-$\infty$를 제안합니다.

- **Technical Details**: Adapt-$\infty$는 리프레시 부족을 방지하고 샘플 효율성과 효과성을 동적으로 균형 맞추는 새로운 다중 방향 및 적응형 데이터 선택 방법입니다. 이 방법은 데이터 샘플의 그래디언트 벡터를 기반으로 의사 스킬 클러스터를 구성하고, 각 클러스터에서 최적의 데이터 선택기를 선택하는 과정을 포함합니다. 추가적으로, 클러스터별 영구 데이터 가지치기 전략을 도입하여 데이터셋의 컨트롤을 형성합니다.

- **Performance Highlights**: Adapt-$\infty$를 사용하여 훈련을 진행하면, 특히 드문 작업에 대해 심각한 망각 현상을 줄이고, 상대적으로 0.9%의 망각률로 기술 전이가 향상되는 것을 확인했습니다. 이를 통해 Adapt-$\infty$는 효율적이고 효과적인 평생 학습을 위한 강력한 프레임워크 역할을 수행합니다.



### Thinking LLMs: General Instruction Following with Thought Generation (https://arxiv.org/abs/2410.10630)
- **What's New**: 본 논문에서는 기존의 LLM(대형 언어 모델)에게 '사고' 능력을 부여하기 위한 새로운 훈련 방법을 제안합니다. 이 방법은 기존 모델을 추가적인 인간 데이터 없이도 복잡한 명령을 따르는 데 필요한 사고 과정을 생성하고 최적화하는 방법입니다.

- **Technical Details**: 우리는 사고 선호 최적화(Thought Preference Optimization, TPO)라는 메서드를 통해 LLM이 응답하기 전에 내부적으로 사고하도록 훈련합니다. 이 방법은 여러 번의 탐색 및 최적화를 통해 이루어지며, AI 피드백으로부터 강화 학습(Reinforcement Learning from AI Feedback, RLAIF) 방식을 채택합니다. 이는 모델이 주어진 명령에 대해 사고를 기록하고, 그에 따라 응답을 생성하도록 합니다.

- **Performance Highlights**: 이 연구의 결과는 AlpacaEval와 Arena-Hard 벤치마크에서 각각 52.5%와 37.3%라는 우수한 성과를 나타냈습니다. 특히, 사고를 통한 성과 향상은 전통적인 문제 해결 및 추론 작업뿐만 아니라 일반 지식, 마케팅 및 건강 분야 등 비추론 카테고리에서도 확인되었습니다.



### Modeling News Interactions and Influence for Financial Market Prediction (https://arxiv.org/abs/2410.10614)
Comments:
          Accepted by EMNLP 2024

- **What's New**: 이번 논문에서는 FININ (Financial Interconnected News Influence Network)이라는 금융 시장 예측 모델을 소개합니다. 이 모델은 뉴스 사건과 시장 움직임 사이의 연결뿐만 아니라 뉴스 항목 간의 상호 작용을 포착하는 데 중점을 두고 있습니다.

- **Technical Details**: FININ 모델은 데이터 융합 인코더와 시장 인식 영향 정량화기로 구성되어 있습니다. 데이터 융합 인코더는 다양한 입력을 다르게 인코딩하여 멀티모달(multi-modal) 데이터를 처리합니다. 시장 인식 영향 정량화기는 뉴스 항목과 가격 간의 관계를 분석합니다.

- **Performance Highlights**: FININ은 S&P 500과 NASDAQ 100 지수에 대한 실험에서 기존의 최신 방법들보다 우수함을 입증했습니다. S&P 500과 NASDAQ 100에서 각각 0.429 및 0.341의 개선된 Sharpe 비율을 달성하며, 뉴스의 시장 가격 반응 지연, 뉴스의 장기 메모리 효과, 재무 뉴스 감정 분석의 한계에 대한 통찰을 제공합니다.



### BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI (https://arxiv.org/abs/2410.10604)
- **What's New**: 본 논문에서는 다양한 MRI 모달리티를 활용한 뇌 이미지 분석을 위한 새로운 다중 모달 비전 사전 학습 프레임워크인 BrainMVP를 제안합니다. BrainMVP는 불완전한 모달리티 문제를 해결하고 다중 모달 정보 융합을 실현합니다.

- **Technical Details**: BrainMVP는 16,022개의 뇌 MRI 스캔 데이터셋을 바탕으로 설정되며, 크로스 모달 재구성이 이루어져 각 모달리티의 독특한 영상 임베딩을 학습합니다. 모달리티 별 데이터 증류 모듈을 통해 각 MRI 이미지의 본질적 표현을 추출하고, 적절한 모달리티 인식을 통해 크로스 모달 연관성을 높입니다.

- **Performance Highlights**: BrainMVP 모델은 6가지 분할 기준에서 0.28%-14.47%의 Dice Score 개선과 4개의 개별 분류 작업에서 0.65%-18.07%의 일관된 정확성을 보여주며, 기존 선도적인 사전 학습 방법들보다 우수한 성능을 입증합니다.



### VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents (https://arxiv.org/abs/2410.10594)
- **What's New**: 이 논문에서는 기존의 텍스트 기반 Retrieval-augmented generation (RAG) 시스템의 한계를 극복하기 위해 비전-언어 모델(Vision-Language Model, VLM)을 이용한 새로운 RAG 파이프라인인 VisRAG를 제안합니다.

- **Technical Details**: VisRAG는 문서를 직접 이미지로 임베딩하여 VLM을 통해 정보를 추출하는 방식으로 동작합니다. VisRAG-Ret와 VisRAG-Gen이라는 두 구성 요소로 이루어져 있으며, 이들은 각각 이미지 기반 정보 검색과 생성 기능을 수행합니다.

- **Performance Highlights**: VisRAG는 전통적인 텍스트 기반 RAG에 비해 검색 및 생성 단계 모두에서 성능이 25-39% 향상되었으며, 특히 다중 문서 처리를 효율적으로 수행할 수 있는 가능성이 확인되었습니다.



### Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation of Code-Mixed Sentences (https://arxiv.org/abs/2410.10580)
Comments:
          Manuscript submitted to COLING 2025

- **What's New**: 코드 혼합(code-mixing)된 문장 생성을 위한 새로운 방법인 Controlled Generation을 제안합니다. 이 방법은 코드 혼합 정도(Code-Mixing Degree, CMD)를 파라미터화하여 주어진 영어 문장에서 의미적으로 동등한 여러 가지 코드 혼합 문장을 생성할 수 있게 합니다.

- **Technical Details**: 또한, 새로운 평가 지표인 GAME(골드 스탠다드 비독립적 평가 지표)를 소개합니다. GAME는 언어와 골드 스탠다드에 비독립적이며, 다른 지표들과 달리 평가를 위한 코드 혼합된 문장에 대해 골드 스탠다드를 필요로 하지 않아서 인간 주석자가 필요 없습니다. 이 지표는 의미적으로 동등한 코드 혼합 문장을 평가할 때, BLEU 점수보다 낮은 표준 편차를 보입니다.

- **Performance Highlights**: 4개 언어 쌍(영어-{힌디어, 벵골어, 프랑스어, 스페인어})에 대한 골드 스탠다드 코드 혼합 문장 데이터셋을 생성하고 공개하여 코드 혼합에 대한 더 많은 계산 연구를 유도합니다.



### Burning RED: Unlocking Subtask-Driven Reinforcement Learning and Risk-Awareness in Average-Reward Markov Decision Processes (https://arxiv.org/abs/2410.10578)
Comments:
          arXiv admin note: substantial text overlap with arXiv:2006.16318, arXiv:2110.13855 by other authors

- **What's New**: 이번 연구에서는 average-reward Markov decision processes (MDPs)의 독특한 구조적 특성을 활용하여 
Reward-Extended Differential (RED) reinforcement learning이라는 새로운 RL 프레임워크를 소개합니다. 이 프레임워크는 average-reward 환경에서 여러 서브태스크를 동시에 해결할 수 있도록 설계되었습니다.

- **Technical Details**: RED 프레임워크의 핵심은 reward-extended temporal-difference (TD) error라는 새로운 개념입니다. 이 구조는 기존의 TD error를 확장한 것으로, average-reward MDP의 특성과 결합되어 여러 서브태스크를 동시 해결 가능하게 합니다.

- **Performance Highlights**: 우리는 RED RL 알고리즘을 사용하여 CVaR나 conditional value-at-risk 리스크 측정의 최적화 문제를 온라인 방식으로 해결할 수 있음을 보여주었습니다. 이는 현재의 최첨단 방법들이 처리하기 어려운 문제를 해결하는 데 있어 RED RL의 잠재력을 입증합니다.



### ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection (https://arxiv.org/abs/2410.10554)
- **What's New**: 본 논문은 ROSAR라는 새로운 프레임워크를 소개하며, 자율 수중 차량이 생성한 사이드 스캔 소나(SSS) 이미지에 특화된 깊은 학습 객체 탐지 모델의 견고성을 향상시킵니다.

- **Technical Details**: ROSAR는 지식 증류(Knowledge Distillation, KD)와 적대적 재훈련(adversarial retraining)을 결합하여 SSS 노이즈에 대한 모델의 효율성과 견고성을 동시 해결하는 접근법을 제안합니다. 이 프레임워크에서는 세 가지 새로운 SSS 데이터셋을 공개하며, 특정 안전 속성을 정의하고, 이를 바탕으로 적대적 데이터셋을 생성하여 재훈련을 수행합니다.

- **Performance Highlights**: ROSAR는 PGD(Projected Gradient Descent) 및 패치 기반 적대적 공격을 통한 비교 분석에서 SSS 특수 조건 하에서 모델의 견고성 및 탐지 정확도를 크게 향상시켜, 최대 1.85%의 개선을 보여주었습니다.



### SLaNC: Static LayerNorm Calibration (https://arxiv.org/abs/2410.10553)
Comments:
          9 pages, 3 figures, NeurIPS 2024 MLNCP Workshop

- **What's New**: 최근 대규모 언어 모델(LLMs)과 관련하여, 이 논문은 Transformer 모델에서의 LayerNorm 계산 시 발생하는 수치적 문제를 해결하기 위한 새로운 기법을 제안하고 있습니다. 이 기법은 FP16 및 FP8 포맷에서의 오버플로우(overflow) 및 언더플로우(underflow) 문제를 효과적으로 제거할 수 있도록 설계되었습니다.

- **Technical Details**: 제안된 기법인 SLaNC(Static LayerNorm Calibration)는 LayerNorm의 입력을 스케일링(scaling)하는 간단한 방법을 제공합니다. 이 방식은 이전의 선형(Linear) 계층의 정적 가중치(static weights)에 기반하여 스케일링 요소를 오프라인에서 계산합니다. 따라서 추론(inference) 동안 추가적인 지연(latency)이나 계산 오버헤드가 발생하지 않습니다.

- **Performance Highlights**: SLaNC 기법을 적용하면 다양한 하드웨어 아키텍처에서 부드럽고 정확하며 자원 효율적인 추론이 가능해집니다. 본 논문은 이론적 근거와 함께 이를 뒷받침하는 수치적 시뮬레이션 결과를 제공합니다.



### Hybrid Transformer for Early Alzheimer's Detection: Integration of Handwriting-Based 2D Images and 1D Signal Features (https://arxiv.org/abs/2410.10547)
- **What's New**: 이번 연구에서는 알츠하이머병(AD) 조기 탐지를 위해 2D 손글씨 이미지와 1D 동적 손글씨 신호를 동시에 통합하는 새로운 하이브리드 어텐션 모델을 제안합니다. 이는 기존의 수동으로 추출한 특징이나 단순한 머신 러닝 모델에 의존하는 접근 방식을 넘어서는 혁신적인 방법입니다.

- **Technical Details**: 제안한 모델은 게이트 메커니즘을 활용하여 2D 손글씨의 공간 패턴과 1D 동적 특징 간의 상관관계를 학습하고, 멀티모달(multi-modal) 데이터를 효과적으로 결합합니다. 새롭게 도입된 손실 함수는 템플릿 대조 손실(template contrastive loss)과 크로스 엔트로피 손실(cross-entropy loss)을 결합하여 분류 성능을 향상시킵니다.

- **Performance Highlights**: DARWIN 데이터셋을 대상으로 한 평가에서, 본 모델은 90.32%의 F1 점수와 90.91%의 정확도를 기록하며, Task 8('L' writing)에서 이전 최상 성능보다 각각 4.61% 및 6.06% 우수한 성과를 보였습니다.



### Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models (https://arxiv.org/abs/2410.10542)
Comments:
          Accepted on NLLP at EMNLP 2024

- **What's New**: 본 연구에서는 인도의 법원 판결 예측을 위한 실제 시나리오를 탐구하고, InLegalBERT, BERT, XLNet과 같은 다양한 transformer 기반 모델과 LLMs인 Llama-2 및 GPT-3.5 Turbo를 활용합니다. 사례가 재판을 위해 제시될 때 순간적인 정보를 기반으로 한 판결 예측을 시도하며, 후향적 분석 없이 실제 상황을 모방합니다.

- **Technical Details**: transformer 모델의 효율성을 평가하고 법적 사실의 요약을 통해 예측 품질을 향상시키는 방법을 실험합니다. 계층적 transformer 모델을 도입하여 판결 사실을 최적화하고, 법령, 판례, 주장과 같은 추가적인 법적 정보를 포함하여 LLMs의 성능을 개선합니다. 이 연구는 GPT-3.5 Turbo가 인도의 법적 판결 예측에서 뛰어난 성능을 보이는 것을 발견했습니다.

- **Performance Highlights**: 자동 평가 및 인간 평가 모두에서 LLMs가 전문가 수준의 성능에 도달하지 못했음을 보이며, 판결 예측과 설명 품질 모두에서 개선의 여지가 있음을 시사합니다. Clarity와 Linking이라는 두 가지 새로운 평가 지표를 정의하여 LLM이 생성한 예측 및 설명의 품질을 평가합니다.



### Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Featur (https://arxiv.org/abs/2410.10537)
Comments:
          33 pages, 8 figures, code repository: this https URL

- **What's New**: 본 연구에서는 음성 병리 (voice pathology) 탐지를 위한 새로운 Robust 특징 집합을 제안합니다. 이 특징 집합은 음향 (acoustic) 수작업 특징의 조합에 기반하며, 새로운 특징으로 피치 차이 (pitch difference)를 도입합니다.

- **Technical Details**: 제안된 방법은 Saarbrücken Voice Database (SVD)에서 수집된 데이터와 K-Means Synthetic Minority Over-Sampling Technique (SMOTE) 알고리즘을 사용한 전처리 (preprocessing)를 결합하여 클래스 불균형 (class imbalance) 문제를 해결합니다. 다양한 기계 학습 (ML) 모델을 이진 분류기 (binary classifiers)로 적용하였으며, 서포트 벡터 머신 (SVM), K-최근접 이웃 (k-nearest neighbors), 나이브 베이즈 (naive Bayes), 결정 트리 (decision tree), 랜덤 포레스트 (random forest), 아다부스트 (AdaBoost) 분류기를 사용하였습니다. 각 분류기의 가능한 하이퍼파라미터 (hyperparameters)와 특징의 하위 집합에 대해 그리드 서치 (grid search)를 수행하여 최상의 분류 방법을 결정합니다.

- **Performance Highlights**: 본 접근법은 음성 병리 탐지에서 최첨단 성능을 달성하였으며, SVD 데이터베이스에서 비가중 평균 재현율 (unweighted average recall)로 측정되었습니다. 불균형 데이터에서의 정확도 (accuracy)를 부정확한 지표로 판단하여 생략하였습니다. 이를 통해 임상 (clinical)에서 ML 방법을 활용할 수 있는 중요한 가능성을 보여주며, 음성 병리의 객관적인 검사를 위한 유용한 도구를 제공합니다. 결과는 반복적인 계층화된 교차 검증 (stratified cross-validation)을 통해 결과의 과대평가를 방지하여 더욱 향상되었습니다.



### Get Rid of Task Isolation: A Continuous Multi-task Spatio-Temporal Learning Framework (https://arxiv.org/abs/2410.10524)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 논문에서는 도시 지능(urban intelligence)을 위한 새로운 Continuous Multi-task Spatio-Temporal learning framework(CMuST)를 제안합니다. 기존의 spatiotemporal 모델들이 환경 변화에 적응하지 못하는 한계를 극복하고, 다양한 도시 데이터 간의 상관관계를 효과적으로 모델링합니다.

- **Technical Details**: CMuST는 Multi-dimensional Spatio-Temporal Interaction Network(MSTI)를 통해 다양한 차원에서의 상호작용을 캡처하며, Rolling Adaptation training scheme(RoAda)를 통해 지속적인 작업 학습을 최적화합니다. RoAda는 작업 고유성을 유지하면서도 서로 연관된 작업 간의 패턴을 반복적으로 모델링합니다.

- **Performance Highlights**: CMuST는 세 개의 도시에서 구축된 벤치마크 데이터셋을 이용해 평가되었으며, 기존 SOAT 방법들과 비교하여 적은 데이터와 새로운 도메인 작업에서 성능 향상을 실현하였습니다.



### Continual Deep Reinforcement Learning to Prevent Catastrophic Forgetting in Jamming Mitigation (https://arxiv.org/abs/2410.10521)
Comments:
          IEEE MILCOM 2024

- **What's New**: 본 논문에서는 Deep Reinforcement Learning (DRL)의 기존 한계를 개선하기 위해 기존의 jamming 패턴을 기억하고 새로운 패턴을 학습하는 방법을 제안합니다. 이 연구는 DRL이 jamming 탐지 및 완화에서 직면하는 catastrophic forgetting 문제를 해결하는 방안을 제시하며 PackNet을 기반으로 한 접근법을 사용합니다.

- **Technical Details**: 연구에서는 패턴 인식을 위해 Deep Q-network (DQN)와 Soft Actor-Critic (SAC) 알고리즘을 활용하고, PackNet 구조적 방법론을 사용하여 기존 jamming 패턴의 지식을 유지하며 새로운 패턴을 효율적으로 학습할 수 있도록 합니다. 이 방법은 지속적 학습을 통해 다양한 jamming 시나리오에 대한 적응성을 높입니다.

- **Performance Highlights**: 본 연구는 기존 DRL 방법에 비해 우수한 anti-jamming 성능을 실현했으며, 패턴 탐지 및 완화에 있어 메트릭스 개선을 통해 보안성과 신뢰성을 높였습니다. 또한, PackNet의 통합을 통해 새로운 jamming 전략을 학습하는 효율성을 보여주었습니다.



### UniGEM: A Unified Approach to Generation and Property Prediction for Molecules (https://arxiv.org/abs/2410.10516)
Comments:
          11 pages, 5 figures

- **What's New**: 본 논문에서는 Molecular generation(분자 생성)과 molecular property prediction(분자 속성 예측)의 통합 접근법을 제시하는 UniGEM이라는 모델을 제안합니다. 두 가지 작업을 효과적으로 해결하는 것을 목표로 하며, 특히 두 가지 작업을 조화롭게 통합하는 방법에 초점을 맞추고 있습니다.

- **Technical Details**: UniGEM은 두 단계로 구성된 diffusion model(확산 모델) 기반의 생성 접근법입니다. 이 모델은 'molecule nucleation phase'(분자 핵 생성 단계)와 'molecule growth phase'(분자 성장 단계)로 나뉘며, 두 가지 단계를 명확하게 분리하여 분자의 구조를 더 효과적으로 생성합니다. 핵 생성 후에는 예측 손실을 확산 과정에 통합하여 양쪽 작업을 최적화합니다.

- **Performance Highlights**: UniGEM은 분자 생성 및 속성 예측 작업에서 모두 우수한 성능을 보입니다. 특히, UniGEM은 전통적인 diffusion-based 모델인 EDM보다 분자 안정성을 약 10% 개선하였으며, 속성 예측에서도 실험 결과가 초기 모델보다 현저히 향상되었습니다. 이 모델은 추가적인 전처리 단계 없이도 훈련된 모델과 비슷한 정확도를 달성할 수 있습니다.



### Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation (https://arxiv.org/abs/2410.10489)
- **What's New**: 이 연구는 LLM의 성능이 특정 언어의 디지털 데이터 가용성과 어떤 관련이 있는지를 분석하였습니다. 연구 결과, GPT-4o가 특정 국가의 사회적 가치를 반영하는 능력의 44%가 해당 언어의 디지털 자원과 상관관계가 있었다고 밝혀졌습니다. 이는 디지털 자원이 부족한 언어에서 성능 저하를 초래하고, 특히 Global South(글로벌 남반구) 국가에서는 디지털 격차를 악화시킬 우려가 있습니다.

- **Technical Details**: 연구는 21개 국가-언어 쌍을 포함하여 94개의 설문 질문으로 구성된 대규모 데이터셋을 개발하였습니다. GPT-4o 모델은 특히 비영어 언어 처리에서 크게 개선되었으며, 새로운 tokenizer(토크나이저)의 도입으로 비영어 언어에 대한 효율성이 향상되었습니다. 이 모델은 또한 LRLs(low-resource languages)에서의 사회적 가치의 반영 정확성을 증가시킵니다.

- **Performance Highlights**: GPT-4o의 비영어 언어 퍼포먼스는 이전 모델에 비해 더 안정적으로 향상되었으며, 특히 Hindi에서는 토큰이 2.9배 감소하는 등의 성과를 보였습니다. 다국어 이해(STEM) 성능을 평가한 결과, 여러 저자들은 비영어 언어에서도 향상된 성과를 보고했으며, 특히 Swahili, Latvian, Welsh 등 저자원 언어에서 긍정적인 결과를 도출하였습니다.



### Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization (https://arxiv.org/abs/2410.10483)
Comments:
          Paper submitted to Computer in Biology and Medicine, ELSEVIER

- **What's New**: 이 연구는 신생아를 위한 AI 기반 시간 감지 시스템을 개발하는 방식으로 신생아의 생명 구제 지원을 향상시키고자 합니다. 특히, 출생 후 '황금 분' 동안 신속한 응급 처치 필요성을 강조합니다.

- **Technical Details**: 본 연구는 세 가지 단계의 방법론을 제안합니다: 첫째, 온도 변동 문제를 완화하기 위해 Gaussian mixture models (GMM) 기반 적응 정규화 기법을 제안합니다; 둘째, 온도 비디오 프레임 안에서 신생아의 존재를 감지하기 위해 AI 모델을 구현하고 배치합니다; 셋째, 모델의 예측을 평가하고 후처리하여 출생 시간(Time of Birth, ToB)을 추정합니다.

- **Performance Highlights**: 실제 성능 평가에서 신생아 탐지에 대한 정확도는 88.1%이며 재현율은 89.3%로 보고되었습니다. 이 방법은 수동 주석에 비해 절대 중앙 편차가 2.7초로 ToB 추정의 정확성을 보여줍니다.



### Model-Based Differentially Private Knowledge Transfer for Large Language Models (https://arxiv.org/abs/2410.10481)
- **What's New**: Llamdex라는 새로운 프레임워크를 제안하여 도메인별 지식을 최대한 활용하면서 개인정보 보호를 보장하는 방법을 제공합니다.

- **Technical Details**: Llamdex는 개인 정보 보호 기능이 있는 도메인 특화 모델을 LLM(large language models)에 통합하여, 기존의 방법들인 retrieval-augmented generation (RAG)나 differentially private data synthesis의 한계를 극복합니다.

- **Performance Highlights**: Llamdex는 기존 방법들에 비해 정확도를 최대 26% 향상시키며, LLM의 응답 정확도를 개선하면서도 원래 LLM과 유사한 추론 효율성을 유지합니다.



### Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification? (https://arxiv.org/abs/2410.10476)
- **What's New**: 본 연구에서는 7개의 오픈 및 클로즈드 소스의 Large Language Models (LLM)의 Temporal Relation Classification (TRC) 작업에서의 성능과 의사 결정 과정을 조사하였습니다.

- **Technical Details**: 이 작업에서는 예시 레이블을 활용한 In-Context Learning (ICL) 접근법과 Low-Rank Adaptation (LoRA) 기법을 사용하여 Llama2 모델을 세부 조정하여 성능을 측정했습니다. LLM의 자가 회귀적인 성질로 인해 마지막 부분에 집중하는 경향을 확인했습니다.

- **Performance Highlights**: 결과적으로, LLM들은 기존의 RoBERTa 기반의 소형 인코더 전용 모델에 비해 TRC 작업에서 성능이 저조하였고, 이는 LLM의 구조적 제한 때문으로 분석되었습니다.



### TABCF: Counterfactual Explanations for Tabular Data Using a Transformer-Based VAE (https://arxiv.org/abs/2410.10463)
Comments:
          Paper accepted at ICAIF '24: 5th ACM International Conference on AI in Finance, Brooklyn, NY, USA, November 2024

- **What's New**: TABCF라는 새로운 counterfactual (CF) 설명 방법이 소개되었습니다. 이 방법은 tabular (표 형식) 데이터의 복잡한 특성과 feature 간의 상관관계를 모델링하기 위해 transformer 기반의 Variational Autoencoder (VAE)를 활용합니다.

- **Technical Details**: TABCF는 mixed feature types (혼합 특성 유형)을 효과적으로 다루기 위해 continuous latent space (연속 잠재 공간)로의 매핑을 사용합니다. Gumbel-Softmax detokenizer를 활용하여 categorical reconstruction (범주별 재구성)을 정밀하게 수행하며, 전체적으로 미분 가능(differentiable)한 구조로 되어 있어 gradient flow (기울기 흐름)를 최적화합니다.

- **Performance Highlights**: 다섯 개의 금융 데이터셋에 대한 광범위한 정량적 평가를 통해 TABCF는 특정 feature types에 대한 bias를 보이지 않으며, 기존 방법들에 비해 더 효과적인 CF를 생성하는 것으로 나타났습니다.



### Compositional Shielding and Reinforcement Learning for Multi-Agent Systems (https://arxiv.org/abs/2410.10460)
- **What's New**: 이 논문은 다중 에이전트 시스템에서의 안전성을 보장하기 위한 새로운 접근 방식을 제안합니다. 에이전트 별로 개별적인 shield를 계산하여 스케일 문제를 해결하고, 각 shield가 지역적 특성을 보장하도록 합니다.

- **Technical Details**: 본 연구에서는 assume-guarantee reasoning을 적용하여 글로벌 안전 사양을 로컬 의무로 분해하는 사운드 증명 규칙을 제시합니다. 이를 통해 각 에이전트의 shield를 독립적으로 합성할 수 있으며, 통신 없이 안전성을 보장합니다.

- **Performance Highlights**: 이 프레임워크의 효과성을 두 가지 사례 연구를 통해 입증하였으며, 계산 시간을 몇 시간에서 몇 초로 단축하고 빠른 학습 수렴을 달성하였습니다.



### Mobility-Aware Federated Learning: Multi-Armed Bandit Based Selection in Vehicular Network (https://arxiv.org/abs/2410.10451)
Comments:
          Accepted by 2024 IEEE Globecom Workshops (GC Wkshps)

- **What's New**: 본 논문에서는 차량 네트워크에서의 연합 학습(federated learning, FL)을 위한 차량 선택 문제를 연구합니다. 차량이 도로 구간을 주행하면서 FL을 수행하는 Mobility-Aware Vehicular Federated Learning (MAVFL) 방안을 설계했습니다. 차량 이동으로 인해 일부 차량이 도로 구간을 벗어나면 훈련이 실패할 수 있으며, 이를 해결하기 위해 실시간 성공적인 훈련 참여 비율을 활용하여 차량 선택을 구현합니다.

- **Technical Details**: 제안된 MAVFL 방식은 차량들이 FL에 참여하기 위해 도로 구간을 통과하며, 각 차량의 모델 업로드 성공률을 실시간으로 평가합니다. 이 과정에서 차량의 이동성을 고려하여 훈련 손실(training loss) 및 지연(delay)을 걸러내는 다중 무장 강도(multi-armed bandit, MAB) 기반의 차량 선택 알고리즘을 설계했습니다. 이론적 수렴성을 분석하여 차량의 이동성이 훈련 손실에 미치는 영향을 도출합니다.

- **Performance Highlights**: 시뮬레이션 결과에 따르면, 제안된 알고리즘은 기존 기준선에 비해 약 28% 더 빠른 수렴속도를 보여주며 훈련 성능이 향상되었습니다. 이는 제안된 MAVFL 방식이 수렴 속도 및 훈련 지연 측면에서 효과적임을 입증합니다.



### Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs (https://arxiv.org/abs/2410.10441)
Comments:
          Tech report

- **What's New**: 비디오 이해를 위한 효율적인 추론을 제공하는 새로운 프롬프트 기반 시각 인식 프레임워크(Free Video-LLM)를 제시합니다.

- **Technical Details**: 이 프레임워크는 공간적-시간적 차원을 분리하고, 작업별 프롬프트에 따라 시간적 프레임 샘플링(temporal frame sampling)과 공간적 RoI 크롭(spatial RoI cropping)을 수행합니다. 이를 통해 비디오 프레임에서 생성되는 시각 토큰(visual tokens)의 수를 효과적으로 줄입니다.

- **Performance Highlights**: 우리의 방법은 여러 비디오 질문-응답 벤치마크에서 높은 성능을 유지하면서 토큰 수를 크게 줄여, 정확도와 계산 효율 간의 최적의 균형을 제공합니다.



### LKASeg:Remote-Sensing Image Semantic Segmentation with Large Kernel Attention and Full-Scale Skip Connections (https://arxiv.org/abs/2410.10433)
Comments:
          The paper is under consideration at 2025 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)

- **What's New**: 본 논문에서는 원격 감지 이미지의 의미적 분할을 위한 새로운 네트워크인 LKASeg를 제안합니다. 이 네트워크는 Large Kernel Attention (LKA)와 Full-Scale Skip Connections (FSC)을 결합하여, 전통적인 CNNs와 Transformers의 한계를 극복합니다.

- **Technical Details**: LKASeg는 ResNet-18 기반의 인코더, LKA 기반의 디코더, 및 전체 규모의 스킵 연결(FSC)로 구성됩니다. LKA는 글로벌 피처를 추출하면서도 self-attention의 계산 오버헤드를 피하고, 채널 적응성을 제공합니다.

- **Performance Highlights**: ISPRS Vaihingen 데이터셋에서 실험을 진행한 결과, mF1 점수 90.33%, mIoU 점수 82.77%를 달성하였습니다.



### FairMindSim: Alignment of Behavior, Emotion, and Belief in Humans and LLM Agents Amid Ethical Dilemmas (https://arxiv.org/abs/2410.10398)
- **What's New**: 이번 연구에서는 AI 정렬(AI alignment) 문제를 해결하기 위한 FairMindSim 이라는 새로운 시뮬레이션을 도입했습니다. 이 시뮬레이션은 불공정한 상황을 통해 도덕적 딜레마를 시뮬레이션하며, LLM(대규모 언어 모델) 에이전트가 인간의 행동을 시뮬레이션하는데 사용됩니다.

- **Technical Details**: FairMindSim은 전통적인 경제 게임을 결합하여 공정성과 정의에 대한 LLM과 인간의 행동 차이를 비교하는 도구입니다. 이 연구는 Belief-Reward Alignment Behavior Evolution Model (BREM)을 제안하며, 이는 recursive reward model (RRM)에 기반하여 믿음의 진화와 결정을 탐구합니다.

- **Performance Highlights**: 연구 결과, GPT-4o는 인간에 비해 공정성과 정의 감각이 뛰어난 것으로 나타났으나, 인간은 복잡한 감정적 안정성을 보여서 의사결정에 영향을 미친다는 발견을 했습니다.



### PIVOT-R: Primitive-Driven Waypoint-Aware World Model for Robotic Manipulation (https://arxiv.org/abs/2410.10394)
Comments:
          Accepted to NeurIPS 2024

- **What's New**: PIVOT-R은 로봇 조작을 위한 새로운 모델로, 과거의 단순한 데이터 적합성과는 달리 태스크 관련 웨이포인트 예측에 집중하여 로봇이 사용자 지시를 더 잘 수행할 수 있게 합니다.

- **Technical Details**: PIVOT-R은 웨이포인트 인식 월드 모델(Waypoint-aware World Model, WAWM)과 경량 액션 예측 모듈을 포함합니다. WAWM은 원시 행동 파싱(primitive action parsing) 및 원시 기반 웨이포인트 예측을 수행하며, 액션 예측 모듈은 저수준(low-level) 행동 디코딩에 중점을 둡니다. 또한 비동기적 계층 실행기(Asynchronous Hierarchical Executor, AHE)를 설계하여 모델의 계산 중복성을 줄이고 실행 효율성을 개선합니다.

- **Performance Highlights**: PIVOT-R은 SeaWave 벤치마크에서 최신(open-source) 모델보다 19.45%의 평균 상대 향상을 달성하였으며, AHE를 사용한 PIVOT-R의 실행 효율성은 28배 증가하고, 성능은 2.9% 하락한 것으로 나타났습니다.



### Stein Variational Evolution Strategies (https://arxiv.org/abs/2410.10390)
- **What's New**: Stein Variational Gradient Descent (SVGD)의 새로운 접근 방식을 제안하여, Evolution Strategies (ES)을 통해 gradient-free SVGD의 성능을 대폭 향상시켰습니다. 이 방법은 기존의 surrogate distribution을 필요로 하지 않습니다.

- **Technical Details**: 제안된 SV-CMA-ES는 SVGD의 데이타 업데이트에서 score term을 CMA-ES의 search distribution mean update로 교체하여 gradient-free SVGD의 효율성을 높입니다. 이는 다양한 어려운 문제에서 효과성을 입증합니다.

- **Performance Highlights**: SV-CMA-ES는 robot trajectory optimization과 reinforcement learning 등 여러 분야의 문제에서 이전의 gradient-free SVGD 방법에 비해 상당한 성능 개선을 보여줍니다.



### BookWorm: A Dataset for Character Description and Analysis (https://arxiv.org/abs/2410.10372)
Comments:
          30 pages, 2 figures, EMNLP 2024 Findings

- **What's New**: 이 연구에서는 복잡한 내러티브와 수많은 등장인물이 포함된 장편 문학 작품에서 등장인물을 이해하는 데 초점을 맞추고 있습니다. 'BookWorm'이라는 새로운 데이터셋을 도입하여 캐릭터 설명과 분석을 통해 등장인물의 발전과 사회적 맥락을 이해하는 여러 과제를 수행합니다.

- **Technical Details**: 우리는 두 가지 과제를 정의합니다: 등장인물 설명(character description)과 등장인물 분석(character analysis). BookWorm 데이터셋은 Gutenberg Project에서 도서와 관련된 인간 작성 설명과 분석을 쌍으로 구성합니다. 우리는 최첨단 long-context 모델의 성능을 평가하고, 데이터셋을 이용해 retrieval-based 접근 방식이 더 효과적임을 발견했습니다. 다양한 기법을 통해 캐릭터 정보를 검색하고, hierarchical 처리 방식보다 retrieval 기반 모델이 두 작업 모두에서 더 나은 성능을 발휘한다는 것을 입증했습니다.

- **Performance Highlights**: 조정(fine-tuned)된 모델을 사용한 경우, coreference 기반 retrieval 방식이 가장 사실적인 설명을 생성하는 것으로 나타났으며, 이는 사실(fact) 및 함축(entailment) 기반 메트릭을 통해 측정되었습니다. 본 연구는 장편 내러티브 이해에 대한 추가 연구를 촉진할 것이란 기대를 표현하고 있습니다.



### Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation (https://arxiv.org/abs/2410.10366)
Comments:
          BIBM 2024

- **What's New**: 이 논문은 의료 이미징 сегментация (segmentation)에서 반지도 학습 (SemiSL)과 대조 학습 (CL) 결합의 진전을 보여줍니다. 특히, 피사체(task)가 없는 경우에도 적은 주석으로 효과적인 모델 성능을 달성하는 방법을 제안합니다.

- **Technical Details**: 제안된 방법론은 학생 네트워크(student network)와 교사 네트워크(teacher network) 간의 친밀도 그래프 기반 지도 신호(affinity-graph-based supervision signals)를 설정하여 Semi-AGCL 프레임워크를 구성합니다. 또한 평균 패치 엔트로피 기반의 상호 패치 샘플링 방법을 설계하여 초기 특징 공간을 구축하고, 친밀도 그래프 손실 함수(affinity-graph-guided loss function)를 통해 학습된 표현의 품질을 향상시키고 과적합(overfitting)을 완화합니다.

- **Performance Highlights**: 실험 결과, 전체 주석 세트의 단 10%만 사용했음에도 불구하고, 제안한 모델은 완전 주석의 기준선과 함께 단 2.52%의 편차로 정확도에 접근했습니다. 특히, 주석의 5%만 사용된 상황에서도, dice metric에서 두 번째 최고 기준선을 23.09% 초과하여 성능이 크게 향상되었고, 특히 CRAG와 ACDC 데이터셋에서 26.57% 개선된 결과를 보였습니다.



### SpeGCL: Self-supervised Graph Spectrum Contrastive Learning without Positive Samples (https://arxiv.org/abs/2410.10365)
Comments:
          13 pages, 3 figures

- **What's New**: 본 연구에서는 기존의 Graph Contrastive Learning (GCL) 방법들이 고주파 정보(high-frequency information)를 충분히 활용하지 못하고, 대부분 시간 영역(time domain)에 초점을 맞추고 있다는 점을 지적합니다. 새로운 Spectral GCL 프레임워크(SpeGCL)를 제안하여, 고주파와 저주파 정보를 동시에 이용하는 방법을 제시합니다.

- **Technical Details**: SpeGCL은 Fourier 변환(Fourier transform)을 사용하여 노드 특성의 고주파와 저주파 정보를 추출하고, Fourier 공간에서 개선된 노드 특성 표현을 얻기 위한 대조 학습 메커니즘을 구축합니다. 이 모델은 오직 부적 샘플(negative samples)만을 사용하여 그래프 임베딩을 세련되게 조정하므로, 기존의 GCL 방법들이 양성 샘플(positive samples)에 의존하는 것과는 다르게 접근합니다.

- **Performance Highlights**: 광범위한 비지도 학습, 전이 학습(transfer learning), 반지도 학습(semi-supervised learning)에서 SpeGCL의 우수성을 검증하였으며, 기존 GCL 방법들에 비해 뛰어난 성능을 보였습니다.



### Disentangling Hate Across Target Identities (https://arxiv.org/abs/2410.10332)
- **What's New**: 이번 연구에서는 혐오 발언(HS) 탐지기에 있어 특정 대상 정체성에 대한 편향과 감정 및 고정관념(속성)이 탐지기 성능에 미치는 영향을 정량적으로 분석했습니다. 특히, 기존의 HateCheck 및 GPT-HateCheck 데이터 세트를 활용하여 HS 예측에 영향을 미치는 다양한 요인에 대한 새로운 통찰을 제공합니다.

- **Technical Details**: 이 연구는 혐오 발언 탐지기 모델이 특정 대상 정체성의 언급에 따라 더 높은 혐오 점수를 할당하는 경향이 있음을 보여줍니다. 또한 HS 탐지기는 부정적인 감정과 혐오성을 혼동하는 경향이 있으며, 이는 반발 발언이나 슬픔을 표현하는 게시물이 혐오적으로 분류되는 위험성을 내포하고 있습니다.

- **Performance Highlights**: 연구 결과는 HS 탐지기가 강한 고정관념에 대해서는 정확하게 예측하지만, 고정관념이 약한 경우에는 어려움을 겪는다는 것을 나타냅니다. 더불어 감정과 고정관념의 분석은 HS 예측에 대한 중요한 통찰을 제공하며, HS 탐지기의 정확성과 공정성을 개선할 수 있는 새로운 방향을 제시합니다.



### GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs (https://arxiv.org/abs/2410.10329)
Comments:
          Under Review

- **What's New**: 최근 연구에서 그래프 기반의 Foundation 모델(GFM)을 위한 GraphCLIP 프레임워크를 제안하여 cross-domain zero/few-shot 학습의 문제를 해결하고, self-supervised contrastive graph-summary pretraining 방식을 통해 강력한 전이학습 성능을 달성했습니다.

- **Technical Details**: GraphCLIP은 대규모 그래프-요약 쌍 데이터를 LLMs의 지원을 받아 생성하고 이를 활용하여 self-supervised contrastive pretraining을 수행합니다. 이 방법론은 invariant learning을 포함하여 cross-domain generalization을 강화하며, 주어진 데이터에 fine-tuning 없이 바로 적용할 수 있는 강력한 zero-shot 능력을 보장합니다. 또한, few-shot 학습을 위한 novel graph prompt tuning 기술을 도입하여 catastrophic forgetting을 최소화하고 학습 비용을 줄였습니다.

- **Performance Highlights**: 광범위한 실험을 통해 GraphCLIP은 다양한 데이터 세트에서 zero-shot 성과를 입증했으며, few-shot 환경에서도 최신의 기법들을 능가하는 성능을 보여주었습니다. 또한, 여러 하위 작업을 통해 GraphCLIP의 범용성을 평가하였습니다.



### DiRW: Path-Aware Digraph Learning for Heterophily (https://arxiv.org/abs/2410.10320)
Comments:
          Under Review

- **What's New**: 이번 연구에서는 Directed Random Walk (DiRW)라는 새로운 접근 방식을 제안하여, 기존 공간 기반 방법들의 효율성과 성능을 개선하는 동시에 지향 그래프(digraphs)에 대한 학습 패러다임을 제시합니다. DiRW는 무게 없이 노드 프로파일과 위상 구조를 고려하여 방향 인식 경로 샘플러를 최적화하여, 다양한 공간 기반 방법과 결합이 가능합니다.

- **Technical Details**: DiRW는 경로를 노드별로 시퀀스로 처리하며, 각 노드에 대해 잘 설계된 랜덤 워크를 수행합니다. 이를 통해 경로에 있는 노드의 순서를 유지하고 한 방향으로의 메시지 전파를 강화합니다. 또한, 노드의 특성을 고려하여 동적으로 이웃을 확장하여 특징 분포의 복잡성을 반영합니다.

- **Performance Highlights**: 9개의 데이터셋에서 진행한 광범위한 실험을 통해, DiRW는 대부분의 기존 공간 기반 방법에 플러그 앤 플레이 전략으로 성능을 향상시키고, 새로운 지향 그래프 학습 패러다임으로 SOTA(State Of The Art) 성능을 달성하는 것으로 나타났습니다.



### EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations (https://arxiv.org/abs/2410.10315)
Comments:
          10 pages, 2 figures

- **What's New**: 이 논문에서는 네트워크 자동화 작업을 위한 간단하고 경량화된 효율적인 Retrieval-Augmented Generation 프레임워크인 EasyRAG을 제안합니다. 이 프레임워크는 정확한 질문 응답, 간단한 배포, 효율적인 추론의 세 가지 장점을 가지고 있습니다.

- **Technical Details**: EasyRAG는 (1) 특정 데이터 처리 워크플로우, (2) 듀얼 라우트 스파스 리트리벌을 통한 코스 랭킹, (3) LLM 리랭커를 통한 재랭킹, (4) LLM 답변 생성 및 최적화를 통해 구성됩니다. 데이터 처리 단계에서 BeautifulSoup을 사용하여 HTML 문서에서 이미지 제목 및 텍스트를 추출하고, PP-OCRv4 모델을 통해 이미지에서 텍스트 콘텐츠를 추출하는 방법을 사용하였습니다. 이를 통해 6000개의 이미지 중 200개 미만으로 필터링할 수 있었습니다.

- **Performance Highlights**: GLM4 트랙에서 1차 예선에서 1위, 준결승에서 2위를 차지한 성과를 보여주며, 모든 구성 요소에 쉽게 통합될 수 있는 효율적인 추론 가속화 방안을 설계하여 RAG의 추론 대기 시간을 크게 줄였습니다.



### Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspectiv (https://arxiv.org/abs/2410.10291)
Comments:
          Our benchmark and code are available at this https URL

- **What's New**: 인간의 지시를 정확히 해석하고 시각화하는 것은 텍스트-이미지(T2I) 합성에 매우 중요합니다. 그러나 현재 모델들은 단어 순서 변화에 따른 의미적 변화를 제대로 포착하지 못하고 있습니다. 이를 해결하기 위해, 우리는 SemVarEffect라는 새로운 메트릭과 SemVarBench라는 벤치마크를 제안합니다.

- **Technical Details**: SemVarEffect는 T2I 모델의 입력과 출력 간 의미적 변화의 인과관계를 평가하기 위해 설계되었습니다. 이는 언어적 변형을 통해 달성된 의미적 변화를 사용하여 모델의 출력에서 나타나는 변화량을 평가합니다. SemVarBench는 11,454개의 샘플로 구성된 고품질 벤치마크로, 10,806개 샘플이 훈련 세트, 648개가 시험 세트에 포함되어 있습니다.

- **Performance Highlights**: CogView-3-Plus와 Ideogram 2 모델이 최고 점수인 0.2/1을 기록했으나, 객체 관계의 의미적 변화에 대한 이해는 부족하여 0.07/1의 낮은 점수를 보였습니다. 우리는 T2I 모델들이 유의미한 의미적 변화를 처리하는 데에서 상당한 한계가 있으며, 추가적인 개선이 필요함을 발견했습니다.



### Trust or Bust: Ensuring Trustworthiness in Autonomous Weapon Systems (https://arxiv.org/abs/2410.10284)
Comments:
          Accepted as a workshop paper at MILCOM 2024, 8 pages

- **What's New**: 이 연구는 자율무기 시스템(Autonomous Weapon Systems, AWS)의 신뢰성에 대한 다각적 접근을 다루고 있으며, 특히 군사 운영에서의 신뢰 구축의 필요성을 강조합니다. 기존 연구 문헌의 체계적인 리뷰를 통해 현재 AWS의 신뢰 역학에 대한 이해의 격차를 찾아내고, 기술자, 윤리학자 및 군 전략가 간의 협력적 접근 방안을 제안합니다.

- **Technical Details**: 신뢰할 수 있는 AI 시스템을 구축하는 것은 군 수사 및 다양한 산업에 성공적으로 통합하기 위한 기본 요소입니다. AWS는 인간의 개입 없이 독립적으로 결정을 내리며 작동하는 능력으로 정의되며, 이는 복잡한 군사 환경에서 빠른 의사 결정을 촉진합니다. 특히, AWS에서는 자율성과 인간의 통제 간 균형이 중요합니다.

- **Performance Highlights**: AWS는 혁신을 촉진하고 방어 능력을 향상시킬 수 있는 잠재력을 가지고 있으며, 높은 정밀도와 속도로 위험한 환경에서 작동할 수 있습니다. 그러나 기술적 장벽, 사이버 보안 위험 및 도덕적 책임과 같은 과제를 동반하고 있으며, 이러한 도전 과제를 해결하기 위한 효과적인 거버넌스와 규제 프레임워크가 필요합니다.



### LoLCATs: On Low-Rank Linearizing of Large Language Models (https://arxiv.org/abs/2410.10254)
Comments:
          47 pages, 20 figures, 18 tables, preprint

- **What's New**: 최근의 발견에 따르면, 저자는 LLM(대형 언어 모델)의 비용 효율적인 선형화를 위한 LoLCATs(저랭크 선형 변환 주의 전이)를 제안합니다. 이 방법은 훈련 과정에서 적은 메모리와 연산 자원 사용으로 LLM의 품질과 효율성을 극대화하는 데 중점을 두고 있습니다.

- **Technical Details**: LoLCATs 방법은 두 단계로 구성됩니다. 첫 번째로, LLM의 softmax 주의를 선형 주의로 대체하는 훈련이 '주의 전이(attention transfer)'를 통해 이루어집니다. 두 번째로, 저랭크 적응(Low-Rank Adaptation, LoRA)을 통해 근사 오차를 조정합니다. 이 방식은 모델의 파라미터와 토큰 효율성을 높이고, 메모리 사용량을 체계적으로 줄이는 데 기여합니다.

- **Performance Highlights**: LoLCATs는 Mistral 7B와 Llama 3 8B 같은 모델에서 이전 선형화 방법 대비 5-shot MMLU에서 20점 이상의 성능 향상 결과를 나타냈습니다. 또한, 모델 파라미터의 0.2%와 훈련 토큰의 0.4%만으로도 효과적인 훈련을 진행할 수 있었습니다. 더불어, 최초로 70B 및 405B LLM을 선형화하는 데 성공하여, 같은 계산 예산 하에서 LLM의 선형화 품질을 크게 개선했습니다.



### Feedback Favors the Generalization of Neural ODEs (https://arxiv.org/abs/2410.10253)
Comments:
          22 pages, 17 figures

- **What's New**: 이 논문은 피드백 메커니즘을 접목시킨 새로운 피드백 신경망(feedback neural networks)을 제안하며, 이를 통해 신경 일반적인 미분 방정식(neural ordinary differential equations, neural ODEs)의 학습된 잠재 동적 모델을 수정하여 일반화 성능을 크게 향상시킵니다.

- **Technical Details**: 기존의 신경망의 일반화 문제를 해결하기 위한 방법으로, 선형형(Line feedback form) 및 비선형 신경형(Nonlinear neural form)의 두 가지 피드백 방법을 도입합니다. 이 피드백 네트워크는 두 자유도(two-DOF) 구조를 가지며, 이전 작업의 정확성을 유지하면서도 이전에 보지 못한 작업에 대한 일반화 성능을 발휘합니다.

- **Performance Highlights**: 본 연구의 실험에서는 실제 불규칙 물체의 궤적 예측과 다양한 불확실성을 고려한 쿼드로터(quadcopter) 모델 예측 제어(model predictive control)를 통해 기존의 모델 기반 및 학습 기반 방법들보다 상당한 개선 효과를 보였습니다.



### LOBG:Less Overfitting for Better Generalization in Vision-Language Mod (https://arxiv.org/abs/2410.10247)
- **What's New**: 기존의 Vision-Language Models(VLM)에서 사용되는 프롬프트 학습 기법들이 과적합(overfitting)으로 인해 일반화 능력에서 큰 저하를 겪고 있어, 이에 대한 해결책으로 LOBG 프레임워크를 제안합니다.

- **Technical Details**: LOBG 프레임워크는 CLIP을 사용하여 과적합을 유발할 수 있는 세밀한 전경 정보(fine-grained foreground information)를 필터링하고, 구조적 토폴로지 보존(STP) 손실 기능을 통해 최적화 과정에서 특성 공간(feature space)의 탄력성을 높입니다. 또한, 출력 수준에서 위계적 로짓 증류(hierarchical logit distillation)를 적용해 출력을 제어하며 STP를 보완합니다.

- **Performance Highlights**: 실험 결과, LOBG는 기존의 최첨단 기법들에 비해 일반화 능력을 크게 향상시켰으며, 새로운 클래스에 대해 2.82%의 성능 향상을 달성했습니다. 11개의 벤치마크 데이터셋에 대한 실험에서 기존의 CLIP과 비교하여 현저히 낮은 과적합을 보여줍니다.



### Revisiting and Benchmarking Graph Autoencoders: A Contrastive Learning Perspectiv (https://arxiv.org/abs/2410.10241)
Comments:
          Preprint, under review

- **What's New**: 이번 연구에서는 그래프 오토인코더(GAE)와 대조 학습(Contrastive Learning) 간의 연결 고리를 제공하며, 새로운 lrGAE 프레임워크를 제안합니다. 이 프레임워크는 대조 학습의 원칙을 활용하여 의미 있는 표현을 학습할 수 있도록 합니다.

- **Technical Details**: lrGAE는 다섯 개의 주요 구성 요소(증강(Augmentation), 대조 뷰(Contrastive Views), 인코더/디코더 네트워크(Encoder/Decoder Networks), 대조 손실(Contrastive Loss), 음성 샘플(Negative Samples))로 구성됩니다. 이 연구에서는 다양한 그래프 기반 학습 작업에서 lrGAE의 성능을 효과적으로 평가합니다.

- **Performance Highlights**: lrGAE는 기존 GAE들보다 더 깊이 있는 이해를 제공하고 다양한 그래프 기반 학습 작업에 대한 새로운 벤치마크를 설정합니다. 실험 결과는 대조 뷰의 효과성에 대한 통찰을 제공합니다.



### ForgeryGPT: Multimodal Large Language Model For Explainable Image Forgery Detection and Localization (https://arxiv.org/abs/2410.10238)
Comments:
          16 pages, 14 figures

- **What's New**: 이번 논문에서는 ForgeryGPT라는 새로운 프레임워크를 제시하여 이미지 위조 감지 및 위치 지정(Image Forgery Detection and Localization, IFDL) 작업의 발전을 도모합니다. 기존 IFDL 방법의 한계를 극복하고, 다양한 언어적 특징 공간에서 고차원 포렌식 지식 상관관계를 포착하며, 설명 가능한 생성 및 상호작용 가능한 대화를 허용합니다.

- **Technical Details**: ForgeryGPT는 다음과 같은 세 가지 주요 구성 요소로 이루어져 있습니다: 이미지 인코더, 맞춤형 Mask-Aware Forgery Extractor 및 대형 언어 모델. Mask-Aware Forgery Extractor는 Forgery Localization Expert(FL-Expert)와 Mask Encoder로 구성되어 있으며, 세밀한 위조 정보를 픽셀 단위로 이해하는 데 중점을 둡니다. 이를 통해 모델은 단순한 위조 확률 점수와 경계값에 의존하지 않고 자동으로 위조를 탐지합니다.

- **Performance Highlights**: ForgedGPT는 성능 실험에서 GPT-4o 및 현재의 최첨단 IFDL 방법을 초월하는 성과를 보였으며, 높은 정확도 외에도, 정량적 분석을 통해 신뢰할 수 있는 설명을 제공함으로써 해석 가능성과 신뢰성을 강화했습니다.



### BanglaQuAD: A Bengali Open-domain Question Answering Datas (https://arxiv.org/abs/2410.10229)
Comments:
          Accepted into LREC-COLING 2024, Turin, Italy

- **What's New**: 본 연구는 신규 벵골어 질의응답 데이터 세트 BanglaQuAD를 소개합니다. 이 데이터 세트는 벵골어 위키피디아 기사를 바탕으로 30,808개의 질문-답변 쌍으로 구성되어 있으며, 네이티브 스피커에 의해 주석이 달린 고품질 데이터를 제공합니다.

- **Technical Details**: BanglaQuAD는 12,000개 이상의 벵골어 위키피디아 기사에서 선택된 658개의 기사를 바탕으로 하며, 다양한 질문 유형과 변동하는 답변 길이를 포함합니다. 이를 위해 BnAnno라는 주석 도구가 개발되어 비구조적 텍스트를 SQuAD 형식으로 변환할 수 있도록 지원합니다.

- **Performance Highlights**: BanglaQuAD 데이터 세트는 87,482의 어휘를 포함하고 있으며, 평균 47개의 질문이 각 기사에서 생성됩니다. 실험 결과, BanglaBERT 및 IndicBERT와 같은 벵골어에 특화된 모델이 높은 성능을 보였습니다.



### QE-EBM: Using Quality Estimators as Energy Loss for Machine Translation (https://arxiv.org/abs/2410.10228)
- **What's New**: 이번 연구에서는 품질 추정기(quality estimator, QE)를 이용하여 학습 가능한 손실 네트워크를 구축하고, NMT(Neural Machine Translation) 모델로 직접 역전파 할 수 있는 QE-EBM 방식을 제안합니다. 이 방법은 기존의 강화학습(reinforcement learning) 접근 방식보다 더 효과적으로 번역 품질을 개선할 수 있습니다.

- **Technical Details**: QE-EBM은 품질 점수를 에너지 손실로 활용하고, QE 모델의 지식을 NMT 모델에 전달하기 위해 에너지 기반 훈련을 사용합니다. 이 연구에서는 QE-STATIC과 QE-DYNAMIC 두 가지 변형을 사용하며, 후자는 대비 학습(contrastive learning)을 통해 에너지 네트워크의 매개변수를 업데이트합니다. 실험은 영어를 출발어로 하여 자원 언어(target language)의 다양성을 테스트합니다.

- **Performance Highlights**: QE-EBM은 REINFORCE 및 proximal policy optimization (PPO), 감독된 세부 조정(supervised fine-tuning) 방법보다 우수한 성능을 발휘하며, 특히 자원 부족 언어에 대한 번역 품질이 향상되었습니다. 또한, 영어-몽골어 번역의 경우, BLEU(2.5), COMET-KIWI(7.1), COMET(5.3), 그리고 XCOMET(6.4)에서 향상을 보였습니다.



### Predicting from Strings: Language Model Embeddings for Bayesian Optimization (https://arxiv.org/abs/2410.10190)
- **What's New**: 이번 연구에서는 Bayesian Optimization을 위한 새로운 프레임워크인 "Embed-then-Regress"를 제안하고 있습니다. 이는 pretrained language models의 string embedding 기능을 활용하여, 다양한 데이터 도메인에 대해 일반적인 회귀(Regression) 기술을 적용할 수 있게 합니다.

- **Technical Details**: 기존의 회귀 모델은 주로 고정된 탐색 공간과 입력 특성에 국한되어 있었으나, 새로운 방법론인 Embed-then-Regress는 arbitrary string을 feature로 사용하게 합니다. 이를 통해 Transformer 기반의 regressor 모델을 구축하고, 오프라인 평가 데이터를 통해 불확실성을 기반으로 한 예측을 수행하며, explore-exploit 기법을 통해 최적화 성과를 달성합니다.

- **Performance Highlights**: 제안된 방법을 이용하면 synthetic, combinatorial, hyperparameter optimization 등 다양한 최적화 작업에서 기존의 Gaussian Process 기반 알고리즘과 비교해 경쟁력 있는 결과를 얻을 수 있습니다.



### Eliminating the Language Bias for Visual Question Answering with fine-grained Causal Intervention (https://arxiv.org/abs/2410.10184)
- **What's New**: 이번 논문에서는 Visual Question Answering(VQA)에서 텍스트 정보로 인해 발생하는 언어 편향을 줄이기 위한 새로운 causal intervention training 스킴인 CIBi를 제안합니다.

- **Technical Details**: CIBi에서는 언어 편향을 context bias와 keyword bias로 나누고, counterfactual 생성과 contrastive learning을 활용하여 context bias를 제거하고 multi-modal representation을 개선합니다. 특히, 각 VQA 훈련 샘플에 대해 두 개의 대응하는 counterfactual 샘플을 생성하여 학습합니다.

- **Performance Highlights**: 실험 결과, CIBi는 다양한 VQA 모델에 적용 가능하며 경쟁력 있는 성능 향상을 보여주었습니다.



### Scalable Multi-Domain Adaptation of Language Models using Modular Experts (https://arxiv.org/abs/2410.10181)
Comments:
          14 pages, 5 figures, 3 tables

- **What's New**: 이번 연구에서는 MoDE(Modular Domain Experts)라는 새로운 아키텍처를 제안합니다. MoDE는 일반적인 Pre-trained Language Models(PLMs)에 모듈형, 도메인 전문 전문가(experts)를 추가하여 다중 도메인 적응 문제를 해결합니다.

- **Technical Details**: MoDE는 Mixture of Experts(MoE) 접근 방식을 기반으로 하며, 각 전문가가 여러 개의 transformer 레이어로 구성되어 있습니다. 각 전문가는 독립적으로 훈련되며, 가벼운 훈련 단계를 통해 협업하여 성능을 강화합니다. MoDE의 아키텍처는 유연한 sharding 구성으로 훈련 속도를 최대 38% 향상시킵니다.

- **Performance Highlights**: MoDE는 기존의 전체 매개변수 미세 조정(full parameter fine-tuning) 방법과 유사한 성능을 달성하면서 1.65% 더 좋은 정보 유지 성능을 보여주었습니다. 또한 MoDE는 여러 도메인에서 우수한 성능을 발휘하여 LoRA보다 1.4%, 전체 매개변수 미세 조정보다 0.6% 향상된 결과를 보였습니다.



### Automated Filtering of Human Feedback Data for Aligning Text-to-Image Diffusion Models (https://arxiv.org/abs/2410.10166)
- **What's New**: 제안된 FiFA(Fine-tuning with Feedback Alignment)는 인간 피드백 데이터셋을 자동으로 필터링하여 텍스트에서 이미지로의 확산 모델을 효율적으로 정렬하는 새로운 알고리즘입니다.

- **Technical Details**: FiFA는 세 가지 요소인 preference margin, text quality, text diversity를 최대화하는 최적화 문제를 해결하여 데이터 샘플을 선택합니다. preference margin은 표본의 정보적 가치를 고려하여 노이즈를 줄이는 데 활용됩니다. 또, text quality는 대형 언어 모델을 통해 평가되며, text diversity는 k-nearest neighbor 엔트로피 추정기를 통해 측정됩니다.

- **Performance Highlights**: FiFA는 전체 데이터의 0.5%만을 사용했음에도 불구하고 훈련 안정성을 극대화하고 성능을 17% 향상시키며, GPU 시간을 1% 이하로 줄였습니다. 또한, 중립적인 프롬프트에 대한 해로운 내용은 50% 이상 감소시키는 데 성공했습니다.



### HSR-Enhanced Sparse Attention Acceleration (https://arxiv.org/abs/2410.10165)
- **What's New**: 본 논문에서는 대형 언어 모델(LLM)의 긴 컨텍스트 작업에서 주의 메커니즘상의 계산 복잡성을 줄이기 위한 새로운 접근 방식이 소개됩니다. 특히, 주의 메커니즘 내에서의 내재된 희소성(sparsity)을 활용하여 주의 생성을 가속화합니다.

- **Technical Details**: 본 연구에서는 Half-Space Reporting (HSR) 데이터 구조를 사용하여 주의 행렬에서 비제로(non-zero) 또는 "대량 활성화(massively activated)" 항목을 신속하게 식별합니다. 이 방법을 통해 긴 입력 컨텍스트에서의 주의 생성을 위해 $O(mn^{4/5})$의 실행 시간을 달성하며, 이는 기존의 $O(mn)$ 방식보다 빠릅니다. 또한, 전체 주의 계산의 실행 시간도 $O(mn)$에서 $O(mn^{1 - 1 / lfloor d/2floor} + mn^{4/5})$로 감소시킵니다.

- **Performance Highlights**: ReLU 주의(almost zero error)를 위한 오류를 도입하지 않으며, Softmax 주의의 경우에도 상당히 미미한 오류를 보이는 결과를 empirically validation로 입증하였습니다. 이 연구는 LLM에서 효율적인 긴 컨텍스트 처리 가능성을 높이며 다양한 분야에서의 적용성을 넓힐 수 있는 중요한 전환점을 나타냅니다.



### Jailbreak Instruction-Tuned LLMs via end-of-sentence MLP Re-weighting (https://arxiv.org/abs/2410.10150)
- **What's New**: 본 논문은 instruction fine-tuning된 large language models (LLMs)의 안전 메커니즘을 조사하고, MLP(다층 퍼셉트론) 뉴런의 재가중화가 모델의 안전성을 크게 저해할 수 있음을 발견하였습니다. 또한, 새로운 화이트박스 jailbreak 방법 2개를 제안합니다: 프롬프트-특정 방법과 프롬프트-일반 방법.

- **Technical Details**: 연구에서는 LLM의 안전성과 MLP 레이어 간의 관계에 주목했습니다. LLM이 종료 문장 추론 중에 유해성 평가를 할 때 MLP 레이어가 중요한 역할을 한다고 가정하였고, MLP 레이어의 뉴런 활성화를 재가중화하여 모델 안전성을 크게 저해할 수 있음을 실험적으로 입증하였습니다. 또한, 모델의 각 프롬프트에 맞게 최적화된 공격 방법과 미리 훈련된 일반화를 통해 모든 새로운 유해 프롬프트를 처리할 수 있는 방법을 개발하였습니다.

- **Performance Highlights**: 제안된 프롬프트-특정 방법은 기존의 최첨단 방법보다 더 나은 성능을 보였으며, 필요한 계산 시간도 적었습니다. 프롬프트-일반 방법은 기존 비슷한 접근법과 비교 가능하였으며, 모델의 기존 능력에 미치는 영향이 적었습니다. 이러한 결과들은 종료 문장 추론에서 MLP 레이어의 수정을 통해 모델의 안전성을 저해할 수 있음을 나타냅니다.



### $\alpha$-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs (https://arxiv.org/abs/2410.10148)
- **What's New**: 본 연구는 대규모 언어 모델(LLM)을 인류의 가치와 의도에 맞게 조정하기 위한 새로운 알고리즘인 \u03b1-DPO를 제안합니다. 기존의 강화 학습 알고리즘인 DPO와 SimPO의 한계를 극복하며, 동적인 보상 마진을 도입하여 보다 효과적인 최적화를 이룹니다.

- **Technical Details**: \u03b1-DPO는 적응형 보상 분포를 사용하여 정책 모델과 기준 모델 간의 균형을 맞추며 개인화된 보상 마진을 달성하는 알고리즘입니다. 이 연구는 KL 발산(KL divergence) 제어를 통해 정렬(alignment)과 다양성(diversity)을 균형 있게 유지하는 이론적 보장을 제공합니다.

- **Performance Highlights**: Empirical evaluations 결과, \u03b1-DPO는 다양한 모델 설정에서 DPO와 SimPO를 지속적으로 초월하며 win rate를 크게 향상시키는 것으로 나타났습니다. 이는 LLM 정렬을 위한 강력한 도구로서의 가능성을 보여줍니다.



### Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning (https://arxiv.org/abs/2410.10144)
Comments:
          15 pages, 2 figures, 5 tables

- **What's New**: 이번 논문에서 제안하는 GENEREL은 유전체와 생물 의학 지식 기반을 연결하는 새로운 프레임워크로, 임상 개념인 질병 및 약물에 대한 생물학적 지식을 언어 모델에 주입하여 효과적으로 연결합니다.

- **Technical Details**: GENEREL은 다중 작업 대조 학습(multi-task contrastive learning)을 통해 SNP와 임상 개념의 임베딩을 조정하며, 병원 데이터, 생물 의학 지식 그래프, GWAS 요약 정보를 활용하여 통합 임베딩 공간을 구축합니다.

- **Performance Highlights**: GENEREL은 생물 의학 개념과 SNP 간의 미세한 관계를 효과적으로 포착하고, 다양한 벤치마크에서 최첨단 성능을 입증하여 유전체 및 생물 의학 데이터의 통합 가능성을 높입니다.



### Beyond-RAG: Question Identification and Answer Generation in Real-Time Conversations (https://arxiv.org/abs/2410.10136)
- **What's New**: 이번 논문에서는 고객 서비스 센터에서 평균 처리 시간(AHT)을 감소시키기 위한 새로운 의사결정 지원 시스템을 제안합니다. 이 시스템은 고객의 질문을 실시간으로 식별하고, 자주 묻는 질문(FAQ)과의 매칭을 통해 직접적으로 답변을 제공합니다. 또한 사전 설정된 FAQ가 없을 경우 역사적 대화 기록에서 FAQ를 자동으로 추출하는 LLM-기반 워크플로우를 도입했습니다.

- **Technical Details**: 본 시스템은 고객과 상담원 간의 상호작용을 통해 실시간으로 질문을 식별하고, 가장 관련성이 높은 질문을 제안합니다. 상담원이 질문을 선택하면, 해당 질문이 FAQ와 매칭될 경우 FAQ 데이터베이스에서 답변을 가져오고, 비FAQ 질문의 경우 RAG(검색 보강 생성) 모델을 이용해 답변을 생성합니다. Match 및 Generate라는 두 개의 스레드를 동시에 실행하여 관련 질문을 제안하며, 이를 통해 시간 소모를 줄이고 AHT를 감소시킵니다.

- **Performance Highlights**: Minerva CQ에 배포된 이 시스템은 운영 효율을 크게 향상시키고, AHT를 감소시키며, 운영 비용을 줄이는 성과를 보였습니다. 특히, 실시간으로 고객 질문을 식별하고 빠르고 정확한 답변을 제공하여 상담원의 생산성을 높이는 데 기여하고 있습니다.



### FormalAlign: Automated Alignment Evaluation for Autoformalization (https://arxiv.org/abs/2410.10135)
Comments:
          23 pages, 13 tables, 3 figures

- **What's New**: 이번 연구에서는 자연어(自然語)와 형식적 언어(形式的言語) 간의 정렬(Alignment)을 자동으로 평가하는 최초의 프레임워크인 FormalAlign을 소개합니다. 이 프레임워크는 기존의 Autoformalization(자동 형식화) 기법의 다수의 한계를 극복하고, 수동 검증(手動 錄證)의 필요성을 감소시킵니다.

- **Technical Details**: FormalAlign은 autoformalization 시퀀스 생성 작업과 입력(output)과 출력 간의 표현 정렬(Representational Alignment)을 학습합니다. 이 연구는 두 개의 상호 보완적(autoformalization과 alignment) 작업을 통합한 이중 손실(Dual Loss) 구조를 사용하여 모델의 성능을 극대화합니다.

- **Performance Highlights**: FormalAlign은 MiniF2F와 FormL4 벤치마크에서 GPT-4보다 훨씬 높은 성능을 보였습니다. 예를 들어, FormL4-Basic 데이터셋에서 Alignment-Selection Score가 99.21%로 GPT-4의 88.91%보다 11.58% 높은 결과를 기록했으며, MiniF2F-Valid에서 66.39%로 GPT-4의 64.34%보다 3.19% 향상되었습니다.



### Learning Linear Attention in Polynomial Tim (https://arxiv.org/abs/2410.10101)
- **What's New**: 본 연구는 단일 계층 Transformer 모델을 대상으로 한 강력한 무관심 PAC 학습(strong, agnostic PAC learning)의 다항 시간 학습 가능성을 최초로 보였다는 점에서 혁신적입니다.

- **Technical Details**: 단일 계층의 선형 Transformer(Linear Transformer)에서 linear attention을 사용하여 특정한 RKHS(Reproducing Kernel Hilbert Space) 내에서 선형 예측기로 취급할 수 있다는 개념을 제시합니다. 이를 통해 선형 Transformer를 학습하는 문제를 일반적인 선형 예측기를 확장된 특성 공간에서 학습하는 문제로 변환합니다.

- **Performance Highlights**: 세 가지 과제(랜덤 선형 attention 네트워크, 키-값 연관, 유한 오토마타 실행 학습)에 대한 경험적 검증을 통해 이론적 발견을 입증하였으며, 효율적으로 학습 가능한 유연하고 일반적인 계산 모델로서 Transformer의 능력을 강조합니다.



### REHRSeg: Unleashing the Power of Self-Supervised Super-Resolution for Resource-Efficient 3D MRI Segmentation (https://arxiv.org/abs/2410.10097)
- **What's New**: 본 논문에서는 자원 효율적인 고해상도 세분화 프레임워크(REHRSeg)를 제안하여 저해상도(LR) 이미지를 입력으로 사용하면서도 고해상도(HR) 세분화를 달성하는 방법을 제시합니다. 이 접근 방식은 실제 임상 분야에서의 데이터 부족 문제를 해결하기 위한 새로운 접근을 제공합니다.

- **Technical Details**: REHRSeg는 셀프-슈퍼레졸루션(self-SR)을 활용하여 가짜 감독(pseudo supervision)을 제공하며, 따라서 2D 스캐닝 프로토콜로 생성된 상대적으로 쉽게 수집할 수 있는 LR 주석 이미지를 모델 훈련에 직접 사용할 수 있습니다. 본 연구의 핵심 기여 사항은 (1) 데이터를 희소하게 만드는 문제를 완화하고 (2) 불확실성 인식(super-resolution head)을 통해 ROI 경계에서의 불확실성을 인식하며, (3) 구조적 지식 증류(knowledge distillation)를 통해 세분화 및 자가 SR의 공간적 특징을 정렬하고 연결성을 강화하는 것입니다.

- **Performance Highlights**: 실험 결과, REHRSeg는 강력한 감독 없이도 고품질의 HR 세분화를 달성하며, LR 세분화 성능을 상당히 향상시키는 것으로 나타났습니다.



### PromptGCN: Bridging Subgraph Gaps in Lightweight GCNs (https://arxiv.org/abs/2410.10089)
- **What's New**: 이 논문에서는 PromptGCN이라는 새로운 경량화된 GCN 모델을 제안하여 서브그래프 간의 간극을 메우는 방법을 소개합니다. 이를 통해 Graph Convolutional Networks의 성능을 개선할 수 있습니다.

- **Technical Details**: PromptGCN은 학습 가능한 프롬프트 임베딩(prompt embeddings)을 설계하여 전역 정보를 획득하고, 이를 각 서브그래프에 결합하여 서브그래프 간 글로벌 정보를 전송하는 방법이 특징입니다. 이 방식은 GCN의 정확도를 증가시키면서도 메모리 소비를 줄이는 데 기여합니다.

- **Performance Highlights**: 일곱 개의 대규모 그래프에 대한 실험 결과, PromptGCN은 기존의 방법들과 비교하여 뛰어난 성능을 보였으며, 특히 Flickr 데이터셋에서 서브그래프 샘플링 방법의 정확도를 최대 5.48% 개선했습니다.



### The Ingredients for Robotic Diffusion Transformers (https://arxiv.org/abs/2410.10088)
- **What's New**: 이번 논문은 고용량(diffusion) Transformer 정책을 위한 중요 설계 결정을 개선하여 다양한 로봇 작업을 효율적으로 해결할 수 있는 새로운 모델인 DiT-Block Policy를 소개합니다.

- **Technical Details**: 이 연구에서는 adaptive Layer Norm (adaLN) 블록과 ResNet 이미지 토크나이저를 활용해 정책 훈련의 안정성을 높이고 멀티모달(multi-modal) 스펙에 적합하게 조정합니다. 이러한 구성 요소의 통합을 통해 SOTA 성능을 달성한 것을 강조합니다.

- **Performance Highlights**: 모델은 ALOHA 로봇에서 1500타임스텝 이상의 장기 작업을 성공적으로 수행하며, 10시간 이상의 다양하고 언어 주석이 포함된 데이터로 훈련되었을 때 성능이 크게 향상되었습니다.



### Divide, Reweight, and Conquer: A Logit Arithmetic Approach for In-Context Learning (https://arxiv.org/abs/2410.10074)
- **What's New**: 본 논문에서는 Logit Arithmetic Reweighting Approach (LARA)라는 새로운 프레임워크를 제안합니다. 이는 In-Context Learning (ICL) 성능을 향상시키기 위해 여러 시연의 logit 기반 앙상블을 활용합니다. 또한, Binary LARA (B-LARA)를 도입하여 이진 값으로 가중치를 제한함으로써 메모리 사용량을 줄입니다.

- **Technical Details**: LARA는 긴 입력 시연을 병렬화 가능한 짧은 입력으로 나누어 메모리 요구 사항을 대폭 줄이고, 각 그룹의 logit을 비부드러운 최적화(non-gradient optimization) 방식을 통해 재가중화하여 정보를 효과적으로 집계합니다. B-LARA는 가중치 값을 {0,1}로 제한하여 검색 공간을 단순화합니다. Covariance Matrix Adaptive Evolution Strategy (CMA-ES)를 이용해 가중치 벡터 공간을 효율적으로 탐색합니다.

- **Performance Highlights**: LARA와 B-LARA는 BBH와 MMLU 벤치마크에서 모든 기준 방법을 초과하는 성능을 보여주었으며, 특히 예제가 적은 저자원 환경과 대량의 시연이 존재하는 상황에서도 우수한 성능을 기록했습니다. 이 방법들은 GPU 메모리 사용량이 낮으면서도 높은 정확도를 자랑합니다.



### Ukrainian-to-English folktale corpus: Parallel corpus creation and augmentation for machine translation in low-resource languages (https://arxiv.org/abs/2410.10063)
- **What's New**: 이 논문은 우크라이나 민속 이야기의 우크라이나어에서 영어로의 번역을 위한 새로운 평행 코퍼스(parallel corpus)를 소개합니다. 기존에 인간 번역가들이 수행하던 작업에 기반하여 새로운 번역을 제안합니다.

- **Technical Details**: 코퍼스는 단어(word) 및 문장(sentence) 기준으로 정렬되어 있어 의미 있는 정보의 최적 큐레이션(curation)을 제공합니다. 이는 머신 번역(machine translation) 모델 훈련 데이터로 사용되도록 특별히 설계되었습니다.

- **Performance Highlights**: 우크라이나 문화 전통과 관습에 대한 접근성을 높이고, 기계 번역의 질을 향상시킬 수 있는 가능성을 제공합니다.



### Dreaming to Assist: Learning to Align with Human Objectives for Shared Control in High-Speed Racing (https://arxiv.org/abs/2410.10062)
Comments:
          Accepted to CoRL 2024, Munich, Germany

- **What's New**: 새로운 연구에서는 고속 동역학 및 전략적 결정이 필요한 다중 자동차 경주와 같은 분야에서 로봇 팀원이 인간 팀원의 전략적 목표에 반응하는 방식을 설명하는 Dream2Assist라는 프레임워크를 제시합니다.

- **Technical Details**: Dream2Assist는 인간 목표 및 가치 함수(value function)를 추론할 수 있는 풍부한 세계 모델과, 주어진 인간 팀원에게 적절한 전문가 지원을 제공하는 보조 에이전트를 결합하고 있습니다. 이 접근 방식은 순환 상태 공간 모델(recurrent state space model)을 기반으로 하여 인간의 의도를 명시적으로 추론합니다.

- **Performance Highlights**: Dream2Assist를 이용한 인간-로봇 팀이 혼합 작업을 수행할 때, 기존의 합성 인간 드라이버 및 여러 베이스라인 지원 전략보다 더 나은 성과를 보여 주었습니다. 또한, 의도 조건화(intent-conditioning)를 통해 작업 수행 동안 인간의 선호에 부합하여 성과를 개선할 수 있었습니다.



### The Epochal Sawtooth Effect: Unveiling Training Loss Oscillations in Adam and Other Optimizers (https://arxiv.org/abs/2410.10056)
Comments:
          15 pages, 21 figures

- **What's New**: 이 논문에서는 훈련 중 일반적으로 관찰되는 반복적인 훈련 손실 패턴인 Epochal Sawtooth Effect (ESE)를 식별하고 분석합니다. 주로 Adam 옵티마이저를 사용할 때 나타나는 이 패턴은 각 에폭의 시작에서 손실이 급격히 감소한 후 점진적인 증가를 보이며, 톱니 모양의 손실 곡선을 형성합니다.

- **Technical Details**: 본 연구에서는 Adam의 매개변수 설정(특히 β1과 β2)이 ESE의 발생에 미치는 영향을 구체적으로 분석합니다. ESE는 데이터 셔플, 배치 크기, 모델의 용량 등 여러 요인에 의해 영향을 받으며, β2의 크기가 손실 곡선의 모양에 중요한 역할을 한다는 점을 강조합니다. β2의 값이 클 경우 손실이 거의 선형적으로 증가하며, 낮은 경우 오목한 경향을 보입니다.

- **Performance Highlights**: 제어된 2차 최소화 문제를 통해 ESE 현상을 재현함으로써 다양한 최적화 문제에서도 이 패턴의 일반성을 입증합니다. 이 연구는 현상에 대한 이론적 통찰과 정량적 분석을 제공하며, 현대 최적화 기술에서 이 보편적인 현상에 대한 포괄적인 이해를 제공합니다.



### XAI-based Feature Selection for Improved Network Intrusion Detection Systems (https://arxiv.org/abs/2410.10050)
Comments:
          24 pages, 4 figures

- **What's New**: 이 연구는 네트워크 보안 분야에서 AI 모델의 설명 가능성(Explainability)과 평가를 위한 새로운 기법을 제안합니다. IDS(침입 탐지 시스템)의 특성 선택(feature selection) 문제를 해결하기 위해 새로운 XAI(eXplainable AI) 기법을 적용합니다.

- **Technical Details**: 연구에서 제안하는 접근법은 여러 AI 기법을 사용하여 도출한 주요 속성과 함께 다섯 가지 새로운 특성 선택 방법을 활용하여 IDS의 공격 탐지를 개선합니다. 연구에서는 RoEduNet-SIMARGL2021 및 CICIDS-2017 두 가지의 네트워크 침입 데이터 세트에 대한 분석을 수행합니다.

- **Performance Highlights**: 연구 결과, XAI 기반의 특성 선택 방법을 사용하는 대부분의 AI 모델이 기존 방법보다 뛰어난 성능을 발휘하는 것으로 나타났습니다. 이를 통해 보안 분석가가 IDS의 결정 과정을 보다 잘 이해할 수 있도록 지원합니다.



### VQ-CNMP: Neuro-Symbolic Skill Learning for Bi-Level Planning (https://arxiv.org/abs/2410.10045)
Comments:
          12 pages, 6 figures, Submitted to Conference on Robot Learning LEAP Workshop 2024

- **What's New**: 이 논문은 라벨이 없는 시연 데이터에서 고수준 기술 표현을 발견할 수 있는 새로운 신경망 모델을 제안합니다. 또한 이 모델을 활용하는 바이레벨 플래닝 파이프라인을 제안하여, 경량 기반 플래닝 접근 방식을 사용합니다. 우리의 모델은 고수준 표현을 추출하면서도 낮은 수준의 정보를 보존하여, 저수준 행동 계획에 활용할 수 있습니다.

- **Technical Details**: 제안된 모델은 벡터 양자화(Vector Quantization) 접근을 사용하여 고수준 기술의 다양한 변형에서 단일 이산 벡터를 학습합니다. 예를 들어, 샌드위치를 냉장고에서 꺼내는 것은 고수준 기술이며, 샌드위치를 어디에서 꺼내느냐는 저수준 구성 요소에 해당합니다. 또한 이 모델은 라벨이 없는 데이터에서 직접 기술을 그룹화할 수 있습니다.

- **Performance Highlights**: 실험에서는 다양한 조건 하에서 기술 발견 성능을 테스트하였고, Multi-Modal LLMs가 학습된 고수준 기술 표현에 라벨을 붙일 수 있는지 여부를 확인하였습니다. 마지막으로, 제안된 파이프라인의 고수준 및 저수준 계획 성능을 테스트하였습니다.



### Are KAN Effective for Identifying and Tracking Concept Drift in Time Series? (https://arxiv.org/abs/2410.10041)
- **What's New**: 본 논문에서는 동적 개념(Concept drift)을 시간 시계열(time series) 분석에서 추적하기 위한 새로운 방법론을 제안합니다. 기존 모델의 한계를 극복하기 위해 Kolmogorov-Arnold Networks (KAN) 기반의 새로운 오토인코더인 WormKAN을 소개합니다.

- **Technical Details**: WormKAN은 KAN-SR 모듈을 통합하여 인코더와 디코더, 자기 표현(self-representation) 레이어를 포함합니다. 이 모델은 동적 개념 전환을 캡처하기 위해 시간 제약 조건을 도입하며, 잠재 공간(latent space) 내 급격한 변화를 통해 개념 전환을 식별합니다. KAN은 스플라인(spline) 매개변수를 활용한 단변량 함수(univariate functions)로 선형 가중치를 대체하여 복잡한 관계를 학습합니다.

- **Performance Highlights**: 실험 결과, WormKAN은 시간 시계열을 의미 있는 개념들로 효과적으로 세분화하고 개념 드리프트(concept drift)의 식별 및 추적을 향상시킬 수 있음을 보여주었습니다. KAN 및 KAN 기반 모델들은 동적으로 변화하는 개념을 포착하는 데 있어 뛰어난 성능을 발휘합니다.



### A Step Towards Mixture of Grader: Statistical Analysis of Existing Automatic Evaluation Metrics (https://arxiv.org/abs/2410.10030)
- **What's New**: 이 연구는 기존의 자동 Question-Answering (QA) 평가 지표의 한계를 통계적으로 분석하고, Mixture Of Grader (MOG)라는 새로운 접근 방식을 제안합니다. MOG는 질문과 정답 쌍을 분류한 후 각 QA 유형에 적합한 평가 지표를 선택하여 보다 정확한 자동 평가를 가능하게 합니다.

- **Technical Details**: 기존의 평가 지표는 질문 유형에 따라 높은 상관관계를 보이며, 단일 지표만으로 사람의 평가를 완전히 반영할 수 없음을 발견했습니다. 연구는 Exact Match (EM), F1 Score, BLEU, ROUGE-L 등 다양한 평가 지표를 사용하여 ChatGPT-o1-preview 모델의 인간 평가와의 상관관계를 측정하였습니다.

- **Performance Highlights**: Pedant 평가 지표는 인간 평가 점수와 0.77의 높은 상관관계를 보였으며, 이는 기존의 평가 지표보다 인간의 평가를 더 잘 반영하는 경향이 있음을 나타냅니다. 이 연구에서는 QA 유형에 따른 평가 지표 사용의 중요성을 강조하며, 각 유형에 대한 다르게 평가하는 방안이 필요함을 제안합니다.



### Online Multi-modal Root Cause Analysis (https://arxiv.org/abs/2410.10021)
- **What's New**: 이 논문은 온라인 다중 모달 원인 구조 학습 방법인 OCEAN을 제안합니다. OCEAN은 마이크로서비스 시스템에서 정확한 원인 분석을 수행할 수 있도록 다양한 데이터 소스로부터 정보를 통합합니다.

- **Technical Details**: OCEAN은 dilated convolutional neural network를 사용해 장기적인 시간 종속성을 캡처하고, graph neural networks를 통해 시스템 엔터티와 주요 성과 지표 간의 인과 관계를 학습합니다. 또한 다수의 특성을 고려하는 attention 메커니즘과 contrastive mutual information maximization 기반의 그래프 융합 모듈을 설계하여 온라인 환경에서 인과 그래프를 학습합니다.

- **Performance Highlights**: 세 개의 실제 데이터셋에서 실시된 광범위한 실험 결과, OCEAN은 기존의 방법들보다 원인 분석의 효과성과 효율성을 크게 향상시킴을 입증했습니다.



### Improving accuracy and convergence of federated learning edge computing methods for generalized DER forecasting applications in power grid (https://arxiv.org/abs/2410.10018)
Comments:
          Presented at the NeurIPS 2022 Tackling Climate Change with Machine Learning workshop

- **What's New**: 이 제안은 현대 저탄소 전력망에서 분산 에너지 자원(DER) 예측을 위한 더욱 정확한 Federated Learning (FL) 방법을 개발하는 것을 목표로 하고 있습니다. 특히, 속도와 통신 요구 사항을 낮추면서 수렴 속도를 높이는 방법에 중점을 두고 있습니다.

- **Technical Details**: 이 프로젝트는 비독립적이며 동일하게 분포되지 않은(non-IID) 데이터 성능 향상을 위해 계층적 클러스터링(hierarchical clustering) 및 반복 연합 클러스터링 알고리즘(Iterative Federated Clustering Algorithm)과 같은 FL의 최근 확장을 활용합니다. 또한, 장기적인 예측을 포함하여 다양한 유형의 FL 글로벌 모델을 실험하고, 전력 시스템 도메인 지식을 결합하여 보다 일반화된 FL 프레임워크를 구축합니다.

- **Performance Highlights**: 향상된 FL 프레임워크를 대규모 현실 데이터세트에서 검증하여 기존 시계열 예측 방법과의 효과성을 입증할 계획입니다. 이를 통해 DER의 통합 및 분산망에서의 신뢰성과 안정성을 개선하여 전력망의 운영 효율성 및 최적화를 향상시키는 것을 목표로 합니다.



### Safety-Aware Fine-Tuning of Large Language Models (https://arxiv.org/abs/2410.10014)
Comments:
          NeurIPS 2024 Workshop on Safe Generative AI

- **What's New**: 본 연구에서는 안전성을 고려한 Fine-Tuning 접근 방식인 Safety-Aware Fine-Tuning (SAFT) 프레임워크를 새롭게 제안합니다. SAFT는 유해한 데이터 샘플을 자동으로 감지하고 제거하여 안전한 모델 작성을 돕습니다.

- **Technical Details**: SAFT는 Low-Rank Adaptation (LoRA) 기법을 이용하여 모델을 학습하며, 다양한 오염 비율(이용자의 불순물 비율)에서 실험을 수행했습니다. 학습 시 향상율(learning rate)은 2e-5로 설정하였고, 모델의 성능은 최대 256개 토큰을 생성하는 Greedy Decoding 방식으로 평가했습니다.

- **Performance Highlights**: 실험 결과, SAFT는 최대 27.8%까지 유해성을 감소시키는 효과를 보여 다른 LLM들에서도 유효성을 입증했습니다. SAFT는 AI 시스템의 강인성과 신뢰성을 향상시킬 수 있는 잠재력을 내포하고 있습니다.



### Enhancing Peer Review in Astronomy: A Machine Learning and Optimization Approach to Reviewer Assignments for ALMA (https://arxiv.org/abs/2410.10009)
Comments:
          19 pages, 5 figures, submitted to PASP

- **What's New**: 2023 Cycle 10에서 ALMA(Atacama Large Millimeter/submillimeter Array) 제안서의 피어 리뷰를 위한 머신 러닝과 최적화 기법을 적용하여 새로운 인력 배치 과정을 도입했습니다.

- **Technical Details**: 이 연구에서는 주제 모델링(topic modeling) 알고리즘을 사용하여 제안서의 주제를 파악하고, 역사적 ALMA 제안서 제출을 기반으로 리뷰어의 전문성을 평가했습니다. 이후 PeerReview4All의 최적화 알고리즘을 적용하여 제안서 주제와 리뷰어 전문성 간의 정렬을 극대화했습니다.

- **Performance Highlights**: 제안서 주제와 리뷰어 전문성 간의 중위 유사성 점수가 이전 사이클보다 51 퍼센트 포인트 증가했으며, 리뷰어들은 자신의 전문가로서의 보고 비율이 20 퍼센트 포인트 증가했습니다. 또한, 프로세스의 효율성이 높아져 3~5일의 수작업 소요 시간을 절약하였습니다.



### Leveraging Customer Feedback for Multi-modal Insight Extraction (https://arxiv.org/abs/2410.09999)
Comments:
          NAACL 2024

- **What's New**: 이 논문은 고객 피드백의 이미지와 텍스트 정보를 융합하여 행동 가능한 인사이트를 효과적으로 추출하는 새로운 다중 모달(multi-modal) 접근 방식을 소개합니다.

- **Technical Details**: 제안된 방법은 라테ント 공간(latent space)에서 이미지와 텍스트 정보를 융합하고 이미지-텍스트 기반 텍스트 디코더(image-text grounded text decoder)를 통해 관련 피드백 세그먼트를 추출합니다. 약한 지도 학습(weakly-supervised) 데이터 생성 기법을 활용하여 훈련 데이터를 생성합니다.

- **Performance Highlights**: 제안한 모델은 보지 않은 데이터에 대해 평가되었으며, 기존 기준선(baselines)을 F1 점수에서 14점 초과하여 뛰어난 성능을 보였습니다.



### SlimSeiz: Efficient Channel-Adaptive Seizure Prediction Using a Mamba-Enhanced Network (https://arxiv.org/abs/2410.09998)
Comments:
          5 pages, 3 figures

- **What's New**: 본 논문은 SlimSeiz 프레임워크를 소개하여, 적응형 채널 선택 방법과 경량화된 신경망 모델을 활용하여 발작 예측의 효율성을 높이고자 하였습니다. 이 방법은 기존의 EEG 채널 수를 22개에서 8개로 줄이면서도 94.8%의 정확도를 유지합니다.

- **Technical Details**: SlimSeiz는 두 가지 주요 단계로 구성됩니다. 첫 번째 단계는 머신러닝 알고리즘을 통해 최적의 채널 집합을 선택하는 것이고, 두 번째 단계는 합성곱 신경망(convolutional neural network)과 Mamba 블록을 기반으로 한 경량화된 신경망 모델을 이용하여 발작을 예측하는 것입니다. 이 모델은 21.2K의 모델 파라미터로 작동합니다.

- **Performance Highlights**: CHB-MIT EEG 데이터셋에서 SlimSeiz는 94.8%의 정확도, 95.5%의 민감도(sensitivity) 및 94.0%의 특이도(specificity)를 달성하였으며, 새로운 SRH-LEI EEG 데이터셋에서도 92.7%의 정확도, 94.7%의 민감도 및 90.7%의 특이도를 기록하였습니다.



### Collu-Bench: A Benchmark for Predicting Language Model Hallucinations in Cod (https://arxiv.org/abs/2410.09997)
- **What's New**: 새로운 연구에서는 LLMs(대형 언어 모델)의 코드 생성에서 발생하는 hallucination(허위 생성)에 대한 분석 및 예측을 위한 새로운 벤치마크인 Collu-Bench를 소개합니다. 이 벤치마크는 코드 생성 및 자동화된 프로그램 수정 작업에서 13,234개의 코드 hallucination 사례를 수집했습니다.

- **Technical Details**: Collu-Bench는 다양한 구조와 크기의 11개 LLMs를 사용하여 5개의 데이터셋에서 구축되었습니다. 상세한 분석을 위해 LLM의 출력에 대한 단계별 로그 확률(per-step log probabilities), 토큰 유형(token types), 생성된 코드에 대한 실행 피드백(execution feedback)을 포함하고 있습니다. 이를 통해 LLMs의 코드 hallucinations 패턴을 이해하고 예측하는 데 도움을 줍니다.

- **Performance Highlights**: 예측 결과, LLMs의 코드 hallucination 예상 정확도는 22.03%에서 33.15% 사이로 나타났습니다. 덜 자신감 있는 LLMs는 hallucination에서 더 낮은 확률을 보이며, 특정 토큰 유형(예: Keyword, Identifier, Type Identifier)일 때 더 자주 hallucination을 발생시킵니다. LSTM 모델이 샘플 예측에서 가장 높은 정확도를 보이는 반면, 랜덤 포레스트는 토큰 예측에서 가장 높은 정확도를 기록했습니다.



### MARS: Multilingual Aspect-centric Review Summarisation (https://arxiv.org/abs/2410.09991)
Comments:
          EMNLP 2024

- **What's New**: 이번 논문에서는 고객 피드백을 요약하여 제품 및 서비스에 대한 실행 가능한 인사이트를 제공하는 새로운 프레임워크 MARS를 제안합니다. 이 프레임워크는 Extract-then-Summarise 방식으로 작동하며, 다국어 리뷰의 도메인 비구속적 측면 요약을 혁신적으로 해결하는 것을 목표로 합니다.

- **Technical Details**: MARS는 두 가지 주요 구성 요소로 구성됩니다: (1) Multilingual InsightNet: 다양한 언어로 작성된 리뷰에서 다단계 구조적 인사이트를 자동으로 추출하는 방법, (2) 대규모 언어 모델(LLMs)을 활용한 적응형 요약 기술로, 추출된 인사이트를 실용적인 방식으로 요약합니다.

- **Performance Highlights**: MARS는 기존 단일 언어 베이스라인에 비해 상당한 성능 향상을 보여주었습니다. 또한 다양한 도메인에서 리뷰의 동적 특성을 다루기 위한 약간의 지도 학습 접근 방식을 통해 새로운 측면을 식별하고 고품질의 요약을 생성할 수 있는 효율성을 입증하였습니다.



### Facial Width-to-Height Ratio Does Not Predict Self-Reported Behavioral Tendencies (https://arxiv.org/abs/2410.09979)
Comments:
          Psychological Science (2017)

- **What's New**: 이번 연구는 137,163명의 대규모 샘플을 통해 얼굴 폭-높이 비율(fWHR)과 행동 경향 사이의 관계를 재검토하였습니다.

- **Technical Details**: 행동 경향은 55개의 잘 확립된 심리측정 척도를 사용하여 측정하였으며, 포함된 항목으로는 지능, 오성 모델(five-factor model) 성격의 영역 및 세부 항목, 충동성, 공정성 감각, 감각적 관심, 자기 모니터링, 인상 관리, 삶의 만족도 등이 있습니다.

- **Performance Highlights**: 연구 결과, fWHR와 이러한 자가 보고된 행동 경향 사이에는 실질적인 연관성이 없음을 보여주었으며, 이는 과거 연구에서의 소규모 샘플 및 특정 실험 환경 외부에서 fWHR과 행동 간의 관계가 일반화될 수 있는지를 의문시하게 만들었습니다.



### Make the Pertinent Salient: Task-Relevant Reconstruction for Visual Control with Distractions (https://arxiv.org/abs/2410.09972)
- **What's New**: Segmentation Dreamer (SD)라는 새로운 방법을 제안하여 시각적 산만함이 있는 환경에서의 표현 학습을 촉진합니다. 이 방법은 이미지 관찰에서 작업 관련 구성 요소만 재구성하도록 돕는 세그멘테이션 마스크(segmentation mask)를 활용합니다.

- **Technical Details**: SD 방법은 시뮬레이션 환경에서 쉽게 접근 가능한 그라운드 트루스 마스크(ground-truth mask)를 사용하거나, 불완전한 세그멘테이션 모델을 활용하여 훈련됩니다. 특히, 세그멘테이션 예측 오류로 인한 잘못된 학습 신호를 피하기 위해 복원 손실(reconstruction loss)을 선택적으로 적용하는 전략이 포함됩니다.

- **Performance Highlights**: SD는 수정된 DeepMind Control Suite(DMC) 및 Meta-World 작업에서 더 나은 샘플 효율(sample efficiency) 및 향상된 최종 성능을 나타냅니다. 특히, 이 방법은 희소 보상(sparse reward) 작업에서 기존 방법으로 해결하기 어려운 문제를 해결할 수 있게 도와줍니다.



### Improving 3D Few-Shot Segmentation with Inference-Time Pseudo-Labeling (https://arxiv.org/abs/2410.09967)
- **What's New**: 이번 연구에서는 few-shot segmentation (FSS) 방법에서 쿼리 데이터의 잠재력을 최대한 활용하여 의료 이미징의 세분화 정확도를 향상시키는 새로운 전략을 제안합니다. 기존 방법들이 쿼리 자체의 정보를 충분히 활용하지 못한 점을 고려하여, 쿼리를 라벨이 없는 데이터로 취급해 예측 정확도를 향상시킬 기회를 제공합니다. 특히, 의료 이미징에서 쿼리의 볼륨 구조는 세분화 개선을 위한 소중한 정보원을 제공합니다.

- **Technical Details**: 제안된 방법은 초기 세분화 점수를 생성하는 프로토타입 접근 방식과 쿼리 슬라이스에서 가장 정보가 많은 부분을 지원 집합으로 전이하는 신뢰도 인식 의사 라벨링 절차를 포함합니다. 이를 통해 확대된 지원 집합을 이용해 더욱 정확한 세분화 마스크를 예측하게 됩니다. 이 방법은 쿼리 데이터와 지원 데이터 간의 통합적 활용을 통해 세분화 성능을 효율적으로 향상시키는 것을 목표로 합니다.

- **Performance Highlights**: 광범위한 실험을 통해 제안된 방법이 다양한 환경과 데이터셋에 걸쳐 성능을 효과적으로 향상시킬 수 있음을 입증했습니다. 제안된 접근 방식은 의료 이미지 세분화 분야에서 데이터 희소성을 극복할 수 있는 잠재력을 보여줍니다.



### Lower-dimensional projections of cellular expression improves cell type classification from single-cell RNA sequencing (https://arxiv.org/abs/2410.09964)
- **What's New**: EnProCell이라는 새로운 세포 유형 분류 방법이 제안되었습니다. 이 방법은 PCA와 MDA(다중 판별 분석)를 결합하여 높은 분산과 세포 유형의 분리를 동시에 캡처합니다.

- **Technical Details**: EnProCell은 두 단계로 구성됩니다. 첫 번째 단계에서는 PCA를 통해 높은 분산을 가진 구성 요소를 찾고, 두 번째 단계에서는 훈련된 모델을 사용하여 테스트 데이터의 세포 유형을 예측합니다. EnProCell은 훈련 데이터에서 추출된 구성 요소를 사용하여 저차 원으로 변환하고, 이 데이터를 기반으로 분류 모델을 학습합니다.

- **Performance Highlights**: EnProCell은 98.91의 정확도와 98.64의 F1 점수로 기존의 방법들보다 우수한 성능을 보였습니다. 불확실한 세포 유형에 대한 예측에서도 99.52의 정확도와 99.07의 F1 점수를 기록했습니다.



### EITNet: An IoT-Enhanced Framework for Real-Time Basketball Action Recognition (https://arxiv.org/abs/2410.09954)
Comments:
          pages

- **What's New**: 이번 연구는 IoT 기술을 통합한 EITNet 모델을 제안하여 농구 선수의 행동 인식을 향상시키고, 선수 퍼포먼스와 게임 전략에 대한 중요한 통찰을 제공하는 데 초점을 맞추고 있습니다. 기존 방법들의 정확성과 효율성이 부족한 문제를 해결하고자, 객관적 데이터 수집 및 처리 방식을 최적화하는 새로운 접근 방식을 제시합니다.

- **Technical Details**: EITNet 모델은 EfficientDet(객체 탐지), I3D(공간-시간 특징 추출), TimeSformer(시간 분석) 등 다양한 딥 러닝 프레임워크를 결합하여 실시간 데이터 수집과 처리를 수행합니다. 이 구조는 92%의 인식 정확도를 달성했으며, EfficientDet 모델의 87%를 초과하고 손실을 50 에포크(epochs) 동안 9.0에서 5.0으로 감소시킵니다.

- **Performance Highlights**: EITNet는 복잡하고 고속의 선수 동작 인식에서 높은 강인성과 정확성을 보였으며, 기존 단일 뷰 영상 분석 방법과 비교했을 때, 동작 인식의 정확성과 데이터 완전성을 significantly 향상시켰음을 입증했습니다. 또한, 실시간 피드백 기제를 통해 코치와 선수에게 보다 체계적이고 효과적인 훈련 지침을 제공하여 운동 능력 향상에 기여합니다.



### State of NLP in Kenya: A Survey (https://arxiv.org/abs/2410.09948)
Comments:
          21 pages

- **What's New**: 이번 연구는 케냐에서의 자연어 처리(NLP) 기술 현황을 종합적으로 평가하여, 원주율 언어에 대한 디지털 성과 및 도전 과제를 다룹니다. 특히 키스와힐리어, 도루어, 기쿠유어 및 루흐야어와 같은 현지 방언에 대한 데이터셋 생성 및 기계 번역, 감정 분석, 음성 인식의 노력들을 강조하고 있습니다.

- **Technical Details**: 이 연구는 데이터 수집, 기존 모델 분석 및 케냐어 언어를 위한 사용 가능한 자원 평가를 포함한 다단계 접근 방식을 따릅니다. 연구에 사용된 주요 방법론은 구글 스칼라, ACL 등에서 발행된 연구 논문 및 공개 데이터셋 리뷰로, 특히 스와힐리어, 도루어, 루흐야어에 중점을 두었습니다.

- **Performance Highlights**: 이 논문은 케냐의 NLP 기술 발전이 여전히 제한된 자원과 도구로 인해 많은 원주율 언어가 디지털 공간에서 저조하게 나타나는 문제를 지적합니다. 대규모 언어 모델 필요성과 기존 데이터셋 및 NLP 모델의 격차를 비판적으로 평가하고, 이를 위해 AI 및 NLP의 미래를 형성하는 정책 및 규제를 논의합니다.



### Generalized Group Data Attribution (https://arxiv.org/abs/2410.09940)
- **What's New**: 새로운 GGDA(Generalized Group Data Attribution) 프레임워크는 개별 훈련 데이터 포인트 대신 데이터 포인트 그룹에 영향을 할당하여 데이터 귀속(Data Attribution)의 계산적 복잡성을 감소시키는 방법을 제시합니다. 이는 대규모 기계 학습 모델에 대한 적용성을 높이는 것이 특징입니다.

- **Technical Details**: GGDA는 기존의 데이터 귀속 방법을 포함하며, 새로운 데이터 귀속 기술이 나타날 때에도 적용될 수 있는 일반적인 프레임워크입니다. 이 방법은 훈련 데이터 포인트 그룹을 집합적으로 고려하여 계산적 오버헤드를 줄이면서도 귀속의 정확성을 유지합니다. 또한 사용자가 효율성과 충실도의 균형을 최적화할 수 있도록 그룹 크기를 조정할 수 있는 유연성을 제공합니다.

- **Performance Highlights**: GGDA를 적용한 결과, 기존의 데이터 귀속 기법(Influence Functions, TracIn, TRAK)에 비해 최대 10배에서 50배까지 빠른 속도로 성능 개선이 있었으며, 데이터셋 프루닝 및 잘못 라벨링된 인스턴스 식별과 같은 다운스트림 응용 프로그램에서 효율성이 크게 향상되었습니다. GGDA는 기존 방법보다 처리 속도와 효과성을 유지하면서 대규모 기계 학습 시나리오에서 실용적인 응용을 가능하게 합니다.



### M2M-Gen: A Multimodal Framework for Automated Background Music Generation in Japanese Manga Using Large Language Models (https://arxiv.org/abs/2410.09928)
- **What's New**: 이번 논문에서는 일본 만화를 위한 배경 음악 생성에 특화된 다중 모드(Multi-Modal) 프레임워크인 M2M Gen을 소개합니다. 이 연구는 기존 데이터 세트의 부족과 기준 설정의 부재라는 주요 도전 과제를 해결하기 위해 자동화된 음악 생성 파이프라인을 제안합니다.

- **Technical Details**: M2M Gen 시스템은 만화의 대화 내용을 사용하여 장면 경계를 탐지하고, 각 장면 내 캐릭터 얼굴을 통해 감정 분류를 수행합니다. 이후, GPT4o를 활용하여 장면 정보를 기반으로 음악 지침을 생성하고, 또 다른 GPT4o 인스턴스가 페이지 수준의 음악 캡션을 생성하여 텍스트-음악 모델에 전달합니다. 이 과정을 통해 만화의 서사 변화에 부합하는 음악을 생성합니다.

- **Performance Highlights**: M2M Gen의 효과는 광범위한 주관적 평가를 통해 입증되었으며, 기존 모델과 비교했을 때 관련성 및 일관성을 갖춘 더 높은 품질의 음악을 생성하는 것으로 나타났습니다.



### Analysis and Design of a Personalized Recommendation System Based on a Dynamic User Interest Mod (https://arxiv.org/abs/2410.09923)
- **What's New**: 인터넷의 빠른 발전과 정보의 폭발로 사용자를 위한 정확한 개인화 추천(Recommendation) 제공이 중요한 연구 주제로 대두되고 있습니다. 본 논문은 동적 사용자 관심 모델(Dynamic User Interest Model)에 기반한 개인화 추천 시스템을 설계하고 분석하였습니다.

- **Technical Details**: 이 시스템은 사용자 행동 데이터(User Behavior Data)를 수집하고, 동적 사용자 관심 모델을 구축하여 여러 추천 알고리즘을 결합하여 사용자가 개인화된 콘텐츠를 받을 수 있도록 합니다. 논문에서는 시스템의 아키텍처 설계(Architecture Design), 알고리즘 구현(Algorithm Implementation), 실험 결과(Experimental Results)에 대해 상세히 논의합니다.

- **Performance Highlights**: 연구 결과에 따르면, 이 시스템은 추천 정확도(Recommendation Accuracy)와 사용자 만족도(User Satisfaction)를 상당히 개선하는 것으로 나타났습니다. 향후 연구 방향(Future Research Directions)도 탐구하고 있습니다.



### Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning (https://arxiv.org/abs/2410.09908)
- **What's New**: 이번 연구에서는 Retrieval-based Parameter Ensemble (RPE)이라는 새로운 방법을 제시합니다. RPE는 Low-Rank Adaptation (LoRA)을 기반으로 하는 벡터화된 데이터베이스를 생성하며, 이는 신규 작업에 대한 모델 적응을 효율적으로 수행할 수 있게 합니다. RPE는 extensive training 및 labeled data에 대한 의존성을 최소화하여 zero-shot learning에 특히 효과적입니다.

- **Technical Details**: RPE는 LoRA-VecDB라는 벡터화된 데이터베이스를 통해 다양한 작업에 대한 LoRA와 그에 해당하는 표현을 저장합니다. 새로운 데이터셋이나 작업 발생 시, 모델의 표현을 추출하여 이 데이터베이스를 쿼리합니다. LoRA-VecDB에서 적합한 LoRA를 검색하고 적절한 가중치를 계산하여 새로운 작업에 모델을 효과적으로 적응시킵니다. 이 과정은 전통적인 fine-tuning 방법보다 효율적이며, 직접적인 데이터 접근 없이 모델 파라미터를 수정함으로써 개인 정보를 보호합니다.

- **Performance Highlights**: RPE는 의료 보고서 생성 및 이미지 분할 작업에 적용되었을 때, supervisede fine-tuning 방법보다 더 효과적이라는 결과를 보였습니다. 또한, RPE는 계산 효율성과 개인 정보 보호를 동시에 강화할 수 있는 잠재력을 가지고 있습니다.



### Large-Scale 3D Medical Image Pre-training with Geometric Context Priors (https://arxiv.org/abs/2410.09890)
Comments:
          CVPR 2024 Extension

- **What's New**: 의료 이미지 분석에서의 주석(annotation) 부족 문제를 해결하기 위한 새로운 접근 방식인 Volume Contrast (VoCo) 프레임워크를 소개합니다. 이 방법은 기하학적 컨텍스트 정보(priors)를 활용하여 주석 없이도 고수준의 의미를 학습할 수 있게 합니다. 특히, 3D 의료 이미지의 일관된 기하학적 관계를 이용함으로써 의미 있는 표현을 학습합니다.

- **Technical Details**: Volume Contrast (VoCo) 프레임워크는 입력 볼륨으로부터 다양한 지역에서 기본 크롭(base crops)을 추출하여 긍정적 및 부정적 쌍을 구성하고, 무작위 크롭의 맥락적 위치를 예측하여 대조 학습(contrastive learning)을 수행합니다. 이 과정에서 모델 표현에 내재된 기하학적 컨텍스트를 인코딩하고, 주석 없이도 고수준의 의미 학습을 가능하게 합니다.

- **Performance Highlights**: VoCo는 대규모 의료 사전 학습 데이터셋인 PreCT-160K를 도입하고, 다양한 의료 작업에 맞춰 모델 크기를 조정하기 위한 가이드라인을 제안하며, 48개의 의료 작업을 포함하는 벤치마크를 구축했습니다. 실험 결과 VoCo의 우수성이 입증되었습니다.



### ChroKnowledge: Unveiling Chronological Knowledge of Language Models in Multiple Domains (https://arxiv.org/abs/2410.09870)
- **What's New**: 이 논문에서는 ChroKnowBench라는 새로운 벤치마크 데이터셋을 소개하여 대형 언어 모델(LLMs)의 시간에 따른 축적 지식을 평가하는 방법을 제시합니다. 이 데이터셋은 시간 종속성, 다양한 도메인, 그리고 시간 상태라는 세 가지 주요 측면을 기반으로 합니다.

- **Technical Details**: ChroKnowBench는 과학적 발견이나 수정된 법률과 같은 진화하는 지식과 수학적 진리나 상식 사실과 같이 변하지 않는 지식을 구별합니다. 연구팀은 ChroKnowledge 프레임워크를 통해 LLMs의 비모수적 비율 연대 지식을 평가하고 업데이트하는 방법을 제시합니다.

- **Performance Highlights**: ChroKnowPrompt를 활용한 평가에서 생물의학 도메인에서 +11.9% 향상된 성능과 일반 도메인에서 +2.8% 향상된 성능을 보였습니다. 이 비모수적 접근 방식은 오픈 소스 모델과 독점 모델 모두에 대한 지식 업데이트를 직접 수행할 수 있습니다.



### Prompt Tuning for Audio Deepfake Detection: Computationally Efficient Test-time Domain Adaptation with Limited Target Datas (https://arxiv.org/abs/2410.09869)
Comments:
          Accepted at Interspeech 2024. Hideyuki Oiso and Yuto Matsunaga contributed equally

- **What's New**: 이번 논문에서는 오디오 딥페이크 탐지(Audio Deepfake Detection, ADD)를 위한 테스트 시 도메인 적응(test-time domain adaptation) 방법을 제안합니다. 주요 도전 과제로는 소스-타겟 도메인의 격차, 제한된 타겟 데이터셋 크기, 높은 계산 비용을 다루고 있습니다.

- **Technical Details**: 우리의 ADD 방법은 'prompt tuning'을 활용한 플러그인 스타일로, 최신 트랜스포머(transformer) 모델과 다른 파인 튜닝(fine-tuning) 방법과 쉽게 통합할 수 있습니다. 이 방법은 소스 도메인 데이터셋에 접근하지 않고도 미리 훈련된 모델을 타겟 데이터셋에 적응시키며, 필요로 하는 추가 매개변수가 적기 때문에 소규모 데이터셋에 잘 적합합니다.

- **Performance Highlights**: 실험 결과, 우리의 방법은 타겟 샘플 크기가 10개의 데이터로도 동등한 오류율(Equal Error Rate, EER)을 개선할 수 있음을 보여주었습니다. 추가적인 계산 비용도 최소화되어, 전체 네트워크를 업데이트하는 전통적인 파인 튜닝 모델과 비교할 때 더 효과적임을 확인했습니다.



### Uncovering, Explaining, and Mitigating the Superficial Safety of Backdoor Defens (https://arxiv.org/abs/2410.09838)
Comments:
          NeurIPS 2024 Spotlight paper. The first two authors contributed equally

- **What's New**: 이번 연구에서는 백도어 공격(Backdoor Attacks)의 안전성을 파악하기 위한 새로운 관점을 제시합니다. 현재의 안전 정화(safety tuning) 방법이 실제로 학습된 백도어 특징을 완전히 제거하는지의 여부를 조사했습니다.

- **Technical Details**: Post-Purification Robustness를 평가하기 위해 Retuning Attack (RA)와 Query-based Reactivation Attack (QRA)을 사용하며, 이들 공격을 통해 정화된 모델에서 백도어 행동이 어떻게 재활성화될 수 있는지를 구체적으로 분석합니다.

- **Performance Highlights**: Path-Aware Minimization (PAM) 방법을 통해 Post-Purification Robustness를 크게 향상시키고, 이는 낮은 Attack Success Rate (ASR)와 높은 깨끗한 정확도를 유지하는 방식으로 나타났습니다.



### LoLI-Street: Benchmarking Low-Light Image Enhancement and Beyond (https://arxiv.org/abs/2410.09831)
Comments:
          Accepted by the Asian Conference on Computer Vision (ACCV 2024)

- **What's New**: 이번 논문에서는 LoLI-Street라는 새로운 데이터셋을 소개합니다. 이 데이터셋은 33,000개의 쌍의 저조도(low-light) 및 잘 노출된(well-exposed) 이미지로 구성되어 있으며, 이는 자율 주행 시스템에서 요구되는 LLIE(low-light image enhancement) 연구에 필수적입니다.

- **Technical Details**: LoLI-Street 데이터셋은 30,000개의 훈련용 이미지, 3,000개의 검증용 이미지, 1,000개의 실시간 저조도 테스트 이미지로 구성되어 있습니다. 제안된 모델인 TriFuse는 삼중융합(transformer and diffusion-based) 모델로, 변환자(transformer)를 사용해 노이즈를 예측하고 샘플링 단계를 감소시킵니다.

- **Performance Highlights**: TriFuse 모델은 LoLI-Street 데이터셋과 기존의 SOTA(state-of-the-art) LLIE 모델 비교에서 LLIE 성능과 객체 탐지 성능에서 뛰어난 결과를 보여주었습니다. 이는 자율 주행과 감시 시스템과 같은 실제 응용에서 효과적인 성과를 의미합니다.



### Single Ground Truth Is Not Enough: Add Linguistic Variability to Aspect-based Sentiment Analysis Evaluation (https://arxiv.org/abs/2410.09807)
Comments:
          Preprint

- **What's New**: 본 논문에서는 Aspect-based Sentiment Analysis (ABSA)의 정확한 평가를 위해 기존 테스트 세트를 대체 가능한 정답으로 보강하는 자동화된 파이프라인을 제안합니다.

- **Technical Details**: 이 연구에서는 네 가지 ASQP 데이터셋을 사용하고, 테스트 세트에서 무작위로 선택한 80개의 샘플에 대해 인간 주석자를 통해 새롭게 구성된 GT 쿼드러플의 정확성을 검증하였습니다. 세 단계(Zoom-In, Zoom-Out, Judge)로 구성된 데이터셋 확장 프로세스를 설명하며, 다양한 Large Language Models (LLMs)로부터의 예측을 수집했습니다.

- **Performance Highlights**: 대체된 테스트 세트를 사용할 경우, LLM들이 T5 모델에 비해 ABSA 작업에서 상당한 성능 향상을 보임을 입증하였으며, Kendall's Tau 점수가 최대 10% 향상되었습니다.



### BlackDAN: A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models (https://arxiv.org/abs/2410.09804)
- **What's New**: 대형 언어 모델(LLMs)의 보안 문제에 대한 다양한 연구가 진행되어왔습니다. 특히, 기존의 jailbreak 전략이 공격 성공률(ASR) 중심으로만 개발되어왔던 문제를 해결하기 위해, BlackDAN은 다목적 최적화를 통해 보다 효과적이고 해석 가능한 jailbreak 방안을 제공합니다.

- **Technical Details**: BlackDAN은 NSGA-II(Non-dominated Sorting Genetic Algorithm II) 알고리즘을 활용하여, 특정 맥락에 맞게 jailbreak 프롬프트를 설계합니다. 이 프레임워크는 공통적으로 사용되는 여러 목표(ASR, stealthiness, semantic relevance 등)를 동시에 최적화하여 해킹 공격을 보다 유연하게 진행할 수 있도록 합니다.

- **Performance Highlights**: 실험 결과, BlackDAN은 기존의 단일 목표 접근법에 비해 성공률이 높고, 다양한 LLM 및 멀티모달 LLM에서 더 나은 견고성을 보여주었습니다. 또한, 생성된 jailbreak 응답은 관련성이 높으면서도 탐지가 용이하지 않은 특성을 가지게 됩니다.



### EBDM: Exemplar-guided Image Translation with Brownian-bridge Diffusion Models (https://arxiv.org/abs/2410.09802)
Comments:
          ECCV 2024

- **What's New**: 이 논문은 Exemplar-guided Image Translation with Brownian-Bridge Diffusion Models (EBDM)라는 새로운 접근법을 제안합니다. 이 방법은 구조 제어가 가능한 초기 지점에 고정된 확률적 브라운 다리 프로세스를 기반으로 하여 주어진 스타일 샘플 이미지만을 조건으로 하는 포토리얼리스틱 이미지(photorealistic image) 생성을 가능하게 합니다.

- **Technical Details**: EBDM 방법은 Global Encoder, Exemplar Network, Exemplar Attention Module의 세 가지 주요 구성 요소를 포함하여 샘플 이미지에서 전역 및 세부 질감 정보를 통합합니다. 이 네트워크는 구조 제어를 통해 이미지를 변환하며, 단일 조건으로 스타일 샘플에 대해 독립적으로 작동합니다.

- **Performance Highlights**: 다양한 데이터셋에서 수행된 실험 결과, EBDM 방법이 기존 접근 방식보다 뛰어난 성능과 계산 효율성을 보여주었다고 보고합니다. 통계적 브라운 다리 확산 과정(stochastic Brownian bridge diffusion process)을 활용한 이 방법은 이미지 번역 작업에서 이전의 문제들을 효과적으로 해결했습니다.



### Predicting Molecular Ground-State Conformation via Conformation Optimization (https://arxiv.org/abs/2410.09795)
- **What's New**: 이 논문은 분자 그래프(molecular graph)와 저품질 3D 형태(low-quality 3D conformation)를 입력으로 활용하여 분자의 기초 상태 형태(ground-state conformation)를 예측하는 새로운 프레임워크인 ConfOpt를 제안합니다.

- **Technical Details**: ConfOpt는 분자 그래프를 참고하여 저품질 형태를 반복적으로 최적화하여 기초 상태 형태를 도출합니다. 이 과정에서 원자 3D 좌표 및 원자 간 거리(interatomic distances)를 동시에 최적화합니다.

- **Performance Highlights**: ConfOpt는 기존 방법들에 비해 성능이 크게 개선되었으며, 분자의 기초 상태 형태를 효율적이고 정확하게 예측할 수 있는 새로운 패러다임을 제공합니다.



### Expanding Search Space with Diverse Prompting Agents: An Efficient Sampling Approach for LLM Mathematical Reasoning (https://arxiv.org/abs/2410.09780)
Comments:
          6 pages, 4 figures

- **What's New**: 이 연구는 전통적인 LLM 접근 방식을 넘어서 다양한 문제 해결 전략을 탐구하기 위해 실험 분석을 수행했습니다. 거기서 각 프롬프트 방법이 독특한 탐색 공간을 탐색한다는 사실을 확인했고, 특히 문제 복잡성이 증가함에 따라 이 차이가 두드러진다고 밝혔습니다.

- **Technical Details**: 세 가지 주요 프롬프트 방법(1) Text, (2) Code, (3) Cumulative Reasoning(CR)을 선택하여 각각의 문제 해결 접근 방식을 분석했습니다. 특히, Uniform Sampling 기법을 통해 서로 다른 방법에서 샘플을 균일하게 결합하여 최대 탐색 공간을 확장했습니다.

- **Performance Highlights**: MATH-hard 데이터셋에서 진행된 연구는 평균적으로 단일 방법에 비해 약 43% 더 적은 실행 횟수로 최대 탐색 공간에 도달하는 성과를 보였습니다. 실험 결과, 다양한 프롬프트 기법을 활용하는 것이 더 넓은 탐색을 가능하게 한다는 가설을 뒷받침합니다.



### HypomimiaCoach: An AU-based Digital Therapy System for Hypomimia Detection & Rehabilitation with Parkinson's Diseas (https://arxiv.org/abs/2410.09772)
- **What's New**: 본 연구에서는 자가 조정 가능한 AI 시스템을 통해 파킨슨병의 비운동 증상인 Hypomimia를 감지하고 치료할 수 있는 새로운 디지털 치료 시스템인 HypomimaCoach를 개발했습니다.

- **Technical Details**: HypomimaCoach는 Facial Action Units (AU)에 기반하여 설계된 디지털 치료 시스템입니다. 이 시스템은 얼굴 제스처 및 움직임을 분석하여 Hypomimia를 감지하고, 환자에게 실시간 피드백을 제공함으로써 재활 훈련을 지원합니다. Action Unit(AU)의 추출 및 융합과 Graph Convolutional Networks(GCN)의 활용을 통해 모델의 정확도를 향상시켰습니다.

- **Performance Highlights**: 파일럿 연구 결과, 참여자들은 자기 효능감이 향상되었으며 의사들로부터 긍정적인 피드백을 받았습니다. 이 시스템은 파킨슨병 환자들의 회복 outcomes을 개선할 수 있는 잠재적 가치를 지닌 것으로 평가되었습니다.



### 'Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated peer-reviews (https://arxiv.org/abs/2410.09770)
Comments:
          EMNLP Main, 17 pages, 5 figures, 9 tables

- **What's New**: 이 논문에서는 AI 생성 논문 리뷰의 탐지를 위한 새로운 접근 방식을 제안합니다. 기존 연구는 일반적인 AI 생성 텍스트 탐지에 집중했으나, 본 연구에서는 특정 리뷰가 ChatGPT에 의해 작성되었는지를 식별하는 문제에 초점을 둡니다.

- **Technical Details**: 제안된 두 가지 모델은 Term Frequency (TF) 모델과 Review Regeneration (RR) 모델로, TF 모델은 AI가 자주 반복하는 토큰을 분석하고, RR 모델은 재프롬프트 하에 유사한 출력을 생성하는 것을 기반으로 합니다. 두 모델은 다양한 공격에 대한 강건성을 테스트하고, 공격을 피하기 위한 방어 전략을 제안합니다.

- **Performance Highlights**: TF 모델은 일반적인 조건에서 RR 모델보다 성능이 좋지만, RR 모델은 공격에 대해 더 강력한 저항력을 보입니다. 실험 결과, 두 제안된 방법 모두 다른 AI 텍스트 탐지기보다 우수한 성능을 보여주며, 연구자들이 만든 데이터셋과 코드는 공개됩니다.



### LibEER: A Comprehensive Benchmark and Algorithm Library for EEG-based Emotion Recognition (https://arxiv.org/abs/2410.09767)
- **What's New**: EEG 기반 감정 인식을 위한 LibEER라는 포괄적인 벤치마크와 알고리즘 라이브러리를 제안합니다. 이는 다양한 모델에서 구현 세부 사항을 일관되게 하여 공정한 비교를 가능하게 합니다.

- **Technical Details**: 이 논문에서는 EEG 기반 감정 인식을 위해 PyTorch를 사용하여 통일된 평가 프레임워크를 설정하고, SEED, SEED-IV, DEAP, HCI의 네 가지 주요 데이터셋을 이용해 10개의 대표적인 딥러닝 EER 모델의 성능을 비교합니다. 사용자는 실험 계획을 쉽게 설정할 수 있는 사용자 친화적인 인터페이스를 제공합니다.

- **Performance Highlights**: LibEER를 통해 다양한 실험 환경에서 인기 있는 모델의 성능을 정교하게 평가할 수 있으며, 이는 연구자들이 EER 모델 선택 및 설계에 유용한 통찰력을 제공합니다.



### EEG-based AI-BCI Wheelchair Advancement: A Brain-Computer Interfacing Wheelchair System Using Machine Learning Mechanism with Right and Left Voluntary Hand Movemen (https://arxiv.org/abs/2410.09763)
- **What's New**: 본 논문은 인공지능(AI) 통합의 새로운 접근 방식으로, 자발적인 손 움직임을 사용하여 휠체어 제어를 위한 뇌-컴퓨터 인터페이스(BCI)를 개발한 내용을 소개합니다.

- **Technical Details**: 이 시스템은 전기생리학적 뇌파(EEG) 데이터를 기반으로 오른손과 왼손의 자발적인 움직임에 따라 휠체어 내비게이션을 시뮬레이션합니다. 전처리된 데이터셋은 개방형 EEG 저장소에서 얻은 것으로, 손 움직임의 시작을 포착하기 위해 19x200 배열로 분할되었습니다. 실험 데이터는 200Hz의 샘플링 주파수로 획득되었습니다. 또한, 휠체어 움직임을 시뮬레이션하기 위해 Tkinter 기반의 인터페이스를 통합하여 사용자에게 기능적이고 직관적인 제어 시스템을 제공합니다.

- **Performance Highlights**: 다양한 머신러닝 모델이 개발되었으며, 랜덤 포레스트(random forest) 모델은 79%의 정확도를 기록했습니다. 로지스틱 회귀(Logistic Regression) 모델은 92%의 정확도로 다른 모델들을 초과 성능을 보였고, 다층 퍼셉트론(Multi-Layer Perceptron, MLP) 모델은 91%의 정확도를 달성했습니다. 또한, Bi-LSTM 주의(attention) 기반 모델은 교차 검증을 통해 평균 86%의 정확도를 보여 BCI 애플리케이션에서의 주의 메커니즘의 잠재력을 입증하였습니다.



### SimBa: Simplicity Bias for Scaling Up Parameters in Deep Reinforcement Learning (https://arxiv.org/abs/2410.09754)
Comments:
          preprint

- **What's New**: 이번 논문에서는 deep reinforcement learning (deep RL)에서 네트워크 매개변수를 확장하기 위해 'simplicity bias'를 주입한 새로운 아키텍처인 SimBa를 소개합니다. 이는 깊은 RL 알고리즘의 샘플 효율성을 일관되게 향상시키는 것으로 입증되었습니다.

- **Technical Details**: SimBa는 세 가지 주요 구성 요소로 이루어져 있습니다: (i) 관측 정규화 레이어, (ii) 잔여 피드포워드 블록 (residual feedforward block), (iii) 출력 레이어 전의 레이어 정규화. 이러한 요소를 통해 SimBa는 매개변수 확장을 효과적으로 지원합니다.

- **Performance Highlights**: SimBa는 다양한 deep RL 알고리즘에서 일관되게 샘플 효율성을 향상시켰으며, Soft Actor-Critic (SAC)와 통합 시 DMC, MyoSuite 및 HumanoidBench에서 최신 deep RL 방법을 초월하는 성능을 달성했습니다.



### Surgical-LLaVA: Toward Surgical Scenario Understanding via Large Language and Vision Models (https://arxiv.org/abs/2410.09750)
Comments:
          NeurIPS 2024 AIM-FM Workshop

- **What's New**: 이 논문에서는 수술 상황을 위한 특별한 LVLM(large vision-language model)인 Surgical-LLaVA를 소개합니다. 이 모델은 수술 이미지와 비디오의 시각적 표현을 언어 특징 공간에 통합하여 수술 시나리오에 따라 조정된 모델을 만듭니다.

- **Technical Details**: Surgical-LLaVA는 수술관련 데이터에 대한 instruction following을 위해 GPT-3.5를 사용하여 다양한 수술 멀티모달 instruction-following 데이터를 생성한 후, 이러한 데이터로 시각-언어 모델을 미세 조정합니다. 이 모델은 수술 절차의 시공간적(spatiotemporal) 표현을 위해 사전 훈련된 시각 인코더와 LLM의 언어 이해 능력을 결합합니다.

- **Performance Highlights**: Surgical-LLaVA는 수술 관련 시나리오에서 멀티모달 채팅 능력을 능가하며, 이전 방법들과 비교해 보다 복잡한 수술 문제를 해결할 수 있는 잠재력을 보였습니다. 실험 결과, 수술 시나리오에서 시각적 질문-답변(dataset VQA) 데이터셋에 대한 성능이 뛰어난 것으로 나타났습니다.



### t-READi: Transformer-Powered Robust and Efficient Multimodal Inference for Autonomous Driving (https://arxiv.org/abs/2410.09747)
Comments:
          15 pages, 16 figures

- **What's New**: t-READi는 다양한 모달리티 센서의 변동성을 수용하여 자율 주행에 필요한 견고하고 효율적인 인식을 가능하게 하는 혁신적인 시스템입니다. 특히, 기존의 멀티모달(fusion) 알고리즘의 한계인 센서 오작동이나 환경 조건의 변화를 효과적으로 처리합니다.

- **Technical Details**: t-READi는 데이터 및 모달리티 변동을 처리하기 위한 변동 인식 모델 적응 알고리즘을 이용합니다. 이 시스템은 사전 학습된 모델에서 여러 가지 변형 모델을 생성하여 현재 입력에 따라 가장 적합한 모델을 선택할 수 있게 합니다. 또한, t-READi는 크로스 모달리티 대조 학습 방법을 사용하여 모달리티 손실에 따른 데이터 결손 문제를 보완합니다.

- **Performance Highlights**: t-READi는 기존 방식에 비해 평균 추론 정확도가 6% 이상 향상되었으며, 추론 지연(latency)을 거의 15배 감소시키는 성과를 보였습니다. 메모리 오버헤드는 최악의 경우에도 단지 5% 증가하여, 자율 주행 환경에서 실질적인 이점을 제공합니다.



### Gradient-Free Neural Network Training on the Edg (https://arxiv.org/abs/2410.09734)
- **What's New**: 본 논문에서는 Gradient Free Training (GFT)이라는 새로운 기법을 제안하여, 신경망을 훈련하는 수단으로 고정밀도 그래디언트를 필요로 하지 않으며, 이로 인해 에지 디바이스에서의 훈련이 가능하다는 특징을 강조합니다.

- **Technical Details**: 제안된 GFT 기법은 각 뉴런의 분류 기여도를 오류 기반으로 평가하고, 비트 전환을 위해 논리 연산을 활용하여 1비트 또는 2비트의 가중치를 가지고 훈련할 수 있게 합니다. 이 과정에서 고정밀도 그래디언트를 계산하는 대신 낮은 정밀도의 기여 텐서를 사용하여 메모리 사용량과 계산 비용을 줄입니다.

- **Performance Highlights**: 여러 표준 데이터셋에서 테스트한 결과, GFT 기법은 기존의 그래디언트 기반 방법과 유사한 성능을 보이며, 연산 요구량을 크게 줄여서 에너지 효율성을 높였습니다.



### MIRAGE: Multimodal Identification and Recognition of Annotations in Indian General Prescriptions (https://arxiv.org/abs/2410.09729)
Comments:
          8 pages, 11 figures, 2 tables

- **What's New**: 본 연구에서는 인도에서 수천 건의 손으로 쓴 처방전 생성 현실을 다루며, 기존의 기록 관리 방식을 개선하기 위해 Multimodal LLMs를 이용한 손글씨 인식(HWR)에 대한 새로운 접근법을 제안합니다. 본 연구는 743,118개의 완전 주석이 달린 고해상도医疗 기록 데이터를 사용하여, LLaVA 1.6 및 Idefics2 모델을 미세 조정하여 약물 이름과 용량을 추출하는 정확도를 82% 달성했습니다.

- **Technical Details**: 연구 방법론인 MIRAGE(멀티모달 주석 식별 및 인식)는 고해상도 의료 기록 데이터를 활용하여 Multimodal LLMs을 통해 약물 인식을 수행합니다. LLaVA는 OpenAI의 CLIP-ViT-Large-Patch14-336 시각 변환기를 통합하고, Idefics2는 SigLIP 비전 인코더를 사용하여 OCR(Optical Character Recognition) 과제를 수행합니다. Accuracy 측정은 AWP(예측 정밀도), AWI(이상 정밀도) 및 HIP(조화 평균)를 기준으로 진행되었습니다.

- **Performance Highlights**: 본 연구의 접근법은 기존 자동화 방법론을 초월하며, 의사들의 전문성과 시뮬레이션된 환자 정보의 포함이 인정 정확도 향상에 기여함을 입증하였습니다. 연구 결과는 손글씨가 포함된 의료 기록의 인식에서 상향 조정된 정확도를 나타내었으며, 다양한 처방전이 포함된 독특한 데이터세트를 기반으로 한 것이 특징입니다.



### A Tidal Current Speed Forecasting Model based on Multiple Periodicity Learning (https://arxiv.org/abs/2410.09718)
- **What's New**: 본 논문에서는 조수 에너지의 전력망 침투율을 높이는 데 중요한 조수 전류 속도 예측의 정확성을 향상시키는 새로운 방법론을 제안합니다. Wavelet-Enhanced Convolutional Network (WCN)을 통해 여러 주기성을 학습할 수 있는 방안을 소개합니다.

- **Technical Details**: 제안된 프레임워크는 1차원 조수 전류 데이터의 내부 주기(intra-period) 및 외부 주기(inter-period) 변화를 2차원 텐서의 행과 열에 삽입합니다. 이를 통해 두차원의 변화가 컨볼루션 커널(convolutional kernels)에 의해 처리될 수 있습니다. 또한, 시간-주파수(time-frequency) 분석 방법을 통합하여 지역적 주기성을 더욱 세밀하게 다룹니다. 하이퍼파라미터(hyperparameters)는 Tree-structured Parzen Estimator 알고리즘을 사용하여 최적화하였습니다.

- **Performance Highlights**: 제안된 WCN 프레임워크는 기준 모델에 비해 10단계 예측에서 평균 절대 오차(mean absolute error)와 평균 제곱 오차(mean square error)를 각각 최대 90.36%와 97.56% 감소시킨 것으로 나타났습니다.



### Agentic Information Retrieva (https://arxiv.org/abs/2410.09713)
Comments:
          11 pages, position paper

- **What's New**: 본 논문에서는 대규모 언어 모델(LLMs)이 정보 검색(Information Retrieval) 방식에 미친 영향을 분석하고, 유능한 LLM 에이전트의 기능을 바탕으로 하는 새로운 정보 검색 패러다임인 Agentic Information Retrieval (Agentic IR)를 소개합니다. 이는 전통적인 정보 검색 시스템의 한계를 극복하고, 보다 유연한 정보 접근 방식을 제시합니다.

- **Technical Details**: Agentic IR은 기존의 고정된 정보 검색 아키텍처 대신, 에이전트를 중심으로 한 통합 아키텍처를 도입합니다. 에이전트는 관찰(observation), 추론(reasoning), 행동(action)을 반복적으로 수행하여 사용자에게 최적의 정보를 제공하는 구조입니다. 이 과정에서 프롬프트 엔지니어링(prompt engineering), 검색 강화 생성(retrieval-augmented generation), 감독 및 강화 학습 기법을 포함한 다양한 방법이 사용됩니다.

- **Performance Highlights**: Agentic IR은 삶의 보조자(life assistant), 비즈니스 보조자(business assistant), 코드 보조자(coding assistant) 등 다양한 응용 분야에서 활용될 가능성이 큽니다. 이를 통해 미래의 디지털 생태계에서 중요한 정보 진입 점이 될 것으로 기대됩니다.



### Universal scaling laws in quantum-probabilistic machine learning by tensor network towards interpreting representation and generalization powers (https://arxiv.org/abs/2410.09703)
Comments:
          5 pages (main text) + 3 pages (appendices), 5 figures (main text) + 4 figures (appendices)

- **What's New**: 이번 연구는 양자-확률적 기계 학습(ML)에서의 보편적인 스케일링 법칙의 출현을 밝혀내는데 기여하였습니다. Generative Tensor Network (GTN)을 통해 무작위 텐서 네트워크 상태에서 부정 로그 가능도(NLL)가 피처 수에 비례하여 증가함을 보였습니다.

- **Technical Details**: GTN 모델은 훈련되지 않은 상태에서 NLL이 선형적으로 증가하며, 이는 '정칙성의 재앙(Catastrophe of Orthogonality)'의 결과입니다. 학습을 통해 정보를 취득하면서 NLL에서 부정적인 2차 보정이 나타나며, 이로 인해 NLL이 저하됩니다. 스케일링 계수는 훈련 샘플 수 및 양자 채널 수와 로그 관계를 나타냅니다.

- **Performance Highlights**: GTN의 일반화 및 표현력은 훈련 및 테스트 세트에서 NLL의 2차 보정 항의 출현으로 입증됩니다. 오버 파라미터화는 훈련 및 테스트 세트 간의 ⍺ 값의 차이를 통해 식별할 수 있습니다. 다양한 데이터셋에서 보편적인 스케일링 법칙이 강력하게 나타났습니다.



### Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG (https://arxiv.org/abs/2410.09699)
- **What's New**: 이 논문은 'Honest AI'라는 새로운 접근 방식을 제안하여 중소형 언어 모델이 잘못된 정보에 대한 환각을 줄이기 위해 "모르겠습니다"라고 대답하도록 세밀하게 조정합니다. 또한, 검색 엔진과 지식 그래프 결과를 활용한 여러 대체 RAG 접근법을 논의하며, 혼합 접근 방식으로 가장 높은 성능을 발휘한 것을 보여줍니다.

- **Technical Details**: 본 논문은 2024 Meta KDD Cup에서 Comprehensive RAG Benchmark(CRAG) 데이터를 사용하여 다양한 RAG 접근 방식을 시도했습니다. CRAG는 복잡도의 변화에 따라 영화나 스포츠와 같은 5개 질문 도메인을 포함하며, 잘못된 전제로 구성된 질문을 다뤘습니다. 원래 RAG 방식과 더불어 미세 조정(fine-tuning)과 두 접근 방식을 혼합한 방법을 통해 성능을 개선하고, 모델의 자원 효율성을 강조합니다.

- **Performance Highlights**: 이 연구팀은 Task 2의 잘못된 전제 질문에서 1위를 차지했으며, 모든 접근 방식이 LLM의 성능을 개선하는 것으로 나타났습니다. 전통적인 RAG만으로는 성능이 크게 향상되지 않았고, 혼합 접근 방식이 CRAG 벤치마크에서 가장 높은 점수를 기록했습니다.



### Can In-context Learning Really Generalize to Out-of-distribution Tasks? (https://arxiv.org/abs/2410.09695)
Comments:
          Preprint, under review

- **What's New**: 이 연구는 in-context learning (ICL)이 훈련 중에 접해지지 않은 out-of-distribution (OOD) 작업에서 어떤 메커니즘으로 작동하는지를 탐구합니다. GPT-2 모델을 사용하여 OOD 수학 함수에 대한 ICL의 성능을 실험적으로 수행하였고, ICL이 OOD 작업에서 어려움을 겪는다는 사실을 발견하였습니다. 또한, ICL의 추상 레이블 학습 능력의 한계도 밝혀냈습니다.

- **Technical Details**: 연구에서는 변환기(Transformers)가 훈련 시 접한 함수들에 의존하며, 기울기 하강법(gradient descent)과 같은 방법으로 OOD 작업을 해결하지 못하는 경향이 있음을 강조합니다. ICL이 OOD 작업에서 잘 작동하지 않는 경우, 주로 훈련 분포에서 크게 벗어난 작업에서 발생합니다. 또한, ICL의 낮은 테스트 오차 선호 현상(low-test-error preference)도 이론적으로 증명했습니다.

- **Performance Highlights**: 연구에 따르면, ICL은 훈련된 특정 함수 클래스에서 OOD 성능이 비슷한 함수 클래스에서 기울기 하강법으로 최적화된 모델의 성능에 접근하는 경향이 있습니다. 또한, Llama-2 및 GPT-4와 같은 실제 LLM이 OOD 작업을 푸는 데 실패하는 조건들도 살펴보았습니다. 이러한 결과들은 ICL의 새로운 작업 학습 능력에 대한 근본적인 논의를 촉발합니다.



### Neural Solver Selection for Combinatorial Optimization (https://arxiv.org/abs/2410.09693)
- **What's New**: 본 연구에서는 서로 다른 신경 솔버들을 효과적으로 조정하기 위한 첫 번째 일반 프레임워크를 제안합니다. 이 프레임워크는 각 문제 인스턴스에 가장 적합한 솔버를 할당하는 것을 목표로 하며, 문제 인스턴스의 특성을 위한 특징 추출과 적합한 모델의 선택 전략을 포함하고 있습니다.

- **Technical Details**: 제안된 프레임워크는 세 가지 주요 구성 요소로 이루어져 있습니다: 특징 추출(Feature extraction), 선택 모델(Selection model), 선택 전략(Selection strategy). 특징 추출에는 graph attention network를 사용하여 COP 인스턴스를 인코딩하고, 선택 모델은 분류 및 순위를 기반으로 훈련됩니다. 여러 선택 전략도 구현되었습니다.

- **Performance Highlights**: 제안한 프레임워크는 Traveling Salesman Problem (TSP)과 Capacitated Vehicle Routing Problem (CVRP)에서 평가되었으며, 기존 최고의 개별 신경 솔버에 비해 TSPLIB에서 최적성 간극(optimality gap)을 0.88%, CVRPLIB에서 0.71% 줄였습니다. 이 과정에서 소요되는 시간은 거의 추가되지 않았습니다.



### ALLoRA: Adaptive Learning Rate Mitigates LoRA Fatal Flaws (https://arxiv.org/abs/2410.09692)
- **What's New**: 본 논문은 Low-Rank Adaptation (LoRA)의 한계를 분석하고, Adaptive Learning Rate (ALLoRA)로 명명된 새로운 접근 방식을 제안합니다. ALLoRA는 Dropout과 scaling factor를 제거하고, 적응형 학습률을 도입하여 더 효율적인 fine-tuning을 가능하게 합니다.

- **Technical Details**: ALLoRA는 Low-Rank Adaptation의 세 가지 주요 한계를 해결합니다: (1) 짧은 학습 단계에서 Dropout의 효과가 감소하며, (2) B의 초기값이 0으로 설정되어 학습 동적이 느려지고, (3) scaling factor로 인해 서로 다른 레이어 간의 비선형 상호작용이 발생합니다. ALLoRA는 $	ext{per sample}$과 $	ext{per parameter}$ gradient를 $	ext{l2 norm}$에 반비례하여 조절합니다.

- **Performance Highlights**: ALLoRA는 다양한 세팅에서 LoRA보다 더 나은 정확도를 보여주며, 최신 LoRA 변형인 Weight-Decomposed Low-Rank Adaptation (DoRA)와 비교하여도 확실히 우수한 성능을 발휘합니다. 또한 ALLoRA는 두 개의 하이퍼파라미터를 제거하여 더 간단하게 구현할 수 있습니다.



### Robust 3D Point Clouds Classification based on Declarative Defenders (https://arxiv.org/abs/2410.09691)
- **What's New**: 이 논문에서는 3D 포인트 클라우드를 2D 이미지로 매핑하기 위한 세 가지 새로운 알고리즘을 제안하고, 기존 Lattice Point Classifier (LPC)를 확장하여 성능 및 방어 메커니즘을 평가합니다. 또한, 새로운 매핑 알고리즘을 통해 2D 이미지 간의 도메인 격차를 줄이기 위해 Generative 모델 기반의 접근 방식을 사용할 것입니다.

- **Technical Details**: 기존의 3D 포인트 클라우드 분류는 2D 이미지 분류와는 다른 방식으로 구현해야 합니다. 본 문서에서는 점 구름을 2D 이미지로 변환하기 위한 Direct projection, Graph drawing 등의 세 가지 알고리즘을 제안하고, 각 방법의 성능과 방어 능력을 실험적으로 분석합니다. 현재 대형 기초 모델을 활용하여 일반적인 2D 이미지와 투영된 2D 이미지 간의 특성 차이를 조사하고 있습니다.

- **Performance Highlights**: 제안된 방법들은 적대적 공격(adversarial attacks)에 대한 내구성이 뛰어나며, 최신 상태의 정확도를 달성합니다. GAN 기반의 분류기는 실제 2D 데이터셋과 비교했을 때 최소한의 도메인 간 차이를 보이는 것으로 나타났습니다. 이러한 학습된 분류기는 포인트 클라우드의 안전성 중요성을 고려하여 설계되었습니다.



### MoIN: Mixture of Introvert Experts to Upcycle an LLM (https://arxiv.org/abs/2410.09687)
- **What's New**: 이 논문은 대형 언어 모델(large language model)의 성능을 향상시키기 위한 새로운 접근 방식을 제안합니다. 기존 모델의 전체 재학습 없이, 의미적으로 관련된 그룹으로 데이터를 나누고 각 그룹에 특화된 "introvert" 전문가(expert)를 훈련시킵니다.

- **Technical Details**: 제안된 방법은 "introvert" 전문가를 활용하여, 각 쿼리(query)가 가장 관련성이 높은 전문가에게 라우팅되는 방식으로 동작합니다. 이 방식은 전문가들 간의 의사소통을 최소화하면서도 병렬화를 극대화할 수 있도록 합니다. 기본 모델은 고정(frozen)되어 있으며, 추가된 LoRA 어댑터(adaptor)가 훈련됩니다.

- **Performance Highlights**: 이 접근 방식은 훈련 시간을 크게 단축시키며, 많은 수의 전문가가 필요할 경우에도 GPU 메모리 요구사항을 줄여 줍니다. 실험 결과 제안된 모델이 기존 모델과 비교했을 때 유사한 perplexity를 보여주었으며, 이는 500B 이상의 토큰으로 훈련된 모델과 동등한 성능임을 시사합니다.



