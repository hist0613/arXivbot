New uploads on arXiv(cs.CL)

### LML: Language Model Learning a Dataset for Data-Augmented Prediction (https://arxiv.org/abs/2409.18957)
Comments:
          First version

- **What's New**: 이 논문은 대규모 언어 모델(LLMs)을 분류 작업에 활용하기 위한 새로운 접근 방식을 소개합니다. 전통적인 머신 러닝(ML) 모델들과는 달리, LLMs를 사용하여 데이터 정리(data cleaning)와 특징 공학(feature engineering)을 간소화합니다.

- **Technical Details**: 이 논문은 'Language Model Learning (LML)'이라는 새로운 개념과 'Data-Augmented Prediction (DAP)'이라는 새로운 방법을 제안합니다. LLM이 데이터를 탐색하고 이해하며 분류를 결정하는 방식으로 분류를 수행합니다. DAP 과정에서는 데이터 요약을 사용하여 자동으로 쿼리를 생성하고, 이를 통해 관련 데이터 행을 검색한 후, 최종적인 분류 결과를 생성합니다.

- **Performance Highlights**: 테스트 사례에서 시스템의 정확도가 90%를 초과하여 기존 ML 모델을 다양한 시나리오에서 초월할 가능성을 입증하였습니다. 사용자가 예측의 논리를 검토할 수 있도록 'Explainable Machine Learning Model'로 행위하는 문구를 프롬프트에 포함시킴으로써 예측의 해석 가능성을 향상시켰습니다.



### Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models (https://arxiv.org/abs/2409.18943)
- **What's New**: 이 논문에서는 대형 언어 모델의 응답 길이를 제어하는 능력을 살펴보기 위해 Target Length Generation Task (TLG)를 제안합니다. 이를 통해 모델이 사용자의 요구에 맞게 특정 길이의 응답을 생성하는 데 어려움을 겪는 문제를 해결하고자 합니다.

- **Technical Details**: 연구진은 정확한 응답 길이를 평가하기 위해 두 가지 메트릭을 설계했습니다: Precise Match (PM)와 Flexible Match (FM). 또한, Ruler라는 새로운 모델 비종속적 접근 방식을 도입하여 Meta Length Tokens (MLTs)를 사용해 대형 언어 모델이 길이 제한이 있는 지침을 따를 수 있도록 개선합니다.

- **Performance Highlights**: Ruler는 다양한 대형 언어 모델에서 Target Length Generation Task를 수행할 때 평균 27.97의 PM 개선과 29.57의 FM 개선을 보여주며, Ruler의 효율성과 일반화 능력을 입증하기 위한 광범위한 실험 결과를 포함합니다.



### AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow (https://arxiv.org/abs/2409.18924)
Comments:
          42 pages, 6 figures, 7 tables

- **What's New**: AIPatient, an advanced simulated patient system, leverages Large Language Models (LLM) and integrates a Knowledge Graph (KG) from Electronic Health Records (EHRs) to enhance clinical decision-making simulations in medical education.

- **Technical Details**: AIPatient utilizes the AIPatient Knowledge Graph (AIPatient KG) sourced from the MIMIC-III database, creating a diverse cohort of 1,495 clinically relevant patients. It employs the Reasoning Retrieval-Augmented Generation (Reasoning RAG) framework, which involves six LLM-powered agents for tasks such as retrieval, KG query generation, and summarization.

- **Performance Highlights**: The AIPatient system achieved an accuracy of 94.15% in EHR-based medical Question Answering (QA) and demonstrated high readability and robustness, making it suitable for diverse applications in medical education and system integration.



### Soft Measures for Extracting Causal Collective Intelligenc (https://arxiv.org/abs/2409.18911)
Comments:
          Camera-ready version accepted for publication in the EMNLP 2024 Workshop NLP4Science

- **What's New**: 이 연구는 복잡한 사회 시스템을 설명하기 위해 집합적 지능(collective intelligence)을 이해하고 모델링하는 중요성을 강조하며, 대규모 언어 모델(large language models, LLMs)을 이용하여 퍼지 인지 맵(fuzzy cognitive maps, FCMs) 추출을 자동화하는 방법을 제안합니다.

- **Technical Details**: 연구에서는 새로운 그래프 기반 유사도 측정(graph-based similarity measures)을 도입하고, 이를 인간 평가와 비교하기 위해 Elo 등급 시스템(Elo rating system)을 적용합니다. FCM의 미세한 뉘앙스(capture nuances)를 포착하는 데 한계가 있다는 것이 강조되며, LLM을 미세 조정(fine-tuning)함으로써 성능을 향상시킬 수 있지만, 기존 측정 방식은 여전히 부족합니다.

- **Performance Highlights**: 결과는 인간 평가와 긍정적인 상관관계를 보이며, 하지만 가장 성능이 좋은 측정 방법조차 FCM의 복잡성을 완전히 포착하지 못하는 한계를 보입니다. 이 연구는 FCM 추출을 위한 부드러운 유사도 측정(soft similarity measures)의 필요성을 강조하며, 자연어 처리(NLP)와 함께 집합적 지능 모델링을 발전시킵니다.



### IDGen: Item Discrimination Induced Prompt Generation for LLM Evaluation (https://arxiv.org/abs/2409.18892)
Comments:
          NeurIPS 2024

- **What's New**: 이 논문은 대형 언어 모델(Large Language Models, LLMs)의 평가를 위한 Item Discrimination (ID) 이론에서 영감을 받은 새로운 프롬프트 합성 프레임워크를 제안합니다.

- **Technical Details**: 제안된 프레임워크는 모델의 능력에 따라 평가 세트를 지속적으로 업데이트하고 정제할 수 있도록 하는 것을 목표로 합니다. 이 프레임워크는 폭과 세부성을 모두 우선시하여, LLMs의 능력을 포괄적으로 평가할 수 있는 프롬프트를 생성합니다. 또한, 프롬프트의 분별력(prompt discrimination)과 난이도 점수를 예측하기 위한 두 가지 모델을 개발하여 데이터 합성을 지원합니다.

- **Performance Highlights**: 생성된 데이터는 다섯 개의 최신 모델(SOTA models)에 대한 평가에 적용되었으며, 평균 점수는 51.92로, 분산은 10.06을 기록하였습니다. 이전 작업(SELF-INSTRUCT 및 WizardLM)이 67점을 초과하며 3.2 이하의 분산을 기록한 것과 비교할 때, 본 프레임워크에서 생성한 데이터는 더 도전적이며 분별력이 뛰어난 것으로 나타났습니다. 3,000개 이상의 정교하게 제작된 프롬프트 데이터를 공개할 예정입니다.



### Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models (https://arxiv.org/abs/2409.18878)
Comments:
          submitted to AMIA Informatics Summit 2025 as a conference paper

- **What's New**: 이번 연구는 정신과 고위험 환경에서 자살 사건을 정확하게 식별하고 분류하여, 자살 예방 조치를 개선하고 운영 부담을 감소시키며 치료 품질을 향상시키는 방법을 제시합니다.

- **Technical Details**: 해당 연구에서는 두 가지 미세 조정 전략(단일 라벨 다수 및 단일 다중 라벨)을 사용하여 500개의 주석이 달린 정신과 평가 노트를 기반으로 네 가지 BERT(Bidirectional Encoder Representations from Transformers) 모델의 성능을 평가하였습니다. 노트는 자살적 사고(SI), 자살 시도(SA), 자살 노출(ES), 비자살적 자기 상해(NSSI)로 라벨링되었습니다.

- **Performance Highlights**: RoBERTa 모델이 binary relevance(이진 관련성) 방법을 사용하여 다른 모델보다 뛰어난 성능을 발휘하여 accuracy(정확도)가 0.86, F1 score가 0.78로 나타났습니다. MentalBERT는 F1 score가 0.74로 BioClinicalBERT의 0.72를 초과하였으며, 단일 다중 라벨 분류기로 미세 조정된 RoBERTa는 0.88의 정확도와 0.81의 F1 score로 성능이 더욱 향상되었습니다.



### Individuation in Neural Models with and without Visual Grounding (https://arxiv.org/abs/2409.18868)
- **What's New**: 이 논문에서는 CLIP 모델과 FastText, SBERT와 같은 텍스트 전용 모델 간의 individuating (개별화) 정보 인코딩의 차이를 보여줍니다.

- **Technical Details**: CLIP 모델이 제공하는 latent representations (잠재 표현)을 연구하며, 기초(substrates), 미세한 집합(granular aggregates), 다양한 수의 객체에 대한 정보를 분석합니다.

- **Performance Highlights**: CLIP 임베딩은 텍스트 전용 데이터로 훈련된 모델들보다 individuating (개별화)에서 정량적 차이를 더 잘 포착하며, 이로부터 도출한 individuating hierarchy (개별화 계층)는 언어학 및 인지 과학에서 제안된 계층과 일치합니다.



### Local Transcription Models in Home Care Nursing in Switzerland: an Interdisciplinary Case Study (https://arxiv.org/abs/2409.18819)
- **What's New**: 최근 자연어 처리(NLP) 분야에서의 발전은 의료 분야를 포함한 다양한 도메인에서 새로운 사용 사례를 가능하게 하고 있습니다. 특히, 전사는 간호 문서화 과정의 자동화를 지원하여 간호사들이 환자와의 상호작용에 더 많은 시간을 할애할 수 있도록 돕습니다.

- **Technical Details**: 이 case study에서는 스위스의 홈 케어 간호 문서화 사례를 조사하였습니다. 우리는 다양한 전사 도구와 모델을 평가하고, OpenAI Whisper를 사용하여 여러 가지 독일어 변형(예: 방언, 외국어 억양) 및 홈 케어 간호 분야 전문가가 수동으로 정리한 예제 텍스트로 실험을 진행했습니다.

- **Performance Highlights**: 우리가 사용한 기본 모델조차도 향후 연구를 위한 좋은 출발점이 될 만큼 충분한 성능을 발휘했습니다.



### LLMs4Synthesis: Leveraging Large Language Models for Scientific Synthesis (https://arxiv.org/abs/2409.18812)
Comments:
          12 pages, 3 figures, Accepted to JCDL 2024 Research Track

- **What's New**: 이 논문은 과학 문헌의 복잡성과 양의 증가에 대응하기 위해 LLMs4Synthesis 프레임워크를 소개합니다. 이 프레임워크는 Large Language Models (LLMs)의 능력을 향상시키기 위해 설계되었습니다.

- **Technical Details**: LLMs4Synthesis 프레임워크는 개방형(open-source) 및 독점적(propriety) LLM을 활용하여 과학적 통합을 신속하고 일관되며 맥락이 풍부하게 수행하는 데 초점을 맞춥니다. 새로운 문서 처리 방법론을 개발하고, 새로운 통합 종류를 정의하며, 통합 평가를 위한 아홉 가지 품질 기준을 설정합니다.

- **Performance Highlights**: LLMs의 통합 강화를 위한 강화 학습(reinforcement learning) 및 AI 피드백을 제안하여 통합 품질을 최적화하고, 정립된 기준에 부합하도록 보장합니다. LLMs4Synthesis 프레임워크와 그 구성 요소는 과학 연구의 통합 생성 및 평가 프로세스를 향상시킬 것으로 기대됩니다.



### A Survey on the Honesty of Large Language Models (https://arxiv.org/abs/2409.18786)
Comments:
          Project Page: this https URL

- **What's New**: 이번 논문은 대형 언어 모델(LLMs)의 정직성(Honesty) 문제를 다루고 있습니다. 현재의 LLMs가 보이는 정직하지 않은 행동을 분석하고, 이와 관련된 다양한 정의와 평가 방법을 제시합니다.

- **Technical Details**: 정직성에 대한 정의가 다양하고, LLMs의 알고 있는 것과 모르는 것을 구분하는 데 어려움이 있으며, 이에 대한 종합적인 이해가 부족한 상황에서, 이 논문은 LLMs의 정직성을 평가하기 위해 여러 접근 방식을 탐색합니다.

- **Performance Highlights**: 논문은 LLMs의 정직성을 향상시키는 전략과 미래 연구 방향에 대한 통찰을 제공하여, 이 중요한 분야에서의 추가 탐색을 촉진하고자 합니다.



### Read Over the Lines: Attacking LLMs and Toxicity Detection Systems with ASCII Art to Mask Profanity (https://arxiv.org/abs/2409.18708)
- **What's New**: 본 논문에서는 언어 모델이 ASCII 아트를 해석하지 못하는 것을 이용한 새로운 형태의 adversarial attacks를 소개합니다. 이러한 공격을 평가하기 위한 ToxASCII benchmark를 제안합니다.

- **Technical Details**: 연구에서는 두 개의 맞춤형 ASCII 아트 폰트를 개발하였으며, 하나는 special tokens를 활용하고 다른 하나는 텍스트로 채워진 문자 형태를 사용합니다. 이 공격들은 OpenAI의 o1-preview 및 LLaMA 3.1 포함 총 10개의 모델에서 1.0의 공격 성공률(Attack Success Rate)을 기록하였습니다.

- **Performance Highlights**: 이 논문은 연구 목적으로 사용된 유해한 언어의 예를 포함하고 있기 때문에 주의가 필요합니다.



### "Why" Has the Least Side Effect on Model Editing (https://arxiv.org/abs/2409.18679)
- **What's New**: 대형 언어 모델(LLM) 훈련 시의 비용 문제와 최신 연구 조명. 모델 편집(model editing)의 중요성 부각.

- **Technical Details**: 이 논문에서는 모델 편집 질문을 유형별로 분류하여 성능 저하의 정도가 질문 유형에 따라 어떻게 달라지는지를 조사하였습니다. 또한, 작은 모델의 통찰력이 큰 모델에 적용될 수 있는지를 평가하였습니다.

- **Performance Highlights**: 성능 저하의 차이와 배치 크기(batch size)가 성능 유지에 미치는 영향 발견. 배치 크기를 늘리는 것이 성능 저하를 완화시킬 수 있다는 결과 도출.



### Rehearsing Answers to Probable Questions with Perspective-Taking (https://arxiv.org/abs/2409.18678)
- **What's New**: 이 논문은 전문적인 구술 발표 중에 발생할 수 있는 질문에 대한 준비에 초점을 맞춘 새로운 QA(Question Answering) 연구를 제시합니다. 기존의 NLP(자연어 처리)가 독해력 및 일반 상식 QA에 중점을 두었던 것과는 다른 방향입니다.

- **Technical Details**: 연구에서는 기업 관리자와 전문 분석가 간의 실제 QA 대화 기록을 사용하여 세 가지 인과 지식 그래프(causal knowledge graphs, KGs)와 세 가지 대형 언어 모델(large language models, LLMs)을 활용하여 제안된 작업을 탐구합니다. 이는 LLMs의 전문적인 QA 시나리오에서의 응용 가능성에 대한 기초적인 통찰을 제공합니다.

- **Performance Highlights**: 이 연구는 응답을 효과적으로 생성하는 데 있어 인과 KGs와 관점 차용(perspective-taking)의 중요성을 강조하며, 전문적인 QA 환경에서 LLMs의 활용 가능성을 탐색합니다.



### Co-Trained Retriever-Generator Framework for Question Generation in Earnings Calls (https://arxiv.org/abs/2409.18677)
- **What's New**: 이 논문은 earnings call (실적 발표) 컨텍스트를 위한 multi-question generation (MQG) 작업을 최조로 제안하고 있으며, 이를 통해 전통적인 방법의 한계를 극복하려고 합니다.

- **Technical Details**: 이 연구에서는 earnings call 전사( transcripts) 수집과 잠재적인 질문을 분류하기 위한 혁신적인 주석(annotation) 기법을 사용합니다. 추가로, 관련 정보를 추출하기 위한 retriever-enhanced 전략을 도입하였습니다.

- **Performance Highlights**: 경험적 평가 결과, 제안된 방법이 생성한 질문의 정확성(accuracy), 일관성(consistency), 및 perplexity에서 두드러진 우수성을 보였습니다.



### HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents (https://arxiv.org/abs/2409.18647)
Comments:
          Accepted to EMNLP 2024 Findings

- **What's New**: 이번 연구에서는 법률 문서의 수사적 역할 레이블링(Rhetorical Role Labeling, RRL)을 위한 계층적 커리큘럼 학습 프레임워크인 HiCuLR을 제안합니다. 이는 RRL을 수행하는 데 있어 문서의 난이도에 따라 모델을 점차적으로 학습시킬 수 있도록 설계되었습니다.

- **Technical Details**: HiCuLR은 외부에서 수사적 역할 수준 커리큘럼(Rhetorical Role-level Curriculum, RC)과 내부에서 문서 수준 커리큘럼(Document-level Curriculum, DC)으로 구성된 두 개의 커리큘럼을 포함합니다. DC는 문서를 난이도에 따라 분류하고, RC는 모델이 수사적 역할의 구분을 점진적으로 강화하도록 합니다.

- **Performance Highlights**: 네 가지 RRL 데이터셋에 대한 실험 결과, HiCuLR의 효과성을 입증하였으며, DC와 RC의 보완적인 특성이 두드러졌습니다.



### The Craft of Selective Prediction: Towards Reliable Case Outcome Classification -- An Empirical Study on European Court of Human Rights Cases (https://arxiv.org/abs/2409.18645)
Comments:
          Accepted to EMNLP Findings

- **What's New**: 이 논문은 법률 자연어 처리(NLP) 분야에서 케이스 결과 분류(Case Outcome Classification, COC) 모델의 신뢰성을 높이기 위한 선택적 예측(selective prediction) 프레임워크 내에서 다양한 디자인 선택이 미치는 영향을 실증적으로 조사합니다.

- **Technical Details**: 연구에서는 사전 학습 데이터(corpus), 신뢰도 추정기(confidence estimator), 미세 조정 손실(fine-tuning loss)과 같은 설계 선택이 COC 모델의 신뢰성에 미치는 영향을 분석하였습니다. 특히, 다양한 도메인 전문 사전 학습 데이터의 중요성을 강조하였으며, 더 큰 모델이 과도한 신뢰(overconfidence)를 보이는 경향이 있다는 점도 지적합니다.

- **Performance Highlights**: 실험 결과, 몬테 카를로 드롭아웃(Monte Carlo dropout) 방법이 신뢰도 추정에서 효과적이며, 신뢰도 기반의 오류 정규화(confident error regularization)가 과신(overconfidence)을 완화하는 데 기여함을 보여주었습니다. 이 연구는 법률 NLP에서 선택적 예측에 대한 최초의 체계적인 탐색으로, 법률 분야에서 모델의 신뢰성을 높이기 위한 연구의 필요성을 강조합니다.



### Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases (https://arxiv.org/abs/2409.18644)
Comments:
          Accepted to EMNLP Findings

- **What's New**: 본 논문에서는 stare decisis 법 이론에 착안하여 법원 판례를 효과적으로 통합하는 방법을 제안합니다.

- **Technical Details**: 법률 문서 처리(LJP) 모델과 함께 판례 검색(retriever) 모델을 결합하기 위해 정밀한 관련성 신호를 바탕으로 훈련합니다. 판례 통합 전략으로는 케이스 간 유사성에 기반한 label interpolation을 통한 직접 통합과 stacked-cross attention 모델을 이용한 판례 융합 모듈을 통한 훈련 중 통합 방법을 제안합니다. 이 과정에서 retriever와 LJP 모델의 공동 훈련(joint training)을 통해 잠재 공간(divergence) 문제를 해결합니다.

- **Performance Highlights**: ECHR 사법 관할권의 LJP 작업에서 실험한 결과, 훈련 중 판례 통합과 retriever 및 LJP 모델의 공동 훈련이 없는 모델이나 판례를 단지 추론(inference) 단계에서 통합한 모델보다 성능이 뛰어난 것으로 나타났습니다. 특히, 희소한 기사(sparser articles)에 보다 큰 이점을 보였습니다.



### Model-based Preference Optimization in Abstractive Summarization without Human Feedback (https://arxiv.org/abs/2409.18618)
Comments:
          Accepted by EMNLP 2024

- **What's New**: 본 연구에서는 인간 피드백 없이 모델의 요약 능력을 향상시키기 위한 새로운 접근 방식인 Model-based Preference Optimization (MPO)을 소개합니다.

- **Technical Details**: MPO는 다양한 decoding strategies를 활용하여 모델이 생성한 preference dataset을 기반으로 LLMs를 미세 조정합니다. 기존의 Direct Preference Optimization (DPO) 방식과는 달리, MPO는 비싼 인간 피드백에 의존하지 않습니다.

- **Performance Highlights**: MPO를 적용한 결과, 표준 요약 데이터셋에서 생성된 요약의 품질이 크게 향상되었습니다. 다양한 평가 지표에서 성능 개선이 나타났습니다.



### Do LLMs suffer from Multi-Party Hangover? A Diagnostic Approach to Addressee Recognition and Response Selection in Conversations (https://arxiv.org/abs/2409.18602)
Comments:
          Accepted to EMNLP 2024 main conference

- **What's New**: 본 연구는 Multi-Party Conversations (MPC)의 분류 성능을 평가하기 위한 새로운 방법론을 제안합니다. 기계 학습 모델의 성능을 특정 구조적 특성에 맞추어 조사함으로써, 전통적인 평가 방법이 간과해 온 구조적 복잡성에 따른 모델 행동의 변화를 검토합니다.

- **Technical Details**: 연구는 Response Selection과 Addressee Recognition 작업을 중심으로 진행하며, 온라인 MPC의 대규모 오픈 코퍼스에서 고정된 사용자 수와 다양한 구조적 특성을 가진 진단 서브데이터셋을 추출합니다. 또한, 개인 정보 보호를 고려하여 원본 사용자명을 사용하지 않고, 원본 텍스트 메시지 대신 대안을 제시합니다.

- **Performance Highlights**: 결과에 따르면 Response Selection은 대화 내용의 텍스트에 더 의존하는 반면, Addressee Recognition은 대화의 구조적 차원을 포착해야 함을 보여줍니다. 대규모 언어 모델(LLM)을 zero-shot 설정에서 사용하여 프롬프트 변형에 대한 민감도가 작업 의존적이라는 점을 강조합니다.



### Hit the Sweet Spot! Span-Level Ensemble for Large Language Models (https://arxiv.org/abs/2409.18583)
- **What's New**: 이 논문에서는 다양한 대규모 언어 모델(LLMs)을 조합하여 서로의 장점을 극대화하는 새로운 접근법인 SweetSpan을 제안합니다. SweetSpan은 기존의 샘플 레벨(sample-level) 및 토큰 레벨(token-level) 앙상블 방법의 한계를 극복합니다.

- **Technical Details**: SweetSpan은 후보 모델들이 공유된 접두사(prefix)를 기반으로 후보 span을 독립적으로 생성합니다. 이후에는 퍼플렉시티(perplexity) 점수를 계산하여 후보 모델 간의 상호 평가를 통해 신뢰할 수 없는 점수를 필터링하고 강력한 span 선택을 이끌어냅니다. 이를 통해 실시간 조정과 정확한 앙상블 결정을 위한 정보 간의 균형을 잘 맞춥니다.

- **Performance Highlights**: 기존의 앙상블 방법들과 비교할 때, 표준 설정 및 성능 차이가 큰 모델을 포함한 도전적 설정에서 실험 결과 SweetSpan의 효과성과 강력함, 다재다능함이 입증되었습니다.



### Research on Predicting Public Opinion Event Heat Levels Based on Large Language Models (https://arxiv.org/abs/2409.18548)
Comments:
          conference

- **What's New**: 최근 몇 년간 큰 언어 모델(large language models)의 급속한 발전으로 인해, GPT-4o와 같은 여러 모델이 언어 작업에서 인간의 성능을 초월하는 탁월한 능력을 보여주었습니다. 이 연구는 공공 여론 분석 분야에서의 잠재적 응용을 탐구합니다.

- **Technical Details**: 이 연구에서는 2022년 7월부터 2023년 12월 사이에 수집된 62,836개의 중국 핫 이벤트 데이터를 전처리하고 분류했습니다. 각 이벤트의 온라인 확산 열 지수를 기반으로 MiniBatchKMeans 알고리즘을 사용하여 이벤트를 자동으로 클러스터링하고 네 가지 열 수준으로 분류했습니다. 이후 각 열 수준에서 250개의 이벤트를 랜덤으로 선택하여 총 1,000개의 평가 데이터셋을 구축했습니다.

- **Performance Highlights**: 평가 과정에서 다양한 큰 언어 모델을 사용하여 두 가지 시나리오(참조 사례 없는 경우와 유사한 사례 참조가 있는 경우)에서 이벤트 열 수준 예측의 정확성을 평가했습니다. 결과적으로 GPT-4o와 DeepseekV2가 후자의 경우 최고의 성능을 보이며 각각 41.4%와 41.5%의 예측 정확도를 기록했습니다. 특히 저온 이벤트(Level 1)의 경우 두 모델의 예측 정확도는 각각 73.6%와 70.4%에 달했습니다. 전체적인 예측 정확도는 열 수준이 높아질수록 감소하는 경향을 보였습니다.



### A Survey on Complex Tasks for Goal-Directed Interactive Agents (https://arxiv.org/abs/2409.18538)
- **What's New**: 최근 대규모 언어 모델(large language models, LLMs)의 발전으로 목표 지향적 상호 작용 에이전트(goal-directed interactive agents)가 다양하고 도전적인 작업을 통해 인간의 일상 생활을 지원할 수 있는 가능성이 열렸습니다. 본 서베이는 이러한 에이전트 평가에 필요한 관련 작업과 환경을 정리하였습니다.

- **Technical Details**: 연구에서는 목표 지향적 상호 작용 에이전트를 평가하기 위해 다양한 과제(task)와 환경(environment)을 수집하고, 현재 에이전트가 직면하는 장애물(obstacles)을 이해하는 데 도움이 되는 차원으로 구조화하였습니다. 이를 통해 에이전트 성능(performance)을 잘 맥락화(contextualize)할 수 있습니다.

- **Performance Highlights**: 본 연구는 Agent의 평가를 위한 최신 자원(resource)을 집약하여, 향후 연구에서 참조할 수 있는 유용한 자료를 제공합니다.



### Do We Need Domain-Specific Embedding Models? An Empirical Investigation (https://arxiv.org/abs/2409.18511)
Comments:
this https URL

- **What's New**: 이 논문에서는 금융 분야에 특화된 Embedding 모델의 필요성을 살펴보며, 새로운 금융 Massive Text Embedding Benchmark (FinMTEB)를 도입하였습니다.

- **Technical Details**: FinMTEB는 금융 분야에 특화된 데이터셋으로 구성되어 있으며, 최신 Embedding 모델 7개의 성능을 평가하였습니다. 데이터셋의 복잡도를 측정하고 분석하여 FinMTEB에서의 성능 저하가 모델의 한계를 나타내는지 검증했습니다.

- **Performance Highlights**: 일반 목적의 MTEB와 비교했을 때, FinMTEB에서 최신 모델들의 성능이 현저히 저하된 것을 관찰하였으며, 이는 금융 분야에 특화된 언어적 및 의미적 패턴을 포착하는 데 어려움을 겪고 있음을 보여줍니다.



### Evaluation of OpenAI o1: Opportunities and Challenges of AGI (https://arxiv.org/abs/2409.18486)
- **What's New**: OpenAI의 o1-preview 대형 언어 모델은 다양한 복잡한 Reasoning 작업에서 인간 수준의 성과를 자주 보여주며, 고급 프로그래밍 문제, 생물학적 추론, 언어 처리 등의 여러 분야에서 두각을 나타냈습니다.

- **Technical Details**: o1-preview는 컴퓨터 과학, 수학, 자연 과학, 의학, 언어학 및 사회 과학 등을 포함한  다수의 분야에서 83.3%의 성공률을 기록하며 복잡한 프로그래밍 문제를 해결했습니다. 특히, 고등학교 수준의 수학 문제에서 100%의 정확도로 단계별 솔루션을 제공하는 등 우수한 성능을 보였습니다. 의료 분야에서는 자연어 추론(Natural Language Inference) 능력이 뛰어나고, EDA 스크립트를 생성하는 등 반도체 설계 과제에서 전문 모델을 초월하는 성과를 얻었습니다.

- **Performance Highlights**: 이 모델은 인류학 및 지질학에서 깊이 있는 이해와 Reasoning 능력을 보여주었으며, 정량적 투자에도 강력한 능력을 가지고 있습니다. 소셜 미디어 분석에서도 효과적인 성과를 거두었고, 정교한 Reasoning과 지식 통합이 필요한 작업에서 특히 뛰어난 결과를 기록했습니다. 그러나 일부 간단한 문제에서 오류가 발생할 수 있고 특정 전문 개념에 대한 도전이 관찰되는 등 일부 제한 사항도 있었습니다.



### URIEL+: Enhancing Linguistic Inclusion and Usability in a Typological and Multilingual Knowledge Bas (https://arxiv.org/abs/2409.18472)
- **What's New**: URIEL+는 URIEL의 한계를 극복하여 2898개의 언어에 대한 typological (유형론적) 특성 범위를 확장하고 사용자 경험을 개선합니다.

- **Technical Details**: URIEL은 7970개 언어에 대한 지리적, 계통적 (phylogenetic), 유형론적 벡터 표현을 제공하며, 4005개 언어의 벡터 간 거리 측정을 포함합니다. URIEL+는 강력하고 사용자 맞춤형 거리 계산을 제공하여 사용자의 요구에 더 잘 맞추도록 개선되었습니다.

- **Performance Highlights**: 업그레이드된 URIEL+는 하위 작업 (downstream tasks)에서 경쟁력 있는 성능을 제공하며, 언어적 거리 연구에 더 잘 맞는 거리를 제공합니다.



### Leveraging Long-Context Large Language Models for Multi-Document Understanding and Summarization in Enterprise Applications (https://arxiv.org/abs/2409.18454)
- **What's New**: 이 논문은 다양한 분야에서 비구조화 데이터의 급증에 따른 다중 문서 이해 및 요약의 중요성을 강조합니다. 전통적인 접근 방식이 정보의 맥락을 잘 잡지 못하고 논리적 일관성을 유지하지 못하는 문제를 다루며, Long-context Large Language Models (LLMs)의 사용을 탐구합니다.

- **Technical Details**: 본 연구는 다중 문서 요약을 효과적으로 수행하기 위한 Long-context LLM의 워크플로우를 설명하며, 법률, 인사(HR), 재무, 소싱과 같은 기업 기능, 의료 및 뉴스 도메인에서의 사례 연구를 다룹니다. 이러한 사례 연구는 효율성과 정확성 모두에서 향상을 보여줍니다.

- **Performance Highlights**: 논문은 데이터셋의 다양성, 모델 확장성 및 편향 완화, 사실 정확성과 같은 윤리적 고려사항과 같은 기술적 장애물에 대한 철저한 분석을 포함하고 있으며, LLM의 기능과 응용 프로그램을 증강하기 위한 미래 연구 방향을 제시합니다.



### Exploring Language Model Generalization in Low-Resource Extractive QA (https://arxiv.org/abs/2409.18446)
- **What's New**: 이 논문에서는 대형 언어 모델(LLMs)이 폐쇄 도메인(closed-domain)에서 특정 지식이 필요한 질문-응답(extractive question answering, EQA) 작업에 대해 제로샷(zero-shot) 방식으로 잘 일반화할 수 있는지를 조사합니다.

- **Technical Details**: 우리는 여러 실험을 통해 LLM의 성능 차이를 설명합니다. 주요 발견 사항으로는: a) LLM은 폐쇄 도메인에서 긴 응답 범위를 검색하는 데 어려움을 겪습니다; b) 특정 LLM은 전반적으로 강력한 성능을 보이지만, 도메인 특정 단어의 의미 구분 같은 기본 요구 사항을 충족하는 데 약점을 보입니다; c) 모델 파라미터를 확장하는 것이 항상 교차 도메인 일반화(cross-domain generalization)에 효과적이지는 않습니다; d) 폐쇄 도메인 데이터셋은 개방형(open-domain) EQA 데이터셋과 quantitatively (정량적으로) 크게 다릅니다.

- **Performance Highlights**: LLM은 폐쇄 도메인에서 발생하는 데이터셋의 요구에 맞추는 데 어려움을 겪고 있으며, 이는 LLM의 개선 방향을 제시하는 중요한 요소입니다.



### Improving Multilingual ASR in the Wild Using Simple N-best Re-ranking (https://arxiv.org/abs/2409.18428)
- **What's New**: 이 논문에서는 다국어 자동 음성 인식(Multilingual Automatic Speech Recognition, ASR) 모델의 평가 방법을 개선하기 위한 간단하면서도 효과적인 N-best 재정렬(N-best re-ranking) 접근법을 소개합니다.

- **Technical Details**: 본 연구는 언어 모델(language models)과 텍스트 기반 언어 식별 모델(text-based language identification models)과 같은 외부 특성을 활용하여 여러 저명한 음향 모델(acoustic models)의 다국어 ASR 정확도를 향상시키는 방법을 제시합니다.

- **Performance Highlights**: FLEURS 벤치마크에서 MMS 및 Whisper 모델을 사용한 결과, 음성 언어 식별(spoken language identification) 정확도가 각각 8.7% 및 6.1% 향상되었으며, 단어 오류율(word error rates)은 각각 3.3% 및 2.0% 낮아졌습니다.



### SciDFM: A Large Language Model with Mixture-of-Experts for Scienc (https://arxiv.org/abs/2409.18412)
Comments:
          12 pages, 1 figure, 9 tables. Technical Report, Under Review

- **What's New**: 최근 대형 언어 모델(LLMs)을 활용하여 과학적 발견을 도우려는 관심이 급증하고 있습니다. 그러나 대부분의 LLM은 일반 과학에만 초점을 맞추고 있을 뿐, 화학 분자와 아미노산 서열과 같은 분야별 지식이 부족합니다. 이를 해결하기 위해 SciDFM이라는 전문가 혼합 모델을 도입하였으며, 이는 처음부터 훈련되어 대학 수준의 과학적 추론을 수행하고 분자 및 아미노산 서열을 이해할 수 있습니다.

- **Technical Details**: SciDFM은 대규모 훈련 데이터 집합을 수집하여 여러 과학 분야의 논문과 서적, 그리고 분야별 데이터베이스에서 수집한 데이터를 포함합니다. 또한, 사전 학습된 모델을 많은 지시 데이터로 추가 세부 조정하여 하위 기초 평가에서의 성능을 향상시킵니다.

- **Performance Highlights**: 실험 결과 SciDFM은 SciEval 및 SciQ와 같은 일반 과학 기초 평가에서 강력한 성능을 보이며, 동등한 크기 모델 중에서 분야별 평가에서도 SOTA(State Of The Art) 성능을 달성하였습니다. 우리는 전문가 선택 결과가 다른 분야의 데이터에 따라 달라진다는 점을 분석하였습니다. 또한 더 넓은 연구 커뮤니티를 위해 SciDFM을 오픈소스했습니다.



### MultiClimate: Multimodal Stance Detection on Climate Change Videos (https://arxiv.org/abs/2409.18346)
Comments:
          5 pages, 1 figure

- **What's New**: 이번 연구에서는 기후 변화(Climate Change, CC)와 관련된 주장을 탐지하기 위한 첫 번째 공개 소스 수동 주석 데이터셋인 MultiClimate를 소개합니다. 이 데이터셋은 100개의 CC 관련 YouTube 비디오와 4,209개의 프레임-전사 쌍으로 구성되어 있습니다.

- **Technical Details**: MultiClimate는 다양한 비전(Vision) 및 언어(Language) 모델, 그리고 멀티모달(Multimodal) 모델을 사용하여 주장을 탐지합니다. 연구 결과, 텍스트 전용 BERT 모델이 이미지 전용 ResNet50 및 ViT 모델보다 현저히 우수한 성능을 보였습니다. 두 가지 모달리티를 결합할 경우, 정확도(Accuracy) 및 F1 점수에서 각각 0.747 및 0.749를 기록하며 최신 기술 수준(State-of-the-art)을 달성했습니다.

- **Performance Highlights**: 100M 크기의 융합(fusion) 모델이 CLIP, BLIP, 그리고 훨씬 더 큰 9B 크기의 멀티모달 IDEFICS 및 텍스트 전용 Llama3와 Gemma2보다 뛰어난 성능을 보였습니다. 이는 대형 언어 모델에 대해 멀티모달 주장 탐지가 여전히 도전적임을 나타냅니다.



### A Generalized LLM-Augmented BIM Framework: Application to a Speech-to-BIM system (https://arxiv.org/abs/2409.18345)
- **What's New**: 이 논문은 건물 정보 모델링(BIM) 작업을 가속화하기 위해 LLM(대형 언어 모델)을 활용한 새로운 프레임워크를 제안합니다. 이는 전통적인 그래픽 사용자 인터페이스를 대체할 가능성을 보여줍니다.

- **Technical Details**: 제안된 프레임워크는 6단계로 구성됩니다: 해석(interpret) - 채우기(fill) - 일치(match) - 구조화(structure) - 실행(execute) - 검토(check). 이 과정은 텍스트에서 BIM 또는 음성을 BIM으로 변환하는 방식을 포함합니다.

- **Performance Highlights**: NADIA-S라는 음성 기반 BIM 응용 프로그램을 구현하여 제안된 프레임워크의 적합성을 입증하였고, 외부 벽 세부 사항을 예로 들었습니다.



### AER-LLM: Ambiguity-aware Emotion Recognition Leveraging Large Language Models (https://arxiv.org/abs/2409.18339)
Comments:
          5 pages, 4 figures

- **What's New**: 본 연구는 LLMs(대규모 언어 모델)의 감정 인식 능력에 대한 새로운 접근을 제공합니다. 특히, 단일 감정 레이블에 국한되지 않고 모호한 감정을 인식하는 능력을 탐구하여 감정 지능(emotional intelligence)의 중요한 측면을 다루고 있습니다.

- **Technical Details**: 연구에서는 LLMs의 제로샷(zero-shot) 및 몇샷(few-shot) 프롬팅(prompts) 기술을 사용하여 문맥 정보(context information)를 과거 대화와 함께 통합함으로써 모호한 감정을 인식하는 과정이 설계되었습니다. 이를 통해 LLMs의 강력한 일반화 능력과 인-컨텍스트 학습(in-context learning)을 활용합니다.

- **Performance Highlights**: 실험 결과, LLMs는 모호한 감정을 인식하는 데 있어 상당한 잠재력을 보여주었으며, 문맥 정보를 포함할 때 그 효과성이 크게 증가함을 발견했습니다. 또한, 덜 모호한 감정을 인식하는 데 높은 효율성을 보이며, 더 모호한 감정들을 인식할 가능성도 제시하였습니다.



### DisGeM: Distractor Generation for Multiple Choice Questions with Span Masking (https://arxiv.org/abs/2409.18263)
- **What's New**: 최근 자연어 처리(Natural Language Processing, NLP) 분야의 발전이 여러 하위 분야에 영향을 미쳤습니다. 이 논문은 다중 선택 질문(Multiple Choice Questions, MCQ)을 위한 방해 요소(distractor) 생성에서의 새로운 접근 방식을 제시합니다.

- **Technical Details**: 본 연구는 사전 훈련된 언어 모델(Pre-trained Language Models, PLMs)을 활용한 간단하고 일반적인 방해 요소 생성 프레임워크를 제공합니다. 기존 방법과 달리, 제안된 프레임워크는 특정 데이터셋에 대한 추가 훈련이 필요하지 않습니다. 두 단계의 프레임워크, 즉 후보 생성(candidate generation)과 후보 선택(candidate selection)으로 구성됩니다.

- **Performance Highlights**: 제안한 방해 요소 생성 프레임워크는 훈련이나 파인튜닝(fine-tuning) 없이도 이전 방법들을 초월하는 성과를 보였으며, 인간 평가에서 더 효과적이고 흥미로운 방해 요소를 생성함을 확인했습니다.



### LangSAMP: Language-Script Aware Multilingual Pretraining (https://arxiv.org/abs/2409.18199)
Comments:
          preprint

- **What's New**: 최근 다국어 사전학습 언어 모델(mPLMs)에서 언어 임베딩(embeddings)의 사용을 피하고 있습니다. 이 논문은 새로운 접근법인 LangSAMP(Language-Script Aware Multilingual Pretraining)를 제안하며, 이를 통해 언어 및 스크립트 정보를 포함하는 임베딩을 활용하여 모델의 표현 학습을 개선합니다.

- **Technical Details**: LangSAMP는 transformer 블록의 출력에 언어 및 스크립트 임베딩을 통합하며, 최종 표현을 언어 모델링 헤드로 전달하기 전에 이러한 정보를 합칩니다. 이는 다국어 코퍼스(500개 이상의 언어 포함)에 대한 XLM-R의 지속적(pretraining) 학습에 적용됩니다.

- **Performance Highlights**: LangSAMP를 적용한 모델은 기준 모델(baseline)을 일관되게 초월하는 성과를 보여줍니다. 추가 분석에서 언어 및 스크립트 임베딩이 언어/스크립트 특화 정보(encoded)는 크로스링구얼 전송(crosslingual transfer)을 위한 소스 언어 선택을 개선함을 보여줍니다.



### LowREm: A Repository of Word Embeddings for 87 Low-Resource Languages Enhanced with Multilingual Graph Knowledg (https://arxiv.org/abs/2409.18193)
Comments:
          Short paper, preview

- **What's New**: 이 논문에서는 87개의 저자원 언어에 대한 정적(Static) 임베딩(Embeddings)의 중앙화된 저장소인 LowREm을 발표합니다.

- **Technical Details**: LowREm은 저자원 언어들을 위한 GloVe 기반 임베딩을 다국어 그래프 지식(Multilingual Graph Knowledge)을 통합하여 개선하는 신규 방법을 제안합니다.

- **Performance Highlights**: 향상된 임베딩은 XLM-R에서 추출된 컨텍스트화된 임베딩과 비교하여 감정 분석(Sentiment Analysis)에서 우수한 성능을 보였습니다.



### Evaluation of Large Language Models for Summarization Tasks in the Medical Domain: A Narrative Review (https://arxiv.org/abs/2409.18170)
- **What's New**: 대형 언어 모델(Large Language Models)의 발전은 임상 자연어 생성(Clinical Natural Language Generation)을 촉진하고, 의료 텍스트의 양을 관리할 수 있는 기회를 창출했습니다. 그러나 의료의 높은 위험 수준은 신뢰할 수 있는 평가를 요구하며, 이는 여전히 도전 과제로 남아 있습니다.

- **Technical Details**: 이 논문은 임상 요약 작업(Clinical Summarization Tasks)의 현재 평가 상태를 분석하고, 전문가의 인간 평가(Human Evaluation) 자원 제약(Resource Constraints)을 해결하기 위한 미래 방향을 제안합니다. 이를 통해 임상 분야에서의 신뢰성을 높이고자 합니다.

- **Performance Highlights**: 이 리뷰는 임상 자연어 생성의 효율성을 높이는 방법을 제안하며, 향후 연구 방향을 명확히 하고, 평가 프로세스의 개선 필요성을 강조합니다.



### Charting the Future: Using Chart Question-Answering for Scalable Evaluation of LLM-Driven Data Visualizations (https://arxiv.org/abs/2409.18764)
- **What's New**: 본 연구는 Visual Question Answering (VQA) 모델을 활용하여 LLM(대형 언어 모델) 생성 데이터 시각화의 평가를 자동화하는 새로운 프레임워크를 제안합니다. 전통적인 평가 방법은 비용이 많이 들고 확장성이 부족한 인간 판단에 의존하거나 오직 데이터 정확도에만 집중하는 경향이 있습니다.

- **Technical Details**: VQA 모델을 사용하여 차트의 데이터 표현 품질 및 일반적인 의사소통 명확성을 평가합니다. 실험은 ChartQA와 PlotQA라는 두 가지 주요 VQA 벤치마크 데이터 세트를 사용하여 OpenAI의 GPT-3.5 Turbo 및 Meta의 Llama 3.1 70B-Instruct 모델로 생성된 시각화를 통해 실시되었습니다.

- **Performance Highlights**: LLM이 생성한 차트는 VQA 성과 기반으로 원래의 비-LLM 생성 차트의 정확도에 미치지 못하며, few-shot prompting이 차트 생성의 정확도를 크게 향상시킬 수 있음을 보여줍니다. 그러나 LLM이 인간이 생성한 그래프의 정확성과 완전히 일치하려면 아직 많은 발전이 필요하다는 점이 강조됩니다.



### Cross-Domain Keyword Extraction with Keyness Patterns (https://arxiv.org/abs/2409.18724)
Comments:
          26 pages, 14 figures

- **What's New**: 이 논문은 주제의존성(domain dependence)과 주석 주관성(annotation subjectivity) 문제를 해결하기 위한 감독된(keyword extraction) 키워드 추출 방식을 제안합니다. 저자는 커뮤니티 수준에서 존재하는 이차적(keyness patterns) 키니스 패턴을 학습하여 키워드를 순위화하는 접근 방식을 소개합니다.

- **Technical Details**: 제안된 접근 방식에서는 독립(feature) 특성(서브랭귀지 도메인 및 용어 길이 포함)과 세 가지 범주의 종속(dependent) 특성(휴리스틱, 특이성, 대표성)을 가진 키니스 패턴을 기반으로 키워드를 평가합니다. 두 개의 합성곱 신경망(convolutional neural network) 모델을 사용하여 키워드 데이터셋에서 키니스 패턴을 학습하며, 부트스트랩 샘플링(bootstrap sampling) 전략으로 주석 주관성을 극복합니다.

- **Performance Highlights**: 이 접근 방식은 일반 감독된 키워드 추출에서 평균 top-10-F-measure 0.316을 기록하며, 총 10개의 키워드 데이터셋에서 최첨단 성능을 달성했습니다. 또한, 훈련 과정에서 제외된 4개의 데이터셋에서 평균 top-10-F-measure 0.346을 기록하며 강력한 크로스 도메인(cross-domain) 성능을 보였습니다.



### KALE-LM: Unleash The Power Of AI For Science Via Knowledge And Logic Enhanced Large Mod (https://arxiv.org/abs/2409.18695)
- **What's New**: AI의 잠재력이 커지고 있는 가운데, 과학 연구를 진전시키기 위해 AI를 활용하는 방안에 대해 논의한 비전 논문입니다.

- **Technical Details**: KALE-LM 모델 시리즈의 일환으로 Llama3-KALE-LM-Chem-8B라는 대형 모델을 제안했으며, 화학 분야와 관련된 작업에서 우수한 성능을 나타냈습니다. 이 모델은 오픈 소스로 공개되었습니다.

- **Performance Highlights**: Llama3-KALE-LM-Chem-8B 모델은 화학 관련 작업에서 뛰어난 성능을 보여주며, 더 지능적인 AI 실현을 위한 강력한 출발점이 될 것으로 기대됩니다.



### Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models (https://arxiv.org/abs/2409.18680)
Comments:
          EMNLP24 Findings

- **What's New**: 본 논문에서는 여러 오디오 작업을 동시에 처리할 수 있는 첫 번째 multi-audio evaluation (MAE) 벤치마크를 제안합니다. 이 벤치마크는 11개 멀티 오디오 작업에서 수집한 20개의 데이터셋으로 구성되어 있습니다.

- **Technical Details**: 기존의 audio-LLMs (ALLMs)는 단일 오디오 작업의 평가에 주로 초점을 맞추었으나, 실제 애플리케이션에서는 여러 오디오 스트림을 동시에 처리하는 경우가 많습니다. 우리는 synthetic data를 활용하여 multi-audio-LLM (MALLM)을 제안하며, 이를 통해 여러 유사한 오디오 간의 음향 맥락을 포착합니다.

- **Performance Highlights**: MALLM은 기존의 모든 기준선 모델 대비 뛰어난 성능을 보여주며, 인간 주석 없이도 높은 데이터 효율성을 달성했습니다. 이는 ALLMs가 멀티 오디오 처리 시대에 접어드는 데 중요한 이정표가 될 것입니다.



### ASAG2024: A Combined Benchmark for Short Answer Grading (https://arxiv.org/abs/2409.18596)
Comments:
          Accepted at SIGCSE-Virtual 2024

- **What's New**: 이 연구는 여러 학과, 채점 기준 및 분포에 걸쳐 통합된 단답형 채점 벤치마크인 ASAG2024를 소개합니다. 이는 자동 채점 시스템의 비교를 용이하게 계속 할 수 있게 합니다.

- **Technical Details**: ASAG2024 벤치마크는 일곱 개의 일반적으로 사용되는 단답형 채점 데이터셋을 통합하여 공통 구조 및 채점 기준을 제공합니다. 연구에서는 최근의 단답형 채점 방법들의 성능을 평가하였으며, LLM 기반 접근 방식이 새로운 높은 점수를 기록하지만 여전히 인간의 성능에 미치지 못한다는 것을 보여주었습니다.

- **Performance Highlights**: 최근 SAG 방법들은 이전보다 높은 점수를 기록했지만, 인간 채점자의 성능과 비교할 때 여전히 큰 간극이 존재합니다. 이는 향후 연구에서 인간-기계 SAG 시스템의 가능성을 열어줍니다.



### "Oh LLM, I'm Asking Thee, Please Give Me a Decision Tree": Zero-Shot Decision Tree Induction and Embedding with Large Language Models (https://arxiv.org/abs/2409.18594)
- **What's New**: 이번 연구에서는 대규모 언어 모델(LLMs)이 데이터가 제한적인 상황에서 예측 모델링을 위해 사전 지식을 활용하는 강력한 방법을 제공함을 보여줍니다. 특히, LLMs이 훈련 데이터 없이도 본질적으로 해석 가능한 머신 러닝 모델인 의사결정나무(decision trees)를 생성할 수 있음을 설명합니다.

- **Technical Details**: 이 연구에서는 LLMs가 압축된 세계 지식을 활용하여 제로샷(Zero-shot) 의사결정나무를 생성하는 방법을 보여줍니다. 이 의사결정나무는 작고 간단한 테이블 데이터셋(tabular datasets)에 대해 데이터 기반 의사결정나무보다 뛰어난 성능을 보일 수 있습니다. 또한, 이 나무에서 파생된 임베딩(embeddings)은 평균적으로 데이터 기반 의사결정나무에서 파생된 것들과 동등한 성능을 나타냅니다.

- **Performance Highlights**: 지식 기반 의사결정나무 유도와 임베딩 접근 방식은 데이터가 제한된 상황에서 데이터 기반 머신 러닝 방법의 강력한 새로운 기준선을 제공합니다.



### EmoPro: A Prompt Selection Strategy for Emotional Expression in LM-based Speech Synthesis (https://arxiv.org/abs/2409.18512)
- **What's New**: 최근 음성 합성 모델의 발전으로, 방대한 데이터셋을 활용한 제로샷(zero-shot) 능력의 향상이 두드러진다. 이런 발전에도 불구하고, 프롬프트(prompt)의 선택이 음성 생성의 품질에 중대한 영향을 미친다는 점에 주목하였다.

- **Technical Details**: 이 논문에서는 감정 조절이 가능한 음성 합성을 위한 두 단계의 프롬프트 선택 전략인 EmoPro를 제안한다. 이 전략은情緒 표현 강도(emotional expression strength), 음성 품질(speech quality), 텍스트-감정 일관성(text-emotion consistency), 모델 생성 성능(model generation performance)이라는 네 가지 관점에서 프롬프트를 평가하여 선택한다.

- **Performance Highlights**: 실험 결과, 제안된 방법으로 선택된 프롬프트는 기본 참조 모델(baseline)으로 얻은 것보다 더 감정적으로 표현력이 풍부하고 매력적인 합성 음성을 생성하는 것으로 나타났다. 오디오 샘플과 코드가 제공될 예정이다.



### Easy2Hard-Bench: Standardized Difficulty Labels for Profiling LLM Performance and Generalization (https://arxiv.org/abs/2409.18433)
Comments:
          NeurIPS 2024 Datasets and Benchmarks Track

- **What's New**: Easy2Hard-Bench라는 새로운 벤치마크 데이터셋의 개발은 어려운 문제에서 쉽게 문제를 풀어내는 일반화 능력을 평가하기 위해 제안되었습니다. 각 문제는 숫자 형태의 난이도 점수로 주석이 달려 있습니다.

- **Technical Details**: 이 데이터셋은 수학, 프로그래밍 문제, 체스 퍼즐, 추리 문제 등 다양한 도메인에서 총 6개의 벤치마크 데이터셋으로 구성되어 있습니다. Item Response Theory (IRT)와 Glicko-2 모델과 같은 난이도 평가 시스템을 활용하여 문제에 대한 숫자 난이도 점수를 일관되게 부여합니다.

- **Performance Highlights**: 여섯 개의 최첨단 LLMs에 대한 광범위한 실험을 통해 다양한 난이도 수준에서의 성능과 일반화 능력을 총체적으로 분석하였으며, 이는 LLM 일반화에 대한 미래 연구에 영감을 줄 것입니다.



### VickreyFeedback: Cost-efficient Data Construction for Reinforcement Learning from Human Feedback (https://arxiv.org/abs/2409.18417)
Comments:
          16 pages, 5 figures

- **What's New**: 이 논문은 Reinforcement Learning from Human Feedback (RLHF)의 비용 효율성에 초점을 맞추고 있습니다. 기존의 preference dataset(선호도 데이터셋)의 경제적 유용성에 대한 고려가 부족했음을 지적하며, 이를 해결하기 위해 새로운 경매 메커니즘을 도입합니다.

- **Technical Details**: RLHF는 대규모 언어 모델(LLM)의 결과에 대한 인간의 선호도를 반영하기 위해 인간의 피드백을 활용합니다. 논문에서는 기존 알고리즘이 복잡한 비전이성(preference)이거나 순환적 관계를 처리하지 못하는 문제를 다룹니다. 경매 메커니즘을 사용하여 선호도 데이터 수집의 효율성을 높이는 방법을 제시합니다.

- **Performance Highlights**: 실험 결과, 제안된 경매 기반 프로토콜은 고품질 피드백에 집중함으로써 LLM의 fine-tuning에서 비용 효율성을 개선하면서도 만족스러운 모델 성능을 유지하는 데 기여한다는 것이 입증되었습니다.



### Defect Prediction with Content-based Features (https://arxiv.org/abs/2409.18365)
- **What's New**: 이 논문에서는 전통적인 결함 예측(Defect Prediction) 접근법과는 다른 소스 코드(content of source code)를 기반으로 한 새로운 접근법을 탐색합니다.

- **Technical Details**: 이 연구에서는 소스 코드의 내용에서 추출한 단어(words), 주제(topics), 데이터 유형(data types), 패키지 이름(package names) 같은 콘텐츠 기반 기능(features)을 사용하여 결함 예측을 수행합니다. 이러한 기능들은 코드 복잡도(metrics that measure complexity)보다 높은 예측력을 가지고 있음을 보였습니다.

- **Performance Highlights**: 연구 결과, 콘텐츠 기반 기능이 코딩 복잡도를 측정하는 기존 방법들보다 예측 성능이 좋으며, 기능 선택(feature selection), 축소(reduction), 조합(combination)을 통해 예측 성능이 더욱 개선된다는 사실이 밝혀졌습니다.



### A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies (https://arxiv.org/abs/2409.18335)
Comments:
          EMNLP Findings 2024

- **What's New**: 최근 인공지능(AI) 및 자연어 처리(NLP)의 발전에도 불구하고, 협상(negotiation)은 여전히 AI 에이전트에게 어려운 분야입니다. 최근에 제안된 FDHC 프레임워크는 공정성(fairness)을 고려하여 인간과 호환되는 협상 전략을 학습할 수 있게 도와줍니다.

- **Technical Details**: FDHC 프레임워크는 보상 설계(reward design)와 탐색(search) 두 가지 측면에서 공정성을 통합합니다. 또한, LGM-Zero라는 새로운 RL(강화 학습) + search 기법을 도입하여 사전 훈련된 언어 모델(pre-trained language model)을 활용하여 대규모 행동 공간에서 인간과 호환되는 제안을 검색합니다.

- **Performance Highlights**: 실험 결과, FDHC는 협상 결과를 더 평등하게 만들고 협상 품질을 향상시키는 데 성공하였습니다.



### Cross-Institutional Structured Radiology Reporting for Lung Cancer Screening Using a Dynamic Template-Constrained Large Language Mod (https://arxiv.org/abs/2409.18319)
- **What's New**: 본 논문은 구조적 방사선 보고서를 생성하기 위한 향상된 오픈 소스 LLM(대형 언어 모델)을 개발하는 새로운 접근법을 제안합니다. 기존 모델들이 직면한 형식 오류, 콘텐츠 착각(content hallucinations), 개인정보 유출 문제를 해결하고자 합니다.

- **Technical Details**: 연구팀은 두 기관으로부터 수집된 5,442개의 비식별화된 LCS 보고서를 분석하고, 이 중 500개의 보고서를 무작위로 선택하여 수작업으로 라벨링하였습니다. 29개의 특징을 포함한 표준화된 보고서 템플릿을 개발했으며, 이를 기반으로 템플릿 제약 디코딩(template-constrained decoding)을 이용해 LLAMA, Qwen, Mistral 등의 오픈 소스 LLM을 향상시켰습니다. 성능 평가는 F1 점수, 신뢰 구간(confidence interval), McNemar test, z-test를 통해 수행되었습니다.

- **Performance Highlights**: 제안한 방법은 여러 기관의 데이터셋에서 LLM 성능을 일관되게 향상시켰으며, 형식 오류나 콘텐츠 착각이 없었습니다. 오픈 소스 LLAMA-3.1 405B 모델의 성능을 최대 10.42% 개선하였고, GPT-4o보다 17.19% 더 뛰어난 성과를 보였습니다. 또한, 대규모 다중 모달(multimodal) 데이터베이스에서 신규 결절 검색 시스템을 성공적으로 프로토타입하고 자동으로 통계 분석을 수행하여, 이전 결과와의 일관성을 보여주었습니다.



### Realistic Evaluation of Model Merging for Compositional Generalization (https://arxiv.org/abs/2409.18314)
- **What's New**: 본 논문에서는 다양한 merging 방법론의 상대적인 장점을 평가하고, 이를 통해 각 방법의 실제 요구 사항을 명확히 하였습니다. 특히, 이미지 분류(image classification), 이미지 생성(image generation), 자연어 처리(natural language processing) 분야에서의 compositional generalization을 위한 merging에 초점을 맞추었습니다.

- **Technical Details**: 연구는 다양한 merging 방법을 일관된 실험 환경에서 비교하였으며, 모델 아키텍처(model architecture), 데이터 가용성(data availability), 계산 예산(computational budget)에 대한 가정이 서로 다를 수 있음을 강조합니다. 또한, 각 merging 방법이 필요로 하는 계산 비용(computational costs)과 병합되는 모델 수가 증가할 때의 성능을 측정하였습니다.

- **Performance Highlights**: 연구 결과는 모델 병합(model merging) 분야의 현재 상태를 명확히 하고, 새로운 방법을 시험할 수 있는 포괄적이고 엄격한 실험 Setup을 제공합니다.



### Advancing Object Detection in Transportation with Multimodal Large Language Models (MLLMs): A Comprehensive Review and Empirical Testing (https://arxiv.org/abs/2409.18286)
- **What's New**: 이번 연구는 교통 시스템에서 객체 탐지(object detection)에 대한 다중 모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)과 대형 비전 모델(Large Vision Models, VLMs)의 응용을 포괄적으로 검토하고 실증적으로 평가하는 것을 목표로 합니다.

- **Technical Details**: 연구의 첫 번째 부분에서는 MLLMs의 교통 응용 분야에서의 잠재적인 이점에 대한 배경을 제공하고, 기존 연구에서 현재 MLLM 기술에 대한 포괄적인 리뷰를 실시했습니다. 두 번째 부분에서는 교통 응용 프로그램에서의 엔드 투 엔드 객체 탐지(taxonomy of end-to-end object detection) 개요와 향후 방향을 제시했습니다.

- **Performance Highlights**: MLLM 성능에 대한 상세한 평가 결과를 제공하며, 도로 안전 특성 추출, 안전 비상 이벤트 탐지, 열화상 이미지의 시각적 추론을 포함한 세 가지 실제 교통 문제에 대한 실증 분석을 수행했습니다. 이 연구는 MLLM의 강점과 개선이 필요한 영역을 밝혀냈으며, 교통에서의 객체 탐지를 향상시키기 위한 MLLM의 실용적인 한계와 도전에 대해 논의합니다.



### MMMT-IF: A Challenging Multimodal Multi-Turn Instruction Following Benchmark (https://arxiv.org/abs/2409.18216)
Comments:
          24 pages, 16 figures

- **What's New**: MMMT-IF 데이터셋과 Programmatic Instruction Following (PIF) 메트릭을 도입하여 멀티모달, 멀티턴 대화에서 지시사항을 따르는 능력을 평가하는 새로운 방법을 제안합니다.

- **Technical Details**: MMMT-IF는 질문들 사이에 추가된 전역 지시사항을 포함하여, 모델이 긴 대화 속에서 분산된 지시사항을 검색하고 지시사항 제약 하에서 추론할 수 있도록 도전합니다. 모든 지시사항은 코드 실행을 통해 객관적으로 검증 가능합니다. PIF 메트릭은 추론 작업을 수행하는 동안 정확하게 따르는 지시사항의 비율을 측정합니다. PIF-N-K 메트릭은 모델 응답 중 K개가 PIF 점수가 1인 비율을 측정하여 강건성을 평가합니다.

- **Performance Highlights**: Gemini 1.5 Pro, GPT-4o, Claude 3.5 Sonnet의 평균 PIF 점수가 턴 1에서 0.81에서 턴 20에서 0.64로 감소하며, 모든 응답을 4회 반복했을 때 GPT-4o와 Gemini가 모든 지시사항을 성공적으로 따르는 경우는 단 11%입니다. 지시사항이 모델 입력 문맥의 끝에 추가되면 평균 PIF 점수가 22.3 포인트 향상됩니다.



### AI Policy Projector: Grounding LLM Policy Design in Iterative Mapmaking (https://arxiv.org/abs/2409.18203)
- **What's New**: 이 논문에서는 정책 설계를 지도 제작(mapmaking)에서 영감을 얻어 새로운 AI 정책 설계 프로세스를 소개합니다.

- **Technical Details**: 이 연구에서 제안하는 Policy Projector는 모델 입력 및 출력 쌍의 지형을 탐색하고 사용자 정의 영역을 정의하며, LLM 출력에 적용할 수 있는 규칙을 탐색할 수 있도록 해줍니다. 예를 들어, '폭력(violence)'과 '그래픽 세부사항(graphic details)'이 포함된 출력이 있는 경우 그래픽 세부사항 없이 다시 쓰는 규칙을 설정할 수 있습니다.

- **Performance Highlights**: 12명의 AI 안전(AI safety) 전문가와의 평가에서, Policy Projector는 정책 설계자가 기존의 포괄적인 해악 분류(harm taxonomy)를 넘어서는 문제적 모델 행동을 해결하는 데 도움을 주었습니다.



### Data-Prep-Kit: getting your data ready for LLM application developmen (https://arxiv.org/abs/2409.18164)
Comments:
          10 pages, 7 figures

- **What's New**: 이 논문에서는 대규모 언어 모델(LLM) 개발을 위한 데이터 준비의 중요성을 강조하며, 사용자들이 손쉽게 확장하고 조정할 수 있는 오픈 소스 데이터 준비 툴킷인 Data Prep Kit (DPK)를 소개합니다.

- **Technical Details**: DPK는 데이터 준비를 사용자의 필요에 맞게 조정할 수 있도록 설계된 아키텍처를 가지고 있으며, 로컬 머신에서 데이터를 준비할 수 있을 뿐만 아니라 수천 개의 CPU 코어가 있는 클러스터에서도 손쉽게 확장할 수 있습니다. DPK는 자연어 및 코드 데이터를 변환하는 확장 가능한 모듈 세트를 제공합니다. 사용자가 추가적인 변환이 필요할 경우, DPK의 지원을 통해 손쉽게 개발할 수 있습니다. 이러한 모듈들은 독립적으로 또는 파이프라인 방식으로 연속적인 작업을 수행하는 데 사용될 수 있습니다.

- **Performance Highlights**: DPK의 성능은 작은 규모에서 시작하여 매우 큰 수의 CPU까지 확장 가능함을 보여줍니다. DPK의 모듈은 Granite 모델 데이터 준비에도 사용되었습니다. DPK는 AI 커뮤니티가 LLM 모델 성능을 향상하거나 Retrieval-Augmented Generation (RAG) 기능으로 모델을 미세 조정할 수 있도록 돕는 귀중한 기여라고 믿습니다.



### Open-World Evaluation for Retrieving Diverse Perspectives (https://arxiv.org/abs/2409.18110)
- **What's New**: 새로운 연구 Benchmark for Retrieval Diversity for Subjective questions (BeRDS)을 소개하여, 여러 관점을 포괄하는 문서 셋을 검색하는 과정을 분석하였습니다.

- **Technical Details**: 이 연구는 복잡한 질문에 대한 다양한 관점을 검색하는 방식을 다룹니다. 단순한 문자열 일치에 의존하지 않고 언어 모델 기반의 자동 평가자를 사용하여 문서가 특정 관점을 포함하는지 판단합니다. 세 가지 유형의 말뭉치(Wikipedia, 웹 스냅샷, 검색 엔진 결과 활용)를 조합한 성능을 평가합니다.

- **Performance Highlights**: 기존의 검색 시스템은 다양한 관점을 포함한 문서 세트를 33.74%의 경우에만 검색할 수 있었습니다. 쿼리 확장 및 다양성 중심의 재정렬 방법을 적용하여 성능 향상을 관찰하였으며, 이러한 접근법들이 밀집 검색기와 결합된 경우 더욱 강력한 결과를 보였습니다.



### Unveiling the Role of Pretraining in Direct Speech Translation (https://arxiv.org/abs/2409.18044)
Comments:
          EMNLP 2024

- **What's New**: 본 연구에서는 직접 음성-텍스트 번역 시스템의 훈련 역학을 처음으로 분석하여, 사전훈련(pretraining)의 역할과 효과적인 훈련 방법을 제안합니다. 구체적으로, 기존의 사전훈련된 인코더를 사용하는 시스템과 무작위로 초기화된 모델을 비교했으며, 무작위 초기화된 모델이 훈련 초기에 인코더의 정보를 제대로 활용하지 못하는 경향이 있음을 확인했습니다.

- **Technical Details**: 본 연구는 Transformer(Vaswani et al., 2017) 아키텍처에서의 디코더 교차-어텐션 메커니즘을 수정하여 훈련 초기 단계에서 소스 정보를 더 잘 통합하도록 하였습니다. ALTI+ 해석 가능성 방법을 활용하여 훈련 데이터의 소스 기여(source contribution)를 분석하고, 이를 통해두 가지 훈련 전략의 효과를 비교합니다. 이로써 음성 번역 모델이 처음 몇 번의 업데이트 동안 인코더의 출력을 조기에 활용하도록 유도합니다.

- **Performance Highlights**: 변경된 구조를 통해, 무작위 초기화된 모델이 사전훈련된 모델과 유사한 성능을 달성하면서도 훈련 시간을 줄일 수 있음을 보여주었습니다. 무작위 초기화된 모델은 최초 30k 업데이트 후에야 안정적인 수준의 소스 기여를 이루는 반면, 사전훈련된 모델은 6k 업데이트 후 안정성에 도달합니다. 이는 음성 번역을 위한 인코더의 훈련 과정이 문장 번역에 비해 더 복잡하다는 점을 시사합니다.



### Automated Detection and Analysis of Power Words in Persuasive Text Using Natural Language Processing (https://arxiv.org/abs/2409.18033)
- **What's New**: 본 연구에서는 마케팅, 정치 및 동기 부여 글쓰기 분야에서 중요한 역할을 하는 power words(파워 워드)를 자동으로 탐지하고 분석하는 방법론을 제안합니다.

- **Technical Details**: Python의 TextBlob 라이브러리와 사용자 정의 어휘를 사용하여 설득력 있는 텍스트 내에서 power words의 존재 및 빈도를 식별합니다.

- **Performance Highlights**: 다양한 도메인에서 다양한 데이터 세트를 조사하여 power words의 효과에 대한 통찰력을 제공합니다. 이는 콘텐츠 제작자, 광고주 및 정책 입안자에게 실용적인 응용 프로그램을 제공합니다.



### DARE: Diverse Visual Question Answering with Robustness Evaluation (https://arxiv.org/abs/2409.18023)
- **What's New**: 이 연구에서는 Vision Language Models (VLMs)의 성능을 평가하기 위해 DARE(Diverse Visual Question Answering with Robustness Evaluation)라고 하는 새로운 VQA 벤치마크를 소개합니다. DARE는 다양한 카테고리의 질문을 포함하며, 모델의 강건성(robustness)을 평가하기 위해 여러 변화를 도입합니다.

- **Technical Details**: DARE는 다음과 같은 네 가지 강건성 요소를 통해 평가됩니다: 1) 안내문의 변형, 2) 대답 옵션 세트의 변형, 3) 출력 형식의 변형, 4) 정답 개수의 변형. 이러한 다양한 평가 요소는 VLMs의 훈련 과정에서 학습한 편향을 드러내는 데 도움이 됩니다. DARE는 다섯 가지 카테고리에 걸쳐 복잡한 시나리오를 포괄하고 각 카테고리에 대해 세밀하게 구축된 평가 항목들을 포함합니다.

- **Performance Highlights**: 최신 VLM 모델들은 여전히 조건부 카운팅(conditional counting) 및 공간적 추론(spatial reasoning)과 같은 '인간에게는 간단한' 비전 이해 작업에서 어려움을 겪고 있으며, 특히 정답 옵션에 대한 변형에 대해 강건하지 못합니다. VLM들은 변형된 질문에서도 일관되게 성능을 발휘하지 못하며, LLaVA 1.6 및 Idefics2는 정답을 하나만 정확하게 표시하는 경향이 있습니다. DARE는 모델의 성능을 더 잘 이해할 수 있는 기회를 제공하며, 이 연구는 VLM의 향후 발전에 기여할 것으로 기대됩니다.



### Multilingual Evaluation of Long Context Retrieval and Reasoning (https://arxiv.org/abs/2409.18006)
Comments:
          Under review

- **What's New**: 이번 연구는 다국어 환경에서의 LLM(대형 언어 모델) 성능을 분석하고, 특히 길이 있는 문맥과 여러 개의 숨겨진 목표 문장을 다루는 능력에 초점을 맞췄습니다.

- **Technical Details**: 연구에서는 영어, 베트남어, 인도네시아어, 스와힐리어, 소말리어의 5개 언어에서 여러 가지 LLM을 평가했습니다. Gemini-1.5와 GPT-4o 모델이 단일 목표 문장을 처리할 때 영어에서 96%의 정확도를 보였으나, 소말리어에서는 36%로 떨어졌습니다. 세 개의 목표 문장을 사용할 경우 영어는 40%, 소말리어는 0%로 성능이 급락했습니다.

- **Performance Highlights**: 모델 성능은 문맥 길이가 증가하고 자원 수준이 낮은 언어로 이동할수록 급격히 감소했습니다. 추론 작업은 모든 언어에 대해 검색 작업보다 더 어려운 것으로 나타났고, 다국어 상황에서 '바늘 찾기' 평가에서도 모델의 한계가 드러났습니다.



### BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search (https://arxiv.org/abs/2409.17972)
- **What's New**: 본 연구는 대규모 언어 모델(LLMs)이 수학 문제 해결 능력을 향상시키기 위한 새로운 방법인 BEATS를 제안합니다. 이 방법은 모델이 문제를 단계별로 해결하도록 유도하는 적절히 설계된 프롬프트(prompt)를 활용하며, 생성된 답변의 정확성을 검증하기 위한 새로운 역검증(back-verification) 기술을 도입합니다.

- **Technical Details**: BEATS는 모델이 문제를 반복적으로 재작성(rewrite)하고, 한 단계씩 진전을 이루며, 이전 단계를 바탕으로 답변을 생성하도록 유도합니다. 또한, 기존의 투표 기반 검증 방식 대신 질문과 정답을 모델에 재제출하여 정답의 정확성을 판단하는 역검증 방식을 적용합니다. 마지막으로, 가지치기(pruning) 트리 탐색을 통해 검색 시간을 최적화하면서도 성과를 높입니다.

- **Performance Highlights**: BEATS 방법은 Qwen2-7B-Instruct 모델을 기반으로 할 때 MATH 데이터셋에서 점수를 36.94에서 61.52로 개선시켰으며, 이는 GPT-4의 42.5를 초월한 성과입니다. 추가적으로 MATH, GSM8K, SVAMP, SimulEq, NumGLUE 등 여러 데이터셋에서도 경쟁력 있는 결과를 달성하였습니다.



### The Hard Positive Truth about Vision-Language Compositionality (https://arxiv.org/abs/2409.17958)
Comments:
          ECCV 2024

- **What's New**: 이 논문에서는 CLIP와 같은 최첨단 비전-언어 모델의 조합 가능성(compositionality) 부족 문제를 다룹니다. 기존 벤치마크에서 힘들었던 점은 이러한 모델들이 하드 네거티브(hard negative)를 사용하여 개선된 성능을 과장해왔다는 것입니다. 이번 연구는 하드 포지티브(hard positive)를 포함한 대상에서 CLIP의 성능이 12.9% 감소하는 반면, 인간은 99%의 정확도를 보인다는 주장을 제기합니다.

- **Technical Details**: 저자들은 112,382개의 하드 네거티브 및 하드 포지티브 캡션으로 평가 데이터셋을 구축하였습니다. CLIP을 하드 네거티브로 파인튜닝(finetuning)할 경우 성능이 최대 38.7%까지 감소했으며, 하드 포지티브가 포함될 때의 효과를 분석하여 조합 가능한 성능을 개선할 수 있음을 밝혀냈습니다.

- **Performance Highlights**: CLIP 모델은 하드 네거티브로 훈련했을 때, 기존 벤치마크에서 성능이 개선되었음에도 불구하고, 하드 포지티브에 대한 성능이 동시에 저하되었습니다. 반면, 하드 네거티브와 하드 포지티브를 동시에 사용하여 훈련했을 때, 두 가지 모두 성능 개선이 이루어졌습니다. 이러한 연구는 조합 가능성에 대한 새로운 차원을 탐구하며 향후 연구 방향을 제시합니다.



### On Translating Technical Terminology: A Translation Workflow for Machine-Translated Acronyms (https://arxiv.org/abs/2409.17943)
Comments:
          AMTA 2024 - The Association for Machine Translation in the Americas organizes biennial conferences devoted to researchers, commercial users, governmental and NGO users

- **What's New**: 이번 논문에서는 기계 번역(Machine Translation, MT) 시스템에서 약어의 모호성 제거(acronym disambiguation)를 제안함으로써, 약어 번역의 정확성을 높이고자 하는 새로운 접근 방식을 소개합니다. 또한 새로운 약어 말뭉치(corpus)를 공개하고, 이를 기반으로 한 검색 기반 임계값(thresholding) 알고리즘을 실험하여 기존의 Google Translate와 OpusMT보다 약 10% 더 나은 성능을 보였습니다.

- **Technical Details**: 기계 번역 시스템의 약어 번역 정확도를 향상시키기 위해, 4단계의 고레벨 프로세스를 제안하였습니다. 이 프로세스는 (1) Google Translate를 사용하여 FR-EN 번역 수행, (2) 영어 장기형(long form, LF)과 단기형(short form, SF) 추출, (3) AB3P 툴을 사용한 약어 가설 생성, (4) 검색 기법을 통한 가설 검증 및 평가입니다. 이 방법들은 텍스트에서 사용된 기술 용어의 신뢰성을 향상시키는데 기여하고자 합니다.

- **Performance Highlights**: Google Translate와 OpusMT와 비교하여, 제안하는 임계값 알고리즘은 약 10%의 성능 향상을 보여주었습니다. 우리의 연구에서는 전문 번역사들이 자주 직면하는 용어 오류를 감소시키는 방안을 제시하고 있으며, 이를 통해 MT 시스템에서의 기술 용어 번역의 적합성을 증대시키는 데 기여할 것입니다.



### Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods (https://arxiv.org/abs/2409.17939)
Comments:
          AMTA 2024 - The Association for Machine Translation in the Americas organizes biennial conferences devoted to researchers, commercial users, governmental and NGO users

- **What's New**: 본 논문은 번역 메모리(Translation Memoires, TMs)와 컴퓨터 보조 번역(Computer-Aided Translation, CAT) 도구에서의 구문 정정 기법인 퍼지 매치 리페어(Fuzzy-Match Repair, FMR) 기술을 발전시키는 데 집중하고 있습니다. 특히, 기존의 기계 번역(Machine Translation, MT) 기법 대신 Word2Vec, BERT, 그리고 GPT-4와 같은 머신 러닝(machine learning) 기반 접근 방식을 사용하여 고정된 단어(anchor word) 번역의 정확성을 향상시킬 수 있는 방법을 제시합니다.

- **Technical Details**: 이 연구는 번역 시스템에서 고정된 단어의 번역을 개선하기 위해 네 가지 기술을 실험했습니다: (1) Neural Machine Translation(NMT), (2) BERT 기반 구현, (3) Word2Vec, (4) OpenAI GPT-4. 특히, 고정된 단어는 두 개의 단어 사이에 위치하며, 연속적인 단어의 가방(CBOW) 패러다임을 따른다고 설명합니다. 내재된 문맥(window) 내에서 각 단어에 가중치를 부여하여 주변 단어가 예측에 미치는 영향을 극대화할 수 있음을 강조하고 있습니다.

- **Performance Highlights**: 실험 결과, Word2Vec, BERT 및 GPT-4는 프랑스어에서 영어로의 번역에 있어 기존의 Neural Machine Translation 시스템보다 유사하거나 더 나은 성능을 보였습니다. 특히, 각 접근 방식이 고정된 단어 번역에서 성공적으로 작동하는 경우를 다루고 있습니다.



### The Lou Dataset -- Exploring the Impact of Gender-Fair Language in German Text Classification (https://arxiv.org/abs/2409.17929)
- **What's New**: 이 연구는 성 평등 언어(gender-fair language)의 효과를 평가하기 위해 최초의 고품질 독일어 텍스트 분류 데이터셋인 Lou를 소개합니다. 이 데이터셋은 성 평등 언어가 언어 모델에 미치는 영향을 체계적으로 분석하는 데 중점을 두고 개발되었습니다.

- **Technical Details**: Lou 데이터셋은 3.6k개의 개정 사례를 포함하며, 7개의 분류 작업(예: stance detection, toxicity classification)을 지원합니다. 이 연구는 성 평등 언어가 언어 모델의 예측에 미치는 영향을 조사하고 특정 개정 전략의 유효성을 평가합니다. 성 평등 언어는 기존의 성별 편향과 관련된 연구를 확장하는 중요한 기회를 제공합니다.

- **Performance Highlights**: 실험 결과, 성 평등 언어는 예측에 상당한 영향을 미치며, 레이블 플립(label flips)과 불확실성 감소가 관찰되었습니다. 특히, 성 평등 언어는 낮은 레이어에서 언어 모델이 개정된 사례를 처리하는 방식에 영향을 주어 예측의 변동성을 초래합니다. 본 연구는 독일어뿐만 아니라 다른 언어에서도 비슷한 패턴이 나타날 가능성을 제시합니다.



### Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion (https://arxiv.org/abs/2409.17928)
Comments:
          EMNLP24 Findings

- **What's New**: 이번 연구에서는 Text-to-Image (T2I) diffusion 모델의 지식 편집을 위한 새로운 프레임워크를 제안합니다. 특히, 새로운 데이터셋 CAKE를 제작하고, 평가지표를 개선하는 adaptive CLIP threshold를 도입하며, Memory-based Prompt Editing (MPE) 접근 방식을 통해 효과적인 지식 업데이트를 구현합니다.

- **Technical Details**: T2I 모델의 편집 성능을 평가하기 위해 CAKE라는 데이터셋에서 paraphrase와 다중 객체 테스트를 포함하여 보다 정밀한 평가를 가능하게 합니다. 또한, 기존의 이진 분류 기반의 평가 방식에서 벗어나 이미지가 목표 사실과 '충분히' 유사한지를 측정하는 adaptive CLIP threshold라는 새로운 기준을 제안합니다. 이와 함께, MPE는 외부의 메모리에 모든 사실 편집을 저장하여 입출력 프롬프트의 오래된 부분을 수정합니다. 이를 통해 MPE는 기존 모델 편집기보다 뛰어난 성과를 보여줍니다.

- **Performance Highlights**: MPE 접근법은 기존의 모델 편집 기법보다 전반적인 성능과 적용 가능성에서 더 우수한 결과를 보였습니다. 연구 결과는 T2I 지식 편집 방법의 신뢰할 수 있는 평가를 촉진할 것으로 예상됩니다.



### Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialec (https://arxiv.org/abs/2409.17912)
- **What's New**: 본 논문에서는 모로코 아랍어, 즉 다리자(Darija)에 맞춰 특별히 개발된 최초의 대형 언어 모델 집합인 Atlas-Chat을 소개합니다. 다리자 언어 자원과 지침 데이터를 통합하여 구축하였으며, 신규 데이터셋을 수동 및 합성적으로 생성했습니다. 이를 통해 우리의 모델이 다리자 지침을 따르고 표준 NLP 작업을 수행하는 데 탁월한 능력을 보입니다.

- **Technical Details**: Atlas-Chat 모델은 9B와 2B 파라미터로 구성되며, 다리자 전용 지침 데이터셋으로 정밀하게 조정(fine-tuned)되었습니다. 이 모델들은 DaijaMMLU benchmark에서 13B 모델을 13% 초과하는 성능 향상을 보여주며, 실험적 결과를 통해 다양한 fine-tuning 전략과 기본 모델 선택에 대한 최적 구성을 실험적으로 분석했습니다.

- **Performance Highlights**: Atlas-Chat 모델은 LLaMa, Jais 및 AceGPT와 같은 기존 아랍어 전문 LLM보다 뛰어난 성능을 발휘하며, 자동화된 메트릭과 시뮬레이션된 승률을 기준으로 평가되었습니다. 이로써, 자원이 부족한 언어 변종에 대한 지침 조정의 설계 방법론을 제공하고, 모든 자원을 공개 접근 가능하게 하여 해당 연구의 포괄성을 강조합니다.



### EMMA-500: Enhancing Massively Multilingual Adaptation of Large Language Models (https://arxiv.org/abs/2409.17892)
- **What's New**: 이번 연구에서는 546개의 언어로 작성된 텍스트를 기반으로 한 대규모 다국어 언어 모델 EMMA-500을 소개합니다. EMMA-500은 저자원 언어의 언어 범위를 개선하기 위해 설계되었습니다. 이를 위해 MaLA 코퍼스를 구성하여 다양하고 포괄적인 데이터 세트를 포함시켰습니다.

- **Technical Details**: EMMA-500은 Llama 2 7B 모델을 기반으로 하여 계속적인 사전 훈련(cont continual pre-training)을 수행하였으며, 이는 저자원 언어에 대한 언어 능력을 확장하는 데 효과적입니다. 이상적으로 구성된 MaLA 코퍼스는 939개의 언어를 포함하며, 74억 개의 공백으로 구분된 토큰을 포함하고 있습니다.

- **Performance Highlights**: EMMA-500 모델은 상반기 후속 결과에서 Llama 2 기반 모델과 다국어 기준선에 비해 두드러진 성과를 보여주었습니다. 모형 크기가 4.5B에서 13B 사이의 모델 중 EMMA-500은 최저의 부정 로그 우도(negative log-likelihood)를 기록하였으며, 일상 추론(common sense reasoning), 기계 번역(machine translation), 개방형 생성(open-ended generation) 작업에서도 우수한 성과를 보였습니다.



### PEDRO: Parameter-Efficient Fine-tuning with Prompt DEpenDent Representation MOdification (https://arxiv.org/abs/2409.17834)
Comments:
          arXiv admin note: text overlap with arXiv:2405.18203

- **What's New**: 이 논문에서는 새로운 PEFT 방법론인 PEDRO(Prompt dEpenDent Representation mOdification)를 소개합니다. PEDRO는 각 Transformer 레이어에 경량의 벡터 생성기(Vector Generator)를 통합하여 입력 프롬프트에 따라 변수를 생성합니다. 이 변수를 통해 LLM의 내부 표현을 수정함으로써 LLM의 동작을 조정합니다.

- **Technical Details**: PEDRO는 Transformer 레이어에서 수정 벡터를 직접 생성하는 메커니즘을 포함하고 있습니다. 이 과정에서 Vector Generator는 입력 프롬프트의 숨겨진 상태를 입력으로 받아 수정 벡터를 출력합니다. 이 구조는 구조상 경량화되어 있으며 다양한 작업에서 PEDRO의 효과를 입증하기 위해 광범위한 실험을 수행했습니다.

- **Performance Highlights**: PEDRO는 비슷한 수의 조정 가능한 파라미터를 사용할 때 최근의 PEFT 벤치마크를 초과하는 성능을 보이며, 단일 백본 다중 테넌트 배포 모델에서는 LoRA보다 더 높은 효율성을 나타냅니다. 이는 산업적인 응용 가능성을 더욱 높이는 결과로 이어집니다.



### BeanCounter: A low-toxicity, large-scale, and open dataset of business-oriented tex (https://arxiv.org/abs/2409.17827)
- **What's New**: 이 논문은 비즈니스 관련 공개 정보를 기반으로 한 159B 토큰의 새로운 데이터셋인 BeanCounter를 소개합니다. 이 데이터셋은 기존의 웹 기반 데이터셋보다 사실적이고, 품질이 높은 동시에 독성이 적은 컨텐츠를 제공합니다.

- **Technical Details**: BeanCounter는 공공 도메인 비즈니스 정보에서 추출된 데이터로, 다른 일반적으로 사용되는 데이터셋과는 최소 0.1%만 겹친다고 보고됩니다. 개인 식별 정보의 포함, 품질 저하 및 편향 등의 문제를 다루며, 모든 항목에 정확한 타임스탬프를 제공합니다.

- **Performance Highlights**: BeanCounter를 지속적으로 재훈련한 두 개의 LLM(대형 언어 모델)을 평가한 결과, 독성 생성이 18-33% 감소했으며, 재무 영역 내 성능이 개선되었습니다. BeanCounter는 저독성과 높은 품질의 도메인별 데이터의 새로운 출처로서, 다중 억 파라미터 LLM 교육에 충분한 규모를 자랑합니다.



### Inference-Time Language Model Alignment via Integrated Value Guidanc (https://arxiv.org/abs/2409.17819)
Comments:
          EMNLP 2024 Findings

- **What's New**: 본 논문에서는 대형 언어 모델(Large Language Models, LLMs) 조정의 복잡성을 피하면서도 효율적으로 인간의 선호에 부합할 수 있게 하는 새로운 방법인 통합 가치 안내(Integrated Value Guidance, IVG)를 소개합니다. IVG는 암묵적(implicit) 및 명시적(explicit) 가치 함수(value function)를 사용하여 언어 모델의 디코딩(decoding)을 유도합니다.

- **Technical Details**: IVG는 두 가지 형태의 가치 함수를 결합합니다. 암묵적 가치 함수는 각 토큰(token)별 샘플링에 적용되고, 명시적 가치 함수는 청크(chunk) 단위의 빔 탐색(beam search)에 사용됩니다. IVG는 다양한 작업에서의 효과를 검증하며, 전통적인 방법들을 능가합니다. 특히, IVG는 gpt2 기반의 가치 함수로부터의 유도 덕분에 감정 생성과 요약 작업에서 성능을 크게 향상했습니다.

- **Performance Highlights**: IVG는 AlpacaEval 2.0과 같은 어려운 지침 따르기 벤치마크에서, 전문가 튜닝된 모델과 상용 모델 모두에서 길이 제어된 승률이 크게 향상되는 것을 보여줍니다. 예를 들어, Mistral-7B-Instruct-v0.2 모델은 19.51%에서 26.51%로, Mixtral-8x7B-Instruct-v0.1 모델은 25.58%에서 33.75%로 증가했습니다.



### Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness (https://arxiv.org/abs/2409.17791)
Comments:
          Accepted at EMNLP 2024 Findings

- **What's New**: 최근에는 대형 언어 모델(LLM)의 보상 모델을 인간 피드백(Human Feedback) 기반 강화 학습(Reinforcement Learning from Human Feedback, RLHF) 방법으로 대체하려는 관심이 증가하고 있습니다. 이 연구에서는 Self-supervised Preference Optimization(SPO) 프레임워크를 제안하여, LLM이 인간의 선호도를 더 잘 이해하고 조정할 수 있도록 합니다.

- **Technical Details**: 본 논문에서는 SPO라는 새로운 자가 감독(preference optimization) 프레임워크를 제안합니다. 이 방법은 LLM의 출력에서 중요한 내용을 선택적으로 제거하여 다양한 선호도 정도의 응답을 생성합니다. 이러한 응답은 자기 감독 모듈로 분류되어 주 손실 함수와 결합되어 LLM을 동시에 최적화합니다.

- **Performance Highlights**: 실험 결과, SPO는 기존의 선호 최적화 방법들과 통합되어 LLM의 성능을 유의미하게 향상시킬 수 있으며, 두 가지 다양한 데이터셋에서 최첨단 결과를 달성했습니다. LLM이 선호도 정도를 구분하는 능력을 높이는 것이 여러 작업에서 성능 향상에 기여한다는 것을 보여주었습니다.



### Faithfulness and the Notion of Adversarial Sensitivity in NLP Explanations (https://arxiv.org/abs/2409.17774)
Comments:
          Accepted as a Full Paper at EMNLP 2024 Workshop BlackBoxNLP

- **What's New**: 본 논문에서는 설명 가능한 AI의 신뢰성을 평가하기 위한 새로운 접근법인 'Adversarial Sensitivity'를 소개합니다. 이 방식은 모델이 적대적 공격을 받을 때 설명자의 반응에 중점을 둡니다.

- **Technical Details**: Adversarial Sensitivity는 신뢰성을 평가하는 지표로, 적대적 입력 변화에 대한 설명자의 민감도를 포착합니다. 이를 통해 신뢰성이 기존 평가 기술의 중대한 한계를 극복하고, 기존의 설명 메커니즘의 정확성을 정량화합니다.

- **Performance Highlights**: 연구팀은 세 개의 텍스트 분류 데이터셋에 대해 여섯 개의 최첨단 후속 설명기에서 제안된 신뢰성 테스트를 수행하고, 인기 있는 설명기 테스트와의 (비)일관성을 보고하였습니다.



### Integrating Hierarchical Semantic into Iterative Generation Model for Entailment Tree Explanation (https://arxiv.org/abs/2409.17757)
- **What's New**: 본 논문은 Controller-Generator 프레임워크(HiSCG)를 기반으로 문장의 계층적 의미(Hierarchical Semantics)를 통합하여 신뢰할 수 있는 설명(Explanation)을 생성하는 새로운 아키텍처를 제안합니다. 이 방법은 동일 계층 및 인접 계층 간의 문장 간 계층적 의미를 처음으로 고려하여 설명의 향상을 이끌어냅니다.

- **Technical Details**: HiSCG 아키텍처는 세 가지 주요 구성 요소로 나뉩니다: 계층적 의미 인코더(Hierarchical Semantic Encoder), 선택 컨트롤러(Selection Controller), 중간 생성 모듈(Intermediate Generation Module). 이 구조는 계층적 연결을 통해 관련 사실을 클러스터링하고, 이러한 사실을 조합하여 결론을 생성하는 과정을 최적화합니다. 각 모듈은 계층적 정보의 활용을 극대화하도록 설계되었습니다.

- **Performance Highlights**: 제안된 방법은 EntailmentBank 데이터셋의 세 가지 설정에서 기존 다른 방법들과 비교하여 동등한 성능을 달성했으며, 두 개의 도메인 외 데이터셋에서 일반화 능력도 입증되었습니다.



### MIO: A Foundation Model on Multimodal Tokens (https://arxiv.org/abs/2409.17692)
Comments:
          Technical Report. Codes and models will be available soon

- **What's New**: MIO라는 새로운 기초 모델이 등장했습니다. 이는 음성, 텍스트, 이미지 및 비디오를 이해하고 생성할 수 있는 멀티모달 토큰 기반의 모델로서, end-to-end 및 autoregressive 방식으로 작동합니다. MIO는 기존의 모델들이 갖고 있지 않았던 all-to-all 방식으로의 이해와 생성을 지원하며, 기존의 비공식 모델들(GPT-4o 등)을 대체할 수 있습니다.

- **Technical Details**: MIO는 causal multimodal modeling에 기반해 4단계의 훈련 과정을 거칩니다: (1) alignment pre-training, (2) interleaved pre-training, (3) speech-enhanced pre-training, (4) 다양한 텍스트, 비주얼, 음성 작업에 대한 포괄적인 감독 하에 fine-tuning을 수행합니다. MIO는 discrete multimodal tokens을 사용하여 학습되며, 이는 대조 손실(contrastive loss)과 재구성 손실(reconstruction loss) 기법을 통해 semantical representation과 low-level features를 포착합니다.

- **Performance Highlights**: MIO는 이전의 dual-modal 및 any-to-any 모델들, 심지어 modality-specific baselines와 비교해서 경쟁력 있는 성능을 보이며, interleaved video-text generation, 시각적 사고의 연쇄(chain-of-visual-thought reasoning), 시각적 가이드라인 생성, 이미지 편집 기능 등 고급 기능을 구현합니다.



### Zero- and Few-shot Named Entity Recognition and Text Expansion in Medication Prescriptions using ChatGP (https://arxiv.org/abs/2409.17683)
- **What's New**: 이번 연구는 ChatGPT 3.5를 사용하여 약물 처방의 데이터 통합 및 해석을 자동화하여 사용자와 기계 모두에게 이해하기 쉬운 형식으로 제공하는 방법을 제시합니다. 이는 자유 텍스트 형태의 약물 진술에서 의미 있는 정보를 구조화하고 확장할 수 있는 가능성을 보여줍니다.

- **Technical Details**: 연구는 Named-Entity Recognition (NER) 및 Text Expansion (EX) 기술을 활용하였습니다. NER은 약물 이름, 농도, 단위, 투여 경로 및 복용 지침을 식별하며, EX는 이를 명확하고 구체적인 형태로 변환합니다. 최적화된 프롬프트를 사용해 NER의 평균 F1 점수는 0.94에 도달하였고, EX는 0.87에 도달하였습니다.

- **Performance Highlights**: 이 연구는 ChatGPT를 사용한 NER 및 EX 작업에서 우수한 성능을 입증하였습니다. 특히, few-shot 학습 접근법을 통해 잘못된 정보를 생성하는 현상(hallucination)을 방지할 수 있었으며, 이는 약물 안전 데이터 처리 시 중요합니다.



### Cross-lingual Human-Preference Alignment for Neural Machine Translation with Direct Quality Optimization (https://arxiv.org/abs/2409.17673)
Comments:
          17 pages, 1 figure

- **What's New**: 이 논문에서는 일반적인 기초 모델을 특정 작업에 맞추기 위해 인간의 피드백(Feedback)으로부터 강화 학습(Reinforcement Learning from Human Feedback, RLHF) 및 직접 선호 최적화(Direct Preference Optimization, DPO)와 같은 작업 정렬 알고리즘을 적용하는 방법을 제시합니다. 특히, 신경 기계 번역(Neural Machine Translation, NMT)에 작업 정렬을 적용하여 데이터의 불일치를 해결하는 접근방식을 소개합니다.

- **Technical Details**: 직접 품질 최적화(Direct Quality Optimization, DQO)라는 DPO의 변형을 도입하며, 이 방법은 인간의 선호를 대리하는 사전 훈련된 번역 품질 추정 모델을 활용합니다. DQO는 자동 척도(BLEU, COMET 등) 및 인간 평가를 통해 번역 품질의 향상을 검증하였습니다.

- **Performance Highlights**: DQO는 다국어 모델에 적용했을 때, 성능을 증가시키고 인력 선호를 향상하며, 모델 출력 분포와 훈련 데이터 분포 간의 거리를 늘리는 결과를 보여줍니다. 특히, DQO에 사용된 데이터에 포함되지 않은 언어와 언어 계통에서도 성능 향상이 관찰되었으며, 이는 일반적인 번역 작업에서 요구되는 행동의 전이 학습(Transfer Learning) 외에도 언어 특정적 언어적 특징들에 대한 향상이 있음을 시사합니다.



### Efficient In-Domain Question Answering for Resource-Constrained Environments (https://arxiv.org/abs/2409.17648)
Comments:
          6 pages, 2 tables

- **What's New**: 이 연구에서는 Retrieval Augmented Fine Tuning (RAFT) 및 Parameter-Efficient Fine Tuning (PEFT) 기법인 Low-Rank Adaptation (LoRA)을 결합하여 자원 제한 환경에서 질문 답변 (QA) 성능을 개선하는 새로운 접근 방식인 CRAFT를 제안합니다.

- **Technical Details**: RAFT는 정보 검색을 결합하여 LLM이 관련 콘텐츠를 기반으로 질문에 효과적으로 답할 수 있게 해주는 기법입니다. LoRA는 훈련된 경량 어댑터를 사용하여 모델을 효율적으로 미세 조정합니다. CRAFT는 RAFT와 LoRA를 결합하여 미세 조정 및 저장 요구 사항을 줄이면서도 RAG 성능을 유지합니다.

- **Performance Highlights**: CRAFT는 7-8억 개의 파라미터를 가진 LLM에서 빠른 추론 시간과 메모리 효율성을 제공하며, 자원 제한 환경에서도 기계 학습 모델의 실용적 적용을 가능하게 합니다.



### T3: A Novel Zero-shot Transfer Learning Framework Iteratively Training on an Assistant Task for a Target Task (https://arxiv.org/abs/2409.17640)
- **What's New**: 이 논문에서는 T3이라 약칭되는 새로운 제로-샷 (zero-shot) 전이 학습 프레임워크를 제안하여, 긴 텍스트 요약(Long Text Summarization) 작업을 위한 효과적인 솔루션을 제공합니다. 이 프레임워크는 보조 작업(assistant task)과 목표 작업(target task) 간의 관계를 활용하여 LLM을 학습시킵니다.

- **Technical Details**: T3는 보조 작업으로써 질문 답변(Question Answering, QA)을 활용하며, 이를 통해 긴 텍스트 요약 작업에 대한 LLM을 훈련합니다. 이 과정에서 QA는 풍부한 공개 데이터 세트를 제공하고, 질문-답변 쌍을 통해 더 많은 개체와 관계를 포함할 수 있어 요약의 질적 성장을 도모합니다. 또한, 질문 생성(Question Generation, QG)을 통해 두 작업 간의 문맥적 특성을 이해하게 됩니다.

- **Performance Highlights**: T3는 BBC summary, NarraSum, FairytaleQA, NLQuAD 데이터셋에서 3개의 기준 LLM에 비해 ROUGE에서 최대 14%, BLEU에서 35%, Factscore에서 16%의 향상치를 보여주며 그 효과성을 입증했습니다.



### ZALM3: Zero-Shot Enhancement of Vision-Language Alignment via In-Context Information in Multi-Turn Multimodal Medical Dialogu (https://arxiv.org/abs/2409.17610)
- **What's New**: 이 논문에서는 ZALM3를 제안하여 다중 회의(Multi-turn) 다중 모달(Multimodal) 의료 대화에서 비전-언어 정합성(Vision-Language Alignment)을 향상시키는 Zero-shot 접근 방식을 소개합니다. 환자가 제공하는 저품질 이미지와 텍스트 간의 관계를 개선하기 위해 LLM을 활용하여 이전 대화 맥락에서 키워드를 요약하고 시각적 영역을 추출합니다.

- **Technical Details**: ZALM3는 이미지 이전의 텍스트 대화에서 정보를 추출하여 관련 지역(Regions of Interest, RoIs)을 확인하는 데 LLM과 비주얼 그라우딩 모델을 활용합니다. 이 접근 방식은 추가적인 주석 작업이나 모델 구조 변경 없이도 비전-언어 정합성을 개선할 수 있는 특징이 있습니다.

- **Performance Highlights**: 세 가지 다른 임상 부서에서 실시한 실험 결과, ZALM3는 통계적으로 유의한 효과를 입증하며, 기존의 간단한 승패 평가 기준에 대한 보다 정량적인 결과를 제공하는 새로운 평가 메트릭을 개발하였습니다.



### Deep CLAS: Deep Contextual Listen, Attend and Sp (https://arxiv.org/abs/2409.17603)
Comments:
          Accepted by NCMMSC 2022

- **What's New**: 이번 연구에서는 Automatic Speech Recognition (ASR)에서 드문 단어의 인식률을 개선할 수 있는 Contextual-LAS (CLAS)의 발전형인 deep CLAS를 제안합니다. 기존 CLAS의 한계를 보완하기 위한 다양한 개선사항을 도입했습니다.

- **Technical Details**: deep CLAS는 문맥 정보를 보다 효율적으로 사용하기 위해 바이어스 손실(bias loss)을 도입합니다. 이 모델은 바이어스 어텐션(bias attention) 점수를 개선하기 위해 바이어스 어텐션의 쿼리를 보강하고, 문맥 정보는 LSTM 대신 Conformer로 인코딩합니다. 또한, 문구 수준 인코딩에서 문자 수준 인코딩으로 변경하여 세밀한 문맥 정보를 얻습니다.

- **Performance Highlights**: 공식 AISHELL-1 및 AISHELL-NER 데이터셋에서 실험한 결과, deep CLAS는 CLAS 기준 모델에 비해 명명 엔티티 인식(named entity recognition) 장면에서 상대적인 Recall 65.78%와 F1-score 53.49% 향상된 성능을 보였습니다.



### DualCoTs: Dual Chain-of-Thoughts Prompting for Sentiment Lexicon Expansion of Idioms (https://arxiv.org/abs/2409.17588)
- **What's New**: 이 논문에서는 관용구(idiom) 감정 분석을 위한 감정 어휘 확장을 자동으로 수행하는 혁신적인 접근 방식이 제안됩니다. 주로 대형 언어 모델(large language models)의 Chain-of-Thought prompting 기법을 활용하여 기존 자원을 통합하고 EmoIdiomE라는 새로운 감정 관용구 어휘 확장 데이터셋을 구축했습니다.

- **Technical Details**: 이 연구에서는 Dual Chain-of-Thoughts (DualCoTs) 방법을 설계하여 언어학적 및 심리언어학적 통찰을 결합함으로써 관용구의 감정 어휘를 자동으로 확장하는 방법을 제시합니다. DualCoTs는 문자적 체인(literal chain)과 어원적 체인(etymological chain)이라는 두 가지 체인으로 구성되어 있습니다. 이 두 체인을 통해 관용구의 감정 예측을 수행하며, 효과적인 감정 어휘 확장을 가능하게 합니다.

- **Performance Highlights**: DualCoTs 방법의 실험 결과, 중국어와 영어 모두에서 관용구 감정 어휘 확장에 효과적임을 입증했습니다. 연구팀은 EmoIdiomE 데이터셋을 통해 기존의 감정 어휘 확장의 한계를 극복하고, 감정 분석 및 감정 어휘 확장 작업에서 높은 정확도를 달성함을 보여주었습니다.



### Leveraging Annotator Disagreement for Text Classification (https://arxiv.org/abs/2409.17577)
- **What's New**: 이 논문은 다수의 주석자에 의해 주석된 데이터셋에서 단일 주석만을 활용하는 기존의 관행을 뛰어넘어, 주석자 간의 의견 불일치를 모델 훈련에 활용할 수 있는 세 가지 전략을 제안하고 비교합니다. 이를 통해 모델의 성능을 향상시킬 수 있는 가능성을 탐구합니다.

- **Technical Details**: 제안된 방법은 확률 기반 다중 레이블 (multi-label) 접근법, 앙상블 시스템 (ensemble system), 그리고 지시 조율 (instruction tuning) 방법입니다. 두 가지 텍스트 분류 작업(증오 발언 감지 및 대화 내 폭력 감지)을 사용하여 이 세 가지 방법의 효과를 평가하고, 다중 레이블 모델과 단일 레이블 모델 간의 성능을 온라인 설문조사를 통해 비교했습니다.

- **Performance Highlights**: 증오 발언 감지에서 다중 레이블 방법이 가장 뛰어난 성능을 보였고, 대화 내 폭력 감지에서는 지시 조율 방법이 최고 성과를 기록했습니다. 다중 레이블 모델의 출력은 단일 레이블 모델보다 텍스트를 더 잘 대표하는 것으로 평가되었습니다.



### Modulated Intervention Preference Optimization (MIPO): Keep the Easy, Refine the Difficu (https://arxiv.org/abs/2409.17545)
Comments:
          8pages, submitted to AAAI 2025

- **What's New**: 이번 연구에서는 Modulated Intervention Preference Optimization (MIPO)라는 새로운 방법론을 제안합니다. MIPO는 주어진 데이터와 참조 모델의 정렬 상태에 따라 개입(intervention) 정도를 조절하여 모델 일치를 최적화합니다.

- **Technical Details**: MIPO는 참조 모델이 잘 정렬된 경우, 정책 모델이 참조 모델과 크게 이탈하지 않도록 개입을 증가시키고, 반대로 정렬이 좋지 않은 경우 개입을 줄여 보다 광범위한 학습을 가능하게 합니다. 이 연구에서는 Mistral-7B와 Llama3-8B 모델을 활용하여 MIPO와 DPO의 성능을 비교합니다.

- **Performance Highlights**: 실험 결과, MIPO는 다양한 평가 시나리오에서 DPO에 비해 일관되게 우수한 성능을 보였습니다.



### Logic-of-Thought: Injecting Logic into Contexts for Full Reasoning in Large Language Models (https://arxiv.org/abs/2409.17539)
Comments:
          20 pages

- **What's New**: 이번 논문은 Logic-of-Thought (LoT) 프로밍 기법을 제안하여 기존의 신경상징적 방법에서 발생하는 정보 손실 문제를 해결하고, LLM의 논리적 추론 능력을 향상시키고자 합니다.

- **Technical Details**: LoT는 입력 문맥에서 명제(propositions)와 논리적 표현(logical expressions)을 추출하여, 이들을 논리적 추론 법칙(logical reasoning laws)에 따라 확장한 뒤, 확장된 논리적 표현을 자연어로 변환하여 LLM의 입력 프롬프트에 추가적인 보강제로 활용합니다. LoT는 기존의 다양한 프롬프트 기법과 호환되도록 설계되었습니다.

- **Performance Highlights**: LoT는 CoT의 ReClor 데이터셋에서 성능을 +4.35% 향상시켰고, CoT-SC는 LogiQA에서 +5% 증가, ToT는 ProofWriter 데이터셋에서 +8% 향상된 성과를 보여주었습니다.



### MUSE: Integrating Multi-Knowledge for Knowledge Graph Completion (https://arxiv.org/abs/2409.17536)
Comments:
          arXiv admin note: text overlap with arXiv:2408.05283

- **What's New**: 이 논문에서는 Knowledge Graph Completion (KGC) 문제를 해결하기 위해 MUSE라는 지식 인식 추론 모델을 제안합니다. MUSE는 결측 관계를 예측하기 위해 다중 지식 표현 학습 메커니즘을 설계하였으며, BERT 조정, Context Message Passing, Relational Path Aggregation을 포함한 세 가지 모듈을 활용합니다.

- **Technical Details**: MUSE는 세 가지 병렬 구성 요소로 이루어진 맞춤형 임베딩 공간을 개발합니다: 1) Prior Knowledge Learning을 통해 BERT를 미세 조정하여 triplet의 의미 표현을 강화합니다; 2) Context Message Passing을 통해 KG의 문맥적 메시지를 강화하고; 3) Relational Path Aggregation을 통해 head entity에서 tail entity까지의 경로 표현을 강화합니다.

- **Performance Highlights**: MUSE는 NELL995 데이터셋에서 H@1 지표가 5.50% 향상되고, MRR 지표가 4.20% 향상되는 성과를 보여주었습니다. 또한, WN18과 WN18RR 데이터셋에서 H@3 수치가 1.00을 달성했습니다.



### Data Proportion Detection for Optimized Data Management for Large Language Models (https://arxiv.org/abs/2409.17527)
- **What's New**: 이 논문은 데이터 비율 탐지(data proportion detection)라는 새로운 주제를 소개하며, LLM의 생성 출력 분석을 통해 사전 학습 데이터 비율을 자동으로 추정할 수 있는 방법을 제안합니다.

- **Technical Details**: 이 논문은 데이터 비율 탐지 문제에 대한 이론적 증명과 실제 알고리즘, 초기 실험 결과를 제시합니다. 데이터 비율 탐지는 특정한 원래 데이터에 대한 사전 지식 없이 모델이 사용하는 사전 학습 데이터의 비율을 파악하는 데 중점을 둡니다.

- **Performance Highlights**: 미리 준비된 데이터 비율 탐지 알고리즘을 통해 초기 실험을 진행했으며, 이는 데이터 비율 탐지의 기준선을 수립하고 향후 연구의 기초로 삼습니다.



### Reducing and Exploiting Data Augmentation Noise through Meta Reweighting Contrastive Learning for Text Classification (https://arxiv.org/abs/2409.17474)
Comments:
          IEEE BigData 2021

- **What's New**: 이 논문은 Meta Reweighting Contrastive (MRCo) 모델을 제안하여 데이터 증강(sample)의 품질을 고려하여 기존의 딥러닝 모델의 성능을 향상시키고자 합니다. 이 프레임워크는 메타 학습(meta learning)과 대조 학습(contrastive learning)을 결합하여 증강된 샘플의 가중치 정보를 활용합니다.

- **Technical Details**: MRCo 모델은 두 가지 최적화 루프를 가지며, 내부 루프는 다운스트림 작업을 위한 주 모듈이 재가중된 손실(loss)로 학습합니다. 외부 루프는 메타 재가중화 모듈이 증강 샘플에 적절한 가중치를 할당합니다. 대조 학습을 이용해 저품질 샘플과 고품질 샘플 간의 차이를 증대시키고 있다.

- **Performance Highlights**: 실험 결과, 본 프레임워크는 Text-CNN 인코더에서 평균 1.6%, 최대 4.3%의 개선율을 보였고, RoBERTa-base 인코더에서는 평균 1.4%, 최대 4.4%의 개선을 기록했습니다. 이는 7개의 GLUE 벤치마크 데이터셋을 기준으로 하였습니다.



### Autoregressive Multi-trait Essay Scoring via Reinforcement Learning with Scoring-aware Multiple Rewards (https://arxiv.org/abs/2409.17472)
Comments:
          EMNLP 2024

- **What's New**: SaMRL(Scoring-aware Multi-reward Reinforcement Learning) 방법론을 제안하여 다중 특성 자동 에세이 평가(multi-trait automated essay scoring)에서 Quadratic Weighted Kappa(QWK) 기반 보상을 통합하고, 평균 제곱 오차(MSE) 페널티를 적용하여 실제 평가 방식을 훈련 과정에 포함시킴으로써 모델의 성능을 향상시킵니다.

- **Technical Details**: 기존의 QWK는 비미분 가능성으로 인해 신경망 학습에 직접 사용되지 못하나, SaMRL은 bi-directional QWK와 MSE 페널티를 통해 다중 특성 평가의 복잡한 측정 방식을 훈련에 유효하게 통합하고, 오토 회귀 점수 생성 프레임워크를 적용해 토큰 생성 확률로 강력한 다중 특성 점수를 예측합니다.

- **Performance Highlights**: ASAP 및 ASAP++ 데이터셋을 통한 광범위한 실험 결과, SaMRL은 기존 강력한 기준선에 비해 각 특성과 프롬프트에서 점수 향상을 이끌어내며, 특히 넓은 점수 범위를 가진 프롬프트에서 기존 RL 사용의 한계를 극복한 점이 두드러집니다.



### What is the social benefit of hate speech detection research? A Systematic Review (https://arxiv.org/abs/2409.17467)
Comments:
          Accepted to the 3rd Workshop on NLP for Positive Impact

- **What's New**: 본 연구는 혐오 발언 탐지(NLP) 시스템의 사회적 영향력을 높이기 위한 윤리적 프레임워크의 필요성을 강조합니다. 연구진은 48개의 혐오 발언 탐지 시스템과 관련된 37개의 논문을 검토하여 현재의 연구 실천과 최선의 실천 간의 간극을 보여줍니다.

- **Technical Details**: 연구는 혐오 발언 탐지 시스템이 데이터 세트 수집과 준비, 특징 엔지니어링, 모델 훈련 및 모델 평가 등의 유사한 워크플로우를 따르며, 데이터의 품질 및 다양성이 시스템 성능에 미치는 영향을 논의합니다. 또한, AI 연구의 책임감 있는 혁신을 위한 새로운 프레임워크를 제안합니다.

- **Performance Highlights**: 연구 결과, 기존의 혐오 발언 탐지 시스템은 사회적 편향성을 내포하고 있으며, 이러한 편향성이 취약한 커뮤니티에 추가적인 불이익을 초래할 수 있음을 나타내었습니다. 따라서, NLP 연구자들은 비단 모델 성능 외에도 시스템의 사회적 영향을 고려해야 할 필요가 강조됩니다.



### Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models (https://arxiv.org/abs/2409.17455)
- **What's New**: 본 연구에서는 언어 모델(당초 LMs)에서 무시되었던 복잡한 대체 요인들이 모델의 신뢰성에 미치는 영향을 분석합니다. 저자들은 다각적으로 단축키(shortcut)를 정의하고 이를 발생, 스타일, 개념으로 분류하여 연구합니다.

- **Technical Details**: 연구에서는 BERT, Llama, SOTA 강인한 모델 등의 다양한 언어 모델에 대해 대체 요인에 대한 저항력과 취약성을 체계적으로 분석합니다. 그 결과, BERT는 모든 유형의 대체 요인에 취약하다는 것을 발견했습니다.

- **Performance Highlights**: 대형 모델의 크기 증가가 항상 Robustness를 보장하지 않으며, 강인한 모델들이 때때로 LLM보다 더 우수한 강인성을 나타냅니다. 모든 모델이 모든 유형의 대체 요인에 대해 강인하지 않다는 것이 드러났습니다.



### Enhancing Financial Sentiment Analysis with Expert-Designed Hin (https://arxiv.org/abs/2409.17448)
- **What's New**: 이 논문은 재무 소셜 미디어 게시물에서 감정 분석을 향상시키는 데 있어 전문가가 설계한 힌트의 역할을 조사합니다.

- **Technical Details**: 대규모 언어 모델(LLMs)의 관점 수용(perspective-taking) 능력을 분석하고, 숫자의 중요성을 강조하는 전문가 설계 힌트를 적용하여 성능 향상을 이루었습니다. 사용된 데이터셋은 Fin-SoMe이며, 10,000개의 트윗을 포함하고 있습니다. 실험에 포함된 LLMs는 PaLM 2, Gemini Pro, GPT-3.5, GPT-4입니다.

- **Performance Highlights**: 전문가 설계 힌트를 포함했을 때 모든 LLM에서 감정 분석 성능이 일관되게 향상되었으며, 특히 숫자와 관련된 게시물에서 두드러진 성과를 보였습니다. 기본적인 프롬프트( Simple Prompt)와 비교했을 때, 전문가의 힌트가 큰 효과를 발휘함을 보여주었습니다.



### HDFlow: Enhancing LLM Complex Problem-Solving with Hybrid Thinking and Dynamic Workflows (https://arxiv.org/abs/2409.17433)
Comments:
          27 pages, 5 figures

- **What's New**: 이 논문에서는 Large Language Models (LLMs)의 복잡한 추론 문제 해결을 위한 새로운 프레임워크인 HDFlow를 소개합니다. 이 프레임워크는 빠른 사고와 느린 사고를 적응적으로 결합하여, 복잡한 문제를 더 잘 해결할 수 있도록 합니다.

- **Technical Details**: HDFlow는 두 가지 주요 구성 요소로 이루어져 있습니다. 첫째, 'Dynamic Workflow'라는 새로운 느린 추론 접근법은 복잡한 문제를 관리 가능한 하위 작업으로 자동 분해합니다. 둘째, 'Hybrid Thinking'은 문제의 복잡성에 따라 빠른 사고와 느린 사고를 동적으로 결합하는 일반적인 프레임워크입니다. 이를 통해 모델은 문제의 복잡성에 따라 적절한 사고 모드를 선택합니다.

- **Performance Highlights**: 실험 결과, HDFlow의 느린 사고 방식 및 동적 워크플로우가 Chain-of-Thought (CoT) 전략보다 평균 22.4% 더 높은 정확도를 보였고, Hybrid Thinking은 네 개의 벤치마크 데이터 세트 중 세 개에서 최고의 정확도를 기록했습니다. 또한 하이브리드 사고를 통한 미세 조정 방법이 오픈 소스 언어 모델의 복잡한 추론 능력을 크게 향상시켰습니다.



### On Extending Direct Preference Optimization to Accommodate Ties (https://arxiv.org/abs/2409.17431)
Comments:
          24 pages

- **What's New**: 이 논문에서는 DPO(Direct Preference Optimization)의 두 가지 변형을 도입하여 쌍별 비교에서 동점(tie) 가능성을 명시적으로 모델링하는 방법을 제시합니다. 즉, 통상적인 Bradley-Terry 모델을 Rao-Kupper와 Davidson의 확장 모델로 대체하여 동점 확률을 명시적으로 포함시킵니다.

- **Technical Details**: DPO는 쌍으로 구성된 옵션 데이터(yw ≻ yl)를 통해 명확한 선호를 요구합니다. 본 연구는 Rao-Kupper 및 Davidson의 모델을 적용하여 동점 사례를 데이터셋에 추가하였고, 이는 작업 성능 저하 없이 실현되었습니다. KL-divergence 측정치를 통해 참조 정책에 대한 정규화가 강화됨을 확인했습니다.

- **Performance Highlights**: 실험 결과, DPO 변형에 동점 데이터를 통합함으로써 성능 저하 없이 훨씬 더 강한 정규화를 달성하였고, 원래 형태의 DPO에서도 유사한 개선 효과를 발견하였습니다. 이러한 발견은 단순히 동점을 제외하는 대신 선호 최적화에서 동점 쌍을 포함할 수 있는 방법을 공고히 합니다.



### Discovering the Gems in Early Layers: Accelerating Long-Context LLMs with 1000x Input Token Reduction (https://arxiv.org/abs/2409.17422)
- **What's New**: 이 연구에서는 긴 컨텍스트 입력을 처리하기 위해 LLM(Large Language Model)의 추론을 가속화하고 GPU 메모리 소모를 줄이는 새로운 접근 방식인 GemFilter를 소개합니다.

- **Technical Details**: GemFilter는 LLM의 초기 레이어를 필터로 사용하여 입력 토큰을 선택하고 압축하는 알고리즘으로, 이에 따라 추후 처리할 컨텍스트 길이를 대폭 줄입니다. 이 방법은 2.4$	imes$ 속도 향상과 30
gpu(%) GPU 메모리 사용량 감소를 달성하였습니다.

- **Performance Highlights**: GemFilter는 Needle in a Haystack 벤치마크에서 기존의 표준 어텐션 및 SnapKV를 능가하며, LongBench 챌린지에서는 SnapKV/H2O와 유사한 성능을 보여줍니다.



### Pre-Finetuning with Impact Duration Awareness for Stock Movement Prediction (https://arxiv.org/abs/2409.17419)
Comments:
          NTCIR-18 FinArg-2 Dataset

- **What's New**: 이 연구는 투자자 의견에 기반한 뉴스 이벤트의 영향 지속 시간을 추정하기 위한 새로운 데이터 세트인 Impact Duration Estimation Dataset (IDED)을 소개하며, 사전 미세 조정(pre-finetuning) 작업을 통해 주식 이동 예측 성능을 향상시키는 방법을 제시합니다. 기존 연구에서 간과된 시간적 정보의 중요성을 강조합니다.

- **Technical Details**: IDED 데이터 세트는 투자자 의견을 포함하고 있으며, 8,760개의 게시물에 대한 영향 지속 시간이 1주일 이내, 1주일 이상, 불확실로 분류되었습니다. 또한, 여러 대형 사전 학습 언어 모델(BERT-Chinese, Multilingual-BERT 등)을 사용하여 IDED로 사전 미세 조정한 결과, 모든 모델에서 성능 향상이 관찰되었습니다. SRLP(Semantic Role Labeling Pooling) 기법과 함께 StockNet 및 HAN 모델과 비교 분석하였습니다.

- **Performance Highlights**: 모든 사전 학습 언어 모델은 SRLP의 성능을 초과하지 못했으며, IDED 적용이 주식 이동 예측에서 성능을 향상시킨다는 것이 입증되었습니다. IDED-Mengzi-Fin 모델이 최상의 성능을 기록하였으며, 이는 해당 모델이 재무 문서로 사전 학습되어 도메인 특화의 이점을 지니기 때문입니다.



### Enhancing Investment Opinion Ranking through Argument-Based Sentiment Analysis (https://arxiv.org/abs/2409.17417)
- **What's New**: 본 연구는 전문가 및 아마추어 투자자의 관점을 모두 고려하여 효과적인 추천 시스템을 위한 이중 접근 방식인 'argument mining' 기술을 도입했습니다. 이를 통해 유망한 투자 의견을 식별하고 분석하는 새로운 방법을 제시합니다.

- **Technical Details**: 연구는 가격 목표(price target)를 사용하여 의견의 강도를 평가하고, 투자 의견을 평가하기 위해 역사적 데이터를 사용하여 모델을 훈련합니다. 또한, 'argument mining' 기법을 사용하여 의견을 명제(premise)와 주장(claim)으로 분해하고 이들의 관계를 분석합니다. 이 과정에서 분석가의 가격 목표를 이용하여 주장의 강도를 수치화합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 보다 높은 수익 잠재력을 가진 의견을 식별하는 능력을 검증하였으며, 추천된 의견과 투자자 행동 간의 관계를 분석하여 리스크(risk) 분석에도 기여하였습니다. 또한, 전문가의 의견 변화와 거래 패턴에 대한 포괄적인 분석이 이루어졌습니다.



### From Deception to Detection: The Dual Roles of Large Language Models in Fake News (https://arxiv.org/abs/2409.17416)
- **What's New**: 최근 연구에서는 다양한 Large Language Models (LLMs)가 가짜 뉴스를 생성할 수 있는 능력과 이러한 모델들이 가짜 뉴스를 감지하는 성능을 비교했습니다. 이는 7개의 LLM을 분석한 최초의 연구로, 각 모델의 편향 및 안전성 준수 여부를 평가하였습니다.

- **Technical Details**: 연구는 LLM의 가짜 뉴스 생성과 감지 등 두 가지 주요 단계를 중점적으로 다루고 있습니다. LLM들은 다양한 편향을 담은 가짜 뉴스를 생성할 수 있으며, 종종 인간이 작성한 내용보다 탐지하기 어렵습니다. 또한, LLM에서 제공하는 설명의 유용성도 평가되었습니다.

- **Performance Highlights**: 결과적으로, 크기가 큰 LLM들이 더 나은 가짜 뉴스 탐지 능력을 보였으며, 일부 모델은 안전 프로토콜을 엄격히 준수하여 편향된 내용을 생성하지 않았습니다. 반면에, 다른 모델은 여러 편향을 포함한 가짜 뉴스를 쉽게 생성할 수 있었고, LLM이 생성한 가짜 뉴스는 일반적으로 인간이 작성한 것보다 탐지될 가능성이 낮다는 사실이 밝혀졌습니다.



### Severity Prediction in Mental Health: LLM-based Creation, Analysis, Evaluation of a Novel Multilingual Datas (https://arxiv.org/abs/2409.17397)
- **What's New**: 이 연구는 다양한 비영어권 언어에서 대규모 언어 모델(LLMs)의 효과성을 평가하기 위한 다국어 정신 건강 데이터셋을 개발하였습니다. 이 데이터셋은 영어에서 그리스어, 터키어, 프랑스어, 포르투갈어, 독일어, 핀란드어로 번역된 사용자 생성 콘텐츠로 구성되어 있습니다. 이는 모델의 성능을 여러 언어에서 종합적으로 평가할 수 있도록 합니다.

- **Technical Details**: 이 연구에서는 GPT와 Llama를 사용하여 여러 언어로 번역된 동일한 데이터셋에서 정신 건강 상태의 심각성을 정밀하게 예측하는 성능을 비교하였습니다. 연구 결과, 언어별로 상당한 성능 차이를 관찰했으며 이는 다국어 정신 건강 지원의 복잡성을 강조합니다. 대상 데이터셋은 다음 링크에서 공개되어 있습니다: https://github.com/y3nk0/multilingual-mental-severity-prediction.

- **Performance Highlights**: 이 연구는 다국어 정신 건강 조건의 심각성을 탐지하는 LLM의 능력에 대한 포괄적인 분석을 제공하며, 특정 언어에서의 성과 차이가 어떻게 발생하는지를 조명합니다. 또한, LLM을 의료 환경에서 사용할 때의 잠재적인 오진 위험에 대해 경고합니다. 이 연구의 접근 방식은 다국어 작업의 비용 절감 측면에서도 중요한 이점을 제공합니다.



### Scaling Behavior for Large Language Models regarding Numeral Systems: An Example using Pythia (https://arxiv.org/abs/2409.17391)
Comments:
          EMNLP 2024 Findings

- **What's New**: 이번 연구에서는 대형 언어 모델(LLMs)의 수치 연산 성능에 영향을 미치는 숫자 체계의 차이를 조사했습니다. 특히, 10진수(base 10) 시스템과 100진수(base 100), 1000진수(base 1000) 시스템의 학습 효율성을 비교하여 10진수 시스템이 보편적으로 더 데이터 효율적임을 보여주었습니다.

- **Technical Details**: 본 연구에서는 LLMs의 수치 연산을 이해하기 위해 서로 다른 숫자 체계(10진수, 100진수, 1000진수)에 대해 실험을 설계했습니다. 중요한 실험 차원으로는 숫자 체계, 데이터 규모, 모델 크기 및 훈련 방식( from-scratch 또는 fine-tuning)이 있습니다. 실험 결과, 10진수 시스템은 훈련에서 일관되게 더 높은 데이터 효율성을 보였으며, 고빈도 토큰이 높은 학습 결과를 낳는 것으로 분석되었습니다.

- **Performance Highlights**: 10진수 시스템은 100진수나 1000진수 시스템에 비해 데이터 규모와 모델 규모에 상관없이 일관되게 더 우수한 성능을 보였습니다. 특히, 10진수 시스템은 숫자 인식 및 연산에서 더 효과적인 패턴을 보여주었으며, 100진수 및 1000진수 시스템은 토큰 수준 인식과 연산에서 어려움을 겪는 것으로 나타났습니다.



### data2lang2vec: Data Driven Typological Features Completion (https://arxiv.org/abs/2409.17373)
Comments:
          9 pages, 11 figures

- **What's New**: 본 연구는 다국어 자연어 처리(NLP)의 모델 적응성을 향상시키기 위해 언어 유형론 데이터베이스를 활용한 새로운 접근법을 제안합니다. 특히, lang2vec 툴킷의 한계를 극복하기 위해 텍스트 데이터를 사용하여 누락된 특성 예측을 수행합니다.

- **Technical Details**: 우리는 1749개 언어에 대해 70% 이상의 정확도를 달성한 다국어 품사(POS) 태거를 소개하며, 외부 통계적 특성과 다양한 머신러닝 알고리즘을 실험합니다. 각 언어의 언어족, 위키피디아 크기, 인간 수 등을 포함한 다수의 특징들을 사용하여 예측을 수행합니다.

- **Performance Highlights**: 우리는 제안된 방법이 기존의 방법보다 두 가지 설정에서 모두 성능이 우수함을 보여주며, 텍스트 기반 접근 방식을 통해 lang2vec 데이터의 전체 특성 목록을 완성하는 데 기여했습니다.



### Internalizing ASR with Implicit Chain of Thought for Efficient Speech-to-Speech Conversational LLM (https://arxiv.org/abs/2409.17353)
Comments:
          Corrected style from final to preprint

- **What's New**: 본 논문에서는 ASR(Automatic Speech Recognition) 및 TTS(Text-to-Speech) 기능을 내재화하여 음성 기반 LLM(Large Language Models)의 대화 능력을 강화하는 새로운 방법을 제안합니다. 기존의 ASR-TTS 파이프라인에서 발생하던 지연을 줄이고, 모델의 음성 이해능력을 향상시키는 것이 주요 목표입니다.

- **Technical Details**: 저자들은 ICoT(Implicit Chain of Thought) 기술을 활용하여 훈련된 Speech LLM에서 ASR 기능을 내재화하는 방법론을 확립했습니다. 이 과정에서 말의 전사 및 응답 생성을 위한 명시적 단계 없이도 음성 대화를 가능하게 합니다. 이러한 접근법은 대화 경험을 Improve하며, 이전의 CoT(Chain of Thought) 방법론을 오디오 및 음성 도메인에 적용한 사례로서 의미가 있습니다.

- **Performance Highlights**: 연구 결과, 기존 ASR-텍스트 기반 방법 대비 14.5%의 지연 감소를 달성했으며, 새로운 대화 모델인 AnyGPT를 통해 약 660,000개의 대화 쌍이 포함된 대규모 합성 대화 데이터셋을 구축하여 연구에 기여했습니다. 모델의 효율성을 개선하고 보다 자연스러운 음성 상호작용이 가능하도록 했습니다.



### How Transliterations Improve Crosslingual Alignmen (https://arxiv.org/abs/2409.17326)
Comments:
          preprint

- **What's New**: 이 논문은 다국어 사전 훈련된 언어 모델(mPLMs)의 크로스링구얼 정렬(alignment)을 개선하기 위한 능동적인 방법으로, 단순한 변환(transliteration) 데이터 추가가 어떻게 성능 향상에 기여하는지 명확히 평가하려는 첫 시도를 다룹니다.

- **Technical Details**: 크로스링구얼 정렬의 정의를 정립하고, 문장 표현(sentence representations)을 기준으로 네 가지 유사성(similarity) 유형을 정의합니다. 실험은 폴란드어-우크라이나어, 힌디어-우르두어 쌍에 대해 진행되며, 데이터 정렬을 평가하기 위해 다양한 설정 하에 여러 모델을 훈련합니다. 실험 결과, 단독으로 추가된 변환 데이터가 유사성을 높이며, 보조 정렬 목표(auxiliary alignment objectives)는 매칭된 쌍을 구별하는 데 도움이 되는 것으로 나타났습니다.

- **Performance Highlights**: 전반적으로 변환 데이터 사용이 모든 유사성 유형을 증가시키지만, 정렬이 항상 다운스트림 성능을 향상시키는 것은 아니라는 점이 드러났습니다. 이러한 결과는 크로스링구얼 정렬과 성능 간의 더 깊은 연구가 필요함을 시사합니다.



### BabyLlama-2: Ensemble-Distilled Models Consistently Outperform Teachers With Limited Data (https://arxiv.org/abs/2409.17312)
Comments:
          9 pages, 3 figures, 5 tables, submitted to the BabyLM Challenge (CoNLL 2024 Shared Task)

- **What's New**: BabyLlama-2는 3억 4500만 개의 매개변수를 가진 모델로, 두 개의 교사 모델로부터 1000만 개의 단어로 학습한 후 BabyLM 대회에 제출된 것이다. 결과적으로 BabyLlama-2는 BLiMP 및 SuperGLUE 벤치마크에서 동일한 데이터 혼합을 사용하는 1000만 및 1억 단어 데이터셋으로 학습된 기준 모델을 능가하였다.

- **Technical Details**: BabyLlama-2는 345M의 decoder-only 모델로, 9.5M 단어로 사전 학습되었다. 하이퍼파라미터 최적화가 광범위하게 수행되었으며, 최적의 하이퍼파라미터 선택이 교사 모델의 우수한 성능에 기인하지 않음을 증명하였다. 지식 증류(knowledge distillation) 기법을 사용하여 샘플 효율성을 높이는 데 중점을 두었다.

- **Performance Highlights**: BabyLlama-2는 기존 모델보다 더 적은 데이터로도 더 높은 성능을 달성하였다. 특히, BLiMP 과제에서 제로 샷(zero-shot) 성능과 모델의 테스트 손실(test loss) 사이에 상관관계를 찾았으며, 이는 모델 성능을 향상시키기 위한 지식 증류의 가능성을 강조한다.



### Plurals: A System for Guiding LLMs Via Simulated Social Ensembles (https://arxiv.org/abs/2409.17213)
- **What's New**: 최근 논의에서 언어 모델들이 특정 관점을 선호한다는 우려가 제기되었습니다. 이에 대한 해결책으로 '어디서도 바라보지 않는 시각'을 추구하는 것이 아니라 다양한 관점을 활용하는 방안을 제안합니다. 'Plurals'라는 시스템과 Python 라이브러리를 소개하게 되었습니다.

- **Technical Details**: Plurals는 다양한 관점을 반영하여 신뢰할 수 있는 소셜 에셈블을 생성하는 시스템으로, 사용자 맞춤형 구조 내에서 '대리인'(Agents)들이 심의(deliberation)를 진행하고, 보고자'(Moderators)가 이를 감독합니다. 이 시스템은 미국 정부의 데이터셋과 통합되어 국가적으로 대표적인 페르소나를 생성하면서 민주적 심의 이론에 영감을 받은 형식으로 사용자 정의가 가능합니다.

- **Performance Highlights**: 여섯 가지 사례 연구를 통해 이론적 일관성과 효용성(efficacy)을 보여주었고, 세 가지 무작위 실험에서는 생성된 산출물이 관련 청중의 온라인 샘플과 잘 맞아떨어짐을 발견했습니다. Plurals는 사용자가 시뮬레이션된 사회적 집단을 생성할 수 있도록 도와주며, 초기 연구 결과 또한 제시됩니다.



### An Effective, Robust and Fairness-aware Hate Speech Detection Framework (https://arxiv.org/abs/2409.17191)
Comments:
          IEEE BigData 2021

- **What's New**: 이 논문은 온라인 소셜 네트워크에서의 증오 발언을 효과적으로 탐지하기 위한 새로운 프레임워크를 제안합니다. 데이터 부족, 모델의 불확실성 추정, 악의적 공격에 대한 강인성 향상 및 공정성 처리의 한계를 극복하고자 합니다.

- **Technical Details**: 제안된 프레임워크는 Bidirectional Quaternion-Quasi-LSTM (BiQQLSTM) 계층을 포함하여 효과성과 효율성을 균형 있게 맞추고, 세 가지 플랫폼에서 수집한 다섯 개 데이터셋을 결합하여 일반화된 모델을 구축합니다. 데이터 증강 기법을 사용해 다양한 공격 및 텍스트 조작에 강한 모델을 만드는 데 주력합니다.

- **Performance Highlights**: 실험 결과, 제안한 모델은 공격이 없는 시나리오에서 8개의 최첨단 방법들보다 5.5% 향상된 성능을 보여주며, 다양한 공격 시나리오에서도 최고 기준 대비 3.1% 향상된 성능을 기록하여 모델의 효과성과 강인성을 입증했습니다.



### Fully automatic extraction of morphological traits from the Web: utopia or reality? (https://arxiv.org/abs/2409.17179)
- **What's New**: 이 논문은 최근의 대형 언어 모델(LLMs)을 활용하여 비구조적인 텍스트에서 식물의 형태학적 특성 정보를 자동으로 수집하고 처리하는 메커니즘을 제안합니다. 이를 통해 전문가가 수년간 수집해야 하는 복잡한 특성 정보를 손쉽게 구축할 수 있습니다.

- **Technical Details**: 제안된 방법론은 다음과 같은 세 가지 입력을 요구합니다: (i) 관심 있는 종의 목록, (ii) 관심 있는 특성 목록, 그리고 (iii) 각 특성이 가질 수 있는 모든 가능한 값의 목록. 이 프로세스는 검색 엔진 API를 사용하여 관련 URL를 가져오고, 이 URL에서 텍스트 콘텐츠를 다운로드합니다. 이후 NLP 모델을 통해 설명 문장을 판별하고, LLM을 사용하여 기술적 특성 값을 추출합니다.

- **Performance Highlights**: 이 방식으로 3개의 수작업으로 작성된 종-특성 행렬을 자동으로 복제하는 평가를 실시했습니다. 결과적으로 75% 이상의 F1-score를 달성하며, 50% 이상의 종-특성 쌍의 값을 찾는 데 성공했습니다. 이는 비구조적 온라인 텍스트로부터 구조화된 특성 데이터베이스를 대규모로 생성하는 것이 현재 가능하다는 점을 보여줍니다.



### CSCE: Boosting LLM Reasoning by Simultaneous Enhancing of Casual Significance and Consistency (https://arxiv.org/abs/2409.17174)
- **What's New**: 현재의 언어 모델(LLMs)에서 Chain-Based(체인 기반) 접근 방식에 의존하지 않고, 인과적 중요성(causal significance)과 일관성(consistency)을 동시에 고려할 수 있는 비체인 기반의 새로운 추론 프레임워크인 CSCE(Causal Significance and Consistency Enhancer)를 제안합니다.

- **Technical Details**: CSCE는 Treatment Effect(치료 효과) 평가를 활용하여 LLM의 손실 함수(loss function)를 맞춤화하고, 인과적 중요성과 일관성을 두 가지 측면에서 향상시킴으로써 인과관계를 정확히 파악하고 다양한 상황에서 견고하고 일관된 성능을 유지하도록 합니다. 이 프레임워크는 최대한의 추론 효율성을 위해 전체 추론 과정을 한 번에 출력합니다.

- **Performance Highlights**: CSCE 방법은 Blocksworld, GSM8K, Hanoi Tower 데이터셋에서 Chain-Based 방법들을 초월하여 높은 성공률과 빠른 처리 속도를 기록하며, 비체인 기반 방법이 LLM의 추론 작업을 완료하는 데에도 기여할 수 있음을 입증했습니다.



### A Multiple-Fill-in-the-Blank Exam Approach for Enhancing Zero-Resource Hallucination Detection in Large Language Models (https://arxiv.org/abs/2409.17173)
Comments:
          20 pages

- **What's New**: 본 논문에서는 이야기가 변경되는 문제를 해결하기 위해 다중 객관식 채우기 시험(multiple-fill-in-the-blank exam) 접근 방식을 포함한 새로운 환각(hallucination) 감지 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 원본 텍스트에서 여러 객체를 마스킹한 후 각 시험 응답이 원본 스토리라인과 일치하도록 LLM을 반복적으로 도와줍니다. 이 과정에서 발생하는 환각 정도를 채점하여 평가합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 기존 방법(SCGP)보다 우수한 성능을 보이며, SCGP와의 앙상블에서도 현저한 성능 향상을 나타냅니다.



### What Would You Ask When You First Saw $a^2+b^2=c^2$? Evaluating LLM on Curiosity-Driven Questioning (https://arxiv.org/abs/2409.17172)
- **What's New**: 본 논문에서는 대규모 언어 모델(LLM)의 새로운 지식 습득 가능성을 평가하기 위한 혁신적인 평가 프레임워크를 제안합니다. 이 프레임워크는 LLM이 과학적 지식을 소개하는 진술에 대한 질문을 생성하도록 유도하여, 처음 접하는 사람처럼 호기심을 가지고 질문하는 방식으로 평가합니다.

- **Technical Details**: 제안된 평가 방법은 호기심 기반 질문 생성(CDQG) 과제로, LLM이 처음 접하는 진술을 상상하며 즉각적으로 떠오르는 질문을 만들어내도록 프롬프트합니다. 생성된 질문은 관련성(relevance), 일관성(coherence), 다양성(diversity) 세 가지 주요 지표로 평가되며, 심리학 문헌에 뿌리를 두고 있습니다. 여러 모델의 성능을 비교 평가하기 위해 물리학, 화학 및 수학 분야의 1101개의 다양한 난이도의 진술로 구성된 합성 데이터셋을 수집했습니다.

- **Performance Highlights**: GPT-4와 Mistral 8x7b와 같은 대형 모델이 일관성 있고 관련성이 높은 질문을 잘 생성하는 반면, 크기가 작은 Phi-2 모델은 동등하거나 그 이상으로 효과적임을 발견했습니다. 이는 모델의 크기만으로 지식 습득 가능성을 판단할 수 없음을 나타냅니다. 연구 결과, 제안된 프레임워크는 LLM의 질문 생성 능력을 새로운 관점에서 평가할 수 있는 기회를 제공합니다.



### Cross-Domain Content Generation with Domain-Specific Small Language Models (https://arxiv.org/abs/2409.17171)
Comments:
          15 pages

- **What's New**: 이 연구는 여러 개별 데이터셋에서의 작은 언어 모델을 활용한 도메인 특정 콘텐츠 생성에 대한 새로운 접근 방식을 탐색합니다. 특히, 두 개의 서로 다른 도메인인 이야기 (story)와 레시피 (recipe)에 대한 모델을 비교하였습니다.

- **Technical Details**: 모델을 각각의 데이터셋에 대해 개별적으로 훈련시키는 방식이 사용되었으며, 사용자 정의 토크나이저 (custom tokenizer)를 적용하여 생성 품질을 크게 향상시켰습니다. 또한 Low-Rank Adaptation (LoRA)나 일반적인 파인튜닝 (fine-tuning) 방법으로 단일 모델을 두 도메인에 적용하려고 시도했지만 유의미한 결과를 얻지 못했습니다. 특히, 전체 파인튜닝(full fine-tuning)중 모델의 가중치 동결 없이 진행 시, 치명적 망각 (catastrophic forgetting)이 발생하였습니다.

- **Performance Highlights**: 지식 확장 전략 (knowledge expansion strategy)을 통해 모델이 이야기와 레시피를 요청에 따라 생성할 수 있도록 하였으며, 이는 서로 다른 데이터셋 간의 의미 있는 출력을 유지하도록 하였습니다. 연구 결과는 고정된 레이어를 가진 지식 확장이 작은 언어 모델이 다양한 도메인에서 콘텐츠를 생성하는 데 효과적인 방법임을 보여줍니다.



### REAL: Response Embedding-based Alignment for LLMs (https://arxiv.org/abs/2409.17169)
- **What's New**: 이 논문에서는 대규모 언어 모델(LLMs)과 인간의 선호를 일치시키기 위한 효율적인 데이터 선택 전략을 제안합니다. 기존 알고리즘의 한계를 극복하기 위해 의미 있는 응답 쌍을 선택하는 방법론을 개발하였습니다.

- **Technical Details**: 제안된 방법은 HH-RLHF 데이터셋에서 유사하지 않은 응답 쌍을 선택하여 LLM의 직접적인 정렬을 개선하며 라벨링 오류를 감소시키는 것을 목표로 합니다. 코사인 유사성을 기반으로 응답 쌍의 유용성을 평가하여 높은 품질의 학습 데이터를 형성합니다.

- **Performance Highlights**: 실험 결과, 유사하지 않은 응답 쌍을 사용한 모델이 대화 작업에서 최상의 승률을 기록하였으며, 라벨러의 작업을 최대 65%까지 절감하는 효율성을 보여주었습니다.



### BERTScoreVisualizer: A Web Tool for Understanding Simplified Text Evaluation with BERTScor (https://arxiv.org/abs/2409.17160)
- **What's New**: BERTScoreVisualizer는 BERTScore 메트릭의 토큰 매칭 정보를 시각화하여 텍스트 단순화 시스템의 품질 분석을 향상시키는 웹 애플리케이션입니다.

- **Technical Details**: 이 도구는 BERTScore의 정밀도, 재현율, F1 점수 외에 참조 텍스트와 후보 텍스트 간의 토큰 매칭 정보를 시각적으로 제공합니다. React 웹 애플리케이션으로 프론트엔드를 구현하고, Flask를 사용해 백엔드를 구성하여 BERT 추론 및 BERTScore 알고리즘을 처리합니다.

- **Performance Highlights**: BERTScoreVisualizer의 독창적인 기능은 각 토큰의 재현율 및 정밀도 점수를 팝업으로 표시하고, 매칭되지 않은 토큰을 강조하여 더 간편한 분석을 제공합니다. 이로 인해 텍스트 품질을 평가하는 데 있어 귀중한 인사이트를 제공합니다.



### Infer Human's Intentions Before Following Natural Language Instructions (https://arxiv.org/abs/2409.18073)
- **What's New**: 이 논문에서는 Ambiguous natural language instructions를 효과적으로 수행하기 위한 새로운 프레임워크인 Follow Instructions with Social and Embodied Reasoning (FISER)를 제안합니다. 이 프레임워크는 사람의 목표와 의도를 추론하는 단계를 명시적으로 포함합니다. 이는 AI 에이전트가 인간의 자연어 명령을 이해하고 협력적 작업을 더 잘 수행하도록 돕습니다.

- **Technical Details**: FISER는 두 가지 주요 구성 요소인 social reasoning과 embodied reasoning을 사용하여 모델이 인간의 의도를 명시적으로 추론할 수 있도록 합니다. 먼저 social reasoning을 통해 인간이 요청하는 하위 작업(sub-task)을 예측한 후, 이러한 지침을 로봇이 이해할 수 있는 작업으로 변환하는 Embodied reasoning 단계로 진행합니다. 또한, FISER는 계획 인식(plan recognition) 단계를 추가하여 인간의 전반적인 계획을 추론하는 데 도움을 줍니다.

- **Performance Highlights**: FISER 모델은 HandMeThat(HMT) 벤치마크에서 64.5%의 성공률을 기록하며, 이전의 end-to-end 접근법을 초월한 성능을 보여줍니다. 또한, FISER는 체인 오브 토트(Chain-of-Thought) 방식으로 GPT-4를 기반으로 한 강력한 기준과 비교했을 때도 우수한 결과를 도출했습니다. 이 결과는 인간의 의도에 대한 중간 추론을 명시적으로 수행하는 것이 AI의 성능을 개선하는 데 효과적임을 입증합니다.



### IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning (https://arxiv.org/abs/2409.18046)
Comments:
          Accepted to EMNLP 2024

- **What's New**: 최근 이미지 캡셔닝(image captioning) 분야에서 이미지-텍스트 데이터 쌍의 한계를 극복하기 위해 텍스트-전용(training) 교육 방법이 탐색되고 있습니다. 본 논문에서는 텍스트 데이터와 이미지 데이터 간의 모달리티 차이를 완화하기 위한 새로운 접근 방식으로 'Image-like Retrieval'을 제안합니다.

- **Technical Details**: 제안된 방법인 IFCap($\textbf{I}$mage-like Retrieval과 $\textbf{F}$requency-based Entity Filtering for Zero-shot $\textbf{Cap}$tioning)는 효율적인 이미지 캡셔닝을 위한 통합 프레임워크로, Fusion Module을 통해 검색된 캡션과 입력 특성을 통합하여 캡션 품질을 향상시킵니다. 또한 Frequency-based Entity Filtering 기술을 도입하여 더 나은 캡션 품질을 제공합니다.

- **Performance Highlights**: 광범위한 실험 결과, IFCap은 기존의 텍스트-전용 훈련 기반 제로샷 캡셔닝(zero-shot captioning) 방식에 비해 이미지 캡셔닝과 비디오 캡셔닝 모두에서 state-of-the-art 성능을 기록하는 것으로 나타났습니다.



### EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions (https://arxiv.org/abs/2409.18042)
Comments:
          Project Page: this https URL

- **What's New**: EMOVA(EMotionally Omni-present Voice Assistant)는 음성 대화에서 다양한 감정과 톤을 지원하며, 최첨단 비전-언어(vision-language) 및 음성(speech) 능력을 결합한 최초의 옴니모달(omni-modal) LLM입니다. 이 모델은 기존 비전-언어 및 음성-언어 모델의 한계를 극복하고, 실시간 대화의 요구를 충족합니다.

- **Technical Details**: EMOVA는 연속 비전 인코더와 의미-음향 분리된 음성 토크나이저를 사용하여 음성 이해 및 생성을 위한 엔드투엔드(end-to-end) 아키텍처를 갖추고 있습니다. 이를 통해 입력 음성의 의미적 내용과 음향적 스타일을 분리하여 다양한 음성 스타일 조절을 지원합니다.

- **Performance Highlights**: EMOVA는 첫 번째로 비전-언어 및 음성 벤치마크에서 최첨단 성능을 달성하였으며, 공공 데이터셋을 활용하여 옴니모달 정렬을 효율적으로 수행하고, 생생한 감정을 담은 음성 대화를 지원합니다.



### Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspectiv (https://arxiv.org/abs/2409.18028)
- **What's New**: 본 연구는 큰 언어 모델(LLM)이 동일한 컨텍스트 내에서 여러 하위 작업을 수행하는 능력에 한계가 있음을 지적하고, 이를 극복하기 위해 멀티 에이전트 시스템을 활용한 문제 해결 방안을 제시합니다.

- **Technical Details**: 본 연구에서는 생성 복잡도(Generation Complexity)라는 지표로 LLM이 정확한 솔루션을 샘플링하기 위해 필요한 생성 횟수를 정량화 하며, 복합 코딩 문제에서 LLM과 멀티 에이전트 시스템 간의 성능 차이를 분석합니다. LLM을 오토회귀 모델로 모델링하고, 두 개의 다른 문제를 독립적으로 해결하는 방법을 논의합니다.

- **Performance Highlights**: 실험적으로, Llama 3 모델을 사용하여 복합 코드 문제에 대한 생성 복잡도의 기하급수적 차이를 입증하였으며, 이는 동일한 컨텍스트 내에서 문제를 해결하기에 LLM이 더 어려움을 겪는 다는 것을 보여줍니다.



### An Adversarial Perspective on Machine Unlearning for AI Safety (https://arxiv.org/abs/2409.18025)
- **What's New**: 이번 연구는 기존의 unlearning(언러닝) 방법이 안전성 훈련(safety training)에서의 위험한 정보 제거를 효과적으로 대체할 수 있는지를 조명합니다. 연구자들은 unlearning이 단순히 정보를 숨기는데 그치고, 위험한 지식이 여전히 회복될 수 있음을 보여줍니다.

- **Technical Details**: 이 논문은 RMU(Residual Memory Unlearning)와 같은 상태-of-the-art unlearning 방법을 평가하며, WMDP(WMD Probing) 벤치마크를 사용하여 안전성 훈련과 비교합니다. 기존 보고된 jailbreak 방법들은 unlearning에 무효로 간주되었으나, 세심하게 적용될 경우 여전히 효과적일 수 있음을 발견하였습니다. 이들은 특정 활성 공간 방향을 제거하거나 무관한 예제를 가진 finetuning을 통해 원래의 성능을 복구할 수 있는 방법을 제시합니다.

- **Performance Highlights**: 연구 결과, unlearning 방법은 특정 공격에 보다 강해 보이지만, 안전성 훈련에 사용된 기법으로 쉽게 우회될 수 있습니다. 특히, GCG와 같은 jailbreak 기법은 손실 함수를 약간 변경함으로써 의미 있는 정확도를 회복할 수 있음을 보여주었습니다.



### Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models (https://arxiv.org/abs/2409.17990)
Comments:
          Code available at this https URL

- **What's New**: 이번 연구에서는 사회 미디어 데이터의 종단적 분석을 위한 도구로, 시간적으로 정렬된 Large Language Models (LLMs)을 제안합니다. 이 연구는 사용자 생성 데이터를 기반으로 Temporal Adapters를 Llama 3 8B에 맞춰 조정하여 긴 시간에 걸쳐 감정과 태도를 추출합니다.

- **Technical Details**: Temporal Adapters를 통해 Llama 3 8B 모델을 조정하고, 24,000명의 영국 Twitter 사용자로부터 2019년 11월부터 2020년 6월까지의 데이터를 기반으로 데이터를 수집합니다. 조정된 모델에 여러 설문지로부터 프롬프트를 제공하여 토큰 확률로부터 longitudinal affect aggregates를 추출합니다.

- **Performance Highlights**: 우리의 추정치는 영국 성인 집단의 설문 데이터와 강한 긍정적 상관관계를 보였으며, 전통적인 분류 모델을 사용했을 때와 일관성 있는 결과를 보여줍니다. 이 방법은 기존의 LLM을 피드백해서 사용자 생성 데이터에 맞추도록 조정하여 감정 집합의 변화를 연구하는 데 유용합니다.



### Weak-To-Strong Backdoor Attacks for LLMs with Contrastive Knowledge Distillation (https://arxiv.org/abs/2409.17946)
- **What's New**: 이번 연구에서는 Parameter-Efficient Fine-Tuning (PEFT)을 사용하는 대규모 언어 모델(LLMs)에 대한 백도어 공격의 효율성을 검증하고, 이를 개선하기 위한 새로운 알고리즘인 W2SAttack(Weak-to-Strong Attack)을 제안합니다.

- **Technical Details**: W2SAttack은 약한 모델에서 강한 모델로 백도어 특징을 전이하는 대조적 지식 증류(constractive knowledge distillation) 기반의 알고리즘입니다. 이 알고리즘은 소규모 언어 모델을 사용하여 완전 파라미터 미세 조정을 통해 백도어를 임베드하고 이를 교사 모델로 활용하여 대규모 학생 모델로 전이합니다. 이 과정에서 정보를 최소화하여 학생 모델이 목표 레이블과 트리거 간의 정렬을 최적화하도록 합니다.

- **Performance Highlights**: W2SAttack은 여러 언어 모델과 백도어 공격 알고리즘을 대상으로 한 실험 결과에서 100%에 가까운 성공률을 기록했습니다. 이는 PEFT를 사용한 기존 백도어 공격의 성능을 크게 개선한 결과입니다.



### Unveiling the Potential of Graph Neural Networks in SME Credit Risk Assessmen (https://arxiv.org/abs/2409.17909)
- **What's New**: 본 논문은 그래프 신경망 (Graph Neural Network)을 활용한 기업 신용 위험 평가 모델을 제안하며, 기업 재무 지표 간의 내재적 연결을 통합합니다.

- **Technical Details**: 29개의 기업 재무 데이터 지표를 선택하고 각 지표를 정점 (vertex)으로 추상화했습니다. 유사도 행렬 (similarity matrix)을 구성하고 최대 신장 트리 알고리즘 (maximum spanning tree algorithm)을 사용하여 기업의 그래프 구조 매핑을 수행했습니다. 매핑된 그래프의 표현 학습 단계에서 그래프 신경망 모델을 구축하여 32차원의 임베딩 표현을 얻었습니다. 세 가지 GraphSAGE 연산을 수행하고 Pool 연산을 통해 결과를 집계했습니다.

- **Performance Highlights**: 실제 기업 데이터에 대한 실험 결과, 제안된 모델은 다단계 신용 수준 추정 작업을 효과적으로 수행하며, ROC 및 기타 평가 기준에 따라 모델의 분류 효과가 중요하고 안정성 (robustness)도 뛰어나며, 다양한 지표 데이터 간의 내재적 연결을 심층적으로 표현합니다.



### Revisiting Acoustic Similarity in Emotional Speech and Music via Self-Supervised Representations (https://arxiv.org/abs/2409.17899)
- **What's New**: 이 연구는 음성 감정 인식(SER)과 음악 감정 인식(MER) 간의 지식을 전이할 수 있는 가능성을 탐구하고, 자가 감독 학습(Self-Supervised Learning, SSL) 모델에서 추출된 공통의 음향 특징을 활용하여 감정 인식 성능을 향상시키는 방법을 제시합니다.

- **Technical Details**: 이 연구에서는 RAVDESS 데이터셋을 사용하여 SSL 모델의 층별 행동을 분석하고, 두 단계의 미세 조정을 통해 SER과 MER 간의 도메인 적응 방법을 비교합니다. 또한, Frechet 오디오 거리(Frechet audio distance)를 사용하여 감정별로 음성 및 음악의 음향 유사성을 평가합니다. 세 가지 SSL 모델(Wav2Vec 2.0, HuBERT, MERT)을 적용하여 각 모델의 음성 및 음악 데이터에서의 성능을 조사합니다.

- **Performance Highlights**: 연구 결과, SER과 MER에서 SSL 모델이 공통된 음향 특징을 잘 포착하긴 하지만, 각기 다른 감정에 따라 그 행동이 다르게 나타납니다. 또한, 효율적인 매개변수 기반 미세 조정을 통해 서로의 지식을 활용하여 SER과 MER 성능을 향상할 수 있음을 보여줍니다.



### Implementing a Nordic-Baltic Federated Health Data Network: a case repor (https://arxiv.org/abs/2409.17865)
Comments:
          24 pages (including appendices), 1 figure

- **What's New**: 이 논문에서는 북유럽-발트해 지역에서 건강 데이터의 2차 사용을 촉진하기 위해 5개국 6개 기관으로 구성된 연합 건강 데이터 네트워크(federated health data network)를 개발하는 과정에서 얻은 초기 경험을 공유합니다.

- **Technical Details**: 이 연구는 혼합 방법(mixed-method approach)을 사용하여 실험 설계(experimental design)와 실행 과학(implementation science)을 결합하여 네트워크 구현에 영향을 미치는 요소를 평가했습니다. 실험 결과, 중앙 집중식 시뮬레이션(centralized simulation)과 비교할 때, 네트워크는 성능 저하(performance degradation) 없이 기능한다는 것을 발견했습니다.

- **Performance Highlights**: 다학제적 접근 방식(interdisciplinary approaches)을 활용하면 이러한 협력 네트워크(collaborative networks)를 구축하는 데 따른 도전 과제를 해결할 수 있는 잠재력이 있지만, 규제 환경이 불확실하고 상당한 운영 비용(operational costs)이 발생하는 것이 문제로 지적되었습니다.



### SECURE: Semantics-aware Embodied Conversation under Unawareness for Lifelong Robot Learning (https://arxiv.org/abs/2409.17755)
Comments:
          10 pages,4 figures, 2 tables

- **What's New**: 본 연구는 로봇이 작업 수행에 필요한 개념을 인식하지 못한 상황에서 진행되는 상호작용적 작업 학습(interactive task learning) 문제를 다루며, 이를 해결하기 위한 새로운 프레임워크 SECURE를 제안합니다.

- **Technical Details**: SECURE는 상징적 추론(symbolic reasoning)과 신경 기초(neural grounding)를 결합하여 로봇이 대화 중에 새로운 개념을 인식하고 학습할 수 있도록 설계되었습니다. 이 프레임워크는 서울대학교의 대학원 연구팀이 개발하였으며, 기존의 기계 학습 모델이 가지는 한계를 극복하고 지속적인 개념 학습을 가능하게 합니다.

- **Performance Highlights**: SECURE를 이용한 로봇은 이전에 알지 못했던 개념을 효과적으로 학습하고, 그로 인해 무의식적 인식 상태에서도 작업 재배치 문제를 성공적으로 해결할 수 있음을 보여주었습니다. 이러한 결과는 로봇이 대화의 의미 논리(semantics)적 결과를 활용하여 보다 효과적으로 학습할 수 있음을 입증합니다.



### Are Transformers in Pre-trained LM A Good ASR Encoder? An Empirical Study (https://arxiv.org/abs/2409.17750)
Comments:
          8pages

- **What's New**: 이번 연구에서는 사전 훈련된 언어 모델(PLM) 내에서 변환기(transformers)의 효능을 탐구하며, 이들이 자동 음성 인식(ASR) 시스템의 인코더로서 어떻게 재활용되는지를 논의합니다. 변환기들은 텍스트 기반의 데이터로 훈련되었음에도 불구하고, 음성 데이터에서도 효과적으로 기능을 수행할 수 있다는 가설을 세우고 있습니다.

- **Technical Details**: 우리의 ASR 모델은 Connectionist Temporal Classification (CTC) 기반의 인코더 전용 아키텍처를 채택합니다. 입력 오디오 피쳐 시퀀스와 이에 대응하는 타겟 레이블 시퀀스를 사용하여 CTC 손실 함수가 정의되며, Qwen 모델의 변환기들이 인코더의 설정에서 핵심 역할을 합니다.

- **Performance Highlights**: 실험 결과, PLM에서 파생된 변환기를 사용한 모델들은 CER 및 WER에서 다수의 ASR 작업에서 유의미한 성능 향상을 보여주었으며, 특히 심도 있는 의미 이해가 중요한 시나리오에서 성능을 크게 개선할 수 있었음이 발견되었습니다.



### Few-shot Pairwise Rank Prompting: An Effective Non-Parametric Retrieval Mod (https://arxiv.org/abs/2409.17745)
Comments:
          Accepted to EMNLP 2024

- **What's New**: 이번 연구에서는 기존의 감독 학습 방식의 복잡성을 줄이고, 대규모 언어 모델(LLM) 기반의 간단한 순위 모델을 제안하여 제로샷(zero-shot) 환경에서도 효과적인 성능 향상을 이끌어냈습니다.

- **Technical Details**: 제안된 방법은 쿼리와 문서 쌍을 기준으로 유사한 쿼리들의 선호 예시를 활용하여, 쿼리와 문서의 쌍에 대한 상대적 선호 순서를 예측합니다. 이는 대규모 언어 모델의 언어 처리 능력을 이용한 몇 샷(few-shot) 프롬프트를 통해 이루어집니다. 이를 통해 기존의 제로샷 모델보다 지속적으로 성능이 개선되었음을 보였습니다.

- **Performance Highlights**: 제안된 모델은 TREC DL과 BEIR 서브셋 벤치마크에서 제로샷 기준선보다 일관된 향상을 보였으며, 복잡한 훈련 파이프라인 없이 감독 모델과 유사한 성능을 달성했습니다. 또한, MS-MARCO의 예시 쿼리를 이용한 실험에서 TREC Covid과 SciFact 테스트 컬렉션에 대한 아웃 오브 도메인 일반화의 가능성을 보여주었습니다.



### Digital Twin Ecosystem for Oncology Clinical Operations (https://arxiv.org/abs/2409.17650)
Comments:
          Pre Print

- **What's New**: 이 논문은 인공지능(AI)과 디지털 트윈(Digital Twin) 기술을 활용하여 종양학(oncology) 분야의 임상 운영을 혁신적으로 향상시키기 위한 새로운 디지털 트윈 프레임워크를 소개합니다. 여러 전문 디지털 트윈을 통합하여 각 환자에 대한 개인화된 치료를 가능하게 하며, 이는 기존의 데이터와 NCCN 가이드라인에 기반하여 클리닉 추천을 제공합니다.

- **Technical Details**: 이 프레임워크는 Medical Necessity Twin, Care Navigator Twin, Clinical History Twin과 같은 여러 개의 전문 디지털 트윈을 활용하여 환자 맞춤형 치료와 워크플로우 효율성을 높입니다. 각 디지털 트윈은 실시간 데이터 교환을 통해 작동하며, 이를 통해 환자의 유일한 데이터에 기반한 개인화된 care path를 생성하여 ACA 데이터를 통합합니다. 이 시스템은 또한 여러 지식 기반을 통합하여 복잡한 상호작용을 시뮬레이션하는 멀티 에이전트 시스템(Multi-Agent Systems)은 의사결정 지원 및 care coordination을 강화할 수 있습니다.

- **Performance Highlights**: 이 논문에서 제시한 사례 연구는 다양한 에이전트들이 어떻게 협력하여 워크플로우를 간소화하고, 적시의 임상 추천을 제공할 수 있는지를 보여줍니다. 디지털 트윈 기술과 AI의 결합으로 인해 임상 결정의 정확성과 환자 맞춤형 치료의 효율성이 크게 향상됩니다.



### On the Implicit Relation Between Low-Rank Adaptation and Differential Privacy (https://arxiv.org/abs/2409.17538)
- **What's New**: 이번 논문에서는 자연어 처리에서의 저차원(adaptation) 접근법이 데이터 프라이버시(data privacy)와 어떻게 연결되는지를 제시합니다. 특히, LoRA(Lo-Rank Adaptation)와 FLoRA(Fully Low-Rank Adaptation)의 방법이 미치는 영향을 분석하여, 이들이 데이터 민감도를 고려한 저차원 적응과 유사하다는 것을 보여줍니다.

- **Technical Details**: LoRA와 FLoRA는 언어 모델 언어를 특정 작업에 적응시키기 위해 몇 개의 레이어에 훈련 가능한 저차원 분해 매트릭스(adapter)를 통합하여, 사전 훈련된 모델의 가중치를 고정한 상태에서 사용됩니다. 이 접근법은 전통적인 매개변수 조정(full fine-tuning) 방식에 비해 필요한 훈련 가능한 매개변数의 수를 상당히 줄입니다. 연구진은 또한 저차원 적응이 DPSGD(Differentially Private Stochastic Gradient Descent)와 근본적으로 유사하다는 것을 입증하며, 가우시안 분포(Gaussian distribution)와의 변동성(variance)도 분석합니다.

- **Performance Highlights**: 연구의 주요 기여는 다음과 같습니다: 1) LoRA/FLoRA로 저차원 적응을 수행하는 것이 어댑터의 배치 그라디언트(batch gradients)에 무작위 노이즈를 주입하는 것과 동등하다는 것을 보여줍니다. 2) 주입된 노이즈의 분산을 찾아 노이즈가 입력 수와 저차원 적응의 순위(rank)가 증가함에 따라 가우시안 분포에 가까워지게 됨을 증명합니다. 3) 저차원 적응의 동역학은 DP 완전 조정(DP full fine-tuning) 어댑터와 매우 유사함을 입증하며, 이러한 저차원 적응이 데이터 프라이버시를 제공할 수 있는 가능성을 제시합니다.



### When A Man Says He Is Pregnant: ERP Evidence for A Rational Account of Speaker-contextualized Language Comprehension (https://arxiv.org/abs/2409.17525)
- **What's New**: 이번 연구는 발화와 화자 간의 맥락을 이해하는 과정에서 나타나는 두 가지의 서로 다른 ERP (event-related potential) 효과인 N400과 P600에 대해 다루고 있습니다. 화자와 메시지 간의 불일치 상황에서 신경생리학적 반응을 분석했습니다.

- **Technical Details**: 연구에 참여한 64명의 참가자를 대상으로 한 실험에서, 말의 의미를 이해하기 위해서 사회적 고정관념을 위반하는 경우에는 N400 효과가 발생하고, 생물학적 지식을 위반하는 경우에는 P600 효과가 발생함을 발견했습니다.

- **Performance Highlights**: 참가자의 개성 중 개방성(openness) 성향에 따라 사회적 N400 효과는 감소했지만, 생물학적 P600 효과는 여전히 강력하게 나타났습니다. 이러한 결과는 기존의 연구에서 나타난 경량한 불일치를 해소하는 데 기여합니다.



### Comparing Unidirectional, Bidirectional, and Word2vec Models for Discovering Vulnerabilities in Compiled Lifted Cod (https://arxiv.org/abs/2409.17513)
Comments:
          6 pages, 2 figures

- **What's New**: 이 연구는 LLVM 코드에서 GPT 모델을 처음부터 훈련하여 생성된 임베딩을 사용해 특정 취약성(예: buffer overflows)을 찾는 결과를 제공합니다. 또한 단방향 변환기(GPT-2)와 양방향 변환기(BERT, RoBERTa) 및 비변환기 기반 임베딩 모델(Skip-Gram, Continuous Bag of Words)의 영향을 비교하고 있습니다.

- **Technical Details**: 연구는 먼저 NIST SARD Juliet 데이터 세트에서 코드 샘플을 선택한 후, RetDec 도구를 사용하여 LLVM으로 변환한 다음 사전 처리를 진행하였습니다. 이후 CWE-121 샘플을 사용하여 GPT-2 모델의 임베딩을 생성하고, 이러한 임베딩을 LSTM 신경망 훈련에 사용하였습니다.

- **Performance Highlights**: GPT-2로부터 생성된 임베딩은 BERT 및 RoBERTa의 양방향 모델보다 뛰어난 성능을 보여주었으며, 92.5%의 정확도와 89.7%의 F1 점수를 기록했습니다. 또한 SGD 옵티마이저가 Adam보다 우수한 성능을 나타냈습니다.



### HaloScope: Harnessing Unlabeled LLM Generations for Hallucination Detection (https://arxiv.org/abs/2409.17504)
Comments:
          NeurIPS 2024 Spotlight

- **What's New**: 이번 논문에서는 HaloScope라는 새로운 학습 프레임워크를 소개합니다. 이 프레임워크는 레이블이 없는 LLM 생성물을 활용하여 hallucination을 탐지하는 데 중점을 두고 있습니다. 기존의 신뢰성 분류기 학습의 주요 어려움인 레이블이 붙은 데이터 부족 문제를 해결하기 위한 접근법을 제시합니다.

- **Technical Details**: HaloScope는 자동화된 membership estimation score를 통해 레이블이 없는 데이터에서 진실한 생성물과 허위 생성물을 구분합니다. 이 프레임워크는 LLM의 잠재적 표현(latent representations)을 활용하여 허위 진술과 관련된 서브스페이스를 식별하고, 이를 통해 이진 진실성 분류기를 훈련할 수 있도록 합니다.

- **Performance Highlights**: HaloScope는 다양한 데이터셋에 걸쳐 hallucination 탐지 성능을 향상시켰으며, TruthfulQA 벤치마크에서 기존의 최첨단 방법 대비 10.69% (AUROC) 향상된 정확도를 기록했습니다. 이로 인해 HaloScope의 실용성과 유연성이 강화되었습니다.



### MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models (https://arxiv.org/abs/2409.17481)
Comments:
          NeurIPS 2024 Spotlight

- **What's New**: 이번 연구는 MaskLLM이라는 새로운 learnable pruning (학습 가능한 가지치기) 방법을 제안합니다. 이 방법은 LLM (대규모 언어 모델)의 Semi-structured (반구조적) sparsity (희소성)을 통해 추론 시 계산 비용을 줄이는 데 초점을 맞추고 있습니다.

- **Technical Details**: MaskLLM은 Gumbel Softmax sampling (검벨 소프트맥스 샘플링)을 활용하여 N:M 패턴을 학습 가능한 분포로 모델링합니다. 이 방법은 N개의 비제로 값과 M개의 매개변수 사이의 관계를 설정하여 대규모 데이터 집합에서 end-to-end training (엔드투엔드 훈련)을 수행할 수 있게 합니다.

- **Performance Highlights**: MaskLLM은 LLaMA-2, Nemotron-4, GPT-3와 같은 여러 LLM을 사용하여 2:4 sparsity 설정 하에 평가되었습니다. 기존의 최첨단 방법에 비해 PPL (perplexity) 측정에서 유의미한 개선을 보였으며, 특히 SparseGPT의 10.42에 비해 MaskLLM은 6.72의 PPL을 달성하였습니다. 이 결과는 MaskLLM이 대규모 모델에서도 효과적으로 고품질 마스크를 학습할 수 있음을 나타냅니다.



### RED QUEEN: Safeguarding Large Language Models against Concealed Multi-Turn Jailbreaking (https://arxiv.org/abs/2409.17458)
- **What's New**: 이 논문에서는 새로운 jailbreak 공격 방법인 Red Queen Attack을 제안합니다. 이 방법은 다단계(멀티턴) 시나리오를 활용하여 악의적인 의도를 숨기고, 14가지 유해 카테고리에서 56,000개의 멀티턴 공격 데이터를 생성합니다.

- **Technical Details**: Red Queen Attack은 다양한 직업과 관계에 기반하여 40개의 시나리오를 구성하며, GPT-4o, Llama3-70B 등 4개의 대표적인 LLM 가족에 대해 87.62% 및 75.4%의 높은 성공률을 기록했습니다. Red Queen Guard라는 완화 전략도 제안하여, 공격 성공률을 1% 미만으로 줄입니다.

- **Performance Highlights**: 모든 LLM이 Red Queen Attack에 취약하며, 대형 모델일수록 공격에 더 민감하다는 사실이 발견되었습니다. 이 연구는 56k 멀티턴 공격 데이터셋과 함께 LLM의 안전성을 높이는 방법을 제시합니다.



### Description-based Controllable Text-to-Speech with Cross-Lingual Voice Contro (https://arxiv.org/abs/2409.17452)
Comments:
          Submitted to ICASSP 2025

- **What's New**: 이번 연구에서는 음성 생성을 위한 새로운 설명 기반의 제어 가능한 TTS 방법을 제안합니다. 이 방법은 교차 언어 제어 기능을 갖추고 있으며, 대상 언어에서 오디오-설명 쌍 데이터의 부족 문제를 해결하기 위해 다국어 간의 연관성을 활용합니다.

- **Technical Details**: 이 TTS 프레임워크는 세 가지 컴포넌트로 구성됩니다: NANSY++ 모델, TTS 음향 모델, 설명 제어 모델. NANSY++ 모델은 자가 학습(self-supervised learning)으로 페이지 분리된 음성 표현을 학습하며, 이를 통해 TTS 모델의 조건적 특징으로 사용되는 음조(timbre)와 스타일(style) 임베딩을 공유합니다. 또한, 설명 제어 모델은 입력된 텍스트 설명을 음조 및 스타일 임베딩으로 변환합니다.

- **Performance Highlights**: 영어와 일본어 TTS 실험 결과, 제안한 방법이 두 언어 모두에서 높은 자연스러움(naturalness)과 제어 가능성(controllability)을 달성하는 것으로 나타났습니다. 특히, 일본어 오디오-설명 쌍 데이터가 없어도 기존 시스템보다 개선된 pitch 및 speaking speed 제어 능력을 보여주었습니다.



### Post-hoc Reward Calibration: A Case Study on Length Bias (https://arxiv.org/abs/2409.17407)
Comments:
          Preprint

- **What's New**: 이 논문은 Large Language Models (LLMs)의 보상 모델 (Reward Model, RM)의 편향을 교정하는 데 도움을 주는 'Post-hoc Reward Calibration' 개념을 소개합니다. 이 접근법은 추가 데이터나 훈련 없이도 성능 향상을 가능하게 합니다.

- **Technical Details**: 편향된 보상을 분해하여 잠재적인 진짜 보상과 특정 특성에 의존하는 편향 항으로 나누는 방법론을 제시합니다. 이를 위해 Locally Weighted Regression 기법을 사용하여 편향을 추정하고 제거하는 방식을 채택하였습니다.

- **Performance Highlights**: 본 연구는 세 가지 실험 설정에서 다음과 같은 성과 향상을 입증하였습니다: 1) RewardBench 데이터셋의 33개 RM에서 평균 3.11 성능 향상, 2) AlpacaEval 벤치마크에 기반한 GPT-4 평가 및 인간 선호도와의 RM 순위 개선, 3) 다양한 LLM-RM 조합에서 RLHF 과정의 Length-Controlled 승률 향상.



### Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation (https://arxiv.org/abs/2409.17313)
Comments:
          EMNLP 2024 Findings; project page: this https URL

- **What's New**: 이 연구는 Vision-Language Navigation (VLN) 작업을 위한 새로운 평가 프레임워크를 제안합니다. 이 프레임워크는 다양한 지침 범주에 대한 현재 모델을 더 세분화된 수준에서 진단하는 것을 목표로 합니다. 특히, context-free grammar (CFG)를 기반으로 한 구조에서 VLN 작업의 지침 카테고리를 설계하고, 이를 Large-Language Models (LLMs)의 도움으로 반자동으로 구성합니다.

- **Technical Details**: 제안된 평가 프레임워크는 atom instruction, 즉 VLN 지침의 기본 행동에 집중합니다. CFG를 사용하여 지침의 구조를 체계적으로 구성하고 5개의 주요 지침 범주(방향 변화, 수직 이동, 랜드마크 인식, 영역 인식, 숫자 이해)를 정의합니다. 이 데이터를 활용하여 평가 데이터셋 NavNuances를 생성하고, 이를 통해 다양한 모델의 성능을 평가하며 문제가 드러나는 경우가 많았습니다.

- **Performance Highlights**: 실험 결과, 모델 간 성능 차이와 일반적인 문제점이 드러났습니다. LLM에 의해 강화된 제로샷 제어 에이전트가 전통적인 감독 학습 모델보다 방향 변화와 랜드마크 인식에서 더 높은 성능을 보였으며, 반면 기존 감독 접근 방식은 선택적 편향으로 인해 원자 개념 변화에 적응하는 데 어려움을 겪었습니다. 이러한 분석은 VLN 방식의 향후 발전에 중요한 통찰력을 제공합니다.



### On the Vulnerability of Applying Retrieval-Augmented Generation within Knowledge-Intensive Application Domains (https://arxiv.org/abs/2409.17275)
- **What's New**: 이 논문은 Retrieval-Augmented Generation (RAG) 시스템의 적대적 강인성(adversarial robustness)을 조사하였습니다. 특히, 의학 분야의 Q&A를 대상으로 한 '보편적인 중독 공격(universal poisoning attacks)'의 취약성을 분석하고 새로운 탐지 기반(defense) 방어 체계를 개발하였습니다.

- **Technical Details**: RAG 시스템은 외부 데이터에서 중요한 정보를 검색(retrieve)하고 이를 LLM의 생성 과정에 통합하는 두 가지 단계를 포함합니다. 이 연구에서는 225개 다양한 설정에서 RAG의 검색 시스템이 개인 식별 정보(PII)와 같은 다양한 타겟 정보를 포함하는 중독 문서에 취약하다는 것을 입증하였습니다. 중독된 문서는 쿼리의 임베딩과 높은 유사성을 유지함으로써 정확히 검색될 수 있음을 발견하였습니다.

- **Performance Highlights**: 제안한 방어 방법은 다양한 Q&A 도메인에서 뛰어난 탐지율(detection rates)을 일관되게 달성하며, 기존의 방어 방법에 비해 훨씬 효과적임을 보여주었습니다. 실험에 따르면 거의 모든 공격에 대해 일관되게 높은 탐지 성공률을 보였습니다.



### Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning (https://arxiv.org/abs/2409.17270)
- **What's New**: 이 연구에서는 LLM(대형 언어 모델)의 출력 신뢰성과 투명성을 높이기 위해 'Proof of Thought'라는 새로운 프레임워크를 소개합니다. 이 프레임워크는 LLM이 생성한 아이디어와 형식 논리 검증을 연결합니다.

- **Technical Details**: Proof of Thought는 사용자 친화적인 개념을 사용하는 JSON 기반의 도메인 특화 언어(DSL)로, 이를 통해 LLM의 출력을 1차 논리(First Order Logic) 구조로 변환하는 커스텀 인터프리터를 사용합니다. 이 방법은 논리적 구조와 인간이 이해할 수 있는 개념 사이의 균형을 이루도록 설계되었습니다.

- **Performance Highlights**: Proof of Thought는 StrategyQA 및 새로운 멀티모달 추론 작업에서 효과를 입증하였으며, 개방형 시나리오에서 향상된 성능을 보였습니다. 이는 AI 시스템의 책임성을 다루고, 높은 위험 도메인에서 인간의 관여를 위한 기초를 설정하는 데 기여합니다.



### StressPrompt: Does Stress Impact Large Language Models and Human Performance Similarly? (https://arxiv.org/abs/2409.17167)
Comments:
          11 pages, 9 figures

- **What's New**: 이번 연구는 Large Language Models (LLMs)가 인간과 유사한 스트레스 반응을 보이는지를 탐구하고, 다양한 스트레스 유도 프롬프트 하에서의 성능 변화를 평가합니다. 이는 스트레스의 심리적 원리를 바탕으로 한 새로운 종류의 프롬프트 세트, StressPrompt를 통해 이루어졌습니다.

- **Technical Details**: 연구에서는 심리학적 이론에 기반하여 설계된 100개의 프롬프트를 개발하였으며, 이는 각각 다른 수준의 스트레스를 유도하도록 설계되었습니다. 또한, LLM의 내부 상태와 성능에 미치는 스트레스의 영향을 측정하기 위한 '스트레스 스캐너'를 도입했습니다.

- **Performance Highlights**: 연구 결과, LLM은 중간 수준의 스트레스 하에서 최적의 성능을 보이며, 낮은 스트레스와 높은 스트레스 모두에서 성능이 저하되는 것으로 나타났습니다. 이는 Yerkes-Dodson 법칙에 부합하며, 고객 서비스, 의료, 응급 대응과 같은 실세계 시나리오에서 AI 시스템의 성능 유지의 중요성을 시사합니다.



### FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression (https://arxiv.org/abs/2409.17141)
- **What's New**: FineZip는 전통적 텍스트 압축 방법에 비해 54배 빠른 압축 시간을 달성함으로써 대규모 텍스트 압축에 대한 사용 가능성을 높입니다.

- **Technical Details**: FineZip는 '온라인' 및 '오프라인' 구성 요소를 결합하여 손실 없는 텍스트 압축을 수행하며, 파라미터 효율적 미세 조정(PEFT) 방식을 사용하여 압축하는 데이터를 Memorize(기억)합니다. 또한, 동적 컨텍스트 사이즈를 활용하여 각 토큰의 압축을 개선하고 병렬 처리 가능성을 높였습니다.

- **Performance Highlights**: FineZip는 기존의 LLMZip보다 약 54배 빠른 압축 성능을 보여주며, 압축 비율을 약 50% 향상시킵니다. 전통적인 알고리즘 기반 압축 방법에 비해 크게 개선된 압축 효율성을 자랑합니다.



### Assessing the Level of Toxicity Against Distinct Groups in Bangla Social Media Comments: A Comprehensive Investigation (https://arxiv.org/abs/2409.17130)
Comments:
          Accepted for publication in "18th International Conference on Information Technology and Applications (ICITA 2024)"

- **What's New**: 이번 연구는 방글라 언어에서 세 가지 특정 집단(트랜스젠더, 원주민, 이주민)에 대한 독성 댓글을 식별하기 위해 다양한 소셜 미디어 출처에서 자료를 수집하고 분석하는 새로운 접근을 제시합니다.

- **Technical Details**: 연구진은 Bangla-BERT, bangla-bert-base, distil-BERT, Bert-base-multilingual-cased와 같은 사전 훈련된 트랜스포머 모델을 사용하여 댓글을 분류합니다. 독성 수준은 높음, 중간, 낮음으로 나눠 측정되며, 정확도(accuracy), 재현율(recall), 정밀도(precision), F1-score 같은 다양한 평가 지표가 사용됩니다.

- **Performance Highlights**: Bangla-BERT 모델은 F1-score 0.8903을 달성하며 다른 대안 모델들을 초월하는 성능을 보였습니다. 이는 방글라 소셜 미디어 대화의 독성 문제를 세밀하게 드러내며, 다양한 인구 집단에 미치는 영향을 분석하여 온라인 차별과 해악 문제를 해결하는 데 기여합니다.



### Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Handy Appetizer (https://arxiv.org/abs/2409.17120)
Comments:
          This book contains 93 pages and 60 figures

- **What's New**: 이 책은 필독서로 인공지능(AI), 머신러닝(ML) 및 딥러닝(DL)이 빅데이터 분석 및 관리의 발전에 미치는 역할을 탐구합니다. 복잡한 수학 개념을 단순화하고, 직관적 시각화 및 실제 사례 연구를 제공하여 독자들이 신경망(neural networks) 및 Convolutional Neural Networks(CNNs)와 같은 기술이 어떻게 작동하는지를 이해하도록 돕습니다.

- **Technical Details**: 책에서는 Transformers, GPT, ResNet, BERT 및 YOLO와 같은 여러 고전 모델과 기술을 소개하며, 자연어 처리(natural language processing), 이미지 인식(image recognition) 및 자율 주행(autonomous driving) 분야에서의 응용을 강조합니다. 사전 훈련된(pre-trained) 모델의 중요성과 그들이 모델의 성능과 정확도를 향상시킬 수 있는 방법을 설명합니다. SQL 및 NoSQL 데이터베이스와 같은 주요 빅데이터 관리 기술의 개관과 Apache Hadoop 및 Spark와 같은 분산 컴퓨팅 프레임워크를 다룹니다.

- **Performance Highlights**: 딥러닝 및 빅데이터 관리 기술을 습득하는 것이 미래 인력에게 중요한 도구라 강조하며, 초보자부터 숙련된 전문가까지 모두에게 필수적인 자료로 자리 잡고 있습니다.



### Programming Every Example: Lifting Pre-training Data Quality like Experts at Sca (https://arxiv.org/abs/2409.17115)
Comments:
          45 pages, 13 figures, 34 tables

- **What's New**: 이번 연구에서는 사전 훈련된 대형 언어 모델에 대해 새로운 접근법인 ProX(Programming Every Example)를 제안합니다. 이는 데이터 정제를 프로그래밍 작업으로 간주하여, 각 개별 예제에 대해 정교한 작업을 생성하고 실행할 수 있게 합니다.

- **Technical Details**: ProX는 모델이 각각의 데이터 예제를 정제하기 위해 필요한 작업을 프로그래밍 방식으로 정의할 수 있도록 하여, 기존의 왜곡된 데이터를 정제하는 데 필요한 유연성을 제공합니다. 이는 문자열 정규화, 데이터 세분화 등의 작업을 포함하여, 0.3B 파라미터를 가진 소형 모델도 인간 전문가와 비슷한 정제 능력을 발휘할 수 있음을 보여줍니다.

- **Performance Highlights**: ProX로 정제된 데이터로 사전 훈련된 모델은 원래 데이터나 다른 필터링 기법으로 정제된 데이터에 비해 다양한 하위 벤치마크에서 2% 이상의 성능 향상을 보였습니다. 특히, OpenWebMath 데이터 세트에서 ProX로 정제된 모델은 Mistral-7B에 비해 평균 정확도가 7.6% 개선되었고, Llama-2-7B에서는 14.6%, CodeLlama-7B에서는 20.3% 향상되었습니다.



### Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition (https://arxiv.org/abs/2409.17073)
- **What's New**: 이 논문은 질문-응답 시스템의 신뢰성을 높이기 위한 정보 출처 표기(attribution) 방법을 다루고 있습니다. 특히 긴 문서에 대한 응답의 출처를 정확히 표기하는 방법에 중점을 두고 있으며, 기존의 표기 방법과는 달리 정보 단위(information units)를 식별하는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 저자는 응답을 사실 기반으로 분해하는 factual decomposition 방법을 제안하며, template-based in-context learning 기법을 사용하여 질문과의 맥락을 고려한 응답 분해를 수행합니다. 또한, negative sampling 기법을 통하여 올바른 분해를 구분할 수 있게 합니다.

- **Performance Highlights**: 실험 결과, context를 고려한 coarse-grain decomposition을 사용한 경우, BM25, GTR, MonoT5 기반의 retrieval 시스템에서 평균 3%의 정확도 향상을 보였습니다. 이로 인해 QASPER 및 Verifiability 데이터셋에서 state-of-the-art 성능을 달성하였습니다.



### Detecting Temporal Ambiguity in Questions (https://arxiv.org/abs/2409.17046)
Comments:
          Accepted at EMNLP 2024 Findings

- **What's New**: 이번 연구에서는 TEMPAMBIQA라는 새로운 데이터셋을 소개합니다. 이 데이터셋은 8,162개의 오픈 도메인 질문으로 구성되어 있으며, 시간적 애매함(temporal ambiguity)을 포착할 수 있도록 수작업으로 주석 처리되었습니다.

- **Technical Details**: TEMPAMBIQA 데이터셋은 시간적 애매함을 연구하기 위해 설계되었으며, 3,879개의 애매한 질문과 4,283개의 명확한 질문을 포함합니다. 다양한 검색 전략을 사용하여 질문의 시간적 애매함을 감지하는 새로운 접근 방식을 제안합니다.

- **Performance Highlights**: 초기 성능 기준을 설정하며, Zero-Shot Question Classification과 Few-Shot Question Classification을 활용한 질문 분류 방법이 효과적임을 보였습니다. BERT(base 모델)를 미세 조정(Fine-Tuned)하여 질문 분류 작업에 사용했습니다. 실험 결과, 여러 모델이 성능을 발휘했으며, 시간적 문맥을 이해하는 데 중요한 진전을 이루었습니다.



### How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does No (https://arxiv.org/abs/2409.17044)
- **What's New**: 대형 언어 모델(LLM)의 성과가 두드러진 가운데, 본 연구는 음성 인식을 위한 다양한 구성요소(SFM, adapter, LLM)가 하위 작업 성과에 미치는 영향을 최초로 분석합니다.

- **Technical Details**: 다양한 adapter 모듈과 LLM, SFM을 이용하여 자동 음성 인식(ASR) 및 음성 번역(ST) 작업을 수행하였으며, SFM과 LLM의 조합에 따라 최적의 adapter 디자인이 달라짐을 규명하였습니다.

- **Performance Highlights**: SFM의 선택에 따라 ASR와 ST 성능이 평균적으로 각각 1 WER 및 2 COMET 포인트 이상 차이가 발생하였다. 따라서 length adapter의 디자인은 선택된 SFM 및 LLM에 크게 의존하는 것이 밝혀졌습니다.



### LLM-CARD: Towards a Description and Landscape of Large Language Models (https://arxiv.org/abs/2409.17011)
Comments:
          ongoing work, 16 pages

- **What's New**: 이번 연구는 자연어 처리(NLP) 분야에서 빠르게 성장하는 대형 언어 모델(LLM)에 대한 중요한 정보를 자동으로 추출하고 정리하는 시스템을 개발했습니다. 이 시스템은 논문에서 LLM에 관한 정보를 효율적으로 검색할 수 있도록 하는 LLM 모델 카드를 생성합니다.

- **Technical Details**: 이 연구에서는 명명된 개체 인식(Named Entity Recognition, NER)과 관계 추출(Relation Extraction, RE) 방법을 사용하여 LLM에 대한 주요 정보를 자동으로 추출합니다. 106개의 학술 논문을 처리하여 3개의 사전(LLM 이름, 라이센스, 응용)을 정의하고, 11,051개의 문장을 추출하였으며 최종적으로 129개의 문장과 106개의 문장을 수작업으로 검토하여 데이터 세트를 구축하였습니다.

- **Performance Highlights**: 이 시스템은 연구자들이 LLM에 대한 정보에 쉽게 접근할 수 있도록 돕고, 라이센스 유형, 활용 분야 등을 간단하게 이해할 수 있게 합니다. 또한, 자동화를 통해 연구자들이 시간이 절약되고 혁신에 집중할 수 있는 기회를 제공합니다.



### Decoding Large-Language Models: A Systematic Overview of Socio-Technical Impacts, Constraints, and Emerging Questions (https://arxiv.org/abs/2409.16974)
Comments:
          28 pages, 5 figures, preprint submitted to journal

- **What's New**: 최근 대형 언어 모델(LLM)의 발전이 자연어 처리(NLP)와 인공지능(AI) 분야에 혁신적인 변화를 가져왔습니다. 이 연구에서는 LLM의 개발 방향, 영향력 및 한계에 대한 체계적인 문헌 조사를 수행하였습니다.

- **Technical Details**: 논문은 LLM 연구의 목표, 방법론, 제한 사항 및 향후 방향성을 서술하며, 알고리즘 개선, 윤리적 도전 과제, 사회적 영향을 포함하여 책임 있는 개발에 대한 고려 사항을 포함합니다. 또한, 체계적인 리뷰 방법론을 통해 문헌을 분석하고, 150회 이상의 인용된 61개의 주요 논문을 선정했습니다.

- **Performance Highlights**: LLM은 번역, 분류, 질문-응답, 요약 및 정보 검색과 같은 복잡한 작업을 수행하는 데 탁월한 성능을 보여줍니다. 특히, GPT-3와 같은 모델은 창의적인 콘텐츠 생성과 대화 시뮬레이션에서 뛰어난 다양한 기능을 발휘하고 있습니다.



### Adaptive Self-Supervised Learning Strategies for Dynamic On-Device LLM Personalization (https://arxiv.org/abs/2409.16973)
Comments:
          First ASLS

- **What's New**: 이번 논문에서는 Adaptive Self-Supervised Learning Strategies (ASLS)를 제안합니다. ASLS는 대규모 언어 모델(LLMs)을 사용자 개인의 선호도에 맞게 동적으로 개인화하는 혁신적인 방법으로, 라벨이 있는 데이터셋의 필요성을 줄이고 실시간 피드백을 기반으로 모델을 조정합니다.

- **Technical Details**: ASLS는 사용자 프로파일링 레이어와 신경망 적응 레이어의 이중 레이어 구조로 구성되어 있습니다. 사용자와의 상호작용 데이터를 수집하여 모델을 실시간으로 미세 조정하며, 이는 계속해서 사용자 피드백을 학습하여 사용자별 맞춤형 응답을 생성합니다. 이 접근법은 계산 자원을 절약하고 개인화 효율성을 높입니다.

- **Performance Highlights**: 다양한 사용자 시나리오에 대한 실험 결과, ASLS는 기존의 개인화 방법 대비 사용자의 참여도와 만족도를 크게 향상시켰습니다. 이러한 결과는 ASLS가 대규모 언어 모델을 보다 반응성이 뛰어나고 맥락을 인지하는 시스템으로 변모시킬 잠재력을 보여줍니다.



### Weighted Cross-entropy for Low-Resource Languages in Multilingual Speech Recognition (https://arxiv.org/abs/2409.16954)
Comments:
          5 pages, 1 figure. Presented at Interspeech 2024

- **What's New**: 이번 논문에서는 저자들이 저자원 언어(low-resource language)를 다국어 자동 음성 인식(multilingual automatic speech recognition, ASR) 시스템에 통합하기 위해 새로운 접근 방식을 제안합니다. 일반적으로 불균형 데이터셋을 다루는 데 사용되는 weighted cross-entropy를 활용하여 미리 학습된 다국어 ASR 모델에 저자원 언어를 통합하는 방법을 제시합니다.

- **Technical Details**: 저자들은 Whisper 모델을 활용하여 5개의 고자원 언어와 1개의 저자원 언어를 fine-tuning하며, 언어 가중치 동적 cross-entropy와 데이터 증강(data augmentation) 기법을 적용합니다. 저자원 언어의 경우, 제안된 접근 방식을 적용하지 않은 fine-tuned 모델에 비해 6.69%의 단어 오류율(word error rate, WER) 감소를 보여주며, 원래 Whisper 모델과 비교하여 48.86% 감소를 기록했습니다. 이를 통해 6개 언어에서 평균 3.29%의 WER 감소 효과를 보였습니다.

- **Performance Highlights**: 이 연구의 접근 방식은 저자원 언어의 인식 정확성을 크게 향상시키고, 고자원 언어의 성능 저하 없이 평균 32.5%의 WER 감소를 보여주었습니다. 이러한 결과는 저자원 언어를 다국어 ASR 모델에 성공적으로 통합하는 새로운 방법론을 나타냅니다.



### Investigating OCR-Sensitive Neurons to Improve Entity Recognition in Historical Documents (https://arxiv.org/abs/2409.16934)
- **What's New**: 이 논문은 Transformer 아키텍처 내에서 OCR 민감한 뉴런의 존재를 조사하고, 역사적 문서에 대한 명명된 개체 인식(NER) 성능에 미치는 영향을 분석합니다. 깨끗한 텍스트 입력과 잡음이 있는 텍스트 입력에 대한 뉴런 활성화를 분석하여 OCR 민감한 뉴런을 식별하고 중화시킴으로써 모델 성능을 향상시키는 방법을 제안합니다.

- **Technical Details**: 실험은 Llama2와 Mistral 두 개의 오픈 액세스 대형 언어 모델을 기반으로 하며, OCR 잡음이 존재하는 텍스트에 대한 뉴런의 반응을 측정하여 OCR 민감한 레이어와 뉴런을 식별하는 데 중점을 둡니다. 이 과정에서 데이터셋은 프랑스 역사 신문의 OCR 수정 버전을 기반으로 생성되며, 다양한 수준의 OCR 잡음이 추가된 토큰을 사용합니다.

- **Performance Highlights**: 실험 결과, 역사 신문 및 고전 해설 문서에서 NER 성능이 개선되는 것으로 나타났고, 이는 특정 뉴런 조절이 잡음이 있는 텍스트에서 모델의 성능을 향상시킬 수 있음을 시사합니다.



### Zero-Shot Detection of LLM-Generated Text using Token Cohesiveness (https://arxiv.org/abs/2409.16914)
Comments:
          To appear at the main conference of EMNLP 2024

- **What's New**: 이 논문에서는 LLM(대형 언어 모델)로 생성된 텍스트를 자동으로 감지하기 위한 새로운 특징인 'token cohesiveness'를 제안하고, 이를 기반으로 TOCSIN이라는 제로샷 감지기(detection) 패러다임을 개발하였습니다.

- **Technical Details**: TOCSIN은 기존의 제로샷 감지기와 token cohesiveness 계산 모듈을 갖춘 이중 채널(dDual-channel) 감지기로 구성되어 있습니다. Token cohesiveness는 입력 텍스트에서 무작위로 일정 비율의 토큰을 삭제한 후, 잔여 텍스트와 그 복사본의 의미적 차이를 측정하여 계산됩니다. 이 방법은 BARTScore를 활용하여 평균적인 의미적 차이를 측정하며, 블랙박스 환경에서도 적합합니다.

- **Performance Highlights**: TOCSIN은 4개의 최신 제로샷 감지기와 함께 여러 다양한 데이터셋에서 실험을 수행하여, 기존 감지기 대비 높은 정확도를 기록하였습니다. 실험 결과는 TOCSIN이 기존의 제로샷 감지기보다 일관되게 의미 있는 개선을 보임을 시사합니다.



### Pruning Multilingual Large Language Models for Multilingual Inferenc (https://arxiv.org/abs/2409.16911)
Comments:
          Accepted at EMNLP 2024 Findings

- **What's New**: 이번 연구에서는 Multilingual Large Language Models (MLLMs)의 비영어 성능을 향상시키기 위해 이 모델들이 영어와 비영어 간의 정렬(alignment) 능력을 활용할 수 있는 방법을 탐구했습니다. 특히, 특히 큰 크기의 기능(features)에 집중하여 비번역(zero-shot) 작업의 성능을 높이는 방법을 제시하였습니다.

- **Technical Details**: MLLMs의 번역 성능 분석에서 큰 크기의 기능이 번역 과정에 중대한 역할을 한다는 것을 발견하였습니다. 이를 통해 우리는 큰 크기의 기능과 관련된 가중치(weights)를 유지하고 나머지 가중치는 줄여서 MLLMs가 비번역 작업에 대해 이러한 기능에 의존하도록 강요하는 전략을 구현하였습니다. 이 방법은 XNLI 및 MARC 작업에서 비영어 성능을 개선하는 데 성공적이었습니다.

- **Performance Highlights**: 분석 결과, 큰 크기의 기능을 사용하는 것이 MLLMs의 비영어 언어에서의 성능을 개선하는 데 기여한다는 사실을 실증적으로 보여주었습니다. XGLM과 mGPT에서 성능 향상을 확인했으나 BLOOM 모델은 프로그래밍 언어 처리 능력 때문에 다소 혼란스러운 결과를 보였습니다. 이 연구는 비영어 비약 연산에 대한 가중치 프루닝(pruning) 전략이 성능 개선에 효과적임을 입증하였습니다.



### Enhancing Temporal Sensitivity and Reasoning for Time-Sensitive Question Answering (https://arxiv.org/abs/2409.16909)
Comments:
          Accepted by EMNLP 2024 Findings

- **What's New**: 본 논문에서는 Time-Sensitive Question Answering (TSQA) 문제를 해결하기 위한 새로운 프레임워크를 제안합니다. 이 프레임워크는 Temporal Information-Aware Embedding과 Granular Contrastive Reinforcement Learning을 통해 모델의 시간 인식 및 추론 능력을 향상시키는 것을 목표로 합니다.

- **Technical Details**: 이 프레임워크는 두 가지 주요 방법론을 포함합니다: Temporal Information-Aware Embedding은 모델의 시간 정보에 대한 민감성을 높이고, Granular Contrastive Reinforcement Learning은 시간적 거리에 따라 원거리 및 근접한 부정적 답변을 제공하여 모델의 시간적 추론 능력을 향상시킵니다.

- **Performance Highlights**: 우리는 제안된 프레임워크가 기존의 LLM보다 TSQA 작업에서 유의미하게 뛰어난 성능을 보여주는 것을 확인했습니다. 실험 결과는 네 개의 다양한 TSQA 데이터셋에서 우리의 프레임워크가 기존 모델보다 크게 향상된 성능을 보였음을 입증합니다.



### Shifting from endangerment to rebirth in the Artificial Intelligence Age: An Ensemble Machine Learning Approach for Hawrami Text Classification (https://arxiv.org/abs/2409.16884)
Comments:
          19 pages, 7 tables, 14 figures

- **What's New**: 이번 연구에서는 6,854개의 Hawrami 텍스트 기사를 기반으로, 텍스트 분류를 위한 다양한 모델을 도입하였습니다. 이는 Hawrami라는 키르디시 방언의 데이터 부족 문제를 해결하는 데 기여하고자 하는 시도로서, 두 명의 원어민이 15개 카테고리로 라벨링하였습니다.

- **Technical Details**: 분류 작업을 위해 K-nearest Neighbor (KNN), Linear Support Vector Machine (Linear SVM), Logistic Regression (LR), Decision Tree (DT) 등의 기법을 활용하였으며, Linear SVM이 96%의 정확도로 가장 우수한 성과를 보였습니다.

- **Performance Highlights**: Linear SVM 모델이 다른 방법들보다 뛰어난 성과를 보여, Hawrami 방언의 텍스트 분류 작업에서 핵심적인 기여를 할 것으로 기대됩니다.



### CodeInsight: A Curated Dataset of Practical Coding Solutions from Stack Overflow (https://arxiv.org/abs/2409.16819)
Comments:
          Accepted to ACL 2024 Findings

- **What's New**: 새로운 CodeInsight 데이터셋을 소개하며, 이는 개발자의 일반적인 작업을 지원하기 위해 독창적으로 설계되었습니다. 이 데이터셋에는 명확한 의도, 관련된 코드 스니펫, 그리고 평균 3개의 관련 단위 테스트 예제가 포함되어 있습니다. 또한, Pandas, Numpy, Regex 및 70개 이상의 표준 Python 라이브러리를 포함하고 있습니다.

- **Technical Details**: 데이터셋은 3,409개의 Python 전문가에 의해 작성된 예제로 구성되어 있으며, 모델을 세부 조정(finetuning) 및 독립적 평가(standalone evaluation)에 사용할 수 있도록 설계되었습니다. 단위 테스트 평가를 완료하기 위해 예제를 분류하여 세부 분석을 가능하게 합니다. 데이터 오염(data contamination) 감소를 위해 예제를 다듬었으며, Mistral 7B, CodeLLaMa 13B, Starcoder 15B 등 세 가지 주요 모델 성능을 통해 확인하였습니다.

- **Performance Highlights**: CodeInsight 데이터셋은 코드 생성 분야에서의 주요 혁신을 포함하고 있습니다. 단위 테스트 기반 평가를 통해 BLEU score와 같은 기존 방법보다 더 강력한 평가 지표를 제공합니다. 또한 예제들은 강점과 약점을 더 깊이 분석할 수 있도록 주석이 달려 있으며, 각 예제는 수작업으로 큐레이션되어 고품질을 보장합니다.



### A Few Hypocrites: Few-Shot Learning and Subtype Definitions for Detecting Hypocrisy Accusations in Online Climate Change Debates (https://arxiv.org/abs/2409.16807)
Comments:
          cite the public version, published at CPSS 2024 @ KONVENS

- **What's New**: 이번 연구는 누군가를 비난하기 위해 사용하는 '위선' (hypocrisy) 주장 탐지를 독립적 작업으로 정의합니다. 기존 연구에서는 위선 주장이 논리적 오류 탐지의 일부로 다뤄졌으나, 본 연구는 이를 새로운 방식으로 접근하여 '환경 위선 주장 데이터셋' (Climate Hypocrisy Accusation Corpus, CHAC)을 구축합니다.

- **Technical Details**: 420개의 Reddit 기후 토론 댓글로 구성된 CHAC 데이터셋은 개인적 위선과 정치적 위선 두 가지 유형으로 주석이 달려있습니다. 이 데이터셋을 기반으로 6샷 방법과 3개의 instruction-tuned Large Language Models (LLMs)을 활용하여 위선 주장 탐지의 성능을 평가합니다.

- **Performance Highlights**: GPT-4o와 Llama-3 모델이 특히 뛰어난 성능을 보여주었으며, F1 점수는 0.68에 도달했습니다. 이는 이전 연구의 F1 점수 0.44에 비해 현저히 향상된 수치입니다. 연구 결과, 모델은 개인적 도덕적 위선 주장을 탐지하는 데는 효과적이나, 정치적 위선 주장을 탐지하는 데는 어려움을 겪었던 것으로 나타났습니다.



### Mitigating the Bias of Large Language Model Evaluation (https://arxiv.org/abs/2409.16788)
- **What's New**: 이번 연구에서는 LLM(as-a-Judge)의 평가 편향을 체계적으로 연구하였습니다. 특히 비공식 소스의 LLM 판별 모델들에서 겉보기 품질(superficial quality)의 중요성을 줄이기 위한 보정(calibration) 방법을 적용하고, 공식 소스 모델에서는 대비 학습(contrastive training)을 제안하여 편향을 완화하고자 했습니다.

- **Technical Details**: 비공식 LLM 판별자의 경우, 확률 기반 평가자와 생성 기반 평가자 모두에서 겉보기 품질을 모델링하여 최종 결과에서 이를 차감하는 두 가지 방법을 제안하였습니다. 이는 자연어 테스트 세트에서 편향을 평가하는 지표를 통해 검증되었습니다.

- **Performance Highlights**: 실험 결과는 제안된 방법들이 기존 평가 편향을 크게 완화시키면서도 자연어 세트에 대한 평가 정확도를 만족스럽게 유지했음을 보여주었습니다.



### Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction (https://arxiv.org/abs/2409.16783)
Comments:
          EMNLP 2024 camera ready version

- **What's New**: 본 논문에서는 HARM (Holistic Automated Red teaMing)을 제안하여, 대형 언어 모델 (LLMs)의 비정상적인 행동을 체계적으로 식별하는 새로운 방법을 소개합니다. HARM은 리스크 카테고리의 세분화된 분류를 바탕으로 한 상향식 접근 방식을 사용하고, 멀티 턴 상호작용을 지원하여 자동화된 레드 팀핑을 강화합니다.

- **Technical Details**: HARM은 세분화된 리스크 분류 체계를 사용하여 다양한 테스트 케이스를 생성하는 방법을 적용합니다. 이 방법은 고유의 파인 튜닝 전략과 강화 학습 기법을 활용하여 인간과 유사한 방식으로 멀티 턴에서의 적대적인 탐색을 수행합니다.

- **Performance Highlights**: 실험 결과를 통해 HARM이 모델의 취약성에 대한 보다 체계적인 이해를 가능하게 하고, 안전한 정렬 과정을 위한 보다 구체적인 가이드를 제공함을 보여주었습니다.



### E-SQL: Direct Schema Linking via Question Enrichment in Text-to-SQL (https://arxiv.org/abs/2409.16751)
- **What's New**: 본 논문에서는 E-SQL이라는 새로운 파이프라인을 소개하며, 이는 자연어 질의를 데이터베이스 스키마와 직접 연결하고 후보 술어를 증강하여 더 복잡한 질의를 다룰 수 있도록 설계되었습니다.

- **Technical Details**: E-SQL은 후보 SQL 생성(CSG), 후보 술어 생성(CPG), 질문 증강(QE), SQL 정제(SR)의 네 가지 주요 모듈로 구성됩니다. 이 시스템은 자연어 질의에 관련된 데이터베이스 요소를 통합하고, SQL 실행 오류를 감지하여 질의를 개선합니다.

- **Performance Highlights**: BIRD 벤치마크에서 E-SQL은 복잡한 질의를 효과적으로 처리하고, 테스트 세트에서 66.29%의 실행 정확도로 경쟁력 있는 성능을 달성하며, 고급 LLM(대형 언어 모델) 환경에서 더 나은 결과를 보여주었습니다.



### RoleBreak: Character Hallucination as a Jailbreak Attack in Role-Playing Systems (https://arxiv.org/abs/2409.16727)
- **What's New**: 이 논문은 캐릭터 환각(character hallucination)의 체계적인 분석을 제시하며, 이를 공격 관점에서 탐구하는 RoleBreak 프레임워크를 소개합니다. 이 프레임워크는 두 가지 주요 메커니즘인 쿼리 희소성(query sparsity)과 역할-쿼리 충돌(role-query conflict)을 캐릭터 환각의 핵심 요소로 식별합니다.

- **Technical Details**: RoleBreakEval이라는 새로운 데이터셋을 구축하고, 이를 통해 기존의 환각 완화 기법을 평가합니다. 두 가지 주 요인, 즉 쿼리 희소성과 역할-쿼리 충돌을 기반으로 공격 쿼리를 반자동으로 생성하여, LLM 기반 역할 놀이 시스템의 취약성을 입증합니다. 이 진행 과정에서 Narrator Mode라는 새로운 방어 전략을 제안하여, 보강된 내러티브 컨텍스트를 생성하고 역할 지침과 사용자 쿼리 간의 충돌을 완화합니다.

- **Performance Highlights**: 실험 결과, Narrator Mode는 전통적인 거부 기반 전략보다 우수한 성과를 보이며, 캐릭터 역할에 대한 충실도를 높이고 전체 내러티브 일관성을 향상시킵니다.



### PMSS: Pretrained Matrices Skeleton Selection for LLM Fine-tuning (https://arxiv.org/abs/2409.16722)
- **What's New**: 최근에 제안된 PMSS(Pre-trained Matrices Skeleton Selection)는 LoRA의 한계를 극복하고, 사전 훈련된 가중치 내의 의미적 정보를 활용하여 높은 랭크 업데이트를 가능하게 하는 새로운 fine-tuning 방법입니다.

- **Technical Details**: PMSS는 사전 훈련된 행렬에서 스켈레톤을 선택하여 작은 행렬만 학습하도록 설계되었습니다. 이를 통해 낮은 비용으로 높은 랭크 업데이트를 달성합니다. PMSS는 DROP, commonsense reasoning, 수학적 추론과 같은 복잡한 작업에서 LoRA보다 우수한 성능을 보입니다.

- **Performance Highlights**: PMSS는 LLaMA2-7B/13B의 DROP 벤치마크에서 각각 +3.4%/+5.9% 성능 향상을 보였고, GSM8K 데이터셋에서 Mistral-7B, Gemma-7B에 대해 각각 +12.89%/+5.61%/+3.11%의 성과를 달성했습니다.



### Probing Omissions and Distortions in Transformer-based RDF-to-Text Models (https://arxiv.org/abs/2409.16707)
Comments:
          Accepted for publication in Transactions of the ACL (TACL)

- **What's New**: 이 논문은 자연어 생성(Natural Language Generation, NLG)에서 중요한 정보가 출력 텍스트에서 누락되는 문제를 분석하며, RDF(Graph)를 텍스트로 변환하는 과정에서 이러한 누락(simulation) 및 왜곡(distortion) 현상을 탐색합니다. BART와 T5 모델의 인코더 출력에서 누락을 탐지하기 위한 새로운 두 가지 방법을 제시합니다.

- **Technical Details**: (i) 파라미터가 필요 없는 프로빙 방법으로, RDF 그래프의 임베딩과 일부 엔티티를 제거한 RDF 그래프의 임베딩 간의 코사인 유사도(cosine similarity)를 계산합니다. (ii) 이진 분류기(binary classifier)로, 인코더 임베딩을 분석하여 누락된 엔티티를 탐지합니다. 연구에서는 RDF 데이터를 영어로 변환한 텍스트에서 누락된 엔티티를 분석하며, 이러한 누락 및 왜곡이 인코더의 출력 임베딩에서 탐지될 수 있음을 보여줍니다.

- **Performance Highlights**: 실험 결과, 두 가지 프로빙 방법 모두에서 인코더 출력에서 누락된 엔티티 및 왜곡된 엔티티의 탐지가 가능함을 입증했습니다. 또한, 로지스틱 회귀(logistic regression)를 활용하여 해당 엔티티가 누락되거나 왜곡될 가능성을 피처(feature) 기반으로 예측할 수 있음을 발견했습니다.



### SynTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA (https://arxiv.org/abs/2409.16682)
Comments:
          EMNLP 2024

- **What's New**: 본 논문에서는 Text-to-SQL 파싱 및 엔드 투 엔드 질문 응답(E2E TQA) 접근 방식의 성과를 비교하고 이들이 갖고 있는 장점을 통합하는 Synergistic Table-based Question Answering(SynTQA) 방법론을 제안합니다.

- **Technical Details**: Text-to-SQL은 숫자 연산 및 긴 테이블 처리에 능숙하고, E2E TQA는 모호한 질문, 비표준 테이블 스키마 및 복잡한 테이블 내용을 잘 처리합니다. 이 연구는 이러한 두 모델을 통합하여 답변 선택(answer selection) 방법을 통해 개선된 성능을 확인했습니다.

- **Performance Highlights**: 실험 결과, feature 기반 및 LLM 기반 답변 선택기를 통해 기존 모델보다 향상된 성능을 보였으며, 복잡한 질문과 테이블에 대해서는 두 가지 접근 방식의 상호 보완적인 강점이 드러났습니다.



### SWE2: SubWord Enriched and Significant Word Emphasized Framework for Hate Speech Detection (https://arxiv.org/abs/2409.16673)
Comments:
          Published in CIKM 2020

- **What's New**: 이 논문에서는 Hate speech(혐오표현) 문제를 해결하기 위한 새로운 프레임워크(SWE2)를 제안합니다. SWE2는 메시지의 내용만을 기반으로 하며, 혐오표현을 자동으로 식별합니다.

- **Technical Details**: SWE2는 두 가지 유형의 서브워드 임베딩(phonetic-level embedding 및 character-level embedding)을 활용합니다. 또한, LSTM+attention 기반의 특성 추출 방법을 설계하여, 전반적인 내용의 의미 정보를 추출합니다. 이 프레임워크는 FastText와 BERT에서의 사전 학습된 변형을 비교하여 어떤 것이 서브워드 표현을 보완하는지 확인했습니다.

- **Performance Highlights**: 우리 모델은 백도어 공격 없이 0.975의 정확도와 0.953의 macro F1 점수를 달성하며 7개의 최신 방법론보다 우수합니다. 극단적인 공격 상황에서도 0.967의 정확도와 0.934의 macro F1 점수를 유지하여 높은 견고성을 입증하였습니다.



### Topic-aware Causal Intervention for Counterfactual Detection (https://arxiv.org/abs/2409.16668)
Comments:
          Accepted to the 4th EMNLP-NLP4DH 2024 workshop

- **What's New**: 이 논문에서는 Counterfactual Detection (CFD) 모델의 성능을 향상시키기 위해 neural topic model (NTM)와 인과적 개입 방법을 통합하는 새로운 접근 방식을 제안합니다. 기존 모델들이 clue phrases에 의존하여 성능 저하가 발생하는 문제를 해결하고자 합니다.

- **Technical Details**: 제안하는 모델은 NTM을 CFD 모듈에 통합하여 입력 문장의 전반적인 의미를 파악합니다. 또한 hidden representation에 대해 인과적 개입(causal intervention)을 시행하여 클래스 불균형(class imbalance)의 부정적인 영향을 줄입니다. 모델은 Variational AutoEncoder 아키텍처를 기반으로 하며, topic encoder와 decoder로 구성되어 있습니다.

- **Performance Highlights**: 광범위한 실험을 통해 제안한 방법이 기존의 최첨단 CFD 및 bias-resolving 접근 방식보다 뛰어난 성능을 보임을 입증하였습니다. 이 방법은 다른 bias-sensitive 자연어 처리 작업에도 적용 가능합니다.



### A Character-Centric Creative Story Generation via Imagination (https://arxiv.org/abs/2409.16667)
- **What's New**: 본 논문에서는 창의적인 스토리 생성을 위한 새로운 프레임워크인 CCI (Character-centric Creative story generation via Imagination)를 소개합니다. CCI는 창의적인 스토리를 생성하기 위해 IG (Image-Guided Imagination)와 MW (Multi-Writer model) 두 가지 혁신적인 모듈을 특징으로 합니다.

- **Technical Details**: IG 모듈은 DALL-E 3를 사용하여 이야기의 주요 요소들(예: 캐릭터, 배경 등)의 시각적 표현을 생성하며, MW 모듈은 IG에서 생성된 스토리 요소를 사용하여 주인공에 대한 여러 설명 후보를 생성하고 이후 가장 적합한 설명을 선택합니다.

- **Performance Highlights**: 연구 결과, CCI 모델이 생성한 스토리는 다양성과 캐릭터의 일관성 모두에서 우수한 성능을 보였으며, 인간 평가에서는 스토리의 창의성, 생동감, 구체성 및 일관성에서 더 높은 선호도를 보였습니다.



### Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts (https://arxiv.org/abs/2409.16658)
Comments:
          10 pages, EMNLP 2024 Findings

- **What's New**: 본 연구에서는 사전 학습된 언어 모델(Pre-trained Language Models, PLMs)이 신뢰할 수 없는 환각(hallucinated) 텍스트에 대해 구별 가능한 생성 확률과 불확실성 분포를 반환한다는 것을 보여줍니다. 이는 모델의 크기나 구조에 상관없이 88-98%의 경우에서 통계적으로 유의미하게 구별되는 결과를 나타냈습니다.

- **Technical Details**: 우리는 24개의 PLM을 6개의 데이터 세트에서 테스트하였으며, 이 과정에서 높은 로스를 가진 데이터 포인트를 절단함으로써 보다 신뢰할 수 있는 뉴스 제목을 생성할 수 있음을 발견했습니다. 또한, 생성 확률과 불확실성이 신뢰성과 긍정적인 상관관계를 가짐을 확인하였습니다. 이 연구에서 제안한 알고리즘은 환각 현상을 줄이는 데 효과적이며, 모델을 파인튜닝(fine-tuning) 할 때 불확실성을 고려하면서 그런 효과를 보였습니다.

- **Performance Highlights**: 제안한 알고리즘은 다른 기준 모델들에 비해 더 높은 신뢰성 메트릭을 달성하였으며, 전반적인 텍스트 품질 지표를 유지하면서도 탁월한 성능을 보였습니다.



### Domain-Independent Automatic Generation of Descriptive Texts for Time-Series Data (https://arxiv.org/abs/2409.16647)
- **What's New**: 이번 연구에서는 시간 시계열 데이터로부터 설명적인 텍스트를 체계적으로 생성하는 도메인 독립적인 방법을 제안합니다. 특히, 시간 시계열 데이터와 설명 텍스트의 쌍을 생성하기 위해 두 가지 접근 방법, 즉 forward approach와 backward approach를 정의하고, 새로운 backward approach를 통해 TACO 데이터셋을 생성합니다.

- **Technical Details**: TACO (Temporal Automated Captions for Observations) 데이터셋은 120만 개의 실제 시간 시계열 데이터 샘플을 사용하여 생성되었습니다. 연구진은 먼저 시간 시계열 클래스 세트를 정의하고, 각 클래스를 기준으로 점수를 계산하여 시간 시계열 데이터를 분류한 후, 이에 해당하는 설명 텍스트를 생성했습니다. 이 과정에서 min-max scaling을 사용하여 데이터와 점수를 정규화하였으며, Llama-3-8B-Instruct 모델을 활용하여 기초 설명 텍스트를 재구성했습니다.

- **Performance Highlights**: 제안된 방법으로 훈련된 contrastive learning 기반 모델은 새로운 도메인에서도 시간 시계열 데이터에 대해 도메인 독립적인 설명 텍스트를 효과적으로 생성할 수 있음을 실험 결과를 통해 입증하였습니다.



### Cross-Lingual and Cross-Cultural Variation in Image Descriptions (https://arxiv.org/abs/2409.16646)
- **What's New**: 이번 연구는 31개 언어 및 다양한 장소의 이미지를 포함하는 대규모 다중모달 데이터셋을 활용하여, 서로 다른 언어 구사자들이 이미지 설명에서 어떻게 다르게 언급하는지를 체계적으로 분석한 첫 연구입니다. 특히 지리적, 유전적으로 가까운 언어 쌍에서 유사한 개체가 더 빈번하게 언급되는 경향을 발견했습니다.

- **Technical Details**: 연구에서 WordNet을 사용하여 이미지 설명에서 언급된 개체를 식별하는 자동화된 방법론을 개발했습니다. XM3600 데이터셋을 사용하여 서로 다른 언어에서의 개체 언급 변화를 정량적으로 분석하는 데 중점을 두었습니다. 이 과정에서 이미지에 포함된 개체 카테고리를 독립적으로 주석으로 추가했습니다.

- **Performance Highlights**: 일부 언어 쌍(예: 일본어는 영어보다 의류를 훨씬 더 자주 언급)에서의 차이를 측정한 사례 연구를 통해 엔티티 카테고리의 눈에 띄는 정도와 언어에 따른 변동성을 확인했습니다. 또한, 이전의 소규모 연구 결과를 지지하는 데이터를 제공하며 기본 수준 카테고리에 대한 선호도가 드러났습니다.



### Training Language Models to Win Debates with Self-Play Improves Judge Accuracy (https://arxiv.org/abs/2409.16636)
Comments:
          48 pages, 12 figures; code at this https URL

- **What's New**: 이 연구에서는 언어 모델을 훈련시켜 토론에서 승리하도록 최적화한 결과, 평가자의 판단 정확도가 향상된다는 것을 처음으로 보였습니다. 이는 토론을 실질적인 확장 가능한 감독 방법으로 구현하고 검증하는 중요한 단계입니다.

- **Technical Details**: 연구는 QuALITY 데이터셋에서의 독해 질문에 대한 정보 비대칭 토론을 통해 진행되었습니다. 참여자 모델이 모든 주장을 두 차례 제시하고, 최종적으로 평가자가 어느 모델의 주장을 신뢰하는지를 결정합니다. 평가자의 정확성은 모델이 다른 모델과 싸울 때의 승률로 측정되었습니다.

- **Performance Highlights**: 토론 훈련 후 평가자의 정확도가 4% 증가했으며(p<10−6), 이러한 향상은 실제 감독 신호 없이도 이루어졌습니다. 반면 비대립 컨설팅 모델을 대상으로 한 실험에서는 모델 숙련도와 평가자 정확성 간의 긍정적인 관계가 발견되지 않았습니다.



### Claim-Guided Textual Backdoor Attack for Practical Applications (https://arxiv.org/abs/2409.16618)
Comments:
          Under Review

- **What's New**: 최근 자연어 처리(Natural Language Processing, NLP) 및 대규모 언어 모델(Large Language Models, LLMs)의 발전은 새로운 보안 취약점을 드러냈습니다. 특히, 이번 연구에서는 입력 변조 없이 내재된 텍스트 클레임(claim)을 트리거로 활용하는 새로운 Claim-Guided Backdoor Attack (CGBA)을 도입합니다.

- **Technical Details**: CGBA는 다음의 세 가지 주요 단계로 구성됩니다: 1) 트레이닝 샘플에서 클레임 추출하기, 2) 유사한 클레임을 군집화하기, 3) 특정 군집을 선택하여 트리거로 설정하고 모델 훈련 중에 백도어를 주입하여 목표 클레임에서 잘못된 결정을 유도합니다. 이 과정은 대조적 손실(contrastive losses), 클레임 거리(claim distance), 다중 작업 손실(multi-tasking losses)을 사용합니다.

- **Performance Highlights**: CGBA는 다양한 데이터셋과 모델에서 실험을 통해 이전 방법들보다 높은 공격 성공률을 보이며, 깨끗한 데이터 정확도에 미치는 영향은 최소화되었습니다. 또한 기존 방어 방법에 대한 스텔스성(stealthiness)을 평가한 결과, perturbation 기반 방법에 대해 높은 저항성을 나타냈습니다.



### Evaluating and Enhancing Large Language Models for Novelty Assessment in Scholarly Publications (https://arxiv.org/abs/2409.16605)
Comments:
          under review

- **What's New**: 본 논문에서는 LLM(대형 언어 모델)의 학술 논문에서의 창의성 및 참신성을 평가하기 위한 새로운 벤치마크인 SchNovel을 도입하였습니다. 이 벤치마크는 arXiv 데이터 세트에서 선택된 15,000 쌍의 논문으로 구성되어 있으며, 각 쌍의 최근 발표된 논문이 더 참신하다고 가정합니다. 또한, RAG-Novelty라는 새로운 방법을 제안하여 LLM이 논문의 참신성을 평가할 때 유사한 논문의 검색을 활용합니다.

- **Technical Details**: SchNovel 벤치마크는 2~10년 차이가 나는 논문 쌍을 포함하며, 이는 특히 높은 수준의 리뷰 과정을 거치는 학술 논문에서 참신성을 평가하는 데 중요합니다. RAG-Novelty는 검색 기반 생성 방법으로, 더 참신한 논문일수록 최근 발표된 논문을 더 많이 검색할 것이라는 가정을 바탕으로 합니다.

- **Performance Highlights**: 광범위한 실험을 통해 RAG-Novelty가 기존의 기준 모델보다 논문의 참신성을 평가하는 데 더 뛰어난 성능을 보인다는 것을 입증했습니다. 이 연구는 LLM의 논문 참신성 평가 능력을 깊이 있게 탐구하고, 다양한 카테고리와 출판 연도 간의 변화를 평가하여 LLM의 성능 향상에 기여하였습니다.



### Overview of the First Shared Task on Clinical Text Generation: RRG24 and "Discharge Me!" (https://arxiv.org/abs/2409.16603)
Comments:
          ACL Proceedings. BioNLP workshop

- **What's New**: 최근 자연어 생성(Natural Language Generation, NLG) 기술이 의료 분야에서 큰 변화를 일으키고 있습니다. 특히, 임상 보고서의 각 섹션을 자동 생성하여 의사들의 업무 부담을 줄이고 병원 문서화 프로세스를 간소화하는 다양한 애플리케이션을 도입하였습니다.

- **Technical Details**: 이번 연구에서는 두 가지 하위 작업으로 이루어진 공유 과제를 제시합니다: (1) Radiology Report Generation (RRG24)와 (2) Discharge Summary Generation ('Discharge Me!')입니다. RRG24는 흉부 X-레이를 기반으로 라디오 로지 보고서의 'Findings' 및 'Impression' 섹션을 생성하는 과제이고, 'Discharge Me!'는 응급실에 입원한 환자를 위한 퇴원 요약의 'Brief Hospital Course' 및 'Discharge Instructions' 섹션을 생성하는 과제입니다. 이 두 작업 모두 클리니션의 반복적인 업무를 덜고 번아웃(Burnout)을 줄이는 것을 목표로 합니다.

- **Performance Highlights**: RRG24 과제에서 201개의 제출물이 8개 팀에서 왔으며, 'Discharge Me!' 과제에서는 211개의 제출물이 16개 팀에서 도착했습니다. 이 작업들은 최근의 발전을 공통 데이터 분할 및 평가 구현을 통해 벤치마킹하는 것을 목표로 하고 있습니다.



### Disentangling Questions from Query Generation for Task-Adaptive Retrieva (https://arxiv.org/abs/2409.16570)
- **What's New**: 본 논문에서는 정보 검색 (Information Retrieval) 문제를 다루며, 기존 쿼리 생성기가 일반적인 검색 의도를 수용하지 못하는 문제를 해결하기 위한 새로운 쿼리 생성기 EGG (Efficient Generalized Generator)를 제안합니다. EGG는 메타 프롬프트 (meta-prompt)를 활용하여 고급 의도를 작업 적응 쿼리로 변환합니다.

- **Technical Details**: EGG는 다양한 검색 의도를 통합하기 위해 메타 프롬프트와 검색기 피드백 (retriever feedback)을 활용하며, 137B LLM (Large Language Model)을 포함한 몇 가지 모델 크기를 제공합니다. 특히, FLAN 137B를 사용하여 few-shot 쿼리 생성에 최적화된 EGG-FLAN과, 적절한 컨텍스트를 사용할 수 있는 EGG-Llama 두 가지 버전을 도입합니다.

- **Performance Highlights**: EGG는 기반 모델 (baseline) 및 기존 모델들을 초월하여 네 가지 작업에서 우수한 성능을 보였으며, 이전의 최첨단 모델보다 47배 더 작은 쿼리 생성기를 사용하면서도 가장 높은 전반적인 성능을 달성했습니다.



### Understanding the Cognitive Complexity in Language Elicited by Product Images (https://arxiv.org/abs/2409.16521)
- **What's New**: 이 논문은 제품 이미지가 소비자에 의해 보고된 다양한 언어적 특징을 유도하는 방식을 다루고 있습니다. 특히, 인간의 언어가 보여주는 인지적 복잡성을 측정하고 검증하는 접근법을 제안하며, 대형 언어 모델(LLM)을 통해 모의된 응답자의 인지 과정을 이해할 수 있는 도구를 제공합니다.

- **Technical Details**: 연구에서는 인간이 생성한 언어의 인지적 복잡성이 제품 이미지에 의해 어떻게 유도되는지를 분석합니다. 이를 위해 14개 카테고리의 4,000개 이상의 제품 이미지와 45,609개의 인간 생성 텍스트 레이블 및 복잡성 평가를 포함한 대규모 데이터셋을 소개합니다. 인지적 복잡성을 측정하기 위해 여러 자연어 모델을 활용하여 인간의 평가와 근접한 결과를 도출합니다.

- **Performance Highlights**: 인간이 평가한 인지적 복잡성은 특정 제품 이미지에 대해 두 사람이 매우 다른 기억을 설명하더라도 높은 복잡성을 가질 수 있음을 보여줍니다. 해당 연구는 인지 복잡성이 선택 예측을 개선하고, 인간과 LLM 간의 생성된 언어의 인지적 복잡성의 분포 차이를 분석하여 데이터의 품질을 평가할 수 있는 가능성을 제시합니다.



### Exploring Knowledge Tracing in Tutor-Student Dialogues (https://arxiv.org/abs/2409.16490)
- **What's New**: 최근 대형 언어 모델(LLMs)의 발전으로 인공지능(AI) 기반의 튜터링 챗봇이 개발되었습니다. 본 연구에서는 학생과 튜터 간의 대화에서 학생 행동을 모델링하는 새로운 접근을 제안합니다. 대화 회차(turn)에 대한 분석을 통해 학생의 지식 수준을 추적하고 오해를 파악할 수 있는 가능성을 제시합니다.

- **Technical Details**: 본 연구는 두 가지 주요 단계를 통해 대화 지식 추적(dialogue knowledge tracing, KT)을 수행합니다: i) 사전 학습된 LLM인 GPT-4o를 사용하여 대화 데이터를 주석 처리하고, ii) 주석이 달린 데이터를 이용해 KT 모델을 훈련합니다. 제안하는 LLMKT 방법은 Llama 3 모델을 활용하여 KT 목표를 위해 미세 조정하고, 기존의 DKT 방법의 임베딩을 시맨틱 텍스트 임베딩으로 대체하는 DKT-Sem을 소개합니다.

- **Performance Highlights**: LLMKT 방법은 두 가지 튜터-학생 수학 대화 데이터셋에서 기존 KT 방법들보다 크게 향상된 성능을 보여주었으며, 이 방법들은 적은 훈련 데이터로도 효과적일 수 있음을 입증했습니다. 또한 GPT-4o의 대화 주석이 전문가의 평가에 따라 정확하다는 점을 보여줘 향후 연구 방향성을 제안합니다.



### Spelling Correction through Rewriting of Non-Autoregressive ASR Lattices (https://arxiv.org/abs/2409.16469)
Comments:
          8 pages, 7 figures

- **What's New**: 이번 연구는 Transformer 기반의 CTC 모델로 생성된 단어 조각(wordpiece) 격자(lattice)를 재작성하기 위한 유한 상태 변환기(Finite-State Transducer, FST) 기법을 소개합니다. 이 알고리즘은 재훈련 없이 단어 조각에서 음소(phoneme)로 직접 변환하는 것을 가능하게 합니다.

- **Technical Details**: 이 논문에서는 비자기회귀(non-autoregressive) CTC 기법으로 생성된 격자의 조정이 어렵다는 한계를 극복하기 위한 방법을 제시합니다. 특히, 비자기회귀 ASR에서는 이전 또는 이후 토큰과 조건적으로 독립적인 토큰들이 발행되어, '소시지 격자' topology의 문제를 해결해야 합니다. FST 기법을 통해 기존 격자의 풍부한 신호를 활용하여 보다 개선된 성능을 달성할 수 있습니다.

- **Performance Highlights**: 연구는 문맥적으로 관련된 개체들에 대한 테스트 세트에서 문장 오류율(Sentence Error Rate, SER)을 최대 15.2% 감소시켰습니다.



### Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification (https://arxiv.org/abs/2409.16461)
- **What's New**: 이번 연구는 LLM(대형 언어 모델)이 자연어(NL)에서 1차 논리(FOL)로의 번역 과정에서 발생하는 오류를 체계적으로 분석하고 이를 개선하기 위한 여러 방법을 제시하고 있습니다. 특히 ProofFOL이라는 고품질의 FOL 주석이 달린 데이터셋을 생성해 소형 모델들도 성능을 향상시킬 수 있도록 합니다.

- **Technical Details**: 이 연구는 ProofWriter 데이터셋을 기반으로 GPT-4o를 사용하여 FOL 번역에 관한 대규모 데이터셋인 ProofFOL을 생성합니다. ProofFOL은 104241 예시의 (premises, conclusion) 쌍과 해당하는 FOL 번역을 포함하고 있으며, 이를 통해 소형 모델인 LLaMA-2 13B 및 Mistral 7B가 LLaMA-2 70B 모델보다 더 나은 성능을 보여줍니다.

- **Performance Highlights**: ProofFOL을 사용한 LLaMA-2 및 Mistral 모델은 ProofWriter와 ProntoQA 데이터셋에서 최첨단 성능을 기록했으며, FOLIO 데이터셋에서는 41% 및 17%의 성능 향상을 달성하였습니다. 이 연구는 데이터 부족 문제 해결을 위한 점진적 훈련 방법과 새로운 검증 메커니즘을 제안합니다.



### FMDLlama: Financial Misinformation Detection based on Large Language Models (https://arxiv.org/abs/2409.16452)
Comments:
          work in progress

- **What's New**: 이 논문은 금융 분야에서의 허위 정보 탐지(FMD)를 위한 최초의 오픈소스 LLM인 FMDLlama를 제안합니다. 이는 Llama3.1에 대한 지침 데이터로 파인튜닝하여 개발하였으며, 첫 번째 다중 작업 FMD 지침 데이터 세트(FMDID)와 FMD 능력을 평가하기 위한 종합적인 벤치마크(FMD-B)를 함께 제공합니다.

- **Technical Details**: FMDLLMs는 허위 정보 탐지 작업에 최적화된 최초의 오픈소스 LLM으로, 다양하고 복잡한 금융 허위 정보 탐지 작업을 수행할 수 있습니다. 이 모델은 지침 조정 지침을 수립하고, 다중 금융 허위 정보 탐지 작업을 다루며, 특정 보고서 클래스의 성능을 극대화하기 위해 모든 작업 데이터 세트를 결합합니다.

- **Performance Highlights**: FMD-B 벤치마크에서 FMDLLMs는 다른 모든 오픈소스 LLM 및 ChatGPT보다 뛰어난 성능을 기록하며, 최신 기술(SOTA) 성능을 달성하였습니다. 이로 인해 LLM의 금융 허위 정보 검증 능력을 평가하는 데 큰 기여를 하였습니다.



### A Comprehensive Survey of Bias in LLMs: Current Landscape and Future Directions (https://arxiv.org/abs/2409.16430)
Comments:
          2 Tables, 1 Figure

- **What's New**: 이 논문은 Large Language Models(LLMs)에서의 편향(bias)에 대한 종합적인 조사(survey)를 제공하며, 다양한 유형, 출처, 영향 및 완화 전략을 체계적으로 분류하고 있습니다.

- **Technical Details**: LLMs의 편향을 여러 차원으로 분류한 후, 현재 연구 결과를 종합하고 실제 응용에서의 편향의 함의를 논의합니다. 또한 기존의 편향 완화(bias mitigation) 기법을 비판적으로 평가하고 LLMs의 공정성(fairness) 및 형평성(equity)을 향상시키기 위한 미래 연구 방향을 제시합니다.

- **Performance Highlights**: 이 조사는 연구자, 실무자 및 정책 입안자들에게 LLMs의 편향 문제를 해결하고 이해하는 데 기초 자료로 활용될 수 있는 중요한 리소스를 제공합니다.



### RISCORE: Enhancing In-Context Riddle Solving in Language Models through Context-Reconstructed Example Augmentation (https://arxiv.org/abs/2409.16383)
- **What's New**: 본 논문에서는 LLM의 수수께끼 해결 능력을 검토하고, RISCORE라는 새로운 자동화된 프롬프트 기법을 소개하여 수수께끼의 해결 성능을 향상시키고자 합니다.

- **Technical Details**: RISCORE(RIddle Solving with COntext REcontruciton)는 수수께끼의 문맥을 재구성하여 몇 가지 샘플을 생성하는 방법으로, 언어 모델이 수수께끼 해결 시 기존의 예시와 결합하여 성능을 극대화합니다.

- **Performance Highlights**: RISCORE는 수직 사고(vertical thinking)와 수평 사고(lateral thinking) 작업에서 언어 모델의 성능을 현저히 향상시키며, 기존 프롬프트 기술보다 뛰어난 성능을 보였습니다.



### Do the Right Thing, Just Debias! Multi-Category Bias Mitigation Using LLMs (https://arxiv.org/abs/2409.16371)
Comments:
          17 pages, 5 Figures

- **What's New**: 이 논문에서는 언어에서의 편향 완화(bias mitigation) 모델을 구축하는 과제를 다룹니다. 기존 데이터셋의 한계를 인식하고, 9개의 사회적 편향 범주를 포함한 1507개의 세심하게 선별된 문장 쌍을 포함하는 새로운 데이터셋 ANUBIS를 소개합니다.

- **Technical Details**: ANUBIS 데이터셋은 인종, 성별, 성 정체성, 성적 지향, 종교, 나이, 국적, 장애, 외모, 사회경제적 지위 등 다양한 편향 범주를 포괄합니다. 우리는 최신 모델 T5를 사용하여 Supervised Fine-Tuning (SFT), 강화 학습(Reinforcement Learning; PPO, DPO 등), In-Context Learning (ICL)을 통해 효과적인 편향 완화 기법을 평가했습니다.

- **Performance Highlights**: 연구 결과, ANUBIS 데이터셋과 기존 데이터셋(WIKIBIAS)에서 훈련된 모델의 성능을 비교하였으며, 모델의 지속 가능성과 환경적 영향을 고려한 평가도 진행하였습니다. 이는 더 공정한 AI 시스템 개발과 사회적 영향을 고려한 기술 발전에 기여할 것으로 기대됩니다.



### Exploring the traditional NMT model and Large Language Model for chat translation (https://arxiv.org/abs/2409.16331)
Comments:
          7 pages, 6 Tables, WMT24

- **What's New**: 이 논문에서는 WMT24 채팅 번역 공유 과제에서 영어와 독일어 간의 이중 번역(en-de) 작업을 위한 Huawei Translation Services Center(HW-TSC)의 제출 사례를 다룹니다. 연구에서는 채팅 데이터를 이용한 모델의 파인튜닝(fine-tuning)과 함께 Minimum Bayesian Risk (MBR) 디코딩 및 자기 학습(self-training) 등의 다양한 전략을 탐색했습니다.

- **Technical Details**: 본 논문에서는 Transformer-Big 아키텍처를 기반으로 한 모델을 사용하며, 기존 NMT 모델 외에 대형 언어 모델(LLM)의 활용을 통해 번역 작업의 새로운 패러다임을 제시합니다. Minimum Bayesian Risk (MBR) 디코딩 기법은 여러 후보 중에서 최소 예상 오류를 가진 출력을 선택하는 방식입니다. 자기 학습 기법(self-training)과 역번역(back-translation)을 통해 번역 품질을 향상시키는 방법을 설명합니다.

- **Performance Highlights**: 결과적으로 MBR 자기 학습 방법이 가장 우수한 성능 향상을 보여주었고, 기계 번역 품질의 측면에서 확실한 개선이 있었습니다. 그러나 LLM의 출력 comet 메트릭은 NMT 모델의 최적 결과를 초과하지 못했습니다.



### DeepScore: A Comprehensive Approach to Measuring Quality in AI-Generated Clinical Documentation (https://arxiv.org/abs/2409.16307)
Comments:
          9 pages, 5 figures, 6 tables

- **What's New**: 이 논문은 DeepScribe의 의료 문서 품질 평가 방법론에 대해 설명합니다. 특히, 다양한 지표와 종합 점수인 'DeepScore'를 통한 품질 및 정확성을 측정하는 방법에 초점을 맞춥니다.

- **Technical Details**: DeepScribe는 'Stat Rates'라는 시스템을 통해 AI가 생성한 의료 노트의 품질을 평가하고, 즉각적인 수정과 알고리즘의 발전 방향을 제시합니다. Major Defect-Free Rate (MDFR), Critical Defect-Free Rate (CDFR), Captured Entity Rate (CER), Accurate Entity Rate (AER), Minimally-Edited Note Rate (MNR), Medical Word Hit Rate (MWHR)와 같은 다양한 지표를 활용하여, AI 문서의 정확성과 사용자 수용성을 분석합니다.

- **Performance Highlights**: DeepScore는 앞서 언급한 모든 지표를 평균내어 계산하여 생성됩니다. 이를 통해 의료 문서 품질에 대한 종합적인 평가를 제공하며, 지속적인 개선을 위한 지침 역할을 합니다.



### Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models (https://arxiv.org/abs/2409.17146)
- **What's New**: Molmo는 현재 공개된 VLM 중에서 가장 최신의 성능을 자랑하며, 독점적인 데이터가 아닌 새롭게 수집된 고품질 데이터로 구성된 이미지를 설명하는 고급 캡션 데이터셋을 기반으로 하고 있습니다. 이 연구는 VLM을 처음부터 구축하는 데 필요한 기본 지식을 제공합니다.

- **Technical Details**: Molmo 모델은 기존의 비전 인코더와 언어 모델을 결합하여 만들어졌습니다. 이 과정에서는 이미지로부터 자세하고 질 높은 설명을 생성하는 새로운 데이터셋인 PixMo를 사용하고, 60~90초 동안 음성으로 설명하도록 요구하여 다양한 내용을 포괄하도록 했습니다. 모델 훈련은 다단계 과정이 아닌, 간단한 훈련 파이프라인을 통해 진행되었습니다.

- **Performance Highlights**: Molmo-72B 모델은 학술 벤치마크에서 최고의 점수를 기록했으며, GPT-4o와 비교했을 때 사용자 선호도 순위에서 두 번째에 올랐습니다. Molmo-1B 모델은 효율적인 성능을 보이며 GPT-4V와 근접한 결과를 보여주었고, 전체적으로 많은 상업적 시스템을 능가하는 성능을 발휘했습니다.



### Can Vision Language Models Learn from Visual Demonstrations of Ambiguous Spatial Reasoning? (https://arxiv.org/abs/2409.17080)
Comments:
          13 pages, 4 figures. Code released at this https URL

- **What's New**: 본 연구에서는 Spatial Visual Ambiguity Tasks (SVAT)라는 새로운 벤치마크를 제안하여 대형 비전-언어 모델(VLM)이 시각적 데모를 통해 새로운 비주얼-스페이셜 개념을 학습할 수 있는지를 평가합니다.

- **Technical Details**: SVAT는 여러 난이도 수준의 분류 작업으로 구성되어 있으며, 목표는 주어진 모호한 텍스트와 시각적 데모를 기반으로 이미지 내에서 관심 있는 객체의 정확한 위치를 학습하는 것입니다. VLM은 이 과제를 위해 Text-Query와 Image-Based Input을 사용하여 정확한 경계 결정을 해야 합니다.

- **Performance Highlights**: Zero-shot 설정에서 VLM은 SVAT 작업에서 실패하고, 단순한 파인튜닝만으로는 5.8%-27.3%의 성능 향상이 가능합니다. 그러나 커리큘럼 학습(Curriculum Learning)을 통해, VLM은 SVAT의 가장 어려운 작업에서 14.2%에서 34.2%의 정확도 개선을 이룰 수 있습니다.



### Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia (https://arxiv.org/abs/2409.17054)
- **What's New**: 이 연구는 동남아시아 지역에서의 의사-환자 상호 작용의 효율성을 개선하기 위해 지역화된 대형 언어 모델(LLM)을 활용한 자동적 환자 기록 전사 및 요약 시스템을 제안합니다.

- **Technical Details**: 이 시스템은 OpenAI의 Whisper 모델을 사용하여 실시간으로 환자-의사 대화를 전사하고, GPT-3를 통해 요약된 정보를 ePuskesmas 전자 건강 기록 형식으로 변환합니다. 주요 과정은 네 가지로 나누어집니다: 대화 녹음, 실시간 전사, 의료 데이터 요약, 자동 ePuskesmas 파서.

- **Performance Highlights**: 이 솔루션을 통해 의사들은 더욱 신속하게 환자 정보를 정리할 수 있으며, 기록의 질도 향상되어 향후 환자 방문을 위한 정보가 더욱 자세하고 통찰력 있게 변모합니다. 이는 인도네시아의 과중한 시설과 의료 제공자의 행정 부담을 해소하는 중요한 진전을 나타냅니다.



### Counterfactual Token Generation in Large Language Models (https://arxiv.org/abs/2409.17027)
- **What's New**: 이번 연구에서는 대규모 언어 모델(LLM)이 출력의 대안에 대해 반사실적 추론(counterfactual reasoning)을 수행할 수 있도록 하는 causal 모델을 개발했습니다. 이는 무작위 샘플링(sampling) 과정에 Gumbel-Max 구조적 인과 모델을 적용하여 구현됩니다.

- **Technical Details**: 제안한 모델은 Llama 3 8B-instruct에서 구현되었으며, 기존의 노드 상태를 유지하지 않는 상태 비저장(stateless) LLM에서 출발하여 반사실적 토큰 생성(counterfactual token generation)을 가능하게 합니다. 이를 통해 모델은 입력된 프롬프트에 따라 자동 회귀(auto-regressive) 생성 방식을 사용하여 가능한 대안을 탐색할 수 있습니다.

- **Performance Highlights**: 반사실적 토큰 생성의 질과 양을 분석한 결과, 모델이 생성한 결과는 기존 출력과 높은 유사성을 보여주었으며, 바이어스 탐지에 대한 유용성도 입증되었습니다. 이 연구는 LLM이 어떻게 세상 모델을 구성하는지에 대한 통찰력을 제공합니다.



### Models Can and Should Embrace the Communicative Nature of Human-Generated Math (https://arxiv.org/abs/2409.17005)
- **What's New**: 이 논문은 수학이 사람에 의해 사람을 위해 구성된다는 관점을 제안하며, 수학 데이터가 단순한 기호적 표현을 넘어선 풍부한 의사소통 의도를 반영한다고 주장합니다. 이 연구는 언어 모델(Language Models)이 수학적 심볼을 처리할 때 인간과 유사한 방식을 채택하고 있음을 실험을 통해 증명합니다.

- **Technical Details**: 연구에서는 두 가지 사례 연구를 통해 언어 모델의 수학적 문제 해결 방식의 비대칭성(asymmetry)과 정렬(ordering)에 대한 선호도를 조사하였습니다. 첫 번째 실험에서는 동일한 기본 방정식에 대해 다양한 형태의 언어 문제를 생성하는 능력을 평가했습니다. 두 번째로, 언어 모델이 수학적 증명의 배열 방식이 자연스러운 방식일 때 더 선호한다는 사실을 발견했습니다. 이는 AI 시스템이 인간이 생성한 수학의 의사소통 의도를 학습하고 표현하는 데 기여할 수 있음을 나타냅니다.

- **Performance Highlights**: 언어 모델들은 같은 방정식에 대해 다르게 해석하며, 문제를 구성할 때 비대칭성을 인식합니다. 또한, 정당한 수학적 증명들의 배열 순서에 대해 인간처럼 자연적인 방식의 선호를 보였습니다. 이러한 결과는 수학적 의사소통에서 맥락을 완전히 무시하지 말고 이를 고려해야 한다는 점을 강조합니다.



### AXCEL: Automated eXplainable Consistency Evaluation using LLMs (https://arxiv.org/abs/2409.16984)
- **What's New**: 이 논문에서는 LLM을 활용하여 텍스트 응답의 일관성을 평가하는 새로운 접근 방식인 AXCEL(Automated eXplainable Consistency Evaluation using LLMs)을 소개합니다. AXCEL은 프롬프트 기반으로 작동하며, 일관성 점수에 대한 설명을 제공하여 사용자가 추론할 수 있도록 돕습니다.

- **Technical Details**: AXCEL는 Chain of Thought (CoT)와 few shot prompting 기술을 사용하여 텍스트의 일관성을 측정합니다. 기존의 메트릭에 비해 AXCEL은 설명 가능성을 제공하며, 특정 태스크에 맞지 않아도 여러 태스크에 적용할 수 있는 일반화 가능성을 가지고 있습니다. AXCEL은 요약, 자유 텍스트 생성, 데이터-텍스트 변환의 세 가지 태스크에서 실험되었습니다.

- **Performance Highlights**: AXCEL은 요약에서는 8.7%, 자유 텍스트 생성에서는 6.2%, 데이터-텍스트 변환 태스크에서는 29.4% 향상된 성능을 보이며, 기존의 non-prompt 및 prompt 기반 최신 메트릭을 초월했습니다. 또한 AXCEL은 오픈 소스 LLM을 사용하더라도 강력한 성능을 보여줍니다.



### Semi-Supervised Cognitive State Classification from Speech with Multi-View Pseudo-Labeling (https://arxiv.org/abs/2409.16937)
- **What's New**: 본 연구는 인지 상태 분류와 같은 주관적 평가가 많이 필요한 음성 분류 작업에서 레이블이 없는 데이터의 문제를 해결하기 위해 새로운 반지도 학습(Semi-Supervised Learning, SSL) 프레임워크를 제안합니다. 특히, 이 프레임워크는 음향과 언어적 특성을 활용한 다중 뷰(pseudo-labeling) 방법을 도입하여 분류 모델 훈련에 가장 확신이 높은 데이터를 선택합니다.

- **Technical Details**: 제안된 SSL 프레임워크는 두 가지 경로로 구성됩니다: 1) 음향 경로, 해당 경로에서는 다양한 오디오 임베딩을 이용해 레이블이 있는 데이터와 레이블이 없는 데이터를 비교하여 유사성을 판단합니다. 2) 언어 경로, 여기서는 대형 언어 모델(Large Language Models, LLMs)을 사용하여 ASR(Automatic Speech Recognition) 전사로부터 예측 레이블을 도출합니다. 프레셰 오디오 거리(Frechet Audio Distance, FAD)를 사용해 레이블이 없는 데이터의 음향 유사성을 측정하고, 이를 통해 고신뢰 데이터와 저신뢰 데이터를 구분합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 라벨이 있는 데이터의 30%만 사용하여도 완전 감독 학습(fully supervised learning)과 유사한 성능을 달성하였으며, 두 개의 기준선보다 훨씬 우수한 성과를 나타냈습니다.



### Cross-lingual Speech Emotion Recognition: Humans vs. Self-Supervised Models (https://arxiv.org/abs/2409.16920)
- **What's New**: 본 연구는 Self-Supervised Learning (SSL) 모델을 통한 Speech Emotion Recognition (SER)에서 인간 성능과의 비교 분석을 수행했습니다. 특히, 단일 언어(monolingual), 교차 언어(cross-lingual) 및 전이 학습(transfer learning) 맥락에서 매개변수 효율적인 미세 조정(Parameter-Efficient Fine-Tuning) 전략을 탐구하고, 방언이 교차 언어 SER에 미치는 영향을 조사하였습니다.

- **Technical Details**: 이 연구는 Wav2vec 2.0 (W2V2) 및 WavLM 등 강력한 사전 훈련(pre-trained) 모델을 사용하여 SSL 기반의 SER 성능을 비교하였습니다. 다양한 PEFT 전략을 통해 모델의 초기 파라미터를 수정하며, 중간층의 음성 표현이 높은 성능을 발휘하는 것을 확인했습니다. 교차 언어 SER에서 모델은 적절한 지식 전이를 통해 목표 언어에 적응할 수 있음을 보여주었으며, 특정 방언의 특성을 고려한 평가를 수행했습니다.

- **Performance Highlights**: 모델과 인간 모두 다른 감정에 대해 뚜렷한 행동 차이를 보였으며, 모델은 네이티브(Native) 화자와 유사한 성능을 기록했습니다. 방언은 인간의 감정 인식에 상당한 영향을 미치는 것으로 나타났으며, 감정 인식 정확도를 조정하기 위한 다양한 PEFT 전략이 효과적이었음을 입증했습니다.



### A Roadmap for Embodied and Social Grounding in LLMs (https://arxiv.org/abs/2409.16900)
Comments:
          Accepted Version of a conference paper presented at Robophilosophy Conference 2024

- **What's New**: 이번 연구는 로봇 시스템에 대규모 언어 모델(LLMs)을 통합하여 의사소통 뿐만 아니라 다중 모달 입력 처리, 고급 추론 및 계획 생성을 통한 변혁적인 패러다임을 제시합니다. LLM의 지식을 경험적 세계와 연결하기 위한 새로운 접근 방식을 탐구합니다.

- **Technical Details**: 이 논문은 LLMs의 기초 모델에 대한 추상 지식을 물리적 현실과 일치시키는 'grounding'(근거화) 과정을 다룹니다. 이 과정에서는 LLMs가 환경에 대한 이해도를 높이고, 객체의 물리적 속성을 통해 추론 능력을 향상시키도록 돕는 기술적 접근이 포함됩니다.

- **Performance Highlights**: 최근의 연구들은 LLMs의 텍스트 기반 작업에서의 효과가 신체적 제어까지 확장되었음을 보여주며, 이는 로봇이 인간과의 협력적 환경에서 더 뛰어난 성능을 발휘할 수 있게 합니다. 그러나 실제 로봇 작업에서 물리적 및 사회적 추 reasoning과 같은 기술들에 대한 LLM의 한계 또한 강조되었습니다.



### Robotic Backchanneling in Online Conversation Facilitation: A Cross-Generational Study (https://arxiv.org/abs/2409.16899)
Comments:
          Published at Proceedings of the 2023 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN 2023)

- **What's New**: 일본은 고령화 사회에 따른 문제, 특히 인지 저하 증가와 돌봄 인력 부족과 같은 도전에 직면하고 있습니다. 본 연구는 AI를 활용한 사회적 존재감을 가진 로봇이 노인과의 상호작용에서의 호환성을 평가하기 위한 첫걸음을 제시합니다.

- **Technical Details**: 이 연구에서는 인지 저하를 방지하기 위한 그룹 대화 프로토콜을 촉진하는 로봇을 평가하기 위한 사용자 연구를 실시했습니다. 로봇은 자연스러운 의사소통 방식인 backchannelling을 사용하도록 변경되어, 그룹 대화의 즐거움을 높이도록 설계되었습니다.

- **Performance Highlights**: 교차 세대 연구를 통해 젊은 성인들은 backchannelling 로봇을 비-backchannelling 로봇보다 더 친절하고 신뢰할 수 있으며 수용 가능하다고 인식했습니다. 또한, 로봇의 backchannelling이 노인 참가자들의 비언어적 backchanneling을 유도했습니다.



### The Role of Language Models in Modern Healthcare: A Comprehensive Review (https://arxiv.org/abs/2409.16860)
- **What's New**: 이 논문은 대형 언어 모델(LLM)이 의료 분야에 어떻게 적용되는지에 대한 체계적인 리뷰를 제공합니다. LLM의 발전 과정과 의료 적용에서의 강점뿐만 아니라 데이터 프라이버시, 편향, 윤리적 고려사항 등의 문제를 논의합니다.

- **Technical Details**: 대형 언어 모델(LLM)은 Transformer 아키텍처를 기반으로 하여 장거리 의존성을 효과적으로 캡처하는 능력을 가지고 있습니다. 모델은 일반적으로 방대한 텍스트 데이터셋으로 사전 학습(pre-training)된 후, 특정 작업에 맞춰 세부 조정(fine-tuning)됩니다. BioBERT, ClinicalBERT와 같은 의료 전용 모델이 개발되어 임상 언어의 독특한 도전을 해결하고 있습니다.

- **Performance Highlights**: LLM은 의료 데이터 분석, 질병 진단, 환자 관리 및 약물 발견과 같은 다양한 분야에서 사용되고 있습니다. 임상 의사결정 지원 및 의료 문서 요약 등의 임무에 대한 효과적인 증상이 입증되었습니다. 측정 기준으로는 MMLU, HumanEval과 같은 벤치마크가 사용되어 모델의 효과성을 평가합니다.



### Exposing Assumptions in AI Benchmarks through Cognitive Modelling (https://arxiv.org/abs/2409.16849)
Comments:
          11 pages, 2 figures

- **What's New**: 본 논문에서는 문화적 AI 벤치마크가 종종 측정된 구성 요소에 대한 암묵적인 가정에 의존하고 있다는 점을 지적하며, 이러한 가정들을 명시적인 인지 모델을 통해 드러내고자 합니다. 구조 방정식 모델(Structural Equation Models; SEM)을 활용하여, 누락된 데이터셋을 식별하고 연구 질문에 답할 수 있는 방법을 제시합니다.

- **Technical Details**: 세부적으로, 우리는 LLM(대형 언어 모델)의 ‘특성’에 관한 명시적 모델링을 통해 심리 측정(psychometrics)에서 영감을 받은 접근 방식을 확장하고 있습니다. 우리의 구조 방정식 모델은 언어 능력, 문화 지식, 정렬(alignment) 간의 관계를 분석합니다. 이 모델은 교차 언어 정렬 이전의 명확한 가정을 드러내어, 데이터셋 개발을 위한 방향을 제시합니다.

- **Performance Highlights**: 본 프레임워크는 기존의 벤치마크와 이론적 구성 간의 관계를 명확히 하며, 다양한 테스트가 잘 측정하는지를 평가할 수 있는 가능성을 열었습니다. 이는 LLM 특성에 대한 더 엄격하고 이론적으로 정당화된 이해를 위한 길을 제시하고, 결과적으로 생성적 AI 시스템의 포괄적이고 세밀한 평가를 촉진합니다.



### Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification (https://arxiv.org/abs/2409.16718)
Comments:
          EMNLP 2024 Main Conference

- **What's New**: 최근 Vision-Language Models (VLMs)에 대한 세밀한 조정이 이루어지면서, 클립 모델의 고유한 매개변수를 조정하는 것의 중요성을 재조명하였다. 이 연구에서는 모든 매개변수를 조정하는 대신 특정 매개변수만을 조정하는 CLIPFit 방법을 제안하였다.

- **Technical Details**: CLIPFit은 기존의 프롬프트 튜닝(prompt tuning) 및 어댑터 튜닝(adapter tuning) 방식과는 다르게, 추가적인 매개변수를 도입하지 않고 클립 모델의 특정 바이어스와 정규화 레이어만 조정하는 방법이다. 이로 인해 파라미터 수가 줄어들고, 성능이 향상된다.

- **Performance Highlights**: CLIPFit을 사용하여 zero-shot CLIP 대비 7.33%의 평균 조화 평균 정확도(harmonic mean accuracy) 개선을 달성하였으며, 이는 16-shot 설정에서 프롬프트 튜닝 및 어댑터 튜닝을 대체할 수 있는 유망한 옵션이다.



### Beyond Turing Test: Can GPT-4 Sway Experts' Decisions? (https://arxiv.org/abs/2409.16710)
- **What's New**: 이 논문은 LLM(대규모 언어 모델) 생성 텍스트가 독자의 반응을 기반으로 사람의 결정에 미치는 영향을 탐구합니다. 특히 아마추어와 전문가 독자의 반응 차이를 분석하며, GPT-4가 유도할 수 있는 설득력 있는 분석을 강조합니다.

- **Technical Details**: 실험은 ECTSum 데이터셋을 기반으로 설계되었으며, 2,425개의 ECC(어닝 컨퍼런스 콜) 기록을 바탕으로 합니다. GPT-4는 중립적 요약과 전문 분석 리포트를 생성하여 투자자에게 제공되었고, 두 단계에서 투자자의 결정을 유도했습니다. 실험은 아마추어와 전문가의 반응을 비교했습니다.

- **Performance Highlights**: 결과적으로 GPT-4가 생성한 분석은 아마추어의 결정에 더 큰 영향을 미치는 반면, 전문가는 전문가 작성 분석에 더 많은 영향을 받는 것으로 나타났습니다. 이는 LLM을 통한 분석 생성이 아마추어에게는 효과적일 수 있으나, 전문가 수준에는 미치지 못한다는 것을 보여줍니다.



### A Survey of Low-bit Large Language Models: Basics, Systems, and Algorithms (https://arxiv.org/abs/2409.16694)
Comments:
          Ruihao Gong leads the overall organization of the survey, with Yifu Ding and Jinyang Du contributing to Sections 2 and 3. Xingyu Zheng is responsible for authoring Section 4, while Chengtao Lv and Zining Wang collaborate on Section 5. Haotong Qin, Jinyang Guo, Michele Magno, and Xianglong Liu provide guidance during the whole process and assist in refining the final manuscript

- **What's New**: 이 논문에서는 대형 언어 모델(LLMs)을 위한 저비트 양자화(low-bit quantization) 방법에 대한 종합적인 조사를 제공합니다. 이는 메모리 사용량과 계산 요구 사항을 줄여주어 LLM의 실제 구현에서 중요한 과제를 해결하는 데 기여합니다.

- **Technical Details**: 저비트 양자화는 모델의 파라미터, 활성화(activations), 그리고 그래디언트의 비트 폭을 줄이는 프로세스로, 메모리 사용량과 계산 요구를 감소시킵니다. 이 논문에서는 저비트 LLM의 기초 원리, 시스템 구현, 알고리즘 전략을 다루고 있습니다. 새로운 저비트 데이터 형식과 양자화 세분화(granularity), 정적 또는 동적 양자화의 차이점 등이 소개됩니다.

- **Performance Highlights**: 저비트 양자화는 LLM의 훈련(training) 및 추론(inference)을 가속화하며, 정확도를 유지하면서도 모델을 저장하는 데 필요한 자원을 줄이는 데 효과적입니다. 이 연구에서는 새로운 연구 분야, 잠재적인 혁신, 그리고 새로운 기술이 LLM 양자화에 미치는 영향을 논의하며, LLM의 효율성 및 적합성을 향상시키기 위한 가치 있는 통찰력을 제공합니다.



### MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making (https://arxiv.org/abs/2409.16686)
- **What's New**: 이번 논문에서는 Multi-Scale Insight Agent (MSI-Agent)를 소개합니다. 이 에이전트는 장기 기억(Long-term memory)을 개선하여 LLMs의 계획 및 의사결정 능력을 높이기 위해 다양한 스케일에서 통찰(insight)을 효과적으로 요약하고 활용하는 방식으로 설계되었습니다.

- **Technical Details**: MSI-Agent는 경험 선택기(experience selector), 통찰 생성기(insight generator), 통찰 선택기(insight selector)의 세 가지 주요 구성 요소를 통해 작동합니다. 이 세 부분으로 이루어진 파이프라인(pipeline)을 활용하여, MSI는 작업에 특화된(task-specific) 고수준의 통찰을 생성하고 이를 데이터베이스에 저장한 후, 의사결정을 위해 관련 통찰을 활용할 수 있습니다.

- **Performance Highlights**: 실험 결과, MSI는 GPT3.5에 기반한 다른 통찰 전략보다 우수한 성능을 보였습니다. 또한, 씨앗 경험(seed experience)과 통찰을 선택하는 전략을 탐구하며, LLM에 더 유용하고 관련성 있는 통찰을 제공하여 더 나은 의사결정을 지원하는 데 초점을 맞추고 있습니다. MSI는 도메인 전환(domain-shifting) 시나리오에서 더 나은 강건성을 보여주는 것으로 관찰되고 있습니다.



### Emotional Dimension Control in Language Model-Based Text-to-Speech: Spanning a Broad Spectrum of Human Emotions (https://arxiv.org/abs/2409.16681)
Comments:
          submitted to ICASSP 2025

- **What's New**: 이 논문은 감정 텍스트 음성 변환(TTS) 시스템의 새로운 프레임워크를 제안하여, 감정 음성 데이터 없이도 다양한 감정 스타일을 합성할 수 있는 기능을 제공합니다. 이 시스템은 쾌감(pleasure), 자극(arousal), 지배(dominance)라는 감정 차원을 제어할 수 있도록 설계되었습니다.

- **Technical Details**: 제안된 TTS 프레임워크는 카테고리 레이블만을 사용해 감정 속성 예측기를 학습하고, 자가 감독 학습(self-supervised learning) 기능을 활용하여 텍스트 입력을 음소 토큰으로 변환합니다. 감정 차원 벡터를 통해 미세한 음향 세부사항의 병렬 예측을 조정합니다. 평가를 위해 LibriTTS 데이터셋을 사용하여 실험을 수행하였습니다.

- **Performance Highlights**: 실험 결과는 제안된 모델이 자연스러움과 다양한 감정 스타일을 효과적으로 합성할 수 있으며, 기존 모델을 초월하는 성능을 보여 줍니다. 또한, 감정 차원 제어를 통해 합성된 음성이 개선된 자연스러움과 발화 일관성을 나타냅니다.



### Speech Recognition Rescoring with Large Speech-Text Foundation Models (https://arxiv.org/abs/2409.16654)
- **What's New**: 본 연구는 LLMs(대규모 언어 모델)를 활용한 자동 음성 인식(ASR) 시스템의 두 번째 패스 재점수를 위한 새로운 접근 방식을 제안합니다. 특히, 음성과 텍스트 양식 모두에서 대규모 데이터를 활용하는 멀티모달 LLMs를 사용하여 기존 ASR의 성능을 향상시키고자 합니다.

- **Technical Details**: 제안된 방법은 HuBERT(음성 인코더)를 사용하여 음성 표현을 추출하고, 이를 k-means 군집화를 통해 불연속 음성 토큰으로 양자화합니다. 이후, 텍스트 토큰은 문장 조각 모델을 사용하여 유도됩니다. 텍스트 및 음성 토큰에 대한 인과 언어 모델링을 위해 디코더 전용 트랜스포머 구조를 적용합니다. 두 번째 패스에서는 ASR로부터의 n-best 가설을 사용하여 모델로부터의 가능도 점수를 계산하고 이를 바탕으로 재순위를 결정합니다.

- **Performance Highlights**: 실험 결과, Whisper 대규모 ASR에 대해 최대 20%의 상대적 개선을 보였으며, 텍스트 전용 LLM에 대해서도 최대 15%의 상대적 개선을 달성했습니다. 이러한 결과는 멀티모달 LLMs가 음성과 텍스트 정보를 활용하여 재점수 과정을 개선할 수 있음을 보여줍니다.



### Enabling Auditory Large Language Models for Automatic Speech Quality Evaluation (https://arxiv.org/abs/2409.16644)
Comments:
          submitted to ICASSP 2025

- **What's New**: 최근 도입된 auditory large language models (LLMs)를 활용하여 자동 음성 품질 평가를 수행하는 방안을 제안합니다. 이 모델은 MOS, SIM 및 A/B 테스트 결과 등을 예측할 수 있도록 조정됩니다.

- **Technical Details**: 이 연구에서는 SALMONN, Qwen-Audio 및 Qwen2-Audio와 같은 오픈소스 auditory LLM을 활용하여 NISQA, BVCC, SOMOS 및 VoxSim 데이터셋을 포함한 다양한 음성 품질 평가 작업을 수행합니다. fine-tuning된 auditory LLM은 자연 언어로 평가할 수 있는 추가적인 능력을 갖추게 됩니다.

- **Performance Highlights**: 실험 결과, auditory LLM은 state-of-the-art task-specific 작은 모델들과 비교하여 MOS 및 SIM 예측에서 경쟁력 있는 성능을 보여주었으며, A/B 테스트와 자연 언어 설명에서도 유망한 결과를 기록했습니다.



### A Unified Hallucination Mitigation Framework for Large Vision-Language Models (https://arxiv.org/abs/2409.16494)
Comments:
          Accepted by TMLR

- **What's New**: 본 논문에서는 다양한 형태의 환각(hallucination) 문제를 해결하기 위해, 쿼리(query)를 분류하고 이를 기반으로 다양한 환각 완화(mitigation) 과정을 수행하는 통합 프레임워크인 Dentist를 제안합니다. 이를 통해 환각의 종류에 따라 각기 다른 접근방법을 적용할 수 있습니다.

- **Technical Details**: Dentist 프레임워크는 먼저 쿼리를 인식(perception)과 추론(reasoning)으로 분류하고, 각 쿼리 유형에 맞는 처리 방법을 사용합니다. 구체적으로, 감지 쿼리에 대한 생성 결과는 부차적 질문(sub-questions)을 통해 검증되며, 추론 쿼리의 경우 체인 오브 생각(Chain-of-Thought, CoT)을 활용해 검증됩니다. 이 검증 루프는 정밀도 향상을 위해 수차례 반복됩니다.

- **Performance Highlights**: MMbench에서 InstructBLIP, LLaVA, VisualGLM과 같은 기존 기법에 비해 이미지 품질 관점에서 13.44%, 10.2%, 15.8%의 정확도 향상을 달성했습니다. 또한, 우리의 방법은 다양한 비주얼 언어 작업에서 효과적이고 우수함을 입증하였습니다.



### Revisiting Acoustic Features for Robust ASR (https://arxiv.org/abs/2409.16399)
Comments:
          submitted to ICASSP 2025

- **What's New**: 이 논문은 생물학적 청각 지각에서 영감을 받은 새로운 음향 특징들을 사용하여 자동 음성 인식(ASR) 시스템의 정확성과 강인성을 평가합니다. 저자들은 새로운 음향 특징인 Frequency Masked Spectrogram (FreqMask)와 Difference of Gammatone Spectrogram (DoGSpec)을 제안하며, 이들이 기존의 Log Mel Spectrogram (LogMelSpec)과 비교하여 우수한 성능을 나타낸다고 주장합니다.

- **Technical Details**: 이 연구에서는 생물학적으로 더 타당한 음향 특징을 사용하는 것이 ASR의 전사 정확성과 강인성에 미치는 영향을 분석합니다. 특징들은 Gammatone filterbank 특징(GammSpec), Frequency Masked Spectrogram (FreqMask), Difference of Gammatone Spectrogram (DoGSpec) 등으로 구성되며, 각 특징은 Short-Time Fourier Transform (STFT)으로부터 계산됩니다. 주목할 만한 점은 FreqMask가 주파수 마스킹 현상을 시뮬레이션하고, DoGSpec가 레테럴 억제를 모델링한다는 것입니다.

- **Performance Highlights**: 실험 결과 DoGSpec은 LogMelSpec에 비해 상대적으로 높은 강인성을 보였으나 정확도 저하가 миним했습니다. GammSpec은 Speech Robust Bench 벤치마크의 비적대적 노이즈에 대해 더 나은 정확도와 강인성을 나타내었습니다. 또한, FreqMask와 DoGSpec를 사용하는 모델이 adversarial attacks에 대해 유의미한 강인성을 제공하며, LogMelSpec과 유사한 WER를 달성했습니다.



### Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs (https://arxiv.org/abs/2409.16341)
- **What's New**: 이번 연구에서는 기존 LLM(대형 언어 모델)을 외부 도구와 함께 사용하는 데 있어, 데이터 품질 평가의 중요성을 강조합니다. 두 가지 새로운 접근 방식을 제안하여 LLM 훈련에 사용할 데이터의 신뢰성을 측정합니다.

- **Technical Details**: 첫 번째 접근 방식은 인간이 정의한 직관적인 정확성 기준을 사용하고, 두 번째 접근 방식은 모델 기반 평가와 in-context evaluation (ICE)을 이용합니다. 또한, 데이터 품질을 평가하기 위한 자동화된 방법을 구현하여 전문가의 주석과 높은 일치를 보였습니다.

- **Performance Highlights**: 데이터 품질이 높은 훈련 데이터로 학습한 모델이 검증되지 않은 데이터로 학습한 모델보다 더 우수한 성능을 보임을 실증적으로 보여주었습니다. 이는 효율적인 훈련 데이터 관리의 중요성을 입증하며, ToolBench와 ToolAlpaca 벤치마크에서 검증되었습니다.



### Towards Within-Class Variation in Alzheimer's Disease Detection from Spontaneous Speech (https://arxiv.org/abs/2409.16322)
- **What's New**: 이 논문은 알츠하이머병(Alzheimer's Disease, AD) 탐지 분야에서 머신러닝(classification model)을 활용하여 AD 환자와 비환자를 구별하려는 연구의 일환이다. 기존의 이진 분류(binary classification) 접근법의 한계점을 지적하며, 내적 변동성(within-class variation) 및 샘플 불균형(instance-level imbalance) 문제를 해결하기 위한 두 가지 새로운 방법, Soft Target Distillation(SoTD)와 Instance-level Re-balancing(InRe)을 제안한다.

- **Technical Details**: AD 탐지의 중요한 문제는 샘플 간 인지 기능의 정도가 다르다는 것이다. SoTD는 샘플의 세부 정보를 인식하여 신뢰도(Awareness of sample degree)를 바탕으로 단계적인 학습을 제공하고, InRe는 데이터 로스(loss)를 재조정하여 오버피팅(over-fitting)을 완화하는 방법이다. 실험은 ADReSS와 ADReSSo 데이터셋에서 BERT 및 RoBERTa 임베딩(features)을 사용하여 수행되었다.

- **Performance Highlights**: 실험 결과, SoTD와 InRe 방법을 도입함으로써 AD 탐지 정확도가 크게 향상되었으며, SoTD는 특히 모델 앙상블(ensemble estimation) 기법에 비해 더 높은 효율성을 보였다. 또한, InRe는 모델의 오버피팅을 현저히 줄이며, 훈련 안정성을 높였다.



### A Literature Review of Keyword Spotting Technologies for Urdu (https://arxiv.org/abs/2409.16317)
- **What's New**: 이 문헌 리뷰는 파키스탄의 저자원 언어(Low-Resource Language)인 우르두어의 키워드 스포팅(Keyword Spotting, KWS) 기술 발전을 조사합니다. 저자원 언어가 직면한 독특한 도전과제와 이를 해결하기 위한 맞춤형 솔루션의 필요성을 강조합니다.

- **Technical Details**: 이 리뷰는 가우시안 혼합 모델(Gaussian Mixture Models, GMMs)에서 심층 신경망(Deep Neural Networks, DNNs) 및 변환기(transformer)와 같은 복잡한 신경 아키텍처의 진화를 추적합니다. 특히 다중 작업 학습(multi-task learning)과 자가 감독 학습(self-supervised learning) 접근법을 통합하여 라벨 없는 데이터(unlabeled data)를 활용하는 방법을 강조합니다. 새로운 EdgeCRNN 모델과 통합된 CNN과 RNN을 포함하여, 키워드 탐지를 위한 최신 모델들과 그 효율성을 논의합니다.

- **Performance Highlights**: 최신 연구에서, 자가 감독 학습(S3RL) 및 경량 변환기 모델들이 우르두어와 같은 저자원 언어에서 KWS 효율성과 정확성을 향상시키는데 긍정적인 영향을 미쳤습니다. Massively Multilingual Speech(MMS) 프로젝트는 1000개 이상의 언어에서 모델을 사전 학습하여 현대적인 음성 기술을 다수의 언어로 확대했으나, 여전히 우르두어는 데이터 부족 문제로 인해 성능 향상에 제한이 있습니다.



### How Redundant Is the Transformer Stack in Speech Representation Models? (https://arxiv.org/abs/2409.16302)
- **What's New**: 이 논문에서는 transformer 기반의 음성 표현 모델에서 계층 간의 중복성을 조사하고, 이러한 중복성을 활용하여 계층을 가지 치거나 대체할 수 있는 가능성을 탐구합니다.

- **Technical Details**: 층 유사성을 분석하기 위해 세 가지 유사도 메트릭(cosine similarity, centered kernel alignment, mutual nearest-neighbor alignment)을 사용하였으며, 고유한 블록 구조와 작업 단계를 발견했습니다. 또한, pruning을 통해 transformer 계층을 최대 40%까지 축소할 수 있음을 보여줍니다.

- **Performance Highlights**: 지식 증류(knowledge distillation) 방법을 이용하여 전체 transformer 스택을 최소화하고, 네트워크 크기를 95-98% 감소시키며, 추론 시간은 최대 94%까지 단축할 수 있음을 입증하였습니다.



### Efficient Training of Self-Supervised Speech Foundation Models on a Compute Budg (https://arxiv.org/abs/2409.16295)
Comments:
          To appear in SLT 2024

- **What's New**: 이 연구는 제한된 계산 예산 하에서 음성 기반 모델 학습의 효율성을 높이기 위한 다양한 요소들을 분석하고 익히려는 시도를 포함하고 있으며, 기존의 방법론들이 잘 알려진 자원 효율성과 성능 간의 균형을 찾기 위한 실험을 진행했습니다.

- **Technical Details**: 논문에서는 self-supervised learning (SSL) 목표를 평가하고, 모델 아키텍처, 모델 크기, 데이터 크기가 SSL 성과에 미치는 영향을 체계적으로 조사합니다. 연구에 따르면 슬리머 모델 아키텍처가 일반적인 작은 모델 아키텍처보다 더 뛰어난 성과를 보이며, 사전 훈련 데이터의 크기도 성능에 큰 영향을 미친다고 밝혔습니다. 또한, 특정 계산 예산 내에서 최적의 모델 크기를 찾는 방법을 제안합니다.

- **Performance Highlights**: 이 연구의 주요 결과는 다음과 같습니다: 1) SSL 목표는 성과에 영향을 줄 수 있지만, 다른 주요 요소에 비해 그 영향이 덜하다. 2) 동일한 계산 및 파라미터 예산 하에서 슬리머 SSL 모델이 일반적으로 사용되는 3-레이어 작은 SSL 모델을 초월한다. 3) 충분히 큰 사전 훈련 데이터의 중요성이 강조되며, 데이터 사이즈와 이터레이션 간의 균형이 필요하다.



### Unsupervised Word Discovery: Boundary Detection with Clustering vs. Dynamic Programming (https://arxiv.org/abs/2409.14486)
Comments:
          3 figures, 3 tables

- **What's New**: 이 논문에서는 비지도 학습 환경에서 음성을 단어와 유사한 단위로 분할하고 이를 군집화하여 렉시콘(lexicon)을 구축하는 새로운 접근 방식을 제안합니다. 이 방법은 인접한 자기 지도 특성 간의 비유사성을 이용하여 단어 경계를 예측하고, 이를 통해 단순한 방식으로 렉시콘을 구축합니다.

- **Technical Details**: 연구에서는 먼저 우세 기반 접근(presence-based approach)을 사용하여 단어 경계를 찾아내고, 그런 다음 발견된 단어들과 그에 대한 특성을 클러스터링하여 렉시콘을 구축합니다. 이 시스템은 HuBERT라는 고급 음성 특성을 기반으로 하며, 주어진 음성 프레임 사이의 코사인 거리(cosine distance)를 이용하여 단어 경계를 예측합니다. 이후 PCA(주성분 분석)로 차원을 축소한 후, 음향 단어 임베딩(acoustic word embedding)을 통해 단어 세그먼트를 고정 차원의 벡터로 변환하여 클러스터링합니다.

- **Performance Highlights**: ZeroSpeech 벤치마크의 5개 언어에서 테스트한 결과, 제안된 간단한 방법은 새로운 ES-KMeans+ 방법과 유사한 성능을 보이며, 속도는 거의 5배 빠릅니다. 또한, 언어에 특화된 모델이 다국어 모델보다 성능이 더 뛰어난 것을 확인했습니다.



### A fast and sound tagging method for discontinuous named-entity recognition (https://arxiv.org/abs/2409.16243)
Comments:
          EMNLP 2024

- **What's New**: 논문에서는 불연속(named entity) 개체 인식을 위한 새로운 태깅 방식(tagging scheme)을 제안합니다. 이 방식은 불연속적인 언급의 내부 구조에 대한 명시적 설명에 기반하며, 혼란 없는 태그 시퀀스 예측을 보장합니다.

- **Technical Details**: 제안된 방법은 가중 유한 상태 자동자(weighted finite state automaton)를 사용하여 마진(marginal) 및 최대 사후 확률 추론(maximum a posteriori inference)을 수행합니다. 이 방법의 시간 복잡도는 입력 길이에 대해 선형이며, GPU에서 효율적으로 구현할 수 있습니다.

- **Performance Highlights**: 생물의학(biomedical) 분야의 세 가지 영어 데이터셋에서 검증하였으며, 기존의 최첨단 결과와 유사한 성능을 보이면서 더 간단하고 빠른 모델을 사용하였습니다.



### EuroLLM: Multilingual Language Models for Europ (https://arxiv.org/abs/2409.16235)
- **What's New**: 이번 연구는 EuroLLM 프로젝트를 소개하고 있으며, 이는 유럽 연합의 모든 공식 언어 및 추가 언어들에 대해 이해하고 생성할 수 있는 다국어(open-weight) 대형 언어 모델(LLM) 스위트를 개발하는 것을 목표로 합니다.

- **Technical Details**: EuroLLM 모델은 다국어 토크나이저를 개발하고, 다양한 출처에서 수집한 데이터를 필터링하여 훈련 데이터셋을 구성하였습니다. 데이터는 웹 데이터, 평행 데이터, 코드/수학 데이터 및 고품질 데이터로 구분되며, 각 언어별로 적절한 데이터를 수집하였습니다. 또한, 머신러닝 성능 향상을 위한 하이퍼파라미터 설정 및 모델 사전 훈련, 후 훈련 과정을 통해 EuroLLM-1.7B 및 EuroLLM-1.7B-Instruct 모델을 개발하였습니다.

- **Performance Highlights**: EuroLLM 모델은 여러 다국어 일반 벤치마크 및 기계 번역 과제를 평가하였으며, 초기 모델인 EuroLLM-1.7B와 EuroLLM-1.7B-Instruct이 여러 언어에서 경쟁력 있는 성능을 보였습니다.



### HelloBench: Evaluating Long Text Generation Capabilities of Large Language Models (https://arxiv.org/abs/2409.16191)
- **What's New**: 최근 대형 언어 모델(LLMs)의 긴 텍스트 생성 능력에 대한 포괄적인 벤치마크가 부족함을 인식하고, 이를 해결하기 위해 계층적 긴 텍스트 생성 벤치마크인 HelloBench를 제안합니다.

- **Technical Details**: HelloBench는 Bloom's Taxonomy에 기반하여 긴 텍스트 생성 작업을 오픈 엔디드 QA, 요약, 채팅, 텍스트 완성, 휴리스틱 텍스트 생성 등 5개 하위 작업으로 분류합니다. 또한 HelloEval이라는 인간-정렬(human-aligned) 평가 방법을 제안하여 인간 평가 시 소요되는 시간을 대폭 줄이면서도 인간 평가와의 상관성을 높입니다.

- **Performance Highlights**: 현재 LLM들은 4000단어 이상의 긴 텍스트 생성에 어려움을 겪고 있으며, 일부는 긴 텍스트 생성이 가능하지만 반복과 품질 저하 등의 문제가 큽니다. HelloEval은 기존 전통적인 지표들(ROUGE, BLEU 등)과 비교하여 인간 평가에 가장 높은 상관성을 보여줍니다.



### Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting Framework (https://arxiv.org/abs/2409.16146)
- **What's New**: 재검색 강화 생성(RAG) 모델의 예측 불확실성을 다룬 연구로, 모델이 자신감이 낮은 질문에 대해서는 답변을 거부하는 프로세스 강화에 중점을 두고 있습니다.

- **Technical Details**: 두 가지 주요 요소, 즉 검색된 결과의 품질과 이 결과들이 활용되는 방식을 통해 RAG 모델의 신뢰도를 평가하는 새로운 접근방식을 제안합니다. 이 방법은 counterfactual prompting 프레임워크를 기반으로 하여, 모델이 이러한 요소를 변경할 수 있도록 유도합니다.

- **Performance Highlights**: 제안된 프레임워크는 Mistral과 ChatGPT를 이용한 RAG 실험에서 3개의 4개 설정에서 주의 깊음(carefulness)과 위험(risk) 측면에서 기존 기준선보다 높은 성능을 보여주었으며, 주의 깊음에서 최대 14.76% 개선 및 위험에서 평균 2.88% 감소를 달성하였습니다.



### Exploring Hint Generation Approaches in Open-Domain Question Answering (https://arxiv.org/abs/2409.16096)
Comments:
          Accepted at EMNLP 2024

- **What's New**: 이 논문에서는 기존의 정보 검색(retrieval) 및 생성(generation) 기반 방법 대신 자동 힌트 생성(Automatic Hint Generation, HG) 기술을 활용한 새로운 QA 시스템 구성 요소인 HINTQA를 제안합니다. HINTQA는 질문에 대한 답변 가능성을 제시하는 힌트를 생성하여 QA 시스템의 정확도를 높입니다.

- **Technical Details**: HINTQA는 질문 q와 후보 답변 집합 𝒜을 활용하여 다수의 힌트를 생성합니다. 각 힌트는 수렴 점수(convergence score)인 HICOS를 통해 힌트의 유용성을 측정하며, 이는 질문에 대한 잠재적 답변을 좁힙니다. 제안된 시스템은 TriviaQA, Natural Questions, Web Questions 데이터셋을 사용하여 세 가지 QA 데이터셋에서 힌트 생성의 효과를 실험했습니다.

- **Performance Highlights**: HINTQA 방식은 정보 검색 및 생성 기반 방법보다 우수한 성과를 보였습니다. 연구 결과에 따르면 힌트를 사용하는 것이 검색된 문서나 생성된 문맥보다 답변의 정확성을 높이는 데 더 효과적이라는 것을 증명했습니다.



### Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering (https://arxiv.org/abs/2409.16025)
Comments:
          EMNLP 2024

- **What's New**: 본 논문은 다국어 및 다시장간 제품 기반 질문 응답(Multilingual Cross-market Product-based Question Answering, MCPQA)이라는 새로운 작업을 제안합니다. 특정 시장의 제품 관련 질문에 대해 더 많은 자원이 있는 보조 시장 정보를 활용하여 답변을 제공합니다.

- **Technical Details**: 우리는 17개 시장에서 700만 개 이상의 질문으로 구성된 데이터 세트를 도입하고 전자 상거래 분야의 질문을 맥락으로 자동 번역하여 McMarket라는 데이터 세트를 분석했습니다. 두 개의 하위 작업인 리뷰 기반 답변 생성(Answer Generation, AG)과 제품 관련 질문 순위 매기기(Question Ranking, QR)에 대한 실험이 수행되었습니다.

- **Performance Highlights**: 결과적으로, 크로스 마켓 정보의 통합이 두 작업 모두에서 성능을 크게 향상시켰으며, LLM 기반 접근 방식이 전통적인 모델보다 우수한 성능을 보여주었습니다.



### AI Can Be Cognitively Biased: An Exploratory Study on Threshold Priming in LLM-Based Batch Relevance Assessmen (https://arxiv.org/abs/2409.16022)
- **What's New**: 이 연구는 LLMs(대형 언어 모델)가 정보 검색(Information Retrieval) 작업에서 문서의 관련성을 판단할 때 경험적으로 관찰된 threshold priming 효과에 영향을 받는지를 조사합니다. 이는 LLM의 인지 편향(cognitive bias)에 대한 연구의 일환으로, LLM이 사람의 판단과 유사한 방식으로 영향을 받을 수 있음을 보여줍니다.

- **Technical Details**: 이 연구에서는 TREC 2019 Deep Learning 구문 수집에서 10개의 주제를 대상으로 LLM의 문서 관련성 평가를 시험했습니다. 실험에는 GPT-3.5, GPT-4, LLaMa2-13B 및 LLaMa2-70B 모델이 사용되었습니다. 초기 문서의 관련성 레벨이 후속 문서의 평가에 미치는 영향을 분석하기 위해 다양한 프로로구(prologue) 및 에필로그(epilogue) 길이를 가지고 실험을 수행했습니다.

- **Performance Highlights**: 결과에 따르면, 초기 문서의 높은 관련성은 후속 문서의 낮은 점수를 유도하는 경향이 있었습니다. 반대로 초기 문서의 낮은 관련성은 후속 문서에 대한 높은 점수를 유발했습니다. LLaMa2-70B 모델은 일부 조건에서 다른 모델과 다른 경향을 보였으며, 다른 모델들은 threshold priming 효과의 성격을 유지했습니다.



### Bridging Speech and Text: Enhancing ASR with Pinyin-to-Character Pre-training in LLMs (https://arxiv.org/abs/2409.16005)
Comments:
          Accepted by ISCSLP2024-Special session-Speech Processing in LLM Era

- **What's New**: 이 논문은 대형 언어 모델(LLM)과 사전 훈련된 음성 모델을 통합하여 자동 음성 인식(ASR)에서의 성능을 개선하는 새로운 접근 방식을 제안합니다. 특히, LLM을 음성 특징을 나타내는 Pinyin 임베딩 시퀀스로 사전 훈련하여 중국어 문자를 생성하도록 훈련합니다.

- **Technical Details**: 본 연구에서는 두 단계의 훈련 방법을 제안하는데, 첫 번째 단계에서 LLM을 Pinyin 입력으로부터 중국어 문자를 예측하도록 미세 조정합니다. 두 번째 단계에서는 사전 훈련된 오디오 모델에서 오디오 특징을 추출하여 LLM에 전달합니다. LoRA(低秩适应)을 사용하여 매개변수를 업데이트하며, 이를 통해 모델이 음성 특징을 수용하고 해당 전사(prediction)를 예측할 수 있도록 합니다.

- **Performance Highlights**: 이 연구에서 제안한 접근 방식은 AISHELL-1 코퍼스에서 Pinyin-문자 사전 훈련 없이 기본 기준선에 비해 9.5%의 상대적인 성능 향상을 보여주었고, 추가적인 보조 텍스트 데이터를 포함하여 Pinyin-문자 사전 훈련을 진행함으로써 19.0%의 성능 향상을 기록했습니다.



### Finetuning LLMs for Comparative Assessment Tasks (https://arxiv.org/abs/2409.15979)
Comments:
          8 pages, 5 figures, 6 tables

- **What's New**: 이 논문은 instruction-tuned 대규모 언어 모델(LLM)을 활용한 비교 평가(comparative assessment) framework를 제안하여, 전통적인 평가 방법들보다 효율적인 방식으로 NLG 시스템의 텍스트 품질을 평가하는 방법을 다룹니다.

- **Technical Details**: 제안된 방법은 LLM을 비교 평가를 위한 soft probabilities로 fine-tuning(fine-tuning)하여, 두 텍스트 간의 비교 결과를 좀 더 정밀하게 모델링하는 접근법에 중점을 둡니다. 이를 통해 true inference time probabilities와 PoE(제품 전문가) 프레임워크 내에서의 가정된 분포를 일치시킬 수 있습니다.

- **Performance Highlights**: 이 논문에서 제안된 방법은 기존의 하드 이진 결정(hard binary decision) 훈련보다 효율적인 비교 수로 더 높은 성능을 달성할 수 있음을 보여주며, 이는 다양한 NLG 평가 벤치마크에서 입증되었습니다.



### Beats of Bias: Analyzing Lyrics with Topic Modeling and Gender Bias Measurements (https://arxiv.org/abs/2409.15949)
Comments:
          Accepted and presented at the 17th International Conference on Social Computing, Behavioral-Cultural Modeling, & Prediction and Behavior Representation in Modeling and Simulation (see this https URL )

- **What's New**: 이 논문은 주제 모델링(topic modeling)과 편견 측정(bias measurement) 기법을 사용하여 영어 노래 가사에서의 성별 편향을 분석하고자 합니다. 537,553개의 영어 노래를 BERTopic으로 클러스터링하여 주제를 구분하고, 시간이 지남에 따라 이들이 어떻게 변화하는지를 보여줍니다.

- **Technical Details**: 노래 가사를 분석하기 위해 자연어 처리(Natural Language Processing, NLP) 기술을 적용하였으며, SC-WEAT(Single Category Word Embedding Association Test)를 사용하여 각 장르별 편향 점수를 산출했습니다. 541개의 주제를 발견했으며, rap 장르의 가사에서 성적 불균형이 두드러진다는 점을 확인했습니다.

- **Performance Highlights**: 연구 결과, 가사의 주요 테마가 로맨스에서 여성의 성적 대상화로 변화하고 있으며, 특히 rap 장르에서 공격적인 표현과 여성혐오적 가사가 남용되고 있음을 발견했습니다. 남성과 관련된 단어는 전반적으로 남성 편향을 보이는 반면, 외모와 약함과 관련된 단어는 여성 편향을 나타냈습니다.



### Automated test generation to evaluate tool-augmented LLMs as conversational AI agents (https://arxiv.org/abs/2409.15934)
Comments:
          14 pages, 5 figures, Submitted to GenBench@EMNLP2024

- **What's New**: 본 논문에서는 Tool-augmented LLMs(대형 언어 모델)를 평가하기 위한 테스트 생성 파이프라인을 제시하고 있습니다. 기존의 평가 데이터셋이 단일 상호작용 및 함수 호출에만 집중했던 반면, 이 연구는 사용자 정의 절차에 기반한 다양한 테스트를 생성합니다.

- **Technical Details**: LLMs를 기반으로 한 추천된 파이프라인은 중간 그래프(intermediate graphs)를 활용하여 발생할 수 있는 비현실적인 내용生성을 제한하고, 대화의 가능성을 널리 포괄하는 고품질 데이터를 생성합니다. 이 연구에서는 고객 지원을 위한 AI 에이전트 평가를 위한 ALMITA(Automated benchmark of Language Models for Intelligent Tool-augmented Agents)라는 수작업으로 제작된 데이터셋을 개발했습니다.

- **Performance Highlights**: 기존 LLM들은 단일 메시지 정확도 및 올바른 함수 호출에 있어 높은 성능을 보였지만, 전체 대화에서의 정확도는 제한적임을 보여주었습니다. 이는 LLMs가 완전 자율 고객 지원 AI 에이전트로 배치될 경우의 성공 가능성에 의문을 제기합니다.



### SLIMER-IT: Zero-Shot NER on Italian Languag (https://arxiv.org/abs/2409.15933)
- **What's New**: 이 논문에서는 이탈리아어에 대한 제로샷 이름 개체 인식(Zero-Shot Named Entity Recognition, NER) 평가 프레임워크를 정의하고, 제로샷 NER을 위한 SLIMER의 이탈리아어 버전인 SLIMER-IT를 소개합니다. SLIMER-IT는 정의 및 가이드라인으로 향상된 프롬프트를 활용하여 다루지 않은 엔티티 태그를 식별하는 데 우수성을 보입니다.

- **Technical Details**: SLIMER-IT는 대형 언어 모델(LLM)을 기반으로 하며, 인스트럭션 튜닝(instruction tuning)을 통해 성능을 개선합니다. 이 접근법은 주어진 텍스트에서 각각의 엔티티 타입을 효과적으로 추출하기 위해 설계된 프롬프트를 사용하여, 모델이 각 엔티티 타입에 집중할 수 있도록 지원합니다. SLIMER는 네임드 엔티티(Named Entity)에 대한 정의와 가이드라인을 제공하여 모델의 라벨링을 최적화합니다.

- **Performance Highlights**: SLIMER-IT는 기존의 다른 최첨단 모델들과 비교했을 때 보지 못한 엔티티 태그(label)를 라벨링하는 데 있어 뛰어난 성능을 보여주었습니다. 실험 결과는 SLIMER-IT가 이탈리아어로 된 데이터셋에서 제로샷 NER을 수행하는 데 매우 효과적임을 입증하였습니다.



### Multilingual Transfer and Domain Adaptation for Low-Resource Languages of Spain (https://arxiv.org/abs/2409.15924)
Comments:
          6 pages,wmt24. arXiv admin note: substantial text overlap with arXiv:2409.14842; text overlap with arXiv:2409.14800

- **What's New**: 이번 논문은 Huawei Translation Service Center (HW-TSC)의 WMT 2024에서의 스페인 저자원 언어 번역 태스크 제출 상태를 소개합니다. 이 연구팀은 스페인어에서 아라곤어(es-arg), 아라니세어(es-arn), 아스투리안어(es-ast)로의 번역 작업에 참여했습니다.

- **Technical Details**: 우리는 다국어 전이(multi-language transfer), 정규화 드롭아웃(regularized dropout), 포워드 번역(forward translation), 백 번역(back translation), Labse denoising, 전이 집합 학습(transduction ensemble learning) 등의 훈련 전략을 사용하여 딥 트랜스포머 기반의 신경 기계 번역(NMT) 모델을 훈련했습니다.

- **Performance Highlights**: 이러한 개선 전략을 통해 우리 제출물은 최종 평가에서 경쟁력 있는 결과를 달성했습니다.



### Explaining word embeddings with perfect fidelity: Case study in research impact prediction (https://arxiv.org/abs/2409.15912)
- **What's New**: 이 논문은 논문 품질 예측을 위한 새로운 기능 중요성 방법인 Self-model Rated Entities (SMER)를 제안하며, SMER는 로지스틱 회귀 모델과 단어 임베딩을 기반으로 하여 정확하고 명확한 설명을 제공합니다.

- **Technical Details**: SMER는 예측의 평균이 특정 단어에 대한 개별 예측과 정확히 대응되도록 하여 로지스틱 회귀 모델에 대해 이론적으로 완벽한 정확성을 보장합니다. 본 연구는 5가지 다양한 실험을 통해 50,000개의 CORD-19 연구 논문에 대한 정량적 및 정성적 평가를 실시했습니다.

- **Performance Highlights**: AOPC 곡선 분석을 통해 SMER는 로지스틱 회귀에서 LIME보다 향상된 설명을 생성한다는 점을 실험적으로 입증하였습니다.



### A Modular-based Strategy for Mitigating Gradient Conflicts in Simultaneous Speech Translation (https://arxiv.org/abs/2409.15911)
- **What's New**: 이 논문에서는 Simultaneous Speech Translation (SimulST)에서 발생하는 최적화 충돌 문제를 해결하기 위해 Modular Gradient Conflict Mitigation (MGCM) 전략을 제안합니다. 기존의 모델 레벨에서 충돌을 해결하는 방법들은 비효율적이었으나, MGCM은 모듈 레벨에서 충돌을 탐지하고 해결함으로써, GPU 메모리 사용을 95% 이상 절감하며 SimulST 성능을 향상시켜줍니다.

- **Technical Details**: MGCM은 Multi-task Learning (MTL) 프레임워크 내의 SimulST 작업을 보다 세밀한 모듈 수준에서 충돌을 감지하고 완화하는데 초점을 맞추고 있습니다. 이는 특히 Simultaneous Automatic Speech Recognition (SimulASR)와 Simultaneous Machine Translation (SimulMT) 등의 보조 작업과 관련된 최적화 목표의 충돌로 발생하는 문제를 해결합니다. 기존의 PCGrad 방법의 한계를 극복하기 위해, MGCM은 모듈화를 통해 결과적이고 효율적인 충돌 해소가 가능하게 합니다.

- **Performance Highlights**: MGCM을 적용한 실험 결과, SimulST 성능은 중간 및 고지연 조건에서 크게 향상되었으며, 오프라인 작업에서 0.68의 BLEU 점수 개선을 달성하였습니다. 또한, GPU 메모리 소비를 95% 이상 줄여, SimulST 작업에 대한 효과적인 솔루션으로 자리잡게 되었습니다.



### Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection (https://arxiv.org/abs/2409.15907)
Comments:
          This paper has been accepted by ECAI 2024

- **What's New**: 이번 논문에서는 LLMs가 데이터베이스 스키마와 셀 값에 대한 도메인 지식을 효과적으로 이해하고 활용할 수 있도록 '지식 주입' (knowledge injection) 방법을 도입하였습니다. 이를 통해 Text-to-SQL 작업에서의 성능을 향상시키는 다양한 기술적 접근을 선보입니다.

- **Technical Details**: 제안된 방법은 특정 도메인 데이터베이스 지식을 기반으로 LLMs를 사전 훈련 (pre-training)하고, 하위 Text-to-SQL 작업에 맞춰 미세 조정 (fine-tuning)하는 것입니다. 이를 통해 Execution Match (EX) 및 Exact Match (EM) 지표에서 현저한 개선을 이루어내며, 컬럼 이름 생성 및 값 일치 오류를 줄입니다.

- **Performance Highlights**: 실험 결과, 제안한 지식 주입 방법이 여러 개의 오픈 소스 LLMs에서 실질적인 성능 향상을 보여주었으며, 이는 다양한 Text-to-SQL 작업에 광범위하게 적용 가능하다는 것을 검증하였습니다.



### Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering (https://arxiv.org/abs/2409.15902)
Comments:
          18 pages, 2 figures, 7 tables

- **What's New**: 본 논문은 간단한 질문에 대한 답변을 제공하기 위한 신뢰할 수 있는 접근방식인 Konstruktor 를 소개합니다. 이 방법은 질문에서 엔티티(entities)를 추출하고 이를 구조화된 지식 그래프(knowledge graphs)와 결합하여 답변을 찾는 과정을 세 가지 단계로 나누어 체계적으로 접근합니다.

- **Technical Details**: Konstruktor는 (i) 엔티티 추출 및 링크, (ii) 관계 예측, (iii) 지식 그래프 쿼리의 세 가지 컴포넌트를 포함합니다. 이를 통해 자연어 처리의 강력한 언어 모델과 지식 그래프의 해석력을 활용합니다. 특히, 이 연구는 Wikidata와 관련된 다양한 방법 및 데이터셋을 활용하여 성능을 평가합니다.

- **Performance Highlights**: 이 연구는 Konstruktor가 기존의 여러 기법, 특히 비용이 많이 드는 end-to-end 신경망 방법들을 능가하는 성과를 보여주며, 네 가지 데이터셋에서 강력한 결과를 보고합니다. 또한, 엔티티 링크 및 관계 탐지에 대한 SOTA 기술과 비교하여 뛰어난 성능을 입증합니다.



### HLB: Benchmarking LLMs' Humanlikeness in Language Us (https://arxiv.org/abs/2409.15890)
- **What's New**: 이 논문에서는 20개의 대형 언어 모델(LLMs)의 인간 유사성을 평가하기 위한 포괄적인 인간 유사성 벤치마크(Humanlikeness Benchmark, HLB)를 제시합니다.

- **Technical Details**: 이 연구는 음성(sound), 단어(word), 구문(syntax), 의미(semantics), 담론(discourse) 등 핵심 언어적 측면을 탐구하기 위해 설계된 10개의 심리언어학적 실험을 사용하여 LLM을 평가합니다. 각 실험의 응답을 2000명 이상의 인간 참가자로부터 수집하고, LLMs의 응답과 비교하여 분포 유사성(distributional similarity)을 통해 인간 유사성을 정량화하였습니다.

- **Performance Highlights**: 결과는 LLM이 여러 언어적 수준에서 인간의 반응을 얼마나 잘 재현하는지에 대한 미세한 차이를 밝혀냅니다. 또한, 다른 성능 지표의 개선이 반드시 인간 유사성의 증가로 이어지지 않으며, 몇 가지 경우에는 감소를 초래할 수 있음을 보여줍니다. 이 연구는 LLM의 언어 사용에서 인간 유사성을 시스템적으로 평가할 수 있는 최초의 프레임워크를 제공합니다.



### Machine Translation Advancements of Low-Resource Indian Languages by Transfer Learning (https://arxiv.org/abs/2409.15879)
Comments:
          6 pages, wmt24. arXiv admin note: substantial text overlap with arXiv:2409.14800

- **What's New**: 이 논문은 Huawei Translation Center (HW-TSC)가 WMT24 인도 언어 기계 번역(MT) 공동 작업에 제출한 내용을 소개합니다. 본 연구는 리소스가 부족한 인도 언어에 대한 신뢰할 수 있는 기계 번역 시스템을 개발하기 위해 두 가지 별도의 knowledge transfer 전략을 적용했습니다.

- **Technical Details**: Assamese(as)와 Manipuri(mn)의 경우, 우리는 기존의 IndicTrans2 오픈소스 모델을 미세 조정하여 영어와 이들 언어 간의 쌍방향 번역을 가능하게 했습니다. Khasi (kh)와 Mizo (mz)의 경우, 네 언어 쌍의 이중 언어 데이터를 이용하여 다국어 모델을 훈련시켰고, 추가적으로 약 8천 쌍의 영어-벵골어 이중 언어 데이터를 사용했습니다. 이를 통해 데이터 부족 문제를 해결했습니다.

- **Performance Highlights**: 전달 학습 실험에서는 en-as에 대해 23.5 BLEU, en-mn에 대해 31.8 BLEU, as-en에 대해 36.2 BLEU, mn-en에 대해 47.9 BLEU의 성과를 거두었습니다. 다국어 모델의 전이 학습 실험 결과는 en-kh에서 19.7 BLEU, en-mz에서 32.8 BLEU, kh-en에서 16.1 BLEU, mz-en에서 33.9 BLEU를 기록하였습니다.



### Privacy Evaluation Benchmarks for NLP Models (https://arxiv.org/abs/2409.15868)
Comments:
          Needs further optimization

- **What's New**: 이 논문은 NLP 모델 특성에 따른 개인정보 공격(Benchmarking) 및 방어 전략 평가 프레임워크를 제안합니다. 일반적인 소규모 모델 및 대형 언어 모델(LLM)을 포함한 여러 종류의 데이터와 프로토콜을 지원하여 종합적인 공격과 방어 전략의 평가를 가능하게 합니다.

- **Technical Details**: 논문에서는 Membership Inference Attack (MIA), Model Inversion Attack (MDIA), Attribute Inference Attack (AIA), Model Extraction Attack (MEA)와 같은 네 가지 주요 개인정보 공격 방식에 대해 연구하며, 다양한 방어 방법과 함께 Knowledge Distillation (KD) 방식을 통해 공격 성능을 개선할 수 있는 방법을 제안합니다. 또한, 공격을 체인 방식으로 연결하는 프레임워크를 제안하여 더욱 서버능한 공격 목표를 달성할 수 있도록 지원합니다.

- **Performance Highlights**: 연구 결과에 따르면, 다양한 도메인 데이터의 사용은 공격 성능에 미치는 영향이 있으며, 각 공격 방식 간의 상호작용과 관계를 분석하여 개선된 방어 전략 및 공격 방법들을 개발했습니다. 이 평가 벤치마크는 다양한 NLP 모델과 데이터셋을 지원하며, 전반적인 프라이버시 위험을 평가할 수 있는 목적으로 디자인되었습니다.



### A Zero-Shot Open-Vocabulary Pipeline for Dialogue Understanding (https://arxiv.org/abs/2409.15861)
- **What's New**: 본 연구에서 우리는 제로샷(zero-shot), 오픈 어휘(open-vocabulary) 시스템을 제안하며, 디지털 대화 이해를 위한 통합된 파이프라인을 구성합니다.

- **Technical Details**: 제안된 방법론은 도메인 분류(domain classification)부터 시작하여, 여러 방법으로 DST(대화 상태 추적)를 수행합니다. 특히 DST를 질문-답변(question-answering) 문제로 변환하는 'DST-as-QA' 방식과 자가 수정 프롬프트(self-refining prompt) 기법을 활용한 'DST-as-SRP'를 포함합니다. 이 시스템은 고정된 슬롯 값에 의존하지 않아 동적으로 적응할 수 있습니다.

- **Performance Highlights**: 제안된 방법은 MultiWOZ 2.1 데이터셋에서 20% 향상된 Joint Goal Accuracy(JGA)를 달성하며, LLM API에 대한 요청 수를 최대 90% 줄입니다. 또한, 제로샷 및 오픈 어휘 설정에서 현재 SOTA 방법들을 초월하는 성능을 보였습니다.



### Unveiling Language Competence Neurons: A Psycholinguistic Approach to Model Interpretability (https://arxiv.org/abs/2409.15827)
- **What's New**: 이 연구는 대규모 언어 모델(GPT-2-XL)을 대상으로 심리언어학 실험을 통해 신경 수준에서의 언어 능력 표현을 탐구합니다. 특히 소리-형태 연관, 소리-성별 연관 및 암묵적 인과관계라는 세 가지 작업을 사용하여 모델의 언어 처리 능력을 분석합니다.

- **Technical Details**: 연구에서는 심리언어학적 Paradigms를 적용하여 신경 세포의 작용을 탐색하고, 특정 신경 세포의 활성화 조작 및 제거(ablation)를 통해 언어 능력과 관련된 신경 생리학적 관계를 규명합니다. 이를 통해 GPT-2-XL이 인간과 유사한 언어 처리 능력을 어떻게 나타내는지를 고찰합니다.

- **Performance Highlights**: GPT-2-XL은 소리-형태 작업에서 어려움을 겪었으나 소리-성별 연관 및 암묵적 인과관계 작업에서는 인간과 유사한 능력을 보였습니다. 이 연구는 언어 모델에서 신경 수준의 해석 가능성 및 내부 메커니즘에 대한 새로운 인사이트를 제공합니다.



### Empirical Insights on Fine-Tuning Large Language Models for Question-Answering (https://arxiv.org/abs/2409.15825)
- **What's New**: 본 연구는 질문-응답(QA) 작업을 위한 대형 언어 모델(LLM)의 전이 학습을 최적화할 수 있는 효과적인 세부 전략을 제시합니다. 기존 연구와 달리, 우리는 사전 훈련된 언어 모델의 메모리와 지식 수준에 따라 데이터를 체계적으로 분류하고, 실험 분석을 통해 세 가지 주요 질문에 대해 답변합니다.

- **Technical Details**: 이 연구에서는 다중 템플릿 보완 메커니즘(multi-template complementation mechanism)을 사용하여 LLM의 특정 지식 유형에 대한 기억 정도를 평가합니다. 또한 SFT(Supervised Fine-Tuning) 단계에서 소수의 데이터 포인트(최소 60개)로도 QA 작업을 성공적으로 수행할 수 있음을 확인했습니다.

- **Performance Highlights**: SFT 데이터의 메모리 수준이 모델 성능에 미치는 영향을 분석한 결과, 사전 훈련 단계에서 잘 기억된 데이터로 훈련할 경우 LLM의 성능이 유의미하게 향상되는 것으로 나타났습니다. 하지만 모델이 거의 기억하지 못한 데이터를 사용한 경우에는 성능이 크게 저하되었습니다.



### NER-Luxury: Named entity recognition for the fashion and luxury domain (https://arxiv.org/abs/2409.15804)
Comments:
          28 pages, 6 figures

- **What's New**: 이 연구에서는 패션과 럭셔리 산업을 위한 명명된 개체 인식(Named-Entity Recognition, NER) 모델 개발의 다양한 도전 과제를 다룹니다. 주된 도전 과제는 개체의 중의성 해소(entity disambiguation), 여러 하위 분야의 프랑스어 기술 전문 용어, ESG 방법론의 부족, 그리고 작고 중간 규모의 럭셔리 하우스부터 대기업에 이르는 산업 내 다양한 기업 구조입니다.

- **Technical Details**: 이 연구에서는 럭셔리 중심으로 주석(annotation)된 36가지 이상의 개체 유형의 분류법(taxonomy)을 도입하고, 명확한 계층적 분류(hierarchical classification)를 준수하는 40,000개 이상의 문장으로 구성된 데이터셋을 생성하였습니다. 또한 패션, 뷰티, 시계, 보석, 향수, 화장품 등 다양한 카테고리를 위한 다섯 개의 감독 학습(supervised) 미세 조정(fine-tuned) 모델(NER-Luxury)을 소개합니다. 이 모델은 미적 측면과 양적 측면 모두를 균형 있게 다룹니다.

- **Performance Highlights**: 추가 실험에서는 우리의 모델과 최신 오픈 소스 대형 언어 모델(state-of-the-art open-source large language models)의 NER 성능을 정량적으로 비교하였으며, 유망한 결과들을 보여주었습니다. 또한 기존 머신러닝 파이프라인에 맞춤형 NER 모델을 통합하는 것의 이점을 강조합니다.



### Small Language Models: Survey, Measurements, and Insights (https://arxiv.org/abs/2409.15790)
- **What's New**: 이 논문은 최근 몇 년 간의 모든 작은 언어 모델(SLM)들을 종합적으로 검토하고 이들의 기술 혁신 및 온디바이스(온기기) 비용을 벤치마킹하여 요약합니다. SLM의 매니페스트 데이터를 공개하여 앞으로의 연구에 기여할 수 있는 기반을 마련합니다.

- **Technical Details**: SLM은 100M에서 5B 파라미터 범위의 transformer 기반, decoder-only 아키텍처로 구성됩니다. 59개의 최첨단 오픈 소스 SLM을 분석하여 아키텍처, 훈련 데이터셋, 훈련 알고리즘의 세 가지 축을 중심으로 기술 혁신을 평가합니다.

- **Performance Highlights**: SLM의 성능을 평가하며, commonsense reasoning, in-context learning, mathematics, coding과 같은 다양한 분야에서 능력을 분석합니다. 또한 벤치마킹 데이터를 통해 디바이스에서의 런타임 비용에 대한 귀중한 통찰을 제공합니다.



### CHBench: A Chinese Dataset for Evaluating Health in Large Language Models (https://arxiv.org/abs/2409.15766)
Comments:
          11 pages

- **What's New**: 이 논문에서는 중국어로 된 LLMs(대형 언어 모델)의 건강 관련 질문 처리 능력을 평가하기 위한 첫 번째 포괄적인 벤치마크인 CHBench를 소개합니다. CHBench는 정신 건강과 신체 건강 각각에 대한 다양한 주제를 포함하는 9,492개의 항목을 포함하고 있습니다.

- **Technical Details**: CHBench는 중국어 LLM의 신체 및 정신 건강 지식 이해를 평가하기 위해 설계되었습니다. 데이터는 웹 게시물, 시험 및 기존 데이터셋에서 수집되며, 실제 시나리오 분석과 추론(task) 문제를 포함하고 있습니다. 데이터의 품질을 평가하기 위해 여러 지표가 사용되며, Ernie Bot을 통해 항목에 대한 응답도 생성합니다.

- **Performance Highlights**: 네 개의 인기 있는 중국어 LLM에 대한 실험 평가 결과, 건강 관련 정보에 대한 이해도를 개선할 여지가 상당히 많음을 보여주었습니다. 이 연구는 중국어 LLM이 건강 관련 시나리오에서 더 안전하고 신뢰할 수 있는 정보를 제공할 수 있도록 하는 데 기여할 것으로 기대됩니다.



### XTRUST: On the Multilingual Trustworthiness of Large Language Models (https://arxiv.org/abs/2409.15762)
Comments:
          21 pages

- **What's New**: 이번 연구에서는 XTRUST라는 최초의 다국어 신뢰성 벤치마크를 도입하였습니다. 이는 LLM의 신뢰성을 평가하는 데 있어 다양한 주제 및 언어를 포괄적으로 포함하고 있습니다.

- **Technical Details**: XTRUST는 10개 언어(아랍어, 중국어, 프랑스어, 독일어, 힌디어, 이탈리아어, 한국어, 포르투갈어, 러시아어, 스페인어)로 데이터를 제공하고 있으며, 23,590개의 샘플을 수집하여 불법 활동, 환각, OOD(Out-of-Distribution) 견고성, 정신 건강, 신체 건강, 독성, 공정성, 잘못된 정보 및 사생활 등 여러 카테고리에 걸쳐 있습니다.

- **Performance Highlights**: 연구 결과, GPT-4가 대부분의 신뢰성 차원에서 다른 모델들을 능가했으며, Text-Davinci-002는 독성 문제에서 최고 성능을 보였습니다. 하지만, 모든 모델은 환각, OOD 견고성, 신체 건강 등 특정 카테고리에서 평균 정확도가 70% 이하로 나타나, LLM 신뢰성 향상의 필요성이 강조되었습니다.



### Hypothesis Clustering and Merging: Novel MultiTalker Speech Recognition with Speaker Tokens (https://arxiv.org/abs/2409.15732)
Comments:
          Submitted to ICASSP 2025

- **What's New**: 이 연구에서는 다중 화자 간 overlapping speech recognition (중첩된 음성 인식)의 문제를 해결하기 위해 Hypothesis Clustering and Merging (HCM)이라는 새로운 방법을 제안합니다. 이 접근법은 특별히 설계된 speaker class tokens를 활용하며, inferring 과정에서 예측된 speaker cluster tokens에 기반한 여러 인식 가설을 선택합니다.

- **Technical Details**: HCM은 k-means clustering을 통해 speaker embeddings를 클러스터링하여 speaker cluster ID를 정의합니다. 이 토큰은 학습 중 전사 시작 부분에 추가되며, attention-based encoder-decoder (AED)를 사용하여 다중 전사 생성시 여러 speaker token을 가정합니다. 예측된 전사 간의 normalized edit distance를 기반으로 하여 Agglomerative Hierarchical Clustering (AHC)으로 클러스터링합니다.

- **Performance Highlights**: LibriMix 데이터셋에서의 실험 결과, 복잡한 3-mix 환경에서 제안한 방법은 기존의 serialized output training (SOT) 방법에 비해 청정 데이터에서 55%, 노이즈가 있는 데이터에서는 36%의 상대적 오류 감소를 달성했습니다.



### Lighter And Better: Towards Flexible Context Adaptation For Retrieval Augmented Generation (https://arxiv.org/abs/2409.15699)
- **What's New**: 이 논문에서는 Retrieval-Augmented Generation (RAG) 시스템의 효율성 및 비용 문제를 해결하기 위한 새로운 방법인 FlexRAG를 소개합니다. FlexRAG는 검색된 컨텍스트를 압축된 형태로 변환하여 LLM(대형 언어 모델)의 인코딩 부담을 줄입니다.

- **Technical Details**: FlexRAG는 검색된 컨텍스트를 압축된 임베딩으로 변환하여 두 단계의 학습 워크플로우를 통해 RAG 성능을 최적화합니다. 첫 번째 단계에서는 일반 코퍼스에 대해 사전 학습을 실시하며, 두 번째 단계에서는 다양한 지침 튜닝 데이터셋을 이용해 과업 특화된 파인튜닝을 수행합니다. 이 과정에서 FlexRAG는 다양한 압축 비율을 지원하며 정보의 중요도에 따라 선택적으로 압축을 수행합니다.

- **Performance Highlights**: FlexRAG는 여러 질문-답변 데이터셋에서 실험을 통해 비용 효율성이 크고, 다양한 압축 비율을 효과적으로 지원하며, 일반적인 사용성 또한 우수함을 입증했습니다. 이러한 결과는 FlexRAG가 RAG 시스템의 효과적이고 경제적인 구성 요소임을 확인시켜 줍니다.



### A Survey of Stance Detection on Social Media: New Directions and Perspectives (https://arxiv.org/abs/2409.15690)
- **What's New**: 이번 논문은 소셜 미디어에서의 스탠스 감지(stance detection) 기법에 대한 포괄적인 설문조사를 제공합니다. 전통적인 모델과 최신 대형 언어 모델(LLM) 기반 기법들을 분석하며, 공공 여론과 감정을 이해하는 데 있어 스탠스 감지의 중요성을 강조합니다.

- **Technical Details**: 스탠스 감지는 사용자의 발언이 특정 주제에 대한 지지, 반대, 중립의 태도를 식별하는 과정입니다. 이 연구에서는 다중 타겟 스탠스 감지, 주장 기반 스탠스 감지, 대화 기반 스탠스 감지 등 다양한 하위 작업을 소개하고, 최신 LLM 기반 방법을 통해 전통적인 기법과 비교합니다.

- **Performance Highlights**: 최근 연구에서는 LLM을 활용한 스탠스 감지의 효과와 미래 방향성을 제안하고 있습니다. 복잡한 멀티모달 환경과 저자원 언어( low-resource languages )에 대한 대처 방안도 논의되고 있으며, 이러한 접근이 새로운 도전과제를 어떻게 해결할 수 있는지에 대해 강조하고 있습니다.



### Mitigating Semantic Leakage in Cross-lingual Embeddings via Orthogonality Constrain (https://arxiv.org/abs/2409.15664)
Comments:
          18 pages, 16 figures

- **What's New**: 이 논문에서는 크로스-링구얼(Cross-lingual) 문장 임베딩에서 의미와 언어를 분리하는 새로운 방법인 ORACLE(ORthogonAlity Constraint LEarning)를 제안합니다. 기존의 방법들이 의미 누수(semantic leakage) 문제로 고통받고 있음을 발견하였습니다.

- **Technical Details**: ORACLE은 두 가지 요소, 즉 intra-class clustering과 inter-class separation을 기반으로 합니다. 이는 의미 임베딩과 언어 임베딩 간의 직교성을 보장하여, 의미와 언어 정보의 분리를 효과적으로 지원합니다.

- **Performance Highlights**: 실험 결과, ORACLE을 사용한 훈련은 의미 누수를 줄이고 임베딩 공간 내에서 의미 정렬을 향상시키는 데 성공했습니다. 이는 크로스-링구얼 검색(cross-lingual retrieval) 및 의미 텍스트 유사성(semantic textual similarity) 작업에서 입증되었습니다.



### English offensive text detection using CNN based Bi-GRU mod (https://arxiv.org/abs/2409.15652)
Comments:
          6 pages and 6 figures

- **What's New**: 본 논문은 Bi-GRU와 CNN 모델을 결합한 새로운 텍스트 분류 모델을 제안하여, 소셜미디어에서의 공격적 언어 탐지 향상을 목표로 하고 있습니다. 기존 모델들을 능가하는 성능을 보이기 위해 31,962개의 트윗 데이터를 사용하여 실험을 수행하였습니다.

- **Technical Details**: 제안된 모델은 1D Convolutional Neural Network (CNN)과 Bi-directional Gated Recurrent Unit (Bi-GRU)을 결합하여 비정상적인 텍스트를 분류하는 구조를 가지고 있습니다. 모델은 입력 레이어, 임베딩 레이어, 여러 개의 컨볼루션 레이어, 비등방향 GRU 레이어, 밀집 레이어 등을 포함한 9개의 레이어로 구성됩니다.

- **Performance Highlights**: 제안한 Bi-GRU-CNN 모델은 기존 모델들과 비교했을 때 우수한 성능을 보이며, 특히 정확도, F1-score, 리콜, 정밀도와 같은 다양한 평가지표에서 양호한 결과를 얻었습니다.



### Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents (https://arxiv.org/abs/2409.15594)
Comments:
          EMNLP Main 2024

- **What's New**: 본 논문에서는 기존의 반이중(half-duplex) 대화 모델의 한계를 극복하고, 동기화된 대화 모델(Synchronous LLMs, SyncLLM)을 제안하여 말하는 대화 모델을 전이중(full-duplex)으로 개발하고자 합니다.

- **Technical Details**: SyncLLM은 Llama3-8b 모델에 시간 정보를 통합하여 실제 세계의 시계와 동기화되도록 설계되었습니다. 이 모델은 212k 시간의 합성된 말하기 대화 데이터와 2k 시간의 실제 대화 데이터를 사용하여 훈련되며, 의미론적 일관성을 유지하면서 자연스러운 대화를 생성합니다.

- **Performance Highlights**: SyncLLM은 대화의 의미론적 유의미성에서 최신 기술보다 +2.2 포인트 향상된 Mean Opinion Score (MOS)를 달성했으며, 자연스러운 턴 테이킹을 유지하면서 두 개의 다른 데이터셋에서 훈련된 모델 간의 전이중 대화를 시뮬레이션할 수 있는 능력을 보여주었습니다.



### Optimizing News Text Classification with Bi-LSTM and Attention Mechanism for Efficient Data Processing (https://arxiv.org/abs/2409.15576)
- **What's New**: 이 논문은 전통적인 수동 분류 방법의 비효율성을 극복하기 위해 딥 러닝을 기반으로 한 뉴스 텍스트 자동 분류 방안을 제안합니다.

- **Technical Details**: 제안하는 방법은 Bi-directional Long Short-Term Memory Network (Bi-LSTM)와 Attention Mechanism을 결합한 최적화 모델을 사용하여 뉴스 텍스트의 효율적인 분류와 관리를 달성합니다.

- **Performance Highlights**: 실험 결과, 이 솔루션은 분류의 정확성과 시의성을 크게 향상시키고 수동 개입의 필요성을 줄이며, 뉴스 산업의 정보 처리 능력을 향상시키고 정보 흐름의 속도를 가속화하는 데 중요한 실용적 의미가 있음을 보여줍니다.



### GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation (https://arxiv.org/abs/2409.15566)
Comments:
          8 pages

- **What's New**: 이번 논문에서는 Retrieval Augmented Generation (RAG) 방식을 개선하여, 메모리 조작을 통한 AI의 성능 향상을 목표로 하고 있습니다. 저자들은 Graphical Eigen Memories For Retrieval Augmented Generation (GEM-RAG)라는 새로운 방법론을 제안하며, 이는 각 텍스트 조각에 대한 '유틸리티(utility)' 질문을 생성하고, 이를 기반으로 메모리 그래프를 구축하여 더 높은 수준의 요약 노드를 생성하는 방법입니다.

- **Technical Details**: GEM-RAG는 주어진 텍스트 코퍼스를 조각으로 분할한 후, LLM을 이용해 관련된 유틸리티 질문을 생성합니다. 생성된 질문의 임베딩은 가중치 그래프를 형성하며, 이 그래프의 고유값 분해를 통해 텍스트의 주요 테마를 포착하는 'eigenthemes' 또는 요약 노드를 생성합니다. 이 방법론은 두 개의 QA 데이터셋, QuALITY와 Qasper에서 성능을 평가하며, 표준 RAG 절차 및 최신 방법인 RAPTOR와 비교하여 우수성을 입증했습니다.

- **Performance Highlights**: GEM-RAG는 두 개의 QA 태스크에서 다른 최신 RAG 방법들과 비교하여 더 나은 성능을 보였습니다. 실험 결과에 따르면, LLM에 의해 생성된 요약 노드와 유틸리티 질문의 수가 모델 성능에 미치는 영향을 정량적으로 분석하여, GEM의 효과성을 뒷받침하는 세부 실험을 수행하였습니다.



### Learning When to Retrieve, What to Rewrite, and How to Respond in Conversational QA (https://arxiv.org/abs/2409.15515)
Comments:
          Accepted in EMNLP (findings) 2024

- **What's New**: 이 논문에서는 대화 맥락에서의 정보 검색 필요성을 판단하여 retrieval을 수행하는 방법인 SELF-multi-RAG를 제안합니다. 이는 대화형 질문 답변(QA) 시스템의 맥락 이해 및 응답 생성의 질을 개선하기 위한 연구입니다.

- **Technical Details**: SELF-multi-RAG 모형은 기존의 SELF-RAG(Asai et al., 2023) 프레임워크를 기반으로 하여, 대화 중 필요한 경우에만 검색을 수행하고, 검색된 문서를 요약하여 유용한 응답을 생성하는 과정에서의 효과를 개선합니다. 이는 대화의 요약된 맥락을 사용하여 관련 문서를 검색하도록 설계되었습니다.

- **Performance Highlights**: SELF-multi-RAG는 실험을 통해 전통적인 SELF-RAG보다 약 13%의 응답 품질 향상을 보여주었으며, 검색 효과성(R@5) 또한 평균 13.5% 향상되었습니다. 이러한 결과는 human annotation에 의해 검증되었습니다.



### In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors in Pretrained Language Models (https://arxiv.org/abs/2409.15454)
Comments:
          Accepted at EMNLP 2024 Findings

- **What's New**: 대규모 언어 모델(LLMs)의 억제 제어(inhibitory control) 능력을 체계적으로 평가한 최초의 연구로, A-Not-B 오류라는 아동 인지 현상을 바탕으로 디자인한 멀티 초이스 QA 시나리오를 통해 LLMs가 얼마나 잘 고착된 답변 패턴을 억제할 수 있는지 테스트함.

- **Technical Details**: 본 연구에서는 유지된 답변 패턴을 억제하는 LLM의 능력을 평가하기 위해 A-Not-B 실험 설정을 텍스트 기반으로 변환하였습니다. LLM에게 같은 정답 선택을 반복적으로 제공하여 패턴을 형성한 뒤, 새로운 질문을 통해 패턴을 변경하는 방식으로 테스트를 진행하였으며, A-Not-B 프롬프트(A-Not-B prompting) 전략을 적용하였습니다.

- **Performance Highlights**: 최신 LLM(예: Llama3-8b)은 3-shot A-Not-B 프롬프트 사용시, 일부 추론 작업에서 정확도가 83.3% 감소하는 심각한 오류를 보였으며, 이는 이들이 초등학생보다도 낮은 인지 능력을 가지고 있음을 나타냅니다. LLM의 오류 발생 원인에 대한 분석 결과, 모델 크기와 데이터 품질이 중요한 요소로 작용하며, 후속 학습 단계에서 자기 설명(self-explanation) 전략이 어느 정도 효과를 보였음을 확인하였습니다.



### CUTE: Measuring LLMs' Understanding of Their Tokens (https://arxiv.org/abs/2409.15452)
Comments:
          Accepted to EMNLP 2024 main conference

- **What's New**: 새로운 벤치마크 CUTE(Character-level Understanding of Tokens Evaluation)를 제안하여 대형 언어 모델(LLM)의 철자(orthographic) 지식을 평가합니다. CUTE는 문자 수준의 작업으로 구성되어 있으며, LLM이 어떻게 텍스트를 조작할 수 있는지를 근본적으로 검사합니다.

- **Technical Details**: CUTE는 철자 정보와 의미적으로 유사한 것의 차이를 이해하는지, 그리고 문자 수준에서 텍스트 조작 능력을 포함한 여러 가지 과제를 포함합니다. 평가된 LLM은 7B부터 132B까지 다양한 매개변수를 갖습니다. 주요 질문으로는 LLM이 자신의 토큰을 구성하는 문자를 인식하는지, 철자와 해당 문자들의 관계를 이해하는지 등의 문제가 포함됩니다.

- **Performance Highlights**: 대부분의 LLM은 토큰의 철자에 대한 지식은 가지고 있지만, 이 정보를 적극적으로 사용하여 텍스트를 조작하는 데에는 실패하는 것으로 나타났습니다. LLM의 이해도가 얼마나 일반화 가능한지에 대한 의문이 제기되었습니다.



### Parse Trees Guided LLM Prompt Compression (https://arxiv.org/abs/2409.15395)
- **What's New**: 이 논문에서는 LLM(대형 언어 모델)의 입력 프롬프트를 압축하는 새로운 방법인 PartPrompt를 소개합니다. 기존의 압축 방법들은 주로 언어 모델을 사용하여 새로운 프롬프트를 생성하거나 중요한 부분을 선택하는 방식으로 이루어졌으나, PartPrompt는 구문 트리를 기반으로 하여 로컬 정보 엔트로피를 활용하고, 구문 간의 연결 패턴을 고려하여 압축을 수행합니다.

- **Technical Details**: PartPrompt는 각 문장의 파싱 트리를 생성하고, 각 노드에 대해 로컬 정보 엔트로피를 계산합니다. 이러한 지역 파싱 트리는 문장, 단락 및 섹션의 계층적 구조에 따라 전역 트리로 구성됩니다. 이후, 연구자들은 새로운 방식인 root-ward propagation 및 leaf-ward propagation을 이용하여 전역 트리의 노드 값을 조정합니다. 마지막으로, 조정된 노드 값을 기반으로 전역 트리를 가지치기하는 재귀 알고리즘이 개발되었습니다.

- **Performance Highlights**: 실험 결과, PartPrompt는 다양한 데이터 세트와 메트릭, 압축 비율 및 LLM의 타겟 모델에서 최신 성과를 기록했습니다. 특히, PartPrompt는 긴 프롬프트에서의 일관성(Corehence) 측면에서도 우수한 성능을 보여주었습니다. 연구진은 이 방법이 기존의 프롬프트 압축 방법들보다 효율적임을 증명했습니다.



### Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation (https://arxiv.org/abs/2409.15381)
Comments:
          Findings of the EMNLP 2024

- **What's New**: 이번 연구는 텍스트-이미지(T2I) 모델에서 다양한 품사(POS) 태그에 대한 적대적 공격의 영향을 조사하며, 기존의 연구들이 주로 명사에 초점을 맞춘 것과 달리 다양한 품사를 다루는 첫 번째 데이터셋을 작성하였습니다.

- **Technical Details**: 고품질의 데이터셋을 통해 POS 태그의 실제 시나리오에서 토큰 교환을 수행하고, 기울기 기반 공격(gradient-based attacks)을 통해 T2I 모델이 잘못된 이미지를 생성하게 만드는 적대적 접미사(adversarial suffixes)를 찾아냈습니다. 연구 결과, 공격 성공률(ASR)은 명사, 고유명사, 형용사에 대해 가장 높았으며, 각각의 POS 태그 카테고리에 따른 공격 메커니즘의 차이를 설명하기 위해 실험을 수행했습니다.

- **Performance Highlights**: 명사와 형용사 공격 시 이미지 생성의 유효성이 높고, 예상하는 속성을 이미지에 포함하도록 유도할 수 있는 성공률이 높았습니다. 특히 동일한 적대적 접미사를 사용하여 다양한 입력 프롬프트에 대해 동일한 속성을 생성할 수 있는 전반적인 특성 또한 확인되었습니다.



### Kalahi: A handcrafted, grassroots cultural LLM evaluation suite for Filipino (https://arxiv.org/abs/2409.15380)
- **What's New**: 다국어 대형 언어 모델(LLMs)에 대한 연구가 진행되는 가운데, Kalahi라는 새로운 문화적 LLM 평가 도구가 필리핀 원주율 사용자를 대상으로 개발되었습니다. 이 도구는 필리핀 고유의 문화적 지식과 가치를 반영한 150개의 정교하게 수작업으로 작성된 프롬프트로 구성되어, LLM이 필리핀 사회에서 일어날 법한 상황에 대해 적절한 대답을 생성할 수 있는지 평가합니다.

- **Technical Details**: Kalahi는 LLM이 필리핀 문화에 기반한 질문에 얼마나 잘 응답할 수 있는지를 평가하기 위해 설계된 도구입니다. 이 평가는 다국어 및 필리핀어 지원 LLM에 대해 수행되었으며, 150개의 상황에 대한 프롬프트를 사용하여 LLM의 성능을 측정합니다. 또한, 프롬프트 작성자는 필리핀 원어민으로 이루어져 있으며, 다양한 사회적 배경을 가진 인물들이 참여하여 문화적 대표성을 보장합니다.

- **Performance Highlights**: 실험 결과, Kalahi는 필리핀 원주율 사용자에게는 쉬운 질문들이 포함되어 있지만, LLM에게는 도전적인 질문으로 나타났습니다. 가장 잘 수행된 LLM은 단지 46.0%의 질문에만 정확히 응답했으며, 필리핀 원주율 사용자의 정확도는 89.10%로 나타났습니다. 이러한 차이는 Kalahi가 LLM의 필리핀 문화 표현을 평가하는 데 있어 신뢰할 수 있는 도구임을 시사합니다.



### Prompting Large Language Models for Supporting the Differential Diagnosis of Anemia (https://arxiv.org/abs/2409.15377)
- **What's New**: 본 연구는 임상 지침에 영감을 받아 비슷한 방식의 진단 경로(Pathways)를 개발하고, 이를 통해 희귀 질환 진단에 대한 한계를 극복하고자 하였습니다.

- **Technical Details**: 연구에서는 Generative Pretrained Transformer 4 (GPT-4), Large Language Model Meta AI (LLaMA), Mistral이라는 세 가지 대형 언어 모델(LLMs)을 이용하여 합성된 데이터셋을 기반으로 빈혈(Anemia) 및 그 하위 유형의 진단을 진행하였습니다. 고급 프롬프트 기법(advanced prompting techniques)을 사용하여 의사결정 프로세스를 향상시켰습니다.

- **Performance Highlights**: 실험 결과, LLMs는 환자 데이터를 기반으로 한 임상 경로 발견에서 큰 잠재력을 보였으며, 모든 실험에서 GPT-4가 최고의 성능을 나타냈습니다.



### Bone: Block Affine Transformation as Parameter Efficient Fine-tuning Methods for Large Language Models (https://arxiv.org/abs/2409.15371)
- **What's New**: 본 논문에서는 Bone(Block Affine)이라는 새로운 PEFT(Parameter-Efficient Fine-Tuning) 방법을 제안하여 기존 LoRA 변형의 한계를 극복하고 전체 파라미터 학습을 초월하는 방법론을 소개합니다. 이 방법은 메모리 오버헤드를 줄이고, 가중치 간의 내부 연결을 강조하여 더 빠른 수렴과 더 나은 데이터 적합을 이끌어냅니다.

- **Technical Details**: Bone은 초기화가 복잡하지 않은 단일 학습 가능한 행렬을 활용하며, 이 행렬은 W𝑊와의 상호작용을 통해 Block Affine 연산을 수행합니다. 이 구조는 LoRA의 두 개의 구조 복잡성을 해소하고, 빠른 수렴 속도와 데이터를 적합시키는 능력을 보여줍니다. 실험은 서로 다른 LLM 아키텍처(LLaMA2, RWKV6)와 다양한 파라미터 스케일을 기반으로 수행되었습니다.

- **Performance Highlights**: 실험 결과, Bone 방식은 LLaMA2-7B 모델을 MetaMathQA 데이터셋으로 파인튜닝 시 49.36의 점수를 기록하며, PISSA보다 5.84% 향상된 성과를 보였습니다. 또한, Bone은 복잡한 초기화 없이 빠른 수렴과 우수한 데이터 적합성을 달성함으로써 성능을 입증하였습니다.



### MedCodER: A Generative AI Assistant for Medical Coding (https://arxiv.org/abs/2409.15368)
- **What's New**: 이번 연구에서는 MedCodER라는 새로운 Generative AI 프레임워크를 소개하며, 의료 코딩의 자동화를 위한 혁신적인 접근 방식을 제시합니다. 특히, 이 프레임워크는 추출(Extraction), 검색(Retrieval), 재정렬(Re-ranking) 기술을 핵심 요소로 활용하여 높은 정확도를 자랑합니다.

- **Technical Details**: MedCodER는 의료 기록에서 질병 진단과 지원 증거를 추출하고, ICD-10 코드를 후보 코드로 검색한 다음, 이를 종합하여 최종 코드를 예측합니다. 이 과정에서 LLM(대형 언어 모델)의 파라메트릭 지식을 보완하기 위해 검색 및 재정렬 기술을 통합하여 성능을 향상시킵니다.

- **Performance Highlights**: MedCodER는 ICD 코드 예측에서 0.60의 micro-F1 점수를 달성하여 현재 최고의 방법보다 유의미하게 향상된 성과를 보입니다. 또한, 제안된 데이터셋은 질병 진단과 ICD 코드, 그리고 이를 정당화하는 지원 증거 텍스트가 주석 처리되어 있어, 코드 선택의 신뢰성을 높이는 데 기여합니다.



### VERA: Validation and Enhancement for Retrieval Augmented systems (https://arxiv.org/abs/2409.15364)
- **What's New**: VERA는 Retrieval-Augmented Generation (RAG) 시스템을 위한 평가 및 개선 시스템으로, LLM의 응답精度를 향상시키기 위한 새로운 방법을 제공합니다. 또한, VERA는 외부 정보를 효과적으로 활용하도록 설계되었습니다.

- **Technical Details**: VERA는 수집된 컨텍스트의 적합성과 불필요한 정보를 제거하는 데 중점을 둡니다. 이 시스템은 평가자 및 향상 LLM을 사용하여 응답 생성 전에 컨텍스트를 평가하고, 응답 생성 후에는 응답을 분리하여 각 문장의 적합성을 점검합니다.

- **Performance Highlights**: 실험 결과, VERA는 소규모 공개 오픈 소스 모델에서 뿐만 아니라 대규모 최첨단 모델에서도 성능을 개선하는 데 뛰어난 효능을 나타냈습니다. VERA는 정보 생성에서 높은 정확성 및 신뢰성을 요구하는 응용 프로그램에 유용한 도구로 자리 잡을 잠재력을 보여주고 있습니다.



### Multitask Mayhem: Unveiling and Mitigating Safety Gaps in LLMs Fine-tuning (https://arxiv.org/abs/2409.15361)
Comments:
          19 pages, 11 figures

- **What's New**: 최근의 Large Language Models (LLMs)에 대한 연구는 다양한 다운스트림 작업에서 가벼운 튜닝이 안전성을 저해할 수 있음을 보여줍니다. 특히, 코드 생성 및 번역 작업에서 안전성 감소가 두드러지며, 새로운 멀티태스크 안전 데이터셋인 MultiTaskBench를 개발하여 이러한 문제를 해결하고자 했습니다.

- **Technical Details**: 이 연구는 네 가지 작업(요약, 코드 생성, 번역, 분류)에 대한 데이터셋을 사용하여 LLM의 튜닝 및 안전성 감소 현상을 분석합니다. 연구에서는 거짓 응답을 방지하기 위해 Reinforcement Learning from Human Feedback (RLHF) 방식을 활용하며, 선행 연구와의 차별성을 위해 안전하게 생성된 데이터셋을 적용합니다.

- **Performance Highlights**: 연구 결과, LLM은 번역 및 분류 작업에서 상대적으로 안전성 유지가 어려웠으며, 코드 데이터로 튜닝할 경우 가장 높은 안전성 저하를 보였습니다. 제안된 MultiTaskBench 데이터셋은 다양한 다운스트림 작업에서 공격 성공률을 효과적으로 감소시켰습니다.



### Watch Your Steps: Observable and Modular Chains of Though (https://arxiv.org/abs/2409.15359)
- **What's New**: 이 논문에서는 Program Trace Prompting (PTP)이라는 새로운 형태의 chain of thought (CoT) 프롬프트를 제안합니다. 이 방법은 CoT의 장점과 유연성을 유지하면서 설명 과정을 보다 관찰 가능하게 만들어 줍니다.

- **Technical Details**: PTP는 Python 기반의 형식을 사용하여 CoT 데모를 포장하고, 각 프롬프트에서는 단계 식별, 입력/출력 동작 정의, CoT 설명을 공식화된 단계로 대체하는 워크플로우를 제공합니다. 이 방법은 다양한 작업에 적용 가능하며, BIG-Bench Hard 벤치마크에서 23개의 작업에 대해 강력한 성능을 보여줍니다.

- **Performance Highlights**: PTP는 대부분의 작업에서 CoT 프롬프트와 비슷한 정확도를 달성하며, 생성된 트레이스는 99% 이상의 법적 단계로 파싱할 수 있습니다. 또한 PTP는 개별 단계 실행과 작업 전체 해결을 모두 가능하게 하며, 대부분의 단계에서 모듈성과 지역성을 평가할 수 있습니다. 실험 결과는 PTP의 유용성을 검증하고, 많은 비국소 오류가 잘못된 알고리즘 추정에서 유래함을 보여줍니다.



### Evaluating Large Language Models with Tests of Spanish as a Foreign Language: Pass or Fail? (https://arxiv.org/abs/2409.15334)
- **What's New**: 본 논문은 Large Language Models (LLMs)이 비영어권 사용자들을 위한 다른 언어, 특히 스페인어에 대한 이해도를 평가한 최초의 연구 중 하나입니다.

- **Technical Details**: TELEIA라는 새로운 벤치마크를 사용하여 LLM의 성능을 평가하였으며, 이 벤치마크는 외국인 학생을 위한 스페인어 시험과 유사한 질문들로 구성되어 있습니다. 평가 항목에는 읽기 이해(reading comprehension), 단어 형성(word formation), 의미(meaning) 및 구성 의미론(compositional semantics), 문법(grammar) 등이 포함됩니다.

- **Performance Highlights**: 결과적으로, LLMs는 스페인어 이해에서는 좋은 성능을 보였으나, 문법적 능력(grammatical competence) 면에서는 여전히 원어민 수준에는 미치지 않는 것으로 나타났습니다.



### Towards Enhancing Linked Data Retrieval in Conversational UIs using Large Language Models (https://arxiv.org/abs/2409.16220)
Comments:
          This paper has been accepted at the 25th International Web Information Systems Engineering Conference (WISE 2024)

- **What's New**: 이 논문은 기존 정보 시스템과 LLMs(대형 언어 모델)의 통합을 통해 Linked Data(LD) 및 RDF(Ressource Description Framework) 트리플스토어에서 데이터를 추출하고 탐색하는 방법을 탐구합니다. 특히, 모델 재훈련 없이도 더 정확한 SPARQL 쿼리를 생성할 수 있는 대화형 사용자 인터페이스(UI)의 강화를 강조합니다.

- **Technical Details**: 본 연구에서는 ForestQB라는 새로운 툴킷을 사용하여 관찰적 LD 데이터로부터 정보를 추출하고, 이 툴킷은 챗봇과 폼 기반 GUI를 통합하여 SPARQL 쿼리를 구성하고 실행합니다. 연구의 초점은 LLMs의 자연어 이해 능력을 활용하여 RDF 엔티티 추출의 정확성을 향상시키는 것입니다.

- **Performance Highlights**: 본 연구의 결과, 제안된 방법론을 통해 시스템의 표현력과 사용자 쿼리에 대한 응답 정확성이 크게 향상되었습니다. 평가 결과는 LLMs가 복잡한 데이터 환경에서 엔티티 추출 및 사용자 인터랙션을 개선시킬 수 있는 가능성을 제시하고 있습니다.



### Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to Extremes Through Rank-Wise Clustering (https://arxiv.org/abs/2409.16167)
- **What's New**: 본 논문은 LoRA(저랭크 적응)을 조합하여 대형 언어 모델(LLM)의 성능을 극대화하는 새로운 접근 방식을 소개합니다. 기존의 LoRA 합성 방법이 주어진 특정 작업에 최적화되어 추가 훈련을 필요로 하는 반면, 본 연구에서는 LoRA 구성 요소를 독립적인 최소 의미 단위(MSU)로 분해 및 재조립하는 방식을 제안합니다.

- **Technical Details**: 제안된 LoRA-LEGO 프레임워크는 여러 LoRA에서 MSU를 클러스터링하여 새로운 LoRA를 구성하는 과정을 포함합니다. 이 과정은 세 가지 주요 단계로 나누어집니다: (1) 후보 LoRA로부터 MSU 풀(pool)을 만들기, (2) 이 MSU 풀을 k 클러스터로 그룹화하기, (3) 클러스터의 중심을 활용해 병합된 LoRA 구성하기. 이를 통해 파라미터 간섭을 해결하면서 다양한 랭크의 LoRA를 유연하게 조합할 수 있습니다.

- **Performance Highlights**: LoRA-LEGO는 다양한 벤치마크에서 기존의 LoRA 병합 방법보다 우수한 성능을 보였습니다. 실험 결과, LoRA-LEGO는 목표 랭크 k에 맞춘 병합 LoRA를 구성할 수 있을 뿐만 아니라, 개별 LoRA에 적용 시에도 파라미터 감소를 통해 원래 모델과 유사한 성능을 달성할 수 있음을 보여주었습니다.



### HA-FGOVD: Highlighting Fine-grained Attributes via Explicit Linear Composition for Open-Vocabulary Object Detection (https://arxiv.org/abs/2409.16136)
Comments:
          This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 본 논문은 Open-Vocabulary Object Detection (OVD) 모델에서 세부 속성을 강조하는 새로운 접근 방식을 제안하여 기존 모델의 성능을 향상시키는 방법을 소개합니다.

- **Technical Details**: 이 방법은 1) Attribute Word Extraction, 2) Attribute Feature Extraction, 3) Attribute Feature Enhancement의 세 가지 주요 프로세스로 구성됩니다. 강력한 LLM(대규모 언어 모델)을 이용해 입력 텍스트에서 속성 단어를 추출하고, 전략적으로 토큰 마스크를 조정하여 OVD 모델의 텍스트 인코더가 전역 텍스트와 속성 특정 피처를 추출합니다. 이 피처들은 선형 조합을 통해 새로운 속성 강조 피쳐로 통합됩니다.

- **Performance Highlights**: FG-OVD 데이터셋에서 실험한 결과, 제안된 방법이 다양한 OVD 모델의 세부 속성 인식 능력을 일관되게 향상시키며 새로운 최첨단 성능을 달성함을 입증하였습니다.



### Implicit assessment of language learning during practice as accurate as explicit testing (https://arxiv.org/abs/2409.16133)
- **What's New**: 이번 연구에서는 Intelligent Tutoring Systems (ITS)에서 학습자의 능력을 평가하기 위해 Item Response Theory (IRT)를 활용합니다. 기존의 포괄적인 테스트 방식 대신, 효율적이면서도 정확한 적응형 테스트(adaptive tests) 개발을 목표로 하고 있습니다.

- **Technical Details**: 연구는 학습자로부터 수집된 데이터를 바탕으로 IRT 모델을 훈련시키고, 이를 통해 적응형 테스트를 안내하는 방식을 사용합니다. 또한, 연습 세션(exercise sessions) 중에 수집된 데이터를 IRT 모델링에 적합한 형태로 변환하는 과정을 진행하며, 언어적 구성(linguistic constructs)을 '항목(items)'으로 연결하여 IRT 모델에 통합합니다.

- **Performance Highlights**: 대규모 연구 결과, 교사의 학습자 능력 평가를 '기준 진리(ground truth)'로 삼고, 테스트와 연습을 통해 얻은 능력 추정치를 비교한 결과, IRT 모델이 연습 기반의 능력 추정에서도 정확성을 발휘함을 확인했습니다.



### MOSS: Enabling Code-Driven Evolution and Context Management for AI Agents (https://arxiv.org/abs/2409.16120)
- **What's New**: MOSS (llM-oriented Operating System Simulation)이라는 새로운 프레임워크를 도입하여 코드 생성과 동적 컨텍스트 관리 시스템을 통합함으로써 AI 에이전트의 적응성과 일관성을 향상시킴.

- **Technical Details**: MOSS는 Python 실행 컨텍스트를 유지하고 지역 변수를 격리하여 여러 상호작용 간의 일관성을 보장하는 메커니즘을 사용합니다. Inversion of Control (IoC) 컨테이너와 데코레이터를 활용하여 가장 낮은 지식 원칙을 적용하며, 이로 인해 에이전트가 구체적인 구현보다는 추상 인터페이스에 집중할 수 있게 합니다.

- **Performance Highlights**: MOSS 프레임워크는 에이전트 개발의 효율성과 기능을 향상시키며, Turing-complete 에이전트를 생성할 수 있는 새로운 가능성을 보여줍니다. 다양한 실제 사례를 통해 에이전트가 코드 생성을 통해 스스로의 역량을 확장할 수 있는 것을 입증하였습니다.



### TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Contro (https://arxiv.org/abs/2409.15977)
Comments:
          Accepted by EMNLP 2024

- **What's New**: 본 논문에서는 TCSinger를 소개합니다. TCSinger는 스타일 전이(style transfer) 및 스타일 제어(style control)를 지원하며, 다양한 언어의 음성 및 노래 스타일에 대한 제로샷(Zero-shot) 노래 목소리 합성(SVS) 모델입니다. 이 모델은 개인화된 제어가 가능한 노래 합성을 가능하게 합니다.

- **Technical Details**: TCSinger는 세 가지 주요 모듈로 구성됩니다: 1) clustering style encoder는 클러스터 벡터 양자화(clustering vector quantization) 모델을 사용하여 스타일 정보를 안정적으로 축소하여 잠재 공간(latent space)에 압축합니다. 2) Style and Duration Language Model (S&D-LM)은 스타일 정보와 음소 지속시간(phoneme duration)을 함께 예측하여 두 가지 작업 모두에 도움을 줍니다. 3) style adaptive decoder는 멜 스타일 적응(normalization) 방법을 이용하여 풍부한 스타일 세부정보가 포함된 노래 목소리를 생성합니다.

- **Performance Highlights**: TCSinger의 실험 결과는 합성 품질(synthesis quality), 가수 유사성(singer similarity), 스타일 제어 가능성과 같은 지표에서 모든 기준 모델을 초과하여 성능을 입증했습니다. 여러 작업에서의 성과에는 제로샷 스타일 전이, 다단계 스타일 제어, 교차 언어 스타일 전이 및 음성-노래 스타일 전이가 포함됩니다.



### BeSimulator: A Large Language Model Powered Text-based Behavior Simulator (https://arxiv.org/abs/2409.15865)
Comments:
          7 pages, 3 figures, 2 tables

- **What's New**: 본 논문에서는 기존의 로봇 시뮬레이터의 한계를 극복하기 위해 행동 시뮬레이션(Behavior Simulation)을 이론적으로 정의하고 새로운 프레임워크인 BeSimulator를 소개하였습니다. BeSimulator는 텍스트 기반의 가상 환경에서 로봇 행동 로직을 수립하여 시뮬레이션하고, 체계적인 사고 과정을 통해 행동의 실행 가능성과 상태 전이를 분석합니다.

- **Technical Details**: BeSimulator는 모듈화된 LLM(large language model) 기반의 프레임워크로, 행동 계획 솔루션(BPS)에 대한 단계별 시뮬레이션을 수행합니다. 이 프레임워크는 '사례 생성'(Case Generation), 'BPS 시뮬레이션'(BPS Simulation), 및 'BPS 평가'(BPS Evaluation)라는 세 가지 핵심 모듈을 포함하고 있습니다. 또한, Chain of Behavior Simulation(CBS) 접근법을 통해 행동의 실행 가능성과 상태 전이를 깊이 분석합니다.

- **Performance Highlights**: BTSIMBENCH라는 행동 트리 기반의 시뮬레이션 벤치마크를 통해 실험한 결과, BeSimulator는 기존 방법들에 비해 14.7%에서 26.6%까지 행동 시뮬레이션 성능이 향상되었습니다. 이는 BeSimulator가 특히 긴 기간의 복잡한 시뮬레이션에서 우수한 성능을 제공함을 입증합니다.



### iGAiVA: Integrated Generative AI and Visual Analytics in a Machine Learning Workflow for Text Classification (https://arxiv.org/abs/2409.15848)
- **What's New**: 이 논문에서는 텍스트 분류를 위한 기계 학습(ML) 모델 개발 시 데이터 부족 문제를 해결하기 위해 시각적 분석(Visual Analytics, VA)을 활용하여 합성 데이터를 생성하는 방법을 제안합니다. 이는 대규모 언어 모델을 활용하여 특정 데이터 부족 문제를 목표로 한 데이터 합성을 가능하게 합니다.

- **Technical Details**: 다양한 데이터 부족 유형을 논의하고, 이러한 부족을 식별하기 위한 다양한 VA 기법을 설명합니다. 또한, iGAiVA라는 소프트웨어 도구를 소개하여 4개의 ML 작업 그룹을 4개의 VA 뷰에 매핑하고, 생성적 AI와 VA를 ML 워크플로우에 통합했습니다.

- **Performance Highlights**: 대상 데이터 합성을 통해 모델 정확도를 향상시키는 효과를 입증했습니다. 이 연구는 ML 텍스트 분류 모델의 개발 및 개선을 위한 새로운 접근 방식을 제공합니다.



### Supervised Fine-Tuning: An Activation Pattern Optimization Process for Attention Heads (https://arxiv.org/abs/2409.15820)
Comments:
          in review

- **What's New**: 이번 논문에서는 LLM의 성능 향상을 위한 새로운 통찰력을 제시합니다. SFT(Supervised Fine-tuning) 과정에서의 주의 패턴(Attention Patterns)을 분석하여 LLM들이 복잡한 작업에 어떻게 적응하는지를 설명합니다.

- **Technical Details**: 저자들은 경량화된 gradient 기반 방법을 사용하여 SFT 과정에서 LLM의 주의 헤드(Attention Heads)가 어떻게 활용되는지를 밝혀냈습니다. 주요 발견은 LLM이 특정 작업에 대해 선택적으로 주의 헤드를 활성화한다는 것입니다.

- **Performance Highlights**: 논문에서 제안한 접근법을 통해 복잡한 작업을 수행할 수 있는 LLM의 성능이 현저히 향상될 수 있음을 보여줍니다. 특히, 주의 패턴을 분석하여 희소한 지침을 활용하면서도 효율성을 극대화할 수 있는 방법을 실험했습니다.



### AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Suppor (https://arxiv.org/abs/2409.15815)
Comments:
          10 pages

- **What's New**: 이번 연구에서는 다국적, 다중 모드 리트리벌 증강 생성(Retrieval-Augmented Generation, RAG) 시스템인 AsthmaBot을 소개합니다. AsthmaBot은 최신 정보와 관련된 문서, 비디오 및 이미지를 통합하여 천식 관련 질문에 대한 답변을 제공합니다.

- **Technical Details**: AsthmaBot은 리트리벌 알고리즘(retrievers)과 다중 모드 지원 기능이 있는 대형 언어 모델(LLM)로 구성되어 있습니다. 이 시스템은 질문-답변 쌍을 바탕으로 정보를 제공하며, 사용자에게 텍스트, 이미지, 비디오가 포함된 응답을 제공합니다. FAQ 데이터를 통해 평가되었습니다.

- **Performance Highlights**: 실험 결과, AsthmaBot은 RAG 기법을 사용하지 않는 기본 모델에 비해 다양한 언어와 모드에서 우수한 성능을 보였습니다. 이 시스템은 사용자 인터페이스를 통해 일반 대중이 손쉽게 접근할 수 있도록 설계되었습니다.



### Federated Large Language Models: Current Progress and Future Directions (https://arxiv.org/abs/2409.15723)
- **What's New**: 이번 논문은 Federated Learning (FL)과 Large Language Models (LLMs) 간의 상호작용을 심도 있게 분석하여 최신 발전 사항과 향후 방향성을 제시합니다. 특히, 데이터 프라이버시와 함께 LLMs의 학습 효율성을 개선하기 위해 각종 방법론과 과제를 살펴봤습니다.

- **Technical Details**: 논문은 LLMs의 Federated Learning(FedLLM)에서의 최신 기법을 요약하고, 세 가지 주요 측면인 데이터 이질성(data heterogeneity), 개인화(personalization), 및 보안(security) 문제를 다룹니다. 또한, FedPIT, FFA-LoRA, 그리고 FEDML-HE와 같은 특정 기법들을 소개하여 성능 및 프라이버시를 증대시키는 다양한 접근법을 제시합니다.

- **Performance Highlights**: 이 논문에서 제안된 다양한 방법론들은 LLMs의 훈련 효율을 극대화 하며, 데이터 통신 비용을 최소화합니다. 예를 들어, FedKSeed와 FedRDMA는 통신 요구량을 대폭 줄이며, 여러 가지 협업 학습 시나리오에서 효과적인 성과를 보여줍니다.



### Making Text Embedders Few-Shot Learners (https://arxiv.org/abs/2409.15700)
- **What's New**: 본 논문에서는 큰 언어 모델(LLM)의 인-context learning (ICL) 기능을 활용하여 텍스트 임베딩 생성 과정을 개선하는 새로운 모델 bge-en-icl을 제안합니다. 이 모델은 적은 수의 샘플을 사용하여 고품질의 텍스트 임베딩을 생성합니다.

- **Technical Details**: bge-en-icl 모델은 쿼리 프롬프트에 작업 관련 예제를 통합하여 LLM의 ICL 능력을 최대한 활용합니다. 이 연구에서는 다양한 attention 메커니즘과 pooling 방법을 평가하여 LLM을 임베딩 모델로 효과적으로 활용하는 방법을 조사했습니다.

- **Performance Highlights**: bge-en-icl 모델은 MTEB 및 AIR-Bench 벤치마크에서 새로운 최첨단(SOTA) 성능을 달성하였으며, 간단한 ICL 전략만으로도 뛰어난 성과를 거둘 수 있다는 것을 입증했습니다. 코드와 데이터셋은 자유롭게 제공됩니다.



### dnaGrinder: a lightweight and high-capacity genomic foundation mod (https://arxiv.org/abs/2409.15697)
- **What's New**: dnaGrinder는 유전자 서열 내의 복잡한 장기 종속성을 효과적으로 관리하면서도 계산 비용을 최소화하는 독창적이고 효율적인 유전체 모델로, 기존의 모델들보다 우수한 성능을 보여줍니다.

- **Technical Details**: dnaGrinder는 Byte Pair Encoding (BPE) 토크나이제이션을 사용하여 DNA 서열을 수치 표현으로 변환하고, Attention with Linear Bias (ALiBi) 기법을 사용하며, Flash Attention 2와 같은 고급 주의 메커니즘을 통합하여 성능과 효율성을 극대화합니다.

- **Performance Highlights**: dnaGrinder는 Nucleotide Transformer 및 DNABERT-2와 같은 최신 DNA 모델에 비해 성능이 동등하거나 우수하며, 단일 고성능 GPU에서 140,000 토큰 이상의 서열을 지원합니다.



### Language-based Audio Moment Retrieva (https://arxiv.org/abs/2409.15672)
- **What's New**: 이번 논문에서는 새로운 작업인 Audio Moment Retrieval (AMR)을 제안하고 설계하였습니다. AMR은 주어진 자연어 쿼리를 바탕으로 잘리지 않은 긴 오디오에서 관련 순간을 예측하는 것을 목표로 합니다. 기존의 언어 기반 오디오 검색 방법과는 달리, AMR은 특정 시간 구간을 추출하고자 합니다.

- **Technical Details**: AMR을 위한 데이터셋 Clotho-Moment를 구축하고, DETR 기반의 오디오 모멘트 모델인 Audio Moment DETR (AM-DETR)을 제안합니다. 이 모델은 오디오 특징 간의 시간적 의존성을 캡처하여 기존의 클립 수준 오디오 검색 방법과의 차별점을 보입니다. 또한, 수동으로 주석이 달린 데이터셋을 통해 실제 데이터에서 방법론의 효과를 측정할 수 있습니다.

- **Performance Highlights**: 실험 결과, Clotho-Moment로 훈련된 AM-DETR은 슬라이딩 윈도우 기반의 클립 수준 검색 방법을 사용하는 기초 모델을 모든 평가 지표에서 능가했습니다. 특히, Recall1@0.7에서 9.00 포인트 향상된 결과를 보였습니다.



### M$^2$PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning (https://arxiv.org/abs/2409.15657)
Comments:
          EMNLP 2024

- **What's New**: 이번 연구에서는 Multimodal Prompt Tuning (M$^2$PT)이라는 새로운 접근 방식을 도입하여 대형 다중 모달 언어 모델 (MLLMs)의 효율적인 지침 조정 (instruction tuning)을 지원합니다.

- **Technical Details**: M$^2$PT는 시각 (visual) 및 텍스트 (textual) 프롬프트를 각각 비전 인코더 (vision encoder)와 언어 프로세서 (language processor)에 통합하여 파인튜닝 (finetuning) 동안 다양한 모달리티 간의 특징을 추출하고 일치시킵니다.

- **Performance Highlights**: 다양한 다중 모달 평가 데이터셋에서 우리의 접근 방식은 여러 최신 기법 (state-of-the-art baselines) 대비 우수한 성능을 보여주었으며, 포괄적인 제거 연구 (ablation studies)를 통해 프롬프트 설계와 접근 방식의 효율성을 확인하였습니다.



### Asking an AI for salary negotiation advice is a matter of concern: Controlled experimental perturbation of ChatGPT for protected and non-protected group discrimination on a contextual task with no clear ground truth answers (https://arxiv.org/abs/2409.15567)
- **What's New**: 이 연구는 네 가지 버전의 ChatGPT를 대상으로 진행된 통제된 실험 편향 감사(bias audit)를 소개합니다. 연구진은 각각의 버전에게 새로운 채용자를 위한 초봉 제안을 요청했으며, 직원의 성별, 대학, 전공 등을 체계적으로 변화시켜 98,800개의 프롬프트를 제출했습니다. 이러한 실험을 통해 ChatGPT가 이러한 작업에 신뢰할 수 없다는 것을 발견했습니다.

- **Technical Details**: 대조군을 포함한 제어된 실험 방법을 사용하여 AI가 질문에 대해 차별적인 응답을 하는지 혹은 공정한 결과를 도출하는지를 평가했습니다. 특히 성별 변화에 따른 통계적으로 유의미한 초봉 제안 차이를 관찰했으며, 사기성 대학 및 전공에 대한 경험적 결과도 비교적 일관되지 않음을 확인하였습니다. 이 연구는 AI/ML의 공정성(fairness) 및 신뢰성(trustworthiness) 문헌에 기여합니다.

- **Performance Highlights**: ChatGPT의 네 가지 모델 버전 간의 초봉 차이가 상이하였으며, 성별, 대학 및 전공에 따라 상당한 격차가 관찰되었습니다. 특히, 고용주와 직원의 목소리에 따라 제안된 급여의 차이가 두드러졌고, 이는 ChatGPT 다중 모델 플랫폼의 일관성 및 신뢰성에 대한 우려를 제기합니다.



### Revise, Reason, and Recognize: LLM-Based Emotion Recognition via Emotion-Specific Prompts and ASR Error Correction (https://arxiv.org/abs/2409.15551)
- **What's New**: 최근 연구에서는 대형 언어 모델(LLMs)이 감정 인식에 효과적일 수 있음을 보여주었으나, 이들의 효용성에 대한 의문이 여전히 존재합니다. 본 논문에서는 음향학(acoustics), 언어학(linguistics), 심리학(psychology)에서의 감정별 지식을 통합한 새로운 프롬프트(prompts)를 제안하고, LLM 기반의 감정 인식의 정확성과 효과성을 실험을 통해 검증합니다.

- **Technical Details**: 우리는 Revise-Reason-Recognize (R3) 프롬프트 파이프라인을 제안하여, 부정확한 텍스트에 대한 감정 인식을 개선합니다. 이 파이프라인은 ASR(Automatic Speech Recognition) 오류를 수정하고, LLM이 감정 인식에 필요한 자율적 설명을 제공하는 방법으로 구성됩니다. 이 외에도, 문맥 인식 학습(context-aware learning)과 지시 조정(instruction tuning) 방법을 실험하여 성능을 향상시키는 데 기여합니다.

- **Performance Highlights**: 실험 결과, 감정별 지식을 통합한 프롬프트와 ASR 오류 교정이 LLM 기반 감정 인식에 효과적임을 확인하였습니다. R3 프롬프트는 ASR 전사 과정에서 발생하는 오류를 정확히 수정하고, 감정 인식의 정확도를 높이는 데 기여하였습니다. 또한, 훈련 스킴들은 LLM의 성능을 향상시키는 데 중요한 역할을 합니다.



### Rethinking Emotion Bias in Music via Frechet Audio Distanc (https://arxiv.org/abs/2409.15545)
- **What's New**: 이 연구 논문은 음악 감정 인식(MER)과 감정 음악 생성(EMG)에서 음악 감정 평가의 객관성을 높이기 위해 여러 오디오 인코더와 Frechet Audio Distance(FAD) 평가 척도를 사용했습니다. 단일 오디오 인코더에 의존할 때의 한계를 강조하며, 다양한 인코더를 통한 평가 방법을 제안합니다.

- **Technical Details**: 연구에서는 Emomusic, MMirex, EMOPIA 등 다양한 데이터셋을 활용하여 MER과 EMG의 객관적인 평가를 진행했습니다. FAD를 사용하여 MUSIC 감정의 객관적인 측정을 목표로 하며, 오디오 인코더의 종류에 따라 성능 차이를 분석합니다. 또한, EMG 접근 방식을 개선하여 생성된 음악 감정의 변동성과 현실성을 높이고자 합니다.

- **Performance Highlights**: 실험 결과는 MER과 EMG 모두 감정 편향 문제를 잘 보여주며, 다중 오디오 인코더와 FAD의 사용이 음악 감정 평가의 객관성을 높일 수 있는 가능성을 나타냅니다. 연구의 접근 방식은 기존의 방법들과 비교해 더 나은 결과를 나타내며, 현실 감정 표현의 향상을 목표로 합니다.



### RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration (https://arxiv.org/abs/2409.15461)
- **What's New**: 본 연구에서는 Retrieval-Augmented Multi-role Multi-expert Collaboration (RAM2C) 프레임워크를 제안하여 고품질의 자유 예술 교육 대화를 자동으로 생성하고, 이 데이터를 통해 LLM(대형 언어 모델)을 조정하는 방안을 소개합니다.

- **Technical Details**: RAM2C 프레임워크는 T-Group(중국어 교사), P-Group(교육 심리학자), E-Group(윤리적 안전 전문가)의 세 가지 전문가 그룹을 구성하여 다중 역할과 다중 전문가 협업을 통해 HTS(인간화된 소통, 교수 전문성, 안전-윤리) 기준에 부합하는 교육 대화를 생성합니다.

- **Performance Highlights**: RAM2C를 통해 생성된 LLM은 특히 문학 교육에서 높은 개인화된 응답과 윤리적으로 안전한 교육 반응을 제공하며, 실험 결과 미세 조정된 모델이 GLM-4와 유사한 성능을 보였습니다.



### The ParlaSpeech Collection of Automatically Generated Speech and Text Datasets from Parliamentary Proceedings (https://arxiv.org/abs/2409.15397)
Comments:
          Submitted to SPECOM 2024

- **What's New**: 이 논문에서는 자원이 부족한 언어의 대량 공개 음성과 텍스트가 정렬된 데이터셋을 구축하는 새로운 접근 방법을 제시합니다. 특히, 크로아티아어, 폴란드어, 세르비아어를 중심으로 한 의회 기록과 그에 따른 음성을 정렬시켜 고품질 데이터셋을 제공합니다.

- **Technical Details**: 이 연구는 ParlaMint 프로젝트의 전 과정을 활용하여, 의회에서의 발언을 기록한 음성과 해당 텍스트의 정렬 문제를 다룹니다. 이 과정에서 장기 오디오 캡쳐를 단어 수준 타임스탬프와 정렬하기 위한 현대적인 방법론을 제안하며, 기존의 복잡한 정렬 문제를 해결하기 위한 노력이 포함됩니다.

- **Performance Highlights**: 최종 결과로 5,000시간 이상의 연설과 텍스트 전사 데이터로 구성된 3개의 고품질 데이터셋이 생성되었습니다. 이 데이터셋은 대상 언어에 대한 음성 및 텍스트 데이터 접근성을 크게 향상시키며, 향후 비슷한 방식으로 더 많은 언어로 확장할 수 있는 잠재력을 지니고 있습니다.



### Toward Automated Clinical Transcriptions (https://arxiv.org/abs/2409.15378)
Comments:
          7 pages, 6 figures

- **What's New**: 본 논문은 최근의 speech-to-text (음성 인식) 및 speaker-labeling (화자 레이블링) 기술을 활용하여 환자-제공자 대화의 정확한 전사를 생성하고, 오류를 강조하여 신속한 인간 검증을 촉진하는 안전한 시스템을 소개합니다.

- **Technical Details**: 이 시스템은 40시간 이상의 시뮬레이션 대화에 적용되어 최적화 되었으며, 의료 문서화의 수작업 노력을 줄이기 위해 설계되었습니다. 특히, 불필요한 수작업을 최소화하여 임상 전사(Clinical Transcriptions)의 자동화를 위한 유망한 기초를 제공합니다.

- **Performance Highlights**: 이 시스템은 정확한 전사를 생성하는 데 있어 뛰어난 성능을 보이며, 의료 분야에서 피로도 증가 및 환자 관리 품질 저하와 같은 부정적인 결과를 완화하는 데 기여할 것으로 기대됩니다.



### ControlMath: Controllable Data Generation Promotes Math Generalist Models (https://arxiv.org/abs/2409.15376)
Comments:
          17 pages

- **What's New**: 본 연구에서는 데이터 증강(data augmentation)에 있어 대형 언어 모델(LLMs)의 제약 사항을 극복하기 위해 ControlMath라는 반복(iterative) 방법론을 소개합니다.

- **Technical Details**: ControlMath는 방정식 생성기(equation-generator) 모듈과 두 개의 LLM 기반 에이전트(agent)를 포함합니다. 방정식 생성 모듈은 다양한 방정식을 생성하고, Problem-Crafter 에이전트는 이를 수학적인 서술 문제로 변환합니다. Reverse-Agent는 'less is more' 원칙에 따라 고품질 데이터를 필터링하고 선택합니다.

- **Performance Highlights**: ControlMathQA는 190,000개의 수학 서술 문제(math word problems)를 포함하고 있으며, 이 데이터셋은 GSM8K와 같은 도메인 내(in-domain) 데이터셋과 결합함으로써 모델의 수학적 일반화(generalization) 능력을 향상시킵니다. 결과적으로 특정 도메인뿐만 아니라 그 너머에서도 성능이 개선되는 것을 보였습니다.



### Fine-Tuning a Time Series Foundation Model with Wasserstein Loss (https://arxiv.org/abs/2409.15367)
Comments:
          4 main pages; 2 figures

- **What's New**: 이번 연구는 시간 시계열 예측을 위한 기초 모델 개발에 있어 최근의 대형 언어 모델(LLM) 발전에 힘입어, cross-entropy loss 대신 Wasserstein loss를 사용하는 방법을 제안하고 있습니다.

- **Technical Details**: 연구진은 LLM 아키텍처를 토큰화된 시간 시계열 데이터로 교육하여 cross-entropy loss로 주어진 모델을 정밀 조정하였습니다. Wasserstein loss는 클래스 간 거리 정보를 반영하며, 성능 비교를 통해 예측 정확도를 개선하는 것이 입증되었습니다.

- **Performance Highlights**: 22개의 zero-shot 데이터셋에서 평가한 결과, cross-entropy loss에 비해 Wasserstein loss를 사용하는 것이 점 추정(point estimation) 성능을 유의미하게 향상시켰습니다.



### Reward-Robust RLHF in LLMs (https://arxiv.org/abs/2409.15360)
- **What's New**: 본 논문에서는 보상 모델의 불안정성과 오류를 해결하기 위한 보상 강건 RLHF(Reward-Robust Reinforcement Learning from Human Feedback) 프레임워크를 제안합니다.

- **Technical Details**: 이 프레임워크는 Bayesian Reward Model Ensembles (BRME)를 통해 보상 함수의 불확실성 집합을 모델링하며, 성능과 강건성을 균형 있게 최적화하는 새로운 목표를 설정합니다.

- **Performance Highlights**: 제안하는 프레임워크는 16개의 다양한 벤치마크에서 전통적인 RLHF를 지속적으로 초월하여 평균 정확도가 약 4% 더 높게 나타났으며, 장기 훈련 과정에서도 더 강한 안정성과 향상된 성능을 보여주었습니다.



### A Joint Spectro-Temporal Relational Thinking Based Acoustic Modeling Framework (https://arxiv.org/abs/2409.15357)
- **What's New**: 본 논문은 인간의 언어 인식에서 중요한 역할을 하는 관계적 사고(relational thinking)를 기반으로 한 음성 인식 시스템을 제안합니다. 기존의 시스템들이 대부분 단순한 시간적 모델에 의존하고 있는 반면, 새로운 접근법은 스펙트로-시간적 관계를 모델링합니다.

- **Technical Details**: 제안된 프레임워크는 음성 세그먼트 간의 관계를 시간(time)과 주파수(frequency) 도메인 모두에서 모델링하여, 생성된 확률적 그래프를 통해 관계 정보를 집계하고 잠재 표현(latent representation)으로 변환합니다. 이는 음성 인식의 성능을 개선하는 데 기여합니다.

- **Performance Highlights**: 이 프레임워크를 통해 구축된 모델은 TIMIT 데이터셋에서 음소(phneme) 인식 작업에서 7.82%의 성능 향상을 달성하였고, 특히 모음(vowel) 인식 능력이 크게 개선되었음을 보여주었습니다.



### Block-Attention for Efficient RAG (https://arxiv.org/abs/2409.15355)
- **What's New**: 이번 논문에서는 Retrieval-Augmented Generation (RAG) 시나리오에서의 추론 지연 및 비용을 줄이기 위해 설계된 새로운 attention 메커니즘인 Block-Attention을 소개합니다. 기존 방법들과 달리, Block-Attention은 검색된 문서를 블록으로 나누어 각 블록이 KV(state) 상태를 독립적으로 계산하도록 하여 효율성을 높입니다.

- **Technical Details**: Block-Attention 메커니즘은 입력 시퀀스를 여러 블록으로 나누고, 각 블록은 자신만의 KV 상태를 self-attention을 통해 계산합니다. 마지막 블록만이 다른 블록에 접근합니다. 이 기법을 통해 모든 passage를 블록으로 정의하고 그 KV 상태를 메모리에 캐시하여, 추론 시의 지연 시간을 크게 줄일 수 있습니다.

- **Performance Highlights**: 실험 결과에 따르면, Block-Attention을 적용하면 평균 TTFT(첫 번째 토큰까지의 시간)를 98.7% 줄일 수 있으며(3638 ms에서 45 ms로 단축), 첫 번째 토큰을 추출할 때의 FLOPs 역시 99.8% 감소시킵니다. 블록-어텐션 모델은 기존의 self-attention 모델에 비해 (Llama3: 68.4% vs 67.9%, Mistral: 62.8% vs 59.6%) 유사하거나 더 나은 성능을 보여줍니다.



### Contextualization of ASR with LLM using phonetic retrieval-based augmentation (https://arxiv.org/abs/2409.15353)
- **What's New**: 이 논문에서는 멀티모달(multi-modal) LLM(대형 언어 모델)을 개인 이름 엔티티를 올바르게 인식하기 위한 새로운 방법을 제안합니다. 구체적으로, 음성 인식 작업에서 LLM이 이름 엔티티를 감지한 후, 개인 데이터베이스에서 음성적으로 유사한 이름 엔티티를 검색하고 이를 LLM에 전달하여 컨텍스트 인식 ASR(자동 음성 인식)을 수행하는 방식을 사용합니다.

- **Technical Details**: 이 연구는 LLM과 오디오 인코더를 통합하고, 이를 통해 오디오 임베딩을 생성하여 ASR 디코딩을 실행합니다. 감지 단계에서 LLM은 음성 신호에서 개인 이름 엔티티를 감지하고, 그 후에 음성적으로 유사한 엔티티를 검색합니다. 검색된 엔티티를 LLM에 전달하여 ASR 디코딩을 통해 최종 결과를 생성합니다. 또한, NPD(정규화된 음향 거리)를 사용하여 음성의 발음 유사성을 측정합니다.

- **Performance Highlights**: 이 방법은 기존의 ASR 시스템과 비교하여 최대 30.2%의 단어 오류율 감소와 73.6%의 이름 엔티티 오류율 감소를 달성했습니다. 이 시스템은 전체 이름 엔티티 데이터베이스를 LLM에 제공하지 않기 때문에 높은 효율성과 대규모 이름 엔티티 데이터베이스에 적용 가능하다는 장점이 있습니다.



### A Large Dataset of Spontaneous Speech with the Accent Spoken in S\~ao Paulo for Automatic Speech Recognition Evaluation (https://arxiv.org/abs/2409.15350)
- **What's New**: 이 논문은 브라질 포르투갈어를 위한 자발적 대화 음성 코퍼스(NURC-SP Audio Corpus)를 새롭게 선보이며, 자동 음성 인식(ASR) 실험 결과를 보고합니다. 이 코퍼스는 포르투갈어의 대화체 발음을 포함하고 있으며, 401명의 화자(여성 204명, 남성 197명)가 참여하여 총 239.30시간의 음성 녹음이 포함되어 있습니다.

- **Technical Details**: NURC-SP Audio Corpus는 Wav2Vec2-XLSR-53 및 Distil-Whisper 모델을 활용하여 ASR 성능을 평가합니다. Wav2Vec2-XLSR-53는 53개 언어의 데이터로 미리 학습된 모델이며, Distil-Whisper는 Whisper 모델의 효율적인 단축 버전입니다. 본 연구에서는 두 모델을 우리의 데이터셋에 맞춰 조정하였습니다. 마지막으로 Distil-Whisper 모델은 NURC-SP Audio Corpus에서 24.22%의 단어 오류율(WER)을 기록했습니다.

- **Performance Highlights**: Distil-Whisper 모델은 24.22%의 WER로 가장 우수한 성과를 거두었으며, Wav2Vec2-XLSR-53 모델은 33.73%의 WER로 뒤를 따릅니다. 이 결과는 자발적 대화의 포르투갈어 음성을 인식할 때 NURC-SP Audio Corpus의 유용성을 입증합니다.



### Revisiting the Solution of Meta KDD Cup 2024: CRAG (https://arxiv.org/abs/2409.15337)
- **What's New**: 이 논문은 Meta KDD CUP 2024의 CRAG Comprehensive RAG Benchmark Challenge에서 팀 APEX의 솔루션을 소개합니다. CRAG 벤치마크는 Retrieval-Augmented Generation (RAG) 시스템의 다양하고 동적인 문제를 평가하는 데 있어 기존 QA 벤치마크의 한계를 극복할 수 있도록 설계되었습니다.

- **Technical Details**: 본 연구에서는 질문의 다양성과 동적인 특성에 맞춘routing 기반의 도메인 및 동적 적응 RAG 파이프라인을 제안합니다. 이 방법은 정보 검색(retrieval), 증대(augmentation), 생성(generation) 세 단계에서 모두 특별한 처리를 수행하며, CRAG에서 우수한 성과를 거두어 최종 경쟁 리더보드에서 작업 2와 3에서 2위를 기록했습니다.

- **Performance Highlights**: 우리의 방법은 CRAG에서 뛰어난 성과를 발휘했으며, 특히 웹 페이지 검색 및 Mock API를 활용해 정보 선택과 통합의 능력을 강조하였습니다. 각 과제는 이전 단계를 기반으로 하여, 참가자들이 더욱 정교한 end-to-end RAG 시스템을 개발하도록 유도합니다.



### Sorbet: A Neuromorphic Hardware-Compatible Transformer-Based Spiking Language Mod (https://arxiv.org/abs/2409.15298)
- **What's New**: 이 논문은 Neuromorphic hardware에 적합한 Transformer 기반의 스파이킹 언어 모델인 Sorbet를 소개합니다. Sorbet는 에너지 소모를 줄이면서도 경쟁력 있는 성능을 유지하는 혁신적인 Softmax와 정규화 방법을 도입하여, 기존의 복잡한 연산에 의존하지 않고 동작할 수 있습니다.

- **Technical Details**: Sorbet는 PTsoftmax라는 새로운 shifting 기반 Softmax와 bit-shifting를 이용한 BSBN이라는 파워 정규화 방법을 기반으로 합니다. 이러한 접근 방식을 통해 기존의 에너지를 많이 소모하는 연산을 대체하며, SNN 상에서의 효율적인 동작을 가능하게 합니다.

- **Performance Highlights**: GLUE 벤치마크를 통한 테스트에서 Sorbet는 낮은 에너지 비용으로 안정된 성능을 유지함을 증명했습니다. 이 모델은 또한 Knowledge Distillation 및 모델 양자화를 활용하여 고도로 압축된 바이너리 가중치 모델을 구현했고, 이는 에너지 효율적인 언어 모델 추론의 잠재력을 보여줍니다.



### The NGT200 Dataset: Geometric Multi-View Isolated Sign Recognition (https://arxiv.org/abs/2409.15284)
Comments:
          Proceedings of the Geometry-grounded Representation Learning and Generative Modeling Workshop (GRaM) at the 41 st International Conference on Machine Learning, Vienna, Austria. PMLR 251, 2024

- **What's New**: 본 연구에서는 Sign Language Processing (SLP)의 다중 관점 고립 기호 인식(MV-ISR)을 다루며, 3D 인식 및 기하학의 중요성을 강조합니다. 또한 새로운 spatio-temporal multi-view benchmark인 NGT200 데이터셋을 소개합니다.

- **Technical Details**: NGT200 데이터셋은 다중 관점에서 촬영된 고립 기호의 비디오 클립에서 추출한 2D 랜드마크를 포함합니다. 이 데이터셋은 3D-LEX 데이터셋과 함께 사용되어 각 기호에 대한 3D Ground Truth를 제공합니다. 이 연구는 SE(2) 등변 모델을 활용하여 MV-ISR의 성능을 향상시킬 수 있음을 보여줍니다.

- **Performance Highlights**: MV-ISR은 SE(2) 등변 모델을 활용하여 성능이 기준선 대비 8%-22% 향상되었습니다. 이를 통해 기호 인식 시스템의 실용성을 높일 수 있는 방법을 제시합니다.



### A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor? (https://arxiv.org/abs/2409.15277)
Comments:
          The first four authors contributed equally, project page available at this https URL

- **What's New**: 본 논문에서는 OpenAI의 새로운 모델 o1이 초기화된 Chain-of-Thought 기법을 사용하여 강력한 언어 모델(Large Language Models, LLMs)의 성능을 강화했음을 소개합니다. 특히, o1의 의료 분야에서의 적용 가능성과 성능을 평가하는 데 중점을 두고 있습니다.

- **Technical Details**: o1 모델은 37개의 의료 데이터셋을 바탕으로 6가지 과제를 평가하였으며, 두 개의 도전적인 질문-답변(QA) 데이터를 새로 작성하였습니다. 평가 항목으로는 이해(Understanding), 추론(Reasoning), 다국어 능력(Multilinguality)을 사용하였습니다.

- **Performance Highlights**: o1은 19개의 데이터셋과 두 개의 새로운 복잡한 QA 시나리오에서 GPT-4 보다 평균 6.2% 및 6.6% 더 정확한 성능을 보였습니다. 그러나 모델의 할루시네이션(Hallucination), 일관성 없는 다국어 능력, 평가 지표 간의 차이 등 여러 약점도 발견되었습니다.



### OmniBench: Towards The Future of Universal Omni-Language Models (https://arxiv.org/abs/2409.15272)
- **What's New**: OmniBench는 여러 모달리티(visual, acoustic, textual) 간의 상호작용을 평가하고 모델의 이해 및 추론 능력을 측정하는 새로운 벤치마크입니다. 이 벤치마크는 모든 모달리티 간의 통합된 이해를 요구하여 기존의 한계를 극복하고 있습니다.

- **Technical Details**: 오미벤치(OmniBench)는 미리 훈련된 초대형 언어 모델(MLLMs)의 tri-modal(3중 모달리티) 처리 능력을 테스트하기 위한 포괄적인 도구입니다. OLMs(omni-language models)는 이러한 능력을 갖춘 모델로 정의됩니다. OLMs는 high-quality human annotations에 의존하여 정확한 응답을 제공하는 데 필요한 모든 모달리티의 통합된 이해를 요구합니다.

- **Performance Highlights**: 대부분의 OLMs는 tri-modal 상황에서 지시 수행 및 추론 능력에 한계를 보이는 것으로 나타났습니다. 기존의 MLLM들은 이미지 또는 오디오와 함께 제공되었을 때 명확한 지시를 따르기 어려운 경우가 많으며, 대체 텍스트 표현 사용 시에도 정확도가 50% 미만으로 낮은 성능을 기록했습니다.



### Behavioral Bias of Vision-Language Models: A Behavioral Finance View (https://arxiv.org/abs/2409.15256)
Comments:
          ICML 2024 Workshop on Large Language Models and Cognition

- **What's New**: 이번 연구는 대형 비전-언어 모델(LVLM)의 행동 편향을 행동 재무학의 관점에서 분석한 최초의 연구로, LVLM이 인간과 유사한 결정의 합리성을 발휘하는지 혹은 인간과 유사한 판단 및 결정 편향에 영향을 받는지를 조사합니다.

- **Technical Details**: 연구는 S&P 500 기업의 주식 역사 및 분기별 주당순이익(EPS) 보고서를 포함하는 멀티모달 데이터셋인 DynoStock을 체계적으로 축적하고, recency bias(최근 편향) 및 authority bias(권위 편향)에 대한 프롬프트 템플릿을 설계하여 LVLM의 편향 영향을 평가하는 새로운 평가 프레임워크를 제안합니다.

- **Performance Highlights**: 연구 결과, LLaVA-NeXT, MobileVLM-V2, Mini-Gemini, MiniCPM-Llama3-V 2.5 및 Phi-3-vision-128k와 같은 최근 공개 소스 LVLM들은 두 가지 행동 편향에 심각한 영향을 받는 것으로 나타났습니다. 반면, 독점 모델인 GPT-4o는 편향의 영향에서 거의 영향을 받지 않았습니다.



### MemBench: Towards Real-world Evaluation of Memory-Augmented Dialogue Systems (https://arxiv.org/abs/2409.15240)
Comments:
          In progress

- **What's New**: 이 논문은 기존의 대화 시스템(DS) 평가 방식의 한계를 극복하기 위해 새로운 메모리 벤치마크인 MemBench를 제안합니다. 이는 인지 과학 및 심리학 이론에 기반하여 다양한 메모리 회상 패러다임을 포함하는 완전한 평가 방법론을 제공합니다.

- **Technical Details**: MemBench는 인지 과학의 두 단계 이론에 따라 구성된 두 가지 작업(메모리 회수 및 인지/주입)을 포함하고 있으며, 수동적 및 능동적 메모리 회상을 모두 고려합니다. 이 벤치마크는 새로운 점수 평가 방식을 도입하여 생성된 응답의 다양한 측면을 포괄적으로 측정합니다.

- **Performance Highlights**: 실험 결과, 현재의 대화 시스템이 메모리를 도입하여도 인간과의 대화에서 여전히 성능이 부족한 점이 드러났습니다. 특히, 메모리 주입이 감정 지원(ES) 능력과 친밀도에 긍정적인 연관성이 있음을 발견하였습니다.



### ASTE Transformer Modelling Dependencies in Aspect-Sentiment Triplet Extraction (https://arxiv.org/abs/2409.15202)
Comments:
          The 2024 Conference on Empirical Methods in Natural Language Processing, November 12-16, Miami, Florida 9 pages, appendix, diagrams

- **What's New**: 본 논문에서는 Aspect-Sentiment Triplet Extraction (ASTE)에서의 종속성을 모델링할 수 있는 새로운 접근 방식인 ASTE-Transformer를 제안합니다.

- **Technical Details**: ASTE-Transformer는 세 가지 유형의 transformer-inspired layers로 구성되며, 이는 (1) 표준 transformer layers, (2) aspect-opinion 쌍 생성 layer, (3) triple 생성 layer입니다. 이 구조는 두 개의 문장을 기반으로 aspect와 opinion을 추출하고, 그 종속성을 동시에 고려하여 sentiment polarity를 할당할 수 있는 능력을 제공합니다.

- **Performance Highlights**: 실험 결과, ASTE-Transformer는 기존의 방법들보다 F1 성능이 향상되었으며, pre-training 기술이 모델 성능을 추가적으로 개선시켰습니다.



### Learning from Contrastive Prompts: Automated Optimization and Adaptation (https://arxiv.org/abs/2409.15199)
- **What's New**: LCP( Learning from Contrastive Prompts) 프레임워크는 기존의 프롬프트 최적화 방법의 한계를 극복하고자 하며, 여러 모델 버전과 언어에서 효과적으로 적응 감소를 제공한다.

- **Technical Details**: LCP는 입력 프롬프트의 패턴 분석을 통해 효과적인 프롬프트를 생성하기 위해 대조 학습(contrastive learning) 기법을 활용한다. 주안점은 좋은 프롬프트와 나쁜 프롬프트를 비교하면서 오류 사례를 학습하는 것이다.

- **Performance Highlights**: LCP는 Big-Bench Hard 데이터셋에서 기존 방법들보다 76% 이상의 승률을 기록하며, 특히 알고리즘적 및 단계별 산술 추론 작업에서 효율성을 보였다.



### PALLM: Evaluating and Enhancing PALLiative Care Conversations with Large Language Models (https://arxiv.org/abs/2409.15188)
Comments:
          Accepted by ACM Transactions on Computing for Healthcare, Special Issue on Large Language Models, Conversational Systems, and Generative AI in Health, pending minor revisions

- **What's New**: 본 연구는 대량 언어 모델(LLMs)을 평가자로 활용하여 통증을 포함한 중증 질환을 겪고 있는 환자들을 위한 완화 의료(Palliative Care) 커뮤니케이션의 품질을 평가하는 새로운 접근 방식을 제안합니다. 기존의 NLP 기술이 임상 커뮤니케이션의 뉘앙스를 포착하는 데 어려움을 겪는 반면, LLMs는 언어적, 상황별 학습 및 추론 능력을 활용하여 이를 극복할 수 있는 가능성을 보여줍니다.

- **Technical Details**: 이 연구에서는 의료 전문가가 제작하고 라벨링한 8개의 시뮬레이션된 임상 커뮤니케이션 스크립트를 사용하여, GPT-4와 LLaMA2-13b와 같은 LLM을테스트하고 프로프팅 전략을 활용하여 이해, 공감, 감정, 존재감 및 명료성과 같은 커뮤니케이션 지표를 평가했습니다. 알고리즘의 성능 향상을 위해 GPT-4에 의해 생성된 합성 데이터를 활용하여 LLaMA 모델을 미세 조정(fine-tune)하였습니다.

- **Performance Highlights**: 우리의 연구 결과는 GPT 기반 모델이 임상 커뮤니케이션 지표 식별에서 90% 이상의 균형 잡힌 정확도와 LLaMA2-13b 모델이 80%의 정확도를 기록하며 비-LLM NLP 기준을 초과하여 LLM이 임상 커뮤니케이션 분석에 대한 높은 잠재력을 지니고 있음을 보여주었습니다. 이는 LLM 기반 시스템의 개발 가능성과 실제 응용 가능성을 강조합니다.



### Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies (https://arxiv.org/abs/2409.15163)
- **What's New**: 이번 연구는 의료 분야에서 LLMs의 효과적인 정보 검색을 위한 다양한 embedding 모델과 pooling 방법의 영향을 분석한 것입니다. 특히, BGE라는 일반 도메인 모델이 의료 전용 모델보다 일관되게 우수한 성능을 보인 점이 주목할 만합니다.

- **Technical Details**: 연구는 MIMIC-III와 사설 전자 건강 기록(EHR) 데이터를 사용하는 세 가지 정보 검색 작업을 수행했습니다. 총 일곱 개 모델을 평가했으며, 각 모델에 대한 embedding pooling 전략이 독립적으로 어떻게 작용하는지도 분석했습니다.

- **Performance Highlights**: BGE 모델은 다른 의료 전용 모델보다 뛰어난 검색 성능을 보였으며, 데이터셋과 쿼리 내용에 따라 상당한 변동성이 있음을 발견했습니다. 최적의 pooling 방법을 제안하여 미래의 검색 시스템 디자인에 기여할 수 있는 통계적으로 검증된 권장 사항을 제공했습니다.



### Inferring Scientific Cross-Document Coreference and Hierarchy with Definition-Augmented Relational Reasoning (https://arxiv.org/abs/2409.15113)
- **What's New**: 이 연구에서는 과학 텍스트에서 문서 간 핵심 참조(coreference)와 계층(hierarchy)을 추론하는 새로운 방법을 제안합니다. 이는 지식 그래프 구축, 검색, 추천 및 발견에 중요한 응용 프로그램을 가지고 있습니다.

- **Technical Details**: 제안된 방법은 논문에서 개념 언급에 대한 문맥-의존적 정의를 생성하기 위해 전체 텍스트 문헌을 검색하며, 이러한 정의를 사용하여 문서 간 관계 감지를 향상시키고, 두 개념 언급의 관계를 설명하는 관계 정의(relational definitions)를 생성하는 것입니다. 또한, 두 단계 재정렬 접근방식을 설계하여 문서 간 링크를 추론할 때 조합 폭발(combinatorial explosion)을 방지합니다.

- **Performance Highlights**: SciCo 데이터셋(SciCo dataset)의 기초에서, 우리는 미세 조정(fine-tuning) 및 문맥 학습(in-context learning) 설정에서 모두 현저한 성능 향상을 달성했습니다. 특히, 미세 조정 설정에서는 기존 모델에 비해 CoNLL F1 점수에서 큰 개선을 보였으며, 계층 감지에서 특히 강력한 성과를 나타냈습니다.



### Using Similarity to Evaluate Factual Consistency in Summaries (https://arxiv.org/abs/2409.15090)
- **What's New**: 이 논문에서는 새로운 제로샷(Zero-shot) 사실성 평가 지표인 Sentence-BERT Score(SBERTScore)를 제안하며, 기존의 BERTScore보다 더 뛰어난 성능을 보임을 보여준다. 또한, 다양한 오류 유형 탐지에서 결합된 기술의 효과를 입증한다.

- **Technical Details**: SBERTScore는 생성된 요약과 원본 문서 간의 문장 임베딩을 비교하여 문장 수준에서 사실성을 평가한다. 이 과정에서 코사인 유사도(cosine similarity)를 계산하여 문장의 의미를 더 잘 표현할 수 있다. 실험 결과 SBERTScore는 n-그램(n-gram) 기반의 방법 및 BERTScore보다 우수하며, NLI 및 QA 기반의 사실성 지표와도 경쟁할 수 있다.

- **Performance Highlights**: SBERTScore는 제로샷 설정에서도 NLI 기반 메트릭보다 우수한 성능을 보였고, QA 기반 메트릭과 비슷한 성능을 보여줬다. 또한, 이 지표는 추가적인 학습 단계 없이 고품질의 사전 학습된 임베딩을 활용하여 계산 복잡성이 낮다.



### Depression Diagnosis Dialogue Simulation: Self-improving Psychiatrist with Tertiary Memory (https://arxiv.org/abs/2409.15084)
- **What's New**: 본 논문에서는 Agent Mental Clinic (AMC)라는 자가 개선형 대화형 에이전트 시스템을 소개하여 우울증 진단의 효율성을 높입니다. 이는 환자와 정신과 의사 에이전트 간의 시뮬레이션된 대화를 통해 이루어지며, 진단 정확도를 높이기 위해 정신과 의사 에이전트의 메모리 구조 및 대화 제어 플러그인을 설계하였습니다.

- **Technical Details**: AMC 시스템은 3개의 주요 부분으로 구성되어 있습니다: 1) 환자 에이전트: D4 데이터셋을 기반으로 생성된 다양한 환자들. 2) 정신과 의사 에이전트: 진단 대화를 통해 반영된 기술을 사용하는 에이전트. 3) 감독자 플러그인: 대화 과정을 제어하고 정신과 의사 에이전트의 반영을 촉진하는 불완전한 에이전트. 이러한 구조는 우울증 진단 및 대화 시뮬레이션의 최적화를 가능하게 합니다.

- **Performance Highlights**: 실험 결과, AMC 시스템은 우울증 진단 정확도를 평균 6.05% 향상시켰으며, 자살 예측 정확도는 1.8% 증가했습니다. 이 시스템은 제한된 수의 레이블이 있는 경우에도 다른 특정 도메인에 적용 가능합니다.



### Enhancing Scientific Reproducibility Through Automated BioCompute Object Creation Using Retrieval-Augmented Generation from Publications (https://arxiv.org/abs/2409.15076)
Comments:
          21 pages, 8 figures

- **What's New**: 본 연구에서는 IEEE BioCompute Object (BCO) 표준을 따르는 문서 생성을 자동화하는 새로운 접근 방식을 제시합니다.

- **Technical Details**: 이 연구는 Retrieval-Augmented Generation (RAG) 및 Large Language Models (LLMs)을 사용하여 과학 논문에서 BCO를 자동으로 생성하는 도구인 BCO assistant를 개발합니다. 주요 기술적 도전 과제인 LLM 환각(data hallucination) 및 긴 맥락 이해(long-context understanding)에 대한 해결책을 설명하며, 두 단계 검색(two-pass retrieval) 및 재순위화(re-ranking) 과정을 포함한 최적화된 검색 프로세스를 구현하였습니다.

- **Performance Highlights**: BCO assistant는 생명정보학(bioinformatics) 연구의 문서화를 자동화하여 필요한 시간과 노력을 크게 줄일 수 있습니다. 이 접근 방식은 과학적 재현성(scientific reproducibility)을 높이고, AI 지원 과학 문서화 및 지식 추출 가능성을 열어줍니다.



### Brotherhood at WMT 2024: Leveraging LLM-Generated Contextual Conversations for Cross-Lingual Image Captioning (https://arxiv.org/abs/2409.15052)
Comments:
          Accepted at the Ninth Conference on Machine Translation (WMT24), co-located with EMNLP 2024

- **What's New**: 본 논문에서는 Brotherhood라는 팀 이름으로 영어에서 저해상도 다중 모달 번역 작업을 위한 시스템을 소개합니다. 영어-힌디어, 영어-하우사어, 영어-벵골어, 영어-말라얄람어 언어 쌍의 다중 모달 번역 작업에 참여하였습니다.

- **Technical Details**: 본 연구는 전통적인 훈련(fine-tuning) 없이 cross-lingual image captioning을 향상시키기 위해 다중 모달 대규모 언어 모델(multi-modal Large Language Models)인 GPT-4o와 Claude 3.5 Sonnet을 활용하는 방법을 제시합니다. Instruction-tuned prompting을 사용하여 잘라낸 이미지에 대한 풍부한 맥락 대화를 생성하며, 영어 캡션을 추가 맥락으로 사용합니다. 이러한 합성 대화는 타겟 언어로 번역됩니다. 마지막으로, 무게 조절 프롬프트(weighted prompting) 전략을 사용하여 원본 영어 캡션과 번역된 대화의 균형을 잡아 타겟 언어에서 캡션을 생성합니다.

- **Performance Highlights**: 본 방법은 영어-힌디어 챌린지 세트에서 37.90 BLEU 점수를 획득했으며, 영어-하우사어의 챌린지와 평가 리더보드에서 각각 1위와 2위에 랭크되었습니다. 또한, 250개의 이미지 하위 집합에 대한 추가 실험을 실시하여 다양한 가중치( weighting schemes) 조정 방식에서 BLEU 점수와 의미론적 유사성 사이의 trade-off를 탐색했습니다.



### Scaling Laws of Decoder-Only Models on the Multilingual Machine Translation Task (https://arxiv.org/abs/2409.15051)
- **What's New**: 최근 연구들은 인코더-디코더(encoder-decoder) 모델의 지배를 받던 기계 번역 분야에서 디코더 전용(decoder-only) 모델의 가능성을 탐구하고 있습니다. 본 연구는 다양한 언어와 도메인에서의 번역 작업을 위해 70M에서 7B 파라미터까지의 디코더 전용 모델을 훈련시키고, 이러한 모델의 스케일링 법칙을 조사하였습니다.

- **Technical Details**: 연구진은 디코더 전용 모델이 대형 언어 모델(LLM)에서 발견된 스케일링 법칙과 유사한 법칙을 따르지만, 모델의 크기가 너무 크거나 다른 데이터 분포에 일반화하는 데에는 어려움이 있다는 것을 발견했습니다. 또한, 모델의 깊이와 너비를 확장하는 방법이 유사한 테스트 손실 개선을 가져오지만, 후자는 모델의 효율성에 더 좋은 영향을 미친다고 합니다.

- **Performance Highlights**: 이번 연구에서 디코더 전용 모델은 이전의 인코더-디코더 모델보다 더 효율적인 훈련을 가능하게 하며, 특히 대량의 데이터를 처리하는 데 유리하다는 점이 강조되었습니다. 또한, 훈련 샘플의 배치(pack) 문제를 해결하기 위한 방법도 제안했습니다.



### Generative LLM Powered Conversational AI Application for Personalized Risk Assessment: A Case Study in COVID-19 (https://arxiv.org/abs/2409.15027)
- **What's New**: 이 연구는 전통적인 머신러닝 방법을 필요로 하지 않는 새로운 질병 위험 평가 방법을 제시하며, Generative LLM을 활용한 스티밍 인간-AI 대화를 통해 전방위적인 진단 가능성을 강조합니다.

- **Technical Details**: 본 연구는 Llama2-7b 및 Flan-T5-xl과 같은 사전 학습된 Generative LLM을 사용하여 COVID-19 심각도 위험 평가 사례 연구를 통해, 적은 수의 자연어 예제를 활용하여 모델을 고도화했습니다. 이를 통해 Logistic Regression, XGBoost, Random Forest와 같은 전통적인 분류기와 비교했습니다.

- **Performance Highlights**: 잘 조정된 LLM들이 전통적인 분류 방법보다 더 높은 AUC 점수를 달성하여, 제한된 데이터에서 사용할 수 있는 가능성을 입증했습니다. 이를 통해 Generative LLM이 의료 분야에서 일반적인 적재와 반응을 공정하게 처리할 수 있음을 강조했습니다.



### Inference-Friendly Models With MixAttention (https://arxiv.org/abs/2409.15012)
- **What's New**: 본 논문에서는 KV 캐시의 크기를 줄이기 위해 MixAttention 아키텍처를 제안하며, 이 아키텍처는 최근의 토큰 집합만을 저장하는 슬라이딩 윈도우 어텐션(Sliding Window Attention)과 레이어 간 KV 캐시 공유(KV Cache Sharing)를 결합한 방법입니다. 이를 통해 메모리 사용량을 줄이고 추론 속도를 개선할 수 있다는 점에서 주목할 만합니다.

- **Technical Details**: MixAttention은 모델의 메모리 소비를 줄이고, 긴 입력에 대한 추론 성능을 향상시키기 위해 슬라이딩 윈도우 어텐션과 KV 캐시 공유를 결합한 방법론을 사용합니다. 여러 가지 아키텍처 변형을 통해 평가하였고, 다양한 조합이 모델의 성능에 미치는 영향을 조사하였습니다. 이 결과, 짧은 및 긴 컨텍스트 작업 모두에서 모델 품질을 유지하면서도 자원 효율성을 최적화하는 구성을 발견하였습니다.

- **Performance Highlights**: MixAttention 구조는 추론 속도를 높이고 메모리 사용량을 줄이는 데 성공적으로 기여했으며, 대부분의 평가 지표에서 표준 트랜스포머 모델과 유사한 성능을 보여주었습니다. 특히, 레이어 간 KV 캐시 공유와 슬라이딩 윈도우 레이어 추가가 추론 성능을 향상시키고 메모리 사용을 줄이는 데 효과적입니다.



### Enhancing Aspect-based Sentiment Analysis in Tourism Using Large Language Models and Positional Information (https://arxiv.org/abs/2409.14997)
Comments:
          19 pages, 17 figures

- **What's New**: 이 논문에서는 관광 분야에서의 Aspect-Based Sentiment Analysis(ABSA)를 위한 새로운 모델 ACOS_LLM을 제안합니다. 이 모델은 Aspect-Category-Opinion-Sentiment Quadruple Extraction(ACOSQE)을 목표로 하며, 기존 전통적인 파이프라인 모델의 문제점을 해결하고자 합니다.

- **Technical Details**: ACOS_LLM 모델은 보조 지식 생성을 위한 Adalora와 모델 압축을 위한 Sparsegpt를 사용하여 전체 모델의 효율성을 높입니다. 이후 Positional 정보와 시퀀스 모델링을 통해 ACOSQE 작업을 수행합니다. 이를 위해 Bi-directional Long Short-Term Memory(BiLSTM)와 Bidirectional Gated Recurrent Unit(BiGRU)를 활용하여 감정 표현의 맥락을 이해하고, 다양한 측면의 감정 방향성을 구분합니다.

- **Performance Highlights**: 실험 결과, ACOS_LLM은 관광 데이터셋에서 다른 모델들에 비해 F1 점수가 7.49% 향상되었고, Rest15와 Rest16 데이터셋에서 각각 0.05% 및 1.06% 향상된 성능을 보여주었습니다.



### Beyond Fine-tuning: Unleashing the Potential of Continuous Pretraining for Clinical LLMs (https://arxiv.org/abs/2409.14988)
- **What's New**: 이번 연구에서는 LLM(대형 언어 모델)을 임상 적용에 맞게 조정하기 위한 네 가지 기법(continuous pretraining, instruct fine-tuning, NEFTune, prompt engineering)의 효과를 검토했습니다.

- **Technical Details**: Mistral 7B 및 Mixtral 8x7B 모델을 활용하며, 500억 토큰의 대규모 임상 사전 학습 데이터셋과 5억 토큰의 instruct fine-tuning 데이터셋을 사용하였습니다. continuous pretraining은 모델의 기초를 다지며 instruct fine-tuning과 NEFTune 방식이 성능 향상에 기여하였습니다.

- **Performance Highlights**: continuous pretraining은 250억 토큰 이상에서 미미한 향상을 보였으나, instruct fine-tuning을 위한 튼튼한 기초를 마련하였고, NEFTune은 모델의 생성 품질을 향상시키는데 추가적인 이점을 가져왔습니다.



### Evaluating Theory of (an uncertain) Mind: Predicting the Uncertain Beliefs of Others in Conversation Forecasting (https://arxiv.org/abs/2409.14986)
- **What's New**: 이 연구는 Theory of Mind의 개념을 확장하여 언어 모델이 대화 중 다른 사람의 신념에 대한 불확실성을 예측하는 새로운 과제를 제안합니다. 기존의 신념 예측 과제가 이분법적으로 신념을 취급하는 반면, 이 논문은 대화자들의 신념이 더 유동적일 수 있으며, 불확실성의 정도까지 평가할 수 있음을 강조합니다.

- **Technical Details**: 저자들은 대화 예측(conversation forecasting) 기법을 통해 언어 모델의 불확실성 예측 능력을 평가합니다. 특히, 대화자가 직접적으로 대화 결과에 대한 불확실성을 예측하도록 모델을 훈련시키고, 이를 바탕으로 세 개의 대화 코퍼스(사회적, 협상, 작업 지향적)와 여덟 개의 모델을 가지고 실험을 수행했습니다.

- **Performance Highlights**: 연구 결과에 따르면, 언어 모델은 다른 사람의 불확실성 변동의 최대 7.5%를 설명할 수 있지만, 이 과제가 여전히 어렵고 이는 향후 연구의 여지를 남깁니다. 저자들은 특히 이 연구의 방법론적 기여 외에도 상황에 따른 대화자의 목표와 맥락이 언어 모델의 ToM(Theory of Mind) 능력에 미치는 영향을 조사했습니다.



### Bilingual Rhetorical Structure Parsing with Large Parallel Annotations (https://arxiv.org/abs/2409.14969)
- **What's New**: 이 논문에서는 러시아어에 대한 병렬 주석을 포함한 대규모 영어 GUM RST 코퍼스를 제시합니다. 이를 통해 교차언어 RST 모델의 개발 및 평가를 가능하게 합니다.

- **Technical Details**: 이 연구는 언어 독립적인 고차 구조를 구성하고, 하위 수준에서 언어별 뉘앙스를 통합하는 최상위에서 하위로의 파서(adaptation) 접근 방식을 사용합니다. 또한, 제한적인 제2언어 주석을 가진 경우에도 파서 전이(transfer)를 효율적으로 수행할 수 있는 양을 탐구합니다.

- **Performance Highlights**: 개발된 end-to-end RST 파서는 영어 RST-DT에서 53.0%의 end-to-end Full F1 score을, 러시아어 RRT에서 45.3%의 F1 score을 기록하는 등 두 언어 모두에서 최첨단 성능을 달성했습니다.



### Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely (https://arxiv.org/abs/2409.14924)
- **What's New**: 이 연구에서는 외부 데이터를 활용한 대형 언어 모델(LLM)의 다양한 활용사례와 그 과정에서의 도전 과제를 제시합니다. 특히 Retrieval-Augmented Generation (RAG) 기법을 활용하여 사용자 쿼리를 네 가지 레벨로 분류하여 각 레벨에 맞는 기술적 접근 방식을 정리합니다.

- **Technical Details**: 본 논문에서는 쿼리를 명시적 사실 쿼리(Explicit Fact Queries), 암시적 사실 쿼리(Implicit Fact Queries), 해석 가능한 근거 쿼리(Interpretable Rationale Queries), 숨겨진 근거 쿼리(Hidden Rationale Queries)로 나누어, 각 쿼리에 필요한 외부 데이터의 유형과 작업의 주요 초점을 정의합니다. 또한 LLM에 외부 데이터를 통합하는 세 가지 주요 형태인 컨텍스트(Context), 소규모 모델(Small Model), 파인 튜닝(Fine-tuning)의 장단점도 살펴봅니다.

- **Performance Highlights**: 데이터 보강 LLM 애플리케이션은 전문성과 적시성을 향상시키며, 도메인 전문가와의 정렬, 모델 환각 감소 및 제어 가능성 및 설명 가능성을 개선하는 장점을 제공합니다. 그러나 여전히 많은 개발자들이 이 기술을 활용하기 위해 상당한 인간 노력을 투입해야 한다는 과제가 남아 있습니다.



### With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models (https://arxiv.org/abs/2409.14917)
Comments:
          Accepted to EMNLP 2024

- **What's New**: 이번 연구는 대형 언어 모델(LLMs)과 비전 언어 모델(VLMs)이 사운드 상징(sound symbolism)을 어떻게 인지하는지를 분석하며, 시각적 정보와 텍스트 정보만으로 소리 기반 현상을 이해할 수 있는 능력을 조사합니다.

- **Technical Details**: VLMs와 LLMs의 소리 상징성을 평가하기 위해 Kiki-Bouba 및 Mil-Mal 심볼리즘 과제를 포함한 다양한 실험을 수행하였으며, 인간의 언어 아이코닉성(judgement of linguistic iconicity) 판단과 LLM의 판단을 비교하는 심층 분석을 진행했습니다.

- **Performance Highlights**: VLMs는 인간 레이블과 다양한 수준의 일치를 나타내며, Magnitude Symbolism을 이해하는 것이 Shape Symbolism보다 더 용이한 것으로 나타났습니다. 모델의 크기에 따라 언어 아이코닉성 이해도가 크게 달라지는 양상을 관찰했습니다.



### Towards a Realistic Long-Term Benchmark for Open-Web Research Agents (https://arxiv.org/abs/2409.14913)
- **What's New**: 새로운 벤치마크가 LLM 에이전트를 경제 가치가 있는 화이트칼라 작업에 대해 평가하기 위해 제안되었습니다. 이 연구에서는 금융 및 컨설팅 분야에서의 종합적이고 "어수선한(messy)" 작업을 평가하며, 이는 고객의 실제 사례에서 도출된 것입니다.

- **Technical Details**: 총 여덟 개의 실제 작업이 평가되며, 다양한 LLM 아키텍처(GPT-4o, Claude-3.5 Sonnet, Llama 3.1 (405b), GPT-4o-mini)가 시험되었습니다. 작업 수행 실패는 일반적인 문제(예: 웹사이트 분석 능력 부족)가 아니라 추론 및 계획의 실패로 간주되었습니다. ReAct 아키텍처가 보조작업을 하위 에이전트에 위임할 수 있는 능력 덕분에 가장 좋은 성과를 보였습니다.

- **Performance Highlights**: Claude-3.5 Sonnet를 사용한 LLM 에이전트들이 GPT-4o를 사용하는 에이전트들보다 크게 우수한 성과를 보였습니다. Llama 3.1 (405b) 및 GPT-4o-mini 기반의 에이전트는 상대적으로 성과가 낮았습니다. 이 벤치마크는 LLM 기반 에이전트의 경제 가치가 있는 작업에서 성능을 더 정확히 추정할 수 있게 합니다.



### Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization (https://arxiv.org/abs/2409.14907)
Comments:
          Full paper accepted at EMNLP 2024 (main)

- **What's New**: 본 연구는 대규모 언어 모델(Large Language Models, LLMs)의 상담 요약능력을 강화하는 새로운 계획 엔진(planning engine)을 도입했습니다. 이 엔진은 우선 대화 구조를 보존하고 도메인별 지식을 통합하는 과정을 두 가지 주요 단계로 나누어 실행합니다.

- **Technical Details**: 제안하는 시스템은 PIECE로 이름 붙여졌으며, Llama-2 기반에서 작동합니다. PIECE는 지식 필터링과 구조적 요소(scaffolding)를 활용하여 도메인 지식을 캡슐화하며, sheaf convolution learning을 통해 대화의 구조적 미세함을 개선합니다. 다양한 자동 요약 평가 메트릭(ROUGE, Bleurt)을 통해 14개의 기준 방법 대비 성능을 비교했습니다.

- **Performance Highlights**: PIECE는 ROUGE 및 Bleurt 점수에서 유의미한 향상을 보여주었으며, Llama-2는 +2.72%, Mistral은 +2.04%, Zephyr는 +1.59%의 향상을 기록했습니다. 전문가 평가를 통해 생성 품질이 효과적이며, 때로는 금본위(gold standard)를 초과하는 결과를 보였습니다.



### DSG-KD: Knowledge Distillation from Domain-Specific to General Language Models (https://arxiv.org/abs/2409.14904)
Comments:
          IEEE ACCESS 2024

- **What's New**: 본 연구는 어린이 응급 치료 센터에서 얻은 전자 의료 기록(EMR) 데이터 기준으로 비상/비비상 분류 작업을 수행하며, 기존의 도메인 특화 언어 모델들이 일반 언어 모델에 비해 성능이 부족함을 보이고 있습니다. 이를 해결하기 위해 도메인 지식 전이 방법론을 제안하였습니다.

- **Technical Details**: 언어 모델은 교사 모델(teacher model)과 학생 모델(student model)로 정의됩니다. 의료 도메인 데이터로 사전 훈련된 모델(예: KM-BERT)을 교사 모델로, 일반 언어 모델(예: Ko-BERT)을 학생 모델로 삼아 지식을 전이하는 과정에서, 학생 모델이 교사 모델의 숨겨진 상태(hidden states) 및 주의 행렬(attention matrices)을 학습하도록 훈련됩니다. 이 방법에서는 Knowledge Distillation (KD) 기술을 활용하여 도메인 특정 지식을 일반 모델에 주입합니다.

- **Performance Highlights**: 제안된 방법은 한국 PED EMR 데이터에서 비상 및 비비상 사례 분류에서 높은 성능을 보여, 기존 모델들을 능가하였습니다. 또한 이 방법론은 다양한 전문 및 기술 분야에서도 폭넓은 적용 가능성을 제시합니다.



### End-to-End Graph Flattening Method for Large Language Models (https://arxiv.org/abs/2409.14880)
Comments:
          2024 1st International Conference on Computational Linguistics and Natural Language Processing (CLNLP 2024)

- **What's New**: 본 연구에서는 Large Language Models (LLMs)의 그래프 처리 성능을 향상시키기 위한 새로운 방법인 End-to-End DAG-Path prompting (EEDP)를 제안합니다. EEDP는 기존의 그래프 평탄화 방법의 한계를 극복하여 장거리 시나리오에서의 추론 성능을 개선합니다.

- **Technical Details**: 기존의 그래프 평탄화 방법은 텍스트 형식으로 변환되어 LLMs에 사용되며, 이로 인해 장거리 의존성을 처리하는 데 한계를 보입니다. EEDP는 주 요약 경로(main backbone paths)를 활용하여 텍스트 설명을 생성하는 방법으로, 그래프의 시작 및 끝 노드만을 고려하여 최적의 표현을 도출합니다.

- **Performance Highlights**: 실제 데이터셋을 기반으로 한 실험 결과 EEDP는 장거리 및 단거리 시나리오에서 모두 뛰어난 성능을 보이며, 특히 장거리 시나리오에서의 LLM 성능 향상에 기여함을 보여주었습니다.



### Privacy Policy Analysis through Prompt Engineering for LLMs (https://arxiv.org/abs/2409.14879)
- **What's New**: PAPEL(Privacy Policy Analysis through Prompt Engineering for LLMs) 프레임워크는 대형 언어 모델(LLMs)의 성능을 활용하여 복잡한 개인정보 보호 정책을 자동으로 분석하는 혁신적인 접근 방식을 제시합니다.

- **Technical Details**: PAPEL는 제로샷(zero-shot), 원샷(one-shot), 소수샷(few-shot) 학습 방법 및 chain-of-thought prompting을 통합하여 LLMs가 개인정보 보호 정책을 효율적으로 분석하고 요약하도록 안내합니다. 추가적인 모델 훈련이 필요하지 않으며, 미리 정의된 프롬프트와 프롬프트 템플릿을 사용합니다.

- **Performance Highlights**: 실험 결과, LLaMA와 Chat GPT 모델을 포함한 LLMs는 개인정보 보호 정책 주석(annotation) 작업에서 F1 점수가 0.8 이상을 기록하여, 기존 자동 분석 접근 방식과 유사한 통찰을 제공하면서도 훈련 노력을 최소화하고 새로운 분석 요구에 대한 적응성을 높였습니다.



### Orthogonal Finetuning for Direct Preference Optimization (https://arxiv.org/abs/2409.14836)
- **What's New**: 본 논문에서는 기존의 Direct Preference Optimization (DPO) 알고리즘에서 발생하는 오버피팅 문제를 해결하기 위해 회전된 선호 최적화(weight-Rotated Preference Optimization, RoPO) 방법을 제안합니다. 이 방법은 신경망의 가중치 매개변수를 회전 및 크기 스트레칭 업데이트하여 초기 지식을 보존합니다.

- **Technical Details**: RoPO는 DPO에서 발생하는 오버피팅 현상을 완화하기 위하여 하이퍼스피어(hypersphere) 내에서의 에너지 변동을 활용하여 신경망의 뉴런 간 각도를 유지합니다. 이를 통해 모델의 표현 능력을 유지하면서도 사람의 선호에 잘 맞는 결과를 생성하도록 합니다. 특히, RoPO 방법은 단 0.0086%의 가중치 매개변수로도 우수한 성능을 발휘합니다.

- **Performance Highlights**: RoPO는 MT-Bench에서 DPO보다 최대 10점, AlpacaEval 2에서 최대 2.8점을 초과하는 성능을 보이며, 생성의 다양성도 평균 6점 증가시키는 결과를 보여줍니다.



### ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback (https://arxiv.org/abs/2409.14826)
- **What's New**: 최근 도구 보강 대형 언어 모델(LLMs)의 발전이 주목받고 있으며, 이들은 다양한 외부 도구와 상호작용하여 최종 답변을 제공합니다. 본 논문에서는 실제 사용자 시나리오를 반영하기 위해 새로운 데이터 세트 MGToolBench를 구축하고, LLM의 작업 완수 및 지침 이행 능력을 향상시키기 위한 ToolPlanner라는 두 단계 강화 학습 프레임워크를 제안합니다.

- **Technical Details**: MGToolBench는 사용자 행동을 반영하기 위해 다단계 사용자 지침 메커니즘을 채택하여 구성되었습니다. ToolPlanner는 첫 번째 단계에서 감독 하에 세밀화(Supervised Fine-Tuning, SFT) 모델을 사용하여 각각의 지침에 대한 해결책 트리를 생성하고, 두 번째 단계에서는 작업 완료 및 지침 이행이라는 두 가지 메트릭으로 생성된 솔루션을 평가합니다. 또한 솔루션 경로 계획 메커니즘을 사용하여 ToolPlanner의 다단계 추론 과정을 안내합니다.

- **Performance Highlights**: 실험 결과 ToolPlanner는 SOTA 모델 대비 Match Rate 26.8%, Pass Rate 20.2%, Win Rate 5.6% 향상되었음을 보여줍니다. 사람 평가에 따르면, 다중 세분화 지침이 사용자 사용 습관과 더 잘 일치하는 것으로 확인되었습니다.



### Past Meets Present: Creating Historical Analogy with Large Language Models (https://arxiv.org/abs/2409.14820)
- **What's New**: 이 논문은 역사적 유추(historical analogy) 획득(task) 연구에 초점을 맞추며, 대규모 언어 모델(Large Language Models, LLMs)을 활용한 유사한 역사적 사건의 검색 및 생성을 탐색합니다.

- **Technical Details**: 이 연구에서는 LLM을 기반으로 하여 역사적 유추를 획득하기 위한 검색(retrieval) 및 생성(generation) 방법을 제안하며, 생성 과정에서의 환각(hallucinations)과 고정관념(stereotypes)을 완화하기 위한 자가 반성(self-reflection) 방법도 제안합니다.

- **Performance Highlights**: 인간 평가 및 다차원 자동 평가를 통해 LLMs가 역사적 유추를 획득하는 데 일반적으로 좋은 잠재력을 가지고 있으며, 자가 반성 방법을 사용함으로써 모델의 성능을 더욱 개선할 수 있음을 보여줍니다.



### MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding (https://arxiv.org/abs/2409.14818)
- **What's New**: 최근 VLM(비전-언어 모델)을 기반으로 한 모바일 AI 에이전트가 주목받고 있으며, 이를 위해 새로운 MobileVLM을 제안했습니다. MobileVLM은 모바일 도메인에 특화된 추가 전처리 단계를 포함하여 UI 이해력 향상을 목표로 합니다.

- **Technical Details**: MobileVLM은 내부 UI 이해와 외부 UI 이해를 위한 두 가지 추가 전처리 단계를 도입하였으며, 4개의 UI 기반 사전 훈련 작업을 정의했습니다. 이를 통해 모델은 세밀한 요소 인식 및 페이지 전환 행동을 보다 잘 인지할 수 있습니다. Mobile3M이라는 대규모 데이터세트를 구축하여 이 훈련을 지원하며, 3백만 개의 UI 페이지와 실제 사용자 행동 데이터로 구성된 방향 그래프 구조를 포함하고 있습니다.

- **Performance Highlights**: 실험 결과, MobileVLM은 ScreenQA 및 다른 평가 데이터셋에서 기존의 SOTA VLM보다 각각 14.34%, 34.18% 향상된 성능을 보여주었습니다.



### MTP: A Dataset for Multi-Modal Turning Points in Casual Conversations (https://arxiv.org/abs/2409.14801)
Comments:
          Accepted by ACL 2024 main conference

- **What's New**: 본 연구는 대화 중 감정적 폭발이나 결정의 변화를 포함한 중요한 순간을 탐지하는 새로운 문제 설정을 제안합니다. 이 과정에서 고품질의 인간 주석이 포함된 멀티모달 데이터셋을 구축하였고, 각 전환점(turning points, TPs)의 정확한 타임스탬프, 설명 및 시각-텍스트 증거를 제시합니다.

- **Technical Details**: TPMaven이라는 프레임워크를 제안하며, 이는 최첨단 비전-언어 모델(vision-language models, VLMs)과 대형 언어 모델(large language models, LLMs)을 활용하여 비디오에서 내러티브를 구성하고 멀티모달 데이터셋에서 전환점을 분류 및 감지하기 위한 작업을 수행합니다. 이 연구는 Multi-modal Turning Point Classification (MTPC), Multi-modal Turning Point Detection (MTPD), Multi-modal Turning Point Reasoning (MTPR)와 같은 세 가지 작업을 통해 대화에서의 주요 전환점을 탐지합니다.

- **Performance Highlights**: TPMaven은 분류에서 0.88의 F1 점수를 달성하고, 탐지에서 0.61의 점수를 기록했습니다. 이러한 성과는 인간이 기대하는 설명과 잘 일치합니다.



### Towards Efficient and Robust VQA-NLE Data Generation with Large Vision-Language Models (https://arxiv.org/abs/2409.14785)
Comments:
          Preprint

- **What's New**: 본 연구는 대규모 비전-언어 모델(LVLMs)을 활용하여 효율적이고 고품질의 합성 VQA-NLE(비전 질문-응답 자연어 설명) 데이터셋을 생성하는 새로운 접근 방식을 제안합니다.

- **Technical Details**: LVLMs의 생성 능력을 활용하여 복잡한 인간 주석 프로세스를 대체하고, 시각적 프롬프트(visual prompts)를 포함하여 데이터 생성의 정확성을 향상시켜 고품질의 설명을 생성하는 두 가지 접근 방식을 도입합니다. 그 과정에서 데이터 triplet (질문, 답변, 설명) 생성을 위한 다양한 프롬프트 파이프라인을 사용합니다.

- **Performance Highlights**: 합성된 VQA-NLE 데이터 생성 방식이 인간 주석에 비해 최대 20배 빠르며, 데이터 품질이 거의 동일하게 유지됨을 보여줍니다. 이 연구는 시각적 프롬프트를 포함하여 텍스트 생성의 관련성을 증가시켰습니다.



### Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method (https://arxiv.org/abs/2409.14781)
Comments:
          Accepted by EMNLP 2024 main

- **What's New**: 본 논문에서는 대형 언어 모델(LLM)의 훈련 데이터 검출 문제를 해결하기 위해 새로운 접근법인 DC-PDD(Divergence Calibration for Pretraining Data Detection)를 제안합니다. 기존의 Min-K% Prob 방식은 비훈련 예제를 정확히 구분하는 데 한계가 있었으나, DC-PDD는 토큰 확률 분포와 빈도 분포의 차이를 바탕으로 더 나은 성능을 보여줍니다.

- **Technical Details**: DC-PDD는 토큰 확률 분포와 토큰 빈도 분포 간의 교차 엔트로피를 계산하여 검출 점수를 산출합니다. 이 방법은 LLM이 블랙박스로 작동하여 내부 구조에 접근하지 않고도 텍스트의 출처를 확인할 수 있습니다. 또한, PatentMIA라는 새로운 벤치마크 데이터셋을 제안하여 중국어 텍스트에 대한 LLM의 검출 성능을 평가합니다.

- **Performance Highlights**: DC-PDD는 기존의 검출 방법에 비해 성능이 크게 향상되었습니다. 예를 들어, AUC와 TPR@5%FPR 지표에서 Min-K% Prob보다 각각 8.6% 및 13.3% 더 뛰어난 성능을 기록했습니다.



### OMPar: Automatic Parallelization with AI-Driven Source-to-Source Compilation (https://arxiv.org/abs/2409.14771)
- **What's New**: 이 논문에서는 OMPar라는 AI 기반 도구를 소개하여 C/C++ 코드의 병렬화를 자동화합니다. OMPar는 Loop 병렬화 가능성을 평가하는 OMPify와 OpenMP pragmas를 생성하는 MonoCoder-OMP라는 두 가지 주요 구성 요소를 통합합니다.

- **Technical Details**: OMPar는 대형 언어 모델(LLM)을 활용한 모듈형 접근 방식을 사용하여 루프 병렬화를 위한 OMPify와 코드 생성을 위한 MonoCoder-OMP를 결합합니다. 이 논문에서는 OMPar의 정확성을 HeCBench와 ParEval 벤치마크를 사용하여 평가하고, 전통적인 도구인 ICPC 및 AutoPar와의 성능을 비교합니다. OMPar는 루프 제안의 90% 이상이 컴파일 및 기능 테스트를 통과함을 보여줍니다.

- **Performance Highlights**: OMPar는 전통적인 자동 병렬화 방법보다 뛰어난 성능을 발휘하며, 부분 코드에서도 효과적으로 작동하여 유연성과 확장성을 강조합니다. 이 연구 결과는 LLM의 자동 병렬화 기술 혁신 가능성을 보여주며, 현대 소프트웨어 시스템에서의 병렬 처리의 효율성을 제고하는 데 기여할 것입니다.



### Language-Agnostic Analysis of Speech Depression Detection (https://arxiv.org/abs/2409.14769)
- **What's New**: 본 연구는 우울 장애(Major Depressive Disorder, MDD)를 가진 사람들의 음성에서 나타나는 멜로디 변화를 분석하여, 영어와 말라얄람어 두 가지 언어에서 음성 기반 우울증 감지 시스템을 개발했습니다. 음성이 감정 상태를 나타내는 중요한 지표임을 보여주며, 언어 독립적인 음성 기반 우울증 탐지 시스템의 가능성을 제시합니다.

- **Technical Details**: Convolutional Neural Networks (CNNs)를 이용해 음성 데이터를 분석하였으며, IViE corpus에서 수집한 데이터를 바탕으로 영어와 말라얄람어에서 특징을 추출하였습니다. 132명의 참가자들이 참여하여, 각 참가자는 44개의 문장을 레코딩했습니다. 음성 데이터는 잡음 처리와 피치 변화 등의 전처리 기법을 사용하여 준비되었습니다.

- **Performance Highlights**: 모델은 50 에폭에 걸쳐 64 샘플의 배치로 훈련되어, 테스트 데이터셋에서 76%의 정확도를 달성하였습니다. 이는 음성을 통해 감정 상태를 효과적으로 분류할 수 있는 능력을 보여줍니다.



### Do Large Language Models have Problem-Solving Capability under Incomplete Information Scenarios? (https://arxiv.org/abs/2409.14762)
Comments:
          Accepted to ACL 2024 (Findings)

- **What's New**: 이 논문에서는 불완전한 정보 시나리오에서 대형 언어 모델(LLMs)의 문제 해결 능력을 평가하기 위해 BrainKing이라는 새로운 게임을 소개합니다. 이 게임은 'Who is undercover'와 'Twenty Questions'를 기반으로 하여 LLM이 제한된 예 또는 아니요 질문을 통해 목표 엔티티를 파악해야 합니다.

- **Technical Details**: BrainKing 게임은 세 가지 난이도(쉬움, 중간, 어려움)를 설정하여 LLM의 세계 지식, 역 발상 및 오류 탐지 능력을 평가합니다. 각 엔티티에 대해 최소 세 가지 개념을 포함하는 계층 개념 목록이 필요하며, LLM 참가자는 잘못된 정보 사이에서 정확한 답을 찾기 위해 최대 20개의 질문을 생성해야 합니다.

- **Performance Highlights**:  실험 결과, LLM은 BrainKing에서 불완전한 정보 시나리오에서의 정확도, 시작 난이도 및 잘못된 답변의 수가 LLM의 성능에 미치는 영향 등을 조사한 결과, LLM의 문제 해결 능력의 한계와 가능성을 확인할 수 있었습니다.



### LINKAGE: Listwise Ranking among Varied-Quality References for Non-Factoid QA Evaluation via LLMs (https://arxiv.org/abs/2409.14744)
Comments:
          Published as a conference paper at EMNLP Findings 2024

- **What's New**: 이 논문은 기존의 NFQA(비사실 질문 응답) 평가 방법의 한계를 극복하기 위해 새로운 listwise 평가 접근법인 LINKAGE를 제안합니다. 이 방법은 LLMs(대형 언어 모델)를 활용해 후보 답변을 다양한 품질의 참고 답변 목록에서 순위를 매기는 방식입니다.

- **Technical Details**: LINKAGE는 NFQA 평가에서 LLMs를 사용하여 품질이 내림차순으로 정렬된 참조 답변 목록에서 후보 답변의 순위를 매기는 접근법을 사용합니다. 또한, 다수의 금본(reference answer) 답변이 없을 때, LLMs의 컨텍스트 학습 능력을 활용하여 다양한 품질의 참조 답변 목록을 생성하여 listwise 평가를 지원합니다. 이 과정은 기존의 pointwise 및 pairwise 비교 방식보다 더 정확한 평가를 가능하게 합니다.

- **Performance Highlights**: 실험 결과, LINKAGE는 세 가지 NFQA 데이터셋(ANTIQUE, TREC DL-NF, WebGLM)에서 자동 평가 점수 및 기존의 pointwise, pairwise 방법들보다 사람의 주석과의 상관관계가 유의미하게 높았습니다. 이는 NFQA 성능 개선을 위한 기반을 제공할 수 있습니다.



### ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information (https://arxiv.org/abs/2409.14740)
- **What's New**: 이번 논문에서는 Toxicraft라는 새로운 프레임워크를 제안하여 유해한 콘텐츠를 식별하는 데 있어 데이터 부족 문제와 일관되지 않은 정의의 문제를 해결하고자 합니다.

- **Technical Details**: Toxicraft는 적은 양의 seed data를 사용하여 다양한 합성(synthetic) 유해 정보 예시를 생성할 수 있는 프레임워크입니다. 이 프레임워크는 독특하면서도 매우 현실적인 예시를 만들어내며, 이를 통해 분류 모델을 강화합니다.

- **Performance Highlights**: 여러 데이터셋을 통해 이루어진 실험에서 탐지 모델의 강건성(robustness)과 적응성(adaptability)이 향상된 것을 보여주며, gold labels에 근접하거나 이를 초월하는 성능을 기록했습니다.



### ERABAL: Enhancing Role-Playing Agents through Boundary-Aware Learning (https://arxiv.org/abs/2409.14710)
Comments:
          arXiv admin note: substantial text overlap with arXiv:2402.10618

- **What's New**: 새로운 연구에서 제안된 ERABAL 프레임워크는 역할을 맡은 언어 모델의 역할 연기 능력을 향상시키기 위한 경계 인식 학습(boundary-aware learning) 방법론을 소개합니다. 이는 역할 특화 대화 생성 파이프라인과 정렬 훈련 방법론을 포함합니다.

- **Technical Details**: ERABAL은 네 개의 모듈로 구성된 자동화된 데이터 생성 파이프라인을 도입하여 경계 인식 대화를 생성합니다. 이 모듈들은 대화 기획자(dialogue planner), 주제 관리자(topic manager), 경계 질의 생성기(boundary query generator), 응답 생성기(response generator)로 이루어져 있으며, 역할 속성에 기반한 특정 질문-응답 쌍을 생성합니다. 또, 경계 인식 선호 최적화(Boundary-aware preference optimization, BPO) 방법이 포함되어 있어 정교한 학습이 가능합니다.

- **Performance Highlights**: ERABAL은 일반적인 모델들과 비교하여 역할 일관성 평가에서 가장 우수한 성능을 보였습니다. 기존 역할 연기 벤치마크에 대한 실험을 통해, ERABAL은 10%의 훈련 대화만으로도 일반적 기준선 모델들에 비해 상당한 성능 향상을 이루어냈으며, WikiRoleEval, CharacterEval, MT-Bench 등에서 뛰어난 결과를 기록하였습니다.



### Target-Aware Language Modeling via Granular Data Sampling (https://arxiv.org/abs/2409.14705)
Comments:
          Accepted to EMNLP 2024 Main Conference, 9 pages, 6 figures, 3 tables

- **What's New**: 이 논문은 특정 도메인에서의 성능을 유지하면서도 데이터 샘플링의 최적화를 통해 언어 모델(ML) 사전 훈련의 효율성을 높이기 위한 새로운 접근 방식을 제안합니다. 특히, n-gram 기법을 활용하여 다중 그레인(멀티-그레인) 토큰으로 특징을 구성하는 중요 샘플링을 다시 다루고 있습니다.

- **Technical Details**: 저자들은 n-gram 토큰을 활용한 중요 샘플링 기법을 통해 데이터 선택성을 극대화하며, 이는 복잡한 모델이 아닌, 사전 훈련된 간단한 코어셋을 보여줍니다. 또한 다중 그레인 특성을 사용하는 새로운 알고리즘이 제안되었으며, 이를 통해 작업 지향적인 데이터 샘플링이 이루어지고 있습니다.

- **Performance Highlights**: 총 1%의 데이터로 학습된 모델이 전체 RefinedWeb 데이터에 맞먹는 성능을 발휘하는 결과를 보여주며, 랜덤 샘플링보다 뛰어난 성능을 나타냅니다. 다양한 모델 크기(125M부터 1.5B까지)에서 이과 같은 우수한 성능이 확인되었습니다.



### Instruction Tuning Vs. In-Context Learning: Revisiting Large Language Models in Few-Shot Computational Social Scienc (https://arxiv.org/abs/2409.14673)
- **What's New**: 본 논문에서는 대규모 언어 모델(LLM)의 Instruction Tuning (IT)과 In-Context Learning (ICL)의 분류 성능을 비교하며, 실제적인 계산 사회과학(CSS) 작업에서의 중요성을 강조합니다. ICL이 대부분의 CSS 작업에서 IT보다 효과적이라는 실험 결과를 도출했습니다.

- **Technical Details**: 연구에서는 ICL과 IT를 사용하여 1-, 8-, 16-, 32-shot 설정에서 6개의 오픈 소스 LLM을 평가합니다. IT는 지도 방식으로 LLM의 파라미터를 업데이트하고, ICL은 특정 작업의 프롬프트(conditioning)를 이용하여 모델 가중치 업데이트 없이 작업을 수행하도록 합니다. 결과적으로 ICL이 IT보다 우수한 성능을 발휘할 뿐만 아니라, 샘플 수의 증가가 성능에 미치는 영향을 조사합니다.

- **Performance Highlights**: ICL은 5개의 CSS 작업에서 IT보다 평균적으로 더 높은 성능을 기록했습니다. 샘플 수를 단순히 증가시키는 것은 ICL이나 IT의 성능을 일관되게 향상시키지 못하며, 때때로 성능 저하를 초래할 수 있습니다. 또한, ICL 프롬프트가 제로샷(zero-shot) 및 Chain-of-Thought (CoT) 프롬프트보다 더 효과적임을 확인했습니다.



### Direct Judgement Preference Optimization (https://arxiv.org/abs/2409.14664)
Comments:
          Preprint

- **What's New**: 이번 연구에서는 언어 모델을 평가하기 위한 새로운 접근 방식인 preference optimization을 통해 긍정적 및 부정적 데이터를 학습하는 방법을 제시합니다.

- **Technical Details**: 우리는 세 가지 접근 방식을 사용하여 다양한 용도에 맞는 preference pairs를 수집하고, 이러한 방식을 통해 생성적 평가 모델(generative judge)의 평가 능력을 향상시킵니다. 본 연구는 다양한 벤치마크에서 종합적인 연구를 통해 방법의 효과성을 입증합니다.

- **Performance Highlights**: 우리의 생성적 평가 모델은 13개 벤치마크 중 10개에서 최고 성능을 달성하였으며, GPT-4o 및 특화된 평가 모델과 같은 강력한 기준을 초월한 결과를 보여줍니다. 추가 분석 결과, 우리 모델은 내재된 편향(예: 위치 편향, 길이 편향)을 잘 극복하고, 평가 프로토콜에 유연하게 적응하며, 다운스트림 생성 모델의 개선을 위한 유용한 언어 피드백을 제공합니다.



### Building Tamil Treebanks (https://arxiv.org/abs/2409.14657)
Comments:
          10 pages

- **What's New**: 이번 논문에서는 타밀어 트리뱅크(Tamil treebanks)의 생성 방법을 세 가지 접근 방식을 통해 논의하고 있습니다: 수동 주석(manual annotation), 계산 문법(computational grammars), 그리고 기계 학습(machine learning) 기법입니다.

- **Technical Details**: 수동 주석은 높은 품질과 풍부한 구문 및 의미 정보를 보장하지만 시간이 많이 소요되고 언어학적 전문 지식이 필요합니다. Lexical Functional Grammar (LFG)와 같은 계산 심층 문법은 깊이 있는 언어 분석을 제공하지만 공식에 대한 상당한 지식이 요구됩니다. 기계 학습 접근 방식은 Stanza, UDpipe, UUParser와 같은 도구를 활용하여 대규모 데이터셋의 자동 주석을 가능하게 하지만, 품질이 높은 주석 데이터와 교차 언어 훈련 자료, 컴퓨팅 파워의 가용성에 의존합니다.

- **Performance Highlights**: 논문에서는 인터넷 데이터를 사용하는 것, 종합적인 언어 분석의 필요성, 숙련된 주석가를 찾는 어려움 등 타밀어 트리뱅크 구축 중 경험한 도전 과제를 다루고 있습니다. 이러한 도전에도 불구하고 타밀어 트리뱅크의 개발은 언어학 연구 진전 및 타밀어를 위한 NLP 도구 개선에 필수적입니다.



### Harmonising the Clinical Melody: Tuning Large Language Models for Hospital Course Summarisation in Clinical Coding (https://arxiv.org/abs/2409.14638)
Comments:
          20 pages, 4 figures

- **What's New**: 이번 연구에서는 병원 경과 요약(hospital course summarisation) 작업을 위해 Llama 3, BioMistral, Mistral Instruct v0.1의 세 가지 사전 훈련된 LLMs(large language models)를 조정했습니다.

- **Technical Details**: Quantized Low Rank Adaptation fine tuning 기법을 사용하여 MIMIC III 데이터셋에서 다양한 임상 노트를 결합하여 입력 임상 텍스트 형태의 자유 텍스트 임상 데이터셋을 생성했습니다. 모델 훈련을 위해 퇴원 요약(discharge summaries)에서 추출한 실제 Brief Hospital Course 섹션과 짝지었습니다. 모델의 효과성을 평가하기 위해 BERTScore와 ROUGE 메트릭스를 사용했습니다.

- **Performance Highlights**: 임상 도메인에 맞게 fine tuning된 LLM들이 병원 경과 요약 작업에서 성능을 크게 향상시켰으며, 임상 코딩을 위한 보조 도구로서의 잠재력을 시사했습니다. 향후 연구는 병원 경과 요약 작업에 적합한 데이터 커레이션(data curation) 방법을 개선하고, 독점 모델에 필적하는 더 발전된 오픈소스 LLM을 조정하는 데 초점을 맞춰야 합니다.



### Can a Neural Model Guide Fieldwork? A Case Study on Morphological Inflection (https://arxiv.org/abs/2409.14628)
- **What's New**: 이 논문에서는 언어학자와 화자 간의 상호작용을 고려한 새로운 모델을 제시하여 언어 데이터 수집 (data collection) 과정의 효율성을 높이고자 하였습니다. 특히, 기존 접근 방식과의 차별점을 두어, 상호작용의 두 가지 '원자적' 사례, 즉 언어학자가 화자를 만족시키는 정확한 추측을 하거나 더 많은 정보를 요청하는 경우를 명확히 구분하여 제안하였습니다.

- **Technical Details**: 제안된 모델은 필드워크 (fieldwork)에서 수집된 이전 데이터를 바탕으로 불완전한 데이터의 잠재적 격차를 식별하고, 다음 반복에서 수집해야 하는 정보의 우선순위를 설정합니다. 또한, 다양한 샘플링 전략의 효율성을 평가하고, 최신 신경 모델의 형태소 구조 일반화 (generalisation) 능력을 test합니다. 특히, morphology 데이터를 수집할 때의 대칭성을 활용하여 active learning (AL) 이론을 적용했습니다.

- **Performance Highlights**: 실험 결과, 주목할 만한 두 가지 전략이 언어 데이터 수집의 효율성을 개선하는 데 기여했습니다: (1) 패러다임 테이블의 셀을 균일하게 샘플링하여 주석 데이터의 다양성을 증가시킬 것과 (2) 모델 신뢰도를 사용하여 긍정적인 상호작용을 강화하고 데이터의 신뢰성 있는 예측을 제공하는 것입니다.



### Can pre-trained language models generate titles for research papers? (https://arxiv.org/abs/2409.14602)
- **What's New**: 이 연구에서는 연구 논문의 초록으로부터 제목을 자동 생성하기 위해 사전 훈련된 대형 언어 모델을 미세 조정하는 방법을 제안합니다. 특히, T5-base, BART-base, PEGASUS-large 모델을 서브셋 LREC-COLING-2024 데이터셋을 이용하여 훈련시켰습니다. 또한, ChatGPT-3.5를 제로샷(zero-shot) 설정에서 사용하여 초기 제목을 생성해보았습니다.

- **Technical Details**: 이 연구에서 활용된 핵심 기술은 딥 뉴럴 모델(deep neural models)로, 여러 사전 훈련된 트랜스포머 모델을 미세 조정하여 논문 제목을 생성하는 데 중점을 두었습니다. 이는 'abstractive text summarization'의 특별한 경우로 볼 수 있으며, 주요 평가 지표로는 ROUGE, METEOR, MoverScore, BERTScore 및 SciBERTScore가 사용되었습니다. 연구팀은 LREC-COLING-2024라는 새로운 데이터셋을 수집하였고, 이 데이터셋은 논문의 초록과 제목의 쌍을 포함하고 있습니다.

- **Performance Highlights**: PEGASUS-large 모델이 선택된 메트릭에서 다른 모델들보다 뛰어난 성능을 보여주었습니다. 특히, PEGASUS-large는 LLM(GPT-3.5, LLaMA)들에 비해 파라미터 수가 적음에도 불구하고 우수한 성능을 발휘했습니다. 연구에서는 또한 사용자에게 다양한 언어 모델을 선택할 수 있는 데모를 제공하였으며, Hugging Face에 미세 조정된 모델과 LREC-COLING-2024 데이터셋을 공개했습니다.



### EchoAtt: Attend, Copy, then Adjust for More Efficient Large Language Models (https://arxiv.org/abs/2409.14595)
- **What's New**: 본 논문에서는 내/외부 레이어 간의 유사한 attention 패턴을 분석하고 이를 활용하여 transformer 기반 모델의 효율성을 극대화하는 EchoAtt라는 새로운 프레임워크를 소개합니다. 이 방법은 LLMs에서 내 연결 레이어 간의 유사성을 활용하여 주의 매트릭스를 공유함으로써 계산 비용을 크게 줄이는 것을 목표로 합니다.

- **Technical Details**: EchoAtt는 지식 증류(knowledge distillation) 설정 내에서 작동하며, 사전 훈련된 teacher 모델이 계산 자원을 효율적으로 사용하는 동시에 모델 성능을 유지하도록 하는 student 모델의 훈련을 유도합니다. 특정 레이어 간 유사한 attention 매트릭스를 선택적으로 공유하여 모델의 복잡성과 필요 자원을 줄입니다.

- **Performance Highlights**: TinyLLaMA-1.1B 모델을 사용한 결과, EchoAtt는 추론 속도를 15% 증가시키고, 훈련 속도를 25% 향상시킴과 동시에 약 4%의 파라미터 수를 줄이는 성과를 나타냈습니다. 이러한 Compression이 이루어짐에도 불구하고 zero-shot 성능은 유지되었습니다.



### The X Types -- Mapping the Semantics of the Twitter Spher (https://arxiv.org/abs/2409.14584)
Comments:
          23 pages

- **What's New**: 본 연구는 약 200,000개의 인기 Twitter 계정을 포함하는 소셜 KB(Social Knowledge Base)를 구축하여, 그 계정에 대한 의미적 정보를 추출하고자 하였습니다. 특히, 이를 136개의 세부 의미 유형으로 구분하여, 각 계정이 정치인, 음악 아티스트 등 어떤 성격을 가지는지를 판별할 수 있는 모델을 개발하였습니다.

- **Technical Details**: 이 연구에서 우리는 Twitter의 대중 계정에 대한 의미적 유형 추정을 위해 DBpedia 및 Wikidata와의 매핑을 통해 레이블이 붙은 데이터를 생성하였습니다. 이 데이터를 이용하여 transformer 기반의 BERT 모델을 미세 조정(finetune)하고, 이를 활용하여 계정의 내용 기반으로 의미적 임베딩(embedding)을 생성하였습니다.

- **Performance Highlights**: 우리의 실험 결과, 레이블이 붙은 데이터셋에서 높은 예측 성능을 보였으며, 이 모델을 통해 Twitter의 모든 엔티티 계정에 대해 의미적 유형 예측을 수행했습니다. 이 정보는 사회적 엔티티의 유사성을 평가하는 주요 작업에서도 성능 향상을 가져오는 것으로 나타났습니다.



### Medical Concept Normalization in a Low-Resource Setting (https://arxiv.org/abs/2409.14579)
Comments:
          Master Thesis

- **What's New**: 이 논문에서는 생물의학 자연어 처리 분야에서의 의료 개념 정규화(Medical Concept Normalization)의 도전 과제를 다루고 있으며, 특히 독일어 비전문 텍스트에서의 한계에 대해 탐구합니다.

- **Technical Details**: 논문에서는 Unified Medical Language System으로 개념이 주석 처리된 독일 의료 온라인 포럼의 포스트로 구성된 데이터셋을 사용하여 실험을 진행했습니다. 다국어 Transformer 기반 모델들이 문자열 유사성 방법보다 우수한 성능을 보이는 결과를 나타냈습니다. 또한, 비전문 언급(normalization of lay mentions)을 개선하기 위한 맥락 정보의 활용도 실험했지만, 기대 이하의 결과를 초래했습니다.

- **Performance Highlights**: 최고 성능 모델의 결과를 기반으로 한 체계적인 오류 분석을 제시하고 있으며, 빈번한 오류를 완화하기 위한 잠재적인 개선 방안을 논의합니다.



### Evaluating the Performance and Robustness of LLMs in Materials Science Q&A and Property Predictions (https://arxiv.org/abs/2409.14572)
- **What's New**: 본 연구는 소재 과학 분야에서의 Large Language Models (LLMs)의 견고성과 신뢰성에 대한 포괄적인 평가와 분석을 수행합니다. 학부 소재 과학 강의에서의 객관식 질문 세트, 다양한 강재 조성과 항복 강도 데이터셋, 그리고 밴드 갭 값이 포함된 데이터셋 등 세 가지 독특한 데이터셋을 사용하여 도메인 특화된 Q&A와 소재 속성 예측을 분석합니다.

- **Technical Details**: 연구에서는 zero-shot chain-of-thought, expert prompting, few-shot in-context learning (ICL) 등의 다양한 프롬프트 전략을 사용하여 LLMs의 성능을 평가하였습니다. 또한, 텍스트 순서 변경과 같은 텍스트 섭동이 LLM의 추론에 미치는 영향을 조사하며, 현실적인 섭동부터 적대적 섭동까지 다양한 유형의 섭동을 테스트하였습니다. 밴드 갭 예측에 대한 세부 조사를 통해 일부 상황에서는 섭동이 모델의 예측 능력을 향상시키는 경향이 나타났습니다.

- **Performance Highlights**: LLMs의 성능 평가는 MSE-MCQs 데이터셋에서 수행되었고, gpt-4-0613이 모든 카테고리에서 가장 높은 점수를 기록했습니다. 또한, 전통적인 랜덤 포레스트 회귀 모델과 비교하여, gpt-3.5-turbo-0613이 few-shot ICL을 활용하여 강재 항복 강도 예측에서 유사한 성능을 보여주었습니다. 이 연구는 소재 과학 분야에서 LLMs의 신뢰성 있는 사용에 대한 정보에 기반한 회의적인 시각을 제시하고, 이를 통한 견고성과 신뢰성 향상을 위한 발전을 촉진하고자 합니다.



### Unleashing the Power of Emojis in Texts via Self-supervised Graph Pre-Training (https://arxiv.org/abs/2409.14552)
Comments:
          Accepted by EMNLP 2024 Main Conference

- **What's New**: 이 논문에서는 이모티콘과 텍스트 간의 관계를 개선하기 위해 포스트, 단어, 이모티콘으로 구성된 이종 그래프(heterogeneous graph)를 구축했습니다. 또한, 텍스트와 이모티콘의 공동 모델링을 위한 그래프 프리트레인 프레임워크(graph pre-train framework)를 제안하며, 이를 통해 텍스트와 이모티콘 사이의 상호작용을 더 잘 이해할 수 있도록 합니다.

- **Technical Details**: 제안된 프레임워크는 두 가지 자가 지도 그래프 사전 훈련 작업(self-supervised graph pre-training tasks)을 포함합니다: 1) 노드 수준 그래프 대비 학습(node-level graph contrastive learning), 2) 엣지 수준 링크 재구성 학습(edge-level link reconstruction learning). 이 방식을 통해 포스트, 이모티콘, 단어 간의 상호작용을 모델링하고, 이를 다양한 다운스트림 작업에서 활용 가능합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 Xiaohongshu 및 Twitter 데이터셋에서 다양한 다운스트림 작업(예: 인기 예측 및 감정 예측)에 대해 이전의 강력한 기준 모델보다 2%에서 10% 더 나은 성능을 보였습니다. 이 모델은 추가적으로 이모티콘 생성 작업에도 활용할 수 있습니다.



### Can AI writing be salvaged? Mitigating Idiosyncrasies and Improving Human-AI Alignment in the Writing Process through Edits (https://arxiv.org/abs/2409.14509)
Comments:
          NLP+HCI, Behavioral Science

- **What's New**: 이번 연구는 LLM(대형 언어 모델) 기반의 텍스트 생성이 인간의 글쓰기와 어떻게 다른지를 탐구하며, 전문가들이 LLM 생성 텍스트의 문제점을 수정하는 과정을 중심으로 진행되었습니다.

- **Technical Details**: 연구진은 LLM에 의해 생성된 텍스트의 단점을 일곱 가지 범주로 정리한 편집 분류법을 제안하였으며, 18명의 전문가 작가가 LLM 생성 문단을 편집하여 LAMP(Language model Authored, Manually Polished) 데이터셋을 구축했습니다. 이 데이터셋은 1,057개의 LLM 생성 문단으로 구성되어 있습니다.

- **Performance Highlights**:  LLM 모델(GPT4o, Claude-3.5-Sonnet, Llama-3.1-70b) 간의 글쓰기 질은 차이가 없음을 발견했으며, 전문가들에 의한 편집이 LLM 문서의 질을 개선하는 데 효과적임을 확인했습니다. 자동 편집 방법은 LLM 생성 텍스트와 인간 작성 텍스트 간의 정렬을 개선하는 데 유망한 성과를 보였습니다.



### A is for Absorption: Studying Feature Splitting and Absorption in Sparse Autoencoders (https://arxiv.org/abs/2409.14507)
- **What's New**: 이번 연구에서는 Sparse Autoencoders (SAEs)를 활용하여 대형 언어 모델(LLMs)의 활성화를 인간이 해석할 수 있는 잠재 공간으로 분해하는 새로운 접근 방식에 대해 다룹니다. 특히, SAEs가 명확한 의미를 지닌 잠재 요소를 추출할 수 있는 정도와 sparsity 또는 SAE의 크기 변화가 명확한 의미성 및 해석 가능성에 미치는 영향을 탐구하였습니다.

- **Technical Details**: 연구는 첫 번째 문자 식별 작업을 통해 진행되었으며, 토큰에 대한 진리 레이블을 완전히 사용할 수 있는 환경에서 실험되었습니다. 이 과정에서 우리는 ‘feature absorption’이라 부르는 문제적 형태의 기능 분할을 확인하였고, 이는 잠재 요소가 인간이 해석할 수 있는 개념을 추적하는 것처럼 보이지만, 특정 토큰에서 예상대로 활성화되지 않는 현상입니다. 또한, SAE의 크기 및 sparsity를 변화시키는 것이 이 문제를 해결하기에 불충분하다는 점을 밝혔습니다.

- **Performance Highlights**: 실험 결과, 처음 문자 분류 작업에서 SAE latents의 정밀도 및 재현율이 선형 프로브보다 상당히 저조하다는 것을 발견하였습니다. 또한, 동일한 기능을 분류하는 것처럼 보이는 latents 간에 정밀도 및 재현율에 큰 차이가 존재하며, 이는 주로 sparsity와 SAE의 폭에 의해 매개된다는 것을 확인했습니다. 우리가 확인한 ‘feature absorption’ 현상은 SAE를 실제 애플리케이션에 활용하는 데 장애가 될 수 있으며, 이러한 잠재 요소들이 신뢰할 수 없는 분류기일 수 있음을 시사합니다.



### Thought-Path Contrastive Learning via Premise-Oriented Data Augmentation for Logical Reading Comprehension (https://arxiv.org/abs/2409.14495)
- **What's New**: 이번 논문에서는 Premise-Oriented Data Augmentation (PODA) 프레임워크를 제안하여 Chain-of-Thought (CoT) 합리화를 통해 올바른 답변 뿐만 아니라 잘못된 선택지에 대한 분석을 포함하고, 잘못된 후보 옵션으로부터 다양한 고품질의 반사실적 데이터(countersfactual context)를 자동으로 구축합니다.

- **Technical Details**: PODA는 올바른 및 잘못된 선택지에 대한 분석을 포함한 CoT 합리화를 생성하며, 각 선택지에 대한 요약 및 식별을 통해 반사실적 맥락을 구축합니다. Thought-Path Contrastive Learning (TPCL) 방법은 원본 및 반사실적 샘플 간의 사고 경로(thought-path)를 비교하여 모델의 논리적 추론 능력을 향상시키게 합니다. 구체적으로, 관계는 지지, 모순, 무관으로 분류되며, 이를 통해 다양한 반사실적 샘플을 생성합니다.

- **Performance Highlights**: 세 가지 대표적인 LLM(대형 언어 모델) 테스트에서 제안된 PODA와 TPCL 방법은 두 가지 논리적 MRC 벤치마크(ReClor 및 LogiQA 2.0)에서 기초 성능을 상당히 개선한 결과를 보여주었습니다.



### CPT-Boosted Wav2vec2.0: Towards Noise Robust Speech Recognition for Classroom Environments (https://arxiv.org/abs/2409.14494)
Comments:
          arXiv admin note: substantial text overlap with arXiv:2405.13018

- **What's New**: 본 연구에서는 Wav2vec2.0을 교실 환경에 적합하도록 조정하기 위해 Continued Pretraining (CPT)의 효과를 분석하고, Wav2vec2.0 기반 모델의 Word Error Rate (WER)를 10% 이상 감소시킬 수 있음을 보여줍니다. 또한, CPT는 다양한 소음과 마이크, 그리고 교실 환경에 대한 모델의 강건성을 향상시키는 데 중요합니다.

- **Technical Details**: Wav2vec2.0은 Self-Supervised Learning (SSL) 기법을 사용하는 음성 표현 모델로, 비지도 학습된 데이터를 통해 언어 모델을 사전 학습한 후, 소규모 레이블 데이터로 파인튜닝(finetuning)합니다. CPT는 이미 사전 학습된 모델에 대해 추가적인 비지도 사전 학습을 수행하는 과정을 의미합니다. 본 연구는 CPT를 통해 교실의 noisy speech 인식에 적합하도록 Wav2vec2.0을 적응시키는 방법을 제안합니다.

- **Performance Highlights**: CPT를 통해 Wav2vec2.0은 다양한 소음 조건에 강건해지며, 기존의 최첨단(State Of The Art, SOTA) ASR 모델보다 소음에 강한 성능을 보여줍니다. 연구 결과, CPT를 사용한 모델은 다양한 마이크 구성과 인구통계적 요소에 대한 강건성을 향상시키는 것으로 나타났습니다.



### Rethinking Semantic Parsing for Large Language Models: Enhancing LLM Performance with Semantic Hints (https://arxiv.org/abs/2409.14469)
Comments:
          Work in progress

- **What's New**: 이 논문은 LLMs (Large Language Models)에서의 시맨틱 파싱 (semantic parsing)의 효과를 조사하며, SENSE라는 새로운 프롬프트 접근 방식을 제안합니다. 기존의 방법과 달리, SENSE는 명시적인 파싱 결과를 주입하는 대신 시맨틱 힌트를 프롬프트에 포함시킵니다.

- **Technical Details**: SENSE는 LLMs가 내부의 시맨틱 파싱 능력을 활용하도록 유도하는 простратегия를 제공합니다. 연구에서는 GLUE (General Language Understanding Evaluation) 벤치마크의 여러 이해 과제와 기계 번역, 패러프레이징 및 단순화와 같은 생성 작업을 포함해 10가지 다양한 태스크에서 SENSE의 성능을 평가했습니다.

- **Performance Highlights**: SENSE는 GPT-4o-mini의 평균 성능을 79.43%에서 81.25%로 향상시켜 BERT의 83.2%에 매우 근접하게 개선했습니다. 또한 MRPC 및 MNLI와 같은 특정 태스크에서 유의미한 향상을 보여 주어, LLMs의 입력 문장 이해력을 강화하는 데 효과적임을 입증하였습니다.



### AggregHate: An Efficient Aggregative Approach for the Detection of Hatemongers on Social Platforms (https://arxiv.org/abs/2409.14464)
- **What's New**: 이 논문은 온라인 혐오 발언 감지의 새로운 접근 방식으로 사용자의 활동과 사용자 네트워크를 고려한 다중 모달(멀티모달) 집계 방식을 제안합니다. 이는 혐오 발언을 감지하기 위해 단순한 텍스트 기반 방법을 넘어서는 것입니다.

- **Technical Details**: 연구에서는 트위터(Twitter), 갭(Gab), 파를러(Parler)의 세 가지 고유 데이터 세트를 활용하여 사용자 레벨에서의 혐오 발언 탐지 기법을 평가하였으며, 다중 모달 집계 접근 방식과 관련된 세 가지 기본적 접근법을 탐구합니다: (i) 고정 임계값을 가진 이진 가중치 사용, (ii) 사회적 맥락에 조건화된 관계적 집계, (iii) 집계된 신뢰도 수준에 조건화된 분산 집계.

- **Performance Highlights**: 상대적으로 대규모 데이터 세트에서도 효율적이며, 사용자 레벨의 컨텍스트 정보를 종합적으로 고려함으로써 기존의 텍스트 및 그래프 기반 방법과 비교하여 혐오 발언 감지를 크게 개선할 수 있음을 보여줍니다.



### Exploring Multilingual Probing in Large Language Models: A Cross-Language Analysis (https://arxiv.org/abs/2409.14459)
- **What's New**: 이번 연구에서는 대형 언어 모델(LLMs)의 probing 기술을 다국어 환경으로 확장하여 다양한 언어에 대한 모델의 행동을 조사했습니다. 이는 대부분 영문 데이터에 초점을 맞추었으나 이제는 16개 언어에서 고급 언어와 저급 언어 간의 성능 차이를 분석합니다.

- **Technical Details**: 우리는 decoder-only LLMs를 사용하여 각 모델의 여러 레이어에서 hidden states를 추출하고 linear classifier probing을 통해 정보 인코딩 방식을 연구했습니다. 적용된 probing 기법은 다국어 컨텍스트에서 LLM의 사실적 지식 및 감성 분류 작업 수행 능력을 평가하는 데 중점을 두었습니다.

- **Performance Highlights**: 주요 발견으로는 고급 언어는 저급 언어에 비해 consistently higher probing accuracy를 나타내며, 고급 언어는 모델의 깊은 레이어에서 유의미한 정확도 향상을 보이는 반면, 저급 언어는 상대적으로 안정적인 성능을 유지했습니다. 또한, 고급 언어 간 probing vector의 유사성은 높은 반면, 저급 언어는 서로 및 고급 언어와의 유사성이 낮다는 점이 발견되었습니다.



### Automotive innovation landscaping using LLM (https://arxiv.org/abs/2409.14436)
Comments:
          9pages, 4Figures, 1 Flow chart

- **What's New**: 본 연구는 Prompt Engineering을 기반으로 한 특허 정보 추출 방법을 소개하며, 이 방법은 자동차 혁신의 경관을 조성하는 데 중요한 역할을 합니다. 기존의 수작업을 통한 방식에서 벗어나, 대형 언어 모델을 활용하여 보다 빠르고 효율적인 특허 분류 및 아이디어 추출을 가능하게 합니다.

- **Technical Details**: Prompt Engineering은 LLM(대형 언어 모델)과의 상호작용을 최적화하며, BERT와 같은 모델을 통해 여러 NLP(자연어 처리) 작업을 지원합니다. 이 연구에서는 OpenAI를 이용하여 TRIZ(Theory of Inventive Problem Solving) 모순을 추출하고, Transformer 기반 LLM을 활용해 특허에서 기술적 문제, 해결책, 이점 등을 식별하는 방법론을 다룹니다.

- **Performance Highlights**: 이 연구의 결과는 열린 특허 데이터셋을 사용하여 연료 전지 기술의 경관을 구성하는 방법을 보여줍니다. 이는 특허 문서의 복잡한 가독성 문제를 해결하고, 보다 빠르고 효율적인 정보 추출을 가능하게 하여 R&D 팀에 귀중한 통찰력을 제공합니다.



### Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations (https://arxiv.org/abs/2409.14399)
Comments:
          Findings of EMNLP 2024

- **What's New**: 본 논문에서는 CRS(Conversational Recommender System)의 설명에서 신뢰성을 높이기 위한 새로운 접근법인 PC-CRS를 제시합니다. 이는 사용자의 수용력을 높이고 장기적인 신뢰를 구축하는 것을 목표로 합니다.

- **Technical Details**: PC-CRS는 전략 기반 설명 생성(Strategy-guided Explanation Generation)과 반복적인 설명 정제(Iterative Explanation Refinement)의 두 단계로 구성됩니다. 이는 Credibility-aware Persuasive Strategies를 활용하여 신뢰성 있는 정보를 포함한 설명을 생성하고, 이후 후보 설명을 수정하여 잘못된 정보를 제거합니다.

- **Performance Highlights**: 실험 결과에 따르면, PC-CRS는 기존 최적 기준선에 비해 평균 8.17%의 신뢰성 점수 향상과 5.07%의 설득력 점수 향상을 달성하였습니다. 신뢰성 있는 설명이 추천의 정확도를 개선하는데 기여한다는 추가 분석도 포함되어 있습니다.



### Predicting User Stances from Target-Agnostic Information using Large Language Models (https://arxiv.org/abs/2409.14395)
- **What's New**: 이 연구에서는 사용자의 대립 견해를 예측하는 방법으로 대규모 언어 모델(Large Language Models, LLMs)을 활용하는 가능성을 조사하고, 기존의 전통적인 기계 학습 모델보다 LLM이 더 효과적임을 보여주고 있습니다. 특히, LLM이 대상 관련이 없는(target-agnostic) 게시물로부터 안정적인 사용자 수준의 태도를 예측할 수 있다는 초기 증거를 제시했습니다.

- **Technical Details**: 연구는 1,000명의 Twitter 사용자로부터 수집된 Connected Behaviour (CB) 데이터셋을 사용하였으며, 이 데이터셋은 대상에 관계 없이 작성된 게시물과 특정 대상에 대한 게시물을 모두 포함합니다. 사용자 수준의 태도 예측(user-level stance prediction)이라는 새로운 작업을 정의하고, 사용자의 게시물이 특정 대상에 대한 언급이 없더라도 LLM을 통해 효과적으로 예측할 수 있다는 것을 입증하려고 하였습니다.

- **Performance Highlights**: LLM을 사용한 태도 예측은 초기에는 성능이 다소 낮을 수 있으나, 입력되는 대상 관련 없는 게시물이 증가함에 따라 성능이 급속도로 개선된다는 점이 관찰되었습니다. LLM은 대상 관련 데이터가 부족한 상황에서도 대중의 의견을 예측할 수 있는 유용한 방법임을 제시하며, 추가 연구를 통해 LLM의 성능과 효과를 향상시켜야 한다고 강조하고 있습니다.



### Investigating Layer Importance in Large Language Models (https://arxiv.org/abs/2409.14381)
- **What's New**: 이번 연구에서는 LLM(대규모 언어 모델)의 개별 레이어의 중요성을 조사하여 이러한 모델의 이해를 심화시킵니다. 이를 위해 Shapley values라는 설명 기법을 활용하여 레이어의 중요성을 신뢰성 있게 평가하는 효율적인 샘플링 방법을 제안하였습니다.

- **Technical Details**: 연구에서는 Shapley value 프레임워크를 확장하여 LLM의 레이어에 대한 기여도를 정량화하였습니다. 또한, 레이어 절제(layer ablation) 실험을 통해 특정 레이어의 성능 저하를 평가하여, 초기 레이어 중 일부가 모델 성능에 미치는 중요한 역할을 탐구하였습니다.

- **Performance Highlights**: Cornerstone layer(주요 레이어)의 제거가 모델 성능의 급격한 하락으로 이어지는 반면, 비가건물 레이어의 제거는 성능에 미미한 변화를 주는 것으로 나타났습니다. 이 연구는 LLM에서 주요 레이어의 존재를 식별하고, 향후 연구에서 이들의 중요성을 강조합니다.



### J2N -- Nominal Adjective Identification and its Application (https://arxiv.org/abs/2409.14374)
Comments:
          7 pages, 4 figures

- **What's New**: 이 연구는 자연어 처리(NLP)에서 명사형 형용사(nominal adjectives, NAs)의 태깅 문제를 해결하기 위해 이들을 'JN'이라는 새로운 품사 태그로 분류하는 방안을 제안합니다. 이는 명사형 형용사를 명확히 식별하고 NLP 성능을 향상시킬 수 있는 가능성을 모색하는 것입니다.

- **Technical Details**: 연구에서는 Hidden Markov Models (HMMs), Maximum Entropy (MaxEnt) 모델 및 Spacy를 사용하여 명사형 형용사의 태깅 방법을 실험하였습니다. 명사형 형용사를 포함한 태깅의 직접적인 영향을 분석하고, BERT 모델을 통해 태그가 없는 텍스트에서도 명사형 형용사를 식별할 수 있도록 훈련하였습니다.

- **Performance Highlights**: 실험 결과, 명사형 형용사(JN)를 사용할 경우 전통적인 품사 태깅 모델에 비해 구문 분석(syntactic analysis) 및 구조적 이해(structural understanding)의 정확도가 개선됨을 보였습니다. 이는 NLP 시스템의 성능을 극대화하고 컴퓨터에서의 영어 문법 이해를 보다 세밀하게 할 수 있는 가능성을 제시합니다.



### The Ability of Large Language Models to Evaluate Constraint-satisfaction in Agent Responses to Open-ended Requests (https://arxiv.org/abs/2409.14371)
- **What's New**: 본 논문에서는 Generative AI 에이전트가 No One Right Answer (NORA) 요청에 대응할 수 있는 능력에 대해 다루고 있습니다. 특히, 입력된 요청의 제약 조건을 자동으로 평가할 수 있는 프레임워크의 필요성을 강조하며, 이를 위해 Arithmetic Constraint-Satisfaction (ACS) 데이터셋을 개발하고 공개합니다.

- **Technical Details**: ACS 데이터셋은 복잡한 사용자 요청과 해당 제약 조건, 에이전트의 응답, 제약 조건 만족도를 나타내는 인간의 레이블로 구성되어 있습니다. 이 데이터셋은 사용자가 요청한 제약 조건의 만족도를 평가하기 위해 응답 전체를 검토해야 하는 독특한 특성을 갖추고 있습니다. LLMs (Large Language Models)의 추론, 인-context 데이터 추출, 산술 계산 및 카운팅 능력을 평가하며, 자동 평가 프레임워크를 이용하여 제약 조건 만족도를 측정합니다.

- **Performance Highlights**: 연구 결과, 대부분의 LLM 모델이 여전히 개선 여지가 크며 주된 오류는 추론 문제에서 발생하는 것으로 나타났습니다. 또한, 적은 수의 프롬프트(few-shot prompting)를 활용할 경우 성능 저하가 발생하는 것이 관찰되었습니다.



### More Effective LLM Compressed Tokens with Uniformly Spread Position Identifiers and Compression Loss (https://arxiv.org/abs/2409.14364)
- **What's New**: 본 연구는 Transformer 입력을 압축된 토큰(compressed tokens)으로 변환하여 대규모 언어 모델(LLMs)의 속도와 비용 효율성을 개선하는 방법을 제시합니다. 특히, 기존의 ICAE 방법에 비해 약 15배에 달하는 압축 비율을 달성하며, 재구성 성능에서도 경쟁력을 유지합니다.

- **Technical Details**: ICA를 활용하여 압축된 토큰의 위치 식별자를 신중히 선택하고 새로운 압축 손실(compression loss)을 제안합니다. 본 연구에서 제시된 아키텍처는 기존의 AE 작업과 언어 모델링(LM) 작업을 결합하는 대신, 압축된 토큰에서 원본 문맥(segment)을 직접 디코딩하는 방법을 사용하여 효율성을 높입니다. 추가적으로, RoPE(position embedding) 기반의 위치 식별자를 고르게 분포시켜 압축 비율을 개선했습니다.

- **Performance Highlights**: 본 연구에서 제안한 방법은 15배의 압축 비율을 달성하며, 압축된 토큰을 통해 대부분의 정보를 유지할 수 있습니다. 이러한 접근 방식은 계산 시간과 비용을 줄이면서도, LLM의 성능을 유지하거나 향상시킬 수 있는 가능성을 보여줍니다.



### Using Natural Language Processing to find Indication for Burnout with Text Classification: From Online Data to Real-World Data (https://arxiv.org/abs/2409.14357)
- **What's New**: 이 논문은 독일어 텍스트에서의 번아웃 감지에 기여하며, 실시간 데이터를 활용한 연구 결과와 AI 모델의 해석 가능성에 대한 심층적인 통찰을 제공합니다.

- **Technical Details**: 번아웃(burnout)은 ICD-11에서 증상으로 분류되며, 만성 직장 스트레스에 기인합니다. 본 연구는 익명성을 유지한 실제 데이터셋을 수집하고, GermanBERT 기반 분류기의 한계를 보여주며, 실용적 응용에서 우수한 성능을 발휘하는 두 가지 BurnoutExpressions 데이터셋 버전을 제시합니다.

- **Performance Highlights**: 연구 결과는 AI 연구자와 임상 전문가 간의 협력이 번아웃 감지 모델 개선에 필수적임을 강조하며, 실제 환경에서 효과를 검증할 수 있는 더 많은 데이터의 필요성을 제기합니다.



### MQM-APE: Toward High-Quality Error Annotation Predictors with Automatic Post-Editing in LLM Translation Evaluators (https://arxiv.org/abs/2409.14335)
Comments:
          Under Review

- **What's New**: 이번 논문에서는 대형 언어 모델(Large Language Models, LLMs)을 활용하여 기계 번역(Machine Translation, MT)의 품질 평가를 위한 새로운 접근 방식인 MQM-APE를 제안합니다. 기존의 GEMBA-MQM 방법론이 제공하는 성능을 초월하여, 자동화된 오류 수정(Automatically Post-Editing, APE)을 통해 비영향적인 오류를 걸러내어 해석 가능성이 높은 오류 주석을 생성합니다.

- **Technical Details**: MQM-APE는 세 가지 주요 역할로 설정된 LLM을 통하여 작동합니다: 1) 오류 분석 평가자(evaluator)가 오류 주석을 제공하고, 2) 자동 포스트 에디터(post-editor)가 오류가 품질 개선에 영향을 미치는지를 판단하며, 3) 쌍별 품질 검증기(pairwise quality verifier)가 오류를 필터링합니다. 이 과정은 WMT22 테스트 세트를 포함하여 다양한 LLM을 사용하여 검증되었습니다.

- **Performance Highlights**: 실험 결과 MQM-APE는 GEMBA-MQM보다 더 높은 신뢰성과 품질을 보여주며, 인간의 주석과 잘 맞춰지는 해석 가능한 오류 범위를 제공합니다. 이 방법은 높은 자원과 낮은 자원 언어 모두에 효과적으로 적용되며, 번역별 평가자와의 상호 보완적인 관계를 형성합니다.



### Unveiling Narrative Reasoning Limits of Large Language Models with Trope in Movie Synopses (https://arxiv.org/abs/2409.14324)
Comments:
          EMNLP 2024 Findings. The first two authors contributed equally. Code: this https URL

- **What's New**: 이 연구는 캐릭터의 전형을 포함하는 영화의 줄거리를 사용하여 최신 대형 언어 모델(LLMs)의 추상적 추론 능력을 평가하였습니다. 특히, CoT(Chain-of-Thought) 프롬프트 방법을 사용할 때 내러티브 추론에서의 낮은 성능을 드러냈습니다. 이를 해결하기 위해 전형별 쿼리 방식을 도입하여 성능을 11.8포인트 향상시켰습니다.

- **Technical Details**: 이 연구는 영화 줄거리에 포함된 전형(trope)을 사용하는 최초의 LLM 분석입니다. CoT가 적용된 경우에도 GPT-4와 같은 모델이 전형 이해 작업에서 무작위 추측 수준의 성능을 보이는 반면, 전형별 쿼리 방식은 성능을 획기적으로 높였습니다. 또한, Adversarial Injection 기법을 통해 LLM이 전형 관련 텍스트 토큰에 대한 민감성을 가지게 될 수 있음을 발견했습니다.

- **Performance Highlights**: 이 연구에서 제시된 전형별 쿼리 방식은 기존 TiMoS(Trope in Movie Synopses) 데이터셋에서 성능을 11.8포인트 향상시켜 새로운 최첨단 성과를 초래하였습니다. CoT가 입력된 경우 LLM의 정확도가 현저히 감소하며, 적대적 입력(Adversarial Input)에 대한 높은 민감도를 보여줍니다.



### PretextTrans: Investigating Medical Factual Knowledge Mastery of LLMs with Predicate-text Dual Transformation (https://arxiv.org/abs/2409.14302)
Comments:
          17 pages, 10 figures

- **What's New**: 이번 연구에서는 현재 대규모 언어 모델(LLMs)의 의료 사실 지식 숙련도를 동적인 평가 스키마를 사용하여 조사하고, 각 의료 사실 지식 포인트에 대한 여러 테스트 샘플을 자동으로 생성하는 방법을 제안합니다. 이는 기존의 LLM이 사용했던 방식의 한계를 극복하기 위한 것입니다.

- **Technical Details**: 우리는 Predicate-text Dual Transformation (PretextTrans)라는 새로운 평가 방법을 제안합니다. 이 방법은 각 의료 지식 포인트를 술어 표현으로 변환하고, 이를 통해 생성된 변형을 바탕으로 다양한 텍스트 표현을 생성합니다. 이러한 방식은 사실적 신뢰성과 표현의 다양성을 동시에 보장합니다. 이 연구에서 12개의 잘 알려진 LLM의 의료 사실 지식 숙련도를 두 개의 의료 데이터 세트를 기반으로 평가했습니다.

- **Performance Highlights**: 실험 결과, 제안된 PretextTrans 방법에 의해 생성된 다중 샘플 데이터 세트에서 LLM의 성능이 기존의 단일 샘플 데이터 세트에 비해 상당히 낮은 것으로 나타났습니다. 이는 현재 LLM들이 의료 사실 지식을 포괄적으로 습득하지 못하고 있음을 보여주며, 실제 의료 시나리오에서의 성능 부진의 원인을 설명합니다.



### ESPERANTO: Evaluating Synthesized Phrases to Enhance Robustness in AI Detection for Text Origination (https://arxiv.org/abs/2409.14285)
- **What's New**: 이 논문은 AI 생성 텍스트 탐지 시스템의 취약성과 현재 시스템의 내구성을 향상시킬 필요성을 강조합니다. 이를 해결하기 위해 새로운 기법인 back-translation을 소개하여 탐지를 우회하는 방법을 검토하면서, 이를 극복하기 위한 대응 방안도 제시합니다.

- **Technical Details**: 제안된 방법은 AI 생성 텍스트를 여러 언어로 번역한 후 영어로 다시 번역하는 과정으로 구성됩니다. 모델은 이러한 back-translated 텍스트를 결합하여 원본 AI 생성 텍스트의 변조 버전을 제작합니다. 이 기법은 720,000 개의 텍스트로 구성된 대규모 데이터셋에서의 실험을 통해 평가되었으며, 다양한 AI 탐지기를 대상으로 검증되었습니다.

- **Performance Highlights**: 변조된 텍스트는 원래 의미를 유지하면서, 기존 탐지 방법의 true positive rate (TPR)을 대폭 낮추는 효과를 보였습니다. 예를 들어, RADAR의 TPR은 질문-응답 데이터셋에서 52% 감소했습니다. 제안된 방법은 back-translation 변조에 노출되었을 때 TPR이 단지 1.85% 감소하는 것으로 나타났습니다.



### Instruction Following without Instruction Tuning (https://arxiv.org/abs/2409.14254)
- **What's New**: 이번 연구에서는 언어 모델을 명시적인 지침-응답 쌍으로 조정(finetuning)하는 기존의 instruction tuning보다 훨씬 간단한 implicit instruction tuning을 발견했다. 이 방식은 오직 응답만으로도 지침 따르기를 할 수 있으며, 교훈적으로 제공된 응답 분포 없이도 프로그래밍, 시 생성 등 다양한 작업을 수행할 수 있음을 보였다.

- **Technical Details**: Implicit instruction tuning은 두 가지 형식(응답 조정(response tuning) 및 단일 작업 조정(single-task finetuning))을 통해 이루어진다. 응답 조정은 오직 응답으로만 훈련되어도 지침 따르기가 가능하다는 것을 보여주었고, 단일 작업 조정은 좁은 도메인 데이터에서 훈련되더라도 넓은 범위의 지침 따르기 행동을 만들어낼 수 있다. 연구팀은 언어 모델의 분포에 대한 간단한 변경이 지침 따르기를 유도할 수 있다는 가설을 세웠고, 세 가지 규칙(시퀀스 종료 확률 증가, 15개 토큰의 확률 균일 수정, 토큰 반복에 대한 패널티)을 적용하여 이를 검증하였다.

- **Performance Highlights**: 응답 조정된 모델은 비슷한 instruction-tuned 모델에 비해 약 43%의 승률을 기록했고, 시 조정된 Llama-2-7B 모델은 AlpacaEval 2에서 instruction-tuned 모델에 비해 23.7%의 승률을 보였다. 이러한 결과는 일반적인 지침-응답 관계를가르치지 않고도 모델이 다양한 지침을 따를 수 있음을 나타낸다.



### Repairs in a Block World: A New Benchmark for Handling User Corrections with Multi-Modal Language Models (https://arxiv.org/abs/2409.14247)
Comments:
          Accepted to EMNLP'24 Main (Upcoming)

- **What's New**: 이 논문은 다층적인 지식 기반의 대화에서 발생하는 Third Position Repair (TPR) 시퀀스를 포함하는 BlockWorld-Repairs라는 새로운 데이터 세트를 수집하고 공개합니다. TPR은 대화 중 오해가 발생했을 때 이를 수정하는 일련의 과정을 설명하며, 대화형 AI 기술에서 중요한 역할을 담당합니다.

- **Technical Details**: TPR은 Addressee가 Speaker를 잘못 이해하고 잘못된 응답을 할 때 발생하는 일련의 반응입니다. 이 데이터 세트는 Vision and Language Models (VLM)의 성능을 평가하는 데 활용되며, 대화의 복잡성과 비대칭적인 참조를 포함합니다. 연구를 통해 VLM은 특정 토큰에 초점을 맞춘 손실 함수를 통해 미세 조정(fine-tuning) 시 보다 나은 성능을 발휘할 수 있음을 발견했습니다.

- **Performance Highlights**: 모든 모델이 인간과 비교할 때 TPR 처리가 미흡하여 성능 차이를 보였습니다. 이러한 결과는 특히 수리(Repair)가 잦은 다중 모달 협력 환경에서 이러한 모델들을 사용할 준비가 아직 안 되어 있음을 보여줍니다. 이에 따라 상호작용 학습을 위한 훈련 체계와 목표가 필요하다는 점을 강조합니다.



### Data-centric NLP Backdoor Defense from the Lens of Memorization (https://arxiv.org/abs/2409.14200)
- **What's New**: 이 논문에서는 DNN 기반 언어 모델의 백도어 공격에 대한 새로운 관점을 제시합니다. 언어 모델 메모리화의 정의를 샘플 단위에서 문장 요소 단위로 확장하고, 백도어는 요소 단위 메모리화의 일종이라는 점을 강조합니다.

- **Technical Details**: 기존의 연구에서는 메모리화를 샘플 단위로 분석했으나, 본 연구는 문장 내의 특정 요소(단어, 구, 구조 등)별 메모리화에 중점을 둡니다. 특히, 훈련 데이터에서 중복된 요소의 빈도가 백도어 공격의 성공률에 긍정적인 상관관계를 가진다는 것을 밝혔습니다. 새로운 데이터 중심 방어 방법인 BMC(Bad Memorization Cleanser)를 제안합니다.

- **Performance Highlights**: BMC는 다양한 NLP 백도어 공격에 대해 8.34배의 공격 성공률 감소를 달성하면서, 부정확도는 단 0.85% 증가시키는 성과를 보였습니다. 이는 기존 방어 방법보다 뛰어난 결과입니다.



### The Imperative of Conversation Analysis in the Era of LLMs: A Survey of Tasks, Techniques, and Trends (https://arxiv.org/abs/2409.14195)
Comments:
          21 pages, work in progress

- **What's New**: 이 논문은 대화 분석(Conversation Analysis, CA)의 체계적인 정의와 중요한 네 가지 절차를 정의하며, 특히 대규모 언어 모델(LLMs)을 활용하여 기존의 연구를 종합적으로 정리합니다.

- **Technical Details**: CA는 대화에서 중요한 정보(예: 참가자 프로필, 감정, 의도 등)를 식별하고, 이러한 요소의 배경을 분석하여 목표 달성을 위한 개선 방안을 제시하는 것을 목표로 합니다. CA 절차는 1) Scene Reconstruction, 2) Causality Analysis, 3) Skill Enhancement, 4) Conversation Generation의 네 가지 단계로 구성됩니다.

- **Performance Highlights**: 노력의 대부분이 여전히 표면적인 대화 요소 분석에 집중되고 있으며, 연구와 비즈니스 간의 큰 격차가 존재합니다. 그러나 LLMs의 도움으로 최근 연구는 원인 분석 및 전략적 작업과 같은 고급 주제로의 연구 경향을 보이고 있습니다.



### Knowledge in Triples for LLMs: Enhancing Table QA Accuracy with Semantic Extraction (https://arxiv.org/abs/2409.14192)
- **What's New**: 이 논문은 semi-structured (반구조화) 테이블에서 Triple을 추출하고 이를 Retrieval-augmented Generation (RAG) 모델과 결합하여 자연어 처리(NLP)에서 질문 응답 시스템(QA)의 정확도와 문맥적 풍부함을 향상시키는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 제안된 방법론은 RDFLib 라이브러리를 사용하여 테이블에서 Triple을 간단히 구성하는 과정을 포함합니다. Triple은 Subject(주어), Predicate(서술어), Object(목적어)로 구성되며, 이를 통해 테이블의 셀 간의 관계를 명확히 표현합니다. 이 Triple은 Fine-tuned GPT-3.5-turbo-0125 모델에 통합되어 응답 생성을 개선하는 데 사용됩니다.

- **Performance Highlights**: 제안된 접근 방식은 FeTaQA 데이터셋에서 기존 기법들보다 성능이 크게 향상되었으며, 특히 Sacre-BLEU 및 ROUGE 지표에서 우수한 성과를 나타냈습니다. 테이블에서 복잡한 정보를 효과적으로 식별하고 명확한 긴 형식의 답변을 생성하는 능력이 두드러집니다.



### QMOS: Enhancing LLMs for Telecommunication with Question Masked loss and Option Shuffling (https://arxiv.org/abs/2409.14175)
- **What's New**: 이 논문은 QMOS라는 혁신적인 접근 방식으로 통신 분야에서 다중 선택 질문에 대한 LLM(대규모 언어 모델)의 성능을 향상시키는 방법을 제시합니다. 기존의 수익 모델에 의존하지 않고 오픈소스의 작은 언어 모델인 Phi-2와 Falcon-7B를 사용하여 Retrieval Augmented Generation (RAG) 프레임워크 내에서 다양한 개선사항을 적용하여 성과를 올릴 수 있었습니다.

- **Technical Details**: QMOS는 질문 마스크 손실 함수(Question-Masked loss)와 옵션 셔플링(Option Shuffling) 기법을 활용하여 LLM을 다중 선택 질문에 효율적으로 적응시킵니다. 이 프로세스는 여러 임베딩 모델을 통해 관련 정보를 다각화하고, 약어 딕셔너리를 확장하며, 정교한 프롬프트 설계를 통해 LLM이 문서에서 답을 선택하도록 유도합니다. 또한 LoRA(저차원 적응, Low-Rank Adaptation) 기법을 통해 Phi-2 모델을 통신 도메인에 맞추어 효율적으로 조정합니다.

- **Performance Highlights**: Falcon-7B 모델은 기본선에서 24.70%에서 49.30%로 정확도를 개선했으며 Phi-2 모델은 42.07%에서 84.65% 사이의 성과를 달성했습니다. 이는 기존 모델에 비해 значительно 향상된 결과로, 효율적이고 비용 효과적인 QA 시스템 구축에 기여할 것으로 예상됩니다.



### Towards Building Efficient Sentence BERT Models using Layer Pruning (https://arxiv.org/abs/2409.14168)
- **What's New**: 이번 연구는 SBERT(문장 BERT) 모델의 효과적인 레이어 프루닝(layer pruning)에 대한 효과를 조사하며, 복잡성을 줄이면서도 강력한 임베딩 유사성을 유지할 수 있는 방법을 제시합니다.

- **Technical Details**: 이 연구에서는 Muril 및 MahaBERT-v2 같은 BERT 모델을 프루닝 전후로 평가하고, MahaBERT-Small 및 MahaBERT-Smaller와 같은 작은 모델들과 비교합니다. NLI(자연어 추론) 및 STS(의미적 텍스트 유사성) 훈련을 포함한 2단계 SBERT 파인튜닝 과정에서 레이어 축소의 임팩트를 평가합니다.

- **Performance Highlights**: 프루닝된 모델이 레이어 수는 적지만 완전한 레이어 모델들과 경쟁력을 가지며, 유사한 크기의 스크래치 모델보다 일관되게 우수한 성능을 보입니다. 결과적으로 레이어 프루닝은 계산 수요를 줄이고 동시에 높은 품질의 임베딩을 유지하는 실용적인 접근법으로 자리잡았습니다.



### On Importance of Pruning and Distillation for Efficient Low Resource NLP (https://arxiv.org/abs/2409.14162)
- **What's New**: 본 연구는 저자들이 마라티어(Marathi)와 같은 자원이 부족한 언어에 대해 대형 트랜스포머 모델을 최적화하는 방법을 제안하는 최초의 연구 중 하나입니다. 마라티어에 대한 효율적인 언어 모델이 부족한 상황에서, 본 연구는 기존 모델의 최적화 기술을 통해 계산 시간과 메모리 사용량을 줄이는 것을 목표로 합니다.

- **Technical Details**: 연구에서는 marathi-topic-all-doc-v2 모델을 기반으로 여러 최적화 기술을 적용합니다. Block Movement Pruning, Knowledge Distillation, Mixed Precision 기법을 개별적으로 그리고 조합하여 적용하여 모델의 효율성을 높입니다. 6개의 실험을 통해 25%, 50%, 75% prunings 및 Knowledge Distillation을 포함한 조합을 테스트했습니다.

- **Performance Highlights**: 25% pruning과 Knowledge Distillation 조합을 통해 2.56배의 속도 향상을 달성하였으며, 기본 정확도를 유지했습니다. 모델의 파라미터 수는 223백만으로 유지되었고, 75% pruning과 Knowledge Distillation을 적용할 경우에는 195백만 파라미터를 갖고 2%의 정확도 감소가 있었습니다. 이러한 최적화는 환경적인 영향 감소에도 기여할 수 있습니다.



### Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis (https://arxiv.org/abs/2409.14144)
Comments:
          Accepted by EMNLP 2024 main. Mechanistic interpretability for arithmetic tasks in large language models

- **What's New**: 이 논문에서는 산술 능력이 제한된 수의 attention heads에 존재하고, 각 head가 다른 작업에 특화되어 있다는 것을 발견하였습니다. Comparative Neuron Analysis (CNA) 방법을 도입하여 입력에서 예측까지의 내부 로직 체인을 네 가지 단계로 식별하였습니다.

- **Technical Details**: CNA 방법은 feature enhancing, feature transferring, feature predicting, prediction enhancing 의 네 가지 단계로 구성되어 있습니다. 이 연구에서 LoRA의 메커니즘을 분석하고, FFN (Feedforward Neural Network) neurons의 계수 점수를 증폭시킴으로써 최종 예측 확률을 높인다는 결론을 내렸습니다.

- **Performance Highlights**: 모델이 산술 작업을 위한 pruning 및 성별 편향을 감소시키기 위한 편집 방법을 설계하였으며, 특히 산술 능력에 영향을 미치는 산술 heads를 파악하는 데 중요한 기여를 하였습니다.



### Obliviate: Neutralizing Task-agnostic Backdoors within the Parameter-efficient Fine-tuning Paradigm (https://arxiv.org/abs/2409.14119)
Comments:
          Under Review

- **What's New**: 본 연구에서는 Parameter-efficient fine-tuning (PEFT) 아키텍처에서 악의적인 백도어 공격에 대한 방어 방법인 Obliviate를 소개합니다. Obliviate는 PEFT 프로세스와 통합되어 작동하며, 이는 두 가지 주요 기술을 포함합니다: 1) PEFT 레이어 내에서 유해하지 않은 뉴런을 증폭하여 모델이 청정 학습 샘플에 더 집중하도록 유도합니다. 2) 트리거 토큰의 영향을 제한하기 위해 어텐션 점수를 정규화합니다.

- **Technical Details**: Obliviate는 PEFT 아키텍처, 특히 adapter, LoRA, prefix-tuning을 기반으로 하여 RoBERTa와 BERT 모델에 적용될 수 있습니다. PEFT에서 훈련 가능한 매개변수가 제한적이기 때문에 기존의 방어 방법을 적용하기 어려운 부분을 극복하여, 백도어 공격을 효과적으로 중화시키기 위한 두 개의 손실 항(term)을 추가합니다.

- **Performance Highlights**: 실험 결과 Obliviate는 최첨단의 task-agnostic 백도어 공격의 성공률(ASR)을 83.6% 감소시키는 효과를 보였으며, 청정 정확도(CACC)는 약간(0.78%) 하락하는 것으로 나타났습니다. 뿐만 아니라, Obliviate는 다양한 공격 전략에 대한 강력한 방어 능력을 보여줍니다.



### Routing in Sparsely-gated Language Models responds to Contex (https://arxiv.org/abs/2409.14107)
- **What's New**: 이 논문은 Mixture-of-Experts (MoE) 아키텍처에서의 토큰-전문가 할당의 문맥 민감도를 평가하고, 특정 문맥에서 단백의 할당을 조사하여 기존의 연구 결과를 발전시킵니다.

- **Technical Details**: 비지도 학습된 텍스트 쌍을 활용하여 다양한 모형 구성에 따른 라우팅의 특성을 분석하였고, 인코더 레이어에서는 (semantic) 연관성에 기반한 라우팅이 주요하나, 디코더 레이어에서는 문맥에 대해 변동성이 큼을 발견하였습니다. 또한, 전문가 수에 따라 문맥 민감도가 증가한다고 보고하였습니다.

- **Performance Highlights**: 모델의 인코더와 디코더 구성 모두에서 라우팅 결정이 문맥 정보에 반응하며, 유사한 문맥에서 단어가 동일한 전문가에 더 일관되게 배정되는 경향을 보였습니다.



### Probing Context Localization of Polysemous Words in Pre-trained Language Model Sub-Layers (https://arxiv.org/abs/2409.14097)
- **What's New**: 이 논문은 고성능의 대형 언어 모델(LLMs)에서의 문맥적 단어 표현의 중요성을 강조하며, 사전학습된 언어 모델(PLM)의 세부적인 서브-레이어 표현에서 문맥화의 강도를 실험적으로 조사합니다. 특히, BERT 모델의 Self-Attention, Feed-Forward Activation, Output 서브-레이어 간의 문맥화 정도를 비교 분석합니다.

- **Technical Details**: 이 연구에서는 선형 프로브(linear probe) 방법을 통해 다의어(polysemous word)의 의미를 식별하는 과제를 수행하며, 다른 문맥에서의 표현을 비교하여 PLM 서브-레이어에서의 문맥화 정도를 분석합니다. 다양한 유사성 지표를 사용해 BERT 서브-레이어의 문맥화 정도를 국소화하고, 서로 다른 단어 위치 및 문맥 길이가 문맥화 정보에 미치는 영향을 조사합니다.

- **Performance Highlights**: 주요 결과로 BERT는 특정 위치와 짧은 문맥에서 문맥화 정도가 높지만, 이는 모든 단어 위치와 문맥 크기에 체계적으로 일반화되지 않음을 보여줍니다. 실험 결과, 단어 위치와 문맥 길이에 따라 BERT 서브-레이어에서의 문맥화의 강도가 다르게 나타나는 것으로 확인되었습니다.



### PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL (https://arxiv.org/abs/2409.14082)
Comments:
          EMNLP 2024 Main Conference. Revised by ARR April and ARR June. 32 pages, 7 figures and 30 tables

- **What's New**: 이번 연구에서는 대형 언어 모델(Large Language Models, LLMs)이 Text-to-SQL 작업에 있어 논리적 사고능력을 발휘할 수 있는 방법을 제안합니다. 특히, 문제 유형에 따라 쿼리 그룹 분할(query group partitioning)을 활용함으로써 LLM들이 특정 문제 유형에 대한 사고 과정을 더 잘 학습할 수 있음을 보여줍니다.

- **Technical Details**: 연구에서 제안하는 PTD-SQL(Problem Type Differentiation SQL)은 LLM들이 다양한 난이도와 문제 카테고리에서 더 뛰어난 추론 능력을 가지도록 돕습니다. 이를 통해 LLM들이 전통적인 SQL 솔루션 접근 방법과의 차별성을 가지고, 특정 문제 유형에 대한 사고 과정을 심도 있게 학습할 수 있게 됩니다.

- **Performance Highlights**: 실험 결과, 여러 고급 LLM들이 PTD-SQL로 강화된 후 Spider 및 BIRD 데이터셋에서 이전의 최첨단(SOTA) 방법들을 능가하거나 동등한 성능을 발휘했습니다. 특히, 초기 성능이 다양한 모델들이 집중적인 훈련(targeted drilling)을 받은 후 큰 향상을 보였으며, 이는 인간의 능력 진전을 연상케 합니다.



### MultiMed: Multilingual Medical Speech Recognition via Attention Encoder Decoder (https://arxiv.org/abs/2409.14074)
Comments:
          Preprint

- **What's New**: 이번 연구는 Medical 분야의 다국어 자동 음성 인식(ASR) 시스템에 대해 소개하며, 5개 언어(베트남어, 영어, 독일어, 프랑스어, 중국어)로 구성된 MultiMed 데이터셋과 다양한 크기의 ASR 모델을 제공합니다. MultiMed는 지금까지의 의료 ASR 데이터셋 중 가장 크고 다양성 있는 데이터셋입니다.

- **Technical Details**: MultiMed는 150시간에 달하는 인적 주석이 달린 의료 분야 음성 데이터를 포함하고 있으며, 이는 다양한 질병, 녹음 조건, 화자 역할 및 고유한 의료 용어를 나타냅니다. 연구진은 End-to-End ASR 훈련을 위해 Layer-wise ablation study를 수행하고, 언어적 분석을 통해 다국어 의료 ASR에 대한 통찰력을 제공합니다.

- **Performance Highlights**: MultiMed는 5개 언어로 150시간의 데이터를 포함하는 세계 최대의 의료 ASR 데이터셋으로 평가받고 있습니다. 이 데이터셋은 ASR 시스템의 성능 향상을 위한 기초를 제공하며, 향후 다양한 의료 애플리케이션, 음성 번역, 그리고 음성 인식 기반의 비서 시스템 개발을 가능하게 합니다.



### Temporally Consistent Factuality Probing for Large Language Models (https://arxiv.org/abs/2409.14065)
- **What's New**: 이 연구에서는 TeCFaP라는 새로운 Temporally Consistent Factuality Probe 작업을 도입하고, TEMP-COFAC라는 고품질의 영어 쿼리 패러프레이즈 데이터셋을 제안합니다. 이를 통해 LLM의 일관된 사실성과 시간적 일관성을 평가하고 개선할 수 있습니다.

- **Technical Details**: TeCFaP는 (key_object, subject-relation, value_object) 형식의 쿼리 구조를 통해 시간적 연결성을 탐색하는 작업입니다. CoTSeLF(Consistent-Time-Sensitive Learning Framework)는 다중작업 지시 튜닝(MT-IT)과 시간 일관성 민감 강화학습(CTSRL)을 결합하여 LLM의 시간적 일관된 사실성을 개선합니다.

- **Performance Highlights**: 실험 결과, CoTSeLF는 temporal factuality, temporal consistency 및 temporally consistent factuality에서 이전 최선 모델보다 각각 12.7%, 10.9%, 90.4% 개선된 성능을 보였습니다.



### Co-occurrence is not Factual Association in Language Models (https://arxiv.org/abs/2409.14057)
- **What's New**: 이 연구에서는 언어 모델이 실제 사실 관계를 학습하는 데 어려움을 겪는 이유를 분석하고, 구체적인 전략을 제안하여 언어 모델이 사실 연관(factual associations)을 보다 효과적으로 학습할 수 있도록 돕는 방법을 제시합니다.

- **Technical Details**: 언어 모델에서 두 가지 형태의 지식 표현, 즉 단어 공변량 통계(co-occurrence statistics)와 실제 사실 연관(factual associations)을 구분했습니다. 연구 결과, 단어 공변량 통계는 트랜스포머 모델의 중간층에 주로 저장되며, 단순한 질문 응답을 넘어서는 추론 시나리오에 일반화되지 않는 반면, 실제 사실 연관은 모델의 하위층(lower layers)에 저장되어 다양한 추론 작업에서 자유롭게 활용할 수 있다는 사실을 발견했습니다.

- **Performance Highlights**: 제안된 두 가지 전략을 통해 새로 학습된 지식의 일반화가 유의미하게 향상되었습니다. 모형을 암묵적 사실 연관이 포함된 텍스트로 학습시킬 경우, 단순한 내러티브 텍스트를 사용할 때보다 새로운 사실을 더 잘 일반화할 수 있는 것으로 나타났습니다.



### GroupDebate: Enhancing the Efficiency of Multi-Agent Debate Using Group Discussion (https://arxiv.org/abs/2409.14051)
Comments:
          18 pages

- **What's New**: 이번 연구에서는 다수의 에이전트가 참여하는 논쟁 방식에서 토큰 비용을 대폭 줄이는 혁신적인 방법인 GroupDebate (GD)를 제안합니다. 기존의 방법들보다 더욱 효율적이면서도 성능을 개선하는 데 초점을 맞추고 있습니다.

- **Technical Details**: GroupDebate 방법은 모든 에이전트를 여러 논쟁 그룹으로 나누고, 그룹 내에서 내부 논쟁을 거친 후 중간 결과를 공유하는 방식을 채택합니다. 이렇게 함으로써 토큰 사용량을 약 51.7%까지 줄이고, 정확도 역시 최대 25%까지 향상시킬 수 있음을 실험을 통해 입증하였습니다.

- **Performance Highlights**: 실험 결과, GroupDebate는 기존 다수의 에이전트 논쟁 방법들에 비해 Arithmetic, GSM8K, MMLU, MATH 데이터셋에서 각각 45%에서 51.7%까지 토큰 비용을 절감하며, MMLU와 MATH 데이터셋에서는 최대 25%의 정확도 향상을 보여주었습니다.



### Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators (https://arxiv.org/abs/2409.14037)
- **What's New**: 이 논문에서는 현재의 Large Language Models(LLMs)를 과학 커뮤니케이터로서의 신뢰성을 평가하는 새로운 접근 방식을 소개합니다. 기존의 벤치마크와는 달리, LLM의 과학적 질문 응답 과제를 기반으로 LLM의 이해도를 평가하는 SCiPS-QA라는 새로운 데이터셋을 도입했습니다.

- **Technical Details**: SCiPS-QA 데이터셋은 복잡한 과학 개념에서의 742개의 Yes/No 질문으로 구성되며, 이를 통해 LLM의 정확성과 일관성을 다양한 기준으로 평가합니다. 실험에는 OpenAI의 GPT 시리즈와 Meta의 Llama 시리즈 및 Mistral 시리즈의 LLM이 포함됩니다. 고급 과학적 이해가 필요한 질문에 대한 LLM의 성능을 테스트하기 위해 다수의 평가 기준을 적용하였습니다.

- **Performance Highlights**: 대부분의 오픈 액세스 모델은 GPT-4 Turbo에 비해 떨어지지만, Llama-3-70B 모델은 다양한 평가에서 GPT-4 Turbo를 초과하는 경우가 있었습니다. 인간 평가자들이 GPT-4 Turbo의 잘못된 응답에 속아 넘어가는 경향도 관찰되었습니다.



### Uncovering Latent Chain of Thought Vectors in Language Models (https://arxiv.org/abs/2409.14026)
Comments:
          2 Pages, Intended for Tiny Papers 2025 Submission to ICLR

- **What's New**: 이 연구는 언어 모델(LM)의 행동을 선도하기 위해 'steering vector'라는 새로운 기법을 소개합니다. 이는 특정 작업에서 파생된 steering vector를 사용하여 Chain of Thought (CoT) Reasoning을 유도하며, 기존 자연어 프롬프트 없이도 이를 가능하게 합니다.

- **Technical Details**: 연구진은 Llama3 8b 및 Mistral 7b v0.2 모델에서 steering vector를 활용하여 CoT Reasoning을 진행하였습니다. 이들은 자연어 프롬프트 쌍을 대비시켜, 각 레이어의 활성화를 추출하고 이를 통해 최종 steering vector를 생성했습니다. PyTorch를 사용하여 추출된 레이어에 vector를 주입하는 방식으로 적용되었습니다.

- **Performance Highlights**: 이 접근 방식은 CoT 프롬프트를 사용한 모델들과 비교하여 경쟁력 있는 성능을 보였으며, 다양한 Reasoning benchmark(GSM8k, MMLU, ARC AI2)에서도 일관되게 CoT 응답을 유도하는 결과를 보여주었습니다. 또한, 전통적인 모델 미세 조정 방법보다 계산 비용이 절감된다는 장점이 있습니다.



### Graph Neural Network Framework for Sentiment Analysis Using Syntactic Featur (https://arxiv.org/abs/2409.14000)
- **What's New**: 소셜 미디어 플랫폼과 전자 상거래 생태계의 빠른 발전에 따라, 의견 분석(opinion mining) 분야가 자연어 처리(natural language processing)에서 중요한 연구 영역으로 떠오르고 있습니다. 본 연구는 텍스트 맥락 내 특정 요소에 대한 세밀한 평가를 추출하는 독특한 프레임워크를 제안합니다.

- **Technical Details**: 제안된 시스템은 구문 구조(syntactic structures)를 행렬(matrix) 형식으로 변환하고, 이 과정에서 그래프 내의 컨볼루션(convolutions) 및 어텐션(attention) 메커니즘을 활용하여 중요한 특징(salient characteristics)을 증류(distill)합니다. 설명자의 위치적 관련(positional relevance)을 어휘 항목(lexical items)과 연관시키는 방식은 입력의 순차적 무결성을 향상시킵니다.

- **Performance Highlights**: 실험(trials) 결과, 이 통합된 그래프 중심(graph-centric) 방안이 평가 범주화(evaluative categorization)의 효율성을 현저히 증대시키며 뛰어난 성능을 보여주었습니다.



### Contrastive Learning for Knowledge-Based Question Generation in Large Language Models (https://arxiv.org/abs/2409.13994)
Comments:
          5 pages, 2 figures

- **What's New**: 이번 연구는 고품질 질문 생성(question generation)을 지원하기 위한 새로운 방법론을 제안합니다. 특히, 지식 기반 질문 생성 기술에 초점을 맞추고 있으며, 이 과정에서 발생하는 착각(hallucination)과 지식 격차를 해결하고자 합니다.

- **Technical Details**: 제안된 방법은 contrastive learning을 통합하여 여러 모델이 도메인 지식을 공동으로 탐색하도록 하며, 생성 과정에서의 잡음과 착각을 줄이도록 유도합니다. 또한, contrasting examples를 포함한 프롬프트(prompt)를 설계하여 질문 생성 성능을 향상시킵니다.

- **Performance Highlights**: 실험 결과, 대조적인 지시 및 예제를 동시에 사용하는 경우 질문 생성의 품질이 크게 향상되었으며, 이는 높은 정확도를 이끌어냅니다. 제안된 방법은 대조적 맥락과 사고의 흐름(chain-of-thought) 프롬프트를 결합함으로써 질문 생성의 품질과 실용성을 효과적으로 개선할 수 있음을 보여주었습니다.



### SMART-RAG: Selection using Determinantal Matrices for Augmented Retrieva (https://arxiv.org/abs/2409.13992)
Comments:
          Under Review

- **What's New**: 본 논문에서는 Retrieval-Augmented Generation (RAG) 기법을 발전시켜, 질문 답변(QA) 작업에서 기존의 문제를 해결하기 위한 새로운 방법인 SMART(Selection using Matrices for Augmented Retrieval)를 소개합니다. 특히, 이 방법은 불필요한 중복성 및 모순된 정보를 효과적으로 제거하는 데 중점을 두고 있습니다.

- **Technical Details**: SMART는 Determinantal Point Processes (DPPs)를 이용하여 검색된 문서 간의 관련성(relationship), 다양성(diversity), 모순(conflict) 관계를 동시에 모델링합니다. 이를 통해 보다 질 높은 맥락(context)을 선택하면서도 문서들 사이의 중복성과 충돌을 효과적으로 방지합니다. SMART는 Natural Language Inference (NLI) 모델을 통해 텍스트 간의 모순 관계를 평가하며, Cosine similarity를 이용해 관련성을 결정합니다.

- **Performance Highlights**: 여러 데이터셋에서 SMART를 적용한 결과, QA 성능이 유의미하게 향상되었으며, 이전의 비지도 학습 방법들보다 우수한 성능을 나타내었습니다. SMART는 RAG 분야에서 새로운 가능성을 제시하는 방법으로 각광받고 있습니다.



### ChemEval: A Comprehensive Multi-Level Chemical Evaluation for Large Language Models (https://arxiv.org/abs/2409.13989)
- **What's New**: 최근 화학 분야에서 LLMs(대형 언어 모델)가 수행하는 역할에 대한 관심이 증가하고 있으며, 이를 바탕으로 화학적 작업을 평가하기 위한 LLMs 벤치마크가 개발되고 있습니다.

- **Technical Details**: 본 연구에서는 ChemEval을 제안하며, 이는 화학 분야 내 다양한 작업에 대한 LLMs의 역량을 종합적으로 평가합니다. ChemEval은 4개의 주요 단계와 12개의 차원을 포함하여 42개의 화학 작업을 평가합니다. 이러한 작업은 오픈소스 데이터와 화학 전문가가 세심하게 구성한 데이터를 기반으로 합니다.

- **Performance Highlights**: 실험 결과, GPT-4와 Claude-3.5와 같은 일반 LLMs는 문헌 이해 및 지시 수행에서는 우수한 성능을 보이나, 고급 화학 지식이 필요한 작업에서는 부족한 성과를 보였습니다. 반면, 전문 LLMs는 향상된 화학 역량을 보여주나, 문학적인 이해력은 감소하는 경향이 있습니다. 이는 화학 분야의 복잡한 작업을 수행할 때 LLMs의 능력을 향상시킬 수 있는 잠재력을 시사합니다.



### Bias and Toxicity in Role-Play Reasoning (https://arxiv.org/abs/2409.13979)
Comments:
          14 pages, 9 figures, 9 tables

- **What's New**: 이번 논문에서는 Large Language Model (LLM)에서 역할 놀이(role-play)의 복잡한 역할과 관련된 잠재적인 위험을 체계적으로 평가하였습니다. 역할 놀이는 모델의 문맥 이해와 추론 개선을 위한 중요한 기술로 자리 잡고 있지만, 편향(bias)과 유해한 콘텐츠(harmful content) 생성의 가능성도 내포하고 있다는 점을 강조합니다.

- **Technical Details**: 우리는 다양한 벤치마크를 통해 LLM이 역할을 수행할 때의 성능 차이를 분석하였으며, 성별, 직업, 인종, 종교 등 여러 요인이 역할 놀이의 결과에 미치는 영향을 살펴보았습니다. 또한 서로 다른 LLM 간의 상호작용을 통한 실험도 진행하며 자동 역할 선택(auto-role selection)이 추론(capacity) 능력을 향상시키면서도 유해한 결과를 초래할 수 있음을 발견하였습니다.

- **Performance Highlights**: 각 벤치마크에서 모델에 따른 성능 변화를 비교한 결과, 역할에 따라 편향 및 유해성이 다르다는 것을 증명했습니다. 특정 역할을 수행할 때, LLM이 생성하는 응답의 유해성이 증가하는 경향을 보였으며, 이로 인해 역할 놀이에서의 사전 검증의 필요성이 대두되었습니다.



### Can Language Model Understand Word Semantics as A Chatbot? An Empirical Study of Language Model Internal External Mismatch (https://arxiv.org/abs/2409.13972)
Comments:
          10 pages, 1 figure, 5 tables

- **What's New**: 이 연구는 언어 모델이 단어 의미를 이해하는데 있어 내부 및 외부 표현 간의 불일치(discrepancy)를 조사합니다. 특히 Encoder-only, Decoder-only, Encoder-Decoder 모델 간의 차이를 살펴봅니다.

- **Technical Details**: 연구에서는 단어 유사성(word similarity), 구조적 예측(structured prediction), 유추(analogy)라는 세 가지 작업을 통해 언어 모델의 단어 의미 이해를 분석합니다. linear probing 방법을 사용하여 모델의 내부 상태와 외부 출력 간의 일치 여부를 평가합니다.

- **Performance Highlights**: 기존 연구와 달리, 본 연구에서는 queries와 probes 간의 유의미한 차이를 발견하였으며, 이는 단어 수준 의미를 포착하는 데 있어서 queries의 한계를 강조합니다.



### Exploring Automated Keyword Mnemonics Generation with Large Language Models via Overgenerate-and-Rank (https://arxiv.org/abs/2409.13952)
Comments:
          EMNLP 2024 findings

- **What's New**: 본 연구에서는 키워드 기억법(keyword mnemonics)이라는 언어 및 어휘 학습의 비교적 탐색이 덜 된 분야를 다루고 있습니다. 이 기술은 기억할 만한 연관성을 통해 어휘를 암기하는 방법입니다. 특히, 대규모 언어 모델(large language models, LLMs)를 활용하여 자동 생성된 기억법을 제안합니다.

- **Technical Details**: 우리는 먼저 LLM을 사용하여 음절 키워드의 집합을 생성한 다음, 해당 키워드와 관련된 언어적 단서를 생성하는 두 단계의 오버생성(overgenerate) 및 순위 매기기(rank) 방법을 제안합니다. 이 과정에서 심리언어학적(psycho-linguistic) 측정치와 사용자 연구 결과를 바탕으로 후보를 평가합니다.

- **Performance Highlights**: LLM이 생성한 기억법은 이미지 가능성(imageability), 일관성(coherence), 사용 유용성에서 인간이 작성한 기억법과 비슷하거나 더 나은 성능을 보였습니다. 그러나 언어 학습자의 배경 및 선호도에 따라 개선 여지가 아직 상당히 남아 있습니다.



### Mufu: Multilingual Fused Learning for Low-Resource Translation with LLM (https://arxiv.org/abs/2409.13949)
Comments:
          29 pages

- **What's New**: 새로운 연구에서 Mufu라는 다국어 지원 시스템을 소개하며, 이는 자동 생성된 다국어 후보를 선택하고 부정확한 번역을 수정하는 지침을 포함합니다. 이 접근 방식은 저자원 환경에서도 번역의 데이터 효율성을 극대화하여 LLM의 추론 기능을 활용합니다.

- **Technical Details**: Mufu는 번역 작업을 후편집(post-editing) 작업으로 전환시킬 수 있는 프롬프트를 사용하며, 이 프롬프트는 입력 품질을 평가하고 의미를 교차 언어적으로 맞추며 적절한 입력에서 내용을 복사하고 잘못된 경우를 무시하는 것을 포함합니다. 이 연구에서는 Flores-200 데이터셋을 기반으로 En-XX 번역에 대한 실험을 진행했습니다.

- **Performance Highlights**: Mufu 스타일의 프롬프트로 미세 조정된 LLM은 낮은 품질의 보조 번역 후보에 강인하게 나타났으며, 64%의 저자원 및 매우 저자원 언어 쌍에서 NLLB 1.3B distilled 모델보다 우수한 성능을 보였습니다. 또한, 이 모델의 증류(distillation)를 통해 추론 비용을 줄이면서도 저자원 번역에서 평균 3.1 chrF 개선을 달성하였습니다.



### Aligning Language Models Using Follow-up Likelihood as Reward Signa (https://arxiv.org/abs/2409.13948)
Comments:
          16 pages, reward model, LLM Alignment

- **What's New**: 본 논문은 사용자 피드백을 활용하여 사용자 요청에 대한 기계의 응답을 평가하는 방법을 제안합니다. 이 방법론에서는 Follow-up Likelihood as Reward (FLR) 메커니즘을 통해 응답의 선호도를 자동적으로 식별할 수 있습니다.

- **Technical Details**: FLR 메커니즘은 두 가지 주요 개념에 기반하여 설계되었습니다. 첫 번째는 사용자의 후속 발언을 보상 신호로 활용하여 응답의 유용성을 평가하는 것입니다. 두 번째는 기본 정책 모델의 온라인 세대에서 선호 데이터를 자동으로 추출하여 이 데이터를 DAP 기법을 통해 조정하는 것입니다. 이 과정에서 자연어 피드백 데이터로 언어 모델을 미세 조정하여 성능을 극대화합니다.

- **Performance Highlights**: FLR는 대규모 인간 주석 데이터 기반의 강력한 보상 모델과 성능에서 동등한 결과를 보였으며, Llama-3-8B-Instruct 모델의 Alpaca-Eval V2에서 길이 조절 승률을 4.45% 향상시켰습니다. 미세 조정을 통해 FLR는 보상 모델링 과제에서 실질적인 성능 향상을 달성했습니다.



### MirrorStories: Reflecting Diversity through Personalized Narrative Generation with Large Language Models (https://arxiv.org/abs/2409.13935)
Comments:
          5 pages (excluding references), accepted to EMNLP 2024 Main Conference

- **What's New**: 이 연구는 개인화된 '미러 스토리' 제작에 있는 대규모 언어 모델(LLMs)의 효과성을 탐구하며, 문학의 다양성이 부족한 점을 해결하려고 합니다.

- **Technical Details**: 미러 스토리는 이름, 성별, 연령, 민족, 독자 관심사 및 이야기 도덕성과 같은 요소들을 통합하여 생성된 1,500개의 개인화된 단편 이야기의 집합입니다. 이 연구는 26인의 다양한 인간 평과자를 통해 LLMs가 생성한 개인화된 이야기가 일반적인 인간 저술 및 LLM 저술의 이야기들에 비해 높은 점수를 기록함을 보여줍니다.

- **Performance Highlights**: 개인화된 LLM 생성 이야기는 참여도 모든 지표에서 평균 4.22 점(5점 만점)에 비해 3.37 점으로 일반적인 이야기들보다 뛰어난 성과를 보였습니다. 이러한 이야기는 텍스트의 다양성을 높이면서도 원래의 도덕성을 유지하는 결과를 가져옵니다.



### One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks (https://arxiv.org/abs/2409.13920)
- **What's New**: 이 논문에서는 형태학적으로 풍부한 언어인 산스크리트를 위한 새로운 프리트레인(pretrained) 언어 모델인 ByT5-Sanskrit를 소개합니다. 이 모델은 산스크리트어 단어 분할 작업에서 이전의 데이터 기반 접근 방식보다 더 나은 성과를 보여주며, 현재 최상의 어휘 기반 모델과 동일한 성능을 보입니다.

- **Technical Details**: ByT5-Sanskrit 모델은 문자 수준의 정보 처리를 기반으로 하며, 대규모 산스크리트 데이터에 대한 프리트레인 이후 여러 NLP Downstream 태스크에 대해 공동 미세 조정(fine-tuning)을 수행합니다. 이 모델은 2023년 최신 NLP 벤치마크에서 새로운 최고 성능(SOTA) 결과를 달성하였습니다.

- **Performance Highlights**: ByT5-Sanskrit는 Hackathon SWS 벤치마크에서 완벽 문장 일치 점수(PM)에서 8.8점의 성과 향상을 달성하며, SIGHUM 데이터셋에서도 현재 최고 성능 모델과 근접한 성과를 보입니다. 또한 Vedic 종속 구문 분석(UAS, LAS) 작업과 OCR 후 교정 작업에서도 기존 최고 방법을 초월한 성과를 냈습니다.



### Target word activity detector: An approach to obtain ASR word boundaries without lexicon (https://arxiv.org/abs/2409.13913)
Comments:
          Submitted to ICASSP 2025

- **What's New**: 본 연구에서는 라이선스의 의존성을 배제하고 단어 경계(word boundaries)를 추정하는 새로운 방법을 제시합니다. 이 방법은 다국어 자동 음성 인식(multilingual ASR) 모델에서 구동될 수 있으며, 여러 언어에 대해 추가 비용 없이 확장 가능합니다.

- **Technical Details**: 제안된 Target Word Activity Detector (TWAD) 모델은 서브워드 토큰 유닛으로부터 단어 임베딩을 학습하고, 이 정보를 사용해 음성 신호 내에서 단어의 활동을 식별합니다. 훈련 중에는 단어 정렬 정보만 필요하여 이전의 방법들보다 더 쉽게 적용할 수 있습니다. TWAD 모델은 기존의 CTC 및 AED 모델들과의 조합을 통해 작동합니다.

- **Performance Highlights**: 이 접근법은 영어, 프랑스어, 스페인어, 이탈리아어, 독일어 총 5개 언어로 훈련된 다국어 ASR 모델을 이용해 검증되었습니다. 성능 비교에서 강력한 베이스라인에 비해 효과적으로 단어 시간 추정(word timing estimation) 성능을 개선했음을 입증하였습니다.



### Enhancing Large Language Models with Domain-specific Retrieval Augment Generation: A Case Study on Long-form Consumer Health Question Answering in Ophthalmology (https://arxiv.org/abs/2409.13902)
- **What's New**: 대규모 언어 모델(LLM)이 의료 분야에서의 잠재력에도 불구하고, 확증되지 않은 증거를 바탕으로 하거나 허구의 (hallucinated) 증거가 포함된 반응을 생성할 수 있다는 점에서 중요한 연구 결과가 제시되었습니다. 본 연구에서는 검색 강화 생성 (RAG, Retrieval Augment Generation) 방식이 의료 분야의 하위 도메인 특정 응용 프로그램에 적용된 몇 안 되는 사례 중 하나로, 70,000개의 안과 관련 문서를 활용한 RAG 파이프라인을 개발하였습니다.

- **Technical Details**: 연구는 장문의 소비자 건강 질문에 대한 사례 연구를 통해 진행되었습니다. 100개의 질문에 대해 RAG를 사용할 경우와 사용하지 않을 경우 LLM의 답변을 10명의 의료 전문가와 함께 체계적으로 평가하였습니다. 평가 항목은 증거의 사실성(factuality), 증거 선택 및 순위 (selection and ranking), 증거 귀속(attribution), 답변의 정확성(accuracy) 및 완전성(completeness)을 포함합니다.

- **Performance Highlights**: RAG가 없는 LLM은 총 252개의 참조 문헌을 제공했으나, 45.3%가 허구였고, 34.1%는 minor error가 있었으며, 20.6%만이 올바른 정보였습니다. 반면, RAG가 적용된 경우 정확성이 크게 향상되어 54.5%가 올바른 정보로 나타났고, 오류 비율은 18.8%로 줄어들었습니다. RAG에 의해 검색된 상위 10개 문서 중 62.5%가 LLM 반응에서 주요 참조로 선택되었으며, 평균 순위는 4.9에 달했습니다. RAG의 사용은 증거 귀속에서도 개선을 보여주었으나(5점 척도에서 1.85에서 2.49로 증가, P<0.001), 정확성은 약간 감소했습니다 (3.52에서 3.23로). RAG는 의료 분야에서의 하위 애플리케이션에 대한 우려를 해소하며, 허구 및 오류의 비율을 크게 감소시켰음을 제시합니다.



### LLM for Everyone: Representing the Underrepresented in Large Language Models (https://arxiv.org/abs/2409.13897)
Comments:
          PhD thesis

- **What's New**: 이 논문은 다국어 설정에서 특히 소외된 언어에 대한 대규모 언어 모델(LLMs)의 한계를 다루고 있습니다.

- **Technical Details**: 소외된 언어에서의 LLM 능력을 평가하기 위한 포괄적인 평가가 수행되었으며, 다국어 및 다문화 일반화의 과제가 드러났습니다. 제안된 방법론은 cross-lingual continual instruction tuning, retrieval-based cross-lingual in-context learning, 및 in-context query alignment을 포함합니다. 또한, 서로 다른 언어에서 작동하는 LLM 간의 문화적 가치 일치를 측정하기 위한 새로운 방법이 제안되었습니다.

- **Performance Highlights**: 이 연구는 소외된 언어에서도 효과적인 일반화를 가능하게 하여 다국어 및 다문화 조화성을 향상시키는 것을 목표로 하고 있습니다.



### Transfer Learning with Clinical Concept Embeddings from Large Language Models (https://arxiv.org/abs/2409.13893)
- **What's New**: 이 연구는 여러 임상 사이트에서 수집된 전자 건강 기록을 분석하여 대형 언어 모델(Large Language Models, LLMs)의 의미적 임베딩이 의료 분야의 지식 전이에 미치는 영향을 평가하였습니다.

- **Technical Details**: 연구는 Med-BERT와 같은 도메인 특화 LLM이 지역 및 직접 전이 시나리오에서 일관되게 우수한 성능을 보인다는 것을 보여주었습니다. 반면에 OpenAI 임베딩과 같은 일반 모델은 최적 성능을 위해 미세 조정(fine-tuning)이 필요합니다. 그러나 생의학 임베딩을 가진 모델의 과도한 조정은 효율성을 감소시킬 가능성이 있습니다.

- **Performance Highlights**: 도메인 특정 임베딩과 신중한 모델 조정의 중요성을 강조하며, 의료 분야에서 효과적인 지식 전이를 위해 이러한 접근 방식이 필요하다는 결론에 도달했습니다.



### A Multi-LLM Debiasing Framework (https://arxiv.org/abs/2409.13884)
- **What's New**: 본 연구에서는 다중 LLM(multi-LLM) 접근 방식을 제안하여 LLM의 편향(bias)을 효과적으로 감소시키고자 합니다. 특별히, 중앙 집중식(centralized)과 분산식(decentralized) 두 가지 방법을 도입하여 비교하였으며, 분산식 방법이 우수한 성능을 보임을 확인했습니다. 이러한 방식은 사회적 그룹 내의 편향을 효과적으로 줄이는 데 기여합니다.

- **Technical Details**: 다중 LLM 프레임워크를 통해 여러 모델이 대화 방식으로 상호작용하며, 편향을 줄이는 방법을 제안합니다. 여기서 중앙 집중식 방식은 하나의 LLM이 대화를 지원하며, 분산식 방식은 모든 모델이 직접 소통합니다. 제안된 BBQ-Hard 벤치마크를 통해 두 방법을 평가하였고, BBQ-Hard 데이터셋은 LLM의 편향을 더 효과적으로 테스트할 수 있는 어려운 문제가 포함되어 있습니다.

- **Performance Highlights**: 다중 LLM 방법은 여러 사회적 그룹에서 기존의 기준 방법(baseline)보다 일관되게 더 우수한 성능을 보였습니다. 연구 결과는 다중 LLM 기반의 편향 감소 프레임워크가 LLM의 출력에서 편향을 유의미하게 줄일 수 있음을 시사합니다.



### "I Never Said That": A dataset, taxonomy and baselines on response clarity classification (https://arxiv.org/abs/2409.13879)
Comments:
          Accepted at Findings of EMNLP 2024

- **What's New**: 본 연구에서는 정치 인터뷰에서 질문에 대한 응답의 명확성을 평가하는 새로운 작업, 즉 response clarity evaluation을 제안합니다. 이를 위해 새로운 구조화된 분류 체계를 도입하고, 관련된 정치 인터뷰에서의 질문-응답(QA) 쌍으로 이루어진 데이터셋을 구축하였습니다.

- **Technical Details**: 제안한 분류 체계는 고수준의 정보 제공과 저수준의 회피 기술을 포함한 두 단계로 구성되어 있습니다. 첫 번째 단계는 응답 명확성을 세 가지 해석 수에 따라 평가하며, 두 번째 단계는 정치 문헌에서의 일반적인 11가지 회피 기법에 대한 세부적인 분류를 제공합니다. 또한, ChatGPT와 인간 주석자를 결합하여 QA 쌍을 수집하고 검증하는 과정을 거쳤습니다.

- **Performance Highlights**: 다양한 모델 아키텍처 및 적응 방법을 실험하여 제안된 데이터셋과 작업에 대한 새로운 기준을 설정하였습니다. 단순한 프롬프트와 지침 조정 기법이 높은 성능을 제공하며, 두 단계 분류 전략을 통해 회피 레이블을 사용할 경우 명확성 분류 성능이 향상되었습니다.



### Instruct-Tuning Pretrained Causal Language Models for Ancient Greek Papyrology and Epigraphy (https://arxiv.org/abs/2409.13870)
Comments:
          7 pages, 1 table. Under review

- **What's New**: 이번 연구에서는 Meta의 Llama 3.1 8B Instruct 모델을 활용하여 고대 그리스 비문과 문서 파피루스의 연대 및 지리적 속성과 텍스트 복원 작업을 위한 미세 조정을 수행하였다. 이 모델은 기존 최고 기록을 초월하였으며, 특히 문서 복원에서 고전적 및 지리적 속성 부여에서 뛰어난 성능을 보였다.

- **Technical Details**: 연구진은 문서 비문과 파피루스를 위한 데이터 세트를 수집하고, 텍스트 복원, 지리적 속성 부여 및 연대 추정을 위한 전처리 과정을 거쳤다. 모델은 문자 에러율(CER) 22.5%와 지리적 속성 부여에서 top-1 정확도 75.0%를 달성하였다. 또한, 파피루스의 텍스트 복원에서는 CER 16.3%와 top-1 정확도 71.3%를 기록하였다.

- **Performance Highlights**: 미세 조정된 모델은 고대 비문의 텍스트 복원에서 평균 22.5%의 CER을 기록했으며, 지리적 속성 부여에서 75%의 top-1 정확도를 달성하였다. 또한 고대 그리스 문서 파피루스에 대한 새로운 기준을 수립하였으며, 연대 측정에서의 평균 편차는 26.2년으로, 기존에 비해 뛰어난 성능을 보였다.



### Unlocking Memorization in Large Language Models with Dynamic Soft Prompting (https://arxiv.org/abs/2409.13853)
- **What's New**: 본 논문은 LLM(대형 언어 모델)의 암기(memorization) 문제를 해결하기 위해 동적 소프트 프롬프트(dynamic soft prompts)를 사용하는 새로운 방법을 제안합니다. 이전 방법들은 입력의 변화에 반응하지 못하는 고정된 소프트 프롬프트만을 사용했으나, 본 방법은 입력 변화에 적응할 수 있는 프롬프트를 생성합니다.

- **Technical Details**: 제안된 방법은 transformer 기반 생성기(generator)를 활용하여 입력에 따라 동적으로 변경되는 소프트 프롬프트를 생성합니다. 이는 암기된 데이터를 보다 정확히 추출할 수 있게 해줍니다. 연구 결과, 본 방법은 기존 기술들과 비교하여 뛰어난 성능을 보였으며, 다양한 실험 환경에서 검증되었습니다.

- **Performance Highlights**: 본 방법은 텍스트 생성(task)과 코드 생성(task) 모두에서 vanilla 기준선 대비 각각 112.75% 및 32.26%의 최대 상대 개선을 달성했습니다. 이를 통해 동적 소프트 프롬프트의 효과성을 입증했습니다.



### Do language models practice what they preach? Examining language ideologies about gendered language reform encoded in LLMs (https://arxiv.org/abs/2409.13852)
- **What's New**: 이번 연구는 대형 언어 모델(LLM)이 생성한 텍스트에서 언어 이데올로기(language ideologies)를 조사했으며, 특히 성별 구분이 있는 영어 표현의 개혁에 대한 사례 연구를 포함합니다. 이는 정치적 편향을 드러내고, LLM의 메타언어적 선호가 특정 정치 집단의 언어 이데올로기를 어떻게 암시적으로 전달하는지를 보여줍니다.

- **Technical Details**: 연구 결과, LLM은 '올바른(corresponding)' 또는 '자연스러운(natural)' 언어 사용에 대한 요청에 대해 보수적(conservative) 가치에 좀 더 유사한 언어를 생성하는 경향이 있음을 발견했습니다. 또한, LLM은 더 명확한 메타언어적(context) 맥락이 제공될 때 성 중립적(gender-neutral) 변형을 보다 자주 사용하는 내부 불일치(internal inconsistency)를 나타냈습니다.

- **Performance Highlights**: 이 연구는 LLM이 생성하는 텍스트에서 나타나는 언어 이데올로기가 사용자의 예상과 다를 수 있음을 강조하고, 이러한 결과가 가치 정렬(value alignment)과 관련된 더 넓은 함의를 갖고 있음을 논의합니다.



### STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions (https://arxiv.org/abs/2409.13843)
Comments:
          9 pages (excluding references), accepted to EMNLP 2024 Main Conference

- **What's New**: 본 연구에서는 Large Language Models (LLMs)에서의 명시적 및 암시적 편향을 평가하기 위한 새로운 접근 방식으로 Sensitivity Testing on Offensive Progressions (STOP) 데이터셋을 소개합니다. 이 데이터셋은 2,700개의 고유 문장을 포함하는 450개의 공격적 진행 상황을 제공하며, 다양한 심각도를 다룹니다.

- **Technical Details**: STOP 데이터셋은 9개의 인구 통계학적 그룹과 46개의 하위 인구 통계학적 그룹을 포괄하여 편향을 다양한 각도에서 평가할 수 있도록 설계되었습니다. 모델의 편향 인식 능력을 평가하기 위해 GPT-4, Mixtral, Llama 3와 같은 여러 주요 모델에 대한 실험이 수행되었습니다. 각 모델의 편향 인식 성공률은 19.3%에서 69.8%까지 다양했습니다.

- **Performance Highlights**: STOP 데이터셋을 활용하여 Llama 3-70b 모델을 파인 튜닝한 결과 BBQ, StereoSet 및 CrowS-Pairs 등에서 최대 191%의 높은 응답률을 달성하며 성능을 유지하거나 개선하는 성과를 보여주었습니다.



### Measuring Copyright Risks of Large Language Model via Partial Information Probing (https://arxiv.org/abs/2409.13831)
Comments:
          8 pages, 8 figures

- **What's New**: 본 논문은 Large Language Models (LLMs)가 저작권이 있는 콘텐츠를 생성할 수 있는 능력을 탐구합니다. 구체적으로, 저작권 내용의 일부 정보를 제공하고 생성된 콘텐츠와 원본 저작물 간의 겹침을 분석하는 방법을 사용하였습니다.

- **Technical Details**: 연구팀은 저작권이 있는 텍스트의 조각을 LLMs에 입력하고 이들이 이를 완성하도록 요청하는 실험을 진행하며, 여기에 Rouge-L Score를 사용하여 생성된 텍스트와 저작권 자료 간의 유사성을 평가하였습니다. 또한, 반복적인 프롬프트 기법을 사용하여 더 많은 저작권 침해 콘텐츠를 생성할 수 있는 가능성을 탐구했습니다.

- **Performance Highlights**: Llama, GPT-4-Turbo와 같은 대규모 매개변수를 가진 모델들이 특히 저작권 자료와 높은 유사성을 보였으며, 특정 유형의 콘텐츠에서는 성능 차이를 보였습니다. 예를 들어, GPT-4-Turbo는 노래 가사를 생성하는 데에서 더 높은 유사도를 나타냈습니다.



### Local Explanations and Self-Explanations for Assessing Faithfulness in black-box LLMs (https://arxiv.org/abs/2409.13764)
- **What's New**: 이 논문은 대규모 언어 모델(LLMs)의 충실성을 평가하는 새로운 작업을 도입했습니다. 이를 위해 로컬 섭동(local perturbations)과 자기 설명(self-explanations)을 활용한 효율적인 설명 가능성(explainability) 기술을 제안합니다.

- **Technical Details**: 이 연구에서는 LLM이 올바른 답변을 생성하는 데 필요한 충분하고 필수적인 부분을 식별하기 위해 일반적으로 사용되는 leave-one-out(LOO) 접근방식을 적용합니다. 우리는 Natural Questions 데이터셋을 사용하여 이 방법을 검증하며, LLM의 자기 설명이 실제로 모델 결정에 어떻게 기여하는지 평가하기 위해 고안된 메트릭을 제안합니다.

- **Performance Highlights**: 제안된 접근법은 모델의 결정 과정을 설명하고 충실성을 평가하는 데 매우 효과적임을 보여주었습니다. 특히 사용자의 질문에 대한 올바른 답변을 생성하는 데 중요한 키워드를 체계적으로 식별함으로써 LLM의 동작 방식에 대한 유의미한 통찰력을 제공합니다.



### Do Large Language Models Need a Content Delivery Network? (https://arxiv.org/abs/2409.13761)
- **What's New**: 이번 논문에서는 대규모 언어 모델(LLM)에서 새로운 지식을 유연하고 효율적으로 주입하는 방법으로 KV 캐시(KV caches)를 활용하는 방법에 대해 제안합니다. 기존의 fine-tuning과 in-context learning 방법에 비해 KV 캐시를 사용하는 것이 지식 주입의 모듈성(modularity) 및 효율성(efficiency)을 동시에 향상시킬 수 있다고 주장합니다. 이를 실현하기 위해 Knowledge Delivery Network(KDN)을 구상하였으며, 이는 LLM 서비스에서 KV 캐시를 동적으로 최적화하는 시스템 구성 요소입니다.

- **Technical Details**: KDN은 LLM에서 처리된 지식을 관리하는 백엔드 시스템으로, KV 캐시의 저장, 전송 및 조합을 최적화하는 기능을 갖추고 있습니다. KDN은 KV 캐시의 위계 구조와 압축을 활용하는 대규모 저장소, KV 캐시를 LLM 엔진 간에 빠르게 전송하는 스트리밍 시스템, 여러 조각의 지식을 결합하는 블렌딩 모듈을 포함합니다. 기존의 LLM 서비스 시스템과 달리 KV 캐시 관리와 LLM 서비스 엔진을 명확히 분리하여 모듈성과 효율성을 개선합니다.

- **Performance Highlights**: KDN 프로토타입 실험을 통해, KV 캐시 학습(KV-cache learning) 방법이 in-context learning과 fine-tuning 방법보다 더 나은 모듈성과 효율성을 보여줄 수 있음을 입증할 수 있는 초기 기술이 이미 연구되어 있다는 점을 강조합니다.



### Optimizing the Songwriting Process: Genre-Based Lyric Generation Using Deep Learning Models (https://arxiv.org/abs/2409.13758)
- **What's New**: 이 논문은 심층 학습 기술을 사용하여 전통적인 작사 과정을 단순화하는 방법을 제안합니다. 18,000곡의 Spotify 노래 데이터를 이용해 LSTM 기반 데이터 모델을 개발하여 장르별로 최적화된 가사를 생성하는 데 초점을 맞춰, 작사 과정을 가속화하는 목표를 세워 두 가지 모델을 비교했습니다.

- **Technical Details**: 본 연구에서는 seq2seq와 LSTM 모델을 사용하여 작업을 수행하였으며, T5 모델을 참조하여 사전 훈련된 모델과 독자적인 LSTM 모델 두 가지를 구축했습니다. 특별히, LSTM 모델의 입력으로 짧은 구문이나 단어를 받아 100자의 구문을 출력하도록 설정하고, 손실 함수는 Cross Entropy를 사용했습니다.

- **Performance Highlights**: 기본 모델이 ROUGE 메트릭에서 더 높은 리콜을 보인 반면, 두 모델 모두 BLEU 메트릭에서는 유사한 정밀도를 나타냈습니다. 생성된 가사 구문들이 특정 장르에 인식 가능하고 이해할 수 있는 수준에 이르렀음을 확인했습니다. 전체적으로, 가사 생성을 가속화하고 장르에 따른 가사를 효과적으로 생성할 수 있음을 보여주었습니다.



### Efficient Hybrid Inference for LLMs: Reward-Based Token Modelling with Selective Cloud Assistanc (https://arxiv.org/abs/2409.13757)
- **What's New**: 이번 논문에서는 고유한 하이브리드 추론(hybrid inference) 접근 방식을 제안합니다. 이 방법은 대형 언어 모델(LLMs)과 소형 언어 모델(SLMs)의 장점을 활용하면서도 비용이 많이 드는 클라우드 LLM의 의존도를 최소화합니다.

- **Technical Details**: 기존의 접근 방식은 전체 쿼리를 SLM이나 클라우드 LLM으로 라우팅하는 방식이나, 본 논문에서는 보상 기반 메커니즘(reward-based mechanism)을 도입하여 토큰 생성 중 클라우드 LLM의 참여 여부를 동적으로 결정합니다. SLM이 예측한 각 토큰은 보상 점수(reward score)로 평가되며, 이 점수가 기준치(threshold) 이하일 때만 클라우드 LLM의 도움을 요청합니다.

- **Performance Highlights**: 실험 결과, 본 기법은 클라우드 LLM의 사용을 획기적으로 줄였으며, 응답 품질에 미치는 영향은 최소한으로 유지되어 비용 효율적인 고성능 언어 모델 배포 솔루션을 제공합니다.



### Language Models Learn Metadata: Political Stance Detection Case Study (https://arxiv.org/abs/2409.13756)
- **What's New**: 이 연구에서는 정치적 입장 감지를 위한 메타데이터의 최적 통합 방법을 탐구하고, 단순한 베이지안 모델이 메타데이터만을 사용하여 기존의 모든 모델을 초월하는 성능을 보인다는 것을 보여줍니다.

- **Technical Details**: 이 논문은 ParlVote+ 데이터셋을 사용하여 정치적 발언 분석을 수행하며, 메타데이터(예: 정당 및 정책)를 포함하는 간단한 선행(prepending) 메커니즘이 더욱 효과적임을 입증합니다. MPNet 모델을 통해 텍스트 정보를 통합하고, 기존의 복잡한 모델링 방식을 비판합니다.

- **Performance Highlights**: 단순한 모델이기에도 불구하고, 이 연구는 큰 생성 언어 모델보다 소형 파인튜닝된 인코더 기반 언어 모델이 제로샷(Zero-shot) 설정에서 더 높은 성능을 나타낼 수 있다는 점을 강조합니다.



### Entity-Aware Self-Attention and Contextualized GCN for Enhanced Relation Extraction in Long Sentences (https://arxiv.org/abs/2409.13755)
- **What's New**: 본 논문에서는 기존의 의존성 기반 접근 방식의 한계를 극복하고자 Entity-aware Self-attention Contextualized GCN (ESC-GCN) 모델을 제안합니다. 이 모델은 입력 문장의 구문 구조와 의미적 문맥을 효과적으로 결합하여 관계 추출 성능을 향상시킵니다.

- **Technical Details**: ESC-GCN 모델은 상대 위치 self-attention을 통해 단어 위치와 관련된 전반적인 의미적 쌍상관성을 획득하고, 컨텍스트 그래프 컨볼루션 네트워크(Convolutional Networks)를 통해 단어 간의 복잡한 내부 문장 종속성을 포착합니다. 또한, entity-aware attention layer를 통해 최종 관계 예측을 위한 중요한 토큰을 동적으로 선택합니다.

- **Performance Highlights**: 다양한 작업에 대한 광범위한 실험에서 ESC-GCN 모델이 기존의 의존성 기반 및 시퀀스 기반 모델들에 비해 뛰어난 성능을 달성했음을 보여주었습니다. 특히 긴 문장에서의 엔티티 간 관계 추출에서 두드러진 성과를 보였습니다.



### Thinking Before Speaking: A Role-playing Model with Minds (https://arxiv.org/abs/2409.13752)
- **What's New**: 이번 논문에서는 Thinking Before Speaking (TBS) 모델을 제안하며, 역할 기반 대화에서 LLM의 성능을 개선하기 위한 새로운 접근법을 소개합니다. 이 모델은 캐릭터의 실제 시나리오를 바탕으로 데이터를 확장하고, 캐릭터의 사고 패턴을 반영하여 LLM이 더욱 사실적인 역할을 수행할 수 있도록 합니다.

- **Technical Details**: TBS 모델은 각 대화 쌍에 대해 캐릭터의 마음가짐을 보완하고, 특정 지식 이상의 질문을 포함한 일부 데이터를 추가하여 LLM을 미세 조정합니다. 이렇게 함으로써 LLM은 캐릭터의 사고 흐름과 논리를 채택하게 되며, 캐릭터의 지식 기반을 벗어나는 응답을 피할 수 있습니다. 이 연구는 새로운 데이터셋과 평가 지표를 마련하여 LLM의 능력을 시험합니다.

- **Performance Highlights**: 실험 결과, TBS 모델은 긴 대화 과정에서 톤, 지식, 마음가짐 측면에서 역할을 더 잘 모방할 수 있음을 보여주었으며, 이는 사용자 경험을 향상하는 데 기여합니다.



### KodeXv0.1: A Family of State-of-the-Art Financial Large Language Models (https://arxiv.org/abs/2409.13749)
Comments:
          11 pages, 8 figures

- **What's New**: 본 논문에서는 KodeXv0.1이라는 새로운 대형 언어 모델 패밀리를 소개합니다. 이 모델은 GPT-4를 초월하는 성능을 보이며, 주로 재무 분야에서 질문 답변을 수행하는 데 최적화되어 있습니다.

- **Technical Details**: KodeXv0.1은 Llama 3.1 8B 및 70B의 기본 변형을 사용하여 특수한 재무 영역을 위해 커스터마이즈된 교육 체계를 통해 발전되었습니다. 이를 위해 공개적으로 사용 가능한 재무 문서를 대량으로 수집하고 처리하여 Context-Question-Answer triplet 형태의 고품질 합성 데이터셋을 생성했습니다. 모델 튜닝은 RAG-aware 4bit LoRA 방법을 사용하여 수행되었습니다.

- **Performance Highlights**: 모델 평가 결과 KodeX-8Bv0.1은 동일한 매개변수 범위 내에서 최신 모델보다 최대 9.24% 더 신뢰성이 높은 결과를 보여주었고, GPT-4보다도 최대 7.07% 우수한 성능을 발휘했습니다. KodeX-70Bv0.1은 모든 테스트 벤치마크에서 GPT-4의 성능을 초과하는 개선을 나타냈습니다.



### TheraGen: Therapy for Every Generation (https://arxiv.org/abs/2409.13748)
Comments:
          12 pages, 11 figures

- **What's New**: 이번 논문에서는 LLaMA 2 7B 모델을 활용하여 개발한 고급 AI 기반 정신 건강 챗봇인 TheraGen을 소개합니다. TheraGen은 100만 개의 대화 입력 데이터를 이용하여 개인화되고 연민이 담긴 정신 건강 관리를 제공하며, 최근의 언어 모델과 트랜스포머 아키텍처의 발전을 기반으로 합니다.

- **Technical Details**: TheraGen은 transfer learning, fine-tuning 및 고급 훈련 기법을 활용하여 최적의 성능을 달성합니다. 클라우드 기반 아키텍처를 통해 고성능 및 가용성이 보장되고, 24시간 언제든지 접근할 수 있는 지원을 제공합니다. 이 시스템은 사용자 친화적인 인터페이스를 제공하여 공감적인 반응과 근거 기반 대처 전략을 제공합니다.

- **Performance Highlights**: 사용자 만족도 평가 결과에 따르면, 94%의 사용자들이 정신적 웰빙이 향상되었다고 보고했습니다. 또한, BLEU 점수는 0.67, ROUGE 점수는 0.62로 응답 정확성이 높음을 나타냅니다. 평균 응답 시간은 1395 밀리초로, 실시간으로 효율적인 지원을 보장합니다.



### Machine Translation with Large Language Models: Decoder Only vs. Encoder-Decoder (https://arxiv.org/abs/2409.13747)
- **What's New**: 본 연구는 대형 언어 모델(LLMs)을 활용하여 인도 지역 언어인 텔루구어, 타밀어, 말라얄람어를 포함한 다국어 기계 번역 모델을 개발하는 데 중점을 두고 있습니다. 특히 Decoder-only 아키텍처와 Encoder-Decoder 아키텍처를 비교하여 번역 품질과 효율성을 최적화하고자 하며, 이는 다양한 언어 쌍 간의 정확하고 맥락에 적합한 번역을 지원합니다.

- **Technical Details**: 이 연구에서는 Encoder-Decoder와 Decoder-only 모델의 성능을 평가하기 위한 체계적인 방법론을 제안합니다. In-Context Learning(Few-Shot Learning)을 통해 기계 번역 쌍을 생성하고, 이를 평가하기 위해 BLEU 메트릭을 사용합니다. XGLM과 mT5 모델을 활용하였으며, XGLM은 500백만 개의 파라미터를 가진 Decoder-only 모델이고, mT5는 3억 개의 파라미터를 가진 Encoder-Decoder 모델로서 다국어 번역에 특화되어 있습니다.

- **Performance Highlights**: 실험 결과, mT5 모델이 인도 언어 쌍에 대해 보다 높은 BLEU 점수를 기록하며 우수한 번역 품질을 보였습니다. 연구는 XGLM과 mT5의 번역 성능을 비교하여 각 모델의 최적 사용 사례와 관련된 통찰력을 제공합니다.



### When Less Is Not More: Large Language Models Normalize Less-Frequent Terms with Lower Accuracy (https://arxiv.org/abs/2409.13746)
- **What's New**: 이 연구는 대규모 언어 모델(GPT-4o)이 인체 표현형 온톨로지(HPO)를 기반으로 한 용어 정규화에서 11,225개의 고유한 용어를 처리할 때 단 13.1%의 정확도를 달성했다는 점을 강조합니다. 이는 저주파 및 긴 용어가 더 많은 정규화 오류를 초래한다는 것을 보여줍니다.

- **Technical Details**: 연구에서는 268,776개의 표현형 주석을 가지는 HPO 데이터셋을 활용하여, 용어의 빈도와 길이에 따라 정규화 정확도를 분석했습니다. 특히, SHAP 및 순열 방법을 사용하여 정규화 오류의 주요 예측 요인으로 낮은 용어 빈도를 확인했습니다.

- **Performance Highlights**: 정확도는 높은 빈도에서 시작하여, 주파수가 낮아질수록 급격히 감소했습니다. 특히 용어의 길이가 길어질수록 정확도가 떨어지는 경향이 있으며, ANOVA 분석을 통해 이 두 요인 간의 중요한 상호작용이 발견되었습니다.



### Context-Aware Membership Inference Attacks against Pre-trained Large Language Models (https://arxiv.org/abs/2409.13745)
- **What's New**: 본 논문에서는 LLM(대형 언어 모델)의 사전 훈련 과정에서 발생하는 맴버십 추론 공격(Membership Inference Attack, MIA)의 새로운 접근 방식을 제안합니다. 기존 MIA는 LLM의 순차적 텍스트 생성 과정을 고려하지 않았습니다.  본 연구에서는 MIA 통계 테스트를 데이터 포인트의 서브시퀀스(perplexity dynamics)에 적응시켜 효과적인 공격을 수행했습니다.

- **Technical Details**: CAMIA(상황 인식 맴버십 추론 공격) 프레임워크를 설계하여 LLM의 다음 토큰 예측 손실(sequence of next-token prediction losses)에서 조정된 맴버십 정보를 추출합니다. 이 방법은 프리픽스(prefix)의 길이, 다양성, perplexity 등의 맥락적 요소를 반영하여 조정된 테스트를 수행합니다. 손실의 기울기, 변동성, 이상치는 멤버와 비멤버를 구분하는 데 중요한 지표입니다. 이러한 동적 행동을 통해 모델의 다양한 상황에 따라 공격 결정을 조정합니다.

- **Performance Highlights**: CAMIA는 Pythia와 GPT-Neo 모델을 포함한 9999개의 사전 훈련된 LLM을 대상으로 평가했으며, 기존 MIA보다 3배 더 많은 멤버를 성공적으로 식별했습니다. 예를 들어, Pythia 모델에서 CAMIA는 1%의 특정 잘못 예측률(FPR)에서 3.35배 높은 진짜 긍정률(TPR)을 달성했습니다. GPT-Neo 모델에서도 TPR이 20% 증가했습니다. 이는 다양한 데이터 도메인에서 일관되게 높은 성능을 보였습니다.



### A Simplified Retriever to Improve Accuracy of Phenotype Normalizations by Large Language Models (https://arxiv.org/abs/2409.13744)
Comments:
          Submitted to Frontiers in Digital Health

- **What's New**: 이 연구는 생물 의학에서 주로 사용되는 딥 러닝 모델을 사용하여 표현형 용어 정규화의 정확성을 향상시키는 새로운 방법을 제안하고 있습니다. 특히 BioBERT를 사용한 문맥적 단어 임베딩에 기반하여 복잡한 정의 생성 없이 빠르고 효과적으로 후보 용어를 매칭시키는 간소화된 검색기를 도입했습니다.

- **Technical Details**: 제안된 방법은 검증된 1,820개의 표현형 용어에 대해 Human Phenotype Ontology (HPO)와의 코사인 유사성을 기준으로 키워드 후보를 선택하고, 이를 통해 LLM이 의미론적으로 가장 적당한 정규화를 선택하게 합니다. LLM은 GPT-4o를 사용하게 되며, 이 과정에서 BioBERT를 통한 두 가지 실험 조건과 LLM + Retriever 방식이 비교됩니다.

- **Performance Highlights**: 정규화 정확도는 기존 62.3%에서 90.3%로 향상되었습니다. 특히 LLM + Retriever 방법은 BioBERT 방법보다 높은 정확도를 보이며, 자동화된 정규화 솔루션의 필요성을 충족할 수 있는 잠재력을 보여줍니다.



### Knowing When to Ask -- Bridging Large Language Models and Data (https://arxiv.org/abs/2409.13741)
Comments:
          39 pages - 25 page paper, 14 page Appendix, 7 figures, 9 tables

- **What's New**: 이번 연구는 대형 언어 모델(LLMs)의 정확성을 향상시키기 위한 새로운 접근 방식을 소개합니다. 데이터 커먼스(Data Commons)라는 신뢰할 수 있는 통계 데이터를 제공하는 오픈 소스 데이터 저장소와 통합하여 모델의 성능을 개선하고자 하였습니다.

- **Technical Details**: 이 논문에서는 두 가지 주요 방법론을 사용합니다: 1) Retrieval Interleaved Generation (RIG), 이 방법은 LLM이 데이터 커먼스로부터 정보를 검색하기 위해 자연어 쿼리를 생성하도록 훈련됩니다. 2) Retrieval Augmented Generation (RAG), 이 방법에서는 관련 데이터 테이블을 데이터 커먼스에서 가져오고 이를 사용하여 LLM의 프롬프트를 보강합니다.

- **Performance Highlights**: 제안된 방법은 다양한 쿼리에 대해 평가되었으며, LLM 출력의 사실적 정확성을 향상시키는 데 있어 효과적임을 입증했습니다. 이는 확인 가능한 통계 데이터에 기반하여 더 신뢰할 수 있는 LLM 구축을 위한 초기 단계로 자리잡고 있습니다.



### Language agents achieve superhuman synthesis of scientific knowledg (https://arxiv.org/abs/2409.13740)
- **What's New**: 이번 연구에서는 PaperQA2라는 고급 언어 모델을 개발하여 과학 문헌 검색 과제에서 인간 전문가와의 성능 비교를 수행했습니다. 결과적으로 PaperQA2는 정보 검색, 요약 및 모순 탐지 작업에서 주제 전문가를 초월할 수 있음을 입증하였습니다.

- **Technical Details**: 연구의 핵심은 PaperQA2를 활용하여 적용된 LitQA2 벤치마크를 통해 과학 문헌에 대한 정보 검색, 요약 및 모순 탐지의 성능을 평가한 점입니다. PaperQA2는 ‘retrieval-augmented generation (RAG)’ 접근 방식을 사용하여, 여러 단계의 작업을 통해 최종 응답을 생성합니다. 각 질문에 대해 평균 14.5개의 논문을 활용하였으며, 정확도는 66.0%로 나타났습니다.

- **Performance Highlights**: PaperQA2는 LitQA2 벤치마크에서 85.2%의 정밀도와 66.0%의 정확도를 기록하였으며, 생물학 논문에서 평균 2.34개의 모순을 발견하는 데 성공했습니다. 이 연구는 AI 모델이 특정 과학 문헌 작업에서 인간 전문가보다 뛰어난 성능을 보여줄 수 있음을 실증적으로 나타냈습니다.



### Table-to-Text Generation with Pretrained Diffusion Models (https://arxiv.org/abs/2409.13739)
Comments:
          IEEE Access

- **What's New**: 이 논문에서는 확산 모델(‘diffusion models’)의 새로운 적용 방식에 대해 다루고 있습니다. 특히, 표(table)에서 텍스트로의 변환(table-to-text) 문제에 대한 효과적인 솔루션을 모색하였고, DPM-Solver++라는 최신 확산 모델 가속기를 핵심 모델에 도입하여 샘플링 전략의 영향을 분석했습니다.

- **Technical Details**: 확산 모델은 여러 단계의 노이즈 제거 과정을 통해 높은 품질의 출력을 생성하는 반복 생성형 모델입니다. 본 연구에서는 GENIE 모델을 사용하여 ToTTo 도전 과제에 적용하였고, 생성 출력의 길이 제한, 예측 집계 방법(ROVER 및 Minimum Bayes-Risk)과 같은 여러 요소의 영향을 조사했습니다. 또한, 다양한 온도 설정에서 자동 회귀(text-to-text) 모델과의 비교를 통해 모델의 성능을 평가했습니다.

- **Performance Highlights**: 본 연구 결과, 확산 모델은 자동 회귀 모델에 비해 품질과 다양성 간의 균형을 유지하며 경쟁력 있는 결과를 도출할 수 있음을 발견했습니다. 특히, 가장 높은 품질을 위해서는 엄격한 길이 제약을 가진 일반 샘플러 사용 후 MBR을 통한 예측 집aggregating 방법이 바람직하며, 높은 수준의 다양성을 포기하고 처리 속도를 높이기를 원한다면 DPM-Solver++와 같은 빠른 샘플러를 활용할 수 있습니다.



### NLP4PBM: A Systematic Review on Process Extraction using Natural Language Processing with Rule-based, Machine and Deep Learning Methods (https://arxiv.org/abs/2409.13738)
- **What's New**: 이 문헌 리뷰에서는 텍스트 설명을 구조화된 프로세스로 변환하는 자동화된 프로세스 추출 분야를 연구하였습니다. 최근 Machine Learning (ML) 및 Deep Learning (DL) 방법들이 Natural Language Processing (NLP) 구성 요소에 점점 더 많이 사용되고 있으며, 이들은 전통적인 규칙 기반 방법보다 더 나은 성능을 보여주고 있습니다.

- **Technical Details**: 논문에서는 자동화된 프로세스 추출의 방법론으로 NLP와 프로세스 생성을 두 단계로 나누어 설명합니다. 첫 번째 단계인 NLP에서는 텍스트의 기본 구성 요소를 분류하고, 두 번째 단계인 프로세스 생성에서는 NLP 출력을 프로세스 모델로 변환하여 제어 흐름(control-flow)과 결정적 요소(decisional elements)를 캡처합니다. 최근에는 Transformers(예: BERT), Long Short-Term Memory (LSTM)와 같은 DL 모델이 많이 사용되고 있으며, Large Language Models (LLMs)의 출현으로 이 분야에 대한 관심이 증가하고 있습니다.

- **Performance Highlights**: 자동화된 프로세스 추출이 정확하고 신뢰할 수 있게 이루어진다면, 효율성을 크게 향상시킬 수 있습니다. 그러나 현재 금준 스탠다드, 스케일러블 주석 데이터셋의 부족은 객관적인 평가와 ML/DL 방법의 교육에 걸림돌이 되고 있습니다. 이 연구에서는 NLP 도구 및 ML/DL 기반의 최신 연구 결과를 반영하여 프로세스 추출에 대한 시스템 리뷰를 제공합니다.



### Analysis of Socially Unacceptable Discourse with Zero-shot Learning (https://arxiv.org/abs/2409.13735)
- **What's New**: 이번 연구는 Socially Unacceptable Discourse (SUD) 분석을 위한 새로운 접근법으로, Entailment 기반 (based) 제로샷 텍스트 분류 (text classification) 방법을 제안합니다. 이 방법은 사전 훈련된 (pre-trained) 변환기 모델 (transformer models)과 프롬프트 기법 (prompting techniques)을 활용하여 SUD 탐지 및 특성 분석에 효과적임을 보여줍니다.

- **Technical Details**: 연구에서는 사전 훈련된 변환기 모델을 바탕으로 SUD 분석을 수행하며, 레이블이 없는 데이터에서 효과적으로 작동하는 제로샷 텍스트 분류 방식을 사용합니다. 이를 통해 극단주의 서사 (extremist narratives)를 분석하고 특성화하기 위한 레이블이 있는 데이터셋 생성이 가능함을 강조합니다.

- **Performance Highlights**: 연구 결과는 모델이 이전에 보지 못한 데이터에 대해 우수한 일반화 능력 (generalization capabilities)을 갖추고 있음을 증명하였으며, SUD 연구 및 온라인 책임 있는 소통을 촉진하기 위한 강력한 도구 개발에 기여할 것으로 기대됩니다.



### Enhancing Kurdish Text-to-Speech with Native Corpus Training: A High-Quality WaveGlow Vocoder Approach (https://arxiv.org/abs/2409.13734)
- **What's New**: 이 논문은 중앙 쿠르드어(Central Kurdish, CKB)에 맞춘 새로운 TTS(텍스트-투-스피치) 시스템의 개발을 다룹니다. 기존의 영어 사전 훈련 모델 대신 21시간의 중앙 쿠르드어 음성 말뭉치(corpus)를 사용하여 커스텀 WaveGlow 보코더(vocoder)를 훈련시켰습니다.

- **Technical Details**: 기존의 Tacotron 기반 시스템을 개선하여, 중앙 쿠르드어에 특화된 WaveGlow 보코더를 훈련했습니다. 이는 쿠르드어의 음소(phonetic) 및 억양(prosodic) 변화를 정확하고 유창하게 적용하기 위해 필요합니다.

- **Performance Highlights**: 최종적으로, 제안된 어댑티브 WaveGlow 모델은 4.91의 MOS(mean opinion score)를 달성하며, 이는 쿠르드어 음성 합성의 새로운 기준을 제시합니다. 이 연구는 중앙 쿠르드어 TTS 시스템의 고급 기능을 강화하며, 다른 쿠르드어 방언과 관련 언어의 발전에도 기여할 수 있는 가능성을 열었습니다.



### RNR: Teaching Large Language Models to Follow Roles and Rules (https://arxiv.org/abs/2409.13733)
- **What's New**: 이 논문에서는 기존의 Instruction Fine-Tuning (IFT) 모델이 복잡한 역할과 규칙을 따르는 데 실패한다는 문제를 해결하기 위해 RoleNRules (RNR)라는 데이터 생성 파이프라인을 제안합니다. 이 파이프라인은 기존 IFT 지침으로부터 다양한 역할과 규칙을 자동으로 생성하여 LLM 모델의 성능을 향상시킵니다.

- **Technical Details**: RoleNRules는 고유한 (system prompt, instruction, response) 트리플을 생성하여 모델이 복잡한 시스템 prompt를 따르도록 훈련할 수 있도록 설계된 데이터 생성 파이프라인입니다. 이 과정에서 LLM을 통해 다양한 역할(description)과 규칙(rules)을 생성하고, 생성된 시스템 prompt와 원래 지침을 기반으로 응답을 생성합니다.

- **Performance Highlights**: RNR로 훈련된 모델은 Traditional Instruction Fine-Tuning에 비해 25% 이상 증가한 규칙 준수 pass-rate를 기록했으며, 일반적인 지침을 따르는 성능 저하 없이 복잡한 지침을 계속해서 따를 수 있는 능력을 유지했습니다.



### TopoChat: Enhancing Topological Materials Retrieval With Large Language Model and Multi-Source Knowledg (https://arxiv.org/abs/2409.13732)
- **What's New**: 대규모 언어 모델(LLMs)을 활용하여 특정 분야의 요구를 충족시키고 대규모 처리를 최적화하는 새로운 접근 방식을 제안합니다. 이를 위해 재료 지식 그래프(MaterialsKG)를 구축하고, 이를 문헌과 통합하여 토폴로지 재료를 위한 대화 시스템인 TopoChat을 개발했습니다.

- **Technical Details**: 이 시스템은 여러 출처의 데이터를 통합하고, 실험 및 이론 계산에서 생성된 방대한 양의 정보를 이용하여 효율적인 정보 검색을 가능하게 합니다. TopoChat은 복잡한 질문에 대해 더 나은 성능을 발휘하며, 재료 추천 및 관련 관계 추론 과제를 수행할 수 있습니다.

- **Performance Highlights**: TopoChat은 기초 LLM에 비해 구조 및 속성 질의, 재료 추천, 복잡한 관계 추론에서 우수한 성능을 보였습니다. 이는 효율적이고 정밀한 정보 검색을 가능하게 하여 응축 물질 분야의 발전을 촉진합니다.



### KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation (https://arxiv.org/abs/2409.13731)
Comments:
          33 pages

- **What's New**: Knowledge Augmented Generation (KAG)은 전문 도메인 지식 서비스를 위한 새로운 프레임워크로, 기존의 Retrieval-Augmented Generation (RAG)의 한계를 극복하기 위해 개발되었습니다. KAG는 Knowledge Graph (KG)와 벡터 검색의 장점을 결합하여 대규모 언어 모델(LLMs)과 KG의 상호 작용을 통해 생성 및 추론 성능을 향상시키는 것을 목표로 합니다.

- **Technical Details**: KAG는 다섯 가지 핵심 요소를 통해 LLM 친화적인 지식 표현(LLMFriSPG), 지식 그래프와 원래 텍스트 청크 간의 상호 색인화, 논리적 형태 기반의 하이브리드 추론 엔진, 의미론적 추론에 따른 지식 정렬, KAG를 위한 모델 기능 향상을 설계하였습니다. 이 프레임워크는 복잡한 Q&A 데이터셋에서 성능을 평가하여 상당한 개선 결과를 나타냈습니다.

- **Performance Highlights**: KAG는 2wiki에서 19.6%, hotpotQA에서 33.5%의 F1 점수를 개선하며 기존의 RAG 방식보다 전문성이 크게 강화된 결과를 보여주었습니다. 또한, KAG는 Ant Group의 E-Government 및 E-Health Q&A 작업에 적용되어 전통적인 RAG 방법에 비해 높은 정확도를 기록하였습니다.



### MathGLM-Vision: Solving Mathematical Problems with Multi-Modal Large Language Mod (https://arxiv.org/abs/2409.13729)
Comments:
          30 pages,19 figures

- **What's New**: 이 논문에서는 다양한 시각적 요소가 포함된 수학 문제를 해결하기 위한 MathGLM-Vision이라는 다중 모달 대형 언어 모델(Multi-Modal Large Language Model, MLLM)을 소개합니다. 특히 이 모델은 MathVL이라는 세밀하게 조정된 데이터셋을 사용하여 수학 문제를 해결하는 데 필요한 시각적 정보를 통합하도록 설계되었습니다.

- **Technical Details**: MathGLM-Vision은 GLM-4V-9B, CogVLM2, CogVLM-32B를 기초 모델로 하여 Fine-Tuning(미세 조정)을 진행하였으며, 다양한 매개변수 크기로 구성됩니다. MathVL 데이터셋은 산술, 대수학, 기하학 등 다양한 수학적 주제를 포함하고, 각 문제에는 단계별 솔루션이 제공되어 모델의 문제 해결능력을 향상시킵니다.

- **Performance Highlights**: MathGLM-Vision은 MathVL-test에서 시각적 입력을 포함한 경우, 텍스트 입력만을 사용한 모델에 비해 더 우수한 성능을 보였습니다. 예를 들어, 기하학 문제 해결(minitest)에서는, MathGLM-Vision-9B가 GLM-4V-9B에 대해 39.68% 성능 개선을, MathGLM-Vision-19B가 CogVLM2에 대해 65.06% 성능 개선을 보였습니다.



### Rule Extrapolation in Language Models: A Study of Compositional Generalization on OOD Prompts (https://arxiv.org/abs/2409.13728)
- **What's New**: 이번 연구는 autoregressive LLMs(대량의 언어 모델)의 OOD(out-of-distribution) 행동을 이해하기 위해 새로운 개념인 'rule extrapolation'을 정의했습니다. 이 개념은 프롬프트가 최소한 하나의 규칙을 위반하는 OOD 시나리오를 설명합니다.

- **Technical Details**: 연구에서는 규칙의 교차점으로 정의된 형식 언어(formal languages)에서의 OOD 구성 일반화(compositional generalization)를 고려했습니다. 다양한 복잡성의 형식 언어를 통해 Transformer, 선형 및 순환 아키텍처, 상태 공간 모델(state space models)에서 규칙 외삽(rule extrapolation)을 평가하였습니다.

- **Performance Highlights**: 연구는 Solomonoff prior(솔로모프 우선)에서 영감을 받은 규칙 외삽의 규범 이론(n normative theory)의 기초를 세우며, LLMs의 아키텍처가 규칙 외삽에 미치는 영향을 이해하는 데 중요한 통찰을 제공합니다.



### Classification performance and reproducibility of GPT-4 omni for information extraction from veterinary electronic health records (https://arxiv.org/abs/2409.13727)
Comments:
          24 pages, 3 figures, 8 supplementary figures

- **What's New**: 이번 연구는 수의학 전자 건강 기록(EHRs)에서 정보 추출을 위한 대형 언어 모델(LLMs)의 성능 차이 및 환경 설정(temperature settings)의 영향을 평가한 최초의 연구입니다. 특히 GPT-4 omni(GPT-4o)와 GPT-3.5 Turbo 모델 간의 비교를 통해 LLM 오류와 인간 관찰자 간의 합의 관계를 조사하였습니다.

- **Technical Details**: 연구는 250개의 EHRs를 분석하여 GPT-4o와 GPT-3.5 Turbo의 성능을 비교하였고, 여섯 가지 임상 징후를 식별하는 작업을 수행했습니다. GPT-4o는 0 온도에서 96.9%의 민감도(sensitivity), 97.6%의 특이도(specificity), 80.7%의 양성 예측 값(positive predictive value) 등 매우 높은 성능을 보였습니다. 반면에 GPT-3.5 Turbo는 오직 81.7%의 민감도를 기록했습니다.

- **Performance Highlights**: GPT-4o는 온도의 영향을 받지 않았으며, 인간 쌍 대비 평균 Cohen's kappa가 0.98로 뛰어난 재현성을 보여주었습니다. 또한 GPT-4o의 오류 대부분은 인간 간의 의견 불일치에서 발생하였으며, 이는 EHR의 모호성(ambiguity)에 기인함을 시사합니다. 따라서, GPT-4o는 수의학 EHR 정보 추출 자동화에 있어 유망한 대안으로 제시됩니다.



### Multilingual Dyadic Interaction Corpus NoXi+J: Toward Understanding Asian-European Non-verbal Cultural Characteristics and their Influences on Engagemen (https://arxiv.org/abs/2409.13726)
Comments:
          8 pages. 6 figures. International Conference on Multimodal Interaction, November 4-8, 2024, San Jose, Costa Rica

- **What's New**: 이번 연구에서는 비언어적 행동이 문화에 따라 어떻게 차별화되는지를 분석하고, 이러한 차이가 대화의 참여도(engagement) 인식에 미치는 영향을 평가하기 위해 다국어(multi-lingual) 비언어적 기능을 COMPUTATIONAL 분석했습니다. 이를 위해 기존의 NoXi 데이터셋을 확장하여 일본어와 중국어로 이루어진 대화 데이터가 포함된 새로운 데이터셋 NoXi+J를 구성했습니다.

- **Technical Details**: 비언어적 특성(non-verbal features)에는 음성 음향(speech acoustics), 표정(facial expressions), 백채널(backchanneling), 제스처(gestures)가 포함됩니다. 다양한 패턴 인식 기법을 통해 이러한 특성을 추출하고, 통계적 분석을 통해 각 언어에서 문화적으로 의존적이고 독립적인 특징을 식별했습니다. 최종적으로 LSTM(Long Short-Term Memory) 모델을 훈련하여 대화의 참여도를 예측하고, SHAP(Shapley Additive Explanations) 분석을 통해 입력 특성과 문화적 특성 간의 상관관계를 분석했습니다.

- **Performance Highlights**: 여섯 개의 기계 학습 모델이 NoXi+J 데이터셋의 서로 다른 언어 화자(subsets)에서 훈련되어 성능을 평가했습니다. 모델의 성능 결과는 분석 결과와 상관관계를 나타내며, 다양한 언어의 비언어적 특성에 따라 성능이 달라지는 것을 확인했습니다. 이 연구는 문화 차이에 대한 인식뿐만 아니라, 비언어적 소통과 대화 참여도의 예측에 있어 기계 학습의 중요성을 강조합니다.



### Identity-related Speech Suppression in Generative AI Content Moderation (https://arxiv.org/abs/2409.13725)
- **What's New**: 이 논문은 자동화된 콘텐츠 조정 시스템에서 마이너리티(미소수) 집단과 관련된 발언 억압(speech suppression)을 정의하고 측정하기 위한 새로운 벤치마크를 제시합니다. 현재 사용되는 콘텐츠 조정 API가 특정 정체성 집단에 대해 어떻게 차별적으로 작용하는지를 분석합니다.

- **Technical Details**: 본 연구에서는 콘텐츠 조정 API의 성능을 평가하기 위해, 사용자 생성 데이터셋과 생성 AI에 특화된 데이터셋을 포함한 총 7개 벤치마크 데이터셋을 사용했습니다. 아울러, 9개 정체성 카테고리를 사용하여 텍스트 데이터를 태그하는 방법론을 공개했습니다. 연구는 활성화된 API에서의 잘못된 태깅과 관련된 문제를 다루면서, 특정 정체성 그룹의 발언이 더 자주 억압(inappropriately flagged)되는지를 확인했습니다.

- **Performance Highlights**: 연구 결과, 자동화된 콘텐츠 조정 시스템은 모든 정체성 그룹에서 관련 발언을 더 자주 억압하며, 기독교 및 이성애자(group) 외의 모든 그룹에 대해 이질적인 결과를 보였습니다. 여러 API 간의 차이점을 분석하여, 생성 AI 콘텐츠의 적절한 조정 능력에 대한 정보를 제공합니다.



### Logically Consistent Language Models via Neuro-Symbolic Integration (https://arxiv.org/abs/2409.13724)
- **What's New**: 이번 연구는 대규모 언어 모델(LLM)의 논리적 일관성을 향상시키기 위해 신경-기호적 추론(neuro-symbolic reasoning)을 기반으로 한 손실(loss) 개념을 도입했습니다. 이를 통해 LLM이 외부의 사실(facts)과 규칙에 논리적으로 일관되도록 학습할 수 있게 하여, LLM의 자가 일관성(self-consistency)을 개선했습니다.

- **Technical Details**: 연구에서는 LLM을 훈련시키는 동안, 강화된 샘플 모델의 확률을 최대화하는 원칙적 목적(objective)을 수립했습니다. 이 방법은 추론 레퍼토리를 잠재적으로 확장하면서, LLM이 제공된 논리적 제약조건에 따라 진실성을 유지하도록 합니다. 실험을 통해, 제한된 사실 세트에 대해 훈련 받은 LLM이 새로운 사실에 대한 진실 신념을 학습할 수 있음을 보였습니다.

- **Performance Highlights**: LoCo-LMs(논리적으로 일관된 LLMs)로 명명된 이번 모델은 외부 해결기(solvers)에 의존하지 않고도, 자가 일관성과 사실성을 향상시킨 것으로 나타났습니다. 제한된 데이터 환경에서도, 기존의 감독적 fine-tuning에 비해 더 우수한 성능을 보였습니다.



### LegiLM: A Fine-Tuned Legal Language Model for Data Complianc (https://arxiv.org/abs/2409.13721)
Comments:
          9 pages, 2 figures

- **What's New**: 이 논문에서는 데이터 보안 및 개인 정보 보호 규정을 준수하기 위해 특별히 설계된 법률 언어 모델인 LegiLM을 소개합니다. LegiLM은 GDPR 법안에 대한 사전 훈련을 기반으로 하여, 특정 행동이나 사건이 데이터 보안 및 개인 정보 보호 규정을 위반했는지를 자동으로 평가할 수 있습니다.

- **Technical Details**: LegiLM 모델은 영어권 법률 자료에서 수집된 전문 법률 데이터로 광범위하게 사전 훈련되었으며, GDPR 관련 데이터셋을 통해 세밀하게 미세 조정되었습니다. 이 모델은 고급 법적 추론 방법과 정보 검색 기술을 통합하여 실제 법률 상담 시의 정확성과 신뢰성을 향상시킵니다.

- **Performance Highlights**: 우리의 평가 결과, LegiLM은 데이터 규제 위반 탐지에서 뛰어난 성능을 보였으며, 이를 통해 적절한 법적 정당성을 제공하고 필요한 준수 수정 사항을 추천할 수 있음을 입증했습니다. 이로 인해 AI 기반의 법적 준수 솔루션의 새로운 기준을 세우게 되었습니다.



### DiVA-DocRE: A Discriminative and Voice-Aware Paradigm for Document-Level Relation Extraction (https://arxiv.org/abs/2409.13717)
- **What's New**: 이번 연구에서는 Document-level Relation Triplet Extraction (DocRTE)을 위한 혁신적인 접근 방식인 DiVA(Discriminative and Voice Aware Paradigm)를 소개합니다. DiVA는 문서 수준에서의 관계 추출을 단순화하여 관계를 식별하기 위해 단순히 문서를 입력하는 방식으로 작동합니다.

- **Technical Details**: DiVA는 두 가지 주요 단계로 구성됩니다: (1) 관계 추출을 위한 문서 수준의 차별화(paradigm) 방식, (2) 추출된 관계에 기반하여 주체와 객체 엔티티를 식별하는 음성 인식(voice-aware) 방식. 이러한 접근 방식을 통해 모델은 문서 전체의 맥락을 이해하고 관계의 방향성 및 음성의 영향을 감지할 수 있습니다.

- **Performance Highlights**: 실험 결과, Re-DocRED 및 DocRED 데이터셋에서 DiVA는 DocRTE 작업에 대해 최고의 성능(SOTA)을 기록했습니다. 기존 방법론들과 비교했을 때, 더 많은 관계 유형을 처리하고, 음성을 고려한 주체와 객체 구분에서 우수한 결과를 보여줍니다.



### Constrained Multi-Layer Contrastive Learning for Implicit Discourse Relationship Recognition (https://arxiv.org/abs/2409.13716)
- **What's New**: 이번 연구에서는 암시적 담화 관계 인식(IDRR)을 위한 새로운 접근 방식으로 감독 대조 학습(supervised contrastive learning, CL) 방법을 제안합니다. 특히, 레이블 및 인스턴스 중심의 대조 학습(label- and instance-centered CL)을 통해 표현 학습을 강화하고, 어휘적으로 제약된 다층 대조 학습(constrained multi-layer CL) 기법을 소개하여 상위 층의 대조 손실이 하위 층보다 작도록 제약을 둡니다.

- **Technical Details**: IDRR을 수행하기 위해 복잡한 다층 신경망(multi-layer neural networks)을 사용했던 기존 방법과 달리, 본 논문에서는 단순하면서도 효과적인 레이블 및 인스턴스 중심 대조 학습(LICL)을 각 레이어에 적용합니다. 이를 통해 여러 레이어에서 LICL을 적용할 때 발생할 수 있는 중복을 줄이기 위한 제약을 추가한 CMCL(Constrained Multi-layer Contrastive Learning) 방식을 개발하였습니다.

- **Performance Highlights**: PDTB 2.0 및 PDTB 3.0 데이터셋에서 실험 결과, 제안한 접근 방식이 다중 클래스 분류(multi-class classification)와 이진 분류(binary classification) 모두에서 성능을 크게 향상시켰음을 보여줍니다. 특히, 중간 레이어에 LICL을 적용하는 것 만으로도 기존 모델에 비해 상당한 개선을 이루었습니다.



### Introducing MeMo: A Multimodal Dataset for Memory Modelling in Multiparty Conversations (https://arxiv.org/abs/2409.13715)
- **What's New**: MeMo 코퍼스는 참가자의 기억 유지 보고서로 주석이 달린 최초의 대화형 데이터세트로, 컴퓨터 모델링을 위한 소중한 자원으로 제공됩니다.

- **Technical Details**: MeMo 코퍼스는 Covid-19 주제에 대한 31시간 분량의 소규모 그룹 토론을 포함하며, 행동 및 지각 측정이 검증된 데이터와 함께 오디오, 비디오, 다중 모달 주석을 통합하고 있습니다. 이 데이터셋은 대화 기억 및 그룹 역학 연구에서 유용한 자료가 됩니다.

- **Performance Highlights**: MeMo 코퍼스는 대화 기억 모델을 구축하는 데 활용 가능하며, 이를 통해 사용자의 기억 및 사회적 상호작용에 대한 이해를 진전시킬 수 있습니다.



### TracrBench: Generating Interpretability Testbeds with Large Language Models (https://arxiv.org/abs/2409.13714)
Comments:
          6 pages + appendix, 4 figures, ICML Mechanistic Interpretability Workshop

- **What's New**: 이 연구에서는 트랜스포머(tansformer) 기반 언어 모델의 해석 가능성(interpretability)을 평가하기 위한 새로운 접근법을 제시합니다. 특히 TracrBench라는 새로운 데이터셋을 소개하며, 이는 121개의 수작업으로 작성된 RASP 프로그램과 LLM(대형 언어 모델) 생성, 인간 검증의 결과로 구성되어 있습니다.

- **Technical Details**: Tracr는 RASP에서 본래의 사실 기반 매핑(ground truth mappings)을 가진 컴파일된 트랜스포머 모델을 생성하는 방법입니다. TracrBench는 해석 가능성 평가 방법들을 검증하기 위해 고안된 테스트베드(test bed)로, LLM을 활용하여 RASP 프로그램을 자동으로 생성하고자 했으나, 이 과정에서 많은 도전과제가 있음을 발견했습니다.

- **Performance Highlights**: 최신 LLM인 GPT-4-turbo는 20-shot 프롬프트와 best-of-5 샘플링을 사용하였으나, 총 101개 테스트 프로그램 중 57개만을 올바르게 구현했습니다. TracrBench는 이러한 과정을 통해 해석 가능성 방법의 평가 및 비교를 위한 가치 있는 테스트베드 역할을 목표로 하고 있습니다.



### Sentiment Informed Sentence BERT-Ensemble Algorithm for Depression Detection (https://arxiv.org/abs/2409.13713)
- **What's New**: 세계 보건 기구(WHO)는 약 2억8000만명이 우울증으로 고통받고 있다고 발표했습니다. 하지만 머신러닝(ML) 기법을 활용한 초기 우울증 탐지에 대한 기존 연구는 제한적입니다. 본 연구는 여러 ML 알고리즘의 성능을 검토하여 초기 우울증 탐지를 개선하는 데 중점을 두었습니다.

- **Technical Details**: 우리는 두 개의 기준 소셜 미디어 데이터셋(D1, D2)을 사용하여 ML 알고리즘의 성능을 분석했습니다. 추가적으로 감정 지표(sentiment indicators)를 통합하여 모델의 성능을 향상시켰습니다. 실험 결과, 문장 양방향 인코더 표현(SBERT)에서 추출한 숫자 벡터를 스태킹 앙상블(stacking ensemble) 모델에 적합시켜 D1 데이터셋에서 69%, D2 데이터셋에서 76%의 F1 점수를 달성했습니다.

- **Performance Highlights**: 감정 지표를 추가적인 특성으로 활용하는 것이 우울증 탐지 모델의 성능 향상에 기여함을 보여주었으며, 향후 연구를 위해 우울증 용어 말뭉치(depressive term corpus)의 개발을 추천합니다.



### Good Idea or Not, Representation of LLM Could (https://arxiv.org/abs/2409.13712)
- **What's New**: 이 논문은 과학적 아이디어를 정량적으로 평가하는 새로운 프레임워크를 제안하며, 대형 언어 모델(LLMs)로부터 얻은 표현을 활용하여 아이디어의 가치를 정량화하는 방법을 탐구합니다. 또한, 약 4,000개의 원고로 구성된 벤치마크 데이터 세트를 공개합니다.

- **Technical Details**: 우리는 LLM의 특정 계층에서 생산된 표현을 사용하여 아이디어의 가치를 정량화하는 프레임워크를 수립하였습니다. 이 연구는 LLM의 표현을 통해 텍스트의 의미론적 특징을 인코딩하고 이를 다양한 아이디어 평가 방법과 결합하여 학문적 질적 평가를 목표로 합니다.

- **Performance Highlights**: 실험 결과, LLM에서 생성된 표현은 인간의 판단과 높은 일관성을 보여주었으며, LLM의 중간 및 후위 계층에서 얻어진 표현이 아이디어 품질 평가에 더 적합하다는 것을 알았습니다. 이러한 접근법은 적은 양의 데이터로도 높은 정확도를 달성할 수 있음을 입증하였습니다.



### You can remove GPT2's LayerNorm by fine-tuning (https://arxiv.org/abs/2409.13710)
- **What's New**: 이 논문에서는 GPT 스타일의 transformer 모델에서 LayerNorm(LN) 레이어를 제거할 수 있음을 보여줍니다. 기존의 LN이 가지는 기계적 해석성의 방해 요소를 해결하기 위해, 사전 훈련된 GPT2-small 모델에서 일부 데이터로 미세 조정하여 LN-free 모델을 생성했습니다.

- **Technical Details**: LN 레이어는 대규모 언어 모델의 훈련을 안정화하는 데 필수적이지만, 그 비선형적 특성으로 인해 모델의 해석이 어려워졌습니다. 본 연구에서는 500M 토큰의 훈련 데이터를 사용하여 GPT2-small 모델에서 LN 레이어를 성공적으로 제거하였고, 해당 모델의 미세 조정 절차와 Hugging Face 리포지토리를 제공합니다.

- **Performance Highlights**: LN-free 모델은 OpenWebText 및 ThePile 데이터셋에서 기존 모델과 유사한 성능을 나타내며, 교차 엔트로피 손실에서는 -0.05, Hellaswag 벤치마크에서는 -0.5% 정확도를 기록했습니다.



### Column Vocabulary Association (CVA): semantic interpretation of dataless tables (https://arxiv.org/abs/2409.13709)
- **What's New**: 이번 논문에서는 Semantic Table Interpretation (STI) 분야에서 새로운 과제인 'Metadata to KG' 트랙을 소개하며, 기존의 데이터에 접근하지 않고 메타데이터 정보만으로 테이블 해석을 수행하는 방법을 검토하였습니다.

- **Technical Details**: 주요 내용은 Column Vocabulary Association (CVA)라는 새로운 개념을 도입하였고, 다양한 Large Language Models (LLMs)과 Retrieval Augmented Generation (RAG) 접근 방식을 통해 CVA 작업을 평가하였습니다. 실험에는 상업적 GPT 모델(예: gpt-3.5-turbo-0.125, gpt-4o, gpt-4-turbo)과 오픈 소스 모델(예: llama3-80b, llama3-7b) 총 7개 모델이 포함되었습니다.

- **Performance Highlights**: 결과적으로, LLM은 일반적으로 온도 설정이 1.0 이하일 때 우수한 성과를 내었고, 특정 사례에서는 100% 정확도를 달성하였습니다. 그러나 데이터의 특성에 따라 전통적인 방법이 LLM의 성과를 초월하는 경우도 있었습니다.



### Towards Safe Multilingual Frontier AI (https://arxiv.org/abs/2409.13708)
Comments:
          23 pages; 1 figure and 10 supplementary figures

- **What's New**: 이번 연구는 효과적으로 다언어 지원을 제공하는 LLMs(대형 언어 모델)의 개발을 강조하며, 특히 다국어 jailbreak(탈옥) 공격으로부터 모델의 안전성을 확보하기 위한 정책 제안을 제시합니다. 이를 통해 AI의 언어적 포용성을 증대시키고, EU의 법적 틀에 맞춘 정책 조치를 모색합니다.

- **Technical Details**: 5개의 선도적인 LLM을 대상으로 EU의 24개 공식 언어에 대한 다국어 jailbreak 공격의 취약성을 정량적으로 분석하였습니다. 다국어 기능과 취약성 간의 관계를 평가하기 위해,  언어 자원화 수준에 대한 새로운 가설을 제안하였습니다.

- **Performance Highlights**: 이 연구에서 제안된 정책은 AI 안전성을 개선하고, 기존의 기술적 공간과 정책적 요구 간의 간극을 줄이기 위해 설계되었습니다. 특히, 저자들은 다국어 AI 개발에 대한 국가적 지원과 다국어 기능의 의무 평가를 포함한 여러 가지 정책 권고안을 제시하고, 이러한 조치들이 AI의 효과성과 안전성을 향상시킬 수 있을 것이라고 강조합니다.



### Decolonising Data Systems: Using Jyutping or Pinyin as tonal representations of Chinese names for data linkag (https://arxiv.org/abs/2409.13706)
- **What's New**: 이 논문은 건강 연구 및 정책 결정에서 데이터 연결(data linkage)의 중요성을 강조하며, 이름 로마나이제이션(name romanisation) 문제를 해결하기 위한 표준화된 시스템의 사용을 제안합니다.

- **Technical Details**: 연구는 중국어 이름을 포함한 771개의 이름을 수집하고, Jyutping, Pinyin 및 홍콩 정부 로마나이제이션 시스템(HKG-romanisation)의 유용성을 비교했습니다. 분석 결과 Jyutping과 Pinyin이 HKG-romanisation 시스템에 비해 오류가 적음을 입증했습니다.

- **Performance Highlights**: 표준화된 로마나이제이션 시스템을 사용하는 것이 중국계 이민자의 데이터 연결률 및 정확성을 향상시킬 수 있으며, 이는 보다 포괄적인 연구 데이터 개발에 기여할 것으로 기대됩니다.



### Debiasing Text Safety Classifiers through a Fairness-Aware Ensemb (https://arxiv.org/abs/2409.13705)
- **What's New**: 이번 연구에서는 대규모 언어 모델(LLMs)의 안전성과 공정성을 보장하기 위한 경량의 후처리(post-processing) 방법을 제시합니다. 기존의 데이터 불균형 문제를 해결하는 새로운 메트릭과 데이터 세트를 도입하여, 편향된 모델의 문제를 완화하고자 합니다.

- **Technical Details**: 편향을 완화하기 위해, 우리는 'Fair Data Reweighting (FDW)'라는 두 단계 방법을 적용하여 교육 세트를 재조정하고, 최종적으로 안전 분류기를 개선하는 앙상블(ensemble) 모델을 구축합니다. 또한, 두 가지 새로운 메트릭인 Average Counterfactual Variance (ACV)와 Sliced Averages (SA)를 도입하여 모델의 공정성을 평가합니다.

- **Performance Highlights**: 우리가 제안한 방법은 모델의 성능에 미치는 영향이 최소한인 상태에서 반사실적 공정성을 개선하는 것으로 나타났습니다. 또한, 새로운 Open AI 데이터 세트와 사용자 지정 프롬프트를 기반으로 한 LLM 생성 데이터 세트를 마련하여, 이들 데이터는 신원을 기반으로 균형이 잡힌 특징을 가집니다.



### Entity Extraction from High-Level Corruption Schemes via Large Language Models (https://arxiv.org/abs/2409.13704)
- **What's New**: 최근 몇 년간 증가한 금융 범죄를 해결하기 위한 전용 데이터셋의 부족을 해결하기 위해 새로운 마이크로 벤치마크 데이터셋을 제안.

- **Technical Details**: 이 논문은 뉴스 기사에서 개인 및 조직을 식별하도록 설계된 새로운 마이크로 벤치마크 데이터셋을 소개하며, 이를 기반으로 다양한 저조도 파라미터의 Large Language Models (LLMs)를 활용하여 금융 범죄 관련 기사에서 개인과 조직을 식별하는 방법론을 개발하였다. 데이터셋은 JSON 형식으로 제공되며, 애매한 엔티티 언급 문제를 해결하기 위한 LLM 기반의 비모호화 방법을 포함한다.

- **Performance Highlights**: 제안된 방법은 기존의 오픈 소스 베이스라인과 비교하여 성능의 우수성을 보였으며, 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1 점수와 같은 표준 지표를 사용하여 평가되었다.



### Shaping the Future of Endangered and Low-Resource Languages -- Our Role in the Age of LLMs: A Keynote at ECIR 2024 (https://arxiv.org/abs/2409.13702)
- **What's New**: 이 논문은 언어가 문화적 및 사회적 정체성을 형성하는 데 중요한 역할을 한다는 점을 강조하며, 오늘날 7100개 이상의 언어 중 상당수가 멸종 위기에 처해 있음을 알립니다. 특히, Occitan 언어를 중심으로 기술과 전통 간의 협력 가능성을 탐구합니다.

- **Technical Details**: Large Language Model (LLM) 기술이 제공하는 번역 및 콘텐츠 생성의 가능성을 논의하며, 이는 멸종 위기 언어 보존과 재활성화의 중요한 요소가 될 수 있습니다. 그러나 이러한 기술은 또한 문화의 동질화 및 이미 취약한 언어의 추가적 소외를 초래할 위험이 있습니다.

- **Performance Highlights**: 인공지능(AI)과 인간의 전문성이 함께 작동하여 언어의 다양성을 보존할 수 있는 희망을 제공할 수 있음을 강조하며, 이를 위해서는 윤리적 및 실용적인 도전 과제를 해결해야 한다고 주장합니다.



### CA-BERT: Leveraging Context Awareness for Enhanced Multi-Turn Chat Interaction (https://arxiv.org/abs/2409.13701)
Comments:
          This paper has been accepted by ICBASE 2024

- **What's New**: 이 논문은 기존의 BERT 모델을 기반으로 다중 대화 상호작용에서의 맥락의 필요성을 감지하는 데 특화된 Context-Aware BERT (CA-BERT) 모델을 소개합니다. 이 모델은 맥락 필요성을 효과적으로 분석하여 대화의 정확성과 관련성을 높이는 데 기여합니다.

- **Technical Details**: CA-BERT는 BERT 아키텍처를 수정하여 다중 턴 대화의 맥락 필요성 분류를 위한 맞춤형 구조를 도입했습니다. 주요 개선 사항으로는 드롭아웃 레이어와 이진 분류기를 추가하여 '맥락 필요' 또는 '맥락 불필요'를 예측하는 기능을 강화했습니다. 이를 통해 효율성이 높아지고, 훈련 데이터에서 수집한 다중 대화 샘플을 활용하여 성과를 평가했습니다.

- **Performance Highlights**: CA-BERT는 기존의 BERT 모델 대비 높은 정확도와 효율성을 보여주었으며, 훈련 시간과 자원 사용량을 획기적으로 줄였습니다. 이번 연구는 네트워크의 맥락 인지 능력을 향상시킴으로써 자동화된 대화 시스템에서 사용자 경험과 상호작용 품질을 개선하는 데 기여할 것으로 기대됩니다.



### Lightweight Transducer Based on Frame-Level Criterion (https://arxiv.org/abs/2409.13698)
Comments:
          Accepted by Interspeech 2024, code repository: this https URL

- **What's New**: 본 논문에서는 메모리와 계산 요구 사항을 크게 줄이는 동시에 비슷한 성능을 유지하는 경량화된 transducer 모델을 제안합니다. 기존 sequence-level criterion 대신 frame-level criterion를 사용하여 성능을 개선하였습니다.

- **Technical Details**: 경량화된 transducer 모델은 CTC(CTC: Connectionist Temporal Classification) 강제 정렬 알고리즘의 결과를 기반으로 각 프레임의 레이블을 결정합니다. 인코더 출력은 디코더 출력과 해당 시간에 결합되며, 결과적으로 메모리 사용량이 O(N*T*U*V)에서 O(N*T*V)로 감소합니다. 또한, 우리는 cross-entropy loss를 사용하여 모델을 훈련시킵니다.

- **Performance Highlights**: 실험 결과, 제안된 모델은 기존 transducer와 유사한 정확도를 달성하였으며, 블랭크 레이블의 비율로 인한 비대칭 분류 문제를 해결함으로써 성능 차이를 극복했습니다. AISHELL-1 데이터셋을 통해 검증하였습니다.



### Prompt Baking (https://arxiv.org/abs/2409.13697)
Comments:
          25 pages, 8 figures

- **What's New**: 이 논문에서는 LLM(대형 언어 모델)의 행동을 변경하기 위해 프롬프트(Prompt)를 가중치(Weight)에 '베이킹(Baking)'하는 새로운 기술을 제안합니다. 이를 통해 요청된 프롬프트에 따라 LLM이 행동하도록 만드는 방법을 제시합니다.

- **Technical Details**: '프롬프트 베이킹'은 프롬프트 $u$와 초기 가중치 $	heta$를 새로운 가중치 셋 $	heta_u$로 변환하여, 새로운 LLM이 원래의 프롬프트된 LLM처럼 행동하도록 하는 과정입니다. 이는 KL divergence를 최소화하는 방식으로 작동하며, 프롬프트를 가중치 업데이트로 변환하여 재사용성을 높입니다.

- **Performance Highlights**: 연구 결과, 프롬프트를 베이킹함으로써 여러 벤치마크(GSM8K, ASDiv, MBPP, ARC-Easy, ARC-Challenge, CommonsenseQA)에서 제로샷(zero-shot) 성능이 개선되었습니다. 또한, 뉴스 헤드라인을 베이킹함으로써 LLM의 지식을 직접 업데이트할 수 있으며, 장기적인 시퀀스에서는 '프롬프트 망각(prompt forgetting)'을 완화할 수 있습니다. 재프롬프트와 재베이킹을 통해 성능이 더욱 향상되며, 이를 반복적으로 수행하는 '프롬프트 추적(Prompt Pursuit)' 방식을 통해 인스트럭션 따라하기 성능에서 극적인 성능 향상을 보였습니다.



### You Only Use Reactive Attention Slice For Long Context Retrieva (https://arxiv.org/abs/2409.13695)
- **What's New**: 이 논문에서는 Attention을 기반으로 한 새로운 검색 기술인 You Only Use Reactive Attention slice (YOURA)를 제안합니다. 기존의 Retrieval Augmented Generation (RAG) 기법이 긴 맥락을 처리하는 데 한계가 있던 점을 개선하여, 모델이 긴 입력 맥락을 효과적으로 활용하도록 합니다.

- **Technical Details**: YOURA는 입력 문맥에서 문장의 관련성을 평가하기 위해 reaction score라는 새로운 검색 휴리스틱을 사용합니다. 각 토큰의 Attention 점수가 쿼리에 어떻게 "반응"하는지를 측정하여 가장 반응이 큰 문장을 검색합니다. 이 과정에서 Embedding-Agnostic Sentence Yield (EASY) 알고리즘을 활용하여 각 문장을 토큰 인덱스 벡터에 매핑합니다.

- **Performance Highlights**: YOURA는 LongBench QA 데이터셋에서 최대 30% 향상된 vLLM 추론 처리량을 달성하며, 질문 응답 품질을 10% 향상시킵니다. EASY 알고리즘은 문장-토큰 인덱스 매핑 정확도를 93% 이상 기록했습니다.



### A Knowledge-Centric Benchmarking Framework and Empirical Study for Retrieval-Augmented Generation (https://arxiv.org/abs/2409.13694)
Comments:
          14 pages, 11 figures; Mingyue Cheng is the corresponding author

- **What's New**: 이 논문에서는 Retrieval-Augmented Generation (RAG) 시스템의 새로운 벤치마크를 제안하고, KDD Cup 2024 CRAG 대회의 데이터셋을 활용하여 RAG의 성능을 분석합니다. 여기서 HTML 형식의 웹 페이지를 Markdown 형식으로 변환하여 LLM이 정보를 효율적으로 활용할 수 있도록 하였습니다.

- **Technical Details**: RAG 모델은 내부 LLM 지식과 외부 지식 소스의 효과적인 융합을 목표로 합니다. 연구에서는 RAG의 전 과정(지식 소스 선택, 검색, 정리 및 추론)을 심도 있게 분석하고, 자동화된 지식 소스 선택 및 노이즈 청크의 영향 등을 조사했습니다. 또한, 하이퍼파라미터 설정에 따른 성능 변화를 분석하였습니다.

- **Performance Highlights**: RAG-X 프레임워크는 CRAG 기본 모델 및 LLM 전용 모델보다 일관되게 우수한 성과를 보였으며, 구조화된 Mock API의 데이터는 비구조화된 웹 출처에 비해 정확도를 향상시키고 환각(hallucination)률을 감소시켰습니다. 그러나 외부 지식 소스의 입력을 늘릴수록 정확도가 개선되지만 환각률도 소폭 증가하는 결과를 보였습니다.



### Archon: An Architecture Search Framework for Inference-Time Techniques (https://arxiv.org/abs/2409.15254)
- **What's New**: 최근의 조사에 따르면, Archon이라는 자동화된 프레임워크가 LLM과 추론 시간 기술들을 결합하여 성능을 향상시키는 데 효과적임을 입증하였습니다. Archon은 다양한 추론 시간 아키텍처를 설계하는 데 유용하며, 하이퍼파라미터 최적화를 통해 최적의 아키텍처를 도출합니다.

- **Technical Details**: Archon 프레임워크는 generation ensembling, multi-sampling, ranking, fusion, critiquing, verification, 및 unit testing과 같은 방법을 포함한 확장 가능한 디자인 공간을 정의합니다. 자동화된 Inference-Time Architecture Search (ITAS) 알고리즘을 통해 LLM과 추론 컴퓨팅 예산에 따라 최적화된 아키텍처를 출력합니다. 또한, Bayesian optimization을 사용하여 하이퍼파라미터 공간을 효과적이고 효율적으로 검색합니다.

- **Performance Highlights**: Archon 아키텍처는 MT-Bench, Arena-Hard-Auto, AlpacaEval 2.0, MixEval, MixEval Hard, MATH, 및 CodeContests와 같은 다양한 벤치마크에서 우수한 성능을 보였습니다. Archon이 설계한 아키텍처는 GPT-4o 및 Claude 3.5 Sonnet 모델보다 평균 14.1 포인트, 오픈 소스 모델과의 비교에서 평균 10.3 포인트의 성능 향상을 기록했습니다.



### Efficiently Dispatching Flash Attention For Partially Filled Attention Masks (https://arxiv.org/abs/2409.15097)
- **What's New**: 새로운 알고리즘 'Binary Block Masking (BinBlkMsk)'을 소개하며, 이 알고리즘은 기존의 Flash Attention을 개선하여 모든 종류의 attention mask를 지원합니다. 특히, 사용자 친화적이며 특정 마스크에 대한 사용자 조정 없이 사용할 수 있습니다.

- **Technical Details**: 이 방법은 attention 행렬의 관련 블록만을 처리하여 비효율적인 계산을 줄입니다. Binary Block Matrix (BinBlkMat)를 사용해 비영 상태의 항목만 선택적으로 처리하고, 긴성폭 넓이 기반으로 최적화된 방식을 도입하여 성능을 크게 향상시킬 수 있습니다.

- **Performance Highlights**: 기존 Flash Attention에 비해 최대 9배의 런타임 성능 개선을 실현했습니다. 이는 실제 시나리오에서 얻은 attention mask를 기반으로 한 실험을 통해 검증되었습니다.



### Evaluating the Usability of LLMs in Threat Intelligence Enrichmen (https://arxiv.org/abs/2409.15072)
- **What's New**: 이번 연구는 사이버 위협 정보(Cyber Threat Intelligence, CTI) 분야에서 다섯 개의 대규모 언어 모델(Large Language Models, LLM)인 ChatGPT, Gemini, Cohere, Copilot, Meta AI의 사용성을 포괄적으로 평가하였습니다. 이를 통해 보안 전문가들이 LLM을 효과적으로 활용할 수 있도록 사용자 인터페이스 및 기능 개선을 위한 구체적인 권장 사항을 제시합니다.

- **Technical Details**: 연구에서는 휴리스틱 워크스루(heuristic walkthrough) 및 사용자 연구(user study) 방법론을 이용하여 LLM의 사용자 인터페이스 설계, 오류 처리, 학습 곡선(learning curve), 성능, 기존 도구와의 통합 등을 평가했습니다. 이는 위협 데이터의 수집, 전처리, 분석 자동화를 지원하는 LLM의 다양한 기능을 탐구하는데 초점을 맞추었습니다.

- **Performance Highlights**: 결과적으로, 연구에서는 LLM 사용 시 발생할 수 있는 주요 사용성 문제들을 식별하고, 각 LLM의 향후 개선을 위한 실행 가능한 권장 사항을 제공합니다. 사용성이 향상되면 보안 전문가들이 이 도구들을 보다 효과적으로 활용하여 사이버 위협에 대응할 수 있는 기반이 마련됩니다.



### Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP (https://arxiv.org/abs/2409.15035)
Comments:
          Short paper. Accepted by the Findings of EMNLP 2024

- **What's New**: CLIP 모델에서 수량 편향(quantity bias)을 조사하여 이미지 생성 작업에서 사용자 의도를 잘 이해하지 못하고 실제 출력과 요구되는 객체 수의 불일치를 보여줌.

- **Technical Details**: 이 연구에서는 텍스트, 이미지 및 교차 모달(cross-modal) 관점에서의 수량 편향을 다루며, 9개의 다양한 CLIP 모델을 평가하고, 수량 관련 명사를 포함하는 수작업 데이터셋을 제작하여 CLIP의 수량 이해력을 평가함. CLIP은 'fewer'와 'more'를 비교하는 데 효과적이지 않으며, 이미지 도메인에서는 서로 다른 원의 수를 가진 이미지 간에도 큰 차이를 구별하지 못함.

- **Performance Highlights**: 실험 결과, CLIP은 텍스트와 이미지의 수량 개념을 효과적으로 이해하지 못하며, 수량 단어 간의 유사성을 잘 구분하지 못하고, 이는 다운스트림(downstream) 작업의 신뢰성을 저하시킴.



### ViBERTgrid BiLSTM-CRF: Multimodal Key Information Extraction from Unstructured Financial Documents (https://arxiv.org/abs/2409.15004)
Comments:
          Accepted in MIDAS (The 8th Workshop on MIning DAta for financial applicationS) workshop of ECML PKDD 2023 conference

- **What's New**: 이 논문은 비정형 문서에서의 핵심 정보 추출(Information Extraction, KIE) 모델에 대한 새로운 접근 방식을 제안합니다. 특히, ViBERTgrid라는 다중 모드 트랜스포머를 비정형 금융 문서에 적응시키고 BiLSTM-CRF 레이어를 통합하여 성능을 크게 향상시킵니다.

- **Technical Details**: 제안된 ViBERTgrid BiLSTM-CRF 모델은 비정형 문서에서의 개체 인식(Named Entity Recognition, NER) 성능을 2%포인트 향상시키면서도 반구조 문서에서의 KIE 성능을 유지합니다. 이 모델은 두 가지 주요 아키텍처인 ViBERTgrid(트랜스포머 기반)와 BiLSTM-CRF(시퀀스 기반)를 결합하여 구문 및 장기 컨텍스트 인식을 제공합니다.

- **Performance Highlights**: 이 모델은 비정형 자금 이체 주문 데이터셋 및 반구조 영수증 데이터셋(SROIE)에서 평가되었으며, SROIE 데이터셋에 대한 토큰 수준 주석을 공개하여 다중 모드 시퀀스 레이블링 모델에서의 사용 가능성을 높였습니다.



### FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension (https://arxiv.org/abs/2409.14750)
Comments:
          19 pages, EMNLP 2024

- **What's New**: FineCops-Ref라는 새로운 REC 데이터셋을 제안했습니다. 이 데이터셋은 접근 가능한 난이도를 제어할 수 있으며, 기존 데이터셋에서는 간과되었던 부정적 샘플에 대한 모델의 저항력을 평가하는 데 중점을 두고 있습니다.

- **Technical Details**: FineCops-Ref 데이터셋은 객체 카테고리, 속성 및 다단계 관계에 대한 세밀한 추론을 요구합니다. 난이도 수준은 대상 객체 위치 파악에 필요한 속성과 관계의 수에 따라 분류됩니다. 샘플에는 부정적인 텍스트와 이미지가 포함되어 있어, 모델의 시각적 기초 능력을 직접 평가할 수 있습니다.

- **Performance Highlights**: 상태 최상 모델들 및 MLLMs을 종합적으로 평가한 결과, grounding 성능의 상당한 차이를 발견했습니다. 간단한 REC 작업에서는 전통적 비전-언어 모델이 우수한 성능을 보였고, 더 높은 난이도에서는 MLLMs가 더 나은 성과를 나타냈습니다. 이는 모델의 미세 조정을 통해 성능이 향상되었음을 보여줍니다.



### VLEU: a Method for Automatic Evaluation for Generalizability of Text-to-Image Models (https://arxiv.org/abs/2409.14704)
Comments:
          accepted by EMNLP2024(long paper,main conference)

- **What's New**: 텍스트-이미지(T2I) 모델의 평가 방법을 개선하기 위해 새로운 평가 지표인 VLEU(Visual Language Evaluation Understudy)를 소개합니다. 이 지표는 대규모 언어 모델을 사용하여 T2I 모델의 다양한 텍스트 프롬프트에 대한 일반화 능력을 정량적으로 평가할 수 있습니다.

- **Technical Details**: VLEU는 시각적 텍스트 도메인의 분포와 T2I 모델이 생성한 이미지의 조건부 분포 간의 Kullback-Leibler divergence를 계산하여 모델의 일반화 능력을 수치적으로 평가합니다. 이 지표는 다양한 텍스트 프롬프트에서 이미지의 생성 품질과 그 일치도를 평가하는 데 활용됩니다. LLM(대규모 언어 모델)과 CLIP 모델을 사용하여 텍스트와 이미지 간의 의미적 일치를 평가합니다.

- **Performance Highlights**: VLEU의 실험을 통해 다양한 T2I 모델의 일반화 능력을 효과적으로 평가할 수 있음을 입증하였습니다. 이 새로운 지표는 T2I 모델 개발에 필수적인 도구로 자리잡을 것으로 기대되며, 실제 사례 연구 또한 발표되어 그 유용성을 보여주었습니다.



### MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification (https://arxiv.org/abs/2409.14703)
Comments:
          Accepted to EMNLP 2024 (Main)

- **What's New**: 본 연구는 LGBTQ+ 프라이드 운동과 관련된 5,063개의 텍스트 내장 이미지로 구성된 새로운 데이터셋 PrideMM을 소개합니다. 이전의 연구들이 단일 측면에 집착했던 것과 달리, 우리는 혐오 발언, 표적 탐지, 입장 분류 및 유머 탐지의 여러 측면을 포함하는 종합적인 데이터셋을 구축했습니다.

- **Technical Details**: PrideMM은 4개의 과제를 포함하고 있습니다: (A) 혐오 발언 탐지, (B) 혐오 발언의 대상 분류, (C) 주제 입장 분류, (D) 의도된 유머 탐지. 우리는 CLIP(Contrastive Language-Image Pre-Training) 모델의 지식을 활용하여 MemeCLIP이라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 경량 Feature Adapters를 활용해 CLIP의 기존 지식을 보존하고, 데이터셋의 불균형을 고려한 코사인 분류기를 통합하여 더욱 견고한 성능을 발휘합니다.

- **Performance Highlights**: MemeCLIP은 두 개의 실제 데이터셋에 대한 실험에서 이전에 제안된 프레임워크보다 우수한 성능을 보여주었으며, 혐오 분류 작업에서는 zero-shot GPT-4와 성능을 비교했습니다. 최종적으로, 모델의 단점도 정 qualitatively 분석하여 문제점을 도출하였습니다.



### Reducing the Footprint of Multi-Vector Retrieval with Minimal Performance Impact via Token Pooling (https://arxiv.org/abs/2409.14683)
- **What's New**: 이번 논문에서는 ColBERT와 같은 다중 벡터 검색 방법의 저장소 및 메모리 요구사항을 줄이기 위한 간단한 클러스터링 기반의 Token Pooling 방법을 도입했습니다. 이 방법은 저장해야 하는 벡터의 수를 획기적으로 줄여줍니다.

- **Technical Details**: Token Pooling 방법은 개별 벡터를 클러스터링하고 평균 풀링을 통해 하나의 벡터로 변환하는 2단계 시스템으로 작동합니다. 세 가지 풀링 방법이 제안되었으며, 특히 계층적 클러스터링이 가장 우수한 결과를 보여주었습니다.

- **Performance Highlights**: 이 방법은 ColBERT 인덱스를 평균적으로 50%의 저장 공간을 줄이면서도 성능 저하가 없음을 보여주었으며, 66%까지의 벡터 수 감소도 가능하였고, 이 경우 성능 저하는 3% 이하에 머물렀습니다.



### RACER: Rich Language-Guided Failure Recovery Policies for Imitation Learning (https://arxiv.org/abs/2409.14674)
Comments:
          Project Website: this https URL

- **What's New**: 본 논문은 로봇 조작을 위한 강력하고 교정 가능한 비주얼-모터(Visuomotor) 정책 개발의 어려움을 다룹니다. 실패 복구 메커니즘과 간단한 언어 지시의 한계를 극복하기 위해, 자동으로 전문가 시연을 실패 복구 궤적(failure recovery trajectories)과 세부 언어 주석으로 보강하는 데이터 생성 파이프라인을 제안합니다.

- **Technical Details**: 우리는 Rich languAge-guided failure reCovERy (RACER)라는 감독-행위자(supervisor-actor) 프레임워크를 소개하며, 이는 실패 복구 데이터를 풍부한 언어 설명과 결합하여 로봇 제어를 향상시킵니다. RACER는 온라인 감독으로 작동하는 비전-언어 모델(Vision-Language Model, VLM)과 다음 행동을 예측하는 언어 조건 비주얼-모터 정책을 포함합니다.

- **Performance Highlights**: 실험 결과, RACER는 RLbench의 다양한 평가 설정에서 기존 최첨단 모델인 Robotic View Transformer (RVT)를 초월하여 우수한 성능을 보여주었습니다. 이는 시뮬레이션 및 실제 환경 모두에서 탁월한 Robustness와 Adaptability를 입증합니다.



### Backtracking Improves Generation Safety (https://arxiv.org/abs/2409.14586)
- **What's New**: 이번 논문에서는 언어 모델 안전성을 위한 새로운 접근법인 'backtracking' 기법을 제안합니다. 이는 언어 모델이 올바르지 않은 생성 결과를 되돌리고 새로운 안전한 응답을 생성할 수 있도록 허용하는 기술입니다.

- **Technical Details**: 'backtracking'은 언어 모델이 생성 중에 특별한 [RESET] 토큰을 사용하여 이전의 안전하지 않은 생성 결과를 식별하고 이를 잊어버리면서 새로운 생성 작업을 시작하는 방식입니다. 본 연구는 SFT(Supervised Fine Tuning)와 DPO(Direct Preference Optimization) 방법론을 통해 훈련되었으며, 이를 통해 Gemma-2-2B와 Llama-3-8B 모델의 안전성을 크게 향상시켰습니다.

- **Performance Highlights**: Backtracking을 사용한 Llama-3-8B 모델은 기준 모델에 비해 안전성이 4배 증가했으며(6.1%에서 1.5%로), 유용성의 감소 없이도 이러한 안전성 향상이 이루어졌습니다. 추가로, 네 가지 적대적 공격에 대한 보호 기능도 제공되었습니다.



### What Are They Doing? Joint Audio-Speech Co-Reasoning (https://arxiv.org/abs/2409.14526)
Comments:
          Submitted to ICASSP 2025

- **What's New**: 이번 논문에서는 오디오와 음성을 동시에 처리할 수 있는 새로운 Joint Audio-Speech Co-Reasoning (JASCO) 태스크를 도입합니다. 이를 통해 오디오 및 음성 처리의 통합과 공동 추론을 필요로 하는 타 부문과의 비교를 범위로 합니다.

- **Technical Details**: JASCO는 오디오 클립과 텍스트 지시문을 입력으로 받아, 오디오 정보와 음성 정보를 결합하여 합리적인 응답을 생성하는 방식으로 설계되었습니다. 또한, 두 가지 정보의 의존성 평가를 통해 모델의 공동 추론 능력을 측정합니다.

- **Performance Highlights**: 제공된 데이터셋 'What Are They Doing'을 통해 여러 Auditory Large Language Models (ALLMs)의 공동 추론 능력을 벤치마크하여 평가하였습니다. 이 평가 방식은 모델이 특정 모달리티에 대한 의존성을 드러내는지를 측정합니다.



### Beyond Words: Evaluating Large Language Models in Transportation Planning (https://arxiv.org/abs/2409.14516)
- **What's New**: 2023년 Generative Artificial Intelligence (GenAI)의 급속한 발전이 도시 교통 및 물류 분야에 혁신적인 변화를 가져왔습니다. 본 연구는 GPT-4와 Phi-3-mini 같은 Large Language Models (LLMs)의 성능을 수송 계획에 적용하는 것을 탐구합니다.

- **Technical Details**: 이 연구는 교통 정보를 반영한 평가 프레임워크를 통해 LLM의 성능과 공간 이해력을 평가합니다. 평가 요소로는 일반적인 지리적 정보 시스템 (GIS) 기술, 교통 관련 도메인 지식 및 현실 세계의 교통 문제 해결 능력이 포함됩니다. 혼합 방법론을 활용하여 연구가 진행되었습니다.

- **Performance Highlights**: 연구 결과, GPT-4는 다양한 GIS 및 교통 관련 작업에서 Phi-3-mini보다 더 뛰어난 정확성과 신뢰성을 보였습니다. 그러나 Phi-3-mini는 특정 분석 시나리오에서 유용함을 나타내어 자원이 제한된 환경에서도 활용 가능성을 보여줍니다. 이 결과는 GenAI 기술이 도시 교통 계획에 미치는 혁신적인 잠재력을 강조합니다.



### A Large Language Model and Denoising Diffusion Framework for Targeted Design of Microstructures with Commands in Natural Languag (https://arxiv.org/abs/2409.14473)
Comments:
          29 pages, 15 figures

- **What's New**: 이번 연구에서는 자연어 처리(Natural Language Processing, NLP), 대규모 언어 모델(Large Language Models, LLMs), 및 Denoising Diffusion Probabilistic Models (DDPMs)를 통합하여 자연어 명령을 통한 미세구조 설계를 가능하게 하는 새로운 프레임워크를 제안합니다.

- **Technical Details**: 프레임워크는 두 가지 주요 구성 요소로 나뉘어 있으며, NLP 구성 요소와 미세구조 생성 구성 요소로 이루어집니다. NLP 구성 요소는 사전 훈련된 LLM을 활용하여 텍스트 설명자 데이터베이스를 생성하고, 사용자 제시 자연어 입력에서 관련 미세구조 설명자를 추출하는 재훈련된 Named Entity Recognition (NER) 모델을 사용합니다. 이후 DDPM을 이용해 특정 기계적 속성과 형태적 특성을 가진 미세구조를 생성합니다.

- **Performance Highlights**: 이 프레임워크는 비선형 하이퍼엘라스틱 미세구조 데이터베이스에서 시연되었으며, 직관적인 자연어 명령으로부터 접근 가능한 역설계를 위한 프로토타입으로 기능합니다. 이를 통해 고객의 입력에 적합한 미세구조 샘플을 효율적으로 생성하고, 광범위한 응용 분야에 대한 적용 가능성을 확대하는 데 기여할 것입니다.



### Opinion Mining on Offshore Wind Energy for Environmental Engineering (https://arxiv.org/abs/2409.14292)
- **What's New**: 이 논문에서는 소셜 미디어 데이터를 활용하여 해상 풍력 에너지에 대한 대중의 의견을 분석합니다. 세 가지 머신러닝 모델, 즉 TextBlob, VADER, SentiWordNet을 사용하여 각 모델이 제공하는 다양한 기능을 활용합니다.

- **Technical Details**: TextBlob은 주관성 분석(subjectivity analysis)과 극성 분류(polarity classification)를 제공하며, VADER는 누적 감정 점수(cumulative sentiment scores)를 산출합니다. SentiWordNet은 맥락(context)을 기준으로 감정을 고려하여 분류를 수행합니다. 자연어 처리(NLP) 기술을 통해 소셜 미디어의 텍스트 데이터에서 의미를 추출합니다.

- **Performance Highlights**: 데이터 시각화 도구를 적절히 사용하여 전체 결과를 표시하며, 이는 시민 과학(citizen science)과 스마트 거버넌스(smart governance)에 부합하여 대중의 의견이 의사 결정 지원(decision support)을 안내하는 역할을 합니다.



### Can-Do! A Dataset and Neuro-Symbolic Grounded Framework for Embodied Planning with Large Multimodal Models (https://arxiv.org/abs/2409.14277)
- **What's New**: 이 논문은 Can-Do라는 새로운 벤치마크 데이터 세트를 도입하여 대형 다중 모달 모델의 체화된 계획 능력을 평가합니다. 이 데이터 세트는 이전의 데이터 세트보다 더 다양한 복잡한 시나리오를 포함하고 있으며, 400개의 다중 모달 샘플로 구성되어 자연어 사용자 지침, 환경을 묘사하는 시각 이미지, 상태 변화 및 해당 동작 계획을 포함하고 있습니다.

- **Technical Details**: Can-Do 데이터 세트는 실제 환경을 묘사하기 위해 실제 장면 이미지와 합성 이미지를 모두 활용합니다. 세 가지 태스크 카테고리(물리적 이해, 상식, 안전)을 중심으로 설계되었으며, 각 샘플은 사용자 의도를 기반으로 시각 시나리오를 인식하고 단계를 생성하는 모델의 능력을 평가합니다. 연구에서는 또한 NeuroGround라는 신경 상징적 프레임워크를 제안하여 모델 생생 생성 과정이 환경의 초기 및 목표 상태에 명확하게 기반하도록 합니다.

- **Performance Highlights**: 실험 결과, NeuroGround 프레임워크는 기존의 강력한 기준선과 비교하여 상당한 이점을 보여주었습니다. 특히, 체화된 계획에서 기존 모델(GPT-4V 포함)의 병목 현상인 시각적 지각, 이해 및 추론 능력에서 개선된 성능을 입증했습니다.



### On Lexical Invariance on Multisets and Graphs (https://arxiv.org/abs/2409.14179)
- **What's New**: 이번 논문에서는 lexical invariance라는 새로운 문제를 다룹니다. 이는 입력의 특정 단어 기반 표현과 관계없이 문장의 의미가 변하지 않아야 한다는 것입니다. 예를 들어, '영화는 극도로 재미있었다'는 '영화는 매우 즐거웠다'와 동일한 의미를 가집니다.

- **Technical Details**: 우리는 multisets 및 그래프에 대해 가장 유표한 lexical invariant (lexical invariant) 함수에 대한 충분조건과 필요조건을 연구했습니다. multisets의 경우, 함수는 원래 multiset의 고유 요소의 개수(multiset of counts)만을 입력으로 받아야 합니다. 그래프의 경우, 함수는 adjacency matrix와 차이 행렬(difference matrix)을 입력으로 받아야 합니다.

- **Performance Highlights**: TU 데이터셋에 대한 합성 실험(synthetic experiments)을 통해 우리의 정리를 검증했습니다. 이러한 연구는 데이터 익명화(anonymization)와 관련하여 실제 애플리케이션에 이바지 할 수 있습니다.



### Will Large Language Models be a Panacea to Autonomous Driving? (https://arxiv.org/abs/2409.14165)
- **What's New**: 이 논문은 대규모 언어 모델(LLM)이 자율주행(AD) 시스템에서 어떻게 활용될 수 있는지를 분석하며, LLM의 최적화 전략을 모듈화 및 엔드 투 엔드 접근법에서 탐색합니다.

- **Technical Details**: 자율주행 기술은 모듈화(modularization)와 엔드 투 엔드(end-to-end)로 나뉘며, 모듈화는 주행 작업을 감지(perception), 예측(prediction), 계획(planning), 제어(control) 모듈로 분해하여 각기 따로 훈련합니다. 반면, 엔드 투 엔드는 센서 데이터에서 제어 신호로 직접 매핑하는 단일 모델을 사용합니다. 두 접근법 모두 훈련 목표의 일관성 부족 문제와 복잡한 도시 교통 상황에서의 예측 불가능한 사건 처리에서 어려움을 겪고 있습니다.

- **Performance Highlights**: LLM들은 강력한 추론 능력과 방대한 지식을 바탕으로 AD 시스템의 이해도 및 의사결정 능력을 향상시킬 수 있는 잠재력을 지니고 있습니다. 하지만 LLM 기반 인공지능이 고급 AD 구현의 열쇠가 될 수 있을지, 그리고 AD 기술 개발을 촉진하는 데 있어서 LLM이 직면할 잠재적 한계와 도전과제를 논의합니다.



### PromptTA: Prompt-driven Text Adapter for Source-free Domain Generalization (https://arxiv.org/abs/2409.14163)
- **What's New**: 이 논문에서는 소스 도메인 데이터에 접근하지 않고도 미지의 타겟 도메인에 적응할 수 있도록 설계된 Prompt-Driven Text Adapter (PromptTA) 방법을 제안합니다. 이는 스타일 특징의 분포를 더 잘 포착하고 도메인 지식의 충분한 범위를 보장하기 위해 재샘플링을 활용합니다.

- **Technical Details**: PromptTA는 다양한 스타일 특징에서 정보를 학습하는 텍스트 기반 어댑터를 도입하여 도메인 정보를 저장합니다. 스타일 특징의 재샘플링 기법을 통해 포괄적인 도메인 지식을 효과적으로 담을 수 있도록 합니다. 이 방법은 CLIP와 같은 비전-언어 모델의 정렬된 이미지-텍스트 표현을 활용하며, 스타일 벡터의 학습 가능한 집합을 통해 다양한 도메인 정보를 표현합니다.

- **Performance Highlights**: 다양한 벤치마크 데이터세트에서 실시된 실험을 통해 PromptTA가 최신 기술 수준의 성능을 달성한 것으로 나타났습니다. 이를 통해 SFDG 분야에서의 발전에 기여하고 있음을 보여줍니다.



### OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching (https://arxiv.org/abs/2409.14038)
Comments:
          4 pages, 1 figure

- **What's New**: 이번 연구에서는 LLM(hallucinations)의 발생이 Ontology Matching(OM) 작업에서 중요한 문제임을 제기하고, 이를 해결하기 위한 OAEI-LLM 데이터셋을 제안합니다. 이 데이터셋은 OM 작업에서 LLM의 환각 현상을 평가하기 위한 기준을 제공합니다.

- **Technical Details**: OAEI-LLM 데이터셋은 기존 OAEI 데이터셋의 확장으로, LLM의 OM 작업에서의 환각 유형을 분류하고 이를 바탕으로 LLM의 정답률을 평가합니다. 새로운 스키마 확장을 통해 LLM이 생성한 결과와 인간이 라벨링한 결과를 비교하고, 환각의 발생 정도를 측정합니다.

- **Performance Highlights**: LLM은 OM 작업에서 높은 성능을 보일 수 있지만, 환각 현상으로 인해 낮은 precision(정밀도) 및 recall(재현율) 문제를 초래할 수 있습니다. OAEI-LLM 데이터셋을 통해 LLM의 환각 현상에 대한 이해를 높이고, 향후 OM 개선 연구에 기여할 것으로 예상됩니다.



### On-device Collaborative Language Modeling via a Mixture of Generalists and Specialists (https://arxiv.org/abs/2409.13931)
- **What's New**: 본 연구에서는 Mixture of Experts (MoE) 아키텍처와 Low-Rank Adaptation (LoRA) 모듈을 활용하여 대형 언어 모델(LLMs)의 온디바이스(On-device) 협업 파인튜닝(collaborative fine-tuning)을 발표합니다. 구체적으로, 전문가의 역할을 일반화(generalists)와 전문화(specialists)로 다양화하는 CoMiGS(Collaborative Mixture of Generalists and Specialists) 접근 방식을 제안합니다.

- **Technical Details**: 우리의 연구에서 중심이 되는 것은 학습 가능한 라우팅 네트워크(routing network)로, 이는 토큰 수준에서 라우팅을 수행하여 협업과 개인화를 미세하게 조정합니다. MoE 아키텍처는 사용자가 다양한 수의 LoRA 모듈을 가질 수 있도록 하여 시스템의 이질성(system heterogeneity)을 해결합니다.

- **Performance Highlights**: 우리의 방법은 높은 데이터 이질성(data heterogeneity)을 가진 다양 한 데이터셋에서 일관되게 우수한 성능을 보입니다. 이를 통해 자원이 적은 사용자도 데이터 양이 많은 사용자에게서 혜택을 받을 수 있음을 보여줍니다.



### Eliciting Instruction-tuned Code Language Models' Capabilities to Utilize Auxiliary Function for Code Generation (https://arxiv.org/abs/2409.13928)
Comments:
          EMNLP 2024 Findings Short

- **What's New**: 본 논문에서는 코드를 생성하기 위해 instruction-tuned 모델(명령 조정 모델)이 보조 함수(auxiliary function)를 효과적으로 활용하는 방법을 탐구합니다. 기존 모델들은 보조 함수를 텍스트 프롬프트에 포함시키는 방식에 한계가 있었으나, 새로운 프롬프트 구조를 통해 성능을 개선했습니다.

- **Technical Details**: 연구자는 보조 함수 정보를 쿼리에 추가하거나 응답_prefix(구성 요소)를 제공하여 instruction-tuned 모델의 코드 생성 능력을 증진시키기 위해 여러 가지 프롬프트를 설계했습니다. 이러한 접근법은 모델이 실제로 코드를 이해하고 보조 함수를 활용하는 데 도움이 됩니다. 실험에서 사용된 모델은 최근의 경쟁력 있는 instruction-tuned 모델들로, Humanextension 벤치마크를 통해 성능 평가를 실시했습니다.

- **Performance Highlights**: 제안된 프롬프트 방식은 gpt-4o와 같은 강력한 상용 모델에 비해 오픈소스 모델의 성능을 초과하는 결과를 보여주었습니다. 특히, 보조 함수와 함께 제공된 쿼리 및 응답 구조에서 파생된 개선 성과가 두드러졌습니다. 결과적으로 instruction-tuned 모델은 일반적으로 기본 모델보다 우수한 성과를 기록했습니다.



### Generative AI Carries Non-Democratic Biases and Stereotypes: Representation of Women, Black Individuals, Age Groups, and People with Disability in AI-Generated Images across Occupations (https://arxiv.org/abs/2409.13869)
- **What's New**: AI 거버넌스(AI governance)와 AI 개발에서의 윤리(Ethics)가 중대한 문제로 떠오르며, 기술 기업, 정부, 연구자들 사이에서 AI가 우리의 민주주의에 미치는 잠재적 위험에 대한 활발한 논의가 이루어지고 있습니다. 이 논문은 생성적 AI(Generative AI)가 평등이 필요한 집단들을 어떻게 포함하거나 배제하는지를 조명합니다.

- **Technical Details**: 연구 결과는 생성적 AI가 성별(Gender), 인종(Race), 나이(Age), 그리고 가시적 장애(Visible Disability)에 관해 균등하게 포함되지 않음을 보여줍니다. 이는 AI 모델이 특정 집단에 대해 편향된 데이터를 학습함으로써 공정성을 결여하고 있음을 시사합니다.

- **Performance Highlights**: 이 연구의 주요 발견은 생성적 AI의 출력이 평등성(Equity)에 대한 고민 없이 설계되었음을 드러내며, 이는 AI 시스템의 설계와 데이터 수집이 더 포괄적이고 공정해야 함을 강조합니다.



### GTSinger: A Global Multi-Technique Singing Corpus with Realistic Music Scores for All Singing Tasks (https://arxiv.org/abs/2409.13832)
Comments:
          Accepted by NeurIPS 2024 (Spotlight)

- **What's New**: 새로운 GTSinger 데이터셋은 고품질의 다국적, 다기술적 노래 코퍼스로, 80.59시간의 노래 음성과 사실적인 음악 악보를 포함하고 있어 기존의 부족했던 노래 데이터셋의 한계를 극복합니다.

- **Technical Details**: GTSinger는 20명의 전문 가수가 참여하여 9개 언어로 다양한 음색과 스타일을 제공하며, 6가지 일반적인 노래 기법(혼합 음성, 플랫, 숨소리, 인두음, 비브라토, 글리산도)에 대한 조절 및 음소 수준 주석을 제공합니다. 데이터셋은 CC BY-NC-SA 4.0 라이센스로 사용 가능합니다.

- **Performance Highlights**: GTSinger의 사용 가능성과 품질을 검증하기 위해 기법 제어 노래 음성 합성, 기술 인식, 스타일 전이, 음성-노래 전환 등 4가지 벤치마크 실험이 수행되었습니다. 이를 통해 다양한 노래 임무에서 우수한 성능을 입증했습니다.



### Synergistic Simulations: Multi-Agent Problem Solving with Large Language Models (https://arxiv.org/abs/2409.13753)
Comments:
          15 pages, 5 figures, published in the MICS 2024 conference

- **What's New**: 이 논문은 Large Language Models (LLMs)을 활용하여 다중 에이전트 시스템을 개발하는 방법을 제시하고 있습니다. 특히, 시뮬레이션 환경에서 에이전트 간의 상호작용을 통합하여 인간 그룹의 문제 해결능력을 모델링하고자 합니다.

- **Technical Details**: 두 가지 시뮬레이션을 구현했습니다: 첫 번째는 두 명의 룸메이트가 있는 물리적 스튜디오 아파트 시뮬레이션, 두 번째는 에이전트들이 프로그래밍 과제를 협력하여 완수하는 시뮬레이션입니다. 이 논문에서는 멀티-에이전트 프레임워크에 대해 논의하고 각 시뮬레이션에서 에이전트의 성능을 분석합니다.

- **Performance Highlights**: 이 연구는 LLM이 인간 협력의 시너지를 어떻게 나타내는지를 보여주려 하며, 미래에 LLM의 응용 가능성을 높이는 데 기여할 수 있는 방향성을 모색합니다.



### VisScience: An Extensive Benchmark for Evaluating K12 Educational Multi-modal Scientific Reasoning (https://arxiv.org/abs/2409.13730)
Comments:
          89 pages, 70 figures

- **What's New**: 이번 논문에서는 다양한 과학 분야에서 다중 모달 대형 언어 모델(MLLMs)의 성능을 평가하기 위해 VisScience라는 새로운 벤치마크를 제시합니다. 이는 수학, 물리학, 화학 세 가지 과목을 아우르며, K12 교육을 기반으로 한 3,000개의 질문을 포함합니다.

- **Technical Details**: VisScience 벤치마크는 초등학교부터 고등학교까지의 21개 주제를 포함하여 각 과목마다 1,000개의 질문을 포함하고 있으며, 질문은 5개의 난이도 수준으로 구분됩니다. 이 연구에서는 25개의 대표적인 MLLMs의 과학적 추론 능력을 평가합니다.

- **Performance Highlights**: 실험 결과에 따르면, 폐쇄형(Closed-source) MLLMs가 개방형(Open-source) 모델보다 일반적으로 뛰어난 성능을 보였습니다. Claude3.5-Sonnet 모델은 수학 53.4%의 정확도를 기록하며 가장 높은 성능을 나타냈고, GPT-4o는 물리학 38.2%, Gemini-1.5-Pro는 화학 47.0%의 정확도를 기록했습니다.



### Retrieval Augmented Generation-Based Incident Resolution Recommendation System for IT Suppor (https://arxiv.org/abs/2409.13707)
Comments:
          7 pages, 3 figures, 6 tables

- **What's New**: 이 연구는 IT 지원 도메인에서의 솔루션 추천 시스템을 위해 개발된 Retrieval Augmented Generation(RAG) 시스템을 소개합니다. 특히, IBM Slate 125m 모델을 사용하여 단일-턴과 다중-턴 IT 지원 사례를 분류하는 새로운 접근법과 성능을 보고합니다.

- **Technical Details**: 시스템은 네 가지 주요 구성 요소로 이루어져 있습니다: encoder-only transformer classifier, query generation system, retriever system, 그리고 answer generator system. 데이터 수집은 약 19,000개의 실제 지원 사례를 기반으로 하며 다양한 소프트웨어 제품에서 수집되었습니다. CNN(Convolutional Neural Networks) 및 cosine similarity를 활용하여 문서를 검색하고 재랭크합니다.

- **Performance Highlights**: 연구 결과, 작은 모델들이 RAG 사건 해결 사용 사례에서 매우 큰 모델들과 동등하거나 더 나은 성능을 보여주었다고 보고합니다. 최종적으로 F1 점수가 0.65에 이르고, 클래스 분류 정확도가 0.54, 재현율이 0.80으로 나타났습니다.



### Declarative Integration and Management of Large Language Models through Finite Automata: Application to Automation, Communication, and Ethics (https://arxiv.org/abs/2409.13693)
Comments:
          Submitted to IAAI-2025, Philadelphia, PA

- **What's New**: 이 논문에서는 공유 히스토리(shared histories)와 트리거(triggers)를 사용하여 주어진 작업에 가장 적합한 대형 언어 모델(Large Language Models, LLMs)을 선언적으로 결합할 수 있는 혁신적인 아키텍처를 제안합니다.

- **Technical Details**: 이 접근 방식은 유한 오토마타(finite automata)와 이벤트 관리 시스템(event management system)을 기반으로 하며, 프로그래밍 노력을 최소화하면서 LLM의 복잡한 통합을 지원합니다. 특히, 긍정 심리학(positive psychology) 방법을 AI와 통합하는 데 유용합니다. 아키텍처 설계 과정은 상태 정의, 트리거 우선순위 설정, LLM의 프롬프트 작성 등의 단계를 포함합니다.

- **Performance Highlights**: 이 프레임워크는 다양한 예제를 통해 그 유연성을 입증했으며, 기차 티켓 예약 자동화, 비폭력적 의사소통(non-violent communication) 계획, LLM의 윤리적 이슈 예방과 관련된 예제를 포함합니다. 이를 통해 복잡한 멀티모달 시스템에서도 효과적인 LLM 통합이 가능함을 보여주었습니다.



New uploads on arXiv(cs.IR)

### Cross-Domain Keyword Extraction with Keyness Patterns (https://arxiv.org/abs/2409.18724)
Comments:
          26 pages, 14 figures

- **What's New**: 이 논문은 주제의존성(domain dependence)과 주석 주관성(annotation subjectivity) 문제를 해결하기 위한 감독된(keyword extraction) 키워드 추출 방식을 제안합니다. 저자는 커뮤니티 수준에서 존재하는 이차적(keyness patterns) 키니스 패턴을 학습하여 키워드를 순위화하는 접근 방식을 소개합니다.

- **Technical Details**: 제안된 접근 방식에서는 독립(feature) 특성(서브랭귀지 도메인 및 용어 길이 포함)과 세 가지 범주의 종속(dependent) 특성(휴리스틱, 특이성, 대표성)을 가진 키니스 패턴을 기반으로 키워드를 평가합니다. 두 개의 합성곱 신경망(convolutional neural network) 모델을 사용하여 키워드 데이터셋에서 키니스 패턴을 학습하며, 부트스트랩 샘플링(bootstrap sampling) 전략으로 주석 주관성을 극복합니다.

- **Performance Highlights**: 이 접근 방식은 일반 감독된 키워드 추출에서 평균 top-10-F-measure 0.316을 기록하며, 총 10개의 키워드 데이터셋에서 최첨단 성능을 달성했습니다. 또한, 훈련 과정에서 제외된 4개의 데이터셋에서 평균 top-10-F-measure 0.346을 기록하며 강력한 크로스 도메인(cross-domain) 성능을 보였습니다.



### Scalable Cross-Entropy Loss for Sequential Recommendations with Large Item Catalogs (https://arxiv.org/abs/2409.18721)
Comments:
          11 pages, accepted for RecSys'24

- **What's New**: 본 논문은 기존의 Cross-Entropy (CE) 손실 함수를 대체하는 새로운 Scalable Cross-Entropy (SCE) 손실 함수를 소개합니다. 이 SCE 손실 함수는 큰 항목 목록을 다루는 데이터 세트에서 CE 손실을 근사하여, 추천 품질을 유지하면서도 시간 효율성과 메모리 사용량을 개선합니다.

- **Technical Details**: SCE 손실 함수는 선택적인 GPU 효율적 계산 전략을 활용하여, 카탈ログ에서 가장 유익한 요소에 집중하고 특히 false positives 가능성이 높은 요소에 중점을 둡니다. 이를 위해 최대 내부 곱 검색(maximum inner product search)을 통해 모델 출력의 하위 집합에 대한 softmax 분포를 근사합니다.

- **Performance Highlights**: 실험 결과, SCE는 다른 대안들과 비교하여 최대 메모리 사용량을 100배까지 줄이면서도 성능 지표를 유지하거나 초과하는 효과를 입증했습니다. 이 접근법은 대규모 언어 모델과 같은 다양한 도메인에서의 대규모 개발 가능성도 열어줍니다.



### Less is More: Towards Sustainability-Aware Persuasive Explanations in Recommender Systems (https://arxiv.org/abs/2409.18690)
Comments:
          The paper was accepted for publication and will be presented in the LBR track of RecSys 2024, 14.- 18. October 2024, Bari, Italy

- **What's New**: 이 논문은 추천 시스템에서 '지속 가능성 인식 설득적 설명'(sustainability-aware persuasive explanations)의 개념을 제안하며, 이는 유엔의 지속 가능한 발전 목표(SDGs)를 달성하는 데 기여할 수 있음을 강조합니다.

- **Technical Details**: 지속 가능성 인식 설득적 설명은 사용자 신뢰를 높이고 특정 제품 구매를 유도하며, 추천의 이유를 이해하도록 도와줍니다. 기존의 전자 상거래 플랫폼에서 흔히 보지 못했던 '적을수록 더 많은' 원칙에 중점을 두고 있습니다. 연구는 세 가지 항목 도메인에서 사용자 연구를 기반으로 하여 진행되었습니다.

- **Performance Highlights**: 사용자 수용성 및 지속 가능성 인식 설득적 설명의 잠재적 효과에 대한 연구 결과가 유망하게 나타났습니다.



### Corpus-informed Retrieval Augmented Generation of Clarifying Questions (https://arxiv.org/abs/2409.18575)
- **What's New**: 이번 연구는 웹 검색을 위한 정보에 기반한 clarifying questions를 생성하는 모델을 개발하는 것을 목표로 합니다. 이는 검색된 코퍼스와 일치하는 질문을 생성하는 방식을 보장합니다.

- **Technical Details**: Retrieval Augmented Language Models (RAG)의 효과를 입증하며, 사용자 쿼리와 검색 코퍼스를 공동으로 모델링하여 불확실성을 특정하고 명확한 질문을 만드는 과정을 중심으로 합니다. 또한, 질문의 폭을 넓히기 위해 더 많은 증거 문서를 모델링하는 방법을 제시합니다. 

- **Performance Highlights**: 현재의 데이터셋은 검색 의도가 코퍼스에 대부분 지원되지 않아 질문 생성 모델이 잘못된 의도를 제안하는 'hallucinate' 현상이 발생합니다. 이를 해결하기 위해 ground truth clarifications와 검색 코퍼스를 정렬하는 데이터셋 증강 방법을 제안하며, 증거 풀의 관련성을 높이기 위한 기법을 연구합니다. 그러나 corpus 내에서 ground truth intents를 식별하는 것은 여전히 어려운 과제임을 확인합니다.



### Decomposing the Jaccard Distance and the Jaccard Index in ABCDE (https://arxiv.org/abs/2409.18522)
- **What's New**: 이 논문은 매우 큰 클러스터링(clusterings) 간의 차이를 평가하는 데 사용되는 ABCDE 기법을 소개합니다. JaccardDistance와 JaccardIndex의 새로운 분해(decomposition)를 수행하여 Impact 및 Quality 메트릭(metric)을 도출했습니다.

- **Technical Details**: JaccardDistance는 두 클러스터링 간의 차이의 크기를 측정하는 진정한 거리 메트릭이며, JaccardIndex는 클러스터링 간의 유사성을 나타내는 보완적인 메트릭입니다. 이 두 메트릭의 관계는 JaccardDistance + JaccardIndex = 1로 표현됩니다. 이는 클러스터링 변화의 특성을 이해하는 데 도움을 줍니다.

- **Performance Highlights**: 논문에서 제안한 새로운 메트릭은 수학적으로 잘 정의되어 있으며 간단한 방정식(equations)을 통해 서로 연결되어 있습니다. 이를 통해 클러스터링 변화의 양 및 품질에 대한 통찰력을 제공합니다.



### Efficient Top-k s-Biplexes Search over Large Bipartite Graphs (https://arxiv.org/abs/2409.18473)
- **What's New**: 이 논문에서는 bipartite graph의 새로운 개념인 $s$-biplex를 소개하고, 이들 중 최대 $k$ 개의 가장 큰 $s$-biplex를 찾는 top-$k$ $s$-biplex search (TBS) 문제를 정의합니다. TBS 문제는 NP-hard임을 증명하며, 이를 해결하기 위해 새로운 branching algorithm인 MVBP를 제안합니다.

- **Technical Details**: $s$-biplex의 정의는 각 서브그래프의 정점이 반대 집합의 최대 $s$개의 정점을 제외한 모든 정점과 인접해야 한다는 것입니다. 제안된 MVBP 알고리즘은 단순한 $2^n$ enumeration 알고리즘을 개선하며, FastMVBP의 경우 $O^*(\gamma_s^{d_2})$의 시간 복잡도를 가집니다. 여기서 $\gamma_s<2$이고, $d_2$는 드문 real-world 그래프의 정점 수보다 훨씬 작습니다.

- **Performance Highlights**: FastMVBP 알고리즘은 8개의 실제 및 합성 데이터셋에 대한 광범위한 실험을 통해 기존의 벤치마크 알고리즘보다 최대 세 배 더 빠른 성능을 발휘했습니다.



### Generative Retrieval Meets Multi-Graded Relevanc (https://arxiv.org/abs/2409.18409)
Comments:
          Accepted by the NeurIPS 2024 (Spotlight)

- **What's New**: 이 논문에서는 정보 검색을 위한 새로운 접근법인 Generative retrieval에 대해 소개합니다. 기존의 방법은 이진 관련성 데이터에 한정되어 있었으나, 본 연구는 다중 등급 관련성을 위한 새로운 프레임워크인 GRaded Generative Retrieval (GR$^2$)을 제안합니다.

- **Technical Details**: GR$^2$는 두 가지 주요 구성 요소에 중점을 둡니다. 첫째, 관련성이 높고 구별 가능한 식별자(docids)를 만드는 것입니다. 이를 위해 docid 생성과 autoencoder 모델의 조합을 통해 관련성과 구별성을 동시에 최적화합니다. 둘째, 관련 등급(relevance grades) 간의 관계에 대한 정보를 훈련 과정에 통합하여 다중 등급 제약 대조 훈련(multi-graded constrained contrastive training)을 구현합니다. 이를 통해 쿼리 및 해당 관련 문서의 식별자 표현을 더 가깝게 만듭니다.

- **Performance Highlights**: GR$^2$는 다중 등급과 이진 관련성이 혼합된 데이터셋에서 광범위한 실험을 수행하였으며, 그 결과 GR$^2$의 효과를 입증하였습니다. 이러한 성과는 개별 문서를 효과적으로 표현할 수 있는 식별자 생성을 가능하게 했음을 나타냅니다.



### Evaluation of Cluster Id Assignment Schemes with ABCDE (https://arxiv.org/abs/2409.18254)
- **What's New**: 이 논문은 클러스터링에서 각 클러스터에 고유한 클러스터 ID를 할당하는 새로운 방법을 제안합니다. 특히, 클러스터가 동일한 개념을 나타낼 경우, 역사적인 클러스터와 동일한 ID를 부여하여 의미론적 ID 안정성을 유지하는 것이 목적입니다.

- **Technical Details**: 이 논문에서는 id 할당의 상대적 장점을 평가하기 위해, 역사적인 클러스터링과 이를 기반으로 한 새로운 클러스터링을 비교합니다. 이 과정에서 기본(Baseline) 방식과 실험 방식으로 할당된 ID 간의 차이를 평가하며, 이를 위해 클러스터 ID 할당 문제를 클러스터 멤버십 문제로 변환하여 ABCDE 기법으로 평가합니다. ABCDE는 수십억 개의 항목이 수백만 개의 클러스터에 그룹화되는 현실 세계의 애플리케이션에서 클러스터 멤버십의 차이를 평가하는 정교한 기술입니다.

- **Performance Highlights**: 이 연구 결과, ID 할당의 질과 규모를 특성화하는 메트릭(metrics)을 생성하여, 클러스터 멤버십과 ID의 변화를 동시에 평가할 수 있는 접근 방식을 제시합니다. 다양한 예를 활용하여 이 아이디어를 설명하고 있습니다.



### LML: Language Model Learning a Dataset for Data-Augmented Prediction (https://arxiv.org/abs/2409.18957)
Comments:
          First version

- **What's New**: 이 논문은 대규모 언어 모델(LLMs)을 분류 작업에 활용하기 위한 새로운 접근 방식을 소개합니다. 전통적인 머신 러닝(ML) 모델들과는 달리, LLMs를 사용하여 데이터 정리(data cleaning)와 특징 공학(feature engineering)을 간소화합니다.

- **Technical Details**: 이 논문은 'Language Model Learning (LML)'이라는 새로운 개념과 'Data-Augmented Prediction (DAP)'이라는 새로운 방법을 제안합니다. LLM이 데이터를 탐색하고 이해하며 분류를 결정하는 방식으로 분류를 수행합니다. DAP 과정에서는 데이터 요약을 사용하여 자동으로 쿼리를 생성하고, 이를 통해 관련 데이터 행을 검색한 후, 최종적인 분류 결과를 생성합니다.

- **Performance Highlights**: 테스트 사례에서 시스템의 정확도가 90%를 초과하여 기존 ML 모델을 다양한 시나리오에서 초월할 가능성을 입증하였습니다. 사용자가 예측의 논리를 검토할 수 있도록 'Explainable Machine Learning Model'로 행위하는 문구를 프롬프트에 포함시킴으로써 예측의 해석 가능성을 향상시켰습니다.



### Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models (https://arxiv.org/abs/2409.18878)
Comments:
          submitted to AMIA Informatics Summit 2025 as a conference paper

- **What's New**: 이번 연구는 정신과 고위험 환경에서 자살 사건을 정확하게 식별하고 분류하여, 자살 예방 조치를 개선하고 운영 부담을 감소시키며 치료 품질을 향상시키는 방법을 제시합니다.

- **Technical Details**: 해당 연구에서는 두 가지 미세 조정 전략(단일 라벨 다수 및 단일 다중 라벨)을 사용하여 500개의 주석이 달린 정신과 평가 노트를 기반으로 네 가지 BERT(Bidirectional Encoder Representations from Transformers) 모델의 성능을 평가하였습니다. 노트는 자살적 사고(SI), 자살 시도(SA), 자살 노출(ES), 비자살적 자기 상해(NSSI)로 라벨링되었습니다.

- **Performance Highlights**: RoBERTa 모델이 binary relevance(이진 관련성) 방법을 사용하여 다른 모델보다 뛰어난 성능을 발휘하여 accuracy(정확도)가 0.86, F1 score가 0.78로 나타났습니다. MentalBERT는 F1 score가 0.74로 BioClinicalBERT의 0.72를 초과하였으며, 단일 다중 라벨 분류기로 미세 조정된 RoBERTa는 0.88의 정확도와 0.81의 F1 score로 성능이 더욱 향상되었습니다.



### Explainable Enrichment-Driven GrAph Reasoner (EDGAR) for Large Knowledge Graphs with Applications in Drug Repurposing (https://arxiv.org/abs/2409.18659)
Comments:
          10 pages, 5 figures, 4 tables

- **What's New**: 이 논문에서는 실세계 개체 간의 연결 및 관계를 나타내는 지식 그래프(Knowledge Graphs, KGs)를 위한 새로운 링크 예측 프레임워크인 Enrichment-Driven GrAph Reasoner(EDGAR)를 제안합니다. 이 프레임워크는 엔티티 지역 규칙(entity-local rules)을 발굴하여 새로운 간선을 추론합니다.

- **Technical Details**: EDGAR는 차별적으로 발현된 유전자 세트에 공통적인 메커니즘을 식별하는 데 사용되는 통계적 방법인 enrichment 분석을 활용합니다. EDGAR의 추론 결과는 본질적으로 설명 가능하고 순위 매길 수 있으며, 각 enrichment 기반 규칙의 통계적 유의성을 나타내는 p-값을 포함합니다. 이 시스템은 ROBOKOP이라는 대규모 생물의학 KG에서 알츠하이머병(AD) 치료를 위한 약물 재창출(drug repurposing) 사례 연구를 통해 그 효과를 입증합니다.

- **Performance Highlights**: KG에서 14개의 알려진 약물을 추출한 후, enrichment 분석을 통해 20개의 맥락적 바이오마커(contextual biomarkers)를 식별하였습니다. 이를 통해 AD에 대한 공유 약물 효능과 관련된 기능적 경로(functional pathways)를 드러냈고, 상위 1000개의 enrichment 결과를 사용하여 1246개의 추가 약물 후보를 발견했습니다. 상위 10개 후보는 의료 문헌의 증거를 통해 검증되었습니다. EDGAR는 ROBOKOP 내에서 배포되어 웹 사용자 인터페이스를 갖추고 있습니다.



### Do We Need Domain-Specific Embedding Models? An Empirical Investigation (https://arxiv.org/abs/2409.18511)
Comments:
this https URL

- **What's New**: 이 논문에서는 금융 분야에 특화된 Embedding 모델의 필요성을 살펴보며, 새로운 금융 Massive Text Embedding Benchmark (FinMTEB)를 도입하였습니다.

- **Technical Details**: FinMTEB는 금융 분야에 특화된 데이터셋으로 구성되어 있으며, 최신 Embedding 모델 7개의 성능을 평가하였습니다. 데이터셋의 복잡도를 측정하고 분석하여 FinMTEB에서의 성능 저하가 모델의 한계를 나타내는지 검증했습니다.

- **Performance Highlights**: 일반 목적의 MTEB와 비교했을 때, FinMTEB에서 최신 모델들의 성능이 현저히 저하된 것을 관찰하였으며, 이는 금융 분야에 특화된 언어적 및 의미적 패턴을 포착하는 데 어려움을 겪고 있음을 보여줍니다.



### Neural Collaborative Filtering to Detect Anomalies in Human Semantic Trajectories (https://arxiv.org/abs/2409.18427)
Comments:
          Accepted for publication in the 1st ACM SIGSPATIAL International Workshop on Geospatial Anomaly Detection (GeoAnomalies'24)

- **What's New**: 이번 연구에서는 인간의 궤적(anomaly detection in human trajectories) 이상 탐지를 위해 경량화된 모델을 개발하였습니다. 이는 기존의 차량 중심 애플리케이션에 비해 부족했던 인간 수준의 궤적 이상 탐지 연구에 기여하고자 합니다.

- **Technical Details**: 우리는 Neural Collaborative Filtering 접근법을 통해 정상적인 이동 패턴(normal mobility)을 모델링하고 예측하는 방법을 제안합니다. 이 방법은 선험적 지식(prior knowledge) 없이 인간 사용자들의 일상 패턴을 모델링함으로써, 데이터가 희소하거나 불완전한 상황(예: cold start)에서 성능을 향상시킵니다. 알고리즘은 두 개의 주요 모듈로 구성됩니다: 첫 번째는 협업 필터링 모듈(collaborative filtering module)로, 개별 사용자의 정상적인 이동 패턴을 모델링합니다. 두 번째는 신경 모듈(neural module)로, 인간 궤적 데이터에 내재된 복잡한 시공간(spatio-temporal) 관계를 해석합니다.

- **Performance Highlights**: 우리는 시뮬레이션 데이터 및 실제 데이터셋을 사용하여 기존의 최첨단 궤적 이상 탐지 방법들과 비교하고, 우리의 방법이 더 우수한 성능을 보임을 보여주었습니다.



### Tracking Software Security Topics (https://arxiv.org/abs/2409.18351)
- **What's New**: 이번 논문에서는 소프트웨어 보안(Security) 관련 주제를 실시간으로 추적할 수 있도록 돕는 새로운 도구, SOSK를 제안합니다.

- **Technical Details**: SOSK는 사용자가 보안 보고서(Report) 집합을 가져와 이를 전처리(pre-process)하고, 텍스트 설명에서 가장 중요한 키워드(Keywords)를 추출합니다. 키워드의 임베딩 벡터(Embedding vector) 유사성을 기반으로 하여, SOSK는 사용자 제공 키워드 세트에서 키워드 세트를 확장하거나 정제할 수 있습니다.

- **Performance Highlights**: 초기 평가 결과, SOSK는 키워드를 효과적으로 확장하고, 사용자 요청에 맞는 보안 보고서를 성공적으로 검색할 수 있음을 보여주었습니다.



### Report on the Workshop on Simulations for Information Access (Sim4IA 2024) at SIGIR 2024 (https://arxiv.org/abs/2409.18024)
Comments:
          Preprint of a SIGIR Forum submission for Vol. 58 No. 2 - December 2024

- **What's New**: 2024년 SIGIR에서 열린 Sim4IA 워크숍에서는 사용자 시뮬레이션(user simulation)의 중요성을 강조하며, 온라인 및 오프라인 평가의 간극을 메울 가능성과 정보 접근을 위한 사용자 시뮬레이션 공유 작업의 조직 문제를 다루었습니다.

- **Technical Details**: 워크숍에서는 사용자 시뮬레이션을 기반으로 한 정보 접근 시스템 평가에 관한 연구자 및 전문가들이 모였으며, 개인화된 정보 접근과 사용자 모델링(user modeling)에 대한 논의가 이루어졌습니다. Gabriella Pasi와 Martin Mladenov의 기조 강연에서는 사용자 경험을 활용한 개인화의 필요성과 사용자 시뮬레이션을 A/B 테스트를 대체할 수 있는 가능성에 대해 논의했습니다.

- **Performance Highlights**: Sim4IA 워크숍은 25명의 참가자가 참여하여 활발한 논의가 이루어진 상호작용 중심의 행사였으며, 참가자들은 짧은 강연과 패널 토론, 브레이크 아웃 세션을 통해 향후 연구 주제에 대한 심화 논의를 진행했습니다.



### Enhancing Tourism Recommender Systems for Sustainable City Trips Using Retrieval-Augmented Generation (https://arxiv.org/abs/2409.18003)
Comments:
          Accepted at the RecSoGood 2024 Workshop co-located with the 18th ACM Conference on Recommender Systems (RecSys 2024)

- **What's New**: 이 논문은 지속 가능한 관광을 고려하여 관광 추천 시스템(Tourism Recommender Systems, TRS)의 새로운 접근 방식을 제안합니다. 이 시스템은 대규모 언어 모델(Large Language Models, LLMs)과 수정된 Retrieval-Augmented Generation(RAG) 파이프라인을 통합하여 사용자 맞춤형 추천을 개선하고 있습니다.

- **Technical Details**: 전통적인 RAG 시스템에 도시의 인기와 계절 수요 기반의 지속 가능성 지표(Sustainability Metric)를 포함하여, Sustainability Augmented Reranking(SAR)라는 수정을 통해 추천의 지속 가능성을 보장합니다. 이 시스템은 사용자 쿼리에 대한 자연어 응답을 기반으로 유럽의 지속 가능한 도시를 추천하도록 설계되었습니다.

- **Performance Highlights**: Llama-3.1-Instruct-8B와 Mistral-Instruct-7B와 같은 인기 있는 오픈 소스 LLM을 사용하여 평가한 결과, SAR이 적용된 방식이 대부분의 메트릭에서 기준선(baseline)과 일치하거나 성능이 우수함을 보여, TRS의 지속 가능성을 통합하는 것의 이점을 강조합니다.



### A Multimodal Single-Branch Embedding Network for Recommendation in Cold-Start and Missing Modality Scenarios (https://arxiv.org/abs/2409.17864)
Comments:
          Accepted at 18th ACM Conference on Recommender Systems (RecSys '24)

- **What's New**: 이 논문은 추천 시스템에서 콜드 스타트(cold-start) 문제를 해결하기 위한 새로운 방법으로, 멀티모달(single-branch) 임베딩 네트워크를 제안합니다. 이를 통해 다양한 모달리티에 기반한 추천 성능을 개선하고자 합니다.

- **Technical Details**: 제안된 방법은 SiBraR(Single-Branch embedding network for Recommendation)로 불리며, 여러 모달리티 데이터를 공유하는 단일 브랜치 네트워크를 통해 처리합니다. SiBraR는 상호작용 데이터와 여러 형태의 사이드 정보를 동일한 네트워크에서 인코딩하여 모달리티 간의 간극(modality gap)을 줄입니다.

- **Performance Highlights**: 대규모 추천 데이터셋에서 실시한 실험 결과, SiBraR는 콜드 스타트 과제에서 기존의 CF 알고리즘과 최신 콘텐츠 기반 추천 시스템(Content-Based Recommender Systems)보다 유의미하게 우수한 성능을 보였습니다.



### Value Identification in Multistakeholder Recommender Systems for Humanities and Historical Research: The Case of the Digital Archive Monasterium.n (https://arxiv.org/abs/2409.17769)
Comments:
          To be presented at: NORMalize 2024: The Second Workshop on the Normative Design and Evaluation of Recommender Systems, October 18, 2024, co-located with the ACM Conference on Recommender Systems 2024 (RecSys 2024), Bari, Italy

- **What's New**: 본 논문은 인문학 및 역사 연구 분야에서 추천 시스템(Recommender Systems, RecSys)의 활용 가능성을 탐구합니다. 특히 Monasterium.net이라는 디지털 아카이브를 중심으로 다양한 이해관계자(stakeholders)의 가치(hostakeholder values)를 식별하고, 이들의 상충하는 요구를 이해하여 추천 시스템의 효용성을 높이는 방안을 제시합니다.

- **Technical Details**: 추천 시스템은 과거의 사용 행동을 분석하여 사용자에게 관련 콘텐츠를 제안하는 기술입니다. 본 논문에서는 인문학과 디지털 인문학(Digital Humanities, DH)의 맥락에서 추천 시스템의 적용이 적절히 이루어지지 않았음을 언급하며, 특히 법적 문서와 문화유산 데이터의 집합 및 전파에 유용할 수 있는 가능성을 강조합니다. Monasterium.net은 약 65만 개의 차터(charters)를 포함한 디지털 아카이브로, 현재 기계 학습(machine learning) 파이프라인의 통합을 통해 사용자 경험을 향상시키고 있습니다.

- **Performance Highlights**: 현재 Monasterium.net은 유럽과 북미에서 매월 약 4,000회의 방문을 받고 있으며, 3,000명의 가입 사용자가 데이터 생성 및 주석 작성 기능에 접근하고 있습니다. 추천 시스템의 도입은 다차원적이고 다양한 데이터를 효과적으로 필터링 및 계층화함으로써 관련 문서의 검색 효율성을 개선할 것으로 기대합니다.



### Few-shot Pairwise Rank Prompting: An Effective Non-Parametric Retrieval Mod (https://arxiv.org/abs/2409.17745)
Comments:
          Accepted to EMNLP 2024

- **What's New**: 이번 연구에서는 기존의 감독 학습 방식의 복잡성을 줄이고, 대규모 언어 모델(LLM) 기반의 간단한 순위 모델을 제안하여 제로샷(zero-shot) 환경에서도 효과적인 성능 향상을 이끌어냈습니다.

- **Technical Details**: 제안된 방법은 쿼리와 문서 쌍을 기준으로 유사한 쿼리들의 선호 예시를 활용하여, 쿼리와 문서의 쌍에 대한 상대적 선호 순서를 예측합니다. 이는 대규모 언어 모델의 언어 처리 능력을 이용한 몇 샷(few-shot) 프롬프트를 통해 이루어집니다. 이를 통해 기존의 제로샷 모델보다 지속적으로 성능이 개선되었음을 보였습니다.

- **Performance Highlights**: 제안된 모델은 TREC DL과 BEIR 서브셋 벤치마크에서 제로샷 기준선보다 일관된 향상을 보였으며, 복잡한 훈련 파이프라인 없이 감독 모델과 유사한 성능을 달성했습니다. 또한, MS-MARCO의 예시 쿼리를 이용한 실험에서 TREC Covid과 SciFact 테스트 컬렉션에 대한 아웃 오브 도메인 일반화의 가능성을 보여주었습니다.



### Autoregressive Generation Strategies for Top-K Sequential Recommendations (https://arxiv.org/abs/2409.17730)
- **What's New**: 이 논문에서는 사용자의 미래 상호작용을 예측하는 Top-K 순차 추천(task)에서 생성적 transformer 기반 모델의 적용 가능성을 탐구합니다. 특히, 일반적으로 사용되는 오토회귀 생성 전략인 greedy decoding, beam search, temperature sampling을 비교하고, 새로운 Reciprocal Rank Aggregation(RRA) 및 Relevance Aggregation(RA) 전략을 제안합니다.

- **Technical Details**: 제안된 접근법은 GPT-2 모델을 사용하여 장기 예측을 수행하는 Top-K 추천 작업에 적용되었습니다. 새로운 multi-sequence 생성 및 집합 방법으로서, 여러 개의 시퀀스를 생성하고 이를 집계하여 최종 추천 목록을 만듭니다. 또한, 다음 항목 예측 작업을 위해 훈련된 모델에서 유용한 성능을 보여줍니다.

- **Performance Highlights**: 제안된 방식은 전통적인 Top-K 예측 방법과 단일 시퀀스 오토회귀 생성 전략에 비해 긴 시간 범위에서 성능을 향상시킵니다. 실험 결과, 제안된 생성 전략이 추천의 성능을 크게 향상시키고 오류 누적을 줄여주는 데 기여함을 보여줍니다.



### Efficient Pointwise-Pairwise Learning-to-Rank for News Recommendation (https://arxiv.org/abs/2409.17711)
- **What's New**: 이 논문에서는 사전 훈련된 언어 모델(PLM)을 기반으로 하는 뉴스 추천의 새로운 프레임워크를 제안합니다. 이 프레임워크는 점수 기반의 pointwise(포인트와이즈) 접근법과 쌍 비교(pairwise) 접근법을 통합하여 규모 문제를 해결합니다.

- **Technical Details**: 제안된 알고리즘인 GLIMPSE는 뉴스 추천을 위해 multi-task(다중 작업) 훈련을 수행합니다. GLIMPSE는 단일 텍스트 생성 작업으로 두 가지 목표(관련성 예측 및 선호도 예측)를 결합하여 최종 순위를 도출합니다. 이 과정에서 Right-To-Left (RTL) 패스를 통해 adjacently(인접하게) 비교를 수행합니다.

- **Performance Highlights**: 광범위한 실험을 통해 MIND와 Adressa 뉴스 추천 데이터셋에서 최신 방법들과 비교하여 성능이 향상된 것을 보여주었습니다.



### Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study (https://arxiv.org/abs/2409.17580)
- **What's New**: Structured-GraphRAG는 복잡한 데이터셋에서 정보 검색의 정확성과 관련성을 향상시키기 위해 설계된 새로운 프레임워크입니다. 이 방법은 전통적인 데이터 검색 방법의 한계를 극복하고, 구조화된 데이터셋에서 자연어 질의를 통한 정보 검색을 지원합니다.

- **Technical Details**: Structured-GraphRAG는 여러 개의 지식 그래프(knowledge graph)를 활용하여 데이터 간의 복잡한 관계를 포착합니다. 이를 통해 더욱 세밀하고 포괄적인 정보 검색이 가능하며, 결과의 신뢰성을 높이고 언어 모델의 출력을 구조화된 형태로 바탕으로 답변을 제공합니다.

- **Performance Highlights**: Structured-GraphRAG는 전통적인 검색 보완 생성 기법과 비교하여 쿼리 처리 효율성을 크게 향상시켰으며, 응답 시간을 단축시켰습니다. 실험의 초점이 축구 데이터에 맞춰져 있지만, 이 프레임워크는 다양한 구조화된 데이터셋에 널리 적용될 수 있어 데이터 분석 및 언어 모델 응용 프로그램의 향상된 도구로 기능합니다.



### Improving the Shortest Plank: Vulnerability-Aware Adversarial Training for Robust Recommender System (https://arxiv.org/abs/2409.17476)
- **What's New**: 이번 연구에서는 추천 시스템의 취약성을 고려한 새로운 방법인 Vulnerability-aware Adversarial Training (VAT)을 제안합니다. 이 방법은 사용자의 적합도에 따라 공격에 대한 보호를 조정함으로써 추천 품질을 유지합니다.

- **Technical Details**: VAT는 사용자의 적합도를 기반으로 취약성을 추정하는 기능을 구현하고, 이를 바탕으로 사용자별로 적응적인 크기의 perturbations를 적용합니다. 이는 기존의 동일한 크기의 perturbations가 아닌, 사용자 맞춤형으로 이루어져 공격의 성공률을 낮추고 추천 품질을 높입니다.

- **Performance Highlights**: VAT는 다양한 추천 모델 및 여러 유형의 공격에 대해 평균 공격 성공률을 21.53% 감소시키면서도, 추천 성능은 12.36% 향상시키는 것으로 확인되었습니다.



### Towards More Relevant Product Search Ranking Via Large Language Models: An Empirical Study (https://arxiv.org/abs/2409.17460)
Comments:
          To be published in CIKM 2024 GenAIECommerce Workshop

- **What's New**: 이 논문은 e-commerce 제품 검색 순위를 최적화하기 위한 새로운 접근 방식을 제안합니다. 특히, Large Language Models (LLMs)를 사용하여 랭킹 관련성을 콘텐츠 기반(content-based)과 참여 기반(engagement-based)으로 분해하고, 이를 모델 학습 과정에서 효율적으로 활용하는 방법을 다룹니다.

- **Technical Details**: 논문은 Learning-to-Rank (LTR) 프레임워크를 기반으로 하며, Walmart.com의 고객 검색 트래픽 데이터를 통해 모델을 학습합니다. 이 과정에서 콘텐츠 기반 관련성과 참여 기반 관련성으로 랭킹 관련성을 나누고, LLM을 사용하여 두 가지 관련성을 균형 있게 고려한 레이블을 생성합니다. 특히, Mistral 7B 모델을 활용하여 인간 평가 데이터를 바탕으로 콘텐츠 기반 관련성 점수를 미세 조정하는 과정을 포함합니다.

- **Performance Highlights**: 제안된 모델은 콘텐츠 기반과 참여 기반 관련성을 균형 있게 반영하여 검색 결과의 유용성을 개선하며, 온라인 테스트와 오프라인 평가를 통해 그 성능을 입증했습니다. 이는 e-commerce 제품 검색랭킹에 LLM을 통합하는 보다 효과적이고 균형 잡힌 모델 디자인을 제시합니다.



### Long or Short or Both? An Exploration on Lookback Time Windows of Behavioral Features in Product Search Ranking (https://arxiv.org/abs/2409.17456)
Comments:
          Published in ACM SIGIR Workshop on eCommerce 2024

- **What's New**: 본 논문에서는 전자 상거래에서 고객의 쇼핑 행동 특성이 상품 검색 순위 모델에 미치는 영향을 연구했습니다. 특히, (query, product) 레벨의 행동 특성을 집계할 때 사용되는 lookback time window의 효과를 조사하며, 이러한 역사적 행동 특성을 통합하는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 행동 특성의 집계 방법에 대한 실증적 연구를 통해, 긴 시간 창 (long time window)과 짧은 시간 창 (short time window)의 장단점을 분석했습니다. 이를 바탕으로, 두 가지 행동 특성을 효과적으로 모델에 통합하는 방법론을 제시했고, Walmart.com의 온라인 A/B 테스트를 통해 이를 검증했습니다.

- **Performance Highlights**: A/B 테스트 결과, 짧은 행동 특성이 Food 및 Consumables 카테고리에서 중요한 역할을 하며, 반대로 ETS와 같은 다이나믹한 환경에서는 짧은 창이 더 유용하다는 것을 확인했습니다. 그러나 두 가지 유형의 행동 특성을 통합한 모델은 전반적으로 성능이 저하되는 경향을 보였습니다.



### Minimizing Live Experiments in Recommender Systems: User Simulation to Evaluate Preference Elicitation Policies (https://arxiv.org/abs/2409.17436)
- **What's New**: 이 연구에서는 YouTube Music 플랫폼의 신규 사용자를 위한 온보딩 프로세스를 평가하는 데 있어, 시뮬레이션 방법론을 개발하여 A/B 테스트를 대체하고 비용을 줄이는 방안을 제시합니다.

- **Technical Details**: 연구의 핵심은 반사적이고 강건한 사용자 행동 모델을 개발하여, 시뮬레이션 서비스를 통해 실시간 실험을 수행하지 않고도 알고리즘의 성능 예측을 가능하게 한다는 것입니다. 이를 위해 순환 신경망(recurrent neural networks)과 트랜스포머(transformers)를 사용하여 사용자 모델을 생성하였습니다.

- **Performance Highlights**: 본 연구는 새로운 PE(preference elicitation) 방법을 통해 신규 사용자가 특정 음악 아티스트에 대한 선호도를 동적으로 질문받는 성과를 보여주었으며, 이러한 프로세스는 실시간 데이터와 연결된 시뮬레이션을 통해 A/B 테스트의 요구 사항을 줄일 수 있음을 시사합니다.



### Results of the Big ANN: NeurIPS'23 competition (https://arxiv.org/abs/2409.17424)
Comments:
          Code: this https URL

- **What's New**: 2023 Big ANN Challenge는 NeurIPS 2023에서 개최되어 Approximate Nearest Neighbor(ANN) 검색의 최신 진행을 목표로 했습니다. 이전에는 전통적인 ANN 검색을 대규모로 확장하는 데 중점을 두었지만, 이번 대회는 필터링 검색, 분포 밖 데이터(out-of-distribution data), 희소(sparse) 및 스트리밍 변형을 다루었습니다.

- **Technical Details**: 이번 대회에서는 필터링된 검색, 분포 밖 데이터, 희소 벡터, 스트리밍 시나리오와 같은 네 가지 트랙이 구성되었습니다. 각 트랙은 데이터베이스로부터 색인을 구축해야 하며, 데이터셋은 공공 클라우드 저장소에서 다운로드할 수 있는 형태로 제공되었습니다. 모든 참가자는 제한된 컴퓨팅 자원으로 새로운 표준 데이터셋에서 제출된 혁신적인 솔루션을 평가받았습니다.

- **Performance Highlights**: 참가 팀들은 업계 표준 기준에 비해 검색 정확성 및 효율성에서 유의미한 개선을 보였으며, 특히 학계 및 산업 팀들로부터 많은 주목할 만한 기여가 있었습니다.



### Enhancing Recommendation with Denoising Auxiliary Task (https://arxiv.org/abs/2409.17402)
- **What's New**: 본 연구는 사용자의 이력(interaction sequences)에서 발생하는 잡음(noise)이 추천 시스템에 미치는 영향을 다루고 있으며, 이를 개선하기 위한 새로운 방법인 자가 감독(Auto-supervised) 보조 작업 결합 훈련(Auxiliary Task Joint Training, ATJT)을 제안합니다.

- **Technical Details**: ATJT 방법은 원본 이력을 바탕으로 랜덤 대체를 통해 인위적으로 생성된 잡음이 포함된 시퀀스를 학습하여 모델의 성능을 향상시키기 위한 것입니다. 잡음 인식 모델과 추천 모델을 난이도에 따라 조정된 가중치로 훈련하여 잡음이 포함된 시퀀스로부터 적절한 학습을 이끌어냅니다.

- **Performance Highlights**: ATJT 방법은 세 개의 데이터셋에서 일관된 기본 모델을 사용하여 실험한 결과, 모델의 추천 성능을 개선하는 데 효과적임을 입증했습니다.



### VectorSearch: Enhancing Document Retrieval with Semantic Embeddings and Optimized Search (https://arxiv.org/abs/2409.17383)
Comments:
          10 pages, 14 figures

- **What's New**: 이 논문은 고차원 데이터 검색의 정확성을 높이기 위해 'VectorSearch'라는 새로운 알고리즘을 제안합니다. 이 시스템은 고급 언어 모델과 다중 벡터 인덱싱 기술을 통합하여 텍스트 데이터의 의미적 관계를 더 잘 파악할 수 있도록 설계되었습니다.

- **Technical Details**: VectorSearch는 데이터의 다차원 임베딩(embeddings)을 효율적으로 검색하는 하이브리드(document retrieval framework) 시스템입니다. HNSWlib 및 FAISS와 같은 최적화 기법을 사용하여 대규모 데이터셋을 효과적으로 관리하고, 복잡한 쿼리 처리 기능을 통해 고급 검색 작업을 지원합니다. 또한, 시스템은 클러스터 환경에서 동적으로 변화하는 데이터셋을 처리할 수 있는 메커니즘을 포함하고 있습니다.

- **Performance Highlights**: 실제 데이터셋을 기반으로 한 실험 결과, VectorSearch는 기존의 기준 메트릭을 초월하여 대규모 검색 작업에서 뛰어난 성능을 보였습니다. 이는 높은 차원의 데이터에서도 저지연성 검색 결과를 제공함으로써 정보 검색의 정확성을 획기적으로 향상시킨 것을 나타냅니다.



### Mamba for Scalable and Efficient Personalized Recommendations (https://arxiv.org/abs/2409.17165)
Comments:
          8 pages, 6 figures, 2 tables

- **What's New**: 이번 연구에서는 개인화 추천 시스템에서 표 형식(tabular data) 데이터를 처리하기 위해 FT-Mamba(Feature Tokenizer + Mamba)라는 새로운 하이브리드 모델을 제안합니다. 이 모델은 FT-Transformer 아키텍처 내의 Transformer 레이어를 Mamba 레이어로 대체하여, 계산 복잡성을 줄이고 효율성을 향상시킵니다.

- **Technical Details**: FT-Mamba 모델은 Mamba 아키텍처를 활용하여, 표 형식 데이터를 시퀀스 형태로 변환하고, Mamba 레이어를 통해 처리합니다. Mamba는 State Space Model(SSM)의 효율성을 개선하며, 시퀀스의 길이에 대해 선형 복잡도(𝒪(L))를 제공합니다. 이는 일반적인 Transformer의 제곱 복잡도(𝒪(L²))를 극복할 수 있게 합니다. 이 모델은 Three datasets (Spotify, H&M, Vaccine messaging)에서 평가되었습니다.

- **Performance Highlights**: FT-Mamba는 기존의 Transformer 기반 모델에 비해 계산 효율성이 향상되었으며, 정확도 같은 주요 추천 지표에서 성능을 유지하거나 초과했습니다. FT-Mamba는 사용자 정보를 인코딩하는 Two-Tower 구조를 사용하여, 개인화 추천 시스템을 위한 확장 가능하고 효과적인 솔루션을 제공합니다.



### Open-World Evaluation for Retrieving Diverse Perspectives (https://arxiv.org/abs/2409.18110)
- **What's New**: 새로운 연구 Benchmark for Retrieval Diversity for Subjective questions (BeRDS)을 소개하여, 여러 관점을 포괄하는 문서 셋을 검색하는 과정을 분석하였습니다.

- **Technical Details**: 이 연구는 복잡한 질문에 대한 다양한 관점을 검색하는 방식을 다룹니다. 단순한 문자열 일치에 의존하지 않고 언어 모델 기반의 자동 평가자를 사용하여 문서가 특정 관점을 포함하는지 판단합니다. 세 가지 유형의 말뭉치(Wikipedia, 웹 스냅샷, 검색 엔진 결과 활용)를 조합한 성능을 평가합니다.

- **Performance Highlights**: 기존의 검색 시스템은 다양한 관점을 포함한 문서 세트를 33.74%의 경우에만 검색할 수 있었습니다. 쿼리 확장 및 다양성 중심의 재정렬 방법을 적용하여 성능 향상을 관찰하였으며, 이러한 접근법들이 밀집 검색기와 결합된 경우 더욱 강력한 결과를 보였습니다.



### Revisit Anything: Visual Place Recognition via Image Segment Retrieva (https://arxiv.org/abs/2409.18049)
Comments:
          Presented at ECCV 2024; Includes supplementary; 29 pages; 8 figures

- **What's New**: 이번 연구에서는 Embodied agents가 시각적으로 장소를 인식하고 이동하는 데 있어 중요한 문제를 다루었습니다. 전체 이미지를 사용하는 기존 방법 대신, 이미지의 '세그먼트'를 인코딩하고 검색하는 새로운 접근 방식을 제안합니다. 이를 통해 SuperSegment라는 새로운 이미지 표현을 생성하여 장소 인식을 향상시킵니다.

- **Technical Details**: 제안된 SegVLAD는 Open-set 이미지 분할(open-set image segmentation)을 통해 이미지를 의미있는 요소(entities)로 분해합니다. 각 아이템은 SuperSegments로 연결되어 구조화됩니다. 새로 제안된 Feature aggregation 방법을 사용하여 이 SuperSegments를 효율적으로 컴팩트한 벡터 표현으로 인코딩합니다. SegVLAD는 다양한 벤치마크 데이터셋에서 기존의 방법보다 높은 인식 리콜을 기록했습니다.

- **Performance Highlights**: SegVLAD는 다양한 VPR 벤치마크 데이터셋에서 최첨단 성능을 달성했습니다. IOU 기반 필터링을 통해 중복성을 줄이고 스토리지를 절약하며, 전체 이미지 기반 검색보다 더욱 뛰어난 성능을 보입니다. 연구 결과, SegVLAD는 이미지 인코더의 특정 작업에 관계없이 적용 가능하고, 객체 인스턴스 검색(object instance retrieval) 과제를 평가하여 '무언가를 재방문(revisit anything)'할 수 있는 잠재력을 보여주었습니다.



### On the Vulnerability of Applying Retrieval-Augmented Generation within Knowledge-Intensive Application Domains (https://arxiv.org/abs/2409.17275)
- **What's New**: 이 논문은 Retrieval-Augmented Generation (RAG) 시스템의 적대적 강인성(adversarial robustness)을 조사하였습니다. 특히, 의학 분야의 Q&A를 대상으로 한 '보편적인 중독 공격(universal poisoning attacks)'의 취약성을 분석하고 새로운 탐지 기반(defense) 방어 체계를 개발하였습니다.

- **Technical Details**: RAG 시스템은 외부 데이터에서 중요한 정보를 검색(retrieve)하고 이를 LLM의 생성 과정에 통합하는 두 가지 단계를 포함합니다. 이 연구에서는 225개 다양한 설정에서 RAG의 검색 시스템이 개인 식별 정보(PII)와 같은 다양한 타겟 정보를 포함하는 중독 문서에 취약하다는 것을 입증하였습니다. 중독된 문서는 쿼리의 임베딩과 높은 유사성을 유지함으로써 정확히 검색될 수 있음을 발견하였습니다.

- **Performance Highlights**: 제안한 방어 방법은 다양한 Q&A 도메인에서 뛰어난 탐지율(detection rates)을 일관되게 달성하며, 기존의 방어 방법에 비해 훨씬 효과적임을 보여주었습니다. 실험에 따르면 거의 모든 공격에 대해 일관되게 높은 탐지 성공률을 보였습니다.



### Enhancing Automatic Keyphrase Labelling with Text-to-Text Transfer Transformer (T5) Architecture: A Framework for Keyphrase Generation and Filtering (https://arxiv.org/abs/2409.16760)
- **What's New**: 이 논문은 Text-to-Text Transfer Transformer (T5) 아키텍처를 기반으로 한 새로운 키프레이즈 생성 모델 docT5keywords를 제안합니다. 이 모델은 문서의 제목과 초록을 입력으로 받아 키프레이즈를 생성합니다. 또한, 다수결 접근법을 통해 생성된 여러 시퀀스의 빈도에 따라 키프레이즈를 정렬하여 예측 결과를 개선하는 방법을 소개합니다.

- **Technical Details**: 모델은 T5 아키텍처를 사용하여 문서의 키프레이즈와 관련된 두 가지 평가 방법론을 구현합니다. 첫 번째는 이진 평가로, 키프레이즈가 주어진 문서와 관련 있는지를 예측합니다. 두 번째로, 여러 AKG 모델에 의한 예측 키프레이즈 필터링을 통해 평가 점수를 개선하는 방법을 사용합니다. 이를 통해 정확성을 높이고 불필요한 키프레이즈를 줄이는 방법을 제안합니다.

- **Performance Highlights**: 실험 결과, 제안한 키프레이즈 생성 모델은 모든 기준선 모델을 크게 능가하며, 일부 경우 100% 이상의 성능 향상을 보였습니다. 필터링 기술은 모든 데이터 세트에서 가짜 긍정(False Positive)을 제거하는 데 근사 완벽한 정확도를 달성했습니다.



### A Prompting-Based Representation Learning Method for Recommendation with Large Language Models (https://arxiv.org/abs/2409.16674)
Comments:
          Risks: The 1st International Workshop on Risks, Opportunities, and Evaluation of Generative Models in Recommendation

- **What's New**: 최근 대규모 언어 모델(LLM)이 추천 시스템(RS) 분야에 도입됨에 따라, 해당 시스템은 혁신적인 변화를 겪고 있습니다. 본 논문은 LLM의 특성을 고려한 새로운 추천 프레임워크인 Prompting-Based Representation Learning Method for Recommendation (P4R)을 제안합니다.

- **Technical Details**: P4R 프레임워크는 LLM 프롬프트 전략을 활용하여 개인화된 항목 프로필을 생성하고, 이 프로필은 미리 학습된 BERT 모델을 사용해 의미적 표현 공간으로 변환됩니다. 또한, 협업 필터링을 위한 Graph Convolution Network (GCN)도 통합되어 일반 추천 작업을 해결합니다.

- **Performance Highlights**: P4R은 최신 추천 모델들과 성능을 비교하였고, LLM 기반 추천 시스템에서 어떤 맥락 정보가 중요한지를 분석했습니다. 실험 결과, 특히 중소기업에 적합한 성능 향상을 보여주었습니다.



### Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation (https://arxiv.org/abs/2409.16627)
Comments:
          Accepted to EMNLP 2024 Findings

- **What's New**: 본 연구에서는 다중 모드 추천 시스템을 위한 경량화된 프레임워크인 full-scale Matryoshka representation learning for multimodal recommendation (fMRLRec)를 소개합니다. fMRLRec는 서로 다른 세부 수준에서 아이템 특징을 캡처하며, 정보적 표현을 학습하여 다차원에서 효율적인 추천을 제공합니다.

- **Technical Details**: fMRLRec는 다양한 모드에서 아이템 특징을 통합하기 위해 간단한 매핑 기법을 사용하여 다중 모드 아이템 특징을 정렬된 피처 공간으로 투사합니다. 효율적인 선형 변환을 설계하여 더 작은 특징을 더 큰 특징으로 임베드하여 대규모 추천 데이터 교육을 위한 메모리 요구 사항을 대폭 줄입니다.

- **Performance Highlights**: fMRLRec는 여러 벤치마크 데이터셋에서 그 효과성과 효율성을 입증하며, 최신 방법들과 비교했을 때 추천 성능과 교육 효율성에서 일관되게 우수한 성과를 보여줍니다.



### Generative Pre-trained Ranking Model with Over-parameterization at Web-Scale (Extended Abstract) (https://arxiv.org/abs/2409.16594)
- **What's New**: 본 연구에서는 웹 검색에서 중요한 웹페이지를 우선순위로 설정하기 위한 새로운 학습 모델인 Generative Semi-Supervised Pre-trained (GS2P) LTR 모델을 제안합니다. 이 모델은 부족한 주석(query-webpage pairs with ranking scores)의 문제를 해결하고, 일반화된 표현을 학습하도록 설계되었습니다.

- **Technical Details**: GS2P 모델은 고품질의 유사 레이블을 추출하기 위해 다양한 LTR 모델의 코-트레이닝(co-training)을 사용합니다. 이 과정에서 일반화된 표현을 학습하기 위해 자기 주의(self-attentive) 네트워크를 활용하며, MLP 기반의 ranker와 Random Fourier Features (RFF)를 조합하여 성능을 향상시킵니다.

- **Performance Highlights**: GS2P 모델은 공개 데이터셋과 실제 대규모 검색 엔진에서 수집한 데이터셋을 사용하여 실험을 수행하였으며, A/B 테스트를 통해 기존 시스템 대비 현저한 성능 향상을 보여주었습니다.



### FusionANNS: An Efficient CPU/GPU Cooperative Processing Architecture for Billion-scale Approximate Nearest Neighbor Search (https://arxiv.org/abs/2409.16576)
Comments:
          15 pages, 26 figures

- **What's New**: FusionANNS는 CPU와 GPU의 협업 필터링 및 재정렬 메커니즘을 활용하여 대량의 벡터 데이터셋에서 고처리량, 저지연, 비용 효율성 및 높은 정확도를 동시에 달성할 수 있는 새로운 ANNS 시스템입니다.

- **Technical Details**: FusionANNS는 (1) 다단계 인덱싱, (2) 휴리스틱 재정렬, (3) 중복 확인 I/O 중복 제거 등 세 가지 혁신적인 디자인을 통해 CPU와 GPU 간의 데이터 전송을 최소화하며, SSD에 저장된 원시 벡터와 GPU의 HBM에서 압축된 벡터를 결합하여 사용합니다.

- **Performance Highlights**: FusionANNS는 SPANN에 비해 9.4-13.1배 높은 QPS(초당 쿼리 수)와 5.7-8.8배 높은 비용 효율성을 달성했으며, RUMMY와 비교하여 2-4.9배 높은 QPS와 2.3-6.8배 높은 비용 효율성을 보장합니다.



### Algorithmic Drift: A Simulation Framework to Study the Effects of Recommender Systems on User Preferences (https://arxiv.org/abs/2409.16478)
- **What's New**: 이 논문은 추천 시스템의 장기적인 사용자 행동 변화에 대한 영향을 정량화할 수 있는 새로운 접근 방식을 제안합니다. 이 연구는 사용자와 추천 알고리즘 간의 상호작용을 모델링하기 위한 확률적 시뮬레이션 프레임워크를 채택합니다.

- **Technical Details**: 논문에서는 사용자 저항(user resistance) 및 관성(inertia)과 같은 행동적 측면을 포함하여 사용자 모델을 공식화하고, 추천 알고리즘이 사용자 선호에 미치는 영향을 평가하기 위해 새로운 메트릭스(새로운 지표)를 도입합니다. 시뮬레이션 모델은 처음에 이질적인 사용자 선호 그룹에서 시작되며, 추천 시스템이 초기 전이 확률을 유도하도록 설계되었습니다.

- **Performance Highlights**: 실험 결과, 제안하는 방법론이 사용자 선호의 변화(algorithmic drift)를 정확히 감지하고 정량화하는 데 효과적이라는 것을 입증하였습니다. 다양한 신합성 데이터셋을 통해 시스템의 강건성을 검증하며, 사용자 선택의 시나리오와 하이퍼 파라미터 설정에 따른 결과를 평가했습니다.



### Spacewalker: Traversing Representation Spaces for Fast Interactive Exploration and Annotation of Unstructured Data (https://arxiv.org/abs/2409.16793)
- **What's New**: 이번 논문에서 우리는 다양한 모달리티를 활용한 비구조화 데이터 분석을 위한 상호작용 도구인 Spacewalker를 소개합니다. 이 도구는 데이터를 탐색하고 주석을 달 수 있도록 설계되었습니다.

- **Technical Details**: Spacewalker는 사용자가 임의의 모달리티의 데이터 세트를 업로드하고, Low-dimensional space에서 데이터의 시맨틱 유사성을 강조하여 시각화할 수 있는 기능을 제공합니다. Bayesians networks 및 Deep Learning 기반의 방법을 사용하여 데이터를 추출합니다.

- **Performance Highlights**: 사용자 연구 결과, Spacewalker는 기존 방법에 비해 데이터 주석 속도를 현저히 개선하며, 데이터 무결성 검증 및 부패 데이터 세트 식별 작업에서도 빠른 탐색이 가능합니다.



### PIFS-Rec: Process-In-Fabric-Switch for Large-Scale Recommendation System Inferences (https://arxiv.org/abs/2409.16633)
- **What's New**: 이 논문은 Deep Learning Recommendation Models (DLRMs)의 성능 개선을 위해 CXL(Compute Express Link) 기술을 활용하여 새로운 PIFS-Rec(장비 스위치 내 작업 처리) 접근 방식을 제안합니다. 이는 메모리 및 대역폭 확장을 최적화하여 DLRMs를 가속화하는 데 중점을 둡니다.

- **Technical Details**: CXL 시스템에서 DLRM 작업량을 특성화하고 주된 병목 현상을 식별합니다. PIFS-Rec는 데이터 프로세싱과 효율적인 메모리 사용을 위한 하드웨어 및 소프트웨어 최적화를 결합하여, 낮은 대기 시간으로 Pond 및 BEACON과의 비교에서 각각 3.89배 및 2.03배 우수한 성능을 보입니다.

- **Performance Highlights**: PIFS-Rec는 CXL 기반 시스템에서의 DLRM 작업의 성능을 크게 향상시킵니다. 본 연구에서 제안한 접근 방식은 데이터 이동 비용을 줄이고, 메모리 대역폭 병목 현상을 해결하여 데이터 센터 규모의 DLRM 처리 성능을 극대화합니다.



### Evaluating and Enhancing Large Language Models for Novelty Assessment in Scholarly Publications (https://arxiv.org/abs/2409.16605)
Comments:
          under review

- **What's New**: 본 논문에서는 LLM(대형 언어 모델)의 학술 논문에서의 창의성 및 참신성을 평가하기 위한 새로운 벤치마크인 SchNovel을 도입하였습니다. 이 벤치마크는 arXiv 데이터 세트에서 선택된 15,000 쌍의 논문으로 구성되어 있으며, 각 쌍의 최근 발표된 논문이 더 참신하다고 가정합니다. 또한, RAG-Novelty라는 새로운 방법을 제안하여 LLM이 논문의 참신성을 평가할 때 유사한 논문의 검색을 활용합니다.

- **Technical Details**: SchNovel 벤치마크는 2~10년 차이가 나는 논문 쌍을 포함하며, 이는 특히 높은 수준의 리뷰 과정을 거치는 학술 논문에서 참신성을 평가하는 데 중요합니다. RAG-Novelty는 검색 기반 생성 방법으로, 더 참신한 논문일수록 최근 발표된 논문을 더 많이 검색할 것이라는 가정을 바탕으로 합니다.

- **Performance Highlights**: 광범위한 실험을 통해 RAG-Novelty가 기존의 기준 모델보다 논문의 참신성을 평가하는 데 더 뛰어난 성능을 보인다는 것을 입증했습니다. 이 연구는 LLM의 논문 참신성 평가 능력을 깊이 있게 탐구하고, 다양한 카테고리와 출판 연도 간의 변화를 평가하여 LLM의 성능 향상에 기여하였습니다.



### Pre-trained Graphformer-based Ranking at Web-scale Search (Extended Abstract) (https://arxiv.org/abs/2409.16590)
- **What's New**: MPGraf 모델은 Transformer와 Graph Neural Networks (GNNs)의 장점을 통합하여 학습 랭킹(learning to rank) 문제에 접근합니다. 이 모델은 모듈형 및 캡슐 기반의 사전 학습(pre-training) 전략을 사용하여 웹 규모의 통합된 LTR 프레임워크를 구현합니다.

- **Technical Details**: MPGraf는 세 가지 주요 단계를 포함합니다: (1) Link Rippiling을 통한 그래프 구성, (2) Hybrid Graphformer를 통한 표현 학습, (3) 모듈 구성(modular composition)을 통한 정밀 조정(surgical fine-tuning)입니다. 이를 통해 sparsely annotated query-webpage 쌍에서 그래프 기반 학습 데이터를 생성하고, GNN과 Transformer 모듈을 조합하여 하이브리드 아키텍처에서 특성 학습을 수행합니다.

- **Performance Highlights**: MPGraf는 실제 검색 엔진 환경에서 extensive offline 및 online 실험을 수행한 결과, 최신의 웹페이지 랭킹 방법들과 비교하여 최고의 성능을 나타냈습니다. 특히 온라인 평가에서 상당한 개선을 달성했습니다.



### Modern Hopfield Networks meet Encoded Neural Representations -- Addressing Practical Considerations (https://arxiv.org/abs/2409.16408)
Comments:
          17 pages, 8 figures, workshop submission to Neurips

- **What's New**: 본 논문은 Modern Hopfield Networks (MHN)에 대한 메타 안정 상태 문제를 해결하는 새로운 접근 방식인 Hopfield Encoding Networks (HEN)를 소개합니다. HEN은 입력 패턴의 분리 가능성을 높이고, 메타 안정 상태를 줄이기 위해 인코딩된 신경 표현을 통합합니다.

- **Technical Details**: HEN은 미리 훈련된 신경 인코더-디코더 모델을 사용하여 입력을 잠재 표현 공간으로 인코딩한 후 저장하고, 재호출 시 다시 디코딩하는 방법을 사용합니다. 이 접근 방식은 MHNs의 메타 안정 상태 문제를 해결하고, 자연어 쿼리를 통한 다양한 입력 모달리티에서의 검색을 가능하게 합니다.

- **Performance Highlights**: 실험 결과는 HEN이 메타 안정 상태를 크게 줄이고, 저장 용량을 증가시키면서 다양한 입력을 완벽히 기억할 수 있음을 나타냅니다. 이는 실제 작업을 위한 연상 기억 네트워크의 실용적인 활용을 향상시킵니다.



### Towards Enhancing Linked Data Retrieval in Conversational UIs using Large Language Models (https://arxiv.org/abs/2409.16220)
Comments:
          This paper has been accepted at the 25th International Web Information Systems Engineering Conference (WISE 2024)

- **What's New**: 이 논문은 기존 정보 시스템과 LLMs(대형 언어 모델)의 통합을 통해 Linked Data(LD) 및 RDF(Ressource Description Framework) 트리플스토어에서 데이터를 추출하고 탐색하는 방법을 탐구합니다. 특히, 모델 재훈련 없이도 더 정확한 SPARQL 쿼리를 생성할 수 있는 대화형 사용자 인터페이스(UI)의 강화를 강조합니다.

- **Technical Details**: 본 연구에서는 ForestQB라는 새로운 툴킷을 사용하여 관찰적 LD 데이터로부터 정보를 추출하고, 이 툴킷은 챗봇과 폼 기반 GUI를 통합하여 SPARQL 쿼리를 구성하고 실행합니다. 연구의 초점은 LLMs의 자연어 이해 능력을 활용하여 RDF 엔티티 추출의 정확성을 향상시키는 것입니다.

- **Performance Highlights**: 본 연구의 결과, 제안된 방법론을 통해 시스템의 표현력과 사용자 쿼리에 대한 응답 정확성이 크게 향상되었습니다. 평가 결과는 LLMs가 복잡한 데이터 환경에서 엔티티 추출 및 사용자 인터랙션을 개선시킬 수 있는 가능성을 제시하고 있습니다.



### TiM4Rec: An Efficient Sequential Recommendation Model Based on Time-Aware Structured State Space Duality Mod (https://arxiv.org/abs/2409.16182)
- **What's New**: 본 연구에서는 TiM4Rec이라는 새로운 시퀀스 추천 백본 모델을 제안하며, low-dimensional 성능 감소 문제를 해결함과 동시에 Mamba 아키텍처의 계산 효율성을 유지합니다. 이는 SSD 아키텍처의 시간 인지 향상 기법을 통해 이루어집니다.

- **Technical Details**: TiM4Rec는 Mamba 아키텍처를 기반으로 하며, 먼저 SSD 아키텍처의 성능 한계를 극복하기 위한 시간 인지 향상 방법을 도입합니다. 이 모델은 low-dimensional 환경에서의 성능을 개선하면서도, linear computational complexity를 유지합니다. TiM4Rec는 기존 Transformer 구조의 SASRec 및 Mamba4Rec 모델보다 훈련 속도와 추론 속도에서 유리합니다.

- **Performance Highlights**: TiM4Rec는 세 가지 데이터 세트를 통해 실험을 진행하였으며, low-dimensional 환경에서 SSD4Rec보다 우수한 성능을 보여주고, high-dimensional 시나리오에서 SSD 아키텍처의 장점을 유지합니다.



### Ducho meets Elliot: Large-scale Benchmarks for Multimodal Recommendation (https://arxiv.org/abs/2409.15857)
- **What's New**: 이 논문은 multimodal recommender 시스템을 위한 대규모 벤치마킹을 제공하는 첫 번째 시도로, 특히 multimodal feature extractor(다중 모달 특성 추출기)에 중점을 두고 있습니다.

- **Technical Details**: 논문에서는 (i) 다중 모달 특성 추출, (ii) 추천 작업에 적합하도록 고수준 표현 개선, (iii) 다중 모달 특성 융합, (iv) 사용자-아이템 점수 예측을 포함하는 기존의 multmodal 추천 파이프라인 과정에서, 첫 번째 단계인 다중 모달 특성 추출에 대한 탐구가 부족하다는 점을 강조합니다.

- **Performance Highlights**: Ducho와 Elliot라는 두 가지 다중 모달 특성 추출 프레임워크를 활용하여, 다양한 하이퍼 파라미터 설정하에 수행된 실험 결과가 중요 통찰력을 제공하여, 차세대 다중 모달 추천 알고리즘을 훈련 및 조정하는 데 도움이 될 수 있습니다.



### IRSC: A Zero-shot Evaluation Benchmark for Information Retrieval through Semantic Comprehension in Retrieval-Augmented Generation Scenarios (https://arxiv.org/abs/2409.15763)
- **What's New**: 이 논문은 다국어 Retrieval-Augmented Generation (RAG) 작업에서 임베딩 모델의 성능을 평가하기 위한 IRSC 벤치마크를 소개합니다. 이 벤치마크는 쿼리 검색, 제목 검색, 단락의 일부 검색, 키워드 검색, 요약 검색의 cinco 가지 검색 작업을 포함합니다.

- **Technical Details**: IRSC 벤치마크는 embedding 모델의 성능을 다양한 검색 과제에서 평가하며, 새로운 메트릭인 Semantic Comprehension Index (SSCI) 및 Retrieval Capability Contest Index (RCCI)를 도입했습니다. 이 벤치마크는 여러 언어(영어, 중국어 및 혼합 언어 데이터셋)에서 모델을 평가합니다.

- **Performance Highlights**: 연구 결과에 따르면, IRSC 벤치마크는 실용적인 RAG 작업에서의 embedding 모델의 성능을 더 잘 이해하고 개발하는 데 기여할 수 있습니다. 이 연구는 embedding 모델의 언어 간 한계를 통찰하는 데 중요한 기여를 합니다.



### Making Text Embedders Few-Shot Learners (https://arxiv.org/abs/2409.15700)
- **What's New**: 본 논문에서는 큰 언어 모델(LLM)의 인-context learning (ICL) 기능을 활용하여 텍스트 임베딩 생성 과정을 개선하는 새로운 모델 bge-en-icl을 제안합니다. 이 모델은 적은 수의 샘플을 사용하여 고품질의 텍스트 임베딩을 생성합니다.

- **Technical Details**: bge-en-icl 모델은 쿼리 프롬프트에 작업 관련 예제를 통합하여 LLM의 ICL 능력을 최대한 활용합니다. 이 연구에서는 다양한 attention 메커니즘과 pooling 방법을 평가하여 LLM을 임베딩 모델로 효과적으로 활용하는 방법을 조사했습니다.

- **Performance Highlights**: bge-en-icl 모델은 MTEB 및 AIR-Bench 벤치마크에서 새로운 최첨단(SOTA) 성능을 달성하였으며, 간단한 ICL 전략만으로도 뛰어난 성과를 거둘 수 있다는 것을 입증했습니다. 코드와 데이터셋은 자유롭게 제공됩니다.



### Cross-Domain Latent Factors Sharing via Implicit Matrix Factorization (https://arxiv.org/abs/2409.15568)
- **What's New**: 이 논문에서는 데이터 희소성 문제를 해결하기 위해 Cross-Domain Implicit Matrix Factorization (CDIMF) 모델을 제안합니다. CDIMF는 기존의 implicit matrix factorization을 확장하여 cross-domain 시나리오에서 사용할 수 있도록 합니다.

- **Technical Details**: CDIMF 모델은 Alternating Direction Method of Multipliers (ADMM)를 활용하여 사용자 간 공유 잠재 요인을 학습하면서 상호작용 행렬을 분해합니다. 이 방법은 사용자의 개인 데이터를 보호하면서 다양한 도메인에서 정보를 교환할 수 있게 합니다.

- **Performance Highlights**: 실험 결과, CDIMF는 여러 산업 데이터셋에서 cold-start와 warm-start 상황 모두에서 경쟁력을 보였으며, 최신 cross-domain 및 single-domain 모델보다 성능이 우수한 것으로 나타났습니다.



### GLARE: Guided LexRank for Advanced Retrieval in Legal Analysis (https://arxiv.org/abs/2409.15348)
Comments:
          26 pages, 8 figures, submitted to AI and Law

- **What's New**: 본 논문에서는 브라질의 특별 항소를 분류하기 위해 새로운 방법인 GLARE를 제안합니다. 이 방법은 비지도 기계 학습(unsupervised machine learning)을 기반으로 하며, 법적 주제를 탐색하는 데 필요한 기존 데이터의 수량적 요구를 줄입니다.

- **Technical Details**: GLARE 방법은 Graph 기반의 LexRank 알고리즘을 수정하여 'Guided LexRank'를 제안하고, BM25 알고리즘을 사용해 생성한 요약과 다양한 주제 간의 유사도를 평가합니다. 이 방법은 특별 항소의 내용을 요약한 후, 해당 요약과 기존 주제 간의 유사성을 평가하여 가장 적합한 주제를 순위 매깁니다.

- **Performance Highlights**: GLARE 방법은 TRF2의 기존 방법보다 훨씬 높은 정확도를 보였습니다. 특별 항소의 적합한 주제를 약 76%의 정확도로 추천할 수 있었으며, 이는 TRF2의 약 35%와 비교됩니다. 특히 데이터가 적은 특정 주제에서 비지도 학습 방법이 더 좋은 성능을 발휘했습니다.



### Big data searching using words (https://arxiv.org/abs/2409.15346)
- **What's New**: 이 논문에서는 빅데이터에서의 언어 검색의 이웃 구조에 대한 기본 개념을 소개하고, 이를 통해 빅데이터의 중요한 위상 구조를 형성하는 방법을 제시합니다.

- **Technical Details**: 논문은 빅데이터 검색에서 Jaccard 유사도(coefficient)를 사용하여 이웃 구조를 활용한 이상 탐지(anomaly detection) 방법을 논의합니다. 또한, 데이터 검색에서 빅데이터의 원시(primal) 개념을 도입합니다.

- **Performance Highlights**: 이 연구는 빅데이터 분석에서 TDA(Topological Data Analysis)와 같은 새로운 방법론의 필요성을 강조하며, 빅데이터의 이웃 구조를 탐색하는 데 있어 현재까지 발견되지 않은 위상적 특징들을 밝힐 가능성을 제안합니다.



### Advertiser Content Understanding via LLMs for Google Ads Safety (https://arxiv.org/abs/2409.15343)
- **What's New**: 이번 연구는 Google Ads 콘텐츠 정책의 일관성을 높이기 위해 광고주의 의도를 이해하는 방법을 제안합니다. 대규모 인공지능 모델(LLMs)을 활용하여 광고주의 콘텐츠 프로필을 생성하고 이를 바탕으로 정책 위반 가능성을 판단합니다.

- **Technical Details**: 연구에서는 LLM을 이용하여 광고주 정보를 수집한 뒤, 광고주 콘텐츠 프로필을 생성하고 이를 비즈니스, 도메인 신호 등 여러 데이터를 포함하여 분석합니다. 최종적으로 LLM이 광고주의 정책 위반 여부를 판단하는데 필요한 프롬프트를 조정합니다.

- **Performance Highlights**: 최소한의 프롬프트 조정을 통해 작은 테스트 세트에서 95%의 정확도에 도달하였습니다. LLM의 성능은 훈련 없이도 뛰어난 결과를 보여주었으며, 이는 향후 모델 개선 및 추가 프롬프트 조정으로 더욱 향상될 것으로 기대됩니다.



### Recall: Empowering Multimodal Embedding for Edge Devices (https://arxiv.org/abs/2409.15342)
- **What's New**: RECALL은 리소스가 제한된 모바일 환경을 위해 최적화된 최초의 on-device 멀티모달 임베딩 시스템이다. 이 시스템은 coarse-grained embedding을 생성하고 query 기반 필터링을 활용하여 높은 처리량과 정확한 검색을 달성한다.

- **Technical Details**: RECALL 시스템은 데이터 인식 pre-exit 예측기, Progressive LoRA healing, 그리고 Speculative fine-grained retrieval의 세 가지 하드웨어-알고리즘 공동 설계를 통해 동작한다. 이 시스템은 multi-layer transformer architecture를 통해 작동하며, coarse-grained embedding을 통해 모달리티 간 검색을 수행하고, 후속 쿼리 단계에서 최종 검색을 정제한다.

- **Performance Highlights**: RECALL은 평균 14.9배 처리량 향상과 13.1배 에너지 소비 감소를 달성하였다. 이 시스템은 배터리 소모를 최소화하면서도 높은 정확도를 유지하며, 전체 MEM에 비해 5% 미만의 상대적 정확도 손실을 초래한다.



### WISDOM: An AI-powered framework for emerging research detection using weak signal analysis and advanced topic modeling (https://arxiv.org/abs/2409.15340)
Comments:
          18 pages, 7 figures

- **What's New**: 이 연구는 WISDOM이라는 자동화된 인공지능(AI) 기반 프레임워크를 소개하여 복잡한 과학적 문제를 해결하고 새로운 연구 주제를 탐지하는 방법을 제시합니다. WISDOM은 고급 topic modeling과 weak signal 분석을 결합하여, 방대한 데이터를 신속하게 처리 및 분석하고, 숨겨진 교차학문적 패턴을 발견하며, 공정한 통찰력을 제공합니다.

- **Technical Details**: WISDOM은 여러 기술 영역에 적용 가능한 다층적이고 모듈형 접근 방식을 채택합니다. 이 프레임워크는 최신 기술인 BERTopic을 사용하여 연구 주제를 식별하고 그 진화를 추적합니다. 또한, weak signal 분석을 채택하여 기존 방법으로는 쉽게 발견하지 못하는 미세한 연구 동향을 탐지합니다. WISDOM은 2004년부터 2021년까지의 수중 감지 기술에 대한 과학 논문을 분석하여 성능을 평가합니다.

- **Performance Highlights**: WISDOM은 수중 감지 기술 분야에서 emerging research 주제를 식별하는 데 있어 높은 정확도와 신뢰성을 보여줍니다. 이 연구는 2004년부터 2021년까지의 데이터를 사용하여 시간에 따른 연구 주제의 진화를 파악하고, AI 기반 접근 방식이 주제 탐지 과정에서의 객관성을 높이며, 사람의 주관적 편향을 제거하는 데 기여한다고 강조합니다.



### Revisiting the Solution of Meta KDD Cup 2024: CRAG (https://arxiv.org/abs/2409.15337)
- **What's New**: 이 논문은 Meta KDD CUP 2024의 CRAG Comprehensive RAG Benchmark Challenge에서 팀 APEX의 솔루션을 소개합니다. CRAG 벤치마크는 Retrieval-Augmented Generation (RAG) 시스템의 다양하고 동적인 문제를 평가하는 데 있어 기존 QA 벤치마크의 한계를 극복할 수 있도록 설계되었습니다.

- **Technical Details**: 본 연구에서는 질문의 다양성과 동적인 특성에 맞춘routing 기반의 도메인 및 동적 적응 RAG 파이프라인을 제안합니다. 이 방법은 정보 검색(retrieval), 증대(augmentation), 생성(generation) 세 단계에서 모두 특별한 처리를 수행하며, CRAG에서 우수한 성과를 거두어 최종 경쟁 리더보드에서 작업 2와 3에서 2위를 기록했습니다.

- **Performance Highlights**: 우리의 방법은 CRAG에서 뛰어난 성과를 발휘했으며, 특히 웹 페이지 검색 및 Mock API를 활용해 정보 선택과 통합의 능력을 강조하였습니다. 각 과제는 이전 단계를 기반으로 하여, 참가자들이 더욱 정교한 end-to-end RAG 시스템을 개발하도록 유도합니다.



### Seeing Faces in Things: A Model and Dataset for Pareidolia (https://arxiv.org/abs/2409.16143)
- **What's New**: 본 연구에서는 인간과 머신 간의 face pareidolia (얼굴 패레이돌리아)에 대한 인식 차이를 조사하기 위해 새로운 데이터셋인 'Faces in Things'를 소개합니다. 이 데이터셋은 무작위로 생성된 이미지에서 인간이 인식한 얼굴 구조를 포함하고 있습니다.

- **Technical Details**: 이 연구는 5,000개의 웹 이미지로 구성된 'Faces in Things' 데이터셋을 사용하여 인간 얼굴 탐지 시스템의 성능을 분석합니다. 연구 결과는 최신 연구 모델인 RetinaFace를 사용하여 성과를 변별하며, 파리돌리아가 머신에서 어떻게 나타나는지를 탐구합니다.

- **Performance Highlights**: 최신 모델은 얼굴 패레이돌리아 탐지에서 인간의 성능에 비해 상당한 격차를 보였습니다. 연구는 이 격차의 약 절반이 동물 얼굴 탐지 모델을 미세 조정하는 것에서 개선될 수 있음을 보여줍니다. 또한, 'Goldilocks zone'이라고 불리는 조건들이 패레이돌리아를 유도할 수 있음을 실험으로 확인하였습니다.



### Exploring Hint Generation Approaches in Open-Domain Question Answering (https://arxiv.org/abs/2409.16096)
Comments:
          Accepted at EMNLP 2024

- **What's New**: 이 논문에서는 기존의 정보 검색(retrieval) 및 생성(generation) 기반 방법 대신 자동 힌트 생성(Automatic Hint Generation, HG) 기술을 활용한 새로운 QA 시스템 구성 요소인 HINTQA를 제안합니다. HINTQA는 질문에 대한 답변 가능성을 제시하는 힌트를 생성하여 QA 시스템의 정확도를 높입니다.

- **Technical Details**: HINTQA는 질문 q와 후보 답변 집합 𝒜을 활용하여 다수의 힌트를 생성합니다. 각 힌트는 수렴 점수(convergence score)인 HICOS를 통해 힌트의 유용성을 측정하며, 이는 질문에 대한 잠재적 답변을 좁힙니다. 제안된 시스템은 TriviaQA, Natural Questions, Web Questions 데이터셋을 사용하여 세 가지 QA 데이터셋에서 힌트 생성의 효과를 실험했습니다.

- **Performance Highlights**: HINTQA 방식은 정보 검색 및 생성 기반 방법보다 우수한 성과를 보였습니다. 연구 결과에 따르면 힌트를 사용하는 것이 검색된 문서나 생성된 문맥보다 답변의 정확성을 높이는 데 더 효과적이라는 것을 증명했습니다.



### SLIMER-IT: Zero-Shot NER on Italian Languag (https://arxiv.org/abs/2409.15933)
- **What's New**: 이 논문에서는 이탈리아어에 대한 제로샷 이름 개체 인식(Zero-Shot Named Entity Recognition, NER) 평가 프레임워크를 정의하고, 제로샷 NER을 위한 SLIMER의 이탈리아어 버전인 SLIMER-IT를 소개합니다. SLIMER-IT는 정의 및 가이드라인으로 향상된 프롬프트를 활용하여 다루지 않은 엔티티 태그를 식별하는 데 우수성을 보입니다.

- **Technical Details**: SLIMER-IT는 대형 언어 모델(LLM)을 기반으로 하며, 인스트럭션 튜닝(instruction tuning)을 통해 성능을 개선합니다. 이 접근법은 주어진 텍스트에서 각각의 엔티티 타입을 효과적으로 추출하기 위해 설계된 프롬프트를 사용하여, 모델이 각 엔티티 타입에 집중할 수 있도록 지원합니다. SLIMER는 네임드 엔티티(Named Entity)에 대한 정의와 가이드라인을 제공하여 모델의 라벨링을 최적화합니다.

- **Performance Highlights**: SLIMER-IT는 기존의 다른 최첨단 모델들과 비교했을 때 보지 못한 엔티티 태그(label)를 라벨링하는 데 있어 뛰어난 성능을 보여주었습니다. 실험 결과는 SLIMER-IT가 이탈리아어로 된 데이터셋에서 제로샷 NER을 수행하는 데 매우 효과적임을 입증하였습니다.



### Mitigating Digital Discrimination in Dating Apps -- The Dutch Breeze cas (https://arxiv.org/abs/2409.15828)
- **What's New**: 2023년 9월, 네덜란드 인권 연구소는 네덜란드의 데이팅 앱 Breeze가 비백인에 대한 차별 가능성을 의심한 것이 정당하다고 결정했습니다. 이로 인해 Breeze는 인종에 따른 차별을 방지해야 한다는 결정을 받았습니다.

- **Technical Details**: 이 논문은 Breeze의 매칭 알고리즘에서 인종에 기반한 차별이 불법인지에 대한 질문과 데이팅 앱들이 매칭 알고리즘에서 차별을 완화하거나 중단할 수 있는 방법을 탐구합니다. 또한, 컴퓨터 과학과 법률의 통찰을 결합하여 Breeze 결정의 법적 및 기술적 어려움을 심도 있게 분석합니다.

- **Performance Highlights**: 정당한 차별 방지 조치를 실행하며, 공정하고 비차별적인 머신러닝(machine learning) 분야에서의 연구와 실천에 대한 논의가 포함되어 있습니다.



### LLM-Cure: LLM-based Competitor User Review Analysis for Feature Enhancemen (https://arxiv.org/abs/2409.15724)
Comments:
          25 pages

- **What's New**: 이 연구에서는 사용자 리뷰를 통한 경쟁 앱 분석을 통해 모바일 앱 기능 향상을 자동으로 제안하는 LLM-Cure라는 접근법을 제안합니다.

- **Technical Details**: LLM-Cure는 사용자 리뷰에서 기능을 추출하고 분류하기 위해 Large Language Model (LLM)을 사용합니다. 앱 내 불만 사항이 제공되면, 경쟁 앱에서 4와 5점 리뷰를 큐레이션하여 타겟 앱에 대한 개선점을 제안합니다.

- **Performance Highlights**: LLM-Cure는 1,056,739개의 리뷰를 분석하여 기능 할당에서 13%의 F1-score, 16%의 recall, 11%의 precision 향상을 보였습니다. 또한, 제안된 개선 사항의 73%가 실제로 구현된 것으로 확인되었습니다.



### Optimizing News Text Classification with Bi-LSTM and Attention Mechanism for Efficient Data Processing (https://arxiv.org/abs/2409.15576)
- **What's New**: 이 논문은 전통적인 수동 분류 방법의 비효율성을 극복하기 위해 딥 러닝을 기반으로 한 뉴스 텍스트 자동 분류 방안을 제안합니다.

- **Technical Details**: 제안하는 방법은 Bi-directional Long Short-Term Memory Network (Bi-LSTM)와 Attention Mechanism을 결합한 최적화 모델을 사용하여 뉴스 텍스트의 효율적인 분류와 관리를 달성합니다.

- **Performance Highlights**: 실험 결과, 이 솔루션은 분류의 정확성과 시의성을 크게 향상시키고 수동 개입의 필요성을 줄이며, 뉴스 산업의 정보 처리 능력을 향상시키고 정보 흐름의 속도를 가속화하는 데 중요한 실용적 의미가 있음을 보여줍니다.



### Stalactite: Toolbox for Fast Prototyping of Vertical Federated Learning Systems (https://arxiv.org/abs/2409.15558)
- **What's New**: 이 논문에서는 다양한 데이터 소유자가 상대적으로 분산된 데이터를 활용하여 머신러닝 모델을 학습할 수 있도록 하는 Vertical Federated Learning (VFL)용 오픈 소스 프레임워크인 Stalactite를 소개합니다. 기존 프레임워크보다 연구자들이 알고리즘 개발에 집중할 수 있도록 UI가 개선되었으며, VFL의 다양한 알고리즘을 쉽게 구현할 수 있는 기능을 제공합니다.

- **Technical Details**: Stalactite는 수학적 개념과 메시지 교환 로직을 분리하는 설계를 통해 VFL 알고리즘을 쉽게 코드로 변환할 수 있도록 합니다. multi-thread, multi-process, distributed 실행 모드를 지원하며, 이들 모드 간의 전환이 간단합니다. 이 프레임워크는 데이터 전송, 훈련 메트릭 저장 등 다양한 기능을 포함하고 있습니다. 또한, Stalactite는 새로운 고유의 공개 데이터셋 SBOL을 제공하며, 레코드 ID를 매칭하여 훈련 집합을 형성합니다.

- **Performance Highlights**: Stalactite는 강화된 logging 기능을 통해 분산 실행 중의 payload, 교환 시간 및 머신러닝 메트릭을 기록할 수 있습니다. 이 프레임워크는 기존의 VFL 알고리즘을 지원하며, 보안성과 성능 면에서 기존 산업 도구의 한계를 극복하고 연구를 위한 실험 환경을 제공합니다.



### MedCodER: A Generative AI Assistant for Medical Coding (https://arxiv.org/abs/2409.15368)
- **What's New**: 이번 연구에서는 MedCodER라는 새로운 Generative AI 프레임워크를 소개하며, 의료 코딩의 자동화를 위한 혁신적인 접근 방식을 제시합니다. 특히, 이 프레임워크는 추출(Extraction), 검색(Retrieval), 재정렬(Re-ranking) 기술을 핵심 요소로 활용하여 높은 정확도를 자랑합니다.

- **Technical Details**: MedCodER는 의료 기록에서 질병 진단과 지원 증거를 추출하고, ICD-10 코드를 후보 코드로 검색한 다음, 이를 종합하여 최종 코드를 예측합니다. 이 과정에서 LLM(대형 언어 모델)의 파라메트릭 지식을 보완하기 위해 검색 및 재정렬 기술을 통합하여 성능을 향상시킵니다.

- **Performance Highlights**: MedCodER는 ICD 코드 예측에서 0.60의 micro-F1 점수를 달성하여 현재 최고의 방법보다 유의미하게 향상된 성과를 보입니다. 또한, 제안된 데이터셋은 질병 진단과 ICD 코드, 그리고 이를 정당화하는 지원 증거 텍스트가 주석 처리되어 있어, 코드 선택의 신뢰성을 높이는 데 기여합니다.



### VERA: Validation and Enhancement for Retrieval Augmented systems (https://arxiv.org/abs/2409.15364)
- **What's New**: VERA는 Retrieval-Augmented Generation (RAG) 시스템을 위한 평가 및 개선 시스템으로, LLM의 응답精度를 향상시키기 위한 새로운 방법을 제공합니다. 또한, VERA는 외부 정보를 효과적으로 활용하도록 설계되었습니다.

- **Technical Details**: VERA는 수집된 컨텍스트의 적합성과 불필요한 정보를 제거하는 데 중점을 둡니다. 이 시스템은 평가자 및 향상 LLM을 사용하여 응답 생성 전에 컨텍스트를 평가하고, 응답 생성 후에는 응답을 분리하여 각 문장의 적합성을 점검합니다.

- **Performance Highlights**: 실험 결과, VERA는 소규모 공개 오픈 소스 모델에서 뿐만 아니라 대규모 최첨단 모델에서도 성능을 개선하는 데 뛰어난 효능을 나타냈습니다. VERA는 정보 생성에서 높은 정확성 및 신뢰성을 요구하는 응용 프로그램에 유용한 도구로 자리 잡을 잠재력을 보여주고 있습니다.



### An Efficient Recommendation Model Based on Knowledge Graph Attention-Assisted Network (KGATAX) (https://arxiv.org/abs/2409.15315)
- **What's New**: 이번 연구에서는 다중 소스 정보를 효과적으로 활용하지 못하는 전통적인 추천 시스템의 한계를 극복하기 위해 'Knowledge Graph Attention-assisted Network (KGAT-AX)'라는 새로운 추천 모델을 제안합니다.

- **Technical Details**: KGAT-AX 모델은 추천 시스템에 지식 그래프(knowledge graph)를 통합하고 주의 메커니즘(attention mechanism)을 도입하여 더 높은 차원의 연결성을 탐구합니다. 다층 상호작용 정보 전파(multilayer interactive information propagation)를 통해 모델은 정보를 집계하여 일반화 능력을 향상시킵니다. 또한, 홀로그램 임베딩(holographic embeddings)을 통해 보조 정보(auxiliary information)를 엔티티에 통합하여, 인접 엔티티의 정보를 학습하여 더 나은 활용이 가능합니다.

- **Performance Highlights**: 실제 데이터셋에 대한 실험을 통해 KGAT-AX 모델의 합리성과 효과성을 입증하였으며, 공공 데이터셋에서 다른 기준선 모델(baseline models)과 비교하여 KGAT-AX가 지식 정보 캡처 및 관계 학습 능력에서 우수함을 확인했습니다.



### Equivariance-based self-supervised learning for audio signal recovery from clipped measurements (https://arxiv.org/abs/2409.15283)
- **What's New**: 이번 연구에서는 비선형 역문제(non-linear inverse problem)인 잘린 측정값(clipped measurements)으로부터 오디오 신호를 복구하는 데 자가지도학습(self-supervised learning) 기법을 적용했습니다. 그동안 자가지도학습은 주로 선형 역문제(linear inverse problems)에 집중되었습니다.

- **Technical Details**: 연구에서는 에퀴바리언스 기반(self-supervised loss)을 제안하며, 이를 통해 잘린 측정값에서 오디오 신호를 복구하는 방법을 연구했습니다. 특히 잘린 측정값의 수준이 다양하고 조절된 조건에서 성능을 평가하였습니다.

- **Performance Highlights**: 제안된 에퀴바리언스 기반 자가지도 해득 전략은 완전지도 학습(fully supervised learning)과 비교했을 때 성능이 유사하게 나왔으며, 교육을 위해 오직 잘린 측정값만을 요구하는 장점을 가지고 있습니다.



### Recommendation with Generative Models (https://arxiv.org/abs/2409.15173)
Comments:
          This submission is a full-length book, expanding significantly on two chapters previously submitted (arXiv:2409.10993v1, arXiv:2408.10946v1). It includes additional chapters, context, analysis, and content, providing a comprehensive presentation of the subject. We have ensured it is appropriately presented as a new, distinct work. arXiv admin note: substantial text overlap with arXiv:2409.10993

- **What's New**: 이 논문은 생성 모델(generative models)과 그 응용 분야에 대한 포괄적인 이해를 제공하며, 특히 딥 생성 모델(deep generative models) 및 그 분류 방법에 중점을 두고 있습니다.

- **Technical Details**: 연구에서 제시된 분류 체계는 딥 생성 모델(DGMs)을 ID 기반 모델(ID-driven models), 대형 언어 모델(large language models, LLMs), 다중 모달 모델(multimodal models)의 세 가지 유형으로 나눴습니다. 각 유형은 고유한 기술적 및 구조적 진전을 다룹니다.

- **Performance Highlights**: Gen-RecSys(생성 권장 시스템)는 더 개인화된, 매력적이며 동적인 사용자 경험을 창출하여 추천의 정확성과 다양성을 개선하는 데 기여합니다. 이 연구는 대화형 AI(conversational AI) 및 다중 모달 콘텐츠 생성(multimodal content generation)과 같은 다양한 분야에서의 발전 방향을 탐색합니다.



### Don't Use LLMs to Make Relevance Judgments (https://arxiv.org/abs/2409.15133)
- **What's New**: 본 논문에서는 TREC 스타일 테스트 수집을 위한 관련성 판단을 생성할 때 대규모 언어 모델(LLM)을 사용하지 말라는 메시지를 전달합니다. LLM이 자연어 프롬프트에 반응하여 인간과 유사한 텍스트 출력을 생성하는 최근의 발전이 정보 검색(IR) 연구자들에게 관련성 판단 수집 과정에서 이 모델들을 어떻게 활용할 수 있을지를 고민하게 했습니다.

- **Technical Details**: 관련성 판단을 수집하는 과정은 복잡하고 비용이 많이 드는 작업입니다. 전통적으로 TREC(텍스트 검색 구성)에서는 2-4주 동안 6명의 계약자가 팀을 이루어 작업을 수행하며, 그 과정에서 소프트웨어를 개발하고 관련성 판단을 기록하는 것에 집중합니다. LLM4Eval 워크숍은 이러한 관련성 판단 생성을 위한 실험을 진행한 자리이며, 결과적으로 도출된 주장은 자동 평가의 가능성을 탐구했던 이전 연구들을 계승하였습니다.

- **Performance Highlights**: 전반적으로 LLM을 사용하여 TREC 스타일의 평가를 위한 관련성 판단을 생성하는 것이 바람직하지 않다는 결론을 도출하였습니다. 정보 검색의 불확실성과 예측의 오류는 성능 평가에 있어 중요한 요소임을 강조하였습니다. 실제 하드웨어와 소프트웨어 개발 없이도 관련성 판단의 효율성을 극대화하기 위한 다양한 접근 방법들이 모색되고 있습니다.



### EMERS: Energy Meter for Recommender Systems (https://arxiv.org/abs/2409.15060)
Comments:
          Accepted at the RecSoGood 2024 Workshop co-located with the 18th ACM Conference on Recommender Systems

- **What's New**: 최근 머신러닝 발전으로 인해 추천 시스템의 교육, 평가 및 배포 과정에서 에너지 소비가 증가하고 있지만, 연구 커뮤니티는 실험의 에너지 소비를 잘 보고하지 않습니다. 이를 해결하기 위해 에너지 소비를 측정, 모니터링 및 기록할 수 있는 EMERS라는 소프트웨어 라이브러리를 소개합니다.

- **Technical Details**: EMERS는 Python 기반의 오픈소스 라이브러리로, 스마트 플러그를 통해 추천 시스템 실험의 에너지를 측정하고 기록합니다. EMERS는 사용자 인터페이스를 제공하여 에너지 소비를 모니터링하고 분석하며, 자동화된 보고서를 생성해 커뮤니티와 공유할 수 있습니다. 주요 기능으로는 사용자 인터페이스, 표준화된 보고서 생성, API를 통한 에너지 소비 로그 기록 및 독립형 로그 기록이 있습니다.

- **Performance Highlights**: EMERS는 에너지 소비를 고주파로 측정할 수 있는 스마트 플러그와 연동되어 있으며, 다양한 하드웨어 시스템에서 호환성과 정확성을 보장합니다. EMERS는 사용자 컴퓨터의 성능에 미치는 영향을 최소화하면서도, 추가 비용이 발생하는 스마트 플러그를 통해 정확한 에너지 소비 측정을 지원합니다.



### FedSlate:A Federated Deep Reinforcement Learning Recommender System (https://arxiv.org/abs/2409.14872)
- **What's New**: FedSlate는 사용자의 행동 간 상호작용을 고려하여 멀티 플랫폼에서 추천 알고리즘의 효율성을 극대화하는 연합 강화 학습 (federated reinforcement learning) 기반의 새로운 접근 방식을 제안합니다.

- **Technical Details**: FedSlate 알고리즘은 SlateQ 알고리즘을 활용하여 추천 콘텐츠의 가치를 평가하고, 사용자 행동의 장기 패턴을 학습합니다. 이 알고리즘은 각 플랫폼에서 로컬 Q-값을 계산하고 이를 중앙 서버에 전달하여 글로벌 Q-값을 생성하는 구조를 가집니다. 이후 로컬 에이전트는 이 Q-값을 바탕으로 정책 결정을 내립니다.

- **Performance Highlights**: 실험 결과, FedSlate는 기존의 기준 방법들에 비해 다양한 환경 설정에서 우수한 성능을 보여주었으며, 기준 방법이 전혀 적용되지 않는 상황에서도 추천 전략 학습을 가능하게 했습니다.



### Pre-trained Language Model and Knowledge Distillation for Lightweight Sequential Recommendation (https://arxiv.org/abs/2409.14810)
Comments:
          in Chinese language

- **What's New**: 이 논문에서는 사전 훈련된 언어 모델(pre-trained language model)과 지식 증류(knowledge distillation)를 기반으로 한 새로운 연속 추천 알고리즘(sequential recommendation algorithm)을 제안합니다.

- **Technical Details**: 이 알고리즘은 두 단계로 작동합니다. 첫 번째 단계에서는 추천 데이터셋에서 사전 훈련된 언어 모델을 미세 조정(fine-tuning)하여 추천 작업에 사전 훈련된 지식을 전이합니다. 두 번째 단계에서는 훈련된 언어 모델을 경량 모델(lightweight model)로 변환하기 위해 지식을 증류(distill)합니다.

- **Performance Highlights**: 여러 공개 추천 데이터셋에서 광범위한 실험을 수행한 결과, 제안한 알고리즘이 추천 정확도(recommendation accuracy)를 향상시키고 적시 추천 서비스(timely recommendation services)를 제공함을 확인했습니다.



### EDGE-Rec: Efficient and Data-Guided Edge Diffusion For Recommender Systems Graphs (https://arxiv.org/abs/2409.14689)
Comments:
          6 pages, 13 figures

- **What's New**: 본 연구에서는 사용자-아이템 상호작용을 예측하기 위해 과거의 이진 데이터에만 의존하던 기존 추천 시스템의 한계를 극복하기 위해, Row-Column Separable Attention (RCSA)라는 새로운 주의 메커니즘을 제안합니다. 이 메커니즘은 실제 값의 상호작용 강도와 사용자 및 아이템의 특성을 직접 활용합니다.

- **Technical Details**: RCSA 메커니즘을 기반으로 한 새로운 Graph Diffusion Transformer (GDiT) 아키텍처를 통해 사용자-아이템 상호작용 그래프의 가중치가 있는 상호작용 행렬을 반복적으로 디노이즈하는 과정을 수행합니다. 이 과정에서는 사용자-아이템 평점 상호작용에서 파생된 에지 가중치와 이원적 구조의 상호작용 그래프를 이용하여 디노이징 과정에서 사용자 및 아이템의 특성을 조건으로 사용합니다.

- **Performance Highlights**: 제안된 방법은 추천 시스템의 사용자-아이템 상호작용 효율성을 높이는 데 기여하며, 예상치 못한 상호작용 강도를 근사하는 데 있어 효과적입니다. 이전 연구들과 비교했을 때, 사용자 및 아이템의 특성을 통합하여 사용자-아이템 상호작용 그래프에서 각 에지의 가중치를 직접 예측하는 최초의 접근 방식입니다.



### Reducing the Footprint of Multi-Vector Retrieval with Minimal Performance Impact via Token Pooling (https://arxiv.org/abs/2409.14683)
- **What's New**: 이번 논문에서는 ColBERT와 같은 다중 벡터 검색 방법의 저장소 및 메모리 요구사항을 줄이기 위한 간단한 클러스터링 기반의 Token Pooling 방법을 도입했습니다. 이 방법은 저장해야 하는 벡터의 수를 획기적으로 줄여줍니다.

- **Technical Details**: Token Pooling 방법은 개별 벡터를 클러스터링하고 평균 풀링을 통해 하나의 벡터로 변환하는 2단계 시스템으로 작동합니다. 세 가지 풀링 방법이 제안되었으며, 특히 계층적 클러스터링이 가장 우수한 결과를 보여주었습니다.

- **Performance Highlights**: 이 방법은 ColBERT 인덱스를 평균적으로 50%의 저장 공간을 줄이면서도 성능 저하가 없음을 보여주었으며, 66%까지의 벡터 수 감소도 가능하였고, 이 경우 성능 저하는 3% 이하에 머물렀습니다.



### Robust Training Objectives Improve Embedding-based Retrieval in Industrial Recommendation Systems (https://arxiv.org/abs/2409.14682)
Comments:
          RobustRecSys workshop @ RecSys 2024

- **What's New**: 본 연구는 소셜 미디어 플랫폼에서 대규모 친구 추천 시스템과 관련된 SSMTL(self-supervised multitask learning)의 강건성(robustness)이 실제 환경에서도 개선될 수 있는지를 평가합니다. 연구를 통해 얻어진 통계적으로 유의미한 결과는 SSMTL 기반 EBR(embedding-based retrieval)의 성능 향상 가능성을 보여줍니다.

- **Technical Details**: 제안된 방법은 두 단계 프로세스에서 작동하며, 첫 번째 단계는 수백만 명의 후보 사용자를 대상으로 후보를 선택하는 검색(retrieval) 단계이며, 두 번째 단계는 선택된 후보 사용자 목록에서 최종 추천을 위한 정렬(ranking) 단계를 포함합니다. 연구에서는 link prediction을 사용하여 사용자 간 관계도에 의한 임베딩을 생성하는 방법을 사용하고, SSMTL을 통해 이 강건성을 대규모 산업 추천 시스템에 적용합니다.

- **Performance Highlights**: 실험 결과, SSMTL 접근 방식을 사용한 경우 친구 추천 시스템의 새로운 친구 추가율에서 최대 5.45%, 콜드 스타트 사용자에서 최대 1.91%의 유의미한 성과 향상이 관찰되었습니다.



### tabulapdf: An R Package to Extract Tables from PDF Documents (https://arxiv.org/abs/2409.14524)
Comments:
          10 pages, 1 figure

- **What's New**: 이 논문에서는 PDF 파일에서 테이블을 직접 R로 가져오는 데 사용되는 R 패키지인 tabulapdf를 소개합니다. 이 패키지는 Tabula Java 라이브러리를 활용하여 데이터 추출 과정을 간소화합니다.

- **Technical Details**: tabulapdf는 PDF 파일에서 테이블을 자동 및 수동으로 추출할 수 있는 기능을 제공하며, R의 Shiny 인터페이스와 통합되어 사용자에게 마우스를 이용한 영역 선택을 가능하게 합니다. 주요 함수인 extract_tables()는 PDF 파일의 모든 페이지에서 테이블을 추출하여 R의 tibble 형식으로 반환합니다.

- **Performance Highlights**: tabulapdf는 조사 저널리즘 분야에서 데이터 추출 시간을 줄여주는 유용한 도구로, 실제 사용 사례로는 COVID-19 치료에 관한 데이터 추출이 포함되어 있습니다. 이 패키지는 PDF의 각 페이지에서 테이블의 존재 여부를 판단하고, 두 가지 알고리즘(‘lattice’와 ‘stream’)을 통해 정확한 데이터 추출을 지원합니다.



### Sliding Window Training -- Utilizing Historical Recommender Systems Data for Foundation Models (https://arxiv.org/abs/2409.14517)
Comments:
          To be published In 18th ACM Conference on Recommender Systems (RecSys '24), October 14--18, 2024, Bari, Italy

- **What's New**: 이 논문에서는 sliding window training 기법을 도입하여 장기 사용자 상호작용 이력을 효과적으로 모델 학습에 활용하는 방법을 제안합니다. 이 방법은 모델 입력 차원을 증가시키지 않으면서도 사용자의 장기 선호를 학습할 수 있도록 지원합니다.

- **Technical Details**: 모델은 대규모 사용자 상호작용 데이터셋(약 2억 5천만 사용자와의 상호작용 포함)을 사용하여 훈련됩니다. 기존의 고정 창법(fixed window approach) 대신, sliding window를 적용하여 사용자 상호작용 이력의 모든 부분을 포함하여 훈련합니다. 이를 통해 모델은 사용자의 장기 관심사를 더 잘 학습할 수 있고, 각 훈련 시점에서 관찰되는 항목 수가 증가합니다.

- **Performance Highlights**: 슬라이딩 윈도우 방식을 사용한 학습이 기본 모델보다 모든 평가 지표에서 우수한 성능을 보였습니다. 이 연구의 결과는 RecSys FM이 사용자 상호작용을 최적화하여 장기적인 사용자 관심사를 이해하고, 전반적인 항목 표현 품질을 향상시키는 데 기여할 것임을 보여줍니다.



### Revisiting BPR: A Replicability Study of a Common Recommender System Baselin (https://arxiv.org/abs/2409.14217)
Comments:
          This paper is accepted at the Reproducibility track of the ACM RecSys '24 conference

- **What's New**: 이 논문에서는 Bayesian Personalized Ranking (BPR) 모델의 다양한 구현 세부사항을 분석하고, 이를 통해 모델의 성능에 미치는 영향을 조사했습니다. 뿐만 아니라, 오픈소스 구현 체계에 대한 일관성 문제를 확인하고, 일부 구현에서 성능이 50%까지 감소하는 문제를 발견했습니다.

- **Technical Details**: BPR 모델은 매트릭스 분해(matrix factorization) 기반의 협업 필터링(collaborative filtering) 방법론으로, 쌍별 순위 손실(pairwise ranking loss)을 도입하여 추천 성능을 향상시킵니다. 본 연구는 다양한 오픈소스 구현 체계와의 비교를 통해 BPR의 세부사항이 성능에 미치는 영향을 분석했습니다. 특정 하이퍼파라미터(hyperparameter)의 조정이 BPR 모델의 성능을 현대 기법들과 유사하게 끌어올릴 수 있음을 보여주었습니다.

- **Performance Highlights**: BPR 모델은 하이퍼파라미터 조정을 통해 최근의 SOTA(state-of-the-art) 방법들과 유사한 성능을 발휘할 수 있으며, 특정 데이터셋에서는 이를 초월한 성과를 남깁니다. 특히, Million Song Dataset에서는 BPR 모델이 NDCG@100에서 Mult-VAE 모델에 비해 10% 향상된 성능을 보였습니다.



### Data Generation via Latent Factor Simulation for Fairness-aware Re-ranking (https://arxiv.org/abs/2409.14078)
- **What's New**: 이 논문은 공정성 인식 추천 시스템(fairness-aware recommendation analysis) 분야에서 사용될 새로운 합성 데이터(synthetic data)를 제안합니다. 저자들은 기존 방식의 한계를 극복하고, 공정성을 고려한 재배치(re-ranking) 알고리즘을 연구하기 위한 합성 추천 시스템 출력(synthetic recommender system outputs)을 생성하는 방법론을 개발하였습니다.

- **Technical Details**: 저자들은 LAtent Factor Simulation (LAFS)이라는 새로운 방법론을 통해 합성 추천 목록을 생성합니다. 이 과정에서 행렬 분해(matrix factorization) 모델이 생성할 수 있는 잠재 요인(latent factors) 행렬을 시뮬레이션하고, 이를 바탕으로 표본 평가(sample ratings)를 생성하여 다양한 공정성 속성을 가진 추천 목록을 형성합니다.

- **Performance Highlights**: LAFS 방법을 통해 생성된 추천 목록은 실제 추천 시스템의 것이와 유사한 특성을 가지며, 다양한 공정성 관련 조건에 따라 데이터 세트의 특성을 조정할 수 있는 가능성을 보여줍니다. 이를 통해 공정성 인식 재배치 알고리즘의 효과를 다양하게 평가할 수 있는 장점이 있습니다.



### WebQuest: A Benchmark for Multimodal QA on Web Page Sequences (https://arxiv.org/abs/2409.13711)
- **What's New**: WebQuest는 다중 페이지 질문-답변(Question-Answering, QA) 데이터셋으로, 웹 상호작용에서의 정보 검색 및 추론을 동시에 요구하는 새로운 벤치마크를 제시합니다. 이 데이터셋은 단일 화면, 다중 화면 및 내비게이션 경로 기반의 질문을 포함하고 있어 기존의 다단계 웹 탐색 방식과는 차별화된 접근을 보여줍니다.

- **Technical Details**: WebQuest 데이터셋은 세 가지 질문 카테고리(단일 화면 QA, 다중 화면 QA, 내비게이션 경로 기반 질문)를 포함하여, 사용자 행동에 기반한 웹 상호작용 시퀀스를 반영하며, 다양한 멀티모달 모델(GPT-4V, Gemini Flash, Claude 3 등)을 평가합니다. 특히, Chain-of-Thought prompting 기법을 적용하여 다중 화면 추론 능력을 향상시키는 방법을 모색합니다.

- **Performance Highlights**: 모델 평가는 단일 페이지와 다중 페이지 추론 간의 성능 차이를 보여주며, WebQuest는 기존 QA 기반 콘텐츠 이해와 에이전트 모델 연구 간의 격차를 해소하는 새로운 QA 모드를 제공합니다. 또한, 데이터셋은 다양한 모델의 능력을 자세히 평가할 수 있는 3개의 데이터 하위 집합을 포함하고 있습니다.



### Retrieval Augmented Generation-Based Incident Resolution Recommendation System for IT Suppor (https://arxiv.org/abs/2409.13707)
Comments:
          7 pages, 3 figures, 6 tables

- **What's New**: 이 연구는 IT 지원 도메인에서의 솔루션 추천 시스템을 위해 개발된 Retrieval Augmented Generation(RAG) 시스템을 소개합니다. 특히, IBM Slate 125m 모델을 사용하여 단일-턴과 다중-턴 IT 지원 사례를 분류하는 새로운 접근법과 성능을 보고합니다.

- **Technical Details**: 시스템은 네 가지 주요 구성 요소로 이루어져 있습니다: encoder-only transformer classifier, query generation system, retriever system, 그리고 answer generator system. 데이터 수집은 약 19,000개의 실제 지원 사례를 기반으로 하며 다양한 소프트웨어 제품에서 수집되었습니다. CNN(Convolutional Neural Networks) 및 cosine similarity를 활용하여 문서를 검색하고 재랭크합니다.

- **Performance Highlights**: 연구 결과, 작은 모델들이 RAG 사건 해결 사용 사례에서 매우 큰 모델들과 동등하거나 더 나은 성능을 보여주었다고 보고합니다. 최종적으로 F1 점수가 0.65에 이르고, 클래스 분류 정확도가 0.54, 재현율이 0.80으로 나타났습니다.



### Zeroshot Listwise Learning to Rank Algorithm for Recommendation (https://arxiv.org/abs/2409.13703)
- **What's New**: 이번 연구는 순위 학습(Learning to rank) 기술의 저조한 채택을 극복하기 위해 제로샷(listwise learning to rank) 알고리즘을 제안합니다. 이는 정보 검색 분야에서 널리 사용되던 기존의 방법과 차별화됩니다.

- **Technical Details**: 연구에서는 순위 통계 근사(order statistic approximation)와 파워 법칙 분포(power law distribution)를 활용하여 제안한 알고리즘을 설계했습니다. 이 접근법은 추천 시스템에서 정확하고 공정한 결과를 제공함을 실험을 통해 입증하고 있습니다.

- **Performance Highlights**: 제안하는 알고리즘은 실험에서 정확성과 공정성을 모두 만족하는 것으로 나타났으며, 추천 시스템 분야에서의 효용성을 강조합니다.



### MAS4POI: a Multi-Agents Collaboration System for Next POI Recommendation (https://arxiv.org/abs/2409.13700)
Comments:
          14 pages, 4 figures

- **What's New**: 이 논문은 LLM(대형 언어 모델)을 기반으로 한 다중 에이전트 시스템(MAS4POI)을 제안하여 사용자 맞춤형 다음 POI(관심 지점) 추천의 성능을 향상시키고자 합니다. MAS4POI는 데이터 에이전트(DataAgent), 관리자(Manager), 분석가(Analyst), 반영기(Reflector), 사용자 에이전트(UserAgent), 탐색자(Searcher), 내비게이터(Navigator) 등 7개의 전문화된 에이전트를 포함하여 다각적인 협력 프로세스를 지원합니다.

- **Technical Details**: MAS4POI는 서로 다른 LLM을 통합하여 작업 워크플로우 및 리소스 관리, 사용자 데이터 분석, 외부 데이터 접근 등을 수행합니다. 각 에이전트는 POI 추천을 위한 상호작용을 통해 데이터 정교화 및 경로 계획을 지원하며, 시스템은 대규모 실세계 데이터셋을 통해 검증됩니다.

- **Performance Highlights**: MAS4POI는 다음 POI 추천의 정확성을 크게 향상시키며, 사용자 개인화된 서비스 제공 및 실시간 Q&A 기능을 통해 다양한 응용 분야에 쉽게 연결될 수 있습니다. 또한, 데이터 부족 문제를 완화하고 여러 대규모 데이터셋을 통해 시스템의 효과를 검증하였습니다.



### Vietnamese Legal Information Retrieval in Question-Answering System (https://arxiv.org/abs/2409.13699)
Comments:
          7 pages

- **What's New**: 본 연구는 Question Answering 시스템의 신뢰성을 증대시키기 위한 새로운 문서 검색 및 추천 방법을 제시합니다. 특히 베트남어를 대상으로 한 문제를 해결하기 위해 데이터 처리, 검색 순서 최적화 및 정보 재정렬 방법을 도입하고 있습니다.

- **Technical Details**: 제안된 시스템은 대형 언어 모델(LLM)과 BM25 검색, Dense Vector search를 결합하여 효율적이고 정확한 정보 검색을 가능하게 합니다. 또한 Reciprocal Rank Fusion 기법을 활용하여 키워드와 벡터 검색의 결과를 통합하고, Active Retrieval을 통해 소스 문서의 재정렬 과정을 수행합니다.

- **Performance Highlights**: 베트남 법률 정보를 다루는 QA 시스템에서 성능과 신뢰성이 크게 향상되었습니다. 최종적으로 약 1,293,347개의 법률 문서와 2,081개의 질문으로 구성된 데이터셋을 사용하여 실험을 진행하였으며, 정보 검색의 정확성과 사용자 경험이 개선되었습니다.



### Generative AI Is Not Ready for Clinical Use in Patient Education for Lower Back Pain Patients, Even With Retrieval-Augmented Generation (https://arxiv.org/abs/2409.15260)
- **What's New**: 본 연구에서는 Retrieval-Augmented Generation (RAG)과 few-shot learning을 활용하여 허리통증(LBP) 환자를 위한 맞춤형 교육 자료를 생성하는 새로운 접근법을 소개합니다.

- **Technical Details**: 이 연구에서는 대형 언어 모델(LLMs)이 RAG를 사용하여 생성된 교육 자료의 중복성, 정확성 및 완전성을 평가하기 위해 물리치료사가 수동으로 검토하였습니다. 또한 생성된 교육 자료의 가독성은 Flesch Reading Ease 점수를 통해 평가되었습니다.

- **Performance Highlights**: RAG 기반 LLMs는 전통적인 LLMs보다 더 정확하고 완전하며 적은 중복성을 가진 환자 교육 자료를 제공합니다. 그러나 생성된 자료는 아직 임상 실무에 사용하기에는 준비가 되어 있지 않으며, AI 모델의 임상적 관련성과 내용의 세분화를 보장하는 데에는 여전히 상당한 과제가 남아 있습니다.



### Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies (https://arxiv.org/abs/2409.15163)
- **What's New**: 이번 연구는 의료 분야에서 LLMs의 효과적인 정보 검색을 위한 다양한 embedding 모델과 pooling 방법의 영향을 분석한 것입니다. 특히, BGE라는 일반 도메인 모델이 의료 전용 모델보다 일관되게 우수한 성능을 보인 점이 주목할 만합니다.

- **Technical Details**: 연구는 MIMIC-III와 사설 전자 건강 기록(EHR) 데이터를 사용하는 세 가지 정보 검색 작업을 수행했습니다. 총 일곱 개 모델을 평가했으며, 각 모델에 대한 embedding pooling 전략이 독립적으로 어떻게 작용하는지도 분석했습니다.

- **Performance Highlights**: BGE 모델은 다른 의료 전용 모델보다 뛰어난 검색 성능을 보였으며, 데이터셋과 쿼리 내용에 따라 상당한 변동성이 있음을 발견했습니다. 최적의 pooling 방법을 제안하여 미래의 검색 시스템 디자인에 기여할 수 있는 통계적으로 검증된 권장 사항을 제공했습니다.



### ViBERTgrid BiLSTM-CRF: Multimodal Key Information Extraction from Unstructured Financial Documents (https://arxiv.org/abs/2409.15004)
Comments:
          Accepted in MIDAS (The 8th Workshop on MIning DAta for financial applicationS) workshop of ECML PKDD 2023 conference

- **What's New**: 이 논문은 비정형 문서에서의 핵심 정보 추출(Information Extraction, KIE) 모델에 대한 새로운 접근 방식을 제안합니다. 특히, ViBERTgrid라는 다중 모드 트랜스포머를 비정형 금융 문서에 적응시키고 BiLSTM-CRF 레이어를 통합하여 성능을 크게 향상시킵니다.

- **Technical Details**: 제안된 ViBERTgrid BiLSTM-CRF 모델은 비정형 문서에서의 개체 인식(Named Entity Recognition, NER) 성능을 2%포인트 향상시키면서도 반구조 문서에서의 KIE 성능을 유지합니다. 이 모델은 두 가지 주요 아키텍처인 ViBERTgrid(트랜스포머 기반)와 BiLSTM-CRF(시퀀스 기반)를 결합하여 구문 및 장기 컨텍스트 인식을 제공합니다.

- **Performance Highlights**: 이 모델은 비정형 자금 이체 주문 데이터셋 및 반구조 영수증 데이터셋(SROIE)에서 평가되었으며, SROIE 데이터셋에 대한 토큰 수준 주석을 공개하여 다중 모드 시퀀스 레이블링 모델에서의 사용 가능성을 높였습니다.



### Adaptive Learning on User Segmentation: Universal to Specific Representation via Bipartite Neural Interaction (https://arxiv.org/abs/2409.14945)
- **What's New**: 본 연구에서는 클릭률(CTR) 및 전환률(CVR) 예측을 위한 사용자를 나타내는 새로운 학습 프레임워크를 제안합니다. 본 프레임워크는 정보 병목(information bottleneck)을 통해 먼저 일반적인 사용자 표현을 학습하고, 그 후 신경 상호 작용(neural interaction)을 통해 세분화(specific segmentation)에 맞는 표현을 통합하고 학습합니다.

- **Technical Details**: 제안된 학습 프레임워크는 가우시안 혼합(latent space)을 통해 사용자 특성을 다차원적으로 클러스터링하여 일반 사용자 표현을 학습합니다. 그런 다음, 비파르타이트 그래프(bipartite graph) 구조를 활용하여 특정 세분화에 대한 표현을 생성하는 상호 작용 과정을 설계합니다. 이 과정에서 모든 데이터로부터 메타 지식을 학습하여 다양한 사용자 그룹에 맞게 조정 가능한 모델을 생성합니다.

- **Performance Highlights**: 제안된 방법은 두 개의 오픈소스 벤치마크와 두 개의 오프라인 비즈니스 데이터셋에서 벤치마크 테스트를 수행하였으며, 두 개의 온라인 마케팅 애플리케이션에서도 성공적으로 배포되었습니다. 결과적으로 제안된 방법은 기존 baseline 방법들보다 우수한 성능을 달성하여 CVR 예측에서 효과적으로 구현되었습니다.



### Nirjas: An open source framework for extracting metadata from the source cod (https://arxiv.org/abs/2409.14609)
Comments:
          2022 12th International Conference on Cloud Computing, Data Science & Engineering (Confluence)

- **What's New**: 이 논문에서는 소프트웨어 개발 과정에서 중요한 메타데이터(metadata)와 주석(comments)의 역할을 강조합니다. 저자들은 파이썬(Python) 기반의 오픈 소스 프레임워크인 Nirjas를 소개하며, 이를 통해 소스 코드에서 메타데이터를 구조적으로 추출할 수 있음을 설명합니다.

- **Technical Details**: Nirjas는 다양한 프로그래밍 언어의 소스 파일에 주석을 추가할 때 사용되는 여러 구문(syntax)과 타입(type), 널리 사용되는 관례(conventions)를 지원합니다. 이 프레임워크는 Regex를 사용하여 정밀하게 메타데이터를 추출하며, 비정규 표현식(non-Regex) 방법은 종종 정확성과 노이즈(separation noise) 처리에서 한계를 보입니다. Nirjas는 주석의 유형(type), 소스 코드 및 해당 주석에 대한 상세한 정보(예: 줄 번호(line number), 파일 이름(file name), 사용 언어(language used), 총 소스 코드 라인 수(SLOC) 등)를 분리하여 제공합니다.

- **Performance Highlights**: Nirjas는 독립형 파이썬 프레임워크/라이브러리로, 소스 또는 pip(파이썬 패키지 설치기)를 통해 쉽게 설치할 수 있습니다. 이 도구는 Google Summer of Code 프로젝트의 일환으로 처음 생성되었으며, 현재 FOSSology 조직에서 개발 및 유지 관리되고 있습니다.



### Beyond Words: Evaluating Large Language Models in Transportation Planning (https://arxiv.org/abs/2409.14516)
- **What's New**: 2023년 Generative Artificial Intelligence (GenAI)의 급속한 발전이 도시 교통 및 물류 분야에 혁신적인 변화를 가져왔습니다. 본 연구는 GPT-4와 Phi-3-mini 같은 Large Language Models (LLMs)의 성능을 수송 계획에 적용하는 것을 탐구합니다.

- **Technical Details**: 이 연구는 교통 정보를 반영한 평가 프레임워크를 통해 LLM의 성능과 공간 이해력을 평가합니다. 평가 요소로는 일반적인 지리적 정보 시스템 (GIS) 기술, 교통 관련 도메인 지식 및 현실 세계의 교통 문제 해결 능력이 포함됩니다. 혼합 방법론을 활용하여 연구가 진행되었습니다.

- **Performance Highlights**: 연구 결과, GPT-4는 다양한 GIS 및 교통 관련 작업에서 Phi-3-mini보다 더 뛰어난 정확성과 신뢰성을 보였습니다. 그러나 Phi-3-mini는 특정 분석 시나리오에서 유용함을 나타내어 자원이 제한된 환경에서도 활용 가능성을 보여줍니다. 이 결과는 GenAI 기술이 도시 교통 계획에 미치는 혁신적인 잠재력을 강조합니다.



### Knowledge in Triples for LLMs: Enhancing Table QA Accuracy with Semantic Extraction (https://arxiv.org/abs/2409.14192)
- **What's New**: 이 논문은 semi-structured (반구조화) 테이블에서 Triple을 추출하고 이를 Retrieval-augmented Generation (RAG) 모델과 결합하여 자연어 처리(NLP)에서 질문 응답 시스템(QA)의 정확도와 문맥적 풍부함을 향상시키는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 제안된 방법론은 RDFLib 라이브러리를 사용하여 테이블에서 Triple을 간단히 구성하는 과정을 포함합니다. Triple은 Subject(주어), Predicate(서술어), Object(목적어)로 구성되며, 이를 통해 테이블의 셀 간의 관계를 명확히 표현합니다. 이 Triple은 Fine-tuned GPT-3.5-turbo-0125 모델에 통합되어 응답 생성을 개선하는 데 사용됩니다.

- **Performance Highlights**: 제안된 접근 방식은 FeTaQA 데이터셋에서 기존 기법들보다 성능이 크게 향상되었으며, 특히 Sacre-BLEU 및 ROUGE 지표에서 우수한 성과를 나타냈습니다. 테이블에서 복잡한 정보를 효과적으로 식별하고 명확한 긴 형식의 답변을 생성하는 능력이 두드러집니다.



### OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching (https://arxiv.org/abs/2409.14038)
Comments:
          4 pages, 1 figure

- **What's New**: 이번 연구에서는 LLM(hallucinations)의 발생이 Ontology Matching(OM) 작업에서 중요한 문제임을 제기하고, 이를 해결하기 위한 OAEI-LLM 데이터셋을 제안합니다. 이 데이터셋은 OM 작업에서 LLM의 환각 현상을 평가하기 위한 기준을 제공합니다.

- **Technical Details**: OAEI-LLM 데이터셋은 기존 OAEI 데이터셋의 확장으로, LLM의 OM 작업에서의 환각 유형을 분류하고 이를 바탕으로 LLM의 정답률을 평가합니다. 새로운 스키마 확장을 통해 LLM이 생성한 결과와 인간이 라벨링한 결과를 비교하고, 환각의 발생 정도를 측정합니다.

- **Performance Highlights**: LLM은 OM 작업에서 높은 성능을 보일 수 있지만, 환각 현상으로 인해 낮은 precision(정밀도) 및 recall(재현율) 문제를 초래할 수 있습니다. OAEI-LLM 데이터셋을 통해 LLM의 환각 현상에 대한 이해를 높이고, 향후 OM 개선 연구에 기여할 것으로 예상됩니다.



### Cost-Effective Community-Hierarchy-Based Mutual Voting Approach for Influence Maximization in Complex Networks (https://arxiv.org/abs/2409.14034)
- **What's New**: 이번 연구는 Cost-Effective Community-Hierarchy-Based Mutual Voting이라는 새로운 접근 방식을 제안하여 복잡 네트워크에서 영향력 극대화를 해결합니다. 이 방법은 노드의 중요성을 측정하기 위한 새로운 개념인 Dual-Scale Community-Hierarchy Information을 기반으로 합니다.

- **Technical Details**: Dual-Scale Community-Hierarchy Information을 통해 노드의 계층 구조와 커뮤니티 구조 정보를 통합하여 중요성을 측정합니다. 새로운 Hierarchical-Community Entropy 개념을 통해 커뮤니티 구조 정보를 평가합니다. 또한, 저비용의 Mutual-Influence 기반 투표 메커니즘과 Lazy Score Updating Strategy를 사용하여 seed 노드를 선택하는 방법을 개발합니다.

- **Performance Highlights**: 실험 결과, 제안된 접근 방식은 16종의 최첨단 기술보다 시간 복잡성과 정확성 간의 균형에서 더 우수한 성능을 보였으며, 균형 지수에서 두 번째로 높은 방법과 비교했을 때 최대 9.29% 향상된 성능을 보여주었습니다.



### Causal Feature Selection Method for Contextual Multi-Armed Bandits in Recommender System (https://arxiv.org/abs/2409.13888)
- **What's New**: 이 논문에서는 기존 기계 학습 모델에 비해 맥락적 멀티암 밴딧 모델에서 중요한 특성을 선택하는 새로운 방법을 제안합니다. 제안된 방법은 이질적 causal 효과(heterogeneous causal effect)를 기반으로 하여 보상 분포에 대한 특성의 기여를 평가합니다.

- **Technical Details**: 제안된 방법은 모델에 특성을 포함시키지 않고, 특성이 보상에 미치는 기여를 기반으로 중요한 특성을 선정합니다. 이 방법은 비선형 관계를 고려하며, 연속형 및 범주형 특성 모두에 적응할 수 있습니다. 또한, 모델 오명세(model mis-specification) 문제를 방지하면서 빠른 계산 속도를 자랑합니다.

- **Performance Highlights**: 모의 데이터와 실제 온라인 실험 데이터를 기반으로 한 실험 평가 결과, 제안된 특성 선택 방법이 중요한 특성을 효과적으로 선택하고, 맥락적 MAB 성과를 향상시킨 것으로 나타났습니다. 더불어, 기존 모델 내장(mis-specification) 방법과 비교했을 때 계산 속도 및 구현 용이성에서 우수한 성과를 보였습니다.



### Segment Discovery: Enhancing E-commerce Targeting (https://arxiv.org/abs/2409.13847)
Comments:
          Accepted at the CONSEQUENCES'24 workshop, co-located with ACM RecSys'24

- **What's New**: 이 논문에서는 고객을 효과적으로 목표로 삼기 위하여 uplift 모델링과 제한 최적화(constrained optimization)를 기반으로 한 새로운 정책 프레임워크를 제안합니다. 이 접근법은 비즈니스 가치의 극대화를 위해 특정 사례에 맞는 개입(intervention)을 수행하는 고객을 식별함으로써, 기존의 무작위 표적 또는 성향에 기반한 접근 방식에 비해 개선점을 보여줍니다.

- **Technical Details**: 제안된 방법론은 두 단계의 접근 방식을 가지고 있습니다. 첫 번째 단계에서는 각 고객에 대한 처치(treatment)의 영향을 추정하고, 두 번째 단계에서는 이러한 추정을 기반으로 고객 집합을 최적화하여 주어진 제약 조건을 고려합니다. 고객의 성향 점수(threshold)와 결과 변수를 기반으로 하는 기존 방법들과 달리, 이 방법론은 불확실성을 감소시키고 보다 일반적인 고객 목표 문제에 적용할 수 있는 프레임워크를 제공합니다.

- **Performance Highlights**: 세 가지 주요 비즈니스 응용 사례를 통한 오프라인 정책 추정 기법과 대규모 온라인 A/B 테스트를 사용하여, 제안된 타겟팅 정책의 유효성을 입증하였습니다. 이 접근법은 기존의 성향 기반 방법에 비해 비즈니스 목표 달성에서 보다 높은 성과를 보여주었습니다.



### Language agents achieve superhuman synthesis of scientific knowledg (https://arxiv.org/abs/2409.13740)
- **What's New**: 이번 연구에서는 PaperQA2라는 고급 언어 모델을 개발하여 과학 문헌 검색 과제에서 인간 전문가와의 성능 비교를 수행했습니다. 결과적으로 PaperQA2는 정보 검색, 요약 및 모순 탐지 작업에서 주제 전문가를 초월할 수 있음을 입증하였습니다.

- **Technical Details**: 연구의 핵심은 PaperQA2를 활용하여 적용된 LitQA2 벤치마크를 통해 과학 문헌에 대한 정보 검색, 요약 및 모순 탐지의 성능을 평가한 점입니다. PaperQA2는 ‘retrieval-augmented generation (RAG)’ 접근 방식을 사용하여, 여러 단계의 작업을 통해 최종 응답을 생성합니다. 각 질문에 대해 평균 14.5개의 논문을 활용하였으며, 정확도는 66.0%로 나타났습니다.

- **Performance Highlights**: PaperQA2는 LitQA2 벤치마크에서 85.2%의 정밀도와 66.0%의 정확도를 기록하였으며, 생물학 논문에서 평균 2.34개의 모순을 발견하는 데 성공했습니다. 이 연구는 AI 모델이 특정 과학 문헌 작업에서 인간 전문가보다 뛰어난 성능을 보여줄 수 있음을 실증적으로 나타냈습니다.



### Shaping the Future of Endangered and Low-Resource Languages -- Our Role in the Age of LLMs: A Keynote at ECIR 2024 (https://arxiv.org/abs/2409.13702)
- **What's New**: 이 논문은 언어가 문화적 및 사회적 정체성을 형성하는 데 중요한 역할을 한다는 점을 강조하며, 오늘날 7100개 이상의 언어 중 상당수가 멸종 위기에 처해 있음을 알립니다. 특히, Occitan 언어를 중심으로 기술과 전통 간의 협력 가능성을 탐구합니다.

- **Technical Details**: Large Language Model (LLM) 기술이 제공하는 번역 및 콘텐츠 생성의 가능성을 논의하며, 이는 멸종 위기 언어 보존과 재활성화의 중요한 요소가 될 수 있습니다. 그러나 이러한 기술은 또한 문화의 동질화 및 이미 취약한 언어의 추가적 소외를 초래할 위험이 있습니다.

- **Performance Highlights**: 인공지능(AI)과 인간의 전문성이 함께 작동하여 언어의 다양성을 보존할 수 있는 희망을 제공할 수 있음을 강조하며, 이를 위해서는 윤리적 및 실용적인 도전 과제를 해결해야 한다고 주장합니다.



New uploads on arXiv(cs.CV)

### PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation (https://arxiv.org/abs/2409.18964)
Comments:
          Accepted to ECCV 2024. Project page: this https URL

- **What's New**: PhysGen은 단일 이미지를 입력으로 사용하여 현실적이고 물리적으로 그럴듯한 비디오를 생성하는 혁신적인 이미지-비디오 생성 방법입니다. 주목할 점은 이미지에 적용된 힘과 토크와 같은 입력 조건을 활용하여 동적 영상을 생성하는 것입니다.

- **Technical Details**: PhysGen의 핵심 구성 요소는 세 가지로 나눌 수 있습니다: (i) 이미지의 기하학, 재료 및 물리적 매개변수를 효과적으로 캡처하는 이미지 이해 모듈; (ii) 강체 물리학(rigid-body physics)과 유추된 매개변수를 사용하는 이미지 공간 동적 시뮬레이션 모델; (iii) 생성적 영상 확산(generative video diffusion) 기법을 활용해 시뮬레이션된 동작을 포함하는 현실적인 비디오 영상을 생성하는 이미지 기반 렌더링 및 정제 모듈입니다.

- **Performance Highlights**: PhysGen을 통해 생성된 비디오는 물리적 사실성과 외관 측면에서 현실적이며 정교한 제어가 가능합니다. 기존의 데이터 기반 이미지-비디오 생성 연구들과의 정량적 비교 및 포괄적인 사용자 연구를 통해 뛰어난 결과를 보여줍니다.



### Exploring Token Pruning in Vision State Space Models (https://arxiv.org/abs/2409.18962)
Comments:
          NeurIPS'24

- **What's New**: 본 논문에서는 State Space Models (SSMs)을 기반으로 한 비전 모델의 효율성을 향상시키기 위해 토큰 기반의 프루닝(token pruning) 기법을 제안합니다. 기존의 Vision Transformers (ViTs) 기술을 활용한 토큰 프루닝 기법의 제한점을 분석하고, SSM의 고유한 계산 특성을 고려하여 새로운 방법을 개발했습니다.

- **Technical Details**: 제안된 방법은 pruning-aware hidden state alignment 기법을 도입하여 남아있는 토큰의 이웃을 안정화하고, SSM 모델에 적합한 토큰 중요성 평가(token importance evaluation) 방법을 통해 토큰 프루닝을 수행합니다. 이로 인해 효율적인 구현 및 실질적인 가속화가 이루어집니다.

- **Performance Highlights**: 제안된 방법은 ImageNet에서 41.6\%의 FLOPs 감소와 함께 81.7\%의 정확도를 달성하며, 다양한 작업에서 성능에 미치는 영향을 최소화하면서도 계산량을 대폭 줄일 수 있음을 입증했습니다. 또한, 이 연구는 SSM 기반 비전 모델의 동작을 이해하는 데 더 깊은 통찰을 제공합니다.



### ProMerge: Prompt and Merge for Unsupervised Instance Segmentation (https://arxiv.org/abs/2409.18961)
Comments:
          ECCV2024 camera-ready

- **What's New**: 이 논문에서는 Unsupervised instance segmentation(비지도 인스턴스 분할)에서 새로운 방법인 Prompt and Merge(ProMerge)를 제안합니다. ProMerge는 self-supervised visual features(자기지도 시각적 특징)를 활용해 패치를 초기 그룹화하고 전략적으로 병합하는 접근법입니다.

- **Technical Details**: ProMerge는 DINO와 같은 self-supervised 모델에서 제공하는 강력한 시각적 특징을 활용하고, sophisticated background-based mask pruning technique(정교한 배경 기반 마스크 가지치기 기법)을 적용하여 초기 세그먼트를 병합합니다. 또한, 기존의 normalized-cut(정규화 컷)을 사용하는 방법에 비해 계산 요구 사항을 줄이며, inference speed(추론 속도)를 크게 개선합니다.

- **Performance Highlights**: ProMerge는 경쟁력 있는 결과를 제공하며, 기존 최첨단 normalized-cut 기반 접근법에 비해 추론 시간을 크게 단축시킵니다. 우리의 마스크 예측을 pseudo-labels(의사 레이블)로 사용하는 객체 탐지기를 훈련할 경우, 다양한 challenging instance segmentation benchmarks(도전적인 인스턴스 분할 벤치마크)에서 현재 최고 수준의 비지도 모델을 능가합니다.



### UniCal: Unified Neural Sensor Calibration (https://arxiv.org/abs/2409.18953)
Comments:
          ECCV 2024. Project page: this https URL

- **What's New**: 이 논문에서는 여러 LiDAR와 카메라를 장착한 자율주행 차량(SDV)에서 손쉽게 보정할 수 있는 통합된 프레임워크인 UniCal을 제공합니다. 이 접근법은 특정 보정 피듈(Fiducial) 없이도 연속적인 장면 표현을 통해 보정 과정을 진행할 수 있게 합니다.

- **Technical Details**: UniCal은 차별 가능한 장면 표현(differentiable scene representation)을 기반으로 하여, 다중 보기를 지오메트릭(geometric) 및 포토메트릭(photometric) 일관되게 렌더링하는 기능을 갖추고 있습니다. 또한, 드라이브-앤-칼리브레이트(drive-and-calibrate) 방식을 통해 야외 센서 데이터를 활용하여 보정 작업을 수행합니다. 이를 통해 센서 보정과 기본 장면 표현을 공동 학습합니다.

- **Performance Highlights**: UniCal은 기존 보정 시스템에 비해 비용 절감 및 운영 오버헤드 감소를 자랑하며, 여러 데이터셋에 대한 포괄적인 평가 결과 UniCal이 기존 보정 접근법에 비해 더 정확하거나 동등한 정밀도를 보임을 demonstrates합니다.



### Spectral Wavelet Dropout: Regularization in the Wavelet Domain (https://arxiv.org/abs/2409.18951)
Comments:
          Accepted by The International Conference on Machine Learning and Applications (ICMLA) 2024

- **What's New**: 이번 연구에서는 Spectral Wavelet Dropout (SWD)이라는 새로운 정규화 (regularization) 방법을 소개합니다. 이 방법은 1D-SWD와 2D-SWD 두 가지 변형을 포함하며, CNN의 일반화 (generalization) 능력을 향상시킵니다.

- **Technical Details**: SWD는 특징 맵의 이산 웨이브렛 분해 (discrete wavelet decomposition)에서 세부 주파수 대역을 무작위로 제거하여 작동합니다. SWD는 기존의 Spectral "Fourier" Dropout (2D-SFD)와 다르게, 주파수 영역(Fourier domain)에서 계수를 제거하는 대신 웨이브렛을 사용합니다. SWD는 단일 하이퍼파라미터만 요구하며, 1D-SFD의 1차원 버전도 구현하여 포괄적인 비교 연구를 수행합니다.

- **Performance Highlights**: CIFAR-10/100 벤치마크에서 1D 및 2D SWD 변형은 1D-SFD 및 2D-SFD에 비해 뛰어난 성능을 보였습니다. 특히, 1D-SWD는 1D/2D-SFD에 비해 계산 복잡도가 현저히 낮습니다. Pascal VOC 객체 탐지 벤치마크에서도 SWD 변형이 1D-SFD 및 2D-SFD를 초월하는 성능과 낮은 계산 복잡도를 보여주었습니다.



### From Seconds to Hours: Reviewing MultiModal Large Language Models on Comprehensive Long Video Understanding (https://arxiv.org/abs/2409.18938)
Comments:
          11 pages

- **What's New**: 본 논문에서는 MultiModal Large Language Models (MM-LLMs)과 시각적인 인코더(visual encoders)의 통합을 통해 긴 비디오 이해(long video understanding)에서의 고유한 도전 과제를 조명합니다. 기존의 정적 이미지(static image)와 짧은 비디오(short video) 이해와의 차별점을 분명히 합니다.

- **Technical Details**: MM-LLMs의 설계(model design) 및 훈련(training methodologies) 방식에서 긴 비디오 이해를 위한 발전을 다룹니다. 짧은 비디오는 연속적인 프레임을 포함하여 공간(spatial) 및 사건 내 템포럴(temporal) 정보를 가지며, 긴 비디오는 여러 사건이 여유 있는 시간 간격으로 발생합니다.

- **Performance Highlights**: 기존 MM-LLMs의 비디오 이해(video understanding) 벤치마크 성능을 비교하고, 긴 비디오 이해를 위한 향후 발전 방향을 논의합니다.



### ReviveDiff: A Universal Diffusion Model for Restoring Images in Adverse Weather Conditions (https://arxiv.org/abs/2409.18932)
- **What's New**: 본 논문에서는 다양한 열악한 환경에서 촬영된 이미지의 품질을 향상시키고 복원할 수 있는 범용 네트워크 아키텍처 'ReviveDiff'를 제안합니다. 이 접근은 특정 작업을 위한 기존의 방법들이 다른 종류의 열화 상황에 적용될 수 없다는 한계를 극복합니다.

- **Technical Details**: ReviveDiff 모델은 움직임이나 전자적 문제에 의한 열화와는 달리, 안개, 물, 저조도와 같은 자연 매체에 의해 발생하는 품질 저하 현상을 이해하고 이를 복원하기 위해 최신 diffusion models를 활용했습니다. 이 모델은 이미지 품질에 영향을 미치는 주요 요인인 선명도(sharpness), 왜곡(distortion), 노이즈 수준(noise level), 동적 범위(dynamic range), 색상 정확성(color accuracy) 등을 고려합니다.

- **Performance Highlights**: ReviveDiff는 Rainy, Underwater, Low-light, Smoke, Nighttime Hazy의 다섯 가지 열화 조건을 아우르는 일곱 개의 벤치마크 데이터셋에서 평가되었으며, 실험 결과 기존의 최첨단 방법들을 정량적 및 시각적으로 능가한다는 것을 입증했습니다.



### SurfaceAI: Automated creation of cohesive road surface quality datasets based on open street-level imagery (https://arxiv.org/abs/2409.18922)
Comments:
          4 pages, 2 figures; accepted at 2nd ACM SIGSPATIAL International Workshop on Advances in Urban-AI

- **What's New**: 본 논문은 도로 표면 유형과 품질에 대한 포괄적인 지리 참조 (georeferenced) 데이터셋을 생성하기 위해 설계된 SurfaceAI라는 파이프라인을 소개합니다. 이는 거리 수준 이미지에서 공개적으로 사용 가능한 자료를 활용하여 개발되었습니다.

- **Technical Details**: SurfaceAI는 crowdsourced (크라우드소싱) 데이터인 Mapillary 데이터를 활용하여 거리 수준 이미지에서 보이는 도로 표면의 유형과 품질을 예측하는 모델을 학습시키고, 이를 통해 전체 도로 구간 조건에 대한 통합 정보를 제공합니다.

- **Performance Highlights**: 도로의 불균형성이 교통 참가자의 안전과 편안함에 미치는 중대한 영향을 강조하며, 인프라 모델링 및 분석에 있어 세부 도로 표면 데이터의 필요성을 충족하는 데 기여합니다.



### Improving Visual Object Tracking through Visual Prompting (https://arxiv.org/abs/2409.18901)
Comments:
          Accepted and to appear in IEEE Transactions on Multimedia

- **What's New**: 본 연구에서는 PiVOT(Visual Prompting mechanism for generic Visual Object Tracking)를 통해 기존의 목표와 주변 방해물(distractor)을 구별하는 문제를 해결하기 위한 새로운 시각적 프롬프트(prompt) 생성 네트워크를 제안합니다.

- **Technical Details**: PiVOT는 CLIP이라는 사전 훈련된 모델을 사용하여 자동으로 시각적 프롬프트를 생성하고 수정합니다. CLIP은 범주 수준의 광범위한 지식을 제공하며, 트래커는 객체 인스턴스(instance-specific data)에 대한 훈련을 통해 고유한 객체 인스턴스를 인식하는 데 강점을 가집니다. PiVOT는 시각적 프롬프트를 잠재적 목표 위치를 강조하는 형태로 컴파일합니다.

- **Performance Highlights**: 여러 벤치마크에서 수행된 실험을 통해 PiVOT은 방해 물체(distractors)를 억제하고 트래커의 성능을 향상시키는 데 효과적임을 입증하였습니다.



### Unsupervised Low-light Image Enhancement with Lookup Tables and Diffusion Priors (https://arxiv.org/abs/2409.18899)
Comments:
          13 pages, 10 figures

- **What's New**: 이번 연구에서는 Poor illumination 환경에서 degraded된 이미지를 효율적으로 복구하기 위한 새로운 Unsupervised LIE framework, DPLUT(Diffusion Prior and Lookup Table)를 제안합니다.

- **Technical Details**: 제안된 방법은 두 가지 주요 구성요소로 이루어집니다: LLUT(Light Adjustment Lookup Table)와 NLUT(Noise Suppression Lookup Table). LLUT는 unsupervised loss를 사용하여 최적화되며, 특정 이미지의 dynamic range를 조정하기 위한 pixel-wise curve parameters를 예측합니다. NLUT는 빛의 밝기 증가 후에 발생하는 noise를 제거하도록 설계되었습니다. 또한, diffusion 모델이 noise에 민감하기 때문에 diffusion priors를 도입하여 높은 성능의 noise 억제를 달성합니다.

- **Performance Highlights**: 광학적 품질과 효율성 측면에서 우리 방법이 기존의 최신 기법(State-of-the-art methods)보다 우수한 성능을 보인다는 실험 결과가 있습니다.



### Detecting Dataset Abuse in Fine-Tuning Stable Diffusion Models for Text-to-Image Synthesis (https://arxiv.org/abs/2409.18897)
- **What's New**: 본 논문은 텍스트-이미지 합성을 위한 Stable Diffusion 모델의 파인 튜닝 과정에서 발생할 수 있는 데이터셋 남용 문제를 다룹니다. 이를 위해 데이터셋의 무단 사용을 감지하고 데이터 유출을 추적할 수 있는 데이터셋 워터마킹 프레임워크를 제시합니다.

- **Technical Details**: 제안된 프레임워크는 여러 워터마킹 방식에서 두 가지 주요 전략을 사용하여 대규모 데이터셋의 권한 부여를 효과적으로 수행합니다. 이 프레임워크는 높은 탐지 정확도를 위해 데이터의 2%만 수정하면 되는 최소한의 영향으로 데이터를 보호하는 장점을 가지고 있습니다.

- **Performance Highlights**: 광범위한 실험을 통해 프레임워크의 효과성, 데이터 유출 추적 능력 및 강인성과 전이 가능성을 입증하였습니다. 이로써 데이터셋 남용을 탐지하는 데 실용적인 응용이 가능함을 보여줍니다.



### S2O: Static to Openable Enhancement for Articulated 3D Objects (https://arxiv.org/abs/2409.18896)
- **What's New**: 이번 논문에서는 정적인 3D 객체로부터 상호작용이 가능한 3D 객체를 생성하는 새로운 S2O(Static to Openable) 작업을 소개합니다. 이는 열 수 있는 부분 탐지, 운동 예측 및 내부 기하학 완성을 통해 이루어집니다.

- **Technical Details**: S2O 작업을 수행하기 위해 통합된 프레임워크를 설계하였으며, 상호작용이 가능한 3D 객체들로 구성된 도전적인 데이터셋을 구축하였습니다. 이 데이터셋은 체계적인 평가를 위한 테스트 베드 역할을 합니다.

- **Performance Highlights**: 실험을 통해 이전 연구에서 제시된 방법들과 S2O 작업을 위한 간단하면서도 효과적인 휴리스틱 방법들을 비교하였습니다. 정적인 3D 객체를 상호작용이 가능한 형태로 변환하는 것이 가능하지만, 실제 환경에 대한 일반화에는 모두 어려움을 겪고 있음을 확인했습니다. 이를 통해 향후 연구 방향에 대한 가능성을 제시합니다.



### Explainable Artifacts for Synthetic Western Blot Source Attribution (https://arxiv.org/abs/2409.18881)
Comments:
          Accepted in IEEE International Workshop on Information Forensics and Security - WIFS 2024, Rome, Italy

- **What's New**: 이 논문은 최신 인공지능 기술이 생성한 합성 과학 이미지가 실제 이미지와 구분되지 않는 상황을 다룹니다. 특히, 'paper mills'라는 조직이 이러한 기술을 악용하여 허위 기사를 생성하는 문제를 강조합니다.

- **Technical Details**: 연구팀은 Generative Adversarial Networks (GANs)와 Diffusion Models 같은 최신 generative 모델이 생성하는 설명 가능한 아티팩트(artifacts)를 식별하려고 합니다. 이를 통해 open-set identification과 source attribution을 가능하게 하여, 이미지가 생성된 모델을 지목할 수 있도록 합니다.

- **Performance Highlights**: 이 연구는 이전의 블랙박스 솔루션에서 벗어나 합성 이미지 안의 아티팩트를 통해 검출 프로세스에 대한 인사이트를 제공하며, 다양한 모델 간의 일반화 문제를 해결하는데 기여할 것으로 기대됩니다.



### CemiFace: Center-based Semi-hard Synthetic Face Generation for Face Recognition (https://arxiv.org/abs/2409.18876)
Comments:
          accepted to NeurIPS 2024. We are preparing the camera-ready version according to the reviews

- **What's New**: 이 논문에서는 얼굴 인식(Face Recognition, FR) 기술 개발에 있어 개인정보 보호 문제를 해결하기 위한 새로운 접근 방식을 제안합니다. 기존의 생성 기법으로 합성된 얼굴 이미지는 성능 저하 문제를 겪는 경우가 많지만, 본 연구는 얼굴 이미지의 유사성이 모델 성능에 미치는 영향을 체계적으로 조사합니다.

- **Technical Details**: 우리는 Center-based Semi-hard Synthetic Face Generation (CemiFace)이라는 새로운 확산 기반 접근 방식을 제안합니다. 이 방법은 각기 다른 유사성 수준을 가진 얼굴 샘플을 생성하여 효과적인 훈련 데이터셋을 형성합니다. 논문에서는 특정 유사성을 가진 얼굴 이미지가 FR 모델 훈련에 어떻게 기여하는지를 분석합니다.

- **Performance Highlights**: 실험 결과, 적절한 유사성을 가진 얼굴 데이터셋으로 훈련 시, 이전 생성 방법에 비해 경쟁력 있는 성능을 낼 수 있다는 것을 보였습니다.



### Emu3: Next-Token Prediction is All You Need (https://arxiv.org/abs/2409.18869)
Comments:
          Project Page: this https URL

- **What's New**: Emu3라는 새로운 모달 모델이 소개되었습니다. 이 모델은 오직 next-token prediction을 사용하여 훈련되었습니다.

- **Technical Details**: Emu3는 이미지를 token화하여 텍스트 및 비디오와 함께 결합한 혼합 멀티모달 시퀀스에서 훈련된 단일 Transformer 모델을 기반으로 합니다. 모델은 고급 멀티모달 작업을 처리하도록 설계되었습니다.

- **Performance Highlights**: Emu3는 SDXL 및 LLaVA-1.6와 같은 기존의 주요 모델을 초월하며, 생성 및 인식 작업 모두에서 잘 작동합니다. 또한 Emu3는 비디오 시퀀스에서 다음 토큰을 예측하여 고충실도 비디오를 생성할 수 있습니다.



### MCUBench: A Benchmark of Tiny Object Detectors on MCUs (https://arxiv.org/abs/2409.18866)
Comments:
          Code and data are available at this https URL

- **What's New**: MCUBench라는 새로운 벤치마크가 소개되었습니다. 이 벤치마크는 100개 이상의 YOLO 기반 객체 탐지 모델을 다루고 있으며, VOC 데이터셋을 바탕으로 7가지 다양한 MCU에서 평가되었습니다.

- **Technical Details**: MCUBench는 다양한 입력 해상도와 YOLO 기반 원스테이지 탐지기에 대한 평균 정확도(average precision), 대기 시간(latency), RAM, 플래시(Flash) 사용량에 대한 상세 데이터를 제공합니다. 고정된 훈련 파이프라인을 가진 통제된 비교를 통해 포괄적인 성능 메트릭을 수집합니다.

- **Performance Highlights**: Pareto 최적 분석을 통해 현대 탐지 헤드와 훈련 기법을 통합함으로써 YOLO 아키텍처(legacy 모델인 YOLOv3 포함)가 평균 평균 정확도(mAP)와 대기 시간 간의 효율적인 균형을 이룰 수 있음을 보여주었습니다. MCUBench는 현대 객체 탐지기의 MCU 성능을 벤치마킹하는 유용한 도구이며, 특정 제약을 기반으로 모델 선택에 도움을 줍니다.



### LW2G: Learning Whether to Grow for Prompt-based Continual Learning (https://arxiv.org/abs/2409.18860)
Comments:
          submit to neurips2024

- **What's New**: 이번 논문에서는 Continual Learning (CL) 분야에서 Prompt-based Continual Learning (PCL)의 성능 향상을 위한 새로운 접근을 제안합니다. 새로운 모듈을 통해 이전 작업 간의 차이를 기반으로 프롬프트 세트를 성장할지 여부를 학습합니다.

- **Technical Details**: 제안된 모듈인 Learn Whether to Grow (LW2G)는 여러 작업이 공유하는 공통점이 있을 때는 공유 프롬프트 세트를 사용하고, 이전 작업과의 큰 차이가 있을 경우 새로운 세트를 추가하는 방식을 채택합니다. 또한, Hinder Forward Capability (HFC) 메트릭을 활용하여 새로운 작업 학습에 대한 방해 요인을 측정합니다. 이를 통해 동적 임계값을 사용해 성장 여부를 자동으로 학습하는 Dynamic Growing Approach를 설계했습니다.

- **Performance Highlights**: 실험 결과, 제안된 방법이 기존의 방법들에 비해 우수한 성능을 보여주었으며, 코드도 공유되어 있어 연구자들이 쉽게 활용할 수 있도록 하였습니다.



### Space-time 2D Gaussian Splatting for Accurate Surface Reconstruction under Complex Dynamic Scenes (https://arxiv.org/abs/2409.18852)
Comments:
          Project page: this https URL

- **What's New**: 새로운 Surface Reconstruction (표면 재구성) 방법을 제시하며, 복잡한 동적 장면에서의 다중 인물 활동과 인간-객체 상호작용에 대한 문제를 해결하기 위해 Space-Time 2D Gaussian Splatting (공간-시간 2D 가우시안 스플래팅) 접근법을 도입했습니다.

- **Technical Details**: 이 방법은 동적 장면에서의 기하학적 품질을 향상시키기 위해 2D Gaussian splats를 학습하고, 깊이(Depth)와 법선(Normal) 정규화기를 도입해 물체 표면에 위치한 가우시안 디스크(Disks)를 변형합니다. 또한 복잡한 장면에서의 가려짐(Occlusion) 문제를 해결하기 위해 조합 불투명도 변형 전략(Opacity Deformation Strategy)을 소개합니다.

- **Performance Highlights**: 실제 세계의 희소 시점 비디오 데이터셋과 단안 동적 데이터셋에서 실험한 결과, 우리의 재구성이 최신 기술(State-of-the-art) 방법들보다 더 우수한 성능을 보이며, 특히 세부 표면 복원에서 뛰어난 결과를 나타냈습니다.



### MinerU: An Open-Source Solution for Precise Document Content Extraction (https://arxiv.org/abs/2409.18839)
Comments:
          MinerU Technical Report

- **What's New**: MinerU는 고정밀 문서 내용 추출을 위한 새로운 오픈소스 솔루션입니다. 기존의 OCR, 레이아웃 감지 및 수식 인식 방법의 한계를 극복하기 위해 다양한 문서 유형에서 효과적으로 콘텐츠를 추출합니다.

- **Technical Details**: MinerU는 정교한 PDF-Extract-Kit 모델을 활용하고 세밀하게 조정된 전처리(preprocessing) 및 후처리(postprocessing) 규칙을 적용하여 결과의 정확성을 높입니다.

- **Performance Highlights**: 실험 결과, MinerU는 다양한 문서 유형에서 일관되게 높은 성능을 달성하여 콘텐츠 추출의 품질과 일관성을 크게 향상시킵니다.



### Classification and regression of trajectories rendered as images via 2D Convolutional Neural Networks (https://arxiv.org/abs/2409.18832)
Comments:
          13 pages, 5 figures

- **What's New**: 이번 연구는 CNN (Convolutional Neural Networks)을 사용하여 다양한 형식으로 렌더링된 합성 궤적(synthetic trajectories)을 이미지로 변환하여 분류(classification) 및 회귀(regression) 문제를 해결하는 효과를 조사합니다.

- **Technical Details**: 본 연구에서는 궤적을 이미지로 변환할 때의 파라미터로 선 두께(line thickness), 이미지 해상도(image resolution), 동작 이력(motion history, 시간 요소의 색상 코딩), 앨리어싱 방지(anti-aliasing) 등을 고려하였습니다. CNN은 이미지에서 특징(feature)의 공간적 계층(spatial hierarchies)을 학습하는 능력을 활용하여 복잡한 형태를 인식합니다.

- **Performance Highlights**: 실험 결과에 따르면, 운동 방향이 중요한 응용 프로그램에서는 모델의 깊이에 따라 적절한 이미지 해상도를 선택하는 것이 중요하다. 또한, 궤적을 이미지로 렌더링함으로써 발생할 수 있는 정보 손실과 스펙트럼 변화 등의 아티팩트(artifacts)를 고려하는 것이 필수적입니다.



### YOLOv8-ResCBAM: YOLOv8 Based on An Effective Attention Module for Pediatric Wrist Fracture Detection (https://arxiv.org/abs/2409.18826)
Comments:
          Accepted by ICONIP 2024. arXiv admin note: substantial text overlap with arXiv:2402.09329

- **What's New**: 본 연구는 YOLOv8 네트워크 아키텍처에 ResCBAM(Convolutional Block Attention Module)을 통합한 YOLOv8-ResCBAM 모델을 제안합니다.

- **Technical Details**: YOLOv8-ResCBAM은 원래 YOLOv8의 구조에 attention 모듈을 적용하여 모델 성능을 개선합니다. ResCBAM은 residual block을 활용하여 네트워크의 중요한 정보를 강화합니다.

- **Performance Highlights**: 제안된 모델은 GRAZPEDWRI-DX 데이터셋에서 mAP 50(Intersection over Union 기준) 성능이 63.6%에서 65.8%로 증가하여 최고의 성능을 달성했습니다.



### EyeTrAES: Fine-grained, Low-Latency Eye Tracking via Adaptive Event Slicing (https://arxiv.org/abs/2409.18813)
Comments:
          32 pages,15 figures,

- **What's New**: Eye-tracking 기술에서 새롭게 제안된 EyeTrAES는 신경모방(event-based) 카메라를 사용하여 높은 정확도로 자연스러운 동공(pupil) 움직임을 추적하는 접근 방식을 소개합니다.

- **Technical Details**: EyeTrAES는 적응형 윈도우/슬라이싱 알고리즘을 활용하여 다양한 눈 움직임 패턴에 대한 비동기식 이벤트 데이터의 적절한 집합을 보장합니다. 단일 눈에서의 누적된 이벤트 프레임에 대해 경량 이미지 처리 기능을 적용하여 동공 분할 및 추적을 수행합니다.

- **Performance Highlights**: EyeTrAES는 동공 추적 충실도를 6% 이상 향상시켜 IoU가 92%에 도달하며, 경쟁 기술에 비해 최소 3배 더 낮은 대기 시간(latency)을 기록합니다. 또한, 개인별 미세한 동공 운동을 통해 생체 인식(Biometric) 지문으로 활용 가능함을 보여줍니다.



### MiniVLN: Efficient Vision-and-Language Navigation by Progressive Knowledge Distillation (https://arxiv.org/abs/2409.18800)
- **What's New**: 최근 Embodied Artificial Intelligence (Embodied AI) 분야에서 모델의 크기가 증가하는 반면, 컴퓨팅 능력은 제한적이라는 문제가 발생했습니다. 본 논문은 Vision-and-Language Navigation (VLN) 과제를 해결하기 위한 두 단계 지식 증류 (knowledge distillation) 프레임워크를 제안합니다.

- **Technical Details**: 제안된 방법은 두 단계에 걸쳐 지식을 캡처하며, 첫 번째 단계에서는 미세한 지식(fine-grained knowledge)을 사전 학습(pretraining) 과정에서, 두 번째 단계에서는 내비게이션 특정 지식(navigation-specific knowledge)을 파인 튜닝(fine-tuning) 과정에서 획득합니다. MiniVLN이라는 학생 모델은 이러한 지식 증류 기술의 잠재력을 시연합니다.

- **Performance Highlights**: MiniVLN은 R2R와 REVERIE 벤치마크에서 교사 모델(teacher model)과 동등한 성능을 기록하며, 모델 파라미터 수는 교사 모델의 약 12%에 불과합니다.



### Supervised Learning Model for Key Frame Identification from Cow Teat Videos (https://arxiv.org/abs/2409.18797)
- **What's New**: 이 논문에서는 신경망(neural networks)과 비디오 분석(video analysis)을 이용하여 젖소의 유선 염증(티티스, mastitis) 위험 평가의 정확성을 향상시키는 방법을 제안합니다.

- **Technical Details**: 젖소의 티티스 감염을 탐지하기 위해, 저자들은 촬영된 비디오에서 유선이 온전하게 보이는 주요 프레임을 식별하는 신경망을 사용합니다. 이러한 주요 프레임은 수의사들이 유선 건강 상태를 평가할 시간적 유연성을 제공하며, 평가의 효율성과 정확성을 증가시킵니다. 복잡한 환경, 변화하는 소의 자세와 위치, 비디오에서 유선을 식별하는 어려움 등이 주요 도전과제로 제시됩니다.

- **Performance Highlights**: 제안된 방법은 유선 비디오에서 주요 프레임을 식별하는 데 있어 단일 거리 척도 또는 모델을 사용할 때보다 성능(F-score)이 향상된 것으로 나타났습니다.



### Student-Oriented Teacher Knowledge Refinement for Knowledge Distillation (https://arxiv.org/abs/2409.18785)
- **What's New**: 이 논문에서는 전통적인 지식 증류(knowledge distillation) 방법이 아닌 학생 중심의 새로운 접근 방식을 소개합니다. 'Student-Oriented Knowledge Distillation (SoKD)'를 통해 교사의 지식을 학생의 필요에 맞게 세밀하게 조정하는 방식을 제안합니다.

- **Technical Details**: SoKD는 훈련 중에 학습 가능한 feature augmentation 전략을 통합하여, 교사의 지식을 학생에게 동적으로 조정합니다. 또한, 'Distinctive Area Detection Module (DAM)'을 도입하여 교사와 학생 간의 상호 관심 지역을 식별함으로써 지식 전송을 보다 효과적으로 집중시킵니다.

- **Performance Highlights**: 광범위한 실험 결과를 통해 제안된 방법의 효율성과 일반화 가능성이 입증되었습니다. 이는 다양한 지식 증류 방법과 통합하여 사용할 수 있는 플러그인 형태로 기능합니다.



### Relighting from a Single Image: Datasets and Deep Intrinsic-based Architectur (https://arxiv.org/abs/2409.18770)
Comments:
          Accepted for publication as a Regular paper in the IEEE Transactions on Multimedia

- **What's New**: 단일 이미지 장면 리라이트( Single image scene relighting) 연구는 새로운 조명 조건에 따라 현실감 있는 이미지를 생성하는 데 주력하고 있습니다. 본 연구는 데이터셋과 방법론적 관점 모두에서 이 문제를 해결하고 있습니다.

- **Technical Details**: 우리는 두 개의 새로운 데이터셋을 제안합니다. 하나는 본질 성분(intrinsic components)의 실제 값이 포함된 합성 데이터셋(synthetic dataset)이고, 다른 하나는 실험실 조건에서 수집된 실제 데이터셋(real dataset)입니다. 리라이트 파이프라인에서 물리적 일관성(physical consistency)을 포함하기 위해 본질 분해(intrinsic decomposition) 기반의 두 단계 네트워크를 구축하였습니다. 또한 우리가 만든 데이터셋과 기존 데이터셋에서 성능 테스트를 통해 우리의 방법이 최첨단 방법보다 뛰어나고, 사전 훈련(pretraining)된 방법의 성능을 향상시킬 수 있음을 입증하였습니다.

- **Performance Highlights**: 우리의 방법은 모든 조명 조건에 적응할 수 있어 애니메이션 결과를 생산할 수 있는 능력을 가지고 있습니다. 제공된 데이터셋, 방법 및 동영상은 공개적으로 이용 가능합니다.



### State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features (https://arxiv.org/abs/2409.18769)
Comments:
          16 pages, 4 figures, 4 tables

- **What's New**: 이번 연구에서는 눈과 눈꺼풀 주위의 거리와 특징들을 정량화하고 질병을 모니터링하는 데 있어서 중요한 정보를 제공하기 위해 3가지 딥러닝 방법을 개발했습니다. 이를 통해 수동 측정의 주관성과 시간 소모를 극복할 수 있습니다.

- **Technical Details**: 연구팀은 세 가지 딥러닝(segmentation) 방법을 사용하여 periorbital distance를 예측하였으며, 이를 통해 예측된 거리의 MAE는 훈련된 인간 주석자 간의 오류와 비슷하거나 그보다 낮았습니다. 현대 방식(SOTA)과 비교하여 모든 데이터셋에서 평균적으로 더 나은 성능을 보였습니다.

- **Performance Highlights**: 모델은 병든 눈에 대해 강력한 segmentation을 달성했으며, 건강한 눈을 사용하여 훈련된 모델에서도 효과적이었습니다. 또한, periorbital distances는 하위 분류(classification) 모델에서 고품질 특징으로 사용될 수 있음을 입증했습니다.



### Charting the Future: Using Chart Question-Answering for Scalable Evaluation of LLM-Driven Data Visualizations (https://arxiv.org/abs/2409.18764)
- **What's New**: 본 연구는 Visual Question Answering (VQA) 모델을 활용하여 LLM(대형 언어 모델) 생성 데이터 시각화의 평가를 자동화하는 새로운 프레임워크를 제안합니다. 전통적인 평가 방법은 비용이 많이 들고 확장성이 부족한 인간 판단에 의존하거나 오직 데이터 정확도에만 집중하는 경향이 있습니다.

- **Technical Details**: VQA 모델을 사용하여 차트의 데이터 표현 품질 및 일반적인 의사소통 명확성을 평가합니다. 실험은 ChartQA와 PlotQA라는 두 가지 주요 VQA 벤치마크 데이터 세트를 사용하여 OpenAI의 GPT-3.5 Turbo 및 Meta의 Llama 3.1 70B-Instruct 모델로 생성된 시각화를 통해 실시되었습니다.

- **Performance Highlights**: LLM이 생성한 차트는 VQA 성과 기반으로 원래의 비-LLM 생성 차트의 정확도에 미치지 못하며, few-shot prompting이 차트 생성의 정확도를 크게 향상시킬 수 있음을 보여줍니다. 그러나 LLM이 인간이 생성한 그래프의 정확성과 완전히 일치하려면 아직 많은 발전이 필요하다는 점이 강조됩니다.



### Enhancing Explainability in Multimodal Large Language Models Using Ontological Contex (https://arxiv.org/abs/2409.18753)
- **What's New**: 최근 Multimodal Large Language Models (MLLMs)에 대한 관심이 증가하고 있습니다. 이러한 모델들은 이미지와 텍스트를 통합하여 다양한 작업을 수행하는 데 있어 놀라운 잠재력을 가지고 있지만, 특정 도메인 응용 분야에서의 정확한 캡션과 시각적 개념 해석에 여전히 어려움을 겪고 있습니다. 본 연구에서는 이러한 문제를 해결하기 위해 온톨로지(ontology)를 통합하는 새로운 프레임워크를 제안합니다.

- **Technical Details**: 우리의 방법은 기존 식물 질병 온톨로지에서 식물 질병에 대한 개념을 활용하여 MLLMs에 질의하고 이미지에서 관련 시각적 개념을 추출합니다. 이후, 식별된 개념에 따라 질병을 분류하기 위해 온톨로지의 추론(reasoning) 능력을 활용합니다. 이는 도메인 특화 응용 분야에서 질병을 설명하는 개념이 정확하게 모델이 사용하도록 하는 데 있어 중요합니다.

- **Performance Highlights**: 온톨로지를 사용함으로써, 우리는 모델이 MLLMs에 의한 개념 주석이 온톨로지의 내용과 일치하는지를 검증하고 오류의 논리를 추적하여 결정 과정에서 투명성(transparency), 설명 가능성(explainability), 신뢰성(trust)을 높일 수 있습니다. 본 프레임워크는 기존의 잘 알려진 MLLMs를 활용한 경험적 연구에 의해 지원되는 온톨로지와 MLLMs의 시너지(new direction)를 제공하도록 설계되었습니다.



### MemFusionMap: Working Memory Fusion for Online Vectorized HD Map Construction (https://arxiv.org/abs/2409.18737)
- **What's New**: 이 논문에서는 자율 주행 시스템을 위한 고해상도 (HD) 맵 구축에 개선된 시간적 추론 능력을 가진 MemFusionMap이라는 새로운 모델을 제안합니다.

- **Technical Details**: MemFusionMap은 역사적 프레임 간의 추론을 개선하는 작업 메모리 융합 모듈을 포함하며, 차량의 궤적 정보를 명시적으로 인지하도록 설계된 새로운 시간적 오버랩 히트맵을 도입합니다. 이러한 두 가지 설계를 통합하여 HD 맵 구축의 성능을 크게 향상시킵니다.

- **Performance Highlights**: MemFusionMap은 기존 방법들보다 최대 5.4% 높은 mAP (mean Average Precision)를 기록하여 성능이 크게 향상되었습니다.



### Search and Detect: Training-Free Long Tail Object Detection via Web-Image Retrieva (https://arxiv.org/abs/2409.18733)
- **What's New**: 이 논문에서는 훈련 과정이 필요 없는 SearchDet라는 긴 꼬리(long-tail) 객체 탐지(object detection) 프레임워크를 소개합니다. 이 프레임워크는 개방형 어휘(open-vocabulary) 객체 탐지 성능을 크게 향상시킵니다.

- **Technical Details**: SearchDet는 객체의 긍정적(positive) 및 부정적(negative) 이미지 집합을 검색하여 이를 임베딩(embedding)하고, 입력 이미지에 가중치가 부여된 쿼리를 계산하여 이미지 내에서 원하는 개념을 탐지합니다. 이 방법은 간단하고 훈련 과정이 필요 없으며, GroundingDINO와 같은 최신(state-of-the-art) 모델에 비해 ODinW에서 48.7% mAP 향상, LVIS에서 59.1% mAP 향상을 달성하였습니다.

- **Performance Highlights**: 우리의 접근 방식은 웹에서 가져온(exemplars) 객체의 집합에 기반하여 안정적인 성능을 제공하며, 이는 비싼 데이터 주석(data annotation) 및 훈련 절차를 줄이는 방향으로 나아갈 수 있는 가능성을 나타냅니다.



### Learning from Pattern Completion: Self-supervised Controllable Generation (https://arxiv.org/abs/2409.18694)
- **What's New**: 이번 논문에서는 인공지능(AI) 분야에서 일반적으로 사용되는 레이블이 있는 학습 데이터 세트에 의존하지 않고 스스로 조절 가능한 생성(self-supervised controllable generation) 방법론을 제안합니다. 이러한 방법은 인간 뇌의 연상 작용을 모방한 것으로, 기능적 전문화를 이루는 모듈화된 오토인코더(modular autoencoder) 네트워크를 통해 이루어집니다.

- **Technical Details**: 제안된 프레임워크인 SCG(self-supervised controllable generation)는 모듈 내 독립성(intra-module independence)과 모듈 간 상관관계(inter-module correlation)를 촉진하기 위해 동등 변환 제약조건(equivariant constraint)을 도입합니다. 이로 인해 색상, 명도, 엣지 검출 모듈 처리에서 기능적 전문성을 확보합니다. 또한, 자기 감독형 패턴 완성(self-supervised pattern completion) 접근을 통해 학습을 진행합니다.

- **Performance Highlights**: 실험 결과, SCG는 색조, 명도, 엣지 검출의 모듈 처리에서 뛰어난 기능적 전문화를 보여주며, 인간 뇌와 유사한 방향 선택성(orientation selectivity), 색상 대립(color antagonism), 중심-주변 수용 영역(center-surround receptive fields) 특징을 나타냅니다. SCG는 페인팅(다시 그린 그림), 스케치, 고대 그래피티와 같은 다양한 작업에서 뛰어난 일반화 능력을 보여줍니다. 기존의 ControlNet과 비교할 때, SCG는 더 높은 노이즈 환경에서도 우수한 강건성(robustness)을 보이며, 자기 감독형 학습 덕분에 향후 더 나은 확장 가능성(scalability) 잠재력을 지니고 있습니다.



### A Novel Unified Architecture for Low-Shot Counting by Detection and Segmentation (https://arxiv.org/abs/2409.18686)
Comments:
          Accepted to NeurIPS2024

- **What's New**: GeCo는 정확한 객체 탐지, 분할 및 수량 추정을 통합된 아키텍처에서 수행할 수 있는 새로운 저샷(object counting) 카운터입니다.

- **Technical Details**: GeCo는 객체 외형의 다양성을 극복하기 위해 새로운 밀집 객체 쿼리(dense object query) 형식을 채택합니다. 또한, 탐지 작업을 직접 최적화하는 새로운 카운팅 손실(counting loss)을 제안하여 기존의 대리 손실(surrogate loss)에서 발생하는 문제를 피합니다.

- **Performance Highlights**: GeCo는 총 카운트 MAE에서 기존의 몇몇 샷 탐지 기반 카운터 대비 약 25% 향상된 성능을 보이며, 모든 저샷 카운팅 설정에서 새로운 최첨단(state-of-the-art) 결과를 세웠습니다.



### Image-guided topic modeling for interpretable privacy classification (https://arxiv.org/abs/2409.18674)
Comments:
          Paper accepted at the eXCV Workshop at ECCV 2024. Supplementary material included. Code available at this https URL

- **What's New**: 이 논문은 이미지에 포함된 개인정보를 예측하고 설명하기 위한 새로운 접근 방식을 제시합니다. 작가는 이미지 내용에 대한 자연어(content descriptors)를 기반으로 개인 정보 보호를 예측하였습니다.

- **Technical Details**: 우리는 이미지 안내 주제 모델링(Image-guided Topic Modeling, ITM)이라는 새로운 방법을 사용하여 개인 정보 보호 점수에 해당하는 설명자를 생성합니다. ITM은 비전 정보와 비전 언어 모델의 이미지 텍스트 설명을 멀티모달 정렬(multimodality alignment)을 통해 활용합니다.

- **Performance Highlights**: Priv×ITM 분류기는 해석 가능한(reference interpretable) 기존 방법보다 5% 더 높은 정확도로 성능을 보였으며, 현재 비해석 가능한(state-of-the-art) 모델과 유사한 성능을 보입니다.



### Exploiting Motion Prior for Accurate Pose Estimation of Dashboard Cameras (https://arxiv.org/abs/2409.18673)
- **What's New**: 본 연구는 대시캠(dashcam) 이미지를 위한 정밀한 자세 추정(pose estimation) 방법을 제안합니다. 이를 통해 카메라의 고유한 모션 프라이어(camera motion prior)를 활용하여 기존 이미지 매칭 방법의 한계를 극복하고자 합니다.

- **Technical Details**: 대시캠으로 캡처된 이미지 시퀀스는 일반적으로 전방 이동(forward movement)이나 측면 회전(lateral turns)과 같은 뚜렷한 모션 프라이어를 나타냅니다. 본 연구는 이를 기반으로 카메라 모션 프라이어를 학습하는 포즈 회귀 모듈(pose regression module)을 개발하고, 이를 관계 추정(correspondence estimation) 및 자세 추정 과정에 통합했습니다.

- **Performance Highlights**: 실제 대시캠 데이터셋에서 우리의 방법은 AUC5°에 대한 포즈 추정에서 기준선(baseline)보다 22% 향상된 성능을 보였으며, 재투영 오류(reprojection error)가 적은 이미지를 19% 더 많이 추정할 수 있었습니다.



### When SAM2 Meets Video Camouflaged Object Segmentation: A Comprehensive Evaluation and Adaptation (https://arxiv.org/abs/2409.18653)
Comments:
          Technical report

- **What's New**: 이번 연구는 Segment Anything Model 2 (SAM2)이 비디오에서 위장된 객체 세분화(video camouflaged object segmentation, VCOS) 작업에서 어떻게 활용될 수 있는지를 조사합니다. VCOS는 색상과 질감이 비슷하고 조명이 좋지 않은 환경에서 객체를 감지하는 어려운 과제입니다.

- **Technical Details**: 연구에서는 SAM2의 성능을 다양한 모델과 프롬프트(클릭, 박스, 마스크)를 사용하여 위장된 비디오 데이터셋에서 평가하였습니다. 또한, 기존의 다중 모달 대형 언어 모델(multimodal large language models, MLLMs) 및 VCOS 방법과 SAM2의 통합을 탐구하였습니다. SAM2를 비디오 위장 데이터셋에 맞추어 세밀하게 조정(fine-tuning)하여 적용하였습니다.

- **Performance Highlights**: SAM2는 비디오에서 위장된 객체를 탐지하는 매우 우수한 제로샷(zero-shot) 능력을 보여주었습니다. 또한, VCOS에 맞게 SAM2의 파라미터를 조정함으로써 이 능력을 더욱 향상시킬 수 있음을 입증하였습니다.



### Unsupervised Fingerphoto Presentation Attack Detection With Diffusion Models (https://arxiv.org/abs/2409.18636)
Comments:
          Accepted by IJCB 2024

- **What's New**: 이번 연구는 스마트폰 기반 비접촉식 지문 인증의 새로운 접근 방식으로, 최신 Denoising Diffusion Probabilistic Model (DDPM)을 활용하여 기존 방식의 단점을 해결하려는 시도를 보여줍니다.

- **Technical Details**: 제안된 방법은 오직 진짜(bona fide) 샘플로만 학습되며, 입력과 출력 쌍 간의 재구성 유사성(reconstruction similarity)을 계산하여 Presentation Attacks (PA)을 탐지합니다. 이를 통해 자율적으로 새로운 Presentation Attack Instruments (PAIs)의 탐지가 가능하게 됩니다.

- **Performance Highlights**: 실험 결과, 제안된 DDPM 기반 PAD 방법은 여러 PAI 클래스에서 다른 기초 비지도(unsupervised) 접근 방식에 비해 현저히 낮은 탐지 오류율(detection error rates)을 기록했습니다.



### From One to the Power of Many: Augmentations for Invariance to Multi-LiDAR Perception from Single-Sensor Datasets (https://arxiv.org/abs/2409.18592)
- **What's New**: 최근 자율주행 차를 위한 LiDAR 인식(methods) 기법들이 deep neural networks에 의해 더욱 향상되고 있습니다. 하지만 single-sensor(단일 센서) 환경에서 훈련된 모델을 modern multi-sensor(현대 다중 센서) 차량에 적용할 때 여전히 성능의 큰 차이가 존재합니다.

- **Technical Details**: 본 논문에서는 성능 차이의 원인으로 invariance(불변성)의 부족을 연구하고, multi-sensor LiDAR 환경으로의 더 나은 전이를 촉진하는 application-specific(응용 특정) data augmentations(데이터 증강)의 초기 솔루션을 제안합니다. 실험을 통해 제안한 증강 방법이 LiDAR 센서 설정의 일반화에 긍정적인 영향을 미친다는 것을 입증합니다.

- **Performance Highlights**: 제안된 데이터 증강 방법이 다양한 LiDAR 센서 설정에서 모델의 불변성 특성에 어떻게 영향을 미치는지에 대한 연구 결과를 포함하고 있습니다.



### Off to new Shores: A Dataset & Benchmark for (near-)coastal Flood Inundation Forecasting (https://arxiv.org/abs/2409.18591)
Comments:
          Accepted at NeurIPS 2024 Datasets & Benchmarks

- **What's New**: 이 논문에서는 홍수 예측을 위한 새로운 데이터셋과 벤치마크를 제안합니다. 이를 통해 다양한 상태-of-the-art 방법을 평가할 수 있는 기회를 제공합니다.

- **Technical Details**: 새로 구성된 데이터셋은 홍수 범위를 예상하는 데 필요한 정보들을 포함하고 있으며, 두 개의 벤치마크 트랙으로 나누어져 있습니다: i) 일반적인 홍수 예측 및 ii) 해안 지역에 집중한 예측.

- **Performance Highlights**: 이 데이터셋과 벤치마크는 홍수 예측과 관련된 연구 및 개발에 중요한 기초 자료를 제공하며, 향후 해결책을 모색하는 데 도움을 줄 것입니다.



### Cross-video Identity Correlating for Person Re-identification Pre-training (https://arxiv.org/abs/2409.18569)
Comments:
          NeurIPS 2024 Accepted Paper

- **What's New**: 본 연구에서는 Cross-video Identity-cOrrelating pre-traiNing (CION) 프레임워크를 제안하여 서로 다른 동영상에서의 동일 인물 이미지 간의 정체성 불변성을 고려합니다. 이전 연구들은 주로 인스턴스 수준 또는 단일 비디오 트랙렛 수준에서의 사전 학습에 국한되어 있었으나, CION은 이를 극복합니다.

- **Technical Details**: CION은 intra-identity consistency와 inter-identity discrimination을 포괄적으로 고려하는 노이즈 개념을 정의하고, 이를 점진적인 다단계 디노이징 문제로 모델링하여 cross-video 이미지 간의 정체성 상관관계를 탐색합니다. 또한, 정체성 유도 자기 증류 손실(identity-guided self-distillation loss)을 제안하여 사람 이미지 내의 정체성 불변성을 활용하여 대규모 사전 학습을 개선합니다.

- **Performance Highlights**: CION은 적은 수의 훈련 샘플을 사용하여도 뛰어난 성능을 기록하고 있으며, 예를 들어 ResNet50-IBN을 사용했을 때, Market1501에서 93.3%의 mAP과 MSMT17에서 74.3%의 mAP를 달성하며 기존의 최첨단 모델에 비해 높은 성능을 보였습니다. 또한, CION은 다양한 연구 및 응용 요구를 충족하기 위해 32개의 모델을 포함하는 ReIDZoo 모델 저수(zoo)를 제공합니다.



### Harmonizing knowledge Transfer in Neural Network with Unified Distillation (https://arxiv.org/abs/2409.18565)
- **What's New**: 이번 논문은 Knowledge Distillation (KD) 방법에 새로운 관점을 제시합니다. 기존의 훈련된 네트워크에서 가벼운 네트워크로 지식을 전이하는 기법을 개선하기 위해 여러 지식 출처를 통합한 KD 프레임워크를 도입하였습니다.

- **Technical Details**: 본 연구에서는 중간 레이어의 특징을 집계하여 포괄적인 표현을 생성하고, 이러한 표현으로부터 분포 매개변수를 예측합니다. 이를 통해 네트워크의 서로 다른 단계에서 지식을 효과적으로 전이할 수 있는 분포 제약을 설정하였습니다.

- **Performance Highlights**: 수많은 실험을 통해 제안된 방법의 효과를 검증하였으며, 기존 방법들보다 더 완전하고 일관성 있는 지식 전이가 이루어졌음을 보여줍니다.



### AL-GTD: Deep Active Learning for Gaze Target Detection (https://arxiv.org/abs/2409.18561)
Comments:
          Accepted to ACM Multimedia 2024

- **What's New**: 본 논문에서는 사람의 시선이 향하는 지점을 감지하는 gaze target detection 분야에서, 라벨이 부착된 데이터셋의 크기에 대한 의존성을 줄이기 위한 AL-GTD라는 혁신적인 접근 방식을 제안합니다.

- **Technical Details**: AL-GTD(Acquisition Learning for Gaze Target Detection)는 감독 학습(supervised learning)과 자기 감독 학습(self-supervised learning)을 통합하여 샘플 획득 함수(sample acquisition function)를 통해 능동 학습(active learning)을 수행합니다. 이 방법은 훈련 단계에서 분포 변화(distribution shifts)를 완화하기 위해 의사 라벨링(pseudo-labeling)을 활용합니다.

- **Performance Highlights**: AL-GTD는 전체 훈련 데이터의 40-50%만 사용하여 모든 AUC 결과에서 최고의 성과를 달성하며, 10-20%의 훈련 데이터로도 만족스러운 성능에 빠르게 도달합니다. 이는 가장 정보가 풍부한 샘플을 획득할 수 있는 기능을 통해 가능하다는 점에서 주목할 만합니다.



### Reducing Semantic Ambiguity In Domain Adaptive Semantic Segmentation Via Probabilistic Prototypical Pixel Contras (https://arxiv.org/abs/2409.18543)
Comments:
          revise

- **What's New**: 이번 연구에서는 도메인 적응의 문제점을 해결하기 위해 확률론적 프로토타입 픽셀 대비(probabilistic proto-typical pixel contrast, PPPC)라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 각 픽셀 임베딩을 다변량 가우시안 분포로 모델링하여 불확실성을 최대한 활용하고, 불확실성을 줄일 수 있는 방법을 제공합니다.

- **Technical Details**: PPPC는 각 픽셀의 임베딩을 확률적으로 모델링하고, 결정 경계(decision boundary)를 모호한 지점에서 멀리하도록 도와주는 프로토타입을 도출합니다. 이 방법은 분포 간 유사성을 계산하는 효율적인 방법을 사용하여 샘플링과 재매개변수화(reparameterization)의 필요성을 없애고 계산 오버헤드를 크게 줄입니다. 또한, 이미지 수준에서 모호한 크롭을 동적으로 선택하여 대조 학습(contrastive learning)에 개입되는 경계점의 수를 증가시킵니다.

- **Performance Highlights**: PPPC는 픽셀 수준의 모호성을 해결하고 판별적 표현(discriminative representations)을 생성하며, 합성(real-synthetic) 및 주간-야간(day-to-night) 적응 작업에서 크게 개선된 성능을 보여줍니다. 특히, 가장 도전적인 주간-야간 적응 시나리오에서 이전 최첨단(state-of-the-art, SOTA)보다 +5.2% mIoU의 성과를 달성하며, 다른 보지 못한 데이터셋에 대해 더 강한 일반화(generalization)를 보입니다.



### How Effective is Pre-training of Large Masked Autoencoders for Downstream Earth Observation Tasks? (https://arxiv.org/abs/2409.18536)
- **What's New**: 이번 연구는 Earth Observation (EO) 분야에서 ViT 기반의 Masked Autoencoders (MAE)의 사전 학습(pre-training) 효과를 조사했습니다. 사전 학습된 모델이 처음부터 학습하는 것보다 얼마나 유리한지에 대한 조건을 분석했습니다.

- **Technical Details**: 두 가지 대규모 ViT 기반 MAE 사전 학습 모델인 Prithvi와 SatMAE를 사용하여 재구성(reconstruction), 분할(segmentation), 분류(classification) 작업에서의 성능을 평가했습니다. Prithvi는 재구성 및 분할 작업에 대해 평가되었고, SatMAE는 분류 작업에서 성능을 평가 받았습니다.

- **Performance Highlights**: 사전 학습은 세부 조정(fine-tuning) 작업이 사전 학습 작업과 유사할 경우, 예를 들어 재구성 작업에서 특히 유리했습니다. 그러나 분할이나 분류 작업과 같은 경우, 특정 하이퍼파라미터 조정을 통해 처음부터 학습하는 것이 동등하게 또는 더 효과적임을 보여주었습니다.



### Prompt-Driven Temporal Domain Adaptation for Nighttime UAV Tracking (https://arxiv.org/abs/2409.18533)
Comments:
          Accepted by IROS2024

- **What's New**: 이번 연구는 야간 UAV(무인 항공기) 추적을 개선하기 위해 새로운 프롬프트 기반의 시간 도메인 적응 훈련 프레임워크(TDA)를 제안합니다. 이 프레임워크는 낮과 밤의 도메인에서 시간적 맥락의 분포를 정렬하여 더 나은 추적 성능을 제공합니다.

- **Technical Details**: 제안된 TDA 프레임워크는 시간적 특징 생성기(temporal feature generator)와 판별기(discriminator)를 훈련시켜 낮과 밤의 도메인 간 시간적 맥락을 정렬합니다. 또한, 프롬프트 기반 객체 탐지기(prompt-driven object miner)를 사용하여 주석이 없는 야간 비디오에서 객체를 정확히 찾습니다. 이와 함께, 장기 야간 UAV 추적을 위한 새로운 벤치마크가 구축되었습니다.

- **Performance Highlights**: TDA 프레임워크로 훈련된 추적기(TDA-Track)는 공개 및 자가 구축된 야간 벤치마크에서 뛰어난 성능을 보였으며, 실제 야간 테스트에서도 그 실용성을 입증했습니다.



### Neural Video Representation for Redundancy Reduction and Consistency Preservation (https://arxiv.org/abs/2409.18497)
- **What's New**: 본 논문에서는 임베디드 신경 표현(Implicit Neural Representations, INRs)을 활용하여 비디오 압축을 개선하는 새로운 방법을 제안합니다. 특히, 프레임의 고주파 성분을 기반으로 특징을 추출하여 기능 중복성을 줄이고, 인접 프레임 간의 특징 차이를 이용하여 프레임 간의 관계를 효율적으로 학습할 수 있도록 합니다.

- **Technical Details**: 제안된 방법은 각 프레임의 고주파 성분을 사용하여 특징을 추출하고, 인접 프레임 간의 특징 차이를 피드백으로 활용하여 네트워크가 프레임 관계를 학습하는 데 도움을 줍니다. 이를 통해 불필요한 중복성을 줄이고 더 나은 비디오 압축을 구현합니다.

- **Performance Highlights**: 실험 결과, 본 방법은 기존의 HNeRV 방법보다 90%의 비디오에서 성능이 향상되는 것으로 나타났습니다.



### Temporal2Seq: A Unified Framework for Temporal Video Understanding Tasks (https://arxiv.org/abs/2409.18478)
- **What's New**: 이번 논문에서는 여러 비디오 이해 작업을 동시에 처리할 수 있는 통합 프레임워크인 Temporal2Seq를 제안합니다. 이는 다양한 작업에 대해 매우 유용한 방향으로 나아가는 것을 목표로 합니다.

- **Technical Details**: Temporal2Seq는 temporal video understanding 작업의 출력을 일련의 개별 토큰(Discrete Tokens)으로 수식화합니다. 이를 통해 단일 아키텍처 내에서 여러 비디오 이해 작업을 위한 generalist 모델을 훈련할 수 있습니다.

- **Performance Highlights**: Temporal2Seq 모델은 세 가지 작업에 대한 테스트 세트에서 평가되었으며, 단일 작업 훈련에 비해 다양한 작업에서 우수한 결과를 도출합니다. 또한, 새로운 데이터셋에서의 일반화 성능도 기존 특정 모델보다 뛰어난 것으로 나타났습니다.



### Underwater Image Enhancement with Physical-based Denoising Diffusion Implicit Models (https://arxiv.org/abs/2409.18476)
- **What's New**: 본 논문은 자율 수중 차량(AUV)에서의 수중 이미지 향상을 위한 UW-DiffPhys라는 새로운 물리 기반(diffusion-based) 이미지 향상 방법을 소개합니다. 기존의 UW-DDPM 프레임워크에서 계산적으로 집약적인 U-Net 변환을 대체하여 복잡성을 줄이고 성능을 유지합니다.

- **Technical Details**: UW-DiffPhys는 물리 기반(UIE, Underwater Image Enhancement) 네트워크 구성요소와 노이즈 제거 U-Net을 결합하여, 최근의 UW-DDPM 솔루션을 통해 요구되는 계산 복잡도를 줄이고 있습니다. 또한, 비마르코프(non-Markovian) 샘플링을 통해 추론 과정을 가속화하기 위해 DDIM(Denoising Diffusion Implicit Model)을 사용합니다.

- **Performance Highlights**: 실험 결과, UW-DiffPhys는 UW-DDPM에 비해 상당한 계산 복잡성과 추론 시간을 감소시켰으며, PSNR, SSIM, UCIQE 등의 주요 지표에서 경쟁력 있는 성능을 달성하였고, 전체 수중 이미지 품질(UIQM) 측면에서도 향상을 보였습니다.



### FoodMLLM-JP: Leveraging Multimodal Large Language Models for Japanese Recipe Generation (https://arxiv.org/abs/2409.18459)
Comments:
          14 pages, 5 figures

- **What's New**: 음식 이미지 이해에 관한 연구는 오랜 시간 동안 진행되어 왔고, 최근 Multimodal Large Language Models (MLLMs)의 발전이 이러한 연구에 큰 기여를 할 것으로 기대됩니다.

- **Technical Details**: 이 연구에서는 일본 레시피 데이터셋을 기반으로 LLaVA-1.5와 Phi-3 Vision이라는 개방형 MLLMs를 미세 조정하였으며, 이를 폐쇄형 모델인 GPT-4o와 비교 평가하였습니다. 레시피의 내용, 재료 및 조리 절차를 평가하기 위해 일본 음식 문화를 포괄적으로 반영한 5,000개의 평가 샘플을 사용했습니다.

- **Performance Highlights**: 우리의 모델은 재료 생성에서 F1 점수 0.531을 기록하여, 현재 최첨단 모델인 GPT-4o의 F1 점수 0.481을 초월함으로써 더 높은 정확도를 나타냈습니다. 또한, 조리 절차 텍스트 생성에서는 GPT-4o와 유사한 성능을 보였습니다.



### Enhancing Crime Scene Investigations through Virtual Reality and Deep Learning Techniques (https://arxiv.org/abs/2409.18458)
- **What's New**: 이 논문은 범죄 현장을 가상 현실(VR) 환경에서 검사하기 위한 사진 측량(photogrammetric) 재구성을 제안하며, 딥러닝(DL) 알고리즘을 통한 완전 자동(object recognition) 객체 인식에 중점을 두고 있습니다.

- **Technical Details**: 클라이언트-서버(client-server) 아키텍처를 통해 사전 훈련된 Faster-RCNN 모델을 선택하였으며, 이는 VR 환경에서 전문가가 선정한 관련 객체를 효과적으로 분류할 수 있는 최적의 방법으로 평가됩니다.

- **Performance Highlights**: 실제 범죄 현장을 시뮬레이션한 실험 결과, 제안된 방법이 잠재적인 증거 가치를 가진 객체를 효과적으로 찾고 인식할 수 있음을 보여주었으며, 특히 건강 및 안전 위험이 있는 범죄 현장(화재, 폭발, 화학물질 등)의 신속한 분석을 가능하게 하였습니다. 이를 통해 주관적 편견(subjective bias)과 현장 오염을 최소화할 수 있습니다.



### DynaWeightPnP: Toward global real-time 3D-2D solver in PnP without correspondences (https://arxiv.org/abs/2409.18457)
- **What's New**: 본 논문은 실시간으로 3D와 2D 형태를 정렬하기 위한 최적의 pose 추정을 주요 다뤘습니다. 특히, correspondences(상응)이 없는 상태에서의 PnP 문제를 다루며, 복잡한 3D와 2D 형태의 등록 문제를 견고하게 처리하는 방법론을 제공합니다.

- **Technical Details**: Reproducing Kernel Hilbert Space (RKHS)를 이용하여 'big-to-small' 문제를 해결하기 위해 iterative reweighted least squares 방법을 적용합니다. 이 연구는 correspondence-free PnP에서 발생하는 회전(rotation)과 변환(translation) 간의 숫자적 모호성 문제를 구체적으로 다루며, 동적 가중치(DynaWeight) 서브 문제를 도입하여 pose 추정과 정렬 정확도를 향상시키는 알고리즘을 제안합니다.

- **Performance Highlights**: 제안된 DynaWeightPnP 알고리즘은 Endovascular Image-Guided Interventions (EIGIs)에서 3D-2D 혈관 중심선 등록 작업에 대한 실험을 통해, 현대 단일 코어 CPU에서 비슷한 방식으로 60 Hz(후처리 없음) 및 31 Hz(후처리 있음)의 등록 처리 속도를 기록했습니다. 이 결과는 기존 방법과 비교했을 때 경쟁력 있는 정확도를 나타내며, 향후 로봇 내비게이션 작업에 적합함을 강조합니다.



### Search3D: Hierarchical Open-Vocabulary 3D Segmentation (https://arxiv.org/abs/2409.18431)
Comments:
          This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 이 논문에서는 Search3D라는 새로운 접근법을 소개합니다. 이 방법은 계층적(open-vocabulary) 3D 장면 표현을 구축하여 다양한 세분화 수준에서 엔티티 검색을 가능하게 합니다.

- **Technical Details**: Search3D는 객체의 세부 파트, 전체 객체, 재료와 같은 속성으로 설명된 영역 등 다양한 레벨의 엔티티 검색을 지원합니다. 또한, MultiScan을 기반으로 하는 장면 규모의 open-vocabulary 3D 파트 분할 벤치마크를 제공하며, ScanNet++에 대해 open-vocabulary 세분화 주석을 추가합니다.

- **Performance Highlights**: Search3D는 여러 작업에서 효과성을 입증하였으며, 기존 방식들과 비교할 때 장면 규모 open-vocabulary 3D 파트 분할에서 우수한 성능을 보임과 동시에 3D 객체와 재료의 세분화에서도 강력한 성능을 유지합니다.



### Robust Network Learning via Inverse Scale Variational Sparsification (https://arxiv.org/abs/2409.18419)
Comments:
          21 pages, 7 figures

- **What's New**: 이 논문에서는 다양한 종류의 노이즈에 대한 저항력을 키우기 위해 새로운 접근법을 제안하고 있습니다.

- **Technical Details**: 본 연구는 시간 연속적(inverse scale space formulation) 인버스 스케일 변동 희소화(framework) 프레임워크를 도입하여 픽셀 간 변동 차이를 판단함으로써 점진적으로 세부적인 대규모 특징을 학습합니다. 이를 통해 작은 스케일 특징을 부드럽게 하여 노이즈를 제거하고, 질감(textures) 및 물체 윤곽(object contours)과 같은 고대비(high-contrast) 세부 사항을 유지합니다.

- **Performance Highlights**: 제안된 방법은 다양한 노이즈 유형에 대한 강력한 저항력을 보여주며, 기존의 주파수 기반(frequency-based) 방법들과 비교 시 간단하고 효율적인 구현을 제공합니다.



### Query matching for spatio-temporal action detection with query-based object detector (https://arxiv.org/abs/2409.18408)
- **What's New**: 이 논문에서는 영상에서 시간적 일관성을 유지해야 하는 스페이쇼-템포럴(spatio-temporal) 액션 감지(action detection) 모델에 DETR(query-based object detection 모델)을 확장하는 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 각 프레임에 DETR을 적용하고, 특징 이동(feature shift)을 이용하여 시간 정보를 통합합니다. 하지만 DETR의 각 프레임에서의 객체 쿼리가 서로 다른 객체와 대응될 수 있어 단순한 특징 이동은 비효율적일 수 있습니다. 이를 해결하기 위해, 우리는 서로 다른 프레임 간의 쿼리 매칭(query matching)을 제안하여 동일한 객체에 대한 쿼리가 매칭되도록 하고, 특징 이동에 사용합니다.

- **Performance Highlights**: 실험 결과, 제안된 쿼리 매칭을 사용하여 쿼리 특징을 이동시킬 때 JHMDB21 데이터셋에서 성능이 상당히 향상되었음을 보여줍니다.



### GenesisTex2: Stable, Consistent and High-Quality Text-to-Texture Generation (https://arxiv.org/abs/2409.18401)
- **What's New**: 이 논문에서는 대규모 텍스트 기반 이미지 확산 모델을 활용한 새로운 텍스처 합성 방법을 제안합니다. 텍스트에서 텍스처로의 변환을 위한 프레임워크를 소개하여 3D 기하학을 위한 텍스처 생성의 도전을 극복하고자 합니다.

- **Technical Details**: 우리의 접근법은 사전 훈련된 diffusion models를 기반으로 하며, self-attention 레이어에서 지역적 주의 재조정 메커니즘(local attention reweighing mechanism)을 도입하여 서로 다른 시점(viewpoint) 간에 공간적 연관성이 있는 패치에 집중하도록 모델을 유도합니다. 또한, 새로운 잠재 공간 병합 파이프라인(latent space merge pipeline)을 제안하여 다양성을 유지하면서도 서로 다른 시점 간의 일관성을 보장합니다.

- **Performance Highlights**: 이 방법은 기존의 최첨단 기술에 비해 텍스처 일관성(texture consistency)과 시각적 품질(visual quality)에서 상당히 우수한 성능을 보였으며, 증류 기반(methods based on distillation) 방법들보다 훨씬 빠른 결과를 제공했습니다. 추가적인 훈련이나 미세 조정(fine-tuning)이 필요 없어, 공공 플랫폼에서 사용할 수 있는 다양한 모델에 쉽게 적용할 수 있습니다.



### You Only Speak Once to S (https://arxiv.org/abs/2409.18372)
Comments:
          7 pages, 4 figures

- **What's New**: 새로운 접근 방식 YOSS(You Only Speak Once to See)를 소개하여 오디오를 활용하여 시각적 장면 내 객체를 기초하는 방법(오디오 기초화)을 제안합니다.

- **Technical Details**: 사전 훈련된 오디오 모델과 시각 모델을 대조 학습(contrastive learning) 및 다중 모달 정렬(multi-modal alignment)을 통해 통합합니다. 이 과정에서 음성 명령 또는 설명을 캡처하고 이를 이미지 내의 해당 객체에 직접 매핑합니다.

- **Performance Highlights**: 실험 결과에 따르면, 오디오 가이드를 객체 기초화에 효과적으로 적용할 수 있으며, 현재의 객체 기초화 방법의 정밀성과 견고성을 향상시킬 수 있는 가능성을 제시합니다. 이는 로봇 시스템 및 컴퓨터 비전 애플리케이션의 성능 개선에 기여할 수 있습니다.



### Multi-hypotheses Conditioned Point Cloud Diffusion for 3D Human Reconstruction from Occluded Images (https://arxiv.org/abs/2409.18364)
Comments:
          17 pages, 7 figures, accepted NeurIPS 2024

- **What's New**: 본 논문에서는 심각한 가림(occlusion) 상황에서도 3D 인간 형태 재구성을 위한 새로운 파이프라인, MHCDIFF를 제안합니다. 이 방법은 픽셀 정렬된 세부 3D 인간 재구성을 위해 점 구름(diffusion) 모델을 도입합니다.

- **Technical Details**: MHCDIFF는 단일 RGB 이미지에서 기하학적 세부 사항을 캡처하기 위해 다수의 가설화된 SMPL(-X) 메쉬로부터 로컬 특징(local features)을 추출하고 이 특징 집합을 활용하여 확산 모델(diffusion model)을 조정합니다. 점 구름 확산(point cloud diffusion) 모델은 누락된(osculaded) 영역을 생성하기 위해 전체적인 일관성(global consistent features)을 캡처하며, 잡음 제거(denoising) 과정에서 잘못 정렬된 SMPL 메쉬를 수정합니다.

- **Performance Highlights**: CAPE 및 MultiHuman 데이터셋에서의 실험 결과, 제안된 방법은 SMPL, 암묵적 함수(implicit functions), 점 구름 확산(point cloud diffusion) 및 이들의 결합 기반의 다양한 최신 기술(SOTA) 방법들과 비교하여 우수한 성능을 보였습니다.



### SinoSynth: A Physics-based Domain Randomization Approach for Generalizable CBCT Image Enhancemen (https://arxiv.org/abs/2409.18355)
Comments:
          MICCAI 2024

- **What's New**: 이번 연구에서는 SinoSynth라는 물리 기반의 열화 모델을 제시하여 다양한 CBCT 특별 아티팩트를 시뮬레이션하고, 고품질 CT 이미지로부터 합성 CBCT 이미지를 생성합니다. 이러한 접근 방식은 사전 정렬된 데이터 없이도 다양한 이미지를 생성할 수 있는 가능성을 보여줍니다.

- **Technical Details**: SinoSynth는 이미지 전환 방법을 통해 CBCT 아티팩트를 해결하려는 전통적인 접근 방식을 개선합니다. 이 모델은 고정합성 데이터 없이 다양한 CBCT 전용 아티팩트를 생성할 수 있으며, 이를 통해 여러 생성 네트워크가 다양한 다기관 데이터 세트에서 상업용 데이터보다 우수한 성능을 발휘하는 것을 확인하였습니다.

- **Performance Highlights**: 광범위한 실험을 통해, 우리의 합성 데이터에서 훈련된 여러 생성 네트워크가 이질적인 다기관 데이터 세트에서 뛰어난 결과를 달성하며, 실제 데이터에서 훈련된 같은 네트워크보다도 성능이 우수함을 보여주었습니다. 또한, 우리의 열화 모델은 조건부 생성 모델에서 해부학적 제약을 강제하는 수단을 제공하여 고품질 및 구조 보존적인 합성 CT 이미지를 생성할 수 있게 해줍니다.



### Does End-to-End Autonomous Driving Really Need Perception Tasks? (https://arxiv.org/abs/2409.18341)
Comments:
          Technical Report

- **What's New**: 이 논문에서는 16개의 내비게이션 기반 토큰(navigation-guided tokens)만을 활용하여 정밀한 장면 정보를 효율적으로 추출하는 새로운 프레임워크인 SSR(Sparse Scene Representation)을 소개합니다. 이는 기존의 감독 학습(supervised learning) 기반의 방법에서 벗어나, 자율주행 시스템의 실시간 배치를 보다 유연하게 만듭니다.

- **Technical Details**: SSR은 E2E 자율주행(End-to-End Autonomous Driving) 방법론의 한계를 극복하기 위해 설계된 프레임워크로, 감독 학습 작업을 필요로 하지 않고 내비게이션 의도(navigation intent)에 직접적으로 관련된 주요 요소에 자원을 집중할 수 있도록 합니다. 또한, Bird's-Eye View (BEV) 월드 모델을 활용한 시간적 향상 모듈을 도입하여, 예측된 미래 장면과 실제 미래 장면을 자기 감독(self-supervision) 방식을 통해 정렬합니다.

- **Performance Highlights**: SSR은 nuScenes 데이터셋에서 최첨단 계획 성능을 달성하며, L2 오류에서 27.2% 상대 감소, UniAD보다 51.6% 낮은 충돌률을 기록했습니다. 또한, SSR은 10.9배 빠른 추론 속도(inference speed)와 13배 더 빠른 훈련 시간(training time)을 제공합니다.



### DeBaRA: Denoising-Based 3D Room Arrangement Generation (https://arxiv.org/abs/2409.18336)
Comments:
          Accepted at NeurIPS 2024. Preprint version

- **What's New**: 본 논문에서는 DeBaRA라는 새로운 score-based model을 소개합니다. 이 모델은 제약이 있는 환경에서 정밀하고 유연한 배치 생성을 위한 것으로, 3D 공간 인식(3D spatial awareness)을 핵심으로 설계되었습니다.

- **Technical Details**: DeBaRA는 객체의 크기와 위치를 정확히 결정하는 것이 장면 합성 시스템(Scene synthesis system)에서 가장 중요한 요소라고 주장합니다. 이 모델은 경량의 conditional score-based model로 설계되어 있으며, 훈련된 DeBaRA 모델을 통해 다양한 다운스트림 애플리케이션(예: scene synthesis, completion, rearrangement)을 수행할 수 있습니다. 또한, Self Score Evaluation 절차를 도입하여 외부 LLM 모델과 최적의 조합으로 사용할 수 있도록 합니다.

- **Performance Highlights**: 광범위한 실험을 통해 기존의 최신 방법들에 비해 여러 시나리오에서 중요한 개선을 보여주었습니다. DeBaRA는 객체의 공간 속성(spatial attributes)에 집중하여 다양한 작업을 효과적으로 수행할 수 있습니다.



### Automated Segmentation and Analysis of Microscopy Images of Laser Powder Bed Fusion Melt Tracks (https://arxiv.org/abs/2409.18326)
Comments:
          21 pages, 10 figures

- **What's New**: 메탈 적층 제조 (metal additive manufacturing) 의 채택이 증가함에 따라, 연구자들과 실무자들은 데이터 기반 접근법(data-driven approaches)으로 인쇄 조건을 최적화하려 하고 있습니다. 이 논문에서는 크로스 섹션 이미지(cross-sectional images)로부터 용융 트랙(melt track)의 차원을 자동으로 식별하고 측정하는 이미지 세분화 신경망(image segmentation neural network)을 제시합니다.

- **Technical Details**: U-Net 아키텍처를 사용하여 서로 다른 연구실, 기계 및 재료에서 수집된 62개의 사전 라벨링된 이미지 데이터 세트(data set)로 훈련합니다. 이미지 증강(image augmentation)과 결합하여, 신경망의 하이퍼파라미터(hyperparameters)인 배치 크기(batch size) 및 학습률(learning rate)을 적절히 조정할 경우, 모델은 분류 정확도(classification accuracy)가 99% 이상, F1 스코어(F1 score)가 90% 이상을 보여줍니다. 신경망은 다양한 사용자에 의해 캡처된 이미지에서도 견고함(robustness)을 보이며, 서로 다른 기계 및 현미경을 사용하여 획득한 이미지에서도 검증되었습니다. 후처리 모듈(post-processing module)은 용융 풀(melt pool)의 높이(height) 및 너비(width)와 젖음 각도(wetting angles)를 추출합니다.

- **Performance Highlights**: 모델 성능 향상을 위한 기회와 다른 적층 제조 공정(directed energy deposition)으로의 전이 학습(transfer learning) 가능성에 대해 논의합니다.



### Harnessing Wavelet Transformations for Generalizable Deepfake Forgery Detection (https://arxiv.org/abs/2409.18301)
- **What's New**: 이번 논문에서는 Deepfake 탐지 방법의 약점을 해결하기 위해 Wavelet-CLIP이라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 Wavelet 변환(Wavelet Transforms)과 ViT-L/14 아키텍처에서 얻은 특징을 통합하여, 복잡한 Deepfake를 효과적으로 탐지할 수 있도록 설계되었습니다.

- **Technical Details**: Wavelet-CLIP는 Wavelet Transform을 이용하여 이미지의 공간적(spatial) 및 주파수(frequency) 특징을 깊이 분석합니다. 사전 훈련된 CLIP 방법으로 ViT-L/14 아키텍처의 특징들을 활용하여 높은 효율성을 발휘합니다.

- **Performance Highlights**: 테스트 결과, Wavelet-CLIP는 교차 데이터에 대한 일반화(cross-dataset generalization)에서 평균 AUC 0.749, 보이지 않는 Deepfake에 대한 강인성(robustness)에서 0.893을 기록하여 기존의 최첨단 방법들을 능가하는 뛰어난 성능을 보여주었습니다.



### SOAR: Self-supervision Optimized UAV Action Recognition with Efficient Object-Aware Pretraining (https://arxiv.org/abs/2409.18300)
- **What's New**: 이번 연구에서는 UAV(무인 항공기)로 촬영된 공중 영상에 대한 새로운 Self-supervised pretraining 알고리즘인 SOAR를 소개합니다. 이전 연구와는 달리, SOAR는 프리트레이닝(pretraining) 과정에서 인간 객체 지식을 통합하여 효율성을 높였습니다.

- **Technical Details**: SOAR는 두 가지 주요 접근 방식을 사용합니다. 첫째, 객체 인식과 관련된 특정 패치를 유지하기 위한 객체 인식 마스킹 전략(object-aware masking strategy)을 제안하였습니다. 둘째, 객체 정보를 활용하여 재구성 손실(reconstruction loss)을 조정하는 객체 인식 손실 함수(object-aware loss function)를 도입했습니다. 이를 통해 불필요한 배경 패치에 대한 편향을 방지할 수 있습니다.

- **Performance Highlights**: SOAR는 vanilla ViT 백본(backbone)을 사용하였으며, NEC-Drone과 UAV-Human 데이터셋에서 각각 9.7% 및 21.4%의 top-1 정확も(accuracy) 증가를 기록하며 기존 UAV 행동 인식(action recognition) 모델을 능가하였습니다. 특히, SOAR는 18.7ms의 비디오 당 추론 속도(inference speed)를 제공하며, 이는 2배에서 5배 더 빠릅니다. 추가로, SOAR는 이전의 Self-supervised learning 방법들과 유사한 정확도를 보여주면서도 87.5% 적은 프리트레이닝 시간과 25% 적은 메모리 사용을 요구합니다.



### Efficient Microscopic Image Instance Segmentation for Food Crystal Quality Contro (https://arxiv.org/abs/2409.18291)
- **What's New**: 본 논문은 제조 과정에서 식품 결정(식품 크리스탈)의 품질 관리를 위한 효율적인 예측 방법을 제안합니다.

- **Technical Details**: 이 연구에서는 기존의 수동 카운팅 방법 대신 오브젝트 디텍션(object detection)에 기반한 효율적인 instance segmentation 방법을 사용하여 식품 결정의 수와 크기 분포를 예측합니다. 식품 결정 분할(segmentation)은 결정의 다양한 형태와 주변의 경질 모사체(hard mimics)로 인해 도전적인 문제입니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 기존 분할 방법들과 비교할 때 결정 카운팅 정확도가 유사하면서도 다섯 배 빠른 속도를 보여줍니다. 또한, 실험을 통해 경질 모사체와 식품 결정을 분리하기 위한 객관적인 기준을 정의하여 유사 데이터셋에서 수동 주석(annotation) 작업에 도움이 될 수 있습니다.



### Advancing Object Detection in Transportation with Multimodal Large Language Models (MLLMs): A Comprehensive Review and Empirical Testing (https://arxiv.org/abs/2409.18286)
- **What's New**: 이번 연구는 교통 시스템에서 객체 탐지(object detection)에 대한 다중 모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)과 대형 비전 모델(Large Vision Models, VLMs)의 응용을 포괄적으로 검토하고 실증적으로 평가하는 것을 목표로 합니다.

- **Technical Details**: 연구의 첫 번째 부분에서는 MLLMs의 교통 응용 분야에서의 잠재적인 이점에 대한 배경을 제공하고, 기존 연구에서 현재 MLLM 기술에 대한 포괄적인 리뷰를 실시했습니다. 두 번째 부분에서는 교통 응용 프로그램에서의 엔드 투 엔드 객체 탐지(taxonomy of end-to-end object detection) 개요와 향후 방향을 제시했습니다.

- **Performance Highlights**: MLLM 성능에 대한 상세한 평가 결과를 제공하며, 도로 안전 특성 추출, 안전 비상 이벤트 탐지, 열화상 이미지의 시각적 추론을 포함한 세 가지 실제 교통 문제에 대한 실증 분석을 수행했습니다. 이 연구는 MLLM의 강점과 개선이 필요한 영역을 밝혀냈으며, 교통에서의 객체 탐지를 향상시키기 위한 MLLM의 실용적인 한계와 도전에 대해 논의합니다.



### Omni6D: Large-Vocabulary 3D Object Dataset for Category-Level 6D Object Pose Estimation (https://arxiv.org/abs/2409.18261)
Comments:
          ECCV 2024 (poster). Github page: this https URL

- **What's New**: Omni6D라는 새로운 RGBD 데이터셋을 소개하며, 다양한 범주와 배경을 포함하여 6D 객체 자세 추정의 현실적인 맥락을 제공한다.

- **Technical Details**: Omni6D 데이터셋은 166개의 범주, 4688개의 인스턴스, 80만 개 이상의 캡처로 구성되어 있어 기존 데이터셋보다 훨씬 넓은 평가 범위를 제공한다. 우리는 대칭성 인식(symmetry-aware) 메트릭을 도입하고 기존 알고리즘에 대한 체계적인 벤치마크를 수행하여 새로운 도전과 통찰력을 탐구한다. 또한, 기존 데이터셋에서 모델을 조정(adapt)할 수 있는 효과적인 파인 튜닝(fine-tuning) 접근법도 제안한다.

- **Performance Highlights**: 이 연구는 산업 및 학계 모두에서 6D 자세 추정의 경계를 확장하고 새로운 통찰력과 상당한 진행을 이룰 수 있는 기반을 마련할 것으로 기대된다.



### PCEvE: Part Contribution Evaluation Based Model Explanation for Human Figure Drawing Assessment and Beyond (https://arxiv.org/abs/2409.18260)
- **What's New**: 본 연구에서는 인간 형상 드로잉(Human Figure Drawing, HFD) 평가 작업에서 모델 결정의 명확성과 설명 가능성을 높이기 위해 부분 기여 평가 기반 모델 설명(Part Contribution Evaluation based Model Explanation, PCEvE) 프레임워크를 제안합니다.

- **Technical Details**: PCEvE는 각 개별 부분의 Shapley Value를 측정하여 모델 결정에 대한 기여도를 평가합니다. 기존의 pixel-level attribution 기반 설명 가능한 AI 설명 방식과 달리, PCEvE는 부분 기여 히스토그램(part contribution histogram)이라는 직관적인 설명을 제공합니다. 또한, PCEvE는 설명의 범위를 샘플 수준(sample-level)에서 클래스 수준(class-level) 및 작업 수준(task-level)으로 확장합니다.

- **Performance Highlights**: PCEvE는 여러 HFD 평가 데이터셋에 대한 광범위한 실험을 통해 엄격하게 검증되었으며, 제안된 방법의 타당성을 확인하기 위한 제어된 실험을 수행했습니다. 또한, PCEvE는 스탠포드 자동차와 같은 포토리얼리스틱(photo-realistic) 데이터셋에도 적용하여 다양성과 응용 가능성을 입증했습니다.



### Amodal Instance Segmentation with Diffusion Shape Prior Estimation (https://arxiv.org/abs/2409.18256)
Comments:
          Accepted at ACCV2024

- **What's New**: 새로운 연구에서는 Amodal Instance Segmentation (AIS)를 위한 AISDiff 모델을 제안합니다. 이 모델은 기존의 방법들이 갖고 있는 한계인 과적합(overfitting) 문제를 해결하고, 객체의 카테고리 세부정보를 고려합니다.

- **Technical Details**: AISDiff는 Diffusion Shape Prior Estimation (DiffSP) 모듈을 통해 가시적인 세분화 마스크와 객체의 카테고리를 예측합니다. 이 과정에서는 occluding masks를 예측하여 occlusion-aware 프로세싱을 수행합니다. DiffSP 모듈은 방대한 데이터셋에서 사전 학습된 conditioned diffusion models을 활용해 시각적 특징을 추출하여 shape prior를 추정합니다.

- **Performance Highlights**: 다양한 AIS 벤치마크에서의 실험을 통해 AISDiff의 효과가 입증되었습니다. 이는 기존 방법들에 비해 성능이 향상되었음을 나타냅니다.



### Spatial Visibility and Temporal Dynamics: Revolutionizing Field of View Prediction in Adaptive Point Cloud Video Streaming (https://arxiv.org/abs/2409.18236)
- **What's New**: 이번 논문에서는 점 구름 비디오(PCV)의 Field-of-View (FoV) 적응 스트리밍을 통해 대역폭 요구 사항을 크게 줄이는 방법을 제안합니다. 기존의 방법들은 일반적으로 6 자유도(6DoF) FoV 예측에 초점을 맞추지만, 본 연구는 셀 가시성(cell visibility) 관점에서 FoV 예측 문제를 재구성하였습니다.

- **Technical Details**: 우리는 역사적 3D 가시성 데이터를 활용하고, 공간 인식(spatial perception), 이웃 셀 상관관계(neighboring cell correlation), 가리기 정보(occlusion information)를 통합하는 새로운 공간 가시성(spatial visibility) 및 객체 인식(object-aware) 그래프 모델을 개발했습니다. 이 모델은 예측된 가시성 분포를 기반으로 3D 데이터 전송 결정을 정확하게 합니다.

- **Performance Highlights**: 우리 모델은 장기 셀 가시성 예측(long-term cell visibility prediction)을 크게 향상시켰으며, 최첨단 모델들에 비해 예측 MSE 손실을 최대 50% 줄였습니다. 동시에 100만 개 이상의 포인트를 가진 점 구름 비디오에 대해 30fps 이상의 실시간 성능을 유지합니다.



### Visual Concept Networks: A Graph-Based Approach to Detecting Anomalous Data in Deep Neural Networks (https://arxiv.org/abs/2409.18235)
- **What's New**: 이 논문에서는 깊은 신경망(Deep Neural Networks, DNN)이 비정상적(anomalous)이고 분포 밖(out-of-distribution, OOD) 데이터에 대해 강화되는 새로운 방법을 소개합니다. 기존 OOD 벤치마크는 단일 객체 작업에 초점을 맞추어 복잡한 현실 세계의 비정상성을 충분히 반영하지 못했습니다.

- **Technical Details**: 제안된 방법은 그래프(graph) 구조와 위상적(topological) 특징을 활용하여 원거리 OOD와 근거리 OOD 데이터를 효과적으로 탐지합니다. 이미지를 상호 연결된 이해 가능한 특징 또는 시각 개념의 네트워크로 변환하여 처리합니다.

- **Performance Highlights**: 대규모 어휘와 다양한 작업을 포함한 두 가지 새로운 작업에서의 광범위한 테스트를 통해 이 방법의 효과를 입증했습니다. 이 접근법은 DNN의 OOD 데이터에 대한 회복력(resilience)을 향상시키며 다양한 애플리케이션에서 성능 개선을 약속합니다.



### Analysis of Spatial augmentation in Self-supervised models in the purview of training and test distributions (https://arxiv.org/abs/2409.18228)
Comments:
          Accepted in ECCV 2024 Workshop on Out-of-distribution generalization in computer vision (OOD-CV)

- **What's New**: 이 논문에서는 self-supervised representation learning 방법에 사용되는 공간적 데이터 증강 기법인 random crop과 cutout에 대한 실증 연구를 제시합니다.

- **Technical Details**: 우리는 random cropping을 overlap과 patch로 구분하여, 두 augmentations의 overlapping 면적과 patch 크기가 downstream task의 정확도에 미치는 영향을 세밀하게 분석했습니다. 또한, cutout augmentation이 좋은 representation을 학습하지 못하는 이유에 대한 통찰도 제공합니다. 마지막으로, scene-centric 이미지에서 두 공간 뷰 사이의 픽셀 거리와 비례하는 margin을 적용하여 객체 중심 분포의 downstream task를 위한 scene-centric representation 학습에 대한 distance-based margin을 제안합니다.

- **Performance Highlights**: 단순한 margin 설정이 learned representation을 향상시킬 수 있음을 보여주며, 이러한 연구는 training augmentations와 test distribution 간의 domain-gap에 대한 이해를 발전시킵니다.



### Evaluation of Security of ML-based Watermarking: Copy and Removal Attacks (https://arxiv.org/abs/2409.18211)
- **What's New**: 이번 논문은 AI 기반 미디어의 저작권 보호 및 데이터 출처 검증을 위한 디지털 워터마킹의 안전성을 평가합니다. 특히 파운데이션 모델 기반의 워터마킹 시스템에 초점을 맞추고, 적대적 공격(adversarial attacks)에 대한 보안을 탐구합니다.

- **Technical Details**: 이 논문은 세 가지 세대의 디지털 워터마킹 시스템을 다룹니다: 수공예 방법(handcrafted methods), 오토인코더 기반(autoencoder-based) 방식, 파운데이션 모델 기반(foundational model) 방법. 저자들은 적대적 임베딩(adversarial embedding) 기술을 활용하여 잠재 공간(latent space)에서 워터마킹의 보안을 평가하는 실험을 수행하였습니다.

- **Performance Highlights**: 실험 결과, 복사(copy) 및 제거(removal) 공격 하에서의 다양한 보안 차원을 조사하였으며, 이 시스템들이 직면한 취약점(vulnerabilities)에 대한 경험적 통찰을 제공합니다. 모든 실험 코드와 결과는 제공된 URL에서 확인할 수 있습니다.



### SSP-RACL: Classification of Noisy Fundus Images with Self-Supervised Pretraining and Robust Adaptive Credal Loss (https://arxiv.org/abs/2409.18147)
Comments:
          IEEE BioCAS 2024

- **What's New**: 새롭게 제안된 방법론, Self-Supervised Pre-training with Robust Adaptive Credal Loss (SSP-RACL)을 통해 fundus 이미지 데이터셋에서 label noise 문제를 해결하는 내용이다.

- **Technical Details**: Masked Autoencoders (MAE)을 활용한 사전 학습(pre-training)과 RACL을 이용해 신뢰도 기준 및 적응형 레이블 이완(parameter) 설정으로 가능성 분포(possibility distributions)를 구축하는 방식이다. 이러한 접근법은 메모리 효과(memoration effect)를 억제하여 더욱 신뢰할 수 있는 ground-truth 추정치를 제공한다.

- **Performance Highlights**: 실험 결과, 제안한 SSP-RACL이 label noise를 처리하는 기존 방법들보다 뛰어난 성능을 보이는 것으로 나타났다.



### UniEmoX: Cross-modal Semantic-Guided Large-Scale Pretraining for Universal Scene Emotion Perception (https://arxiv.org/abs/2409.18877)
Comments:
          This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 이번 연구에서는 감정 인식을 위한 새로운 대규모 사전 학습 프레임워크인 UniEmoX를 소개합니다. 이는 심리학 연구에서 개인과 환경 간의 상호작용이 감정 탐색 과정과 분리될 수 없다는 점에 영감을 받았습니다.

- **Technical Details**: UniEmoX는 심장 중심(scene-centric) 및 개인 중심(person-centric) 저수준 이미지 공간 구조 정보를 통합하여 더 미세하고 구분 가능한 감정 표현을 도출하는 것을 목표로 합니다. 또한, CLIP 모델을 활용하여 이미지-텍스트 샘플 간의 유사성을 통해 감정 임베딩 표현을 효과적으로 향상시키는 방식으로 동작합니다.

- **Performance Highlights**: 총 6개의 벤치마크 데이터 세트와 2개의 하위 작업에서 실시한 실험을 통해 UniEmoX의 효과성을 검증하였으며, 다양한 시나리오에서 감정 분석을 위한 기존 심리학 이론과 현대적인 대비 학습(contrastive learning) 및 마스크 이미지 모델링 기법을 통합한 최초의 대규모 사전 학습 프레임워크입니다.



### Simulating Dynamic Tumor Contrast Enhancement in Breast MRI using Conditional Generative Adversarial Networks (https://arxiv.org/abs/2409.18872)
- **What's New**: 이번 논문은 유방 MRI에서 가상 대비 증강(virtual contrast enhancement) 방법을 제시하며, 기존의 대비 물질 기반 DCE-MRI(Dynamic Contrast-Enhanced MRI) 방식에 대한 비침습적(alternative) 대안을 제공합니다.

- **Technical Details**: 우리는 조건부 생성적 적대 신경망(conditional generative adversarial network, GAN)을 사용하여 대비가 없는 MRI에서 DCE-MRI 이미지를 예측하고, 여러 대응 DCE-MRI 시간 점의 순차적으로 생성된 이미지를 포함합니다. 이를 통해 종양의 위치(Localization) 파악과 특성 분석(Characterization)이 가능해지며, 관련된 건강 위험을 피할 수 있습니다.

- **Performance Highlights**: 우리는 합성된 DCE-MRI 이미지의 질적(qualitatively) 및 정량적(quantitatively) 평가를 수행하고, 종양 분할(tumor segmentation) 하위 작업에서의 유용성을 평가하기 위해 다중 메트릭(SAMe)을 제안합니다. 이 접근법은 현실적(realistic)이고 유용한 DCE-MRI 시퀀스를 생성하는 데 있어 유망한 결과를 보여주며, 특히 대비 물질 투여가 금기인 환자의 유방암 진단 및 치료 향상에 대한 가능성을 강조합니다.



### Positional Encoder Graph Quantile Neural Networks for Geographic Data (https://arxiv.org/abs/2409.18865)
Comments:
          17 main text pages, 4 figures

- **What's New**: 이번 논문에서는 Positional Encoder Graph Neural Networks (PE-GNNs)의 한계를 극복하기 위해 Positional Encoder Graph Quantile Neural Network (PE-GQNN)를 소개합니다. 이 방법은 PE-GNNs와 Quantile Neural Networks, 다시 조정 기술을 결합하여 예측 분포에 대한 최소한의 가정을 가지고 완전히 비모수적인 프레임워크를 제공합니다.

- **Technical Details**: PE-GQNN의 새로운 네트워크 아키텍처를 제안하며, quantile 기반 손실 함수를 결합하여 계산 복잡성을 증가시키지 않고도 정확하고 신뢰할 수 있는 확률적 모델을 생성합니다. 또한 KNN 예측기를 모델에 통합할 수 있는 구조화된 방법을 소개하며, GNN 레이어 연산을 통해 데이터 누수를 방지합니다.

- **Performance Highlights**: 벤치마크 데이터셋에 대한 실험 결과, PE-GQNN은 예측 정확도와 불확실성 정량화 모두에서 기존의 최고 수준의 방법들보다 상당한 개선을 나타냅니다.



### Early diagnosis of Alzheimer's disease from MRI images with deep learning mod (https://arxiv.org/abs/2409.18814)
Comments:
          7 pages, 3 figures, Presented at the 20-th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP) 21-22 February, 2024, Mazandaran University of Science and Technology, Babol, Iran

- **What's New**: 이 연구에서는 알츠하이머병(Alzheimer's disease, AD) 진단을 위한 새로운 방법으로 합성 소수 샘플 오버샘플링 기술(SMOTE)과 사전 훈련된 CNN(Convolutional Neural Network)을 활용한 뇌 MRI(Magnetic Resonance Imaging) 분석 프레임워크를 제안합니다.

- **Technical Details**: 이 프레임워크는 환자의 의료 기록, 신경심리학적 검사, MRI를 포함한 다양한 접근 방식을 통해 알츠하이머병의 특징을 식별합니다. 특히, Kaggle에서 얻은 이미지 데이터셋의 클래스 불균형 문제를 SMOTE를 통해 해결하였고, DEMNET라는 알츠하이머 네트워크에 사전 훈련된 CNN을 적용하여 중요한 특징들을 추출했습니다.

- **Performance Highlights**: 제안된 모델은 98.67%의 높은 정확도로 알츠하이머병 이미지를 분류하는 성능을 달성하였습니다.



### Open-Nav: Exploring Zero-Shot Vision-and-Language Navigation in Continuous Environment with Open-Source LLMs (https://arxiv.org/abs/2409.18794)
- **What's New**: 이번 연구에서는 Open-Nav라는 새로운 접근 방식을 제안하여, 오픈 소스 LLMs(large language models)의 활용을 통해 VLN(task) 문제를 제로샷(zero-shot)으로 해결하고자 하였다.

- **Technical Details**: Open-Nav는 공간-시간적 사고 연쇄(chain-of-thought) 방식으로 VLN 작업을 수행하며, 이를 통해 작업을 이해하고, 진행 상황을 추정하며, 결정을 내리는 단계로 나눈다. 또한, 세밀한 객체(object) 및 공간(spatial) 지식을 활용하여 장면 인식을 개선하고 LLM의 내비게이션(navigation) 추론 능력을 향상시킨다.

- **Performance Highlights**: 모의 환경과 실제 환경에서의 광범위한 실험을 통해 Open-Nav는 폐쇄형 LLM을 사용한 경우와 비교하여 경쟁력 있는 성능을 달성하였다.



### Excavating in the Wild: The GOOSE-Ex Dataset for Semantic Segmentation (https://arxiv.org/abs/2409.18788)
Comments:
          Submitted to IEEE for review

- **What's New**: 이번 연구에서는 독일의 야외 및 오프로드 데이터셋(GOOSE) 프레임워크의 일반화 가능성을 다룹니다. 특히 새로운 GOOSE-Ex 데이터셋을 오픈소스하여 5000개의 추가 멀티모달 프레임을 제공합니다.

- **Technical Details**: GOOSE-Ex 데이터셋은 다양한 완전히 다른 환경에서 기록된 라벨이 있는 멀티모달 프레임을 포함하며, 로봇 굴착기와 4족 동물을 사용합니다. 이 연구에서는 미지의 환경에서 다양한 플랫폼과 센서 모달리티에 대한 의미적 분할(semantic segmentation) 성능을 종합적으로 분석합니다.

- **Performance Highlights**: 결합된 데이터셋은 오프로드 내비게이션(offroad navigation), 객체 조작(object manipulation), 장면 완성(scene completion)과 같은 다양한 다운스트림 애플리케이션이나 대회에 활용될 수 있음을 보여줍니다.



### DualDn: Dual-domain Denoising via Differentiable ISP (https://arxiv.org/abs/2409.18783)
Comments:
          Accepted at ECCV 2024, Project page: this https URL

- **What's New**: 이 논문에서는 이미지 노이즈 제거를 위한 새로운 방법론인 DualDn을 제안합니다. 기존의 단일 도메인(domaian) 노이즈 제거 방식과 달리 DualDn은 원시(raw) 도메인과 sRGB 도메인 각각에 대해 독립적인 두 개의 노이즈 제거 네트워크를 구성합니다.

- **Technical Details**: DualDn은 원시 도메인에서 센서 특이 노이즈 및 공간적으로 변하는 노이즈 수준에 적응하고, sRGB 도메인에서는 ISP(이미지 신호 처리)의 변동성에 적응하여 ISP에 의해 증폭된 잔여 노이즈를 제거합니다. 두 네트워크는 미분 가능(differentiable)한 ISP와 연결되어 end-to-end 방식으로 훈련됩니다.

- **Performance Highlights**: DualDn은 다양한 새로운 노이즈, ISP 파라미터, 그리고 신규 ISP 파이프라인에 적응할 수 있어 일반화(generalizability)에서 뛰어난 성능을 기록합니다. 실험 결과, DualDn은 최신 성능(state-of-the-art performance)을 달성했으며, 실제 카메라에서 재훈련 없이도 플러그 앤 플레이(plug-and-play) 노이즈 제거 모듈로 사용할 수 있습니다.



### A Generalized Tensor Formulation for Hyperspectral Image Super-Resolution Under General Spatial Blurring (https://arxiv.org/abs/2409.18731)
- **What's New**: 본 논문에서는 하이퍼스펙트럴 이미지의 슈퍼 해상도를 달성하기 위한 새로운 텐서 기반 접근법을 제안합니다. 이 방법은 일반화된 텐서 형식을 사용하여 임의의 공간 저하 매트릭스를 처리할 수 있도록 합니다.

- **Technical Details**: 제안된 방법은 Kronecker 분해(Kronecker decomposition)를 기반으로 한 일반화된 텐서 공식화(generalized tensor formulation)를 사용합니다. 또한, 독립적인 수평 및 수직 블러링(horizontal and vertical blurring)으로 가정되지 않은 비분리(anistropic) 블러링을 모델링할 수 있는 조건을 분석합니다.

- **Performance Highlights**: 실험 결과, 제안된 일반화된 텐서 접근법이 전통적인 매트릭스 기반 기법뿐만 아니라 최신 텐서 기반 방법들과 비교하여 뛰어난 성능을 보임을 확인했습니다. 특히 비분리 공간 블러링(anisotropic spatial blurring) 경우에 큰 성능 향상이 있었습니다.



### Effectiveness of learning-based image codecs on fingerprint storag (https://arxiv.org/abs/2409.18730)
Comments:
          Accepted ad Wifs 2024

- **What's New**: 이 연구는 학습 기반 이미지 코덱이 지문 이미지 저장에 어떤 영향을 미치는지를 최초로 조사한 것으로, 학습 기반 압축 기술이 생체 데이터 저장 분야에 적용 가능성을 강조합니다.

- **Technical Details**: 연구에서는 JPEG-AI와 같은 학습 기반 이미지 코딩 표준의 효과를 살펴보며, 압축 아티팩트가 지문 특징과 랜드마크(landmarks) 추출에 미치는 영향을 분석합니다. 지문 이미지의 특성과 일반적인 컬러 이미지의 특성이 다르기 때문에 기존 모델이 이러한 이미지에서 어떻게 작동하는지에 대한 분석이 필수적입니다.

- **Performance Highlights**: 실험 결과, 고정 비율 포인트에서 학습된 솔루션은 JPEG2000과 같은 기존 지문 코딩 표준보다 왜곡(distortion)과 minutiae 보존 측면에서 뛰어난 성능을 보였습니다. 특히, 지문 인식 자동화에는 영향을 미치지 않으며, 인간의 시각적 검사를 위한 이미지 품질을 향상시킵니다.



### Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification (https://arxiv.org/abs/2409.18715)
- **What's New**: 본 논문에서는 비소세포 폐암(Non-small cell lung cancer, NSCLC)의 조기 발견과 세분화된 하위 유형 분류를 위한 혁신적인 다중 모드 데이터 통합 방법을 제안합니다. 이는 CT 및 PET 스캔과 임상 건강 기록 및 유전체 데이터를 융합하는 새로운 접근 방식을 포함합니다.

- **Technical Details**: 우리는 MedClip 및 BEiT와 같은 고급 머신러닝(advanced machine learning) 모델을 활용하여, 이미지 특징 추출을 위한 정교한 방법을 개발했습니다. 이러한 다중 모드 분류기 모델은 94.04%의 정확도를 기록하며, 기존의 접근 방식보다 상당한 성능 향상을 보여줍니다.

- **Performance Highlights**: 우리의 연구는 NSCLC 검출 및 분류의 정확성, 정밀도, 재현율 및 F1 점수 등 주요 성능 지표에서 두드러진 개선을 나타냅니다. 이는 NSCLC 진단을 변화시킬 수 있는 잠재력을 가지고 있으며, 더욱 효과적인 치료 계획 및 결과 개선에 기여할 것입니다.



### 3DPX: Single Panoramic X-ray Analysis Guided by 3D Oral Structure Reconstruction (https://arxiv.org/abs/2409.18701)
- **What's New**: 이번 연구에서는 Panoramic X-ray (PX) 영상 분석을 위한 새로운 방법인 3DPX를 제안합니다. 3DPX는 2D-to-3D reconstruction 기법을 활용하여 PX에서 결손된 3D 해부학 정보를 보완합니다.

- **Technical Details**: 3DPX는 (i) 새로운 점진적 재구성 네트워크(progressive reconstruction network)를 통해 2D-to-3D 재구성을 개선하고, (ii) 3D 유도 2D PX 분류 및 분할 작업을 위한 대비 유도 양방향 다중 모드 정렬 모듈을 포함합니다. 이 네트워크는 여러 피라미드 수준에서 중간 재구성에 대한 지식을 적용하여 3D 이미지를 점진적으로 재구성합니다.

- **Performance Highlights**: 464개의 연구를 포함한 두 개의 구강 데이터 세트에 대한 광범위한 실험 결과, 3DPX는 2D-to-3D 재구성, PX 분류 및 병변 분할을 포함한 다양한 작업에서 최첨단 방법을 능가했습니다.



### Enhanced Convolution Neural Network with Optimized Pooling and Hyperparameter Tuning for Network Intrusion Detection (https://arxiv.org/abs/2409.18642)
Comments:
          7 Pages , 2 figures , 4 Tables , Conference paper

- **What's New**: 이번 연구에서는 네트워크 침입 탐지 시스템(Network Intrusion Detection Systems, NIDS)을 위한 향상된 합성곱 신경망(Enhanced Convolutional Neural Network, EnCNN)을 제안합니다. 이 방법론은 KDDCUP'99 데이터셋을 사용하여 성능을 평가하고, 기존의 방법에 비해 10% 이상의 정확도 향상을 보여주었습니다.

- **Technical Details**: 연구에서는 데이터 전처리(data preprocessing), 탐색적 데이터 분석(exploratory data analysis, EDA), 기능 공학(feature engineering)을 포함하는 포괄적인 방법론을 사용하였습니다. EnCNN의 성능을 로지스틱 회귀(Logistic Regression), 결정 트리(Decision Trees), 서포트 벡터 머신(Support Vector Machines, SVM), 랜덤 포레스트(Random Forest), 아다부스트(AdaBoost), 투표 앙상블(Voting Ensemble) 등 다양한 기계 학습 알고리즘과 비교했습니다.

- **Performance Highlights**: EnCNN은 기존 최첨단 접근 방식에 비해 10%의 정확도 향상을 이루었습니다. 이는 실시간 네트워크 침입 탐지에서 EnCNN의 효과성을 보여주며, 보안 위협을 식별 및 완화하고 전체 네트워크의 복원력을 강화하는 강력한 솔루션을 제공함을 의미합니다.



### Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow (https://arxiv.org/abs/2409.18628)
Comments:
          Keywords: Epistemic Uncertainty - Out-of-Distribution Detection - CT Segmentation - OAR contouring - Radiotherapy

- **What's New**: 본 연구는 방사선 치료 계획에서의 목표 구조물 및 위험 장기(Organ-at-Risk, OAR)의 윤곽을 정확히 지정하는 것의 중요성을 강조하며, 최근 딥러닝(deep learning)의 발전을 통해 OAR 윤곽화 성능을 개선했으나, OOD(out-of-distribution) 시나리오의 신뢰성 문제를 다루고 있다. 특히, epistemic uncertainty(계량적 불확실성) 추정 통합을 통해 OOD 감지를 위한 새로운 방법론을 제시한다.

- **Technical Details**: 연구에서는 OAR 윤곽화 워크플로우에 epistemic uncertainty estimation을 통합하여 임상적으로 관련 있는 시나리오에서 OOD를 감지하는 방법을 제안한다. 구체적으로 설계된 데이터 세트를 사용하여 OOD 감지를 위한 고급 통계적 방법을 도입하고, 예측의 신뢰성이 떨어지는 사례를 식별하는 데 효과적임을 입증한다.

- **Performance Highlights**: 이 연구에서 제안한 접근법은 OOD 감지를 위한 AUC-ROC(Area Under the Curve - Receiver Operating Characteristic)를 0.95로 달성하였으며, 임플란트 사례에 대한 특이도(specificity) 0.95 및 민감도(sensitivity) 0.92를 기록하였다. 이는 모델 예측의 신뢰성을 판단하는 데 있어 전문가의 검토가 필요한 경우를 효과적으로 표시하는 데 기여한다.



### Metasurface-generated large and arbitrary analog convolution kernels for accelerated machine vision (https://arxiv.org/abs/2409.18614)
- **What's New**: 인공지능(AI) 분야의 발전 속에서, 기계 비전(machine vision) 및 의료 진단에서 중요한 역할을 하는 합성곱 신경망(convolutional neural networks)의 디지털 합성곱 층을 광학 메타표면(optical metasurface)으로 대체하는 연구가 이뤄졌습니다.

- **Technical Details**: 광학 메타표면을 이용하여 공간 주파수(domain) 훈련 방법(spatial frequency domain training method)을 개발하였으며, 이를 통해 아날로그(analog) 합성곱 커널(convolution kernels)을 임의의 형태로 생성할 수 있게 되었습니다. 이 방법은 비정형 조명(incoherent illumination) 조건에서 다수의 병렬 합성곱 커널을 생성합니다.

- **Performance Highlights**: MNIST 데이터셋에서 98.59%의 분류 정확도를 달성하였으며, Fashion-MNIST 및 CIFAR-10 데이터셋에서는 각각 92.63%와 68.67%의 정확도를 보였습니다. 이 연구는 아날로그 광학 합성곱의 독특한 이점을 강조하며, 특히 엣지 디바이스(edge devices)에서 기계 비전 작업을 가속화할 수 있는 유망한 경로입니다.



### CodeSCAN: ScreenCast ANalysis for Video Programming Tutorials (https://arxiv.org/abs/2409.18556)
- **What's New**: 이번 논문에서는 코딩 스크린캐스트(video tutorial) 분석을 위한 대규모 데이터셋인 CodeSCAN을 소개합니다. 이는 프로그래밍 교육에서의 비디오 튜토리얼의 검색 문제를 해결하기 위해 개발되었습니다.

- **Technical Details**: CodeSCAN 데이터셋은 Visual Studio Code 환경에서 캡처된 12,000개의 스크린샷으로 구성되어 있으며, 24개의 프로그래밍 언어, 25개의 폰트(font), 90개 이상의 테마(theme), 다양한 레이아웃(layout) 변화 및 현실적인 사용자 상호작용을 포함합니다. 또한, 통합 개발 환경(IDE) 요소 탐지, 흑백 변환(color-to-black-and-white conversion), 광학 문자 인식(OCR)에 대한 세부적인 정량적(quantitative) 및 정성적(qualitative) 평가를 실시합니다.

- **Performance Highlights**: 이 연구의 결과는 코딩 스크린캐스트 분석에 대한 연구 촉진을 기대하며, 데이터셋 및 벤치마크의 소스 코드를 공개하여 연구원들이 이용할 수 있도록 하였습니다.



### Efficient Noise Mitigation for Enhancing Inference Accuracy in DNNs on Mixed-Signal Accelerators (https://arxiv.org/abs/2409.18553)
- **What's New**: 본 논문에서는 아날로그 신경망의 정확도에 미치는 프로세스 유도 및 노화 관련 변동의 영향을 완화하여 신경 모델의 강인성을 향상시키는 프레임워크를 제안합니다.

- **Technical Details**: 변동은 활성화의 정밀도에 영향을 미치는 노이즈로 모델링되며, 사전 훈련된 모델의 선택된 레이어 사이에 삽입된 디노이징 블록(denoising block)을 소개합니다. 디노이징 블록을 훈련하여 다양한 노이즈 수준에 대한 모델의 강인성을 크게 증가 시킬 수 있음을 입증하였습니다. 디노이징 블록 추가로 인한 오버헤드를 최소화하기 위해 최적의 삽입 지점을 식별하는 탐색 알고리즘을 제시하고, 혼합 신호 가속기에 통합할 수 있는 효율적인 디노이징 블록 아키텍처를 제안합니다.

- **Performance Highlights**: DNN 모델을 ImageNet 및 CIFAR-10 데이터셋에서 훈련하여 접근 방식을 평가한 결과, 평균적으로 2.03%의 파라미터 카운트 오버헤드를 수용함으로써 변동으로 인한 정확도 감소가 31.7%에서 1.15%로 줄어드는 것을 보여주었습니다.



### Token Caching for Diffusion Transformer Acceleration (https://arxiv.org/abs/2409.18523)
- **What's New**: Diffusion transformers의 성능은 뛰어나지만, 높은 계산 비용이 동반됩니다. 이에 따라 TokenCache라는 새로운 사후 훈련 가속화 방법을 제안합니다.

- **Technical Details**: TokenCache는 토큰 기반 멀티 블록 아키텍처를 활용하여 추론 단계 간 토큰 간 중복 계산을 줄입니다. 세 가지 주요 질문에 답합니다: (1) 중복성을 없애기 위해 어떤 토큰을 가지칠지, (2) 어떤 블록을 효율적으로 가지칠지, (3) 속도와 품질을 균형 있게 하기 위해 언제 캐싱을 적용할지.

- **Performance Highlights**: 실험 결과, TokenCache는 여러 모델에서 diffusion transformers의 생성 품질과 추론 속도 간의 효과적인 균형을 달성하였습니다.



### Med-IC: Fusing a Single Layer Involution with Convolutions for Enhanced Medical Image Classification and Segmentation (https://arxiv.org/abs/2409.18506)
Comments:
          13 pages, 5 figures, 4 tables, preprint submitted to an Elsevier journal

- **What's New**: 이번 연구에서는 의학 이미지를 처리하는 데 있어, Convolutional Neural Network (CNN) 모델에 Involution 레이어를 단일 추가함으로써 분류 및 세분화 성능이 향상된다는 새로운 접근법을 소개합니다.

- **Technical Details**: Convolution(합성곱) 연산은 의료 이미지를 포함한 다양한 영상에서 시각적 패턴을 추출하는 데 제한적인 성능을 보입니다. Involution(역합성곱) 과정은 이러한 제한을 보완하며, CNN 아키텍처 전에 단일 Involution 레이어를 적용함으로써 성능을 개선할 수 있습니다. 연구는 Involution 레이어가 과도하게 사용될 경우 의료 이미지에 대한 예측 정확도가 저하될 수 있음을 보여줍니다.

- **Performance Highlights**: 단일 Involution 레이어 추가 전략은 대부분의 기존 연구 성과를 초과하는 결과를 낳아, 상당히 적은 수의 가중치 매개변수로도 개선된 성능을 유지할 수 있습니다.



### Towards Diverse Device Heterogeneous Federated Learning via Task Arithmetic Knowledge Integration (https://arxiv.org/abs/2409.18461)
Comments:
          NeurIPS 2024

- **What's New**: 이번 논문에서는 Fedrated Learning(Federated Learning, FL)의 한계를 극복하기 위해 TAKFL이라는 새로운 KD 기반 프레임워크를 제안합니다. 이 프레임워크는 다양한 이질적인 장치 모델의 지식 전이를 독립적으로 수행하여, 각 장치의 고유한 기여를 보존합니다.

- **Technical Details**: TAKFL은 각 장치 프로토타입의 앙상블에서 지식 전이를 별도의 작업으로 처리하며, 각 장치의 정보를 효과적으로 증류할 수 있도록 설계되었습니다. 또한, KD 기반의 self-regularization 기법을 도입하여 noise와 비지도 앙상블 증류 과정에서 발생하는 문제를 완화시킵니다.

- **Performance Highlights**: TAKFL은 컴퓨터 비전(CV) 및 자연어 처리(NLP) 작업에서 종합적인 평가를 수행하였으며, 다양한 데이터셋과 설정에서 SOTA(State Of The Art) 결과를 달성하여 기존 KD 기반 방법들보다 월등한 성능을 보였습니다.



### Gradient-free Decoder Inversion in Latent Diffusion Models (https://arxiv.org/abs/2409.18442)
Comments:
          19 pages, Accepted to NeurIPS 2024

- **What's New**: 본 논문에서는 Latent Diffusion Models (LDMs)에서 효율적인 gradient-free decoder inversion 방법을 제안합니다. 이는 기존의 gradient 기반 방법이 요구하는 메모리와 시간을 대폭 줄이는 혁신적인 접근 방식입니다.

- **Technical Details**: 이 접근 방식은 다양한 latent 모델에 적용 가능하며, 이론적 수렴 특성을 연구하였습니다. 특히, forward step method와 inertial Krasnoselskii-Mann (KM) iteration을 분석하였으며, 최근 LDMs에 만족되는 완만한 코코어시비티(cocoercivity) 조건 하에 적용됩니다.

- **Performance Highlights**: Adam optimizer와 learning rate scheduling을 활용한 본 방법은 기존의 gradient 기반 방법보다 계산 시간과 메모리 소모를 획기적으로 줄였으며, noise-space watermarking과 같은 다양한 응용에서 효율적인 계산을 가능하게 하였습니다. 이로써 유사한 오류 수준을 유지하면서도 성능이 개선되었습니다.



### A3: Active Adversarial Alignment for Source-Free Domain Adaptation (https://arxiv.org/abs/2409.18418)
Comments:
          Accepted at ICMLA 2024

- **What's New**: 본 논문은 레이블이 없는 대상 도메인으로부터 지식을 전이하기 위해 레이블이 있는 출처 도메인에서 지식을 전이하는 비지도 도메인 적응(Unsupvised Domain Adaptation, UDA) 분야의 최신 동향인 Source-free UDA에 대한 새로운 접근법인 Active Adversarial Alignment (A3)를 제안합니다.

- **Technical Details**: A3는 self-supervised learning, adversarial training, 및 active learning을 결합하여 견고한 Source-free UDA를 가능하게 합니다. 이 프레임워크는 acquisition function을 사용하여 유익하고 다양한 데이터를 능동적으로 샘플링하고 모델을 adversarial losses와 consistency regularization을 통해 적응시킵니다. 이는 출처 데이터에 접근하지 않고도 분포를 정렬합니다.

- **Performance Highlights**: A3는 효과적인 도메인 정렬 및 노이즈 감소를 위해 능동적 및 적대적 학습의 시너지를 활용하여 Source-free UDA를 발전시킵니다.



### MultiClimate: Multimodal Stance Detection on Climate Change Videos (https://arxiv.org/abs/2409.18346)
Comments:
          5 pages, 1 figure

- **What's New**: 이번 연구에서는 기후 변화(Climate Change, CC)와 관련된 주장을 탐지하기 위한 첫 번째 공개 소스 수동 주석 데이터셋인 MultiClimate를 소개합니다. 이 데이터셋은 100개의 CC 관련 YouTube 비디오와 4,209개의 프레임-전사 쌍으로 구성되어 있습니다.

- **Technical Details**: MultiClimate는 다양한 비전(Vision) 및 언어(Language) 모델, 그리고 멀티모달(Multimodal) 모델을 사용하여 주장을 탐지합니다. 연구 결과, 텍스트 전용 BERT 모델이 이미지 전용 ResNet50 및 ViT 모델보다 현저히 우수한 성능을 보였습니다. 두 가지 모달리티를 결합할 경우, 정확도(Accuracy) 및 F1 점수에서 각각 0.747 및 0.749를 기록하며 최신 기술 수준(State-of-the-art)을 달성했습니다.

- **Performance Highlights**: 100M 크기의 융합(fusion) 모델이 CLIP, BLIP, 그리고 훨씬 더 큰 9B 크기의 멀티모달 IDEFICS 및 텍스트 전용 Llama3와 Gemma2보다 뛰어난 성능을 보였습니다. 이는 대형 언어 모델에 대해 멀티모달 주장 탐지가 여전히 도전적임을 나타냅니다.



### DRL-STNet: Unsupervised Domain Adaptation for Cross-modality Medical Image Segmentation via Disentangled Representation Learning (https://arxiv.org/abs/2409.18340)
Comments:
          MICCAI 2024 Challenge, FLARE Challenge, Unsupervised domain adaptation, Organ segmentation, Feature disentanglement, Self-training

- **What's New**: 본 논문에서는 cross-modality(크로스 모달리티) 의료 이미지 분할을 위한 새로운 프레임워크인 DRL-STNet을 제안합니다. 이 방법은 Generative Adversarial Networks(GANs), Disentangled Representation Learning(DRL), Self-Training(ST)를 활용합니다.

- **Technical Details**: DRL-STNet은 GAN 내에서 DRL을 이용하여 이미지를 소스 모달리티에서 타겟 모달리티로 변환합니다. 초기 단계에서는 변환된 이미지와 소스 레이블로 분할 모델을 학습한 후, 합성 이미지와 실제 이미지의 결합을 통해 pseudo-labels(의사 레이블) 및 실제 레이블로 반복적으로 미세 조정합니다.

- **Performance Highlights**: 제안된 DRL-STNet은 FLARE 도전 과제 데이터셋에서 복부 장기 분할에서 11.4% Dice similarity coefficient(다이스 유사도 계수) 및 13.1% Normalized Surface Dice metric(정규화된 표면 다이스 측정치) 향상을 보여 주며, 각각 74.21% 및 80.69%의 점수를 기록했습니다. 평균 실행 시간은 41초이며, GPU 메모리-시간 곡선 아래 면적은 11,292 MB입니다.



### Photon Inhibition for Energy-Efficient Single-Photon Imaging (https://arxiv.org/abs/2409.18337)
Comments:
          Accepted for ECCV 2024. Supplementary material and code available at this https URL

- **What's New**: 최근 등장한 단일광자 카메라(Single-Photon Cameras, SPCs)는 저조도, 높은 동적 범위, 빠른 움직임의 복잡한 이미지 분석에 유용하게 사용되고 있습니다. 하지만, 단일광자 눈금 다이오드(Single-Photon Avalanche Diode, SPAD)를 기반으로 한 SPC의 경우, 각 광자 감지 과정에서 소비되는 에너지가 복잡하다는 문제를 가지고 있습니다. 이 논문에서는 이 문제를 해결하기 위해 "photon inhibition"이라는 새로운 계산적 이미징(computational imaging) 접근 방식을 제안하고 있습니다.

- **Technical Details**: 이 연구에서는 photon inhibition을 통해 실제 SPAD 픽셀을 실시간으로 비활성화하여 가장 유용한 차기 광자를 선택하는 경량(on-sensor) 계산적 억제 정책을 개발했습니다. 이 정책은 다운스트림 추론 작업 목표 및 자원 제약에 따라 공간 및 시간 내에서 감지를 전략적으로 할당합니다.

- **Performance Highlights**: 시뮬레이션과 실제 SPC로 캡처한 데이터를 통해, 이미지 재구성 및 경계 감지 작업에 대한 맞춤형 정책을 설계하여 90
% 이상의 광자 감지 감소를 보였으나, 작업 성능 지표를 유지하는 성능을 시연했습니다. 이러한 결과는 에너지 효율적인 단일광자 이미징의 미래 가능성을 열어줍니다.



### Realistic Evaluation of Model Merging for Compositional Generalization (https://arxiv.org/abs/2409.18314)
- **What's New**: 본 논문에서는 다양한 merging 방법론의 상대적인 장점을 평가하고, 이를 통해 각 방법의 실제 요구 사항을 명확히 하였습니다. 특히, 이미지 분류(image classification), 이미지 생성(image generation), 자연어 처리(natural language processing) 분야에서의 compositional generalization을 위한 merging에 초점을 맞추었습니다.

- **Technical Details**: 연구는 다양한 merging 방법을 일관된 실험 환경에서 비교하였으며, 모델 아키텍처(model architecture), 데이터 가용성(data availability), 계산 예산(computational budget)에 대한 가정이 서로 다를 수 있음을 강조합니다. 또한, 각 merging 방법이 필요로 하는 계산 비용(computational costs)과 병합되는 모델 수가 증가할 때의 성능을 측정하였습니다.

- **Performance Highlights**: 연구 결과는 모델 병합(model merging) 분야의 현재 상태를 명확히 하고, 새로운 방법을 시험할 수 있는 포괄적이고 엄격한 실험 Setup을 제공합니다.



### Flat'n'Fold: A Diverse Multi-Modal Dataset for Garment Perception and Manipulation (https://arxiv.org/abs/2409.18297)
- **What's New**: Flat'n'Fold는 의류 조작을 위한 새로운 대규모 데이터셋으로, 기존 데이터셋의 중요한 격차를 해결합니다. 44개의 고유 의류 항목을 8개 카테고리에 걸쳐 총 1,212개의 인간과 887개의 로봇 시연으로 구성되어 있습니다.

- **Technical Details**: 이 데이터셋은 구겨진 상태에서 접힌 상태까지의 전체 조작 과정을 포착하며, 동기화된 다중 관점 RGB-D 이미지, 포인트 클라우드(point clouds), 그리고 손 또는 그리퍼(gripper) 위치 및 회전을 포함한 행동 데이터를 제공합니다. 이 데이터에 대한 다양성과 복잡성을 기존 기준과 비교하여 정량화하였습니다.

- **Performance Highlights**: Flat'n'Fold의 유용성을 보여주기 위해, 그리핑 포인트(prediction) 예측 및 하위 작업(subtask) 분해에 대한 새로운 기준을 설정했습니다. 이 작업에 대해 최첨단 모델을 평가한 결과, 개선이 필요한 부분이 많음을 확인했습니다. 이는 변형 가능한 객체의 로봇 인식과 조작 분야에서의 발전 가능성을 강조합니다.



### Synthesizing beta-amyloid PET images from T1-weighted Structural MRI: A Preliminary Study (https://arxiv.org/abs/2409.18282)
- **What's New**: 이번 연구에서는 T1-weighted MRI 스캔을 이용하여 3D diffusion models를 활용한 Aβ-PET 이미지를 합성하는 방안을 제시합니다. 이는 기존의 Aβ-PET 이미징의 제한된 사용을 극복하기 위한 시도로, 구조적 MRI를 대안으로 활용합니다.

- **Technical Details**: Aβ-PET 이미지는 알츠하이머병(AD)의 병리학적 특징인 아밀로이드 플라크의 축적을 나타내며, 본 연구에서는 고품질의 Aβ-PET 이미지를 생성하기 위해 3D diffusion models를 사용했습니다. Aβ 침착 패턴의 변동성 때문에 경도 인지 장애(MCI) 환자에 대해서는 효과가 덜하다는 한계를 지녔습니다.

- **Performance Highlights**: 인지가 정상인 경우에는 고품질의 Aβ-PET 이미지가 생성되었으나, MCI 환자에 대해서는 추가적인 데이터(예: MCI 사례의 샘플 수 증대 및 임상적, 인구통계적 정보, 인지 및 기능 평가, 종단적 데이터 포함)가 필요할 것으로 보입니다.



### Task-recency bias strikes back: Adapting covariances in Exemplar-Free Class Incremental Learning (https://arxiv.org/abs/2409.18265)
Comments:
          Accepted for NeurIPS 2024

- **What's New**: 본 논문에서는 과거 데이터에 접근할 수 없는 상황에서 모델을 훈련하는 Exemplar-Free Class Incremental Learning (EFCIL) 문제를 다룹니다. 기존의 최첨단 방법은 클래스들을 나타내기 위해 Gaussian 분포를 사용하지만, 두 가지 주요 문제로 인해 그 효과성이 제한됩니다.

- **Technical Details**: 첫 번째 문제는 각 클래스의 공분산 행렬(covariance matrices)이 변화하고 매 작업(task)마다 적응해야 한다는 점입니다. 두 번째 문제는 훈련 중 발생하는 차원 축소(dimensionality collapse)로 인한 작업 최신성(task-recency) 편향입니다. 본 연구에서는 AdaGauss라는 새로운 방법을 제안하여, 작업 간 공분산 행렬을 적응시키고 추가적인 anti-collapse 손실 함수(loss function)를 통해 작업 최신성 편향을 완화합니다.

- **Performance Highlights**: AdaGauss는 기존의 EFCIL 벤치마크(benchmarks) 및 데이터셋(datasets)에서 최상급 결과를 나타내며, 스크래치부터 훈련할 때나 사전 훈련(pre-trained)된 모델에서 시작할 때 모두 우수한 성과를 보여줍니다.



### Developing a Dual-Stage Vision Transformer Model for Lung Disease Classification (https://arxiv.org/abs/2409.18257)
Comments:
          3 pages, 3 figures, Applied to the IEEE MetroCon 2024 Conference

- **What's New**: 이번 연구에서는 폐 질환 진단을 위해 Vision Transformer (ViT)와 Swin Transformer를 통합한 이중 단계(dual-stage) 비전 트랜스포머 모델을 개발했습니다.

- **Technical Details**: 이 모델은 X-ray 스캔을 기반으로 14종의 폐 질환을 분류하며, 데이터 전처리와 신경망(neural network) 훈련 과정을 거친 후 계산된 정확도는 92.06%에 이릅니다.

- **Performance Highlights**: 제안된 모델은 폐 질환 분류 및 진단에 있어 높은 정확도를 보여주어 유망한 결과를 나타냈습니다.



### PNR: Physics-informed Neural Representation for high-resolution LFM reconstruction (https://arxiv.org/abs/2409.18223)
- **What's New**: 본 논문에서는 고해상도 Light Field Microscopy (LFM) 재구성을 위한 새로운 방법인 PNR (Physics-informed Neural Representation)을 소개합니다. PNR은 기존의 방법들보다 성능을 크게 향상시킵니다.

- **Technical Details**: PNR은 비지도학습(unsupervised) 및 명시적(feature representation) 접근 방식을 활용하여 RLD보다 PSNR에서 6.1 dB의 개선을 달성합니다. 또한, 고주파 정보 회복을 위한 주파수 기반(frequency-based) 훈련 손실(train loss)을 사용하며, 이로 인해 SOTA 방법들에 비해 LPIPS를 최소 절반으로 줄였습니다. PNR은 물리 기반의 변형 보정(aberration correction) 전략을 통합하여 최적화 과정에서 Zernike 다항식 파라미터를 최적화합니다.

- **Performance Highlights**: PNR은 복잡한 생물학적 시나리오에서도 높은 성능을 제공하며, 향후 고해상도 생물학적 이미징 응용에서 유망한 솔루션이 될 것입니다. 코드는 공개될 예정입니다.



### Learning to Drive via Asymmetric Self-Play (https://arxiv.org/abs/2409.18218)
Comments:
          ECCV 2024

- **What's New**: 본 연구에서는 실제 데이터에 의존하지 않고도 운전 정책을 학습할 수 있는 비대칭 자기 플레이(asymmetric self-play) 방법을 제안합니다. 이 방법은 도전적이고 현실적인 합성 시나리오(synthetic scenarios)를 활용하여 데이터 세트를 확장합니다.

- **Technical Details**: 비대칭 자기 플레이는 두 개의 에이전트로 구성되어 있으며, 하나는 시나리오를 생성하는 '교사(teacher)' 역할을 하고, 다른 하나는 그 시나리오를 해결하는 '학생(student)' 역할을 합니다. 이를 통해 운전 시뮬레이션에서 더 적은 충돌로 현실적인 정책을 학습합니다.

- **Performance Highlights**: 우리의 정책은 기존의 적대적 접근(adversarial approaches)이나 실제 데이터를 사용하는 방법에 비해 종합적으로 성능이 크게 향상되며, 특히 드문(long-tail) 시나리오에서도 우수한 결과를 보입니다.



### Toward Efficient Deep Blind RAW Image Restoration (https://arxiv.org/abs/2409.18204)
Comments:
          IEEE International Conference on Image Processing (ICIP) 2024. arXiv admin note: text overlap with arXiv:2312.15487

- **What's New**: 이 논문에서는 sRGB 도메인에서의 처리의 복잡성에도 불구하고, RAW 이미지에서 직접적으로 이미지 복원(image restoration)을 수행하는 새로운 방법을 제시하고 있습니다.

- **Technical Details**: 새로운 사실적 저하(degradation) 파이프라인을 설계하여, 심층 심각한 RAW 복원 모델(deep blind RAW restoration models)을 훈련합니다. 이 파이프라인은 사실적인 센서 노이즈(sensor noise), 모션 블러(motion blur), 카메라 흔들림(camera shake) 및 기타 일반적인 저하를 고려합니다.

- **Performance Highlights**: 본 연구에서 훈련된 모델은 여러 센서의 데이터를 사용하여 noise와 blur을 성공적으로 줄이고, 다양한 카메라로 촬영된 RAW 이미지의 세부사항을 복원할 수 있습니다.



### FlowTurbo: Towards Real-time Flow-Based Image Generation with Velocity Refiner (https://arxiv.org/abs/2409.18128)
Comments:
          Accepted to NeurIPS 2024

- **What's New**: 이 논문에서는 흐름 기반 생성 모델의 샘플링 속도를 가속화하면서 샘플링 품질을 향상시키는 FlowTurbo라는 새로운 프레임워크를 제안합니다.

- **Technical Details**: FlowTurbo는 샘플링 중 속도 예측기가 안정적이라는 사실을 이용하여 경량화된 속도 정제기를 통해 속도를 추정합니다. 추가로, pseudo corrector 및 sample-aware compilation 기법을 통해 추론 시간을 단축합니다. 이 프레임워크는 다단계 샘플링 패러다임을 변경하지 않으며 이미지 편집이나 인페인팅과 같은 다양한 작업에 효과적으로 적용할 수 있습니다.

- **Performance Highlights**: FlowTurbo를 다양한 흐름 기반 모델에 통합함으로써 클래스 조건 생성에서 53.1%~58.3%의 가속 비율을 달성하였으며, 텍스트-이미지 생성에서는 29.8%~38.5%의 가속을 이뤘습니다. ImageNet에서 FlowTurbo는 100 (ms / img) 당 FID 2.12, 38 (ms / img)에서 FID 3.93을 기록하며 실시간 이미지 생성을 가능하게 했습니다.



### EgoLM: Multi-Modal Language Model of Egocentric Motions (https://arxiv.org/abs/2409.18127)
Comments:
          Project Page: this https URL

- **What's New**: 최근 웨어러블 장치의 보급으로, 인공지능(AI)의 맥락적 이해를 위한 에고센트릭(egocentric) 동작 학습이 필수적입니다. 이 논문에서는 다중 모달(multi-modal) 입력(예: 에고센트릭 비디오와 모션 센서)을 통해 에고센트릭 동작을 추적하고 이해하는 새로운 프레임워크인 EgoLM을 제시합니다.

- **Technical Details**: EgoLM은 두 가지 주요 작업인 에고센트릭 모션 추적(egocentric motion tracking)과 이해(understanding)를 통합하여 다루며, 이를 위해 대규모 언어 모델(large language model, LLM)을 활용하여 에고센트릭 모션과 자연어의 결합 분포(joint distribution)를 모델링합니다. 또한, 모션 센서 데이터와 에고센트릭 비디오를 결합하여 서로 다른 입력을 통합하고, 다중 작업(multi-task) 교육을 통해 효과를 극대화합니다.

- **Performance Highlights**: EgoLM을 대규모 인체 모션 데이터셋인 Nymeria에서 실험한 결과, 기존 모션 추적 및 이해 방법과 비교하여 가장 우수한 성능을 보였습니다. 이 프레임워크는 에고센트릭 학습에 대한 통합적인 접근 방식을 제시하며, 특히 에고센트릭 비디오와 희소(유한) 센서 데이터를 결합한 새로운 설정이 주목받고 있습니다.



### LLaVA-3D: A Simple yet Effective Pathway to Empowering LMMs with 3D-awareness (https://arxiv.org/abs/2409.18125)
Comments:
          Project page: this https URL

- **What's New**: 최근 Large Multimodal Models (LMMs)의 발전이 2D 시각 이해 작업에서의 능력을 크게 향상시켰습니다. 그러나 3D 장면 이해를 위한 3D 인식 모델 개발은 대규모 3D 시각-언어 데이터세트의 부족과 강력한 3D 인코더의 결여로 제약을 받아왔습니다. 본 논문에서 소개된 LLaVA-3D 프레임워크는 2D 이해 능력을 유지하면서 3D 장면 이해를 효율적으로 적응시킬 수 있는 혁신적인 접근 방식입니다.

- **Technical Details**: LLaVA-3D는 간단하지만 효과적인 3D Patch 표현을 도입하여 2D CLIP 패치 특징을 3D 공간의 해당 위치와 연결합니다. 이 방법은 2D LMM에 3D 패치를 통합하고 2D 및 3D 비전-언어 명령 튜닝을 공동으로 수행하여 2D 이미지 이해와 3D 장면 이해를 위한 통합 아키텍처를 생성합니다. 이 모델은 3D 비전-언어 데이터세트에서 훈련된 후, 기존 3D LMM보다 3.5배 빠르게 수렴하여 고도로 효율적인 성능을 보입니다.

- **Performance Highlights**: LLaVA-3D는 3D 캡션 생성, 3D 질문 응답, 3D 그라운딩 등의 다양한 3D 작업에서 최첨단 성능을 달성하였으며, 기존 3D LMM보다 훈련 시간과 에폭 수가 현저히 적습니다. 또한 LLaVA와 비교할 때 2D 이미지 이해 및 언어 대화 능력 또한 유사하게 유지됩니다.



### Lotus: Diffusion-based Visual Foundation Model for High-quality Dense Prediction (https://arxiv.org/abs/2409.18124)
Comments:
          Project page: this https URL

- **What's New**: 본 논문에서는 기존의 diffusion 모델이 dense prediction 작업에 적합하지 않다는 문제를 인식하고, 새로운 접근법인 Lotus 모델을 제안하며 기존 모델 대비 효율성과 성능이 월등히 향상된 결과를 보여줍니다.

- **Technical Details**: Lotus는 noise 예측 대신 직접적인 주석 예측을 통해 모델의 해석을 개선하며, 하나의 단계로 단순화된 diffusion 과정을 도입하여 훈련과 추론 속도를 크게 향상시킵니다. 또한, 'detail preserver'라는 새로운 튜닝 전략을 통해 세밀한 예측을 더 정확하게 수행할 수 있게 합니다.

- **Performance Highlights**: Lotus는 zero-shot monocular depth 및 surface normal estimation에서 SoTA (state-of-the-art) 성능을 달성하였으며, 기존 디퓨전 기반 방법들에 비해 수백 배 빨라 효율성을 극대화했습니다. 이 모델은 59K의 훈련 샘플로도 놀라운 성능을 발휘합니다.



### Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography (https://arxiv.org/abs/2409.18119)
Comments:
          This work is also the basis of the overall best solution for the MICCAI 2024 CXR-LT Challenge

- **What's New**: 이 연구는 의료 영상 분야에서 Contrastive Language-Image Pre-training (CLIP) 모델의 초기 적응을 유방 촬영술에 적용하고, 데이터 부족과 고해상도 이미지의 세부 사항 강조를 해결하기 위한 새로운 접근 방식을 제안합니다.

- **Technical Details**: 제안하는 방법은 Multi-view와 Multi-scale Alignment (MaMA)를 기반으로 하며, 각 관점에서 정보를 활용하여 multi-view mammography의 특징을 동시에 정렬하는 시스템을 구축합니다. 또한, clinical report 부족 문제를 해결하기 위해 template-based report construction 방식을 개발하고, parameter-efficient fine-tuning 기법을 적용합니다.

- **Performance Highlights**: EMBED 및 RSNA-Mammo의 대규모 실제 유방촬영 데이터셋에서 3개의 다른 작업에 대해 기존 방법보다 우수한 성능을 보여주었으며, 모델 크기의 52%만으로도 뛰어난 성과를 달성했습니다.



### EdgeRunner: Auto-regressive Auto-encoder for Artistic Mesh Generation (https://arxiv.org/abs/2409.18114)
Comments:
          Project Page: this https URL

- **What's New**: 이 논문에서는 고품질 3D 메쉬 생성을 위한 자동 회귀 자동 인코더(ArAE) 모델을 제안합니다. ArAE 모델은 4,000개 면(면)을 가진 메쉬를 $512^3$의 공간 해상도로 생성할 수 있으며, 새로운 메쉬 토큰화 알고리즘을 도입하여 훈련 효율성을 크게 향상시킵니다.

- **Technical Details**: 제안된 방법인 EdgeRunner는 50%의 시퀀스 길이 압축과 토큰 간의 장거리 의존성 감소를 통해 훈련 효율성을 크게 개선합니다. ArAE는 가변 길이의 삼각형 메쉬를 고정 길이의 잠재 벡터로 압축하며, 이 잠재 공간은 다른 모달리티에 조건화된 잠재 확산 모델을 훈련하는 데 사용될 수 있습니다.

- **Performance Highlights**: 실험 결과, EdgeRunner는 4,000개의 면을 가진 다양한 고품질 아티스틱 메쉬를 생성할 수 있으며, 이전 방법에 비해 두 배 긴 시퀀스와 네 배 높은 해상도를 자랑합니다. 이는 포인트 클라우드 또는 단일 뷰 이미지에서 생성된 메쉬에 대해 뛰어난 일반화 및 강인성을 보여줍니다.



### E.T. Bench: Towards Open-Ended Event-Level Video-Language Understanding (https://arxiv.org/abs/2409.18111)
Comments:
          Accepted to NeurIPS 2024 Datasets and Benchmarks Track

- **What's New**: 최근의 Video Large Language Models (Video-LLMs)와 더불어 E.T. Bench (Event-Level & Time-Sensitive Video Understanding Benchmark)의 도입으로 비디오 이해의 새로운 기준이 세워졌습니다. 이 벤치마크는 현재 존재하는 평가 방식의 한계를 극복하고, 이벤트 레벨의 비디오 이해를 위한 고유한 과제를 제시합니다.

- **Technical Details**: E.T. Bench는 7,300개의 샘플과 12개의 과제로 구성된 대규모 벤치마크로, 8개 도메인에서 7,000개의 비디오(총 251.4시간)를 포함합니다. 이 벤치마크는 3단계 작업 분류법으로 범주화되어 있으며, 참조(referring), 그라운딩(grounding), 밀집 캡션(dense captioning), 복잡한 이해(complex understanding)라는 4가지 주요 기능을 통해 비디오를 평가합니다.

- **Performance Highlights**: 기존 비디오 QA 벤치마크에서 선도적인 모델들은 E.T. Bench에서의 세밀한 과제를 해결하는 데 어려움을 겪었습니다. 특히, E.T. Chat이라는 새로운 모델이 제안되었으며, 이는 타임스탬프 예측을 임베딩 매칭 문제로 재정의함으로써 우수한 성능을 입증했습니다. E.T. Instruct 164K라는 맞춤형 데이터 세트 또한 다중 이벤트와 시간 민감 시나리오를 위해 개발되었습니다.



### Find Rhinos without Finding Rhinos: Active Learning with Multimodal Imagery of South African Rhino Habitats (https://arxiv.org/abs/2409.18104)
Comments:
          9 pages, 9 figures, IJCAI 2023 Special Track on AI for Good

- **What's New**: 이 연구는 코뿔소 보호를 위한 새로운 접근 방식을 제안하고 있으며, 코뿔소의 집단 배변 장소를 지도화하는 것을 통해 이들의 공간 행동에 대한 정보를 수집할 수 있는 방법을 모색하고 있다.

- **Technical Details**: 이 논문은 원거리에서 감지된 열 감지(thermal), RGB, LiDAR 이미지를 사용하여 코뿔소 배변 장소를 탐지하는 분류기를 구축하고, 수동적 및 능동적 학습 설정에서 이를 수행한다. 특히, 기존 능동 학습 방법들이 지극히 불균형한 데이터셋의 문제로 성능이 저하되는 문제를 해결하기 위해, MultimodAL이라고 불리는 새로운 능동 학습 시스템을 설계하였다.

- **Performance Highlights**: 제안된 방법은 94% 감소된 라벨 수로 수동적 학습 모델과 경쟁력을 갖추며, 유사한 크기의 데이터셋에 적용할 경우 라벨링 시간에서 76시간 이상을 절약할 수 있는 것으로 나타났다. 또한, 연구 결과 배변 장소가 무작위 분포가 아니라 클러스터 형태로 밀집해 있다는 점을 발견하여, 이에 따라 기동대(rangers) 활동의 효율성을 높이기 위한 방안을 제시하고 있다.



### AI-Powered Augmented Reality for Satellite Assembly, Integration and Tes (https://arxiv.org/abs/2409.18101)
- **What's New**: 이번 논문은 인공지능(AI)과 증강현실(AR)의 통합을 통해 위성 조립, 통합 및 테스트(AIT) 프로세스를 혁신하려는 유럽우주청(ESA)의 프로젝트 "AI for AR in Satellite AIT"에 대해 설명합니다. 이 시스템은 Microsoft HoloLens 2를 사용하여 기술자에게 실시간으로 맥락에 맞는 지침과 피드백을 제공합니다.

- **Technical Details**: AI4AR 시스템은 컴퓨터와 AR 헤드셋으로 구성되어 있으며, 객체 감지 및 추적, 6D 포즈 추정과 OCR을 포함한 다양한 컴퓨터 비전 알고리즘을 이용합니다. 특히, 6D 포즈 모델 훈련에 합성 데이터를 사용하는 접근법이 독창적이며, 이는 AIT 프로세스의 복잡한 환경에서 유용합니다.

- **Performance Highlights**: AI 모델의 정확도가 70%를 넘었고, 객체 감지 모델은 95% 이상의 정확도를 기록했습니다. 자동 주석화 기능을 가진 Segmented Anything Model for Automatic Labelling(SAMAL)을 통해 실제 데이터의 주석화 속도가 수동 주석화보다 최대 20배 빨라졌습니다.



### Self-supervised Pretraining for Cardiovascular Magnetic Resonance Cine Segmentation (https://arxiv.org/abs/2409.18100)
Comments:
          Accepted to Data Engineering in Medical Imaging (DEMI) Workshop at MICCAI 2024

- **What's New**: 이번 연구는 Self-supervised pretraining (SSP) 방법이 Cardiovascular Magnetic Resonance (CMR) short-axis cine segmentation에서 어떻게 효용성을 가지는지를 평가하고 있으며, 대규모 무라벨 데이터셋을 활용하는 가능성을 탐구합니다.

- **Technical Details**: 본 연구에서는 SimCLR, positional contrastive learning, DINO 및 masked image modeling (MIM) 등 4가지 SSP 방법을 사용하여 296명의 연구대상에서 총 90,618개의 2D 슬라이스를 통한 무라벨 프리트레이닝을 진행했습니다. 이후 여러 수의 레이블이 있는 데이터를 통해 각 SSP 방법으로 2D 모델의 파인튜닝을 수행하여 baseline 모델과 성능을 비교했습니다.

- **Performance Highlights**: 결과적으로, 레이블 데이터가 충분하지 않은 경우, MIM을 사용한 SSP는 0.86의 DSC를 기록하며 무라벨로부터 학습한 모델보다 개선된 결과를 보였습니다. 반면에, 충분한 레이블 데이터가 있을 경우 SSP는 성능 향상을 보이지 않았습니다.



### EfficientCrackNet: A Lightweight Model for Crack Segmentation (https://arxiv.org/abs/2409.18099)
- **What's New**: 본 연구에서는 Convolutional Neural Networks (CNNs)와 transform architecture를 결합한 EfficientCrackNet이라는 경량 하이브리드 모델을 제안합니다. 이 모델은 정밀한 균열(segmentation) 감지를 위해 설계되었으며, 높은 정확도와 낮은 계산 비용을 동시에 제공합니다.

- **Technical Details**: EfficientCrackNet 모델은 depthwise separable convolutions (DSC)와 MobileViT block을 통합하여 전역 및 지역 특성을 캡처합니다. Edge Extraction Method (EEM)를 사용하여 사전 훈련 없이도 효율적인 균열 가장자리 감지를 수행하며, Ultra-Lightweight Subspace Attention Module (ULSAM)을 통해 특성 추출을 향상합니다.

- **Performance Highlights**: 세 개의 벤치마크 데이터셋(Crack500, DeepCrack, GAPs384)을 기반으로 한 광범위한 실험에 따르면, EfficientCrackNet은 단 0.26M의 파라미터와 0.483 FLOPs(G)만으로 기존의 경량 모델들보다 우수한 성능을 보였습니다. 이 모델은 정확성과 계산 효율성 간의 최적의 균형을 제공하여 실제 균열 분할 작업에 강력하고 적응 가능한 솔루션을 제공합니다.



### DiffSSC: Semantic LiDAR Scan Completion using Denoising Diffusion Probabilistic Models (https://arxiv.org/abs/2409.18092)
Comments:
          Under review

- **What's New**: 이 논문에서는 자율 주행 차량을 위한 Semantic Scene Completion (SSC) 작업을 다루고 있으며, LiDAR(빛 감지 및 범위 측정) 센서로부터 얻는 드문 드로우 포인트 클라우드의 빈 공간과 폐쇄된 지역을 예측할 수 있는 방안을 제시합니다.

- **Technical Details**: 제안된 DiffSSC 방법론은 Denoising Diffusion Probabilistic Models (DDPM)을 기반으로 하여 점진적인 노이즈 제거를 통해 LiDAR 점 클라우드를 처리합니다. 이 과정에서는 기하학 및 의미적 정보가 동시에 모델링되며, 로컬과 글로벌 정규화 손실을 통해 학습 과정을 안정화합니다.

- **Performance Highlights**: 제안된 방법은 자율 주행 데이터셋에서 기존의 최첨단 SSC 방법보다 우수한 성능을 보이며, LiDAR 점 클라우드 처리에서 메모리 사용량 및 양자화 오류를 줄이는 데 성공했습니다.



### Stable Video Portraits (https://arxiv.org/abs/2409.18083)
Comments:
          Accepted at ECCV 2024, Project: this https URL

- **What's New**: 본 논문에서는 2D와 3D를 혼합한 새로운 생성 방법인 SVP(Stable Video Portraits)를 제시합니다. 이 방법은 대규모 사전 훈련된 텍스트-투-이미지 모델(Stable Diffusion)과 3D Morphable Models (3DMM)을 활용하여 대화하는 얼굴의 포토리얼리스틱한 비디오를 생성합니다.

- **Technical Details**: SVP는 2D 안정적 확산 모델에 대한 개인화된 미세 조정을 통해 3DMM 시퀀스를 조건으로 제공하고, 시간적 노이즈 제거 절차를 도입하여 비디오 모델로 전환합니다. 이 결과로, 3DMM 기반 제어를 통해 3D 형태의 아바타 이미지를 생성하고, 테스트 시 텍스트에 정의된 유명인사로 아바타의 얼굴을 변형할 수 있는 기능을 포함합니다.

- **Performance Highlights**: SVP 방법은 최신 모노큘러 헤드 아바타 방법보다 우수한 성능을 보이고 있으며, 고충실도의 인체 얼굴 이미지를 세밀하게 재구성하는 능력에서 특히 뛰어납니다. 8분 이상의 비디오 시퀀스를 포함한 포트레이트 아바타 데이터셋도 제공됩니다.



### FreeEdit: Mask-free Reference-based Image Editing with Multi-modal Instruction (https://arxiv.org/abs/2409.18071)
Comments:
          14 pages, 14 figures, project website: this https URL

- **What's New**: 본 논문에서는 사용자가 지정한 시각적 개념을 기반으로 한 이미지 편집을 가능하게 하는 FreeEdit라는 새로운 접근법을 제안합니다. 이 방법은 사용자가 제공한 언어 명령을 통해 참조 이미지를 효과적으로 재현할 수 있도록 합니다.

- **Technical Details**: FreeEdit는 다중 모달 instruction encoder를 활용하여 언어 명령을 인코딩하고, 이를 기반으로 편집 과정을 안내합니다. Decoupled Residual ReferAttention (DRRA) 모듈을 통해 참조 이미지에서 추출한 세밀한 특성을 이미지 편집 과정에 효과적으로 통합합니다. 또한, FreeBench라는 고품질 데이터셋을 구축하였으며, 이는 원본 이미지, 편집 후 이미지 및 참조 이미지를 포함하여 다양한 편집 태스크를 지원합니다.

- **Performance Highlights**: FreeEdit는 객체 추가 및 교체와 같은 참고 기반 이미지 편집 작업에서 기존 방법보다 우수한 성능을 보이며, 수동 편집 마스크를 필요로 하지 않아 사용의 편리함을 크게 향상시킵니다. 실험을 통해 얻은 결과는 FreeEdit가 고품질 제로샷(zero-shot) 편집을 달성하고, 편리한 언어 명령으로 사용자 요구를 충족할 수 있음을 보여줍니다.



### LightAvatar: Efficient Head Avatar as Dynamic Neural Light Field (https://arxiv.org/abs/2409.18057)
Comments:
          Appear in ECCV'24 CADL Workshop. Code: this https URL

- **What's New**: 본 논문에서는 Neural Light Fields (NeLFs)를 기반으로 한 최초의 헤드 아바타 모델인 LightAvatar를 제안합니다. 이 모델은 메쉬(mesh)나 볼륨 렌더링(volume rendering)을 사용하지 않으면서도 고품질 이미지를 효율적으로 렌더링할 수 있습니다.

- **Technical Details**: LightAvatar는 3DMM 파라미터와 카메라 포즈를 입력으로 받아 단일 네트워크의 사전 통과(forward pass)를 통해 이미지를 렌더링합니다. 이를 통해 NeRF의 수백 번의 네트워크 통과를 줄여 렌더링 속도를 크게 향상시켰습니다. 또한, 지식 증류(distillation)를 활용하여 학습 안정성을 높이고, 실 데이터에서의 적합 오류를 보정하기 위한 워핑 필드 네트워크를 도입하였습니다.

- **Performance Highlights**: LightAvatar는 상업용 GPU (RTX3090)에서 512x512 해상도로 174.1 FPS의 성능을 보여주며, 기존 NeRF 기반 아바타들보다 훨씬 빠른 속도로 고품질 이미지를 생성할 수 있습니다.



### Visual Data Diagnosis and Debiasing with Concept Graphs (https://arxiv.org/abs/2409.18055)
- **What's New**: CONBIAS는 비주얼 데이터셋의 Concept co-occurrence Biases를 진단하고 완화하기 위해 개발된 새로운 프레임워크입니다. 이는 비주얼 데이터셋을 지식 그래프(knowledge graph)로 표현하여 편향된 개념의 동시 발생을 분석하고 이를 통해 데이터셋의 불균형을 파악합니다.

- **Technical Details**: CONBIAS 프레임워크는 세 가지 주요 단계로 이루어져 있습니다: (1) Concept Graph Construction: 데이터셋에서 개념의 지식 그래프를 구축합니다. (2) Concept Diagnosis: 생성된 지식 그래프를 분석하여 개념 불균형을 진단합니다. (3) Concept Debiasing: 그래프 클리크(clique)를 사용해 불균형한 개념 조합을 샘플링하고 이에 대한 이미지를 생성하여 데이터셋을 보완합니다. 이 과정에서 대규모 언어 모델의 의존성을 줄였습니다.

- **Performance Highlights**: CONBIAS를 기반으로 한 데이터 증강(data augmentation) 방법이 여러 데이터셋에서 일반화 성능을 향상시키는 데 성공적임을 보여줍니다. 기존의 최첨단 방법들과 비교했을 때, 균형 잡힌 개념 분포에 기반한 데이터 증강이 분류기의 전반적인 성능을 개선시킴을 실험을 통해 입증하였습니다.



### Revisit Anything: Visual Place Recognition via Image Segment Retrieva (https://arxiv.org/abs/2409.18049)
Comments:
          Presented at ECCV 2024; Includes supplementary; 29 pages; 8 figures

- **What's New**: 이번 연구에서는 Embodied agents가 시각적으로 장소를 인식하고 이동하는 데 있어 중요한 문제를 다루었습니다. 전체 이미지를 사용하는 기존 방법 대신, 이미지의 '세그먼트'를 인코딩하고 검색하는 새로운 접근 방식을 제안합니다. 이를 통해 SuperSegment라는 새로운 이미지 표현을 생성하여 장소 인식을 향상시킵니다.

- **Technical Details**: 제안된 SegVLAD는 Open-set 이미지 분할(open-set image segmentation)을 통해 이미지를 의미있는 요소(entities)로 분해합니다. 각 아이템은 SuperSegments로 연결되어 구조화됩니다. 새로 제안된 Feature aggregation 방법을 사용하여 이 SuperSegments를 효율적으로 컴팩트한 벡터 표현으로 인코딩합니다. SegVLAD는 다양한 벤치마크 데이터셋에서 기존의 방법보다 높은 인식 리콜을 기록했습니다.

- **Performance Highlights**: SegVLAD는 다양한 VPR 벤치마크 데이터셋에서 최첨단 성능을 달성했습니다. IOU 기반 필터링을 통해 중복성을 줄이고 스토리지를 절약하며, 전체 이미지 기반 검색보다 더욱 뛰어난 성능을 보입니다. 연구 결과, SegVLAD는 이미지 인코더의 특정 작업에 관계없이 적용 가능하고, 객체 인스턴스 검색(object instance retrieval) 과제를 평가하여 '무언가를 재방문(revisit anything)'할 수 있는 잠재력을 보여주었습니다.



### IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning (https://arxiv.org/abs/2409.18046)
Comments:
          Accepted to EMNLP 2024

- **What's New**: 최근 이미지 캡셔닝(image captioning) 분야에서 이미지-텍스트 데이터 쌍의 한계를 극복하기 위해 텍스트-전용(training) 교육 방법이 탐색되고 있습니다. 본 논문에서는 텍스트 데이터와 이미지 데이터 간의 모달리티 차이를 완화하기 위한 새로운 접근 방식으로 'Image-like Retrieval'을 제안합니다.

- **Technical Details**: 제안된 방법인 IFCap($\textbf{I}$mage-like Retrieval과 $\textbf{F}$requency-based Entity Filtering for Zero-shot $\textbf{Cap}$tioning)는 효율적인 이미지 캡셔닝을 위한 통합 프레임워크로, Fusion Module을 통해 검색된 캡션과 입력 특성을 통합하여 캡션 품질을 향상시킵니다. 또한 Frequency-based Entity Filtering 기술을 도입하여 더 나은 캡션 품질을 제공합니다.

- **Performance Highlights**: 광범위한 실험 결과, IFCap은 기존의 텍스트-전용 훈련 기반 제로샷 캡셔닝(zero-shot captioning) 방식에 비해 이미지 캡셔닝과 비디오 캡셔닝 모두에서 state-of-the-art 성능을 기록하는 것으로 나타났습니다.



### EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions (https://arxiv.org/abs/2409.18042)
Comments:
          Project Page: this https URL

- **What's New**: EMOVA(EMotionally Omni-present Voice Assistant)는 음성 대화에서 다양한 감정과 톤을 지원하며, 최첨단 비전-언어(vision-language) 및 음성(speech) 능력을 결합한 최초의 옴니모달(omni-modal) LLM입니다. 이 모델은 기존 비전-언어 및 음성-언어 모델의 한계를 극복하고, 실시간 대화의 요구를 충족합니다.

- **Technical Details**: EMOVA는 연속 비전 인코더와 의미-음향 분리된 음성 토크나이저를 사용하여 음성 이해 및 생성을 위한 엔드투엔드(end-to-end) 아키텍처를 갖추고 있습니다. 이를 통해 입력 음성의 의미적 내용과 음향적 스타일을 분리하여 다양한 음성 스타일 조절을 지원합니다.

- **Performance Highlights**: EMOVA는 첫 번째로 비전-언어 및 음성 벤치마크에서 최첨단 성능을 달성하였으며, 공공 데이터셋을 활용하여 옴니모달 정렬을 효율적으로 수행하고, 생생한 감정을 담은 음성 대화를 지원합니다.



### ReliOcc: Towards Reliable Semantic Occupancy Prediction via Uncertainty Learning (https://arxiv.org/abs/2409.18026)
Comments:
          Technical report. Work in progress

- **What's New**: 본 연구에서는 카메라 기반의 시맨틱 점유 예측(semantic occupancy prediction) 모델의 신뢰성(reliability)을 평가하고, 이를 개선하기 위한 새로운 방법인 ReliOcc를 제안합니다. 지금까지 LiDAR(라이다)와 비교하여 카메라 모델의 정확도는 개선되었지만, 신뢰성 측면에서는 여전히 큰 격차가 존재합니다.

- **Technical Details**: ReliOcc는 기존의 모델에 플러그 앤 플레이(plug-and-play) 방식으로 통합될 수 있는 방법으로, 개별 복셀(voxel)의 하이브리드 불확실성(hybrid uncertainty)과 샘플링 기반의 노이즈를 혼합 학습(mix-up learning)을 통해 결합합니다. 또한, 오프라인 모드에서 모델 신뢰성을 강화하기 위한 불확실성 인식 보정 전략(uncertainty-aware calibration strategy)을 제공합니다.

- **Performance Highlights**: 다양한 실험 설정에서 ReliOcc는 모델의 신뢰성을 상당히 향상시키면서 정의 기하학 및 시맨틱 예측의 정확성을 유지하는 데 성공하였습니다. 특히, 제안된 방법은 센서 고장 및 도메인 외 노이즈(out of domain noises)에도 강인성을 보였습니다.



### Transferring disentangled representations: bridging the gap between synthetic and real images (https://arxiv.org/abs/2409.18017)
- **What's New**: 이 연구는 합성 데이터(synthetic data)를 사용하여 실제 데이터에 적용 가능한 일반 목적의 분리 표현(disentangled representation)을 학습할 가능성을 탐구합니다. 이 과정에서 성능을 향상시키기 위한 미세 조정(fine-tuning)의 효과와 전이(transfer) 후 보존되는 분리 특성에 대해 논의합니다.

- **Technical Details**: 본 연구에서는 OMES (Overlap Multiple Encoding Scores)라는 새로운 간섭 기반(intervention-based) 지표를 제안하여, 표현에서 인코딩된 요소들의 품질을 측정합니다. 이는 기존의 분류기(classifier) 의존적인 방법들과는 달리, 분류기 없는(intervention-based) 접근을 채택하여 요소의 분포를 분석하며, 데이터를 쌍으로 매칭하여 단일 요소만 다르게 하여 평가합니다.

- **Performance Highlights**: 연구 결과, 합성 데이터에서 학습된 표현을 실제 데이터로 전이할 수 있는 가능성이 있으며, 일부 분리 수준이 효과적임을 보여줍니다. 특히, 다양한 (Source, Target) 쌍에 대한 실험을 통해 학습된 DR의 표현력이 잘 평가됨을 확인하였습니다.



### InterNet: Unsupervised Cross-modal Homography Estimation Based on Interleaved Modality Transfer and Self-supervised Homography Prediction (https://arxiv.org/abs/2409.17993)
- **What's New**: 본 논문에서는 InterNet이라는 새로운 비지도 방식의 교차 모달 호모그래피(모드의 전환) 추정 프레임워크를 제안합니다. 이 방법은 모달리티 전이(modality transfer)와 자기 감독(self-supervised) 호모그래피 예측을 기반으로 하며, 혁신적인 상호 최적화(interleaved optimization) 프레임워크를 도입하여 두 구성 요소를 순차적으로 개선하는 방식을 사용합니다.

- **Technical Details**: InterNet은 서로 다른 모달리티의 이미지 간의 호모그래피를 추정하기 위해 설계되었습니다. 이 네트워크는 모달리티 전이 모듈과 호모그래피 추정 모듈로 구성되어 있으며, 두 모듈을 교차로 훈련하여 모달리티 간의 격차를 줄이는 방식으로 동작합니다. 또한, 정밀 호모그래피 특징 손실(fine-grained homography feature loss)을 도입하여 두 모듈 간의 상호작용을 강화하고, 간단하지만 효과적인 증류 훈련(distillation training) 기법을 적용해 모델 파라미터를 줄이고 교차 도메인 일반화 능력을 향상시킵니다.

- **Performance Highlights**: 실험 결과, InterNet은 다양한 데이터셋에서 최신 비지도 방식 중에서 최상의 성능을 달성하며, MHN과 LocalTrans와 같은 많은 지도 방식보다 더 높은 성능을 기록했습니다. InterNet은 GoogleMap과 WHU-OPT-SAR 데이터셋에서 각각 MHN보다 54.3% 및 47.4%, LocalTrans보다 61.8% 및 85.8% 낮은 평균 코너 오차(MACEs)를 달성하였습니다.



### Deblur e-NeRF: NeRF from Motion-Blurred Events under High-speed or Low-light Conditions (https://arxiv.org/abs/2409.17988)
Comments:
          Accepted to ECCV 2024. Project website is accessible at this https URL. arXiv admin note: text overlap with arXiv:2006.07722 by other authors

- **What's New**: 본 연구에서는 이벤트 카메라의 Motion Blur를 효과적으로 처리할 수 있는 새로운 방법인 Deblur e-NeRF를 제안합니다. 이 방법은 고속 또는 저조도 조건에서 생성된 Motion-blurred 이벤트를 기반으로 최소 블러의 Neural Radiance Fields (NeRF)를 직접 복원하는 것을 목표로 합니다.

- **Technical Details**: Deblur e-NeRF의 핵심 구성 요소는 임의의 속도와 조명 조건에서 이벤트 Motion Blur를 고려하는 물리적으로 정확한 픽셀 대역폭 모델입니다. 이 모델은 이벤트 생성 모델의 일부로 통합되어 블러가 최소화된 NeRF 복원을 지원하며, 새로운 임계값 정규화된 총 변동 손실(threshold-normalized total variation loss)을 도입하여 큰 텍스처 없는 패치를 더 잘 정규화합니다.

- **Performance Highlights**: 실제로 검증된 실험과 현실적으로 시뮬레이션된 시퀀스를 통해 Deblur e-NeRF의 효과성을 확인하였습니다. 더불어, 연구에 사용된 코드, 이벤트 시뮬레이터 및 합성 이벤트 데이터 세트는 오픈 소스로 제공됩니다.



### LLM4Brain: Training a Large Language Model for Brain Video Understanding (https://arxiv.org/abs/2409.17987)
Comments:
          ECCV2024 Workshop

- **What's New**: 본 연구에서는 LLM(대형 언어 모델)을 기반으로 한 접근 방식으로, 비디오 자극으로 유발된 fMRI(기능적 MRI) 신호로부터 시각-의미 정보를 재구성하는 방법을 소개합니다. 특히, 우리는 fMRI 인코더에 적응기를 장착하여 뇌 반응을 비디오 자극과 정렬된 잠재 표현으로 변환합니다.

- **Technical Details**: 제안된 방법은 두 단계의 훈련 프로세스를 사용합니다: Stage I은 fMRI와 비디오 데이터 간의 교차 모드 정렬을 배우고, Stage II는 감독된 지침 파인튜닝입니다. 첫 번째 단계에서는 CLIP 손실을 사용하여 fMRI 및 비디오 임베딩 간의 정렬을 학습합니다.

- **Performance Highlights**: 우리는 제안된 방법이 다양한 정량적 의미 메트릭을 사용하여 우수한 결과를 달성했으며, 진실 정보와의 유사성을 나타낸다는 것을 강조합니다. 또한, 우리의 방법은 다양한 자극 및 개인에 대해 좋은 일반화 능력을 보여줍니다.



### BlinkTrack: Feature Tracking over 100 FPS via Events and Images (https://arxiv.org/abs/2409.17981)
- **What's New**: BlinkTrack는 이벤트 데이터와 RGB 이미지를 통합하여 고주파수 피쳐 트래킹을 위한 새로운 프레임워크입니다. 이 방법은 Kalman 필터를 학습 기반 프레임워크로 확장하여 동기화되지 않은 잠재적 오류를 해결합니다.

- **Technical Details**: BlinkTrack은 이벤트 모듈과 이미지 모듈로 구성되어 있으며, 학습 가능 Kalman 필터를 사용합니다. 이 구조는 기존의 단일 모달리티 트래커를 개선하고 모달리티 간의 비동기 데이터 융합을 지원합니다.

- **Performance Highlights**: BlinkTrack은 기존 이벤트 기반 방법보다 성능이 크게 향상되었으며, 이벤트 데이터가 전처리된 경우 100 FPS 이상, 다중 모달리티 데이터가 포함될 경우 80 FPS 이상으로 작동합니다.



### HydraViT: Stacking Heads for a Scalable V (https://arxiv.org/abs/2409.17978)
- **What's New**: 새로운 HydraViT 접근 방식은 다중 크기의 Vision Transformers (ViTs) 모델을 학습하고 저장하는 필요성을 없애면서, 스케일러블한 ViT를 가능하게 합니다.

- **Technical Details**: HydraViT는 Multi-head Attention (MHA) 메커니즘을 기반으로 하여, 다양한 하드웨어 환경에 적응할 수 있도록 임베딩 차원과 MHA의 헤드 수를 동적으로 조정합니다. 이 방식은 최대 10개의 서브 네트워크를 생성할 수 있습니다.

- **Performance Highlights**: HydraViT는 ImageNet-1K 데이터셋에서 동일한 GMACs와 처리량을 기준으로, 기존 모델 대비 최대 7 p.p. 높은 정확성을 달성하며, 이는 다양한 하드웨어 환경에서 특히 유용합니다.



### Cross-Modality Attack Boosted by Gradient-Evolutionary Multiform Optimization (https://arxiv.org/abs/2409.17977)
- **What's New**: 최근의 적대적 공격(adversarial attack) 연구에서, 중첩된 이미지 모달리티(infrared, thermal, RGB 이미지 등) 간에 적대적 공격의 전이성을 다룬 연구가 부족했던 부분을 보완하는 새로운 'Multiform Attack' 전략을 제안합니다.

- **Technical Details**: 제안하는 듀얼 레이어 최적화 프레임워크는 'gradient-evolution'을 기반으로 하여 다양한 모달리티 간의 효과적인 노이즈 전이를 촉진합니다. 첫 번째 층은 각 모달리티 내에서 범용적인 방해를 생성하며, 두 번째 최적화에서는 진화 알고리즘을 사용해 서로 다른 모달리티 간의 공유 방해를 찾습니다. 이러한 방법을 통해 우리는 협력적이고 포괄적인 보안 접근 방식을 실현합니다.

- **Performance Highlights**: 다양한 이질적 데이터셋에서의 광범위한 테스트를 통해 'Multiform Attack'이 기존의 기술들보다 월등한 성능과 강인성을 보인 것을 입증했습니다. 이는 교차 모달 적대적 공격의 전이성을 개선하여 복잡한 다중 모달 시스템의 보안 취약성을 이해하는 데 새로운 시각을 제공합니다.



### CNCA: Toward Customizable and Natural Generation of Adversarial Camouflage for Vehicle Detectors (https://arxiv.org/abs/2409.17963)
- **What's New**: 본 연구는 사용자 정의 가능한 자연스러운 적대적 위장(Adversarial Camouflage) 생성을 위해 사전 훈련된 diffusion 모델을 활용하는 새로운 접근 방식을 제안합니다. 이를 통해 이전의 고정관념과 달리 어렵고 신경망이 쉽게 식별할 수 있었던 적대적 위장으로부터 벗어날 수 있습니다.

- **Technical Details**: 이 방법은 사용자가 제공하는 텍스트 프롬프트를 기반으로 최적의 텍스쳐 이미지를 생성하고, 적대적 특성과 원래의 텍스트 프롬프트 기능을 결합하여 diffusion 모델의 조건부 입력을 형성합니다. 이 과정에서 클리핑 전략을 도입하여 자연스러움과 공격 성능 간의 균형을 유지합니다.

- **Performance Highlights**: 우리는 광범위한 실험을 통해 제안된 방법이 기존 최첨단 기법들보다 자연스럽고 커스터마이즈 가능한 위장을 생성할 수 있고, 공격 성능에서도 경쟁력을 가진다는 것을 입증하였습니다. 코드도 공개되었습니다.



### Spatial Hierarchy and Temporal Attention Guided Cross Masking for Self-supervised Skeleton-based Action Recognition (https://arxiv.org/abs/2409.17951)
Comments:
          12 pages,6 figures,IEEE Trans

- **What's New**: 본 논문에서는 스켈레톤 기반 행동 인식을 위한 새로운 프레임워크인 계층적 및 어텐션 기반 교차 마스킹 프레임워크(HA-CM)를 제안합니다. HA-CM은 시간적 및 공간적 관점에서 스켈레톤 시퀀스에 마스킹을 적용하여 단일 마스킹 방법의 고유한 편향을 완화합니다.

- **Technical Details**: HA-CM은 하이퍼볼릭 공간을 활용하여 고차원 스켈레톤의 계층 구조를 유지하고, 참여 조인트의 하위 계층을 마스킹 기준으로 사용합니다. 시간 흐름에서는 조인트의 글로벌 어텐션을 활용하여 마스킹 기법을 개선하고, 교차 대비 손실을 손실 함수에 도입해 인스턴스 수준의 특징 학습을 향상시킵니다.

- **Performance Highlights**: HA-CM은 세 개의 공개 대규모 데이터세트인 NTU-60, NTU-120, PKU-MMD에서 효율성과 보편성을 입증했습니다.



### Perturb, Attend, Detect and Localize (PADL): Robust Proactive Image Defens (https://arxiv.org/abs/2409.17941)
- **What's New**: 본 논문에서는 PADL(Proactive Attack Detection and Localization)이라는 혁신적인 솔루션을 제안하여 이미지 조작 탐지 및 위치 지정을 위한 새로운 접근 방식을 구현하였습니다. 이 방법은 이미지에 대한 특정한 방해 요소를 생성하는 대칭 인코딩 및 디코딩 스킴을 기반으로 하여, 기존 방법들의 한계를 극복합니다.

- **Technical Details**: PADL은 transformer 아키텍처의 cross-attention 메커니즘을 활용해, 이미지에 특화된 방해 요소를 생성하는데, 이 과정은 코드화 및 복호화 모듈로 구성된 대칭적 구조에서 이루어집니다.  또한 새로운 손실 함수를 통해 방해 요소의 다양성을 유지하여 성능을 향상시킵니다.

- **Performance Highlights**: PADL은 다양한 이미지 생성 모델에 대해 우수한 일반화 성능을 보이며, StarGANv2, BlendGAN, DiffAE 등 여러 미지의 모델에 적용 가능함을 입증합니다. 또한 새로운 평가 프로토콜을 통해 탐지 정확도에 따라 위치 지정 성능을 공정하게 평가하여 실제 시나리오를 더 잘 반영합니다.



### Neural Light Spheres for Implicit Image Stitching and View Synthesis (https://arxiv.org/abs/2409.17924)
Comments:
          Project site: this https URL

- **What's New**: 이번 연구에서는 네트워크 기반의 구형 신경 광선 필드 모델을 통해 파노라마 이미지를 효과적으로 스티칭(stitching)하고 재렌더링하는 방법을 제안합니다. 이 모델은 카메라 경로와 고해상도 장면 재구성을 동시에 추정하여, 다양한 경로로 촬영된 파노라마 비디오를 처리할 수 있습니다.

- **Technical Details**: 연구에서 제안한 모델은 깊이 시차(depth parallax), 시점 의존 조명(view-dependent lighting), 지역 장면의 움직임 및 색상 변화를 처리할 수 있는 구성 요소로 나뉘어 있으며, 모델 크기는 장면당 80MB에 1080p 해상도로 50 FPS의 실시간 렌더링을 지원합니다. 추가로, Android 기반의 데이터 수집 도구를 제공하여 카메라 및 시스템 메타데이터와 함께 RAW 이미지 배열을 녹화할 수 있습니다.

- **Performance Highlights**: 전통적인 이미지 스티칭 및 방사선 필드(radiance field) 방법과 비교하여 향상된 재구성 품질을 입증하였으며, 장면의 움직임 및 비이상적인 촬영 설정에 대해 훨씬 높은 내성을 보여줍니다. 50개의 실내 및 실외 핸드헬드 파노라마 장면이 포함된 데이터셋도 공개되었습니다.



### Resolving Multi-Condition Confusion for Finetuning-Free Personalized Image Generation (https://arxiv.org/abs/2409.17920)
- **What's New**: 이번 논문은 여러 개의 참조 이미지를 사용할 때 발생하는 객체 혼동 문제를 해결하기 위해 새로운 가중 병합(weighted-merge) 방법을 제안합니다. 이 방법은 diffusion model에서 잠재 이미지 특성과 목표 객체와의 관련성을 조사하여 참조 이미지 특성을 적절하게 통합합니다.

- **Technical Details**: 제안된 가중 병합 방법은 참조 이미지의 특성을 해당 객체에 맞게 병합하며, 이는 각각의 잠재 이미지 특성의 위치에 따라 달라지는 가중치를 이용합니다. 또한, 여러 객체를 포함한 데이터셋에서 기존의 사전 훈련된 모델에 통합되며, 노이즈 추가 실험을 통해 객체 관련성 예측의 유효성이 검증되었습니다.

- **Performance Highlights**: 이 방법은 11백만 개의 이미지로 구성된 SA-1B 데이터셋을 활용하여 모델을 훈련한 후, Concept101 및 DreamBooth 데이터셋에서 다중 객체 개인화 이미지 생성의 최첨단 성능을 달성했습니다. 또한 단일 객체 개인화 이미지 생성에서도 성능이 크게 향상되었습니다.



### WaSt-3D: Wasserstein-2 Distance for Scene-to-Scene Stylization on 3D Gaussians (https://arxiv.org/abs/2409.17917)
- **What's New**: 이번 논문에서는 3D 장면에서의 스타일 전이에 대한 새로운 접근 방식을 제시합니다. 기존의 2D 이미지 스타일 전이 기술에 비해 3D 장면에서의 기하학을 보다 정확하게 복제할 수 있는 방법을 모색하였습니다.

- **Technical Details**: 연구팀은 명시적인 Gaussian Splatting (GS) 표현을 활용하여 스타일 장면과 콘텐츠 장면 간의 Gaussian 분포를 Earth Mover's Distance (EMD)를 사용하여 직접 일치시킵니다. 이를 통해 공간의 부드러움을 유지할 수 있도록 엔트로피 정규화 Wasserstein-2 거리도 도입하였습니다. 그리고 장면 스타일화 문제를 더 작은 단위로 분해하여 효율성을 높였습니다.

- **Performance Highlights**: 제안한 WaSt-3D 방법은 스타일 장면의 세부 정보를 콘텐츠 장면에 충실하게 전이함으로써 고해상도 3D 스타일화를 가능하게 합니다. 이 방법은 다양한 콘텐츠 및 스타일 장면에서도 일관되게 성능을 발휘하며, 어떠한 학습 없이 최적화 기반 기법만 사용하여 결과를 도출합니다.



### LKA-ReID:Vehicle Re-Identification with Large Kernel Attention (https://arxiv.org/abs/2409.17908)
Comments:
          The paper is under consideration at 2025 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)

- **What's New**: 지능형 교통 시스템과 스마트 시티 인프라의 빠른 발전에 따라 차량 재식별 기술(vehicle Re-ID)이 중요한 연구 분야로 부상하고 있습니다. 이 논문에서는 큰 커널 주의 메커니즘(large kernel attention, LKA)을 활용한 LKA-ReID를 제안하며, 이로써 차량의 글로벌 및 로컬 피처를 보다 포괄적으로 추출하고 inter-class 간 유사성을 해결하고자 합니다.

- **Technical Details**: LKA-ReID는 네 개의 브랜치로 구성된 네트워크를 사용하여 각 브랜치가 2048 차원의 피처를 생성합니다. LKA 모듈을 통해 차량의 글로벌 및 로컬 특성을 추출하고, HCA(hybrid channel attention) 모듈을 사용하여 채널과 공간 정보를 결합하여 배경 및 방해 정보를 제거하고 중요한 특성을 강조합니다.

- **Performance Highlights**: VeRi-776 데이터셋에서 LKA-ReID의 효과를 실험했으며, mAP(micro Average Precision)는 86.65%, Rank-1은 98.03%에 도달하여 경쟁력 있는 성능을 입증했습니다.



### Self-supervised Monocular Depth Estimation with Large Kernel Attention (https://arxiv.org/abs/2409.17895)
Comments:
          The paper is under consideration at 2025 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)

- **What's New**: 이 논문에서는 Self-Supervised Monocular Depth Estimation을 위한 새로운 네트워크를 제안합니다. 특히, 큰 커널 어텐션(large kernel attention)을 기반으로 한 디코더를 통해 깊이 추정에서의 성능을 개선합니다.

- **Technical Details**: 제안한 네트워크는 인코더-디코더 아키텍처를 채택하며, 인코더에서는 HRNet18을 사용하여 다중 스케일 특성을 유지합니다. 디코더는 LKA(large kernel attention)와 업샘플링 모듈을 통해 관측된 이미지를 세밀하게 복원합니다. 이 과정에서 2D 이미지 구조를 손상시키지 않으면서도 채널 적응성을 유지합니다.

- **Performance Highlights**: KITTI 데이터셋의 실험에서 AbsRel = 0.095, SqRel = 0.620, RMSE = 4.148, RMSElog = 0.169, δ<1.25 = 90.7의 성능을 달성했습니다.



### Upper-Body Pose-based Gaze Estimation for Privacy-Preserving 3D Gaze Target Detection (https://arxiv.org/abs/2409.17886)
Comments:
          Accepted in the T-CAP workshop at ECCV 2024

- **What's New**: 이 논문은 사람의 상체 자세와 깊이 지도(depth map)를 활용하여 3D 시선 방향을 추출하고, 이를 통해 주목하는 대상을 예측하는 새로운 접근 방식을 제시합니다. 또한, 얼굴 이미지를 필요로 하지 않고도 주목 대상을 탐지하는 방법을 통해 프라이버시를 보호할 수 있습니다.

- **Technical Details**: 논문에서 제안하는 방법은 상체 스켈레톤과 깊이 지도를 사용하여 3D 시선 추정 및 주목 대상을 탐지하는 다중 단계 또는 엔드-투-엔드 파이프라인을 활용합니다. 각 단계에서 상체 자세 피처 및 장면 깊이 지도에서 추출한 컨볼루션 피처를 조합하여 실시간으로 높은 정확도의 3D 시선 벡터를 생성합니다.

- **Performance Highlights**: 제안된 방법은 GFIE 데이터셋에서 최첨단 결과를 달성하여 3D 시선 목표 탐지 분야에서의 새로운 기준을 마련했습니다. 이 방법은 개인의 얼굴 정보를 사용하지 않고도 정확한 시선 추정과 주목 대상 탐지가 가능하여 특히 개인의 프라이버시를 유지하는 측면에서 중요한 혁신을 제공합니다.



### Self-Distilled Depth Refinement with Noisy Poisson Fusion (https://arxiv.org/abs/2409.17880)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 본 연구는 Depth Refinement(심도 정제)의 새로운 프레임워크인 Self-distilled Depth Refinement (SDDR)을 제안합니다. 이 모델은 저해상도 심도 예측 결과를 고해상도로 변환하며, 모호한 에지(boundaries)와 잡음을 줄이고자 합니다.

- **Technical Details**: SDDR은 노이즈가 있는 Poisson fusion 문제로 심도 정제를 모델링합니다. 이는 두 가지 노이즈: local inconsistency noise와 edge deformation noise를 고려하여 심도 예측 오류를 분리합니다. SDDR의 주요 구성 요소는 depth edge representation과 edge-based guidance입니다. SDDR은 coarse-to-fine self-distillation을 통해 pseudo-labels로서 low-noise depth edge representations를 생성합니다.

- **Performance Highlights**: SDDR은 Middlebury2021, Multiscopic, Hypersim 및 자연 장면에서의 DIML와 DIODE 데이터셋에서 모두 우수한 성능을 달성했습니다. 이전 방법들보다 심도 정확도와 에지 품질이 현저히 개선되었으며 efficiency(효율성) 또한 높아졌습니다. 또한 SDDR이 생성한 정확한 depth edge labels는 다른 모델 학습에 활용되어 성능을 향상시킬 수 있음을 보여주었습니다.



### A New Dataset for Monocular Depth Estimation Under Viewpoint Shifts (https://arxiv.org/abs/2409.17851)
Comments:
          17 pages, 5 figures. Accepted at ECCV 2024 2nd Workshop on Vision-Centric Autonomous Driving (VCAD)

- **What's New**: 본 논문에서는 모노큘라 깊이 추정(Depth Estimation)과 관련하여 카메라 위치와 방향이 모델에 미치는 영향을 정량화할 수 있는 새로운 데이터셋과 평가 방법론을 소개합니다. 이 접근법은 고가의 lidar 센서를 사용할 필요 없이 객체 감지 및 호모그래피 추정을 기반으로 한 새로운 'ground truth' 전략을 제안합니다.

- **Technical Details**: 제안된 방법은 호모그래피( Homography)와 객체 감지를 결합하여 도로 장면에서 모노큘라 깊이 추정의 오류를 측정하는 'ground truth' 소스로 사용합니다. 이 연구는 여러 알려진 카메라 설정에서 기록된 다양한 비디오 시퀀스를 수집하고 이를 사용하여 모던 깊이 추정 모델의 다양한 뷰포인트 변화에 대한 강건성을 평가합니다. 데이터셋은 kaggle.com/datasets/aurelpjetri/viewpointdepth에서 액세스할 수 있습니다.

- **Performance Highlights**: 본 연구의 결과는 3D 장면 이해를 위한 깊이 추정이 다양한 뷰포인트에서 어떻게 영향을 받는지를 정량화합니다. 실험 결과, 기존 lidar 'ground truth'를 사용한 평가 결과와 유사한 결과를 보여 대안적 접근법의 유효성을 입증합니다.



### Unsupervised Learning Based Multi-Scale Exposure Fusion (https://arxiv.org/abs/2409.17830)
Comments:
          11 pages

- **What's New**: 이 논문은 비지도 학습 기반의 다중 스케일 노출 융합 알고리즘(ULMEF)를 제안합니다. 기존의 알고리즘과는 달리, 이미지 세트를 융합하는 것뿐만 아니라, 같은 HDR 장면에서 다른 노출의 이미지를 이용하여 새로운 손실 함수(loss functions)를 정의합니다.

- **Technical Details**: ULMEF는 비지도 학습 방법을 사용하며, 다중 스케일 주의 모듈(multi-scale attention module)을 포함하여 장면 깊이와 지역 대비(local contrast)를 효과적으로 보존합니다. 새로운 손실 함수는 융합할 이미지 집합과 비축점(이와 같이) LDR 이미지 집합을 분리하여 정의하여, 훈련 효율을 향상시킵니다.

- **Performance Highlights**: 제안된 ULMEF 알고리즘은 다양한 데이터셋에서 실험 결과 다른 최신의 노출 융합 알고리즘들보다 우수한 성능을 보였습니다. 이는 이미지 융합 품질을 현저히 향상시키며, 기존 알고리즘들이 남기는 밝기 질서 역전 아티팩트(brightness order reversal artifacts)를 방지합니다.



### Kendall's $\tau$ Coefficient for Logits Distillation (https://arxiv.org/abs/2409.17823)
- **What's New**: 본 논문에서는 KL divergence의 제약으로 인한 학생 모델의 비효율적 최적화를 해결하기 위해 Rank-Kendall Knowledge Distillation(RKKD)라는 새로운 플러그 앤 플레이(ranking loss) 기법을 제안합니다. RKKD는 학생의 로짓(logits)에서 채널 값의 순서를 제약하여 작은 값 채널들에도 집중할 수 있도록 합니다.

- **Technical Details**: RKKD는 Kendall의 τ𝜏	au 계수를 기반으로 하여 학생 모델의 로짓 내에서 값의 순서를 제약하는 랭크(loss) 기능을 제공합니다. 이 랭크 제약은 상위 채널의 올바른 클래스를 최상위 순위로 구속하여 KL divergence와 작업 손실(task loss)의 최적화 방향을 일치시키는 데 도움을 줍니다. 저자는 다양한 차별적 형태의 Kendall 계수를 탐구합니다.

- **Performance Highlights**: CIFAR-100 및 ImageNet 데이터셋에서 광범위한 실험이 수행되었으며, RKKD는 다양한 지식 증류(baseline) 설정에서 성능을 향상시켰습니다. RKKD는 기존 지식 증류 방법에 플러그 앤 플레이 방식으로 추가되어 다양한 교사-학생 아키텍처 조합에서 전반적인 개선을 보여 주었습니다.



### Cascade Prompt Learning for Vision-Language Model Adaptation (https://arxiv.org/abs/2409.17805)
Comments:
          ECCV2024

- **What's New**: 이번 연구에서는 Vision-Language Models (VLMs)인 CLIP의 성능 향상을 위한 Cascade Prompt Learning (CasPL) 프레임워크를 제안합니다. 이 프레임워크는 일반적인 지식과 특정 지식을 동시에 캡처할 수 있는 새로운 학습 패러다임을 제공합니다.

- **Technical Details**: CasPL은 두 가지의 학습 가능한 프롬프트로 구성됩니다. 첫 번째는 도메인 일반 지식을 추출하는 'boosting prompt'이며, 두 번째는 다운스트림 태스크를 미세 조정하는 'adapting prompt'입니다. 이 두 단계는 서로 연결되어 단계적으로 최적화됩니다. CasPL은 기존의 다른 프롬프트 학습 방법들과 쉽게 통합할 수 있는 플러그 앤 플레이 모듈입니다.

- **Performance Highlights**: CasPL은 PromptSRC 방법과 비교했을 때, 기본 클래스(Base Classes)에서 평균 1.85%, 새로운 클래스(Novel Classes)에서 3.44%, 그리고 조화 평균(Harmonic Mean)에서 2.72%의 성능 향상을 보여주었습니다.



### Reblurring-Guided Single Image Defocus Deblurring: A Learning Framework with Misaligned Training Pairs (https://arxiv.org/abs/2409.17792)
Comments:
          The source code and dataset are available at this https URL

- **What's New**: 이번 논문은 misaligned training pairs를 사용하여 단일 이미지 defocus deblurring을 위한 reblurring-guided 학습 프레임워크를 제안합니다. 새로운 SDD 데이터셋을 수집하여 이러한 방법의 유효성을 검증하고 있습니다.

- **Technical Details**: 이 프레임워크는 baseline defocus deblurring 네트워크를 구축하고, reblurring 모듈을 사용하여 입력 흐림 이미지와 deblurred 이미지 간의 공간적 일관성을 유지합니다. 이 모듈은 isotropic blur kernels을 재구성하고 pseudo defocus blur map을 통해 training triplets를 형성합니다.

- **Performance Highlights**: 제안된 방법은 기존의 state-of-the-art 방법들과 비교하여 향상된 성능을 보이며, SDD 데이터셋을 통해 학습된 모델을 평가할 수 있습니다.



### Taming Diffusion Prior for Image Super-Resolution with Domain Shift SDEs (https://arxiv.org/abs/2409.17778)
Comments:
          This paper is accepted by NeurIPS 2024

- **What's New**: 본 연구에서는 기존의 Diffusion 모델을 활용하여 이미지 초해상도(SR) 문제를 해결하는 DoSSR 모델을 제안하며, 저해상도(Low-Resolution, LR) 이미지를 시작점으로 하는 접근 방식을 통해 효율성을 크게 향상시켰습니다.

- **Technical Details**: DoSSR 모델은 도메인 이동 방정식(domain shift equation)을 기반으로 하여 기존의 Diffusion 모델과 통합됩니다. 이 과정은 확률적 미분 방정식(Stochastic Differential Equations, SDEs)으로 연속적인 형태로 전환되어 높은 샘플링 효율성을 달성합니다.

- **Performance Highlights**: 실험 결과, DoSSR 모델은 합성 및 실제 데이터셋에서 최신 기술 대비 뛰어난 성능을 보여주었으며, 단 5회의 샘플링 단계만으로도 상대적으로 5-7배 빠른 속도를 제공합니다.



### Harnessing Shared Relations via Multimodal Mixup Contrastive Learning for Multimodal Classification (https://arxiv.org/abs/2409.17777)
Comments:
          RK and RS contributed equally to this work, 20 Pages, 8 Figures, 9 Tables

- **What's New**: 본 논문에서는 M3CoL(Multimodal Mixup Contrastive Learning) 접근 방식을 제안하여, 다양한 모달리티 간의 미묘한 공유 관계를 포착할 수 있음을 보여줍니다. M3CoL은 모달리티 간의 혼합 샘플을 정렬하여 강력한 표현을 학습하는 Mixup 기반의 대조 손실을 활용합니다.

- **Technical Details**: M3CoL은 이미지-텍스트 데이터셋(N24News, ROSMAP, BRCA, Food-101)에서 광범위한 실험을 통해 공유 모달리티 관계를 효과적으로 포착하고, 다양한 도메인에서 일반화 능력을 발휘합니다. 이는 fusion module과 unimodal prediction modules로 구성된 프레임워크에 기반하였으며, Mixup 기반의 대조 손실을 통해 보조 감독을 강화합니다.

- **Performance Highlights**: M3CoL은 N24News, ROSMAP, BRCA 데이터셋에서 최첨단 방법들을 초월하는 성능을 보이며, Food-101에서는 유사한 성능을 달성했습니다. 이를 통해 공유 관계 학습의 중요성이 강조되며, 강력한 다중 모달 학습을 위한 새로운 연구 방향을 열어갑니다.



### UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology (https://arxiv.org/abs/2409.17775)
- **What's New**: 이번 연구에서는 다채로운 염색을 이용한 조직병리학 이미지의 통합을 위해 다중 모달리티(transformer) 모델인 UNICORN을 제안하였습니다. 이 모델은 학습 및 추론 중 결측값을 처리할 수 있으며, 상이한 염색 방법을 통해 아테롬성 동맥경화증의 중증도를 예측합니다.

- **Technical Details**: UNICORN은 다단계(end-to-end) 훈련이 가능한 transformer 아키텍처로, 256x256 px 크기의 패치로 분할된 WSIs를 처리합니다. 개별적으로 처리된 도메인 전문 모듈들이 각각의 염색에서 고유한 특징을 학습하고, 집계 전문가 모듈이 다양한 염색 간의 상호작용을 학습하여 정보 통합을 수행합니다.

- **Performance Highlights**: UNICORN은 4,000개의 다중 염색 전체 슬라이드 이미지(WSIs)를 평가하여 0.67의 분류 정확도를 달성하였고, 이는 현재 최고 수준의 타 모델들을 초월하는 성능입니다. 모델은 다양한 염색 방법을 통한 조직의 특징을 효과적으로 식별하고, 질병 진행 모델링에서도 높은 성능을 나타냈습니다.



### Confidence intervals uncovered: Are we ready for real-world medical imaging AI? (https://arxiv.org/abs/2409.17763)
Comments:
          Paper accepted at MICCAI 2024 conference

- **What's New**: 이 논문은 의료 영상(segmentation) 분야에서 AI 성능 변동성을 평가되지 않는 문제를 다루고 있습니다. 2023년 MICCAI에서 발표된 논문 221편을 분석한 결과, 50% 이상의 논문이 성능 변동성을 평가하지 않고, 단 0.5%의 논문만이 신뢰 구간(confidence intervals, CIs)을 보고했습니다. 이는 기존 논문들이 임상 적용을 위한 충분한 근거를 제공하지 않음을 지적합니다.

- **Technical Details**: 연구에서는 segmentation 논문에서 보고되지 않은 표준 편차(standard deviation, SD)를 평균 Dice 유사도 계수(Dice similarity coefficient, DSC)의 2차 다항식 함수를 통해 근사할 수 있음을 보여줍니다. 이를 바탕으로 2023년 MICCAI segmentation 논문의 평균 DSC 주변에 95% CIs를 재구성하였고, 그 중간 CI 폭은 0.03으로 첫 번째와 두 번째 순위 방법 간의 중간 성능 격차보다 세 배 더 큽니다.

- **Performance Highlights**: 60% 이상의 논문에서 두 번째 순위 방법의 평균 성능이 첫 번째 순위 방법의 신뢰 구간 내에 포함되었으며, 이는 현재 보고된 성능이 실제 임상에서의 가능성을 충분히 뒷받침하지 않음을 의미합니다.



### Text Image Generation for Low-Resource Languages with Dual Translation Learning (https://arxiv.org/abs/2409.17747)
Comments:
          23 pages, 11 figures

- **What's New**: 이 연구에서는 고자원 언어에서의 실제 텍스트 이미지 스타일을 모방하여 저자원 언어의 텍스트 이미지를 생성하는 새로운 접근 방식을 제안합니다. 이를 통해 저자원 언어의 장면 텍스트 인식 성능을 향상시키고자 합니다.

- **Technical Details**: 제안된 방법은 'synthetic'(합성)과 'real'(실제)라는 이진 상태에 따라 조건화된 diffusion model(확산 모델)을 이용합니다. 이 모델은 텍스트 이미지를 합성과 실제 이미지로 변환하는 이중 번역 작업(Dual Translation Learning, DTL)에 대한 훈련을 포함하여 텍스트 인식 모델의 성능을 극대화하는 데 중요한 역할을 합니다. 또한 Fidelity-Diversity Balancing Guidance 및 Fidelity Enhancement Guidance와 같은 두 가지 지침 기술을 도입하여 생성된 텍스트 이미지의 정확성과 다양성을 향상시킵니다.

- **Performance Highlights**: 실험 결과, 제안된 프레임워크를 통해 생성된 텍스트 이미지는 저자원 언어의 장면 텍스트 인식 모델의 성능을 크게 개선할 수 있음을 보여주었습니다.



### AnyLogo: Symbiotic Subject-Driven Diffusion System with Gemini Status (https://arxiv.org/abs/2409.17740)
Comments:
          13 pages, 12 figures

- **What's New**: 이번 연구에서는 AnyLogo라는 새로운 제로샷 지역 맞춤형 모델을 소개하고 있습니다. 이 모델은 복잡한 설정을 없애고, 뛰어난 세부 일관성을 가지고 있습니다.

- **Technical Details**: AnyLogo는 대칭적 확산 시스템을 기반으로 하며, 단일 디노이징 모델 내에서 엄격한 서명 추출과 창의적 콘텐츠 생성이 체계적으로 재활용됩니다. 이는 주제 전달 효율성을 향상시킵니다.

- **Performance Highlights**: AnyLogo는 약 1K의 고품질 쌍을 포함한 로고 수준 커스터마이징 벤치마크에서 실험을 수행하여 방법의 효과와 실용성을 입증했습니다.



### Neural Implicit Representation for Highly Dynamic LiDAR Mapping and Odometry (https://arxiv.org/abs/2409.17729)
- **What's New**: 이 논문은 NeRF-LOAM을 기반으로 하여 동적 객체를 포함한 외부 환경의 3D 재구성을 개선하는 새로운 방법을 제안합니다. 특히, 동적 전경과 정적 배경을 분리하여 정적 배경만으로 밀집 3D 지도를 만드는 방법론을 소개합니다.

- **Technical Details**: 제안된 방법은 두 가지 주요 구성 요소로 나뉩니다. 첫 번째는 정적 배경과 동적 전경을 분리하는 것입니다. 동적인 요소를 매핑 과정에서 제외함으로써 밀집 3D 지도를 생성합니다. 두 번째 구성 요소는 다중 해상도 표현을 지원하기 위해 옥트리(Octree) 구조를 확장하는 것입니다. Fourier feature encoding을 통해 샘플링된 포인트에 고주파 정보를 캡처하여 재구성 결과를 개선합니다.

- **Performance Highlights**: 다양한 데이터셋에서 수행한 평가 결과, 제안된 방법이 현재 최첨단 접근 방식들보다 더 경쟁력 있는 결과를 달성하는 것으로 나타났습니다. 또한, 동적 객체 제거 및 구멍 메우기에서 뛰어난 성능을 보여줍니다.



### AlterMOMA: Fusion Redundancy Pruning for Camera-LiDAR Fusion Models with Alternative Modality Masking (https://arxiv.org/abs/2409.17728)
Comments:
          17 pages, 3 figures, Accepted by NeurIPS 2024

- **What's New**: 본 논문에서는 카메라-라이다(Camera-LiDAR) 융합 모델의 효율성을 높이기 위해 새로운 가지치기 프레임워크인 AlterMOMA를 제안합니다.

- **Technical Details**: AlterMOMA는 각 모달리티에 대해 대체 마스킹을 사용하고 중요도 평가 함수인 AlterEva를 통해 중복된 파라미터를 식별합니다. 이 과정에서는 한 모달리티 파라미터가 활성화 및 비활성화될 때의 손실 변화를 관찰하여 중복 파라미터를 식별합니다.

- **Performance Highlights**: AlterMOMA는 nuScenes 및 KITTI 데이터셋의 다양한 3D 자율 주행 작업에서 기존의 가지치기 방법보다 뛰어난 성능을 보이며, 최첨단 성능을 달성하였습니다.



### Scene Understanding in Pick-and-Place Tasks: Analyzing Transformations Between Initial and Final Scenes (https://arxiv.org/abs/2409.17720)
Comments:
          Conference Paper, ICEE 2024, 7 pages, 5 figures

- **What's New**: 본 논문은 로봇이 사람과 함께 작업할 수 있도록 환경을 이해할 수 있는 로봇 시스템의 개발을 목표로 한다. 초기 및 최종 장면의 이미지를 통해 픽 앤 플레이스(pick and place) 작업을 감지하기 위한 데이터셋을 수집하고 YOLOv5 네트워크를 사용해 객체를 탐지하여, 픽 앤 플레이스 작업을 도출하는 두 가지 방법을 제안한다. 

- **Technical Details**: 제안된 방법 중 첫 번째는 기하학적 방법으로, 두 장면에서 객체의 움직임을 추적하여 바운딩 박스(bounding boxes)의 교차점에 기반하여 작업을 감지한다. 두 번째는 CNN(Convolutional Neural Network) 기반 방법으로, 교차된 바운딩 박스를 가진 객체를 분류하여 객체 간의 공간적 관계를 이해한다. VGG16 백본을 사용하는 CNN 기반 방법이 기하학적 방법보다 약 12% 높은 성능을 보였다.

- **Performance Highlights**: CNN 기반 방법은 특정 상황에서 84.3%의 성공률을 기록하며, 전반적인 성능에서 기하학적 방법보다 약 12% 높은 점수를 기록하였다.



### Behaviour4All: in-the-wild Facial Behaviour Analysis Toolk (https://arxiv.org/abs/2409.17717)
- **What's New**: Behavior4All은 야외 환경에서 얼굴 행동 분석을 위한 포괄적이고 오픈 소스인 도구 모음입니다. 얼굴 위치 탐지, 감정 점수 추정, 기본 표정 인식 및 행동 단위 탐지를 하나의 프레임워크 내에서 통합합니다.

- **Technical Details**: Behavior4All은 CPU 버전과 GPU 가속 버전으로 제공되며, 12개의 대규모 야외 데이터셋을 활용하여 500만 장 이상의 이미지로 테스트되었습니다. 이 도구는 비포함 주석을 다루기 위해 분포 일치 및 레이블 공동 주석을 활용하는 새로운 프레임워크를 도입하여, 관련성에 대한 사전 지식을 인코딩합니다. 또한, FaceLocalizationNet과 FacebehaviourNet의 두 가지 주요 구성 요소로 구성되어 있습니다.

- **Performance Highlights**: Behavior4All은 AUC, 기본 표정 인식, VA 추정 및 AU 탐지를 포함한 모든 데이터베이스와 작업에서 기존 도구 및 최첨단 기술을 초월하는 성능과 공정성을 보여주었습니다. 또한, 다른 도구들보다 1.9배 이상의 처리 속도로 작동합니다.



### MoGenTS: Motion Generation based on Spatial-Temporal Joint Modeling (https://arxiv.org/abs/2409.17686)
Comments:
          Accepted to NeurIPS 2024

- **What's New**: 본 연구는 개별 관절을 벡터로 양자화하여 모션 생성을 간소화하고, 공간-시간적 구조를 유지하며, 2D 토큰 맵을 생성하는 새로운 방법을 제안합니다. 이는 이전 방법들이 전체 포즈를 양자화하면서 발생했던 문제들을 해결하는 방향으로 발전했습니다.

- **Technical Details**: 우리는 2D 모션 양자화를 기반으로 한 공간-시간 모델링 프레임워크를 구축하였습니다. 여기서는 2D 조인트 VQVAE, 시간-공간 2D 마스킹 기술 및 공간-시간 2D 주의(attention) 메커니즘을 결합하여 2D 토큰들 간의 신호를 효과적으로 활용합니다. 각각의 관절은 개별 코드로 양자화되어 2D 토큰을 형성하며, 2D 컨볼루션 네트워크를 통해 효율적인 특성 추출이 이루어집니다.

- **Performance Highlights**: 우리의 방법은 HumanML3D 데이터셋에서 FID를 26.6% 감소시키고, KIT-ML 데이터셋에서는 29.9% 감소시키는 성능 향상을 보였습니다. 이는 이전의 최첨단 방법(SOTA) 대비 매우 우수한 결과입니다.



### Dark Miner: Defend against unsafe generation for text-to-image diffusion models (https://arxiv.org/abs/2409.17682)
- **What's New**: 이번 논문은 Text-to-image diffusion 모델의 안전성 문제를 해결하기 위해 새로운 방법인 Dark Miner를 제안합니다. 기존 방법들이 훈련 단계에서 보지 못한 텍스트에 대한 안전한 생성을 보장하지 못했던 문제를 분석하고, 안전 개념을 효과적으로 지우기 위해 반복되는 3단계 과정(채굴, 검증, 회피)을 포함한 DM2 방식에 대해 설명합니다.

- **Technical Details**: Dark Miner는 unsafe 개념의 최대 생성 확률을 가진 임베딩을 채굴하는 'mining', 이를 검증하는 'verifying', 그리고 안전한 텍스트에 조건화된 생성 확률로 수정하는 'circumventing'의 세 가지 단계를 반복적으로 수행합니다. 이 과정에서 DM2는 unsafe 생성의 총 확률을_EFFECTIVELY_ 줄이는 방안을 모색합니다.

- **Performance Highlights**: 실험 결과, DM2는 6개의 최신 방법과 비교했을 때 전반적인 지우기 성능과 공격 방어 성능에서 우수한 결과를 보였으며, 4개의 최신 공격에 대해서도 높은 방어 효과를 유지했습니다. 이러한 성능은 DM2가 일반 텍스트에 조건화된 생성 능력을 보존하면서 이루어졌습니다.



### Event-based Stereo Depth Estimation: A Survey (https://arxiv.org/abs/2409.17680)
Comments:
          28 pages, 20 figures, 7 tables

- **What's New**: 이 연구는 기존의 연구들에서 다루어지지 않았던 스테레오 데이터셋에 대한 포괄적인 개요를 제공합니다. 또한, 딥러닝(DL) 방법과 스테레오 데이터셋에 대한 광범위한 리뷰를 최초로 수행하고, 새로운 벤치마크를 생성하기 위한 실용적인 제안도 포함하고 있습니다.

- **Technical Details**: 이 논문은 이벤트 카메라(event cameras)의 깊이 추정(depth estimation)과 관련하여 스테레오(Stereo) 기술을 다룹니다. 이벤트 카메라는 퍼픽셀(pixel) 밝기 변화(brightness changes)를 비동기적으로 감지하는 생체 모방 센서로, 높은 시간 해상도(temporal resolution)와 높은 동적 범위(dynamic range)를 가지고 있습니다. 이러한 특성으로 인해 스테레오 매칭(stereo matching)에서의 성능이 이점이 있습니다.

- **Performance Highlights**: 이 연구는 스테레오 깊이 추정 분야에서 딥러닝 기반 접근 방식의 발전을 조명하고 있으며, 정확도(accuracy)와 효율성(efficiency) 측면에서 최적 성능을 달성하는 데 여전히 많은 도전이 있다고 밝혔습니다. 이벤트 기반 컴퓨팅(event-based computing)에서의 주요 장점과 도전 과제(challenges)에 대해서도 논의하고 있습니다.



### EM-Net: Efficient Channel and Frequency Learning with Mamba for 3D Medical Image Segmentation (https://arxiv.org/abs/2409.17675)
Comments:
          10 pages, 3 figures, accepted by MICCAI 2024

- **What's New**: 본 논문에서는 EM-Net이라는 새로운 3D 의료 이미지 분할 모델을 소개합니다. EM-Net은 Mamba 기반 아키텍처를 활용하여 지역 간의 상호작용을 효율적으로 캡처하며, 다양한 스케일에서의 특징 학습을 조화롭게 하는 주파수 도메인 학습을 활용하여 훈련 속도를 가속화할 수 있습니다.

- **Technical Details**: EM-Net은 채널 압축 강화 Mamba 블록(CSRM 블록)과 효율적인 주파수 도메인 학습(EFL) 레이어를 채택하여 다중 스케일의 특징을 추출하며, Mamba 기술을 통해 메모리 비용을 줄이면서 분할 성능을 향상시킵니다. 이 프레임워크는 효율적인 인코더-디코더 구조를 기반으로 하며, 3D 입력 데이터를 패치로 분할하고, 각각의 패치에서 중요한 특징을 학습합니다.

- **Performance Highlights**: EM-Net은 두 개의 도전적인 다중 장기 데이터셋에서 테스트되었으며, 기존 최첨단(SOTA) 모델보다 2배 빠른 훈련 속도를 제공하며, 파라미터 크기가 거의 절반인 상황에서 더 나은 분할 정확도를 보여주었습니다.



### Self-Supervised Learning of Deviation in Latent Representation for Co-speech Gesture Video Generation (https://arxiv.org/abs/2409.17674)
Comments:
          5 pages, 5 figures, conference

- **What's New**: 이번 연구에서는 공동 언어(코스피치) 제스처 생성을 위한 혁신적인 접근 방식을 제안하며, 이는 자가 감독(self-supervised) 표현과 픽셀 수준의 모션 변화를 결합합니다. 기존의 방법이 점 수준(point-level) 모션 변환에 주로 집중했던 것에 비해, 본 연구는 손 제스처 생성의 질을 높이는데 집중하고 있습니다.

- **Technical Details**: 제안된 방법은 자가 감독 모듈을 이용하여 풍경(세부) 변화를 생성합니다. 이 모듈은 라텐트(잠재) 변화 추출기(latent deviation extractor), 워핑 계산기(warping calculator), 라텐트 변화 디코더(latent deviation decoder)로 구성됩니다. 이 시스템은 발화자의 음성 및 소스 이미지 입력을 통해 자연스럽고 동기화된 제스처 비디오를 생성합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 생성된 비디오의 질을 향상시켰으며, FGD, DIV, FVD에서 2.7%에서 4.5% 개선, PSNR에서 8.1%, SSIM에서 2.5% 개선을 보였습니다. 이는 현재의 최신 기법보다 뛰어난 성과를 보여줍니다.



### Leveraging Anthropometric Measurements to Improve Human Mesh Estimation and Ensure Consistent Body Shapes (https://arxiv.org/abs/2409.17671)
- **What's New**: 이 연구는 SOTA (State of the Art) 인간 메시 추정(Human Mesh Estimation, HME) 모델이 비디오의 각 프레임마다 다르게 몸체 모양을 출력하는 문제를 해결하기 위해, 인체 측정(anthropometric measurements)을 이용하여 각각의 인간에게 맞는 일관된 기본 몸체 모양을 생성하는 모델 A2B를 제안합니다.

- **Technical Details**: A2B 모델은 인체 측정을 HME의 몸체 모양 파라미터로 변환하는 머신 러닝 모델입니다. 이 모델은 HME 데이터셋의 GT(ground truth) 데이터의 불일치를 밝혀내고, SMPL-X 모델의 몸체 모양 파라미터와 인체 측정을 연결하는 다양한 모델을 생성하고 평가하여 일관된 메시를 생성합니다. 추가적으로, 조인트 회전을 보완하기 위해 역기구학(inverse kinematics, IK)을 적용합니다.

- **Performance Highlights**: A2B 모델을 통해 HME 모델의 성능이 크게 향상되어, ASPset 및 fit3D와 같은 도전적인 데이터셋에서 MPJPE(Mean Per Joint Position Error)를 30mm 이상 낮출 수 있음을 보여줍니다. 제안된 방법은 SOTA HME 모델보다 더 높은 정확도로 HME를 구현할 수 있습니다.



### MECD: Unlocking Multi-Event Causal Discovery in Video Reasoning (https://arxiv.org/abs/2409.17647)
Comments:
          Accepted at NeurIPS 2024 as a spotlight paper

- **What's New**: 새로운 과제인 Multi-Event Causal Discovery (MECD)는 장기 비디오에서 사건 간의 인과 관계를 발견하는 것을 목표로 합니다. 기존의 질문-답변(Question-Answering) 패러다임에 한정된 비디오 추론 과제를 넘어 다양한 이벤트에 대한 포괄적이고 구조화된 인과 분석을 제공합니다.

- **Technical Details**: 이 연구에서는 Granger Causality 방법에서 영감을 받아 새로운 프레임워크를 제안하여 효율적인 마스크 기반 이벤트 예측 모델을 사용하고, Event Granger Test를 수행합니다. 이를 통해 조건부 인과 추론 기법인 front-door adjustment와 counterfactual inference를 통합하여 인과성 혼동과 허위 인과성 문제를 해결합니다.

- **Performance Highlights**: 실험 결과, 제안된 프레임워크는 다중 이벤트 비디오에서 인과 관계를 예측하는 데 있어 GPT-4o 및 VideoLLaVA보다 각각 5.7% 및 4.1% 더 우수한 성능을 보였습니다.



### P4Q: Learning to Prompt for Quantization in Visual-language Models (https://arxiv.org/abs/2409.17634)
- **What's New**: 이 논문에서는 Vision-Language Models (VLMs) 의 양자화(quantization)와 미세 조정(fine-tuning)을 통합하는 새로운 방법인 'Prompt for Quantization'(P4Q)을 제안합니다. 이 방법은 PTQ(Post-Training Quantization) 모델의 인식 성능을 향상시키기 위해 경량 아키텍처를 설계합니다.

- **Technical Details**: P4Q는 이미지 특징과 텍스트 특징 간의 격차를 줄이기 위해 학습 가능한 프롬프트(prompt)를 사용하여 텍스트 표현을 재구성하고, 저비트(low-bit) 어댑터(QAdapter)를 사용하여 이미지와 텍스트 특징 분포를 재조정하는 방법입니다. 또한 코사인 유사도 예측을 기반으로 하는 증류 손실(distillation loss)을 도입하여 확장성 있는 증류를 수행합니다.

- **Performance Highlights**: P4Q 방법은 이전 연구보다 뛰어난 성능을 보이며, ImageNet 데이터셋에서 8비트 P4Q가 CLIP-ViT/B-32을 4배 압축하면서도 Top-1 정확도 66.94%를 기록하였습니다. 이는 전체 정밀(full-precision) 모델보다 2.24% 향상된 결과입니다.



### Hand-object reconstruction via interaction-aware graph attention mechanism (https://arxiv.org/abs/2409.17629)
Comments:
          7 pages, Accepted by ICIP 2024

- **What's New**: 이 연구에서는 손과 객체의 상호작용을 고려한 새로운 그래프 주의(attention) 메커니즘을 제안합니다. 기존 방법론이 그래프의 엣지 연관성을 충분히 활용하지 못했던 점을 극복하기 위해, 공통 관계 엣지(common relation edges)와 주의 유도 엣지(attention-guided edges)를 도입하여 물리적 타당성을 향상시키기 위한 그래프 기반 개선 방법을 소개합니다.

- **Technical Details**: 제안된 접근 방식은 상호작용 인식을 위한 그래프 주의 메커니즘을 통해 손과 객체의 메쉬(mesh)를 이미지에서 추정하여, 두 가지 타이프의 엣지(즉, intra-class와 inter-class 노드 간의 연결)를 사용하여 밀접하게 상관된 노드 간의 관계를 설정합니다. 이 연구는 ObMan와 DexYCB 데이터셋을 활용하여 제안된 방법의 효과성을 평가했습니다.

- **Performance Highlights**: 실험 결과, 손과 객체 간의 물리적 타당성이 개선되었음을 확인했습니다. 정량적 및 정성적으로 관찰된 결과는 제안된 상호작용 인식 그래프 주의 메커니즘이 손과 객체 포즈 추정을 통해 물리적 타당성을 획기적으로 향상시킴을 보여줍니다.



### Appearance Blur-driven AutoEncoder and Motion-guided Memory Module for Video Anomaly Detection (https://arxiv.org/abs/2409.17608)
Comments:
          13 pages, 11 figures

- **What's New**: 비디오 이상 탐지(VAD)의 새로운 방법으로, 우리는 제로샷 학습을 통한 교차 데이터셋 검증을 가능하게 하는 모션 가이드를 통한 메모리 모듈을 제안합니다. 이 방법은 Gaussian 블러를 적용한 이미지로부터 비정상적으로 흐릿한 특성을 인식합니다.

- **Technical Details**: 본 연구에서는 Gaussian 블러를 raw appearance 이미지에 추가하여 global pseudo-anomaly를 생성하고, multi-scale residual channel attention(MRCA)을 통해 정상 샘플의 이 pseudo-anomaly를 복원합니다. 수업 단계에서 모션 특성을 기록하여 메모리 아이템을 추출하고, 테스트 단계에서 이 정보를 활용해 정상성과 비정상 동작의 간극을 확대합니다.

- **Performance Highlights**: 세 가지 벤치마크 데이터셋에 대한 광범위한 실험에서 제안된 방법이 경쟁력 있는 성능을 발휘함을 입증했습니다. 특히, 테스트 중 적응 없이도 강력한 성능을 달성하며 교차 데이터셋 검증에서 우수함을 보여줍니다.



### Good Data Is All Imitation Learning Needs (https://arxiv.org/abs/2409.17605)
- **What's New**: 이 논문에서는 Autonomous/Automated Driving Systems (ADS)에서 기존의 teacher-student 모델, imitation learning, behavior cloning의 한계를 극복하기 위해 Counterfactual Explanations (CFEs)를 새로운 데이터 증강 기법으로 도입하였습니다.

- **Technical Details**: CFEs는 최소한의 입력 수정으로 결정 경계 근처에 있는 학습 샘플을 생성하여 수집된 데이터에 희귀한 사건을 포함시킴으로써 전문가 운전자의 전략을 더 포괄적으로 표현할 수 있게 해줍니다. 이 논문은 CARLA 시뮬레이터에서 CF-Driver를 통해 실험하며 SOTA 수준의 성과를 입증하였습니다.

- **Performance Highlights**: CF-Driver는 드라이빙 점수 84.2를 기록하며 이전 최고 모델보다 15.02% 향상된 성과를 달성하며, CFEs를 통해 드라이빙 전략의 개선을 보여줍니다. 또한, 연구 개발을 위해 생성된 데이터셋은 공개하여 후속 연구를 촉진할 계획입니다.



### TA-Cleaner: A Fine-grained Text Alignment Backdoor Defense Strategy for Multimodal Contrastive Learning (https://arxiv.org/abs/2409.17601)
- **What's New**: 이 논문에서는 CLIP와 같은 대규모 사전학습 모델이 데이터 중독된 백도어 공격에 취약하다는 점을 지적하며, 이를 해결하기 위한 새로운 방어 기법 TA-Cleaner를 제안합니다.

- **Technical Details**: TA-Cleaner는 CleanCLIP의 한계를 보완하기 위해 세밀한 텍스트 정렬 기법을 적용합니다. 매 에포크마다 긍정 및 부정 서브텍스트를 생성하고 이를 이미지와 정렬하여 텍스트 자기 감독(self-supervision)을 강화함으로써 백도어 트리거의 특징 연결을 차단합니다.

- **Performance Highlights**: 특히 BadCLIP과 같은 새로운 공격 기법에 대해 TA-Cleaner는 CleanCLIP보다 Top-1 ASR을 52.02%, Top-10 ASR을 63.88% 감소시키며 뛰어난 방어 성능을 보임을 보여주었습니다.



### Unifying Dimensions: A Linear Adaptive Approach to Lightweight Image Super-Resolution (https://arxiv.org/abs/2409.17597)
- **What's New**: 본 논문에서는 기존의 Window-based Transformer의 높은 계산 복잡성 문제를 해결하기 위해 linear focal separable attention (FSA)와 dual-branch 구조를 결합한 Linear Adaptive Mixer Network (LAMNet)를 제안했습니다. 이를 통해 경량화된 모델링이 가능해졌으며, inference 속도가 개선되었습니다.

- **Technical Details**: LAMNet는 ConvNet의 장점을 살려 adaptive spatial aggregation 기능을 갖춘 convolution 기반 구조입니다. 구체적으로, FSA는 2D 가중치 행렬을 희소화하면서도 높은 차원의 정보와 복잡한 관계를 모형화할 수 있도록 설계되었으며, Channel Selective Mixer (CSM)와 정보 교환 모듈 (IEM)도 포함되어 있습니다. DGFN 구조를 통해 spatial gating 구현 시 채널 정보의 다변성을 보장합니다.

- **Performance Highlights**: 실험 결과, LAMNet는 기존의 SA 기반 Transformer 방법들보다 우수한 성능을 달성하면서도 CNN만큼의 계산 효율성을 유지하며, inference 시간을 최대 3배 단축하는 성과를 보여주었습니다.



### Improving Fast Adversarial Training via Self-Knowledge Guidanc (https://arxiv.org/abs/2409.17589)
Comments:
          13 pages

- **What's New**: 이 논문에서는 Fast Adversarial Training (FAT)에서 발생하는 불균형 문제를 체계적으로 조사하고, 이를 해결하는 Self-Knowledge Guided FAT (SKG-FAT) 방법론을 제안합니다. SKG-FAT는 각 클래스의 학습 상태에 따라 차별화된 정규화 가중치를 할당하고, 학습 정확도에 따라 레이블을 동적으로 조정함으로써/adversarial robustness를 증가시키는 데 초점을 맞춥니다.

- **Technical Details**: FAT의 기존 방법들은 모든 훈련 데이터를 균일하게 최적화하는 전략을 사용하여/imbalanced optimization을 초래합니다. 본 연구에서는 클래스 간의 성능 격차를 드러내고, 이를 해소하기 위해/self-knowledge guided regularization과/self-knowledge guided label relaxation을 도입합니다. SKG-FAT는 자연적으로 생성되는 지식을 활용하여 adversarial robustness를 증대시킬 수 있습니다.

- **Performance Highlights**: SKG-FAT는 네 가지 표준 데이터셋에 대한 광범위한 실험을 통해/adversarial robustness를 향상시키면서도 경쟁력 있는 clean accuracy를 유지하며, 최신 방법들과 비교해 우수한 성능을 보였습니다.



### ID$^3$: Identity-Preserving-yet-Diversified Diffusion Models for Synthetic Face Recognition (https://arxiv.org/abs/2409.17576)
Comments:
          Accepted to NeurIPS 2024

- **What's New**: 본 논문에서는 심층 학습을 기반으로 한 합성 얼굴 인식(SFR) 모델인 ID³를 소개합니다. 이 모델은 개인 정보 보호를 고려하여 실제 얼굴 데이터의 분포를 모사하는 합성 얼굴 데이터셋을 생성하는 데 중점을 두고 있습니다.

- **Technical Details**: ID³ 모델은 ID-preserving loss를 활용하여 서로 다른 얼굴 속성을 지니면서도 동일한 개체의 정체성을 유지하는 얼굴 이미지를 생성합니다. 이론적으로는 제안한 손실 함수를 최소화하는 것이 조정된 조건부 로그 가능성의 하한을 최대화하는 것과 동등하다는 것을 보여줍니다.

- **Performance Highlights**: ID³는 다섯 가지 난이도 높은 벤치마크에서 기존의 최첨단 SFR 방법들 대비 약 2.4%의 성능 향상을 보였습니다.



### Flexiffusion: Segment-wise Neural Architecture Search for Flexible Denoising Schedu (https://arxiv.org/abs/2409.17566)
- **What's New**: Flexiffusion은 신속한 생성 과정을 최적화하기 위해 생성 단계와 네트워크 구조를 동시에 조정하는 새롭고 훈련이 필요하지 않은 Neural Architecture Search(NAS) 패러다임을 도입했습니다.

- **Technical Details**: Flexiffusion은 생성 과정을 등간격 단계로 나누고, 각 단계는 전면 단계(full step), 부분 단계(partial step), 무효 단계(null step)로 구성됩니다. 이 방법은 캐시 메커니즘을 사용해 모델 재훈련 없이 효율적인 탐색을 가능하게 합니다.

- **Performance Highlights**: Flexiffusion의 모델은 LDM-4-G의 경우 2.6배, Stable Diffusion V1.5에서는 5.1배의 속도 향상을 기록했습니다. 여러 데이터셋에서의 실험 결과 Flexiffusion이 이미지 생성 속도와 품질을 효과적으로 개선함을 확인했습니다.



### Pixel-Space Post-Training of Latent Diffusion Models (https://arxiv.org/abs/2409.17565)
- **What's New**: 이번 논문에서는 Latent Diffusion Models (LDMs)의 한계를 극복하기 위한 새로운 접근 방법을 제안합니다. LDMs는 이미지 생성 분야에서 큰 발전을 이루었지만, 고주파 세부 사항과 복잡한 구성 생성에서 여전히 어려움이 있음을 지적합니다.

- **Technical Details**: LDMs가 고주파 세부 사항을 잘 생성하지 못하는 이유는 기존 학습이 보통 $8 	imes 8$의 낮은 공간 해상도에서 이뤄지기 때문이라고 가설합니다. 이를 해결하기 위해 포스트 트레이닝 과정에서 pixel-space supervision을 추가하는 방법을 제안하였습니다.

- **Performance Highlights**: 실험 결과, pixel-space objective를 추가함으로써 최첨단 DiT transformer와 U-Net diffusion 모델의 supervised quality fine-tuning 및 preference-based post-training에서 시각적 품질 및 결함 지표가 크게 향상되었으며, 동일한 텍스트 정렬 품질을 유지했습니다.



### General Compression Framework for Efficient Transformer Object Tracking (https://arxiv.org/abs/2409.17564)
- **What's New**: 본 논문에서는 CompressTracker라는 새로운 모델 압축 프레임워크를 제안하여, 사전 훈련된 추적 모델의 사이즈를 최소한의 성능 저하로 경량화하는 방법을 소개합니다. 이 방법은 Transformer 기반의 객체 추적에서의 효율성을 향상시키기 위한 단계 구분 전략을 특징으로 합니다.

- **Technical Details**: CompressTracker는 사전 훈련된 교사 모델의 변환기 레이어를 여러 개의 단계로 나누어 각 단계에서 학생 모델이 교사 모델의 행동을 모방하도록 학습합니다. 또한, 교사 모델의 특정 단계를 학생 모델의 특정 단계와 랜덤하게 교체하여 훈련하는 교체 훈련(replacement training) 기법을 도입하였습니다. 이러한 방법은 학습 과정에서 예측 가이던스(prediction guidance)와 단계 별 특성 모방(stage-wise feature mimicking)을 추가하여 학생 모델의 성능을 향상시킵니다.

- **Performance Highlights**: CompressTracker-4는 OSTrack에서 압축되어 4개의 Transformer 레이어를 사용하며, LaSOT에서 약 96%의 성능을 유지(66.1% AUC)하면서 2.17배 속도 향상을 달성합니다. 이 모델은 훈련 시간도 20시간과 같이 단순화된 과정으로 줄였습니다.



### Dynamic Subframe Splitting and Spatio-Temporal Motion Entangled Sparse Attention for RGB-E Tracking (https://arxiv.org/abs/2409.17560)
Comments:
          15 pages, 8 figures, conference

- **What's New**: 이 논문에서는 동적 이벤트 서브프레임 분할 전략(Dynamic Event Subframe Splitting, DES)을 제안하여 이벤트 스트림을 더 미세한 이벤트 클러스터로 나누고, 이에 따라 상대적으로 느린 속도의 객체 추적이 가능하도록 합니다. 또한, 이러한 접근을 통해 시간적 정보를 최대한 활용합니다.

- **Technical Details**: 제안한 방법은 이벤트 기반 희소 주의(attention) 메커니즘(Event-based Sparse Attention, ESA)를 설계하여 시공간(spatial and temporal) 차원에서의 이벤트 특징 간 상호작용을 강화합니다. 동적 이벤트 서브프레임 분할 전략(DES)은 이벤트 스트림을 다수의 동적 서브프레임으로 나누어 모션 정보를 보존합니다. 또한, 시공간 모션 얽힘 추출기(Spatio-Temporal Motion Entanglement Extractor, STME)는 이벤트 기반 희소 주의 메커니즘을 결합하여 다양한 시간적 속성의 이동 정보를 추출합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 FE240 및 COESOT 데이터셋에서 기존 최첨단 방법보다 뛰어난 성능을 보여주었으며, 이벤트 데이터 처리를 위한 효과적인 방법을 제공합니다.



### Triple Point Masking (https://arxiv.org/abs/2409.17547)
- **What's New**: 본 논문에서는 제한된 데이터 환경에서 기존 3D 마스크 학습 방법의 성능 한계를 극복하기 위한 새로운 Triple Point Masking (TPM) 기법을 소개합니다. 이 기법은 다중 마스크 학습을 위한 확장 가능한 프레임워크로, 3D 포인트 클라우드 데이터를 위한 masked autoencoder의 사전 학습을 지원합니다.

- **Technical Details**: TPM은 기본 모델에 두 가지 추가 마스크 선택지(중간 마스크 및 낮은 마스크)를 통합하여 객체 복구 과정을 다양한 방법으로 표현할 수 있도록 설계되었습니다. 이 과정에서 고차원 마스킹 기법의 한계를 극복하고, 다양한 3D 객체에 대한 여러 표현을 고려하여 더 유연하고 정확한 완성 능력을 제공합니다. 또한, SVM 기반의 최적 가중치 선택 모듈을 통해 다운스트림 네트워크에 최적의 가중치를 적용하여 선형 정확성을 극대화합니다.

- **Performance Highlights**: TPM을 탑재한 네 가지 기본 모델은 다양한 다운스트림 작업에서 전반적인 성능 향상을 달성했습니다. 예를 들어, Point-MAE는 TPM 적용 후 사전 학습 및 미세 조정 단계에서 각각 1.1% 및 1.4%의 추가 성과를 보였습니다.



### CAMOT: Camera Angle-aware Multi-Object Tracking (https://arxiv.org/abs/2409.17533)
- **What's New**: 본 논문은 Multi-Object Tracking (MOT)을 위한 간단한 카메라 각도 추정기인 CAMOT를 제안합니다. 이 방법은 occlusion과 부정확한 거리 추정을 해결하는 데 중점을 둡니다.

- **Technical Details**: CAMOT는 비디오 프레임 내의 여러 객체가 평면에 위치해 있다는 가정을 바탕으로 객체 탐지를 통해 카메라 각도를 추정합니다. 이 방법은 각 객체의 깊이를 제공하여 pseudo-3D MOT를 가능하게 하고, 다양한 2D MOT 방법에 플러그인 형태로 적용될 수 있습니다.

- **Performance Highlights**: CAMOT를 ByteTrack에 적용했을 때 MOT17에서 63.8% HOTA, 80.6% MOTA, 78.5% IDF1를 기록하며, 기존의 깊이 추정기들보다 계산 비용이 훨씬 낮고 속도는 24.92 FPS에 달합니다.



### SimVG: A Simple Framework for Visual Grounding with Decoupled Multi-modal Fusion (https://arxiv.org/abs/2409.17531)
Comments:
          21pages, 11figures, NeurIPS2024

- **What's New**: 이번 연구에서는 Visual Grounding (VG) 문제를 해결하기 위한 새로운 프레임워크 SimVG를 제안합니다. 기존의 복잡한 모듈이나 아키텍처 대신, SimVG는 멀티모달 전이 학습 모델을 활용하여 시각-언어 기능 융합을 하위 작업으로부터 분리합니다.

- **Technical Details**: SimVG는 기존의 멀티모달 모델을 기반으로 하며, 객체 토큰(Object Tokens)을 포함하여 하위 작업(Task)과 사전 학습(Pre-training) 작업을 깊게 통합하는 방식으로 설계되었습니다. 동적 가중치 균형 증류(DWBD) 방법을 사용하여 다중 브랜치 동기식 학습 과정에서 간단한 브랜치의 표현력을 향상시킵니다. 이 브랜치는 경량 MLP로 구성되어, 구조를 단순화하고 추론 속도를 개선합니다.

- **Performance Highlights**: SimVG는 RefCOCO/+/g, ReferIt, Flickr30K 등 총 6개의 VG 데이터셋에서 실험을 실시한 결과, 효율성과 수렴 속도에서 개선을 이루었으며, 새로운 최첨단 성능을 달성했습니다. 특히, 단일 RTX 3090 GPU에서 RefCOCO/+/g 데이터셋에 대해 12시간 훈련하여 이룬 성과가 주목할 만합니다.



### Drone Stereo Vision for Radiata Pine Branch Detection and Distance Measurement: Integrating SGBM and Segmentation Models (https://arxiv.org/abs/2409.17526)
- **What's New**: 이 연구에서는 드론 기반의 가지치기 시스템을 개발하여, 전통적인 수동 가지치기의 안전 위험을 해결하고자 합니다. 이 시스템은 전문적인 가지치기 도구와 스테레오 비전 카메라를 활용하여 가지를 정확하게 감지하고 자를 수 있는 기능을 제공합니다.

- **Technical Details**: 시스템은 YOLO와 Mask R-CNN을 포함한 딥 러닝 알고리즘을 사용하여 가지 감지를 정확하게 수행하며, Semi-Global Matching 알고리즘을 통합하여 신뢰성 있는 거리 추정을 가능하게 합니다. 이를 통해 드론은 가지의 위치를 정밀하게 파악하고 효율적인 가지치기를 수행할 수 있습니다.

- **Performance Highlights**: 실험 결과에 따르면, YOLO와 SGBM의 결합 구현이 드론이 가지를 정확하게 감지하고 드론으로부터의 거리를 측정하는 데 성공적이라는 것을 보여줍니다. 이 연구는 가지치기 작업의 안전성과 효율성을 향상시키는 한편, 농업 및 임업 관행의 자동화를 위한 드론 기술의 발전에 중요한 기여를 합니다.



### JoyType: A Robust Design for Multilingual Visual Text Creation (https://arxiv.org/abs/2409.17524)
Comments:
          Under Review at AAAI 2025

- **What's New**: 이번 논문에서는 멀티링구얼 비주얼 텍스트 생성을 위한 JoyType이라는 새로운 접근법을 소개합니다. JoyType은 이미지 생성 과정에서 텍스트의 글꼴 스타일을 유지하도록 설계되었습니다.

- **Technical Details**: JoyType는 1 백만 개의 데이터 쌍으로 구성된 훈련 데이터셋, JoyType-1M을 기반으로 합니다. 각 데이터 쌍은 이미지, 해당 설명 및 이미지 내 글꼴 스타일에 대한 글리프 지침을 포함합니다. Font ControlNet을 개발하여 글꼴 스타일 정보를 추출하고 이미지 생성을 조정하며, 멀티 레이어 OCR 인식 손실(multi-layer OCR-aware loss)을 도입하여 작은 글꼴을 생성하는 모델의 능력을 강화합니다.

- **Performance Highlights**: JoyType은 기존 최첨단 방법들에 비해 현저하게 우수한 성능을 보였습니다. HuggingFace 및 CivitAI와 같은 다른 안정적인 확산 모델과 함께 다양한 스타일의 이미지를 생성하는 플러그인으로 기능할 수 있습니다.



### EAGLE: Egocentric AGgregated Language-video Engin (https://arxiv.org/abs/2409.17523)
Comments:
          Accepted by ACMMM 24

- **What's New**: EAGLE (Egocentric AGgregated Language-video Engine) 모델과 EAGLE-400K 데이터셋을 소개하여, 다양한 egocentric video 이해 작업을 통합하는 단일 프레임워크를 제공합니다.

- **Technical Details**: EAGLE-400K는 400K개의 다양한 샘플로 구성된 대규모 instruction-tuning 데이터셋으로, 활동 인식부터 절차 지식 학습까지 다양한 작업을 향상시킵니다. EAGLE는 공간적(spatial) 및 시간적(temporal) 정보를 효과적으로 캡처할 수 있는 강력한 비디오 멀티모달 대형 언어 모델(MLLM)입니다.

- **Performance Highlights**: 광범위한 실험을 통해 EAGLE는 기존 모델보다 우수한 성능을 발휘하며, 개별 작업에 대한 이해와 비디오 내용에 대한 전체적인 해석을 균형 있게 수행할 수 있는 능력을 강조합니다.



### SCOMatch: Alleviating Overtrusting in Open-set Semi-supervised Learning (https://arxiv.org/abs/2409.17512)
Comments:
          ECCV 2024 accepted

- **What's New**: 이번 논문에서는 Open-set Semi-Supervised Learning (OSSL)의 새로운 방법인 SCOMatch를 제안합니다. 이 방법은 기존 OSSL이 직면하는 과도한 신뢰의 문제를 해결하며, OOD(Out-of-Distribution) 샘플을 새로운 클래스(functional class)로 취급하여 더욱 효과적인 학습을 진행합니다.

- **Technical Details**: SCOMatch는 두 가지 주요 전략을 통해 OOD 샘플을 신뢰할 수 있는 레이블 데이터로 선택하고(Memory Queue), 기존 SSL 작업에 새로운 (K+1)-class SSL을 통합합니다. 이 과정에서 OOD 메모리 큐와 업데이트 전략을 사용하고, Close-set 및 Open-set self-training을 동시에 수행하게 됩니다.

- **Performance Highlights**: SCOMatch는 TinyImageNet 데이터셋에서 Close-set 정확도를 13.4% 향상시키는 등 여러 벤치마크에서 기존 OSSL 방법들을 뛰어넘는 성능을 보여 줍니다. 이는 포괄적인 실험과 시각화를 통해 각 구성 요소의 효과가 입증되었습니다.



### Uni-Med: A Unified Medical Generalist Foundation Model For Multi-Task Learning Via Connector-MoE (https://arxiv.org/abs/2409.17508)
- **What's New**: 이 논문은 다양한 시각 및 언어 작업을 위한 일반-purpose 인터페이스로서, 의료 분야의 multi-task learning을 위한 통합된 Multi-modal large language model (MLLM)을 제안합니다. 특히, 이전의 연구들이 처리하지 않았던 connector 문제를 해결하고자 합니다. 향후 Uni-Med는 의학 분야에서의 새로운 시도를 이루어낼 것입니다.

- **Technical Details**: Uni-Med는 범용 시각 feature extraction 모듈, connector mixture-of-experts (CMoE) 모듈, 그리고 LLM으로 구성된 의료 전문 기초 모델입니다. CMoE는 잘 설계된 라우터를 활용하여 projection experts의 혼합을 통해 connector에서 발생하는 문제를 해결합니다. 이 접근 방식을 통해 6개의 의료 관련 작업을 수행할 수 있습니다: 질문 응답(question answering), 시각 질문 응답(visual question answering), 보고서 생성(report generation), 지칭 표현 이해(referring expression comprehension), 지칭 표현 생성(referring expression generation) 및 이미지 분류(image classification).

- **Performance Highlights**: Uni-Med는 connector에서의 multi-task 간섭을 해결하려는 첫 번째 노력으로, 다양한 구성에서 CMoE를 도입하여 평균 8%의 성능 향상을 validates합니다. 이전의 최신 의료 MLLM과 비교할 때, Uni-Med는 다양한 작업에서 경쟁력 있거나 더 우수한 평가 지표를 달성하였습니다.



### Learning Quantized Adaptive Conditions for Diffusion Models (https://arxiv.org/abs/2409.17487)
- **What's New**: 이 논문에서는 낮은 함수 평가 수(NFE)로 고품질 이미지를 생성하는 데 있어 ODE(Ordinary Differential Equation) 경로의 곡률을 줄이기 위한 새로운 접근 방식을 제안합니다. 적응 가능한 조건을 활용하여 경로 곡률을 효과적으로 감소시키며, 추가적인 훈련 매개변수는 1%에 불과합니다.

- **Technical Details**: 제안된 방법은 경로의 교차 정도를 줄이기 위해 적응형으로 학습된 양자화 조건을 사용합니다. 이것은 경로 재배치 없이도 가능하며, 실제로 샘플링을 가속화할 수 있습니다. 기존의 방법들은 최적화 과정을 통해 경로의 교차를 줄이려고 했으나, 이 과정에서 마진 노이즈 분포를 유지하는 데 어려움이 있었습니다. 이러한 문제를 해결하기 위해 제안된 방법이 사용됩니다.

- **Performance Highlights**: CIFAR-10에서 6 NFE로 5.14 FID를 달성하였으며, FFHQ 64x64에서 6.91 FID, AFHQv2에서 3.10 FID를 기록합니다. 이는 기존의 확산 모델에 비해 우수한 성능을 보여줍니다.



### Revisiting Deep Ensemble Uncertainty for Enhanced Medical Anomaly Detection (https://arxiv.org/abs/2409.17485)
Comments:
          Early accepted by MICCAI2024

- **What's New**: 의료 이상 탐지(Anomaly Detection) 방법론에 있어 새로운 접근 방식인 Diversified Dual-space Uncertainty Estimation(D2UE)을 제안하며, 이 방법은 Redundancy-Aware Repulsion(RAR) 및 Dual-Space Uncertainty(DSU)를 통해 정상 샘플에 대한 동의와 이상 샘플에 대한 이견을 균형있게 조정합니다.

- **Technical Details**: D2UE 프레임워크는 다수의 Autoencoder 구조를 가진 N개의 학습자로 구성되며, 이들은 정상 샘플에 대해 동의하고 이상 샘플에 대해 이견을 나타내도록 설계되었습니다. RAR는 여러 학습자가 보다 다양한 feature space에서 학습하도록 유도하며, DSU는 입력과 출력 공간에서의 불확실성을 결합하여 이상 지역을 강조합니다.

- **Performance Highlights**: 다양한 백본을 가진 5개의 의료 벤치마크에 대해 종합 평가를 실시했으며, 실험 결과 D2UE가 기존의 최첨단 방법들보다 우수한 성능을 보였고, 각 구성 요소의 효과iveness도 입증되었습니다.



### TFS-NeRF: Template-Free NeRF for Semantic 3D Reconstruction of Dynamic Scen (https://arxiv.org/abs/2409.17459)
Comments:
          Accepted in NeuRIPS 2024

- **What's New**: TFS-NeRF는 복잡한 상호작용을 가진 동적 장면에 대한 템플릿 프리(Template-free) 3D 시맨틱(semantic) NeRF를 도입하며, 희소 또는 단일 시점 RGB 비디오로부터 학습합니다. 이 방법은 기존 LBS (Linear Blend Skinning) 방식보다 훈련 시간을 단축시키고, 각 개체의 동작을 비텐트(Given) 분리합니다.

- **Technical Details**: 본 프레임워크는 INN(Invertible Neural Network)를 사용하여 LBS 예측을 단순화하고, 개별 개체의 스킨닝 가중치를 최적화하여 각각의 Signed Distance Field(SDF)를 정확하게 생성합니다. 세부적으로, 우리는 의미 기반(ray sampling)으로 샘플링하여 각 개체의 독립적인 변환을 학습합니다.

- **Performance Highlights**: 광범위한 실험을 통해 본 방법이 복잡한 상호작용 속에서 변형 가능한 물체와 비변형 가능한 물체 모두에 대해 높은 품질의 재구성을 생성하며, 기존 방법들에 비해 훈련 효율성도 향상되었다는 것을 보여주었습니다.



### CadVLM: Bridging Language and Vision in the Generation of Parametric CAD Sketches (https://arxiv.org/abs/2409.17457)
- **What's New**: 이 논문은 Parametric Computer-Aided Design (CAD) 분야에서 CAD 생성 작업을 위한 새로운 Vision Language 모델인 CadVLM을 제안합니다. 이는 기존의 CAD 모델링 방법의 한계를 극복하고, 스케치 이미지와 텍스트를 결합한 멀티모달 접근법을 적용하였습니다.

- **Technical Details**: CadVLM은 사전 학습된 모델을 활용하여 엔지니어링 스케치를 효과적으로 조작할 수 있는 엔드 투 엔드 모델입니다. 이 모델은 스케치 원시 시퀀스 및 스케치 이미지를 통합하여 CAD 자동완성(CAD autocompletion) 및 CAD 자동 제약(CAD autoconstraint)과 같은 다양한 CAD 스케치 생성 작업에서 뛰어난 성능을 발휘합니다.

- **Performance Highlights**: CadVLM은 SketchGraphs 데이터셋에서 CAD 자동완성 및 CAD 자동 제약 작업에서 우수한 성능을 보였으며, Entity Accuracy, Sketch Accuracy, CAD F1 score로 평가된 새로운 평가 지표를 소개하였습니다.



### AgMTR: Agent Mining Transformer for Few-shot Segmentation in Remote Sensing (https://arxiv.org/abs/2409.17453)
Comments:
          accepted to IJCV

- **What's New**: 본 연구에서는 원거리 센싱 시나리오에서의 일부샷 세분화(Few-shot Segmentation, FSS)를 위해 새로운 에이전트 마이닝 변환기(Agent Mining Transformer, AgMTR)를 제안한다. AgMTR는 피사체의 픽셀 수준 세분화 문제를 해결하기 위해 지역 인식 에이전트를 활용하여 의미적 상관관계를 구축한다.

- **Technical Details**: AgMTR는 에이전트 학습 인코더(Agent Learning Encoder, ALE), 에이전트 집계 디코더(Agent Aggregation Decoder, AAD), 의미 정렬 디코더(Semantic Alignment Decoder, SAD)의 세 가지 구성 요소로 구성된다. ALE는 지원 픽셀에서 클래스별 의미를 효율적으로 마이닝하고, AAD는 레이블이 없는 이미지로부터 유용한 의미를 탐색한다. SAD는 쿼리 이미지와 에이전트 간의 의미적 일관성을 촉진하여 세분화를 돕는다.

- **Performance Highlights**: iSAID 원거리 센싱 벤치마크에서 제안된 AgMTR 방법은 최첨단 성능을 달성하였으며, PASCAL-5i와 COCO-20i와 같은 자연 시나리오에서도 경쟁력 있는 결과를 유지하였다.



### Rejection Sampling IMLE: Designing Priors for Better Few-Shot Image Synthesis (https://arxiv.org/abs/2409.17439)
- **What's New**: 최근 연구는 한정된 훈련 데이터로 딥 생성 모델을 학습하는 분야에서의 진전을 보여주고 있습니다. 본 논문에서는 Implicit Maximum Likelihood Estimation (IMLE) 기술을 보다 발전시켜, 시험 시 데이타와 훈련 시 데이터 간의 불일치를 해결하는 RS-IMLE라는 새로운 접근법을 제안합니다.

- **Technical Details**: 기존 IMLE 방식은 훈련 시 선택한 잠재 코드와 검사 시 샘플링되는 잠재 코드 간에 불일치가 발생하는 문제는 유지했습니다. RS-IMLE는 훈련에 사용되는 사전 분포를 조정하여 이러한 불일치를 극복하고, 훈련 데이터와 더욱 유사한 분포를 가진 샘플을 선택하게끔 합니다.

- **Performance Highlights**: RS-IMLE를 사용한 결과, 아홉 개의 소수 데이터 이미지 세트에서 GAN 및 기존 IMLE 기반 방법들과 비교하여 평균 45.9%의 FID 가치를 감소시키며, 이미지 생성 품질이 크게 향상되었습니다.



### HazeSpace2M: A Dataset for Haze Aware Single Image Dehazing (https://arxiv.org/abs/2409.17432)
Comments:
          Accepted by ACM Multimedia 2024

- **What's New**: 본 연구에서는 HazeSpace2M 데이터셋을 소개합니다. 이 데이터셋은 200만 개 이상의 이미지로 구성되어 있으며, 각기 다른 형태의 안개를 분류하여 디하징(dehazing) 효과를 향상시키기 위해 설계되었습니다.

- **Technical Details**: HazeSpace2M 데이터셋은 10가지 안개 강도 레벨과 다양한 장면(Fog, Cloud, Environmental Haze (EH))을 포함하고 있습니다. 본 연구에서는 먼저 안개 유형을 분류한 후, 특정 유형에 대한 디하징 기법을 적용하는 접근 방식을 사용하였습니다. 전통적인 방법과는 다르게, 이 기술은 안개 유형에 따른 디하징을 적용하여 실제 환경에서의 이미지 선명도를 개선합니다.

- **Performance Highlights**: ResNet50과 AlexNet을 사용한 벤치마킹 결과, 기존 합성 데이터셋에 대비하여 각각 92.75% 및 92.50%의 정확도를 달성했습니다. 그러나 HazeSpace2M 데이터셋을 테스트했을 때, 모델들은 각각 80%와 70%의 정확도에 그쳤습니다. 추가 실험 결과, 안개 유형 분류 후 전문 디하저를 사용하면 PSNR에서 2.41%, SSIM에서 17.14%, MSE에서 10.2%의 성능 향상을 얻을 수 있었습니다. 또한, SOTA 모델을 통해 우리 프레임워크를 적용하면 성능이 크게 개선됨을 알 수 있었습니다.



### AgRegNet: A Deep Regression Network for Flower and Fruit Density Estimation, Localization, and Counting in Orchards (https://arxiv.org/abs/2409.17400)
- **What's New**: 이 논문에서는 농업 산업의 노동력과 비용 문제를 해결하기 위한 자동화된 꽃과 과일 밀도 추정 기술을 제안합니다. 특히, AgRegNet이라는 딥 회귀 기반 네트워크를 사용하여, 탐지(Object Detection)나 다각형 주석(Polygon Annotation) 없이 꽃과 과일의 밀도, 개수, 위치를 추정합니다.

- **Technical Details**: AgRegNet은 U-Net 아키텍처에서 영감을 받아 개발된 U자형 네트워크로, 인코더-디코더 스킵 커넥션을 포함하고 있습니다. ConvNeXt-T를 수정한 구조로 특징을 추출하며, 포인트 주석(Point Annotation) 정보를 바탕으로 학습되고, 세그멘테이션 정보 및 주의 모듈(Attention Modules)을 활용하여 relevant한 꽃과 과일의 특징을 강조합니다.

- **Performance Highlights**: 실험 결과, AgRegNet은 구조적 유사도 지수(Structural Similarity Index, SSIM), 백분율 평균 절대 오차(percentage Mean Absolute Error, pMAE), 평균 평균 정밀도(mean Average Precision, mAP) 측면에서 높은 정확도를 달성했습니다. 특히, 꽃 이미지의 SSIM은 0.938, pMAE는 13.7%, mAP는 0.81이며, 과일 이미지의 경우 SSIM은 0.910, pMAE는 5.6%, mAP는 0.93으로 나타났습니다.



### The Overfocusing Bias of Convolutional Neural Networks: A Saliency-Guided Regularization Approach (https://arxiv.org/abs/2409.17370)
- **What's New**: 본 논문에서는 Neural Networks(신경망)가 훈련 데이터가 제한적일 때 특정 이미지 영역에 초점을 맞추는 경향을 설명하고, 이러한 경향을 개선하기 위한 새로운 정규화 방법인 Saliency Guided Dropout(SGDrop)를 제안합니다.

- **Technical Details**: SGDrop은 attribution methods(어트리뷰션 방법)을 사용하여 훈련 중 가장 중요한 특징들의 영향을 줄이고, 신경망이 입력 이미지의 다양한 영역에 주의를 분산시키도록 유도합니다. SGDrop의 구현은 훈련 과정에서 중요한 특징을 선택적으로 삭제하는 방식으로 진행됩니다.

- **Performance Highlights**: 여러 비주얼 분류 벤치마크에서 SGDrop을 적용한 모델은 더 넓은 어트리뷰션과 신경 활동을 보여주었으며, 이는 입력 이미지의 전체적인 관점을 반영합니다. 또한, SGDrop을 통해 일반화 성능이 향상되는 것을 확인할 수 있었습니다.



### Improving satellite imagery segmentation using multiple Sentinel-2 revisits (https://arxiv.org/abs/2409.17363)
- **What's New**: 최근 원격 탐사(data) 데이터의 분석은 대규모 및 다양한 데이터 셋에서 사전 훈련된 공유 모델을 사용하는 컴퓨터 비전의 기술을 차용함으로써 큰 혜택을 보고 있습니다. 본 논문에서는 여러 번 촬영된 동일 위치의 이미지에 대한 특성을 반영하여 사전 훈련된 원격 탐사 모델의 미세 조정(fine-tuning)에서 이러한 재방문(revisit)의 최적 사용 방안을 탐구합니다.

- **Technical Details**: 연구의 초점은 기후 변화 완화(climate change mitigation)와 관련된 전력 변전소(segmentation) 문제로, 여러 다중 시간 입력(multi-temporal input) 방식과 다양한 모델 아키텍처를 통해 이미지를 조합하는 방법을 테스트했습니다. 실험 결과, 모델의 잠재 공간(latent space)에서 여러 번의 재방문 이미지를 결합하는 것이 다른 방법보다 우수하다는 것을 발견했습니다. 또한, SWIN Transformer 기반 아키텍처가 U-net 및 ViT 기반 모델보다 더 높은 성능을 보였습니다.

- **Performance Highlights**: 이 연구는 재방문 데이터를 활용한 전력 변전소 분할(task)에서 성능 향상이 두드러졌으며, 그 결과는 별도의 건물 밀도 추정(task)에서도 일반화 가능성을 검증했습니다. 전체적으로, 재방문을 사용한 단순하면서도 효과적인 접근 방법이 원격 탐사 커뮤니티에 귀중한 통찰을 제공함을 확인했습니다.



### A vision-based framework for human behavior understanding in industrial assembly lines (https://arxiv.org/abs/2409.17356)
- **What's New**: 본 논문은 자동차 도어 제조와 관련하여 산업 조립 라인에서 인간 행동을 캡처하고 이해하기 위한 비전 기반 프레임워크를 도입합니다. 이 프레임워크는 고급 컴퓨터 비전 기술을 활용하여 작업자의 위치와 3D 자세를 추정하고, 작업 자세, 행동 및 작업 진행 상황을 분석합니다. 주요 기여는 CarDA 데이터셋의 도입으로, 이는 인간 자세 및 행동 분석을 지원하기 위해 현실적인 환경에서 캡처한 도메인 관련 조립 동작을 포함합니다.

- **Technical Details**: 이 프레임워크는 상태-of-the-art 방식의 인간 자세 추정(human pose estimation), 인체공학적 자세 평가(ergonomic postural evaluation), 인간 행동 모니터링(human action monitoring)을 사용하여, 조립 과정 동안 인간 활동의 신체적·인체공학적·운영 측면을 모니터링하고 평가하는 데 중점을 둡니다. CarDA 데이터셋은 실시간 평가를 가능하게 하며, 실제 산업 설정에서 적용성과 효과성을 보장합니다.

- **Performance Highlights**: 실험 결과는 제안된 접근 방식이 작업자의 자세를 분류하는 데 효과적임을 보여주며, 조립 작업 진행 상황을 모니터링하는 데 강력한 성능을 발휘합니다.



### SeaSplat: Representing Underwater Scenes with 3D Gaussian Splatting and a Physically Grounded Image Formation Mod (https://arxiv.org/abs/2409.17345)
Comments:
          Project page here: this https URL

- **What's New**: SeaSplat은 3D radiance fields의 최근 발전을 활용하여 실시간 수중 장면 렌더링을 가능하게 하는 방법입니다. 이 방법은 물체와 수중 환경의 시각적 특성을 고려한 물리적으로 기반한 수중 이미지 형성 모델을 통해 3D Gaussian Splatting (3DGS)과 결합됩니다.

- **Technical Details**: SeaSplat은 물질의 매개변수와 기본 3D 표현을 동시에 학습함으로써 장면의 진정한 색상을 복원하고, 장면의 기하학을 더 정확하게 추정합니다. 이 방법은 SeaThru-NeRF 데이터셋에서 수집된 실제 수중 장면에도 적용되며, 시뮬레이션으로 저하된 실제 장면에서도 효과적입니다.

- **Performance Highlights**: SeaSplat을 통해 수중 매질이 있는 장면에서 새로운 시점에서의 렌더링 성능이 향상되었으며, 장면의 진정한 색상을 복원하고 렌더링을 매질의 존재 없이 복원할 수 있었습니다. 또한, 수중 이미지 형성이 장면 구조 학습을 도우며, 깊이 지도 품질을 향상시킵니다.



### Energy-Efficient & Real-Time Computer Vision with Intelligent Skipping via Reconfigurable CMOS Image Sensors (https://arxiv.org/abs/2409.17341)
Comments:
          Under review

- **What's New**: 이 논문은 CMOS 이미지 센서(CMOS image sensor, CIS) 시스템을 재설계하여 에너지 효율성을 개선하는 새로운 방법을 제시합니다. 이 시스템은 비 사건성이 있는 영역이나 행을 선택적으로 생략하여 에너지를 절약하며, 이는 센서의 읽기 단계에서 수행됩니다.

- **Technical Details**: 제안된 시스템은 비디오 프레임 과정에서 에너지를 절감할 수 있도록 고안된 커스텀 형식의 재구성 가능한 CIS를 사용합니다. 새로운 마스킹 알고리즘이 실시간으로 생략 과정을 지능적으로 안내하여, 자율주행 및 증강/가상 현실 응용에 적합합니다. 이 시스템은 또한 애플리케이션 필요에 따라 표준 모드로도 작동할 수 있습니다. 하드웨어 알고리즘 협업 프레임워크에서 BDD100K 및 ImageNetVID 기반의 객체 탐지와 OpenEDS 기반의 시선 추정에서 평가하여 최대 53%의 에너지 비용 절감 효과와 SOTA 정확도를 달성했습니다.

- **Performance Highlights**: 제안된 알고리즘-하드웨어 공동 설계 프레임워크는 자율 주행 및 AR/VR 응용에 대해 46% (행 단위 생략), 53% (행 단위 생략), 52% (영역 단위 생략) 에너지 효율성을 달성하며 SOTA 정확도를 유지합니다.



### Block Expanded DINORET: Adapting Natural Domain Foundation Models for Retinal Imaging Without Catastrophic Forgetting (https://arxiv.org/abs/2409.17332)
Comments:
this http URL, C. Merk and M. Buob contributed equally as shared-first authors. D. Cabrera DeBuc, M. D. Becker and G. M. Somfai contributed equally as senior authors for this work

- **What's New**: 이 연구에서는 자기 지도 학습(self-supervised learning)과 파라미터 효율적인 미세 조정(parameter-efficient fine-tuning)을 이용하여 망막 이미징(retinal imaging) 작업을 위한 두 가지 새로운 기초 모델인 DINORET와 BE DINORET을 개발하였습니다.

- **Technical Details**: DINOv2 비전 트랜스포머(vision transformer)를 적응하여 망막 이미징 분류 작업에 활용하였으며, 두 모델 모두 공개된 색상 안저 사진(color fundus photographs)을 사용하여 개발 및 미세 조정을 진행하였습니다. 우리는 블록 확장(block expansion)이라는 새로운 도메인 적응(domain adaptation) 전략을 도입하였습니다.

- **Performance Highlights**: DINORET과 BE DINORET은 망막 이미징 작업에서 경쟁력 있는 성능을 보여주었고, 블록 확장 모델이 대부분의 데이터 세트에서 최고 점수를 기록했습니다. 특히 DINORET과 BE DINORET은 데이터 효율성 측면에서 RETFound을 초과하며, 블록 확장이 재학습 시의 재난적 망각(catastrophic forgetting)을 성공적으로 완화했다는 점이 주목할 만합니다.



### ChatCam: Empowering Camera Control through Conversational AI (https://arxiv.org/abs/2409.17331)
Comments:
          Paper accepted to NeurIPS 2024

- **What's New**: 이 연구에서는 사용자가 자연어로 카메라를 제어할 수 있는 새로운 시스템 ChatCam을 소개합니다. 이를 통해 영상 제작 과정에서의 기술적 장벽이 낮아지고, 전문적인 촬영 기법을 쉽게 적용할 수 있습니다.

- **Technical Details**: ChatCam은 사용자의 요청을 이해하고, CineGPT라는 GPT 기반의 오토회귀 모델 및 Anchor Determinator를 활용하여 카메라 경로를 생성합니다. 이 모델은 텍스트-경로 쌍 데이터셋에 기반하여 훈련되어 텍스트 조건에 따른 경로 생성을 가능하게 합니다.

- **Performance Highlights**: 실험을 통해 ChatCam의 카메라 운영에 대한 복잡한 지시를 해석하고 실행하는 능력을 입증하였으며, 실제 제작 환경에서의 가능성이 높음을 보여주었습니다.



### VL4AD: Vision-Language Models Improve Pixel-wise Anomaly Detection (https://arxiv.org/abs/2409.17330)
Comments:
          27 pages, 9 figures, to be published in ECCV 2024 2nd Workshop on Vision-Centric Autonomous Driving (VCAD)

- **What's New**: 이 논문에서는 기존의 anomaly segmentation 방법의 한계를 극복하기 위해 Vision-Language (VL) 인코더를 통합한 새로운 접근법을 제안합니다. 이로 인해 비정상 클래스를 더 잘 인식할 수 있게 됩니다.

- **Technical Details**: 제안된 VL4AD 모델은 max-logit prompt ensembling 및 class-merging 전략을 포함하여 텍스트 프롬프트를 통해 데이터 및 훈련이 필요 없는 비정상 감지를 가능하게 합니다. 이를 통해 VL 모델의 일반화된 지식을 활용합니다.

- **Performance Highlights**: VL4AD 모델은 널리 사용되는 벤치마크 데이터셋에서 경쟁력 있는 성능을 보여주며, 픽셀 단위의 비정상 탐지에서 의의 있는 발전을 이룹니다.



### Bi-TTA: Bidirectional Test-Time Adapter for Remote Physiological Measuremen (https://arxiv.org/abs/2409.17316)
Comments:
          Project page: this https URL

- **What's New**: 본 연구에서는 Test-Time Adaptation (TTA) 기법을 rPPG(원격 광체적맥파측정) 분야에 처음으로 도입했습니다. 이는 사전 학습된 모델이 추론( inference ) 중에 목표 도메인에 적응할 수 있도록 하여, 개인 정보 보호 문제로 인해 소스 데이터나 라벨이 필요하지 않게 만듭니다.

- **Technical Details**: Bi-TTA는 두 가지 전문가 지식 기반의 자가 감독( self-supervised ) 형태를 활용하여 rPPG 모델을 조정합니다. 여기에는 '전향 적응'(prospective adaptation) 모듈과 '후향 안정화'(retrospective stabilization) 모듈이 포함되어 있습니다. 전향 적응 모듈은 불필요한 도메인 노이즈를 제거하여 안정성을 높이며, 후향 안정화 모듈은 모델 파라미터를 동적으로 강화하여 과적합이나 기억 상실을 방지합니다.

- **Performance Highlights**: Bi-TTA는 기존의 TTA 알고리즘과 비교하여 비약적으로 향상된 적응 능력을 보여주었으며, 실험 결과에서 우수한 성능을 입증했습니다. 대규모 벤치마크가 마련되었으며, 이는 향후 rPPG 연구에 기여할 것입니다.



### Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation (https://arxiv.org/abs/2409.17313)
Comments:
          EMNLP 2024 Findings; project page: this https URL

- **What's New**: 이 연구는 Vision-Language Navigation (VLN) 작업을 위한 새로운 평가 프레임워크를 제안합니다. 이 프레임워크는 다양한 지침 범주에 대한 현재 모델을 더 세분화된 수준에서 진단하는 것을 목표로 합니다. 특히, context-free grammar (CFG)를 기반으로 한 구조에서 VLN 작업의 지침 카테고리를 설계하고, 이를 Large-Language Models (LLMs)의 도움으로 반자동으로 구성합니다.

- **Technical Details**: 제안된 평가 프레임워크는 atom instruction, 즉 VLN 지침의 기본 행동에 집중합니다. CFG를 사용하여 지침의 구조를 체계적으로 구성하고 5개의 주요 지침 범주(방향 변화, 수직 이동, 랜드마크 인식, 영역 인식, 숫자 이해)를 정의합니다. 이 데이터를 활용하여 평가 데이터셋 NavNuances를 생성하고, 이를 통해 다양한 모델의 성능을 평가하며 문제가 드러나는 경우가 많았습니다.

- **Performance Highlights**: 실험 결과, 모델 간 성능 차이와 일반적인 문제점이 드러났습니다. LLM에 의해 강화된 제로샷 제어 에이전트가 전통적인 감독 학습 모델보다 방향 변화와 랜드마크 인식에서 더 높은 성능을 보였으며, 반면 기존 감독 접근 방식은 선택적 편향으로 인해 원자 개념 변화에 적응하는 데 어려움을 겪었습니다. 이러한 분석은 VLN 방식의 향후 발전에 중요한 통찰력을 제공합니다.



### Disco4D: Disentangled 4D Human Generation and Animation from a Single Imag (https://arxiv.org/abs/2409.17280)
- **What's New**: 이번 논문에서 제안하는 Disco4D는 단일 이미지에서 4D 사람 모델과 애니메이션을 생성하는 새로운 Gaussian Splatting 프레임워크입니다. Disco4D는 기존 방식과 달리 SMPL-X 모델을 사용하여 인체와 의류를 효과적으로 분리하여 생성 세부 정보와 유연성을 크게 향상시킵니다.

- **Technical Details**: Disco4D는 SMPL-X 모델을 사용하여 인체를 모델링하고 Gaussian 모델을 통해 의류를 독립적으로 모델링합니다. 주요 기술 혁신으로는 1) 의류 Gaussians의 효율적인 학습과 적합, 2) Diffusion 모델을 사용하여 시각적으로 보이지 않는 부분을 모델링, 3) 각 의류 Gaussian에 대한 아이덴티티 인코딩 학습 등이 있습니다.

- **Performance Highlights**: Disco4D는 4D 인간 생성 및 애니메이션 작업에서 우수한 성능을 입증했습니다. 의류와 신체의 독립적인 재구성 덕분에 정밀한 카테고리화 및 추출이 가능하며, 다양한 편집 기능을 지원합니다. 또한, SMPL-X 모델을 기반으로 한 애니메이션 기능 향상 덕분에 복잡한 몸동작에 대한 의류의 반응을 세밀하게 조정할 수 있습니다.



### Walker: Self-supervised Multiple Object Tracking by Walking on Temporal Appearance Graphs (https://arxiv.org/abs/2409.17221)
Comments:
          ECCV 2024

- **What's New**: Walker는 희소한 bounding box 주석과 추적 레이블 없이 비디오에서 학습하는 첫 번째 self-supervised tracker입니다. 이는 다수의 객체 추적(MOT) 방법에서 필수적인 주석 작업을 크게 줄여줍니다.

- **Technical Details**: Walker는 quasi-dense temporal object appearance graph를 설계하고, 그래프에서 랜덤 워크를 최적화하여 인스턴스 유사성을 학습하는 새로운 multi-positive contrastive objective를 제안합니다. 이 알고리즘은 그래프 내 인스턴스 간의 상호 배타적인 연결 속성을 강화하여 MOT를 위한 학습된 토폴로지를 최적화합니다.

- **Performance Highlights**: Walker는 MOT17, DanceTrack, BDD100K에서 경쟁력 있는 성능을 달성하였고, 이전의 self-supervised trackers를 초월하며 주석 요구 사항을 400배까지 줄이면서도 우수한 결과를 보였습니다.



### Neural Network Architecture Search Enabled Wide-Deep Learning (NAS-WD) for Spatially Heterogenous Property Awared Chicken Woody Breast Classification and Hardness Regression (https://arxiv.org/abs/2409.17210)
- **What's New**: 최근 몇 년간 빠른 성장률과 높은 육계 수확량을 위한 집중적인 유전자 선택으로 인해 전 세계 가금류 산업은 '우디 브레스트(woody breast)'라는 어려운 문제에 직면하고 있습니다. 본 연구에서는 hyperspectral imaging (HSI)과 machine learning 알고리즘을 결합해 우디 브레스트 상태를 비침습적이고 객관적이며 높은 처리량으로 평가할 수 있는 방법을 제시합니다.

- **Technical Details**: 본 연구는 250개의 생닭 가슴살 필렛(sample)을 수집하여 정상, 경증, 중증으로 분류하였고, HSI 처리 모델 설계 시 공간적으로 이질적인 경도 분포를 고려했습니다. 이 연구에서는 HSI를 통해 WB 수준을 분류하고 샘플 경도 데이터와의 상관관계를 찾기 위한 회귀(regression) 모델을 구축했습니다. 신경망 구조 검색(neural architecture search, NAS)을 통해 NAS-WD라는 광범위-깊이 신경망 모델을 개발하였으며, NAS를 통해 자동으로 네트워크 구조와 하이퍼파라미터를 최적화했습니다.

- **Performance Highlights**: NAS-WD는 95%의 전반적인 정확도로 세 가지 WB 수준을 분류할 수 있으며, 기존의 전통적인 머신 러닝 모델보다 성능이 우수합니다. 스펙트럼 데이터와 경도 간의 회귀 상관관계는 0.75로, 전통적인 회귀 모델보다 더 높은 성능을 보여줍니다.



### 2024 BRAVO Challenge Track 1 1st Place Report: Evaluating Robustness of Vision Foundation Models for Semantic Segmentation (https://arxiv.org/abs/2409.17208)
Comments:
          arXiv admin note: substantial text overlap with arXiv:2409.15107

- **What's New**: 2024 BRAVO Challenge의 Track 1에서 Cityscapes 데이터셋으로 훈련된 모델을 제시하며, 다양한 out-of-distribution 데이터셋에서의 강건성을 평가합니다. 이 연구는 Vision Foundation Models (VFM)을 활용하여 DINOv2에 간단한 segmentation decoder를 붙여 전체 모델을 fine-tuning하여 우수한 성능을 보여줍니다.

- **Technical Details**: 이 연구에서는 DINOv2 VFM을 사용하여 semantic segmentation을 위한 pre-trained 모델을 fine-tuning합니다. 기본 구성에서 간단한 linear decoder를 사용하여 patch-level features를 segmentation logits로 변환합니다. 다양한 모델 크기, patch 크기, pre-training 전략 및 segmentation decoders를 실험하여 우리의 접근 방식의 효과를 평가합니다.

- **Performance Highlights**: 우리는 기존의 복잡한 모델들을 능가하여 이 챌린지에서 1위를 달성했습니다. 우리의 간단한 접근 방식이 어떻게 specialist 모델들보다 더 나은 성능을 내는지를 입증하며, 향후 연구에서 관심을 끌 수 있는 새로운 관찰도 제시합니다.



### AACLiteNet: A Lightweight Model for Detection of Fine-Grained Abdominal Aortic Calcification (https://arxiv.org/abs/2409.17203)
Comments:
          10 pages including references

- **What's New**: 이 연구에서는 경량화된 딥러닝 모델인 'AACLiteNet'을 제안하여, 고해상도의 Abdominal Aortic Calcification (AAC) 점수를 효과적으로 예측할 수 있도록 하였습니다. 기존의 자동화 모델들에 비해 정확도가 높고 메모리 사용량이 적어, 휴대용 컴퓨팅 장치에서 실용적으로 사용될 수 있는 특징이 있습니다.

- **Technical Details**: AACLiteNet은 경량화된 Convolutional Neural Network (CNN)과 효율적인 글로벌 주의 메커니즘을 통합하여 설계되었습니다. 이 모델은 소규모 데이터셋에서 학습할 수 있도록 최적화되어 있으며, 누적 및 세분화된 AAC 점수를 단일 헤드로 예측할 수 있습니다. 네트워크는 여러 단계의 2D convolution 작업을 통해 복잡한 특징 표현을 학습합니다. 특히, Depthwise Convolution (DWC) 기법을 채택하여 계산 비용과 메모리 사용량을 줄였습니다.

- **Performance Highlights**: AACLiteNet은 이전 모델에 비해 85.94%의 높아진 평균 정확도를 기록했으며, 이는 이전 최상의 모델인 81.98%에 비해 개선된 수치입니다. 또한, 계산 비용은 19.88배, 메모리 사용량은 2.26배 감소하여, 휴대용 기기에서 구현 가능함을 보여주었습니다.



### Cross Dataset Analysis and Network Architecture Repair for Autonomous Car Lane Detection (https://arxiv.org/abs/2409.17158)
- **What's New**: 본 연구에서는 자율주행 차량의 차선 인식 애플리케이션을 위한 교차 데이터세트 분석과 신경망 아키텍처 수리를 수행합니다. 제공된 아키텍처인 ERFCondLaneNet은 복잡한 형상의 차선을 탐지하는 데 어려움을 겪는 기존의 CondLaneNet을 개선한 것입니다.

- **Technical Details**: 이 연구에서 제안하는 ERFCondLaneNet은 CondLaneNet [liu_condlanenet_2021]과 ERFNet [romera_erfnet_2018]을 통합하여 만들어졌으며, Transfer Learning (TL) 프로토콜을 사용하여 두 가지 주요 차선 탐지 벤치마크인 CULane과 CurveLanes에서 테스트되었습니다. 이 기술은 성능을 유지하면서도 33% 적은 특징을 사용하여 모델 크기를 46% 줄였습니다.

- **Performance Highlights**: ERFCondLaneNet은 ResnetCondLaneNet과 비슷한 성능을 보이며, 이는 복잡한 지형을 가진 차선 탐지에서  충분한 정확성을 유지합니다. 학습 과정에서 기존 모델보다 적은 데이터로도 우수한 결과를 보여줍니다.



### An Art-centric perspective on AI-based content moderation of nudity (https://arxiv.org/abs/2409.17156)
Comments:
          To be published at the AI4VA (AI for Visual Arts) Workshop and Challenges at ECCV 2024

- **What's New**: 이번 연구에서는 예술적 나체 이미지에 대한 알고리즘 필터링 알고리즘의 성능을 분석하고, 성별 및 스타일 편향과 같은 기술적 한계를 발견했습니다. 또한, 예술적 나체 이미지 분류의 개선을 위해 다중 모달 제로샷 классифика는 방안을 제안하였습니다.

- **Technical Details**: 세 개의 공개된 NSFW (Not-Safe-For-Work) 이미지 분류 알고리즘을 사용하여 140개 이상의 예술적 나체 이미지의 성능을 비교했습니다. 우리는 최신 다중 모달 심층학습 모델(CLIp)을 활용하여 예술적 나체 분류를 향상시킬 것을 제안합니다.

- **Performance Highlights**: 실험 결과, 알고리즘은 예술적 나체 이미지를 음란물로 잘못 분류하는 등 높은 오검출률과 오탐률을 보였습니다. 제안된 다중 모달 접근법을 통해 성능이 크게 개선된다는 것을 확인했습니다.



### Robot See Robot Do: Imitating Articulated Object Manipulation with Monocular 4D Reconstruction (https://arxiv.org/abs/2409.18121)
Comments:
          CoRL 2024, Project page: this https URL

- **What's New**: 이 논문에서는 Robot See Robot Do (RSRD)라는 방법을 개발하여, 단일 모노큘러 RGB 인간 시연을 통해 가동 가능한 객체 조작을 모방할 수 있도록 로봇에게 학습 능력을 제공합니다. 이 방법은 단일 정적 다중 뷰 객체 스캔을 기반으로 하여, 로봇이 객체의 부품 움직임을 복구하고 이를 통해 객체의 경로를 모사할 수 있도록 합니다.

- **Technical Details**: RSRD는 4D Differentiable Part Models (4D-DPM)라는 방법을 제안하여, 모노큘러 비디오에서 3D 부품 움직임을 회복합니다. 이 접근 방식은 기능 필드를 활용하여 이터레이티브 최적화를 수행하며, 이는 기하학적 규제기를 사용하여 단일 비디오로부터 3D 움직임을 복구할 수 있게 합니다.

- **Performance Highlights**: RSRD는 10회의 실험에서 9개의 객체에서 평균 87%의 성공률을 기록했으며, 총 90회의 실험에서 최종 성공률이 60%에 도달했습니다. 이 모든 결과는 대규모 사전 훈련된 비전 모델로부터 얻은 기능 필드만을 통해 이루어졌습니다.



### EvMAPPER: High Altitude Orthomapping with Event Cameras (https://arxiv.org/abs/2409.18120)
Comments:
          7 pages, 7 figures

- **What's New**: 이번 연구는 이벤트 카메라를 사용하여 전통적인 CMOS 카메라의 한계를 극복하고, 어려운 조명 조건에서도 높은 해상도의 orthomosaic(정사영상)를 생성할 수 있는 새로운 접근법을 제시합니다.

- **Technical Details**: 연구팀은 고해상도의 동기화된 데이터 수집을 위한 하드웨어 및 소프트웨어 아키텍처를 개발하였으며, 이를 통해 이벤트 카메라 데이터를 기존의 orthomosaic 생성 도구와 통합하는 방법을 제안했습니다. 또한, 고속 비행 중의 어려운 조명 조건에서 촬영한 고해상도 이벤트 카메라 데이터셋을 공개했습니다.

- **Performance Highlights**: 이벤트 카메라를 사용한 orthomosaic 생성은 조명 조건에 구애받지 않으며, 기존의 RGB 카메라를 활용한 결과와 비교하여 좋은 성능을 보였습니다. 이러한 접근 방식은 향후 UAV(무인 항공기) 기반의 고해상도 이미지 생성에 중요한 방향성을 제시합니다.



### MALPOLON: A Framework for Deep Species Distribution Modeling (https://arxiv.org/abs/2409.18102)
- **What's New**: MALPOLON은 딥 종 분포 모델(Deep-SDM) 훈련 및 추론을 지원하는 새로운 프레임워크입니다. 사용자가 Python 언어에 대한 일반적인 지식만으로도 딥 러닝 방식의 SDM을 시험해볼 수 있도록 설계되었습니다.

- **Technical Details**: 이 프레임워크는 Python으로 작성되었으며 PyTorch 라이브러리를 기반으로 합니다. 모듈성이 뛰어나고, 사용자 맞춤형 데이터셋에 대한 신경망 훈련을 위한 버튼 클릭 예제가 제공됩니다. YAML 기반의 설정과 병렬 컴퓨팅, 다중 GPU 활용이 가능합니다.

- **Performance Highlights**: MALPOLON은 접근성을 높이고 성능 확장성을 지원하기 위해 open-source로 제공되며, GitHub와 PyPi에 배포되었습니다. 다양한 시나리오에서의 사용 예제 및 광범위한 문서화가 이루어져 있습니다.



### SKT: Integrating State-Aware Keypoint Trajectories with Vision-Language Models for Robotic Garment Manipulation (https://arxiv.org/abs/2409.18082)
- **What's New**: 이 연구에서는 다양한 의류 소목(garment categories)에 대해 단일 모델로 키포인트(keypoint) 예측을 개선하기 위해 비전-언어 모델(vision-language models, VLM)을 사용하는 통합 접근 방식을 제안합니다. 본 연구는 의류의 다양한 변형 상태를 관리하는 데 도움을 줄 수 있는 새로운 접근법을 제시합니다.

- **Technical Details**: 제안된 방법은 상태 인식 쌍 키포인트 생성(State-aware paired keypoint formation) 기법을 활용하여 다양한 의류 환경에 잘 일반화되는 상태 인식 키포인트 궤적(State-aware Keypoint Trajectories)을 생성합니다. 이를 통해 비주얼 시그널과 텍스트 설명을 함께 해석할 수 있으며, 고급 물리 시뮬레이터를 이용한 대규모 합성 데이터셋을 통해 훈련됩니다.

- **Performance Highlights**: 실험 결과, VLM 기반 방법이 키포인트 감지 정확성과 작업 성공률을 획기적으로 향상시켜 주목받았습니다. 이 연구는 VLM을 활용하여 장기적으로 홈 자동화 및 보조 로봇 분야에서의 폭넓은 응용 가능성을 제시하고 있습니다.



### PhoCoLens: Photorealistic and Consistent Reconstruction in Lensless Imaging (https://arxiv.org/abs/2409.17996)
Comments:
          NeurIPS 2024 Spotlight

- **What's New**: 이 논문에서는 기존의 렌즈 기반 시스템보다 크기, 무게 및 비용 측면에서 이점이 있는 렌즈 없는 카메라의 이미지 재구성을 개선하기 위해 새로운 두 단계 접근 방식을 소개합니다. 이 접근 방식은 일관성과 포토리얼리즘을 동시에 달성하는 데 중점을 두고 있습니다.

- **Technical Details**: 첫 번째 단계에서는 시공간 변동 표시 함수(Variation of Point Spread Function, PSF)에 적응하는 공간적으로 변하는 복원(deconvolution) 방법을 사용하여 저주파(low-frequency) 콘텐츠를 정확하게 재구성합니다. 두 번째 단계에서는 사전 훈련된 확산(diffusion) 모델에서 생성적 사전(Generative Prior)을 통합하여 고주파(high-frequency) 세부사항을 복원하며, 첫 번째 단계에서 복원된 저주파 콘텐츠에 조건을 부여하여 포토리얼리즘을 높입니다.

- **Performance Highlights**: 우리의 방법은 기존의 방법들과 비교하여 데이터 충실도(data fidelity)와 시각적 품질(visual quality) 사이의 우수한 균형을 달성했습니다. PhlatCam과 DiffuserCam의 두 가지 렌즈 없는 시스템에서 성능을 입증하며, 시각적 개선을 여러 평가 지표를 통해 보여주고 있습니다.



### The Hard Positive Truth about Vision-Language Compositionality (https://arxiv.org/abs/2409.17958)
Comments:
          ECCV 2024

- **What's New**: 이 논문에서는 CLIP와 같은 최첨단 비전-언어 모델의 조합 가능성(compositionality) 부족 문제를 다룹니다. 기존 벤치마크에서 힘들었던 점은 이러한 모델들이 하드 네거티브(hard negative)를 사용하여 개선된 성능을 과장해왔다는 것입니다. 이번 연구는 하드 포지티브(hard positive)를 포함한 대상에서 CLIP의 성능이 12.9% 감소하는 반면, 인간은 99%의 정확도를 보인다는 주장을 제기합니다.

- **Technical Details**: 저자들은 112,382개의 하드 네거티브 및 하드 포지티브 캡션으로 평가 데이터셋을 구축하였습니다. CLIP을 하드 네거티브로 파인튜닝(finetuning)할 경우 성능이 최대 38.7%까지 감소했으며, 하드 포지티브가 포함될 때의 효과를 분석하여 조합 가능한 성능을 개선할 수 있음을 밝혀냈습니다.

- **Performance Highlights**: CLIP 모델은 하드 네거티브로 훈련했을 때, 기존 벤치마크에서 성능이 개선되었음에도 불구하고, 하드 포지티브에 대한 성능이 동시에 저하되었습니다. 반면, 하드 네거티브와 하드 포지티브를 동시에 사용하여 훈련했을 때, 두 가지 모두 성능 개선이 이루어졌습니다. 이러한 연구는 조합 가능성에 대한 새로운 차원을 탐구하며 향후 연구 방향을 제시합니다.



### Visualization of Age Distributions as Elements of Medical Data-Stories (https://arxiv.org/abs/2409.17854)
Comments:
          11 pages, 7 figures

- **What's New**: 본 연구는 의학적 내러티브 시각화에서 질병의 연령 분포를 효과적으로 표현하기 위한 방법을 탐구합니다. 특히, 피코그램(pictogram) 변형의 효과를 비교 평가하여, 정보 이해도 및 미적 요소를 향상시키는 방법을 제시합니다.

- **Technical Details**: 이 연구는 3가지 피코그램 변형(바 형태의 피코그램, 스택 아래 피코그램, 주석)이 있는 18개의 시각화를 분석하였습니다. 총 72명의 참가자와 3명의 전문가 리뷰를 통해 평가를 진행했으며, 디자인 선택 기준(comprehension, aesthetics, engagement, and memorability)에 따라 결과를 도출하였습니다.

- **Performance Highlights**: 주석을 사용한 피코그램이 정보 이해도와 미적 요소에서 가장 효과적이었으나, 전통적인 바 차트는 참여도에서 선호되었습니다. 다양한 시각화 변형을 통한 사용자 기억력의 향상도 기록되었습니다.



### CASPFormer: Trajectory Prediction from BEV Images with Deformable Attention (https://arxiv.org/abs/2409.17790)
Comments:
          Under Review at ICPR 2024, Kolkata

- **What's New**: 이 논문에서는 고해상도 (High Definition, HD) 맵에 의존하지 않고 Bird-Eye-View (BEV) 이미지를 기반으로 다중 모드 모션 예측을 수행할 수 있는 Context Aware Scene Prediction Transformer (CASPFormer)를 제안합니다. 이는 자율 주행 및 운전 보조 시스템에 클라우드 서비스의 확장성을 제공할 수 있는 혁신적 방법입니다.

- **Technical Details**: CASPFormer는 래스터화된 BEV 이미지를 사용하여 다중 모드 벡터화된 궤적을 생성합니다. 이 시스템은 기존의 인식 모듈과 통합할 수 있으며, 포스트 프로세싱 없이 벡터화된 궤적을 직접 디코딩합니다. 디포머블 (Deformable) 어텐션 방식으로 궤적을 반복적으로 디코딩하며, 이는 컴퓨팅 효율성을 높이고 중요한 공간 위치에 초점을 맞출 수 있도록 합니다. 또한, 학습 가능한 모드 쿼리를 통합하여 다수의 씬-일관적인 궤적을 생성할 때 '모드 붕괴' 문제를 해결합니다.

- **Performance Highlights**: 우리의 모델은 nuScenes 데이터셋에서 평가되었으며, 여러 메트릭에서 최신 기술 수준의 성능을 달성했습니다. 특히, 다중 궤적 예측에서의 높은 정확도와 효율성을 보이며, 기존의 HD 맵 기반 방법들 대비 비용 효율적이고 확장 가능한 해결책을 제안합니다.



### LGFN: Lightweight Light Field Image Super-Resolution using Local Convolution Modulation and Global Attention Feature Extraction (https://arxiv.org/abs/2409.17759)
Comments:
          10 pages, 5 figures

- **What's New**: 본 논문에서는 가벼운 LF 이미지 초해상도(SR)를 위한 모델인 LGFN을 제안합니다. 이 모델은 서로 다른 관점의 로컬 및 글로벌 특성과 다양한 채널의 특성을 통합하여 성능을 향상시킵니다.

- **Technical Details**: LGFN은 CNN 기반의 특성 추출 모듈인 DGCE를 사용하여 로컬 특성을 추출하고, ESAM과 ECAM을 통해 글로벌 및 채널 특성을 효과적으로 추출합니다. 본 모델은 0.45M의 파라미터 수와 19.33G의 FLOPs를 가지며, 경쟁력 있는 성과를 달성하였습니다.

- **Performance Highlights**: LGFN 모델은 NTIRE2024 Light Field Super Resolution Challenge에서 Track 2 Fidelity & Efficiency 부문에서 2위, Track 1 Fidelity 부문에서 7위를 기록하였습니다.



### Robotic-CLIP: Fine-tuning CLIP on Action Data for Robotic Applications (https://arxiv.org/abs/2409.17727)
Comments:
          7 pages

- **What's New**: 본 논문에서는 Robotic-CLIP을 소개하여 로봇의 인식 능력을 강화하고자 합니다. Robotic-CLIP은 CLIP 모델을 기초로 하여 동작 데이터인 309,433개의 비디오(~740만 프레임)를 사용해 대조 학습(contrastive learning)을 통해 Fine-tuning되었습니다.

- **Technical Details**: Robotic-CLIP은 텍스트 지시와 비디오 프레임 간의 의미론적 정렬(semantic alignment)을 수행할 뿐만 아니라 비디오 내 동작을 효과적으로 포착하고 강조합니다. 두 개의 서로 다른 프레임을 사용하여 동작 관계를 더 잘 이해할 수 있도록 설계되었습니다.

- **Performance Highlights**: Robotic-CLIP은 다양한 언어 기반 로봇 작업에서 다른 CLIP 기반 모델들보다 뛰어난 성능을 보입니다. 실제 그리핑(grasping) 응용 프로그램에서도 실용적인 효과를 보여주었습니다.



### Explanation Bottleneck Models (https://arxiv.org/abs/2409.17663)
Comments:
          13 pages, 4 figures

- **What's New**: 이 논문은 사전 정의된 개념 세트에 의존하지 않고 입력에서 텍스트 설명을 생성할 수 있는 새로운 해석 가능한 심층 신경망 모델인 설명 병목 모델(XBMs)을 제안합니다.

- **Technical Details**: XBMs는 입력 데이터에서 텍스트 설명을 생성하고, 이를 기반으로 최종 작업 예측을 수행하는 모델입니다. XBMs는 사전 학습된 비전-언어 인코더-디코더 모델을 활용하여 입력 데이터에 나타난 개념을 포착합니다. 훈련 과정 중 '설명 증류(explanation distillation)' 기술을 사용하여 분류기의 성능과 텍스트 설명의 품질을 모두 확보합니다.

- **Performance Highlights**: 실험 결과, XBMs는 기존의 개념 병목 모델(CBMs)과 비교하여 더욱 유의미하고 자연스러운 언어 설명을 제공하며, 블랙박스 기준선 모델에 필적하는 성능을 달성하고 있습니다. 특히, XBMs는 테스트 정확도에서 CBMs을 크게 초월합니다.



### Provable Performance Guarantees of Copy Detection Patterns (https://arxiv.org/abs/2409.17649)
- **What's New**: 이번 연구에서는 Copy Detection Patterns (CDPs)의 인증 기술에 대한 새로운 이론적 프레임워크를 제시하여, 다양한 기준을 통해 CDP의 성능을 보장하는 방법을 모색합니다. 이를 통해 기존의 단순한 매트릭스에서 벗어나 보다 정교한 기법을 도입할 수 있게 됩니다.

- **Technical Details**: CDPs는 고해상도 인쇄나 레이저 각인 기술로 생성된 무작위 이진 패턴으로, 물리적 패턴과 디지털 템플릿을 비교하여 인증이 이루어집니다. 본 논문은 Hamming distance, cross-entropy, Neymann-Pearson likelihood ratio와 같은 통계적 테스트를 기반으로 한 세 가지 품질 측정 기준을 제안합니다.

- **Performance Highlights**: 새로운 접근 방식으로 CDP 인증의 신뢰성과 효과성을 향상시키기 위한 이론적 발견을 제공합니다. 특히, 복잡한 공격 기법에 대응하기 위해 다양한 결정 전략 및 융합 규칙을 고려하여 최적화 방법을 제시합니다.



### Diversity-Driven Synthesis: Enhancing Dataset Distillation through Directed Weight Adjustmen (https://arxiv.org/abs/2409.17612)
- **What's New**: 본 논문은 데이터 세트를 압축하면서도 핵심 특징을 보존하는 방법, 특히 데이터셋 디스틸레이션(dataset distillation)에 대한 새로운 접근 방식을 제안하고 있습니다. 기존 방법들이 각 합성 데이터 인스턴스를 개별적으로 생성하는 방식에 제한되어 있었다면, 이번 연구는 다양성을 높이기 위한 동적 및 방향성 가중치 조정 기술을 도입하여 합성 과정의 대표성과 다양성을 극대화합니다.

- **Technical Details**: 연구에서는 Batch Normalization (BN) 손실 내의 분산 정규화기(variance regularizer)가 합성 데이터의 다양성을 보장하는 핵심 요소임을 밝혔습니다. 반면, 평균 정규화기(mean regularizer)는 기대와 달리 다양성을 제약하는 역할을 하고 있습니다. 또한, 원본 데이터셋에서 단 하나의 감독(source of supervision) 역할을 하는 teacher 모델의 가중치를 동적으로 조정하는 메커니즘이 도입되어 있습니다.

- **Performance Highlights**: CIFAR, Tiny-ImageNet, ImageNet-1K 등 다양한 데이터셋을 대상으로 한 실험에서 제안된 방법이 높은 성능을 보였으며, 최소한의 계산 비용(<0.1%)으로도 매우 다양한 합성 데이터셋을 생성할 수 있음을 보여주었습니다. 이 연구는 데이터셋 디스틸레이션의 효율성을 높이는 데 기여할 것입니다.



### ZALM3: Zero-Shot Enhancement of Vision-Language Alignment via In-Context Information in Multi-Turn Multimodal Medical Dialogu (https://arxiv.org/abs/2409.17610)
- **What's New**: 이 논문에서는 ZALM3를 제안하여 다중 회의(Multi-turn) 다중 모달(Multimodal) 의료 대화에서 비전-언어 정합성(Vision-Language Alignment)을 향상시키는 Zero-shot 접근 방식을 소개합니다. 환자가 제공하는 저품질 이미지와 텍스트 간의 관계를 개선하기 위해 LLM을 활용하여 이전 대화 맥락에서 키워드를 요약하고 시각적 영역을 추출합니다.

- **Technical Details**: ZALM3는 이미지 이전의 텍스트 대화에서 정보를 추출하여 관련 지역(Regions of Interest, RoIs)을 확인하는 데 LLM과 비주얼 그라우딩 모델을 활용합니다. 이 접근 방식은 추가적인 주석 작업이나 모델 구조 변경 없이도 비전-언어 정합성을 개선할 수 있는 특징이 있습니다.

- **Performance Highlights**: 세 가지 다른 임상 부서에서 실시한 실험 결과, ZALM3는 통계적으로 유의한 효과를 입증하며, 기존의 간단한 승패 평가 기준에 대한 보다 정량적인 결과를 제공하는 새로운 평가 메트릭을 개발하였습니다.



### Let the Quantum Creep In: Designing Quantum Neural Network Models by Gradually Swapping Out Classical Components (https://arxiv.org/abs/2409.17583)
Comments:
          50 pages (including Appendix), many figures, accepted as a poster on QTML2024. Code available at this https URL

- **What's New**: 이 논문에서는 양자 신경망(Quantum Neural Network, QNN)의 구조적 한계를 극복하기 위해 고전적 신경망과 양자 신경망 사이의 점진적인 전환 전략, HybridNet을 제안합니다. 이는 정보 흐름을 유지하면서 고전적 신경망 레이어를 점진적으로 양자 레이어로 대체하는 프레임워크를 제공합니다.

- **Technical Details**: 제안된 HybridNet은 고전적 모델에서 양자 모델로의 전환을 통해 양자 구성이 신경망의 성능에 미치는 영향을 보다 면밀히 분석합니다. 연구에서는 FlippedQuanv3x3라는 새로운 양자 커널과 데이터 재업로드 회로(Data Reuploading Circuit)를 도입하여 고전적 선형 레이어와 동일한 입력 및 출력을 공유하는 양자 레이어를 구현합니다.

- **Performance Highlights**: MNIST, FashionMNIST, CIFAR-10 데이터셋에 대한 수치 실험을 통해 양자 구성요소의 체계적인 도입이 성능 변화에 미치는 영향을 분석했습니다. 연구 결과, 기존의 QNN 모델보다 더 효과적인 성능을 발휘할 수 있음을 발견하였습니다.



### Advancing Open-Set Domain Generalization Using Evidential Bi-Level Hardest Domain Scheduler (https://arxiv.org/abs/2409.17555)
Comments:
          Accepted to NeurIPS 2024. The source code will be available at this https URL

- **What's New**: 본 논문은 Open-Set Domain Generalization (OSDG) 문제를 다루며, 기존의 정해진 도메인 스케줄러와 비교하여 적응형 도메인 스케줄러의 효과를 제안합니다. 이를 통해 동적 환경에서의 데이터 배틀링에 대한 새로운 접근 방식을 제시합니다.

- **Technical Details**: 논문에서 제안하는 EBiL-HaDS (Evidential Bi-Level Hardest Domain Scheduler)는 도메인 신뢰도를 측정하는 방법을 사용하여 도메인 간의 프레젠테이션 순서를 동적으로 조정합니다. 이 방법은 follower network를 활용해 신뢰도를 평가하고, bi-level 최적화 기법을 사용하여 학습합니다.

- **Performance Highlights**: 실험 결과, EBiL-HaDS는 PACS, DigitsDG 및 OfficeHome 데이터셋에서 OSDG 성능을 크게 향상시키며, 기존의 임의적이거나 연속적인 도메인 스케줄링 방법보다 더 효과적인 성능 개선을 보였습니다.



### Robotic Environmental State Recognition with Pre-Trained Vision-Language Models and Black-Box Optimization (https://arxiv.org/abs/2409.17519)
Comments:
          Accepted at Advanced Robotics, website - this https URL

- **What's New**: 이번 연구에서는 로봇이 다양한 환경에서 자율적으로 탐색하고 작동하기 위해 필요로 하는 환경 상태 인식을 위한 새로운 방법을 제안합니다. 특히, 사전 훈련된 대규모 Vision-Language Models (VLMs)를 활용하여 환경 상태를 통합적으로 인식할 수 있는 방법을 개발하였습니다.

- **Technical Details**: VLM을 사용하여 Visual Question Answering (VQA) 및 Image-to-Text Retrieval (ITR) 작업을 수행합니다. 이를 통해 로봇은 문이 열려 있는지, 물이 흐르고 있는지와 같은 다양한 환경 상태를 인식할 수 있습니다. 또한, 블랙박스 최적화를 통해 적절한 텍스트를 선택하는 방식으로 인식 정확도를 향상시킬 수 있습니다.

- **Performance Highlights**: 실험을 통해 제안된 방법의 효과성을 입증하였고, Fetch라는 모바일 로봇에서 인식 행동에 적용하였습니다. 이 방법은 다양한 상태 인식을 가능하게 하며, 여러 개의 모델과 프로그램을 준비할 필요 없이 소스 코드 및 컴퓨터 자원의 관리를 용이하게 해줍니다.



### NeuroPath: A Neural Pathway Transformer for Joining the Dots of Human Connectomes (https://arxiv.org/abs/2409.17510)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 논문은 신경 이미지 데이터에서 구조적 연결성(Structural Connectivity, SC)과 기능적 연결성(Functional Connectivity, FC) 간의 결합 메커니즘에 대한 연구를 소개합니다. 특히 'NeuroPath'라는 새로운 생물학적 영감을 받은 딥 모델을 제안하여, SC와 FC의 쌍으로부터 복잡한 신경 구조의 특징 표현을 발견하고 인지 행동의 예측 및 질병 진단에 활용할 수 있습니다.

- **Technical Details**: NeuroPath 모델은 고차원 토폴로지의 표현 학습 문제로 구성된 SC-FC 결합 메커니즘을 다루며, 다중 헤드 자기 주의(multi-head self-attention) 메커니즘을 사용하여 SC와 FC의 쌍 그래프에서 다중 모달 특징 표현을 캡처합니다. 이를 통해 우리는 SC의 다양한 경로들이 FC를 지원하는 방식(예: cyclic loop)을 이해할 수 있게 됩니다.

- **Performance Highlights**: NeuroPath 지표는 HCP(인간 연결체 프로젝트) 및 UK Biobank와 같은 대규모 공개 데이터셋에서 검증되었으며, 기존의 최첨단 성능을 초과하여 인지 상태 예측과 질병 위험 진단에서 뛰어난 잠재력을 보였습니다.



### Shape-intensity knowledge distillation for robust medical image segmentation (https://arxiv.org/abs/2409.17503)
- **What's New**: 이 논문에서는 의료 이미지 분할을 위한 새로운 접근 방식을 제안합니다. 이는 shape-intensity prior 정보를 분할 네트워크에 통합하여 정확한 분할 결과를 얻는 것을 목표로 하고 있습니다.

- **Technical Details**: 제안된 방법은 teacher network에서 class-wise 평균화된 훈련 이미지를 사용하여 shape-intensity 정보를 추출한 후, knowledge distillation을 통해 이 정보를 student network에 전파합니다. 이 과정에서 student network는 추가적인 계산 비용 없이 shape-intensity 정보를 효과적으로 학습합니다.

- **Performance Highlights**: 다섯 가지 의료 이미지 분할 작업에서 실험한 결과, 제안된 Shape-Intensity Knowledge Distillation (SIKD)은 기존의 여러 baseline 모델들을 일관되게 개선하였으며, 특히 cross-dataset 일반화 능력이 향상되었습니다.



### Global-Local Medical SAM Adaptor Based on Full Adaption (https://arxiv.org/abs/2409.17486)
- **What's New**: 최근 시각 언어 모델(visual language models)인 Segment Anything Model (SAM)의 발전이 보편적인 의미 분할(universal semantic segmentation) 분야에서 큰 혁신을 가져왔습니다. 특히 Medical SAM adaptor (Med-SA)를 통해 의료 이미지 분할에 많은 도움을 주었습니다. 하지만 Med-SA는 부분적 적응(partial adaption) 방식으로 SAM을 미세 조정(fine-tunes)하여 개선의 여지가 있습니다.

- **Technical Details**: 이 논문에서는 전체 적응(full adaption)이 가능한 새로운 글로벌 의료 SAM 어댑터(GMed-SA)를 제안합니다. GMed-SA는 SAM을 전 세계적으로 적응할 수 있도록 설계되었습니다. 또한 GMed-SA와 Med-SA를 결합하여 글로벌-로컬 의료 SAM 어댑터(GLMed-SA)를 제안하며, SAM을 글로벌과 로컬 모두에 적응시킵니다.

- **Performance Highlights**: 우리는 도전적인 공개 2D 흑색종(segmentation dataset) 분할 데이터셋에서 GLMed-SA의 광범위한 실험을 진행했습니다. 결과는 GLMed-SA가 다양한 평가 메트릭(evaluation metrics)에서 여러 최첨단 의미 분할 방법들보다 뛰어난 성능을 발휘함을 보여주었으며, 우리의 방법의 우수성을 입증하였습니다.



### Study of Subjective and Objective Quality in Super-Resolution Enhanced Broadcast Images on a Novel SR-IQA Datas (https://arxiv.org/abs/2409.17451)
Comments:
          This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 이 연구에서는 저해상도 방송 콘텐츠의 슈퍼 해상도(Super-Resolution, SR) 이미지를 평가하기 위한 새로운 이미지 품질 평가(IQA) 데이터셋인 SREB(Super-Resolution Enhanced Broadcasting contents) 데이터셋을 소개합니다. 기존 데이터셋들과 달리 SREB는 원본 이미지의 고유 해상도를 그대로 사용하며, SR 이미지의 왜곡과 개선을 모두 고려하고 있습니다.

- **Technical Details**: SREB 데이터셋은 낮은 품질의 방송 콘텐츠 원본 이미지와 해당 SR 이미지, 그리고 품질 점수를 포함합니다. 주관적 품질 테스트를 수행하여 평균 의견 점수(Mean Opinion Score, MOS)를 도출하였으며, 다양한 SR 방법에 대한 주관적 품질 영향 요인을 분석하였습니다. 기존의 IQA 메트릭스의 성능을 비교 분석하여, 딥러닝 기반의 메트릭스가 더 우수한 성능을 보였음을 확인했습니다.

- **Performance Highlights**: SREB 데이터셋을 기반으로 한 연구 결과, 현재 IQA 메트릭스의 한계가 드러났으며, SR 이미지의 인식 품질을 더 잘 반영하는 IQA 메트릭스의 필요성이 강조되었습니다. 또한, 51명의 참여자로부터 420개의 주관적 품질 점수가 수집되어 실제 환경에서의 SR 이미지 평가를 지원합니다.



### Transient Adversarial 3D Projection Attacks on Object Detection in Autonomous Driving (https://arxiv.org/abs/2409.17403)
Comments:
          20 pages, 7 figures, SmartSP 2024

- **What's New**: 이 논문에서는 자율 주행 시나리오에서 물체 탐지를 타겟으로 한 새로운 적대적 3D 프로젝션 공격을 제안합니다. 기존의 고정된 적대적 패턴과 달리, 이 새로운 유형의 공격은 3D 표면에서의 일시적 수정과 같은 유연성을 제공합니다.

- **Technical Details**: 이 공격은 최적화 문제로 구성되며, 색상 매핑(color mapping) 및 기하변환 모델(geometric transformation models)을 결합하여 설계되었습니다. 특히, Thin Plate Spine (TPS) 알고리즘을 사용하여 2D 이미지를 3D 표면에 효과적으로 변형합니다.

- **Performance Highlights**: 실험 결과, YOLOv3 및 Mask R-CNN을 기준으로 한 공격의 성공률이 낮은 조도 조건에서 최대 100%에 달하는 것으로 나타났습니다. 이는 실제 자율주행 상황에서의 치명적인 결과를 초래할 수 있는 공격의 효과를 강조합니다.



### Data-efficient Trajectory Prediction via Coreset Selection (https://arxiv.org/abs/2409.17385)
- **What's New**: 이 논문에서는 복잡한 주행 시나리오(시나리오)에서 데이터 부족 문제와 과대표현된 주행 시나리오로 인한 데이터 중복 문제를 완화하기 위해 새로운 데이터 효율적인 훈련 방법인 'coreset selection'을 제안합니다. 이 방법은 다양한 난이도의 시나리오 간 비율을 조절하면서 중요 데이터를 선택하여, 훈련 성능을 유지하면서 데이터 용량을 줄입니다.

- **Technical Details**: 이 방법은 데이터셋의 난이도 수준에 따라 데이터를 그룹화하고, 각 샘플에 대한 하위 모듈러 이득(submodular gain)을 계산하여 가장 가치 있는 데이터를 선택합니다. 두 가지 선택 방법인 'Fixed Selection'과 'Balanced Selection'을 통해 데이터 분포를 조절하며, 특히 Balnced Selection 방법은 복잡한 시나리오에서 유리한 성과를 보여줍니다. 또한, coresets는 일반화 능력이 뛰어나고 다양한 모델에 대해 테스트되었습니다.

- **Performance Highlights**: Fixed Selection 방법을 이용한 coresets는 전체 데이터셋의 50%만으로도 성능 저하 없이 비슷한 결과를 보여주었으며, Balanced Selection 방법은 더 복잡한 주행 시나리오에서 현저한 성과를 기록했습니다. 선택된 coresets는 SOTA 모델인 HPNet에서도 유사한 성능을 발휘하여, 모델의 다양한 난이도 시나리오에서의 일반화 능력을 강화했습니다.



### Optical Lens Attack on Deep Learning Based Monocular Depth Estimation (https://arxiv.org/abs/2409.17376)
Comments:
          26 pages, 13 figures, SecureComm 2024

- **What's New**: 이 논문에서는 자율 주행 시스템에서 사용되는 단안 깊이 추정(MDE) 알고리즘의 보안 위험을 조사하고, LensAttack이라는 새로운 물리적 공격 기법을 제안합니다. 이 공격은 카메라에 광학 렌즈를 전략적으로 배치하여 물체의 깊이 인식을 조작합니다.

- **Technical Details**: LensAttack은 두 가지 공격 형식을 포함합니다: 오목 렌즈 공격(concave lens attack)과 볼록 렌즈 공격(convex lens attack)으로, 각기 다른 렌즈를 사용하여 잘못된 깊이 인식을 유도합니다. 두 렌즈의 배치는 물체의 크기를 변경하여 깊이 추정 결과에 영향을 미치며, 이를 수학적 모델로 구축하여 다양한 공격 매개변수를 고려합니다.

- **Performance Highlights**: 시뮬레이션 및 실험을 통해 LensAttack의 효과성을 입증했으며, 세 가지 최신 MDE 모델에 대해 11.48%와 29.84%의 평균 에러율을 기록했습니다. 이러한 결과는 자율 주행 시스템의 깊이 추정 정확도에 대한 LensAttack의 중대한 영향을 강조합니다.



### Implicit Neural Representations for Simultaneous Reduction and Continuous Reconstruction of Multi-Altitude Climate Data (https://arxiv.org/abs/2409.17367)
Comments:
          arXiv admin note: text overlap with arXiv:2401.16936

- **What's New**: 이번 논문에서는 다중 고도 풍속 데이터 분석 및 저장을 위한 심층 학습 프레임워크인 GEI-LIIF를 제안합니다. 이 프레임워크는 차원 축소(dimensionality reduction), 교차 모드 예측(cross-modal prediction), 슈퍼 해상도(super-resolution)를 동시에 지원하여 기존의 방법론보다 우수한 성능을 보입니다.

- **Technical Details**: GEI-LIIF는 고해상도 데이터의 효과적인 회복을 위해 임시 신경망(implicit neural networks)을 사용합니다. 이 접근 방식은 고해상도 풍속 데이터를 저해상도로 축소한 후, 연속적인 슈퍼 해상도 표현을 학습하는 방식으로 작동합니다. 구체적으로, 별도의 입력 모드에 구애받지 않는 모드 특정 저차원 표현을 학습하기 위한 새로운 잠재 손실 함수(latent loss function)를 제안합니다.

- **Performance Highlights**: 제안된 방법은 슈퍼 해상도 품질 및 압축 효율성(compression efficiency) 면에서 기존의 방법들을 초월한다고 입증되었습니다. 실험 결과, 기후 변화 분석 및 풍력 에너지 최적화에 유용한 다중 모드 형태로 풍속 패턴을 추정할 수 있는 가능성을 보여줍니다.



### Multi-scale decomposition of sea surface height snapshots using machine learning (https://arxiv.org/abs/2409.17354)
- **What's New**: 이번 연구는 고해상도 Sea Surface Height (SSH) 데이터를 사용하여 균형 운동 (BM)과 비균형 운동 (UBM)으로 SSH를 분해하는 새로운 기법을 제안합니다. 특히, ZCA 흰색화 (whitening) 기술과 데이터 증강 (data augmentation)을 통해 다양한 공간 스케일에서의 분해 문제를 해결하려고 합니다.

- **Technical Details**: 연구에서는 ZCA 변환을 통해 UBM을 처리하기 전에 흰색화하여 여러 스케일에서의 정보 증가를 꾀하며, 전통적인 방법에 비해 훈련 안정성 및 계산 효율성을 개선합니다. 입력 SSH 데이터는 Agulhas retroflection 지역의 고해상도 글로벌 해양 시뮬레이션 데이터에서 가져왔고, 다양한 데이터를 처리하기 위해 회전 증강 및 합성 샘플 생성을 사용했습니다.

- **Performance Highlights**: 연구 결과, 제안된 기법은 기존의 딥러닝 모델에 비해 다중 스케일 데이터 처리에서 더 나은 성능을 보여주었으며, BM과 UBM의 정확한 분해를 가능하게 했습니다. 특히, ZCA 흰색화 기법이 훈련 안정성과 모델의 일반화 능력에 긍정적인 영향을 미쳤음을 증명했습니다.



### An Integrated Deep Learning Framework for Effective Brain Tumor Localization, Segmentation, and Classification from Magnetic Resonance Images (https://arxiv.org/abs/2409.17273)
Comments:
          36 pages, 27 figures, 5 tables

- **What's New**: 본 연구는 자기공명영상(MRI)을 바탕으로 뇌종양의 조기 진단을 위한 딥러닝(DL) 프레임워크를 제안합니다. 특히 이 연구에서는 뇌신경에서 발생하는 다양한 형태의 종양을 정확하게 국소화(localize)하고 분할(segment)하며 등급을 분류(classify) 할 수 있는 방법론을 다룹니다.

- **Technical Details**: 링크넷(LinkNet) 프레임워크를 VGG19에서 영감을 받은 인코더 아키텍처로 개선하여 멀티모달(multi-modal) 종양 특징 추출을 향상시켰으며, 공간 및 그래프 주의 메커니즘(spatial and graph attention mechanisms)을 통해 특징 강조 및 상호 특징 관계를 정제합니다. 이후, 세레즈넷101(SeResNet101) CNN 모델을 인코더 백본으로 통합하여 종양을 분할하였으며, 이로 인해 96% IoU 점수를 달성하였습니다. 분할된 종양을 분류하기 위해 세레즈넷152(SeResNet152) 특징 추출기와 적응형 부스팅(classifier)을 결합하여 98.53%의 정확도를 실현하였습니다.

- **Performance Highlights**: 제안된 모델들은 뚜렷한 성과를 보이며, 의료 AI의 발전을 통해 조기 진단을 가능하게 하고 환자에 대한 보다 정확한 치료 옵션을 제공할 가능성을 지니고 있습니다.



### AIM 2024 Challenge on Efficient Video Super-Resolution for AV1 Compressed Conten (https://arxiv.org/abs/2409.17256)
Comments:
          European Conference on Computer Vision (ECCV) 2024 - Advances in Image Manipulation (AIM)

- **What's New**: 본 연구에서는 비디오 초해상도(Video Super-Resolution, VSR) 문제를 해결하기 위한 새로운 실시간 프레임워크를 제안합니다. 기존의 VSR 방법론들은 높은 계산 요구사항으로 인해 저FPS 및 낮은 전력 효율을 초래하는데, 이 연구에서는 퍼포먼스를 높이면서도 실제 사용 환경에 적합한 최적화를 제공합니다.

- **Technical Details**: 제안된 두 가지 애플리케이션(540p에서 4K로의 확대 및 360p에서 1080p로의 확대) 각각에 대해 4K 해상도의 고품질 테스트 세트를 사용하여 최신 비디오 코덱인 AV1을 통해 비디오를 압축했습니다. 모든 제안된 방법은 각 프레임을 독립적으로 처리하여 효율성을 높입니다.

- **Performance Highlights**: 제안된 방법들이 기존의 침 인터폴레이션 기법들보다 VMAF 및 PSNR 개선을 이루었으며, 대부분의 솔루션은 150K 이하의 파라미터를 가지고 250 GMACs 미만의 연산량으로 24-30FPS의 실시간 초해상도 처리가 가능합니다.



### MODEL&CO: Exoplanet detection in angular differential imaging by learning across multiple observations (https://arxiv.org/abs/2409.17178)
- **What's New**: 이 연구에서는 태양계 외부 행성(exoplanets)의 직접 이미징(direct imaging)에서 발생하는 신호 간섭(nuisance model)을 구축하기 위한 새로운 방법을 제안합니다. 기존의 관측에 의존하는 방법이 아닌, 슈퍼바이즈드 딥 러닝(supervised deep learning) 기술을 활용하여 다수의 관측 아카이브를 통해 모델링하는 접근 방식을 사용합니다.

- **Technical Details**: 제안된 접근법은 신호를 재구성하는 과제로 변환하고 데이터의 두 가지 보완적 표현으로부터 간섭의 구조를 캡처합니다. 기존의 참조 차별 이미징(reference differential imaging) 접근 방식과 달리, 제안된 모델은 고차 비선형적이며 명시적인 이미지 간 유사성 측정 및 차감 과정을 사용하지 않습니다. 또한 학습 가능한 공간 특성의 통계적 모델링을 포함하여 탐지 민감도(detection sensitivity)와 이질적 데이터에 대한 강인성을 향상시킵니다.

- **Performance Highlights**: VLT/SPHERE 기기의 여러 데이터 세트에 이 알고리즘을 적용한 결과, PACO 알고리즘과 비교하여 우수한 정밀도-재현율(precision-recall) 균형을 보여줍니다. 특히 ADI에 의해 유도되는 다양성이 가장 제한적일 때, 제안된 접근 방식이 다수의 관측을 통해 정보를 학습할 수 있는 능력을 지원합니다.



### Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models (https://arxiv.org/abs/2409.17146)
- **What's New**: Molmo는 현재 공개된 VLM 중에서 가장 최신의 성능을 자랑하며, 독점적인 데이터가 아닌 새롭게 수집된 고품질 데이터로 구성된 이미지를 설명하는 고급 캡션 데이터셋을 기반으로 하고 있습니다. 이 연구는 VLM을 처음부터 구축하는 데 필요한 기본 지식을 제공합니다.

- **Technical Details**: Molmo 모델은 기존의 비전 인코더와 언어 모델을 결합하여 만들어졌습니다. 이 과정에서는 이미지로부터 자세하고 질 높은 설명을 생성하는 새로운 데이터셋인 PixMo를 사용하고, 60~90초 동안 음성으로 설명하도록 요구하여 다양한 내용을 포괄하도록 했습니다. 모델 훈련은 다단계 과정이 아닌, 간단한 훈련 파이프라인을 통해 진행되었습니다.

- **Performance Highlights**: Molmo-72B 모델은 학술 벤치마크에서 최고의 점수를 기록했으며, GPT-4o와 비교했을 때 사용자 선호도 순위에서 두 번째에 올랐습니다. Molmo-1B 모델은 효율적인 성능을 보이며 GPT-4V와 근접한 결과를 보여주었고, 전체적으로 많은 상업적 시스템을 능가하는 성능을 발휘했습니다.



### DreamWaltz-G: Expressive 3D Gaussian Avatars from Skeleton-Guided 2D Diffusion (https://arxiv.org/abs/2409.17145)
Comments:
          Project page: this https URL

- **What's New**: 이 논문은 텍스트 기반의 3D 아바타 생성 프레임워크인 DreamWaltz-G를 소개한다. 이 프레임워크는 Skeleton-guided Score Distillation과 Hybrid 3D Gaussian 아바타 표현을 핵심으로 하여, 보다 일관성 있는 아바타 생성을 목표로 한다.

- **Technical Details**: DreamWaltz-G는 두 가지 단계로 아바타를 생성하는 방식으로, (I) Canonical Avatar Generation 단계에서 텍스트 설명을 바탕으로 기본 3D 아바타를 생성하고, (II) Animatable Avatar Learning 단계에서 이 아바타를 SMPL-X로 리깅하고 애니메이션을 추가하는 최적화를 진행한다.

- **Performance Highlights**: 광범위한 실험을 통해 DreamWaltz-G는 기존 방법들과 비교하여 시각적 품질과 애니메이션 표현력 면에서 우수한 성능을 발휘하며, 인상적인 3D 아바타 생성 및 애니메이션 수행 능력을 입증했다.



### Attention Prompting on Image for Large Vision-Language Models (https://arxiv.org/abs/2409.17143)
Comments:
          Website, see this https URL

- **What's New**: 본 연구에서는 Attention Prompting on Image (𝒜⁢𝒫⁢ℐ𝒜𝒫ℐ)라는 새로운 프롬프트 기법을 제안하여, 원본 이미지 위에 텍스트 쿼리 기반 주의 열지도를 오버레이함으로써 LVLM의 성능을 향상시킵니다.

- **Technical Details**: 이 기법은 보조 LVLM 모델을 활용하여 입력 이미지에 대한 주의 열지도를 생성합니다. 이때 CLIP과 같은 이미지-텍스트 매칭 모델의 cls 토큰 유사도 점수를 기반으로 하여 열지도를 만들어 냅니다. 생성된 열지도는 원본 이미지의 픽셀 값에 단순히 곱해져 LVLM의 실제 입력 이미지가 됩니다.

- **Performance Highlights**: Attention Prompting on Image는 LLaVA-1.5 모델의 MM-Vet, LLaVA-Wild 벤치마크에서 각각 3.8% 및 2.9%의 성능 향상을 보여줍니다.



### Streaming Neural Images (https://arxiv.org/abs/2409.17134)
Comments:
          IEEE International Conference on Image Processing (ICIP)2024

- **What's New**: 본 논문은 Implicit Neural Representations (INRs)의 이미지 압축에서의 기존 한계를 분석하고, 계산 비용, 성능 불안정성 및 견고성과 같은 중요한 요인을 제시합니다.

- **Technical Details**: INRs는 신호를 지속적으로 설명하는 함수로 매핑하여 RGB 값을 생성하는 방식으로, 신경망(Neural Network)을 사용하여 이 함수(ϕ)를 학습합니다. 또한, SPINR(Streaming Progressive INRs) 방법론을 소개하여 이미지 압축 및 전송에서의 여러 문제를 해결합니다.

- **Performance Highlights**: 각종 실험을 통해 INRs의 강화된 압축 능력을 보였으며, 기존 압축 방식인 JPEG 및 JPEG2000과 비교하여 그 잠재력을 강조합니다.



### Small data deep learning methodology for in-field disease detection (https://arxiv.org/abs/2409.17119)
Comments:
          9 pages

- **What's New**: 본 연구에서는 농업 질병, 특히 감자에서 발생하는 연한 증상을 조기에 감지할 수 있는 첫 번째 머신러닝 모델을 제안합니다. 이 모델은 필드에서 직접 촬영된 고해상도 RGB 이미지를 분석하여 기존 문헌의 한계를 극복하고 실제 적용 가능성을 제시합니다.

- **Technical Details**: 제안된 ISD4L(In-field Small Data Disease Detection with Deep Learning) 방법론은 고해상도 이미지를 패치(patch)로 나누고, 이 패치를 사용한 훈련을 통해 진단 모델을 학습합니다. 이 모델은 깊은 합성곱 신경망(convolutional neural networks)과 초점 손실 함수(focal loss function)를 활용하며, 데이터 증강(data augmentation) 기법을 통해 적은 수의 고해상도 이미지로도 효과적인 훈련이 가능합니다.

- **Performance Highlights**: 개발된 모델은 테스트 데이터셋에서 모든 늦은 흑색병(latent blight) 사례를 올바르게 감지하며, 초기 증상을 식별하는 데 있어 높은 정확성과 효과성을 입증했습니다. 이러한 결과는 농업에서의 질병 및 해충 조기 감지를 위한 머신러닝의 잠재적 활용성을 강화합니다.



### MorphoSeg: An Uncertainty-Aware Deep Learning Method for Biomedical Segmentation of Complex Cellular Morphologies (https://arxiv.org/abs/2409.17110)
- **What's New**: 이 논문에서는 생물학적 세포의 복잡한 형태를 효과적으로 분할하기 위한 새로운 벤치마크 데이터셋인 Ntera-2 (NT2) 세포를 소개하고, 동 불확실성을 인식하는 딥러닝 프레임워크인 MorphoSeg를 제안합니다.

- **Technical Details**: MorphoSeg는 저확률 영역에서 가상의 이상치를 샘플링하는 방식을 통하여 세포 분할의 경계를 개선하는 방법입니다. 이 접근법은 TransUNet을 기반으로 하여 불규칙한 세포 형상과 훈련의 어려움을 해결합니다.

- **Performance Highlights**: MorphoSeg는 Dice Similarity Coefficient (DSC)를 80.35%에서 86.57%로 향상시키고, Hausdorff Distance (HD95)를 21.98에서 15.75로 감소시키는데 성공하여 정확도가 크게 향상되었습니다.



### Unveiling Ontological Commitment in Multi-Modal Foundation Models (https://arxiv.org/abs/2409.17109)
Comments:
          Qualitative Reasoning Workshop 2024 (QR2024) colocated with ECAI2024, camera-ready submission; first two authors contributed equally; 10 pages, 4 figures, 3 tables

- **What's New**: 이번 논문은 다중 모달 심층 신경망(DNN)에서 학습된 개념의 슈퍼클래스 계층 구조를 추출하는 방법을 제안합니다. 이를 통해 질적 추론(qualitative reasoning, QR) 모델과의 검증 및 확인을 위한 단계로 나아갑니다.

- **Technical Details**: 우리는 DNN의 텍스트 입력 모달리티를 사용하여 리프 개념의 임베딩을 얻고, 이를 계층적 클러스터링을 통해 의미적 유사성을 기반으로 하는 슈퍼클래스 개념을 라벨링합니다. 제안된 방법은 다중 모달 DNN의 중간 표현에서 간단한 온톨로지를 추출하고 검증할 수 있도록 돕습니다.

- **Performance Highlights**: 실험 결과, 제안된 방법이 의미 있는 온톨로지를 추출할 수 있고, 주어진 온톨로지와의 불일치성을 밝혀낼 수 있음을 보여주었습니다. 또한, QR 모델의 추출 및 삽입에 대한 잠재적 응용 가능성을 논의하였습니다.



### Text2CAD: Generating Sequential CAD Models from Beginner-to-Expert Level Text Prompts (https://arxiv.org/abs/2409.17106)
Comments:
          Accepted in NeurIPS 2024 (Spotlight)

- **What's New**: 텍스트 기반의 지침을 통해 파라메트릭 (parametric) CAD 모델을 생성하는 첫 번째 AI 프레임워크인 Text2CAD를 제안합니다. 이 접근 방식은 모든 수준의 디자이너에게 적합하도록 설계되었으며, 디지털 프로토타입 제작의 효율성을 향상시킬 수 있습니다.

- **Technical Details**: Text2CAD는 디자이너 친화적인 텍스트 프롬프트를 기반으로 CAD 모델을 생성하는 엔드 투 엔드 (end-to-end) 트랜스포머 기반의 오토리그레시브 (auto-regressive) 네트워크를 포함합니다. 이 시스템은 DeepCAD 데이터셋에 대한 텍스트 주석을 생성하기 위한 데이터 주석 파이프라인을 도입하여 약 170,000개의 모델과 660,000개의 텍스트 주석을 포함하고 있습니다.

- **Performance Highlights**: 우리의 실험 분석은 제안한 프레임워크가 시각적 품질, 파라메트릭 정밀도, 기하학적 정확성을 포함한 다양한 메트릭을 통해 두 단계(2-stage) 기준 방법보다 우수한 성능을 보여주었음을 입증합니다.



### General Detection-based Text Line Recognition (https://arxiv.org/abs/2409.17095)
- **What's New**: 이번 논문에서는 인쇄된 텍스트(OCR)와 손글씨(HTR) 인식을 위해 새로운 탐지 기반 접근 방식인 DTLR(Detection-based Text Line Recognition)을 제안합니다. 기존의 HTR 방법들은 개별 문자를 분리하여 처리하는 데 어려움이 있었으나, 본 연구에서는 이를 극복하여 다양한 스크립트에 적용 가능한 방식으로 발전하였습니다.

- **Technical Details**: DTLR 접근 방식은 세 가지 주요 통찰에 기반하고 있습니다: (i) 다양한 데이터로의 합성 사전 훈련을 통해 문자의 위치를 적절히 일반화할 수 있게 된다; (ii) 현대의 transformer 기반 탐지 모델은 여러 인스턴스를 조화롭게 탐지하며, 적절한 마스킹 전략을 사용하면 각 탐지 간의 일관성을 활용할 수 있다; (iii) 사전 훈련된 탐지 모델을 사용하여 실제 데이터에서의 라인 수준 주석으로 미세 조정할 수 있으며, 이는 다른 알파벳에서도 적용할 수 있다.

- **Performance Highlights**: 우리는 DTLR이 다양한 데이터셋에서 뛰어난 성능을 발휘하며, 특히 중국어 스크립트 인식에서 CASIA v2 데이터셋과 암호 인식에서 Borg 및 Copiale 데이터셋에서 선진 성능을 개선했음을 입증했습니다. 이 접근 방식은 기존 HTR 방식과는 다른 패러다임을 채택하여 여러 스크립트에서 효과적으로 작동합니다.



### BitQ: Tailoring Block Floating Point Precision for Improved DNN Efficiency on Resource-Constrained Devices (https://arxiv.org/abs/2409.17093)
- **What's New**: 이번 연구에서는 DNN(Deep Neural Networks) 추론을 위한 최적의 BFP(Block Floating Point) 구현을 목표로 하는 비트너스(Bitwidth) 인식 분석 모델링 프레임워크(BitQ)를 제안합니다. 기존의 BFP 기반 양자화가 블록 크기와 정확도를 경험적으로 선택하였던 반면, BitQ는 최적의 BFP 블록 크기와 비트너스를 결정하기 위한 최적화 문제를 해결합니다.

- **Technical Details**: BitQ는 자원 제약 장치에서의 DNN 효율성을 높이기 위해 데이터 이동량과 정확성 간의 트레이드오프를 활용하며, BFP 양자화 설정을 탐색하기 위한 최적의 구성을 식별합니다. 이 방식은 DNN의 데이터 재사용성을 충분히 탐색하여 데이터 이동량을 평가하는 BFP 기반 모델링 접근 방식을 사용합니다.

- **Performance Highlights**: 실험 결과, BitQ는 이미지 분류, 객체 탐지, 장면 세분화 응용 분야에서 기존의 최첨단 기법들과 비교하여 뛰어난 성능을 보였으며, 정확성을 유지하면서 계산 효율성과 메모리 접근 요구 사항을 감소시켰습니다.



### Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification (https://arxiv.org/abs/2409.17091)
Comments:
          17 pages, 7 figures, 7 tables

- **What's New**: 이 논문에서는 Ctrl-GenAug라는 새로운 생성적 증강 프레임워크를 제안하여, 의료 시퀀스 분류를 위한 고도로 의미적이고 연속적인 시퀀스 생성을 지원하고 부정확하게 합성된 샘플을 억제합니다.

- **Technical Details**: Ctrl-GenAug는 다중 모달 조건 유도 시퀀스 생성기를 통해 진단 촉진 샘플을 제어 가능하게 합성하며, 시간적/입체적 일관성을 향상시키는 연속 증강 모듈을 통합합니다. 또한, 불확실한 사례를 억제하는 노이즈 합성 데이터 필터를 설계하였습니다.

- **Performance Highlights**: 세 가지 의료 데이터셋과 세 가지 패러다임에서 훈련된 11개의 네트워크를 사용한 광범위한 실험에서 Ctrl-GenAug의 효과성과 일반성이 입증되었습니다. 특히, 대표성이 부족한 고위험 군과 도메인 외 조건에서의 성능 향상을 보여주었습니다.



### Parameter-efficient Bayesian Neural Networks for Uncertainty-aware Depth Estimation (https://arxiv.org/abs/2409.17085)
Comments:
          Presented at UnCV Workshop at ECCV'24

- **What's New**: 본 연구에서는 대규모 Transformer 기반 비전 모델의 서브스페이스 Bayesian inference를 위해 Parameter-Efficient Fine-Tuning (PEFT) 방법이 적합한지 조사합니다. 특히 LoRA, BitFit, DiffFit 및 새로운 PEFT 방법인 CoLoRA를 조합하여, 단일 깊이 추정(MDE)에서 보다 강건하고 신뢰할 수 있는 예측 성능을 확보할 수 있음을 보여줍니다.

- **Technical Details**: PEFT 방법(LoRA, BitFit, DiffFit 등)을 사용하여 매개변수의 고차원성 문제를 해결하고, 효율적인 추론이 가능함을 입증했습니다. CoLoRA는 Tucker 분해를 기반으로 한 저차원 perturbation을 적용하여 깊이 추정 문제에 적합하게 설계되었습니다.

- **Performance Highlights**: 실험 결과, 제안된 PEFT 방법을 사용하여 MDE에서 개선된 예측 성능을 달성하였고, Bayesian inference를 통해 모델의 신뢰성을 높일 수 있음을 확인하였습니다.



### Can Vision Language Models Learn from Visual Demonstrations of Ambiguous Spatial Reasoning? (https://arxiv.org/abs/2409.17080)
Comments:
          13 pages, 4 figures. Code released at this https URL

- **What's New**: 본 연구에서는 Spatial Visual Ambiguity Tasks (SVAT)라는 새로운 벤치마크를 제안하여 대형 비전-언어 모델(VLM)이 시각적 데모를 통해 새로운 비주얼-스페이셜 개념을 학습할 수 있는지를 평가합니다.

- **Technical Details**: SVAT는 여러 난이도 수준의 분류 작업으로 구성되어 있으며, 목표는 주어진 모호한 텍스트와 시각적 데모를 기반으로 이미지 내에서 관심 있는 객체의 정확한 위치를 학습하는 것입니다. VLM은 이 과제를 위해 Text-Query와 Image-Based Input을 사용하여 정확한 경계 결정을 해야 합니다.

- **Performance Highlights**: Zero-shot 설정에서 VLM은 SVAT 작업에서 실패하고, 단순한 파인튜닝만으로는 5.8%-27.3%의 성능 향상이 가능합니다. 그러나 커리큘럼 학습(Curriculum Learning)을 통해, VLM은 SVAT의 가장 어려운 작업에서 14.2%에서 34.2%의 정확도 개선을 이룰 수 있습니다.



### Benchmarking Domain Generalization Algorithms in Computational Pathology (https://arxiv.org/abs/2409.17063)
- **What's New**: 이번 연구는 30개의 도메인 일반화 (Domain Generalization, DG) 알고리즘의 효과를 3개의 CPath 작업에 대해 평가하고, 새로운 다중 도메인 종양 탐지 데이터셋 (HISTOPANTUM)을 소개합니다.

- **Technical Details**: 연구에서는 7,560회의 교차 검증 (cross-validation) 실험을 통해 DG 알고리즘의 상대적인 성능을 비교하며, 최근에 제안된 pretrained foundation models와 같은 모달리티별 (modality-specific) 기법을 통합했습니다.

- **Performance Highlights**: 자기 감독 학습 (self-supervised learning) 및 염색 증강 (stain augmentation) 기법이 consistently 다른 알고리즘보다 좋은 성능을 보였으며, 연구 결과는 연구자들이 CPath 작업에 적합한 DG 접근 방식을 선택하는 데 도움을 줄 수 있습니다.



### Degradation-Guided One-Step Image Super-Resolution with Diffusion Priors (https://arxiv.org/abs/2409.17058)
Comments:
          The code is available at this https URL

- **What's New**: 본 논문에서는 효율성을 크게 개선한 새로운 하나의 단계로 구성된 Super-resolution (SR) 모델인 S3Diff를 소개합니다. 이는 기존의 diffusion 모델을 기반으로 하여 저해상도(Low-Resolution, LR) 이미지에서 고해상도(High-Resolution, HR) 이미지로 변환하는 과정을 최적화합니다.

- **Technical Details**: 제안된 S3Diff 모델은 Degradation-guided Low-Rank Adaptation (LoRA) 모듈을 사용하여 LR 이미지의 저하 정보를 기반으로 모델의 매개변수를 조정합니다. 이는 기존의 fine-tuning 전략과는 달리, 더욱 효율적이고 데이터 의존적인 SR 모델을 제공합니다.

- **Performance Highlights**: 실험 결과, S3Diff 모델은 최근의 최첨단 방법들과 비교했을 때 효율성과 효과성이 우수함을 입증하였습니다. 특히, 샘플링 단계 수를 대폭 줄이면서도 높은 시각적 품질을 유지하였습니다.



### ControlCity: A Multimodal Diffusion Model Based Approach for Accurate Geospatial Data Generation and Urban Morphology Analysis (https://arxiv.org/abs/2409.17049)
Comments:
          20 pages

- **What's New**: 이 논문에서는 다중 소스의 자원(Volunteer Geographic Information, VGI)을 활용하여 도시 건물 외형 데이터를 생성하는 새로운 접근방법인 ControlCity를 제안합니다. 이 모델은 여러 데이터 모달리티를 통합하여 더 정확하고 유용한 지리정보를 생성할 수 있습니다.

- **Technical Details**: ControlCity는 텍스트, 메타데이터, 이미지 데이터를 포함하는 'image-text-metadata-building footprint' 데이터 셋을 구축하고, 이를 기반으로 multimodal diffusion model을 사용하여 건물 외형 데이터를 생성합니다. 텍스트와 메타데이터를 정렬하여 도시의 건물 패턴을 학습하고, 개선된 ControlNet을 통해 도로 네트워크 및 토지 이용 이미지를 통합합니다.

- **Performance Highlights**: ControlCity는 전 세계 22개 도시에서 실험을 통해 평균 FID 점수 50.94를 기록하였으며, 기존 방법 대비 71.01%의 오류 감소와 38.46% 향상된 MIoU 점수를 달성했습니다. 제로샷 도시 생성을 통해 도시 구조를 정확하게 예측하고 생성할 수 있는 강력한 일반화 능력을 입증했습니다.



### GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design (https://arxiv.org/abs/2409.17045)
- **What's New**: 본 연구에서는 Deep Generative Models (DGM)을 공학 설계에 적용하기 위한 데이터셋 GeoBiked를 제공하며, 대규모 기초 모델을 활용하여 데이터 레이블링 자동화를 위한 방법을 제안합니다. GeoBiked 데이터셋은 4,355개의 자전거 이미지를 포함하고 있으며, 구조적 및 기술적 특징으로 주석이 달려 있습니다.

- **Technical Details**: GeoBiked 데이터셋은 이미지 생성 모델에서 추출한 통합 잠재 특징(Hyperfeatures)을 사용하여 구조적 이미지의 기하학적 대응 관계(예: 바퀴 중심 위치)를 검출하는 두 가지 자동 레이블링 기술을 조사합니다. 또한 GPT-4o를 통해 기술 이미지에 대한 다양한 설명을 생성합니다. 기술 이미지를 Diffusion-Hyperfeatures로 표현하여 기하학적 대응 관계를 측정할 수 있습니다.

- **Performance Highlights**: GeoBiked 데이터셋을 기반으로 한 두 가지 자동 레이블링 방법은, 잠재 이미지 특징의 학습된 통합을 통해 보지 못한 이미지에서 기하학적 기준점을 정확히 예측할 수 있음을 보여주며, GPT-4o를 통해 생성된 다양한 텍스트 설명은 정확한 기술 이미지를 설명합니다. 이러한 접근은 기술 이미지의 일반적인 포인트 검출 및 주석 작업에 적용 가능한 방법으로 제안됩니다.



### EventHDR: from Event to High-Speed HDR Videos and Beyond (https://arxiv.org/abs/2409.17029)
Comments:
          TPAMI 2024

- **What's New**: 이 논문은 이벤트 카메라에서 생성된 이벤트 시퀀스를 활용하여 고속 HDR 비디오를 재구성하는 획기적인 기술적 접근 방식을 제시합니다. 재귀적 합성곱 신경망(recurrent convolutional neural network)을 사용하여 키 프레임 가이드를 통해 정보 손실을 방지하며, 실세계 데이터셋을 새롭게 수집하여 연구의 기초를 다집니다.

- **Technical Details**: 이 연구는 스파스 이벤트 데이터를 통해 영상 재구성이 발생할 수 있는 오류 누적을 방지하기 위해 키 프레임 가이드를 제공하는 재귀 신경망(RNN)을 제안합니다. 또한, 피라미드 변형 네트워크(pyramidal deformable network)를 사용하여 연속적인 이벤트 프레임 간의 기능을 정렬하여 시간적 일관성을 향상시키는 방법을 도입합니다.

- **Performance Highlights**: 실험 결과, 제안한 방법은 고속 HDR 비디오 재구성에서 최첨단 성능을 달성했으며, 실제 쌍 데이터셋을 이용하여 다양한 컴퓨터 비전 작업, 예를 들면, 물체 탐지, 파노라마 분할, 광학 흐름 추정 및 단안 깊이 추정에서 우수한 성능을 발휘했습니다.



### Enhanced Wavelet Scattering Network for image inpainting detection (https://arxiv.org/abs/2409.17023)
- **What's New**: 이 연구는 이미지 인페인팅의 진위를 감지하기 위해 저수준 노이즈 분석에 기반한 혁신적인 방법들을 제안합니다. 특성 추출을 위한 Dual-Tree Complex Wavelet Transform (DT-CWT)와 변조 영역 감지 및 위치 지정을 위한 합성곱 신경망 (CNN)을 결합하여 접근합니다.

- **Technical Details**: DT-CWT는 전송 불변성 (shift-invariance)을 제공하여 인페인팅 과정에서 미세 조작에 대한 강인성을 증가시키고, 방향 선택성은 특정 주파수 대역 및 방향에서 인페인팅으로 인해 발생하는 미세한 아티팩트를 감지하는 데 도움을 줍니다. 또한, 텍스처 분할과 노이즈 분산 추정 (noise variance estimation)을 결합하여 변조된 영역을 찾는 융합 감지 모듈을 제안합니다.

- **Performance Highlights**: 우리의 접근 방식은 최첨단 방법들과 비교하여 모든 인용된 대안보다 우수한 성능을 보임을 입증했습니다. 트레이닝 코드와 사전 훈련된 모델 가중치는 제공된 URL에서 이용 가능할 것입니다.



### PTQ4RIS: Post-Training Quantization for Referring Image Segmentation (https://arxiv.org/abs/2409.17020)
- **What's New**: 이 논문은 Referring Image Segmentation (RIS) 모델에 대한 새로운 포스트-트레이닝 양자화(post-training quantization) 프레임워크인 PTQ4RIS를 제안합니다. PTQ4RIS는 자원 제한적인 엣지 디바이스에서의 실제 응용을 위한 효율적이고 효과적인 솔루션을 제공합니다.

- **Technical Details**: PTQ4RIS는 Dual-Region Quantization (DRQ) 및 Reorder-based Outlier-retained Quantization (RORQ) 방법을 통해 RIS 모델의 양자화 시 성능 저하를 해결합니다. DRQ는 비주얼 인코더의 활성화 분포를 다루며, RORQ는 텍스트 인코더에서 아웃라이어(outlier)의 영향을 최소화합니다.

- **Performance Highlights**: PTQ4RIS는 RefCOCO+ testB 데이터셋에서 FP 모델과 동등한 성능을 기록하며, W6A6 및 W4A8 설정에서도 성능 저하가 각각 0.66 OIoU와 1.54 OIoU에 불과합니다. 이는 RIS 모델에서 포스트-트레이닝 양자화(PTQ) 도입의 가능성을 강조합니다.



### CNN Mixture-of-Depths (https://arxiv.org/abs/2409.17016)
Comments:
          Conference Paper of the Asian Conference on Computer Vision (ACCV) 2024

- **What's New**: CNN Mixture-of-Depths (MoD) 접근법을 도입하여 CNN의 계산 효율성을 개선하였습니다. 이 방법은 현재 예측과 관련성에 따라 채널을 선택적으로 처리하여 계산 자원을 최적화합니다. MoD는 동적 계산 그래프 없이 정적 계산 그래프를 사용하여 하드웨어 효율성을 높이고, 훈련 및 추론 과정을 가속화합니다.

- **Technical Details**: MoD는 Conv-Blocks 내에서 입력 특성 맵의 각 채널의 중요성을 평가한 후, 상위 k개 채널을 선택하여 처리합니다. 이를 통해 처리할 채널 수를 조정하고, 계산 부하를 줄이며, 최종적으로 처리된 채널과 원본 특성 맵의 첫 k개 채널을 융합하여 특징 표현을 강화합니다.

- **Performance Highlights**: ResNet86-MoD는 표준 ResNet50을 능가하며 CPU에서 6%, GPU에서 5% 더 빠른 처리 속도를 제공합니다. ResNet75-MoD는 ResNet50과 동일한 성능을 유지하며 CPU에서 25%, GPU에서 15%의 속도 향상을 보여줍니다.



### Adverse Weather Optical Flow: Cumulative Homogeneous-Heterogeneous Adaptation (https://arxiv.org/abs/2409.17001)
- **What's New**: 이 연구는 악천후에서의 광학 흐름 문제를 해결하기 위해 누적 동질-이질 적응 프레임워크인 CH2DA-Flow를 제안합니다. 이 방법은 깨끗한 장면에서 악천후에 이르는 지식 전이를 위한 중간 단계로 합성 열화 도메인을 활용합니다.

- **Technical Details**: 제안된 CH2DA-Flow 프레임워크는 두 가지 주요 과정으로 구성됩니다: 깨끗한-열화 동작 적응(CDMA)과 합성-실제 동작 적응(SRMA). CDMA에서는 정적 날씨에 대해 깊이 연관 동질 동작 적응을, 동적 날씨에 대해 왜곡 오차 이질 경계 적응을 설계했습니다. SRMA에서는 합성 및 실제 열화 이미지를 비용 볼륨(cos volume) 공간으로 변환하고 K-L 발산을 사용하여 두 도메인 간의 동질적 상관 값의 전반적인 거리를 측정합니다.

- **Performance Highlights**: 제안된 방법은 다양한 악천후 조건에서의 성능이 우수함을 입증하기 위해 광범위한 실험을 수행했으며, 새로운 실제 악천후 데이터셋이 수작업으로 주석 처리된 광학 흐름 레이블과 함께 제공됩니다. 여러 이동 객체와 다양한 장면을 포함해 동적인 환경에서도 효과적으로 작동함을 확인했습니다.



### Single Image, Any Face: Generalisable 3D Face Generation (https://arxiv.org/abs/2409.16990)
- **What's New**: 새로운 모델 Gen3D-Face를 제안하여, 제약 없는 단일 이미지를 통해 3D 인간 얼굴 아바타를 생성하는 것을 가능하게 함. 이 모델은 기존 방법들이 겪던 일반화 문제를 해결하기 위해 다중 보기 일관성(diffusion framework)을 통해 작동함.

- **Technical Details**: Gen3D-Face는 한 개의 얼굴 이미지를 입력으로 받아 다중 보기 이미지를 생성하고, 그 후 신경 표면 건축(neural surface construction)을 수행함. 입력 조건에 따라 메쉬 추정(input-conditioned mesh estimation)을 활용하여 모델의 일반화를 도모하고, 다양한 외형 스타일을 가진 중복들을 처리함. 멀티 뷰 조인트 생성(multi-view joint generation) 방식을 도입하여 보기 간의 일관성을 높임.

- **Performance Highlights**: 광범위한 실험을 통해 제안된 방법이 기존 방법들 대비 우수한 성능을 보이며, 특히 새로운 도메인에서의 단일 이미지 3D 얼굴 생성에서 성능이 월등함을 입증함. 이는 다양한 상황에서 현실적인 3D 얼굴 아바타 생성을 위한 혁신적인 접근법임.



### Path-adaptive Spatio-Temporal State Space Model for Event-based Recognition with Arbitrary Duration (https://arxiv.org/abs/2409.16953)
Comments:
          First version

- **What's New**: 이 연구에서는 이벤트 카메라의 비동기적 데이터 흐름을 이용하여 객체 및 행동 인식의 새로운 프레임워크인 PAST-SSM을 제안합니다. 이 프레임워크는 임의의 지속 시간(0.1초에서 4.5분)에서 이벤트를 인식하고 다양한 추론 주파수에 일반화하는 능력을 갖추었습니다.

- **Technical Details**: PAST-SSM 프레임워크는 Path-Adaptive Event Aggregation and Scan (PEAS) 모듈을 사용하여 다양한 지속 시간의 이벤트를 고정된 차원의 특징으로 인코딩합니다. 또한 Multi-faceted Selection Guiding (MSG) 손실을 도입하여 인코딩된 특징의 무작위성과 중복을 최소화합니다. 이로 인해 모델의 일반화 능력이 향상됩니다. 최종적으로 상태 공간 모델(SSM)을 활용하여 인코딩된 특징의 시공간 특성을 학습합니다.

- **Performance Highlights**: 실험 결과, PAST-SSM 모델은 DVS Action, SeAct, HARDVS 데이터셋에서 각각 +3.45%, +0.38%, +8.31%의 성능 향상을 보였으며, ArDVS100, Real-ArDVS10 및 TemArDVS 데이터셋에서 각각 97.35%, 100.00%, 89.00%의 Top-1 정확도를 달성했습니다. 또한, 다양한 추론 주파수에 대해 최대 8.62%의 성능 저하를 보이며, 이전 샘플링 방법의 27.59%에 비해 뛰어난 일반화 성능을 발휘했습니다.



### DALDA: Data Augmentation Leveraging Diffusion Model and LLM with Adaptive Guidance Scaling (https://arxiv.org/abs/2409.16949)
Comments:
          Accepted to ECCV Synthetic Data for Computer Vision Workshop (Oral)

- **What's New**: 이 논문에서는 데이터가 부족한 상황에서의 문제를 해결하기 위해 Large Language Model (LLM)과 Diffusion Model (DM)을 활용하는 데이터 증강 프레임워크를 제안합니다. 이 방법은 LLM을 통해 생성된 텍스트 프롬프트에 새로운 의미 정보를 삽입하고, 실제 이미지를 시각적 프롬프트로 사용하여 의미적으로 풍부한 이미지를 생성하도록 합니다.

- **Technical Details**: 우리의 접근 방식은 다중 모달 조건부 Diffusion Model (MMDM)에서 예제 이미지와 텍스트 프롬프트의 영향을 조화롭게 균형 잡는 Adaptive Guidance Scaling (AGS) 메커니즘을 포함합니다. CLIPScore를 기반으로 이미지 생성을 위한 텍스트 프롬프트의 가중치를 동적으로 조정하여 생성된 이미지가 목표 분포를 벗어나지 않도록 합니다.

- **Performance Highlights**: 실험 결과, 제안한 방법은 기존 방법들보다 높은 다양성과 개선된 분류 모델 성능을 보여주며, 특히 몇 가지 샷(few-shot) 설정에서 효율적임을 입증했습니다.



### NTIRE 2024 Challenge on Stereo Image Super-Resolution: Methods and Results (https://arxiv.org/abs/2409.16947)
- **What's New**: 이번 논문은 3차 NTIRE 스테레오 이미지 초해상도(SR) 챌린지를 요약하고 새로운 솔루션 및 결과에 초점을 맞추었습니다. 이 챌린지의 목표는 저해상도 스테레오 이미지 쌍을 x4 배율로 고해상도로 변환하는 것입니다.

- **Technical Details**: 이번 챌린지는 bicubic degradation과 실제 열화(real degradation) 두 가지 트랙으로 구성되어 있습니다. 총 108명과 70명의 참가자가 각각 성공적으로 등록했고, 테스트 단계에서 14개 팀과 13개 팀이 PSNR(RGB) 점수가 기준을 초과하여 유효한 결과를 제출했습니다. 이 챌린지는 스테레오 이미지 SR을 위한 새로운 벤치마크를 설정했습니다.

- **Performance Highlights**: NTIRE 2024 챌린지는 주어진 계산 제약 하에서 SR의 최첨단을 측정하고 이를 한계까지 밀어붙이는 것을 목표로 하고 있으며, 참가자들은 이번 대회를 통해 새로운 접근법을 비교할 수 있습니다.



### Face Forgery Detection with Elaborate Backbon (https://arxiv.org/abs/2409.16945)
- **What's New**: 이번 연구에서는 Face Forgery Detection (FFD) 모델의 일반화 성능을 개선하기 위해 Backbone의 사전 훈련(parallel training) 및 미세 조정(fine-tuning) 과정을 재조명했습니다. 기존의 모델들이 Backbone의 중요성을 간과한 반면, 본 연구에서는 ViT(Visual Transformer) 네트워크와 자가 지도 학습(self-supervised learning)을 통한 Backbone 개발을 제안하였습니다.

- **Technical Details**: FFD 모델을 위한 새로운 Backbone 구조를 구현했으며, 다양한 포뮬레이션을 통해 강력한 얼굴 특징 표현(capacities)을 할 수 있는 능력을 확보했습니다. 또한, 신뢰성 있는 추론(inference)을 위해 예측 신뢰도(prediction confidence)를 활용한 임계값 최적화(mechanism) 기법을 도입했습니다.

- **Performance Highlights**: 종합적인 실험을 통해 본 연구에서 제안한 FFD 모델이 기존 모델들보다 우수한 FFD 및 프레젠테이션 공격 탐지(presentation attack detection) 성능을 달성했음을 입증했습니다. 코드는 해당 링크에서 확인할 수 있습니다.



### Generative Object Insertion in Gaussian Splatting with a Multi-View Diffusion Mod (https://arxiv.org/abs/2409.16938)
Comments:
          Project Page: this https URL

- **What's New**: 본 논문에서는 Gaussian Splatting으로 표현된 3D 콘텐츠에 새로운 객체를 삽입하는 혁신적인 방법을 제안합니다. 이 방법은 MVInpainter라는 다중 뷰 확산 모델(multi-view diffusion model)을 기반으로 하여, 사전 학습된 안정적인 비디오 확산 모델을 활용하여 보기 일관성(view-consistent)을 보장하는 객체 인핑팅을 제공합니다.

- **Technical Details**: MVInpainter의 핵심은 ControlNet 기반의 조건부 주입 모듈을 통합하여 보다 통제되고 예측 가능한 다중 뷰 생성을 가능하게 하는 것입니다. 이 모델은 원본 3D 씬과 대조 모델에서 배경, BBox(Bounding Box) 수준의 마스크 및 깊이 맵을 추출하여, 입력으로 세 가지 세트를 사용해 목표 객체 설명에 맞춰 인핑팅 결과를 생성합니다.

- **Performance Highlights**: 다양한 실험을 통해 제안된 방법이 기존 방법들보다 뛰어난 성과를 보임을 입증하였습니다. 우리의 접근 방식은 다양한 결과를 생성하고, 보기 일관성을 보장하며, 더 나은 객체 품질을 제공합니다.



### Game4Loc: A UAV Geo-Localization Benchmark from Game Data (https://arxiv.org/abs/2409.16925)
Comments:
          Project page: this https URL

- **What's New**: 이번 연구에서는 영상 기반 UAV (Unmanned Aerial Vehicle) 지리 위치 추정 기술을 개선하기 위한 대규모 데이터셋인 GTA-UAV를 구축하였습니다. 이 데이터셋은 실제 사용 사례를 반영하기 위해 드론-위성 이미지 쌍의 부분 일치를 포함하도록 설계되었습니다.

- **Technical Details**: GTA-UAV 데이터셋은 현대의 컴퓨터 게임을 활용하여 다양한 비행 고도, 자세, 장면 및 타겟을 포함하여 전방위 연속 영역에서 수집한 33,763개의 드론-뷰 이미지로 구성됩니다. 또한, 데이터 쌍의 학습을 위해 가중치 기반 대비 학습 방식인 weighted-InfoNCE를 도입하여 부분 일치 이미지를 효과적으로 학습할 수 있도록 하였습니다.

- **Performance Highlights**: 이 연구 결과, 제안된 데이터셋과 학습 방법이 UAV 지리 위치 추정에서 효과적임을 입증했으며, 실제 상황에 대한 일반화 능력도 확인되었습니다. 이러한 접근은 기존의 완벽한 일치 데이터셋의 한계를 극복하고, 보다 현실적인 운영 환경에서의 적용 가능성을 높였습니다.



### An Adaptive Screen-Space Meshing Approach for Normal Integration (https://arxiv.org/abs/2409.16907)
- **What's New**: 본 연구에서는 이미지 도메인에서 적응형 표면 삼각분할(Adaptive Surface Triangulation)을 도입하여 삼각형 메쉬(triangle mesh)에서 법선(normal) 통합(normal integration)을 수행하는 새로운 방법을 제안합니다. 이 접근은 기존의 픽셀 그리드(pixel grids)보다 표면 세부사항에 적응하여 표현을 스파스하게 만들어, 계산 효율성을 크게 개선합니다.

- **Technical Details**: 연구의 핵심 통찰은 법선에서 표면 곡률(curvature)을 계산할 수 있다는 것이고, 이를 통해 평탄한 영역(flat areas)을 식별하고 픽셀을 삼각형으로 집계합니다. 사용자는 단일 매개변수를 통해 근사 품질을 조절할 수 있으며, 64 MP 노말 맵(normal maps)에서 메쉬 생성 및 통합을 수행하는데 몇 분이 소요되는 반면, 기존의 픽셀 기반 접근법은 수시간이 소요됩니다.

- **Performance Highlights**: 실제 및 합성 데이터에서 실험 결과, 법선 통합을 위해 필요한 정점(vertex)의 수가 픽셀보다 10배에서 100배 적게 요구됨을 보여주었습니다. 또한 이 스파스성은 픽셀 수에 대한 하위선형(sublinear) 런타임으로 이어짐을 시사합니다.



### Towards Underwater Camouflaged Object Tracking: An Experimental Evaluation of SAM and SAM 2 (https://arxiv.org/abs/2409.16902)
Comments:
          Preprint. Work in Progress

- **What's New**: 이번 논문에서는 UW-COT라는 첫 번째 대규모 수중 위장 물체 추적 데이터셋을 제안하고, 이 데이터셋을 기반으로 여러 최신 시각 물체 추적 방법의 실험적 평가를 수행하였습니다.

- **Technical Details**: UW-COT 데이터셋은 96개 카테고리로 구성된 220개의 수중 비디오 시퀀스를 포함하며, 각 프레임에 대해 위장된 물체에 대한 바운딩 박스 주석을 제공합니다. 이 데이터셋을 통해 SAM(Segmentation Anything Model)과 SAM 2의 성능을 비교하였으며, SAM 2는 시간적 일관성, 신뢰성, 기능 임베딩, 컴퓨팅 효율성 및 신규 도메인 일반화 능력이 개선되었습니다.

- **Performance Highlights**: SAM 2는 UW-COT 데이터셋에서 SAM 기반 추적기(SAM-DA 및 Tracking Anything)보다 뛰어난 성능을 보였으며, 현재의 최신 VOT 방법들보다 우수한 성능을 기록하였습니다. 이는 SAM 2가 비디오 데이터의 동적 도전 과제를 해결하기 위한 향상된 솔루션을 제공한다는 것을 보여줍니다.



### HVT: A Comprehensive Vision Framework for Learning in Non-Euclidean Spac (https://arxiv.org/abs/2409.16897)
- **What's New**: 이번 논문에서는 하이퍼볼릭 기하 (hyperbolic geometry)를 통합한 새로운 비전 트랜스포머 (Vision Transformer) 모델인 하이퍼볼릭 비전 트랜스포머 (Hyperbolic Vision Transformer, HVT)를 제안합니다. 전통적인 비전 트랜스포머가 유클리드 공간 (Euclidean space)에서 작동하는 반면, 하이퍼볼릭 비전 트랜스포머는 하이퍼볼릭 거리와 뫼비우스 변환 (Möbius transformations)을 활용하여 계층적 관계를 더 효과적으로 모델링합니다.

- **Technical Details**: 하이퍼볼릭 비전 트랜스포머는 비전 데이터 내의 계층적 및 관계적 의존성을 최적화하기 위해 하이퍼볼릭 신경 구성 요소 (Hyperbolic Neural Components)와 뫼비우스 변환을 적용합니다. 이 모델은 하이퍼볼릭 공간에서 작동하도록 신경망의 구성 요소, 예를 들어 어텐션 메커니즘 (attention mechanisms) 및 피드-포워드 네트워크 (feed-forward networks)를 확장합니다. 또한, 수학적 구조를 통해 어텐션 레이어와 최적화에서 하이퍼볼릭 기하를 적용하는 방법을 제시합니다.

- **Performance Highlights**: 이미지넷 데이터셋 (ImageNet dataset)을 사용한 실험 결과, 하이퍼볼릭 비전 트랜스포머는 이미지 분류 (image classification) 작업에서 성능이 향상되었음을 보여 주었습니다. 특히, 전통적인 유클리드 접근 방식에 비해 계층적 구조를 더 잘 모델링할 수 있는 능력을 입증하였습니다.



### Linking in Style: Understanding learned features in deep learning models (https://arxiv.org/abs/2409.16865)
- **What's New**: 이 논문은 CNN(Convolutional Neural Networks)에서 학습된 특성을 체계적으로 분석하고 시각화할 수 있는 자동화된 방법을 제안합니다. 특히, 사전 학습된 분류기의 곧 전 단계(또는 penultimate layer)를 생성 모델(StyleGAN-XL)의 잠재 공간(latent space)에 매핑하는 링크 네트워크(linking network)를 도입하여 분류기의 표현을 해석할 수 있는 시각화를 가능하게 합니다.

- **Technical Details**: 우리의 방법은 두 가지 단계로 구성됩니다. 첫째, 사전 학습된 StyleGAN-XL에 기반한 효율적인 특징 시각화 도구를 구축하여 여러 사전 학습된 CNN과 유연하게 연결할 수 있습니다. 둘째, 비지도 추적 방법(unsupervised tracking methods)과 소수의 샷 이미지 분할(few-shot image segmentation)을 활용하여 분류기의 표현 공간에서 학습한 개념을 자동으로 평가합니다. 이를 통해 각 유닛의 특성을 분석하고 요약 통계(summary statistics)를 작성할 수 있습니다.

- **Performance Highlights**: 우리는 제안하는 방법을 통해 단일 유닛에서 학습된 추상적 개념을 밝히고, 분류기의 결정 경계를 분석하여 분류에 있어 가장 중요한 특징을 해석할 수 있음을 보여줍니다. 링크 네트워크는 훈련이 쉬우며, GAN 및 분류기 훈련과는 분리되어 효율적으로 학습됩니다.



### Towards Unified 3D Hair Reconstruction from Single-View Portraits (https://arxiv.org/abs/2409.16863)
Comments:
          SIGGRAPH Asia 2024, project page: this https URL

- **What's New**: 본 논문에서는 단일 시점(single-view)에서 다양한 머리 스타일에 대한 3D 헤어 재구성을 가능하게 하는 새로운 전략을 제안합니다. 복잡한 머리 스타일을 처리할 수 있도록 고안된 통합 파이프라인을 통해, 손상된 머리 스타일을 복원하는 데 있어 기존의 한계를 극복했습니다. 또한, 새로운 합성 데이터셋 SynMvHair를 구축하여 다양한 스타일의 3D 헤어 재구성을 위한 기초를 마련했습니다.

- **Technical Details**: 제안한 접근법은 2D diffusion priors을 활용한 coarse-to-fine 최적화 기반 방법으로, Gaussian 기반의 3D 헤어 표현을 사용합니다. 이 방법은 view-wise와 pixel-wise Gaussian refinement 두 가지 모듈을 최적화하여 고품질의 텍스처를 제공합니다. HairSynthesizer와 HairEnhancer라는 두 가지 diffusion-based hair priors를 통해, 단일 시점 이미지를 조건으로 하여 세밀한 3D 헤어를 생성할 수 있습니다.

- **Performance Highlights**: 제안된 방법은 다양한 머리 스타일을 단일 시점 이미지에서 재구성할 수 있는 가능성을 보여주었고, 복잡한 머리 스타일을 복원하는 데 있어 state-of-the-art 성능을 달성했습니다. 특히, 실제 이미지에 대한 강력한 일반화 능력을 입증하였고, 고속으로 고품질의 멀티 뷰 헤어 렌더링을 가능하게 합니다.



### Limitations of (Procrustes) Alignment in Assessing Multi-Person Human Pose and Shape Estimation (https://arxiv.org/abs/2409.16861)
- **What's New**: 이 논문은 비디오 감시 시나리오에서 3D 인간 포즈와 형상을 정확하게 추정하는 데 있어 새로운 도전 과제를 다룹니다. 기존 메트릭의 한계를 극복하기 위해 RotAvat라는 새로운 기법을 제안합니다.

- **Technical Details**: RotAvat는 3D 메시를 지면과 정렬하는 방법을 개선하여 W-MPJPE 및 W-PVE 메트릭을 정교화합니다. 기존 방법들은 카메라의 시점 변화로 인한 3D 몸체의 글로벌 위치를 제대로 반영하지 못하고 있습니다.

- **Performance Highlights**: RotAvat는 기존 최첨단 방법들(BEV, SPEC, CLIFF)에 비해 복잡한 상황에서도 더 나은 성능을 보여주며, 2D 입력만으로도 안정적인 결과를 도출함으로써 비디오 감시 환경에서 3D 포즈 추정의 정확도를 높입니다.



### The Role of Language Models in Modern Healthcare: A Comprehensive Review (https://arxiv.org/abs/2409.16860)
- **What's New**: 이 논문은 대형 언어 모델(LLM)이 의료 분야에 어떻게 적용되는지에 대한 체계적인 리뷰를 제공합니다. LLM의 발전 과정과 의료 적용에서의 강점뿐만 아니라 데이터 프라이버시, 편향, 윤리적 고려사항 등의 문제를 논의합니다.

- **Technical Details**: 대형 언어 모델(LLM)은 Transformer 아키텍처를 기반으로 하여 장거리 의존성을 효과적으로 캡처하는 능력을 가지고 있습니다. 모델은 일반적으로 방대한 텍스트 데이터셋으로 사전 학습(pre-training)된 후, 특정 작업에 맞춰 세부 조정(fine-tuning)됩니다. BioBERT, ClinicalBERT와 같은 의료 전용 모델이 개발되어 임상 언어의 독특한 도전을 해결하고 있습니다.

- **Performance Highlights**: LLM은 의료 데이터 분석, 질병 진단, 환자 관리 및 약물 발견과 같은 다양한 분야에서 사용되고 있습니다. 임상 의사결정 지원 및 의료 문서 요약 등의 임무에 대한 효과적인 증상이 입증되었습니다. 측정 기준으로는 MMLU, HumanEval과 같은 벤치마크가 사용되어 모델의 효과성을 평가합니다.



### A Versatile and Differentiable Hand-Object Interaction Representation (https://arxiv.org/abs/2409.16855)
Comments:
          Accepted at the Winter Applications in Computer Vision 2025 conference. 9 pages, 6 figures

- **What's New**: 이 논문에서는 Coarse Hand-Object Interaction Representation (CHOIR)이라는 새로운 HOI 모델링 필드를 제시했습니다. CHOIR는 완전한 미분 가능성을 가지고 있어 다양한 작업에 응용할 수 있습니다.

- **Technical Details**: CHOIR는 이산적인 비부호 거리(discrete unsigned distances)를 활용하여 연속적인 형태(shape)와 자세(pose)를 인코딩하며, 다변량 가우시안 분포(multivariate Gaussian distributions)를 통해 밀집 접촉 맵(dense contact maps)을 적은 매개변수로 표현합니다. 이 연구에서는 JointDiffusion이라는 확산 모델을 설계하여 노이즈가 있는 손-물체 상호작용(hand-object interactions) 또는 단순한 물체 기하학(Object geometries)을 기반으로 하는 그립(grasp) 분포를 학습합니다.

- **Performance Highlights**: JointDiffusion은 정제(refinement) 작업에서 접촉 F1 점수를 $5\%$ 증가시켰으며, 합성(synthesis) 작업에서 시뮬레이션 변위를 $46\%$ 감소시켰습니다. 실험 결과, CHOIR와 함께 사용하는 JointDiffusion은 특정 작업을 위한 기존 방법에 비해 접촉 정확도(contact accuracy)와 물리적 현실감(physical realism)에서 우수한 성능을 나타냈습니다.



### Robust Scene Change Detection Using Visual Foundation Models and Cross-Attention Mechanisms (https://arxiv.org/abs/2409.16850)
Comments:
          7 pages

- **What's New**: 본 논문에서는 DINOv2라는 비주얼 파운데이션 모델의 강력한 특징 추출 능력을 활용한 새로운 장면 변화 탐지(scene change detection; SCD) 방법을 제안합니다. 본 방법은 강한 조명 변화, 계절적 변화 및 관점의 차이와 같은 주요 과제를 해결하기 위해 전체 이미지에 대한 크로스 주의(full-image cross-attention)를 통합합니다.

- **Technical Details**: 제안하는 방법은 이미지 쌍 간의 일치 및 불일치 사항을 효과적으로 학습하기 위해 1) 백본(backbone) 네트워크를 고정하여 밀집한 파운데이션 특징의 일반성을 유지하고, 2) 관점 차이에 보다 최적으로 대처하기 위해 '전체 이미지' 크로스 주의 방법을 사용합니다.

- **Performance Highlights**: VL-CMU-CD 및 PSCD와 같은 두 가지 벤치마크 데이터셋에서 실험을 진행했으며, 특히 이미지 쌍 간의 기하학적 변화가 포함된 시나리오에서 F1-score가 크게 향상됨을 보였습니다. 결과는 기존의 최첨단 접근 방식에 비해 우리 방법의 뛰어난 일반화 능력을 보여줍니다.



### IRASNet: Improved Feature-Level Clutter Reduction for Domain Generalized SAR-ATR (https://arxiv.org/abs/2409.16845)
Comments:
          16 pages, 11 figures

- **What's New**: 본 연구에서는 SAR-ATR(합성 개구 레이더 자동 목표 인식) 분야에서 도메인 일반화(Domain Generalization)를 위한 새로운 프레임워크인 IRASNet을 제안합니다. 이 프레임워크는 효과적인 특징 수준의 클러터(clutter) 감소와 도메인 불변 특징 학습을 가능하게 하여 기존의 기술적 한계를 극복하고자 합니다.

- **Technical Details**: IRASNet은 1) 클러터 감소 모듈(Clutter Reduction Module, CRM)을 통해 특징 맵에서 신호 대 클러터 비율(Signal-to-Clutter Ratio, SCR)을 최대화하고, 2) 적대적 학습(Adversarial Learning)과 CRM을 통합하여 클러터 감소된 도메인 불변 특징을 추출하며, 3) 마스크 지상 진실(Mask Ground Truth) 인코딩을 사용하여 정책적 감독(Positional Supervision) 작업을 통해 특징 추출을 개선합니다. 이 모든 작업은 측정된 데이터 없이도 이루어집니다.

- **Performance Highlights**: IRASNet은 공개 SAR 데이터셋인 SAMPLE에서 뛰어난 성능을 달성하며, 기존의 SAR-ATR 방법들과 비교할 때 뛰어난 일반화 성능을 보여줍니다. 덧붙여, 특징 수준의 클러터 감소 능력 또한 크게 향상되어 레이더 이미지 패턴 인식 분야에서 중요한 진전을 이루었습니다.



### Explicitly Modeling Pre-Cortical Vision with a Neuro-Inspired Front-End Improves CNN Robustness (https://arxiv.org/abs/2409.16838)
- **What's New**: 이번 연구에서는 이전의 VOneNets를 기반으로 하여 후드 구조를 일반화하기 위해 RetinaBlock을 도입하고, RetinaNets 및 EVNets라는 두 가지 새로운 CNN 모델 패밀리를 소개합니다. 이 모델들은 망막 및 외측 슬상핵(LGN)의 시각처리 단계를 시뮬레이션하여 CNN의 견고성을 개선합니다.

- **Technical Details**: RetinaBlock은 midget과 parasol 망막 신경세포의 시각적 프로세싱을 모델링하여, 여러 개의 병렬 경로를 통해 작동합니다. 관심영역(RF) 내의 공간적 종합을 수행하고, DoG(차이-가우시안) 필터를 통해 주위와의 반응을 모델링하여 대칭세포의 상호작용을 시뮬레이션합니다. RetinaNets는 표준 CNN 백엔드 아키텍처를 통합하며, EVNets는 VOneBlock과 결합하여 동작합니다.

- **Performance Highlights**: RetinaNets는 기존 모델에 비해 12.3%의 상대적 견고성 향상이 관찰되었으며, EVNets는 18.5%의 향상을 보였습니다. 이러한 개선은 다양한 방식의 이미지 왜곡에 대해 일반화되었으나, 깨끗한 이미지 정확도에 약간의 감소가 동반되었습니다.



### Focus Entirety and Perceive Environment for Arbitrary-Shaped Text Detection (https://arxiv.org/abs/2409.16827)
- **What's New**: 이번 연구에서는 다각적 정보 레벨을 활용한 임의 형태 텍스트 탐지기를 제안합니다. 핵심 모듈(FEM)과 주변 환경 모듈(PEM)을 통해 기존의 노이즈에 취약한 하향식 모델링 방식의 문제를 해결합니다.

- **Technical Details**: 제안하는 Focus Entirety Module (FEM)은 몸체 레벨의 특징을 추출하고 상향식의 노이즈 영향 감소 방식으로 텍스트를 모델링합니다. Perceive Environment Module (PEM)은 지역 레벨의 정보를 추출하고, 픽셀 주변의 긍정 샘플 분포를 강조하여 픽셀 상호작용을 촉진합니다.

- **Performance Highlights**: 제안된 FEPE 모델은 공개된 4개의 데이터셋에서 기존의 최첨단 기법을 초월하는 성능을 보여주며, 수평, 회전 및 불규칙 형태의 텍스트를 모두 처리할 수 있는 능력을 입증하였습니다.



### XAI-guided Insulator Anomaly Detection for Imbalanced Datasets (https://arxiv.org/abs/2409.16821)
Comments:
          Accepted as a workshop paper at ECCV 2024

- **What's New**: 이 연구에서는 전선의 절연체 결함을 탐지하기 위한 새로운 파이프라인을 제안합니다. UAV(무인 항공기)를 활용하여 수집한 이미지를 통해 절연체 결함을 정확하게 검출하고 분류하는 방법론을 개발하였습니다.

- **Technical Details**: 제안된 방법은 YOLOv8 모델을 사용하여 절연체를 검출하고, 비율이 불균형한 데이터셋 문제를 해결하기 위해 로지스틱 회귀를 통한 재훈련 기법을 적용하였습니다. 또한, LRP(층별 관련 전파기법)를 활용하여 결함의 위치를 정확히 설명하고 시각화했습니다.

- **Performance Highlights**: 결함 탐지 정확도를 최대 13% 향상시켰으며, 클래스 불균형 문제를 해결하여 예측 유지보수의 효과성을 크게 개선하였습니다. 이 연구는 산업 현장에서의 비전 기반 검사 및 예측 유지 보수에 가치 있는 기여를 하고 있습니다.



### Spotlight Text Detector: Spotlight on Candidate Regions Like a Camera (https://arxiv.org/abs/2409.16820)
- **What's New**: 본 논문에서 제안하는 Spotlight Text Detector (STD)는 불규칙한 형태의 텍스트를 보다 정확하게 감지하기 위해 두 가지 모듈, 즉 Spotlight Calibration Module (SCM)과 Multivariate Information Extraction Module (MIEM)을 포함하여 복잡한 배경에서도 텍스트 감지를 효과적으로 향상시킨다.

- **Technical Details**: SCM은 후보 영역에 초점을 맞춰 예측된 텍스트 커널을 정확하게 보정하여 잘못된 긍정 샘플을 제거하는 방식으로 작동한다. MIEM은 다양한 기하학적 특성을 탐색하여 텍스트의 형태, 크기 및 방향의 다양성에 대처하며, 연산량을 최소화하면서 여러 공간적 관계를 포착한다. 두 모듈은 서로 보완적으로 동작하여 텍스트 감지의 효율성을 극대화한다.

- **Performance Highlights**: 광범위한 실험을 통해 제안한 STD는 ICDAR2015, CTW1500, MSRA-TD500, Total-Text와 같은 다양한 데이터셋에서 기존의 최첨단 방법들 대비 우수한 성능을 보였으며, 특히 불규칙 형상의 텍스트를 효과적으로 감지하는 능력을 지닌 것으로 나타났다.



### Benchmarking Deep Learning Models for Object Detection on Edge Computing Devices (https://arxiv.org/abs/2409.16808)
- **What's New**: 본 논문에서는 YOLOv8, EfficientDet Lite, SSD와 같은 최신 객체 탐지 모델을 자원 제한이 있는 엣지 디바이스에서 성능을 평가하였습니다. Raspberry Pi와 Jetson Orin Nano 등 다양한 엣지 디바이스에서 에너지 소비, 추론 시간, 평균 정밀도(Mean Average Precision, mAP) 등의 성능 지표를 수집하였습니다.

- **Technical Details**: 우리가 연구한 모델들은 YOLOv8 (버전 Nano, Small, Medium), EfficientDet Lite (Lite0, Lite1, Lite2), 그리고 SSD (SSD MobileNet V1, SSDLite MobileDet)입니다. 각 모델은 Raspberry Pi 3,4,5 및 TPU 가속기 사용 여부에 따라 성능 평가를 진행하였고, 전반적으로 객체 탐지를 위한 다양한 머신 러닝 프레임워크(PyTorch, TensorFlow Lite, TensorRT)를 활용하였습니다.

- **Performance Highlights**: YOLOv8 Medium과 같은 높은 mAP 모델은 에너지 소비가 많고 느린 편이지만, SSD MobileNet V1 모델은 에너지 효율성이 뛰어나고 속도가 빠른 것으로 나타났습니다. Jetson Orin Nano는 요청 처리에 있어 가장 빠르고 에너지 효율적이지만 대기 전력 소비가 가장 높은 것으로 분석되었습니다. 이 연구는 엣지 디바이스에 딥러닝 모델을 배포할 때 정확성, 속도 및 에너지 효율성 간의 균형을 고려해야 한다는 점을 강조합니다.



### Topological SLAM in colonoscopies leveraging deep features and topological priors (https://arxiv.org/abs/2409.16806)
Comments:
          MICCAI 2024

- **What's New**: 이번 연구에서는 ColonSLAM을 소개합니다. 이는 기존의 SLAM 시스템에 딥 러닝 기반의 기능과 위상적 프라이어(topological priors)를 결합하여 전체 대장의 위상적 지도를 생성하는 시스템입니다.

- **Technical Details**: ColonSLAM은 고전적인 metric SLAM과 함께 딥 로컬리제이션 네트워크를 활용하여 동일한 지점에서 촬영된 이미지 간의 관계를 식별하고, transformer 기반의 매칭 네트워크를 통해 복잡한 맵을 구축합니다. 이 시스템은 선형 연결만으로 이루어진 작은 metric 서브맵을 조합하여 위상적 맵 G=(N,E) 형태로 생성합니다. 각 노드는 대장 구조의 특정 구역을 나타내며, 간선은 공간에서 연결 가능한 장소를 연결합니다.

- **Performance Highlights**: Endomapper 데이터셋을 통한 평가를 통해 ColonSLAM이 실제 인간 탐사를 통해 전체 대장 지도를 생성할 수 있는 잠재력을 보여주었습니다. 이 연구는 대장 내시경에 있어 기존의 방법들보다 더 복잡한 맵을 구축할 수 있게 하여, 의료 영상 인식 기술에 기여할 것으로 기대됩니다.



### Spacewalker: Traversing Representation Spaces for Fast Interactive Exploration and Annotation of Unstructured Data (https://arxiv.org/abs/2409.16793)
- **What's New**: 이번 논문에서 우리는 다양한 모달리티를 활용한 비구조화 데이터 분석을 위한 상호작용 도구인 Spacewalker를 소개합니다. 이 도구는 데이터를 탐색하고 주석을 달 수 있도록 설계되었습니다.

- **Technical Details**: Spacewalker는 사용자가 임의의 모달리티의 데이터 세트를 업로드하고, Low-dimensional space에서 데이터의 시맨틱 유사성을 강조하여 시각화할 수 있는 기능을 제공합니다. Bayesians networks 및 Deep Learning 기반의 방법을 사용하여 데이터를 추출합니다.

- **Performance Highlights**: 사용자 연구 결과, Spacewalker는 기존 방법에 비해 데이터 주석 속도를 현저히 개선하며, 데이터 무결성 검증 및 부패 데이터 세트 식별 작업에서도 빠른 탐색이 가능합니다.



### MixPolyp: Integrating Mask, Box and Scribble Supervision for Enhanced Polyp Segmentation (https://arxiv.org/abs/2409.16774)
Comments:
          Accepted in IEEE BIBM 2024

- **What's New**: 본 논문에서는 기존의 주석 방식의 한계를 극복하기 위해 다양한 주석 유형을 결합한 혼합 감독 기법인 MixPolyp를 제안합니다. 기존 방식이 단일 주석 유형에 의존하는 것과 달리, MixPolyp는 픽셀, 박스, 스크리블 주석을 통합하여 데이터의 가용성을 높이고 레이블링 비용을 감소시키는 데 초점을 맞춥니다.

- **Technical Details**: MixPolyp는 세 가지 새로운 감독 손실 함수를 도입하여 다양한 주석을 처리합니다. 1) Subspace Projection loss (L_SP): 예측과 박스 주석 간의 형태 불일치를 제거합니다. 2) Binary Minimum Entropy loss (L_BME): 레이블이 없는 픽셀에 대한 제어를 제공하여 감독의 희소성을 완화합니다. 3) Linear Regularization loss (L_LR): 예측 간의 일관성을 보장하여 비고유성(non-uniqueness)을 줄입니다. 이 손실들은 모델 구조에 구애받지 않으며, 훈련 중에만 사용되어 추론 시 계산 비용이 없습니다.

- **Performance Highlights**: 다섯 개의 데이터셋에 대한 광범위한 실험을 통해 MixPolyp의 효과성은 입증되었습니다. MixPolyp는 기존의 완전 감독 결과를 초월하여 고품질의 폴립 마스크를 예측하는 성능을 보여줍니다.



### MaViLS, a Benchmark Dataset for Video-to-Slide Alignment, Assessing Baseline Accuracy with a Multimodal Alignment Algorithm Leveraging Speech, OCR, and Visual Features (https://arxiv.org/abs/2409.16765)
- **What's New**: 이 논문에서는 강의 비디오와 해당 슬라이드를 정렬하는 벤치마크 데이터셋을 제시하고, 음성, 텍스트 및 이미지에서 특징을 활용하는 새로운 다중 모달 알고리즘을 소개합니다.

- **Technical Details**: 제안된 알고리즘은 동적 프로그래밍(dynamic programming)을 사용하여 최적의 슬라이드 시퀀스를 결정하며, OCR(Optical Character Recognition)을 통해 얻은 특징들이 매칭 정확도에 크게 기여한다고 보고합니다. 알고리즘은 SIFT(Scale-Invariant Feature Transform)에 비해 평균 0.82의 정확도를 기록하면서 속도는 약 11배 빨라졌습니다.

- **Performance Highlights**: 제안된 알고리즘은 다양한 강의 스타일과 비디오 품질에 따른 매칭 정확도의 차이를 보였으며, 슬라이드 전환을 제재할 경우 정확도가 향상되었습니다. 또한, 매칭의 정확도는 오디오 전사에 의해서도 유용한 정보를 제공하고, OCR 데이터가 부족할 때 더욱 유용함을 강조합니다.



### Statewide Visual Geolocalization in the Wild (https://arxiv.org/abs/2409.16763)
- **What's New**: 이 연구에서는 राज्य 규모의 검색 영역 내에서 자연에서 촬영한 거리 전경 사진의 지리적 위치를 예측하는 방법을 제시합니다. 항공 이미지를 데이터베이스와 비교하여 거리 전경 사진의 정확한 위치를 정의할 수 있는 모델을 훈련시켰습니다.

- **Technical Details**: 이 방법은 검색 영역을 지리적 셀로 분할하고, 각 셀과 해당 사진을 결합된 임베딩 공간에 매핑하여 테스트 시 검색을 수행합니다. 다양한 수준의 세부 정보(Levels of Detail)를 활용하여 주변 장면에 대한 충분한 정보를 제공합니다. 새로운 검색 지역 레이아웃을 설계하여 대규모 지역으로 확장할 수 있습니다.

- **Performance Highlights**: 이 방법은 매사추세츠주에 업로드된 모든 비파노라마 거리 전경 사진의 60.6%를 실제 위치로부터 50m 이내로 정확하게 지역화하는 데 성공하였습니다.



### Navigating the Maze of Explainable AI: A Systematic Approach to Evaluating Methods and Metrics (https://arxiv.org/abs/2409.16756)
- **What's New**: 이번 논문에서는 LATEC이라는 대규모 벤치마크를 소개합니다. 이 벤치마크는 17개의 주요 Explainable AI (XAI) 방법을 20가지 메트릭으로 평가하여, 다양한 설계 매개변수와 모델 아키텍처를 통합하여 7,560개의 조합을 체계적으로 분석합니다.

- **Technical Details**: LATEC을 통해 XAI 방법의 평가에서 자주 발생하는 메트릭 간의 상충 가능성을 발견하였으며, 이는 신뢰할 수 없는 순위를 초래할 수 있습니다. 논문에서는 보다 강력한 평가 방안을 제안하며, 다양한 XAI 방법을 종합적으로 평가하여 실무자들이 필요에 맞는 적절한 방법을 선택할 수 있도록 지원합니다. 또한 LATEC은 326k saliency maps와 378k metric scores를 공공 데이터셋으로 제공하여 향후 XAI 연구에 기여할 수 있도록 합니다.

- **Performance Highlights**: 특히, Expected Gradients라는 새로운 고성능 방법이 기존 연구에서 검토되지 않았음을 발견하였으며, 이는 LATEC의 중요한 발견 중 하나로, 향후 XAI 연구 방향에 중대한 영향을 미칠 것으로 예상됩니다.



### Commonly Interesting Images (https://arxiv.org/abs/2409.16736)
Comments:
          ECCV 2024

- **What's New**: 본 논문은 개인의 주관적 취향이 관여하는 시각적 흥미로움(visual interestingness) 개념을 형식적으로 정의하고, 이미지의 공통적 흥미(common interest) 요소를 밝혀내기 위해 2.5천 명의 Flickr 사용자로부터 수집한 500k 이미지를 분석합니다.

- **Technical Details**: FlickrUser-dataset을 기반으로 이미지의 특성을 분석하며, perceptual, denotative, connotative 특징을 포함합니다. Bottom-up 처리와 top-down 처리 간의 상호작용을 통해 흥미로움이 형성된다는 이론을 제시합니다. 또한 공통적 흥미와 주관적 흥미의 연속성을 제안하며 컴퓨터 모델 학습에 활용하였습니다.

- **Performance Highlights**: 전문적으로 촬영된 경관 이미지들은 큰 공통적 흥미를 유발하는 반면, 개인적 사건을 담은 이미지는 주관적 흥미를 자아내며 개인의 기억과 감정을 자극하는 경향이 있습니다.



### EAGLE: Towards Efficient Arbitrary Referring Visual Prompts Comprehension for Multimodal Large Language Models (https://arxiv.org/abs/2409.16723)
- **What's New**: 이번 논문에서는 EAGLE이라는 새로운 Multimodal Large Language Model (MLLM)을 제안하여, 임의의 referring visual prompts를 이해하는 능력을 향상시킵니다. EAGLE는 기존 모델들보다 훈련 노력을 줄이면서도 효과적으로 다양한 형태의 시각적 프롬프트를 처리할 수 있도록 설계되었습니다.

- **Technical Details**: EAGLE는 주어진 이미지에 색깔이 입혀진 패치로 referring visual prompts를 렌더링하여 이미지 자원을 활용합니다. 또한 Geometry-Agnostic Learning (GAL) 패러다임을 도입하여 다양한 형태의 referring visual prompts와의 관계를 분리합니다. 이로 인해 MLLM이 강조된 객체를 인식하는 데 더 집중할 수 있도록 합니다.

- **Performance Highlights**: EAGLE는 다양한 임의의 시각적 프롬프트를 처리하는 데 있어 기존 최첨단 방법들보다 더 효율적으로 작동하며, 실험 결과에서 더욱 향상된 성능을 보여줍니다. 또한, 우리의 방법은 기존의 지역 텍스트 정렬 프로세스를 새롭게 시작하는 것보다, 시각적 프롬프트를 효과적으로 제시하는 것이 훨씬 효율적임을 입증하였습니다.



### Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification (https://arxiv.org/abs/2409.16718)
Comments:
          EMNLP 2024 Main Conference

- **What's New**: 최근 Vision-Language Models (VLMs)에 대한 세밀한 조정이 이루어지면서, 클립 모델의 고유한 매개변수를 조정하는 것의 중요성을 재조명하였다. 이 연구에서는 모든 매개변수를 조정하는 대신 특정 매개변수만을 조정하는 CLIPFit 방법을 제안하였다.

- **Technical Details**: CLIPFit은 기존의 프롬프트 튜닝(prompt tuning) 및 어댑터 튜닝(adapter tuning) 방식과는 다르게, 추가적인 매개변수를 도입하지 않고 클립 모델의 특정 바이어스와 정규화 레이어만 조정하는 방법이다. 이로 인해 파라미터 수가 줄어들고, 성능이 향상된다.

- **Performance Highlights**: CLIPFit을 사용하여 zero-shot CLIP 대비 7.33%의 평균 조화 평균 정확도(harmonic mean accuracy) 개선을 달성하였으며, 이는 16-shot 설정에서 프롬프트 튜닝 및 어댑터 튜닝을 대체할 수 있는 유망한 옵션이다.



### Pose-Guided Fine-Grained Sign Language Video Generation (https://arxiv.org/abs/2409.16709)
Comments:
          ECCV 2024

- **What's New**: 이 논문에서는 Sign Language Video Generation (SLVG) 분야에서 새로운 Pose-Guided Motion Model (PGMM)을 제안하여 고품질의 시각적 세부 사항과 일관된 동작을 가진 수화 비디오 생성의 한계를 극복하고자 합니다.

- **Technical Details**: 이 방법은 Coarse Motion Module (CMM)과 Pose Fusion Module (PFM)으로 구성되며, CMM을 통해 광학 흐름 왜곡(optical flow warping)을 활용하여 거친 구조의 동작을 완성하고, PFM은 RGB와 포즈 모달리티 정보를 결합하여 세부 사항 생성을 정교하게 진행합니다. 또한 새로운 Temporal Consistency Difference (TCD) 메트릭을 설계하여 비디오의 일관성을 정량적으로 평가합니다.

- **Performance Highlights**: 실험 결과, 제안하는 PGMM은 기존의 최첨단 방법들보다 뛰어난 성능을 보였으며, 다양한 비디오 테스트에서 높은 세부 사항 및 동시성의 개선을 보여주었습니다.



### Pix2Next: Leveraging Vision Foundation Models for RGB to NIR Image Translation (https://arxiv.org/abs/2409.16706)
Comments:
          19 pages,12 figures

- **What's New**: Pix2Next는 RGB 이미지를 기반으로 고해상도 NIR 이미지를 생성하는 혁신적인 이미지-이미지 변환 프레임워크입니다. 이 방법은 최신 Vision Foundation Model (VFM)을 활용하여_encoder-decoder_ 아키텍처에서 크로스-어텐션 메커니즘(cross-attention mechanism)을 통합하여 특징 통합을 향상시킵니다. 더불어, 여러 해상도에서 현실적인 이미지 생성을 보장하는 PatchGAN 판별자를 사용하여 NIR 이미지 생성의 품질과 세부사항을 개선합니다.

- **Technical Details**: Pix2Next은 RGB 이미지를 NIR 이미지로 변환하는 과정에서 고유한 세부 사항과 스펙트럼 특성을 유지하는 데 중점을 두고 설계되었습니다. 실제로, Segmentation과 Object Detection 태스크에 대한 성능 평가와 함께 다양한 손실 함수가 글로벌 컨텍스트 이해와 로컬 특징 보존을 연결하여 모델 성능을 높입니다. 또한	RANUS 데이터셋을 사용하여 테스트를 진행하였습니다.

- **Performance Highlights**: Pix2Next는 FID(Frechet Inception Distance) 점수를 기존 방법에 비해 34.81% 향상시켜, 세 가지 시각 품질 지표에서 뛰어난 성능을 보였습니다. 또한, NIR 이미지로의 변환된 데이터를 이용하여 자율 주행 인식 태스크에서 더욱 개선된 성능을 보여주어, 제한된 실 NIR 데이터셋을 보완하는 데 있어 효용성을 입증했습니다.



### Layout-Corrector: Alleviating Layout Sticking Phenomenon in Discrete Diffusion Mod (https://arxiv.org/abs/2409.16689)
Comments:
          Accepted by ECCV2024, Project Page: this https URL

- **What's New**: 이 논문은 기존의 Discrete Diffusion Models (DDMs)에서 발생하는 레이아웃 고착(Layout Sticking) 현상을 해결하기 위해 Layout-Corrector라는 새롭고 간단한 모듈을 제안합니다.

- **Technical Details**: Layout-Corrector는 레이아웃의 각 요소에 대한 정확성 점수를 평가하고, 저조한 점수를 가진 요소를 재초기화하여 하모니가 있는 레이아웃을 생성을 돕습니다. 이 모듈은 DDM과 함께 사용되며, 각 생성 과정에서 하모니를 고려하여 불일치하는 요소를 식별합니다.

- **Performance Highlights**: Layout-Corrector는 다양한 기준 벤치마크에서 테스트되어 DDM과 함께 사용할 경우 레이아웃 생성 성능을 일관되게 향상시키고, 정확성-다양성 무역의 조절을 통한 성능 저하를 완화합니다.



### Skyeyes: Ground Roaming using Aerial View Images (https://arxiv.org/abs/2409.16685)
- **What's New**: 이번 논문에서는 Skyeyes라는 새로운 프레임워크를 소개합니다. 이 프레임워크는 항공 이미지 데이터만을 사용하여 지상 시점의 포토리얼리스틱(photorealistic) 이미지를 생성할 수 있어, 자율주행 및 게임 디자인 등에서 사실감을 동반한 3D 환경을 구현합니다.

- **Technical Details**: Skyeyes는 3D 표현과 시점 일관성 생성 모델을 결합하여 생성된 이미지 간의 일관성을 보장합니다. SuGaR를 활용해 정밀한 세부 정보를 유지하고, 지상 뷰 이미지 생성을 위한 카메라 포즈를 학습합니다. 생성 과정에서 주어진 항공 이미지를 바탕으로 appearance control 모듈을 통해 픽셀 정확성을 유지하며, 마지막으로 view consistency 모듈을 통해 시간적 일관성을 확보합니다.

- **Performance Highlights**: 대규모의 합성 및 지리적으로 정렬된 데이터셋을 구축하고 다양한 실험을 통해 기존 기법들보다 우수한 성능을 보였습니다. 정성적 및 정량적 분석에서 탁월한 결과를 나타내며, 합성 기술의 최전선에 위치하고 있습니다. 개발한 코드와 데이터셋은 논문 수락 후 공개될 예정입니다.



### TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans (https://arxiv.org/abs/2409.16666)
Comments:
          Accepted by ECCVW 2024. Project page: this https URL

- **What's New**: TalkinNeRF라는 새로운 프레임워크를 소개하며, 이는 모노큘러 비디오로부터 전신 인간의 동적 neural radiance field (NeRF)를 학습합니다. 기존 연구들은 신체 자세나 얼굴만 표현했으나, 이 방법에서는 신체 전체를 아우르는 메시지를 전달하는 데 필요한 모든 요소를 통합합니다.

- **Technical Details**: TalkinNeRF는 모노큘러 비디오에서 인간의 4D 모션을 표현하는 통합된 NeRF 기반 네트워크 입니다. 신체, 얼굴, 손에 대해 각각의 모듈을 학습하고, 복잡한 손가락 움직임을 표현하기 위해 추가적인 변형 필드도 학습합니다. 또한, 다중 정체성 표현을 통해 여러 주체에 대한 동시에 학습이 가능합니다.

- **Performance Highlights**: 기존 최첨단 기술을 능가하여 동적인 전신 인간 애니메이션을 생성하는 데 있어 우수한 성과를 보여줍니다. TalkinNeRF는 핸드 아티큘레이션(hand articulation)과 얼굴 표정(facial expressions)을 활용하여 새로운 포즈에 대해서도 견고한 애니메이션을 만들어냅니다.



### Progressive Representation Learning for Real-Time UAV Tracking (https://arxiv.org/abs/2409.16652)
Comments:
          Accepted by the 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)

- **What's New**: 이 논문에서는 UAV(무인 항공기) 추적을 위한 새로운 점진적 표현 학습 프레임워크인 PRL-Track을 제안합니다. PRL-Track은 거친 표현 학습과 정밀 표현 학습의 두 부분으로 나뉘며, 특히 복잡한 동적 환경에서의 객체 추적 성능을 개선하는 데 중점을 둡니다.

- **Technical Details**: PRL-Track은 CNN(합성곱 신경망)을 기반으로 하는 거친 표현 학습과 ViT(비전 트랜스포머)를 기반으로 하는 정밀 표현 학습을 통합합니다. 거친 표현 학습에서는 외관 정보와 의미론적 정보를 이용한 두 개의 혁신적인 조절기(regulator)를 사용하는데, 이는 외관 간섭을 완화하고 깊은 특징에서 의미 정보를 캡처합니다. 정밀 표현 학습에서는 새로운 계층적 모델링 생성기가 도입되어 객체의 거친 표현을 연결합니다.

- **Performance Highlights**: 종합 실험에 따르면 PRL-Track은 세 개의 권위 있는 UAV 추적 벤치마크에서 우수한 성능을 보여주었습니다. 실제 테스트 결과, PRL-Track은 일반적인 UAV 플랫폼에서 초당 42.6 프레임으로 뛰어난 추적 성능을 실현하여 효율성과 강인성을 입증했습니다.



### Enhancing Nighttime UAV Tracking with Light Distribution Suppression (https://arxiv.org/abs/2409.16631)
- **What's New**: 이 논문은 LMEnhancer라는 새로운 저조도 이미지 향상 기술을 제안하여, 야간 드론(UAV) 추적의 효과성을 높이고자 합니다. 기존의 저조도 이미지 향상 기법들이 복잡한 조명 조건에서의 불균형한 조명 분포를 간과하는 문제를 해결하기 위해, 이 작업은 조명 분포 억제를 통한 향상을 도모합니다.

- **Technical Details**: LDEnhancer는 이미지 콘텐츠 정보와 조명 분포 정보를 특징 공간에서 분리하여 목표 지향적인 향상을 가능하게 하는 새로운 이미지 콘텐츠 정제 모듈을 개발합니다. 또한, 두 개의 파라미터 맵을 활용하여 저조도 이미지의 픽셀 단위 조정을 위한 혁신적인 순회 반복 조정을 제안합니다. 이 연구실에서는 40개의 시퀀스와 74K 이상의 프레임으로 구성된 새로운 야간 UAV 추적 데이터셋 NAT2024-2도 구축하였습니다.

- **Performance Highlights**: LDEnhancer는 기존의 저조도 향상 기법에 비해 야간 UAV 추적에서 우수한 성능을 보여주었으며, 권위있는 UAV 벤치마크에서 검증된 강건성을 통해 실세계 테스트에서도 효율성과 실용성을 입증했습니다.



### DeformStream: Deformation-based Adaptive Volumetric Video Streaming (https://arxiv.org/abs/2409.16615)
- **What's New**: 비대칭적 볼륨 비디오 스트리밍 (Volumetric Video Streaming)의 성능을 향상시키기 위해, 기하학적 변형의 유용성을 활용한 새로운 프레임워크인 Deformation-based Adaptive Volumetric Video Streaming을 소개합니다. 이 방법은 메쉬 기반 표현의 본질적 변형 가능성을 활용하여, 새로운 프레임을 이전 프레임의 모션에서 재구성함으로써 대역폭 사용량을 크게 줄이는 동시에 각 프레임 간 시각적 일관성을 보장합니다.

- **Technical Details**: DeformStream은 인코더, 네트워크 적응, 디코더의 세 가지 주요 구성 요소로 나뉘며, GoF(Group of Frames) 개념을 기반으로 메쉬 시퀀스를 청크 방식으로 스트리밍합니다. 각 I-프레임은 최초의 메쉬 데이터와 앵커 노드 그래프를 포함하고, 후속 P-프레임은 각 노드의 변형 행렬만 포함합니다. 이러한 방식은 메쉬 간의 상관관계를 유지하여 데이터 전송을 최적화합니다.

- **Performance Highlights**: Deformation-based Adaptive Volumetric Video Streaming은 기존의 메쉬 기반 스트리밍 시스템보다 대역폭 효율성과 시각적 품질에서 모두 뛰어난 성능을 보이며, 실시간 볼륨 비디오 애플리케이션을 위한 강력한 솔루션을 제공합니다.



### Semi-LLIE: Semi-supervised Contrastive Learning with Mamba-based Low-light Image Enhancemen (https://arxiv.org/abs/2409.16604)
- **What's New**: 새로운 Semi-LLIE(Mean Teacher 기반의 준지도 저조도 이미지 향상) 프레임워크가 제안되었습니다. 이 프레임워크는 비구조적 데이터(unpaired data)를 모델 학습에 통합하여 저조도 이미지 향상의 성능을 향상시킵니다.

- **Technical Details**: Semi-LLIE는 semantic-aware contrastive loss와 Mamba 기반 저조도 이미지 향상 백본(backbone)을 활용하여 이미지를 향상시킵니다. contrastive loss는 이미지의 조명 분포를 정확하게 전달하여 자연스러운 색상을 구현하고, Mamba는 다중 스케일 특징 학습을 통해 로컬 지역의 픽셀 관계 표현을 강화합니다.

- **Performance Highlights**: Semi-LLIE는 Visdrone 및 LRSW 데이터셋에서 기존 최첨단(SOTA) 비지도 방법보다 뛰어난 성능을 보이며, 감지 태스크의 성능 향상에도 기여합니다.



### FAFA: Frequency-Aware Flow-Aided Self-Supervision for Underwater Object Pose Estimation (https://arxiv.org/abs/2409.16600)
Comments:
          ECCV 2024

- **What's New**: 본 논문에서는 자율 수중 차량(Unmanned Underwater Vehicles, UUVs)의 6D 자세 추정(pose estimation)을 위한 Frequency-Aware Flow-Aided(self-supervised) 프레임워크인 FAFA를 제시합니다. 이 프레임워크는 합성 데이터(예: synthetic data)에서 학습한 후 실제 수중 환경에 적응하는 방식으로 작동합니다.

- **Technical Details**: FAFA는 두 단계로 구성된 self-supervised 프레임워크로서, 첫 번째 단계에서는 Fast Fourier Transform(FFT)을 기반으로 하는 데이터 증강(data augmentation) 방법으로 RGB 이미지에서 도메인 불변 특징(domain-invariant features)을 추출합니다. 두 번째로, multi-level flow-aided consistencies를 통해 이미지와 피처(feature) 수준에서 정렬(alignment)을 강제하여 네트워크의 성능을 향상시킵니다.

- **Performance Highlights**: 연구자는 FAFA가 수중 6D 객체 자세 벤치마크에서 현재의 최첨단(state-of-the-art) 방법보다 현저한 성능 향상을 보였음을 입증했습니다. FAFA는 추가적인 실제 세계의 감독 신호없이도 뛰어난 성능을 자랑합니다.



### EventHallusion: Diagnosing Event Hallucinations in Video LLMs (https://arxiv.org/abs/2409.16597)
- **What's New**: 최근 다중 모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)이 비디오 이해 분야에서 큰 진전을 이루었습니다. 본 논문은 EventHallusion이라는 새로운 벤치마크를 제안하여 비디오 이벤트 이해에서 VideoLLMs의 홀루시네이션(hallucination) 문제를 평가합니다.

- **Technical Details**: EventHallusion은 VideoLLMs의 홀루시네이션 현상을 평가하기 위해 비디오와 질문을 수집하고 주의 깊게 주석을 달아, 모델이 비디오 콘텐츠를 정확하게 이해하는 대신 기존 선험적(prior) 지식에 기반해 이벤트를 해석하도록 유도합니다. 또한, Temporal Contrastive Decoding (TCD)이라는 단순하면서도 효과적인 방법을 통해 비디오 LLM의 홀루시네이션 문제를 해결합니다. TCD는 원본 비디오와 생성된 비디오를 비교하여 모델의 선험적 경향을 억제합니다.

- **Performance Highlights**: 제안된 EventHallusion 벤치마크에서 8개의 오픈소스 및 2개의 클로즈드소스 VideoLLMs를 종합적으로 평가한 결과, 오픈소스 모델은 심각한 홀루시네이션 문제를 겪는 반면, 클로즈드소스 모델은 훨씬 더 나은 성능을 보였습니다. TCD 방법으로 오픈소스 VideoLLMs를 보강함으로써 대부분의 메트릭에서 성능이 개선되었습니다.



### SelectiveKD: A semi-supervised framework for cancer detection in DBT through Knowledge Distillation and Pseudo-labeling (https://arxiv.org/abs/2409.16581)
Comments:
          10 pages, 2 figures, 1 table

- **What's New**: 이번 논문에서는 Digital Breast Tomosynthesis (DBT)용 컴퓨터 보조 탐지(CAD) 시스템에 대한 새로운 반지도 학습 프레임워크인 SelectiveKD를 제안합니다. 이 프레임워크는 제한된 수의 주석이 달린 슬라이스(slices)를 이용하여 높은 성능을 달성할 수 있도록 설계되었습니다.

- **Technical Details**: SelectiveKD는 Knowledge Distillation (KD) 개념을 활용하여 주석이 없는 DBT 슬라이스를 이용하는 접근 방식을 제공합니다. 주석이 달린 슬라이스로 학습된 teacher 모델이 student's 모델에 감독 신호를 전송하여 전체 DBT 볼륨의 슬라이스에 대한 교육을 받습니다. 이는 Pseudo Labels (PL)을 사용하여 데이터 세트를 선택적으로 확장하는 방법을 통해 노이즈 문제를 완화합니다.

- **Performance Highlights**: 10,000건 이상의 DBT exams로 구성된 대규모 실제 데이터셋을 통해 검증된 SelectiveKD는 주석이 없는 슬라이스를 효과적으로 활용하여 암 분류 성능(AUC)과 일반화 성능을 유의미하게 개선하였습니다. 이 방식은 대량의 주석 확보 비용을 절감하며 다양한 제조업체 간의 일반화 능력을 유지합니다.



### Source-Free Domain Adaptation for YOLO Object Detection (https://arxiv.org/abs/2409.16538)
Comments:
          ECCV 2024: European Conference on Computer Vision - Workshop on Out-of-Distribution Generalization in Computer Vision Foundation Models, Milan Italy

- **What's New**: 본 논문에서는 Object Detection(OD)의 Source-Free Domain Adaptation(SFDA) 분야에서 YOLO 계열의 단일 단계 탐지기를 향상시키는 새로운 방법인 Source-Free YOLO(SF-YOLO)를 제안합니다.

- **Technical Details**: SF-YOLO는 Teacher-Student 프레임워크를 기반으로 하여, 학생 모델이 특정 타겟 도메인에 대한 학습된 데이터 증강 기법을 통해 훈련됩니다. 이 방법은 레이블이 없는 타겟 데이터만을 사용하며 기능 정렬(Feature Alignment)을 요구하지 않습니다. 또한, 새로운 Student Stabilisation Module(SSM)을 도입하여 훈련의 안정성을 높이고, 레이블이 없는 상황에서의 정확도 저하 문제를 해결합니다.

- **Performance Highlights**: 실험 결과, SF-YOLO는 Cityscapes, Foggy Cityscapes, Sim10k, KITTI 데이터셋에서 여러 도전적인 도메인 적응 벤치마크에서 현재의 최고 성능을 보이는 탐지기들과 경쟁할 수 있으며, 심지어는 소스 데이터를 사용하는 적응 방법보다 나은 성능을 기록하기도 하였습니다. 저희의 접근법은 낮은 계산 자원을 요구하며, 실용적인 실시간 응용에 적합합니다.



### Prompt Sliders for Fine-Grained Control, Editing and Erasing of Concepts in Diffusion Models (https://arxiv.org/abs/2409.16535)
Comments:
          ECCV'24 - Unlearning and Model Editing Workshop. Code: this https URL

- **What's New**: 이번 논문에서는 이미지 생성 및 편집을 위한 Diffusion 모델의 새로운 접근 방식인 Factor Graph-DMs (FG-DMs)를 제안합니다. 이 방식은 기존의 방법보다 더 정밀하게 이미지 속성을 제어할 수 있는 가능성을 열어줍니다.

- **Technical Details**: FG-DMs는 이미지와 조건 변수를 모델링하기 위한 새로운 프레임워크로, 모듈화된 구조를 통해 다양한 시스템에서 작동할 수 있도록 지원합니다. FG-DM은 기존의 Stable Diffusion (SD) 모델을 기반으로 하여 조건적 변수의 분포를 학습하며, Attention Distillation Loss를 통해 생성된 조건의 신뢰성을 높입니다.

- **Performance Highlights**: FG-DM은 CelebA-HQ, ADE20K, Cityscapes 및 COCO 데이터세트에서 훈련된 결과 고품질의 이미지를 생성하며, 낮은 FID 점수와 높은 LPIPS 점수를 기록하여 이미지 다양성이 증가하는 성과를 보였습니다. 또한, Prompt Sliders 방법을 통해 새로운 개념을 학습하는 동시에 원하지 않는 개념을 삭제하는 작업이 가능하여 30% 빠른 속도를 자랑합니다.



### Low Latency Point Cloud Rendering with Learned Splatting (https://arxiv.org/abs/2409.16504)
Comments:
          Published at CVPR 2024 Workshop on AIS: Vision, Graphics and AI for Streaming (this https URL)

- **What's New**: 이번 연구는 점 구름(Point Cloud)을 사용하여 실시간 고화질 렌더링을 가능하게 하는 새로운 프레임워크를 제안합니다. 이는 동적 점 구름을 실시간으로 렌더링할 수 있는 능력을 갖추고 있으며, 기존의 렌더링 솔루션보다 우수한 품질과 속도를 자랑합니다.

- **Technical Details**: 제안된 메소드는 Point-to-Ellipsoid (P2ENet)이라는 경량 3D 희소 합성곱 신경망을 활용하여 색상이 있는 점 구름의 각 점을 3D 타원으로 변환합니다. 이후 이 타원을 스플랫팅하여 현재 관점에서의 부드러운 질감과 표면 법선을 렌더링합니다. 이러한 방식은 각 장면에 대한 최적화를 필요로 하지 않으며, 고품질의 렌더링을 가능하게 합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 100 FPS 이상의 속도로 고화질의 구멍 없는 이미지를 렌더링할 수 있으며, 초기 지연이 30 ms 미만인 것으로 확인되었습니다. 또한 환경 잡음에 대해 강력한 내성을 보입니다.



### GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization (https://arxiv.org/abs/2409.16502)
Comments:
          Project website at this https URL

- **What's New**: 본 연구에서는 3D Gaussian Splatting (3DGS) 기술을 활용하여 시각적 로컬라이제이션(visual localization)을 향상시키는 새로운 프레임워크 GSplatLoc을 제안합니다. 이 방법은 기존의 메모리 소모나 최적화 요구 사항을 해결하는 데 중점을 두고 있습니다.

- **Technical Details**: GSplatLoc은 XFeat의 경량 키포인트 감지 및 기술 모델로 생성된 고밀도 기술 맵을 활용하여 3DGS에 밀집된 키포인트 설명자(dense keypoint descriptors)를 증류(distill)합니다. 이를 통해 공간 이해도를 개선하고, 2D-3D 대응(relations)을 통해 더 정확한 카메라 포즈 예측을 가능하게 합니다. 초기 포즈 추정 후에는 포토메트릭 왜곡 손실(photometric warping loss)을 사용하여 포즈를 세분화(refine)합니다.

- **Performance Highlights**: 이번 연구는 인기 있는 실내 및 실외 데이터셋에서 벤치마킹한 결과, 기존의 최첨단 Neural Render Pose (NRP) 방법들, 특히 NeRFMatch와 PNeRFLoc을 능가하는 성과를 보여주었습니다.



### Real-Time Detection of Electronic Components in Waste Printed Circuit Boards: A Transformer-Based Approach (https://arxiv.org/abs/2409.16496)
Comments:
          International Conference on Applications in Electronics Pervading Industry, Environment and Society (ApplePies2024). Proceedings are published in the Springer Lecture Notes in Electrical Engineering

- **What's New**: 본 논문은 Waste Printed Circuit Boards (WPCBs)에서 Critical Raw Materials (CRMs)인 구리, 망간, 갈륨 등의 농도를 높여 효율적으로 추출하기 위한 방법으로 전자 부품의 선택적 분해를 제안합니다. 이를 위해 인공지능 비전 기술에 기반한 메카트로닉 시스템을 사용하여 전자 부품을 실시간으로 감지하고 위치를 추적하는 데 중점을 두었습니다.

- **Technical Details**: 연구진은 Real-Time DEtection TRansformer (RT-DETR) 모델 아키텍처를 사용하여 전자 부품 감지 및 위치 추적의 실시간 정확성을 평가했습니다. Transformer 아키텍처는 이미지의 특징을 추출하기 위해 CNN 백본을 사용하며, 이후 Transformer 인코더와 디코더를 통해 객체 요청을 처리하고 예측합니다. 논문에서는 V-PCB라는 커스텀 데이터셋을 사용하여 실험을 진행하였고, Mean Average Precision (mAP) 메트릭스를 통해 성능을 평가하였습니다.

- **Performance Highlights**: RT-DETR 모델은 최신 YOLOv8 및 YOLOv9 모델에 비해 우수한 성능을 기록했으며, 이는 인공지능 비전 기술의 장점을 활용하여 WPCBs의 CRMs 추출을 효율적으로 수행할 수 있음을 보여줍니다. 여러 가지 전자 부품에 대한 감지 작업을 통해 대량의 부품을 신속하고 정확하게 분류할 수 있는 가능성을 제시합니다.



### A Unified Hallucination Mitigation Framework for Large Vision-Language Models (https://arxiv.org/abs/2409.16494)
Comments:
          Accepted by TMLR

- **What's New**: 본 논문에서는 다양한 형태의 환각(hallucination) 문제를 해결하기 위해, 쿼리(query)를 분류하고 이를 기반으로 다양한 환각 완화(mitigation) 과정을 수행하는 통합 프레임워크인 Dentist를 제안합니다. 이를 통해 환각의 종류에 따라 각기 다른 접근방법을 적용할 수 있습니다.

- **Technical Details**: Dentist 프레임워크는 먼저 쿼리를 인식(perception)과 추론(reasoning)으로 분류하고, 각 쿼리 유형에 맞는 처리 방법을 사용합니다. 구체적으로, 감지 쿼리에 대한 생성 결과는 부차적 질문(sub-questions)을 통해 검증되며, 추론 쿼리의 경우 체인 오브 생각(Chain-of-Thought, CoT)을 활용해 검증됩니다. 이 검증 루프는 정밀도 향상을 위해 수차례 반복됩니다.

- **Performance Highlights**: MMbench에서 InstructBLIP, LLaVA, VisualGLM과 같은 기존 기법에 비해 이미지 품질 관점에서 13.44%, 10.2%, 15.8%의 정확도 향상을 달성했습니다. 또한, 우리의 방법은 다양한 비주얼 언어 작업에서 효과적이고 우수함을 입증하였습니다.



### Proactive Schemes: A Survey of Adversarial Attacks for Social Good (https://arxiv.org/abs/2409.16491)
Comments:
          Submitted for review

- **What's New**: 본 논문은 컴퓨터 비전 분야에서 적대적 공격(adversarial attack)이 머신 러닝 모델의 취약점을 악용하는 방식과 이에 대한 방어적 접근으로 사회적 이익을 추구하는 방법을 다룹니다. 특히, 새로운 proactive schemes를 통해 입력 데이터를 암호화하고 심층 학습 모델의 성능을 향상시키는 방안을 제시합니다.

- **Technical Details**: 적대적 공격은 입력 데이터에 미세한 섭동(perturbation)을 추가하여 잘못된 예측이나 분류를 유도합니다. 본 연구에서는 'templates'이라 불리는 추가 신호를 사용하여 입력 데이터를 암호화하고, 이를 통해 다양한 컴퓨터 비전 및 자연어 처리(natural language processing) 응용 프로그램에 적용할 수 있는 proactive schemes를 설명합니다. 이러한 방법론은 전통적인 passive schemes와 달리 입력 데이터 분포를 변경하지 않고 성능을 개선할 수 있습니다. 또한, 매체의 보안을 유지하며 원본과 비교하여 품질을 보장하는 암호화 및 학습 과정에 대해 설명합니다.

- **Performance Highlights**: proactive schemes는 다양한 응용 분야에서의 성능을 향상시킬 수 있는 잠재력을 가지고 있습니다. 예를 들어, 이미지 개선, 인공지능 생성 모델(GenAI) 및 대형 언어 모델(LLM) 방어, 저작권 보호 및 개인 정보 보호 등의 응용이 가능합니다. 이 논문은 다양한 template 유형 및 그에 따른 암호화 과정, 학습 목표를 탐구하며, 향후 발전 방향과 함께 현재의 한계점에 대해 논의합니다.



### Frequency-based View Selection in Gaussian Splatting Reconstruction (https://arxiv.org/abs/2409.16470)
Comments:
          8 pages, 4 figures

- **What's New**: 이번 연구에서는 3D Gaussian Splatting을 사용한 3차원 재구성을 위한 능동적인 시점 선택 문제를 다루고 있습니다. 기존의 방법들이 특정 장면에 일반화하는 데 어려움이 있었던 반면, 본 연구는 주파수 영역에서 가능성 있는 뷰를 순위 매김하여 새로운 시점의 정보 이득을 효과적으로 추정할 수 있는 방법을 제안합니다. 이로 인해 제한된 수의 입력 이미지로도 효율적인 3D 재구성이 가능합니다.

- **Technical Details**: 이 알고리즘은 처음에 몇 개의 이미지를 입력받고, Gaussian Splatting 모델의 렌더링 결과를 바탕으로 방문할 시점을 능동적으로 생성합니다. 이 방식은 기존 모델 아키텍처 및 효율성의 제약을 극복하여 3D-GS 모델에 맞춤화된 카메라 뷰 선택 파이프라인을 생성합니다. SfM(Structure-from-Motion) 알고리즘을 통해 카메라 포즈를 계산하고, 스프레드 포인트 클라우드를 기반으로 3D Gaussians를 생성합니다.

- **Performance Highlights**: 제안된 방법은 데이터셋에서 단 1/3의 뷰로 합리적인 렌더링 결과를 도출하며, 뷰포인트 간의 이동 거리도 크게 줄였습니다. 이는 3D 재구성을 위한 능동적인 뷰 선택에서 최첨단 성과를 나타냅니다.



### Underground Mapping and Localization Based on Ground-Penetrating Radar (https://arxiv.org/abs/2409.16446)
- **What's New**: 본 논문은 Ground Penetrating Radar (GPR) 데이터를 활용한 심층 신경망 기반의 포물선 신호 감지 네트워크를 소개합니다. GPR 센서의 B-scan 이미지를 사용하여 지하 객체의 3D 재구성과 점 군 지도 생성에 기여하며, 기존의 단일 작업 기반 알고리즘을 다중 작업 네트워크로 발전시켰습니다.

- **Technical Details**: 제안하는 ParNet은 GPR B-scan 데이터에서 주요 포인트를 감지하고, 포물선 방정식을 적합하여 지하 객체의 단면 깊이를 계산합니다. GPRNet은 희소 점 군을 세분화 및 보완하여 밀집된 3D 점 군을 생성합니다. 또한, NetVLAD을 통해 A-scan 데이터에서 특성을 추출하여 알려지지 않은 위치에서의 로컬라이징을 수행합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 GPR 데이터를 기반으로 한 지하 객체 위치 추정 및 3D 재구성이 효과적임을 증명하였으며, 복잡한 지하 환경에서 점 군의 보완 및 정확한 매칭을 통한 정확성을 향상시켰습니다.



### Hand Gesture Classification Based on Forearm Ultrasound Video Snippets Using 3D Convolutional Neural Networks (https://arxiv.org/abs/2409.16431)
Comments:
          Accepted to IUS 2024

- **What's New**: 본 연구에서는 3D CNN 기술을 활용하여 손 동작 인식을 위한 초음파 비디오 세그먼트에서 시공간(spatiotemporal) 패턴을 캡처합니다. 기존의 2D CNN을 사용한 연구와는 달리, 연속 손 동작에 따른 초음파 데이터의 시간적 특성을 반영하여 제안된 모델의 성능을 향상시켰습니다.

- **Technical Details**: 이 연구에서는 3명의 피실험자가 12개의 손 동작을 수행하는 동안 촬영된 초음파 데이터를 사용했습니다. (2+1)D 컨볼루션 신경망 모델이 기존의 2D 및 3D CNN 모델과 비교되었습니다. 데이터 전처리 과정에서 모션 캡처 시스템을 사용해 실제 손가락 각도를 계산하고, 초음파 이미지를 크기가 224x224로 크롭하여 학습에 적합하도록 변환했습니다.

- **Performance Highlights**: 제안된 모델은 손 동작 분류 정확도를 96.5%에서 98.8%로 향상시켰으며, 이는 초음파 비디오 스니펫을 사용하여 손 동작 분류 성능을 개선하는데 있어 뛰어난 장점을 보여줍니다.



### Leveraging Local Structure for Improving Model Explanations: An Information Propagation Approach (https://arxiv.org/abs/2409.16429)
- **What's New**: 최근 심층 신경망(DNN) 모델의 결정 해석을 위한 다양한 설명 방법들이 개발되었으며, 본 논문에서는 IProp이라는 새로운 방법을 제안합니다. IProp은 각 픽셀의 기여도를 독립적으로 평가하는 대신, 이웃 픽셀과의 구조적 유사성을 고려해 공동으로 평가합니다.

- **Technical Details**: IProp은 각 픽셀의 기여도를 설명 정보의 소스로 모델링하며, Markov Reward Process(MRP)를 통해 모든 픽셀 간의 정보 전파를 다이나믹하게 처리합니다. 정보 전파는 연속적으로 발생하며, 픽셀 간의 상관관계를 포착합니다.

- **Performance Highlights**: IProp은 다양한 DNN 모델과 기존 설명 방법에 대한 실험을 통해 해석 가능성 메트릭에서 현저한 개선을 확인했으며, 정량적 및 정성적으로 모든 기준 방법보다 우수한 결과를 보여주었습니다.



### Improving Intersession Reproducibility for Forearm Ultrasound based Hand Gesture Classification through an Incremental Learning Approach (https://arxiv.org/abs/2409.16415)
Comments:
          Accepted to IUS 2024

- **What's New**: 이번 연구는 초음파 (ultrasound)를 이용한 손 제스처 분류 (hand gesture classification)에서 모델을 여러 세션에 걸쳐 훈련 (training)하여 일반화하는 방법을 제안했습니다. 이를 통해 초음파 프로브를 이동하거나 교체한 경우에도 정확도를 유지할 수 있는 모델을 개발할 수 있었습니다.

- **Technical Details**: 이 연구에서는 CNN (Convolutional Neural Network)을 사용하여 데이터 수집 세션에서 수집된 초음파 이미지를 학습했습니다. 순차적으로 5개의 convolution 레이어와 후속된 dense 레이어를 사용하여 5가지 손 제스처를 분류했습니다. 또한, 모델의 상위 레이어는 동결되어 기능 추출기에 따라 조정되었고, 낮은 레이어는 새로운 데이터를 기반으로 점진적으로 학습되었습니다.

- **Performance Highlights**: 연구 결과, 2회의 점진적 fine tuning 세션 후 모델의 분류 정확도가 약 10% 증가했습니다. vanilla 모델의 평균 정확도는 85.4%였고, fine tuning 후 1회차에서는 93.8%, 2회차에는 95.5%로 상승했습니다. 이러한 결과는 모델의 정확도가 향상되었음을 보여주며, 데이터 저장 공간과 처리 능력을 절약할 수 있음을 나타냅니다.



### Camera Calibration and Stereo via a Single Image of a Spherical Mirror (https://arxiv.org/abs/2409.16386)
Comments:
          12 pages, 11 figures

- **What's New**: 이 논문은 구면 거울(spherical mirror)을 사용하는 단일 뷰(camera view)를 통해 카메라 보정을 위한 새로운 기법을 제시합니다. 이 기법은 이미지에서 볼 수 있는 구의 윤곽과 그 반사를 활용하여 정밀한 보정을 달성하는 효과를 보여줍니다.

- **Technical Details**: 저자들은 카다이옵트릭(stereo imaging) 시스템에서 단일 구면 거울을 이용한 방법을 다루고 있으며, 카메라 매트릭스(calibration matrix) 보정과 카다이옵트릭 스테레오를 동시에 수행합니다. 이 연구는 카메라의 반사, 구면 거울에 있는 두 쌍의 대응 점 또는 특별한 경우의 단일 대응을 통하여 구의 중심 및 윤곽을 찾는 방법을 제안합니다.

- **Performance Highlights**: 실험 결과는Synthetic 및 실제 데이터 모두를 포함하여 제안된 접근법의 실행 가능성 및 정확성을 입증합니다. 해당 연구는 단순한 카다이옵트릭 스테레오 시스템 개발에 기여할 수 있는 잠재력을 보여줍니다.



### Towards Synthetic Data Generation for Improved Pain Recognition in Videos under Patient Constraints (https://arxiv.org/abs/2409.16382)
Comments:
          Pain Recognition Synthetic Data Video Analysis Privacy Preserving

- **What's New**: 이 연구는 비디오 기반의 통증 인식을 향상시키기 위해 합성 데이터(synthetic data)를 활용하는 혁신적인 접근 방식을 소개합니다. 기존의 데이터 수집 방식이 윤리적 및 물리적 도전과제를 포함하는 반면, 본 연구에서는 작은 데이터 세트를 통해 3D 얼굴 모델을 합성하여 다양한 시점에서 통증 표정을 반영합니다. 이를 통해 8,600개의 합성 얼굴을 생성하고, 실제 데이터와 결합하여 통증 인식 모델의 성능을 개선할 수 있음을 보여줍니다.

- **Technical Details**: 본 연구에서는 고급 얼굴 캡처 기법을 사용하고, CelebV-HQ 및 FFHQ-UV와 같은 공개 데이터셋을 활용하여 인구 통계학적 다양성을 확보했습니다. 참여자의 얼굴을 대체하여 개인 정보를 보호하며, 3D CNN을 적용하여 비디오 기반의 통증 인식 모델을 훈련하는데 필요한 합성 데이터셋을 생성했습니다.

- **Performance Highlights**: 합성 데이터로 훈련한 모델이 실제 참가자의 소량 데이터와 함께 사용될 때, 통증 인식 성능이 현저히 향상되었습니다. 본 접근 방식은 데이터 부족과 윤리적 문제를 해결하며, 프라이버시를 유지하는 데이터셋 생성의 새로운 연구 방향을 제공합니다. 모든 리소스는 공개되어 있어 이 분야에서의 혁신을 촉진할 수 있도록 하고 있습니다.



### Instance Segmentation of Reinforced Concrete Bridges with Synthetic Point Clouds (https://arxiv.org/abs/2409.16381)
Comments:
          33 pages, 12 figures, Submitted to "Automation in Construction"

- **What's New**: 위 논문에서는 다리 구조물의 요소 수준 검사 자동화를 위한 새로운 접근 방식을 제안합니다. 이 접근 방식은 세 가지 독특한 방법을 사용하여 합성 데이터를 생성하며, 기존 연구에서 부족했던 인스턴스 세분화(instance segmentation)에 초점을 맞춥니다.

- **Technical Details**: 제안된 프레임워크는 Mask3D transformer 모델을 활용하며 하이퍼파라미터 조정(hyperparameter tuning)과 새로운 차폐 기법(occlusion technique)으로 최적화됩니다. 이 모델은 실제 LiDAR와 포토그래메트리(photogrammetry)로 수집된 다리 포인트 클라우드에서 최첨단 성능을 달성합니다.

- **Performance Highlights**: 이 연구는 요소 수준 다리 검사 자동화를 위한 프레임워크의 가능성을 보여주며, 더욱 포괄적인 상태 문서화를 통해 전체 다리 관리의 향상을 기대할 수 있습니다.



### Development and Application of a Sentinel-2 Satellite Imagery Dataset for Deep-Learning Driven Forest Wildfire Detection (https://arxiv.org/abs/2409.16380)
- **What's New**: 본 연구에서는 Google Earth Engine(GEE)에서 소싱한 양 시점의 Sentinel-2 위성 이미지를 활용하여 10만 개 이상의 레이블이 부착된 산불 전후 이미지 쌍으로 이루어진 California Wildfire GeoImaging Dataset(CWGID)을 구축하여 딥러닝(DL)을 통한 산불 탐지를 위해 기여하고자 하였습니다.

- **Technical Details**: CWGID는 고해상도 위성 이미지 데이터셋으로, 데이터 획득은 권위 있는 출처에서 이루어졌으며, 세 가지 사전 훈련된 Convolutional Neural Network(CNN) 아키텍처를 활용하여 초기 데이터세트 분석이 진행되었습니다. 특히 EF EfficientNet-B0 모델이 산불 탐지에서 92% 이상의 정확도를 달성하였습니다.

- **Performance Highlights**: CWGID와 이를 구축하는 방법론은 DL 아키텍처 훈련 및 테스트를 위한 귀중한 자원으로 작용하며, 모델 훈련 및 평가 시 높은 정확도와 낮은 손실을 기록하였습니다. 본 연구는 산불 탐지를 위한 높은 품질의 레이블 이미지 데이터셋의 필요성을 강조하며, 산불 전후 이미지를 사용하여 성능을 개선하는 데 기여하고 있습니다.



### LiDAR-3DGS: LiDAR Reinforced 3D Gaussian Splatting for Multimodal Radiance Field Rendering (https://arxiv.org/abs/2409.16296)
- **What's New**: 이번 논문에서는 3D Gaussian Splatting(3DGS) 기반의 Radiance Field Rendering에 LiDAR 입력을 활용한 혁신적인 방법인 LiDAR-3DGS를 소개합니다.

- **Technical Details**: LiDAR-3DGS는 LiDAR로 생성된 포인트 클라우드를 이용해 3DGS 입력을 보강하여 3D 모델의 정확성 및 세부사항을 크게 향상시킵니다. 이 방법은 볼트, 구멍 및 기타 중요한 특징들을 포착하는 데 도움을 주며, 이는 원격 모니터링 및 유지보수와 같은 엔지니어링 응용에 매우 중요합니다. 3DGS 알고리즘을 수정하지 않고도, LiDAR 포인트 클라우드의 소폭 추가로 모델의 인지 품질이 향상됨을 보여주었습니다.

- **Performance Highlights**: 모델이 30,000회 반복 실행 이후 PSNR(피크 신호 대 잡음 비율)이 7.064% 증가하고 SSIM(구조적 유사도 지표)이 0.565% 개선되었습니다. 사용된 LiDAR는 상용 등급의 기기였으며, 향후 더 고급 LiDAR 시스템을 통해 이러한 개선은 더욱 발전할 수 있습니다.



### GenCAD: Image-Conditioned Computer-Aided Design Generation with Transformer-Based Contrastive Representation and Diffusion Priors (https://arxiv.org/abs/2409.16294)
Comments:
          24 pages, 13 figures

- **What's New**: 이번 논문에서는 GenCAD라는 새로운 생성 모델을 소개합니다. 이 모델은 CAD 명령어 시퀀스로 변환하여 편집 가능한 3D 형태를 생성하며, 이미지 입력을 통해 CAD 프로그램을 생성합니다.

- **Technical Details**: GenCAD는 autoregressive transformer와 latent diffusion 모델을 통합하여 이미지에서 CAD 명령 시퀀스를 생성합니다. 이를 위해 contrastive learning 프레임워크를 활용하여 CAD 이미지와 CAD 명령 시퀀스의 공동 분포를 학습합니다.

- **Performance Highlights**: GenCAD는 기존의 최신 방법들보다 3D 형상 생성의 정밀도와 수정 가능성 면에서 월등한 성능을 보였습니다. 특히, 긴 시퀀스의 3D 형상 생성 정확도가 크게 향상되어 복잡한 설계 작업에 적합합니다.



### Explaining Human Comparisons using Alignment-Importance Heatmaps (https://arxiv.org/abs/2409.16292)
- **What's New**: 이 논문에서는 사람의 유사성 판단을 비교하는 과정을 설명하기 위해 Alignement Importance Score (AIS) 열지도를 제안하고 있습니다. AIS는 Deep Neural Network (DNN)의 표현 기하학과 인간의 그것 사이의 정렬에 대한 기여도를 측정합니다.

- **Technical Details**: 이 연구는 DNN의 마지막 합성곱 층에서 핀셋하여 이미지에 대한 중요한 정보를 설명합니다. 구체적으로, AIS를 활용하여 높은 평가 점수를 가진 특징 맵만 사용하여 인간의 유사성 판단을 예측하는 데 있어 정확도를 높입니다. 연구는 전통적인 saliency map과 비교하여 결과의 해석 가능성을 평가합니다.

- **Performance Highlights**: DNN의 임베딩으로부터 인간의 유사성 판단을 예측하는 데 Alignment Importance가 개선된 결과를 보였으며, 이미지 공간에서 어떤 정보가 중요한지를 설명하는 통찰력을 제공합니다.



### PACE: marrying generalization in PArameter-efficient fine-tuning with Consistency rEgularization (https://arxiv.org/abs/2409.17137)
Comments:
          Accepted by NeurIPS 2024 as a spotlight. This preliminary version will soon be extended with the experiments and analyses from the rebuttal

- **What's New**: 본 연구는 Parameter-Efficient Fine-Tuning (PEFT) 방법의 일반화 문제를 해결하기 위해 새로운 접근 방식을 제안합니다. PACE라는 방법은 작은 gradient norm과 대규모 데이터셋의 관계를 이론적으로 연결하고, 이를 통해 fine-tuned 모델의 일반화를 향상시키는 것을 목표로 합니다.

- **Technical Details**: PACE는 두 가지 주요 전략을 결합합니다. 첫째, ADAPT에 의해 학습된 feature에 대해 multiplicative noise를 적용하여 perturbation을 일으킵니다. 둘째, 다양한 perturbation 아래에서 fine-tuned 모델의 출력이 일관되게 유지되도록 합니다. 이를 통해 gradient regularization이 강화되어 모델의 일반화 성능이 향상됩니다.

- **Performance Highlights**: PACE는 VTAB-1k, FGVC, few-shot learning, domain adaptation 등 4가지 비주얼 적응 작업에서 기존 PEFT 방법들을 능가하는 성과를 보여줍니다. 이 연구는 날로 증가하는 모델의 크기와 복잡성을 관리하는 데 중요한 통찰을 제공합니다.



### Classification of Gleason Grading in Prostate Cancer Histopathology Images Using Deep Learning Techniques: YOLO, Vision Transformers, and Vision Mamba (https://arxiv.org/abs/2409.17122)
- **What's New**: 이 연구에서는 전립선암 진단을 위한 Gleason 등급 분류 자동화를 위해 YOLO, Vision Transformers, Vision Mamba의 세 가지 딥러닝 (deep learning) 방법론의 효과를 비교합니다.

- **Technical Details**: Gleason2019 및 SICAPv2이라는 두 개의 공개 데이터셋을 사용하여 각 모델의 성능을 훈련하고 테스트했습니다. 각 모델은 false positive rate, false negative rate, precision, recall과 같은 메트릭을 기반으로 평가되었습니다.

- **Performance Highlights**: Vision Mamba는 모든 성능 지표에서 우수한 성과를 보였으며, 높은 precision과 recall을 유지하면서 false positives 및 negatives를 최소화했습니다. YOLO는 실시간 분석에 유리한 속도와 효율성을 보여주었으며, Vision Transformers는 이미지 내 긴 거리 종속성을 잘 포착했지만 다른 모델들에 비해 더 높은 계산 복잡성을 나타냈습니다.



### The Effect of Perceptual Metrics on Music Representation Learning for Genre Classification (https://arxiv.org/abs/2409.17069)
Comments:
          arXiv admin note: text overlap with arXiv:2312.03455

- **What's New**: 이 연구에서는 음악 이해 작업, 특히 장르 분류에 대한 성능을 향상시킬 수 있는 방법으로, 지각 메트릭(perceptual metrics)을 활용하는 새로운 접근법을 제안합니다. 특히, 자기 부호화기(autoencoders)로부터 추출된 특징을 사용하여 지각 손실(perceptual losses)로 훈련된 모델이 장르 분류를 개선할 수 있음을 입증했습니다.

- **Technical Details**: 지각 메트릭은 인간 관찰자의 지각 행동을 근사하는 데 설계된 객관적인 측정 지표입니다. 예를 들어, 구조적 유사도(SSIM)와 정규화된 라플라스 피라미드 거리(NLPD)와 같은 지표를 스펙트로그램(spectrograms)에 적용하여 오디오 품질에 대한 인간 평가와 더 나은 연관성을 보이는 것을 보여주었습니다. 이들 메트릭은 모델 훈련 시 손실 함수(loss function)으로 사용되어 모델의 성능을 개선할 수 있습니다.

- **Performance Highlights**: K-최근접 이웃(K-Nearest Neighbours) 분류기를 사용할 때, 전통적인 MSE(mean squared error)보다 지각 메트릭을 통한 성능 향상이 나타났습니다. 특히 로지스틱 회귀(Logistic Regression) 모델은 자기 부호화기에서 추출된 잠재 특징(latent features)을 활용할 때 높은 F1 점수를 기록했습니다. 그러나 NLPD는 군집화(clustering) 거리 측정에는 적합하지 않은 것으로 나타났으며, 이는 불필요한 정보를 제거함으로써 느리게 변화하는 부분들을 배제하기 때문입니다.



### Automated Surgical Skill Assessment in Endoscopic Pituitary Surgery using Real-time Instrument Tracking on a High-fidelity Bench-top Phantom (https://arxiv.org/abs/2409.17025)
Comments:
          7 pages, 6 figures

- **What's New**: 이 연구에서는 내시경 뇌하수체 수술의 비강 단계를 시뮬레이션한 새로운 공개 데이터 세트를 소개하였습니다. 이는 수술 기술 평가를 자동화하는 데 필요한 새로운 기반 모델 PRINTNet을 개발하고, 수술 기술 수준을 예측하는 데 사용되는 다양한 인사이트를 제공합니다.

- **Technical Details**: PRINTNet (Pituitary Real-time INstrument Tracking Network)은 DeepLabV3를 사용한 분류 및 세분화, StrongSORT를 이용한 추적, 그리고 NVIDIA Holoscan SDK를 통한 실시간 성능으로 구성됩니다. 이 모델은 22 Frames Per Second (FPS)에서 71.9%의 Multiple Object Tracking Precision을 달성했습니다.

- **Performance Highlights**: MULTILAYER Perceptron은 수술 기술 수준을 예측하는 데 87%의 정확도를 기록하였으며, '전체 절차 시간 대비 도구 가시 시간의 비율'이 높은 수술 기술과 상관관계가 있음을 나타냈습니다. 이 연구는 시뮬레이션된 내시경 뇌하수체 수술에서 자동화된 수술 기술 평가의 가능성을 보여줍니다.



### WasteGAN: Data Augmentation for Robotic Waste Sorting through Generative Adversarial Networks (https://arxiv.org/abs/2409.16999)
Comments:
          Accepted at 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)

- **What's New**: 이번 논문에서는 로봇 폐기물 분류 문제를 해결하기 위한 획기적인 접근으로 WasteGAN이라는 새로운 GAN(Generative Adversarial Network) 아키텍처를 소개합니다. 이 방법은 제한된 라벨링된 데이터를 사용하여 성능을 향상시키기 위한 데이터 증대(data augmentation) 기법을 적용합니다.

- **Technical Details**: WasteGAN은 새로운 손실 함수(loss function)와 활성화 함수(activation function), 그리고 더 큰 생성기 블록(generator block)을 포함하고 있어, 네트워크가 제한된 예제 수로부터 학습하고 실제 세계 분포를 더 잘 반영하는 데이터를 합성할 수 있도록 돕습니다. 이 기술은 특히 폐기물 처리 분야의 비구조적 장면에서의 학습에 중점을 두고 있습니다.

- **Performance Highlights**: WasteGAN을 기반으로 한 데이터 증대 방법은 ZeroWaste 데이터셋에서 다양한 최첨단 세그멘테이션(segmentation) 모델을 훈련하는 데 효과적임이 입증되었습니다. 논문에서는 성능이 최대 5.8% 향상되었음을 보고하며, 실제 로봇 폐기물 분류 시스템에 통합하여 탁월한 성과를 보였습니다.



### PitRSDNet: Predicting Intra-operative Remaining Surgery Duration in Endoscopic Pituitary Surgery (https://arxiv.org/abs/2409.16998)
Comments:
          Accepted to the Augmented Environments for Computer-Assisted Interventions (AE-CAI) Workshop at the Medical Image Computing and Computer-Assisted Interventions (MICCAI) Conference 2024

- **What's New**: 이 논문은 내시경 뇌하수체 수술 중 수술의 남은 시간(Remaining Surgery Duration, RSD) 예측을 위한 새로운 모델, PitRSDNet을 제안합니다. 이 모델은 과거 데이터를 활용하여 작업 흐름에 중점을 둔 spatio-temporal neural network 모델입니다.

- **Technical Details**: PitRSDNet은 두 가지 형태로 작업 흐름 지식을 RSD 예측에 통합합니다: 1) RSD와 단계(step)를 동시에 예측하는 multi-task learning; 2) 시간 학습과 추론에서 이전 단계를 맥락으로 포함시킵니다. 이 모델은 88개의 비디오로 구성된 새로운 내시경 뇌하수체 수술 데이터셋에서 훈련 및 평가되어 이전의 통계적 및 기계 학습 방법보다 경쟁력 있는 성능 개선을 보여줍니다.

- **Performance Highlights**: PitRSDNet은 수술의 마지막 10-20분 동안 5분 이하의 오차를 예상하며, 전체 수술 시간에 대해서는 10분 이하의 오차를 가지는 것이 기대됩니다. 연구 결과는 PitRSDNet이 이전 단계의 지식을 활용하여 이상치(outlier) 사례에서 RSD의 정밀성을 개선하는 방법을 강조합니다.



### Multi-Robot Informative Path Planning for Efficient Target Mapping using Deep Reinforcement Learning (https://arxiv.org/abs/2409.16967)
Comments:
          arXiv admin note: text overlap with arXiv:2402.04894

- **What's New**: 자율 로봇이 업무를 수행하는 과정에서, 한정된 자원 예산 아래에서 정보 수집과 탐색을 극대화하기 위해 새로운 심층 강화 학습 기법을 제안했습니다.

- **Technical Details**: 우리의 접근 방식은 다중 로봇(멀티 로봇) 정보 경로 계획(Informative Path Planning, IPP) 문제를 해결하기 위해 증강 그래프를 활용합니다. 이는 통신 및 로봇 간 충돌 회피를 위한 계획을 가능하게 합니다. 각각의 로봇은 제한된 감지 범위를 가진 UAV로 구성되어 있으며, 통신 모듈을 통해 모든 인근 로봇과 정보를 전송합니다.

- **Performance Highlights**: 제안한 방안은 초점 탐색 목표 발견 수에서 기존의 최첨단 다중 로봇 목표 매핑 기술보다 33.75% 더 뛰어난 성능을 보였으며, 여러 UAV를 사용하는 도시 감시 시나리오에서 실제 성능을 검증하였습니다.



### Go-SLAM: Grounded Object Segmentation and Localization with Gaussian Splatting SLAM (https://arxiv.org/abs/2409.16944)
- **What's New**: 새로운 Go-SLAM 프레임워크를 소개하며, 3D Gaussian Splatting SLAM을 활용하여 동적 환경을 재구성하고 장면 표현 내에서 객체 수준 정보를 통합합니다. 이 시스템은 고급 객체 분할 기술을 사용하여 각 Gaussian splat에 고유한 식별자를 할당합니다.

- **Technical Details**: Go-SLAM은 3D Gaussian Splatting을 기반으로 하며, 객체 감지 및 세분화 모델을 포함하여 고급 컴퓨터 비전 기술을 활용하여 환경을 재구성합니다. 또한, 자연어 처리 기술을 활용하여 사용자 또는 고급 계획 알고리즘이 객체를 유연하게 쿼리할 수 있도록 합니다.

- **Performance Highlights**: 종합적인 평가 결과, 다양한 장면 설정에서 정밀도와 recall, IoU가 각각 17%, 27%, 35% 개선되는 것을 보여주며, Go-SLAM의 효율성을 입증합니다.



### Going Beyond U-Net: Assessing Vision Transformers for Semantic Segmentation in Microscopy Image Analysis (https://arxiv.org/abs/2409.16940)
Comments:
          to be published in ECCV 2024 BioImage Computing Workshop

- **What's New**: 이 논문은 전통적인 U-Net 모델과 최신 변환기(transformer) 기반 모델 간의 비교를 통해 생물 의학 이미지 세분화에서의 성능 향상을 제시합니다. 특히, UNETR, Segment Anything Model, Swin-UPerNet 모델을 활용하여 전자 현미경, 밝은 필드, 조직 병리학, 위상 대비와 같은 다양한 이미지 모달리티에서 이들 모델을 평가합니다.

- **Technical Details**: 변환기 기반 모델은 Attention Mechanism을 활용하여 이미지 구조를 분석하며, ViT(Vision Transformer) 및 Swin Transformer와 같은 최신 기술을 포함합니다. 이는 이미지 세분화에서 로컬 컨텍스트를 더욱 잘 포착하고, 수용 필드를 확장할 수 있게 해줍니다. 특히, Swin Transformer를 이용한 UPerNet 기반 디코더의 구조적 개선을 통해 세부 사항 잡기 및 세분화 정확도를 향상하는 방법을 제안합니다.

- **Performance Highlights**: 개선된 Swin-UPerNet 모델은 기존의 U-Net 모델과 비개선된 Swin-UPerNet 대비 세분화 성능이 향상된 결과를 보였습니다. 이는 변환기 기반 모델이 생물 의학 이미지 세분화의 효율성과 적용 가능성을 높일 수 있는 가능성을 보여줍니다.



### Moner: Motion Correction in Undersampled Radial MRI with Unsupervised Neural Representation (https://arxiv.org/abs/2409.16921)
Comments:
          18 pages, 13 pages

- **What's New**: 최근 연구에서는 움직임 보정(motion correction, MoCo) 문제를 해결하기 위해 여러 기법들이 제안되었습니다. 본 논문에서는 Moner라는 새로운 비지도 학습 MoCo 방법을 제안하여, 고품질의 MR 이미지를 확보하기 위한 대규모 데이터셋 없이도 정확한 움직임을 추정할 수 있습니다.

- **Technical Details**: Moner는 암묵적 신경 표현(Implicit Neural Representation, INR)을 활용하여 비선형 문제를 해결합니다. INR에 준정적(quasi-static) 모션 모델을 통합하고 푸리에 슬라이스 정리를 활용하여 radial MRI 복구를 역 투영(back-projection) 문제로 재구성합니다. 이 방법은 MRI k-space 데이터로 인해 발생하는 고역(dynamics) 문제를 완화하여 안정적인 모델 최적화를 도모합니다.

- **Performance Highlights**: Moner는 두 개의 공공 MRI 데이터셋(fastMRI와 MoDL)에서 평가했으며, 도메인 내(data in-domain)에서는 최신의 MoCo 기술과 유사한 성능을 보였고, 도메인 외(out-of-domain) 데이터에서 상당한 성능 향상을 보여주었습니다.



### Towards General Text-guided Image Synthesis for Customized Multimodal Brain MRI Generation (https://arxiv.org/abs/2409.16818)
Comments:
          23 pages, 9 figures

- **What's New**: 본 논문에서는 TUMSyn이라는 텍스트 기반의 범용 MR 이미지 생성 모델을 제안합니다. 이 모델은 정기적으로 수집된 스캔 데이터로부터 요구되는 이미징 메타데이터를 기반으로 뇌 MR 이미지를 유연하게 생성할 수 있습니다.

- **Technical Details**: TUMSyn 모델은 31,407개의 3D 이미지를 포함하는 대규모 뇌 MR 데이터베이스를 기반으로 훈련됩니다. 우리는 대칭적 학습(contrastive learning)을 사용하여 텍스트 인코더를 미리 훈련하고, 이를 통해 메타데이터에서 관련된 이미지 기능을 효과적으로 추출합니다. 두 단계의 훈련 전략을 통해 이미지와 텍스트 페어를 조정하여 MR 이미지를 생성합니다.

- **Performance Highlights**: TUMSyn은 다양한 데이터셋과 임상 평가에서 높은 성능을 보여주었습니다. PSNR(최대 신호 대 잡음 비율)은 2.86 dB까지 향상되었으며, SSIM(구조적 유사성 지수)은 0.044의 개선을 보였습니다. 또한, TUMSyn은 적응성이 뛰어난 제로샷 학습(zero-shot learning)에서 우수한 성능을 발휘하며, 뇌 종양 영역의 정확한 합성을 통해 진단 지원에 활용 가능성을 나타냅니다.



### Inline Photometrically Calibrated Hybrid Visual SLAM (https://arxiv.org/abs/2409.16810)
- **What's New**: 본 논문은 Hybrid direct-indirect visual SLAM (H-SLAM)에 온라인 순차적 photometric calibration을 통합한 새로운 접근을 제시합니다. 이를 통해 다양한 조명 조건에서의 픽셀 강도 값을 정규화하여 H-SLAM의 정확성을 개선하고, 기존 SLAM 시스템에 비해 월등한 성능을 보여줍니다.

- **Technical Details**: 본 연구에서는 Online Sequential Photometric Calibration (OSPC) 기술을 H-SLAM에 통합하여, 카메라의 응답 함수(Camera Response Function, CRF)와 비네팅(vignetting)을 순차적으로 추정하고 이를 통해 V-SLAM의 입력 프레임을 교정합니다. 이 과정은 더욱 안정적이고 일관된 피쳐 추적 및 깊이 추정을 가능하게 합니다.

- **Performance Highlights**: 실험 결과, photometrically calibrated H-SLAM은 TUM monoVO와 자작 데이터셋을 포함한 여러 테스트에서 다른 최첨단 SLAM 시스템보다 뛰어난 성능을 보였습니다. 특히, 실시간 SLAM 테스트에서는 기존 SLAM 시스템들을 현저히 능가하는 결과를 기록했습니다.



### Scalable Ensemble Diversification for OOD Generalization and Detection (https://arxiv.org/abs/2409.16797)
Comments:
          Under review

- **What's New**: 본 연구는 Scalable Ensemble Diversification (SED)라는 새로운 방법론을 제시하여 기존의 다양한 앙상블 학습 방법의 한계를 극복합니다. 특히, OOD 샘플 없이도 대규모 데이터에서 효과적으로 적용할 수 있는 방식으로 설계되었습니다.

- **Technical Details**: SED는 세 가지 주요 기술적 혁신을 통해 발전되었습니다: (1) 하드 샘플을 동적으로 식별하여 모델 간의 불일치를 유도합니다. (2) 각 반복에서 무작위로 선택된 두 모델에 대해서만 다양화 목표를 적용하여 계산 비용을 줄입니다. (3) 네트워크의 출력 근처의 일부 레이어에만 영향을 미치도록 하여 심층 네트워크에서의 다양화 목표를 조정합니다.

- **Performance Highlights**: ImageNet에서의 실험을 통해 SED의 다양한 이점을 확인했습니다. OOD 일반화와 OOD 탐지 모두에서 성능이 상당히 향상되었으며, Predictive Diversity Score (PDS) 방법론은 OOD 샘플 탐지에서 기존 방법들을 초월하는 성능을 보였습니다.



### Let There Be Light: Robust Lensless Imaging Under External Illumination With Deep Learning (https://arxiv.org/abs/2409.16766)
Comments:
          4 pages, dataset: this https URL

- **What's New**: 이 논문은 렌즈가 없는 카메라에서 외부 조명(ambient lighting)이 가지는 중요성을 다룹니다. 기존 연구에서는 대상 물체에서 방출된 빛에만 초점을 맞추었으나, 이 연구는 다양한 조명 조건에서의 데이터 세트를 제공하고 외부 조명을 고려한 복구 기술을 제안합니다.

- **Technical Details**: 제안된 방법은 물리 기반의 이미지 복구 기술로, 외부 조명의 추정치를 이미지 복구 과정에 통합합니다. 연구진은 25K 개의 다양한 조명 조건에서 측정된 렌즈 없는 데이터셋을 오픈소스로 배포하였으며, 이를 통해 모델 기반 최적화와 신경망(neural network) 기법을 결합하여 이미지 품질을 크게 향상시킬 수 있음을 보여줍니다.

- **Performance Highlights**: 제안된 기법은 기존 재구성 방법들과 비교할 때 질적 및 양적 개선을 보이며, 외부 조명에 대한 적응력을 높이는 것이 렌즈 없는 이미징의 실용성과 채택 가능성을 증대시킵니다.



### The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning (https://arxiv.org/abs/2409.16733)
Comments:
          12 pages, 5 figures, 2 tables; accepted on MICCAI Workshop on Advancing Data Solutions in Medical Imaging AI

- **What's New**: 이 연구는 3D 의료 이미지에서 손실 압축이 분할 품질에 부정적인 영향을 미치지 않음을 보여줍니다. Gu사에서는 깊은 신경망(DNN) 기반 모델이 압축된 데이터로 훈련될 때 감손 없이 비압축 데이터에서도 예측할 수 있음을 입증했습니다.

- **Technical Details**: 연구는 CT 및 MRI의 3D 의료 이미지를 대상으로 손실 압축이 DNN 기반 분할 모델에 미치는 영향을 분석합니다. JPEG 2000 압축 방식을 사용하여 훈련 데이터를 최대 20배 압축하고도 분할 품질 유지가 가능함을 보여줍니다. nnU-Net을 프레임워크로 사용하여 20개의 분할 작업을 수행했습니다.

- **Performance Highlights**: 연구 결과, 손실 압축 비율이 20배인 경우에도 DNN 모델은 여전히 높은 품질의 분할 능력을 유지하며, 압축된 이미지를 기반으로 한 훈련 후에도 비압축 이미지에 대해 예측 품질이 보장된다고 확인되었습니다.



### Non-stationary BERT: Exploring Augmented IMU Data For Robust Human Activity Recognition (https://arxiv.org/abs/2409.16730)
- **What's New**: 이 연구에서는 OPPOHAR라는 새로운 인간 활동 인식(HAR) 데이터셋을 소개합니다. 이는 모바일 장치에서 수집된 IMU 데이터로 구성되어 있으며 사용자의 특정 활동 인식을 위해 최적화된 경량 네트워크인 Non-stationary BERT를 제안합니다. 또한 가속도계와 자이로스코프 데이터 간의 깊은 관계를 탐구하기 위한 간단하면서도 효과적인 데이터 증강(data augmentation) 방법을 도입합니다.

- **Technical Details**: 논문에서는 IMU 데이터의 자기 감시(self-supervised) 사전 훈련(pretraining)과 감독(classification) 단계를 포함한 Non-stationary BERT 네트워크 설계를 제안합니다. 이 네트워크는 가속도계와 자이로스코프 데이터의 상호 관계를 고려하여 새로운 시퀀스를 생성하고, 이를 기반으로 한 데이터 증강 방법을 도입하여 HAR 성능을 향상시킵니다. 또한, 사용자 개인의 데이터를 사용한 분산 배포 최적화된 경량 네트워크를 구현합니다.

- **Performance Highlights**: 제안된 Non-stationary BERT 네트워크는 다양한 활동 인식 데이터셋에서 최신 성능(state-of-the-art performance)을 달성하였으며, 데이터 증강 방법은 광범위한 적응 가능성을 보여줍니다. 이 연구는 사용자 개인의 데이터로 훈련된 분류기를 통해 프라이버시를 보장하면서도 사용자 맞춤형 활동 인식을 가능하게 합니다.



### SDCL: Students Discrepancy-Informed Correction Learning for Semi-supervised Medical Image Segmentation (https://arxiv.org/abs/2409.16728)
Comments:
          Accepted at MICCAI 2024

- **What's New**: 이번 연구에서는 Semi-supervised medical image segmentation (SSMIS) 방법의 한계인 확인 및 인지 편향을 해결하기 위해 Students Discrepancy-Informed Correction Learning (SDCL) 프레임워크를 제안합니다. 이 프레임워크는 두 명의 학생 모델과 하나의 비훈련 교사 모델을 사용하며, 두 학생 간의 세분화 차이를 통해 자기 수정 학습을 유도합니다.

- **Technical Details**: SDCL 프레임워크는 Mean Teacher 접근법을 개선하여 설계되었습니다. 두 개의 학습 가능한 학생과 하나의 EMA (Exponential Moving Average) 교사를 통해 세분화의 차이가 존재하는 영역을 잠재적인 편향 영역으로 식별합니다. 또한, 두 개의 수정 손실 함수가 사용되어 올바른 세분화 부피 간의 거리를 최소화하고 잘못된 세분화 부피의 엔트로피를 최대화합니다.

- **Performance Highlights**: 세 가지 공공 의료 이미지 데이터셋(Pancreas, LA, ACDC)에서 실험한 결과, SDCL은 현재 State-of-the-Art (SOTA) SSMIS 방법을 각각 2.57%, 3.04%, 2.34% 초과하는 Dice 점수를 기록했습니다. 또한 ACDC 데이터셋에서는 완전 감독 방법과의 정확도가 매우 유사하며, Pancreas 및 LA 데이터셋에서는 이를 초과하는 성능을 보였습니다.



### 3DDX: Bone Surface Reconstruction from a Single Standard-Geometry Radiograph via Dual-Face Depth Estimation (https://arxiv.org/abs/2409.16702)
Comments:
          MICCAI 2024. 12 pages, 4 figures

- **What's New**: 이번 연구에서는 단일 X선 이미지를 이용한 3D 뼈 표면 복원 작업을 새롭게 제안하였습니다. 기존의 다른 접근법들과는 다르게, X선의 고유한 특성을 활용하여 여러 깊이 맵을 동시에 학습하는 방법을 채택하였습니다.

- **Technical Details**: 제안된 방법(3DDX)은 X선 이미지로부터 프론트 및 백 서페이스의 깊이 맵을 동시에 추정합니다. 이 과정에서 새로운 손실 함수가 도입되어 특정 기하학적 제약 하에 스케일-특화 훈련이 가능해집니다. 또한, 600명의 CT와 2651개의 X선 이미지를 활용하여 방법의 효과성을 검증하였습니다.

- **Performance Highlights**: 기존 방법과 비교했을 때, 표면 재구축 오차가 4.78mm에서 1.96mm로 감소하는 등 상당한 정확도 향상을 보였으며, 임상 적용 가능성을 시사합니다.



### TSBP: Improving Object Detection in Histology Images via Test-time Self-guided Bounding-box Propagation (https://arxiv.org/abs/2409.16678)
Comments:
          MICCAI 2024

- **What's New**: 본 논문에서는 Test-time Self-guided Bounding-box Propagation (TSBP) 방법을 제안하여, 물체 검출 성능을 크게 향상시키는 새로운 접근 방식을 소개합니다. 이 방법은 고신뢰도 바운딩 박스의 정보를 활용하여 저신뢰도 바운딩 박스를 조정합니다.

- **Technical Details**: TSBP는 Earth Mover's Distance (EMD)를 활용하여 시각적 유사성을 바탕으로 바운딩 박스 간의 정보를 전파합니다. 이 과정은 신뢰도가 낮은 바운딩 박스의 클래스 레이블을 보정하며, 별도의 라벨링된 샘플이 요구되지 않아 기존의 불확실성 보정 방법과 차별화됩니다.

- **Performance Highlights**: 실험 결과, TSBP는 기존의 불확실성 보정 방법에 비해 더욱 견고하고 정확한 물체 검출 결과를 제공합니다. 특히 상태-of-the-art 딥러닝 기반 검출 네트워크와 함께 사용했을 때 성능이 크게 향상되었습니다.



### Mitigating Covariate Shift in Imitation Learning for Autonomous Vehicles Using Latent Space Generative World Models (https://arxiv.org/abs/2409.16663)
Comments:
          7 pages, 6 figures, for ICRA 2025 conference, for associated video file, see this https URL

- **What's New**: 본 논문에서는 자율주행에서 발생하는 covariate shift 문제를 해결하기 위해 잠재 공간 생성 세계 모델(latent space generative world models)의 사용을 제안합니다. 저자들은 드라이빙 정책이 인간의 행동을 따른 학습을 활용하여 오류에서 회복할 수 있도록 설계하였으며, 실제 환경에서도 훈련 데이터의 분포를 초과한 perturbations에 대응할 수 있음을 보여줍니다.

- **Technical Details**: 제안된 시스템은 잠재 공간 생성 세계 모델을 통해 드라이빙 정책을 공동 학습하는 구조를 가지고 있으며, 새로운 ego 상태를 샘플링하여 훈련 데이터에서 발견되지 않았던 상태를 탐색합니다. 이를 통해 driving policy가 인간의 시연에서 관찰된 상태에 대해 더 가깝게 행동을 선택할 수 있도록 합니다. 또한, 다중 뷰 크로스 어텐션(multi-view cross-attention)을 사용하는 새로운 Transformer 기반의 인식 인코더(perception encoder)를 도입하였습니다.

- **Performance Highlights**: 실험 결과, 저자들은 CARLA 시뮬레이터와 NVIDIA DRIVE Sim에서 닫힌 루프(closed-loop) 테스트를 통해 이전 최첨단 기술보다 유의미한 개선을 달성하였으며, 다양한 perturbations을 처리할 수 있는 능력을 입증하였습니다.



### Deep-Learning Recognition of Scanning Transmission Electron Microscopy: Quantifying and Mitigating the Influence of Gaussian Noises (https://arxiv.org/abs/2409.16637)
- **What's New**: STEM(Scanning Transmission Electron Microscopy) 이미지를 통해 나노 입자를 인식하기 위한 Deep Learning Mask R-CNN 모델을 제안하며, 생성된 큰 데이터셋의 컴퓨터 기반 자동화를 위한 접근법을 개발했습니다.

- **Technical Details**: Mask R-CNN 모델은 다양한 Gaussian 잡음, 입자 모양 및 크기를 고려하여 나노 입자를 이미지에서 인식합니다. Gaussian noise가 인식 정확도에 미치는 영향을 분석하고, Gaussian 및 Non-Local Means 필터를 적용하여 노이즈의 영향을 줄였습니다.

- **Performance Highlights**: STEM-HAADF 이미지에 대해 Mask R-CNN 모델은 전통적인 threshold 방법보다 더 높은 인식 정확도를 달성하였습니다. 실험 및 시뮬레이션 결과 모두 만족스러운 인식 정확도를 보였으며, 복잡한 구조의 대량 데이터를 분석하는 데 유용합니다.



### Stochastic Subsampling With Average Pooling (https://arxiv.org/abs/2409.16630)
Comments:
          17 pages, 8 figures

- **What's New**: 본 논문에서는 기존의 Dropout 방식이 갖는 일관성 결여 문제를 해결한 새로운 모듈인 stochastic average pooling을 제안합니다. 이 모듈은 pooling 과정에서 Dropout과 유사한 확률성을 통합하여 신경망의 성능을 개선할 수 있습니다.

- **Technical Details**: Stochastic average pooling은 stochastic subsampling과 average pooling을 통합한 방식입니다. 이는 기존 average pooling을 대체할 수 있으며, 코드 변경이 최소화됩니다. 이 방법은 수학적 기호와 함께 명확하게 정의되어 있습니다.

- **Performance Highlights**: 실험 결과, stochastic average pooling로 기존 평균 풀링을 대체하면 다양한 데이터셋, 작업 및 모델에서 성능이 일관되게 개선되는 것으로 나타났습니다.



### FLaRe: Achieving Masterful and Adaptive Robot Policies with Large-Scale Reinforcement Learning Fine-Tuning (https://arxiv.org/abs/2409.16578)
- **What's New**: 최근 로봇 공학 분야에서는 대규모 다중 작업 Behavior Cloning을 통해 일반화된 로봇 정책을 구축하기 위한 여러 노력이 진행되고 있습니다. 본 논문에서는 FLaRe라는 대규모 Reinforcement Learning 미세 조정 프레임워크를 제안하여, 사전 훈련된 표현을 통합하고, 대규모 훈련 및 그래디언트 안정화 기술을 사용하여 성능 향상을 목표로 합니다.

- **Technical Details**: FLaRe는 다중 작업 로봇 정책에서 시작하여 대규모 RL을 통한 미세 조정을 수행합니다. 이 과정에서 안정적인 RL 미세 조정을 보장하기 위해 간단하면서도 효과적인 기술을 도입하며, 이를 통해 성능을 대폭 향상시킵니다. FLaRe는 15배의 훈련 시간 단축을 제공하고, 전통적인 손으로 설계된 보상 함수 없이도 작동할 수 있습니다.

- **Performance Highlights**: FLaRe는 가정용 모바일 조작 작업에서 평균 79.5%의 성공률을 달성하며, 이전 SoTA 방법에 비해 +23.6%의 절대 향상을 기록했습니다. 실제 로봇에서의 성능도 평균 80.7%를 달성하며, 이전 최고 기록에 비해 +30.7% 개선된 결과를 보였습니다. FLaRe는 미세 조정에 필요한 인력이 적고, 새로운 구조와 행동에 빠르게 적응할 수 있는 장점을 가지고 있습니다.



### Diffusion Models to Enhance the Resolution of Microscopy Images: A Tutoria (https://arxiv.org/abs/2409.16488)
Comments:
          45 pages, 8 figures

- **What's New**: 본 튜토리얼에서는 Denoising Diffusion Probabilistic Models (DDPMs)을 사용하여 저해상도 현미경 이미지를 그에 상응하는 고해상도 이미지로 변환하는 방법에 대한 포괄적인 가이드를 제공합니다.

- **Technical Details**: 이 논문에서는 Diffusion Models을 기반으로한 이미지-이미지 변환 기술을 구현하는 방법을 설명하며, PyTorch를 사용한 구체적인 코드 구현과 함께 필요한 수학적 이론과 배경 지식을 포함합니다. 또한 microtubule 구조 이미지와 같은 실제 데이터를 활용하여 모델 성능을 향상시키는 기법에 대해서도 다룹니다.

- **Performance Highlights**: Diffusion 모델은 텍스트-이미지 변환 및 이미지 변환 작업에서 성공적으로 사용되고 있으며, 생물학적 구조를 복원하는 데 있어 뛰어난 해상도를 제공합니다. 특히, 저해상도 이미지를 체계적으로 처리하며, 딥러닝을 통한 단일 이미지 초해상도(SISR) 분야에서 긍정적인 결과를 나타내고 있습니다.



### Initialization of Monocular Visual Navigation for Autonomous Agents Using Modified Structure from Small Motion (https://arxiv.org/abs/2409.16465)
Comments:
          6 pages, 1 page for references, 6 figures, 1 table, IEEEtran format This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 우리는 우주에서 자율 로봇을 위한 독립적인 단안 시각 동시 위치 추정 및 지도 작성(vSLAM) 초기화 파이프라인을 제안합니다. 이 방법은 고전적인 Structure from Small Motion (SfSM)을 강화하여 약한 원근 투영(scene) 환경에서 단안(vSLAM) 에이전트를 강력하게 초기화합니다.

- **Technical Details**: 이 연구는 불확실한 기하학을 해결하기 위해 약한 원근 투영 및 중심 지향 동작(center-pointing motion)에 대한 SfSM 접근 방식을 개선합니다. 새로운 세 단계 초기화 파이프라인은 회전 추정, 평면 기하학을 통한 번들 조정(bundle adjustment) 및 전반적인 추정 과정을 포함하며, 고화질 위성 검사 이미지를 이용해 검증하였습니다. 또한, 반전 깊이에 대한 재매개변수를 도입하여 수치적 안정성을 보장하고, 3D 랜드마크의 재매개변수를 통해 이미지 기능 좌표 벡터의 양자화를 고려했습니다.

- **Performance Highlights**: 이 방법은 약한 원근 투영이 있는 현실적인 위성 검사 이미지를 사용하여 다른 단안 초기화 절차와 비교했을 때 더 향상된 성능과 효과성을 보여주었습니다. 시뮬레이션 데이터 세트를 기반으로 초기화 과정의 정확성과 신뢰성을 높여, 특히 우주에서의 비협조적 거주 우주 물체(RSO)의 검사 및 근접 작전 중에 안전한 비행 경로를 확보하는 데 기여할 수 있습니다.



### A novel open-source ultrasound dataset with deep learning benchmarks for spinal cord injury localization and anatomical segmentation (https://arxiv.org/abs/2409.16441)
- **What's New**: 이번 연구에서는 10,223개의 Brightness-mode (B-mode) 초음파 이미지를 포함하는 대규모 데이터셋을 공개했습니다. 이 데이터셋은 대칭 단면을 가진 25마리의 육계 소에서 얻은 것으로, 부상 전후의 척수 이미지를 포함합니다. 또한, 여러 최첨단 객체 탐지 알고리즘의 성능을 비교 분석하여 부상 부위의 위치를 파악하고 해부학적 구조에 레이블을 붙이는 방법을 제시하였습니다.

- **Technical Details**: 이 연구에서 사용된 YOLOv8 객체 탐지 모델은 부상 위치 탐지에서 평균 정확도(mAP50-95) 0.606을 달성하여 최상의 성능을 기록했습니다. DeepLabv3 세분화 모델은 보이지 않는 육계 생리학에 대해 평균 Dice 점수 0.587을 기록했고, SAMed는 인간 해부학에 대한 제로샷 일반화에서 0.445의 평균 Dice 점수를 달성하였습니다. 데이터셋은 건강한 및 손상된 척수의 해부학적 구조를 포함합니다.

- **Performance Highlights**: 본 연구는 SCI(척수 손상)에 대한 자동화된 지속 진단의 최초 선구적 노력을 담고 있으며, 연구자와 의료전문가들이 사용할 수 있는 가장 큰 주석 데이터셋을 제공함으로써 임상 결과를 향상시키기 위한 맞춤형 치료의 새로운 방법을 모색하고 있습니다.



### Lessons Learned from a Unifying Empirical Study of Parameter-Efficient Transfer Learning (PETL) in Visual Recognition (https://arxiv.org/abs/2409.16434)
Comments:
          Code is available at this https URL

- **What's New**: 최근 Parameter-efficient transfer learning (PETL) 기술에 대한 관심이 커지고 있으며, 이를 통해 기존의 대규모 pre-trained 모델을 더욱 효율적으로 조정하여 다양한 downstream 작업에서의 성능을 향상시키고자 하는 연구가 진행되고 있습니다. 본 논문은 Vision Transformers의 맥락에서 PETL 방법들을 통합적으로 비교하고, 그들의 성능을 체계적으로 분석하였습니다.

- **Technical Details**: 이 연구에서는 Low-Rank Adaptation (LoRA), Visual Prompt Tuning (VPT), Adapter 등 다양한 PETL 기법을 사용하여 진행하였으며, 하이퍼 파라미터(learning rate, weight decay 등)를 체계적으로 조정하여 low-shot benchmark인 VTAB-1K의 정확도를 비교하였습니다. 또한, CIFAR-100 및 RESISC와 같은 풀사이즈 데이터셋에서도 PETL 방법을 평가하였습니다.

- **Performance Highlights**: PETL 접근 방식들이 잘 조정되었을 경우 VTAB-1K에서 유사한 정확도를 기록하였으며, PETL 방법들은 낮은 샷의 데이터에서도 뛰어난 성능을 보여주었습니다. 무수한 학습 데이터를 가진 시나리오에서도 PETL이 full fine-tuning과 동등하거나 그 이상의 결과를 도출할 수 있다는 점이 주목할 만합니다. 또한 PETL은 distribution shift에 대한 강건성을 가지며, 기존 모델의 일반성을 유지하는 결과를 보였습니다.



### Vision-based Xylem Wetness Classification in Stem Water Potential Determination (https://arxiv.org/abs/2409.16412)
- **What's New**: 본 연구는 Stem Water Potential (SWP) 측정을 자동화하기 위한 새로운 접근 방식을 제안합니다. Scholander Pressure Chamber를 사용하여 줄기 탐지(stem detection)와 수관(xylem) 습도 분류를 자동화하고, YOLOv8n 및 ResNet50을 활용하여 이를 개선하였습니다.

- **Technical Details**: 본 연구에서는 SWP 측정을 위한 자동화된 시스템을 구축하였으며, YOLOv8n과 ResNet50 기반의 정확한 검출 및 분류 방법을 적용했습니다. 추가적으로, 데이터 확대(data augmentation) 및 모델 파라미터 튜닝을 통해 20개의 SWP 측정에 대해 평가를 진행했습니다.

- **Performance Highlights**: 최고 성능의 모델은 줄기 탐지 및 수관 습도 분류에서 80.98%의 Top-1 정확도를 기록하였고, 이는 SWP 측정의 자동화 작업에서 가장 뛰어난 성과로 평가됩니다.



### Modern Hopfield Networks meet Encoded Neural Representations -- Addressing Practical Considerations (https://arxiv.org/abs/2409.16408)
Comments:
          17 pages, 8 figures, workshop submission to Neurips

- **What's New**: 본 논문은 Modern Hopfield Networks (MHN)에 대한 메타 안정 상태 문제를 해결하는 새로운 접근 방식인 Hopfield Encoding Networks (HEN)를 소개합니다. HEN은 입력 패턴의 분리 가능성을 높이고, 메타 안정 상태를 줄이기 위해 인코딩된 신경 표현을 통합합니다.

- **Technical Details**: HEN은 미리 훈련된 신경 인코더-디코더 모델을 사용하여 입력을 잠재 표현 공간으로 인코딩한 후 저장하고, 재호출 시 다시 디코딩하는 방법을 사용합니다. 이 접근 방식은 MHNs의 메타 안정 상태 문제를 해결하고, 자연어 쿼리를 통한 다양한 입력 모달리티에서의 검색을 가능하게 합니다.

- **Performance Highlights**: 실험 결과는 HEN이 메타 안정 상태를 크게 줄이고, 저장 용량을 증가시키면서 다양한 입력을 완벽히 기억할 수 있음을 나타냅니다. 이는 실제 작업을 위한 연상 기억 네트워크의 실용적인 활용을 향상시킵니다.



### Patch-Based Contrastive Learning and Memory Consolidation for Online Unsupervised Continual Learning (https://arxiv.org/abs/2409.16391)
Comments:
          Published in Conference on Lifelong Learning Agents (COLLAS) 2024

- **What's New**: 논문에서는 상대적으로 탐색이 부족한 학습 패러다임인 Online Unsupervised Continual Learning (O-UCL)에 집중하고 있습니다. O-UCL은 비정상적인 레이블 없는 데이터 스트림을 처리하며 점진적으로 클래스의 수를 식별하는 능력을 길러주는 방식입니다. 본 연구는 실시간으로 새로운 클래스를 식별하고, 기존에 학습한 클래스를 잊지 않으면서 데이터를 스트리밍 방식으로 처리하는 동적 접근 방식을 제안합니다.

- **Technical Details**: 제안된 방법인 Patch-based Contrastive learning and Memory Consolidation (PCMC)은 데이터의 패치 수준의 특징을 식별하고 클러스터링하여 데이터를 이해합니다. PCMC는 인코더를 통해 패치 임베딩을 추출하고, 새로운 데이터를 기존 분포에 통합하면서 재학습 시 기억을 통합하는 기능을 갖추고 있습니다. 이 접근 방식은 주기적인 '깨어남'과 '수면' 주기를 통해 개념적으로 변화를 관리합니다.

- **Performance Highlights**: PCMC의 성능은 ImageNet과 Places365 데이터셋에서 생성된 스트림을 기반으로 평가되었습니다. 여러 기존 방법들과 간단한 기준점과의 성능 비교를 통해 PCMC의 유효성을 입증하였습니다.



### Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review (https://arxiv.org/abs/2409.16340)
Comments:
          21 pages, 5 figures, 4 tables, Review paper, preprint to Radiology AI. arXiv admin note: text overlap with arXiv:2406.12815

- **What's New**: 이번 논문은 Federated Learning (FL)을 통해 의료 이미징에서의 AI 모델 훈련을 개선할 수 있는 가능성을 탐구합니다. 특히, 데이터 공유 없이 민감한 정보를 보호하면서 협업할 수 있는 방법론을 다루며, 기존의 FL 접근법의 기본적인 문제점과 한계를 짚어봅니다.

- **Technical Details**: FL은 분산된 환경에서 여러 기관이 AI 모델을 공동으로 훈련할 수 있도록 하는 기술입니다. 이 과정에서 모델의 update 정보(예: gradients)만 공유되며 데이터는 공유되지 않습니다. 그러나 민감한 정보가 여전히 추론될 수 있는 가능성이 남아 있으며, 이는 privacy-preserving Federated Learning (PPFL)와 Uncertainty Quantification (UQ) 연구와 깊은 연관이 있습니다. 논문에서는 다양한 FL 알고리즘(예: FedAvg, FedProx 등)의 발전을 소개하고, 비독립적이고 동질적이지 않은 데이터 세트(data heterogeneity)의 문제를 해결하기 위한 접근 방식도 설명합니다.

- **Performance Highlights**: 이 논문은 FL이 의료 이미징에서 모델의 신뢰성을 높이는 방법으로 여겨지며, 정확하고 일반화 가능한 AI 모델 개발에 기여할 수 있는 잠재력을 가지고 있다고 강조합니다. 특히, 각기 다른 클라이언트 환경에서의 데이터 이질성을 고려하는 Personalized Federated Learning (PFL) 기법의 중요성을 제시하며, FL의 적용 사례를 통해 효과를 분석합니다.



### Predicting Distance matrix with large language models (https://arxiv.org/abs/2409.16333)
- **What's New**: RNA 구조 예측에 대한 새로운 접근 방법을 제안합니다. 대규모 사전 훈련된 RNA 언어 모델과 잘 훈련된 변환기(transformer)를 사용하여 RNA 염기 사이의 거리를 정확하게 추론할 수 있습니다.

- **Technical Details**: 거리 매트릭스(distance matrix)를 직접 예측하는 방법을 제시하며, 이 과정에서 기존의 3D 구조 모델링에서 발생하는 데이터 부족 문제를 해결하기 위한 혁신적인 접근 방식을 채택합니다. 우리는 변환기의 주의(attention) 메커니즘이 RNA 염기 쌍의 거리를 예측하는 데 적합하다고 주장합니다.

- **Performance Highlights**: 제안된 Distance Transformer(DiT)는 사전 훈련된 RNA 언어 모델을 통해 RNA 거리 매트릭스를 예측하고, 이를 통해 RNA 구조 및 기능에 대한 이해를 높일 수 있는 가능성을 보여줍니다.



### MRI Radiomics for IDH Genotype Prediction in Glioblastoma Diagnosis (https://arxiv.org/abs/2409.16329)
Comments:
          8 pages, 1 figure

- **What's New**: 이번 논문은 MRI 이미지를 활용한 Radiomics의 최신 동향을 다루고 있으며, 특히 Isocitrate dehydrogenase (IDH) 돌연변이 상태를 식별하는데 중점을 둡니다. IDH 돌연변이는 고등급 교모세포종과 등급 IV 별아교종의 중요 생체표지자로, 비침습적인 진단 방법의 필요성을 강조합니다.

- **Technical Details**: 논문에서 다루는 MRI Radiomics 워크플로우는 MRI 이미지에서 특징 추출을 위한 주요 단계를 설명합니다. 이미지 세분화는 수동, 반자동 또는 자동 방법으로 수행될 수 있으며, 자동 세분화는 딥러닝 모델을 사용하여 더 빠르고 정확하게 수행됩니다. 이미지 전처리 과정은 필수적으로 포함되며, 스컬 스트리핑과 다양한 필터링 기법이 사용됩니다.

- **Performance Highlights**: 이 연구는 IDH 돌연변이 상태를 정확히 예측하기 위한 MRI 기반 비침습적 방법의 효과를 입증하고 있으며, 이는 각환자에 맞춘 치료 계획 수립에 기여할 것입니다. 또한, 딥러닝 기반의 자동 세분화 기법은 임상 적용 가능성을 높이고 있습니다.



### Developing a Thailand solar irradiance map using Himawari-8 satellite imageries and deep learning models (https://arxiv.org/abs/2409.16320)
Comments:
          23 pages, 14 figures

- **What's New**: 이 논문은 태국의 태양 복사 지도(Global Horizontal Irradiance, GHI)를 30분마다 온라인으로 보여주는 플랫폼을 소개합니다. 이 플랫폼은 Himawari-8 위성 이미지를 기반으로 한 구름 지수(cloud index)와, Linke turbidity로 조정된 Ineichen 맑은 하늘 모델을 사용하여 GHI를 추정합니다.

- **Technical Details**: GHI 추정 모델에서 입력으로는 맑은 하늘 복사량, 구름 지수, MERRA-2 데이터베이스의 재분석 GHI 및 온도 데이터를 포함합니다. 사용된 머신 러닝 모델로는 LightGBM, LSTM, Informer, Transformer가 있으며, 2022-2023년 기간 동안 53개 지상 스테이션에서 15분 단위의 GHI 데이터를 평가하여 성능을 비교했습니다.

- **Performance Highlights**: 모든 모델은 경쟁력 있는 성능을 보였으며, SolCast 서비스보다 우수한 결과를 나타냈습니다. LightGBM 모델의 MAE(Mean Absolute Error)는 78.58 W/sqm, RMSE(Root Mean Square Error)는 118.97 W/sqm로 최상위 성능을 기록했습니다. Informer 모델은 추가적으로 재분석 MERRA-2 데이터 없이 MAE 78.67 W/sqm로 우수한 성능을 보였습니다.



### Damage detection in an uncertain nonlinear beam based on stochastic Volterra series: an experimental application (https://arxiv.org/abs/2409.16305)
- **What's New**: 이 논문은 구조물의 비선형 행동과 데이터의 자연 변동을 고려하여, 손상 탐지 문제 해결을 위한 확률적(Probabilistic) Volterra 시리즈의 실험적 적용을 다룹니다. 비선형 시스템에서 손상을 탐지하기 위해 기존의 결정론적(Deterministic) 방법과 확률적 방법의 비교를 수행합니다.

- **Technical Details**: 이 연구에서는 비선형 운동을 하는 고정 단작업 빔(Cantilever beam)을 실험적으로 사용하였으며, 실험적 데이터의 변동성을 보완하기 위해 확률적 Volterra 커널(Volterra kernel)의 기여도를 이용한 접근법이 적용되었습니다. 처치(causation)된 손상은 볼트 연결(bolted connection)에서의 질량 변화(mass changes)에 따른 것이며, 비선형 기여도와 선형 기여도를 비교하여 분석합니다.

- **Performance Highlights**: 확률적 모델이 데이터 변동성을 고려할 때 손상의 존재를 통계적 신뢰도로 탐지할 수 있는 능력을 보여주며, 비선형 메트릭이 선형 메트릭보다 손상 감지에 더 높은 민감도를 가지는 장점이 입증되었습니다. 이는 비선형 행동을 가진 시스템에서 비선형 메트릭을 사용하는 것이 중요하다는 것을 강조합니다.



### Computer Aided Detection and Classification of mammograms using Convolutional Neural Network (https://arxiv.org/abs/2409.16290)
- **What's New**: 이번 연구에서는 유방(X-ray) 영상에서 유방 종양을 정상과 비정상으로 분류하기 위한 새로운 기법으로 Convolutional Neural Network (CNN)을 활용하였습니다.

- **Technical Details**: 연구에 사용된 DDSM (Digital Database for Screening Mammography) 데이터셋에는 정상 유방 이미지를 약 460장, 비정상 유방 이미지를 920장 포함하고 있습니다. CNN을 사용하여 초기 종양의 자동 탐지 방법을 소개합니다.

- **Performance Highlights**: 기계 학습과 심층 학습(Deep Learning) 기술 적용을 통해 초기 유방암 증상인 덩어리(masses)와 미세 석회화(micro-calcifications)의 탐지가 더욱 정확해질 수 있습니다.



### Self-Supervised Any-Point Tracking by Contrastive Random Walks (https://arxiv.org/abs/2409.16288)
Comments:
          ECCV 2024. Project link: this https URL . Code: this https URL

- **What's New**: 이번 연구에서는 Tracking Any Point (TAP) 문제에 대한 간단하고 효과적인 self-supervised (자기지도) 접근 방식이 제안되었습니다. 주목할 점은 global matching transformer를 사용해 cycle consistency (순환 일관성) 학습을 통해 관측한 데이터를 통해 모델을 훈련시키는 것입니다.

- **Technical Details**: 제안된 방법은 contrastive random walk (대조적 무작위 보행)를 이용하여 개체의 이동 궤적을 추적하는 것을 목표로 합니다. 이를 위해 space-time graph (공간-시간 그래프)의 transition matrix (전이 행렬)을 정의하여 모든 쌍의 비교를 수행할 수 있는 기법을 채택하였습니다. 이 방법은 데이터 증강 기법을 통해 모델이 shortcut solutions (지름길 해법)에 영향을 받지 않도록 설계되었습니다.

- **Performance Highlights**: TAP-Vid 벤치마크에서 강력한 성능을 입증하였으며, DIFT와 같은 이전의 self-supervised 추적 방법을 초월하였습니다. 실험 결과, TAP-Net과 유사한 경쟁력 있는 성능을 가지며 여러 supervised (지도학습) 방법과 겨룰 수 있는 수준에 도달했습니다.



### MonoFormer: One Transformer for Both Diffusion and Autoregression (https://arxiv.org/abs/2409.16280)
- **What's New**: 이 논문에서는 autoregression 기반의 텍스트 생성과 diffusion 기반의 시각적 생성 방법에 대해 단일 transformer를 공유하여 사용하자는 간단한 아이디어를 제안합니다. MonoFormer라는 이름의 접근 방식은 텍스트와 이미지 생성을 모두 수행할 수 있는 가능성을 보여줍니다.

- **Technical Details**: Transformer는 시각적 생성에 diffusion 모델을 적용하는 데 성공적으로 사용되며, autoregression과 diffusion을 위한 transformer 훈련이 유사하다는 점에서 feasibility가 있습니다. autoregressive transformer는 causal attention mask를 사용하고, diffusion transformer는 bidirectional attention mask를 사용하여 차이를 두고 있습니다. 단일 transformer를 통해 텍스트와 이미지 생성을 모두 학습하는 방법론이 논의됩니다.

- **Performance Highlights**: 실험 결과, MonoFormer는 현재 최첨단 방법에 대한 경쟁력 있는 이미지 생성 성능을 달성했으며, 텍스트 생성 능력 또한 유지합니다.



### Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation (https://arxiv.org/abs/2409.16278)
Comments:
          9 pages, 6 figures

- **What's New**: 최근 열린 어휘(panoptic) 세분화(open-vocabulary panoptic segmentation) 기법의 발전이 이루어졌습니다. 새로운 방법인 Semantic Refocused Tuning (SMART)이 마스크 분류(mask classification)의 성능을 크게 향상시키며, 적은 학습 자원으로도 효과적인 방법론을 제안합니다.

- **Technical Details**: SMART는 Semantic-guided Mask Attention과 Query Projection Tuning이라는 두 가지 핵심 혁신을 통해 세분화를 개선합니다. 이를 통해 VLM(비전-언어 모델의 이미지 포커스 조정)에서 마스크 토큰의 새 분포에 적응할 수 있는 효율성을 제공합니다.

- **Performance Highlights**: SMART는 동종의 대표적인 벤치마크에서 최대 1.3 PQ 및 5.4 mIoU의 성능 향상을 보이며, 이전의 최상위 모델과 비교하여 학습 비용을 약 10배 감소시켰습니다.



### AIM 2024 Challenge on UHD Blind Photo Quality Assessmen (https://arxiv.org/abs/2409.16271)
Comments:
          ECCV 2024 - Advances in Image Manipulation (AIM). arXiv admin note: text overlap with arXiv:2401.10511 by other authors

- **What's New**: AIM 2024 UHD-IQA Challenge가 소개되었습니다. 이 대회는 최신 고해상도 사진에 대한 No-Reference Image Quality Assessment (NR-IQA)의 발전을 목표로 하고 있습니다. UHD-IQA Benchmark Database를 기반으로 하며, 뛰어난 기술적 품질을 지닌 6073개의 UHD-1 (4K) 이미지가 포함되어 있습니다.

- **Technical Details**: UHD-IQA는 현대 카메라로 촬영된 섬세한 열화가 있는 고해상도 이미지를 평가하기 위한 도전과제로 설정되었습니다. 대회 참가자들은 50G MACs의 계산 예산 내에서 높은 예측 성능을 목표로 새로운 아키텍처와 훈련 전략을 개발해야 합니다. 주요 평가 지표로는 Pearson Linear Correlation Coefficient (PLCC), Spearman Rank-order Correlation Coefficient (SRCC), Kendall Rank Correlation Coefficient (KRCC) 및 절대 오차 지표인 Mean Absolute Error (MAE)와 Root Mean Square Error (RMSE)가 사용됩니다.

- **Performance Highlights**: 주요 참가팀 중 SJTU는 전체 대회 우승을 차지하였고, SZU SongBai가 1위, CIPLAB이 2위로 뒤를 이었습니다. 성능 평가에서는 전반적으로 성능 지표의 감소가 나타났으며, 특히 CIPLAB은 특수 테스트 세트에서 2위를 기록했습니다.



### CDChat: A Large Multimodal Model for Remote Sensing Change Description (https://arxiv.org/abs/2409.16261)
- **What's New**: 이 논문에서는 리모트 센싱(REMOTE SENSING) 이미지의 변화를 설명할 수 있는 새로운 대화형 변환 모델인 CDChat을 제안합니다. CDChat은 기존의 GeoChat보다 향상된 성능을 보이며, bi-temporal RS 이미지 간의 변화 설명을 위한 새로운 데이터셋을 활용합니다.

- **Technical Details**: CDChat은 LLaVA-1.5와 같은 대형 언어 모델(LLM)을 기반으로 하며, 비디오 변환기(CLIP ViT-L-14)를 통해 bi-temporal 이미지를 처리합니다. 이 모델은 시암식 비전 인코더(Siamese vision encoder)를 활용하여 변경된 이미지의 특징을 별도로 추출하고 이를 결합하여 언어 공간에 투사합니다.

- **Performance Highlights**: CDChat은 기존의 LMM보다 개선된 성능을 보여주며, 특히 bi-temporal RS 이미지 간의 semantic 변화 탐지에 강점을 가지고 있습니다. 고해상도 이미지를 지원하여 작은 변화 지역에 대한 주의를 기울일 수 있는 능력을 강화했습니다.



### Fields of The World: A Machine Learning Benchmark Dataset For Global Agricultural Field Boundary Segmentation (https://arxiv.org/abs/2409.16252)
- **What's New**: 농업 모니터링 및 평가에서 중요한 역할을 하는 농작물 경계 데이터를 수집하는 비용을 절감하기 위해, 본 논문에서는 다양한 국가의 데이터를 포함한 새로운 기계 학습(Machine Learning, ML) 벤치마크 데이터셋인 'Fields of The World (FTW)'를 제안합니다.

- **Technical Details**: FTW 데이터셋은 24개국에서 수집된 70,462개의 샘플을 포함하며, 각 샘플은 다중 날짜, 다중 스펙트럴 Sentinel-2 위성 이미지와 함께 인스턴스 및 의미적 세분화 마스크가 쌍으로 제공됩니다. 이 데이터셋은 전 세계 농업 경관의 다양성을 반영하고 있으며 ML 모델의 성능을 향상시키기 위한 여러 기준 작업을 포함합니다.

- **Performance Highlights**: FTW 데이터셋으로 훈련된 모델은 다양한 국가에서 전이 학습 및 제로샷(Zero-shot) 성능이 우수하며, 실제 시나리오인 에티오피아의 Sentinel-2 장면에서 긍정적인 질적 성능을 보였습니다.



### Label-Augmented Dataset Distillation (https://arxiv.org/abs/2409.16239)
- **What's New**: 본 연구에서는 Label-Augmented Dataset Distillation (LADD)이라는 새로운 데이터셋 증류 프레임워크를 도입하였습니다. LADD는 라벨을 증강하여 데이터셋 증류를 개선하며, 이는 더 풍부한 의미를 포착하기 위해 각 합성 이미지에서 추가적인 밀집 라벨을 생성합니다.

- **Technical Details**: LADD는 두 가지 주요 단계로 이루어져 있습니다: 증류(distillation) 단계와 배포(deployment) 단계입니다. 증류 단계에서는 기존 증류 알고리즘을 사용하여 합성 이미지를 생성한 후 이미지 서브샘플링 알고리즘을 적용하여 각 합성 이미지에 대한 밀집 라벨을 생성합니다. 배포 단계에서는 글로벌 뷰 이미지와 원래 라벨, 그리고 로컬 뷰 이미지와 해당 밀집 라벨을 결합하여 다양한 학습 신호를 제공합니다.

- **Performance Highlights**: LADD는 기존 방법들보다 평균 14.9%의 정확도 향상을 달성했으며, 87% 적은 메모리를 사용하면서 5 IPC에서 6 IPC 기준을 지속적으로 초과했습니다. LADD는 또한 다양한 데이터셋과 모델 아키텍처에서 검증되었습니다.



### VideoPatchCore: An Effective Method to Memorize Normality for Video Anomaly Detection (https://arxiv.org/abs/2409.16225)
Comments:
          Accepted to ACCV 2024

- **What's New**: 영상 이상 탐지(Video Anomaly Detection, VAD) 분야에서 새로운 메모리 기반 접근법인 VideoPatchCore(VPC)를 제안합니다. VPC는 정상 프레임의 특징을 메모리에서 저장하고 재구성하여 비정상 프레임을 식별하는 기존 방법의 한계를 극복합니다.

- **Technical Details**: VPC는 두 개의 스트림(로컬 및 글로벌)과 세 가지 메모리 은행(공간적, 시간적, 고수준 의미론적)을 활용하여 영상 데이터의 시공간적 특성을 포착합니다. 이 방법은 PatchCore에서 영감을 얻었으며, CLIP의 비전 인코더를 활용하여 메모리를 최적화합니다. 메모리 최적화는 greedy coreset subsampling 방식을 통해 수행됩니다.

- **Performance Highlights**: VPC는 기존의 최첨단 방법과 비교해 훌륭한 성능을 보여주며, 다양한 형태의 이상 탐지가 가능합니다. 이 접근 방법은 추가 훈련 없이 구현이 용이하여 VAD 작업의 접근성을 높이고 있습니다.



### Deep Learning for Precision Agriculture: Post-Spraying Evaluation and Deposition Estimation (https://arxiv.org/abs/2409.16213)
- **What's New**: 본 논문은 정밀 농업에서의 정밀 스프레이 시스템을 평가하기 위한 자동화된 eXplainable Artificial Intelligence (XAI) 컴퓨터 비전 파이프라인을 제안합니다. 이 시스템은 전통적인 농업 방법 없이 포스트 스프레이 후 이미지를 평가할 수 있도록 설계되었습니다.

- **Technical Details**: 연구에서는 샘플로 사용하는 작물 및 잡초에 대해 의미론적 분할(semantic segmentation)을 수행하고, 각 작물이 스프레이되었는지를 식별할 수 있습니다. 이를 위해 Weakly Supervised Deposition Estimation (WSDE) 작업이 추가되어 클래스별 spray deposit 무게를 정확하게 정량화합니다. 데이터셋은 공개되어 있으며, 클래스 활성화 지도(Class Activation Mapping, CAM)를 사용하여 모델의 예측과 결합하여 스프레이 침착값을 도출합니다. 또한, Fully Convolutional Network와 EfficientNet-B0 백본 구조를 통해 성능을 최적화하고 의미론적 분할의 해석 가능성 또한 향상되었습니다.

- **Performance Highlights**: 시험 집합에서 세 클래스간에 스프레이 침착 값의 평균 절대 차이는 156.8 {\,}μL로 평가되었습니다. 이 연구에서는 AblationCAM과 ScoreCAM의 두 가지 다른 CAM 기법을 비교하여 각 기법의 효용과 해석 가능성을 평가했습니다.



### MaskBit: Embedding-free Image Generation via Bit Tokens (https://arxiv.org/abs/2409.16211)
Comments:
          Project page: this https URL

- **What's New**: 이 논문에서는 Masked transformer 모델을 활용한 이미지 생성 접근 방식의 발전을 다룬다. 주목할 만한 기여로는 기존 VQGAN 모델의 현대화와 비트 토큰(bit tokens)을 사용하는 새로운 생성 네트워크 MaskBit의 제안이 있다.

- **Technical Details**: VQGAN+라는 현대화된 VQGAN 모델은 성능을 매우 향상시켰으며, FID(Fréchet Inception Distance) 점수가 7.94에서 1.66으로 개선되었다. MaskBit은 비트 토큰을 직접 사용하여 이미지를 생성하는 새로운 방식을 도입하여, 305M 파라미터를 갖고도 ImageNet 256x256 벤치마크에서 FID 1.52를 달성하였다.

- **Performance Highlights**: 이 연구는 VQGAN+의 성능을 향상시킴으로써 기존의 최첨단 모델과 경쟁할 수 있는 성과를 달성했으며, MaskBit은 더욱 소형의 생성器 모델을 통해 가장 최신의 성과를 즉음으로 달성하였다.



### LLMCount: Enhancing Stationary mmWave Detection with Multimodal-LLM (https://arxiv.org/abs/2409.16209)
- **What's New**: LMMCount는 대형 언어 모델 (Large Language Models, LLM)을 활용하여 밀리미터파 감지기의 성능을 개선하는 최초의 시스템입니다. 이 시스템은 주변 군중을 비침습적이고 개인정보 보호 방식으로 감지할 수 있도록 개발되었습니다.

- **Technical Details**: LLMCount 시스템은 세 개의 모듈로 구성되어 있으며, 한 모듈은 로컬 처리 장치에서 실행되고 두 개의 모듈은 클라우드 기반 LLM으로 처리 에이전트로 배치됩니다. 기본적으로 IWR-1443 레이더 칩을 사용하여 mmWave 데이터를 수집하며, 이 데이터를 클라우드로 업로드하여 실시간으로 감지 결과를 제공합니다.

- **Performance Highlights**: LLMCount는 다양한 시나리오에서 높은 감지 정확성을 달성하였으며, 이전 방법들에 비해 낮은 전체 지연시간을 기록했습니다. 이는 다양한 환경에서의 적응성을 크게 향상시켰습니다.



### Segmentation Strategies in Deep Learning for Prostate Cancer Diagnosis: A Comparative Study of Mamba, SAM, and YOLO (https://arxiv.org/abs/2409.16205)
- **What's New**: 이 연구에서는 전립선 암의 조직병리학 이미지 세분화를 위한 3가지 딥러닝 기반 방법인 Mamba, SAM, YOLO의 비교 분석을 제시합니다.

- **Technical Details**: 연구에서는 Dice score, precision, recall 등의 메트릭을 사용하여 Gleason 2019와 SICAPv2 두 개의 포괄적인 데이터셋에서 이들 모델의 성능을 평가했습니다. H-vmunet 모델은 높은 차원의 시각 상태 공간과 2D 선택적 스캔 작업을 통합한 구조를 통해 다양한 규모의 병변 감지를 효율적이고 민감하게 수행할 수 있습니다.

- **Performance Highlights**: H-vmunet 모델이 모든 메트릭에서 가장 높은 점수를 달성하며, 전립선 암 진단과 치료 계획에서 중요한 역할을 할 수 있는 잠재력을 보여줍니다.



### Expert-level vision-language foundation model for real-world radiology and comprehensive evaluation (https://arxiv.org/abs/2409.16183)
- **What's New**: 이번 연구에서는 방사선학에 맞춘 대규모 오픈 소스 비전-언어(Vision-Language) 기반 모델인 RadFound를 소개합니다. RadFound는 810만 장 이상의 이미지와 25만 개의 이미지-텍스트 쌍으로 구성된 데이터셋을 사용하여 훈련되었습니다.

- **Technical Details**: RadFound는 방사선학에 특화된 고급 비전 인코더를 도입하여 이미지 내부의 로컬 특징과 이미지 간의 맥락 정보를 포착합니다. 또한, 방사선학에 맞춘 통합된 크로스 모달(Cross-modal) 학습 설계를 채택하고 있습니다. 이를 통해 의료 비전-언어 질문-응답, 캡셔닝(captioning), 리포트 생성과 같은 방사선 해석 작업을 포함한 기준을 설정했습니다.

- **Performance Highlights**: RadFound는 2D 이미지(흉부 X선), 다중 뷰 이미지(유방 촬영), 3D 이미지(갑상선 CT 스캔)와 같은 세 가지 대표적인 모달리티가 포함된 현실 세계 기준에서 평가받았으며, 다른 VL 기반 모델들에 비해 정량적 메트릭과 인간 평가 모두에서 현저한 성과를 보였습니다.



### SDFit: 3D Object Pose and Shape by Fitting a Morphable SDF to a Single Imag (https://arxiv.org/abs/2409.16178)
Comments:
          11 pages, 7 figures, 2 tables

- **What's New**: 이 논문에서는 단일 이미지를 통해 3D 객체의 자세(pose)와 형태(shape)를 복원하는 방법에 대한 새로운 접근법인 SDFit을 제시합니다. 이 방법은 기존의 한계점을 극복하려는 시도로, 모양과 자세를 동시에 추정할 수 있는 가능성을 보여줍니다.

- **Technical Details**: SDFit은 (1) 학습된 signed-distance-function (SDF) 모델을 기반으로 하여 강력한 변형 가능한 형태(morphable shape) 사전(prior)으로 작용하고, (2) 2D 이미지와 3D 형태를 공동 공간에 매핑할 수 있는 기초 모델(foundational models)을 활용하며, (3) 이미지로부터 풍부한 특징을 추론합니다. SDFit은 이미지로부터 3D 형태 가설을 생성하고, 해당 형태를 이미지와 비교하여 반복적으로 정교화하는 방식으로 작동합니다.

- **Performance Highlights**: SDFit은 Pix3D 및 Pascal3D+ 데이터셋에서 평가되었으며, 현대의 학습 기반 방법들과 유사한 성능을 보였습니다. 특히, 고유한 점은 SDFit이 미리 학습이 필요하지 않으며, 자연 이미지에 대한 일반화(generalization)에 강한 가능성을 보여주는 점입니다.



### Fine Tuning Text-to-Image Diffusion Models for Correcting Anomalous Images (https://arxiv.org/abs/2409.16174)
- **What's New**: 이 연구는 DreamBooth 기법을 사용하여 Stable Diffusion 3 모델을 미세 조정하는 방법을 제안합니다. 이 방법은 특정 프롬프트에 대해 생성된 비정상적인 이미지를 줄이는 것을 목표로 합니다.

- **Technical Details**: Stable Diffusion 3 모델은 DreamBooth 기법을 통해 추가 정보를 학습하여 이미지 생성을 개선합니다. LoRA(저랭크 적응) 기법을 이용하여 훈련 파라미터 수를 줄이면서 성능을 높일 수 있습니다. 실험에서는 SSIM(구조적 유사도 지수), PSNR(피크 신호 대 잡음 비율), FID(프레셰 관창 거리)와 같은 다양한 메트릭을 사용하여 성능을 평가하였습니다.

- **Performance Highlights**: 미세 조정된 Stable Diffusion 3 모델은 FID에서 266.5844를 기록하여 원래 모델의 366.9462보다 낮은 값을 보였습니다. SSIM에서는 0.2258로 원래 모델의 0.1387보다 개선되었습니다. PSNR은 23.2820 dB로 원래 모델 23.1765 dB보다 약간 더 높은 품질의 이미지를生成했습니다. 사용자 설문 조사에서는 미세 조정된 모델의 생성한 이미지가 보다 자연스러웠다는 의견이 대다수였습니다.



### MIMO: Controllable Character Video Synthesis with Spatial Decomposed Modeling (https://arxiv.org/abs/2409.16160)
Comments:
          Project Page: this https URL

- **What's New**: 본 논문에서는 사용자 입력에 의해 제어 가능한 속성(캐릭터, 동작 및 장면)을 가진 캐릭터 비디오를 합성할 수 있는 MIMO라는 새로운 프레임워크를 제안합니다. 이 방법은 다양한 캐릭터에 대해 고급 확장성 및 새로운 3D 동작의 일반성을 제공하며, 실시간 상호작용이 가능한 실제 장면에 적용됩니다.

- **Technical Details**: MIMO에서는 2D 비디오를 컴팩트한 공간 코드로 인코딩합니다. 구체적으로 단안 깊이 추정기를 사용하여 2D 프레임 픽셀을 3D로 변환 후, 동영상 클립을 3D 깊이를 기반으로 주요 인물, 하위 장면 및 부유하는 오클루전의 세 가지 공간 구성 요소로 분해합니다. 이 구성 요소들은 각각의 조정 신호로 사용되며, 이를 통해 복잡한 동작 표현과 사용자 제어를 가능하게 합니다.

- **Performance Highlights**: 실험 결과 MIMO는 다양한 속성을 제어할 수 있는 고품질 캐릭터 비디오 합성에서 효과성과 견고성을 입증했습니다. 이 방법은 또한 기존의 2D 방법들이 갖는 한계를 극복하고, 복잡한 3D 동작 및 물체 간 상호작용이 있는 실제 장면을 처리할 수 있는 가능성을 보여줍니다.



### ComiCap: A VLMs pipeline for dense captioning of Comic Panels (https://arxiv.org/abs/2409.16159)
Comments:
          Accepted at ECCV 2024 Workshop (AI for Visual Art), repo: this https URL

- **What's New**: 이 논문에서는 Vision-Language Models (VLMs)를 활용한 만화 패널의 밀집 캡션 생성 파이프라인을 제안합니다. 기존의 VLM을 추가 훈련 없이 활용하며, 중요한 속성을 고려하는 두 단계의 메트릭을 개발하여 모델의 성능을 평가합니다.

- **Technical Details**: 제안된 파이프라인은 자동 핵심 요소 추출 및 BERT-score 평가를 기반으로 한 두 단계의 메트릭을 사용하여 VLM이 제공하는 캡션의 속성을 검토합니다. 또한 1,500개의 패널에 대한 캡션과 속성 목록이 주석 처리되어 있으며, 이를 기반으로 하는 벤치마크 데이터를 사용하여 기존 오픈 소스 VLM의 성능을 평가합니다.

- **Performance Highlights**: 본 파이프라인을 통해 2백만 개 이상의 패널이 주석 처리되어, 고급 캡션이 제공됩니다. 밀집 캡션은 훈련된 특정 모델이 생성한 캡션보다 정량적 및 정성적으로 우수한 결과를 보여줍니다.



### MCTrack: A Unified 3D Multi-Object Tracking Framework for Autonomous Driving (https://arxiv.org/abs/2409.16149)
Comments:
          14 pages, 7 figures

- **What's New**: 이번 논문에서는 MCTrack이라는 새로운 3D 다중 객체 추적 방법을 소개하며, KITTI, nuScenes, Waymo 데이터셋 전반에서 최신 성능(SOTA)을 달성하였습니다.

- **Technical Details**: MCTrack은 기존의 데이터셋 간 일반화의 격차를 해소하며, BaseVersion이라는 표준화된 결과 포맷을 제안하여 연구 진영에서 데이터 전처리 부담을 줄일 수 있게 합니다. 이 방법은 BEV(각도-위치) 평면에서의 1차 매칭과 이미지 평면에서의 2차 매칭을 포함한 두 단계의 매칭 전략을 사용하여 정확성을 높입니다.

- **Performance Highlights**: MCTrack은 KITTI 및 nuScenes 데이터셋에서 1위를, Waymo 데이터셋에서 2위를 차지하며, 특히 실제 엔지니어링 응용 프로그램을 염두에 두고 설계되었습니다. 또한, 움직임 관련 정보(속도, 가속도, 각속도)를 평가하는 새로운 메트릭스를 도입하여 다중 객체 추적 작업 후의 모션 정보를 적절히 전달하는 데 중점을 두었습니다.



### Gaussian Deja-vu: Creating Controllable 3D Gaussian Head-Avatars with Enhanced Generalization and Personalization Abilities (https://arxiv.org/abs/2409.16147)
Comments:
          11 pages, Accepted by WACV 2025 in Round 1

- **What's New**: 최근 3D Gaussian Splatting (3DGS)의 발전으로 3D 헤드 아바타 모델링의 잠재력이 크게 향상되었습니다. 본 논문에서는 'Gaussian Déjà-vu' 프레임워크를 통해 보다 신속하게 개인화된 3DGS 기반 헤드 아바타를 생성하는 방법을 제안합니다.

- **Technical Details**: Gaussian Déjà-vu 프레임워크는 일반화된 3D 아바타 모델을 훈련한 후, 단일 이미지와 단안 비디오를 통해 개인화하는 과정을 포함합니다. 초기 3D Gaussian 헤드 모델은 대규모 2D 이미지 데이터셋에서 훈련되었습니다. 제안된 방법은 learnable expression-aware rectification blendmaps를 통해 3D Gaussian의 초기값을 수정합니다.

- **Performance Highlights**: 제안된 방법은 기존 3D Gaussian 헤드 아바타 제작 방법에 비해 포토리얼리스틱 품질이 우수하며, 훈련 시간 소비를 최소 1/4로 줄여 몇 분 안에 아바타를 생성합니다.



### Learning to Localize Actions in Instructional Videos with LLM-Based Multi-Pathway Text-Video Alignmen (https://arxiv.org/abs/2409.16145)
Comments:
          Accepted to ECCV 2024

- **What's New**: 본 연구는 교육 비디오에서 절차 단계를 지역화하는 새로운 훈련 프레임워크를 제안합니다. 특히, Large Language Models (LLM)을 활용하여 작업에 관련 없는 정보를 필터링하고, LLM을 통해 요약된 단계 문장을 기반으로 신뢰할 수 있는 대응 관계를 생성하기 위한 Multi-Pathway Text-Video Alignment (MPTVA) 전략을 도입했습니다.

- **Technical Details**: 제안된 MPTVA 전략은 (1) 내레이션 타임스탬프를 이용한 단계-내레이션-비디오 정합, (2) 장기적인 의미 유사성 기반의 직접적인 단계-비디오 정합, (3) 다양한 비디오 도메인에서 학습된 짧은 텍스트-비디오 정합 모델을 통한 단계-비디오 정합을 포함하는 세 가지 경로에서 정합을 측정합니다. 이를 통해 LLM 단계와 비디오 간의 신뢰성 있는 가상 정합을 생성합니다.

- **Performance Highlights**: 제안된 접근법은 절차 단계 정렬, 단계 지역화 및 내레이션 정렬의 세 가지 하위 작업에서 기존 최첨단 기술들을 5.9%, 3.1%, 2.8% 각각 초과하는 성과를 보여주었습니다. LLM 단계로 훈련된 모델이 wikiHow 단계로 훈련된 모델에 비해 10.7% 더 나은 성능을 보인 점이 주목할 만합니다.



### Seeing Faces in Things: A Model and Dataset for Pareidolia (https://arxiv.org/abs/2409.16143)
- **What's New**: 본 연구에서는 인간과 머신 간의 face pareidolia (얼굴 패레이돌리아)에 대한 인식 차이를 조사하기 위해 새로운 데이터셋인 'Faces in Things'를 소개합니다. 이 데이터셋은 무작위로 생성된 이미지에서 인간이 인식한 얼굴 구조를 포함하고 있습니다.

- **Technical Details**: 이 연구는 5,000개의 웹 이미지로 구성된 'Faces in Things' 데이터셋을 사용하여 인간 얼굴 탐지 시스템의 성능을 분석합니다. 연구 결과는 최신 연구 모델인 RetinaFace를 사용하여 성과를 변별하며, 파리돌리아가 머신에서 어떻게 나타나는지를 탐구합니다.

- **Performance Highlights**: 최신 모델은 얼굴 패레이돌리아 탐지에서 인간의 성능에 비해 상당한 격차를 보였습니다. 연구는 이 격차의 약 절반이 동물 얼굴 탐지 모델을 미세 조정하는 것에서 개선될 수 있음을 보여줍니다. 또한, 'Goldilocks zone'이라고 불리는 조건들이 패레이돌리아를 유도할 수 있음을 실험으로 확인하였습니다.



### HA-FGOVD: Highlighting Fine-grained Attributes via Explicit Linear Composition for Open-Vocabulary Object Detection (https://arxiv.org/abs/2409.16136)
Comments:
          This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 본 논문은 Open-Vocabulary Object Detection (OVD) 모델에서 세부 속성을 강조하는 새로운 접근 방식을 제안하여 기존 모델의 성능을 향상시키는 방법을 소개합니다.

- **Technical Details**: 이 방법은 1) Attribute Word Extraction, 2) Attribute Feature Extraction, 3) Attribute Feature Enhancement의 세 가지 주요 프로세스로 구성됩니다. 강력한 LLM(대규모 언어 모델)을 이용해 입력 텍스트에서 속성 단어를 추출하고, 전략적으로 토큰 마스크를 조정하여 OVD 모델의 텍스트 인코더가 전역 텍스트와 속성 특정 피처를 추출합니다. 이 피처들은 선형 조합을 통해 새로운 속성 강조 피쳐로 통합됩니다.

- **Performance Highlights**: FG-OVD 데이터셋에서 실험한 결과, 제안된 방법이 다양한 OVD 모델의 세부 속성 인식 능력을 일관되게 향상시키며 새로운 최첨단 성능을 달성함을 입증하였습니다.



### VisioPhysioENet: Multimodal Engagement Detection using Visual and Physiological Signals (https://arxiv.org/abs/2409.16126)
Comments:
          5 Pages, 2 figures

- **What's New**: 이번 논문에서는 Learner engagement(학습자 참여)을 감지하기 위한 VisioPhysioENet이라는 새로운 멀티모달 시스템을 제안합니다. 이 시스템은 visual cues(시각적 신호)와 physiological signals(생리 신호)를 활용하여 참여도를 탐지하며, Dlib 라이브러리를 사용한 얼굴 랜드마크 추출 및 OpenCV 라이브러리를 통한 추가 평가를 통해 시각적 특성을 두 단계로 추출합니다.

- **Technical Details**: VisioPhysioENet는 facial landmark(얼굴 랜드마크) 추출을 위해 Dlib을 활용하고, Eye Aspect Ratio (EAR), Pitch(피치), Yaw(요), Roll(롤)과 같은 지표를 포함하는 비주얼 피쳐를 처리합니다. 또한, remote photoplethysmography (rPPG) 신호를 비디오 입력을 통해 캡처하여 심혈관 활동을 모니터링합니다. 이 시스템은 multi-output classifiers(다중 출력 분류기)와 late fusion techniques(후처리 융합 기법)을 활용하여 다양한 참여 수준을 탐지하는 데 있어 정확성을 높입니다.

- **Performance Highlights**: DAiSEE 데이터 세트에서 철저한 평가를 수행한 결과, VisioPhysioENet는 63.09%의 정확도를 달성하여 기존 방법론보다 다양한 참여 수준을 식별하는 데 있어 우수한 능력을 보였습니다.



### Neuromorphic Drone Detection: an Event-RGB Multimodal Approach (https://arxiv.org/abs/2409.16099)
Comments:
          Accepted at NeVi Workshop at ECCV24

- **What's New**: 이번 연구에서는 드론 감지를 위한 새로운 모델을 제안하며, Neuromorphic 데이터와 RGB 데이터를 효과적으로 융합하여 정확한 탐지를 위한 멀티모달 접근 방식을 탐구합니다. 또한, NeRDD(Neuromorphic-RGB Drone Detection)라는 새로운 데이터셋을 공개하여 3.5시간 이상의 주석이 달린 멀티모달 녹화를 제공합니다.

- **Technical Details**: Neuromorphic 카메라는 전통적인 RGB 카메라에 비해 높은 속도 및 변화하는 조명 조건에서 뛰어난 성능을 보여줍니다. 이 연구에서는 스파이킹 네트워크와 같은 다양한 신경망 아키텍처를 조합하여 드론 탐지 정확도를 향상시킵니다. 또한, 두 데이터 스트림을 융합하는 다양한 전략을 비교하여 성능 최적화를 도모합니다.

- **Performance Highlights**: 실험 결과에 따르면, Neuromorphic 카메라와 RGB 데이터의 조합은 각각 분리된 경우보다 드론 탐지율을 더욱 향상시킵니다. NeRDD 데이터셋의 사용으로 드론 탐지의 정확성이 크게 증가했음을 확인하였습니다.



### From Pixels to Words: Leveraging Explainability in Face Recognition through Interactive Natural Language Processing (https://arxiv.org/abs/2409.16089)
- **What's New**: 본 논문에서는 Face Recognition (FR) 모델의 해석 가능성(transformability)을 높이기 위해 모델 불가지론적 설명 가능한 인공지능(Explainable Artificial Intelligence, XAI)과 자연어 처리(Natural Language Processing, NLP) 기술을 결합한 상호작용형 프레임워크를 제안합니다. 이 프레임워크는 사용자와의 대화를 통해 다양한 질문에 정확하게 응답할 수 있습니다.

- **Technical Details**: 제안된 프레임워크는, 프레임워크의 각 모듈에서 사용되는 기술의 세부사항을 포함하여 3개의 주요 모듈로 구성됩니다: (i) FR 시스템 및 신뢰도 추정, (ii) 설명 가능성 방법, (iii) NLP 기반의 사용자 친화적 질문-응답(QA) 인터페이스입니다. 이 시스템은 ArcFace 모델을 사용하여 얼굴 이미지를 비교하고, Probabilistic Interpretable Comparison (PIC) 스코어를 통해 유사성과 신뢰도를 평가합니다.

- **Performance Highlights**: 제안된 방법은 다양한 실험을 통해 FR 시스템 성능을 저하시키지 않으면서도 해석 가능성을 향상시키는 효과를 입증했습니다. 또한, 자가 분류에서의 사용자 질문을 통해 보다 정확한 정보를 제공하고, 민감한 애플리케이션에서의 의사 결정 투명성을 추가로 강화할 수 있습니다.



### MM-CamObj: A Comprehensive Multimodal Dataset for Camouflaged Object Scenarios (https://arxiv.org/abs/2409.16084)
Comments:
          9 pages, 5 figures. Work in progress

- **What's New**: 이 논문에서는 MM-CamObj 데이터셋을 새롭게 구축하였으며, 특히 위장된(camouflaged) 객체와 장면을 다루는 LVLM(CamObj-Llava)을 제안합니다.

- **Technical Details**: MM-CamObj 데이터셋은 두 개의 하위 집합으로 나뉘어 있으며, CamObj-Align는 VL 정렬(VL alignment)을 위한 11,363개의 이미지-텍스트 쌍을 포함하고, CamObj-Instruct는 LVLM을 위한 매뉴얼을 따르는 성능 개선을 목적으로 다양한 지시와 함께 68,849개의 대화를 포함합니다. 학습 전략으로는 curriculum learning이 도입되어, 난이도에 따라 자료를 제공하며, CamObj-Bench는 위장 JPEG 작업을 평가하는 기준으로 600개의 이미지와 7개의 작업을 포함합니다.

- **Performance Highlights**: CamObj-Llava는 CamObj-Bench에서 7개 작업의 4개에서 GPT-4o 대비 25.84%의 성능 향상을 보여주며, 위장 장면에 대한 이해, 인식, 위치 측정 및 개수를 정확히 수행하는 데 있어 뛰어난 성능을 입증합니다.



### GS-Net: Global Self-Attention Guided CNN for Multi-Stage Glaucoma Classification (https://arxiv.org/abs/2409.16082)
Comments:
          5 pages, 3 figures

- **What's New**: 본 논문은 다단계 녹내장(Glaucoma) 분류를 위한 새로운 네트워크인 GS-Net을 제안합니다. GS-Net은 글로벌 자기 주의(attention) 모듈인 GSAM을 도입하여 fundus 이미지에서 더 많은 구별 가능한 특징을 추출하도록 설계되었습니다.

- **Technical Details**: GS-Net은 백본 네트워크(backbone network), 글로벌 자기 주의 모듈(GSAM), 및 분류기로 구성됩니다. GSAM은 채널 주의 모듈(CAM)과 공간 주의 모듈(SAM) 두 개의 병렬 모듈로 이루어져 있으며, 이들은 각각 채널과 공간 차원에서의 글로벌 특징 종속성(global feature dependencies)을 학습합니다.

- **Performance Highlights**: 실험 결과 GS-Net은 기존의 최첨단 방법들보다 우수한 성능을 보이며, GSAM은 인기 있는 자기 주의 모듈들과 비교했을 때 경쟁력 있는 성능을 발휘합니다.



### Open-World Object Detection with Instance Representation Learning (https://arxiv.org/abs/2409.16073)
Comments:
          Our project website can be found at this https URL

- **What's New**: 본 논문에서는 Open World에서 객체 탐지(Object Detection) 문제를 해결하기 위해 Vision Foundation Models(VFM)의 지식을 활용한 새로운 방법을 제안합니다. 기존의 OWOD 방법들이 탐지된 객체 간의 세밀한 관계를 포착하지 못하는 문제를 해결하고자 합니다.

- **Technical Details**: 본 방법은 두 가지 모듈인 Unknown Box Refine Module과 Embedding Transfer Module을 통해 작동합니다. Unknown Box Refine Module은 Segment Anything Model(SAM)에서 생성된 세그멘테이션 마스크를 활용하여 미지의 객체의 바운딩 박스를 보정합니다. Embedding Transfer Module은 VFM의 픽셀 레벨 특징에서 얻은 인스턴스 간의 유사성을 탐지기의 인스턴스 임베딩에 전이하여 특징 공간을 향상시킵니다.

- **Performance Highlights**: 이 논문에서 제안한 방법은 OWOD 기반의 다른 방법들보다 뛰어난 성능을 보이며, 미지의 객체 탐지 성능과 임베딩된 특징 공간의 품질을 높이고 있습니다. 또한, 개방형 세계 추적(open-world tracking) 작업에서 세밀한 특징을 학습한 결과로 적용 가능성이 증대되었음을 보여줍니다.



### Machine learning approaches for automatic defect detection in photovoltaic systems (https://arxiv.org/abs/2409.16069)
Comments:
          31 pages, 14 figures

- **What's New**: 본 연구는 태양광(PV) 모듈의 결함 감지에 대한 최신 딥러닝 기반 컴퓨터 비전 기술을 검토하고 분석합니다. 드론 이미징을 통해 태양전지 패널의 결함을 실시간으로 분석할 수 있는 AI 모델 개발에 중점을 둡니다.

- **Technical Details**: 이 논문에서는 드론을 이용한 이미지 캡처 방법을 사용하여 IR 이미지, EL 이미지 및 RGB 이미지의 세 가지 유형을 기반으로 효율적으로 결함을 감지하는 다양한 접근법을 비교합니다. 또한, CNN을 포함한 딥러닝 아키텍처와 데이터 증강(data augmentation) 또는 생성적 적대 네트워크(generative adversarial networks) 기술을 결합하여 이루어진 기존의 다양한 방법론에 대해서도 논의합니다.

- **Performance Highlights**: 모델 해석 가능성 분석을 수행한 결과, 결함 분류를 위해 이미지의 어두운 영역에 초점을 맞추고 있음이 밝혀졌습니다. 결함 감지의 정확성을 높이기 위해 기하학적 딥러닝 기법을 기존 접근법과 통합하거나, 물리 법칙에 기반한 신경망을 활용하는 방법을 제안합니다.



### Benchmarking Robustness of Endoscopic Depth Estimation with Synthetically Corrupted Data (https://arxiv.org/abs/2409.16063)
Comments:
          To appear at the Simulation and Synthesis in Medical Imaging (SASHIMI) workshop at MICCAI 2024

- **What's New**: 이 연구에서 제안된 Depth Estimation Robustness Score (DERS)는 외과적 환경에서의 깊이 추정 모델의 강건성을 평가하기 위한 새로운 기준을 설정합니다. 이 평가는 수술 중 발생할 수 있는 이미지 왜곡을 반영하기 위한 포괄적인 데이터셋을 기반으로 합니다.

- **Technical Details**: 제안된 DERS는 에러 (Error), 정확도 (Accuracy) 및 강건성 (Robustness)을 결합하여 깊이 추정 기술의 성능을 평가하기 위한 복합 지표입니다. 연구는 조명 변화, 시각적 장애물, 센서 노이즈 등 모델의 성능에 영향을 미치는 다양한 왜곡 유형을 포함합니다.

- **Performance Highlights**: 두 개의 단안 (Monocular) 깊이 추정 모델을 통한 실험 결과는 실제 환경에서의 알고리즘 신뢰성을 강조하였으며, 데이터 저하 (Data Corruption)에 강한 알고리즘의 필요성을 부각시켰습니다. 연구는 수술 정밀도 및 환자 안전 개선에 기여하는 실질적인 결과를 도출하였습니다.



### Generative 3D Cardiac Shape Modelling for In-Silico Trials (https://arxiv.org/abs/2409.16058)
Comments:
          EFMI Special Topic Conference 2024

- **What's New**: 본 논문에서는 심층 학습(deep learning) 방법을 통해 인공 대동맥(aortic) 형태를 모델링하고 생성하는 기법을 제안합니다. 이 방법은 형태를 신경 서명 거리 필드(neural signed distance field)의 영(零) 수준 집합(zero-level set)으로 표현하고, 이 형태들의 기하학적 특징을 인코딩하는 학습 가능한 임베딩 벡터(embedding vectors)에 의해 조건화합니다.

- **Technical Details**: 네트워크는 CT 이미지로 재구성된 대동맥 뿌리(aortic root) 메쉬(mesh) 데이터셋을 기반으로 훈련되며, 신경 필드(neural field)가 샘플링된 표면 점(surface points)에서 사라지도록 하고, 공간 기울기(spatial gradient)가 단위 노름(unit norm)을 가지도록 강제합니다.

- **Performance Highlights**: 실험 결과, 제안된 모델은 대동맥 형태를 높은 충실도(high fidelity)로 표현할 수 있으며, 학습된 임베딩 벡터에서 샘플링하여 실제 환자의 해부학을 닮은 새로운 형태를 생성할 수 있습니다. 이러한 형태는 인실리코 시험(in-silico trials)에 활용될 수 있습니다.



### Towards Robust Object Detection: Identifying and Removing Backdoors via Module Inconsistency Analysis (https://arxiv.org/abs/2409.16057)
- **What's New**: 본 논문은 두 단계 객체 탐지 모델에서의 백도어(Backdoor) 탐지 및 제거 문제를 다룬 최초의 접근법으로, 객체 탐지 모델의 독특한 특성에 맞춘 새로운 백도어 방어 프레임워크를 제안합니다.

- **Technical Details**: 제안된 백도어 탐지 방법은 객체 탐지 모델의 두 주요 구성 요소인 Region Proposal Network (RPN)과 Region Classification Network (R-CNN) 간의 예측 불일치를 정량화하고 분석하여 백도어의 존재를 확인합니다. 제안된 백도어 제거 전략은 특정 모듈에 대한 재초기화와 소량의 깨끗한 데이터에 대한 전체 모델의 미세 조정을 포함합니다.

- **Performance Highlights**: 폭넓은 실험 결과에 따르면, 제안된 방법은 백도어 제거율에서 기존 방법에 비해 약 90% 개선을 달성하였으며, 깨끗한 데이터에 대한 정확도 손실은 4% 미만으로 제한되었습니다.



### Adversarial Watermarking for Face Recognition (https://arxiv.org/abs/2409.16056)
- **What's New**: 본 연구는 얼굴 인식 시스템에서 워터마킹(watermarking)과 적대적 공격(adversarial attacks) 간의 상호작용을 탐구하며, 적대적 워터마킹 공격(adversarial watermarking attack)이라는 새로운 위협 모델을 소개합니다.

- **Technical Details**: 워터마킹은 디지털 이미지를 통해 소유권을 주장하고 무단 변경을 모니터링하는 데 필수적인 기술입니다. 얼굴 인식 시스템에서 워터마킹은 데이터 무결성과 보안을 보장하는 데 중요한 역할을 하지만, 공격자는 워터마킹 프로세스에 간섭하여 인식 성능을 심각하게 저하시킬 수 있습니다. 본 연구는 CASIA-WebFace 데이터셋을 통해 적대적 워터마킹 공격이 얼굴 매칭 정확성을 최대 67.2%까지 감소시킬 수 있음을 보여줍니다.

- **Performance Highlights**: 적대적 워터마킹 공격의 적용으로 인해 워터마킹이 없는 상태에서는 이미지가 정확하게 인식되지만, 워터마킹이 적용된 후에는 인식 실패를 유발하는 중요한 취약점이 발견되었습니다.



### Unleashing the Potential of Synthetic Images: A Study on Histopathology Image Classification (https://arxiv.org/abs/2409.16002)
Comments:
          Accepted at ECCV 2024 - BioImage Computing Workshop

- **What's New**: 이 연구는 히스토패스올로지(Histopathology) 이미지를 위한 새로운 합성 데이터 생성 방법을 탐구합니다. 특히, Diffusion 모델을 사용하여 이미지 패치를 생성하고, 이를 통해 기존 데이터 세트를 보강하여 분류 성능을 향상시키는 방법을 제안합니다.

- **Technical Details**: 연구에서는 Denoising Diffusion Probabilistic Models (DDPM)을 활용하여 클래스 라벨에 조건화된 합성 히스토패스올로지 이미지 패치를 생성합니다. 실험 결과에 따르면, Diffusion 모델은 전이 학습(Transfer Learning)에 효과적이며, GAN(Generative Adversarial Networks)으로 생성된 샘플은 데이터 증강(Augmentation)에 적합합니다. 또한, Transformer 기반의 생성 모델은 CNN(Convolutional Neural Networks) 기반 모델보다 이미지 필터링이 필요하지 않습니다.

- **Performance Highlights**: PCam 데이터 세트에 대한 실험 결과, 합성 이미지는 기존 데이터 세트를 효과적으로 보강하고, 히스토패스올로지 이미지 분류 작업의 성능을 향상시키는 데 기여합니다. 제안된 방법은 분석 모델과 최근 GAN 기반 합성 데이터 확장 방식 대비 분류 성능을 개선했습니다.



### Improvements to SDXL in NovelAI Diffusion V3 (https://arxiv.org/abs/2409.15997)
Comments:
          14 pages, 8 figures

- **What's New**: NovelAI Diffusion V3 모델은 SDXL을 기반으로 하며, 훈련 관행에서 여러 가지 향상을 이루었습니다. 특히 Zero Terminal SNR과 v-prediction 파라미터화를 도입했습니다.

- **Technical Details**: SDXL의 훈련 과정에서 𝜖-prediction에서 v-prediction으로 전환하였고, 노이즈 스케줄을 개선하여 더 높은 시그마 레벨까지 훈련하였습니다. 이를 통해 모델은 노이즈로부터 의미 있는 색상과 주파수를 예측하도록 학습하게 되었습니다.

- **Performance Highlights**: 모델의 훈련 진행을 통해 고해상도 이미지 생성에서 일관성을 회복하였으며, 실제 이미지의 품질 개선과 더불어 수렴 속도가 빨라졌습니다.



### Leveraging Unsupervised Learning for Cost-Effective Visual Anomaly Detection (https://arxiv.org/abs/2409.15980)
- **What's New**: 이 연구는 사전 훈련된 모델을 사용하고 저렴한 하드웨어로 시각적 이상 탐지 시스템을 개발하여 중소기업(SMEs)의 구매 부담을 줄이기 위한 새로운 접근 방식을 제안합니다. 이 시스템은 최소한의 데이터로 모델 훈련을 수행할 수 있으며, Raspberry Pi 4B에서 효율적으로 배포됩니다.

- **Technical Details**: 이 시스템은 Anomalib 라이브러리의 비지도 학습 모델을 활용하여 작동합니다. 10장의 정상 제품 이미지만을 사용하여 Raspberry Pi에서 90초 만에 이상 탐지 교육과 추론을 완료할 수 있으며, F1 매크로 점수는 0.95 이상을 기록합니다. PaDiM, PatchCore, CFlow-AD 및 FastFlow와 같은 여러 알고리즘이 적용되어 성능을 비교했습니다.

- **Performance Highlights**: 연구 결과, 이 저비용의 시각적 이상 탐지 시스템은 환경 변화에 약간 민감하지만, 중소 제조업체를 위한 공장 자동화 검사의 신속하고 경제적인 방법으로써의 가능성을 보여주었습니다. 시스템은 IoT(Internet of Things) 환경에서 효율적인 운영을 위한 샘플링과 같은 높은 성능을 유지합니다.



### Adversarial Backdoor Defense in CLIP (https://arxiv.org/abs/2409.15968)
- **What's New**: 이번 연구에서는 기존의 backdoor 공격 방어 방법들이 효과적이지 않은 이유를 조사하고, Adversarial Backdoor Defense (ABD)라는 새로운 데이터 증강(Data Augmentation) 방법을 제안합니다. ABD는 adversarial examples와 backdoor samples의 특징을 정교하게 맞추어 backdoor 공격을 효과적으로 무력화합니다.

- **Technical Details**: ABD는 기존의 데이터 증강 방법의 한계를 보완하기 위해, adversarial examples를 생성하고 이를 데이터 증강 과정에서 활용합니다. 이는 InfoNCE 손실 함수를 통해 모델의 피처 공간(feature space)에서 backdoor 특성과 유사한 주의를 생성합니다. 이러한 방식을 통해 모델은 악의적 입력에 더 잘 대응할 수 있도록 훈련됩니다.

- **Performance Highlights**: ABD는 BadNet에 대해 공격 성공률(Attack Success Rate, ASR)을 8.66%, Blended 공격을 10.52%, BadCLIP 공격에 대해 53.64%로 줄이는 성과를 보여주었습니다. 또한, clean accuracy의 평균 감소는 단 1.73%로 유지되었습니다.



### Semantics-Controlled Gaussian Splatting for Outdoor Scene Reconstruction and Rendering in Virtual Reality (https://arxiv.org/abs/2409.15959)
- **What's New**: 본 연구에서는 Semantics-Controlled GS (SCGS)라는 새로운 접근 방식을 제안하고, 이를 통해 비통제된 자연 환경에서 대규모 장면을 분리할 수 있게 되었습니다. 이 방법은 VR에서 장면 편집과 장면 파트 추출을 가능하게 합니다.

- **Technical Details**: SCGS는 Gaussian rasterization 과정을 수정하여 3D Gaussians를 2D 이미지 공간 및 3D Gaussian 공간에서 거의 동일한 품질로 분류합니다. 이를 통해 전체 클래스를 대규모로 제거할 수 있으며, SCGS는 기존의 'circling' 방식에 의존하지 않습니다. 또한, 새로운 야외 데이터셋을 도입하여 사용자 경험을 향상시킵니다.

- **Performance Highlights**: 당사는 제안된 방법이 기존 기술보다 시각 품질 및 3D-OVS 데이터셋에서의 세분화 품질 면에서 우수하다는 것을 입증했습니다. 사용자 연구 결과, 참가자들은 plain GS에 비해 SCGS를 선호하는 경향을 보였습니다.



### An ensemble framework approach of hybrid Quantum convolutional neural networks for classification of breast cancer images (https://arxiv.org/abs/2409.15958)
Comments:
          Accepted in the 3rd International Conference on Data Electronics and Computing

- **What's New**: 이번 연구에서는 Quantum Neural Network (QNN)와 혼합형 클래식-양자 신경망 아키텍처의 효과를 평가하여, 기존의 클래스 특징 추출과 결합한 새로운 하이브리드 모델을 제안하고 breast cancer histopathological dataset을 이용한 실험 결과를 제시했습니다.

- **Technical Details**: 연구에서는 세 가지의 하이브리드 Quantum Convolutional Neural Network (QCNN) 아키텍처를 개발하고, 각 아키텍처는 서로 다른 네트워크 구조를 가집니다. 이 모델들은 양자 회로를 통해 최종 클래스 확률을 계산하며, 전통적인 CNN을 통해 추출된 특성을 사용합니다. 연구 결과, 개별 모델의 정확도는 85.59%였으며, 앙상블 기법을 통해 86.72%로 개선되었습니다.

- **Performance Highlights**: 하이브리드 모델의 조합을 통한 앙상블 기법이 기존의 개별 QNN과 전통적인 신경망보다 우수한 성능을 보여주었습니다. 이는 양자-클래식 혼합 방식의 신경망이 의료 이미지 분류 작업에서 효과적으로 적용 가능하다는 것을 증명합니다.



### Mind the Prompt: A Novel Benchmark for Prompt-based Class-Agnostic Counting (https://arxiv.org/abs/2409.15953)
- **What's New**: 이 논문에서는 Class-Agnostic Counting (CAC)에 대한 새로운 평가 벤치마크인 Prompt-Aware Counting (PrACo)을 소개하여, 과거의 데이터세트와 메트릭스의 한계를 극복하고자 합니다. PrACo는 텍스트 프롬프트를 통해 수량을 카운팅하는 모델을 평가하기 위한 메트릭스를 제공합니다.

- **Technical Details**: PrACo 벤치마크는 두 가지 테스트로 구성되어 있습니다: (i) negative-label test, 이는 특정 클래스가 없는 이미지에서 프롬프트를 사용하여 테스트하고, (ii) mosaic test, 이는 두 개의 서로 다른 클래스가 포함된 인위적으로 만든 이미지에서 하나의 클래스만 설명하는 프롬프트를 사용하여 평가합니다. 이는 현재의 CAC 데이터셋의 부족함과 기존의 측정 지표의 한계를 보완하기 위해 설계되었습니다.

- **Performance Highlights**: 최신 SOTA(prompt-based CAC) 기술들을 평가한 결과, 일부 모델이 표준 클래스별 카운팅 메트릭에서 높은 성능을 보이지만, 프롬프트에서 설명하는 객체 클래스를 이해하는 데 있어 유의미한 결핍을 드러내어 더 세밀한 훈련 절차나 설계 수정이 필요함을 강조하였습니다.



### A Formalization of Image Vectorization by Region Merging (https://arxiv.org/abs/2409.15940)
- **What's New**: 이 논문에서는 이미지 벡터화(image vectorization)가 이미지 분할(image segmentation)이라는 점을 강조하며, 세분화에서 조합되는 방식으로 발전할 수 있음을 지적합니다. 또한, 기존 방식의 한계를 다루기 위해 영역 병합(region merging)과 곡선 평활화(curve smoothing)를 교대로 적용하는 새로운 벡터화 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 서로 다른 도메인 파라미터에 의해 유도된 이중 그래프(dual graph)와 원래 그래프(primal graph)에서의 교차 작업을 포함합니다. 이 방법은 또한 지역 정보의 갱신과 곡선 근사화를 분리하던 기존의 한계를 해결하고, Beaulieu-Goldberg 및 Mumford-Shah 함수와 같은 다양한 이득 함수(gain functionals)와 연관시켜 formalize합니다.

- **Performance Highlights**: 실험 결과, 제안된 벡터화 방법은 최신 소프트웨어와 비교해 동등하거나 우수한 충실도(fidelity)와 비용 효율을 보여주었습니다. 이 기술은 직관적인 몇 가지 파라미터에 의해서도 명확한 행동을 보이며, 비트맵에서 벡터 그래픽으로의 효율적인 변환을 가능하게 합니다.



### Self-supervised Shape Completion via Involution and Implicit Correspondences (https://arxiv.org/abs/2409.15939)
Comments:
          ECCV 2024

- **What's New**: 이 논문은 자가 감독(self-supervised) 학습 접근 방식을 사용하여 3D 형태 보완(shape completion) 작업을 수행하는 방법을 제안합니다. 특별한 점은 보완 함수(G)가 자기 역함수(involutory function)로 표현될 수 있어, 이는 G(G(X)) = X라는 제약을 의미합니다.

- **Technical Details**: 제안된 방법에서는 내용의 일관성(consistency measure)을 캔노니컬 스페이스(canonical space)에서 정의하여 보완 함수를 감독하고 'freeze and alternate' 전략을 활용하여 보완 및 대응 모듈을 최적화합니다. 또한, 불완전한(불완전한) 점 집합을 정의하기 위해 'Unsigned Distance Field (UDF)' 표현을 사용하여 점 정보의 밀도를 높이고, 부분 형태를 완성하는 데 필요한 자체 감독 손실을 도출합니다.

- **Performance Highlights**: 이 방법은 강체 형태(rigid shapes)와 비강체 형태(non-rigid shapes) 모두에서 우수한 성과를 보이며, 몇 가지 경우에 대해 감독 학습(supervised accuracy)에 근접하는 놀라운 정확도를 달성합니다.



### Automatic Registration of SHG and H&E Images with Feature-based Initial Alignment and Intensity-based Instance Optimization: Contribution to the COMULIS Challeng (https://arxiv.org/abs/2409.15931)
- **What's New**: 이 연구에서는 비침습적 두 번째 조화 생성 (second-harmonic generation, SHG) 이미지와 헤마톡 실린 (hematoxylin and eosin, H&E) 이미지를 자동으로 정합하는 새로운 방법을 제안합니다. 이 방법은 훈련 없이 자동 키포인트 매칭과 인스턴스 최적화를 통한 변형 정합(deformable registration)을 기반으로 합니다.

- **Technical Details**: 제안된 방법은 세 가지 단계로 구성됩니다: (i) 전처리, (ii) SuperPoint 및 SuperGlue를 이용한 특징 기반의 초기 정합, (iii) 인스턴스 최적화를 통한 조밀한 변형 정합. 이 과정에서 SHG와 H&E 이미지는 각기 다른 강도 분포를 가지고 있으므로 전처리를 통해 특징을 최대한 유사하게 만듭니다.

- **Performance Highlights**: 제안된 방법은 Learn2Reg 챌린지의 데이터셋을 사용하여 평가되었으며, 초기 정합에서 88%의 성공률과 평균 목표 등록 오류(average target registration error) 2.48을 기록했습니다. 이 방법의 소스 코드는 공개되어 DeeperHistReg 이미지 등록 프레임워크에 통합되어 사용될 수 있습니다.



### Facing Asymmetry -- Uncovering the Causal Link between Facial Symmetry and Expression Classifiers using Synthetic Interventions (https://arxiv.org/abs/2409.15927)
Comments:
          45 pages; 26 figures; accepted at ACCV 2024

- **What's New**: 이 연구는 얼굴 대칭(Facial Symmetry)이 표현 분류기 모델의 출력 행동에 미치는 영향을 분석하는 구조적 인과 모델을 개발하였으며, 이를 통해 unilateral facial palsy 환자의 얼굴 표현을 개선하는 방법에 대한 통찰을 제공합니다.

- **Technical Details**: 연구진은 얼굴 대칭의 영향을 분석하기 위해 구조적 인과 모델(Structural Causal Model)에서 파생된 합성 개입 프레임워크(Synthetic Interventional Framework)를 사용했습니다. 이 프레임워크는 얼굴 대칭을 변경하면서 다른 요소를 고정하여 네트워크의 출력 행동을 분석할 수 있게 합니다.

- **Performance Highlights**: 17개의 표현 분류기를 분석한 결과, 얼굴 대칭이 감소할수록 모델의 출력 활성화가 의미있게 낮아지는 것을 발견했습니다. 이 연구는 얼굴 대칭이 표현 분류기 행동에 중요한 인과적 요인임을 강조합니다.



### Learning Compact Channel Correlation Representation for LiDAR Place Recognition (https://arxiv.org/abs/2409.15919)
Comments:
          Submitted to ICRA 2025

- **What's New**: 본 논문은 LiDAR 장소 인식(LiDAR place recognition)을 위해 Compact Channel Correlation Representation (C3R)이라는 새로운 접근 방식을 제안합니다. C3R은 기존의 공분산 풀링(covariance pooling) 방법의 계산 부담과 차원 축소 문제를 해결하고자 하며, 피처 매트릭스를 소규모 그룹으로 나눈 후, 그룹별 공분산 행렬을 계산하고 이를 학습 가능한 집합 전략으로 집계합니다.

- **Technical Details**: C3R 방법은 피처 채널을 작은 그룹으로 나누고 각 그룹에 대해 공분산 행렬을 형성하여 로컬 피처 간의 상관관계를 효과적으로 캡처합니다. 이를 통해 데이터베이스 검색 속도를 높이고, 규범 행렬(normalization)을 적용하여 안정성을 보장합니다. 이론적 분석을 통해 순열 불변성(permutation invariance)과 고상호 정보(mutual information) 유지 능력을 보여줍니다.

- **Performance Highlights**: Oxford RobotCar, In-house, MulRan, WildPlaces 데이터셋에서 C3R 방법의 정확성과 강인성을 입증하기 위해 광범위한 실험을 수행하였으며, 기존의 첫 번째 차원 풀링 및 공분산 풀링 방법들과 비교하여 우수한 성능을 나타냈습니다. 코드 또한 논문 수락 후 공개될 예정입니다.



### Exploring the potential of collaborative UAV 3D mapping in Kenyan savanna for wildlife research (https://arxiv.org/abs/2409.15914)
Comments:
          accepted at IMAV 2024

- **What's New**: 본 논문은 UAV 기반의 협업 매핑 기술을 통해 야생 생물 보존을 지원하는 새로운 접근 방식을 탐구하고 있습니다. 특히 Visual Simultaneous Localization and Mapping (V-SLAM)과 Structure-from-Motion (SfM) 방법론의 실시간 성능 비교를 통해 이들의 장단점을 분석합니다.

- **Technical Details**: 이 연구에서는 V-SLAM의 전통적 제한 사항과 최근의 On-the-Fly (OtF) SfM의 가능성을 동시에 고려합니다. 협업 UAV의 데이터 수집 과정을 통해, 각각의 UAV가 실시간으로 자율적으로 위치를 파악하고, 맵을 재구성하는 구조를 갖추고 있습니다. OtF-SfM은 여러 UAV가 수집한 이미지 스트림을 실시간으로 처리하는 기능을 제안합니다.

- **Performance Highlights**: 연구에서는 두 가지 데이터 세트를 활용하여 협업 UAV의 성능을 평가했습니다. 최종 평가에서는 각 기법의 항공 경로 정확도를 Root Mean Square Error (RMSE) 지표로 측정하며, CNN으로 추출한 학습 기반의 tie points가 최종 정확도에 미치는 영향을 검토합니다.



### Unimotion: Unifying 3D Human Motion Synthesis and Understanding (https://arxiv.org/abs/2409.15904)
Comments:
          Project Page: this https URL

- **What's New**: Unimotion은 유연한 모션 제어 및 프레임 수준의 모션 이해가 가능한 최초의 통합 다중 작업 인간 모션 모델입니다. 기존의 모델은 글로벌 텍스트 또는 세밀한 프레임 스크립트 중 하나만 사용하여 아바타의 모션을 제어할 수 있었으나, Unimotion은 두 가지 모두를 동시에 수행할 수 있습니다.

- **Technical Details**: Unimotion은 글로벌 시퀀스 레벨 또는 로컬 프레임 레벨 텍스트 입력을 다룰 수 있으며, 각 포즈에 대한 세부적인 텍스트 설명이나 인간 모션 시퀀스를 출력합니다. 이 모델은 트랜스포머 아키텍처를 사용하고, 각각의 3D 포즈와 프레임 수준 텍스트 간의 시간적 정렬을 수행합니다. 지역 텍스트를 포즈와 함께 확산(diffusion)시키는 방법을 통해 모션 생성 및 이해의 유연성을 제공합니다.

- **Performance Highlights**: Unimotion은 HumanML3D 데이터셋의 프레임 수준 텍스트에서 모션으로의 전이 작업에서 최신 기술(State-of-the-art) 결과를 기록했습니다. 또한, 이 모델은 2D 비디오 주석, 4D 모캡 주석, 계층적 제어 및 모션 편집 등의 다양한 실제 응용 분야에 유용하게 사용될 수 있습니다.



### Unsupervised Attention Regularization Based Domain Adaptation for Oracle Character Recognition (https://arxiv.org/abs/2409.15893)
- **What's New**: 이 연구에서는 중국의 고대 문자인 oracle characters 인식 문제를 해결하기 위해 새로운 비지도 도메인 적응(Unsupervised Domain Adaptation, UDA) 방법인 비지도 주의 정규화 네트워크(Unsung Attention Regularization Network, UARN)를 개발했습니다. UARN은 레이블이 있는 손으로 쓴 oracle 문자에서 레이블이 없는 스캔 데이터로 인식 지식을 전이하는 역할을 합니다.

- **Technical Details**: UARN은 주의 일관성(attention consistency) 및 주의 구분성(attention discriminability)을 고려하여 oracle 문자 인식을 개선합니다. 전통적인 UDA 방법은 주로 분포 불일치를 줄이는 데 중점을 두지만, 본 연구에서는 이미지 플리핑 (flipping)에 대한 강건성을 요구합니다. 이를 통해 맵 경계가 서로 일치하도록 하고 구분이 어려운 클래스 간의 시각적 혼란을 줄입니다.

- **Performance Highlights**: Oracle-241 데이터셋을 이용한 실험 결과, UARN은 기존의 구조-텍스처 분리 네트워크(Structure-Texture Separation Network)보다 8.5% 더 우수한 성능을 보였으며, 더 나은 해석 가능성과 정확도를 기록했습니다.



### CAD: Memory Efficient Convolutional Adapter for Segment Anything (https://arxiv.org/abs/2409.15889)
Comments:
          14 pages

- **What's New**: 이 논문은 이미지 분할(분할 의미하는 Segment Anything, SAM)에서의 메모리 효율성을 개선하기 위해 새로운 병렬 컨볼루션 어댑터 아키텍처를 제안합니다. 기존의 어댑터 방식이 GPU 메모리 소모 문제를 갖고 있다는 점을 강조하며, 이를 해결하기 위해 SAM의 이미지 인코더와 병렬로 연결되는 방안을 제시합니다.

- **Technical Details**: 새로운 아키텍처는 SAM 모델의 이미지 인코더와 병렬로 연결되어 훈련 중에 이미지 인코더의 활성화(activation) 및 기울기(gradient)를 저장할 필요가 없게 만듭니다. 이를 통해 GPU 메모리 사용량이 절반 이하로 줄어들어, 간단한 디코더 미세 조정(fine-tuning)에 대한 대안으로 가치를 부각시켰습니다. 이 연구에서는 Fast Fourier Transform(FFT)을 사용하여 입력 이미지에서 고주파수 성분(high-frequency components, HFC)을 추출하는 방식을 채택하였습니다.

- **Performance Highlights**: 우리의 제안된 구조는 SAM 어댑터와 SAM 디코더와 비교하여 두 가지 도전 과제(그림자 탐지 및 위장 객체 탐지)에서 경쟁력 있는 실험 결과를 보여주었으며, 하드웨어 제한에 따라 어댑터 기반 학습이 불가능할 경우 유용한 대안임을 입증하였습니다.



### Exploring VQ-VAE with Prosody Parameters for Speaker Anonymization (https://arxiv.org/abs/2409.15882)
- **What's New**: 이번 연구에서는 Vector-Quantized Variational Auto-Encoder (VQ-VAE)를 기반으로 한 새로운 화자 익명화 접근법이 소개됩니다. 이 방법은 음성의 프로소디(prosody), 언어적 콘텐츠, 화자 정체성을 분리하여 화자 정체성만 수정할 수 있도록 설계되었습니다.

- **Technical Details**: 제안된 아키텍처는 세 개의 별도 브랜치를 통해 콘텐츠, 프로소디 및 화자 정체성에 대한 임베딩(embedding)을 계산합니다. 합성(synthesis) 과정에서 이 임베딩을 기반으로, 디코더는 화자 및 프로소디 정보를 조건으로 하여 더 섬세한 감정 상태를 포착하고 화자 식별을 정밀 조정합니다.

- **Performance Highlights**: 이 방법은 감정 정보를 보존하는 데 있어 대부분의 기준 기술(baseline techniques)을 능가하는 성과를 보였습니다. 그러나 다른 음성 프라이버시(voice privacy) 작업에서는 더 제한된 성과를 보여 추가적인 개선이 필요하다는 점이 강조되었습니다.



### Zero-Shot Detection of AI-Generated Images (https://arxiv.org/abs/2409.15875)
- **What's New**: AI 생성 이미지 탐지는 전례 없는 현실감과 능력을 가진 새로운 생성 아키텍처들이 지속적으로 등장하면서 매우 어려운 도전이 되고 있습니다. 이 논문에서는 AI 생성 훈련 데이터가 필요 없고 생성 아키텍처에 대한 지식도 필요 없는 제로샷 엔트로피 기반 탐지기(ZED)를 제안합니다.

- **Technical Details**: ZED 탐지기는 머신 생성 텍스트 탐지에 대한 최근 연구에서 영감을 받아 분석 중인 이미지가 실제 이미지 모델에 비해 얼마나 놀라운지를 측정합니다. 이를 위해, 우리는 손실 없는 이미지 인코더를 사용하여 각 픽셀의 확률 분포를 추정합니다. 이 인코더는 다중 해상도 아키텍처를 가지고 있으며, 컨텍스트는 이미지의 저해상도 버전의 픽셀로 구성됩니다.

- **Performance Highlights**: 제안된 탐지기는 단일 판별 피처(discriminative feature)를 사용하여 최첨단의(SoTA) 성능을 달성하며, 다양한 생성 모델에 대해 평균 3% 이상의 정확도 향상을 이룹니다.



### Potential Field as Scene Affordance for Behavior Change-Based Visual Risk Object Identification (https://arxiv.org/abs/2409.15846)
Comments:
          8 pages, 4 figures

- **What's New**: 이 논문에서는 지능형 운전 시스템을 위해 잠재적 위험을 식별하는 새로운 비주얼 리스크 객체 식별 프레임워크인 Visual-ROI를 제안합니다. 기존 방법들은 공간적 정확성과 시간적 일관성에서 눈에 띄는 한계를 보였으며, 이는 장면의 affordance를 완전하게 이해하지 못한 데서 비롯됩니다.

- **Technical Details**: 새로운 프레임워크는 Bird's Eye View (BEV) 표현을 사용하여 위험 객체를 식별하는데 있어 잠재적 필드(potential fields)를 탐색합니다. 이는 도로 인프라 및 교통 참여자로부터 유도된 반발력(repulsive forces)과 목표 지점에서 유도되는 인력(attractive forces)을 포함합니다. BEV 시맨틱 분할 결과를 통해 잠재적 필드를 계산하여 공간적 및 시간적 일관성을 개선했습니다.

- **Performance Highlights**: 실험 결과, 제안한 방법은 RiskBench 데이터셋에서 20.3% 및 11.6% 향상을 보였으며, nuScenes 데이터셋에서도 각각 5.4%의 공간적 정확성 증가와 7.2%의 시간적 일관성 향상을 보여주었습니다. 또한, 계산 효율성이 88% 증가했습니다.



### FSF-Net: Enhance 4D Occupancy Forecasting with Coarse BEV Scene Flow for Autonomous Driving (https://arxiv.org/abs/2409.15841)
- **What's New**: 이번 연구는 차량 자율 주행을 위한 4D occupancy forecasting의 새로운 접근 방식을 제안합니다. 제안된 방법은 BEV(scene flow)에서의 coarse 예측을 활용하여 4D 점유도 맵의 경향성을 효과적으로 예측함으로써 자율 주행의 안전성을 향상시키는 데 기여하고자 합니다.

- **Technical Details**: FSF-Net은 coarse BEV scene flow에 기반한 구조를 가지며, 여러 단계의 네트워크로 구성되어 있습니다. 첫 단계에서는 coarse BEV scene flow를 기반으로 general occupancy forecasting architecture를 개발하고, 두 번째 단계에서는 VQ-Mamba network를 통해 spatial-temporal structural scene feature를 추출하고, 마지막으로 U-Net 기반의 quality fusion network를 통해 최종 예측 결과를 개선합니다.

- **Performance Highlights**: FSF-Net은 공공 Occ3D 데이터셋을 바탕으로 Extensive experiments을 수행한 결과, IoU 및 mIoU에서 각각 현존하는 최첨단 방법보다 9.56% 및 10.87% 향상된 성과를 기록했습니다. 이러한 성과는 자율 주행의 안전성을 크게 향상시킬 것으로 기대됩니다.



### Deep Learning Techniques for Automatic Lateral X-ray Cephalometric Landmark Detection: Is the Problem Solved? (https://arxiv.org/abs/2409.15834)
Comments:
          16 pages, 7 figures

- **What's New**: 본 논문에서는 craniofacial landmark (두개안면 중요 지점) 의 자동 탐지를 위한 'Cephalometric Landmark Detection (CL-Detection)' 데이터셋을 소개합니다. 이는 가장 크고 포괄적인 공개 데이터셋으로 600장의 Lateral X-ray 이미지와 38개의 랜드마크를 포함하고 있습니다.

- **Technical Details**: CL-Detection 데이터셋은 다수의 의료기관과 장비에서 수집된 이미지 데이터로 구성되어 있으며, 이 데이터셋을 기반으로 한 2023 MICCAI CL-Detection Challenge를 통해 여러 연구팀이 제안한 deep learning (딥 러닝) 방법을 평가했습니다. 참가자들은 자동 landmark detection 알고리즘을 개발하고 Docker 컨테이너를 제출하여 성능을 비교했습니다.

- **Performance Highlights**: 최고의 방법들은 전문가 분석을 근접하게 재현하며, 평균 탐지율은 75.719%, 평균 반경 오차는 1.518 mm에 도달했습니다. 그러나 아직 개선의 여지가 있으며 여러 가지 실패하는 시나리오가 존재함을 확인하였습니다.



### PseudoNeg-MAE: Self-Supervised Point Cloud Learning using Conditional Pseudo-Negative Embeddings (https://arxiv.org/abs/2409.15832)
Comments:
          Submitted to ICRA2025

- **What's New**: PseudoNeg-MAE는 점구름(point cloud) 마스크 오토인코더(mask autoencoder)의 전역 특징 표현을 향상시키는 새로운 자기 지도 학습(self-supervised learning) 프레임워크로, 변환에 민감하고 식별 가능(discriminative)한 표현을 모두 지원한다. 기존의 대비 학습(contrastive learning) 방법들은 불변성(invariance) 확보에 집중하여 변환과 관련된 중요한 정보를 손실할 수 있었으나, PseudoNeg-MAE는 COPE라는 파라메트릭 네트워크를 사용하여 원본과 변환된 데이터 포인트 간의 관계를 모델링한다.

- **Technical Details**: 본 프레임워크는 COnditional Pseudo Negatives Embedding 네트워크(COPE)를 사용하여 다양한 변환을 적용한 입력 점구름에 대해 의사 부정(pseudo-negative) 임베딩을 생성하고, 이 ผ่าน 새로운 손실 함수로 COPE를 정규화하여 불변 솔루션으로 수렴하는 것을 방지한다. 이를 통해 MAE의 글로벌 표현이 보다 식별 가능하고 변환에 민감해진다.

- **Performance Highlights**: PseudoNeg-MAE는 ModelNet40 및 ScanObjectNN 데이터셋에서의 모양 분류 및 상대 자세 추정(relative pose estimation) 작업에서 최고 성능(state-of-the-art performance)을 달성하며, 특히 상대 회전 추정에서 뛰어난 정확도를 보여준다. 이러한 결과는 PseudoNeg-MAE가 식별 가능하고 변환 민감한 표현을 학습하는 데 효과적임을 나타낸다.



### Layer-wise Model Merging for Unsupervised Domain Adaptation in Segmentation Tasks (https://arxiv.org/abs/2409.15813)
- **What's New**: 본 논문에서는 기존에 훈련된 모델들을 결합하여 비용 없이 모델 병합을 수행하는 새로운 아키텍처를 제안합니다. 이 방법은 레이어 단위로 모델을 통합하여 초기 레이어를 통합하면서 최종 레이어의 특수성을 유지합니다.

- **Technical Details**: 제안된 방법은 Unsupervised Domain Adaptation (UDA)의 맥락에서 다양한 태스크와 데이터셋에 대해 실험하였으며, 특히 Semantic과 Panoptic Segmentation 작업에 적합합니다. 이 방법은 모델 파라미터의 일관성을 유지하고 서로 다른 데이터셋 및 태스크에서의 모델 병합을 가능하게 합니다.

- **Performance Highlights**: 실험 결과, 서로 다른 아키텍처의 모델 병합 시 mIoU가 6.8% 향상되었고, Semantic과 Panoptic Segmentation 모델 병합을 통해 mPQ가 7% 증가하는 등 UDA의 성능이 크게 향상되었습니다.



### Hyperbolic Image-and-Pointcloud Contrastive Learning for 3D Classification (https://arxiv.org/abs/2409.15810)
Comments:
          Accepted at IROS2024

- **What's New**: 이번 연구에서는 3D 대비 표현 학습의 새로운 접근법인 하이퍼볼릭 이미지 및 포인트 클라우드 대비 학습(HyperIPC)을 제안합니다. 기존의 코사인 유사도의 대비 학습 방법이 다중 모달 데이터의 잠재적인 의미 계층을 충분히 탐색하지 못하는 문제를 해결하기 위해, 하이퍼볼릭 공간을 활용합니다. HyperIPC는 서로 다른 모달 간의 강한 의미 계층 상관관계를 확립하기 위해 이미지를 사용하는 동시에, 포인트 클라우드를 통해 불변의 특징을 포착합니다.

- **Technical Details**: HyperIPC의 두 가지 모드로, intra-modal(내부 모달)과 cross-modal(교차 모달) 대비 학습을 다룹니다. 내부 모달에서는 포인트 클라우드의 고유한 기하학적 구조를 기반으로 하이퍼볼릭 임베딩(embedding) 표현을 탐색하여 불변 특징을 캡처합니다. 교차 모달에서는 미리 훈련된 이미지 인코더를 사용하여 2D 정보를 추출하고 이를 하이퍼볼릭 공간으로 매핑하여 대비 학습을 수행합니다. 또한, Poincaré 원형 모델을 사용하여 수치 안정성을 유지하면서 노드를 최적화합니다.

- **Performance Highlights**: HyperIPC는 ScanObjectNN 데이터셋에서 객체 분류 성능을 2.8% 향상시키고, 몇 샷 분류 결과를 5.9% 개선하는 등 뛰어난 성과를 보였습니다. 또한, ablation study를 통해 HyperIPC의 파라미터 설정의 논리성과 서브모듈의 효과성을 검증하였습니다.



### A Computer Vision Approach for Autonomous Cars to Drive Safe at Construction Zon (https://arxiv.org/abs/2409.15809)
Comments:
          6 Pages, Double columns

- **What's New**: 이 논문은 건설 구역에서의 도로 장애물 검출을 위한 혁신적이고 정확한 모델을 제안하며, 다양한 데이터 드리프트 조건에서 작동하도록 설계되었습니다.

- **Technical Details**: 이 논문에서 제안하는 모델은 컴퓨터 비전 기술을 기반으로 하며, YOLO 프레임워크를 사용하여 건설 구역에서의 장애물(예: 비콘, 콘, 장애물)을 탐지합니다. CARLA 시뮬레이터를 사용하여 드리프트된 데이터 세트를 생성하고, 이 데이터 세트는 다양한 도시 맵, 도로 레이아웃, 조명 및 날씨 조건을 고려하여 구축되었습니다.

- **Performance Highlights**: 개발된 모델은 94% 이상의 평균 정밀도를 달성하였으며, 검증 데이터 세트에서의 추론 시간은 1.6 밀리초에 불과해 매우 신뢰할 만한 성능을 보여줍니다.



### 3D-JEPA: A Joint Embedding Predictive Architecture for 3D Self-Supervised Representation Learning (https://arxiv.org/abs/2409.15803)
- **What's New**: 3D-JEPA는 새로운 비생성적(非生成的) 3D self-supervised representation learning(SSRL) 프레임워크로, 다중 블록 샘플링 전략과 컨텍스트 인지 디코더를 도입하여 대상 블록의 재구성을 향상시킵니다. 이 접근법은 기존의 수작업 데이터 증강 기법을 사용하지 않고, 특징 공간에서 높은 수준의 의미론적 표현을 학습할 수 있도록 지원합니다. 

- **Technical Details**: 3D-JEPA는 입력 점 구름(Point Cloud)을 처리하기 위해 토큰 임베딩(module) 사용, 다중 블록 샘플링 전략을 통해 컨텍스트 블록과 다양한 대표 대상(target) 블록을 생성합니다. 컨텍스트 인지 디코더를 통해 컨텍스트 정보를 지속적으로 제공함으로써, encoder는 대상 블록에 대한 의미론적 모델링을 보다 잘 수행할 수 있습니다.

- **Performance Highlights**: 3D-JEPA는 다양한 3D 다운스트림 작업에서 높은 효율성과 효과성을 보여줍니다. 예를 들어, PB_T50_RS 데이터셋에서 150개의 프리트레이닝 에폭(epoch)으로 88.65%의 정확도를 달성하였으며, 기존 방법들에 비해 필요한 훈련 에폭 수를 절반으로 줄이는 성과를 올렸습니다.



### DIAL: Dense Image-text ALignment for Weakly Supervised Semantic Segmentation (https://arxiv.org/abs/2409.15801)
Comments:
          accepted by the European Conference on Computer Vision (ECCV), 2024

- **What's New**: 본 논문에서는 Dense Alignment Learning Network (DALNet)를 제안하여 약한 감독 시맨틱 세분화(Weakly Supervised Semantic Segmentation, WSSS)의 문제를 해결합니다. DALNet은 텍스트 임베딩을 활용하여 객체의 포괄적인 이해와 정확한 위치 지정 기능을 향상시킵니다.

- **Technical Details**: DALNet은 두 가지 정렬 전략을 사용합니다: (1) Global Implicit Alignment (GIA)로 클래스 토큰과 텍스트 임베딩 간의 유사성을 극대화하고 배경 임베딩과의 유사성을 최소화하며, (2) Local Explicit Alignment (LEA)는 패치 토큰의 공간 정보를 사용하여 객체의 위치 지정을 개선합니다. 또한 이미지와 텍스트 간의 전경 특징을 정렬하면서 배경과 분리하는 교차 대비 학습(cross-contrastive learning) 접근 방식을 제안합니다.

- **Performance Highlights**: PASCAL VOC 및 MS COCO 데이터셋에서의 실험을 통해 DALNet이 기존의 WSSS 방법들보다 우수한 성능을 보임을 입증하였으며, 특히 단일 스테이지 방법으로서 효율적인 종단 간 프로세스를 가능하게 합니다.



### Training Data Attribution: Was Your Model Secretly Trained On Data Created By Mine? (https://arxiv.org/abs/2409.15781)
- **What's New**: 이 연구에서는 상용 텍스트-이미지(Model) 모델을 사용하여 생성된 데이터를 활용하여 비인가 사용을 방지하는 새로운 접근법을 제안합니다. 특히 추가적인 수정 없이도 의심되는 모델의 학습 데이터를 추적할 수 있는 방법을 제공합니다.

- **Technical Details**: 이 논문에서는 데이터 생성 과정에서 발생하는 고유한 '기억' 특성을 활용하여, 의심되는 모델이 특정한 소스 모델로부터 학습된 데이터를 가지고 있는지를 규명하는 방법을 개발합니다. 이는 모델의 훈련 알고리즘이나 출력에 수정 없이 이루어집니다. 이를 통해 두 가지 주요 접근 방식을 취하는데, 하나는 개별 샘플 수준에서 '핵심 샘플'을 선택하는 방법이고, 다른 하나는 통계적 수준에서 여러 그림자 모델(shadow models)을 훈련하여 데이터를 판별하는 방법입니다.

- **Performance Highlights**: 본 연구의 방법론은 의심되는 모델의 학습 데이터가 약 30%만 포함되어 있는 경우에도 0.6 이상의 정확도를 기록하였으며, 통계적 수준의 방법은 전체적으로 85%가 넘는 정확도로 소스 모델의 데이터를 식별하는 데 성공했습니다.



### Teaching Tailored to Talent: Adverse Weather Restoration via Prompt Pool and Depth-Anything Constrain (https://arxiv.org/abs/2409.15739)
Comments:
          Accepted by ECCV'2024

- **What's New**: 최근 악천후(Adverse Weather) 회복에 대한 발전이 잠재력을 보여주고 있지만, 실제 세계에서의 예측 불가능하고 다양한 날씨 열화 조합은 상당한 도전 과제가 되고 있습니다. 본 연구에서는 'T3-DiffWeather'라는 새로운 파이프라인을 소개하며, 이는 네트워크가 서브 프롬프트(sub-prompts)를 자율적으로 조합해 날씨 프롬프트(weather-prompts)를 구성하도록 하는 프롬프트 풀을 사용합니다.

- **Technical Details**: 우리는 또한 Depth-Anything 기능에 의해 제한된 일반 프롬프트를 통합하여 확산 과정(diffusion process)에 대한 장면별 조건(scene-specific condition)을 제공합니다. 또한, 대조 프롬프트 손실(contrastive prompt loss)을 도입하여 두 가지 유형의 프롬프트에 대한 뚜렷한 표현을 보장합니다. T3-DiffWeather는 다양한 합성 및 실제 데이터 세트에서 국지 상태를 통해 최신 악천후 제거 기술을 극복하며 최첨단 성능을 달성합니다.

- **Performance Highlights**: 우리는 T3-DiffWeather가 다양한 악천후 벤치마크에서 SOTA(State-of-the-Art) 성능을 달성했으며, 최신 WeatherDiffusion에 비해 샘플링 단계 수가 10배 줄어들어 계산 효율성(computational efficiency)에서 현저한 이점을 지닌다는 결과를 발표하였습니다.



### LaPose: Laplacian Mixture Shape Modeling for RGB-Based Category-Level Object Pose Estimation (https://arxiv.org/abs/2409.15727)
Comments:
          Accepted by ECCV 2024

- **What's New**: LaPose는 RGB 기반의 객체 포즈 추정 기술에서 발생하는 깊이 정보 부재에 따른 문제를 해결하기 위해 제안된 새로운 프레임워크입니다. 이는 Laplacian mixture model을 사용하여 객체 모양의 불확실성을 명시적으로 정량화하고 다양한 객체 기하학적 특성을 포착합니다.

- **Technical Details**: LaPose는 두 가지 정보 스트림을 활용하여 객체 모양을 Laplacian mixture model로 모델링합니다. 이로 인해 각 점의 확률 분포를 정의하여 형태 불확실성을 제외하고, PnP 모듈을 통해 2D-3D 대응 관계를 설정하여 포즈를 해결합니다. 또한, 스케일 모호성을 해소하기 위해 스케일 불변(object size and translation) 표현을 도입하였습니다.

- **Performance Highlights**: LaPose는 NOCS 데이터셋에서 RGB 기반 객체 포즈 추정에서 최신 성능을 달성하였으며, 실험 결과는 제안된 디자인 선택의 효과성을 확인합니다.



### Disentangled Generation and Aggregation for Robust Radiance Fields (https://arxiv.org/abs/2409.15715)
Comments:
          27 pages, 11 figures, Accepted by ECCV'2024

- **What's New**: 이 연구에서는 트리플레인(triplane) 기반의 3D 표현을 사용하여 카메라 포즈(camera poses) 및 3D 장면을 효율적이고 고품질로 추정하는 방법을 제안합니다. 특히, Disentangled Triplane Generation 모듈과 Disentangled Plane Aggregation을 도입하여 카메라 포즈 업데이트 시 발생하는 문제를 완화하고, 새로운 두 단계의 Warm-start 훈련 전략을 통해 최적화를 개선합니다.

- **Technical Details**: 트리플레인 기반의 대표적인 접근 방식에서는 지역 업데이트(local updating)로 인해 최적화 과정에서 로컬 미니마(local minima)에 빠지는 문제가 있습니다. 이를 해결하기 위해, 본 연구의 Disentangled Plane Aggregation(DPA) 방식은 각 플레인의 피처(feature)를 독립적으로 분리하여 카메라 포즈와 장면의 대표성을 강건하고 모호하지 않게 최적화합니다. 이 연구는 또한 트리플레인 생성기를 통해 패러미터를 공유하여 전체 맥락을 참고할 수 있는 구조를 제공합니다.

- **Performance Highlights**: 제안된 방법은 LLFF 및 NeRF-synthetic 데이터셋에서 새로운 뷰 생성(novel view synthesis)과 포즈 추정(pose estimation) 모두에서 최신 성능(state-of-the-art performance)을 기록했습니다. 정량적 및 정성적 평가 결과를 통해, 카메라 포즈가 불확실하거나 노이즈가 있는 경우에도 우수한 성능을 보임을 입증했습니다.



### Plenoptic PNG: Real-Time Neural Radiance Fields in 150 KB (https://arxiv.org/abs/2409.15689)
- **What's New**: 이 논문의 목표는 2D 이미지로부터 3D 장면을 매우 압축된 표현으로 인코딩하고, 다양한 플랫폼에서 실시간으로 전송, 디코딩 및 렌더링할 수 있게 하는 것입니다. NeRF 및 Gaussian Splats의 발전에도 불구하고, 이들 방법의 큰 모델 크기와 특수 렌더러는 자유 시점 3D 콘텐츠를 이미지만큼 쉽게 배포하는 데에 도전 과제가 있습니다.

- **Technical Details**: 우리는 Plenoptic Portable Neural Graphics(줄여서 PPNG)라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 장면의 플레놉틱 함수를 사인 곱함수로 인덱싱된 밀집 볼륨에 인코딩하는 새로운 3D 표현을 포함합니다. 이 방법은 공간의 여러 위치 간의 특징 공유를 가능하게 하여 전통적인 공간의 보컬보다 더 높은 압축성을 제공합니다. 또한, 새로운 경량 렌더링 파이프라인을 개발하여 Plenoptic PNG 표현을 표준 GL 텍스처와 프래그먼트 셰이더로 인스턴트 디코딩할 수 있습니다.

- **Performance Highlights**: 우리는 Plenoptic PNG가 이전 메모리 효율적 방법에 비해 100배 작은 154KB 모델 크기로 기초 라인보다 뛰어난 성능을 보였다고 보고합니다. 이 방법은 모든 실시간 웹 준비 NeRF 방법 중에서 훈련 속도, 렌더링 품질, 모델 크기 간의 최상의 균형을 보여 주며, 몰입형 3D 미디어를 위한 널리 접근 가능한 현실적이고 효율적인 상호 교환 파일 형식을 제공합니다.



### PDT: Uav Target Detection Dataset for Pests and Diseases Tr (https://arxiv.org/abs/2409.15679)
Comments:
          23 pages, 11 figures, European Conference on Computer Vision 2024

- **What's New**: 본 논문에서는 고해상도의 UAV 기반 데이터셋인 Pests and Diseases Tree 데이터셋(PDT dataset)과 Common Weed and Crop 데이터셋(CWC dataset)을 개발하여, 농업 드론의 잡초, 해충 및 질병 감지 모델의 한계를 극복하고자 합니다. 이러한 데이터셋들은 실세계 운영 환경에서 수집되어, 기존의 데이터셋으로 인해 발생하는 문제를 해결합니다.

- **Technical Details**: PDT 데이터셋은 다양한 고도에서 잡초 및 해충을 감지할 수 있는 고정밀 UAV 데이터셋으로, 이는 스마트 농업에서 필요한 실질적인 데이터 수요를 충족하기 위해 디자인되었습니다. 또한, YOLO-Dense Pest(YOLO-DP) 모델을 설계하고, 이를 통해 다수의 테스트 모델을 재평가하여 데이터셋의 완전성과 YOLO-DP 모델의 효과성을 증명합니다.

- **Performance Highlights**: PDT 및 CWC 데이터셋을 기반으로 한 YOLO-DP 모델은 높은 정확도로 잡초, 해충 및 질병 이미지를 탐지할 수 있는 능력을 보여줍니다. 기존의 검출 모델과 비교하여, YOLO-DP는 뛰어난 성능을 발휘하며, 농업 UAV의 효율성을 향상시킬 것으로 기대됩니다.



### ImPoster: Text and Frequency Guidance for Subject Driven Action Personalization using Diffusion Models (https://arxiv.org/abs/2409.15650)
- **What's New**: 이 논문에서는 ImPoster라는 새로운 알고리즘을 제안하여, '소스' 주체가 '드라이빙' 동작을 수행하는 목표 이미지를 생성합니다. 이는 기존의 방법들과 달리 비지도(unsupervised) 방식으로 동작하며, 추가적인 주석 없이 소스 이미지과 드라이빙 이미지, 그리고 두 이미지에 대한 텍스트 설명만으로 동작합니다.

- **Technical Details**: ImPoster는 사전 훈련된(text-to-image) Latent Diffusion Model을 기반으로 하며, 소스 이미지와 드라이빙 이미지의 특성을 학습하기 위해 모델을 소량의 반복을 통해 미세 조정(finetuning)합니다. 추론 시에는 단계적 텍스트 프롬프트를 사용하여 원하는 목표 이미지를 생성하며, 새로운 확산 가이드 구성을 통해 각 단계에서 소스 주체와 드라이빙 동작의 매니폴드(manifold)로 생성을 유도합니다. 주파수(guidance)는 이미지의 주파수 도메인 속성을 반영하여 생성 과정에서 유용하게 사용됩니다.

- **Performance Highlights**: ImPoster는 다양하고 광범위한 소스-드라이빙 이미지 쌍에서 검증되어 이전 방법들과 비교하여 성능 향상을 입증하였습니다. 120,120 개의 이미지 쌍을 다룬 데이터셋을 기반으로 하여, 예를 들어 코끼리가 책을 읽거나, 원숭이가 명상하고 푸시업을 하거나, 테디베어가 기타를 치는 등의 다양한 이미지를 생성할 수 있습니다. 또한, CLIP Score, SSCD, DINO 등과 같은 기존 대안들과의 정량적 및 정성적 비교를 통해 ImPoster의 효과성을 확인했습니다.



### KISS-Matcher: Fast and Robust Point Cloud Registration Revisited (https://arxiv.org/abs/2409.15615)
Comments:
          9 pages, 9 figures

- **What's New**: KISS-Matcher는 포인트 클라우드 등록을 위한 오픈 소스 C++ 라이브러리로, 기존의 포인트 피처 히스토그램(FPFH)보다 향상된 Faster-PFH 기능 감지기를 포함하여, 등록 파이프라인의 모든 구성 요소를 통합하여 전체적인 효율성을 높였습니다.

- **Technical Details**: KISS-Matcher는 4개의 주요 구성 요소로 이루어져 있습니다: 기하학적 억제(geometric suppression), Faster-PFH 기반의 피처 추출 및 초기 매칭, k-core 기반의 그래프 이론적 아웃라이어 제거, 그리고 변형 비선형(non-minimal) 해결사입니다. 이는 두 개의 불규칙한 복셀화된 포인트 클라우드 간의 정렬을 목표로 합니다.

- **Performance Highlights**: KISS-Matcher는 기존의 최첨단 아웃라이어 강건 등록 파이프라인보다 빠른 성능을 자랑하며, 스캔 수준 등록에서 최첨단 방법과 동등한 성능을 보여주고, 특히 서브맵 수준 및 맵 수준 등록에서 우수한 확장성과 적용성을 갖습니다.



### Assessment of Submillimeter Precision via Structure from Motion Technique in Close-Range Capture Environments (https://arxiv.org/abs/2409.15602)
Comments:
          This study comprises 23 pages, 15 figures, and 5 tables. It is part of an ongoing PhD thesis currently under development

- **What's New**: 이 연구는 구조물 실험을 위한 서브 밀리미터 품질의 3D 모델 생성을 위한 Structure from Motion (SfM) 기법의 가능성을 조사하며, 실험에서는 1미터 거리에서 다양한 품질 설정을 적용하였다.

- **Technical Details**: SfM 기법을 통해 캡처 과정에서 카메라 보정 모델, Scale Bars 분포, 겹치는 비율, 수직 및 경사진 이미지 사용 등을 고려하였다. 80%의 겹침률을 적용하여 RMSE 값 약 0.1mm를 달성하였다.

- **Performance Highlights**: 이 연구 결과는 실험실 환경에서 구조적 시험을 위한 서브 밀리미터 수준의 정밀도를 가진 3D 모델링이 가능함을 보여준다. 이를 통해 구조물 모니터링 및 분석 분야에서 SfM 기법의 활용 가능성이 더욱 확대될 것으로 기대된다.



### FACET: Fast and Accurate Event-Based Eye Tracking Using Ellipse Modeling for Extended Reality (https://arxiv.org/abs/2409.15584)
Comments:
          8 pages, 5 figures

- **What's New**: 본 논문에서는 FACET(Fast and Accurate Event-based Eye Tracking)이라는 새로운 신경망 모델을 제안하여, 이벤트 데이터를 기반으로 눈동자의 타원 매개변수를 실시간으로 출력합니다. 이 모델은 XR(Extended Reality) 애플리케이션에 최적화되어 있으며, 기존의 프레임 기반 시스템이 가진 한계점을 극복하고자 합니다.

- **Technical Details**: FACET은 이벤트 기반의 경량화된 눈동자 검출기로, 기존의 이벤트 데이터에서 직접 타원을 예측하는 방식으로 동작합니다. 이를 위해 EV-Eye 데이터셋을 증강하고, 새로운 삼각법 손실 함수를 도입하여 타원 매개변수의 각도 불연속성 문제를 해결했습니다. 또한, 이벤트 볼륨의 수치화 방법을 설계하여 이벤트 표현값의 분포를 정규화했습니다.

- **Performance Highlights**: FACET은 향상된 EV-Eye 테스트 세트에서 평균 눈동자 중심 오류 0.20 픽셀과 0.53 ms의 추론 시간을 달성하여, 기존의 EV-Eye보다 픽셀 오류를 1.6배, 추론 시간을 1.8배 줄였습니다. 또한, 모델은 4.4배 적은 파라미터 수와 11.7배 적은 산술 연산으로 구현되었습니다.



### Clinical-grade Multi-Organ Pathology Report Generation for Multi-scale Whole Slide Images via a Semantically Guided Medical Text Foundation Mod (https://arxiv.org/abs/2409.15574)
- **What's New**: 이 논문은 Patient-level Multi-organ Pathology Report Generation (PMPRG) 모델을 제안하며, 이는 multi-scale WSI의 특징을 활용하여 정확한 병리 보고서를 생성하는 새로운 접근 방식을 모색합니다.

- **Technical Details**: PMPRG 모델은 multi-scale regional vision transformer (MR-ViT) 모델에서 나온 multi-scale WSI 특징을 이용하며, 실제 병리 보고서를 기반으로 VLM 훈련을 통해 보고서를 자동으로 생성합니다. 이 모델은 다양한 장기로부터 얻어진 여러 WSIs를 바탕으로 환자 수준의 보고서를 처리할 수 있도록 설계되었습니다.

- **Performance Highlights**: 모델은 METEOR 점수 0.68을 달성하며, 전반적인 접근 방식의 효과성을 입증합니다. 또한 이 모델은 많은 WSIs를 포함한 경우에도 효율적으로 병리 보고서를 생성할 수 있어 실제 임상 환경에 적합합니다.



### Critic Loss for Image Classification (https://arxiv.org/abs/2409.15565)
Comments:
          8 pages

- **What's New**: 이번 논문에서는 이미지 분류를 위한 새로운 손실 함수인 Critic Loss for Image Classification (CrtCl)을 제안합니다. CrtCl는 분류Classifier와 평정Critic을 공동으로 학습시켜 모델의 성능을 향상시킵니다. 이 접근법은 레이블이 있는 데이터와 없는 데이터 모두에서 학습할 수 있도록 지원합니다.

- **Technical Details**: CrtCl은 이미지 분류를 생성기-비평가(Generator-Critic) 프레임워크로 설정하여, 기본 분류기가 생성기로서 클래스에 대한 확률 분포를 생성합니다. 평정가는 이 생성기 모델이 올바른 분류를 했는지를 예측하여 손실 값을 계산합니다. 이 구조는 레이블이 없는 데이터를 활용이 가능하며, 세미-슈퍼바이즈드(Secondary learning) 환경에서도 효과적입니다.

- **Performance Highlights**: CrtCl은 세 가지 이미지 분류 데이터셋에서 다양한 양의 레이블 데이터로 실험한 결과, 기존의 베이스라인 대비 분류기의 일반화 및 캘리브레이션(Calibration)을 향상시켰습니다. 또한, 액티브 러닝(Active Learning)에서도 높은 정확도와 캘리브레이션 결과를 보였습니다.



### QUB-PHEO: A Visual-Based Dyadic Multi-View Dataset for Intention Inference in Collaborative Assembly (https://arxiv.org/abs/2409.15560)
- **What's New**: QUB-PHEO는 조립 작업 및 의도 추론에서 인간-로봇 상호작용(HRI) 연구를 발전시킬 가능성을 지닌 시각 기반 쌍방 데이터셋을 소개합니다. 이 데이터셋은 '로봇 대리인' 역할을 하는 두 참가자 간의 풍부한 다중 모드 상호작용을 캡처하며, 36개의 고유한 하위 작업으로 further 세분화된 다양한 조립 작업을 포함합니다.

- **Technical Details**: QUB-PHEO는 70명의 참가자로부터 시각적 주석(visual annotations)인 얼굴 랜드마크(facial landmarks), 시선(gaze), 손 움직임(hand movements) 및 객체 위치(object localization) 등을 포함하여, 두 가지 버전의 데이터를 제공합니다: 50명의 참가자를 위한 전체 비디오 데이터와 70명 모두를 위한 시각적 신호(visual cues)입니다. 기존의 단일 뷰 데이터셋의 한계를 극복하기 위해 다중 뷰 데이터 수집 및 하위 작업 인코딩을 특화하여 개발되었습니다.

- **Performance Highlights**: 이 데이터셋은 다중 시각적 데이터와 복잡한 인간 행동 및 의도에 대한 세부 정보를 제공하여 HRI의 기존 문제를 해결합니다. QUB-PHEO는 인간-로봇 협업에서 향상된 알고리즘 개발을 위한 기본 자원으로 작용하여, 로봇이 인간 행동과 의도를 더 높은 정확도로 해석하고 예측할 수 있도록 돕습니다.



### Mixture of Efficient Diffusion Experts Through Automatic Interval and Sub-Network Selection (https://arxiv.org/abs/2409.15557)
Comments:
          Accepted to the 18th European Conference on Computer Vision, ECCV 2024

- **What's New**: 이 논문에서는 사전 훈련된 확산 모델을 효율적인 전문가의 혼합(Mixture of Efficient Experts)으로 가지치기(pruning)하는 새로운 방법인 DiffPruning을 제안합니다. 이는 각 시간대에 대해 전문화된 모델을 분리하여 사용하며, 이를 통해 샘플링 비용을 줄일 수 있습니다.

- **Technical Details**: Diffusion Probabilistic Models (DPMs)의 샘플링 과정은 많은 양의 denoising steps를 필요로 합니다. 이를 개선하기 위해, 논문에서는 denoising timesteps 간의 유사성을 분석하여 데이터 세트에 따라 자연스러운 클러스터링을 확인하고, 각 간격에 대해 전문가를 세분화하여 fine-tuning합니다. 또한, Expert Routing Agent (ERA)를 도입하여 전문가들 간의 compute resource를 자동으로 할당합니다.

- **Performance Highlights**: DiffPruning 방법은 LSUN-Church, LSUN-Beds, FFHQ, ImageNet 등의 다양한 데이터 세트에서 효과성을 입증하였습니다. 특히, 모델 성과를 유지하면서도 샘플링 속도를 크게 향상시켰습니다.



### SOFI: Multi-Scale Deformable Transformer for Camera Calibration with Enhanced Line Queries (https://arxiv.org/abs/2409.15553)
- **What's New**: 이 연구에서는 카메라 캘리브레이션(camera calibration)을 위한 새로운 모델인 SOFI (multi-Scale defOrmable transFormer for camera calibratIon with enhanced line queries)를 소개합니다. 기존의 transformer 기반 모델들이 교차 스케일 상호작용(cross-scale interaction) 부족 문제를 가지고 있었던 반면, SOFI는 선(line) 쿼리를 개선하여 이러한 문제를 해결합니다.

- **Technical Details**: SOFI는 선 내용을 기반으로 한 선 쿼리(line queries)를 개선해 카메라 캘리브레이션에서 더 나은 성능을 발휘합니다. 이 모델은 다중 스케일(deformable) 어텐션 메커니즘을 사용하여 백본(backbone)에서 생성된 피쳐 맵(feature maps) 간의 교차 스케일 상호작용을 촉진합니다. 새로 제안된 선 쿼리는 각 인코더 층에 선 분절(geometric features)을 입력으로 사용함으로써 쿼리 초기화를 새롭게 설정합니다.

- **Performance Highlights**: SOFI는 Google Street View, Horizon Line in the Wild, Holicity 등 다양한 데이터셋에서 기존 방법들을 능가하며, 경쟁력 있는 추론 속도(inference speed)를 유지하고 있습니다.



### VaLID: Verification as Late Integration of Detections for LiDAR-Camera Fusion (https://arxiv.org/abs/2409.15529)
- **What's New**: 이 논문에서는 LiDAR와 카메라 데이터를 활용한 차량 객체 탐지에 대한 새로운 모델 독립적인 late fusion 방법인 VaLID를 제안합니다. 이 방법은 각 예측된 bounding box가 허용 가능한지를 검증하며, LiDAR 탐지기의 잘못된 예측을 줄이는 데 중점을 둡니다.

- **Technical Details**: VaLID는 캘리퍼스 멀티-레이어 퍼셉트론(Multi-Layer Perceptron, MLP)을 사용하여 높은 재현율(bias)로 LiDAR 탐지기의 잘못된 예측을 줄이는 동시에 실제 예측을 유지합니다. KITTI 데이터셋에서 여러 조합의 LiDAR 및 카메라 탐지기를 평가하여 평균 63.9%의 거짓 긍정(false positive)을 줄였습니다.

- **Performance Highlights**: 우리의 방법은 특정 데이터셋에 특별히 훈련되지 않은 일반 카메라 탐지기를 사용할 때에도 최신 기술과 경쟁할 수 있는 성능을 나타냅니다. VaLID 방식은 차량 감지에 대한 전반적인 평균 정밀도(average precision)를 향상시키는 데 기여했습니다.



### SpaGBOL: Spatial-Graph-Based Orientated Localisation (https://arxiv.org/abs/2409.15514)
- **What's New**: 이번 연구에서는 Cross-View Geo-Localisation 문제를 해결하기 위해 첫 번째 그래프 구조의 데이터셋과 GNN(그래프 신경망)을 도입하였습니다. 새로운 접근 방식으로, 여러 개의 거리뷰 이미지를 통해 지도 노드의 일반화를 개선하고, 노드 근접성과 특성 유사성 간의 상관관계를 활용한 첫 시스템을 개발했습니다.

- **Technical Details**: 이 연구에서 제안하는 SpaGBOL 모델은 GNN 아키텍처를 사용하여 도시 지역에서의 Geo-Localisation 기술을 개선합니다. 데이터는 거리뷰 이미지 및 위성 이미지의 집합으로 구성되며, 이들은 그래프의 노드를 통해 연결되며 도로는 그래프의 엣지로 표현됩니다. GNN은 미지의 시퀀스를 생성하고, 이웃 도로 방향에 기초한 새로운 검색 필터링 기법을 제공합니다.

- **Performance Highlights**: SpaGBOL은 이전 기술 대비 11%의 Top-1 검색 정확도를 개선하였으며, SpaGBOL 데이터셋에 대한 Bearing Vector Matching으로 필터링 시 50%의 개선을 보여 주었습니다. 이로써 새로운 시퀀스를 인식하는 데 필요한 실제적인 적용 가능성을 높였습니다.



### PixelBytes: Catching Unified Embedding for Multimodal Generation (https://arxiv.org/abs/2409.15512)
- **What's New**: 이 보고서는 PixelBytes Embedding이라는 새로운 접근 방식을 소개합니다. 이는 통합된 멀티모달 표현 학습(unified multimodal representation learning)을 위한 방법으로, 다양한 입력을 단일하고 일관된 표현으로 캡처하여 텍스트 및 픽셀화된 이미지에 대한 멀티모달 시퀀스 생성의 우수한 특성을 조화롭게 구현할 수 있도록 합니다.

- **Technical Details**: PixelBytes는 최신 시퀀스 모델인 Image Transformers, PixelCNN 및 Mamba-Bytes에서 영감을 받아 서로 다른 데이터 타입을 통합하는 데에 어려움을 해결하는 것을 목표로 합니다. RNNs(순환신경망), SSMs(상태공간모델), 주의(Attention) 기반 모델 등 다양한 모델 아키텍처를 탐구하며, 양방향 처리(bidirectional processing)와 혁신적인 PxBy embedding 기술에 중점을 둡니다.

- **Performance Highlights**: PixelBytes Pok{é}mon 데이터셋을 사용한 실험에서, PxBy embedding과 합성곱(convolutional) 레이어를 사용한 양방향 시퀀스 모델이 일관된 멀티모달 시퀀스를 생성할 수 있는 가능성을 입증했습니다. 이 작업은 통합 AI 모델의 발전에 기여하며, 멀티모달 데이터를 이해하고 생성하는 데 있어 보다 통합된 방식을 가능하게 합니다.



### Analysis of Human Perception in Distinguishing Real and AI-Generated Faces: An Eye-Tracking Based Study (https://arxiv.org/abs/2409.15498)
- **What's New**: 최근 인공지능(AI) 분야의 발전으로 인해 사실감 있는 인간 얼굴 생성에서 현저한 향상을 이루었습니다. 본 연구에서는 인간이 실제 이미지와 가짜 이미지 간의 차이를 어떻게 인식하고 구별하는지를 조사하였습니다. 본 연구는 Eye-tracking 기술을 활용하여 AI가 생성한 얼굴 이미지와 실제 얼굴 이미지를 판별하는 인간의 인식 방식을 분석했습니다.

- **Technical Details**: 본 연구에서는 StyleGAN-3을 활용하여 생성된 이미지와 Flickr-Faces-HQ Dataset(FFHQ)에서 샘플링한 실제 얼굴 이미지를 사용하였습니다. 실험 대상자들은 7000개 이상의 이미지를 보고 그 결과를 기록하였으며, 이와 동시에 Eye-tracking을 통해 시선 정보를 수집했습니다. 연구를 통해 인식 정확도 76.80%로 실제와 가짜 얼굴을 구별할 수 있는 평균적인 능력을 확인하였습니다.

- **Performance Highlights**: 연구 결과, 참여자들은 가짜 이미지로 의심되는 경우 이미지를 더욱 면밀히 분석하는 경향이 있음을 발견하였습니다. Eye-tracking 방식으로 수집된 데이터 분석을 통해 인식 정확도, 반응 시간, 주목 지속 시간 등의 다양한 측면에서 심도 깊은 분석을 수행하여, 인간의 시각적 행동 패턴을 이해하는 중요한 통찰을 제공했습니다.



### VLMine: Long-Tail Data Mining with Vision Language Models (https://arxiv.org/abs/2409.15486)
- **What's New**: 본 연구에서는 사용되지 않은 라벨 데이터를 통해 드문(long-tail) 예제들을 식별하는 데이터 마이닝(data mining) 방법론을 제안합니다. 제안된 방법은 VLM(Vision Language Model)을 활용하여 이미지 내용을 키워드(keyword) 집합으로 요약하고, 키워드의 빈도를 기반으로 드문 예제를 식별합니다.

- **Technical Details**: 제안된 방법인 VLMine은 VLM에서 추출한 지식을 활용하여 드문 예제를 식별합니다. 기존 모델의 불확실성(uncertainty) 기반 방식보다 VLM의 키워드 빈도 분석이 더 효과적인 신호를 제공하는 것을 보여줍니다. VLMine은 특정 태스크와 무관하게 사용할 수 있는 모델-불가지론적(data-agnostic) 방법입니다.

- **Performance Highlights**: VLMine을 통해 2D 이미지 분류 및 3D 객체 탐지 태스크에서 10%에서 50%의 성능 향상을 달성하였으며, ImageNet-LT, Places-LT, Waymo Open Dataset에서의 벤치마크 시험에서 기존 방법들에 비해 일관된 개선 결과를 보여주었습니다.



### MediConfusion: Can you trust your AI radiologist? Probing the reliability of multimodal medical foundation models (https://arxiv.org/abs/2409.15477)
Comments:
          17 Pages, 5 figures

- **What's New**: 새로운 벤치마크인 MediConfusion이 등장하여, 의료 분야에서 Multimodal Large Language Models (MLLMs)의 실패 유형을 시각적 관점에서 평가하는 데 중점을 두고 있습니다. 이 벤치마크는 기존 모델들의 한계를 드러내고, 신뢰할 수 있는 의료 AI 솔루션 개발에 중요한 기초 자료를 제공합니다.

- **Technical Details**: MediConfusion은 시각적으로 분명히 다른 이미지 쌍을 사용해 MLLMs가 혼란을 겪는 경향을 조사합니다. 이 벤치마크는 LLM(대규모 언어 모델) 프롬프트를 통해 생성된 다수의 선택 문제를 포함하고 있으며, 의료 영상 데이터셋인 ROCO를 활용하여 수집한 이미지 쌍 간의 특성을 분석해 신뢰성 문제를 탐구합니다.

- **Performance Highlights**: 현재 모든 모델(오픈 소스 및 독점 모델 포함)이 MediConfusion에서 무작위 추측보다 낮은 성능을 보이고 있습니다. 이는 의료 MLLMs의 신뢰성에 대한 심각한 우려를 나타내며, 연구자들은 보다 신뢰할 수 있는 모델 디자인을 위한 공통적인 실패 패턴을 파악하기 위해 노력하고 있습니다.



### Mat\'ern Kernels for Tunable Implicit Surface Reconstruction (https://arxiv.org/abs/2409.15466)
Comments:
          18 pages, 8 figures

- **What's New**: 이번 연구에서는 Matérn 커널(Matern kernels) 가족을 활용하여 조정 가능한 implicit surface reconstruction 방법을 제안하고 있습니다. 최근 3D 방향 포인트 클라우드 재구성에서 커널 방법의 성공을 기반으로 개발되었습니다.

- **Technical Details**: Matérn 커널은 정규화된 실수 공간을 기반으로 하며, 강력한 조정 가능성을 제공합니다. 이 커널들은 특히 arc-cosine 커널을 기반으로 한 최신 기술을 초월하는 성능을 보이며, 구현이 쉽고 계산 속도가 빠르며 확장성이 뛰어납니다. 저자들은 Matérn 커널의 스펙트럼을 Fourier feature 매핑과 유사한 방식으로 조정할 수 있음을 이론적으로 분석했습니다. 또한, SIREN 네트워크와의 관련성을 탐구하며 arc-cosine 커널과의 관계도 분석하였습니다.

- **Performance Highlights**: 특히 Laplace 커널은 Matérn 커널 가족의 일원으로서, 노이즈가 없는 경우 최신 방법들과 거의 동등한 성능을 보이며, 훈련 시간도 5배 이상 단축되어 효율적입니다.



### Revealing an Unattractivity Bias in Mental Reconstruction of Occluded Faces using Generative Image Models (https://arxiv.org/abs/2409.15443)
Comments:
          This paper and a corresponding poster were presented at the Cognitive Computational Neuroscience conference in 2024

- **What's New**: 이번 연구는 얼굴의 부분적 가림이 얼굴 매력을 증가시킨다는 기존의 가설에 도전합니다. 실험 결과, 가려진 얼굴의 모습이 오히려 비매력적인 특성을 가진 것으로 재구성된다는 것을 밝혀냈습니다.

- **Technical Details**: 두 가지 온라인 실험을 통해 관찰자들에게 가려진 얼굴 부위의 매력을 평가하도록 하였으며, 최신의 diffusion-based 이미지 생성기를 사용하여 비매력적, 중립적, 매력적인 얼굴 부분 이미지를 생성하였습니다. 실험 방법으로는 delayed matching-to-sample (DMTS) 과제를 활용하였습니다.

- **Performance Highlights**: 실험 결과, 일반적인 얼굴 매력 평가 과제에서는 매력도 편향이 나타났지만, DMTS 과제에서는 비매력적 이미지가 더 많이 선택되는 경향을 보여 비매력적 편향이 재구성 과정에서 발생함을 밝혀내었습니다.



### Ultrafast vision perception by neuromorphic optical flow (https://arxiv.org/abs/2409.15345)
Comments:
          17 pages, 4 figures

- **What's New**: 이번 연구는 기존의 2D 방법의 한계를 극복하기 위한 3D neuromorphic optical flow (광학 흐름) 방법을 제시합니다. 이는 움직임 속성을 직접 하드웨어에 적용하여 정확한 모션 신호를 생성함으로써 비디오 데이터의 처리 시간을 단축시킵니다.

- **Technical Details**: 이 연구에서는 memristors를 활용하여 외부 움직임 특성을 직접 하드웨어에 통합하는 새로운 접근법이 소개되었습니다. 이는 모션 속도를 처리하는 속도를 크게 향상시키고, 다중 영역의 세부적인 움직임 분석을 가능하게 합니다.

- **Performance Highlights**: 이 접근 방식은 평균 0.3초의 비디오 데이터 처리 시간을 단축하면서도 모션 예측, 객체 추적, 객체 분할의 정확도를 유지 또는 향상시킵니다. UAV 시나리오에서 첫 번째로 interframe visual processing (프레임 간 시각 처리)를 달성했습니다.



### Video-Driven Graph Network-Based Simulators (https://arxiv.org/abs/2409.15344)
- **What's New**: 본 논문에서는 짧은 비디오를 통해 물리적 속성을 유추할 수 있는 새로운 방법을 제안합니다. 이 방식은 명시적인 파라미터 입력 없이도 시스템의 동작을 시뮬레이션할 수 있게 해줍니다.

- **Technical Details**: 제안된 방법은 Video-Driven Graph Network-based Simulator (VDGNS)로, 짧은 비디오 세퀀스를 통해 물리적 인코딩 P를 추정하고, 기존의 Graph Neural Network (GNS) 프레임워크를 활용하여 다양한 물리 시스템의 동작을 예측합니다. 이 과정은 비디오 인코더와 GNS의 두 가지 주요 구성 요소로 이루어져 있습니다.

- **Performance Highlights**: 실험 결과, 비디오에서 추출한 인코딩이 효과적으로 시스템의 물리적 속성을 포착하며, 특정 인코딩과 시스템의 운동 사이의 선형적인 관계가 나타났음을 보여줍니다.



### StyleReiser: Stylizing Video With Reinforced Structure Guid (https://arxiv.org/abs/2409.15341)
- **What's New**: 본 논문에서는 StyleReiser라는 예제 기반 비디오 스타일화 방법을 소개합니다. 이 방법은 주어진 키프레임의 스타일을 전체 비디오 시퀀스에 전달하면서 시각적 일관성을 유지합니다. 이전의 키프레임 기반 방법들과 달리, StyleReiser는 지정된 스타일과의 일관성을 고려하고 비디오 시퀀스에 나타나는 새로운 구조적 요소에 대한 충실도를 유지합니다.

- **Technical Details**: StyleReiser는 예제 기반 비디오 스타일화에서 기존 방법들이 구조 보존을 명시적으로 고려하지 않았음을 지적하고, 스타일 가이드를 완화하여 입력 비디오의 새로운 구조적 요소에 대한 충실도를 강조합니다. 이 접근법은 구조 변화에 대한 저항력을 상당히 증가시켜 추가 키프레임을 지정할 필요성을 없앱니다. 특히, 이 기술은 실시간으로 추론을 수행할 수 있어 비디오 통화 같은 인터랙티브한 상황에서도 유용하게 사용할 수 있습니다.

- **Performance Highlights**: StyleReiser는 비디오 스타일화 품질을 크게 향상시킬 수 있으며, 텍스트 기반 비디오 스타일화 방법의 결과를 개선하는 데 도움을 줍니다. 특히, 새로운 구조 요소가 등장할 때 발생할 수 있는 불안정을 억제함으로써 사용자에게 생성된 키프레임을 통해 맞춤 편집을 수행할 수 있게 해줍니다.



### Electrooptical Image Synthesis from SAR Imagery Using Generative Adversarial Networks (https://arxiv.org/abs/2409.15331)
- **What's New**: 본 연구는 Synthetic Aperture Radar (SAR) 이미지를 electro-optical (EO) 이미지로 변환하는 데 사용되는 최첨단 Generative Adversarial Networks (GAN) 모델을 비교하고 평가했습니다. 특히, 개선된 시각적 해석 가능성을 제공하는 새로운 dual-generator architecture를 도입하였습니다.

- **Technical Details**: 연구에서 사용된 GAN 모델에는 Pix2Pix, CycleGan, S-CycleGan 및 partial convolutions를 활용한 새로운 dual-generator GAN이 포함됩니다. 이 모델들은 SAR 이미지를 EO 이미지로 변환하는 과정에서 점진적으로 사실감을 개선하도록 설계되었으며, transformers 아키텍처를 이용하여 더욱 정교한 변환을 가능하게 합니다.

- **Performance Highlights**: 실험 결과, 생성된 EO 이미지들은 실제 EO 이미지와 비교할 때 시각적 충실성과 특징 보존 측면에서 상당한 개선을 보여 SAR 데이터의 해석 가능성을 높였습니다. 또한, 이 기술은 환경 모니터링, 도시 계획 및 군사 정찰과 같은 다양한 응용 분야에서 SAR 데이터의 신속하고 정확한 해석에 기여할 수 있는 잠재력이 있습니다.



### Texture Discrimination via Hilbert Curve Path Based Information Quantifiers (https://arxiv.org/abs/2409.15327)
- **What's New**: 이 논문은 Hilbert curve를 사용하여 이미지로부터 데이터를 추출하고 새로운 texture classification 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 두 단계로 구성됩니다. 첫 번째 단계에서는 두 차원 이미지를 Hilbert curve를 통해 일 차원 시간 시리즈로 변환하고, 두 번째 단계에서는 Bandt & Pompe 기호화를 사용하여 세 가지 정보 이론 quantifiers인 permutation entropy, permutation complexity 및 Fisher 정보 측정을 계산합니다.

- **Performance Highlights**: 이 방법은 Brodatz 이미지 데이터베이스와 같은 일반적으로 사용되는 이미지 데이터셋에서 우수한 성능을 보여주며, 회전, 대칭, 색상 변형에 강한 강건성을 입증하였습니다.



### Deep Transfer Learning for Breast Cancer Classification (https://arxiv.org/abs/2409.15313)
- **What's New**: 이 논문에서는 유방암 이미지를 분류하기 위해 VGG, Vision Transformers (ViT), ResNet 모델을 활용하고, 이 알고리즘들의 성능을 비교 분석하였습니다. 특히, Invasive Ductal Carcinoma (IDC) 암 이미지를 분류하는 데 있어 ResNet-34가 90.40%의 정확도를 기록하며 우수한 성능을 보였습니다.

- **Technical Details**: 본 연구는 Convolutional Neural Networks (CNN) 아키텍처인 VGG, ResNet 및 새로운 Vision Transformers를 사용하여 유방암 데이터를 분석했습니다. 데이터셋은 162개의 전체 슬라이드 이미지로 구성되어 있으며, 이를 50x50 픽셀 크기의 패치로 나누어 학습에 사용했습니다. 이미지 전처리 및 증강(image augmentation) 기술이 적용되어 모델 성능을 향상시켰습니다.

- **Performance Highlights**: ResNet-34는 90.40%의 높은 정확도를 기록하였고, Pretrained VGG-16은 적은 파라미터를 업데이트하기 때문에 더 높은 F1-score를 달성하였습니다. 이러한 결과는 Deep Transfer Learning이 유방암 진단 분야에 큰 도움이 될 것임을 시사합니다.



### Enhancing coastal water body segmentation with Landsat Irish Coastal Segmentation (LICS) datas (https://arxiv.org/abs/2409.15311)
- **What's New**: 아일랜드 해안선의 중대한 변화 감지를 위해 Landsat Irish Coastal Segmentation (LICS) 데이터셋이 새롭게 발표되었습니다. 이 데이터셋은 해양 물체 세분화에 적용할 수 있는 딥러닝 방법 개발을 지원합니다.

- **Technical Details**: LICS 데이터셋은 아일랜드의 다양한 환경 조건과 기후 특정성을 반영하여, 해안선 세분화를 위한 최초의 딥러닝용 세분화 데이터셋입니다. 연구에서는 U-NET 알고리즘이 95.0%의 최고 정확도를 기록하였으나, Normalised Difference Water Index (NDWI)가 평균 97.2%의 정확도로 더 우수한 성능을 보였습니다.

- **Performance Highlights**: 딥러닝을 활용한 해안선 세분화 성능이 기대보다 우수했으나, 더 정확한 훈련 데이터와 침식 측정 방안을 고려하여 성능 개선이 가능할 것이라고 제안합니다. 데이터셋과 코드가 무료로 제공되며, 이는 재현 가능한 연구와 해안 모니터링의 발전을 지원합니다.



### The NGT200 Dataset: Geometric Multi-View Isolated Sign Recognition (https://arxiv.org/abs/2409.15284)
Comments:
          Proceedings of the Geometry-grounded Representation Learning and Generative Modeling Workshop (GRaM) at the 41 st International Conference on Machine Learning, Vienna, Austria. PMLR 251, 2024

- **What's New**: 본 연구에서는 Sign Language Processing (SLP)의 다중 관점 고립 기호 인식(MV-ISR)을 다루며, 3D 인식 및 기하학의 중요성을 강조합니다. 또한 새로운 spatio-temporal multi-view benchmark인 NGT200 데이터셋을 소개합니다.

- **Technical Details**: NGT200 데이터셋은 다중 관점에서 촬영된 고립 기호의 비디오 클립에서 추출한 2D 랜드마크를 포함합니다. 이 데이터셋은 3D-LEX 데이터셋과 함께 사용되어 각 기호에 대한 3D Ground Truth를 제공합니다. 이 연구는 SE(2) 등변 모델을 활용하여 MV-ISR의 성능을 향상시킬 수 있음을 보여줍니다.

- **Performance Highlights**: MV-ISR은 SE(2) 등변 모델을 활용하여 성능이 기준선 대비 8%-22% 향상되었습니다. 이를 통해 기호 인식 시스템의 실용성을 높일 수 있는 방법을 제시합니다.



### Gen2Act: Human Video Generation in Novel Scenarios enables Generalizable Robot Manipulation (https://arxiv.org/abs/2409.16283)
Comments:
          Preprint. Under Review

- **What's New**: 이 논문은 웹 데이터에서 생성한 인간 비디오를 통해 로봇 조작 정책이 새로운 물체 및 모션에 일반화될 수 있도록 하는 방법을 제시합니다. Gen2Act라는 접근 방식을 통해 로봇 정책을 비디오 생성 모델에 조건화하여 무작위 작업을 수행하는 프레임워크를 사용합니다.

- **Technical Details**: Gen2Act는 언어 조건조작을 제로샷(Zero-shot) 인간 비디오 생성과 로봇 행동으로의 변환을 포함하는 폐쇄 루프(policy) 형태로 구현되어 있습니다. 이를 위해 비디오 예측 모델을 사용하여 주어진 작업 설명에 따라 인간 비디오를 생성하고, 생성된 비디오에 조건화된 로봇 동작을 추론하는 모델을 학습시킵니다.

- **Performance Highlights**: Gen2Act는 로봇 상호작용 데이터가 부족한 상황에서도 새로운 물체 유형과 모션 유형을 Manipulation 하는 데 평균 약 30% 높은 성공률을 보여주었습니다. 또한 연속적인 작업인 커피 만들기와 같은 긴 활동 수행에도 적용 가능합니다.



### Compressed Depth Map Super-Resolution and Restoration: AIM 2024 Challenge Results (https://arxiv.org/abs/2409.16277)
Comments:
          ECCV 2024 - Advances in Image Manipulation (AIM)

- **What's New**: 이 논문은 증강 현실(AR) 및 가상 현실(VR) 응용 프로그램을 위한 깊이 정보의 효율적 처리를 강조합니다. 특히, 압축된 데이터로부터 고품질 깊이 맵을 reconstruction하는 혁신적인 depth upsampling 기술 개발에 중점을 두고 있습니다.

- **Technical Details**: 깊이 맵은 객체 인식(object recognition), 장면 이해(scene understanding), 제스처 추적(gesture tracking) 등에 필수적인 요소입니다. 다루는 기술적 측면으로는 depth compression, depth completion 및 depth densification이 있습니다. 복잡한 degradations 문제를 해결하기 위해 U-Net 기반 아키텍처를 활용한 단순하고 효과적인 네트워크를 제안합니다.

- **Performance Highlights**: 전통적인 Bicubic interpolation이 기대한 성능을 보이지 않으며, 최근의 상위 3개 방법(UM-IT, DAS-Depth, DINOv2 + ControlNet)은 인코더-디코더 구조를 사용하여 HR RGB 이미지 및 LR 깊이 맵을 조건화하여 HR 깊이 맵을 예측합니다.



### Fine-Tuning is Fine, if Calibrated (https://arxiv.org/abs/2409.16223)
Comments:
          The first three authors contribute equally

- **What's New**: 본 연구에서는 사전 학습된 모델(Foundation Model)에서 세부 클래스를 대상으로 한 파인튜닝(fine-tuning) 중 발생하는 문제를 체계적으로 분석합니다. 연구 결과, 파인튜닝된 모델이 정확도가 하락하는 주된 원인이 로짓 스케일의 불일치임을 밝혀내고, 이러한 문제를 해결하기 위해 단순한 후처리(calibration) 방법을 제안합니다.

- **Technical Details**: 사전 학습된 분류기를 세부 클래스에 맞춰 파인튜닝하면 일반적인 정확도가 손상되지만, 이 논문에서는 파인튜닝 후에도 특징 추출기(feature extractor)의 성능 수치가 개선됨을 확인하였습니다. NCM(Nearest Class Mean) 분류기를 통해 특징 품질을 평가한 결과, 파인튜닝 동안 실종된 클래스에 대한 특징 분리가 향상되었습니다. 로짓 스케일의 불일치가 피해를 주며, 이 문제는 후처리 방법으로 보완할 수 있습니다.

- **Performance Highlights**: 다수의 벤치마크(예: ImageNet)에서 후처리 보정(calibration)을 통해 파인튜닝된 모델의 성능이 현저히 향상되었으며, 이는 강력한 기준선 모델조차 능가했습니다. 연구 결과는 간단한 파라미터 조정만으로도 유의미한 성과를 달성할 수 있음을 보여줍니다.



### Tiny Robotics Dataset and Benchmark for Continual Object Detection (https://arxiv.org/abs/2409.16215)
Comments:
          Paper under review

- **What's New**: 본 논문에서는 Tiny Robotics 분야에서 시스템의 지속적 학습(continual learning) 능력을 평가하기 위한 새로운 벤치마크와 Tiny Robotics Object Detection (TiROD)라는 데이터 세트를 소개합니다. 이 데이터 세트는 소형 모바일 로봇을 이용해 수집되었으며, 다양한 도메인과 객체 클래스에서 객체 탐지기의 적응력을 테스트하도록 설계되었습니다.

- **Technical Details**: 제안된 TiROD 데이터 세트는 5개의 서로 다른 환경(실내 및 실외)에서 13개의 객체 클래스를 캡처하여 다양한 객체 탐지기의 성능을 평가하는 데 사용됩니다. 본 연구는 Nanodet과 Yolov8라는 두 대의 최첨단 객체 탐지기를 지속적 학습 전략과 결합하여 평가하며, 그들의 강점과 한계에 대한 통찰을 제공합니다.

- **Performance Highlights**: TiROD의 벤치마크 결과는 Tiny Robotics에서 강력하고 효율적인 객체 탐지 시스템의 발전을 위해 해결해야 할 주요 도전과제를 나타냅니다. 이 논문은 또한 이 분야의 지속적인 발전을 촉진하기 위해 모든 접근 방식의 소스 코드를 공개합니다.



### Upper-body free-breathing Magnetic Resonance Fingerprinting applied to the quantification of water T1 and fat fraction (https://arxiv.org/abs/2409.16200)
Comments:
          19 pages, 9 figures, 3 tables

- **What's New**: 이 연구는 모션 보정된 (MoCo) MRF T1-FF 접근법을 제안하여 폐부위에서 발생하는 호흡 모션 효과를 줄이고, 이를 통해 정확한 MRI 매개변수 맵을 재구성하는 새로운 방법을 보여줍니다.

- **Technical Details**: 제안된 접근법은 최적화된 초기 모션 스캔을 사용하여 모션 필드를 추정하고, 이를 기반으로 MRF 데이터를 수정하여 FF 및 T1이 보정된 파라메트릭 맵을 재구성합니다. 이 방법은 호흡 근육과 같은 희귀한 부위에서도 적용 가능성을 높이며, 기존 MRF의 한계를 극복합니다.

- **Performance Highlights**: 검증 결과, 최소한의 모션 영향을 받은 지역에서 MoCo 재구성이 비보정 재구성과 큰 차이를 보이지 않았으며, 호흡 근육 같은 모션의 영향을 많이 받는 영역에서는 모션 블러링과 아티팩트를 유의미하게 감소시켰습니다. 또한, 횡격막이 모션 보정 후에도 선명하게 나타났습니다.



### Efficient Motion Prediction: A Lightweight & Accurate Trajectory Prediction Model With Fast Training and Inference Speed (https://arxiv.org/abs/2409.16154)
Comments:
          Accepted to IROS 2024

- **What's New**: 본 논문에서는 자율 주행을 위한 새로운 효율적인 모션 예측 모델(EMP)을 제안하며, 이는 단일 GPU에서 몇 시간의 훈련으로도 경쟁력 있는 결과를 도출해냅니다.

- **Technical Details**: EMP는 표준 transformer 블록을 기반으로 하여 에이전트의 이력, 도로 형태 및 장면 정보를 인코딩하고, 미래의 경로 및 신뢰도 점수를 디코딩하기 위해 단순한 다층 퍼셉트론 기반 디코더와 복잡한 transformer 기반 방법을 비교합니다.

- **Performance Highlights**: 이 모델은 AV2 데이터셋에서 우수한 성능을 보이며, 훈련 속도가 약 100% 빨라졌으며, 매우 효율적인 추론 속도를 제공합니다.



### CloudTrack: Scalable UAV Tracking with Cloud Semantics (https://arxiv.org/abs/2409.16111)
Comments:
          7 pages, 3 figures

- **What's New**: 본 논문에서는 UAV(무인 항공기) 하드웨어의 한계를 극복하기 위해 특별히 설계된 의미적으로 조건화된 개방 어휘(open vocabulary) 객체 추적 방법을 제안합니다.

- **Technical Details**: 제안된 방법은Missing person의 언어적 설명, 예를 들면 셔츠의 색상 등을 기반으로 작동할 수 있으며, 특정 훈련 없이 미션을 수행할 수 있습니다. 또한, 잠재적으로 움직이는 대상을 효율적으로 추적할 수 있는 장점이 있습니다.

- **Performance Highlights**: 실험 결과는 제안된 방법의 다재다능함과 효과성을 입증합니다.



### Multi-Model Ensemble Approach for Accurate Bi-Atrial Segmentation in LGE-MRI of Atrial Fibrillation Patients (https://arxiv.org/abs/2409.16083)
- **What's New**: 이 논문은 심방 세동(Atrial Fibrillation, AF)에 대한 이해를 높이고, AF 환자들의 절제술(ablation) 성공 가능성을 예측하는 데 필요한 심방(fibrosis 및 scarring) 이미징의 중요성을 강조합니다. 특히, 다중 센터의 3D LGE-MRI를 이용한 다중 클래스 심방 분할(Multi-class Bi-Atrial Segmentation, MBAS) 문제를 다룹니다.

- **Technical Details**: 이 연구는 Unet, ResNet, EfficientNet, VGG와 같은 여러 머신 러닝 모델을 통합하여 LGE-MRI 데이터에서 자동 심방 분할을 수행하는 앙상블 모델을 제안합니다. 모델은 Dice Similarity Coefficient (DSC) 및 95% Hausdorff distance (HD95)을 사용하여 평가되었습니다.

- **Performance Highlights**: 내부 테스트 데이터셋에서 모델은 DSC 88.41%, 98.48%, 98.45%와 HD95 1.07, 0.95, 0.64라는 성과를 달성하여 분할 정확도가 향상되었음을 보여줍니다. 이는 AF에 대한 이해를 지지하고 보다 타겟팅된 절제 전략 개발에 기여합니다.



### Enhanced Unsupervised Image-to-Image Translation Using Contrastive Learning and Histogram of Oriented Gradients (https://arxiv.org/abs/2409.16042)
Comments:
          Critical Errors in Data or Analysis

- **What's New**: 이 논문은 이미지-투-이미지 전환 분야에서, 대칭이 아닌(contrastive) 데이터 쌍을 초월하여 이미지의 핵심 콘텐츠와 구조를 유지하면서 변환하는 새로운 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 Contrastive Unpaired Translation (CUT) 모델을 기반으로 하며, Histogram of Oriented Gradients (HOG) 특징을 통합하여 세미틱 레이블 없이도 이미지의 세미틱 구조를 보존할 수 있도록 합니다. HOG 특징 간의 손실(loss)을 최소화하여 이미지 품질을 향상시킵니다.

- **Performance Highlights**: GTA5 데이터셋의 합성 게임 환경을 도시 풍경(cityscapes) 데이터셋의 현실적인 장면으로 변환하는 실험에서, 환상(hallucinations)을 줄이고 이미지 품질을 향상시키는 데 있어 중요한 개선을 보였습니다.



### Deep chroma compression of tone-mapped images (https://arxiv.org/abs/2409.16032)
- **What's New**: 본 논문에서는 HDR(High Dynamic Range) 톤 매핑 이미지의 색상 압축을 위한 생성적 적대 신경망(GAN)을 제안합니다. 이는 정확한 색상 표현을 위해 이미지의 색조 속성을 고려한 손실 함수를 설계하였습니다.

- **Technical Details**: 제안된 모델은 널리 사용되는 모든 톤 매핑 연산자(TMO)와 호환되며, 색상 정확도를 향상시키기 위해 GAN 손실과 L1 손실, 색조 기반 손실을 결합한 새로운 손실 함수를 사용합니다.

- **Performance Highlights**: 모델은 기존의 색상 압축 방법에 비해 색상 정확도에서 뛰어난 성능을 보이며, 실시간 성능을 달성하여 제한된 계산 자원을 가진 장치에 적합합니다.



### VascX Models: Model Ensembles for Retinal Vascular Analysis from Color Fundus Images (https://arxiv.org/abs/2409.16016)
- **What's New**: 본 논문에서는 색 망막 사진(Color Fundus Images, CFI)에서 망막 혈관 구조를 분석하기 위한 VascX 모델 세트를 소개합니다. 이 모델들은 다양한 장치로부터의 이미지 품질과 다양한 병리학적 조건에서 강력한 성능을 보여줍니다.

- **Technical Details**: VascX 모델은 혈관(vessel), 동맥-정맥(artery-vein), 디스크(segmentation에 대한) 세분화와 중심와(fovea) 위치 지정에 대한 모델을 제공합니다. 이 모델들은 Rotterdam Study에서 수집된 공공 데이터세트와 전문가 주석을 통해 구축되었습니다.

- **Performance Highlights**: 우리의 모델은 다양한 품질의 CFI에서 기존 시스템에 비해 우수한 세분화(segmentation) 성능을 보여주었으며, 특히 중간 품질의 이미지에서 동맥-정맥 및 디스크 세분화 성능의 현저한 향상을 보였습니다. VascX 모델은 인력의 판단보다 높은 정밀도로 혈관을 세분화할 수 있습니다.



### DepMamba: Progressive Fusion Mamba for Multimodal Depression Detection (https://arxiv.org/abs/2409.15936)
- **What's New**: DepMamba라는 새로운 모델을 제안하여, 우울증 검출에 필요한 효율적이고 진보적인 오디오-비주얼 융합 방식으로 접근합니다.

- **Technical Details**: Hierarchy를 기반으로 한 문맥 모델링과 진보적인 다중모달 융합을 특징으로 하며, CNN과 Mamba 블록을 이용하여 긴 시퀀스에서 로컬부터 글로벌 특징을 추출합니다. 또한, 다중모달 협력 State Space Model (SSM)을 이용하여 각 모달리티의 상호 및 개별 정보를 추출합니다.

- **Performance Highlights**: 실험 결과, DepMamba는 기존 최첨단 모델들에 비해 정확성과 효율성에서 우수한 성능을 보였습니다.



### FedRepOpt: Gradient Re-parametrized Optimizers in Federated Learning (https://arxiv.org/abs/2409.15898)
- **What's New**: 이 논문에서는 Federated Learning(FL) 환경에서 머신 러닝 모델의 훈련을 위한 새로운 방법론인 FedRepOpt를 제안합니다. FedRepOpt는 복잡한 모델과 유사한 성능을 내는 간단한 로컬 모델을 학습할 수 있도록 하는 gradient re-parameterization 기법을 활용합니다.

- **Technical Details**: FedRepOpt는 VGG 스타일과 Ghost 스타일 모델에서의 FL 환경에 적합한 optimizer로, 복잡한 모델에서 추출된 모델 특화 하이퍼파라미터에 따라 optimizer의 gradient를 수정합니다. 이를 통해 FedRepOpt 기반 모델이 RepGhost 스타일 및 RepVGG 스타일 네트워크에 비해 성능이 각각 16.7% 및 11.4% 향상되었음을 실험적으로 입증하였습니다.

- **Performance Highlights**: FedRepOpt를 사용하는 모델은 복잡한 구조에 비해 11.7% 및 57.4%의 빠른 수렴 시간을 달성하며, FL 환경에서 높은 성능과 효율성을 보여줍니다. 또한, FedRepOpt는 저사양 및 고사양 기기에서 유효한 성능을 유지하면서도 비슷한 학습 패턴을 보입니다.



### Investigating Gender Bias in Lymph-node Segmentation with Anatomical Priors (https://arxiv.org/abs/2409.15888)
- **What's New**: 이번 연구는 방사선 치료에서의 임상 목표 부피(CTV) 세분화를 개선하기 위해 인체 해부학적 사전 지식(Anatomical Prior, AP)을 활용한 새로운 접근 방식을 소개합니다. 특히 여성 환자에서의 성별 편향(gender bias)을 완화하는 효과를 연구하였습니다.

- **Technical Details**: 연구에서는 45개의 전신 CT 3D 볼륨 및 여러 구조(예: OARs)를 세분화하고 이를 여러 가지 입력 방식을 통해 세분화 모델에 적용하였습니다. nnU-Net 프레임워크를 사용하여 데이터의 특성에 따라 모델을 조정했습니다. 평가 지표로는 Dice Score(DSC)와 Hausdorff Distance(HD)를 사용했습니다.

- **Performance Highlights**: 해부학적 사전 지식을 사용하여 CTV 세분화의 품질이 향상되었으며, 특히 복부 지역에서 성별 편향이 감소하였습니다. 이러한 접근은 자동 세분화에서의 성별 편향을 줄이는 가능성을 보여주었습니다.



### Unsupervised dMRI Artifact Detection via Angular Resolution Enhancement and Cycle Consistency Learning (https://arxiv.org/abs/2409.15883)
Comments:
          Accepted to AJCAI2024, dMRI, Unsupervised artifact detection, Angular resolution enhancement, Cycle consistency

- **What's New**: 이 연구에서는 노코멘트 학습(unsupervised learning) 기반의 새로운 dMRI 아티팩트 검출 도구 UdAD-AC를 제안하였습니다. 이 도구는 앵글 해상도 향상(angular resolution enhancement)과 사이클 일관성 학습(cycle consistency learning)을 활용하여 아티팩트 없는 dMRI 데이터를 학습하며, 아티팩트를 포함한 데이터를 자동으로 검출할 수 있습니다.

- **Technical Details**: UdAD-AC는 아티팩트 없는 dMRI 볼륨을 앵글 해상도 향상된 분수 이방성(FA) 맵으로 변환하고, 사이클 일관성 학습을 통해 아티팩트 검출 시 일관성을 유지합니다. 테스트 단계에서는 아티팩트가 포함된 dMRI 데이터에 대해 설계된 신뢰도 점수(confidence score)를 사용하여 아티팩트를 검출합니다.

- **Performance Highlights**: 실험 결과, UdAD-AC는 광범위한 공공 데이터셋에서 경쟁 방법들에 비해 우수한 성능을 보여주었으며, 아티팩트 검출 정확도가 가장 높았습니다. 이는 dMRI 연구의 신뢰성과 생산성을 높이는 데 큰 기여를 할 것입니다.



### Aided design of bridge aesthetics based on Stable Diffusion fine-tuning (https://arxiv.org/abs/2409.15812)
Comments:
          10 pages, 13 figures

- **What's New**: 이번 논문에서는 Stable Diffusion의 세부 조정(fine-tuning) 기법을 활용하여 새로운 교량(bridge) 디자인 혁신을 돕는 방법을 제시합니다.

- **Technical Details**: 교량의 실제 사진 데이터셋을 구축하고, Textual Inversion, Dreambooth, Hypernetwork, Lora의 네 가지 방법을 사용하여 Stable Diffusion을 세부 조정합니다. 이 기술들은 데이터셋 이미지의 주요 특성을 포착하여 Stable Diffusion의 개인화(customization)를 실현합니다.

- **Performance Highlights**: 세부 조정된 모델은 다양한 혁신적인 새로운 교량 유형을 생성할 수 있으며, 이는 인간 디자이너에게 풍부한 영감을 제공합니다. 이 기술은 인간 디자이너의 창의력을 촉진하는 엔진(engine of creativity)으로 작용할 수 있습니다.



### ManiNeg: Manifestation-guided Multimodal Pretraining for Mammography Classification (https://arxiv.org/abs/2409.15745)
- **What's New**: 이 논문에서는 유방암 스크리닝 및 분석을 위한 효과적인 방법으로 관심을 끌고 있는 대조 학습(Contrastive Learning)의 개선된 접근법인 ManiNeg을 소개합니다. 특히 유방 조직의 특성을 반영하여 강력한 부정 샘플을 선택하는 새로운 방법론이 등장했습니다.

- **Technical Details**: ManiNeg은 발생 현상(Manifestation)을 근거로 하여 부정 샘플을 효과적으로 선정하는 방법을 제안합니다. 발생 현상은 유병의 증상 및 징후를 의미하며, 이는 하드 부정 샘플 선택에 있어 지식 기반의 강력한 자료를 제공합니다. 이 방법은 모델 최적화에 대한 불변성을 갖고 있어 효율적인 샘플링을 가능하게 합니다.

- **Performance Highlights**: 실험 결과 ManiNeg은 단일 모달과 다중 모달 환경 모두에서 표현 학습을 크게 향상시키는 것으로 나타났습니다. MVKL 데이터 세트에서 평가된 결과, ManiNeg은 다양한 데이터셋에서 일반화 능력을 보여주며 성능을 개선시키는 데 기여했습니다.



### ViKL: A Mammography Interpretation Framework via Multimodal Aggregation of Visual-knowledge-linguistic Features (https://arxiv.org/abs/2409.15744)
- **What's New**: 이 논문에서는 MVKL이라는 첫 번째 멀티모달(multi-modal) 유방 촬영술(mammography) 데이터셋을 소개하며, 시각적 정보 외에도 임상 보고서와 방사선학적 특성과 같은 다양한 특성을 통합하여 보다 해석 가능하고 일반화 가능한 표현 방식의 필요성을 강조하고 있습니다.

- **Technical Details**: MVKL 데이터셋은 다중 시점(multi-view) 이미지를 포함하며, ViKL(framework) 모델은 시각적(Visual), 지식 기반(Knowledge), 언어적(Linguistic) 특성을 조화롭게 통합하여 대조 학습(triple contrastive learning) 방식을 사용하여 양질의 표현 공간을 생성합니다. 이 모델은 병리학적 라벨 없이 쌍(pairing) 정보를 활용하며, 새로운 힘든 부정 샘플 선택 메커니즘인 ManiNeg를 제안하여 전통적인 방법의 한계를 극복합니다.

- **Performance Highlights**: ViKL은 시각적 사전 학습과 임상 보고서 및 상징적 정보를 통합하여 병리학적 분류를 현저히 개선하고, 다양한 데이터셋 간 전이 가능성을 보여주며, 미세 병변을 검출할 수 있는 능력을 갖추었습니다. 실험 결과는 MVKL 데이터셋을 통해 이루어져, 불균형 문제를 최소화하고 효율적인 다중 모달 구조를 갖춘 것을 확인했습니다.



### Real-Time Pedestrian Detection on IoT Edge Devices: A Lightweight Deep Learning Approach (https://arxiv.org/abs/2409.15740)
Comments:
          10 pages, 3 tables, 12 figures, article submitted to IEEE for possible publication

- **What's New**: 이번 연구는 경량화된 딥러닝(Deep Learning) 모델을 인공지능 사물인터넷(Artificial Intelligence of Things, AIoT) 에지 기기에 구현하여 보행자 탐지를 실시간으로 수행하는 방안을 제안합니다. 이를 위해 최적화된 유 아운리 룩 원(You Only Look Once, YOLO) 기반의 딥러닝 모델을 개발하였습니다.

- **Technical Details**: 연구에서는 에지 서버(edge server)의 한계인 제한된 처리 능력을 극복하기 위해 압축된 심층 신경망(Deep Neural Network, DNN) 모델을 활용합니다. 해당 경량화된 모델을 Nvidia Jetson Nano에 배포하여 실시간 보행자 탐지 테스트를 실시하였으며, 결과적으로 147 밀리세컨드의 빠른 추론 속도와 78%의 정확도를 달성했습니다.

- **Performance Highlights**: 최적화된 YOLO 모델은 2.3 프레임 매 초에 78%의 정확도로 실시간 보행자 탐지를 수행하였으며, 이는 기존 모델보다 상당한 개선을 나타냅니다.



### Autonomous Hiking Trail Navigation via Semantic Segmentation and Geometric Analysis (https://arxiv.org/abs/2409.15671)
- **What's New**: 논문에서는 자율 하이킹 경로 내비게이션을 위한 새로운 접근 방식을 소개하며, 이 방식은 경로 준수와 필요 시 비경로 이동을 조화롭게 할 수 있는 기술을 개발하였습니다. Traversability Analysis 모듈은 카메라 이미지의 의미론적 데이터와 LiDAR의 기하학적 정보를 통합하여 주변 지형에 대한 포괄적인 이해를 제공합니다.

- **Technical Details**: 이 연구에서는 하이킹 경로의 탐색성을 평가하기 위해 두 가지 주요 모듈을 개발하였습니다. 첫 번째는 기하학적 및 의미적 정보를 결합하는 Traversability 분석 모듈이고, 두 번째는 경량 로봇이 경로를 안전하게 탐색할 수 있도록 중간 목표를 선택하는 Waypoint selection 모듈입니다. 이 시스템은 LiDAR 및 스테레오 카메라로부터 수집한 데이터를 기반으로 실시간으로 경로의 탐색 가능성을 평가합니다.

- **Performance Highlights**: West Virginia University Core Arboretum에서 실험을 통해 방법론의 효과가 검증되었으며, 시뮬레이션을 통한 다양한 가중치 테스트를 통해 의미적 및 기하학적 정보 간의 균형을 평가하였습니다. 이 연구는 자율 로봇이 하이킹 경로에서 안전하게 탐색할 수 있도록 하는 가능성을 보여주었습니다.



### Personalized Federated Learning via Backbone Self-Distillation (https://arxiv.org/abs/2409.15636)
Comments:
          Pubished in ACM MMAsia 2023

- **What's New**: 이 논문에서는 개인화된 연합 학습을 촉진하기 위해 백본(Backbone) 자기 증류(Self-Distillation) 접근 방식을 제안합니다. 각 클라이언트가 로컬 모델을 훈련하고 오직 백본 가중치만 서버에 전송하는 방식을 사용합니다.

- **Technical Details**: 각 클라이언트 모델은 공유 백본과 개인 헤드(Head)로 나뉘어 있으며, 서버는 백본 가중치만 집계하여 글로벌 백본을 구축합니다. 그런 다음 각 클라이언트는 글로벌 백본을 교사(Teacher)로 사용하여 로컬 백본을 업데이트 합니다.

- **Performance Highlights**: 12개의 최신 접근 방식과 비교한 실험 결과, 제안된 방법이 성능을 크게 향상시키며, 글로벌 지식 전이(Global Knowledge Transfer)를 통해 클라이언트 모델의 개인화를 효과적으로 지원함을 보여주었습니다.



### MapEx: Indoor Structure Exploration with Probabilistic Information Gain from Global Map Predictions (https://arxiv.org/abs/2409.15590)
Comments:
          7 pages

- **What's New**: 본 연구에서는 구조화된 실내 환경을 탐색하는 로봇을 위한 새로운 탐색 프레임워크인 MapEx를 제안합니다. MapEx는 예측된 지도를 사용해 확률적 센서 모델을 형성하여 정보 이득(metrics of information gain)을 추정합니다. 특히, 다양한 예측된 지도를 생성하고 계산된 변동성과 추정된 가시 영역을 고려하여 탐색 계획을 수립합니다.

- **Technical Details**: MapEx는 관찰된 정보를 기반으로 여러 개의 예측된 지도를 생성하며, 여기서 평균 및 분산 지도를 계산합니다. 이 프레임워크는 여러 예측된 지도의 변동성과 가시 영역을 고려하여 주어진 관점(viewpoint)의 정보 이득을 계산합니다. 또한, MapEx는 LiDAR 센서를 사용하여 환경을 탐색하며, 이전의 탐사 방식과 비교하여 더 효율적인 정보를 얻을 수 있습니다.

- **Performance Highlights**: KTH 데이터셋을 이용한 실험에서, MapEx는 기존의 지도 예측 기반 탐색 방법보다 평균 12.4% 개선된 성능을 보였고, 최근접 전선(frontier) 접근법보다 25.4% 향상된 결과를 달성했습니다.



### Mixing Data-driven and Geometric Models for Satellite Docking Port State Estimation using an RGB or Event Camera (https://arxiv.org/abs/2409.15581)
Comments:
          Submitted to IEEE ICRA 2025

- **What's New**: 이 논문은 자동화된 위성 도킹 포트 탐지 및 상태 추정을 위한 파이프라인을 제안하며, 이는 모노큘러 비전 데이터(standard RGB sensing 또는 event camera)를 활용하여 비용을 절감하고 궤도 쓰레기를 줄이는 데 기여합니다.

- **Technical Details**: 제안된 파이프라인은 Lockheed Martin Mission Augmentation Port (LM-MAP)를 목표로 하며, 단순 기하학적 모델과 데이터 기반 기법을 조합하여 데이터 효율적인 경량 추정을 실현합니다. 이 방법은 RANndom SAmple Consensus (RANSAC) 접근 방식을 사용하여 포트의 6-자유도(DoF) 위치 추정을 가능하게 합니다.

- **Performance Highlights**: 실험을 통해 RGB와 event camera 데이터 모두에 대해 알고리즘의 성능을 비교하였으며, 두 가지 데이터 소스를 모두 독립적으로 처리할 수 있는 유연성을 갖추고 있습니다. 이는 위성 유지 관리 및 궤도 클러터 방지에 기여할 것으로 기대됩니다.



### A Novel Framework for the Automated Characterization of Gram-Stained Blood Culture Slides Using a Large-Scale Vision Transformer (https://arxiv.org/abs/2409.15546)
- **What's New**: 본 연구에서는 Gram 염색을 이용한 전체 슬라이드 이미지 (WSI) 분석을 위한 인공지능 보조 특성화 프레임워크를 새롭게 소개합니다. 이는 혈류 감염 진단을 위한 중요한 초기 데이터를 제공합니다.

- **Technical Details**: 이 모델은 transformer 기반으로 개발되어 이전의 convolutional neural network (CNN) 방법에 비해 대규모 데이터 세트에 대해 더욱 확장 가능합니다. 수동으로 패치 레벨 주석을 필요로 하지 않기 때문입니다. 본 연구에서는 Dartmouth-Hitchcock Medical Center에서 수집한 대규모 Gram 염색 데이터 세트를 사용하여 다섯 가지 주요 Gram 염색 WSI 카테고리를 분류했습니다.

- **Performance Highlights**: 모델의 분류 정확도는 0.858 (95% CI: 0.805, 0.905)이며, AUC는 0.952 (95% CI: 0.922, 0.976)로, 475개 슬라이드를 사용한 다섯 겹 중첩 교차 검증을 통해 확인되었습니다. 또한, 추가적인 파인튜닝 없이도 외부 데이터 세트에서도 강력한 성능을 달성하였습니다.



### Speech2rtMRI: Speech-Guided Diffusion Model for Real-time MRI Video of the Vocal Tract during Speech (https://arxiv.org/abs/2409.15525)
Comments:
          4 pages

- **What's New**: 이 연구는 Magnetic Resonance Imaging (MRI) 비디오를 기반으로 말하는 동안의 외부 기관(articulator) 모션을 시각적으로 표현하기 위한 데이터 기반 방법을 소개하고 있습니다. 이 방법은 사전 학습된 스피치 모델을 활용하여 일반화된 시각적 도메인을 구축하고, Speech-to-video diffusion model을 통해 새로운 데이터에 적용할 수 있습니다.

- **Technical Details**: 연구는 Speech-Conditioned Diffusion 모델인 Speech2rtMRI를 제안하여, 실시간 MRI 비디오에서 발음 운동을 합성합니다. 모델은 원시 오디오와 기관 운동 비디오 세트를 동기화하여 학습하며, Pre-trained speech model(WavLM 등)을 사용하여 비디오 생성을 위한 임베딩을 보다 효과적으로 제공합니다. 훈련과 샘플링 두 단계로 이루어진 이 접근법은 3D Diffusion U-Net을 통해 시각적 데이터를 생성합니다.

- **Performance Highlights**: 실험 결과, WavLM 모델이 전체적으로 가장 높은 일반화 점수를 기록했으며, 생성된 비디오에서 자주 발생하는 부자연스러운 혀 운동과 비디오 왜곡 현상이 있는 것으로 나타났습니다. 인간 평가에서는 생성된 MRI 비디오의 관련성, 진정성, 그리고 제한 사항이 평가되었습니다.



### MATCH POLICY: A Simple Pipeline from Point Cloud Registration to Manipulation Policies (https://arxiv.org/abs/2409.15517)
Comments:
          project url: this https URL

- **What's New**: MATCH POLICY는 로봇의 다양한 조작 작업에서 높은 정확도를 요구하는 픽-플레이스(pick and place) 작업을 해결하는 새로운 파이프라인을 제안합니다. 기존 방법과 달리 MATCH POLICY는 작동 예시를 기반으로 목표를 등록하는 점에 초점을 맞추어 학습 없이 조작 정책을 실현할 수 있는 간단한 방법입니다.

- **Technical Details**: MATCH POLICY는 피크 및 플레이스(pick and place) 대상으로 지정된 점 구름(point cloud) 등록(registration) 작업으로 로봇 조작 정책 학습을전환하는 것을 특징으로 합니다. 이 방법은 RANSAC 및 ICP와 같은 최적화 기반 방법을 활용하여 이전 작업에서 수집한 데모를 활용하여 픽-플레이스 정책을 즉시 생성합니다.

- **Performance Highlights**: 이 방법은 RLBench 벤치마크에서 여러 강력한 기준선과 비교하여 다양한 작업에서 최첨단 성능을 보이며, 오직 하나의 데모로도 신뢰할 수 있는 성능을 달성할 수 있습니다. 또한 다양한 카메라 설정에서도 높은 적응력을 보이며, 장기 작업 및 관절 객체에 대해서도 효과적으로 작동합니다.



### Bayesian computation with generative diffusion models by Multilevel Monte Carlo (https://arxiv.org/abs/2409.15511)
Comments:
          13 images

- **What's New**: 본 논문에서는 Bayesian computation에서 diffusion models (확산 모델)의 계산 비용을 크게 줄이는 Multilevel Monte Carlo (MLMC) 전략을 제안하고 있습니다. 이는 다양한 정확도를 가진 모델을 결합하여 비용-정확도 트레이드오프를 활용함으로써 달성됩니다.

- **Technical Details**: MLMC 접근법은 Bayesian 통계 프레임워크 내에서 고차원 양 x∈ℝ^n을 관측 데이터 y∈ℝ^m로부터 추정함으로써, posterior distribution (후방 분포)을 생성하는 데 사용됩니다. 이는 관측 모델의 결정론적 측면을 인코딩하는 선형 Gaussian 모델을 포함하며, 본 연구는 다양한 기계 학습 기술을 통해 이러한 모델의 효율성을 향상시키는 방법을 설명합니다.

- **Performance Highlights**: 이 제안된 MLMC 접근법은 세 가지 전형적인 계산 영상 문제에서 검증되었으며, 기존의 Monte Carlo 평균 방식에 비해 계산 비용이 4배에서 8배까지 감소하는 결과를 보였습니다.



### Adenocarcinoma Segmentation Using Pre-trained Swin-UNet with Parallel Cross-Attention for Multi-Domain Imaging (https://arxiv.org/abs/2409.15501)
Comments:
          6 pages 2 figures

- **What's New**: 이 논문에서는 다양한 장기와 스캐너 간의 선종성(adenocarcinoma) 세분화를 위한 새로운 프레임워크를 제안합니다. 이 프레임워크는 Swin-UNet 아키텍처와 병렬 교차 주의 모듈을 결합하여 도메인 변동과 형태적 변화를 고려합니다.

- **Technical Details**: 이 프레임워크는 사전 훈련된 인코더(encoder)와 Swin-UNet 구조로 구성되어 있으며, 다중 스케일 특징(feature)을 추출할 수 있는 장점을 가지고 있습니다. 인코더는 각각 다른 장기에서의 세분화 병목을 방지하기 위해 이미지넷(ImageNet) 데이터셋에서 사전 훈련되었습니다. 프레임워크는 두 개의 주요 작업, 즉 Cross-Organ and Cross-Scanner Adenocarcinoma Segmentation에 대해 평가되었습니다.

- **Performance Highlights**: 제안된 모델은 Cross-Organ 및 Cross-Scanner 세분화 작업에서 각각 0.7469 및 0.7597의 점수를 기록하여 다양한 조건에서도 일관된 성능을 보여주었습니다. 특히, 모델의 세분화 결과는 해부학적 변동성이 있는 상태에서도 종양 경계를 정확히 예측하는 데 강점을 보였으며, 이는 강력한 특성 추출 및 전이 학습(transfer learning) 능력 덕분으로 분석됩니다.



### Autonomous Exploration and Semantic Updating of Large-Scale Indoor Environments with Mobile Robots (https://arxiv.org/abs/2409.15493)
Comments:
          7 pages, 7 figures. Project page is available at this https URL

- **What's New**: 본 연구에서는 모바일 로봇이 자율적으로 미지의 환경을 탐색하고, 해당 환경의 의미 있는 지도를 생성 및 업데이트할 수 있는 새로운 로봇 시스템을 소개합니다. 이 시스템은 LiDAR 스캐너와 RGB-D 카메라를 활용하여 2D occupancy grid mapping과 객체 인식을 수행합니다.

- **Technical Details**: 우리는 2D occupancy grid map과 객체 의미 정보를 결합한 새로운 의미적 맵 표현 방식을 도입하였습니다. 이 표현 방식을 통해 topological map의 노드를 추가하거나 삭제하여 쉽게 의미를 업데이트할 수 있습니다. 또한, 로봇은 

- LiDAR를 통해 환경의 2D occupancy grid map을 생성하고
- 탐색 경로를 계획하여 따라가며
- 실시간으로 RGB-D 카메라로 객체를 감지해 2D occupancy grid에 추가하는 방식으로 semantic map을 생성합니다.

- **Performance Highlights**: 우리는 이 시스템을 텍사스 대학교의 ECSS 빌딩 4층에서 테스트하였으며, 로봇은 93m x 90m의 공간을 탐색하여 효율적으로 semantic map을 만들고, 환경 내에서 객체가 이동된 후에도 의미 지도를 성공적으로 업데이트하는 성능을 보였습니다.



### Adapting Segment Anything Model for Unseen Object Instance Segmentation (https://arxiv.org/abs/2409.15481)
Comments:
          Submitted to ICRA 2025

- **What's New**: 이번 논문에서는 Unseen Object Instance Segmentation (UOIS) 작업을 위한 데이터 효율적인 솔루션인 UOIS-SAM을 제안합니다. 이 모델은 Segment Anything Model (SAM)의 높은 정확도와 강력한 일반화 능력을 활용합니다.

- **Technical Details**: UOIS-SAM은 Heatmap-based Prompt Generator (HPG)와 Hierarchical Discrimination Network (HDNet) 두 가지 주요 구성 요소를 통합합니다. HPG는 클래스에 구애받지 않는 포인트 프롬프트를 생성하며, HDNet은 SAM의 마스크 디코더를 대체하여 배경 혼동과 과분할(over-segmentation) 문제를 완화합니다.

- **Performance Highlights**: UOIS-SAM은 이전 방법들에 비해 훈련 샘플의 10%만을 사용하여 OCID, OSD와 같은 여러 데이터셋에서 최첨단 성능을 달성하였으며, 복잡한 테이블 환경에서의 효과성과 강건성을 강조합니다.



### Tag Map: A Text-Based Map for Spatial Reasoning and Navigation with Large Language Models (https://arxiv.org/abs/2409.15451)
- **What's New**: 본 연구에서는 대형 이미지 인식 모델을 활용하여 수천 개의 의미 클래스를 명시적으로 표현할 수 있는 텍스트 기반 맵을 제안합니다. 이 맵은 대형 언어 모델(LLM)과 쉽게 통합되며, 로봇이 사용자 작업을 해결하기 위해 PLANS (작업 계획)를 생성하는 데 필요한 장면 정보를 제공합니다.

- **Technical Details**: 제안된 태그 맵은 이미지 태깅 모델이 인식한 고유 엔티티(태그)를 저장하고, 각 태그가 인식된 시점(뷰포인트)과 연관됩니다. 이 맵은 메모리의 효율성을 극대화하기 위해 비구조적인 데이터베이스로 구현됩니다. 또한, 3D 로컬라이제이션을 통해 태그와 관련된 지역을 생성하는 과정을 설명합니다.

- **Performance Highlights**: 정량적 실험을 통해 제안된 태그 맵의 로컬라이제이션 성능이 최신 개방형 어휘 맵과 비교하여 정확도와 재현성을 유지하면서도 사용하는 메모리를 몇 배나 줄일 수 있음을 보여줍니다. 실제 로봇 실험에서도 태그 맵이 LLM을 기반으로 사용자 요청을 처리하고 실행 가능한 내비게이션 계획을 생성하는 데 효과적임을 입증했습니다.



### BurstM: Deep Burst Multi-scale SR using Fourier Space with Optical Flow (https://arxiv.org/abs/2409.15384)
Comments:
          12 pages

- **What's New**: 새로운 접근 방식인 Deep Burst Multi-scale SR(BurstM)을 소개합니다. 이 방법은 Optical Flow를 활용하여 정확한 프레임 정렬을 가능하게 하고, 각 프레임의 연속적인 Fourier 계수를 예측하여 고주파 텍스처를 표현하는 데 중점을 둡니다.

- **Technical Details**: BurstM은 Optical Flow를 이용하여 프레임 간의 상관된 오프셋을 제공하며, Well-aligned 정보를 통해 고주파 텍스처를 잘 표현할 수 있도록 Fourier 정보를 추정합니다. 이 방법은 고정된 SR 스케일 문제를 해결하고, 다양한 스케일의 슈퍼 해상도(SR) 처리를 지원하여 계산적 효율성을 갖춥니다.

- **Performance Highlights**: BurstM은 기존 MFSR 방법에 비해 이미지 품질과 계산 효율성에서 우수한 성능을 보이며, 광범위한 스케일에서의 유연성을 제공합니다.



### DS2TA: Denoising Spiking Transformer with Attenuated Spatiotemporal Attention (https://arxiv.org/abs/2409.15375)
Comments:
          arXiv admin note: text overlap with arXiv:2311.09376

- **What's New**: 본 논문에서는 비전을 위한 새로운 아키텍처인 DS2TA(Denoising Spiking transformer with Attenuated SpatioTemporal Attention)를 소개하며, 이는 템포럴 차원에서 조정된 스페이쇼템포럴 어텐션(SpatioTemporal Attention) 메커니즘을 도입하여 기존 스파이킹 트랜스포머의 한계를 뛰어넘습니다.

- **Technical Details**: DS2TA는 입력 발화의 시간 및 공간에서 발생하는 상관관계를 고려하여, spiking 쿼리, 키, 값 및 최종 출력을 계산하는 TASA(Temporally Attenuated Spatiotemporal Attention)를 구현함으로써, 스파이킹 뉴런의 계산 능력을 최대한 활용합니다. 또한, 비선형 스파이킹 어텐션 디노이저(nonlinear spiking attention denoisers)를 사용하여 주의 맵의 강인성과 표현력을 향상시킵니다.

- **Performance Highlights**: DS2TA는 CIFAR10에서 94.92%, CIFAR100에서 77.47%, CIFAR10-DVS에서 79.1%, DVS-Gesture에서 94.44%의 top-1 정확도로 여러 정적 이미지와 동적 신경형 하드웨어 데이터셋에서 최첨단 성능을 입증하였습니다.



### Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data (https://arxiv.org/abs/2409.15374)
- **What's New**: 이 연구는 자폐 스펙트럼 장애(ASD)의 조기 진단과 개입을 위한 새로운 접근 방식을 제시하며, 기존의 진단 모델의 해석 가능성을 높이는 데 초점을 맞추고 있습니다. 이 연구는 ASD를 정확히 분류할 뿐만 아니라, 그 작동 방식에 대한 설명 가능한 통찰력을 제공하는 딥 러닝(DL) 모델을 개발하려고 합니다.

- **Technical Details**: 사용된 데이터셋은 884개의 샘플로 구성된 자폐 뇌 영상 데이터 교환(ABIDE)의 전처리된 버전입니다. 이 연구는 resting-state functional Magnetic Resonance Imaging (fMRI) 데이터 분석을 통해 ASD의 잠재 바이오마커를 식별하고, Remove And Retrain (ROAR) 기술을 사용하여 해석 가능성 방법을 벤치마킹합니다.

- **Performance Highlights**: 모델은 ASD를 정확하게 분류할 수 있으며, ASD와 일반인 집단(Typical Controls) 간의 비정상적인 뇌 영역을 강조합니다. 이러한 발견은 다양한 데이터셋과 방법론에서의 선행 연구들에 의해 검증되었으며, 향후 ASD의 조기 진단 및 신경 기초 이해에 중요한 의미를 갖습니다.



### Damage detection in an uncertain nonlinear beam based on stochastic Volterra series (https://arxiv.org/abs/2409.15349)
- **What's New**: 본 논문은 비선형 행동을 보이는 기계 시스템에서 손상 감지를 위한 확률적(Probabilistic)Volterra 시리즈 접근 방식을 제안합니다. 이를 통해 시스템의 비선형 특성과 데이터 변동성을 동시에 설명하는 새로운 모델을 개발하였습니다.

- **Technical Details**: Volterra 시리즈는 선형 컨볼루션 개념의 일반화로, 시스템의 선형 및 비선형 기여를 분리하는 데 유리합니다. 본 연구에서는 Kautz 함수와 함께 확률적 Volterra 시리즈를 활용하여 비선형 동작을 분석하고, 시스템의 불확실성으로 인해 발생하는 문제를 극복하고자 하였습니다. 특히, 비선형 강성(linear stiffness)과 감쇠 계수(damping coefficient)의 변화를 통해 시스템의 불확실성을 시뮬레이션합니다.

- **Performance Highlights**: 실험 결과, 높은 차수의 Volterra 커널을 고려하여 비선형 분석을 수행했을 때, 작고 확률적인 신뢰도(probability confidence)를 가진 균열을 감지할 수 있음을 보여주었습니다. 이는 불확실성이 존재하는 경우에도 손상 감지 절차를 효과적으로 진행할 수 있도록 하며, 기존의 SHM 기술을 보완하는 중요한 접근을 제시합니다.



### A Lightweight GAN-Based Image Fusion Algorithm for Visible and Infrared Images (https://arxiv.org/abs/2409.15332)
- **What's New**: 이 논문은 성능과 효율성의 균형을 강조하여 가시광선(visible light) 이미지와 적외선(infrared) 이미지를 병합하기 위한 경량화된 이미지 융합(image fusion) 알고리즘을 제시합니다.

- **Technical Details**: 제안된 방법은 Generative Adversarial Network (GAN)에서 생성기(generator)를 개선하기 위해 Convolutional Block Attention Module (CBAM)을 통합하고, Depthwise Separable Convolution (DSConv)을 사용하여 계산의 효율성을 높입니다. 이러한 혁신은 모델의 계산 비용을 크게 줄이며, 파라미터 수와 추론 지연(inference latency)을 낮춥니다.

- **Performance Highlights**: M3FD 데이터셋을 이용한 비교 실험을 통해 제안된 알고리즘이 융합 품질(fusion quality) 면에서 유사한 이미지 융합 방법들을 능가하며, 임베디드 장치에서 배포하기에 더 자원 효율적인 솔루션을 제공함을 보여주었습니다. 경량화된 설계의 효과는 광범위한 ablation 연구를 통해 검증되었습니다.



### Visual Prompting in Multimodal Large Language Models: A Survey (https://arxiv.org/abs/2409.15310)
Comments:
          10 pages

- **What's New**: 본 논문은 시각적 프롬프트(visual prompting) 방법에 대한 첫 포괄적 설문조사로, 다중 모달 대규모 언어 모델(MLLMs)의 발전을 다룬다. 이를 통해 기존의 텍스트 기반 프롬프트보다 미세 조정된 비주얼 인스트럭션을 제공하여 MLLMs의 시각적 이해 및 추론 능력을 향상하는 다양한 접근 방식을 소개한다.

- **Technical Details**: MLLMs는 사전 훈련된 대형 언어 모델(LLMs)과 시각적 능력을 결합한 모델로, 단어뿐만 아니라 이미지에 대한 비주얼 프롬프트를 생성하여 더 높은 수준의 상황 이해를 가능하게 한다. 논문은 비주얼 프롬프트의 분류, 자동 프롬프트 주석 생성(generative methods), 시각적 부합(alignment) 방안 및 오브젝트 참조(object referring)에 대한 내용이 포함되어 있다.

- **Performance Highlights**: 강화된 시각적 프롬프트 방법들은 MLLM의 시각적 감각을 더욱 정교하게 하여, 보다 정확한 시각적 기초(visual grounding), 객체 참조 및 조합적 추론(compositional reasoning) 기능을 제공한다고 제안된다.



### PixWizard: Versatile Image-to-Image Visual Assistant with Open-Language Instructions (https://arxiv.org/abs/2409.15278)
Comments:
          Code is released at this https URL

- **What's New**: 이번 논문에서는 PixWizard라는 다재다능한 이미지-투-이미지 비주얼 어시스턴트를 제시합니다. 이 모델은 자연어 명령에 기반하여 이미지 생성, 조작 및 변환을 수행할 수 있으며, 다양한 비전 작업을 통합한 이미지-텍스트-투-이미지 생성 프레임워크를 구축했습니다.

- **Technical Details**: PixWizard는 Diffusion Transformers (DiT)를 기반 모델로 사용하고 있으며, 다양한 해상도의 이미지를 처리할 수 있는 유연한 메커니즘을 도입했습니다. 이를 통해 입력의 종횡비에 따라 동적으로 이미지를 처리할 수 있으며, 구조 인식 (structure-aware) 및 의미 인식 (semantic-aware) 가이드를 포함하여 효과적인 정보 융합을 지원합니다.

- **Performance Highlights**: 실험 결과, PixWizard는 다양한 해상도에서 인상적인 생성 및 이해 능력을 보여주었으며, 훈련 중 접하지 않았던 작업에 대해서도 뛰어난 일반화 능력을 보였습니다. 이는 PixWizard가 강력한 인터랙티브 이미지-투-이미지 비주얼 어시스턴트로서의 위상을 높여줍니다.



### MaterialFusion: Enhancing Inverse Rendering with Material Diffusion Priors (https://arxiv.org/abs/2409.15273)
Comments:
          Project Page: this https URL

- **What's New**: 본 연구는 MaterialFusion이라는 새로운 3D 역 렌더링 파이프라인을 소개하며, 텍스처와 재료 특성에 대한 2D prior를 결합하여 다중 조명 환경에서도 신뢰할 수 있는 복원력을 가지고 있다고 주장합니다.

- **Technical Details**: 이 연구는 안정적인 2D diffusion 모델인 StableMaterial을 활용하여 주어진 입력 외관으로부터 가장 가능성 높은 albedo(반사율)와 재료를 추정합니다. 또한, score distillation sampling (SDS)을 사용하여 albedo 및 재료의 최적화를 유도함으로써 이전 연구에 비해 재조명(relighting) 성능을 향상시킵니다.

- **Performance Highlights**: MaterialFusion은 NeRF Synthetic, NeRFactor 데이터셋, BlenderVault 데이터셋 및 Stanford-ORB 데이터셋에서 검증되어, 새로운 조명 조건 아래에서 복원된 객체의 외관을 크게 개선함을 보여줍니다.



### ReLoo: Reconstructing Humans Dressed in Loose Garments from Monocular Video in the Wild (https://arxiv.org/abs/2409.15269)
Comments:
          Project page: this https URL

- **What's New**: 이 논문에서는 ReLoo라는 새로운 방법을 소개합니다. 이 방법은 느슨한 의류를 착용한 인물의 3D 모델을 높은 품질로 재구성할 수 있는 기술을 제공합니다. 기존의 방법들이 타이트한 의류에만 적합했으나, ReLoo는 다양한 의류의 비정형적인 변형을 효과적으로 처리할 수 있습니다.

- **Technical Details**: ReLoo는 layered neural human representation을 기반으로 하여, 인체의 내부와 외부 의류를 분리하여 표현합니다. 또한 non-hierarchical virtual bone deformation module을 통해 의류의 자연스러운 움직임을 표현할 수 있습니다. 이 모델은 다계층 차별적 볼륨 렌더링(multi-layer differentiable volume rendering)을 활용하여 인체와 의류의 형상, 외관 및 변형을 최적화합니다.

- **Performance Highlights**: ReLoo는 MonoLoose라는 새로운 데이터셋을 사용하여 느슨한 의류를 착용한 인물의 3D 재구성에서 기존의 방법들보다 우월한 성능을 보여주었습니다. 실험 결과는 인체 모양과 의류의 변화를 정확하게 캡처하며, 이전 기술 대비 높은 품질의 시각적 결과를 제공합니다.



### S$^2$AG-Vid: Enhancing Multi-Motion Alignment in Video Diffusion Models via Spatial and Syntactic Attention-Based Guidanc (https://arxiv.org/abs/2409.15259)
- **What's New**: 본 논문에서는 다중 객체가 포함된 텍스트-비디오(T2V) 생성에서의 객체와 동작 정렬 문제를 해결하기 위해 S$^2$AG-Vid라는 새로운 추론 단계 최적화 방법을 제안합니다. 이 방법은 훈련 없이 적용될 수 있으며, 다양한 객체가 특정 동작과 더 잘 정렬되도록 돕습니다.

- **Technical Details**: S$^2$AG-Vid는 첫째, 초기 노이즈 제거 과정에서 공간 위치 기반 교차 주의(cross-attention, CA) 제약 조건을 적용해 여러 개의 명사가 올바른 주제 영역에 주의를 기울일 수 있도록 합니다. 둘째, 동작-주제 결합을 강화하기 위해 문법 안내 대조 제약(syntax-guided contrastive constraint)을 실시하며, 이는 동사 CA 맵과 해당 명사 CA 맵 간의 상관관계를 개선하는 것을 목표로 합니다.

- **Performance Highlights**: 정성적 및 정량적 평가에서 S$^2$AG-Vid는 기존 모델에 비해 매우 높은 품질의 비디오를 생성하며, 객체와 동작 간의 일관성을 크게 향상시키는 데 성공하였습니다.



### ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models (https://arxiv.org/abs/2409.15250)
- **What's New**: 최근 대규모 언어 모델과 대규모 로봇 데이터셋의 발전이 로봇 모델의 패러다임 전환을 이끌며, 다양한 작업, 장면 및 로봇 양식에 적응할 수 있는 일반화 능력을 가진 모델로 변화했습니다. 특히 Open Vision Language Action 모델은 다양한 작업에서 강력한 성능을 보여줍니다.

- **Technical Details**: 이 연구에서는 3가지 기존 로봇 기초 모델의 시각적 일반화 능력을 연구하고, 이에 대한 평가 프레임워크를 제안합니다. 기존 모델들은 시각적 도메인 아웃오브도메인(Out-of-Domain, OOD) 시나리오에 대한 강건성을 보이지 않으며, 이는 훈련 데이터의 변동성 부족 및 기억상실(catastrophic forgetting) 때문일 수 있습니다. OpenVLA 모델이 이러한 문제를 겪는 것을 보여주고, 모델 병합(model merging)을 기반으로 한 점진적 백본 리버설(grand backbone reversal) 접근법을 제안하여 재학습 후 시각적 일반화 능력을 복원합니다.

- **Performance Highlights**: ReVLA 모델은 OpenVLA에 비해 시각적 OOD 작업에서 그립(grasping) 및 리프팅(lifting) 성능에서 각각 77%와 66%의 향상을 달성하였습니다.



### Enhancing Pedestrian Trajectory Prediction with Crowd Trip Information (https://arxiv.org/abs/2409.15224)
- **What's New**: 본 논문은 보행자 궤적 예측을 위한 새로운 접근 방식으로, 군중의 이동 정보를 새로운 모달리티로 도입한 RNTransformer 모델을 제안합니다. 이 모델은 사회적 상호작용 및 도로 환경을 고려하여 보행자의 행동을 보다 정확하게 예측할 수 있도록 설계되었습니다.

- **Technical Details**: RNTransformer는 군중 이동 정보를 활용하여 사회적 상호작용에 대한 글로벌 정보를 캡처하는 일반 모델입니다. 이 모델은 여러 소셜 인지 지역 보행자 궤적 예측 모델과 결합되어 성능을 입증하였으며, Social-LSTM에서 ADE/FDE 지표에서 각각 1.3/2.2%, Social-STGCNN에서 6.5/28.4%, S-Implicit에서 8.6/4.3% 향상을 보여주었습니다. 이를 통해 다양한 데이터세트에서 보행자 궤적 예측의 정확도가 크게 향상되었음을 확인하였습니다.

- **Performance Highlights**: RNTransformer는 다양한 기저 보행자 궤적 예측 모델에 대한 정확도를 개선하는 데 성공했으며, 기본 모델에 비해 보행자 목표를 보다 정확하게 샘플링하는 데 기여했습니다. 본 연구에서 개발된 모델은 다양한 데이터세트에 대해 폭넓은 실험을 통해 검증되었습니다.



### HydroVision: LiDAR-Guided Hydrometric Prediction with Vision Transformers and Hybrid Graph Learning (https://arxiv.org/abs/2409.15213)
- **What's New**: 본 연구는 수문 예측에서 수면 상승 예측을 위해 LiDAR 데이터와 Vision Transformer (ViT)를 사용하여 지형 고도가 수역의 흐름과 연결성에 미치는 영향을 통합합니다.

- **Technical Details**: 연구는 GRU 블록을 그래프 합성과 결합하여 시계열 데이터 내의 공간적 의존성을 모델링합니다. 정적 그래프는 LiDAR 데이터에서 파생되며, 동적 그래프는 시간에 따른 변화를 고려합니다. 이 하이브리드 그래프 학습 구조는 수문 시스템 내의 복잡한 상호작용을 포착합니다.

- **Performance Highlights**: 퀘벡의 여러 수위 관측소에서 실험한 결과, 제안된 방법은 예측 오류를 평균 10% 감소시켰고, 예측 기간이 길어질수록 개선 효과가 더욱 두드러졌습니다.



### HOTVCOM: Generating Buzzworthy Comments for Videos (https://arxiv.org/abs/2409.15196)
Comments:
          Accepted to ACL 2024 (Findings)

- **What's New**: 중국어 비디오 핫 댓글 생성을 위한 새로운 데이터셋 HotVCom을 구축하였으며, 94,000개의 다양한 비디오와 1억 3천7백만 개의 댓글을 포함하고 있습니다. 또한, 비디오 핫 댓글 생성 프레임워크 ComHeat를 소개합니다.

- **Technical Details**: ComHeat는 시각적, 청각적, 텍스트 데이터를 통합하여 중국 비디오 데이터셋에서 영향력 있는 핫 댓글을 생성합니다. 이 프레임워크는 Supervised Fine-Tuning 기법을 통해 초기 댓글을 생성하고, 강화 학습을 통해 개선합니다. 또한 Tree-of-Thought 접근법을 활용하여 댓글의 품질을 높입니다.

- **Performance Highlights**: ComHeat 프레임워크는 새로 구축된 HotVCom 데이터셋과 기존 데이터셋에서 다른 기준 모델들을 초월하는 성능을 보여줍니다. 새로운 종합 평가 지표를 통해 댓글의 유용성, 관련성, 창의성 및 사용자 참여도를 강조합니다.



### Interpretability-Guided Test-Time Adversarial Defens (https://arxiv.org/abs/2409.15190)
Comments:
          ECCV 2024. Project Page: this https URL

- **What's New**: 본 논문에서는 해석 가능성(interpretablity) 기반의 뉴런 중요도 순위(neuron importance ranking) 방법을 이용하여 출력 클래스에 중요한 뉴런을 식별하는 혁신적이고 저비용의 테스트 타임 적대적 방어(test-time adversarial defense) 방식을 제안합니다. 우리의 방법은 훈련 없이도 실행되어 로버스트-정확도 무역비율을 상당히 개선하며, 최소한의 계산 오버헤드를 맞습니다.

- **Technical Details**: 우리의 IG-Defense(Interpretability-Guided Defense) 방법은 뉴런의 중요도 순위를 기반으로 클래스별 뉴런의 중요도를 계산하여 얻은 인사이트를 활용합니다. 주요 아이디어는 중요한 뉴런이 아닌 뉴런의 활동을 마스킹(masking)하여 인식된 활성화 이동을 제한하는 것입니다.

- **Performance Highlights**: IG-Defense는 CIFAR10, CIFAR100, ImageNet-1k에서 각각 평균 2.6%, 4.9%, 2.8%의 성능 향상을 보였으며, 강력한 적응형 공격(adaptive attacks) 하에서도 1.5%의 성능 향상을 기록하였습니다. IG-Defense는 가장 효율적인 테스트 타임 방어 방법 중 하나이며, 기존 방법보다 4배 빠른 성능을 보여줍니다.



### MIMAFace: Face Animation via Motion-Identity Modulated Appearance Feature Learning (https://arxiv.org/abs/2409.15179)
- **What's New**: 이 논문에서는 현재 확산 기반 얼굴 애니메이션 방법의 한계를 살펴보고, 모션과 정체성 수준에서 CLIP(Contrastive Language–Image Pre-training) 특징을 조절하는 새로운 모듈을 제안합니다. 이를 통해 더 높은 품질의 애니메이션 비디오를 생성할 수 있게 됩니다.

- **Technical Details**: Motion-Identity Modulated Appearance Learning Module (MIA)와 Inter-clip Affinity Learning Module (ICA)를 도입하여 모션과 정체성을 동시에 조절하고, 클립 간의 시간적 관계를 모델링합니다. MIA는 CLIP 특징을 조절하여 고해상도 얼굴 텍스처(예: 주름, 근육 수축)를 생성하고, ICA는 훈련 데이터와 생성된 프레임 간의 의미/색상 불연속성을 해소합니다.

- **Performance Highlights**: 이 방법을 사용하여 정밀한 얼굴 모션 제어(예: 표정과 시선)를 달성하고, 신뢰할 수 있는 정체성 보존과 함께 클립 내 및 클립 간 시간적 일관성을 유지하는 애니메이션 비디오를 생성할 수 있습니다. 실험 결과, 제안하는 방법이 기존의 다른 방법들보다 뛰어난 성능을 보임을 보여줍니다.



### SpikeGS: Learning 3D Gaussian Fields from Continuous Spike Stream (https://arxiv.org/abs/2409.15176)
Comments:
          Accepted by ACCV 2024

- **What's New**: 이번 논문에서는 스파이크 카메라(spike camera)의 스파이크 스트림(spike stream)만을 사용하여 3D 가우시안 필드(3D Gaussian fields)를 학습하는 최초의 방법인 SpikeGS를 소개합니다. SpikeGS는 고품질의 실시간 렌더링(real-time rendering)을 달성하며, 노이즈가 많은 저조도(low-light) 환경에서도 높인 강인함(robustness)을 보여줍니다.

- **Technical Details**: SpikeGS는 3DGS(3D Gaussian Splatting) 기법을 기반으로 한 미분 가능(diff differentiable) 스파이크 스트림 렌더링 프레임워크를 설계하였습니다. 이 프레임워크는 다중 뷰 일관성(multi-view consistency)과 타일 기반의 멀티스레드 병렬 렌더링(tile-based multi-threaded parallel rendering) 메커니즘을 활용하여, 높은 품질의 렌더링 결과를 생성합니다. 추가로, 다양한 조명 조건에서 일반화될 수 있는 스파이크 렌더링 손실 함수(spike rendering loss function)를 제안하였습니다.

- **Performance Highlights**: 실험 결과, 본 방법은 실제 및 합성 데이터셋(synthetic datasets) 모두에서 기존의 최신 기술 대비 렌더링 품질과 속도에서 뛰어난 성능을 나타냈습니다.



### FusionRF: High-Fidelity Satellite Neural Radiance Fields from Multispectral and Panchromatic Acquisitions (https://arxiv.org/abs/2409.15132)
- **What's New**: FusionRF는 위성 이미지에서 광학적으로 비가공된 데이터를 사용하여 지형 재구성을 수행하는 새로운 신경 렌더링 방법입니다. 기존의 팬샤프닝(pansharpening) 방법과는 달리 사전 지식이 필요 없이 복잡한 외부 처리 없이 이미지를 융합할 수 있도록 합니다.

- **Technical Details**: FusionRF는 멀티스펙트럴(multispectral) 이미지와 팬크로매틱(panchromatic) 이미지를 직접 최적화하여 고해상도 이미지를 생성합니다. 이를 통해 공간 해상도 손실을 모델링하는 새로운 블러 커널(sparse blur kernel)을 내장하였습니다. 또한, 모달 임베딩(modal embedding)을 도입하여 다양한 이미지 특성을 효과적으로 인코딩하고, 불확실성 학습을 통해 동적 객체와 고정 객체를 구분합니다.

- **Performance Highlights**: 실험 결과, FusionRF는 Depth Reconstruction(깊이 재구성) 및 새로운 보기에서의 선명도에서 기존의 최신 방법(State-of-the-Art)을 초월하는 성능을 보였으며, 멀티스펙트럴 정보를 잘 유지합니다.



### Detect, Describe, Discriminate: Moving Beyond VQA for MLLM Evaluation (https://arxiv.org/abs/2409.15125)
Comments:
          ECCV 2024 Workshop EVAL-FoMo; Project Page: this https URL

- **What's New**: 본 논문은 Multimodal Large Language Models (MLLMs)의 비주얼 개념 이해 능력을 평가하기 위한 새로운 벤치마크인 D3 벤치마크를 소개합니다. D3에서는 매우 유사한 이미지 쌍을 비교하여 집합된 시각적 차이를 정확하게 감지하고 이를 기반으로 자연어로 묘사하도록 요구합니다.

- **Technical Details**: D3 벤치마크는 247개의 고도로 유사한 이미지 쌍으로 구성되며, 각 쌍은 특별한 시각적 차이점(POD, Point of Difference)을 가지고 있습니다. 모델은 해당 차이를 감지하고 타겟 이미지를 독특하게 설명하도록 유도되며, 자가 검색(self-retrieval) 방법을 통해 효과성을 평가합니다.

- **Performance Highlights**: 일반적으로 현재의 MLLM 모델들은 D3 벤치마크에서 39.7%의 성과를 보이며, 이는 무작위 추측보다 낮습니다. 반면 MMVP 벤치마크에서는 동일 개념 네트워크인 Gemini-1.5-Pro가 87.3%의 성과를 기록해 학생들은 D3에서 보다 도전적인 작업으로 인식하고 있음을 나타냅니다.



### Diffusion-based RGB-D Semantic Segmentation with Deformable Attention Transformer (https://arxiv.org/abs/2409.15117)
- **What's New**: 본 연구에서는 RGB-D semantic segmentation 문제를 해결하기 위해 diffusion 기반의 프레임워크를 제안합니다. 또한 Depth 이미지에서 특징을 추출하기 위해 Deformable Attention Transformer를 사용하면 무효 영역의 특성을 효과적으로 포착할 수 있음을 보여줍니다.

- **Technical Details**: 제안된 방법은 RGB-D 이미지를 모형화하는 능력이 뛰어나며, 훈련 시간이 크게 단축된 상태에서 State-of-the-Art 성능을 달성합니다. 실험 결과, NYUv2와 SUN-RGBD 데이터 세트에서 뛰어난 성능을 보였습니다.

- **Performance Highlights**: RGB-D semantic segmentation에서의 성능 향상을 위해 제안된 방법은 전통적인 discriminative 방법과 비교하여 훈련 시간은 짧으면서도 성능은 우수합니다. 실험 결과, 특히 어려운 이미지 데이터에서도 State-of-the-Art 성능을 달성하였습니다.



New uploads on arXiv(cs.AI)

### UniEmoX: Cross-modal Semantic-Guided Large-Scale Pretraining for Universal Scene Emotion Perception (https://arxiv.org/abs/2409.18877)
Comments:
          This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 이번 연구에서는 감정 인식을 위한 새로운 대규모 사전 학습 프레임워크인 UniEmoX를 소개합니다. 이는 심리학 연구에서 개인과 환경 간의 상호작용이 감정 탐색 과정과 분리될 수 없다는 점에 영감을 받았습니다.

- **Technical Details**: UniEmoX는 심장 중심(scene-centric) 및 개인 중심(person-centric) 저수준 이미지 공간 구조 정보를 통합하여 더 미세하고 구분 가능한 감정 표현을 도출하는 것을 목표로 합니다. 또한, CLIP 모델을 활용하여 이미지-텍스트 샘플 간의 유사성을 통해 감정 임베딩 표현을 효과적으로 향상시키는 방식으로 동작합니다.

- **Performance Highlights**: 총 6개의 벤치마크 데이터 세트와 2개의 하위 작업에서 실시한 실험을 통해 UniEmoX의 효과성을 검증하였으며, 다양한 시나리오에서 감정 분석을 위한 기존 심리학 이론과 현대적인 대비 학습(contrastive learning) 및 마스크 이미지 모델링 기법을 통합한 최초의 대규모 사전 학습 프레임워크입니다.



### Mitigating Selection Bias with Node Pruning and Auxiliary Options (https://arxiv.org/abs/2409.18857)
- **What's New**: 본 연구는 대규모 언어 모델(LLMs)의 선택 편향(selection bias)을 모델의 내부 표현에서 조사하고, 이를 해결하기 위한 새로운 방법인 Bias Node Pruning (BNP)과 Auxiliary Option Injection (AOI)을 제안합니다.

- **Technical Details**: Bias Node Pruning (BNP)은 편향에 기여하는 선형 계층 파라미터를 제거하는 방법으로, 선택 편향을 줄이는 데 효과적입니다. Auxiliary Option Injection (AOI)은 블랙박스 LLMs에서도 호환되는 입력 수정 기술로, 단순하면서도 효과적인 디바이싱(debiasing) 방법입니다. 또한 Choice Kullback-Leibler Divergence (CKLD)라는 새로운 메트릭을 소개하여, 기존 메트릭의 라벨 불균형(label imbalance)에 대한 민감도 부족 문제를 해결합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법들이 다양한 데이터셋에서 강력하고 적응력이 뛰어난 성능을 보였으며, 세 가지 LLM에 적용되었습니다.



### LLM With Tools: A Survey (https://arxiv.org/abs/2409.18807)
Comments:
          10 pages

- **What's New**: 본 논문은 대형 언어 모델(LLM)의 효율성과 정확성을 향상시키기 위해 외부 도구를 통합하는 새로운 접근방식을 탐구합니다. LLM이 외부 도구를 사용하는 방법을 교육하는 과정에서의 방법론, 도전 과제 및 발전을 깊이 있게 설명합니다.

- **Technical Details**: 우리는 사용자 지침을 실행 가능한 계획 및 실행으로 매핑하는 일련의 함수에 의해 안내되는 도구 통합을 위한 표준화된 패러다임을 소개합니다. 이는 사용자 의도 이해, 도구 선택, 동적 계획 조정의 중요성을 강조합니다. 이 과정에서 도구 호출 시기, 선택의 정확성, 견고한 추론 과정의 필요성과 같은 여러 도전 과제를 식별했습니다.

- **Performance Highlights**: 최종적으로, 우리는 Chameleon의 결과를 ScienceQA에서 재현하고 코드 구조를 분석했습니다. 이 연구는 LLM이 단순한 도구 사용자에서 도구 생성자로서의 역할로 재정의될 수 있는 가능성을 탐구합니다.



### Learning from Demonstration with Implicit Nonlinear Dynamics Models (https://arxiv.org/abs/2409.18768)
Comments:
          21 pages, 9 figures

- **What's New**: 이 논문에서는 Learning from Demonstration (LfD) 프로세스의 오류 누적 문제를 해결하는 새로운 접근 방식을 제안합니다. 고정 비선형 동적 시스템을 포함하는 독창적인 신경망 레이어를 개발하여, 동적 특성을 조정할 수 있도록 하였습니다.

- **Technical Details**: 이 새로운 신경망 레이어는 reservoir computing에 영감을 받아 설계되었으며, 기존의 신경망 아키텍처에 통합하여 인간의 필기 동작을 재현하는 LASA Human Handwriting Dataset을 사용하여 검증했습니다. 이를 통해 정책 실행 시 오류 누적 문제를 효과적으로 해결하였습니다.

- **Performance Highlights**: 경험적 실험 결과, 제안한 레이어를 통합한 모델이 기존의 정책 예측의 시간적 앙상블 및 Echo State Networks (ESNs)와 비교할 때 필기 작업에서 더 높은 정확도와 강건성을 보여주었으며, 다양한 동적 조건에서도 일반화할 수 있는 성능을 보였습니다.



### Autoregressive Policy Optimization for Constrained Allocation Tasks (https://arxiv.org/abs/2409.18735)
Comments:
          Accepted at NeurIPS 2024

- **What's New**: 이 논문에서는 한정된 자원을 각 개체(entity)에 배분해야 하는 제약 할당 작업(constrained allocation tasks)을 다루고 있습니다. 특히 자율 회귀 과정(autoregressive process)을 기반으로 하는 새로운 방법을 제안하고 초기에 발생하는 편향을 상쇄하기 위한 새로운 디바이싱 메커니즘(de-biasing mechanism)을 도입하였습니다.

- **Technical Details**: 이 방법은 각 개체에 대한 할당을 순차적으로 샘플링하는 방식으로 설계되었습니다. 제약 조건(linear constraints)에 따라 투자자들은 특정 산업 부문에 자금의 30% 이상을 할당할 수 없다는 등의 규칙이 있습니다. 이는 허용되는 할당(action space)을 복잡하게 제한하므로 제약을 위반하지 않는 정책을 학습하기 어렵습니다.

- **Performance Highlights**: 제안한 방법은 포트폴리오 최적화(portfolio optimization), 컴퓨팅 작업 분배(computational workload distribution), 그리고 합성 할당 벤치마크(synthetic allocation benchmark)의 세 가지 제약 할당 작업에서 다양한 제약 강화 학습(Constrained Reinforcement Learning, CRL) 방법들과 비교하여 뛰어난 성능을 보였습니다.



### Semantic Model Component Implementation for Model-driven Semantic Communications (https://arxiv.org/abs/2409.18704)
- **What's New**: 본 논문에서는 모델 기반의 의미(semantic) 통신에서 모델의 전파(propagation)가 핵심 기능임을 설명하고, 교차 소스 도메인(cross-source domain) 및 교차 작업(cross-task) 의미 컴포넌트 모델을 설계하였습니다.

- **Technical Details**: 의미 모델 컴포넌트(SMC)는 물리적 채널을 통해 지능이 흐를 수 있도록 설계되었으며, 엣지 노드(edge node)에서 기본 모델을 배포하고 대형 서버 노드가 이를 업데이트하는 구조를 가지고 있습니다. 이 시스템은 다양한 소스와 작업(tasks)을 처리할 수 있습니다. 또한, 채널 노이즈(channel noise)가 모델 성능에 미치는 영향을 논의하고, 노이즈 저항성을 높이기 위한 방법으로 노이즈 주입(injection noise) 및 정규화(regularization)를 제안합니다.

- **Performance Highlights**: SMC는 더 작은 모델 파라미터를 사용하면서도 성능을 유지하고 노이즈에 대한 저항성을 개선하여 교차 소스 및 교차 작업 기능을 달성합니다. 모델 컴포넌트를 실제 응용 프로그램에 적용하기 위해 부품 전이 기반의 무인 차량 추적 프로토타입이 구현되었습니다.



### KALE-LM: Unleash The Power Of AI For Science Via Knowledge And Logic Enhanced Large Mod (https://arxiv.org/abs/2409.18695)
- **What's New**: AI의 잠재력이 커지고 있는 가운데, 과학 연구를 진전시키기 위해 AI를 활용하는 방안에 대해 논의한 비전 논문입니다.

- **Technical Details**: KALE-LM 모델 시리즈의 일환으로 Llama3-KALE-LM-Chem-8B라는 대형 모델을 제안했으며, 화학 분야와 관련된 작업에서 우수한 성능을 나타냈습니다. 이 모델은 오픈 소스로 공개되었습니다.

- **Performance Highlights**: Llama3-KALE-LM-Chem-8B 모델은 화학 관련 작업에서 뛰어난 성능을 보여주며, 더 지능적인 AI 실현을 위한 강력한 출발점이 될 것으로 기대됩니다.



### Toward Universal and Interpretable World Models for Open-ended Learning Agents (https://arxiv.org/abs/2409.18676)
Comments:
          4 pages including appendix, 6 including appendix and references; 2 figures

- **What's New**: 이번 논문에서는 오픈 엔디드(Open-ended) 학습 에이전트를 지원하는 일반적이고 조합적이며 해석 가능한 생성적 세계 모델(generative world models)의 새로운 클래스를 소개합니다.

- **Technical Details**: 이 모델은 광범위한 확률 과정(stochastic processes)을 근사화할 수 있는 희소한 베이즈 네트워크(Bayesian networks)로 구성되어 있으며, 에이전트가 해석 가능하고 계산적으로 확장 가능한 방식으로 세계 모델을 학습할 수 있도록 지원합니다. 이 접근 방식은 베이즈 구조 학습(Bayesian structure learning)과 본질적으로 동기 부여된 계획(intrinsically motivated planning)을 통합하여 에이전트가 능동적으로 세계 모델을 개발하고 수정할 수 있게 합니다.

- **Performance Highlights**: 이러한 방법론은 오픈 엔디드 학습을 촉진하고 더욱 견고하고 적응적인 행동을 이끌어낼 수 있는 가능성을 보여줍니다.



### Not the Silver Bullet: LLM-enhanced Programming Error Messages are Ineffective in Practic (https://arxiv.org/abs/2409.18661)
Comments:
          To appear in the proceedings of the 2024 UK and Ireland Computing Education Research conference (UKICER '24)

- **What's New**: 이 연구는 새로운 언어 모델인 GPT-4가 프로그래밍 오류 메시지를 이해하고 해결하는 데 있어 초보 프로그래머에게 미치는 영향을 실질적인 상황에서 평가했습니다.

- **Technical Details**: 106명의 참가자를 대상으로 한 연구로, 참가자들은 6개의 버그가 있는 C 프로그램을 수정하는 과제를 수행했습니다. 각각의 프로그램에 대해 참가자들은 일반 컴파일러 오류 메시지, 전문가가 작성한 오류 메시지, 또는 GPT-4가 생성한 오류 메시지 중 하나를 무작위로 부여받았습니다.

- **Performance Highlights**: GPT-4가 생성한 오류 메시지는 6개 과제 중 단 1개의 과제에서만 전통적인 컴파일러 오류 메시지를 능가하는 것으로 나타났으며, 전문가의 손으로 작성된 설명이 여전히 LLM과 전통적인 오류 메시지보다 모든 측면에서 더 뛰어난 결과를 보였습니다.



### Reducing Diversity to Generate Hierarchical Archetypes (https://arxiv.org/abs/2409.18633)
- **What's New**: 이 논문에서는 자동으로 추상화 계층을 생성하는 프레임워크(framework)를 제안합니다. 이는 지능적인 행동을 구축하기 위해 필수적인 요구사항으로, 최근의 신경과학 연구에 의해 명확히 드러났습니다.

- **Technical Details**: 작업의 기반이 되는 원시(primitives)의 특성을 명시하고, 이를 바탕으로 구성 아키타입(constructive archetypes)의 계층을 자동으로 생성할 수 있는 방법론(methodology)을 개발하였습니다. 또한, 수리적 정의와 증명을 통해 이 프레임워크의 효과성을 입증하였습니다.

- **Performance Highlights**: 이 프레임워크는 기존의 인공지능 시스템에서 계층적 추상화를 구축하는 데 사용할 수 있으며, 복잡한 문제 해결 및 지능형 시스템 개발에 있어서 새로운 통찰력을 제공할 것으로 기대됩니다.



### Refutation of Spectral Graph Theory Conjectures with Search Algorithms) (https://arxiv.org/abs/2409.18626)
- **What's New**: 이 논문에서는 스펙트럴 그래프 이론(spectral graph theory) 추측의 자동 반박(automatic refutation) 방법을 제안합니다. 기존 연구들은 제한된 크기의 그래프를 생성하거나 딥 강화 학습(deep reinforcement learning)을 통해 반박하는 방식이었습니다.

- **Technical Details**: 우리는 이러한 한계를 해결하기 위해 검색 알고리즘(search algorithms)을 사용합니다. 이 방법을 통해 잠재적으로 큰 반례(counter-example)를 몇 초 만에 찾을 수 있습니다. 다양한 검색 알고리즘을 Graffiti의 여러 추측에 적용했습니다.

- **Performance Highlights**: 우리가 연구한 13개의 Graffiti에서 이미 반박된 추측 중 12개를 몇 초 만에 반박하는 데 성공했습니다. 또한, 지금까지 미해결이었던 Graffiti의 추측 197도 반박하였습니다.



### Unsupervised Cognition (https://arxiv.org/abs/2409.18624)
- **What's New**: 본 논문에서는 최신 인지 모델에 영감을 받아서 의사결정을 위한 기존의 획기적인 primitive 기반 비지도학습(unconstrained learning) 접근 방식을 제안합니다.

- **Technical Details**: 이 방법론은 입력 공간을 독립적으로 구성된 분산 계층 구조(distributed hierarchical structure)로 모델링합니다. 이는 기존의 비지도 학습(classification) 기법들과 비교되며, 특히 암 유형 분류(cancer type classification)에 집중하여 성능을 평가합니다.

- **Performance Highlights**: 제안된 접근 방식은 기존의 최첨단 비지도 학습 알고리즘뿐만 아니라 감독 학습(supervised learning) 알고리즘을 초월하여 더 나은 성능과 인지 모델과 유사한 행동 패턴을 보여줍니다.



### ASAG2024: A Combined Benchmark for Short Answer Grading (https://arxiv.org/abs/2409.18596)
Comments:
          Accepted at SIGCSE-Virtual 2024

- **What's New**: 이 연구는 여러 학과, 채점 기준 및 분포에 걸쳐 통합된 단답형 채점 벤치마크인 ASAG2024를 소개합니다. 이는 자동 채점 시스템의 비교를 용이하게 계속 할 수 있게 합니다.

- **Technical Details**: ASAG2024 벤치마크는 일곱 개의 일반적으로 사용되는 단답형 채점 데이터셋을 통합하여 공통 구조 및 채점 기준을 제공합니다. 연구에서는 최근의 단답형 채점 방법들의 성능을 평가하였으며, LLM 기반 접근 방식이 새로운 높은 점수를 기록하지만 여전히 인간의 성능에 미치지 못한다는 것을 보여주었습니다.

- **Performance Highlights**: 최근 SAG 방법들은 이전보다 높은 점수를 기록했지만, 인간 채점자의 성능과 비교할 때 여전히 큰 간극이 존재합니다. 이는 향후 연구에서 인간-기계 SAG 시스템의 가능성을 열어줍니다.



### "Oh LLM, I'm Asking Thee, Please Give Me a Decision Tree": Zero-Shot Decision Tree Induction and Embedding with Large Language Models (https://arxiv.org/abs/2409.18594)
- **What's New**: 이번 연구에서는 대규모 언어 모델(LLMs)이 데이터가 제한적인 상황에서 예측 모델링을 위해 사전 지식을 활용하는 강력한 방법을 제공함을 보여줍니다. 특히, LLMs이 훈련 데이터 없이도 본질적으로 해석 가능한 머신 러닝 모델인 의사결정나무(decision trees)를 생성할 수 있음을 설명합니다.

- **Technical Details**: 이 연구에서는 LLMs가 압축된 세계 지식을 활용하여 제로샷(Zero-shot) 의사결정나무를 생성하는 방법을 보여줍니다. 이 의사결정나무는 작고 간단한 테이블 데이터셋(tabular datasets)에 대해 데이터 기반 의사결정나무보다 뛰어난 성능을 보일 수 있습니다. 또한, 이 나무에서 파생된 임베딩(embeddings)은 평균적으로 데이터 기반 의사결정나무에서 파생된 것들과 동등한 성능을 나타냅니다.

- **Performance Highlights**: 지식 기반 의사결정나무 유도와 임베딩 접근 방식은 데이터가 제한된 상황에서 데이터 기반 머신 러닝 방법의 강력한 새로운 기준선을 제공합니다.



### Experimental Evaluation of Machine Learning Models for Goal-oriented Customer Service Chatbot with Pipeline Architectur (https://arxiv.org/abs/2409.18568)
- **What's New**: 이 논문은 고객 서비스 챗봇을 위한 맞춤형 실험 평가 접근법을 제시하여, 자연어 이해(NLU), 대화 관리(DM), 자연어 생성(NLG)라는 세 가지 주요 구성 요소에 중점을 둡니다.

- **Technical Details**: 연구에서는 NLU(BERT 및 LSTM 사용), DM(DQN 및 DDQN 활용), NLG(GPT-2 및 DialoGPT 활용)의 개별 평가를 강조하며, 하이퍼파라미터 최적화와 후보 모델 평가를 수행합니다.

- **Performance Highlights**: NLU에서는 BERT가 의도 탐지에서 우수한 성과를 보였고, LSTM은 슬롯 채우기에서 더 나은 결과를 나타냈습니다. DM에서는 DDQN 모델이 DQN을 능가하며 더 적은 턴 수, 더 높은 보상 및 성공률을 달성했습니다. NLG에서는 대형 언어 모델인 GPT-2가 DialoGPT보다 BLEU, METEOR 및 ROUGE 지표에서 더 뛰어난 성능을 보여주었습니다.



### Align$^2$LLaVA: Cascaded Human and Large Language Model Preference Alignment for Multi-modal Instruction Curation (https://arxiv.org/abs/2409.18541)
- **What's New**: 최근 Multi-modal Large Language Models (MLLMs) 분야에서 LLaVA 시리즈 모델과 같은 최신 기술은 방대한 기계 생성 지침 데이터 조정에 의해 발전하고 있습니다. 그러나 이러한 자동 지침 수집 파이프라인은 데이터 품질에 중대한 변동성을 초래합니다.

- **Technical Details**: 이 논문에서는 두 가지 독특한 관점, 즉 인간과 LLM 선호 정렬을 통해 기계 생성 멀티모달 지침 데이터의 대량 집합을 압축하고 고품질 형태로 변환하는 새로운 지침 큐레이션 알고리즘을 소개합니다. (i) 인간 선호 정렬: 전문가는 주관적 및 객관적 기준을 통해 데이터 품질을 평가하고, 주석이 달린 데이터셋에 대해 보상 모델을 훈련시켜 인간의 지침 정렬에 대한 미세한 이해를 내재화합니다. (ii) LLM 선호 정렬: 보상 모델에 의해 선택된 지침을 바탕으로 MLLM에서 사용되는 내부 LLM의 작성 스타일에 시각적 지침을 맞추는 방법을 제안합니다.

- **Performance Highlights**: 신 synthetic 멀티모달 지침을 최대 90% 압축하여 모델 성능을 유지하거나 개선할 수 있음을 실험을 통해 입증했습니다. 특히, 전체 훈련 샘플 수를 158k에서 14k로 감소시킴으로써(9배 작아짐) 다양한 MLLM 벤치마크에서 모델이 전체 데이터셋에 비해 일관되게 우수한 성능을 발휘했습니다.



### Data Analysis in the Era of Generative AI (https://arxiv.org/abs/2409.18475)
- **What's New**: 본 논문은 AI 기반 도구가 데이터 분석을 재형성할 수 있는 잠재력을 탐구합니다. 특히, 대형 언어 모델과 다중 모달 모델의 등장으로 데이터 분석 작업 흐름의 다양한 단계를 향상시키기 위한 새로운 기회들이 제공된다는 점에 주목합니다.

- **Technical Details**: AI 도구는 사용자의 고급 의도를 실행 가능한 코드, 차트 및 인사이트로 변환하는 기능을 갖추고 있으며, 인간 중심 디자인 원칙을 통해 직관적인 상호작용을 촉진하고 사용자 신뢰를 구축하는 방법을 논의합니다. 이러한 시스템이 직면한 연구 도전 과제로는 모델 능력 향상, 평가 및 벤치마크, 최종 사용자 요구 사항 이해 등이 있습니다.

- **Performance Highlights**: AI-assisted 분석(workflow)이 여러 앱에 걸쳐 신속하게 진행될 수 있도록 하여 데이터 분석의 효율성을 높이는 방안을 제시하고 있습니다.



### Cost-Aware Dynamic Cloud Workflow Scheduling using Self-Attention and Evolutionary Reinforcement Learning (https://arxiv.org/abs/2409.18444)
Comments:
          This paper has been accepted by ICSOC (International Conference on Service-Oriented Computing) 2024

- **What's New**: 이번 논문에서는 클라우드 환경에서 Cost-aware Dynamic Multi-Workflow Scheduling (CDMWS) 문제를 다룹니다. 이는 가상 머신 (VM) 인스턴스를 효율적으로 할당하여 서비스 수준 계약 (SLA) 위반에 따른 벌금과 VM 임대료를 최소화하는 데 목표를 두고 있습니다.

- **Technical Details**: 전통적인 Reinforcement Learning (RL) 정책 네트워크는 기본적인 feedforward 아키텍처를 사용하여 각 VM 인스턴스의 적합성을 개별적으로 결정합니다. 그러나 본 논문에서는 Self-Attention Policy Network (SPN-CWS)를 제안하여 모든 VM으로부터 전역 정보를 포착하는 방법을 제시합니다. 또한 Evolution Strategy 기반의 RL 시스템(ERL)을 개발하여 SPN-CWS를 신뢰성 있게 훈련합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법이 여러 벤치마크 CDMWS 문제에 대해 기존의 최첨단 알고리즘들보다 눈에 띄게 우수한 성능을 보였음을 확인했습니다.



### Physics Augmented Tuple Transformer for Autism Severity Level Detection (https://arxiv.org/abs/2409.18438)
Comments:
          12 pages

- **What's New**: 이 논문은 자폐 스펙트럼 장애(ASD)의 중증도 인식을 위해 물리 법칙을 활용하는 새로운 프레임워크를 제안합니다. 이 프레임워크는 스켈레톤 기반의 운동 궤적을 통해 피험자의 행동을 고차원 잠재 공간에서 인코딩하는 물리 기반 신경망 아키텍처를 포함하고 있습니다.

- **Technical Details**: 제안된 네트워크는 두 가지 디코더를 사용합니다: 물리 기반 디코더(physics-based decoder)와 비물리 기반 디코더(non-physics-based decoder). 물리 기반 디코더는 스켈레톤 시퀀스에 적용되는 물리 법칙을 예측 과정에 적용하며, 비물리 기반 디코더는 예측된 행동과 실제 행동 간의 차이를 최소화하도록 최적화됩니다. 또한, 분류기도 동일한 잠재 공간 임베딩을 활용하여 ASD의 중증도를 인식합니다.

- **Performance Highlights**: 제안된 방법은 여러 ASD 진단 벤치마크에서 최첨단 성능을 달성했으며, ASD 진단 작업 외에도 낙상 예측(publicly available benchmark for fall prediction) 실험을 통해 모델의 우수성을 입증했습니다.



### Multimodal Trajectory Prediction for Autonomous Driving on Unstructured Roads using Deep Convolutional Network (https://arxiv.org/abs/2409.18399)
Comments:
          11 pages,6 figures

- **What's New**: 최근 자율 주행 기술이 열린 광산(오픈핏 마이닝)에서 안전하고 효율적인 광물 수송을 이루기 위해 주목받고 있습니다. 이 논문에서는 비구조적 도로에서의 경로 예측 문제를 해결하기 위한 새로운 방법이 제안되었습니다.

- **Technical Details**: 제안된 방법은 목표 차량의 여러 가능한 경로와 그 확률을 예측합니다. 주변 환경과 목표 차량의 과거 경로는 래스터화한 이미지로 인코딩되며, 이는 심층 합성곱 네트워크를 사용하여 입력으로 넣어집니다. 이 기술은 열린 광산 자율 주행 시나리오에 특화된 데이터셋을 기반으로 오프라인 테스트를 수행하였습니다.

- **Performance Highlights**: 제안된 방법은 물리 기반(physics-based) 방법과 비교하여 평가되었으며, 실제 적용 가능성을 높이는 중요한 결과를 도출하였습니다. 오픈 소스 코드 및 데이터는 제공된 링크에서 확인할 수 있습니다.



### Improving Agent Behaviors with RL Fine-tuning for Autonomous Driving (https://arxiv.org/abs/2409.18343)
- **What's New**: 이번 연구는 자율주행 차량의 에이전트 행동 모델링에서 에이전트를 보다 신뢰성 있게 만들기 위한 방법을 제시합니다. 특히, 행동 모델을 강화 학습( reinforcement learning)을 통해 폐쇄 루프( closed-loop)로 미세 조정하여 개선된 성능을 보여줍니다.

- **Technical Details**: 연구에서는 Waymo Open Sim Agents 챌린지에서 개선된 전반적인 성능은 물론 충돌률(collision rate)과 같은 목표 지표(targeted metrics)의 향상도 확인되었습니다. 또한, 시뮬레이션된 에이전트의 능력을 직접 평가하기 위한 새로운 정책 평가 벤치마크(policy evaluation benchmark)를 도입하여 자율주행 차량 플래너의 품질을 측정하는 방법을 제공합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법이 에이전트 행동의 신뢰성을 높이며, 자율주행 차량 계획의 성과를 향상시키는 우수성을 입증하였습니다.



### A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies (https://arxiv.org/abs/2409.18335)
Comments:
          EMNLP Findings 2024

- **What's New**: 최근 인공지능(AI) 및 자연어 처리(NLP)의 발전에도 불구하고, 협상(negotiation)은 여전히 AI 에이전트에게 어려운 분야입니다. 최근에 제안된 FDHC 프레임워크는 공정성(fairness)을 고려하여 인간과 호환되는 협상 전략을 학습할 수 있게 도와줍니다.

- **Technical Details**: FDHC 프레임워크는 보상 설계(reward design)와 탐색(search) 두 가지 측면에서 공정성을 통합합니다. 또한, LGM-Zero라는 새로운 RL(강화 학습) + search 기법을 도입하여 사전 훈련된 언어 모델(pre-trained language model)을 활용하여 대규모 행동 공간에서 인간과 호환되는 제안을 검색합니다.

- **Performance Highlights**: 실험 결과, FDHC는 협상 결과를 더 평등하게 만들고 협상 품질을 향상시키는 데 성공하였습니다.



### Input-Dependent Power Usage in GPUs (https://arxiv.org/abs/2409.18324)
- **What's New**: 이번 논문에서는 GPU의 입력 데이터를 조정하여 고전력 소모 문제를 해결할 수 있는 방법을 제안합니다.

- **Technical Details**: 연구에서는 행렬-행렬 곱셈(GEMM)에 대한 입력 값 분포(value distribution), 비트 유사성(bit similarity), 위치 배치(placement), 희소성(sparsity) 등 네 가지 가지 입력 변화를 실험하였습니다. 이 입력 변화를 통해 GPU의 전력 사용량이 최대 40%까지 변화할 수 있음을 확인하였습니다.

- **Performance Highlights**: 입력에 따라  비트 플립(bit flip)의 수가 변화하게 되며, 이를 통해 컴파일러와 스케줄러 최적화를 가능하게 하여 GPU 전력 관리 및 에너지 소비 절감을 할 수 있음을 제안합니다.



### Cross-Institutional Structured Radiology Reporting for Lung Cancer Screening Using a Dynamic Template-Constrained Large Language Mod (https://arxiv.org/abs/2409.18319)
- **What's New**: 본 논문은 구조적 방사선 보고서를 생성하기 위한 향상된 오픈 소스 LLM(대형 언어 모델)을 개발하는 새로운 접근법을 제안합니다. 기존 모델들이 직면한 형식 오류, 콘텐츠 착각(content hallucinations), 개인정보 유출 문제를 해결하고자 합니다.

- **Technical Details**: 연구팀은 두 기관으로부터 수집된 5,442개의 비식별화된 LCS 보고서를 분석하고, 이 중 500개의 보고서를 무작위로 선택하여 수작업으로 라벨링하였습니다. 29개의 특징을 포함한 표준화된 보고서 템플릿을 개발했으며, 이를 기반으로 템플릿 제약 디코딩(template-constrained decoding)을 이용해 LLAMA, Qwen, Mistral 등의 오픈 소스 LLM을 향상시켰습니다. 성능 평가는 F1 점수, 신뢰 구간(confidence interval), McNemar test, z-test를 통해 수행되었습니다.

- **Performance Highlights**: 제안한 방법은 여러 기관의 데이터셋에서 LLM 성능을 일관되게 향상시켰으며, 형식 오류나 콘텐츠 착각이 없었습니다. 오픈 소스 LLAMA-3.1 405B 모델의 성능을 최대 10.42% 개선하였고, GPT-4o보다 17.19% 더 뛰어난 성과를 보였습니다. 또한, 대규모 다중 모달(multimodal) 데이터베이스에서 신규 결절 검색 시스템을 성공적으로 프로토타입하고 자동으로 통계 분석을 수행하여, 이전 결과와의 일관성을 보여주었습니다.



### Retrospective Comparative Analysis of Prostate Cancer In-Basket Messages: Responses from Closed-Domain LLM vs. Clinical Teams (https://arxiv.org/abs/2409.18290)
- **What's New**: 이번 논문에서는 RadOnc-GPT라는 특화된 대형 언어 모델(Large Language Model, LLM)을 소개합니다. 이 모델은 전립선암의 방사선 치료를 중점적으로 다루며, 환자와의 소통을 개선하기 위해 설계되었습니다.

- **Technical Details**: RadOnc-GPT는 병원 전체 전자 건강 기록(Electronic Health Record, EHR) 데이터베이스와 방사선 종양학에 특화된 내부 데이터베이스를 통합하여 운영됩니다. 이 모델은 158개의 이전 메시지 상호작용을 기반으로 평가되었으며, 정량적 자연어 처리(Natural Language Processing, NLP) 분석과 임상팀의 두 차례에 걸친 평가로 응답의 질을 분석하였습니다.

- **Performance Highlights**: RadOnc-GPT는 응답의 'Clarity'(명확성)와 'Empathy'(공감) 부분에서 임상 팀보다 약간 우수한 성과를 보였으며, 'Completeness'(완전성)와 'Correctness'(정확성)에서 비슷한 점수를 기록했습니다. 이 모델은 간호사에게 메시지 처리 시 5.2분, 임상 의사에게는 2.4분의 시간을 절약할 것으로 추정되며, 임상 팀의 업무 부담을 줄이고 의료비 절감에도 기여할 수 있습니다.



### Trustworthy AI: Securing Sensitive Data in Large Language Models (https://arxiv.org/abs/2409.18222)
Comments:
          40 pages, 1 figure

- **What's New**: 이 논문은 Large Language Models (LLMs)의 신뢰 메커니즘을 통합하여 민감한 정보의 공개를 동적으로 제어할 수 있는 포괄적인 프레임워크를 제안합니다.

- **Technical Details**: 제안된 프레임워크는 세 가지 핵심 요소로 구성됩니다: 사용자 신뢰 프로파일링(User Trust Profiling), 정보 민감도 감지(Information Sensitivity Detection), 및 적응형 출력 제어(Adaptive Output Control). Role-Based Access Control (RBAC), Attribute-Based Access Control (ABAC), Named Entity Recognition (NER)와 같은 기술을 활용하고, 맥락 분석(contextual analysis) 및 차등 프라이버시(differential privacy)와 같은 개인 정보 보호 방법을 통합합니다.

- **Performance Highlights**: 이 시스템은 사용자의 신뢰 수준에 따라 민감한 정보를 적절히 공개하여 데이터 유용성과 개인 정보 보호의 균형을 맞추고, LLMs의 안전한 배치를 위한 새로운 접근 방식을 제공합니다.



### MMMT-IF: A Challenging Multimodal Multi-Turn Instruction Following Benchmark (https://arxiv.org/abs/2409.18216)
Comments:
          24 pages, 16 figures

- **What's New**: MMMT-IF 데이터셋과 Programmatic Instruction Following (PIF) 메트릭을 도입하여 멀티모달, 멀티턴 대화에서 지시사항을 따르는 능력을 평가하는 새로운 방법을 제안합니다.

- **Technical Details**: MMMT-IF는 질문들 사이에 추가된 전역 지시사항을 포함하여, 모델이 긴 대화 속에서 분산된 지시사항을 검색하고 지시사항 제약 하에서 추론할 수 있도록 도전합니다. 모든 지시사항은 코드 실행을 통해 객관적으로 검증 가능합니다. PIF 메트릭은 추론 작업을 수행하는 동안 정확하게 따르는 지시사항의 비율을 측정합니다. PIF-N-K 메트릭은 모델 응답 중 K개가 PIF 점수가 1인 비율을 측정하여 강건성을 평가합니다.

- **Performance Highlights**: Gemini 1.5 Pro, GPT-4o, Claude 3.5 Sonnet의 평균 PIF 점수가 턴 1에서 0.81에서 턴 20에서 0.64로 감소하며, 모든 응답을 4회 반복했을 때 GPT-4o와 Gemini가 모든 지시사항을 성공적으로 따르는 경우는 단 11%입니다. 지시사항이 모델 입력 문맥의 끝에 추가되면 평균 PIF 점수가 22.3 포인트 향상됩니다.



### Autonomous Network Defence using Reinforcement Learning (https://arxiv.org/abs/2409.18197)
- **What's New**: 이 논문에서는 네트워크 보안의 방어자가 공격자에 비해 불리한 상황을 반전시키기 위해 자율 에이전트(autonomous agents)의 효과를 조사합니다.

- **Technical Details**: 강화 학습(reinforcement learning)에 대한 배경을 제공하고, 3개의 서브넷(subnets)으로 구성된 13개의 호스트(hosts)의 네트워크 환경 시뮬레이션에서 이벤트를 테스트합니다. 논문에서는 신뢰할 수 있는 방어를 위한 새로운 강화 학습 에이전트를 설계 및 훈련합니다.

- **Performance Highlights**: 이 에이전트는 공격자가 두 가지 유형 – 하나는 네트워크 레이아웃에 대한 완전한 지식을 가진 고급 지속 위협(advanced persistent threat, APT) 에이전트와 다른 하나는 탐색을 통해 자원을 발견해야 하지만 보다 일반적인 에이전트로서의 공격을 계속 방어할 수 있음을 보여줍니다.



### Data-Prep-Kit: getting your data ready for LLM application developmen (https://arxiv.org/abs/2409.18164)
Comments:
          10 pages, 7 figures

- **What's New**: 이 논문에서는 대규모 언어 모델(LLM) 개발을 위한 데이터 준비의 중요성을 강조하며, 사용자들이 손쉽게 확장하고 조정할 수 있는 오픈 소스 데이터 준비 툴킷인 Data Prep Kit (DPK)를 소개합니다.

- **Technical Details**: DPK는 데이터 준비를 사용자의 필요에 맞게 조정할 수 있도록 설계된 아키텍처를 가지고 있으며, 로컬 머신에서 데이터를 준비할 수 있을 뿐만 아니라 수천 개의 CPU 코어가 있는 클러스터에서도 손쉽게 확장할 수 있습니다. DPK는 자연어 및 코드 데이터를 변환하는 확장 가능한 모듈 세트를 제공합니다. 사용자가 추가적인 변환이 필요할 경우, DPK의 지원을 통해 손쉽게 개발할 수 있습니다. 이러한 모듈들은 독립적으로 또는 파이프라인 방식으로 연속적인 작업을 수행하는 데 사용될 수 있습니다.

- **Performance Highlights**: DPK의 성능은 작은 규모에서 시작하여 매우 큰 수의 CPU까지 확장 가능함을 보여줍니다. DPK의 모듈은 Granite 모델 데이터 준비에도 사용되었습니다. DPK는 AI 커뮤니티가 LLM 모델 성능을 향상하거나 Retrieval-Augmented Generation (RAG) 기능으로 모델을 미세 조정할 수 있도록 돕는 귀중한 기여라고 믿습니다.



### A Survey on Multimodal Benchmarks: In the Era of Large AI Models (https://arxiv.org/abs/2409.18142)
Comments:
          Ongoing project

- **What's New**: 이번 논문에서는 Multimodal Large Language Models (MLLMs)에 대한 벤치마크(benchmark) 분석이 부족한 상황에서, 211개의 벤치마크를 체계적으로 검토하였습니다.

- **Technical Details**: MLLMs의 평가를 위해 이해, 추론, 생성 및 응용의 네 가지 핵심 영역에서 벤치마크를 분석하였으며, 작업 설계(task design), 평가 지표(evaluation metrics) 및 데이터셋 구성(dataset construction)에 대한 세부적인 분석을 제공합니다.

- **Performance Highlights**: 이 논문은 MLLM 연구의 발전에 기여할 수 있는 포괄적인 벤치마킹 관행(overview of benchmarking practices)을 제공하며, 향후 연구의 유망한 방향성을 제시하고자 합니다.



### PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation (https://arxiv.org/abs/2409.18964)
Comments:
          Accepted to ECCV 2024. Project page: this https URL

- **What's New**: PhysGen은 단일 이미지를 입력으로 사용하여 현실적이고 물리적으로 그럴듯한 비디오를 생성하는 혁신적인 이미지-비디오 생성 방법입니다. 주목할 점은 이미지에 적용된 힘과 토크와 같은 입력 조건을 활용하여 동적 영상을 생성하는 것입니다.

- **Technical Details**: PhysGen의 핵심 구성 요소는 세 가지로 나눌 수 있습니다: (i) 이미지의 기하학, 재료 및 물리적 매개변수를 효과적으로 캡처하는 이미지 이해 모듈; (ii) 강체 물리학(rigid-body physics)과 유추된 매개변수를 사용하는 이미지 공간 동적 시뮬레이션 모델; (iii) 생성적 영상 확산(generative video diffusion) 기법을 활용해 시뮬레이션된 동작을 포함하는 현실적인 비디오 영상을 생성하는 이미지 기반 렌더링 및 정제 모듈입니다.

- **Performance Highlights**: PhysGen을 통해 생성된 비디오는 물리적 사실성과 외관 측면에서 현실적이며 정교한 제어가 가능합니다. 기존의 데이터 기반 이미지-비디오 생성 연구들과의 정량적 비교 및 포괄적인 사용자 연구를 통해 뛰어난 결과를 보여줍니다.



### Exploring Token Pruning in Vision State Space Models (https://arxiv.org/abs/2409.18962)
Comments:
          NeurIPS'24

- **What's New**: 본 논문에서는 State Space Models (SSMs)을 기반으로 한 비전 모델의 효율성을 향상시키기 위해 토큰 기반의 프루닝(token pruning) 기법을 제안합니다. 기존의 Vision Transformers (ViTs) 기술을 활용한 토큰 프루닝 기법의 제한점을 분석하고, SSM의 고유한 계산 특성을 고려하여 새로운 방법을 개발했습니다.

- **Technical Details**: 제안된 방법은 pruning-aware hidden state alignment 기법을 도입하여 남아있는 토큰의 이웃을 안정화하고, SSM 모델에 적합한 토큰 중요성 평가(token importance evaluation) 방법을 통해 토큰 프루닝을 수행합니다. 이로 인해 효율적인 구현 및 실질적인 가속화가 이루어집니다.

- **Performance Highlights**: 제안된 방법은 ImageNet에서 41.6\%의 FLOPs 감소와 함께 81.7\%의 정확도를 달성하며, 다양한 작업에서 성능에 미치는 영향을 최소화하면서도 계산량을 대폭 줄일 수 있음을 입증했습니다. 또한, 이 연구는 SSM 기반 비전 모델의 동작을 이해하는 데 더 깊은 통찰을 제공합니다.



### ProMerge: Prompt and Merge for Unsupervised Instance Segmentation (https://arxiv.org/abs/2409.18961)
Comments:
          ECCV2024 camera-ready

- **What's New**: 이 논문에서는 Unsupervised instance segmentation(비지도 인스턴스 분할)에서 새로운 방법인 Prompt and Merge(ProMerge)를 제안합니다. ProMerge는 self-supervised visual features(자기지도 시각적 특징)를 활용해 패치를 초기 그룹화하고 전략적으로 병합하는 접근법입니다.

- **Technical Details**: ProMerge는 DINO와 같은 self-supervised 모델에서 제공하는 강력한 시각적 특징을 활용하고, sophisticated background-based mask pruning technique(정교한 배경 기반 마스크 가지치기 기법)을 적용하여 초기 세그먼트를 병합합니다. 또한, 기존의 normalized-cut(정규화 컷)을 사용하는 방법에 비해 계산 요구 사항을 줄이며, inference speed(추론 속도)를 크게 개선합니다.

- **Performance Highlights**: ProMerge는 경쟁력 있는 결과를 제공하며, 기존 최첨단 normalized-cut 기반 접근법에 비해 추론 시간을 크게 단축시킵니다. 우리의 마스크 예측을 pseudo-labels(의사 레이블)로 사용하는 객체 탐지기를 훈련할 경우, 다양한 challenging instance segmentation benchmarks(도전적인 인스턴스 분할 벤치마크)에서 현재 최고 수준의 비지도 모델을 능가합니다.



### $O(d/T)$ Convergence Theory for Diffusion Probabilistic Models under Minimal Assumptions (https://arxiv.org/abs/2409.18959)
- **What's New**: 본 논문은 점수 기반 확산 모델(score-based diffusion models)의 이론적 수렴성을 개선하여 빠른 수렴 이론을 확립합니다. 기존의 이론적 보장이 엄격한 가정이나 최적이 아닌 수렴 속도에 의해 제한되는 문제를 해결합니다.

- **Technical Details**: 우리는 최소한의 가정 하에 인기 있는 SDE(Stochastic Differential Equation) 기반 샘플러의 빠른 수렴 이론을 수립합니다. 분석 결과, $	ext{l}_2$-정확한 점수 함수(score function) 추정치를 제공하면, 목표 분포(target distribution)와 생성된 분포들 간의 총 변이 거리(total variation distance)가 O(d/T)로 상한이 설정됩니다. 여기서 d는 데이터 차원, T는 단계의 수를 나타냅니다.

- **Performance Highlights**: 이 결과는 유한한 1차 모멘트를 가지는 모든 목표 분포에 대해 적용되며, 기존의 SDE 기반 샘플러와 ODE(Ordinary Differential Equation) 기반 샘플러의 수렴 이론을 개선합니다. 이 연구는 각 단계에서 오류가 어떻게 전파되는지를 세밀하게 나타내는 새로운 분석 도구를 통해 이루어졌습니다.



### LML: Language Model Learning a Dataset for Data-Augmented Prediction (https://arxiv.org/abs/2409.18957)
Comments:
          First version

- **What's New**: 이 논문은 대규모 언어 모델(LLMs)을 분류 작업에 활용하기 위한 새로운 접근 방식을 소개합니다. 전통적인 머신 러닝(ML) 모델들과는 달리, LLMs를 사용하여 데이터 정리(data cleaning)와 특징 공학(feature engineering)을 간소화합니다.

- **Technical Details**: 이 논문은 'Language Model Learning (LML)'이라는 새로운 개념과 'Data-Augmented Prediction (DAP)'이라는 새로운 방법을 제안합니다. LLM이 데이터를 탐색하고 이해하며 분류를 결정하는 방식으로 분류를 수행합니다. DAP 과정에서는 데이터 요약을 사용하여 자동으로 쿼리를 생성하고, 이를 통해 관련 데이터 행을 검색한 후, 최종적인 분류 결과를 생성합니다.

- **Performance Highlights**: 테스트 사례에서 시스템의 정확도가 90%를 초과하여 기존 ML 모델을 다양한 시나리오에서 초월할 가능성을 입증하였습니다. 사용자가 예측의 논리를 검토할 수 있도록 'Explainable Machine Learning Model'로 행위하는 문구를 프롬프트에 포함시킴으로써 예측의 해석 가능성을 향상시켰습니다.



### Unconditional stability of a recurrent neural circuit implementing divisive normalization (https://arxiv.org/abs/2409.18946)
- **What's New**: 본 연구에서는 생물학적으로 그럴듯한 신경역학 모델의 안정성을 높이기 위해 동적 분배 정규화(dynamic divisive normalization, DN)와 ORGaNICs 회로 모델의 안정성을 연결했습니다. 이는 다양한 신경생리학적 현상을 모사할 수 있는 회로 모델입니다.

- **Technical Details**: 우리는 Lyapunov의 간접법을 사용하여 재귀 가중치 행렬이 단위 행렬일 때 임의 차원의 ORGaNICs 회로에 대한 무조건적 지역 안정성을 증명했습니다. 또한 이를 커플링된 감쇠 조화 진동기 시스템에 연결하여 회로의 에너지 함수 도출과 함께 회로와 개별 뉴런이 달성하고자 하는 목표를 규명합니다. 일반적인 재귀 가중치 행렬의 경우 2D 모델의 안정성을 증명하고, 더 높은 차원에서도 안정성이 유지됨을 실험적으로 입증했습니다.

- **Performance Highlights**: ORGaNICs는 자체적인 안정성 특성과 적응형 시간 상수 덕분에 폭발, 소멸 및 진동하는 그래디언트 문제를 해결하며, 시간에 따른 역전파(backpropagation through time) 방법으로 훈련될 수 있습니다. RNN 벤치마크에서 ORGaNICs는 정적 이미지 분류 작업에서 대안 신경역학 모델보다 우수한 성능을 보였으며, 순차 작업에서는 LSTM과 유사한 성능을 나타냈습니다.



### Building Trust Through Voice: How Vocal Tone Impacts User Perception of Attractiveness of Voice Assistants (https://arxiv.org/abs/2409.18941)
Comments:
          Extended Abstract

- **What's New**: 본 논문은 음성 비서(Voice Assistants, VAs)가 복잡한 작업에 적합하다고 인식될 수 있도록 음성의 톤이 사용자의 신뢰성에 미치는 영향을 탐구하였습니다.

- **Technical Details**: 연구에서는 다양한 음성 톤을 가진 VA의 음성을 실험 참가자들에게 제공하여, 각 음성의 매력도(attractiveness)와 신뢰성(trustworthiness)을 평가하였습니다. 긍정적이거나 중립적인 톤을 가진 VA가 더욱 매력적이고 신뢰성 있게 인식되었습니다.

- **Performance Highlights**: VA의 음성 톤 설계를 통해 사용자가 느끼는 신뢰성을 향상시킬 수 있다는 결론에 도달하였습니다. 연구 결과, 매력적으로 느껴지는 VA가 사용자의 신뢰를 높이는 데 긍정적인 영향을 미친다는 것을 보였습니다.



### From Seconds to Hours: Reviewing MultiModal Large Language Models on Comprehensive Long Video Understanding (https://arxiv.org/abs/2409.18938)
Comments:
          11 pages

- **What's New**: 본 논문에서는 MultiModal Large Language Models (MM-LLMs)과 시각적인 인코더(visual encoders)의 통합을 통해 긴 비디오 이해(long video understanding)에서의 고유한 도전 과제를 조명합니다. 기존의 정적 이미지(static image)와 짧은 비디오(short video) 이해와의 차별점을 분명히 합니다.

- **Technical Details**: MM-LLMs의 설계(model design) 및 훈련(training methodologies) 방식에서 긴 비디오 이해를 위한 발전을 다룹니다. 짧은 비디오는 연속적인 프레임을 포함하여 공간(spatial) 및 사건 내 템포럴(temporal) 정보를 가지며, 긴 비디오는 여러 사건이 여유 있는 시간 간격으로 발생합니다.

- **Performance Highlights**: 기존 MM-LLMs의 비디오 이해(video understanding) 벤치마크 성능을 비교하고, 긴 비디오 이해를 위한 향후 발전 방향을 논의합니다.



### AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow (https://arxiv.org/abs/2409.18924)
Comments:
          42 pages, 6 figures, 7 tables

- **What's New**: AIPatient, an advanced simulated patient system, leverages Large Language Models (LLM) and integrates a Knowledge Graph (KG) from Electronic Health Records (EHRs) to enhance clinical decision-making simulations in medical education.

- **Technical Details**: AIPatient utilizes the AIPatient Knowledge Graph (AIPatient KG) sourced from the MIMIC-III database, creating a diverse cohort of 1,495 clinically relevant patients. It employs the Reasoning Retrieval-Augmented Generation (Reasoning RAG) framework, which involves six LLM-powered agents for tasks such as retrieval, KG query generation, and summarization.

- **Performance Highlights**: The AIPatient system achieved an accuracy of 94.15% in EHR-based medical Question Answering (QA) and demonstrated high readability and robustness, making it suitable for diverse applications in medical education and system integration.



### Soft Measures for Extracting Causal Collective Intelligenc (https://arxiv.org/abs/2409.18911)
Comments:
          Camera-ready version accepted for publication in the EMNLP 2024 Workshop NLP4Science

- **What's New**: 이 연구는 복잡한 사회 시스템을 설명하기 위해 집합적 지능(collective intelligence)을 이해하고 모델링하는 중요성을 강조하며, 대규모 언어 모델(large language models, LLMs)을 이용하여 퍼지 인지 맵(fuzzy cognitive maps, FCMs) 추출을 자동화하는 방법을 제안합니다.

- **Technical Details**: 연구에서는 새로운 그래프 기반 유사도 측정(graph-based similarity measures)을 도입하고, 이를 인간 평가와 비교하기 위해 Elo 등급 시스템(Elo rating system)을 적용합니다. FCM의 미세한 뉘앙스(capture nuances)를 포착하는 데 한계가 있다는 것이 강조되며, LLM을 미세 조정(fine-tuning)함으로써 성능을 향상시킬 수 있지만, 기존 측정 방식은 여전히 부족합니다.

- **Performance Highlights**: 결과는 인간 평가와 긍정적인 상관관계를 보이며, 하지만 가장 성능이 좋은 측정 방법조차 FCM의 복잡성을 완전히 포착하지 못하는 한계를 보입니다. 이 연구는 FCM 추출을 위한 부드러운 유사도 측정(soft similarity measures)의 필요성을 강조하며, 자연어 처리(NLP)와 함께 집합적 지능 모델링을 발전시킵니다.



### Improving Visual Object Tracking through Visual Prompting (https://arxiv.org/abs/2409.18901)
Comments:
          Accepted and to appear in IEEE Transactions on Multimedia

- **What's New**: 본 연구에서는 PiVOT(Visual Prompting mechanism for generic Visual Object Tracking)를 통해 기존의 목표와 주변 방해물(distractor)을 구별하는 문제를 해결하기 위한 새로운 시각적 프롬프트(prompt) 생성 네트워크를 제안합니다.

- **Technical Details**: PiVOT는 CLIP이라는 사전 훈련된 모델을 사용하여 자동으로 시각적 프롬프트를 생성하고 수정합니다. CLIP은 범주 수준의 광범위한 지식을 제공하며, 트래커는 객체 인스턴스(instance-specific data)에 대한 훈련을 통해 고유한 객체 인스턴스를 인식하는 데 강점을 가집니다. PiVOT는 시각적 프롬프트를 잠재적 목표 위치를 강조하는 형태로 컴파일합니다.

- **Performance Highlights**: 여러 벤치마크에서 수행된 실험을 통해 PiVOT은 방해 물체(distractors)를 억제하고 트래커의 성능을 향상시키는 데 효과적임을 입증하였습니다.



### Multi-Source Hard and Soft Information Fusion Approach for Accurate Cryptocurrency Price Movement Prediction (https://arxiv.org/abs/2409.18895)
- **What's New**: 본 연구에서는 암호화폐 가격 예측의 정확성을 향상시키기 위한 새로운 접근 방식인 Hard and Soft Information Fusion (HSIF)를 소개합니다.

- **Technical Details**: HSIF 방식은 역사적 가격 기록과 기술적 지표를 포함하는 하드 정보와, X(구 트위터)에서 수집한 뉴스 제목 및 트윗 등의 소프트 정보를 결합합니다. 이 데이터는 기계 학습 모델인 Bidirectional Encoder Representations from Transformers (BERT) 기반의 감성 분석 방법인 Financial BERT (FinBERT)를 통해 처리됩니다. 마지막으로 처리된 하드 및 소프트 데이터를 기반으로 bidirectional long short-term memory (BiLSTM) 모델을 사용하여 장기 종속성을 포착합니다.

- **Performance Highlights**: 모델은 비트코인 관련 데이터를 테스트한 결과, 약 96.8%의 가격 변동 예측 정확도를 기록했습니다. 이 접근 방식은 소셜 감정의 영향을 확장하여 기술적 분석 예측을 보완함으로써, 단일 출처 데이터에 의존하는 기존 모델보다 우수하다는 것을 강조했습니다.



### Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models (https://arxiv.org/abs/2409.18878)
Comments:
          submitted to AMIA Informatics Summit 2025 as a conference paper

- **What's New**: 이번 연구는 정신과 고위험 환경에서 자살 사건을 정확하게 식별하고 분류하여, 자살 예방 조치를 개선하고 운영 부담을 감소시키며 치료 품질을 향상시키는 방법을 제시합니다.

- **Technical Details**: 해당 연구에서는 두 가지 미세 조정 전략(단일 라벨 다수 및 단일 다중 라벨)을 사용하여 500개의 주석이 달린 정신과 평가 노트를 기반으로 네 가지 BERT(Bidirectional Encoder Representations from Transformers) 모델의 성능을 평가하였습니다. 노트는 자살적 사고(SI), 자살 시도(SA), 자살 노출(ES), 비자살적 자기 상해(NSSI)로 라벨링되었습니다.

- **Performance Highlights**: RoBERTa 모델이 binary relevance(이진 관련성) 방법을 사용하여 다른 모델보다 뛰어난 성능을 발휘하여 accuracy(정확도)가 0.86, F1 score가 0.78로 나타났습니다. MentalBERT는 F1 score가 0.74로 BioClinicalBERT의 0.72를 초과하였으며, 단일 다중 라벨 분류기로 미세 조정된 RoBERTa는 0.88의 정확도와 0.81의 F1 score로 성능이 더욱 향상되었습니다.



### CESNET-TimeSeries24: Time Series Dataset for Network Traffic Anomaly Detection and Forecasting (https://arxiv.org/abs/2409.18874)
- **What's New**: 이 논문은 네트워크 트래픽에서의 이상 탐지(anomaly detection)가 컴퓨터 네트워크의 보안을 유지하고 악의적인 활동을 식별하는 데 중요하다는 점을 강조합니다. 기존의 이상 탐지 기법에서 부족했던 실제 네트워크 데이터셋을 제공하여 이론과 실제의 간극을 메우고자 합니다.

- **Technical Details**: 저자는 CESNET3 네트워크에서 수집한 네트워크 엔티티의 행동에 대한 시계열(time series) 데이터로 구성된 데이터셋을 소개합니다. 이 데이터셋은 275,000개의 활성 IP 주소에서 40주 동안의 네트워크 트래픽 데이터를 포함하고 있습니다. ISP 출처는 네트워크 엔티티 간에 높은 수준의 변동성을 보장합니다.

- **Performance Highlights**: 이 데이터셋은 예측 기반(forecasting) 이상 탐지 접근법의 실제 적용에 대한 유용한 통찰력을 제공합니다. 다양한 네트워크 환경에서의 성능 평가에 기여할 수 있습니다.



### Individuation in Neural Models with and without Visual Grounding (https://arxiv.org/abs/2409.18868)
- **What's New**: 이 논문에서는 CLIP 모델과 FastText, SBERT와 같은 텍스트 전용 모델 간의 individuating (개별화) 정보 인코딩의 차이를 보여줍니다.

- **Technical Details**: CLIP 모델이 제공하는 latent representations (잠재 표현)을 연구하며, 기초(substrates), 미세한 집합(granular aggregates), 다양한 수의 객체에 대한 정보를 분석합니다.

- **Performance Highlights**: CLIP 임베딩은 텍스트 전용 데이터로 훈련된 모델들보다 individuating (개별화)에서 정량적 차이를 더 잘 포착하며, 이로부터 도출한 individuating hierarchy (개별화 계층)는 언어학 및 인지 과학에서 제안된 계층과 일치합니다.



### Positional Encoder Graph Quantile Neural Networks for Geographic Data (https://arxiv.org/abs/2409.18865)
Comments:
          17 main text pages, 4 figures

- **What's New**: 이번 논문에서는 Positional Encoder Graph Neural Networks (PE-GNNs)의 한계를 극복하기 위해 Positional Encoder Graph Quantile Neural Network (PE-GQNN)를 소개합니다. 이 방법은 PE-GNNs와 Quantile Neural Networks, 다시 조정 기술을 결합하여 예측 분포에 대한 최소한의 가정을 가지고 완전히 비모수적인 프레임워크를 제공합니다.

- **Technical Details**: PE-GQNN의 새로운 네트워크 아키텍처를 제안하며, quantile 기반 손실 함수를 결합하여 계산 복잡성을 증가시키지 않고도 정확하고 신뢰할 수 있는 확률적 모델을 생성합니다. 또한 KNN 예측기를 모델에 통합할 수 있는 구조화된 방법을 소개하며, GNN 레이어 연산을 통해 데이터 누수를 방지합니다.

- **Performance Highlights**: 벤치마크 데이터셋에 대한 실험 결과, PE-GQNN은 예측 정확도와 불확실성 정량화 모두에서 기존의 최고 수준의 방법들보다 상당한 개선을 나타냅니다.



### MECG-E: Mamba-based ECG Enhancer for Baseline Wander Remova (https://arxiv.org/abs/2409.18828)
Comments:
          7 pages, 5 figures

- **What's New**: 본 논문에서는 노이즈 조건이 심한 상황에서도 효과적으로 작동하는 새로운 ECG (Electrocardiogram) denoising 모델, Mamba 기반 ECG Enhancer (MECG-E)를 제안합니다.

- **Technical Details**: MECG-E 모델은 빠른 추론 속도와 뛰어난 비선형 매핑 능력으로 잘 알려진 Mamba 아키텍처를 활용합니다. 다양한 ECG denoising 방법들이 존재하지만, 기존 기법들은 매우 노이즈가 많은 조건에서 성능이 미흡하고, 추론 중 여러 단계를 요구하여 온라인 처리 시 지연 시간이 발생합니다.

- **Performance Highlights**: 실험 결과, MECG-E는 여러 지표에서 기존의 유명한 모델들을 초월하며, 노이즈 조건에 따른 다양한 상황에서도 우수한 성능을 보였습니다. 또한, MECG-E는 최첨단 diffusion 기반 ECG denoiser보다 추론 시간이 짧아 모델의 실용성과 효율성을 입증합니다.



### Early diagnosis of Alzheimer's disease from MRI images with deep learning mod (https://arxiv.org/abs/2409.18814)
Comments:
          7 pages, 3 figures, Presented at the 20-th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP) 21-22 February, 2024, Mazandaran University of Science and Technology, Babol, Iran

- **What's New**: 이 연구에서는 알츠하이머병(Alzheimer's disease, AD) 진단을 위한 새로운 방법으로 합성 소수 샘플 오버샘플링 기술(SMOTE)과 사전 훈련된 CNN(Convolutional Neural Network)을 활용한 뇌 MRI(Magnetic Resonance Imaging) 분석 프레임워크를 제안합니다.

- **Technical Details**: 이 프레임워크는 환자의 의료 기록, 신경심리학적 검사, MRI를 포함한 다양한 접근 방식을 통해 알츠하이머병의 특징을 식별합니다. 특히, Kaggle에서 얻은 이미지 데이터셋의 클래스 불균형 문제를 SMOTE를 통해 해결하였고, DEMNET라는 알츠하이머 네트워크에 사전 훈련된 CNN을 적용하여 중요한 특징들을 추출했습니다.

- **Performance Highlights**: 제안된 모델은 98.67%의 높은 정확도로 알츠하이머병 이미지를 분류하는 성능을 달성하였습니다.



### LLMs4Synthesis: Leveraging Large Language Models for Scientific Synthesis (https://arxiv.org/abs/2409.18812)
Comments:
          12 pages, 3 figures, Accepted to JCDL 2024 Research Track

- **What's New**: 이 논문은 과학 문헌의 복잡성과 양의 증가에 대응하기 위해 LLMs4Synthesis 프레임워크를 소개합니다. 이 프레임워크는 Large Language Models (LLMs)의 능력을 향상시키기 위해 설계되었습니다.

- **Technical Details**: LLMs4Synthesis 프레임워크는 개방형(open-source) 및 독점적(propriety) LLM을 활용하여 과학적 통합을 신속하고 일관되며 맥락이 풍부하게 수행하는 데 초점을 맞춥니다. 새로운 문서 처리 방법론을 개발하고, 새로운 통합 종류를 정의하며, 통합 평가를 위한 아홉 가지 품질 기준을 설정합니다.

- **Performance Highlights**: LLMs의 통합 강화를 위한 강화 학습(reinforcement learning) 및 AI 피드백을 제안하여 통합 품질을 최적화하고, 정립된 기준에 부합하도록 보장합니다. LLMs4Synthesis 프레임워크와 그 구성 요소는 과학 연구의 통합 생성 및 평가 프로세스를 향상시킬 것으로 기대됩니다.



### Esports Debut as a Medal Event at 2023 Asian Games: Exploring Public Perceptions with BERTopic and GPT-4 Topic Fine-Tuning (https://arxiv.org/abs/2409.18798)
- **What's New**: 이번 연구는 2023 아시안 게임에서의 e스포츠에 대한 대중의 의견과 가치 공동 창출(co-creation) 과정을 LLM-enhanced BERTopic 모델링 분석을 통해 조사하였습니다.

- **Technical Details**: 다섯 가지 주요 테마를 통해 대중의 인식과 주요 이해관계자들이 e스포츠 생태계 내외에서 가치를 공동 창출하는 방식을 식별했습니다. 소셜 미디어 마케팅의 전략적 사용이 대중의 의견에 영향을 미치고 e스포츠 이벤트 및 브랜드를 홍보하는 데 중요한 역할을 했습니다.

- **Performance Highlights**: e스포츠가 메달 이벤트로 포함되면서 보다 넓은 수용을 보여주었고, 부정적인 대중의 인식을 완화하는 데 기여했습니다. 전통적인 e스포츠 생태계 외부의 이해관계자들이 기여한 가치가 국가 대표 및 성과 증진에 중요한 역할을 했음을 발견했습니다. 이는 e스포츠를 스포츠로 정당화하는 지속적인 노력에 대한 지지를 나타냅니다.



### Supervised Learning Model for Key Frame Identification from Cow Teat Videos (https://arxiv.org/abs/2409.18797)
- **What's New**: 이 논문에서는 신경망(neural networks)과 비디오 분석(video analysis)을 이용하여 젖소의 유선 염증(티티스, mastitis) 위험 평가의 정확성을 향상시키는 방법을 제안합니다.

- **Technical Details**: 젖소의 티티스 감염을 탐지하기 위해, 저자들은 촬영된 비디오에서 유선이 온전하게 보이는 주요 프레임을 식별하는 신경망을 사용합니다. 이러한 주요 프레임은 수의사들이 유선 건강 상태를 평가할 시간적 유연성을 제공하며, 평가의 효율성과 정확성을 증가시킵니다. 복잡한 환경, 변화하는 소의 자세와 위치, 비디오에서 유선을 식별하는 어려움 등이 주요 도전과제로 제시됩니다.

- **Performance Highlights**: 제안된 방법은 유선 비디오에서 주요 프레임을 식별하는 데 있어 단일 거리 척도 또는 모델을 사용할 때보다 성능(F-score)이 향상된 것으로 나타났습니다.



### Hierarchical Federated ADMM (https://arxiv.org/abs/2409.18796)
- **What's New**: 본 논문에서는 널리 사용되는 gradient descent (경량 경사 하강법) 기반의 계층적 연합 학습 (hierarchical federated learning, FL) 알고리즘에서 벗어나, alternating direction method of multipliers (ADMM) 기반의 새로운 계층적 FL 프레임워크를 개발했습니다.

- **Technical Details**: 이 프레임워크 내에서 두 가지 새로운 FL 알고리즘을 제안합니다. 첫 번째 알고리즘은 상위 계층에 ADMM을 사용하고, 하위 계층에서도 ADMM을 사용하는 알고리즘과, 두 번째 알고리즘은 하위 계층에 전통적인 gradient descent 방법을 사용하는 알고리즘입니다.

- **Performance Highlights**: 제안된 알고리즘은 기존 알고리즘보다 학습 수렴성 (learning convergence) 및 정확도 (accuracy) 면에서 우수함을 실험을 통해 입증했습니다. 또한, 하위 계층에서의 gradient descent는 지역 단계 (local steps)가 매우 제한적일 경우에도 잘 작동하며, 두 계층에서 모두 ADMM을 사용할 경우 더 나은 성능을 보입니다.



### A Survey on the Honesty of Large Language Models (https://arxiv.org/abs/2409.18786)
Comments:
          Project Page: this https URL

- **What's New**: 이번 논문은 대형 언어 모델(LLMs)의 정직성(Honesty) 문제를 다루고 있습니다. 현재의 LLMs가 보이는 정직하지 않은 행동을 분석하고, 이와 관련된 다양한 정의와 평가 방법을 제시합니다.

- **Technical Details**: 정직성에 대한 정의가 다양하고, LLMs의 알고 있는 것과 모르는 것을 구분하는 데 어려움이 있으며, 이에 대한 종합적인 이해가 부족한 상황에서, 이 논문은 LLMs의 정직성을 평가하기 위해 여러 접근 방식을 탐색합니다.

- **Performance Highlights**: 논문은 LLMs의 정직성을 향상시키는 전략과 미래 연구 방향에 대한 통찰을 제공하여, 이 중요한 분야에서의 추가 탐색을 촉진하고자 합니다.



### HardCore Generation: Generating Hard UNSAT Problems for Data Augmentation (https://arxiv.org/abs/2409.18778)
- **What's New**: 이 논문에서는 SAT 문제의 핵심 기여자들을 식별하고 조작하는 새로운 접근법을 제안하고 있습니다. 기존의 데이터셋의 한계를 극복하기 위해 그래프 뉴럴 네트워크를 활용한 빠른 core detection 기법을 소개하였으며, 이를 통해 도전적인 SAT 문제를 보다 효율적으로 생성할 수 있음을 보여줍니다.

- **Technical Details**: 이 연구는 'core'라고 알려진 문제의 'hardness'의 핵심 요소를 다루며, 기존의 전통적 휴리스틱(core detection techniques) 방법의 시간 비용을 절감하는 데 초점을 맞추고 있습니다. 이를 위해 그래프 뉴럴 네트워크(graph neural network)를 활용하여 빠른 core detection 절차를 개발하였습니다.

- **Performance Highlights**: 생성된 합성 SAT 문제들은 해결하기 어려운 문제를 유지하며, 원래 예제 문제의 주요 속성을 보존합니다. 실험을 통해 이러한 합성 SAT 문제들이 solver 런타임 예측의 개선에 기여할 수 있음을 입증하였습니다.



### State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features (https://arxiv.org/abs/2409.18769)
Comments:
          16 pages, 4 figures, 4 tables

- **What's New**: 이번 연구에서는 눈과 눈꺼풀 주위의 거리와 특징들을 정량화하고 질병을 모니터링하는 데 있어서 중요한 정보를 제공하기 위해 3가지 딥러닝 방법을 개발했습니다. 이를 통해 수동 측정의 주관성과 시간 소모를 극복할 수 있습니다.

- **Technical Details**: 연구팀은 세 가지 딥러닝(segmentation) 방법을 사용하여 periorbital distance를 예측하였으며, 이를 통해 예측된 거리의 MAE는 훈련된 인간 주석자 간의 오류와 비슷하거나 그보다 낮았습니다. 현대 방식(SOTA)과 비교하여 모든 데이터셋에서 평균적으로 더 나은 성능을 보였습니다.

- **Performance Highlights**: 모델은 병든 눈에 대해 강력한 segmentation을 달성했으며, 건강한 눈을 사용하여 훈련된 모델에서도 효과적이었습니다. 또한, periorbital distances는 하위 분류(classification) 모델에서 고품질 특징으로 사용될 수 있음을 입증했습니다.



### OpenObject-NAV: Open-Vocabulary Object-Oriented Navigation Based on Dynamic Carrier-Relationship Scene Graph (https://arxiv.org/abs/2409.18743)
Comments:
          Project website: this https URL

- **What's New**: 이 논문은 로봇이 자주 사용되는 물체와 그 위치의 관계를 동적으로 업데이트할 수 있는 새로운 방법을 제시합니다. 이를 위해 Carrier-Relationship Scene Graph (CRSG)를 구축하고, 로봇 내비게이션 중 실시간으로 Carrying status를 반영합니다.

- **Technical Details**: CRSG는 여러 개의 객체와 그 객체를 가지고 있는 정적 캐리어 간의 관계를 캡처합니다. 내비게이션 과정은 Markov Decision Process로 모델링되며, 각 단계에서 Large Language Model의 상식 지식과 시각-언어 기능 유사성을 바탕으로 의사 결정을 진행합니다.

- **Performance Highlights**: Habitat 시뮬레이터에서 진행된 일련의 장기 시퀀스 내비게이션 테스트에서 로봇이 이동한 목표물로 효율적으로 내비게이션 할 수 있음을 입증했습니다. 이 알고리즘은 실제 로봇에 배포되어 실용적인 효과성을 검증했습니다.



### MemFusionMap: Working Memory Fusion for Online Vectorized HD Map Construction (https://arxiv.org/abs/2409.18737)
- **What's New**: 이 논문에서는 자율 주행 시스템을 위한 고해상도 (HD) 맵 구축에 개선된 시간적 추론 능력을 가진 MemFusionMap이라는 새로운 모델을 제안합니다.

- **Technical Details**: MemFusionMap은 역사적 프레임 간의 추론을 개선하는 작업 메모리 융합 모듈을 포함하며, 차량의 궤적 정보를 명시적으로 인지하도록 설계된 새로운 시간적 오버랩 히트맵을 도입합니다. 이러한 두 가지 설계를 통합하여 HD 맵 구축의 성능을 크게 향상시킵니다.

- **Performance Highlights**: MemFusionMap은 기존 방법들보다 최대 5.4% 높은 mAP (mean Average Precision)를 기록하여 성능이 크게 향상되었습니다.



### Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification (https://arxiv.org/abs/2409.18715)
- **What's New**: 본 논문에서는 비소세포 폐암(Non-small cell lung cancer, NSCLC)의 조기 발견과 세분화된 하위 유형 분류를 위한 혁신적인 다중 모드 데이터 통합 방법을 제안합니다. 이는 CT 및 PET 스캔과 임상 건강 기록 및 유전체 데이터를 융합하는 새로운 접근 방식을 포함합니다.

- **Technical Details**: 우리는 MedClip 및 BEiT와 같은 고급 머신러닝(advanced machine learning) 모델을 활용하여, 이미지 특징 추출을 위한 정교한 방법을 개발했습니다. 이러한 다중 모드 분류기 모델은 94.04%의 정확도를 기록하며, 기존의 접근 방식보다 상당한 성능 향상을 보여줍니다.

- **Performance Highlights**: 우리의 연구는 NSCLC 검출 및 분류의 정확성, 정밀도, 재현율 및 F1 점수 등 주요 성능 지표에서 두드러진 개선을 나타냅니다. 이는 NSCLC 진단을 변화시킬 수 있는 잠재력을 가지고 있으며, 더욱 효과적인 치료 계획 및 결과 개선에 기여할 것입니다.



### Read Over the Lines: Attacking LLMs and Toxicity Detection Systems with ASCII Art to Mask Profanity (https://arxiv.org/abs/2409.18708)
- **What's New**: 본 논문에서는 언어 모델이 ASCII 아트를 해석하지 못하는 것을 이용한 새로운 형태의 adversarial attacks를 소개합니다. 이러한 공격을 평가하기 위한 ToxASCII benchmark를 제안합니다.

- **Technical Details**: 연구에서는 두 개의 맞춤형 ASCII 아트 폰트를 개발하였으며, 하나는 special tokens를 활용하고 다른 하나는 텍스트로 채워진 문자 형태를 사용합니다. 이 공격들은 OpenAI의 o1-preview 및 LLaMA 3.1 포함 총 10개의 모델에서 1.0의 공격 성공률(Attack Success Rate)을 기록하였습니다.

- **Performance Highlights**: 이 논문은 연구 목적으로 사용된 유해한 언어의 예를 포함하고 있기 때문에 주의가 필요합니다.



### Speech Boosting: Low-Latency Live Speech Enhancement for TWS Earbuds (https://arxiv.org/abs/2409.18705)
Comments:
          Accepted by Interspeech 2024

- **What's New**: 이 논문은 진정한 무선 스테레오(TWS) 이어버드에서 사용하기 위한 음성 향상 솔루션을 소개합니다. 이 솔루션은 소음이 많은 환경에서 대화를 지원하도록 특별히 설계되었습니다.

- **Technical Details**: 주요한 설계 요소로는 네트워크 아키텍처(network architecture)와 도메인(domain), 손실 함수(loss functions)의 설계, 프루닝(pruning) 방법, 하드웨어 특화 최적화(hardware-specific optimization)가 포함됩니다. 음성 향상 모델의 계산 복잡성을 감소시키고, 3ms 이하의 지연(lag)을 유지하여 실시간 대화를 보장하는 데 중점을 두었습니다.

- **Performance Highlights**: 기존의 기준(baseline) 모델들과 비교했을 때, 음성 향상 품질에서 상당한 개선을 보이며 계산 복잡성과 알고리즘 지연을 동시에 줄였습니다.



### Learning from Pattern Completion: Self-supervised Controllable Generation (https://arxiv.org/abs/2409.18694)
- **What's New**: 이번 논문에서는 인공지능(AI) 분야에서 일반적으로 사용되는 레이블이 있는 학습 데이터 세트에 의존하지 않고 스스로 조절 가능한 생성(self-supervised controllable generation) 방법론을 제안합니다. 이러한 방법은 인간 뇌의 연상 작용을 모방한 것으로, 기능적 전문화를 이루는 모듈화된 오토인코더(modular autoencoder) 네트워크를 통해 이루어집니다.

- **Technical Details**: 제안된 프레임워크인 SCG(self-supervised controllable generation)는 모듈 내 독립성(intra-module independence)과 모듈 간 상관관계(inter-module correlation)를 촉진하기 위해 동등 변환 제약조건(equivariant constraint)을 도입합니다. 이로 인해 색상, 명도, 엣지 검출 모듈 처리에서 기능적 전문성을 확보합니다. 또한, 자기 감독형 패턴 완성(self-supervised pattern completion) 접근을 통해 학습을 진행합니다.

- **Performance Highlights**: 실험 결과, SCG는 색조, 명도, 엣지 검출의 모듈 처리에서 뛰어난 기능적 전문화를 보여주며, 인간 뇌와 유사한 방향 선택성(orientation selectivity), 색상 대립(color antagonism), 중심-주변 수용 영역(center-surround receptive fields) 특징을 나타냅니다. SCG는 페인팅(다시 그린 그림), 스케치, 고대 그래피티와 같은 다양한 작업에서 뛰어난 일반화 능력을 보여줍니다. 기존의 ControlNet과 비교할 때, SCG는 더 높은 노이즈 환경에서도 우수한 강건성(robustness)을 보이며, 자기 감독형 학습 덕분에 향후 더 나은 확장 가능성(scalability) 잠재력을 지니고 있습니다.



### MG-Net: Learn to Customize QAOA with Circuit Depth Awareness (https://arxiv.org/abs/2409.18692)
Comments:
          29 pages, 16 figures

- **What's New**: 이번 논문에서는 Quantum Approximate Optimization Algorithm (QAOA)와 그 변형들이 조합 최적화(combinatorial optimization) 문제를 해결하는 데 가진 잠재력을 분석합니다. 특히, QAOA의 수렴(convergence) 행동을 연구하고, 문제 특유의 회로 깊이(circuit depth)와 관련된 딜레마를 다룹니다.

- **Technical Details**: 우리는 Mixer Generator Network (MG-Net)라는 새로운 심층 학습(deep learning) 프레임워크를 제안합니다. MG-Net은 특정 작업(task)과 회로 깊이에 따라 최적의 mixer Hamiltonians를 동적으로 생성하는 기능을 가지고 있습니다. 이 네트워크는 Ising 모델과 최대 컷(maximum cut) 문제와 같은 여러 시뮬레이션을 통해 성능을 입증했습니다.

- **Performance Highlights**: MG-Net은 64 큐비트(qubits)까지의 위상별(Max-Cut instances)와 Ising 모델에서 높은 근사 비율(approximation ratio)과 효율성(efficiency)을 보여줍니다.



### Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models (https://arxiv.org/abs/2409.18680)
Comments:
          EMNLP24 Findings

- **What's New**: 본 논문에서는 여러 오디오 작업을 동시에 처리할 수 있는 첫 번째 multi-audio evaluation (MAE) 벤치마크를 제안합니다. 이 벤치마크는 11개 멀티 오디오 작업에서 수집한 20개의 데이터셋으로 구성되어 있습니다.

- **Technical Details**: 기존의 audio-LLMs (ALLMs)는 단일 오디오 작업의 평가에 주로 초점을 맞추었으나, 실제 애플리케이션에서는 여러 오디오 스트림을 동시에 처리하는 경우가 많습니다. 우리는 synthetic data를 활용하여 multi-audio-LLM (MALLM)을 제안하며, 이를 통해 여러 유사한 오디오 간의 음향 맥락을 포착합니다.

- **Performance Highlights**: MALLM은 기존의 모든 기준선 모델 대비 뛰어난 성능을 보여주며, 인간 주석 없이도 높은 데이터 효율성을 달성했습니다. 이는 ALLMs가 멀티 오디오 처리 시대에 접어드는 데 중요한 이정표가 될 것입니다.



### Exploiting Motion Prior for Accurate Pose Estimation of Dashboard Cameras (https://arxiv.org/abs/2409.18673)
- **What's New**: 본 연구는 대시캠(dashcam) 이미지를 위한 정밀한 자세 추정(pose estimation) 방법을 제안합니다. 이를 통해 카메라의 고유한 모션 프라이어(camera motion prior)를 활용하여 기존 이미지 매칭 방법의 한계를 극복하고자 합니다.

- **Technical Details**: 대시캠으로 캡처된 이미지 시퀀스는 일반적으로 전방 이동(forward movement)이나 측면 회전(lateral turns)과 같은 뚜렷한 모션 프라이어를 나타냅니다. 본 연구는 이를 기반으로 카메라 모션 프라이어를 학습하는 포즈 회귀 모듈(pose regression module)을 개발하고, 이를 관계 추정(correspondence estimation) 및 자세 추정 과정에 통합했습니다.

- **Performance Highlights**: 실제 대시캠 데이터셋에서 우리의 방법은 AUC5°에 대한 포즈 추정에서 기준선(baseline)보다 22% 향상된 성능을 보였으며, 재투영 오류(reprojection error)가 적은 이미지를 19% 더 많이 추정할 수 있었습니다.



### Effects of AI Feedback on Learning, the Skill Gap, and Intellectual Diversity (https://arxiv.org/abs/2409.18660)
- **What's New**: 이번 연구에서는 대규모 온라인 체스 플랫폼에서 52,000명의 의사결정자의 데이터를 사용하여 AI 피드백이 학습, 기술 격차(skill gap), 그리고 의사결정 전략의 다양성에 미치는 영향을 탐구합니다.

- **Technical Details**: 연구에 따르면, 개인은 실패보다 성공 경험이 있는 상황에서 AI 피드백을 찾을 가능성이 더 높습니다. 그러나 성공에 대한 피드백은 미래 성과를 감소시키고, 실패에 대한 피드백은 성과를 증가시키는 것으로 나타났습니다. 또한, 고숙련 의사결정자는 AI 피드백을 더 자주 구하며, 실패 후에 피드백을 찾는 경향이 더 강하고, 저숙련자들보다 피드백에서 더 큰 혜택을 봅니다.

- **Performance Highlights**: AI 피드백 접근성이 오히려 고숙련자와 저숙련자 간의 기술 격차를 증가시키고, 42개의 주요 플랫폼 업데이트를 통해 AI 피드백 접근성 증가가 지적 다양성의 감소로 이어질 수 있음을 보여줍니다. 이는 AI 피드백으로부터 학습하는 것이 자동적이지 않으며, AI를 올바르게 사용하는 것이 자체적으로 하나의 기술임을 나타냅니다.



### When SAM2 Meets Video Camouflaged Object Segmentation: A Comprehensive Evaluation and Adaptation (https://arxiv.org/abs/2409.18653)
Comments:
          Technical report

- **What's New**: 이번 연구는 Segment Anything Model 2 (SAM2)이 비디오에서 위장된 객체 세분화(video camouflaged object segmentation, VCOS) 작업에서 어떻게 활용될 수 있는지를 조사합니다. VCOS는 색상과 질감이 비슷하고 조명이 좋지 않은 환경에서 객체를 감지하는 어려운 과제입니다.

- **Technical Details**: 연구에서는 SAM2의 성능을 다양한 모델과 프롬프트(클릭, 박스, 마스크)를 사용하여 위장된 비디오 데이터셋에서 평가하였습니다. 또한, 기존의 다중 모달 대형 언어 모델(multimodal large language models, MLLMs) 및 VCOS 방법과 SAM2의 통합을 탐구하였습니다. SAM2를 비디오 위장 데이터셋에 맞추어 세밀하게 조정(fine-tuning)하여 적용하였습니다.

- **Performance Highlights**: SAM2는 비디오에서 위장된 객체를 탐지하는 매우 우수한 제로샷(zero-shot) 능력을 보여주었습니다. 또한, VCOS에 맞게 SAM2의 파라미터를 조정함으로써 이 능력을 더욱 향상시킬 수 있음을 입증하였습니다.



### Enhanced Convolution Neural Network with Optimized Pooling and Hyperparameter Tuning for Network Intrusion Detection (https://arxiv.org/abs/2409.18642)
Comments:
          7 Pages , 2 figures , 4 Tables , Conference paper

- **What's New**: 이번 연구에서는 네트워크 침입 탐지 시스템(Network Intrusion Detection Systems, NIDS)을 위한 향상된 합성곱 신경망(Enhanced Convolutional Neural Network, EnCNN)을 제안합니다. 이 방법론은 KDDCUP'99 데이터셋을 사용하여 성능을 평가하고, 기존의 방법에 비해 10% 이상의 정확도 향상을 보여주었습니다.

- **Technical Details**: 연구에서는 데이터 전처리(data preprocessing), 탐색적 데이터 분석(exploratory data analysis, EDA), 기능 공학(feature engineering)을 포함하는 포괄적인 방법론을 사용하였습니다. EnCNN의 성능을 로지스틱 회귀(Logistic Regression), 결정 트리(Decision Trees), 서포트 벡터 머신(Support Vector Machines, SVM), 랜덤 포레스트(Random Forest), 아다부스트(AdaBoost), 투표 앙상블(Voting Ensemble) 등 다양한 기계 학습 알고리즘과 비교했습니다.

- **Performance Highlights**: EnCNN은 기존 최첨단 접근 방식에 비해 10%의 정확도 향상을 이루었습니다. 이는 실시간 네트워크 침입 탐지에서 EnCNN의 효과성을 보여주며, 보안 위협을 식별 및 완화하고 전체 네트워크의 복원력을 강화하는 강력한 솔루션을 제공함을 의미합니다.



### Quantum Algorithms for Drone Mission Planning (https://arxiv.org/abs/2409.18631)
Comments:
          14 pages, 7 figures

- **What's New**: 이번 논문은 ISR (Intelligence, Surveillance and Reconnaissance) 자산을 활용하여 드론(UAV)이 여러 목표를 방문하는 임무 계획을 최적화하는 방법을 제안합니다. 특히 새로운 제한사항과 목표가 발생할 때 신속하게 해결책을 찾는 데 중점을 두었습니다.

- **Technical Details**: 이 논문에서는 다수의 문제를 Mixed Integer Linear Program (MILP)으로 공식화한 후, 이를 Quadratic Unconstrained Binary Optimisation (QUBO)로 변환하는 과정을 다룹니다. 제안된 공식화는 다양한 제한사항에 맞게 조정 가능하며, qubit의 확장이 명확하게 제공됩니다.

- **Performance Highlights**: 상업용 양자 어닐러(quantum annealer)를 사용하여 QUBO 공식화를 해결한 결과를 현재의 edge classical solvers와 비교했습니다. 또한 QAOA (Quantum Approximate Optimisation Algorithms)를 통해 문제를 해결한 결과도 분석하였고, 그러한 결과 또한 논의하였습니다. 마지막으로, Variational Quantum Eigensolver (VQE) 형식으로 문제를 효율적으로 인코딩하는 방법과 qubit을 효과적으로 활용하기 위한 ansatz를 조정한 방법을 제시하였습니다.



### Entropy, concentration, and learning: a statistical mechanics primer (https://arxiv.org/abs/2409.18630)
- **What's New**: 이 논문은 손실 최소화(loss minimization)를 통해 훈련된 인공지능 모델이 정보 이론(information theory)과 통계 물리학(statistical physics)에서 유래된 원칙에 기반하여 성공적으로 작동함을 보여줍니다. 특히, 통계 역학(statistical mechanics)의 관점에서 이러한 연결을 탐구합니다.

- **Technical Details**: AI 및 머신러닝(ML) 기반의 샘플 농도(sample concentration) 행동을 설명하기 위해 기본 원리(first-principles)에서 시작하여, 통계 역학의 발전이 exponential families의 중요성을 강조하고, 통계(statistics), 물리학(physics), 정보 이론의 양(quantity)과의 관계를 정립하고 있음을 설명합니다.

- **Performance Highlights**: 이 연구는 통계 역학을 활용해 AI 모델링 및 손실 최소화 방법에 대한 새로운 통찰을 제공하며, 기존의 원리를 통합하여 성능 향상을 도모할 수 있는 가능성을 제시합니다.



### Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow (https://arxiv.org/abs/2409.18628)
Comments:
          Keywords: Epistemic Uncertainty - Out-of-Distribution Detection - CT Segmentation - OAR contouring - Radiotherapy

- **What's New**: 본 연구는 방사선 치료 계획에서의 목표 구조물 및 위험 장기(Organ-at-Risk, OAR)의 윤곽을 정확히 지정하는 것의 중요성을 강조하며, 최근 딥러닝(deep learning)의 발전을 통해 OAR 윤곽화 성능을 개선했으나, OOD(out-of-distribution) 시나리오의 신뢰성 문제를 다루고 있다. 특히, epistemic uncertainty(계량적 불확실성) 추정 통합을 통해 OOD 감지를 위한 새로운 방법론을 제시한다.

- **Technical Details**: 연구에서는 OAR 윤곽화 워크플로우에 epistemic uncertainty estimation을 통합하여 임상적으로 관련 있는 시나리오에서 OOD를 감지하는 방법을 제안한다. 구체적으로 설계된 데이터 세트를 사용하여 OOD 감지를 위한 고급 통계적 방법을 도입하고, 예측의 신뢰성이 떨어지는 사례를 식별하는 데 효과적임을 입증한다.

- **Performance Highlights**: 이 연구에서 제안한 접근법은 OOD 감지를 위한 AUC-ROC(Area Under the Curve - Receiver Operating Characteristic)를 0.95로 달성하였으며, 임플란트 사례에 대한 특이도(specificity) 0.95 및 민감도(sensitivity) 0.92를 기록하였다. 이는 모델 예측의 신뢰성을 판단하는 데 있어 전문가의 검토가 필요한 경우를 효과적으로 표시하는 데 기여한다.



### Model-based Preference Optimization in Abstractive Summarization without Human Feedback (https://arxiv.org/abs/2409.18618)
Comments:
          Accepted by EMNLP 2024

- **What's New**: 본 연구에서는 인간 피드백 없이 모델의 요약 능력을 향상시키기 위한 새로운 접근 방식인 Model-based Preference Optimization (MPO)을 소개합니다.

- **Technical Details**: MPO는 다양한 decoding strategies를 활용하여 모델이 생성한 preference dataset을 기반으로 LLMs를 미세 조정합니다. 기존의 Direct Preference Optimization (DPO) 방식과는 달리, MPO는 비싼 인간 피드백에 의존하지 않습니다.

- **Performance Highlights**: MPO를 적용한 결과, 표준 요약 데이터셋에서 생성된 요약의 품질이 크게 향상되었습니다. 다양한 평가 지표에서 성능 개선이 나타났습니다.



### TemporalPaD: a reinforcement-learning framework for temporal feature representation and dimension reduction (https://arxiv.org/abs/2409.18597)
- **What's New**: TemporalPaD는 시계열 데이터셋을 위한 새로운 end-to-end 딥러닝 프레임워크로, 강화 학습(reinforcement learning)과 신경망(neural networks)을 통합하여 특성 표현(feature representation) 및 특성 감소(feature reduction)를 동시에 진행할 수 있도록 설계되었습니다.

- **Technical Details**: TemporalPaD는 Actor-Critic(AC) 프레임워크를 기반으로 하는 세 가지 협력 모듈인 Policy Module(정책 모듈), Representation Module(표현 모듈), Classification Module(분류 모듈)로 구성됩니다. 정책 모듈은 RL을 통해 차원 축소를 담당하고, 표현 모듈은 특성을 추출하며, 분류 모듈은 비평가 역할을 합니다.

- **Performance Highlights**: TemporalPaD는 29개의 UCI 데이터셋을 사용하여 10회 독립 테스트 및 10겹 교차 검증을 통해 종합적으로 평가되었습니다. 또한, 실제 DNA 분류 문제에 적용하여 우수한 성능을 입증하였습니다. 이 프레임워크는 구조화된 데이터와 시퀀스 데이터셋 모두에 적용 가능합니다.



### Analysis of Truncated Singular Value Decomposition for Koopman Operator-Based Lane Change Mod (https://arxiv.org/abs/2409.18586)
Comments:
          Submitted to the 21st International Conference on Informatics in Control, Automation and Robotics (ICINCO 2024)

- **What's New**: 자동 운전(context of autonomous driving)에서 차량 성능 및 안전성을 향상시키기 위한 복합 동적 시스템 이해 및 모델링의 중요성에 대한 연구가 진행되었습니다. 특히, 최근에 강조된 방법인 Koopman operators와 그 근사 방식인 Extended Dynamic Mode Decomposition (EDMD)에 대한 연구가 포함되어 있습니다.

- **Technical Details**: 이 연구에서는 Koopman operators로부터 대규모 데이터 세트를 효율적으로 근사하기 위해 특히 truncated SVD(특이값 분해)를 사용합니다. EDMD에서 사용되는 다양한 basis functions의 평가가 진행되며, lane change behavior 모델을 나타내기 위한 truncated SVD의 순위도 매겨집니다. 이 과정의 목적은 계산 효율성(computational efficiency)과 정보 손실(information loss) 간의 균형을 맞추는 것입니다.

- **Performance Highlights**: 연구 결과에 따르면, truncated SVD 기법이 계산 교육 시간(computational training time)을 크게 줄이지 못하고, 상당한 정보 손실을 초래한다는 점이 발견되었습니다.



### An Enhanced Federated Prototype Learning Method under Domain Shif (https://arxiv.org/abs/2409.18578)
Comments:
          8 pages, 6 figures

- **What's New**: 이 논문은 Federated Learning (FL)에서 서로 다른 도메인에서 샘플링된 데이터의 이질성(heterogeneity)이 모델 성능에 미치는 영향을 해결하기 위해 새로운 방식을 제안합니다. 특히, variance-aware dual-level prototype clustering을 도입하고 $
abla$-sparsity prototype loss를 사용하여 intra-class similarity와 inter-class similarity를 조절합니다.

- **Technical Details**: 제안된 알고리즘은 Federated Prototype Learning with Convergent Clusters (FedPLCC)로 명명되며, 클러스터 내에서 특징이 수렴하도록 개선되었습니다. 클러스터의 크기에 따라 각 프로토타입에 가중치를 부여하여 inter-class 거리를 증가시키고, 서로 다른 도메인에서 오는 프로토타입의 거리를 줄이기 위해 손실 함수 계산을 위해 일정 비율의 프로토타입만 선택합니다.

- **Performance Highlights**: Digit-5, Office-10 및 DomainNet 데이터셋에서 평가한 결과, 제안된 방법은 기존 접근 방식에 비해 더 나은 성능을 보였습니다.



### Efficient Noise Mitigation for Enhancing Inference Accuracy in DNNs on Mixed-Signal Accelerators (https://arxiv.org/abs/2409.18553)
- **What's New**: 본 논문에서는 아날로그 신경망의 정확도에 미치는 프로세스 유도 및 노화 관련 변동의 영향을 완화하여 신경 모델의 강인성을 향상시키는 프레임워크를 제안합니다.

- **Technical Details**: 변동은 활성화의 정밀도에 영향을 미치는 노이즈로 모델링되며, 사전 훈련된 모델의 선택된 레이어 사이에 삽입된 디노이징 블록(denoising block)을 소개합니다. 디노이징 블록을 훈련하여 다양한 노이즈 수준에 대한 모델의 강인성을 크게 증가 시킬 수 있음을 입증하였습니다. 디노이징 블록 추가로 인한 오버헤드를 최소화하기 위해 최적의 삽입 지점을 식별하는 탐색 알고리즘을 제시하고, 혼합 신호 가속기에 통합할 수 있는 효율적인 디노이징 블록 아키텍처를 제안합니다.

- **Performance Highlights**: DNN 모델을 ImageNet 및 CIFAR-10 데이터셋에서 훈련하여 접근 방식을 평가한 결과, 평균적으로 2.03%의 파라미터 카운트 오버헤드를 수용함으로써 변동으로 인한 정확도 감소가 31.7%에서 1.15%로 줄어드는 것을 보여주었습니다.



### Research on Predicting Public Opinion Event Heat Levels Based on Large Language Models (https://arxiv.org/abs/2409.18548)
Comments:
          conference

- **What's New**: 최근 몇 년간 큰 언어 모델(large language models)의 급속한 발전으로 인해, GPT-4o와 같은 여러 모델이 언어 작업에서 인간의 성능을 초월하는 탁월한 능력을 보여주었습니다. 이 연구는 공공 여론 분석 분야에서의 잠재적 응용을 탐구합니다.

- **Technical Details**: 이 연구에서는 2022년 7월부터 2023년 12월 사이에 수집된 62,836개의 중국 핫 이벤트 데이터를 전처리하고 분류했습니다. 각 이벤트의 온라인 확산 열 지수를 기반으로 MiniBatchKMeans 알고리즘을 사용하여 이벤트를 자동으로 클러스터링하고 네 가지 열 수준으로 분류했습니다. 이후 각 열 수준에서 250개의 이벤트를 랜덤으로 선택하여 총 1,000개의 평가 데이터셋을 구축했습니다.

- **Performance Highlights**: 평가 과정에서 다양한 큰 언어 모델을 사용하여 두 가지 시나리오(참조 사례 없는 경우와 유사한 사례 참조가 있는 경우)에서 이벤트 열 수준 예측의 정확성을 평가했습니다. 결과적으로 GPT-4o와 DeepseekV2가 후자의 경우 최고의 성능을 보이며 각각 41.4%와 41.5%의 예측 정확도를 기록했습니다. 특히 저온 이벤트(Level 1)의 경우 두 모델의 예측 정확도는 각각 73.6%와 70.4%에 달했습니다. 전체적인 예측 정확도는 열 수준이 높아질수록 감소하는 경향을 보였습니다.



### An Epistemic Human-Aware Task Planner which Anticipates Human Beliefs and Decisions (https://arxiv.org/abs/2409.18545)
Comments:
          15 pages, 4 figures, 1 table

- **What's New**: 이번 연구에서는 인간과 로봇 간의 신뢰도 차이가 큰 상황에서 단체 행동(shared execution experience)이 간헐적으로 이루어지는 경우를 위한 Human-Aware Task Planning 프레임워크를 확장하였습니다. 특히, 통제할 수 없는 인간 행동을 고려하여 로봇 정책을 구축하는 것이 목표입니다.

- **Technical Details**: 제안된 새로운 계획 프레임워크는 AND-OR 검색 기반의 솔버(solver)를 기반으로 하며, 상황 평가(situation assessment) 및 관점 취득(perspective taking)을 포함한 지식 추론(knowledge reasoning)을 통합합니다. 이 시스템은 잠재적 진전을 동적으로 모델링하고 관리하며, 에이전트가 작업 실행 경험을 공유할 때와 공유하지 않을 때를 정확히 추적합니다.

- **Performance Highlights**: 초기 실험은 새로운 도메인과 적응된 도메인에서 수행되었으며, 프레임워크의 효과를 입증하였습니다. 새로운 솔버는 로봇과 인간의 다르게 믿는 맥락을 추정할 수 있어, 로봇이 적절한 시점에 소통(communication)하거나 작업 수행을 연기할 수 있도록 계획을 합성(synthesis)할 수 있게 합니다.



### MIMII-Gen: Generative Modeling Approach for Simulated Evaluation of Anomalous Sound Detection System (https://arxiv.org/abs/2409.18542)
- **What's New**: 본 논문에서는 기계 소음에서의 이상 탐지(anomaly detection) 시스템 개발을 위한 새로운 접근 방식을 제안합니다. 특히, 레이턴트 확산(latent diffusion) 기반 모델을 사용하여 다양한 이상(anomalies)을 생성함으로써 기존의 데이터 부족 문제를 해결하고자 하였습니다.

- **Technical Details**: 제안된 방법에서는 Flan-T5 모델을 활용하여 오디오 파일 메타데이터에서 파생된 캡션을 인코딩하고, U-Net 아키텍처를 사용하여 조건부 생성(conditional generation)을 수행합니다. 이는 EnCodec 레이턴트 공간(latent space) 내에서 오디오 신호를 생성하여 높은 맥락적 관련성(contextual relevance)과 품질을 보장합니다.

- **Performance Highlights**: 제작된 소리의 품질은 Fréchet Audio Distance (FAD) 점수와 기타 메트릭스를 통해 객관적으로 평가되었으며, 기존 모델들을 초월하는 성능을 보였습니다. 또한, 생성된 데이터를 활용한 이상 탐지 시스템의 평가 결과 AUC(Area Under Curve) 점수가 원본 데이터와 4.8% 차이를 보이며, 생성된 데이터의 효과성을 입증하였습니다.



### EmoPro: A Prompt Selection Strategy for Emotional Expression in LM-based Speech Synthesis (https://arxiv.org/abs/2409.18512)
- **What's New**: 최근 음성 합성 모델의 발전으로, 방대한 데이터셋을 활용한 제로샷(zero-shot) 능력의 향상이 두드러진다. 이런 발전에도 불구하고, 프롬프트(prompt)의 선택이 음성 생성의 품질에 중대한 영향을 미친다는 점에 주목하였다.

- **Technical Details**: 이 논문에서는 감정 조절이 가능한 음성 합성을 위한 두 단계의 프롬프트 선택 전략인 EmoPro를 제안한다. 이 전략은情緒 표현 강도(emotional expression strength), 음성 품질(speech quality), 텍스트-감정 일관성(text-emotion consistency), 모델 생성 성능(model generation performance)이라는 네 가지 관점에서 프롬프트를 평가하여 선택한다.

- **Performance Highlights**: 실험 결과, 제안된 방법으로 선택된 프롬프트는 기본 참조 모델(baseline)으로 얻은 것보다 더 감정적으로 표현력이 풍부하고 매력적인 합성 음성을 생성하는 것으로 나타났다. 오디오 샘플과 코드가 제공될 예정이다.



### Fairness-aware Multiobjective Evolutionary Learning (https://arxiv.org/abs/2409.18499)
Comments:
          14 pages

- **What's New**: 이 논문은 Multiobjective evolutionary learning (MOEL)에서 모델 훈련 중 동적으로 공정성 측정치의 대표 세트를 결정하는 방법을 제안합니다. 이는 이전에 정해진 정적 세트 대신 훈련 중에 적응적으로 변경될 수 있습니다.

- **Technical Details**: 기존의 MOEL 접근법은 데이터셋과 사전 지식에 의존하고 상당한 계산 비용이 요구되며, 공정성 측정 지표가 모델 훈련 과정에 따라 다를 수 있습니다. 본 연구에서는 12개의 잘 알려진 벤치마크 데이터셋에서 실험을 수행하여, 동적으로 결정된 공정성 측정 세트를 최적화 목표로 사용하며, 이는 훈련 과정 중에 시간에 따라 변화할 수 있습니다.

- **Performance Highlights**: 제안된 MOEL 프레임워크는 정확도와 25개의 공정성 측정을 포함하여 불공정성을 완화하기 위한 최신 방법들과 비교하여 뛰어난 성능을 보였습니다. 이러한 결과는 훈련 중 최적화 목표를 동적으로 설정하는 것이 중요함을 강조합니다.



### Towards Diverse Device Heterogeneous Federated Learning via Task Arithmetic Knowledge Integration (https://arxiv.org/abs/2409.18461)
Comments:
          NeurIPS 2024

- **What's New**: 이번 논문에서는 Fedrated Learning(Federated Learning, FL)의 한계를 극복하기 위해 TAKFL이라는 새로운 KD 기반 프레임워크를 제안합니다. 이 프레임워크는 다양한 이질적인 장치 모델의 지식 전이를 독립적으로 수행하여, 각 장치의 고유한 기여를 보존합니다.

- **Technical Details**: TAKFL은 각 장치 프로토타입의 앙상블에서 지식 전이를 별도의 작업으로 처리하며, 각 장치의 정보를 효과적으로 증류할 수 있도록 설계되었습니다. 또한, KD 기반의 self-regularization 기법을 도입하여 noise와 비지도 앙상블 증류 과정에서 발생하는 문제를 완화시킵니다.

- **Performance Highlights**: TAKFL은 컴퓨터 비전(CV) 및 자연어 처리(NLP) 작업에서 종합적인 평가를 수행하였으며, 다양한 데이터셋과 설정에서 SOTA(State Of The Art) 결과를 달성하여 기존 KD 기반 방법들보다 월등한 성능을 보였습니다.



### Review of Digital Asset Development with Graph Neural Network Unlearning (https://arxiv.org/abs/2409.18455)
- **What's New**: 이 논문은 디지털 자산 분야에서 Graph Neural Networks (GNNs)의 역할과 이에 맞춘 혁신적인 unlearning 기술을 소개합니다. 특히, 데이터 개인 정보 보호와 규제 준수의 필요성이 증가하는 배경에서 이러한 기술이 중요하다는 점을 강조합니다.

- **Technical Details**: 이 연구에서는 unlearning 전략을 데이터 기반 근사(data-driven approximation)와 모델 기반 근사(model-driven approximation)로 두 가지 주요 클래스로 분류합니다. 각각의 접근 방법은 특정 노드의 영향을 제거하기 위한 그래프 구조 변경과 GNN 내부 파라미터 및 아키텍처 수정 등을 포함합니다.

- **Performance Highlights**: 이 논문에서 제안된 방법은 사기 탐지, 위험 평가, 토큰 관계 예측 및 분산 거버넌스와 같은 다양한 사용 사례에서 효율적입니다. 또한, 실시간 금융 애플리케이션에서 모델 성능과 데이터 unlearning 요구사항 간의 균형을 맞추는 데 있어 직면하는 도전 과제를 논의하며, 두 가지 unlearning 전략의 장점을 결합한 하이브리드 접근 방식을 제안하여 GNN의 효율성과 효과성을 향상시키고자 합니다.



### Leveraging Long-Context Large Language Models for Multi-Document Understanding and Summarization in Enterprise Applications (https://arxiv.org/abs/2409.18454)
- **What's New**: 이 논문은 다양한 분야에서 비구조화 데이터의 급증에 따른 다중 문서 이해 및 요약의 중요성을 강조합니다. 전통적인 접근 방식이 정보의 맥락을 잘 잡지 못하고 논리적 일관성을 유지하지 못하는 문제를 다루며, Long-context Large Language Models (LLMs)의 사용을 탐구합니다.

- **Technical Details**: 본 연구는 다중 문서 요약을 효과적으로 수행하기 위한 Long-context LLM의 워크플로우를 설명하며, 법률, 인사(HR), 재무, 소싱과 같은 기업 기능, 의료 및 뉴스 도메인에서의 사례 연구를 다룹니다. 이러한 사례 연구는 효율성과 정확성 모두에서 향상을 보여줍니다.

- **Performance Highlights**: 논문은 데이터셋의 다양성, 모델 확장성 및 편향 완화, 사실 정확성과 같은 윤리적 고려사항과 같은 기술적 장애물에 대한 철저한 분석을 포함하고 있으며, LLM의 기능과 응용 프로그램을 증강하기 위한 미래 연구 방향을 제시합니다.



### State-free Reinforcement Learning (https://arxiv.org/abs/2409.18439)
- **What's New**: 이 연구에서는 	extit{상태 없는 RL} (state-free RL) 문제를 다루며, 알고리즘이 환경과 상호작용하기 전에 상태 정보가 없음을 제시합니다.

- **Technical Details**: 우리는 도달할 수 있는 상태 집합 ${S}^	ext{Π} := igl	m{s | 	ext{max}_{	ext{π} 	ext{in Π}} q^{P, 	ext{π}}(s) > 0} igr	m$를 정의하고, 상태 공간 $S$에 대한 정보 없이도 작동하는 알고리즘을 설계했습니다. 이 알고리즘의 후회(regret)는 ${S}$와 완전히 독립적이며 오로지 ${S}^	ext{Π}$에만 의존합니다.

- **Performance Highlights**: 이 연구는 하이퍼 파라미터 조정이 필요 없는 	extit{파라미터 없는 RL} (parameter-free RL) 알고리즘 설계의 구체적인 첫 걸음으로 볼 수 있습니다.



### Multi-agent Reinforcement Learning for Dynamic Dispatching in Material Handling Systems (https://arxiv.org/abs/2409.18435)
- **What's New**: 본 논문은 다중 에이전트 강화 학습(MARL) 접근 방식을 통해 동적 디스패칭(dynamic dispatching) 전략을 학습하는 방법을 제안합니다. 이 연구는 다양한 산업에서 자재 처리 시스템의 처리량 최적화에 중요한 역할을 합니다.

- **Technical Details**: 본 연구에서는 실제 시스템의 복잡성을 반영한 자재 처리 환경을 개발하였으며, 다양한 위치에서의 활동, 물리적 제약 및 고유의 불확실성과 같은 요소를 포함합니다. 학습 중 탐색(employ exploration)을 개선하기 위해 기존의 동적 디스패칭 휴리스틱(heuristics)을 통합하는 방법을 제안합니다.

- **Performance Highlights**: 실험 결과, 제안한 방법은 중앙 처리량(median throughput) 측면에서 기존 휴리스틱보다 최대 7.4% 향상된 성능을 보여주었습니다. 또한 서로 다른 기능을 가진 여러 에이전트를 훈련할 때 다양한 아키텍처가 MARL 성능에 미치는 영향을 분석하였습니다. 첫 번째 MARL 에이전트를 휴리스틱으로 사용하여 두 번째 MARL 에이전트를 훈련함으로써 성과를 더욱 개선할 수 있음을 보여주고 있습니다.



### Easy2Hard-Bench: Standardized Difficulty Labels for Profiling LLM Performance and Generalization (https://arxiv.org/abs/2409.18433)
Comments:
          NeurIPS 2024 Datasets and Benchmarks Track

- **What's New**: Easy2Hard-Bench라는 새로운 벤치마크 데이터셋의 개발은 어려운 문제에서 쉽게 문제를 풀어내는 일반화 능력을 평가하기 위해 제안되었습니다. 각 문제는 숫자 형태의 난이도 점수로 주석이 달려 있습니다.

- **Technical Details**: 이 데이터셋은 수학, 프로그래밍 문제, 체스 퍼즐, 추리 문제 등 다양한 도메인에서 총 6개의 벤치마크 데이터셋으로 구성되어 있습니다. Item Response Theory (IRT)와 Glicko-2 모델과 같은 난이도 평가 시스템을 활용하여 문제에 대한 숫자 난이도 점수를 일관되게 부여합니다.

- **Performance Highlights**: 여섯 개의 최첨단 LLMs에 대한 광범위한 실험을 통해 다양한 난이도 수준에서의 성능과 일반화 능력을 총체적으로 분석하였으며, 이는 LLM 일반화에 대한 미래 연구에 영감을 줄 것입니다.



### A3: Active Adversarial Alignment for Source-Free Domain Adaptation (https://arxiv.org/abs/2409.18418)
Comments:
          Accepted at ICMLA 2024

- **What's New**: 본 논문은 레이블이 없는 대상 도메인으로부터 지식을 전이하기 위해 레이블이 있는 출처 도메인에서 지식을 전이하는 비지도 도메인 적응(Unsupvised Domain Adaptation, UDA) 분야의 최신 동향인 Source-free UDA에 대한 새로운 접근법인 Active Adversarial Alignment (A3)를 제안합니다.

- **Technical Details**: A3는 self-supervised learning, adversarial training, 및 active learning을 결합하여 견고한 Source-free UDA를 가능하게 합니다. 이 프레임워크는 acquisition function을 사용하여 유익하고 다양한 데이터를 능동적으로 샘플링하고 모델을 adversarial losses와 consistency regularization을 통해 적응시킵니다. 이는 출처 데이터에 접근하지 않고도 분포를 정렬합니다.

- **Performance Highlights**: A3는 효과적인 도메인 정렬 및 노이즈 감소를 위해 능동적 및 적대적 학습의 시너지를 활용하여 Source-free UDA를 발전시킵니다.



### VickreyFeedback: Cost-efficient Data Construction for Reinforcement Learning from Human Feedback (https://arxiv.org/abs/2409.18417)
Comments:
          16 pages, 5 figures

- **What's New**: 이 논문은 Reinforcement Learning from Human Feedback (RLHF)의 비용 효율성에 초점을 맞추고 있습니다. 기존의 preference dataset(선호도 데이터셋)의 경제적 유용성에 대한 고려가 부족했음을 지적하며, 이를 해결하기 위해 새로운 경매 메커니즘을 도입합니다.

- **Technical Details**: RLHF는 대규모 언어 모델(LLM)의 결과에 대한 인간의 선호도를 반영하기 위해 인간의 피드백을 활용합니다. 논문에서는 기존 알고리즘이 복잡한 비전이성(preference)이거나 순환적 관계를 처리하지 못하는 문제를 다룹니다. 경매 메커니즘을 사용하여 선호도 데이터 수집의 효율성을 높이는 방법을 제시합니다.

- **Performance Highlights**: 실험 결과, 제안된 경매 기반 프로토콜은 고품질 피드백에 집중함으로써 LLM의 fine-tuning에서 비용 효율성을 개선하면서도 만족스러운 모델 성능을 유지하는 데 기여한다는 것이 입증되었습니다.



### SciDFM: A Large Language Model with Mixture-of-Experts for Scienc (https://arxiv.org/abs/2409.18412)
Comments:
          12 pages, 1 figure, 9 tables. Technical Report, Under Review

- **What's New**: 최근 대형 언어 모델(LLMs)을 활용하여 과학적 발견을 도우려는 관심이 급증하고 있습니다. 그러나 대부분의 LLM은 일반 과학에만 초점을 맞추고 있을 뿐, 화학 분자와 아미노산 서열과 같은 분야별 지식이 부족합니다. 이를 해결하기 위해 SciDFM이라는 전문가 혼합 모델을 도입하였으며, 이는 처음부터 훈련되어 대학 수준의 과학적 추론을 수행하고 분자 및 아미노산 서열을 이해할 수 있습니다.

- **Technical Details**: SciDFM은 대규모 훈련 데이터 집합을 수집하여 여러 과학 분야의 논문과 서적, 그리고 분야별 데이터베이스에서 수집한 데이터를 포함합니다. 또한, 사전 학습된 모델을 많은 지시 데이터로 추가 세부 조정하여 하위 기초 평가에서의 성능을 향상시킵니다.

- **Performance Highlights**: 실험 결과 SciDFM은 SciEval 및 SciQ와 같은 일반 과학 기초 평가에서 강력한 성능을 보이며, 동등한 크기 모델 중에서 분야별 평가에서도 SOTA(State Of The Art) 성능을 달성하였습니다. 우리는 전문가 선택 결과가 다른 분야의 데이터에 따라 달라진다는 점을 분석하였습니다. 또한 더 넓은 연구 커뮤니티를 위해 SciDFM을 오픈소스했습니다.



### BoT-Drive: Hierarchical Behavior and Trajectory Planning for Autonomous Driving using POMDPs (https://arxiv.org/abs/2409.18411)
- **What's New**: 이 논문은 자율 주행에서의 동적 도로 환경의 불확실성을 해결하기 위한 BoT-Drive 계획 알고리즘을 소개합니다.

- **Technical Details**: BoT-Drive는 Partially Observable Markov Decision Process (POMDP) 프레임워크 내에서 행동 및 경로 수준의 불확실성을 다룹니다. 이 알고리즘은 운전 모델을 사용하여 알 수 없는 행동 의도를 특징짓고, 이러한 모델 파라미터를 활용하여 숨겨진 운전 스타일을 추론합니다. 또한 BoT-Drive는 운전 모델을 자율 차량의 의사결정 행동으로 취급하여 POMDP 전의 복잡성을 효과적으로 해소합니다. 안전성과 견고성을 높이기 위해, 계획자는 계획된 고수준 행동에 조건화된 주행 경로를 개선하기 위해 중요 샘플링(importance sampling)을 적용합니다.

- **Performance Highlights**: 실제 데이터에 대한 평가 결과, BoT-Drive는 기존의 계획 방법과 학습 기반 방법 모두를 초월하여 정규 및 복잡한 도시 주행 장면에서 일관되게 높은 성능을 나타내었으며, 주행 안전성과 신뢰성에서 중요한 개선을 보였습니다.



### GenesisTex2: Stable, Consistent and High-Quality Text-to-Texture Generation (https://arxiv.org/abs/2409.18401)
- **What's New**: 이 논문에서는 대규모 텍스트 기반 이미지 확산 모델을 활용한 새로운 텍스처 합성 방법을 제안합니다. 텍스트에서 텍스처로의 변환을 위한 프레임워크를 소개하여 3D 기하학을 위한 텍스처 생성의 도전을 극복하고자 합니다.

- **Technical Details**: 우리의 접근법은 사전 훈련된 diffusion models를 기반으로 하며, self-attention 레이어에서 지역적 주의 재조정 메커니즘(local attention reweighing mechanism)을 도입하여 서로 다른 시점(viewpoint) 간에 공간적 연관성이 있는 패치에 집중하도록 모델을 유도합니다. 또한, 새로운 잠재 공간 병합 파이프라인(latent space merge pipeline)을 제안하여 다양성을 유지하면서도 서로 다른 시점 간의 일관성을 보장합니다.

- **Performance Highlights**: 이 방법은 기존의 최첨단 기술에 비해 텍스처 일관성(texture consistency)과 시각적 품질(visual quality)에서 상당히 우수한 성능을 보였으며, 증류 기반(methods based on distillation) 방법들보다 훨씬 빠른 결과를 제공했습니다. 추가적인 훈련이나 미세 조정(fine-tuning)이 필요 없어, 공공 플랫폼에서 사용할 수 있는 다양한 모델에 쉽게 적용할 수 있습니다.



### Code Vulnerability Repair with Large Language Model using Context-Aware Prompt Tuning (https://arxiv.org/abs/2409.18395)
- **What's New**: 대규모 언어 모델(Large Language Models, LLMs)의 취약한 코드를 탐지 및 수정하는 데에 있어 중요한 문제를 다룬 본 연구에서는, GitHub Copilot을 사용하여 버퍼 오버플로우(vulnerabilities involving buffer overflow) 취약점을 중심으로 연구를 진행했습니다.

- **Technical Details**: 실험 결과, Copilot의 버퍼 오버플로우 취약점 탐지율은 76%로 나타났으나, 취약점 수리율은 단 15%에 그쳤습니다. 이를 개선하기 위해 컨텍스트 인식 프롬프트 튜닝(context-aware prompt tuning) 기법을 제안하여, 다양한 보안 및 코드 맥락에 대한 도메인 지식을 주입하게 됩니다.

- **Performance Highlights**: 이러한 접근 방식을 통해 Copilot의 취약점 수리율은 63%로 증가하며, 도메인 지식 없이 수리한 경우에 비해 4배 이상의 개선을 나타냈습니다.



### Speech to Reality: On-Demand Production using Natural Language, 3D Generative AI, and Discrete Robotic Assembly (https://arxiv.org/abs/2409.18390)
Comments:
          This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. An updated version will replace this version

- **What's New**: 본 논문에서는 자연어(Natural Language)를 사용하여 음성을 물리적인 객체로 변환하는 시스템을 소개합니다. 이 시스템은 3D generative Artificial Intelligence와 로봇 조립 기술을 결합하여, 3D 모델링이나 로봇 프로그래밍에 대한 전문 지식이 없는 사용자도 물리적인 객체를 만들 수 있도록 합니다.

- **Technical Details**: 시스템은 음성을 해석하여 3D 객체를 생성합니다. 생성된 객체는 voxel 컴포넌트로 분리되고, 그 후 최적의 조립 순서가 계산됩니다. 마지막으로 로봇 툴패스(Toolpath)가 생성되어, lattice 기반의 voxel 구성요소를 사용한 이산(discrete) 로봇 조립을 통해 물리 생산에서 발생할 수 있는 문제들을 해결합니다. 이 시스템은 여러 가지 객체(예: 의자, 선반 등)를 조립하는 데 이용될 수 있으며, 조립 과정은 6축 로봇 팔을 사용하여 5분 이내에 완료됩니다.

- **Performance Highlights**: 본 시스템은 다양한 객체를 신속하게 조립할 수 있는 능력을 보여줍니다. 음성 명령을 통해 신속하게 3D 객체를 생성하고 조립할 수 있는 기능은 제조와 디자인 프로세스를 혁신적으로 변화시킬 잠재력이 있습니다.



### Robo-CSK-Organizer: Commonsense Knowledge to Organize Detected Objects for Multipurpose Robots (https://arxiv.org/abs/2409.18385)
- **What's New**: 이번 논문에서는 로봇의 맥락 인식 능력을 향상시키기 위해 고전 지식 기반에서 상식(commonsense knowledge)을 통합한 Robo-CSK-Organizer 시스템을 소개합니다. 이 시스템은 탐지된 객체를 작업에 적합한 방식으로 분류하여 조직할 수 있도록 돕습니다.

- **Technical Details**: Robo-CSK-Organizer는 ChatGPT와 같은 딥러닝 도구에만 의존하는 시스템과는 달리 다음과 같은 여러 가지 장점을 제공합니다. 명확성이 뛰어나며, 객체 배치에서 일관성을 유지합니다. 또한, 다양한 작업 기반 분류(task-based classifications)에 적응할 수 있습니다. 이 시스템은 설명 가능한 AI(explainable AI)에 기여하여 신뢰(trust)와 인간-로봇 협력(human-robot collaboration)을 향상시키는 데 도움을 줍니다.

- **Performance Highlights**: 실험 결과, 가정용 로봇 환경을 시뮬레이션하여 Robo-CSK-Organizer가 맥락적으로 관련된 위치에 객체를 배치하는 데 뛰어난 성능을 보였습니다. 이 연구는 AI 기반 시스템이 인간의 인지(cognition) 수준에 더 가까운 상식에 기반한 의사결정을 할 수 있는 능력을 강조합니다.



### Adaptive Learning of the Latent Space of Wasserstein Generative Adversarial Networks (https://arxiv.org/abs/2409.18374)
- **What's New**: 본 연구에서는 새로운 프레임워크인 latent Wasserstein GAN (LWGAN)을 제안하여 Wasserstein auto-encoder와 Wasserstein GAN을 융합했습니다. 이를 통해 데이터 매니폴드(manifold)의 내재 차원(intrinsic dimension)을 적응적으로 학습할 수 있습니다.

- **Technical Details**: LWGAN은 인코더 네트워크와 제너레이터 네트워크를 통해 학습된 인코딩 분포의 내재 차원이 데이터 매니폴드의 차원과 같음을 입증합니다. 이론적으로, 우리의 추정된 내재 차원이 데이터 매니폴드의 진정한 차원의 일관된 추정임을 수립했습니다. 또한 LWGAN의 일반화 오류(generalization error)에 대한 상한을 제공합니다.

- **Performance Highlights**: 종합적인 실험 결과, LWGAN은 여러 시나리오에서 올바른 내재 차원을 식별할 수 있으며, 학습된 잠재 분포(latent distribution)로부터 고품질의 합성 데이터(synthetic data)를 생성할 수 있음을 보여주었습니다.



### Multi-hypotheses Conditioned Point Cloud Diffusion for 3D Human Reconstruction from Occluded Images (https://arxiv.org/abs/2409.18364)
Comments:
          17 pages, 7 figures, accepted NeurIPS 2024

- **What's New**: 본 논문에서는 심각한 가림(occlusion) 상황에서도 3D 인간 형태 재구성을 위한 새로운 파이프라인, MHCDIFF를 제안합니다. 이 방법은 픽셀 정렬된 세부 3D 인간 재구성을 위해 점 구름(diffusion) 모델을 도입합니다.

- **Technical Details**: MHCDIFF는 단일 RGB 이미지에서 기하학적 세부 사항을 캡처하기 위해 다수의 가설화된 SMPL(-X) 메쉬로부터 로컬 특징(local features)을 추출하고 이 특징 집합을 활용하여 확산 모델(diffusion model)을 조정합니다. 점 구름 확산(point cloud diffusion) 모델은 누락된(osculaded) 영역을 생성하기 위해 전체적인 일관성(global consistent features)을 캡처하며, 잡음 제거(denoising) 과정에서 잘못 정렬된 SMPL 메쉬를 수정합니다.

- **Performance Highlights**: CAPE 및 MultiHuman 데이터셋에서의 실험 결과, 제안된 방법은 SMPL, 암묵적 함수(implicit functions), 점 구름 확산(point cloud diffusion) 및 이들의 결합 기반의 다양한 최신 기술(SOTA) 방법들과 비교하여 우수한 성능을 보였습니다.



### Tracking Software Security Topics (https://arxiv.org/abs/2409.18351)
- **What's New**: 이번 논문에서는 소프트웨어 보안(Security) 관련 주제를 실시간으로 추적할 수 있도록 돕는 새로운 도구, SOSK를 제안합니다.

- **Technical Details**: SOSK는 사용자가 보안 보고서(Report) 집합을 가져와 이를 전처리(pre-process)하고, 텍스트 설명에서 가장 중요한 키워드(Keywords)를 추출합니다. 키워드의 임베딩 벡터(Embedding vector) 유사성을 기반으로 하여, SOSK는 사용자 제공 키워드 세트에서 키워드 세트를 확장하거나 정제할 수 있습니다.

- **Performance Highlights**: 초기 평가 결과, SOSK는 키워드를 효과적으로 확장하고, 사용자 요청에 맞는 보안 보고서를 성공적으로 검색할 수 있음을 보여주었습니다.



### A Generalized LLM-Augmented BIM Framework: Application to a Speech-to-BIM system (https://arxiv.org/abs/2409.18345)
- **What's New**: 이 논문은 건물 정보 모델링(BIM) 작업을 가속화하기 위해 LLM(대형 언어 모델)을 활용한 새로운 프레임워크를 제안합니다. 이는 전통적인 그래픽 사용자 인터페이스를 대체할 가능성을 보여줍니다.

- **Technical Details**: 제안된 프레임워크는 6단계로 구성됩니다: 해석(interpret) - 채우기(fill) - 일치(match) - 구조화(structure) - 실행(execute) - 검토(check). 이 과정은 텍스트에서 BIM 또는 음성을 BIM으로 변환하는 방식을 포함합니다.

- **Performance Highlights**: NADIA-S라는 음성 기반 BIM 응용 프로그램을 구현하여 제안된 프레임워크의 적합성을 입증하였고, 외부 벽 세부 사항을 예로 들었습니다.



### DRL-STNet: Unsupervised Domain Adaptation for Cross-modality Medical Image Segmentation via Disentangled Representation Learning (https://arxiv.org/abs/2409.18340)
Comments:
          MICCAI 2024 Challenge, FLARE Challenge, Unsupervised domain adaptation, Organ segmentation, Feature disentanglement, Self-training

- **What's New**: 본 논문에서는 cross-modality(크로스 모달리티) 의료 이미지 분할을 위한 새로운 프레임워크인 DRL-STNet을 제안합니다. 이 방법은 Generative Adversarial Networks(GANs), Disentangled Representation Learning(DRL), Self-Training(ST)를 활용합니다.

- **Technical Details**: DRL-STNet은 GAN 내에서 DRL을 이용하여 이미지를 소스 모달리티에서 타겟 모달리티로 변환합니다. 초기 단계에서는 변환된 이미지와 소스 레이블로 분할 모델을 학습한 후, 합성 이미지와 실제 이미지의 결합을 통해 pseudo-labels(의사 레이블) 및 실제 레이블로 반복적으로 미세 조정합니다.

- **Performance Highlights**: 제안된 DRL-STNet은 FLARE 도전 과제 데이터셋에서 복부 장기 분할에서 11.4% Dice similarity coefficient(다이스 유사도 계수) 및 13.1% Normalized Surface Dice metric(정규화된 표면 다이스 측정치) 향상을 보여 주며, 각각 74.21% 및 80.69%의 점수를 기록했습니다. 평균 실행 시간은 41초이며, GPU 메모리-시간 곡선 아래 면적은 11,292 MB입니다.



### AER-LLM: Ambiguity-aware Emotion Recognition Leveraging Large Language Models (https://arxiv.org/abs/2409.18339)
Comments:
          5 pages, 4 figures

- **What's New**: 본 연구는 LLMs(대규모 언어 모델)의 감정 인식 능력에 대한 새로운 접근을 제공합니다. 특히, 단일 감정 레이블에 국한되지 않고 모호한 감정을 인식하는 능력을 탐구하여 감정 지능(emotional intelligence)의 중요한 측면을 다루고 있습니다.

- **Technical Details**: 연구에서는 LLMs의 제로샷(zero-shot) 및 몇샷(few-shot) 프롬팅(prompts) 기술을 사용하여 문맥 정보(context information)를 과거 대화와 함께 통합함으로써 모호한 감정을 인식하는 과정이 설계되었습니다. 이를 통해 LLMs의 강력한 일반화 능력과 인-컨텍스트 학습(in-context learning)을 활용합니다.

- **Performance Highlights**: 실험 결과, LLMs는 모호한 감정을 인식하는 데 있어 상당한 잠재력을 보여주었으며, 문맥 정보를 포함할 때 그 효과성이 크게 증가함을 발견했습니다. 또한, 덜 모호한 감정을 인식하는 데 높은 효율성을 보이며, 더 모호한 감정들을 인식할 가능성도 제시하였습니다.



### Embodied-RAG: General non-parametric Embodied Memory for Retrieval and Generation (https://arxiv.org/abs/2409.18313)
Comments:
          Web: this https URL

- **What's New**: 새로운 연구에서는 Embodied-RAG라는 프레임워크를 소개하여 로봇의 탐색 및 학습 능력을 향상시키는 동시에, 비모수 메모리 시스템을 활용하여 계층적인 지식을 구성할 수 있는 방법을 제시하고 있습니다.

- **Technical Details**: Embodied-RAG는 다양한 환경 및 쿼리 유형에서 공간적(spatial) 및 의미적(semantic) 해상도를 처리할 수 있는 구조를 가지고 있습니다. 이 시스템의 핵심은 세밀한 언어 설명을 저장하는 의미적 숲(semantic forest) 형태의 메모리에 있으며, 이를 통해 다양한 로봇 플랫폼에서 맥락에 맞는 출력을 효율적으로 생성할 수 있습니다.

- **Performance Highlights**: Embodied-RAG는 19개 환경에서 200개 이상의 설명 및 탐색 쿼리를 성공적으로 처리하여 RAG를 로봇공학(domain of robotics) 분야와 연결하는 데 효과적임을 입증하였습니다.



### Harnessing Wavelet Transformations for Generalizable Deepfake Forgery Detection (https://arxiv.org/abs/2409.18301)
- **What's New**: 이번 논문에서는 Deepfake 탐지 방법의 약점을 해결하기 위해 Wavelet-CLIP이라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 Wavelet 변환(Wavelet Transforms)과 ViT-L/14 아키텍처에서 얻은 특징을 통합하여, 복잡한 Deepfake를 효과적으로 탐지할 수 있도록 설계되었습니다.

- **Technical Details**: Wavelet-CLIP는 Wavelet Transform을 이용하여 이미지의 공간적(spatial) 및 주파수(frequency) 특징을 깊이 분석합니다. 사전 훈련된 CLIP 방법으로 ViT-L/14 아키텍처의 특징들을 활용하여 높은 효율성을 발휘합니다.

- **Performance Highlights**: 테스트 결과, Wavelet-CLIP는 교차 데이터에 대한 일반화(cross-dataset generalization)에서 평균 AUC 0.749, 보이지 않는 Deepfake에 대한 강인성(robustness)에서 0.893을 기록하여 기존의 최첨단 방법들을 능가하는 뛰어난 성능을 보여주었습니다.



### SOAR: Self-supervision Optimized UAV Action Recognition with Efficient Object-Aware Pretraining (https://arxiv.org/abs/2409.18300)
- **What's New**: 이번 연구에서는 UAV(무인 항공기)로 촬영된 공중 영상에 대한 새로운 Self-supervised pretraining 알고리즘인 SOAR를 소개합니다. 이전 연구와는 달리, SOAR는 프리트레이닝(pretraining) 과정에서 인간 객체 지식을 통합하여 효율성을 높였습니다.

- **Technical Details**: SOAR는 두 가지 주요 접근 방식을 사용합니다. 첫째, 객체 인식과 관련된 특정 패치를 유지하기 위한 객체 인식 마스킹 전략(object-aware masking strategy)을 제안하였습니다. 둘째, 객체 정보를 활용하여 재구성 손실(reconstruction loss)을 조정하는 객체 인식 손실 함수(object-aware loss function)를 도입했습니다. 이를 통해 불필요한 배경 패치에 대한 편향을 방지할 수 있습니다.

- **Performance Highlights**: SOAR는 vanilla ViT 백본(backbone)을 사용하였으며, NEC-Drone과 UAV-Human 데이터셋에서 각각 9.7% 및 21.4%의 top-1 정확も(accuracy) 증가를 기록하며 기존 UAV 행동 인식(action recognition) 모델을 능가하였습니다. 특히, SOAR는 18.7ms의 비디오 당 추론 속도(inference speed)를 제공하며, 이는 2배에서 5배 더 빠릅니다. 추가로, SOAR는 이전의 Self-supervised learning 방법들과 유사한 정확도를 보여주면서도 87.5% 적은 프리트레이닝 시간과 25% 적은 메모리 사용을 요구합니다.



### Flat'n'Fold: A Diverse Multi-Modal Dataset for Garment Perception and Manipulation (https://arxiv.org/abs/2409.18297)
- **What's New**: Flat'n'Fold는 의류 조작을 위한 새로운 대규모 데이터셋으로, 기존 데이터셋의 중요한 격차를 해결합니다. 44개의 고유 의류 항목을 8개 카테고리에 걸쳐 총 1,212개의 인간과 887개의 로봇 시연으로 구성되어 있습니다.

- **Technical Details**: 이 데이터셋은 구겨진 상태에서 접힌 상태까지의 전체 조작 과정을 포착하며, 동기화된 다중 관점 RGB-D 이미지, 포인트 클라우드(point clouds), 그리고 손 또는 그리퍼(gripper) 위치 및 회전을 포함한 행동 데이터를 제공합니다. 이 데이터에 대한 다양성과 복잡성을 기존 기준과 비교하여 정량화하였습니다.

- **Performance Highlights**: Flat'n'Fold의 유용성을 보여주기 위해, 그리핑 포인트(prediction) 예측 및 하위 작업(subtask) 분해에 대한 새로운 기준을 설정했습니다. 이 작업에 대해 최첨단 모델을 평가한 결과, 개선이 필요한 부분이 많음을 확인했습니다. 이는 변형 가능한 객체의 로봇 인식과 조작 분야에서의 발전 가능성을 강조합니다.



### Enhancing Lossy Compression Through Cross-Field Information for Scientific Applications (https://arxiv.org/abs/2409.18295)
Comments:
          9 pages, 9 figures, accepted by DRBSD-10

- **What's New**: 본 논문은 과학 데이터 세트 내에서의 중요한 교차 필드 상관 관계를 식별하고, CNN(Convolutional Neural Network)을 이용하여 이러한 정보를 추출하는 새로운 하이브리드 예측 모델을 제안합니다.

- **Technical Details**: 제안된 하이브리드 모델은 기존의 로컬 필드 정보와 결합하여 교차 필드 정보를 활용합니다. 이를 통해 예측 정확성을 높이고, 손실 압축(lossy compression) 성능을 개선합니다.

- **Performance Highlights**: 이 모델은 세 가지 과학 데이터 세트에서 검증되었으며, 특정 오류 한계 내에서 압축 비율을 최대 25% 개선하고, 데이터 세부정보를 더 잘 보존하며, 아티팩트(artifacts)를 줄이는 성능을 보였습니다.



### Criticality and Safety Margins for Reinforcement Learning (https://arxiv.org/abs/2409.18289)
Comments:
          17 pages, 10 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 이 논문에서는 최근 강화 학습(Reinforcement Learning) 방법들이 안전하지 않은 상황을 만날 수 있다는 점을 다루고 있습니다. 이에 따라, 이러한 상황을 식별하는 것이 분석 및 실행 과정에서 인간의 감시를 요청할 수 있는 이점을 제공할 수 있는 중요성을 강조하고 있습니다.

- **Technical Details**: 논문에서는 true criticality와 proxy criticality라는 두 가지 개념을 도입하여, 강화 학습 에이전트가 정책(policy)에서 벗어나 무작위 행동을 n번 연속으로 따를 때 예상되는 보상의 감소를 기반으로 합니다. true criticality는 구체적인 지표로 작용하며, proxy criticality는 통계적으로 true criticality와 단조롭게(monotonic) 관계를 구성하는 저오버헤드(low-overhead) 메트릭입니다. 이 메트릭들은 신뢰 구간 내에서 tolerable 성능 손실을 초과하지 않는 무작위 행동의 수로 정의된 안전 여유(safety margins)에 의해 더욱 설명 가능합니다.

- **Performance Highlights**: Atari Beamrider 환경에서 A3C 에이전트를 사용하여 한 실험을 진행한 결과, 최소 5%의 안전 여유가 47%의 에이전트 손실을 포함하는 것으로 나타났습니다. 즉, 5%의 결정을 감독함으로써 에이전트의 오류를 약 50% 예방할 수 있다는 것을 제시합니다. 이러한 점에서 이 프레임워크는 나쁜 결정이 이루어지기 전에 그 잠재적 영향을 측정할 수 있어, 자율 에이전트의 더 효과적인 디버깅(debugging)과 감독을 가능하게 합니다.



### Advancing Object Detection in Transportation with Multimodal Large Language Models (MLLMs): A Comprehensive Review and Empirical Testing (https://arxiv.org/abs/2409.18286)
- **What's New**: 이번 연구는 교통 시스템에서 객체 탐지(object detection)에 대한 다중 모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)과 대형 비전 모델(Large Vision Models, VLMs)의 응용을 포괄적으로 검토하고 실증적으로 평가하는 것을 목표로 합니다.

- **Technical Details**: 연구의 첫 번째 부분에서는 MLLMs의 교통 응용 분야에서의 잠재적인 이점에 대한 배경을 제공하고, 기존 연구에서 현재 MLLM 기술에 대한 포괄적인 리뷰를 실시했습니다. 두 번째 부분에서는 교통 응용 프로그램에서의 엔드 투 엔드 객체 탐지(taxonomy of end-to-end object detection) 개요와 향후 방향을 제시했습니다.

- **Performance Highlights**: MLLM 성능에 대한 상세한 평가 결과를 제공하며, 도로 안전 특성 추출, 안전 비상 이벤트 탐지, 열화상 이미지의 시각적 추론을 포함한 세 가지 실제 교통 문제에 대한 실증 분석을 수행했습니다. 이 연구는 MLLM의 강점과 개선이 필요한 영역을 밝혀냈으며, 교통에서의 객체 탐지를 향상시키기 위한 MLLM의 실용적인 한계와 도전에 대해 논의합니다.



### Omni6D: Large-Vocabulary 3D Object Dataset for Category-Level 6D Object Pose Estimation (https://arxiv.org/abs/2409.18261)
Comments:
          ECCV 2024 (poster). Github page: this https URL

- **What's New**: Omni6D라는 새로운 RGBD 데이터셋을 소개하며, 다양한 범주와 배경을 포함하여 6D 객체 자세 추정의 현실적인 맥락을 제공한다.

- **Technical Details**: Omni6D 데이터셋은 166개의 범주, 4688개의 인스턴스, 80만 개 이상의 캡처로 구성되어 있어 기존 데이터셋보다 훨씬 넓은 평가 범위를 제공한다. 우리는 대칭성 인식(symmetry-aware) 메트릭을 도입하고 기존 알고리즘에 대한 체계적인 벤치마크를 수행하여 새로운 도전과 통찰력을 탐구한다. 또한, 기존 데이터셋에서 모델을 조정(adapt)할 수 있는 효과적인 파인 튜닝(fine-tuning) 접근법도 제안한다.

- **Performance Highlights**: 이 연구는 산업 및 학계 모두에서 6D 자세 추정의 경계를 확장하고 새로운 통찰력과 상당한 진행을 이룰 수 있는 기반을 마련할 것으로 기대된다.



### PCEvE: Part Contribution Evaluation Based Model Explanation for Human Figure Drawing Assessment and Beyond (https://arxiv.org/abs/2409.18260)
- **What's New**: 본 연구에서는 인간 형상 드로잉(Human Figure Drawing, HFD) 평가 작업에서 모델 결정의 명확성과 설명 가능성을 높이기 위해 부분 기여 평가 기반 모델 설명(Part Contribution Evaluation based Model Explanation, PCEvE) 프레임워크를 제안합니다.

- **Technical Details**: PCEvE는 각 개별 부분의 Shapley Value를 측정하여 모델 결정에 대한 기여도를 평가합니다. 기존의 pixel-level attribution 기반 설명 가능한 AI 설명 방식과 달리, PCEvE는 부분 기여 히스토그램(part contribution histogram)이라는 직관적인 설명을 제공합니다. 또한, PCEvE는 설명의 범위를 샘플 수준(sample-level)에서 클래스 수준(class-level) 및 작업 수준(task-level)으로 확장합니다.

- **Performance Highlights**: PCEvE는 여러 HFD 평가 데이터셋에 대한 광범위한 실험을 통해 엄격하게 검증되었으며, 제안된 방법의 타당성을 확인하기 위한 제어된 실험을 수행했습니다. 또한, PCEvE는 스탠포드 자동차와 같은 포토리얼리스틱(photo-realistic) 데이터셋에도 적용하여 다양성과 응용 가능성을 입증했습니다.



### AI Policy Projector: Grounding LLM Policy Design in Iterative Mapmaking (https://arxiv.org/abs/2409.18203)
- **What's New**: 이 논문에서는 정책 설계를 지도 제작(mapmaking)에서 영감을 얻어 새로운 AI 정책 설계 프로세스를 소개합니다.

- **Technical Details**: 이 연구에서 제안하는 Policy Projector는 모델 입력 및 출력 쌍의 지형을 탐색하고 사용자 정의 영역을 정의하며, LLM 출력에 적용할 수 있는 규칙을 탐색할 수 있도록 해줍니다. 예를 들어, '폭력(violence)'과 '그래픽 세부사항(graphic details)'이 포함된 출력이 있는 경우 그래픽 세부사항 없이 다시 쓰는 규칙을 설정할 수 있습니다.

- **Performance Highlights**: 12명의 AI 안전(AI safety) 전문가와의 평가에서, Policy Projector는 정책 설계자가 기존의 포괄적인 해악 분류(harm taxonomy)를 넘어서는 문제적 모델 행동을 해결하는 데 도움을 주었습니다.



### Evaluation of Large Language Models for Summarization Tasks in the Medical Domain: A Narrative Review (https://arxiv.org/abs/2409.18170)
- **What's New**: 대형 언어 모델(Large Language Models)의 발전은 임상 자연어 생성(Clinical Natural Language Generation)을 촉진하고, 의료 텍스트의 양을 관리할 수 있는 기회를 창출했습니다. 그러나 의료의 높은 위험 수준은 신뢰할 수 있는 평가를 요구하며, 이는 여전히 도전 과제로 남아 있습니다.

- **Technical Details**: 이 논문은 임상 요약 작업(Clinical Summarization Tasks)의 현재 평가 상태를 분석하고, 전문가의 인간 평가(Human Evaluation) 자원 제약(Resource Constraints)을 해결하기 위한 미래 방향을 제안합니다. 이를 통해 임상 분야에서의 신뢰성을 높이고자 합니다.

- **Performance Highlights**: 이 리뷰는 임상 자연어 생성의 효율성을 높이는 방법을 제안하며, 향후 연구 방향을 명확히 하고, 평가 프로세스의 개선 필요성을 강조합니다.



### Harmful Fine-tuning Attacks and Defenses for Large Language Models: A Survey (https://arxiv.org/abs/2409.18169)
- **What's New**: 최근 연구에 따르면, 새로운 fine-tuning-as-a-service 비즈니스 모델이 심각한 안전 문제를 드러내고 있습니다. 사용자가 업로드한 몇 가지 해로운 데이터로 인한 fine-tuning이 모델의 안전 정렬(safety alignment)을 위협할 수 있습니다. 이러한 공격은 harmful fine-tuning으로 알려져 있으며, 연구 커뮤니티 내에서 큰 관심을 받고 있습니다.

- **Technical Details**: 논문은 먼저 문제의 위협 모델(threat model)을 제시하고, harmful fine-tuning 공격과 그 변종을 소개합니다. 이후 기존 문헌에 대한 체계적인 조사(survey)를 진행하여 공격 및 방어(defenses), 기계적 분석(mechanical analysis)에 대해 논의합니다.

- **Performance Highlights**: 논문은 연구 문제를 공식적으로 정립하고, 향후 연구 방향(future research directions)을 제안합니다. 또한, 동료 평가(peer review) 과정에서 실험/공격/방어 설정의 현실성에 대한 질문을 제기할 때 유용할 수 있는 흥미로운 질문 목록을 포함하고 있습니다.



### A Survey on Neural Architecture Search Based on Reinforcement Learning (https://arxiv.org/abs/2409.18163)
- **What's New**: 딥러닝의 폭발적인 발전 덕분에 기계 학습의 feature extraction 자동화가 성공적으로 이루어졌습니다. 이제 연구자들은 최적의 네트워크 구조와 하이퍼파라미터를 자동으로 찾을 수 있는 방법을 모색하고 있습니다.

- **Technical Details**: 논문에서는 Neural Architecture Search (NAS)의 전반적인 발전 상황을 소개하고, 특히 reinforcement learning과 관련된 NAS 작업의 개요를 제공합니다. 또한, 복잡한 구조와 자원이 부족한 환경에서의 개선 및 변형에 대해 논의합니다.

- **Performance Highlights**: Neural Architecture Search를 통해 다양한 작업에 최적화된 네트워크 구조를 자동적으로 발견할 수 있는 가능성이 열리며, 이는 성능 향상에 큰 기여를 할 것으로 기대됩니다.



### The Nexus of AR/VR, Large Language Models, UI/UX, and Robotics Technologies in Enhancing Learning and Social Interaction for Children: A Systematic Review (https://arxiv.org/abs/2409.18162)
Comments:
          none

- **What's New**: 이 리뷰 연구에서는 대형 언어 모델(LLMs), 증강 현실(AR) 및 사용자 인터페이스/사용자 경험(UI/UX) 디자인의 결합이 자폐 스펙트럼 장애(ASD)를 가진 아동 치료에서 어떻게 활용될 수 있는지를 살펴보았습니다.

- **Technical Details**: 연구에서는 PubMed, ACM, IEEE Xplore, Elsevier 및 Google Scholar에서 150개의 관련 출판물을 찾아냈고, 이 중 42개를 방법론적 엄격성과 관련성을 기준으로 선정하여 심층 분석하였습니다. 세 가지 주요 영역이 다뤄졌습니다: AR이 사회적 및 학습 결과를 어떻게 개선할 수 있는지, LLMs가 의사소통에 어떻게 기여할 수 있는지, UI/UX 디자인이 이러한 기술의 효과성에 어떤 영향을 미치는지입니다.

- **Performance Highlights**: 결과에 따르면 LLMs는 개인화된 학습 및 의사소통 지원을 제공할 수 있지만, AR은 사회적 기술, 동기 및 집중력을 향상시키는 데 긍정적인 영향을 미치는 것으로 나타났습니다. ASD 아동을 위한 접근 가능하고 흥미로운 개입은 효과적인 UI/UX 디자인에 크게 의존하며, 이 연구는 개인화, 접근성 및 통합과 관련된 난제들을 해결하기 위한 추가 연구의 필요성을 강조하고 있습니다.



### Decomposition of one-layer neural networks via the infinite sum of reproducing kernel Banach spaces (https://arxiv.org/abs/2409.18132)
Comments:
          13 pages

- **What's New**: 이번 논문에서는 RKBS(Reproducing Kernel Banach Spaces)의 합을 정의하고, RKBS의 특성 정리를 이용하여 이를 직접 합(Direct Sum) 기능공간과의 호환성을 증명합니다.

- **Technical Details**: RKBS의 합은 $p$-norm RKBS의 합으로 분해할 수 있으며, 이는 RKBS 클래스의 구조적 이해에 기여하는 응용 프로그램을 제공합니다.

- **Performance Highlights**: 이 연구는 RKBS의 수학적 구조를 더 깊이 이해하는 데 중요한 기초를 마련하며, 기능적 관점에서 RKBS의 합이 어떻게 작용하는지를 설명합니다.



### Infer Human's Intentions Before Following Natural Language Instructions (https://arxiv.org/abs/2409.18073)
- **What's New**: 이 논문에서는 Ambiguous natural language instructions를 효과적으로 수행하기 위한 새로운 프레임워크인 Follow Instructions with Social and Embodied Reasoning (FISER)를 제안합니다. 이 프레임워크는 사람의 목표와 의도를 추론하는 단계를 명시적으로 포함합니다. 이는 AI 에이전트가 인간의 자연어 명령을 이해하고 협력적 작업을 더 잘 수행하도록 돕습니다.

- **Technical Details**: FISER는 두 가지 주요 구성 요소인 social reasoning과 embodied reasoning을 사용하여 모델이 인간의 의도를 명시적으로 추론할 수 있도록 합니다. 먼저 social reasoning을 통해 인간이 요청하는 하위 작업(sub-task)을 예측한 후, 이러한 지침을 로봇이 이해할 수 있는 작업으로 변환하는 Embodied reasoning 단계로 진행합니다. 또한, FISER는 계획 인식(plan recognition) 단계를 추가하여 인간의 전반적인 계획을 추론하는 데 도움을 줍니다.

- **Performance Highlights**: FISER 모델은 HandMeThat(HMT) 벤치마크에서 64.5%의 성공률을 기록하며, 이전의 end-to-end 접근법을 초월한 성능을 보여줍니다. 또한, FISER는 체인 오브 토트(Chain-of-Thought) 방식으로 GPT-4를 기반으로 한 강력한 기준과 비교했을 때도 우수한 결과를 도출했습니다. 이 결과는 인간의 의도에 대한 중간 추론을 명시적으로 수행하는 것이 AI의 성능을 개선하는 데 효과적임을 입증합니다.



### Explaining Explaining (https://arxiv.org/abs/2409.18052)
- **What's New**: 본 논문은 기계 학습 시스템의 블랙 박스 문제를 해결하기 위해 설명가능한 인공지능(XAI) 및 인간 중심의 설명가능한 인공지능(HCXAI) 접근 방식을 결합하는 하이브리드(cognitive agents) 방법을 제안합니다.

- **Technical Details**: 제안된 접근 방식은 지식 기반 인프라를 활용하며, 상황에 따라 기계 학습을 통해 획득한 데이터를 보조적으로 사용합니다. 이로 인해 인공지능 시스템이 사용자에게 더욱 필요한 설명을 제공할 수 있습니다.

- **Performance Highlights**: 시뮬레이션된 로봇 팀이 사용자의 지시에 따라 협력적인 검색 작업을 수행하는 시연 시스템의 예를 통해 이러한 에이전트의 설명 가능성을 보여줍니다.



### Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspectiv (https://arxiv.org/abs/2409.18028)
- **What's New**: 본 연구는 큰 언어 모델(LLM)이 동일한 컨텍스트 내에서 여러 하위 작업을 수행하는 능력에 한계가 있음을 지적하고, 이를 극복하기 위해 멀티 에이전트 시스템을 활용한 문제 해결 방안을 제시합니다.

- **Technical Details**: 본 연구에서는 생성 복잡도(Generation Complexity)라는 지표로 LLM이 정확한 솔루션을 샘플링하기 위해 필요한 생성 횟수를 정량화 하며, 복합 코딩 문제에서 LLM과 멀티 에이전트 시스템 간의 성능 차이를 분석합니다. LLM을 오토회귀 모델로 모델링하고, 두 개의 다른 문제를 독립적으로 해결하는 방법을 논의합니다.

- **Performance Highlights**: 실험적으로, Llama 3 모델을 사용하여 복합 코드 문제에 대한 생성 복잡도의 기하급수적 차이를 입증하였으며, 이는 동일한 컨텍스트 내에서 문제를 해결하기에 LLM이 더 어려움을 겪는 다는 것을 보여줍니다.



### Role-RL: Online Long-Context Processing with Role Reinforcement Learning for Distinct LLMs in Their Optimal Roles (https://arxiv.org/abs/2409.18014)
- **What's New**: 이번 논문에서는 자동 뉴스 보도, 라이브 전자상거래 및 바이럴 짧은 동영상과 같이 다양한 스트리밍 미디어에서 정보를 수신하고 정리하는 과정에서 발생하는 무제한 길이의 문서를 처리하기 위한 새로운 패러다임, 즉 Online Long-context Processing (OLP)을 제안합니다.

- **Technical Details**: 제안된 OLP는 다양한 LLM (Large Language Models)을 효율적으로 활용할 수 있는 방법론으로, Role Reinforcement Learning (Role-RL) 기법을 통해 여러 LLM을 성능에 맞게 OLP 파이프라인 내에서 자동으로 배치하는 메커니즘을 제공합니다. 이 프레임워크는 각 모델의 성능에 따라 역할을 분담하므로 최적의 성능을 달성할 수 있습니다.

- **Performance Highlights**: OLP-MINI 데이터셋에 대한 광범위한 실험 결과, Role-RL 프레임워크를 적용한 OLP는 평균 재현율(Recall Rate) 93.2%를 달성하며, LLM 비용을 79.4% 절감할 수 있음을 보여주었습니다.



### CRoP: Context-wise Robust Static Human-Sensing Personalization (https://arxiv.org/abs/2409.17994)
Comments:
          31 pages, 10 figues and 13 tables

- **What's New**: 이 연구에서는 CRoP라는 새로운 정적 개인화 접근 방식을 소개합니다. 이는 사전 학습된 모델을 활용하고, 모델 프루닝을 통해 개인화 및 일반화 성능을 최적화합니다.

- **Technical Details**: CRoP는 오프라인에서 구입한 사전 훈련 모델을 활용하여, 개별 사용자를 위해 개발된 모델의 일반적인 특성을 고려합니다. 이는 Gradient Inner Product 분석 및 다양한 데이터 세트를 통해 설계 선택을 정당화합니다.

- **Performance Highlights**: CRoP는 네 가지 인간 감지 데이터 세트에 대해 개인화 효과성과 사용자 내 강건성을 보여주었습니다. 이를 통해 임상 환경에서 노출이 적은 데이터로도 모델의 성능을 극대화할 수 있습니다.



### Enhancing elusive clues in knowledge learning by contrasting attention of language models (https://arxiv.org/abs/2409.17954)
Comments:
          7 pages and 17 figures

- **What's New**: 이 논문은 대규모 언어 모델들이 지식 학습의 효율성을 높이는 방법에 대한 새로운 접근법을 제안합니다. 특히, 언어 모델의 주의(attention) 가중치를 비교하여 중요한 힌트를 식별하고, 이를 데이터 augmentation 방식으로 활용하여 성능을 향상시키는 방법을 소개합니다.

- **Technical Details**: 이 연구에서는 대규모 언어 모델과 소규모 언어 모델 간의 주의 가중치 차이를 분석하여, 작은 모델들이 간과하기 쉬운 중요한 단서를 포착합니다. 이 단서들은 `token-dropout data augmentation` 기법을 통해 강조되며, 사실 기억력에서 성능 향상을 보여줍니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 소규모 및 대규모 모델 모두에서 효과적으로 사실 기반의 지식 학습 성능을 향상시켰습니다. 기존의 데이터 augmentation 방법들과 비교할 때, 새로운 접근법이 모든 모델에 걸쳐 우수한 성능을 보였습니다.



### Navigation in a simplified Urban Flow through Deep Reinforcement Learning (https://arxiv.org/abs/2409.17922)
- **What's New**: 최근 도심 환경에서의 UAV(무인 항공기) 사용 증가로 인해 에너지 효율성과 소음 감소를 위한 새로운 비행 계획 최적화 전략이 필요해졌습니다. 이 논문은 DRL(Deep Reinforcement Learning) 알고리즘을 개발하여 UAV의 자율 내비게이션을 가능하게 하는 방법을 제안합니다.

- **Technical Details**: 논문에서는 두 차원 유동장(flow field)에서 UAV의 비행 경로를 최적화하기 위해 PPO+LSTM 셀을 사용하여 알고리즘을 구현하였습니다. 이 방식은 단순한 PPO 및 TD3 알고리즘에 비해 비행 경로 최적화와 상관하여 상당한 개선을 보여주었습니다.

- **Performance Highlights**: PPO+LSTM로 훈련된 정책은 98.7% 의 성공률(SR)과 0.1% 의 충돌률(CR)을 기록하였으며, 이는 기존의 PPO(75.6% SR, 18.6% CR)와 TD3(77.4% SR, 14.5% CR) 알고리즘을 능가하는 성과입니다.



### Learning to Love Edge Cases in Formative Math Assessment: Using the AMMORE Dataset and Chain-of-Thought Prompting to Improve Grading Accuracy (https://arxiv.org/abs/2409.17904)
- **What's New**: 이번 논문에서는 아프리카 여러 국가의 학생들이 사용하는 학습 플랫폼 Rori에서 수집한 53,000개의 수학 개방형 질문-답변 쌍으로 이루어진 새로운 데이터세트 AMMORE를 소개합니다.

- **Technical Details**: AMMORE 데이터세트는 학생들의 수학 성취도를 연구하기 위한 중요한 자원으로, 두 가지 실험을 통해 대규모 언어 모델(LLM)을 사용하여 학생의 도전적인 답변을 채점하는 방법을 평가했습니다. 실험 1에서는 zero-shot, few-shot 및 chain-of-thought prompting을 포함한 다양한 LLM 기반 접근 방식을 사용하여 규칙 기반 분류기가 정확하게 채점하지 못한 학생 답변의 1%를 채점했습니다. 실험 2에서는 최상의 LLM 기반 접근 방식에서 생성된 점수를 Bayesian Knowledge Tracing (BKT) 모델에 전달하여 학생의 특정 수업 마스터리를 추정했습니다.

- **Performance Highlights**: 체인 오브 씽킹(prompting)은 가장 잘 수행된 접근 방식으로, 엣지 케이스의 92%를 정확하게 채점하여 채점 정확도를 98.7%에서 99.9%로 향상시켰습니다. LLM 체인 오브 씽킹 접근 방식을 사용했을 때, 학생의 마스터리 상태를 잘못 분류한 비율이 6.9%에서 2.6%로 감소하여 모델의 정확성 향상이 학생 마스터리 추정에 중요한 변화를 가져올 수 있음을 보여줍니다.



### DarkSAM: Fooling Segment Anything Model to Segment Nothing (https://arxiv.org/abs/2409.17874)
Comments:
          This paper has been accepted by the 38th Annual Conference on Neural Information Processing Systems (NeurIPS'24)

- **What's New**: 본 논문에서는 Segment Anything Model (SAM)에 대한 최초의 프롬프트-프리(universal attack framework)가 제안되었습니다. 새로운 공격 방법인 DarkSAM은 semantic decoupling 기반의 공간 공격과 texture distortion 기반의 주파수 공격을 포함합니다.

- **Technical Details**: DarkSAM은 SAM의 출력을 전경(foreground)과 배경(background)으로 나눈 후, 그림의 semantic blueprint를 이용하여 공격 목표를 설정합니다. 공간 영역에서는 이미지의 전경과 배경의 의미를 방해하여 SAM을 혼란스럽게 하고, 주파수 영역에서는 고주파 성분(texture information)을 왜곡하여 공격 효과를 강화합니다.

- **Performance Highlights**: 실험 결과, DarkSAM은 다양한 데이터셋에서 SAM 및 그 변형 모델(HQ-SAM 및 PerSAM)을 대상으로 높은 공격 성공률과 전이 가능성을 보여주었습니다.



### Detecting and Measuring Confounding Using Causal Mechanism Shifts (https://arxiv.org/abs/2409.17840)
- **What's New**: 본 논문은 관측 데이터에서의 혼란 변수(confounding variable)를 탐지하고 측정하는 포괄적인 접근 방식이 제안됩니다. 기존 연구들이 비관측 혼란 변수의 존재를 간과한 반면, 우리는 이를 해결하기 위해 다양한 방법론을 마련했습니다.

- **Technical Details**: (i) 변수 집합 간의 혼란을 탐지하고 측정하기 위한 정의와 방법, (ii) 관측된 혼란과 비관측 혼란 효과를 분리하며, (iii) 서로 다른 변수 집합 간의 혼란 편향의 상대 강도를 이해하는 방법론을 포함합니다. 이 연구는 파라메트릭(parmetric) 또는 인과 충분성(causal sufficiency) 가정을 완화함으로써 데이터에서 혼란을 체계적으로 탐구하는 최초의 연구로, 여러 맥락(context)에서 얻은 데이터를 활용합니다.

- **Performance Highlights**: 실험 결과는 이론적 분석을 뒷받침하며, 제안된 혼란 측정의 유용성을 강조합니다. 여러 환경에서의 데이터 활용을 통해 혼란 탐지 및 측정의 효과를 입증했습니다.



### DREAMS: A python framework to train deep learning models with model card reporting for medical and health applications (https://arxiv.org/abs/2409.17815)
- **What's New**: EEG (Electroencephalography) 데이터 분석을 위해 설계된 포괄적인 딥러닝 프레임워크, DREAMS (Deep REport for AI ModelS) 를 소개합니다. 이 프레임워크는 모델 훈련 및 결과 리포트를 위한 기능을 제공하여 의료 연구자와 개발자에게 투명하고 책임 있는 AI 모델을 지원합니다.

- **Technical Details**: DREAMS는 Python 패키지로, 모델 카드 (model cards)를 생성하여 ML (Machine Learning) 및 DL (Deep Learning) 모델의 성능 특성을 문서화하는 포괄적인 프레임워크입니다. 이 프레임워크는 데이터 수집, 전처리, 모델 훈련 및 평가를 포함한 모든 프로세스를 체계적으로 기록합니다. 내부적으로는 EDA (Exploratory Data Analysis)와 같이 데이터 분석을 시각화하는 과정을 포함하며, YAML 파일을 통해 모든 정보에 대한 경로를 정의합니다.

- **Performance Highlights**: DREAMS는 EEG 데이터 분석의 투명성과 윤리적 사용을 촉진하며, 기계 학습 모델의 문서화된 성능 지표를 통해 연구자와 임상의가 효과적으로 모델을 이용할 수 있도록 돕습니다. 특히, EEG 데이터 특정 감정 분류에서 세 가지 주요 범주: 부정적, 중립적, 긍정적 감정을 분류하는 예시를 통해 그 효용성을 보여줍니다.



### Ophthalmic Biomarker Detection with Parallel Prediction of Transformer and Convolutional Architectur (https://arxiv.org/abs/2409.17788)
Comments:
          5 pages

- **What's New**: 본 논문에서는 Optical Coherence Tomography (OCT) 이미지를 이용한 안과 바이오 마커(blog detection) 탐지에서 새로운 접근법을 제시합니다. Convolutional Neural Network (CNN)와 Vision Transformer의 앙상블을 활용하여 보다 정밀한 분석을 가능하게 합니다.

- **Technical Details**: 이 방법은 CNN의 지역적 특징 추출 능력과 Transformer의 전역적 특징 추출 능력을 결합하여 최적의 결과를 도출합니다. OLIVES 데이터셋을 사용하여 OCT 이미지에서 6개의 주요 바이오 마커를 탐지하였으며, 이는 기존 방식에 비해 성능이 크게 향상되었습니다.

- **Performance Highlights**: 평가 지표로 사용된 매크로 평균 F1 스코어(macro averaged F1 score)가 데이터셋에서 유의미한 개선을 보였습니다.



### The application of GPT-4 in grading design university students' assignment and providing feedback: An exploratory study (https://arxiv.org/abs/2409.17698)
Comments:
          25 pages, 5 figures

- **What's New**: 이 연구는 GPT-4가 디자인 대학 학생들의 과제를 효과적으로 채점하고 유용한 피드백을 제공할 수 있는지를 조사합니다.

- **Technical Details**: 연구는 iterative research approach (반복적 연구 접근 방식)을 사용하여 Custom GPT를 개발했습니다. 연구 결과, GPT와 인간 채점자 간의 inter-reliability (상호 신뢰성)가 교육자들에 의해 일반적으로 수용되는 수준에 도달했습니다.

- **Performance Highlights**: GPT의 채점 intra-reliability (내부 신뢰성)은 0.65에서 0.78 사이로 나타났습니다. 이는 적절한 지침을 제공할 경우 일관된 결과를 제공함을 의미하며, 일관성과 비교 가능성은 교육 평가의 신뢰성을 보장하는 두 가지 주요 규칙입니다.



### Artificial Data Point Generation in Clustered Latent Space for Small Medical Datasets (https://arxiv.org/abs/2409.17685)
Comments:
          8 pages, 2 figures

- **What's New**: 이 연구는 작은 의료 데이터셋에서 분류 성능을 향상시키기 위한 합성 데이터 생성 방법인 AGCL(Artificial Data Point Generation in Clustered Latent Space)를 소개합니다. AGCL은 K-평균 클러스터링을 기반으로 하여 클래스 표현이 뚜렷한 클러스터에서 합성 데이터 포인트를 생성하는 방식으로 작동합니다.

- **Technical Details**: AGCL 프레임워크는 특징 추출, K-평균 클러스터링, 클래스 분리를 위한 클러스터 평가 및 각 클러스터의 매개변수를 기반으로 정규 분포에서 합성 데이터 포인트를 생성하는 과정을 포함합니다. 이 방법은 파킨슨병 스크리닝을 위한 얼굴 표정 데이터에 적용되어 여러 머신러닝 분류기에서 평가되었습니다.

- **Performance Highlights**: AGCL은 기본선(GN) 및 kNNMTD와 비교하여 분류 정확도를 유의미하게 향상시켰으며, 서로 다른 감정에 대한 다수결 방식의 교차 검증에서 90.90%의 정확도를 기록했습니다. AGCL은 궁극적으로 83.33%의 테스트 정확도를 달성하며, 작은 데이터셋 증대에 효과적임을 입증했습니다.



### Explanation Bottleneck Models (https://arxiv.org/abs/2409.17663)
Comments:
          13 pages, 4 figures

- **What's New**: 이 논문은 사전 정의된 개념 세트에 의존하지 않고 입력에서 텍스트 설명을 생성할 수 있는 새로운 해석 가능한 심층 신경망 모델인 설명 병목 모델(XBMs)을 제안합니다.

- **Technical Details**: XBMs는 입력 데이터에서 텍스트 설명을 생성하고, 이를 기반으로 최종 작업 예측을 수행하는 모델입니다. XBMs는 사전 학습된 비전-언어 인코더-디코더 모델을 활용하여 입력 데이터에 나타난 개념을 포착합니다. 훈련 과정 중 '설명 증류(explanation distillation)' 기술을 사용하여 분류기의 성능과 텍스트 설명의 품질을 모두 확보합니다.

- **Performance Highlights**: 실험 결과, XBMs는 기존의 개념 병목 모델(CBMs)과 비교하여 더욱 유의미하고 자연스러운 언어 설명을 제공하며, 블랙박스 기준선 모델에 필적하는 성능을 달성하고 있습니다. 특히, XBMs는 테스트 정확도에서 CBMs을 크게 초월합니다.



### A Fuzzy-based Approach to Predict Human Interaction by Functional Near-Infrared Spectroscopy (https://arxiv.org/abs/2409.17661)
- **What's New**: 이번 논문은 심리 연구에서 신경 모델의 해석 가능성과 효율성을 높이기 위해 Fuzzy Attention Layer라는 새로운 Fuzzy 기반 주의 메커니즘을 소개합니다. 이 메커니즘은 Transformer Encoder 모델에 통합되어, 기능적 근적외선 분광법(fNIRS)으로 캡처한 신경 신호를 통해 복잡한 심리 현상을 분석할 수 있도록 합니다.

- **Technical Details**: Fuzzy Attention Layer는 퍼지 집합 이론(Fuzzy set theory)과 Fuzzy 신경망(Fuzzy neural networks), Transformer 시퀀스 모델링을 결합하여 신경 활동 패턴을 학습합니다. 이 계층은 전통적인 dot-product attention보다 향상된 모델 성능을 제공하며, 신경 데이터 집합에서의 해석 가능성을 높입니다.

- **Performance Highlights**: 실험 결과, Fuzzy Attention Layer는 손을 잡고 소통하는 참여자의 fNIRS 데이터를 분석한 결과, 해석 가능한 신경 활동 패턴을 학습함과 동시에 모델 성능을 향상시켰습니다. 이를 통해 인간 간의 터치, 감정 교환과 같은 사회적 행동의 미묘한 복잡성을 해독할 수 있는 잠재력을 보여주었습니다.



### Hierarchical End-to-End Autonomous Driving: Integrating BEV Perception with Deep Reinforcement Learning (https://arxiv.org/abs/2409.17659)
- **What's New**: 이 논문은 Deep Reinforcement Learning (DRL) 기반의 end-to-end 자율주행 프레임워크를 제안하며, Bird's-Eye-View (BEV) 표현을 활용하여 주행 환경을 통합적으로 이해할 수 있도록 합니다.

- **Technical Details**: 이 시스템은 서로 다른 방향을 향한 카메라의 입력을 통합하여 BEV 표현을 구성하고, BEV 데이터를 통해 관련 특징을 추출하는 신경망 모듈을 설계하여 DRL 에이전트에 입력합니다. 이를 통해 추출된 특성은 DRL 에이전트가 주행 전략을 직접 학습할 수 있도록 합니다.

- **Performance Highlights**: 우리의 방법은 자율주행 제어 작업에서 최신 기술보다 성능을 크게 개선하여 충돌 비율을 20% 줄이는 결과를 보여주었습니다.



### FactorSim: Generative Simulation via Factorized Representation (https://arxiv.org/abs/2409.17652)
Comments:
          neurips 2024, project website: this https URL

- **What's New**: 새로운 접근 방식인 FACTORSIM을 소개하며, 텍스트 입력에서 전체 시뮬레이션 코드를 생성하여 에이전트를 훈련할 수 있는 가능성을 제시합니다.

- **Technical Details**: FactorSim은 각 단계에서 필요한 문맥을 줄이기 위해 구조적 모듈성에 기반한 부분적으로 관찰 가능한 마르코프 결정 과정(POMDP) 표현을 활용합니다. 이 과정에서 Model-View-Controller(MVC) 소프트웨어 디자인 패턴을 사용하여 시뮬레이션 생성을 구조화합니다.

- **Performance Highlights**: FACTORSIM은 기존 방법들에 비해 시뮬레이션 생성의 정확도와 제로샷 전이 능력, 인간 평가에서 우수한 성능을 보여주며 로봇 작업 생성에서도 효과적임을 입증했습니다.



### Digital Twin Ecosystem for Oncology Clinical Operations (https://arxiv.org/abs/2409.17650)
Comments:
          Pre Print

- **What's New**: 이 논문은 인공지능(AI)과 디지털 트윈(Digital Twin) 기술을 활용하여 종양학(oncology) 분야의 임상 운영을 혁신적으로 향상시키기 위한 새로운 디지털 트윈 프레임워크를 소개합니다. 여러 전문 디지털 트윈을 통합하여 각 환자에 대한 개인화된 치료를 가능하게 하며, 이는 기존의 데이터와 NCCN 가이드라인에 기반하여 클리닉 추천을 제공합니다.

- **Technical Details**: 이 프레임워크는 Medical Necessity Twin, Care Navigator Twin, Clinical History Twin과 같은 여러 개의 전문 디지털 트윈을 활용하여 환자 맞춤형 치료와 워크플로우 효율성을 높입니다. 각 디지털 트윈은 실시간 데이터 교환을 통해 작동하며, 이를 통해 환자의 유일한 데이터에 기반한 개인화된 care path를 생성하여 ACA 데이터를 통합합니다. 이 시스템은 또한 여러 지식 기반을 통합하여 복잡한 상호작용을 시뮬레이션하는 멀티 에이전트 시스템(Multi-Agent Systems)은 의사결정 지원 및 care coordination을 강화할 수 있습니다.

- **Performance Highlights**: 이 논문에서 제시한 사례 연구는 다양한 에이전트들이 어떻게 협력하여 워크플로우를 간소화하고, 적시의 임상 추천을 제공할 수 있는지를 보여줍니다. 디지털 트윈 기술과 AI의 결합으로 인해 임상 결정의 정확성과 환자 맞춤형 치료의 효율성이 크게 향상됩니다.



### AI Delegates with a Dual Focus: Ensuring Privacy and Strategic Self-Disclosur (https://arxiv.org/abs/2409.17642)
- **What's New**: 이 논문은 AI delegate의 사용자 선호도를 조사한 파일럿 연구를 기반으로 개인 정보 보호와 자발적 공개(self-disclosure) 사이의 균형을 맞추는 새로운 시스템을 제안합니다.

- **Technical Details**: 이 AI delegate 시스템은 대화의 맥락, 관계의 성격, 양쪽 당사자의 편안함 수준을 고려하여 적절한 정보 공개 전략을 선택합니다. 이는 다중 에이전트 프레임워크(multi-agent framework)를 기반으로 하여 대화 목표를 평가하고, 사회적 규범 및 맥락 정보를 바탕으로 대화 전략을 조정합니다.

- **Performance Highlights**: 사용자 연구 결과, 제안된 AI delegate는 다양한 사회적 상호작용에서 개인 정보를 전략적으로 보호하고, LLM과 인간 평가자 간의 일치를 통해 사회적 목표 달성을 위한 적절한 자발적 공개 행동을 보여줍니다.



### Dirichlet-Based Coarse-to-Fine Example Selection For Open-Set Annotation (https://arxiv.org/abs/2409.17607)
- **What's New**: 이번 논문에서는 오픈셋 노이즈가 포함된 데이터에 대해 기존의 Active Learning (AL) 기법의 한계를 극복하기 위해, Dirichlet 기반의 Coarse-to-Fine Example Selection (DCFS) 전략을 제안합니다. 특히, 기존 softmax 기반의 예측에서 발생하는 불안정성을 해결하고, 알려진 클래스와 미지의 클래스를 효과적으로 구별할 수 있는 방법을 제시합니다.

- **Technical Details**: 이 방법은 simplex 기반의 evidential deep learning (EDL)을 활용하여 softmax의 translation invariance를 제거하고, 데이터 및 분포 불확실성을 동시에 고려합니다. 또한, 두 개의 분류 헤드를 통해 모델의 불일치성을 활용하여 강력한 알려진 클래스 예제를 식별하며, 불확실성을 결합하여 두 단계의 전략으로 가장 정보량이 많은 예제를 선택합니다.

- **Performance Highlights**: DCFS는 다양한 openness ratio 데이터셋에서 실험을 진행하였고, 기존 방법들에 비해 뛰어난 예측 정확도를 기록하였으며, 복잡한 오픈셋 환경에서 정보량이 많은 예제를 효과적으로 선택하여 모델 성능을 현저히 향상시키며, state-of-the-art 성능을 달성하였습니다.



### A Scalable Data-Driven Framework for Systematic Analysis of SEC 10-K Filings Using Large Language Models (https://arxiv.org/abs/2409.17581)
Comments:
          10 pages, 7 figures

- **What's New**: 본 연구는 NYSE에 상장된 다수의 기업 성과를 신속하고 비용 효율적으로 평가하고 비교하는 새로운 데이터 기반 접근법을 제안합니다. 이 접근법은 SEC 10-K 보고서를 기반으로 기업의 성과를 체계적으로 분석하고 점수를 매기는 대규모 언어 모델(LLM) 사용을 포함합니다.

- **Technical Details**: SEC 10-K filings에서 데이터를 추출하고 전처리하기 위한 자동화된 시스템을 도입하여 각 섹션을 식별하고 핵심 정보를 분리합니다. 이 데이터는 Cohere의 Command-R+ LLM에 공급되어 다양한 성과 지표에 대한 정량적 평가를 생성합니다.

- **Performance Highlights**: 제안된 시스템은 기업 성과를 연도별로 비교할 수 있는 인터랙티브 GUI를 통해 시각화합니다. 이를 통해 사용자들은 기업의 전략적 변화와 성과 개선을 시간 경과에 따라 쉽게 평가하고 비교할 수 있습니다.



### Showing Many Labels in Multi-label Classification Models: An Empirical Study of Adversarial Examples (https://arxiv.org/abs/2409.17568)
Comments:
          14 pages

- **What's New**: 딥 뉴럴 네트워크(Deep Neural Networks, DNNs)의 발전과 함께 다중 레이블(multi-label) 도메인에서도 적대적 예제(adversarial examples)의 영향을 연구하였습니다. 본 연구는 '많은 레이블 표시(Showing Many Labels)'라는 새로운 유형의 공격을 소개합니다.

- **Technical Details**: 이 공격의 목표는 분류기(classifier) 결과에서 포함된 레이블 수를 극대화하는 것입니다. 실험에서는 9개의 공격 알고리즘(attack algorithms)을 선택하고 '많은 레이블 표시' 상황에서 성능을 평가하였습니다. 8개의 알고리즘은 다중 클래스(multi-class) 환경에서 다중 레이블 환경으로 적응되었고, 나머지 하나는 기존 다중 레이블 환경을 위해 특별히 설계되었습니다.

- **Performance Highlights**: ML-LIW 및 ML-GCN 모델을 선택하여 VOC2007, VOC2012, NUS-WIDE, COCO의 4가지 인기 다중 레이블 데이터셋에서 학습하였습니다. 실험 결과 '많은 레이블 표시' 하에서는 반복 공격(iterative attacks)이 일회성 공격(one-step attacks)보다 현저히 더 높은 성공률(success rate)을 보였습니다. 또한, 데이터셋에 있는 모든 레이블을 표시하는 것이 가능함을 보여주었습니다.



### Just say what you want: only-prompting self-rewarding online preference optimization (https://arxiv.org/abs/2409.17534)
- **What's New**: 이 논문에서는 Reinforcement Learning from Human Feedback (RLHF)의 온라인 자기 보상 정렬 방법(self-rewarding alignment methods)을 다루고 있습니다. 기존의 자기 보상 접근 방식이 판단 능력에 의존하는 반면, 우리는 새로운 프롬프트 기반의 자기 보상 온라인 알고리즘을 제안합니다. 이 알고리즘은 판단 능력 없이도 선호 데이터셋을 생성할 수 있습니다.

- **Technical Details**: 우리는 긍정적 및 부정적 예시 간의 최적성 최적화(optimality gap)를 세밀하게 조정할 수 있는 방식을 채택하였으며, 훈련 후반부에 더 많은 난이도가 있는 부정적 예시(hard negatives)를 생성하여 모델이 미묘한 인간의 선호를 더 잘 포착할 수 있도록 돕습니다. 실험은 Mistral-7B와 Mistral-Instruct-7B 두 가지 기본 모델을 바탕으로 수행되었습니다.

- **Performance Highlights**: 우리의 방법은 AlpacaEval 2.0에서 34.5%의 Length-controlled Win Rates를 달성하며 여러 기준 방법들보다 종합적으로 우수한 성능을 보였습니다.



### Functional Classification of Spiking Signal Data Using Artificial Intelligence Techniques: A Review (https://arxiv.org/abs/2409.17516)
Comments:
          8 figures, 32 pages

- **What's New**: 이번 논문은 인지과학 및 컴퓨터 과학 간의 교차점을 강조하며, 신경 세포 행동의 분석에서 spike의 중요성을 다룹니다. 특히 인공지능(AI)의 도움을 받아 spike를 효과적으로 분류하는 방법에 대한 최근의 연구 결과를 검토합니다.

- **Technical Details**: 본 논문에서는 spike classification(스파이크 분류)의 전처리(preprocessing), 분류(classification), 평가(evaluation) 세 가지 주요 구성 요소를 중심으로 AI의 역할을 탐구합니다. 전통적인 수작업(spike classification)과 비교하여 머신러닝(machine learning) 및 딥러닝(deep learning) 접근법을 통한 신호 데이터의 자동화된 처리의 중요성을 설명합니다.

- **Performance Highlights**: 현재까지의 연구들은 AI를 활용한 스파이크 분류의 정확성을 높일 수 있는 잠재력을 보여줍니다. 효율적인 알고리즘의 필요성도 강조하며, 향후 연구에서 더욱 발전된 방법론과 문제 해결을 위한 방향을 제시합니다.



### From News to Forecast: Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection (https://arxiv.org/abs/2409.17515)
Comments:
          This paper has been accepted for NeurIPS 2024

- **What's New**: 이 논문은 시간 시계열 예측을 향상하기 위해 Large Language Models (LLMs)과 Generative Agents를 사용하는 새로운 접근 방식을 소개합니다. 이 방법은 뉴스 콘텐츠와 시간 시계열 변동을 정렬하여 여러 사회적 사건을 예측 모델에 적응적으로 통합합니다.

- **Technical Details**: 우리는 LLM 기반 에이전트를 사용하여 관련 없는 뉴스를 반복적으로 걸러내고, 인간과 유사한 추론 및 반성을 통해 예측을 평가합니다. 이를 통해 예기치 않은 사건 및 사회적 행동의 변화와 같은 복잡한 사건을 분석하고 뉴스의 선택 논리 및 에이전트의 출력을 지속적으로 개선합니다.

- **Performance Highlights**: 결과는 예측 정확도가 상당히 향상되었음을 보여주며, 비구조적 뉴스 데이터를 효과적으로 활용하여 시간 시계열 예측의 패러다임 변화를 제안합니다. 다양한 도메인(예: 금융, 에너지, 교통, 비트코인)에서 더 높은 예측 정확도를 달성했습니다.



### GLinSAT: The General Linear Satisfiability Neural Network Layer By Accelerated Gradient Descen (https://arxiv.org/abs/2409.17500)
- **What's New**: 본 논문에서는 신경망(Neural Network) 출력이 특정 제약 조건을 만족하도록 하는 새로운 접근 방식을 제안합니다. 특히, 일반적인 선형 제약 조건을 만족시키는 GLinSAT 레이어를 개발하여, 효율적인 배치 처리와 GPU에서의 고속 연산을 가능하게 하였습니다.

- **Technical Details**: GLinSAT는 엔트로피 정규화(Entropy Regularization)를 추가한 선형 계획 문제(Linear Programming)로 신경망 출력 투영 문제를 공식화합니다. 이 문제는 쌍대성 정리(Duality Theorem)에 의해 Lipschitz 연속 기울기를 가진 비제약 볼록 최적화 문제(Unconstrained Convex Optimization Problem)로 변환됩니다. GLinSAT은 이 문제를 해결하기 위해 가속화된 기울기 하강 알고리즘(Accelerated Gradient Descent Algorithm)을 사용하여 구현되었습니다.

- **Performance Highlights**: 실험 결과, GLinSAT는 제약이 포함된 외판원 문제(Constrained Traveling Salesman Problems), 아웃라이어가 포함된 부분 그래프 매칭(Partial Graph Matching with Outliers), 예측 포트폴리오 할당(Predictive Portfolio Allocation) 및 전력 시스템 단위 확립(Power System Unit Commitment)에서 기존의 만족도 레이어들에 비해 우수한 성능을 보여주었습니다.



### Human Mobility Modeling with Limited Information via Large Language Models (https://arxiv.org/abs/2409.17495)
- **What's New**: 이 연구는 기존의 데이터 기반 인간 이동 모델링의 한계를 극복하기 위해 Large Language Model(LLM)을 활용한 새로운 인간 이동 모델링 프레임워크를 제안합니다. 이 접근법은 고품질의 이동 데이터에 대한 의존도를 크게 줄이고, 기본적인 사회-인구통계적 정보만으로 개인의 일상 이동 패턴을 생성할 수 있도록 합니다.

- **Technical Details**: 제안된 프레임워크는 개인의 사회-인구통계적 정보에 기반해 활동의 순서를 생성하는 'activity chain' 개념을 사용합니다. LLM의 추론 및 논리적 사고 능력을 활용하여, 공공 자원의 고차원 통계와 구조화된 가이드라인을 활용하여 에이전트의 이동 패턴을 모델링합니다. Jensen-Shannon Divergence(JSD) 측정에서 0.011로 NHTS 데이터셋과 SCAG의 ABM 모델과 비교할 때 유망한 결과를 보였습니다.

- **Performance Highlights**: 이 프레임워크는 지역에 따라 다양한 인간 이동 패턴을 효과적으로 모델링할 수 있음을 보여주었으며, LLM의 활용을 통해 데이터 수집의 어려움을 극복할 수 있는 가능성을 제시합니다. 이는 교통 수요 모델링과 다중 모형, 다중 규모의 교통 시뮬레이션을 지원할 수 있는 토대를 제공합니다.



### Global-Local Medical SAM Adaptor Based on Full Adaption (https://arxiv.org/abs/2409.17486)
- **What's New**: 최근 시각 언어 모델(visual language models)인 Segment Anything Model (SAM)의 발전이 보편적인 의미 분할(universal semantic segmentation) 분야에서 큰 혁신을 가져왔습니다. 특히 Medical SAM adaptor (Med-SA)를 통해 의료 이미지 분할에 많은 도움을 주었습니다. 하지만 Med-SA는 부분적 적응(partial adaption) 방식으로 SAM을 미세 조정(fine-tunes)하여 개선의 여지가 있습니다.

- **Technical Details**: 이 논문에서는 전체 적응(full adaption)이 가능한 새로운 글로벌 의료 SAM 어댑터(GMed-SA)를 제안합니다. GMed-SA는 SAM을 전 세계적으로 적응할 수 있도록 설계되었습니다. 또한 GMed-SA와 Med-SA를 결합하여 글로벌-로컬 의료 SAM 어댑터(GLMed-SA)를 제안하며, SAM을 글로벌과 로컬 모두에 적응시킵니다.

- **Performance Highlights**: 우리는 도전적인 공개 2D 흑색종(segmentation dataset) 분할 데이터셋에서 GLMed-SA의 광범위한 실험을 진행했습니다. 결과는 GLMed-SA가 다양한 평가 메트릭(evaluation metrics)에서 여러 최첨단 의미 분할 방법들보다 뛰어난 성능을 발휘함을 보여주었으며, 우리의 방법의 우수성을 입증하였습니다.



### MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models (https://arxiv.org/abs/2409.17481)
Comments:
          NeurIPS 2024 Spotlight

- **What's New**: 이번 연구는 MaskLLM이라는 새로운 learnable pruning (학습 가능한 가지치기) 방법을 제안합니다. 이 방법은 LLM (대규모 언어 모델)의 Semi-structured (반구조적) sparsity (희소성)을 통해 추론 시 계산 비용을 줄이는 데 초점을 맞추고 있습니다.

- **Technical Details**: MaskLLM은 Gumbel Softmax sampling (검벨 소프트맥스 샘플링)을 활용하여 N:M 패턴을 학습 가능한 분포로 모델링합니다. 이 방법은 N개의 비제로 값과 M개의 매개변수 사이의 관계를 설정하여 대규모 데이터 집합에서 end-to-end training (엔드투엔드 훈련)을 수행할 수 있게 합니다.

- **Performance Highlights**: MaskLLM은 LLaMA-2, Nemotron-4, GPT-3와 같은 여러 LLM을 사용하여 2:4 sparsity 설정 하에 평가되었습니다. 기존의 최첨단 방법에 비해 PPL (perplexity) 측정에서 유의미한 개선을 보였으며, 특히 SparseGPT의 10.42에 비해 MaskLLM은 6.72의 PPL을 달성하였습니다. 이 결과는 MaskLLM이 대규모 모델에서도 효과적으로 고품질 마스크를 학습할 수 있음을 나타냅니다.



### What Would Happen Next? Predicting Consequences from An Event Causality Graph (https://arxiv.org/abs/2409.17480)
- **What's New**: 본 논문은 사건 스크립트 체인(event script chain) 대신 사건 인과 그래프(Event Causality Graph, ECG)를 활용하여 사건 예측의 정확성을 높이는 새로운 Causality Graph Event Prediction (CGEP) 작업을 제안합니다. 이를 위해 Semantic Enhanced Distance-sensitive Graph Prompt Learning (SeDGPL) 모델을 제시하며, 이는 세 가지 모듈로 구성되어 있습니다.

- **Technical Details**: SeDGPL 모델은 (1) 거리 민감 그래프 선형화(Distance-sensitive Graph Linearization, DsGL) 모듈을 통해 ECG를 PLM(Pre-trained Language Model)의 입력으로 변환합니다. (2) 이벤트 강화 인과성 인코딩(Event-Enriched Causality Encoding, EeCE) 모듈은 이벤트의 맥락적 의미와 그래프 스키마 정보를 통합하여 이벤트 표현을 풍부하게 합니다. (3) 의미적 대조 사건 예측(Semantic Contrast Event Prediction, ScEP) 모듈은 다양한 후보 사건 사이에서 이벤트 표현을 강화하고, 대조 학습 프레임워크를 통해 결과 사건을 예측합니다.

- **Performance Highlights**: 실험 결과, SeDGPL 모델이 기존 경쟁 모델보다 CGEP 작업에서 우수한 성능을 발휘함을 입증하였으며, ECG 기반의 사건 예측이 사건 스크립트 체인 기반 예측보다 더 합리적임을 확인했습니다.



### A Time Series is Worth Five Experts: Heterogeneous Mixture of Experts for Traffic Flow Prediction (https://arxiv.org/abs/2409.17440)
Comments:
          20 pages, 4 figures

- **What's New**: 이번 연구에서는 교통 흐름 예측을 위해 변수 중심(variable-centric) 및 선행 지식 중심(prior knowledge-centric) 모델링 기법을 도입한 TITAN이라는 이질적(expert) 혼합 모델을 제안합니다. TITAN은 3개의 시퀀스 중심(expert)과 1개의 변수 중심(expert), 1개의 선행 지식 중심(expert)으로 구성되어 있습니다.

- **Technical Details**: TITAN 모델은 세 가지 서로 다른 전문가 유형으로 구성됩니다: 1) 시퀀스 중심 예측 전문가, 2) 변수 중심 예측 전문가, 3) 선행 지식 중심 리더 전문가. 저희는 전문가 간의 지식 정렬을 위해 저순위 행렬(low-rank matrix)을 활용하며, 이를 통해 다양한 백본 네트워크를 통합하여 MoE 프레임워크에서 효과적으로 inductive bias를 줄이는 방향으로 설계되었습니다.

- **Performance Highlights**: TITAN 모델은 METR-LA 및 PEMS-BAY라는 두 개의 공공 교통 네트워크 데이터 세트에서 평가되어, 기존의 최첨단(SOTA) 모델에 비해 4.37%에서 11.53%의 성능 향상을 달성하였습니다. 평균적으로 9%의 개선을 보였습니다.



### Exploring the Use of ChatGPT for a Systematic Literature Review: a Design-Based Research (https://arxiv.org/abs/2409.17426)
Comments:
          21 pages, 13 figures, 2 tables

- **What's New**: 본 연구는 교육, 배우기, 교수 및 연구 등 여러 교육적 맥락에서 사용되고 있는 ChatGPT의 시스템적 문헌 리뷰(SSR) 수행 가능성을 탐구합니다. 또한, ChatGPT를 사용하여 이전에 발표된 SSR을 분석하고 비교하여 그 차이를 발견했습니다.

- **Technical Details**: 이 연구는 디자인 기반 접근법을 사용하여 33개 논문에 대한 SSR을 ChatGPT로 수행했습니다. ChatGPT는 문헌을 분석하기 위해 세부적이고 정확한 프롬프트가 필요하지만, 신뢰성과 유효성을 향상시키기 위한 연구자의 전략도 중요합니다.

- **Performance Highlights**: 연구 결과, ChatGPT는 SSR을 수행할 수 있는 능력이 있지만 제한 사항도 존재함을 확인했습니다. 연구자들은 SSR 수행 시 ChatGPT를 사용하는 데 필요한 가이드라인을 제시했습니다.



### Exploring Semantic Clustering in Deep Reinforcement Learning for Video Games (https://arxiv.org/abs/2409.17411)
- **What's New**: 이 논문에서는 비디오 게임을 위한 딥 강화 학습(Deep Reinforcement Learning, DRL)의 의미 클러스터링(semaitc clustering) 특성을 조사하여 DRL의 내부 동역학을 이해하고 그 해석 가능성을 발전시킵니다.

- **Technical Details**: 제안된 새로운 DRL 아키텍처는 의미 클러스터링 모듈을 통합하여 특징 차원 축소(feature dimensionality reduction) 및 온라인 클러스터링(online clustering)을 지원합니다. 이 모듈은 DRL 훈련 파이프라인에 원활하게 통합되어 기존의 t-SNE 기반 분석 방법에서 보였던 불안정성 문제를 해결하고, 광범위한 수동 주석(manual annotation)의 필요성을 제거합니다.

- **Performance Highlights**: 실험을 통해 제안된 모듈 및 DRL의 의미 클러스터링 특성의 효과성을 검증하였으며, 이를 기반으로 정책(policy)의 계층 구조(hierarchical structure) 및 특징 공간(feature space) 내의 의미 분포(semantic distribution)를 이해하는 데 도움이 되는 새로운 분석 방법을 소개합니다.



### Post-hoc Reward Calibration: A Case Study on Length Bias (https://arxiv.org/abs/2409.17407)
Comments:
          Preprint

- **What's New**: 이 논문은 Large Language Models (LLMs)의 보상 모델 (Reward Model, RM)의 편향을 교정하는 데 도움을 주는 'Post-hoc Reward Calibration' 개념을 소개합니다. 이 접근법은 추가 데이터나 훈련 없이도 성능 향상을 가능하게 합니다.

- **Technical Details**: 편향된 보상을 분해하여 잠재적인 진짜 보상과 특정 특성에 의존하는 편향 항으로 나누는 방법론을 제시합니다. 이를 위해 Locally Weighted Regression 기법을 사용하여 편향을 추정하고 제거하는 방식을 채택하였습니다.

- **Performance Highlights**: 본 연구는 세 가지 실험 설정에서 다음과 같은 성과 향상을 입증하였습니다: 1) RewardBench 데이터셋의 33개 RM에서 평균 3.11 성능 향상, 2) AlpacaEval 벤치마크에 기반한 GPT-4 평가 및 인간 선호도와의 RM 순위 개선, 3) 다양한 LLM-RM 조합에서 RLHF 과정의 Length-Controlled 승률 향상.



### AI Enabled Neutron Flux Measurement and Virtual Calibration in Boiling Water Reactors (https://arxiv.org/abs/2409.17405)
- **What's New**: 이 논문에서는 고온수로(Cooling Water Reactor)에서의 전력 분포를 정확하게 측정하기 위한 새로운 접근법을 제시합니다. 특히, 두 가지 딥러닝(DL) 모델인 SurrogateNet과 LPRMNet을 통해 오프라인과 온라인 전력 분포 간의 편향을 줄이고, 안전하고 경제적인 Reload Core 설계를 가능하게 합니다.

- **Technical Details**: SurrogateNet은 다른 LPRM의 판독값을 이용해 특정 LPRM의 판독값을 예측하고, LPRMNet은 원자로의 상태 변수를 기반으로 LPRM 값을 예측합니다. 두 모델 모두 작동 주파수는 약 1Hz이며, LPRM 시스템은 핵심 신호를 제공합니다. DNN 아키텍처들은 각각 1%와 3%의 테스트 오류를 보여줍니다.

- **Performance Highlights**: 모델의 응용으로는 LPRM이 우회되거나 오류가 발생했을 때의 가상 센서 기능, 연속 캘리브레이션 간의 가상 캘리브레이션, LPRM의 종말 수명(EOL) 결정의 높은 정확성 등이 포함됩니다. 이로 인해 오프라인과 예측된 전력 분포 간의 편향이 감소하게 됩니다.



### Search for Efficient Large Language Models (https://arxiv.org/abs/2409.17372)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 본 논문은 Large Language Models (LLMs)의 최적 아키텍처를 찾기 위한 트레이닝이 필요 없는 아키텍처 검색 프레임워크를 제안합니다. 이 방법은 기존 LLM의 기본 강점을 유지하면서도 추론 속도를 향상시키는 최적의 서브넷을 식별하는 것을 목표로 합니다.

- **Technical Details**: 새로운 아키텍처 검색 방법은 초기 아키텍처의 가중치 중요성을 기반으로 하여 초기 아키텍처를 설정하고, 진화 기반(Path-based) 알고리즘을 통해 효율적인 서브넷을 글로벌하게 검색합니다. 최종적으로, 선택된 서브넷의 가중치를 조정하기 위해 ADMM(Alternating Direction Method of Multipliers) 기반의 재형성 알고리즘을 도입합니다.

- **Performance Highlights**: 제안된 방법은 여러 기준점에서 SOTA 구조적 가지치기(SOTA structured pruning) 작업들을 초월하는 성능을 나타내며, GPU 메모리 사용량을 줄이고 추론 속도를 크게 향상시킵니다. 예를 들어, LLaMA-7B 모델에서는 perplexity가 10.21로, LLM-Pruner의 38.27보다 우수한 성과를 보였습니다.



### A Hybrid Quantum-Classical AI-Based Detection Strategy for Generative Adversarial Network-Based Deepfake Attacks on an Autonomous Vehicle Traffic Sign Classification System (https://arxiv.org/abs/2409.17311)
- **What's New**: 이번 연구에서는 자율주행차량(AV)의 교통신호 인식 시스템을 속이기 위한 딥페이크(deepfake) 공격 방법을 제시했습니다. 딥페이크 기술이 악의적인 공격에서 어떻게 활용될 수 있는지를 탐구하였습니다.

- **Technical Details**: 연구진은 생성적 적대 신경망(Generative Adversarial Network, GAN)을 기반으로 한 딥페이크 공격을 설계하였습니다. 하이브리드 양자-고전적 신경망(hybrid quantum-classical neural networks, NNs)을 활용하여 교통신호 이미지의 특징을 양자 상태로 암호화하는 방식으로 메모리 요구량을 감소시켰습니다.

- **Performance Highlights**: 하이브리드 딥페이크 탐지 접근법은 실제 및 딥페이크 교통신호 이미지에 대해 여러 베이스라인 고전적 합성곱 신경망(classical convolutional NNs)과 비교 평가한 결과, 대부분의 경우 베이스라인보다 유사하거나 높은 성능을 나타냈고, 가장 얕은 고전적 합성곱 NN의 메모리 사용량의 1/3 이하에서 실행될 수 있음을 보여주었습니다.



### Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning (https://arxiv.org/abs/2409.17270)
- **What's New**: 이 연구에서는 LLM(대형 언어 모델)의 출력 신뢰성과 투명성을 높이기 위해 'Proof of Thought'라는 새로운 프레임워크를 소개합니다. 이 프레임워크는 LLM이 생성한 아이디어와 형식 논리 검증을 연결합니다.

- **Technical Details**: Proof of Thought는 사용자 친화적인 개념을 사용하는 JSON 기반의 도메인 특화 언어(DSL)로, 이를 통해 LLM의 출력을 1차 논리(First Order Logic) 구조로 변환하는 커스텀 인터프리터를 사용합니다. 이 방법은 논리적 구조와 인간이 이해할 수 있는 개념 사이의 균형을 이루도록 설계되었습니다.

- **Performance Highlights**: Proof of Thought는 StrategyQA 및 새로운 멀티모달 추론 작업에서 효과를 입증하였으며, 개방형 시나리오에서 향상된 성능을 보였습니다. 이는 AI 시스템의 책임성을 다루고, 높은 위험 도메인에서 인간의 관여를 위한 기초를 설정하는 데 기여합니다.



### AAPM: Large Language Model Agent-based Asset Pricing Models (https://arxiv.org/abs/2409.17266)
- **What's New**: 이 연구에서는 LLM 에이전트를 활용한 새로운 자산 가격 책정 접근 방식인 LLM Agent-based Asset Pricing Models (AAPM)을 제안합니다. 이 방법은 정성적인 투자 분석과 정량적인 경제적 요인을 결합하여 자산의 초과 수익을 예측하는 데 중점을 둡니다.

- **Technical Details**: AAPM 모델은 최신 뉴스 분석을 반복적으로 수행하는 LLM 에이전트를 사용하며, 이전 분석 보고서와 책, 백과사전, 저널 등을 포함하는 지식 기반을 지원합니다. 이 모델은 분석 보고서와 수동 요인을 결합하여 향후 초과 자산 수익을 예측합니다.

- **Performance Highlights**: 실험 결과, AAPM은 머신러닝 기반 자산 가격 책정 기준을 초월하여 샤프 비율을 9.6% 향상시키고 자산 가격 오류에 대한 평균 |α|를 10.8% 개선했습니다.



### Collaborative Comic Generation: Integrating Visual Narrative Theories with AI Models for Enhanced Creativity (https://arxiv.org/abs/2409.17263)
Comments:
          This paper has been accepted for oral presentation at CREAI2024, ECAI, 2024. However, the author's attendance is currently uncertain due to visa issues

- **What's New**: 이 연구에서는 컴퓨터 생성 모델을 활용하여 만화 생성 과정의 효율성을 향상시키기 위해 새로운 시각적 내러티브 생성 시스템을 제안합니다. 이 시스템은 인간의 창의성과 AI 모델을 결합하여 만화 콘텐츠 제작을 지원하는 협업 플랫폼을 제공합니다.

- **Technical Details**: 시스템은 다중 AI 모델을 활용하여 저자들이 생성 과정을 사용자 지정할 수 있는 사람-중심(‘human-in-the-loop’) 워크플로우로 구조화되어 있습니다. 주요 구성 요소로는 그래픽 사용자 인터페이스(GUI), 모델 컨테이너, 이미지 시퀀스 모델, 생성기, 렌더러 등 여섯 개의 모듈이 있습니다.

- **Performance Highlights**: 이 시스템은 스토리 요소가 잘 반영된 이미지 시퀀스를 생성하며, 저자들이 부분적으로 수정할 수 있도록 하여 만화 제작을 더 유연하고 효율적으로 만듭니다. 또한 드라마틱한 이야기 전개와 캐릭터 일관성을 보장합니다.



### Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography (https://arxiv.org/abs/2409.18119)
Comments:
          This work is also the basis of the overall best solution for the MICCAI 2024 CXR-LT Challenge

- **What's New**: 이 연구는 의료 영상 분야에서 Contrastive Language-Image Pre-training (CLIP) 모델의 초기 적응을 유방 촬영술에 적용하고, 데이터 부족과 고해상도 이미지의 세부 사항 강조를 해결하기 위한 새로운 접근 방식을 제안합니다.

- **Technical Details**: 제안하는 방법은 Multi-view와 Multi-scale Alignment (MaMA)를 기반으로 하며, 각 관점에서 정보를 활용하여 multi-view mammography의 특징을 동시에 정렬하는 시스템을 구축합니다. 또한, clinical report 부족 문제를 해결하기 위해 template-based report construction 방식을 개발하고, parameter-efficient fine-tuning 기법을 적용합니다.

- **Performance Highlights**: EMBED 및 RSNA-Mammo의 대규모 실제 유방촬영 데이터셋에서 3개의 다른 작업에 대해 기존 방법보다 우수한 성능을 보여주었으며, 모델 크기의 52%만으로도 뛰어난 성과를 달성했습니다.



### Find Rhinos without Finding Rhinos: Active Learning with Multimodal Imagery of South African Rhino Habitats (https://arxiv.org/abs/2409.18104)
Comments:
          9 pages, 9 figures, IJCAI 2023 Special Track on AI for Good

- **What's New**: 이 연구는 코뿔소 보호를 위한 새로운 접근 방식을 제안하고 있으며, 코뿔소의 집단 배변 장소를 지도화하는 것을 통해 이들의 공간 행동에 대한 정보를 수집할 수 있는 방법을 모색하고 있다.

- **Technical Details**: 이 논문은 원거리에서 감지된 열 감지(thermal), RGB, LiDAR 이미지를 사용하여 코뿔소 배변 장소를 탐지하는 분류기를 구축하고, 수동적 및 능동적 학습 설정에서 이를 수행한다. 특히, 기존 능동 학습 방법들이 지극히 불균형한 데이터셋의 문제로 성능이 저하되는 문제를 해결하기 위해, MultimodAL이라고 불리는 새로운 능동 학습 시스템을 설계하였다.

- **Performance Highlights**: 제안된 방법은 94% 감소된 라벨 수로 수동적 학습 모델과 경쟁력을 갖추며, 유사한 크기의 데이터셋에 적용할 경우 라벨링 시간에서 76시간 이상을 절약할 수 있는 것으로 나타났다. 또한, 연구 결과 배변 장소가 무작위 분포가 아니라 클러스터 형태로 밀집해 있다는 점을 발견하여, 이에 따라 기동대(rangers) 활동의 효율성을 높이기 위한 방안을 제시하고 있다.



### AI-Powered Augmented Reality for Satellite Assembly, Integration and Tes (https://arxiv.org/abs/2409.18101)
- **What's New**: 이번 논문은 인공지능(AI)과 증강현실(AR)의 통합을 통해 위성 조립, 통합 및 테스트(AIT) 프로세스를 혁신하려는 유럽우주청(ESA)의 프로젝트 "AI for AR in Satellite AIT"에 대해 설명합니다. 이 시스템은 Microsoft HoloLens 2를 사용하여 기술자에게 실시간으로 맥락에 맞는 지침과 피드백을 제공합니다.

- **Technical Details**: AI4AR 시스템은 컴퓨터와 AR 헤드셋으로 구성되어 있으며, 객체 감지 및 추적, 6D 포즈 추정과 OCR을 포함한 다양한 컴퓨터 비전 알고리즘을 이용합니다. 특히, 6D 포즈 모델 훈련에 합성 데이터를 사용하는 접근법이 독창적이며, 이는 AIT 프로세스의 복잡한 환경에서 유용합니다.

- **Performance Highlights**: AI 모델의 정확도가 70%를 넘었고, 객체 감지 모델은 95% 이상의 정확도를 기록했습니다. 자동 주석화 기능을 가진 Segmented Anything Model for Automatic Labelling(SAMAL)을 통해 실제 데이터의 주석화 속도가 수동 주석화보다 최대 20배 빨라졌습니다.



### EfficientCrackNet: A Lightweight Model for Crack Segmentation (https://arxiv.org/abs/2409.18099)
- **What's New**: 본 연구에서는 Convolutional Neural Networks (CNNs)와 transform architecture를 결합한 EfficientCrackNet이라는 경량 하이브리드 모델을 제안합니다. 이 모델은 정밀한 균열(segmentation) 감지를 위해 설계되었으며, 높은 정확도와 낮은 계산 비용을 동시에 제공합니다.

- **Technical Details**: EfficientCrackNet 모델은 depthwise separable convolutions (DSC)와 MobileViT block을 통합하여 전역 및 지역 특성을 캡처합니다. Edge Extraction Method (EEM)를 사용하여 사전 훈련 없이도 효율적인 균열 가장자리 감지를 수행하며, Ultra-Lightweight Subspace Attention Module (ULSAM)을 통해 특성 추출을 향상합니다.

- **Performance Highlights**: 세 개의 벤치마크 데이터셋(Crack500, DeepCrack, GAPs384)을 기반으로 한 광범위한 실험에 따르면, EfficientCrackNet은 단 0.26M의 파라미터와 0.483 FLOPs(G)만으로 기존의 경량 모델들보다 우수한 성능을 보였습니다. 이 모델은 정확성과 계산 효율성 간의 최적의 균형을 제공하여 실제 균열 분할 작업에 강력하고 적응 가능한 솔루션을 제공합니다.



### DiffSSC: Semantic LiDAR Scan Completion using Denoising Diffusion Probabilistic Models (https://arxiv.org/abs/2409.18092)
Comments:
          Under review

- **What's New**: 이 논문에서는 자율 주행 차량을 위한 Semantic Scene Completion (SSC) 작업을 다루고 있으며, LiDAR(빛 감지 및 범위 측정) 센서로부터 얻는 드문 드로우 포인트 클라우드의 빈 공간과 폐쇄된 지역을 예측할 수 있는 방안을 제시합니다.

- **Technical Details**: 제안된 DiffSSC 방법론은 Denoising Diffusion Probabilistic Models (DDPM)을 기반으로 하여 점진적인 노이즈 제거를 통해 LiDAR 점 클라우드를 처리합니다. 이 과정에서는 기하학 및 의미적 정보가 동시에 모델링되며, 로컬과 글로벌 정규화 손실을 통해 학습 과정을 안정화합니다.

- **Performance Highlights**: 제안된 방법은 자율 주행 데이터셋에서 기존의 최첨단 SSC 방법보다 우수한 성능을 보이며, LiDAR 점 클라우드 처리에서 메모리 사용량 및 양자화 오류를 줄이는 데 성공했습니다.



### GSON: A Group-based Social Navigation Framework with Large Multimodal Mod (https://arxiv.org/abs/2409.18084)
- **What's New**: 이번 연구에서는 GSON이라고 명명된 그룹 기반 사회 내비게이션 프레임워크를 소개합니다. 이 프레임워크는 모바일 로봇이 주변의 사회 집단을 인식하고 활용할 수 있도록 지원하여, 사회적 맥락을 고려한 내비게이션을 가능하게 합니다.

- **Technical Details**: GSON은 Large Multimodal Model (LMM)의 시각적 추론 능력을 활용하여 보행자 간의 사회적 관계를 제로샷(Zero-shot)으로 추출하는 시각적 프롬프팅 기법을 적용합니다. 로봇은 2D LiDAR와 RGB 카메라를 통해 주변 환경을 감지하고, 사회 집단 추정 모듈과 사회적으로 인식된 계획 모듈을 통해 경로를 계획합니다. GSON은 글로벌 경로 계획(global path planning)과 로컬 동작 계획(local motion planning) 간의 중간 수준 계획(mid-level planning)을 통해 사회적 구조를 유지하며 움직임을 조율합니다.

- **Performance Highlights**: GSON 프레임워크는 다양한 사회적 상호작용 시나리오에서 강화된 로봇 내비게이션 성능을 보여주며, 기존의 기준선 방법들보다 사회 구조를 최소한으로 방해하며 내비게이션할 수 있는 효과성을 입증하였습니다.



### SKT: Integrating State-Aware Keypoint Trajectories with Vision-Language Models for Robotic Garment Manipulation (https://arxiv.org/abs/2409.18082)
- **What's New**: 이 연구에서는 다양한 의류 소목(garment categories)에 대해 단일 모델로 키포인트(keypoint) 예측을 개선하기 위해 비전-언어 모델(vision-language models, VLM)을 사용하는 통합 접근 방식을 제안합니다. 본 연구는 의류의 다양한 변형 상태를 관리하는 데 도움을 줄 수 있는 새로운 접근법을 제시합니다.

- **Technical Details**: 제안된 방법은 상태 인식 쌍 키포인트 생성(State-aware paired keypoint formation) 기법을 활용하여 다양한 의류 환경에 잘 일반화되는 상태 인식 키포인트 궤적(State-aware Keypoint Trajectories)을 생성합니다. 이를 통해 비주얼 시그널과 텍스트 설명을 함께 해석할 수 있으며, 고급 물리 시뮬레이터를 이용한 대규모 합성 데이터셋을 통해 훈련됩니다.

- **Performance Highlights**: 실험 결과, VLM 기반 방법이 키포인트 감지 정확성과 작업 성공률을 획기적으로 향상시켜 주목받았습니다. 이 연구는 VLM을 활용하여 장기적으로 홈 자동화 및 보조 로봇 분야에서의 폭넓은 응용 가능성을 제시하고 있습니다.



### FreeEdit: Mask-free Reference-based Image Editing with Multi-modal Instruction (https://arxiv.org/abs/2409.18071)
Comments:
          14 pages, 14 figures, project website: this https URL

- **What's New**: 본 논문에서는 사용자가 지정한 시각적 개념을 기반으로 한 이미지 편집을 가능하게 하는 FreeEdit라는 새로운 접근법을 제안합니다. 이 방법은 사용자가 제공한 언어 명령을 통해 참조 이미지를 효과적으로 재현할 수 있도록 합니다.

- **Technical Details**: FreeEdit는 다중 모달 instruction encoder를 활용하여 언어 명령을 인코딩하고, 이를 기반으로 편집 과정을 안내합니다. Decoupled Residual ReferAttention (DRRA) 모듈을 통해 참조 이미지에서 추출한 세밀한 특성을 이미지 편집 과정에 효과적으로 통합합니다. 또한, FreeBench라는 고품질 데이터셋을 구축하였으며, 이는 원본 이미지, 편집 후 이미지 및 참조 이미지를 포함하여 다양한 편집 태스크를 지원합니다.

- **Performance Highlights**: FreeEdit는 객체 추가 및 교체와 같은 참고 기반 이미지 편집 작업에서 기존 방법보다 우수한 성능을 보이며, 수동 편집 마스크를 필요로 하지 않아 사용의 편리함을 크게 향상시킵니다. 실험을 통해 얻은 결과는 FreeEdit가 고품질 제로샷(zero-shot) 편집을 달성하고, 편리한 언어 명령으로 사용자 요구를 충족할 수 있음을 보여줍니다.



### Visual Data Diagnosis and Debiasing with Concept Graphs (https://arxiv.org/abs/2409.18055)
- **What's New**: CONBIAS는 비주얼 데이터셋의 Concept co-occurrence Biases를 진단하고 완화하기 위해 개발된 새로운 프레임워크입니다. 이는 비주얼 데이터셋을 지식 그래프(knowledge graph)로 표현하여 편향된 개념의 동시 발생을 분석하고 이를 통해 데이터셋의 불균형을 파악합니다.

- **Technical Details**: CONBIAS 프레임워크는 세 가지 주요 단계로 이루어져 있습니다: (1) Concept Graph Construction: 데이터셋에서 개념의 지식 그래프를 구축합니다. (2) Concept Diagnosis: 생성된 지식 그래프를 분석하여 개념 불균형을 진단합니다. (3) Concept Debiasing: 그래프 클리크(clique)를 사용해 불균형한 개념 조합을 샘플링하고 이에 대한 이미지를 생성하여 데이터셋을 보완합니다. 이 과정에서 대규모 언어 모델의 의존성을 줄였습니다.

- **Performance Highlights**: CONBIAS를 기반으로 한 데이터 증강(data augmentation) 방법이 여러 데이터셋에서 일반화 성능을 향상시키는 데 성공적임을 보여줍니다. 기존의 최첨단 방법들과 비교했을 때, 균형 잡힌 개념 분포에 기반한 데이터 증강이 분류기의 전반적인 성능을 개선시킴을 실험을 통해 입증하였습니다.



### DualAD: Dual-Layer Planning for Reasoning in Autonomous Driving (https://arxiv.org/abs/2409.18053)
Comments:
          Autonomous Driving, Large Language Models (LLMs), Human Reasoning, Critical Scenario

- **What's New**: 새로운 자율주행 프레임워크인 DualAD가 소개되었습니다. 본 프레임워크는 인간의 추론을 모방하여 자율주행 시스템의 성능을 향상시키는 데 중점을 두고 있습니다. DualAD는 하위 계층에서는 규칙 기반의 동작 계획자(rule-based motion planner)가 작동하고, 상위 계층에서는 규칙 기반의 텍스트 인코더(rule-based text encoder)가 주행 시나리오를 텍스트 설명으로 변환한 후, 이를 대형 언어 모델(LLM)이 처리하여 주행 결정을 내립니다.

- **Technical Details**: DualAD는 두 개의 레이어로 구성됩니다. 첫 번째 레이어는 기본적인 주행 작업을 수행하는 규칙 기반의 동작 계획자이며, 두 번째 레이어는 주행 시나리오를 텍스트로 변환하고 이를 LLM을 통해 처리합니다. 특히, 잠재적 위험이 탐지되면 상위 레이어가 하위 레이어의 결정을 수정하여 인간의 사고 방식을 모방합니다.

- **Performance Highlights**: DualAD는 제로샷(zero-shot)으로 학습된 LLM을 활용하여 일반적인 규칙 기반 동작 계획자보다 뛰어난 성능을 보여주었습니다. 특히, 텍스트 인코더의 효과적인 활용이 모델의 시나리오 이해도를 크게 향상시켰으며, 통합된 DualAD 모델은 강력한 LLM이 추가될수록 성능이 개선됨을 알 수 있었습니다.



### Revisit Anything: Visual Place Recognition via Image Segment Retrieva (https://arxiv.org/abs/2409.18049)
Comments:
          Presented at ECCV 2024; Includes supplementary; 29 pages; 8 figures

- **What's New**: 이번 연구에서는 Embodied agents가 시각적으로 장소를 인식하고 이동하는 데 있어 중요한 문제를 다루었습니다. 전체 이미지를 사용하는 기존 방법 대신, 이미지의 '세그먼트'를 인코딩하고 검색하는 새로운 접근 방식을 제안합니다. 이를 통해 SuperSegment라는 새로운 이미지 표현을 생성하여 장소 인식을 향상시킵니다.

- **Technical Details**: 제안된 SegVLAD는 Open-set 이미지 분할(open-set image segmentation)을 통해 이미지를 의미있는 요소(entities)로 분해합니다. 각 아이템은 SuperSegments로 연결되어 구조화됩니다. 새로 제안된 Feature aggregation 방법을 사용하여 이 SuperSegments를 효율적으로 컴팩트한 벡터 표현으로 인코딩합니다. SegVLAD는 다양한 벤치마크 데이터셋에서 기존의 방법보다 높은 인식 리콜을 기록했습니다.

- **Performance Highlights**: SegVLAD는 다양한 VPR 벤치마크 데이터셋에서 최첨단 성능을 달성했습니다. IOU 기반 필터링을 통해 중복성을 줄이고 스토리지를 절약하며, 전체 이미지 기반 검색보다 더욱 뛰어난 성능을 보입니다. 연구 결과, SegVLAD는 이미지 인코더의 특정 작업에 관계없이 적용 가능하고, 객체 인스턴스 검색(object instance retrieval) 과제를 평가하여 '무언가를 재방문(revisit anything)'할 수 있는 잠재력을 보여주었습니다.



### HARMONIC: Cognitive and Control Collaboration in Human-Robotic Teams (https://arxiv.org/abs/2409.18047)
Comments:
          Submitted to ICRA 2025 Conference, Atlanta, GA, USA

- **What's New**: 이 논문은 다중 로봇 계획 및 협력에 대한 새로운 접근 방식을 선보입니다. 로봇과 인간이 팀을 이루어 작업할 때 인지 전략을 포함하여 메타인지, 자연어 통신 및 설명 가능성을 통합한 시스템을 설명합니다.

- **Technical Details**: HARMONIC 아키텍처를 사용하여 인지 및 제어 기능을 팀 전반에 걸쳐 유연하게 통합합니다. 유연한 중앙집중식 및 분산 방식의 계획 접근 방식을 활용하여 로봇이 목표, 계획, 태도를 인식하고 그들의 행동과 결정에 대한 설명을 제공할 수 있도록 합니다.

- **Performance Highlights**: 이 연구는 이질적인 로봇 팀(UGV 및 드론 포함)이 인간과 함께 공동 검색 작업을 수행하는 시뮬레이션 실험 결과를 통해 복잡한 실제 시나리오를 처리하는 로봇 팀의 능력을 보여줍니다.



### IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning (https://arxiv.org/abs/2409.18046)
Comments:
          Accepted to EMNLP 2024

- **What's New**: 최근 이미지 캡셔닝(image captioning) 분야에서 이미지-텍스트 데이터 쌍의 한계를 극복하기 위해 텍스트-전용(training) 교육 방법이 탐색되고 있습니다. 본 논문에서는 텍스트 데이터와 이미지 데이터 간의 모달리티 차이를 완화하기 위한 새로운 접근 방식으로 'Image-like Retrieval'을 제안합니다.

- **Technical Details**: 제안된 방법인 IFCap($\textbf{I}$mage-like Retrieval과 $\textbf{F}$requency-based Entity Filtering for Zero-shot $\textbf{Cap}$tioning)는 효율적인 이미지 캡셔닝을 위한 통합 프레임워크로, Fusion Module을 통해 검색된 캡션과 입력 특성을 통합하여 캡션 품질을 향상시킵니다. 또한 Frequency-based Entity Filtering 기술을 도입하여 더 나은 캡션 품질을 제공합니다.

- **Performance Highlights**: 광범위한 실험 결과, IFCap은 기존의 텍스트-전용 훈련 기반 제로샷 캡셔닝(zero-shot captioning) 방식에 비해 이미지 캡셔닝과 비디오 캡셔닝 모두에서 state-of-the-art 성능을 기록하는 것으로 나타났습니다.



### HARMONIC: A Framework for Explanatory Cognitive Robots (https://arxiv.org/abs/2409.18037)
Comments:
          Accepted for presentation at ICRA@40. 23-26 September 2024, Rotterdam, Netherlands

- **What's New**: HARMONIC 프레임워크는 일반 목적의 로봇을 신뢰할 수 있는 팀원으로 변환하여 복잡한 의사결정, 자연어 소통 및 인간 수준의 설명을 가능하게 하는 시스템입니다.

- **Technical Details**: HARMONIC은 전략적(cognitive) 레이어와 전술적(robot) 레이어로 구성된 이중 제어 아키텍처를 가지고 있으며, 이 두 레이어는 독립적으로 상호작용합니다. 전략적 레이어는 주의 관리, 지각 해석 및 유틸리티 기반 의사결정 모듈을 포함하고, 전술적 레이어는 센서 입력 처리 및 로봇 제어를 담당합니다.

- **Performance Highlights**: 초기 구현에서는 인간-로봇 팀이 아파트 환경에서 분실된 열쇠를 찾는 시뮬레이션 작업을 수행합니다. HARMONIC 기반의 로봇인 UGV와 드론이 인간과 협력하여 검색 매개변수를 설정하고 전략적 계획을 선택 및 실행합니다.



### An Adversarial Perspective on Machine Unlearning for AI Safety (https://arxiv.org/abs/2409.18025)
- **What's New**: 이번 연구는 기존의 unlearning(언러닝) 방법이 안전성 훈련(safety training)에서의 위험한 정보 제거를 효과적으로 대체할 수 있는지를 조명합니다. 연구자들은 unlearning이 단순히 정보를 숨기는데 그치고, 위험한 지식이 여전히 회복될 수 있음을 보여줍니다.

- **Technical Details**: 이 논문은 RMU(Residual Memory Unlearning)와 같은 상태-of-the-art unlearning 방법을 평가하며, WMDP(WMD Probing) 벤치마크를 사용하여 안전성 훈련과 비교합니다. 기존 보고된 jailbreak 방법들은 unlearning에 무효로 간주되었으나, 세심하게 적용될 경우 여전히 효과적일 수 있음을 발견하였습니다. 이들은 특정 활성 공간 방향을 제거하거나 무관한 예제를 가진 finetuning을 통해 원래의 성능을 복구할 수 있는 방법을 제시합니다.

- **Performance Highlights**: 연구 결과, unlearning 방법은 특정 공격에 보다 강해 보이지만, 안전성 훈련에 사용된 기법으로 쉽게 우회될 수 있습니다. 특히, GCG와 같은 jailbreak 기법은 손실 함수를 약간 변경함으로써 의미 있는 정확도를 회복할 수 있음을 보여주었습니다.



### Transferring disentangled representations: bridging the gap between synthetic and real images (https://arxiv.org/abs/2409.18017)
- **What's New**: 이 연구는 합성 데이터(synthetic data)를 사용하여 실제 데이터에 적용 가능한 일반 목적의 분리 표현(disentangled representation)을 학습할 가능성을 탐구합니다. 이 과정에서 성능을 향상시키기 위한 미세 조정(fine-tuning)의 효과와 전이(transfer) 후 보존되는 분리 특성에 대해 논의합니다.

- **Technical Details**: 본 연구에서는 OMES (Overlap Multiple Encoding Scores)라는 새로운 간섭 기반(intervention-based) 지표를 제안하여, 표현에서 인코딩된 요소들의 품질을 측정합니다. 이는 기존의 분류기(classifier) 의존적인 방법들과는 달리, 분류기 없는(intervention-based) 접근을 채택하여 요소의 분포를 분석하며, 데이터를 쌍으로 매칭하여 단일 요소만 다르게 하여 평가합니다.

- **Performance Highlights**: 연구 결과, 합성 데이터에서 학습된 표현을 실제 데이터로 전이할 수 있는 가능성이 있으며, 일부 분리 수준이 효과적임을 보여줍니다. 특히, 다양한 (Source, Target) 쌍에 대한 실험을 통해 학습된 DR의 표현력이 잘 평가됨을 확인하였습니다.



### Control Industrial Automation System with Large Language Models (https://arxiv.org/abs/2409.18009)
- **What's New**: 이 논문은 대형 언어 모델(LLM)을 산업 자동화 시스템에 통합하기 위한 새로운 프레임워크를 제안합니다.

- **Technical Details**: 프레임워크는 산업 업무를 위한 에이전트 시스템, 구조화된 프로프트(prompting) 방법 및 사건 기반(event-driven) 정보 모델링 메커니즘을 포함하고 있으며, 이는 LLM 추론을 위한 실시간 데이터를 제공합니다.

- **Performance Highlights**: 제안된 방법은 LLM이 정보 해석, 생산 계획 생성 및 자동화 시스템의 작업 제어를 가능하게 하여 산업 자동화 시스템의 적응력을 높이고 자연어를 통한 더 직관적인 인간-기계 상호 작용을 지원합니다.



### Joint Localization and Planning using Diffusion (https://arxiv.org/abs/2409.17995)
Comments:
          7 pages, 9 figures. Submitted to ICRA 2025, under review

- **What's New**: 이번 연구에서는 로봇 내비게이션 문제 해결을 위한 새로운 Diffusion 모델을 제안합니다. 이는 전방향 로컬라이제이션(global localization)과 경로 계획(path planning), 두 가지 프로세스를 통합하여 임의의 2D 환경에서의 탐색을 가능하게 합니다.

- **Technical Details**: 제안된 모델은 LIDAR 스캔, 장애물 맵 및 목표 위치에 의존하여 충돌 없는 경로를 생성합니다. 연구는 SE(2) 공간에서의 확산을 구현하며, 장애물과 센서 관측치에 따라 디노이징 과정이 어떻게 조정되는지를 설명합니다.

- **Performance Highlights**: 실험 결과, 제안된 조건화 기법이 훈련 환경과 상당히 다른 외관의 현실적인 맵에 대한 일반화를 가능하게 하며, 불확실한 솔루션을 정확히 설명할 수 있음을 보여주었습니다. 또한, 실제 환경에서의 실시간 경로 계획 및 제어를 위한 모델의 활용 가능성을 시연했습니다.



### HydraViT: Stacking Heads for a Scalable V (https://arxiv.org/abs/2409.17978)
- **What's New**: 새로운 HydraViT 접근 방식은 다중 크기의 Vision Transformers (ViTs) 모델을 학습하고 저장하는 필요성을 없애면서, 스케일러블한 ViT를 가능하게 합니다.

- **Technical Details**: HydraViT는 Multi-head Attention (MHA) 메커니즘을 기반으로 하여, 다양한 하드웨어 환경에 적응할 수 있도록 임베딩 차원과 MHA의 헤드 수를 동적으로 조정합니다. 이 방식은 최대 10개의 서브 네트워크를 생성할 수 있습니다.

- **Performance Highlights**: HydraViT는 ImageNet-1K 데이터셋에서 동일한 GMACs와 처리량을 기준으로, 기존 모델 대비 최대 7 p.p. 높은 정확성을 달성하며, 이는 다양한 하드웨어 환경에서 특히 유용합니다.



### Weak-To-Strong Backdoor Attacks for LLMs with Contrastive Knowledge Distillation (https://arxiv.org/abs/2409.17946)
- **What's New**: 이번 연구에서는 Parameter-Efficient Fine-Tuning (PEFT)을 사용하는 대규모 언어 모델(LLMs)에 대한 백도어 공격의 효율성을 검증하고, 이를 개선하기 위한 새로운 알고리즘인 W2SAttack(Weak-to-Strong Attack)을 제안합니다.

- **Technical Details**: W2SAttack은 약한 모델에서 강한 모델로 백도어 특징을 전이하는 대조적 지식 증류(constractive knowledge distillation) 기반의 알고리즘입니다. 이 알고리즘은 소규모 언어 모델을 사용하여 완전 파라미터 미세 조정을 통해 백도어를 임베드하고 이를 교사 모델로 활용하여 대규모 학생 모델로 전이합니다. 이 과정에서 정보를 최소화하여 학생 모델이 목표 레이블과 트리거 간의 정렬을 최적화하도록 합니다.

- **Performance Highlights**: W2SAttack은 여러 언어 모델과 백도어 공격 알고리즘을 대상으로 한 실험 결과에서 100%에 가까운 성공률을 기록했습니다. 이는 PEFT를 사용한 기존 백도어 공격의 성능을 크게 개선한 결과입니다.



### On Translating Technical Terminology: A Translation Workflow for Machine-Translated Acronyms (https://arxiv.org/abs/2409.17943)
Comments:
          AMTA 2024 - The Association for Machine Translation in the Americas organizes biennial conferences devoted to researchers, commercial users, governmental and NGO users

- **What's New**: 이번 논문에서는 기계 번역(Machine Translation, MT) 시스템에서 약어의 모호성 제거(acronym disambiguation)를 제안함으로써, 약어 번역의 정확성을 높이고자 하는 새로운 접근 방식을 소개합니다. 또한 새로운 약어 말뭉치(corpus)를 공개하고, 이를 기반으로 한 검색 기반 임계값(thresholding) 알고리즘을 실험하여 기존의 Google Translate와 OpusMT보다 약 10% 더 나은 성능을 보였습니다.

- **Technical Details**: 기계 번역 시스템의 약어 번역 정확도를 향상시키기 위해, 4단계의 고레벨 프로세스를 제안하였습니다. 이 프로세스는 (1) Google Translate를 사용하여 FR-EN 번역 수행, (2) 영어 장기형(long form, LF)과 단기형(short form, SF) 추출, (3) AB3P 툴을 사용한 약어 가설 생성, (4) 검색 기법을 통한 가설 검증 및 평가입니다. 이 방법들은 텍스트에서 사용된 기술 용어의 신뢰성을 향상시키는데 기여하고자 합니다.

- **Performance Highlights**: Google Translate와 OpusMT와 비교하여, 제안하는 임계값 알고리즘은 약 10%의 성능 향상을 보여주었습니다. 우리의 연구에서는 전문 번역사들이 자주 직면하는 용어 오류를 감소시키는 방안을 제시하고 있으며, 이를 통해 MT 시스템에서의 기술 용어 번역의 적합성을 증대시키는 데 기여할 것입니다.



### Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods (https://arxiv.org/abs/2409.17939)
Comments:
          AMTA 2024 - The Association for Machine Translation in the Americas organizes biennial conferences devoted to researchers, commercial users, governmental and NGO users

- **What's New**: 본 논문은 번역 메모리(Translation Memoires, TMs)와 컴퓨터 보조 번역(Computer-Aided Translation, CAT) 도구에서의 구문 정정 기법인 퍼지 매치 리페어(Fuzzy-Match Repair, FMR) 기술을 발전시키는 데 집중하고 있습니다. 특히, 기존의 기계 번역(Machine Translation, MT) 기법 대신 Word2Vec, BERT, 그리고 GPT-4와 같은 머신 러닝(machine learning) 기반 접근 방식을 사용하여 고정된 단어(anchor word) 번역의 정확성을 향상시킬 수 있는 방법을 제시합니다.

- **Technical Details**: 이 연구는 번역 시스템에서 고정된 단어의 번역을 개선하기 위해 네 가지 기술을 실험했습니다: (1) Neural Machine Translation(NMT), (2) BERT 기반 구현, (3) Word2Vec, (4) OpenAI GPT-4. 특히, 고정된 단어는 두 개의 단어 사이에 위치하며, 연속적인 단어의 가방(CBOW) 패러다임을 따른다고 설명합니다. 내재된 문맥(window) 내에서 각 단어에 가중치를 부여하여 주변 단어가 예측에 미치는 영향을 극대화할 수 있음을 강조하고 있습니다.

- **Performance Highlights**: 실험 결과, Word2Vec, BERT 및 GPT-4는 프랑스어에서 영어로의 번역에 있어 기존의 Neural Machine Translation 시스템보다 유사하거나 더 나은 성능을 보였습니다. 특히, 각 접근 방식이 고정된 단어 번역에서 성공적으로 작동하는 경우를 다루고 있습니다.



### Intelligent Energy Management: Remaining Useful Life Prediction and Charging Automation System Comprised of Deep Learning and the Internet of Things (https://arxiv.org/abs/2409.17931)
- **What's New**: 이번 연구는 배터리의 Remaining Useful Life (RUL)을 예측하기 위한 머신 러닝(Machine Learning) 기반 모델의 개발을 목표로 합니다. 또한 IoT(Internet of Things) 개념을 활용하여 충전 시스템을 자동화하고 결함을 관리하는 방법을 제시합니다.

- **Technical Details**: 연구에서는 catboost, Multi-Layer Perceptron (MLP), Gated Recurrent Unit (GRU) 모델 및 혼합 모델을 개발하여 차량의 RUL을 세 가지 클래스로 분류할 수 있는 성능을 보여줍니다. 이 데이터는 tkinter GUI를 통해 입력되고 pyserial 백엔드를 사용하여 Esp-32 마이크로컨트롤러에 연계되어 충전 및 방전 작업을 가능하게 합니다.

- **Performance Highlights**: 모델들은 99% 이상의 정확도로 RUL을 분류할 수 있으며, Blynk IoT 플랫폼을 사용해 다양한 차량 파라미터 간의 관계를 나타내는 그래프를 시뮬레이션합니다. 또한 자동화된 충전 및 에너지 절약 메커니즘을 위한 릴레이 기반 트리거링도 가능합니다.



### Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion (https://arxiv.org/abs/2409.17928)
Comments:
          EMNLP24 Findings

- **What's New**: 이번 연구에서는 Text-to-Image (T2I) diffusion 모델의 지식 편집을 위한 새로운 프레임워크를 제안합니다. 특히, 새로운 데이터셋 CAKE를 제작하고, 평가지표를 개선하는 adaptive CLIP threshold를 도입하며, Memory-based Prompt Editing (MPE) 접근 방식을 통해 효과적인 지식 업데이트를 구현합니다.

- **Technical Details**: T2I 모델의 편집 성능을 평가하기 위해 CAKE라는 데이터셋에서 paraphrase와 다중 객체 테스트를 포함하여 보다 정밀한 평가를 가능하게 합니다. 또한, 기존의 이진 분류 기반의 평가 방식에서 벗어나 이미지가 목표 사실과 '충분히' 유사한지를 측정하는 adaptive CLIP threshold라는 새로운 기준을 제안합니다. 이와 함께, MPE는 외부의 메모리에 모든 사실 편집을 저장하여 입출력 프롬프트의 오래된 부분을 수정합니다. 이를 통해 MPE는 기존 모델 편집기보다 뛰어난 성과를 보여줍니다.

- **Performance Highlights**: MPE 접근법은 기존의 모델 편집 기법보다 전반적인 성능과 적용 가능성에서 더 우수한 결과를 보였습니다. 연구 결과는 T2I 지식 편집 방법의 신뢰할 수 있는 평가를 촉진할 것으로 예상됩니다.



### PhantomLiDAR: Cross-modality Signal Injection Attacks against LiDAR (https://arxiv.org/abs/2409.17907)
- **What's New**: 이 논문은 LiDAR(빛 탐지 및 거리 측정) 시스템의 신뢰성을 위협하는 새로운 공격 벡터인 크로스 모디얼리티 신호 주입 공격(Cross-modality signal injection attacks)의 가능성을 조사합니다. 특히, 의도적인 전자기 간섭(IEMI)을 생성하여 LiDAR 출력을 조작하는 방법을 제시합니다.

- **Technical Details**: PhantomLiDAR 공격을 통해 LiDAR 시스템의 내부 센서와 모듈을 대상으로 하여 Points Interference, Points Injection, Points Removal, LiDAR Power-Off 등의 공격 방식을 구현하였습니다. 이 과정에서 EM 공격 장치를 사용하여 다양한 주파수 대역에서 취약점을 실험적으로 검색하고, 고유한 평가 방법을 통해 효과성을 검증했습니다.

- **Performance Highlights**: PhantomLiDAR는 시뮬레이션 및 실제 실험을 통해 최대 16,000개의 가짜 포인트를 주입할 수 있는 능력을 입증했습니다. 공격 거리 5미터에서도 목표물 숨기기가 가능하며, SOTA 기반 레이저 공격보다 5배 더 많은 포인트를 주입할 수 있는 성과를 달성했습니다.



### Revisiting Acoustic Similarity in Emotional Speech and Music via Self-Supervised Representations (https://arxiv.org/abs/2409.17899)
- **What's New**: 이 연구는 음성 감정 인식(SER)과 음악 감정 인식(MER) 간의 지식을 전이할 수 있는 가능성을 탐구하고, 자가 감독 학습(Self-Supervised Learning, SSL) 모델에서 추출된 공통의 음향 특징을 활용하여 감정 인식 성능을 향상시키는 방법을 제시합니다.

- **Technical Details**: 이 연구에서는 RAVDESS 데이터셋을 사용하여 SSL 모델의 층별 행동을 분석하고, 두 단계의 미세 조정을 통해 SER과 MER 간의 도메인 적응 방법을 비교합니다. 또한, Frechet 오디오 거리(Frechet audio distance)를 사용하여 감정별로 음성 및 음악의 음향 유사성을 평가합니다. 세 가지 SSL 모델(Wav2Vec 2.0, HuBERT, MERT)을 적용하여 각 모델의 음성 및 음악 데이터에서의 성능을 조사합니다.

- **Performance Highlights**: 연구 결과, SER과 MER에서 SSL 모델이 공통된 음향 특징을 잘 포착하긴 하지만, 각기 다른 감정에 따라 그 행동이 다르게 나타납니다. 또한, 효율적인 매개변수 기반 미세 조정을 통해 서로의 지식을 활용하여 SER과 MER 성능을 향상할 수 있음을 보여줍니다.



### Why Companies "Democratise" Artificial Intelligence: The Case of Open Source Software Donations (https://arxiv.org/abs/2409.17876)
Comments:
          30 pages, 1 figure, 5 tables

- **What's New**: 이 연구는 인공지능(AI) 민주화의 상업적 유인을 이해하는 것을 목표로 하며, 43개의 AI 오픈 소스 소프트웨어(OSS) 기부 사례를 분석하여 그에 대한 분류 체계를 제시합니다. 이를 통해 AI 민주화의 다양한 이점이 상업적 이익과 연결되어 있음을 강조합니다.

- **Technical Details**: 이 연구는 혼합 연구 방법(mixed-methods approach)을 사용하여 기업의 AI OSS 기부에 대한 상업적 유인을 조사합니다. 연구에서는 기부 전에 제출된 기술 발표, 기부 후 블로그 글, 설문조사, 반구조화된 인터뷰를 분석하고,OSS 프로젝트의 거버넌스 및 통제 권한을 민주화하는 것의 중요성에 대해 설명합니다.

- **Performance Highlights**: AI OSS 기부는 외부 기여자를 유치하고 개발 비용을 절감하며 산업 표준에 영향을 미치는 등 다운스트림 목표를 위한 구조적 촉진제 역할을 합니다. 개인 개발자의 하향식(bottom-up) 유인이 AI 민주화에 있어 중요함을 강조하며, 다른 AI 민주화 노력에 대한 유인을 이해하는 데 도움이 되는 틀과 도구를 제공합니다.



### Efficient Arbitrary Precision Acceleration for Large Language Models on GPU Tensor Cores (https://arxiv.org/abs/2409.17870)
- **What's New**: 해당 논문은 대형 언어 모델(LLM)의 효율적인 추론을 위한 새로운 가속화 방안을 제안합니다. 특히, 이 논문에서는 대칭 양자화(symmetric quantization)를 지원하는 새롭고 효율적인 데이터 형식인 bipolar-INT를 소개합니다.

- **Technical Details**: 제안된 방법은 주로 세 가지로 구성됩니다: (1) bipolar-INT 데이터 형식 도입; (2) 비트 수준에서 행렬을 분해하고 복원하는 방법으로 임의 정밀도(matrix multiplication에서 비트 수준 분해 및 복구) 행렬 곱셈(arbitrary precision MatMul) 스킴 구현; (3) 효율적인 행렬 전처리(matrix preprocessing) 방법 도입 및 데이터 회복 지향의 메모리 관리(memory management) 시스템 설계로, 이를 통해 GPU Tensor Core 활용을 극대화합니다.

- **Performance Highlights**: 실험 결과, 제안된 스킴은 NVIDIA의 CUTLASS와 비교할 때 행렬 곱셈에서 최대 13배의 속도 향상을 달성하며, LLM에 통합 시 추론 속도에서 최대 6.7배의 가속을 실현합니다. 이로 인해 LLM의 추론 효율이 크게 향상되어 더 넓고 반응성이 뛰어난 LLM 응용을 가능하게 합니다.



### Implementing a Nordic-Baltic Federated Health Data Network: a case repor (https://arxiv.org/abs/2409.17865)
Comments:
          24 pages (including appendices), 1 figure

- **What's New**: 이 논문에서는 북유럽-발트해 지역에서 건강 데이터의 2차 사용을 촉진하기 위해 5개국 6개 기관으로 구성된 연합 건강 데이터 네트워크(federated health data network)를 개발하는 과정에서 얻은 초기 경험을 공유합니다.

- **Technical Details**: 이 연구는 혼합 방법(mixed-method approach)을 사용하여 실험 설계(experimental design)와 실행 과학(implementation science)을 결합하여 네트워크 구현에 영향을 미치는 요소를 평가했습니다. 실험 결과, 중앙 집중식 시뮬레이션(centralized simulation)과 비교할 때, 네트워크는 성능 저하(performance degradation) 없이 기능한다는 것을 발견했습니다.

- **Performance Highlights**: 다학제적 접근 방식(interdisciplinary approaches)을 활용하면 이러한 협력 네트워크(collaborative networks)를 구축하는 데 따른 도전 과제를 해결할 수 있는 잠재력이 있지만, 규제 환경이 불확실하고 상당한 운영 비용(operational costs)이 발생하는 것이 문제로 지적되었습니다.



### A Multimodal Single-Branch Embedding Network for Recommendation in Cold-Start and Missing Modality Scenarios (https://arxiv.org/abs/2409.17864)
Comments:
          Accepted at 18th ACM Conference on Recommender Systems (RecSys '24)

- **What's New**: 이 논문은 추천 시스템에서 콜드 스타트(cold-start) 문제를 해결하기 위한 새로운 방법으로, 멀티모달(single-branch) 임베딩 네트워크를 제안합니다. 이를 통해 다양한 모달리티에 기반한 추천 성능을 개선하고자 합니다.

- **Technical Details**: 제안된 방법은 SiBraR(Single-Branch embedding network for Recommendation)로 불리며, 여러 모달리티 데이터를 공유하는 단일 브랜치 네트워크를 통해 처리합니다. SiBraR는 상호작용 데이터와 여러 형태의 사이드 정보를 동일한 네트워크에서 인코딩하여 모달리티 간의 간극(modality gap)을 줄입니다.

- **Performance Highlights**: 대규모 추천 데이터셋에서 실시한 실험 결과, SiBraR는 콜드 스타트 과제에서 기존의 CF 알고리즘과 최신 콘텐츠 기반 추천 시스템(Content-Based Recommender Systems)보다 유의미하게 우수한 성능을 보였습니다.



### Machine Learning-based vs Deep Learning-based Anomaly Detection in Multivariate Time Series for Spacecraft Attitude Sensors (https://arxiv.org/abs/2409.17841)
Comments:
          Accepted for the ESA SPAICE Conference 2024

- **What's New**: 이번 연구는 우주선의 태세 센서에서 발생하는 다변량 시계열의 고착 값(stuck value) 감지를 위한 두 가지 AI 기반 접근 방식을 분석하고, 전통적인 임계값 검사에서의 한계를 극복하기 위한 혁신적인 기술을 제시합니다.

- **Technical Details**: 연구에서는 머신 러닝(ML)의 XGBoost 알고리즘과 심층 학습(DL) 방법인 다채널 합성곱 신경망(CNN)을 사용하여 다변량 시간 시계열 데이터에서 고착 값을 탐지합니다. 두 방법의 해석 가능성과 일반화 가능성을 논의하며, 특히 고착 값이 발생한 신호에서 AI 기반 FDIR 기능의 효과성을 강조합니다.

- **Performance Highlights**: XGBoost는 해석 가능성을 제공합니다. CNN은 빠른 처리 속도와 더 적은 파라미터로 성능을 극대화하며, 일반적인 우주선의 제한된 계산 자원에도 잘 적응합니다. 두 접근 방식은 AI 기반 FDIR의 성능 향상에 기여하며, 특히 고착 값 감지의 정확성을 높이는 데 효과적입니다.



### Language Models as Zero-shot Lossless Gradient Compressors: Towards General Neural Parameter Prior Models (https://arxiv.org/abs/2409.17836)
Comments:
          To appear in NeurIPS 2024

- **What's New**: 본 논문에서는 신경망 기울기(gradient)에 대한 통계적 사전 모델이 오랫동안 간과되어왔음을 지적하며, 대규모 언어 모델(LLM)이 제로샷(zero-shot) 설정에서 기울기 사전으로 작용할 수 있는 가능성을 제시합니다. 이를 통해 효율적인 기울기 압축 방법인 LM-GC를 개발했습니다.

- **Technical Details**: LM-GC는 LLM과 산술 부호화(arithmetic coding)를 통합하여 기울기를 텍스트와 유사한 형식으로 변환합니다. 이 방법은 기울기의 구조와 LLM이 인식 가능한 기호 사이의 정렬을 유지하며, LLM의 토큰 효율성을 최대 38배 향상시키는 특징이 있습니다.

- **Performance Highlights**: LM-GC는 기존의 손실 없는 압축 방법보다 10%에서 최대 17.2% 더 우수한 압축률을 나타내며, 다양한 데이터세트 및 아키텍처에서 실험을 통해 입증되었습니다. 또한, 본 방법은 양자화 및 희소화와 같은 손실 압축 기법과도 호환 가능성을 보였습니다.



### Inference-Time Language Model Alignment via Integrated Value Guidanc (https://arxiv.org/abs/2409.17819)
Comments:
          EMNLP 2024 Findings

- **What's New**: 본 논문에서는 대형 언어 모델(Large Language Models, LLMs) 조정의 복잡성을 피하면서도 효율적으로 인간의 선호에 부합할 수 있게 하는 새로운 방법인 통합 가치 안내(Integrated Value Guidance, IVG)를 소개합니다. IVG는 암묵적(implicit) 및 명시적(explicit) 가치 함수(value function)를 사용하여 언어 모델의 디코딩(decoding)을 유도합니다.

- **Technical Details**: IVG는 두 가지 형태의 가치 함수를 결합합니다. 암묵적 가치 함수는 각 토큰(token)별 샘플링에 적용되고, 명시적 가치 함수는 청크(chunk) 단위의 빔 탐색(beam search)에 사용됩니다. IVG는 다양한 작업에서의 효과를 검증하며, 전통적인 방법들을 능가합니다. 특히, IVG는 gpt2 기반의 가치 함수로부터의 유도 덕분에 감정 생성과 요약 작업에서 성능을 크게 향상했습니다.

- **Performance Highlights**: IVG는 AlpacaEval 2.0과 같은 어려운 지침 따르기 벤치마크에서, 전문가 튜닝된 모델과 상용 모델 모두에서 길이 제어된 승률이 크게 향상되는 것을 보여줍니다. 예를 들어, Mistral-7B-Instruct-v0.2 모델은 19.51%에서 26.51%로, Mixtral-8x7B-Instruct-v0.1 모델은 25.58%에서 33.75%로 증가했습니다.



### Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness (https://arxiv.org/abs/2409.17791)
Comments:
          Accepted at EMNLP 2024 Findings

- **What's New**: 최근에는 대형 언어 모델(LLM)의 보상 모델을 인간 피드백(Human Feedback) 기반 강화 학습(Reinforcement Learning from Human Feedback, RLHF) 방법으로 대체하려는 관심이 증가하고 있습니다. 이 연구에서는 Self-supervised Preference Optimization(SPO) 프레임워크를 제안하여, LLM이 인간의 선호도를 더 잘 이해하고 조정할 수 있도록 합니다.

- **Technical Details**: 본 논문에서는 SPO라는 새로운 자가 감독(preference optimization) 프레임워크를 제안합니다. 이 방법은 LLM의 출력에서 중요한 내용을 선택적으로 제거하여 다양한 선호도 정도의 응답을 생성합니다. 이러한 응답은 자기 감독 모듈로 분류되어 주 손실 함수와 결합되어 LLM을 동시에 최적화합니다.

- **Performance Highlights**: 실험 결과, SPO는 기존의 선호 최적화 방법들과 통합되어 LLM의 성능을 유의미하게 향상시킬 수 있으며, 두 가지 다양한 데이터셋에서 최첨단 결과를 달성했습니다. LLM이 선호도 정도를 구분하는 능력을 높이는 것이 여러 작업에서 성능 향상에 기여한다는 것을 보여주었습니다.



### Harnessing Shared Relations via Multimodal Mixup Contrastive Learning for Multimodal Classification (https://arxiv.org/abs/2409.17777)
Comments:
          RK and RS contributed equally to this work, 20 Pages, 8 Figures, 9 Tables

- **What's New**: 본 논문에서는 M3CoL(Multimodal Mixup Contrastive Learning) 접근 방식을 제안하여, 다양한 모달리티 간의 미묘한 공유 관계를 포착할 수 있음을 보여줍니다. M3CoL은 모달리티 간의 혼합 샘플을 정렬하여 강력한 표현을 학습하는 Mixup 기반의 대조 손실을 활용합니다.

- **Technical Details**: M3CoL은 이미지-텍스트 데이터셋(N24News, ROSMAP, BRCA, Food-101)에서 광범위한 실험을 통해 공유 모달리티 관계를 효과적으로 포착하고, 다양한 도메인에서 일반화 능력을 발휘합니다. 이는 fusion module과 unimodal prediction modules로 구성된 프레임워크에 기반하였으며, Mixup 기반의 대조 손실을 통해 보조 감독을 강화합니다.

- **Performance Highlights**: M3CoL은 N24News, ROSMAP, BRCA 데이터셋에서 최첨단 방법들을 초월하는 성능을 보이며, Food-101에서는 유사한 성능을 달성했습니다. 이를 통해 공유 관계 학습의 중요성이 강조되며, 강력한 다중 모달 학습을 위한 새로운 연구 방향을 열어갑니다.



### Faithfulness and the Notion of Adversarial Sensitivity in NLP Explanations (https://arxiv.org/abs/2409.17774)
Comments:
          Accepted as a Full Paper at EMNLP 2024 Workshop BlackBoxNLP

- **What's New**: 본 논문에서는 설명 가능한 AI의 신뢰성을 평가하기 위한 새로운 접근법인 'Adversarial Sensitivity'를 소개합니다. 이 방식은 모델이 적대적 공격을 받을 때 설명자의 반응에 중점을 둡니다.

- **Technical Details**: Adversarial Sensitivity는 신뢰성을 평가하는 지표로, 적대적 입력 변화에 대한 설명자의 민감도를 포착합니다. 이를 통해 신뢰성이 기존 평가 기술의 중대한 한계를 극복하고, 기존의 설명 메커니즘의 정확성을 정량화합니다.

- **Performance Highlights**: 연구팀은 세 개의 텍스트 분류 데이터셋에 대해 여섯 개의 최첨단 후속 설명기에서 제안된 신뢰성 테스트를 수행하고, 인기 있는 설명기 테스트와의 (비)일관성을 보고하였습니다.



### Federated Learning under Attack: Improving Gradient Inversion for Batch of Images (https://arxiv.org/abs/2409.17767)
Comments:
          5 pages, 7 figures

- **What's New**: 이 논문은 Federated Learning(FL) 시스템의 공격에 대한 새로운 접근 방식, Deep Leakage from Gradients with Feedback Blending (DLG-FB)을 제안합니다. 이 방법은 이미지 배치(batch) 내의 공간적 상관관계를 활용하여 공격 성능을 개선합니다.

- **Technical Details**: DLG-FB는 이미 성공적으로 재구성된 이미지들을 결합하여 공격 초기 입력으로 사용합니다. 기존의 공격 방법들은 매번 무작위 데이터를 초기화했으나, DLG-FB는 재건된 이미지를 혼합하여 더 나은 출발점을 제공합니다. 이로 인해 공격 성공률이 19.18% 향상되었고, 공격당한 이미지당 반복 횟수가 48.82% 감소했습니다.

- **Performance Highlights**: 실험 결과, DLG-FB는 이미지 재구성의 정확성과 효율성을 크게 향상시켰습니다. 특히 다수의 이미지를 목표로 할수록 성능이 더욱 두드러졌습니다.



### Confidence intervals uncovered: Are we ready for real-world medical imaging AI? (https://arxiv.org/abs/2409.17763)
Comments:
          Paper accepted at MICCAI 2024 conference

- **What's New**: 이 논문은 의료 영상(segmentation) 분야에서 AI 성능 변동성을 평가되지 않는 문제를 다루고 있습니다. 2023년 MICCAI에서 발표된 논문 221편을 분석한 결과, 50% 이상의 논문이 성능 변동성을 평가하지 않고, 단 0.5%의 논문만이 신뢰 구간(confidence intervals, CIs)을 보고했습니다. 이는 기존 논문들이 임상 적용을 위한 충분한 근거를 제공하지 않음을 지적합니다.

- **Technical Details**: 연구에서는 segmentation 논문에서 보고되지 않은 표준 편차(standard deviation, SD)를 평균 Dice 유사도 계수(Dice similarity coefficient, DSC)의 2차 다항식 함수를 통해 근사할 수 있음을 보여줍니다. 이를 바탕으로 2023년 MICCAI segmentation 논문의 평균 DSC 주변에 95% CIs를 재구성하였고, 그 중간 CI 폭은 0.03으로 첫 번째와 두 번째 순위 방법 간의 중간 성능 격차보다 세 배 더 큽니다.

- **Performance Highlights**: 60% 이상의 논문에서 두 번째 순위 방법의 평균 성능이 첫 번째 순위 방법의 신뢰 구간 내에 포함되었으며, 이는 현재 보고된 성능이 실제 임상에서의 가능성을 충분히 뒷받침하지 않음을 의미합니다.



### Integrating Hierarchical Semantic into Iterative Generation Model for Entailment Tree Explanation (https://arxiv.org/abs/2409.17757)
- **What's New**: 본 논문은 Controller-Generator 프레임워크(HiSCG)를 기반으로 문장의 계층적 의미(Hierarchical Semantics)를 통합하여 신뢰할 수 있는 설명(Explanation)을 생성하는 새로운 아키텍처를 제안합니다. 이 방법은 동일 계층 및 인접 계층 간의 문장 간 계층적 의미를 처음으로 고려하여 설명의 향상을 이끌어냅니다.

- **Technical Details**: HiSCG 아키텍처는 세 가지 주요 구성 요소로 나뉩니다: 계층적 의미 인코더(Hierarchical Semantic Encoder), 선택 컨트롤러(Selection Controller), 중간 생성 모듈(Intermediate Generation Module). 이 구조는 계층적 연결을 통해 관련 사실을 클러스터링하고, 이러한 사실을 조합하여 결론을 생성하는 과정을 최적화합니다. 각 모듈은 계층적 정보의 활용을 극대화하도록 설계되었습니다.

- **Performance Highlights**: 제안된 방법은 EntailmentBank 데이터셋의 세 가지 설정에서 기존 다른 방법들과 비교하여 동등한 성능을 달성했으며, 두 개의 도메인 외 데이터셋에서 일반화 능력도 입증되었습니다.



### SECURE: Semantics-aware Embodied Conversation under Unawareness for Lifelong Robot Learning (https://arxiv.org/abs/2409.17755)
Comments:
          10 pages,4 figures, 2 tables

- **What's New**: 본 연구는 로봇이 작업 수행에 필요한 개념을 인식하지 못한 상황에서 진행되는 상호작용적 작업 학습(interactive task learning) 문제를 다루며, 이를 해결하기 위한 새로운 프레임워크 SECURE를 제안합니다.

- **Technical Details**: SECURE는 상징적 추론(symbolic reasoning)과 신경 기초(neural grounding)를 결합하여 로봇이 대화 중에 새로운 개념을 인식하고 학습할 수 있도록 설계되었습니다. 이 프레임워크는 서울대학교의 대학원 연구팀이 개발하였으며, 기존의 기계 학습 모델이 가지는 한계를 극복하고 지속적인 개념 학습을 가능하게 합니다.

- **Performance Highlights**: SECURE를 이용한 로봇은 이전에 알지 못했던 개념을 효과적으로 학습하고, 그로 인해 무의식적 인식 상태에서도 작업 재배치 문제를 성공적으로 해결할 수 있음을 보여주었습니다. 이러한 결과는 로봇이 대화의 의미 논리(semantics)적 결과를 활용하여 보다 효과적으로 학습할 수 있음을 입증합니다.



### Byzantine-Robust Aggregation for Securing Decentralized Federated Learning (https://arxiv.org/abs/2409.17754)
Comments:
          18 pages, 7 figures, 1 table

- **What's New**: 본 논문은 분산된 환경에서의 Decentralized Federated Learning(DFL)을 위한 새로운 Byzantine-robust aggregation 알고리즘 WFAgg를 제안합니다. 이는 중앙 서버 없이도 보안을 강화하는데 기여합니다.

- **Technical Details**: WFAgg 알고리즘은 다수의 필터를 사용하여 Byzantine 공격을 분석하고 완화하는 기능을 갖추고 있으며, 동적 분산 토폴로지에서의 강력한 견고성을 제공합니다. 이를 통해 중앙 집중식 Byzantine-robust aggregation 알고리즘과 비교하여 다양한 Byzantine 공격 시나리오에서도 높은 모델 정확성과 수렴성을 유지할 수 있습니다.

- **Performance Highlights**: 실험 결과, 제안된 알고리즘 WFAgg는 여러 중앙 집중식 Byzantine-robust aggregation 알고리즘(예: Multi-Krum, Clustering)과 비교하여 이미지 분류 문제에서 더 높은 정확도를 기록하며, 중앙 집중식 시스템보다 우수한 모델 일관성 결과를 보여줍니다.



### AlterMOMA: Fusion Redundancy Pruning for Camera-LiDAR Fusion Models with Alternative Modality Masking (https://arxiv.org/abs/2409.17728)
Comments:
          17 pages, 3 figures, Accepted by NeurIPS 2024

- **What's New**: 본 논문에서는 카메라-라이다(Camera-LiDAR) 융합 모델의 효율성을 높이기 위해 새로운 가지치기 프레임워크인 AlterMOMA를 제안합니다.

- **Technical Details**: AlterMOMA는 각 모달리티에 대해 대체 마스킹을 사용하고 중요도 평가 함수인 AlterEva를 통해 중복된 파라미터를 식별합니다. 이 과정에서는 한 모달리티 파라미터가 활성화 및 비활성화될 때의 손실 변화를 관찰하여 중복 파라미터를 식별합니다.

- **Performance Highlights**: AlterMOMA는 nuScenes 및 KITTI 데이터셋의 다양한 3D 자율 주행 작업에서 기존의 가지치기 방법보다 뛰어난 성능을 보이며, 최첨단 성능을 달성하였습니다.



### Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experienc (https://arxiv.org/abs/2409.17702)
Comments:
          Code, data and demo videos at this https URL

- **What's New**: 이 논문에서는 로봇 경험을 효과적으로 언어로 표현하기 위해 대규모 사전 훈련된 모델을 활용하는 새로운 접근 방식을 소개합니다. 특히, 긴 경험의 흐름을 요약하고 질의 응답을 수행하는 데 중점을 두고 있으며, 기존의 규칙 기반 시스템이나 세분화된 심층 모델에 대한 의존도를 줄였습니다.

- **Technical Details**: 이 연구에서는 에피소드 기억(Episodic Memory, EM)에서 파생된 계층적 트리 구조를 구성하여 로봇의 경험 흐름을 저장합니다. 로우 레벨 수준에는 원시 지각(raw perception) 및 감각 데이터가 포함되고, 더 높은 수준에서는 사건이 자연어 개념으로 추상화됩니다. 사용자 질의에 대한 답변을 위해 대형 언어 모델(Large Language Model, LLM)을 사용하여 EM에서 필요한 정보를 동적으로 탐색하게 됩니다.

- **Performance Highlights**: H-Emv 시스템은 시뮬레이션된 가정용 로봇 데이터와 실제 세계의 로봇 녹음 데이터를 활용하여 테스트되었으며, 매우 긴 역사 데이터에 대해 효율적으로 확장할 수 있음을 보여주었습니다. 이 시스템은 여러 시간의 시뮬레이션 데이터와 6시간 이상의 실제 인간 영상에서 뛰어난 성능을 발휘하였습니다.



### MoJE: Mixture of Jailbreak Experts, Naive Tabular Classifiers as Guard for Prompt Attacks (https://arxiv.org/abs/2409.17699)
- **What's New**: 이 논문은 Large Language Models (LLMs)의 보안을 강화하기 위한 새로운 방어 메커니즘인 MoJE (Mixture of Jailbreak Expert)를 제안합니다. 기존의 guardrails 방법들이 갖는 한계를 극복하고, 탈옥(jailbreak) 공격 탐지의 정확도와 효율성을 동시에 향상시키는 구조입니다.

- **Technical Details**: MoJE는 간단한 언어 통계 기법을 활용하여, 다양한 토큰화(tokenization) 전략이나 n-그램(n-gram) 특징 추출을 통해 탈옥 공격을 탐지하고 필터링합니다. 이 구조는 기존의 state-of-the-art guardrails에 비해 공격 탐지 정확도, 대기 시간(latency), 처리량(throughput) 면에서 우수한 성능을 보입니다. 또한, 모듈러 특성 덕분에 새로운 공격에 대한 방어 모델이나 OOD(out-of-distribution) 데이터셋을 포함하도록 쉽게 확장 가능합니다.

- **Performance Highlights**: MoJE는 여러 데이터셋에서 유해 내용 탐지에서 기존의 ProtectAI 및 Llama-Guard와 같은 최첨단 솔루션을 초월하며, 탈옥 공격에 대한 저항력이 뛰어납니다. 특히, 90%의 탈옥 공격을 탐지하면서도 정상 프롬프트(benign prompts)에 대한 정확도를 유지하여 LLMs의 보안을 크게 강화합니다.



### MIO: A Foundation Model on Multimodal Tokens (https://arxiv.org/abs/2409.17692)
Comments:
          Technical Report. Codes and models will be available soon

- **What's New**: MIO라는 새로운 기초 모델이 등장했습니다. 이는 음성, 텍스트, 이미지 및 비디오를 이해하고 생성할 수 있는 멀티모달 토큰 기반의 모델로서, end-to-end 및 autoregressive 방식으로 작동합니다. MIO는 기존의 모델들이 갖고 있지 않았던 all-to-all 방식으로의 이해와 생성을 지원하며, 기존의 비공식 모델들(GPT-4o 등)을 대체할 수 있습니다.

- **Technical Details**: MIO는 causal multimodal modeling에 기반해 4단계의 훈련 과정을 거칩니다: (1) alignment pre-training, (2) interleaved pre-training, (3) speech-enhanced pre-training, (4) 다양한 텍스트, 비주얼, 음성 작업에 대한 포괄적인 감독 하에 fine-tuning을 수행합니다. MIO는 discrete multimodal tokens을 사용하여 학습되며, 이는 대조 손실(contrastive loss)과 재구성 손실(reconstruction loss) 기법을 통해 semantical representation과 low-level features를 포착합니다.

- **Performance Highlights**: MIO는 이전의 dual-modal 및 any-to-any 모델들, 심지어 modality-specific baselines와 비교해서 경쟁력 있는 성능을 보이며, interleaved video-text generation, 시각적 사고의 연쇄(chain-of-visual-thought reasoning), 시각적 가이드라인 생성, 이미지 편집 기능 등 고급 기능을 구현합니다.



### Efficient Bias Mitigation Without Privileged Information (https://arxiv.org/abs/2409.17691)
Comments:
          Accepted at the 18th European Conference on Computer Vision (ECCV 2024) as an Oral presentation

- **What's New**: 본 논문에서는 Bias Mitigation을 위한 Targeted Augmentations (TAB)라는 새로운 프레임워크를 제안합니다. 이 방법은 그룹 레이블 없이도 훈련 세트를 재조정하여 바이어스를 감소시키는 효과적인 방법으로, 기존의 방법들보다 뛰어난 성능을 보입니다.

- **Technical Details**: TAB는 하이퍼파라미터 최적화가 필요 없는 간단한 비지도 학습 기반의 바이어스 완화 파이프라인입니다. 이는 보조 모델의 전체 훈련 이력을 활용하여 spurious samples를 식별하고, 그룹 균형 훈련 세트를 생성합니다.

- **Performance Highlights**: TAB는 기존의 비지도 방법들보다 worst-group 성능을 향상시키며 전체 정확도를 유지합니다. 이 방법은 다양한 실제 데이터 세트에 쉽게 적용할 수 있으며, 그룹 정보나 모델 선택 없이도 성능 개선을 이룰 수 있습니다.



### Graph Edit Distance with General Costs Using Neural Set Divergenc (https://arxiv.org/abs/2409.17687)
Comments:
          Published at NeurIPS 2024

- **What's New**: GRAPHEDX는 서로 다른 비용의 edit operations를 명시적으로 고려하여 Graph Edit Distance (GED)를 추정하는 새로운 신경망 모델입니다. 이를 통해 여러 종류의 edit 작업에 대해 보다 정확한 추정을 가능합니다.

- **Technical Details**: GRAPHEDX는 네 가지 edit 작업(edge deletion, edge addition, node deletion, node addition)에 대한 비용을 포함하는 quadratic assignment problem (QAP)으로 GED를 모델링합니다. 각 그래프는 노드와 엣지의 embedding으로 표현되며, Gumbel-Sinkhorn permutation generator를 통해 노드와 엣지 간의 정렬을 학습합니다.

- **Performance Highlights**: 여러 데이터 세트에서 진행된 실험 결과, GRAPHEDX는 예측 오류 측면에서 최신의 방법들과 휴리스틱을 일관되게 초월하는 성능을 보였습니다.



### Preserving logical and functional dependencies in synthetic tabular data (https://arxiv.org/abs/2409.17684)
Comments:
          Submitted to Pattern Recognition Journal

- **What's New**: 이 논문에서는 기존의 기능적 의존성(functioanal dependencies) 외에도 속성 간의 논리적 의존성(logical dependencies)을 도입하였습니다. 이와 함께, 테이블 데이터에서 논리적 의존성을 수량적으로 평가할 수 있는 새로운 방법을 제시합니다.

- **Technical Details**: 새롭게 제안된 방법을 사용하여 여러 최신 합성 데이터 생성 알고리즘을 비교하고, 공개 데이터 세트에서 논리적 및 기능적 의존성을 보존하는 능력을 시험합니다. 이러한 연구는 기능적 의존성을 완전히 보존하는 합성 테이블 데이터 생성 알고리즘의 한계를 밝혀냅니다.

- **Performance Highlights**: 본 연구에서는 특정 합성 데이터 생성 모델들이 속성 간의 논리적 의존성을 잘 보존할 수 있음을 보여주며, 향후 작업에 특화된 합성 테이블 데이터 생성 모델 개발의 필요성과 기회를 제시합니다.



### Zero- and Few-shot Named Entity Recognition and Text Expansion in Medication Prescriptions using ChatGP (https://arxiv.org/abs/2409.17683)
- **What's New**: 이번 연구는 ChatGPT 3.5를 사용하여 약물 처방의 데이터 통합 및 해석을 자동화하여 사용자와 기계 모두에게 이해하기 쉬운 형식으로 제공하는 방법을 제시합니다. 이는 자유 텍스트 형태의 약물 진술에서 의미 있는 정보를 구조화하고 확장할 수 있는 가능성을 보여줍니다.

- **Technical Details**: 연구는 Named-Entity Recognition (NER) 및 Text Expansion (EX) 기술을 활용하였습니다. NER은 약물 이름, 농도, 단위, 투여 경로 및 복용 지침을 식별하며, EX는 이를 명확하고 구체적인 형태로 변환합니다. 최적화된 프롬프트를 사용해 NER의 평균 F1 점수는 0.94에 도달하였고, EX는 0.87에 도달하였습니다.

- **Performance Highlights**: 이 연구는 ChatGPT를 사용한 NER 및 EX 작업에서 우수한 성능을 입증하였습니다. 특히, few-shot 학습 접근법을 통해 잘못된 정보를 생성하는 현상(hallucination)을 방지할 수 있었으며, 이는 약물 안전 데이터 처리 시 중요합니다.



### Prototype based Masked Audio Model for Self-Supervised Learning of Sound Event Detection (https://arxiv.org/abs/2409.17656)
Comments:
          Submitted to ICASSP2025; The code for this paper will be available at this https URL after the paper is accepted

- **What's New**: 본 논문은 라벨이 없는 데이터를 더 효과적으로 활용하기 위해 프로토타입 기반 마스킹 오디오 모델(Prototype based Masked Audio Model, PMAM) 알고리즘을 제안합니다. 이는 음향 사건 탐지(Sound Event Detection, SED)에서 자가 지도 표현 학습을 위한 새로운 접근 방법으로, Gaussian mixture model(GMM)을 사용한 의미론적으로 풍부한 프레임 수준의 의사 레이블을 생성합니다.

- **Technical Details**: PMAM은 두 개의 주요 구성 요소로 이루어져 있으며, 여기에는 인코더 네트워크와 컨텍스트 네트워크가 포함됩니다. 인코더 네트워크는 스펙트로그램에서 프레임 수준의 잠재 표현(latent embeddings)을 추출하고, 컨텍스트 네트워크는 마스킹된 오디오 모델 작업을 통해 사운드 사건의 시간적 의존성을 모델링합니다. 트랜스포머 및 CNN 구조를 채택하고, 프로토타입 기반의 이진 교차 엔트로피 손실을 사용하여 다양한 프로토타입에 대한 독립적인 예측을 가능하게 합니다.

- **Performance Highlights**: DESED 작업을 이용한 유사 실험에서 PMAM은 62.5%의 PSDS1 점수를 기록하며 기존 최첨단 모델을 뛰어넘는 성능을 보여주었습니다. 이는 제안된 기술의 우수성을 입증합니다.



### AssistantX: An LLM-Powered Proactive Assistant in Collaborative Human-Populated Environmen (https://arxiv.org/abs/2409.17655)
Comments:
          6 pages, 8 figures, 4 tables

- **What's New**: 최근 연구들은 인간이 밀집한 환경에서의 지능형 비서에 대한 수요 증가에 대응하여 자율 로봇 시스템에 중점을 두고 있습니다. 특히, Large Language Models (LLMs)의 발전이 이러한 시스템을 개선할 새로운 길을 열었습니다.

- **Technical Details**: 본 연구에서는 AssistantX라는 LLM 기반의 능동 비서를 소개하며, 물리적 사무 환경에서 자율적으로 작동하도록 설계되었습니다. 새로운 다중 에이전트 아키텍처인 PPDR4X를 활용하여 복잡한 상황에서도 효과적으로 작업을 수행할 수 있습니다.

- **Performance Highlights**: AssistantX는 명확한 지시에 반응하고, 메모리에서 추가 정보를 능동적으로 검색하며, 타 팀원과 협력하여 작업의 성공적인 완료를 위해 노력하는 등 강력한 성능을 보여줍니다.



### T3: A Novel Zero-shot Transfer Learning Framework Iteratively Training on an Assistant Task for a Target Task (https://arxiv.org/abs/2409.17640)
- **What's New**: 이 논문에서는 T3이라 약칭되는 새로운 제로-샷 (zero-shot) 전이 학습 프레임워크를 제안하여, 긴 텍스트 요약(Long Text Summarization) 작업을 위한 효과적인 솔루션을 제공합니다. 이 프레임워크는 보조 작업(assistant task)과 목표 작업(target task) 간의 관계를 활용하여 LLM을 학습시킵니다.

- **Technical Details**: T3는 보조 작업으로써 질문 답변(Question Answering, QA)을 활용하며, 이를 통해 긴 텍스트 요약 작업에 대한 LLM을 훈련합니다. 이 과정에서 QA는 풍부한 공개 데이터 세트를 제공하고, 질문-답변 쌍을 통해 더 많은 개체와 관계를 포함할 수 있어 요약의 질적 성장을 도모합니다. 또한, 질문 생성(Question Generation, QG)을 통해 두 작업 간의 문맥적 특성을 이해하게 됩니다.

- **Performance Highlights**: T3는 BBC summary, NarraSum, FairytaleQA, NLQuAD 데이터셋에서 3개의 기준 LLM에 비해 ROUGE에서 최대 14%, BLEU에서 35%, Factscore에서 16%의 향상치를 보여주며 그 효과성을 입증했습니다.



### P4Q: Learning to Prompt for Quantization in Visual-language Models (https://arxiv.org/abs/2409.17634)
- **What's New**: 이 논문에서는 Vision-Language Models (VLMs) 의 양자화(quantization)와 미세 조정(fine-tuning)을 통합하는 새로운 방법인 'Prompt for Quantization'(P4Q)을 제안합니다. 이 방법은 PTQ(Post-Training Quantization) 모델의 인식 성능을 향상시키기 위해 경량 아키텍처를 설계합니다.

- **Technical Details**: P4Q는 이미지 특징과 텍스트 특징 간의 격차를 줄이기 위해 학습 가능한 프롬프트(prompt)를 사용하여 텍스트 표현을 재구성하고, 저비트(low-bit) 어댑터(QAdapter)를 사용하여 이미지와 텍스트 특징 분포를 재조정하는 방법입니다. 또한 코사인 유사도 예측을 기반으로 하는 증류 손실(distillation loss)을 도입하여 확장성 있는 증류를 수행합니다.

- **Performance Highlights**: P4Q 방법은 이전 연구보다 뛰어난 성능을 보이며, ImageNet 데이터셋에서 8비트 P4Q가 CLIP-ViT/B-32을 4배 압축하면서도 Top-1 정확도 66.94%를 기록하였습니다. 이는 전체 정밀(full-precision) 모델보다 2.24% 향상된 결과입니다.



### Hand-object reconstruction via interaction-aware graph attention mechanism (https://arxiv.org/abs/2409.17629)
Comments:
          7 pages, Accepted by ICIP 2024

- **What's New**: 이 연구에서는 손과 객체의 상호작용을 고려한 새로운 그래프 주의(attention) 메커니즘을 제안합니다. 기존 방법론이 그래프의 엣지 연관성을 충분히 활용하지 못했던 점을 극복하기 위해, 공통 관계 엣지(common relation edges)와 주의 유도 엣지(attention-guided edges)를 도입하여 물리적 타당성을 향상시키기 위한 그래프 기반 개선 방법을 소개합니다.

- **Technical Details**: 제안된 접근 방식은 상호작용 인식을 위한 그래프 주의 메커니즘을 통해 손과 객체의 메쉬(mesh)를 이미지에서 추정하여, 두 가지 타이프의 엣지(즉, intra-class와 inter-class 노드 간의 연결)를 사용하여 밀접하게 상관된 노드 간의 관계를 설정합니다. 이 연구는 ObMan와 DexYCB 데이터셋을 활용하여 제안된 방법의 효과성을 평가했습니다.

- **Performance Highlights**: 실험 결과, 손과 객체 간의 물리적 타당성이 개선되었음을 확인했습니다. 정량적 및 정성적으로 관찰된 결과는 제안된 상호작용 인식 그래프 주의 메커니즘이 손과 객체 포즈 추정을 통해 물리적 타당성을 획기적으로 향상시킴을 보여줍니다.



### Neural P$^3$M: A Long-Range Interaction Modeling Enhancer for Geometric GNNs (https://arxiv.org/abs/2409.17622)
Comments:
          Published as a conference paper at NeurIPS 2024

- **What's New**: Neural P$^3$M은 기하학적 그래프 신경망(GNN)의 한계를 극복하기 위해 망 점(mesh points)과 원자(Atoms)를 함께 통합한 새로운 프레임워크입니다. 이를 통해 대규모 분자 시스템에서의 장거리 상호작용을 효과적으로 캡처할 수 있습니다.

- **Technical Details**: Neural P$^3$M은 전통적인 수학적 연산을 훈련 가능한 방식으로 재구성하여 원자와 메쉬 스케일에서 단거리와 장거리 상호작용을 포착합니다. 기존의 LSRM 및 Ewald MP 방법과 비교하여 유연성과 계산 효율성을 높였습니다. 인접한 원자 및 메쉬 간의 정보 교환을 포함하여 장거리 항(terms)의 수식을 가능하게 합니다.

- **Performance Highlights**: Neural P$^3$M은 MD22 데이터셋에서 최첨단 성능을 달성하며, OE62 데이터셋에서는 평균 22% 개선된 에너지 평균 절대 오차(MAE)를 기록하였습니다. 여러 기하학적 GNN과 통합하여 Ag 및 MD22 벤치마크에서 상당한 개선을 이루었습니다.



### Open Digital Rights Enforcement Framework (ODRE): from descriptive to enforceable policies (https://arxiv.org/abs/2409.17602)
Comments:
          20 pages, 3 Figures, Submitted to Computers & Security journal

- **What's New**: 이 논문에서는 Open Digital Rights Language (ODRL) 정책에 집행 기능을 추가하기 위한 Open Digital Rights Enforcement (ODRE) 프레임워크를 소개합니다. ODRE는 정책을 기술할 수 있는 새로운 접근 방식을 제공하며, 동적 데이터 처리 및 함수 평가가 가능하도록 다양한 언어와 결합합니다.

- **Technical Details**: ODRE 프레임워크는 ODRL에서 기술된 정책을 집행할 수 있도록 적응된 알고리즘을 포함합니다. 이 알고리즘은 정책에 선언된 데이터 사용 제약이 충족되었는지를 검증하고, 필요시 정책이 명시한 작업을 호출합니다. 알고리즘은 동적 데이터 처리 메커니즘을 구현하여 개인 정보 유출을 방지합니다.

- **Performance Highlights**: ODRE의 두 가지 오픈 소스 구현체 (Python과 Java)를 통해 여러 실험을 진행하였으며, 구현의 성능과 확장성 특징을 보여주는 긍정적인 결과가 도출되었습니다. 각 구현은 24개의 단위 시험을 통과하며, 정책을 집행하는 데 소요된 시간을 보고합니다.



### TA-Cleaner: A Fine-grained Text Alignment Backdoor Defense Strategy for Multimodal Contrastive Learning (https://arxiv.org/abs/2409.17601)
- **What's New**: 이 논문에서는 CLIP와 같은 대규모 사전학습 모델이 데이터 중독된 백도어 공격에 취약하다는 점을 지적하며, 이를 해결하기 위한 새로운 방어 기법 TA-Cleaner를 제안합니다.

- **Technical Details**: TA-Cleaner는 CleanCLIP의 한계를 보완하기 위해 세밀한 텍스트 정렬 기법을 적용합니다. 매 에포크마다 긍정 및 부정 서브텍스트를 생성하고 이를 이미지와 정렬하여 텍스트 자기 감독(self-supervision)을 강화함으로써 백도어 트리거의 특징 연결을 차단합니다.

- **Performance Highlights**: 특히 BadCLIP과 같은 새로운 공격 기법에 대해 TA-Cleaner는 CleanCLIP보다 Top-1 ASR을 52.02%, Top-10 ASR을 63.88% 감소시키며 뛰어난 방어 성능을 보임을 보여주었습니다.



### Subjective and Objective Quality-of-Experience Evaluation Study for Live Video Streaming (https://arxiv.org/abs/2409.17596)
Comments:
          14 pages, 5 figures

- **What's New**: 최근 라이브 비디오 스트리밍에 대한 QoE(Quality of Experience) 평가를 위해 새로운 데이터셋인 TaoLive QoE가 발표되었습니다. 이 데이터셋은 실시간 방송에서 수집된 42개의 소스 비디오와 다양한 스트리밍 왜곡으로 인해 손상된 1,155개의 왜곡 비디오로 구성되어 있습니다.

- **Technical Details**: TaoLive QoE 데이터셋을 기반으로 주관적 및 객관적 QoE 평가를 실시하였으며, 실시간 콘텐츠에 대한 기존 QoE 모델의 한계를 강조했습니다. 특히, 새로운 end-to-end QoE 평가 모델인 TAO-QoE는 다중 스케일의 의미(feature)와 광학 흐름(optical flow) 기반 모션 특징을 통합하여 QoE 점수를 예측하는 혁신적인 접근 방식을 제안합니다.

- **Performance Highlights**: TAO-QoE는 기존 QoE 모델들보다 라이브 비디오 콘텐츠에 대해 더 정확한 평가 성능을 보여주며, 통계적 QoS 특성에 대한 의존성을 제거하여 실시간 방송 시나리오에서 우수한 성과를 달성하는 것을 목표로 하고 있습니다.



### Deep Manifold Part 1: Anatomy of Neural Network Manifold (https://arxiv.org/abs/2409.17592)
- **What's New**: 이 논문은 Neural Network (신경망)의 수학적 프레임워크인 Deep Manifold를 개발하여, 신경망의 수치 계산 특성과 학습 가능성을 탐구합니다. 주요 발견 사항으로는 신경망이 거의 무한한 자유도와 깊이에 따른 지수적인 학습 능력을 갖고 있다는 것을 들 수 있습니다.

- **Technical Details**: Neural network learning space (신경망 학습 공간)와 deep manifold space (딥 매니폴드 공간)라는 두 가지 개념을 새롭게 정의하였습니다. 또한, neural network intrinsic pathway (신경망 내재 경로) 및 fixed point (고정 점)라는 새로운 개념을 소개하였습니다. 고차 비선형(High-order non-linearity)을 다루는 Numerical Manifold Method를 통해 신경망의 해부학적 구조를 연구합니다.

- **Performance Highlights**: Deep Manifold는 LLM (Large Language Model) 훈련 과정에서 부정적 시간(Negative time)의 중요성을 강조하며, 데이터의 위치 임베딩을 통한 암묵적 시간 인코딩이 LLM의 훈련 성능에 미치는 영향을 분석합니다. 연구 결과, 신경망 모델의 학습 능력이 비선형성을 어떻게 극복하는지에 대한 통찰력을 얻을 수 있었습니다.



### Improving Fast Adversarial Training via Self-Knowledge Guidanc (https://arxiv.org/abs/2409.17589)
Comments:
          13 pages

- **What's New**: 이 논문에서는 Fast Adversarial Training (FAT)에서 발생하는 불균형 문제를 체계적으로 조사하고, 이를 해결하는 Self-Knowledge Guided FAT (SKG-FAT) 방법론을 제안합니다. SKG-FAT는 각 클래스의 학습 상태에 따라 차별화된 정규화 가중치를 할당하고, 학습 정확도에 따라 레이블을 동적으로 조정함으로써/adversarial robustness를 증가시키는 데 초점을 맞춥니다.

- **Technical Details**: FAT의 기존 방법들은 모든 훈련 데이터를 균일하게 최적화하는 전략을 사용하여/imbalanced optimization을 초래합니다. 본 연구에서는 클래스 간의 성능 격차를 드러내고, 이를 해소하기 위해/self-knowledge guided regularization과/self-knowledge guided label relaxation을 도입합니다. SKG-FAT는 자연적으로 생성되는 지식을 활용하여 adversarial robustness를 증대시킬 수 있습니다.

- **Performance Highlights**: SKG-FAT는 네 가지 표준 데이터셋에 대한 광범위한 실험을 통해/adversarial robustness를 향상시키면서도 경쟁력 있는 clean accuracy를 유지하며, 최신 방법들과 비교해 우수한 성능을 보였습니다.



### Multimodal Banking Dataset: Understanding Client Needs through Event Sequences (https://arxiv.org/abs/2409.17587)
- **What's New**: 이 논문은 산업 규모의 공개 멀티모달 은행 데이터셋인 Multimodal Banking Dataset (MBD)를 소개합니다. 이 데이터셋은 150만 개 이상의 법인 고객 데이터를 포함하고 있으며, 다양한 소스에서 수집된 대량의 시퀀스 정보를 제공합니다.

- **Technical Details**: MBD는 9억 5천만 건의 은행 거래, 10억 건의 지리적 이벤트, 500만 개의 기술 지원 대화 임베딩, 4개의 은행 제품에 대한 월별 집계 구매를 포함합니다. 데이터는 클라이언트 개인 정보 보호를 위해 적절히 익명화되어 있습니다. 이 데이터셋은 두 가지 비즈니스 태스크(종합 캠페인 및 클라이언트 매칭)에 대한 기준을 제공합니다.

- **Performance Highlights**: MBD를 사용하여 다중 모달 베이스라인이 단일 모달 기법보다 각 태스크에 대해 우수함을 입증하는 수치 결과를 제공합니다. 이 데이터셋은 향후 이벤트 시퀀스에 대한 대규모 및 다중 모달 알고리즘 개발을 촉진할 수 있는 새로운 관점을 열어줄 잠재력을 가지고 있습니다.



### Let the Quantum Creep In: Designing Quantum Neural Network Models by Gradually Swapping Out Classical Components (https://arxiv.org/abs/2409.17583)
Comments:
          50 pages (including Appendix), many figures, accepted as a poster on QTML2024. Code available at this https URL

- **What's New**: 이 논문에서는 양자 신경망(Quantum Neural Network, QNN)의 구조적 한계를 극복하기 위해 고전적 신경망과 양자 신경망 사이의 점진적인 전환 전략, HybridNet을 제안합니다. 이는 정보 흐름을 유지하면서 고전적 신경망 레이어를 점진적으로 양자 레이어로 대체하는 프레임워크를 제공합니다.

- **Technical Details**: 제안된 HybridNet은 고전적 모델에서 양자 모델로의 전환을 통해 양자 구성이 신경망의 성능에 미치는 영향을 보다 면밀히 분석합니다. 연구에서는 FlippedQuanv3x3라는 새로운 양자 커널과 데이터 재업로드 회로(Data Reuploading Circuit)를 도입하여 고전적 선형 레이어와 동일한 입력 및 출력을 공유하는 양자 레이어를 구현합니다.

- **Performance Highlights**: MNIST, FashionMNIST, CIFAR-10 데이터셋에 대한 수치 실험을 통해 양자 구성요소의 체계적인 도입이 성능 변화에 미치는 영향을 분석했습니다. 연구 결과, 기존의 QNN 모델보다 더 효과적인 성능을 발휘할 수 있음을 발견하였습니다.



### Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study (https://arxiv.org/abs/2409.17580)
- **What's New**: Structured-GraphRAG는 복잡한 데이터셋에서 정보 검색의 정확성과 관련성을 향상시키기 위해 설계된 새로운 프레임워크입니다. 이 방법은 전통적인 데이터 검색 방법의 한계를 극복하고, 구조화된 데이터셋에서 자연어 질의를 통한 정보 검색을 지원합니다.

- **Technical Details**: Structured-GraphRAG는 여러 개의 지식 그래프(knowledge graph)를 활용하여 데이터 간의 복잡한 관계를 포착합니다. 이를 통해 더욱 세밀하고 포괄적인 정보 검색이 가능하며, 결과의 신뢰성을 높이고 언어 모델의 출력을 구조화된 형태로 바탕으로 답변을 제공합니다.

- **Performance Highlights**: Structured-GraphRAG는 전통적인 검색 보완 생성 기법과 비교하여 쿼리 처리 효율성을 크게 향상시켰으며, 응답 시간을 단축시켰습니다. 실험의 초점이 축구 데이터에 맞춰져 있지만, 이 프레임워크는 다양한 구조화된 데이터셋에 널리 적용될 수 있어 데이터 분석 및 언어 모델 응용 프로그램의 향상된 도구로 기능합니다.



### Dr. GPT in Campus Counseling: Understanding Higher Education Students' Opinions on LLM-assisted Mental Health Services (https://arxiv.org/abs/2409.17572)
Comments:
          5 pages

- **What's New**: 이번 연구는 대학생들이 AI 응용 프로그램, 특히 Large Language Models (LLMs)를 통해 정신 건강을 향상시킬 수 있는 방안에 대한 인식을 조사했습니다. 파일럿 인터뷰를 통해 다섯 가지 시나리오에서 LLMs의 사용에 대한 학생들의 의견을 탐색했습니다.

- **Technical Details**: 대학생들의 정신 건강에 대한 LLMs의 잠재력은 초기 스크리닝(Initial Screening) 및 후속 치료(Follow-up Care) 시나리오에서 특히 높게 평가되었습니다. 연구는 LLM의 맞춤형 상호작용과 정기적인 체크인 기능이 학생들에게 매우 유용하다는 것을 보여줍니다. 여러 연구는 LLMs가 치료적 대화와 데이터 검색을 통해 정신 건강 개입을 강화하는 데 기여할 수 있음을 시사합니다.

- **Performance Highlights**: 참여자들은 LLM이 초기 스크리닝에서 정신 건강 문제를 보다 효과적으로 표현할 수 있게 해주며, 후속 치료에서는 치료 계획의 이행을 지원하는 데 긍정적인 역할을 할 수 있다고 인식하였습니다. 그러나 LLM이 감정적 지원을 제공하는 데 있어 한계가 있음을 우려하는 목소리도 있었습니다.



### Pixel-Space Post-Training of Latent Diffusion Models (https://arxiv.org/abs/2409.17565)
- **What's New**: 이번 논문에서는 Latent Diffusion Models (LDMs)의 한계를 극복하기 위한 새로운 접근 방법을 제안합니다. LDMs는 이미지 생성 분야에서 큰 발전을 이루었지만, 고주파 세부 사항과 복잡한 구성 생성에서 여전히 어려움이 있음을 지적합니다.

- **Technical Details**: LDMs가 고주파 세부 사항을 잘 생성하지 못하는 이유는 기존 학습이 보통 $8 	imes 8$의 낮은 공간 해상도에서 이뤄지기 때문이라고 가설합니다. 이를 해결하기 위해 포스트 트레이닝 과정에서 pixel-space supervision을 추가하는 방법을 제안하였습니다.

- **Performance Highlights**: 실험 결과, pixel-space objective를 추가함으로써 최첨단 DiT transformer와 U-Net diffusion 모델의 supervised quality fine-tuning 및 preference-based post-training에서 시각적 품질 및 결함 지표가 크게 향상되었으며, 동일한 텍스트 정렬 품질을 유지했습니다.



### Triple Point Masking (https://arxiv.org/abs/2409.17547)
- **What's New**: 본 논문에서는 제한된 데이터 환경에서 기존 3D 마스크 학습 방법의 성능 한계를 극복하기 위한 새로운 Triple Point Masking (TPM) 기법을 소개합니다. 이 기법은 다중 마스크 학습을 위한 확장 가능한 프레임워크로, 3D 포인트 클라우드 데이터를 위한 masked autoencoder의 사전 학습을 지원합니다.

- **Technical Details**: TPM은 기본 모델에 두 가지 추가 마스크 선택지(중간 마스크 및 낮은 마스크)를 통합하여 객체 복구 과정을 다양한 방법으로 표현할 수 있도록 설계되었습니다. 이 과정에서 고차원 마스킹 기법의 한계를 극복하고, 다양한 3D 객체에 대한 여러 표현을 고려하여 더 유연하고 정확한 완성 능력을 제공합니다. 또한, SVM 기반의 최적 가중치 선택 모듈을 통해 다운스트림 네트워크에 최적의 가중치를 적용하여 선형 정확성을 극대화합니다.

- **Performance Highlights**: TPM을 탑재한 네 가지 기본 모델은 다양한 다운스트림 작업에서 전반적인 성능 향상을 달성했습니다. 예를 들어, Point-MAE는 TPM 적용 후 사전 학습 및 미세 조정 단계에서 각각 1.1% 및 1.4%의 추가 성과를 보였습니다.



### Modulated Intervention Preference Optimization (MIPO): Keep the Easy, Refine the Difficu (https://arxiv.org/abs/2409.17545)
Comments:
          8pages, submitted to AAAI 2025

- **What's New**: 이번 연구에서는 Modulated Intervention Preference Optimization (MIPO)라는 새로운 방법론을 제안합니다. MIPO는 주어진 데이터와 참조 모델의 정렬 상태에 따라 개입(intervention) 정도를 조절하여 모델 일치를 최적화합니다.

- **Technical Details**: MIPO는 참조 모델이 잘 정렬된 경우, 정책 모델이 참조 모델과 크게 이탈하지 않도록 개입을 증가시키고, 반대로 정렬이 좋지 않은 경우 개입을 줄여 보다 광범위한 학습을 가능하게 합니다. 이 연구에서는 Mistral-7B와 Llama3-8B 모델을 활용하여 MIPO와 DPO의 성능을 비교합니다.

- **Performance Highlights**: 실험 결과, MIPO는 다양한 평가 시나리오에서 DPO에 비해 일관되게 우수한 성능을 보였습니다.



### On the Implicit Relation Between Low-Rank Adaptation and Differential Privacy (https://arxiv.org/abs/2409.17538)
- **What's New**: 이번 논문에서는 자연어 처리에서의 저차원(adaptation) 접근법이 데이터 프라이버시(data privacy)와 어떻게 연결되는지를 제시합니다. 특히, LoRA(Lo-Rank Adaptation)와 FLoRA(Fully Low-Rank Adaptation)의 방법이 미치는 영향을 분석하여, 이들이 데이터 민감도를 고려한 저차원 적응과 유사하다는 것을 보여줍니다.

- **Technical Details**: LoRA와 FLoRA는 언어 모델 언어를 특정 작업에 적응시키기 위해 몇 개의 레이어에 훈련 가능한 저차원 분해 매트릭스(adapter)를 통합하여, 사전 훈련된 모델의 가중치를 고정한 상태에서 사용됩니다. 이 접근법은 전통적인 매개변수 조정(full fine-tuning) 방식에 비해 필요한 훈련 가능한 매개변数의 수를 상당히 줄입니다. 연구진은 또한 저차원 적응이 DPSGD(Differentially Private Stochastic Gradient Descent)와 근본적으로 유사하다는 것을 입증하며, 가우시안 분포(Gaussian distribution)와의 변동성(variance)도 분석합니다.

- **Performance Highlights**: 연구의 주요 기여는 다음과 같습니다: 1) LoRA/FLoRA로 저차원 적응을 수행하는 것이 어댑터의 배치 그라디언트(batch gradients)에 무작위 노이즈를 주입하는 것과 동등하다는 것을 보여줍니다. 2) 주입된 노이즈의 분산을 찾아 노이즈가 입력 수와 저차원 적응의 순위(rank)가 증가함에 따라 가우시안 분포에 가까워지게 됨을 증명합니다. 3) 저차원 적응의 동역학은 DP 완전 조정(DP full fine-tuning) 어댑터와 매우 유사함을 입증하며, 이러한 저차원 적응이 데이터 프라이버시를 제공할 수 있는 가능성을 제시합니다.



### SimVG: A Simple Framework for Visual Grounding with Decoupled Multi-modal Fusion (https://arxiv.org/abs/2409.17531)
Comments:
          21pages, 11figures, NeurIPS2024

- **What's New**: 이번 연구에서는 Visual Grounding (VG) 문제를 해결하기 위한 새로운 프레임워크 SimVG를 제안합니다. 기존의 복잡한 모듈이나 아키텍처 대신, SimVG는 멀티모달 전이 학습 모델을 활용하여 시각-언어 기능 융합을 하위 작업으로부터 분리합니다.

- **Technical Details**: SimVG는 기존의 멀티모달 모델을 기반으로 하며, 객체 토큰(Object Tokens)을 포함하여 하위 작업(Task)과 사전 학습(Pre-training) 작업을 깊게 통합하는 방식으로 설계되었습니다. 동적 가중치 균형 증류(DWBD) 방법을 사용하여 다중 브랜치 동기식 학습 과정에서 간단한 브랜치의 표현력을 향상시킵니다. 이 브랜치는 경량 MLP로 구성되어, 구조를 단순화하고 추론 속도를 개선합니다.

- **Performance Highlights**: SimVG는 RefCOCO/+/g, ReferIt, Flickr30K 등 총 6개의 VG 데이터셋에서 실험을 실시한 결과, 효율성과 수렴 속도에서 개선을 이루었으며, 새로운 최첨단 성능을 달성했습니다. 특히, 단일 RTX 3090 GPU에서 RefCOCO/+/g 데이터셋에 대해 12시간 훈련하여 이룬 성과가 주목할 만합니다.



### Drone Stereo Vision for Radiata Pine Branch Detection and Distance Measurement: Integrating SGBM and Segmentation Models (https://arxiv.org/abs/2409.17526)
- **What's New**: 이 연구에서는 드론 기반의 가지치기 시스템을 개발하여, 전통적인 수동 가지치기의 안전 위험을 해결하고자 합니다. 이 시스템은 전문적인 가지치기 도구와 스테레오 비전 카메라를 활용하여 가지를 정확하게 감지하고 자를 수 있는 기능을 제공합니다.

- **Technical Details**: 시스템은 YOLO와 Mask R-CNN을 포함한 딥 러닝 알고리즘을 사용하여 가지 감지를 정확하게 수행하며, Semi-Global Matching 알고리즘을 통합하여 신뢰성 있는 거리 추정을 가능하게 합니다. 이를 통해 드론은 가지의 위치를 정밀하게 파악하고 효율적인 가지치기를 수행할 수 있습니다.

- **Performance Highlights**: 실험 결과에 따르면, YOLO와 SGBM의 결합 구현이 드론이 가지를 정확하게 감지하고 드론으로부터의 거리를 측정하는 데 성공적이라는 것을 보여줍니다. 이 연구는 가지치기 작업의 안전성과 효율성을 향상시키는 한편, 농업 및 임업 관행의 자동화를 위한 드론 기술의 발전에 중요한 기여를 합니다.



### EAGLE: Egocentric AGgregated Language-video Engin (https://arxiv.org/abs/2409.17523)
Comments:
          Accepted by ACMMM 24

- **What's New**: EAGLE (Egocentric AGgregated Language-video Engine) 모델과 EAGLE-400K 데이터셋을 소개하여, 다양한 egocentric video 이해 작업을 통합하는 단일 프레임워크를 제공합니다.

- **Technical Details**: EAGLE-400K는 400K개의 다양한 샘플로 구성된 대규모 instruction-tuning 데이터셋으로, 활동 인식부터 절차 지식 학습까지 다양한 작업을 향상시킵니다. EAGLE는 공간적(spatial) 및 시간적(temporal) 정보를 효과적으로 캡처할 수 있는 강력한 비디오 멀티모달 대형 언어 모델(MLLM)입니다.

- **Performance Highlights**: 광범위한 실험을 통해 EAGLE는 기존 모델보다 우수한 성능을 발휘하며, 개별 작업에 대한 이해와 비디오 내용에 대한 전체적인 해석을 균형 있게 수행할 수 있는 능력을 강조합니다.



### Robotic Environmental State Recognition with Pre-Trained Vision-Language Models and Black-Box Optimization (https://arxiv.org/abs/2409.17519)
Comments:
          Accepted at Advanced Robotics, website - this https URL

- **What's New**: 이번 연구에서는 로봇이 다양한 환경에서 자율적으로 탐색하고 작동하기 위해 필요로 하는 환경 상태 인식을 위한 새로운 방법을 제안합니다. 특히, 사전 훈련된 대규모 Vision-Language Models (VLMs)를 활용하여 환경 상태를 통합적으로 인식할 수 있는 방법을 개발하였습니다.

- **Technical Details**: VLM을 사용하여 Visual Question Answering (VQA) 및 Image-to-Text Retrieval (ITR) 작업을 수행합니다. 이를 통해 로봇은 문이 열려 있는지, 물이 흐르고 있는지와 같은 다양한 환경 상태를 인식할 수 있습니다. 또한, 블랙박스 최적화를 통해 적절한 텍스트를 선택하는 방식으로 인식 정확도를 향상시킬 수 있습니다.

- **Performance Highlights**: 실험을 통해 제안된 방법의 효과성을 입증하였고, Fetch라는 모바일 로봇에서 인식 행동에 적용하였습니다. 이 방법은 다양한 상태 인식을 가능하게 하며, 여러 개의 모델과 프로그램을 준비할 필요 없이 소스 코드 및 컴퓨터 자원의 관리를 용이하게 해줍니다.



### Multi-Designated Detector Watermarking for Language Models (https://arxiv.org/abs/2409.17518)
- **What's New**: 이 논문에서는 대형 언어 모델(LLM)에 대한 다중 지정 탐지기 수조(MDDW; multi-designated detector watermarking) 기술을 제안합니다. 이 기술은 모델 제공자가 두 가지 주요 특성을 가진 수조를 생성할 수 있게 합니다: (i) 특정 여러 지정 탐지기만 워터마크를 식별할 수 있으며, (ii) 일반 사용자에게는 출력 품질이 눈에 띄게 저하되지 않습니다.

- **Technical Details**: MDDW의 보안 정의를 형식화하고, 다중 지정 검증기 서명(MDVS; multi-designated verifier signatures)을 사용하여 MDDW를 구축하기 위한 프레임워크를 제공합니다. MDDW는 모델 제공자, 지정 탐지기, 사용자라는 세 가지 역할을 포함하며, MDDW 스킴은 설정 알고리즘, 모델 제공자를 위한 키 생성 알고리즘, 지정 탐지기를 위한 키 생성 알고리즘, 워터마킹 알고리즘 및 탐지 알고리즘으로 구성됩니다.

- **Performance Highlights**: MDDW 스킴의 구현은 기존 방법보다 향상된 기능과 유연성을 강조하며, 만족스러운 성능 지표를 보입니다. 실험 평가 결과 MDDW의 적용 가능성을 보여줍니다.



### Dataset Distillation-based Hybrid Federated Learning on Non-IID Data (https://arxiv.org/abs/2409.17517)
- **What's New**: 이번 연구에서는 비독립적이고 동일 분포하지 않은(Non-IID) 데이터로 인한 라벨 분포 왜곡(label distribution skew) 문제를 해결하기 위해 HFLDD라는 새로운 하이브리드 연합 학습 프레임워크를 제안합니다.

- **Technical Details**: HFLDD는 클라이언트를 이질적인 클러스터로 분할하며, 각 클러스터 내의 데이터 라벨은 비균형하지만 클러스터 간에는 균형을 이룹니다. 클러스터 헤더는 해당 클러스터의 원거리 데이터를 수집하고 서버와 협업하여 모델 학습을 수행합니다. 이 과정은 기존의 IID 데이터에서 수행되는 전통적인 연합 학습과 유사하여 Non-IID 데이터의 영향을 효과적으로 감소시킵니다.

- **Performance Highlights**: 실험 결과에 따르면, 데이터 라벨이 심각하게 불균형할 때 HFLDD가 Baseline 방법들에 비해 테스트 정확도(test accuracy)와 통신 비용(communication cost) 모두에서 우수한 성능을 보였습니다.



### NeuroPath: A Neural Pathway Transformer for Joining the Dots of Human Connectomes (https://arxiv.org/abs/2409.17510)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 논문은 신경 이미지 데이터에서 구조적 연결성(Structural Connectivity, SC)과 기능적 연결성(Functional Connectivity, FC) 간의 결합 메커니즘에 대한 연구를 소개합니다. 특히 'NeuroPath'라는 새로운 생물학적 영감을 받은 딥 모델을 제안하여, SC와 FC의 쌍으로부터 복잡한 신경 구조의 특징 표현을 발견하고 인지 행동의 예측 및 질병 진단에 활용할 수 있습니다.

- **Technical Details**: NeuroPath 모델은 고차원 토폴로지의 표현 학습 문제로 구성된 SC-FC 결합 메커니즘을 다루며, 다중 헤드 자기 주의(multi-head self-attention) 메커니즘을 사용하여 SC와 FC의 쌍 그래프에서 다중 모달 특징 표현을 캡처합니다. 이를 통해 우리는 SC의 다양한 경로들이 FC를 지원하는 방식(예: cyclic loop)을 이해할 수 있게 됩니다.

- **Performance Highlights**: NeuroPath 지표는 HCP(인간 연결체 프로젝트) 및 UK Biobank와 같은 대규모 공개 데이터셋에서 검증되었으며, 기존의 최첨단 성능을 초과하여 인지 상태 예측과 질병 위험 진단에서 뛰어난 잠재력을 보였습니다.



### Uni-Med: A Unified Medical Generalist Foundation Model For Multi-Task Learning Via Connector-MoE (https://arxiv.org/abs/2409.17508)
- **What's New**: 이 논문은 다양한 시각 및 언어 작업을 위한 일반-purpose 인터페이스로서, 의료 분야의 multi-task learning을 위한 통합된 Multi-modal large language model (MLLM)을 제안합니다. 특히, 이전의 연구들이 처리하지 않았던 connector 문제를 해결하고자 합니다. 향후 Uni-Med는 의학 분야에서의 새로운 시도를 이루어낼 것입니다.

- **Technical Details**: Uni-Med는 범용 시각 feature extraction 모듈, connector mixture-of-experts (CMoE) 모듈, 그리고 LLM으로 구성된 의료 전문 기초 모델입니다. CMoE는 잘 설계된 라우터를 활용하여 projection experts의 혼합을 통해 connector에서 발생하는 문제를 해결합니다. 이 접근 방식을 통해 6개의 의료 관련 작업을 수행할 수 있습니다: 질문 응답(question answering), 시각 질문 응답(visual question answering), 보고서 생성(report generation), 지칭 표현 이해(referring expression comprehension), 지칭 표현 생성(referring expression generation) 및 이미지 분류(image classification).

- **Performance Highlights**: Uni-Med는 connector에서의 multi-task 간섭을 해결하려는 첫 번째 노력으로, 다양한 구성에서 CMoE를 도입하여 평균 8%의 성능 향상을 validates합니다. 이전의 최신 의료 MLLM과 비교할 때, Uni-Med는 다양한 작업에서 경쟁력 있거나 더 우수한 평가 지표를 달성하였습니다.



### Autoregressive Multi-trait Essay Scoring via Reinforcement Learning with Scoring-aware Multiple Rewards (https://arxiv.org/abs/2409.17472)
Comments:
          EMNLP 2024

- **What's New**: SaMRL(Scoring-aware Multi-reward Reinforcement Learning) 방법론을 제안하여 다중 특성 자동 에세이 평가(multi-trait automated essay scoring)에서 Quadratic Weighted Kappa(QWK) 기반 보상을 통합하고, 평균 제곱 오차(MSE) 페널티를 적용하여 실제 평가 방식을 훈련 과정에 포함시킴으로써 모델의 성능을 향상시킵니다.

- **Technical Details**: 기존의 QWK는 비미분 가능성으로 인해 신경망 학습에 직접 사용되지 못하나, SaMRL은 bi-directional QWK와 MSE 페널티를 통해 다중 특성 평가의 복잡한 측정 방식을 훈련에 유효하게 통합하고, 오토 회귀 점수 생성 프레임워크를 적용해 토큰 생성 확률로 강력한 다중 특성 점수를 예측합니다.

- **Performance Highlights**: ASAP 및 ASAP++ 데이터셋을 통한 광범위한 실험 결과, SaMRL은 기존 강력한 기준선에 비해 각 특성과 프롬프트에서 점수 향상을 이끌어내며, 특히 넓은 점수 범위를 가진 프롬프트에서 기존 RL 사용의 한계를 극복한 점이 두드러집니다.



### Adjusting Regression Models for Conditional Uncertainty Calibration (https://arxiv.org/abs/2409.17466)
Comments:
          Machine Learning Special Issue on Uncertainty Quantification

- **What's New**: 이 논문에서는 분할(conformal prediction) 일치 결과의 조건부 커버리지(conditional coverage)를 개선하기 위한 새로운 회귀(Regression) 알고리즘을 제안합니다. 기존의 방법들이 조건부 커버리지 보장을 제공하지 못하는 문제를 해결하고자 조건부 커버리지와 명목(marginal) 커버리지 사이의 미커버리지(miscoverage) 갭을 제어하는 세부 목표를 설정했습니다.

- **Technical Details**: 제안된 알고리즘은 기본적으로 분할(conformal prediction) 절차를 적용한 후의 회귀 함수 최적화를 통해 조건부 커버리지를 향상시키고, Kolmogorov-Smirnov 거리와의 연결고리를 구축합니다. 구체적으로는 미커버리지 갭에 대한 상한을 설정하고, 이를 제어하기 위한 끝에서 끝(end-to-end) 알고리즘을 제안합니다.

- **Performance Highlights**: 이 방법론은 합성 데이터(synthetic datasets) 및 실제 데이터(real-world datasets)에서 실험적으로 유효성을 입증했으며, 기존의 방법들과 비교했을 때 조건부 커버리지의 개선 효과를 확인할 수 있었습니다.



### CadVLM: Bridging Language and Vision in the Generation of Parametric CAD Sketches (https://arxiv.org/abs/2409.17457)
- **What's New**: 이 논문은 Parametric Computer-Aided Design (CAD) 분야에서 CAD 생성 작업을 위한 새로운 Vision Language 모델인 CadVLM을 제안합니다. 이는 기존의 CAD 모델링 방법의 한계를 극복하고, 스케치 이미지와 텍스트를 결합한 멀티모달 접근법을 적용하였습니다.

- **Technical Details**: CadVLM은 사전 학습된 모델을 활용하여 엔지니어링 스케치를 효과적으로 조작할 수 있는 엔드 투 엔드 모델입니다. 이 모델은 스케치 원시 시퀀스 및 스케치 이미지를 통합하여 CAD 자동완성(CAD autocompletion) 및 CAD 자동 제약(CAD autoconstraint)과 같은 다양한 CAD 스케치 생성 작업에서 뛰어난 성능을 발휘합니다.

- **Performance Highlights**: CadVLM은 SketchGraphs 데이터셋에서 CAD 자동완성 및 CAD 자동 제약 작업에서 우수한 성능을 보였으며, Entity Accuracy, Sketch Accuracy, CAD F1 score로 평가된 새로운 평가 지표를 소개하였습니다.



### HDFlow: Enhancing LLM Complex Problem-Solving with Hybrid Thinking and Dynamic Workflows (https://arxiv.org/abs/2409.17433)
Comments:
          27 pages, 5 figures

- **What's New**: 이 논문에서는 Large Language Models (LLMs)의 복잡한 추론 문제 해결을 위한 새로운 프레임워크인 HDFlow를 소개합니다. 이 프레임워크는 빠른 사고와 느린 사고를 적응적으로 결합하여, 복잡한 문제를 더 잘 해결할 수 있도록 합니다.

- **Technical Details**: HDFlow는 두 가지 주요 구성 요소로 이루어져 있습니다. 첫째, 'Dynamic Workflow'라는 새로운 느린 추론 접근법은 복잡한 문제를 관리 가능한 하위 작업으로 자동 분해합니다. 둘째, 'Hybrid Thinking'은 문제의 복잡성에 따라 빠른 사고와 느린 사고를 동적으로 결합하는 일반적인 프레임워크입니다. 이를 통해 모델은 문제의 복잡성에 따라 적절한 사고 모드를 선택합니다.

- **Performance Highlights**: 실험 결과, HDFlow의 느린 사고 방식 및 동적 워크플로우가 Chain-of-Thought (CoT) 전략보다 평균 22.4% 더 높은 정확도를 보였고, Hybrid Thinking은 네 개의 벤치마크 데이터 세트 중 세 개에서 최고의 정확도를 기록했습니다. 또한 하이브리드 사고를 통한 미세 조정 방법이 오픈 소스 언어 모델의 복잡한 추론 능력을 크게 향상시켰습니다.



### Discovering the Gems in Early Layers: Accelerating Long-Context LLMs with 1000x Input Token Reduction (https://arxiv.org/abs/2409.17422)
- **What's New**: 이 연구에서는 긴 컨텍스트 입력을 처리하기 위해 LLM(Large Language Model)의 추론을 가속화하고 GPU 메모리 소모를 줄이는 새로운 접근 방식인 GemFilter를 소개합니다.

- **Technical Details**: GemFilter는 LLM의 초기 레이어를 필터로 사용하여 입력 토큰을 선택하고 압축하는 알고리즘으로, 이에 따라 추후 처리할 컨텍스트 길이를 대폭 줄입니다. 이 방법은 2.4$	imes$ 속도 향상과 30
gpu(%) GPU 메모리 사용량 감소를 달성하였습니다.

- **Performance Highlights**: GemFilter는 Needle in a Haystack 벤치마크에서 기존의 표준 어텐션 및 SnapKV를 능가하며, LongBench 챌린지에서는 SnapKV/H2O와 유사한 성능을 보여줍니다.



### Solar Active Regions Emergence Prediction Using Long Short-Term Memory Networks (https://arxiv.org/abs/2409.17421)
Comments:
          20 pages, 8 figures, 5 tables, under review at the AAS Astrophysical Journal

- **What's New**: 이 연구에서는 Long Short-Term Memory (LSTM) 모델을 개발하여 태양 표면에서 활성 영역(Active Regions, AR)의 형성을 예측합니다. 이 모델은 Solar Dynamics Observatory (SDO) Helioseismic and Magnetic Imager (HMI)로부터 얻은 Doppler shift velocity, continuum intensity, magnetic field observations를 활용하여 시간 시계열 데이터셋을 생성했습니다.

- **Technical Details**: LSTM 모델은 acústic power 및 magnetic flux의 변화를 포착하는 기능이 있으며, 이 연구에서는 61개의 신생 AR에 대한 데이터를 수집하여 12시간 전 continuum intensity를 예측하기 위해 훈련되었습니다. 연구에 사용된 데이터는 활성 영역의 출현 전후의 상태를 포함합니다.

- **Performance Highlights**: 모델 8은 실험 설정에서 모든 테스트 활성 영역의 출현 예측에 성공하였고, AR11726, AR13165 및 AR13179의 경우 각각 10, 29, 5시간 전에 예측했습니다. 이 모델의 RMSE(평균 제곱근 오차) 값은 태양 디스크의 활성 및 조용한 지역 모두에 대해 평균 0.11로, ML 기반의 태양 AR 예측의 기초를 마련했습니다.



### From Deception to Detection: The Dual Roles of Large Language Models in Fake News (https://arxiv.org/abs/2409.17416)
- **What's New**: 최근 연구에서는 다양한 Large Language Models (LLMs)가 가짜 뉴스를 생성할 수 있는 능력과 이러한 모델들이 가짜 뉴스를 감지하는 성능을 비교했습니다. 이는 7개의 LLM을 분석한 최초의 연구로, 각 모델의 편향 및 안전성 준수 여부를 평가하였습니다.

- **Technical Details**: 연구는 LLM의 가짜 뉴스 생성과 감지 등 두 가지 주요 단계를 중점적으로 다루고 있습니다. LLM들은 다양한 편향을 담은 가짜 뉴스를 생성할 수 있으며, 종종 인간이 작성한 내용보다 탐지하기 어렵습니다. 또한, LLM에서 제공하는 설명의 유용성도 평가되었습니다.

- **Performance Highlights**: 결과적으로, 크기가 큰 LLM들이 더 나은 가짜 뉴스 탐지 능력을 보였으며, 일부 모델은 안전 프로토콜을 엄격히 준수하여 편향된 내용을 생성하지 않았습니다. 반면에, 다른 모델은 여러 편향을 포함한 가짜 뉴스를 쉽게 생성할 수 있었고, LLM이 생성한 가짜 뉴스는 일반적으로 인간이 작성한 것보다 탐지될 가능성이 낮다는 사실이 밝혀졌습니다.



### Sociotechnical Approach to Enterprise Generative Artificial Intelligence (E-GenAI) (https://arxiv.org/abs/2409.17408)
- **What's New**: 이 논문에서는 비즈니스 생태계를 사회기술적(sociotechnical) 접근으로 특성화하는 새로운 방법론을 제시합니다. 특히 SCM, ERP, CRM 플랫폼을 통해 제공자(Providers), 기업(Enterprise), 고객(Customers) 간의 관계에 중점을 두고 있습니다.

- **Technical Details**: OID 모델을 통해 비즈니스 인텔리전스(Business Intelligence, BI), 퍼지 로직(Fuzzy Logic, FL), 발명 문제 해결 이론(TRIZ)을 통합하고, OIDK 모델을 통해 지식 관리(Knowledge Management, KM) 및 불완전 지식 관리(Imperfect Knowledge Management, IKM)를 조율합니다. 또한 E-GenAI 비즈니스 생태계는 SCM, ERP, CRM의 GenAI 기반 플랫폼과 BI, FL, TRIZ, KM, IKM의 GenAI 기반 플랫폼을 통합하여 대형 언어 모델(Large Language Models, LLMs)을 정렬합니다.

- **Performance Highlights**: 마지막으로, LLM의 역학을 이해하기 위해 유한 자동자(finite automata)를 활용하여 팔로워(Followers)와 팔로우이(Followees) 간의 관계를 모델링합니다. 이를 통해 소셜 미디어 플랫폼에서 사용자 특성을 식별할 수 있는 LLM 구축을 촉진합니다.



### Transient Adversarial 3D Projection Attacks on Object Detection in Autonomous Driving (https://arxiv.org/abs/2409.17403)
Comments:
          20 pages, 7 figures, SmartSP 2024

- **What's New**: 이 논문에서는 자율 주행 시나리오에서 물체 탐지를 타겟으로 한 새로운 적대적 3D 프로젝션 공격을 제안합니다. 기존의 고정된 적대적 패턴과 달리, 이 새로운 유형의 공격은 3D 표면에서의 일시적 수정과 같은 유연성을 제공합니다.

- **Technical Details**: 이 공격은 최적화 문제로 구성되며, 색상 매핑(color mapping) 및 기하변환 모델(geometric transformation models)을 결합하여 설계되었습니다. 특히, Thin Plate Spine (TPS) 알고리즘을 사용하여 2D 이미지를 3D 표면에 효과적으로 변형합니다.

- **Performance Highlights**: 실험 결과, YOLOv3 및 Mask R-CNN을 기준으로 한 공격의 성공률이 낮은 조도 조건에서 최대 100%에 달하는 것으로 나타났습니다. 이는 실제 자율주행 상황에서의 치명적인 결과를 초래할 수 있는 공격의 효과를 강조합니다.



### Enhancing Recommendation with Denoising Auxiliary Task (https://arxiv.org/abs/2409.17402)
- **What's New**: 본 연구는 사용자의 이력(interaction sequences)에서 발생하는 잡음(noise)이 추천 시스템에 미치는 영향을 다루고 있으며, 이를 개선하기 위한 새로운 방법인 자가 감독(Auto-supervised) 보조 작업 결합 훈련(Auxiliary Task Joint Training, ATJT)을 제안합니다.

- **Technical Details**: ATJT 방법은 원본 이력을 바탕으로 랜덤 대체를 통해 인위적으로 생성된 잡음이 포함된 시퀀스를 학습하여 모델의 성능을 향상시키기 위한 것입니다. 잡음 인식 모델과 추천 모델을 난이도에 따라 조정된 가중치로 훈련하여 잡음이 포함된 시퀀스로부터 적절한 학습을 이끌어냅니다.

- **Performance Highlights**: ATJT 방법은 세 개의 데이터셋에서 일관된 기본 모델을 사용하여 실험한 결과, 모델의 추천 성능을 개선하는 데 효과적임을 입증했습니다.



### AgRegNet: A Deep Regression Network for Flower and Fruit Density Estimation, Localization, and Counting in Orchards (https://arxiv.org/abs/2409.17400)
- **What's New**: 이 논문에서는 농업 산업의 노동력과 비용 문제를 해결하기 위한 자동화된 꽃과 과일 밀도 추정 기술을 제안합니다. 특히, AgRegNet이라는 딥 회귀 기반 네트워크를 사용하여, 탐지(Object Detection)나 다각형 주석(Polygon Annotation) 없이 꽃과 과일의 밀도, 개수, 위치를 추정합니다.

- **Technical Details**: AgRegNet은 U-Net 아키텍처에서 영감을 받아 개발된 U자형 네트워크로, 인코더-디코더 스킵 커넥션을 포함하고 있습니다. ConvNeXt-T를 수정한 구조로 특징을 추출하며, 포인트 주석(Point Annotation) 정보를 바탕으로 학습되고, 세그멘테이션 정보 및 주의 모듈(Attention Modules)을 활용하여 relevant한 꽃과 과일의 특징을 강조합니다.

- **Performance Highlights**: 실험 결과, AgRegNet은 구조적 유사도 지수(Structural Similarity Index, SSIM), 백분율 평균 절대 오차(percentage Mean Absolute Error, pMAE), 평균 평균 정밀도(mean Average Precision, mAP) 측면에서 높은 정확도를 달성했습니다. 특히, 꽃 이미지의 SSIM은 0.938, pMAE는 13.7%, mAP는 0.81이며, 과일 이미지의 경우 SSIM은 0.910, pMAE는 5.6%, mAP는 0.93으로 나타났습니다.



### Beyond Redundancy: Information-aware Unsupervised Multiplex Graph Structure Learning (https://arxiv.org/abs/2409.17386)
Comments:
          Appear in NeurIPS 2024

- **What's New**: 이 논문에서는 여러 가지 간선 유형에 대한 노드 표현을 수동 라벨링 없이 학습하는 비지도 다중 그래프 학습(UMGL)에 초점을 두고 있습니다. 특히, 그래프 구조의 신뢰성을 고려하지 않았던 기존 연구의 한계를 지적하며, 다양한 그래프에서 노이즈를 제거하고 과제 관련 정보를 보존하는 새로운 비지도 학습 방법을 제안합니다.

- **Technical Details**: 제안된 프레임워크인 정보 인식 비지도 다중 그래프 융합(InfoMGF)은 그래프 구조 정제를 활용하여 불필요한 노이즈를 제거하고, 동시에 공유된 과제 관련 정보와 고유한 과제 관련 정보를 최대화합니다. 이 프레임워크는 비지도 학습 방식으로 다중 그래프에서 융합 그래프를 학습합니다.

- **Performance Highlights**: 다양한 다운스트림 작업에 대해 여러 기준선과 비교하여 InfoMGF의 우수한 성능과 강건성을 입증합니다. 특히, 비지도 방법임에도 불구하고 기존의 정교한 감독 방법보다 더 나은 성능을 보였습니다.



### Data-efficient Trajectory Prediction via Coreset Selection (https://arxiv.org/abs/2409.17385)
- **What's New**: 이 논문에서는 복잡한 주행 시나리오(시나리오)에서 데이터 부족 문제와 과대표현된 주행 시나리오로 인한 데이터 중복 문제를 완화하기 위해 새로운 데이터 효율적인 훈련 방법인 'coreset selection'을 제안합니다. 이 방법은 다양한 난이도의 시나리오 간 비율을 조절하면서 중요 데이터를 선택하여, 훈련 성능을 유지하면서 데이터 용량을 줄입니다.

- **Technical Details**: 이 방법은 데이터셋의 난이도 수준에 따라 데이터를 그룹화하고, 각 샘플에 대한 하위 모듈러 이득(submodular gain)을 계산하여 가장 가치 있는 데이터를 선택합니다. 두 가지 선택 방법인 'Fixed Selection'과 'Balanced Selection'을 통해 데이터 분포를 조절하며, 특히 Balnced Selection 방법은 복잡한 시나리오에서 유리한 성과를 보여줍니다. 또한, coresets는 일반화 능력이 뛰어나고 다양한 모델에 대해 테스트되었습니다.

- **Performance Highlights**: Fixed Selection 방법을 이용한 coresets는 전체 데이터셋의 50%만으로도 성능 저하 없이 비슷한 결과를 보여주었으며, Balanced Selection 방법은 더 복잡한 주행 시나리오에서 현저한 성과를 기록했습니다. 선택된 coresets는 SOTA 모델인 HPNet에서도 유사한 성능을 발휘하여, 모델의 다양한 난이도 시나리오에서의 일반화 능력을 강화했습니다.



### VectorSearch: Enhancing Document Retrieval with Semantic Embeddings and Optimized Search (https://arxiv.org/abs/2409.17383)
Comments:
          10 pages, 14 figures

- **What's New**: 이 논문은 고차원 데이터 검색의 정확성을 높이기 위해 'VectorSearch'라는 새로운 알고리즘을 제안합니다. 이 시스템은 고급 언어 모델과 다중 벡터 인덱싱 기술을 통합하여 텍스트 데이터의 의미적 관계를 더 잘 파악할 수 있도록 설계되었습니다.

- **Technical Details**: VectorSearch는 데이터의 다차원 임베딩(embeddings)을 효율적으로 검색하는 하이브리드(document retrieval framework) 시스템입니다. HNSWlib 및 FAISS와 같은 최적화 기법을 사용하여 대규모 데이터셋을 효과적으로 관리하고, 복잡한 쿼리 처리 기능을 통해 고급 검색 작업을 지원합니다. 또한, 시스템은 클러스터 환경에서 동적으로 변화하는 데이터셋을 처리할 수 있는 메커니즘을 포함하고 있습니다.

- **Performance Highlights**: 실제 데이터셋을 기반으로 한 실험 결과, VectorSearch는 기존의 기준 메트릭을 초월하여 대규모 검색 작업에서 뛰어난 성능을 보였습니다. 이는 높은 차원의 데이터에서도 저지연성 검색 결과를 제공함으로써 정보 검색의 정확성을 획기적으로 향상시킨 것을 나타냅니다.



### Tesla's Autopilot: Ethics and Tragedy (https://arxiv.org/abs/2409.17380)
- **What's New**: 이번 사례 연구는 Tesla의 Autopilot과 관련된 사건에서 윤리적 결과를 다루고 있습니다. Tesla Motors의 도덕적 책임과 함께 자율 주행 기술의 윤리적 도전에 대한 넓은 평가를 강조합니다.

- **Technical Details**: 사례 연구는 7단계 윤리적 의사결정 프로세스를 사용하여 Tesla Motors의 도덕적 책임을 분석합니다. 사용자 행동, 시스템 제한, 규제적 함의가 포함되며 자율 주행 기술에 대한 윤리적 고려를 일반적으로 탐구합니다.

- **Performance Highlights**: 사고 분석을 통해 자율 주행 기술의 도입 과정에서 발생할 수 있는 도덕적 딜레마를 강조하며, Tesla가 도로에서 인간과 기계가 공유하는 미래에 맞춰 도덕적 원칙과 법적 시스템을 정렬하는 것이 중요하다고 강조합니다.



### The Overfocusing Bias of Convolutional Neural Networks: A Saliency-Guided Regularization Approach (https://arxiv.org/abs/2409.17370)
- **What's New**: 본 논문에서는 Neural Networks(신경망)가 훈련 데이터가 제한적일 때 특정 이미지 영역에 초점을 맞추는 경향을 설명하고, 이러한 경향을 개선하기 위한 새로운 정규화 방법인 Saliency Guided Dropout(SGDrop)를 제안합니다.

- **Technical Details**: SGDrop은 attribution methods(어트리뷰션 방법)을 사용하여 훈련 중 가장 중요한 특징들의 영향을 줄이고, 신경망이 입력 이미지의 다양한 영역에 주의를 분산시키도록 유도합니다. SGDrop의 구현은 훈련 과정에서 중요한 특징을 선택적으로 삭제하는 방식으로 진행됩니다.

- **Performance Highlights**: 여러 비주얼 분류 벤치마크에서 SGDrop을 적용한 모델은 더 넓은 어트리뷰션과 신경 활동을 보여주었으며, 이는 입력 이미지의 전체적인 관점을 반영합니다. 또한, SGDrop을 통해 일반화 성능이 향상되는 것을 확인할 수 있었습니다.



### Koopman-driven grip force prediction through EMG sensing (https://arxiv.org/abs/2409.17340)
Comments:
          11 pages, 8 figures, journal

- **What's New**: 본 연구는 단일 sEMG 센서 쌍을 이용하여 중간 잡기(grasping)에서의 힘 추정치를 정확하게 도출하는 방법론을 개발하였습니다. 기존 연구들이 정확한 예측을 위해 많은 수의 센서를 요구하는 데 비해, 우리가 제안하는 방법론은 최소한의 센서를 사용하여도 높은 신뢰도를 달성할 수 있도록 설계되었습니다.

- **Technical Details**: 연구 결과, 공차(variance) 없는 sEMG 신호와 그립 힘(grip force) 사이에 높은 피크 상관관계를 달성했으며, 데이터 기반의 Koopman operator를 활용하여 실시간 움켜잡기 힘의 추정 및 단기 예측을 진행하였습니다. 또한, 약 30 ms 내에 0.5초 sEMG 신호 배치를 처리하고 예측하는 고속 알고리즘이 고안되었습니다.

- **Performance Highlights**: 추정된 그립 힘의 wMAPE(weighted Mean Absolute Percentage Error)는 약 5.5%였으며, 0.5초 예측 시에도 wMAPE가 약 17.9%에 달했습니다. 전극 위치에 대한 민감도 분석을 통해 정확한 배치에 대한 요구 조건이 비현저하다는 결과를 도출하였고, 이 연구는 전통적인 방법론에 비해 실시간 적용 가능성을 증가시켰습니다.



### The Technology of Outrage: Bias in Artificial Intelligenc (https://arxiv.org/abs/2409.17336)
Comments:
          Distribution Statement A. Approved for public release; distribution is unlimited

- **What's New**: 본 연구는 알고리즘이 사람을 대체할 수 있다는 통념과 알고리즘이 편향될 수 없다는 주장에 대해 심층적으로 논의하고, 알고리즘 편향에 대한 감정적인 반응의 세 가지 형태를 진단합니다.

- **Technical Details**: 편향(bias)이라는 용어의 모호함을 해소하고, 지능적 시스템에 대한 새로운 감사(audit) 방법을 개발하며, 이러한 시스템에 특정 기능을 구축하는 등 AI 커뮤니티가 취할 수 있는 세 가지 실용적인 접근법을 제안합니다.

- **Performance Highlights**: AI가 인간의 행동을 모방하며, 이러한 시스템이 인간의 편견을 반영함에 따라 public의 우려가 증가하고 있습니다. 이 연구는 복잡한 수학적 모델을 통한 알고리즘 편향 문제 해결에 기여할 방법을 제시합니다.



### Block Expanded DINORET: Adapting Natural Domain Foundation Models for Retinal Imaging Without Catastrophic Forgetting (https://arxiv.org/abs/2409.17332)
Comments:
this http URL, C. Merk and M. Buob contributed equally as shared-first authors. D. Cabrera DeBuc, M. D. Becker and G. M. Somfai contributed equally as senior authors for this work

- **What's New**: 이 연구에서는 자기 지도 학습(self-supervised learning)과 파라미터 효율적인 미세 조정(parameter-efficient fine-tuning)을 이용하여 망막 이미징(retinal imaging) 작업을 위한 두 가지 새로운 기초 모델인 DINORET와 BE DINORET을 개발하였습니다.

- **Technical Details**: DINOv2 비전 트랜스포머(vision transformer)를 적응하여 망막 이미징 분류 작업에 활용하였으며, 두 모델 모두 공개된 색상 안저 사진(color fundus photographs)을 사용하여 개발 및 미세 조정을 진행하였습니다. 우리는 블록 확장(block expansion)이라는 새로운 도메인 적응(domain adaptation) 전략을 도입하였습니다.

- **Performance Highlights**: DINORET과 BE DINORET은 망막 이미징 작업에서 경쟁력 있는 성능을 보여주었고, 블록 확장 모델이 대부분의 데이터 세트에서 최고 점수를 기록했습니다. 특히 DINORET과 BE DINORET은 데이터 효율성 측면에서 RETFound을 초과하며, 블록 확장이 재학습 시의 재난적 망각(catastrophic forgetting)을 성공적으로 완화했다는 점이 주목할 만합니다.



### KIPPS: Knowledge infusion in Privacy Preserving Synthetic Data Generation (https://arxiv.org/abs/2409.17315)
- **What's New**: 이 논문은 KIPPS라는 새로운 프레임워크를 제안하여, Generative Deep Learning 모델에 Domain 및 Regulatory Knowledge를 포함시킴으로써 Privacy Preserving Synthetic 데이터 생성을 개선합니다.

- **Technical Details**: KIPPS는 Generative 모델의 학습 과정에서 속성 값에 대한 추가 맥락과 도메인 제약을 강화하는 방법으로, 데이터를 합성하는 모델의 수용성을 높입니다. 이는 주로 Cybersecurity와 Healthcare와 같은 전문화된 도메인에서 사용됩니다.

- **Performance Highlights**: KIPPS 모델은 실제 데이터셋을 사용하여 프라이버시 보호와 데이터 정확도 간의 균형을 유지하는 효과를 보여줍니다. 모델은 최신 프라이버시 공격에 대해 회복력이 뛰어나며, 다운스트림 작업에서 원본 데이터와 유사한 정보를 유지합니다.



### Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation (https://arxiv.org/abs/2409.17313)
Comments:
          EMNLP 2024 Findings; project page: this https URL

- **What's New**: 이 연구는 Vision-Language Navigation (VLN) 작업을 위한 새로운 평가 프레임워크를 제안합니다. 이 프레임워크는 다양한 지침 범주에 대한 현재 모델을 더 세분화된 수준에서 진단하는 것을 목표로 합니다. 특히, context-free grammar (CFG)를 기반으로 한 구조에서 VLN 작업의 지침 카테고리를 설계하고, 이를 Large-Language Models (LLMs)의 도움으로 반자동으로 구성합니다.

- **Technical Details**: 제안된 평가 프레임워크는 atom instruction, 즉 VLN 지침의 기본 행동에 집중합니다. CFG를 사용하여 지침의 구조를 체계적으로 구성하고 5개의 주요 지침 범주(방향 변화, 수직 이동, 랜드마크 인식, 영역 인식, 숫자 이해)를 정의합니다. 이 데이터를 활용하여 평가 데이터셋 NavNuances를 생성하고, 이를 통해 다양한 모델의 성능을 평가하며 문제가 드러나는 경우가 많았습니다.

- **Performance Highlights**: 실험 결과, 모델 간 성능 차이와 일반적인 문제점이 드러났습니다. LLM에 의해 강화된 제로샷 제어 에이전트가 전통적인 감독 학습 모델보다 방향 변화와 랜드마크 인식에서 더 높은 성능을 보였으며, 반면 기존 감독 접근 방식은 선택적 편향으로 인해 원자 개념 변화에 적응하는 데 어려움을 겪었습니다. 이러한 분석은 VLN 방식의 향후 발전에 중요한 통찰력을 제공합니다.



### Neural Network Plasticity and Loss Sharpness (https://arxiv.org/abs/2409.17300)
- **What's New**: 최신 연구는 비정상적(non-stationary) 환경에서의 연속 학습(Continual Learning)에서 플라스틱성 손실(plasticity loss)과 손실 경량(sharpness) 간의 관계를 조사하였다. 이 논문에서는 이러한 손실을 줄이기 위한 샤프니스 정규화(sharpness regularization) 기법의 사용을 제안한다.

- **Technical Details**: 연속 학습 모델은 시간이 지남에 따라 변화하는 데이터 흐름을 학습하는 모델로, 신경망(neural network)의 예측이 다른 작업에 적응할 수 있는 능력을 요구한다. 본 연구는 손실의 헤세 행렬(Hessian matrix) 최대 고유값(maximal eigenvalue)을 통해 손실 경량을 정량화하며, 이는 네트워크가 처리하는 작업 수에 따라 증가한다는 기존 연구를 바탕으로 한다. 샤프니스 정규화 기법이 사용되며, 이는 네트워크가 더 '평평한(flatter)' 최소값을 찾도록 유도한다.

- **Performance Highlights**: 실험 결과, 샤프니스 정규화 기법은 플라스틱성 손실 감소에 유의미한 영향을 미치지 않는 것으로 나타났다. 이는 이러한 기술이 연속 학습 설정에서의 성능 유지에 있어 한계가 있음을 시사한다.



### SpoofCeleb: Speech Deepfake Detection and SASV In The Wild (https://arxiv.org/abs/2409.17285)
Comments:
          9 pages, 2 figures, 8 tables

- **What's New**: SpoofCeleb 데이터셋은 Speech Deepfake Detection (SDD) 및 Spoofing-robust Automatic Speaker Verification (SASV) 연구를 위해 설계되었으며, 1,251명의 독특한 화자들로부터 250만 개가 넘는 발화 데이터를 포함합니다.

- **Technical Details**: 이 데이터셋은 VoxCeleb1에서 자동 생성된 텍스트 음성 변환(Text-To-Speech, TTS) 시스템을 기반으로 하여 자연스러운 환경에서 수집된 발화로 구성되어 있습니다. 품질이 우수한 합성 음성의 악성 사용을 방지하기 위한 연구를 지원합니다.

- **Performance Highlights**: 정확한 평가 프로토콜이 포함된 학습, 검증 및 평가 세트로 잘 구분되어 있으며, SDD 및 SASV 작업에 대한 기준 성능을 제시하여 연구의 효율성을 높입니다.



### Memory Networks: Towards Fully Biologically Plausible Learning (https://arxiv.org/abs/2409.17282)
Comments:
          2024

- **What's New**: 이번 연구에서 제안하는 Memory Network(메모리 네트워크)는 생물학적 원리에 영감을 받아, 기존 딥러닝 모델에서 사용하는 backpropagation(역전파) 및 convolutions(합성곱)을 회피하고, 단일 패스(single pass)로 작동하는 새로운 접근 방식을 제공합니다. 이로 인해 빠르고 효율적인 학습이 가능해지며, 데이터에 대한 최소한의 노출로도 빠르게 적응할 수 있는 뇌의 능력을 모방합니다.

- **Technical Details**: Memory Network는 입력된 데이터를 인코딩하여 각 뉴런이 새 입력과 같은 레이블을 가진 이전 입력의 평균 표현 사이의 유사성에 기반하여 업데이트되는 방식으로 작동합니다. 이는 전통적인 큰 규모의 CNN(합성곱 신경망)과는 달리, 지역적 플라스틱성(local plasticity) 메커니즘을 활용하여 학습하며, 이는 생물학적 과정과 더욱 밀접하게 일치합니다.

- **Performance Highlights**: 실험 결과, Memory Network는 MNIST와 같은 간단한 데이터셋에서 효율적이고 생물학적으로 그럴듯한 학습을 달성하며 강력한 성능을 보였습니다. 그러나 CIFAR10과 같은 더 복잡한 데이터셋에서는 추가적인 개선이 필요함을 나타내어, 생물학적 과정에 근접하면서도 계산 효율성을 유지할 수 있는 새로운 알고리즘과 기법 개발의 필요성을 강조했습니다.



### On the Vulnerability of Applying Retrieval-Augmented Generation within Knowledge-Intensive Application Domains (https://arxiv.org/abs/2409.17275)
- **What's New**: 이 논문은 Retrieval-Augmented Generation (RAG) 시스템의 적대적 강인성(adversarial robustness)을 조사하였습니다. 특히, 의학 분야의 Q&A를 대상으로 한 '보편적인 중독 공격(universal poisoning attacks)'의 취약성을 분석하고 새로운 탐지 기반(defense) 방어 체계를 개발하였습니다.

- **Technical Details**: RAG 시스템은 외부 데이터에서 중요한 정보를 검색(retrieve)하고 이를 LLM의 생성 과정에 통합하는 두 가지 단계를 포함합니다. 이 연구에서는 225개 다양한 설정에서 RAG의 검색 시스템이 개인 식별 정보(PII)와 같은 다양한 타겟 정보를 포함하는 중독 문서에 취약하다는 것을 입증하였습니다. 중독된 문서는 쿼리의 임베딩과 높은 유사성을 유지함으로써 정확히 검색될 수 있음을 발견하였습니다.

- **Performance Highlights**: 제안한 방어 방법은 다양한 Q&A 도메인에서 뛰어난 탐지율(detection rates)을 일관되게 달성하며, 기존의 방어 방법에 비해 훨씬 효과적임을 보여주었습니다. 실험에 따르면 거의 모든 공격에 대해 일관되게 높은 탐지 성공률을 보였습니다.



### Model aggregation: minimizing empirical variance outperforms minimizing empirical error (https://arxiv.org/abs/2409.17267)
Comments:
          The code in this paper is available for download at this https URL

- **What's New**: 이 논문은 다양한 모델의 예측을 하나의 더 정확한 출력으로 집계하는 데이터 기반 프레임워크를 제안합니다. 이 집계 접근 방식은 각 모델의 강점을 활용하여 전체 정확도를 높이며, 비침해적이고 모델 불가지론적(model-agnostic)입니다.

- **Technical Details**: 제안된 집계 방법에는 최소 오류 집계(Minimal Error Aggregation, MEA)와 최소 분산 집계(Minimal Variance Aggregation, MVA)가 포함됩니다. MEA는 집계의 예측 오류를 최소화하는 반면, MVA는 분산을 최소화합니다. MEVA(Minimal Empirical Variance Aggregation)는 모델 오류를 추정하여 집계를 구성하며, MEEA(Minimal Empirical Error Aggregation)와 비교하여 데이터를 기준으로 한 추정에서 일관성 있게 더 우수한 성능을 발휘합니다.

- **Performance Highlights**: 제안된 MEVA 기법은 데이터 과학 작업 및 오퍼레이터 학습 과제에서 검증되었으며, 모든 사례에서 직접 오류 최소화 방법보다 우수한 성능을 보였습니다. 이는 MEVA가 개별 모델보다 더 강력하고 효과적인 집계 모델을 제공함을 시사합니다.



### Disk2Planet: A Robust and Automated Machine Learning Tool for Parameter Inference in Disk-Planet Systems (https://arxiv.org/abs/2409.17228)
Comments:
          Accepted to ApJ

- **What's New**: Disk2Planet라는 기계 학습 기반 도구를 소개합니다. 이 도구는 관측된 원시 행성계(disk-planet) 구조에서 핵심 매개변수를 추론합니다.

- **Technical Details**: Disk2Planet은 2D 밀도(density) 및 속도(velocity) 맵의 형태로 입력된 원반 구조를 바탕으로, Shakura–Sunyaev 점성(viscosity), 원반 비율(aspect ratio), 행성-별 질량 비율(planet-star mass ratio), 행성의 반지름(radius) 및 방위각(azimuth) 같은 매개변수를 출력합니다. 이 도구는 CMA-ES라는 복잡한 최적화 문제를 위한 진화 알고리즘과, 원반-행성 상호작용의 예측을 위해 설계된 PPDONet이라는 신경망(neural network)을 통합했습니다. 전체 자동화된 시스템으로, Nvidia A100 GPU에서 3분 이내에 하나의 시스템의 매개변수를 검색할 수 있습니다.

- **Performance Highlights**: Disk2Planet은 0.001에서 0.01 정도의 정확도로 매개변수를 추론할 수 있으며, 결측치(missing data)와 다양한 노이즈(noise) 수준을 처리할 수 있는 강력성을 입증했습니다.



### Data-Centric AI Governance: Addressing the Limitations of Model-Focused Policies (https://arxiv.org/abs/2409.17216)
- **What's New**: 현재의 강력한 AI 능력에 대한 규제는 "기초" (foundation) 또는 "최전선" (frontier) 모델에 너무 좁게 초점을 맞추고 있으며, 이러한 용어의 모호성과 불일치로 인해 거버넌스 노력의 기초가 불안정하다는 점을 강조합니다.

- **Technical Details**: 이 논문은 데이터셋의 크기와 내용이 모델의 성능에 미치는 영향을 평가하는 데 필수적인 요소라는 것을 보여주며, 상대적으로 "작은" 모델조차도 충분히 특정한 데이터셋에 노출될 경우 동등한 결과를 달성할 수 있음을 설명합니다. 논의는 데이터 사용의 중요성을 간과하는 동안 정책 논쟁이 발생하는 웃음을 다룹니다.

- **Performance Highlights**: 과도한 사후 규제의 위험성을 강조하고, 능력을 신중하게 정량적으로 평가할 수 있는 경로를 제시하여 규제 환경을 단순화할 수 있는 가능성을 보여줍니다.



### Plurals: A System for Guiding LLMs Via Simulated Social Ensembles (https://arxiv.org/abs/2409.17213)
- **What's New**: 최근 논의에서 언어 모델들이 특정 관점을 선호한다는 우려가 제기되었습니다. 이에 대한 해결책으로 '어디서도 바라보지 않는 시각'을 추구하는 것이 아니라 다양한 관점을 활용하는 방안을 제안합니다. 'Plurals'라는 시스템과 Python 라이브러리를 소개하게 되었습니다.

- **Technical Details**: Plurals는 다양한 관점을 반영하여 신뢰할 수 있는 소셜 에셈블을 생성하는 시스템으로, 사용자 맞춤형 구조 내에서 '대리인'(Agents)들이 심의(deliberation)를 진행하고, 보고자'(Moderators)가 이를 감독합니다. 이 시스템은 미국 정부의 데이터셋과 통합되어 국가적으로 대표적인 페르소나를 생성하면서 민주적 심의 이론에 영감을 받은 형식으로 사용자 정의가 가능합니다.

- **Performance Highlights**: 여섯 가지 사례 연구를 통해 이론적 일관성과 효용성(efficacy)을 보여주었고, 세 가지 무작위 실험에서는 생성된 산출물이 관련 청중의 온라인 샘플과 잘 맞아떨어짐을 발견했습니다. Plurals는 사용자가 시뮬레이션된 사회적 집단을 생성할 수 있도록 도와주며, 초기 연구 결과 또한 제시됩니다.



### 2024 BRAVO Challenge Track 1 1st Place Report: Evaluating Robustness of Vision Foundation Models for Semantic Segmentation (https://arxiv.org/abs/2409.17208)
Comments:
          arXiv admin note: substantial text overlap with arXiv:2409.15107

- **What's New**: 2024 BRAVO Challenge의 Track 1에서 Cityscapes 데이터셋으로 훈련된 모델을 제시하며, 다양한 out-of-distribution 데이터셋에서의 강건성을 평가합니다. 이 연구는 Vision Foundation Models (VFM)을 활용하여 DINOv2에 간단한 segmentation decoder를 붙여 전체 모델을 fine-tuning하여 우수한 성능을 보여줍니다.

- **Technical Details**: 이 연구에서는 DINOv2 VFM을 사용하여 semantic segmentation을 위한 pre-trained 모델을 fine-tuning합니다. 기본 구성에서 간단한 linear decoder를 사용하여 patch-level features를 segmentation logits로 변환합니다. 다양한 모델 크기, patch 크기, pre-training 전략 및 segmentation decoders를 실험하여 우리의 접근 방식의 효과를 평가합니다.

- **Performance Highlights**: 우리는 기존의 복잡한 모델들을 능가하여 이 챌린지에서 1위를 달성했습니다. 우리의 간단한 접근 방식이 어떻게 specialist 모델들보다 더 나은 성능을 내는지를 입증하며, 향후 연구에서 관심을 끌 수 있는 새로운 관찰도 제시합니다.



### Enhancing Guardrails for Safe and Secure Healthcare AI (https://arxiv.org/abs/2409.17190)
- **What's New**: 이번 논문에서는 헬스케어 AI에 내재된 독특한 안전 및 보안 문제를 조사하고, 의료 분야에 적합한 안전망 개선 방안을 제안합니다. 특히, 비임상 환경에서 발생할 수 있는 환각(hallucination), 잘못된 정보(misinformation)의 확산, 사실 정확성의 필요성을 강조합니다.

- **Technical Details**: 이 연구는 NVIDIA NeMo Guardrails와 Llama Guard의 통합 방법을 제안합니다. NeMo Guardrails는 사용자의 프롬프트를 벡터 표현으로 변환하고, Llama Guard는 악의적인 우회(jailbreaking)를 방지하여 의료 AI 시스템의 무결성을 보장합니다. 두 프레임워크를 통합하여 의료 AI 시스템의 리스크를 줄이기 위한 방법론을 제시합니다.

- **Performance Highlights**: 이 통합 접근 방식은 여러 의료 데이터 세트를 통해 평가되었으며, 정확하고 신뢰성 있는 헬스케어 AI의 사용을 보장하여 환자 안전을 향상시키는 데 기여할 것이 기대됩니다. 이 연구는 의료 AI의 널리 보급되는(application) 가능성을 높이는 데 중점을 두고 있습니다.



### Transfer learning for financial data predictions: a systematic review (https://arxiv.org/abs/2409.17183)
Comments:
          43 pages, 5 tables, 1 figure

- **What's New**: 이 논문은 전이 학습(Transfer Learning) 방법론을 금융 시장 예측에 적용하는 데 중점을 두고 있으며, 기존에는 신경망(neural network) 아키텍처에 주로 집중된 리뷰가 많았던 점을 지적합니다.

- **Technical Details**: 금융 시계열 데이터는 노이즈(noise)와 뉴스에 취약하며, 전통적인 통계 방법론은 선형성(linearity) 및 정규성(normality) 가정을 바탕으로 하였기 때문에 비선형적(non-linear) 특성을 잘 설명하지 못합니다. 신경망은 금융 가격 예측에 있어 주요한 머신 러닝 도구로 자리잡고 있으며, 전이 학습은 출발하는 작업(source task)에서 목표 작업(target task)으로 지식을 전이하는 방법으로, 금융 예측에 있어 유용한 도구가 될 수 있습니다.

- **Performance Highlights**: 전이 학습 방법론은 향후 주식 시장 예측의 도전과제 및 잠재적 미래 방향성을 탐구하는 데 중요한 역할을 할 것으로 기대됩니다.



### Fully automatic extraction of morphological traits from the Web: utopia or reality? (https://arxiv.org/abs/2409.17179)
- **What's New**: 이 논문은 최근의 대형 언어 모델(LLMs)을 활용하여 비구조적인 텍스트에서 식물의 형태학적 특성 정보를 자동으로 수집하고 처리하는 메커니즘을 제안합니다. 이를 통해 전문가가 수년간 수집해야 하는 복잡한 특성 정보를 손쉽게 구축할 수 있습니다.

- **Technical Details**: 제안된 방법론은 다음과 같은 세 가지 입력을 요구합니다: (i) 관심 있는 종의 목록, (ii) 관심 있는 특성 목록, 그리고 (iii) 각 특성이 가질 수 있는 모든 가능한 값의 목록. 이 프로세스는 검색 엔진 API를 사용하여 관련 URL를 가져오고, 이 URL에서 텍스트 콘텐츠를 다운로드합니다. 이후 NLP 모델을 통해 설명 문장을 판별하고, LLM을 사용하여 기술적 특성 값을 추출합니다.

- **Performance Highlights**: 이 방식으로 3개의 수작업으로 작성된 종-특성 행렬을 자동으로 복제하는 평가를 실시했습니다. 결과적으로 75% 이상의 F1-score를 달성하며, 50% 이상의 종-특성 쌍의 값을 찾는 데 성공했습니다. 이는 비구조적 온라인 텍스트로부터 구조화된 특성 데이터베이스를 대규모로 생성하는 것이 현재 가능하다는 점을 보여줍니다.



### CSCE: Boosting LLM Reasoning by Simultaneous Enhancing of Casual Significance and Consistency (https://arxiv.org/abs/2409.17174)
- **What's New**: 현재의 언어 모델(LLMs)에서 Chain-Based(체인 기반) 접근 방식에 의존하지 않고, 인과적 중요성(causal significance)과 일관성(consistency)을 동시에 고려할 수 있는 비체인 기반의 새로운 추론 프레임워크인 CSCE(Causal Significance and Consistency Enhancer)를 제안합니다.

- **Technical Details**: CSCE는 Treatment Effect(치료 효과) 평가를 활용하여 LLM의 손실 함수(loss function)를 맞춤화하고, 인과적 중요성과 일관성을 두 가지 측면에서 향상시킴으로써 인과관계를 정확히 파악하고 다양한 상황에서 견고하고 일관된 성능을 유지하도록 합니다. 이 프레임워크는 최대한의 추론 효율성을 위해 전체 추론 과정을 한 번에 출력합니다.

- **Performance Highlights**: CSCE 방법은 Blocksworld, GSM8K, Hanoi Tower 데이터셋에서 Chain-Based 방법들을 초월하여 높은 성공률과 빠른 처리 속도를 기록하며, 비체인 기반 방법이 LLM의 추론 작업을 완료하는 데에도 기여할 수 있음을 입증했습니다.



### A Multiple-Fill-in-the-Blank Exam Approach for Enhancing Zero-Resource Hallucination Detection in Large Language Models (https://arxiv.org/abs/2409.17173)
Comments:
          20 pages

- **What's New**: 본 논문에서는 이야기가 변경되는 문제를 해결하기 위해 다중 객관식 채우기 시험(multiple-fill-in-the-blank exam) 접근 방식을 포함한 새로운 환각(hallucination) 감지 방법을 제안합니다.

- **Technical Details**: 제안된 방법은 원본 텍스트에서 여러 객체를 마스킹한 후 각 시험 응답이 원본 스토리라인과 일치하도록 LLM을 반복적으로 도와줍니다. 이 과정에서 발생하는 환각 정도를 채점하여 평가합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 기존 방법(SCGP)보다 우수한 성능을 보이며, SCGP와의 앙상블에서도 현저한 성능 향상을 나타냅니다.



### What Would You Ask When You First Saw $a^2+b^2=c^2$? Evaluating LLM on Curiosity-Driven Questioning (https://arxiv.org/abs/2409.17172)
- **What's New**: 본 논문에서는 대규모 언어 모델(LLM)의 새로운 지식 습득 가능성을 평가하기 위한 혁신적인 평가 프레임워크를 제안합니다. 이 프레임워크는 LLM이 과학적 지식을 소개하는 진술에 대한 질문을 생성하도록 유도하여, 처음 접하는 사람처럼 호기심을 가지고 질문하는 방식으로 평가합니다.

- **Technical Details**: 제안된 평가 방법은 호기심 기반 질문 생성(CDQG) 과제로, LLM이 처음 접하는 진술을 상상하며 즉각적으로 떠오르는 질문을 만들어내도록 프롬프트합니다. 생성된 질문은 관련성(relevance), 일관성(coherence), 다양성(diversity) 세 가지 주요 지표로 평가되며, 심리학 문헌에 뿌리를 두고 있습니다. 여러 모델의 성능을 비교 평가하기 위해 물리학, 화학 및 수학 분야의 1101개의 다양한 난이도의 진술로 구성된 합성 데이터셋을 수집했습니다.

- **Performance Highlights**: GPT-4와 Mistral 8x7b와 같은 대형 모델이 일관성 있고 관련성이 높은 질문을 잘 생성하는 반면, 크기가 작은 Phi-2 모델은 동등하거나 그 이상으로 효과적임을 발견했습니다. 이는 모델의 크기만으로 지식 습득 가능성을 판단할 수 없음을 나타냅니다. 연구 결과, 제안된 프레임워크는 LLM의 질문 생성 능력을 새로운 관점에서 평가할 수 있는 기회를 제공합니다.



### Cross-Domain Content Generation with Domain-Specific Small Language Models (https://arxiv.org/abs/2409.17171)
Comments:
          15 pages

- **What's New**: 이 연구는 여러 개별 데이터셋에서의 작은 언어 모델을 활용한 도메인 특정 콘텐츠 생성에 대한 새로운 접근 방식을 탐색합니다. 특히, 두 개의 서로 다른 도메인인 이야기 (story)와 레시피 (recipe)에 대한 모델을 비교하였습니다.

- **Technical Details**: 모델을 각각의 데이터셋에 대해 개별적으로 훈련시키는 방식이 사용되었으며, 사용자 정의 토크나이저 (custom tokenizer)를 적용하여 생성 품질을 크게 향상시켰습니다. 또한 Low-Rank Adaptation (LoRA)나 일반적인 파인튜닝 (fine-tuning) 방법으로 단일 모델을 두 도메인에 적용하려고 시도했지만 유의미한 결과를 얻지 못했습니다. 특히, 전체 파인튜닝(full fine-tuning)중 모델의 가중치 동결 없이 진행 시, 치명적 망각 (catastrophic forgetting)이 발생하였습니다.

- **Performance Highlights**: 지식 확장 전략 (knowledge expansion strategy)을 통해 모델이 이야기와 레시피를 요청에 따라 생성할 수 있도록 하였으며, 이는 서로 다른 데이터셋 간의 의미 있는 출력을 유지하도록 하였습니다. 연구 결과는 고정된 레이어를 가진 지식 확장이 작은 언어 모델이 다양한 도메인에서 콘텐츠를 생성하는 데 효과적인 방법임을 보여줍니다.



### REAL: Response Embedding-based Alignment for LLMs (https://arxiv.org/abs/2409.17169)
- **What's New**: 이 논문에서는 대규모 언어 모델(LLMs)과 인간의 선호를 일치시키기 위한 효율적인 데이터 선택 전략을 제안합니다. 기존 알고리즘의 한계를 극복하기 위해 의미 있는 응답 쌍을 선택하는 방법론을 개발하였습니다.

- **Technical Details**: 제안된 방법은 HH-RLHF 데이터셋에서 유사하지 않은 응답 쌍을 선택하여 LLM의 직접적인 정렬을 개선하며 라벨링 오류를 감소시키는 것을 목표로 합니다. 코사인 유사성을 기반으로 응답 쌍의 유용성을 평가하여 높은 품질의 학습 데이터를 형성합니다.

- **Performance Highlights**: 실험 결과, 유사하지 않은 응답 쌍을 사용한 모델이 대화 작업에서 최상의 승률을 기록하였으며, 라벨러의 작업을 최대 65%까지 절감하는 효율성을 보여주었습니다.



### StressPrompt: Does Stress Impact Large Language Models and Human Performance Similarly? (https://arxiv.org/abs/2409.17167)
Comments:
          11 pages, 9 figures

- **What's New**: 이번 연구는 Large Language Models (LLMs)가 인간과 유사한 스트레스 반응을 보이는지를 탐구하고, 다양한 스트레스 유도 프롬프트 하에서의 성능 변화를 평가합니다. 이는 스트레스의 심리적 원리를 바탕으로 한 새로운 종류의 프롬프트 세트, StressPrompt를 통해 이루어졌습니다.

- **Technical Details**: 연구에서는 심리학적 이론에 기반하여 설계된 100개의 프롬프트를 개발하였으며, 이는 각각 다른 수준의 스트레스를 유도하도록 설계되었습니다. 또한, LLM의 내부 상태와 성능에 미치는 스트레스의 영향을 측정하기 위한 '스트레스 스캐너'를 도입했습니다.

- **Performance Highlights**: 연구 결과, LLM은 중간 수준의 스트레스 하에서 최적의 성능을 보이며, 낮은 스트레스와 높은 스트레스 모두에서 성능이 저하되는 것으로 나타났습니다. 이는 Yerkes-Dodson 법칙에 부합하며, 고객 서비스, 의료, 응급 대응과 같은 실세계 시나리오에서 AI 시스템의 성능 유지의 중요성을 시사합니다.



### ScriptSmith: A Unified LLM Framework for Enhancing IT Operations via Automated Bash Script Generation, Assessment, and Refinemen (https://arxiv.org/abs/2409.17166)
Comments:
          Under Review

- **What's New**: 본 논문에서는 사이트 신뢰성 엔지니어링(SRE) 분야에서 발생하는 이슈를 보다 효율적으로 관리하고 해결하기 위한 혁신적인 접근 방식을 제시합니다. 대규모 언어 모델(LLMs)을 활용하여 Bash 스크립트 생성, 평가 및 개선을 자동화하는 방법을 통해 SRE 팀의 생산성을 향상시키고자 합니다.

- **Technical Details**: 이 연구에서는 CodeSift 데이터셋(100개 작업)과 InterCode 데이터셋(153개 작업)을 활용하여 LLMs가 스크립트를 자동으로 평가하고 개선할 수 있는지 실험하였습니다. 이를 통해 실행 환경에 의존하지 않는 프레임워크 'ScriptSmith'를 개발하여, 추천된 행동 단계에 대한 올바른 Bash 스크립트를 생성하는 데 중점을 두었습니다. 해당 프레임워크는 과거 작업의 카탈로그에서 일치하는 스크립트를 찾고, 없다면 새로운 스크립트를 동적으로 생성합니다.

- **Performance Highlights**: 실험 결과, 제안된 프레임워크는 스크립트 생성에서 7-10%의 전체적인 개선을 보였으며, Llama3과 Gemini 모델을 바탕으로 한 Bash 데이터셋 평가에서도 유의미한 정확도를 기록하였습니다. 특히, Llama3_70B 모델은 CodeSift 데이터셋에서 75%의 정확도를 보였으며, Gemini1.5_Pro 모델 역시 우수한 성능을 보여주었습니다.



### Cross Dataset Analysis and Network Architecture Repair for Autonomous Car Lane Detection (https://arxiv.org/abs/2409.17158)
- **What's New**: 본 연구에서는 자율주행 차량의 차선 인식 애플리케이션을 위한 교차 데이터세트 분석과 신경망 아키텍처 수리를 수행합니다. 제공된 아키텍처인 ERFCondLaneNet은 복잡한 형상의 차선을 탐지하는 데 어려움을 겪는 기존의 CondLaneNet을 개선한 것입니다.

- **Technical Details**: 이 연구에서 제안하는 ERFCondLaneNet은 CondLaneNet [liu_condlanenet_2021]과 ERFNet [romera_erfnet_2018]을 통합하여 만들어졌으며, Transfer Learning (TL) 프로토콜을 사용하여 두 가지 주요 차선 탐지 벤치마크인 CULane과 CurveLanes에서 테스트되었습니다. 이 기술은 성능을 유지하면서도 33% 적은 특징을 사용하여 모델 크기를 46% 줄였습니다.

- **Performance Highlights**: ERFCondLaneNet은 ResnetCondLaneNet과 비슷한 성능을 보이며, 이는 복잡한 지형을 가진 차선 탐지에서  충분한 정확성을 유지합니다. 학습 과정에서 기존 모델보다 적은 데이터로도 우수한 결과를 보여줍니다.



### Confident Teacher, Confident Student? A Novel User Study Design for Investigating the Didactic Potential of Explanations and their Impact on Uncertainty (https://arxiv.org/abs/2409.17157)
Comments:
          15 pages, 5 figures, 1 table, presented at ECML 2024, AIMLAI Workshop, Vilnius

- **What's New**: 이 연구는 Explainable Artificial Intelligence (XAI)의 평가를 위한 실험 디자인을 제안하며, 1200명의 참가자를 대상으로 AI와의 협력 설정에서 설명이 인간 성과에 미치는 영향을 조사합니다.

- **Technical Details**: 이 연구에서는 복잡한 생물 분류의 시각적 주석 작업에서 XAI의 잠재력을 평가하였고, 사용자가 기계의 예측을 보여줄 때와 설명을 추가했을 때의 차이를 분석했습니다. 또한, 사용자의 주석이 AI 도움 후에도 유의미하게 개선되지 않았음을 발견했습니다.

- **Performance Highlights**: 사용자는 AI 지원으로 주석 정확도가 높아졌지만, 모델의 예측을 보여주는 것과 설명을 제공하는 것의 효과는 유의미한 차이가 없었습니다. 또한, 사용자가 잘못된 예측을 반복하는 부정적 효과가 발견되었습니다.



### Turn Every Application into an Agent: Towards Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents (https://arxiv.org/abs/2409.17140)
- **What's New**: 이 논문은 AXIS라는 새로운 LLM 기반 에이전트 프레임워크를 제안하여 UI(UI)의 행위보다 API(API)의 행위를 우선시함으로써 사용자 인터페이스와의 상호작용에서 발생하는 지연(latency)과 신뢰성(reliability) 문제를 해결하고자 합니다.

- **Technical Details**: AXIS는 기존의 소프트웨어 애플리케이션을 자동 탐색하고 지원 문서 및 액션 트레일에서 통찰력을 학습하며 새로운 API를 생성할 수 있는 기능을 갖춘 자기 탐색(self-exploration) LLM 기반 프레임워크입니다. 이 프레임워크는 API 호출을 통해 작업을 수행하며, 예를 들어 Word 문서에 2×2 테이블을 삽입할 때 API 호출로 단 한 줄의 코드(doc.Tables.Add(NumRows=2,NumColumns=2)) 만으로 작업을 완료할 수 있습니다.

- **Performance Highlights**: AXIS를 사용하여 Office Word에서 수행한 실험 결과, 작업 완료 시간(task completion time)을 65%-70% 단축시키고 인지적 작업 부담(cognitive workload)을 38%-53% 감소시켰으며, 정확성은 97%-98%로 유지되었습니다. 이 연구는 LLM 시대에 애플리케이션 제공자를 위한 새로운 UI 디자인 원칙과 인간-에이전트-컴퓨터 상호작용(HACI) 프레임워크의 기여를 포함합니다.



### On-orbit Servicing for Spacecraft Collision Avoidance With Autonomous Decision Making (https://arxiv.org/abs/2409.17125)
Comments:
          The first joint European Space Agency SPAICE Conference / IAA Conference on AI in and for Space

- **What's New**: 본 연구는 인공지능(AI)을 기반으로 한 자율 궤도 서비스(On-Orbit Servicing, OOS) 임무 개발을 다루며, 이를 통해 우주선 충돌 회피 기동(Collision Avoidance Maneuvers, CAM)을 지원합니다. 특히 강화 학습(Reinforcement Learning, RL)으로 훈련된 자율 ‘서빙기(servicer)’를 제안하고, 충돌 위험을 자동으로 탐지하며 endangered satellite과 조우하고 도킹하여 최적의 CAM을 수행합니다.

- **Technical Details**: 본 연구는 목표 위성을 보호하기 위해 자율적으로 CAM을 결정하고 수행하는 서빙기 우주선을 고려합니다. 연구는 궤도 역학 시뮬레이터, 에이전트, 환경, 그리고 에이전트 훈련 알고리즘을 포함하는 프레임워크를 구성합니다. 또한, Markov Decision Process (MDP) 모델을 사용하여 자율 결정 문제를 형성하고, 각 위성과 쓰레기, 서빙기의 상태, 행동, 보상 함수를 정의합니다.

- **Performance Highlights**: 초기 결과는 Collision Avoidance 서비스에 대한 자율 로봇 OOS의 실행 가능성을 보여줍니다. 특히, 한 대의 서빙기 우주선과 하나의 endangered satellite 시나리오에서 집중적으로 연구하여 그 실행의 복잡성을 논의합니다.



### VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models (https://arxiv.org/abs/2409.17066)
- **What's New**: 이 논문에서는 Large Language Models (LLMs)의 극히 저비트 양자화를 위한 새로운 접근법인 Vector Post-Training Quantization (VPTQ)을 제시합니다. VPTQ는 2비트 양자화를 지원하여 메모리 요구 사항을 줄이고 저장 비용을 최적화합니다.

- **Technical Details**: VPTQ는 두 번째 순서 최적화(Second-Order Optimization)를 사용하여 LLM의 벡터 양자화(Vector Quantization) 문제를 공식화합니다. 이 알고리즘은 채널 독립적인 두 번째 순서 최적화를 통해 세밀한 벡터 양자화를 제공하며, 최적화 문제를 분해하여 효과적인 코드북 초기화 알고리즘을 제안합니다. 또한, 잔여(residual)와 이상치(outlier) 양자화를 지원하여 모델의 정확성을 향상시키고 모델 압축을 추가적으로 진행합니다.

- **Performance Highlights**: 실험 결과에 따르면 VPTQ는 LLaMA-2에서 모델 양자화의 혼란도(perplexity)를 $0.01$-$0.34$ 감소시키고, Mistral-7B에서 $0.38$-$0.68$, LLaMA-3에서 $4.41$-$7.34$의 향상을 보였습니다. QA 작업에서 평균적으로 LLaMA-2는 $0.79$-$1.5	ext{ 	extbf{	extit{	extbf{	extit{%}}}}}$, Mistral-7B는 $1	ext{ 	extbf{	extit{%}}}$, LLaMA-3는 $11$-$22	ext{ 	extbf{	extit{	extbf{	extit{%}}}}}$의 정확도 개선을 나타냈습니다. 이 방법은 이전 방법 대비 $1.6$-$1.8	imes$의 추론 처리량을 증가시켰습니다.



### DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data (https://arxiv.org/abs/2409.17055)
- **What's New**: 이 논문은 의료 데이터의 다중 모드(multi-modal) 통합을 위한 새로운 방법인 DRIM을 소개합니다. DRIM은 결측 데이터가 있는 상황에서도 공유된 정보와 고유한 정보를 효과적으로 캡처합니다. 이 방법은 환자 관련 정보와 각 모드에 특정한 정보를 분리하여 인코딩합니다.

- **Technical Details**: DRIM은 각 모드에 대한 두 개의 인코더(encoder)를 사용하여, 하나는 공유 정보(shared information)를, 다른 하나는 고유 정보(unique information)를 캡처합니다. 이를 통해 두 가지 차원에서 정보 통합을 수행합니다: 첫 번째로는 공유 정보 집합을 모으고, 두 번째로는 고유 정보를 조합하여 포괄적인 표현을 생성합니다. 또한 DRIM은 attention 기반의 융합 방법을 사용해 결측 모드를 자연스럽게 관리합니다.

- **Performance Highlights**: DRIM은 교모종(glioma) 환자의 생존 예측 작업에서 기존의 최신 알고리즘을 초월하는 성능을 발휘했습니다. 특히, DRIM은 결측 모드가 있어도 성능이 안정적이며, 의료 데이터의 복잡한 특성을 효과적으로 다룰 수 있습니다.



### Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia (https://arxiv.org/abs/2409.17054)
- **What's New**: 이 연구는 동남아시아 지역에서의 의사-환자 상호 작용의 효율성을 개선하기 위해 지역화된 대형 언어 모델(LLM)을 활용한 자동적 환자 기록 전사 및 요약 시스템을 제안합니다.

- **Technical Details**: 이 시스템은 OpenAI의 Whisper 모델을 사용하여 실시간으로 환자-의사 대화를 전사하고, GPT-3를 통해 요약된 정보를 ePuskesmas 전자 건강 기록 형식으로 변환합니다. 주요 과정은 네 가지로 나누어집니다: 대화 녹음, 실시간 전사, 의료 데이터 요약, 자동 ePuskesmas 파서.

- **Performance Highlights**: 이 솔루션을 통해 의사들은 더욱 신속하게 환자 정보를 정리할 수 있으며, 기록의 질도 향상되어 향후 환자 방문을 위한 정보가 더욱 자세하고 통찰력 있게 변모합니다. 이는 인도네시아의 과중한 시설과 의료 제공자의 행정 부담을 해소하는 중요한 진전을 나타냅니다.



### AI-Driven Risk-Aware Scheduling for Active Debris Removal Missions (https://arxiv.org/abs/2409.17012)
- **What's New**: 본 논문에서는 Deep Reinforcement Learning (DRL)을 기반으로 한 자율 의사 결정 계획 모델을 통해 Active Debris Removal (ADR) 미션에서 우주 쓰레기 제거 작업을 최적화하는 방안을 제시합니다.

- **Technical Details**: ADR 미션 계획 문제는 Cost-Constrained Traveling Salesman Problem (CCTSP)로 구성된다는 점이 강조되며, OTV(Orbital Transfer Vehicle)가 쓰레기 간 전이를 수행하며 비행 시간을 최소화하고 연료를 효율적으로 사용할 수 있도록 설계됩니다. 상태 공간은 남은 쓰레기 수, OTV의 총 연료량, 남은 임무 시간, 현재 제거할 쓰레기, 각 쓰레기의 제거 여부 및 충돌 위험 수준을 포함합니다.

- **Performance Highlights**: 제안된 모델을 통해 OTV는 쓰레기 제거 작업의 최적 계획을 수립할 수 있으며, 자동적으로 충돌 위험이 높은 쓰레기를 포함시키는 방식으로 계획을 업데이트하는 능력을 얻는 것으로 나타났습니다.



### Models Can and Should Embrace the Communicative Nature of Human-Generated Math (https://arxiv.org/abs/2409.17005)
- **What's New**: 이 논문은 수학이 사람에 의해 사람을 위해 구성된다는 관점을 제안하며, 수학 데이터가 단순한 기호적 표현을 넘어선 풍부한 의사소통 의도를 반영한다고 주장합니다. 이 연구는 언어 모델(Language Models)이 수학적 심볼을 처리할 때 인간과 유사한 방식을 채택하고 있음을 실험을 통해 증명합니다.

- **Technical Details**: 연구에서는 두 가지 사례 연구를 통해 언어 모델의 수학적 문제 해결 방식의 비대칭성(asymmetry)과 정렬(ordering)에 대한 선호도를 조사하였습니다. 첫 번째 실험에서는 동일한 기본 방정식에 대해 다양한 형태의 언어 문제를 생성하는 능력을 평가했습니다. 두 번째로, 언어 모델이 수학적 증명의 배열 방식이 자연스러운 방식일 때 더 선호한다는 사실을 발견했습니다. 이는 AI 시스템이 인간이 생성한 수학의 의사소통 의도를 학습하고 표현하는 데 기여할 수 있음을 나타냅니다.

- **Performance Highlights**: 언어 모델들은 같은 방정식에 대해 다르게 해석하며, 문제를 구성할 때 비대칭성을 인식합니다. 또한, 정당한 수학적 증명들의 배열 순서에 대해 인간처럼 자연적인 방식의 선호를 보였습니다. 이러한 결과는 수학적 의사소통에서 맥락을 완전히 무시하지 말고 이를 고려해야 한다는 점을 강조합니다.



### Harnessing Diversity for Important Data Selection in Pretraining Large Language Models (https://arxiv.org/abs/2409.16986)
- **What's New**: 본 논문에서는 대규모 언어 모델(LLM)의 사전 훈련을 위한 데이터 선택 접근 방식인 	exttt{Quad}를 제안합니다. 이 방법은 데이터의 질과 다양성을 동시에 고려하여 모델 성능을 극대화하는 데 기여합니다.

- **Technical Details**: 	exttt{Quad}는 주어진 데이터셋을 유사한 데이터 인스턴스를 클러스터링하고, 각 클러스터에서 샘플을 선택하여 측정 비용을 절감합니다. 영향을 평가하기 위해 iHVP(computation methods)를 주의(attention) 레이어에 맞게 수정하였습니다.

- **Performance Highlights**: 	exttt{Quad}는 고품질 데이터를 선택하는 동시에 데이터의 다양성을 유지하여 LLM의 성능을 최적화합니다. 이 접근 방식은 데이터 선택 과정에서 영향 점수를 활용하여 클러스터의 품질을 높이고, MAB(Multi-Armed Bandit) 방법론을 통해 효율성을 극대화합니다.



### AXCEL: Automated eXplainable Consistency Evaluation using LLMs (https://arxiv.org/abs/2409.16984)
- **What's New**: 이 논문에서는 LLM을 활용하여 텍스트 응답의 일관성을 평가하는 새로운 접근 방식인 AXCEL(Automated eXplainable Consistency Evaluation using LLMs)을 소개합니다. AXCEL은 프롬프트 기반으로 작동하며, 일관성 점수에 대한 설명을 제공하여 사용자가 추론할 수 있도록 돕습니다.

- **Technical Details**: AXCEL는 Chain of Thought (CoT)와 few shot prompting 기술을 사용하여 텍스트의 일관성을 측정합니다. 기존의 메트릭에 비해 AXCEL은 설명 가능성을 제공하며, 특정 태스크에 맞지 않아도 여러 태스크에 적용할 수 있는 일반화 가능성을 가지고 있습니다. AXCEL은 요약, 자유 텍스트 생성, 데이터-텍스트 변환의 세 가지 태스크에서 실험되었습니다.

- **Performance Highlights**: AXCEL은 요약에서는 8.7%, 자유 텍스트 생성에서는 6.2%, 데이터-텍스트 변환 태스크에서는 29.4% 향상된 성능을 보이며, 기존의 non-prompt 및 prompt 기반 최신 메트릭을 초월했습니다. 또한 AXCEL은 오픈 소스 LLM을 사용하더라도 강력한 성능을 보여줍니다.



### Informed deep hierarchical classification: a non-standard analysis inspired approach (https://arxiv.org/abs/2409.16956)
- **What's New**: 이번 연구는 다계층 분류 작업을 위한 새로운 접근 방식을 제안합니다. 이 방법은 다중 레이블로 구성되고 엄격한 부모-자식 구조로 조직된 데이터를 분류하는 문제에 초점을 맞추고 있습니다. 발표된 접근 방식은 lexicographic hybrid deep neural network (LH-DNN)라는 다중 출력 심층 신경망 구조를 포함합니다.

- **Technical Details**: 이 LH-DNN 아키텍처는 lexicographic multi-objective optimization(선형 다목적 최적화), non-standard analysis(비표준 해석학), deep learning(심층 학습) 등의 다양한 연구 분야의 도구를 결합하여 설계되었습니다. 이 접근법은 데이터 계층 구조와 일치하도록 학습 과정을 조정하는 방식으로, 학습 파라미터, 훈련 에폭 및 계산 시간을 대폭 줄이며 성능은 B-CNN과 유사하거나 우수할 수 있다는 것을 보여줍니다.

- **Performance Highlights**: LH-DNN은 CIFAR10, CIFAR100 및 Fashion-MNIST 벤치마크에서 B-CNN과 비교하여 학습 효율성이 높고 계층 관계를 학습하는 데 강력한 성능을 발휘합니다. 이 방식은 별도의 손실 함수 가중치 없이도 적용됩니다.



### Setting the AI Agenda -- Evidence from Sweden in the ChatGPT Era (https://arxiv.org/abs/2409.16946)
Comments:
          This paper is part of the Second AEQUITAS Workshop on Fairness and Bias in AI | co-located with ECAI 2024, October 19--24, 2024, Santiago de Compostela, Spain

- **What's New**: 이번 연구는 스웨덴에서 ChatGPT 출시 이전과 이후의 인공지능(AI) 메타 논의의 발전을 조사합니다. 연구자는 정치 엘리트가 상대적으로 침묵하고 AI 논의가 학계에서 주도되고 있다는 점을 강조합니다.

- **Technical Details**: 정량적 데이터셋을 기반으로 한 질적 내용 분석을 수행하여 스웨덴의 주요 신문에 실린 엘리트 의견 기사를 분석했습니다. 연구는 단기 리스크와 장기 리스크의 논의 경향을 분류하였으며, AI에 대한 논의가 점점 더 실질적이고 리스크 지향적으로 변화하고 있음을 보여줍니다.

- **Performance Highlights**: 2022년 이후 AI 관련 논의에서 단기 리스크에 대한 강조가 증가했음을 나타내며, 이는 스웨덴 내 정치 엘리트보다 학문적 엘리트가 AI 논쟁을 주도하고 있음을 시사합니다.



### Quantum-Classical Sentiment Analysis (https://arxiv.org/abs/2409.16928)
Comments:
          Submitted to BigHPC 2024 - this https URL

- **What's New**: 이번 연구에서는 감정 분석(Sentiment Analysis)을 위한 혼합 고전-양자 분류기(Hybrid Classical-Quantum Classifier, HCQC)의 적용을 조사하며, HCQC의 성능을 고전적 CPLEX 분류기 및 Transformer 아키텍처와 비교했습니다. HCQC는 Transformer에 비해 분류 정확도는 떨어지지만, 상대적으로 빠르게 근사해결에 도달할 수 있다는 점이 발견되었습니다. 또한 D-Wave의 비공개 특성으로 인한 HCQC의 아키텍처 상에서의 병목 현상도 밝혀졌습니다.

- **Technical Details**: 자연어 처리(Natural Language Processing)에서 높은 품질의 데이터를 확보하는 것과 모델의 훈련 시간이라는 두 가지 주요 도전이 있습니다. 우리는 비전통적인 컴퓨팅 아키텍처를 사용하여 훈련 시간을 단축시켜 더 표현력이 뛰어난 모델을 얻는 것에 초점을 맞추었습니다. 이를 위해 D-Wave의 아디아바틱 양자 컴퓨터(Adiabatic Quantum Computing, AQC) 아키텍처를 선택하였으며, 여기서는 QUBO(Quadratic Unconstrained Binary Optimization) 형태로 감정 분석을 수행합니다. 실험에서는 TweetEval 데이터셋을 사용했으며, 감정 클래스를 세 가지(positive, negative, neutral)로 나눈 후, neutral 클래스를 제외하고 positive와 negative의 균형 잡힌 데이터셋을 생성했습니다.

- **Performance Highlights**: RoBERTa는 94.3%의 높은 정확도로 분류 결과를 제공했으며, HCQC의 D-Wave 솔루션은 각각 76.1%의 정확도를 보였습니다. D-Wave의 최적 할당을 찾는 데 소요된 시간은 39.2초로, CPLEX의 101.9초보다 60% 적었습니다. 또한, RoBERTa는 예측을 위해 136.8초가 소요되어 CPLEX나 D-Wave보다 더 많은 시간이 요구되었습니다. 이 연구는 QPU의 활용도를 높이기 위해 새로운 하이브리드 솔버(웨이브 문제)를 개발하는 방법도 제안하고 있습니다.



### AI-assisted Gaze Detection for Proctoring Online Exams (https://arxiv.org/abs/2409.16923)
Comments:
          Accepted to HCOMP-24 Works-in-Progress and Demonstration track

- **What's New**: 이번 연구에서는 고위험 온라인 시험에서 시험 응시자가 화면에서 시선을 돌리는지를 감지하는 AI 보조 시스템을 제안하였습니다. 이 시스템은 감독관이 비디오 프레임 간 탐색을 통해 의심스러운 순간을 더 효과적으로 식별할 수 있도록 지원합니다.

- **Technical Details**: AI 보조 시선 감지 시스템은 시험 응시자의 각 프레임에서 예측된 시선 방향을 산포도로 표시합니다. 감독관은 시선 플롯에서 특정 영역을 선택하고, 관련된 비디오 타임스탬프를 강조 표시하여 비디오 프레임을 보다 효율적으로 탐색할 수 있습니다.

- **Performance Highlights**: 사용자 연구를 통해, 본 시스템은 기존의 인간 중심 프로토콜과 기계 학습 기반 프로토콜보다 더 효과적인 성능을 보였으며, 감독관이 보다 정교한 판단을 내릴 수 있도록 지원함을 입증하였습니다.



### Tell Me What You Don't Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing (https://arxiv.org/abs/2409.16913)
- **What's New**: 이 연구는 Role-Playing Agents(RPAs)의 역할 지식과 충돌하는 쿼리에 대한 응답 정확도를 향상시키기 위해 경량화된 표현 편집 방법을 소개합니다. 이를 통해 RPAs의 반려 능력을 강화하고 일반적인 역할 수행 능력을 유지할 수 있음을 보였습니다.

- **Technical Details**: 연구에서는 두 가지 주요 충돌 범주(역할 맥락 지식 충돌, 역할 파라메트릭 지식 충돌)로 쿼리를 분류하고 각각 중 4가지 특정 시나리오를 고려하여 RPA의 반려 능력을 평가하기 위한 평가 기준을 구축했습니다. 또한, 내부 표현의 rejection region과 direct response region을 분석하여 각 쿼리에 따른 반응 패턴을 규명하였습니다.

- **Performance Highlights**: 실험 결과, 최신 모델(GPT-4, Llama-3 등) 사이에서 다양한 충돌 시나리오에 따른 반려 능력의 유의미한 차이를 발견하였으며, 제안한 표현 편집 방법이 충돌 요청을 효과적으로 반려할 수 있도록 도와주었습니다. 이는 RPAs의 역할 수행 능력을 저하시키지 않으면서 반려 능력을 향상시키는 데 기여하였습니다.



### AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging (https://arxiv.org/abs/2409.16898)
- **What's New**: 이번 연구에서는 Intra-cardiac Echocardiography (ICE) 이미징을 위한 인공지능 기반의 폐쇄 루프(view guidance system)를 제안합니다. 이 시스템은 사용자에게 전문 지식 없이도 ICE 이미징을 지원하도록 설계되었습니다. 특히, 경험이 적은 사용자가 ICE 카테터를 효과적으로 조종할 수 있도록 돕습니다.

- **Technical Details**: 제안된 시스템은 임의의 뷰와 임상적으로 정의된 ICE 뷰 간의 상대적 위치 및 방향 벡터를 모델링합니다. 사용자에게 현재 뷰에서 원하는 뷰로의 전환을 안내하며, 이는 폐쇄 루프 구성에서 작동하여 ICE 카테터 상태를 예측하고 업데이트합니다. 시스템은 기존 임상 워크플로우를 방해하지 않고 통합될 수 있도록 설계되었습니다.

- **Performance Highlights**: 시뮬레이션 기반 평가에서 6532 테스트 데이터셋을 통해 89%의 성공률을 기록하였습니다. 이는 제안된 시스템이 ICE 이미징 절차의 정확성과 효율성을 향상시킬 수 있는 가능성을 강조합니다.



### Automating Traffic Model Enhancement with AI Research Agen (https://arxiv.org/abs/2409.16876)
Comments:
          19 pages, 10 figures

- **What's New**: 새로운 트래픽 모델 개발을 위해 TR-Agent라는 AI 기반 시스템을 도입했습니다. 이 시스템은 기존의 비효율적인 수작업 프로세스를 대체하고 연구 효율성을 높이기 위해 구조적이고 반복적인 파이프라인을 통해 자율적으로 트래픽 모델을 개발하고 개선할 수 있도록 설계되었습니다.

- **Technical Details**: TR-Agent는 아이디어 생성(Idea Generation), 이론 формuliering, 이론 평가, 반복 최적화(Iterative Optimization)라는 네 가지 주요 단계로 연구 파이프라인을 세분화하며, 각 단계에 맞는 네 가지 모듈(아이디어 생성기, 코드 생성기, 평가기, 분석기)을 활용합니다. 아이디어 생성기는 Retrieval-Augmented Generation (RAG) 기술을 통해 기존 모델의 결함을 식별하고 개선점을 제안합니다. 코드 생성기는 이러한 아이디어를 실행 가능한 파이썬 함수로 변환하고 반복적으로 디버깅합니다. 평가기는 새로 생성된 모델 함수를 평가하며, 분석기는 성능을 분석하고 추가 개선을 위한 피드백을 제공합니다.

- **Performance Highlights**: TR-Agent는 전통적인 모델 대비 25%, 75%, 90% 향상을 알고리즘별로 달성하였으며, IDM, MOBIL, LWR 모델에서 유의미한 성능 개선을 나타냈습니다. 연구자는 TR-Agent의 최적화 과정을 통해 상세한 분석 결과와 개선 사항을 확인할 수 있으며, 이를 통해 모델 개발을 보다 빠르고 효율적으로 할 수 있습니다.



### Ethical and Scalable Automation: A Governance and Compliance Framework for Business Applications (https://arxiv.org/abs/2409.16872)
- **What's New**: AI 적용의 대중화가 이루어짐에 따라 기업에서 윤리 (ethics), 거버넌스 (governance), 법적 준수 (legal compliance)와 관련된 주요 도전 과제가 발생하고 있습니다. 이 논문에서는 윤리적 (ethical), 제어 가능 (controllable), 실행 가능 (viable), 그리고 바람직한 (desirable) AI를 보장하기 위한 프레임워크를 소개합니다.

- **Technical Details**: 제안된 프레임워크는 성능 (performance)과 설명 가능성 (explainability) 간의 균형을 맞추어야 하며, 금융 (finance) 및 의료 (healthcare)와 같은 분야에서 규제 요구 사항을 충족할 수 있도록 실제적인 조언을 제공합니다. 대규모 언어 모델 (large language models) 사용 사례를 통해 환경 문제에 대한 태도를 모방하는 합성 의견 (synthetic opinions)을 생성하는 비용 효과적인 대안을 제시합니다.

- **Performance Highlights**: 프레임워크의 유효성을 다양한 사례 연구 (case studies)를 통해 검증하였으며, Chi-test 점수 (Chi-test scores), 정규화된 상호 정보 (normalized mutual information), 그리고 Jaccard 지수 (Jaccard indexes)와 같은 지표를 사용하여 합성 데이터와 기대 분포 간의 정렬 (alignment)을 정량화하였습니다. 향후 연구에서는 다양한 산업 환경에서 프레임워크의 경험적 검증 (empirical validation)을 추가로 탐색할 필요가 있습니다.



### Multi-objective Evolution of Heuristic Using Large Language Mod (https://arxiv.org/abs/2409.16867)
- **What's New**: 이 논문에서는 다목적 최적화(multi-objective optimization) 문제로서 휴리스틱(h heuristics) 검색을 모델링하는 새로운 접근 방식을 제안합니다. 기존 연구들은 최적 성능만을 목표로 했으나, 본 연구는 효율성과 확장성 등의 실용적인 기준도 고려합니다.

- **Technical Details**: 제안된 프레임워크는 다목적 진화 휴리스틱(Multi-objective Evolution of Heuristic, MEoH)으로, 대형 언어 모델(large language models, LLMs)을 활용하여 코드 비유사성(code dissimilarity) 및 목표 공간의 지배성(dominance)을 모두 고려한 새로운 지배-비유사성 메커니즘을 설계합니다.

- **Performance Highlights**: MEoH는 온라인 빈 포장 문제(online Bin Packing Problem, BPP)와 외판원 문제(Traveling Salesman Problem, TSP)에서 입증되었으며, 단일 실행으로 다양한 엘리트 휴리스틱(heuristics)을 자동 생성하여 기존 방법들보다 더 많은 트레이드오프 옵션을 제공합니다. 효율성이 최대 10배 향상되었으며, 다목적 검색은 휴리스틱 설계에 대한 새로운 통찰력을 제공하고 다양한 휴리스틱 발견으로 이어집니다.



### Dispute resolution in legal mediation with quantitative argumentation (https://arxiv.org/abs/2409.16854)
- **What's New**: 본 논문에서는 Mediation(중재)의 독특한 역학을 고려하여 QuAM(Quantitative Argumentation Mediate) 프레임워크를 도입하여 논의의 목표 수용성을 평가하는 새로운 방법론을 제안합니다.

- **Technical Details**: QuAM은 당사자들의 지식과 중재자의 법적 기준과 사실을 통합하여 중재 목표의 수용성을 결정하는 프레임워크입니다. 또한, 목표 인수의 수용 가능성과 관련 변수가 부여된 값 간의 관계를 모델링하는 새로운 형식을 개발합니다.

- **Performance Highlights**: QuAM 프레임워크는 법적 중재 과정 전반에 걸쳐 중재자를 지원하고, 각 당사자 간의 협략을 보다 효율적으로 관리할 수 있도록 합니다.



### Exposing Assumptions in AI Benchmarks through Cognitive Modelling (https://arxiv.org/abs/2409.16849)
Comments:
          11 pages, 2 figures

- **What's New**: 본 논문에서는 문화적 AI 벤치마크가 종종 측정된 구성 요소에 대한 암묵적인 가정에 의존하고 있다는 점을 지적하며, 이러한 가정들을 명시적인 인지 모델을 통해 드러내고자 합니다. 구조 방정식 모델(Structural Equation Models; SEM)을 활용하여, 누락된 데이터셋을 식별하고 연구 질문에 답할 수 있는 방법을 제시합니다.

- **Technical Details**: 세부적으로, 우리는 LLM(대형 언어 모델)의 ‘특성’에 관한 명시적 모델링을 통해 심리 측정(psychometrics)에서 영감을 받은 접근 방식을 확장하고 있습니다. 우리의 구조 방정식 모델은 언어 능력, 문화 지식, 정렬(alignment) 간의 관계를 분석합니다. 이 모델은 교차 언어 정렬 이전의 명확한 가정을 드러내어, 데이터셋 개발을 위한 방향을 제시합니다.

- **Performance Highlights**: 본 프레임워크는 기존의 벤치마크와 이론적 구성 간의 관계를 명확히 하며, 다양한 테스트가 잘 측정하는지를 평가할 수 있는 가능성을 열었습니다. 이는 LLM 특성에 대한 더 엄격하고 이론적으로 정당화된 이해를 위한 길을 제시하고, 결과적으로 생성적 AI 시스템의 포괄적이고 세밀한 평가를 촉진합니다.



### PeerArg: Argumentative Peer Review with LLMs (https://arxiv.org/abs/2409.16813)
- **What's New**: 이 논문은 PeerArg 시스템을 제안하여 LLM(대형 언어 모델)과 지식 표현 방법을 결합하여 동료 검토(peer review) 과정을 지원하고 이해할 수 있는 새로운 파이프라인을 소개합니다. PeerArg는 논문에 대한 리뷰 세트를 입력으로 받아 논문 수락 예측을 출력합니다.

- **Technical Details**: PeerArg는 컴퓨터 논증(computational argumentation) 방법을 사용하여 리뷰 이해를 향상시키고, 논문의 수락 결정 프로세스와 리뷰 간의 일치를 평가합니다. 여기서는 이진 논증 프레임워크(bipolar argumentation frameworks)를 활용하여 리뷰와 리뷰 집계 과정을 모델링합니다. 논문은 또한 몇 샷 학습(few-shot learning)을 사용하는 새로운 end-2-end LLM을 제안하여 주어진 리뷰로부터 논문 수락을 예측합니다.

- **Performance Highlights**: Ethical argumentation 통해 LLM을 강화하면 성능이 향상되며, PeerArg 파이프라인이 특정 하이퍼파라미터 조합을 사용할 경우, 모든 데이터 세트에서 LLM보다 더 우수한 성능을 발휘한다는 결과를 보여주었습니다.



### Large Language Model Predicts Above Normal All India Summer Monsoon Rainfall in 2024 (https://arxiv.org/abs/2409.16799)
Comments:
          3 figures

- **What's New**: 이번 연구에서는 AISMR(All India Summer Monsoon Rainfall)의 예측 정확도를 높이기 위해 최신 LLM 모델인 PatchTST를 조정하고 세부 조정을 했습니다.

- **Technical Details**: PatchTST 모델은 과거 AISMR 데이터, Niño3.4 지수 및 카테고리별 인도양 쌍극자(Indian Ocean Dipole) 값을 사용하여 훈련되었으며, 그 결과 여러 인기 있는 신경망 모델 및 통계 모델보다 더 높은 성능을 보여줍니다.

- **Performance Highlights**: Fine-tuned PatchTST 모델은 0.07%의 RMSE(Root Mean Square Error)와 0.976의 Spearman 상관관계를 기록하며, 이는 가장 성능이 좋은 신경망 모델보다 약 80% 더 높은 정확도를 나타냅니다. 이 모델은 2024년 몬순이 정상 이상으로 예상되며, 전체 국가에 대해 6월에서 9월까지 총 921.6mm의 강수량을 예측하고 있습니다.



### LLaMa-SciQ: An Educational Chatbot for Answering Science MCQ (https://arxiv.org/abs/2409.16779)
- **What's New**: LLaMa-SciQ라는 교육용 챗봇을 개발해 대학생들이 STEM 분야의 수학적 문제를 해결하고 이해하도록 돕고 있습니다.

- **Technical Details**: LLaMa-SciQ는 Mistral-7B 및 LLaMa-8B 모델을 비교하여 더 높은 평가 정확도를 보이는 LLaMa-8B 모델을 선택했습니다. 모델의 정확성을 높이기 위해 Retrieval-Augmented Generation (RAG) 방식을 도입하고, 양자화를 통해 모델을 압축하여 추론 시간을 단축했습니다.

- **Performance Highlights**: LLaMa-SciQ는 GSM8k 데이터셋에서 74.5%의 정확도를 달성하였고, MATH 데이터셋에서는 30%의 정확도를 보였습니다. 양자화된 모델은 성능이 5%만 낮아져 효율성을 크게 향상시켰습니다.



### Non-stationary BERT: Exploring Augmented IMU Data For Robust Human Activity Recognition (https://arxiv.org/abs/2409.16730)
- **What's New**: 이 연구에서는 OPPOHAR라는 새로운 인간 활동 인식(HAR) 데이터셋을 소개합니다. 이는 모바일 장치에서 수집된 IMU 데이터로 구성되어 있으며 사용자의 특정 활동 인식을 위해 최적화된 경량 네트워크인 Non-stationary BERT를 제안합니다. 또한 가속도계와 자이로스코프 데이터 간의 깊은 관계를 탐구하기 위한 간단하면서도 효과적인 데이터 증강(data augmentation) 방법을 도입합니다.

- **Technical Details**: 논문에서는 IMU 데이터의 자기 감시(self-supervised) 사전 훈련(pretraining)과 감독(classification) 단계를 포함한 Non-stationary BERT 네트워크 설계를 제안합니다. 이 네트워크는 가속도계와 자이로스코프 데이터의 상호 관계를 고려하여 새로운 시퀀스를 생성하고, 이를 기반으로 한 데이터 증강 방법을 도입하여 HAR 성능을 향상시킵니다. 또한, 사용자 개인의 데이터를 사용한 분산 배포 최적화된 경량 네트워크를 구현합니다.

- **Performance Highlights**: 제안된 Non-stationary BERT 네트워크는 다양한 활동 인식 데이터셋에서 최신 성능(state-of-the-art performance)을 달성하였으며, 데이터 증강 방법은 광범위한 적응 가능성을 보여줍니다. 이 연구는 사용자 개인의 데이터로 훈련된 분류기를 통해 프라이버시를 보장하면서도 사용자 맞춤형 활동 인식을 가능하게 합니다.



### A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcar (https://arxiv.org/abs/2409.16721)
- **What's New**: 이 연구에서는 심장병, 간경화 및 망막 질환을 분류하기 위해 Residual Networks와 Artificial Neural Networks를 결합한 새로운 딥러닝 예측 분석 프레임워크를 제안합니다.

- **Technical Details**: 데이터는 세 가지 서로 다른 출처에서 전처리되며, 카테고리 데이터 변환, 차원 축소, 결측 데이터 합성을 포함하여 준비됩니다. 이미지 데이터셋에 대해서는 ResNet 아키텍처를 사용하여 특징 추출을 수행하고, 카테고리 데이터셋에는 스케일러 변환을 사용합니다.

- **Performance Highlights**: 망막 촬영 이미지, 간경화 단계, 심장병 진단 예측에 대한 정확도는 각각 93%, 99%, 95%로 높은 성능을 기록하였으며, F1-score, precision, recall 등의 상세한 분석을 통해 제안된 방법의 효과성을 입증하였습니다.



### A Survey of Low-bit Large Language Models: Basics, Systems, and Algorithms (https://arxiv.org/abs/2409.16694)
Comments:
          Ruihao Gong leads the overall organization of the survey, with Yifu Ding and Jinyang Du contributing to Sections 2 and 3. Xingyu Zheng is responsible for authoring Section 4, while Chengtao Lv and Zining Wang collaborate on Section 5. Haotong Qin, Jinyang Guo, Michele Magno, and Xianglong Liu provide guidance during the whole process and assist in refining the final manuscript

- **What's New**: 이 논문에서는 대형 언어 모델(LLMs)을 위한 저비트 양자화(low-bit quantization) 방법에 대한 종합적인 조사를 제공합니다. 이는 메모리 사용량과 계산 요구 사항을 줄여주어 LLM의 실제 구현에서 중요한 과제를 해결하는 데 기여합니다.

- **Technical Details**: 저비트 양자화는 모델의 파라미터, 활성화(activations), 그리고 그래디언트의 비트 폭을 줄이는 프로세스로, 메모리 사용량과 계산 요구를 감소시킵니다. 이 논문에서는 저비트 LLM의 기초 원리, 시스템 구현, 알고리즘 전략을 다루고 있습니다. 새로운 저비트 데이터 형식과 양자화 세분화(granularity), 정적 또는 동적 양자화의 차이점 등이 소개됩니다.

- **Performance Highlights**: 저비트 양자화는 LLM의 훈련(training) 및 추론(inference)을 가속화하며, 정확도를 유지하면서도 모델을 저장하는 데 필요한 자원을 줄이는 데 효과적입니다. 이 연구에서는 새로운 연구 분야, 잠재적인 혁신, 그리고 새로운 기술이 LLM 양자화에 미치는 영향을 논의하며, LLM의 효율성 및 적합성을 향상시키기 위한 가치 있는 통찰력을 제공합니다.



### CaBRNet, an open-source library for developing and evaluating Case-Based Reasoning Models (https://arxiv.org/abs/2409.16693)
- **What's New**: 이 논문에서는 self-explainable (자기 설명 가능한) 모델을 설계하기 위한 새로운 접근법으로 CaBRNet을 제안합니다. 이는 기존의 post-hoc (사후 분석) 방법의 한계를 극복하는 것을 목표로 합니다.

- **Technical Details**: CaBRNet은 Case-Based Reasoning Networks (사례 기반 추론 네트워크)를 위한 오픈 소스, 모듈형, 역 호환 가능한 프레임워크입니다. 이 논문은 이 프레임워크의 설계와 구현에 대한 상세한 설명을 제공합니다.

- **Performance Highlights**: CaBRNet은 높은 재현성(reproducibility) 및 비교 가능성을 보장하며, 다양한 기준(standards)에서 일관된 성능을 발휘합니다.



### MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making (https://arxiv.org/abs/2409.16686)
- **What's New**: 이번 논문에서는 Multi-Scale Insight Agent (MSI-Agent)를 소개합니다. 이 에이전트는 장기 기억(Long-term memory)을 개선하여 LLMs의 계획 및 의사결정 능력을 높이기 위해 다양한 스케일에서 통찰(insight)을 효과적으로 요약하고 활용하는 방식으로 설계되었습니다.

- **Technical Details**: MSI-Agent는 경험 선택기(experience selector), 통찰 생성기(insight generator), 통찰 선택기(insight selector)의 세 가지 주요 구성 요소를 통해 작동합니다. 이 세 부분으로 이루어진 파이프라인(pipeline)을 활용하여, MSI는 작업에 특화된(task-specific) 고수준의 통찰을 생성하고 이를 데이터베이스에 저장한 후, 의사결정을 위해 관련 통찰을 활용할 수 있습니다.

- **Performance Highlights**: 실험 결과, MSI는 GPT3.5에 기반한 다른 통찰 전략보다 우수한 성능을 보였습니다. 또한, 씨앗 경험(seed experience)과 통찰을 선택하는 전략을 탐구하며, LLM에 더 유용하고 관련성 있는 통찰을 제공하여 더 나은 의사결정을 지원하는 데 초점을 맞추고 있습니다. MSI는 도메인 전환(domain-shifting) 시나리오에서 더 나은 강건성을 보여주는 것으로 관찰되고 있습니다.



### Judgment of Thoughts: Courtroom of the Binary Logical Reasoning in Large Language Models (https://arxiv.org/abs/2409.16635)
- **What's New**: 이 논문은 이진 논리 추론 작업에 특화된 새로운 프롬프트 엔지니어링 기법인 Judgement of Thought (JoT)를 제안합니다. JoT는 변호사, 검사, 판사 세 가지 역할을 통해 모델의 추론을 보다 신뢰할 수 있고 정확하게 수행할 수 있도록 돕습니다.

- **Technical Details**: JoT 프레임워크는 고급 모델을 판사에게 할당하고, 저급 모델을 변호사와 검사에게 사용합니다. 이를 통해 판사는 변호사와 검사로부터의 응답을 보다 잘 이해하고, 정확한 판단을 내릴 수 있습니다. JoT는 BigBenchHard와 Winogrande와 같은 LLM 벤치마크 데이터셋에서 기존 방법론인 Chain of Thought (CoT) 및 Self-Consistency (SC)를 초과하는 성능을 보였습니다.

- **Performance Highlights**: JoT는 이진 논리 추론 작업에서 모델의 정확성과 신뢰성을 크게 향상시켰으며, Fake News Detection 및 SMS Spam Detection과 같은 실제 문제에서도 기존 기술에 비해 유사하거나 개선된 성능을 보여주었습니다. 이는 JoT가 여러 분야에서 실질적인 적용 가능성을 지닌다는 것을 시사합니다.



### On Your Mark, Get Set, Predict! Modeling Continuous-Time Dynamics of Cascades for Information Popularity Prediction (https://arxiv.org/abs/2409.16623)
- **What's New**: 이번 연구에서는 정보의 인기 예측을 위한 새로운 모델인 ConCat을 제안합니다. 이 모델은 지속적인 시간 다이나믹스를 조건부 강도 함수와 결합하여 정보의 확산 과정을 보다 정확하게 모델링할 수 있도록 설계되었습니다.

- **Technical Details**: ConCat은 신경 Ordinary Differential Equations (ODEs)를 활용하여 비정상적인 정보의 확산 이벤트를 지속적인 시간 내에서 모델링합니다. 또한, 신경 Temporal Point Processes (TPPs)를 사용하여 정보 집합의 글로벌 트렌드를 정밀하게 포착하고, 이를 통해 예측 성능을 향상시킵니다. 이 모델은 그래프 구조와 순차적 이벤트 정보를 기반으로 작동합니다.

- **Performance Highlights**: ConCat은 세 가지 실제 데이터 세트에서 평가한 결과, 기존의 최첨단 모델에 비해 2.3%에서 33.2%까지 성능 향상을 나타냈습니다. 이는 정보의 인기 예측 태스크에 있어 뛰어난 효율성을 입증합니다.



### Entailment-Driven Privacy Policy Classification with LLMs (https://arxiv.org/abs/2409.16621)
Comments:
          8 pages, 4 figures, 3 tables

- **What's New**: 이 논문에서는 개인 정보 보호 정책의 내용을 이해하기 쉽게 분류하기 위한 기존의 방법들과는 다른 접근방식인, "entailment-driven LLM" 기반의 프레임워크를 제안합니다. 최근의 Large Language Models (LLMs) 기술 발전을 활용해, 복잡한 개인정보 보호 정책을 사용자가 이해할 수 있도록 명확하게 분류하는 방법을 제시하였으며, 평균 11.2% 향상된 F1 점수를 기록했습니다.

- **Technical Details**: 제안된 프레임워크는 개인정보 보호 정책의 단락을 12개의 카테고리(예: 첫 번째 당사자 데이터 수집/사용, 제3자 공유/수집 등)로 분류합니다. 이 과정에서, explain classifier가 분류의 이유를 생성하고, blank filler가 그 이유를 재구성하며, entailment verifier가 최종 결정을 내리는 방식으로 진행됩니다. 이러한 과정은 사람의 사고 과정을 모방하여 더 신뢰할 수 있는 출력을 제공합니다.

- **Performance Highlights**: OPP-115 데이터셋을 사용하여 실험을 수행한 결과, 제안된 방법은 기존의 LLM 방법들보다 평균 8.6%, 14.5%, 10.5% 높은 F1 점수를 기록했습니다. 또한, 예측 결과의 57.9%는 법률 전문가가 도출한 추론과 최소 50% 이상 겹치는 것으로 나타났습니다.



### Optimized Monte Carlo Tree Search for Enhanced Decision Making in the FrozenLake Environmen (https://arxiv.org/abs/2409.16620)
- **What's New**: 이 논문은 Monte Carlo Tree Search (MCTS) 알고리즘을 FrozenLake 환경에 최적화하여 적용한 새로운 구현을 제안합니다. 이 최적화는 누적 보상과 방문 수 테이블을 통합하여 효율적인 학습을 가능하게 하고, 이를 통해 기존의 방법보다 더 빠른 수렴을 달성합니다.

- **Technical Details**: 최적화된 MCTS 알고리즘은 누적 보상(Q)과 방문 수(N) 테이블, 그리고 Upper Confidence Bound for Trees (UCT) 공식을 활용하여 결정-making을 개선합니다. 이 알고리즘은 반복적인 시뮬레이션을 통해 가능 상태-행동 궤적을 대표하는 검색 트리를 구축하며, UCT 공식은 탐색과 활용의 균형을 맞추는 데 중앙적 역할을 합니다.

- **Performance Highlights**: 최적화된 MCTS는 평균 보상 0.8 및 70%의 성공률을 기록했으며, 약 10,000 에피소드 후 안정화되었습니다. 다른 알고리즘 대비 성능이 우수하여, MCTS with Policy는 평균 보상 0.4와 성공률 35%에 그쳤고, Q-Learning은 평균 보상 0.8과 성공률 60%를 기록했습니다.



### CasFT: Future Trend Modeling for Information Popularity Prediction with Dynamic Cues-Driven Diffusion Models (https://arxiv.org/abs/2409.16619)
- **What's New**: 이번 논문에서는 정보의 확산 과정에서 관찰된 패턴을 기반으로 미래의 인기 트렌드를 예측하는 새로운 접근법인 CasFT를 제안합니다. 특히, 기존의 방법들이 미래의 인기 변화를 간과하는 문제를 해결하고자 하였습니다.

- **Technical Details**: CasFT는 정보 확산(cascade) 및 신경 ODEs(neural Ordinary Differential Equations)를 활용하여 미래의 인기 상승 트렌드를 생성합니다. 이 모델은 관찰된 성장률을 기반으로 하여, 예측 시점까지의 성장률을 전파하고, 누적 인기를 계산하는 데 중점을 두었습니다.

- **Performance Highlights**: CasFT는 실제 데이터 세트에 대한 실험을 통해 기존의 최첨단 방법들보다 2.2%에서 19.3% 까지 예측 정확도가 향상되었음을 입증하였습니다.



### Enhancing disease detection in radiology reports through fine-tuning lightweight LLM on weak labels (https://arxiv.org/abs/2409.16563)
- **What's New**: 이번 연구에서는 Llama 3.1-8B와 같은 경량 LLM을 합성 레이블(synthetic labels)을 사용한 파인튜닝(fine-tuning)을 통해 개선할 수 있는 가능성을 조사했습니다. 두 개의 작업을 결합하여 각각의 지침(instruction) 데이터셋을 혼합하여 공동 훈련하였습니다. 이 접근법은 의료 분야에서 LLM의 특화 가능성을 보여줍니다.

- **Technical Details**: 연구에서는 두 가지 라디오 로지(tasks)에 대해 경량 LLM을 파인튜닝 했습니다. 첫 번째 작업은 여러 선택지 속에서 폐 질환을 분류하는 것이고, 두 번째 작업은 라디오 로지 보고서에서 비정상 발견을 추출하는 것입니다. 고품질 합성 레이블(GPT-4o에 의해 생성된)을 사용할 경우 Llama 3.1-8B는 질병 탐지 작업에서 micro F1 점수 0.91을 달성했습니다.

- **Performance Highlights**: 경량 LLM인 Llama 3.1-8B는 저품질의 합성 레이블(예: MIMIC-CXR에서)이 사용되었을 때도 지정된 라벨과 비교하여 과속성 샘플의 정확성을 초과했습니다(micro F1 점수: 0.67 vs 0.63). 이는 모델의 강력한 기본 능력을 보여주는 것입니다.



### Dynamic-Width Speculative Beam Decoding for Efficient LLM Inferenc (https://arxiv.org/abs/2409.16560)
- **What's New**: 이 논문은 대규모 언어 모델(LLMs)의 추론 과정을 가속화하는 새로운 접근 방식인 dynamic-width speculative beam decoding (DSBD)를 제안합니다. DSBD는 추측 디코딩과 빔 샘플링을 통합하여 속도와 품질을 향상시키고자 합니다.

- **Technical Details**: DSBD는 작은 보조 모델을 활용해 초안 토큰을 생성하고, 그 토큰을 기반으로 대규모 모델에서 여러 후보 시퀀스를 동시에 생성하는 새로운 검증 체계를 도입합니다. 또한, 적응형 메커니즘을 통해 컨텍스트에 따라 빔 수를 동적으로 조정하고, 여러 개의 트리를 동시에 처리하는 나무 기반 병렬 검증 기술을 확장합니다.

- **Performance Highlights**: 실험 결과 DSBD는 빔 샘플링에 비해 1.5-1.9배의 속도 향상과 1.8-2.5배의 에너지 소비 감소를 달성했으며, 다운스트림 작업에서 성능 저하 없이도 한결 우수한 출력 품질을 보여주었습니다.



### Context-aware and Style-related Incremental Decoding framework for Discourse-Level Literary Translation (https://arxiv.org/abs/2409.16539)
Comments:
          7 pages, 2 figures, wmt24

- **What's New**: 이번 보고서에서는 WMT24 담론 수준의 문학 번역 과제를 위한 우리의 접근 방식을 제시하며, 중국어-영어 언어 쌍에 중점을 둡니다. 문학 텍스트의 번역은 복잡한 의미, 관용구 및 이야기 구조로 인해 도전 과제가 많습니다. 이를 해결하기 위해 Chinese-Llama2 모델을 활용하였고, Continual Pre-training (CPT) 및 Supervised Fine-Tuning (SFT)을 결합하여 이 과제를 위한 특별한 개선을 이루었습니다.

- **Technical Details**: 우리는 TP3(Three-Stages Translation Pipeline) 훈련 패러다임을 소개하며,<br>- Stage 1: 풍부한 단일 언어 데이터를 활용한 Continual Pre-training.<br>- Stage 2: 문장을 정렬한 이중 언어 문서의 Interlinear Text Format을 사용한 Continual Pre-training.<br>- Stage 3: Semantic coherence 및 stylistic consistency 향상을 위한 Supervised Fine-Tuning을 진행합니다.

- **Performance Highlights**: 실험 결과, 문장 수준 및 문서 수준의 BLEU 점수에서 유의미한 개선이 있었으며, 이로 인해 제안된 프레임워크가 문서 수준의 문학 번역의 복잡성을 해결하는 데 효과적임을 보였습니다.



### Graph Pruning Based Spatial and Temporal Graph Convolutional Network with Transfer Learning for Traffic Prediction (https://arxiv.org/abs/2409.16532)
Comments:
          14 pages, accepted by ICIAAI2023, withdrawn from proceedings

- **What's New**: 이번 연구에서는 도시화 및 인구 급증으로 인한 교통 혼잡 문제를 보다 효과적으로 해결하기 위해 새로운 Spatial-temporal Convolutional Network(TL-GPSTGN)를 제안했습니다. 이 모델은 그래프 가지치기(graph pruning) 및 전이 학습(transfer learning) 프레임워크를 기반으로 합니다.

- **Technical Details**: TL-GPSTGN은 도로 네트워크 구조와 특성 데이터의 상관관계 및 정보 엔트로피 분석을 통해 필수적인 그래프 구조와 정보를 추출합니다. 그래프 가지치기 기술을 활용하여 그래프의 인접 행렬(adjacency matrix)과 입력 특성 데이터를 처리하여 모델의 이동 성능(migration performance)을 크게 개선합니다. 그 후, 잘 특성화된 데이터를 공간-시간 그래프 컨볼루션 네트워크(spatial-temporal graph convolutional network)에 입력하여 공간적 및 시간적 관계를 포착하고 도로 상태 예측을 수행합니다.

- **Performance Highlights**: TL-GPSTGN은 실제 데이터셋에서 종합적인 테스트 및 검증을 수행하였으며, 동일한 조건 하에서 다른 일반적으로 사용되는 모델들과의 예측 성능을 비교하였습니다. 결과적으로, TL-GPSTGN은 단일 데이터셋에서 뛰어난 예측 정확도를 보였으며, 다양한 데이터셋 간의 견고한 이동 성능을 입증하였습니다.



### SynChart: Synthesizing Charts from Language Models (https://arxiv.org/abs/2409.16517)
- **What's New**: GPT-4V(O) 모델을 기반으로 한 데이터 생성 방법을 탐색하며, 다중 모달리티(multi-modality) 모델을 위한 대규모 차트 데이터셋 SynChart를 구축하였습니다. 이 데이터셋은 약 400만 개의 다양한 차트 이미지와 7500만 개 이상의 밀집 주석을 포함하고 있습니다.

- **Technical Details**: SynChart 데이터셋은 데이터 테이블, 코드, 설명, 질문-답변 세트를 포함하여 차트 이미지를 위한 고품질 주석을 제공합니다. 우리는 LLM을 활용하여 차트 시각화를 위한 코드 생성 및 차트 데이터의 다양성을 확보하였으며, 그래픽 엔진으로 Matplotlib, Seaborn, Plotly 및 Bokeh를 사용했습니다.

- **Performance Highlights**: 훈련된 4.2B 차트 전문가 모델은 ChartQA 작업에서 GPT-4O 성능에 근접하며 GPT-4V를 초과하는 성과를 기록했습니다.



### Unsupervised Text Representation Learning via Instruction-Tuning for Zero-Shot Dense Retrieva (https://arxiv.org/abs/2409.16497)
Comments:
          Accepted at DCAI24 workshop@CIKM2024

- **What's New**: 본 연구에서는 라오-블랙웰 정리를 기반으로 한 새로운 비지도 학습 방식의 텍스트 표현 학습 기법을 제안합니다. 이 방법은 사전훈련된 인코더-디코더 대형 언어 모델(LLM)을 활용하여 쿼리와 코퍼스를 효과적으로 표현할 수 있습니다.

- **Technical Details**: 연구에서는 두 단계의 자기 지시 조정(self-instructed-tuning)을 통해 비지도 방식으로 코퍼스 표현을 학습합니다. 첫 번째 단계에서는 미리 정의된 지침에 따라 질문 생성과 키워드 요약 작업을 수행해 합성적인 쿼리를 생성하고, 두 번째 단계에서는 품질 필터를 적용하여 생성된 쿼리의 성능을 향상시킵니다. 이러한 과정은 Rao-Blackwell 정리에 의해 코퍼스의 임베딩을 개선하는 데 기여합니다.

- **Performance Highlights**: 제안한 방법은 NDCG@10, MRR@100, Recall@100 등의 지표에서 세 개의 영어 데이터 세트와 한 개의 독일어 데이터 세트를 이용하여 평가되었습니다. 최종적으로 기존의 세 가지 경쟁 모델보다 성능이 개선되었으며, FLAN-T5 모델 변형을 기반으로 하여 평균적으로 성능을 약 3.34%에서 3.50% 향상시켰습니다.



### Artificial Intelligence for Secured Information Systems in Smart Cities: Collaborative IoT Computing with Deep Reinforcement Learning and Blockchain (https://arxiv.org/abs/2409.16444)
- **What's New**: 이 논문은 사물인터넷(IoT)과 블록체인(Blockchain) 기술을 통합하여 스마트 시티에서의 모바일 전송을 최적화하고 안전한 데이터 교환을 실현하는 방법에 대해 investigates(조사)합니다. 특히, 심층 강화 학습(Deep Reinforcement Learning, DRL)을 IoT 환경에 접목하여 높은 적응성 및 결정 능력을 제공합니다.

- **Technical Details**: 블록체인의 불변성(Immutable), 확장성(Scalable), 분산화(Decentralized) 솔루션이 IoT의 프라이버시(Privacy), 보안(Security), 데이터 무결성(Data Integrity) 문제를 해결하는 데 어떻게 기여하는지를 고찰합니다. 이 논문은 2015년부터 2024년까지 발표된 연구들을 기반으로 다양한 접근 방식을 분류하고 실용적인 분류 체계(Taxonomies)를 제공합니다.

- **Performance Highlights**: DRL과 블록체인의 조합은 IoT 네트워크의 성능을 향상시키며, 프라이버시와 보안을 유지합니다. 본 연구는 블록체인의 분산 프레임워크와 DRL의 결합이 모바일 전송 효율성을 향상시키고 Robust하며 프라이버시 보호가 가능한 IoT 시스템을 보장할 수 있음을 보여줍니다.



### HAICOSYSTEM: An Ecosystem for Sandboxing Safety Risks in Human-AI Interactions (https://arxiv.org/abs/2409.16427)
Comments:
          Both the second and third authors contributed equally

- **What's New**: HAICOSYSTEM은 다양한 사회적 상호작용 내에서 AI 에이전트의 안전성을 평가하기 위해 다차원적 평가 프레임워크를 제공합니다. 이는 모듈식 샌드박스 환경을 통해 멀티 턴 상호작용을 시뮬레이션하고, AI 에이전트가 다양한 도구를 사용하여 복잡한 시나리오를 탐색할 수 있도록 합니다.

- **Technical Details**: HAICOSYSTEM은 92개의 시나리오를 바탕으로 1840회의 시뮬레이션을 실행하여, AI 에이전트와 인간 사용자 간의 상호작용을 실재감 있게 모사합니다. 평가 프레임워크 HAICOSYSTEM-EVAL은 안전성과 성능을 동시에 측정하며, 법적 위험과 같은 다양한 안전 위험 차원도 포함됩니다.

- **Performance Highlights**: 상태-of-the-art LLM들이 50% 이상의 경우 안전 위험을 보이는 것으로 나타났으며, 특히 악의적인 사용자와의 상호작용에서 위험이 증가합니다. HAICOSYSTEM은 향후 연구 및 AI 에이전트의 안전 생태계 구축에 기반을 제공합니다.



### Design and Evaluation of a CDSS for Drug Allergy Management Using LLMs and Pharmaceutical Data Integration (https://arxiv.org/abs/2409.16395)
- **What's New**: HELIOT라는 혁신적인 임상 의사결정 지원 시스템(CDSS)이 소개되었으며, 이는 약물 알레르기 관리에 초점을 맞추고 있습니다.

- **Technical Details**: HELIOT는 Large Language Models (LLMs)와 포괄적인 제약 데이터 저장소를 통합하여 고급 자연어 처리(Natural Language Processing, NLP) 기능을 활용합니다. 이를 통해 복잡한 의료 텍스트를 해석하고 비정형 데이터를 종합할 수 있습니다.

- **Performance Highlights**: HELIOT는 합성 환자 데이터 세트와 전문가 확인된 기초 진실을 사용한 실증 평가에서 높은 정확도(accuracy), 정밀도(precision), 재현율(recall), F1 점수를 보여주었으며, 여러 실험에서 100	ext{%}에 도달하는 결과를 보였습니다.



### Rao-Blackwellized POMDP Planning (https://arxiv.org/abs/2409.16392)
- **What's New**: 본 연구는 Rao-Blackwellized POMDP (RB-POMDP) 근사 해법을 도입하고, 신념 업데이트(belief updates) 및 온라인 계획(online planning)에서 Rao-Blackwellization을 적용하기 위한 일반적인 방법들을 제시합니다.

- **Technical Details**: Partially Observable Markov Decision Processes (POMDPs)는 불확실성 하에서 의사 결정을 위한 구조화된 프레임워크를 제공합니다. Sequential Importance Resampling Particle Filters (SIRPF)는 대규모 근사 POMDP 풀링기에서 신념 업데이트에 흔히 사용되지만, 시스템의 상태 차원이 증가함에 따라 입자 부족(particle deprivation) 및 높은 계산 비용(computational costs) 등의 문제에 직면합니다.

- **Performance Highlights**: 시뮬레이션된 로컬라이제이션 문제에서 SIRPF와 Rao-Blackwellized Particle Filters (RBPF)의 성능을 비교한 결과, RBPF가 적은 수의 입자로 시간이 지남에 따라 정확한 신념 근사를 유지하며, 더욱 놀라운 점은 RBPF가 사각형 기반 통합(quadrature-based integration)과 결합될 경우 SIRPF 기반 계획보다 질적으로 planning 품질이 크게 향상된다는 것을 확인했습니다.



### Beyond Text-to-Text: An Overview of Multimodal and Generative Artificial Intelligence for Education Using Topic Modeling (https://arxiv.org/abs/2409.16376)
- **What's New**: 이 연구에서는 교육 분야에서의 생성형 인공지능(Generative AI)과 다중모달(multimodal) 접근법 연구의 현황을 분석하였습니다. 기존 연구는 주로 텍스트-텍스트 모델에 중점을 두고 있어 다중모달 기술의 잠재력을 간과하고 있다는 점을 지적합니다.

- **Technical Details**: 4175개의 논문에 대한 주제 모델링(topic modeling)을 사용하였으며, 38개의 해석 가능한 주제를 14개의 테마 영역으로 구성하였습니다. 이 과정에서 BERTopic 접근방식을 적용해 문서의 잠재적 주제를 추출하였습니다.

- **Performance Highlights**: 결과적으로, 다중모달 접근법과 생성형 AI가 교육에 어떤 일관된 연구 방향성을 제공하는지를 보여주며, 다채로운 인공지능 기술이 교육 분야에서 어떻게 활용될 수 있는지를 탐구할 수 있는 기회를 제시합니다.



### WeatherFormer: Empowering Global Numerical Weather Forecasting with Space-Time Transformer (https://arxiv.org/abs/2409.16321)
- **What's New**: WeatherFormer라는 새로운 transformer 기반의 수치 기상 예측(NWP) 프레임워크를 제안하여 데이터 기반 NWP의 성능 격차를 줄이는데 기여하고 있습니다.

- **Technical Details**: WeatherFormer는 공간-시간 요인 분해 transformer 블록을 사용하여 파라미터 및 메모리 소비를 줄이고, 위치 인식 적응형 푸리에 신경 연산자(PAFNO)를 도입하여 위치에 민감한 토큰 혼합을 수행합니다. 또한 두 가지 데이터 증강 전략을 통해 성능을 향상시키고 훈련 소비를 저감합니다.

- **Performance Highlights**: WeatherBench 데이터셋에서의 광범위한 실험 결과, WeatherFormer는 기존 깊은 학습 방법들보다 뛰어난 성능을 발휘하였으며, 최신 물리 모델과 더욱 근접한 성능을 서술하고 있습니다.



### Differential Privacy Regularization: Protecting Training Data Through Loss Function Regularization (https://arxiv.org/abs/2409.17144)
- **What's New**: 본 논문에서는 Neural Network 기반의 머신러닝 모델이 민감한 정보를 노출하지 않도록 하기 위해 기존의 DP-SGD(Differentially Private Stochastic Gradient Descent) 알고리즘의 효율성을 개선한 새로운 정규화 전략인 PDP-SGD를 제안하였다.

- **Technical Details**: 본 연구는 PDP-SGD라는 새로운 접근 방식을 통해 손실 함수의 정규화로 차별적 프라이버시(Differential Privacy)를 구현할 수 있음을 보여준다. PDP-SGD는 네트워크 파라미터와 입력값에 직접적으로 의존하는 정규화 항을 포함하여 기울기 누출(Gradient Leakage) 공격에 대한 방어를 구현한다.

- **Performance Highlights**: PDP-SGD는 Gaussian noise의 명시적 도입 없이도 효율적으로 동작하며, 기존 DP-SGD가 직면했던 정확도 저하 문제를 완화하는 가능성을 제시한다. 또한 이 방식은 컴퓨팅 비용을 줄이는 데에도 기여할 수 있다.



### Attention Prompting on Image for Large Vision-Language Models (https://arxiv.org/abs/2409.17143)
Comments:
          Website, see this https URL

- **What's New**: 본 연구에서는 Attention Prompting on Image (𝒜⁢𝒫⁢ℐ𝒜𝒫ℐ)라는 새로운 프롬프트 기법을 제안하여, 원본 이미지 위에 텍스트 쿼리 기반 주의 열지도를 오버레이함으로써 LVLM의 성능을 향상시킵니다.

- **Technical Details**: 이 기법은 보조 LVLM 모델을 활용하여 입력 이미지에 대한 주의 열지도를 생성합니다. 이때 CLIP과 같은 이미지-텍스트 매칭 모델의 cls 토큰 유사도 점수를 기반으로 하여 열지도를 만들어 냅니다. 생성된 열지도는 원본 이미지의 픽셀 값에 단순히 곱해져 LVLM의 실제 입력 이미지가 됩니다.

- **Performance Highlights**: Attention Prompting on Image는 LLaVA-1.5 모델의 MM-Vet, LLaVA-Wild 벤치마크에서 각각 3.8% 및 2.9%의 성능 향상을 보여줍니다.



### FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression (https://arxiv.org/abs/2409.17141)
- **What's New**: FineZip는 전통적 텍스트 압축 방법에 비해 54배 빠른 압축 시간을 달성함으로써 대규모 텍스트 압축에 대한 사용 가능성을 높입니다.

- **Technical Details**: FineZip는 '온라인' 및 '오프라인' 구성 요소를 결합하여 손실 없는 텍스트 압축을 수행하며, 파라미터 효율적 미세 조정(PEFT) 방식을 사용하여 압축하는 데이터를 Memorize(기억)합니다. 또한, 동적 컨텍스트 사이즈를 활용하여 각 토큰의 압축을 개선하고 병렬 처리 가능성을 높였습니다.

- **Performance Highlights**: FineZip는 기존의 LLMZip보다 약 54배 빠른 압축 성능을 보여주며, 압축 비율을 약 50% 향상시킵니다. 전통적인 알고리즘 기반 압축 방법에 비해 크게 개선된 압축 효율성을 자랑합니다.



### Blox-Net: Generative Design-for-Robot-Assembly Using VLM Supervision, Physics Simulation, and a Robot with Res (https://arxiv.org/abs/2409.17126)
Comments:
          8 pages, 7 Figures

- **What's New**: 이번 논문에서는 Generative Design-for-Robot-Assembly (GDfRA)라는 새로운 문제를 제안합니다. 이 과정은 자연어 프롬프트(예: '기린')와 3D 프린팅한 블록과 같은 물리적 부품의 이미지를 기반으로 조립을 생성하는 것입니다. 이를 통해 로봇이 조립을 보다 효과적으로 수행할 수 있도록 설계되었습니다.

- **Technical Details**: Blox-Net은 VLM(vision language model)과 시뮬레이션, 물리적 로봇 실험을 결합하여 GDfRA 문제를 해결하는 시스템입니다. 3단계로 구성되어 있으며, 각 단계에서 3D 부품의 적절한 배열을 디자인하고, 이를 물리적 로봇이 구축할 수 있도록 검증합니다. 이 시스템은 인간의 개입 없이도 작동할 수 있도록 설계되었습니다.

- **Performance Highlights**: Blox-Net은 조립물의 '인지성'에서 63.5%의 Top-1 정확도를 기록했습니다. 자동화된 재설계를 거친 후, 로봇은 10회 연속 조립에서 거의 완벽한 성공률을 보였습니다. 특히, 99.2%의 정확도로 블록을 자율적으로 배치하는 데 성공했습니다.



### Programming Every Example: Lifting Pre-training Data Quality like Experts at Sca (https://arxiv.org/abs/2409.17115)
Comments:
          45 pages, 13 figures, 34 tables

- **What's New**: 이번 연구에서는 사전 훈련된 대형 언어 모델에 대해 새로운 접근법인 ProX(Programming Every Example)를 제안합니다. 이는 데이터 정제를 프로그래밍 작업으로 간주하여, 각 개별 예제에 대해 정교한 작업을 생성하고 실행할 수 있게 합니다.

- **Technical Details**: ProX는 모델이 각각의 데이터 예제를 정제하기 위해 필요한 작업을 프로그래밍 방식으로 정의할 수 있도록 하여, 기존의 왜곡된 데이터를 정제하는 데 필요한 유연성을 제공합니다. 이는 문자열 정규화, 데이터 세분화 등의 작업을 포함하여, 0.3B 파라미터를 가진 소형 모델도 인간 전문가와 비슷한 정제 능력을 발휘할 수 있음을 보여줍니다.

- **Performance Highlights**: ProX로 정제된 데이터로 사전 훈련된 모델은 원래 데이터나 다른 필터링 기법으로 정제된 데이터에 비해 다양한 하위 벤치마크에서 2% 이상의 성능 향상을 보였습니다. 특히, OpenWebMath 데이터 세트에서 ProX로 정제된 모델은 Mistral-7B에 비해 평균 정확도가 7.6% 개선되었고, Llama-2-7B에서는 14.6%, CodeLlama-7B에서는 20.3% 향상되었습니다.



### Unveiling Ontological Commitment in Multi-Modal Foundation Models (https://arxiv.org/abs/2409.17109)
Comments:
          Qualitative Reasoning Workshop 2024 (QR2024) colocated with ECAI2024, camera-ready submission; first two authors contributed equally; 10 pages, 4 figures, 3 tables

- **What's New**: 이번 논문은 다중 모달 심층 신경망(DNN)에서 학습된 개념의 슈퍼클래스 계층 구조를 추출하는 방법을 제안합니다. 이를 통해 질적 추론(qualitative reasoning, QR) 모델과의 검증 및 확인을 위한 단계로 나아갑니다.

- **Technical Details**: 우리는 DNN의 텍스트 입력 모달리티를 사용하여 리프 개념의 임베딩을 얻고, 이를 계층적 클러스터링을 통해 의미적 유사성을 기반으로 하는 슈퍼클래스 개념을 라벨링합니다. 제안된 방법은 다중 모달 DNN의 중간 표현에서 간단한 온톨로지를 추출하고 검증할 수 있도록 돕습니다.

- **Performance Highlights**: 실험 결과, 제안된 방법이 의미 있는 온톨로지를 추출할 수 있고, 주어진 온톨로지와의 불일치성을 밝혀낼 수 있음을 보여주었습니다. 또한, QR 모델의 추출 및 삽입에 대한 잠재적 응용 가능성을 논의하였습니다.



### Accumulator-Aware Post-Training Quantization (https://arxiv.org/abs/2409.17092)
- **What's New**: 이 논문에서는 포스트 트레이닝 양자화 (Post-Training Quantization, PTQ) 환경에서 누산기 (accumulator)에 대한 양자화를 정식으로 연구하는 최초의 사례를 제시하고 있습니다. 'AXE'라는 새로운 프레임워크를 도입하여 PTQ 알고리즘에 오버플로우 회피 보장을 추가합니다.

- **Technical Details**: AXE는 기본적으로 레이어 단위로 가중치와 활성화 값의 양자화를 지지하는 알고리즘에 적용할 수 있도록 개발되었습니다. GPFQ 및 OPTQ라는 최신 PTQ 알고리즘 위에 AXE를 구현하면서 다단계 누산 지원을 일반화했습니다. 이는 대형 언어 모델(LLM)에서도 최적화 가능성을 열어줍니다.

- **Performance Highlights**: AXE는 이미지 분류 및 언어 생성 모델을 대상으로 평가되었으며, 누산기 비트 폭과 모델 정확성 간의 트레이드오프에서 기존 방법들에 비해 상당한 개선을 보여주었습니다. 특히, 다단계 누산을 목표로 할 때 Pythia 모델 세트에서 뛰어난 확장성을 입증하였습니다.



### Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification (https://arxiv.org/abs/2409.17091)
Comments:
          17 pages, 7 figures, 7 tables

- **What's New**: 이 논문에서는 Ctrl-GenAug라는 새로운 생성적 증강 프레임워크를 제안하여, 의료 시퀀스 분류를 위한 고도로 의미적이고 연속적인 시퀀스 생성을 지원하고 부정확하게 합성된 샘플을 억제합니다.

- **Technical Details**: Ctrl-GenAug는 다중 모달 조건 유도 시퀀스 생성기를 통해 진단 촉진 샘플을 제어 가능하게 합성하며, 시간적/입체적 일관성을 향상시키는 연속 증강 모듈을 통합합니다. 또한, 불확실한 사례를 억제하는 노이즈 합성 데이터 필터를 설계하였습니다.

- **Performance Highlights**: 세 가지 의료 데이터셋과 세 가지 패러다임에서 훈련된 11개의 네트워크를 사용한 광범위한 실험에서 Ctrl-GenAug의 효과성과 일반성이 입증되었습니다. 특히, 대표성이 부족한 고위험 군과 도메인 외 조건에서의 성능 향상을 보여주었습니다.



### SEN12-WATER: A New Dataset for Hydrological Applications and its Benchmarking (https://arxiv.org/abs/2409.17087)
Comments:
          Submitted to IEEE Transactions on Geoscience and Remote Sensing. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 본 연구에서는 기후 변화와 가뭄 증가 문제 해결을 위한 새로운 데이터셋인 SEN12-WATER를 소개합니다. 이 데이터셋은 제거 및 분석을 위한 새로운 end-to-end Deep Learning 프레임워크와 함께 제공됩니다.

- **Technical Details**: SEN12-WATER 데이터셋은 SAR (Synthetic Aperture Radar) polarization, 고도(elevation), 기울기(slope), 다중 스펙트럼(optical bands)을 포함한 시공간 데이터큐브(spatiotemporal datacube)입니다. 제안된 DL 프레임워크는 U-Net 아키텍처를 통한 수체(segmentation) 분할과 TD-CNN(Time-Distributed-Convolutional Neural Network)을 이용한 시계열(time series) 분석을 포함합니다.

- **Performance Highlights**: 제안된 방법론은 물리적 양(예: 물의 부피)의 시간 변화를 검토하여 물의 동역학에 대한 중요한 통찰을 제공합니다. 결과는 Precision, Recall, Intersection over Union 등과 같은 맞춤형 메트릭스를 통해 검증되었습니다.



### The Effect of Perceptual Metrics on Music Representation Learning for Genre Classification (https://arxiv.org/abs/2409.17069)
Comments:
          arXiv admin note: text overlap with arXiv:2312.03455

- **What's New**: 이 연구에서는 음악 이해 작업, 특히 장르 분류에 대한 성능을 향상시킬 수 있는 방법으로, 지각 메트릭(perceptual metrics)을 활용하는 새로운 접근법을 제안합니다. 특히, 자기 부호화기(autoencoders)로부터 추출된 특징을 사용하여 지각 손실(perceptual losses)로 훈련된 모델이 장르 분류를 개선할 수 있음을 입증했습니다.

- **Technical Details**: 지각 메트릭은 인간 관찰자의 지각 행동을 근사하는 데 설계된 객관적인 측정 지표입니다. 예를 들어, 구조적 유사도(SSIM)와 정규화된 라플라스 피라미드 거리(NLPD)와 같은 지표를 스펙트로그램(spectrograms)에 적용하여 오디오 품질에 대한 인간 평가와 더 나은 연관성을 보이는 것을 보여주었습니다. 이들 메트릭은 모델 훈련 시 손실 함수(loss function)으로 사용되어 모델의 성능을 개선할 수 있습니다.

- **Performance Highlights**: K-최근접 이웃(K-Nearest Neighbours) 분류기를 사용할 때, 전통적인 MSE(mean squared error)보다 지각 메트릭을 통한 성능 향상이 나타났습니다. 특히 로지스틱 회귀(Logistic Regression) 모델은 자기 부호화기에서 추출된 잠재 특징(latent features)을 활용할 때 높은 F1 점수를 기록했습니다. 그러나 NLPD는 군집화(clustering) 거리 측정에는 적합하지 않은 것으로 나타났으며, 이는 불필요한 정보를 제거함으로써 느리게 변화하는 부분들을 배제하기 때문입니다.



### Benchmarking Domain Generalization Algorithms in Computational Pathology (https://arxiv.org/abs/2409.17063)
- **What's New**: 이번 연구는 30개의 도메인 일반화 (Domain Generalization, DG) 알고리즘의 효과를 3개의 CPath 작업에 대해 평가하고, 새로운 다중 도메인 종양 탐지 데이터셋 (HISTOPANTUM)을 소개합니다.

- **Technical Details**: 연구에서는 7,560회의 교차 검증 (cross-validation) 실험을 통해 DG 알고리즘의 상대적인 성능을 비교하며, 최근에 제안된 pretrained foundation models와 같은 모달리티별 (modality-specific) 기법을 통합했습니다.

- **Performance Highlights**: 자기 감독 학습 (self-supervised learning) 및 염색 증강 (stain augmentation) 기법이 consistently 다른 알고리즘보다 좋은 성능을 보였으며, 연구 결과는 연구자들이 CPath 작업에 적합한 DG 접근 방식을 선택하는 데 도움을 줄 수 있습니다.



### ControlCity: A Multimodal Diffusion Model Based Approach for Accurate Geospatial Data Generation and Urban Morphology Analysis (https://arxiv.org/abs/2409.17049)
Comments:
          20 pages

- **What's New**: 이 논문에서는 다중 소스의 자원(Volunteer Geographic Information, VGI)을 활용하여 도시 건물 외형 데이터를 생성하는 새로운 접근방법인 ControlCity를 제안합니다. 이 모델은 여러 데이터 모달리티를 통합하여 더 정확하고 유용한 지리정보를 생성할 수 있습니다.

- **Technical Details**: ControlCity는 텍스트, 메타데이터, 이미지 데이터를 포함하는 'image-text-metadata-building footprint' 데이터 셋을 구축하고, 이를 기반으로 multimodal diffusion model을 사용하여 건물 외형 데이터를 생성합니다. 텍스트와 메타데이터를 정렬하여 도시의 건물 패턴을 학습하고, 개선된 ControlNet을 통해 도로 네트워크 및 토지 이용 이미지를 통합합니다.

- **Performance Highlights**: ControlCity는 전 세계 22개 도시에서 실험을 통해 평균 FID 점수 50.94를 기록하였으며, 기존 방법 대비 71.01%의 오류 감소와 38.46% 향상된 MIoU 점수를 달성했습니다. 제로샷 도시 생성을 통해 도시 구조를 정확하게 예측하고 생성할 수 있는 강력한 일반화 능력을 입증했습니다.



### GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design (https://arxiv.org/abs/2409.17045)
- **What's New**: 본 연구에서는 Deep Generative Models (DGM)을 공학 설계에 적용하기 위한 데이터셋 GeoBiked를 제공하며, 대규모 기초 모델을 활용하여 데이터 레이블링 자동화를 위한 방법을 제안합니다. GeoBiked 데이터셋은 4,355개의 자전거 이미지를 포함하고 있으며, 구조적 및 기술적 특징으로 주석이 달려 있습니다.

- **Technical Details**: GeoBiked 데이터셋은 이미지 생성 모델에서 추출한 통합 잠재 특징(Hyperfeatures)을 사용하여 구조적 이미지의 기하학적 대응 관계(예: 바퀴 중심 위치)를 검출하는 두 가지 자동 레이블링 기술을 조사합니다. 또한 GPT-4o를 통해 기술 이미지에 대한 다양한 설명을 생성합니다. 기술 이미지를 Diffusion-Hyperfeatures로 표현하여 기하학적 대응 관계를 측정할 수 있습니다.

- **Performance Highlights**: GeoBiked 데이터셋을 기반으로 한 두 가지 자동 레이블링 방법은, 잠재 이미지 특징의 학습된 통합을 통해 보지 못한 이미지에서 기하학적 기준점을 정확히 예측할 수 있음을 보여주며, GPT-4o를 통해 생성된 다양한 텍스트 설명은 정확한 기술 이미지를 설명합니다. 이러한 접근은 기술 이미지의 일반적인 포인트 검출 및 주석 작업에 적용 가능한 방법으로 제안됩니다.



### How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does No (https://arxiv.org/abs/2409.17044)
- **What's New**: 대형 언어 모델(LLM)의 성과가 두드러진 가운데, 본 연구는 음성 인식을 위한 다양한 구성요소(SFM, adapter, LLM)가 하위 작업 성과에 미치는 영향을 최초로 분석합니다.

- **Technical Details**: 다양한 adapter 모듈과 LLM, SFM을 이용하여 자동 음성 인식(ASR) 및 음성 번역(ST) 작업을 수행하였으며, SFM과 LLM의 조합에 따라 최적의 adapter 디자인이 달라짐을 규명하였습니다.

- **Performance Highlights**: SFM의 선택에 따라 ASR와 ST 성능이 평균적으로 각각 1 WER 및 2 COMET 포인트 이상 차이가 발생하였다. 따라서 length adapter의 디자인은 선택된 SFM 및 LLM에 크게 의존하는 것이 밝혀졌습니다.



### Counterfactual Token Generation in Large Language Models (https://arxiv.org/abs/2409.17027)
- **What's New**: 이번 연구에서는 대규모 언어 모델(LLM)이 출력의 대안에 대해 반사실적 추론(counterfactual reasoning)을 수행할 수 있도록 하는 causal 모델을 개발했습니다. 이는 무작위 샘플링(sampling) 과정에 Gumbel-Max 구조적 인과 모델을 적용하여 구현됩니다.

- **Technical Details**: 제안한 모델은 Llama 3 8B-instruct에서 구현되었으며, 기존의 노드 상태를 유지하지 않는 상태 비저장(stateless) LLM에서 출발하여 반사실적 토큰 생성(counterfactual token generation)을 가능하게 합니다. 이를 통해 모델은 입력된 프롬프트에 따라 자동 회귀(auto-regressive) 생성 방식을 사용하여 가능한 대안을 탐색할 수 있습니다.

- **Performance Highlights**: 반사실적 토큰 생성의 질과 양을 분석한 결과, 모델이 생성한 결과는 기존 출력과 높은 유사성을 보여주었으며, 바이어스 탐지에 대한 유용성도 입증되었습니다. 이 연구는 LLM이 어떻게 세상 모델을 구성하는지에 대한 통찰력을 제공합니다.



### INT-FlashAttention: Enabling Flash Attention for INT8 Quantization (https://arxiv.org/abs/2409.16997)
- **What's New**: 본 논문에서는 FlashAttention과 양자화 방법을 통합한 첫 번째 INT8 양자화 아키텍처인 INT-FlashAttention을 소개합니다. 이 아키텍처는 Amplere GPU에서 FlashAttention의 추론 속도를 크게 향상시킵니다.

- **Technical Details**: INT-FlashAttention은 INT8 활성화 및 일반 행렬 곱셈 (GEMM) 커널을 사용하여 구성된 최적의 프로토타입으로, 첫 번째 완전 INT8 입력을 가지는 어텐션 연산자입니다. INT-FlashAttention은 훈련 후 양자화(p스트레이닝(quantization)) 구조로, 다른 데이터 형식인 INT4와 호환됩니다.

- **Performance Highlights**: 실험 결과, INT-FlashAttention은 FlashAttention-FP16 대비 72% 빠른 추론 속도를 달성하였고, FlashAttention-FP8 대비 최대 82% 더 작은 양자화 오류를 보였습니다.



### Towards User-Focused Research in Training Data Attribution for Human-Centered Explainable AI (https://arxiv.org/abs/2409.16978)
- **What's New**: 이번 연구는 Explainable AI(XAI) 분야에서 기존의 하향식(bottom-up) 접근 대신 사용자의 요구를 중심으로 한 상향식(top-down) 접근 방식을 제안합니다. 특히 Training Data Attribution(TDA) 하위 분야에 초점을 맞추어 현재 사용자가 필요로 하는 기획 및 요구 사항을 파악했습니다.

- **Technical Details**: 우리는 10명의 AI 실무자와의 인터뷰 및 31명의 모델 개발자를 대상으로 한 시스템적 조사를 통해 TDA에 대한 사용자 니즈를 분석했습니다. 이를 통해 TDA에서 현재 간과되고 있는 다양한 작업을 확인했습니다.

- **Performance Highlights**: 사용자 중심의 TDA 연구 방향을 제안하며, 기계 학습 모델의 개발자가 TDA 설명을 필요로 하고, 유연성과 안정성을 요구하는 경향이 있음을 발견했습니다. 특히, 전체 교육 데이터 집단에 대한 기여도 설명이 개인 기여도 설명보다 더 선호되는 것으로 나타났습니다.



### Decoding Large-Language Models: A Systematic Overview of Socio-Technical Impacts, Constraints, and Emerging Questions (https://arxiv.org/abs/2409.16974)
Comments:
          28 pages, 5 figures, preprint submitted to journal

- **What's New**: 최근 대형 언어 모델(LLM)의 발전이 자연어 처리(NLP)와 인공지능(AI) 분야에 혁신적인 변화를 가져왔습니다. 이 연구에서는 LLM의 개발 방향, 영향력 및 한계에 대한 체계적인 문헌 조사를 수행하였습니다.

- **Technical Details**: 논문은 LLM 연구의 목표, 방법론, 제한 사항 및 향후 방향성을 서술하며, 알고리즘 개선, 윤리적 도전 과제, 사회적 영향을 포함하여 책임 있는 개발에 대한 고려 사항을 포함합니다. 또한, 체계적인 리뷰 방법론을 통해 문헌을 분석하고, 150회 이상의 인용된 61개의 주요 논문을 선정했습니다.

- **Performance Highlights**: LLM은 번역, 분류, 질문-응답, 요약 및 정보 검색과 같은 복잡한 작업을 수행하는 데 탁월한 성능을 보여줍니다. 특히, GPT-3와 같은 모델은 창의적인 콘텐츠 생성과 대화 시뮬레이션에서 뛰어난 다양한 기능을 발휘하고 있습니다.



### Adaptive Self-Supervised Learning Strategies for Dynamic On-Device LLM Personalization (https://arxiv.org/abs/2409.16973)
Comments:
          First ASLS

- **What's New**: 이번 논문에서는 Adaptive Self-Supervised Learning Strategies (ASLS)를 제안합니다. ASLS는 대규모 언어 모델(LLMs)을 사용자 개인의 선호도에 맞게 동적으로 개인화하는 혁신적인 방법으로, 라벨이 있는 데이터셋의 필요성을 줄이고 실시간 피드백을 기반으로 모델을 조정합니다.

- **Technical Details**: ASLS는 사용자 프로파일링 레이어와 신경망 적응 레이어의 이중 레이어 구조로 구성되어 있습니다. 사용자와의 상호작용 데이터를 수집하여 모델을 실시간으로 미세 조정하며, 이는 계속해서 사용자 피드백을 학습하여 사용자별 맞춤형 응답을 생성합니다. 이 접근법은 계산 자원을 절약하고 개인화 효율성을 높입니다.

- **Performance Highlights**: 다양한 사용자 시나리오에 대한 실험 결과, ASLS는 기존의 개인화 방법 대비 사용자의 참여도와 만족도를 크게 향상시켰습니다. 이러한 결과는 ASLS가 대규모 언어 모델을 보다 반응성이 뛰어나고 맥락을 인지하는 시스템으로 변모시킬 잠재력을 보여줍니다.



### Dynamic Obstacle Avoidance through Uncertainty-Based Adaptive Planning with Diffusion (https://arxiv.org/abs/2409.16950)
- **What's New**: 이번 연구에서는 강화 학습을 시퀀스 모델링 문제로 접근하면서, 움직이는 장애물이 있는 역동적인 환경에서도 효과적으로 충돌 회피를 수행할 수 있는 적응형 생성 계획(adaptive generative planning) 방법을 제안합니다. 이 방법은 불확실성을 기반으로 리플래닝 빈도를 동적으로 조절하여, 전통적인 방법들보다 더 나은 성능을 보여줍니다.

- **Technical Details**: 제안된 방법은 생성 모델(generative models), 특히 diffusion models를 활용하여 깊은 앙상블 역다이나믹스(action dynamics) 모델로부터 얻은 불확실성 추정을 기반으로 합니다. 이를 통해 1) 정해진 튜닝 파라미터에 따라 긴 시간 계획(long-horizon planning)과 각 단계에서의 리플래닝(replanning) 간의 유연한 균형을 제공하고, 2) 불필요한 리플래닝을 줄이면서 안전성을 확보할 수 있습니다.

- **Performance Highlights**: 실험 결과, 평균 경로 길이가 13.5% 증가하고, 평균 보상(mean reward) 또한 12.7% 증가하며, 이는 충돌 비율의 감소와 안전하게 환경을 탐색할 수 있는 능력이 향상되었음을 나타냅니다.



### Go-SLAM: Grounded Object Segmentation and Localization with Gaussian Splatting SLAM (https://arxiv.org/abs/2409.16944)
- **What's New**: 새로운 Go-SLAM 프레임워크를 소개하며, 3D Gaussian Splatting SLAM을 활용하여 동적 환경을 재구성하고 장면 표현 내에서 객체 수준 정보를 통합합니다. 이 시스템은 고급 객체 분할 기술을 사용하여 각 Gaussian splat에 고유한 식별자를 할당합니다.

- **Technical Details**: Go-SLAM은 3D Gaussian Splatting을 기반으로 하며, 객체 감지 및 세분화 모델을 포함하여 고급 컴퓨터 비전 기술을 활용하여 환경을 재구성합니다. 또한, 자연어 처리 기술을 활용하여 사용자 또는 고급 계획 알고리즘이 객체를 유연하게 쿼리할 수 있도록 합니다.

- **Performance Highlights**: 종합적인 평가 결과, 다양한 장면 설정에서 정밀도와 recall, IoU가 각각 17%, 27%, 35% 개선되는 것을 보여주며, Go-SLAM의 효율성을 입증합니다.



### Generative Object Insertion in Gaussian Splatting with a Multi-View Diffusion Mod (https://arxiv.org/abs/2409.16938)
Comments:
          Project Page: this https URL

- **What's New**: 본 논문에서는 Gaussian Splatting으로 표현된 3D 콘텐츠에 새로운 객체를 삽입하는 혁신적인 방법을 제안합니다. 이 방법은 MVInpainter라는 다중 뷰 확산 모델(multi-view diffusion model)을 기반으로 하여, 사전 학습된 안정적인 비디오 확산 모델을 활용하여 보기 일관성(view-consistent)을 보장하는 객체 인핑팅을 제공합니다.

- **Technical Details**: MVInpainter의 핵심은 ControlNet 기반의 조건부 주입 모듈을 통합하여 보다 통제되고 예측 가능한 다중 뷰 생성을 가능하게 하는 것입니다. 이 모델은 원본 3D 씬과 대조 모델에서 배경, BBox(Bounding Box) 수준의 마스크 및 깊이 맵을 추출하여, 입력으로 세 가지 세트를 사용해 목표 객체 설명에 맞춰 인핑팅 결과를 생성합니다.

- **Performance Highlights**: 다양한 실험을 통해 제안된 방법이 기존 방법들보다 뛰어난 성과를 보임을 입증하였습니다. 우리의 접근 방식은 다양한 결과를 생성하고, 보기 일관성을 보장하며, 더 나은 객체 품질을 제공합니다.



### Semi-Supervised Cognitive State Classification from Speech with Multi-View Pseudo-Labeling (https://arxiv.org/abs/2409.16937)
- **What's New**: 본 연구는 인지 상태 분류와 같은 주관적 평가가 많이 필요한 음성 분류 작업에서 레이블이 없는 데이터의 문제를 해결하기 위해 새로운 반지도 학습(Semi-Supervised Learning, SSL) 프레임워크를 제안합니다. 특히, 이 프레임워크는 음향과 언어적 특성을 활용한 다중 뷰(pseudo-labeling) 방법을 도입하여 분류 모델 훈련에 가장 확신이 높은 데이터를 선택합니다.

- **Technical Details**: 제안된 SSL 프레임워크는 두 가지 경로로 구성됩니다: 1) 음향 경로, 해당 경로에서는 다양한 오디오 임베딩을 이용해 레이블이 있는 데이터와 레이블이 없는 데이터를 비교하여 유사성을 판단합니다. 2) 언어 경로, 여기서는 대형 언어 모델(Large Language Models, LLMs)을 사용하여 ASR(Automatic Speech Recognition) 전사로부터 예측 레이블을 도출합니다. 프레셰 오디오 거리(Frechet Audio Distance, FAD)를 사용해 레이블이 없는 데이터의 음향 유사성을 측정하고, 이를 통해 고신뢰 데이터와 저신뢰 데이터를 구분합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 라벨이 있는 데이터의 30%만 사용하여도 완전 감독 학습(fully supervised learning)과 유사한 성능을 달성하였으며, 두 개의 기준선보다 훨씬 우수한 성과를 나타냈습니다.



### Investigating OCR-Sensitive Neurons to Improve Entity Recognition in Historical Documents (https://arxiv.org/abs/2409.16934)
- **What's New**: 이 논문은 Transformer 아키텍처 내에서 OCR 민감한 뉴런의 존재를 조사하고, 역사적 문서에 대한 명명된 개체 인식(NER) 성능에 미치는 영향을 분석합니다. 깨끗한 텍스트 입력과 잡음이 있는 텍스트 입력에 대한 뉴런 활성화를 분석하여 OCR 민감한 뉴런을 식별하고 중화시킴으로써 모델 성능을 향상시키는 방법을 제안합니다.

- **Technical Details**: 실험은 Llama2와 Mistral 두 개의 오픈 액세스 대형 언어 모델을 기반으로 하며, OCR 잡음이 존재하는 텍스트에 대한 뉴런의 반응을 측정하여 OCR 민감한 레이어와 뉴런을 식별하는 데 중점을 둡니다. 이 과정에서 데이터셋은 프랑스 역사 신문의 OCR 수정 버전을 기반으로 생성되며, 다양한 수준의 OCR 잡음이 추가된 토큰을 사용합니다.

- **Performance Highlights**: 실험 결과, 역사 신문 및 고전 해설 문서에서 NER 성능이 개선되는 것으로 나타났고, 이는 특정 뉴런 조절이 잡음이 있는 텍스트에서 모델의 성능을 향상시킬 수 있음을 시사합니다.



### Cross-lingual Speech Emotion Recognition: Humans vs. Self-Supervised Models (https://arxiv.org/abs/2409.16920)
- **What's New**: 본 연구는 Self-Supervised Learning (SSL) 모델을 통한 Speech Emotion Recognition (SER)에서 인간 성능과의 비교 분석을 수행했습니다. 특히, 단일 언어(monolingual), 교차 언어(cross-lingual) 및 전이 학습(transfer learning) 맥락에서 매개변수 효율적인 미세 조정(Parameter-Efficient Fine-Tuning) 전략을 탐구하고, 방언이 교차 언어 SER에 미치는 영향을 조사하였습니다.

- **Technical Details**: 이 연구는 Wav2vec 2.0 (W2V2) 및 WavLM 등 강력한 사전 훈련(pre-trained) 모델을 사용하여 SSL 기반의 SER 성능을 비교하였습니다. 다양한 PEFT 전략을 통해 모델의 초기 파라미터를 수정하며, 중간층의 음성 표현이 높은 성능을 발휘하는 것을 확인했습니다. 교차 언어 SER에서 모델은 적절한 지식 전이를 통해 목표 언어에 적응할 수 있음을 보여주었으며, 특정 방언의 특성을 고려한 평가를 수행했습니다.

- **Performance Highlights**: 모델과 인간 모두 다른 감정에 대해 뚜렷한 행동 차이를 보였으며, 모델은 네이티브(Native) 화자와 유사한 성능을 기록했습니다. 방언은 인간의 감정 인식에 상당한 영향을 미치는 것으로 나타났으며, 감정 인식 정확도를 조정하기 위한 다양한 PEFT 전략이 효과적이었음을 입증했습니다.



### Enhancing Temporal Sensitivity and Reasoning for Time-Sensitive Question Answering (https://arxiv.org/abs/2409.16909)
Comments:
          Accepted by EMNLP 2024 Findings

- **What's New**: 본 논문에서는 Time-Sensitive Question Answering (TSQA) 문제를 해결하기 위한 새로운 프레임워크를 제안합니다. 이 프레임워크는 Temporal Information-Aware Embedding과 Granular Contrastive Reinforcement Learning을 통해 모델의 시간 인식 및 추론 능력을 향상시키는 것을 목표로 합니다.

- **Technical Details**: 이 프레임워크는 두 가지 주요 방법론을 포함합니다: Temporal Information-Aware Embedding은 모델의 시간 정보에 대한 민감성을 높이고, Granular Contrastive Reinforcement Learning은 시간적 거리에 따라 원거리 및 근접한 부정적 답변을 제공하여 모델의 시간적 추론 능력을 향상시킵니다.

- **Performance Highlights**: 우리는 제안된 프레임워크가 기존의 LLM보다 TSQA 작업에서 유의미하게 뛰어난 성능을 보여주는 것을 확인했습니다. 실험 결과는 네 개의 다양한 TSQA 데이터셋에서 우리의 프레임워크가 기존 모델보다 크게 향상된 성능을 보였음을 입증합니다.



### Discriminative Anchor Learning for Efficient Multi-view Clustering (https://arxiv.org/abs/2409.16904)
Comments:
          This work has been accepted by TMM

- **What's New**: 이 논문에서는 Multi-view clustering을 위한 차별적 앵커 학습(discriminative anchor learning)을 제안하여 기존 방법의 단점을 해결하고자 했다. 이 방법은 각 뷰(view)에 대한 차별적(feature) 표현을 학습하고, 이를 통해 공유 앵커 그래프(shared anchor graph)의 품질을 향상시키며, 앵커 간의 보완적(complementary) 정보도 고려한다.

- **Technical Details**: 차별적 앵커 학습(discriminative anchor learning for multi-view clustering, DALMC) 방식은 원본 데이터셋을 기준으로 각 뷰에 대해 차별적 feature representation을 학습하고, 이를 바탕으로 합동 앵커 그래프(consensus anchor graph)를 구축한다. 이 과정은 차별적 feature 학습과 앵커 그래프 구축을 통합하여 서로 개선될 수 있도록 한다. 또한 최적 앵커(anchors)와 합동 앵커 그래프는 직교 제약조건(orthogonal constraints)을 통해 학습된다.

- **Performance Highlights**: 다양한 데이터셋에 대한 실험 결과, DALMC는 기존 방법들에 비해 효율성과 효과성을 입증했다. 이 알고리즘은 선형 시간 복잡도를 가지며, 대규모 데이터셋을 효율적으로 처리할 수 있는 능력을 보여준다.



### Towards Underwater Camouflaged Object Tracking: An Experimental Evaluation of SAM and SAM 2 (https://arxiv.org/abs/2409.16902)
Comments:
          Preprint. Work in Progress

- **What's New**: 이번 논문에서는 UW-COT라는 첫 번째 대규모 수중 위장 물체 추적 데이터셋을 제안하고, 이 데이터셋을 기반으로 여러 최신 시각 물체 추적 방법의 실험적 평가를 수행하였습니다.

- **Technical Details**: UW-COT 데이터셋은 96개 카테고리로 구성된 220개의 수중 비디오 시퀀스를 포함하며, 각 프레임에 대해 위장된 물체에 대한 바운딩 박스 주석을 제공합니다. 이 데이터셋을 통해 SAM(Segmentation Anything Model)과 SAM 2의 성능을 비교하였으며, SAM 2는 시간적 일관성, 신뢰성, 기능 임베딩, 컴퓨팅 효율성 및 신규 도메인 일반화 능력이 개선되었습니다.

- **Performance Highlights**: SAM 2는 UW-COT 데이터셋에서 SAM 기반 추적기(SAM-DA 및 Tracking Anything)보다 뛰어난 성능을 보였으며, 현재의 최신 VOT 방법들보다 우수한 성능을 기록하였습니다. 이는 SAM 2가 비디오 데이터의 동적 도전 과제를 해결하기 위한 향상된 솔루션을 제공한다는 것을 보여줍니다.



### A Roadmap for Embodied and Social Grounding in LLMs (https://arxiv.org/abs/2409.16900)
Comments:
          Accepted Version of a conference paper presented at Robophilosophy Conference 2024

- **What's New**: 이번 연구는 로봇 시스템에 대규모 언어 모델(LLMs)을 통합하여 의사소통 뿐만 아니라 다중 모달 입력 처리, 고급 추론 및 계획 생성을 통한 변혁적인 패러다임을 제시합니다. LLM의 지식을 경험적 세계와 연결하기 위한 새로운 접근 방식을 탐구합니다.

- **Technical Details**: 이 논문은 LLMs의 기초 모델에 대한 추상 지식을 물리적 현실과 일치시키는 'grounding'(근거화) 과정을 다룹니다. 이 과정에서는 LLMs가 환경에 대한 이해도를 높이고, 객체의 물리적 속성을 통해 추론 능력을 향상시키도록 돕는 기술적 접근이 포함됩니다.

- **Performance Highlights**: 최근의 연구들은 LLMs의 텍스트 기반 작업에서의 효과가 신체적 제어까지 확장되었음을 보여주며, 이는 로봇이 인간과의 협력적 환경에서 더 뛰어난 성능을 발휘할 수 있게 합니다. 그러나 실제 로봇 작업에서 물리적 및 사회적 추 reasoning과 같은 기술들에 대한 LLM의 한계 또한 강조되었습니다.



### Revisiting Space Mission Planning: A Reinforcement Learning-Guided Approach for Multi-Debris Rendezvous (https://arxiv.org/abs/2409.16882)
Comments:
          Accepted for publication at the 2024 International Conference on Space Robotics (iSpaRo)

- **What's New**: 이 연구는 우주 쓰레기 탐방의 효율적인 순서를 결정하기 위해 심층 강화 학습(deep reinforcement learning) 분야의 masked Proximal Policy Optimization(PPO) 알고리즘을 도입합니다. 목표는 주어진 모든 쓰레기를 방문하는 최적의 순서를 찾고, 이를 통해 전체 미션의 총 소요 시간을 최소화 하는 것입니다.

- **Technical Details**: 이 연구에서는 신경망(neural network) 정책을 개발하고, 다양한 쓰레기 환경에서 시뮬레이션된 우주 미션을 통해 훈련합니다. 훈련 후에 신경망은 Izzo의 Lambert 기법을 사용해 최적의 경로를 계산하며, 강화 학습 접근법을 통해 계획 효율성이 크게 향상되었습니다. 기존의 유전 알고리즘(Genetic algorithm)과 탐욕 알고리즘(Greedy algorithm)과 비교하여 각각 약 10.96%와 13.66%의 미션 시간을 줄이는 데 성공했습니다.

- **Performance Highlights**: 이 모델은 다양한 시뮬레이션 시나리오에서 쓰레기 방문의 가장 시간 효율적인 순서를 식별하며, 가장 빠른 계산 속도로 결과를 도출합니다. 이는 우주 쓰레기 제거를 위한 미래의 미션 계획 전략을 향상시키는데 기여할 것으로 기대됩니다.



### The Role of Language Models in Modern Healthcare: A Comprehensive Review (https://arxiv.org/abs/2409.16860)
- **What's New**: 이 논문은 대형 언어 모델(LLM)이 의료 분야에 어떻게 적용되는지에 대한 체계적인 리뷰를 제공합니다. LLM의 발전 과정과 의료 적용에서의 강점뿐만 아니라 데이터 프라이버시, 편향, 윤리적 고려사항 등의 문제를 논의합니다.

- **Technical Details**: 대형 언어 모델(LLM)은 Transformer 아키텍처를 기반으로 하여 장거리 의존성을 효과적으로 캡처하는 능력을 가지고 있습니다. 모델은 일반적으로 방대한 텍스트 데이터셋으로 사전 학습(pre-training)된 후, 특정 작업에 맞춰 세부 조정(fine-tuning)됩니다. BioBERT, ClinicalBERT와 같은 의료 전용 모델이 개발되어 임상 언어의 독특한 도전을 해결하고 있습니다.

- **Performance Highlights**: LLM은 의료 데이터 분석, 질병 진단, 환자 관리 및 약물 발견과 같은 다양한 분야에서 사용되고 있습니다. 임상 의사결정 지원 및 의료 문서 요약 등의 임무에 대한 효과적인 증상이 입증되었습니다. 측정 기준으로는 MMLU, HumanEval과 같은 벤치마크가 사용되어 모델의 효과성을 평가합니다.



### OffRIPP: Offline RL-based Informative Path Planning (https://arxiv.org/abs/2409.16830)
Comments:
          7 pages, 6 figures, submitted to ICRA 2025

- **What's New**: 이번 연구에서는 Offline RL 기반의 정보 경로 계획 (Informative Path Planning, IPP) 프레임워크인 OffRIPP를 제안합니다. 이는 실시간 상호작용 없이 정보 수익을 극대화하는 경로를 계획합니다.

- **Technical Details**: OffRIPP 프레임워크는 배치 제약 강화 학습 (Batch-Constrained Reinforcement Learning)을 활용하여 미리 수집된 데이터셋에서 학습하며, 전통적인 방법들보다 안전하고 비용 효율적으로 작동합니다. 이 접근법은 다양한 알고리즘에 의해 생성된 데이터셋으로부터 학습할 수 있습니다.

- **Performance Highlights**: 실험 결과, OffRIPP는 기존의 여러 IPP 알고리즘, 온라인 RL 기반 훈련 방식 및 동작 복제 (Behavior Cloning)와 비교할 때 성능이 우수한 결과를 보였으며, 운영 비용을 줄이는 데 도움을 주었습니다.



### On the role of Artificial Intelligence methods in modern force-controlled manufacturing robotic tasks (https://arxiv.org/abs/2409.16828)
Comments:
          To be published in Proceedings of the 20th International Conference on Informatics in Control, Automation and Robotics (ICINCO)

- **What's New**: 이번 논문은 인공지능(AI)과 포스 제어(force-controlled) 로봇 작업의 통합에 대해 탐구하며, 이는 첨단 제조(advanced manufacturing)의 중요한 요소이자 산업 4.0의 기초입니다. AI가 로봇 매니퓰레이터에 미치는 영향과 이를 통한 스마트 제조의 혁신을 다룹니다.

- **Technical Details**: 포스 제어는 다양한 산업 및 의료 응용 분야에서 필수적인 요소로 여겨지며, 이 논문에서는 AI 기반 포스 제어 기술의 최신 동향과 이를 통한 공정 혁신을 설명합니다. 포스 제어에 대한 기존 기법을 기반으로, AI는 환경의 비선형 특성과 복잡성을 극복하는데 도움을 줄 수 있습니다.

- **Performance Highlights**: 포스 제어 작업의 예로는 디버링(deburring), 폴리싱(polishing), 조립(assembly) 작업이 있으며, 특히 peg-in-hole (PiH) 조립 작업이 강조됩니다. 논문은 AI 기반 기법의 최신 동향과 이들이 현장에서의 적용성 및 성능을 어떻게 개선할 수 있는지를 탐구합니다.



### Learning phase-space flows using time-discrete implicit Runge-Kutta PINNs (https://arxiv.org/abs/2409.16826)
Comments:
          10 pages, 4 figures, published in the International Conference on Scientific Computing and Machine Learning, see this http URL

- **What's New**: 본 연구에서는 고차원 함수형 비선형 결합 미분 방정식의 위상 공간 솔루션을 얻기 위한 계산 프레임워크를 제시합니다. 이를 위해 High-order Implicit Runge-Kutta Physics-Informed Neural Networks (IRK-PINNs) 방식을 사용하였습니다.

- **Technical Details**: 기존의 미분 방정식 해법을 바탕으로 하여, 좌표가 함수로 처리되는 맥락으로의 스킴을 수정하였습니다. 이 수정은 외부 필드에서 입자의 운동 방정식을 효율적으로 해결할 수 있도록 해줍니다.

- **Performance Highlights**: 우리의 접근 방식을 활용하여, 중심 힘 필드에 위치한 질량 입자와 주기적인 전기 필드에서의 하전 입자의 운동 방정식을 성공적으로 해결하였습니다.



### Uncertainty Representations in State-Space Layers for Deep Reinforcement Learning under Partial Observability (https://arxiv.org/abs/2409.16824)
- **What's New**: 이 논문은 기대되는 수익을 극대화하기 위해 모델-프리 아키텍처 내에서 훈련된 스탠드얼론 Kalman 필터 레이어를 제안합니다. 이 레이어는 숨겨진 상태 표현의 불확실성을 포함할 수 있는 내부 메커니즘을 갖추고 있습니다.

- **Technical Details**: Kalman 필터 레이어는 선형 상태 공간 모델에서 닫힌 형태의 Gaussian 추론을 수행하며, 시퀀스 길이에 대해 로그적으로 확장 가능합니다. 이 레이어는 표준 모델-프리 아키텍처의 다른 순환 레이어와 쉽게 교체 가능하며, 잠재 상태 표현의 확률적 필터링을 위한 명시적 메커니즘을 포함합니다.

- **Performance Highlights**: 다양한 POMDP 문제에서 실시된 실험 결과, Kalman 필터 레이어는 의사결정에서 불확실성 추론이 중요한 문제에서 다른 상태 기반 모델보다 우수한 성능을 발휘하였습니다.



### XAI-guided Insulator Anomaly Detection for Imbalanced Datasets (https://arxiv.org/abs/2409.16821)
Comments:
          Accepted as a workshop paper at ECCV 2024

- **What's New**: 이 연구에서는 전선의 절연체 결함을 탐지하기 위한 새로운 파이프라인을 제안합니다. UAV(무인 항공기)를 활용하여 수집한 이미지를 통해 절연체 결함을 정확하게 검출하고 분류하는 방법론을 개발하였습니다.

- **Technical Details**: 제안된 방법은 YOLOv8 모델을 사용하여 절연체를 검출하고, 비율이 불균형한 데이터셋 문제를 해결하기 위해 로지스틱 회귀를 통한 재훈련 기법을 적용하였습니다. 또한, LRP(층별 관련 전파기법)를 활용하여 결함의 위치를 정확히 설명하고 시각화했습니다.

- **Performance Highlights**: 결함 탐지 정확도를 최대 13% 향상시켰으며, 클래스 불균형 문제를 해결하여 예측 유지보수의 효과성을 크게 개선하였습니다. 이 연구는 산업 현장에서의 비전 기반 검사 및 예측 유지 보수에 가치 있는 기여를 하고 있습니다.



### Scalable Ensemble Diversification for OOD Generalization and Detection (https://arxiv.org/abs/2409.16797)
Comments:
          Under review

- **What's New**: 본 연구는 Scalable Ensemble Diversification (SED)라는 새로운 방법론을 제시하여 기존의 다양한 앙상블 학습 방법의 한계를 극복합니다. 특히, OOD 샘플 없이도 대규모 데이터에서 효과적으로 적용할 수 있는 방식으로 설계되었습니다.

- **Technical Details**: SED는 세 가지 주요 기술적 혁신을 통해 발전되었습니다: (1) 하드 샘플을 동적으로 식별하여 모델 간의 불일치를 유도합니다. (2) 각 반복에서 무작위로 선택된 두 모델에 대해서만 다양화 목표를 적용하여 계산 비용을 줄입니다. (3) 네트워크의 출력 근처의 일부 레이어에만 영향을 미치도록 하여 심층 네트워크에서의 다양화 목표를 조정합니다.

- **Performance Highlights**: ImageNet에서의 실험을 통해 SED의 다양한 이점을 확인했습니다. OOD 일반화와 OOD 탐지 모두에서 성능이 상당히 향상되었으며, Predictive Diversity Score (PDS) 방법론은 OOD 샘플 탐지에서 기존 방법들을 초월하는 성능을 보였습니다.



### Symbolic State Partition for Reinforcement Learning (https://arxiv.org/abs/2409.16791)
- **What's New**: 본 논문은 연속 상태 공간에서 직접적으로 작동할 수 없는 테이블 기반 강화 학습(tabular reinforcement learning) 방법의 문제를 다룹니다. 이 문제의 해결책 중 하나는 상태 공간을 분할(partition)하는 것입니다. 이 연구에서는 환경 동역학(dynamics)을 기반으로 상징적 실행(symbolic execution)을 통해 분할을 추출하는 방법을 제안합니다.

- **Technical Details**: 상징적 분할(symbolic partitioning)은 비선형 관계(nonlinear relations)가 있는 상태 구성 요소 간의 근사화가 학습 과정에서 해롭다는 점을 충분히 고려합니다. 이상적인 분할은 가능한 한 거칠게(coarse) 하면서도 주어진 문제의 상태 공간의 핵심 구조(key structure)를 포착할 수 있어야 합니다.

- **Performance Highlights**: 상징적 분할을 통해 강화 학습이 드문 보상(sparse rewards) 상황에서도 성능이 향상된다는 것을 보였습니다. 논문에서는 정밀도(precision), 확장성(scalability), 학습 에이전트 성능(performance), 학습된 정책의 상태 공간 커버리지(state space coverage) 측면에서 평가를 수행하였습니다.



### Enhancing Feature Selection and Interpretability in AI Regression Tasks Through Feature Attribution (https://arxiv.org/abs/2409.16787)
- **What's New**: 이 연구는 Explainable Artificial Intelligence (XAI) 분야의 feature attribution 방법을 활용하여 회귀 문제에서 입력 데이터의 비정보적 특징을 필터링하고, 예측의 정확도 및 안정성을 높이는 방법을 제안합니다.

- **Technical Details**: 연구자들은 Integrated Gradients (IG)와 k-means 클러스터링을 결합한 feature selection pipeline을 도입했습니다. 이 방법은 실제 산업 문제인 터보 기계 개발 과정에서 블레이드 진동 분석에 적용되었습니다. IG는 gradient 기반의 모델 독립적 접근법으로, 이전에 회귀 문제에서 사용된 바 있습니다.

- **Performance Highlights**: 이 접근법은 생성된 투명한 더미 데이터에서 실험을 통해 효과를 검증한 후, 실제 문제에 적용되었습니다. 제안된 방법은 established baseline feature selection 방법 및 KernelShap과 비교되었습니다.



### Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction (https://arxiv.org/abs/2409.16783)
Comments:
          EMNLP 2024 camera ready version

- **What's New**: 본 논문에서는 HARM (Holistic Automated Red teaMing)을 제안하여, 대형 언어 모델 (LLMs)의 비정상적인 행동을 체계적으로 식별하는 새로운 방법을 소개합니다. HARM은 리스크 카테고리의 세분화된 분류를 바탕으로 한 상향식 접근 방식을 사용하고, 멀티 턴 상호작용을 지원하여 자동화된 레드 팀핑을 강화합니다.

- **Technical Details**: HARM은 세분화된 리스크 분류 체계를 사용하여 다양한 테스트 케이스를 생성하는 방법을 적용합니다. 이 방법은 고유의 파인 튜닝 전략과 강화 학습 기법을 활용하여 인간과 유사한 방식으로 멀티 턴에서의 적대적인 탐색을 수행합니다.

- **Performance Highlights**: 실험 결과를 통해 HARM이 모델의 취약성에 대한 보다 체계적인 이해를 가능하게 하고, 안전한 정렬 과정을 위한 보다 구체적인 가이드를 제공함을 보여주었습니다.



### Super Level Sets and Exponential Decay: A Synergistic Approach to Stable Neural Network Training (https://arxiv.org/abs/2409.16769)
- **What's New**: 본 논문에서는 신경망 최적화 프로세스를 향상시키기 위해 동적인 학습률 알고리즘을 개발하였습니다. 이 알고리즘은 지수적 감소(exponential decay)와 고급 과적합 방지 전략을 통합하여 최적화의 안정성을 높입니다. 또한, 이론적 프레임워크를 수립하여 Lyapunov 안정성 원리를 통해 손실 함수의 초레벨 집합(superlevel sets)의 연결성을 보장합니다.

- **Technical Details**: 이 논문은 동적 학습률(dynamic learning rate)과 손실 함수의 초레벨 집합(superlevel set) 간의 수학적 관계를 탐구합니다. 지수적 감소에 기반한 학습률 ‌η(t)=η₀e^{-αt} 모델을 통해 최적화 경로의 연결성을 유지하며, 불안정한 지역에 갇히지 않도록 합니다. 이를 통해 안정적이고 효율적인 최적화를 달성하는 방법을 제시합니다.

- **Performance Highlights**: 이 연구는 신경망 훈련 과정에서 에러를 최소화하면서 과적합(overfitting)을 방지하는 데 효과적입니다. 제안된 알고리즘은 더 나은 일반화 능력을 제공하며, 다양한 데이터 환경에서 일관된 안정성을 유지하여 신뢰성을 높입니다.



### MaViLS, a Benchmark Dataset for Video-to-Slide Alignment, Assessing Baseline Accuracy with a Multimodal Alignment Algorithm Leveraging Speech, OCR, and Visual Features (https://arxiv.org/abs/2409.16765)
- **What's New**: 이 논문에서는 강의 비디오와 해당 슬라이드를 정렬하는 벤치마크 데이터셋을 제시하고, 음성, 텍스트 및 이미지에서 특징을 활용하는 새로운 다중 모달 알고리즘을 소개합니다.

- **Technical Details**: 제안된 알고리즘은 동적 프로그래밍(dynamic programming)을 사용하여 최적의 슬라이드 시퀀스를 결정하며, OCR(Optical Character Recognition)을 통해 얻은 특징들이 매칭 정확도에 크게 기여한다고 보고합니다. 알고리즘은 SIFT(Scale-Invariant Feature Transform)에 비해 평균 0.82의 정확도를 기록하면서 속도는 약 11배 빨라졌습니다.

- **Performance Highlights**: 제안된 알고리즘은 다양한 강의 스타일과 비디오 품질에 따른 매칭 정확도의 차이를 보였으며, 슬라이드 전환을 제재할 경우 정확도가 향상되었습니다. 또한, 매칭의 정확도는 오디오 전사에 의해서도 유용한 정보를 제공하고, OCR 데이터가 부족할 때 더욱 유용함을 강조합니다.



### Offline and Distributional Reinforcement Learning for Radio Resource Managemen (https://arxiv.org/abs/2409.16764)
- **What's New**: 이 논문은 기존의 온라인 강화 학습(online RL) 방식에서 오프라인 및 분포적 강화 학습(off-line and distributional RL)을 적용하여 무선 네트워크의 무선 자원 관리(radio resource management, RRM) 문제에 대한 새로운 해결책을 제시합니다.

- **Technical Details**: 제안된 알고리즘은 고정된 데이터셋을 사용하여 환경과의 상호작용 없이 오프라인 학습을 수행하며, 반환(return)의 분포를 고려하여 불확실성을 처리합니다. RRM 문제에 대한 이 접근 방식은 평균 성과만을 고려하는 기존 방법들의 한계를 극복합니다.

- **Performance Highlights**: 모의실험 결과, 제안된 오프라인 및 분포적 RL 알고리즘이 기존의 자원 관리 모델보다 우수한 성능을 보였으며, 온라인 RL보다 16% 높은 성과를 달성했습니다.



### GB-RVFL: Fusion of Randomized Neural Network and Granular Ball Computing (https://arxiv.org/abs/2409.16735)
- **What's New**: 본 논문에서는 랜덤 벡터 기능 링크(RVFL) 네트워크의 문제점을 해결하기 위해, 입력으로 개별 샘플 대신 granular balls (GBs)을 사용하는 GB-RVFL 모델과, GBs의 지리적 구조를 보존하기 위한 graph embedding (GE) 통합 모델인 GE-GB-RVFL을 제안합니다.

- **Technical Details**: GB-RVFL 모델은 GB의 중심 행렬의 역행렬만 필요로하여 확장성을 높이고, GB의 조밀성을 활용하여 노이즈와 이상치에 대한 강인성을 개선합니다. GE-GB-RVFL 모델은 데이터셋의 내재적 기하구조를 보존하면서 GB-RVFL의 핵심 특성을 유지하며, 그래프 정규화 항을 포함하는 방법론을 통합하여 데이터 구조의 세부정보를 보존합니다.

- **Performance Highlights**: GB-RVFL 및 GE-GB-RVFL 모델은 KEEL, UCI, NDC 및 생물의학 데이터셋에서 평가되었으며, 기존의 기준 모델에 비해 우수한 성능을 입증하였습니다. 특히, 실제 생물의학 데이터셋에서도 적용 가능성을 보여주며, 유방암 분류 및 알츠하이머병 분류에서의 향상된 성능을 나타냈습니다.



### Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification (https://arxiv.org/abs/2409.16718)
Comments:
          EMNLP 2024 Main Conference

- **What's New**: 최근 Vision-Language Models (VLMs)에 대한 세밀한 조정이 이루어지면서, 클립 모델의 고유한 매개변수를 조정하는 것의 중요성을 재조명하였다. 이 연구에서는 모든 매개변수를 조정하는 대신 특정 매개변수만을 조정하는 CLIPFit 방법을 제안하였다.

- **Technical Details**: CLIPFit은 기존의 프롬프트 튜닝(prompt tuning) 및 어댑터 튜닝(adapter tuning) 방식과는 다르게, 추가적인 매개변수를 도입하지 않고 클립 모델의 특정 바이어스와 정규화 레이어만 조정하는 방법이다. 이로 인해 파라미터 수가 줄어들고, 성능이 향상된다.

- **Performance Highlights**: CLIPFit을 사용하여 zero-shot CLIP 대비 7.33%의 평균 조화 평균 정확도(harmonic mean accuracy) 개선을 달성하였으며, 이는 16-shot 설정에서 프롬프트 튜닝 및 어댑터 튜닝을 대체할 수 있는 유망한 옵션이다.



### Pix2Next: Leveraging Vision Foundation Models for RGB to NIR Image Translation (https://arxiv.org/abs/2409.16706)
Comments:
          19 pages,12 figures

- **What's New**: Pix2Next는 RGB 이미지를 기반으로 고해상도 NIR 이미지를 생성하는 혁신적인 이미지-이미지 변환 프레임워크입니다. 이 방법은 최신 Vision Foundation Model (VFM)을 활용하여_encoder-decoder_ 아키텍처에서 크로스-어텐션 메커니즘(cross-attention mechanism)을 통합하여 특징 통합을 향상시킵니다. 더불어, 여러 해상도에서 현실적인 이미지 생성을 보장하는 PatchGAN 판별자를 사용하여 NIR 이미지 생성의 품질과 세부사항을 개선합니다.

- **Technical Details**: Pix2Next은 RGB 이미지를 NIR 이미지로 변환하는 과정에서 고유한 세부 사항과 스펙트럼 특성을 유지하는 데 중점을 두고 설계되었습니다. 실제로, Segmentation과 Object Detection 태스크에 대한 성능 평가와 함께 다양한 손실 함수가 글로벌 컨텍스트 이해와 로컬 특징 보존을 연결하여 모델 성능을 높입니다. 또한	RANUS 데이터셋을 사용하여 테스트를 진행하였습니다.

- **Performance Highlights**: Pix2Next는 FID(Frechet Inception Distance) 점수를 기존 방법에 비해 34.81% 향상시켜, 세 가지 시각 품질 지표에서 뛰어난 성능을 보였습니다. 또한, NIR 이미지로의 변환된 데이터를 이용하여 자율 주행 인식 태스크에서 더욱 개선된 성능을 보여주어, 제한된 실 NIR 데이터셋을 보완하는 데 있어 효용성을 입증했습니다.



### Layout-Corrector: Alleviating Layout Sticking Phenomenon in Discrete Diffusion Mod (https://arxiv.org/abs/2409.16689)
Comments:
          Accepted by ECCV2024, Project Page: this https URL

- **What's New**: 이 논문은 기존의 Discrete Diffusion Models (DDMs)에서 발생하는 레이아웃 고착(Layout Sticking) 현상을 해결하기 위해 Layout-Corrector라는 새롭고 간단한 모듈을 제안합니다.

- **Technical Details**: Layout-Corrector는 레이아웃의 각 요소에 대한 정확성 점수를 평가하고, 저조한 점수를 가진 요소를 재초기화하여 하모니가 있는 레이아웃을 생성을 돕습니다. 이 모듈은 DDM과 함께 사용되며, 각 생성 과정에서 하모니를 고려하여 불일치하는 요소를 식별합니다.

- **Performance Highlights**: Layout-Corrector는 다양한 기준 벤치마크에서 테스트되어 DDM과 함께 사용할 경우 레이아웃 생성 성능을 일관되게 향상시키고, 정확성-다양성 무역의 조절을 통한 성능 저하를 완화합니다.



### Erase then Rectify: A Training-Free Parameter Editing Approach for Cost-Effective Graph Unlearning (https://arxiv.org/abs/2409.16684)
Comments:
          Under review

- **What's New**: 이번 연구에서는 Erase then Rectify (ETR)라는 두 단계의 훈련 없는 접근 방식을 제안하여 효율적이고 확장 가능한 그래프 비학습 (graph unlearning)을 실현했습니다. 이 방법은 특정 노드나 엣지의 영향을 제거하는 데 중점을 두었으며, 기존의 방법들이 필요한 추가 훈련을 하지 않고도 높은 유용성을 유지합니다.

- **Technical Details**: ETR 방법은 두 단계로 구성되어 있습니다. 첫 번째 단계인 Erase에서는 중요한 매개변수를 마스킹하여 비학습 샘플의 영향을 효과적으로 제거합니다. 두 번째 단계인 Rectify에서는 남은 데이터 세트에 대한 모델의 그래디언트를 추정하여 GNN의 성능을 향상시키는 기법을 적용합니다. ETR은 전체 훈련 데이터에 접근하지 않고도 그래프 비학습을 수행할 수 있게 설계되었습니다.

- **Performance Highlights**: ETR은 평균적으로 4583.9배 적은 시간과 4.2배 적은 메모리 사용량을 기록하며 비학습 효율성, 성능, 그리고 유용성 측면에서도 뛰어난 결과를 보였습니다. 이는 대규모 그래프에도 적용가능한 가능성을 제시합니다.



### TSBP: Improving Object Detection in Histology Images via Test-time Self-guided Bounding-box Propagation (https://arxiv.org/abs/2409.16678)
Comments:
          MICCAI 2024

- **What's New**: 본 논문에서는 Test-time Self-guided Bounding-box Propagation (TSBP) 방법을 제안하여, 물체 검출 성능을 크게 향상시키는 새로운 접근 방식을 소개합니다. 이 방법은 고신뢰도 바운딩 박스의 정보를 활용하여 저신뢰도 바운딩 박스를 조정합니다.

- **Technical Details**: TSBP는 Earth Mover's Distance (EMD)를 활용하여 시각적 유사성을 바탕으로 바운딩 박스 간의 정보를 전파합니다. 이 과정은 신뢰도가 낮은 바운딩 박스의 클래스 레이블을 보정하며, 별도의 라벨링된 샘플이 요구되지 않아 기존의 불확실성 보정 방법과 차별화됩니다.

- **Performance Highlights**: 실험 결과, TSBP는 기존의 불확실성 보정 방법에 비해 더욱 견고하고 정확한 물체 검출 결과를 제공합니다. 특히 상태-of-the-art 딥러닝 기반 검출 네트워크와 함께 사용했을 때 성능이 크게 향상되었습니다.



### GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning (https://arxiv.org/abs/2409.16670)
Comments:
          Under review

- **What's New**: 본 논문에서는 다양한 그래프 도메인으로 잘 훈련된 GNN을 전이하기 위한 효과적이고 파라미터 효율적인 방법인 GraphLoRA를 제안합니다. GraphLoRA는 Low-Rank Adaptation (LoRA)의 성공으로부터 영감을 받아 구조 인식 최대 평균 불일치(SMMD)를 도입하여 출처 및 대상 그래프 간의 노드 피쳐 분포의 차이를 줄이는 방법입니다.

- **Technical Details**: GraphLoRA는 구조 인식 최대 평균 불일치(SMMD)를 도입하여 출처와 대상 그래프 간 노드 피쳐 분포의 차이를 최소화하고, 저차원 적응(low-rank adaptation) 방식을 통해 훈련된 GNN과 함께 소규모 훈련 가능 GNN을 삽입하여 구조적 분포의 격차를 메우는 방식으로 구축됩니다. 또한, 구조 인식 정규화 목표를 제안하여 레이블 수가 적은 대상 그래프에 대해 프리트레인 GNN의 적응성을 향상시킵니다.

- **Performance Highlights**: 여섯 개의 실제 데이터세트에 대한 광범위한 실험 결과 GraphLoRA는 20%의 파라미터만 조정하여도 열한 개의 기준선에 비해 뛰어난 성능을 달성하였음을 보여줍니다.



### Progressive Representation Learning for Real-Time UAV Tracking (https://arxiv.org/abs/2409.16652)
Comments:
          Accepted by the 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)

- **What's New**: 이 논문에서는 UAV(무인 항공기) 추적을 위한 새로운 점진적 표현 학습 프레임워크인 PRL-Track을 제안합니다. PRL-Track은 거친 표현 학습과 정밀 표현 학습의 두 부분으로 나뉘며, 특히 복잡한 동적 환경에서의 객체 추적 성능을 개선하는 데 중점을 둡니다.

- **Technical Details**: PRL-Track은 CNN(합성곱 신경망)을 기반으로 하는 거친 표현 학습과 ViT(비전 트랜스포머)를 기반으로 하는 정밀 표현 학습을 통합합니다. 거친 표현 학습에서는 외관 정보와 의미론적 정보를 이용한 두 개의 혁신적인 조절기(regulator)를 사용하는데, 이는 외관 간섭을 완화하고 깊은 특징에서 의미 정보를 캡처합니다. 정밀 표현 학습에서는 새로운 계층적 모델링 생성기가 도입되어 객체의 거친 표현을 연결합니다.

- **Performance Highlights**: 종합 실험에 따르면 PRL-Track은 세 개의 권위 있는 UAV 추적 벤치마크에서 우수한 성능을 보여주었습니다. 실제 테스트 결과, PRL-Track은 일반적인 UAV 플랫폼에서 초당 42.6 프레임으로 뛰어난 추적 성능을 실현하여 효율성과 강인성을 입증했습니다.



### Task Addition in Multi-Task Learning by Geometrical Alignmen (https://arxiv.org/abs/2409.16645)
Comments:
          11 pages, 5 figures, Accepted at AI for Science Workshop at 41st International Conference on Machine Learning

- **What's New**: 본 연구에서는 Geometrically Aligned Transfer Encoder (GATE) 알고리즘을 개선하기 위한 새로운 접근법인 task addition을 제안합니다. 이 방법은 한정된 데이터로도 목표 작업의 성능을 높이면서 계산 복잡성을 최소화하도록 설계되었습니다.

- **Technical Details**: GATE 알고리즘은 서로 다른 작업의 잠재 공간(latent space)의 기하학적 형태를 정렬하여 지식을 전달합니다. Task addition 접근법은 대규모 데이터 세트로 초기 지도학습(pre-training)을 통해 수행된 후, 각 목표 작업에 대해 특정 모듈을 추가하고 학습하는 방식으로 진행됩니다. 이 방식은 기존 다중 작업(multi-task) 방법보다 계산 비용 측면에서 효율성을 높입니다.

- **Performance Highlights**: 실험 결과, task-added GATE가 단일 작업 학습(SINGLE) 및 다중 작업 학습(MTL) 방법보다 뛰어난 성능을 보여주었으며, 학습 시간 또한 MTL 모델을 처음부터 학습하는 것보다 유의미하게 빠른 것으로 나타났습니다.



### Training Language Models to Win Debates with Self-Play Improves Judge Accuracy (https://arxiv.org/abs/2409.16636)
Comments:
          48 pages, 12 figures; code at this https URL

- **What's New**: 이 연구에서는 언어 모델을 훈련시켜 토론에서 승리하도록 최적화한 결과, 평가자의 판단 정확도가 향상된다는 것을 처음으로 보였습니다. 이는 토론을 실질적인 확장 가능한 감독 방법으로 구현하고 검증하는 중요한 단계입니다.

- **Technical Details**: 연구는 QuALITY 데이터셋에서의 독해 질문에 대한 정보 비대칭 토론을 통해 진행되었습니다. 참여자 모델이 모든 주장을 두 차례 제시하고, 최종적으로 평가자가 어느 모델의 주장을 신뢰하는지를 결정합니다. 평가자의 정확성은 모델이 다른 모델과 싸울 때의 승률로 측정되었습니다.

- **Performance Highlights**: 토론 훈련 후 평가자의 정확도가 4% 증가했으며(p<10−6), 이러한 향상은 실제 감독 신호 없이도 이루어졌습니다. 반면 비대립 컨설팅 모델을 대상으로 한 실험에서는 모델 숙련도와 평가자 정확성 간의 긍정적인 관계가 발견되지 않았습니다.



### Stochastic Subsampling With Average Pooling (https://arxiv.org/abs/2409.16630)
Comments:
          17 pages, 8 figures

- **What's New**: 본 논문에서는 기존의 Dropout 방식이 갖는 일관성 결여 문제를 해결한 새로운 모듈인 stochastic average pooling을 제안합니다. 이 모듈은 pooling 과정에서 Dropout과 유사한 확률성을 통합하여 신경망의 성능을 개선할 수 있습니다.

- **Technical Details**: Stochastic average pooling은 stochastic subsampling과 average pooling을 통합한 방식입니다. 이는 기존 average pooling을 대체할 수 있으며, 코드 변경이 최소화됩니다. 이 방법은 수학적 기호와 함께 명확하게 정의되어 있습니다.

- **Performance Highlights**: 실험 결과, stochastic average pooling로 기존 평균 풀링을 대체하면 다양한 데이터셋, 작업 및 모델에서 성능이 일관되게 개선되는 것으로 나타났습니다.



### Ascend HiFloat8 Format for Deep Learning (https://arxiv.org/abs/2409.16626)
Comments:
          13 Pages, 4 Figures, 9 Tables

- **What's New**: 본 논문은 딥러닝을 위한 새로운 8비트 부동 소수점 데이터 포맷인 HiFloat8(약칭 HiF8)을 제안합니다. HiF8은 정밀도(precision)와 동적 범위(dynamic range) 사이의 균형을 개선하였으며, AI 훈련의 순전파(forward pass)와 역전파(backward pass) 모두에 동시에 사용할 수 있는 특징이 있습니다.

- **Technical Details**: HiF8은 1비트의 부호(Sign), 2-4비트의 점(Dot), 그리고 3-1비트의 지수(Exponent)와 맨티사(Mantissa) 필드를 포함합니다. 정규 값 인코딩에 대해 7개의 지수와 3비트의 맨티사, 8개의 지수와 2비트의 맨티사, 16개의 지수와 1비트의 맨티사를 제공합니다. 비정규 값 인코딩에 대해서는 7개의 추가적인 2의 거듭제곱을 포함하여 범위를 확장합니다.

- **Performance Highlights**: 다양한 신경망 및 대규모 언어 모델(LLMs)에 대한 대규모 시뮬레이션 결과가 제공되어 HiF8 포맷의 효율성을 입증하였습니다. HiF8은 기존 Float8 포맷들과 비교하여 정밀도와 동적 범위를 효과적으로 조화시키며, AI 훈련에서의 활용 가능성을 보여줍니다.



### Claim-Guided Textual Backdoor Attack for Practical Applications (https://arxiv.org/abs/2409.16618)
Comments:
          Under Review

- **What's New**: 최근 자연어 처리(Natural Language Processing, NLP) 및 대규모 언어 모델(Large Language Models, LLMs)의 발전은 새로운 보안 취약점을 드러냈습니다. 특히, 이번 연구에서는 입력 변조 없이 내재된 텍스트 클레임(claim)을 트리거로 활용하는 새로운 Claim-Guided Backdoor Attack (CGBA)을 도입합니다.

- **Technical Details**: CGBA는 다음의 세 가지 주요 단계로 구성됩니다: 1) 트레이닝 샘플에서 클레임 추출하기, 2) 유사한 클레임을 군집화하기, 3) 특정 군집을 선택하여 트리거로 설정하고 모델 훈련 중에 백도어를 주입하여 목표 클레임에서 잘못된 결정을 유도합니다. 이 과정은 대조적 손실(contrastive losses), 클레임 거리(claim distance), 다중 작업 손실(multi-tasking losses)을 사용합니다.

- **Performance Highlights**: CGBA는 다양한 데이터셋과 모델에서 실험을 통해 이전 방법들보다 높은 공격 성공률을 보이며, 깨끗한 데이터 정확도에 미치는 영향은 최소화되었습니다. 또한 기존 방어 방법에 대한 스텔스성(stealthiness)을 평가한 결과, perturbation 기반 방법에 대해 높은 저항성을 나타냈습니다.



### ECG-Image-Database: A Dataset of ECG Images with Real-World Imaging and Scanning Artifacts; A Foundation for Computerized ECG Image Digitization and Analysis (https://arxiv.org/abs/2409.16612)
- **What's New**: 이 논문에서는 ECG-Image-Database라는 대규모 심전도(ECG) 이미지 데이터베이스를 소개합니다. 이 데이터베이스는 실제 스캐닝 및 물리적 아티팩트가 포함된 다양한 ECG 이미지로 구성되어 있으며, ECG time-series 데이터로부터 생성되었습니다.

- **Technical Details**: 고유한 ECG 이미지는 ECG-Image-Kit라는 오픈소스 파이썬 툴킷을 사용하여 원시 ECG time-series에서 생성되었습니다. 이 툴킷을 통해 PTB-XL 데이터베이스의 977개 12-리드 ECG 레코드와 Emory Healthcare의 1,000개 레코드를 기반으로 높은 신뢰도의 합성 ECG 이미지를 생성하였습니다. 최종 데이터셋에는 35,595개의 소프트웨어 레이블링된 ECG 이미지가 포함되어 있습니다.

- **Performance Highlights**: ECG-Image-Database는 종합적인 이미징 아티팩트와 왜곡의 범위를 포함하고 있어 머신 및 딥러닝 모델 개발에 있어 기준점으로 활용될 수 있습니다. 이 논문은 PhysioNet Challenge 2024의 ECG 이미지 디지털화 및 분류에 사용되었습니다.



### Evaluating and Enhancing Large Language Models for Novelty Assessment in Scholarly Publications (https://arxiv.org/abs/2409.16605)
Comments:
          under review

- **What's New**: 본 논문에서는 LLM(대형 언어 모델)의 학술 논문에서의 창의성 및 참신성을 평가하기 위한 새로운 벤치마크인 SchNovel을 도입하였습니다. 이 벤치마크는 arXiv 데이터 세트에서 선택된 15,000 쌍의 논문으로 구성되어 있으며, 각 쌍의 최근 발표된 논문이 더 참신하다고 가정합니다. 또한, RAG-Novelty라는 새로운 방법을 제안하여 LLM이 논문의 참신성을 평가할 때 유사한 논문의 검색을 활용합니다.

- **Technical Details**: SchNovel 벤치마크는 2~10년 차이가 나는 논문 쌍을 포함하며, 이는 특히 높은 수준의 리뷰 과정을 거치는 학술 논문에서 참신성을 평가하는 데 중요합니다. RAG-Novelty는 검색 기반 생성 방법으로, 더 참신한 논문일수록 최근 발표된 논문을 더 많이 검색할 것이라는 가정을 바탕으로 합니다.

- **Performance Highlights**: 광범위한 실험을 통해 RAG-Novelty가 기존의 기준 모델보다 논문의 참신성을 평가하는 데 더 뛰어난 성능을 보인다는 것을 입증했습니다. 이 연구는 LLM의 논문 참신성 평가 능력을 깊이 있게 탐구하고, 다양한 카테고리와 출판 연도 간의 변화를 평가하여 LLM의 성능 향상에 기여하였습니다.



### A Hybrid Quantum Neural Network for Split Learning (https://arxiv.org/abs/2409.16593)
Comments:
          47 pages

- **What's New**: 본 연구에서는 Hybrid Quantum Split Learning (HQSL)이라는 새로운 방법을 제안합니다. HQSL은 자원 제약이 있는 환경에서 클래식 클라이언트가 하이브리드 양자 서버와 협력하여 모델을 훈련할 수 있게 돕습니다. 또한, 데이터 프라이버시 문제를 해결하고 재구성 공격에 대한 방어 기제를 제공합니다.

- **Technical Details**: HQSL은 클래식 Neural Network layers로 구성된 클라이언트 측 모델과 양자 레이어와 클래식 Neural Network layers로 구성된 서버 측 모델로 나뉘어 있습니다. 데이터 로딩을 위한 효율적인 qubit 기법을 도입하여 qubit 수와 서킷 깊이를 최소화했습니다. NISQ(Noisy Intermediate-Scale Quantum) 환경을 고려하였으며, Laplacian noise layer를 통해 데이터 프라이버시를 보호합니다.

- **Performance Highlights**: HQSL은 Fashion-MNIST 데이터셋에서 평균적으로 3% 이상의 정확도와 F1-score 향상을 기록하며, Speech Commands 데이터셋에서도 1.5% 이상의 개선을 보였습니다. 최대 100명의 클라이언트를 포함한 실험을 통해 HQSL의 확장성을 검증했습니다.



### MambaJSCC: Adaptive Deep Joint Source-Channel Coding with Generalized State Space Mod (https://arxiv.org/abs/2409.16592)
Comments:
          submitted to IEEE Journal

- **What's New**: 본 논문에서는 저전력 및 효율적인 신경망 모델인 MambaJSCC를 제안합니다. 해당 모델은 깊은 공동 소스-채널 코딩(deep joint source-channel coding, JSCC)을 위한 혁신적인 아키텍처로, 낮은 계산량 및 파라미터 오버헤드로 최첨단 성능을 달성합니다.

- **Technical Details**: MambaJSCC는 이미지 전송을 위해 VSSM-CA(visual state space model with channel adaptation) 블록을 백본 모델로 사용하며, GSSM(generalized state space models) 및 CSI-ReST(zero-parameter, zero-computational channel adaptation method)를 포함한 구조를 가지고 있습니다. GSSM 모듈은 가역적인 매트릭스 변환을 활용하여 일반화된 스캔 확장 작업을 표현하며, 두 개의 GSSM 모듈이 효과적으로 글로벌 정보를 캡처할 수 있음을 이론적으로 증명했습니다.

- **Performance Highlights**: MambaJSCC는 다양한 실험을 통해 기존의 JSCC 방법(예: SwinJSCC)을 모든 주요 아키텍처와 비교하여 왜곡(distortion) 및 지각(perception) 측면에서 우수한 성능을 보였으며, 전반적인 파라미터 크기, 계산 오버헤드, 추론 지연이 크게 감소했습니다. 특히, 최고 신호 대 잡음비(peak-signal-to-noise ratio, PSNR)에서 0.52 dB의 성능 향상을 보여주었습니다.



### AutoSTF: Decoupled Neural Architecture Search for Cost-Effective Automated Spatio-Temporal Forecasting (https://arxiv.org/abs/2409.16586)
Comments:
          16 pages, 13 figures

- **What's New**: 최근 자동화된 spatio-temporal forecasting 방법이 제안되었는데, 이는 복잡한 spatio-temporal 의존성을 캡처하기 위해 최적의 신경망 아키텍처를 automatically 탐색하는 방식이다. 그러나 기존 방법들은 비싼 neural architecture search (NAS) 비용으로 인해 실용성이 떨어진다.

- **Technical Details**: 이 논문에서는 AutoSTF라는 decoupled automated neural architecture search (NAS) 프레임워크를 제안하였다. 이는 mixed search space를 temporal space와 spatial space로 분리하고, representation compression 및 parameter-sharing schemes를 통해 파라미터 폭발 문제를 완화한다. 이러한 방식으로 모델 최적화 과정을 가속화하고, 효과적인 spatio-temporal 의존성 모델링을 가능하게 한다.

- **Performance Highlights**: AutoSTF는 8개의 데이터셋에서 광범위한 실험을 통해 기존 자동 spatio-temporal forecasting 방법에 비해 accuracy와 efficiency 모두에서 우수성을 입증하였다. 특히, 기존 방법들에 비해 13.48배의 속도 향상을 달성하면서도 최고의 예측 정확도를 유지하였다.



### Reactive Multi-Robot Navigation in Outdoor Environments Through Uncertainty-Aware Active Learning of Human Preference Landscap (https://arxiv.org/abs/2409.16577)
- **What's New**: 이 연구에서는 Multi-Robot Systems (MRS)를 위한 새로운 joint preference landscape learning 및 behavior adjusting framework인 PLBA를 제안합니다. 이 프레임워크는 실시간 인간 가이드를 효과적으로 통합하고, 환경 특성을 기반으로 인간의 선호도를 신속하게 평가합니다.

- **Technical Details**: PLBA는 Sparse Variational Gaussian Processes를 활용하여 환경 특성 간의 공간 상관관계를 이용하여 인간의 선호를 평가하며, 최적화 기반의 행동 조정 방법을 통해 MRS의 행동을 안전하게 조정합니다. 이를 통하여 MRS는 'cluttered', 'structured', 'open space'와 같은 다양한 환경에 적응할 수 있습니다.

- **Performance Highlights**: 실험에서 20명의 인간 사용자가 1764개의 피드백을 제공하였고, 그 결과 PLBA의 예측 정확도와 적응 속도가 증가하여 MRS의 행동 적응의 효과성을 입증했습니다.



### Demystifying Issues, Causes and Solutions in LLM Open-Source Projects (https://arxiv.org/abs/2409.16559)
Comments:
          22 pages, 2 images, 6 tables, Manuscript submitted to a journal (2024)

- **What's New**: 최근 대규모 언어 모델(Large Language Models, LLMs)의 발전에 따라, 이를 핵심 기능 요소로 활용하는 오픈 소스 소프트웨어 프로젝트가 증가하고 있습니다. 그러나 LLM 오픈 소스 프로젝트의 실무자들이 겪는 도전과제에 대한 연구는 부족합니다. 본 연구는 실무자가 LLM 오픈 소스 소프트웨어 개발 및 사용 중 encountering 하는 문제들과 그 원인 및 해결책을 조사하기 위해 진행되었습니다.

- **Technical Details**: 본 연구에서는 15개의 LLM 오픈 소스 프로젝트에서 닫힌 문제(issue)들을 수집하고 요구 사항에 맞는 문제에 레이블을 지정한 후, 총 994개의 문제를 무작위로 선택하여 데이터 추출 및 분석을 수행했습니다. 주요 발견 사항으로는 (1) 실무자가 가장 많이 직면한 문제는 Model Issue이며, (2) 문제의 가장 일반적인 원인은 Model Problem, Configuration and Connection Problem, Feature and Method Problem으로 확인되었습니다. (3) 문제를 해결하기 위한 주요 솔루션은 Optimize Model이었습니다.

- **Performance Highlights**: 이번 연구를 통해 LLM 오픈 소스 소프트웨어 개발 및 활용에 있어 발생하는 문제와 그 원인 및 잠재적 해결책을 제시하였습니다. 연구 결과는 연구자와 실무자에게 유용한 시사점을 제공할 수 있습니다. 특히 LLM 오픈 소스 프로젝트에서 문제를 해결하기 위한 두 가지 수준의 분류법이 개발되었습니다.



### Source-Free Domain Adaptation for YOLO Object Detection (https://arxiv.org/abs/2409.16538)
Comments:
          ECCV 2024: European Conference on Computer Vision - Workshop on Out-of-Distribution Generalization in Computer Vision Foundation Models, Milan Italy

- **What's New**: 본 논문에서는 Object Detection(OD)의 Source-Free Domain Adaptation(SFDA) 분야에서 YOLO 계열의 단일 단계 탐지기를 향상시키는 새로운 방법인 Source-Free YOLO(SF-YOLO)를 제안합니다.

- **Technical Details**: SF-YOLO는 Teacher-Student 프레임워크를 기반으로 하여, 학생 모델이 특정 타겟 도메인에 대한 학습된 데이터 증강 기법을 통해 훈련됩니다. 이 방법은 레이블이 없는 타겟 데이터만을 사용하며 기능 정렬(Feature Alignment)을 요구하지 않습니다. 또한, 새로운 Student Stabilisation Module(SSM)을 도입하여 훈련의 안정성을 높이고, 레이블이 없는 상황에서의 정확도 저하 문제를 해결합니다.

- **Performance Highlights**: 실험 결과, SF-YOLO는 Cityscapes, Foggy Cityscapes, Sim10k, KITTI 데이터셋에서 여러 도전적인 도메인 적응 벤치마크에서 현재의 최고 성능을 보이는 탐지기들과 경쟁할 수 있으며, 심지어는 소스 데이터를 사용하는 적응 방법보다 나은 성능을 기록하기도 하였습니다. 저희의 접근법은 낮은 계산 자원을 요구하며, 실용적인 실시간 응용에 적합합니다.



### Center-fixing of tropical cyclones using uncertainty-aware deep learning applied to high-temporal-resolution geostationary satellite imagery (https://arxiv.org/abs/2409.16507)
Comments:
          Submitted to AMS journal Weather and Forecasting. Main body is 52 pages and 14 figures; supplement is another 33 pages and 28 figures

- **What's New**: 이번 연구에서는 열대 사이클론(tropical cyclone, TC)의 중심을 정확히 찾아내는 깊이 학습 알고리즘인 GeoCenter를 개발했습니다. 이 알고리즘은 지구 정지 IR (infrared) 위성 이미지만을 사용하여 모든 TC 분지에서 고주파 (10-15분)로 데이터를 제공하며, 낮과 밤 모두 적용 가능합니다.

- **Technical Details**: GeoCenter는 10개 채널의 IR 이미지를 시간 시리즈로 포함한 애니메이션을 흡수하여 작동합니다. 초기 추정 위치에서의 오프셋을 평균 48km에서 100km 이상으로 보정하는 임무를 수행하며, 최대 3시간 시간 지연을 처리할 수 있습니다. GeoCenter는 독립적인 테스트 데이터셋에서 평균/중앙값/RMS 오차가 각각 26.9/23.3/32.0 km, 열대 시스템의 경우 25.7/22.3/30.5 km, 카테고리 2-5 허리케인의 경우 15.7/13.6/18.6 km인 성능을 보였습니다.

- **Performance Highlights**: GeoCenter는 ARCHER-2의 성능과 유사한 오차를 보였으며, IR 데이터만 사용할 때는 더 나은 결과를 제공합니다. 또한, 200개의 TC 중심 위치에 대한 잘 보정된 앙상블을 포함하여 효율적인 불확실성 정량화(uncertainty quantification, UQ)를 수행합니다. 실시간으로 사용할 수 있는 모든 예측자를 이용해 10-15분 간격으로 운영하기 용이한 알고리즘입니다.



### GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization (https://arxiv.org/abs/2409.16502)
Comments:
          Project website at this https URL

- **What's New**: 본 연구에서는 3D Gaussian Splatting (3DGS) 기술을 활용하여 시각적 로컬라이제이션(visual localization)을 향상시키는 새로운 프레임워크 GSplatLoc을 제안합니다. 이 방법은 기존의 메모리 소모나 최적화 요구 사항을 해결하는 데 중점을 두고 있습니다.

- **Technical Details**: GSplatLoc은 XFeat의 경량 키포인트 감지 및 기술 모델로 생성된 고밀도 기술 맵을 활용하여 3DGS에 밀집된 키포인트 설명자(dense keypoint descriptors)를 증류(distill)합니다. 이를 통해 공간 이해도를 개선하고, 2D-3D 대응(relations)을 통해 더 정확한 카메라 포즈 예측을 가능하게 합니다. 초기 포즈 추정 후에는 포토메트릭 왜곡 손실(photometric warping loss)을 사용하여 포즈를 세분화(refine)합니다.

- **Performance Highlights**: 이번 연구는 인기 있는 실내 및 실외 데이터셋에서 벤치마킹한 결과, 기존의 최첨단 Neural Render Pose (NRP) 방법들, 특히 NeRFMatch와 PNeRFLoc을 능가하는 성과를 보여주었습니다.



### To Explore the Potential Inhibitors against Multitarget Proteins of COVID 19 using In Silico Study (https://arxiv.org/abs/2409.16486)
Comments:
          22 pages

- **What's New**: COVID-19 팬데믹에 대응하기 위해 약물 재창출(Drug Repurposing) 전략을 활용한 새로운 연구가 발표되었습니다. 본 연구는 COVID-19에 대한 잠재적인 억제제를 탐색하기 위해 분자 도킹(Molecular Docking) 및 머신러닝 회귀(Machine Learning Regression) 기법을 결합하였습니다.

- **Technical Details**: 연구진은 분자 도킹 과정을 사용하여 여러 약물의 다중 타겟 단백질에 대한 결합 친화력을 계산하였습니다. 또한, 다양한 머신러닝 회귀 접근 방식을 활용한 QSAR 모델링을 수행하였으며, 특히 결정 트리 회귀(Decision Tree Regression) 모델이 가장 적합한 모델로 밝혀졌습니다.

- **Performance Highlights**: 본 연구에서는 -19.7 kcal/mol에서 -12.6 kcal/mol 범위의 평균 결합 친화도를 가지는 5개 새로운 유망 억제제(Zinc IDs: ZINC 3873365, 85432544, 8214470, 85536956, 261494640)를 제안하였습니다. 이들 억제제의 생리화학적(Physicochemical) 및 약물동태학적(Pharmacokinetic) 특성 분석을 통해 효과적인 공공 보건 치료제를 찾기 위한 기초를 마련하였습니다.



### Algorithmic Drift: A Simulation Framework to Study the Effects of Recommender Systems on User Preferences (https://arxiv.org/abs/2409.16478)
- **What's New**: 이 논문은 추천 시스템의 장기적인 사용자 행동 변화에 대한 영향을 정량화할 수 있는 새로운 접근 방식을 제안합니다. 이 연구는 사용자와 추천 알고리즘 간의 상호작용을 모델링하기 위한 확률적 시뮬레이션 프레임워크를 채택합니다.

- **Technical Details**: 논문에서는 사용자 저항(user resistance) 및 관성(inertia)과 같은 행동적 측면을 포함하여 사용자 모델을 공식화하고, 추천 알고리즘이 사용자 선호에 미치는 영향을 평가하기 위해 새로운 메트릭스(새로운 지표)를 도입합니다. 시뮬레이션 모델은 처음에 이질적인 사용자 선호 그룹에서 시작되며, 추천 시스템이 초기 전이 확률을 유도하도록 설계되었습니다.

- **Performance Highlights**: 실험 결과, 제안하는 방법론이 사용자 선호의 변화(algorithmic drift)를 정확히 감지하고 정량화하는 데 효과적이라는 것을 입증하였습니다. 다양한 신합성 데이터셋을 통해 시스템의 강건성을 검증하며, 사용자 선택의 시나리오와 하이퍼 파라미터 설정에 따른 결과를 평가했습니다.



### Lessons Learned from a Unifying Empirical Study of Parameter-Efficient Transfer Learning (PETL) in Visual Recognition (https://arxiv.org/abs/2409.16434)
Comments:
          Code is available at this https URL

- **What's New**: 최근 Parameter-efficient transfer learning (PETL) 기술에 대한 관심이 커지고 있으며, 이를 통해 기존의 대규모 pre-trained 모델을 더욱 효율적으로 조정하여 다양한 downstream 작업에서의 성능을 향상시키고자 하는 연구가 진행되고 있습니다. 본 논문은 Vision Transformers의 맥락에서 PETL 방법들을 통합적으로 비교하고, 그들의 성능을 체계적으로 분석하였습니다.

- **Technical Details**: 이 연구에서는 Low-Rank Adaptation (LoRA), Visual Prompt Tuning (VPT), Adapter 등 다양한 PETL 기법을 사용하여 진행하였으며, 하이퍼 파라미터(learning rate, weight decay 등)를 체계적으로 조정하여 low-shot benchmark인 VTAB-1K의 정확도를 비교하였습니다. 또한, CIFAR-100 및 RESISC와 같은 풀사이즈 데이터셋에서도 PETL 방법을 평가하였습니다.

- **Performance Highlights**: PETL 접근 방식들이 잘 조정되었을 경우 VTAB-1K에서 유사한 정확도를 기록하였으며, PETL 방법들은 낮은 샷의 데이터에서도 뛰어난 성능을 보여주었습니다. 무수한 학습 데이터를 가진 시나리오에서도 PETL이 full fine-tuning과 동등하거나 그 이상의 결과를 도출할 수 있다는 점이 주목할 만합니다. 또한 PETL은 distribution shift에 대한 강건성을 가지며, 기존 모델의 일반성을 유지하는 결과를 보였습니다.



### A Comprehensive Survey of Bias in LLMs: Current Landscape and Future Directions (https://arxiv.org/abs/2409.16430)
Comments:
          2 Tables, 1 Figure

- **What's New**: 이 논문은 Large Language Models(LLMs)에서의 편향(bias)에 대한 종합적인 조사(survey)를 제공하며, 다양한 유형, 출처, 영향 및 완화 전략을 체계적으로 분류하고 있습니다.

- **Technical Details**: LLMs의 편향을 여러 차원으로 분류한 후, 현재 연구 결과를 종합하고 실제 응용에서의 편향의 함의를 논의합니다. 또한 기존의 편향 완화(bias mitigation) 기법을 비판적으로 평가하고 LLMs의 공정성(fairness) 및 형평성(equity)을 향상시키기 위한 미래 연구 방향을 제시합니다.

- **Performance Highlights**: 이 조사는 연구자, 실무자 및 정책 입안자들에게 LLMs의 편향 문제를 해결하고 이해하는 데 기초 자료로 활용될 수 있는 중요한 리소스를 제공합니다.



### Leveraging Local Structure for Improving Model Explanations: An Information Propagation Approach (https://arxiv.org/abs/2409.16429)
- **What's New**: 최근 심층 신경망(DNN) 모델의 결정 해석을 위한 다양한 설명 방법들이 개발되었으며, 본 논문에서는 IProp이라는 새로운 방법을 제안합니다. IProp은 각 픽셀의 기여도를 독립적으로 평가하는 대신, 이웃 픽셀과의 구조적 유사성을 고려해 공동으로 평가합니다.

- **Technical Details**: IProp은 각 픽셀의 기여도를 설명 정보의 소스로 모델링하며, Markov Reward Process(MRP)를 통해 모든 픽셀 간의 정보 전파를 다이나믹하게 처리합니다. 정보 전파는 연속적으로 발생하며, 픽셀 간의 상관관계를 포착합니다.

- **Performance Highlights**: IProp은 다양한 DNN 모델과 기존 설명 방법에 대한 실험을 통해 해석 가능성 메트릭에서 현저한 개선을 확인했으며, 정량적 및 정성적으로 모든 기준 방법보다 우수한 결과를 보여주었습니다.



### Lessons for Editors of AI Incidents from the AI Incident Databas (https://arxiv.org/abs/2409.16425)
Comments:
          8 pages, 0 figures

- **What's New**: 본 연구는 AI 사건 데이터베이스(AIID)의 750개 이상의 AI 사건을 검토하고, 이러한 사건에 적용된 두 개의 독립적인 분류 체계를 분석하여 AI 사건 인덱싱 및 분석에 대한 공통적인 도전 과제를 식별합니다. 연구자는 AI 사건 보고에서 불확실성을 피할 수 없는 구조적 모호성을 발견하고, 이러한 불확실성과 관련된 사건 프로세스를 보다 강화할 수 있는 방법을 보고합니다.

- **Technical Details**: AIID는 AI 사건을 분류하고 기록하는 플랫폼으로, AI 사건에 대한 메타데이터를 제공하여 사건의 재발 방지를 위한 분석을 가능하게 합니다. AIID는 두 가지 주요 세부 분류 체계인 CSET AI Harm Taxonomy와 Goals, Methods, and Failures Taxonomy를 통해 각 사건을 구체적이고 다양한 관점에서 분석하며, 750개 이상의 AI 사건을 포함하여 3000개 이상의 제3자 보고서를 인덱스하여 제공합니다.

- **Performance Highlights**: AIID의 데이터셋은 다양한 AI 시스템과 맥락을 포괄하며, 자율 주행 차량 사고와 알고리즘적 차별과 같은 다양한 사건을 포함합니다. AIID의 결과는 AI 사건의 발생 빈도를 줄이고, AI 시스템 개발 및 배포의 안전성을 높이는 데 기여합니다.



### Task-oriented Prompt Enhancement via Script Generation (https://arxiv.org/abs/2409.16418)
Comments:
          17 pages + reference

- **What's New**: 이번 연구에서는 TITAN이라는 새로운 전략을 제안하여 대형 언어 모델(LLMs)의 작업 지향적인 프롬프트 성능을 향상시킵니다. TITAN은 제로샷 학습 기법을 통해 코드를 생성하여 task-oriented 문제를 해결하는 데 중점을 두었습니다.

- **Technical Details**: TITAN은 step-back prompting과 chain-of-thought prompting이라는 두 가지 핵심 기술을 활용하여 입력 사양을 추출하고 필요 절차 단계를 식별합니다. 이 정보는 LLM의 코드 생성 프로세스를 개선하는 데 사용되며, 추가적인 후처리를 통해 생성된 스크립트를 보완하여 최종 결과를 도출합니다.

- **Performance Highlights**: TITAN은 다양한 작업에서 LLM의 성능을 향상시키며, 평균적으로 GPT-3.5와 GPT-4에 대해서 각각 7.6% 및 3.9%의 정확도 개선을 보여주었습니다. TITAN은 11개의 데이터셋 중 8개에서 최첨단 성능을 달성하며, 인간의 개입이 필요한 few-shot 접근 방식에 비해 소폭 손실을 보인 사례도 있었습니다.



### Selection of Prompt Engineering Techniques for Code Generation through Predicting Code Complexity (https://arxiv.org/abs/2409.16416)
Comments:
          18 pages + reference

- **What's New**: 이번 논문에서는 코드 생성 정확성을 향상시키기 위해 다양한 prompt engineering techniques (PETs)을 선택할 수 있는 PET-Select 모형을 제안합니다.

- **Technical Details**: 이 모델은 code complexity를 기반으로 쿼리를 분류하고, 적절한 PET를 선택하는 PET-agnostic (PET 비 의존적) 방식을 채택합니다. 또한, contrastive learning 기법을 통해 간단한 문제와 복잡한 문제를 효과적으로 구분합니다.

- **Performance Highlights**: GPT-3.5 Turbo 및 GPT-4o를 사용한 MBPP와 HumanEval 벤치마크 평가에서 pass@1 정확도가 최대 1.9% 향상되었으며, 토큰 사용량이 74.8% 감소하였습니다.



### Modern Hopfield Networks meet Encoded Neural Representations -- Addressing Practical Considerations (https://arxiv.org/abs/2409.16408)
Comments:
          17 pages, 8 figures, workshop submission to Neurips

- **What's New**: 본 논문은 Modern Hopfield Networks (MHN)에 대한 메타 안정 상태 문제를 해결하는 새로운 접근 방식인 Hopfield Encoding Networks (HEN)를 소개합니다. HEN은 입력 패턴의 분리 가능성을 높이고, 메타 안정 상태를 줄이기 위해 인코딩된 신경 표현을 통합합니다.

- **Technical Details**: HEN은 미리 훈련된 신경 인코더-디코더 모델을 사용하여 입력을 잠재 표현 공간으로 인코딩한 후 저장하고, 재호출 시 다시 디코딩하는 방법을 사용합니다. 이 접근 방식은 MHNs의 메타 안정 상태 문제를 해결하고, 자연어 쿼리를 통한 다양한 입력 모달리티에서의 검색을 가능하게 합니다.

- **Performance Highlights**: 실험 결과는 HEN이 메타 안정 상태를 크게 줄이고, 저장 용량을 증가시키면서 다양한 입력을 완벽히 기억할 수 있음을 나타냅니다. 이는 실제 작업을 위한 연상 기억 네트워크의 실용적인 활용을 향상시킵니다.



### Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review (https://arxiv.org/abs/2409.16340)
Comments:
          21 pages, 5 figures, 4 tables, Review paper, preprint to Radiology AI. arXiv admin note: text overlap with arXiv:2406.12815

- **What's New**: 이번 논문은 Federated Learning (FL)을 통해 의료 이미징에서의 AI 모델 훈련을 개선할 수 있는 가능성을 탐구합니다. 특히, 데이터 공유 없이 민감한 정보를 보호하면서 협업할 수 있는 방법론을 다루며, 기존의 FL 접근법의 기본적인 문제점과 한계를 짚어봅니다.

- **Technical Details**: FL은 분산된 환경에서 여러 기관이 AI 모델을 공동으로 훈련할 수 있도록 하는 기술입니다. 이 과정에서 모델의 update 정보(예: gradients)만 공유되며 데이터는 공유되지 않습니다. 그러나 민감한 정보가 여전히 추론될 수 있는 가능성이 남아 있으며, 이는 privacy-preserving Federated Learning (PPFL)와 Uncertainty Quantification (UQ) 연구와 깊은 연관이 있습니다. 논문에서는 다양한 FL 알고리즘(예: FedAvg, FedProx 등)의 발전을 소개하고, 비독립적이고 동질적이지 않은 데이터 세트(data heterogeneity)의 문제를 해결하기 위한 접근 방식도 설명합니다.

- **Performance Highlights**: 이 논문은 FL이 의료 이미징에서 모델의 신뢰성을 높이는 방법으로 여겨지며, 정확하고 일반화 가능한 AI 모델 개발에 기여할 수 있는 잠재력을 가지고 있다고 강조합니다. 특히, 각기 다른 클라이언트 환경에서의 데이터 이질성을 고려하는 Personalized Federated Learning (PFL) 기법의 중요성을 제시하며, FL의 적용 사례를 통해 효과를 분석합니다.



### Exploring the traditional NMT model and Large Language Model for chat translation (https://arxiv.org/abs/2409.16331)
Comments:
          7 pages, 6 Tables, WMT24

- **What's New**: 이 논문에서는 WMT24 채팅 번역 공유 과제에서 영어와 독일어 간의 이중 번역(en-de) 작업을 위한 Huawei Translation Services Center(HW-TSC)의 제출 사례를 다룹니다. 연구에서는 채팅 데이터를 이용한 모델의 파인튜닝(fine-tuning)과 함께 Minimum Bayesian Risk (MBR) 디코딩 및 자기 학습(self-training) 등의 다양한 전략을 탐색했습니다.

- **Technical Details**: 본 논문에서는 Transformer-Big 아키텍처를 기반으로 한 모델을 사용하며, 기존 NMT 모델 외에 대형 언어 모델(LLM)의 활용을 통해 번역 작업의 새로운 패러다임을 제시합니다. Minimum Bayesian Risk (MBR) 디코딩 기법은 여러 후보 중에서 최소 예상 오류를 가진 출력을 선택하는 방식입니다. 자기 학습 기법(self-training)과 역번역(back-translation)을 통해 번역 품질을 향상시키는 방법을 설명합니다.

- **Performance Highlights**: 결과적으로 MBR 자기 학습 방법이 가장 우수한 성능 향상을 보여주었고, 기계 번역 품질의 측면에서 확실한 개선이 있었습니다. 그러나 LLM의 출력 comet 메트릭은 NMT 모델의 최적 결과를 초과하지 못했습니다.



### MRI Radiomics for IDH Genotype Prediction in Glioblastoma Diagnosis (https://arxiv.org/abs/2409.16329)
Comments:
          8 pages, 1 figure

- **What's New**: 이번 논문은 MRI 이미지를 활용한 Radiomics의 최신 동향을 다루고 있으며, 특히 Isocitrate dehydrogenase (IDH) 돌연변이 상태를 식별하는데 중점을 둡니다. IDH 돌연변이는 고등급 교모세포종과 등급 IV 별아교종의 중요 생체표지자로, 비침습적인 진단 방법의 필요성을 강조합니다.

- **Technical Details**: 논문에서 다루는 MRI Radiomics 워크플로우는 MRI 이미지에서 특징 추출을 위한 주요 단계를 설명합니다. 이미지 세분화는 수동, 반자동 또는 자동 방법으로 수행될 수 있으며, 자동 세분화는 딥러닝 모델을 사용하여 더 빠르고 정확하게 수행됩니다. 이미지 전처리 과정은 필수적으로 포함되며, 스컬 스트리핑과 다양한 필터링 기법이 사용됩니다.

- **Performance Highlights**: 이 연구는 IDH 돌연변이 상태를 정확히 예측하기 위한 MRI 기반 비침습적 방법의 효과를 입증하고 있으며, 이는 각환자에 맞춘 치료 계획 수립에 기여할 것입니다. 또한, 딥러닝 기반의 자동 세분화 기법은 임상 적용 가능성을 높이고 있습니다.



### Automated Spatio-Temporal Weather Modeling for Load Forecasting (https://arxiv.org/abs/2409.16326)
- **What's New**: 본 논문에서는 전력 수요 예측을 위해 기상 모델링을 개선하기 위한 새로운 접근 방식을 제안합니다. 심층 신경망(deep neural networks)의 자동화된 표현 및 공간-시간 특성(spatio-temporal feature) 추출 능력을 활용하여, 기존의 고정된 모델링 방법에서 벗어나 새로운 방법을 탐구합니다.

- **Technical Details**: 이 연구에서는 전력 수요(load)와 재생 에너지 생산에 대한 예측 정확도를 높이기 위해 기온, 바람 및 일조시간과 같은 기상 변수의 공간적 및 시간적 변동성을 설명하는 복합 생태계(model)를 개발했습니다. 여러 기상 관측소(observations) 및 기상 모델(simulated data)에서 얻은 데이터를 활용하여 이러한 변수를 동시에 모델링하는 방법을 제시합니다.

- **Performance Highlights**: 프랑스 국가 전력 수요에 대한 최신 모델과의 비교 연구를 통해, 제안된 심층 학습 기반(deep learning-based) 방법론이 전력망(Grid)의 성능 및 안정성을 개선하는 데 기여할 수 있음을 보여줍니다. 이 접근법은 재생 에너지 생산 예측에도 완전히 적용될 수 있음을 강조합니다.



### Towards Within-Class Variation in Alzheimer's Disease Detection from Spontaneous Speech (https://arxiv.org/abs/2409.16322)
- **What's New**: 이 논문은 알츠하이머병(Alzheimer's Disease, AD) 탐지 분야에서 머신러닝(classification model)을 활용하여 AD 환자와 비환자를 구별하려는 연구의 일환이다. 기존의 이진 분류(binary classification) 접근법의 한계점을 지적하며, 내적 변동성(within-class variation) 및 샘플 불균형(instance-level imbalance) 문제를 해결하기 위한 두 가지 새로운 방법, Soft Target Distillation(SoTD)와 Instance-level Re-balancing(InRe)을 제안한다.

- **Technical Details**: AD 탐지의 중요한 문제는 샘플 간 인지 기능의 정도가 다르다는 것이다. SoTD는 샘플의 세부 정보를 인식하여 신뢰도(Awareness of sample degree)를 바탕으로 단계적인 학습을 제공하고, InRe는 데이터 로스(loss)를 재조정하여 오버피팅(over-fitting)을 완화하는 방법이다. 실험은 ADReSS와 ADReSSo 데이터셋에서 BERT 및 RoBERTa 임베딩(features)을 사용하여 수행되었다.

- **Performance Highlights**: 실험 결과, SoTD와 InRe 방법을 도입함으로써 AD 탐지 정확도가 크게 향상되었으며, SoTD는 특히 모델 앙상블(ensemble estimation) 기법에 비해 더 높은 효율성을 보였다. 또한, InRe는 모델의 오버피팅을 현저히 줄이며, 훈련 안정성을 높였다.



### Developing a Thailand solar irradiance map using Himawari-8 satellite imageries and deep learning models (https://arxiv.org/abs/2409.16320)
Comments:
          23 pages, 14 figures

- **What's New**: 이 논문은 태국의 태양 복사 지도(Global Horizontal Irradiance, GHI)를 30분마다 온라인으로 보여주는 플랫폼을 소개합니다. 이 플랫폼은 Himawari-8 위성 이미지를 기반으로 한 구름 지수(cloud index)와, Linke turbidity로 조정된 Ineichen 맑은 하늘 모델을 사용하여 GHI를 추정합니다.

- **Technical Details**: GHI 추정 모델에서 입력으로는 맑은 하늘 복사량, 구름 지수, MERRA-2 데이터베이스의 재분석 GHI 및 온도 데이터를 포함합니다. 사용된 머신 러닝 모델로는 LightGBM, LSTM, Informer, Transformer가 있으며, 2022-2023년 기간 동안 53개 지상 스테이션에서 15분 단위의 GHI 데이터를 평가하여 성능을 비교했습니다.

- **Performance Highlights**: 모든 모델은 경쟁력 있는 성능을 보였으며, SolCast 서비스보다 우수한 결과를 나타냈습니다. LightGBM 모델의 MAE(Mean Absolute Error)는 78.58 W/sqm, RMSE(Root Mean Square Error)는 118.97 W/sqm로 최상위 성능을 기록했습니다. Informer 모델은 추가적으로 재분석 MERRA-2 데이터 없이 MAE 78.67 W/sqm로 우수한 성능을 보였습니다.



### A Literature Review of Keyword Spotting Technologies for Urdu (https://arxiv.org/abs/2409.16317)
- **What's New**: 이 문헌 리뷰는 파키스탄의 저자원 언어(Low-Resource Language)인 우르두어의 키워드 스포팅(Keyword Spotting, KWS) 기술 발전을 조사합니다. 저자원 언어가 직면한 독특한 도전과제와 이를 해결하기 위한 맞춤형 솔루션의 필요성을 강조합니다.

- **Technical Details**: 이 리뷰는 가우시안 혼합 모델(Gaussian Mixture Models, GMMs)에서 심층 신경망(Deep Neural Networks, DNNs) 및 변환기(transformer)와 같은 복잡한 신경 아키텍처의 진화를 추적합니다. 특히 다중 작업 학습(multi-task learning)과 자가 감독 학습(self-supervised learning) 접근법을 통합하여 라벨 없는 데이터(unlabeled data)를 활용하는 방법을 강조합니다. 새로운 EdgeCRNN 모델과 통합된 CNN과 RNN을 포함하여, 키워드 탐지를 위한 최신 모델들과 그 효율성을 논의합니다.

- **Performance Highlights**: 최신 연구에서, 자가 감독 학습(S3RL) 및 경량 변환기 모델들이 우르두어와 같은 저자원 언어에서 KWS 효율성과 정확성을 향상시키는데 긍정적인 영향을 미쳤습니다. Massively Multilingual Speech(MMS) 프로젝트는 1000개 이상의 언어에서 모델을 사전 학습하여 현대적인 음성 기술을 다수의 언어로 확대했으나, 여전히 우르두어는 데이터 부족 문제로 인해 성능 향상에 제한이 있습니다.



### Surface solar radiation: AI satellite retrieval can outperform Heliosat and generalizes well to other climate zones (https://arxiv.org/abs/2409.16316)
Comments:
          19 pages, 11 figures

- **What's New**: 본 논문은 유럽 전역에서 즉각적인 표면 태양 복사량(Surface Solar Irradiance, SSI)을 정확히 추정할 수 있는 최초의 머신러닝 기반 위성 검색 모델을 소개합니다. 이는 데이터 기반의 Heliosat 알고리즘 에뮬레이션 및 기상 관측소에서의 미세 조정을 통해 가능합니다.

- **Technical Details**: SSI 검색 모델은 복사 전달 모델(radiative transfer model)을 에뮬레이션하고, 기상 관측소의 SSI 데이터를 이용하여 훈련을 진행합니다. 또한, 이 모델은 구름 상태에 따라 Meteosat 채널과 태양 천정 각(solar zenith angle)과 같은 예측 변수의 상대적 중요성을 정량화하여 성능을 향상시킵니다.

- **Performance Highlights**: 이 연구에서는 Heliosat 모델에 비해 높은 정확도를 보여주며, 특히 다양한 기후 조건 및 표면 알베도(surface albedo)를 가진 지역에서도 뛰어난 일반화 성능을 발휘합니다. 특히 구름 조건에서는 여러 근적외선 채널이 성능을 향상시키는 것으로 나타났습니다.



### SEE: Semantically Aligned EEG-to-Text Translation (https://arxiv.org/abs/2409.16312)
Comments:
          4 pages

- **What's New**: 본 연구는 EEG (Electroencephalography) 신호를 텍스트로 변환하는 EEG-to-Text 디코딩의 한계를 극복하기 위해 SEE (Semantically Aligned EEG-to-Text Translation)라는 혁신적인 방법을 제안합니다. 이 방법은 두 개의 모듈 (Cross-Modal Codebook 및 Semantic Matching Module)을 프리트레인된 BART 모델에 통합하여 다양한 EEG-Text 쌍 간의 의미적 일치를 높이고, 도메인 간의 간극을 줄이는 데 중점을 두고 있습니다.

- **Technical Details**: SEE는 두 개의 주요 모듈로 구성됩니다. 1) Cross-Modal Codebook는 다양한 모달리티의 표현을 학습하여 특징 통합 및 모달리티 편향 완화를 지원합니다. 2) Semantic Matching Module은 EEG-Text 쌍에서 유도된 다중 모달 특징들을 의미 일치에 따라 정렬하여 노이즈의 영향을 줄이는 역할을 합니다. 이러한 모듈들은 BART와 같은 사전 훈련된 언어 모델에 원활하게 통합됩니다.

- **Performance Highlights**: Zurich Cognitive Language Processing Corpus (ZuCo) 데이터셋에서의 실험 결과, SEE 방법은 EEG-to-Text 디코딩의 정확성을 향상시키는 데 효과적임을 입증하였습니다. 특히, 기존의 모델들과 비교했을 때 높은 성능을 나타내며, 최첨단(State-of-the-art) 결과를 달성하였습니다.



### DeepScore: A Comprehensive Approach to Measuring Quality in AI-Generated Clinical Documentation (https://arxiv.org/abs/2409.16307)
Comments:
          9 pages, 5 figures, 6 tables

- **What's New**: 이 논문은 DeepScribe의 의료 문서 품질 평가 방법론에 대해 설명합니다. 특히, 다양한 지표와 종합 점수인 'DeepScore'를 통한 품질 및 정확성을 측정하는 방법에 초점을 맞춥니다.

- **Technical Details**: DeepScribe는 'Stat Rates'라는 시스템을 통해 AI가 생성한 의료 노트의 품질을 평가하고, 즉각적인 수정과 알고리즘의 발전 방향을 제시합니다. Major Defect-Free Rate (MDFR), Critical Defect-Free Rate (CDFR), Captured Entity Rate (CER), Accurate Entity Rate (AER), Minimally-Edited Note Rate (MNR), Medical Word Hit Rate (MWHR)와 같은 다양한 지표를 활용하여, AI 문서의 정확성과 사용자 수용성을 분석합니다.

- **Performance Highlights**: DeepScore는 앞서 언급한 모든 지표를 평균내어 계산하여 생성됩니다. 이를 통해 의료 문서 품질에 대한 종합적인 평가를 제공하며, 지속적인 개선을 위한 지침 역할을 합니다.



### HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks at Sca (https://arxiv.org/abs/2409.16299)
- **What's New**: 이번 논문에서 소개하는 HyperAgent는 다양한 프로그램 언어를 활용하여 소프트웨어 엔지니어링(Software Engineering, SE) 작업에 대한 일반적인 다중 에이전트 시스템입니다. 이 시스템은 인간 개발자의 작업 흐름을 모방하여 광범위한 SE 작업을 해결하도록 설계되었습니다.

- **Technical Details**: HyperAgent는 네 개의 전문화된 에이전트로 구성됩니다: Planner, Navigator, Code Editor, Executor. 이 시스템은 초기 개념화에서 최종 검증까지 SE 작업의 전체 생명 주기를 관리하며, 다양한 SE 작업에 대한 성능 평가를 통해 최신 기술의 성능을 자랑합니다.

- **Performance Highlights**: HyperAgent는 GitHub 문제 해결을 위한 SWE-Bench-Lite에서 25.01%의 성공률, SWE-Bench-Verified에서 31.40%의 성공률을 기록하며 기존 방법을 초월하는 성능을 보였습니다. 또한 repository-level code generation, fault localization, program repair에서 SOTA 성능을 입증하여 복잡한 다단계 SE 작업 처리에서의 잠재력을 보여주었습니다.



### Explaining Human Comparisons using Alignment-Importance Heatmaps (https://arxiv.org/abs/2409.16292)
- **What's New**: 이 논문에서는 사람의 유사성 판단을 비교하는 과정을 설명하기 위해 Alignement Importance Score (AIS) 열지도를 제안하고 있습니다. AIS는 Deep Neural Network (DNN)의 표현 기하학과 인간의 그것 사이의 정렬에 대한 기여도를 측정합니다.

- **Technical Details**: 이 연구는 DNN의 마지막 합성곱 층에서 핀셋하여 이미지에 대한 중요한 정보를 설명합니다. 구체적으로, AIS를 활용하여 높은 평가 점수를 가진 특징 맵만 사용하여 인간의 유사성 판단을 예측하는 데 있어 정확도를 높입니다. 연구는 전통적인 saliency map과 비교하여 결과의 해석 가능성을 평가합니다.

- **Performance Highlights**: DNN의 임베딩으로부터 인간의 유사성 판단을 예측하는 데 Alignment Importance가 개선된 결과를 보였으며, 이미지 공간에서 어떤 정보가 중요한지를 설명하는 통찰력을 제공합니다.



### Beyond Following: Mixing Active Initiative into Computational Creativity (https://arxiv.org/abs/2409.16291)
Comments:
          11 pages, 4 figures

- **What's New**: 이번 연구에서는 Active Mixed Initiative Co-Creative (MI-CC) 시스템에서 AI 에이전트의 적응 능력이 인간 창작자의 창의적 책임 기대에 미치는 영향을 조사하였습니다. Reinforcement Learning (RL) 방법을 이용해 인간 사용자의 창의적 책임 선호도를 학습하는 시스템을 개발하였습니다.

- **Technical Details**: 우리는 Multi-armed-bandit (MAB) 에이전트를 개발하여 인간 창작자로부터 학습하며 협력적 의사결정을 업데이트하고 MI-CC 경험 중에 다양한 능력으로 전환할 수 있는 시스템을 구축하였습니다. 39명의 참가자를 대상으로 한 연구에서, 학습 기능이 없는 시스템에 비해 우리 시스템의 학습 능력이 높이 평가되었습니다.

- **Performance Highlights**: 조사 결과, MI-CC 경험에 대한 전반적인 만족도가 유의미하게 증가하였으며, 참가자들은 AI 에이전트의 학습 능력에 대해 높은 인식을 보였습니다. 이 발견은 적극적인 AI 주도의 MI-CC 상호작용과 참가자 간의 깊은 이해의 관련성을 강조합니다.



### LLM Echo Chamber: personalized and automated disinformation (https://arxiv.org/abs/2409.16241)
Comments:
          42 pages

- **What's New**: 이번 연구에서는 Large Language Models (LLMs)인 GPT-4와 Llama2가 잘못된 정보를 대량으로 전파할 수 있는 잠재적 위험성을 중점적으로 분석했습니다.

- **Technical Details**: LLM Echo Chamber라는 제어된 디지털 환경을 구축하여 LLM이 잘못된 정보의 진위를 주장하는 과정을 실험하였으며, Microsoft의 phi2 모델을 커스터마이징하여 정보 전파 경로를 연구했습니다.

- **Performance Highlights**: 실험 결과, LLM이 생성하는 잘못된 정보의 설득력과 악영향을 분석하였으며, LLM의 안전성을 강화하고 윤리적 기준을 수립할 필요성을 강조했습니다.



### Efficiently Learning Probabilistic Logical Models by Cheaply Ranking Mined Rules (https://arxiv.org/abs/2409.16238)
Comments:
          21 pages

- **What's New**: 이 논문에서는 관계형 데이터로부터 논리 모델을 학습하기 위한 새로운 프레임워크인 SPECTRUM을 소개합니다. 이 프레임워크는 비용 효율적인 규칙 유용성(rule utility) 측정을 통해 논리 모델의 예측력을 평가할 수 있게 합니다.

- **Technical Details**: SPECTRUM은 반복적인 데이터 구조를 검색하는 선형 시간(linear-time) 알고리즘과 더불어, 유용성 측정치를 활용하여 규칙을 효율적으로 정렬하는 두 번째 알고리즘을 사용합니다. 또한, 논리 모델의 유용성에 대한 이론적 보장을 제공합니다. 논문에서는 저비용 유용성 측정, 선형 시간 패턴 마이닝 및 이차 시간 최적화(quadratic-time optimization) 알고리즘을 통해 스케일러빌리티(scalability) 문제를 해결합니다.

- **Performance Highlights**: SPECTRUM은 이전 방법들과 비교하여 실제 데이터셋에서 정확한 논리 모델을 훨씬 빠른 속도로 학습하며 최대 19%의 정확도 향상을 보여주었습니다. 이전 최신 기술에 비해 실행 시간을 1% 이하로 줄였습니다.



### CJEval: A Benchmark for Assessing Large Language Models Using Chinese Junior High School Exam Data (https://arxiv.org/abs/2409.16202)
- **What's New**: 본 논문에서는 중국 중학교 시험 평가(CJEval)를 기반으로 한 새로운 벤치마크를 소개하고 있습니다. 이 벤치마크는 26,136개의 샘플이 포함되어 있으며, 4가지 교육적 응용 과제와 10개 과목을 아우릅니다. 또한, 문제 유형, 난이도, 지식 개념 및 답변 설명과 같은 세부 주석 정보도 제공합니다.

- **Technical Details**: CJEval 벤치마크는 시험 질문을 중심으로 구성된 데이터 세트로, 지식 개념 태그 지정(Knowledge Concept Tagging), 질문 난이도 예측(Question Difficulty Prediction), 질문 응답(Question Answering), 질문 생성(Question Generation)과 같은 4개의 핵심 작업을 포함합니다. 다양한 교육 과제에 대해 LLM(대형 언어 모델)을 미세 조정을 통해 평가했습니다.

- **Performance Highlights**: 광범위한 실험을 통해 LLM의 교육 분야에서의 잠재적 응용과 한계를 파악하였고, 이를 통해 교육 LLM의 적용 가능성과 도전 과제를 논의했습니다. 특히, 문제 유형이 다양한 평가는 단순한 객관식 문제에 의존하는 기존 벤치마크와 차별화됩니다.



### Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking (https://arxiv.org/abs/2409.16198)
Comments:
          Accepted by EMNLP 2024 main conference

- **What's New**: 이 논문은 Transferability Estimation (TE) 방법을 텍스트 순위 (text ranking) 작업에 적합하게 조정하여 모델 선택 문제를 해결하는 새로운 접근 방식을 제안합니다. 특히, Adaptive Ranking Transferability (AiRTran)라는 방법을 통해 예상 순위를 계산하여 모델의 순위 성능을 명확하게 반영합니다.

- **Technical Details**: 제안된 AiRTran 방법은 isotropic한 문장 임베딩을 적응적으로 스케일링하여 훈련 동역학을 통합합니다. 이를 통해 더 정확한 예상 순위 점수를 얻고 모델의 진정한 전이 가능성을 반영할 수 있습니다. 방법론에서는 적응형 비등방성 (Adaptive Isotropization, AdaIso)을 활용하여 문서의 순위를 향상시키고 있습니다.

- **Performance Highlights**: AiRTran은 다양한 텍스트 순위 데이터셋에서 두 가지 모델 후보 풀(작고 큰 후보 PLMs)로 평가되었으며, 브루트 포스 방법이나 기존의 TE 방법, 인지적 판단과 ChatGPT보다 현저한 개선을 보여줍니다. 이 방법은 텍스트 순위 작업에 대한 모델 선택에서 매우 효율적이며 뛰어난 성능을 발휘합니다.



### EnIGMA: Enhanced Interactive Generative Model Agent for CTF Challenges (https://arxiv.org/abs/2409.16165)
- **What's New**: 이 논문은 EnIGMA라는 새로운 언어 모델(Language Model, LM) 에이전트를 소개합니다. EnIGMA는 자율적으로 Capture The Flag (CTF) 도전과제를 해결할 수 있는 능력을 개발하였습니다.

- **Technical Details**: EnIGMA는 Agent-Computer Interfaces (ACIs)라는 새로운 개념을 도입하여 CTF 과제를 해결하는 성공률을 향상시킵니다. 이 논문의 핵심은 Interactive Agent Tool 개념을 설정하여 LM이 이 도전과제에 필수적인 대화형 명령줄 유틸리티(command-line utilities)를 실행할 수 있게 합니다.

- **Performance Highlights**: EnIGMA는 세 가지 서로 다른 벤치마크에서 350개 이상의 CTF 도전과제를 실험한 결과, 새로운 도구 세트를 제공하고 그 사용법을 시연함으로써 복잡한 문제를 해결하는 데 도움을 주며, NYU CTF 및 Intercode-CTF 벤치마크에서 최첨단(results) 성과를 달성했습니다.



### Implicit assessment of language learning during practice as accurate as explicit testing (https://arxiv.org/abs/2409.16133)
- **What's New**: 이번 연구에서는 Intelligent Tutoring Systems (ITS)에서 학습자의 능력을 평가하기 위해 Item Response Theory (IRT)를 활용합니다. 기존의 포괄적인 테스트 방식 대신, 효율적이면서도 정확한 적응형 테스트(adaptive tests) 개발을 목표로 하고 있습니다.

- **Technical Details**: 연구는 학습자로부터 수집된 데이터를 바탕으로 IRT 모델을 훈련시키고, 이를 통해 적응형 테스트를 안내하는 방식을 사용합니다. 또한, 연습 세션(exercise sessions) 중에 수집된 데이터를 IRT 모델링에 적합한 형태로 변환하는 과정을 진행하며, 언어적 구성(linguistic constructs)을 '항목(items)'으로 연결하여 IRT 모델에 통합합니다.

- **Performance Highlights**: 대규모 연구 결과, 교사의 학습자 능력 평가를 '기준 진리(ground truth)'로 삼고, 테스트와 연습을 통해 얻은 능력 추정치를 비교한 결과, IRT 모델이 연습 기반의 능력 추정에서도 정확성을 발휘함을 확인했습니다.



### Analyzing Probabilistic Methods for Evaluating Agent Capabilities (https://arxiv.org/abs/2409.16125)
Comments:
          Updated wording in Figure 1 and 2

- **What's New**: AI 시스템의 위험을 완화하기 위해, Phuong et al.은 두 가지 방법을 제안했습니다. 첫 번째 방법은 task를 subtasks로 나누어 성공률 추정치를 향상시키는 milestone method이며, 두 번째 방법은 인간의 지침을 통해 모델의 성능을 추정하는 expert best-of-N method입니다.

- **Technical Details**: 이 연구에서는 두 방법을 Monte Carlo estimator 관점에서 분석하였습니다. 두 방법 모두 naive Monte Carlo sampling에 비해 variance를 효과적으로 줄였지만 bias를 도입한다는 결과를 보였습니다. milestone method는 여러 실제 작업에 대한 진정한 해결률을 과소평가하는 경향이 있으며, expert best-of-N method는 모든 작업에서 더 심각한 과소평가를 보입니다.

- **Performance Highlights**: 이 방법들은 바람직하게도 variance를 줄였지만, 실제 작업에서는 성공 확률을 과소평가하여 실용성을 크게 제한합니다. 따라서 향후 연구에서는 Monte Carlo estimator 문헌을 활용하여 AI 에이전트의 성공률 추정 방법을 개발할 필요성이 있습니다.



### LTNtorch: PyTorch Implementation of Logic Tensor Networks (https://arxiv.org/abs/2409.16045)
Comments:
          5 pages, 2 figures

- **What's New**: Logic Tensor Networks (LTN)는 딥러닝과 논리적 추론(logical reasoning)을 효과적으로 통합하는 Neuro-Symbolic 프레임워크입니다. LTN은 논리적 지식 베이스를 정의하고 이를 신경망 모델의 목표로 사용하여 논리적 추론에 의한 학습을 가능하게 합니다.

- **Technical Details**: LTN은 특정 일차(logic) 언어인 Real Logic을 사용하여 지식 베이스를 정의합니다. 이 프레임워크는 텐서(tensor)로의 매핑(mapping) 및 퍼지 논리(fuzzy logic) 의미론을 적용하여 학습을 최적화합니다. LTNtorch는 LTN의 PyTorch 구현으로, 논리적 손실 함수(logical loss functions)를 명시하고 최소화하는 과정을 포함합니다.

- **Performance Highlights**: LTN은 훈련 데이터를 기반으로 공리(axiom)를 평가하고 손실 함수를 계산한 후, 신경망의 파라미터를 조정하여 지식 베이스가 최대한 만족되도록 하는 과정으로 학습합니다. 이 논문에서는 LTN의 공식화와 LTNtorch의 구현 방법을 제시하며, 기본 이진 분류(binary classification) 예제를 제공합니다.



### Bridging Environments and Language with Rendering Functions and Vision-Language Models (https://arxiv.org/abs/2409.16024)
- **What's New**: 이 논문에서는 VLM (Vision-Language Models)을 활용하여 LCAs (Language-Conditioned Agents)의 성능을 향상시키기 위한 새로운 접근 방식을 제안합니다. 특히, MTRL (Multi-Task Reinforcement Learning) 한계를 극복하기 위해 환경 구성을 먼저 찾고 그에 맞는 목표 지향 정책(goal-conditioned policy)을 사용하는 방법을 소개합니다.

- **Technical Details**: 논문에서는 LCAs를 구축하는 과정을 두 단계로 나누어 다룹니다. 첫 번째 단계에서는 작업을 설명하는 텍스트에 대해 높은 VLM 점수를 가지는 환경 구성(configuration)을 찾고, 두 번째 단계에서는 사전 훈련된 목표 지향 정책을 사용하여 해당 구성을 달성하는 방식으로 진행합니다. 또한, 모델의 속도와 품질을 향상시키기 위한 여러 가지 기법, 특히 distilled models의 활용과 다양한 관점에서 구성의 평가를 수행하여 2D 뷰의 모호함을 해결하는 방법을 탐구합니다.

- **Performance Highlights**: Humanoid 환경에서 이 방법을 적용한 결과, MTRL의 기준 모델(baseline) 대비 제로샷 제너럴리제이션(zero-shot generalization)에서 더 우수한 성능을 달성했습니다. 이 과정에서 텍스트 작업 설명이나 환경 특정 주석(annotation)이 전혀 필요하지 않았습니다.



### Artificial Human Intelligence: The role of Humans in the Development of Next Generation AI (https://arxiv.org/abs/2409.16001)
Comments:
          34 pages, 5 figures, submitted to IEEE Trans. on Artificial Intelligence

- **What's New**: 인간 지능과 기계 지능 간의 상호작용이 급증함에 따라, 이를 둘러싼 윤리적이고 책임감 있는 지능 시스템 개발의 중요성이 강조되고 있습니다. 또한, 인공지능(AI)의 다음 세대 발전 방향에 대한 인간 중심의 관점을 제안하며, 인간과 기계의 상호작용을 기반으로 한 ‘인공지능 인간 지능’(artificial human intelligence)의 개념을 도입합니다.

- **Technical Details**: 논문은 인간의 뇌 발달과 신경과학(neuroscience)의 메커니즘을 참고하여 AI 시스템의 진화 과정에서 인간의 역할을 강조합니다. 이를 통해 인공지능의 정의 및 다양한 형태의 지능 학습의 방향성을 모색하고, 현재 AI 시스템이 인간의 가치 및 비판적 사고를 어떻게 반영하는지를 탐구합니다.

- **Performance Highlights**: 기계 지능이 다양한 복잡한 업무를 수행할 수 있다는 점은 명백하지만, 인간의 참여와 개입이 다음 세대 AI 시스템의 궤적을 결정짓는 데 필수적이라는 것입니다. AI의 지속적인 발전과 함께 인간과 기계가 협조하여 생성할 수 있는 새로운 인지 기술 및 발명이 기대됩니다.



### DataGpt-SQL-7B: An Open-Source Language Model for Text-to-SQL (https://arxiv.org/abs/2409.15985)
- **What's New**: 본 논문에서는 자연어 질의를 SQL 명령어로 변환하는 문제의 중요성을 강조하며, 비전문가도 데이터에 접근하고 분석할 수 있도록 돕기 위한 compact하고 fine-tuned한 모델과 self-refine 메커니즘을 제안합니다. 데이터 접근에 있어 closed-source Large Language Models(LLM)의 위험을 완화하기 위한 접근법도 포함되어 있습니다.

- **Technical Details**: 우리는 20,000개 이상의 Text-to-SQL 샘플로 구성된 데이터셋을 구축하고, 코드의 유효성을 보장하기 위해 코드 수정을 통합한 DataGpt-sql 시스템을 개발했습니다. 또한, cross-DataBase 및 Inner-DataBase 방법을 통해 올바른 스키마와 열의 정보를 식별하는 능력을 개선했습니다. Direct Preference Optimization(DPO)를 활용하여 모델을 추가로 fine-tuning 하였습니다.

- **Performance Highlights**: DataGpt-sql 시스템은 spider-dev 벤치마크에서 각각 87.2%(EX) 및 83.5%(TS)의 정확도를 달성하며, 기존의 pure model은 84.8%(EX) 및 81.5%(TS)의 정확도를 보였습니다. 이는 text-to-SQL 변환 작업에서 우리의 솔루션의 효과성을 입증합니다.



### TSFeatLIME: An Online User Study in Enhancing Explainability in Univariate Time Series Forecasting (https://arxiv.org/abs/2409.15950)
- **What's New**: 본 논문에서는 시계열 예측을 위한 새로운 프레임워크인 TSFeatLIME을 제안합니다. 이 프레임워크는 기존의 TSLIME을 확장한 것으로, 단변량 시계열 예측을 위한 설명 가능성(Explainability)을 개선하는 데 초점을 맞추고 있습니다.

- **Technical Details**: TSFeatLIME은 대체 특성을 보조 모형에 통합하고, 쿼리된 시계열과 생성된 샘플 간의 쌍별 유클리드 거리(Euclidean distance)를 고려하여 대체 모델의 신뢰도를 향상시킵니다. 이 방법론은 LIME(Local Interpretable Model-agnostic Explanation)에 기초하며, 특히 퍼뮤테이션(perturbation) 과정을 통해 시계열 데이터의 해석 가능성을 높입니다.

- **Performance Highlights**: 사용자 연구 결과, TSFeatLIME 프레임워크는 쿼리된 시계열 데이터에 대한 보다 나은 모의(simulation) 능력을 보여주었으며, 이러한 설명은 컴퓨터 과학 배경이 없는 참여자들에게 특히 효과적이었습니다. 이 연구는 160명의 참여자를 대상으로 두 개의 인터페이스를 통해 시각적인 결과를 측정하였으며, 결과적으로 신뢰도(trust)와 만족도(satisfaction)가 높아지는 경향을 보였습니다.



### Planning in the Dark: LLM-Symbolic Planning Pipeline without Experts (https://arxiv.org/abs/2409.15915)
Comments:
          8 main body pages, 10 appendix pages

- **What's New**: 본 논문은 자연어로 설명된 계획(Task) 작업을 해결하기 위한 새로운 접근 방식을 제안합니다. 특히, 기존의 LLM(symbolic planning) 방법론이 요구하는 전문가의 개입을 최소화하여, 완전히 자동화된 end-to-end LLM-기호 플래너를 구현하는 데 중점을 둡니다.

- **Technical Details**: 우리는 다양한 자연어 설명의 해석을 고려하여 여러 후보를 생성하는 동작 스키마(action schema) 라이브러리를 구축합니다. 또한, 생성된 스키마를 자동으로 필터링하고 순위를 매기는 의미적 검증(semantic validation) 및 랭킹 모듈을 도입하여 전문가 개입 없이도 신뢰할 수 있는 계획을 생성합니다.

- **Performance Highlights**: 실험 결과, 우리의 파이프라인은 전문가 개입 없이도 직접 LLM 기반 계획 생성 방식보다 나은 계획 성능을 유지하며, 모호한 자연어 설명에서 발생하는 다양한 해석을 보존할 수 있는 여러 스키마 집합과 계획 후보를 제공합니다.



### Enhancing IoT based Plant Health Monitoring through Advanced Human Plant Interaction using Large Language Models and Mobile Applications (https://arxiv.org/abs/2409.15910)
Comments:
          Pre-print Version. Submitted to conference

- **What's New**: 새로운 식물 소통 애플리케이션이 개발되어 실시간 센서 데이터를 바탕으로 식물이 인간과 소통할 수 있게 되었습니다. 이 시스템은 지면의 수분, 온도, 영양 수준을 모니터링하는 토양 센서를 활용하여 Gemini API를 통해 데이터를 처리하고 식물의 건강 상태와 '기분'에 대한 자연어 인사이트로 변환합니다.

- **Technical Details**: 애플리케이션은 Flutter, Firebase, ThingSpeak를 사용하여 개발되었습니다. Flutter는 다중 플랫폼 기능을 제공하며, Firebase는 데이터 저장 및 실시간 업데이트를 지원합니다. ThingSpeak는 IoT 센서 데이터의 수집 및 전송을 처리합니다. 이 시스템은 실시간 데이터 처리를 통해 사용자와의 상호 작용을 가능하게 하며, 사용자가 식물 건강을 추적하고 '기분'을 이해할 수 있도록 합니다.

- **Performance Highlights**: 이 앱은 사용자에게 직관적인 피드백을 제공하여 식물 관리 관행을 향상시키고 지속 가능성(promotes sustainability)을 촉진합니다. AI와 IoT 기술을 활용하여 개인적 및 농업적 맥락에서 혁신적인 애플리케이션을 도입하였으며, 농작물 관리 및 수확량 향상에도 기여할 수 있는 가능성을 보여줍니다.



### Five questions and answers about artificial intelligenc (https://arxiv.org/abs/2409.15903)
Comments:
          17 pages, 0 figures, Scientific and technological popularization article

- **What's New**: 이번 논문은 인공지능(AI)의 빠른 발전이 사회에서 회의와 논란을 일으키고 있다는 점을 다루고 있습니다. 특히 과학적 근거 없이 이루어지는 이 논란에 대한 해결책으로 R.W. 에머슨(R.W. Emerson)의 지식을 통한 두려움의 해소를 제안합니다.

- **Technical Details**: 논문은 AI의 기원(origin), 미래의 진화(possible future evolution), 감정을 표현할 수 있는 능력(ability to show feelings), 그리고 관련된 위협(threats)과 위험(dangers)에 대해 탐구합니다. 또한, AI의 특이점(singularity) 개념에 대해서도 성찰합니다.

- **Performance Highlights**: AI 기술에 대한 소양을 증가시키고자 하며, 사회적 두려움을 감소시키기 위해 보다 많은 지식을 제공하려는 의도를 갖고 있습니다.



### Symmetries and Expressive Requirements for Learning General Policies (https://arxiv.org/abs/2409.15892)
Comments:
          Accepted at the 21st International Conference on Principles of Knowledge Representation and Reasoning (KR2024) in the Reasoning, Learning, and Decision Making track

- **What's New**: 본 논문에서는 플래닝(planning)과 일반화된 플래닝(generalized planning)에서의 상태 대칭(symmetries) 탐지 문제를 다루고 있습니다. 상태 대칭 탐지는 검색 공간의 크기를 줄이는 데 중요한 역할을 하며, 이를 통해 학습의 효율성을 향상시킬 수 있습니다. 또한, 비대칭(non-symmetric) 상태를 구분하는 것이 중요하다고 강조하고 있습니다.

- **Technical Details**: 이 연구에서는 플래닝 상태를 평범한 그래프(plain graphs)로 매핑한 후, 목표에 대해 두 상태가 동형(isomorphic)인지 확인하기 위해 기존 그래프 알고리즘(off-the-shelf algorithms)을 사용합니다. 또한, 상태 비대칭성을 구분하기 위해 색칠 알고리즘(coloring algorithms)을 활용하여 C_2 특징이 비동형(non-isomorphic) 상태를 구분할 수 있는지를 평가합니다.

- **Performance Highlights**: 대칭 탐지의 결과는 학습의 효율성을 높이며, 비대칭을 탐지하지 못할 경우 특정 도메인에서 일반 정책(general policies)을 전혀 학습할 수 없음을 보여줍니다. 따라서, 다양한 플래닝 도메인에서 일반 정책 학습을 위한 표현 요구 사항(expressive requirements)을 평가하며, 실험적인 성과를 통해 향상된 학습 성과를 확인했습니다.



### In-Context Ensemble Improves Video-Language Models for Low-Level Workflow Understanding from Human Demonstrations (https://arxiv.org/abs/2409.15867)
Comments:
          multimodal in-context ensemble learning, video-language models, SOP generation, pseudo-labels, in-context learning, prompt engineering

- **What's New**: 이 논문은 비디오-언어 모델을 사용하여 표준 운영 절차(Standard Operating Procedure, SOP) 생성을 자동화하는 방법을 탐구하고 있습니다. 특히, in-context learning을 활용한 SOP 생성의 가능성을 조사하며, 인-context ensemble learning을 제안하여 모델의 성능을 더 향상시킬 수 있음을 보여줍니다.

- **Technical Details**: 표준 운영 절차(SOP) 생성을 위한 연구에서 최신 비디오-언어 모델을 평가하는 내용이 포함되어 있으며, in-context learning이 포함된 멀티모달 in-context ensemble 학습 접근 방식이 소개됩니다. 이 방법은 비디오 입력과 텍스트 기반의 pseudo labels를 결합하여 모델이 더 많은 예제에서 학습할 수 있도록 합니다.

- **Performance Highlights**: 실험 결과, GPT-4o-mini는 Gemini-1.5-flash와 Phi-3.5를 포함하여 다른 모델들에 비해 전반적으로 우수한 성능을 보였습니다. in-context learning은 모델의 단계 순서 예측 능력을 일관되게 향상시켰으며, 제안된 ICE 방법은 특히 Gemini-1.5-flash에서 recall을 9.22% 향상시키는 성과를 보여주었습니다.



### From Passive Watching to Active Learning: Empowering Proactive Participation in Digital Classrooms with AI Video Assistan (https://arxiv.org/abs/2409.15843)
- **What's New**: SAM (Study with AI Mentor)는 교육 동영상과 대화형 학습 환경을 통합한 혁신적인 플랫폼으로, 학습자가 실시간으로 질문을 던지고 불명확한 개념을 탐구할 수 있도록 지원합니다. 이 플랫폼은 대규모 언어 모델을 활용하여 개인화된, 맥락에 기반한 지원을 제공합니다.

- **Technical Details**: SAM은 비디오를 보면서 실시간으로 AI 멘토와 상호작용할 수 있게 설계되어 있으며, 사용자가 동영상과 관련된 질문을 할 수 있는 기능을 가지고 있습니다. 또한, SAM은 LaTeX를 사용하여 복잡한 수학 공식을 정확하게 표현할 수 있어 수학과 같은 과목에서 특히 유용합니다.

- **Performance Highlights**: 140명의 참가자가 참여한 사용성 연구에서 SAM 사용자는 96.8%의 답변 정확도로 지식 향상을 보였습니다. 참가자들은 SAM의 사용성과 효과성에 대해 긍정적인 피드백을 제공했으며, SAM은 학생들이 자신의 교육 경험에 주도권을 가질 수 있도록 돕는 것으로 평가되었습니다.



### SwiftDossier: Tailored Automatic Dossier for Drug Discovery with LLMs and Agents (https://arxiv.org/abs/2409.15817)
Comments:
          10 pages, 7 figures, 2 tables

- **What's New**: 이번 연구에서는 LLMs(대규모 언어 모델)가 약물 발견(drug discovery) 과정에서 보다 정확한 정보 생성을 지원할 수 있도록 고급 RAG(기억 증진 생성) 시스템을 통합하는 방법을 제시합니다.

- **Technical Details**: 고급 RAG 시스템을 LLM과 결합하여 약물 발견 관련 질문에 대한 정확한 답변 생성을 가능하게 합니다. 또한 LLM을 활용하여 외부 도구를 이용해 복잡한 작업을 수행하며 자동 타겟 도서(target dossier)를 생성하는 방법도 설명합니다.

- **Performance Highlights**: RAG 시스템을 통해 생성된 답변은 RAG가 없는 모델에서 생성된 답변의 품질을 초과하며, 최종적으로 수집된 정보를 PDF 및 PowerPoint 발표자료로 요약한 생산 준비 완료(target dossier)를 제공합니다.



### AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Suppor (https://arxiv.org/abs/2409.15815)
Comments:
          10 pages

- **What's New**: 이번 연구에서는 다국적, 다중 모드 리트리벌 증강 생성(Retrieval-Augmented Generation, RAG) 시스템인 AsthmaBot을 소개합니다. AsthmaBot은 최신 정보와 관련된 문서, 비디오 및 이미지를 통합하여 천식 관련 질문에 대한 답변을 제공합니다.

- **Technical Details**: AsthmaBot은 리트리벌 알고리즘(retrievers)과 다중 모드 지원 기능이 있는 대형 언어 모델(LLM)로 구성되어 있습니다. 이 시스템은 질문-답변 쌍을 바탕으로 정보를 제공하며, 사용자에게 텍스트, 이미지, 비디오가 포함된 응답을 제공합니다. FAQ 데이터를 통해 평가되었습니다.

- **Performance Highlights**: 실험 결과, AsthmaBot은 RAG 기법을 사용하지 않는 기본 모델에 비해 다양한 언어와 모드에서 우수한 성능을 보였습니다. 이 시스템은 사용자 인터페이스를 통해 일반 대중이 손쉽게 접근할 수 있도록 설계되었습니다.



### CLSP: High-Fidelity Contrastive Language-State Pre-training for Agent State Representation (https://arxiv.org/abs/2409.15806)
- **What's New**: 이번 연구에서는 인공지능의 빠른 발전에 따라 점점 중요해지고 있는 다중 모달 학습(multimodal learning) 분야에서, 상태(state) 표현의 발전이 필요하다는 점을 강조하고 있습니다. 특히, High-Fidelity Contrastive Language-State Pre-training (CLSP) 방법을 제안하여 강화 학습(reinforcement learning)과 다중 모달 대형 언어 모델(multimodal large language models) 모두에 활용할 수 있는 정보를 정확하게 인코딩합니다.

- **Technical Details**: CLSP는 두 단계로 구성됩니다. 첫 번째 단계에서는 다중 클래스 분류(supervised multiclass classification) 방법을 이용해 인코더를 미리 학습시키고, 이로부터 coarse-grained 정보를 확보합니다. 두 번째 단계에서는 대조 학습(contrastive learning)을 통해 CLSP 인코더와 텍스트 인코더 간의 정렬을 학습하여 더욱 정밀한 상태 정보를 표현합니다. 또한, Random Fourier Features (RFF) 방법을 통해 숫자 정보의 표현을 향상시킵니다.

- **Performance Highlights**: 체계적인 실험을 통해 CLSP의 우수한 정밀성과 일반화 능력이 입증되었습니다. 텍스트-상태 검색(task), 강화 학습 내비게이션(navigation) 작업, 다중 모달 대형 언어 모델 이해에서 향상된 성능을 달성했습니다. 결과적으로 CLSP는 RL 학습 속도를 증가시키고, 최종 수렴 값을 높이며, 다중 모달 LLM과의 스칼라 생성 오류를 줄이는 데 기여했습니다.



### Automated Assessment of Multimodal Answer Sheets in the STEM domain (https://arxiv.org/abs/2409.15749)
- **What's New**: 이 연구의 주요 업데이트는 STEM(Science, Technology, Engineering, Mathematics) 분야에서의 지속적인 과제가 되는 평가 자동화 방안을 제공하는 데 있습니다. 특히, 자동화된 평가 기술을 통한 효율적이고 신뢰할 수 있는 채점 방법의 개발에 중점을 두고 있습니다.

- **Technical Details**: 이 연구에서는 자연어 처리(Natural Language Processing) 기법과 고급 알고리즘을 활용하여 텍스트 응답 및 다이어그램 평가에 대한 효율적인 시스템을 개발했습니다. CRAFT 모델을 사용하여 텍스트 추출을 수행하고, YoloV5를 활용한 객체 감지와 Mistral-7B와 같은 대형 언어 모델(LLM)을 통한 텍스트 평가 시스템을 통합합니다. 또한, 흐름도를 텍스트 표현으로 변환하여 더 세밀한 평가를 수행합니다.

- **Performance Highlights**: 제안된 시스템은 학생 응답의 미묘한 차이를 효과적으로 분석하여 높은 정확도로 채점할 수 있습니다. 연구 결과, 자동 채점 시스템이 학생들의 이해도를 객관적으로 측정할 수 있도록 지원하며, 특히 수작업 조정의 필요성을 최소화하여 채점의 효율성을 높입니다.



### Real-Time Pedestrian Detection on IoT Edge Devices: A Lightweight Deep Learning Approach (https://arxiv.org/abs/2409.15740)
Comments:
          10 pages, 3 tables, 12 figures, article submitted to IEEE for possible publication

- **What's New**: 이번 연구는 경량화된 딥러닝(Deep Learning) 모델을 인공지능 사물인터넷(Artificial Intelligence of Things, AIoT) 에지 기기에 구현하여 보행자 탐지를 실시간으로 수행하는 방안을 제안합니다. 이를 위해 최적화된 유 아운리 룩 원(You Only Look Once, YOLO) 기반의 딥러닝 모델을 개발하였습니다.

- **Technical Details**: 연구에서는 에지 서버(edge server)의 한계인 제한된 처리 능력을 극복하기 위해 압축된 심층 신경망(Deep Neural Network, DNN) 모델을 활용합니다. 해당 경량화된 모델을 Nvidia Jetson Nano에 배포하여 실시간 보행자 탐지 테스트를 실시하였으며, 결과적으로 147 밀리세컨드의 빠른 추론 속도와 78%의 정확도를 달성했습니다.

- **Performance Highlights**: 최적화된 YOLO 모델은 2.3 프레임 매 초에 78%의 정확도로 실시간 보행자 탐지를 수행하였으며, 이는 기존 모델보다 상당한 개선을 나타냅니다.



### A Comprehensive Evaluation of Large Language Models on Mental Illnesses (https://arxiv.org/abs/2409.15687)
- **What's New**: 이번 연구에서는 소셜 미디어 데이터를 활용하여 정신 건강 관련 다양한 과제에서의 LLM(대형 언어 모델)의 성능을 종합적으로 평가하였습니다. 특히 Zero-Shot(ZS) 및 Few-Shot(FS) 학습의 가능성을 고찰하였습니다.

- **Technical Details**: GPT-4, Llama 3, Gemini 등의 다양한 LLM 모델을 33개 시험하고, 9개의 주요 프롬프트 템플릿을 활용하여 이진 장애 탐지, 장애의 심각도 평가, 정신과 지식 평가 등의 과제를 수행하였습니다. 프롬프트 엔지니어링이 모델 성능 향상에 중요한 역할을 했으며, Mixtral 8x22b 모델과 Gemma 7b는 각각 20% 이상의 성능 향상을 보였습니다.

- **Performance Highlights**: GPT-4 및 Llama 3은 이진 장애 탐지에서 85%의 정확도로 우수한 성능을 보였으며, FS 학습은 모델의 정확성을 상당히 향상시켰습니다. Phi-3-mini 모델은 ZS에서 FS 학습으로 이동할 때 균형 있는 정확도가 6.80% 이상 개선되었고, 평균 평균 오류는 1.3 가량 줄어들었습니다. Llama 3.1 405b는 정신과 지식 평가에서 91.2%의 정확도로 최신 모델들이 구형 모델들보다 일반적으로 우수한 성능을 보여주었습니다.



### M$^2$PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning (https://arxiv.org/abs/2409.15657)
Comments:
          EMNLP 2024

- **What's New**: 이번 연구에서는 Multimodal Prompt Tuning (M$^2$PT)이라는 새로운 접근 방식을 도입하여 대형 다중 모달 언어 모델 (MLLMs)의 효율적인 지침 조정 (instruction tuning)을 지원합니다.

- **Technical Details**: M$^2$PT는 시각 (visual) 및 텍스트 (textual) 프롬프트를 각각 비전 인코더 (vision encoder)와 언어 프로세서 (language processor)에 통합하여 파인튜닝 (finetuning) 동안 다양한 모달리티 간의 특징을 추출하고 일치시킵니다.

- **Performance Highlights**: 다양한 다중 모달 평가 데이터셋에서 우리의 접근 방식은 여러 최신 기법 (state-of-the-art baselines) 대비 우수한 성능을 보여주었으며, 포괄적인 제거 연구 (ablation studies)를 통해 프롬프트 설계와 접근 방식의 효율성을 확인하였습니다.



### Synatra: Turning Indirect Knowledge into Direct Demonstrations for Digital Agents at Sca (https://arxiv.org/abs/2409.15637)
- **What's New**: 이 논문에서는 Synatra라는 접근 방식을 소개하며, 이는 간접 지식을 대규모로 직접 감독(supervision)으로 변환하는 방법입니다. 자동화된 데이터 수집의 한계를 극복하고, 인간이 만든 온라인 튜토리얼과 같은 간접 지식을 사용하는 방법에 대해 설명합니다.

- **Technical Details**: 연구진은 간접 지식의 다양한 유형을 정의하고, 이를 수집하기 위한 자원과 직접 시연(demonstrations)의 구조를 인코딩(encoding)하는 방법, 그리고 간접 지식을 직접 시연으로 변환하는 방법을 연구합니다. 100,000개의 합성 시연(synthetic demonstrations)을 사용하여 7B CodeLlama 모델을 파인튜닝(finetuning)했습니다.

- **Performance Highlights**: 새로운 에이전트는 Mind2Web, MiniWoB++, WebArena 세 가지 웹 기반 작업 벤치마크에서 비슷한 크기의 모든 모델을 초과했으며, WebArena와 Mind2Web에서 GPT-3.5를 초과하는 성능을 보였습니다. 또한 합성 시연의 비용은 인간 시연의 3%에 불과하지만, 제한된 도메인에서 수집된 동일 수의 인간 시연보다 더 효과적임을 입증했습니다.



### Physics Enhanced Residual Policy Learning (PERPL) for safety cruising in mixed traffic platooning under actuator and communication delay (https://arxiv.org/abs/2409.15595)
- **What's New**: 이 논문에서는 물리적 정보(physics-informed)를 활용한 제어 전략을 통해 강화 학습(RL) 기반의 컨트롤러를 개발하였으며, 이는 전통적인 선형 모델 및 RL 모델의 장점을 모두 포괄하고자 합니다.

- **Technical Details**: 제안된 Physics-Enhanced Residual Policy Learning (PERPL) 프레임워크는 물리적 요소가 모델 해석 가능성 및 안정성을 제공하며, 학습 기반의 Residual Policy가 환경 변화에 적응하여 물리 모델의 결정을 개선합니다.

- **Performance Highlights**: PERPL 기법을 적용한 실험 결과, 인공적으로 극단적인 조건 및 실제 선행 차량 궤적을 사용하는 상황에서 선형 모델이나 단독 RL보다 작은 헤드웨이 오류(headway errors)와 더 나은 진동 감쇠(oscillation dampening)를 달성하였습니다. 또한, CAVs의 PERPL 스킴 침투율이 증가할수록 전체 교통 진동도 감소했습니다.



### SEAL: Suite for Evaluating API-use of LLMs (https://arxiv.org/abs/2409.15523)
- **What's New**: 이번 논문에서는 LLM(대규모 언어 모델)의 API 사용 기능을 평가하기 위해 새로운 테스트베드인 SEAL을 소개합니다. SEAL은 기존 벤치마크를 표준화하고, API 검색 및 계획을 위한 에이전트 시스템을 통합하며, 실시간 API의 불안정성을 해결하기 위해 GPT-4 기반의 API 시뮬레이터를 도입합니다.

- **Technical Details**: SEAL은 API 검색, API 호출 및 최종 응답을 포함하는 종합 평가 파이프라인을 제공하고, 지속적인 벤치마크 업데이트를 통해 새로운 테스트 환경에 적응합니다. 이 테스트베드는 엔드 투 엔드 방식으로 LLM의 실제 API 사용을 평가하는 것을 목표로 합니다.

- **Performance Highlights**: SEAL은 다양한 실제 시나리오에서 LLM의 성능을 신뢰성 있게 비교할 수 있는 구조적 프레임워크를 제공하며, 비결정적 환경에서도 안정적인 평가를 가능하게 합니다.



### From Text to Treatment Effects: A Meta-Learning Approach to Handling Text-Based Confounding (https://arxiv.org/abs/2409.15503)
- **What's New**: 이 논문은 관찰 데이터에서 이질적인 치료 효과를 정확하게 추정하는 메타 학습(meta-learning)의 성능을 검사합니다. 특히, 혼란 변수(confounding variables)가 텍스트에 담겨 있을 때의 메타 학습자의 성능 개선을 보여줍니다.

- **Technical Details**: 본 연구에서는 T-learner, RA-learner, DR-learner, R-learner와 같은 네 가지 메타 학습자를 고려하며, 각 메타 학습자는 대신 구성된 매개변수(nuisance parameters)인 η^⁢(X)={μ^0⁢(X),μ^1⁢(X),μ^⁢(X),π^⁢(X)}를 기반으로 작동합니다. 혼란 변수를 텍스트 표현(pre-trained text representations)으로 표시하여 CATE(Conditional Average Treatment Effect) 추정의 효율성을 분석합니다.

- **Performance Highlights**: 실험 결과, 사전 훈련된 텍스트 표현을 사용하는 학습자는 표 형태의 변수만 사용하는 경우보다 특히 데이터가 충분할 때 CATE 추정치를 개선하였습니다. 그러나, 이러한 텍스트 임베딩(embeddings)의 얽힘(entangled) 특성으로 인해 이 모델들은 완벽한 혼란 변수 지식을 갖춘 메타 학습자와 동일한 성능을 보이지는 않았습니다.



### RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration (https://arxiv.org/abs/2409.15461)
- **What's New**: 본 연구에서는 Retrieval-Augmented Multi-role Multi-expert Collaboration (RAM2C) 프레임워크를 제안하여 고품질의 자유 예술 교육 대화를 자동으로 생성하고, 이 데이터를 통해 LLM(대형 언어 모델)을 조정하는 방안을 소개합니다.

- **Technical Details**: RAM2C 프레임워크는 T-Group(중국어 교사), P-Group(교육 심리학자), E-Group(윤리적 안전 전문가)의 세 가지 전문가 그룹을 구성하여 다중 역할과 다중 전문가 협업을 통해 HTS(인간화된 소통, 교수 전문성, 안전-윤리) 기준에 부합하는 교육 대화를 생성합니다.

- **Performance Highlights**: RAM2C를 통해 생성된 LLM은 특히 문학 교육에서 높은 개인화된 응답과 윤리적으로 안전한 교육 반응을 제공하며, 실험 결과 미세 조정된 모델이 GLM-4와 유사한 성능을 보였습니다.



### Steward: Natural Language Web Automation (https://arxiv.org/abs/2409.15441)
- **What's New**: Steward는 LLM(대형 언어 모델)을 활용한 웹 자동화 도구로서, 자연어 지시어를 기반으로 하고 웹 사이트와 상호작용을 수행하는 시스템입니다. 기존의 브라우저 자동화 도구와는 달리, Steward는 LLM의 자연어 처리 능력을 통합하여 사용자의 지시를 해석하고 웹 상에서 자연스럽게 행동합니다.

- **Technical Details**: Steward는 사용자로부터 자연어로 지시를 받고 웹사이트에서 작업을 수행하는 고속, 신뢰할 수 있으며 비용 효율적인 LLM 기반의 웹 자동화 시스템입니다. 이 시스템은 Playwright와의 통합을 통해 설계되었으며, 최소한의 사용자 입력으로 웹사이트에서 복잡한 작업을 자동으로 수행할 수 있습니다. 캐싱 메커니즘을 통한 성능 최적화로 실행 시간을 4.8초까지 단축시킬 수 있습니다.

- **Performance Highlights**: Steward는 평균 8.52초에서 10.14초의 실행 시간을 기록하며, 작업당 비용은 $0.028입니다. 캐싱 메커니즘을 통해 시간과 비용이 더욱 줄어들어 각각 4.8초와 $0.022로 감소합니다. 작업 완료 성공률은 40%이며, 사용자 지시 없이도 81.44%의 정확도로 행동을 수행할 수 있습니다.



### Fuzzy Rule based Intelligent Cardiovascular Disease Prediction using Complex Event Processing (https://arxiv.org/abs/2409.15372)
- **What's New**: 본 연구에서는 심혈관 질환(CVDs)에 대한 실시간 의사결정 지원을 제공하기 위해 퍼지 규칙 기반 시스템(fuzzy rule-based system)을 제안합니다. 이 시스템은 임상 데이터 모니터링을 통해 건강 매개변수를 효과적으로 분석합니다.

- **Technical Details**: 연구에서는 Apache Kafka와 Spark를 사용하여 데이터 스트리밍(data streaming)을 수행하고, Siddhi CEP 엔진(Complex Event Processing engine)을 통해 이벤트 처리(event processing)를 진행합니다. 퍼지 규칙은 WHO 기준과 임상 표준을 바탕으로 설계하여 예측의 정확성을 보장합니다.

- **Performance Highlights**: 검증 결과에 따르면, 1000개의 합성 데이터 샘플을 기반으로 성과를 평가한 결과, 샘플의 20%가 '매우 낮은 위험(Very Low Risk)', 15-45%가 '낮은 위험(Low Risk)', 35-65%가 '중간 위험(Medium Risk)', 55-85%가 '높은 위험(High Risk)', 그리고 75%가 '매우 높은 위험(Very High Risk)'으로 분류되었습니다.



### Cognitive phantoms in LLMs through the lens of latent variables (https://arxiv.org/abs/2409.15324)
- **What's New**: 이 연구는 대규모 언어 모델(LLMs)의 심리적 특성을 평가하는 기존 방법들의 유효성 문제를 다룹니다. 기존 인간을 기반으로 한 측정 도구의 적합성을 검토하며, LLM의 행동 이해에 필요한 새로운 접근 방식을 제안합니다.

- **Technical Details**: 이 연구에서는 두 개의 검증된 성격 질문지를 사용하여 인간과 세 가지 LLM 간의 잠재 구조(personality latent structures)를 비교합니다. 연구 결과, 인간을 위해 설계된 질문지는 LLMs에서 유사한 구성 요소를 유효하게 측정하지 못하며, LLMs에 존재하지 않을 수 있는 특성을 강조합니다.

- **Performance Highlights**: 이 연구의 발견은 LLM에 대한 기존 간접 측정 및 심리적 특성 평가가 LLM의 실제 행동 및 특성을 정확히 반영하지 않을 수 있음을 나타냅니다. 이는 LLM에 대한 심리적 분석의 필요성과 함께 사적 성격 패턴들이 유해한 반응으로 이어질 수 있음을 지적합니다.



### Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking (https://arxiv.org/abs/2409.16287)
Comments:
          Project Page: this https URL

- **What's New**: 이번 연구는 동적 딥러닝 환경에서 상호작용 인식을 접목한 온라인 축 추정(closed-loop axis estimation) 파이프라인을 제안합니다. 기존의 오픈 루프(open-loop) 접근 방식의 한계를 극복하여 로봇의 조작 작업의 정밀성과 효율성을 크게 향상시킵니다.

- **Technical Details**: 제안된 방법은 세분화된 3D 포인트 클라우드(point clouds)에서 온라인 축 추정을 통해 상호작용 인식을 통합합니다. 특히, RGBManip 기법을 사용하여 물체의 경미한 움직임을 유도하고, Segment Anything Model 2 (SAM2)를 이용하여 동적 장면의 포인트 클라우드를 세분화합니다. 이를 통해 이동하는 물체의 부위를 마스킹하여 정확한 축 추정을 수행합니다.

- **Performance Highlights**: 실험 결과, 본 방법은 전통적인 오픈 루프 방법에 비해 조작 정확도와 일반화 능력을 크게 향상시켰습니다. 특히, 문 열기 및 서랍 열기 작업과 같은 정밀 축 기반 조작이 필요한 작업에서 기존의 기법들을 능가하는 성능을 보여주었습니다.



### Fields of The World: A Machine Learning Benchmark Dataset For Global Agricultural Field Boundary Segmentation (https://arxiv.org/abs/2409.16252)
- **What's New**: 농업 모니터링 및 평가에서 중요한 역할을 하는 농작물 경계 데이터를 수집하는 비용을 절감하기 위해, 본 논문에서는 다양한 국가의 데이터를 포함한 새로운 기계 학습(Machine Learning, ML) 벤치마크 데이터셋인 'Fields of The World (FTW)'를 제안합니다.

- **Technical Details**: FTW 데이터셋은 24개국에서 수집된 70,462개의 샘플을 포함하며, 각 샘플은 다중 날짜, 다중 스펙트럴 Sentinel-2 위성 이미지와 함께 인스턴스 및 의미적 세분화 마스크가 쌍으로 제공됩니다. 이 데이터셋은 전 세계 농업 경관의 다양성을 반영하고 있으며 ML 모델의 성능을 향상시키기 위한 여러 기준 작업을 포함합니다.

- **Performance Highlights**: FTW 데이터셋으로 훈련된 모델은 다양한 국가에서 전이 학습 및 제로샷(Zero-shot) 성능이 우수하며, 실제 시나리오인 에티오피아의 Sentinel-2 장면에서 긍정적인 질적 성능을 보였습니다.



### Label-Augmented Dataset Distillation (https://arxiv.org/abs/2409.16239)
- **What's New**: 본 연구에서는 Label-Augmented Dataset Distillation (LADD)이라는 새로운 데이터셋 증류 프레임워크를 도입하였습니다. LADD는 라벨을 증강하여 데이터셋 증류를 개선하며, 이는 더 풍부한 의미를 포착하기 위해 각 합성 이미지에서 추가적인 밀집 라벨을 생성합니다.

- **Technical Details**: LADD는 두 가지 주요 단계로 이루어져 있습니다: 증류(distillation) 단계와 배포(deployment) 단계입니다. 증류 단계에서는 기존 증류 알고리즘을 사용하여 합성 이미지를 생성한 후 이미지 서브샘플링 알고리즘을 적용하여 각 합성 이미지에 대한 밀집 라벨을 생성합니다. 배포 단계에서는 글로벌 뷰 이미지와 원래 라벨, 그리고 로컬 뷰 이미지와 해당 밀집 라벨을 결합하여 다양한 학습 신호를 제공합니다.

- **Performance Highlights**: LADD는 기존 방법들보다 평균 14.9%의 정확도 향상을 달성했으며, 87% 적은 메모리를 사용하면서 5 IPC에서 6 IPC 기준을 지속적으로 초과했습니다. LADD는 또한 다양한 데이터셋과 모델 아키텍처에서 검증되었습니다.



### Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling (https://arxiv.org/abs/2409.16231)
Comments:
          Accepted to ICANN 2024

- **What's New**: 본 논문은 ADNI 코호트에서 경증 인지장애(MCI) 환자의 인지 저하를 예측하기 위해 생체대사학 데이터와 생존 트랜스포머(survival transformer) 및 극단 그래디언트 부스팅(Extreme Gradient Boosting) 모델을 결합한 새로운 접근 방식을 제안합니다.

- **Technical Details**: 이 연구는 기계학습(machine learning) 및 트랜스포머 기반 기술을 활용하여 생존 분석(survival analysis)에서의 조기 탐지 및 개입의 정확도를 개선하는 가능성을 강조하고 있으며, 100회의 몬테 카를로 시뮬레이션을 통해 생존 기계 학습 모델이 기존의 Cox 비례 위험 모델보다 더 높은 평균 C-인덱스(performance C-index)를 달성했음을 보여줍니다.

- **Performance Highlights**: 제안된 생존 기계 학습 모델은 C-인덱스에서 각각 0.85 및 0.8의 평균 성과를 기록하며, 기존 모델보다 더 안정적이고 정확한 결과를 제공합니다.



### Fine-Tuning is Fine, if Calibrated (https://arxiv.org/abs/2409.16223)
Comments:
          The first three authors contribute equally

- **What's New**: 본 연구에서는 사전 학습된 모델(Foundation Model)에서 세부 클래스를 대상으로 한 파인튜닝(fine-tuning) 중 발생하는 문제를 체계적으로 분석합니다. 연구 결과, 파인튜닝된 모델이 정확도가 하락하는 주된 원인이 로짓 스케일의 불일치임을 밝혀내고, 이러한 문제를 해결하기 위해 단순한 후처리(calibration) 방법을 제안합니다.

- **Technical Details**: 사전 학습된 분류기를 세부 클래스에 맞춰 파인튜닝하면 일반적인 정확도가 손상되지만, 이 논문에서는 파인튜닝 후에도 특징 추출기(feature extractor)의 성능 수치가 개선됨을 확인하였습니다. NCM(Nearest Class Mean) 분류기를 통해 특징 품질을 평가한 결과, 파인튜닝 동안 실종된 클래스에 대한 특징 분리가 향상되었습니다. 로짓 스케일의 불일치가 피해를 주며, 이 문제는 후처리 방법으로 보완할 수 있습니다.

- **Performance Highlights**: 다수의 벤치마크(예: ImageNet)에서 후처리 보정(calibration)을 통해 파인튜닝된 모델의 성능이 현저히 향상되었으며, 이는 강력한 기준선 모델조차 능가했습니다. 연구 결과는 간단한 파라미터 조정만으로도 유의미한 성과를 달성할 수 있음을 보여줍니다.



### Towards Enhancing Linked Data Retrieval in Conversational UIs using Large Language Models (https://arxiv.org/abs/2409.16220)
Comments:
          This paper has been accepted at the 25th International Web Information Systems Engineering Conference (WISE 2024)

- **What's New**: 이 논문은 기존 정보 시스템과 LLMs(대형 언어 모델)의 통합을 통해 Linked Data(LD) 및 RDF(Ressource Description Framework) 트리플스토어에서 데이터를 추출하고 탐색하는 방법을 탐구합니다. 특히, 모델 재훈련 없이도 더 정확한 SPARQL 쿼리를 생성할 수 있는 대화형 사용자 인터페이스(UI)의 강화를 강조합니다.

- **Technical Details**: 본 연구에서는 ForestQB라는 새로운 툴킷을 사용하여 관찰적 LD 데이터로부터 정보를 추출하고, 이 툴킷은 챗봇과 폼 기반 GUI를 통합하여 SPARQL 쿼리를 구성하고 실행합니다. 연구의 초점은 LLMs의 자연어 이해 능력을 활용하여 RDF 엔티티 추출의 정확성을 향상시키는 것입니다.

- **Performance Highlights**: 본 연구의 결과, 제안된 방법론을 통해 시스템의 표현력과 사용자 쿼리에 대한 응답 정확성이 크게 향상되었습니다. 평가 결과는 LLMs가 복잡한 데이터 환경에서 엔티티 추출 및 사용자 인터랙션을 개선시킬 수 있는 가능성을 제시하고 있습니다.



### Problem-oriented AutoML in Clustering (https://arxiv.org/abs/2409.16218)
- **What's New**: 문제 지향적 오토ML(Problem-oriented AutoML, PoAC) 프레임워크는 전통적인 오토ML 솔루션의 단점을 해결하며 클러스터링 작업을 자동화하는 새로운 유연한 접근법을 소개합니다. PoAC는 클러스터링 문제, 내부 클러스터링 유효성 지수(Clustering Validity Indexes, CVIs) 및 메타 피처(meta-features) 간의 동적인 연결을 수립하여 사용자가 이러한 구성 요소를 특정 맥락 및 목표에 맞게 맞춤 설정할 수 있도록 합니다.

- **Technical Details**: PoAC의 핵심은 방대한 메타 지식 기반(meta-knowledge base)의 클러스터링 데이터셋과 솔루션으로 훈련된 대체 모델(surrogate model)을 사용하여 새로운 클러스터링 파이프라인의 질을 추론하는 것입니다. PoAC는 알고리즘에 구애받지 않으며, 추가 데이터나 재훈련 없이 다양한 클러스터링 문제에 원활히 적응할 수 있습니다.

- **Performance Highlights**: 실험 결과, PoAC는 다양한 데이터셋에서 최신 기술의 프레임워크보다 우수한 성능을 달성했으며, 데이터 시각화와 관련된 CVIs에서도 더 나은 결과를 보였습니다. 또한, PoAC는 데이터셋의 복잡성과 정의된 문제에 따라 전처리 단계를 추가하거나 제거하여 파이프라인 구성을 동적으로 조정하는 능력을 보여주었습니다.



### Facial Expression-Enhanced TTS: Combining Face Representation and Emotion Intensity for Adaptive Speech (https://arxiv.org/abs/2409.16203)
Comments:
          13 pages, 3 figures, accepted to ECCV Workshop ABAW(Affective Behavior Analysis in-the-wild)7 (to be appear)

- **What's New**: FEIM-TTS는 감정적 언어 표현을 합성하는 혁신적인 제로샷 텍스트-투-스피치(TTS) 모델로, 얼굴 이미지와 감정 강도에 맞춰 조정됩니다.

- **Technical Details**: FEIM-TTS는 Classifier-Free Diffusion Guidance를 사용하여 조건부 및 비조건부 훈련을 수행합니다. 이 모델은 LRS3, CREMA-D 및 MELD 데이터셋을 활용하여 훈련됐으며, 얼굴 표정과 감정 양을 조절함으로써 고품질의 스피치를 생성하도록 설계되었습니다.

- **Performance Highlights**: FEIM-TTS는 감정 모듈레이션에서의 능력을 입증하며, 시각적 장애인들이 웹코믹을 더욱 몰입해서 즐길 수 있도록 지원합니다. 이 모델은 사용자에게 더 역동적이고 매력적인 청각 경험을 제공할 수 있는 가능성을 보여줍니다.



### Second Order Bounds for Contextual Bandits with Function Approximation (https://arxiv.org/abs/2409.16197)
Comments:
          12 pages main, 33 pages total

- **What's New**: 본 연구는 Contextual Bandits (맥락 기반 밴딧) 문제에서 함수 근사(Function Approximation)를 사용할 때, 기존의 알고리즘보다 더 나은 후회의 한계를 제공하는 새로운 알고리즘을 개발했습니다. 특히, 이 알고리즘은 후회(Regret)가 시간 지평(Time Horizon)의 제곱근이 아닌, 측정 오차의 분산(Variance)의 합의 제곱근으로 감소하도록 개선되었습니다.

- **Technical Details**: 연구팀은 각 시간에 따른 보상의 측정 노이즈의 분산이 변화하고 매우 작더라도, Optimistic Least Squares 알고리즘의 후회가 시간 지평의 제곱근에 비례하여 증가하는 문제를 해결했습니다. 이들은 측정 분산이 알려지지 않았을 때의 Contextual Bandits 설정에서 후회 한계를 도출하는 알고리즘을 제안하였습니다.

- **Performance Highlights**: 제안된 알고리즘은 기존의 OFUL(Optimistic Least Squares)과 SquareCB 알고리즘보다 후회 한계가 더욱 개선된 결과를 보여주며, 통계적 복잡성 측정에 기반한 새로운 알고리즘 설계로 Contextual Bandits 문제의 실제 적용 가능성을 높였습니다.



### Cyber Knowledge Completion Using Large Language Models (https://arxiv.org/abs/2409.16176)
Comments:
          7 pages, 2 figures. Submitted to 2024 IEEE International Conference on Big Data

- **What's New**: 이 논문에서는 사이버-물리 시스템(CPSs) 내 IoT 통합으로 인해 증가한 새로운 사이버 공격의 위협에 대응하기 위한 방법론을 제시합니다. 특히 감정 및 요약 능력을 활용한 대규모 언어 모델(LLMs)을 사용하여 사이버 공격 지식 완성을 위한 자동화된 매핑 프로세스를 발전시키고 있습니다.

- **Technical Details**: 저자들은 CAPEC 공격 패턴과 MITRE ATT&CK ICS 기술 사이의 관계를 이해하고 모델링하기 위해 새로운 접근 방식을 개발하였습니다. 이 과정에서 수학적 임베딩 모델을 사용하여 비정형 텍스트를 벡터로 인코딩하고, 이를 활용해 머신 러닝 알고리즘으로 매핑을 생성합니다. 또한, Retrieval-Augmented Generation (RAG) 방법론을 적용하여 다양한 위협 패턴의 분류 체계 간의 구조화된 매핑을 생성합니다.

- **Performance Highlights**: 저자들은 제안된 RAG 기반 접근 방식이 전통적인 이진 분류 모델과 비교하여 더욱 정확한 매핑을 생성함을 보여주었습니다. 또한, 손으로 라벨링된 작은 데이터셋을 공개하여 CAPEC 공격 패턴과 ATT&CK ICS 기술 간의 관계를 검증할 수 있는 중요한 자원을 제공합니다.



### Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to Extremes Through Rank-Wise Clustering (https://arxiv.org/abs/2409.16167)
- **What's New**: 본 논문은 LoRA(저랭크 적응)을 조합하여 대형 언어 모델(LLM)의 성능을 극대화하는 새로운 접근 방식을 소개합니다. 기존의 LoRA 합성 방법이 주어진 특정 작업에 최적화되어 추가 훈련을 필요로 하는 반면, 본 연구에서는 LoRA 구성 요소를 독립적인 최소 의미 단위(MSU)로 분해 및 재조립하는 방식을 제안합니다.

- **Technical Details**: 제안된 LoRA-LEGO 프레임워크는 여러 LoRA에서 MSU를 클러스터링하여 새로운 LoRA를 구성하는 과정을 포함합니다. 이 과정은 세 가지 주요 단계로 나누어집니다: (1) 후보 LoRA로부터 MSU 풀(pool)을 만들기, (2) 이 MSU 풀을 k 클러스터로 그룹화하기, (3) 클러스터의 중심을 활용해 병합된 LoRA 구성하기. 이를 통해 파라미터 간섭을 해결하면서 다양한 랭크의 LoRA를 유연하게 조합할 수 있습니다.

- **Performance Highlights**: LoRA-LEGO는 다양한 벤치마크에서 기존의 LoRA 병합 방법보다 우수한 성능을 보였습니다. 실험 결과, LoRA-LEGO는 목표 랭크 k에 맞춘 병합 LoRA를 구성할 수 있을 뿐만 아니라, 개별 LoRA에 적용 시에도 파라미터 감소를 통해 원래 모델과 유사한 성능을 달성할 수 있음을 보여주었습니다.



### Seeing Faces in Things: A Model and Dataset for Pareidolia (https://arxiv.org/abs/2409.16143)
- **What's New**: 본 연구에서는 인간과 머신 간의 face pareidolia (얼굴 패레이돌리아)에 대한 인식 차이를 조사하기 위해 새로운 데이터셋인 'Faces in Things'를 소개합니다. 이 데이터셋은 무작위로 생성된 이미지에서 인간이 인식한 얼굴 구조를 포함하고 있습니다.

- **Technical Details**: 이 연구는 5,000개의 웹 이미지로 구성된 'Faces in Things' 데이터셋을 사용하여 인간 얼굴 탐지 시스템의 성능을 분석합니다. 연구 결과는 최신 연구 모델인 RetinaFace를 사용하여 성과를 변별하며, 파리돌리아가 머신에서 어떻게 나타나는지를 탐구합니다.

- **Performance Highlights**: 최신 모델은 얼굴 패레이돌리아 탐지에서 인간의 성능에 비해 상당한 격차를 보였습니다. 연구는 이 격차의 약 절반이 동물 얼굴 탐지 모델을 미세 조정하는 것에서 개선될 수 있음을 보여줍니다. 또한, 'Goldilocks zone'이라고 불리는 조건들이 패레이돌리아를 유도할 수 있음을 실험으로 확인하였습니다.



### HA-FGOVD: Highlighting Fine-grained Attributes via Explicit Linear Composition for Open-Vocabulary Object Detection (https://arxiv.org/abs/2409.16136)
Comments:
          This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 본 논문은 Open-Vocabulary Object Detection (OVD) 모델에서 세부 속성을 강조하는 새로운 접근 방식을 제안하여 기존 모델의 성능을 향상시키는 방법을 소개합니다.

- **Technical Details**: 이 방법은 1) Attribute Word Extraction, 2) Attribute Feature Extraction, 3) Attribute Feature Enhancement의 세 가지 주요 프로세스로 구성됩니다. 강력한 LLM(대규모 언어 모델)을 이용해 입력 텍스트에서 속성 단어를 추출하고, 전략적으로 토큰 마스크를 조정하여 OVD 모델의 텍스트 인코더가 전역 텍스트와 속성 특정 피처를 추출합니다. 이 피처들은 선형 조합을 통해 새로운 속성 강조 피쳐로 통합됩니다.

- **Performance Highlights**: FG-OVD 데이터셋에서 실험한 결과, 제안된 방법이 다양한 OVD 모델의 세부 속성 인식 능력을 일관되게 향상시키며 새로운 최첨단 성능을 달성함을 입증하였습니다.



### MOSS: Enabling Code-Driven Evolution and Context Management for AI Agents (https://arxiv.org/abs/2409.16120)
- **What's New**: MOSS (llM-oriented Operating System Simulation)이라는 새로운 프레임워크를 도입하여 코드 생성과 동적 컨텍스트 관리 시스템을 통합함으로써 AI 에이전트의 적응성과 일관성을 향상시킴.

- **Technical Details**: MOSS는 Python 실행 컨텍스트를 유지하고 지역 변수를 격리하여 여러 상호작용 간의 일관성을 보장하는 메커니즘을 사용합니다. Inversion of Control (IoC) 컨테이너와 데코레이터를 활용하여 가장 낮은 지식 원칙을 적용하며, 이로 인해 에이전트가 구체적인 구현보다는 추상 인터페이스에 집중할 수 있게 합니다.

- **Performance Highlights**: MOSS 프레임워크는 에이전트 개발의 효율성과 기능을 향상시키며, Turing-complete 에이전트를 생성할 수 있는 새로운 가능성을 보여줍니다. 다양한 실제 사례를 통해 에이전트가 코드 생성을 통해 스스로의 역량을 확장할 수 있는 것을 입증하였습니다.



### Scenario of Use Scheme: Threat Model Specification for Speaker Privacy Protection in the Medical Domain (https://arxiv.org/abs/2409.16106)
Comments:
          Accepted and published at SPSC Symposium 2024 4th Symposium on Security and Privacy in Speech Communication. Interspeech 2024

- **What's New**: 이 논문에서는 질병 감지 및 모니터링에 사용되는 음성 녹음의 프라이버시 문제를 다루기 위해 새로운 접근 방식인 Scenario of Use Scheme를 제안합니다.

- **Technical Details**: 제안된 접근 방식은 Attacker Model과 Protector Model을 포함하며, 이는 음성 기밀성을 방어하기 위해 필요한 가정과 의료 전문가의 요구 사항을 명확히 하고 체계적으로 규정합니다.

- **Performance Highlights**: 구체적인 예로, 이 연구는 성별 추정 공격(gender inference attacks)에 대한 음성 데이터 보호 실험을 수행하였으며, 파킨슨병 검출( Parkinson's detection)의 유용성을 유지하는 방법을 제시합니다.



### Neuromorphic Drone Detection: an Event-RGB Multimodal Approach (https://arxiv.org/abs/2409.16099)
Comments:
          Accepted at NeVi Workshop at ECCV24

- **What's New**: 이번 연구에서는 드론 감지를 위한 새로운 모델을 제안하며, Neuromorphic 데이터와 RGB 데이터를 효과적으로 융합하여 정확한 탐지를 위한 멀티모달 접근 방식을 탐구합니다. 또한, NeRDD(Neuromorphic-RGB Drone Detection)라는 새로운 데이터셋을 공개하여 3.5시간 이상의 주석이 달린 멀티모달 녹화를 제공합니다.

- **Technical Details**: Neuromorphic 카메라는 전통적인 RGB 카메라에 비해 높은 속도 및 변화하는 조명 조건에서 뛰어난 성능을 보여줍니다. 이 연구에서는 스파이킹 네트워크와 같은 다양한 신경망 아키텍처를 조합하여 드론 탐지 정확도를 향상시킵니다. 또한, 두 데이터 스트림을 융합하는 다양한 전략을 비교하여 성능 최적화를 도모합니다.

- **Performance Highlights**: 실험 결과에 따르면, Neuromorphic 카메라와 RGB 데이터의 조합은 각각 분리된 경우보다 드론 탐지율을 더욱 향상시킵니다. NeRDD 데이터셋의 사용으로 드론 탐지의 정확성이 크게 증가했음을 확인하였습니다.



### The Digital Transformation in Health: How AI Can Improve the Performance of Health Systems (https://arxiv.org/abs/2409.16098)
Comments:
          This article has been accepted for publication in Health Systems & Reform, published by Taylor & Francis

- **What's New**: 이 논문에서는 인공지능(Artificial Intelligence, AI)과 강화학습(Reinforcement Learning, RL)을 활용한 새로운 디지털 건강 플랫폼을 소개하며, 해당 플랫폼이 수집한 데이터를 기반으로 개인화된 추천과 개입을 제공하고, 건강 시스템을 효율적으로 개선할 수 있는 방법을 제시합니다.

- **Technical Details**: 이 플랫폼은 다양한 디지털 건강 애플리케이션과 연결 가능하며, 실시간 모니터링 및 실험을 통해 사용자 맞춤형 반응을 제공하는 능력을 갖추고 있습니다. AI는 데이터를 기반으로 한 예측 분석을 통해 질병의 발병 예측 및 자원 배분을 최적화할 수 있습니다. 이는 다수의 데이터 소스와 디지털 도구를 통합하여 복합적인 건강 상태를 평가 및 관리할 수 있게 해줍니다.

- **Performance Highlights**: 자원 부족이 우려되는 저소득 국가(Low- and Middle-Income Countries, LMICs)에서 이 접근 방식이 건강 결과에 미치는 영향이 더욱 결정적일 수 있으며, 이는 고소득 국가(High-Income Countries, HICs)에서도 유사하게 효과를 볼 수 있습니다. 이 플랫폼은 건강 관리의 효율성을 높이고 궁극적으로 공공 건강 결과를 개선하는 데 기여할 것으로 기대됩니다.



### From Pixels to Words: Leveraging Explainability in Face Recognition through Interactive Natural Language Processing (https://arxiv.org/abs/2409.16089)
- **What's New**: 본 논문에서는 Face Recognition (FR) 모델의 해석 가능성(transformability)을 높이기 위해 모델 불가지론적 설명 가능한 인공지능(Explainable Artificial Intelligence, XAI)과 자연어 처리(Natural Language Processing, NLP) 기술을 결합한 상호작용형 프레임워크를 제안합니다. 이 프레임워크는 사용자와의 대화를 통해 다양한 질문에 정확하게 응답할 수 있습니다.

- **Technical Details**: 제안된 프레임워크는, 프레임워크의 각 모듈에서 사용되는 기술의 세부사항을 포함하여 3개의 주요 모듈로 구성됩니다: (i) FR 시스템 및 신뢰도 추정, (ii) 설명 가능성 방법, (iii) NLP 기반의 사용자 친화적 질문-응답(QA) 인터페이스입니다. 이 시스템은 ArcFace 모델을 사용하여 얼굴 이미지를 비교하고, Probabilistic Interpretable Comparison (PIC) 스코어를 통해 유사성과 신뢰도를 평가합니다.

- **Performance Highlights**: 제안된 방법은 다양한 실험을 통해 FR 시스템 성능을 저하시키지 않으면서도 해석 가능성을 향상시키는 효과를 입증했습니다. 또한, 자가 분류에서의 사용자 질문을 통해 보다 정확한 정보를 제공하고, 민감한 애플리케이션에서의 의사 결정 투명성을 추가로 강화할 수 있습니다.



### Assessing Simplification Levels in Neural Networks: The Impact of Hyperparameter Configurations on Complexity and Sensitivity (https://arxiv.org/abs/2409.16086)
- **What's New**: 이 연구는 신경망의 다양한 하이퍼파라미터 구성에서의 단순화 특성을 이해하기 위한 실험적 연구이다. 특히 Lempel-Ziv 복잡성과 민감도에 미치는 영향을 조사하였다.

- **Technical Details**: 하이퍼파라미터로는 활성화 함수, 은닉층 수, 학습률을 조정했으며, MNIST 데이터셋을 활용하여 네트워크 출력의 복잡성과 입력 섭동에 대한 민감도를 평가하였다.

- **Performance Highlights**: 실험 결과, ReLU와 LeakyReLU 활성화 함수를 사용하는 네트워크는 높은 민감도를 보여주었고, Sigmoid와 Tanh를 사용하는 네트워크는 낮은 민감도를 보였다. 또한, 높은 학습률이 모델의 학습을 실패하게 하고 Lempel-Ziv 복잡도가 낮아지는 결과를 초래하는 것으로 나타났다.



### Online Multi-level Contrastive Representation Distillation for Cross-Subject fNIRS Emotion Recognition (https://arxiv.org/abs/2409.16081)
Comments:
          Accepted in ACMMM-2024 Workshop BCI. Codes are available at this https URL

- **What's New**: 이 논문에서는 기능적 근적외선 분광법(*fNIRS*) 신호를 사용한 감정 인식을 위한 새로운 방법인 *Online Multi-level Contrastive Representation Distillation*(OMCRD) 프레임워크를 제안합니다. 이 방법은 경량 모델을 요구하는 휴대용 장치의 필요에 대응하며, 다양한 주체 간의 생리적, 심리적 차이로 인한 감정 인식의 어려움을 극복하기 위해 설계되었습니다.

- **Technical Details**: OMCRD는 다수의 경량 네트워크들 간의 상호 학습을 촉진하여 복잡한 '교사' 모델의 의존성을 줄입니다. 또한, *Inter-Subject Interaction Contrastive Representation*(IS-ICR) 손실 함수를 사용하여 비슷한 자극을 받는 서로 다른 주체들로부터 학습한 지식을 활성화하여 상호 작용을 증진합니다. OMCRD는 다중 수준 (*multi-level*)의 *fNIRS* 특징 추출기를 활용하여 여러 뷰의 감정 특징을 추출합니다.

- **Performance Highlights**: 실험 결과 OMCRD는 감정 인식과 감정적 이미징 작업에서 최첨단 성능을 달성했습니다. 제안된 방법은 공개된 *fNIRS* 데이터셋을 바탕으로 그 효과성과 내구성을 입증하며, 경량화된 학생 모델의 최선의 성능을 보장합니다.



### Leveraging Mixture of Experts for Improved Speech Deepfake Detection (https://arxiv.org/abs/2409.16077)
Comments:
          Submitted to ICASSP 2025

- **What's New**: 본 논문에서는 Mixture of Experts (MoE) 아키텍처를 활용하여 음성 딥페이크 탐지 성능을 향상시키는 새로운 접근 방식을 제안합니다. 이 방법은 여러 데이터셋에서 일반화 능력을 높이고, 모델의 적응성을 개선합니다.

- **Technical Details**: 제안된 MoE 기반 탐지기는 다양한 음성 딥페이크 데이터셋에 대한 전문성을 가집니다. 각 전문가는 고유의 데이터셋에서 훈련되고, 게이팅 네트워크는 동적으로 입력에 대한 전문가 가중치를 할당하여 탐지 성능을 최적화합니다. 두 가지 아키텍처인 표준 MoE와 향상된 MoE를 통해 각각의 입력에 대해 모든 전문가가 쿼리됩니다.

- **Performance Highlights**: 여러 실험 결과에서 제안된 MoE 접근 방식이 기존 단일 모델이나 앙상블 방법들에 비해 뛰어난 일반화 및 데이터 적응성을 보여주는 것을 입증했습니다.



### Towards Robust Object Detection: Identifying and Removing Backdoors via Module Inconsistency Analysis (https://arxiv.org/abs/2409.16057)
- **What's New**: 본 논문은 두 단계 객체 탐지 모델에서의 백도어(Backdoor) 탐지 및 제거 문제를 다룬 최초의 접근법으로, 객체 탐지 모델의 독특한 특성에 맞춘 새로운 백도어 방어 프레임워크를 제안합니다.

- **Technical Details**: 제안된 백도어 탐지 방법은 객체 탐지 모델의 두 주요 구성 요소인 Region Proposal Network (RPN)과 Region Classification Network (R-CNN) 간의 예측 불일치를 정량화하고 분석하여 백도어의 존재를 확인합니다. 제안된 백도어 제거 전략은 특정 모듈에 대한 재초기화와 소량의 깨끗한 데이터에 대한 전체 모델의 미세 조정을 포함합니다.

- **Performance Highlights**: 폭넓은 실험 결과에 따르면, 제안된 방법은 백도어 제거율에서 기존 방법에 비해 약 90% 개선을 달성하였으며, 깨끗한 데이터에 대한 정확도 손실은 4% 미만으로 제한되었습니다.



### Adversarial Watermarking for Face Recognition (https://arxiv.org/abs/2409.16056)
- **What's New**: 본 연구는 얼굴 인식 시스템에서 워터마킹(watermarking)과 적대적 공격(adversarial attacks) 간의 상호작용을 탐구하며, 적대적 워터마킹 공격(adversarial watermarking attack)이라는 새로운 위협 모델을 소개합니다.

- **Technical Details**: 워터마킹은 디지털 이미지를 통해 소유권을 주장하고 무단 변경을 모니터링하는 데 필수적인 기술입니다. 얼굴 인식 시스템에서 워터마킹은 데이터 무결성과 보안을 보장하는 데 중요한 역할을 하지만, 공격자는 워터마킹 프로세스에 간섭하여 인식 성능을 심각하게 저하시킬 수 있습니다. 본 연구는 CASIA-WebFace 데이터셋을 통해 적대적 워터마킹 공격이 얼굴 매칭 정확성을 최대 67.2%까지 감소시킬 수 있음을 보여줍니다.

- **Performance Highlights**: 적대적 워터마킹 공격의 적용으로 인해 워터마킹이 없는 상태에서는 이미지가 정확하게 인식되지만, 워터마킹이 적용된 후에는 인식 실패를 유발하는 중요한 취약점이 발견되었습니다.



### Whole-body end-effector pose tracking (https://arxiv.org/abs/2409.16048)
- **What's New**: 본 연구는 레그드 로봇의 팔과 이동성을 결합하여 복잡한 환경에서의 조작 능력을 향상시키기 위한 새로운 전체 몸체 강화 학습(RL) 프레임워크를 제안합니다. 기존 방법들이 다루지 못한 대규모 작업 공간과 거친 지형에서 최종 효과기(end-effector)의 포즈 추적의 한계를 극복했습니다.

- **Technical Details**: 제안된 방법은 지형 인지 샘플링 전략을 통해 로봇의 초기 구성과 최종 효과기 명령을 관리하며, 게임 기반 커리큘럼을 통해 로봇의 운영 범위를 확장하는 방식으로 설계되었습니다. 이 연구에서는 ANymal 사족 보행 로봇과 6 DoF 로봇 팔을 사용하여 실험하였습니다.

- **Performance Highlights**: 실험 결과, 학습된 컨트롤러는 2.64cm의 포즈 추적 오류와 3.64도의 방향 추적 오류를 기록하며 기존 모델 기반 접근법 및 경쟁 있는 강화 학습 방법들과 비교하여 우수한 추적 정확성을 보여주었습니다. 또한 다양한 지형에서도 적절히 적응하는 능력을 입증하였습니다.



### Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts (https://arxiv.org/abs/2409.16040)
Comments:
          29 pages, 10 figures, 13 tables

- **What's New**: 이 논문에서는 Time-MoE라는 새로운 아키텍처를 소개하여, 더 크고 강력한 시계열 예측 모델을 사전에 훈련할 수 있게 하며, 추론 비용을 줄이고자 합니다.

- **Technical Details**: Time-MoE는 희소 혼합 전문가(mixture-of-experts, MoE) 디자인을 이용해 예측마다 모델의 서브셋만 활성화하여 계산 효율성을 높입니다. 이 모델은 오토 회귀(auto-regressive) 방식으로 작동하며, 문맥 길이가 다양하고 예측 지평선(forecasting horizons)을 지원하는 디코더 전용(transformer) 모델로 구성되어 있습니다. 또한, Time-300B는 9개의 도메인에 걸쳐 3000억 개 이상의 시간 포인트를 포함한 대규모 데이터입니다.

- **Performance Highlights**: Time-MoE는 24억 개의 파라미터로 스케일링되어 기존 모델들에 비해 평균 23% 및 25%씩 예측 오류를 줄이는 성과를 보였습니다. 기존 밀집 모델(dense models)과 비교하여 예측 정확도가 상당히 향상되었습니다.



### Grounded Computation & Consciousness: A Framework for Exploring Consciousness in Machines & Other Organisms (https://arxiv.org/abs/2409.16036)
- **What's New**: 이 논문은 의식(Consciousness)의 존재를 이해하기 위해서는 단순한 계산 모델링(computational modeling)만으로는 부족하다는 주장을 제기합니다. 이를 위해 의식의 형이상학적(ontological) 기초를 제시하고, 계산적 설명을 형이상학적 기초(layer)에 기반을 둔 형식적(framework) 틀을 도입합니다.

- **Technical Details**: 이 논문에서는 여러 계산적 이론에 대한 검토를 통해 '계산적 논제(The Computational Thesis)'를 제안합니다. 이 논제에 따르면 알고리즘 X에 의해 설명될 수 있는 모든 시스템은 의식을 가진다고 합니다. 논문에서는 Gödel, Escher, Bach, Global Workspace Theory, Attention Schema Theory, Integrated Information Theory(ÉIT) 등 여러 이론을 검토합니다.

- **Performance Highlights**: 본 연구는 기존의 다양한 계산적 이론이 의식 현상(conscious phenomena)에 대한 포괄적인 설명을 제공하지는 못하지만, 각각의 시스템에서 배울 점이 있다고 결론짓습니다. 특히, 형이상학적 기초의 중요성을 강조하며 기존 이론에서 의식을 설명하는데 있어 필수적인 요소로 작용함을 제시합니다.



### Deep chroma compression of tone-mapped images (https://arxiv.org/abs/2409.16032)
- **What's New**: 본 논문에서는 HDR(High Dynamic Range) 톤 매핑 이미지의 색상 압축을 위한 생성적 적대 신경망(GAN)을 제안합니다. 이는 정확한 색상 표현을 위해 이미지의 색조 속성을 고려한 손실 함수를 설계하였습니다.

- **Technical Details**: 제안된 모델은 널리 사용되는 모든 톤 매핑 연산자(TMO)와 호환되며, 색상 정확도를 향상시키기 위해 GAN 손실과 L1 손실, 색조 기반 손실을 결합한 새로운 손실 함수를 사용합니다.

- **Performance Highlights**: 모델은 기존의 색상 압축 방법에 비해 색상 정확도에서 뛰어난 성능을 보이며, 실시간 성능을 달성하여 제한된 계산 자원을 가진 장치에 적합합니다.



### AI Can Be Cognitively Biased: An Exploratory Study on Threshold Priming in LLM-Based Batch Relevance Assessmen (https://arxiv.org/abs/2409.16022)
- **What's New**: 이 연구는 LLMs(대형 언어 모델)가 정보 검색(Information Retrieval) 작업에서 문서의 관련성을 판단할 때 경험적으로 관찰된 threshold priming 효과에 영향을 받는지를 조사합니다. 이는 LLM의 인지 편향(cognitive bias)에 대한 연구의 일환으로, LLM이 사람의 판단과 유사한 방식으로 영향을 받을 수 있음을 보여줍니다.

- **Technical Details**: 이 연구에서는 TREC 2019 Deep Learning 구문 수집에서 10개의 주제를 대상으로 LLM의 문서 관련성 평가를 시험했습니다. 실험에는 GPT-3.5, GPT-4, LLaMa2-13B 및 LLaMa2-70B 모델이 사용되었습니다. 초기 문서의 관련성 레벨이 후속 문서의 평가에 미치는 영향을 분석하기 위해 다양한 프로로구(prologue) 및 에필로그(epilogue) 길이를 가지고 실험을 수행했습니다.

- **Performance Highlights**: 결과에 따르면, 초기 문서의 높은 관련성은 후속 문서의 낮은 점수를 유도하는 경향이 있었습니다. 반대로 초기 문서의 낮은 관련성은 후속 문서에 대한 높은 점수를 유발했습니다. LLaMa2-70B 모델은 일부 조건에서 다른 모델과 다른 경향을 보였으며, 다른 모델들은 threshold priming 효과의 성격을 유지했습니다.



### Improvements to SDXL in NovelAI Diffusion V3 (https://arxiv.org/abs/2409.15997)
Comments:
          14 pages, 8 figures

- **What's New**: NovelAI Diffusion V3 모델은 SDXL을 기반으로 하며, 훈련 관행에서 여러 가지 향상을 이루었습니다. 특히 Zero Terminal SNR과 v-prediction 파라미터화를 도입했습니다.

- **Technical Details**: SDXL의 훈련 과정에서 𝜖-prediction에서 v-prediction으로 전환하였고, 노이즈 스케줄을 개선하여 더 높은 시그마 레벨까지 훈련하였습니다. 이를 통해 모델은 노이즈로부터 의미 있는 색상과 주파수를 예측하도록 학습하게 되었습니다.

- **Performance Highlights**: 모델의 훈련 진행을 통해 고해상도 이미지 생성에서 일관성을 회복하였으며, 실제 이미지의 품질 개선과 더불어 수렴 속도가 빨라졌습니다.



### Leveraging Unsupervised Learning for Cost-Effective Visual Anomaly Detection (https://arxiv.org/abs/2409.15980)
- **What's New**: 이 연구는 사전 훈련된 모델을 사용하고 저렴한 하드웨어로 시각적 이상 탐지 시스템을 개발하여 중소기업(SMEs)의 구매 부담을 줄이기 위한 새로운 접근 방식을 제안합니다. 이 시스템은 최소한의 데이터로 모델 훈련을 수행할 수 있으며, Raspberry Pi 4B에서 효율적으로 배포됩니다.

- **Technical Details**: 이 시스템은 Anomalib 라이브러리의 비지도 학습 모델을 활용하여 작동합니다. 10장의 정상 제품 이미지만을 사용하여 Raspberry Pi에서 90초 만에 이상 탐지 교육과 추론을 완료할 수 있으며, F1 매크로 점수는 0.95 이상을 기록합니다. PaDiM, PatchCore, CFlow-AD 및 FastFlow와 같은 여러 알고리즘이 적용되어 성능을 비교했습니다.

- **Performance Highlights**: 연구 결과, 이 저비용의 시각적 이상 탐지 시스템은 환경 변화에 약간 민감하지만, 중소 제조업체를 위한 공장 자동화 검사의 신속하고 경제적인 방법으로써의 가능성을 보여주었습니다. 시스템은 IoT(Internet of Things) 환경에서 효율적인 운영을 위한 샘플링과 같은 높은 성능을 유지합니다.



### Disentangling Age and Identity with a Mutual Information Minimization Approach for Cross-Age Speaker Verification (https://arxiv.org/abs/2409.15974)
Comments:
          Interspeech 2024

- **What's New**: 본 논문은 Cross-Age Speaker Verification (CASV)에서 나이와 관련된 정보와 정체성 정보를 효과적으로 분리하는 새로운 방법인 상호 정보(minimization of mutual information, MI) 기반의 접근 방식을 제안합니다.

- **Technical Details**: 제안된 방법은 두 개의 모듈로 구성되어 있습니다: 백본 모델(backbone model)과 MI 추정기(MI estimator). 백본 모델은 초기 임베딩(initial embedding)을 추출하고, 이를 나이 관련 임베딩(age embedding)과 나이 불변의 정체성 임베딩(age-invariant identity embedding)으로 분리합니다. MI 추정기는 두 임베딩 간의 상호 정보를 측정하고 이를 최소화하는 방향으로 백본 모델을 유도하여 나이 불변의 음성 임베딩을 만듭니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 Vox-CA 데이터 세트의 다양한 Cross-Age 테스트 세트에서 이전의 최첨단 방법(state-of-the-art)보다 EER에서 1.53%, minDCF에서 4.79% 향상된 성능을 보여줍니다.



### Edge-device Collaborative Computing for Multi-view Classification (https://arxiv.org/abs/2409.15973)
- **What's New**: 이 논문은 딥러닝 계산을 클라우드 대신 네트워크의 엣지로 이전하여 응답 속도를 높이고 대역폭 소비를 줄이며 개인 정보 보호 문제를 해결하는 방안을 제안합니다. 특히, 협업 추론(collaborative inference)을 통해 데이터를 공유하고 컴퓨팅 부담을 분산하는 다양한 방법을 탐구합니다.

- **Technical Details**: 본 연구는 다중 뷰 분류(multi-view classification) 태스크에 중점을 두고, 엣지 서버와 최종 장치 간의 협업 방식을 조사합니다. 기존의 중앙 집중식(centralized) 또는 분산(distributed) 방식 외에도, 데이터 중복을 줄여 대역폭 소비를 감소시키는 선택적(selective) 방식도 제안합니다. 각 엣지 노드는 그들의 데이터를 기초로 하여 추론 작업에 기여할지를 결정합니다.

- **Performance Highlights**: 실험 결과, 제안된 선택적 협업 방식이 통신 절약을 18%에서 74%까지 달성할 수 있고, 여전히 90% 이상의 정확도를 유지할 수 있음을 보여줍니다. 심지어, 시각적 뷰를 일부 생략하더라도 평균 정확도는 71.92%에서 83.75%의 범위를 유지하며, 중앙 집중식 추론에 비해 대역폭 소비를 몇 배 감소시킬 수 있음을 강조합니다.



### Creating Healthy Friction: Determining Stakeholder Requirements of Job Recommendation Explanations (https://arxiv.org/abs/2409.15971)
Comments:
          14 pages, 3 figures, to be published in ACM RecSys in HR '24: 4th Workshop on Recommender Systems for Human Resources

- **What's New**: 이 연구는 구직에 있어 신뢰성 있는 Job Recommender System (JRS)의 필요성을 강조하며, 이 시스템이 이해 가능하고 투명하게 작동해야 한다고 주장합니다.

- **Technical Details**: 혼합 설계 사용자 연구(n=30)를 통해 여러 이해관계자가 추천 시스템의 설명을 바탕으로 의사결정을 하도록 평가했습니다. 사용된 지표는 객관적 지표인 정확도(correctness)와 효율성(efficiency)과 주관적 지표인 신뢰(trust), 투명성(transparency), 유용성(usefulness)을 포함했습니다.

- **Performance Highlights**: 모든 이해관계자는 설명이 포함된 JRS를 유용하다고 느꼈으나, 설명이 의사결정 속도와 정확도를 크게 개선시키지 못했습니다. 또한 이해관계자들은 주로 자신의 지식과 직관에 의존하며, 텍스트 기반 설명을 선호하는 경향이 있었습니다.



### Provably Efficient Exploration in Inverse Constrained Reinforcement Learning (https://arxiv.org/abs/2409.15963)
- **What's New**: 이번 논문에서는 Inverse Constrained Reinforcement Learning (ICRL)을 통해 복잡한 환경에서 최적 제약 조건을 도출하기 위한 새로운 전략적 탐색 프레임워크를 제안합니다. 기존의 ICRL 알고리즘은 상호작용 환경에서 학습 샘플을 수집하지만, 이러한 샘플링 전략의 효율성과 효과성은 불분명했습니다.

- **Technical Details**: 제안된 프레임워크에서는 ICRL 문제를 위한 실현 가능 제약 조건 집합을 정의하고, 전문가 정책(expert policy)과 환경 역학(environmental dynamics)이 제약 조건의 최적성에 어떻게 영향을 미치는지 조사합니다. 두 가지 탐색 알고리즘을 제안하여 1) 비용 추정의 한정된 집합 오류(bounded aggregate error)를 동적으로 줄이고, 2) 탐색 정책(exploration policy)을 전략적으로 제약합니다.

- **Performance Highlights**: 제안된 알고리즘의 성능은 다양한 환경에서 실증적으로 검증되었으며, 이론적으로 타당한 샘플 복잡도가 기반이 됩니다.



### ASD-Diffusion: Anomalous Sound Detection with Diffusion Models (https://arxiv.org/abs/2409.15957)
Comments:
          This paper will appear at ICPR 2024

- **What's New**: 본 논문은 공장 환경에서 비감독형 이상 음성 감지(ASD) 위한 새로운 방법인 ASD-Diffusion을 제안합니다. 이는 정상 소리만으로 이상을 감지하는 일반화 가능한 방법을 개발하는 것을 목표로 합니다.

- **Technical Details**: ASD-Diffusion은 노이즈가 섞인 음성 특징을 사용하여 정상 패턴으로 재구성한 후, 재구성 과정에서 원래 입력과 큰 차이를 보이는 이상을 필터링하는 알고리즘을 도입합니다. 또한, Denoising Diffusion Implicit Model (DDIM)을 적용하여 샘플링 속도를 향상시켰습니다.

- **Performance Highlights**: DCASE 2023 챌린지의 실험 결과, 제안된 방법은 기준 모델 대비 7.75% 성능 향상을 보여 효과성을 입증했습니다.



### Historical Trajectory Assisted Zeroth-Order Federated Optimization (https://arxiv.org/abs/2409.15955)
Comments:
          28 pages with theoretical proof

- **What's New**: 이번 연구에서는 Federated Learning에서 기울기 정보가 없는 상황에서도 기울기 추정을 개선하기 위해 비등방성 샘플링(non-isotropic sampling) 방법을 제안합니다. 이는 과거의 솔루션 궤적을 기반으로 하는 방법으로 유망한 영역을 탐색하는 것을 장려합니다.

- **Technical Details**: 제안된 방법은 비등방성 가우시안 분포(non-isotropic Gaussian distribution)를 사용하여 기울기를 추정하며, 이는 두 개의 부분으로 구성된 공분산 행렬(covariance matrix)을 사용하여 구현됩니다. 첫 번째 부분은 최근의 훈련 궤적에 의해 형성된 부분공간을 포함하며, 두 번째 부분은 아이덴티티 행렬(identity matrix)로, 이는 전역적인 탐색(global exploration)을 보장합니다. 기울기 추정에는 수렴 속도가 기존 방법들이 유지되면서 통신 오버헤드가 거의 없는 장점이 있습니다.

- **Performance Highlights**: 여러 수치 실험을 통해 제안된 방법의 효과가 검증되었으며, 기존에 과대 평가된 기울기 추정 방법에 비해 개선된 성능을 보였습니다. 이 방법은 특히 로컬 데이터 샘플만을 사용해도 강력한 결과를 도출할 수 있습니다.



### Automated test generation to evaluate tool-augmented LLMs as conversational AI agents (https://arxiv.org/abs/2409.15934)
Comments:
          14 pages, 5 figures, Submitted to GenBench@EMNLP2024

- **What's New**: 본 논문에서는 Tool-augmented LLMs(대형 언어 모델)를 평가하기 위한 테스트 생성 파이프라인을 제시하고 있습니다. 기존의 평가 데이터셋이 단일 상호작용 및 함수 호출에만 집중했던 반면, 이 연구는 사용자 정의 절차에 기반한 다양한 테스트를 생성합니다.

- **Technical Details**: LLMs를 기반으로 한 추천된 파이프라인은 중간 그래프(intermediate graphs)를 활용하여 발생할 수 있는 비현실적인 내용生성을 제한하고, 대화의 가능성을 널리 포괄하는 고품질 데이터를 생성합니다. 이 연구에서는 고객 지원을 위한 AI 에이전트 평가를 위한 ALMITA(Automated benchmark of Language Models for Intelligent Tool-augmented Agents)라는 수작업으로 제작된 데이터셋을 개발했습니다.

- **Performance Highlights**: 기존 LLM들은 단일 메시지 정확도 및 올바른 함수 호출에 있어 높은 성능을 보였지만, 전체 대화에서의 정확도는 제한적임을 보여주었습니다. 이는 LLMs가 완전 자율 고객 지원 AI 에이전트로 배치될 경우의 성공 가능성에 의문을 제기합니다.



### Multilingual Transfer and Domain Adaptation for Low-Resource Languages of Spain (https://arxiv.org/abs/2409.15924)
Comments:
          6 pages,wmt24. arXiv admin note: substantial text overlap with arXiv:2409.14842; text overlap with arXiv:2409.14800

- **What's New**: 이번 논문은 Huawei Translation Service Center (HW-TSC)의 WMT 2024에서의 스페인 저자원 언어 번역 태스크 제출 상태를 소개합니다. 이 연구팀은 스페인어에서 아라곤어(es-arg), 아라니세어(es-arn), 아스투리안어(es-ast)로의 번역 작업에 참여했습니다.

- **Technical Details**: 우리는 다국어 전이(multi-language transfer), 정규화 드롭아웃(regularized dropout), 포워드 번역(forward translation), 백 번역(back translation), Labse denoising, 전이 집합 학습(transduction ensemble learning) 등의 훈련 전략을 사용하여 딥 트랜스포머 기반의 신경 기계 번역(NMT) 모델을 훈련했습니다.

- **Performance Highlights**: 이러한 개선 전략을 통해 우리 제출물은 최종 평가에서 경쟁력 있는 결과를 달성했습니다.



### Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection (https://arxiv.org/abs/2409.15907)
Comments:
          This paper has been accepted by ECAI 2024

- **What's New**: 이번 논문에서는 LLMs가 데이터베이스 스키마와 셀 값에 대한 도메인 지식을 효과적으로 이해하고 활용할 수 있도록 '지식 주입' (knowledge injection) 방법을 도입하였습니다. 이를 통해 Text-to-SQL 작업에서의 성능을 향상시키는 다양한 기술적 접근을 선보입니다.

- **Technical Details**: 제안된 방법은 특정 도메인 데이터베이스 지식을 기반으로 LLMs를 사전 훈련 (pre-training)하고, 하위 Text-to-SQL 작업에 맞춰 미세 조정 (fine-tuning)하는 것입니다. 이를 통해 Execution Match (EX) 및 Exact Match (EM) 지표에서 현저한 개선을 이루어내며, 컬럼 이름 생성 및 값 일치 오류를 줄입니다.

- **Performance Highlights**: 실험 결과, 제안한 지식 주입 방법이 여러 개의 오픈 소스 LLMs에서 실질적인 성능 향상을 보여주었으며, 이는 다양한 Text-to-SQL 작업에 광범위하게 적용 가능하다는 것을 검증하였습니다.



### Boosting Code-Switching ASR with Mixture of Experts Enhanced Speech-Conditioned LLM (https://arxiv.org/abs/2409.15905)
Comments:
          Submitted to ICASSP 2025

- **What's New**: 본 논문에서는 자동 음성 인식(Automatic Speech Recognition, ASR)의 코드 스위칭(Code-Switching, CS) 문제를 해결하기 위해 대화식 음성 모델(Speech-Conditioned Large Language Model, SC-LLM)과 전문가 혼합(Mixture of Experts, MoE) 기반 커넥터를 통합한 새로운 접근 방식을 소개합니다.

- **Technical Details**: IDIT(Insertion and Deletion of Interruption Token) 메커니즘을 통해 LLM의 텍스트 생성 능력을 음성 인식 과업에 효과적으로 이전하는 방법을 제안합니다. 두 단계로 진행되는 훈련 전략이 포함되어 있으며, 첫 번째 단계에서 언어 전문화 전문가(Language-Specialized Experts, LSE)와 함께 음성 표현을 텍스트로 매핑합니다. 두 번째 단계에서는 IDIT 메커니즘을 활용하여 모든 전문가가 일반 표현을 학습하도록 합니다.

- **Performance Highlights**: 실험 결과, 본 방법은 ASRU-2019 Mandarin-English 코드 스위칭 데이터셋에서 기존 모델들에 비해 10% 이상의 성능 향상을 보여주며, SC-LLM의 잠재력을 입증했습니다.



### Machine Translation Advancements of Low-Resource Indian Languages by Transfer Learning (https://arxiv.org/abs/2409.15879)
Comments:
          6 pages, wmt24. arXiv admin note: substantial text overlap with arXiv:2409.14800

- **What's New**: 이 논문은 Huawei Translation Center (HW-TSC)가 WMT24 인도 언어 기계 번역(MT) 공동 작업에 제출한 내용을 소개합니다. 본 연구는 리소스가 부족한 인도 언어에 대한 신뢰할 수 있는 기계 번역 시스템을 개발하기 위해 두 가지 별도의 knowledge transfer 전략을 적용했습니다.

- **Technical Details**: Assamese(as)와 Manipuri(mn)의 경우, 우리는 기존의 IndicTrans2 오픈소스 모델을 미세 조정하여 영어와 이들 언어 간의 쌍방향 번역을 가능하게 했습니다. Khasi (kh)와 Mizo (mz)의 경우, 네 언어 쌍의 이중 언어 데이터를 이용하여 다국어 모델을 훈련시켰고, 추가적으로 약 8천 쌍의 영어-벵골어 이중 언어 데이터를 사용했습니다. 이를 통해 데이터 부족 문제를 해결했습니다.

- **Performance Highlights**: 전달 학습 실험에서는 en-as에 대해 23.5 BLEU, en-mn에 대해 31.8 BLEU, as-en에 대해 36.2 BLEU, mn-en에 대해 47.9 BLEU의 성과를 거두었습니다. 다국어 모델의 전이 학습 실험 결과는 en-kh에서 19.7 BLEU, en-mz에서 32.8 BLEU, kh-en에서 16.1 BLEU, mz-en에서 33.9 BLEU를 기록하였습니다.



### Whisper in Medusa's Ear: Multi-head Efficient Decoding for Transformer-based ASR (https://arxiv.org/abs/2409.15869)
Comments:
          Under Review

- **What's New**: Whisper-Medusa는 대규모 Transformer 모델을 위한 新한 음성 인식(Speech Recognition) 방법론으로, 단일 단계에서 여러 개의 토큰을 예측하여 처리 속도를 개선합니다. 기존 Whisper 모델의 구조를 확장하여 속도를 극대화하고 Word Error Rate (WER)에 미치는 영향을 최소화하는 방식입니다.

- **Technical Details**: Whisper-Medusa는 Speculative Decoding 기법을 활용하여 K+1 토큰을 동시에 예측하는 방식을 채택합니다. 전반적인 구조는 인코더-디코더 transformer 모델로, 입력 오디오를 처리하고 다차원 임베딩으로 변환한 후, 이를 기반으로 여러 개의 토큰을 동시에 생성합니다.

- **Performance Highlights**: 이 모델은 다양한 다국어 데이터셋에서 올바른 인식 성능을 유지하면서 50%의 레이턴시 감소를 보여줍니다. Whisper-Medusa의 효율성을 강조하기 위해 여러 학습 설정 및 데이터셋에서의 효과를 평가했습니다.



### BeSimulator: A Large Language Model Powered Text-based Behavior Simulator (https://arxiv.org/abs/2409.15865)
Comments:
          7 pages, 3 figures, 2 tables

- **What's New**: 본 논문에서는 기존의 로봇 시뮬레이터의 한계를 극복하기 위해 행동 시뮬레이션(Behavior Simulation)을 이론적으로 정의하고 새로운 프레임워크인 BeSimulator를 소개하였습니다. BeSimulator는 텍스트 기반의 가상 환경에서 로봇 행동 로직을 수립하여 시뮬레이션하고, 체계적인 사고 과정을 통해 행동의 실행 가능성과 상태 전이를 분석합니다.

- **Technical Details**: BeSimulator는 모듈화된 LLM(large language model) 기반의 프레임워크로, 행동 계획 솔루션(BPS)에 대한 단계별 시뮬레이션을 수행합니다. 이 프레임워크는 '사례 생성'(Case Generation), 'BPS 시뮬레이션'(BPS Simulation), 및 'BPS 평가'(BPS Evaluation)라는 세 가지 핵심 모듈을 포함하고 있습니다. 또한, Chain of Behavior Simulation(CBS) 접근법을 통해 행동의 실행 가능성과 상태 전이를 깊이 분석합니다.

- **Performance Highlights**: BTSIMBENCH라는 행동 트리 기반의 시뮬레이션 벤치마크를 통해 실험한 결과, BeSimulator는 기존 방법들에 비해 14.7%에서 26.6%까지 행동 시뮬레이션 성능이 향상되었습니다. 이는 BeSimulator가 특히 긴 기간의 복잡한 시뮬레이션에서 우수한 성능을 제공함을 입증합니다.



### A Zero-Shot Open-Vocabulary Pipeline for Dialogue Understanding (https://arxiv.org/abs/2409.15861)
- **What's New**: 본 연구에서 우리는 제로샷(zero-shot), 오픈 어휘(open-vocabulary) 시스템을 제안하며, 디지털 대화 이해를 위한 통합된 파이프라인을 구성합니다.

- **Technical Details**: 제안된 방법론은 도메인 분류(domain classification)부터 시작하여, 여러 방법으로 DST(대화 상태 추적)를 수행합니다. 특히 DST를 질문-답변(question-answering) 문제로 변환하는 'DST-as-QA' 방식과 자가 수정 프롬프트(self-refining prompt) 기법을 활용한 'DST-as-SRP'를 포함합니다. 이 시스템은 고정된 슬롯 값에 의존하지 않아 동적으로 적응할 수 있습니다.

- **Performance Highlights**: 제안된 방법은 MultiWOZ 2.1 데이터셋에서 20% 향상된 Joint Goal Accuracy(JGA)를 달성하며, LLM API에 대한 요청 수를 최대 90% 줄입니다. 또한, 제로샷 및 오픈 어휘 설정에서 현재 SOTA 방법들을 초월하는 성능을 보였습니다.



### Identification For Control Based on Neural Networks: Approximately Linearizable Models (https://arxiv.org/abs/2409.15858)
Comments:
          15 pages, 3 figures, 6 tables, accepted as a poster in SysDO 2024, Stuttgart, Germany

- **What's New**: 이번 연구는 비선형 시스템의 효율적인 제어 설계 및 안정성 분석을 위한 제어 지향 식별 방법을 제시합니다. 신경망(Neural Networks)을 사용하여 비선형 시스템의 시간 영역 내 입력-출력 동작을 근사하는 이산 시간 비선형 상태-공간 모델을 식별합니다.

- **Technical Details**: 제안된 방법은 모델을 피드백에 의해 근사적으로 선형화할 수 있도록 구성되어, 제어 법칙이 학습 단계에서 자명하게 따르도록 합니다. 상태공간 모델 내 신경망 구조를 요구하며, 비선형 함수 f는 신경망을 통해 근사화됩니다. 선형 제어 이론이 제어기 설계 및 폐루프 시스템의 안정성 분석에 활용됩니다.

- **Performance Highlights**: 연구된 방법론은 시스템 식별을 위한 일반적인 벤치마크를 사용하여 효과성을 입증되었으며, 비선형 시스템의 안정성 분석 및 제어 설계 과정을 간소화하는 데 기여합니다.



### Adaptive Learn-then-Test: Statistically Valid and Efficient Hyperparameter Selection (https://arxiv.org/abs/2409.15844)
- **What's New**: 새로운 기법인 adaptive learn-then-test (aLTT)를 소개합니다. aLTT는 AI 모델의 모집단 리스크에 대해 유한 샘플 통계적 보증을 제공하는 효율적인 하이퍼파라미터 선택 절차입니다. 기존의 learn-then-test (LTT) 방식과는 달리, aLTT는 e-processes를 활용한 데이터 의존적 방식으로 순차적으로 다중 가설 검정을 수행하며, 테스트 라운드를 줄이는 데 적합합니다.

- **Technical Details**: aLTT는 p-value 기반의 다중 가설 검정(MHT)에 의존하는 기존의 LTT 기술과는 달리, e-process를 통한 데이터 의존적 MHT 방식을 구현합니다. 이러므로 테스트 라운드 수를 줄일 수 있으며, 특히 테스트가 비용이 많이 들거나 안전 위험이 있는 상황에서 효과적입니다. aLTT는 FWER(가족간 오류 비율) 및 FDR(허위 발견율)에 대한 엄격한 통제를 보장합니다.

- **Performance Highlights**: aLTT는 오프라인 강화 학습을 위한 온라인 정책 선택 및 무선 공학을 위한 자원 할당과 같은 두 가지 실제 시나리오에서 하이퍼파라미터를 효과적으로 선택할 수 있는 능력을 보여주었습니다. LTT가 필요한 테스트 라운드의 일부만을 사용하여 신뢰할 수 있는 하이퍼파라미터를 제공합니다.



### Empirical Insights on Fine-Tuning Large Language Models for Question-Answering (https://arxiv.org/abs/2409.15825)
- **What's New**: 본 연구는 질문-응답(QA) 작업을 위한 대형 언어 모델(LLM)의 전이 학습을 최적화할 수 있는 효과적인 세부 전략을 제시합니다. 기존 연구와 달리, 우리는 사전 훈련된 언어 모델의 메모리와 지식 수준에 따라 데이터를 체계적으로 분류하고, 실험 분석을 통해 세 가지 주요 질문에 대해 답변합니다.

- **Technical Details**: 이 연구에서는 다중 템플릿 보완 메커니즘(multi-template complementation mechanism)을 사용하여 LLM의 특정 지식 유형에 대한 기억 정도를 평가합니다. 또한 SFT(Supervised Fine-Tuning) 단계에서 소수의 데이터 포인트(최소 60개)로도 QA 작업을 성공적으로 수행할 수 있음을 확인했습니다.

- **Performance Highlights**: SFT 데이터의 메모리 수준이 모델 성능에 미치는 영향을 분석한 결과, 사전 훈련 단계에서 잘 기억된 데이터로 훈련할 경우 LLM의 성능이 유의미하게 향상되는 것으로 나타났습니다. 하지만 모델이 거의 기억하지 못한 데이터를 사용한 경우에는 성능이 크게 저하되었습니다.



### Interactive Example-based Explanations to Improve Health Professionals' Onboarding with AI for Human-AI Collaborative Decision Making (https://arxiv.org/abs/2409.15814)
- **What's New**: 이 논문에서는 AI-assisted decision-making에서 건강 전문가들이 AI의 결정을 더 잘 신뢰할 수 있도록 도와주는 interactive example-based explanations를 제안합니다. 이를 통해 사용자가 AI 모델에 대한 신뢰를 향상시킬 수 있는 방법을 모색합니다.

- **Technical Details**: AI 기반의 의사결정 지원 시스템을 구현하였으며, 신경망(neural network)을 사용하여 뇌졸중 생존자의 운동 질을 평가합니다. 이 시스템은 사용자가 입력한 새로운 운동 데이터에 가까운 k-neighbourhoods를 시각화하여 AI의 출력과 실제 레이블을 함께 보여줍니다. 이를 통해 사용자는 데이터가 어떻게 표현되었고 AI 모델이 어떻게 작동하는지를 이해할 수 있습니다.

- **Performance Highlights**: interactive example-based explanations를 제공한 결과, 건강 전문가들은 AI에 대한 신뢰도가 개선되었으며, '올바른' 결정을 내릴 확률이 높아지고 '잘못된' 결정의 확률은 낮아졌습니다. 이러한 결과는 사용자가 onboarding 과정에서 AI를 더 효과적으로 사용할 수 있도록 도와줍니다.



### Layer-wise Model Merging for Unsupervised Domain Adaptation in Segmentation Tasks (https://arxiv.org/abs/2409.15813)
- **What's New**: 본 논문에서는 기존에 훈련된 모델들을 결합하여 비용 없이 모델 병합을 수행하는 새로운 아키텍처를 제안합니다. 이 방법은 레이어 단위로 모델을 통합하여 초기 레이어를 통합하면서 최종 레이어의 특수성을 유지합니다.

- **Technical Details**: 제안된 방법은 Unsupervised Domain Adaptation (UDA)의 맥락에서 다양한 태스크와 데이터셋에 대해 실험하였으며, 특히 Semantic과 Panoptic Segmentation 작업에 적합합니다. 이 방법은 모델 파라미터의 일관성을 유지하고 서로 다른 데이터셋 및 태스크에서의 모델 병합을 가능하게 합니다.

- **Performance Highlights**: 실험 결과, 서로 다른 아키텍처의 모델 병합 시 mIoU가 6.8% 향상되었고, Semantic과 Panoptic Segmentation 모델 병합을 통해 mPQ가 7% 증가하는 등 UDA의 성능이 크게 향상되었습니다.



### Towards Universal Large-Scale Foundational Model for Natural Gas Demand Forecasting (https://arxiv.org/abs/2409.15794)
- **What's New**: 본 연구는 자연가스 수요 예측을 위해 특별히 설계된 첫 번째 기초 모델(Foundation Model)을 제안합니다. 기존 전통적 방법들이 현업에서의 복잡한 수요 패턴 예측에 한계를 보이는 반면, 기초 모델은 이 문제를 해결하기 위한 견고한 솔루션을 제공합니다.

- **Technical Details**: 기반 모델은 대조 학습(contrastive learning)을 활용하여 역사적 소비 데이터의 노이즈 및 유사 샘플의 잘못된 분류 문제가 예측 정확도에 미치는 영향을 개선했습니다. 새로운 노이즈 필터링 기법을 통합하여 학습된 표현의 질을 향상시키고, 산업별 특성을 잘 포착할 수 있도록 사전 훈련(prior tuning) 과정을 수행했습니다.

- **Performance Highlights**: 우리의 모델은 ENN 그룹에서 다수의 산업 및 상업적 고객 데이터(MSE에서 3.68%, MASE에서 6.15% 개선)를 사용한 실험에서 기존의 최첨단 방법을 초월하는 성능을 나타냈습니다.



### Small Language Models: Survey, Measurements, and Insights (https://arxiv.org/abs/2409.15790)
- **What's New**: 이 논문은 최근 몇 년 간의 모든 작은 언어 모델(SLM)들을 종합적으로 검토하고 이들의 기술 혁신 및 온디바이스(온기기) 비용을 벤치마킹하여 요약합니다. SLM의 매니페스트 데이터를 공개하여 앞으로의 연구에 기여할 수 있는 기반을 마련합니다.

- **Technical Details**: SLM은 100M에서 5B 파라미터 범위의 transformer 기반, decoder-only 아키텍처로 구성됩니다. 59개의 최첨단 오픈 소스 SLM을 분석하여 아키텍처, 훈련 데이터셋, 훈련 알고리즘의 세 가지 축을 중심으로 기술 혁신을 평가합니다.

- **Performance Highlights**: SLM의 성능을 평가하며, commonsense reasoning, in-context learning, mathematics, coding과 같은 다양한 분야에서 능력을 분석합니다. 또한 벤치마킹 데이터를 통해 디바이스에서의 런타임 비용에 대한 귀중한 통찰을 제공합니다.



### Spatial-Temporal Mixture-of-Graph-Experts for Multi-Type Crime Prediction (https://arxiv.org/abs/2409.15764)
- **What's New**: ST-MoGE는 범죄 예측의 공간-시간 이질성을 해결하려고 고안된 혁신적인 프레임워크입니다. 이는 범죄 카테고리에 특화된 Mixture-of-Experts (MoE) 아키텍처를 활용하여 다양한 범죄 패턴을 통합적으로 잡아냅니다.

- **Technical Details**: ST-MoGE는 Attentive-gated Mixture-of-Graph-Experts (MGEs) 모듈을 도입하여 다양한 범죄 카테고리의 공간-시간 의존성을 포착합니다. 또한 Cross-Expert Contrastive Learning (CECL)을 통해 각 전문가가 특정 패턴 모델링에 집중하도록 하여 혼합 및 중복을 줄입니다. Hierarchical Adaptive Loss Re-weighting (HALR) 기법을 통해 불균형적인 공간 분포 문제를 해결합니다.

- **Performance Highlights**: ST-MoGE는 뉴욕시와 시카고 두 개의 실제 범죄 데이터셋을 활용하여 12개의 기존 방법들과 비교하여 탁월한 성과를 보였습니다. 실험 결과, 제안된 방법의 우수성이 입증되었습니다.



### IRSC: A Zero-shot Evaluation Benchmark for Information Retrieval through Semantic Comprehension in Retrieval-Augmented Generation Scenarios (https://arxiv.org/abs/2409.15763)
- **What's New**: 이 논문은 다국어 Retrieval-Augmented Generation (RAG) 작업에서 임베딩 모델의 성능을 평가하기 위한 IRSC 벤치마크를 소개합니다. 이 벤치마크는 쿼리 검색, 제목 검색, 단락의 일부 검색, 키워드 검색, 요약 검색의 cinco 가지 검색 작업을 포함합니다.

- **Technical Details**: IRSC 벤치마크는 embedding 모델의 성능을 다양한 검색 과제에서 평가하며, 새로운 메트릭인 Semantic Comprehension Index (SSCI) 및 Retrieval Capability Contest Index (RCCI)를 도입했습니다. 이 벤치마크는 여러 언어(영어, 중국어 및 혼합 언어 데이터셋)에서 모델을 평가합니다.

- **Performance Highlights**: 연구 결과에 따르면, IRSC 벤치마크는 실용적인 RAG 작업에서의 embedding 모델의 성능을 더 잘 이해하고 개발하는 데 기여할 수 있습니다. 이 연구는 embedding 모델의 언어 간 한계를 통찰하는 데 중요한 기여를 합니다.



### TFG: Unified Training-Free Guidance for Diffusion Models (https://arxiv.org/abs/2409.15761)
- **What's New**: 본 논문은 교육 없이도 원하는 목표 속성을 가진 샘플을 생성할 수 있는 새로운 알고리즘 프레임워크인 Training Free Guidance (TFG)를 소개합니다. 기존 방식들의 이론적 기초와 방대한 벤치마크 테스트가 부족했던 점을 해결하고, TFG에서 기존 방법들이 특별한 하이퍼파라미터 서브스페이스에 해당함을 입증합니다.

- **Technical Details**: TFG의 하이퍼파라미터 검색 전략은 다양한 다운스트림 작업에 쉽게 적용할 수 있도록 설계되었습니다. 이 연구에서는 7개의 확산 모델(difussion models)을 이용해 16개의 작업과 40개의 목표에 대해 체계적으로 벤치마크를 수행했습니다. TFG는_all_datasets에서 평균 8.5% 향상된 성능을 기록하였습니다.

- **Performance Highlights**: TFG는 다양한 복잡도의 목표와 데이터셋에서 사용자 요구에 맞는 샘플을 생성하는 데 뛰어난 성능을 보였습니다. TFG 방법론은 기존 방법들과 비교하여 전반적으로 우수함을 입증하였고, 교육이 필요 없는 조건 생성 알고리즘 관련 연구의 강력한 기반을 제시합니다.



### Stage-Wise Reward Shaping for Acrobatic Robots: A Constrained Multi-Objective Reinforcement Learning Approach (https://arxiv.org/abs/2409.15755)
Comments:
          7 pages

- **What's New**: 본 논문에서는 강화 학습(reinforcement learning, RL)의 보상 기능 정의를 단순화하기 위한 새로운 방법을 제안합니다. 제안된 방법은 제약된 다목적 RL(constrained multi-objective RL, CMORL) 프레임워크를 활용하여, 여러 개의 보상 및 비용 함수를 단계별로 정의함으로써 보상 설계 과정을 간소화하는 것을 목표로 합니다.

- **Technical Details**: CMORL 프레임워크를 사용하여 복잡한 동작을 필요로 하는 여러 단계의 작업을 정의합니다. 각 단계에 대해 독립적인 보상 및 비용 함수를 설정하며, 이를 통해 각 동작의 특성에 맞는 보상을 제공합니다. 또한, 제안된 방식은 여러 가지 acrobatic tasks에서의 성공적인 수행을 목표로 하며, proximal policy optimization (PPO) 알고리즘의 변형인 constrained multi-objective PPO (CoMOPPO)를 통해 정책 업데이트를 수행합니다.

- **Performance Highlights**: 제안된 방법은 쿼드복잡(rigorous quadrupedal) 및 휴머노이드 로봇에서 다양한 acrobatic tasks(예: back-flips, two-hand walks 등)를 성공적으로 수행하는 것을 보여주었으며, 기존의 RL 및 제약 RL 알고리즘에 비해 우수한 결과를 보였습니다. 실제 환경에서의 테스트에서도 우수한 성능을 입증하였습니다.



### Development and Validation of Heparin Dosing Policies Using an Offline Reinforcement Learning Algorithm (https://arxiv.org/abs/2409.15753)
- **What's New**: 본 연구는 강화학습(Artificial Intelligence, AI) 기반의 개인화된 헤파린(heparin) 투여 정책을 제안하여 집중치료실(ICU)에서의 복잡한 약물 투여 문제를 해결합니다. 이는 정교한 의사결정 지원 도구의 개발을 위한 선례를 마련합니다.

- **Technical Details**: 이 연구는 향상된 기계 학습 기술과 대규모 임상 데이터(Medical Information Mart for Intensive Care III, MIMIC-III)를 활용하여 헤파린 투여의 정확성을 높이는 방법을 제시합니다. 배치 제약 강화 학습(batch-constrained RL) 접근 방식을 통해 비원주율 오류를 최소화하고, 가중 중요 샘플링(weighted importance sampling) 기술을 사용하여 정책의 효과성을 평가합니다.

- **Performance Highlights**: 제안된 배치 제약 Q 학습(Batch-Constrained Q-learning, BCQ) 알고리즘은 기존의 딥 RL(ddeep Reinforcement Learning) 방식보다 성능이 우수하며, t-SNE 기법을 통해 정책의 효율성을 시각적으로 분석하고 헤파린 투여의 효과를 극대화하는 데 기여합니다.



### The Roles of Generative Artificial Intelligence in Internet of Electric Vehicles (https://arxiv.org/abs/2409.15750)
Comments:
          25 Pages

- **What's New**: 이번 논문은 생성형 인공지능(GenAI) 모델의 발전과 전기차(\acEV) 및 전기차 인터넷(\acIoEV) 애플리케이션에서의 활용을 조사합니다. 특히, GenAI를 통해 IoEV의 다양한 계층에서 전기차의 배터리, 개별 전기차, 스마트 그리드, 그리고 보안 레이어에 대한 구체적인 기술을 분류하고 소개합니다.

- **Technical Details**: 논문에서는 IoEV의 네 가지 주요 레이어를 소개합니다: 배터리 레이어, 개별 EV 레이어, EV가 포함된 스마트 그리드 레이어, 그리고 보안 레이어. 각 레이어에 적용된 GenAI 기술로는 Transformer, \acGAN, \acAE, \acVAE, 그리고 \acGDM 등이 포함됩니다. 또한, 각 레이어의 GenAI 모델 학습을 위한 공개 데이터셋 요약이 제공됩니다.

- **Performance Highlights**: 이 논문은 GenAI 기술을 통해 IoEV 시스템을 더욱 강력하고 효율적으로 발전시키기 위한 미래 연구 방향을 제시합니다. GenAI의 활용은 데이터 부족 문제 해결, 이상 탐지, EV 충전 로드 예측, 시나리오 생성을 통해 IoEV 애플리케이션의 품질을 향상시킬 것으로 기대됩니다.



### Training Neural Networks for Modularity aids Interpretability (https://arxiv.org/abs/2409.15747)
Comments:
          4 pages, preprint

- **What's New**: 본 논문은 신경망의 해석 가능성을 높이기 위해 모델을 분리된 클러스터로 나누는 새로운 접근법을 제시합니다. 이를 통해 모델의 각 기능을 독립적으로 연구할 수 있습니다. 또한, 'enmeshment loss'라는 새로운 손실 함수를 도입하여 훈련 동안 비상호작용 클러스터를 형성할 수 있도록 유도합니다.

- **Technical Details**: 기존의 클러스터링 방법은 신경망의 해석에 비효율적이라는 점을 강조하며, 'Bipartite Spectral Graph Clustering (BSGC)' 알고리즘을 제안합니다. 이 알고리즘은 가중치 기반의 유사도 행렬을 사용하여 신경망의 레이어를 bipartite 클러스터로 나누며, 이 과정에서 'enmeshment loss'가 클러스터의 모듈화를 촉진합니다. 이 손실 항은 훈련 중에 클러스터 간의 간섭을 최소화하는 데 도움을 줍니다.

- **Performance Highlights**: CIFAR-10 데이터셋에서 실험을 통해 클러스터링된 모델은 95% 이상의 정확도를 유지하며, 효과적인 회로 크기(ECS)가 줄어들어 해석 가능성이 향상되었습니다. 연구 결과, 클러스터링된 모델은 비클러스터 모델에 비해 평균적으로 61.25% 더 적은 파라미터를 갖는 효과적인 회로를 생성하여, 독립적으로 클러스터가 기여하는 정도를 보여줍니다.



### EvoFA: Evolvable Fast Adaptation for EEG Emotion Recognition (https://arxiv.org/abs/2409.15733)
- **What's New**: EEG 기반 감정 인식에서의 모델 재사용 시 성능 저하 문제를 해결하기 위해, 본 논문에서는 Evolvable Fast Adaptation (EvoFA)라는 온라인 적응 프레임워크를 제안했습니다. 이 프레임워크는 Few-Shot Learning (FSL)과 Domain Adaptation (DA)을 통합하여 빠른 적응과 분포 일치를 이룹니다.

- **Technical Details**: EvoFA는 두 단계 일반화 과정을 통해 FSL의 빠른 적응성과 DA의 분포 일치를 조화롭게 결합합니다. 학습 단계에서는 강력한 일반화 능력을 지닌 메타 학습 모델을 구축하고, 테스팅 단계에서는 진화하는 소스 데이터를 기반으로 타겟 데이터의 주변 분포를 반복적으로 정렬하여 온라인 테스트 성능을 향상시킵니다.

- **Performance Highlights**: EvoFA는 기존 FSL 방법 및 이전의 온라인 방법들과 비교해 상당한 성능 향상을 달성했습니다. 본 연구는 실제 상황에서 EEG 기반 감정 인식의 보다 폭넓은 사용을 가능하게 합니다.



### Learning Multiple Probabilistic Decisions from Latent World Model in Autonomous Driving (https://arxiv.org/abs/2409.15730)
- **What's New**: 이번 논문에서 제안하는 LatentDriver는 오토리그레시브(world model) 세계 모델을 활용하여 불확실성 모델링을 개선하고 자기오도문제를 해결하여 더 나은 의사결정을 이끌어내는 방법을 제시합니다.

- **Technical Details**: LatentDriver는 환경의 다음 상태와 차량의 가능한 행동을 혼합(미xture) 분포로 모델링합니다. 이를 통해 결정의 확률적 성격을 캡쳐하며, 여러 확률적 가설을 세워 행동을 예측합니다. 또한, 행동을 미리 샘플링하여 자기오도 문제를 완화합니다. 미들 레이어에서 샘플링된 행동을 사용하여 최종 결정을 내리는 방식입니다.

- **Performance Highlights**: 실험 결과, LatentDriver는 최신 강화 학습(reinforcement learning) 및 모방 학습(imitation learning) 방법을 초월하며, 전문가 수준의 성능을 보였습니다. Waymax 벤치마크에서 평가할 때, 비반응형 및 반응형 에이전트에 대한 평가에서 두각을 나타냈습니다.



New uploads on arXiv(cs.LG)

### $O(d/T)$ Convergence Theory for Diffusion Probabilistic Models under Minimal Assumptions (https://arxiv.org/abs/2409.18959)
- **What's New**: 본 논문은 점수 기반 확산 모델(score-based diffusion models)의 이론적 수렴성을 개선하여 빠른 수렴 이론을 확립합니다. 기존의 이론적 보장이 엄격한 가정이나 최적이 아닌 수렴 속도에 의해 제한되는 문제를 해결합니다.

- **Technical Details**: 우리는 최소한의 가정 하에 인기 있는 SDE(Stochastic Differential Equation) 기반 샘플러의 빠른 수렴 이론을 수립합니다. 분석 결과, $	ext{l}_2$-정확한 점수 함수(score function) 추정치를 제공하면, 목표 분포(target distribution)와 생성된 분포들 간의 총 변이 거리(total variation distance)가 O(d/T)로 상한이 설정됩니다. 여기서 d는 데이터 차원, T는 단계의 수를 나타냅니다.

- **Performance Highlights**: 이 결과는 유한한 1차 모멘트를 가지는 모든 목표 분포에 대해 적용되며, 기존의 SDE 기반 샘플러와 ODE(Ordinary Differential Equation) 기반 샘플러의 수렴 이론을 개선합니다. 이 연구는 각 단계에서 오류가 어떻게 전파되는지를 세밀하게 나타내는 새로운 분석 도구를 통해 이루어졌습니다.



### A-FedPD: Aligning Dual-Drift is All Federated Primal-Dual Learning Needs (https://arxiv.org/abs/2409.18915)
- **What's New**: 이번 논문에서는 연합 학습(federated learning, FL)에서 발생하는 'dual drift' 문제를 해결하기 위한 새로운 방법인 Aligned Federated Primal Dual (A-FedPD)을 제안합니다. 이 문제는 비볼록(non-convex) 시나리오에서 오래도록 비활성화된 클라이언트들이 참여하는 중에 발생하는 이차 히스테리시스(dual hysteresis)를 의미합니다.

- **Technical Details**: A-FedPD 방법은 비참여 로컬 클라이언트를 위해 글로벌 합의(global consensus)와 로컬 이중 변수(local dual variables)를 정렬시키기 위해 가상 이중 업데이트(virtual dual updates)를 구성합니다. 이 방법은 부드러운 비볼록 목적에서의 최적화 및 일반화 효율성에 대한 포괄적인 분석을 제공합니다.

- **Performance Highlights**: 다양한 고전적인 연합 학습 세팅에서 A-FedPD의 효과를 검증하기 위한 광범위한 실험이 수행되었으며, 이를 통해 높은 효율성과 실용성을 입증했습니다.



### Best Arm Identification with Minimal Regr (https://arxiv.org/abs/2409.18909)
Comments:
          Preprint

- **What's New**: 최소한의 후회(minimal regret)로 최적 팔(best arm) 식별(best arm identification, BAI) 문제를 소개하며, 책임감 있는(experimentation) 실험을 요구하는 실제 응용을 모티브로 삼았습니다.

- **Technical Details**: 이 논문은 다중 팔 밴딧(multi-armed bandit) 문제의 새로운 변형을 제시합니다. 우리는 정보 이론(information-theoretic) 기법을 활용하여 기대 누적 후회(expected cumulative regret)에 대한 인스턴스 의존(instance-dependent) 하한을 설정합니다. 또한, 고정 신뢰(fixed-confidence) BAI에서 누적 후회와 샘플 복잡도(sample complexity) 간의 긴장을 강조하는 흥미로운 불가능성 결과를 제시합니다. Double KL-UCB 알고리즘을 설계하고 분석하여, 신뢰 수준(confidence level)이 0으로 수렴할 때 점근적 최적(asymptotic optimality)을 달성합니다.

- **Performance Highlights**: 이 알고리즘은 팔 선택(arm selection)을 가이드하기 위해 두 가지 신뢰 경계(confidence bounds)를 사용하여 무작위 방식(randomized manner)으로 작동합니다. 이 연구는 누적 후회와 최적 팔 식별 간의 본질적인 연결을 새롭게 조명합니다.



### In-depth Analysis of Privacy Threats in Federated Learning for Medical Data (https://arxiv.org/abs/2409.18907)
- **What's New**: 이 논문에서는 의료 데이터의 연합 학습(Federated Learning) 환경에서의 개인 정보 보호 위험을 분석하는 Holistic Framework인 MedPFL을 제안합니다.

- **Technical Details**: MedPFL 프레임워크를 통해 개인 정보 보호 공격으로부터 의료 이미지를 안전하게 보호하기 위한 효과적인 완화 전략을 개발합니다. 또한, 경험적 분석을 통해 적대자가 개인 의료 이미지를 정확하게 재구성할 수 있는 심각한 개인 정보 보호 위험을 보여줍니다.

- **Performance Highlights**: 연합 학습 환경에서의 랜덤 노이즈 추가 방어 메커니즘이 의료 이미지를 개인 정보 보호 공격으로부터 항상 효과적으로 보호하지 못함을 밝혔다. 이를 통해 의료 데이터 보호를 위한 독특하고 긴급한 도전 과제를 제시합니다.



### Multi-Source Hard and Soft Information Fusion Approach for Accurate Cryptocurrency Price Movement Prediction (https://arxiv.org/abs/2409.18895)
- **What's New**: 본 연구에서는 암호화폐 가격 예측의 정확성을 향상시키기 위한 새로운 접근 방식인 Hard and Soft Information Fusion (HSIF)를 소개합니다.

- **Technical Details**: HSIF 방식은 역사적 가격 기록과 기술적 지표를 포함하는 하드 정보와, X(구 트위터)에서 수집한 뉴스 제목 및 트윗 등의 소프트 정보를 결합합니다. 이 데이터는 기계 학습 모델인 Bidirectional Encoder Representations from Transformers (BERT) 기반의 감성 분석 방법인 Financial BERT (FinBERT)를 통해 처리됩니다. 마지막으로 처리된 하드 및 소프트 데이터를 기반으로 bidirectional long short-term memory (BiLSTM) 모델을 사용하여 장기 종속성을 포착합니다.

- **Performance Highlights**: 모델은 비트코인 관련 데이터를 테스트한 결과, 약 96.8%의 가격 변동 예측 정확도를 기록했습니다. 이 접근 방식은 소셜 감정의 영향을 확장하여 기술적 분석 예측을 보완함으로써, 단일 출처 데이터에 의존하는 기존 모델보다 우수하다는 것을 강조했습니다.



### HM3: Hierarchical Multi-Objective Model Merging for Pretrained Models (https://arxiv.org/abs/2409.18893)
- **What's New**: 모델 병합 (model merging) 기법이 발전하여 다양한 아키텍처 내에서의 병합 가능성을 제시합니다. 이전 방식은 동일한 아키텍처의 모델만을 대상으로 했으나, 이 논문은 아키텍처 공간의 병합 과정을 강화 학습 (reinforcement learning) 문제로 모델링했습니다.

- **Technical Details**: 정책 네트워크 (policy network)와 가치 네트워크 (value network)를 오프라인 샘플링 (offline sampling)을 통해 훈련하고, 이를 온라인 최적화 (online optimization)에 사용하여 병합 전략을 개선하는 방법을 설명합니다. 또한 사용자의 다양한 작업 선호를 반영하기 위해 다중 목표 최적화 (multi-objective optimization) 패러다임을 도입했습니다.

- **Performance Highlights**: 텍스트 번역 (text translation), 수학적 추론 (mathematical reasoning), 코드 생성 (code generation) 등 여러 작업에서 제안된 프레임워크의 효과성과 우수성을 실험 결과로 검증하였습니다. 코드 프로세스 검토 후 공개될 예정입니다.



### HR-Extreme: A High-Resolution Dataset for Extreme Weather Forecasting (https://arxiv.org/abs/2409.18885)
Comments:
          10 pages, under review

- **What's New**: 이 연구는 NOAA의 3-km 실시간 데이터인 High-Resolution Rapid Refresh (HRRR) 데이터를 기반으로 한 고해상도 극한 날씨 사건들로 구성된 포괄적인 데이터셋을 소개합니다. 극한 날씨 예측의 중요성을 인식하고, 부족한 데이터셋 문제를 해결하기 위해 특별히 기획되었습니다.

- **Technical Details**: 모델의 성능 평가에는 현재의 첨단 deep learning 모델과 Numerical Weather Prediction (NWP) 시스템이 포함됩니다. 연구의 주요 기여는 일반적 손실(general loss)과 HR-Extreme에서 다른 모델들에 비해 우수한 성능을 보여주는 HR-Heim이라는 개선된 baseline deep learning 모델입니다.

- **Performance Highlights**: 극한 날씨 사건의 오류가 전체 예측 오류보다 현저히 크다는 것이 밝혀졌으며, 이는 날씨 예측에서 주요 손실(source of loss)을 나타냅니다. 이러한 결과는 극한 날씨 예측의 정확성을 향상시키기 위한 향후 연구의 필요성을 강조합니다.



### CESNET-TimeSeries24: Time Series Dataset for Network Traffic Anomaly Detection and Forecasting (https://arxiv.org/abs/2409.18874)
- **What's New**: 이 논문은 네트워크 트래픽에서의 이상 탐지(anomaly detection)가 컴퓨터 네트워크의 보안을 유지하고 악의적인 활동을 식별하는 데 중요하다는 점을 강조합니다. 기존의 이상 탐지 기법에서 부족했던 실제 네트워크 데이터셋을 제공하여 이론과 실제의 간극을 메우고자 합니다.

- **Technical Details**: 저자는 CESNET3 네트워크에서 수집한 네트워크 엔티티의 행동에 대한 시계열(time series) 데이터로 구성된 데이터셋을 소개합니다. 이 데이터셋은 275,000개의 활성 IP 주소에서 40주 동안의 네트워크 트래픽 데이터를 포함하고 있습니다. ISP 출처는 네트워크 엔티티 간에 높은 수준의 변동성을 보장합니다.

- **Performance Highlights**: 이 데이터셋은 예측 기반(forecasting) 이상 탐지 접근법의 실제 적용에 대한 유용한 통찰력을 제공합니다. 다양한 네트워크 환경에서의 성능 평가에 기여할 수 있습니다.



### Challenges of Generating Structurally Diverse Graphs (https://arxiv.org/abs/2409.18859)
- **What's New**: 이 논문은 구조적으로 다양한 그래프(set of structurally diverse graphs)를 생성하는 문제를 탐구합니다. 이는 그래프 알고리즘(testing graph algorithms) 또는 신경 근사(neural approximations)를 테스트하는 데 중요할 수 있습니다.

- **Technical Details**: 논문에서는 그래프 집합의 다양성을 정의하는 방법과 이를 측정하기 위한 적절한 다양성 척도(diversity measure)를 선택하는 과정을 설명합니다. 그런 다음, 주어진 다양성 척도를 최적화하기 위해 여러 알고리즘을 제안하고 비교합니다. 여기에는 표준 랜덤 그래프 모델(standard random graph models), 지역 그래프 최적화(local graph optimization), 유전 알고리즘(genetic algorithms), 신경 생성 모델(neural generative models) 기반의 접근 방식이 포함됩니다.

- **Performance Highlights**: 기본 랜덤 그래프 생성기(Basic random graph generators)보다 다양성이 크게 향상될 수 있음을 보여주었습니다. 또한 생성된 그래프에 대한 분석을 통해 그래프 거리(graph distances)의 속성을 better 이해할 수 있으며, 최적화에 사용되는 다양성 척도에 따라 얻어진 그래프의 구조적 특성이 매우 다를 수 있음을 드러냅니다.



### Two Sparse Matrices are Better than One: Sparsifying Neural Networks with Double Sparse Factorization (https://arxiv.org/abs/2409.18850)
- **What's New**: 이번 연구에서는 Neural Network(신경망)의 크기와 복잡성을 줄이기 위한 새로운 기법, Double Sparse Factorization (DSF) 방법을 제안합니다.

- **Technical Details**: 모델의 가중치 행렬을 두 개의 Sparse(희소) 행렬로 분해하는 구조를 가지고 있으며, 이를 해결하는 것은 계산적으로 어려운 문제입니다. 따라서 ADMM (Alternating Direction Method of Multipliers) 기반의 효율적인 heuristic(휴리스틱) 방법을 제안하여 최첨단 결과를 달성하였습니다.

- **Performance Highlights**: 우리의 방법을 적용한 LLaMA2-13B 모델은 크기를 50% 줄일 수 있으며, Dense LLaMA2-7B 모델보다 더 좋은 성능을 유지합니다. 또한, Optimal Brain Compression 방법과도 비교하여 우수한 결과를 보여줍니다. 추가적인 모델 Fine-tuning(미세 조정) 후에도 정확도가 지속적으로 향상됩니다.



### ARLBench: Flexible and Efficient Benchmarking for Hyperparameter Optimization in Reinforcement Learning (https://arxiv.org/abs/2409.18827)
Comments:
          Accepted at the 17th European Workshop on Reinforcement Learning

- **What's New**: 이 논문에서는 RL(강화 학습)에서 하이퍼파라미터 최적화(HPO)의 효율적인 비교를 가능하게 하는 새로운 벤치마크인 ARLBench를 제안합니다. 이를 통해 다양한 HPO 접근 방식을 평가할 수 있습니다.

- **Technical Details**: ARLBench는 다양한 알고리즘과 환경 조합을 아우르는 HPO 작업의 대표적인 하위 집합을 선택하여 구성됩니다. 이를 통해 하이퍼파라미터 성능 프로파일을 생성하고, 이전에 필요했던 컴퓨팅 자원의 일부만으로 연구를 가능하게 합니다.

- **Performance Highlights**: 이 연구는 ARLBench를 통해 고도화된 RL 에이전트를 훈련시키기 위한 하이퍼파라미터 최적화 연구에 있어 더 많은 연구자들이 참여할 수 있도록 합니다. 벤치마크와 대규모 데이터 세트는 공개되어 있습니다.



### Hierarchical Federated ADMM (https://arxiv.org/abs/2409.18796)
- **What's New**: 본 논문에서는 널리 사용되는 gradient descent (경량 경사 하강법) 기반의 계층적 연합 학습 (hierarchical federated learning, FL) 알고리즘에서 벗어나, alternating direction method of multipliers (ADMM) 기반의 새로운 계층적 FL 프레임워크를 개발했습니다.

- **Technical Details**: 이 프레임워크 내에서 두 가지 새로운 FL 알고리즘을 제안합니다. 첫 번째 알고리즘은 상위 계층에 ADMM을 사용하고, 하위 계층에서도 ADMM을 사용하는 알고리즘과, 두 번째 알고리즘은 하위 계층에 전통적인 gradient descent 방법을 사용하는 알고리즘입니다.

- **Performance Highlights**: 제안된 알고리즘은 기존 알고리즘보다 학습 수렴성 (learning convergence) 및 정확도 (accuracy) 면에서 우수함을 실험을 통해 입증했습니다. 또한, 하위 계층에서의 gradient descent는 지역 단계 (local steps)가 매우 제한적일 경우에도 잘 작동하며, 두 계층에서 모두 ADMM을 사용할 경우 더 나은 성능을 보입니다.



### HardCore Generation: Generating Hard UNSAT Problems for Data Augmentation (https://arxiv.org/abs/2409.18778)
- **What's New**: 이 논문에서는 SAT 문제의 핵심 기여자들을 식별하고 조작하는 새로운 접근법을 제안하고 있습니다. 기존의 데이터셋의 한계를 극복하기 위해 그래프 뉴럴 네트워크를 활용한 빠른 core detection 기법을 소개하였으며, 이를 통해 도전적인 SAT 문제를 보다 효율적으로 생성할 수 있음을 보여줍니다.

- **Technical Details**: 이 연구는 'core'라고 알려진 문제의 'hardness'의 핵심 요소를 다루며, 기존의 전통적 휴리스틱(core detection techniques) 방법의 시간 비용을 절감하는 데 초점을 맞추고 있습니다. 이를 위해 그래프 뉴럴 네트워크(graph neural network)를 활용하여 빠른 core detection 절차를 개발하였습니다.

- **Performance Highlights**: 생성된 합성 SAT 문제들은 해결하기 어려운 문제를 유지하며, 원래 예제 문제의 주요 속성을 보존합니다. 실험을 통해 이러한 합성 SAT 문제들이 solver 런타임 예측의 개선에 기여할 수 있음을 입증하였습니다.



### TensorSocket: Shared Data Loading for Deep Learning Training (https://arxiv.org/abs/2409.18749)
- **What's New**: 이 논문에서는 Tensorsocket을 소개하여 딥러닝 모델 훈련의 계산 요구사항을 줄이는 방법을 제안합니다. Tensorsocket은 동시에 훈련되는 프로세스들이 동일한 데이터 로더(data loader)를 공유하도록 하여 CPU 측의 병목현상을 완화합니다.

- **Technical Details**: Tensorsocket은 collocated (동시) 훈련 작업 간의 중복 계산을 줄이고 최신 GPU-GPU interconnects를 활용합니다. 이는 GPU에서 높은 처리량을 자랑하는 작업이 CPU의 낮은 데이터 로딩 처리량 때문에 극복되지 않는 상황에서 특히 효과적입니다.

- **Performance Highlights**: Tensorsocket은 데이터 공유 없이는 실행할 수 없는 시나리오를 가능하게 하며, 훈련 처리량(training throughput)을 최대 $100\%$까지 증가시킵니다. 클라우드 인스턴스를 사용할 경우, Tensorsocket은 CPU 측에서 하드웨어 자원 요구를 줄여 $50\%$의 비용 절감 효과를 나타냅니다. 또한 Tensorsocket은 CoorDL 및 Joader와 같은 최신 솔루션을 능가하며, 더 적은 CPU 자원으로 더 높은 처리량을 달성하거나 이를 유지하는 데 용이합니다.



### Cottention: Linear Transformers With Cosine Attention (https://arxiv.org/abs/2409.18747)
Comments:
          12 pages, 5 figures

- **What's New**: 이 논문은 소프트맥스(attention mechanisms, 특히 softmax attention)의 메모리 복잡성을 극복하기 위해 코사인 유사성을 이용한 새로운 주의 메커니즘인 Cottention을 소개합니다.

- **Technical Details**: Cottention은 코사인 유사성을 활용하여 주의 방정식을 재구성함으로써 시퀀스 길이에 대해 선형 메모리 복잡성(native linear memory complexity)을 달성합니다. 이러한 성질로 인해, Cottention은 주의 계산 중 상수 메모리 사용을 가능하게 하며, 커스텀 CUDA 커널을 통해 효율적인 계산을 보장합니다.

- **Performance Highlights**: Cottention은 양방향 BERT와 인과적 GPT 태스크에서 소프트맥스 어텐션과 유사한 성능을 보여주며, 메모리 요구 사항은 상당히 감소합니다. 이를 통해 Cottention은 성능을 저하하지 않으면서 긴 시퀀스를 처리할 수 있는 유망한 대안이 됩니다.



### Rethinking the Power of Timestamps for Robust Time Series Forecasting: A Global-Local Fusion Perspectiv (https://arxiv.org/abs/2409.18696)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이번 연구에서는 GLAFF라는 새로운 프레임워크를 제안하여 시계열 예측(Time Series Forecasting)에서의 글로벌 의존성을 보다 효과적으로 모델링합니다.

- **Technical Details**: GLAFF는 시간 정보(timestamps)를 개별적으로 모델링하여 글로벌 의존성을 캡처합니다. 이 프레임워크는 플러그인(plugin)으로 작동하며, 글로벌 정보와 로컬 정보의 결합 가중치를 적응적으로 조정하여 다양한 시계열 예측 백본(backbone)과 원활하게 협력할 수 있습니다.

- **Performance Highlights**: 아홉 개의 실제 데이터셋에서 수행된 실험 결과, GLAFF는 널리 사용되는 주류 예측 모델의 평균 성능을 12.5% 향상시켰으며, 이전의 최고 성능 방법보다 5.5% 더 뛰어난 성능을 보였습니다.



### Understanding the Benefits of SimCLR Pre-Training in Two-Layer Convolutional Neural Networks (https://arxiv.org/abs/2409.18685)
Comments:
          65 pages, 4 figures

- **What's New**: 이 논문에서는 SimCLR 메소드의 이론적인 사례 연구를 소개합니다. SimCLR은 비전 작업을 위한 매우 인기 있는 대조 학습(contrastive learning) 방법으로, 레이블이 없는 데이터를 이용해 딥 뉴럴 네트워크(Deep Neural Networks)를 사전 훈련합니다.

- **Technical Details**: 이 연구는 2층 컨볼루션 신경망(CNN)을 훈련하여 장난감 이미지(data model) 데이터 모델을 학습하는 과정을 다룹니다. 특정 레이블이 있는 데이터 수에 대한 조건 하에 SimCLR 프리트레이닝(pre-training)과 감독된 미세 조정(supervised fine-tuning)이 거의 최적의 테스트 손실을 달성함을 보여줍니다.

- **Performance Highlights**: SimCLR의 프리트레이닝(label complexity)은 감독된 데이터(direct training on supervised data)에서 직접 훈련하는 것보다 훨씬 덜 요구됩니다. 이러한 분석은 더 적은 레이블로 학습할 때 SimCLR의 이점을 설명합니다.



### How green is continual learning, really? Analyzing the energy consumption in continual training of vision foundation models (https://arxiv.org/abs/2409.18664)
Comments:
          This manuscript has been accepted at the Green FOundation MOdels (GreenFOMO) ECCV 2024 Workshop

- **What's New**: 이 연구는 AI의 환경적 영향이 점점 더 커짐에 따라 지속적 학습(continual learning) 알고리즘의 에너지 효율성에 대한 체계적인 이해를 목표로 합니다. 특히, Energy NetScore라는 새로운 지표를 제안하여 에너지 소비와 정확도 간의 균형을 평가합니다.

- **Technical Details**: 이 연구는 ViT-B/16이라는 사전 훈련된 모델을 사용하여 CIFAR-100, ImageNet-R, DomainNet의 세 가지 표준 데이터 세트에서 최근의 다양한 지속적 학습 알고리즘(대표 기반, 프롬프트 기반, 예시 기반)을 비교하는 광범위한 실험을 수행했습니다. 실험에서는 에너지 소모를 측정하고, 교육 및 추론 단계에서 지속적 학습 알고리즘의 성능을 평가했습니다.

- **Performance Highlights**: 실험 결과, 지속적 학습 알고리즘의 종류에 따라 훈련 및 추론 중 에너지 소비에 매우 다른 영향을 미친다는 것을 보여주었습니다. 특히, 추론 단계에서의 에너지 소비가 지속적 학습 모델의 환경 지속 가능성 평가에 중요하다는 점이 강조되었습니다.



### Entropy, concentration, and learning: a statistical mechanics primer (https://arxiv.org/abs/2409.18630)
- **What's New**: 이 논문은 손실 최소화(loss minimization)를 통해 훈련된 인공지능 모델이 정보 이론(information theory)과 통계 물리학(statistical physics)에서 유래된 원칙에 기반하여 성공적으로 작동함을 보여줍니다. 특히, 통계 역학(statistical mechanics)의 관점에서 이러한 연결을 탐구합니다.

- **Technical Details**: AI 및 머신러닝(ML) 기반의 샘플 농도(sample concentration) 행동을 설명하기 위해 기본 원리(first-principles)에서 시작하여, 통계 역학의 발전이 exponential families의 중요성을 강조하고, 통계(statistics), 물리학(physics), 정보 이론의 양(quantity)과의 관계를 정립하고 있음을 설명합니다.

- **Performance Highlights**: 이 연구는 통계 역학을 활용해 AI 모델링 및 손실 최소화 방법에 대한 새로운 통찰을 제공하며, 기존의 원리를 통합하여 성능 향상을 도모할 수 있는 가능성을 제시합니다.



### Differentially Private Non Parametric Copulas: Generating synthetic data with non parametric copulas under privacy guarantees (https://arxiv.org/abs/2409.18611)
Comments:
          12 pages, 5 figures, deciding 2025 conference to which to submit

- **What's New**: 본 연구는 비모수적(Non-parametric) copula 기반의 합성 데이터 생성 모델인 DPNPC에 Differential Privacy를 통합한 Enhanced Fourier Perturbation 기법을 적용하여 데이터 생성의 사생활 보호를 강화하는 방법을 제시하고 있습니다.

- **Technical Details**: DPNPC 모델은 혼합형( Mixed) 테이블 데이터베이스에 대해 합성 데이터를 생성하며, 모델은 비모수적 copula를 기반으로 하여 다변량 종속성을 효과적으로 모델링합니다. 이 연구에서는 DPNPC를 PrivBayes, DP-Copula, DP-Histogram과 비교하여 사생활, 유용성(Utility), 실행 시간(Execution Time)을 평가합니다.

- **Performance Highlights**: DPNPC 모델은 작은 $
 	ext{ε}$ 값에서도 사생활을 유지하며, 훈련 시간이 단축되는 등 다른 모델들보다 향상된 성능을 보여줍니다. 그러나 다양한 인코딩 방식에 따른 성능 평가와 추가적인 프라이버시 공격에 대한 고려가 필요하다는 한계점이 존재합니다.



### TemporalPaD: a reinforcement-learning framework for temporal feature representation and dimension reduction (https://arxiv.org/abs/2409.18597)
- **What's New**: TemporalPaD는 시계열 데이터셋을 위한 새로운 end-to-end 딥러닝 프레임워크로, 강화 학습(reinforcement learning)과 신경망(neural networks)을 통합하여 특성 표현(feature representation) 및 특성 감소(feature reduction)를 동시에 진행할 수 있도록 설계되었습니다.

- **Technical Details**: TemporalPaD는 Actor-Critic(AC) 프레임워크를 기반으로 하는 세 가지 협력 모듈인 Policy Module(정책 모듈), Representation Module(표현 모듈), Classification Module(분류 모듈)로 구성됩니다. 정책 모듈은 RL을 통해 차원 축소를 담당하고, 표현 모듈은 특성을 추출하며, 분류 모듈은 비평가 역할을 합니다.

- **Performance Highlights**: TemporalPaD는 29개의 UCI 데이터셋을 사용하여 10회 독립 테스트 및 10겹 교차 검증을 통해 종합적으로 평가되었습니다. 또한, 실제 DNA 분류 문제에 적용하여 우수한 성능을 입증하였습니다. 이 프레임워크는 구조화된 데이터와 시퀀스 데이터셋 모두에 적용 가능합니다.



### Optimistic Games for Combinatorial Bayesian Optimization with Application to Protein Design (https://arxiv.org/abs/2409.18582)
- **What's New**: 이 논문에서는 새로운 게임 이론적 접근 방식인 GameOpt를 제안합니다. GameOpt는 조합 최적화 문제에서 Bayesian optimization을 적용하기 위해 개발되었으며, 복잡한 확장성을 가지는 조합 공간에서도 효율적으로 작동합니다.

- **Technical Details**: GameOpt는 서로 다른 최적화 변수 간의 협력 게임을 설정하고, 상한 신뢰 경계(acquisition function)로부터의 게임 균형 점(game equilibria)을 선택합니다. 이를 통해 조합 도메인의 복잡성을 개별 의사 결정 집합으로 분해할 수 있습니다. 이 방식은 대규모 조합 공간에 대해 스케일이 가능합니다.

- **Performance Highlights**: GameOpt는 단백질 설계(problem design) 문제에 적용되었으며, 실제 단백질 데이터셋 4개에서 성능을 검증하였습니다. 기존 방법에 비해 GameOpt는 정보성 있는 단백질 구성을 반복적으로 선택하여 높은 활성 단백질 변형을 매우 빠르게 발견하는 데 성공하였습니다.



### Using Deep Autoregressive Models as Causal Inference Engines (https://arxiv.org/abs/2409.18581)
- **What's New**: 기존의 인과 추론( causal inference ) 모델은 저차원 혼란 변수(low-dimensional confounders)와 단일 행동(singleton actions)만 처리하는 데 한계가 있었습니다. 이번 연구에서는 복잡한 혼란 변수와 순차적 행동(sequential actions)을 처리할 수 있는 자기회귀(autoregressive) CI 프레임워크를 제안합니다.

- **Technical Details**: 우리는 {	extit{sequecification}}을 통해 기저 인과 다이어그램에서 데이터를 일련의 토큰(sequence of tokens)으로 변환합니다. 이 접근 방식은 어떤 DAG(Directed Acyclic Graph)에서 생성된 데이터로 훈련할 수 있게 하며, 단일 모델을 사용하여 여러 통계량(statistical quantities) 추정을 가능하게 합니다.

- **Performance Highlights**: 이 연구는 CI( Causal Inference )에 적합하게 조정된 AR 모델이 미로 탐색(navigating mazes), 체스 엔드게임(chess endgames) 플레이, 특정 키워드가 논문 수용률에 미치는 영향 평가와 같은 다양한 복잡한 응용 프로그램에서 얼마나 효율적이고 효과적인지 보여줍니다.



### An Enhanced Federated Prototype Learning Method under Domain Shif (https://arxiv.org/abs/2409.18578)
Comments:
          8 pages, 6 figures

- **What's New**: 이 논문은 Federated Learning (FL)에서 서로 다른 도메인에서 샘플링된 데이터의 이질성(heterogeneity)이 모델 성능에 미치는 영향을 해결하기 위해 새로운 방식을 제안합니다. 특히, variance-aware dual-level prototype clustering을 도입하고 $
abla$-sparsity prototype loss를 사용하여 intra-class similarity와 inter-class similarity를 조절합니다.

- **Technical Details**: 제안된 알고리즘은 Federated Prototype Learning with Convergent Clusters (FedPLCC)로 명명되며, 클러스터 내에서 특징이 수렴하도록 개선되었습니다. 클러스터의 크기에 따라 각 프로토타입에 가중치를 부여하여 inter-class 거리를 증가시키고, 서로 다른 도메인에서 오는 프로토타입의 거리를 줄이기 위해 손실 함수 계산을 위해 일정 비율의 프로토타입만 선택합니다.

- **Performance Highlights**: Digit-5, Office-10 및 DomainNet 데이터셋에서 평가한 결과, 제안된 방법은 기존 접근 방식에 비해 더 나은 성능을 보였습니다.



### Climate Adaptation with Reinforcement Learning: Experiments with Flooding and Transportation in Copenhagen (https://arxiv.org/abs/2409.18574)
- **What's New**: 이 연구에서는 기후 변화로 인해 증가하는 극한 강우 사건에 대한 도시의 적응 전략을 최적화하기 위해 강화 학습(Reinforcement Learning, RL)을 활용한 새로운 접근 방식을 제시합니다.

- **Technical Details**: 이 프레임워크는 미래의 강우 사건과 홍수에 대한 기후 변화 예측을 통합하고, 도시 전체의 차량 이동을 모델링하였으며, 인프라와 이동성에 대한 직접적 및 간접적 영향을 평가합니다.

- **Performance Highlights**: 예비 결과에 따르면, RL 기반 접근 방식은 특정 도시 지역에서의 개입 우선순위를 정하고 이를 구현하기 위한 최적의 시기를 식별함으로써 의사결정을 크게 향상시킬 수 있음을 시사합니다.



### Towards an active-learning approach to resource allocation for population-based damage prognosis (https://arxiv.org/abs/2409.18572)
- **What's New**: 이번 연구에서는 구조 건강 모니터링(Structural Health Monitoring, SHM)에서 손상 예측(damage prognosis)의 어려움을 해결하기 위해 인구 기반 SHM(Population-Based SHM, PBSHM) 접근 방식을 채택하였습니다.

- **Technical Details**: PBSHM 접근 방식은 과거 구조물에서 수집된 데이터 정보를 활용하여 현재 손상이 진행 중인 구조물에 대한 보다 정확한 추론을 수행하는 정보를 공유하는 문제로 간주합니다. 특히 일부 데이터만으로 손상 진화의 아웃라이어(outlier)를 추론하는 도전 과제가 있습니다. 두 가지 모니터링 시스템, 즉 낮은 가용성과 높은 정확도(저 불확실성) 시스템과 널리 사용 가능하고 낮은 정확도(높은 불확실성) 시스템을 고려하여 자원의 할당 문제를 연구합니다.

- **Performance Highlights**: 활성 학습(active learning) 접근 방식을 통해 높은 정확도의 시스템이 할당될 구조물을 식별하여 전체 인구 내에서 기계 학습 모델의 예측 능력을 향상시키는 것이 이번 연구의 주요 목표입니다.



### Optimizing DNN Inference on Multi-Accelerator SoCs at Training-tim (https://arxiv.org/abs/2409.18566)
Comments:
          This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 본 논문에서는 다중 특화 컴퓨팅 유닛(CU)을 활용한 Edge에서 Deep Neural Networks (DNN)의 저지연 및 낮은 전력 소비를 위한 진보된 heterogeneous Systems-on-Chips (SoCs) 개발을 다룹니다. 이를 위해 ODiMO라는 하드웨어 인식 도구를 제시하여 DNN의 세밀한 매핑을 효율적으로 탐색합니다.

- **Technical Details**: ODiMO는 훈련 단계에서 다양한 SoC의 CU들 사이에서 DNN 레이어를 전략적으로 분할하고, 이를 병렬 처리하여 총 추론 에너지 소비 또는 지연 시간을 균형 있게 조절합니다. 이를 통해 SoC의 고유한 기능에 의해 영향을 받는 정확도를 고려하여 최적화합니다.

- **Performance Highlights**: CIFAR-10, CIFAR-100, ImageNet 데이터셋에서 DIANA와 Darkside라는 두 개의 오픈소스 heterogeneous SoC를 대상으로 실험한 결과, ODiMO는 Darkside SoC에서 수동 휴리스틱 매핑에 비해 DNN의 지연 시간을 최고 8배 줄였으며, 에너지를 목표로 할 경우 최대 50.8배 더 효율적인 매핑을 생성했습니다. 이때 정확도 저하는 0.3% 미만이었습니다.



### CodeSCAN: ScreenCast ANalysis for Video Programming Tutorials (https://arxiv.org/abs/2409.18556)
- **What's New**: 이번 논문에서는 코딩 스크린캐스트(video tutorial) 분석을 위한 대규모 데이터셋인 CodeSCAN을 소개합니다. 이는 프로그래밍 교육에서의 비디오 튜토리얼의 검색 문제를 해결하기 위해 개발되었습니다.

- **Technical Details**: CodeSCAN 데이터셋은 Visual Studio Code 환경에서 캡처된 12,000개의 스크린샷으로 구성되어 있으며, 24개의 프로그래밍 언어, 25개의 폰트(font), 90개 이상의 테마(theme), 다양한 레이아웃(layout) 변화 및 현실적인 사용자 상호작용을 포함합니다. 또한, 통합 개발 환경(IDE) 요소 탐지, 흑백 변환(color-to-black-and-white conversion), 광학 문자 인식(OCR)에 대한 세부적인 정량적(quantitative) 및 정성적(qualitative) 평가를 실시합니다.

- **Performance Highlights**: 이 연구의 결과는 코딩 스크린캐스트 분석에 대한 연구 촉진을 기대하며, 데이터셋 및 벤치마크의 소스 코드를 공개하여 연구원들이 이용할 수 있도록 하였습니다.



### Efficient Noise Mitigation for Enhancing Inference Accuracy in DNNs on Mixed-Signal Accelerators (https://arxiv.org/abs/2409.18553)
- **What's New**: 본 논문에서는 아날로그 신경망의 정확도에 미치는 프로세스 유도 및 노화 관련 변동의 영향을 완화하여 신경 모델의 강인성을 향상시키는 프레임워크를 제안합니다.

- **Technical Details**: 변동은 활성화의 정밀도에 영향을 미치는 노이즈로 모델링되며, 사전 훈련된 모델의 선택된 레이어 사이에 삽입된 디노이징 블록(denoising block)을 소개합니다. 디노이징 블록을 훈련하여 다양한 노이즈 수준에 대한 모델의 강인성을 크게 증가 시킬 수 있음을 입증하였습니다. 디노이징 블록 추가로 인한 오버헤드를 최소화하기 위해 최적의 삽입 지점을 식별하는 탐색 알고리즘을 제시하고, 혼합 신호 가속기에 통합할 수 있는 효율적인 디노이징 블록 아키텍처를 제안합니다.

- **Performance Highlights**: DNN 모델을 ImageNet 및 CIFAR-10 데이터셋에서 훈련하여 접근 방식을 평가한 결과, 평균적으로 2.03%의 파라미터 카운트 오버헤드를 수용함으로써 변동으로 인한 정확도 감소가 31.7%에서 1.15%로 줄어드는 것을 보여주었습니다.



### Wasserstein Distance-Weighted Adversarial Network for Cross-Domain Credit Risk Assessmen (https://arxiv.org/abs/2409.18544)
- **What's New**: 이 논문은 금융 기관의 신용 위험 평가를 개선하기 위한 적대적 도메인 적응(adversarial domain adaptation, ADA) 적용에 대해 다룹니다. 특히 역사적 대출 데이터의 부족 문제인 콜드 스타트(cold start) 문제와 고위험 거래의 데이터 불균형(data imbalance) 문제를 해결하는 데 초점을 맞추었습니다.

- **Technical Details**: 논문에서는 Wasserstein Distance Weighted Adversarial Domain Adaptation Network (WD-WADA)라는 개선된 ADA 프레임워크를 소개합니다. 이 방법은 Wasserstein distance를 이용해 출처(source) 도메인과 목표(target) 도메인을 효과적으로 정렬합니다. 제안된 방법은 데이터의 클래스 분포와 예측 난이도(level of difficulty)를 조정하기 위한 혁신적인 가중치(weighted) 전략을 포함합니다.

- **Performance Highlights**: WD-WADA는 콜드 스타트 문제를 완화할 뿐만 아니라 도메인 간 차이(domain differences)의 보다 정확한 측정을 제공합니다. 실제 신용 데이터셋을 통한 광범위한 실험을 통해 모델의 효과성을 입증하였으며, 이는 기존 방법들과 비교하여 교차 도메인 학습(cross-domain learning), 분류 정확도(classification accuracy), 모델 안정성(model stability)에서 우수한 성능을 보여주었습니다.



### Token Caching for Diffusion Transformer Acceleration (https://arxiv.org/abs/2409.18523)
- **What's New**: Diffusion transformers의 성능은 뛰어나지만, 높은 계산 비용이 동반됩니다. 이에 따라 TokenCache라는 새로운 사후 훈련 가속화 방법을 제안합니다.

- **Technical Details**: TokenCache는 토큰 기반 멀티 블록 아키텍처를 활용하여 추론 단계 간 토큰 간 중복 계산을 줄입니다. 세 가지 주요 질문에 답합니다: (1) 중복성을 없애기 위해 어떤 토큰을 가지칠지, (2) 어떤 블록을 효율적으로 가지칠지, (3) 속도와 품질을 균형 있게 하기 위해 언제 캐싱을 적용할지.

- **Performance Highlights**: 실험 결과, TokenCache는 여러 모델에서 diffusion transformers의 생성 품질과 추론 속도 간의 효과적인 균형을 달성하였습니다.



### Fairness-aware Multiobjective Evolutionary Learning (https://arxiv.org/abs/2409.18499)
Comments:
          14 pages

- **What's New**: 이 논문은 Multiobjective evolutionary learning (MOEL)에서 모델 훈련 중 동적으로 공정성 측정치의 대표 세트를 결정하는 방법을 제안합니다. 이는 이전에 정해진 정적 세트 대신 훈련 중에 적응적으로 변경될 수 있습니다.

- **Technical Details**: 기존의 MOEL 접근법은 데이터셋과 사전 지식에 의존하고 상당한 계산 비용이 요구되며, 공정성 측정 지표가 모델 훈련 과정에 따라 다를 수 있습니다. 본 연구에서는 12개의 잘 알려진 벤치마크 데이터셋에서 실험을 수행하여, 동적으로 결정된 공정성 측정 세트를 최적화 목표로 사용하며, 이는 훈련 과정 중에 시간에 따라 변화할 수 있습니다.

- **Performance Highlights**: 제안된 MOEL 프레임워크는 정확도와 25개의 공정성 측정을 포함하여 불공정성을 완화하기 위한 최신 방법들과 비교하여 뛰어난 성능을 보였습니다. 이러한 결과는 훈련 중 최적화 목표를 동적으로 설정하는 것이 중요함을 강조합니다.



### Treating Brain-inspired Memories as Priors for Diffusion Model to Forecast Multivariate Time Series (https://arxiv.org/abs/2409.18491)
- **What's New**: 이 논문은 Multivariate Time Series (MTS) 예측을 위한 새로운 접근 방식을 제안합니다. 인간의 기억 메커니즘에서 영감을 받아, 채널을 공유하는 뇌 기반의 메모리 모듈을 도입하여 시간적 패턴을 더 효과적으로 모델링합니다.

- **Technical Details**: 제안된 메모리 모듈은 의미적 메모리(semantic memory)와 사건적 메모리(episodic memory)로 구성됩니다. 의미적 메모리는 주기적인 이벤트와 같은 일반적인 패턴을 포착하고, 사건적 메모리는 갑작스러운 사건과 같은 특별한 패턴을 포착하는 데 사용됩니다. 또한, 메모리의 회상(recall) 및 업데이트(update) 메커니즘을 설계하여 이들 패턴을 더욱 잘 활용할 수 있습니다.

- **Performance Highlights**: 여덟 개의 데이터 세트에서 실시한 실험 결과, 제안된 뇌 기반의 메모리 강화 확산 모델은 다양한 채널에서 반복되는 시간적 패턴을 포착하고 활용하는 데 있어 우수성을 입증하였습니다. 예측의 정확성과 강건성을 현저히 향상시킵니다.



### HSTFL: A Heterogeneous Federated Learning Framework for Misaligned Spatiotemporal Forecasting (https://arxiv.org/abs/2409.18482)
Comments:
          Under review

- **What's New**: 이 논문에서는 개인 데이터에 직접 접근하지 않고도 다중 당사자가 협력하여 spatiotemporal forecasting을 수행할 수 있는 방법을 제안합니다.

- **Technical Details**: 제안된 Heterogeneous SpatioTemporal Federated Learning (HSTFL) 프레임워크는 서로 다른 도메인의 geo-distributed time series 데이터에 대해 협력할 수 있도록 하며, 개인 정보 보호를 유지합니다. 특히, 각 참여자의 spatiotemporal 의존성을 보존하도록 설계된 vertical federated spatiotemporal representation learning과 cross-client spatiotemporal 의존성을 통합하는 multi-level knowledge fusion 방식을 사용합니다.

- **Performance Highlights**: HSTFL은 inference attack에 효과적으로 저항하며, 다양한 baseline에 비해 상당한 성능 향상을 보여줍니다.



### Deep Heterogeneous Contrastive Hyper-Graph Learning for In-the-Wild Context-Aware Human Activity Recognition (https://arxiv.org/abs/2409.18481)
Comments:
          IMWUT 2023

- **What's New**: 이 논문은 Human Activity Recognition (HAR) 문제를 다루며, 다양한 맥락(context)에서 신호가 변동하는 문제를 해결하기 위한 새로운 Deep Heterogeneous Contrastive Hyper-Graph Learning (DHC-HGL) 프레임워크를 제안합니다.

- **Technical Details**: DHC-HGL은 Context-Aware HAR (CA-HAR) 데이터의 이질적인 특성을 다루기 위해, 서로 다른 세 종류의 서브 하이퍼그래프(sub-hypergraph)를 구성하고, 각각의 서브 그래프에 맞춤형 HyperGraph Convolution (HGC) 레이어를 적용하여 edge-heterogeneity를 처리합니다. 또한, node-heterogeneity를 보장하기 위해 대조 손실 함수(contrastive loss function)를 채택하였습니다.

- **Performance Highlights**: DHC-HGL은 두 가지 CA-HAR 데이터 세트에서 엄격한 평가를 수행한 결과, 기존의 최첨단 모델보다 Matthews Correlation Coefficient (MCC)에서 5.8%에서 16.7% 향상되었으며, Macro F1 점수에서 3.0%에서 8.4% 향상된 성능을 보였습니다. 또한, 학습된 CA-HAR 노드 임베딩(node embeddings)을 UMAP을 사용해 시각화하여 모델의 설명 가능성을 높였습니다.



### CycleNet: Enhancing Time Series Forecasting through Modeling Periodic Patterns (https://arxiv.org/abs/2409.18479)
- **What's New**: 이 논문은 장기 시계열 예측(Long-Term Time Series Forecasting)에서 중요한 주기성을 명시적으로 모델링하는 새로운 접근 방식을 소개합니다.

- **Technical Details**: Residual Cycle Forecasting (RCF) 기법을 도입하여 학습 가능한 반복 주기를 사용하여 시퀀스 내의 고유한 주기 패턴을 모델링하고, 모델링된 주기의 잔여 성분에 대한 예측을 수행합니다. 이 방법은 Linear layer 또는 얕은 MLP와 결합하여 CycleNet이라는 간단하지만 강력한 모델을 형성합니다.

- **Performance Highlights**: CycleNet은 전력, 날씨, 에너지를 포함한 여러 분야에서 최첨단 예측 정확도를 달성하며, 필요한 매개변수 수량을 90% 이상 줄여 효율성을 크게 개선합니다. 또한 RCF는 기존 모델(예: PatchTST, iTransformer)의 예측 정확도를 상당히 향상시킬 수 있는 혁신적인 플러그 앤 플레이(plug-and-play) 기술입니다.



### Fairness without Sensitive Attributes via Knowledge Sharing (https://arxiv.org/abs/2409.18470)
- **What's New**: 본 연구에서는 공공의 개인 정보 보호에 대한 우려가 커짐에 따라 민감한 속성 값의 접근이 제한될 수 있는 상황에서, 이를 해결하기 위한 새로운 접근법인 "Reckoner"를 제안합니다.

- **Technical Details**: Reckoner는 두 개의 모델을 사용하는 이중 모델 시스템으로, 높은 신뢰도를 가진 데이터 하위 집합에서 초기화된 모델이 낮은 신뢰도의 데이터 하위 집합에서 초기화된 모델로부터 학습합니다. 이는 편향된 예측을 피하는 데 기여합니다.

- **Performance Highlights**: 실험 결과, Reckoner는 COMPAS 데이터셋과 New Adult 데이터셋에서 정확성과 공정성 지표를 모두 고려할 때, 기존의 최첨단 방법들보다 일관되게 우수한 성과를 보였습니다.



### A TextGCN-Based Decoding Approach for Improving Remote Sensing Image Captioning (https://arxiv.org/abs/2409.18467)
Comments:
          Under Review

- **What's New**: 이번 연구는 원격 감지 이미지(remote sensing images)의 자동 캡션 생성(captioning)을 위한 새로운 접근 방식을 제안합니다. 특히, Text Graph Convolutional Network(TextGCN)와 다층 LSTM(multi-layer LSTMs)을 활용한 인코더-디코더 세트를 도입했습니다.

- **Technical Details**: 제안된 방법은 TextGCN을 통해 생성된 임베딩(embeddings)이 문장(sentence)과 코퍼스(corpus) 수준에서 단어 간 의미적 관계를 포착하여 디코더의 이해를 향상시킵니다. 또한, 최종 캡션 생성을 위한 공정한 검색 전략(fairness in the search strategy)을 보장하기 위해 비교 기반 비임 검색(comparison-based beam search) 방법을 발전시켰습니다.

- **Performance Highlights**: 우리의 방법은 BLEU-1에서 BLEU-4, METEOR, ROUGE-L, CIDEr를 포함한 7개의 메트릭(metrics)을 사용하여 3개의 데이터셋(datasets)에서 평가되었습니다. 결과적으로, 제안된 방법이 기존의 최신 인코더-디코더 프레임워크(state-of-the-art encoder-decoder methods)보다 유의미한 성능 개선을 보였습니다.



### Latent Representation Learning for Multimodal Brain Activity Translation (https://arxiv.org/abs/2409.18462)
- **What's New**: 본 연구에서는 다양한 뇌 이미징 기술을 통합하는 새로운 프레임워크인 SAMBA(Spatiotemporal Alignment of Multimodal Brain Activity)를 소개합니다. 이 프레임워크는 서로 다른 뇌 활동 데이터를 효과적으로 연결하여 최대한 포괄적으로 뇌 기능을 이해할 수 있도록 돕습니다.

- **Technical Details**: SAMBA는 모달리티 특유의 편견이 없는 통합된 잠재 공간(latent space)을 학습하여 공간(spatial) 및 시간적(temporal) 해상도 간의 간극을 줄입니다. 이 과정에서 주파수 필터링을 위한 새로운 주의(attention)-기반(wavelet decomposition) 분해 방법과 기능적 연결성을 모델링하는 그래프 주의 네트워크(Graph Attention Networks), 그리고 뇌 신호의 시간적 자기상관(temporal autocorrelation)을 캡처하기 위한 순환 레이어(recurrent layers)를 포함합니다.

- **Performance Highlights**: SAMBA의 학습 과정은 뇌 정보 처리의 풍부한 표현(representation)을 학습하는데, 이는 외부 자극이 뇌 활동을 유발하는 방식을 분류하는데 이용될 수 있습니다. 이러한 접근법은 신경과학 연구 및 임상 맥락에서의 광범위한 응용 가능성을 제시합니다.



### Towards Diverse Device Heterogeneous Federated Learning via Task Arithmetic Knowledge Integration (https://arxiv.org/abs/2409.18461)
Comments:
          NeurIPS 2024

- **What's New**: 이번 논문에서는 Fedrated Learning(Federated Learning, FL)의 한계를 극복하기 위해 TAKFL이라는 새로운 KD 기반 프레임워크를 제안합니다. 이 프레임워크는 다양한 이질적인 장치 모델의 지식 전이를 독립적으로 수행하여, 각 장치의 고유한 기여를 보존합니다.

- **Technical Details**: TAKFL은 각 장치 프로토타입의 앙상블에서 지식 전이를 별도의 작업으로 처리하며, 각 장치의 정보를 효과적으로 증류할 수 있도록 설계되었습니다. 또한, KD 기반의 self-regularization 기법을 도입하여 noise와 비지도 앙상블 증류 과정에서 발생하는 문제를 완화시킵니다.

- **Performance Highlights**: TAKFL은 컴퓨터 비전(CV) 및 자연어 처리(NLP) 작업에서 종합적인 평가를 수행하였으며, 다양한 데이터셋과 설정에서 SOTA(State Of The Art) 결과를 달성하여 기존 KD 기반 방법들보다 월등한 성능을 보였습니다.



### Review of Digital Asset Development with Graph Neural Network Unlearning (https://arxiv.org/abs/2409.18455)
- **What's New**: 이 논문은 디지털 자산 분야에서 Graph Neural Networks (GNNs)의 역할과 이에 맞춘 혁신적인 unlearning 기술을 소개합니다. 특히, 데이터 개인 정보 보호와 규제 준수의 필요성이 증가하는 배경에서 이러한 기술이 중요하다는 점을 강조합니다.

- **Technical Details**: 이 연구에서는 unlearning 전략을 데이터 기반 근사(data-driven approximation)와 모델 기반 근사(model-driven approximation)로 두 가지 주요 클래스로 분류합니다. 각각의 접근 방법은 특정 노드의 영향을 제거하기 위한 그래프 구조 변경과 GNN 내부 파라미터 및 아키텍처 수정 등을 포함합니다.

- **Performance Highlights**: 이 논문에서 제안된 방법은 사기 탐지, 위험 평가, 토큰 관계 예측 및 분산 거버넌스와 같은 다양한 사용 사례에서 효율적입니다. 또한, 실시간 금융 애플리케이션에서 모델 성능과 데이터 unlearning 요구사항 간의 균형을 맞추는 데 있어 직면하는 도전 과제를 논의하며, 두 가지 unlearning 전략의 장점을 결합한 하이브리드 접근 방식을 제안하여 GNN의 효율성과 효과성을 향상시키고자 합니다.



### Hierarchical Federated Learning with Multi-Timescale Gradient Correction (https://arxiv.org/abs/2409.18448)
Comments:
          Accepted to NeurIPS 2024

- **What's New**: 이번 논문은 기존의 중앙 서버와 클라이언트 간의 연결로만 구성된 전통적인 federated learning (FL)의 한계를 극복하기 위해 hierarchical federated learning (HFL) 접근법을 제안합니다. 특히 이 방법은 여러 단계의 집합체(aggregation points)를 활용하여 데이터의 비균일성 문제를 해결하려고 합니다.

- **Technical Details**: 이 논문에서는 multi-timescale gradient correction (MTGC) 방법론을 소개합니다. MTGC는 클라이언트의 그래디언트가 그룹 그래디언트로 조정되도록 하는 제어 변수를 도입하여 클라이언트 모델의 드리프트를 감소시키고, 그룹 그래디언트를 글로벌 그래디언트로 조정하여 그룹 모델의 드리프트도 감소시킵니다. 우리는 비볼록(non-convex) 환경에서 MTGC의 수렴 성질을 분석합니다.

- **Performance Highlights**: 다양한 데이터셋과 모델에 대한 광범위한 실험을 통해 MTGC가 다양한 HFL 환경에서 효과적임을 검증하였습니다. 제안된 알고리즘은 데이터의 비균일성에 영향을 받지 않고 안정적이라는 것을 입증합니다.



### Gradient-free Decoder Inversion in Latent Diffusion Models (https://arxiv.org/abs/2409.18442)
Comments:
          19 pages, Accepted to NeurIPS 2024

- **What's New**: 본 논문에서는 Latent Diffusion Models (LDMs)에서 효율적인 gradient-free decoder inversion 방법을 제안합니다. 이는 기존의 gradient 기반 방법이 요구하는 메모리와 시간을 대폭 줄이는 혁신적인 접근 방식입니다.

- **Technical Details**: 이 접근 방식은 다양한 latent 모델에 적용 가능하며, 이론적 수렴 특성을 연구하였습니다. 특히, forward step method와 inertial Krasnoselskii-Mann (KM) iteration을 분석하였으며, 최근 LDMs에 만족되는 완만한 코코어시비티(cocoercivity) 조건 하에 적용됩니다.

- **Performance Highlights**: Adam optimizer와 learning rate scheduling을 활용한 본 방법은 기존의 gradient 기반 방법보다 계산 시간과 메모리 소모를 획기적으로 줄였으며, noise-space watermarking과 같은 다양한 응용에서 효율적인 계산을 가능하게 하였습니다. 이로써 유사한 오류 수준을 유지하면서도 성능이 개선되었습니다.



### State-free Reinforcement Learning (https://arxiv.org/abs/2409.18439)
- **What's New**: 이 연구에서는 	extit{상태 없는 RL} (state-free RL) 문제를 다루며, 알고리즘이 환경과 상호작용하기 전에 상태 정보가 없음을 제시합니다.

- **Technical Details**: 우리는 도달할 수 있는 상태 집합 ${S}^	ext{Π} := igl	m{s | 	ext{max}_{	ext{π} 	ext{in Π}} q^{P, 	ext{π}}(s) > 0} igr	m$를 정의하고, 상태 공간 $S$에 대한 정보 없이도 작동하는 알고리즘을 설계했습니다. 이 알고리즘의 후회(regret)는 ${S}$와 완전히 독립적이며 오로지 ${S}^	ext{Π}$에만 의존합니다.

- **Performance Highlights**: 이 연구는 하이퍼 파라미터 조정이 필요 없는 	extit{파라미터 없는 RL} (parameter-free RL) 알고리즘 설계의 구체적인 첫 걸음으로 볼 수 있습니다.



### Multi-agent Reinforcement Learning for Dynamic Dispatching in Material Handling Systems (https://arxiv.org/abs/2409.18435)
- **What's New**: 본 논문은 다중 에이전트 강화 학습(MARL) 접근 방식을 통해 동적 디스패칭(dynamic dispatching) 전략을 학습하는 방법을 제안합니다. 이 연구는 다양한 산업에서 자재 처리 시스템의 처리량 최적화에 중요한 역할을 합니다.

- **Technical Details**: 본 연구에서는 실제 시스템의 복잡성을 반영한 자재 처리 환경을 개발하였으며, 다양한 위치에서의 활동, 물리적 제약 및 고유의 불확실성과 같은 요소를 포함합니다. 학습 중 탐색(employ exploration)을 개선하기 위해 기존의 동적 디스패칭 휴리스틱(heuristics)을 통합하는 방법을 제안합니다.

- **Performance Highlights**: 실험 결과, 제안한 방법은 중앙 처리량(median throughput) 측면에서 기존 휴리스틱보다 최대 7.4% 향상된 성능을 보여주었습니다. 또한 서로 다른 기능을 가진 여러 에이전트를 훈련할 때 다양한 아키텍처가 MARL 성능에 미치는 영향을 분석하였습니다. 첫 번째 MARL 에이전트를 휴리스틱으로 사용하여 두 번째 MARL 에이전트를 훈련함으로써 성과를 더욱 개선할 수 있음을 보여주고 있습니다.



### Easy2Hard-Bench: Standardized Difficulty Labels for Profiling LLM Performance and Generalization (https://arxiv.org/abs/2409.18433)
Comments:
          NeurIPS 2024 Datasets and Benchmarks Track

- **What's New**: Easy2Hard-Bench라는 새로운 벤치마크 데이터셋의 개발은 어려운 문제에서 쉽게 문제를 풀어내는 일반화 능력을 평가하기 위해 제안되었습니다. 각 문제는 숫자 형태의 난이도 점수로 주석이 달려 있습니다.

- **Technical Details**: 이 데이터셋은 수학, 프로그래밍 문제, 체스 퍼즐, 추리 문제 등 다양한 도메인에서 총 6개의 벤치마크 데이터셋으로 구성되어 있습니다. Item Response Theory (IRT)와 Glicko-2 모델과 같은 난이도 평가 시스템을 활용하여 문제에 대한 숫자 난이도 점수를 일관되게 부여합니다.

- **Performance Highlights**: 여섯 개의 최첨단 LLMs에 대한 광범위한 실험을 통해 다양한 난이도 수준에서의 성능과 일반화 능력을 총체적으로 분석하였으며, 이는 LLM 일반화에 대한 미래 연구에 영감을 줄 것입니다.



### Neural Collaborative Filtering to Detect Anomalies in Human Semantic Trajectories (https://arxiv.org/abs/2409.18427)
Comments:
          Accepted for publication in the 1st ACM SIGSPATIAL International Workshop on Geospatial Anomaly Detection (GeoAnomalies'24)

- **What's New**: 이번 연구에서는 인간의 궤적(anomaly detection in human trajectories) 이상 탐지를 위해 경량화된 모델을 개발하였습니다. 이는 기존의 차량 중심 애플리케이션에 비해 부족했던 인간 수준의 궤적 이상 탐지 연구에 기여하고자 합니다.

- **Technical Details**: 우리는 Neural Collaborative Filtering 접근법을 통해 정상적인 이동 패턴(normal mobility)을 모델링하고 예측하는 방법을 제안합니다. 이 방법은 선험적 지식(prior knowledge) 없이 인간 사용자들의 일상 패턴을 모델링함으로써, 데이터가 희소하거나 불완전한 상황(예: cold start)에서 성능을 향상시킵니다. 알고리즘은 두 개의 주요 모듈로 구성됩니다: 첫 번째는 협업 필터링 모듈(collaborative filtering module)로, 개별 사용자의 정상적인 이동 패턴을 모델링합니다. 두 번째는 신경 모듈(neural module)로, 인간 궤적 데이터에 내재된 복잡한 시공간(spatio-temporal) 관계를 해석합니다.

- **Performance Highlights**: 우리는 시뮬레이션 데이터 및 실제 데이터셋을 사용하여 기존의 최첨단 궤적 이상 탐지 방법들과 비교하고, 우리의 방법이 더 우수한 성능을 보임을 보여주었습니다.



### Dual Cone Gradient Descent for Training Physics-Informed Neural Networks (https://arxiv.org/abs/2409.18426)
- **What's New**: 본 논문에서는 Partial Differential Equations (PDEs)을 해결하기 위한 새로운 최적화 기법인 Dual Cone Gradient Descent (DCGD)를 제안합니다. 이 기법은 기존의 Physics-informed neural networks (PINNs)에서 발생하는 비대칭적인 손실 함수의 문제를 해결하는 데 중점을 두고 있습니다.

- **Technical Details**: Dual Cone Gradient Descent (DCGD)는 업데이트된 그래디언트의 방향을 조정하여 두 개의 손실 함수인 PDE 잔차 손실(PDE residual loss)과 경계 손실(boundary loss)과의 내적이 비부정적인 영역인 이중 원뿔 영역(dual cone region) 내에 있도록 합니다. 이론적으로, DCGD 알고리즘의 수렴 속성을 비볼록(non-convex) 설정에서 분석했습니다.

- **Performance Highlights**: 여러 Benchmark 방정식에서 실험을 수행한 결과, DCGD는 다양한 평가 메트릭(링크 참고)에서 다른 최적화 알고리즘을 초월하는 성능을 보여주었습니다. 특히, DCGD는 PINNs의 실패 모드(failure mode) 및 복잡한 PDE에 대한 훈련의 안정성을 향상시켰으며, 기존의 최적화 모델보다 우수한 예측 정확도를 달성했습니다. 또한, DCGD는 학습률 점진적 감소(learning rate annealing) 및 Neural Tangent Kernel (NTK)과 같은 인기 있는 PINNs 전략과 결합하여 더 향상될 수 있습니다.



### A physics-driven sensor placement optimization methodology for temperature field reconstruction (https://arxiv.org/abs/2409.18423)
- **What's New**: 이 논문에서는 물리 기반의 기준을 사용하여 센서 위치를 최적화하는 새로운 방법론인 물리 기반 센서 배치 최적화(PSPO; Physics-driven Sensor Placement Optimization) 방법을 제안합니다.

- **Technical Details**: PSPO 방법에서는 센서 위치에 따라 결정되는 조건 수(condition number)를 기반으로 하여 재구성 오류의 이론적 상한과 하한을 도출합니다. 또한, 유전 알고리즘(genetic algorithm)을 사용하여 최적의 센서 위치를 찾습니다.

- **Performance Highlights**: 실험 결과, PSPO 방법이 무작위 및 균일 선택 방법에 비해 재구성 정확도를 거의 한 자리 수 개선했으며, 기존 데이터 기반 배치 최적화 방법들과 유사한 재구성 정확도를 달성했습니다.



### A3: Active Adversarial Alignment for Source-Free Domain Adaptation (https://arxiv.org/abs/2409.18418)
Comments:
          Accepted at ICMLA 2024

- **What's New**: 본 논문은 레이블이 없는 대상 도메인으로부터 지식을 전이하기 위해 레이블이 있는 출처 도메인에서 지식을 전이하는 비지도 도메인 적응(Unsupvised Domain Adaptation, UDA) 분야의 최신 동향인 Source-free UDA에 대한 새로운 접근법인 Active Adversarial Alignment (A3)를 제안합니다.

- **Technical Details**: A3는 self-supervised learning, adversarial training, 및 active learning을 결합하여 견고한 Source-free UDA를 가능하게 합니다. 이 프레임워크는 acquisition function을 사용하여 유익하고 다양한 데이터를 능동적으로 샘플링하고 모델을 adversarial losses와 consistency regularization을 통해 적응시킵니다. 이는 출처 데이터에 접근하지 않고도 분포를 정렬합니다.

- **Performance Highlights**: A3는 효과적인 도메인 정렬 및 노이즈 감소를 위해 능동적 및 적대적 학습의 시너지를 활용하여 Source-free UDA를 발전시킵니다.



### VickreyFeedback: Cost-efficient Data Construction for Reinforcement Learning from Human Feedback (https://arxiv.org/abs/2409.18417)
Comments:
          16 pages, 5 figures

- **What's New**: 이 논문은 Reinforcement Learning from Human Feedback (RLHF)의 비용 효율성에 초점을 맞추고 있습니다. 기존의 preference dataset(선호도 데이터셋)의 경제적 유용성에 대한 고려가 부족했음을 지적하며, 이를 해결하기 위해 새로운 경매 메커니즘을 도입합니다.

- **Technical Details**: RLHF는 대규모 언어 모델(LLM)의 결과에 대한 인간의 선호도를 반영하기 위해 인간의 피드백을 활용합니다. 논문에서는 기존 알고리즘이 복잡한 비전이성(preference)이거나 순환적 관계를 처리하지 못하는 문제를 다룹니다. 경매 메커니즘을 사용하여 선호도 데이터 수집의 효율성을 높이는 방법을 제시합니다.

- **Performance Highlights**: 실험 결과, 제안된 경매 기반 프로토콜은 고품질 피드백에 집중함으로써 LLM의 fine-tuning에서 비용 효율성을 개선하면서도 만족스러운 모델 성능을 유지하는 데 기여한다는 것이 입증되었습니다.



### Embed and Emulate: Contrastive representations for simulation-based inferenc (https://arxiv.org/abs/2409.18402)
- **What's New**: 본 논문에서는 고차원 물리 시스템을 효율적으로 처리할 수 있는 새로운 시뮬레이션 기반 추론(SBI) 방법, Embed and Emulate (E&E)를 소개합니다. E&E는 대조 학습(contrastive learning)에 기반하여 복잡한 다중 모드(multi-modal) 매개변수 후분포를 처리합니다.

- **Technical Details**: E&E는 데이터의 낮은 차원 잠재 임베딩(latent embedding)과 해당 잠재 공간에서의 빠른 에뮬레이터(emulator)를 학습합니다. 이를 통해 고비용의 시뮬레이션이나 고차원 에뮬레이터를 필요로 하지 않고도 데이터 생성과 매개변수 추정을 수행할 수 있습니다.

- **Performance Highlights**: E&E가 기존 방법들보다 우수한 성능을 발휘함을 실제적인 비식별 파라미터 추정 작업에 대해 보여주었으며, 고차원의 혼돈 시스템인 Lorenz 96을 사용한 합성 실험에서 이론적 속성을 입증하였습니다.



### Discovery and inversion of the viscoelastic wave equation in inhomogeneous media (https://arxiv.org/abs/2409.18370)
- **What's New**: 본 논문에서는 드문 데이터(sparse data)와 노이즈가 많은 데이터(noisy data)로부터 부분 미분 방정식(partial differential equations)을 정확하게 식별하는 데 있어 새로운 하이브리드 프레임워크를 제안합니다.

- **Technical Details**: 이 프레임워크는 발견(discovery) 및 임베딩(embedding)이라는 두 가지 방향 최적화(alternating direction optimization) 단계로 구성됩니다. 발견 단계에서는 현재 잘 개발된 드문 회귀 기법을 사용하여 관측치로부터 지배 방정식을 예비적으로 식별합니다. 임베딩 단계에서는 순환 합성곱 신경망(recurrent convolutional neural network, RCNN)을 구현하여 이산화된 파동 방정식의 시간-공간(iterations in time-space) 반복 과정을 효율적으로 처리합니다.

- **Performance Highlights**: 제안된 방법은 고수준의 노이즈와 제한된 데이터 가용성에도 불구하고 뛰어난 강인성(robustness)과 정확성(accuracy)을 보여줍니다. 다양한 시나리오에서 파동 방정식을 실험하여 이 방법의 성능을 평가하였고, 그 결과 주요 물리 방정식을 신뢰성 있게 식별할 수 있음을 확인하였습니다.



### Generative AI for fast and accurate Statistical Computation of Fluids (https://arxiv.org/abs/2409.18359)
Comments:
          71 pages, 30 figures

- **What's New**: 이 논문에서는 3차원 난류 유체 유동의 빠르고 정확하며 강건한 통계 계산을 위한 생성 AI 알고리즘인 GenCFD를 제안합니다. 이 알고리즘은 조건부 스코어 기반의 diffusion model을 기반으로 합니다.

- **Technical Details**: GenCFD는 비압축성(incompressible) 및 압축성(compressible) 유체 유동에 대한 광범위한 수치 실험을 통해 통계적 양(mean, variance, point pdfs, higher-order moments)의 정확한 근사를 제공하며, 난류 유체 유동의 고품질 현실적인 샘플을 생성하고 우수한 스펙트럼 해상도를 보장합니다.

- **Performance Highlights**: 기존의 평균 제곱 오차(mean (absolute) square errors)를 최소화하도록 훈련된 operator learning 기반의 앙상블은 평균 유동(mean flow)으로 회귀하는 것과 대조적으로, 본 알고리즘은 통계적 양의 정확한 근사치를 제공합니다. 또한, 본 논문에서는 diffusion models가 유체 유동을 정확하게 생성하는 놀라운 메커니즘에 대한 엄격한 이론적 결과를 제시합니다.



### FedDCL: a federated data collaboration learning as a hybrid-type privacy-preserving framework based on federated learning and data collaboration (https://arxiv.org/abs/2409.18356)
Comments:
          18 pages, 6 figures, 3 tables

- **What's New**: 이번 연구에서는 연속적인 외부 통신이 극도로 어려운 상황에서도 적용 가능한 연합 데이터 협업 학습(FedDCL) 프레임워크를 제안합니다.

- **Technical Details**: FedDCL 프레임워크에서 각 사용자 기관은 차원 감소된 중간 표현(data representation)을 독립적으로 구성하고, 이를 인접 기관과 내부 그룹 DC 서버에서 공유합니다. 각 DC 서버에서는 중간 표현을 협업 표현(collaboration representations)으로 변환하고, 그룹 내 서버 간에 연합 학습(federated learning)을 수행합니다.

- **Performance Highlights**: 제안된 FedDCL의 성능은 기존의 연합 학습과 비교할 때 동등한 성능을 보여주었습니다.



### Benchmarking Graph Conformal Prediction: Empirical Analysis, Scalability, and Theoretical Insights (https://arxiv.org/abs/2409.18332)
- **What's New**: 이번 논문에서는 기계 학습 모델의 불확실성을 정량화하는 conformal prediction에 대한 최근 연구 흐름을 다루고, 특히 그래프 데이터에 대한 불확실성 정량화에 대한 적합한 방법론을 제시합니다. 기존 연구의 구현과 평가의 모순을 분석하고, 대규모 그래프 데이터셋에 대한 방법 효율성을 높이는 기술을 소개합니다.

- **Technical Details**: 이 연구에서는 기존 방법론의 선택을 분석하고, 이를 기반으로 대규모 그래프 데이터셋을 처리하기 위한 새로운 기법을 제안합니다. 주요 기법은 확장 가능성과 성능을 유지하면서 기존 그래프 conformal prediction 방법을 조정하는 것입니다.

- **Performance Highlights**: 이론적 및 경험적 결과를 통해, 제안된 기법이 대규모 그래프 데이터셋에서 성능 저하 없이 적용 가능함을 입증합니다. 향후 그래프 conformal prediction 연구에 대한 권장 사항도 포함되어 있습니다.



### DMC-VB: A Benchmark for Representation Learning for Control with Visual Distractors (https://arxiv.org/abs/2409.18330)
Comments:
          NeurIPS 2024 Datasets and Benchmarks Track. Dataset available at: this https URL

- **What's New**: 이번 논문에서는 DeepMind Control Visual Benchmark (DMC-VB)를 소개합니다. 이 데이터셋은 DeepMind Control Suite에서 수집되었으며, 시각적 방해 요소가 있는 상황에서 오프라인 강화 학습(offline reinforcement learning) 에이전트의 강인함을 평가하는 데 사용됩니다.

- **Technical Details**: DMC-VB는 다양한 난이도의 이동 및 탐색(task) 작업을 조합하며, 정적(static) 및 동적(dynamic) 시각적 변화를 포함하고, 서로 다른 기술 수준(skill level)의 정책(policy)으로 생성된 데이터를 고려합니다. 또한, 상태(state)와 픽셀 관찰(pixel observation)의 쌍을 체계적으로 제공하며, 규모는 수십 배 크고 숨겨진 목표에 대한 작업도 포함됩니다.

- **Performance Highlights**: 실험 결과, 사전 학습(pretrained)된 표현(representations)은 DMC-VB에서 정책 학습에 도움이 되지 않으며, 픽셀 관찰에서 학습된 정책과 상태에서 학습된 정책 간에 큰 표현 격차(representation gap)가 존재함을 알 수 있었습니다. 또한, 전문가 데이터가 제한적일 때는 불완전한 데이터(suboptimal data) 및 확률론적(hidden stochastic) 숨겨진 목표가 있는 작업에서 사전 학습된 표현을 통해 정책 학습이 개선될 수 있음을 보여주었습니다.



### Towards the Mitigation of Confirmation Bias in Semi-supervised Learning: a Debiased Training Perspectiv (https://arxiv.org/abs/2409.18316)
Comments:
          11 pages, 4 figures

- **What's New**: 이번 논문은 Semi-supervised learning (SSL)에서 발생하는 confirmation bias 문제를 해결하기 위한 새로운 프레임워크인 TaMatch를 소개합니다. TaMatch는 교육 단계에서 매번 누적되는 편향을 수정하기 위해 debiased pseudo labels의 생성과 활용 방법에 대한 통찰을 제공합니다.

- **Technical Details**: TaMatch는 prior target distribution과 모델의 학습 상태에서 파생된 스케일링 비율을 사용하여 각 훈련 단계에서 편향을 추정하고 수정합니다. 이 비율은 레이블이 없는 데이터에 대한 원시 예측을 조정하여 debiased pseudo labels를 생성하고, 예측된 클래스에 따라 다르게 가중치를 부여하여 학습의 공정성을 높입니다.

- **Performance Highlights**: TaMatch는 이미지 분류 작업에서 기존의 최신 방법들보다 현저히 뛰어난 성능을 보이며, SSL에서 pseudo labels의 생성과 활용의 중요성을 강조합니다.



### Realistic Evaluation of Model Merging for Compositional Generalization (https://arxiv.org/abs/2409.18314)
- **What's New**: 본 논문에서는 다양한 merging 방법론의 상대적인 장점을 평가하고, 이를 통해 각 방법의 실제 요구 사항을 명확히 하였습니다. 특히, 이미지 분류(image classification), 이미지 생성(image generation), 자연어 처리(natural language processing) 분야에서의 compositional generalization을 위한 merging에 초점을 맞추었습니다.

- **Technical Details**: 연구는 다양한 merging 방법을 일관된 실험 환경에서 비교하였으며, 모델 아키텍처(model architecture), 데이터 가용성(data availability), 계산 예산(computational budget)에 대한 가정이 서로 다를 수 있음을 강조합니다. 또한, 각 merging 방법이 필요로 하는 계산 비용(computational costs)과 병합되는 모델 수가 증가할 때의 성능을 측정하였습니다.

- **Performance Highlights**: 연구 결과는 모델 병합(model merging) 분야의 현재 상태를 명확히 하고, 새로운 방법을 시험할 수 있는 포괄적이고 엄격한 실험 Setup을 제공합니다.



### Causality-based Subject and Task Fingerprints using fMRI Time-series Data (https://arxiv.org/abs/2409.18298)
- **What's New**: 이번 논문은 뇌의 복잡한 상관관계를 밝혀내는 시스템 신경과학의 인과 모델에 대한 새로운 연구 동향을 다루고 있습니다. 특히 fMRI(기능적 자기공명영상)에서 인과성을 기반으로 한 접근법을 사용하여 개인의 인지 패턴을 식별하는 방법을 제안합니다.

- **Technical Details**: 논문에서 제안하는 방법은 'spatio-temporal' (공간-시간적) 인과 서명을 추출하기 위해 두 가지 시간 척도의 선형 상태-공간 모델을 설정합니다. 여기서 'causal fingerprint' (인과 지문)의 개념을 정량화하며, 기존의 다른 지문 연구와 차별화된 점은 인과관계 관점에서 지문을 정량화한다는 것입니다. 이 과정은 모드 분해(modal decomposition) 및 투영 방법과 GNN 기반(그래프 신경망) 모델을 사용하여 수행됩니다.

- **Performance Highlights**: 실험 결과와 비인과적 기반 방법들과의 비교를 통해 제안된 방법의 효과성을 입증하였습니다. 결과적으로, 뇌 기능에 대한 기존 이해를 바탕으로 얻어진 인과 서명의 생물학적 관련성을 논의합니다. 본 연구는 건강한 대조군 및 신경퇴행성 질환에 대한 잠재적 응용을 목표로 하는 인과 지문 연구의 후속 연구에 길을 열어줍니다.



### Enhancing Lossy Compression Through Cross-Field Information for Scientific Applications (https://arxiv.org/abs/2409.18295)
Comments:
          9 pages, 9 figures, accepted by DRBSD-10

- **What's New**: 본 논문은 과학 데이터 세트 내에서의 중요한 교차 필드 상관 관계를 식별하고, CNN(Convolutional Neural Network)을 이용하여 이러한 정보를 추출하는 새로운 하이브리드 예측 모델을 제안합니다.

- **Technical Details**: 제안된 하이브리드 모델은 기존의 로컬 필드 정보와 결합하여 교차 필드 정보를 활용합니다. 이를 통해 예측 정확성을 높이고, 손실 압축(lossy compression) 성능을 개선합니다.

- **Performance Highlights**: 이 모델은 세 가지 과학 데이터 세트에서 검증되었으며, 특정 오류 한계 내에서 압축 비율을 최대 25% 개선하고, 데이터 세부정보를 더 잘 보존하며, 아티팩트(artifacts)를 줄이는 성능을 보였습니다.



### Criticality and Safety Margins for Reinforcement Learning (https://arxiv.org/abs/2409.18289)
Comments:
          17 pages, 10 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 이 논문에서는 최근 강화 학습(Reinforcement Learning) 방법들이 안전하지 않은 상황을 만날 수 있다는 점을 다루고 있습니다. 이에 따라, 이러한 상황을 식별하는 것이 분석 및 실행 과정에서 인간의 감시를 요청할 수 있는 이점을 제공할 수 있는 중요성을 강조하고 있습니다.

- **Technical Details**: 논문에서는 true criticality와 proxy criticality라는 두 가지 개념을 도입하여, 강화 학습 에이전트가 정책(policy)에서 벗어나 무작위 행동을 n번 연속으로 따를 때 예상되는 보상의 감소를 기반으로 합니다. true criticality는 구체적인 지표로 작용하며, proxy criticality는 통계적으로 true criticality와 단조롭게(monotonic) 관계를 구성하는 저오버헤드(low-overhead) 메트릭입니다. 이 메트릭들은 신뢰 구간 내에서 tolerable 성능 손실을 초과하지 않는 무작위 행동의 수로 정의된 안전 여유(safety margins)에 의해 더욱 설명 가능합니다.

- **Performance Highlights**: Atari Beamrider 환경에서 A3C 에이전트를 사용하여 한 실험을 진행한 결과, 최소 5%의 안전 여유가 47%의 에이전트 손실을 포함하는 것으로 나타났습니다. 즉, 5%의 결정을 감독함으로써 에이전트의 오류를 약 50% 예방할 수 있다는 것을 제시합니다. 이러한 점에서 이 프레임워크는 나쁜 결정이 이루어지기 전에 그 잠재적 영향을 측정할 수 있어, 자율 에이전트의 더 효과적인 디버깅(debugging)과 감독을 가능하게 합니다.



### SLIDE: A machine-learning based method for forced dynamic response estimation of multibody systems (https://arxiv.org/abs/2409.18272)
Comments:
          Paper currently in submission for journal publication

- **What's New**: 이 논문에서는 기계 및 다물체 시스템의 출력 시퀀스를 추정하기 위해 설계된 딥러닝 기반의 새로운 방법인 SLiding-window Initially-truncated Dynamic-response Estimator (SLIDE)를 소개합니다. 이 방법은 강제 자극이 주어진 경우뿐만 아니라 그 외의 경우에도 적용 가능합니다.

- **Technical Details**: SLIDE는 감쇠 시스템(damped systems)의 동적 반응(dynamic response)을 전체 시스템 상태를 요구하지 않고 추정할 수 있는 능력이 특징입니다. 이 방법은 초기 효과(initial effects)의 감소에 따라 출력 윈도우(output window)를 잘라내어 사용하며, 이는 시스템의 선형화된 방정식의 복소 고유값(complex eigenvalues)으로 근사됩니다. 두 번째 신경망(neural network)은 오차 추정을 제공하도록 훈련되어 이 방법의 적용 가능성을 더욱 향상시킵니다.

- **Performance Highlights**: 이 방법은 듀핑 오실레이터(Duffing oscillator), 유연한 슬라이더-크랭크 시스템(flexible slider-crank system), 유연한 소켓에 장착된 산업용 6R 조작기(6R manipulator) 등 다양한 시스템에 적용되었습니다. 결과적으로, 시뮬레이션(simulation) 속도가 수백만 배에 이르는 성능 향상을 보여주며, 실시간 성능을 대폭 초과합니다.



### Using dynamic loss weighting to boost improvements in forecast stability (https://arxiv.org/abs/2409.18267)
- **What's New**: 본 논문은 N-BEATS 모델의 확장을 통해 정확도(accuracy) 외에도 예측 안정성(forecast stability)을 추가 최적화 목표로 포함하는 방법을 제안합니다.

- **Technical Details**: 연구에서는 예측 오차(forecast error)와 예측 불안정성(forecast instability) 성분을 포함한 복합 손실 함수(composite loss function)를 최소화하여 더 안정적인 예측을 얻는 방법을 다룹니다. 또한, 동적 손실 가중치(dynamic loss weighting) 알고리즘을 적용하여 훈련 중 손실 가중치를 변경하는 방법에 대해 연구했습니다. 타사 랜덤 가중치(Task-Aware Random Weighting) 접근 방식의 확장이 가장 높은 성능을 나타냅니다.

- **Performance Highlights**: 여러 동적 손실 가중치 방법들이 안정성을 높이면서 정확도를 저해하지 않는 목표를 달성했음을 보여주었고, 제안된 방법이 가장 뛰어난 성능을 보였습니다.



### Task-recency bias strikes back: Adapting covariances in Exemplar-Free Class Incremental Learning (https://arxiv.org/abs/2409.18265)
Comments:
          Accepted for NeurIPS 2024

- **What's New**: 본 논문에서는 과거 데이터에 접근할 수 없는 상황에서 모델을 훈련하는 Exemplar-Free Class Incremental Learning (EFCIL) 문제를 다룹니다. 기존의 최첨단 방법은 클래스들을 나타내기 위해 Gaussian 분포를 사용하지만, 두 가지 주요 문제로 인해 그 효과성이 제한됩니다.

- **Technical Details**: 첫 번째 문제는 각 클래스의 공분산 행렬(covariance matrices)이 변화하고 매 작업(task)마다 적응해야 한다는 점입니다. 두 번째 문제는 훈련 중 발생하는 차원 축소(dimensionality collapse)로 인한 작업 최신성(task-recency) 편향입니다. 본 연구에서는 AdaGauss라는 새로운 방법을 제안하여, 작업 간 공분산 행렬을 적응시키고 추가적인 anti-collapse 손실 함수(loss function)를 통해 작업 최신성 편향을 완화합니다.

- **Performance Highlights**: AdaGauss는 기존의 EFCIL 벤치마크(benchmarks) 및 데이터셋(datasets)에서 최상급 결과를 나타내며, 스크래치부터 훈련할 때나 사전 훈련(pre-trained)된 모델에서 시작할 때 모두 우수한 성과를 보여줍니다.



### Trustworthy Text-to-Image Diffusion Models: A Timely and Focused Survey (https://arxiv.org/abs/2409.18214)
Comments:
          under review

- **What's New**: 이번 논문은 Text-to-Image (T2I) Diffusion Models (DMs)의 신뢰성을 조사하기 위한 새로운 접근 방식을 제시합니다. 기존의 연구가 T2I DMs의 특성에 부족했던 점을 보완하여, 신뢰성에 관한 통합적인 분석을 제공합니다.

- **Technical Details**: T2I DMs의 비기능적 속성(robustness, fairness, security, privacy, factuality, explainability)과 관련된 여러 방법(falsification, enhancement, verification & validation, assessment)을 탐구합니다. 정의/측정항목에 기반한 최근 문헌의 제안 방법을 요약합니다.

- **Performance Highlights**: 연구 결과를 바탕으로 T2I DMs의 벤치마크와 도메인 애플리케이션을 평가하고, 현재 연구의 격차를 강조합니다. 기존 방법의 한계를 논의하고, 신뢰할 수 있는 T2I DMs 개발을 위한 향후 연구 방향을 제안합니다.



### Bridging OOD Detection and Generalization: A Graph-Theoretic View (https://arxiv.org/abs/2409.18205)
Comments:
          NeurIPS 2024. arXiv admin note: text overlap with arXiv:2310.06221 by other authors

- **What's New**: 본 논문에서는 현대 머신러닝의 문맥에서 OOD(out-of-distribution) 일반화와 탐지 문제를 통합적으로 해결할 수 있는 새로운 그래프 이론(graph-theoretic) 프레임워크를 제안합니다.

- **Technical Details**: 제안된 방법은 그래프의 인접 행렬(adjacency matrix)의 분해(factorization)를 통해 데이터 표현을 얻으며, 이를 통해 OOD 일반화 및 탐지 성능을 정량화하는 오류를 증명할 수 있습니다. 이론적 기초를 바탕으로 한 접근 방식으로, 두 가지 문제를 함께 해결할 수 있는 가능성을 보여줍니다.

- **Performance Highlights**: 실험 결과는 기존 방법들에 비해 경쟁력 있는 성능을 나타내며, 이론적 근거를 뒷받침하는 결과를 보여줍니다. 관련 코드는 공개적으로 제공됩니다.



### Jump Diffusion-Informed Neural Networks with Transfer Learning for Accurate American Option Pricing under Data Scarcity (https://arxiv.org/abs/2409.18168)
- **What's New**: 이번 연구는 미국식 옵션(American option) 가격 책정을 위한 포괄적 프레임워크를 제시하며, 비선형 최적화 알고리즘(nonlinear optimization algorithms), 해석적 및 수치 모델(analytical and numerical models), 신경망(neural networks)을 결합하여 가격 책정 성능을 개선합니다.

- **Technical Details**: 제안된 프레임워크는 데이터 부족(scarce data) 문제를 해결하기 위해 수치적 데이터 증강(numerical data augmentation) 및 물리적으로 제약이 있는 점프 확산(jump diffusion process) 기반 신경망을 통합하여 로그 수익 분포의 레프토쿠르토시스(leptokurtosis)를 포착합니다. Bayesian 최적화를 통한 워밍업 기간(warm-up period)을 설계하여 최적의 데이터 손실(data loss) 및 물리적 손실(physical loss) 계수를 제공합니다.

- **Performance Highlights**: 여섯 개의 사례 연구(experimental case studies)의 실험 결과는 프레임워크의 정확성, 수렴성(convergence), 물리적 효과성(physical effectiveness), 일반화(generalization)를 입증하며, 특히 깊은 아웃 오브 더 머니 옵션(deep out-of-the-money options) 가격 책정에서 우수한 성능을 보여줍니다.



### A Survey on Neural Architecture Search Based on Reinforcement Learning (https://arxiv.org/abs/2409.18163)
- **What's New**: 딥러닝의 폭발적인 발전 덕분에 기계 학습의 feature extraction 자동화가 성공적으로 이루어졌습니다. 이제 연구자들은 최적의 네트워크 구조와 하이퍼파라미터를 자동으로 찾을 수 있는 방법을 모색하고 있습니다.

- **Technical Details**: 논문에서는 Neural Architecture Search (NAS)의 전반적인 발전 상황을 소개하고, 특히 reinforcement learning과 관련된 NAS 작업의 개요를 제공합니다. 또한, 복잡한 구조와 자원이 부족한 환경에서의 개선 및 변형에 대해 논의합니다.

- **Performance Highlights**: Neural Architecture Search를 통해 다양한 작업에 최적화된 네트워크 구조를 자동적으로 발견할 수 있는 가능성이 열리며, 이는 성능 향상에 큰 기여를 할 것으로 기대됩니다.



### Most Influential Subset Selection: Challenges, Promises, and Beyond (https://arxiv.org/abs/2409.18153)
Comments:
          Accepted at the 38th Conference on Neural Information Processing Systems (NeurIPS 2024)

- **What's New**: 이번 논문은 기계 학습 모델의 행동이 훈련 데이터에 어떻게 기여하는지를 분석하는 방법을 다룹니다. 특히 기존 영향 함수(influence function)가 개별 샘플들의 영향을 설명하는 데 한계를 보임을 지적하고, Most Influential Subset Selection (MISS) 문제를 통해 집합 샘플들의 집합적 영향력을 효과적으로 캡처하려고 합니다.

- **Technical Details**: MISS 문제는 가장 큰 집단적 영향을 미치는 훈련 샘플의 부분 집합(subset)을 식별하는 것을 목표로 합니다. 논문에서는 기존 MISS 접근 방식의 강점과 약점을 분석하고 influence-based greedy heuristics 알고리즘이 선형 회귀(linear regression)에서도 실패할 수 있음을 입증합니다. 이를 통해, 영향 함수의 오류와 집단적 영향의 비가법적(non-additive) 구조 같은 실패 모드를 구체적으로 설명합니다. 반대로, 이러한 휴리스틱(heuristics)을 반복적으로 적용하는 적응형(adaptive) 버전의 효과를 보여주며, 샘플 간 상호 작용을 효과적으로 캡처할 수 있음을 입증합니다.

- **Performance Highlights**: real-world 데이터셋을 통한 실험은 이론적 발견을 뒷받침하며, 적응성이 분류(task classification) 작업과 비선형 신경망(non-linear neural networks) 같은 복잡한 시나리오에도 효과적임을 보여줍니다. 마지막으로, 성능과 컴퓨팅 효율성(c computational efficiency) 간의 본질적인 트레이드오프(trade-off)를 강조하며, 선형 데이터 모델링 점수(linear datamodeling score)와 같은 가법(additive) 메트릭의 사용에 대해 의문을 제기합니다.



### PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation (https://arxiv.org/abs/2409.18964)
Comments:
          Accepted to ECCV 2024. Project page: this https URL

- **What's New**: PhysGen은 단일 이미지를 입력으로 사용하여 현실적이고 물리적으로 그럴듯한 비디오를 생성하는 혁신적인 이미지-비디오 생성 방법입니다. 주목할 점은 이미지에 적용된 힘과 토크와 같은 입력 조건을 활용하여 동적 영상을 생성하는 것입니다.

- **Technical Details**: PhysGen의 핵심 구성 요소는 세 가지로 나눌 수 있습니다: (i) 이미지의 기하학, 재료 및 물리적 매개변수를 효과적으로 캡처하는 이미지 이해 모듈; (ii) 강체 물리학(rigid-body physics)과 유추된 매개변수를 사용하는 이미지 공간 동적 시뮬레이션 모델; (iii) 생성적 영상 확산(generative video diffusion) 기법을 활용해 시뮬레이션된 동작을 포함하는 현실적인 비디오 영상을 생성하는 이미지 기반 렌더링 및 정제 모듈입니다.

- **Performance Highlights**: PhysGen을 통해 생성된 비디오는 물리적 사실성과 외관 측면에서 현실적이며 정교한 제어가 가능합니다. 기존의 데이터 기반 이미지-비디오 생성 연구들과의 정량적 비교 및 포괄적인 사용자 연구를 통해 뛰어난 결과를 보여줍니다.



### Exploring Token Pruning in Vision State Space Models (https://arxiv.org/abs/2409.18962)
Comments:
          NeurIPS'24

- **What's New**: 본 논문에서는 State Space Models (SSMs)을 기반으로 한 비전 모델의 효율성을 향상시키기 위해 토큰 기반의 프루닝(token pruning) 기법을 제안합니다. 기존의 Vision Transformers (ViTs) 기술을 활용한 토큰 프루닝 기법의 제한점을 분석하고, SSM의 고유한 계산 특성을 고려하여 새로운 방법을 개발했습니다.

- **Technical Details**: 제안된 방법은 pruning-aware hidden state alignment 기법을 도입하여 남아있는 토큰의 이웃을 안정화하고, SSM 모델에 적합한 토큰 중요성 평가(token importance evaluation) 방법을 통해 토큰 프루닝을 수행합니다. 이로 인해 효율적인 구현 및 실질적인 가속화가 이루어집니다.

- **Performance Highlights**: 제안된 방법은 ImageNet에서 41.6\%의 FLOPs 감소와 함께 81.7\%의 정확도를 달성하며, 다양한 작업에서 성능에 미치는 영향을 최소화하면서도 계산량을 대폭 줄일 수 있음을 입증했습니다. 또한, 이 연구는 SSM 기반 비전 모델의 동작을 이해하는 데 더 깊은 통찰을 제공합니다.



### LML: Language Model Learning a Dataset for Data-Augmented Prediction (https://arxiv.org/abs/2409.18957)
Comments:
          First version

- **What's New**: 이 논문은 대규모 언어 모델(LLMs)을 분류 작업에 활용하기 위한 새로운 접근 방식을 소개합니다. 전통적인 머신 러닝(ML) 모델들과는 달리, LLMs를 사용하여 데이터 정리(data cleaning)와 특징 공학(feature engineering)을 간소화합니다.

- **Technical Details**: 이 논문은 'Language Model Learning (LML)'이라는 새로운 개념과 'Data-Augmented Prediction (DAP)'이라는 새로운 방법을 제안합니다. LLM이 데이터를 탐색하고 이해하며 분류를 결정하는 방식으로 분류를 수행합니다. DAP 과정에서는 데이터 요약을 사용하여 자동으로 쿼리를 생성하고, 이를 통해 관련 데이터 행을 검색한 후, 최종적인 분류 결과를 생성합니다.

- **Performance Highlights**: 테스트 사례에서 시스템의 정확도가 90%를 초과하여 기존 ML 모델을 다양한 시나리오에서 초월할 가능성을 입증하였습니다. 사용자가 예측의 논리를 검토할 수 있도록 'Explainable Machine Learning Model'로 행위하는 문구를 프롬프트에 포함시킴으로써 예측의 해석 가능성을 향상시켰습니다.



### RepairBench: Leaderboard of Frontier Models for Program Repair (https://arxiv.org/abs/2409.18952)
- **What's New**: RepairBench는 AI 기반 프로그램 수리의 새로운 리더보드로, 실행 기반 평가를 사용하여 패치를 테스트하는 방식을 채택합니다.

- **Technical Details**: RepairBench는 Defects4J와 GitBug-Java라는 두 가지 고품질 벤치를 활용하여 최신 모델의 성능을 실제 프로그램 수리 작업에 대해 평가합니다. 모든 패치는 컴파일되고 테스트 스위트에 대해 실행됩니다.

- **Performance Highlights**: RepairBench는 최신 모델들이 어떻게 작동하는지를 빈번하고 표준화된 방법으로 평가할 수 있는 기회를 제공합니다. 또한, 이 평가 프레임워크는 공개되어 새로운 모델이 출시될 때마다 업데이트됩니다.



### Spectral Wavelet Dropout: Regularization in the Wavelet Domain (https://arxiv.org/abs/2409.18951)
Comments:
          Accepted by The International Conference on Machine Learning and Applications (ICMLA) 2024

- **What's New**: 이번 연구에서는 Spectral Wavelet Dropout (SWD)이라는 새로운 정규화 (regularization) 방법을 소개합니다. 이 방법은 1D-SWD와 2D-SWD 두 가지 변형을 포함하며, CNN의 일반화 (generalization) 능력을 향상시킵니다.

- **Technical Details**: SWD는 특징 맵의 이산 웨이브렛 분해 (discrete wavelet decomposition)에서 세부 주파수 대역을 무작위로 제거하여 작동합니다. SWD는 기존의 Spectral "Fourier" Dropout (2D-SFD)와 다르게, 주파수 영역(Fourier domain)에서 계수를 제거하는 대신 웨이브렛을 사용합니다. SWD는 단일 하이퍼파라미터만 요구하며, 1D-SFD의 1차원 버전도 구현하여 포괄적인 비교 연구를 수행합니다.

- **Performance Highlights**: CIFAR-10/100 벤치마크에서 1D 및 2D SWD 변형은 1D-SFD 및 2D-SFD에 비해 뛰어난 성능을 보였습니다. 특히, 1D-SWD는 1D/2D-SFD에 비해 계산 복잡도가 현저히 낮습니다. Pascal VOC 객체 탐지 벤치마크에서도 SWD 변형이 1D-SFD 및 2D-SFD를 초월하는 성능과 낮은 계산 복잡도를 보여주었습니다.



### Unconditional stability of a recurrent neural circuit implementing divisive normalization (https://arxiv.org/abs/2409.18946)
- **What's New**: 본 연구에서는 생물학적으로 그럴듯한 신경역학 모델의 안정성을 높이기 위해 동적 분배 정규화(dynamic divisive normalization, DN)와 ORGaNICs 회로 모델의 안정성을 연결했습니다. 이는 다양한 신경생리학적 현상을 모사할 수 있는 회로 모델입니다.

- **Technical Details**: 우리는 Lyapunov의 간접법을 사용하여 재귀 가중치 행렬이 단위 행렬일 때 임의 차원의 ORGaNICs 회로에 대한 무조건적 지역 안정성을 증명했습니다. 또한 이를 커플링된 감쇠 조화 진동기 시스템에 연결하여 회로의 에너지 함수 도출과 함께 회로와 개별 뉴런이 달성하고자 하는 목표를 규명합니다. 일반적인 재귀 가중치 행렬의 경우 2D 모델의 안정성을 증명하고, 더 높은 차원에서도 안정성이 유지됨을 실험적으로 입증했습니다.

- **Performance Highlights**: ORGaNICs는 자체적인 안정성 특성과 적응형 시간 상수 덕분에 폭발, 소멸 및 진동하는 그래디언트 문제를 해결하며, 시간에 따른 역전파(backpropagation through time) 방법으로 훈련될 수 있습니다. RNN 벤치마크에서 ORGaNICs는 정적 이미지 분류 작업에서 대안 신경역학 모델보다 우수한 성능을 보였으며, 순차 작업에서는 LSTM과 유사한 성능을 나타냈습니다.



### Probabilistic Analysis of Least Squares, Orthogonal Projection, and QR Factorization Algorithms Subject to Gaussian Nois (https://arxiv.org/abs/2409.18905)
- **What's New**: 본 논문에서는 Liesen et al. (2002)의 연구를 확장하여, 직교 정규 행렬 Q에 열(column) c를 추가했을 때의 조건 수(condition number) 변화에 대한 분석을 수행합니다. 이 연구는 Q의 범위(span)에 대해 c의 수직성(perpendicularity)에 특히 중점을 두고 있습니다.

- **Technical Details**: 우리는 정확한 산술(Exact Arithmetic)과 Q의 완전한 직교 정규성(perfect orthonormality) 가정을 하지 않고 행렬 B의 조건 수 증가에 대한 경계를 도출합니다. 이러한 접근은 QR 인수분해(QR factorization) 알고리즘과 같은 수치적 방법을 적용할 때 발생하는 문제들을 해결할 수 있는 기반을 제공합니다.

- **Performance Highlights**: 또한, 우리는 가우시안 노이즈(Gaussian noise) 하에서의 직교 투영(orthogonal projection) 및 최소 제곱(least squares)의 성능에 대한 결과를 제공하여, 이론 개발을 더욱 지지하고 있습니다.



### Simulating Dynamic Tumor Contrast Enhancement in Breast MRI using Conditional Generative Adversarial Networks (https://arxiv.org/abs/2409.18872)
- **What's New**: 이번 논문은 유방 MRI에서 가상 대비 증강(virtual contrast enhancement) 방법을 제시하며, 기존의 대비 물질 기반 DCE-MRI(Dynamic Contrast-Enhanced MRI) 방식에 대한 비침습적(alternative) 대안을 제공합니다.

- **Technical Details**: 우리는 조건부 생성적 적대 신경망(conditional generative adversarial network, GAN)을 사용하여 대비가 없는 MRI에서 DCE-MRI 이미지를 예측하고, 여러 대응 DCE-MRI 시간 점의 순차적으로 생성된 이미지를 포함합니다. 이를 통해 종양의 위치(Localization) 파악과 특성 분석(Characterization)이 가능해지며, 관련된 건강 위험을 피할 수 있습니다.

- **Performance Highlights**: 우리는 합성된 DCE-MRI 이미지의 질적(qualitatively) 및 정량적(quantitatively) 평가를 수행하고, 종양 분할(tumor segmentation) 하위 작업에서의 유용성을 평가하기 위해 다중 메트릭(SAMe)을 제안합니다. 이 접근법은 현실적(realistic)이고 유용한 DCE-MRI 시퀀스를 생성하는 데 있어 유망한 결과를 보여주며, 특히 대비 물질 투여가 금기인 환자의 유방암 진단 및 치료 향상에 대한 가능성을 강조합니다.



### Individuation in Neural Models with and without Visual Grounding (https://arxiv.org/abs/2409.18868)
- **What's New**: 이 논문에서는 CLIP 모델과 FastText, SBERT와 같은 텍스트 전용 모델 간의 individuating (개별화) 정보 인코딩의 차이를 보여줍니다.

- **Technical Details**: CLIP 모델이 제공하는 latent representations (잠재 표현)을 연구하며, 기초(substrates), 미세한 집합(granular aggregates), 다양한 수의 객체에 대한 정보를 분석합니다.

- **Performance Highlights**: CLIP 임베딩은 텍스트 전용 데이터로 훈련된 모델들보다 individuating (개별화)에서 정량적 차이를 더 잘 포착하며, 이로부터 도출한 individuating hierarchy (개별화 계층)는 언어학 및 인지 과학에서 제안된 계층과 일치합니다.



### Positional Encoder Graph Quantile Neural Networks for Geographic Data (https://arxiv.org/abs/2409.18865)
Comments:
          17 main text pages, 4 figures

- **What's New**: 이번 논문에서는 Positional Encoder Graph Neural Networks (PE-GNNs)의 한계를 극복하기 위해 Positional Encoder Graph Quantile Neural Network (PE-GQNN)를 소개합니다. 이 방법은 PE-GNNs와 Quantile Neural Networks, 다시 조정 기술을 결합하여 예측 분포에 대한 최소한의 가정을 가지고 완전히 비모수적인 프레임워크를 제공합니다.

- **Technical Details**: PE-GQNN의 새로운 네트워크 아키텍처를 제안하며, quantile 기반 손실 함수를 결합하여 계산 복잡성을 증가시키지 않고도 정확하고 신뢰할 수 있는 확률적 모델을 생성합니다. 또한 KNN 예측기를 모델에 통합할 수 있는 구조화된 방법을 소개하며, GNN 레이어 연산을 통해 데이터 누수를 방지합니다.

- **Performance Highlights**: 벤치마크 데이터셋에 대한 실험 결과, PE-GQNN은 예측 정확도와 불확실성 정량화 모두에서 기존의 최고 수준의 방법들보다 상당한 개선을 나타냅니다.



### Classical Statistical (In-Sample) Intuitions Don't Generalize Well: A Note on Bias-Variance Tradeoffs, Overfitting and Moving from Fixed to Random Designs (https://arxiv.org/abs/2409.18842)
- **What's New**: 이번 논문은 현대 기계 학습(ML)에서 나타나는 이질적인 현상인 double descent와 benign overfitting이 고전 통계학의 직관과 정반대의 모습을 보이는 이유를 설명합니다. 특히, 고전 통계학 교과서에서 배운 직관들이 고정 설계(fixed design) 설정에서 비롯되었다고 강조합니다.

- **Technical Details**: 논문은 ML의 예측을 일반화 오류(generalization error), 즉 랜덤 설계(random designs)에서의 예측 오류로 평가함에 따라 학습 결과가 과거와 다르게 나타나는 이유를 분석합니다. 이러한 고정 설계에서의 사람 인식은 resampling과 noisy outcomes의 관계에서 주로 형성되었다고 합니다. 이 변화가 bias-variance tradeoff와 관련이 깊고, ML에서 double descent와 benign overfitting 현상을 관찰하는 것의 가능성과 불가능성에 대해서도 논의합니다.

- **Performance Highlights**: 이 연구에서는 고정 설계와 랜덤 설계에서 ML 성능의 차이점을 명확히하고, 이러한 차이가 통계학의 기초 직관에 미치는 영향을 밝히며, ML의 성능을 이해하는 데 도움이 되는 새로운 관점을 제시합니다.



### Constructing Confidence Intervals for 'the' Generalization Error -- a Comprehensive Benchmark Study (https://arxiv.org/abs/2409.18836)
- **What's New**: 이번 연구는 머신러닝에서 예측 모델의 품질을 평가하기 위한 신뢰 구간(confidence intervals, CIs) 방법의 종합적 비교 연구입니다. 이는 기존의 연구들과 다르게, 총 13가지 방법을 18개의 테이블 회귀 및 분류 문제를 통해 비교 분석한 첫 대규모 연구로 자리잡고 있습니다.

- **Technical Details**: 이 연구에서는 다양한 재샘플링 절차와 분산 추정 기법을 결합한 13가지 CIs 계산 방법을 검토했습니다. 연구의 기초는 CIs의 구성 시 발생하는 도전 과제들을 포함하여, 네 가지 달리기 모델(inducers)과 여덟 가지 손실 함수(loss functions)를 사용했습니다. 또한, 상대적인 커버리지 빈도(relative coverage frequency), 폭(width), 그리고 런타임(runtime)을 기준으로 CIs 방법들을 평가했습니다.

- **Performance Highlights**: 결과적으로, 이 연구는 추천할 수 있는 방법의 하위 집합을 식별하였고, 연구에 사용된 데이터셋을 OpenML에 벤치마킹 세트로 게시하고 코드를 GitHub에 공개하여 후속 연구의 기초로 삼을 수 있도록 했습니다.



### Classification and regression of trajectories rendered as images via 2D Convolutional Neural Networks (https://arxiv.org/abs/2409.18832)
Comments:
          13 pages, 5 figures

- **What's New**: 이번 연구는 CNN (Convolutional Neural Networks)을 사용하여 다양한 형식으로 렌더링된 합성 궤적(synthetic trajectories)을 이미지로 변환하여 분류(classification) 및 회귀(regression) 문제를 해결하는 효과를 조사합니다.

- **Technical Details**: 본 연구에서는 궤적을 이미지로 변환할 때의 파라미터로 선 두께(line thickness), 이미지 해상도(image resolution), 동작 이력(motion history, 시간 요소의 색상 코딩), 앨리어싱 방지(anti-aliasing) 등을 고려하였습니다. CNN은 이미지에서 특징(feature)의 공간적 계층(spatial hierarchies)을 학습하는 능력을 활용하여 복잡한 형태를 인식합니다.

- **Performance Highlights**: 실험 결과에 따르면, 운동 방향이 중요한 응용 프로그램에서는 모델의 깊이에 따라 적절한 이미지 해상도를 선택하는 것이 중요하다. 또한, 궤적을 이미지로 렌더링함으로써 발생할 수 있는 정보 손실과 스펙트럼 변화 등의 아티팩트(artifacts)를 고려하는 것이 필수적입니다.



### Early diagnosis of Alzheimer's disease from MRI images with deep learning mod (https://arxiv.org/abs/2409.18814)
Comments:
          7 pages, 3 figures, Presented at the 20-th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP) 21-22 February, 2024, Mazandaran University of Science and Technology, Babol, Iran

- **What's New**: 이 연구에서는 알츠하이머병(Alzheimer's disease, AD) 진단을 위한 새로운 방법으로 합성 소수 샘플 오버샘플링 기술(SMOTE)과 사전 훈련된 CNN(Convolutional Neural Network)을 활용한 뇌 MRI(Magnetic Resonance Imaging) 분석 프레임워크를 제안합니다.

- **Technical Details**: 이 프레임워크는 환자의 의료 기록, 신경심리학적 검사, MRI를 포함한 다양한 접근 방식을 통해 알츠하이머병의 특징을 식별합니다. 특히, Kaggle에서 얻은 이미지 데이터셋의 클래스 불균형 문제를 SMOTE를 통해 해결하였고, DEMNET라는 알츠하이머 네트워크에 사전 훈련된 CNN을 적용하여 중요한 특징들을 추출했습니다.

- **Performance Highlights**: 제안된 모델은 98.67%의 높은 정확도로 알츠하이머병 이미지를 분류하는 성능을 달성하였습니다.



### Convergence of Diffusion Models Under the Manifold Hypothesis in High-Dimensions (https://arxiv.org/abs/2409.18804)
- **What's New**: 이번 연구에서는 Denoising Diffusion Probabilistic Models (DDPM)을 매니폴드 가설(manifold hypothesis) 하에서 분석하고, 이 모델들이 점수(score)를 학습하는 데 있어서 환경 차원(ambient dimension)와 독립적인 속도로 성과를 달성함을 증명하였습니다.

- **Technical Details**: 이 연구는 DDPM과 잘 알려진 가우시안 프로세스(Gaussian Processes)의 극한(extrema) 이론을 연결하는 새로운 프레임워크를 개발하여 수행되었습니다. 샘플링(sampling)의 경우 Kullback-Leibler divergence에 대해 환경 차원과 독립적인 속도를, Wasserstein distance에 대해 O(√D)의 속도를 얻었습니다.

- **Performance Highlights**: 본 연구의 결과는 DDPM이 높은 차원 데이터 분포에서의 실질적인 성과를 가지고 있으며, 매니폴드 가설을 통해 그 효용성을 크게 향상시킬 수 있음을 보여줍니다.



### Esports Debut as a Medal Event at 2023 Asian Games: Exploring Public Perceptions with BERTopic and GPT-4 Topic Fine-Tuning (https://arxiv.org/abs/2409.18798)
- **What's New**: 이번 연구는 2023 아시안 게임에서의 e스포츠에 대한 대중의 의견과 가치 공동 창출(co-creation) 과정을 LLM-enhanced BERTopic 모델링 분석을 통해 조사하였습니다.

- **Technical Details**: 다섯 가지 주요 테마를 통해 대중의 인식과 주요 이해관계자들이 e스포츠 생태계 내외에서 가치를 공동 창출하는 방식을 식별했습니다. 소셜 미디어 마케팅의 전략적 사용이 대중의 의견에 영향을 미치고 e스포츠 이벤트 및 브랜드를 홍보하는 데 중요한 역할을 했습니다.

- **Performance Highlights**: e스포츠가 메달 이벤트로 포함되면서 보다 넓은 수용을 보여주었고, 부정적인 대중의 인식을 완화하는 데 기여했습니다. 전통적인 e스포츠 생태계 외부의 이해관계자들이 기여한 가치가 국가 대표 및 성과 증진에 중요한 역할을 했음을 발견했습니다. 이는 e스포츠를 스포츠로 정당화하는 지속적인 노력에 대한 지지를 나타냅니다.



### Supervised Learning Model for Key Frame Identification from Cow Teat Videos (https://arxiv.org/abs/2409.18797)
- **What's New**: 이 논문에서는 신경망(neural networks)과 비디오 분석(video analysis)을 이용하여 젖소의 유선 염증(티티스, mastitis) 위험 평가의 정확성을 향상시키는 방법을 제안합니다.

- **Technical Details**: 젖소의 티티스 감염을 탐지하기 위해, 저자들은 촬영된 비디오에서 유선이 온전하게 보이는 주요 프레임을 식별하는 신경망을 사용합니다. 이러한 주요 프레임은 수의사들이 유선 건강 상태를 평가할 시간적 유연성을 제공하며, 평가의 효율성과 정확성을 증가시킵니다. 복잡한 환경, 변화하는 소의 자세와 위치, 비디오에서 유선을 식별하는 어려움 등이 주요 도전과제로 제시됩니다.

- **Performance Highlights**: 제안된 방법은 유선 비디오에서 주요 프레임을 식별하는 데 있어 단일 거리 척도 또는 모델을 사용할 때보다 성능(F-score)이 향상된 것으로 나타났습니다.



### A method of using RSVD in residual calculation of LowBit GEMM (https://arxiv.org/abs/2409.18772)
- **What's New**: 최근 하드웨어 기술의 발전이 저정밀(low-precision) 애플리케이션에 많은 가능성을 제공하고 있으나, 저정밀 사용 시 계산 정확도를 유지하는 데 큰 도전이 있어왔습니다. 본 논문에서는 저랭크(residual low-rank) 근사를 도입한 low-rank residuals quantized matrix multiplication (LRQMM) 방법을 제안합니다.

- **Technical Details**: LRQMM은 밀집 상태의 저정밀 정량화(matrix multiplication) 행렬 곱셈에서 저랭크(residual low-rank) 근사를 통해 잔여 보상을 수행하는 방법입니다. BLAS-2 수준의 추가 시간 오버헤드만으로 여러 배의 정확도 향상을 가져올 수 있으며, 이 방법은 추가 데이터 없이도 사전 훈련(pre-training)이 가능합니다. 또한, LRQMM은 저정밀 GEMM 연산자와만 작동하여 다른 방법들과 쉽게 결합할 수 있다는 장점이 있습니다.

- **Performance Highlights**: 실험 결과, LRQMM은 직접 정량화된(matrix multiplication) 행렬 곱셈의 오류를 1~2 오더 만큼 줄일 수 있으며, 대규모 행렬 크기를 다룰 때 계산 속도는 약 20%만 감소합니다. 심층 학습 네트워크에서 LRQMM-4bit는 Resnet-50 구조에서 ImageNet Top-1 정확도가 61.8%에 달하며, 직접 정량화의 정확도는 8.3%에 불과합니다.



### Learning from Demonstration with Implicit Nonlinear Dynamics Models (https://arxiv.org/abs/2409.18768)
Comments:
          21 pages, 9 figures

- **What's New**: 이 논문에서는 Learning from Demonstration (LfD) 프로세스의 오류 누적 문제를 해결하는 새로운 접근 방식을 제안합니다. 고정 비선형 동적 시스템을 포함하는 독창적인 신경망 레이어를 개발하여, 동적 특성을 조정할 수 있도록 하였습니다.

- **Technical Details**: 이 새로운 신경망 레이어는 reservoir computing에 영감을 받아 설계되었으며, 기존의 신경망 아키텍처에 통합하여 인간의 필기 동작을 재현하는 LASA Human Handwriting Dataset을 사용하여 검증했습니다. 이를 통해 정책 실행 시 오류 누적 문제를 효과적으로 해결하였습니다.

- **Performance Highlights**: 경험적 실험 결과, 제안한 레이어를 통합한 모델이 기존의 정책 예측의 시간적 앙상블 및 Echo State Networks (ESNs)와 비교할 때 필기 작업에서 더 높은 정확도와 강건성을 보여주었으며, 다양한 동적 조건에서도 일반화할 수 있는 성능을 보였습니다.



### Geometric deep learning for galaxy-halo connection: a case study for galaxy intrinsic alignments (https://arxiv.org/abs/2409.18761)
Comments:
          12 pages, 5 figures. submitted to MNRAS

- **What's New**: 이번 연구에서는 космологии(우주론) 이미징 조사에서 요구되는 대규모 시뮬레이션을 위한 새로운 접근 방식을 제안합니다. 특히, Intrinsic Alignments(내재 정렬) 현상을 모델링하기 위해 Deep Generative Model(딥 생성 모델)을 사용하여 3D 은하 형태와 방향을 샘플링합니다.

- **Technical Details**: 제안된 모델은 SO(3) $	imes$ $	ext{R}^n$ 확산 생성 모델로, 은하의 방향성과 n개의 스칼라특성을 함께 모델링합니다. E(3) 동형의 Graph Neural Networks(그래프 신경망)를 사용하여 우리 우주를 구성하는 유클리드 대칭을 명시적으로 존중하면서 구현됩니다.

- **Performance Highlights**: 모델은 은하의 방향성, 크기, 형태 및 색상과 같은 유클리드와 비유클리드 특성을 일관되게 예측할 수 있는 능력을 보여줍니다. 이러한 능력은 Compsonsic (복잡한) 은하 물리학의 영향을 받는 비선형 스케일에서 통계적으로 일관된 은하 방향성을 학습하고 예측하는 데 기여합니다.



### MemFusionMap: Working Memory Fusion for Online Vectorized HD Map Construction (https://arxiv.org/abs/2409.18737)
- **What's New**: 이 논문에서는 자율 주행 시스템을 위한 고해상도 (HD) 맵 구축에 개선된 시간적 추론 능력을 가진 MemFusionMap이라는 새로운 모델을 제안합니다.

- **Technical Details**: MemFusionMap은 역사적 프레임 간의 추론을 개선하는 작업 메모리 융합 모듈을 포함하며, 차량의 궤적 정보를 명시적으로 인지하도록 설계된 새로운 시간적 오버랩 히트맵을 도입합니다. 이러한 두 가지 설계를 통합하여 HD 맵 구축의 성능을 크게 향상시킵니다.

- **Performance Highlights**: MemFusionMap은 기존 방법들보다 최대 5.4% 높은 mAP (mean Average Precision)를 기록하여 성능이 크게 향상되었습니다.



### Autoregressive Policy Optimization for Constrained Allocation Tasks (https://arxiv.org/abs/2409.18735)
Comments:
          Accepted at NeurIPS 2024

- **What's New**: 이 논문에서는 한정된 자원을 각 개체(entity)에 배분해야 하는 제약 할당 작업(constrained allocation tasks)을 다루고 있습니다. 특히 자율 회귀 과정(autoregressive process)을 기반으로 하는 새로운 방법을 제안하고 초기에 발생하는 편향을 상쇄하기 위한 새로운 디바이싱 메커니즘(de-biasing mechanism)을 도입하였습니다.

- **Technical Details**: 이 방법은 각 개체에 대한 할당을 순차적으로 샘플링하는 방식으로 설계되었습니다. 제약 조건(linear constraints)에 따라 투자자들은 특정 산업 부문에 자금의 30% 이상을 할당할 수 없다는 등의 규칙이 있습니다. 이는 허용되는 할당(action space)을 복잡하게 제한하므로 제약을 위반하지 않는 정책을 학습하기 어렵습니다.

- **Performance Highlights**: 제안한 방법은 포트폴리오 최적화(portfolio optimization), 컴퓨팅 작업 분배(computational workload distribution), 그리고 합성 할당 벤치마크(synthetic allocation benchmark)의 세 가지 제약 할당 작업에서 다양한 제약 강화 학습(Constrained Reinforcement Learning, CRL) 방법들과 비교하여 뛰어난 성능을 보였습니다.



### Scalable Cross-Entropy Loss for Sequential Recommendations with Large Item Catalogs (https://arxiv.org/abs/2409.18721)
Comments:
          11 pages, accepted for RecSys'24

- **What's New**: 본 논문은 기존의 Cross-Entropy (CE) 손실 함수를 대체하는 새로운 Scalable Cross-Entropy (SCE) 손실 함수를 소개합니다. 이 SCE 손실 함수는 큰 항목 목록을 다루는 데이터 세트에서 CE 손실을 근사하여, 추천 품질을 유지하면서도 시간 효율성과 메모리 사용량을 개선합니다.

- **Technical Details**: SCE 손실 함수는 선택적인 GPU 효율적 계산 전략을 활용하여, 카탈ログ에서 가장 유익한 요소에 집중하고 특히 false positives 가능성이 높은 요소에 중점을 둡니다. 이를 위해 최대 내부 곱 검색(maximum inner product search)을 통해 모델 출력의 하위 집합에 대한 softmax 분포를 근사합니다.

- **Performance Highlights**: 실험 결과, SCE는 다른 대안들과 비교하여 최대 메모리 사용량을 100배까지 줄이면서도 성능 지표를 유지하거나 초과하는 효과를 입증했습니다. 이 접근법은 대규모 언어 모델과 같은 다양한 도메인에서의 대규모 개발 가능성도 열어줍니다.



### Enhancing Spectrum Efficiency in 6G Satellite Networks: A GAIL-Powered Policy Learning via Asynchronous Federated Inverse Reinforcement Learning (https://arxiv.org/abs/2409.18718)
Comments:
          Submitted to IEEE Transactions on Mobile Computing (16 pages, 10 figures)

- **What's New**: 이 논문에서는 비가시 통신망(Non-Terrestrial Networks, NTN)에서의 빔포밍(Beamforming), 스펙트럼 할당(Spectrum Allocation), 원격 사용자 장비(Remote User Equipment, RUE) 연관 최적화를 위한 새로운 생성적 적대 모방 학습(Generative Adversarial Imitation Learning, GAIL) 기반 정책 학습 접근법을 제안합니다.

- **Technical Details**: 이 접근법은 전통적인 강화 학습(Reward Learning) 방법의 제한을 극복하기 위해 역강화 학습(Inverse Reinforcement Learning, IRL)과 GAIL 프레임워크를 활용하여 수동 설계 없이 자동으로 보상 함수(Reward Function)를 학습합니다. 또한 비동기 연합 학습(Asynchronous Federated Learning) 방식을 융합하여 분산된 다중 위성 시스템이 협력하여 최적 정책을 도출할 수 있게 합니다.

- **Performance Highlights**: 제안된 다중 에이전트 비동기 연합 IRL(MA-AFIRL) 방법은 전통적인 RL 접근 방식보다 성능이 뛰어나며, 수렴 및 보상 값에서 $14.6\%$ 향상을 달성했습니다. 이 GAIL 기반 정책 학습은 6G NTN 최적화를 위한 새로운 벤치마크를 설정합니다.



### MG-Net: Learn to Customize QAOA with Circuit Depth Awareness (https://arxiv.org/abs/2409.18692)
Comments:
          29 pages, 16 figures

- **What's New**: 이번 논문에서는 Quantum Approximate Optimization Algorithm (QAOA)와 그 변형들이 조합 최적화(combinatorial optimization) 문제를 해결하는 데 가진 잠재력을 분석합니다. 특히, QAOA의 수렴(convergence) 행동을 연구하고, 문제 특유의 회로 깊이(circuit depth)와 관련된 딜레마를 다룹니다.

- **Technical Details**: 우리는 Mixer Generator Network (MG-Net)라는 새로운 심층 학습(deep learning) 프레임워크를 제안합니다. MG-Net은 특정 작업(task)과 회로 깊이에 따라 최적의 mixer Hamiltonians를 동적으로 생성하는 기능을 가지고 있습니다. 이 네트워크는 Ising 모델과 최대 컷(maximum cut) 문제와 같은 여러 시뮬레이션을 통해 성능을 입증했습니다.

- **Performance Highlights**: MG-Net은 64 큐비트(qubits)까지의 위상별(Max-Cut instances)와 Ising 모델에서 높은 근사 비율(approximation ratio)과 효율성(efficiency)을 보여줍니다.



### Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow (https://arxiv.org/abs/2409.18628)
Comments:
          Keywords: Epistemic Uncertainty - Out-of-Distribution Detection - CT Segmentation - OAR contouring - Radiotherapy

- **What's New**: 본 연구는 방사선 치료 계획에서의 목표 구조물 및 위험 장기(Organ-at-Risk, OAR)의 윤곽을 정확히 지정하는 것의 중요성을 강조하며, 최근 딥러닝(deep learning)의 발전을 통해 OAR 윤곽화 성능을 개선했으나, OOD(out-of-distribution) 시나리오의 신뢰성 문제를 다루고 있다. 특히, epistemic uncertainty(계량적 불확실성) 추정 통합을 통해 OOD 감지를 위한 새로운 방법론을 제시한다.

- **Technical Details**: 연구에서는 OAR 윤곽화 워크플로우에 epistemic uncertainty estimation을 통합하여 임상적으로 관련 있는 시나리오에서 OOD를 감지하는 방법을 제안한다. 구체적으로 설계된 데이터 세트를 사용하여 OOD 감지를 위한 고급 통계적 방법을 도입하고, 예측의 신뢰성이 떨어지는 사례를 식별하는 데 효과적임을 입증한다.

- **Performance Highlights**: 이 연구에서 제안한 접근법은 OOD 감지를 위한 AUC-ROC(Area Under the Curve - Receiver Operating Characteristic)를 0.95로 달성하였으며, 임플란트 사례에 대한 특이도(specificity) 0.95 및 민감도(sensitivity) 0.92를 기록하였다. 이는 모델 예측의 신뢰성을 판단하는 데 있어 전문가의 검토가 필요한 경우를 효과적으로 표시하는 데 기여한다.



### Unsupervised Cognition (https://arxiv.org/abs/2409.18624)
- **What's New**: 본 논문에서는 최신 인지 모델에 영감을 받아서 의사결정을 위한 기존의 획기적인 primitive 기반 비지도학습(unconstrained learning) 접근 방식을 제안합니다.

- **Technical Details**: 이 방법론은 입력 공간을 독립적으로 구성된 분산 계층 구조(distributed hierarchical structure)로 모델링합니다. 이는 기존의 비지도 학습(classification) 기법들과 비교되며, 특히 암 유형 분류(cancer type classification)에 집중하여 성능을 평가합니다.

- **Performance Highlights**: 제안된 접근 방식은 기존의 최첨단 비지도 학습 알고리즘뿐만 아니라 감독 학습(supervised learning) 알고리즘을 초월하여 더 나은 성능과 인지 모델과 유사한 행동 패턴을 보여줍니다.



### ASAG2024: A Combined Benchmark for Short Answer Grading (https://arxiv.org/abs/2409.18596)
Comments:
          Accepted at SIGCSE-Virtual 2024

- **What's New**: 이 연구는 여러 학과, 채점 기준 및 분포에 걸쳐 통합된 단답형 채점 벤치마크인 ASAG2024를 소개합니다. 이는 자동 채점 시스템의 비교를 용이하게 계속 할 수 있게 합니다.

- **Technical Details**: ASAG2024 벤치마크는 일곱 개의 일반적으로 사용되는 단답형 채점 데이터셋을 통합하여 공통 구조 및 채점 기준을 제공합니다. 연구에서는 최근의 단답형 채점 방법들의 성능을 평가하였으며, LLM 기반 접근 방식이 새로운 높은 점수를 기록하지만 여전히 인간의 성능에 미치지 못한다는 것을 보여주었습니다.

- **Performance Highlights**: 최근 SAG 방법들은 이전보다 높은 점수를 기록했지만, 인간 채점자의 성능과 비교할 때 여전히 큰 간극이 존재합니다. 이는 향후 연구에서 인간-기계 SAG 시스템의 가능성을 열어줍니다.



### "Oh LLM, I'm Asking Thee, Please Give Me a Decision Tree": Zero-Shot Decision Tree Induction and Embedding with Large Language Models (https://arxiv.org/abs/2409.18594)
- **What's New**: 이번 연구에서는 대규모 언어 모델(LLMs)이 데이터가 제한적인 상황에서 예측 모델링을 위해 사전 지식을 활용하는 강력한 방법을 제공함을 보여줍니다. 특히, LLMs이 훈련 데이터 없이도 본질적으로 해석 가능한 머신 러닝 모델인 의사결정나무(decision trees)를 생성할 수 있음을 설명합니다.

- **Technical Details**: 이 연구에서는 LLMs가 압축된 세계 지식을 활용하여 제로샷(Zero-shot) 의사결정나무를 생성하는 방법을 보여줍니다. 이 의사결정나무는 작고 간단한 테이블 데이터셋(tabular datasets)에 대해 데이터 기반 의사결정나무보다 뛰어난 성능을 보일 수 있습니다. 또한, 이 나무에서 파생된 임베딩(embeddings)은 평균적으로 데이터 기반 의사결정나무에서 파생된 것들과 동등한 성능을 나타냅니다.

- **Performance Highlights**: 지식 기반 의사결정나무 유도와 임베딩 접근 방식은 데이터가 제한된 상황에서 데이터 기반 머신 러닝 방법의 강력한 새로운 기준선을 제공합니다.



### Experimental Evaluation of Machine Learning Models for Goal-oriented Customer Service Chatbot with Pipeline Architectur (https://arxiv.org/abs/2409.18568)
- **What's New**: 이 논문은 고객 서비스 챗봇을 위한 맞춤형 실험 평가 접근법을 제시하여, 자연어 이해(NLU), 대화 관리(DM), 자연어 생성(NLG)라는 세 가지 주요 구성 요소에 중점을 둡니다.

- **Technical Details**: 연구에서는 NLU(BERT 및 LSTM 사용), DM(DQN 및 DDQN 활용), NLG(GPT-2 및 DialoGPT 활용)의 개별 평가를 강조하며, 하이퍼파라미터 최적화와 후보 모델 평가를 수행합니다.

- **Performance Highlights**: NLU에서는 BERT가 의도 탐지에서 우수한 성과를 보였고, LSTM은 슬롯 채우기에서 더 나은 결과를 나타냈습니다. DM에서는 DDQN 모델이 DQN을 능가하며 더 적은 턴 수, 더 높은 보상 및 성공률을 달성했습니다. NLG에서는 대형 언어 모델인 GPT-2가 DialoGPT보다 BLEU, METEOR 및 ROUGE 지표에서 더 뛰어난 성능을 보여주었습니다.



### Robustness of AI-based weather forecasts in a changing clima (https://arxiv.org/abs/2409.18529)
Comments:
          14 pages, 4 figures

- **What's New**: 최근 1-2년 동안 데이터 기반 머신러닝 모델이 날씨 예측 분야에서 획기적인 진전을 이루었으며, 최신 모델이 다양한 기술 점수에서 최상의 물리 기반 모델을 능가하고 있습니다. 이러한 발전이 기후 과학에도 혁신을 가져올 수 있는지에 대한 질문이 제기되고 있습니다.

- **Technical Details**: 최신 머신러닝 모델은 현재 기후에서 훈련되어, 비산업화(pre-industrial), 현재, 미래의 2.9K 더 따뜻한 기후 상태를 포함한 다양한 기후 상태에 대해 유능한 예측을 할 수 있음을 보여줍니다. 이는 짧은 시간 동안 날씨를 형성하는 역학이 변화하는 기후에서도 본질적으로 다르지 않을 수 있음을 시사합니다. 이러한 모델은 기후 응용을 위한 필수 요건인 분포 외 일반화(out-of-distribution generalization) 능력을 입증했습니다.

- **Performance Highlights**: 그러나 두 모델은 미래의 따뜻한 기후 상태 예측에서 전 세계 평균의 차가운 편향(global-mean cold bias)을 나타내며, 이는 훈련된 현재 기후에게로 드리프트하는 경향이 있습니다. 또한 사전 산업(pre-industrial) 경우에도 세 모델 중 두 개가 따뜻해지는 경향이 있습니다. 이러한 편향의 가능한 수정 방법을 논의하며, 공간적 분포를 분석하여 훈련 데이터에 결여된 해양-빙산 및 육상 표면 정보와 관련된 복잡한 온난화 및 냉각 패턴을 발견했습니다.



### Med-IC: Fusing a Single Layer Involution with Convolutions for Enhanced Medical Image Classification and Segmentation (https://arxiv.org/abs/2409.18506)
Comments:
          13 pages, 5 figures, 4 tables, preprint submitted to an Elsevier journal

- **What's New**: 이번 연구에서는 의학 이미지를 처리하는 데 있어, Convolutional Neural Network (CNN) 모델에 Involution 레이어를 단일 추가함으로써 분류 및 세분화 성능이 향상된다는 새로운 접근법을 소개합니다.

- **Technical Details**: Convolution(합성곱) 연산은 의료 이미지를 포함한 다양한 영상에서 시각적 패턴을 추출하는 데 제한적인 성능을 보입니다. Involution(역합성곱) 과정은 이러한 제한을 보완하며, CNN 아키텍처 전에 단일 Involution 레이어를 적용함으로써 성능을 개선할 수 있습니다. 연구는 Involution 레이어가 과도하게 사용될 경우 의료 이미지에 대한 예측 정확도가 저하될 수 있음을 보여줍니다.

- **Performance Highlights**: 단일 Involution 레이어 추가 전략은 대부분의 기존 연구 성과를 초과하는 결과를 낳아, 상당히 적은 수의 가중치 매개변수로도 개선된 성능을 유지할 수 있습니다.



### WHOMP: Optimizing Randomized Controlled Trials via Wasserstein Homogeneity (https://arxiv.org/abs/2409.18504)
Comments:
          46 pages, 3 figures

- **What's New**: 이번 연구에서는 데이터셋을 다양한 하위 그룹으로 나누는 방법을 조사하고, 각 하위 그룹 내 다양성을 극대화하면서 하위 그룹 간 유사성을 최소화하는 새로운 방법론인 $	extit{Wasserstein Homogeneity Partition}$ (WHOMP)을 소개합니다.

- **Technical Details**: WHOMP는 종종 발생하는 그룹 분할에서의 불균형한 상황으로 인한 오류, 즉 유사성 비율의 문제(Accidental Bias)를 만족스럽게 최소화합니다. 이 연구에서는 WHOMP를 랜덤 서브샘플링(random subsampling), 공변량 적응 랜덤화(covariate-adaptive randomization), 재랜덤화(rerandomization), 반 클러스터링(anti-clustering) 등 기존의 분할 방법들과 비교하였습니다. 이 방법의 최적 솔루션 또한 하위 그룹의 평균과 분산의 안정성 간의 트레이드오프를 보여줍니다.

- **Performance Highlights**: 수치 실험을 통해 WHOMP 방법의 효과성을 검증하였으며, 전통적인 방법들보다 뛰어난 성능을 보였습니다.



### URIEL+: Enhancing Linguistic Inclusion and Usability in a Typological and Multilingual Knowledge Bas (https://arxiv.org/abs/2409.18472)
- **What's New**: URIEL+는 URIEL의 한계를 극복하여 2898개의 언어에 대한 typological (유형론적) 특성 범위를 확장하고 사용자 경험을 개선합니다.

- **Technical Details**: URIEL은 7970개 언어에 대한 지리적, 계통적 (phylogenetic), 유형론적 벡터 표현을 제공하며, 4005개 언어의 벡터 간 거리 측정을 포함합니다. URIEL+는 강력하고 사용자 맞춤형 거리 계산을 제공하여 사용자의 요구에 더 잘 맞추도록 개선되었습니다.

- **Performance Highlights**: 업그레이드된 URIEL+는 하위 작업 (downstream tasks)에서 경쟁력 있는 성능을 제공하며, 언어적 거리 연구에 더 잘 맞는 거리를 제공합니다.



### Robust Network Learning via Inverse Scale Variational Sparsification (https://arxiv.org/abs/2409.18419)
Comments:
          21 pages, 7 figures

- **What's New**: 이 논문에서는 다양한 종류의 노이즈에 대한 저항력을 키우기 위해 새로운 접근법을 제안하고 있습니다.

- **Technical Details**: 본 연구는 시간 연속적(inverse scale space formulation) 인버스 스케일 변동 희소화(framework) 프레임워크를 도입하여 픽셀 간 변동 차이를 판단함으로써 점진적으로 세부적인 대규모 특징을 학습합니다. 이를 통해 작은 스케일 특징을 부드럽게 하여 노이즈를 제거하고, 질감(textures) 및 물체 윤곽(object contours)과 같은 고대비(high-contrast) 세부 사항을 유지합니다.

- **Performance Highlights**: 제안된 방법은 다양한 노이즈 유형에 대한 강력한 저항력을 보여주며, 기존의 주파수 기반(frequency-based) 방법들과 비교 시 간단하고 효율적인 구현을 제공합니다.



### Scientific Machine Learning Seismology (https://arxiv.org/abs/2409.18397)
Comments:
          English translation of the manuscript submitted to Zisin (Journal of the Seismological Society of Japan)

- **What's New**: 이 연구는 과학 기계 학습(Scientific Machine Learning, SciML)이라는 학문 간 경계 연구 분야에 대해 설명합니다. SciML는 물리학 이론과 기계 학습, 특히 딥 러닝을 통합하여 복잡한 자연 현상을 이해하고 예측합니다.

- **Technical Details**: SciML의 핵심 개념, 응용 분야 및 전망을 다룹니다. 특히, 물리학 정보를 포함한 신경망(Physics-Informed Neural Networks, PINNs)과 신경 연산자(Neural Operators, NOs)라는 두 가지 주요 방법에 대해 논의합니다. PINNs는 지배 법칙을 손실 함수에 통합하여 정방향 및 역문제를 해결할 수 있습니다. NOs는 무한 차원 공간 간의 관계를 다루는 연산자 학습 모델입니다.

- **Performance Highlights**: SciML은 관측 데이터에 대한 의존성을 줄이며, 딥 러닝의 적용 범위를 자연 과학으로 확장하는 잠재력을 가지고 있습니다. 시뮬레이션 데이터를 기반으로 한 복잡한 시스템의 시간 진화를 모델링하는 데 있어 NOs는 가능성을 보여줍니다. 이 연구는 지진학에서의 활용과 함께, 통계적 프레임워크와 물리적 원칙을 통합한 새로운 모델링 접근법을 제시합니다.



### CurricuLLM: Automatic Task Curricula Design for Learning Complex Robot Skills using Large Language Models (https://arxiv.org/abs/2409.18382)
Comments:
          Submitted to ICRA 2025

- **What's New**: CurricuLLM은 언어 모델(LLM)의 능력을 활용하여 훈련 과정에서 점진적으로 어려움을 증가시켜 복잡한 정책을 배우는 Curriculum Learning을 도와주는 새로운 접근 방식을 제안합니다.

- **Technical Details**: CurricuLLM의 과정은 세 단계로 구성됩니다: (1단계) 자연어 형태로 하위 과제를 생성하여 타겟 과제 학습을 지원, (2단계) 하위 과제의 자연어 설명을 실행 가능한 태스크 코드로 변환(보상 코드 및 목표 분포 코드 포함), (3단계) 궤적 롤아웃 및 하위 과제 설명을 기반으로 학습된 정책 평가.

- **Performance Highlights**: CurricuLLM은 다양한 로봇 시뮬레이션 환경에서 조작(manipulation), 내비게이션(navigation), 보행(locomotion) 등의 복잡한 로봇 제어 과제를 학습하는 데 도움을 줍니다. 또한, 실제 환경에서 CurricuLLM을 통해 학습한 인간형 보행 정책의 유효성을 검증했습니다.



### Adaptive Learning of the Latent Space of Wasserstein Generative Adversarial Networks (https://arxiv.org/abs/2409.18374)
- **What's New**: 본 연구에서는 새로운 프레임워크인 latent Wasserstein GAN (LWGAN)을 제안하여 Wasserstein auto-encoder와 Wasserstein GAN을 융합했습니다. 이를 통해 데이터 매니폴드(manifold)의 내재 차원(intrinsic dimension)을 적응적으로 학습할 수 있습니다.

- **Technical Details**: LWGAN은 인코더 네트워크와 제너레이터 네트워크를 통해 학습된 인코딩 분포의 내재 차원이 데이터 매니폴드의 차원과 같음을 입증합니다. 이론적으로, 우리의 추정된 내재 차원이 데이터 매니폴드의 진정한 차원의 일관된 추정임을 수립했습니다. 또한 LWGAN의 일반화 오류(generalization error)에 대한 상한을 제공합니다.

- **Performance Highlights**: 종합적인 실험 결과, LWGAN은 여러 시나리오에서 올바른 내재 차원을 식별할 수 있으며, 학습된 잠재 분포(latent distribution)로부터 고품질의 합성 데이터(synthetic data)를 생성할 수 있음을 보여주었습니다.



### A model-constrained Discontinuous Galerkin Network (DGNet) for Compressible Euler Equations with Out-of-Distribution Generalization (https://arxiv.org/abs/2409.18371)
- **What's New**: 이 연구에서는 큰 규모의 복잡한 동적 시스템에 대한 실시간 정확한 솔루션을 필요로 하는 응용 분야인 디지털 트윈과 같은 분야에서, 모델 제약(discontinuous Galerkin Network, DGNet) 접근 방식을 개발했습니다. 이는 이전 연구를 확장한 내용으로, 압축 유체 방정식에 대한 새로운 방법론을 다룹니다.

- **Technical Details**: DGNet의 핵심은 여러 가지 주요 전략의 융합입니다: (i) 시계열 통합(time integration) 계획을 활용하여 시간적 상관관계를 포착하고 신경망(neural network) 속도를 계산 시간 단축에 활용; (ii) 학습된 접선 기울기(tangent slope)가 지배 방정식을 만족하도록 보장하는 모델 제약 접근 방식 적용; (iii) Riemann 해결기 대리 모델과 볼륨 통합 보정을 나타내는 GNN(그래프 신경망) 영감을 받은 아키텍처 활용; (iv) 입력 정규화(input normalization) 기술 도입으로 다양한 초기 조건, 경계 조건 및 솔루션 순서에서 대리 모델의 일반화 가능성 증대; (v) 데이터 무작위화(randomization) 기법 포함하여 대리 모델과 실제 수치 모델 간의 합의 증진 및 훈련 시 데이터 생성 엔진 역할을 수행.

- **Performance Highlights**: 우리의 DGNet 접근 방식의 효과성, 안정성 및 일반화 가능성을 검증하기 위해 1D 및 2D 압축 유체 방정식 문제에 대한 포괄적인 수치 결과를 제시합니다.



### Defect Prediction with Content-based Features (https://arxiv.org/abs/2409.18365)
- **What's New**: 이 논문에서는 전통적인 결함 예측(Defect Prediction) 접근법과는 다른 소스 코드(content of source code)를 기반으로 한 새로운 접근법을 탐색합니다.

- **Technical Details**: 이 연구에서는 소스 코드의 내용에서 추출한 단어(words), 주제(topics), 데이터 유형(data types), 패키지 이름(package names) 같은 콘텐츠 기반 기능(features)을 사용하여 결함 예측을 수행합니다. 이러한 기능들은 코드 복잡도(metrics that measure complexity)보다 높은 예측력을 가지고 있음을 보였습니다.

- **Performance Highlights**: 연구 결과, 콘텐츠 기반 기능이 코딩 복잡도를 측정하는 기존 방법들보다 예측 성능이 좋으며, 기능 선택(feature selection), 축소(reduction), 조합(combination)을 통해 예측 성능이 더욱 개선된다는 사실이 밝혀졌습니다.



### Multi-hypotheses Conditioned Point Cloud Diffusion for 3D Human Reconstruction from Occluded Images (https://arxiv.org/abs/2409.18364)
Comments:
          17 pages, 7 figures, accepted NeurIPS 2024

- **What's New**: 본 논문에서는 심각한 가림(occlusion) 상황에서도 3D 인간 형태 재구성을 위한 새로운 파이프라인, MHCDIFF를 제안합니다. 이 방법은 픽셀 정렬된 세부 3D 인간 재구성을 위해 점 구름(diffusion) 모델을 도입합니다.

- **Technical Details**: MHCDIFF는 단일 RGB 이미지에서 기하학적 세부 사항을 캡처하기 위해 다수의 가설화된 SMPL(-X) 메쉬로부터 로컬 특징(local features)을 추출하고 이 특징 집합을 활용하여 확산 모델(diffusion model)을 조정합니다. 점 구름 확산(point cloud diffusion) 모델은 누락된(osculaded) 영역을 생성하기 위해 전체적인 일관성(global consistent features)을 캡처하며, 잡음 제거(denoising) 과정에서 잘못 정렬된 SMPL 메쉬를 수정합니다.

- **Performance Highlights**: CAPE 및 MultiHuman 데이터셋에서의 실험 결과, 제안된 방법은 SMPL, 암묵적 함수(implicit functions), 점 구름 확산(point cloud diffusion) 및 이들의 결합 기반의 다양한 최신 기술(SOTA) 방법들과 비교하여 우수한 성능을 보였습니다.



### AQMLator -- An Auto Quantum Machine Learning E-Platform (https://arxiv.org/abs/2409.18338)
Comments:
          15 pages, 3 figures, links to software in the text

- **What's New**: 이 논문에서는 AQMLator라는 새로운 Auto Quantum Machine Learning 플랫폼을 소개합니다. 이 플랫폼은 최소한의 사용자 입력으로 양자 레이어를 자동으로 제안하고 학습할 수 있도록 설계되어 있습니다.

- **Technical Details**: AQMLator는 기존의 기계 학습(ML) 라이브러리를 사용하여 개발되어 있으며, 이는 기존 ML 파이프라인에 쉽게 통합될 수 있게 합니다. 이 플랫폼은 양자 컴퓨터(QC)를 ML 모델에 통합하여 사용자의 진입 장벽을 낮추고, 데이터 과학자들이 QML을 사용할 수 있도록 합니다.

- **Performance Highlights**: AQMLator는 자동 아키텍처 검색(auto architecture search)을 통해 ML 시스템 설계 과정에서 인간의 개입을 최소화하여 효율적인 모델 구현을 가능하게 합니다.



### A Framework for Standardizing Similarity Measures in a Rapidly Evolving Field (https://arxiv.org/abs/2409.18333)
Comments:
          11 pages, 9 figures

- **What's New**: 이 논문에서는 인공지능(Artificial Intelligence)과 생물학적 시스템(Biological Systems) 간의 정렬을 정량화하기 위한 유사도 측정(Similarity Measures)의 중요한 역할과 이들 간의 비교를 용이하게 하기 위한 Python 저장소를 개발하고 있음을 소개합니다.

- **Technical Details**: 다양한 유사도 측정 방법과 그들의 구현 방법의 다양성 때문에, 연구들을 비교하기가 어렵습니다. 본 연구는 약 100개의 다양한 유사도 측정 방법을 포함한 14개 패키지의 정보를 수집한 저장소를 제공하여 이러한 유사도 측정 방법들을 벤치마킹(Benchmarking)하고 표준화(Standardization)하는 데 중점을 두고 있습니다.

- **Performance Highlights**: Centered Kernel Alignment (CKA)와 같은 일반적으로 사용되는 방법조차도 12가지 이상의 변형이 존재하며, 이 분야가 발전함에 따라 이 숫자는 계속 증가할 것으로 보입니다. 이러한 유사도 측정의 동향과 모범 사례들은 계속 변화할 것이므로, 현재의 저장소는 시점에 대한 유용한 도구로 여겨집니다.



### Local Prediction-Powered Inferenc (https://arxiv.org/abs/2409.18321)
- **What's New**: 본 논문에서는 Prediction-Powered Inference (PPI) 기법을 활용한 새로운 형태의 로컬 다변수 회귀(local multivariable regression) 알고리즘을 소개합니다. 이 알고리즘은 샘플 사이즈가 제한된 경우에도 추정의 분산을 최소화하면서 오류를 증가시키지 않는 방법을 제시합니다.

- **Technical Details**: 이 연구는 로컬 회귀 분석에서 더 높은 가중치를 특정 점 $x$에 가까운 포인트에 할당하는 것을 강조합니다. PPI 기법을 도입하여 추정의 분산을 줄이는 알고리즘을 구현하고, 신뢰구간(confidence intervals), 편향 보정(bias correction), 및 커버리지 확률(coverage probabilities)을 분석하였습니다.

- **Performance Highlights**: 수치 시뮬레이션(numerical simulation)과 실제 데이터 실험(real-data experiments)을 통해 본 알고리즘의 우수성과 정확성을 입증하였으며, 기존 PPI 기법 대비 이론적인 계산 효율성과 설명 가능성(explainability)을 개선하였습니다.



### Embodied-RAG: General non-parametric Embodied Memory for Retrieval and Generation (https://arxiv.org/abs/2409.18313)
Comments:
          Web: this https URL

- **What's New**: 새로운 연구에서는 Embodied-RAG라는 프레임워크를 소개하여 로봇의 탐색 및 학습 능력을 향상시키는 동시에, 비모수 메모리 시스템을 활용하여 계층적인 지식을 구성할 수 있는 방법을 제시하고 있습니다.

- **Technical Details**: Embodied-RAG는 다양한 환경 및 쿼리 유형에서 공간적(spatial) 및 의미적(semantic) 해상도를 처리할 수 있는 구조를 가지고 있습니다. 이 시스템의 핵심은 세밀한 언어 설명을 저장하는 의미적 숲(semantic forest) 형태의 메모리에 있으며, 이를 통해 다양한 로봇 플랫폼에서 맥락에 맞는 출력을 효율적으로 생성할 수 있습니다.

- **Performance Highlights**: Embodied-RAG는 19개 환경에서 200개 이상의 설명 및 탐색 쿼리를 성공적으로 처리하여 RAG를 로봇공학(domain of robotics) 분야와 연결하는 데 효과적임을 입증하였습니다.



### Deep-ER: Deep Learning ECCENTRIC Reconstruction for fast high-resolution neurometabolic imaging (https://arxiv.org/abs/2409.18303)
- **What's New**: 본 연구에서는 7T MRI 스캐너를 사용하여 비침습적으로 고속 고해상도 대뇌 대사 영상을 얻기 위한 Deep Learning 기반의 효율적인 재구성 방법, 즉 Deep-ER을 소개합니다. 이는 기존의 MRSI 방법 대비 600배 빠른 재구성을 가능하게 합니다.

- **Technical Details**: 본 연구는 ECCENTRIC 펄스 시퀀스를 사용하여 3.4 mm$^3$의 등방성 해상도로 전체 뇌의 대사 이미징을 수행하였으며, 27명의 참가자(22명의 건강한 자원봉사자와 5명의 교모세포종 환자)의 데이터를 사용하였습니다. 딥 신경망은 반복적인 엮인 합성곱(interlaced convolutional) 층을 사용하여 설계되었습니다.

- **Performance Highlights**: Deep-ER은 신호 대 잡음 비율(signal-to-noise ratio)을 12%-45% 향상시켰으며, Cramer-Rao 하한(Cramer-Rao lower bounds)을 8%-50% 줄이며 대사물질 정량화에서 개선된 성능을 보여주었습니다. 이를 통해 교모세포종의 이질성과 경계가 명확하게 시각화되었습니다.



### Harnessing Wavelet Transformations for Generalizable Deepfake Forgery Detection (https://arxiv.org/abs/2409.18301)
- **What's New**: 이번 논문에서는 Deepfake 탐지 방법의 약점을 해결하기 위해 Wavelet-CLIP이라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 Wavelet 변환(Wavelet Transforms)과 ViT-L/14 아키텍처에서 얻은 특징을 통합하여, 복잡한 Deepfake를 효과적으로 탐지할 수 있도록 설계되었습니다.

- **Technical Details**: Wavelet-CLIP는 Wavelet Transform을 이용하여 이미지의 공간적(spatial) 및 주파수(frequency) 특징을 깊이 분석합니다. 사전 훈련된 CLIP 방법으로 ViT-L/14 아키텍처의 특징들을 활용하여 높은 효율성을 발휘합니다.

- **Performance Highlights**: 테스트 결과, Wavelet-CLIP는 교차 데이터에 대한 일반화(cross-dataset generalization)에서 평균 AUC 0.749, 보이지 않는 Deepfake에 대한 강인성(robustness)에서 0.893을 기록하여 기존의 최첨단 방법들을 능가하는 뛰어난 성능을 보여주었습니다.



### SOAR: Self-supervision Optimized UAV Action Recognition with Efficient Object-Aware Pretraining (https://arxiv.org/abs/2409.18300)
- **What's New**: 이번 연구에서는 UAV(무인 항공기)로 촬영된 공중 영상에 대한 새로운 Self-supervised pretraining 알고리즘인 SOAR를 소개합니다. 이전 연구와는 달리, SOAR는 프리트레이닝(pretraining) 과정에서 인간 객체 지식을 통합하여 효율성을 높였습니다.

- **Technical Details**: SOAR는 두 가지 주요 접근 방식을 사용합니다. 첫째, 객체 인식과 관련된 특정 패치를 유지하기 위한 객체 인식 마스킹 전략(object-aware masking strategy)을 제안하였습니다. 둘째, 객체 정보를 활용하여 재구성 손실(reconstruction loss)을 조정하는 객체 인식 손실 함수(object-aware loss function)를 도입했습니다. 이를 통해 불필요한 배경 패치에 대한 편향을 방지할 수 있습니다.

- **Performance Highlights**: SOAR는 vanilla ViT 백본(backbone)을 사용하였으며, NEC-Drone과 UAV-Human 데이터셋에서 각각 9.7% 및 21.4%의 top-1 정확も(accuracy) 증가를 기록하며 기존 UAV 행동 인식(action recognition) 모델을 능가하였습니다. 특히, SOAR는 18.7ms의 비디오 당 추론 속도(inference speed)를 제공하며, 이는 2배에서 5배 더 빠릅니다. 추가로, SOAR는 이전의 Self-supervised learning 방법들과 유사한 정확도를 보여주면서도 87.5% 적은 프리트레이닝 시간과 25% 적은 메모리 사용을 요구합니다.



### Predicting Muscle Thickness Deformation from Muscle Activation Patterns: A Dual-Attention Framework (https://arxiv.org/abs/2409.18266)
- **What's New**: 이 논문은 근육 활성화와 두께 변형 간의 관계를 이해하기 위한 새로운 접근법을 제시합니다. 기존에 초음파(ultrasound) 기술에서 단점으로 지적된 이동식 장치에서의 제한을 극복하기 위해, 표면 근전도(sEMG) 신호를 활용하여 근육 두께 변형을 예측하는 딥러닝 접근법을 도입했습니다.

- **Technical Details**: 이 연구에서는 자기 주의(Self-attention)와 교차 주의(Cross-attention) 메커니즘을 결합한 이중 주의 구조를 통해 sEMG 데이터에서 직접적으로 근육 변형을 예측합니다. 이 방식은 초음파 측정의 필요성을 없애며, 근육의 생체 전기 신호를 분석하여 실시간 데이터 예측을 가능하게 합니다.

- **Performance Highlights**: 여섯 명의 건강한 피험자를 대상으로 한 실험 결과, 평균 0.923±0.900mm의 정밀도로 근육 변형을 정확히 예측할 수 있음을 입증하였습니다. 이는 이 방법이 임상 진단(clinical diagnostics), 스포츠 과학(sports science), 재활(rehabilitation) 분야에서의 응용 가능성을 보여줍니다.



### DisGeM: Distractor Generation for Multiple Choice Questions with Span Masking (https://arxiv.org/abs/2409.18263)
- **What's New**: 최근 자연어 처리(Natural Language Processing, NLP) 분야의 발전이 여러 하위 분야에 영향을 미쳤습니다. 이 논문은 다중 선택 질문(Multiple Choice Questions, MCQ)을 위한 방해 요소(distractor) 생성에서의 새로운 접근 방식을 제시합니다.

- **Technical Details**: 본 연구는 사전 훈련된 언어 모델(Pre-trained Language Models, PLMs)을 활용한 간단하고 일반적인 방해 요소 생성 프레임워크를 제공합니다. 기존 방법과 달리, 제안된 프레임워크는 특정 데이터셋에 대한 추가 훈련이 필요하지 않습니다. 두 단계의 프레임워크, 즉 후보 생성(candidate generation)과 후보 선택(candidate selection)으로 구성됩니다.

- **Performance Highlights**: 제안한 방해 요소 생성 프레임워크는 훈련이나 파인튜닝(fine-tuning) 없이도 이전 방법들을 초월하는 성과를 보였으며, 인간 평가에서 더 효과적이고 흥미로운 방해 요소를 생성함을 확인했습니다.



### Development of an Edge Resilient ML Ensemble to Tolerate ICS Adversarial Attacks (https://arxiv.org/abs/2409.18244)
Comments:
          Accepted by Dynamic Data Driven Applications Systems: International Conference, DDDAS, Springer. 2024

- **What's New**: 이번 연구에서는 산업 제어 시스템(ICS)의 보안을 향상시키기 위한 견고한 엣지 머신 러닝(reML) 아키텍처를 개발했습니다. 이 아키텍처는 적대적 공격(adversarial attacks)에 저항할 수 있도록 설계되었으며, 데이터 에어 갭 변환(Data Air Gap Transformation, DAGT)을 통해 데이터 특성 공간을 익명화합니다.

- **Technical Details**: reML 아키텍처는 Resilient DDDAS 패러다임과 Moving Target Defense (MTD) 이론 및 TinyML을 기반으로 하며, 머신 러닝 예측을 위한 모델을 무작위화(randomize)합니다. 이 방법은 전력 제한이 있는 장치에서도 배치 가능한 에너지 효율적(power-efficient)이고 개인 정보 보호(privavy-preserving)를 지원합니다.

- **Performance Highlights**: 연구에서는 ICS 데이터셋을 사용하여 reML의 성능을 평가하였고, 엣지 장치에서 견고한 머신 러닝 추론(resilient ML inference)을 제공하는 실행 가능한 방법임을 입증했습니다.



### Towards sub-millisecond latency real-time speech enhancement models on hearables (https://arxiv.org/abs/2409.18239)
- **What's New**: 본 연구는 리소스 제한 환경에서의 서브 밀리세컨드(latency) 처리 공간을 탐구하며, 효율적인 최소 위상 FIR 필터(minimum-phase FIR filter)를 활용한 음성 향상(speech enhancement) 기법을 제시합니다.

- **Technical Details**: 본 연구에서 우리는 단일 마이크로폰을 사용하여 평균 SI-SDRi가 4.1 dB인 음성 향상을 관찰했습니다. 644k 파라미터를 가진 경량 LSTM 기반 모델을 사용하여 FIR 탭을 생성하고, 시스템이 388 MIPS의 저전력 DSP(low-power DSP)에서 실행될 수 있음을 입증했습니다.

- **Performance Highlights**: 우리의 시스템은 0.32 ms에서 1.25 ms의 평균 알고리즘 지연(mean algorithmic latency)과 3.35 ms의 평균 종단 간 지연(mean end-to-end latency)을 달성하며, DNSMOS는 미지의 오디오 녹음에서 0.2 증가합니다.



### Spatial Visibility and Temporal Dynamics: Revolutionizing Field of View Prediction in Adaptive Point Cloud Video Streaming (https://arxiv.org/abs/2409.18236)
- **What's New**: 이번 논문에서는 점 구름 비디오(PCV)의 Field-of-View (FoV) 적응 스트리밍을 통해 대역폭 요구 사항을 크게 줄이는 방법을 제안합니다. 기존의 방법들은 일반적으로 6 자유도(6DoF) FoV 예측에 초점을 맞추지만, 본 연구는 셀 가시성(cell visibility) 관점에서 FoV 예측 문제를 재구성하였습니다.

- **Technical Details**: 우리는 역사적 3D 가시성 데이터를 활용하고, 공간 인식(spatial perception), 이웃 셀 상관관계(neighboring cell correlation), 가리기 정보(occlusion information)를 통합하는 새로운 공간 가시성(spatial visibility) 및 객체 인식(object-aware) 그래프 모델을 개발했습니다. 이 모델은 예측된 가시성 분포를 기반으로 3D 데이터 전송 결정을 정확하게 합니다.

- **Performance Highlights**: 우리 모델은 장기 셀 가시성 예측(long-term cell visibility prediction)을 크게 향상시켰으며, 최첨단 모델들에 비해 예측 MSE 손실을 최대 50% 줄였습니다. 동시에 100만 개 이상의 포인트를 가진 점 구름 비디오에 대해 30fps 이상의 실시간 성능을 유지합니다.



### Visual Concept Networks: A Graph-Based Approach to Detecting Anomalous Data in Deep Neural Networks (https://arxiv.org/abs/2409.18235)
- **What's New**: 이 논문에서는 깊은 신경망(Deep Neural Networks, DNN)이 비정상적(anomalous)이고 분포 밖(out-of-distribution, OOD) 데이터에 대해 강화되는 새로운 방법을 소개합니다. 기존 OOD 벤치마크는 단일 객체 작업에 초점을 맞추어 복잡한 현실 세계의 비정상성을 충분히 반영하지 못했습니다.

- **Technical Details**: 제안된 방법은 그래프(graph) 구조와 위상적(topological) 특징을 활용하여 원거리 OOD와 근거리 OOD 데이터를 효과적으로 탐지합니다. 이미지를 상호 연결된 이해 가능한 특징 또는 시각 개념의 네트워크로 변환하여 처리합니다.

- **Performance Highlights**: 대규모 어휘와 다양한 작업을 포함한 두 가지 새로운 작업에서의 광범위한 테스트를 통해 이 방법의 효과를 입증했습니다. 이 접근법은 DNN의 OOD 데이터에 대한 회복력(resilience)을 향상시키며 다양한 애플리케이션에서 성능 개선을 약속합니다.



### Revolutionizing Payload Inspection: A Self-Supervised Journey to Precision with Few Shots (https://arxiv.org/abs/2409.18219)
- **What's New**: 이 논문은 현대 사이버 공격에 대한 새로운 맬웨어 탐지 방법을 제안합니다. 특히, 기존의 감독학습(Supervised Learning) 방식이 새로운 공격에 대한 일반화(generalization)에 실패하는 문제를 해결하기 위해, 자기 감독 학습(Self-Supervised Learning)과 몇 샷 학습(Few-Shot Learning)을 활용합니다.

- **Technical Details**: 제안된 방법은 트랜스포머(Transformer)를 사용하여 비라벨 데이터셋에서 페이로드(payload)의 임베딩(Embedding)을 학습합니다. 이는 페이로드의 일부를 마스킹(masking)하여 수행되며, 이로부터 학습된 표현(representation)은 다양한 다운스트림 태스크(tasks)에 잘 일반화됩니다. 추출된 표현은 맬웨어 탐지 알고리즘의 훈련에 사용되며, 소수의 샷(few-shot) 접근법을 통해 새로운 유형의 공격에 적응합니다.

- **Performance Highlights**: 여러 데이터셋에 대한 실험 결과, 제안된 접근법은 다양한 새로운 시나리오에 대한 성공적인 탐지 및 일반화 성능을 보여줍니다.



### Learning to Drive via Asymmetric Self-Play (https://arxiv.org/abs/2409.18218)
Comments:
          ECCV 2024

- **What's New**: 본 연구에서는 실제 데이터에 의존하지 않고도 운전 정책을 학습할 수 있는 비대칭 자기 플레이(asymmetric self-play) 방법을 제안합니다. 이 방법은 도전적이고 현실적인 합성 시나리오(synthetic scenarios)를 활용하여 데이터 세트를 확장합니다.

- **Technical Details**: 비대칭 자기 플레이는 두 개의 에이전트로 구성되어 있으며, 하나는 시나리오를 생성하는 '교사(teacher)' 역할을 하고, 다른 하나는 그 시나리오를 해결하는 '학생(student)' 역할을 합니다. 이를 통해 운전 시뮬레이션에서 더 적은 충돌로 현실적인 정책을 학습합니다.

- **Performance Highlights**: 우리의 정책은 기존의 적대적 접근(adversarial approaches)이나 실제 데이터를 사용하는 방법에 비해 종합적으로 성능이 크게 향상되며, 특히 드문(long-tail) 시나리오에서도 우수한 결과를 보입니다.



### MMMT-IF: A Challenging Multimodal Multi-Turn Instruction Following Benchmark (https://arxiv.org/abs/2409.18216)
Comments:
          24 pages, 16 figures

- **What's New**: MMMT-IF 데이터셋과 Programmatic Instruction Following (PIF) 메트릭을 도입하여 멀티모달, 멀티턴 대화에서 지시사항을 따르는 능력을 평가하는 새로운 방법을 제안합니다.

- **Technical Details**: MMMT-IF는 질문들 사이에 추가된 전역 지시사항을 포함하여, 모델이 긴 대화 속에서 분산된 지시사항을 검색하고 지시사항 제약 하에서 추론할 수 있도록 도전합니다. 모든 지시사항은 코드 실행을 통해 객관적으로 검증 가능합니다. PIF 메트릭은 추론 작업을 수행하는 동안 정확하게 따르는 지시사항의 비율을 측정합니다. PIF-N-K 메트릭은 모델 응답 중 K개가 PIF 점수가 1인 비율을 측정하여 강건성을 평가합니다.

- **Performance Highlights**: Gemini 1.5 Pro, GPT-4o, Claude 3.5 Sonnet의 평균 PIF 점수가 턴 1에서 0.81에서 턴 20에서 0.64로 감소하며, 모든 응답을 4회 반복했을 때 GPT-4o와 Gemini가 모든 지시사항을 성공적으로 따르는 경우는 단 11%입니다. 지시사항이 모델 입력 문맥의 끝에 추가되면 평균 PIF 점수가 22.3 포인트 향상됩니다.



### A Unified View on Learning Unnormalized Distributions via Noise-Contrastive Estimation (https://arxiv.org/abs/2409.18209)
Comments:
          35 pages

- **What's New**: 이번 논문은 noise-contrastive estimation (NCE)을 기반으로 하는 여러 추정량(estimators)을 연구하였으며, 비정규화된 분포(unnormalized distributions)를 학습하는 새로운 방법론을 제시합니다.

- **Technical Details**: 이 연구는 다양한 비정규화 분포 학습 방법을 NCE의 관점에서 통합적으로 접근하였으며, 특히 지수적 가족(exponential families)에 대해 제안된 추정량의 유한 샘플 수렴 속도(finite-sample convergence rates)를 새로운 정칙성 가정(regularity assumptions) 하에 확립합니다.

- **Performance Highlights**: 주요 결과는 이러한 추정량이 기존 추정량보다 우수한 성능을 보이며, 비정규화된 분포 학습 분야에 있어 새로운 통찰(insights)을 제공함을 보여줍니다.



### AI Policy Projector: Grounding LLM Policy Design in Iterative Mapmaking (https://arxiv.org/abs/2409.18203)
- **What's New**: 이 논문에서는 정책 설계를 지도 제작(mapmaking)에서 영감을 얻어 새로운 AI 정책 설계 프로세스를 소개합니다.

- **Technical Details**: 이 연구에서 제안하는 Policy Projector는 모델 입력 및 출력 쌍의 지형을 탐색하고 사용자 정의 영역을 정의하며, LLM 출력에 적용할 수 있는 규칙을 탐색할 수 있도록 해줍니다. 예를 들어, '폭력(violence)'과 '그래픽 세부사항(graphic details)'이 포함된 출력이 있는 경우 그래픽 세부사항 없이 다시 쓰는 규칙을 설정할 수 있습니다.

- **Performance Highlights**: 12명의 AI 안전(AI safety) 전문가와의 평가에서, Policy Projector는 정책 설계자가 기존의 포괄적인 해악 분류(harm taxonomy)를 넘어서는 문제적 모델 행동을 해결하는 데 도움을 주었습니다.



### Loop-Diffusion: an equivariant diffusion model for designing and scoring protein loops (https://arxiv.org/abs/2409.18201)
- **What's New**: 이번 연구에서는 Loop-Diffusion이라는 새로운 에너지 기반 확산 모델(diffusion model)을 소개하며, 이는 전체 단백질 유니버스에서 일반적인 단백질 루프에 대한 데이터셋을 활용하여 기능 예측 작업에 일반화된 에너지 기능을 학습합니다.

- **Technical Details**: Loop-Diffusion은 단백질 구조로부터 기능적 특성을 예측하는 중앙 문제를 해결하기 위한 접근법으로, 기존의 기계 학습 방법들이 갖고 있는 데이터 부족과 편향성의 한계를 극복하고자 합니다. 이 모델은 단백질-무역소(TCR-pMHC) 인터페이스의 점수를 평가하는 데 사용되었으며, 에너지 기반 모델의 저속성 및 정확성의 문제를 해결합니다.

- **Performance Highlights**: Loop-Diffusion은 결합을 강화하는 돌연변이(bond-enhancing mutations)를 인식하는 데 있어서 최첨단(state-of-the-art) 결과를 보여주었습니다. 이는 기능 예측 작업에서의 효율성과 정확성을 동시에 향상시킬 수 있는 가능성을 제시합니다.



### Autonomous Network Defence using Reinforcement Learning (https://arxiv.org/abs/2409.18197)
- **What's New**: 이 논문에서는 네트워크 보안의 방어자가 공격자에 비해 불리한 상황을 반전시키기 위해 자율 에이전트(autonomous agents)의 효과를 조사합니다.

- **Technical Details**: 강화 학습(reinforcement learning)에 대한 배경을 제공하고, 3개의 서브넷(subnets)으로 구성된 13개의 호스트(hosts)의 네트워크 환경 시뮬레이션에서 이벤트를 테스트합니다. 논문에서는 신뢰할 수 있는 방어를 위한 새로운 강화 학습 에이전트를 설계 및 훈련합니다.

- **Performance Highlights**: 이 에이전트는 공격자가 두 가지 유형 – 하나는 네트워크 레이아웃에 대한 완전한 지식을 가진 고급 지속 위협(advanced persistent threat, APT) 에이전트와 다른 하나는 탐색을 통해 자원을 발견해야 하지만 보다 일반적인 에이전트로서의 공격을 계속 방어할 수 있음을 보여줍니다.



### Harmful Fine-tuning Attacks and Defenses for Large Language Models: A Survey (https://arxiv.org/abs/2409.18169)
- **What's New**: 최근 연구에 따르면, 새로운 fine-tuning-as-a-service 비즈니스 모델이 심각한 안전 문제를 드러내고 있습니다. 사용자가 업로드한 몇 가지 해로운 데이터로 인한 fine-tuning이 모델의 안전 정렬(safety alignment)을 위협할 수 있습니다. 이러한 공격은 harmful fine-tuning으로 알려져 있으며, 연구 커뮤니티 내에서 큰 관심을 받고 있습니다.

- **Technical Details**: 논문은 먼저 문제의 위협 모델(threat model)을 제시하고, harmful fine-tuning 공격과 그 변종을 소개합니다. 이후 기존 문헌에 대한 체계적인 조사(survey)를 진행하여 공격 및 방어(defenses), 기계적 분석(mechanical analysis)에 대해 논의합니다.

- **Performance Highlights**: 논문은 연구 문제를 공식적으로 정립하고, 향후 연구 방향(future research directions)을 제안합니다. 또한, 동료 평가(peer review) 과정에서 실험/공격/방어 설정의 현실성에 대한 질문을 제기할 때 유용할 수 있는 흥미로운 질문 목록을 포함하고 있습니다.



### Data-Prep-Kit: getting your data ready for LLM application developmen (https://arxiv.org/abs/2409.18164)
Comments:
          10 pages, 7 figures

- **What's New**: 이 논문에서는 대규모 언어 모델(LLM) 개발을 위한 데이터 준비의 중요성을 강조하며, 사용자들이 손쉽게 확장하고 조정할 수 있는 오픈 소스 데이터 준비 툴킷인 Data Prep Kit (DPK)를 소개합니다.

- **Technical Details**: DPK는 데이터 준비를 사용자의 필요에 맞게 조정할 수 있도록 설계된 아키텍처를 가지고 있으며, 로컬 머신에서 데이터를 준비할 수 있을 뿐만 아니라 수천 개의 CPU 코어가 있는 클러스터에서도 손쉽게 확장할 수 있습니다. DPK는 자연어 및 코드 데이터를 변환하는 확장 가능한 모듈 세트를 제공합니다. 사용자가 추가적인 변환이 필요할 경우, DPK의 지원을 통해 손쉽게 개발할 수 있습니다. 이러한 모듈들은 독립적으로 또는 파이프라인 방식으로 연속적인 작업을 수행하는 데 사용될 수 있습니다.

- **Performance Highlights**: DPK의 성능은 작은 규모에서 시작하여 매우 큰 수의 CPU까지 확장 가능함을 보여줍니다. DPK의 모듈은 Granite 모델 데이터 준비에도 사용되었습니다. DPK는 AI 커뮤니티가 LLM 모델 성능을 향상하거나 Retrieval-Augmented Generation (RAG) 기능으로 모델을 미세 조정할 수 있도록 돕는 귀중한 기여라고 믿습니다.



### Decomposable Transformer Point Processes (https://arxiv.org/abs/2409.18158)
Comments:
          accepted at NeurIPS 2024

- **What's New**: 이 논문에서는 주목 기반 아키텍처(Attention-based architecture)를 사용하여 강점을 유지하면서도 계산적으로 집중적인 thinning 알고리즘의 한계를 극복하는 새로운 프레임워크를 제안합니다.

- **Technical Details**: 이 프레임워크는 Markov 성질을 만족하는 로그 정규 분포(log-normal distribution)의 혼합을 사용하여 사건 간 시간의 조건부 분포(conditional distribution)를 모델링하고, Transformer 기반 아키텍처로 마크의 조건부 확률 질량 함수(conditional probability mass function)를 모델링합니다.

- **Performance Highlights**: 제안된 방법은 이전 사건의 이력을 기반으로 다음 사건을 예측하는 데 있어 최첨단(state-of-the-art) 성능을 달성하였으며, thinning 알고리즘에 의존하지 않는 inference 방법이 더 효과적임을 입증했습니다. 긴 시간 예측(long-horizon prediction)의 도전 과제에도 우수한 성능을 보였고, inference에 필요한 시간은 thinning 기반 베이스라인에 비해 극히 짧았습니다.



### A novel application of Shapley values for large multidimensional time-series data: Applying explainable AI to a DNA profile classification neural network (https://arxiv.org/abs/2409.18156)
Comments:
          16 pages, 5 figures

- **What's New**: 이번 연구는 고차원, 시계열 데이터(time-series-like data)에 대한 Shapley value의 계산을 효율적으로 처리하는 새로운 방법을 제시합니다. 특히, 이미지 처리에서 사용되는 superpixel의 개념을 적용하여 Shapley value 계산을 간소화하였습니다.

- **Technical Details**: 본 연구는 합성곱 신경망(Convolutional Neural Network, CNN)에 의해 분류된 다변량 시계열 데이터(multivariate time-series-like data)에 적용되며, 고유한 방법론을 통해 DNA 프로파일의 31,200개의 스캔 포인트를 효율적으로 처리합니다. 연구의 배경인 포렌식 DNA 분류 예시에서, Shapley value의 계산 방식이 superpixel의 개념과 결합되어 있습니다.

- **Performance Highlights**: 이 방법의 적용으로, 시간 소모가 큰 기존의 수동 분류 과정에 비해 Shapley value의 계산이 현실적이고 정확하며 빠르게 이루어질 수 있음을 보여줍니다. 피험자로부터 생성된 DNA 추출 배경 소음을 식별하고 유전적 대립유전자(alleles)를 효과적으로 처리할 수 있는 가능성을 제공합니다.



### Reinforcement Learning for Finite Space Mean-Field Type Games (https://arxiv.org/abs/2409.18152)
- **What's New**: 이 논문에서는 대규모 협력 게임인 Mean Field Type Games (MFTGs)를 위한 강화 학습 (reinforcement learning) 방법을 개발하였습니다. 이 게임에서는 지속적으로 변화하는 동적 시스템과 보상 함수 (reward functions)를 갖는 게임 환경 속에서 비협조적인 여러 세력 간의 상호작용을 고려합니다.

- **Technical Details**: MFTG의 해결책이 유한 크기의 협력 게임에서 근사적인 Nash 균형 (Nash equilibria)을 생성함을 증명하고, Mean-field 공간의 양자화 (quantization)와 Nash Q-learning을 기반으로 한 첫 번째 알고리즘과 더 큰 공간에 스케일할 수 있는 심층 강화 학습 (deep reinforcement learning) 알고리즘을 제안하였습니다.

- **Performance Highlights**: 5개 환경에서 수행된 수치 예제 (numerical examples)들을 통해 제안된 방법의 scalability (확장성)와 efficiency (효율성)를 입증하였습니다.



### A shortest-path based clustering algorithm for joint human-machine analysis of complex datasets (https://arxiv.org/abs/1812.11850)
- **What's New**: 본 논문에서는 여러 학문 분야에서 얻은 데이터셋의 분석을 위한 클러스터링(clustering) 기법을 제안합니다. 특히, 서로 다른 구조를 가진 그룹들이 공존하는 데이터셋에서 그룹화를 효과적으로 수행하는 새로운 알고리즘을 소개합니다.

- **Technical Details**: 제안된 알고리즘은 데이터 포인트 간의 경로를 탐색함으로써 클러스터링을 수행합니다. 이 방식은 경로의 특성(예: 간격(gap), 밀도(density) 변화 등)을 평가하고 특정 경로에 대한 선호를 표현할 수 있습니다. 또한, 경로 분류기(path classifier)를 훈련시킴으로써 수용 가능한 클러스터(admissible clusters) 및 비수용 가능한 클러스터(non-admissible clusters)에 대한 기존 지식을 통합하는 것을 지원합니다.

- **Performance Highlights**: 제안된 방법은 공개적으로 이용 가능한 벤치마크에서 합성(shape) 데이터와 현미경(microscopy) 데이터 등 도전적인 데이터셋에 대해 정확성을 입증하였습니다.



### MALPOLON: A Framework for Deep Species Distribution Modeling (https://arxiv.org/abs/2409.18102)
- **What's New**: MALPOLON은 딥 종 분포 모델(Deep-SDM) 훈련 및 추론을 지원하는 새로운 프레임워크입니다. 사용자가 Python 언어에 대한 일반적인 지식만으로도 딥 러닝 방식의 SDM을 시험해볼 수 있도록 설계되었습니다.

- **Technical Details**: 이 프레임워크는 Python으로 작성되었으며 PyTorch 라이브러리를 기반으로 합니다. 모듈성이 뛰어나고, 사용자 맞춤형 데이터셋에 대한 신경망 훈련을 위한 버튼 클릭 예제가 제공됩니다. YAML 기반의 설정과 병렬 컴퓨팅, 다중 GPU 활용이 가능합니다.

- **Performance Highlights**: MALPOLON은 접근성을 높이고 성능 확장성을 지원하기 위해 open-source로 제공되며, GitHub와 PyPi에 배포되었습니다. 다양한 시나리오에서의 사용 예제 및 광범위한 문서화가 이루어져 있습니다.



### Optimal Protocols for Continual Learning via Statistical Physics and Control Theory (https://arxiv.org/abs/2409.18061)
Comments:
          19 pages, 9 figures

- **What's New**: 이 논문은 인공 신경망이 여러 작업을 순차적으로 학습하는 동안 발생하는 catastrophic forgetting 문제를 해결하기 위한 이론적 프레임워크를 제안합니다. 특히, training dynamics에 대한 정확한 방정식과 optimal control 방법을 결합하여 작업 선택 프로토콜을 최적화하는 방법을 제시합니다.

- **Technical Details**: 연구는 통계 물리학의 차원 축소 기법과 최적 제어 이론의 Pontryagin의 최대 원리를 결합하여 이루어졌습니다. 학습 곡선을 나타내는 ODE(Ordinary Differential Equations)를 활용하여 최적의 작업 선택 프로토콜과 학습 속도 조정 방안을 도출했습니다. 이론적 분석 후, 실제 데이터셋에서의 유효성을 검증했습니다.

- **Performance Highlights**: 연구 결과, 제안된 "pseudo-optimal" 전략은 Fashion-MNIST 데이터셋에서의 지속적 학습 작업에서 성공적으로 적용되어, 기존의 heuristic 전략보다 더 나은 성능을 나타냈습니다. 또한, 중간 작업 유사성에서 catastrophic forgetting이 최소화된다는 점을 규명하여 기존 연구와의 차별성을 보였습니다.



### Inverse Reinforcement Learning with Multiple Planning Horizons (https://arxiv.org/abs/2409.18051)
Comments:
          Accepted at RLC 2024

- **What's New**: 이번 연구에서는 전문가들이 공유 보상 함수(shared reward function) 아래에서 다양한 계획 지평선(planning horizon)을 가지고 행동하는 인버스 강화 학습(inverse reinforcement learning, IRL) 문제를 다뤘습니다. 전문가의 계획 지평선이 서로 다르기 때문에 존재하는 할인 요인(discount factor)에 대한 정보가 없으면 보상 함수는 더 큰 해답 가능 공간(solution space)을 가지게 되어, 기존 IRL 접근 방식으로 보상 함수를 식별하기가 어렵습니다.

- **Technical Details**: 연구에서는 전문가 특유의 할인 요인을 바탕으로 전문가 정책(expert policies)을 재구성하는 글로벌 멀티 에이전트 보상 함수를 학습할 수 있는 두 가지 새로운 알고리즘을 개발했습니다. 이 알고리즘들은 두 가지 인기 있는 IRL 접근 방식인 선형 프로그래밍 IRL(linear programming IRL, LP-IRL) 및 최대 인과 엔트로피 IRL(max causal entropy IRL, MCE-IRL)의 맥락에서 문제를 해결합니다.

- **Performance Highlights**: 두 알고리즘 모두에서 보상 함수와 할인 요인의 가능 솔루션 공간(feasible solution space)을 특성화하였고, 학습된 보상 함수가 여러 도메인에서 일반화 가능성을 경험적으로 입증했습니다. 이 연구는 기존 IRL 접근 방식이 마주하는 도전 과제를 극복하고, 향후 IRL 연구에서 참고할 수 있는 중요한 기초 자료로서 기능할 것입니다.



### An Adversarial Perspective on Machine Unlearning for AI Safety (https://arxiv.org/abs/2409.18025)
- **What's New**: 이번 연구는 기존의 unlearning(언러닝) 방법이 안전성 훈련(safety training)에서의 위험한 정보 제거를 효과적으로 대체할 수 있는지를 조명합니다. 연구자들은 unlearning이 단순히 정보를 숨기는데 그치고, 위험한 지식이 여전히 회복될 수 있음을 보여줍니다.

- **Technical Details**: 이 논문은 RMU(Residual Memory Unlearning)와 같은 상태-of-the-art unlearning 방법을 평가하며, WMDP(WMD Probing) 벤치마크를 사용하여 안전성 훈련과 비교합니다. 기존 보고된 jailbreak 방법들은 unlearning에 무효로 간주되었으나, 세심하게 적용될 경우 여전히 효과적일 수 있음을 발견하였습니다. 이들은 특정 활성 공간 방향을 제거하거나 무관한 예제를 가진 finetuning을 통해 원래의 성능을 복구할 수 있는 방법을 제시합니다.

- **Performance Highlights**: 연구 결과, unlearning 방법은 특정 공격에 보다 강해 보이지만, 안전성 훈련에 사용된 기법으로 쉽게 우회될 수 있습니다. 특히, GCG와 같은 jailbreak 기법은 손실 함수를 약간 변경함으로써 의미 있는 정확도를 회복할 수 있음을 보여주었습니다.



### Spatiotemporal Learning on Cell-embedded Graphs (https://arxiv.org/abs/2409.18013)
- **What's New**: 이 논문에서는 새로운 Cell-embedded Graph Neural Network (CeGNN) 모델을 제안하여 공간-시간 동역학(spatiotemporal dynamics)을 높여진 성능으로 학습합니다. 기존의 node-edge 메세지 전송(mechanism) 방식의 한계를 극복하고, 학습 가능한 셀 속성(cell attribution)을 도입하여 지역 특징의 공간 의존성을 더 잘 포착합니다.

- **Technical Details**: CeGNN 모델은 메세지 전송 과정을 고차원(local aggregation scheme)으로 업그레이드하여 볼록 정보(volumetric information)를 활용합니다. 또한, 새로운 feature-enhanced block을 설계하여 모델의 성능 향상 및 over-smoothness 문제를 해소합니다. 이 블록은 잠재 특징(latent feature)을 기초 함수로 취급하여 2차 비선형 항을 생성합니다.

- **Performance Highlights**: 다양한 PDE 시스템과 실제 데이터셋에서의 광범위한 실험 결과, CeGNN은 다른 기준 모델들에 비해 우수한 성능을 보이며, 특히 여러 PDE 시스템에서 예측 오차를 최대 1 순위(orders of magnitude)까지 감소시켰습니다. 이로 인해, lower error, better interpretability, robust generalizability를 달성하여 공간-시간 동역학 분야에 중요한 기여를 하였습니다.



### Safe Time-Varying Optimization based on Gaussian Processes with Spatio-Temporal Kern (https://arxiv.org/abs/2409.18000)
Comments:
          Accepted to NeurIPS 2024

- **What's New**: 본 논문에서는 Time-Varying Safe Bayesian Optimization (TVSBO) 알고리즘, TVSafeOpt를 제안합니다. 이 알고리즘은 시간에 따라 변하는 보상 함수와 안전 제약을 동시 최적화할 수 있는 능력을 갖추고 있으며, 명시적인 변화 감지 없이도 시간 변동 안전 영역을 안전하게 추적할 수 있습니다.

- **Technical Details**: TVSafeOpt는 Bayesian Optimization 방법론에 기반하며, spatio-temporal kernel(공간-시간 커널)을 이용하여 시간에 따라 변화하는 보상 및 안전 제약을 다룹니다. 또한, 시간 Lipschitz constants(시간 리프시츠 상수)를 활용하여 문제의 시간 의존성을 명시적으로 표현함으로써, 현재 안전 집합의 전달을 안전하게 수행합니다.

- **Performance Highlights**: 실험 결과, TVSafeOpt 알고리즘은 안전성과 최적성 면에서 기존의 SafeOpt와 비교하여 우수한 성능을 보이며, 이를 통해 가스 압축기와 같은 실제 사례 연구에서도 안전성을 보장하는 것을 확인했습니다.



### Dimension-independent learning rates for high-dimensional classification problems (https://arxiv.org/abs/2409.17991)
- **What's New**: 본 논문은 $RBV^2$ 공간에서의 분류 함수의 근사 및 추정 문제를 연구합니다. 특히, 제한된 가중치를 가진 신경망(neural networks)이 모든 $RBV^2$ 함수를 근사할 수 있음을 보여줍니다. 이를 통해 분류 함수에 대한 신경망의 존재성을 입증하며, 다양한 규칙성을 가진 결정 경계의 영향을 분석합니다.

- **Technical Details**: $RBV^2$ 함수는 정규화된 신경망 학습 문제의 솔루션으로 자연스럽게 발생하며, 이러한 함수는 차원의 저주(curse of dimensionality) 없이 신경망으로 근사할 수 있습니다. 신경망은 제한된 가중치를 가진 경우에도 분류 함수를 근사할 수 있음을 입증하며, 이러한 경계 조건을 통해 추정 속도를 정량화합니다. 또한, 결정 경계의 복잡성을 정규 함수의 그래프로 모델링합니다.

- **Performance Highlights**: 수치 연구를 통해 다양한 규칙성 조건이 결정 경계에 미치는 영향을 분석했습니다. 이 연구는 기존 연구들에서 주장된 여러 경계 조건과 비교하여 추가적인 통찰을 제공합니다.



### Supra-Laplacian Encoding for Transformer on Dynamic Graphs (https://arxiv.org/abs/2409.17986)
- **What's New**: SLATE(Spatio-temporal TransformErs)이라는 새로운 spatio-temporal encoding을 소개하며, Graph Transformers(GT) 아키텍처를 통해 dynamic link prediction의 성능을 향상시킵니다. 이 방식은 supra-Laplacian 매트를 활용하여 temporal과 structural 정보를 동시에 보존합니다.

- **Technical Details**: SLATE는 Discrete Time Dynamic Graphs(DTDGs)를 multi-layer 그래프 형태로 변형하고, 이의 spectral 속성을 이용합니다. 또한 cross-attention 메커니즘을 통해 노드 간의 쌍별 관계를 정밀하게 모델링하여 edge 표현을 최적화합니다. 이 과정을 통해 SLATE는 그래프 내에서 발생하는 상호작용을 효과적으로 반영합니다.

- **Performance Highlights**: SLATE는 9개의 데이터셋에서 최신 기술들 대비 뛰어난 성능을 보이며, 실험 결과에서 우수한 예측 효율성과 정확도를 입증합니다. SLATE는 단일 층 transformer를 사용하여 메모리와 계산 효율성을 유지하면서도 뛰어난 확장성을 제공합니다.



### Adaptive Stream Processing on Edge Devices through Active Inferenc (https://arxiv.org/abs/2409.17937)
- **What's New**: 본 논문에서는 IoT 환경에서의 데이터 처리의 복잡성을 해결하기 위한 새로운 기계 학습 (Machine Learning, ML) 패러다임인 Active Inference (AIF)를 제안합니다. 이는 신경과학에서 유래된 개념으로, 뇌가 감각 정보를 예측하고 평가하여 장기적인 놀라움을 줄이는 방식을 설명합니다.

- **Technical Details**: 이 논문은 다양한 장치에서 여러 자율 주행 서비스의 세 가지 서비스 수준 목표 (Service Level Objectives, SLOs)를 지속적으로 최적화하는 AIF 기반 에이전트를 구현하고 평가합니다. 에이전트는 인과 지식 (causal knowledge)을 사용하여 자신의 행동이 SLO 충족에 어떻게 연관되는지를 점진적으로 이해하며, 최적화된 결과를 얻기 위해 최대 30회의 반복을 요구합니다.

- **Performance Highlights**: AIF와 인과 구조 덕분에, 본 연구의 방법은 의사 결정을 완전히 투명하게 보장하며, 결과 해석과 문제 해결을 수월하게 만듭니다. 짧은 시간 내에 정확한 결과를 제공할 수 있는 능력을 보여주고 있습니다.



### Sample compression unleashed : New generalization bounds for real valued losses (https://arxiv.org/abs/2409.17932)
- **What's New**: 이 논문은 샘플 압축 이론(sample compression theory)을 통한 일반화 보장을 개선하기 위한 새로운 프레임워크를 제시합니다. 기존의 연구에서 주로 사용되었던 제로-원 손실(zero-one loss) 대신, 실제 값 손실(real-valued losses)에 대한 일반화 경계를 도출합니다.

- **Technical Details**: 샘플 압축 이론은 제한된 훈련 데이터셋의 부분집합과 짧은 메시지를 사용하여 예측기를 완전히 정의할 수 있다는 아이디어에서 출발합니다. 본 논문에서는 Pick-To-Learn(P2L) 메타 알고리즘을 활용하여 깊은 신경망을 훈련시키고, 이를 통해 새로운 압축 경계의 긴밀함(tightness)을 실증적으로 보여줍니다. 또한, 새로운 경계는 비일관성(non-consistent) 상황에서도 유효합니다.

- **Performance Highlights**: 실험 결과, 제안된 샘플 압축 경계는 다양한 모델(예: 신경망, 결정 숲)을 통해 검증되었으며, 파라미터 수에 상관없이 동일한 일반화 보장을 제공합니다. 예를 들어, 5000만 개의 파라미터를 가진 모델과 100만 개의 파라미터를 가진 모델이 동일한 경험적 손실(empirical loss)을 달성하는 경우 유사한 일반화 보장을 제공할 수 있습니다.



### Intelligent Energy Management: Remaining Useful Life Prediction and Charging Automation System Comprised of Deep Learning and the Internet of Things (https://arxiv.org/abs/2409.17931)
- **What's New**: 이번 연구는 배터리의 Remaining Useful Life (RUL)을 예측하기 위한 머신 러닝(Machine Learning) 기반 모델의 개발을 목표로 합니다. 또한 IoT(Internet of Things) 개념을 활용하여 충전 시스템을 자동화하고 결함을 관리하는 방법을 제시합니다.

- **Technical Details**: 연구에서는 catboost, Multi-Layer Perceptron (MLP), Gated Recurrent Unit (GRU) 모델 및 혼합 모델을 개발하여 차량의 RUL을 세 가지 클래스로 분류할 수 있는 성능을 보여줍니다. 이 데이터는 tkinter GUI를 통해 입력되고 pyserial 백엔드를 사용하여 Esp-32 마이크로컨트롤러에 연계되어 충전 및 방전 작업을 가능하게 합니다.

- **Performance Highlights**: 모델들은 99% 이상의 정확도로 RUL을 분류할 수 있으며, Blynk IoT 플랫폼을 사용해 다양한 차량 파라미터 간의 관계를 나타내는 그래프를 시뮬레이션합니다. 또한 자동화된 충전 및 에너지 절약 메커니즘을 위한 릴레이 기반 트리거링도 가능합니다.



### Graph Reasoning with Large Language Models via Pseudo-code Prompting (https://arxiv.org/abs/2409.17906)
- **What's New**: 최근 큰 언어 모델(LLM)의 성능이 그래프 문제 해결에 사용될 수 있는 가능성을 새로운 방식인 pseudo-code(의사 코드)를 통해 조사하였습니다. 이 연구에서는 pseudo-code를 활용한 prompting이 LLM의 그래프 알고리즘 문제 해결 성능을 높일 수 있는지를 평가하였습니다.

- **Technical Details**: 이 연구에서는 그래프 추론 과제를 수행하여 10101010 그래프 문제를 가진 두 LLM 계열(GPT와 Mixtral)의 성능을 분석했습니다. 기존 자연어 프롬프트가 불명확할 수 있는 반면, pseudo-code는 문제 해결을 위한 명확한 지침을 제공합니다.

- **Performance Highlights**: 실험 결과, pseudo-code를 사용하는 어프로치가 LLM의 성능을 향상시킴을 확인하였으며, 특히 LLM이 해결하기 어려워했던 간단한 그래프 문제와 복잡한 문제 모두에서 개선 효과를 보였습니다.



### A multi-source data power load forecasting method using attention mechanism-based parallel cnn-gru (https://arxiv.org/abs/2409.17889)
- **What's New**: 본 논문에서는 전력 수요 예측의 정확도를 높이기 위해 새로운 병렬 구조 네트워크(Parallel Structure Network)를 제안합니다. 이 모델은 동적 요소와 정적 요소 모두에서 중요한 정보를 추출할 수 있습니다.

- **Technical Details**: 논문은 복잡성 학습 이론(Complexity Learning Theory)을 기반으로 병렬 구조를 통해 통합된 모델이 개별 베이스 학습기보다 우수한 일반화 능력(Generalization Ability)을 나타낸다고 주장합니다. 제안된 PCGA 모델은 병렬 CNN 모듈과 GRU 모듈을 활용하여 공간적 특성과 동적 시계열 데이터의 장기 의존성을 포착합니다. 이와 함께 주의(attention) 레이어를 추가하여 중요한 정보를 강조합니다.

- **Performance Highlights**: 실험을 통해 PCGA 모델은 기존의 5개의 기초 모델(BP, CNN, LSTM, BILSTM, GRU)과 비교하여 예측 정확도가 유의미하게 향상된 것으로 나타났으며, 이는 전력 수요 예측과 관련된 공간적 및 시간적 특성을 효과적으로 추출했음을 확인합니다.



### A method for identifying causality in the response of nonlinear dynamical systems (https://arxiv.org/abs/2409.17872)
- **What's New**: 이 논문은 랜덤하고 폭넓은 자극에 대한 비선형 동적 시스템의 반응 예측을 가능하게 하는 새로운 방법을 제안합니다. 이 방안은 고충실도 (high fidelity) 모델 없이 주파수에 따라 시스템의 입력-출력 데이터에서 인과적 요소를 식별합니다. 또한, 주어진 모델을 활용하여 노이즈가 있는 출력 측정값을 최적 결합하여 시스템의 입력을 예측합니다.

- **Technical Details**: 이 연구에서는 비선형 동적 시스템의 다양한 특성을 이해하기 위해 출력과 입력 간의 인과적 관계를 정량화하는 비선형 코히어런스 메트릭 (nonlinear coherence metric)을 활용합니다. 이를 통해 시스템의 입력과 출력 간의 신호의 인과적 기여를 분리할 수 있으며, 예상치는 주어진 모델의 예측 및 노이즈가 포함된 출력 데이터의 적절한 결합으로 도출됩니다.

- **Performance Highlights**: 제안한 방법은 다양한 비선형 동적 시스템에 적용 가능한 가능성을 지니며, 특히 능동 소음 감소 (Active Noise Reduction, ANR)와 같은 실용 분야에 적용될 수 있습니다. 기존의 완전한 기준 모델 없이도, 적은 양의 데이터로 비선형 코히어런스를 효과적으로 추정할 수 있는 가능성을 보여줍니다.



### Efficient Arbitrary Precision Acceleration for Large Language Models on GPU Tensor Cores (https://arxiv.org/abs/2409.17870)
- **What's New**: 해당 논문은 대형 언어 모델(LLM)의 효율적인 추론을 위한 새로운 가속화 방안을 제안합니다. 특히, 이 논문에서는 대칭 양자화(symmetric quantization)를 지원하는 새롭고 효율적인 데이터 형식인 bipolar-INT를 소개합니다.

- **Technical Details**: 제안된 방법은 주로 세 가지로 구성됩니다: (1) bipolar-INT 데이터 형식 도입; (2) 비트 수준에서 행렬을 분해하고 복원하는 방법으로 임의 정밀도(matrix multiplication에서 비트 수준 분해 및 복구) 행렬 곱셈(arbitrary precision MatMul) 스킴 구현; (3) 효율적인 행렬 전처리(matrix preprocessing) 방법 도입 및 데이터 회복 지향의 메모리 관리(memory management) 시스템 설계로, 이를 통해 GPU Tensor Core 활용을 극대화합니다.

- **Performance Highlights**: 실험 결과, 제안된 스킴은 NVIDIA의 CUTLASS와 비교할 때 행렬 곱셈에서 최대 13배의 속도 향상을 달성하며, LLM에 통합 시 추론 속도에서 최대 6.7배의 가속을 실현합니다. 이로 인해 LLM의 추론 효율이 크게 향상되어 더 넓고 반응성이 뛰어난 LLM 응용을 가능하게 합니다.



### Machine Learning-based vs Deep Learning-based Anomaly Detection in Multivariate Time Series for Spacecraft Attitude Sensors (https://arxiv.org/abs/2409.17841)
Comments:
          Accepted for the ESA SPAICE Conference 2024

- **What's New**: 이번 연구는 우주선의 태세 센서에서 발생하는 다변량 시계열의 고착 값(stuck value) 감지를 위한 두 가지 AI 기반 접근 방식을 분석하고, 전통적인 임계값 검사에서의 한계를 극복하기 위한 혁신적인 기술을 제시합니다.

- **Technical Details**: 연구에서는 머신 러닝(ML)의 XGBoost 알고리즘과 심층 학습(DL) 방법인 다채널 합성곱 신경망(CNN)을 사용하여 다변량 시간 시계열 데이터에서 고착 값을 탐지합니다. 두 방법의 해석 가능성과 일반화 가능성을 논의하며, 특히 고착 값이 발생한 신호에서 AI 기반 FDIR 기능의 효과성을 강조합니다.

- **Performance Highlights**: XGBoost는 해석 가능성을 제공합니다. CNN은 빠른 처리 속도와 더 적은 파라미터로 성능을 극대화하며, 일반적인 우주선의 제한된 계산 자원에도 잘 적응합니다. 두 접근 방식은 AI 기반 FDIR의 성능 향상에 기여하며, 특히 고착 값 감지의 정확성을 높이는 데 효과적입니다.



### Language Models as Zero-shot Lossless Gradient Compressors: Towards General Neural Parameter Prior Models (https://arxiv.org/abs/2409.17836)
Comments:
          To appear in NeurIPS 2024

- **What's New**: 본 논문에서는 신경망 기울기(gradient)에 대한 통계적 사전 모델이 오랫동안 간과되어왔음을 지적하며, 대규모 언어 모델(LLM)이 제로샷(zero-shot) 설정에서 기울기 사전으로 작용할 수 있는 가능성을 제시합니다. 이를 통해 효율적인 기울기 압축 방법인 LM-GC를 개발했습니다.

- **Technical Details**: LM-GC는 LLM과 산술 부호화(arithmetic coding)를 통합하여 기울기를 텍스트와 유사한 형식으로 변환합니다. 이 방법은 기울기의 구조와 LLM이 인식 가능한 기호 사이의 정렬을 유지하며, LLM의 토큰 효율성을 최대 38배 향상시키는 특징이 있습니다.

- **Performance Highlights**: LM-GC는 기존의 손실 없는 압축 방법보다 10%에서 최대 17.2% 더 우수한 압축률을 나타내며, 다양한 데이터세트 및 아키텍처에서 실험을 통해 입증되었습니다. 또한, 본 방법은 양자화 및 희소화와 같은 손실 압축 기법과도 호환 가능성을 보였습니다.



### Ordinary Differential Equations for Enhanced 12-Lead ECG Generation (https://arxiv.org/abs/2409.17833)
- **What's New**: 본 연구에서는 생리학적 동역학에 대한 깊은 통찰을 바탕으로 심장 동역학을 나타내는 보통 미분 방정식(ODE)을 생성 모델에 통합하여 12-리드 ECG 데이터를 생성하는 새로운 방법인 MultiODE-GAN을 제안합니다.

- **Technical Details**: MultiODE-GAN은 12-리드 ECG 데이터 생성을 위해 설계된 Generative Adversarial Network(GAN) 프레임워크로, 전통적인 교차 엔트로피 손실 함수와 함께 Euler 손실 함수를 결합하여 합성 심장 박동이 ODE 모델에서 생산된 실제 심장 박동에 가깝도록 보장합니다. 이 과정에서 모든 리드 간의 의존성을 활용하여 생리학적 관계를 충실히 반영하여 데이터를 생성합니다.

- **Performance Highlights**: 실험 결과, MultiODE-GAN 모델이 기존의 다른 생성 모델들과 비교하여 심박수 분류 정확도가 현저히 향상된 것으로 나타났습니다. 이는 심장 질환 감지 및 진단의 성능을 개선하는 데 기여할 수 있습니다.



### Continual learning with task specialis (https://arxiv.org/abs/2409.17806)
- **What's New**: 이 논문에서는 Catastrophic Forgetting(재앙적 망각) 문제를 해결하기 위해 Continual Learning with Task Specialists (CLTS) 모델을 제안합니다. CLTS는 Class Incremental Learning (Class-IL) 상황에서 발생하는 지식 잃음을 최소화하며, 새로운 데이터 스트림을 통해 지속적으로 학습할 수 있는 접근 방식을 제공합니다.

- **Technical Details**: CLTS 모델은 Task Specialists (T S)와 Task Predictor (T P)로 구성되어 있으며, Stable Diffusion (SD) 모듈을 활용하여 데이터 흐름에서의 클래스 점진적 학습을 수행합니다. 모델은 Variational Autoencoder (V AE), K-Means 클러스터링, 그리고 Bootstrapping Language-Image Pre-training (BLIP) 모델을 포함하여 텍스트 캡션을 생성합니다.

- **Performance Highlights**: CIFAR10, CIFAR100, TinyImagenet과 같은 실제 데이터셋에서 수행한 Class-IL 실험 결과, CLTS 모델은 네 개의 최신 기술 모델(SOTA) 기반선보다 우수한 성능을 보였습니다.



### CASPFormer: Trajectory Prediction from BEV Images with Deformable Attention (https://arxiv.org/abs/2409.17790)
Comments:
          Under Review at ICPR 2024, Kolkata

- **What's New**: 이 논문에서는 고해상도 (High Definition, HD) 맵에 의존하지 않고 Bird-Eye-View (BEV) 이미지를 기반으로 다중 모드 모션 예측을 수행할 수 있는 Context Aware Scene Prediction Transformer (CASPFormer)를 제안합니다. 이는 자율 주행 및 운전 보조 시스템에 클라우드 서비스의 확장성을 제공할 수 있는 혁신적 방법입니다.

- **Technical Details**: CASPFormer는 래스터화된 BEV 이미지를 사용하여 다중 모드 벡터화된 궤적을 생성합니다. 이 시스템은 기존의 인식 모듈과 통합할 수 있으며, 포스트 프로세싱 없이 벡터화된 궤적을 직접 디코딩합니다. 디포머블 (Deformable) 어텐션 방식으로 궤적을 반복적으로 디코딩하며, 이는 컴퓨팅 효율성을 높이고 중요한 공간 위치에 초점을 맞출 수 있도록 합니다. 또한, 학습 가능한 모드 쿼리를 통합하여 다수의 씬-일관적인 궤적을 생성할 때 '모드 붕괴' 문제를 해결합니다.

- **Performance Highlights**: 우리의 모델은 nuScenes 데이터셋에서 평가되었으며, 여러 메트릭에서 최신 기술 수준의 성능을 달성했습니다. 특히, 다중 궤적 예측에서의 높은 정확도와 효율성을 보이며, 기존의 HD 맵 기반 방법들 대비 비용 효율적이고 확장 가능한 해결책을 제안합니다.



### Byzantine-Robust Aggregation for Securing Decentralized Federated Learning (https://arxiv.org/abs/2409.17754)
Comments:
          18 pages, 7 figures, 1 table

- **What's New**: 본 논문은 분산된 환경에서의 Decentralized Federated Learning(DFL)을 위한 새로운 Byzantine-robust aggregation 알고리즘 WFAgg를 제안합니다. 이는 중앙 서버 없이도 보안을 강화하는데 기여합니다.

- **Technical Details**: WFAgg 알고리즘은 다수의 필터를 사용하여 Byzantine 공격을 분석하고 완화하는 기능을 갖추고 있으며, 동적 분산 토폴로지에서의 강력한 견고성을 제공합니다. 이를 통해 중앙 집중식 Byzantine-robust aggregation 알고리즘과 비교하여 다양한 Byzantine 공격 시나리오에서도 높은 모델 정확성과 수렴성을 유지할 수 있습니다.

- **Performance Highlights**: 실험 결과, 제안된 알고리즘 WFAgg는 여러 중앙 집중식 Byzantine-robust aggregation 알고리즘(예: Multi-Krum, Clustering)과 비교하여 이미지 분류 문제에서 더 높은 정확도를 기록하며, 중앙 집중식 시스템보다 우수한 모델 일관성 결과를 보여줍니다.



### Recent advances in interpretable machine learning using structure-based protein representations (https://arxiv.org/abs/2409.17726)
- **What's New**: 최근 머신러닝(ML)의 발전이 생물학 구조 분야에 혁신을 가져오고 있다. 특히 AlphaFold와 같은 신경망이 단백질 구조 예측에 폭넓게 사용되고 있다. 이 논문에서는 낮은 해상도에서 높은 해상도까지 단백질 3D 구조를 표현하는 다양한 방법을 소개하고, 해석 가능한 ML 방법들이 단백질 구조, 기능 및 단백질-단백질 상호작용 예측에 어떻게 기여할 수 있는지를 보여준다.

- **Technical Details**: 단백질은 생명의 기본 요소이며, 그 기능은 3차원(3D) 구조와 밀접하게 연관되어 있다. AlphaFold2(AF2)는 단백질의 아미노산 서열을 기초로 한 구조 예측의 주요 도전 과제를 해결하는 혁신적인 신경망 아키텍처이다. 해석 가능한 ML 방법들은 다양한 단백질 관련 작업에 이용되며, 통합 그래디언트(Integrated Gradients)와 그라디언트 가중 클래스 활성화 맵(GradCAM)과 같은 기법들이 사용된다. 이러한 해석 가능한 방법들은 단백질 기능 예측과 상호작용에 대한 이해를 증진시킨다.

- **Performance Highlights**: 이 논문은 단백질의 구조 기반 표현에 대한 다양한 방법을 탐구하고, 해석 가능성이 높은 ML 방법의 적용을 통해 단백질의 기능 및 단백질-단백질 상호작용 예측에서의 성과를 강조했다. AlphaFold는 실험적 데이터와 매우 유사한 구조를 정확하게 예측할 수 있으며, 이는 약물 개발 및 단백질 디자인 분야에서의 응용 가능성을 높인다.



### PGN: The RNN's New Successor is Effective for Long-Range Time Series Forecasting (https://arxiv.org/abs/2409.17703)
- **What's New**: 본 논문에서는 RNN의 후속 모델인 Parallel Gated Network (PGN)을 제안합니다. PGN은 Historical Information Extraction (HIE) 레이어를 사용하여 정보 전파 경로를 $	ext{O}(1)$로 줄임으로써 RNN의 한계를 극복합니다.

- **Technical Details**: PGN은 과거 시간 단계에서 정보를 직접 캡처하고, 게이트 메커니즘(gated mechanisms)을 활용하여 이를 현재 시간 단계 정보와 선택적으로 융합합니다. Temporal PGN (TPGN) 프레임워크는 두 가지 가지(branch)를 포함하여 장기 주기 패턴과 단기간 정보를 효과적으로 캡처합니다. TPGN은 $	ext{O}(	ext{L}^{0.5})$의 이론적 복잡도를 유지하여 효율성을 확보합니다.

- **Performance Highlights**: 실험 결과, TPGN은 다섯 개의 벤치마크 데이터세트에서 최신 성능(state-of-the-art, SOTA)을 달성하며, PGN의 효과성을 확인했습니다.



### Efficient Bias Mitigation Without Privileged Information (https://arxiv.org/abs/2409.17691)
Comments:
          Accepted at the 18th European Conference on Computer Vision (ECCV 2024) as an Oral presentation

- **What's New**: 본 논문에서는 Bias Mitigation을 위한 Targeted Augmentations (TAB)라는 새로운 프레임워크를 제안합니다. 이 방법은 그룹 레이블 없이도 훈련 세트를 재조정하여 바이어스를 감소시키는 효과적인 방법으로, 기존의 방법들보다 뛰어난 성능을 보입니다.

- **Technical Details**: TAB는 하이퍼파라미터 최적화가 필요 없는 간단한 비지도 학습 기반의 바이어스 완화 파이프라인입니다. 이는 보조 모델의 전체 훈련 이력을 활용하여 spurious samples를 식별하고, 그룹 균형 훈련 세트를 생성합니다.

- **Performance Highlights**: TAB는 기존의 비지도 방법들보다 worst-group 성능을 향상시키며 전체 정확도를 유지합니다. 이 방법은 다양한 실제 데이터 세트에 쉽게 적용할 수 있으며, 그룹 정보나 모델 선택 없이도 성능 개선을 이룰 수 있습니다.



### Graph Edit Distance with General Costs Using Neural Set Divergenc (https://arxiv.org/abs/2409.17687)
Comments:
          Published at NeurIPS 2024

- **What's New**: GRAPHEDX는 서로 다른 비용의 edit operations를 명시적으로 고려하여 Graph Edit Distance (GED)를 추정하는 새로운 신경망 모델입니다. 이를 통해 여러 종류의 edit 작업에 대해 보다 정확한 추정을 가능합니다.

- **Technical Details**: GRAPHEDX는 네 가지 edit 작업(edge deletion, edge addition, node deletion, node addition)에 대한 비용을 포함하는 quadratic assignment problem (QAP)으로 GED를 모델링합니다. 각 그래프는 노드와 엣지의 embedding으로 표현되며, Gumbel-Sinkhorn permutation generator를 통해 노드와 엣지 간의 정렬을 학습합니다.

- **Performance Highlights**: 여러 데이터 세트에서 진행된 실험 결과, GRAPHEDX는 예측 오류 측면에서 최신의 방법들과 휴리스틱을 일관되게 초월하는 성능을 보였습니다.



### Preserving logical and functional dependencies in synthetic tabular data (https://arxiv.org/abs/2409.17684)
Comments:
          Submitted to Pattern Recognition Journal

- **What's New**: 이 논문에서는 기존의 기능적 의존성(functioanal dependencies) 외에도 속성 간의 논리적 의존성(logical dependencies)을 도입하였습니다. 이와 함께, 테이블 데이터에서 논리적 의존성을 수량적으로 평가할 수 있는 새로운 방법을 제시합니다.

- **Technical Details**: 새롭게 제안된 방법을 사용하여 여러 최신 합성 데이터 생성 알고리즘을 비교하고, 공개 데이터 세트에서 논리적 및 기능적 의존성을 보존하는 능력을 시험합니다. 이러한 연구는 기능적 의존성을 완전히 보존하는 합성 테이블 데이터 생성 알고리즘의 한계를 밝혀냅니다.

- **Performance Highlights**: 본 연구에서는 특정 합성 데이터 생성 모델들이 속성 간의 논리적 의존성을 잘 보존할 수 있음을 보여주며, 향후 작업에 특화된 합성 테이블 데이터 생성 모델 개발의 필요성과 기회를 제시합니다.



### Optimal Memorization Capacity of Transformers (https://arxiv.org/abs/2409.17677)
- **What's New**: 최근 머신러닝 분야에서 Transformers의 기억 용량(memorization capacity)에 대한 연구가 증가하고 있지만, Transformers의 효율성은 아직 잘 이해되지 않고 있습니다. 본 논문에서는 다음 토큰 예측(next-token prediction) 환경에서 입력 시퀀스의 길이 $n$와 수 $N$에 대해 $ 	ilde{O}(	ext{sqrt}(N))$ 파라미터로 라벨을 기억할 수 있음을 보여주며, 이는 로그(logarithmic) 요인을 제외하면 최적이라는 점을 증명합니다.

- **Technical Details**: 이 연구에서는 다음 토큰 예측의 설정과 시퀀스-투-시퀀스(sequence-to-sequence) 설정에서의 기억 용량을 분석합니다. 특히, 하드맥스(hardmax)를 사용하는 Transformers의 경우, 적어도 $	ilde{O}(	ext{sqrt}(nN))$ 파라미터가 충분할 뿐만 아니라 필요하다는 것을 발견했습니다. 입력 시퀀스를 효율적으로 식별할 수 있는 셀프 어텐션(self-attention) 메커니즘이 있지만, 각 토큰에 라벨을 연관짓는 과정에서는 피드포워드 네트워크(feed-forward network)가 병목 현상(bottleneck)으로 작용함을 시사합니다.

- **Performance Highlights**: 이 연구 결과는 Transformers가 입력 길이 $n$에 거의 영향을 받지 않으면서 파라미터 공유(parameter sharing)의 이점을 통해 효율적으로 기억할 수 있음을 나타냅니다.



### Model-Free Stochastic Process Modeling and Optimization using Normalizing Flows (https://arxiv.org/abs/2409.17632)
Comments:
          13 pages, 7 Figures, 5 Tables

- **What's New**: 이 연구는 화학 공정의 확률적 동역학(stochastic dynamics)을 학습하기 위해 조건부 정규화 흐름(conditional normalizing flows)을 이산 시간 모델(discrete-time models)로 제안합니다.

- **Technical Details**: 정규화 흐름(normalizing flows)은 이전 상태(prior states)와 제어 입력(control inputs)에 따라 시스템 상태의 확률 밀도 함수(probability density function, PDF)를 학습하는 능동적인 딥 생성 모델(deep generative model)입니다. 이 연구는 이러한 정규화 흐름을 사용하여 비선형 확률적 동역학(nonlinear stochastic dynamics)를 모델링합니다.

- **Performance Highlights**: 연속 반응기(continuous reactor)와 반응기 캐스케이드(reactor cascade)에 대한 시뮬레이션에서 정규화 흐름은 장기간에 걸쳐 안정적인 결과를 제공하며, 열린 루프 제어에서 확률적 및 확률적 MPC(model predictive control) 제안으로 우수한 품질을 보여줍니다.



### Convolutional Signal Propagation: A Simple Scalable Algorithm for Hypergraphs (https://arxiv.org/abs/2409.17628)
- **What's New**: 이 논문에서는 침투형 신호 전파(Convolutional Signal Propagation, CSP)라는 새로운 방법을 제안합니다. CSP는 이분 그래프(bipartite graph)와 하이퍼그래프(hypergraph)에 네이티브(natively)로 작동하며, 간단한 코드 몇 줄로 구현할 수 있는 비모수적(non-parametric)이고 확장 가능한 방법입니다.

- **Technical Details**: CSP는 기존의 레이블 전파(label propagation) 방법을 하이퍼그래프에 쉽게 확장할 수 있는 형태로 구현되었습니다. 또한 CSP는 하이퍼그래프 컨볼루션 네트워크(hypergraph convolutional networks) 및 나이브 베이즈 분류기(naive Bayes classifier)와의 관계를 명확히 하였습니다.

- **Performance Highlights**: CSP는 여러 실제 데이터 세트(real-world datasets)에 대해 높은 성능을 보여주어, 하이퍼그래프 노드 분류 및 검색 작업에서 저렴한 계산 복잡도를 유지하면서 경쟁력 있는 결과를 제공합니다. 이 방법은 자연어 처리(natural language processing)와 같은 전통적인 하이퍼그래프와 관련이 없는 작업에서도 좋은 성과를 달성하였습니다.



### Benign or Not-Benign Overfitting in Token Selection of Attention Mechanism (https://arxiv.org/abs/2409.17625)
- **What's New**: 이번 연구는 transformer 모델에서의 주의 메커니즘(attention mechanism) 내에서 benign overfitting의 존재를 분석한 첫 번째 연구입니다. 기존의 이론적 연구들은 주로 선형 모델이나 2층 신경망에 국한되었으나, 본 연구는 attention 아키텍처에 초점을 맞추어 그 메커니즘을 설명합니다.

- **Technical Details**: 주의 메커니즘에서의 benign overfitting을 확인하기 위해, training 시 주의 확률(attention probabilities)의 행동에 따라 다양한 시나리오에서 benign overfitting과 not-benign overfitting 사례를 제시합니다. 특히, 소프트맥스(softmax) 함수의 미분 및 주어진 조건 하에서의 성질을 상세히 분석하고, 기울기(iteration) 및 토큰 인덱스(token index)에 대한 고유 계수(unique coefficients)가 존재함을 보입니다.

- **Performance Highlights**: 이 연구는 attention 아키텍처에서의 benign overfitting을 설명하고, 이러한 현상이 발생하기 위한 조건과 특성을 규명하여, 향후 딥러닝 모델의 일반화 성능을 향상시키는 데 중요한 기초 자료를 제공합니다.



### Neural P$^3$M: A Long-Range Interaction Modeling Enhancer for Geometric GNNs (https://arxiv.org/abs/2409.17622)
Comments:
          Published as a conference paper at NeurIPS 2024

- **What's New**: Neural P$^3$M은 기하학적 그래프 신경망(GNN)의 한계를 극복하기 위해 망 점(mesh points)과 원자(Atoms)를 함께 통합한 새로운 프레임워크입니다. 이를 통해 대규모 분자 시스템에서의 장거리 상호작용을 효과적으로 캡처할 수 있습니다.

- **Technical Details**: Neural P$^3$M은 전통적인 수학적 연산을 훈련 가능한 방식으로 재구성하여 원자와 메쉬 스케일에서 단거리와 장거리 상호작용을 포착합니다. 기존의 LSRM 및 Ewald MP 방법과 비교하여 유연성과 계산 효율성을 높였습니다. 인접한 원자 및 메쉬 간의 정보 교환을 포함하여 장거리 항(terms)의 수식을 가능하게 합니다.

- **Performance Highlights**: Neural P$^3$M은 MD22 데이터셋에서 최첨단 성능을 달성하며, OE62 데이터셋에서는 평균 22% 개선된 에너지 평균 절대 오차(MAE)를 기록하였습니다. 여러 기하학적 GNN과 통합하여 Ag 및 MD22 벤치마크에서 상당한 개선을 이루었습니다.



### Diversity-Driven Synthesis: Enhancing Dataset Distillation through Directed Weight Adjustmen (https://arxiv.org/abs/2409.17612)
- **What's New**: 본 논문은 데이터 세트를 압축하면서도 핵심 특징을 보존하는 방법, 특히 데이터셋 디스틸레이션(dataset distillation)에 대한 새로운 접근 방식을 제안하고 있습니다. 기존 방법들이 각 합성 데이터 인스턴스를 개별적으로 생성하는 방식에 제한되어 있었다면, 이번 연구는 다양성을 높이기 위한 동적 및 방향성 가중치 조정 기술을 도입하여 합성 과정의 대표성과 다양성을 극대화합니다.

- **Technical Details**: 연구에서는 Batch Normalization (BN) 손실 내의 분산 정규화기(variance regularizer)가 합성 데이터의 다양성을 보장하는 핵심 요소임을 밝혔습니다. 반면, 평균 정규화기(mean regularizer)는 기대와 달리 다양성을 제약하는 역할을 하고 있습니다. 또한, 원본 데이터셋에서 단 하나의 감독(source of supervision) 역할을 하는 teacher 모델의 가중치를 동적으로 조정하는 메커니즘이 도입되어 있습니다.

- **Performance Highlights**: CIFAR, Tiny-ImageNet, ImageNet-1K 등 다양한 데이터셋을 대상으로 한 실험에서 제안된 방법이 높은 성능을 보였으며, 최소한의 계산 비용(<0.1%)으로도 매우 다양한 합성 데이터셋을 생성할 수 있음을 보여주었습니다. 이 연구는 데이터셋 디스틸레이션의 효율성을 높이는 데 기여할 것입니다.



### RmGPT: Rotating Machinery Generative Pretrained Mod (https://arxiv.org/abs/2409.17604)
- **What's New**: 이번 연구에서는 회전 기계의 진단 및 예측 작업을 위한 통합 모델 RmGPT를 제안합니다. RmGPT는 다양한 데이터셋을 효과적으로 처리하기 위해 신호 토큰(Signal Tokens), 프롬프트 토큰(Prompt Tokens), 시간-주파수 작업 토큰(Time-Frequency Task Tokens) 및 고장 토큰(Fault Tokens)을 사용하여 이질적인 데이터를 통합하는 새로운 토큰 기반 프레임워크를 도입합니다.

- **Technical Details**: RmGPT는 자가 감독 학습(self-supervised learning)을 통해 견고한 특징 추출(feature extraction)을 수행하며, 다음 신호 토큰 예측(next signal token prediction) 프리트레이닝(pretraining) 전략과 함께 효율적인 프롬프트 학습(prompt learning) 방법을 소개합니다. 이 모델은 다양한 신호 입력을 적응적으로 처리할 수 있도록 설계되었으며, Attention Mechanism을 사용하여 신호의 의미를 효율적으로 추출합니다.

- **Performance Highlights**: RmGPT는 여러 실험에서 최신 알고리즘(state-of-the-art)을 능가하며 진단 작업에서 거의 완벽한 정확도를 달성하고 예측 작업에서 매우 낮은 오류율을 보여주었습니다. 특히, 16-class one-shot 실험에서 92%의 정확도를 달성하여 적은 학습 샘플로도 우수한 성능을 발휘하는 것을 입증했습니다.



### Deep Manifold Part 1: Anatomy of Neural Network Manifold (https://arxiv.org/abs/2409.17592)
- **What's New**: 이 논문은 Neural Network (신경망)의 수학적 프레임워크인 Deep Manifold를 개발하여, 신경망의 수치 계산 특성과 학습 가능성을 탐구합니다. 주요 발견 사항으로는 신경망이 거의 무한한 자유도와 깊이에 따른 지수적인 학습 능력을 갖고 있다는 것을 들 수 있습니다.

- **Technical Details**: Neural network learning space (신경망 학습 공간)와 deep manifold space (딥 매니폴드 공간)라는 두 가지 개념을 새롭게 정의하였습니다. 또한, neural network intrinsic pathway (신경망 내재 경로) 및 fixed point (고정 점)라는 새로운 개념을 소개하였습니다. 고차 비선형(High-order non-linearity)을 다루는 Numerical Manifold Method를 통해 신경망의 해부학적 구조를 연구합니다.

- **Performance Highlights**: Deep Manifold는 LLM (Large Language Model) 훈련 과정에서 부정적 시간(Negative time)의 중요성을 강조하며, 데이터의 위치 임베딩을 통한 암묵적 시간 인코딩이 LLM의 훈련 성능에 미치는 영향을 분석합니다. 연구 결과, 신경망 모델의 학습 능력이 비선형성을 어떻게 극복하는지에 대한 통찰력을 얻을 수 있었습니다.



### Multimodal Banking Dataset: Understanding Client Needs through Event Sequences (https://arxiv.org/abs/2409.17587)
- **What's New**: 이 논문은 산업 규모의 공개 멀티모달 은행 데이터셋인 Multimodal Banking Dataset (MBD)를 소개합니다. 이 데이터셋은 150만 개 이상의 법인 고객 데이터를 포함하고 있으며, 다양한 소스에서 수집된 대량의 시퀀스 정보를 제공합니다.

- **Technical Details**: MBD는 9억 5천만 건의 은행 거래, 10억 건의 지리적 이벤트, 500만 개의 기술 지원 대화 임베딩, 4개의 은행 제품에 대한 월별 집계 구매를 포함합니다. 데이터는 클라이언트 개인 정보 보호를 위해 적절히 익명화되어 있습니다. 이 데이터셋은 두 가지 비즈니스 태스크(종합 캠페인 및 클라이언트 매칭)에 대한 기준을 제공합니다.

- **Performance Highlights**: MBD를 사용하여 다중 모달 베이스라인이 단일 모달 기법보다 각 태스크에 대해 우수함을 입증하는 수치 결과를 제공합니다. 이 데이터셋은 향후 이벤트 시퀀스에 대한 대규모 및 다중 모달 알고리즘 개발을 촉진할 수 있는 새로운 관점을 열어줄 잠재력을 가지고 있습니다.



### Multiplicative Logit Adjustment Approximates Neural-Collapse-Aware Decision Boundary Adjustmen (https://arxiv.org/abs/2409.17582)
- **What's New**: 이 논문에서는 Multiplicative Logit Adjustment (MLA)의 이론적 보장을 제공하여 분류모델의 의사 결정 경계를 최적화하는 방법을 제시합니다. 이는 특징 분포의 추정을 기반으로 하여 신경붕괴(Neural Collapse)에 접근하는 방식입니다.

- **Technical Details**: 제안된 MLA 방법은 두 단계의 이론에 의거합니다. 첫 번째 단계에서는 신경붕괴에 기반하여 특징의 분포를 추정하고 이를 통해 최적의 의사 결정 경계를 조정하는 이론을 개발합니다. 두 번째 단계에서는 MLA가 이 최적 방법을 근사화함을 보여줍니다.

- **Performance Highlights**: 실험을 통해 MLA의 근사화가 실제 비이상적인 조건에서 여전히 유효하다는 것을 검증하였으며, 또한 MLA의 하이퍼파라미터 조정에 대한 경험적 지침을 제공합니다.



### Derandomizing Multi-Distribution Learning (https://arxiv.org/abs/2409.17567)
- **What's New**: 이번 논문에서는 다중 분포 학습(multi-distribution learning)에서의 무작위 예측기(randomized predictor) 대신 결정론적 예측기(deterministic predictor)를 생성할 수 있는 가능성을 탐구합니다. 기존의 알고리즘들이 무작위성을 가진 예측기를 출력하는 반면, 이 논문에서는 그를 어떻게 결정론적 예측기로 전환할 수 있는지를 제시합니다.

- **Technical Details**: 저자들은 다중 분포 학습의 효율성을 증대시키기 위해 불일치 최소화(discrepancy minimization)로의 축소를 통해 다중 분포 학습을 비무작위화(derandomization)하는 것이 계산적으로 어렵다는 것을 보여줍니다. 특히, 효율적인 경험적 위험 최소화(ERM, Empirical Risk Minimization)가 가능하더라도 이 과제가 여전히 어렵다는 점을 강조합니다.

- **Performance Highlights**: 긍정적인 측면에서는, 저자들이 제시한 구조적 조건(structural condition)을 통해 기존의 무작위 다중 분포 예측기를 효율적으로 결정론적 예측기로 변환할 수 있는 검증된 방법을 제공하여, 실제 문제에의 적용 가능성을 높였습니다.



### Advancing Open-Set Domain Generalization Using Evidential Bi-Level Hardest Domain Scheduler (https://arxiv.org/abs/2409.17555)
Comments:
          Accepted to NeurIPS 2024. The source code will be available at this https URL

- **What's New**: 본 논문은 Open-Set Domain Generalization (OSDG) 문제를 다루며, 기존의 정해진 도메인 스케줄러와 비교하여 적응형 도메인 스케줄러의 효과를 제안합니다. 이를 통해 동적 환경에서의 데이터 배틀링에 대한 새로운 접근 방식을 제시합니다.

- **Technical Details**: 논문에서 제안하는 EBiL-HaDS (Evidential Bi-Level Hardest Domain Scheduler)는 도메인 신뢰도를 측정하는 방법을 사용하여 도메인 간의 프레젠테이션 순서를 동적으로 조정합니다. 이 방법은 follower network를 활용해 신뢰도를 평가하고, bi-level 최적화 기법을 사용하여 학습합니다.

- **Performance Highlights**: 실험 결과, EBiL-HaDS는 PACS, DigitsDG 및 OfficeHome 데이터셋에서 OSDG 성능을 크게 향상시키며, 기존의 임의적이거나 연속적인 도메인 스케줄링 방법보다 더 효과적인 성능 개선을 보였습니다.



### A Simple but Strong Baseline for Sounding Video Generation: Effective Adaptation of Audio and Video Diffusion Models for Joint Generation (https://arxiv.org/abs/2409.17550)
Comments:
          The source code will be released soon

- **What's New**: 이 논문은 오디오와 비디오를 동시에 생성하는 간단하지만 강력한 베이스라인(baseline) 방법을 제시합니다. 기존의 확산 모델(difussion models)을 기반으로 오디오와 비디오를 결합한 단일 모델을 구성하여 훈련합니다.

- **Technical Details**: 모델의 정렬(alignment)을 향상시키기 위해 두 가지 새로운 메커니즘을 도입했습니다: 타임스텝 조정(timestep alignment)과 CMC-PE(Cross-Modal Conditioning as Positional Encoding). CMC-PE는 크로스 모달(cross-modal) 정보를 시간적 위치 정보처럼 임베딩하여 모델에 입력합니다.

- **Performance Highlights**: 실험 결과, 제안한 두 가지 메커니즘의 효과가 입증되었으며, 제안한 방법이 기존 방법들과 비교하여 비디오 품질(video quality), 오디오 품질(audio quality), 그리고 크로스 모달 정렬(cross-modal alignment)에서 동등하거나 더 나은 성능을 보여주었습니다.



### On the Implicit Relation Between Low-Rank Adaptation and Differential Privacy (https://arxiv.org/abs/2409.17538)
- **What's New**: 이번 논문에서는 자연어 처리에서의 저차원(adaptation) 접근법이 데이터 프라이버시(data privacy)와 어떻게 연결되는지를 제시합니다. 특히, LoRA(Lo-Rank Adaptation)와 FLoRA(Fully Low-Rank Adaptation)의 방법이 미치는 영향을 분석하여, 이들이 데이터 민감도를 고려한 저차원 적응과 유사하다는 것을 보여줍니다.

- **Technical Details**: LoRA와 FLoRA는 언어 모델 언어를 특정 작업에 적응시키기 위해 몇 개의 레이어에 훈련 가능한 저차원 분해 매트릭스(adapter)를 통합하여, 사전 훈련된 모델의 가중치를 고정한 상태에서 사용됩니다. 이 접근법은 전통적인 매개변수 조정(full fine-tuning) 방식에 비해 필요한 훈련 가능한 매개변数의 수를 상당히 줄입니다. 연구진은 또한 저차원 적응이 DPSGD(Differentially Private Stochastic Gradient Descent)와 근본적으로 유사하다는 것을 입증하며, 가우시안 분포(Gaussian distribution)와의 변동성(variance)도 분석합니다.

- **Performance Highlights**: 연구의 주요 기여는 다음과 같습니다: 1) LoRA/FLoRA로 저차원 적응을 수행하는 것이 어댑터의 배치 그라디언트(batch gradients)에 무작위 노이즈를 주입하는 것과 동등하다는 것을 보여줍니다. 2) 주입된 노이즈의 분산을 찾아 노이즈가 입력 수와 저차원 적응의 순위(rank)가 증가함에 따라 가우시안 분포에 가까워지게 됨을 증명합니다. 3) 저차원 적응의 동역학은 DP 완전 조정(DP full fine-tuning) 어댑터와 매우 유사함을 입증하며, 이러한 저차원 적응이 데이터 프라이버시를 제공할 수 있는 가능성을 제시합니다.



### Dataset Distillation-based Hybrid Federated Learning on Non-IID Data (https://arxiv.org/abs/2409.17517)
- **What's New**: 이번 연구에서는 비독립적이고 동일 분포하지 않은(Non-IID) 데이터로 인한 라벨 분포 왜곡(label distribution skew) 문제를 해결하기 위해 HFLDD라는 새로운 하이브리드 연합 학습 프레임워크를 제안합니다.

- **Technical Details**: HFLDD는 클라이언트를 이질적인 클러스터로 분할하며, 각 클러스터 내의 데이터 라벨은 비균형하지만 클러스터 간에는 균형을 이룹니다. 클러스터 헤더는 해당 클러스터의 원거리 데이터를 수집하고 서버와 협업하여 모델 학습을 수행합니다. 이 과정은 기존의 IID 데이터에서 수행되는 전통적인 연합 학습과 유사하여 Non-IID 데이터의 영향을 효과적으로 감소시킵니다.

- **Performance Highlights**: 실험 결과에 따르면, 데이터 라벨이 심각하게 불균형할 때 HFLDD가 Baseline 방법들에 비해 테스트 정확도(test accuracy)와 통신 비용(communication cost) 모두에서 우수한 성능을 보였습니다.



### HaloScope: Harnessing Unlabeled LLM Generations for Hallucination Detection (https://arxiv.org/abs/2409.17504)
Comments:
          NeurIPS 2024 Spotlight

- **What's New**: 이번 논문에서는 HaloScope라는 새로운 학습 프레임워크를 소개합니다. 이 프레임워크는 레이블이 없는 LLM 생성물을 활용하여 hallucination을 탐지하는 데 중점을 두고 있습니다. 기존의 신뢰성 분류기 학습의 주요 어려움인 레이블이 붙은 데이터 부족 문제를 해결하기 위한 접근법을 제시합니다.

- **Technical Details**: HaloScope는 자동화된 membership estimation score를 통해 레이블이 없는 데이터에서 진실한 생성물과 허위 생성물을 구분합니다. 이 프레임워크는 LLM의 잠재적 표현(latent representations)을 활용하여 허위 진술과 관련된 서브스페이스를 식별하고, 이를 통해 이진 진실성 분류기를 훈련할 수 있도록 합니다.

- **Performance Highlights**: HaloScope는 다양한 데이터셋에 걸쳐 hallucination 탐지 성능을 향상시켰으며, TruthfulQA 벤치마크에서 기존의 최첨단 방법 대비 10.69% (AUROC) 향상된 정확도를 기록했습니다. 이로 인해 HaloScope의 실용성과 유연성이 강화되었습니다.



### Broadcast Product: Shape-aligned Element-wise Multiplication and Beyond (https://arxiv.org/abs/2409.17502)
- **What's New**: 본 논문에서는 두 개의 텐서 간의 새롭게 정의된 연산인 broadcast product를 제안합니다. 이 연산은 두 텐서의 형태를 맞추기 위해 요소를 복제한 후 Hadamard product를 계산합니다.

- **Technical Details**: broadcast product는 두 텐서의 요소 크기를 맞추고 나서의 Hadamard product로, numpy에서의 broadcast operation과 수학적으로 동등합니다. 본 논문에서는 broadcast product를 구현한 새로운 텐서 분해 모델을 제시하며, 이를 통해 차원 축소의 잠재적 응용을 강조합니다.

- **Performance Highlights**: 이 새로운 연산자는 복잡한 문제에 대한 간결한 설명을 가능하게 하여 새로운 수학적 모델과 최적화 과제를 제시할 수 있는 잠재력이 있습니다.



### Does Worst-Performing Agent Lead the Pack? Analyzing Agent Dynamics in Unified Distributed SGD (https://arxiv.org/abs/2409.17499)
Comments:
          To appear in NeurIPS 2024

- **What's New**: 이번 연구에서는 Unified Distributed SGD (UD-SGD)의 비대칭적 분석을 수행하며, 분산 학습에서 통신 패턴과 샘플링 전략의 다양성을 탐구합니다. 특히 Federated Learning (FL) 환경에서의 샘플링 방식이 수렴 속도에 미치는 영향을 분석합니다.

- **Technical Details**: UD-SGD의 성능은 i.i.d. 샘플링, 섞기(shuffling), 그리고 마르코프 샘플링(Markovian sampling) 같은 다양한 샘플링 전략에 의해 영향을 받습니다. 각 에이전트의 동적 변화가 중앙 극한 정리(CLT)에 의해 제한 공분산 행렬에 미치는 영향을 고려하여 수렴 속도를 평가합니다.

- **Performance Highlights**: 효율적인 샘플링 전략을 사용한 소수의 에이전트가 보통의 샘플링 전략을 사용하는 대다수의 에이전트를 초과하는 성능을 발휘할 수 있음을 확인하였으며, 이는 분산 학습에서의 전통적인 분석을 넘어서는 새로운 통찰력을 제공합니다.



### MathDSL: A Domain-Specific Language for Concise Mathematical Solutions Via Program Synthesis (https://arxiv.org/abs/2409.17490)
- **What's New**: 본 논문에서는 수학 방정식 해결을 위한 도메인-specific 언어(MathDSL)를 소개하며, 이 언어가 기존의 강화 학습(reinforcement learning) 기반 방법들보다 더 우수한 성능을 보인다고 주장합니다.

- **Technical Details**: MathDSL은 수학적 해결책의 간결함을 측정하기 위한 정량적(metric) 지표를 도입하며, DreamCoder라는 프로그램 합성 시스템을 활용하여 선형 방정식을 더욱 정확하고 간결하게 해결할 수 있는 프로그램을 생성합니다. 또한, 이전의 강화 학습 시스템의 작업 공간(action spaces)을 DSL로 활용하는 경우에도 MathDSL이 더 나은 성능을 보여준다고 설명합니다.

- **Performance Highlights**: MathDSL을 사용하여 DreamCoder가 생성한 프로그램들은 전통적인 강화 학습 시스템 대비 높은 정확도와 간결함을 자랑하며, 이러한 접근법은 수학 교육에서도 활용될 수 있는 인간이 이해할 수 있는 해결 전략으로 변환될 수 있음을 보여줍니다.



### Heterogeneous Hyper-Graph Neural Networks for Context-aware Human Activity Recognition (https://arxiv.org/abs/2409.17483)
Comments:
          PerCom 2023

- **What's New**: 이 논문은 Context-aware Human Activity Recognition (CHAR) 문제를 그래프 표현 학습(task)으로 재정의하여 사용자 활동 인식의 성능을 향상시키는 새로운 접근 방식을 제안합니다. 특히 <Activity, Phone Placement> 튜플 인식 문제에 집중하며, CHAR 데이터에서 발견된 이질적인 하이퍼그래프 구조를 통한 새로운 모델을 도입합니다.

- **Technical Details**: CHAR 데이터에 숨겨진 그래프 구조를 도출하기 위해 Heterogeneous HyperGraph Neural Network (HHGNN-CHAR) 아키텍처를 제안합니다. 이 구조는 사용자, 전화 배치, 활동의 세 가지 이질적인 노드로 구성되며, 모든 노드 간의 연결은 하이퍼엣지(hyperedge)로 표현됩니다. 또한, 그래프 표현 학습 문제로 변환된 CHAR 작업을 통해 세 가지 노드 간의 관계를 명시적으로 파악하고 활용할 수 있습니다.

- **Performance Highlights**: 제안된 HHGNN-CHAR 모델은 현실적인 in-the-wild CHAR 데이터셋에서 기존 SOTA 모델들에 비해 Matthews Correlation Coefficient (MCC)에서 14.04%, Macro F1 점수에서 7.01% 향상된 성능을 보였으며, 각 모델 구성 요소의 기여도에 대한 철저한 평가도 수행되었습니다.



### On the Impact of Feature Heterophily on Link Prediction with Graph Neural Networks (https://arxiv.org/abs/2409.17475)
Comments:
          Accepted to NeurIPS 2024

- **What's New**: 이 논문에서는 연결된 노드들이 서로 다른 클래스 레이블 또는 특성을 가지는 경향인 이질성(heterophily)이 Graph Neural Network (GNN) 성능에 미치는 영향을 분석합니다. 특히 노드 특성의 이질성이 링크 예측(link prediction) 작업에 주는 영향을 체계적으로 연구합니다.

- **Technical Details**: 이 논문에서는 동질성(homophily) 및 비동질성(non-homophilic) 링크 예측 작업을 위한 형식적 정의를 소개하고, 이러한 작업을 위해 필요한 최적화의 차이를 강조하는 이론적 프레임워크를 제시합니다. 또한, 링크 예측 인코더 및 디코더가 다양한 특성 동질성 수준에 어떻게 적응하는지 분석하고 비동질성 링크 예측 성능을 개선하기 위한 설계를 도입합니다.

- **Performance Highlights**: 합성 데이터 및 실제 데이터셋에 대한 실증 분석을 통해 이론적 통찰이 확인되었으며, 링크 예측 작업에서 동질성 이상의 성능을 개선하기 위해 GNN 인코더와 기타 시각적 설계의 중요성이 강조됩니다. 특히, 메세지 패싱(message passing)에서의 에고(ego) 및 이웃(neighbor) 임베딩 분리가 중요하다는 점이 강조되었습니다.



### Stress Detection from Photoplethysmography in a Virtual Reality Environmen (https://arxiv.org/abs/2409.17427)
Comments:
          Updated code and data available at this https URL

- **What's New**: 개인화된 가상 현실 노출 치료법(VRET)을 사용하여 환자의 정신 상태를 평가하는 새로운 플랫폼이 제안되었습니다. 이 연구는 비침습적이고 흔히 사용되는 생리학적 신호인 photoplethysmography (PPG)를 통한 정신 상태 감지의 가능성을 탐구합니다.

- **Technical Details**: 연구에서는 relaxing과 stressful이라는 두 가지 VR 환경을 통해 PPG 생리학적 데이터를 수집하였고, 이를 이용해 사용자의 상태(편안함과 스트레스 상태)를 자동으로 감지하는 모델을 학습했습니다. 최종적으로, 70.6%의 정확도로 이 두 상태를 분류하는 데 성공했습니다.

- **Performance Highlights**: 이 연구는 복잡한 방법론보다 단순한 PPG 신호를 사용하여 스트레스 상태를 예측하는 데 있어 성능이 우수함을 보여주었습니다. 해당 모델은 정서적 및 생리적 상태를 실시간으로 더 정확하게 모니터링할 수 있는 가능성을 강조합니다.



### Spiders Based on Anxiety: How Reinforcement Learning Can Deliver Desired User Experience in Virtual Reality Personalized Arachnophobia Treatmen (https://arxiv.org/abs/2409.17406)
Comments:
          Under review at ACM Transactions on Interactive Intelligent Systems (TIIS). Code and data available at this https URL

- **What's New**: 이 논문은 개인화된 가상 현실 노출 치료(VRET)를 위한 새로운 프레임워크를 제안합니다. 이 프레임워크는 절차적 콘텐츠 생성(Procedural Content Generation, PCG)과 강화 학습(Reinforcement Learning, RL)을 활용하여 환자의 특정 불안을 유도하는 거미를 자동 생성합니다.

- **Technical Details**: 제안된 시스템은 환자가 거미를 관찰할 때 특정한 불안 반응을 유도하도록 거미를 조정할 수 있는 절차적 콘텐츠 생성 기술과 강화 학습 알고리즘을 결합합니다. 이는 거미의 특성을 환자의 반응에 맞추어 자동으로 최적화합니다.

- **Performance Highlights**: 제안된 시스템은 전통적인 규칙 기반 VRET 방법보다 우수한 성능을 보였습니다. 이는 치료 과정에서의 시간 효율성을 높이고, 각 환자에 맞춤형으로 거미를 제공하는 데 있어 중요한 발전을 나타냅니다.



### Zeroth-Order Policy Gradient for Reinforcement Learning from Human Feedback without Reward Inferenc (https://arxiv.org/abs/2409.17401)
- **What's New**: 이번 논문은 보상 추론 (reward inference) 없이 동작하는 두 가지 새로운 강화학습(RLHF) 알고리즘을 제안합니다. 이 알고리즘은 일반적인 RL 문제에 대해 효율성을 증명하며, Bradely-Terry 모델을 넘어서 인간 선호 모델에 적용됩니다.

- **Technical Details**: 제안된 알고리즘은 사람의 선호로부터 로컬 벨류 함수 차이를 추정하고 zeroth-order gradient approximator를 사용하여 정책 기울기를 근사합니다. 이 접근 방식은 기본적인 MDP 및 스토캐스틱 MDP에 대해 적용 가능하며, 기존의 reward inference 기법이 가진 여러 도전과제를 피할 수 있습니다.

- **Performance Highlights**: 기존 DPO의 한계를 극복하여, 보다 일반적인 환경에서 효율적으로 작동하는 알고리즘을 개발하였음을 증명했습니다. 실험 결과는 보상 모델을 사용하지 않고도 효과적인 정책 학습이 가능함을 보여줍니다.



### Trading through Earnings Seasons using Self-Supervised Contrastive Representation Learning (https://arxiv.org/abs/2409.17392)
- **What's New**: 이번 연구에서는 Earnings 데이터의 활용을 극대화하기 위한 Contrastive Earnings Transformer (CET) 모델을 소개합니다. 이 모델은 자가 지도 학습(self-supervised learning) 접근 방식을 통해 Earnings 데이터의 시간에 따른 변화하는 중요성을 효과적으로 다룰 수 있도록 설계되었습니다.

- **Technical Details**: CET 모델은 Contrastive Predictive Coding (CPC)에 기초하여 구성됩니다. 이는 다변량 시간 시계열 데이터를 처리하는 데 뛰어난 Transformer 아키텍처를 사용하여 복잡한 종속 관계를 효과적으로 모델링합니다. 또한, 자가 지도 사전 학습(self-supervised pre-training)을 통해 무표시된 가격 및 Earnings 데이터로부터 유용한 시간 인식 표현을 학습할 수 있습니다.

- **Performance Highlights**: CET 모델은 다양한 산업군에 걸쳐 기존 벤치마크 모델들과 비교하여 독특한 장점을 보여주었습니다. 특히, Earnings 데이터가 시간이 지남에 따라 어떤 방식으로 변하는지를 이해하고 이를 기반으로 지속적인 주식 예측을 가능하게 합니다.



### Beyond Redundancy: Information-aware Unsupervised Multiplex Graph Structure Learning (https://arxiv.org/abs/2409.17386)
Comments:
          Appear in NeurIPS 2024

- **What's New**: 이 논문에서는 여러 가지 간선 유형에 대한 노드 표현을 수동 라벨링 없이 학습하는 비지도 다중 그래프 학습(UMGL)에 초점을 두고 있습니다. 특히, 그래프 구조의 신뢰성을 고려하지 않았던 기존 연구의 한계를 지적하며, 다양한 그래프에서 노이즈를 제거하고 과제 관련 정보를 보존하는 새로운 비지도 학습 방법을 제안합니다.

- **Technical Details**: 제안된 프레임워크인 정보 인식 비지도 다중 그래프 융합(InfoMGF)은 그래프 구조 정제를 활용하여 불필요한 노이즈를 제거하고, 동시에 공유된 과제 관련 정보와 고유한 과제 관련 정보를 최대화합니다. 이 프레임워크는 비지도 학습 방식으로 다중 그래프에서 융합 그래프를 학습합니다.

- **Performance Highlights**: 다양한 다운스트림 작업에 대해 여러 기준선과 비교하여 InfoMGF의 우수한 성능과 강건성을 입증합니다. 특히, 비지도 방법임에도 불구하고 기존의 정교한 감독 방법보다 더 나은 성능을 보였습니다.



### Data-efficient Trajectory Prediction via Coreset Selection (https://arxiv.org/abs/2409.17385)
- **What's New**: 이 논문에서는 복잡한 주행 시나리오(시나리오)에서 데이터 부족 문제와 과대표현된 주행 시나리오로 인한 데이터 중복 문제를 완화하기 위해 새로운 데이터 효율적인 훈련 방법인 'coreset selection'을 제안합니다. 이 방법은 다양한 난이도의 시나리오 간 비율을 조절하면서 중요 데이터를 선택하여, 훈련 성능을 유지하면서 데이터 용량을 줄입니다.

- **Technical Details**: 이 방법은 데이터셋의 난이도 수준에 따라 데이터를 그룹화하고, 각 샘플에 대한 하위 모듈러 이득(submodular gain)을 계산하여 가장 가치 있는 데이터를 선택합니다. 두 가지 선택 방법인 'Fixed Selection'과 'Balanced Selection'을 통해 데이터 분포를 조절하며, 특히 Balnced Selection 방법은 복잡한 시나리오에서 유리한 성과를 보여줍니다. 또한, coresets는 일반화 능력이 뛰어나고 다양한 모델에 대해 테스트되었습니다.

- **Performance Highlights**: Fixed Selection 방법을 이용한 coresets는 전체 데이터셋의 50%만으로도 성능 저하 없이 비슷한 결과를 보여주었으며, Balanced Selection 방법은 더 복잡한 주행 시나리오에서 현저한 성과를 기록했습니다. 선택된 coresets는 SOTA 모델인 HPNet에서도 유사한 성능을 발휘하여, 모델의 다양한 난이도 시나리오에서의 일반화 능력을 강화했습니다.



### Implicit Neural Representations for Simultaneous Reduction and Continuous Reconstruction of Multi-Altitude Climate Data (https://arxiv.org/abs/2409.17367)
Comments:
          arXiv admin note: text overlap with arXiv:2401.16936

- **What's New**: 이번 논문에서는 다중 고도 풍속 데이터 분석 및 저장을 위한 심층 학습 프레임워크인 GEI-LIIF를 제안합니다. 이 프레임워크는 차원 축소(dimensionality reduction), 교차 모드 예측(cross-modal prediction), 슈퍼 해상도(super-resolution)를 동시에 지원하여 기존의 방법론보다 우수한 성능을 보입니다.

- **Technical Details**: GEI-LIIF는 고해상도 데이터의 효과적인 회복을 위해 임시 신경망(implicit neural networks)을 사용합니다. 이 접근 방식은 고해상도 풍속 데이터를 저해상도로 축소한 후, 연속적인 슈퍼 해상도 표현을 학습하는 방식으로 작동합니다. 구체적으로, 별도의 입력 모드에 구애받지 않는 모드 특정 저차원 표현을 학습하기 위한 새로운 잠재 손실 함수(latent loss function)를 제안합니다.

- **Performance Highlights**: 제안된 방법은 슈퍼 해상도 품질 및 압축 효율성(compression efficiency) 면에서 기존의 방법들을 초월한다고 입증되었습니다. 실험 결과, 기후 변화 분석 및 풍력 에너지 최적화에 유용한 다중 모드 형태로 풍속 패턴을 추정할 수 있는 가능성을 보여줍니다.



### Revisiting inverse Hessian vector products for calculating influence functions (https://arxiv.org/abs/2409.17357)
Comments:
          23 pages, 7 figures, 4 tables

- **What's New**: 이 논문은 모델의 출력을 훈련 데이터에 어떻게 귀속시키는지 설명하기 위한 도구인 influence function(영향 함수)의 새롭고 실용적인 접근 방식을 제시합니다. 특히, LiSSA(Linear Stochastic Second-Order Algorithm)의 하이퍼파라미터 선택이 헤시안(Hessian)의 스펙트럼 특성과 밀접하게 연관되어 있음을 밝혔습니다.

- **Technical Details**: 저자들은 세 가지 하이퍼파라미터인 스케일링 팩터(scaling factor), 배치 크기(batch size), 스텝 수(steps)를 헤시안의 특성에 따라 선택할 수 있는 방법을 제안합니다. 이를 위해 랜덤 스케칭(random sketching) 기법을 사용하여 이러한 통계를 평가하며, LiSSA의 수렴을 보장하기 위한 배치 크기의 요구 조건을 우선 검토합니다.

- **Performance Highlights**: 이 연구는 다양한 비전 및 언어 모델에 대해 LiSSA의 성능을 실험적으로 검증했으며, 그 결과 배치 크기가 적당히 크면 알고리즘이 수렴할 수 있다는 것을 확인했습니다. 또한, PBRF(Proximal Bregman Retraining Functions)를 기준으로 비교함으로써 새로운 방법론이 기존의 영향 함수 근사 방식에서 발생하는 불확실성을 줄일 수 있음을 보여줍니다.



### Learning Utilities from Demonstrations in Markov Decision Processes (https://arxiv.org/abs/2409.17355)
- **What's New**: 본 논문은 순차적 의사결정 문제에서 행동의 시연을 통해 유용한 지식을 추출하려는 목표를 가지고 있습니다. 특히, 대부분의 Inverse Reinforcement Learning (IRL) 모델들이 리스크 중립(risk-neutral) 대리인을 가정하는 것과 달리, 본 연구는 대리인의 리스크 태도를 명시적으로 표현하는 새로운 모델을 제안합니다.

- **Technical Details**: 본 연구에서는 Markov Decision Processes (MDPs) 내에서 리스크 태도를 유틸리티 함수(utility function)를 통해 표현하는 행동 모델을 제안합니다. 이를 통해 Utility Learning (UL) 문제를 정의하며, 대리인의 유틸리티의 부분 식별성(partial identifiability)을 분석합니다. 또한, 유한 데이터 환경(finite-data regime)에서 UL을 위한 두 가지 효율적인 알고리즘을 고안하고, 샘플 복잡도(sample complexity)를 분석하였습니다.

- **Performance Highlights**: 논문에서는 제안된 모델 및 알고리즘의 개념 증명(proof-of-concept) 실험 결과를 통해 이들을 실증적으로 검증하였습니다.



### Non-asymptotic Convergence of Training Transformers for Next-token Prediction (https://arxiv.org/abs/2409.17335)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 본 논문에서는 Transformer의 next-token prediction(NTP) 성능을 비대칭적이지 않은(Non-asymptotic) 관점에서 분석하였습니다. 기존 연구들이 주로 비대칭적 성능에 초점을 맞춘 것과 달리, 훈련 데이터셋의 구조적 특성을 수학적 프레임워크를 통해 정밀하게 규명하고 있습니다.

- **Technical Details**: 단일층(Single-layer) Transformer는 self-attention 모듈과 feed-forward 레이어로 구성되어 있습니다. 훈련 데이터셋은 부분 순서(Partial orders)를 기반으로 특성을 정의하였고, 두 단계의 훈련 알고리즘을 설계하였습니다. 첫 번째 단계는 feed-forward 레이어를 위한 전처리(pre-processing)이며, 두 번째 단계는 attention 레이어를 위한 주요 훈련 단계입니다. 두 레이어는 각각 max-margin 솔루션 방향으로 서브 선형(Sub-linear) 수렴을 보입니다.

- **Performance Highlights**: 교차 엔트로피 손실(Cross-entropy loss)은 선형(Linear) 수렴 속도를 나타내며, 훈련된 Transformer는 데이터셋 변화(Dataset shift)에 대해 뛰어난 예측 능력을 보여줍니다. 이러한 결과는 Transformer의 일반화 성능(Generalization performance)을 강조합니다. 또한, 주의(Attention) 그래디언트(Gradient)의 새로운 특성을 개발하여 훈련 과정의 수렴에 미치는 기여를 심층 분석하였습니다.



### The poison of dimensionality (https://arxiv.org/abs/2409.17328)
Comments:
          29 pages, 3 figures

- **What's New**: 이 논문은 기계 학습 모델의 크기가 중독 공격에 대한 취약성에 미치는 영향을 심화하여 이해합니다. 특히, D≥169H²/P² 파라미터를 가진 선형 및 로지스틱 회귀 모델이 중독자에 의해 임의로 조작될 수 있음을 밝혀냈습니다.

- **Technical Details**: 중독 데이터의 수를 H (honestly labeled data)와 P (poisoned data)로 정의할 때, P=Θ(H)인 경우 D는 H와 증가하지 말아야 한다는 것입니다. 새로운 수학적 증명으로, 최신 중독 방어 기술을 적용했음에도 불구하고 선형 및 로지스틱 회귀에서 제로 안정성을 제공하지 않는다는 결론을 도출했습니다.

- **Performance Highlights**: 실험을 통해 모델의 표현력(model expressivity)과 중독 공격 면 공격 표면(attack surface) 간의 기본적인 트레이드오프를 강조했습니다. MNIST 및 FashionMNIST 데이터 세트에 대해 랜덤 특징을 가진 선형 분류 모델로 실험을 수행하였습니다.



### KIPPS: Knowledge infusion in Privacy Preserving Synthetic Data Generation (https://arxiv.org/abs/2409.17315)
- **What's New**: 이 논문은 KIPPS라는 새로운 프레임워크를 제안하여, Generative Deep Learning 모델에 Domain 및 Regulatory Knowledge를 포함시킴으로써 Privacy Preserving Synthetic 데이터 생성을 개선합니다.

- **Technical Details**: KIPPS는 Generative 모델의 학습 과정에서 속성 값에 대한 추가 맥락과 도메인 제약을 강화하는 방법으로, 데이터를 합성하는 모델의 수용성을 높입니다. 이는 주로 Cybersecurity와 Healthcare와 같은 전문화된 도메인에서 사용됩니다.

- **Performance Highlights**: KIPPS 모델은 실제 데이터셋을 사용하여 프라이버시 보호와 데이터 정확도 간의 균형을 유지하는 효과를 보여줍니다. 모델은 최신 프라이버시 공격에 대해 회복력이 뛰어나며, 다운스트림 작업에서 원본 데이터와 유사한 정보를 유지합니다.



### Consistent estimation of generative model representations in the data kernel perspective spac (https://arxiv.org/abs/2409.17308)
- **What's New**: 이 논문은 생성 모델의 임베딩 기반 표현의 이론적 결과를 제시하며, 다양한 쿼리에 대한 모델 동작의 차이를 연구하는 기술의 필요성을 강조합니다. 새로운 관점 공간(perspective space)을 제안하여, 여러 모델과 쿼리가 증가하는 상황에서의 일관된 추정을 위한 충분한 조건을 설정합니다.

- **Technical Details**: 고정된 모델과 쿼리 집합, 그리고 이들이 증가하는 경우를 포함한 세 가지 설정에서 관점 공간을 분석합니다. 각 설정에 대해서는 다차원 축척(multi-dimensional scaling) 기법을 사용하여 원시 스트레스 기준(raw stress criterion)에 따른 일관된 벡터 추정 결과를 제시합니다. 이러한 기법은 활용 시 생성 모델의 다양한 동작을 포착하는 데 유용합니다.

- **Performance Highlights**: 제안된 이론적 결과는 여러 실험적 연구를 통해 지지되며, 생성 모델의 임베딩 및 다차원 축척을 활용한 복잡한 객체의 표현 가능성을 보여줍니다. 이 논문은 생성 모델의 동작 차이를 분석하는 데 있어 중요한 기여를 하며, 향후 잠재적 응용 및 확장의 기초를 제공합니다.



### Neural Network Plasticity and Loss Sharpness (https://arxiv.org/abs/2409.17300)
- **What's New**: 최신 연구는 비정상적(non-stationary) 환경에서의 연속 학습(Continual Learning)에서 플라스틱성 손실(plasticity loss)과 손실 경량(sharpness) 간의 관계를 조사하였다. 이 논문에서는 이러한 손실을 줄이기 위한 샤프니스 정규화(sharpness regularization) 기법의 사용을 제안한다.

- **Technical Details**: 연속 학습 모델은 시간이 지남에 따라 변화하는 데이터 흐름을 학습하는 모델로, 신경망(neural network)의 예측이 다른 작업에 적응할 수 있는 능력을 요구한다. 본 연구는 손실의 헤세 행렬(Hessian matrix) 최대 고유값(maximal eigenvalue)을 통해 손실 경량을 정량화하며, 이는 네트워크가 처리하는 작업 수에 따라 증가한다는 기존 연구를 바탕으로 한다. 샤프니스 정규화 기법이 사용되며, 이는 네트워크가 더 '평평한(flatter)' 최소값을 찾도록 유도한다.

- **Performance Highlights**: 실험 결과, 샤프니스 정규화 기법은 플라스틱성 손실 감소에 유의미한 영향을 미치지 않는 것으로 나타났다. 이는 이러한 기술이 연속 학습 설정에서의 성능 유지에 있어 한계가 있음을 시사한다.



### Memory Networks: Towards Fully Biologically Plausible Learning (https://arxiv.org/abs/2409.17282)
Comments:
          2024

- **What's New**: 이번 연구에서 제안하는 Memory Network(메모리 네트워크)는 생물학적 원리에 영감을 받아, 기존 딥러닝 모델에서 사용하는 backpropagation(역전파) 및 convolutions(합성곱)을 회피하고, 단일 패스(single pass)로 작동하는 새로운 접근 방식을 제공합니다. 이로 인해 빠르고 효율적인 학습이 가능해지며, 데이터에 대한 최소한의 노출로도 빠르게 적응할 수 있는 뇌의 능력을 모방합니다.

- **Technical Details**: Memory Network는 입력된 데이터를 인코딩하여 각 뉴런이 새 입력과 같은 레이블을 가진 이전 입력의 평균 표현 사이의 유사성에 기반하여 업데이트되는 방식으로 작동합니다. 이는 전통적인 큰 규모의 CNN(합성곱 신경망)과는 달리, 지역적 플라스틱성(local plasticity) 메커니즘을 활용하여 학습하며, 이는 생물학적 과정과 더욱 밀접하게 일치합니다.

- **Performance Highlights**: 실험 결과, Memory Network는 MNIST와 같은 간단한 데이터셋에서 효율적이고 생물학적으로 그럴듯한 학습을 달성하며 강력한 성능을 보였습니다. 그러나 CIFAR10과 같은 더 복잡한 데이터셋에서는 추가적인 개선이 필요함을 나타내어, 생물학적 과정에 근접하면서도 계산 효율성을 유지할 수 있는 새로운 알고리즘과 기법 개발의 필요성을 강조했습니다.



### Model aggregation: minimizing empirical variance outperforms minimizing empirical error (https://arxiv.org/abs/2409.17267)
Comments:
          The code in this paper is available for download at this https URL

- **What's New**: 이 논문은 다양한 모델의 예측을 하나의 더 정확한 출력으로 집계하는 데이터 기반 프레임워크를 제안합니다. 이 집계 접근 방식은 각 모델의 강점을 활용하여 전체 정확도를 높이며, 비침해적이고 모델 불가지론적(model-agnostic)입니다.

- **Technical Details**: 제안된 집계 방법에는 최소 오류 집계(Minimal Error Aggregation, MEA)와 최소 분산 집계(Minimal Variance Aggregation, MVA)가 포함됩니다. MEA는 집계의 예측 오류를 최소화하는 반면, MVA는 분산을 최소화합니다. MEVA(Minimal Empirical Variance Aggregation)는 모델 오류를 추정하여 집계를 구성하며, MEEA(Minimal Empirical Error Aggregation)와 비교하여 데이터를 기준으로 한 추정에서 일관성 있게 더 우수한 성능을 발휘합니다.

- **Performance Highlights**: 제안된 MEVA 기법은 데이터 과학 작업 및 오퍼레이터 학습 과제에서 검증되었으며, 모든 사례에서 직접 오류 최소화 방법보다 우수한 성능을 보였습니다. 이는 MEVA가 개별 모델보다 더 강력하고 효과적인 집계 모델을 제공함을 시사합니다.



### CodonMPNN for Organism Specific and Codon Optimal Inverse Folding (https://arxiv.org/abs/2409.17265)
Comments:
          Appeared at the 2024 ICML AI4Science workshop

- **What's New**: CodonMPNN은 단백질 구조 및 유기체 레이블에 조건화하여 코돈(codon) 서열을 생성하는 새로운 방법입니다. 이는 단백질 백본 구조(protein backbone structure)를 기반으로 하며, 기존의 최적 코돈 선택을 초월하는 성능을 제공합니다.

- **Technical Details**: CodonMPNN은 ProteinMPNN의 구조를 유지하며, 20개의 잔기(residue) 대신 64개의 코돈을 예측합니다. 이 모델은 또한 DNA가 발현될 호스트 시스템에 대한 조건화를 추가하여 모든 순서의 autoregressive 모델(autoregressive model)입니다. 각 코돈 서열에 대한 예측은 단백질 구조로부터의 임베딩(embedding)을 활용하여 수행됩니다.

- **Performance Highlights**: CodonMPNN은 이전의 역접힘(inverse folding) 접근법과 유사한 성능을 유지하며, 생성된 아미노산 서열에 대한 코돈 회수율(codon recovery rate)을 기존 방법보다 높습니다. 또한, 동일한 단백질 서열에 대해서도 높은 피트니스(fitness)를 가진 코돈 서열을 생성할 가능성이 더 높습니다.



### Mnemosyne: Parallelization Strategies for Efficiently Serving Multi-Million Context Length LLM Inference Requests Without Approximations (https://arxiv.org/abs/2409.17264)
- **What's New**: 본 연구에서는 Mnemosyne을 통해 1000만 토큰까지의 긴 컨텍스트(Large Context)를 위한 효율적인 대화형 추론(interactive inference) 방법을 제안합니다. 이 시스템은 조정 가능한 청크(chunk) 처리, 시퀀스 파이프라인 병렬 처리(Sequence Pipeline Parallelism, SPP), 키-값 캐시 병렬 처리(KV Cache Parallelism, KVP)를 통해 긴 컨텍스트의 추론 및 처리 속도를 획기적으로 개선하고 있습니다.

- **Technical Details**: Mnemosyne 시스템은 세 가지 주요 혁신을 제공합니다: 1. 적응형 청킹(adaptive chunking): 다양한 로드 특성에 따라 청크 크기를 동적으로 조정하여 HOL 블로킹(head-of-line blocking)을 최소화합니다. 2. 시퀀스 파이프라인 병렬 처리(SPP): 긴 요청의 청크를 병렬로 처리하여 TTFT(Time to First Token)를 줄입니다. 3. 키-값 캐시 병렬 처리(KVP): 디코드(decode) 단계 동안 처리 속도를 높이기 위해 여러 서버의 키-값 캐시를 분산하여 병렬화합니다. 이러한 기법들은 3D 병렬성 전략으로 융합되어 효율적인 긴 컨텍스트 추론을 가능하게 합니다.

- **Performance Highlights**: Mnemosyne은 1000만 토큰까지 지원하는 최초의 시스템으로, TBT(Time Between Tokens)를 30ms 이내로 유지하면서 높은 처리량(througput)을 달성합니다. 이러한 성과는 다양한 컨텍스트 길이에 대한 혼합 배치(mixed batching)를 통해 이루어졌으며, 실제 생산 환경에서도 적합한 성능을 입증했습니다.



### A random measure approach to reinforcement learning in continuous tim (https://arxiv.org/abs/2409.17200)
Comments:
          33 pages

- **What's New**: 이번 논문에서는 지속적인 시간에서도 탐색(exploration)을 모델링하기 위한 랜덤 측도(random measure) 접근 방식이 제안되었습니다. 이는 측치(control)가 있는 강화 학습(reinforcement learning)에서 사용됩니다.

- **Technical Details**: 우리는 연속 시간에서 랜덤 제어를 샘플링할 때 이산 시간 그리드(discrete-time grid)에서의 경우를 고려하였으며, 결과적으로 생긴 확률 미분 방정식(stochastic differential equation, SDE)을 적절한 랜덤 측도로 구동되는 방정식(reformulate)으로 변환하였습니다. 이 랜덤 측도(random measures)의 구성은 브라운 운동(Brownian motion)과 포아송 랜덤 측도(Poisson random measure)를 사용하며, 이는 원래 모델 동역학에서의 노이즈 원천입니다. 또한 제어 실행을 위한 그리드에서 샘플링된 추가적인 랜덤 변수들이 포함됩니다. 마지막으로, 샘플링 그리드의 메쉬 크기가 0으로 갈 때 이 랜덤 측도에 대한 경계 정리(limit theorem)를 증명하였습니다.

- **Performance Highlights**: 이 논문에서 제안된 그리드 샘플링 한계 SDE는 탐색적인 SDE와 최근의 지속적인 시간 강화 학습 문헌(sample SDE)을 대체할 수 있으며, 이는 탐색적 제어 문제의 이론적 분석 및 학습 알고리즘의 도출에 활용될 수 있습니다.



### Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography (https://arxiv.org/abs/2409.18119)
Comments:
          This work is also the basis of the overall best solution for the MICCAI 2024 CXR-LT Challenge

- **What's New**: 이 연구는 의료 영상 분야에서 Contrastive Language-Image Pre-training (CLIP) 모델의 초기 적응을 유방 촬영술에 적용하고, 데이터 부족과 고해상도 이미지의 세부 사항 강조를 해결하기 위한 새로운 접근 방식을 제안합니다.

- **Technical Details**: 제안하는 방법은 Multi-view와 Multi-scale Alignment (MaMA)를 기반으로 하며, 각 관점에서 정보를 활용하여 multi-view mammography의 특징을 동시에 정렬하는 시스템을 구축합니다. 또한, clinical report 부족 문제를 해결하기 위해 template-based report construction 방식을 개발하고, parameter-efficient fine-tuning 기법을 적용합니다.

- **Performance Highlights**: EMBED 및 RSNA-Mammo의 대규모 실제 유방촬영 데이터셋에서 3개의 다른 작업에 대해 기존 방법보다 우수한 성능을 보여주었으며, 모델 크기의 52%만으로도 뛰어난 성과를 달성했습니다.



### Find Rhinos without Finding Rhinos: Active Learning with Multimodal Imagery of South African Rhino Habitats (https://arxiv.org/abs/2409.18104)
Comments:
          9 pages, 9 figures, IJCAI 2023 Special Track on AI for Good

- **What's New**: 이 연구는 코뿔소 보호를 위한 새로운 접근 방식을 제안하고 있으며, 코뿔소의 집단 배변 장소를 지도화하는 것을 통해 이들의 공간 행동에 대한 정보를 수집할 수 있는 방법을 모색하고 있다.

- **Technical Details**: 이 논문은 원거리에서 감지된 열 감지(thermal), RGB, LiDAR 이미지를 사용하여 코뿔소 배변 장소를 탐지하는 분류기를 구축하고, 수동적 및 능동적 학습 설정에서 이를 수행한다. 특히, 기존 능동 학습 방법들이 지극히 불균형한 데이터셋의 문제로 성능이 저하되는 문제를 해결하기 위해, MultimodAL이라고 불리는 새로운 능동 학습 시스템을 설계하였다.

- **Performance Highlights**: 제안된 방법은 94% 감소된 라벨 수로 수동적 학습 모델과 경쟁력을 갖추며, 유사한 크기의 데이터셋에 적용할 경우 라벨링 시간에서 76시간 이상을 절약할 수 있는 것으로 나타났다. 또한, 연구 결과 배변 장소가 무작위 분포가 아니라 클러스터 형태로 밀집해 있다는 점을 발견하여, 이에 따라 기동대(rangers) 활동의 효율성을 높이기 위한 방안을 제시하고 있다.



### Self-supervised Pretraining for Cardiovascular Magnetic Resonance Cine Segmentation (https://arxiv.org/abs/2409.18100)
Comments:
          Accepted to Data Engineering in Medical Imaging (DEMI) Workshop at MICCAI 2024

- **What's New**: 이번 연구는 Self-supervised pretraining (SSP) 방법이 Cardiovascular Magnetic Resonance (CMR) short-axis cine segmentation에서 어떻게 효용성을 가지는지를 평가하고 있으며, 대규모 무라벨 데이터셋을 활용하는 가능성을 탐구합니다.

- **Technical Details**: 본 연구에서는 SimCLR, positional contrastive learning, DINO 및 masked image modeling (MIM) 등 4가지 SSP 방법을 사용하여 296명의 연구대상에서 총 90,618개의 2D 슬라이스를 통한 무라벨 프리트레이닝을 진행했습니다. 이후 여러 수의 레이블이 있는 데이터를 통해 각 SSP 방법으로 2D 모델의 파인튜닝을 수행하여 baseline 모델과 성능을 비교했습니다.

- **Performance Highlights**: 결과적으로, 레이블 데이터가 충분하지 않은 경우, MIM을 사용한 SSP는 0.86의 DSC를 기록하며 무라벨로부터 학습한 모델보다 개선된 결과를 보였습니다. 반면에, 충분한 레이블 데이터가 있을 경우 SSP는 성능 향상을 보이지 않았습니다.



### Infer Human's Intentions Before Following Natural Language Instructions (https://arxiv.org/abs/2409.18073)
- **What's New**: 이 논문에서는 Ambiguous natural language instructions를 효과적으로 수행하기 위한 새로운 프레임워크인 Follow Instructions with Social and Embodied Reasoning (FISER)를 제안합니다. 이 프레임워크는 사람의 목표와 의도를 추론하는 단계를 명시적으로 포함합니다. 이는 AI 에이전트가 인간의 자연어 명령을 이해하고 협력적 작업을 더 잘 수행하도록 돕습니다.

- **Technical Details**: FISER는 두 가지 주요 구성 요소인 social reasoning과 embodied reasoning을 사용하여 모델이 인간의 의도를 명시적으로 추론할 수 있도록 합니다. 먼저 social reasoning을 통해 인간이 요청하는 하위 작업(sub-task)을 예측한 후, 이러한 지침을 로봇이 이해할 수 있는 작업으로 변환하는 Embodied reasoning 단계로 진행합니다. 또한, FISER는 계획 인식(plan recognition) 단계를 추가하여 인간의 전반적인 계획을 추론하는 데 도움을 줍니다.

- **Performance Highlights**: FISER 모델은 HandMeThat(HMT) 벤치마크에서 64.5%의 성공률을 기록하며, 이전의 end-to-end 접근법을 초월한 성능을 보여줍니다. 또한, FISER는 체인 오브 토트(Chain-of-Thought) 방식으로 GPT-4를 기반으로 한 강력한 기준과 비교했을 때도 우수한 결과를 도출했습니다. 이 결과는 인간의 의도에 대한 중간 추론을 명시적으로 수행하는 것이 AI의 성능을 개선하는 데 효과적임을 입증합니다.



### Revisit Anything: Visual Place Recognition via Image Segment Retrieva (https://arxiv.org/abs/2409.18049)
Comments:
          Presented at ECCV 2024; Includes supplementary; 29 pages; 8 figures

- **What's New**: 이번 연구에서는 Embodied agents가 시각적으로 장소를 인식하고 이동하는 데 있어 중요한 문제를 다루었습니다. 전체 이미지를 사용하는 기존 방법 대신, 이미지의 '세그먼트'를 인코딩하고 검색하는 새로운 접근 방식을 제안합니다. 이를 통해 SuperSegment라는 새로운 이미지 표현을 생성하여 장소 인식을 향상시킵니다.

- **Technical Details**: 제안된 SegVLAD는 Open-set 이미지 분할(open-set image segmentation)을 통해 이미지를 의미있는 요소(entities)로 분해합니다. 각 아이템은 SuperSegments로 연결되어 구조화됩니다. 새로 제안된 Feature aggregation 방법을 사용하여 이 SuperSegments를 효율적으로 컴팩트한 벡터 표현으로 인코딩합니다. SegVLAD는 다양한 벤치마크 데이터셋에서 기존의 방법보다 높은 인식 리콜을 기록했습니다.

- **Performance Highlights**: SegVLAD는 다양한 VPR 벤치마크 데이터셋에서 최첨단 성능을 달성했습니다. IOU 기반 필터링을 통해 중복성을 줄이고 스토리지를 절약하며, 전체 이미지 기반 검색보다 더욱 뛰어난 성능을 보입니다. 연구 결과, SegVLAD는 이미지 인코더의 특정 작업에 관계없이 적용 가능하고, 객체 인스턴스 검색(object instance retrieval) 과제를 평가하여 '무언가를 재방문(revisit anything)'할 수 있는 잠재력을 보여주었습니다.



### IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning (https://arxiv.org/abs/2409.18046)
Comments:
          Accepted to EMNLP 2024

- **What's New**: 최근 이미지 캡셔닝(image captioning) 분야에서 이미지-텍스트 데이터 쌍의 한계를 극복하기 위해 텍스트-전용(training) 교육 방법이 탐색되고 있습니다. 본 논문에서는 텍스트 데이터와 이미지 데이터 간의 모달리티 차이를 완화하기 위한 새로운 접근 방식으로 'Image-like Retrieval'을 제안합니다.

- **Technical Details**: 제안된 방법인 IFCap($\textbf{I}$mage-like Retrieval과 $\textbf{F}$requency-based Entity Filtering for Zero-shot $\textbf{Cap}$tioning)는 효율적인 이미지 캡셔닝을 위한 통합 프레임워크로, Fusion Module을 통해 검색된 캡션과 입력 특성을 통합하여 캡션 품질을 향상시킵니다. 또한 Frequency-based Entity Filtering 기술을 도입하여 더 나은 캡션 품질을 제공합니다.

- **Performance Highlights**: 광범위한 실험 결과, IFCap은 기존의 텍스트-전용 훈련 기반 제로샷 캡셔닝(zero-shot captioning) 방식에 비해 이미지 캡셔닝과 비디오 캡셔닝 모두에서 state-of-the-art 성능을 기록하는 것으로 나타났습니다.



### FlowBench: A Large Scale Benchmark for Flow Simulation over Complex Geometries (https://arxiv.org/abs/2409.18032)
- **What's New**: FlowBench라는 새로운 데이터셋을 소개하며, 이는 복잡한 기하학을 가진 유체 흐름 시뮬레이션에 중점을 두고 있다. FlowBench는 10,000개 이상의 샘플을 포함하고 있으며, 이는 현재 공개된 유체 물리 데이터셋 중 가장 큰 규모이다.

- **Technical Details**: FlowBench는 다양한 흐름 조건(예: Reynolds number와 Grashoff number)과 함께 두 가지 유형(parametric vs. non-parametric)의 복잡한 기하학에서의 유체 흐름 시뮬레이션 데이터를 포함하고 있으며, 모든 샘플은 검증된 시뮬레이터 프레임워크를 통해 완전히 해결된 직접 수치 시뮬레이션의 결과이다.

- **Performance Highlights**: FlowBench를 활용하여 복잡한 기하학과 유체 흐름 현상 간의 상호작용을 평가하는 것을 목표로 하며, Neural PDE solvers의 성능을 순위별로 평가하기 위한 여러 평가 메트릭스를 제시하고 있다. 또한, FNO, CNO, WNO, DeepONet 등 여러 기본 방법의 성능을 비교한다.



### PhoCoLens: Photorealistic and Consistent Reconstruction in Lensless Imaging (https://arxiv.org/abs/2409.17996)
Comments:
          NeurIPS 2024 Spotlight

- **What's New**: 이 논문에서는 기존의 렌즈 기반 시스템보다 크기, 무게 및 비용 측면에서 이점이 있는 렌즈 없는 카메라의 이미지 재구성을 개선하기 위해 새로운 두 단계 접근 방식을 소개합니다. 이 접근 방식은 일관성과 포토리얼리즘을 동시에 달성하는 데 중점을 두고 있습니다.

- **Technical Details**: 첫 번째 단계에서는 시공간 변동 표시 함수(Variation of Point Spread Function, PSF)에 적응하는 공간적으로 변하는 복원(deconvolution) 방법을 사용하여 저주파(low-frequency) 콘텐츠를 정확하게 재구성합니다. 두 번째 단계에서는 사전 훈련된 확산(diffusion) 모델에서 생성적 사전(Generative Prior)을 통합하여 고주파(high-frequency) 세부사항을 복원하며, 첫 번째 단계에서 복원된 저주파 콘텐츠에 조건을 부여하여 포토리얼리즘을 높입니다.

- **Performance Highlights**: 우리의 방법은 기존의 방법들과 비교하여 데이터 충실도(data fidelity)와 시각적 품질(visual quality) 사이의 우수한 균형을 달성했습니다. PhlatCam과 DiffuserCam의 두 가지 렌즈 없는 시스템에서 성능을 입증하며, 시각적 개선을 여러 평가 지표를 통해 보여주고 있습니다.



### Joint Localization and Planning using Diffusion (https://arxiv.org/abs/2409.17995)
Comments:
          7 pages, 9 figures. Submitted to ICRA 2025, under review

- **What's New**: 이번 연구에서는 로봇 내비게이션 문제 해결을 위한 새로운 Diffusion 모델을 제안합니다. 이는 전방향 로컬라이제이션(global localization)과 경로 계획(path planning), 두 가지 프로세스를 통합하여 임의의 2D 환경에서의 탐색을 가능하게 합니다.

- **Technical Details**: 제안된 모델은 LIDAR 스캔, 장애물 맵 및 목표 위치에 의존하여 충돌 없는 경로를 생성합니다. 연구는 SE(2) 공간에서의 확산을 구현하며, 장애물과 센서 관측치에 따라 디노이징 과정이 어떻게 조정되는지를 설명합니다.

- **Performance Highlights**: 실험 결과, 제안된 조건화 기법이 훈련 환경과 상당히 다른 외관의 현실적인 맵에 대한 일반화를 가능하게 하며, 불확실한 솔루션을 정확히 설명할 수 있음을 보여주었습니다. 또한, 실제 환경에서의 실시간 경로 계획 및 제어를 위한 모델의 활용 가능성을 시연했습니다.



### LoopSR: Looping Sim-and-Real for Lifelong Policy Adaptation of Legged Robots (https://arxiv.org/abs/2409.17992)
Comments:
          under review

- **What's New**: LoopSR이라는 새로운 생애 주기 정책 적응 방법을 제안합니다. 이 방법은 실제 환경에서의 지속적인 학습을 시뮬레이션 정책 사전 교육과 통합하여 실제 배포 중 지속적인 개선이 가능합니다.

- **Technical Details**: LoopSR은 트랜스포머 기반 인코더를 활용하여 실제 세계의 궤적을 잠재 공간(latent space)으로 투영합니다. 오토인코더 아키텍쳐와 대조적 학습(contrastive learning) 방법을 채택하여 현실 세계의 동적 특성을 잘 추출합니다. 또, 시뮬레이션 매개변수를 위해 디코더에서 예측된 매개변수와 시뮬레이션 궤적 데이터셋에서 검색된 매개변수를 결합하여 지속적인 훈련을 합니다.

- **Performance Highlights**: LoopSR는 강력한 기준선과 비교하여 우수한 데이터 효율성을 달성하였으며, 제한된 양의 데이터만으로도 시뮬레이션-대-시뮬레이션 및 시뮬레이션-대-실제 실험 모두에서 뛰어난 성능을 보였습니다.



### Hypergame Theory for Decentralized Resource Allocation in Multi-user Semantic Communications (https://arxiv.org/abs/2409.17985)
- **What's New**: 본 논문에서는 다중 사용자 지향의 Semantic Communications (SC) 시스템을 위한 혁신적인 분산 컴퓨팅 및 통신 리소스 할당 프레임워크를 제안합니다. 이는 기존 솔루션이 다루지 못했던 컴퓨팅 및 통신의 균형을 고려합니다.

- **Technical Details**: 이 프레임워크는 Stackelberg hyper game 이론을 적용하여 통신과 컴퓨팅 자원(자원 allocation)을 효율적으로 분산 방식으로 할당함으로써 최종 사용자에게 최대의 작업 경험 품질을 제공하도록 설계되었습니다. 또한, 사용자 간의 상호작용에서 오해를 모델링하기 위해 새로운 분석 공식을 개발했습니다.

- **Performance Highlights**: 시뮬레이션 결과에 따르면, 제안된 Stackelberg hyper game 접근법은 사용자의 오해를 고려하여 통신 및 컴퓨팅 리소스를 효과적으로 활용하면서도 높은 사용자 경험 품질을 유지하는 데 있어 최신 기술보다 우수한 성능을 보여주었습니다.



### HydraViT: Stacking Heads for a Scalable V (https://arxiv.org/abs/2409.17978)
- **What's New**: 새로운 HydraViT 접근 방식은 다중 크기의 Vision Transformers (ViTs) 모델을 학습하고 저장하는 필요성을 없애면서, 스케일러블한 ViT를 가능하게 합니다.

- **Technical Details**: HydraViT는 Multi-head Attention (MHA) 메커니즘을 기반으로 하여, 다양한 하드웨어 환경에 적응할 수 있도록 임베딩 차원과 MHA의 헤드 수를 동적으로 조정합니다. 이 방식은 최대 10개의 서브 네트워크를 생성할 수 있습니다.

- **Performance Highlights**: HydraViT는 ImageNet-1K 데이터셋에서 동일한 GMACs와 처리량을 기준으로, 기존 모델 대비 최대 7 p.p. 높은 정확성을 달성하며, 이는 다양한 하드웨어 환경에서 특히 유용합니다.



### BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search (https://arxiv.org/abs/2409.17972)
- **What's New**: 본 연구는 대규모 언어 모델(LLMs)이 수학 문제 해결 능력을 향상시키기 위한 새로운 방법인 BEATS를 제안합니다. 이 방법은 모델이 문제를 단계별로 해결하도록 유도하는 적절히 설계된 프롬프트(prompt)를 활용하며, 생성된 답변의 정확성을 검증하기 위한 새로운 역검증(back-verification) 기술을 도입합니다.

- **Technical Details**: BEATS는 모델이 문제를 반복적으로 재작성(rewrite)하고, 한 단계씩 진전을 이루며, 이전 단계를 바탕으로 답변을 생성하도록 유도합니다. 또한, 기존의 투표 기반 검증 방식 대신 질문과 정답을 모델에 재제출하여 정답의 정확성을 판단하는 역검증 방식을 적용합니다. 마지막으로, 가지치기(pruning) 트리 탐색을 통해 검색 시간을 최적화하면서도 성과를 높입니다.

- **Performance Highlights**: BEATS 방법은 Qwen2-7B-Instruct 모델을 기반으로 할 때 MATH 데이터셋에서 점수를 36.94에서 61.52로 개선시켰으며, 이는 GPT-4의 42.5를 초월한 성과입니다. 추가적으로 MATH, GSM8K, SVAMP, SimulEq, NumGLUE 등 여러 데이터셋에서도 경쟁력 있는 결과를 달성하였습니다.



### On Translating Technical Terminology: A Translation Workflow for Machine-Translated Acronyms (https://arxiv.org/abs/2409.17943)
Comments:
          AMTA 2024 - The Association for Machine Translation in the Americas organizes biennial conferences devoted to researchers, commercial users, governmental and NGO users

- **What's New**: 이번 논문에서는 기계 번역(Machine Translation, MT) 시스템에서 약어의 모호성 제거(acronym disambiguation)를 제안함으로써, 약어 번역의 정확성을 높이고자 하는 새로운 접근 방식을 소개합니다. 또한 새로운 약어 말뭉치(corpus)를 공개하고, 이를 기반으로 한 검색 기반 임계값(thresholding) 알고리즘을 실험하여 기존의 Google Translate와 OpusMT보다 약 10% 더 나은 성능을 보였습니다.

- **Technical Details**: 기계 번역 시스템의 약어 번역 정확도를 향상시키기 위해, 4단계의 고레벨 프로세스를 제안하였습니다. 이 프로세스는 (1) Google Translate를 사용하여 FR-EN 번역 수행, (2) 영어 장기형(long form, LF)과 단기형(short form, SF) 추출, (3) AB3P 툴을 사용한 약어 가설 생성, (4) 검색 기법을 통한 가설 검증 및 평가입니다. 이 방법들은 텍스트에서 사용된 기술 용어의 신뢰성을 향상시키는데 기여하고자 합니다.

- **Performance Highlights**: Google Translate와 OpusMT와 비교하여, 제안하는 임계값 알고리즘은 약 10%의 성능 향상을 보여주었습니다. 우리의 연구에서는 전문 번역사들이 자주 직면하는 용어 오류를 감소시키는 방안을 제시하고 있으며, 이를 통해 MT 시스템에서의 기술 용어 번역의 적합성을 증대시키는 데 기여할 것입니다.



### Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods (https://arxiv.org/abs/2409.17939)
Comments:
          AMTA 2024 - The Association for Machine Translation in the Americas organizes biennial conferences devoted to researchers, commercial users, governmental and NGO users

- **What's New**: 본 논문은 번역 메모리(Translation Memoires, TMs)와 컴퓨터 보조 번역(Computer-Aided Translation, CAT) 도구에서의 구문 정정 기법인 퍼지 매치 리페어(Fuzzy-Match Repair, FMR) 기술을 발전시키는 데 집중하고 있습니다. 특히, 기존의 기계 번역(Machine Translation, MT) 기법 대신 Word2Vec, BERT, 그리고 GPT-4와 같은 머신 러닝(machine learning) 기반 접근 방식을 사용하여 고정된 단어(anchor word) 번역의 정확성을 향상시킬 수 있는 방법을 제시합니다.

- **Technical Details**: 이 연구는 번역 시스템에서 고정된 단어의 번역을 개선하기 위해 네 가지 기술을 실험했습니다: (1) Neural Machine Translation(NMT), (2) BERT 기반 구현, (3) Word2Vec, (4) OpenAI GPT-4. 특히, 고정된 단어는 두 개의 단어 사이에 위치하며, 연속적인 단어의 가방(CBOW) 패러다임을 따른다고 설명합니다. 내재된 문맥(window) 내에서 각 단어에 가중치를 부여하여 주변 단어가 예측에 미치는 영향을 극대화할 수 있음을 강조하고 있습니다.

- **Performance Highlights**: 실험 결과, Word2Vec, BERT 및 GPT-4는 프랑스어에서 영어로의 번역에 있어 기존의 Neural Machine Translation 시스템보다 유사하거나 더 나은 성능을 보였습니다. 특히, 각 접근 방식이 고정된 단어 번역에서 성공적으로 작동하는 경우를 다루고 있습니다.



### Unveiling the Potential of Graph Neural Networks in SME Credit Risk Assessmen (https://arxiv.org/abs/2409.17909)
- **What's New**: 본 논문은 그래프 신경망 (Graph Neural Network)을 활용한 기업 신용 위험 평가 모델을 제안하며, 기업 재무 지표 간의 내재적 연결을 통합합니다.

- **Technical Details**: 29개의 기업 재무 데이터 지표를 선택하고 각 지표를 정점 (vertex)으로 추상화했습니다. 유사도 행렬 (similarity matrix)을 구성하고 최대 신장 트리 알고리즘 (maximum spanning tree algorithm)을 사용하여 기업의 그래프 구조 매핑을 수행했습니다. 매핑된 그래프의 표현 학습 단계에서 그래프 신경망 모델을 구축하여 32차원의 임베딩 표현을 얻었습니다. 세 가지 GraphSAGE 연산을 수행하고 Pool 연산을 통해 결과를 집계했습니다.

- **Performance Highlights**: 실제 기업 데이터에 대한 실험 결과, 제안된 모델은 다단계 신용 수준 추정 작업을 효과적으로 수행하며, ROC 및 기타 평가 기준에 따라 모델의 분류 효과가 중요하고 안정성 (robustness)도 뛰어나며, 다양한 지표 데이터 간의 내재적 연결을 심층적으로 표현합니다.



### Designing Short-Stage CDC-XPUFs: Balancing Reliability, Cost, and Security in IoT Devices (https://arxiv.org/abs/2409.17902)
- **What's New**: 이 논문은 IoT(Internet of Things) 시스템에서 보안을 강화하기 위한 새로운 접근 방법인 Component-Differentially Challenged XOR-PUFs(CDC-XPUFs)에 대해 설명합니다. 전통적인 PUFs가 머신러닝(ML) 및 신뢰성 기반 공격에 취약한 문제를 해결하기 위해, 이 연구에서는 예방 선택 전략을 도입하여 신뢰성을 향상시키고 경량 아키텍처를 통해 하드웨어 오버헤드를 줄이는 최적화된 CDC-XPUF 설계를 제안합니다.

- **Technical Details**: 신뢰성 기반 공격에 대한 취약성을 줄이기 위해 가장 안정적이고 일관된 Challenge-Response Pair(CRP)만을 양자화하여 PUF 응답의 신뢰성을 개선하는 예방 선택 메커니즘이 도입되었습니다. CDC-XPUF는 각 APUF 구성 요소에 독특한 챌린지를 할당하는 구조로 설계되었고, 이를 통해 하드웨어 복잡성과 전송 오버헤드를 줄였습니다. 이러한 설계는 높은 비선형성을 유지하여 ML 공격에 대한 저항력을 높였습니다.

- **Performance Highlights**: 실험 결과, CDC-XPUF는 자원 소모를 현저히 낮추며 ML 공격에 대해 강력한 저항성을 유지하고, 신뢰성을 향상시킨 것으로 나타났습니다. 이러한 성과는 자원이 제한된 IoT 시스템에 널리 배포될 가능성을 보여줍니다.



### Model-Free versus Model-Based Reinforcement Learning for Fixed-Wing UAV Attitude Control Under Varying Wind Conditions (https://arxiv.org/abs/2409.17896)
Comments:
          Published at ICINCO 2024

- **What's New**: 이 논문은 고정익 무인 비행기(fixed-wing unmanned aerial vehicle, FWUAV)의 자세(control) 제어를 위한 모델 프리(model-free)와 모델 기반(model-based) 강화 학습의 성능을 비교합니다. 특히, 다양한 비행 동역학과 바람 장애를 다루는 능력에 집중하고 있습니다.

- **Technical Details**: Temporal Difference Model Predictive Control(TD-MPC) 에이전트가 PID 제어기 및 기타 모델 프리 강화 학습 기법에 비해 추적 정확성과 강건성에서 우수함을 보였습니다. 두 가지 접근법으로 행동 변동 패널티(action variation penalty)와 행동 정책 부드러움을 위한 조건화(conditioning)를 평가합니다.

- **Performance Highlights**: TD-MPC는nominal wind conditions(기본 바람 조건)에서의 순수한 참조 추적에서 우수함을 보였으며, 리튬 배터리 사용 및 액츄에이터 소모를 측정하는 주요 지표로서 actuation fluctuation이 도입되었습니다.



### Implementing a Nordic-Baltic Federated Health Data Network: a case repor (https://arxiv.org/abs/2409.17865)
Comments:
          24 pages (including appendices), 1 figure

- **What's New**: 이 논문에서는 북유럽-발트해 지역에서 건강 데이터의 2차 사용을 촉진하기 위해 5개국 6개 기관으로 구성된 연합 건강 데이터 네트워크(federated health data network)를 개발하는 과정에서 얻은 초기 경험을 공유합니다.

- **Technical Details**: 이 연구는 혼합 방법(mixed-method approach)을 사용하여 실험 설계(experimental design)와 실행 과학(implementation science)을 결합하여 네트워크 구현에 영향을 미치는 요소를 평가했습니다. 실험 결과, 중앙 집중식 시뮬레이션(centralized simulation)과 비교할 때, 네트워크는 성능 저하(performance degradation) 없이 기능한다는 것을 발견했습니다.

- **Performance Highlights**: 다학제적 접근 방식(interdisciplinary approaches)을 활용하면 이러한 협력 네트워크(collaborative networks)를 구축하는 데 따른 도전 과제를 해결할 수 있는 잠재력이 있지만, 규제 환경이 불확실하고 상당한 운영 비용(operational costs)이 발생하는 것이 문제로 지적되었습니다.



### A Multimodal Single-Branch Embedding Network for Recommendation in Cold-Start and Missing Modality Scenarios (https://arxiv.org/abs/2409.17864)
Comments:
          Accepted at 18th ACM Conference on Recommender Systems (RecSys '24)

- **What's New**: 이 논문은 추천 시스템에서 콜드 스타트(cold-start) 문제를 해결하기 위한 새로운 방법으로, 멀티모달(single-branch) 임베딩 네트워크를 제안합니다. 이를 통해 다양한 모달리티에 기반한 추천 성능을 개선하고자 합니다.

- **Technical Details**: 제안된 방법은 SiBraR(Single-Branch embedding network for Recommendation)로 불리며, 여러 모달리티 데이터를 공유하는 단일 브랜치 네트워크를 통해 처리합니다. SiBraR는 상호작용 데이터와 여러 형태의 사이드 정보를 동일한 네트워크에서 인코딩하여 모달리티 간의 간극(modality gap)을 줄입니다.

- **Performance Highlights**: 대규모 추천 데이터셋에서 실시한 실험 결과, SiBraR는 콜드 스타트 과제에서 기존의 CF 알고리즘과 최신 콘텐츠 기반 추천 시스템(Content-Based Recommender Systems)보다 유의미하게 우수한 성능을 보였습니다.



### How Feature Learning Can Improve Neural Scaling Laws (https://arxiv.org/abs/2409.17858)
- **What's New**: 이번 연구에서는 kernel 한계를 넘어서는 solvable model을 개발하였습니다. 이 모델은 딥러닝 성능이 모델 크기, 훈련 시간 및 데이터 양에 따라 어떻게 변화하는지를 분석합니다. 딥러닝 모델의 작업 난이도에 따라 세 가지 scaling regime (hard, easy, super easy)을 구분하고, 특히 feature learning이 hard tasks에서 scaling law를 개선하는 방법을 보여줍니다.

- **Technical Details**: 제안된 모델은 두 개의 층을 가진 선형 신경망이고, projected gradient descent를 이용하여 훈련됩니다. 이 모델은 training time, model size, training set size에서의 power law scaling을 재현합니다. 성능 개선 조건은 source exponent (α, β)와 관련이 있으며, β < 1인 hard task에서 feature learning이 scaling law 개선에 기여합니다.

- **Performance Highlights**: 실험을 통해, nonlinear MLPs가 power-law Fourier 스펙트라를 기반으로 함수에 맞춰 훈련되는 과정에서 얻은 성능이 feature learning이 scaling law 개선에 기여함을 분명히 입증했습니다. 이러한 결과는 기존 연구들보다 더 빠른 훈련과 scaling law를 달성하는 데 유용하다는 것을 나타냅니다.



### AMARO: All Heavy-Atom Transferable Neural Network Potentials of Protein Thermodynamics (https://arxiv.org/abs/2409.17852)
- **What's New**: 본 연구에서는 Advanced Machine-learning Atomic Representation Omni-force-field (AMARO)라는 새로운 신경망 포텐셜을 도입하였습니다. 이는 O(3)-equivariant message-passing neural network 아키텍처인 TensorNet을 결합하여 방수소(AH) 원자를 제외한 코스-그래이딩 맵을 사용하여 훈련된 신경망 포텐셜(NNP)입니다. AMARO는 사전 에너지 항 없이 단순한 조정 기반의 NNP 훈련이 가능함을 보여줍니다.

- **Technical Details**: AMARO는 기존의 모든 원자 수준의 분자 동역학(MD) 시뮬레이션의 높은 계산 비용을 피하기 위해, 보다 적은 자유도를 가진 분자 시스템을 모델링하는 코스-그래이딩(CG) 방법을 사용합니다. O(3)-equivariant의 특성을 가진 TensorNet 신경망 구조를 통해, AMARO는 콜렉티브 좌표에 대한 자유 에너지 풍경을 설명하기 위해 many-body potential of mean force (PMF)를 사용합니다. 연구 결과, AMARO는 약 50%의 자유도 감소에도 불구하고 안정성 및 일반화 능력을 가지고 있습니다.

- **Performance Highlights**: AMARO는 기존의 CG-NNP 모델들과 비교했을 때 사전 에너지를 필요로 하지 않으면서도 안정성과 전이력을 유지할 수 있음을 입증하였습니다. 이는 다양한 단백질 시스템에서 효과적인 시뮬레이션을 위한 가능성을 열어주며, 생체 분자 상호작용의 보다 정교한 탐색을 지원할 것입니다.



### Physics-aligned Schr\"{o}dinger bridg (https://arxiv.org/abs/2409.17825)
- **What's New**: 본 논문에서는 물리적 제약 조건을 준수하면서 평면적 필드를 효과적으로 재구성할 수 있는 새로운 데이터 기반 프레임워크인 Physics-aligned Schrödinger Bridge (PalSB)를 소개합니다.

- **Technical Details**: PalSB는 두 단계로 구성된 훈련 과정을 활용하여 희소 측정값으로부터 지역적으로 고해상도 필드를 생성합니다. 첫 번째 단계에서는 diffusion Schrödinger bridge (DSB)를 사용하여 필드를 생성하고, 두 번째 단계에서는 물리학에 기반한 손실 함수를 통해 물리적 원칙에 부합하도록 모델을 정제합니다. 또한, 물리적 경계 조건 준수를 위해 경계 인식 샘플링 기법을 도입하였습니다.

- **Performance Highlights**: PalSB는 세 가지 복잡한 비선형 시스템에서 적용되어 기존 방법에 비해 더 높은 정확도를 달성하며 물리적 제약 조건 준수 성능 또한 향상되었습니다. 이를 통해 PalSB의 고급 재구성 기법 가능성을 입증하였습니다.



### Generative Modeling of Molecular Dynamics Trajectories (https://arxiv.org/abs/2409.17808)
Comments:
          NeurIPS 2024

- **What's New**: MDGen이라는 새로운 패러다임을 소개하여 분자역학(Molecular Dynamics, MD)의 시뮬레이션 경로를 직접 생성 모델링함으로써 다목적 서리겟 모델을 학습할 수 있습니다. 이를 통해 기존의 MD 방법으로는 다루기 어려운 다양한 다운스트림 작업을 수행할 수 있도록 합니다.

- **Technical Details**: MDGen은 분자 시스템의 초기 '프레임'(frame)을 제공받아 해당 시스템의 시간 진화를 샘플링할 수 있는 전방 시뮬레이션을 수행합니다. 또한, 두 개의 경로 끝점에서 프레임을 제공해 이들을 연결하는 가능한 경로(transition path sampling)를 샘플링할 수 있습니다. 이 외에도 주어진 맥락에 따라 줄기(upsampling)와 인페인팅(inpainting) 작업을 통해 분자 설계의 기초 단계를 시작할 수 있습니다.

- **Performance Highlights**: MDGen은 테트라펩타이드(tetrapeptide) 시뮬레이션에서 뛰어난 성능을 보여주며, 자유 에너지 표면(free energy surfaces)과 동적 내용을 정확하게 재현할 수 있습니다. 또한, MDGen을 사용한 분자 인페인팅은 기존의 정적 프레임 기반 방법보다 훨씬 높은 시퀀스 복구율을 달성하며, 단일 모델 샘플을 통해 10만 프레임의 경로를 캡처할 수 있는 가능성을 보여주었습니다.



### Enriched Functional Tree-Based Classifiers: A Novel Approach Leveraging Derivatives and Geometric Features (https://arxiv.org/abs/2409.17804)
- **What's New**: 이 연구는 Function Data Analysis (FDA)와 tree-based ensemble 기법을 통합하여 고차원 시계열 데이터의 지도 분류를 위한 새로운 접근 방식을 제안합니다. Enriched Functional Tree-Based Classifiers (EFTCs)라는 프레임워크는 도함수 및 기하학적 특징을 활용하여 예측 성능을 향상시키고 분산을 줄이는 데 중점을 둡니다.

- **Technical Details**: 제안된 EFTCs는 Functional Classification Trees (FCTs), Functional K-NN (FKNN), Functional Random Forest (FRF), Functional XGBoost (FXGB), Functional LightGBM (FLGBM) 등 다양한 기능 분류 모델에서 실행 가능하며, 이 연구는 7개의 실제 데이터 세트와 6개의 시뮬레이션 시나리오에서 광범위한 실험 평가를 진행했습니다.

- **Performance Highlights**: 연구 결과는 전통적인 접근 방식에 비해 많은 개선을 보여주며, 다양한 함수적 특성을 활용하는 방식이 특정 방법에서 성능을 현저히 향상시킨다는 것을 나타냅니다. 이는 FDA의 복잡한 고차원 학습 문제에 대한 응용에 대한 새로운 통찰을 제공합니다.



### Predicting the Stay Length of Patients in Hospitals using Convolutional Gated Recurrent Deep Learning Mod (https://arxiv.org/abs/2409.17786)
- **What's New**: 이 연구에서는 입원 환자의 병원 체류 기간(Length of Stay, LoS)을 예측하기 위한 강력한 하이브리드 딥 러닝 모델을 제안합니다. 이 모델은 다층 합성곱 신경망(Multi-layer Convolutional Neural Networks, CNNs), 게이트 순환 유닛(Gated Recurrent Units, GRU), 그리고 밀집 신경망(Dense Neural Networks, DNN)을 조합하여 전통적인 기계 학습(Machine Learning, ML) 및 딥 러닝(Deep Learning, DL) 방법보다 우수한 성능을 보입니다.

- **Technical Details**: 제안된 하이브리드 모델(CNN-GRU-DNN)은 병원 및 환자의 지리적 지표, 인구 통계학적 마커(예: 민족, 인종, 나이), 의료 특성(예: CCS 진단 코드, APR DRG 코드, 질병 중증도 지표) 등을 포함하여 여러 변수를 분석합니다. 10-fold 교차 검증(test)에서 평균 89%의 LoS 정확도로, LSTM, BiLSTM, GRU, CNN과 비교하여 각각 19%, 18.2%, 18.6%, 7% 더 높은 성과를 기록했습니다.

- **Performance Highlights**: 정확한 LoS 예측은 병원이 자원을 최적화하고 장기 체류와 관련된 비용을 절감하는 데 도움을 줍니다. 또한 병원 체류 관리에 대한 새로운 전략을 위한 길을 열며, 헬스케어 연구와 혁신의 발전을 촉진할 수 있는 가능성을 가지고 있습니다.



### Confidence intervals uncovered: Are we ready for real-world medical imaging AI? (https://arxiv.org/abs/2409.17763)
Comments:
          Paper accepted at MICCAI 2024 conference

- **What's New**: 이 논문은 의료 영상(segmentation) 분야에서 AI 성능 변동성을 평가되지 않는 문제를 다루고 있습니다. 2023년 MICCAI에서 발표된 논문 221편을 분석한 결과, 50% 이상의 논문이 성능 변동성을 평가하지 않고, 단 0.5%의 논문만이 신뢰 구간(confidence intervals, CIs)을 보고했습니다. 이는 기존 논문들이 임상 적용을 위한 충분한 근거를 제공하지 않음을 지적합니다.

- **Technical Details**: 연구에서는 segmentation 논문에서 보고되지 않은 표준 편차(standard deviation, SD)를 평균 Dice 유사도 계수(Dice similarity coefficient, DSC)의 2차 다항식 함수를 통해 근사할 수 있음을 보여줍니다. 이를 바탕으로 2023년 MICCAI segmentation 논문의 평균 DSC 주변에 95% CIs를 재구성하였고, 그 중간 CI 폭은 0.03으로 첫 번째와 두 번째 순위 방법 간의 중간 성능 격차보다 세 배 더 큽니다.

- **Performance Highlights**: 60% 이상의 논문에서 두 번째 순위 방법의 평균 성능이 첫 번째 순위 방법의 신뢰 구간 내에 포함되었으며, 이는 현재 보고된 성능이 실제 임상에서의 가능성을 충분히 뒷받침하지 않음을 의미합니다.



### Few-shot Pairwise Rank Prompting: An Effective Non-Parametric Retrieval Mod (https://arxiv.org/abs/2409.17745)
Comments:
          Accepted to EMNLP 2024

- **What's New**: 이번 연구에서는 기존의 감독 학습 방식의 복잡성을 줄이고, 대규모 언어 모델(LLM) 기반의 간단한 순위 모델을 제안하여 제로샷(zero-shot) 환경에서도 효과적인 성능 향상을 이끌어냈습니다.

- **Technical Details**: 제안된 방법은 쿼리와 문서 쌍을 기준으로 유사한 쿼리들의 선호 예시를 활용하여, 쿼리와 문서의 쌍에 대한 상대적 선호 순서를 예측합니다. 이는 대규모 언어 모델의 언어 처리 능력을 이용한 몇 샷(few-shot) 프롬프트를 통해 이루어집니다. 이를 통해 기존의 제로샷 모델보다 지속적으로 성능이 개선되었음을 보였습니다.

- **Performance Highlights**: 제안된 모델은 TREC DL과 BEIR 서브셋 벤치마크에서 제로샷 기준선보다 일관된 향상을 보였으며, 복잡한 훈련 파이프라인 없이 감독 모델과 유사한 성능을 달성했습니다. 또한, MS-MARCO의 예시 쿼리를 이용한 실험에서 TREC Covid과 SciFact 테스트 컬렉션에 대한 아웃 오브 도메인 일반화의 가능성을 보여주었습니다.



### Autoregressive Generation Strategies for Top-K Sequential Recommendations (https://arxiv.org/abs/2409.17730)
- **What's New**: 이 논문에서는 사용자의 미래 상호작용을 예측하는 Top-K 순차 추천(task)에서 생성적 transformer 기반 모델의 적용 가능성을 탐구합니다. 특히, 일반적으로 사용되는 오토회귀 생성 전략인 greedy decoding, beam search, temperature sampling을 비교하고, 새로운 Reciprocal Rank Aggregation(RRA) 및 Relevance Aggregation(RA) 전략을 제안합니다.

- **Technical Details**: 제안된 접근법은 GPT-2 모델을 사용하여 장기 예측을 수행하는 Top-K 추천 작업에 적용되었습니다. 새로운 multi-sequence 생성 및 집합 방법으로서, 여러 개의 시퀀스를 생성하고 이를 집계하여 최종 추천 목록을 만듭니다. 또한, 다음 항목 예측 작업을 위해 훈련된 모델에서 유용한 성능을 보여줍니다.

- **Performance Highlights**: 제안된 방식은 전통적인 Top-K 예측 방법과 단일 시퀀스 오토회귀 생성 전략에 비해 긴 시간 범위에서 성능을 향상시킵니다. 실험 결과, 제안된 생성 전략이 추천의 성능을 크게 향상시키고 오류 누적을 줄여주는 데 기여함을 보여줍니다.



### QuForge: A Library for Qudits Simulation (https://arxiv.org/abs/2409.17716)
Comments:
          18 pages, 7 figures

- **What's New**: 이 논문에서는 qudit(다차원 양자 비트) 기반의 양자 회로 시뮬레이션을 위한 Python 기반 라이브러리인 QuForge를 소개합니다. QuForge는 선택된 qudit 차원에 맞게 양자 알고리즘을 구현하는 데 필요한 양자 게이트를 제공합니다.

- **Technical Details**: QuForge는 차별화 가능한(differentiable) 프로그래밍 프레임워크 위에 구축되어 있으며, GPU 및 TPU와 같은 가속 장치에서 실행할 수 있도록 설계되었습니다. 이 라이브러리는 메모리 소모를 줄이는 희소(sparse) 연산을 지원하며, 차별화된 그래프로 양자 회로를 구성하여 양자 기계 학습 알고리즘의 구현을 용이하게 합니다.

- **Performance Highlights**: QuForge는 고성능의 희소 행렬 연산을 활용하여 대량의 qudit를 사용하는 시스템의 시뮬레이션에 필요한 계산 자원을 크게 줄입니다. 이는 기존의 밀집 행렬 연산(dense matrix operations)에 의존하는 방법들과 비교하여 스케일러블(scalable)한 효율성을 제공합니다.



### Efficient Pointwise-Pairwise Learning-to-Rank for News Recommendation (https://arxiv.org/abs/2409.17711)
- **What's New**: 이 논문에서는 사전 훈련된 언어 모델(PLM)을 기반으로 하는 뉴스 추천의 새로운 프레임워크를 제안합니다. 이 프레임워크는 점수 기반의 pointwise(포인트와이즈) 접근법과 쌍 비교(pairwise) 접근법을 통합하여 규모 문제를 해결합니다.

- **Technical Details**: 제안된 알고리즘인 GLIMPSE는 뉴스 추천을 위해 multi-task(다중 작업) 훈련을 수행합니다. GLIMPSE는 단일 텍스트 생성 작업으로 두 가지 목표(관련성 예측 및 선호도 예측)를 결합하여 최종 순위를 도출합니다. 이 과정에서 Right-To-Left (RTL) 패스를 통해 adjacently(인접하게) 비교를 수행합니다.

- **Performance Highlights**: 광범위한 실험을 통해 MIND와 Adressa 뉴스 추천 데이터셋에서 최신 방법들과 비교하여 성능이 향상된 것을 보여주었습니다.



### Transfer Learning in $\ell_1$ Regularized Regression: Hyperparameter Selection Strategy based on Sharp Asymptotic Analysis (https://arxiv.org/abs/2409.17704)
Comments:
          23 pages, 9 figures

- **What's New**: 이번 연구에서는 Transfer learning 기술을 통해 고차원 희소 회귀 문제에서 관련된 데이터 세트 간의 정보 전이를 극대화하는 새로운 방법론을 제시합니다. 특히, Trans-Lasso와 Pretraining Lasso의 하이퍼파라미터 선택이 알고리즘 성능에 미치는 영향을 체계적으로 분석하였습니다.

- **Technical Details**: 이 논문에서는 Replica method를 사용한 비대칭 분석을 통해 일반화 성능에 미치는 하이퍼파라미터의 선택이 미치는 영향을 탐구하였습니다. 알고리즘은 두 단계로 작동하며, 첫 번째 단계에서는 여러 관련 데이터 세트에서 공통 특징을 찾고, 두 번째 단계에서는 특정 대상 데이터 세트에 대해 모델을 미세 조정하는 과정을 포함합니다. 이 과정에서 필요없는 정보는 무시할 수 있어 하이퍼파라미터 선택의 노력을 줄일 수 있음을 발견하였습니다.

- **Performance Highlights**: 실제 애플리케이션에서 IMDb 데이터 세트를 사용하여 알고리즘의 성능을 검증하였으며, 결과적으로 알고리즘의 단순성과 효율성을 입증하였습니다. 하이퍼파라미터의 적절한 선택이 모델 성능에 중요한 영향을 미치지만, 경량화된 선택 전략을 통해 그 과정이 단순화될 수 있음을 확인하였습니다.



### MoJE: Mixture of Jailbreak Experts, Naive Tabular Classifiers as Guard for Prompt Attacks (https://arxiv.org/abs/2409.17699)
- **What's New**: 이 논문은 Large Language Models (LLMs)의 보안을 강화하기 위한 새로운 방어 메커니즘인 MoJE (Mixture of Jailbreak Expert)를 제안합니다. 기존의 guardrails 방법들이 갖는 한계를 극복하고, 탈옥(jailbreak) 공격 탐지의 정확도와 효율성을 동시에 향상시키는 구조입니다.

- **Technical Details**: MoJE는 간단한 언어 통계 기법을 활용하여, 다양한 토큰화(tokenization) 전략이나 n-그램(n-gram) 특징 추출을 통해 탈옥 공격을 탐지하고 필터링합니다. 이 구조는 기존의 state-of-the-art guardrails에 비해 공격 탐지 정확도, 대기 시간(latency), 처리량(throughput) 면에서 우수한 성능을 보입니다. 또한, 모듈러 특성 덕분에 새로운 공격에 대한 방어 모델이나 OOD(out-of-distribution) 데이터셋을 포함하도록 쉽게 확장 가능합니다.

- **Performance Highlights**: MoJE는 여러 데이터셋에서 유해 내용 탐지에서 기존의 ProtectAI 및 Llama-Guard와 같은 최첨단 솔루션을 초월하며, 탈옥 공격에 대한 저항력이 뛰어납니다. 특히, 90%의 탈옥 공격을 탐지하면서도 정상 프롬프트(benign prompts)에 대한 정확도를 유지하여 LLMs의 보안을 크게 강화합니다.



### MIO: A Foundation Model on Multimodal Tokens (https://arxiv.org/abs/2409.17692)
Comments:
          Technical Report. Codes and models will be available soon

- **What's New**: MIO라는 새로운 기초 모델이 등장했습니다. 이는 음성, 텍스트, 이미지 및 비디오를 이해하고 생성할 수 있는 멀티모달 토큰 기반의 모델로서, end-to-end 및 autoregressive 방식으로 작동합니다. MIO는 기존의 모델들이 갖고 있지 않았던 all-to-all 방식으로의 이해와 생성을 지원하며, 기존의 비공식 모델들(GPT-4o 등)을 대체할 수 있습니다.

- **Technical Details**: MIO는 causal multimodal modeling에 기반해 4단계의 훈련 과정을 거칩니다: (1) alignment pre-training, (2) interleaved pre-training, (3) speech-enhanced pre-training, (4) 다양한 텍스트, 비주얼, 음성 작업에 대한 포괄적인 감독 하에 fine-tuning을 수행합니다. MIO는 discrete multimodal tokens을 사용하여 학습되며, 이는 대조 손실(contrastive loss)과 재구성 손실(reconstruction loss) 기법을 통해 semantical representation과 low-level features를 포착합니다.

- **Performance Highlights**: MIO는 이전의 dual-modal 및 any-to-any 모델들, 심지어 modality-specific baselines와 비교해서 경쟁력 있는 성능을 보이며, interleaved video-text generation, 시각적 사고의 연쇄(chain-of-visual-thought reasoning), 시각적 가이드라인 생성, 이미지 편집 기능 등 고급 기능을 구현합니다.



### Artificial Data Point Generation in Clustered Latent Space for Small Medical Datasets (https://arxiv.org/abs/2409.17685)
Comments:
          8 pages, 2 figures

- **What's New**: 이 연구는 작은 의료 데이터셋에서 분류 성능을 향상시키기 위한 합성 데이터 생성 방법인 AGCL(Artificial Data Point Generation in Clustered Latent Space)를 소개합니다. AGCL은 K-평균 클러스터링을 기반으로 하여 클래스 표현이 뚜렷한 클러스터에서 합성 데이터 포인트를 생성하는 방식으로 작동합니다.

- **Technical Details**: AGCL 프레임워크는 특징 추출, K-평균 클러스터링, 클래스 분리를 위한 클러스터 평가 및 각 클러스터의 매개변수를 기반으로 정규 분포에서 합성 데이터 포인트를 생성하는 과정을 포함합니다. 이 방법은 파킨슨병 스크리닝을 위한 얼굴 표정 데이터에 적용되어 여러 머신러닝 분류기에서 평가되었습니다.

- **Performance Highlights**: AGCL은 기본선(GN) 및 kNNMTD와 비교하여 분류 정확도를 유의미하게 향상시켰으며, 서로 다른 감정에 대한 다수결 방식의 교차 검증에서 90.90%의 정확도를 기록했습니다. AGCL은 궁극적으로 83.33%의 테스트 정확도를 달성하며, 작은 데이터셋 증대에 효과적임을 입증했습니다.



### Explanation Bottleneck Models (https://arxiv.org/abs/2409.17663)
Comments:
          13 pages, 4 figures

- **What's New**: 이 논문은 사전 정의된 개념 세트에 의존하지 않고 입력에서 텍스트 설명을 생성할 수 있는 새로운 해석 가능한 심층 신경망 모델인 설명 병목 모델(XBMs)을 제안합니다.

- **Technical Details**: XBMs는 입력 데이터에서 텍스트 설명을 생성하고, 이를 기반으로 최종 작업 예측을 수행하는 모델입니다. XBMs는 사전 학습된 비전-언어 인코더-디코더 모델을 활용하여 입력 데이터에 나타난 개념을 포착합니다. 훈련 과정 중 '설명 증류(explanation distillation)' 기술을 사용하여 분류기의 성능과 텍스트 설명의 품질을 모두 확보합니다.

- **Performance Highlights**: 실험 결과, XBMs는 기존의 개념 병목 모델(CBMs)과 비교하여 더욱 유의미하고 자연스러운 언어 설명을 제공하며, 블랙박스 기준선 모델에 필적하는 성능을 달성하고 있습니다. 특히, XBMs는 테스트 정확도에서 CBMs을 크게 초월합니다.



### Efficient Fairness-Performance Pareto Front Computation (https://arxiv.org/abs/2409.17643)
- **What's New**: 이 논문은 공정한 표현(fair representation)과 분류기의 성능(performance) 사이의 트레이드오프(trade-off)를 다룹니다. 고차원 매개변수 공간을 가진 복잡한 모델을 훈련시키지 않고도 최적의 Pareto Front를 계산하는 새로운 방법을 제안합니다.

- **Technical Details**: 논문에서는 민감한 속성(sensitive attribute)과 데이터 특성(data features)을 고려하여 representation의 구조적 속성을 분석합니다. 이를 통해 Pareto Front의 계산 문제를 소규모 이산 최적화 문제로 축소할 수 있음을 보입니다. 제안된 MIFPO(Minimum Fairness-Pareto Optimization) 문제는 볼록-비볼록 최적화(concave-convex programming) 기법을 통해 해결됩니다.

- **Performance Highlights**: 실험적으로 여러 실제 벤치마크 데이터셋을 사용하여 제안한 방법의 성능을 비교 평가하였으며, 그 결과 기존의 복잡한 모델 없이도 효과적으로 공정한 표현을 찾을 수 있음을 시사합니다.



### FlowMAC: Conditional Flow Matching for Audio Coding at Low Bit Rates (https://arxiv.org/abs/2409.17635)
Comments:
          Submitted to ICASSP 2025

- **What's New**: 본 논문은 FlowMAC을 소개합니다. 이는 조건부 흐름 매칭(Conditional Flow Matching, CFM) 기반의 혁신적인 신경 오디오 코덱으로, 낮은 비트 전송률에서 고품질 일반 오디오 압축을 가능하게 합니다.

- **Technical Details**: FlowMAC은 멜 스펙트로그램 인코더, 양자화기(Quantizer), 디코더를 공동 학습합니다. 추론(Inference) 시, 디코더는 ODE 솔버를 이용해 연속 정규화 흐름(Continuous Normalizing Flow)을 통합하여 고품질 멜 스펙트로그램을 생성합니다. 이 접근법은 간단한 손실 함수와 CFM 목표를 통해 멜 스펙트로그램을 압축합니다.

- **Performance Highlights**: 3 kbps에서 FlowMAC은 현재 가장 발전된 GAN 기반 및 DDPM 기반 신경 오디오 코덱과 유사한 품질을 달성합니다. 더불어, FlowMAC은 복잡성과 품질 간의 균형을 조정할 수 있는 조정 가능한 추론 파이프라인을 제공하여 CPU에서 실시간 코딩이 가능합니다.



### Good Data Is All Imitation Learning Needs (https://arxiv.org/abs/2409.17605)
- **What's New**: 이 논문에서는 Autonomous/Automated Driving Systems (ADS)에서 기존의 teacher-student 모델, imitation learning, behavior cloning의 한계를 극복하기 위해 Counterfactual Explanations (CFEs)를 새로운 데이터 증강 기법으로 도입하였습니다.

- **Technical Details**: CFEs는 최소한의 입력 수정으로 결정 경계 근처에 있는 학습 샘플을 생성하여 수집된 데이터에 희귀한 사건을 포함시킴으로써 전문가 운전자의 전략을 더 포괄적으로 표현할 수 있게 해줍니다. 이 논문은 CARLA 시뮬레이터에서 CF-Driver를 통해 실험하며 SOTA 수준의 성과를 입증하였습니다.

- **Performance Highlights**: CF-Driver는 드라이빙 점수 84.2를 기록하며 이전 최고 모델보다 15.02% 향상된 성과를 달성하며, CFEs를 통해 드라이빙 전략의 개선을 보여줍니다. 또한, 연구 개발을 위해 생성된 데이터셋은 공개하여 후속 연구를 촉진할 계획입니다.



### Conjugate Bayesian Two-step Change Point Detection for Hawkes Process (https://arxiv.org/abs/2409.17591)
Comments:
          10 pages, accepted by NeurIPS 2024

- **What's New**: 본 연구에서는 Hawkes 과정에 대한 경량 Bayesian 두 단계 변화점 탐지 방법을 제안합니다. 이 방법은 데이터 증강(data augmentation)을 통해 비공식적인 우선분포(non-conjugate prior) 문제를 해결하고, 더 정확하고 효율적인 탐지를 가능하게 합니다.

- **Technical Details**: Hawkes 과정은 시간에 발생하는 일련의 이산 이벤트를 모델링하는 데 사용됩니다. 본 연구에서 제안하는 CoBay-CPD는 비공식적인 포인트 프로세스 가능성과 우선분포 간의 비공식성으로 발생하는 문제를 해결하기 위해 보조 잠재 변수(auxiliary latent variables)를 활용하여 조건부 공식을 이루도록 하였습니다. 이 방법론은 Gibbs 샘플링을 통해 수치적 추론을 간소화합니다.

- **Performance Highlights**: 실험 결과, CoBay-CPD는 기존의 기준 모델에 비해 변화점 탐지의 정확성과 신속성을 모두 향상시켰습니다. 특히 한정된 데이터에서 보다 효과적으로 변화점을 감지할 수 있는 능력을 입증하였으며, 다양한 동적 이벤트 모델링 시나리오에서 실제 적용 가능성을 강조하였습니다.



### Let the Quantum Creep In: Designing Quantum Neural Network Models by Gradually Swapping Out Classical Components (https://arxiv.org/abs/2409.17583)
Comments:
          50 pages (including Appendix), many figures, accepted as a poster on QTML2024. Code available at this https URL

- **What's New**: 이 논문에서는 양자 신경망(Quantum Neural Network, QNN)의 구조적 한계를 극복하기 위해 고전적 신경망과 양자 신경망 사이의 점진적인 전환 전략, HybridNet을 제안합니다. 이는 정보 흐름을 유지하면서 고전적 신경망 레이어를 점진적으로 양자 레이어로 대체하는 프레임워크를 제공합니다.

- **Technical Details**: 제안된 HybridNet은 고전적 모델에서 양자 모델로의 전환을 통해 양자 구성이 신경망의 성능에 미치는 영향을 보다 면밀히 분석합니다. 연구에서는 FlippedQuanv3x3라는 새로운 양자 커널과 데이터 재업로드 회로(Data Reuploading Circuit)를 도입하여 고전적 선형 레이어와 동일한 입력 및 출력을 공유하는 양자 레이어를 구현합니다.

- **Performance Highlights**: MNIST, FashionMNIST, CIFAR-10 데이터셋에 대한 수치 실험을 통해 양자 구성요소의 체계적인 도입이 성능 변화에 미치는 영향을 분석했습니다. 연구 결과, 기존의 QNN 모델보다 더 효과적인 성능을 발휘할 수 있음을 발견하였습니다.



### Pixel-Space Post-Training of Latent Diffusion Models (https://arxiv.org/abs/2409.17565)
- **What's New**: 이번 논문에서는 Latent Diffusion Models (LDMs)의 한계를 극복하기 위한 새로운 접근 방법을 제안합니다. LDMs는 이미지 생성 분야에서 큰 발전을 이루었지만, 고주파 세부 사항과 복잡한 구성 생성에서 여전히 어려움이 있음을 지적합니다.

- **Technical Details**: LDMs가 고주파 세부 사항을 잘 생성하지 못하는 이유는 기존 학습이 보통 $8 	imes 8$의 낮은 공간 해상도에서 이뤄지기 때문이라고 가설합니다. 이를 해결하기 위해 포스트 트레이닝 과정에서 pixel-space supervision을 추가하는 방법을 제안하였습니다.

- **Performance Highlights**: 실험 결과, pixel-space objective를 추가함으로써 최첨단 DiT transformer와 U-Net diffusion 모델의 supervised quality fine-tuning 및 preference-based post-training에서 시각적 품질 및 결함 지표가 크게 향상되었으며, 동일한 텍스트 정렬 품질을 유지했습니다.



### Joint Source-Channel Coding: Fundamentals and Recent Progress in Practical Designs (https://arxiv.org/abs/2409.17557)
Comments:
          Under review for possible publication

- **What's New**: 이 논문은 다음 세대 모바일 네트워크의 지연(latency) 및 대역폭(bandwidth) 요구사항을 줄이기 위해 의미 기반 및 작업 지향 통신(semantic- and task-oriented communication) 방법론을 제안합니다. 특히 DeepJSCC(deep joint source-channel coding)의 통합을 통해 최근에 부각된 JSCC의 장점들을 강조하고 있습니다.

- **Technical Details**: JSCC는 압축(compression)과 채널 코딩(channel coding)을 최적화하여 상호작용할 수 있는 방식으로 설계된 통신 시스템입니다. 또한 JSCC는 전통적인 분리 방식(SSCC)과 비교할 때 유한한 블록 길이(finite blocklength) 및 변동하는 채널 시간(timely-varying channels) 시나리오에서 높은 성능을 보여줍니다.

- **Performance Highlights**: DeepJSCC는 다양한 소스 모달리티(source modalities)와 데이터셋에 맞춰 설계 가능하여 경쟁력 있는 성능을 제공합니다. 이 논문은 특히 자율 주행, 드론 감시, 웨어러블 시스템과 같은 중요 응용 분야에 대한 고신뢰성(low-latency) 통신을 가능하게 하는 새로운 접근이 필요하다고 강조합니다.



### MASSFormer: Mobility-Aware Spectrum Sensing using Transformer-Driven Tiered Structur (https://arxiv.org/abs/2409.17546)
- **What's New**: 본 논문에서는 사용자 이동성을 효과적으로 모델링하는 새로운 이동 인식 기반의 트랜스포머 구조(MASSFormer)를 제안하여 협력 스펙트럼 감지(cooperative spectrum sensing) 방법을 개발하였습니다. 기존의 방법들과 달리, 모바일 주 사용자가 존재하는 동적인 시나리오를 고려하여 사용자 이동성으로 인해 발생하는 복잡성을 해결하였습니다.

- **Technical Details**: MASSFormer 방법은 SU-transformer 네트워크를 사용하여 각 사용자의 스펙트럼 데이터로부터 spatio-temporal features를 학습합니다. 이후, 협력 트랜스포머 네트워크가 모든 사용자의 특성을 기반으로 그룹 수준의 PU 상태를 예측합니다. 또한, attention 메커니즘을 통해 입력 데이터의 장기 종속성을 효과적으로 캡처하여 사용자 이동성을 기반으로 한 정확한 예측을 가능하게 합니다. 이 연구는 무선 환경에서의 경로 손실(path loss)과 채널 페이딩(channel fading) 문제를 해결합니다.

- **Performance Highlights**: 제안된 MASSFormer 방법은 기존의 스펙트럼 감지 방법들과 비교하여 감지 확률(detection probability), 감지 오류(sensing error), 분류 정확도(classification accuracy) 측면에서 우수한 성능을 입증하였습니다. 시뮬레이션 결과는 본 방법의 강건성(robustness) 또한 보여줍니다.



### Modulated Intervention Preference Optimization (MIPO): Keep the Easy, Refine the Difficu (https://arxiv.org/abs/2409.17545)
Comments:
          8pages, submitted to AAAI 2025

- **What's New**: 이번 연구에서는 Modulated Intervention Preference Optimization (MIPO)라는 새로운 방법론을 제안합니다. MIPO는 주어진 데이터와 참조 모델의 정렬 상태에 따라 개입(intervention) 정도를 조절하여 모델 일치를 최적화합니다.

- **Technical Details**: MIPO는 참조 모델이 잘 정렬된 경우, 정책 모델이 참조 모델과 크게 이탈하지 않도록 개입을 증가시키고, 반대로 정렬이 좋지 않은 경우 개입을 줄여 보다 광범위한 학습을 가능하게 합니다. 이 연구에서는 Mistral-7B와 Llama3-8B 모델을 활용하여 MIPO와 DPO의 성능을 비교합니다.

- **Performance Highlights**: 실험 결과, MIPO는 다양한 평가 시나리오에서 DPO에 비해 일관되게 우수한 성능을 보였습니다.



### Optimizing the Induced Correlation in Omnibus Joint Graph Embeddings (https://arxiv.org/abs/2409.17544)
Comments:
          34 pages, 8 figures

- **What's New**: 이 논문은 Omnibus joint graph embedding (OMNI) 프레임워크의 자동화를 위한 최초의 노력을 제시하고 있으며, 두 가지 주요 문제인 correlation-to-OMNI 문제와 flat correlation 문제를 다룹니다.

- **Technical Details**: Omnibus embedding은 여러 네트워크를 동시에 저차원 유클리드 공간으로 임베딩하는 방법론으로, OMNI 행렬을 구성한 후 Adjacency Spectral Embedding을 사용하여 임베딩합니다. 새로 제안된 corr2Omni 알고리즘은 주어진 그래프 쌍의 상관관계 매트릭스에서 일반화된 Omnibus 가중치를 추정합니다.

- **Performance Highlights**: 시뮬레이션 및 실제 데이터 설정에서 corr2Omni 알고리즘의 효과가 기존 전통적인 Omnibus 구조보다 향상된 것을 보여줍니다.



### Functional Classification of Spiking Signal Data Using Artificial Intelligence Techniques: A Review (https://arxiv.org/abs/2409.17516)
Comments:
          8 figures, 32 pages

- **What's New**: 이번 논문은 인지과학 및 컴퓨터 과학 간의 교차점을 강조하며, 신경 세포 행동의 분석에서 spike의 중요성을 다룹니다. 특히 인공지능(AI)의 도움을 받아 spike를 효과적으로 분류하는 방법에 대한 최근의 연구 결과를 검토합니다.

- **Technical Details**: 본 논문에서는 spike classification(스파이크 분류)의 전처리(preprocessing), 분류(classification), 평가(evaluation) 세 가지 주요 구성 요소를 중심으로 AI의 역할을 탐구합니다. 전통적인 수작업(spike classification)과 비교하여 머신러닝(machine learning) 및 딥러닝(deep learning) 접근법을 통한 신호 데이터의 자동화된 처리의 중요성을 설명합니다.

- **Performance Highlights**: 현재까지의 연구들은 AI를 활용한 스파이크 분류의 정확성을 높일 수 있는 잠재력을 보여줍니다. 효율적인 알고리즘의 필요성도 강조하며, 향후 연구에서 더욱 발전된 방법론과 문제 해결을 위한 방향을 제시합니다.



### Comparing Unidirectional, Bidirectional, and Word2vec Models for Discovering Vulnerabilities in Compiled Lifted Cod (https://arxiv.org/abs/2409.17513)
Comments:
          6 pages, 2 figures

- **What's New**: 이 연구는 LLVM 코드에서 GPT 모델을 처음부터 훈련하여 생성된 임베딩을 사용해 특정 취약성(예: buffer overflows)을 찾는 결과를 제공합니다. 또한 단방향 변환기(GPT-2)와 양방향 변환기(BERT, RoBERTa) 및 비변환기 기반 임베딩 모델(Skip-Gram, Continuous Bag of Words)의 영향을 비교하고 있습니다.

- **Technical Details**: 연구는 먼저 NIST SARD Juliet 데이터 세트에서 코드 샘플을 선택한 후, RetDec 도구를 사용하여 LLVM으로 변환한 다음 사전 처리를 진행하였습니다. 이후 CWE-121 샘플을 사용하여 GPT-2 모델의 임베딩을 생성하고, 이러한 임베딩을 LSTM 신경망 훈련에 사용하였습니다.

- **Performance Highlights**: GPT-2로부터 생성된 임베딩은 BERT 및 RoBERTa의 양방향 모델보다 뛰어난 성능을 보여주었으며, 92.5%의 정확도와 89.7%의 F1 점수를 기록했습니다. 또한 SGD 옵티마이저가 Adam보다 우수한 성능을 나타냈습니다.



### NeuroPath: A Neural Pathway Transformer for Joining the Dots of Human Connectomes (https://arxiv.org/abs/2409.17510)
Comments:
          Accepted by NeurIPS 2024

- **What's New**: 이 논문은 신경 이미지 데이터에서 구조적 연결성(Structural Connectivity, SC)과 기능적 연결성(Functional Connectivity, FC) 간의 결합 메커니즘에 대한 연구를 소개합니다. 특히 'NeuroPath'라는 새로운 생물학적 영감을 받은 딥 모델을 제안하여, SC와 FC의 쌍으로부터 복잡한 신경 구조의 특징 표현을 발견하고 인지 행동의 예측 및 질병 진단에 활용할 수 있습니다.

- **Technical Details**: NeuroPath 모델은 고차원 토폴로지의 표현 학습 문제로 구성된 SC-FC 결합 메커니즘을 다루며, 다중 헤드 자기 주의(multi-head self-attention) 메커니즘을 사용하여 SC와 FC의 쌍 그래프에서 다중 모달 특징 표현을 캡처합니다. 이를 통해 우리는 SC의 다양한 경로들이 FC를 지원하는 방식(예: cyclic loop)을 이해할 수 있게 됩니다.

- **Performance Highlights**: NeuroPath 지표는 HCP(인간 연결체 프로젝트) 및 UK Biobank와 같은 대규모 공개 데이터셋에서 검증되었으며, 기존의 최첨단 성능을 초과하여 인지 상태 예측과 질병 위험 진단에서 뛰어난 잠재력을 보였습니다.



### Uni-Med: A Unified Medical Generalist Foundation Model For Multi-Task Learning Via Connector-MoE (https://arxiv.org/abs/2409.17508)
- **What's New**: 이 논문은 다양한 시각 및 언어 작업을 위한 일반-purpose 인터페이스로서, 의료 분야의 multi-task learning을 위한 통합된 Multi-modal large language model (MLLM)을 제안합니다. 특히, 이전의 연구들이 처리하지 않았던 connector 문제를 해결하고자 합니다. 향후 Uni-Med는 의학 분야에서의 새로운 시도를 이루어낼 것입니다.

- **Technical Details**: Uni-Med는 범용 시각 feature extraction 모듈, connector mixture-of-experts (CMoE) 모듈, 그리고 LLM으로 구성된 의료 전문 기초 모델입니다. CMoE는 잘 설계된 라우터를 활용하여 projection experts의 혼합을 통해 connector에서 발생하는 문제를 해결합니다. 이 접근 방식을 통해 6개의 의료 관련 작업을 수행할 수 있습니다: 질문 응답(question answering), 시각 질문 응답(visual question answering), 보고서 생성(report generation), 지칭 표현 이해(referring expression comprehension), 지칭 표현 생성(referring expression generation) 및 이미지 분류(image classification).

- **Performance Highlights**: Uni-Med는 connector에서의 multi-task 간섭을 해결하려는 첫 번째 노력으로, 다양한 구성에서 CMoE를 도입하여 평균 8%의 성능 향상을 validates합니다. 이전의 최신 의료 MLLM과 비교할 때, Uni-Med는 다양한 작업에서 경쟁력 있거나 더 우수한 평가 지표를 달성하였습니다.



### Sequential Kernelized Stein Discrepancy (https://arxiv.org/abs/2409.17505)
- **What's New**: 본 연구에서는 kernelized Stein discrepancy의 순차적 버전을 제안하여, 계속 모니터링되고 적응적으로 중단될 수 있는 비정규 밀도에 대한 적합성 검정을 수행할 수 있도록 합니다. 이 새로운 접근법은 고정된 샘플 크기가 필요 없으며, 데이터 수집 중에 언제든지 검정을 중단할 수 있는 유연성을 제공합니다.

- **Technical Details**: 우리는 Stein kernel에 대한 균일한 경계 조건을 부과하지 않고, 임의의 점 평가에서 Stein kernel의 잠재적 경계를 활용합니다. 이로부터 test martingales를 정의하여 새로운 순차적 테스트에 기여합니다. 이 연구는 level-α 순차적 적합성 검정을 개발하여, 비정규 밀도에 대응합니다. 이러한 검정에서는 null 가설이 쉽게 기각될 수 있습니다.

- **Performance Highlights**: 우리는 다양한 분포에 대해 검정의 실증적 성능을 보여주며, 제약된 Boltzmann 머신과 같은 특정 샘플 품질을 평가하는 데 유용성을 강조합니다. 이러한 anytime-valid 검정은 자원 낭비를 방지하고, 복잡한 문제에 대한 충분한 증거를 확보하는 데 이점을 제공합니다.



### MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models (https://arxiv.org/abs/2409.17481)
Comments:
          NeurIPS 2024 Spotlight

- **What's New**: 이번 연구는 MaskLLM이라는 새로운 learnable pruning (학습 가능한 가지치기) 방법을 제안합니다. 이 방법은 LLM (대규모 언어 모델)의 Semi-structured (반구조적) sparsity (희소성)을 통해 추론 시 계산 비용을 줄이는 데 초점을 맞추고 있습니다.

- **Technical Details**: MaskLLM은 Gumbel Softmax sampling (검벨 소프트맥스 샘플링)을 활용하여 N:M 패턴을 학습 가능한 분포로 모델링합니다. 이 방법은 N개의 비제로 값과 M개의 매개변수 사이의 관계를 설정하여 대규모 데이터 집합에서 end-to-end training (엔드투엔드 훈련)을 수행할 수 있게 합니다.

- **Performance Highlights**: MaskLLM은 LLaMA-2, Nemotron-4, GPT-3와 같은 여러 LLM을 사용하여 2:4 sparsity 설정 하에 평가되었습니다. 기존의 최첨단 방법에 비해 PPL (perplexity) 측정에서 유의미한 개선을 보였으며, 특히 SparseGPT의 10.42에 비해 MaskLLM은 6.72의 PPL을 달성하였습니다. 이 결과는 MaskLLM이 대규모 모델에서도 효과적으로 고품질 마스크를 학습할 수 있음을 나타냅니다.



### Reducing and Exploiting Data Augmentation Noise through Meta Reweighting Contrastive Learning for Text Classification (https://arxiv.org/abs/2409.17474)
Comments:
          IEEE BigData 2021

- **What's New**: 이 논문은 Meta Reweighting Contrastive (MRCo) 모델을 제안하여 데이터 증강(sample)의 품질을 고려하여 기존의 딥러닝 모델의 성능을 향상시키고자 합니다. 이 프레임워크는 메타 학습(meta learning)과 대조 학습(contrastive learning)을 결합하여 증강된 샘플의 가중치 정보를 활용합니다.

- **Technical Details**: MRCo 모델은 두 가지 최적화 루프를 가지며, 내부 루프는 다운스트림 작업을 위한 주 모듈이 재가중된 손실(loss)로 학습합니다. 외부 루프는 메타 재가중화 모듈이 증강 샘플에 적절한 가중치를 할당합니다. 대조 학습을 이용해 저품질 샘플과 고품질 샘플 간의 차이를 증대시키고 있다.

- **Performance Highlights**: 실험 결과, 본 프레임워크는 Text-CNN 인코더에서 평균 1.6%, 최대 4.3%의 개선율을 보였고, RoBERTa-base 인코더에서는 평균 1.4%, 최대 4.4%의 개선을 기록했습니다. 이는 7개의 GLUE 벤치마크 데이터셋을 기준으로 하였습니다.



### Adjusting Regression Models for Conditional Uncertainty Calibration (https://arxiv.org/abs/2409.17466)
Comments:
          Machine Learning Special Issue on Uncertainty Quantification

- **What's New**: 이 논문에서는 분할(conformal prediction) 일치 결과의 조건부 커버리지(conditional coverage)를 개선하기 위한 새로운 회귀(Regression) 알고리즘을 제안합니다. 기존의 방법들이 조건부 커버리지 보장을 제공하지 못하는 문제를 해결하고자 조건부 커버리지와 명목(marginal) 커버리지 사이의 미커버리지(miscoverage) 갭을 제어하는 세부 목표를 설정했습니다.

- **Technical Details**: 제안된 알고리즘은 기본적으로 분할(conformal prediction) 절차를 적용한 후의 회귀 함수 최적화를 통해 조건부 커버리지를 향상시키고, Kolmogorov-Smirnov 거리와의 연결고리를 구축합니다. 구체적으로는 미커버리지 갭에 대한 상한을 설정하고, 이를 제어하기 위한 끝에서 끝(end-to-end) 알고리즘을 제안합니다.

- **Performance Highlights**: 이 방법론은 합성 데이터(synthetic datasets) 및 실제 데이터(real-world datasets)에서 실험적으로 유효성을 입증했으며, 기존의 방법들과 비교했을 때 조건부 커버리지의 개선 효과를 확인할 수 있었습니다.



### RED QUEEN: Safeguarding Large Language Models against Concealed Multi-Turn Jailbreaking (https://arxiv.org/abs/2409.17458)
- **What's New**: 이 논문에서는 새로운 jailbreak 공격 방법인 Red Queen Attack을 제안합니다. 이 방법은 다단계(멀티턴) 시나리오를 활용하여 악의적인 의도를 숨기고, 14가지 유해 카테고리에서 56,000개의 멀티턴 공격 데이터를 생성합니다.

- **Technical Details**: Red Queen Attack은 다양한 직업과 관계에 기반하여 40개의 시나리오를 구성하며, GPT-4o, Llama3-70B 등 4개의 대표적인 LLM 가족에 대해 87.62% 및 75.4%의 높은 성공률을 기록했습니다. Red Queen Guard라는 완화 전략도 제안하여, 공격 성공률을 1% 미만으로 줄입니다.

- **Performance Highlights**: 모든 LLM이 Red Queen Attack에 취약하며, 대형 모델일수록 공격에 더 민감하다는 사실이 발견되었습니다. 이 연구는 56k 멀티턴 공격 데이터셋과 함께 LLM의 안전성을 높이는 방법을 제시합니다.



### Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models (https://arxiv.org/abs/2409.17455)
- **What's New**: 본 연구에서는 언어 모델(당초 LMs)에서 무시되었던 복잡한 대체 요인들이 모델의 신뢰성에 미치는 영향을 분석합니다. 저자들은 다각적으로 단축키(shortcut)를 정의하고 이를 발생, 스타일, 개념으로 분류하여 연구합니다.

- **Technical Details**: 연구에서는 BERT, Llama, SOTA 강인한 모델 등의 다양한 언어 모델에 대해 대체 요인에 대한 저항력과 취약성을 체계적으로 분석합니다. 그 결과, BERT는 모든 유형의 대체 요인에 취약하다는 것을 발견했습니다.

- **Performance Highlights**: 대형 모델의 크기 증가가 항상 Robustness를 보장하지 않으며, 강인한 모델들이 때때로 LLM보다 더 우수한 강인성을 나타냅니다. 모든 모델이 모든 유형의 대체 요인에 대해 강인하지 않다는 것이 드러났습니다.



### Description-based Controllable Text-to-Speech with Cross-Lingual Voice Contro (https://arxiv.org/abs/2409.17452)
Comments:
          Submitted to ICASSP 2025

- **What's New**: 이번 연구에서는 음성 생성을 위한 새로운 설명 기반의 제어 가능한 TTS 방법을 제안합니다. 이 방법은 교차 언어 제어 기능을 갖추고 있으며, 대상 언어에서 오디오-설명 쌍 데이터의 부족 문제를 해결하기 위해 다국어 간의 연관성을 활용합니다.

- **Technical Details**: 이 TTS 프레임워크는 세 가지 컴포넌트로 구성됩니다: NANSY++ 모델, TTS 음향 모델, 설명 제어 모델. NANSY++ 모델은 자가 학습(self-supervised learning)으로 페이지 분리된 음성 표현을 학습하며, 이를 통해 TTS 모델의 조건적 특징으로 사용되는 음조(timbre)와 스타일(style) 임베딩을 공유합니다. 또한, 설명 제어 모델은 입력된 텍스트 설명을 음조 및 스타일 임베딩으로 변환합니다.

- **Performance Highlights**: 영어와 일본어 TTS 실험 결과, 제안한 방법이 두 언어 모두에서 높은 자연스러움(naturalness)과 제어 가능성(controllability)을 달성하는 것으로 나타났습니다. 특히, 일본어 오디오-설명 쌍 데이터가 없어도 기존 시스템보다 개선된 pitch 및 speaking speed 제어 능력을 보여주었습니다.



### Efficient Federated Learning against Heterogeneous and Non-stationary Client Unavailability (https://arxiv.org/abs/2409.17446)
Comments:
          Accepted to NeurIPS 2024

- **What's New**: 이 논문에서는 불규칙한 클라이언트 가용성 문제를 해결하기 위한 새로운 접근 방식인 FedAPM을 제안합니다. 이는 기존의 FedAvg 알고리즘이 겪는 클라이언트 비가용성의 비정상성을 간과하는 문제를 해결합니다.

- **Technical Details**: FedAPM은 비가용 클라이언트로 인해 놓친 계산을 보상하는 알고리즘 구조를 포함하고 있으며, 표준 FedAvg에 비해 $O(1)$의 추가 메모리 및 계산 자원만 필요합니다. 또한, 비정상적인 동적 환경에 대해 무관심하게 지역 업데이트를 균등하게 분산시킬 수 있습니다.

- **Performance Highlights**: FedAPM은 비볼록(non-convex) 목표에 대해서도 정적 목표 지점으로 수렴하며, 원하는 선형 속도 개선 속성을 달성하는 것을 보여줍니다. 실제 데이터 세트에 대한 수치 실험을 통해 그 분석을 뒷받침하였습니다.



### Rejection Sampling IMLE: Designing Priors for Better Few-Shot Image Synthesis (https://arxiv.org/abs/2409.17439)
- **What's New**: 최근 연구는 한정된 훈련 데이터로 딥 생성 모델을 학습하는 분야에서의 진전을 보여주고 있습니다. 본 논문에서는 Implicit Maximum Likelihood Estimation (IMLE) 기술을 보다 발전시켜, 시험 시 데이타와 훈련 시 데이터 간의 불일치를 해결하는 RS-IMLE라는 새로운 접근법을 제안합니다.

- **Technical Details**: 기존 IMLE 방식은 훈련 시 선택한 잠재 코드와 검사 시 샘플링되는 잠재 코드 간에 불일치가 발생하는 문제는 유지했습니다. RS-IMLE는 훈련에 사용되는 사전 분포를 조정하여 이러한 불일치를 극복하고, 훈련 데이터와 더욱 유사한 분포를 가진 샘플을 선택하게끔 합니다.

- **Performance Highlights**: RS-IMLE를 사용한 결과, 아홉 개의 소수 데이터 이미지 세트에서 GAN 및 기존 IMLE 기반 방법들과 비교하여 평균 45.9%의 FID 가치를 감소시키며, 이미지 생성 품질이 크게 향상되었습니다.



### Minimizing Live Experiments in Recommender Systems: User Simulation to Evaluate Preference Elicitation Policies (https://arxiv.org/abs/2409.17436)
- **What's New**: 이 연구에서는 YouTube Music 플랫폼의 신규 사용자를 위한 온보딩 프로세스를 평가하는 데 있어, 시뮬레이션 방법론을 개발하여 A/B 테스트를 대체하고 비용을 줄이는 방안을 제시합니다.

- **Technical Details**: 연구의 핵심은 반사적이고 강건한 사용자 행동 모델을 개발하여, 시뮬레이션 서비스를 통해 실시간 실험을 수행하지 않고도 알고리즘의 성능 예측을 가능하게 한다는 것입니다. 이를 위해 순환 신경망(recurrent neural networks)과 트랜스포머(transformers)를 사용하여 사용자 모델을 생성하였습니다.

- **Performance Highlights**: 본 연구는 새로운 PE(preference elicitation) 방법을 통해 신규 사용자가 특정 음악 아티스트에 대한 선호도를 동적으로 질문받는 성과를 보여주었으며, 이러한 프로세스는 실시간 데이터와 연결된 시뮬레이션을 통해 A/B 테스트의 요구 사항을 줄일 수 있음을 시사합니다.



### Website visits can predict angler presence using machine learning (https://arxiv.org/abs/2409.17425)
Comments:
          31 pages

- **What's New**: 본 연구는 캐나다 온타리오의 거의 200개 호수에서 하루 동안의 낚시 배 출현과 비행기에서 측정된 배 수를 예측하기 위해 온라인 플랫폼의 고해상도 사용자 생성 데이터와 쉽게 접근 가능한 보조 데이터를 통합하여 예측 모델을 적용했습니다.

- **Technical Details**: 이 연구에서는 낚시 배 출현을 예측하기 위해 Machine Learning (ML) 모델을 활용하였습니다. Lake-information 웹사이트 방문 데이터만으로도 78%의 정확도로 낚시 배 출현을 예측할 수 있었으나, 환경, 사회 생태학적, 기상, 사용자 생성 특성을 통합한 모델은 배 수 예측의 성능을 향상시켰습니다. 훈련에 포함된 알려진 호수에 대한 모델은 최대 R² 0.77에 도달했지만, 잘 알려지지 않은 호수에 대해서는 R² 0.21로 성능이 저조했습니다.

- **Performance Highlights**: 이 연구는 온라인 플랫폼에서 사용자 생성 데이터를 통합함으로써 예측 모델의 가치를 입증하였으며, 머신러닝 모델이 수산물 관리를 향상시키는 잠재력을 강조하였습니다. 전통적인 설문조사 접근법의 한계를 극복하고 보다 효율적이고 지속 가능한 레크리에이션 어업 관리 전략을 제시하는 데 기여할 수 있습니다.



### Results of the Big ANN: NeurIPS'23 competition (https://arxiv.org/abs/2409.17424)
Comments:
          Code: this https URL

- **What's New**: 2023 Big ANN Challenge는 NeurIPS 2023에서 개최되어 Approximate Nearest Neighbor(ANN) 검색의 최신 진행을 목표로 했습니다. 이전에는 전통적인 ANN 검색을 대규모로 확장하는 데 중점을 두었지만, 이번 대회는 필터링 검색, 분포 밖 데이터(out-of-distribution data), 희소(sparse) 및 스트리밍 변형을 다루었습니다.

- **Technical Details**: 이번 대회에서는 필터링된 검색, 분포 밖 데이터, 희소 벡터, 스트리밍 시나리오와 같은 네 가지 트랙이 구성되었습니다. 각 트랙은 데이터베이스로부터 색인을 구축해야 하며, 데이터셋은 공공 클라우드 저장소에서 다운로드할 수 있는 형태로 제공되었습니다. 모든 참가자는 제한된 컴퓨팅 자원으로 새로운 표준 데이터셋에서 제출된 혁신적인 솔루션을 평가받았습니다.

- **Performance Highlights**: 참가 팀들은 업계 표준 기준에 비해 검색 정확성 및 효율성에서 유의미한 개선을 보였으며, 특히 학계 및 산업 팀들로부터 많은 주목할 만한 기여가 있었습니다.



### Discovering the Gems in Early Layers: Accelerating Long-Context LLMs with 1000x Input Token Reduction (https://arxiv.org/abs/2409.17422)
- **What's New**: 이 연구에서는 긴 컨텍스트 입력을 처리하기 위해 LLM(Large Language Model)의 추론을 가속화하고 GPU 메모리 소모를 줄이는 새로운 접근 방식인 GemFilter를 소개합니다.

- **Technical Details**: GemFilter는 LLM의 초기 레이어를 필터로 사용하여 입력 토큰을 선택하고 압축하는 알고리즘으로, 이에 따라 추후 처리할 컨텍스트 길이를 대폭 줄입니다. 이 방법은 2.4$	imes$ 속도 향상과 30
gpu(%) GPU 메모리 사용량 감소를 달성하였습니다.

- **Performance Highlights**: GemFilter는 Needle in a Haystack 벤치마크에서 기존의 표준 어텐션 및 SnapKV를 능가하며, LongBench 챌린지에서는 SnapKV/H2O와 유사한 성능을 보여줍니다.



### Solar Active Regions Emergence Prediction Using Long Short-Term Memory Networks (https://arxiv.org/abs/2409.17421)
Comments:
          20 pages, 8 figures, 5 tables, under review at the AAS Astrophysical Journal

- **What's New**: 이 연구에서는 Long Short-Term Memory (LSTM) 모델을 개발하여 태양 표면에서 활성 영역(Active Regions, AR)의 형성을 예측합니다. 이 모델은 Solar Dynamics Observatory (SDO) Helioseismic and Magnetic Imager (HMI)로부터 얻은 Doppler shift velocity, continuum intensity, magnetic field observations를 활용하여 시간 시계열 데이터셋을 생성했습니다.

- **Technical Details**: LSTM 모델은 acústic power 및 magnetic flux의 변화를 포착하는 기능이 있으며, 이 연구에서는 61개의 신생 AR에 대한 데이터를 수집하여 12시간 전 continuum intensity를 예측하기 위해 훈련되었습니다. 연구에 사용된 데이터는 활성 영역의 출현 전후의 상태를 포함합니다.

- **Performance Highlights**: 모델 8은 실험 설정에서 모든 테스트 활성 영역의 출현 예측에 성공하였고, AR11726, AR13165 및 AR13179의 경우 각각 10, 29, 5시간 전에 예측했습니다. 이 모델의 RMSE(평균 제곱근 오차) 값은 태양 디스크의 활성 및 조용한 지역 모두에 대해 평균 0.11로, ML 기반의 태양 AR 예측의 기초를 마련했습니다.



### AI Enabled Neutron Flux Measurement and Virtual Calibration in Boiling Water Reactors (https://arxiv.org/abs/2409.17405)
- **What's New**: 이 논문에서는 고온수로(Cooling Water Reactor)에서의 전력 분포를 정확하게 측정하기 위한 새로운 접근법을 제시합니다. 특히, 두 가지 딥러닝(DL) 모델인 SurrogateNet과 LPRMNet을 통해 오프라인과 온라인 전력 분포 간의 편향을 줄이고, 안전하고 경제적인 Reload Core 설계를 가능하게 합니다.

- **Technical Details**: SurrogateNet은 다른 LPRM의 판독값을 이용해 특정 LPRM의 판독값을 예측하고, LPRMNet은 원자로의 상태 변수를 기반으로 LPRM 값을 예측합니다. 두 모델 모두 작동 주파수는 약 1Hz이며, LPRM 시스템은 핵심 신호를 제공합니다. DNN 아키텍처들은 각각 1%와 3%의 테스트 오류를 보여줍니다.

- **Performance Highlights**: 모델의 응용으로는 LPRM이 우회되거나 오류가 발생했을 때의 가상 센서 기능, 연속 캘리브레이션 간의 가상 캘리브레이션, LPRM의 종말 수명(EOL) 결정의 높은 정확성 등이 포함됩니다. 이로 인해 오프라인과 예측된 전력 분포 간의 편향이 감소하게 됩니다.



### Enhancing Recommendation with Denoising Auxiliary Task (https://arxiv.org/abs/2409.17402)
- **What's New**: 본 연구는 사용자의 이력(interaction sequences)에서 발생하는 잡음(noise)이 추천 시스템에 미치는 영향을 다루고 있으며, 이를 개선하기 위한 새로운 방법인 자가 감독(Auto-supervised) 보조 작업 결합 훈련(Auxiliary Task Joint Training, ATJT)을 제안합니다.

- **Technical Details**: ATJT 방법은 원본 이력을 바탕으로 랜덤 대체를 통해 인위적으로 생성된 잡음이 포함된 시퀀스를 학습하여 모델의 성능을 향상시키기 위한 것입니다. 잡음 인식 모델과 추천 모델을 난이도에 따라 조정된 가중치로 훈련하여 잡음이 포함된 시퀀스로부터 적절한 학습을 이끌어냅니다.

- **Performance Highlights**: ATJT 방법은 세 개의 데이터셋에서 일관된 기본 모델을 사용하여 실험한 결과, 모델의 추천 성능을 개선하는 데 효과적임을 입증했습니다.



### Severity Prediction in Mental Health: LLM-based Creation, Analysis, Evaluation of a Novel Multilingual Datas (https://arxiv.org/abs/2409.17397)
- **What's New**: 이 연구는 다양한 비영어권 언어에서 대규모 언어 모델(LLMs)의 효과성을 평가하기 위한 다국어 정신 건강 데이터셋을 개발하였습니다. 이 데이터셋은 영어에서 그리스어, 터키어, 프랑스어, 포르투갈어, 독일어, 핀란드어로 번역된 사용자 생성 콘텐츠로 구성되어 있습니다. 이는 모델의 성능을 여러 언어에서 종합적으로 평가할 수 있도록 합니다.

- **Technical Details**: 이 연구에서는 GPT와 Llama를 사용하여 여러 언어로 번역된 동일한 데이터셋에서 정신 건강 상태의 심각성을 정밀하게 예측하는 성능을 비교하였습니다. 연구 결과, 언어별로 상당한 성능 차이를 관찰했으며 이는 다국어 정신 건강 지원의 복잡성을 강조합니다. 대상 데이터셋은 다음 링크에서 공개되어 있습니다: https://github.com/y3nk0/multilingual-mental-severity-prediction.

- **Performance Highlights**: 이 연구는 다국어 정신 건강 조건의 심각성을 탐지하는 LLM의 능력에 대한 포괄적인 분석을 제공하며, 특정 언어에서의 성과 차이가 어떻게 발생하는지를 조명합니다. 또한, LLM을 의료 환경에서 사용할 때의 잠재적인 오진 위험에 대해 경고합니다. 이 연구의 접근 방식은 다국어 작업의 비용 절감 측면에서도 중요한 이점을 제공합니다.



### VectorSearch: Enhancing Document Retrieval with Semantic Embeddings and Optimized Search (https://arxiv.org/abs/2409.17383)
Comments:
          10 pages, 14 figures

- **What's New**: 이 논문은 고차원 데이터 검색의 정확성을 높이기 위해 'VectorSearch'라는 새로운 알고리즘을 제안합니다. 이 시스템은 고급 언어 모델과 다중 벡터 인덱싱 기술을 통합하여 텍스트 데이터의 의미적 관계를 더 잘 파악할 수 있도록 설계되었습니다.

- **Technical Details**: VectorSearch는 데이터의 다차원 임베딩(embeddings)을 효율적으로 검색하는 하이브리드(document retrieval framework) 시스템입니다. HNSWlib 및 FAISS와 같은 최적화 기법을 사용하여 대규모 데이터셋을 효과적으로 관리하고, 복잡한 쿼리 처리 기능을 통해 고급 검색 작업을 지원합니다. 또한, 시스템은 클러스터 환경에서 동적으로 변화하는 데이터셋을 처리할 수 있는 메커니즘을 포함하고 있습니다.

- **Performance Highlights**: 실제 데이터셋을 기반으로 한 실험 결과, VectorSearch는 기존의 기준 메트릭을 초월하여 대규모 검색 작업에서 뛰어난 성능을 보였습니다. 이는 높은 차원의 데이터에서도 저지연성 검색 결과를 제공함으로써 정보 검색의 정확성을 획기적으로 향상시킨 것을 나타냅니다.



### Data-driven Probabilistic Trajectory Learning with High Temporal Resolution in Terminal Airspac (https://arxiv.org/abs/2409.17359)
Comments:
          Submitted to AIAA-JAIS

- **What's New**: 이 논문은 비행 궤적 예측에 대한 데이터 기반 학습 프레임워크를 제안합니다. 이 프레임워크는 혼합 모델(mixture models)과 seq2seq 기반 신경망(neural networks)의 예측 능력을 활용하며, 오류 전파(error propagation) 및 차원 축소(dimensionality reduction)와 같은 문제에 대한 해결 방안을 제공합니다. 이는 기존의 최신 방법보다 더욱 높은 예측 정확도를 보이며, 특히 공항 주변의 터미널 공역에서의 궤적 예측에 적합합니다.

- **Technical Details**: 제안된 학습 프레임워크는 과거의 궤적 및 맥락 정보를 고려하여 장기 예측(long-step prediction)의 정확도를 현저하게 개선합니다. 학습된 모델은 시간 간격 1초의 높은 시간 해상도(temporal resolution)를 유지한다는 점이 특징입니다. 이는 비행기뿐만 아니라 UAV의 궤적 예측에도 사용될 수 있는 데이터 드리븐(data-driven) 방법론을 활용합니다.

- **Performance Highlights**: 제안된 방법은 터미널 공역 비행 궤적 데이터 세트에서 기존의 주류 예측 방법을 초월한 성능을 보여주었습니다. 예측된 궤적은 실제 값(ground truth)과 더욱 근접하며, 시간적 해상도가 향상된 것이 주요 성과입니다.



### Accelerating Multi-Block Constrained Optimization Through Learning to Optimiz (https://arxiv.org/abs/2409.17320)
Comments:
          15 pages, 2 figures

- **What's New**: 이 논문은 기존의 Learning to Optimize (L2O) 접근법을 멀티 블록 ADMM(Alternating Direction Method of Multipliers) 방법으로 확장하려는 시도를 다루고 있습니다. 이 확장은 최적화 문제의 분리 가능한 구조를 활용하여 반복 복잡성을 크게 줄이는 데 중요합니다. 특히, 이 연구에서는 Majorized Proximal Augmented Lagrangian Method (MPALM)을 활용하여 수렴성을 보장하는 방안을 제시하고, 하이퍼파라미터 선택의 문제를 해결하기 위한 새로운 L2O 접근법을 제안합니다.

- **Technical Details**: 논문에서는 멀티 블록 최적화 문제를 정의하고, 전통적인 최적화 알고리즘보다 L2O 접근법에 의한 퍼포먼스를 검증합니다. MPALM은 현재까지 성능에 대해 높은 민감도를 보여주는 하이퍼파라미터를 적응적으로 선택하는 기법이 필요합니다. 본 연구는 이는 감독 학습을 통해 해결합니다. 성능 비교를 위해 Lasso 문제와 최적 수송 문제에 이 방법이 적용됩니다.

- **Performance Highlights**: 수치 실험 결과, 제안된 프레임워크는 기존의 인기 있는 대안들에 비해 뛰어난 성능을 보여줍니다. 이 연구는 일반적인 선형 제약 조건을 가진 복합 최적화 문제에도 적용 가능하여 실제 응용 가능성을 넓히는 데 기여합니다.



### BabyLlama-2: Ensemble-Distilled Models Consistently Outperform Teachers With Limited Data (https://arxiv.org/abs/2409.17312)
Comments:
          9 pages, 3 figures, 5 tables, submitted to the BabyLM Challenge (CoNLL 2024 Shared Task)

- **What's New**: BabyLlama-2는 3억 4500만 개의 매개변수를 가진 모델로, 두 개의 교사 모델로부터 1000만 개의 단어로 학습한 후 BabyLM 대회에 제출된 것이다. 결과적으로 BabyLlama-2는 BLiMP 및 SuperGLUE 벤치마크에서 동일한 데이터 혼합을 사용하는 1000만 및 1억 단어 데이터셋으로 학습된 기준 모델을 능가하였다.

- **Technical Details**: BabyLlama-2는 345M의 decoder-only 모델로, 9.5M 단어로 사전 학습되었다. 하이퍼파라미터 최적화가 광범위하게 수행되었으며, 최적의 하이퍼파라미터 선택이 교사 모델의 우수한 성능에 기인하지 않음을 증명하였다. 지식 증류(knowledge distillation) 기법을 사용하여 샘플 효율성을 높이는 데 중점을 두었다.

- **Performance Highlights**: BabyLlama-2는 기존 모델보다 더 적은 데이터로도 더 높은 성능을 달성하였다. 특히, BLiMP 과제에서 제로 샷(zero-shot) 성능과 모델의 테스트 손실(test loss) 사이에 상관관계를 찾았으며, 이는 모델 성능을 향상시키기 위한 지식 증류의 가능성을 강조한다.



### Sparsity, Regularization and Causality in Agricultural Yield: The Case of Paddy Rice in Peru (https://arxiv.org/abs/2409.17298)
- **What's New**: 이 연구는 페루의 다양한 지역에서 벼(경작지) 수확량을 예측하기 위해 농업 조사 데이터와 원격 감지 시계열 데이터를 통합하는 새로운 접근법을 도입합니다.

- **Technical Details**: 이 연구에서는 sparse regression과 Elastic-Net 정규화 기법을 활용하여 NDVI, 강수량 및 온도와 같은 원격 감지 변수와 농업 수확량 사이의 인과 관계를 식별합니다. 비선형 패턴과 지연 효과를 포착하기 위해 이러한 변수의 1차 및 2차 동적 변환(속도 및 가속도)을 적용했습니다. 방법론으로는 Elastic-Net 정규화 회귀 모델, Generalized Additive Models (GAM), 그리고 XGBoost 모델을 사용합니다.

- **Performance Highlights**: 정규화 기법과 기후 및 지리 데이터를 결합함으로써 수확량 변동성에 대한 보다 정확한 예측을 가능하게 하였으며, Granger 의미에서 인과 관계의 존재를 확인했습니다. 이 연구는 벼 재배의 효율성과 지속 가능성을 높이는 데 기여합니다.



### Schr\"odinger bridge based deep conditional generative learning (https://arxiv.org/abs/2409.17294)
Comments:
          22 pages, 4 figures

- **What's New**: 이 논문에서는 조건부 분포(conditional distributions)를 학습하기 위한 새로운 슈뢰딩거 브릿지(Schrödinger bridge) 기반의 심층 생성 방법을 소개합니다. 이 방법은 고정된 점에서 원하는 목표 조건부 분포로의 확산 과정을 통해 데이터를 생성합니다.

- **Technical Details**: 연구진은 확산 과정(diffusion process)을 통해 조건부 샘플을 생성하며, 확산 방정식(stochastic differential equation, SDE)을 이산화하여 결과를 알기 위해 심층 신경망(deep neural network)을 활용합니다. 이 알고리즘은 조건부 정보(conditional information)를 통합하여 운반 계획을 점진적으로 개선하는 반복적인 솔버(iterative solver) 방식을 사용합니다.

- **Performance Highlights**: 이 방법의 성능은 기존 방법들과 비교하여 생성된 샘플의 품질이 월등히 높음을 입증합니다. 또한, 생성된 샘플은 조건부 밀도 추정(conditional density estimation) 및 관련 통계량 추정(conditional mean, conditional standard deviation)에도 효과적으로 이용될 수 있습니다.



### Blockchain-Enabled Variational Information Bottleneck for Data Extraction Based on Mutual Information in Internet of Vehicles (https://arxiv.org/abs/2409.17287)
Comments:
          This paper has been submitted to IEEE Journal. The source code has been released at: this https URL Mutual-Information-in-the-IoV

- **What's New**: 최근 차량 간 통신(In-Vehicle Communication) 및 프라이버시 문제를 해결하기 위해, 블록체인 기술을 활용한 새로운 데이터 전송 방식인 BVIB(블록체인 기반 변분 정보 병목 기술)가 제안되었습니다. 이 접근법은 차량의 컴퓨팅 부담을 줄이고, 네트워크 보안을 강화하는 데 중점을 두고 있습니다.

- **Technical Details**: 기술적으로, BVIB는 인코딩과 디코딩 작업을 차량과 서버 간에 분배하여 효율성을 높입니다. 이는 Variational Information Bottleneck (VIB) 기술과 블록체인의 조합을 통해 이루어지며, DNN(Deep Neural Network)을 사용하여 데이터 압축을 최적화합니다. BVIB는 서버에서 수행할 디코딩과 차량에서 수행할 인코딩을 분리하여 컴퓨팅 부담을 줄입니다.

- **Performance Highlights**: 실험 결과, BVIB는 데이터 전송량을 줄이고 시스템 지연을 최소화하는 데 있어 뛰어난 성능을 보여주었습니다. 기존 알고리즘 대비 상호 정보(Mutual Information) 경계 정확도와 보안 측면에서 솔루션의 효과성이 입증되었습니다.



### Building Real-time Awareness of Out-of-distribution in Trajectory Prediction for Autonomous Vehicles (https://arxiv.org/abs/2409.17277)
- **What's New**: 이번 연구는 자율주행차의 궤적 예측에서 out-of-distribution (OOD) 인식의 실시간 모니터링 방법을 제시합니다. 특히, 사람의 직관으로는 쉽게 감지할 수 없는 속임수 같은 OOD 상황을 다루고자 하였습니다.

- **Technical Details**: 기존의 궤적 예측에서는 QCD (Quickest Change Detection) 기법을 사용하여 예측 오류를 모니터링하며, 이는 실시간으로 OOD를 인식할 수 있게 도와줍니다. 이러한 기법은 경량이며, 궤적 예측 추론 중 언제든지 OOD 상황 발생을 처리할 수 있습니다. 실험에서는 adversarial trajectory perturbation을 이용하여 OOD 궤적을 생성하였습니다.

- **Performance Highlights**: 모든 실험 결과에서 제안된 방법들이 기존의 방법들보다 우수한 성능을 보이는 것으로 나타났습니다. 제안된 접근법은 여러 실제 데이터셋에 대해 효과적인 결과를 보여주며, 자율주행차의 안전한 주행을 위한 신뢰성을 높입니다.



### Multiview Canonical Correlation Analysis for Automatic Pathological Speech Detection (https://arxiv.org/abs/2409.17276)
Comments:
          Submitted to ICASSP 2025

- **What's New**: 본 논문에서는 Multiview Canonical Correlation Analysis (MCCA)를 사용하여 자동 병리적 음성 탐지의 성능을 향상시키는 새로운 접근 방식을 제안합니다. MCCA는 입력 표현에서 비상관 정보를 제거함으로써 병리적 음성 탐지의 정확성을 높입니다.

- **Technical Details**: MCCA는 PCA(Principal Component Analysis)의 확장으로, 여러 뷰(view) 각각의 데이터를 통합하여 공통적인 저차원 표현을 찾습니다. 이를 통해 병리학과 무관한 신호를 억제하고 병리적 신호를 적절히 유지할 수 있습니다.

- **Performance Highlights**: MCCA를 활용한 전통적인 분류기들이 복잡한 신경망 아키텍처를 사용하는 방법보다 비교 가능하거나 더 우수한 성능을 보입니다. 또한, 모델 해석 가능성을 유지하면서도 구조적인 표현을 보존합니다.



### On the Vulnerability of Applying Retrieval-Augmented Generation within Knowledge-Intensive Application Domains (https://arxiv.org/abs/2409.17275)
- **What's New**: 이 논문은 Retrieval-Augmented Generation (RAG) 시스템의 적대적 강인성(adversarial robustness)을 조사하였습니다. 특히, 의학 분야의 Q&A를 대상으로 한 '보편적인 중독 공격(universal poisoning attacks)'의 취약성을 분석하고 새로운 탐지 기반(defense) 방어 체계를 개발하였습니다.

- **Technical Details**: RAG 시스템은 외부 데이터에서 중요한 정보를 검색(retrieve)하고 이를 LLM의 생성 과정에 통합하는 두 가지 단계를 포함합니다. 이 연구에서는 225개 다양한 설정에서 RAG의 검색 시스템이 개인 식별 정보(PII)와 같은 다양한 타겟 정보를 포함하는 중독 문서에 취약하다는 것을 입증하였습니다. 중독된 문서는 쿼리의 임베딩과 높은 유사성을 유지함으로써 정확히 검색될 수 있음을 발견하였습니다.

- **Performance Highlights**: 제안한 방어 방법은 다양한 Q&A 도메인에서 뛰어난 탐지율(detection rates)을 일관되게 달성하며, 기존의 방어 방법에 비해 훨씬 효과적임을 보여주었습니다. 실험에 따르면 거의 모든 공격에 대해 일관되게 높은 탐지 성공률을 보였습니다.



### An Integrated Deep Learning Framework for Effective Brain Tumor Localization, Segmentation, and Classification from Magnetic Resonance Images (https://arxiv.org/abs/2409.17273)
Comments:
          36 pages, 27 figures, 5 tables

- **What's New**: 본 연구는 자기공명영상(MRI)을 바탕으로 뇌종양의 조기 진단을 위한 딥러닝(DL) 프레임워크를 제안합니다. 특히 이 연구에서는 뇌신경에서 발생하는 다양한 형태의 종양을 정확하게 국소화(localize)하고 분할(segment)하며 등급을 분류(classify) 할 수 있는 방법론을 다룹니다.

- **Technical Details**: 링크넷(LinkNet) 프레임워크를 VGG19에서 영감을 받은 인코더 아키텍처로 개선하여 멀티모달(multi-modal) 종양 특징 추출을 향상시켰으며, 공간 및 그래프 주의 메커니즘(spatial and graph attention mechanisms)을 통해 특징 강조 및 상호 특징 관계를 정제합니다. 이후, 세레즈넷101(SeResNet101) CNN 모델을 인코더 백본으로 통합하여 종양을 분할하였으며, 이로 인해 96% IoU 점수를 달성하였습니다. 분할된 종양을 분류하기 위해 세레즈넷152(SeResNet152) 특징 추출기와 적응형 부스팅(classifier)을 결합하여 98.53%의 정확도를 실현하였습니다.

- **Performance Highlights**: 제안된 모델들은 뚜렷한 성과를 보이며, 의료 AI의 발전을 통해 조기 진단을 가능하게 하고 환자에 대한 보다 정확한 치료 옵션을 제공할 가능성을 지니고 있습니다.



### Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning (https://arxiv.org/abs/2409.17270)
- **What's New**: 이 연구에서는 LLM(대형 언어 모델)의 출력 신뢰성과 투명성을 높이기 위해 'Proof of Thought'라는 새로운 프레임워크를 소개합니다. 이 프레임워크는 LLM이 생성한 아이디어와 형식 논리 검증을 연결합니다.

- **Technical Details**: Proof of Thought는 사용자 친화적인 개념을 사용하는 JSON 기반의 도메인 특화 언어(DSL)로, 이를 통해 LLM의 출력을 1차 논리(First Order Logic) 구조로 변환하는 커스텀 인터프리터를 사용합니다. 이 방법은 논리적 구조와 인간이 이해할 수 있는 개념 사이의 균형을 이루도록 설계되었습니다.

- **Performance Highlights**: Proof of Thought는 StrategyQA 및 새로운 멀티모달 추론 작업에서 효과를 입증하였으며, 개방형 시나리오에서 향상된 성능을 보였습니다. 이는 AI 시스템의 책임성을 다루고, 높은 위험 도메인에서 인간의 관여를 위한 기초를 설정하는 데 기여합니다.



### Disk2Planet: A Robust and Automated Machine Learning Tool for Parameter Inference in Disk-Planet Systems (https://arxiv.org/abs/2409.17228)
Comments:
          Accepted to ApJ

- **What's New**: Disk2Planet라는 기계 학습 기반 도구를 소개합니다. 이 도구는 관측된 원시 행성계(disk-planet) 구조에서 핵심 매개변수를 추론합니다.

- **Technical Details**: Disk2Planet은 2D 밀도(density) 및 속도(velocity) 맵의 형태로 입력된 원반 구조를 바탕으로, Shakura–Sunyaev 점성(viscosity), 원반 비율(aspect ratio), 행성-별 질량 비율(planet-star mass ratio), 행성의 반지름(radius) 및 방위각(azimuth) 같은 매개변수를 출력합니다. 이 도구는 CMA-ES라는 복잡한 최적화 문제를 위한 진화 알고리즘과, 원반-행성 상호작용의 예측을 위해 설계된 PPDONet이라는 신경망(neural network)을 통합했습니다. 전체 자동화된 시스템으로, Nvidia A100 GPU에서 3분 이내에 하나의 시스템의 매개변수를 검색할 수 있습니다.

- **Performance Highlights**: Disk2Planet은 0.001에서 0.01 정도의 정확도로 매개변수를 추론할 수 있으며, 결측치(missing data)와 다양한 노이즈(noise) 수준을 처리할 수 있는 강력성을 입증했습니다.



### 2024 BRAVO Challenge Track 1 1st Place Report: Evaluating Robustness of Vision Foundation Models for Semantic Segmentation (https://arxiv.org/abs/2409.17208)
Comments:
          arXiv admin note: substantial text overlap with arXiv:2409.15107

- **What's New**: 2024 BRAVO Challenge의 Track 1에서 Cityscapes 데이터셋으로 훈련된 모델을 제시하며, 다양한 out-of-distribution 데이터셋에서의 강건성을 평가합니다. 이 연구는 Vision Foundation Models (VFM)을 활용하여 DINOv2에 간단한 segmentation decoder를 붙여 전체 모델을 fine-tuning하여 우수한 성능을 보여줍니다.

- **Technical Details**: 이 연구에서는 DINOv2 VFM을 사용하여 semantic segmentation을 위한 pre-trained 모델을 fine-tuning합니다. 기본 구성에서 간단한 linear decoder를 사용하여 patch-level features를 segmentation logits로 변환합니다. 다양한 모델 크기, patch 크기, pre-training 전략 및 segmentation decoders를 실험하여 우리의 접근 방식의 효과를 평가합니다.

- **Performance Highlights**: 우리는 기존의 복잡한 모델들을 능가하여 이 챌린지에서 1위를 달성했습니다. 우리의 간단한 접근 방식이 어떻게 specialist 모델들보다 더 나은 성능을 내는지를 입증하며, 향후 연구에서 관심을 끌 수 있는 새로운 관찰도 제시합니다.



### Immersion and Invariance-based Coding for Privacy-Preserving Federated Learning (https://arxiv.org/abs/2409.17201)
- **What's New**: 이번 논문에서는 차별적 개인 정보 보호(differential privacy)와 시스템 몰입(system immersion) 도구를 이용하여 개인 정보 보호를 위한 연합 학습 프레임워크를 제안합니다. 이 프레임워크는 기존 방식에 비해 모델 성능과 시스템 효율성을 유지하면서도 더 강력한 개인 정보 보호를 제공합니다.

- **Technical Details**: 제안된 프레임워크는 기계 학습 모델의 파라미터를 인코딩 및 디코딩하는 랜덤 코딩을 통해, 클라이언트와 서버 간의 커뮤니케이션에서 개인 정보를 보호할 수 있도록 설계되었습니다. 클라이언트는 자신의 데이터에 대한 직접적 접근 없이도 모델 파라미터를 업데이트하고, 서버는 최종 모델 파라미터를 복원할 수 있습니다.

- **Performance Highlights**: 실험 결과, 제안된 방식이 기존의 연합 학습 알고리즘과 동일한 정확도와 수렴 속도를 유지하면서도 원하지 않는 정보 누출을 방지한다는 점이 확인되었습니다. 이는 다양한 기계 학습 모델에서 적용 가능하며, 최적의 개인 정보 보호 보장이 가능함을 보여줍니다.



### An Effective, Robust and Fairness-aware Hate Speech Detection Framework (https://arxiv.org/abs/2409.17191)
Comments:
          IEEE BigData 2021

- **What's New**: 이 논문은 온라인 소셜 네트워크에서의 증오 발언을 효과적으로 탐지하기 위한 새로운 프레임워크를 제안합니다. 데이터 부족, 모델의 불확실성 추정, 악의적 공격에 대한 강인성 향상 및 공정성 처리의 한계를 극복하고자 합니다.

- **Technical Details**: 제안된 프레임워크는 Bidirectional Quaternion-Quasi-LSTM (BiQQLSTM) 계층을 포함하여 효과성과 효율성을 균형 있게 맞추고, 세 가지 플랫폼에서 수집한 다섯 개 데이터셋을 결합하여 일반화된 모델을 구축합니다. 데이터 증강 기법을 사용해 다양한 공격 및 텍스트 조작에 강한 모델을 만드는 데 주력합니다.

- **Performance Highlights**: 실험 결과, 제안한 모델은 공격이 없는 시나리오에서 8개의 최첨단 방법들보다 5.5% 향상된 성능을 보여주며, 다양한 공격 시나리오에서도 최고 기준 대비 3.1% 향상된 성능을 기록하여 모델의 효과성과 강인성을 입증했습니다.



### Decentralized Federated Learning with Gradient Tracking over Time-Varying Directed Networks (https://arxiv.org/abs/2409.17189)
- **What's New**: 본 연구는 시간에 따라 변화하는 방향 그래프에서 에이전트 간 상호작용 문제를 다루며, 분산된 학습(Decentralized Learning) 환경에서 모델 최적화를 위한 새로운 알고리즘 DSGTm-TV를 제안합니다. 이 알고리즘은 데이터 프라이버시를 보호하면서도 에이전트들이 지역적으로 최적화할 수 있도록 설계되었습니다.

- **Technical Details**: DSGTm-TV 알고리즘은 그래디언트 추적(Gradient Tracking)과 헤비볼 모멘텀(Heavy-Ball Momentum) 기법을 통합하여 글로벌 목표 함수(Objective Function)를 분산적으로 최적화합니다. 에이전트는 인접한 에이전트와 정보를 교환하며 로우 및 컬럼 스토캐스틱 믹싱 매트릭스를 사용하여 지역 모델 파라미터와 그래디언트 추정치를 업데이트합니다. 이를 통해 일관성과 최적성을 보장하며, 동적이고 비동기적인 네트워크 환경에서도 수렴성을 유지하고 있습니다.

- **Performance Highlights**: 실제 이미지 분류 및 자연어 처리(NLP) 업무에서의 비교를 통해 DSGTm-TV의 성능이 최신 기준선(State-of-the-art Baselines)과 비교하여 효과적임을 입증했습니다. 특히, 본 알고리즘은 비동조화된 하이퍼파라미터를 사용하는 에이전트들도 독립적으로 최적화할 수 있도록 허용합니다.



### Transfer learning for financial data predictions: a systematic review (https://arxiv.org/abs/2409.17183)
Comments:
          43 pages, 5 tables, 1 figure

- **What's New**: 이 논문은 전이 학습(Transfer Learning) 방법론을 금융 시장 예측에 적용하는 데 중점을 두고 있으며, 기존에는 신경망(neural network) 아키텍처에 주로 집중된 리뷰가 많았던 점을 지적합니다.

- **Technical Details**: 금융 시계열 데이터는 노이즈(noise)와 뉴스에 취약하며, 전통적인 통계 방법론은 선형성(linearity) 및 정규성(normality) 가정을 바탕으로 하였기 때문에 비선형적(non-linear) 특성을 잘 설명하지 못합니다. 신경망은 금융 가격 예측에 있어 주요한 머신 러닝 도구로 자리잡고 있으며, 전이 학습은 출발하는 작업(source task)에서 목표 작업(target task)으로 지식을 전이하는 방법으로, 금융 예측에 있어 유용한 도구가 될 수 있습니다.

- **Performance Highlights**: 전이 학습 방법론은 향후 주식 시장 예측의 도전과제 및 잠재적 미래 방향성을 탐구하는 데 중요한 역할을 할 것으로 기대됩니다.



### Fully automatic extraction of morphological traits from the Web: utopia or reality? (https://arxiv.org/abs/2409.17179)
- **What's New**: 이 논문은 최근의 대형 언어 모델(LLMs)을 활용하여 비구조적인 텍스트에서 식물의 형태학적 특성 정보를 자동으로 수집하고 처리하는 메커니즘을 제안합니다. 이를 통해 전문가가 수년간 수집해야 하는 복잡한 특성 정보를 손쉽게 구축할 수 있습니다.

- **Technical Details**: 제안된 방법론은 다음과 같은 세 가지 입력을 요구합니다: (i) 관심 있는 종의 목록, (ii) 관심 있는 특성 목록, 그리고 (iii) 각 특성이 가질 수 있는 모든 가능한 값의 목록. 이 프로세스는 검색 엔진 API를 사용하여 관련 URL를 가져오고, 이 URL에서 텍스트 콘텐츠를 다운로드합니다. 이후 NLP 모델을 통해 설명 문장을 판별하고, LLM을 사용하여 기술적 특성 값을 추출합니다.

- **Performance Highlights**: 이 방식으로 3개의 수작업으로 작성된 종-특성 행렬을 자동으로 복제하는 평가를 실시했습니다. 결과적으로 75% 이상의 F1-score를 달성하며, 50% 이상의 종-특성 쌍의 값을 찾는 데 성공했습니다. 이는 비구조적 온라인 텍스트로부터 구조화된 특성 데이터베이스를 대규모로 생성하는 것이 현재 가능하다는 점을 보여줍니다.



### What Would You Ask When You First Saw $a^2+b^2=c^2$? Evaluating LLM on Curiosity-Driven Questioning (https://arxiv.org/abs/2409.17172)
- **What's New**: 본 논문에서는 대규모 언어 모델(LLM)의 새로운 지식 습득 가능성을 평가하기 위한 혁신적인 평가 프레임워크를 제안합니다. 이 프레임워크는 LLM이 과학적 지식을 소개하는 진술에 대한 질문을 생성하도록 유도하여, 처음 접하는 사람처럼 호기심을 가지고 질문하는 방식으로 평가합니다.

- **Technical Details**: 제안된 평가 방법은 호기심 기반 질문 생성(CDQG) 과제로, LLM이 처음 접하는 진술을 상상하며 즉각적으로 떠오르는 질문을 만들어내도록 프롬프트합니다. 생성된 질문은 관련성(relevance), 일관성(coherence), 다양성(diversity) 세 가지 주요 지표로 평가되며, 심리학 문헌에 뿌리를 두고 있습니다. 여러 모델의 성능을 비교 평가하기 위해 물리학, 화학 및 수학 분야의 1101개의 다양한 난이도의 진술로 구성된 합성 데이터셋을 수집했습니다.

- **Performance Highlights**: GPT-4와 Mistral 8x7b와 같은 대형 모델이 일관성 있고 관련성이 높은 질문을 잘 생성하는 반면, 크기가 작은 Phi-2 모델은 동등하거나 그 이상으로 효과적임을 발견했습니다. 이는 모델의 크기만으로 지식 습득 가능성을 판단할 수 없음을 나타냅니다. 연구 결과, 제안된 프레임워크는 LLM의 질문 생성 능력을 새로운 관점에서 평가할 수 있는 기회를 제공합니다.



### Mamba for Scalable and Efficient Personalized Recommendations (https://arxiv.org/abs/2409.17165)
Comments:
          8 pages, 6 figures, 2 tables

- **What's New**: 이번 연구에서는 개인화 추천 시스템에서 표 형식(tabular data) 데이터를 처리하기 위해 FT-Mamba(Feature Tokenizer + Mamba)라는 새로운 하이브리드 모델을 제안합니다. 이 모델은 FT-Transformer 아키텍처 내의 Transformer 레이어를 Mamba 레이어로 대체하여, 계산 복잡성을 줄이고 효율성을 향상시킵니다.

- **Technical Details**: FT-Mamba 모델은 Mamba 아키텍처를 활용하여, 표 형식 데이터를 시퀀스 형태로 변환하고, Mamba 레이어를 통해 처리합니다. Mamba는 State Space Model(SSM)의 효율성을 개선하며, 시퀀스의 길이에 대해 선형 복잡도(𝒪(L))를 제공합니다. 이는 일반적인 Transformer의 제곱 복잡도(𝒪(L²))를 극복할 수 있게 합니다. 이 모델은 Three datasets (Spotify, H&M, Vaccine messaging)에서 평가되었습니다.

- **Performance Highlights**: FT-Mamba는 기존의 Transformer 기반 모델에 비해 계산 효율성이 향상되었으며, 정확도 같은 주요 추천 지표에서 성능을 유지하거나 초과했습니다. FT-Mamba는 사용자 정보를 인코딩하는 Two-Tower 구조를 사용하여, 개인화 추천 시스템을 위한 확장 가능하고 효과적인 솔루션을 제공합니다.



### Autonomous Vehicle Decision-Making Framework for Considering Malicious Behavior at Unsignalized Intersections (https://arxiv.org/abs/2409.17162)
- **What's New**: 이 논문은 자율주행차가 신호가 없는 교차로에서 다른 악의적 행동을 하는 차량과 마주쳤을 때의 안전성과 효율성을 개선하기 위한 Q-learning 기반 의사결정 프레임워크를 제안합니다. 전통적인 보상 신호에 대한 개선된 접근으로, 위기 상황에서 안전을 강조할 수 있도록 가변 가중치 매개변수를 도입합니다.

- **Technical Details**: 제안된 Adaptive Safety-Enhanced Q-Learning Framework (ASEQ)는 교차로의 사고 위험을 줄이기 위해 긴급 및 비긴급 위험 회피를 게임 이론적 의사결정 프로세스에 통합합니다. 특히, Time-to-Collision (TTC) 메트릭을 사용하여 안전, 편안함, 효율성을 동적으로 조절합니다. 또한, 차량의 행동에 대한 1차 이론적 마인드(Theory of Mind, ToM) 추론 방식을 적용하여 대상 차량의 동기를 이해합니다.

- **Performance Highlights**: Prescan/Simulink 코시뮬레이션을 통해 성능 검증을 실시하였으며, 결과적으로 제안된 의사결정 프레임워크가 설정된 요구사항을 충족할 수 있음을 보여주었습니다. 이는 교차로에서 자율주행차의 안전성과 효율성을 향상시키는데 기여할 것으로 기대됩니다.



### Cross Dataset Analysis and Network Architecture Repair for Autonomous Car Lane Detection (https://arxiv.org/abs/2409.17158)
- **What's New**: 본 연구에서는 자율주행 차량의 차선 인식 애플리케이션을 위한 교차 데이터세트 분석과 신경망 아키텍처 수리를 수행합니다. 제공된 아키텍처인 ERFCondLaneNet은 복잡한 형상의 차선을 탐지하는 데 어려움을 겪는 기존의 CondLaneNet을 개선한 것입니다.

- **Technical Details**: 이 연구에서 제안하는 ERFCondLaneNet은 CondLaneNet [liu_condlanenet_2021]과 ERFNet [romera_erfnet_2018]을 통합하여 만들어졌으며, Transfer Learning (TL) 프로토콜을 사용하여 두 가지 주요 차선 탐지 벤치마크인 CULane과 CurveLanes에서 테스트되었습니다. 이 기술은 성능을 유지하면서도 33% 적은 특징을 사용하여 모델 크기를 46% 줄였습니다.

- **Performance Highlights**: ERFCondLaneNet은 ResnetCondLaneNet과 비슷한 성능을 보이며, 이는 복잡한 지형을 가진 차선 탐지에서  충분한 정확성을 유지합니다. 학습 과정에서 기존 모델보다 적은 데이터로도 우수한 결과를 보여줍니다.



### Differential Privacy Regularization: Protecting Training Data Through Loss Function Regularization (https://arxiv.org/abs/2409.17144)
- **What's New**: 본 논문에서는 Neural Network 기반의 머신러닝 모델이 민감한 정보를 노출하지 않도록 하기 위해 기존의 DP-SGD(Differentially Private Stochastic Gradient Descent) 알고리즘의 효율성을 개선한 새로운 정규화 전략인 PDP-SGD를 제안하였다.

- **Technical Details**: 본 연구는 PDP-SGD라는 새로운 접근 방식을 통해 손실 함수의 정규화로 차별적 프라이버시(Differential Privacy)를 구현할 수 있음을 보여준다. PDP-SGD는 네트워크 파라미터와 입력값에 직접적으로 의존하는 정규화 항을 포함하여 기울기 누출(Gradient Leakage) 공격에 대한 방어를 구현한다.

- **Performance Highlights**: PDP-SGD는 Gaussian noise의 명시적 도입 없이도 효율적으로 동작하며, 기존 DP-SGD가 직면했던 정확도 저하 문제를 완화하는 가능성을 제시한다. 또한 이 방식은 컴퓨팅 비용을 줄이는 데에도 기여할 수 있다.



### PACE: marrying generalization in PArameter-efficient fine-tuning with Consistency rEgularization (https://arxiv.org/abs/2409.17137)
Comments:
          Accepted by NeurIPS 2024 as a spotlight. This preliminary version will soon be extended with the experiments and analyses from the rebuttal

- **What's New**: 본 연구는 Parameter-Efficient Fine-Tuning (PEFT) 방법의 일반화 문제를 해결하기 위해 새로운 접근 방식을 제안합니다. PACE라는 방법은 작은 gradient norm과 대규모 데이터셋의 관계를 이론적으로 연결하고, 이를 통해 fine-tuned 모델의 일반화를 향상시키는 것을 목표로 합니다.

- **Technical Details**: PACE는 두 가지 주요 전략을 결합합니다. 첫째, ADAPT에 의해 학습된 feature에 대해 multiplicative noise를 적용하여 perturbation을 일으킵니다. 둘째, 다양한 perturbation 아래에서 fine-tuned 모델의 출력이 일관되게 유지되도록 합니다. 이를 통해 gradient regularization이 강화되어 모델의 일반화 성능이 향상됩니다.

- **Performance Highlights**: PACE는 VTAB-1k, FGVC, few-shot learning, domain adaptation 등 4가지 비주얼 적응 작업에서 기존 PEFT 방법들을 능가하는 성과를 보여줍니다. 이 연구는 날로 증가하는 모델의 크기와 복잡성을 관리하는 데 중요한 통찰을 제공합니다.



### Characterizing stable regions in the residual stream of LLMs (https://arxiv.org/abs/2409.17113)
- **What's New**: 이 연구에서는 Transformers의 잔여 스트림(residual stream) 내에서 '안정적인 영역(stable regions)'을 식별하여, 작은 활성화 변화에 무관하게 모델의 출력이 유지되지만, 영역 경계에서 높은 민감도를 보여주는 특성을 발견했습니다. 이러한 안정적인 영역은 훈련 과정 중 나타나며, 모델 크기가 증가함에 따라 더욱 명확하게 정의됩니다. 또한, 이들 영역은 의미론적 구별(semantic distinctions)과 alinh되고, 비슷한 프롬프트가 동일한 영역에 클러스터링되는 경향이 있습니다.

- **Technical Details**: 이 연구는 주로 Transformer의 첫 번째 레이어 이후의 잔여 스트림 활성화 간의 보간(interpolation)을 통해 모델 출력을 측정하는 방식을 채택했습니다. 안정적인 영역은 모델 매개변수에 따라 여러 단계로 분할되며, 작은 변화는 대체로 출력에 미치는 영향이 적지만, 영역의 경계에서는 큰 변화가 발생합니다. 이를 통해 연구자들은 잔여 스트림이 어떻게 구성되는지를 이해하기 위해 50개의 균등 간격의 보간값을 사용하여 L2 거리를 계산했습니다.

- **Performance Highlights**: 실험 결과에 따르면, 의미적으로 유사한 프롬프트는 동일한 안정적인 영역에 속할 가능성이 높며, 모델의 크기가 커질수록 유사한 프롬프트 간의 차이가 줄어드는 경향이 있었습니다. Qwen2 모델의 경우, 유사한 쌍의 보간에서는 선형적 변화가 관찰된 반면, 다른 쌍에서는 급격한 점프가 나타났습니다. 이는 작은 변화가 큰 영향을 미치는 영역 경계에서의 특징을 뒷받침합니다.



### Accumulator-Aware Post-Training Quantization (https://arxiv.org/abs/2409.17092)
- **What's New**: 이 논문에서는 포스트 트레이닝 양자화 (Post-Training Quantization, PTQ) 환경에서 누산기 (accumulator)에 대한 양자화를 정식으로 연구하는 최초의 사례를 제시하고 있습니다. 'AXE'라는 새로운 프레임워크를 도입하여 PTQ 알고리즘에 오버플로우 회피 보장을 추가합니다.

- **Technical Details**: AXE는 기본적으로 레이어 단위로 가중치와 활성화 값의 양자화를 지지하는 알고리즘에 적용할 수 있도록 개발되었습니다. GPFQ 및 OPTQ라는 최신 PTQ 알고리즘 위에 AXE를 구현하면서 다단계 누산 지원을 일반화했습니다. 이는 대형 언어 모델(LLM)에서도 최적화 가능성을 열어줍니다.

- **Performance Highlights**: AXE는 이미지 분류 및 언어 생성 모델을 대상으로 평가되었으며, 누산기 비트 폭과 모델 정확성 간의 트레이드오프에서 기존 방법들에 비해 상당한 개선을 보여주었습니다. 특히, 다단계 누산을 목표로 할 때 Pythia 모델 세트에서 뛰어난 확장성을 입증하였습니다.



### Locally Regularized Sparse Graph by Fast Proximal Gradient Descen (https://arxiv.org/abs/2409.17090)
Comments:
          Accepted by UAI2023

- **What's New**: 이 논문에서는 Support Regularized Sparse Graph(SRSG)라는 새로운 데이터 클러스터링 기법을 제안합니다. 기존의 vanilla sparse graph는 각 데이터의 기하학적 정보를 별도로 고려하지 않아 한계가 있었으나, SRSG는 데이터의 지역 기하 구조를 반영하기 위해 지역 평활성을 장려합니다.

- **Technical Details**: SRSG는 잘 정의된 support regularization term을 사용하여 인접한 데이터 포인트의 이웃 간에 지역 평활성을 촉진합니다. 이 논문에서는 non-convex optimization 문제를 해결하기 위한 Fast Proximal Gradient Descent with Support Projection(FPGD-SP)라는 효율적이고 검증된 최적화 알고리즘을 제안합니다. FPGD-SP는 비부드러운 비볼록 문제에도 불구하고 Nesterov의 최적 수렴 속도를 달성합니다.

- **Performance Highlights**: 다양한 실제 데이터 세트에 대해 수행된 광범위한 실험 결과는 SRSG가 다른 경쟁 클러스터링 방법들에 비해 우수한 성능을 발휘한다는 것을 보여줍니다. 이를 통해 SRSG가 특히 고차원 데이터 클러스터링에서 뛰어난 결과를 내는 것을 입증했습니다.



### Efficient Feature Interactions with Transformers: Improving User Spending Propensity Predictions in Gaming (https://arxiv.org/abs/2409.17077)
Comments:
          6 pages, 3 figures

- **What's New**: Dream11의 사용자 지출 성향 예측 문제를 다루며, 새로운 딥러닝 아키텍처를 제안하여 기존 모델보다 우수한 성능을 보임.

- **Technical Details**: 제안하는 Proximity-Aware Contextual Transformer는 FT-Transformer를 기반으로 하며, 사용자와 게임 특성 간의 복잡한 상관관계를 캡처하기 위해 설계됨. 과거 거래 데이터를 기반으로 사용자 지출 성향을 예측하기 위한 함수 f를 학습하여 손실 함수 L을 최소화하고, 대규모 데이터셋에서의 모델의 일반화 능력을 강화하고자 함.

- **Performance Highlights**: 제안된 모델은 FT-Transformer에 비해 MAE(Mean Absolute Error)를 2.5%, MSE(Mean Squared Error)를 21.8% 개선함.



### Predictive Covert Communication Against Multi-UAV Surveillance Using Graph Koopman Autoencoder (https://arxiv.org/abs/2409.17048)
- **What's New**: 이 논문은 다중 드론 감시 환경에서의 저확률 탐지(LPD) 통신을 위한 새로운 프레임워크인 예측 은닉 통신(predictive covert communication)을 제안합니다. 이는 드론의 위치 예측을 기반으로 네트워크 노드의 송신 전력을 전략적으로 제어하여 탐지 가능성을 최소화합니다.

- **Technical Details**: 제안된 방법은 그래프 신경망(Graph Neural Networks)과 쿠프만 이론(Koopman theory)을 통합하여 복잡한 다중 드론 네트워크 내에서의 상호작용을 모델링하며, 제한된 데이터로도 비선형 동역학을 선형화하여 장기 예측을 가능하게 합니다. 논문에서는 또한 시스템 모델과 문제 정의를 명확하게 제시하고 있습니다.

- **Performance Highlights**: 시뮬레이션 결과에 따르면, 제안된 방법으로 예측된 궤적은 기존의 잘 알려진 최첨단 기법들과 비교할 때 63%에서 75% 낮은 탐지 확률을 보였으며, 이는 실질적인 저지연 은닉 작업을 가능하게 함을 보여주고 있습니다.



### Counterfactual Token Generation in Large Language Models (https://arxiv.org/abs/2409.17027)
- **What's New**: 이번 연구에서는 대규모 언어 모델(LLM)이 출력의 대안에 대해 반사실적 추론(counterfactual reasoning)을 수행할 수 있도록 하는 causal 모델을 개발했습니다. 이는 무작위 샘플링(sampling) 과정에 Gumbel-Max 구조적 인과 모델을 적용하여 구현됩니다.

- **Technical Details**: 제안한 모델은 Llama 3 8B-instruct에서 구현되었으며, 기존의 노드 상태를 유지하지 않는 상태 비저장(stateless) LLM에서 출발하여 반사실적 토큰 생성(counterfactual token generation)을 가능하게 합니다. 이를 통해 모델은 입력된 프롬프트에 따라 자동 회귀(auto-regressive) 생성 방식을 사용하여 가능한 대안을 탐색할 수 있습니다.

- **Performance Highlights**: 반사실적 토큰 생성의 질과 양을 분석한 결과, 모델이 생성한 결과는 기존 출력과 높은 유사성을 보여주었으며, 바이어스 탐지에 대한 유용성도 입증되었습니다. 이 연구는 LLM이 어떻게 세상 모델을 구성하는지에 대한 통찰력을 제공합니다.



### CombU: A Combined Unit Activation for Fitting Mathematical Expressions with Neural Networks (https://arxiv.org/abs/2409.17021)
- **What's New**: 이 논문에서는 Combined Units activation (CombU)라는 새로운 활성화 함수 전략을 소개합니다. 이는 서로 다른 차원에서 다양한 활성화 함수를 조합하여 활용하는 접근법입니다.

- **Technical Details**: CombU는 ReLU, ELU, NLReLU와 같은 여러 활성화 함수를 조합하여 신경망의 각 층에서 각기 다른 차원의 출력을 활성화합니다. 이론적으로, 이 조합은 일반적인 수학적 표현을 완벽하게 적합시키는 가능성을 지니고 있습니다.

- **Performance Highlights**: CombU는 16개의 메트릭 중 10개에서 SOTA 활성화 함수들과 비교하여 뛰어난 성능을 보였고, 나머지 6개 메트릭에서도 상위 3위 내에 랭크되었습니다. 수학적 표현 이해 및 분류와 회귀, 생성 작업에서 우수한 성능을 입증하였습니다.



### INT-FlashAttention: Enabling Flash Attention for INT8 Quantization (https://arxiv.org/abs/2409.16997)
- **What's New**: 본 논문에서는 FlashAttention과 양자화 방법을 통합한 첫 번째 INT8 양자화 아키텍처인 INT-FlashAttention을 소개합니다. 이 아키텍처는 Amplere GPU에서 FlashAttention의 추론 속도를 크게 향상시킵니다.

- **Technical Details**: INT-FlashAttention은 INT8 활성화 및 일반 행렬 곱셈 (GEMM) 커널을 사용하여 구성된 최적의 프로토타입으로, 첫 번째 완전 INT8 입력을 가지는 어텐션 연산자입니다. INT-FlashAttention은 훈련 후 양자화(p스트레이닝(quantization)) 구조로, 다른 데이터 형식인 INT4와 호환됩니다.

- **Performance Highlights**: 실험 결과, INT-FlashAttention은 FlashAttention-FP16 대비 72% 빠른 추론 속도를 달성하였고, FlashAttention-FP8 대비 최대 82% 더 작은 양자화 오류를 보였습니다.



### What is the relationship between Slow Feature Analysis and the Successor Representation? (https://arxiv.org/abs/2409.16991)
Comments:
          52 pages, 5 figures

- **What's New**: 본 논문은 Slow Feature Analysis (SFA)와 Successor Representation (SR)의 분석적 비교를 통해 두 기법의 연결성을 탐구합니다. 이는 분야가 다른 두 기법이지만, 수학적 구조 및 민감한 정보 측면에서 중요한 유사성을 공유하고 있음을 밝혀냅니다.

- **Technical Details**: SFA는 시간별 데이터에서 차원 축소를 위해 고안된 비지도 학습 방법이며, SFA 알고리즘의 여러 변형을 분석합니다. 이 연구에서는 Markov Decision Process (MDP) 설정에서의 SFA의 적용을 다루며, SR과 관련된 고유값 문제를 포함합니다.

- **Performance Highlights**: SFA를 사용하여 SR과 관련된 장소 및 그리드 유사 필드를 생성할 수 있음을 입증하며, 그리드 월(gridworld) 환경에서 실험적으로 확인했습니다. 이로 인해 SFA와 SR 간의 직접적인 연결이 가능함을 보여줍니다.



### Bridge to Real Environment with Hardware-in-the-loop for Wireless Artificial Intelligence Paradigms (https://arxiv.org/abs/2409.16968)
- **What's New**: 이번 논문에서는 자율 주행 차량(VANET)의 무선 표준 IEEE802.11p를 개선하기 위해 개발된 하드웨어-인-더-루프(hardware-in-the-loop, HIL) 테스트베드를 소개합니다. 이 시스템은 모의 및 실제 환경에서 인공지능(AI) 알고리즘과 LiDAR 데이터 등 여러 서비스를 테스트할 수 있는 기회를 제공합니다.

- **Technical Details**: 테스트베드는 OMNet++, Python, UDP 서버/클라이언트, 로봇 운영 체제(Robotic Operation Systems, ROS)를 사용하여 개발되었습니다. 이 접근 방식은 실제 기기를 모의 환경에 통합하여 제품이나 솔루션을 시장에 내놓는 데 필요한 시간과 비용을 줄이는 데 중점을 두고 있습니다.

- **Performance Highlights**: 테스트 결과는 지연(delay)과 처리량(throughput) 측면에서 평가되었으며, 두 가지 서비스인 LiDAR 데이터와 비디오 데이터를 이용한 실험의 효과를 입증했습니다.



### ABCFair: an Adaptable Benchmark approach for Comparing Fairness Methods (https://arxiv.org/abs/2409.16965)
- **What's New**: 이 논문에서는 머신러닝에서의 편향(bias) 완화를 위한 다양한 방법들이 존재하지만, 각 방법들이 다루는 문제의 설정이 뚜렷하게 다르다는 것을 강조합니다. 이러한 차이를 극복하기 위해 ABCFair라는 새로운 벤치마크 접근법을 제안하고, 이 방법은 실제 문제 설정에 적응할 수 있도록 설계되었습니다.

- **Technical Details**: ABCFair는 데이터(Data), 공정성 방법(FairnessMethod), 평가자(Evaluator)의 세 가지 유연한 구성 요소를 통해 다양한 요구를 충족할 수 있습니다. 10개의 방법, 7개의 공정성 개념, 3가지 민감한 특성 형식, 2가지 출력 분포 형식에서 벤치마킹을 통해 검증되었습니다.

- **Performance Highlights**: ABCFair의 성과는 편향 완화 방법의 공정성-정확성(trade-off)과 관련된 주요 질문에 도전할 수 있는 기회를 제공합니다. 이는 특히 이중 레이블 데이터셋을 통해 성과를 평가할 때 유용하며, 실제로 이중 레이블 데이터셋을 벤치마킹에 사용한 최초의 연구로 자리 잡습니다.



### Decomposition of Equivariant Maps via Invariant Maps: Application to Universal Approximation under Symmetry (https://arxiv.org/abs/2409.16922)
- **What's New**: 이 논문은 그룹 G에 관한 불변(invariant) 및 변환(equivariant) 맵 간의 관계에 대한 이론을 개발하고, 이를 딥러닝 네트워크에 적용하여 새로운 통찰을 제공합니다. 특히, 변환 맵과 일부 불변 맵 간의 일대일 대응 관계를 확립하여, 변환 맵 문제를 불변 맵 문제로 축소할 수 있게 합니다.

- **Technical Details**: 이 논문에서 제안된 이론은 주어진 그룹 G가 작용하는 집합에 대해 G-equivariant 맵과 특정 stabilizer 서브그룹 H_i의 G-invariant 맵 간의 일대일 대응이 존재한다는 것입니다. 이 관계를 통해 우리는 G-equivariant와 G-invariant 네트워크의 복잡성을 비교하고, ReLU 활성화 함수를 사용하는 G-equivariant 딥러닝 네트워크의 근사 속도를 제공합니다.

- **Performance Highlights**: 제안된 불변 맵과 변환 맵 간의 관계를 활용하여, 우리는 기존의 불변 아키텍처에서 변환 아키텍처를 만들어낼 수 있는 방법을 보여줍니다. 우리의 모델은 기존의 전통적인 모델과는 다르지만, 매개변수 수가 이들과 비교하여 매우 적을 수 있음을 강조합니다. 또한, G-equivariant 및 G-invariant 네트워크의 근사 속도를 제시하며, 이는 머신러닝의 다양한 응용 분야에서 중요한 임팩트를 줄 수 있습니다.



### Discriminative Anchor Learning for Efficient Multi-view Clustering (https://arxiv.org/abs/2409.16904)
Comments:
          This work has been accepted by TMM

- **What's New**: 이 논문에서는 Multi-view clustering을 위한 차별적 앵커 학습(discriminative anchor learning)을 제안하여 기존 방법의 단점을 해결하고자 했다. 이 방법은 각 뷰(view)에 대한 차별적(feature) 표현을 학습하고, 이를 통해 공유 앵커 그래프(shared anchor graph)의 품질을 향상시키며, 앵커 간의 보완적(complementary) 정보도 고려한다.

- **Technical Details**: 차별적 앵커 학습(discriminative anchor learning for multi-view clustering, DALMC) 방식은 원본 데이터셋을 기준으로 각 뷰에 대해 차별적 feature representation을 학습하고, 이를 바탕으로 합동 앵커 그래프(consensus anchor graph)를 구축한다. 이 과정은 차별적 feature 학습과 앵커 그래프 구축을 통합하여 서로 개선될 수 있도록 한다. 또한 최적 앵커(anchors)와 합동 앵커 그래프는 직교 제약조건(orthogonal constraints)을 통해 학습된다.

- **Performance Highlights**: 다양한 데이터셋에 대한 실험 결과, DALMC는 기존 방법들에 비해 효율성과 효과성을 입증했다. 이 알고리즘은 선형 시간 복잡도를 가지며, 대규모 데이터셋을 효율적으로 처리할 수 있는 능력을 보여준다.



### Revisiting Space Mission Planning: A Reinforcement Learning-Guided Approach for Multi-Debris Rendezvous (https://arxiv.org/abs/2409.16882)
Comments:
          Accepted for publication at the 2024 International Conference on Space Robotics (iSpaRo)

- **What's New**: 이 연구는 우주 쓰레기 탐방의 효율적인 순서를 결정하기 위해 심층 강화 학습(deep reinforcement learning) 분야의 masked Proximal Policy Optimization(PPO) 알고리즘을 도입합니다. 목표는 주어진 모든 쓰레기를 방문하는 최적의 순서를 찾고, 이를 통해 전체 미션의 총 소요 시간을 최소화 하는 것입니다.

- **Technical Details**: 이 연구에서는 신경망(neural network) 정책을 개발하고, 다양한 쓰레기 환경에서 시뮬레이션된 우주 미션을 통해 훈련합니다. 훈련 후에 신경망은 Izzo의 Lambert 기법을 사용해 최적의 경로를 계산하며, 강화 학습 접근법을 통해 계획 효율성이 크게 향상되었습니다. 기존의 유전 알고리즘(Genetic algorithm)과 탐욕 알고리즘(Greedy algorithm)과 비교하여 각각 약 10.96%와 13.66%의 미션 시간을 줄이는 데 성공했습니다.

- **Performance Highlights**: 이 모델은 다양한 시뮬레이션 시나리오에서 쓰레기 방문의 가장 시간 효율적인 순서를 식별하며, 가장 빠른 계산 속도로 결과를 도출합니다. 이는 우주 쓰레기 제거를 위한 미래의 미션 계획 전략을 향상시키는데 기여할 것으로 기대됩니다.



### Risk-averse learning with delayed feedback (https://arxiv.org/abs/2409.16866)
- **What's New**: 이 논문에서는 딜레이(Delay)를 고려한 위험 회피 학습(Risk-averse Learning)을 조사합니다. 구체적으로는, Conditional Value at Risk (CVaR)를 위험 측정 수단으로 사용하며, 알려지지 않았지만 제한된 지연(Delayed Feedback)과 함께 적용 가능한 두 가지 위험 회피 학습 알고리즘을 개발했습니다.

- **Technical Details**: 저자들은 원 포인트(One-point) 및 투 포인트(Two-point) 제로 스텝 최적화 방법을 기반으로 한 두 가지 알고리즘을 제안합니다. 이 알고리즘들은 총 샘플 수(Total Samplings)와 누적 지연(Cumulative Delay)에 따른 결과를 분석합니다. 특히, 투 포인트 위험 회피 학습 방식이 원 포인트 방식보다 더 낮은 후회도(Regret Bound)를 달성하는 것으로 나타났습니다.

- **Performance Highlights**: 실험 결과, 원 포인트 알고리즘은 특정 지연 조건 하에서 서브리니어(Subliner) 후회도를 달성하고, 투 포인트 알고리즘은 지연에 대해 높은 내성을 보여주며 최소한의 제약 조건에서 서브리니어 후회도를 달성합니다. 특히, 다이나믹 가격 책정 문제에 대한 수치 실험을 통해 제안된 알고리즘의 성능을 입증했습니다.



### Demo2Vec: Learning Region Embedding with Demographic Information (https://arxiv.org/abs/2409.16837)
- **What's New**: 이 연구에서는 사회적, 경제적 맥락을 반영하는 인구 통계 데이터(예: 소득, 교육 수준 등)를 사용하여 지역 임베딩(region embedding)의 품질을 향상시키고, 다양한 도시 예측 작업에서 성능을 개선할 수 있는 가능성을 제시합니다.

- **Technical Details**: 지역 임베딩을 생성하기 위해 Jenson-Shannon (JS) Divergence를 손실 함수로 사용하여 다중 관점(multi-view) 표현 학습을 수행하고, 뉴욕과 시카고의 데이터에서 소득 정보를 포함함으로써 지역 임베딩 학습 성능을 10.22% 향상시키는 효과를 확인했습니다. 이 연구에서는 지역 간 상관 관계를 통합하는 그래프 기반(greph-based) 학습을 활용합니다.

- **Performance Highlights**: 모빌리티 + 소득의 조합이 기존 모델보다 예측 성능에서 최대 10.22% 향상된 것으로 나타났으며, 지역 임베딩 학습에서 인구 통계적 특성이 중요한 요소임을 입증했습니다.



### Asynchronous Fractional Multi-Agent Deep Reinforcement Learning for Age-Minimal Mobile Edge Computing (https://arxiv.org/abs/2409.16832)
- **What's New**: 본 논문은 사이버 물리 시스템(Cyber-Physical Systems, CPS) 내의 실시간 네트워킹 애플리케이션에서 정보의 적시성을 측정하는 중요한 메트릭인 정보의 나이(Age of Information, AoI)를 최적화하는 새로운 접근법을 제안합니다. 이를 위해, 태스크 업데이트 및 오프로드 정책을 공동으로 최적화하여 AoI를 최소화하는 프레임워크를 개발했습니다.

- **Technical Details**: 연구에서는 모바일 에지 컴퓨팅(Mobile Edge Computing, MEC) 시스템에서의 컴퓨팅 집약적인 업데이트의 적시성을 조사하고, 분수 강화 학습(Fractional Reinforcement Learning, RL) 프레임워크를 설계하여 동적 에지 로드와 작업 스케줄링 문제를 해결합니다. 또한 비동기 결정 문제를 해결하기 위해 비동기 모델 프리 분수 다중 에이전트 RL 알고리즘을 개발하였습니다.

- **Performance Highlights**: 제안된 알고리즘은 실험을 통해 기존의 베이스라인 알고리즘과 비교하여 평균 AoI를 최대 52.6% 감소시켰으며, 다양한 성과 지표에서 성능 향상을 보여줍니다.



### Learning phase-space flows using time-discrete implicit Runge-Kutta PINNs (https://arxiv.org/abs/2409.16826)
Comments:
          10 pages, 4 figures, published in the International Conference on Scientific Computing and Machine Learning, see this http URL

- **What's New**: 본 연구에서는 고차원 함수형 비선형 결합 미분 방정식의 위상 공간 솔루션을 얻기 위한 계산 프레임워크를 제시합니다. 이를 위해 High-order Implicit Runge-Kutta Physics-Informed Neural Networks (IRK-PINNs) 방식을 사용하였습니다.

- **Technical Details**: 기존의 미분 방정식 해법을 바탕으로 하여, 좌표가 함수로 처리되는 맥락으로의 스킴을 수정하였습니다. 이 수정은 외부 필드에서 입자의 운동 방정식을 효율적으로 해결할 수 있도록 해줍니다.

- **Performance Highlights**: 우리의 접근 방식을 활용하여, 중심 힘 필드에 위치한 질량 입자와 주기적인 전기 필드에서의 하전 입자의 운동 방정식을 성공적으로 해결하였습니다.



### Uncertainty Representations in State-Space Layers for Deep Reinforcement Learning under Partial Observability (https://arxiv.org/abs/2409.16824)
- **What's New**: 이 논문은 기대되는 수익을 극대화하기 위해 모델-프리 아키텍처 내에서 훈련된 스탠드얼론 Kalman 필터 레이어를 제안합니다. 이 레이어는 숨겨진 상태 표현의 불확실성을 포함할 수 있는 내부 메커니즘을 갖추고 있습니다.

- **Technical Details**: Kalman 필터 레이어는 선형 상태 공간 모델에서 닫힌 형태의 Gaussian 추론을 수행하며, 시퀀스 길이에 대해 로그적으로 확장 가능합니다. 이 레이어는 표준 모델-프리 아키텍처의 다른 순환 레이어와 쉽게 교체 가능하며, 잠재 상태 표현의 확률적 필터링을 위한 명시적 메커니즘을 포함합니다.

- **Performance Highlights**: 다양한 POMDP 문제에서 실시된 실험 결과, Kalman 필터 레이어는 의사결정에서 불확실성 추론이 중요한 문제에서 다른 상태 기반 모델보다 우수한 성능을 발휘하였습니다.



### A parametric framework for kernel-based dynamic mode decomposition using deep learning (https://arxiv.org/abs/2409.16817)
- **What's New**: 이 논문에서는 kernel 기반의 동적 모드 분해(dynamic mode decomposition, DMD) 방법을 위한 parametric framework를 제안합니다. 이 프레임워크는 LANDO 알고리즘을 기반으로 하며, 오프라인과 온라인 두 단계로 구성되어 있습니다.

- **Technical Details**: 먼저, 오프라인 단계에서는 주어진 훈련 데이터로부터 시스템의 동역학을 모사하는 LANDO 모델을 준비합니다. 그 다음, 온라인 단계에서는 이 모델을 활용하여 특정 시간에서 새로운 데이터를 생성하고, deep learning 기술을 사용하여 파라미터와 상태 간의 매핑을 근사합니다. 또한, 계산 비용을 줄이기 위해 차원 축소 기법을 사용합니다.

- **Performance Highlights**: 세 가지 수치 예제(롯카-볼테라 모델, 열 방정식, 반응-확산 방정식)를 통해 제안된 프레임워크의 효율성과 효과성을 입증합니다.



### Accelerating TinyML Inference on Microcontrollers through Approximate Kernels (https://arxiv.org/abs/2409.16815)
- **What's New**: 이번 연구는 마이크로컨트롤러(Microcontroller) 기반 IoT 기기의 성능 개선을 위해 근사 컴퓨팅(Approximate Computing)과 소프트웨어 커널 디자인(Kernel Design)을 결합한 새로운 접근 방식을 제안합니다.

- **Technical Details**: 본 연구는 커널 기반 근사 프레임워크를 사용하여 각 합성곱 레이어의 피연산자(Operands)를 언팩(Unpack)하고, 각 피연산자의 중요성을 결정하기 위한 오프라인 계산을 수행합니다. 이후, 계산된 중요도를 바탕으로 계산 생략(Computation Skipping) 근사 전략을 적용합니다. 이 방법은 STM32-Nucleo 보드에서 두 가지 인기 있는 CNN 모델을 사용해 시험되었습니다.

- **Performance Highlights**: 시험 결과, 최신 기술에 비해 평균 21%의 대기시간(Latency) 감소를 달성했으며, Top-1 분류 정확도(Classification Accuracy)의 저하 없이 성능 향상을 이루었습니다. 더 낮은 정확도 요구사항의 경우, 대기시간 감소 효과는 더욱 두드러지게 나타났습니다.



### Scalable Ensemble Diversification for OOD Generalization and Detection (https://arxiv.org/abs/2409.16797)
Comments:
          Under review

- **What's New**: 본 연구는 Scalable Ensemble Diversification (SED)라는 새로운 방법론을 제시하여 기존의 다양한 앙상블 학습 방법의 한계를 극복합니다. 특히, OOD 샘플 없이도 대규모 데이터에서 효과적으로 적용할 수 있는 방식으로 설계되었습니다.

- **Technical Details**: SED는 세 가지 주요 기술적 혁신을 통해 발전되었습니다: (1) 하드 샘플을 동적으로 식별하여 모델 간의 불일치를 유도합니다. (2) 각 반복에서 무작위로 선택된 두 모델에 대해서만 다양화 목표를 적용하여 계산 비용을 줄입니다. (3) 네트워크의 출력 근처의 일부 레이어에만 영향을 미치도록 하여 심층 네트워크에서의 다양화 목표를 조정합니다.

- **Performance Highlights**: ImageNet에서의 실험을 통해 SED의 다양한 이점을 확인했습니다. OOD 일반화와 OOD 탐지 모두에서 성능이 상당히 향상되었으며, Predictive Diversity Score (PDS) 방법론은 OOD 샘플 탐지에서 기존 방법들을 초월하는 성능을 보였습니다.



### Symbolic State Partition for Reinforcement Learning (https://arxiv.org/abs/2409.16791)
- **What's New**: 본 논문은 연속 상태 공간에서 직접적으로 작동할 수 없는 테이블 기반 강화 학습(tabular reinforcement learning) 방법의 문제를 다룹니다. 이 문제의 해결책 중 하나는 상태 공간을 분할(partition)하는 것입니다. 이 연구에서는 환경 동역학(dynamics)을 기반으로 상징적 실행(symbolic execution)을 통해 분할을 추출하는 방법을 제안합니다.

- **Technical Details**: 상징적 분할(symbolic partitioning)은 비선형 관계(nonlinear relations)가 있는 상태 구성 요소 간의 근사화가 학습 과정에서 해롭다는 점을 충분히 고려합니다. 이상적인 분할은 가능한 한 거칠게(coarse) 하면서도 주어진 문제의 상태 공간의 핵심 구조(key structure)를 포착할 수 있어야 합니다.

- **Performance Highlights**: 상징적 분할을 통해 강화 학습이 드문 보상(sparse rewards) 상황에서도 성능이 향상된다는 것을 보였습니다. 논문에서는 정밀도(precision), 확장성(scalability), 학습 에이전트 성능(performance), 학습된 정책의 상태 공간 커버리지(state space coverage) 측면에서 평가를 수행하였습니다.



### Enhancing Feature Selection and Interpretability in AI Regression Tasks Through Feature Attribution (https://arxiv.org/abs/2409.16787)
- **What's New**: 이 연구는 Explainable Artificial Intelligence (XAI) 분야의 feature attribution 방법을 활용하여 회귀 문제에서 입력 데이터의 비정보적 특징을 필터링하고, 예측의 정확도 및 안정성을 높이는 방법을 제안합니다.

- **Technical Details**: 연구자들은 Integrated Gradients (IG)와 k-means 클러스터링을 결합한 feature selection pipeline을 도입했습니다. 이 방법은 실제 산업 문제인 터보 기계 개발 과정에서 블레이드 진동 분석에 적용되었습니다. IG는 gradient 기반의 모델 독립적 접근법으로, 이전에 회귀 문제에서 사용된 바 있습니다.

- **Performance Highlights**: 이 접근법은 생성된 투명한 더미 데이터에서 실험을 통해 효과를 검증한 후, 실제 문제에 적용되었습니다. 제안된 방법은 established baseline feature selection 방법 및 KernelShap과 비교되었습니다.



### Super Level Sets and Exponential Decay: A Synergistic Approach to Stable Neural Network Training (https://arxiv.org/abs/2409.16769)
- **What's New**: 본 논문에서는 신경망 최적화 프로세스를 향상시키기 위해 동적인 학습률 알고리즘을 개발하였습니다. 이 알고리즘은 지수적 감소(exponential decay)와 고급 과적합 방지 전략을 통합하여 최적화의 안정성을 높입니다. 또한, 이론적 프레임워크를 수립하여 Lyapunov 안정성 원리를 통해 손실 함수의 초레벨 집합(superlevel sets)의 연결성을 보장합니다.

- **Technical Details**: 이 논문은 동적 학습률(dynamic learning rate)과 손실 함수의 초레벨 집합(superlevel set) 간의 수학적 관계를 탐구합니다. 지수적 감소에 기반한 학습률 ‌η(t)=η₀e^{-αt} 모델을 통해 최적화 경로의 연결성을 유지하며, 불안정한 지역에 갇히지 않도록 합니다. 이를 통해 안정적이고 효율적인 최적화를 달성하는 방법을 제시합니다.

- **Performance Highlights**: 이 연구는 신경망 훈련 과정에서 에러를 최소화하면서 과적합(overfitting)을 방지하는 데 효과적입니다. 제안된 알고리즘은 더 나은 일반화 능력을 제공하며, 다양한 데이터 환경에서 일관된 안정성을 유지하여 신뢰성을 높입니다.



### Interpreting Deep Neural Network-Based Receiver Under Varying Signal-To-Noise Ratios (https://arxiv.org/abs/2409.16768)
Comments:
          7+1 pages, 8 figures

- **What's New**: 이 연구는 신경망, 특히 컨볼루션 신경망 기반 수신기 모델을 해석하기 위한 새로운 방법을 제안합니다. 이 방법은 모델의 어떤 유닛이 관심 있는 채널 매개변수에 대한 정보를 가장 많이(또는 가장 적게) 포함하는지를 식별하여, 전반적(global) 및 개별적(local) 수준의 통찰을 제공합니다.

- **Technical Details**: 주요 기술적인 세부사항으로, 제안된 방법은 Mutual Information (MI)을 추정하는 메커니즘을 포함하고 있으며, 고차원 설정에서도 견고한 추정이 가능합니다. 딥 신경망 기반 수신기 모델의 활성화(activation)를 사용하여 채널 매개변수를 예측하는 설명자 모델(explainer model)을 훈련시키고, 이 모델의 예측 성능을 평가함으로써 해석을 수행합니다.

- **Performance Highlights**: 실험 결과, 제안된 방법은 DeepRx 모델이 SNR 신호 처리에서 어떤 유닛이 가장 많은 정보를 포함하는지를 효과적으로 식별하는 데 성공했습니다. 추가적으로, 이 방법은 학습 데이터에 크게 의존하지 않으며, 모델의 예측 성능에 안정적인 결과를 보였습니다.



### Exploring Information-Theoretic Metrics Associated with Neural Collapse in Supervised Training (https://arxiv.org/abs/2409.16767)
Comments:
          arXiv admin note: substantial text overlap with arXiv:2406.03999

- **What's New**: 이 논문에서는 매트릭스 엔트로피(matrix entropy)와 상호 정보(mutual information) 같은 정보 이론적 메트릭(metrics)을 활용하여 감독 학습(supervised learning)을 분석합니다.

- **Technical Details**: 데이터 표현(data representations)과 분류 헤드 가중치(classification head weights)의 정보 콘텐츠 및 감독 학습 동안의 정보 상호 작용을 탐구합니다. 새로운 메트릭으로는 매트릭스 상호 정보 비율(matrix mutual information ratio, MIR)과 매트릭스 정보 엔트로피 차이 비율(matrix information entropy difference ratio, HDR)을 제안합니다.

- **Performance Highlights**: HDR와 MIR은 감독 학습(supervised learning)과 반감독 학습(semi-supervised learning)의 성능을 향상시키는 데 효과적임을 보여줍니다.



### Offline and Distributional Reinforcement Learning for Radio Resource Managemen (https://arxiv.org/abs/2409.16764)
- **What's New**: 이 논문은 기존의 온라인 강화 학습(online RL) 방식에서 오프라인 및 분포적 강화 학습(off-line and distributional RL)을 적용하여 무선 네트워크의 무선 자원 관리(radio resource management, RRM) 문제에 대한 새로운 해결책을 제시합니다.

- **Technical Details**: 제안된 알고리즘은 고정된 데이터셋을 사용하여 환경과의 상호작용 없이 오프라인 학습을 수행하며, 반환(return)의 분포를 고려하여 불확실성을 처리합니다. RRM 문제에 대한 이 접근 방식은 평균 성과만을 고려하는 기존 방법들의 한계를 극복합니다.

- **Performance Highlights**: 모의실험 결과, 제안된 오프라인 및 분포적 RL 알고리즘이 기존의 자원 관리 모델보다 우수한 성능을 보였으며, 온라인 RL보다 16% 높은 성과를 달성했습니다.



### GB-RVFL: Fusion of Randomized Neural Network and Granular Ball Computing (https://arxiv.org/abs/2409.16735)
- **What's New**: 본 논문에서는 랜덤 벡터 기능 링크(RVFL) 네트워크의 문제점을 해결하기 위해, 입력으로 개별 샘플 대신 granular balls (GBs)을 사용하는 GB-RVFL 모델과, GBs의 지리적 구조를 보존하기 위한 graph embedding (GE) 통합 모델인 GE-GB-RVFL을 제안합니다.

- **Technical Details**: GB-RVFL 모델은 GB의 중심 행렬의 역행렬만 필요로하여 확장성을 높이고, GB의 조밀성을 활용하여 노이즈와 이상치에 대한 강인성을 개선합니다. GE-GB-RVFL 모델은 데이터셋의 내재적 기하구조를 보존하면서 GB-RVFL의 핵심 특성을 유지하며, 그래프 정규화 항을 포함하는 방법론을 통합하여 데이터 구조의 세부정보를 보존합니다.

- **Performance Highlights**: GB-RVFL 및 GE-GB-RVFL 모델은 KEEL, UCI, NDC 및 생물의학 데이터셋에서 평가되었으며, 기존의 기준 모델에 비해 우수한 성능을 입증하였습니다. 특히, 실제 생물의학 데이터셋에서도 적용 가능성을 보여주며, 유방암 분류 및 알츠하이머병 분류에서의 향상된 성능을 나타냈습니다.



### Verified Relative Safety Margins for Neural Network Twins (https://arxiv.org/abs/2409.16726)
- **What's New**: 본 논문에서는 두 개의 Deep Neural Network (DNN) 분류기의 강건성을 비교하기 위해 Relative Safety Margins (RSM) 개념을 도입하였습니다. 이 개념은 특성적인 결정 경계를 통해 서로 다른 네트워크의 결정 질을 정량화할 수 있는 방법을 제공합니다. 특히, pruning, quantization, distillation이 적용된 네트워크에서의 이 강건성 분석이 중요하게 다루어집니다.

- **Technical Details**: RSM은 두 개의 DNN 분류기가 동일한 입력과 출력 도메인을 가지면서 의사 결정 시 상대적인 여유(rich margin)를 평가합니다. 또한, Local Relative Safety Margins (LRSM)로 일반화되어, 다양한 perturbations를 고려한 보다 구체적인 분석을 가능하게 합니다. 이를 통해 네트워크 상대의 결정 질에 대한 상하한을 제공하는 프레임워크를 제안합니다.

- **Performance Highlights**: MNIST, CIFAR10과 두 개의 실제 의료 데이터셋을 이용하여 실험을 수행하였고, pruning 및 quantization 기법이 결정의 강건성을 보존하는 데에 취약할 수 있음을 밝혔다. 특히, compact 네트워크가 ‘일반’ 위험과 정상 입력을 신뢰할 수 있게 분류하는 것이 필수적이며, 이 과정에서의 강건성 결여는 환자의 안전을 저해할 수 있음을 강조합니다.



### Numerical Approximation Capacity of Neural Networks with Bounded Parameters: Do Limits Exist, and How Can They Be Measured? (https://arxiv.org/abs/2409.16697)
Comments:
          Universal Approximation; Bounded Weights; Analytic Function; Numerical Span Dimension; Infinite Width Neural Network}

- **What's New**: 이 논문은 제한된 비선형 파라미터 공간에서 심층 신경망(DNN)의 근사 용량에 대한 이론적 연구를 수행하고, 근사 용량의 한계를 정량화하는 새로운 개념인 $	extit{ε outer measure}$ 및 $	extit{Numerical Span Dimension (NSdim)}$을 도입합니다.

- **Technical Details**: 논문에서는 유니버설 근사 정리가 제한된 비선형 파라미터에서 여전히 유효한지의 여부를 질문하며, DNN을 유한한 차원 벡터 공간으로 만 재구성할 수 있는지를 분석합니다. 또한, 백프로파게이션(Back-propagation) 신경망과 무작위 파라미터 네트워크(예: Extreme Learning Machine) 간의 관계를 논의합니다.

- **Performance Highlights**: 딥 뉴럴 네트워크는 계속적인 또는 이산적인 면에서 근사 용량이 유한한 차원 공간에 구속된다는 점에서, 복잡한 함수 근사에 대한 제한을 보이며, 이로 인해 너비와 깊이 간의 균형을 이해하는 데 기여할 수 있습니다.



### Erase then Rectify: A Training-Free Parameter Editing Approach for Cost-Effective Graph Unlearning (https://arxiv.org/abs/2409.16684)
Comments:
          Under review

- **What's New**: 이번 연구에서는 Erase then Rectify (ETR)라는 두 단계의 훈련 없는 접근 방식을 제안하여 효율적이고 확장 가능한 그래프 비학습 (graph unlearning)을 실현했습니다. 이 방법은 특정 노드나 엣지의 영향을 제거하는 데 중점을 두었으며, 기존의 방법들이 필요한 추가 훈련을 하지 않고도 높은 유용성을 유지합니다.

- **Technical Details**: ETR 방법은 두 단계로 구성되어 있습니다. 첫 번째 단계인 Erase에서는 중요한 매개변수를 마스킹하여 비학습 샘플의 영향을 효과적으로 제거합니다. 두 번째 단계인 Rectify에서는 남은 데이터 세트에 대한 모델의 그래디언트를 추정하여 GNN의 성능을 향상시키는 기법을 적용합니다. ETR은 전체 훈련 데이터에 접근하지 않고도 그래프 비학습을 수행할 수 있게 설계되었습니다.

- **Performance Highlights**: ETR은 평균적으로 4583.9배 적은 시간과 4.2배 적은 메모리 사용량을 기록하며 비학습 효율성, 성능, 그리고 유용성 측면에서도 뛰어난 결과를 보였습니다. 이는 대규모 그래프에도 적용가능한 가능성을 제시합니다.



### GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning (https://arxiv.org/abs/2409.16670)
Comments:
          Under review

- **What's New**: 본 논문에서는 다양한 그래프 도메인으로 잘 훈련된 GNN을 전이하기 위한 효과적이고 파라미터 효율적인 방법인 GraphLoRA를 제안합니다. GraphLoRA는 Low-Rank Adaptation (LoRA)의 성공으로부터 영감을 받아 구조 인식 최대 평균 불일치(SMMD)를 도입하여 출처 및 대상 그래프 간의 노드 피쳐 분포의 차이를 줄이는 방법입니다.

- **Technical Details**: GraphLoRA는 구조 인식 최대 평균 불일치(SMMD)를 도입하여 출처와 대상 그래프 간 노드 피쳐 분포의 차이를 최소화하고, 저차원 적응(low-rank adaptation) 방식을 통해 훈련된 GNN과 함께 소규모 훈련 가능 GNN을 삽입하여 구조적 분포의 격차를 메우는 방식으로 구축됩니다. 또한, 구조 인식 정규화 목표를 제안하여 레이블 수가 적은 대상 그래프에 대해 프리트레인 GNN의 적응성을 향상시킵니다.

- **Performance Highlights**: 여섯 개의 실제 데이터세트에 대한 광범위한 실험 결과 GraphLoRA는 20%의 파라미터만 조정하여도 열한 개의 기준선에 비해 뛰어난 성능을 달성하였음을 보여줍니다.



### The Credibility Transformer (https://arxiv.org/abs/2409.16653)
Comments:
          30 pages

- **What's New**: 본 연구에서는 Credibility Transformer라는 새로운 아키텍처를 도입하여 트랜스포머(Transformer) 모델이 테이블 형식의 데이터에서 예측 성능을 극대화할 수 있음을 보였습니다. 이 아키텍처는 특별한 CLS 토큰을 통해 과거 정보와 관찰 정보의 가중 평균을 기반으로 하는 신뢰성 메커니즘을 적용합니다.

- **Technical Details**: Credibility Transformer의 핵심은 특별한 CLS 토큰을 사용하는 것입니다. 이 CLS 토큰은 주어진 데이터의 신뢰성 정보를 인코딩하고, 기존의 Transformer 아키텍처와 결합하여 예측 모델의 성능을 향상시키는 역할을 합니다. 저자는 Bayesian credibility 이론을 바탕으로 두 세트의 정보를 결합하여 신뢰성 기반의 평균을 계산합니다.

- **Performance Highlights**: 본 연구의 Credibility Transformer는 기존의 심층 학습 모델을 초월하는 성능을 보였습니다. 연구 결과에 따르면, 이 새로운 아키텍처는 특히 비즈니스 보험 데이터셋에서 현저하게 높은 예측 성능을 나타냈으며, 기존 모델에 비해 안정적인 학습을 지원합니다.



### Task Addition in Multi-Task Learning by Geometrical Alignmen (https://arxiv.org/abs/2409.16645)
Comments:
          11 pages, 5 figures, Accepted at AI for Science Workshop at 41st International Conference on Machine Learning

- **What's New**: 본 연구에서는 Geometrically Aligned Transfer Encoder (GATE) 알고리즘을 개선하기 위한 새로운 접근법인 task addition을 제안합니다. 이 방법은 한정된 데이터로도 목표 작업의 성능을 높이면서 계산 복잡성을 최소화하도록 설계되었습니다.

- **Technical Details**: GATE 알고리즘은 서로 다른 작업의 잠재 공간(latent space)의 기하학적 형태를 정렬하여 지식을 전달합니다. Task addition 접근법은 대규모 데이터 세트로 초기 지도학습(pre-training)을 통해 수행된 후, 각 목표 작업에 대해 특정 모듈을 추가하고 학습하는 방식으로 진행됩니다. 이 방식은 기존 다중 작업(multi-task) 방법보다 계산 비용 측면에서 효율성을 높입니다.

- **Performance Highlights**: 실험 결과, task-added GATE가 단일 작업 학습(SINGLE) 및 다중 작업 학습(MTL) 방법보다 뛰어난 성능을 보여주었으며, 학습 시간 또한 MTL 모델을 처음부터 학습하는 것보다 유의미하게 빠른 것으로 나타났습니다.



### Functional Stochastic Gradient MCMC for Bayesian Neural Networks (https://arxiv.org/abs/2409.16632)
- **What's New**: 이 논문은 Bayesian Neural Networks (BNNs)에서 기능 공간으로의 확장된 SGMCMC (Stochastic Gradient Markov Chain Monte Carlo) 방법을 제안합니다. 이를 통해 정보가 더 풍부한 기능 사전 분포를 통합할 수 있습니다.

- **Technical Details**: 기능 SGMCMC는 제안된 새로운 확산 동역학(dynamics)을 기반으로 하며, 이는 Itô 보조정리를 사용하여 설계되었습니다. 이 새로운 동역학의 정지 분포는 함수에 대한 목표 후방 분포(target posterior distribution)임을 증명합니다.

- **Performance Highlights**: 제안된 방법은 여러 벤치마크 작업에서 기존의 매개변수 공간 SGMCMC 및 매개변수 및 기능 공간 변분 추론(method)보다 향상된 예측 성능(accuracy)과 불확실성 추정(uncertainty quantification)을 보여줍니다.



### Stochastic Subsampling With Average Pooling (https://arxiv.org/abs/2409.16630)
Comments:
          17 pages, 8 figures

- **What's New**: 본 논문에서는 기존의 Dropout 방식이 갖는 일관성 결여 문제를 해결한 새로운 모듈인 stochastic average pooling을 제안합니다. 이 모듈은 pooling 과정에서 Dropout과 유사한 확률성을 통합하여 신경망의 성능을 개선할 수 있습니다.

- **Technical Details**: Stochastic average pooling은 stochastic subsampling과 average pooling을 통합한 방식입니다. 이는 기존 average pooling을 대체할 수 있으며, 코드 변경이 최소화됩니다. 이 방법은 수학적 기호와 함께 명확하게 정의되어 있습니다.

- **Performance Highlights**: 실험 결과, stochastic average pooling로 기존 평균 풀링을 대체하면 다양한 데이터셋, 작업 및 모델에서 성능이 일관되게 개선되는 것으로 나타났습니다.



### Ascend HiFloat8 Format for Deep Learning (https://arxiv.org/abs/2409.16626)
Comments:
          13 Pages, 4 Figures, 9 Tables

- **What's New**: 본 논문은 딥러닝을 위한 새로운 8비트 부동 소수점 데이터 포맷인 HiFloat8(약칭 HiF8)을 제안합니다. HiF8은 정밀도(precision)와 동적 범위(dynamic range) 사이의 균형을 개선하였으며, AI 훈련의 순전파(forward pass)와 역전파(backward pass) 모두에 동시에 사용할 수 있는 특징이 있습니다.

- **Technical Details**: HiF8은 1비트의 부호(Sign), 2-4비트의 점(Dot), 그리고 3-1비트의 지수(Exponent)와 맨티사(Mantissa) 필드를 포함합니다. 정규 값 인코딩에 대해 7개의 지수와 3비트의 맨티사, 8개의 지수와 2비트의 맨티사, 16개의 지수와 1비트의 맨티사를 제공합니다. 비정규 값 인코딩에 대해서는 7개의 추가적인 2의 거듭제곱을 포함하여 범위를 확장합니다.

- **Performance Highlights**: 다양한 신경망 및 대규모 언어 모델(LLMs)에 대한 대규모 시뮬레이션 결과가 제공되어 HiF8 포맷의 효율성을 입증하였습니다. HiF8은 기존 Float8 포맷들과 비교하여 정밀도와 동적 범위를 효과적으로 조화시키며, AI 훈련에서의 활용 가능성을 보여줍니다.



### Random Forest Regression Feature Importance for Climate Impact Pathway Detection (https://arxiv.org/abs/2409.16609)
- **What's New**: 본 논문에서는 기후(source) 소스의 시공간(spatio-temporal) 하향 하원 영향을 발견하고 순위를 매기는 새로운 기술을 개발하였습니다. 이를 위해 Random Forest Regression (RFR)과 SHapley Additive exPlanation (SHAP) 기능 중요성을 활용합니다.

- **Technical Details**: RFR을 분류(classification) 또는 회귀(regression) 작업에 사용하는 대신, (i) 관심 있는 시공간 기능(spatio-temporal features) 세트에 대해 랜덤 포레스트(RF) 회귀기를 훈련시키고, (ii) 해당 기능과 관련된 SHAP 가중치를 사용하여 쌍(pair-wise) 기능 중요성을 계산하며, (iii) 이러한 기능 중요성을 가중 경로 네트워크(weighted pathway network)로 변환하여 기후 기능 간의 상호 의존성을 추적하고 순위를 매기는 새로운 RFR 기반 작업 흐름을 제안합니다.

- **Performance Highlights**: 우리는 단계적 검증(tiered verification) 접근 방식을 적용하여, (i) 합성(coupled)된 방정식 세트를 사용한 실험 및 (ii) 필리핀에서 발생한 1991년 피나투보 산 화산 폭발에 대한 전체 결합 시뮬레이션을 통해 새로운 경로 식별 방법론(pathway identification methodology)의 정확성을 검증했습니다. 결과적으로, 우리의 RFR 기능 중요성 기반 접근 방식은 두 테스트 케이스 모두에 대해 알려진 영향 경로를 정확하게 감지할 수 있음을 발견했습니다.



### Pre-trained Graphformer-based Ranking at Web-scale Search (Extended Abstract) (https://arxiv.org/abs/2409.16590)
- **What's New**: MPGraf 모델은 Transformer와 Graph Neural Networks (GNNs)의 장점을 통합하여 학습 랭킹(learning to rank) 문제에 접근합니다. 이 모델은 모듈형 및 캡슐 기반의 사전 학습(pre-training) 전략을 사용하여 웹 규모의 통합된 LTR 프레임워크를 구현합니다.

- **Technical Details**: MPGraf는 세 가지 주요 단계를 포함합니다: (1) Link Rippiling을 통한 그래프 구성, (2) Hybrid Graphformer를 통한 표현 학습, (3) 모듈 구성(modular composition)을 통한 정밀 조정(surgical fine-tuning)입니다. 이를 통해 sparsely annotated query-webpage 쌍에서 그래프 기반 학습 데이터를 생성하고, GNN과 Transformer 모듈을 조합하여 하이브리드 아키텍처에서 특성 학습을 수행합니다.

- **Performance Highlights**: MPGraf는 실제 검색 엔진 환경에서 extensive offline 및 online 실험을 수행한 결과, 최신의 웹페이지 랭킹 방법들과 비교하여 최고의 성능을 나타냈습니다. 특히 온라인 평가에서 상당한 개선을 달성했습니다.



### AutoSTF: Decoupled Neural Architecture Search for Cost-Effective Automated Spatio-Temporal Forecasting (https://arxiv.org/abs/2409.16586)
Comments:
          16 pages, 13 figures

- **What's New**: 최근 자동화된 spatio-temporal forecasting 방법이 제안되었는데, 이는 복잡한 spatio-temporal 의존성을 캡처하기 위해 최적의 신경망 아키텍처를 automatically 탐색하는 방식이다. 그러나 기존 방법들은 비싼 neural architecture search (NAS) 비용으로 인해 실용성이 떨어진다.

- **Technical Details**: 이 논문에서는 AutoSTF라는 decoupled automated neural architecture search (NAS) 프레임워크를 제안하였다. 이는 mixed search space를 temporal space와 spatial space로 분리하고, representation compression 및 parameter-sharing schemes를 통해 파라미터 폭발 문제를 완화한다. 이러한 방식으로 모델 최적화 과정을 가속화하고, 효과적인 spatio-temporal 의존성 모델링을 가능하게 한다.

- **Performance Highlights**: AutoSTF는 8개의 데이터셋에서 광범위한 실험을 통해 기존 자동 spatio-temporal forecasting 방법에 비해 accuracy와 efficiency 모두에서 우수성을 입증하였다. 특히, 기존 방법들에 비해 13.48배의 속도 향상을 달성하면서도 최고의 예측 정확도를 유지하였다.



### Efficient and generalizable nested Fourier-DeepONet for three-dimensional geological carbon sequestration (https://arxiv.org/abs/2409.16572)
- **What's New**: 이번 연구에서는 지질 탄소 포집(Geological Carbon Sequestration, GCS) 프로젝트에서 CO₂의 이동 경로와 압력 분포를 예측하기 위해 Nested Fourier-DeepONet이라는 새로운 모델을 개발했습니다. 이 모델은 Fourier neural operator (FNO)의 장점과 Deep Operator Network(DeepONet)의 모듈성을 결합하여 성능을 향상시켰습니다.

- **Technical Details**: Nested Fourier-DeepONet 모델은 CO₂와 물의 다상 흐름을 모델링하고, 각각의 시간 좌표를 독립적으로 처리함으로써 80% 이상의 GPU 메모리 요구 사항을 감소시킵니다. 또한, 이 모델은 훈련 시간도 절반으로 줄이며 Nested FNO보다 두 배의 효율성을 자랑합니다. 연구에서는 CO₂의 압력 상승 및 탄소 포화도를 3D로 시뮬레이션하여 다양한 주입 방식과 지하 조건에서의 탄소 이동을 조사하였습니다.

- **Performance Highlights**: Nested Fourier-DeepONet 모델은 Nested FNO보다 시간을 초과하여 추정할 때 50% 이상의 오차 감소를 나타내며, 주입률, 우물 수, 저장소 특성과 같은 다양한 매개변수에 대한 외삽 정확성도 우수합니다. 이 모델은 GCS의 다양한 시나리오에서 효율적으로 적용될 수 있는 가능성을 보여줍니다.



### EMIT- Event-Based Masked Auto Encoding for Irregular Time Series (https://arxiv.org/abs/2409.16554)
- **What's New**: 이 논문에서는 비정형 시간 시리즈 데이터에 대한 새로운 프리트레이닝 프레임워크인 EMIT(Event-based Masking for Irregular Time Series)를 제안합니다. 이 프레임워크는 데이터 변화율을 기반으로 마스킹 포인트를 선택하여 마스킹 기반 재구성을 진행함으로써 비정형 데이터의 자연스러운 변동성을 보존합니다.

- **Technical Details**: EMIT는 비정형 시간 시리즈의 내재된 패턴을 효과적으로 학습하기 위해 마스킹 자동 인코더를 활용합니다. 주요 접근 방식은 변화율이 높은 포인트를 마스킹하여 이를 재구성하는 데 집중하는 것입니다. 이 방법은 임베딩 방식으로 데이터의 타이밍이나 값에 영향을 주지 않고 비정형 데이터 처리 능력을 향상시킵니다.

- **Performance Highlights**: MIMIC-III 및 PhysioNet Challenge 데이터셋을 이용한 실험 결과, EMIT 프레임워크가 비정형 시간 시리즈 데이터의 표현 품질을 현저히 향상시키는 것으로 나타났습니다. 이 과정에서 모델은 제한된 라벨 데이터로도 효과적으로 파인튜닝이 가능한 것으로 검증되었습니다.



### AlignedKV: Reducing Memory Access of KV-Cache with Precision-Aligned Quantization (https://arxiv.org/abs/2409.16546)
- **What's New**: 이 논문은 Mixed-precision quantization의 새로운 기준인 'precision alignment'를 제안하여 매개변수의 중요성을 정량적으로 평가하는 프레임워크를 제공합니다.

- **Technical Details**: Mixed-precision quantization은 중요 매개변수와 비중요 매개변수를 구분하여, 매트릭스 곱셈 시 더 높은 정밀도를 요구하는 매개변수의 정확성을 평가합니다. 새로운 'precision alignment' 기준을 적용하여, 두 개의 피연산자가 동일한 정밀도를 가져야 한다는 원칙을 확립했습니다. 이는 KV-Cache 정량화 기법에 적용되어 메모리 접근 지연을 25% 줄이고, LLM의 Attention Block에서 최대 1.3배의 속도 향상을 달성합니다.

- **Performance Highlights**: 제안된 기술은 거의 정밀도의 손실 없이 LLM의 디코딩 단계에서 메모리 접근을 25% 절감하고, Attention 연산에서 최대 1.3배의 속도 향상을 제공합니다.



### Monge-Kantorovich Fitting With Sobolev Budgets (https://arxiv.org/abs/2409.16541)
Comments:
          68 pages, 23 figures, 50 pages without figures

- **What's New**: 이번 연구에서는 $m < n$인 경우에 $f : \mathbb{R}^m \to \mathbb{R}^n$으로 매개변수화된 측도 $
u$를 사용하여 $n$차원 확률 측도 $ho$의 '최적' 근사를 찾는 문제를 다룹니다. 또한 Sobolev norm에 대한 제약조건을 설정하여 근사 복잡도를 제어합니다.

- **Technical Details**: Monge-Kantorovich $p$-cost ($\mathbb{W}_p^p(\rho, \nu)$)를 사용하여 근사의 성능을 정량화하며, $W^{k,q}$ Sobolev norm의 제약을 두어 기능적 $\\mathscr{J}_p(f)$을 최소화하는 문제로 다시 정리합니다. $k \geq 1$에 대해 일반적으로 다루며, $k q > m$인 경우 최적 해의 존재를 보장합니다.

- **Performance Highlights**: 모델링된 생성 학습 작업에서는 손글씨 숫자 이미지를 생성하는 GAN 훈련 과정에서, 제약 조건을 부여하여 성능을 향상시키는 교훈을 얻었으며, 이 성능은 가중치 감소(weight-decay)와 경쟁할 수준입니다.



### A QoE-Aware Split Inference Accelerating Algorithm for NOMA-based Edge Intelligenc (https://arxiv.org/abs/2409.16537)
Comments:
          16pages, 19figures. arXiv admin note: substantial text overlap with arXiv:2312.15850

- **What's New**: 이 논문에서는 resource 제한이 있는 edge device에서 대규모 AI 모델을 직접 배포하는 것의 비효율성을 언급하며, 'model split inference' 방식을 제안하였습니다. 이 방식은 AI 모델을 여러 개의 서브 모델로 나누고, 자원 소모가 큰 서브 모델을 edge 서버에 무선으로 오프로드하여 자원 요구량과 추론 지연을 줄입니다.

- **Technical Details**: 본 논문에서는 QoS(서비스 품질) 외에 사용자의 경험(QoE)에 미치는 영향을 고려하지 않은 기존 연구의 한계를 지적하며, EI(edge intelligence)에서 split inference를 가속화하고 QoE와 자원 소모 간의 균형을 맞추기 위한 자원 할당 알고리즘인 ERA를 제안합니다. ERA는 자원 소모, QoE 및 추론 지연을 고려하여 최적의 모델 분할 전략 및 자원 할당 전략을 찾습니다. 최적의 균형을 위해 기울기 하강법(gradient descent) 기반 알고리즘을 사용하였고, GD 알고리즘의 복잡성을 줄이기 위한 루프 반복 GD 방식을 개발하였습니다.

- **Performance Highlights**: 실험 결과, ERA의 성능이 기존 연구들보다 현저히 우수한 것으로 나타났습니다. 이 알고리즘은 수렴성, 복잡성 및 근사 오차(properties)를 포함한 다양한 특성을 조사하였습니다.



### Learning Linear Dynamics from Bilinear Observations (https://arxiv.org/abs/2409.16499)
Comments:
          35 pages, 3 figures

- **What's New**: 본 논문에서는 부분 관측된 동적 시스템을学习하는 문제를 다룬다. 이 시스템은 선형 상태 전이(Linear State Transition)와 이변량 관찰(Bilinear Observations)을 포함 청경하며, 과정 노이즈와 측정 노이즈에 대한 약한 가정 하에, 미지의 동적 행렬(Unknown Dynamics Matrices)을 학습하는데 필요한 샘플 복잡성(Sample Complexity)과 오류 경계(Error Bound)를 제시한다.

- **Technical Details**: 이 연구는 현재 입력과 입력의 이력을 결합한 Kronecker 곱(Kronecker Product)을 포함한 디자인 매트릭스와 함께 하는 회귀 문제(Regression Problem)로 구성된다. 연구 결과는 가벼운 꼬리(Heavy-Tailed) 노이즈를 갖는 데이터에서도 적용되며, 특히 통계적 오류율(Statistical Error Rates)과 샘플 복잡성을 수학적으로 분석했다. 더불어, 간단한 무작위 설계를 통한 입력 및 설계 행렬의 유지(Excitation Persistence) 문제 해결을 위한 방식도 논의한다.

- **Performance Highlights**: 단일 유한 궤적을 기반으로 학습할 경우, 정확한 오류 범위를 기록하며, 주어진 입력에 따라 데이터 의존적 오류 범위(Data-Dependent Error Bound)와 데이터 비의존적 오류 범위(Data-Independent Error Bound)를 제공한다. 실험 결과, 시스템의 메모리(메르코프 매개변수 및 동적 행렬의 스펙트럴 반지름)에 따라 추정 오류 간의 상충 관계를 보여준다.



### Flight: A FaaS-Based Framework for Complex and Hierarchical Federated Learning (https://arxiv.org/abs/2409.16495)
- **What's New**: 이번 논문에서는 Fedrated Learning(FL)의 새로운 프레임워크인 Flight를 제안합니다. Flight는 복잡한 계층적 다단계(topologies) 구조를 지원하며, 비동기(Asynchronous) 집계를 가능하게 합니다. 이를 통해 매우 많은 수의 디바이스를 동시에 처리할 수 있는 기능을 갖추고 있습니다.

- **Technical Details**: Flight는 제어(control) 평면과 데이터(data) 평면을 분리하여 효율적인 배포를 지원합니다. Flight의 아키텍처는 여러 개의 중간 집계기(intermediate aggregators)를 포함하는 다단계 계층 구조를 통해 더욱 지역적(contextual)인 모델 집계를 수행할 수 있습니다. Flight는 데이터 전송량 감소 및 비동기 FL을 통해 훈련 시간을 단축시킵니다.

- **Performance Highlights**: Flight는 최대 2048개의 동시 디바이스를 지원하며, 여러 모델에서 FL의 메이크스팬(makespan)을 감소시켰습니다. 또한, Flight의 계층적 FL 모델은 통신 오버헤드를 60% 이상 줄일 수 있음을 보여주었습니다.



### Generative AI-driven forecasting of oil production (https://arxiv.org/abs/2409.16482)
- **What's New**: 이번 연구에서는 여러 개의 우물이 있는 석유 생산 예측 문제를 다룹니다. 특히, Generative AI 기술을 활용하여 40년 동안의 4개 다중 우물 사이트에서 석유 및 물 생산의 시계열 예측을 수행합니다.

- **Technical Details**: 우리는 TimeGrad라는 자기회귀 모델과 긴 시퀀스 시계열 데이터를 예측하기 위해 특별히 조정된 Transformer 아키텍처의 변형인 Informer를 사용합니다. 이 모델들은 불확실성을 효과적으로 모델링하고 정밀한 예측을 제공할 수 있도록 설계되었습니다.

- **Performance Highlights**: TimeGrad와 Informer의 예측은 모두 실제 데이터와 밀접하게 일치하며, 특히 Informer의 전반적인 성능이 돋보여 모든 사이트에서 석유 생산 속도 예측에서 TimeGrad보다 높은 효율성을 보입니다.



### Communication and Energy Efficient Federated Learning using Zero-Order Optimization Techniqu (https://arxiv.org/abs/2409.16456)
- **What's New**: 이번 논문에서는 연합 학습(Federated Learning, FL)의 통신 병목 현상과 에너지 소비 문제를 해결하기 위해 제로 오더(Zero-Order, ZO) 최적화 방법을 제안하였습니다. 이 방법은 각 기기가 전체 그래디언트 벡터 전체를 업로드하는 대신 매 반복마다 양자화된 단일 스칼라 값을 업로드하게끔 하여 통신 요구량을 대폭 줄입니다.

- **Technical Details**: 제안된 ZO 최적화 방법은 비볼록(non-convex) 설정에서 수렴성 이론을 증명하고, 전통적인 그래디언트 기반 방법에 비해 통신 비용 및 에너지 소비를 현저히 감소시킴을 보여주었습니다. 이 방법은 양자화의 영향을 고려하고, 무선 오류로 인한 패킷 손실 또한 분석에 포함됩니다. ZO 방법론은 최소화 하려는 손실 함수에 대한 그래디언트 정보가 없거나 계산할 수 없는 상황에서 기법을 이용하여 함수 값을 사용해 그래디언트를 추정합니다.

- **Performance Highlights**: 제안된 FL 방법은 O(d)만큼의 통신 자원 절약 효과를 보여 주며, 각 기기가 그래디언트를 계산할 필요 없이 손실 함수의 수치 값을 직접 계산하게 됩니다. 이는 계산 자원의 소모를 줄이고, 에너지 소비를 현저히 낮추는 결과를 초래합니다. 또한, hyperparameter tuning 같은 복잡한 문제에서도 유용하게 사용될 수 있습니다.



### Lessons Learned from a Unifying Empirical Study of Parameter-Efficient Transfer Learning (PETL) in Visual Recognition (https://arxiv.org/abs/2409.16434)
Comments:
          Code is available at this https URL

- **What's New**: 최근 Parameter-efficient transfer learning (PETL) 기술에 대한 관심이 커지고 있으며, 이를 통해 기존의 대규모 pre-trained 모델을 더욱 효율적으로 조정하여 다양한 downstream 작업에서의 성능을 향상시키고자 하는 연구가 진행되고 있습니다. 본 논문은 Vision Transformers의 맥락에서 PETL 방법들을 통합적으로 비교하고, 그들의 성능을 체계적으로 분석하였습니다.

- **Technical Details**: 이 연구에서는 Low-Rank Adaptation (LoRA), Visual Prompt Tuning (VPT), Adapter 등 다양한 PETL 기법을 사용하여 진행하였으며, 하이퍼 파라미터(learning rate, weight decay 등)를 체계적으로 조정하여 low-shot benchmark인 VTAB-1K의 정확도를 비교하였습니다. 또한, CIFAR-100 및 RESISC와 같은 풀사이즈 데이터셋에서도 PETL 방법을 평가하였습니다.

- **Performance Highlights**: PETL 접근 방식들이 잘 조정되었을 경우 VTAB-1K에서 유사한 정확도를 기록하였으며, PETL 방법들은 낮은 샷의 데이터에서도 뛰어난 성능을 보여주었습니다. 무수한 학습 데이터를 가진 시나리오에서도 PETL이 full fine-tuning과 동등하거나 그 이상의 결과를 도출할 수 있다는 점이 주목할 만합니다. 또한 PETL은 distribution shift에 대한 강건성을 가지며, 기존 모델의 일반성을 유지하는 결과를 보였습니다.



### Is All Learning (Natural) Gradient Descent? (https://arxiv.org/abs/2409.16422)
Comments:
          14 pages, 3 figures

- **What's New**: 본 논문에서는 특정 클래스의 효과적인 학습 규칙이 자연 기울기 감소(natural gradient descent)로 표현될 수 있음을 보이고 있습니다. 주로, 이 학습 규칙들은 손실 함수(loss function)와 메트릭(metric)을 기준으로 업데이트가 이루어지는 형태로 설명됩니다.

- **Technical Details**: 저자들은 대칭 양의 정부호 행렬(symmetric positive definite matrix)과 손실 함수의 음의 기울기(negative gradient)의 곱으로 학습 규칙이 표현될 수 있으며 이는 연속 시간(continuous-time), 이산 시간(discrete-time), 확률적(stochastic) 및 고차원(high-order) 학습 규칙에 모두 적용 가능하다고 설명합니다. 또한, 이러한 메트릭은 표준형(canonical form)을 가지며 조건수(condition number)를 최소화하는 최적 메트릭에 대한 여러 가지 식별이 이루어집니다.

- **Performance Highlights**: 이 연구는 특정한 형태의 업데이트가 이루어지는 전통적인 기울기 감소 방식과는 다르게, 다양한 학습 규칙도 효과적으로 성능 지표를 개선할 수 있음을 보여줍니다. 특히, 지속적인 개선을 보장하면서 유연한 메트릭을 선택하면 효율적인 업데이트를 이끌어낼 수 있는 가능성을 제안합니다.



### Evaluating Blocking Biases in Entity Matching (https://arxiv.org/abs/2409.16410)
- **What's New**: 본 연구는 Entity Matching (EM)에서 Blocking 기법의 공정성을 다루고 있습니다. 기존의 Blocking 메트릭스를 공정성을 반영하도록 확장하여 Blocking 기법의 편향을 평가할 수 있는 프레임워크를 제공합니다. 특히, 다양한 Blocking 방법의 효과성과 공정성을 평가하는 실험을 통해 EM 과정에서의 공정성 고려의 중요성을 부각시킵니다.

- **Technical Details**: EM은 서로 다른 소스에서 동일한 실체를 찾아내는 작업으로, 전통적으로는 Block을 사용하여 비교의 수를 줄입니다. 본 연구에서는 기존의 Blocking 메트릭스(Reduction Ratio, Pair Completeness)의 공정성 측정을 위한 확장을 제안하고, 이를 통해 Blocking 방법에서의 편향을 평가합니다. 실험 분석을 통해 다양한 Blocking 기법의 효과와 편향을 이해합니다.

- **Performance Highlights**: 연구 결과는 EM의 Blocking 단계에서 공정성을 고려하는 것이 필수적이며, 이를 통해 데이터 통합 작업에서 공정한 결과를 보장할 수 있음을 보여줍니다. 최근의 Blocking 기술들이 공정성 문제를 해결하는 데 기여할 수 있는 가능성을 제시합니다.



### Modern Hopfield Networks meet Encoded Neural Representations -- Addressing Practical Considerations (https://arxiv.org/abs/2409.16408)
Comments:
          17 pages, 8 figures, workshop submission to Neurips

- **What's New**: 본 논문은 Modern Hopfield Networks (MHN)에 대한 메타 안정 상태 문제를 해결하는 새로운 접근 방식인 Hopfield Encoding Networks (HEN)를 소개합니다. HEN은 입력 패턴의 분리 가능성을 높이고, 메타 안정 상태를 줄이기 위해 인코딩된 신경 표현을 통합합니다.

- **Technical Details**: HEN은 미리 훈련된 신경 인코더-디코더 모델을 사용하여 입력을 잠재 표현 공간으로 인코딩한 후 저장하고, 재호출 시 다시 디코딩하는 방법을 사용합니다. 이 접근 방식은 MHNs의 메타 안정 상태 문제를 해결하고, 자연어 쿼리를 통한 다양한 입력 모달리티에서의 검색을 가능하게 합니다.

- **Performance Highlights**: 실험 결과는 HEN이 메타 안정 상태를 크게 줄이고, 저장 용량을 증가시키면서 다양한 입력을 완벽히 기억할 수 있음을 나타냅니다. 이는 실제 작업을 위한 연상 기억 네트워크의 실용적인 활용을 향상시킵니다.



### Patch-Based Contrastive Learning and Memory Consolidation for Online Unsupervised Continual Learning (https://arxiv.org/abs/2409.16391)
Comments:
          Published in Conference on Lifelong Learning Agents (COLLAS) 2024

- **What's New**: 논문에서는 상대적으로 탐색이 부족한 학습 패러다임인 Online Unsupervised Continual Learning (O-UCL)에 집중하고 있습니다. O-UCL은 비정상적인 레이블 없는 데이터 스트림을 처리하며 점진적으로 클래스의 수를 식별하는 능력을 길러주는 방식입니다. 본 연구는 실시간으로 새로운 클래스를 식별하고, 기존에 학습한 클래스를 잊지 않으면서 데이터를 스트리밍 방식으로 처리하는 동적 접근 방식을 제안합니다.

- **Technical Details**: 제안된 방법인 Patch-based Contrastive learning and Memory Consolidation (PCMC)은 데이터의 패치 수준의 특징을 식별하고 클러스터링하여 데이터를 이해합니다. PCMC는 인코더를 통해 패치 임베딩을 추출하고, 새로운 데이터를 기존 분포에 통합하면서 재학습 시 기억을 통합하는 기능을 갖추고 있습니다. 이 접근 방식은 주기적인 '깨어남'과 '수면' 주기를 통해 개념적으로 변화를 관리합니다.

- **Performance Highlights**: PCMC의 성능은 ImageNet과 Places365 데이터셋에서 생성된 스트림을 기반으로 평가되었습니다. 여러 기존 방법들과 간단한 기준점과의 성능 비교를 통해 PCMC의 유효성을 입증하였습니다.



### Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs (https://arxiv.org/abs/2409.16341)
- **What's New**: 이번 연구에서는 기존 LLM(대형 언어 모델)을 외부 도구와 함께 사용하는 데 있어, 데이터 품질 평가의 중요성을 강조합니다. 두 가지 새로운 접근 방식을 제안하여 LLM 훈련에 사용할 데이터의 신뢰성을 측정합니다.

- **Technical Details**: 첫 번째 접근 방식은 인간이 정의한 직관적인 정확성 기준을 사용하고, 두 번째 접근 방식은 모델 기반 평가와 in-context evaluation (ICE)을 이용합니다. 또한, 데이터 품질을 평가하기 위한 자동화된 방법을 구현하여 전문가의 주석과 높은 일치를 보였습니다.

- **Performance Highlights**: 데이터 품질이 높은 훈련 데이터로 학습한 모델이 검증되지 않은 데이터로 학습한 모델보다 더 우수한 성능을 보임을 실증적으로 보여주었습니다. 이는 효율적인 훈련 데이터 관리의 중요성을 입증하며, ToolBench와 ToolAlpaca 벤치마크에서 검증되었습니다.



### Automated Spatio-Temporal Weather Modeling for Load Forecasting (https://arxiv.org/abs/2409.16326)
- **What's New**: 본 논문에서는 전력 수요 예측을 위해 기상 모델링을 개선하기 위한 새로운 접근 방식을 제안합니다. 심층 신경망(deep neural networks)의 자동화된 표현 및 공간-시간 특성(spatio-temporal feature) 추출 능력을 활용하여, 기존의 고정된 모델링 방법에서 벗어나 새로운 방법을 탐구합니다.

- **Technical Details**: 이 연구에서는 전력 수요(load)와 재생 에너지 생산에 대한 예측 정확도를 높이기 위해 기온, 바람 및 일조시간과 같은 기상 변수의 공간적 및 시간적 변동성을 설명하는 복합 생태계(model)를 개발했습니다. 여러 기상 관측소(observations) 및 기상 모델(simulated data)에서 얻은 데이터를 활용하여 이러한 변수를 동시에 모델링하는 방법을 제시합니다.

- **Performance Highlights**: 프랑스 국가 전력 수요에 대한 최신 모델과의 비교 연구를 통해, 제안된 심층 학습 기반(deep learning-based) 방법론이 전력망(Grid)의 성능 및 안정성을 개선하는 데 기여할 수 있음을 보여줍니다. 이 접근법은 재생 에너지 생산 예측에도 완전히 적용될 수 있음을 강조합니다.



### Probabilistic Spatiotemporal Modeling of Day-Ahead Wind Power Generation with Input-Warped Gaussian Processes (https://arxiv.org/abs/2409.16308)
Comments:
          29 pages, 12 figures

- **What's New**: 본 연구는 일일 풍력 전력 예측의 특성을 포착하기 위해 Gaussian Process (GP) 시공간 모델을 설계하였습니다. 우리는 수백 개의 풍력 발전소 위치에서 시간 단위로 하루 앞선 예측을 수행하며, 공간과 시간에 걸쳐 완전한 확률적 결합 모델을 구축하는 것을 주요 목표로 삼고 있습니다.

- **Technical Details**: 시공간 커널은 시각적 및 공간적 입력 워핑을 구현하여 풍력 전력의 공분산에서 비정상성을 포착합니다. 우리는 합성 실험을 통해 공간 커널 선택을 검증하고, 비정상성을 다루기 위해 워핑의 효과를 입증합니다. 풍력 발전소의 현실적이고 완전히 보정된 데이터 세트를 사용하여 사례 연구를 진행하였습니다.

- **Performance Highlights**: 모델은 예측 분포를 제공하고, 실시된 시뮬레이션은 풍력 전력 생성의 불확실성을 캡처하는 데 사용될 수 있습니다. 특히, 이 모델은 예측 분위수와 같은 불확실성 메트릭을 직접 출력할 수 있으며, 확률적 프로그래밍을 위한 시나리오 생성 엔진으로 사용될 수 있습니다.



### Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models (https://arxiv.org/abs/2409.17146)
- **What's New**: Molmo는 현재 공개된 VLM 중에서 가장 최신의 성능을 자랑하며, 독점적인 데이터가 아닌 새롭게 수집된 고품질 데이터로 구성된 이미지를 설명하는 고급 캡션 데이터셋을 기반으로 하고 있습니다. 이 연구는 VLM을 처음부터 구축하는 데 필요한 기본 지식을 제공합니다.

- **Technical Details**: Molmo 모델은 기존의 비전 인코더와 언어 모델을 결합하여 만들어졌습니다. 이 과정에서는 이미지로부터 자세하고 질 높은 설명을 생성하는 새로운 데이터셋인 PixMo를 사용하고, 60~90초 동안 음성으로 설명하도록 요구하여 다양한 내용을 포괄하도록 했습니다. 모델 훈련은 다단계 과정이 아닌, 간단한 훈련 파이프라인을 통해 진행되었습니다.

- **Performance Highlights**: Molmo-72B 모델은 학술 벤치마크에서 최고의 점수를 기록했으며, GPT-4o와 비교했을 때 사용자 선호도 순위에서 두 번째에 올랐습니다. Molmo-1B 모델은 효율적인 성능을 보이며 GPT-4V와 근접한 결과를 보여주었고, 전체적으로 많은 상업적 시스템을 능가하는 성능을 발휘했습니다.



### DreamWaltz-G: Expressive 3D Gaussian Avatars from Skeleton-Guided 2D Diffusion (https://arxiv.org/abs/2409.17145)
Comments:
          Project page: this https URL

- **What's New**: 이 논문은 텍스트 기반의 3D 아바타 생성 프레임워크인 DreamWaltz-G를 소개한다. 이 프레임워크는 Skeleton-guided Score Distillation과 Hybrid 3D Gaussian 아바타 표현을 핵심으로 하여, 보다 일관성 있는 아바타 생성을 목표로 한다.

- **Technical Details**: DreamWaltz-G는 두 가지 단계로 아바타를 생성하는 방식으로, (I) Canonical Avatar Generation 단계에서 텍스트 설명을 바탕으로 기본 3D 아바타를 생성하고, (II) Animatable Avatar Learning 단계에서 이 아바타를 SMPL-X로 리깅하고 애니메이션을 추가하는 최적화를 진행한다.

- **Performance Highlights**: 광범위한 실험을 통해 DreamWaltz-G는 기존 방법들과 비교하여 시각적 품질과 애니메이션 표현력 면에서 우수한 성능을 발휘하며, 인상적인 3D 아바타 생성 및 애니메이션 수행 능력을 입증했다.



### FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression (https://arxiv.org/abs/2409.17141)
- **What's New**: FineZip는 전통적 텍스트 압축 방법에 비해 54배 빠른 압축 시간을 달성함으로써 대규모 텍스트 압축에 대한 사용 가능성을 높입니다.

- **Technical Details**: FineZip는 '온라인' 및 '오프라인' 구성 요소를 결합하여 손실 없는 텍스트 압축을 수행하며, 파라미터 효율적 미세 조정(PEFT) 방식을 사용하여 압축하는 데이터를 Memorize(기억)합니다. 또한, 동적 컨텍스트 사이즈를 활용하여 각 토큰의 압축을 개선하고 병렬 처리 가능성을 높였습니다.

- **Performance Highlights**: FineZip는 기존의 LLMZip보다 약 54배 빠른 압축 성능을 보여주며, 압축 비율을 약 50% 향상시킵니다. 전통적인 알고리즘 기반 압축 방법에 비해 크게 개선된 압축 효율성을 자랑합니다.



### Learning with Dynamics: Autonomous Regulation of UAV Based Communication Networks with Dynamic UAV Crew (https://arxiv.org/abs/2409.17139)
Comments:
          7 pages, 6 figures, magazine paper

- **What's New**: 본 논문은 Unmanned Aerial Vehicle (UAV) 기반의 통신 네트워크(UCN)에서 동적으로 변화하는 UAV 세트를 고려한 Reinforcement Learning (RL) 기반의 전략 설계를 논의합니다. 기존 연구들 대부분이 고정된 UAV 집단을 전제로 하고 반응적인 전략에 중점을 두었던 반면, 이 연구에서는 사전 예방적인 전략을 통해 Solar-powered UCN에서의 UAV 관리 방안을 제안합니다.

- **Technical Details**: Dynamically changing environments에서 효율적인 네트워크 관리를 위해, RL을 활용하여 응답성과 예방적으로 UAV의 상태를 조절할 수 있는 전략이 개발되었습니다. 이는 UAV의 휴대폰 사용 기반의 통신과 자원 관리, 그리고 궤적 제어를 포함하여 동적으로 변화하는 UAV 그룹을 다루는 방식으로 진행됩니다. 특히 Multi-Agent RL (MARL) 접근 방식을 통해 UAV들 간의 분산 학습이 가능하게 되어 확장성 문제를 해결합니다.

- **Performance Highlights**: 자기 지속 가능한 UCN 구축을 위한 RL 기반의 전략을 통해, 네트워크 성능 극대화와 사용자 요구 변동에 대응할 수 있는 유연성을 제공한다는 점에서 우수한 성과를 기대할 수 있습니다. 본 연구는 UAV가 배터리가 소진될 경우 네트워크를 일시적으로 이탈하는 상황에서 발생하는 문제를 효과적으로 해결함과 동시에, 향후 태양광 충전 UAV의 활용 방안을 제시합니다.



### Landscape of Policy Optimization for Finite Horizon MDPs with General State and Action (https://arxiv.org/abs/2409.17138)
- **What's New**: 본 논문에서는 강화 학습( Reinforcement Learning )의 정책 경량화( Policy Gradient ) 방법의 글로벌 수렴성을 향상시키기 위한 새로운 프레임워크를 제시합니다. 이는 Kurdyka-Lojasiewicz (KL) 조건을 통해 비볼록( nonconvex ) 최적화 문제를 다루는 것입니다.

- **Technical Details**: 정책 최적화 문제의 KŁ 조건을 수립하기 위해 여러 가지 쉽게 검증 가능한 가정을 도입했습니다. 구체적으로, 목적 함수의 기울기가 제한되어 있을 경우, 예상 최적 Q-값 함수가 KŁ 조건을 만족하며, 순차적 분해 불평등이 성립하는 경우를 보여주었습니다. 이는 비볼록인 MDP( Markov Decision Process ) 문제에서 첫 번째 차수 필요 최적 조건을 만족하는 모든 지점이 글로벌 최적임을 나타냅니다.

- **Performance Highlights**: 정확한 정책 그래디언트 방법은 선형 수렴률을 전시하며, 확률적 정책 그래디언트 방법은 $	ilde{	ext{O}}(\epsilon^{-1})$의 샘플 복잡도로 ϵ-최적 정책을 찾을 수 있음을 증명했습니다. 이 연구는 마르코프 조정 수요를 가지는 다기간 재고 시스템과 확률적 현금 잔고 문제에 대한 선례 없는 샘플 복잡성 결과를 제시했습니다.



### Blox-Net: Generative Design-for-Robot-Assembly Using VLM Supervision, Physics Simulation, and a Robot with Res (https://arxiv.org/abs/2409.17126)
Comments:
          8 pages, 7 Figures

- **What's New**: 이번 논문에서는 Generative Design-for-Robot-Assembly (GDfRA)라는 새로운 문제를 제안합니다. 이 과정은 자연어 프롬프트(예: '기린')와 3D 프린팅한 블록과 같은 물리적 부품의 이미지를 기반으로 조립을 생성하는 것입니다. 이를 통해 로봇이 조립을 보다 효과적으로 수행할 수 있도록 설계되었습니다.

- **Technical Details**: Blox-Net은 VLM(vision language model)과 시뮬레이션, 물리적 로봇 실험을 결합하여 GDfRA 문제를 해결하는 시스템입니다. 3단계로 구성되어 있으며, 각 단계에서 3D 부품의 적절한 배열을 디자인하고, 이를 물리적 로봇이 구축할 수 있도록 검증합니다. 이 시스템은 인간의 개입 없이도 작동할 수 있도록 설계되었습니다.

- **Performance Highlights**: Blox-Net은 조립물의 '인지성'에서 63.5%의 Top-1 정확도를 기록했습니다. 자동화된 재설계를 거친 후, 로봇은 10회 연속 조립에서 거의 완벽한 성공률을 보였습니다. 특히, 99.2%의 정확도로 블록을 자율적으로 배치하는 데 성공했습니다.



### Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Handy Appetizer (https://arxiv.org/abs/2409.17120)
Comments:
          This book contains 93 pages and 60 figures

- **What's New**: 이 책은 필독서로 인공지능(AI), 머신러닝(ML) 및 딥러닝(DL)이 빅데이터 분석 및 관리의 발전에 미치는 역할을 탐구합니다. 복잡한 수학 개념을 단순화하고, 직관적 시각화 및 실제 사례 연구를 제공하여 독자들이 신경망(neural networks) 및 Convolutional Neural Networks(CNNs)와 같은 기술이 어떻게 작동하는지를 이해하도록 돕습니다.

- **Technical Details**: 책에서는 Transformers, GPT, ResNet, BERT 및 YOLO와 같은 여러 고전 모델과 기술을 소개하며, 자연어 처리(natural language processing), 이미지 인식(image recognition) 및 자율 주행(autonomous driving) 분야에서의 응용을 강조합니다. 사전 훈련된(pre-trained) 모델의 중요성과 그들이 모델의 성능과 정확도를 향상시킬 수 있는 방법을 설명합니다. SQL 및 NoSQL 데이터베이스와 같은 주요 빅데이터 관리 기술의 개관과 Apache Hadoop 및 Spark와 같은 분산 컴퓨팅 프레임워크를 다룹니다.

- **Performance Highlights**: 딥러닝 및 빅데이터 관리 기술을 습득하는 것이 미래 인력에게 중요한 도구라 강조하며, 초보자부터 숙련된 전문가까지 모두에게 필수적인 자료로 자리 잡고 있습니다.



### Programming Every Example: Lifting Pre-training Data Quality like Experts at Sca (https://arxiv.org/abs/2409.17115)
Comments:
          45 pages, 13 figures, 34 tables

- **What's New**: 이번 연구에서는 사전 훈련된 대형 언어 모델에 대해 새로운 접근법인 ProX(Programming Every Example)를 제안합니다. 이는 데이터 정제를 프로그래밍 작업으로 간주하여, 각 개별 예제에 대해 정교한 작업을 생성하고 실행할 수 있게 합니다.

- **Technical Details**: ProX는 모델이 각각의 데이터 예제를 정제하기 위해 필요한 작업을 프로그래밍 방식으로 정의할 수 있도록 하여, 기존의 왜곡된 데이터를 정제하는 데 필요한 유연성을 제공합니다. 이는 문자열 정규화, 데이터 세분화 등의 작업을 포함하여, 0.3B 파라미터를 가진 소형 모델도 인간 전문가와 비슷한 정제 능력을 발휘할 수 있음을 보여줍니다.

- **Performance Highlights**: ProX로 정제된 데이터로 사전 훈련된 모델은 원래 데이터나 다른 필터링 기법으로 정제된 데이터에 비해 다양한 하위 벤치마크에서 2% 이상의 성능 향상을 보였습니다. 특히, OpenWebMath 데이터 세트에서 ProX로 정제된 모델은 Mistral-7B에 비해 평균 정확도가 7.6% 개선되었고, Llama-2-7B에서는 14.6%, CodeLlama-7B에서는 20.3% 향상되었습니다.



### Non-asymptotic convergence analysis of the stochastic gradient Hamiltonian Monte Carlo algorithm with discontinuous stochastic gradient with applications to training of ReLU neural networks (https://arxiv.org/abs/2409.17107)
- **What's New**: 본 논문에서는 Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) 알고리즘이 Wasserstein-1 및 Wasserstein-2 거리에서 목표 분포에 수렴하는 비비대칭(non-asymptotic) 분석을 제공합니다. 특히, 기존 문헌에서는 불연속적인(stochastic gradient) 경량을 허용하지 않았던 반면, 이번 연구에서는 이를 인정합니다.

- **Technical Details**: SGHMC 알고리즘은 비연속적인 스토캐스틱 경량을 포함하는 비볼록(non-convex) stochastic optimization 문제의 예상 초과 위험(expected excess risk)에 대한 명시적 상한(explicit upper bounds)을 제공합니다. 이 상한은 임의로 작게 조정될 수 있습니다. 이 연구에서는 ReLU 활성화 함수가 포함된 신경망 훈련과 같은 문제를 포함합니다.

- **Performance Highlights**: 주요 결과의 적용 가능성을 보여주기 위해, 양자 추정(quantile estimation) 및 금융과 인공지능 관련 ReLU 신경망을 포함한 여러 최적화 문제에 대한 수치 실험을 제시합니다.



### Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification (https://arxiv.org/abs/2409.17091)
Comments:
          17 pages, 7 figures, 7 tables

- **What's New**: 이 논문에서는 Ctrl-GenAug라는 새로운 생성적 증강 프레임워크를 제안하여, 의료 시퀀스 분류를 위한 고도로 의미적이고 연속적인 시퀀스 생성을 지원하고 부정확하게 합성된 샘플을 억제합니다.

- **Technical Details**: Ctrl-GenAug는 다중 모달 조건 유도 시퀀스 생성기를 통해 진단 촉진 샘플을 제어 가능하게 합성하며, 시간적/입체적 일관성을 향상시키는 연속 증강 모듈을 통합합니다. 또한, 불확실한 사례를 억제하는 노이즈 합성 데이터 필터를 설계하였습니다.

- **Performance Highlights**: 세 가지 의료 데이터셋과 세 가지 패러다임에서 훈련된 11개의 네트워크를 사용한 광범위한 실험에서 Ctrl-GenAug의 효과성과 일반성이 입증되었습니다. 특히, 대표성이 부족한 고위험 군과 도메인 외 조건에서의 성능 향상을 보여주었습니다.



### SEN12-WATER: A New Dataset for Hydrological Applications and its Benchmarking (https://arxiv.org/abs/2409.17087)
Comments:
          Submitted to IEEE Transactions on Geoscience and Remote Sensing. Copyright may be transferred without notice, after which this version may no longer be accessible

- **What's New**: 본 연구에서는 기후 변화와 가뭄 증가 문제 해결을 위한 새로운 데이터셋인 SEN12-WATER를 소개합니다. 이 데이터셋은 제거 및 분석을 위한 새로운 end-to-end Deep Learning 프레임워크와 함께 제공됩니다.

- **Technical Details**: SEN12-WATER 데이터셋은 SAR (Synthetic Aperture Radar) polarization, 고도(elevation), 기울기(slope), 다중 스펙트럼(optical bands)을 포함한 시공간 데이터큐브(spatiotemporal datacube)입니다. 제안된 DL 프레임워크는 U-Net 아키텍처를 통한 수체(segmentation) 분할과 TD-CNN(Time-Distributed-Convolutional Neural Network)을 이용한 시계열(time series) 분석을 포함합니다.

- **Performance Highlights**: 제안된 방법론은 물리적 양(예: 물의 부피)의 시간 변화를 검토하여 물의 동역학에 대한 중요한 통찰을 제공합니다. 결과는 Precision, Recall, Intersection over Union 등과 같은 맞춤형 메트릭스를 통해 검증되었습니다.



### The Effect of Perceptual Metrics on Music Representation Learning for Genre Classification (https://arxiv.org/abs/2409.17069)
Comments:
          arXiv admin note: text overlap with arXiv:2312.03455

- **What's New**: 이 연구에서는 음악 이해 작업, 특히 장르 분류에 대한 성능을 향상시킬 수 있는 방법으로, 지각 메트릭(perceptual metrics)을 활용하는 새로운 접근법을 제안합니다. 특히, 자기 부호화기(autoencoders)로부터 추출된 특징을 사용하여 지각 손실(perceptual losses)로 훈련된 모델이 장르 분류를 개선할 수 있음을 입증했습니다.

- **Technical Details**: 지각 메트릭은 인간 관찰자의 지각 행동을 근사하는 데 설계된 객관적인 측정 지표입니다. 예를 들어, 구조적 유사도(SSIM)와 정규화된 라플라스 피라미드 거리(NLPD)와 같은 지표를 스펙트로그램(spectrograms)에 적용하여 오디오 품질에 대한 인간 평가와 더 나은 연관성을 보이는 것을 보여주었습니다. 이들 메트릭은 모델 훈련 시 손실 함수(loss function)으로 사용되어 모델의 성능을 개선할 수 있습니다.

- **Performance Highlights**: K-최근접 이웃(K-Nearest Neighbours) 분류기를 사용할 때, 전통적인 MSE(mean squared error)보다 지각 메트릭을 통한 성능 향상이 나타났습니다. 특히 로지스틱 회귀(Logistic Regression) 모델은 자기 부호화기에서 추출된 잠재 특징(latent features)을 활용할 때 높은 F1 점수를 기록했습니다. 그러나 NLPD는 군집화(clustering) 거리 측정에는 적합하지 않은 것으로 나타났으며, 이는 불필요한 정보를 제거함으로써 느리게 변화하는 부분들을 배제하기 때문입니다.



### Benchmarking Domain Generalization Algorithms in Computational Pathology (https://arxiv.org/abs/2409.17063)
- **What's New**: 이번 연구는 30개의 도메인 일반화 (Domain Generalization, DG) 알고리즘의 효과를 3개의 CPath 작업에 대해 평가하고, 새로운 다중 도메인 종양 탐지 데이터셋 (HISTOPANTUM)을 소개합니다.

- **Technical Details**: 연구에서는 7,560회의 교차 검증 (cross-validation) 실험을 통해 DG 알고리즘의 상대적인 성능을 비교하며, 최근에 제안된 pretrained foundation models와 같은 모달리티별 (modality-specific) 기법을 통합했습니다.

- **Performance Highlights**: 자기 감독 학습 (self-supervised learning) 및 염색 증강 (stain augmentation) 기법이 consistently 다른 알고리즘보다 좋은 성능을 보였으며, 연구 결과는 연구자들이 CPath 작업에 적합한 DG 접근 방식을 선택하는 데 도움을 줄 수 있습니다.



### DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data (https://arxiv.org/abs/2409.17055)
- **What's New**: 이 논문은 의료 데이터의 다중 모드(multi-modal) 통합을 위한 새로운 방법인 DRIM을 소개합니다. DRIM은 결측 데이터가 있는 상황에서도 공유된 정보와 고유한 정보를 효과적으로 캡처합니다. 이 방법은 환자 관련 정보와 각 모드에 특정한 정보를 분리하여 인코딩합니다.

- **Technical Details**: DRIM은 각 모드에 대한 두 개의 인코더(encoder)를 사용하여, 하나는 공유 정보(shared information)를, 다른 하나는 고유 정보(unique information)를 캡처합니다. 이를 통해 두 가지 차원에서 정보 통합을 수행합니다: 첫 번째로는 공유 정보 집합을 모으고, 두 번째로는 고유 정보를 조합하여 포괄적인 표현을 생성합니다. 또한 DRIM은 attention 기반의 융합 방법을 사용해 결측 모드를 자연스럽게 관리합니다.

- **Performance Highlights**: DRIM은 교모종(glioma) 환자의 생존 예측 작업에서 기존의 최신 알고리즘을 초월하는 성능을 발휘했습니다. 특히, DRIM은 결측 모드가 있어도 성능이 안정적이며, 의료 데이터의 복잡한 특성을 효과적으로 다룰 수 있습니다.



### How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does No (https://arxiv.org/abs/2409.17044)
- **What's New**: 대형 언어 모델(LLM)의 성과가 두드러진 가운데, 본 연구는 음성 인식을 위한 다양한 구성요소(SFM, adapter, LLM)가 하위 작업 성과에 미치는 영향을 최초로 분석합니다.

- **Technical Details**: 다양한 adapter 모듈과 LLM, SFM을 이용하여 자동 음성 인식(ASR) 및 음성 번역(ST) 작업을 수행하였으며, SFM과 LLM의 조합에 따라 최적의 adapter 디자인이 달라짐을 규명하였습니다.

- **Performance Highlights**: SFM의 선택에 따라 ASR와 ST 성능이 평균적으로 각각 1 WER 및 2 COMET 포인트 이상 차이가 발생하였다. 따라서 length adapter의 디자인은 선택된 SFM 및 LLM에 크게 의존하는 것이 밝혀졌습니다.



### CNN Mixture-of-Depths (https://arxiv.org/abs/2409.17016)
Comments:
          Conference Paper of the Asian Conference on Computer Vision (ACCV) 2024

- **What's New**: CNN Mixture-of-Depths (MoD) 접근법을 도입하여 CNN의 계산 효율성을 개선하였습니다. 이 방법은 현재 예측과 관련성에 따라 채널을 선택적으로 처리하여 계산 자원을 최적화합니다. MoD는 동적 계산 그래프 없이 정적 계산 그래프를 사용하여 하드웨어 효율성을 높이고, 훈련 및 추론 과정을 가속화합니다.

- **Technical Details**: MoD는 Conv-Blocks 내에서 입력 특성 맵의 각 채널의 중요성을 평가한 후, 상위 k개 채널을 선택하여 처리합니다. 이를 통해 처리할 채널 수를 조정하고, 계산 부하를 줄이며, 최종적으로 처리된 채널과 원본 특성 맵의 첫 k개 채널을 융합하여 특징 표현을 강화합니다.

- **Performance Highlights**: ResNet86-MoD는 표준 ResNet50을 능가하며 CPU에서 6%, GPU에서 5% 더 빠른 처리 속도를 제공합니다. ResNet75-MoD는 ResNet50과 동일한 성능을 유지하며 CPU에서 25%, GPU에서 15%의 속도 향상을 보여줍니다.



### PitRSDNet: Predicting Intra-operative Remaining Surgery Duration in Endoscopic Pituitary Surgery (https://arxiv.org/abs/2409.16998)
Comments:
          Accepted to the Augmented Environments for Computer-Assisted Interventions (AE-CAI) Workshop at the Medical Image Computing and Computer-Assisted Interventions (MICCAI) Conference 2024

- **What's New**: 이 논문은 내시경 뇌하수체 수술 중 수술의 남은 시간(Remaining Surgery Duration, RSD) 예측을 위한 새로운 모델, PitRSDNet을 제안합니다. 이 모델은 과거 데이터를 활용하여 작업 흐름에 중점을 둔 spatio-temporal neural network 모델입니다.

- **Technical Details**: PitRSDNet은 두 가지 형태로 작업 흐름 지식을 RSD 예측에 통합합니다: 1) RSD와 단계(step)를 동시에 예측하는 multi-task learning; 2) 시간 학습과 추론에서 이전 단계를 맥락으로 포함시킵니다. 이 모델은 88개의 비디오로 구성된 새로운 내시경 뇌하수체 수술 데이터셋에서 훈련 및 평가되어 이전의 통계적 및 기계 학습 방법보다 경쟁력 있는 성능 개선을 보여줍니다.

- **Performance Highlights**: PitRSDNet은 수술의 마지막 10-20분 동안 5분 이하의 오차를 예상하며, 전체 수술 시간에 대해서는 10분 이하의 오차를 가지는 것이 기대됩니다. 연구 결과는 PitRSDNet이 이전 단계의 지식을 활용하여 이상치(outlier) 사례에서 RSD의 정밀성을 개선하는 방법을 강조합니다.



### Towards User-Focused Research in Training Data Attribution for Human-Centered Explainable AI (https://arxiv.org/abs/2409.16978)
- **What's New**: 이번 연구는 Explainable AI(XAI) 분야에서 기존의 하향식(bottom-up) 접근 대신 사용자의 요구를 중심으로 한 상향식(top-down) 접근 방식을 제안합니다. 특히 Training Data Attribution(TDA) 하위 분야에 초점을 맞추어 현재 사용자가 필요로 하는 기획 및 요구 사항을 파악했습니다.

- **Technical Details**: 우리는 10명의 AI 실무자와의 인터뷰 및 31명의 모델 개발자를 대상으로 한 시스템적 조사를 통해 TDA에 대한 사용자 니즈를 분석했습니다. 이를 통해 TDA에서 현재 간과되고 있는 다양한 작업을 확인했습니다.

- **Performance Highlights**: 사용자 중심의 TDA 연구 방향을 제안하며, 기계 학습 모델의 개발자가 TDA 설명을 필요로 하고, 유연성과 안정성을 요구하는 경향이 있음을 발견했습니다. 특히, 전체 교육 데이터 집단에 대한 기여도 설명이 개인 기여도 설명보다 더 선호되는 것으로 나타났습니다.



### Adaptive Self-Supervised Learning Strategies for Dynamic On-Device LLM Personalization (https://arxiv.org/abs/2409.16973)
Comments:
          First ASLS

- **What's New**: 이번 논문에서는 Adaptive Self-Supervised Learning Strategies (ASLS)를 제안합니다. ASLS는 대규모 언어 모델(LLMs)을 사용자 개인의 선호도에 맞게 동적으로 개인화하는 혁신적인 방법으로, 라벨이 있는 데이터셋의 필요성을 줄이고 실시간 피드백을 기반으로 모델을 조정합니다.

- **Technical Details**: ASLS는 사용자 프로파일링 레이어와 신경망 적응 레이어의 이중 레이어 구조로 구성되어 있습니다. 사용자와의 상호작용 데이터를 수집하여 모델을 실시간으로 미세 조정하며, 이는 계속해서 사용자 피드백을 학습하여 사용자별 맞춤형 응답을 생성합니다. 이 접근법은 계산 자원을 절약하고 개인화 효율성을 높입니다.

- **Performance Highlights**: 다양한 사용자 시나리오에 대한 실험 결과, ASLS는 기존의 개인화 방법 대비 사용자의 참여도와 만족도를 크게 향상시켰습니다. 이러한 결과는 ASLS가 대규모 언어 모델을 보다 반응성이 뛰어나고 맥락을 인지하는 시스템으로 변모시킬 잠재력을 보여줍니다.



### Informed deep hierarchical classification: a non-standard analysis inspired approach (https://arxiv.org/abs/2409.16956)
- **What's New**: 이번 연구는 다계층 분류 작업을 위한 새로운 접근 방식을 제안합니다. 이 방법은 다중 레이블로 구성되고 엄격한 부모-자식 구조로 조직된 데이터를 분류하는 문제에 초점을 맞추고 있습니다. 발표된 접근 방식은 lexicographic hybrid deep neural network (LH-DNN)라는 다중 출력 심층 신경망 구조를 포함합니다.

- **Technical Details**: 이 LH-DNN 아키텍처는 lexicographic multi-objective optimization(선형 다목적 최적화), non-standard analysis(비표준 해석학), deep learning(심층 학습) 등의 다양한 연구 분야의 도구를 결합하여 설계되었습니다. 이 접근법은 데이터 계층 구조와 일치하도록 학습 과정을 조정하는 방식으로, 학습 파라미터, 훈련 에폭 및 계산 시간을 대폭 줄이며 성능은 B-CNN과 유사하거나 우수할 수 있다는 것을 보여줍니다.

- **Performance Highlights**: LH-DNN은 CIFAR10, CIFAR100 및 Fashion-MNIST 벤치마크에서 B-CNN과 비교하여 학습 효율성이 높고 계층 관계를 학습하는 데 강력한 성능을 발휘합니다. 이 방식은 별도의 손실 함수 가중치 없이도 적용됩니다.



### Dynamic Obstacle Avoidance through Uncertainty-Based Adaptive Planning with Diffusion (https://arxiv.org/abs/2409.16950)
- **What's New**: 이번 연구에서는 강화 학습을 시퀀스 모델링 문제로 접근하면서, 움직이는 장애물이 있는 역동적인 환경에서도 효과적으로 충돌 회피를 수행할 수 있는 적응형 생성 계획(adaptive generative planning) 방법을 제안합니다. 이 방법은 불확실성을 기반으로 리플래닝 빈도를 동적으로 조절하여, 전통적인 방법들보다 더 나은 성능을 보여줍니다.

- **Technical Details**: 제안된 방법은 생성 모델(generative models), 특히 diffusion models를 활용하여 깊은 앙상블 역다이나믹스(action dynamics) 모델로부터 얻은 불확실성 추정을 기반으로 합니다. 이를 통해 1) 정해진 튜닝 파라미터에 따라 긴 시간 계획(long-horizon planning)과 각 단계에서의 리플래닝(replanning) 간의 유연한 균형을 제공하고, 2) 불필요한 리플래닝을 줄이면서 안전성을 확보할 수 있습니다.

- **Performance Highlights**: 실험 결과, 평균 경로 길이가 13.5% 증가하고, 평균 보상(mean reward) 또한 12.7% 증가하며, 이는 충돌 비율의 감소와 안전하게 환경을 탐색할 수 있는 능력이 향상되었음을 나타냅니다.



### Feedforward Controllers from Learned Dynamic Local Model Networks with Application to Excavator Assistance Functions (https://arxiv.org/abs/2409.16875)
- **What's New**: 이번 논문에서는 제로 동적(zero dynamics)을 가진 지역 모델 네트워크(local model networks, LMNs)에 대한 피드백 선형화를 통해 유효한 컨트롤러(controller)를 생성할 수 있는 기준을 제시하고 있습니다. 이는 LMNs 모델 구조의 제한을 극복하는 중요한 발전입니다.

- **Technical Details**: 피드백 선형화(feedback linearization) 과정에서 우리가 제안한 기준은 생성된 컨트롤러의 입력-출력 안정성(bounded-input bounded-output stability)입니다. 추가적으로, 측정된 교란 신호(measured disturbance signals)와 다중 입력 및 출력(multiple inputs and outputs)을 고려하는 방법을 제시합니다.

- **Performance Highlights**: 하드웨어 실험을 통해, 기록된 잡음 데이터에서 LMNs를 훈련하고, 굴삭기의 레벨링 보조 시스템의 일부로 사용되는 피드포워드 컨트롤러(feedforward controller)를 도출함으로써, 교란 신호와 다중 입력 출력의 통합이 학습된 컨트롤러의 추적 성능을 향상시켰음을 보여줍니다.



### Ethical and Scalable Automation: A Governance and Compliance Framework for Business Applications (https://arxiv.org/abs/2409.16872)
- **What's New**: AI 적용의 대중화가 이루어짐에 따라 기업에서 윤리 (ethics), 거버넌스 (governance), 법적 준수 (legal compliance)와 관련된 주요 도전 과제가 발생하고 있습니다. 이 논문에서는 윤리적 (ethical), 제어 가능 (controllable), 실행 가능 (viable), 그리고 바람직한 (desirable) AI를 보장하기 위한 프레임워크를 소개합니다.

- **Technical Details**: 제안된 프레임워크는 성능 (performance)과 설명 가능성 (explainability) 간의 균형을 맞추어야 하며, 금융 (finance) 및 의료 (healthcare)와 같은 분야에서 규제 요구 사항을 충족할 수 있도록 실제적인 조언을 제공합니다. 대규모 언어 모델 (large language models) 사용 사례를 통해 환경 문제에 대한 태도를 모방하는 합성 의견 (synthetic opinions)을 생성하는 비용 효과적인 대안을 제시합니다.

- **Performance Highlights**: 프레임워크의 유효성을 다양한 사례 연구 (case studies)를 통해 검증하였으며, Chi-test 점수 (Chi-test scores), 정규화된 상호 정보 (normalized mutual information), 그리고 Jaccard 지수 (Jaccard indexes)와 같은 지표를 사용하여 합성 데이터와 기대 분포 간의 정렬 (alignment)을 정량화하였습니다. 향후 연구에서는 다양한 산업 환경에서 프레임워크의 경험적 검증 (empirical validation)을 추가로 탐색할 필요가 있습니다.



### Quantifying Visual Properties of GAM Shape Plots: Impact on Perceived Cognitive Load and Interpretability (https://arxiv.org/abs/2409.16870)
Comments:
          to be published in proceedings of the 58th Hawaii International Conference on System Sciences (HICSS)

- **What's New**: 이 연구는 Generalized Additive Models (GAMs)의 구조적 속성과 시각적 표현이 사용자에게 미치는 인지 부담(cognitive load) 간의 관계를 탐구합니다. 57명의 참가자를 대상으로 시각적 속성이 인지 부담에 미치는 영향을 정량화하고 분석하였습니다.

- **Technical Details**: 모델의 시각적 속성은 도형 플롯(shape plot)에서 나타나는 기복의 수(number of kinks), 그래프의 길이(graph length) 등의 다양한 매트릭스(metrics)를 통해 정량화되었습니다. 연구 결과, 기복의 수는 사용자의 인지 부담 점수를 설명하는 가장 효과적인 지표로 나타났으며, 86.4%의 변동성을 설명했습니다.

- **Performance Highlights**: GAM 도형 플롯에서의 인지 부담을 예측하는 간단한 모델을 개발하였으며, 이는 사용자 개입 없이 GAM 해석 가능성을 평가하는 데 유용한 도구가 될 수 있습니다. 연구 결과는 인지 부담에 미치는 시각적 속성을 잘 정량화했으며, 공개된 도형 플롯 데이터셋을 통해 후속 연구를 위한 기초 자료를 제공합니다.



### Optimal starting point for time series forecasting (https://arxiv.org/abs/2409.16843)
- **What's New**: 본 논문에서는 Optimal Starting Point Time Series Forecast (OSP-TSP)라는 새로운 접근법을 제안하여, 시계열 데이터의 본질적인 특성을 캡처하고, 입력 데이터의 길이를 조절하여 예측 성능을 향상시키는 방법을 소개합니다.

- **Technical Details**: OSP-TSP는 XGBoost와 LightGBM 모델을 활용하여 시계열의 최적 시작점(Optimal Starting Point, OSP)을 결정합니다. 이 방법은 다양한 주파수에서 M4 데이터셋 및 실제 데이터셋으로 성능을 평가하였으며, OSP-TSP 기반 예측이 전체 데이터셋을 사용하는 경우보다 일관되게 우수한 예측 성능을 보였습니다.

- **Performance Highlights**: 실험 결과, OSP-TSP 방식은 과거 데이터에 비해 최근 데이터에 더 중점을 두어 예측 정확도를 향상시켰습니다. 또한, 충분한 데이터가 필요함을 인식하고, OSP 식별을 위한 데이터 부족 문제를 해결하기 위한 맞춤형 솔루션을 제안하였습니다.



### Large Language Model Predicts Above Normal All India Summer Monsoon Rainfall in 2024 (https://arxiv.org/abs/2409.16799)
Comments:
          3 figures

- **What's New**: 이번 연구에서는 AISMR(All India Summer Monsoon Rainfall)의 예측 정확도를 높이기 위해 최신 LLM 모델인 PatchTST를 조정하고 세부 조정을 했습니다.

- **Technical Details**: PatchTST 모델은 과거 AISMR 데이터, Niño3.4 지수 및 카테고리별 인도양 쌍극자(Indian Ocean Dipole) 값을 사용하여 훈련되었으며, 그 결과 여러 인기 있는 신경망 모델 및 통계 모델보다 더 높은 성능을 보여줍니다.

- **Performance Highlights**: Fine-tuned PatchTST 모델은 0.07%의 RMSE(Root Mean Square Error)와 0.976의 Spearman 상관관계를 기록하며, 이는 가장 성능이 좋은 신경망 모델보다 약 80% 더 높은 정확도를 나타냅니다. 이 모델은 2024년 몬순이 정상 이상으로 예상되며, 전체 국가에 대해 6월에서 9월까지 총 921.6mm의 강수량을 예측하고 있습니다.



### World Model-based Perception for Visual Legged Locomotion (https://arxiv.org/abs/2409.16784)
Comments:
          under review

- **What's New**: 이번 논문에서는 legged locomotion(다리가 있는 로봇의 보행)에서의 새로운 접근 방식인 World Model-based Perception(WMP)을 제안합니다. 기존의 프라이빗 정보에 의존하는 모방 학습 방식의 한계를 극복하고, 환경에 대한 모델을 기반으로 정책을 학습하는 방식을 제시합니다.

- **Technical Details**: WMP는 과거의 관측값을 활용하여 미래의 감각 정보를 예측하는 세계 모델을 훈련시키고, 이를 바탕으로 정책을 학습합니다. 논문은 기존의 Reinforcement Learning (RL)과 Model-Based Reinforcement Learning (MBRL) 접근 방식을 결합한 새로운 프레임워크를 개발했습니다. 또한, WMP는 Robo-Unitree A1 로봇에서 다양한 지형에서 테스트되었으며, 시뮬레이션에서 85cm의 Gap과 55cm의 Climb을 성공적으로 극복했습니다.

- **Performance Highlights**: WMP는 기존의 최첨단 기준 모델들과 비교하여 높은 성능을 보였고, 실제 환경에서의 테스트에서도 확인되었습니다. 특히, 시뮬레이션 환경에서 최적의 보상을 얻었으며, 실제 로봇 환경에서도 복잡한 지형에서의 성능을 크게 향상시켰습니다.



### MaViLS, a Benchmark Dataset for Video-to-Slide Alignment, Assessing Baseline Accuracy with a Multimodal Alignment Algorithm Leveraging Speech, OCR, and Visual Features (https://arxiv.org/abs/2409.16765)
- **What's New**: 이 논문에서는 강의 비디오와 해당 슬라이드를 정렬하는 벤치마크 데이터셋을 제시하고, 음성, 텍스트 및 이미지에서 특징을 활용하는 새로운 다중 모달 알고리즘을 소개합니다.

- **Technical Details**: 제안된 알고리즘은 동적 프로그래밍(dynamic programming)을 사용하여 최적의 슬라이드 시퀀스를 결정하며, OCR(Optical Character Recognition)을 통해 얻은 특징들이 매칭 정확도에 크게 기여한다고 보고합니다. 알고리즘은 SIFT(Scale-Invariant Feature Transform)에 비해 평균 0.82의 정확도를 기록하면서 속도는 약 11배 빨라졌습니다.

- **Performance Highlights**: 제안된 알고리즘은 다양한 강의 스타일과 비디오 품질에 따른 매칭 정확도의 차이를 보였으며, 슬라이드 전환을 제재할 경우 정확도가 향상되었습니다. 또한, 매칭의 정확도는 오디오 전사에 의해서도 유용한 정보를 제공하고, OCR 데이터가 부족할 때 더욱 유용함을 강조합니다.



### PMSS: Pretrained Matrices Skeleton Selection for LLM Fine-tuning (https://arxiv.org/abs/2409.16722)
- **What's New**: 최근에 제안된 PMSS(Pre-trained Matrices Skeleton Selection)는 LoRA의 한계를 극복하고, 사전 훈련된 가중치 내의 의미적 정보를 활용하여 높은 랭크 업데이트를 가능하게 하는 새로운 fine-tuning 방법입니다.

- **Technical Details**: PMSS는 사전 훈련된 행렬에서 스켈레톤을 선택하여 작은 행렬만 학습하도록 설계되었습니다. 이를 통해 낮은 비용으로 높은 랭크 업데이트를 달성합니다. PMSS는 DROP, commonsense reasoning, 수학적 추론과 같은 복잡한 작업에서 LoRA보다 우수한 성능을 보입니다.

- **Performance Highlights**: PMSS는 LLaMA2-7B/13B의 DROP 벤치마크에서 각각 +3.4%/+5.9% 성능 향상을 보였고, GSM8K 데이터셋에서 Mistral-7B, Gemma-7B에 대해 각각 +12.89%/+5.61%/+3.11%의 성과를 달성했습니다.



### Dashing for the Golden Snitch: Multi-Drone Time-Optimal Motion Planning with Multi-Agent Reinforcement Learning (https://arxiv.org/abs/2409.16720)
Comments:
          7 pages, 6 figures

- **What's New**: 최근의 자율 드론 혁신이 단일 드론 구성에서의 시간 최적 비행을 가능하게 하고, 여러 드론 시스템의 기동성을 최적 제어 및 학습 기반 방법을 통해 향상시켰습니다. 그러나 여러 드론 시스템의 시간 최적 모션 계획에 대한 연구는 아직 충분히 진행되지 않았습니다. 본 논문에서는 에이전트 간 강화 학습을 사용한 분산 정책 네트워크를 통해 여러 드론의 시간 최적 비행을 제시합니다.

- **Technical Details**: 우리는 최적화 기반 방법에서 영감을 받아 충돌 회피와 비행 효율성 간 균형을 맞추기 위해 소프트 충돌 패널티를 도입했습니다. 중앙 집중 훈련, 분산 실행(CTDE) 방식을 사용하여 PPO를 수정하여 훈련의 효율성과 안정성을 높이고, 온보드 컴퓨테이션만으로 경량 구현을 보장합니다. 이 연구는 여러 드론이 상대 충돌을 피하면서 시간 최적 성능으로 웨이포인트를 통과하는 훈련을 가능하게 합니다.

- **Performance Highlights**: 편리한 실험 결과, 제안된 방법은 단일 드론 시스템에 비해 약간의 성능 저하가 있었지만, 충돌률은 낮고 거의 시간 최적 성능을 유지했습니다. 실제 실험에서는 두 개의 쿼드로터가 시뮬레이션에서와 동일한 네트워크를 사용하여 최대 속도 13.65 m/s와 최대 바디 비율 13.4 rad/s를 달성했습니다.



### Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification (https://arxiv.org/abs/2409.16718)
Comments:
          EMNLP 2024 Main Conference

- **What's New**: 최근 Vision-Language Models (VLMs)에 대한 세밀한 조정이 이루어지면서, 클립 모델의 고유한 매개변수를 조정하는 것의 중요성을 재조명하였다. 이 연구에서는 모든 매개변수를 조정하는 대신 특정 매개변수만을 조정하는 CLIPFit 방법을 제안하였다.

- **Technical Details**: CLIPFit은 기존의 프롬프트 튜닝(prompt tuning) 및 어댑터 튜닝(adapter tuning) 방식과는 다르게, 추가적인 매개변수를 도입하지 않고 클립 모델의 특정 바이어스와 정규화 레이어만 조정하는 방법이다. 이로 인해 파라미터 수가 줄어들고, 성능이 향상된다.

- **Performance Highlights**: CLIPFit을 사용하여 zero-shot CLIP 대비 7.33%의 평균 조화 평균 정확도(harmonic mean accuracy) 개선을 달성하였으며, 이는 16-shot 설정에서 프롬프트 튜닝 및 어댑터 튜닝을 대체할 수 있는 유망한 옵션이다.



### A Survey of Low-bit Large Language Models: Basics, Systems, and Algorithms (https://arxiv.org/abs/2409.16694)
Comments:
          Ruihao Gong leads the overall organization of the survey, with Yifu Ding and Jinyang Du contributing to Sections 2 and 3. Xingyu Zheng is responsible for authoring Section 4, while Chengtao Lv and Zining Wang collaborate on Section 5. Haotong Qin, Jinyang Guo, Michele Magno, and Xianglong Liu provide guidance during the whole process and assist in refining the final manuscript

- **What's New**: 이 논문에서는 대형 언어 모델(LLMs)을 위한 저비트 양자화(low-bit quantization) 방법에 대한 종합적인 조사를 제공합니다. 이는 메모리 사용량과 계산 요구 사항을 줄여주어 LLM의 실제 구현에서 중요한 과제를 해결하는 데 기여합니다.

- **Technical Details**: 저비트 양자화는 모델의 파라미터, 활성화(activations), 그리고 그래디언트의 비트 폭을 줄이는 프로세스로, 메모리 사용량과 계산 요구를 감소시킵니다. 이 논문에서는 저비트 LLM의 기초 원리, 시스템 구현, 알고리즘 전략을 다루고 있습니다. 새로운 저비트 데이터 형식과 양자화 세분화(granularity), 정적 또는 동적 양자화의 차이점 등이 소개됩니다.

- **Performance Highlights**: 저비트 양자화는 LLM의 훈련(training) 및 추론(inference)을 가속화하며, 정확도를 유지하면서도 모델을 저장하는 데 필요한 자원을 줄이는 데 효과적입니다. 이 연구에서는 새로운 연구 분야, 잠재적인 혁신, 그리고 새로운 기술이 LLM 양자화에 미치는 영향을 논의하며, LLM의 효율성 및 적합성을 향상시키기 위한 가치 있는 통찰력을 제공합니다.



### Layout-Corrector: Alleviating Layout Sticking Phenomenon in Discrete Diffusion Mod (https://arxiv.org/abs/2409.16689)
Comments:
          Accepted by ECCV2024, Project Page: this https URL

- **What's New**: 이 논문은 기존의 Discrete Diffusion Models (DDMs)에서 발생하는 레이아웃 고착(Layout Sticking) 현상을 해결하기 위해 Layout-Corrector라는 새롭고 간단한 모듈을 제안합니다.

- **Technical Details**: Layout-Corrector는 레이아웃의 각 요소에 대한 정확성 점수를 평가하고, 저조한 점수를 가진 요소를 재초기화하여 하모니가 있는 레이아웃을 생성을 돕습니다. 이 모듈은 DDM과 함께 사용되며, 각 생성 과정에서 하모니를 고려하여 불일치하는 요소를 식별합니다.

- **Performance Highlights**: Layout-Corrector는 다양한 기준 벤치마크에서 테스트되어 DDM과 함께 사용할 경우 레이아웃 생성 성능을 일관되게 향상시키고, 정확성-다양성 무역의 조절을 통한 성능 저하를 완화합니다.



### TSBP: Improving Object Detection in Histology Images via Test-time Self-guided Bounding-box Propagation (https://arxiv.org/abs/2409.16678)
Comments:
          MICCAI 2024

- **What's New**: 본 논문에서는 Test-time Self-guided Bounding-box Propagation (TSBP) 방법을 제안하여, 물체 검출 성능을 크게 향상시키는 새로운 접근 방식을 소개합니다. 이 방법은 고신뢰도 바운딩 박스의 정보를 활용하여 저신뢰도 바운딩 박스를 조정합니다.

- **Technical Details**: TSBP는 Earth Mover's Distance (EMD)를 활용하여 시각적 유사성을 바탕으로 바운딩 박스 간의 정보를 전파합니다. 이 과정은 신뢰도가 낮은 바운딩 박스의 클래스 레이블을 보정하며, 별도의 라벨링된 샘플이 요구되지 않아 기존의 불확실성 보정 방법과 차별화됩니다.

- **Performance Highlights**: 실험 결과, TSBP는 기존의 불확실성 보정 방법에 비해 더욱 견고하고 정확한 물체 검출 결과를 제공합니다. 특히 상태-of-the-art 딥러닝 기반 검출 네트워크와 함께 사용했을 때 성능이 크게 향상되었습니다.



### CryptoTrain: Fast Secure Training on Encrypted Datas (https://arxiv.org/abs/2409.16675)
Comments:
          Accepted by CCS-LAMPS 2024

- **What's New**: CryptoTrain-B라는 혼합 암호화 프로토콜을 기반으로 한 새로운 안전한 훈련 시스템이 개발되었습니다. 이 시스템은 Fully Homomorphic Encryption(FHE)과 Oblivious Transfer(OT)를 결합하여 불필요한 부트스트래핑을 제거합니다.

- **Technical Details**: 프로토콜에서는 암호화된 입력 및 모델을 포함하는 연산에서 CCMul(비밀문자-비밀문자 곱셈)이 주요 병목 현상으로 지적되었습니다. CCMul-Precompute 기법을 통해, 오프라인에서 CCMul을 미리 계산하고, 훈련 중 리소스가 덜 소모되는 ciphertext-plaintext multiplication(CPMul)으로 전환합니다. 또한, 기존의 다항식 컨볼루션에서는 관련 없는 값을 다항식 슬롯에 인코딩하므로 추가적인 연산이 필요합니다. 이를 해결하기 위해 관련된 입력 값만 인코딩하는 correlated polynomial convolution을 도입했습니다.

- **Performance Highlights**: CryptoTrain은 이전 방법들에 비해 훈련 시간을 약 5.3배 단축시키는 성능 개선을 보여주었습니다.



### SWE2: SubWord Enriched and Significant Word Emphasized Framework for Hate Speech Detection (https://arxiv.org/abs/2409.16673)
Comments:
          Published in CIKM 2020

- **What's New**: 이 논문에서는 Hate speech(혐오표현) 문제를 해결하기 위한 새로운 프레임워크(SWE2)를 제안합니다. SWE2는 메시지의 내용만을 기반으로 하며, 혐오표현을 자동으로 식별합니다.

- **Technical Details**: SWE2는 두 가지 유형의 서브워드 임베딩(phonetic-level embedding 및 character-level embedding)을 활용합니다. 또한, LSTM+attention 기반의 특성 추출 방법을 설계하여, 전반적인 내용의 의미 정보를 추출합니다. 이 프레임워크는 FastText와 BERT에서의 사전 학습된 변형을 비교하여 어떤 것이 서브워드 표현을 보완하는지 확인했습니다.

- **Performance Highlights**: 우리 모델은 백도어 공격 없이 0.975의 정확도와 0.953의 macro F1 점수를 달성하며 7개의 최신 방법론보다 우수합니다. 극단적인 공격 상황에서도 0.967의 정확도와 0.934의 macro F1 점수를 유지하여 높은 견고성을 입증하였습니다.



### Wildlife Product Trading in Online Social Networks: A Case Study on Ivory-Related Product Sales Promotion Posts (https://arxiv.org/abs/2409.16671)
Comments:
          ICWSM 2024

- **What's New**: 본 논문은 온라인 사회적 네트워크에서의 야생동물 제품 판매 홍보 행동을 탐지하고 인식하는 과제에 초점을 맞추고 있으며, 이를 위해 인간-인-루프 머신 러닝 과정을 통한 데이터 수집 및 레이블링 방법을 제안합니다.

- **Technical Details**: 1) 기존 연구와 달리, 본 연구는 network-propagation을 기반으로 한 데이터 수집 방법을 통해 야생동물 제품 거래에 관한 스케일 가능한 데이터셋을 생성하고, 이를 통해 양성과 어려운 부정 클래스(hard-negatives)의 샘플을 구분합니다. 2) 제안된 데이터셋을 활용하여 머신 러닝 결과를 벤치마크하고, 의심스러운 야생동물 판매 게시물 및 계정을 자동으로 식별하는 실용적인 프레임워크를 구축합니다. 3) 판매 게시물의 체계화된 분석을 통해 현재의 판매 행동 및 패턴을 심층적으로 탐구합니다.

- **Performance Highlights**: 이 논문은 첫 번째로 사회적 네트워크에서의 야생동물 거래 관련 게시물에 대한 스케일 가능한 데이터셋을 소개하며, 다중 모달리티(Multi-modality)를 활용하여 머신 러닝 알고리즘의 활발한 자동 식별 가능성을 입증합니다. 연구 결과는 여러 평가 지표를 통해 제안된 방법의 성능을 명확히 보여줍니다.



### Mitigating Covariate Shift in Imitation Learning for Autonomous Vehicles Using Latent Space Generative World Models (https://arxiv.org/abs/2409.16663)
Comments:
          7 pages, 6 figures, for ICRA 2025 conference, for associated video file, see this https URL

- **What's New**: 본 논문에서는 자율주행에서 발생하는 covariate shift 문제를 해결하기 위해 잠재 공간 생성 세계 모델(latent space generative world models)의 사용을 제안합니다. 저자들은 드라이빙 정책이 인간의 행동을 따른 학습을 활용하여 오류에서 회복할 수 있도록 설계하였으며, 실제 환경에서도 훈련 데이터의 분포를 초과한 perturbations에 대응할 수 있음을 보여줍니다.

- **Technical Details**: 제안된 시스템은 잠재 공간 생성 세계 모델을 통해 드라이빙 정책을 공동 학습하는 구조를 가지고 있으며, 새로운 ego 상태를 샘플링하여 훈련 데이터에서 발견되지 않았던 상태를 탐색합니다. 이를 통해 driving policy가 인간의 시연에서 관찰된 상태에 대해 더 가깝게 행동을 선택할 수 있도록 합니다. 또한, 다중 뷰 크로스 어텐션(multi-view cross-attention)을 사용하는 새로운 Transformer 기반의 인식 인코더(perception encoder)를 도입하였습니다.

- **Performance Highlights**: 실험 결과, 저자들은 CARLA 시뮬레이터와 NVIDIA DRIVE Sim에서 닫힌 루프(closed-loop) 테스트를 통해 이전 최첨단 기술보다 유의미한 개선을 달성하였으며, 다양한 perturbations을 처리할 수 있는 능력을 입증하였습니다.



### Learning Representation for Multitask learning through Self Supervised Auxiliary learning (https://arxiv.org/abs/2409.16651)
- **What's New**: 이번 논문에서는 Multi-task learning에서 공유 인코더의 표현 품질을 개선하기 위한 새로운 방법인 Dummy Gradient norm Regularization(DGR)을 제안합니다. 이 방법은 공유 인코더의 보편성을 향상시키는 것을 목표로 하며, 이제까지 해결되지 않았던 문제를 다룹니다.

- **Technical Details**: DGR은 더미(문자 없음) task-specific predictor에 대한 손실 함수의 기울기(norm)를 감소시켜 공유 인코더의 표현의 보편성을 높입니다. 이 방식은 기존의 Multi-task learning 알고리즘과의 통합이 쉬워, 여러 기준을 사용한 실험을 통해 효과성이 입증되었습니다.

- **Performance Highlights**: 여러 Multi-task learning 기준 데이터셋에 대한 실험에서, DGR은 공유 표현의 품질을 효과적으로 개선하여 Multi-task 예측 성능을 높였습니다. DGR을 적용한 다양한 분류기에서 기존의 Multi-task learning 방법들보다 우수한 성능을 보였습니다.



### Domain-Independent Automatic Generation of Descriptive Texts for Time-Series Data (https://arxiv.org/abs/2409.16647)
- **What's New**: 이번 연구에서는 시간 시계열 데이터로부터 설명적인 텍스트를 체계적으로 생성하는 도메인 독립적인 방법을 제안합니다. 특히, 시간 시계열 데이터와 설명 텍스트의 쌍을 생성하기 위해 두 가지 접근 방법, 즉 forward approach와 backward approach를 정의하고, 새로운 backward approach를 통해 TACO 데이터셋을 생성합니다.

- **Technical Details**: TACO (Temporal Automated Captions for Observations) 데이터셋은 120만 개의 실제 시간 시계열 데이터 샘플을 사용하여 생성되었습니다. 연구진은 먼저 시간 시계열 클래스 세트를 정의하고, 각 클래스를 기준으로 점수를 계산하여 시간 시계열 데이터를 분류한 후, 이에 해당하는 설명 텍스트를 생성했습니다. 이 과정에서 min-max scaling을 사용하여 데이터와 점수를 정규화하였으며, Llama-3-8B-Instruct 모델을 활용하여 기초 설명 텍스트를 재구성했습니다.

- **Performance Highlights**: 제안된 방법으로 훈련된 contrastive learning 기반 모델은 새로운 도메인에서도 시간 시계열 데이터에 대해 도메인 독립적인 설명 텍스트를 효과적으로 생성할 수 있음을 실험 결과를 통해 입증하였습니다.



### Examining the Rat in the Tunnel: Interpretable Multi-Label Classification of Tor-based Malwar (https://arxiv.org/abs/2409.16639)
- **What's New**: Tor 네트워크의 악성 트래픽을 정확히 분류하는 데 초점을 맞춘 최신 연구로, 기존의 방안보다 90% 이상의 성능을 달성하였다.

- **Technical Details**: Message-Passing Neural Networks (MPNN) 기반의 다중 레이블 분류 기법을 사용하여 Micro Average Precision (MAP), Micro Average Recall (MAR) 및 Hamming Loss에서 유의미한 향상을 보여준다. 또한, Explainable Artificial Intelligence (XAI) 기법을 통해 모델의 예측 과정 해석을 시도하였다.

- **Performance Highlights**: MAP 95.44%, MAR 93.98% 달성, 이전 방법들에 비해 19.98%, 10.15%, 59.21%의 성능 향상 기록. 모든 기법의 강건성은 적대적 왜곡을 통해 평가됨.



### PIFS-Rec: Process-In-Fabric-Switch for Large-Scale Recommendation System Inferences (https://arxiv.org/abs/2409.16633)
- **What's New**: 이 논문은 Deep Learning Recommendation Models (DLRMs)의 성능 개선을 위해 CXL(Compute Express Link) 기술을 활용하여 새로운 PIFS-Rec(장비 스위치 내 작업 처리) 접근 방식을 제안합니다. 이는 메모리 및 대역폭 확장을 최적화하여 DLRMs를 가속화하는 데 중점을 둡니다.

- **Technical Details**: CXL 시스템에서 DLRM 작업량을 특성화하고 주된 병목 현상을 식별합니다. PIFS-Rec는 데이터 프로세싱과 효율적인 메모리 사용을 위한 하드웨어 및 소프트웨어 최적화를 결합하여, 낮은 대기 시간으로 Pond 및 BEACON과의 비교에서 각각 3.89배 및 2.03배 우수한 성능을 보입니다.

- **Performance Highlights**: PIFS-Rec는 CXL 기반 시스템에서의 DLRM 작업의 성능을 크게 향상시킵니다. 본 연구에서 제안한 접근 방식은 데이터 이동 비용을 줄이고, 메모리 대역폭 병목 현상을 해결하여 데이터 센터 규모의 DLRM 처리 성능을 극대화합니다.



### Evaluating and Enhancing Large Language Models for Novelty Assessment in Scholarly Publications (https://arxiv.org/abs/2409.16605)
Comments:
          under review

- **What's New**: 본 논문에서는 LLM(대형 언어 모델)의 학술 논문에서의 창의성 및 참신성을 평가하기 위한 새로운 벤치마크인 SchNovel을 도입하였습니다. 이 벤치마크는 arXiv 데이터 세트에서 선택된 15,000 쌍의 논문으로 구성되어 있으며, 각 쌍의 최근 발표된 논문이 더 참신하다고 가정합니다. 또한, RAG-Novelty라는 새로운 방법을 제안하여 LLM이 논문의 참신성을 평가할 때 유사한 논문의 검색을 활용합니다.

- **Technical Details**: SchNovel 벤치마크는 2~10년 차이가 나는 논문 쌍을 포함하며, 이는 특히 높은 수준의 리뷰 과정을 거치는 학술 논문에서 참신성을 평가하는 데 중요합니다. RAG-Novelty는 검색 기반 생성 방법으로, 더 참신한 논문일수록 최근 발표된 논문을 더 많이 검색할 것이라는 가정을 바탕으로 합니다.

- **Performance Highlights**: 광범위한 실험을 통해 RAG-Novelty가 기존의 기준 모델보다 논문의 참신성을 평가하는 데 더 뛰어난 성능을 보인다는 것을 입증했습니다. 이 연구는 LLM의 논문 참신성 평가 능력을 깊이 있게 탐구하고, 다양한 카테고리와 출판 연도 간의 변화를 평가하여 LLM의 성능 향상에 기여하였습니다.



### Generative Pre-trained Ranking Model with Over-parameterization at Web-Scale (Extended Abstract) (https://arxiv.org/abs/2409.16594)
- **What's New**: 본 연구에서는 웹 검색에서 중요한 웹페이지를 우선순위로 설정하기 위한 새로운 학습 모델인 Generative Semi-Supervised Pre-trained (GS2P) LTR 모델을 제안합니다. 이 모델은 부족한 주석(query-webpage pairs with ranking scores)의 문제를 해결하고, 일반화된 표현을 학습하도록 설계되었습니다.

- **Technical Details**: GS2P 모델은 고품질의 유사 레이블을 추출하기 위해 다양한 LTR 모델의 코-트레이닝(co-training)을 사용합니다. 이 과정에서 일반화된 표현을 학습하기 위해 자기 주의(self-attentive) 네트워크를 활용하며, MLP 기반의 ranker와 Random Fourier Features (RFF)를 조합하여 성능을 향상시킵니다.

- **Performance Highlights**: GS2P 모델은 공개 데이터셋과 실제 대규모 검색 엔진에서 수집한 데이터셋을 사용하여 실험을 수행하였으며, A/B 테스트를 통해 기존 시스템 대비 현저한 성능 향상을 보여주었습니다.



### MambaJSCC: Adaptive Deep Joint Source-Channel Coding with Generalized State Space Mod (https://arxiv.org/abs/2409.16592)
Comments:
          submitted to IEEE Journal

- **What's New**: 본 논문에서는 저전력 및 효율적인 신경망 모델인 MambaJSCC를 제안합니다. 해당 모델은 깊은 공동 소스-채널 코딩(deep joint source-channel coding, JSCC)을 위한 혁신적인 아키텍처로, 낮은 계산량 및 파라미터 오버헤드로 최첨단 성능을 달성합니다.

- **Technical Details**: MambaJSCC는 이미지 전송을 위해 VSSM-CA(visual state space model with channel adaptation) 블록을 백본 모델로 사용하며, GSSM(generalized state space models) 및 CSI-ReST(zero-parameter, zero-computational channel adaptation method)를 포함한 구조를 가지고 있습니다. GSSM 모듈은 가역적인 매트릭스 변환을 활용하여 일반화된 스캔 확장 작업을 표현하며, 두 개의 GSSM 모듈이 효과적으로 글로벌 정보를 캡처할 수 있음을 이론적으로 증명했습니다.

- **Performance Highlights**: MambaJSCC는 다양한 실험을 통해 기존의 JSCC 방법(예: SwinJSCC)을 모든 주요 아키텍처와 비교하여 왜곡(distortion) 및 지각(perception) 측면에서 우수한 성능을 보였으며, 전반적인 파라미터 크기, 계산 오버헤드, 추론 지연이 크게 감소했습니다. 특히, 최고 신호 대 잡음비(peak-signal-to-noise ratio, PSNR)에서 0.52 dB의 성능 향상을 보여주었습니다.



### FLaRe: Achieving Masterful and Adaptive Robot Policies with Large-Scale Reinforcement Learning Fine-Tuning (https://arxiv.org/abs/2409.16578)
- **What's New**: 최근 로봇 공학 분야에서는 대규모 다중 작업 Behavior Cloning을 통해 일반화된 로봇 정책을 구축하기 위한 여러 노력이 진행되고 있습니다. 본 논문에서는 FLaRe라는 대규모 Reinforcement Learning 미세 조정 프레임워크를 제안하여, 사전 훈련된 표현을 통합하고, 대규모 훈련 및 그래디언트 안정화 기술을 사용하여 성능 향상을 목표로 합니다.

- **Technical Details**: FLaRe는 다중 작업 로봇 정책에서 시작하여 대규모 RL을 통한 미세 조정을 수행합니다. 이 과정에서 안정적인 RL 미세 조정을 보장하기 위해 간단하면서도 효과적인 기술을 도입하며, 이를 통해 성능을 대폭 향상시킵니다. FLaRe는 15배의 훈련 시간 단축을 제공하고, 전통적인 손으로 설계된 보상 함수 없이도 작동할 수 있습니다.

- **Performance Highlights**: FLaRe는 가정용 모바일 조작 작업에서 평균 79.5%의 성공률을 달성하며, 이전 SoTA 방법에 비해 +23.6%의 절대 향상을 기록했습니다. 실제 로봇에서의 성능도 평균 80.7%를 달성하며, 이전 최고 기록에 비해 +30.7% 개선된 결과를 보였습니다. FLaRe는 미세 조정에 필요한 인력이 적고, 새로운 구조와 행동에 빠르게 적응할 수 있는 장점을 가지고 있습니다.



### Source-Free Domain Adaptation for YOLO Object Detection (https://arxiv.org/abs/2409.16538)
Comments:
          ECCV 2024: European Conference on Computer Vision - Workshop on Out-of-Distribution Generalization in Computer Vision Foundation Models, Milan Italy

- **What's New**: 본 논문에서는 Object Detection(OD)의 Source-Free Domain Adaptation(SFDA) 분야에서 YOLO 계열의 단일 단계 탐지기를 향상시키는 새로운 방법인 Source-Free YOLO(SF-YOLO)를 제안합니다.

- **Technical Details**: SF-YOLO는 Teacher-Student 프레임워크를 기반으로 하여, 학생 모델이 특정 타겟 도메인에 대한 학습된 데이터 증강 기법을 통해 훈련됩니다. 이 방법은 레이블이 없는 타겟 데이터만을 사용하며 기능 정렬(Feature Alignment)을 요구하지 않습니다. 또한, 새로운 Student Stabilisation Module(SSM)을 도입하여 훈련의 안정성을 높이고, 레이블이 없는 상황에서의 정확도 저하 문제를 해결합니다.

- **Performance Highlights**: 실험 결과, SF-YOLO는 Cityscapes, Foggy Cityscapes, Sim10k, KITTI 데이터셋에서 여러 도전적인 도메인 적응 벤치마크에서 현재의 최고 성능을 보이는 탐지기들과 경쟁할 수 있으며, 심지어는 소스 데이터를 사용하는 적응 방법보다 나은 성능을 기록하기도 하였습니다. 저희의 접근법은 낮은 계산 자원을 요구하며, 실용적인 실시간 응용에 적합합니다.



### GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization (https://arxiv.org/abs/2409.16502)
Comments:
          Project website at this https URL

- **What's New**: 본 연구에서는 3D Gaussian Splatting (3DGS) 기술을 활용하여 시각적 로컬라이제이션(visual localization)을 향상시키는 새로운 프레임워크 GSplatLoc을 제안합니다. 이 방법은 기존의 메모리 소모나 최적화 요구 사항을 해결하는 데 중점을 두고 있습니다.

- **Technical Details**: GSplatLoc은 XFeat의 경량 키포인트 감지 및 기술 모델로 생성된 고밀도 기술 맵을 활용하여 3DGS에 밀집된 키포인트 설명자(dense keypoint descriptors)를 증류(distill)합니다. 이를 통해 공간 이해도를 개선하고, 2D-3D 대응(relations)을 통해 더 정확한 카메라 포즈 예측을 가능하게 합니다. 초기 포즈 추정 후에는 포토메트릭 왜곡 손실(photometric warping loss)을 사용하여 포즈를 세분화(refine)합니다.

- **Performance Highlights**: 이번 연구는 인기 있는 실내 및 실외 데이터셋에서 벤치마킹한 결과, 기존의 최첨단 Neural Render Pose (NRP) 방법들, 특히 NeRFMatch와 PNeRFLoc을 능가하는 성과를 보여주었습니다.



### Exploring Knowledge Tracing in Tutor-Student Dialogues (https://arxiv.org/abs/2409.16490)
- **What's New**: 최근 대형 언어 모델(LLMs)의 발전으로 인공지능(AI) 기반의 튜터링 챗봇이 개발되었습니다. 본 연구에서는 학생과 튜터 간의 대화에서 학생 행동을 모델링하는 새로운 접근을 제안합니다. 대화 회차(turn)에 대한 분석을 통해 학생의 지식 수준을 추적하고 오해를 파악할 수 있는 가능성을 제시합니다.

- **Technical Details**: 본 연구는 두 가지 주요 단계를 통해 대화 지식 추적(dialogue knowledge tracing, KT)을 수행합니다: i) 사전 학습된 LLM인 GPT-4o를 사용하여 대화 데이터를 주석 처리하고, ii) 주석이 달린 데이터를 이용해 KT 모델을 훈련합니다. 제안하는 LLMKT 방법은 Llama 3 모델을 활용하여 KT 목표를 위해 미세 조정하고, 기존의 DKT 방법의 임베딩을 시맨틱 텍스트 임베딩으로 대체하는 DKT-Sem을 소개합니다.

- **Performance Highlights**: LLMKT 방법은 두 가지 튜터-학생 수학 대화 데이터셋에서 기존 KT 방법들보다 크게 향상된 성능을 보여주었으며, 이 방법들은 적은 훈련 데이터로도 효과적일 수 있음을 입증했습니다. 또한 GPT-4o의 대화 주석이 전문가의 평가에 따라 정확하다는 점을 보여줘 향후 연구 방향성을 제안합니다.



### Diffusion Models to Enhance the Resolution of Microscopy Images: A Tutoria (https://arxiv.org/abs/2409.16488)
Comments:
          45 pages, 8 figures

- **What's New**: 본 튜토리얼에서는 Denoising Diffusion Probabilistic Models (DDPMs)을 사용하여 저해상도 현미경 이미지를 그에 상응하는 고해상도 이미지로 변환하는 방법에 대한 포괄적인 가이드를 제공합니다.

- **Technical Details**: 이 논문에서는 Diffusion Models을 기반으로한 이미지-이미지 변환 기술을 구현하는 방법을 설명하며, PyTorch를 사용한 구체적인 코드 구현과 함께 필요한 수학적 이론과 배경 지식을 포함합니다. 또한 microtubule 구조 이미지와 같은 실제 데이터를 활용하여 모델 성능을 향상시키는 기법에 대해서도 다룹니다.

- **Performance Highlights**: Diffusion 모델은 텍스트-이미지 변환 및 이미지 변환 작업에서 성공적으로 사용되고 있으며, 생물학적 구조를 복원하는 데 있어 뛰어난 해상도를 제공합니다. 특히, 저해상도 이미지를 체계적으로 처리하며, 딥러닝을 통한 단일 이미지 초해상도(SISR) 분야에서 긍정적인 결과를 나타내고 있습니다.



### Score-based Neural Ordinary Differential Equations for Computing Mean Field Control Problems (https://arxiv.org/abs/2409.16471)
- **What's New**: 이 논문은 고차 미분 방정식을 포함하는 신경 변별 방정식(neural differential equations) 시스템을 제안하여 경로를 따라 first- 및 second-order score functions를 나타냅니다. 기존의 각각의 노이즈를 가진 mean field control (MFC) 문제를 새로운 최적화 문제로 재구성하는 방법도 소개합니다.

- **Technical Details**: 제안된 신경 ODE 시스템은 확률 밀도 함수의 변화를 근사하는 데 중요한 gradient와 Hessian을 포함한 신경 역학을 발전시킵니다. 또한, 고차 정규화흐름(high-order normalizing flows)을 사용하여 MFC 문제를 해결하려고 합니다. 이 과정에서 새로운 정규화 항을 도입하여 점성 Hamilton--Jacobi--Bellman (HJB) 방정식의 특성이 만족되도록 합니다.

- **Performance Highlights**: 다양한 MFC 문제를 해결하기 위한 수치 예제를 통해 제안된 최적화 방법이 효과적이며 정확한 성능을 보임을 입증하였습니다. 이 방법은 전통적인 방법보다 효율적으로 stochastic dynamics와 개인 간의 상호작용을 포착합니다.



### A Multi-Agent Multi-Environment Mixed Q-Learning for Partially Decentralized Wireless Network Optimization (https://arxiv.org/abs/2409.16450)
Comments:
          Submitted to 2025 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)

- **What's New**: 본 논문에서는 부분적으로 분산된 무선 네트워크를 위한 새로운 다중 에이전트 MEMQ 알고리즘을 제안합니다. 이 알고리즘은 여러 모바일 송신기(TX)와 기지국(BS)으로 구성된 네트워크에서 독립적으로 또는 협조적으로 작업할 수 있도록 설계되었습니다.

- **Technical Details**: TX는 서로의 상태와 동작에 접근할 수 없으며, 비협조적 상태에서는 개별 비용을 최소화하기 위해 독립적으로 행동합니다. 협조적 상태에서는 TX가 로컬 관찰에 기반하여 공동 상태를 추정하고, 리더 TX와 최소한의 정보를 공유하여 공동 비용을 최소화합니다. 정보 공유 비용은 TX의 수에 따라 선형적으로 증가하며, 공동 상태-행동 공간의 크기와는 무관합니다.

- **Performance Highlights**: 제안된 알고리즘은 중앙 집중식 MEMQ에 비해 50% 더 빠르며, 평균 정책 오류(APE)는 20% 증가합니다. 또한, 여러 고급 분산 Q-learning 알고리즘에 비해 25% 빠르며, APE는 40% 감소합니다. 알고리즘의 수렴 속도 또한 빠른 것으로 평가되었습니다.



### A novel open-source ultrasound dataset with deep learning benchmarks for spinal cord injury localization and anatomical segmentation (https://arxiv.org/abs/2409.16441)
- **What's New**: 이번 연구에서는 10,223개의 Brightness-mode (B-mode) 초음파 이미지를 포함하는 대규모 데이터셋을 공개했습니다. 이 데이터셋은 대칭 단면을 가진 25마리의 육계 소에서 얻은 것으로, 부상 전후의 척수 이미지를 포함합니다. 또한, 여러 최첨단 객체 탐지 알고리즘의 성능을 비교 분석하여 부상 부위의 위치를 파악하고 해부학적 구조에 레이블을 붙이는 방법을 제시하였습니다.

- **Technical Details**: 이 연구에서 사용된 YOLOv8 객체 탐지 모델은 부상 위치 탐지에서 평균 정확도(mAP50-95) 0.606을 달성하여 최상의 성능을 기록했습니다. DeepLabv3 세분화 모델은 보이지 않는 육계 생리학에 대해 평균 Dice 점수 0.587을 기록했고, SAMed는 인간 해부학에 대한 제로샷 일반화에서 0.445의 평균 Dice 점수를 달성하였습니다. 데이터셋은 건강한 및 손상된 척수의 해부학적 구조를 포함합니다.

- **Performance Highlights**: 본 연구는 SCI(척수 손상)에 대한 자동화된 지속 진단의 최초 선구적 노력을 담고 있으며, 연구자와 의료전문가들이 사용할 수 있는 가장 큰 주석 데이터셋을 제공함으로써 임상 결과를 향상시키기 위한 맞춤형 치료의 새로운 방법을 모색하고 있습니다.



### Leveraging Local Structure for Improving Model Explanations: An Information Propagation Approach (https://arxiv.org/abs/2409.16429)
- **What's New**: 최근 심층 신경망(DNN) 모델의 결정 해석을 위한 다양한 설명 방법들이 개발되었으며, 본 논문에서는 IProp이라는 새로운 방법을 제안합니다. IProp은 각 픽셀의 기여도를 독립적으로 평가하는 대신, 이웃 픽셀과의 구조적 유사성을 고려해 공동으로 평가합니다.

- **Technical Details**: IProp은 각 픽셀의 기여도를 설명 정보의 소스로 모델링하며, Markov Reward Process(MRP)를 통해 모든 픽셀 간의 정보 전파를 다이나믹하게 처리합니다. 정보 전파는 연속적으로 발생하며, 픽셀 간의 상관관계를 포착합니다.

- **Performance Highlights**: IProp은 다양한 DNN 모델과 기존 설명 방법에 대한 실험을 통해 해석 가능성 메트릭에서 현저한 개선을 확인했으며, 정량적 및 정성적으로 모든 기준 방법보다 우수한 결과를 보여주었습니다.



### Statistical tuning of artificial neural network (https://arxiv.org/abs/2409.16426)
Comments:
          18 pages,4 figures, 11 tables and 7 algorithms

- **What's New**: 이번 연구는 신경망의 해석 가능성을 향상시키기 위한 새로운 방법론을 소개합니다. 특히, 단일 은닉층(single hidden layer)을 가진 모델에 초점을 맞추어 신경망 추정기가 비모수 회귀 모델(nonparametric regression model)으로 해석될 수 있음을 입증했습니다.

- **Technical Details**: 연구에서는 입력 뉴런의 중요성을 평가하기 위한 통계적 테스트(statistical tests)와 네트워크의 이해도를 높이기 위한 차원 축소(dimensionality reduction) 알고리즘인 클러스터링(clustering) 및 주성분 분석(PCA)을 제안했습니다. 또한 인공 신경망(ANN)의 성능을 평가하기 위한 부트스트래핑 기법(bootstrapping technique)을 개발했습니다.

- **Performance Highlights**: IDC와 Iris 데이터셋을 활용하여 제안된 방법론의 실제 유용성을 검증하였으며, 이 연구는 신경망의 해석 가능성을 제고하여 입력, 출력 및 개별 네트워크 구성 요소 간의 관계를 이해하는 데 도움을 줍니다.



### Lessons for Editors of AI Incidents from the AI Incident Databas (https://arxiv.org/abs/2409.16425)
Comments:
          8 pages, 0 figures

- **What's New**: 본 연구는 AI 사건 데이터베이스(AIID)의 750개 이상의 AI 사건을 검토하고, 이러한 사건에 적용된 두 개의 독립적인 분류 체계를 분석하여 AI 사건 인덱싱 및 분석에 대한 공통적인 도전 과제를 식별합니다. 연구자는 AI 사건 보고에서 불확실성을 피할 수 없는 구조적 모호성을 발견하고, 이러한 불확실성과 관련된 사건 프로세스를 보다 강화할 수 있는 방법을 보고합니다.

- **Technical Details**: AIID는 AI 사건을 분류하고 기록하는 플랫폼으로, AI 사건에 대한 메타데이터를 제공하여 사건의 재발 방지를 위한 분석을 가능하게 합니다. AIID는 두 가지 주요 세부 분류 체계인 CSET AI Harm Taxonomy와 Goals, Methods, and Failures Taxonomy를 통해 각 사건을 구체적이고 다양한 관점에서 분석하며, 750개 이상의 AI 사건을 포함하여 3000개 이상의 제3자 보고서를 인덱스하여 제공합니다.

- **Performance Highlights**: AIID의 데이터셋은 다양한 AI 시스템과 맥락을 포괄하며, 자율 주행 차량 사고와 알고리즘적 차별과 같은 다양한 사건을 포함합니다. AIID의 결과는 AI 사건의 발생 빈도를 줄이고, AI 시스템 개발 및 배포의 안전성을 높이는 데 기여합니다.



### Towards Representation Learning for Weighting Problems in Design-Based Causal Inferenc (https://arxiv.org/abs/2409.16407)
Comments:
          UAI 2024, typos in UAI version fixed

- **What's New**: 이 논문에서는 최적 가중치의 추정 과정에서 표본의 결과(outcome) 정보 없이도 효과적으로 작동하는 디자인 기반 가중치(design-based weights)에 대한 새로운 접근 방식을 제시합니다. 특히, 표현 학습(representation learning)이 가중치를 효과적으로 찾는 데 중요한 역할을 한다고 강조합니다.

- **Technical Details**: 기존의 접근 방법과는 달리, 이 연구는 표현의 선택으로 인한 오류를 주목하며 이 오류를 최소화하기 위한 일반적인 프레임워크를 제안합니다. 최근의 연구와 연결하여, 가중치와 신경망(neural networks)을 결합하여 유연한 표현을 학습할 수 있는 end-to-end 추정 절차를 제안합니다.

- **Performance Highlights**: 우리는 제안한 방법이 치료 효과 추정에서 벤치마크 데이터셋을 기반으로 경쟁력 있는 성과를 보여줌을 입증합니다. 학습된 표현은 모든 가중치 방법의 입력으로 사용할 수 있어, 일반적인 전처리 방법으로 활용될 수 있습니다.



### Rao-Blackwellized POMDP Planning (https://arxiv.org/abs/2409.16392)
- **What's New**: 본 연구는 Rao-Blackwellized POMDP (RB-POMDP) 근사 해법을 도입하고, 신념 업데이트(belief updates) 및 온라인 계획(online planning)에서 Rao-Blackwellization을 적용하기 위한 일반적인 방법들을 제시합니다.

- **Technical Details**: Partially Observable Markov Decision Processes (POMDPs)는 불확실성 하에서 의사 결정을 위한 구조화된 프레임워크를 제공합니다. Sequential Importance Resampling Particle Filters (SIRPF)는 대규모 근사 POMDP 풀링기에서 신념 업데이트에 흔히 사용되지만, 시스템의 상태 차원이 증가함에 따라 입자 부족(particle deprivation) 및 높은 계산 비용(computational costs) 등의 문제에 직면합니다.

- **Performance Highlights**: 시뮬레이션된 로컬라이제이션 문제에서 SIRPF와 Rao-Blackwellized Particle Filters (RBPF)의 성능을 비교한 결과, RBPF가 적은 수의 입자로 시간이 지남에 따라 정확한 신념 근사를 유지하며, 더욱 놀라운 점은 RBPF가 사각형 기반 통합(quadrature-based integration)과 결합될 경우 SIRPF 기반 계획보다 질적으로 planning 품질이 크게 향상된다는 것을 확인했습니다.



### Development and Application of a Sentinel-2 Satellite Imagery Dataset for Deep-Learning Driven Forest Wildfire Detection (https://arxiv.org/abs/2409.16380)
- **What's New**: 본 연구에서는 Google Earth Engine(GEE)에서 소싱한 양 시점의 Sentinel-2 위성 이미지를 활용하여 10만 개 이상의 레이블이 부착된 산불 전후 이미지 쌍으로 이루어진 California Wildfire GeoImaging Dataset(CWGID)을 구축하여 딥러닝(DL)을 통한 산불 탐지를 위해 기여하고자 하였습니다.

- **Technical Details**: CWGID는 고해상도 위성 이미지 데이터셋으로, 데이터 획득은 권위 있는 출처에서 이루어졌으며, 세 가지 사전 훈련된 Convolutional Neural Network(CNN) 아키텍처를 활용하여 초기 데이터세트 분석이 진행되었습니다. 특히 EF EfficientNet-B0 모델이 산불 탐지에서 92% 이상의 정확도를 달성하였습니다.

- **Performance Highlights**: CWGID와 이를 구축하는 방법론은 DL 아키텍처 훈련 및 테스트를 위한 귀중한 자원으로 작용하며, 모델 훈련 및 평가 시 높은 정확도와 낮은 손실을 기록하였습니다. 본 연구는 산불 탐지를 위한 높은 품질의 레이블 이미지 데이터셋의 필요성을 강조하며, 산불 전후 이미지를 사용하여 성능을 개선하는 데 기여하고 있습니다.



### Scalable quantum dynamics compilation via quantum machine learning (https://arxiv.org/abs/2409.16346)
- **What's New**: 본 연구에서는 Variational Quantum Compilation (VQC) 방법을 통해 복잡한 양자 동역학 시뮬레이션의 효율성을 크게 향상시킴을 보였다. 특히, 분산(Distribution) 외 일반화를 통해 많은 바디 동역학을 작은 데이터 세트로 학습하여 단위원 회로를 생성하는 혁신적인 접근 방식을 제시하였다.

- **Technical Details**: 이 연구에서는 Tensor Network 방법을 활용하여 저 얽힘(Entanglement) 특성을 가진 상태를 압축하고, 훈련 과정에서 VQC 회로의 정확성을 높이기 위해 기계 학습(Machine Learning) 개념을 적용하였다. 많은 수의 큐비트(n-qubit) 시스템에서, 단일 VQC 회로가 Trotterization 회로에 비해 월등한 성능을 보이는 것을 입증하였다.

- **Performance Highlights**: VQC 회로는 이전 VQC 결과에 비해 단위 연산 불일치를 약 0.0009로 줄였으며, 이는 Tensor Network 구현을 통해 확인되었다. 또한, VQC는 1D 및 2D 시스템에서 고차원 양자 시스템의 동역학 시뮬레이션에 매우 정확한 결과를 보여주었다.



### Transformer based time series prediction of the maximum power point for solar photovoltaic cells (https://arxiv.org/abs/2409.16342)
Comments:
          Published June 2022, in Energy Science and Engineering, Volume10, Issue9, Pages 3397-3410

- **What's New**: 이 논문은 다양한 시계열 기반 환경 입력을 고려한 개선된 딥 러닝 기반 최대 전력점 추적(MPPT) 방법을 제안합니다. 기본 신경망 아키텍처를 사용하는 기존 MPPT 알고리즘과 달리, 이 논문에서는 포괄적인 환경 특성 집합을 통해 특정 위치의 환경 조건을 모델링합니다.

- **Technical Details**: 논문은 시계열 예측 모델로 훈련된 변환기(Transformer) 기반 딥 러닝 아키텍처를 사용합니다. 모델은 50개 위치에서 수집된 전형적인 기상 연도 데이터 포인트를 포함하는 데이터셋으로 훈련되며, 입력 특성에는 시간 기반 특성이 포함되어 있습니다. 변환기 모듈 내의 주의(attention) 메커니즘은 데이터의 시간적 패턴을 효율적으로 학습할 수 있게 돕습니다.

- **Performance Highlights**: 제안된 모델은 200시간 연속 데이터로 구성된 테스트 데이터셋에서 비영점 운영 전압에서 평균 0.47%의 예측 평균 퍼센트 오차를 달성하였습니다. 평균 전력 효율성은 99.54%이며 최대 전력 효율성은 99.98%에 달합니다. 모델은 실제 시간 시뮬레이션을 통해 검증되었습니다.



### Large-scale digital phenotyping: identifying depression and anxiety indicators in a general UK population with over 10,000 participants (https://arxiv.org/abs/2409.16339)
- **What's New**: 디지털 표현형 (digital phenotyping)의 새로운 접근 방식은 우울증과 불안 관리에서 비용 효율적이며 실질적인 통찰력을 제공합니다.

- **Technical Details**: 영국의 일반 인구에서 10,129명 참가자를 대상으로 한 단면 분석 연구에서, 참여자들은 Fitbit과 같은 착용 가능한 기기를 통해 데이터를 공유하고 우울증(PHQ-8), 불안(GAD-7) 및 기분에 대한 자가 보고 질문지를 작성했습니다. 첫째, PHQ-8/GAD-7 점수와 착용기기 기반 특성, 인구통계학적 정보, 건강 데이터를 분석했습니다. 그 후, 비지도 군집 분석 을 통해 우울증이나 불안과 관련된 행동 패턴을 식별했습니다. 마지막으로, XGBoost 모델을 사용하여 우울증과 불안을 예측하고 다양한 변수 집합의 결과를 비교했습니다.

- **Performance Highlights**: 우울증과 불안의 심각도는 기분, 연령, 성별, BMI, 수면 패턴, 신체 활동, 심박수와 같은 여러 요인과 유의미한 연관성을 보였습니다. 군집 분석 결과, 낮은 신체 활동 수준과 높은 심박수를 동시에 보이는 참가자는 더 심각한 증상을 보고하였습니다. 모든 변수가 포함된 예측 모델은 우울증에 대해 $R^2$=0.41, MAE=3.42, 불안에 대해 $R^2$=0.31, MAE=3.50의 성과를 보였습니다. 이 연구는 디지털 표현형과 머신러닝 기술을 통해 정신 질환의 신속한 선별을 위한 잠재적 지표를 규명했습니다.



### Refereeing the Referees: Evaluating Two-Sample Tests for Validating Generators in Precision Sciences (https://arxiv.org/abs/2409.16336)
Comments:
          v1: 42 pages, 5 figures, 7 tables, additional plots and tables available on GitHub and linked in the article

- **What's New**: 본 논문은 과학 응용 분야에서 비모수적 2표본 테스트(non-parametric two-sample tests)의 성능과 계산 효율성을 평가하는 강력한 방법론을 제안합니다. 특히, 입자 물리학과 같은 고차원 생성 모델에 최적화된 테스트를 다룹니다.

- **Technical Details**: 제안된 방법은 sliced Wasserstein distance, Kolmogorov-Smirnov 통계의 평균 및 새로운 sliced Kolmogorov-Smirnov 통계를 비롯한 측정 도구에 기반하고 있습니다. 각 테스트는 병렬로 평가될 수 있어, 귀무가설(null hypothesis) 하에서의 분포에 대한 빠르고 신뢰할 수 있는 추정이 가능합니다.

- **Performance Highlights**: 1차원 기반 테스트는 최근 제안된 다변량 메트릭(multi-variate metrics)과 유사한 감도를 제공하지만, 훨씬 낮은 계산 비용으로 고차원 환경에서의 생성 모델 평가에 특히 적합하다는 것을 보여줍니다.



### Predicting Distance matrix with large language models (https://arxiv.org/abs/2409.16333)
- **What's New**: RNA 구조 예측에 대한 새로운 접근 방법을 제안합니다. 대규모 사전 훈련된 RNA 언어 모델과 잘 훈련된 변환기(transformer)를 사용하여 RNA 염기 사이의 거리를 정확하게 추론할 수 있습니다.

- **Technical Details**: 거리 매트릭스(distance matrix)를 직접 예측하는 방법을 제시하며, 이 과정에서 기존의 3D 구조 모델링에서 발생하는 데이터 부족 문제를 해결하기 위한 혁신적인 접근 방식을 채택합니다. 우리는 변환기의 주의(attention) 메커니즘이 RNA 염기 쌍의 거리를 예측하는 데 적합하다고 주장합니다.

- **Performance Highlights**: 제안된 Distance Transformer(DiT)는 사전 훈련된 RNA 언어 모델을 통해 RNA 거리 매트릭스를 예측하고, 이를 통해 RNA 구조 및 기능에 대한 이해를 높일 수 있는 가능성을 보여줍니다.



### MRI Radiomics for IDH Genotype Prediction in Glioblastoma Diagnosis (https://arxiv.org/abs/2409.16329)
Comments:
          8 pages, 1 figure

- **What's New**: 이번 논문은 MRI 이미지를 활용한 Radiomics의 최신 동향을 다루고 있으며, 특히 Isocitrate dehydrogenase (IDH) 돌연변이 상태를 식별하는데 중점을 둡니다. IDH 돌연변이는 고등급 교모세포종과 등급 IV 별아교종의 중요 생체표지자로, 비침습적인 진단 방법의 필요성을 강조합니다.

- **Technical Details**: 논문에서 다루는 MRI Radiomics 워크플로우는 MRI 이미지에서 특징 추출을 위한 주요 단계를 설명합니다. 이미지 세분화는 수동, 반자동 또는 자동 방법으로 수행될 수 있으며, 자동 세분화는 딥러닝 모델을 사용하여 더 빠르고 정확하게 수행됩니다. 이미지 전처리 과정은 필수적으로 포함되며, 스컬 스트리핑과 다양한 필터링 기법이 사용됩니다.

- **Performance Highlights**: 이 연구는 IDH 돌연변이 상태를 정확히 예측하기 위한 MRI 기반 비침습적 방법의 효과를 입증하고 있으며, 이는 각환자에 맞춘 치료 계획 수립에 기여할 것입니다. 또한, 딥러닝 기반의 자동 세분화 기법은 임상 적용 가능성을 높이고 있습니다.



### GATher: Graph Attention Based Predictions of Gene-Disease Links (https://arxiv.org/abs/2409.16327)
- **What's New**: GATher는 440만 개 이상의 엣지를 포함한 생물의학 그래프를 통합하여 치료 유전자-질병 링크를 예측하도록 설계된 그래프 주의 네트워크입니다. 이 모델은 GATv3라는 혁신적인 그래프 주의 합성곱 레이어와, 각각의 엣지 유형에 대한 변환을 집계하는 GATv3HeteroConv를 포함하여 복잡한 상호작용을 관리하는 능력을 향상시킵니다.

- **Technical Details**: GATher는 하드 네거티브 샘플링과 다중 작업 사전 훈련을 활용하여 위상적 불균형을 해결하고 특이성을 개선하며, 2018년까지의 데이터를 훈련하여 임상 시험 결과를 예측합니다. 이 모델은 각 엣지 유형에 대해 GATv3 레이어와 GATv3HeteroConv를 사용하고, 각 엣지 유형의 중요성을 평가하는 주의 메커니즘을 통해 해석 가능성을 높입니다.

- **Performance Highlights**: GATher는 2024년 임상 시험 목표 상위 200개를 우선 순위로 지정하는 데 14.1%의 정밀도를 달성했으며, 이는 다른 방법보다 3.5% 개선된 결과입니다. GATher는 unmet efficacy 실패에 대해 0.69, 긍정적인 효능에 대해 0.79의 ROC AUC를 달성하여 HGT, GAT, GATv2 및 R2E 모델을 능가합니다.



### Towards Within-Class Variation in Alzheimer's Disease Detection from Spontaneous Speech (https://arxiv.org/abs/2409.16322)
- **What's New**: 이 논문은 알츠하이머병(Alzheimer's Disease, AD) 탐지 분야에서 머신러닝(classification model)을 활용하여 AD 환자와 비환자를 구별하려는 연구의 일환이다. 기존의 이진 분류(binary classification) 접근법의 한계점을 지적하며, 내적 변동성(within-class variation) 및 샘플 불균형(instance-level imbalance) 문제를 해결하기 위한 두 가지 새로운 방법, Soft Target Distillation(SoTD)와 Instance-level Re-balancing(InRe)을 제안한다.

- **Technical Details**: AD 탐지의 중요한 문제는 샘플 간 인지 기능의 정도가 다르다는 것이다. SoTD는 샘플의 세부 정보를 인식하여 신뢰도(Awareness of sample degree)를 바탕으로 단계적인 학습을 제공하고, InRe는 데이터 로스(loss)를 재조정하여 오버피팅(over-fitting)을 완화하는 방법이다. 실험은 ADReSS와 ADReSSo 데이터셋에서 BERT 및 RoBERTa 임베딩(features)을 사용하여 수행되었다.

- **Performance Highlights**: 실험 결과, SoTD와 InRe 방법을 도입함으로써 AD 탐지 정확도가 크게 향상되었으며, SoTD는 특히 모델 앙상블(ensemble estimation) 기법에 비해 더 높은 효율성을 보였다. 또한, InRe는 모델의 오버피팅을 현저히 줄이며, 훈련 안정성을 높였다.



### WeatherFormer: Empowering Global Numerical Weather Forecasting with Space-Time Transformer (https://arxiv.org/abs/2409.16321)
- **What's New**: WeatherFormer라는 새로운 transformer 기반의 수치 기상 예측(NWP) 프레임워크를 제안하여 데이터 기반 NWP의 성능 격차를 줄이는데 기여하고 있습니다.

- **Technical Details**: WeatherFormer는 공간-시간 요인 분해 transformer 블록을 사용하여 파라미터 및 메모리 소비를 줄이고, 위치 인식 적응형 푸리에 신경 연산자(PAFNO)를 도입하여 위치에 민감한 토큰 혼합을 수행합니다. 또한 두 가지 데이터 증강 전략을 통해 성능을 향상시키고 훈련 소비를 저감합니다.

- **Performance Highlights**: WeatherBench 데이터셋에서의 광범위한 실험 결과, WeatherFormer는 기존 깊은 학습 방법들보다 뛰어난 성능을 발휘하였으며, 최신 물리 모델과 더욱 근접한 성능을 서술하고 있습니다.



### Developing a Thailand solar irradiance map using Himawari-8 satellite imageries and deep learning models (https://arxiv.org/abs/2409.16320)
Comments:
          23 pages, 14 figures

- **What's New**: 이 논문은 태국의 태양 복사 지도(Global Horizontal Irradiance, GHI)를 30분마다 온라인으로 보여주는 플랫폼을 소개합니다. 이 플랫폼은 Himawari-8 위성 이미지를 기반으로 한 구름 지수(cloud index)와, Linke turbidity로 조정된 Ineichen 맑은 하늘 모델을 사용하여 GHI를 추정합니다.

- **Technical Details**: GHI 추정 모델에서 입력으로는 맑은 하늘 복사량, 구름 지수, MERRA-2 데이터베이스의 재분석 GHI 및 온도 데이터를 포함합니다. 사용된 머신 러닝 모델로는 LightGBM, LSTM, Informer, Transformer가 있으며, 2022-2023년 기간 동안 53개 지상 스테이션에서 15분 단위의 GHI 데이터를 평가하여 성능을 비교했습니다.

- **Performance Highlights**: 모든 모델은 경쟁력 있는 성능을 보였으며, SolCast 서비스보다 우수한 결과를 나타냈습니다. LightGBM 모델의 MAE(Mean Absolute Error)는 78.58 W/sqm, RMSE(Root Mean Square Error)는 118.97 W/sqm로 최상위 성능을 기록했습니다. Informer 모델은 추가적으로 재분석 MERRA-2 데이터 없이 MAE 78.67 W/sqm로 우수한 성능을 보였습니다.



### A Literature Review of Keyword Spotting Technologies for Urdu (https://arxiv.org/abs/2409.16317)
- **What's New**: 이 문헌 리뷰는 파키스탄의 저자원 언어(Low-Resource Language)인 우르두어의 키워드 스포팅(Keyword Spotting, KWS) 기술 발전을 조사합니다. 저자원 언어가 직면한 독특한 도전과제와 이를 해결하기 위한 맞춤형 솔루션의 필요성을 강조합니다.

- **Technical Details**: 이 리뷰는 가우시안 혼합 모델(Gaussian Mixture Models, GMMs)에서 심층 신경망(Deep Neural Networks, DNNs) 및 변환기(transformer)와 같은 복잡한 신경 아키텍처의 진화를 추적합니다. 특히 다중 작업 학습(multi-task learning)과 자가 감독 학습(self-supervised learning) 접근법을 통합하여 라벨 없는 데이터(unlabeled data)를 활용하는 방법을 강조합니다. 새로운 EdgeCRNN 모델과 통합된 CNN과 RNN을 포함하여, 키워드 탐지를 위한 최신 모델들과 그 효율성을 논의합니다.

- **Performance Highlights**: 최신 연구에서, 자가 감독 학습(S3RL) 및 경량 변환기 모델들이 우르두어와 같은 저자원 언어에서 KWS 효율성과 정확성을 향상시키는데 긍정적인 영향을 미쳤습니다. Massively Multilingual Speech(MMS) 프로젝트는 1000개 이상의 언어에서 모델을 사전 학습하여 현대적인 음성 기술을 다수의 언어로 확대했으나, 여전히 우르두어는 데이터 부족 문제로 인해 성능 향상에 제한이 있습니다.



### Surface solar radiation: AI satellite retrieval can outperform Heliosat and generalizes well to other climate zones (https://arxiv.org/abs/2409.16316)
Comments:
          19 pages, 11 figures

- **What's New**: 본 논문은 유럽 전역에서 즉각적인 표면 태양 복사량(Surface Solar Irradiance, SSI)을 정확히 추정할 수 있는 최초의 머신러닝 기반 위성 검색 모델을 소개합니다. 이는 데이터 기반의 Heliosat 알고리즘 에뮬레이션 및 기상 관측소에서의 미세 조정을 통해 가능합니다.

- **Technical Details**: SSI 검색 모델은 복사 전달 모델(radiative transfer model)을 에뮬레이션하고, 기상 관측소의 SSI 데이터를 이용하여 훈련을 진행합니다. 또한, 이 모델은 구름 상태에 따라 Meteosat 채널과 태양 천정 각(solar zenith angle)과 같은 예측 변수의 상대적 중요성을 정량화하여 성능을 향상시킵니다.

- **Performance Highlights**: 이 연구에서는 Heliosat 모델에 비해 높은 정확도를 보여주며, 특히 다양한 기후 조건 및 표면 알베도(surface albedo)를 가진 지역에서도 뛰어난 일반화 성능을 발휘합니다. 특히 구름 조건에서는 여러 근적외선 채널이 성능을 향상시키는 것으로 나타났습니다.



### SEA-ViT: Sea Surface Currents Forecasting Using Vision Transformer and GRU-Based Spatio-Temporal Covariance Modeling (https://arxiv.org/abs/2409.16313)
Comments:
          16 pages

- **What's New**: SEA-ViT는 Vision Transformer (ViT)와 양방향 Gated Recurrent Units (GRUs)를 결합한 고급 딥러닝 모델이다. 이 모델은 고주파 레이더 (HF) 데이터를 사용하여 해양 표면 해류(U, V)를 예측하는 데 필요한 시공간 공분산을 포착할 수 있도록 설계되었다.

- **Technical Details**: SEA-ViT는 30년 이상의 방대한 데이터셋을 활용하고 ENSO 지수를 통합하여 해양 해류의 복잡한 의존 관계를 해결한다. 데이터 전처리를 통해 U와 V 벡터를 정규화하고, 기후적 변화와 관련된 ENSO 지수를 추가하여 모델의 예측 능력을 강화하였다. Bidirectional GRUs와 ViT를 결합하여 시간적 의존성을 포착하고 공간적 상호작용을 촉진한다.

- **Performance Highlights**: SEA-ViT는 태국의 해양 지역에서 해양 작전과 환경 관리를 위한 정밀한 예측을 가능하게 하며, 전통적인 모델의 한계를 극복하여 해류 예측의 정확성을 대폭 향상시킨다.



### Damage detection in an uncertain nonlinear beam based on stochastic Volterra series: an experimental application (https://arxiv.org/abs/2409.16305)
- **What's New**: 이 논문은 구조물의 비선형 행동과 데이터의 자연 변동을 고려하여, 손상 탐지 문제 해결을 위한 확률적(Probabilistic) Volterra 시리즈의 실험적 적용을 다룹니다. 비선형 시스템에서 손상을 탐지하기 위해 기존의 결정론적(Deterministic) 방법과 확률적 방법의 비교를 수행합니다.

- **Technical Details**: 이 연구에서는 비선형 운동을 하는 고정 단작업 빔(Cantilever beam)을 실험적으로 사용하였으며, 실험적 데이터의 변동성을 보완하기 위해 확률적 Volterra 커널(Volterra kernel)의 기여도를 이용한 접근법이 적용되었습니다. 처치(causation)된 손상은 볼트 연결(bolted connection)에서의 질량 변화(mass changes)에 따른 것이며, 비선형 기여도와 선형 기여도를 비교하여 분석합니다.

- **Performance Highlights**: 확률적 모델이 데이터 변동성을 고려할 때 손상의 존재를 통계적 신뢰도로 탐지할 수 있는 능력을 보여주며, 비선형 메트릭이 선형 메트릭보다 손상 감지에 더 높은 민감도를 가지는 장점이 입증되었습니다. 이는 비선형 행동을 가진 시스템에서 비선형 메트릭을 사용하는 것이 중요하다는 것을 강조합니다.



### How Redundant Is the Transformer Stack in Speech Representation Models? (https://arxiv.org/abs/2409.16302)
- **What's New**: 이 논문에서는 transformer 기반의 음성 표현 모델에서 계층 간의 중복성을 조사하고, 이러한 중복성을 활용하여 계층을 가지 치거나 대체할 수 있는 가능성을 탐구합니다.

- **Technical Details**: 층 유사성을 분석하기 위해 세 가지 유사도 메트릭(cosine similarity, centered kernel alignment, mutual nearest-neighbor alignment)을 사용하였으며, 고유한 블록 구조와 작업 단계를 발견했습니다. 또한, pruning을 통해 transformer 계층을 최대 40%까지 축소할 수 있음을 보여줍니다.

- **Performance Highlights**: 지식 증류(knowledge distillation) 방법을 이용하여 전체 transformer 스택을 최소화하고, 네트워크 크기를 95-98% 감소시키며, 추론 시간은 최대 94%까지 단축할 수 있음을 입증하였습니다.



### Gait Switching and Enhanced Stabilization of Walking Robots with Deep Learning-based Reachability: A Case Study on Two-link Walker (https://arxiv.org/abs/2409.16301)
Comments:
          The first two authors contributed equally. This work is supported in part by the NSF Grant CMMI-1944722, the NSF CAREER Program under award 2240163, the NASA ULI on Safe Aviation Autonomy, and the DARPA Assured Autonomy and Assured Neuro Symbolic Learning and Reasoning (ANSR) programs. The work of Jason J. Choi received the support of a fellowship from Kwanjeong Educational Foundation, Korea

- **What's New**: 이번 연구는 학습 기반 보행 제어기를 설계하여 안정성을 보장하는 방법에 대해 다룹니다. 하이브리드 동역학을 가진 다리 로봇의 안정적 보행 패턴에 대한 매력의 영역(region of attraction, RoA)을 검증하는 접근 방식을 사용하여, 이전 연구의 한계를 극복하고자 합니다.

- **Technical Details**: 이 논문에서는 심층 학습 기반의 해밀턴-자코비(Hamilton-Jacobi, HJ) 도달 가능성 분석을 통해 하이브리드 보행 로봇 동역학을 다룹니다. 학습된 HJ 해법을 사용하여 다양한 보행 패턴에 대한 RoA 라이브러리를 추정하고, 각기 다른 게이트를 안정화하는 일단계 예측 제어기를 설계합니다. 또한 RoA 분석을 통해 외부 영향을 받는 상황에서 게이트 전환 전략을 수립합니다.

- **Performance Highlights**: 제안된 방법은 두-link 워커 시뮬레이션에서 검증되었으며, 이전의 모델 기반 방법론과 비교하여 개선된 안정성을 달성하였습니다. 제어기는 RoA를 기반으로 게이트 전환이 가능하며, 강한 외란에 대해서도 안정적으로 작동하는 성능을 보여주었습니다.



### BetterBodies: Reinforcement Learning guided Diffusion for Antibody Sequence Design (https://arxiv.org/abs/2409.16298)
- **What's New**: 이번 연구에서는 BetterBodies라는 새로운 방법론을 제안하여 항체 CDRH3 서열을 설계하는 데 있어 개선된 바인딩 친화도(binding affinity)를 달성하는 사례를 보여주고 있습니다. 최근의 오프라인 강화 학습(offline RL) 기법을 융합하여 다수의 데이터 분포에서 다양한 서열을 생성할 수 있는 가능성을 시사합니다.

- **Technical Details**: BetterBodies는 Variational Autoencoders (VAEs)와 강화 학습(RL) 기반의 잠재 확산(latent diffusion) 모델을 결합하여 새로운 항체 CDRH3 서열을 생성합니다. 이 과정에서 Q-함수 기반 필터링 및 VAE의 잠재 공간에서 생리물리학적(biophysical) 특성을 반영하는 대조 손실(contrastive loss)을 사용하여 생성된 서열의 평균 바인딩 친화도를 향상시킵니다. 이 방법론은 실험적으로 SARS-CoV 스파이크 수용체 결합 영역에 대한 낮은 바인딩 친화도 서열의 설계를 효과적으로 개선할 수 있음을 입증합니다.

- **Performance Highlights**: BetterBodies는 Absolut! 시뮬레이터를 사용하여 개발된 서열이 SARS-CoV의 스파이크 수용체 결합 도메인에 대한 바인딩 친화도를 기존 서열에 비해 현저히 향상시키는 결과를 보여주었습니다. 이 연구는 비용 집약적인 기존의 실험 방법을 대체할 수 있는 잠재력을 지닌 계산 항체 설계(computational antibody design) 방법의 가능성을 제시합니다.



### Efficient Training of Self-Supervised Speech Foundation Models on a Compute Budg (https://arxiv.org/abs/2409.16295)
Comments:
          To appear in SLT 2024

- **What's New**: 이 연구는 제한된 계산 예산 하에서 음성 기반 모델 학습의 효율성을 높이기 위한 다양한 요소들을 분석하고 익히려는 시도를 포함하고 있으며, 기존의 방법론들이 잘 알려진 자원 효율성과 성능 간의 균형을 찾기 위한 실험을 진행했습니다.

- **Technical Details**: 논문에서는 self-supervised learning (SSL) 목표를 평가하고, 모델 아키텍처, 모델 크기, 데이터 크기가 SSL 성과에 미치는 영향을 체계적으로 조사합니다. 연구에 따르면 슬리머 모델 아키텍처가 일반적인 작은 모델 아키텍처보다 더 뛰어난 성과를 보이며, 사전 훈련 데이터의 크기도 성능에 큰 영향을 미친다고 밝혔습니다. 또한, 특정 계산 예산 내에서 최적의 모델 크기를 찾는 방법을 제안합니다.

- **Performance Highlights**: 이 연구의 주요 결과는 다음과 같습니다: 1) SSL 목표는 성과에 영향을 줄 수 있지만, 다른 주요 요소에 비해 그 영향이 덜하다. 2) 동일한 계산 및 파라미터 예산 하에서 슬리머 SSL 모델이 일반적으로 사용되는 3-레이어 작은 SSL 모델을 초월한다. 3) 충분히 큰 사전 훈련 데이터의 중요성이 강조되며, 데이터 사이즈와 이터레이션 간의 균형이 필요하다.



### GenCAD: Image-Conditioned Computer-Aided Design Generation with Transformer-Based Contrastive Representation and Diffusion Priors (https://arxiv.org/abs/2409.16294)
Comments:
          24 pages, 13 figures

- **What's New**: 이번 논문에서는 GenCAD라는 새로운 생성 모델을 소개합니다. 이 모델은 CAD 명령어 시퀀스로 변환하여 편집 가능한 3D 형태를 생성하며, 이미지 입력을 통해 CAD 프로그램을 생성합니다.

- **Technical Details**: GenCAD는 autoregressive transformer와 latent diffusion 모델을 통합하여 이미지에서 CAD 명령 시퀀스를 생성합니다. 이를 위해 contrastive learning 프레임워크를 활용하여 CAD 이미지와 CAD 명령 시퀀스의 공동 분포를 학습합니다.

- **Performance Highlights**: GenCAD는 기존의 최신 방법들보다 3D 형상 생성의 정밀도와 수정 가능성 면에서 월등한 성능을 보였습니다. 특히, 긴 시퀀스의 3D 형상 생성 정확도가 크게 향상되어 복잡한 설계 작업에 적합합니다.



### Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinemen (https://arxiv.org/abs/2406.11176)
Comments:
          Accepted to EMNLP 2024 (Main Conference)

- **What's New**: 이 논문에서는 Iterative step-level Process Refinement (IPR) 프레임워크를 소개합니다. 이 방법은 전문가 경로(expert trajectory)를 활용하여 에이전트의 학습을 개선하는데 중점을 두고 있습니다.

- **Technical Details**: IPR 프레임워크는 몬테 카를로 방법(Monte Carlo method)을 사용하여 단계별 보상(step-level rewards)을 추정합니다. 각 반복(iteration) 동안 에이전트는 전문가 경로를 따라 탐색하고 새로운 행동(actions)을 생성합니다. 생성된 행동들은 해당 전문가 경로의 단계와 비교하여 보상을 평가합니다.

- **Performance Highlights**: 세 가지 복잡한 에이전트 작업에서 실시한 실험 결과, IPR 프레임워크는 여러 강력한 기준선(baselines)을 초월하는 성능을 보여주었으며, 행동 효율성을 높인다는 점에서 IPR의 효과가 입증되었습니다.



### Learning To Help: Training Models to Assist Legacy Devices (https://arxiv.org/abs/2409.16253)
Comments:
          12 pages, 4 figures

- **What's New**: 이 논문에서는 기계 학습 모델이 제한된 하드웨어에서 동작하는 모바일 엣지 클라우드(MEC) 시스템에서의 새로운 문제를 다룹니다. 특히, 이전에는 엣지 서버가 완벽한 전문가 혹은 오라클로 가정하고 클라이언트를 교육하는 데 집중했으나, 이 연구에서는 반대로 고정된 클라이언트를 위한 엣지를 교육하는 문제를 나타냅니다.

- **Technical Details**: 연구는 Learning with Abstention (LWA)이라는 프레임워크를 기반으로 합니다. 클라이언트는 특정 상황에서 예측을 거부하고 엣지 서버에게 작업을 오프로드 할 수 있는 결정 규칙을 가지고 있습니다. 이 경우, Bayes-optimal rule과 일반화 한계를 발견하고, 일관된 여유 손실 함수(surrogate loss function)를 도출했습니다. 또한, 이 연구는 이론적 절차와 함께 일반적인 딥러닝 아키텍처 및 손실 함수 모델링을 제공합니다.

- **Performance Highlights**: 실험 결과, 제안된 프레임워크는 기존의 신뢰 기반 거부 규칙(confidence-based rejection rules)보다 우수한 성능을 보였습니다. 이 결과는 제안된 여유 손실 함수로 학습된 모델이 더 능동적인 훈련 과정을 제공함을 보여줍니다.



### Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling (https://arxiv.org/abs/2409.16231)
Comments:
          Accepted to ICANN 2024

- **What's New**: 본 논문은 ADNI 코호트에서 경증 인지장애(MCI) 환자의 인지 저하를 예측하기 위해 생체대사학 데이터와 생존 트랜스포머(survival transformer) 및 극단 그래디언트 부스팅(Extreme Gradient Boosting) 모델을 결합한 새로운 접근 방식을 제안합니다.

- **Technical Details**: 이 연구는 기계학습(machine learning) 및 트랜스포머 기반 기술을 활용하여 생존 분석(survival analysis)에서의 조기 탐지 및 개입의 정확도를 개선하는 가능성을 강조하고 있으며, 100회의 몬테 카를로 시뮬레이션을 통해 생존 기계 학습 모델이 기존의 Cox 비례 위험 모델보다 더 높은 평균 C-인덱스(performance C-index)를 달성했음을 보여줍니다.

- **Performance Highlights**: 제안된 생존 기계 학습 모델은 C-인덱스에서 각각 0.85 및 0.8의 평균 성과를 기록하며, 기존 모델보다 더 안정적이고 정확한 결과를 제공합니다.



### Fine-Tuning is Fine, if Calibrated (https://arxiv.org/abs/2409.16223)
Comments:
          The first three authors contribute equally

- **What's New**: 본 연구에서는 사전 학습된 모델(Foundation Model)에서 세부 클래스를 대상으로 한 파인튜닝(fine-tuning) 중 발생하는 문제를 체계적으로 분석합니다. 연구 결과, 파인튜닝된 모델이 정확도가 하락하는 주된 원인이 로짓 스케일의 불일치임을 밝혀내고, 이러한 문제를 해결하기 위해 단순한 후처리(calibration) 방법을 제안합니다.

- **Technical Details**: 사전 학습된 분류기를 세부 클래스에 맞춰 파인튜닝하면 일반적인 정확도가 손상되지만, 이 논문에서는 파인튜닝 후에도 특징 추출기(feature extractor)의 성능 수치가 개선됨을 확인하였습니다. NCM(Nearest Class Mean) 분류기를 통해 특징 품질을 평가한 결과, 파인튜닝 동안 실종된 클래스에 대한 특징 분리가 향상되었습니다. 로짓 스케일의 불일치가 피해를 주며, 이 문제는 후처리 방법으로 보완할 수 있습니다.

- **Performance Highlights**: 다수의 벤치마크(예: ImageNet)에서 후처리 보정(calibration)을 통해 파인튜닝된 모델의 성능이 현저히 향상되었으며, 이는 강력한 기준선 모델조차 능가했습니다. 연구 결과는 간단한 파라미터 조정만으로도 유의미한 성과를 달성할 수 있음을 보여줍니다.



### Problem-oriented AutoML in Clustering (https://arxiv.org/abs/2409.16218)
- **What's New**: 문제 지향적 오토ML(Problem-oriented AutoML, PoAC) 프레임워크는 전통적인 오토ML 솔루션의 단점을 해결하며 클러스터링 작업을 자동화하는 새로운 유연한 접근법을 소개합니다. PoAC는 클러스터링 문제, 내부 클러스터링 유효성 지수(Clustering Validity Indexes, CVIs) 및 메타 피처(meta-features) 간의 동적인 연결을 수립하여 사용자가 이러한 구성 요소를 특정 맥락 및 목표에 맞게 맞춤 설정할 수 있도록 합니다.

- **Technical Details**: PoAC의 핵심은 방대한 메타 지식 기반(meta-knowledge base)의 클러스터링 데이터셋과 솔루션으로 훈련된 대체 모델(surrogate model)을 사용하여 새로운 클러스터링 파이프라인의 질을 추론하는 것입니다. PoAC는 알고리즘에 구애받지 않으며, 추가 데이터나 재훈련 없이 다양한 클러스터링 문제에 원활히 적응할 수 있습니다.

- **Performance Highlights**: 실험 결과, PoAC는 다양한 데이터셋에서 최신 기술의 프레임워크보다 우수한 성능을 달성했으며, 데이터 시각화와 관련된 CVIs에서도 더 나은 결과를 보였습니다. 또한, PoAC는 데이터셋의 복잡성과 정의된 문제에 따라 전처리 단계를 추가하거나 제거하여 파이프라인 구성을 동적으로 조정하는 능력을 보여주었습니다.



### Second Order Bounds for Contextual Bandits with Function Approximation (https://arxiv.org/abs/2409.16197)
Comments:
          12 pages main, 33 pages total

- **What's New**: 본 연구는 Contextual Bandits (맥락 기반 밴딧) 문제에서 함수 근사(Function Approximation)를 사용할 때, 기존의 알고리즘보다 더 나은 후회의 한계를 제공하는 새로운 알고리즘을 개발했습니다. 특히, 이 알고리즘은 후회(Regret)가 시간 지평(Time Horizon)의 제곱근이 아닌, 측정 오차의 분산(Variance)의 합의 제곱근으로 감소하도록 개선되었습니다.

- **Technical Details**: 연구팀은 각 시간에 따른 보상의 측정 노이즈의 분산이 변화하고 매우 작더라도, Optimistic Least Squares 알고리즘의 후회가 시간 지평의 제곱근에 비례하여 증가하는 문제를 해결했습니다. 이들은 측정 분산이 알려지지 않았을 때의 Contextual Bandits 설정에서 후회 한계를 도출하는 알고리즘을 제안하였습니다.

- **Performance Highlights**: 제안된 알고리즘은 기존의 OFUL(Optimistic Least Squares)과 SquareCB 알고리즘보다 후회 한계가 더욱 개선된 결과를 보여주며, 통계적 복잡성 측정에 기반한 새로운 알고리즘 설계로 Contextual Bandits 문제의 실제 적용 가능성을 높였습니다.



### Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to Extremes Through Rank-Wise Clustering (https://arxiv.org/abs/2409.16167)
- **What's New**: 본 논문은 LoRA(저랭크 적응)을 조합하여 대형 언어 모델(LLM)의 성능을 극대화하는 새로운 접근 방식을 소개합니다. 기존의 LoRA 합성 방법이 주어진 특정 작업에 최적화되어 추가 훈련을 필요로 하는 반면, 본 연구에서는 LoRA 구성 요소를 독립적인 최소 의미 단위(MSU)로 분해 및 재조립하는 방식을 제안합니다.

- **Technical Details**: 제안된 LoRA-LEGO 프레임워크는 여러 LoRA에서 MSU를 클러스터링하여 새로운 LoRA를 구성하는 과정을 포함합니다. 이 과정은 세 가지 주요 단계로 나누어집니다: (1) 후보 LoRA로부터 MSU 풀(pool)을 만들기, (2) 이 MSU 풀을 k 클러스터로 그룹화하기, (3) 클러스터의 중심을 활용해 병합된 LoRA 구성하기. 이를 통해 파라미터 간섭을 해결하면서 다양한 랭크의 LoRA를 유연하게 조합할 수 있습니다.

- **Performance Highlights**: LoRA-LEGO는 다양한 벤치마크에서 기존의 LoRA 병합 방법보다 우수한 성능을 보였습니다. 실험 결과, LoRA-LEGO는 목표 랭크 k에 맞춘 병합 LoRA를 구성할 수 있을 뿐만 아니라, 개별 LoRA에 적용 시에도 파라미터 감소를 통해 원래 모델과 유사한 성능을 달성할 수 있음을 보여주었습니다.



### TabEBM: A Tabular Data Augmentation Method with Distinct Class-Specific Energy-Based Models (https://arxiv.org/abs/2409.16118)
Comments:
          48 pages, 15 figures, 30 tables

- **What's New**: 이번 논문에서는 TabEBM이라는 새로운 클래스 조건부 생성 방법을 제안합니다. 기존의 생성적 방법들이 소규모 데이터셋에서 과적합(overfitting) 문제를 겪는 데 반해, TabEBM은 각 클래스에 대해 별도의 Energy-Based Model (EBM)을 사용하여 클래스 특유의 데이터 분포를 모델링합니다.

- **Technical Details**: TabEBM은 Energy-Based Models (EBMs)를 이용해 각 클래스에 대해 고유한 데이터 분포를 모델링합니다. 이는 모호한 클래스 분포에서도 견고한 에너지 경관(energy landscapes)을 생성하여, 데이터의 품질을 향상시킵니다. TabEBM은 PyTorch를 이용해 구현되었으며, 데이터 증강(data augmentation) 시 독립적으로 높은 통계적 신뢰성(statistical fidelity)을 발휘합니다.

- **Performance Highlights**: TabEBM으로 생성된 합성 데이터는 기존 방법들보다 더 높은 품질을 가지며, 다양한 크기의 데이터셋에 대해 분류 성능(classification performance)이 일관되게 개선되었습니다. 특히 소규모 데이터셋에서 최고의 성능을 발휘합니다.



### Self-attention as an attractor network: transient memories without backpropagation (https://arxiv.org/abs/2409.16112)
- **What's New**: 이 논문에서는 self-attention 레이어를 local energy term의 도함수로 표현할 수 있음을 보여줍니다. 이를 통해 self-attention의 새로운 해석을 제시하고 물리학에서 영감을 얻은 이론적 접근을 위한 기틀을 마련합니다.

- **Technical Details**: 저자들은 self-attention을 attractor network로 해석하고, 각 토큰을 d차원의 벡터 스핀으로 고려하여 예측 작업을 물리 시스템의 관점에서 설명합니다. 이 과정에서 토큰의 에너지를 정의하고, 자기 토큰 업데이트가 local energy function의 도함수로 표현될 수 있음을 보여줍니다. 이 모델은 backpropagation을 사용하지 않고 negative pseudo-likelihood loss를 최소화하여 훈련됩니다.

- **Performance Highlights**: 이 모델은 masked token prediction과 denoising 작업에서 테스트되었으며, 전체 transformer 블록과 표준 vision transformer와 비교되었습니다. 이 연구는 self-attention 메커니즘이 transient states를 생성하며, 학습 및 테스트 예제와 강한 상관관계를 가짐을 보여줍니다.



### The Digital Transformation in Health: How AI Can Improve the Performance of Health Systems (https://arxiv.org/abs/2409.16098)
Comments:
          This article has been accepted for publication in Health Systems & Reform, published by Taylor & Francis

- **What's New**: 이 논문에서는 인공지능(Artificial Intelligence, AI)과 강화학습(Reinforcement Learning, RL)을 활용한 새로운 디지털 건강 플랫폼을 소개하며, 해당 플랫폼이 수집한 데이터를 기반으로 개인화된 추천과 개입을 제공하고, 건강 시스템을 효율적으로 개선할 수 있는 방법을 제시합니다.

- **Technical Details**: 이 플랫폼은 다양한 디지털 건강 애플리케이션과 연결 가능하며, 실시간 모니터링 및 실험을 통해 사용자 맞춤형 반응을 제공하는 능력을 갖추고 있습니다. AI는 데이터를 기반으로 한 예측 분석을 통해 질병의 발병 예측 및 자원 배분을 최적화할 수 있습니다. 이는 다수의 데이터 소스와 디지털 도구를 통합하여 복합적인 건강 상태를 평가 및 관리할 수 있게 해줍니다.

- **Performance Highlights**: 자원 부족이 우려되는 저소득 국가(Low- and Middle-Income Countries, LMICs)에서 이 접근 방식이 건강 결과에 미치는 영향이 더욱 결정적일 수 있으며, 이는 고소득 국가(High-Income Countries, HICs)에서도 유사하게 효과를 볼 수 있습니다. 이 플랫폼은 건강 관리의 효율성을 높이고 궁극적으로 공공 건강 결과를 개선하는 데 기여할 것으로 기대됩니다.



### Assessing Simplification Levels in Neural Networks: The Impact of Hyperparameter Configurations on Complexity and Sensitivity (https://arxiv.org/abs/2409.16086)
- **What's New**: 이 연구는 신경망의 다양한 하이퍼파라미터 구성에서의 단순화 특성을 이해하기 위한 실험적 연구이다. 특히 Lempel-Ziv 복잡성과 민감도에 미치는 영향을 조사하였다.

- **Technical Details**: 하이퍼파라미터로는 활성화 함수, 은닉층 수, 학습률을 조정했으며, MNIST 데이터셋을 활용하여 네트워크 출력의 복잡성과 입력 섭동에 대한 민감도를 평가하였다.

- **Performance Highlights**: 실험 결과, ReLU와 LeakyReLU 활성화 함수를 사용하는 네트워크는 높은 민감도를 보여주었고, Sigmoid와 Tanh를 사용하는 네트워크는 낮은 민감도를 보였다. 또한, 높은 학습률이 모델의 학습을 실패하게 하고 Lempel-Ziv 복잡도가 낮아지는 결과를 초래하는 것으로 나타났다.



### Learning with Confidence: Training Better Classifiers from Soft Labels (https://arxiv.org/abs/2409.16071)
- **What's New**: 이번 연구에서는 soft labels (소프트 레이블)을 사용한 학습법(SLL: Soft Label Learning)이 기존의 hard labels (하드 레이블) 기반 학습법보다 분류 모델의 예측 성능을 향상시킬 수 있는지를 탐구합니다. 이는 레이블의 불확실성을 고려한 접근 방식이며, 특히 의료 데이터와 같은 복잡한 환경에서의 유용성을 입증합니다.

- **Technical Details**: 논문에서는 soft labels를 통한 학습법의 기초를 설명하면서, 다양한 wrapper 방법을 활용하여 hard labels와 soft labels의 성능을 비교하는 실험을 수행하였습니다. 본 연구에서는 특히 label noise (레이블 노이즈)가 모델 성능에 미치는 영향에 대해 분석하고, miscalibration (오교정)에 대해 연구하였습니다. 이 과정에서 다양한 noise 모델과 soft label에 특화된 4가지 오교정 모델을 포함하였습니다.

- **Performance Highlights**: 실험 결과, soft label 학습 방식은 복잡하고 제한된 데이터 세트에서도 hard label 방법을 능가하는 성능을 보여주었습니다. 실제 데이터 세트에서도 이 방법이 기존의 하드 레이블 방식과 대등한 성능을 유지하면서 더 정확한 신뢰도 추정치를 제공하였음을 밝혔습니다.



### Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts (https://arxiv.org/abs/2409.16040)
Comments:
          29 pages, 10 figures, 13 tables

- **What's New**: 이 논문에서는 Time-MoE라는 새로운 아키텍처를 소개하여, 더 크고 강력한 시계열 예측 모델을 사전에 훈련할 수 있게 하며, 추론 비용을 줄이고자 합니다.

- **Technical Details**: Time-MoE는 희소 혼합 전문가(mixture-of-experts, MoE) 디자인을 이용해 예측마다 모델의 서브셋만 활성화하여 계산 효율성을 높입니다. 이 모델은 오토 회귀(auto-regressive) 방식으로 작동하며, 문맥 길이가 다양하고 예측 지평선(forecasting horizons)을 지원하는 디코더 전용(transformer) 모델로 구성되어 있습니다. 또한, Time-300B는 9개의 도메인에 걸쳐 3000억 개 이상의 시간 포인트를 포함한 대규모 데이터입니다.

- **Performance Highlights**: Time-MoE는 24억 개의 파라미터로 스케일링되어 기존 모델들에 비해 평균 23% 및 25%씩 예측 오류를 줄이는 성과를 보였습니다. 기존 밀집 모델(dense models)과 비교하여 예측 정확도가 상당히 향상되었습니다.



### Exploring the Impact of Outlier Variability on Anomaly Detection Evaluation Metrics (https://arxiv.org/abs/2409.15986)
Comments:
          8 Pages, 5 figures

- **What's New**: 이 연구는 다양한 이상 탐지 조건 하에서 F1 점수, ROC AUC (Receiver Operating Characteristic Area Under Curve) 및 AUCPR (Precision-Recall Curve Area Under Curve) 세 가지 이탈 탐지 지표의 성능을 비교하고 분석합니다. 연구에서 통상적으로 받아들여지는 이러한 지표의 신뢰성 및 독립적인 통찰력을 검토합니다.

- **Technical Details**: 연구는 K-Nearest Neighbors (KNN), Local Outlier Factor (LOF), One-Class Support Vector Machine (OCSVM), Isolation Forest (IForest) 알고리즘을 활용하여 이루어졌습니다. 데이터 세트에서 이상치를 포함한 비율과 오염 임계값에 따른 결과를 분석하고, 특정 조건에서 ROC AUC와 AUCPR 사이의 정렬을 관찰했습니다.

- **Performance Highlights**: F1 점수와 AUCPR은 이상치 비율에 민감하지만, ROC AUC는 일관성을 유지하며 이러한 변동에 영향을 받지 않는 것으로 나타났습니다. 고정된 이상치 비율 조건에서는 ROC AUC와 AUCPR 사이의 정렬이 확인되어, 이러한 지표를 비교하는 것이 덜 중요할 수 있음을 시사합니다.



### Edge-device Collaborative Computing for Multi-view Classification (https://arxiv.org/abs/2409.15973)
- **What's New**: 이 논문은 딥러닝 계산을 클라우드 대신 네트워크의 엣지로 이전하여 응답 속도를 높이고 대역폭 소비를 줄이며 개인 정보 보호 문제를 해결하는 방안을 제안합니다. 특히, 협업 추론(collaborative inference)을 통해 데이터를 공유하고 컴퓨팅 부담을 분산하는 다양한 방법을 탐구합니다.

- **Technical Details**: 본 연구는 다중 뷰 분류(multi-view classification) 태스크에 중점을 두고, 엣지 서버와 최종 장치 간의 협업 방식을 조사합니다. 기존의 중앙 집중식(centralized) 또는 분산(distributed) 방식 외에도, 데이터 중복을 줄여 대역폭 소비를 감소시키는 선택적(selective) 방식도 제안합니다. 각 엣지 노드는 그들의 데이터를 기초로 하여 추론 작업에 기여할지를 결정합니다.

- **Performance Highlights**: 실험 결과, 제안된 선택적 협업 방식이 통신 절약을 18%에서 74%까지 달성할 수 있고, 여전히 90% 이상의 정확도를 유지할 수 있음을 보여줍니다. 심지어, 시각적 뷰를 일부 생략하더라도 평균 정확도는 71.92%에서 83.75%의 범위를 유지하며, 중앙 집중식 추론에 비해 대역폭 소비를 몇 배 감소시킬 수 있음을 강조합니다.



### Provably Efficient Exploration in Inverse Constrained Reinforcement Learning (https://arxiv.org/abs/2409.15963)
- **What's New**: 이번 논문에서는 Inverse Constrained Reinforcement Learning (ICRL)을 통해 복잡한 환경에서 최적 제약 조건을 도출하기 위한 새로운 전략적 탐색 프레임워크를 제안합니다. 기존의 ICRL 알고리즘은 상호작용 환경에서 학습 샘플을 수집하지만, 이러한 샘플링 전략의 효율성과 효과성은 불분명했습니다.

- **Technical Details**: 제안된 프레임워크에서는 ICRL 문제를 위한 실현 가능 제약 조건 집합을 정의하고, 전문가 정책(expert policy)과 환경 역학(environmental dynamics)이 제약 조건의 최적성에 어떻게 영향을 미치는지 조사합니다. 두 가지 탐색 알고리즘을 제안하여 1) 비용 추정의 한정된 집합 오류(bounded aggregate error)를 동적으로 줄이고, 2) 탐색 정책(exploration policy)을 전략적으로 제약합니다.

- **Performance Highlights**: 제안된 알고리즘의 성능은 다양한 환경에서 실증적으로 검증되었으며, 이론적으로 타당한 샘플 복잡도가 기반이 됩니다.



### Historical Trajectory Assisted Zeroth-Order Federated Optimization (https://arxiv.org/abs/2409.15955)
Comments:
          28 pages with theoretical proof

- **What's New**: 이번 연구에서는 Federated Learning에서 기울기 정보가 없는 상황에서도 기울기 추정을 개선하기 위해 비등방성 샘플링(non-isotropic sampling) 방법을 제안합니다. 이는 과거의 솔루션 궤적을 기반으로 하는 방법으로 유망한 영역을 탐색하는 것을 장려합니다.

- **Technical Details**: 제안된 방법은 비등방성 가우시안 분포(non-isotropic Gaussian distribution)를 사용하여 기울기를 추정하며, 이는 두 개의 부분으로 구성된 공분산 행렬(covariance matrix)을 사용하여 구현됩니다. 첫 번째 부분은 최근의 훈련 궤적에 의해 형성된 부분공간을 포함하며, 두 번째 부분은 아이덴티티 행렬(identity matrix)로, 이는 전역적인 탐색(global exploration)을 보장합니다. 기울기 추정에는 수렴 속도가 기존 방법들이 유지되면서 통신 오버헤드가 거의 없는 장점이 있습니다.

- **Performance Highlights**: 여러 수치 실험을 통해 제안된 방법의 효과가 검증되었으며, 기존에 과대 평가된 기울기 추정 방법에 비해 개선된 성능을 보였습니다. 이 방법은 특히 로컬 데이터 샘플만을 사용해도 강력한 결과를 도출할 수 있습니다.



### Overcoming Reward Model Noise in Instruction-Guided Reinforcement Learning (https://arxiv.org/abs/2409.15922)
Comments:
          9 main body pages, 7 appendix pages

- **What's New**: 이번 연구에서는 비전-언어 모델(vision-language models, VLMs)의 보상 모델로서의 사용 시 발생할 수 있는 치명적인 결함을 밝힙니다. 특히 보상 신호에 소음이 포함될 경우 에이전트의 성능이 현저히 저하될 수 있음을 증명하였습니다.

- **Technical Details**: 연구진은 기존의 코사인 유사성(cosine similarity) 측정 방식의 한계를 지적하며, 잘못된 보상을 야기할 수 있는 이유로 '오답 보상(false positive rewards)'이 더 유해하다고 주장합니다. 이를 해결하기 위해 이진 상호정보(Binary Mutual Information, BiMI)라는 새로운 보상 함수를 도입했습니다. BiMI는 보상 신호의 잡음을 줄이기 위해 설계되었으며, 에이전트의 성능을 평균적으로 44.5% 향상시켰습니다.

- **Performance Highlights**: BiMI를 사용한 실험 결과는 다양한 환경에서의 에이전트 성능을 크게 개선했으며, 이는 VLM 기반 보상 모델이 실제 적용에서 더욱 타당성을 지니게 함을 보여줍니다.



### FedRepOpt: Gradient Re-parametrized Optimizers in Federated Learning (https://arxiv.org/abs/2409.15898)
- **What's New**: 이 논문에서는 Federated Learning(FL) 환경에서 머신 러닝 모델의 훈련을 위한 새로운 방법론인 FedRepOpt를 제안합니다. FedRepOpt는 복잡한 모델과 유사한 성능을 내는 간단한 로컬 모델을 학습할 수 있도록 하는 gradient re-parameterization 기법을 활용합니다.

- **Technical Details**: FedRepOpt는 VGG 스타일과 Ghost 스타일 모델에서의 FL 환경에 적합한 optimizer로, 복잡한 모델에서 추출된 모델 특화 하이퍼파라미터에 따라 optimizer의 gradient를 수정합니다. 이를 통해 FedRepOpt 기반 모델이 RepGhost 스타일 및 RepVGG 스타일 네트워크에 비해 성능이 각각 16.7% 및 11.4% 향상되었음을 실험적으로 입증하였습니다.

- **Performance Highlights**: FedRepOpt를 사용하는 모델은 복잡한 구조에 비해 11.7% 및 57.4%의 빠른 수렴 시간을 달성하며, FL 환경에서 높은 성능과 효율성을 보여줍니다. 또한, FedRepOpt는 저사양 및 고사양 기기에서 유효한 성능을 유지하면서도 비슷한 학습 패턴을 보입니다.



### Self-Supervised Graph Embedding Clustering (https://arxiv.org/abs/2409.15887)
- **What's New**: 이번 논문에서는 K-means 군집화에 기반한 새로운 통합 프레임워크를 제안합니다. 이 프레임워크는 저차원 매니폴드(low-dimensional manifold) 클러스터링을 통해 클러스터 간의 클래스(class) 균형을 유지하면서 군집화의 효과를 극대화합니다.

- **Technical Details**: 제안한 방법은 중심이 없는 K-means(centroid-free K-means)와 저차원 그래프 임베딩(graph embedding)을 통합하여, 군집화와 임베딩을 동시에 수행합니다. 레이블(label) 정보는 지역 구조(local structure)와 결합되어 매니폴드 구조를 형성합니다. 또한, ℓ_{2,1}-norm을 최대화하여 클래스 균형을 자연스럽게 유지함을 이론적으로 증명하였습니다.

- **Performance Highlights**: 여러 데이터셋에 대한 실험 결과, Our-LPP 및 Our-MFA 모델이 우수하고 신뢰할 수 있는 클러스터링 성능을 보였습니다. 제안된 방법은 중앙 중심점의 선택에 민감하지 않으며, 복잡한 하이퍼파라미터 없이 효과적인 군집화를 가능하게 합니다.



### iGAiVA: Integrated Generative AI and Visual Analytics in a Machine Learning Workflow for Text Classification (https://arxiv.org/abs/2409.15848)
- **What's New**: 이 논문에서는 텍스트 분류를 위한 기계 학습(ML) 모델 개발 시 데이터 부족 문제를 해결하기 위해 시각적 분석(Visual Analytics, VA)을 활용하여 합성 데이터를 생성하는 방법을 제안합니다. 이는 대규모 언어 모델을 활용하여 특정 데이터 부족 문제를 목표로 한 데이터 합성을 가능하게 합니다.

- **Technical Details**: 다양한 데이터 부족 유형을 논의하고, 이러한 부족을 식별하기 위한 다양한 VA 기법을 설명합니다. 또한, iGAiVA라는 소프트웨어 도구를 소개하여 4개의 ML 작업 그룹을 4개의 VA 뷰에 매핑하고, 생성적 AI와 VA를 ML 워크플로우에 통합했습니다.

- **Performance Highlights**: 대상 데이터 합성을 통해 모델 정확도를 향상시키는 효과를 입증했습니다. 이 연구는 ML 텍스트 분류 모델의 개발 및 개선을 위한 새로운 접근 방식을 제공합니다.



### Supervised Fine-Tuning: An Activation Pattern Optimization Process for Attention Heads (https://arxiv.org/abs/2409.15820)
Comments:
          in review

- **What's New**: 이번 논문에서는 LLM의 성능 향상을 위한 새로운 통찰력을 제시합니다. SFT(Supervised Fine-tuning) 과정에서의 주의 패턴(Attention Patterns)을 분석하여 LLM들이 복잡한 작업에 어떻게 적응하는지를 설명합니다.

- **Technical Details**: 저자들은 경량화된 gradient 기반 방법을 사용하여 SFT 과정에서 LLM의 주의 헤드(Attention Heads)가 어떻게 활용되는지를 밝혀냈습니다. 주요 발견은 LLM이 특정 작업에 대해 선택적으로 주의 헤드를 활성화한다는 것입니다.

- **Performance Highlights**: 논문에서 제안한 접근법을 통해 복잡한 작업을 수행할 수 있는 LLM의 성능이 현저히 향상될 수 있음을 보여줍니다. 특히, 주의 패턴을 분석하여 희소한 지침을 활용하면서도 효율성을 극대화할 수 있는 방법을 실험했습니다.



### Aided design of bridge aesthetics based on Stable Diffusion fine-tuning (https://arxiv.org/abs/2409.15812)
Comments:
          10 pages, 13 figures

- **What's New**: 이번 논문에서는 Stable Diffusion의 세부 조정(fine-tuning) 기법을 활용하여 새로운 교량(bridge) 디자인 혁신을 돕는 방법을 제시합니다.

- **Technical Details**: 교량의 실제 사진 데이터셋을 구축하고, Textual Inversion, Dreambooth, Hypernetwork, Lora의 네 가지 방법을 사용하여 Stable Diffusion을 세부 조정합니다. 이 기술들은 데이터셋 이미지의 주요 특성을 포착하여 Stable Diffusion의 개인화(customization)를 실현합니다.

- **Performance Highlights**: 세부 조정된 모델은 다양한 혁신적인 새로운 교량 유형을 생성할 수 있으며, 이는 인간 디자이너에게 풍부한 영감을 제공합니다. 이 기술은 인간 디자이너의 창의력을 촉진하는 엔진(engine of creativity)으로 작용할 수 있습니다.



### Towards Universal Large-Scale Foundational Model for Natural Gas Demand Forecasting (https://arxiv.org/abs/2409.15794)
- **What's New**: 본 연구는 자연가스 수요 예측을 위해 특별히 설계된 첫 번째 기초 모델(Foundation Model)을 제안합니다. 기존 전통적 방법들이 현업에서의 복잡한 수요 패턴 예측에 한계를 보이는 반면, 기초 모델은 이 문제를 해결하기 위한 견고한 솔루션을 제공합니다.

- **Technical Details**: 기반 모델은 대조 학습(contrastive learning)을 활용하여 역사적 소비 데이터의 노이즈 및 유사 샘플의 잘못된 분류 문제가 예측 정확도에 미치는 영향을 개선했습니다. 새로운 노이즈 필터링 기법을 통합하여 학습된 표현의 질을 향상시키고, 산업별 특성을 잘 포착할 수 있도록 사전 훈련(prior tuning) 과정을 수행했습니다.

- **Performance Highlights**: 우리의 모델은 ENN 그룹에서 다수의 산업 및 상업적 고객 데이터(MSE에서 3.68%, MASE에서 6.15% 개선)를 사용한 실험에서 기존의 최첨단 방법을 초월하는 성능을 나타냈습니다.



### Zero-shot forecasting of chaotic systems (https://arxiv.org/abs/2409.15771)
Comments:
          Comments welcome. All zero-shot benchmark forecast results and scripts are available online at this https URL

- **What's New**: 이번 연구는 초기 학습 없이 새로운 시스템을 예측할 수 있는 foundation models의 제로샷(Zero-shot) 학습 패러다임이 혼돈 시스템(chaotic systems) 예측에 적용될 수 있는지를 평가합니다.

- **Technical Details**: 135개의 독특한 혼돈 동역학 시스템과 1억 개의 시점에서 foundation models가 맞춤형 모델과 비교하여 경쟁력 있는 예측을 수행함을 발견했습니다. 특히 훈련 데이터가 제한된 경우에 이러한 경향이 두드러졌습니다.

- **Performance Highlights**: Foundation models는 점 예측이 실패하더라도 혼돈 끌개(chaotic attractors)의 장기적인 통계적 특성을 보존하는 강력한 능력을 보여 주었습니다. 이 연구는 혼돈 시스템에 대한 제로샷 예측에서 foundation models의 가능성과 문제점을 강조합니다.



### Spatial-Temporal Mixture-of-Graph-Experts for Multi-Type Crime Prediction (https://arxiv.org/abs/2409.15764)
- **What's New**: ST-MoGE는 범죄 예측의 공간-시간 이질성을 해결하려고 고안된 혁신적인 프레임워크입니다. 이는 범죄 카테고리에 특화된 Mixture-of-Experts (MoE) 아키텍처를 활용하여 다양한 범죄 패턴을 통합적으로 잡아냅니다.

- **Technical Details**: ST-MoGE는 Attentive-gated Mixture-of-Graph-Experts (MGEs) 모듈을 도입하여 다양한 범죄 카테고리의 공간-시간 의존성을 포착합니다. 또한 Cross-Expert Contrastive Learning (CECL)을 통해 각 전문가가 특정 패턴 모델링에 집중하도록 하여 혼합 및 중복을 줄입니다. Hierarchical Adaptive Loss Re-weighting (HALR) 기법을 통해 불균형적인 공간 분포 문제를 해결합니다.

- **Performance Highlights**: ST-MoGE는 뉴욕시와 시카고 두 개의 실제 범죄 데이터셋을 활용하여 12개의 기존 방법들과 비교하여 탁월한 성과를 보였습니다. 실험 결과, 제안된 방법의 우수성이 입증되었습니다.



### TFG: Unified Training-Free Guidance for Diffusion Models (https://arxiv.org/abs/2409.15761)
- **What's New**: 본 논문은 교육 없이도 원하는 목표 속성을 가진 샘플을 생성할 수 있는 새로운 알고리즘 프레임워크인 Training Free Guidance (TFG)를 소개합니다. 기존 방식들의 이론적 기초와 방대한 벤치마크 테스트가 부족했던 점을 해결하고, TFG에서 기존 방법들이 특별한 하이퍼파라미터 서브스페이스에 해당함을 입증합니다.

- **Technical Details**: TFG의 하이퍼파라미터 검색 전략은 다양한 다운스트림 작업에 쉽게 적용할 수 있도록 설계되었습니다. 이 연구에서는 7개의 확산 모델(difussion models)을 이용해 16개의 작업과 40개의 목표에 대해 체계적으로 벤치마크를 수행했습니다. TFG는_all_datasets에서 평균 8.5% 향상된 성능을 기록하였습니다.

- **Performance Highlights**: TFG는 다양한 복잡도의 목표와 데이터셋에서 사용자 요구에 맞는 샘플을 생성하는 데 뛰어난 성능을 보였습니다. TFG 방법론은 기존 방법들과 비교하여 전반적으로 우수함을 입증하였고, 교육이 필요 없는 조건 생성 알고리즘 관련 연구의 강력한 기반을 제시합니다.



### Development and Validation of Heparin Dosing Policies Using an Offline Reinforcement Learning Algorithm (https://arxiv.org/abs/2409.15753)
- **What's New**: 본 연구는 강화학습(Artificial Intelligence, AI) 기반의 개인화된 헤파린(heparin) 투여 정책을 제안하여 집중치료실(ICU)에서의 복잡한 약물 투여 문제를 해결합니다. 이는 정교한 의사결정 지원 도구의 개발을 위한 선례를 마련합니다.

- **Technical Details**: 이 연구는 향상된 기계 학습 기술과 대규모 임상 데이터(Medical Information Mart for Intensive Care III, MIMIC-III)를 활용하여 헤파린 투여의 정확성을 높이는 방법을 제시합니다. 배치 제약 강화 학습(batch-constrained RL) 접근 방식을 통해 비원주율 오류를 최소화하고, 가중 중요 샘플링(weighted importance sampling) 기술을 사용하여 정책의 효과성을 평가합니다.

- **Performance Highlights**: 제안된 배치 제약 Q 학습(Batch-Constrained Q-learning, BCQ) 알고리즘은 기존의 딥 RL(ddeep Reinforcement Learning) 방식보다 성능이 우수하며, t-SNE 기법을 통해 정책의 효율성을 시각적으로 분석하고 헤파린 투여의 효과를 극대화하는 데 기여합니다.



### The Roles of Generative Artificial Intelligence in Internet of Electric Vehicles (https://arxiv.org/abs/2409.15750)
Comments:
          25 Pages

- **What's New**: 이번 논문은 생성형 인공지능(GenAI) 모델의 발전과 전기차(\acEV) 및 전기차 인터넷(\acIoEV) 애플리케이션에서의 활용을 조사합니다. 특히, GenAI를 통해 IoEV의 다양한 계층에서 전기차의 배터리, 개별 전기차, 스마트 그리드, 그리고 보안 레이어에 대한 구체적인 기술을 분류하고 소개합니다.

- **Technical Details**: 논문에서는 IoEV의 네 가지 주요 레이어를 소개합니다: 배터리 레이어, 개별 EV 레이어, EV가 포함된 스마트 그리드 레이어, 그리고 보안 레이어. 각 레이어에 적용된 GenAI 기술로는 Transformer, \acGAN, \acAE, \acVAE, 그리고 \acGDM 등이 포함됩니다. 또한, 각 레이어의 GenAI 모델 학습을 위한 공개 데이터셋 요약이 제공됩니다.

- **Performance Highlights**: 이 논문은 GenAI 기술을 통해 IoEV 시스템을 더욱 강력하고 효율적으로 발전시키기 위한 미래 연구 방향을 제시합니다. GenAI의 활용은 데이터 부족 문제 해결, 이상 탐지, EV 충전 로드 예측, 시나리오 생성을 통해 IoEV 애플리케이션의 품질을 향상시킬 것으로 기대됩니다.



### Training Neural Networks for Modularity aids Interpretability (https://arxiv.org/abs/2409.15747)
Comments:
          4 pages, preprint

- **What's New**: 본 논문은 신경망의 해석 가능성을 높이기 위해 모델을 분리된 클러스터로 나누는 새로운 접근법을 제시합니다. 이를 통해 모델의 각 기능을 독립적으로 연구할 수 있습니다. 또한, 'enmeshment loss'라는 새로운 손실 함수를 도입하여 훈련 동안 비상호작용 클러스터를 형성할 수 있도록 유도합니다.

- **Technical Details**: 기존의 클러스터링 방법은 신경망의 해석에 비효율적이라는 점을 강조하며, 'Bipartite Spectral Graph Clustering (BSGC)' 알고리즘을 제안합니다. 이 알고리즘은 가중치 기반의 유사도 행렬을 사용하여 신경망의 레이어를 bipartite 클러스터로 나누며, 이 과정에서 'enmeshment loss'가 클러스터의 모듈화를 촉진합니다. 이 손실 항은 훈련 중에 클러스터 간의 간섭을 최소화하는 데 도움을 줍니다.

- **Performance Highlights**: CIFAR-10 데이터셋에서 실험을 통해 클러스터링된 모델은 95% 이상의 정확도를 유지하며, 효과적인 회로 크기(ECS)가 줄어들어 해석 가능성이 향상되었습니다. 연구 결과, 클러스터링된 모델은 비클러스터 모델에 비해 평균적으로 61.25% 더 적은 파라미터를 갖는 효과적인 회로를 생성하여, 독립적으로 클러스터가 기여하는 정도를 보여줍니다.



### EvoFA: Evolvable Fast Adaptation for EEG Emotion Recognition (https://arxiv.org/abs/2409.15733)
- **What's New**: EEG 기반 감정 인식에서의 모델 재사용 시 성능 저하 문제를 해결하기 위해, 본 논문에서는 Evolvable Fast Adaptation (EvoFA)라는 온라인 적응 프레임워크를 제안했습니다. 이 프레임워크는 Few-Shot Learning (FSL)과 Domain Adaptation (DA)을 통합하여 빠른 적응과 분포 일치를 이룹니다.

- **Technical Details**: EvoFA는 두 단계 일반화 과정을 통해 FSL의 빠른 적응성과 DA의 분포 일치를 조화롭게 결합합니다. 학습 단계에서는 강력한 일반화 능력을 지닌 메타 학습 모델을 구축하고, 테스팅 단계에서는 진화하는 소스 데이터를 기반으로 타겟 데이터의 주변 분포를 반복적으로 정렬하여 온라인 테스트 성능을 향상시킵니다.

- **Performance Highlights**: EvoFA는 기존 FSL 방법 및 이전의 온라인 방법들과 비교해 상당한 성능 향상을 달성했습니다. 본 연구는 실제 상황에서 EEG 기반 감정 인식의 보다 폭넓은 사용을 가능하게 합니다.



### Federated Large Language Models: Current Progress and Future Directions (https://arxiv.org/abs/2409.15723)
- **What's New**: 이번 논문은 Federated Learning (FL)과 Large Language Models (LLMs) 간의 상호작용을 심도 있게 분석하여 최신 발전 사항과 향후 방향성을 제시합니다. 특히, 데이터 프라이버시와 함께 LLMs의 학습 효율성을 개선하기 위해 각종 방법론과 과제를 살펴봤습니다.

- **Technical Details**: 논문은 LLMs의 Federated Learning(FedLLM)에서의 최신 기법을 요약하고, 세 가지 주요 측면인 데이터 이질성(data heterogeneity), 개인화(personalization), 및 보안(security) 문제를 다룹니다. 또한, FedPIT, FFA-LoRA, 그리고 FEDML-HE와 같은 특정 기법들을 소개하여 성능 및 프라이버시를 증대시키는 다양한 접근법을 제시합니다.

- **Performance Highlights**: 이 논문에서 제안된 다양한 방법론들은 LLMs의 훈련 효율을 극대화 하며, 데이터 통신 비용을 최소화합니다. 예를 들어, FedKSeed와 FedRDMA는 통신 요구량을 대폭 줄이며, 여러 가지 협업 학습 시나리오에서 효과적인 성과를 보여줍니다.



### Applying Incremental Learning in Binary-Addition-Tree Algorithm for Dynamic Binary-State Network Reliability (https://arxiv.org/abs/2409.15721)
- **What's New**: 본 논문은 Binary-Addition-Tree(BAT) 알고리즘을 향상시키기 위해 incremental learning 기법을 통합한 새로운 접근법을 제시합니다.

- **Technical Details**: BAT는 네트워크 신뢰성(Network Reliability) 및 최적화(Optimization) 문제를 해결하기 위한 강력한 implicit enumeration 방법입니다. 그러나 전통적인 BAT는 정적 특성으로 인해 동적이고 대규모 네트워크에서는 어려움을 겪습니다. 저자들은 incremental learning을 도입함으로써 BAT가 새로운 데이터나 네트워크 변화에 맞추어 성능을 반복적으로 개선할 수 있도록 합니다.

- **Performance Highlights**: 실험 결과는 제안된 방법이 전통적인 BAT와 MP 기반 알고리즘, MC 기반 알고리즘에 비해 계산 효율성과 해결 품질 모두에서 상당한 개선을 보임을 나타냅니다.



### Adversarial Federated Consensus Learning for Surface Defect Classification Under Data Heterogeneity in IIo (https://arxiv.org/abs/2409.15711)
- **What's New**: 이 논문에서는 데이터 이질성과 개인 정보 보호 문제를 해결하기 위한 새로운 개인화된 연합 학습 방법론인 Adversarial Federated Consensus Learning (AFedCL)을 제안합니다. 이 방법은 여러 클라이언트 간 협업 학습을 통해, 각 클라이언트의 특정 데이터 분포에 최적화된 개인화된 모델을 개발합니다.

- **Technical Details**: AFedCL은 adversarial training을 활용하여 클라이언트 간 데이터 분포를 정렬하고, 글로벌 지식 망각 문제를 완화합니다. 이 접근 방식은 동적 합의 구조 전략과 합의 인식 집계 메커니즘(aggregation mechanism)을 결합하여 클라이언트의 글로벌 지식 학습 효율성을 기반으로 집계 가중치를 부여합니다. 또한, 글로벌 및 로컬 기능을 최적의 비율로 활용하기 위해 적응형 특징 융합 모듈을 설계하였습니다.

- **Performance Highlights**: AFedCL 방식은 세 가지 스트립 스틸 SDC 데이터셋에서 기존의 최신 방법인 FedALA에 비해 최대 5.67%의 정확도 증가를 달성했습니다.



### GraphGI:A GNN Explanation Method using Game Interaction (https://arxiv.org/abs/2409.15698)
- **What's New**: 본 논문에서는 GraphGI라는 새로운 설명 기법을 제안합니다. 이는 모델의 예측을 설명하기 위해 상호작용 강도가 가장 높은 coalition을 식별하고 이를 설명 하위 그래프로 나타냅니다.

- **Technical Details**: GraphGI는 훈련된 모형과 입력 그래프를 기반으로 하여 중요한 edge를 점진적으로 추가하여 예측을 설명합니다. 게임 이론에 기반한 상호작용 값이 사용되어 edge 추가 후 상호작용 강도를 평가합니다. Shapley 값 및 게임 이론적 상호작용 값을 계산하기 위한 효과적인 근사 기법이 도입되었습니다.

- **Performance Highlights**: 실험 결과 GraphGI는 우수한 충실도(fidelity)와 희소성(sparsity)을 제공하여 결과의 해석 가능성을 유지한 것으로 나타났습니다.



### Linear Contextual Bandits with Interferenc (https://arxiv.org/abs/2409.15682)
- **What's New**: 이 논문은 여러 단위가 동시에 존재하는 상황에서 Contextual Bandits (CB)에서의 간섭(interference) 문제를 다루는 첫 번째 연구로, 인과 추론(causal inference)과 온라인 의사결정(online decision-making) 간의 간극을 메우고 있습니다.

- **Technical Details**: 저자들은 Linear Contextual Bandits (LinCB) 모델을 확장하여 간섭을 고려한 체계적인 프레임워크를 제시하고, 보상 모델링 과정에서의 간섭 효과를 명시적으로 정량화하는 알고리즘을 개발하였습니다. 이와 함께, 서브선형 후회(sublinear regret) 경계와 유한 샘플 상한(finite sample upper bounds), 비대칭 속성(asymptotic properties) 등의 포괄적인 이론적 보장을 제공합니다.

- **Performance Highlights**: 시뮬레이션 및 MovieLens 데이터를 기반으로 생성한 합성 데이터(synthetic data)를 통해 제안된 접근법의 효과를 입증하였습니다.



### Distributed Online Bandit Nonconvex Optimization with One-Point Residual Feedback via Dynamic Regr (https://arxiv.org/abs/2409.15680)
- **What's New**: 이 논문은 변동하는 유향 그래프( digraph) 상의 비볼록( nonconvex) 손실 함수들에 대한 분산 온라인( distributed online) 밴딧 최적화 문제에 대해 다룹니다. 기존의 다중포인트( multi-point) 밴딧 알고리즘이 온라인 최적화에 적합하지 않다는 점을 강조하고, 새로운 하나의 포인트( one-point) 잔여 피드백( residual feedback) 분산 온라인 알고리즘을 제안합니다.

- **Technical Details**: 제안된 알고리즘은 두 지점의 잔여정보를 이용하여 기울기( gradient)를 추정하고, 각 반복(iteration) 당 샘플링 복잡성이 𝒪(1)인 점에서 손실에 대한 후회 경계를 줄입니다. 알고리즘의 성능 평가는 동적 후회( dynamic regret)를 이용하여 수행됩니다. 적절한 단계 크기와 평활 매개변수를 선택함으로써 이 알고리즘의 기대 동적 후회가 기존 두 포인트 피드백을 사용하는 알고리즘과 유사하게 설정될 수 있음을 보여줍니다.

- **Performance Highlights**: 수치 시뮬레이션을 통해 제안한 알고리즘의 효과성을 입증하였으며, 전통적인 하나의 포인트 피드백 알고리즘과 비교했을 때 성능이 크게 개선되었습니다. 이러한 알고리즘은 비볼록 최적화 문제에 대한 현실에서의 적용 가능성을 높입니다.



### Double-Path Adaptive-correlation Spatial-Temporal Inverted Transformer for Stock Time Series Forecasting (https://arxiv.org/abs/2409.15662)
- **What's New**: DPA-STIFormer라는 새로운 Spatial-Temporal Transformer 모델이 주식 예측을 위한 혁신적인 방법으로 제안되었습니다. 이 모델은 시간 단계를 토큰으로 사용하지 않고, 특징 변화에 따라 각 노드를 모델링함으로써 더 포괄적으로 동적인 공간 정보를 추출합니다.

- **Technical Details**: DPA-STIFormer는 Double-Path Adaptive-correlation Inverted Encoder와 Decomposed Fitting을 포함한 단일 Decoder Block으로 구성됩니다. 이 모델은 Softmax Attention 메커니즘을 사용하여 중요 가중치를 포함한 토큰 간의 상관관계를 학습하고, Double-Path 방식으로 서로 다른 두 종류의 상관관계를 통합합니다.

- **Performance Highlights**: 4개의 주식 데이터셋에 대한 실험 결과, DPA-STIFormer는 주식 시장의 공간-시간 상관관계를 더 효과적으로 모델링할 수 있는 능력을 보여주며, 기존 방법들보다 뛰어난 성능을 달성했습니다.



### Looped Transformers for Length Generalization (https://arxiv.org/abs/2409.15647)
- **What's New**: 이번 연구에서는 Adaptive Steps를 갖춘 Looped Transformers가 Length Generalization을 크게 향상시킨다는 점을 보여주었습니다. 이는 알고리즘적 작업에서의 입력 길이가 미지의 경우에도 효과적으로 작동함을 의미합니다.

- **Technical Details**: Looped Transformers는 기본적으로 Transformer 아키텍처를 기반으로 하며, 여러 번 입력 시퀀스를 처리하여 중간 출력을 다음 반복의 입력으로 전달합니다. 이 구조는 알고리즘적 솔루션의 복잡성에 따라 유연하게 단계 수를 조정할 수 있습니다. 핵심 아이디어는 n-n-RASP-L 문제에 대한 학습을 통해 정답을 단계적으로 감독하는 것입니다.

- **Performance Highlights**: Empirical 결과에 따르면, Looped Transformers는 다양한 작업에서 길이 일반화 성능이 기존 방법에 비해 우수한 결과를 보이며, 문제 복잡성에 따라 적응적인 단계 수를 활용하여 효과적으로 해결할 수 있습니다.



### Personalized Federated Learning via Backbone Self-Distillation (https://arxiv.org/abs/2409.15636)
Comments:
          Pubished in ACM MMAsia 2023

- **What's New**: 이 논문에서는 개인화된 연합 학습을 촉진하기 위해 백본(Backbone) 자기 증류(Self-Distillation) 접근 방식을 제안합니다. 각 클라이언트가 로컬 모델을 훈련하고 오직 백본 가중치만 서버에 전송하는 방식을 사용합니다.

- **Technical Details**: 각 클라이언트 모델은 공유 백본과 개인 헤드(Head)로 나뉘어 있으며, 서버는 백본 가중치만 집계하여 글로벌 백본을 구축합니다. 그런 다음 각 클라이언트는 글로벌 백본을 교사(Teacher)로 사용하여 로컬 백본을 업데이트 합니다.

- **Performance Highlights**: 12개의 최신 접근 방식과 비교한 실험 결과, 제안된 방법이 성능을 크게 향상시키며, 글로벌 지식 전이(Global Knowledge Transfer)를 통해 클라이언트 모델의 개인화를 효과적으로 지원함을 보여주었습니다.



### Data Augmentation for Sparse Multidimensional Learning Performance Data Using Generative AI (https://arxiv.org/abs/2409.15631)
- **What's New**: 이 논문에서는 학습 성과 데이터의 희소성(data sparsity) 문제를 해결하기 위해 학습 데이터 보강을 위한 체계적인 프레임워크를 제안하고 있습니다. 주목할 점은 텐서 분해(tensor factorization) 기법을 활용하여 결측값을 보간하고 생성적 인공지능(generative AI) 모델을 통해 다양한 학습 성과 패턴을 생성하는 것입니다.

- **Technical Details**: 연구는 학습자의 질문, 답변 및 시도를 포함하는 3차원 텐서로 학습 성과를 표현합니다. 결측값 보간을 위해 텐서 분해 기법을 사용하며, 이는 지식 추적(knowledge tracing) 작업에 기반하여 실측값을 바탕으로 결측 성과 값을 예측할 수 있도록 합니다. 생성적 모델로는 Generative Adversarial Networks (GANs)와 Generative Pre-Trained Transformers (GPT)를 비교하여 다양한 학습 데이터 클러스터의 데이터를 생성합니다.

- **Performance Highlights**: 연구 결과 텐서 분해를 통한 데이터 보강이 지식 마스터리 추적 및 예측 성과를 향상시키며, GAN 기반의 시뮬레이션이 GPT와 비교해 통계적 편향이 적고 전반적인 안정성이 뛰어난 것으로 나타났습니다. 이는 저자의 실험적으로 개발된 성인 읽기 이해(AutoTutor) 데이터셋에서 확인되었습니다.



### Reinforcement Feature Transformation for Polymer Property Performance Prediction (https://arxiv.org/abs/2409.15616)
- **What's New**: 이번 연구는 폴리머(property)의 성능 예측을 위한 새로운 접근 방식을 제안합니다. 특히, 폴리머 데이터셋의 질이 낮아 발생하는 문제를 해결하기 위해 설명 가능한(descriptor) 표현 공간의 최적 재구성을 목표로 하고 있습니다.

- **Technical Details**: 연구에서는 Traceable Group-wise Reinforcement Generation Perspective라는 독창적인 프레임워크를 제안합니다. 이는 Reinforcement Learning(RL)을 기반으로 하여 표현 공간을 단계적으로 생성(generate)하고 선택(select)하는 상호작용 프로세스로 재정의 합니다. 구체적으로는, Markov Decision Processes(MDPs)를 활용하여 논리를 수행하고, 연속적인 강화 학습(cascading reinforcement learning)을 통해 디스크립터의 생성을 자동화합니다.

- **Performance Highlights**: 실험 결과, 제안된 프레임워크는 폴리머 기계 학습 모델의 성능을 크게 향상시키며, 설명 가능한 방식으로 디스크립터 세트를 자동으로 생성하는 데 성공했습니다.



### Revolutionizing Biomarker Discovery: Leveraging Generative AI for Bio-Knowledge-Embedded Continuous Space Exploration (https://arxiv.org/abs/2409.15612)
- **What's New**: 본 논문은 개인 맞춤형 의학에서 중요한 바이오마커(​biomarker) 식별을 자동화하는 새로운 프레임워크를 제안합니다. 이는 복잡한 생물학적 시스템의 분석 수고를 줄이고, 기계 학습을 통해 보다 효율적이고 효과적인 예측 결과를 도출하는 것을 목표로 합니다.

- **Technical Details**: 제안된 프레임워크는 두 가지 주요 모듈로 구성됩니다: 1) 훈련 데이터 준비, 2) 임베딩(embedding) 최적화-생성(generation). 첫 번째 모듈은 다중 에이전트 시스템을 사용하여 바이오마커 서브셋과 그에 대한 예측 정확성의 쌍을 자동으로 수집하여 훈련 데이터를 생성합니다. 두 번째 모듈은 변환기(transformer) 기반의 구조를 바탕으로 임베딩 공간을 학습하며, 예측 정확성을 향상시키기 위한 최적화를 수행합니다.

- **Performance Highlights**: 이 연구는 세 개의 실제 데이터셋에 대한 광범위한 실험을 통해 제안된 방법의 효율성, 강건성(robustness), 효과성을 입증하였습니다. 자동화된 바이오마커 식별을 통해, 더 적은 노동력으로 더욱 정확한 예측 결과를 도출할 수 있는 가능성을 보여주었습니다.



### Deep Learning Approach for Knee Point Detection on Noisy Data (https://arxiv.org/abs/2409.15608)
- **What's New**: 이번 논문에서는 노이즈가 있는 데이터 내에서 knee point를 찾는 데 있어 새로운 접근 방식을 제안합니다. 기존 연구들은 원래 스케일의 데이터 기반으로 knee point를 정의했으나, 본 연구에서는 정규화된 데이터 기반의 knee point 정의를 제시하며, 수학적 곡률(curvature) 정의를 도입합니다.

- **Technical Details**: 정규화된 이산 데이터 포인트에 대한 수학적 곡률 정의를 사용해 knee point를 식별합니다. 노이즈를 포함한 합성 데이터를 생성하여 실제 시나리오를 모사하고, U-Net-like 아키텍처를 가진 CNN(Convolutional Neural Network)을 사용하여 knee point를 정확하게 탐지합니다.

- **Performance Highlights**: 제안된 모델은 모든 합성 데이터셋에 대해 기존 방법들보다 뛰어난 성능을 보였으며, 모든 테스트 세트에서 최상의 F1 점수를 기록했습니다.



### Polyatomic Complexes: A topologically-informed learning representation for atomistic systems (https://arxiv.org/abs/2409.15600)
- **What's New**: 이 논문에서는 화학 구조의 강력한 표현을 개발하는 데 어려움을 겪고 있는 가운데, 새로운 'polyatomic complexes'라는 표현을 제안합니다. 이는 모든 구조적, 기하학적, 효율성 및 일반화 제약 조건을 충족한다고 입증되었습니다.

- **Technical Details**: 논문은 atomistic system을 인코딩하기 위한 일반 알고리즘을 제공합니다. 제안된 방법은 기존의 SMILES, ECFP 및 SELFIES와 같은 다른 화학 구조 표현의 제한을 해결하고, 각 원자의 화학적 속성을 포함하여 긴 거리 상호 작용을 고려할 수 있는 능력을 갖추고 있습니다. 이로 인해 표현이 선형적으로 작동함을 보였으며, 시간 복잡도는 O(S)로 입증되었습니다.

- **Performance Highlights**: 다양한 작업에서 현재의 최첨단 방법과 비교할 수 있는 성능을 보고하였으며, 모든 코드와 데이터셋이 오픈소스로 제공됩니다. 이는 연구자들이 새로운 표현 방법을 쉽게 활용할 수 있음을 의미합니다.



### CauSkelNet: Causal Representation Learning for Human Behaviour Analysis (https://arxiv.org/abs/2409.15564)
- **What's New**: 이 연구는 인간의 관절 역학과 복잡한 행동을 더 잘 이해하기 위해 인과 추론(causal inference) 기반의 새로운 표현 학습 방법을 도입했습니다.

- **Technical Details**: 제안된 방법은 Peter-Clark(PC) 알고리즘과 Kullback-Leibler(KL) divergence를 결합한 두 단계(framework) 프레임워크를 사용하여 관절 간의 인과 관계를 식별하고 정량화합니다. 이 방법은 상호작용(interactions)을 효과적으로 포착하고 해석 가능하며 견고한 표현을 생성합니다.

- **Performance Highlights**: EmoPain 데이터셋에서 실험 결과, 우리의 인과 GCN은 전통적인 GCN보다 정확도(accuracy), F1 스코어, 재현율(recall)에서 뛰어난 성능을 보였으며, 특히 보호 행동(protective behaviors)을 감지하는 데 강점을 보였습니다. 또한 모델은 데이터 규모 변화에 대해 높은 불변성(invariance)을 유지하여 실제 응용에서의 신뢰성을 향상시켰습니다.



### Stalactite: Toolbox for Fast Prototyping of Vertical Federated Learning Systems (https://arxiv.org/abs/2409.15558)
- **What's New**: 이 논문에서는 다양한 데이터 소유자가 상대적으로 분산된 데이터를 활용하여 머신러닝 모델을 학습할 수 있도록 하는 Vertical Federated Learning (VFL)용 오픈 소스 프레임워크인 Stalactite를 소개합니다. 기존 프레임워크보다 연구자들이 알고리즘 개발에 집중할 수 있도록 UI가 개선되었으며, VFL의 다양한 알고리즘을 쉽게 구현할 수 있는 기능을 제공합니다.

- **Technical Details**: Stalactite는 수학적 개념과 메시지 교환 로직을 분리하는 설계를 통해 VFL 알고리즘을 쉽게 코드로 변환할 수 있도록 합니다. multi-thread, multi-process, distributed 실행 모드를 지원하며, 이들 모드 간의 전환이 간단합니다. 이 프레임워크는 데이터 전송, 훈련 메트릭 저장 등 다양한 기능을 포함하고 있습니다. 또한, Stalactite는 새로운 고유의 공개 데이터셋 SBOL을 제공하며, 레코드 ID를 매칭하여 훈련 집합을 형성합니다.

- **Performance Highlights**: Stalactite는 강화된 logging 기능을 통해 분산 실행 중의 payload, 교환 시간 및 머신러닝 메트릭을 기록할 수 있습니다. 이 프레임워크는 기존의 VFL 알고리즘을 지원하며, 보안성과 성능 면에서 기존 산업 도구의 한계를 극복하고 연구를 위한 실험 환경을 제공합니다.



### CANDERE-COACH: Reinforcement Learning from Noisy Feedback (https://arxiv.org/abs/2409.15521)
- **What's New**: 본 논문에서는 비정상적인 피드백(noisy feedback)으로부터 학습할 수 있는 CANDERE-COACH 알고리즘을 제안합니다. 이 알고리즘은 불완전한 교사(teacher)로부터의 피드백을 처리하여 RL 에이전트가 성공적으로 학습할 수 있도록 해줍니다.

- **Technical Details**: 제안된 CANDERE-COACH 알고리즘은 노이즈 필터링 메커니즘을 포함하여 이미 40%의 잘못된 교사 피드백을 포함한 상황에서도 작동할 수 있습니다. 알고리즘은 피드백을 긍정적(positive) 및 부정적(negative)으로 분류하여 RL 에이전트에게 필요한 정보를 제공합니다. 또한, noise detecting module을 통해 시각적 데이터에서 노이즈를 감지하고 필터링합니다.

- **Performance Highlights**: 세 가지 일반 도메인에서의 실험 결과, 제안된 방법이 기초 선행 연구(baselines)보다 비약적으로 뛰어난 성능을 보여 주었으며, 노이즈가 포함된 피드백에서도 RL 에이전트가 효과적으로 학습할 수 있다는 것을 입증했습니다.



### Enabling Resource-Efficient On-Device Fine-Tuning of LLMs Using Only Inference Engines (https://arxiv.org/abs/2409.15520)
- **What's New**: 이 논문에서는 리소스가 제한된 엣지(Edge) 장치에서 대형 언어 모델(LLMs)을 효율적으로 미세 조정(fine-tuning)하기 위한 새로운 자원 효율적 제로오더(zeroth-order) 최적화 접근 방식을 소개합니다. 특히, 파라미터 효율적인 미세 조정 방법과 통합하여 효과적으로 모델을 조정할 수 있는 방법을 제시합니다.

- **Technical Details**: 제안된 방법은 파라렐라이즈드 랜덤화 그래디언트 추정기(P-RGE)를 사용하여, 고속 및 효율적인 그래디언트 추정을 수행합니다. 이 방법은 외부 루프 및 내부 루프 병렬화를 통해 여러 함수 쿼리를 동시에 처리하고, 메모리 오버헤드를 최소화하며, Quantization 기법과 잘 통합됩니다.

- **Performance Highlights**: P-RGE는 실험을 통해 LLM의 미세 조정 정확도를 유지하면서도 런타임 속도 향상과 메모리 절약을 달성하는 것을 보여주었습니다. 특히, Android 스마트폰 및 Jetson Nano와 같은 엣지 장치에서의 실제 배포 가능성을 입증하였습니다.



### Eagle: Efficient Training-Free Router for Multi-LLM Inferenc (https://arxiv.org/abs/2409.15518)
- **What's New**: Eagle는 기존 LLM 라우터의 한계를 극복하기 위해 고안된 새로운 LLM 라우팅 접근 방식을 제안합니다. 이 시스템은 전역 및 지역 ELO(Elos) 랭킹 모듈을 결합하여 모델 선택의 질을 향상시키고 계산 비용을 줄입니다.

- **Technical Details**: Eagle은 LLM의 일반 능력과 전문 능력을 평가하고, 훈련이 필요 없는 라우터로서 기존 방법들에 비해 4.8%의 초기 설정 시간만 소요하며, 실시간 데이터 업데이트에 대해서는 0.5-1%의 시간만 필요합니다. ELO 알고리즘을 사용하여 모델의 질 순위를 계산하고, 연관된 피드백 정보를 통해 모델을 지속적으로 업데이트합니다.

- **Performance Highlights**: Eagle은 다양한 데이터셋에서 실험을 통해 기존 방법들에 비해 일관되게 우수한 성과를 보였으며, AUC(Area Under Curve) 점수에서 최대 23.52%의 향상을 이뤘습니다. 또한, 초기화 시간은 기준 방법의 1/20로 줄였고, 온라인 처리 시에는 100배에서 200배 더 빠른 속도를 자랑합니다.



### Neural Control Variates with Automatic Integration (https://arxiv.org/abs/2409.15394)
- **What's New**: 이 논문은 임의의 신경망 아키텍처를 활용하여 control variates를 구축하는 방법을 제안합니다. 기존의 접근법이 충분히 표현력이 없는 함수에 의존했던 반면, 본 연구는 learnable parametric model을 이용하여 이 문제를 해결하려고 합니다.

- **Technical Details**: 우리는 신경망을 사용해 적분 함수의 anti-derivative를 근사화하여 control variate 함수를 구성합니다. 이 방법을 Walk-on-sphere 알고리즘에 적용하여 편미분 방정식을 해결하였습니다. 자동 미분(automatic differentiation)을 통해 적분이 이루어질 수 있도록 하는 것이 핵심입니다.

- **Performance Highlights**: 우리의 결과는 다양한 네트워크 아키텍처를 사용하여 기존의 control variate 방법보다 낮은 분산(variance)을 달성함을 보여줍니다. 이 연구는 Monte Carlo integration의 variance를 줄이는 데 있어 중요한 첫 걸음을 내딛었습니다.



### Approximated Orthogonal Projection Unit: Stabilizing Regression Network Training Using Natural Gradien (https://arxiv.org/abs/2409.15393)
- **What's New**: AOPU(Approximated Orthogonal Projection Unit)는 신경망(Neural Network)의 훈련 안정성을 향상시키고 최소 분산 추정(MVE)에 도달할 수 있도록 설계된 새로운 네트워크입니다. AOPU는 이중 매개변수로 그래디언트 역전파를 잘라내는 방식을 제안하며, 이를 통해 신뢰할 수 있는 훈련 안정성을 제공합니다.

- **Technical Details**: AOPU는 주요 두 개의 매개변수를 도입하여 각각의 매개변수가 추적 가능한지 여부를 구분합니다. 이중 매개변수는 추적 가능한 매개변수의 그래디언트 업데이트를 최적화하며, 일부는 자연 그래디언트(NG)에 근사화됩니다. Rank Ratio(RR)라는 해석 가능성 지표를 통해 네트워크의 동역학을 심층적으로 분석할 수 있으며, RR은 샘플의 독립성 비율을 측정하여 모델의 성능 예측에 도움을 줍니다.

- **Performance Highlights**: AOPU는 두 개의 화학 프로세스 데이터셋에서 실험 결과, 기존의 다른 모델들보다 우수한 안정적 수렴성을 보여주어 소프트 센서 분야에서 중요한 발전으로 기록되었습니다.



### Supply Risk-Aware Alloy Discovery and Design (https://arxiv.org/abs/2409.15391)
Comments:
          26 pages, 11 figures, submitted to Materialia

- **What's New**: 본 논문에서는 공급망 위험을 고려한 새로운 합금 디자인 접근 방식을 소개합니다. 이 방법은 기존의 언어 모델과 텍스트 분석을 활용하여 소재 피드스톡 공급 위험 지수를 예측하는 전문 모델을 개발합니다.

- **Technical Details**: 이 접근법은 다목적, 다제약 설계 공간을 효율적으로 탐색하기 위해 Batch Bayesian Optimization (BBO)을 사용합니다. BBO는 성능 목표와 최소화된 공급 위험을 균형 있게 조정하는 파레토 최적의 고엔트로피 합금(HEAs)을 식별하는 데 활용됩니다.

- **Performance Highlights**: MoNbTiVW 시스템을 이용한 사례 연구를 통해 공급 위험을 디자인 과정에 통합함으로써 고성능이면서 지속 가능하고 경제적으로 실행 가능한 합금을 개발할 수 있음을 입증합니다.



### Coverage and Bias of Street View Imagery in Mapping the Urban Environmen (https://arxiv.org/abs/2409.15386)
- **What's New**: 이 논문은 Street View Imagery (SVI)의 환경 정보에 대한 대표성을 정량적으로 평가하는 새로운 워크플로우를 제안합니다. 특히, 도시 환경에서 SVI의 기능 수준 커버리지를 측정하고 데이터의 품질과 신뢰성에 관한 문제를 다룹니다.

- **Technical Details**: 이 연구는 SVI와 목표 기능 간의 위치적 관계 및 환경 장애물의 영향을 통합하여 적용되는 워크플로우를 제안합니다. Isovist 분석 및 Semantic Segmentation 기법이 사용되며, SVI 측정을 위한 지표 시스템을 개발하여 커버리지를 평가합니다. 이 연구는 런던을 사례 연구 지역으로 삼고, 건물 파사드를 검토하여 SVI의 커버리지 및 변동성을 분석합니다.

- **Performance Highlights**: 세 가지 실험을 통해 SVI의 환경 정보 커버리지에서의 잠재적 편향을 식별했습니다. 실험 결과는 기존의 공간 분포 기반 커버리지 추정 방법과 비교하여 SVI 커버리지의 빈곤성이 나타났으며, 데이터 수집 간격이 기능 수준 SVI 커버리지에 미치는 영향을 탐구했습니다.



### ControlMath: Controllable Data Generation Promotes Math Generalist Models (https://arxiv.org/abs/2409.15376)
Comments:
          17 pages

- **What's New**: 본 연구에서는 데이터 증강(data augmentation)에 있어 대형 언어 모델(LLMs)의 제약 사항을 극복하기 위해 ControlMath라는 반복(iterative) 방법론을 소개합니다.

- **Technical Details**: ControlMath는 방정식 생성기(equation-generator) 모듈과 두 개의 LLM 기반 에이전트(agent)를 포함합니다. 방정식 생성 모듈은 다양한 방정식을 생성하고, Problem-Crafter 에이전트는 이를 수학적인 서술 문제로 변환합니다. Reverse-Agent는 'less is more' 원칙에 따라 고품질 데이터를 필터링하고 선택합니다.

- **Performance Highlights**: ControlMathQA는 190,000개의 수학 서술 문제(math word problems)를 포함하고 있으며, 이 데이터셋은 GSM8K와 같은 도메인 내(in-domain) 데이터셋과 결합함으로써 모델의 수학적 일반화(generalization) 능력을 향상시킵니다. 결과적으로 특정 도메인뿐만 아니라 그 너머에서도 성능이 개선되는 것을 보였습니다.



### Enhancing Performance and Scalability of Large-Scale Recommendation Systems with Jagged Flash Attention (https://arxiv.org/abs/2409.15373)
Comments:
          3 pages, 2 figures

- **What's New**: 이 논문은 최신 추천 시스템에서 하드웨어 가속기를 활용하여 복잡한 랭킹 패러다임을 탐색하는 새로운 접근 방식을 제시합니다. 특히, GPU 기반의 계산 비용 문제를 해결하기 위한 Jagged Feature Interaction Kernels와 Jagged Flash Attention을 도입하여 성능을 개선하고 메모리 사용을 줄였습니다.

- **Technical Details**: Jagged Feature Interaction Kernels는 긴 범주형 특징에서 세밀한 인사이트를 추출하기 위한 혁신적인 방법으로, 패딩 없이 동적으로 크기가 조정되는 텐서를 효율적으로 처리합니다. Jagged Flash Attention은 기존의 dense attention에 비해 최대 9배의 속도 향상과 22배의 메모리 절약을 실현합니다. 이를 통해 메모리 사용이 선형적으로 증가하며, 53% 더 메모리 효율성을 보여 줍니다.

- **Performance Highlights**: 생산 모델에서 약 10%의 QPS(Queries Per Second) 향상과 18%의 메모리 절약을 관찰 하였으며, 이는 더 긴 특징과 복잡한 모델 아키텍처를 수용하는 추천 시스템의 확장을 가능하게 합니다.



### Smirk: An Atomically Complete Tokenizer for Molecular Foundation Models (https://arxiv.org/abs/2409.15370)
Comments:
          26 pages, 6 figures

- **What's New**: 이번 연구에서는 분자 기반 모델(Molecular Foundation Models)의 발전을 다루며, 기존의 폐쇄 어휘(tokenizer) 방식에 의해 발생하는 한계를 극복하기 위한 두 가지 새로운 tokenizer(s)인 smirk와 smirk-gpe를 소개합니다. 이들은 OpenSMILES 규격을 전부 표현할 수 있도록 설계되었습니다.

- **Technical Details**: 연구팀은 13개의 화학 전용 tokenizer를 체계적으로 평가하며 SMILES 언어의 커버리지를 분석하였습니다. 이를 통해 다양한 화학 구조를 포괄하지 못하는 기존 모델의 정보 손실 문제를 조명했습니다. 특히, 화학 기원 모형에서 open-vocabulary 모델링의 중요성을 강조하고, 이를 위한 화학적으로 다양한 벤치마크의 필요성을 제기했습니다.

- **Performance Highlights**: 새로 소개된 smirk 및 smirk-gpe tokenizer는 SMILES 문자열의 전 범위를 처리하면서 기존의 방법들에서 겪었던 여러 문제를 회피하는데 성공하였으며, 이는 화학 분자 예측 및 디자인에서의 성능 향상에 기여할 것으로 기대됩니다.



### Geometric Relational Embeddings (https://arxiv.org/abs/2409.15369)
Comments:
          Doctoral Dissertation, 177 pages

- **What's New**: 본 논문은 관계형 데이터의 복잡한 구조적 특성과 기호적 속성을 효과적으로 포착할 수 있는 기하학적 관계 임베딩(geometric relational embeddings) 모델을 제안합니다. 기존의 벡터 임베딩(vector embeddings) 방법론의 한계를 뛰어넘어 기하학적 임베딩을 도입하여 더 정교한 관계 구조 및 이산적 의미를 표현합니다.

- **Technical Details**: 제안된 기하학적 관계 임베딩 모델은 네트워크와 지식 그래프에서의 계층(hierarchies) 및 사이클(cycles)과 같은 복잡한 구조 패턴, 지식 그래프에서의 관계 및 논리적 패턴, 온톨로지에서의 논리적 구조(logical structures), 그리고 엔티티(entity)와 관계(relation) 간의 고차(high-order) 복잡한 관계를 포착하는 데 유효합니다. 이러한 기하학적 임베딩은 하이퍼볼릭 공간(hyperbolic space)과 유클리드 벡터 공간(Euclidean vector space)에서의 기하학적 요소로 데이터 객체를 매핑합니다.

- **Performance Highlights**: 벤치마크 및 실제 데이터셋을 통한 결과는 기하학적 관계 임베딩이 관계 데이터의 이산적, 기호적 및 구조적 특성을 효과적으로 포착함을 보여줍니다. 이로 인해 다양한 관계 추론(task)에서 성능 향상이 발생했습니다.



### Fine-Tuning a Time Series Foundation Model with Wasserstein Loss (https://arxiv.org/abs/2409.15367)
Comments:
          4 main pages; 2 figures

- **What's New**: 이번 연구는 시간 시계열 예측을 위한 기초 모델 개발에 있어 최근의 대형 언어 모델(LLM) 발전에 힘입어, cross-entropy loss 대신 Wasserstein loss를 사용하는 방법을 제안하고 있습니다.

- **Technical Details**: 연구진은 LLM 아키텍처를 토큰화된 시간 시계열 데이터로 교육하여 cross-entropy loss로 주어진 모델을 정밀 조정하였습니다. Wasserstein loss는 클래스 간 거리 정보를 반영하며, 성능 비교를 통해 예측 정확도를 개선하는 것이 입증되었습니다.

- **Performance Highlights**: 22개의 zero-shot 데이터셋에서 평가한 결과, cross-entropy loss에 비해 Wasserstein loss를 사용하는 것이 점 추정(point estimation) 성능을 유의미하게 향상시켰습니다.



### Trajectory Anomaly Detection with Language Models (https://arxiv.org/abs/2409.15366)
- **What's New**: 본 논문은 LM-TAD라는 자가 회귀 인과 주의 학습 모델을 사용하여 궤적(anomaly) 이상 탐지에 대한 새로운 접근을 제안합니다. 이 방법은 궤적과 언어 진술 사이의 유사성을 활용하여 구조적 연관성을 기반으로 궤적의 확률 분포를 학습합니다.

- **Technical Details**: 이 모델은 궤적을 일종의 토큰(토큰화된 GPS 좌표 등) 시퀀스로 취급하여 각 위치를 생성할 확률을 계산하고, 이를 바탕으로 비정상적인 위치를 높은 정밀도로 식별합니다. 사용자의 행동 패턴을 반영하기 위해 사용자 특정 토큰을 통합하였고, perplexity와 surprisal rate 메트릭을 도입하여 궤적 내 특정한 비정상 위치를 탐지합니다.

- **Performance Highlights**: LM-TAD는 Pattern of Life (PoL) 데이터 세트에서 사용자 맥락을 고려한 비정상 궤적을 성공적으로 탐지하여 기존 방법들보다 우수한 성능을 보였고, Porto 택시 데이터 세트에서도 경쟁력 있는 결과를 나타냈습니다. 또한, 이 방법은 온라인 이상 탐지에 적합하여 계산 지연을 대폭 줄일 수 있습니다.



### Novel Saliency Analysis for the Forward Forward Algorithm (https://arxiv.org/abs/2409.15365)
Comments:
          2nd International Conference on Artificial Intelligence, Blockchain, and Internet of Things, (AIBThings)

- **What's New**: 이 논문에서는 신경망 학습에 Forward Forward (FF) 알고리즘을 도입하여 전통적인 백프로파게이션(Backpropagation, BP) 방법에서 벗어난 새로운 접근 방식을 제안합니다. FF 알고리즘은 실제 데이터와 합성 데이터로 두 번의 전방 패스를 실행하여 학습 과정을 단순하고 효율적으로 만듭니다.

- **Technical Details**: FF 알고리즘은 신경망에서 식별되지 않은 비선형성 문제를 해결하는 새로운 방식으로, 긍정적 데이터와 부정적 데이터에 대한 각각의 목표를 달성하는 두 개의 전방 패스를 사용합니다. 이 알고리즘은 기존의 BP 방식 없이도 신경망이 데이터를 직접 학습할 수 있게 합니다.

- **Performance Highlights**: MNIST 및 Fashion MNIST 데이터셋을 활용한 실험 결과, FF 알고리즘은 전통적인 다층 퍼셉트론(Multi-Layer Perceptron, MLP) 아키텍처와 동등한 성능을 보이며, 해석 가능성을 크게 향상시킵니다.



### Combustion Condition Identification using a Decision Tree based Machine Learning Algorithm Applied to a Model Can Combustor with High Shear Swirl Injector (https://arxiv.org/abs/2409.15363)
- **What's New**: 본 연구에서는 메탄 연료를 사용하는 단일 캔 연소기의 역회전 고전단 소용돌이 분사기에서의 음향 압력과 고속 불꽃 이미지를 분석하여 연소 조건을 분류하기 위해 결정 트리 기반의 머신러닝 알고리즘을 활용하였습니다.

- **Technical Details**: 실험은 실험실 모형 가스 터빈 연소기에서 수행되었으며, 고전단 소용돌이 분사기를 통해 연료와 공기가 혼합됩니다. 기하학적 소용돌이 수는 1.5 및 0.8로 설정되었고, 흡입되는 공기는 300 slpm의 일정한 유량으로 공급됩니다. 연구에서 획득한 데이터는 시간 시계열 분석을 통해 특성 특징을 추출하였습니다.

- **Performance Highlights**: 훈련된 머신러닝 모델은 안정적 및 불안정적 작업을 정확하게 분류하였으며, 연구된 매개변수 범위 내에서 연소 조건을 효과적으로 예측할 수 있음을 보여주었습니다.



### Reward-Robust RLHF in LLMs (https://arxiv.org/abs/2409.15360)
- **What's New**: 본 논문에서는 보상 모델의 불안정성과 오류를 해결하기 위한 보상 강건 RLHF(Reward-Robust Reinforcement Learning from Human Feedback) 프레임워크를 제안합니다.

- **Technical Details**: 이 프레임워크는 Bayesian Reward Model Ensembles (BRME)를 통해 보상 함수의 불확실성 집합을 모델링하며, 성능과 강건성을 균형 있게 최적화하는 새로운 목표를 설정합니다.

- **Performance Highlights**: 제안하는 프레임워크는 16개의 다양한 벤치마크에서 전통적인 RLHF를 지속적으로 초월하여 평균 정확도가 약 4% 더 높게 나타났으며, 장기 훈련 과정에서도 더 강한 안정성과 향상된 성능을 보여주었습니다.



### Block-Attention for Efficient RAG (https://arxiv.org/abs/2409.15355)
- **What's New**: 이번 논문에서는 Retrieval-Augmented Generation (RAG) 시나리오에서의 추론 지연 및 비용을 줄이기 위해 설계된 새로운 attention 메커니즘인 Block-Attention을 소개합니다. 기존 방법들과 달리, Block-Attention은 검색된 문서를 블록으로 나누어 각 블록이 KV(state) 상태를 독립적으로 계산하도록 하여 효율성을 높입니다.

- **Technical Details**: Block-Attention 메커니즘은 입력 시퀀스를 여러 블록으로 나누고, 각 블록은 자신만의 KV 상태를 self-attention을 통해 계산합니다. 마지막 블록만이 다른 블록에 접근합니다. 이 기법을 통해 모든 passage를 블록으로 정의하고 그 KV 상태를 메모리에 캐시하여, 추론 시의 지연 시간을 크게 줄일 수 있습니다.

- **Performance Highlights**: 실험 결과에 따르면, Block-Attention을 적용하면 평균 TTFT(첫 번째 토큰까지의 시간)를 98.7% 줄일 수 있으며(3638 ms에서 45 ms로 단축), 첫 번째 토큰을 추출할 때의 FLOPs 역시 99.8% 감소시킵니다. 블록-어텐션 모델은 기존의 self-attention 모델에 비해 (Llama3: 68.4% vs 67.9%, Mistral: 62.8% vs 59.6%) 유사하거나 더 나은 성능을 보여줍니다.



### An Efficient Recommendation Model Based on Knowledge Graph Attention-Assisted Network (KGATAX) (https://arxiv.org/abs/2409.15315)
- **What's New**: 이번 연구에서는 다중 소스 정보를 효과적으로 활용하지 못하는 전통적인 추천 시스템의 한계를 극복하기 위해 'Knowledge Graph Attention-assisted Network (KGAT-AX)'라는 새로운 추천 모델을 제안합니다.

- **Technical Details**: KGAT-AX 모델은 추천 시스템에 지식 그래프(knowledge graph)를 통합하고 주의 메커니즘(attention mechanism)을 도입하여 더 높은 차원의 연결성을 탐구합니다. 다층 상호작용 정보 전파(multilayer interactive information propagation)를 통해 모델은 정보를 집계하여 일반화 능력을 향상시킵니다. 또한, 홀로그램 임베딩(holographic embeddings)을 통해 보조 정보(auxiliary information)를 엔티티에 통합하여, 인접 엔티티의 정보를 학습하여 더 나은 활용이 가능합니다.

- **Performance Highlights**: 실제 데이터셋에 대한 실험을 통해 KGAT-AX 모델의 합리성과 효과성을 입증하였으며, 공공 데이터셋에서 다른 기준선 모델(baseline models)과 비교하여 KGAT-AX가 지식 정보 캡처 및 관계 학습 능력에서 우수함을 확인했습니다.



### Reducing Bias in Deep Learning Optimization: The RSGDM Approach (https://arxiv.org/abs/2409.15314)
- **What's New**: 본 논문에서는 SGDM(단순 경량 경량 경량 하강법)과 Adam을 포함한 기존의 딥러닝 최적화 기법에서의 편향(bias)과 지연(lag)을 해결하기 위한 RSGDM 알고리즘을 제안합니다.

- **Technical Details**: RSGDM 알고리즘은 SGDM에서 발생하는 편향과 지연을 무시할 수 없는 지수 이동 평균(exponential moving averages) 추정의 한계를 분석하여, 미분 보정(differential correction) 기법을 도입하여 이러한 문제를 해결합니다.

- **Performance Highlights**: CIFAR 데이터셋에 대한 실험을 통해 RSGDM 알고리즘이 SGDM 알고리즘에 비해 수렴 정확도(convergence accuracy) 면에서 우수함을 입증하였습니다.



### Visual Prompting in Multimodal Large Language Models: A Survey (https://arxiv.org/abs/2409.15310)
Comments:
          10 pages

- **What's New**: 본 논문은 시각적 프롬프트(visual prompting) 방법에 대한 첫 포괄적 설문조사로, 다중 모달 대규모 언어 모델(MLLMs)의 발전을 다룬다. 이를 통해 기존의 텍스트 기반 프롬프트보다 미세 조정된 비주얼 인스트럭션을 제공하여 MLLMs의 시각적 이해 및 추론 능력을 향상하는 다양한 접근 방식을 소개한다.

- **Technical Details**: MLLMs는 사전 훈련된 대형 언어 모델(LLMs)과 시각적 능력을 결합한 모델로, 단어뿐만 아니라 이미지에 대한 비주얼 프롬프트를 생성하여 더 높은 수준의 상황 이해를 가능하게 한다. 논문은 비주얼 프롬프트의 분류, 자동 프롬프트 주석 생성(generative methods), 시각적 부합(alignment) 방안 및 오브젝트 참조(object referring)에 대한 내용이 포함되어 있다.

- **Performance Highlights**: 강화된 시각적 프롬프트 방법들은 MLLM의 시각적 감각을 더욱 정교하게 하여, 보다 정확한 시각적 기초(visual grounding), 객체 참조 및 조합적 추론(compositional reasoning) 기능을 제공한다고 제안된다.



### Reservoir Static Property Estimation Using Nearest-Neighbor Neural Network (https://arxiv.org/abs/2409.15295)
Comments:
          6 pages, 3 figures; updated to tex source

- **What's New**: 이 논문은 가까운 이웃(nearest-neighbor) 신경망(neural network)을 사용하여 저수지 모델링에서 정적 속성의 공간적 분포를 추정하는 새로운 접근 방식을 제안합니다.

- **Technical Details**: 제안된 방법은 신경망의 강점을 활용하여 복잡하고 비선형(non-linear) 함수를 근사하며, 공간 보간(spatial interpolation) 작업에 특히 유용합니다. 가까운 이웃 알고리즘을 통합하여 데이터 포인트 간의 지역적 공간 관계를 포착하고, 무작위화(randomization)를 통해 보간 과정에서 발생하는 불확실성(uncertainty)을 정량화합니다. 이 접근 방식은 일반적인 지구통계학적 방법인 역거리 가중치(Inverse Distance Weighting, IDW)와 크리깅(Kriging)의 한계를 극복합니다.

- **Performance Highlights**: 이 방법은 공간 근접성과 불확실성 정량화를 통합하여 다공성과 투과성과 같은 정적 속성 예측의 정확성을 향상시킬 수 있습니다.



### Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking (https://arxiv.org/abs/2409.16287)
Comments:
          Project Page: this https URL

- **What's New**: 이번 연구는 동적 딥러닝 환경에서 상호작용 인식을 접목한 온라인 축 추정(closed-loop axis estimation) 파이프라인을 제안합니다. 기존의 오픈 루프(open-loop) 접근 방식의 한계를 극복하여 로봇의 조작 작업의 정밀성과 효율성을 크게 향상시킵니다.

- **Technical Details**: 제안된 방법은 세분화된 3D 포인트 클라우드(point clouds)에서 온라인 축 추정을 통해 상호작용 인식을 통합합니다. 특히, RGBManip 기법을 사용하여 물체의 경미한 움직임을 유도하고, Segment Anything Model 2 (SAM2)를 이용하여 동적 장면의 포인트 클라우드를 세분화합니다. 이를 통해 이동하는 물체의 부위를 마스킹하여 정확한 축 추정을 수행합니다.

- **Performance Highlights**: 실험 결과, 본 방법은 전통적인 오픈 루프 방법에 비해 조작 정확도와 일반화 능력을 크게 향상시켰습니다. 특히, 문 열기 및 서랍 열기 작업과 같은 정밀 축 기반 조작이 필요한 작업에서 기존의 기법들을 능가하는 성능을 보여주었습니다.



